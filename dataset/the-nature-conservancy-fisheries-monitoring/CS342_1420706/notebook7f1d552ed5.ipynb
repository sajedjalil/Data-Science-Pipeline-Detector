{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"127f7d15-876d-ffee-732a-981314de3a07"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"946a2e22-0382-f0d0-dad5-39f448c2caa5"},"outputs":[],"source":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# imports needed for CNN\nimport csv\nimport cv2\nimport os, glob\nimport pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Load the data\ndef load_data(data_dir):\n    \"\"\"\n    From: https://medium.com/@waleedka/traffic-sign-recognition-with-tensorflow-629dffc391a6#.v471kaepx\n    \"\"\"\n    # Get all subdirectories of data_dir. Each represents a label.\n    directories = [d for d in os.listdir(data_dir)\n                   if os.path.isdir(os.path.join(data_dir, d))]\n    # Loop through the label directories and collect the data in\n    # two lists, labels and images.\n    labels = []\n    images = []\n\n    category = 0\n    for d in directories:\n        label_dir = os.path.join(data_dir, d)\n        file_names = [os.path.join(label_dir, f)\n                      for f in os.listdir(label_dir)\n                      if f.endswith(\".jpg\")]\n        \n        # adding an early stop for sake of speed\n        stop = 0\n        for f in file_names:\n            img = cv2.imread(f)\n            imresize = cv2.resize(img, (200, 125))\n            #plt.imshow(imresize)\n            images.append(imresize)\n            labels.append(category)\n            # remove this to use full data set\n            if stop > 10:\n                break\n            stop += 1\n            # end early stop\n            \n        category += 1\n\n    return images, labels\n\ndata_dir = \"../input\"\nimages, labels = load_data(data_dir)\n    \nprint (images)\nprint (labels)\n\n\n\ndef cross_validate(Xs, ys):\n    X_train, X_test, y_train, y_test = train_test_split(\n            Xs, ys, test_size=0.2, random_state=0)\n    return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = cross_validate(images, labels)\n\n\n\n# normalize inputs from 0-255 and 0.0-1.0\nX_train = np.array(X_train).astype('float32')\nX_test = np.array(X_test).astype('float32')\nX_train = X_train / 255.0\nX_test = X_test / 255.0\n\n# one hot encode outputs\ny_train = np.array(y_train)\ny_test = np.array(y_test)\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]\nprint(\"Data normalized and hot encoded.\")\n\n\n\n\ndef createCNNModel(num_classes):\n\n    # Create the model\n    model = Sequential()\n    model.add(Convolution2D(32, 3, 3, input_shape=(125, 200, 3), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n    model.add(Dropout(0.2))\n    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    # Compile model\n    epochs = 1  # >>> should be 25+\n    lrate = 0.01\n    decay = lrate/epochs\n    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    print(model.summary())\n    return model, epochs\n\n# create our CNN model\nmodel, epochs = createCNNModel(num_classes)\nprint(\"CNN Model created.\")\n\n\n\n# fit and run our model\nseed = 7\nnp.random.seed(seed)\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epochs, batch_size=64)\n# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))\n\nprint(\"done\")\n\n\n\nfrom os import listdir\nfrom os.path import isfile, join\n\nprediction_output_list = []  # list of lists, containing logistic regression for each file\nfnames = [f for f in listdir(\"../input/test_stg1/\") if isfile(join(\"../input/test_stg1/\", f))]\nprint(\"Testing File Names:\")\nprint(fnames)\n\n# early stoppage...\n# only do 10\ni = 0\nfor f in fnames:\n    file_name = \"../input/test_stg1/\" + f\n    print(\"---Evaluating File at: \" + file_name)\n    img = cv2.imread(file_name)  \n    imresize = cv2.resize(img, (200, 125))  # resize so we're always comparing same-sized images\n    imlist = np.array([imresize])\n    print(\"Neural Net Prediction:\")\n    cnn_prediction = model.predict_proba(imlist)\n    print(cnn_prediction)\n\n    # format list for csv output\n    csv_output_list = []\n    csv_output_list.append(f)\n    for elem in cnn_prediction:\n        for value in elem:\n            csv_output_list.append(value)\n\n    # append filename to make sure we have right format to write to csv\n    print(\"CSV Output List Formatted:\")\n    print(csv_output_list)\n\n\n    # and append this file to the output_list (of lists)\n    prediction_output_list.append(csv_output_list)\n\n    ############## STOP EARLY TO SAVE TIME #################\n    if i > 10:\n        #break\n        i += 1\n    #####  REMOVE TO RUN AGAINST FULL TEST SET ########\n\n# Write to csv\n\n#  Commented out for Kaggle, but you can use this to write to a CSV on your own computer.\ntry:\n    with open(\"cnn_predictions.csv\", \"wb\") as f:\n        writer = csv.writer(f)\n        writer.writerow(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])\n        writer.writerows(prediction_output_list)\nfinally:\n    f.close()\n\nprint(\"done\")\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3533ec01-7e63-941e-757d-ed816ac7b0e3"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}