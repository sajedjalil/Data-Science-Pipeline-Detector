{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c92a0cdc-b392-168e-547f-1cb36f6724d5"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5860b2b7-4e52-b74e-1574-6acfd1f26975"},"outputs":[],"source":"import numpy as np\nfrom keras.layers.core import  Lambda, Merge\nfrom keras.layers.convolutional import Convolution2D\nfrom keras import backend as K\nfrom keras.engine import Layer\nfrom os import listdir\nfrom os.path import isfile, join, dirname\nfrom scipy.io import loadmat\nimport gc\nfrom keras.utils.layer_utils import layer_from_config\nfrom keras.models import Model\nfrom keras.layers import *\n\n# Credits to heuritech for their great code which was a great inspiration.\n# Some of the code comes directly from their repository.\n# You can look it up: https://github.com/heuritech/convnets-keras\n\n\t\n# Keras doesn't have a 4D softmax. So we need this.\nclass Softmax4D(Layer):\n    def __init__(self, axis=-1,**kwargs):\n        self.axis=axis\n        super(Softmax4D, self).__init__(**kwargs)\n\n    def build(self,input_shape):\n        pass\n\n    def call(self, x,mask=None):\n        e = K.exp(x - K.max(x, axis=self.axis, keepdims=True))\n        s = K.sum(e, axis=self.axis, keepdims=True)\n        return e / s\n\n    def get_output_shape_for(self, input_shape):\n        return input_shape\n\t\t\n\ndef get_dim(model, layer_index, input_shape=None):\n    \n    # Input shape is the shape of images used during training.\n    if input_shape is not None:\n        dummy_vector = np.zeros((1,) + input_shape)\n    else:\n        if model.layers[0].input_shape[2] is None:\n            raise ValueError('You must provide \\\"input_shape = (3,256,256)\\\" for example when calling the function.')\n        dummy_vector = np.zeros((1,) + model.layers[0].input_shape[1:])\n    \n    intermediate_layer_model = Model(input=model.input,\n                                 output=model.layers[layer_index].output)\n    \n    out = intermediate_layer_model.predict(dummy_vector)\n    \n    return out.shape[1:]\n\t\n\ndef from_config(layer, config_dic):\n    config_correct = {}\n    config_correct['class_name'] = type(layer)\n    config_correct['config'] = config_dic\n    return layer_from_config(config_correct)\n\t\n\ndef add_to_model(x, layer):\n    new_layer = from_config(layer, layer.get_config())\n    x = new_layer(x)\n    if layer.get_weights() is not None:\n        new_layer.set_weights(layer.get_weights())\n    return x\n\t\n\ndef layer_type(layer):\n    return str(layer)[10:].split(\" \")[0].split(\".\")[-1]\n\t\n\ndef detect_configuration(model):\n    # must return the configuration and the number of the first pooling layer\n    \n    # Names (types) of layers from end to beggining\n    inverted_list_layers = [layer_type(layer) for layer in model.layers[::-1]]\n    \n    layer1 = None\n    layer2 = None \n    \n    i = len(model.layers)\n    \n    for layer in inverted_list_layers:\n        i -= 1\n        if layer2 is None:\n            if layer == \"GlobalAveragePooling2D\" or layer == \"GlobalMaxPooling2D\":\n                layer2 = layer\n\n            elif layer == \"Flatten\":\n                return \"local pooling - flatten\", i-1\n            \n        else:\n            layer1 = layer\n            break\n            \n    if layer1 == \"MaxPooling2D\" and layer2 == \"GlobalMaxPooling2D\":\n        return \"local pooling - global pooling (same type)\", i\n    elif layer1 == \"AveragePooling2D\" and layer2 == \"GlobalAveragePooling2D\":\n        return \"local pooling - global pooling (same type)\", i\n    \n    elif layer1 == \"MaxPooling2D\" and layer2 == \"GlobalAveragePooling2D\":\n        return \"local pooling - global pooling (different type)\", i+1\n    elif layer1 == \"AveragePooling2D\" and layer2 == \"GlobalMaxPooling2D\":\n        return \"local pooling - global pooling (different type)\", i+1\n    \n    else:\n        return \"global pooling\", i\n\t\t\n    \ndef add_zeros(w, nb_zeros):\n    \n    n = w.shape[3]\n    indexes = np.array(range(1, n))\n    w1 = w\n    for i in range(nb_zeros):\n        w1 = np.insert(w1, indexes + i, 0, axis=2)\n    for i in range(nb_zeros):\n        w1 = np.insert(w1, indexes + i, 0, axis=3)\n    return w1\n\t\n    \ndef insert_weights(layer, new_layer):\n    W,b = layer.get_weights()\n    n_filter,previous_filter,ax1,ax2 = new_layer.get_weights()[0].shape\n    ax1 = ax2 = int(np.sqrt(layer.get_weights()[0].shape[0]/new_layer.get_weights()[0].shape[1]))\n    new_W = W.reshape((previous_filter,ax1,ax2,n_filter))\n    new_W = new_W.transpose((3,0,1,2))\n    new_W = new_W[:,:,::-1,::-1]\n\t\n    \n    if ax1!=1:\n        insert_zeros = int((new_layer.get_weights()[0].shape[2] - ax1)/(ax1-1))\n        print(\"insert_zeros=\" + str(insert_zeros))\n        new_W =  add_zeros(new_W, insert_zeros)\n    \n    new_layer.set_weights([new_W,b])\n\t\n    \ndef copy_last_layers(model, begin,x):\n    \n    i=begin\n    \n    for layer in model.layers[begin:]:\n        if layer_type(layer) == \"Dense\":\n            \n            if i == len(model.layers)-1:\n                x = add_reshaped_layer(layer,x,1, no_activation=True)\n            else:\n                x = add_reshaped_layer(layer,x,1)\n            \n        elif layer_type(layer) == \"Dropout\":\n            pass\n                \n        elif layer_type(layer) == \"Activation\" and i == len(model.layers)-1:\n            break\n               \n        else:\n            x = add_to_model(x, layer)\n        i+=1\n    \n    x = Softmax4D(axis=1,name=\"softmax\")(x)\n    return x\n    \n                \ndef add_reshaped_layer(layer, x, size, no_activation=False, add_zeros = None):\n\n    conf = layer.get_config()\n    \n    if no_activation:\n        activation=\"linear\"\n    else:\n        activation=conf[\"activation\"]\n        \n    #size = int(np.sqrt(layer.get_weights()[0].shape[0]/conf[\"output_dim\"]))\n    \n    new_layer = Convolution2D(conf[\"output_dim\"],size,size, activation=activation, name=conf['name'])\n         \n        \n    x= new_layer(x)\n    # We transfer the weights:\n    insert_weights(layer, new_layer)\n    return x\n    \n\ndef to_heatmap(model, input_shape = None, delete = False):\n    \n    # there are four configurations possible:\n    # global pooling\n    # local pooling - flatten\n    # local pooling - global pooling (same type)\n    # local pooling - global pooling (different type)\n    \n    model_type, index = detect_configuration(model)\n    \n    print(\"Model type detected: \" + model_type)\n    \n    #new_layer.set_weights(model.layers[0].get_weights())\n    img_input = Input(shape=(3,None,None))\n   \n    # Inchanged part:\n    middle_model = Model(input=model.layers[1].input, output=model.layers[index-1].output)\n    \n    x = middle_model(img_input)\n    \n    print(\"Model cut at layer: \" + str(index))\n        \n    if model_type == \"global pooling\":\n        x = copy_last_layers(model, index+1,x)\n              \n    elif model_type == \"local pooling - flatten\":\n        \n        layer = model.layers[index]\n        dic = layer.get_config()\n        add_zeros = dic[\"strides\"][0] - 1\n        dic[\"strides\"] = (1,1)\n        new_pool = from_config(layer, dic)\n        x = new_pool(x)\n        \n        size = get_dim(model, index, input_shape)[1]\n        print(\"Pool size infered: \" + str(size))\n        \n        conv_size = size + (size-1) * add_zeros\n        \n        print(\"New convolution size: \" + str(conv_size))\n        \n        if index+2 != len(model.layers)-1:\n            x = add_reshaped_layer(model.layers[index+2],x,conv_size, add_zeros=add_zeros)\n        else:\n            x = add_reshaped_layer(model.layers[index+2],x,conv_size, add_zeros=add_zeros,no_activation=True)\n            \n        x = copy_last_layers(model, index+3,x)\n        \n        \n    elif model_type == \"local pooling - global pooling (same type)\":\n        \n        \n        dim = get_dim(model, index, input_shape=input_shape)\n\n        new_pool_size = model.layers[index].get_config()[\"pool_size\"][0] * dim[1]\n        \n        print(\"Pool size infered: \" + str(new_pool_size))\n        \n        x = AveragePooling2D(pool_size=(new_pool_size, new_pool_size), strides=(1,1)) (x)\n        x = copy_last_layers(model, index+2,x)\n        \n        \n    elif model_type == \"local pooling - global pooling (different type)\":\n        x= copy_last_layers(model, index+1,x)\n    else:\n        raise IndexError(\"no type for model: \" + str(model_type))\n        \n    \n    \n    if delete:\n        del(model)\n        gc.collect()\n        print(\"Original model was deleted.\")\n    \n    return Model(img_input, x)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0ff053e7-73a8-e96e-3423-858b303c10e1"},"outputs":[],"source":"import urllib.request\nurllib.request.urlretrieve(\"https://raw.githubusercontent.com/gabrieldemarmiesse/heatmaps/master/heatmap.py\", \"heatmap.py\")\n\nfrom heatmap import to_heatmap\nfrom heatmap import synset_to_dfs_ids\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_v3 import InceptionV3\n\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.models import model_from_json"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c009230-ccc8-c2ef-1c9b-566624456560","collapsed":true},"outputs":[],"source":"def display_heatmap(new_model, img_path):\n\n    plt.figure()\n    img=mpimg.imread(img_path)\n    plt.subplot(121)\n    plt.imshow(img)\n    \n    img = image.load_img(img_path)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n\n    out = new_model.predict(x)\n\n    s = \"n02512053\" # Imagenet code for \"fish\"\n    ids = synset_to_dfs_ids(s)\n    heatmap_fish = out[0,ids].sum(axis=0)\n    plt.subplot(122)\n    plt.imshow(heatmap_fish, interpolation=\"none\")\n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0045aaf7-0369-65b5-ac74-348cadb0b86d"},"source":"## Let's try with a VGG16:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32dc7ef0-9d4b-59cd-f3ce-9b4132bf502c"},"outputs":[],"source":"model = VGG16()\nnew_model = to_heatmap(model)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c54c8359-b763-d8c9-8fd2-be22ad10893a"},"outputs":[],"source":"display_heatmap(new_model, \"./train/ALB/img_00110.jpg\")\ndisplay_heatmap(new_model, \"./train/ALB/img_00003.jpg\")\ndisplay_heatmap(new_model, \"./train/ALB/img_00085.jpg\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"0326ff41-ca2b-9e65-7f5c-4d33e9af04f0"},"source":"## Now with a ResNet50:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"102af9c8-5602-897b-92cf-be64c733905e"},"outputs":[],"source":"model = ResNet50()\nnew_model = to_heatmap(model)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1a3dd28-0175-41bd-6289-62237953df65"},"outputs":[],"source":"display_heatmap(new_model, \"./train/ALB/img_00110.jpg\")\ndisplay_heatmap(new_model, \"./train/ALB/img_00003.jpg\")\ndisplay_heatmap(new_model, \"./train/ALB/img_00085.jpg\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"5b6c3614-77e7-8d12-1072-88c185de6779"},"source":"## Now with a custom classifier:"},{"cell_type":"markdown","metadata":{"_cell_guid":"a888065e-b100-fd78-a3bf-575da2a5be54"},"source":"Class 0 is \"fish\" and class 1 is \"no fish\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36580105-b33a-0b4a-72ee-638b402913b2"},"outputs":[],"source":"# load json and create model\njson_file = open('model_2c_10e_R50_1.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nmodel = model_from_json(loaded_model_json)\n# load weights into new model\nmodel.load_weights(\"model_2c_10e_R50_1.h5\")\nprint(\"Loaded model from disk\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47833df7-5394-cac6-e656-0db4c2752e5c"},"outputs":[],"source":"new_model = to_heatmap(model, input_shape=(3,256,256))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f390ee98-bb03-ff15-0987-7d9e70ef0822","collapsed":true},"outputs":[],"source":"def display_heatmap(new_model, img_path):\n\n    plt.figure()\n    img=mpimg.imread(img_path)\n    plt.subplot(121)\n    plt.imshow(img)\n    \n    img = image.load_img(img_path)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n\n    out = new_model.predict(x)\n\n    heatmap_fish = out[0,[0]].sum(axis=0)\n    plt.subplot(122)\n    plt.imshow(heatmap_fish, interpolation=\"none\")\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d0b39ad-04af-ab99-64f4-acd82df058ed"},"outputs":[],"source":"display_heatmap(new_model, \"./train/ALB/img_00110.jpg\")\ndisplay_heatmap(new_model, \"./train/ALB/img_00003.jpg\")\ndisplay_heatmap(new_model, \"./train/ALB/img_00085.jpg\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"1bb683fb-21b5-dc69-c379-2122a06c947b"},"source":"## Now with the InceptionV3:"},{"cell_type":"markdown","metadata":{"_cell_guid":"57aec5ea-809b-7a29-8f8d-357ee38e058e"},"source":"It's buggy and I don't know why. If someone could figure it out, it'd be great."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab463322-817d-ae16-dd03-6d84d8309935"},"outputs":[],"source":"model = InceptionV3()\nnew_model = to_heatmap(model)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ca09e55-1034-6bbb-5f62-7f0ac5acc3de"},"outputs":[],"source":"display_heatmap(new_model, \"./train/ALB/img_00110.jpg\")\ndisplay_heatmap(new_model, \"./train/ALB/img_00003.jpg\")\ndisplay_heatmap(new_model, \"./train/ALB/img_00085.jpg\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"730fad14-a4b3-b326-6476-f61ae475acb2"},"source":"Don't hesitate to contribute!"},{"cell_type":"markdown","metadata":{"_cell_guid":"bbc0f970-2aa9-1423-2d28-f5522fb4baf0"},"source":"Here is some code to transform a Keras classifier into a heatmap generator. \nA lot of ideas were taken from this repository: https://github.com/heuritech/convnets-keras \nThis is just an optimised sliding window.\nIt works with classic models from Imagenet and also custom models.\nIt doesn't work well with Tensorflow right now (if someone could contribute to make it work on tensorflow, it'd be super cool).\nThere is also a bug with the InceptionV3. I'm still trying to figure it out.\n\nThe github repository for the files is here: https://github.com/gabrieldemarmiesse/heatmaps \n\nDon't hesitate to contribute!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"384d83d5-2110-dfe1-9b0c-5f62f3bd9c32"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c0babc0-475f-2806-86fa-475ebaf059de","collapsed":true},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"c6570050-f734-71dd-df16-a5d664f5b947"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f3e840c4-1ee3-ea06-35c8-0d4909aeb8a4"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec61c552-2bde-ae2b-e7ae-e0fd55de0963"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"83e0157d-6b77-aaf8-cb23-8a2a767b7b4c"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba46d4e8-d174-d896-96ff-c503313289f5"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0660971-50b5-9155-49cc-c470ab5998b4"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"0ee7e481-d13b-b968-ee73-ec120aaec565"},"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"b757cd80-284a-0589-553f-2d965c8d8d20"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68dec84d-648e-ae65-a6fc-de01b42da15f"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be2aaa44-3ef4-53ca-70b0-85fb6a85539e"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b639b849-a881-3931-aa15-f0378e7640f9","collapsed":true},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"548088cf-5bc7-87ae-046e-cc052e32c9ac"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"6d249160-047b-a508-bfef-db2ffb8d5a4e"},"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"b1faee7e-6f26-9c47-eabe-eb57d9086724"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"230132b6-ccc0-884c-6c78-3dcc20368fd1"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3104ddd3-54ce-46eb-add1-e480ff3eb8d5"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"dda58790-595c-976e-1845-ede3268bdb3d"},"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}