{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"0e96ae8a-8871-4511-4fc3-8f247ee0af58"},"source":"## Fish Species Classification With Keras Convolutional Neural NetworkÂ¶"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fe135a2-3814-2cc9-df48-ab0bf720a91a"},"outputs":[],"source":"import numpy as np\nimport random\nimport os\nimport glob\nimport cv2\nimport datetime\nimport pandas as pd\nimport time\nimport h5py\nimport csv\n\nfrom scipy.misc import imresize, imsave\n\nfrom sklearn.cross_validation import KFold, train_test_split\nfrom sklearn.metrics import log_loss, confusion_matrix\nfrom sklearn.utils import shuffle\n\nfrom PIL import Image, ImageChops, ImageOps\n\nimport matplotlib.pyplot as plt\n\nfrom keras import backend as K\nfrom keras.callbacks import EarlyStopping, Callback\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras import optimizers\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense\n\n%matplotlib inline"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b5da7cd-d0e7-0735-d6a1-70439acbe29c"},"source":"## Configuration and Hyperparameters"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa5096f3-b930-daab-99f6-33dae9f76b6a"},"outputs":[],"source":"### paths to training and testing data\ntrain_path = '../data_aug/train' # I'm using an augmented dataset locally so results will be different\ntest_path = '../data_aug/test'\n\n### path for preloaded vgg16 weights and bottleneck model (once trained)\nweights_path = '../vgg16_weights.h5'\nbottleneck_model_weights_path = '../bottleneck_model_300_aug.h5'  # these need to be in local directory\n\n### settings for keras early stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=1, mode='auto')\n\n### other hyperparameters\nn_folds = 5\nbatch_size = 8\nnb_epoch = 2\nbottleneck_epoch = 3  # used when training bottleneck model\nval_split = .15  # if not using kfold cv\nclasses = [\"ALB\", \"BET\", \"DOL\", \"LAG\", \"NoF\", \"OTHER\", \"SHARK\", \"YFT\"]\nnum_classes = len(classes)\n\n### image dimensions\nimg_width, img_height = 300, 300\nnum_channels = 3\n\n### class weights\n# target_num = 472.125\n# class_weight = {0: target_num/1719., 1: target_num/200., 2: target_num/117., 3: target_num/67.,\n#                 4: target_num/465., 5: target_num/299., 6: target_num/176., 7: target_num/734.}\nclass_weight = None"},{"cell_type":"markdown","metadata":{"_cell_guid":"25ee1563-6800-9558-07a4-ea7404bd2e31"},"source":"## Helper Functions For Loading Data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1cd89dd6-0ef4-eaaa-aca0-dc5fa0d80855"},"outputs":[],"source":"def load_images(path):\n    img = cv2.imread(path)\n    resized = cv2.resize(img, (img_width, img_height), cv2.INTER_LINEAR)\n    return resized"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75d260e7-2b9d-21c8-95ed-64fcfaef22b1"},"outputs":[],"source":"def load_train():\n    X_train = []\n    X_train_id = []\n    y_train = []\n    start_time = time.time()\n\n    print('Loading training images...')\n    folders = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n    for fld in folders:\n        index = folders.index(fld)\n        print('Loading {} files (Index: {})'.format(fld, index))\n        path = os.path.join(train_path, fld, '*g')\n        files = glob.glob(path)\n        for fl in files:\n            flbase = os.path.basename(fl)\n            img = load_images(fl)\n            X_train.append(img)\n            X_train_id.append(flbase)\n            y_train.append(index)\n\n    print('Training data load time: {} seconds'.format(round(time.time() - start_time, 2)))\n    return X_train, y_train, X_train_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c66fc235-b311-3762-432c-614e19062ab9"},"outputs":[],"source":"def load_test():\n    path = os.path.join(test_path, 'test_stg1', '*.jpg')\n    files = sorted(glob.glob(path))\n\n    X_test = []\n    X_test_id = []\n    for fl in files:\n        flbase = os.path.basename(fl)\n        img = load_images(fl)\n        X_test.append(img)\n        X_test_id.append(flbase)\n\n    return X_test, X_test_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f063380-fdbd-0ecf-d7f5-618dba32c55a"},"outputs":[],"source":"def normalize_train_data():\n    train_data, train_target, train_id = load_train()\n\n    train_data = np.array(train_data, dtype=np.uint8)\n    train_target = np.array(train_target, dtype=np.uint8)\n\n    train_data = train_data.transpose((0, 3, 1, 2))\n\n    train_data = train_data.astype('float32')\n    train_data = train_data / 255\n    train_target = np_utils.to_categorical(train_target, 8)\n\n    print('Shape of training data:', train_data.shape)\n    return train_data, train_target, train_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19208c2f-343a-c369-784b-95074c38293d"},"outputs":[],"source":"def normalize_test_data():\n    start_time = time.time()\n    test_data, test_id = load_test()\n\n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.transpose((0, 3, 1, 2))\n\n    test_data = test_data.astype('float32')\n    test_data = test_data / 255\n\n    print('Shape of testing data:', test_data.shape)\n    return test_data, test_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a16a53c6-f638-6d6a-f627-c22a940618e8"},"outputs":[],"source":"train_data, train_target, train_id = normalize_train_data()\ntrain_data, train_target, train_id = shuffle(train_data, train_target, train_id)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2eb7cb8c-e54e-7de3-de7c-78420d743610"},"source":"## Helper Function For Plotting Images"},{"cell_type":"markdown","metadata":{"_cell_guid":"bff5f407-9e4f-e3bc-709b-be42baed2234"},"source":"Function used to plot 9 images in a 3x3 grid (or fewer, depending on how many images are passed), and writing the true and predicted classes below each image."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c83f2af-0828-fe6f-49cb-f80a73d8a72e"},"outputs":[],"source":"def plot_images(images, cls_true, cls_pred=None):\n    \n    if len(images) == 0:\n        print(\"no images to show\")\n        return \n    else:\n        random_indices = random.sample(range(len(images)), min(len(images), 9))\n            \n    images, cls_true  = zip(*[(images[i], cls_true[i]) for i in random_indices])\n    \n    # Create figure with 3x3 sub-plots.\n    fig, axes = plt.subplots(3, 3)\n    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n\n    for i, ax in enumerate(axes.flat):\n        # Plot image.\n        image = images[i].transpose((1, 2, 0))\n        ax.imshow(image)\n\n        # Show true and predicted classes.\n        if cls_pred is None:\n            xlabel = \"True: {0}\".format(cls_true[i])\n        else:\n            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n\n        # Show the classes as the label on the x-axis.\n        ax.set_xlabel(xlabel)\n        \n        # Remove ticks from the plot.\n        ax.set_xticks([])\n        ax.set_yticks([])\n    \n    # Ensure the plot is shown correctly with multiple plots\n    # in a single Notebook cell.\n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ed067645-88d0-0305-185a-8b05452f4624"},"source":"## Build Model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51cf3ce9-aae6-4266-0ba9-b6dd205a3453"},"outputs":[],"source":"def build_model():\n    model = Sequential()\n    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n\n    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n    \n    # load the weights of the VGG16 networks\n    f = h5py.File(weights_path)\n    for k in range(f.attrs['nb_layers']):\n        if k >= len(model.layers):\n            # we don't look at the last (fully-connected) layers in the savefile\n            break\n        g = f['layer_{}'.format(k)]\n        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n        model.layers[k].set_weights(weights)\n    f.close()\n    \n    # build a classifier model to put on top of the convolutional model\n    bottleneck_model = Sequential()\n    bottleneck_model.add(Flatten(input_shape=model.output_shape[1:]))\n    bottleneck_model.add(Dense(256, activation='relu'))\n    bottleneck_model.add(Dropout(0.5))\n    bottleneck_model.add(Dense(8, activation='softmax'))\n    \n    # load weights from bottleneck model\n    bottleneck_model.load_weights(bottleneck_model_weights_path)\n\n    # add the model on top of the convolutional base\n    model.add(bottleneck_model)\n\n    # set the first 25 layers (up to the last conv block)\n    # to non-trainable (weights will not be updated)\n    for layer in model.layers[:25]:\n        layer.trainable = False\n        \n    # compile the model with a SGD/momentum optimizer\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9))\n    return model"},{"cell_type":"markdown","metadata":{"_cell_guid":"548a4e2d-48ec-a345-c886-c30edd97c9c6"},"source":"Before we start training, we use the bottleneck method to extract features from the images in our dataset. We save them as .npy files. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff969955-449f-b429-9394-c57bb136c2f4"},"outputs":[],"source":"def save_bottleneck_features():\n    datagen = ImageDataGenerator(rescale=1./255)\n\n    # build the VGG16 network\n    model = Sequential()\n    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n\n    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    # load the weights of the VGG16 networks\n    f = h5py.File(weights_path)\n    for k in range(f.attrs['nb_layers']):\n        if k >= len(model.layers):\n            # we don't look at the last (fully-connected) layers in the savefile\n            break\n        g = f['layer_{}'.format(k)]\n        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n        model.layers[k].set_weights(weights)\n    f.close()\n    print('Model loaded.')\n    \n    # create validation split\n    train_data, train_target, _ = normalize_train_data()\n    X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_target, test_size=val_split)\n\n    # create generator for train data\n    generator = datagen.flow(\n            X_train,\n            Y_train,\n            batch_size=batch_size,\n            shuffle=False)\n    \n    # save train features to .npy file\n    bottleneck_features_train = model.predict_generator(generator, X_train.shape[0])\n    np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n\n    # create generator for validation data\n    generator = datagen.flow(\n            X_valid,\n            Y_valid,\n            batch_size=batch_size,\n            shuffle=False)\n    \n    # save validation features to .npy file\n    bottleneck_features_validation = model.predict_generator(generator, X_valid.shape[0])\n    np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n    return Y_train, Y_valid"},{"cell_type":"markdown","metadata":{"_cell_guid":"3da78229-123b-244a-d4f9-4ae97ccb39c5"},"source":"Then we train a base model on these features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22cda7cc-9220-31e2-7ffd-c5ab34f122c0"},"outputs":[],"source":"def train_bottleneck_model():\n    train_labels, validation_labels = save_bottleneck_features()\n\n    train_data = np.load(open('bottleneck_features_train.npy', 'rb'))\n    validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n    \n    model = Sequential()\n    model.add(Flatten(input_shape=train_data.shape[1:]))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(8, activation='softmax'))\n\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n\n    model.fit(train_data,\n              train_labels,\n              nb_epoch=bottleneck_epoch,\n              batch_size=batch_size,\n              validation_data=(validation_data, validation_labels),\n              callbacks=[early_stopping],\n              class_weight=class_weight,\n              verbose=2)\n    \n    model.save_weights(bottleneck_model_weights_path)\n    return model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7c1f6eb-b6e2-2fc9-c174-0b1e7632c656"},"outputs":[],"source":"# train_bottleneck_model()  # leave this commented out once it's been done once -- takes a while to run"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cfcd7d0c-9e6f-9de5-673a-43bdf3718fab"},"outputs":[],"source":"## Main Training Function"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97c1e4a3-d028-a2a8-2eea-4ec82c0771fe"},"outputs":[],"source":"def run_train(n_folds=n_folds):\n    num_fold = 0\n    sum_score = 0\n    models = []   \n    callbacks = [\n        early_stopping\n    ]\n    \n    ### if we just want to train a single model without cross-validation, set n_folds to 0 or None\n    if not n_folds:\n        model = build_model()\n        \n        X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_target, test_size=val_split)\n        print('Training...')\n        print('Size of train split: ', len(X_train), len(Y_train))\n        print('Size of validation split: ', len(X_valid), len(Y_valid))\n              \n        model.fit(X_train,\n          Y_train,\n          batch_size=batch_size,\n          nb_epoch=nb_epoch,\n          shuffle=True,\n          verbose=1,\n          validation_data=(X_valid, Y_valid),\n          callbacks=callbacks,\n          class_weight=class_weight)\n\n        predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n        score = log_loss(Y_valid, predictions_valid)\n        print('Loss: ', score)\n        sum_score += score\n        models.append(model)\n                     \n    else:\n        kf = KFold(len(train_id), n_folds=n_folds, shuffle=True, random_state=7)\n\n        for train_index, test_index in kf:\n            model = build_model()\n            X_train = train_data[train_index]\n            Y_train = train_target[train_index]\n            X_valid = train_data[test_index]\n            Y_valid = train_target[test_index]\n\n            num_fold += 1\n            print('Training on fold {} of {}...'.format(num_fold, n_folds))\n            print('Size of train split: ', len(X_train), len(Y_train))\n            print('Size of validation split: ', len(X_valid), len(Y_valid))\n\n            model.fit(X_train,\n                      Y_train,\n                      batch_size=batch_size,\n                      nb_epoch=nb_epoch,\n                      shuffle=True,\n                      verbose=1,\n                      validation_data=(X_valid, Y_valid),\n                      callbacks=callbacks,\n                      class_weight=class_weight)\n\n            predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n            score = log_loss(Y_valid, predictions_valid)\n            print('Loss for fold {0}: '.format(num_fold), score)\n            sum_score += score*len(test_index)\n            models.append(model)\n        score = sum_score/len(train_data)\n        \n    print(\"Average loss across folds: \", score)\n    \n    info_string = \"loss-{0:.2f}_{1}fold_{2}x{3}_{4}epoch_patience_vgg16\".format(score, n_folds, img_width, img_height, nb_epoch)\n    return info_string, models"},{"cell_type":"markdown","metadata":{"_cell_guid":"7ef3e8c9-9004-323a-73ed-f5c8b3d19084"},"source":"## Helper Functions For Making Predictions"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"441e8a1d-6385-9ef3-a325-cb85a711d9cd"},"outputs":[],"source":"def create_submission(predictions, test_id, info):\n    result = pd.DataFrame(predictions, columns=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n    result.loc[:, 'image'] = pd.Series(test_id, index=result.index)\n    now = datetime.datetime.now()\n    sub_file = info + '.csv'\n    result.to_csv(sub_file, index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7e54456-e557-e141-9f0e-2862f78b0c0b"},"outputs":[],"source":"def merge_several_folds_mean(data, n_folds):\n    a = np.array(data[0])\n    for i in range(1, n_folds):\n        a += np.array(data[i])\n    a /= n_folds\n    return a.tolist()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e26068e-8526-3ccb-c936-63c2de28eb90"},"outputs":[],"source":"def ensemble_predict(info_string, models):\n    num_fold = 0\n    yfull_test = []\n    test_id = []\n    n_folds = len(models)\n\n    for i in range(n_folds):\n        model = models[i]\n        num_fold += 1\n        print('Predicting on fold {} of {}'.format(num_fold, n_folds))\n        test_data, test_id = normalize_test_data()\n        test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n        yfull_test.append(test_prediction)\n\n    preds = merge_several_folds_mean(yfull_test, n_folds)\n    create_submission(preds, test_id, info_string)"},{"cell_type":"markdown","metadata":{"_cell_guid":"69bf2a30-eef3-dc8c-7717-6ab96fb6f0f9"},"source":"Run the training and prediction code"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58200372-a161-f069-6dfc-52c1abc4e617"},"outputs":[],"source":"info_string, models = run_train()\nensemble_predict(info_string, models)"},{"cell_type":"markdown","metadata":{"_cell_guid":"18a5a7bd-f1d2-6469-8435-5140920f0987"},"source":"## Performance & Visualization"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"caac2768-704e-2ba3-68ca-6d4431d9e2b0"},"outputs":[],"source":"model = random.choice(models)  # choose a model for visualization\n\n### or choose one manually...\n\n# model = models[1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e48d070-b698-2f4e-01f7-ec2573dbbda9"},"outputs":[],"source":"perm = np.arange(int(val_split*len(train_target)))\nnp.random.shuffle(perm)\nsample_valid = train_data[perm]\nlabels_valid = train_target[perm]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5b47a3b-3d64-0316-c073-6323ab370698"},"outputs":[],"source":"def plot_example_errors(cls_pred, correct):\n    # This function is called from print_validation_accuracy() below.\n\n    # cls_pred is an array of the predicted class-number for\n    # all images in the validation set.\n\n    # correct is a boolean array whether the predicted class\n    # is equal to the true class for each image in the validation set.\n\n    # Negate the boolean array.\n    incorrect = (correct == False)\n    \n    # Get the images from the validation set that have been\n    # incorrectly classified.\n    images = sample_valid[incorrect]\n    \n    # Get the predicted classes for those images.\n    cls_pred = cls_pred[incorrect]\n\n    # Get the true classes for those images.\n    labels = np.array([classes[np.argmax(x)] for x in labels_valid])\n    cls_true = labels[incorrect]\n    \n    # Plot the first 9 images.\n    plot_images(images=images[0:9],\n                cls_true=cls_true[0:9],\n                cls_pred=cls_pred[0:9])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75b78fd4-8a86-bfde-e68f-ef3f4cda6ff7"},"outputs":[],"source":"def plot_confusion_matrix(cls_pred):\n    # This is called from print_validation_accuracy() below.\n\n    # cls_pred is an array of the predicted class-number for\n    # all images in the validation set.\n\n    # Get the true classifications for the test-set.\n    cls_true = [classes[np.argmax(x)] for x in labels_valid]\n    \n    # Get the confusion matrix using sklearn.\n    cm = confusion_matrix(y_true=cls_true,\n                          y_pred=cls_pred,\n                          labels=classes)\n\n    # Print the confusion matrix as text.\n    print(cm)\n\n    # Plot the confusion matrix as an image.\n    plt.matshow(cm)\n\n    # Make various adjustments to the plot.\n    plt.colorbar()\n    tick_marks = np.arange(num_classes)\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n\n    # Ensure the plot is shown correctly with multiple plots\n    # in a single Notebook cell.\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98d4023c-d7d2-4474-548b-ebb276d000e2"},"outputs":[],"source":"def print_validation_accuracy(show_example_errors=False,\n                              show_confusion_matrix=False):\n    \n    test_batch_size = 4\n    \n    # Number of images in the validation set.\n    num_test = len(labels_valid)\n    \n    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n    \n    i = 0\n    # iterate through batches and create list of predictions\n    while i < num_test:\n        # The ending index for the next batch is denoted j.\n        j = min(i + test_batch_size, num_test)\n\n        # Get the images from the test-set between index i and j.\n        images = sample_valid[i:j, :]\n\n        # Calculate the predicted class using TensorFlow.\n        cls_pred[i:j] = [np.argmax(x) for x in model.predict(images)]\n\n        # Set the start-index for the next batch to the\n        # end-index of the current batch.\n        i = j\n    \n    # Convenience variable for the true class-numbers of the validation set.\n    cls_pred = np.array([classes[x] for x in cls_pred])\n    cls_true = np.array([classes[np.argmax(x)] for x in labels_valid])\n\n    # Create a boolean array whether each image is correctly classified.\n    correct = (cls_true == cls_pred)\n\n    # Calculate the number of correctly classified images.\n    # When summing a boolean array, False means 0 and True means 1.\n    correct_sum = correct.sum()\n\n    # Classification accuracy is the number of correctly classified\n    # images divided by the total number of images in the test-set.\n    acc = float(correct_sum) / num_test\n\n    # Print the accuracy.\n    msg = \"Accuracy on validation set: {0:.1%} ({1} / {2})\"\n    print(msg.format(acc, correct_sum, num_test))\n\n    # Plot some examples of mis-classifications, if desired.\n    if show_example_errors:\n        print(\"Example errors:\")\n        plot_example_errors(cls_pred=cls_pred, correct=correct)\n\n    # Plot the confusion matrix, if desired.\n    if show_confusion_matrix:\n        print(\"Confusion Matrix:\")\n        plot_confusion_matrix(cls_pred=cls_pred)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4cd4904b-8948-af33-a268-90200a24c8f3"},"outputs":[],"source":"print_validation_accuracy(show_example_errors=False, show_confusion_matrix=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"415e0cbe-b9fe-fef5-2fd4-6f439e278fab"},"outputs":[],"source":"layer_name = 'conv5_3'\n\n\n# util function to convert a tensor into a valid image\ndef deprocess_image(x):\n    # normalize tensor: center on 0., ensure std is 0.1\n    x -= x.mean()\n    x /= (x.std() + 1e-5)\n    x *= 0.1\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n    if K.image_dim_ordering() == 'th':\n        x = x.transpose((1, 2, 0))\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\n\n# this is the placeholder for the input images\ninput_img = model.input\n\n# get the symbolic outputs of each \"key\" layer (we gave them unique names).\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n\n\ndef normalize(x):\n    # utility function to normalize a tensor by its L2 norm\n    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n\n\nkept_filters = []\nfor filter_index in range(0, 512):\n    if filter_index % 64 == 0:\n        print('Processing filter %d' % filter_index)\n    start_time = time.time()\n\n    # we build a loss function that maximizes the activation\n    # of the nth filter of the layer considered\n    layer_output = layer_dict[layer_name].output\n    if K.image_dim_ordering() == 'th':\n        loss = K.mean(layer_output[:, filter_index, :, :])\n    else:\n        loss = K.mean(layer_output[:, :, :, filter_index])\n\n    # we compute the gradient of the input picture wrt this loss\n    grads = K.gradients(loss, input_img)[0]\n\n    # normalization trick: we normalize the gradient\n    grads = normalize(grads)\n\n    # this function returns the loss and grads given the input picture\n    iterate = K.function([input_img], [loss, grads])\n\n    # step size for gradient ascent\n    step = 1.\n\n    # we start from a gray image with some random noise\n    if K.image_dim_ordering() == 'th':\n        input_img_data = np.random.random((1, 3, img_width, img_height))\n    else:\n        input_img_data = np.random.random((1, img_width, img_height, 3))\n    input_img_data = (input_img_data - 0.5) * 20 + 128\n\n    # we run gradient ascent for 20 steps\n    for i in range(20):\n        loss_value, grads_value = iterate([input_img_data])\n        input_img_data += grads_value * step\n\n        if loss_value <= 0.:\n            # some filters get stuck to 0, we can skip them\n            break\n\n    # decode the resulting input image\n    if loss_value > 0:\n        img = deprocess_image(input_img_data[0])\n        kept_filters.append((img, loss_value))\n    end_time = time.time()\n\n# we will stich the best n**2 filters on a n x n grid.\nn = 5\n\n# the filters that have the highest loss are assumed to be better-looking.\n# we will only keep the top n**2 filters.\nkept_filters.sort(key=lambda x: x[1], reverse=True)\nkept_filters = kept_filters[:n * n]\n\n# build a black picture with enough space for\n# our n x n filters of size with a 5px margin in between\nmargin = 5\nwidth = n * img_width + (n - 1) * margin\nheight = n * img_height + (n - 1) * margin\nstitched_filters = np.zeros((width, height, 3))\n\n# fill the picture with our saved filters\nfor i in range(n):\n    for j in range(n):\n        img, loss = kept_filters[i * n + j]\n        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n\n# save image and display\nimsave('feats.jpg', stitched_filters)\nplt.imshow(stitched_filters)"},{"cell_type":"markdown","metadata":{"_cell_guid":"1652c90a-5d3a-734d-3240-60158298bfab"},"source":"## Save Model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7ce3c0c-304f-e45d-7d7c-542460b4aeee"},"outputs":[],"source":"### if we like this model, save the weights\n\n#model.save_weights(\"favorite_model.h5\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"35c09403-80f4-e76c-8870-e05d886c16c3"},"source":"## MISC"},{"cell_type":"markdown","metadata":{"_cell_guid":"601edf8d-8aec-6f3c-d3d1-4b78bd41b311"},"source":"Script for adding augmented images to dataset using keras ImageDataGenerator"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e836ecd-305e-f6d9-8d9d-cddc768dd9d1"},"outputs":[],"source":"### augmentation script\n\n# train_path = '../data_aug/train/YFT/'\n\n# ## define data preparation\n# datagen = ImageDataGenerator(\n#                              width_shift_range=.1,\n#                              )\n\n# ## fit parameters from data\n# generator = datagen.flow_from_directory(\n#                            train_path,\n#                            target_size=(512, 512),\n#                            class_mode=None,\n#                            batch_size=335,\n#                            shuffle=True,\n#                            save_to_dir=train_path,\n#                            save_prefix=\"aug_\"\n#                            )\n\n\n# for X_batch, y_batch in generator:\n#     break"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}