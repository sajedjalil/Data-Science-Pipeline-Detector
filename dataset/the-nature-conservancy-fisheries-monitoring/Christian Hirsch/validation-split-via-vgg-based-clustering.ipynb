{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3a38337a-1505-a1f2-83c1-71a48f952297"},"source":"# Validation split via VGG-based clustering"},{"cell_type":"markdown","metadata":{"_cell_guid":"bc060d4c-31fa-54d7-0e84-9fc5bdd40076"},"source":"In the NCFM competition it is challenging to set up a good validation strategy, since the training set contains many highly similar images. We use a clustering based on the level-4 VGG features in order separate similar images from non-similar ones."},{"cell_type":"markdown","metadata":{"_cell_guid":"1b192b67-cf0d-7cda-1b3d-f53023623a1b"},"source":"First, we import standard libraries and fix constants."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2261bfc-f81c-5158-276b-1ed0e290d888"},"outputs":[],"source":"import h5py\nimport os\n\nfrom keras.applications import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.models import Model\n\nimport numpy as np\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n\n#path to training data\nDATA_PATH = '../input/train'\n\n#Number of clusters for K-Means\nN_CLUSTS = 5#250\n\n#Number of clusters used for validation\nN_VAL_CLUSTS = 1#50\n\nSEED = 42\nnp.random.seed(SEED)\n\n##############################################\n#######NORMALIZED IMAGE SIZE\n##############################################\nIMG_WIDTH = 640\nIMG_HEIGHT = 360\n\n##############################################\n#######SUBSAMPLE DATA\n##############################################\n\n#how many images to take?\nSAMP_SIZE = 8"},{"cell_type":"markdown","metadata":{"_cell_guid":"943b1e36-1a05-acb5-3c65-7da2c7dcc543"},"source":"## Subsample data "},{"cell_type":"markdown","metadata":{"_cell_guid":"f8d72bfd-0097-abe2-71ce-cf444df0613e"},"source":"In order for the notebook to run on Kaggle scripts, we subsample the training data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44003dfc-0f6d-7ae4-796f-5e2e5788cfc9"},"outputs":[],"source":"subsample = []\nfor fish in os.listdir(DATA_PATH):\n    if(os.path.isfile(os.path.join(DATA_PATH, fish))): \n        continue\n    subsample_class = [os.path.join(DATA_PATH, fish, fn) for \n                       fn in os.listdir(os.path.join(DATA_PATH, fish))]\n    subsample += subsample_class\nsubsample = subsample[:SAMP_SIZE]"},{"cell_type":"markdown","metadata":{"_cell_guid":"846b96d5-7822-889b-d3ef-834e21b2c1cb"},"source":"## Extract VGG features"},{"cell_type":"markdown","metadata":{"_cell_guid":"ce93fdd3-cfdb-5fb7-1fd5-078bb1dddd1a"},"source":"Next, we extract layer 4 VGG features from the images. The clustering will be based on these features. First, we load the VGG16 model pretrained on imagenet. Unfortunately, imagenet-weights are not available on Kaggle scripts."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"860e969c-bb80-2535-f768-176c979a9850"},"outputs":[],"source":"base_model = VGG16(weights = None, include_top = False, input_shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n#base_model = VGG16(weights = 'imagenet', include_top = False, input_shape = (IMG_HEIGHT, IMG_WIDTH, 3))\nmodel = Model(input = base_model.input, output = base_model.get_layer('block4_pool').output)"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd36866f-1046-6279-3461-c1957da13d4e"},"source":"After a preprocessing the images can be fed to the pretrained VGG16."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6ae3752-c97d-e832-e1b1-b0a9e9ed52be"},"outputs":[],"source":"def preprocess_image(path):\n    img = image.load_img(path, target_size = (IMG_HEIGHT, IMG_WIDTH))\n    arr = image.img_to_array(img)\n    arr = np.expand_dims(arr, axis = 0)\n    return preprocess_input(arr)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8adafb2-333c-4101-3fbc-bbd1cc250829"},"outputs":[],"source":"%%time\npreprocessed_images = np.vstack([preprocess_image(fn) for fn in subsample])\nvgg_features = model.predict(preprocessed_images)\nvgg_features = vgg_features.reshape(len(subsample), -1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd5efdec-e8bc-86af-72e6-dc7df86cdb29"},"source":"## Cluster by K-Means "},{"cell_type":"markdown","metadata":{"_cell_guid":"44a1d5d0-8bc4-f78a-2e15-2a4e603afeca"},"source":"We cluster the images according to the K-Means algorithm."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dbf8a829-c849-7fb3-a727-07ab03a2b918"},"outputs":[],"source":"%%time\nkm = KMeans(n_clusters = N_CLUSTS, n_jobs = -1)\nclust_preds = km.fit_predict(StandardScaler().fit_transform(vgg_features))"},{"cell_type":"markdown","metadata":{"_cell_guid":"28c8d061-e6d7-6536-378b-570b0bebc84a"},"source":"Then, we select at random the clusters that will form the validation set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b532b52d-2439-b1a8-d387-0915a0c0d9bc"},"outputs":[],"source":"val_clusters = np.random.choice(range(N_CLUSTS), N_VAL_CLUSTS, replace = False)\nval_sample = np.array(subsample)[np.in1d(clust_preds, val_clusters)]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8ef482c-0b4a-162a-fb07-bdae109ddc77"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}