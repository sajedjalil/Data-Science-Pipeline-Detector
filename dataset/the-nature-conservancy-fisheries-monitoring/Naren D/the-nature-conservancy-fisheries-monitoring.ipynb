{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ff00af51-d38a-40ea-2b0c-2c99af8a7b0a"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"600d93cf-129c-a4e2-edbf-7a18c94646ff"},"outputs":[],"source":"import numpy as np\nnp.random.seed(2016)\n\nimport os\nimport glob\nimport cv2\nimport datetime\nimport pandas as pd\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.cross_validation import KFold\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom sklearn.metrics import log_loss\nfrom keras import __version__ as keras_version\n\n\n\ndef get_im_cv2(path):\n    img = cv2.imread(path)\n    new = cv2.resize(img, (32, 32), cv2.INTER_LINEAR)\n    return new\n\n\ndef load_train():\n    X_train = []\n    X_train_id = []\n    y_train = []\n    start_time = time.time()\n\n    print('Read train images')\n    folders = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n    for fld in folders:\n        index = folders.index(fld)\n        print('Load folder {} (Index: {})'.format(fld, index))\n        path = os.path.join('..', 'input', 'train', fld, '*.jpg')\n        files = glob.glob(path)\n        for fl in files:\n            flbase = os.path.basename(fl)\n            img = get_im_cv2(fl)\n            X_train.append(img)\n            X_train_id.append(flbase)\n            y_train.append(index)   #what does this do?\n\n    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n    return X_train, y_train, X_train_id\n\n\ndef load_test():\n    path = os.path.join('..', 'input', 'test_stg1', '*.jpg')\n    files = sorted(glob.glob(path))\n\n    X_test = []\n    X_test_id = []\n    for fl in files:\n        flbase = os.path.basename(fl)\n        img = get_im_cv2(fl)\n        X_test.append(img)\n        X_test_id.append(flbase)\n\n    return X_test, X_test_id\n\n\ndef create_submission(predictions, test_id, info):\n    result1 = pd.DataFrame(predictions, columns=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n    result1.loc[:, 'image'] = pd.Series(test_id, index=result1.index)\n    now = datetime.datetime.now()\n    sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n    result1.to_csv(sub_file, index=False)\n\n\ndef read_and_normalize_train_data():\n    train_data, train_target, train_id = load_train()\n\n    print('Convert to numpy...')\n    train_data = np.array(train_data, dtype=np.uint8)\n    train_target = np.array(train_target, dtype=np.uint8)\n\n    print('Reshape...')\n    train_data = train_data.transpose((0, 3, 1, 2))\n\n    print('Convert to float...')\n    train_data = train_data.astype('float32')\n    train_data = train_data / 255\n    train_target = np_utils.to_categorical(train_target, 8)\n\n    print('Train shape:', train_data.shape)\n    print(train_data.shape[0], 'train samples')\n    return train_data, train_target, train_id\n\n\ndef read_and_normalize_test_data():\n    start_time = time.time()\n    test_data, test_id = load_test()\n\n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.transpose((0, 3, 1, 2))\n\n    test_data = test_data.astype('float32')\n    test_data = test_data / 255\n\n    print('Test shape:', test_data.shape)\n    print(test_data.shape[0], 'test samples')\n    print('Read and process test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n    return test_data, test_id\n\n\ndef dict_to_list(d):\n    ret = []\n    for i in d.items():\n        ret.append(i[1])\n    return ret\n\n\ndef merge_several_folds_mean(data, nfolds):\n    a = np.array(data[0])\n    for i in range(1, nfolds):\n        a += np.array(data[i])\n    a /= nfolds\n    return a.tolist()\n\n\ndef create_model():\n    model = Sequential()\n    model.add(ZeroPadding2D((1, 1), input_shape=(3, 32, 32), dim_ordering='th'))\n    model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th'))\n    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))\n    model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n\n    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))\n    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))\n    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))\n    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n    \n    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))   \n    model.add(Convolution2D(16, 3, 3, activation='relu', dim_ordering='th'))\n    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))   \n    model.add(Convolution2D(16, 3, 3, activation='relu', dim_ordering='th'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n    model.add(Dropout(0.2))\n    \n\n    model.add(Flatten())\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(2.5)) #changed this from 0.5\n    model.add(Dense(8, activation='softmax'))\n\n    sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n\n    return model\n\n\ndef get_validation_predictions(train_data, predictions_valid):\n    pv = []\n    for i in range(len(train_data)):\n        pv.append(predictions_valid[i])\n    return pv\n\n\ndef run_cross_validation_create_models(nfolds=10):\n    # input image dimensions\n    batch_size = 32\n    nb_epoch = 10\n    random_state = 51\n\n    train_data, train_target, train_id = read_and_normalize_train_data()\n\n    yfull_train = dict()\n    kf = KFold(len(train_id), n_folds=nfolds, shuffle=True, random_state=random_state)\n    num_fold = 0\n    sum_score = 0\n    models = []\n    for train_index, test_index in kf:\n        model = create_model()\n        X_train = train_data[train_index]\n        Y_train = train_target[train_index]\n        X_valid = train_data[test_index]\n        Y_valid = train_target[test_index]\n\n        num_fold += 1\n        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n        print('Split train: ', len(X_train), len(Y_train))\n        print('Split valid: ', len(X_valid), len(Y_valid))\n\n        callbacks = [\n            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n        ]\n        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n              shuffle=True, verbose=2, validation_data=(X_valid, Y_valid),\n              callbacks=callbacks)\n\n        predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n        score = log_loss(Y_valid, predictions_valid)\n        print('Score log_loss: ', score)\n        sum_score += score*len(test_index)\n\n        # Store valid predictions\n        for i in range(len(test_index)):\n            yfull_train[test_index[i]] = predictions_valid[i]\n\n        models.append(model)\n\n    score = sum_score/len(train_data)\n    print(\"Log_loss train independent avg: \", score)\n\n    info_string = 'loss_' + str(score) + '_folds_' + str(nfolds) + '_ep_' + str(nb_epoch)\n    return info_string, models\n\n\ndef run_cross_validation_process_test(info_string, models):\n    batch_size = 16\n    num_fold = 0\n    yfull_test = []\n    test_id = []\n    nfolds = len(models)\n\n    for i in range(nfolds):\n        model = models[i]\n        num_fold += 1\n        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n        test_data, test_id = read_and_normalize_test_data()\n        test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n        yfull_test.append(test_prediction)\n\n    test_res = merge_several_folds_mean(yfull_test, nfolds)\n    info_string = 'loss_' + info_string \\\n                + '_folds_' + str(nfolds)\n    create_submission(test_res, test_id, info_string)\n\n\nif __name__ == '__main__':\n    print('Keras version: {}'.format(keras_version))\n    num_folds = 3\n    info_string, models = run_cross_validation_create_models(num_folds)\n    run_cross_validation_process_test(info_string, models)\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0940fbfe-78b1-56f9-773b-8298fc75dd7c"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}