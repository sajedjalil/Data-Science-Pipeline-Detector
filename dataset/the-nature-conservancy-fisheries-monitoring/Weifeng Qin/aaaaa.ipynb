{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"7795e163-508e-4550-3401-34790a498551"},"source":"# Detecting night photos\n\nIn the dataset, there are both day and night photos. Theoretically, it should be a good idea to train separate CNNs for them, as the color distribution is somewhat different, and, because of this, joining both types of photos in one dataset could be inefficient when it comes to training a CNN. The following notebook explores the idea of detecting day and night photos and separating them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89d36c80-4800-181e-66f7-aa0d1e132268"},"outputs":[],"source":"import numpy as np\nimport glob\nimport random\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn import cluster\nfrom sklearn import neighbors\nfrom scipy.misc import imread, imsave"},{"cell_type":"markdown","metadata":{"_cell_guid":"84a30ee6-97a2-34c9-94cb-90d408c9b2ef"},"source":"It seems obvious that \"night\" photos are a little bit more greenish. Let's explore this a little more.\n\nLet's plot some images alongside with mean of their components (R/G/B) below."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0bf59be2-21fe-b3e9-fa97-a10191b10fd0"},"outputs":[],"source":"# load images\nimgs_to_load = 20\n\npreview_files = sorted(glob.glob('../input/train/*/*.jpg'), key=lambda x: random.random())[:imgs_to_load]\npreview = np.array([imread(img) for img in preview_files])\n\ndef show_loaded_with_means(imgs):\n    rows_total = int(len(preview) / 4)\n    for i in range(rows_total):\n        _, img_ax = plt.subplots(1, 4, sharex='col', sharey='row', figsize=(8, 2))\n        _, imgmean_ax = plt.subplots(1, 4, sharex='col', sharey='row', figsize=(8, 2))\n        for j in range(4):\n            img = preview[i*4+j]\n            img_mean = np.mean(img, axis=(0,1))\n            # calculate squared means to amplify green dominance effect\n            img_mean = np.power(img_mean, 2)\n            \n            # show plots\n            img_ax[j].axis('off')\n            img_ax[j].imshow(img)\n            imgmean_ax[j].bar(range(3), img_mean, width=0.3, color='blue')\n            imgmean_ax[j].set_xticks(np.arange(3) + 0.3 / 2)\n            imgmean_ax[j].set_xticklabels(['R', 'G', 'B'])\n\nshow_loaded_with_means(preview)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"c71499ac-ae70-1c51-a528-0eaaf88b87ff"},"source":"It can be seen that in night photos, green component shows clear dominance over R/B components, when it comes to its mean. This is something that should be easily picked up by k-means algorithm."},{"cell_type":"markdown","metadata":{"_cell_guid":"a7bd3ce1-a974-252e-a102-c132e8592be0"},"source":"Before applying it, let's first explore one more idea for representing each training image. If G component dominance is something that determines whether photo is day or night, we could, for mean of each component, store sum of differences between it and different component means. That way, dominance would mean higher number, and non-dominance would be punished."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"541b8257-7a1e-209c-bd26-ad6b9b0e9546"},"outputs":[],"source":"imgs_to_load = 20\n\npreview_files = sorted(glob.glob('../input/train/*/*.jpg'), key=lambda x: random.random())[:imgs_to_load]\npreview = np.array([imread(img) for img in preview_files])\n\ndef show_loaded_with_mean_differences(imgs):\n    rows_total = int(len(preview) / 4)\n    for i in range(rows_total):\n        _, img_ax = plt.subplots(1, 4, sharex='col', sharey='row', figsize=(8, 2))\n        _, imgmean_ax = plt.subplots(1, 4, sharex='col', sharey='row', figsize=(8, 2))\n        for j in range(4):\n            # calculate features of an image\n            img = preview[i*4+j]\n            img_mean = np.mean(img, axis=(0,1))\n            img_features = np.zeros(3)\n            img_features[0] = (img_mean[0] - img_mean[1]) + (img_mean[0] - img_mean[2])\n            img_features[1] = (img_mean[1] - img_mean[0]) + (img_mean[1] - img_mean[2])\n            img_features[2] = (img_mean[2] - img_mean[0]) + (img_mean[2] - img_mean[1])\n            \n            # display plots\n            img_ax[j].axis('off')\n            img_ax[j].imshow(img)\n            imgmean_ax[j].bar(range(3), img_features, width=0.3, color='blue')\n            imgmean_ax[j].set_xticks(np.arange(3) + 0.3 / 2)\n            imgmean_ax[j].set_xticklabels(['R', 'G', 'B'])\n\nshow_loaded_with_mean_differences(preview)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"5308f1cc-a829-31c9-d422-4d19914056af"},"source":"Looks promising - it seems high G component values are only achieved by night photos! This is the approach we'll use with k-means."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4744ff6a-e40a-ab98-e7de-a2e6dd4a4a21"},"outputs":[],"source":"# one cluster will be day photos, the other one night photos\nknn_cls = 2\n# increase this number while training locally for better results\ntraining_imgs = 50\n\ntraining_files = sorted(glob.glob('../input/train/*/*.jpg'), key=lambda x: random.random())[:training_imgs]\ntraining = np.array([imread(img) for img in training_files])\ntraining_means = np.array([np.mean(img, axis=(0, 1)) for img in training])\ntraining_features = np.zeros((training_imgs, 3))\nfor i in range(training_imgs):\n    training_features[i][0] = (training_means[i][0] - training_means[i][1])\n    training_features[i][0] += (training_means[i][0] - training_means[i][2])\n    training_features[i][1] = (training_means[i][1] - training_means[i][0])\n    training_features[i][1] += (training_means[i][1] - training_means[i][2])\n    training_features[i][2] = (training_means[i][2] - training_means[i][0])\n    training_features[i][2] += (training_means[i][2] - training_means[i][1])\n\nkmeans = cluster.KMeans(n_clusters=knn_cls).fit(training_features)\nprint(np.bincount(kmeans.labels_))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7ad24f6-e5a1-063f-07a1-b068bcefb746"},"outputs":[],"source":"def show_four(imgs, title):\n    _, ax = plt.subplots(1, 4, sharex='col', sharey='row', figsize=(8, 2))\n    plt.suptitle(title, size=8)\n    for i, img in enumerate(imgs[:4]):\n        ax[i].axis('off')\n        ax[i].imshow(img)\n\nfor i in range(knn_cls):\n    cluster_i = training[np.where(kmeans.labels_ == i)]\n    show_four(cluster_i[:4], 'cluster' + str(i))"},{"cell_type":"markdown","metadata":{"_cell_guid":"878ec8f2-5cd3-ece3-4f3e-b39c79ad3b88"},"source":"It seems like the clustering was successful. When training locally on more images, entire training data splits successfully between night and day photos, with ~1-2 photos being misclassified, which seems like a good result, as entire training dataset consists of ~3777 images.\n\nRunning the script below should generate 'clustered' directory inside training folder, which should contain split data."},{"cell_type":"markdown","metadata":{"_cell_guid":"9b2f83eb-ff54-a57c-24ae-7bb8c9bfc91c"},"source":"    batch = 100\n    \n    # now load all training examples and cluster them\n    CLUSTER_FOLDER = os.path.abspath('./data/train/clustered')\n    training_filenames = sorted(glob.glob('./data/train/*/*.jpg'))\n    \n    # make directories if they doesn't exist\n    if not os.path.isdir(CLUSTER_FOLDER):\n        os.makedirs(CLUSTER_FOLDER)\n    \n    for cluster_num in xrange(knn_cls):\n        single_cluster_folder = os.path.join(CLUSTER_FOLDER, str(cluster_num))\n        if not os.path.isdir(single_cluster_folder):\n            os.mkdir(single_cluster_folder)\n    \n    saved_files = 0\n    while saved_files < len(training_filenames):\n        training_files = training_filenames[saved_files:saved_files+batch]\n        training = np.array([imread(img) for img in training_files])\n        training_means = np.array([np.mean(img, axis=(0, 1)) for img in training])\n        training_features = np.zeros((training_imgs, 3))\n        for i in xrange(len(training)):\n            training_features[i][0] = (training_means[i][0] - training_means[i][1])\n            training_features[i][0] += (training_means[i][0] - training_means[i][2])\n            training_features[i][1] = (training_means[i][1] - training_means[i][0])\n            training_features[i][1] += (training_means[i][1] - training_means[i][2])\n            training_features[i][2] = (training_means[i][2] - training_means[i][0])\n            training_features[i][2] += (training_means[i][2] - training_means[i][1])\n            \n        img_cls = kmeans.predict(training_features)\n        \n        for i, img in enumerate(training):\n            cluster = img_cls[i]\n            save_path = path.join(CLUSTER_FOLDER, str(cluster))\n            class_name = path.basename(path.dirname(training_files[i]))\n            save_path = path.join(save_path, class_name)\n            if not path.isdir(save_path):\n                os.makedirs(save_path)\n            save_path = path.join(save_path, path.basename(training_files[i]))\n            print save_path\n            imsave(save_path, img)\n            saved_files += 1\n        \n        print str(saved_files) + \"/\" + str(len(training_filenames))"},{"cell_type":"markdown","metadata":{"_cell_guid":"5c27faef-61db-759b-5e33-238cf12ccc09"},"source":"One idea that makes sense, would be to develop and apply some kind of \"night\" filter to make all images look like they come from same distribution (which should be easier than a \"day\" filter, as intuitively night photos contain less color information than day photos, and it is probably easier to \"lose\" some information than to \"gain\" it), but I have no experience in image processing and apart from simple heuristics, I can't come up with approach that would look natural.\n\nThis is my first take on a serious kaggle competition, and first kernel ever, so any feedback is welcome ;)\n(I suspect some of my heuristics are a little more complicated than they should be,  and maybe some of them don't even make much sense...)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}