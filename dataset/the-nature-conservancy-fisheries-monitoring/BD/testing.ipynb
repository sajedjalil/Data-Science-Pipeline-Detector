{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4214f3ed-3856-e7e9-a514-7f45e1e83925"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d935d88-afa7-5596-84bb-1081da5eeabd"},"outputs":[],"source":"import os, cv2, random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\n%matplotlib inline \n\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nTRAIN_DIR = '../input/train/'\nTEST_DIR = '../input/test_stg1/'\nFISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\nROWS = 90  #720\nCOLS = 160 #1280\nCHANNELS = 3"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"853f1e57-ae8c-4eb0-d747-c8f13c84a9ff"},"outputs":[],"source":"def get_images(fish):\n    \"\"\"Load files from train folder\"\"\"\n    fish_dir = TRAIN_DIR+'{}'.format(fish)\n    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n    return images\n\ndef read_image(src):\n    \"\"\"Read and resize individual images\"\"\"\n    im = cv2.imread(src, cv2.IMREAD_COLOR)\n    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n    return im\n\n\nfiles = []\ny_all = []\n\nfor fish in FISH_CLASSES:\n    fish_files = get_images(fish)\n    files.extend(fish_files)\n    \n    y_fish = np.tile(fish, len(fish_files))\n    y_all.extend(y_fish)\n    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n    \ny_all = np.array(y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a19d949-e117-5ff8-8235-40da6cdfacae"},"outputs":[],"source":"X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\nfor i, im in enumerate(files): \n    X_all[i] = read_image(TRAIN_DIR+im)\n    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n\nprint(X_all.shape)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"712147e7-5598-20f3-756a-cf48ee2f6057"},"outputs":[],"source":"## Uncomment to check out a fish from each class\nuniq = np.unique(y_all, return_index=True)\nprint(uniq)\nfor f, i in zip(uniq[0], uniq[1]):\n    plt.imshow(X_all[i])\n    plt.title(f)\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd595371-ec86-9262-79dc-b37678f50a44"},"outputs":[],"source":"# One Hot Encoding Labels\ny_all = LabelEncoder().fit_transform(y_all)\ny_all = np_utils.to_categorical(y_all)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n                                                    test_size=0.2, random_state=23, \n                                                    stratify=y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4d408f9-5575-f0f5-0176-204fa58c8508"},"outputs":[],"source":"optimizer = RMSprop(lr=1e-4)\nobjective = 'categorical_crossentropy'\n\ndef center_normalize(x):\n    return (x - K.mean(x)) / K.std(x)\n\nmodel = Sequential()\n\nmodel.add(Activation(activation=center_normalize, input_shape=(ROWS, COLS, CHANNELS)))\n\nmodel.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(len(FISH_CLASSES)))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss=objective, optimizer=optimizer)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9944b61e-2393-b72f-c392-628bc8e4a290"},"outputs":[],"source":"early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n        \nmodel.fit(X_train, y_train, batch_size=64, nb_epoch=1,\n              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9393cff6-24b1-c4c9-a457-d5908f6c1557"},"outputs":[],"source":"preds = model.predict(X_valid, verbose=1)\nprint(\"Validation Log Loss: {}\".format(log_loss(y_valid, preds)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b37e92f9-61e9-cc81-a9d3-034458fd804c"},"outputs":[],"source":"test_files = [im for im in os.listdir(TEST_DIR)]\ntest = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n\nfor i, im in enumerate(test_files): \n    test[i] = read_image(TEST_DIR+im)\n    \ntest_preds = model.predict(test, verbose=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"24596950-c5d1-6712-060d-78042bae243e"},"outputs":[],"source":"\n\nsubmission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\nsubmission.insert(0, 'image', test_files)\nsubmission.head()\n\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}