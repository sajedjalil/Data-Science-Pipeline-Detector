{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# The Nature Conservancy Fisheries Monitoring","metadata":{"id":"yf6kyqT5T3sp"}},{"cell_type":"markdown","source":"https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring","metadata":{"id":"Ok60XB2xT3st"}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nprint(tf.__version__)","metadata":{"_kg_hide-output":true,"_uuid":"784aaee522ae53eff2274a388350b1b1dd60649b","id":"E_jFvL7tT3su","outputId":"faaf8275-1e16-47b5-fa3b-38303ffad201","execution":{"iopub.status.busy":"2022-05-14T16:00:14.482923Z","iopub.execute_input":"2022-05-14T16:00:14.48319Z","iopub.status.idle":"2022-05-14T16:00:14.487804Z","shell.execute_reply.started":"2022-05-14T16:00:14.48316Z","shell.execute_reply":"2022-05-14T16:00:14.48714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Подключение к Kaggle через Kaggle API реализуем с помощью API Token:\n# # https://www.kaggle.com/general/74235\n# # Easiest way to download kaggle data in Google Colab\n\n# ! pip install -q kaggle","metadata":{"id":"H5zABAFAvV4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # импортирую свой Kaggle API Token\n# from google.colab import files\n\n# # Choose the kaggle.json file  (Kaggle API Token)\n# files.upload()","metadata":{"id":"mp1OnKKUvbt0","outputId":"6cd06787-4e51-4ba1-b38e-916c2ea686c8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #  Make directory named kaggle and copy kaggle.json file there.\n# ! mkdir ~/.kaggle\n\n# ! cp kaggle.json ~/.kaggle/","metadata":{"id":"noIxT8qRvgF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Change the permissions of the file.\n# ! chmod 600 ~/.kaggle/kaggle.json","metadata":{"id":"r1ptnaxXveKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # That's all! You can check if everything's okay by running this command\n# # (список датасетов с Kaggle)\n# ! kaggle datasets list","metadata":{"id":"U-8h0oFovjGV","outputId":"1dacfd60-a60d-4a81-d074-217af3ae2deb","execution":{"iopub.status.busy":"2022-05-14T14:51:22.085638Z","iopub.execute_input":"2022-05-14T14:51:22.086109Z","iopub.status.idle":"2022-05-14T14:51:23.104706Z","shell.execute_reply.started":"2022-05-14T14:51:22.08607Z","shell.execute_reply":"2022-05-14T14:51:23.103785Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Download required dataset from Kaggle\n# !kaggle competitions download -c the-nature-conservancy-fisheries-monitoring","metadata":{"id":"Cvs8nszLvvmb","outputId":"f3f61a22-3927-4cba-c9a5-fe8478f3a7fd","execution":{"iopub.status.busy":"2022-05-14T14:54:38.495735Z","iopub.execute_input":"2022-05-14T14:54:38.496561Z","iopub.status.idle":"2022-05-14T14:54:39.493223Z","shell.execute_reply.started":"2022-05-14T14:54:38.496519Z","shell.execute_reply":"2022-05-14T14:54:39.492069Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !unzip the-nature-conservancy-fisheries-monitoring.zip","metadata":{"id":"Xxw62mNOvvdT","outputId":"7d6d3512-3a67-485b-e756-cd608c7e03cf","execution":{"iopub.status.busy":"2022-05-14T14:51:01.914307Z","iopub.execute_input":"2022-05-14T14:51:01.914584Z","iopub.status.idle":"2022-05-14T14:51:02.581592Z","shell.execute_reply.started":"2022-05-14T14:51:01.914548Z","shell.execute_reply":"2022-05-14T14:51:02.580761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip \"../input/the-nature-conservancy-fisheries-monitoring/test_stg1.zip\"","metadata":{"id":"NOm0cywxwpVt","execution":{"iopub.status.busy":"2022-05-14T14:58:30.901339Z","iopub.execute_input":"2022-05-14T14:58:30.902122Z","iopub.status.idle":"2022-05-14T14:58:34.9036Z","shell.execute_reply.started":"2022-05-14T14:58:30.90208Z","shell.execute_reply":"2022-05-14T14:58:34.90276Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip \"../input/the-nature-conservancy-fisheries-monitoring/train.zip\"","metadata":{"id":"9LUT_sVXwwDk","execution":{"iopub.status.busy":"2022-05-14T15:00:03.468986Z","iopub.execute_input":"2022-05-14T15:00:03.469415Z","iopub.status.idle":"2022-05-14T15:00:16.488644Z","shell.execute_reply.started":"2022-05-14T15:00:03.469375Z","shell.execute_reply":"2022-05-14T15:00:16.486761Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install py7zr","metadata":{"id":"2Bub7pIVbmNJ","execution":{"iopub.status.busy":"2022-05-14T15:00:24.837383Z","iopub.execute_input":"2022-05-14T15:00:24.838177Z","iopub.status.idle":"2022-05-14T15:00:56.8335Z","shell.execute_reply.started":"2022-05-14T15:00:24.838137Z","shell.execute_reply":"2022-05-14T15:00:56.832528Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!py7zr x \"../input/the-nature-conservancy-fisheries-monitoring/test_stg2.7z\"","metadata":{"id":"RuLs7Eh2bo73","execution":{"iopub.status.busy":"2022-05-14T15:01:23.411936Z","iopub.execute_input":"2022-05-14T15:01:23.41225Z","iopub.status.idle":"2022-05-14T15:03:13.094182Z","shell.execute_reply.started":"2022-05-14T15:01:23.412215Z","shell.execute_reply":"2022-05-14T15:03:13.093248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir(\"../working/train\"))","metadata":{"id":"YmoJLXvSwoiP","outputId":"681f5f19-f8bf-47a0-9c38-2acbb2ea524b","execution":{"iopub.status.busy":"2022-05-14T16:00:49.604248Z","iopub.execute_input":"2022-05-14T16:00:49.604967Z","iopub.status.idle":"2022-05-14T16:00:49.609439Z","shell.execute_reply.started":"2022-05-14T16:00:49.604927Z","shell.execute_reply":"2022-05-14T16:00:49.608722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir \"../working/boxes\"","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:06:46.265478Z","iopub.execute_input":"2022-05-14T15:06:46.266032Z","iopub.status.idle":"2022-05-14T15:06:46.931847Z","shell.execute_reply.started":"2022-05-14T15:06:46.265994Z","shell.execute_reply":"2022-05-14T15:06:46.93059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# скачиваем разметку для обучающей выборки\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5458/bet_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5459/shark_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5460/dol_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5461/yft_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5462/alb_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5463/lag_labels.json","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:36:54.029754Z","iopub.execute_input":"2022-05-14T15:36:54.030021Z","iopub.status.idle":"2022-05-14T15:36:59.428485Z","shell.execute_reply.started":"2022-05-14T15:36:54.029991Z","shell.execute_reply":"2022-05-14T15:36:59.42768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(\"../working\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:00:58.566659Z","iopub.execute_input":"2022-05-14T16:00:58.566921Z","iopub.status.idle":"2022-05-14T16:00:58.572288Z","shell.execute_reply.started":"2022-05-14T16:00:58.566892Z","shell.execute_reply":"2022-05-14T16:00:58.571456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! cp *.json \"../working/boxes\"","metadata":{"execution":{"iopub.status.busy":"2022-05-14T15:41:01.599961Z","iopub.execute_input":"2022-05-14T15:41:01.600233Z","iopub.status.idle":"2022-05-14T15:41:02.314054Z","shell.execute_reply.started":"2022-05-14T15:41:01.600202Z","shell.execute_reply":"2022-05-14T15:41:02.313086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(\"../working/boxes\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:01:14.603671Z","iopub.execute_input":"2022-05-14T16:01:14.603933Z","iopub.status.idle":"2022-05-14T16:01:14.608613Z","shell.execute_reply.started":"2022-05-14T16:01:14.603905Z","shell.execute_reply":"2022-05-14T16:01:14.607919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Загружаем разметку","metadata":{"_uuid":"263db29157d5633d6f9e7340ab5efec72c677b66","id":"6Nb85jcJT3sx"}},{"cell_type":"code","source":"import json\nfrom glob import glob\n\nTRAIN_PREFIX = '../working/train'\n\n# предварительно файлы с описанием разметки (*_labels.json) должны быть загружены в каталог /boxes\n\ndef load_annotations():\n    boxes = dict()\n    for path in glob('../working/boxes/*.json'):\n        label = os.path.basename(path).split('_', 1)[0]\n        print(label)\n        with open(path) as src:\n            for annotation in json.load(src):\n                basename = os.path.basename(annotation['filename'])\n                annotation['filename'] = os.path.join(\n                    TRAIN_PREFIX, label.upper(), basename)\n                for rect in annotation['annotations']:\n                    rect['x'] += rect['width'] / 2\n                    rect['y'] += rect['height'] / 2\n                    rect['class'] = label\n                if os.path.isfile(annotation['filename']):\n                    boxes.setdefault(label, []).append(annotation)\n    return boxes\n\ndef draw_boxes(annotation, rectangles=None, image_size=None):\n    \n    def _draw(img, rectangles, scale_x, scale_y, color=(0, 255, 0)):\n        for i, rect in enumerate(rectangles):\n            pt1 = (int((rect['x'] - rect['width'] / 2) * scale_x),\n                   int((rect['y'] - rect['height'] / 2) * scale_y))\n            pt2 = (int((rect['x'] + rect['width'] / 2) * scale_x),\n                   int((rect['y'] + rect['height'] / 2) * scale_y))\n            img = cv2.rectangle(img.copy(), pt1, pt2, \n                                color=color, thickness=12)\n            img = cv2.putText(img.copy(), annotation['annotations'][i]['class'], tuple(np.array(pt1)+[0,-7]), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 4 )\n        return img\n    \n    def __draw(img, rectangles, scale_x, scale_y, color=(0, 255, 0)):\n        for i, rect in enumerate(rectangles):\n            pt1 = (int((rect['x'] - rect['width'] / 2) * scale_x),\n                   int((rect['y'] - rect['height'] / 2) * scale_y))\n            pt2 = (int((rect['x'] + rect['width'] / 2) * scale_x),\n                   int((rect['y'] + rect['height'] / 2) * scale_y))\n            img = cv2.rectangle(img.copy(), pt1, pt2, \n                                color=color, thickness=2)\n            img = cv2.putText(img.copy(), counts['class'][int(rect['label'])] + ': ' + str(rect['label']), tuple(np.array(pt1)+[0,-7]), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 4 )\n        return img\n    \n    scale_x, scale_y = 1., 1.\n    \n    img = cv2.imread(annotation['filename'], cv2.IMREAD_COLOR)[...,::-1]\n    if image_size is not None:\n        scale_x = 1. * image_size[0] / img.shape[1]\n        scale_y = 1. * image_size[1] / img.shape[0]\n        img = cv2.resize(img, image_size)\n        \n    img = _draw(img, annotation.get('annotations', []), scale_x, scale_y)\n    \n    if rectangles is not None:\n        img = __draw(img, rectangles, 1., 1., (255, 0, 0))\n\n    return img","metadata":{"_uuid":"76496f443d36d16b961aeef10b365e3822b06a2b","id":"LrYn-987T3sy","execution":{"iopub.status.busy":"2022-05-14T16:02:53.314944Z","iopub.execute_input":"2022-05-14T16:02:53.315226Z","iopub.status.idle":"2022-05-14T16:02:53.33808Z","shell.execute_reply.started":"2022-05-14T16:02:53.315194Z","shell.execute_reply":"2022-05-14T16:02:53.33725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Визуализируем разметку","metadata":{"id":"3FXExzTpT3s0"}},{"cell_type":"code","source":"boxes = load_annotations()  # загружаем разметку детекций","metadata":{"id":"M7xc0edbT3s1","outputId":"7cabbac7-9301-4518-cca3-1f2751298fbe","execution":{"iopub.status.busy":"2022-05-14T16:02:59.989172Z","iopub.execute_input":"2022-05-14T16:02:59.989896Z","iopub.status.idle":"2022-05-14T16:03:00.228046Z","shell.execute_reply.started":"2022-05-14T16:02:59.989859Z","shell.execute_reply":"2022-05-14T16:03:00.227344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# зафиксируем перечень классов, чтобы при загрузке разметки (json) нумерация классов была всегда одинакова (не сбивалась)\ncounts = pd.DataFrame(\n    [(k, len(v)) for k, v in boxes.items()],\n    columns=['class', 'count']).sort_values(by='count', ascending=False).reset_index()\ncounts.drop(columns='index', inplace=True)\ncounts","metadata":{"id":"4L5eo1S7T3s2","outputId":"d5d9bc28-4b43-4fc7-b3a3-ca70828f6df2","execution":{"iopub.status.busy":"2022-05-14T16:03:03.968976Z","iopub.execute_input":"2022-05-14T16:03:03.96936Z","iopub.status.idle":"2022-05-14T16:03:04.004209Z","shell.execute_reply.started":"2022-05-14T16:03:03.969327Z","shell.execute_reply":"2022-05-14T16:03:04.003576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fish_classes = counts['class'].values\nfish_classes","metadata":{"id":"D3g39XlcLpef","outputId":"918bf2b7-8789-429c-a43a-554012208d39","execution":{"iopub.status.busy":"2022-05-14T16:03:09.479683Z","iopub.execute_input":"2022-05-14T16:03:09.479967Z","iopub.status.idle":"2022-05-14T16:03:09.489983Z","shell.execute_reply.started":"2022-05-14T16:03:09.479936Z","shell.execute_reply":"2022-05-14T16:03:09.488922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Легенда классификации рыб будет выглядеть так:\n# class 0: alb - Albacore tuna \n# class 1: yft - Yellowfin tuna\n# class 2: bet - Bigeye tuna\n# class 3: shark - Sharks\n# class 4: dol - Dolphinfish (Mahi Mahi)\n# class 5: lag - Opah, Moonfish (Lamprus Guttatus)\n\n# Остальные классы - без разметки:\n# nof - No Fishes (на фото нет никаких рыб)\n# oth - Other Fishes (на фото другие рыбы, не относящиеся ни к одному из вышеперечисленных классов)","metadata":{"id":"5rKDlcfOnopK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nannotation = boxes['alb'][0]\nprint(annotation)\nimg = draw_boxes(annotation)\n\nplt.figure(figsize=(6, 6), dpi=120)\nplt.imshow(img)\nplt.title('{} {}x{}'.format(\n    annotation['filename'], img.shape[0], img.shape[1]));","metadata":{"_uuid":"bb49d388931db2cbd5d8f08b9104299ca90a8c5a","id":"BVON2qhyT3s3","outputId":"dd8ff14c-8fd4-4d85-f559-dde6155239f5","execution":{"iopub.status.busy":"2022-05-14T16:03:18.20286Z","iopub.execute_input":"2022-05-14T16:03:18.203342Z","iopub.status.idle":"2022-05-14T16:03:18.654416Z","shell.execute_reply.started":"2022-05-14T16:03:18.203305Z","shell.execute_reply":"2022-05-14T16:03:18.653809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Распределение размеров разметки","metadata":{"_uuid":"0caa7502a0deb8e5e18773b6d2be8ed2f8d0dd4f","id":"q8AlRgURT3s4"}},{"cell_type":"code","source":"annotations = sum([box['annotations']\n                   for box in sum(boxes.values(), [])], [])\n\nwidths = [rect['width'] for rect in annotations]\nheights = [rect['height'] for rect in annotations]\n\nplt.hist(widths)\nplt.hist(heights);","metadata":{"_uuid":"8db3e3e9aa63c1216d3a1f13526d74ab3abe31a8","id":"M3CqeNOqT3s5","outputId":"07b121a5-1862-49fb-9817-f8c4151f1bf5","execution":{"iopub.status.busy":"2022-05-14T16:03:25.725355Z","iopub.execute_input":"2022-05-14T16:03:25.726109Z","iopub.status.idle":"2022-05-14T16:03:25.967Z","shell.execute_reply.started":"2022-05-14T16:03:25.72607Z","shell.execute_reply":"2022-05-14T16:03:25.966326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Экстрактор признаков","metadata":{"_uuid":"b01ffd790e6e7a81bfee104faa4bfa84ad7597c8","id":"BW_2tpMVT3s6"}},{"cell_type":"code","source":"from tensorflow.keras.applications import vgg16\n\nIMG_HEIGHT = 750\nIMG_WIDTH = 1200\n\nfeatures = vgg16.VGG16(weights='imagenet',\n                       include_top=False,\n                       input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\n# дообучаем последние 5 слоев\nfor layer in features.layers[:-5]:\n    layer.trainable = False\n    \nfeature_tensor = features.layers[-1].output\nprint(feature_tensor.shape)","metadata":{"_uuid":"f3e6d68bd5e0c8a97319185f25a3b25673482606","id":"t8Im9EOMT3s7","outputId":"f1e18f8a-fef9-42bc-a859-19b4784e27ba","execution":{"iopub.status.busy":"2022-05-14T16:03:30.903495Z","iopub.execute_input":"2022-05-14T16:03:30.903774Z","iopub.status.idle":"2022-05-14T16:03:35.157625Z","shell.execute_reply.started":"2022-05-14T16:03:30.903743Z","shell.execute_reply":"2022-05-14T16:03:35.155643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Сетка якорей (anchor grid)","metadata":{"_uuid":"ac4e46072546760703354bd43fa09c5d6bd69fb9","id":"g_soNqPNT3s7"}},{"cell_type":"code","source":"FEATURE_SHAPE = (feature_tensor.shape[1],\n                 feature_tensor.shape[2])\n\nGRID_STEP_H = IMG_HEIGHT / FEATURE_SHAPE[0]\nGRID_STEP_W = IMG_WIDTH / FEATURE_SHAPE[1]\n\nANCHOR_WIDTH = 150.\nANCHOR_HEIGHT = 150. \n\n# сетка якорей, размер определяется соотношением \n# размера входного изображения и размером тензора признаков\nANCHOR_CENTERS = np.mgrid[GRID_STEP_H/2:IMG_HEIGHT:GRID_STEP_H,\n                          GRID_STEP_W/2:IMG_WIDTH:GRID_STEP_W]","metadata":{"_uuid":"9d267722da49aad29f4bd4b625473295c3293e5f","id":"rJQMnj96T3s7","execution":{"iopub.status.busy":"2022-05-14T16:03:43.211197Z","iopub.execute_input":"2022-05-14T16:03:43.21178Z","iopub.status.idle":"2022-05-14T16:03:43.219132Z","shell.execute_reply.started":"2022-05-14T16:03:43.211741Z","shell.execute_reply":"2022-05-14T16:03:43.218496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = counts.shape[0]\nnum_classes","metadata":{"id":"z7-EIanJ1rHr","outputId":"7617eaf9-7d76-43e2-c258-03e43081dfa3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.special import softmax\n\ndef iou(rect, x_scale, y_scale, anchor_x, anchor_y,\n        anchor_w=ANCHOR_WIDTH, anchor_h=ANCHOR_HEIGHT):\n    \n    rect_x1 = (rect['x'] - rect['width'] / 2) * x_scale\n    rect_x2 = (rect['x'] + rect['width'] / 2) * x_scale\n    \n    rect_y1 = (rect['y'] - rect['height'] / 2) * y_scale\n    rect_y2 = (rect['y'] + rect['height'] / 2) * y_scale\n    \n    anch_x1, anch_x2 = anchor_x - anchor_w / 2, anchor_x + anchor_w / 2\n    anch_y1, anch_y2 = anchor_y - anchor_h / 2, anchor_y + anchor_h / 2\n    \n    dx = (min(rect_x2, anch_x2) - max(rect_x1, anch_x1))\n    dy = (min(rect_y2, anch_y2) - max(rect_y1, anch_y1))\n    \n    intersection = dx * dy if (dx > 0 and dy > 0) else 0.\n    \n    anch_square = (anch_x2 - anch_x1) * (anch_y2 - anch_y1)\n    rect_square = (rect_x2 - rect_x1) * (rect_y2 - rect_y1)\n    union = anch_square + rect_square - intersection\n    \n    return intersection / union\n\ndef encode_anchors(annotation, img_shape, iou_thr=0.5):\n    encoded = np.zeros(shape=(FEATURE_SHAPE[0],\n                              FEATURE_SHAPE[1], 11), dtype=np.float32)\n    x_scale = 1. * IMG_WIDTH / img_shape[1]\n    y_scale = 1. * IMG_HEIGHT / img_shape[0]\n    for rect in annotation['annotations']:\n        scores = []\n        label = fish_classes == rect['class']\n                \n        for row in range(FEATURE_SHAPE[0]):\n            for col in range(FEATURE_SHAPE[1]):\n                anchor_x = ANCHOR_CENTERS[1, row, col]\n                anchor_y = ANCHOR_CENTERS[0, row, col]\n                score = iou(rect, x_scale, y_scale, anchor_x, anchor_y)\n                scores.append((score, anchor_x, anchor_y, row, col))\n        \n        scores = sorted(scores, reverse=True)\n        if scores[0][0] < iou_thr:\n            scores = [scores[0]]  # default anchor\n        else:\n            scores = [e for e in scores if e[0] > iou_thr]\n            \n        for score, anchor_x, anchor_y, row, col in scores:\n            dx = (anchor_x - rect['x'] * x_scale) / ANCHOR_WIDTH\n            dy = (anchor_y - rect['y'] * y_scale) / ANCHOR_HEIGHT\n            dw = (ANCHOR_WIDTH - rect['width'] * x_scale) / ANCHOR_WIDTH\n            dh = (ANCHOR_HEIGHT - rect['height'] * y_scale) / ANCHOR_HEIGHT\n            encoded[row, col] = np.array([*label, 1., dx, dy, dw, dh])\n\n    return encoded\n\ndef _sigmoid(x):\n    return 1. / (1. + np.exp(-x))\n\ndef decode_prediction(prediction, conf_thr=0.1):\n    rectangles = []\n    for row in range(FEATURE_SHAPE[0]):\n        for col in range(FEATURE_SHAPE[1]):\n            \n            label = np.empty(6)\n            # заполняем предсказанные вероятности каждого из 6-и классов в поля 'label'\n            label[0], label[1], label[2], label[3], label[4], label[5], conf, dx, dy, dw, dh = prediction[row, col]\n            conf = _sigmoid(conf)\n            label = softmax(label)\n\n            if conf > conf_thr:\n                anchor_x = ANCHOR_CENTERS[1, row, col]\n                anchor_y = ANCHOR_CENTERS[0, row, col]\n                rectangles.append({'x': anchor_x - dx * ANCHOR_WIDTH,\n                                   'y': anchor_y - dy * ANCHOR_HEIGHT,\n                                   'width': ANCHOR_WIDTH - dw * ANCHOR_WIDTH,\n                                   'height': ANCHOR_HEIGHT - dh * ANCHOR_HEIGHT,\n                                   'conf': conf,\n                                   'label': np.argmax(_sigmoid(label)),\n                                   'labels': label })\n    return rectangles\n\ndef non_max_suppression(rectangles, max_output_size, iou_threshold=0.5):\n    if not rectangles:\n        return rectangles\n    \n    boxes = [[r['y'],\n              r['x'],\n              r['y'] + r['height'],\n              r['x'] + r['width']] for r in rectangles]\n    scores = [r['conf'] for r in rectangles]\n    indices = tf.image.non_max_suppression(np.array(boxes),\n                                           np.array(scores),\n                                           max_output_size,\n                                           iou_threshold)\n    \n    return [rectangles[i] for i in indices]","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"5qy5sZecT3s8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Валидация энкодинга/декодинга якорей","metadata":{"id":"oQeUJegkT3s9"}},{"cell_type":"code","source":"annotation = boxes['lag'][0]\n\nencoded = encode_anchors(annotation,\n                         img_shape=(IMG_HEIGHT, IMG_WIDTH),\n                         iou_thr=0.1)\n\ndecoded = decode_prediction(encoded, conf_thr=0.7)\ndecoded = sorted(decoded, key = lambda e: -e['conf'])\n\nplt.figure(figsize=(6, 6), dpi=120)\nplt.imshow(draw_boxes(annotation, decoded))\nplt.title('{} {}x{}'.format(\n    annotation['filename'], img.shape[0], img.shape[1]));","metadata":{"id":"ocvDdQJkT3s9","outputId":"8f65a3e6-2472-417a-85b4-f55cd42b5515"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Функция потерь","metadata":{"_uuid":"69b77cba0531fd1ed1c2634e929bee24ac068f7a","id":"bWYbIvNhT3s-"}},{"cell_type":"code","source":"K = tf.keras.backend\n\ndef confidence_loss(y_true, y_pred):\n    conf_loss = K.binary_crossentropy(y_true[..., 6], \n                                      y_pred[..., 6],\n                                      from_logits=True)\n    return conf_loss\n\ndef smooth_l1(y_true, y_pred):\n    abs_loss = K.abs(y_true[..., -4:] - y_pred[..., -4:])\n    square_loss = 0.5 * K.square(y_true[..., -4:] - y_pred[..., -4:])\n    mask = K.cast(K.greater(abs_loss, 1.), 'float32')\n    total_loss = (abs_loss - 0.5) * mask + 0.5 * square_loss * (1. - mask)\n    return K.sum(total_loss, axis=-1)\n\ndef classification_loss(y_tr, y_pr, alpha=0.25, gamma=2.0):\n  \n    y_true = y_tr[..., :6]\n    y_pred = y_pr[..., :6]\n\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n        labels=y_true, logits=y_pred)\n    \n    probs = tf.nn.softmax(y_pred)\n    alpha = tf.where(tf.equal(y_true, 1.0), alpha, (1.0 - alpha))\n    pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n    loss = alpha * tf.pow(1.0 - pt, gamma) * cross_entropy\n    \n    return tf.reduce_sum(loss, axis=-1)\n\ndef class_loss(y_tr, y_pr):\n    \n    y_true = y_tr[..., :6]\n    y_pred = y_pr[..., :6]\n    \n    cross_entropy = K.categorical_crossentropy(y_true[..., :6], \n                                               y_pred[..., :6],\n                                               from_logits=True)\n\n    return cross_entropy\n\ndef total_loss(y_true, y_pred, neg_pos_ratio=3):\n    batch_size = K.shape(y_true)[0]\n    \n    y_true = K.reshape(y_true, (batch_size, -1, 11))\n    y_pred = K.reshape(y_pred, (batch_size, -1, 11))\n    \n    # TODO: добавьте функцию потерь для классификации детекции\n    cls_loss = classification_loss(y_true, y_pred)\n  \n    # confidence loss\n    conf_loss = confidence_loss(y_true, y_pred)\n    \n    # smooth l1 loss\n    loc_loss = smooth_l1(y_true, y_pred)\n    \n    # positive examples loss\n    pos_conf_loss = K.sum(conf_loss * y_true[..., 6], axis=-1)\n    pos_class_loss = K.sum(cls_loss * y_true[..., 6], axis=-1)\n    pos_loc_loss = K.sum(loc_loss * y_true[..., 6], axis=-1)\n   \n    # negative examples loss\n    anchors = K.shape(y_true)[1]\n    num_pos = K.sum(y_true[..., 6], axis=-1)\n    num_pos_avg = K.mean(num_pos)\n    num_neg = K.min([neg_pos_ratio * (num_pos_avg) + 1., K.cast(anchors, 'float32')])\n    \n    # hard negative mining\n    neg_conf_loss, _ = tf.nn.top_k(conf_loss * (1. - y_true[..., 6]),\n                                   k=K.cast(num_neg, 'int32'))\n\n    neg_conf_loss = K.sum(neg_conf_loss, axis=-1)\n    \n    # total conf loss\n    total_conf_loss = (neg_conf_loss + pos_conf_loss) / (num_neg + num_pos + 1e-32)\n    cls_loss = pos_class_loss / (num_pos + 1e-32)\n    loc_loss = pos_loc_loss / (num_pos + 1e-32)\n    \n    return total_conf_loss + 0.5 * loc_loss + cls_loss","metadata":{"_uuid":"52a6271f7fabac76acec4013093bc35a7f1dc335","id":"ZLRxsKK0T3s-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка данных","metadata":{"id":"KkR9cjdnT3s_"}},{"cell_type":"code","source":"from random import shuffle\n\ndef load_img(path, target_size=(IMG_WIDTH, IMG_HEIGHT)):\n    img = cv2.imread(path, cv2.IMREAD_COLOR)[...,::-1]\n    img_shape = img.shape\n    img_resized = cv2.resize(img, target_size)\n    return img_shape, vgg16.preprocess_input(img_resized.astype(np.float32))\n\ndef data_generator(boxes, batch_size=32):\n    boxes = sum(boxes.values(), [])\n    while True:\n        shuffle(boxes)\n        for i in range(len(boxes)//batch_size):\n            X, y = [], []\n            for j in range(i*batch_size,(i+1)*batch_size):\n                img_shape, img = load_img(boxes[j]['filename'])\n                # TODO: добавьте one-hot encoding в разметку для классов\n                #print('boxes[j]', boxes[j])\n                y_ = encode_anchors(boxes[j], img_shape)\n                y.append(y_)\n                X.append(img)\n            yield np.array(X), np.array(y)","metadata":{"id":"lIQDv2dJT3s_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Добавляем выход детектора","metadata":{"id":"3I1A0zDyT3tA"}},{"cell_type":"code","source":"output = tf.keras.layers.BatchNormalization()(feature_tensor)\n\n# TODO: добавьте выходы для классификации детекции.\n# Добавлено 6 выходов для классификации детекции 6-и классов (alb, bet, dol, lag, shark, yft).\n# Вероятности классов 'Other Fishes' и 'No Fishes' возьмем из примера (sample_submission), они будут константами (не входят в выходы НС):\n#  Oth: 0.079142\n#  NoF: 0.123081\n\n# Итого получилось 11 выходов: \n# - 6 классов (вероятности каждого из классов, рассчитанные по функции sоftmax)\n# - 2 координаты x,y верхнего левого угла распознанного изображения\n# - 2 величины смещения (высота, ширина) от координат верхнего левого угла распознанного изображения\n# - 1 вероятность наличия распознанного изображения на картинке (по функции сигмоиды)\n\noutput = tf.keras.layers.Conv2D(11,\n                                kernel_size=(1, 1), \n                                activation='linear',\n                                kernel_regularizer='l2')(output)\n\nmodel = tf.keras.models.Model(inputs=features.inputs, outputs=output)\nmodel.summary()","metadata":{"_uuid":"a8904e155a9d956eecccd59a9b104bcfd20c44e1","id":"lE3YideiT3tA","outputId":"67d8c67f-44b1-43d7-c4dd-896e464b95fd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение","metadata":{"id":"sqq8qCaHT3tB"}},{"cell_type":"code","source":"adam = tf.keras.optimizers.Adam(learning_rate=3e-4, decay=1e-6)\nmodel.compile(optimizer=adam, \n              loss=total_loss,\n              metrics=[confidence_loss, classification_loss, smooth_l1])","metadata":{"id":"pKx-q1AxT3tB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 5\n\ngen = data_generator(boxes, batch_size=batch_size)\nsteps_per_epoch = sum(map(len, boxes.values()), 0) / batch_size\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    'fishdetector.hdf5',\n    monitor='loss',\n    verbose=1,  \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto',\n    save_freq=10)\n\nmodel.fit(gen, \n          steps_per_epoch=steps_per_epoch,\n          epochs=10,\n          callbacks=[checkpoint])","metadata":{"_uuid":"88d52a3e5e2f887dcf4cb295c62c3820c97f0db9","id":"I4i1UG7AT3tB","outputId":"8ec15582-0b1a-42c5-9a5a-7b721374da3a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Результат работы детектора","metadata":{"id":"G75e9Vw2T3tC"}},{"cell_type":"code","source":"# загружаем веса ранее обученной модели (чтобы не проводить повторное длительное обучение)\n# model.load_weights('../content/fishdetector_11outputs.hdf5')","metadata":{"id":"_BUbH9v0T3tC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotation = boxes['lag'][0]\n\n_, sample_img = load_img(annotation['filename'])\npred = model.predict(np.array([sample_img,]))\n\ndecoded = decode_prediction(pred[0], conf_thr=0.15)\n\ndecoded = non_max_suppression(decoded,\n                              max_output_size=2,\n                              iou_threshold=0.5)\n\nplt.figure(figsize=(6, 6), dpi=120)\nimg = draw_boxes(annotation, decoded, (IMG_WIDTH, IMG_HEIGHT))\nplt.imshow(img)\nplt.title('Предсказание модели {}x{}'.format(*img.shape));","metadata":{"id":"kVyaALDCP47B","outputId":"580566fe-469c-4347-af2e-3640ca59c16c","execution":{"iopub.status.busy":"2022-05-14T17:01:07.808056Z","iopub.execute_input":"2022-05-14T17:01:07.808342Z","iopub.status.idle":"2022-05-14T17:01:08.379943Z","shell.execute_reply.started":"2022-05-14T17:01:07.80831Z","shell.execute_reply":"2022-05-14T17:01:08.379304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Визуализируем предсказание на тесте","metadata":{"id":"ecmDJ0cOT3tD"}},{"cell_type":"code","source":"test_images = glob('../working/test_stg1/*.jpg')[10:30]\n\n\nplt.figure(figsize=(6, 4 * len(test_images)), dpi=120)\n\nfor i, filename in enumerate(test_images):\n    _, sample_img = load_img(filename)\n\n    pred = model.predict(np.array([sample_img,]))\n    decoded = decode_prediction(pred[0], conf_thr=0.01)\n    decoded = non_max_suppression(decoded,\n                                  max_output_size=1,\n                                  iou_threshold=0.5)\n    plt.subplot(len(test_images), 1, i + 1)\n    img = draw_boxes({'filename': filename}, decoded, (IMG_WIDTH, IMG_HEIGHT))\n    plt.imshow(img)\n    plt.title('Предсказание на тесте {}'.format(filename.split('/')[-1]));","metadata":{"id":"2yLhFte7T3tE","outputId":"08611858-6b29-4432-8a04-250e2f5781b6","execution":{"iopub.status.busy":"2022-05-14T16:58:36.770907Z","iopub.execute_input":"2022-05-14T16:58:36.77118Z","iopub.status.idle":"2022-05-14T16:58:36.783179Z","shell.execute_reply.started":"2022-05-14T16:58:36.771149Z","shell.execute_reply":"2022-05-14T16:58:36.782403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Агрегация результатов","metadata":{"id":"DnMw69QeT3tE"}},{"cell_type":"code","source":"# TODO: предскажите класс рыбы для фотографии из тестовой выборки\n#\n# Подготовьте файл с предсказаниями вероятностей для каждой фотографии:\n# image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\n# img_00001.jpg,1,0,0,0,0,...,0\n# img_00002.jpg,0.3,0.1,0.6,0,...,0\n\nfish_classes","metadata":{"id":"l1CQWZ0wT3tE","outputId":"05840077-7aa9-4972-a46e-311e4b966589"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# При подготовке файла будем использовать зафиксированный ранее перечень классов, \n# при этом class 0 = decoded[0] = 'alb - Albacore tuna' и т.д.\n\n# class 0: alb - Albacore tuna \n# class 1: yft - Yellowfin tuna\n# class 2: bet - Bigeye tuna\n# class 3: shark - Sharks\n# class 4: dol - Dolphinfish (Mahi Mahi)\n# class 5: lag - Opah, Moonfish (Lamprus Guttatus)","metadata":{"id":"P0woBDCo_75a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-14T17:12:10.801405Z","iopub.execute_input":"2022-05-14T17:12:10.80199Z","iopub.status.idle":"2022-05-14T17:12:10.806841Z","shell.execute_reply.started":"2022-05-14T17:12:10.801945Z","shell.execute_reply":"2022-05-14T17:12:10.805951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_predictions():\n    ptable = pd.DataFrame(columns=['image', 'ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK','YFT'])\n    \n    for i, file in enumerate(tqdm(glob('../working/test_stg1/*.jpg'))):\n        bn = os.path.basename(file)\n        # print(bn)\n        _, sample_img = load_img(file)\n        \n        pred = model.predict(np.array([sample_img,]))[0]\n        decoded = decode_prediction(pred, conf_thr=0.01)\n        decoded = non_max_suppression(decoded,\n                              max_output_size=1,\n                              iou_threshold=0.5)\n        \n        decoded = decoded[0]['labels']\n\n        ptable.loc[i, 'image'] = bn\n        ptable.loc[i, 'ALB'] = decoded[0]\n        ptable.loc[i, 'BET'] = decoded[2]\n        ptable.loc[i, 'DOL'] = decoded[4]\n        ptable.loc[i, 'LAG'] = decoded[5]\n        ptable.loc[i, 'SHARK'] = decoded[3]\n        ptable.loc[i, 'YFT'] = decoded[1]\n        ptable.loc[i, 'NoF'] = 0.123081 # фиксированная вероятность для класса 'No Fishes' из файла sample_submission\n        ptable.loc[i, 'OTHER'] = 0.079142 # фиксированная вероятность для класса 'Other Fishes' из файла sample_submission\n\n    i += 1    \n    \n    for j, file in enumerate(tqdm(glob('../working/test_stg2/*.jpg'))):\n        bn = os.path.basename(file)\n        \n        bn = \"test_stg2/\" + bn\n       \n        _, sample_img = load_img(file)\n        \n        pred = model.predict(np.array([sample_img,]))[0]\n\n        decoded = decode_prediction(pred, conf_thr=0.01)\n        decoded = non_max_suppression(decoded,\n                              max_output_size=1,\n                              iou_threshold=0.5)\n        \n        decoded = decoded[0]['labels']\n\n        ptable.loc[i + j, 'image'] = bn\n        ptable.loc[i + j, 'ALB'] = decoded[0]\n        ptable.loc[i + j, 'BET'] = decoded[2]\n        ptable.loc[i + j, 'DOL'] = decoded[4]\n        ptable.loc[i + j, 'LAG'] = decoded[5]\n        ptable.loc[i + j, 'SHARK'] = decoded[3]\n        ptable.loc[i + j, 'YFT'] = decoded[1]\n        \n        ptable.loc[i + j, 'NoF'] = 0.123081 # фиксированная вероятность для класса 'No Fishes' из файла sample_submission\n        ptable.loc[i + j, 'OTHER'] = 0.079142 # фиксированная вероятность для класса 'Other Fishes' из файла sample_submission\n\n    return ptable","metadata":{"id":"8Q2zJ-V6Hnng","execution":{"iopub.status.busy":"2022-05-14T17:16:29.462697Z","iopub.execute_input":"2022-05-14T17:16:29.46313Z","iopub.status.idle":"2022-05-14T17:16:29.479419Z","shell.execute_reply.started":"2022-05-14T17:16:29.463087Z","shell.execute_reply":"2022-05-14T17:16:29.478493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Готовим данные для отправки**","metadata":{"id":"7zQX9DImZPtC"}},{"cell_type":"code","source":"pred_table = make_predictions()\npred_table.to_csv(\"submit.csv\", index=False)\nprint(os.listdir(\"./\"))","metadata":{"id":"eXl6nOZEZWdQ","outputId":"76221199-b3de-4470-d29e-3d1f88266d91","execution":{"iopub.status.busy":"2022-05-14T17:16:49.704045Z","iopub.execute_input":"2022-05-14T17:16:49.704327Z","iopub.status.idle":"2022-05-14T17:56:16.52222Z","shell.execute_reply.started":"2022-05-14T17:16:49.704296Z","shell.execute_reply":"2022-05-14T17:56:16.521535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_table","metadata":{"id":"Nq59IJanI9qz","outputId":"7cc04178-8e2f-456f-dd4a-1c67895c19d7","execution":{"iopub.status.busy":"2022-05-14T17:58:58.724122Z","iopub.execute_input":"2022-05-14T17:58:58.72487Z","iopub.status.idle":"2022-05-14T17:58:58.740438Z","shell.execute_reply.started":"2022-05-14T17:58:58.724829Z","shell.execute_reply":"2022-05-14T17:58:58.739738Z"},"trusted":true},"execution_count":null,"outputs":[]}]}