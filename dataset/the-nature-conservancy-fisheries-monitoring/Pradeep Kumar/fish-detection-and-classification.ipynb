{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"344dd1d4-fd11-8f03-417b-0195ce44b12e"},"outputs":[],"source":"#!/usr/bin/env python\n\n\"\"\"image_classification.py: Classify images to horses, bikes\"\"\"\n\nimport os\nimport argparse\nimport glob\nimport cv2\nimport numpy as np\nfrom scipy.cluster import vq\n\nimport pandas as pd\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\n\n\n__author__ = \"Pradeep Kumar A.V.\"\n\n\nCLASSES = {\n    'ALB': 1,\n    'BET': 2,\n    'DOL': 3,\n    'LAG': 4,\n    'NoF': 5,\n    'OTHER': 6,\n    'SHARK': 7,\n    'YFT': 8\n}\n\nCLASSES_REV = {value: key for key, value in CLASSES.items()}\n\n\n# Helper functions\ndef _load_img(path):\n    \"\"\"\n    :param path: path of image to be loaded.\n    :return: cv2 image object\n    \"\"\"\n    img = cv2.imread(path)\n    # Convert the image from cv2 default BGR format to RGB (for convenience)\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n\ndef _pretty_print(msg):\n        print()\n        print('=' * len(msg))\n        print(msg)\n        print('=' * len(msg))\n\n\ndef _detect_and_describe(image, method='ORB'):\n    \"\"\"\n    :param image: Input RGB color image\n    :return: keypoints and features tuple\n    \"\"\"\n    # detect and extract features from the image\n    if method == 'SIFT':\n        descriptor = cv2.xfeatures2d.SIFT_create()\n    else:\n        descriptor = cv2.ORB_create()\n    (kps, features) = descriptor.detectAndCompute(image, None)\n\n    # convert the keypoints from KeyPoint objects to NumPy\n    # arrays\n    kps = np.float32([kp.pt for kp in kps])\n    features = np.float32(features)\n\n    # return a tuple of keypoints and features\n    return kps, features\n\n\ndef _kmeans_clustering(data, k=7):\n    \"\"\"\n    :param data: input data\n    :param k: K value\n    :return: k-Means clusters\n    \"\"\"\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n    flags = cv2.KMEANS_RANDOM_CENTERS\n    ret, label, centers = cv2.kmeans(data, k, None, criteria, 10, flags)\n    return centers\n\n\n#  Main wrapper methods\n\ndef extract_img_features(img_data_dir, type='train'):\n    \"\"\"\n    :param img_data_dir: directory path where the images reside.\n     The training images should reside in class named folders\n    :return:\n    \"\"\"\n    if type == 'train':\n        files = glob.glob(\"%s/*/*\" % img_data_dir)\n    else:\n        files = glob.glob(\"%s/*\" % img_data_dir)\n    dataset_size = len(files)\n    resp = np.zeros((dataset_size, 1))\n    ctr = 0\n    print(\"\\nProcessing images, and generating descriptors..\\n\")\n    des_list = []\n    for f in files:\n        print(\"Processing image %s\" % f)\n        img = _load_img(f)\n        kpts, des = _detect_and_describe(img)\n        des_list.append((f, des))\n        if type == 'train':\n            resp[ctr] = CLASSES[f.split('/')[-2]]\n            ctr += 1\n\n    descriptors = des_list[0][1]\n    for image_path, descriptor in des_list[1:]:\n        descriptors = np.vstack((descriptors, descriptor))\n\n    k = 13\n    print(\"\\nClustering the descriptors to form BOVW dictionary..\\n\")\n    centers = _kmeans_clustering(descriptors, k)\n    im_features = np.zeros((dataset_size, k), \"float32\")\n    for i in range(dataset_size):\n        words, distance = vq.vq(des_list[i][1], centers)\n        for w in words:\n            im_features[i][w] += 1\n\n    # Scaling the values of features\n    stdSlr = StandardScaler().fit(im_features)\n    im_features = stdSlr.transform(im_features)\n\n    resp = np.float32(resp)\n    return files, im_features, resp\n\n\ndef train_classifier(train_data, train_resp):\n    \"\"\"\n    :param train_data: training data array\n    :param train_resp: training data labels\n    :return: trained classifier object\n    \"\"\"\n    model = KNeighborsClassifier(weights='distance', n_jobs=-1)\n    model.fit(train_data, train_resp)\n    return model\n\n\ndef test_classifier(model, test_data):\n    \"\"\"\n    :param model: trained kNN classifier object\n    :param test_data: test data array\n    :return: predicted classes\n    \"\"\"\n    result = model.predict_proba(test_data)\n    return result\n\n\ndef main():\n    \"\"\"\n    Main wrapper to call the classifier\n    :return: None\n    \"\"\"\n    training_data_dir = '../input/train'\n    testing_data_dir = '../input/test_stg1'\n\n    # Extract features and train the classifier\n    _pretty_print(\"Extracting training image features\")\n    train_files, train_data, train_resp = \\\n        extract_img_features(training_data_dir)\n    _pretty_print(\"Training the classifier\")\n    model = train_classifier(train_data, train_resp)\n\n    if os.path.exists(testing_data_dir):\n        # Extract features and test the classifier\n        _pretty_print(\"Extracting testing image features\")\n        test_files, test_data, test_resp = \\\n            extract_img_features(testing_data_dir, type='test')\n        _pretty_print(\"Testing the classifier\")\n        predictions = test_classifier(model, test_data)\n        columns = [CLASSES_REV[int(entry)] for entry in model.classes_]\n        submission1 = pd.DataFrame(predictions, columns=columns)\n        images = [f.split('/')[-1] for f in test_files]\n        submission1.insert(0, 'image', images)\n        submission1.head()\n        submission1.to_csv(\"KNN_ORB_submission.csv\", index=False)\n\n\nif __name__ == '__main__':\n    main()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c90be43c-7fd9-ad89-a9f0-359241900855"},"outputs":[],"source":"from subprocess import check_output\nprint(check_output([\"ls\"]).decode(\"utf8\"))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}