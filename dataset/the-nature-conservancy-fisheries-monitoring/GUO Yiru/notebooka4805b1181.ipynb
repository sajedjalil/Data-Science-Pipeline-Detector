{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"674fbb7c-84e0-5717-4b37-3ce52df54870"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15ff5271-46ef-56ea-dc1a-fa5f73b6d159"},"outputs":[],"source":"import os\nimport glob\nimport cv2\nimport datetime\nimport pandas as pd\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.cross_validation import KFold\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\nfrom keras.optimizers import SGD, Adagrad\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom keras.constraints import maxnorm\nfrom sklearn.metrics import log_loss\nfrom keras import __version__ as keras_version\n\nnp.random.seed(1984)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd129814-2b02-000b-ab63-88efd2b2a2bb"},"outputs":[],"source":"def create_model():\n    model = Sequential()\n    \n    model.add(ZeroPadding2D((1, 1), input_shape=(3, 64, 64), dim_ordering='th'))\n    # 8 cnn kernel, each size is 3*3, activation func is relu (or tanh), \n    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th', init='he_uniform'))\n    model.add(Dropout(0.5)) #2\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))\n    model.add(Convolution2D(16, 3, 3, activation='relu', dim_ordering='th', init='he_uniform'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n    model.add(Dropout(0.5)) #2\n    \n    model.add(Flatten())\n    model.add(Dense(96, activation='relu',init='he_uniform'))\n    model.add(Dropout(0.5)) #4\n    model.add(Dense(24, activation='relu',init='he_uniform'))\n    model.add(Dropout(0.5)) #2\n    model.add(Dense(8, activation='softmax'))\n\n    sgd = SGD(lr=1e-2, decay=1e-4, momentum=0.89, nesterov=False)\n    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n\n    return model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb7c9088-e0a5-e49d-9f85-295140dcdbe9"},"outputs":[],"source":"def vgg_std16_model(img_rows, img_cols, color_type=1):\n    model = Sequential()\n    model.add(ZeroPadding2D((1, 1), input_shape=(color_type,\n                                                 img_rows, img_cols)))\n    model.add(Convolution2D(3,3,64, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,64, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,128, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,128, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,256, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,256, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,256, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,512, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,512, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,512, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,512, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,512, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(3,3,512, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1000, activation='softmax'))\n\n    model.load_weights('../input/vgg16_weights.h5')\n\n    # Code above loads pre-trained data and\n    model.layers.pop()\n    model.add(Dense(10, activation='softmax'))\n    # Learning rate is changed to 0.001\n    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n    return model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c48dbb9-2e3f-6585-fb53-87e74f852317"},"outputs":[],"source":"def get_im_cv2(path):\n    img = cv2.imread(path) #read picture's full path, return numpy.ndarray matrix\n    \n#    resized = cv2.resize(img, (64, 64), cv2.INTER_NN) # nearest neighbor\n#    resized = cv2.resize(img, (64, 64), cv2.INTER_AREA) # \n#    resized = cv2.resize(img, (64, 64), cv2.INTER_CUBIC) \n    \n    resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n    return resized"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"904b91a8-ecf7-4cf5-c702-6b0b10224d0c"},"outputs":[],"source":"def load_train():\n    X_train = []\n    X_train_id = []\n    y_train = []\n    start_time = time.time()\n\n    print('Read train images')\n    folders = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n    for fld in folders:\n        index = folders.index(fld)\n        print('Load folder {} (Index: {})'.format(fld, index))\n        #get all jpg files in current path\n        path = os.path.join('..', 'input', 'train', fld, '*.jpg')\n        files = glob.glob(path)\n        for fl in files:\n            flbase = os.path.basename(fl) #return file name\n            img = get_im_cv2(fl)\n            X_train.append(img)\n            X_train_id.append(flbase)\n            y_train.append(index)\n\n    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n    return X_train, y_train, X_train_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55fdc912-3d68-9631-d4fd-f297af15773f"},"outputs":[],"source":"def load_test():\n    path = os.path.join('..', 'input', 'test_stg1', '*.jpg')\n    files = sorted(glob.glob(path))\n\n    X_test = []\n    X_test_id = []\n    for fl in files:\n        flbase = os.path.basename(fl)\n        img = get_im_cv2(fl)\n        X_test.append(img)\n        X_test_id.append(flbase)\n\n    return X_test, X_test_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7a47287c-d234-1fd8-3833-10768066358b"},"outputs":[],"source":"def create_submission(predictions, test_id, info):\n    result1 = pd.DataFrame(predictions, columns=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n    result1.loc[:, 'image'] = pd.Series(test_id, index=result1.index)\n    now = datetime.datetime.now()\n    sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n    result1.to_csv(sub_file, index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"201016e2-299f-2f1e-9d04-588e759b0048"},"outputs":[],"source":"def read_and_normalize_train_data():\n    train_data, train_target, train_id = load_train()\n\n    print('Convert to numpy...')\n    train_data = np.array(train_data, dtype=np.uint8)\n    train_target = np.array(train_target, dtype=np.uint8)\n\n    print('Reshape...')\n    train_data = train_data.transpose((0, 3, 1, 2))\n\n    print('Convert to float...')\n    train_data = train_data.astype('float32')\n    train_data = train_data / 255\n    train_target = np_utils.to_categorical(train_target, 8)\n\n    print('Train shape:', train_data.shape)\n    print(train_data.shape[0], 'train samples')\n    return train_data, train_target, train_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cdd301cb-d1ce-b103-7f1a-c5b69750d7b6"},"outputs":[],"source":"def read_and_normalize_test_data():\n    start_time = time.time()\n    test_data, test_id = load_test()\n\n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.transpose((0, 3, 1, 2))\n\n    test_data = test_data.astype('float32')\n    test_data = test_data / 255\n\n    print('Test shape:', test_data.shape)\n    print(test_data.shape[0], 'test samples')\n    print('Read and process test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n    return test_data, test_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53a51840-bdd8-1968-d576-ae3766f1e0c2"},"outputs":[],"source":"def dict_to_list(d):\n    ret = []\n    for i in d.items():\n        ret.append(i[1])\n    return ret"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2d39fb0-d3a4-6756-1004-45d349d10fac"},"outputs":[],"source":"def merge_several_folds_mean(data, nfolds):\n    a = np.array(data[0])\n    for i in range(1, nfolds):\n        a += np.array(data[i])\n    a /= nfolds\n    return a.tolist()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3cb2c9ce-1a07-047a-0d66-c40faa911015"},"outputs":[],"source":"def get_validation_predictions(train_data, predictions_valid):\n    pv = []\n    for i in range(len(train_data)):\n        pv.append(predictions_valid[i])\n    return pv"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c1ec6a6-c557-3047-33be-0159a7b4006b"},"outputs":[],"source":"color_type_global = 3\n\n# color_type = 1 - gray\n# color_type = 3 - RGB"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"899c360c-e434-afa7-743f-4476be21e536"},"outputs":[],"source":"def run_cross_validation_create_models(nfolds=10):\n    # input image dimensions\n    batch_size = 64 #\n    nb_epoch = 8 #\n    random_state = 57 #51\n    first_rl = 96\n    \n    img_rows, img_cols = 224, 224\n    \n    train_data, train_target, train_id = read_and_normalize_train_data()\n\n    yfull_train = dict()\n    kf = KFold(len(train_id), n_folds=nfolds, shuffle=True, random_state=random_state)\n    num_fold = 0\n    sum_score = 0\n    models = []\n    for train_index, test_index in kf:\n        model = vgg_std16_model(img_rows, img_cols, color_type_global)       \n        X_train = train_data[train_index]\n        Y_train = train_target[train_index]\n        X_valid = train_data[test_index]\n        Y_valid = train_target[test_index]\n\n        num_fold += 1\n        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n        print('Split train: ', len(X_train), len(Y_train))\n        print('Split valid: ', len(X_valid), len(Y_valid))\n\n        callbacks = [\n            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n        ]\n        # model.fit is a training phase\n        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n                  shuffle=True, #shuffle=true mean reshape data\n                  verbose=2, #output information type 0,1,2\n                  validation_data=(X_valid, Y_valid), #used for validation\n              callbacks=callbacks)\n\n        predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n        score = log_loss(Y_valid, predictions_valid)\n        print('Score log_loss: ', score)\n        sum_score += score*len(test_index)\n\n        # Store valid predictions\n        for i in range(len(test_index)):\n            yfull_train[test_index[i]] = predictions_valid[i]\n\n        models.append(model)\n\n    score = sum_score/len(train_data)\n    print(\"Log_loss train independent avg: \", score)\n\n    info_string = '_' + str(np.round(score,3)) + '_flds_' + str(nfolds) + '_eps_' + str(nb_epoch) + '_fl_' + str(first_rl)\n    return info_string, models\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3b780b48-f4f0-0947-98cf-41d3a7078fe9"},"outputs":[],"source":"def run_cross_validation_process_test(info_string, models):\n    batch_size = 32\n    num_fold = 0\n    yfull_test = []\n    test_id = []\n    nfolds = len(models)\n\n    for i in range(nfolds):\n        model = models[i]\n        num_fold += 1\n        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n        test_data, test_id = read_and_normalize_test_data()\n        test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n        yfull_test.append(test_prediction)\n\n    test_res = merge_several_folds_mean(yfull_test, nfolds)\n    info_string = 'loss_' + info_string \\\n                + '_folds_' + str(nfolds)\n    create_submission(test_res, test_id, info_string)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c90ee22e-40a6-46eb-d8b4-a1e21cda802e"},"outputs":[],"source":"if __name__ == '__main__':\n    print('Keras version: {}'.format(keras_version))\n    num_folds = 3\n    info_string, models = run_cross_validation_create_models(num_folds)\n    run_cross_validation_process_test(info_string, models)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e986c1f9-142d-968f-5005-58f9be917aa9"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}