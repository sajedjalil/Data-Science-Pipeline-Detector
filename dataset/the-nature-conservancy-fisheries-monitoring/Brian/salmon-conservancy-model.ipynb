{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a0490e4-3294-f4d3-749a-0152f8e20a21"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/train\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"e1f0213d-aa69-fd7e-a882-988ff2199fcd"},"source":"The first step is to build tensor representations of all of the images with labels. This should be straightforward, but it's memory intensive which is causing problems."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c3d294a-8637-8475-0aef-53938e625e04"},"outputs":[],"source":"import matplotlib.image as mim\nimport resource\n\ndf = {\"image\":[],\"species\":[]}\n\n# Doing this directly exceeds memory limits. Not 100% sure how to (a) measure this, (b) work around it.\n# Could possibly build the dataframe one species at a time, then save them to CSV and merge them.\n# However it would be nice to be able to use all the data in training...\n\nfor folder in check_output([\"ls\", \"../input/train\"]).decode(\"utf8\").split('\\n'):\n    print(folder)\n    contents = check_output([\"ls\", \"../input/train/\"+folder]).decode(\"utf8\").split('\\n')[:10]\n    for image in contents:\n        if image[-4:]!='.jpg':\n#            print(resource.getrusage(resource.RUSAGE_SELF)[2]*resource.getpagesize()/1000000.0)\n            continue\n        df['image'].append(mim.imread(\"../input/train/\"+folder+'/'+image))\n        df['species'].append(folder)\n    del contents"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2342f026-212c-4dab-a9e3-e176f197927e"},"outputs":[],"source":"max0 = 0\nmax1 = 0\n\nfor x in df[\"image\"]:\n    sh = x.shape\n    if sh[0]>max0:\n        max0 = sh[0]\n    if sh[1]>max1:\n        max1 = sh[1]\n   \nprint(\"The biggest image dimensions seen were:\",max0,max1)\n\nfrom scipy.stats import describe\navs = []\nfor x in df[\"image\"]:\n    avs.append(np.mean(x))\nprint(\"The average brightness among all images was:\",np.mean(avs))"},{"cell_type":"markdown","metadata":{"_cell_guid":"8c77a065-e016-0519-b7f2-6e78b798bbd3"},"source":"The next step will be to clean up the images with a couple basic steps: adjusting brightness, and filling them out with gray to be a uniform size."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71730cf7-a655-b19e-5d56-b70b3bb59f05"},"outputs":[],"source":"def normalize(image,newshape=(974,1732,3)):\n    '''Takes in an image array of shape (x,y,3)\n    @returns an image array of shape (974,1732,3) with average unraveled value 0\n    by subtracting averages, and either extending with zeroes or cropping'''\n    shape = image.shape\n    if shape[0]>newshape[0]:\n        image = image[:newshape[0],:,:]\n    if shape[1]>newshape[1]:\n        image = image[:,:newshape[1],:]\n    image = image - np.mean(image,axis=None)\n    newimage = np.zeros(newshape)\n    newimage[:image.shape[0],:image.shape[1],:] = image\n    return newimage\n\ntest = df[\"image\"][0]\nprint(describe(np.reshape(test,(-1,3))))\nres = normalize(test)\nprint(describe(np.reshape(res,(-1,3))))\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be5bb0f6-7241-19d9-e7c9-60a92f65acb3"},"outputs":[],"source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nX = np.array([normalize(x) for x in df[\"image\"]])\ny = df[\"species\"]\ndel df\n\nfrom sklearn.preprocessing import LabelEncoder\n\nenc = LabelEncoder()\nenc.fit(y)\ny = enc.transform(y)\n\ntrain_dataset, valid_dataset, train_labels, valid_labels = train_test_split(X,y,stratify=y)\n\nimage_h = 974\nimage_w = 1732\nnum_labels = 8\nnum_channels = 1 # grayscale\n\nimport numpy as np\n\ndef reformat(dataset, labels):\n  dataset = dataset.reshape(\n    (-1, image_h, image_w, num_channels)).astype(np.float32)\n  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n  return dataset, labels\ntrain_dataset, train_labels = reformat(train_dataset, train_labels)\nvalid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n#test_dataset, test_labels = reformat(test_dataset, test_labels)\nprint('Training set', train_dataset.shape, train_labels.shape)\nprint('Validation set', valid_dataset.shape, valid_labels.shape)\n#print('Test set', test_dataset.shape, test_labels.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"533d15a1-62b5-962f-71fb-6a332e295169"},"outputs":[],"source":"train_dataset = np.array(X_train)\ntrain_labels = np.array(y_train)\nvalid_dataset = np.array(X_test)\nvalid_labels = np.array(y_test)\n\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"e8db9043-ff88-d757-d76c-2fced6df7be6"},"source":"There are two options for sort of \"feature engineering\" I would like to pursue, ideally in parallel.\n\nThe first is to separate the images into superpixels, and then be able to isolate only the fish-like parts. One way of doing this would be to feed each superpixel block into a trained AlexNET and see which is classified as fish. This is a bulky solution, but I don't have a naively better idea.\n\nThe second is to use a combination of manual and deep learning models to identify a few key features that the different fish might have. For example, length-to-width ratio, fin shape, scale colors, or facial structure. This should be easier to work out if we can identify the superpixels first."},{"cell_type":"markdown","metadata":{"_cell_guid":"7bc49e16-3676-137c-d1b7-1d72f200d9d0"},"source":"Finally we can build a model. I would like to build two models based on the two sets of engineered features above.\n\nTo process the images, I will build a convolutional neural net to train as a classifier on the dataset. There's plenty of data and convolutional models are great for image processing, so this should be an effective model on its own.\n\nAdditionally, I'll build a simpler (perhaps naive bayes?) model based on the extracted numerical features. This should both give us a way of being more or less confident of our future predictions, as well as giving a simple explanation for what sorts of features might make a picture difficult to classify. \n\nThese two models can then be combined in whatever way works out to be effective to get the final classification system."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3783e6a2-03fe-50fe-056c-c352ec79b126"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff73c0b0-facb-fd3b-78d9-131d88563ab3"},"outputs":[],"source":"image_h = 974\nimage_w = 1732\nnum_labels = 8\nnum_channels = 1 # grayscale\n\nimport numpy as np\n\ndef reformat(dataset, labels):\n  dataset = dataset.reshape(\n    (-1, image_h, image_w, num_channels)).astype(np.float32)\n  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n  return dataset, labels\ntrain_dataset, train_labels = reformat(train_dataset, train_labels)\nvalid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n#test_dataset, test_labels = reformat(test_dataset, test_labels)\nprint('Training set', train_dataset.shape, train_labels.shape)\nprint('Validation set', valid_dataset.shape, valid_labels.shape)\n#print('Test set', test_dataset.shape, test_labels.shape)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}