{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport cv2\nimport os\nimport glob\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import model_from_json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.optimizers import Adam\n# from keras import Activation\nfrom tensorflow.keras.models import Model, Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n\ncol = {'c0': 'safe driving',\n'c1': 'texting - right',\n'c2': 'talking on the phone - right',\n'c3': 'texting - left',\n'c4': 'talking on the phone - left',\n'c5':'operating the radio',\n'c6': 'drinking',\n'c7': 'reaching behind',\n'c8': 'hair and makeup',\n'c9': 'talking to passenger'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/state-farm-distracted-driver-detection/imgs\"\ntrain_path = os.path.join(DATA_PATH, \"train\")\ntest_path = os.path.join(DATA_PATH, \"test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(path):\n    img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2,\n                                   height_shift_range=0.3, zoom_range=0.3,\n                                   channel_shift_range=0.0,\n                                   fill_mode='nearest', cval=0.0, horizontal_flip=True, vertical_flip=False, rescale=1/255.,\n                                   data_format='channels_last', validation_split=0.3,\n                                   dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_datagen = ImageDataGenerator(rescale=1/255.,\n                                   data_format='channels_last', validation_split=0.3,\n                                   dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(train_path, target_size=(256,256), color_mode=\"grayscale\", \n                                                    class_mode=\"categorical\", batch_size=64, subset=\"training\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_generator = val_datagen.flow_from_directory(train_path, target_size=(256,256), color_mode=\"grayscale\", \n                                                    class_mode=\"categorical\", batch_size=64, subset=\"validation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_model(input_shape=(256,256,1)):\n    model = Sequential()\n    model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=input_shape, activation='elu'))\n#     model.add(Activation(activation='elu'))\n    model.add(MaxPooling2D())\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='elu'))\n#     model.add(Activation(activation=elu))\n    model.add(MaxPooling2D())\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='elu'))\n#     model.add(Activation(activation=elu))\n    model.add(MaxPooling2D())\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='elu'))\n#     model.add(Activation(activation=elu))\n    model.add(MaxPooling2D())\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='elu'))\n#     model.add(Activation(activation=elu))\n    model.add(MaxPooling2D())\n    model.add(BatchNormalization())\n\n#     model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='elu'))\n# #     model.add(Activation(activation=elu))\n#     model.add(MaxPooling2D())\n#     model.add(BatchNormalization())\n\n    # model.add(Conv2D(filters=32, kernel_size=(3, 3), activation=elu))\n    # model.add(Activation(activation=elu))\n    # model.add(MaxPooling2D())\n    # model.add(BatchNormalization())\n\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(3000, activation='elu'))\n#     model.add(Activation(activation=elu))\n    model.add(Dropout(rate=0.25))\n    model.add(Dense(2000, activation='elu'))\n#     model.add(Activation(activation='elu'))\n    model.add(Dropout(rate=0.25))\n    model.add(Dense(10, activation='softmax'))\n    \n    return (model)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = make_model()\nopt = Adam(lr=0.0001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 3\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = 'distracted_driver.h5'\n# reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5,\n#                              verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1,\n                             save_best_only=True, save_weights_only=False, mode='auto', period=1)\ncallback_l = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator,\n                              steps_per_epoch= train_generator.samples // batch_size,\n                              epochs=epochs,\n                              validation_data=val_generator,\n                              validation_steps=val_generator.samples // batch_size, callbacks=callback_l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.saved_model.save(model, \"distracted_driver\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loaded = tf.saved_model.load(\"distracted_driver\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tflite_model_file = 'distracted_driver.tflite'\nwith open(tflite_model_file, \"wb\") as f:\n    f.write(tflite_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clss = {'0': 'safe driving',\n'1': 'texting - right',\n'2': 'talking on the phone - right',\n'3': 'texting - left',\n'4': 'talking on the phone - left',\n'5':'operating the radio',\n'6': 'drinking',\n'7': 'reaching behind',\n'8': 'hair and makeup',\n'9': 'talking to passenger'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking working\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = input_details[0]['shape']\nprint(input_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (1,256,256,1)\n# input_data = np.ones(input_shape, dtype=np.float32)\ninput_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test/img_100001.jpg\"\ninput_data = cv2.imread(input_path,0)\ninput_data = cv2.resize(input_data, (256, 256))\n# input_data = cv2.cv2Color(input_data, cv2.COLORBGR2RGB)\ninput_data = (input_data / 255).astype(np.float32)\ninput_data = tf.expand_dims(input_data, -1)\ninput_data = tf.expand_dims(input_data, 0)\nprint(input_data.shape)\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\ntflite_results = interpreter.get_tensor(output_details[0]['index'])\ncpred = np.argmax(tflite_results, axis=1)\nprint(cpred)\nprint(clss[str(cpred[0])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tflite_results = interpreter.get_tensor(output_details[0]['index'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tflite_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cpred = np.argmax(tflite_results, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cpred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clss[str(cpred[0])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! tar -zcvf distracted_driver.tar.gz \"distracted_driver/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}