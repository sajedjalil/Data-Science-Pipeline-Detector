{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd \nfrom skimage import io\nfrom skimage import color\nfrom PIL import Image\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom dask.array.image import imread\nfrom dask import bag, threaded\nfrom dask.diagnostics import ProgressBar\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport math\n\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.layers import Flatten,Dropout\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image \nfrom keras.layers.normalization import BatchNormalization\nfrom keras import optimizers\nfrom keras.callbacks import LearningRateScheduler\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"driver_details = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv',na_values='na')\nprint(driver_details.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image = []\nimage_label = []\n\n\nfor i in range(10):\n    print('now we are in the folder C',i)\n    imgs = os.listdir(\"../input/state-farm-distracted-driver-detection/imgs/train/c\"+str(i))\n    for j in range(1300):\n    #for j in range(100):\n        img_name = \"../input/state-farm-distracted-driver-detection/imgs/train/c\"+str(i)+\"/\"+imgs[j]\n        img = cv2.imread(img_name)\n        #img = color.rgb2gray(img)\n        img = img[50:,120:-50]\n        img = cv2.resize(img,(224,224))\n        label = i\n        driver = driver_details[driver_details['img'] == imgs[j]]['subject'].values[0]\n        train_image.append([img,label,driver])\n        image_label.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.shuffle(train_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"driv_selected = ['p050', 'p015', 'p022', 'p056']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train= []\ny_train = []\nX_test = []\ny_test = []\nD_train = []\nD_test = []\ntrue_test = []\n\nfor features,labels,drivers in train_image:\n    if drivers in driv_selected:\n        X_test.append(features)\n        y_test.append(labels)\n        D_test.append(drivers)\n        true_test.append(labels)\n    \n    else:\n        X_train.append(features)\n        y_train.append(labels)\n        D_train.append(drivers)\n    \nprint (len(X_train),len(X_test))\nprint (len(y_train),len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train).reshape(-1,224,224,3)\nX_test = np.array(X_test).reshape(-1,224,224,3)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n\nprint (X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Defining the input\n\nfrom keras.layers import Input\nresnet50_input = Input(shape = (224, 224, 3), name = 'Image_input')\n\n## The RESNET model\n\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.applications.resnet50 import ResNet50\n\n\n#Get the RESNET weights and layers\n\nmodel_resnet50_conv = ResNet50(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\nmodel_resnet50_conv.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use the generated model \nfrom keras.models import Model\n\n\noutput_resnet50_conv = model_resnet50_conv(resnet50_input)\n\n#Add the fully-connected layers \n\nx = Flatten(name='flatten')(output_resnet50_conv)\n# x = Dense(4096, activation='relu', name='fc1')(x)\n# x = Dense(4096, activation='relu', name='fc2')(x)\nx = Dense(10, activation='softmax', name='predictions')(x)\n\n\nresnet50_pretrained = Model(input = resnet50_input, output = x)\n# for layer in resnet50_pretrained.layers[:2]:\n#     layer.trainable=False\n# for layer in resnet50_pretrained.layers[2:]:\n#     layer.trainable=True\n\n\nresnet50_pretrained.summary()\n\n# Compile CNN model\nadam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0)\n\n\n\ndef step_decay(epoch):\n    initial_lrate = 0.001\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(drop,  \n        math.floor((1+epoch)/epochs_drop))\n    return lrate\nlrate = LearningRateScheduler(step_decay)\n\nsgd = optimizers.SGD(lr = 0.001)\n\n\nresnet50_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\n\ncheckpointer = ModelCheckpoint('resnet_weights_aug_alltrained_sgd2_setval.hdf5', verbose=1, save_best_only=True)\nearlystopper = EarlyStopping(monitor='accuracy', patience=7, verbose=1)\n\n\ndatagen = ImageDataGenerator(\n    height_shift_range=0.5,\n    width_shift_range = 0.5,\n    zoom_range = 0.5,\n    rotation_range=30\n        )\n#datagen.fit(X_train)\ndata_generator = datagen.flow(X_train, y_train, batch_size = 64)\n\n# Fits the model on batches with real-time data augmentation:\nresnet50_model = resnet50_pretrained.fit_generator(data_generator,steps_per_epoch = len(X_train) / 64, callbacks=[checkpointer, earlystopper,lrate],\n                                                            epochs = 40, verbose = 1, validation_data = (X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (10, 5))\naxes[0].plot(range(1, len(resnet50_pretrained.history.history['accuracy']) + 1), resnet50_pretrained.history.history['accuracy'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Accuracy')\naxes[0].plot(range(1, len(resnet50_pretrained.history.history['val_accuracy']) + 1), resnet50_pretrained.history.history['val_accuracy'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Accuracy')\naxes[0].set_xlabel('Epochs', fontsize = 14)\naxes[0].set_ylabel('Accuracy',fontsize = 14)\naxes[0].set_title('CNN Dropout Accuracy Trainig VS Testing', fontsize = 14)\naxes[0].legend(loc = 'best')\naxes[1].plot(range(1, len(resnet50_pretrained.history.history['loss']) + 1), resnet50_pretrained.history.history['loss'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Loss')\naxes[1].plot(range(1, len(resnet50_pretrained.history.history['val_loss']) + 1), resnet50_pretrained.history.history['val_loss'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Loss')\naxes[1].set_xlabel('Epochs', fontsize = 14)\naxes[1].set_ylabel('Loss',fontsize = 14)\naxes[1].set_title('CNN Dropout Loss Trainig VS Testing', fontsize = 14)\naxes[1].legend(loc = 'best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels is the image array\ntest_image = []\ni = 0\nfig, ax = plt.subplots(1, 20, figsize = (50,50 ))\n\nfiles = os.listdir('../input/state-farm-distracted-driver-detection/imgs/test/')\nnums = np.random.randint(low=1, high=len(files), size=20)\nfor i in range(20):\n    print ('Image number:',i)\n    img = cv2.imread('../input/state-farm-distracted-driver-detection/imgs/test/'+files[nums[i]])\n    #img = color.rgb2gray(img)\n    img = img[50:,120:-50]\n    img = cv2.resize(img,(224,224))\n    test_image.append(img)\n    ax[i].imshow(img,cmap = 'gray')\n    plt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\n\nfor img in test_image:\n    test.append(img)\n    \nresnet50_pretrained.load_weights('resnet_weights_aug_alltrained_sgd2_setval.hdf5')\n\n\ntest = np.array(test).reshape(-1,224,224,3)\nprediction = resnet50_pretrained.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags = { \"C0\": \"safe driving\",\n\"C1\": \"texting - right\",\n\"C2\": \"talking on the phone - right\",\n\"C3\": \"texting - left\",\n\"C4\": \"talking on the phone - left\",\n\"C5\": \"operating the radio\",\n\"C6\": \"drinking\",\n\"C7\": \"reaching behind\",\n\"C8\": \"hair and makeup\",\n\"C9\": \"talking to passenger\" }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels is the image array\ni = 0\nfig, ax = plt.subplots(20, 1, figsize = (100,100))\n\nfor i in range(20):\n    ax[i].imshow(test[i].squeeze())\n    predicted_class = 'C'+str(np.where(prediction[i] == np.amax(prediction[i]))[0][0])\n    ax[i].set_title(tags[predicted_class])\n    plt.show","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}