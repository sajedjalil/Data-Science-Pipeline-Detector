{"cells":[{"metadata":{"_uuid":"40733c39647bac5056ba0dada8409d6184fefb68"},"cell_type":"markdown","source":"## Using Resnet 50 for Driver Distraction Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom keras import layers\nfrom keras import models\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nfrom os import listdir, makedirs\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import VGG16, ResNet50, VGG19, InceptionV3\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras import optimizers, regularizers\nfrom keras.optimizers import SGD\nfrom glob import glob\nimport cv2\nimport warnings \nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dense, Dropout, Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\nfrom keras.losses import categorical_crossentropy\nfrom keras.models import Model\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nimport tensorflow as tf\nimport time\nimport os\n#from tqdm import tqdm # for progress indication\n\nprint(os.listdir(\"../input\"))\ndata_dir = '../input/'\ndata_dir1= '../input/state-farm-distracted-driver-detection/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"right_root_dir = '../input/right-cure-final/imgs_right_cure_final_noise'\n\n#left_root_dir= '../input/state-farm-distracted-driver-detection/'\nleft_root_dir= '../input/left-cure-final/imgs_left_cure_final_noise'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#right_root_dir = '../input/right_created/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_list =  ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6','c7', 'c8', 'c9']\nleft_class_desc = ['safe driving', 'texting-right', 'talking on the phone-right', 'texting-left', 'talking on the phone-left', \n              'operating the radio', 'drinking', 'reaching behind', 'hair and makeup', 'talking to passenger']\nright_class_desc = ['safe driving', 'texting-left', 'talking on the phone-left', 'texting-right', 'talking on the phone-right', \n              'operating the radio', 'drinking', 'reaching behind', 'hair and makeup', 'talking to passenger']\ndf_desc = pd.DataFrame({'class': class_list, 'left_desc': left_class_desc,  'right_desc': right_class_desc})\ndf_desc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_train_dir = os.path.join(left_root_dir, 'train')\nleft_test_dir = os.path.join(left_root_dir, 'test')\n\nright_train_dir = os.path.join(right_root_dir, 'train')\nright_test_dir = os.path.join(right_root_dir, 'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(left_train_dir)\nclass_dirs = os.listdir(left_train_dir)\nfor classname in class_dirs:\n    if classname != '.DS_Store':\n        print('{}: {} images'.format(classname, len(os.listdir(os.path.join(right_train_dir, classname)))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = []\nfor class_id, classname in enumerate(class_list):\n    for file in os.listdir(os.path.join(left_train_dir, classname)):\n        train.append(['train/{}/{}'.format(classname, file), class_id, classname])\n        \ntrain = pd.DataFrame(train, columns=['file', 'class_id', 'classname'])\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(np.unique(train[\"class_id\"]))\nprint(\"num of classes: \", num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"driver_list= []\nprint(classname)\nfor class_id, classname in enumerate(class_list):\n    for file in os.listdir(os.path.join(left_train_dir, classname)):\n        s=str(file)\n        arr=s.split(\"_\")\n        driver_list.append(arr[0])\nprint(len(driver_list))\nprint(driver_list[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(driver_list) \ndf.head()\ndf[0].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfig, axs = plt.subplots(1,1,figsize=(14,5))\nsns.countplot(df[0], ax = axs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection  import train_test_split\ntarget = train[\"class_id\"]\n\n# split dataset into training and validation data with 70:30 split\ntest_size = 0.30 # taking 70:30 training and test set\nseed = 7  # Random numbmer seeding for reapeatability of the code\nX_train, X_val, y_train, y_val = train_test_split(train, target, test_size=test_size, random_state=seed)\n\n# pls note X_train & X_test contain the records of image file.. later we will read these images\n# and converted into image data(i.e pixel) for further processing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training shape: {}\".format(X_train.shape))\nprint(\"Validation shape: {}\".format(X_val.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom keras.preprocessing import image\ndef read_img_cv2_gray(filepath, size):\n    img = cv2.imread(os.path.join(left_root_dir, filepath)) #, cv2.IMREAD_GRAYSCALE\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #IMREAD_GRAYSCALE\n    resizeImg = cv2.resize(gray, size, interpolation = cv2.INTER_AREA) # resize image  \n    img_data = image.img_to_array(resizeImg)\n    img_data = np.expand_dims(img_data.copy(), axis=0)\n    return img_data\n\ndef read_img_cv2(filepath, size):\n    img = cv2.imread(os.path.join(left_root_dir, filepath)) #, cv2.IMREAD_GRAYSCALE\n    resizeImg = cv2.resize(img, size, interpolation = cv2.INTER_AREA) # resize image  \n    img_data = image.img_to_array(resizeImg)\n    img_data = np.expand_dims(img_data.copy(), axis=0)\n    return img_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_SIZE = 128  # to experiment with higher pixel size\n\n# reading image file for traing dataset\nX_train_features = np.zeros((len(X_train), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, file in enumerate(X_train['file']):\n    img_data = read_img_cv2(file, (INPUT_SIZE, INPUT_SIZE))\n    X_train_features[i] = img_data\nprint('Training Images shape: {} size: {:,}'.format(X_train_features.shape, X_train_features.size))\n\n# reading image file for validation dataset\nX_val_features = np.zeros((len(X_val), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, file in enumerate(X_val['file']):\n    img_data = read_img_cv2(file, (INPUT_SIZE, INPUT_SIZE))\n    X_val_features[i] = img_data\nprint('Validation Images shape: {} size: {:,}'.format(X_val_features.shape, X_val_features.size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_features = X_train_features.astype('float32')/255\nX_val_features = X_val_features.astype('float32')/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_train_cat = keras.utils.to_categorical(y_train, num_classes=num_classes)\ny_val_cat = keras.utils.to_categorical(y_val, num_classes=num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training data shape:\")\nprint(\"Features: \",X_train_features.shape)\nprint(\"Target: \",y_train_cat.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nValidation data shape:\")\nprint(\"Features: \",X_val_features.shape)\nprint(\"Target: \",y_val_cat.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# utility fxn to plot model history and accuracy for each epoch\ndef plot_model_history(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n    \n# utiliy fxn to get y_predict in 1D\n# y_predict is array of 12 classes for each cases.. let form the new data which give label value in 1D.. \n# this is required for classification matrix.. cm expect 1D array\ndef get1D_y_predict(y_pred):\n    result = []\n    for i in range(len(y_pred)):\n        result.append(np.where(y_pred[i] == np.max(y_pred[i]))[0][0])\n    return result    \n\ndef plot_cnf_matrix(cnf_matrix, name):\n    fig, ax = plt.subplots(1, figsize=(12,5))\n    ax = sns.heatmap(cnf_matrix, ax=ax, cmap=plt.cm.Greens, annot=True)\n    ax.set_xticklabels(class_list)\n    ax.set_yticklabels(class_list)\n    plt.title('Confusion Matrix')\n    plt.ylabel('True class')\n    plt.xlabel('Predicted class')\n    fig.savefig('{}_cnf.png'.format(name), dpi=300)\n    plt.show();\n    \n# use tensorboard callback which will passed in model.fit function.\n# utility fxn ffor Initializing Early stopping and Model chekpoint callbacks**\ndef EarlyStopingModelCheckPoint():\n    #tensorboard = TensorBoard(log_dir=\".logs/{}\".format(time.time()))\n\n    #Adding Early stopping callback to the fit function is going to stop the training,\n    #if the val_loss is not going to change even '0.001' for more than 5 continous epochs\n\n    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5)\n\n    #Adding Model Checkpoint callback to the fit function is going to save the weights whenever val_loss achieves \n    # a new low value. Hence saving the best weights occurred during training\n\n    model_checkpoint =  ModelCheckpoint('bestmodel.h5',\n                                                               monitor='val_loss',\n                                                               verbose=1,\n                                                               save_best_only=True,\n                                                               save_weights_only=False,\n                                                               mode='auto',\n                                                               period=1)\n    return early_stopping, model_checkpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_resnet():\n    resnet = ResNet50(include_top=False, input_shape=(224, 224, 3))\n    \n    model = Sequential()\n    model.add(resnet)\n    model.add(Flatten())\n    model.add(Dense(1024, activation = \"relu\"))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(Dense(10, activation='softmax'))   \n    model.summary()\n    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])\n    return resnet, model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_my_resnet(resnet):    \n    model = Sequential()\n    model.add(resnet)\n    model.add(Flatten())\n    model.add(Dense(1024, activation = \"relu\"))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(Dense(10, activation='softmax'))   \n    model.summary()\n    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])\n    return  model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet = ResNet50(include_top=False, input_shape=(128, 128, 3))\nresnet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Freeze the layers except the last 4 layers\n#for layer in resnet.layers[:-4]:\n    #layer.trainable = False\n \n# Check the trainable status of the individual layers\n#for layer in resnet.layers:\n    #print(layer, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_resnet = create_my_resnet(resnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping,model_checkpoint = EarlyStopingModelCheckPoint()\n\n# Train the model\nstart = time.time()\n\nhistory1 = model_resnet.fit(X_train_features, y_train_cat, # feature and target vector\n          validation_data=(X_val_features, y_val_cat), # data for evaluation\n          epochs=50, #200\n          batch_size=64, # Number of observations per batch\n          verbose=1,     # Print description after each epoch\n          callbacks=[early_stopping,model_checkpoint])\n\nend = time.time()\nexecution_dur1 = end - start;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot model history\nplot_model_history(history1)\n\n# compute accuracy for validation dataset\nval_loss, val_acc = model_resnet.evaluate(X_val_features, y_val_cat)\nprint('\\nValidation accuracy: %0.2f' %(val_acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the model\ny_predict = model_resnet.predict(X_val_features)\ny_predict1D = get1D_y_predict(y_predict)\nacc = metrics.accuracy_score(y_val,y_predict1D)\nprint('Validation accuracy: %0.2f' %(acc*100))\n\n# classification report with model acciracy and F1 score\ncr = metrics.classification_report(y_val,y_predict1D)\nprint(\"Classification Report: \\n\\n\", cr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = metrics.confusion_matrix(y_val, y_predict1D)\n\nfilename = \"{}_TB4B5_cnf\".format(model_resnet)\nplot_cnf_matrix(cm, filename)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}