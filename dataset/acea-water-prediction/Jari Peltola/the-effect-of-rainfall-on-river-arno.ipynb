{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# The Effect of Rainfall on River Arno ","metadata":{}},{"cell_type":"markdown","source":"**TABLE OF CONTENTS**\n1. Introduction <br>\n*1.1 River Arno*<br>\n*1.2 Hydrometry*<br>\n*1.3 Rainfall*<br>\n2. Data Exploration <br>\n3. Annual Data 2015-2019 <br>\n4. Hydrometry And Rainfall Average 2015-2019 <br>\n5. Conclusion<br>\n6. *Addendum: Lake Bilancino*<br>\n7. *The Xboost Expedition*","metadata":{}},{"cell_type":"markdown","source":"Although this notebook uses the *Acea Smart Water Analytics* competition dataset, it is not a contest entry. As someone dedicated to learn more about data analysis, I possess no skills for building comprehensive and reliable predictive models, which indeed was the aim of the competition in question. Rather, this notebook is a part of a personal learning process.\n\nThe reseach question of this notebook was however indirectly provided by the competition organizers. The contest briefing included the following paragraph:\n\n**\"It is of the utmost importance to notice that some features like rainfall and temperature, which are present in each dataset, don’t go alongside the date. Indeed, both rainfall and temperature affect features like level, flow, depth to groundwater and hydrometry some time after it fell down. This means, for instance, that rain fell on 1st January doesn’t affect the mentioned features right the same day but some time later.** ***As we don’t know how many days/weeks/months later rainfall affects these features, this is another aspect to keep into consideration when analyzing the dataset.\"***\n\nAs noted, the *Acea Smart Water Analytics* competition was all about predictive models. Personally, I was fascinated about the notion that by their own admission ***the organizers did not know how rainfall affects any of their water resources***. Therefore, I set as my research question to analyze one particular water resource, namely river Arno, from the viewpoint of rainfall.\n\n*So, what is the relationship between rainfall and river Arno water level?* Let's see if we find anything.\n\n*January 22nd, 2021<br>*\n*Jari Peltola*","metadata":{}},{"cell_type":"markdown","source":"> ## 1. Introduction","metadata":{}},{"cell_type":"markdown","source":"### 1.1 River Arno","metadata":{}},{"cell_type":"markdown","source":"As the competition brief has it:\n\n\"*Arno is the second largest river in peninsular Italy and the main waterway in Tuscany and it has a relatively torrential regime, due to the nature of the surrounding soils (marl and impermeable clays). Arno results to be the main source of water supply of the metropolitan area of Florence-Prato-Pistoia. The availability of water for this waterbody is evaluated \nby checking the hydrometric level of the river at the section of Nave di Rosano.*\"\n\nThis introduction tells us two important things. First, **the soil surrounding river Arno is hard**, meaning it does not preserve water. As it is, this fact alone suggests that the rainfall in the area finds it way to Arno relatively fast.\n\nAnother thing worth noting is that **the water level is always checked on a particular section of the river**, meaning the number we get is consistent. However at the same time, the figure does not necessaarily tell us the whole truth about Arno, since one part of a river can indeed behave quite differently compared to other sections. \n\nFinally, **water consumption figures were not part of the competition dataset.** As increasing or decreasing consumption greatly affects water resources, this feature brings its own level of uncertainty to any analysis concerning the nature and behavior of these water resources. ","metadata":{}},{"cell_type":"markdown","source":"### 1.2 Hydrometry","metadata":{}},{"cell_type":"markdown","source":"The following passage was taken from an online article written by hydraulic engineer **Christian Lallement** (link to full article below):\n\nhttps://www.encyclopedie-environnement.org/en/water/hydrometry-measuring-flow-river-why-how/\n\n\n\"*Hydrometry, a science distinct and complementary to hydrology (science of water in its natural environment) and hydraulics (physics of flows), is the discipline that seeks to measure river flows. The flow rate -volume of water crossing a section of a stream for one unit of time- is expressed in cubic metres per second (m3/s). Each watercourse follows a particular regime, determined by the rhythm of precipitation and its hydrological “terroir”. For the world’s most populated river, the Amazon, the variation in flow between two extreme months of the same month is only one to two. And from one year to the next, its average annual flow at its mouth varies only 10 to 15% around its 206,000 m3/s value. The Amazon is an extremely regular river. On the other hand, an African river like the Chari has an average flow of 1197 m3/s at its outlet in Lake Chad. Within the same year, the variation in flow between two extreme months is a factor of 20 (150 to 3000 m3/s). And from one year to the next, the average annual flow can vary by a factor of two: 739 m3/s in 1942, 1720 m3/s in 1956. The Chari therefore has a much more contrasting regime.*\"\n\nConcerning river Arno, we know know how the river flow is measured. Also, we know that **the \"rhythm\" of the river is an important factor**. Actually, this issue was also mentioned in the contest brief:\n\n\"*During fall and winter waterbodies are refilled, but during spring and summer they start to drain. To help preserve the health of these waterbodies it is important to predict the most efficient water availability, in terms of level and water flow for each day of the year.*\"\n\nLastly, we know now that **hydrometry uses cubic metres per second (m3/s) as unit for measurement**. For example, if there is '1.26' as measurement in the dataset, this to my knowledge means that by that time river Arno had a flow of 1260 cubic meters per second. ","metadata":{}},{"cell_type":"markdown","source":"### 1.3 Rainfall","metadata":{}},{"cell_type":"markdown","source":"The National Center of Atmospheric Research (NCAR) scientist **Peggy Lemone** has written the following about measuring rainfall (link to full post below):\n\nhttps://scied.ucar.edu/blog/measuring-rainfall-–-it’s-easy-and-difficult-same-time-0\n\n\"*The exposure of the rain gauge is undoubtedly the greatest source of error.  According to the National Weather Service and CoCoRAHS (both of which use citizen volunteers to measure rainfall), “exposure” of the rain gauge is important. Rain may be blocked by nearby obstacles causing the number to be lower than it should. Or, rain may be blown into or away from the gauge by wind gusts.  The recommendation is that the gauge be about twice the distance from the height of the nearest obstacles, but still sheltered from the wind.*\"\n\nThus **the rainfall figures can be misleading** because of the instruments used as well as circumstantial differences (a raincloud hovers around observation area etc.) However **the competition dataset includes different locations on rainfall, enabling us to compare regional rainfall figures.** \n\nFinally, it is assumed that all rainfall measurement in the dataset were provided in millimetres, although I could not actually confirm this. I have personally measured both snowfall and rainfall while serving in the army, and there are different options for doing it regarding measurement frequency. Since there is only one rainfall measurement per day in the dataset, **it is further assumed that all rainfall measurements in the dataset are given in millimetres/day (mm/d) format**.\n\nIt is also worth noting that there is a way of converting rainfall into snowfall: a millimeter of water on wintertime roughly equals to one centimeter of snow. \n\nAs for our task, it looks like our work is cut out.\n\n***We need to find the rhythm of River Arno.***","metadata":{}},{"cell_type":"markdown","source":"> ## 2. Data Exploration","metadata":{}},{"cell_type":"markdown","source":"First, let's import the modules.","metadata":{}},{"cell_type":"code","source":"# import modules\nimport math\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport numpy as np\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\n\nfrom pandas.testing import assert_frame_equal\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:09.355731Z","iopub.execute_input":"2021-06-08T10:12:09.35618Z","iopub.status.idle":"2021-06-08T10:12:09.373024Z","shell.execute_reply.started":"2021-06-08T10:12:09.356139Z","shell.execute_reply":"2021-06-08T10:12:09.371526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next we set the column and row display and upload the dataset as dataframe.","metadata":{}},{"cell_type":"code","source":"# set column and row display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# load dataset\ndf = pd.read_csv('../input/acea-water-prediction/River_Arno.csv') \n\n# make a working copy of the original dataframe\ndf_copy = df.copy()\n\n# show ten last rows\ndf.tail(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:09.507745Z","iopub.execute_input":"2021-06-08T10:12:09.508184Z","iopub.status.idle":"2021-06-08T10:12:09.568284Z","shell.execute_reply.started":"2021-06-08T10:12:09.508146Z","shell.execute_reply":"2021-06-08T10:12:09.567013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We may also want to know the overall size of our dataframe.","metadata":{}},{"cell_type":"code","source":"#get dataframe shape\nshape = df_copy.shape\nprint('\\nDataFrame Shape :', shape)\nprint('\\nNumber of rows :', shape[0])\nprint('\\nNumber of columns :', shape[1])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:09.647813Z","iopub.execute_input":"2021-06-08T10:12:09.648265Z","iopub.status.idle":"2021-06-08T10:12:09.655911Z","shell.execute_reply.started":"2021-06-08T10:12:09.648227Z","shell.execute_reply":"2021-06-08T10:12:09.654285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we check the data type, we can see that the Date column is not in datetime format. Next we convert the column in question accordingly.","metadata":{}},{"cell_type":"code","source":"df_copy.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:09.799174Z","iopub.execute_input":"2021-06-08T10:12:09.799564Z","iopub.status.idle":"2021-06-08T10:12:09.811188Z","shell.execute_reply.started":"2021-06-08T10:12:09.799531Z","shell.execute_reply":"2021-06-08T10:12:09.808261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change column to DateTime format\ndf_copy['Date'] =  pd.to_datetime(df_copy['Date'],dayfirst=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:09.931042Z","iopub.execute_input":"2021-06-08T10:12:09.931449Z","iopub.status.idle":"2021-06-08T10:12:09.952159Z","shell.execute_reply.started":"2021-06-08T10:12:09.931415Z","shell.execute_reply":"2021-06-08T10:12:09.950716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As for river Arno, only the first five rainfall locations include any data. Therfore we make a new dataframe **df_arno**, which includes the five locations along with datetime column.","metadata":{}},{"cell_type":"code","source":"# select preferred columns by name\ndf_arno = df_copy.loc[:,['Date', 'Rainfall_Le_Croci', 'Rainfall_Cavallina', 'Rainfall_S_Agata', 'Rainfall_Mangona', 'Rainfall_S_Piero', 'Hydrometry_Nave_di_Rosano']]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:10.07192Z","iopub.execute_input":"2021-06-08T10:12:10.072315Z","iopub.status.idle":"2021-06-08T10:12:10.079774Z","shell.execute_reply.started":"2021-06-08T10:12:10.072282Z","shell.execute_reply":"2021-06-08T10:12:10.078118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also change the column names to more practical form.","metadata":{}},{"cell_type":"code","source":"df_arno.rename(columns = {'Rainfall_Le_Croci':'Le_Croci'}, inplace = True) \ndf_arno.rename(columns = {'Rainfall_Cavallina':'Cavallina'}, inplace = True) \ndf_arno.rename(columns = {'Rainfall_S_Agata':'S_Agata'}, inplace = True) \ndf_arno.rename(columns = {'Rainfall_Mangona':'Mangona'}, inplace = True) \ndf_arno.rename(columns = {'Rainfall_S_Piero':'S_Piero'}, inplace = True) \ndf_arno.rename(columns = {'Hydrometry_Nave_di_Rosano':'Hydrometry'}, inplace = True) ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:10.219376Z","iopub.execute_input":"2021-06-08T10:12:10.219733Z","iopub.status.idle":"2021-06-08T10:12:10.231665Z","shell.execute_reply.started":"2021-06-08T10:12:10.219694Z","shell.execute_reply":"2021-06-08T10:12:10.230339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" df_arno.head()  ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:10.371761Z","iopub.execute_input":"2021-06-08T10:12:10.372211Z","iopub.status.idle":"2021-06-08T10:12:10.389693Z","shell.execute_reply.started":"2021-06-08T10:12:10.372176Z","shell.execute_reply":"2021-06-08T10:12:10.388117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that hydrometry measurements go back to 1998. This analysis takes into account the assumed effect of climate change on old data. By default, each years these days is usually the hottest year ever experienced when it comes to temperature. In other words, the ever-changing climate may in fact render some old data increasingly obsolete. This is why this notebook uses only measurements starting from year 2015 onwards.\n\nNext we mask the dataframe to fit this criteria.","metadata":{}},{"cell_type":"code","source":"# mask dataframe\nstart_date = '2015-01-01'\nend_date = '2020-06-30'\n\n# wear a mask\nmask = (df_arno['Date'] >= start_date) & (df_arno['Date'] < end_date)\ndf_arno = df_arno.loc[mask]\n\ndf_arno.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:10.537386Z","iopub.execute_input":"2021-06-08T10:12:10.537777Z","iopub.status.idle":"2021-06-08T10:12:10.559489Z","shell.execute_reply.started":"2021-06-08T10:12:10.537744Z","shell.execute_reply":"2021-06-08T10:12:10.558299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data from year 2020 includes the first six months of the years. For our purposes however, we need data from all 12 months of the year. \n\nNext we make five new dataframes, each for one year between 2015-2019. After masking the dataframe, the Hydrometry column is temporarily removed. After that, an average rainfall figure is calculated from the five individual rainfall locations. Finally the Hydromerty column is renamed and reinserted to the dataframe.","metadata":{}},{"cell_type":"code","source":"# mask dataframe\nstart_date_2019 = '2019-01-01'\nend_date_2019 = '2019-12-31'\n\n# wear a mask\nmask_2019 = (df_arno['Date'] >= start_date_2019) & (df_arno['Date'] < end_date_2019)\ndf_arno_2019 = df_arno.loc[mask_2019]\n\n# remove column\npop_hydrometry_2019 = df_arno_2019.pop(\"Hydrometry\")\n\n# calculate average per dataframe row\ndf_arno_2019['Rainfall_Mean_2019'] = df_arno_2019.mean(axis=1)\n\n# reinsert oolumn\ndf_arno_2019['Hydrometry_2019'] = pop_hydrometry_2019\n\n# reset index\ndf_arno_2019.reset_index(inplace = True) \n\n# select and drop selected column\ncol = ['index']\ndf_arno_2019 = df_arno_2019.drop(col, axis=1)\n\ndf_arno_2019.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:10.69278Z","iopub.execute_input":"2021-06-08T10:12:10.693194Z","iopub.status.idle":"2021-06-08T10:12:10.728128Z","shell.execute_reply.started":"2021-06-08T10:12:10.693162Z","shell.execute_reply":"2021-06-08T10:12:10.726774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next the same is done to four remaining years included in the analysis.","metadata":{}},{"cell_type":"code","source":"start_date_2018 = '2018-01-01'\nend_date_2018 = '2018-12-31'\n\nmask_2018 = (df_arno['Date'] >= start_date_2018) & (df_arno['Date'] < end_date_2018)\ndf_arno_2018 = df_arno.loc[mask_2018]\n\npop_hydrometry_2018 = df_arno_2018.pop(\"Hydrometry\")\n\ndf_arno_2018['Rainfall_Mean_2018'] = df_arno_2018.mean(axis=1)\ndf_arno_2018['Hydrometry_2018'] = pop_hydrometry_2018\n\ndf_arno_2018.reset_index(inplace = True) \n\ncol = ['index']\ndf_arno_2018 = df_arno_2018.drop(col, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:10.842257Z","iopub.execute_input":"2021-06-08T10:12:10.842751Z","iopub.status.idle":"2021-06-08T10:12:10.861641Z","shell.execute_reply.started":"2021-06-08T10:12:10.842716Z","shell.execute_reply":"2021-06-08T10:12:10.860107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_date_2017 = '2017-01-01'\nend_date_2017 = '2017-12-31'\n\nmask_2017 = (df_arno['Date'] >= start_date_2017) & (df_arno['Date'] < end_date_2017)\ndf_arno_2017 = df_arno.loc[mask_2017]\n\npop_hydrometry_2017 = df_arno_2017.pop(\"Hydrometry\")\n\ndf_arno_2017['Rainfall_Mean_2017'] = df_arno_2017.mean(axis=1)\ndf_arno_2017['Hydrometry_2017'] = pop_hydrometry_2017\n\ndf_arno_2017.reset_index(inplace = True) \n\ncol = ['index']\ndf_arno_2017 = df_arno_2017.drop(col, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:10.971497Z","iopub.execute_input":"2021-06-08T10:12:10.97221Z","iopub.status.idle":"2021-06-08T10:12:10.992906Z","shell.execute_reply.started":"2021-06-08T10:12:10.972169Z","shell.execute_reply":"2021-06-08T10:12:10.991106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_date_2016 = '2016-01-01'\nend_date_2016 = '2016-12-31'\n\nmask_2016 = (df_arno['Date'] >= start_date_2016) & (df_arno['Date'] < end_date_2016)\ndf_arno_2016 = df_arno.loc[mask_2016]\n\npop_hydrometry_2016 = df_arno_2016.pop(\"Hydrometry\")\n\ndf_arno_2016['Rainfall_Mean_2016'] = df_arno_2016.mean(axis=1)\ndf_arno_2016['Hydrometry_2016'] = pop_hydrometry_2016\n\ndf_arno_2016.reset_index(inplace = True) \n\ncol = ['index']\ndf_arno_2016 = df_arno_2016.drop(col, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:11.112349Z","iopub.execute_input":"2021-06-08T10:12:11.112742Z","iopub.status.idle":"2021-06-08T10:12:11.130403Z","shell.execute_reply.started":"2021-06-08T10:12:11.112694Z","shell.execute_reply":"2021-06-08T10:12:11.129106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_date_2015 = '2015-01-01'\nend_date_2015 = '2015-12-31'\n\nmask_2015 = (df_arno['Date'] >= start_date_2015) & (df_arno['Date'] < end_date_2015)\ndf_arno_2015 = df_arno.loc[mask_2015]\n\npop_hydrometry_2015 = df_arno_2015.pop(\"Hydrometry\")\n\ndf_arno_2015['Rainfall_Mean_2015'] = df_arno_2015.mean(axis=1)\ndf_arno_2015['Hydrometry_2015'] = pop_hydrometry_2015\n\ndf_arno_2015.reset_index(inplace = True) \n\ncol = ['index']\ndf_arno_2015 = df_arno_2015.drop(col, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:11.255295Z","iopub.execute_input":"2021-06-08T10:12:11.256237Z","iopub.status.idle":"2021-06-08T10:12:11.275211Z","shell.execute_reply.started":"2021-06-08T10:12:11.256185Z","shell.execute_reply":"2021-06-08T10:12:11.273812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a visual representation from year 2019 to see what we are dealing with. For clarity, the first plot includes only three rainfall locations, and the other two are included in the next plot. The x-axis is set to describe date whereas y-axis axe shows both the rainfall and hydrometry, which both use different units, as we saw in the beginning. Therefore the y-axis unit is not a specific measurement unit but, rather, a complementary figure (tick range 0-50). ","metadata":{}},{"cell_type":"code","source":"# plot figure\nfig = go.Figure()\n\n# add hydrometry trace\nfig.add_trace(go.Scatter(x=df_arno_2019['Date'],\n                y=df_arno_2019['Hydrometry_2019'],\n                name='Hydrometry',\n                mode='lines',\n                marker_color='black'\n               ))\n\n# add rainfall traces\nfig.add_trace(go.Scatter(x=df_arno_2019['Date'],\n                y=df_arno_2019['Le_Croci'],\n                name='Le Croci',\n                mode='lines',         \n                marker_color='orange'\n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_2019['Date'],\n                y=df_arno_2019['Cavallina'],\n                name='Cavallina',\n                mode='lines',         \n                line=dict(color='blue', width=2,\n                              dash='dot')         \n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_2019['Date'],\n                y=df_arno_2019['S_Agata'],\n                name='S_Agata',\n                mode='lines',          \n                line=dict(color='green', width=2,\n                              dash='dash')      \n                ))\n\n# set outlook etc.\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nannotations = []\n\n# add data source\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\n# add header\nfig.update_layout(\n    title='<b>River Arno</b>:<br>Hydrometry and rainfall (2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Number of cases',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.3,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\n\n# set axes etc.\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_yaxes(title_text='Hydrometry and rainfall')\nfig.update_yaxes(title_font=dict(size=14))\n\n# show figure\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:11.397334Z","iopub.execute_input":"2021-06-08T10:12:11.39786Z","iopub.status.idle":"2021-06-08T10:12:11.543676Z","shell.execute_reply.started":"2021-06-08T10:12:11.397826Z","shell.execute_reply":"2021-06-08T10:12:11.542811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot figure\nfig = go.Figure()\n\n# add hydrometry trace\nfig.add_trace(go.Scatter(x=df_arno_2019['Date'],\n                y=df_arno_2019['Hydrometry_2019'],\n                name='Hydrometry',\n                mode='lines',\n                marker_color='black'\n               ))\n\n# add rainfall traces\nfig.add_trace(go.Scatter(x=df_arno_2019['Date'],\n                y=df_arno_2019['Mangona'],\n                name='Mangona',\n                mode='lines',         \n                marker_color='orange'\n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_2019['Date'],\n                y=df_arno_2019['S_Piero'],\n                name='S_Piero',\n                mode='lines',         \n                line=dict(color='blue', width=2,\n                              dash='dot')         \n                ))\n\n# set outlook etc.\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nannotations = []\n\n# add data source\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\n# add header\nfig.update_layout(\n    title='<b>River Arno</b>:<br>Hydrometry and rainfall (2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Number of cases',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.3,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\n\n# set axes etc.\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_yaxes(title_text='Hydrometry and rainfall')\nfig.update_yaxes(title_font=dict(size=14))\n\n# show figure\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:11.545058Z","iopub.execute_input":"2021-06-08T10:12:11.545484Z","iopub.status.idle":"2021-06-08T10:12:11.670645Z","shell.execute_reply.started":"2021-06-08T10:12:11.545452Z","shell.execute_reply":"2021-06-08T10:12:11.669859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that when flow is concerned, Arno is a stable and predictable river. Even during the winter months, top waterflow was below 7.0 with most days having a measurement closer to 2.0. As for rainfall, during winter months there were local measurements up to 64 millimetres a day. This kind og figure becomes even more impressive if one recalls that one millimeter of rainfall roughly equals to one centimeter of snow.\n\nIt would be useful to have an average rainfall figure based on all give measurement locations, so we do that next. For this, we create a new dataframe **df_rainfall**.","metadata":{}},{"cell_type":"code","source":"# make new dataframe\ndf_rainfall = df_arno.copy()\n\n# remove column\npop_hydrometry = df_rainfall.pop(\"Hydrometry\")\n\n# calculate average\ndf_rainfall['Rainfall_Mean'] = df_rainfall.mean(axis=1)\n\n# resinsert column\ndf_rainfall['Hydrometry'] = pop_hydrometry\n\ndf_rainfall.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:11.672001Z","iopub.execute_input":"2021-06-08T10:12:11.672418Z","iopub.status.idle":"2021-06-08T10:12:11.694362Z","shell.execute_reply.started":"2021-06-08T10:12:11.672387Z","shell.execute_reply":"2021-06-08T10:12:11.693575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can inspect the rainfall average and hydrometry from years 2015-2019 more closely.","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\n\n \nfig.add_trace(go.Scatter(x=df_rainfall['Date'],\n                y=df_rainfall['Hydrometry'],\n                name='Hydrometry',\n                mode='lines',\n                marker_color='black'\n               ))\n\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>River Arno</b>:<br>Hydrometry (2015-)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Hydrometry',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.7,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:11.743676Z","iopub.execute_input":"2021-06-08T10:12:11.744239Z","iopub.status.idle":"2021-06-08T10:12:11.916841Z","shell.execute_reply.started":"2021-06-08T10:12:11.744206Z","shell.execute_reply":"2021-06-08T10:12:11.915433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\n\n \nfig.add_trace(go.Scatter(x=df_rainfall['Date'],\n                y=df_rainfall['Hydrometry'],\n                name='Hydrometry',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.add_trace(go.Scatter(x=df_rainfall['Date'],\n                y=df_rainfall['Rainfall_Mean'],\n                name='Rainfall Average',\n                mode='lines',         \n                line=dict(color='red', width=2,\n                               dash='dot')    \n                ))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>River Arno</b>:<br>Hydrometry and average rainfall (2015-)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Hydrometry and rainfall',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.7,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:11.919507Z","iopub.execute_input":"2021-06-08T10:12:11.919853Z","iopub.status.idle":"2021-06-08T10:12:12.204137Z","shell.execute_reply.started":"2021-06-08T10:12:11.919819Z","shell.execute_reply":"2021-06-08T10:12:12.202919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At least in 2015-2019 the peak periods have been rather predicable when the amount of rainfall as well as date of occurrence are concerned.","metadata":{}},{"cell_type":"markdown","source":"## 3. Annual data 2015-2019","metadata":{}},{"cell_type":"markdown","source":"We continue by concentrating on the annual datasets. Next we make copies of all five of them and select the Hydrometry column along with the average rainfall column.","metadata":{}},{"cell_type":"code","source":"# copy dataframes to new ones\ndf_arno_2019_copy = df_arno_2019.copy()\ndf_arno_2018_copy = df_arno_2018.copy()\ndf_arno_2017_copy = df_arno_2017.copy()\ndf_arno_2016_copy = df_arno_2016.copy()\ndf_arno_2015_copy = df_arno_2015.copy()\n\n# select preferred columns \ndf_arno_2019_copy = df_arno_2019_copy.loc[:,['Rainfall_Mean_2019', 'Hydrometry_2019']]\ndf_arno_2018_copy = df_arno_2018_copy.loc[:,['Rainfall_Mean_2018', 'Hydrometry_2018']]\ndf_arno_2017_copy = df_arno_2017_copy.loc[:,['Rainfall_Mean_2017', 'Hydrometry_2017']]\ndf_arno_2016_copy = df_arno_2016_copy.loc[:,['Rainfall_Mean_2016', 'Hydrometry_2016']]\ndf_arno_2015_copy = df_arno_2015_copy.loc[:,['Rainfall_Mean_2015', 'Hydrometry_2015']]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.206454Z","iopub.execute_input":"2021-06-08T10:12:12.20714Z","iopub.status.idle":"2021-06-08T10:12:12.225392Z","shell.execute_reply.started":"2021-06-08T10:12:12.207084Z","shell.execute_reply":"2021-06-08T10:12:12.223915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is notable that 2016 was a leap year, and any annual data from a leap year thus includes one row more than other years. However, since applying strict daily schedule does not apply well to annual rainfall or weather in general, this is not considered a major issue in this notebook. \n\nFor further merging of dataframes, we next create new variable with simple ascending numeric value (1-365). After that, the variable is assigned to all five dataframes as column Day.","metadata":{}},{"cell_type":"code","source":"# create variable\none_to_365 = pd.Series(range(1,366))\n\n# set new column\ndf_arno_2015_copy['Day'] = one_to_365\ndf_arno_2016_copy['Day'] = one_to_365\ndf_arno_2017_copy['Day'] = one_to_365\ndf_arno_2018_copy['Day'] = one_to_365\ndf_arno_2019_copy['Day'] = one_to_365","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.228094Z","iopub.execute_input":"2021-06-08T10:12:12.228609Z","iopub.status.idle":"2021-06-08T10:12:12.243649Z","shell.execute_reply.started":"2021-06-08T10:12:12.228559Z","shell.execute_reply":"2021-06-08T10:12:12.242233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take year 2019 as example to see what we have:","metadata":{}},{"cell_type":"code","source":"df_arno_2019_copy.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.245204Z","iopub.execute_input":"2021-06-08T10:12:12.245628Z","iopub.status.idle":"2021-06-08T10:12:12.259612Z","shell.execute_reply.started":"2021-06-08T10:12:12.24559Z","shell.execute_reply":"2021-06-08T10:12:12.258712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next we merge our five dataframes based on the common Day column. We do this with two dataframes at a time.","metadata":{}},{"cell_type":"code","source":"# merge dataframes\ndf_con_one = pd.merge(df_arno_2015_copy, df_arno_2016_copy, on='Day')\ndf_con_two = pd.merge(df_arno_2017_copy, df_arno_2018_copy, on='Day')\ndf_con_three = pd.merge(df_con_one, df_con_two, on='Day')\ndf_arno_1519 = pd.merge(df_con_three, df_arno_2019_copy, on='Day')\n\ndf_arno_1519.tail(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.261273Z","iopub.execute_input":"2021-06-08T10:12:12.261751Z","iopub.status.idle":"2021-06-08T10:12:12.30028Z","shell.execute_reply.started":"2021-06-08T10:12:12.261713Z","shell.execute_reply":"2021-06-08T10:12:12.299442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have all five years and their respected data in one dataframe **df_arno_1519**. If we take a closer look at the data, we can see that on one particular day the hydrometry reading is in fact 0.0. Although it is in theory possible that river Arno was on strike that day, it is more likely that there is a flub in that particular day's measurement. There is no need whatsoever to do anything about it, but since all other measurements are above 1.0, any further plotting of visuals would suffer from this unfortunate measurement error. Therefore I will manually change that day's measurement from zero to one. Although 1.0 is likely not the correct value either, it serves purpose as \"neutral\" value since we are after average hydrometry readings,   ","metadata":{}},{"cell_type":"code","source":"# change row value\ndf_arno_1519.at[269,'Hydrometry_2019']=1.0","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.326982Z","iopub.execute_input":"2021-06-08T10:12:12.327563Z","iopub.status.idle":"2021-06-08T10:12:12.332105Z","shell.execute_reply.started":"2021-06-08T10:12:12.32752Z","shell.execute_reply":"2021-06-08T10:12:12.331163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Hydrometry and rainfall average 2015-2019","metadata":{}},{"cell_type":"markdown","source":"Now we can plot our data more comfortably. We start with hydrometry readings from years 2015-2019.","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\n\n \nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Hydrometry_2015'],\n                name='Hydrometry 2015',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Hydrometry_2016'],\n                name='Hydrometry 2016',\n                mode='lines',         \n                marker_color='orange'\n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Hydrometry_2017'],\n                name='Hydrometry 2017',\n                mode='lines',         \n                marker_color='magenta'      \n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Hydrometry_2018'],\n                name='Hydrometry 2018',\n                mode='lines',          \n                marker_color='steelblue'   \n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Hydrometry_2019'],\n                name='Hydrometry 2019',\n                mode='lines',          \n                marker_color='forestgreen'   \n                ))\n\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>River Arno</b>:<br>Hydrometry (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Hydrometry',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.3,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=1, dtick= 10)\n#fig.update_xaxes(tick0=1, dtick= 364)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_yaxes(title_text='Hydrometry average')\nfig.update_xaxes(title_text='Day')\n\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.434858Z","iopub.execute_input":"2021-06-08T10:12:12.435438Z","iopub.status.idle":"2021-06-08T10:12:12.529634Z","shell.execute_reply.started":"2021-06-08T10:12:12.4354Z","shell.execute_reply":"2021-06-08T10:12:12.528549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the \"rhythm of Arno\" much better now when it comes to flow. Starting from mid-February (day 45 onwards), the hydrometry figures reach up to 5.0. Coming mid-April (day 100), hydrometry readings start to come down and basically stay down right up to the end of October (day 300) when the autumn rainfall starts to take effect.\n\nNext will will create similar visuals on rainfall average.","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Rainfall_Mean_2015'],\n                name='Rainfall Average 2015',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Rainfall_Mean_2016'],\n                name='Rainfall Average 2016',\n                mode='lines',         \n                marker_color='orange'\n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Rainfall_Mean_2017'],\n                name='Rainfall Average 2017',\n                mode='lines',         \n                marker_color='magenta'      \n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Rainfall_Mean_2018'],\n                name='Rainfall Average 2018',\n                mode='lines',          \n                marker_color='steelblue'   \n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_1519['Day'],\n                y=df_arno_1519['Rainfall_Mean_2019'],\n                name='Rainfall Average 2019',\n                mode='lines',          \n                marker_color='forestgreen'   \n                ))\n\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>River Arno</b>:<br>Rainfall Average (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Rainfall average',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.3,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.531847Z","iopub.execute_input":"2021-06-08T10:12:12.532215Z","iopub.status.idle":"2021-06-08T10:12:12.623708Z","shell.execute_reply.started":"2021-06-08T10:12:12.53218Z","shell.execute_reply":"2021-06-08T10:12:12.622251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The rainfall readings somewhat follow the hydrometry readings with a couple of exceptions. For example, during summer months the rainfall does not have similar an effect to hydrometry as in spring. Of course during the spring period there is also a lot of snow melting in the mountain region where Arno begins its flow, so rainfall is by no means not the only factor affecting the river hydrometry. \n\nNext we pick the rainfall average readings along with Day column to a new dataframe **df_arno_fall_mean**. After that we calculate one overall rainfall average covering the annual averages from years 2015-2019.","metadata":{}},{"cell_type":"code","source":"# create dataframe\ndf_arno_fall_mean = df_arno_1519.loc[:,['Day', 'Rainfall_Mean_2015', 'Rainfall_Mean_2016', 'Rainfall_Mean_2017', 'Rainfall_Mean_2018', 'Rainfall_Mean_2019']]\n\n# remove column\npop_rain_day = df_arno_fall_mean.pop(\"Day\")\n\n# calculate average\ndf_arno_fall_mean['Rainfall_Mean'] = df_arno_fall_mean.mean(axis=1)\n\n# reinsert column\ndf_arno_fall_mean['Day'] = pop_rain_day\n\ndf_arno_fall_mean.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.670789Z","iopub.execute_input":"2021-06-08T10:12:12.671205Z","iopub.status.idle":"2021-06-08T10:12:12.700026Z","shell.execute_reply.started":"2021-06-08T10:12:12.671169Z","shell.execute_reply":"2021-06-08T10:12:12.698621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's do the same with the hydrometry readings next.","metadata":{}},{"cell_type":"code","source":"df_arno_hydro_mean = df_arno_1519.loc[:,['Day', 'Hydrometry_2015', 'Hydrometry_2016', 'Hydrometry_2017', 'Hydrometry_2018', 'Hydrometry_2019']]\n\npop_hydro_day = df_arno_hydro_mean.pop(\"Day\")\n\ndf_arno_hydro_mean['Hydrometry_Mean'] = df_arno_hydro_mean.mean(axis=1)\ndf_arno_hydro_mean['Day'] = pop_hydro_day\n\ndf_arno_hydro_mean.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.701883Z","iopub.execute_input":"2021-06-08T10:12:12.702282Z","iopub.status.idle":"2021-06-08T10:12:12.726094Z","shell.execute_reply.started":"2021-06-08T10:12:12.702247Z","shell.execute_reply":"2021-06-08T10:12:12.72518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are looking for overall averages only, so we extract them to two new dataframes **df_arno_rainfall** and **df_arno_hydrometry**, with the Day column as common denominator for future merging.","metadata":{}},{"cell_type":"code","source":"# create dataframes\ndf_arno_rainfall = df_arno_fall_mean.loc[:,['Day', 'Rainfall_Mean']]\ndf_arno_hydrometry = df_arno_hydro_mean.loc[:,['Day', 'Hydrometry_Mean']]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.757739Z","iopub.execute_input":"2021-06-08T10:12:12.758118Z","iopub.status.idle":"2021-06-08T10:12:12.767841Z","shell.execute_reply.started":"2021-06-08T10:12:12.758086Z","shell.execute_reply":"2021-06-08T10:12:12.766242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we merge these to dataframes to **df_arno_waterbody**.","metadata":{}},{"cell_type":"code","source":"# merge dataframes\ndf_arno_waterbody = pd.merge(df_arno_rainfall, df_arno_hydrometry, on='Day')\n\ndf_arno_waterbody.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.85609Z","iopub.execute_input":"2021-06-08T10:12:12.856503Z","iopub.status.idle":"2021-06-08T10:12:12.877476Z","shell.execute_reply.started":"2021-06-08T10:12:12.856468Z","shell.execute_reply":"2021-06-08T10:12:12.875874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our final plots are visual presentations of this dataframe.","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\n \nfig.add_trace(go.Scatter(x=df_arno_waterbody['Day'],\n                y=df_arno_waterbody['Hydrometry_Mean'],\n                name='Hydrometry Average (2015-2019)',\n                mode='lines',\n                marker_color='black'\n               ))\n\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>River Arno</b>:<br>Hydrometry average (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Hydrometry',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.3,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_xaxes(title_text='Day')\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:12.926034Z","iopub.execute_input":"2021-06-08T10:12:12.926453Z","iopub.status.idle":"2021-06-08T10:12:13.006022Z","shell.execute_reply.started":"2021-06-08T10:12:12.926419Z","shell.execute_reply":"2021-06-08T10:12:13.004091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\n \nfig.add_trace(go.Scatter(x=df_arno_waterbody['Day'],\n                y=df_arno_waterbody['Hydrometry_Mean'],\n                name='Hydrometry Average (2015-2019)',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.add_trace(go.Scatter(x=df_arno_waterbody['Day'],\n                y=df_arno_waterbody['Rainfall_Mean'],\n                name='Rainfall Average (2015-2019)',\n                mode='lines',         \n                marker_color='orange'\n                ))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>River Arno</b>:<br>Hydrometry and rainfall average (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Hydrometry and rainfall',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.3,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_xaxes(title_text='Day')\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.008762Z","iopub.execute_input":"2021-06-08T10:12:13.009271Z","iopub.status.idle":"2021-06-08T10:12:13.093043Z","shell.execute_reply.started":"2021-06-08T10:12:13.009224Z","shell.execute_reply":"2021-06-08T10:12:13.092127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Conclusion","metadata":{}},{"cell_type":"markdown","source":"As noted in the beginning, the units for rainfall (millimetres/day) and hydrometry (cubic meters/second) are not directly comparable, the plot above showing both is not a scaled presentation of these two features. However, as hydrometry reacts to rainfall, the mutual coexistence of these two features can be well observed. \n\nOur research question was all about analyzing how long does it take for rainfall to have an effect on hydrometry when river Arno is concerned.\n\n**Based on the 2015-2019 data, during peak rainfall it takes about 2-3 calendar days for rainfall to have an effect on river Arno hydrometry. During warm summer months however, this effect is radically diminished.**\n\n**After summer, when the rainfall increases starting from September (day 250 onwards), it starts to have effect on hydrometry only in late October (day 300 onwards) because of the long dry summer spell.** \n\nAs climate change evolves, it remains to be seen what kind of effect it has concerning Arno water level. One feature outside this analysis is the snow situation in the area. As ice is known to gradually recede from mountaineous areas in Europe, increased humidity may well bring snow on occasions previously considered unlikely.  \n\nFinally, as mentioned in the beginning, water consumption and demand will partly dictate the level of water reservoirs especially in dry summer months, when average rainfall is lower and there is no melting snow effect. In the case of river Arno, this summer period lasts about 150 days (from day 100 to day 250). Thus, from the viewpoint of water consumption, the major question is whether the more rainy winter months are still able to \"refill\" river Arno in a way that does not lead to \"spillover\" (i.e. destructive flooding).\n\nParadoxically, too much clean water in form of rainfall causes failure of sewage system. Thus overwhelming flow will furthermore contaminate household water, if river Arno breaks its levees and penetrates into residential areas. As we can see from hydrometry averages, this is most likely to happen either in November or in February.\n\nEverything we know about climate change would suggest that all this will in the future be ever more challenging a task. As mentioned in the beginning, the riverbanks of Arno don't effectively store water. Yet the biggest problem may still not be the Arno region running out of water in summer.\n\nIt may be all about water running over Arno region in winter.","metadata":{}},{"cell_type":"markdown","source":"## 6. Addendum: Lake Bilancino","metadata":{}},{"cell_type":"markdown","source":"The rather sparse English Wikipedia article on Lake Bilancino (Lago di Bilancino) describes the lake as following (link to full article below, however the paragraph below *is* the full article):\n\nhttps://en.wikipedia.org/wiki/Lago_di_Bilancino\n\n\"***Lago di Bilancino is an artificial lake near Barberino di Mugello in the Metropolitan City of Florence, Tuscany, Italy, made with a dam on the river Sieve. At an elevation of 252 m, the lake surface area is approximately 5 km².***\"\n\nMoreover, the supplemental brief from the dataset states the following:\n\n\"***Bilancino lake is an artificial lake located in the municipality of Barberino di Mugello (about 50 km from Florence). It is used to refill the Arno river during the summer months. Indeed, during the winter months, the lake is filled up and then, during the summer months, the water of the lake is poured into the Arno river.***\"\n\nHowever small these glimpses into Lake Bilancino might be, they provide us with important facts. First, **lake Bilancino gets most its water from river Sieve, which is not part of the original dataset**. Secondly, **Bilancino is the water reservoir for river Arno during summer months**. This means the \"rhythm of Bilancino\" is very much intertwined with whatever is going on in Arno.\n\nIn the analysis on river Arno and rainfall, it was discovered that Arno has a dry spell ranging from May to August. Also, Arno has two \"flood peaks\" when the water level threatens to overwhelm riverbanks. Of course, lake Bilancino can fill Arno but it does not work the other way. If autumn rainfall starts to fill Bilancino too much and Arno is at peak flow at the same time, there is nowhere Bilancino can be emptied into.\n\nBased on the Arno analysis, two resesarch questions should be asked concerning lake Bilancino. First, **does lake Bilancino \"dry up\" during summer?** Secondly, **is Bilancino water level \"too high\" during winter months, meaning the reservoir itself would be in danger of breaking its barriers?**\n\nSo let's get to work.","metadata":{}},{"cell_type":"code","source":"# set column and row display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\n# load dataset\ndf = pd.read_csv('../input/acea-water-prediction/Lake_Bilancino.csv') \n\n# make a working copy of the original dataframe\ndf_bilancino = df.copy()\n\n# change column to DateTime format\ndf_bilancino['Date'] =  pd.to_datetime(df_bilancino['Date'],dayfirst=True)\n\n# mask dataframe\nstart_date = '2015-01-01'\nend_date = '2020-06-30'\n\n# wear a mask\nmask = (df_bilancino['Date'] >= start_date) & (df_bilancino['Date'] < end_date)\ndf_bilancino = df_bilancino.loc[mask]\n\ndf_bilancino.rename(columns = {'Rainfall_Le_Croci':'Le_Croci'}, inplace = True) \ndf_bilancino.rename(columns = {'Rainfall_Cavallina':'Cavallina'}, inplace = True) \ndf_bilancino.rename(columns = {'Rainfall_S_Agata':'S_Agata'}, inplace = True) \ndf_bilancino.rename(columns = {'Rainfall_Mangona':'Mangona'}, inplace = True) \ndf_bilancino.rename(columns = {'Rainfall_S_Piero':'S_Piero'}, inplace = True) \ndf_bilancino.rename(columns = {'Hydrometry_Nave_di_Rosano':'Hydrometry'}, inplace = True) \n\ndf_bilancino.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.095158Z","iopub.execute_input":"2021-06-08T10:12:13.095477Z","iopub.status.idle":"2021-06-08T10:12:13.156549Z","shell.execute_reply.started":"2021-06-08T10:12:13.095444Z","shell.execute_reply":"2021-06-08T10:12:13.1556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The rainfall readings are identical with river Arno data, so they can be applied as such to lake Bilancino. In addition, there are readings on lake water level (assumably in meter.centimeter format) and low rate. This of course can mean two different things, either water flowing *into* the lake or water flowing *out* from the lake. \n\nAs Bilancino is a water reservoir with its own man-controlled flow out from the lake into Arno, it is further assumed that flow rate in the dataset describes this water flow from Bilancino into Arno. Also, the water flow unit remains unclear in the original dataset, so in this analysis it is assumed that this unit is the same as in Arno's hydrometry i.e. cubic metres in second. \n\nWe already have average rainfall and hydrometry on Arno from 2015-2019 period. Next we will do the same with lake Bilancino and its water level as well as flow rate. As for temperature, I find it more or less unreliable a factor in analyzing lake Bilancino, since the same exact temperature has quite different an effect depending on air humidity, hours of unimpeded sunlight etc. Therefore temperature readings are further excluded from this analysis.\n\nFirst, let's check the five-year period of Bilancino data.","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\n\n \nfig.add_trace(go.Scatter(x=df_bilancino['Date'],\n                y=df_bilancino['Lake_Level'],\n                name='Lake Level',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.add_trace(go.Scatter(x=df_bilancino['Date'],\n                y=df_bilancino['Flow_Rate'],\n                name='Flow Rate',\n                mode='lines',         \n                line=dict(color='red', width=2,\n                               dash='dot')    \n                ))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>Lake Bilancino</b>:<br>Lake level and flow rate (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Lake level and flow rate',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.7,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.158573Z","iopub.execute_input":"2021-06-08T10:12:13.158893Z","iopub.status.idle":"2021-06-08T10:12:13.432996Z","shell.execute_reply.started":"2021-06-08T10:12:13.158861Z","shell.execute_reply":"2021-06-08T10:12:13.431449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the water level is artificially kept relatively steady. The flow rate seems to increase every year between November and February, which is the flood season in Arno. \n\nBecause there is certainly no water shortage in Arno during winter, the rational explanation would be that lake Bilancino water flow needs to be increased at the same time regardless of Arno. After all, there is an increase in Bilancino water level every autumn from 246-247 to 250 and even above. In numbers this does not sound much, but it we think about water level in metres in a lake, these numbers suddenly get a whole new level of importance. Therefore seems that the \"pattern of crisis\" concerning Arno and Bilancino would be when levels in both waterbodies rise simultaneously during rain season above a certain threshold level considered as safe. \n\nFor example, in November 2019 river Arno rose to its highest levels in 20 years (link to article below):\n\nhttps://www.wantedinrome.com/news/florence-on-alert-as-river-arno-rises-to-highest-levels-in-20-years.html\n\nAccording to article, on November 17th Arno had water level of 4,8 meters as a result of 62 millimetres of rainfall in 24 hours. In November 2019, Bilancino water level rapidly rose from 247 to 250 metres caused by the same rainy spell.\n\nAccording to Wikipedia, lake Bilancino has surface elevation of 252 metres. This figure most likely serves also as the final threshold below which water level in the lake must stay in order to be controlled. Given the wave effect caused by wind, the actual safety level is more likely closer to 250 metres.\n\n**If all this is true, lake Bilancino is not about to dry up every year during summer but actually flow over on annual basis during winter.** \n\nNext we create a new dataframe **df_bi_copy** with appropriate columns:","metadata":{}},{"cell_type":"code","source":"# select preferred columns by name\ndf_bi_copy = df_bilancino.loc[:,['Date', 'Lake_Level', 'Flow_Rate']]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.435521Z","iopub.execute_input":"2021-06-08T10:12:13.435844Z","iopub.status.idle":"2021-06-08T10:12:13.442505Z","shell.execute_reply.started":"2021-06-08T10:12:13.435812Z","shell.execute_reply":"2021-06-08T10:12:13.441004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can create the annual dataframes in one neat bulk.","metadata":{}},{"cell_type":"code","source":"start_date_2019 = '2019-01-01'\nend_date_2019 = '2019-12-31'\nmask_2019 = (df_bi_copy['Date'] >= start_date_2019) & (df_bi_copy['Date'] < end_date_2019)\ndf_bilancino_2019 = df_bi_copy.loc[mask_2019]\npop_date_2019 = df_bilancino_2019.pop(\"Date\")\ndf_bilancino_2019.rename(columns = {'Lake_Level':'Lake_Level_2019'}, inplace = True) \ndf_bilancino_2019.rename(columns = {'Flow_Rate':'Flow_Rate_2019'}, inplace = True) \ndf_bilancino_2019.reset_index(inplace = True) \ncol = ['index']\ndf_bilancino_2019 = df_bilancino_2019.drop(col, axis=1)\n\n\nstart_date_2018 = '2018-01-01'\nend_date_2018 = '2018-12-31'\nmask_2018 = (df_bi_copy['Date'] >= start_date_2018) & (df_bi_copy['Date'] < end_date_2018)\ndf_bilancino_2018 = df_bi_copy.loc[mask_2018]\npop_date_2018 = df_bilancino_2018.pop(\"Date\")\ndf_bilancino_2018.rename(columns = {'Lake_Level':'Lake_Level_2018'}, inplace = True) \ndf_bilancino_2018.rename(columns = {'Flow_Rate':'Flow_Rate_2018'}, inplace = True) \ndf_bilancino_2018.reset_index(inplace = True) \ncol = ['index']\ndf_bilancino_2018 = df_bilancino_2018.drop(col, axis=1)\n\nstart_date_2017 = '2017-01-01'\nend_date_2017 = '2017-12-31'\nmask_2017 = (df_bi_copy['Date'] >= start_date_2017) & (df_bi_copy['Date'] < end_date_2017)\ndf_bilancino_2017 = df_bi_copy.loc[mask_2017]\npop_date_2017 = df_bilancino_2017.pop(\"Date\")\ndf_bilancino_2017.rename(columns = {'Lake_Level':'Lake_Level_2017'}, inplace = True) \ndf_bilancino_2017.rename(columns = {'Flow_Rate':'Flow_Rate_2017'}, inplace = True) \ndf_bilancino_2017.reset_index(inplace = True) \ncol = ['index']\ndf_bilancino_2017 = df_bilancino_2017.drop(col, axis=1)\n\nstart_date_2016 = '2016-01-01'\nend_date_2016 = '2016-12-31'\nmask_2016 = (df_bi_copy['Date'] >= start_date_2016) & (df_bi_copy['Date'] < end_date_2016)\ndf_bilancino_2016 = df_bi_copy.loc[mask_2016]\npop_date_2016 = df_bilancino_2016.pop(\"Date\")\ndf_bilancino_2016.rename(columns = {'Lake_Level':'Lake_Level_2016'}, inplace = True) \ndf_bilancino_2016.rename(columns = {'Flow_Rate':'Flow_Rate_2016'}, inplace = True) \ndf_bilancino_2016.reset_index(inplace = True) \ncol = ['index']\ndf_bilancino_2016 = df_bilancino_2016.drop(col, axis=1)\n\nstart_date_2015 = '2015-01-01'\nend_date_2015 = '2015-12-31'\nmask_2015 = (df_bi_copy['Date'] >= start_date_2015) & (df_bi_copy['Date'] < end_date_2015)\ndf_bilancino_2015 = df_bi_copy.loc[mask_2015]\npop_date_2015 = df_bilancino_2015.pop(\"Date\")\ndf_bilancino_2015.rename(columns = {'Lake_Level':'Lake_Level_2015'}, inplace = True) \ndf_bilancino_2015.rename(columns = {'Flow_Rate':'Flow_Rate_2015'}, inplace = True) \ndf_bilancino_2015.reset_index(inplace = True) \ncol = ['index']\ndf_bilancino_2015 = df_bilancino_2015.drop(col, axis=1)\n\n# create variable\none_to_365 = pd.Series(range(1,366))\n\n# set new column\ndf_bilancino_2015['Day'] = one_to_365\ndf_bilancino_2016['Day'] = one_to_365\ndf_bilancino_2017['Day'] = one_to_365\ndf_bilancino_2018['Day'] = one_to_365\ndf_bilancino_2019['Day'] = one_to_365\n\n# merge dataframes\ndf_bil_one = pd.merge(df_bilancino_2015, df_bilancino_2016, on='Day')\ndf_bil_two = pd.merge(df_bilancino_2017, df_bilancino_2018, on='Day')\ndf_bil_three = pd.merge(df_bil_one, df_bil_two, on='Day')\ndf_bilancino_1519 = pd.merge(df_bil_three, df_bilancino_2019, on='Day')\n\ndf_bilancino_1519.tail(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.445299Z","iopub.execute_input":"2021-06-08T10:12:13.445661Z","iopub.status.idle":"2021-06-08T10:12:13.540186Z","shell.execute_reply.started":"2021-06-08T10:12:13.445628Z","shell.execute_reply":"2021-06-08T10:12:13.538637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\n\n \nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Lake_Level_2015'],\n                name='Lake level 2015',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Lake_Level_2016'],\n                name='Lake level 2016',\n                mode='lines',         \n                marker_color='orange'\n                ))\n\nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Lake_Level_2017'],\n                name='Lake level 2017',\n                mode='lines',         \n                marker_color='magenta'      \n                ))\n\nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Lake_Level_2018'],\n                name='Lake level 2018',\n                mode='lines',          \n                marker_color='steelblue'   \n                ))\n\nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Lake_Level_2019'],\n                name='Lake level 2019',\n                mode='lines',          \n                marker_color='forestgreen'   \n                ))\n\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>Lake Bilancino</b>:<br>Lake level (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Hydrometry',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.2,\n        y=0.4,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n#fig.update_xaxes(tick0=1, dtick= 364)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_yaxes(title_text='Lake level')\nfig.update_xaxes(title_text='Day')\n\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.542477Z","iopub.execute_input":"2021-06-08T10:12:13.542977Z","iopub.status.idle":"2021-06-08T10:12:13.64803Z","shell.execute_reply.started":"2021-06-08T10:12:13.542912Z","shell.execute_reply":"2021-06-08T10:12:13.646842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The figure above seems to support the hypothesis that lake Bilancino has no shortage of water. Rather the water level is most of the time close to maximum level defined by the artificially created surrounding surface level (252 metres).","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\n\n \nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Flow_Rate_2015'],\n                name='Flow rate 2015',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Flow_Rate_2016'],\n                name='Flow rate 2016',\n                mode='lines',         \n                marker_color='orange'\n                ))\n\nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Flow_Rate_2017'],\n                name='Flow rate 2017',\n                mode='lines',         \n                marker_color='magenta'      \n                ))\n\nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Flow_Rate_2018'],\n                name='Flow rate 2018',\n                mode='lines',          \n                marker_color='steelblue'   \n                ))\n\nfig.add_trace(go.Scatter(x=df_bilancino_1519['Day'],\n                y=df_bilancino_1519['Flow_Rate_2019'],\n                name='Flow rate 2019',\n                mode='lines',          \n                marker_color='forestgreen'   \n                ))\n\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>Lake Bilancino</b>:<br>Flow rate (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Hydrometry',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.3,\n        y=0.6,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n#fig.update_xaxes(tick0=1, dtick= 364)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_yaxes(title_text='Flow rate')\nfig.update_xaxes(title_text='Day')\n\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.650312Z","iopub.execute_input":"2021-06-08T10:12:13.65077Z","iopub.status.idle":"2021-06-08T10:12:13.753825Z","shell.execute_reply.started":"2021-06-08T10:12:13.650723Z","shell.execute_reply":"2021-06-08T10:12:13.75272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As noted earlier, it is assumed that the flow rate in the dataset is consistent with the hydrometer measurements i.e. both are given in cubic metres per second format. If one takes a look at the lake Bilancino flow rates, there are significant peaks during winter season reaching up to 31.0. \n\nThis is not about lake Bilancino acting as a water reservoir, since river Arno has no water shortage during winter period. Rather is seems that the figures describe lake Bilancino in crisis mode, a waterbody in the brink of breaking its levees.\n\nNext we calculate the five-year averages of both water flow and lake level.","metadata":{}},{"cell_type":"code","source":"df_bilancino_level_mean = df_bilancino_1519.loc[:,['Day', 'Lake_Level_2015', 'Lake_Level_2016', 'Lake_Level_2017', 'Lake_Level_2018', 'Lake_Level_2019']]\npop_level_day = df_bilancino_level_mean.pop(\"Day\")\ndf_bilancino_level_mean['Lake_Level_Mean'] = df_bilancino_level_mean.mean(axis=1)\ndf_bilancino_level_mean['Day'] = pop_level_day\n\ndf_bilancino_flow_mean = df_bilancino_1519.loc[:,['Day', 'Flow_Rate_2015', 'Flow_Rate_2016', 'Flow_Rate_2017', 'Flow_Rate_2018', 'Flow_Rate_2019']]\npop_flow_day = df_bilancino_flow_mean.pop(\"Day\")\ndf_bilancino_flow_mean['Flow_Rate_Mean'] = df_bilancino_flow_mean.mean(axis=1)\ndf_bilancino_flow_mean['Day'] = pop_flow_day","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.755663Z","iopub.execute_input":"2021-06-08T10:12:13.756386Z","iopub.status.idle":"2021-06-08T10:12:13.774819Z","shell.execute_reply.started":"2021-06-08T10:12:13.756335Z","shell.execute_reply":"2021-06-08T10:12:13.773488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create dataframes\ndf_bilancino_level = df_bilancino_level_mean.loc[:,['Day', 'Lake_Level_Mean']]\ndf_bilancino_flow = df_bilancino_flow_mean.loc[:,['Day', 'Flow_Rate_Mean']]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.776133Z","iopub.execute_input":"2021-06-08T10:12:13.776453Z","iopub.status.idle":"2021-06-08T10:12:13.785469Z","shell.execute_reply.started":"2021-06-08T10:12:13.776423Z","shell.execute_reply":"2021-06-08T10:12:13.784344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge dataframes\ndf_bilancino_waterbody = pd.merge(df_bilancino_level, df_bilancino_flow, on='Day')\ndf_bilancino_waterbody.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.786702Z","iopub.execute_input":"2021-06-08T10:12:13.787138Z","iopub.status.idle":"2021-06-08T10:12:13.809902Z","shell.execute_reply.started":"2021-06-08T10:12:13.787108Z","shell.execute_reply":"2021-06-08T10:12:13.809119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge dataframes\ndf_arno_and_bilancino = pd.merge(df_arno_waterbody, df_bilancino_waterbody, on='Day')\ndf_arno_and_bilancino.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.813079Z","iopub.execute_input":"2021-06-08T10:12:13.813504Z","iopub.status.idle":"2021-06-08T10:12:13.842418Z","shell.execute_reply.started":"2021-06-08T10:12:13.813472Z","shell.execute_reply":"2021-06-08T10:12:13.841304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\n \nfig.add_trace(go.Scatter(x=df_arno_and_bilancino['Day'],\n                y=df_arno_and_bilancino['Hydrometry_Mean'],\n                name='Arno Hydrometry Average (2015-2019)',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.add_trace(go.Scatter(x=df_arno_and_bilancino['Day'],\n                y=df_arno_and_bilancino['Rainfall_Mean'],\n                name='Arno Rainfall Average (2015-2019)',\n                mode='lines',         \n                marker_color='orange'\n                ))\n\nfig.add_trace(go.Scatter(x=df_arno_and_bilancino['Day'],\n                y=df_arno_and_bilancino['Flow_Rate_Mean'],\n                name='Bilancino Flow Rate Average (2015-2019)',\n                mode='lines',         \n                marker_color='red'\n                ))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>River Arno and Lake Bilancino</b>:<br>Hydrometry, rainfall average, water flow average (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Hydrometry, rainfall, water flow',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.17,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_xaxes(title_text='Day')\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.844795Z","iopub.execute_input":"2021-06-08T10:12:13.845134Z","iopub.status.idle":"2021-06-08T10:12:13.926777Z","shell.execute_reply.started":"2021-06-08T10:12:13.845103Z","shell.execute_reply":"2021-06-08T10:12:13.92585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The flow rate of lake Bilancino seems to have two different peaks at the turn of each year. The time between February and March finds lake Bilancino having to release its water pressure into Arno, and at the end of October the autumn rainfall has again filled the lake up.\n\nFinally, let's take a look at the lake level average.","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\n \nfig.add_trace(go.Scatter(x=df_arno_and_bilancino['Day'],\n                y=df_arno_and_bilancino['Lake_Level_Mean'],\n                name='Lake Level Average (2015-2019)',\n                mode='lines',\n                marker_color='black'\n               ))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=False,\n        showticklabels=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n\nannotations = []\n\nannotations.append(dict(xref='paper', yref='paper', x=0.75, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Source: Kaggle.com<br> Acea Smart Water Analytics competition', \n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    title='<b>Lake Bilancino</b>:<br>Lake level average (2015-2019)',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Lake level',\n        titlefont_size=14,\n        tickfont_size=14,\n    ),\n    \n     title_font=dict(\n        size=12,     \n    ),\n    legend=dict(\n        x=0.3,\n        y=0.9,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    )\n)\nfig.update_yaxes(tick0=0, dtick= 50)\n\nfig.update_layout(\n   font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.update_xaxes(title_text='Day')\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_yaxes(title_font=dict(size=14))\n\nfig.show()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:13.928177Z","iopub.execute_input":"2021-06-08T10:12:13.92849Z","iopub.status.idle":"2021-06-08T10:12:14.000217Z","shell.execute_reply.started":"2021-06-08T10:12:13.928459Z","shell.execute_reply":"2021-06-08T10:12:13.999464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most important factor in lake level is in my opinion the fact that lake Bilancino level is man-controlled. Therefore I found it odd that this feature was to be predicted by algorithmic modeling. As we can see from the average figures, winter has no problem filling Bilancino to its maximum level of 252 metres.\n\nRather, there seems to be an ongoing struggle to let water out of Bilancino into Arno. Of course Arno has its limits too, and when rainfall exceeds certain threshold, both Bilancino and Arno may meet their respective limits simultaneously, leading to uncontrolled flooding.\n\nThis is why it seems - based on what we just learned - that **the real issue with Bilancino and Arno is that the combination of the two is insufficient by capacity to handle the increasing rainfall likely created by accelerating climate change in the near future.**\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## 7. The Xboost Expedition","metadata":{}},{"cell_type":"markdown","source":"As noted in the beginning, I possess no skills to make accurate predictive models. The content above is something I can to some extent vouch for at least when it comes to how and why different measures were taken.\n\nBeyond this sentence, this is no longer the case. To be honest, I don't know what the ---- I'm about to get into. Hence the title referring to an expedition. I may be stuck on thick data ice in the middle of nowhere pretty soon, seriously thinking if canine tastes good with lamp oil... Horrible, horrible...\n\n*What? How did Roald Amundsen get into this? Well, he did disappear in the Arctic, flying way too high...*\n\nIn a sentence, I am about to try the simplest of modeling first time ever, without any necessary skills or knowledge. The first obstacle I encountered had to do with train, test and validation data. Apparently everything I thought I knew about it was wrong...\n\nFor a long time, I was under the impression that the following is true:\n\n*One uses train-test split function to divide data into train and test sets.*\n\nEnter Wikipedia article on the matter (link to full article below):\n\nhttps://en.wikipedia.org/wiki/Training%2C_validation%2C_and_test_sets\n\n\"*The model is initially fit on a training dataset, which is a set of examples used to fit the parameters (e.g. weights of connections between neurons in artificial neural networks) of the model. The model (e.g. a neural net or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, for example using optimization methods such as gradient descent or stochastic gradient descent on.*\"\n\n\"*Successively, the fitted model is used to predict the responses for the observations in a second dataset called the validation dataset. The validation dataset provides an unbiased evaluation of a model fit on the training dataset while tuning the model's hyperparameters (e.g. the number of hidden units (layers and layer widths) in a neural network.*\"\n\n\"*Finally, the test dataset is a dataset used to provide an unbiased evaluation of a final model fit on the training dataset. If the data in the test dataset has never been used in training (for example in cross-validation), the test dataset is also called a holdout dataset.*\"\n\n\"*The term \"validation set\" is sometimes used instead of \"test set\" in some literature (e.g., if the original dataset was partitioned into only two subsets, the test set might be referred to as the validation set).*\"\n\nIt seems that I am not the only one who has trouble knowing what they are doing regarding train, test and validation datasets. ***How come there is massive confusion when there are exactly three different variables available to create that confusion in the first place?***\n\nBecause the function is called train-test split, it would in my opinion be correct to call the datasets it provides \"training set\" and \"testing set\", and the third and separate dataset - used for validating the model afterwards - would be called \"validation set\". To prove the usefulness of this, next time you visit car dealership, ask for a validation drive.\n\nBut then again, I am just an inexperienced explorer about to be seriously stuck in data ice on imminent basis. It's somehow comforting to know though that others seem to have trouble with these extreme conditions too at least when it comes to defining concepts...\n\nOne has to start the expedition somewhere, so I will next import the module.","metadata":{}},{"cell_type":"code","source":"# import module\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.001407Z","iopub.execute_input":"2021-06-08T10:12:14.001901Z","iopub.status.idle":"2021-06-08T10:12:14.005906Z","shell.execute_reply.started":"2021-06-08T10:12:14.001868Z","shell.execute_reply":"2021-06-08T10:12:14.004739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next I will load the dataset and define predictors as well as the target. **My aim is to see whether the average rainfall readings combined with lake Bilancino water level and flow rate (predictors) can actually predict the lake Arno hydrometry (target).** \n\nAs a layman's guess, there should be no trouble whatsoever since the two waterbodies and their respected average values are indeed interconnected, but we'll see...","metadata":{}},{"cell_type":"code","source":"# load dataset\ndata = df_arno_and_bilancino\n\n# select predictors\npredictors = ['Rainfall_Mean', 'Lake_Level_Mean', 'Flow_Rate_Mean']\nX = data[predictors]\n\n# select target\ny = data.Hydrometry_Mean","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.007307Z","iopub.execute_input":"2021-06-08T10:12:14.00782Z","iopub.status.idle":"2021-06-08T10:12:14.022092Z","shell.execute_reply.started":"2021-06-08T10:12:14.007786Z","shell.execute_reply":"2021-06-08T10:12:14.020492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With a conceptually heavy heart, **I will next call the train-test split function and also call the two datasets as X_train and X_valid. I then separate dataset X_test to be applied later**. 70 percent of overall data goes to training set, whereas 20 percent goes to validation and 10 percent is left for testing.  ","metadata":{}},{"cell_type":"code","source":"# thank you to Jorge Barrios on Stack Overflow for this solution\n\n# link to thread:\n\n#https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn#15136\n\n# Define ratios\nratio_train = 0.7\nratio_val = 0.2\nratio_test = 0.1\n\n# Produce test split\nX_remaining, X_test, y_remaining, y_test = train_test_split(\n    X, y, test_size=ratio_test)\n\n# Adjust val ratio, w.r.t. remaining dataset\nratio_remaining = 1 - ratio_test\nratio_val_adjusted = ratio_val / ratio_remaining\n\n# Produce train and val splits\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_remaining, y_remaining, test_size=ratio_val_adjusted)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.02382Z","iopub.execute_input":"2021-06-08T10:12:14.024556Z","iopub.status.idle":"2021-06-08T10:12:14.03957Z","shell.execute_reply.started":"2021-06-08T10:12:14.024494Z","shell.execute_reply":"2021-06-08T10:12:14.038418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check dataset shape \nX_train.shape,X_valid.shape,X_test.shape,y_train.shape,y_valid.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.041987Z","iopub.execute_input":"2021-06-08T10:12:14.042382Z","iopub.status.idle":"2021-06-08T10:12:14.057929Z","shell.execute_reply.started":"2021-06-08T10:12:14.042348Z","shell.execute_reply":"2021-06-08T10:12:14.05677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, after importing the respected XGBoost (eXtreme Gradient Boosting) module, the very basic parameters for it will be chosen. All choices are based on the article written by **Aarsahy Jain** (link to full article below). I also noted that the article author gives credit to **Sudalai Rajikumar**, a Kaggle member whose excellent and carefully maintained COVID-19 datasets I have previously taken advantage of. \n\nhttps://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n\nAs this is the simplest of model, I will only select three parameters: number of estimators, max_depth and learning rate.  By doing so, I will have no warm thoughts about people who think the {} characters were a really great invention (no keyboard manufacturers seem to share this view).","metadata":{}},{"cell_type":"code","source":"# import module\nfrom xgboost import XGBRegressor\n\n# select and define parameters \nparameters = {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}\n\n# create regressor model with parameters\narno_model = XGBRegressor(**parameters)\n\n# fit model with training data\narno_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.060047Z","iopub.execute_input":"2021-06-08T10:12:14.060811Z","iopub.status.idle":"2021-06-08T10:12:14.122488Z","shell.execute_reply.started":"2021-06-08T10:12:14.060747Z","shell.execute_reply":"2021-06-08T10:12:14.12107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next phase is to try to get some grip on how the simplest of models behaves by evaluating it. Some cut-paste results (links to full Wikipedia articles below):\n\nhttps://en.wikipedia.org/wiki/Mean_squared_error\n\n\"*In statistics, the mean squared error (MSE) ...measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value. MSE is a risk function, corresponding to the expected value of the squared error loss... The MSE is a measure of the quality of an estimator—it is always non-negative, and values closer to zero are better.*\"\n\n\"*RMSE (Root Mean Squared Error) is the error rate by the square root of MSE.*\"\n\nLet's check out these two metrics.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n\ny_pred = arno_model.predict(X_valid)\nmse = mean_squared_error(y_valid, y_pred)\n\nprint(\"MSE: %.2f\" % mse)\nprint(\"RMSE: %.2f\" % (mse**(1/2.0)))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.124505Z","iopub.execute_input":"2021-06-08T10:12:14.124876Z","iopub.status.idle":"2021-06-08T10:12:14.142136Z","shell.execute_reply.started":"2021-06-08T10:12:14.12484Z","shell.execute_reply":"2021-06-08T10:12:14.140509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As I am on an expedition to unknown, I will reload my pipe and check what just happened while printing out the model training score.","metadata":{}},{"cell_type":"code","source":"score = arno_model.score(X_train, y_train)   \n\nprint(\"Training score: \", score) ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.143978Z","iopub.execute_input":"2021-06-08T10:12:14.14444Z","iopub.status.idle":"2021-06-08T10:12:14.161573Z","shell.execute_reply.started":"2021-06-08T10:12:14.144393Z","shell.execute_reply":"2021-06-08T10:12:14.160614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*What?* That's not a proper score, more like election result in North Korea... As I try to get my sled away from the thaw, I at the same time quietly explore ways of evaluating the figure above. Again, with layman's logic I would think that the dataset of average readings on Arno and Bilancino is so \"easy\" that the algorithm fits too well and therefore  \"sinks\" into the data thaw, thus more or less mimicking it in a way that is often referred as \"overfitting\". ***If the model technically becomes one with the training data, applying it to another, unseen dataset (the infamous \"test dataset\") might prove to be disastrous a move... like training for Arctic expedition in a basement fridge...***\n\nI will next try the mean cross-validation score. By doing so, I will hold no warm thoughts about internet, because there is no simple online article telling what sort of score should be considered as \"good\". I mean, if mean cross-validation renders unequivocal results, there should be a unified scale for interpreting the result instead of huge opinion disputes in the Stack Overflow comment section. Otherwise no two models and their validation scores can be compared with each other in any way... \n\nMost of the tutorials end up exactly the same: \"well, here is the validation score result\". *Ok fine, but is it a good or bad result? If the teacher cannot answer that, how are the students expected to do so?* Seriously, I start to think that I am not the only one lost in the data thaw with one's own thoughts... There is no way the tutorial writers all forgot to explain the very same thing. What if they don't really understand it either? *The validation score is dependent on what is predicted? Good, so what is the preferred percentage of deviation?* Without common idea of a preferred score, the outcome is necessarily prone to subjective evaluation and therefore becomes more philosophical than statistical object.\n\nSuddenly I understand all those forum posts much better, they are applying rhetoric to supplement data... But after all, if there is something to be expressed in the first place, it can be expressed in a clear manner. **Ludwig Wittgenstein** said that, or maybe **Dua Lipa**...\n\nSome articles available on validation I found are below as links:\n\nhttps://towardsdatascience.com/cross-validation-explained-evaluating-estimator-performance-e51e5430ff85\n\nhttps://www.dummies.com/programming/big-data/data-science/data-science-cross-validating-in-python/\n\nhttps://vitalflux.com/k-fold-cross-validation-python-example/","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, KFold\n\n# cross validation \nscores = cross_val_score(arno_model,X_train, y_train, cv=5)\n\n# print average accuracy\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.162934Z","iopub.execute_input":"2021-06-08T10:12:14.163452Z","iopub.status.idle":"2021-06-08T10:12:14.368806Z","shell.execute_reply.started":"2021-06-08T10:12:14.163412Z","shell.execute_reply":"2021-06-08T10:12:14.367935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = KFold(n_splits=10, shuffle=True)\nkf_cv_scores = cross_val_score(arno_model, X_train, y_train, cv=kfold)\n\nprint(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.370178Z","iopub.execute_input":"2021-06-08T10:12:14.370676Z","iopub.status.idle":"2021-06-08T10:12:14.77719Z","shell.execute_reply.started":"2021-06-08T10:12:14.370636Z","shell.execute_reply":"2021-06-08T10:12:14.77632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\npipeline = make_pipeline(StandardScaler(), XGBRegressor(n_estimators=100, max_depth=4))\n\nscores = cross_val_score(pipeline, X=X_train, y=y_train, cv=10, n_jobs=1)\n \nprint('Cross Validation accuracy scores: %s' % scores)\nprint('Cross Validation accuracy: %.3f +/- %.3f' % (np.mean(scores),np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:14.778505Z","iopub.execute_input":"2021-06-08T10:12:14.779001Z","iopub.status.idle":"2021-06-08T10:12:15.191254Z","shell.execute_reply.started":"2021-06-08T10:12:14.778945Z","shell.execute_reply":"2021-06-08T10:12:15.190365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To me the results above are somewhat in line with each other, but as I mentioned, I am in the data Arctic equipped with t-shirt and slippers and thus don't know what the ---- I'm doing here except for rapidly turning into an ice statue... \n\nThere was also a piece of code online (I didn' t preserve the exact source, unfortunately) for plotting the results between predictions and original values, so I will throw that in the mix.","metadata":{}},{"cell_type":"code","source":"x_ax = range(len(y_valid))\nplt.scatter(x_ax, y_valid, s=5, color=\"blue\", label=\"original\")\nplt.plot(x_ax, y_pred, lw=0.8, color=\"red\", label=\"predicted\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.192607Z","iopub.execute_input":"2021-06-08T10:12:15.193111Z","iopub.status.idle":"2021-06-08T10:12:15.416342Z","shell.execute_reply.started":"2021-06-08T10:12:15.193073Z","shell.execute_reply":"2021-06-08T10:12:15.415534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check dataset shape \ny_valid.shape,y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.417451Z","iopub.execute_input":"2021-06-08T10:12:15.417855Z","iopub.status.idle":"2021-06-08T10:12:15.42326Z","shell.execute_reply.started":"2021-06-08T10:12:15.417825Z","shell.execute_reply":"2021-06-08T10:12:15.422388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To the best of my knowledge, the cross validation score with standard deviation is about the accuracy of predicted values in the average hydrometry column (target). As printed below, the target column has a range of 1.91 to 2.76 with a mean of 1.45. I have my own idea on whether the score (which obviously changes slightly every time the notebook is run) is good or bad, but I can only repeat my wish of some sort of uniform scale being available.","metadata":{}},{"cell_type":"code","source":"df_arno_and_bilancino['Hydrometry_Mean'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.424502Z","iopub.execute_input":"2021-06-08T10:12:15.42502Z","iopub.status.idle":"2021-06-08T10:12:15.443802Z","shell.execute_reply.started":"2021-06-08T10:12:15.424973Z","shell.execute_reply":"2021-06-08T10:12:15.443015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next I will dig up the humble test dataset created earlier and apply it for the simplest of models.","metadata":{}},{"cell_type":"code","source":"y_pred_two = arno_model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred_two)\n\nprint(\"MSE: %.2f\" % mse)\nprint(\"RMSE: %.2f\" % (mse**(1/2.0)))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.445143Z","iopub.execute_input":"2021-06-08T10:12:15.445592Z","iopub.status.idle":"2021-06-08T10:12:15.46527Z","shell.execute_reply.started":"2021-06-08T10:12:15.445547Z","shell.execute_reply":"2021-06-08T10:12:15.46409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_ax = range(len(y_test))\nplt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\nplt.plot(x_ax, y_pred_two, lw=0.8, color=\"red\", label=\"predicted\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.466856Z","iopub.execute_input":"2021-06-08T10:12:15.467456Z","iopub.status.idle":"2021-06-08T10:12:15.703331Z","shell.execute_reply.started":"2021-06-08T10:12:15.467404Z","shell.execute_reply":"2021-06-08T10:12:15.702092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check dataset shape \ny_test.shape,y_pred_two.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.704913Z","iopub.execute_input":"2021-06-08T10:12:15.705609Z","iopub.status.idle":"2021-06-08T10:12:15.713254Z","shell.execute_reply.started":"2021-06-08T10:12:15.705554Z","shell.execute_reply":"2021-06-08T10:12:15.711925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*So what would happen if the simplest of models actually encountered completely new data?* \n\n*In other words...*\n\n***How does one actually apply a new dataset after the model is all tuned up? What happens if one simply changes the dataset to a new one when making the predictions? Seriously, I looked up 25-30 articles and did not find a clear answer to this. Also, the Kaggle course on intermediate machine learning did not have a word on it...***\n\nThe year 2020 data in the original dataset is something that has so far been unused, so why not try that? \n\n***Just to make it clear, the following most likely does not make any sense at all and - in the spirit of true expedition - the results may prove to be utterly obscure. The moment I learn how to do the process right, I promise I will then act accordingly instead of scribbling an expedition journal while suffering from a serious case of data-induced snowblindness...***\n\nAs the pristine data needs to fit the training data in format, I do some quick housekeeping in my hastily built igloo next.","metadata":{}},{"cell_type":"code","source":"start_date_2020 = '2020-01-01'\nend_date_2020 = '2020-06-30'\nmask_2020_arno = (df_arno['Date'] >= start_date_2020) & (df_arno['Date'] < end_date_2020)\ndf_arno_2020 = df_arno.loc[mask_2020_arno]\npop_hydrometry_2020 = df_arno_2020.pop(\"Hydrometry\")\ndf_arno_2020['Rainfall_Mean'] = df_arno_2020.mean(axis=1)\ndf_arno_2020['Hydrometry_Mean'] = pop_hydrometry_2020\ndf_arno_2020.reset_index(inplace = True) \ncol = ['index', 'Date', 'Le_Croci', 'Cavallina', 'S_Agata', 'Mangona', 'S_Piero']\ndf_arno_2020 = df_arno_2020.drop(col, axis=1)\none_to_365 = pd.Series(range(1,366))\ndf_arno_2020['Day'] = one_to_365\n\nmask_2020_bilancino = (df_bi_copy['Date'] >= start_date_2020) & (df_bi_copy['Date'] < end_date_2020)\ndf_bilancino_2020 = df_bi_copy.loc[mask_2020_bilancino]\npop_date_2020 = df_bilancino_2020.pop(\"Date\")\ndf_bilancino_2020.rename(columns = {'Lake_Level':'Lake_Level_Mean'}, inplace = True) \ndf_bilancino_2020.rename(columns = {'Flow_Rate':'Flow_Rate_Mean'}, inplace = True) \ndf_bilancino_2020.reset_index(inplace = True) \ncol = ['index']\ndf_bilancino_2020 = df_bilancino_2020.drop(col, axis=1)\none_to_365 = pd.Series(range(1,366))\ndf_bilancino_2020['Day'] = one_to_365\n\ndf_Xpedition_test = pd.merge(df_arno_2020, df_bilancino_2020, on='Day')\ndf_Xpedition_test.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.714703Z","iopub.execute_input":"2021-06-08T10:12:15.715018Z","iopub.status.idle":"2021-06-08T10:12:15.760886Z","shell.execute_reply.started":"2021-06-08T10:12:15.714987Z","shell.execute_reply":"2021-06-08T10:12:15.759771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Xpedition_test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.762508Z","iopub.execute_input":"2021-06-08T10:12:15.763148Z","iopub.status.idle":"2021-06-08T10:12:15.774113Z","shell.execute_reply.started":"2021-06-08T10:12:15.7631Z","shell.execute_reply":"2021-06-08T10:12:15.773035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's NaN value, unless we're talking bread it's never favourable...","metadata":{}},{"cell_type":"code","source":"print(df_Xpedition_test[df_Xpedition_test[\"Hydrometry_Mean\"].isnull()])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.775617Z","iopub.execute_input":"2021-06-08T10:12:15.775987Z","iopub.status.idle":"2021-06-08T10:12:15.792157Z","shell.execute_reply.started":"2021-06-08T10:12:15.775927Z","shell.execute_reply":"2021-06-08T10:12:15.791195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Xpedition_test.at[125,'Hydrometry_Mean']=1.0","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.79573Z","iopub.execute_input":"2021-06-08T10:12:15.796128Z","iopub.status.idle":"2021-06-08T10:12:15.804033Z","shell.execute_reply.started":"2021-06-08T10:12:15.796092Z","shell.execute_reply":"2021-06-08T10:12:15.802863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Xpedition_test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.805728Z","iopub.execute_input":"2021-06-08T10:12:15.8061Z","iopub.status.idle":"2021-06-08T10:12:15.821676Z","shell.execute_reply.started":"2021-06-08T10:12:15.806056Z","shell.execute_reply":"2021-06-08T10:12:15.820214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_two = df_Xpedition_test\npredictors = ['Rainfall_Mean', 'Lake_Level_Mean', 'Flow_Rate_Mean']\nX_test = data_two[predictors]\ny_test = data_two.Hydrometry_Mean\ny_pred_two = arno_model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred_two)\n\nprint(\"MSE: %.2f\" % mse)\nprint(\"RMSE: %.2f\" % (mse**(1/2.0)))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.823662Z","iopub.execute_input":"2021-06-08T10:12:15.824133Z","iopub.status.idle":"2021-06-08T10:12:15.841099Z","shell.execute_reply.started":"2021-06-08T10:12:15.824096Z","shell.execute_reply":"2021-06-08T10:12:15.839693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_ax = range(len(y_test))\nplt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\nplt.plot(x_ax, y_pred_two, lw=0.8, color=\"red\", label=\"predicted\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T10:12:15.843012Z","iopub.execute_input":"2021-06-08T10:12:15.843523Z","iopub.status.idle":"2021-06-08T10:12:16.073188Z","shell.execute_reply.started":"2021-06-08T10:12:15.843476Z","shell.execute_reply":"2021-06-08T10:12:16.07226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"End of expedition, time to heal the frostbites and scurvy. I think **Adolf Erik Nordenskiöld** said that, or maybe **Billie Eilish**... ","metadata":{}}]}