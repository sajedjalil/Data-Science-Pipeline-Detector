{"cells":[{"metadata":{"_uuid":"2c3f4869-a18f-478b-9b99-22895267b0ef","_cell_guid":"35c5ed87-d37c-4a7a-9449-cb9cbf7efc0b","trusted":true},"cell_type":"markdown","source":"In this notebook, I will be trying to implement stratified approach with non-square image file. I am new at cross validation approach, so any suggestion would be highly appreciated. \n\nAs many people reported that the image should not be cropped as it reduced the performance of the model, so I decided to try on the original non-square image. I had tried with 128x128 preprocessed cropped image [in this notebook](https://www.kaggle.com/ipythonx/keras-grapheme-gridmask-augmix-ensemble/data#data). And In this notebook, I will be using [Grapheme Image 137x236](https://www.kaggle.com/ipythonx/137x236/settings). \n\nThe competition is about to end soon, And so I'm trying with it just for the learning opportunity. So, it's just a baseline and aim isn't to improve model performance. However, I request any participant who are going with the stratified approach, if you have any suggestion or feedback, please let me know.\n\n---\n\n<html><font size=3 color='red'>If you find this kernel interesting, please leave an UPVOTE. It motivates me to produce more quality content. Thank you.</font></html> ‚ù§"},{"metadata":{},"cell_type":"markdown","source":"Inspiring Notebooks:\n\n - [Keras EfficientNet B3 Training + Inference](https://www.kaggle.com/rsmits/keras-efficientnet-b3-training-inference) \n\n - [resnet34-Inference-by Abhishek Thakur](https://www.kaggle.com/gopidurgaprasad/resnet34-inference-by-abhishek-thakur)\n\n - [iterative stratification](https://www.kaggle.com/yiheng/iterative-stratification)\n "},{"metadata":{"_uuid":"ca2c7280-2415-4dff-94cf-4e0ad517cc81","_cell_guid":"70c1de47-4e48-428e-b4c2-95cc6e864320","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# general packages\nimport warnings\nimport json\nimport os\nfrom PIL import Image\nfrom glob import glob\nfrom zipfile import ZipFile\nimport pandas as pd\nimport numpy as np\n\n#sklearns \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import train_test_split \n\nimport random\nimport cv2\nimport gc\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# keras modules \nfrom keras.optimizers import Adam, Nadam, SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, load_model, Sequential\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, GlobalMaxPooling2D\nfrom keras.layers import (MaxPooling2D, Input, Average, Activation, MaxPool2D,\n                          Flatten, LeakyReLU, BatchNormalization, concatenate)\nfrom keras import models\nfrom keras import layers\nfrom keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras_applications.resnet50 import ResNet50\nfrom keras_applications.resnet_v2 import ResNet50V2\nfrom keras.applications.xception import Xception\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                             EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger)\nfrom sklearn.metrics import accuracy_score, recall_score\nfrom keras.callbacks import Callback\n\n\nfrom keras.utils import Sequence\nfrom keras import utils as np_utils\n# from tensorflow.keras_radam import RAdam\nfrom keras.callbacks import (Callback, ModelCheckpoint,\n                                        LearningRateScheduler,EarlyStopping, \n                                        ReduceLROnPlateau,CSVLogger)\n\nimport albumentations\nfrom PIL import Image, ImageOps, ImageEnhance\nfrom albumentations.core.transforms_interface import ImageOnlyTransform\nfrom albumentations.augmentations import functional as F\nfrom albumentations import (ShiftScaleRotate,IAAAffine,IAAPerspective,\n    RandomRotate90, IAAAdditiveGaussianNoise, GaussNoise\n)\n\nimport tensorflow as tf\nwarnings.simplefilter('ignore')\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95622995-f68a-467a-9195-fe878a052176","_cell_guid":"02ff580a-dd3e-4922-b919-7712064efe6a","trusted":true},"cell_type":"code","source":"SEED = 2020\nbatch_size = 64\nFACTOR = 0.6\nstats = (0.0692, 0.2051)\n\nHEIGHT = 137 \nWIDTH = 236\n\ndim = (int(HEIGHT * FACTOR), int(WIDTH * FACTOR))\nresize_wid = int(WIDTH * FACTOR)\nresize_hit = int(HEIGHT * FACTOR)\n\n\ndef seed_all(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nseed_all(SEED)\n\n# load files\nim_path = '../input/137x236/137x236/'\ntrain = pd.read_csv('/kaggle/input/train-new/fold_trian')\ntest = pd.read_csv('../input/bengaliai-cv19/test.csv')\n\n# top 5 samples\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"689422ec-2647-4a07-969f-34448b092ff9","_cell_guid":"228de286-0b27-4a58-93fd-21d8fb328cf2","trusted":true},"cell_type":"markdown","source":"# Grapheme Generator"},{"metadata":{"_uuid":"bde05fdb-3185-4da4-af2f-fe8aa21fa185","_cell_guid":"3d804dad-1284-4bab-93ed-168ce39ada9d","trusted":true},"cell_type":"code","source":"class GraphemeGenerator(Sequence):\n    def __init__(self, data, batch_size, dim, kfold = (1,), shuffle=False, transform = None):\n        \n        data = data[[\"image_id\", \"grapheme_root\", \"vowel_diacritic\",\n                     \"consonant_diacritic\", \"fold\"]]\n        data = data[data.fold.isin(kfold)].reset_index(drop=True)\n        self._data = data\n        \n        self._label_1 = pd.get_dummies(self._data['grapheme_root'], \n                                       columns = ['grapheme_root'])\n        self._label_2 = pd.get_dummies(self._data['vowel_diacritic'], \n                                       columns = ['vowel_diacritic'])\n        self._label_3 = pd.get_dummies(self._data['consonant_diacritic'], \n                                       columns = ['consonant_diacritic'])\n        self._list_idx = data.index.values\n        self._batch_size = batch_size\n        self._dim = dim\n        self._shuffle = shuffle\n        self._transform = transform\n        self._kfold = kfold\n        self.on_epoch_end()  \n        \n    def __len__(self):\n        return int(np.floor(len(self._data)/self._batch_size))\n    \n    def __getitem__(self, index):\n        batch_idx = self._indices[index*self._batch_size:(index+1)*self._batch_size]\n        _idx = [self._list_idx[k] for k in batch_idx]\n\n        Data     = np.empty((self._batch_size, *self._dim, 1))\n\n        Target_1 = np.empty((self._batch_size, 168), dtype = int)\n        Target_2 = np.empty((self._batch_size,  11), dtype = int)\n        Target_3 = np.empty((self._batch_size,   7), dtype = int)\n        \n        for i, k in enumerate(_idx):\n            image = cv2.imread(im_path + self._data['image_id'][k] + '.png') \n            image = cv2.resize(image, (resize_wid, resize_hit)) \n\n            if len(self._kfold) != 1:\n                if self._transform is not None:\n                    res =  self._transform(image=image)['image']\n                    \n            gray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114]) \n            image = gray(image) \n            \n            image = (image.astype(np.float32)/255.0 - stats[0])/stats[1]\n            image = image[:, :, np.newaxis]\n            Data[i,:, :, :] =  image\n        \n            Target_1[i,:] = self._label_1.loc[k, :].values\n            Target_2[i,:] = self._label_2.loc[k, :].values\n            Target_3[i,:] = self._label_3.loc[k, :].values\n            \n        return Data, [Target_1, Target_2, Target_3]\n    \n    \n    def on_epoch_end(self):\n        self._indices = np.arange(len(self._list_idx))\n        if self._shuffle:\n            np.random.shuffle(self._indices)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8399bd1a-478e-4f70-ab3e-63ce66504e5e","_cell_guid":"c323487b-7bdc-4fd0-bf03-da1719840c7d","trusted":true},"cell_type":"markdown","source":"# Data Augmentation\n\nFor the augmentation part, I'm simply following [XingJian Lyu](https://www.kaggle.com/roguekk007)'s suggestion that he'd mentioned in [Useful Baseline Data Augmentations?](https://www.kaggle.com/c/bengaliai-cv19/discussion/132642), specificly in [here](https://www.kaggle.com/c/bengaliai-cv19/discussion/132642#759415). "},{"metadata":{"_uuid":"11636c98-a4ce-41f7-9a58-75a818ec2f81","_cell_guid":"e26a82b5-0419-4b06-89cb-7bf503a40078","trusted":true},"cell_type":"code","source":"train_transform = albumentations.Compose([\n                albumentations.OneOf([\n                    ShiftScaleRotate(scale_limit=.15, rotate_limit=15, \n                                     border_mode=cv2.BORDER_CONSTANT),\n                    IAAAffine(shear=20, mode='constant'),\n                    IAAPerspective(),\n                ])\n            ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will pass each fold as validation set. Iterate manually."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = GraphemeGenerator(train, batch_size, dim , \n                                    shuffle = True,  \n                                    kfold = (0, 1, 2, 3), \n                                    transform = train_transform)\n\nval_generator = GraphemeGenerator(train, batch_size, dim, kfold = (4,),\n                              shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a40f3402-dcf2-4820-8df7-65bc6c8f0073","_cell_guid":"6e517d03-ad1e-4136-9b89-6eeab3f056c0","trusted":true},"cell_type":"markdown","source":"## Visualize the samples"},{"metadata":{"_uuid":"ed0834ae-6cf8-4b9d-a2c3-0de32e362186","_cell_guid":"73b0baa1-fdd6-45cf-8dd1-cb1f186d9f04","trusted":true},"cell_type":"code","source":"from pylab import rcParams\n\n# helper function to plot sample \ndef plot_imgs(dataset_show):\n    '''\n    code: <plot_imgs> method from - https://www.kaggle.com/haqishen/gridmask\n    '''\n    rcParams['figure.figsize'] = 20,10\n    for i in range(2):\n        f, ax = plt.subplots(1,5)\n        for p in range(5):\n            idx = np.random.randint(0, len(dataset_show))\n            img, label = dataset_show[idx]\n            ax[p].grid(False)\n            ax[p].imshow(img[0][:,:,0], cmap=plt.get_cmap('gray'))\n            ax[p].set_title(idx)\n\nplot_imgs(train_generator) \nplot_imgs(val_generator)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93f3b58d-2e58-4615-88d2-1642332c1c9a","_cell_guid":"09e6cdc0-dbb3-4673-828f-c68b838fd91e","trusted":true},"cell_type":"markdown","source":"# Modeling\n\nI will be using `EfficientNet B0`; simple enough for quick prototyping. And I will initial with the pre-trained  **Noisy Student** weights, as mentioned [here](https://www.kaggle.com/c/bengaliai-cv19/discussion/132894). A public dataset of the all weights can be found from [here](https://www.kaggle.com/ipythonx/efficientnet-keras-noisystudent-weights-b0b7). "},{"metadata":{"_uuid":"5c4726af-03a8-471a-9f0c-d441cfd0c2ad","_cell_guid":"c566cd01-40bf-45b7-b98c-e486a224cc52","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install ../input/efficientnet-keras-source-code/repository/qubvel-efficientnet-c993591","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bb2516e-b014-49ec-8cfc-c4ca961920de","_cell_guid":"2d3e70f0-736f-4ce9-9a7e-12445dab56b7","trusted":true},"cell_type":"code","source":"import efficientnet.keras as efn \n\ndef create_model(input_dim, output_dim, base_model):\n    \n    input_tensor = Input(input_dim)\n    \n    x = Conv2D(3, (3, 3), padding='same',  kernel_initializer='he_uniform', \n               bias_initializer='zeros')(input_tensor)\n    curr_output = base_model(x)\n\n    curr_output = GlobalAveragePooling2D()(curr_output)\n    curr_output = Dense(784, activation='relu')(curr_output)\n    curr_output = Dropout(0.5)(curr_output)\n\n    oputput1 = Dense(168,  activation='softmax', name='gra') (curr_output)\n    oputput2 = Dense(11,  activation='softmax', name='vow') (curr_output)\n    oputput3 = Dense(7,  activation='softmax', name='cons') (curr_output)\n    output_tensor = [oputput1, oputput2, oputput3]\n\n    model = Model(input_tensor, output_tensor)\n    \n    return model\n\nwg = '../input/efficientnet-keras-noisystudent-weights-b0b7/efficientnet-b0_noisy-student_notop.h5'\nefnet = efn.EfficientNetB0(weights=wg,\n                      include_top = False, input_shape=(*dim, 3))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a4d6503-b785-4395-859e-0ed0638344da","_cell_guid":"c35b3c9d-d693-4197-add5-b4ba0391c4e1","trusted":true},"cell_type":"markdown","source":"## Competition Eval Metrics\n\nThe following code cell is bit modified version of the original author and unfortunately I forget to where I found it; so can't give the credit. "},{"metadata":{"_uuid":"bcfb2e23-e6e9-47fa-9a54-763fd15ce784","_cell_guid":"bea4a366-fb7b-42f6-8e49-909ddddcf2fa","trusted":true},"cell_type":"code","source":"def macro_recall(y_true, y_pred):\n    return recall_score(y_true, y_pred, average='macro')\n\nclass CustomCallback(tf.keras.callbacks.Callback):\n    def __init__(self, val_data, batch_size = 32):\n        super().__init__()\n        self.valid_data = val_data\n        self.batch_size = batch_size\n    \n    def on_epoch_begin(self,epoch, logs={}):\n        self.recall_scores = []\n        self.avg_recall = []\n        \n    def on_epoch_end(self, epoch, logs={}):\n        batches = len(self.valid_data)\n        total = batches * self.batch_size\n        self.val_recalls = {0: [], 1:[], 2:[]}\n        \n        for batch in range(batches):\n            xVal, yVal = self.valid_data.__getitem__(batch)\n            val_preds = self.model.predict(xVal)\n            \n            for i in range(3):\n                preds = np.argmax(val_preds[i], axis=1)\n                true = np.argmax(yVal[i], axis=1)\n                self.val_recalls[i].append(macro_recall(true, preds))\n        \n        for i in range(3):\n            self.recall_scores.append(np.average(self.val_recalls[i]))\n\n        avg_result = np.average(self.recall_scores, weights=[2, 1, 1])\n        self.avg_recall.append(avg_result)    \n\n        if avg_result >= max(self.avg_recall):\n            print(\"Avg. Recall Improved. Saving model.\")\n            print(f\"Avg. Recall: {round(avg_result, 4)}\")\n            self.model.save_weights('best_avg_recall.h5')\n        return","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"086395c3-5b82-4671-b50d-18ea1b653792","_cell_guid":"6bd239df-3077-4411-adca-76d87880782e","trusted":true},"cell_type":"code","source":"def Call_Back():\n    # model check point\n    checkpoint = ModelCheckpoint('Fold4.h5', \n                                 monitor = 'val_gra_loss', \n                                 verbose = 0, save_best_only=True, \n                                 mode = 'min',\n                                 save_weights_only = True)\n    \n    csv_logger = CSVLogger('Fold4.csv')\n\n    reduceLROnPlat = ReduceLROnPlateau(monitor='val_gra_loss',\n                                   factor=0.3, patience=3,\n                                   verbose=1, mode='auto',\n                                   epsilon=0.0001, cooldown=1, min_lr=0.000001)\n    \n    custom_callback = CustomCallback(val_generator)\n\n    return [checkpoint, csv_logger, reduceLROnPlat, custom_callback]\n\n\n# epoch size \nepochs = 2\n\n# calling all callbacks \ncallbacks = Call_Back()\n\ntraining = False\n\nif training:\n    # acatual training (fitting)\n    train_history = model.fit_generator(\n        train_generator,\n        steps_per_epoch=batch_size, # batch_size\n        validation_data=val_generator,\n        validation_steps = batch_size,\n        epochs=epochs,\n        callbacks=callbacks\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Loading\nI've train in local machine of all 5 folds. Let's define the models and load the weights."},{"metadata":{"trusted":true},"cell_type":"code","source":"model0 = create_model(input_dim=(*dim, 1), \n                     output_dim=(168,11,7), base_model = efnet)\n\nmodel1 = create_model(input_dim=(*dim, 1), \n                     output_dim=(168,11,7), base_model = efnet)\n\nmodel2 = create_model(input_dim=(*dim, 1), \n                     output_dim=(168,11,7), base_model = efnet)\n\nmodel3 = create_model(input_dim=(*dim, 1), \n                     output_dim=(168,11,7), base_model = efnet)\n\nmodel4 = create_model(input_dim=(*dim, 1), \n                     output_dim=(168,11,7), base_model = efnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model0.load_weights('../input/foldparts/Fold0.h5')\nmodel1.load_weights('../input/foldparts/Fold1.h5')\nmodel2.load_weights('../input/foldparts/Fold2.h5')\nmodel3.load_weights('../input/foldparts/Fold3.h5')\nmodel4.load_weights('../input/foldparts/Fold4.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = (0.0692, 0.2051)\nfrom tqdm import tqdm\n\n# Image Prep\ndef resize_image(img, WIDTH_NEW, HEIGHT_NEW):\n    # Reshape\n    img = img.reshape(HEIGHT, WIDTH)\n    image_resized = cv2.resize(img, (HEIGHT_NEW, WIDTH_NEW),\n                               interpolation = cv2.INTER_AREA)\n\n    return image_resized  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\ndef test_batch_generator(df, batch_size):\n    num_imgs = len(df)\n\n    for batch_start in range(0, num_imgs, batch_size):\n        curr_batch_size = min(num_imgs, batch_start + batch_size) - batch_start\n        idx = np.arange(batch_start, batch_start + curr_batch_size)\n\n        names_batch = df.iloc[idx, 0].values\n        imgs_batch = 255 - df.iloc[idx, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n        X_batch = np.zeros((curr_batch_size, resize_hit, resize_wid, 1))\n        \n        for j in range(curr_batch_size):\n            img = (imgs_batch[j,]*(255.0/imgs_batch[j,].max())).astype(np.uint8)\n            img = resize_image(img, resize_hit, resize_wid)\n            img = (img.astype(np.float32)/255.0 - stats[0])/stats[1]\n            img = img[:, :, np.newaxis]\n            X_batch[j,] = img\n\n        yield X_batch, names_batch\n\n\n# load the parquet files \nTEST = [\n    \"../input/bengaliai-cv19/test_image_data_0.parquet\",\n    \"../input/bengaliai-cv19/test_image_data_1.parquet\",\n    \"../input/bengaliai-cv19/test_image_data_2.parquet\",\n    \"../input/bengaliai-cv19/test_image_data_3.parquet\",\n]\n\n# placeholders \nrow_id = []\ntarget = []\n\n# iterative over the test sets\nfor fname in tqdm(TEST):\n    test_ = pd.read_parquet(fname)\n    test_gen = test_batch_generator(test_, batch_size=batch_size)\n\n    for batch_x, batch_name in test_gen:\n        # prediction\n        batch_predict0 = model0.predict(batch_x, batch_size = 128)\n        batch_predict1 = model1.predict(batch_x, batch_size = 128)\n        batch_predict2 = model2.predict(batch_x, batch_size = 128)\n        batch_predict3 = model3.predict(batch_x, batch_size = 128)\n        batch_predict4 = model4.predict(batch_x, batch_size = 128)\n \n        for idx, name in enumerate(batch_name):\n            row_id += [\n                f\"{name}_consonant_diacritic\",\n                f\"{name}_grapheme_root\",\n                f\"{name}_vowel_diacritic\",\n            ]\n            target += [\n                np.argmax((batch_predict0[2] + batch_predict1[2] + \n                           batch_predict2[2] + batch_predict3[2] + \n                           batch_predict4[2])/5, axis=1)[idx],\n                \n                np.argmax((batch_predict0[0] + batch_predict1[0] + \n                           batch_predict2[0] + batch_predict3[0] + \n                           batch_predict4[0])/5, axis=1)[idx],\n                \n                np.argmax((batch_predict0[1] + batch_predict1[1] + \n                           batch_predict2[1] + batch_predict3[1] + \n                           batch_predict4[1])/5, axis=1)[idx],\n            ]\n\n    del test_\n    gc.collect()\n    \n    \ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\n\ndf_sample.to_csv('submission.csv',index=False)\ngc.collect()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}