{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Learning Starter : Simple LSTM\n\nThis notebook leverages the time series structure of the data.\n\nI expect sequential Deep Learning models to dominate in this competition, so here's a simple LSTM architecture.\n\nParameters were not really tweaked so the baseline is easily improvable.\n\nCode is taken from previous work, some functions are documented but the doc may be outdated.\n\n\n**Don't fork without upvoting ^^**","metadata":{}},{"cell_type":"code","source":"import os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom collections import Counter\n\nwarnings.filterwarnings(\"ignore\")\nNUM_WORKERS = 4","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-23T15:48:46.478452Z","iopub.execute_input":"2021-09-23T15:48:46.478713Z","iopub.status.idle":"2021-09-23T15:48:46.487149Z","shell.execute_reply.started":"2021-09-23T15:48:46.478686Z","shell.execute_reply":"2021-09-23T15:48:46.485315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"markdown","source":"### Load","metadata":{}},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/ventilator-pressure-prediction/\"\n\nsub = pd.read_csv(DATA_PATH + 'sample_submission.csv')\ndf_train = pd.read_csv(DATA_PATH + 'train.csv')\ndf_test = pd.read_csv(DATA_PATH + 'test.csv')\n\n\ndf = df_train[df_train['breath_id'] < 5].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T15:48:46.489559Z","iopub.execute_input":"2021-09-23T15:48:46.489819Z","iopub.status.idle":"2021-09-23T15:48:53.634942Z","shell.execute_reply.started":"2021-09-23T15:48:46.489787Z","shell.execute_reply":"2021-09-23T15:48:53.634211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T15:48:53.636116Z","iopub.execute_input":"2021-09-23T15:48:53.636406Z","iopub.status.idle":"2021-09-23T15:48:53.64783Z","shell.execute_reply.started":"2021-09-23T15:48:53.636373Z","shell.execute_reply":"2021-09-23T15:48:53.647007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Viz","metadata":{}},{"cell_type":"code","source":"def plot_sample(sample_id, df):\n    df_breath = df[df['breath_id'] == sample_id]\n    r, c  = df_breath[['R', 'C']].values[0]\n\n    cols = ['u_in', 'u_out', 'pressure'] if 'pressure' in df.columns else ['u_in', 'u_out']\n    \n    plt.figure(figsize=(12, 4))\n    for col in ['u_in', 'u_out', 'pressure']:\n        plt.plot(df_breath['time_step'], df_breath[col], label=col)\n        \n    plt.legend()\n    plt.title(f'Sample {sample_id} - R={r}, C={c}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-23T15:48:53.649146Z","iopub.execute_input":"2021-09-23T15:48:53.649787Z","iopub.status.idle":"2021-09-23T15:48:53.659721Z","shell.execute_reply.started":"2021-09-23T15:48:53.649751Z","shell.execute_reply":"2021-09-23T15:48:53.658992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df['breath_id'].unique():\n    plot_sample(i, df_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T15:48:53.662555Z","iopub.execute_input":"2021-09-23T15:48:53.662929Z","iopub.status.idle":"2021-09-23T15:48:54.52807Z","shell.execute_reply.started":"2021-09-23T15:48:53.662894Z","shell.execute_reply":"2021-09-23T15:48:54.527229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass VentilatorDataset(Dataset):\n    def __init__(self, df):\n        if \"pressure\" not in df.columns:\n            df['pressure'] = 0\n\n        self.df = df.groupby('breath_id').agg(list).reset_index()\n        \n        self.prepare_data()\n                \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def prepare_data(self):\n        self.pressures = np.array(self.df['pressure'].values.tolist())\n        \n        rs = np.array(self.df['R'].values.tolist())\n        cs = np.array(self.df['C'].values.tolist())\n        u_ins = np.array(self.df['u_in'].values.tolist())\n        \n        self.u_outs = np.array(self.df['u_out'].values.tolist())\n        \n        self.inputs = np.concatenate([\n            rs[:, None], \n            cs[:, None], \n            u_ins[:, None], \n            np.cumsum(u_ins, 1)[:, None],\n            self.u_outs[:, None]\n        ], 1).transpose(0, 2, 1)\n\n    def __getitem__(self, idx):\n        data = {\n            \"input\": torch.tensor(self.inputs[idx], dtype=torch.float),\n            \"u_out\": torch.tensor(self.u_outs[idx], dtype=torch.float),\n            \"p\": torch.tensor(self.pressures[idx], dtype=torch.float),\n        }\n        \n        return data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-23T15:48:54.529171Z","iopub.execute_input":"2021-09-23T15:48:54.529677Z","iopub.status.idle":"2021-09-23T15:48:54.54095Z","shell.execute_reply.started":"2021-09-23T15:48:54.529633Z","shell.execute_reply":"2021-09-23T15:48:54.540153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = VentilatorDataset(df)\ndataset[0]","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-23T15:48:54.542036Z","iopub.execute_input":"2021-09-23T15:48:54.542377Z","iopub.status.idle":"2021-09-23T15:48:54.588499Z","shell.execute_reply.started":"2021-09-23T15:48:54.542342Z","shell.execute_reply":"2021-09-23T15:48:54.587699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model\n- 2 Layer MLP\n- Bidirectional LSTM\n- Prediction dense layer","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass RNNModel(nn.Module):\n    def __init__(\n        self,\n        input_dim=4,\n        lstm_dim=256,\n        dense_dim=256,\n        logit_dim=256,\n        num_classes=1,\n    ):\n        super().__init__()\n\n        self.mlp = nn.Sequential(\n            nn.Linear(input_dim, dense_dim // 2),\n            nn.ReLU(),\n            nn.Linear(dense_dim // 2, dense_dim),\n            nn.ReLU(),\n        )\n\n        self.lstm = nn.LSTM(dense_dim, lstm_dim, batch_first=True, bidirectional=True)\n\n        self.logits = nn.Sequential(\n            nn.Linear(lstm_dim * 2, logit_dim),\n            nn.ReLU(),\n            nn.Linear(logit_dim, num_classes),\n        )\n\n    def forward(self, x):\n        features = self.mlp(x)\n        features, _ = self.lstm(features)\n        pred = self.logits(features)\n        return pred","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-23T15:48:54.589829Z","iopub.execute_input":"2021-09-23T15:48:54.59009Z","iopub.status.idle":"2021-09-23T15:48:54.598299Z","shell.execute_reply.started":"2021-09-23T15:48:54.590057Z","shell.execute_reply":"2021-09-23T15:48:54.597347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"### Utils","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport random\nimport numpy as np\n\n\ndef seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results.\n\n    Args:\n        seed (int): Number of the seed.\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \n    \ndef count_parameters(model, all=False):\n    \"\"\"\n    Counts the parameters of a model.\n\n    Args:\n        model (torch model): Model to count the parameters of.\n        all (bool, optional):  Whether to count not trainable parameters. Defaults to False.\n\n    Returns:\n        int: Number of parameters.\n    \"\"\"\n    if all:\n        return sum(p.numel() for p in model.parameters())\n    else:\n        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n    \ndef worker_init_fn(worker_id):\n    \"\"\"\n    Handles PyTorch x Numpy seeding issues.\n\n    Args:\n        worker_id (int): Id of the worker.\n    \"\"\"\n    np.random.seed(np.random.get_state()[1][0] + worker_id)\n    \n\ndef save_model_weights(model, filename, verbose=1, cp_folder=\"\"):\n    \"\"\"\n    Saves the weights of a PyTorch model.\n\n    Args:\n        model (torch model): Model to save the weights of.\n        filename (str): Name of the checkpoint.\n        verbose (int, optional): Whether to display infos. Defaults to 1.\n        cp_folder (str, optional): Folder to save to. Defaults to \"\".\n    \"\"\"\n    if verbose:\n        print(f\"\\n -> Saving weights to {os.path.join(cp_folder, filename)}\\n\")\n    torch.save(model.state_dict(), os.path.join(cp_folder, filename))","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-09-23T15:48:54.599733Z","iopub.execute_input":"2021-09-23T15:48:54.600002Z","iopub.status.idle":"2021-09-23T15:48:54.612278Z","shell.execute_reply.started":"2021-09-23T15:48:54.599968Z","shell.execute_reply":"2021-09-23T15:48:54.611666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Metric & Loss\n> The competition will be scored as the mean absolute error between the predicted and actual pressures during the inspiratory phase of each breath. The expiratory phase is not scored.","metadata":{}},{"cell_type":"code","source":"def compute_metric(df, preds):\n    \"\"\"\n    Metric for the problem, as I understood it.\n    \"\"\"\n    \n    y = np.array(df['pressure'].values.tolist())\n    w = 1 - np.array(df['u_out'].values.tolist())\n    \n    assert y.shape == preds.shape and w.shape == y.shape, (y.shape, preds.shape, w.shape)\n    \n    mae = w * np.abs(y - preds)\n    mae = mae.sum() / w.sum()\n    \n    return mae\n\n\nclass VentilatorLoss(nn.Module):\n    \"\"\"\n    Directly optimizes the competition metric\n    \"\"\"\n    def __call__(self, preds, y, u_out):\n        w = 1 - u_out\n        mae = w * (y - preds).abs()\n        mae = mae.sum(-1) / w.sum(-1)\n\n        return mae","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-09-23T15:48:54.613671Z","iopub.execute_input":"2021-09-23T15:48:54.613938Z","iopub.status.idle":"2021-09-23T15:48:54.624018Z","shell.execute_reply.started":"2021-09-23T15:48:54.613905Z","shell.execute_reply":"2021-09-23T15:48:54.623311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fit","metadata":{}},{"cell_type":"code","source":"import gc\nimport time\nimport torch\nimport numpy as np\nfrom torch.utils.data import DataLoader\nfrom transformers import get_linear_schedule_with_warmup\n\n\ndef fit(\n    model,\n    train_dataset,\n    val_dataset,\n    loss_name=\"L1Loss\",\n    optimizer=\"Adam\",\n    epochs=50,\n    batch_size=32,\n    val_bs=32,\n    warmup_prop=0.1,\n    lr=1e-3,\n    num_classes=1,\n    verbose=1,\n    first_epoch_eval=0,\n    device=\"cuda\"\n):\n    avg_val_loss = 0.\n\n    # Optimizer\n    optimizer = getattr(torch.optim, optimizer)(model.parameters(), lr=lr)\n\n    # Data loaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=True,\n        worker_init_fn=worker_init_fn\n    )\n\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=val_bs,\n        shuffle=False,\n        num_workers=NUM_WORKERS,\n        pin_memory=True,\n    )\n\n    # Loss\n#     loss_fct = getattr(torch.nn, loss_name)(reduction=\"none\")\n    loss_fct = VentilatorLoss()\n\n    # Scheduler\n    num_warmup_steps = int(warmup_prop * epochs * len(train_loader))\n    num_training_steps = int(epochs * len(train_loader))\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps, num_training_steps\n    )\n\n    for epoch in range(epochs):\n        model.train()\n        model.zero_grad()\n        start_time = time.time()\n\n        avg_loss = 0\n        for data in train_loader:\n            pred = model(data['input'].to(device)).squeeze(-1)\n\n            loss = loss_fct(\n                pred,\n                data['p'].to(device),\n                data['u_out'].to(device),\n            ).mean()\n            loss.backward()\n            avg_loss += loss.item() / len(train_loader)\n\n            optimizer.step()\n            scheduler.step()\n\n            for param in model.parameters():\n                param.grad = None\n\n        model.eval()\n        mae, avg_val_loss = 0, 0\n        preds = []\n\n        with torch.no_grad():\n            for data in val_loader:\n                pred = model(data['input'].to(device)).squeeze(-1)\n\n                loss = loss_fct(\n                    pred.detach(), \n                    data['p'].to(device),\n                    data['u_out'].to(device),\n                ).mean()\n                avg_val_loss += loss.item() / len(val_loader)\n\n                preds.append(pred.detach().cpu().numpy())\n        \n        preds = np.concatenate(preds, 0)\n        mae = compute_metric(val_dataset.df, preds)\n\n        elapsed_time = time.time() - start_time\n        if (epoch + 1) % verbose == 0:\n            elapsed_time = elapsed_time * verbose\n            lr = scheduler.get_last_lr()[0]\n            print(\n                f\"Epoch {epoch + 1:02d}/{epochs:02d} \\t lr={lr:.1e}\\t t={elapsed_time:.0f}s \\t\"\n                f\"loss={avg_loss:.3f}\",\n                end=\"\\t\",\n            )\n\n            if (epoch + 1 >= first_epoch_eval) or (epoch + 1 == epochs):\n                print(f\"val_loss={avg_val_loss:.3f}\\tmae={mae:.3f}\")\n            else:\n                print(\"\")\n\n    del (val_loader, train_loader, loss, data, pred)\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    return preds\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-23T15:48:54.625348Z","iopub.execute_input":"2021-09-23T15:48:54.625727Z","iopub.status.idle":"2021-09-23T15:48:54.644985Z","shell.execute_reply.started":"2021-09-23T15:48:54.625694Z","shell.execute_reply":"2021-09-23T15:48:54.644315Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict","metadata":{}},{"cell_type":"code","source":"def predict(\n    model,\n    dataset,\n    batch_size=64,\n    device=\"cuda\"\n):\n    \"\"\"\n    Usual torch predict function. Supports sigmoid and softmax activations.\n    Args:\n        model (torch model): Model to predict with.\n        dataset (PathologyDataset): Dataset to predict on.\n        batch_size (int, optional): Batch size. Defaults to 64.\n        device (str, optional): Device for torch. Defaults to \"cuda\".\n\n    Returns:\n        numpy array [len(dataset) x num_classes]: Predictions.\n    \"\"\"\n    model.eval()\n\n    loader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\n    )\n    \n    preds = []\n    with torch.no_grad():\n        for data in loader:\n            pred = model(data['input'].to(device)).squeeze(-1)\n            preds.append(pred.detach().cpu().numpy())\n\n    preds = np.concatenate(preds, 0)\n    return preds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-23T15:48:54.646153Z","iopub.execute_input":"2021-09-23T15:48:54.646981Z","iopub.status.idle":"2021-09-23T15:48:54.657297Z","shell.execute_reply.started":"2021-09-23T15:48:54.646942Z","shell.execute_reply":"2021-09-23T15:48:54.656586Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"def train(config, df_train, df_val, df_test, fold):\n    \"\"\"\n    Trains and validate a model.\n\n    Args:\n        config (Config): Parameters.\n        df_train (pandas dataframe): Training metadata.\n        df_val (pandas dataframe): Validation metadata.\n        df_test (pandas dataframe): Test metadata.\n        fold (int): Selected fold.\n\n    Returns:\n        np array: Study validation predictions.\n    \"\"\"\n\n    seed_everything(config.seed)\n\n    model = RNNModel(\n        input_dim=config.input_dim,\n        lstm_dim=config.lstm_dim,\n        dense_dim=config.dense_dim,\n        logit_dim=config.logit_dim,\n        num_classes=config.num_classes,\n    ).to(config.device)\n    model.zero_grad()\n\n    train_dataset = VentilatorDataset(df_train)\n    val_dataset = VentilatorDataset(df_val)\n    test_dataset = VentilatorDataset(df_test)\n\n    n_parameters = count_parameters(model)\n\n    print(f\"    -> {len(train_dataset)} training breathes\")\n    print(f\"    -> {len(val_dataset)} validation breathes\")\n    print(f\"    -> {n_parameters} trainable parameters\\n\")\n\n    pred_val = fit(\n        model,\n        train_dataset,\n        val_dataset,\n        loss_name=config.loss,\n        optimizer=config.optimizer,\n        epochs=config.epochs,\n        batch_size=config.batch_size,\n        val_bs=config.val_bs,\n        lr=config.lr,\n        warmup_prop=config.warmup_prop,\n        verbose=config.verbose,\n        first_epoch_eval=config.first_epoch_eval,\n        device=config.device,\n    )\n    \n    pred_test = predict(\n        model, \n        test_dataset, \n        batch_size=config.val_bs, \n        device=config.device\n    )\n\n    if config.save_weights:\n        save_model_weights(\n            model,\n            f\"{config.selected_model}_{fold}.pt\",\n            cp_folder=\"\",\n        )\n\n    del (model, train_dataset, val_dataset, test_dataset)\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    return pred_val, pred_test","metadata":{"execution":{"iopub.status.busy":"2021-09-23T15:48:54.659093Z","iopub.execute_input":"2021-09-23T15:48:54.659848Z","iopub.status.idle":"2021-09-23T15:48:54.67134Z","shell.execute_reply.started":"2021-09-23T15:48:54.659813Z","shell.execute_reply":"2021-09-23T15:48:54.670658Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### $k$-fold","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\ndef k_fold(config, df, df_test):\n    \"\"\"\n    Performs a patient grouped k-fold cross validation.\n    \"\"\"\n\n    pred_oof = np.zeros(len(df))\n    preds_test = []\n    \n    gkf = GroupKFold(n_splits=config.k)\n    splits = list(gkf.split(X=df, y=df, groups=df[\"breath_id\"]))\n\n    for i, (train_idx, val_idx) in enumerate(splits):\n        if i in config.selected_folds:\n            print(f\"\\n-------------   Fold {i + 1} / {config.k}  -------------\\n\")\n\n            df_train = df.iloc[train_idx].copy().reset_index(drop=True)\n            df_val = df.iloc[val_idx].copy().reset_index(drop=True)\n\n            pred_val, pred_test = train(config, df_train, df_val, df_test, i)\n            \n            pred_oof[val_idx] = pred_val.flatten()\n            preds_test.append(pred_test.flatten())\n\n    print(f'\\n -> CV MAE : {compute_metric(df, pred_oof) :.3f}')\n\n    return pred_oof, np.mean(preds_test, 0)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T15:48:54.673976Z","iopub.execute_input":"2021-09-23T15:48:54.674446Z","iopub.status.idle":"2021-09-23T15:48:54.683986Z","shell.execute_reply.started":"2021-09-23T15:48:54.674412Z","shell.execute_reply":"2021-09-23T15:48:54.683289Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"class Config:\n    \"\"\"\n    Parameters used for training\n    \"\"\"\n    # General\n    seed = 42\n    verbose = 1\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    save_weights = True\n\n    # k-fold\n    k = 5\n    selected_folds = [0, 1, 2, 3, 4]\n    \n    # Model\n    selected_model = 'rnn'\n    input_dim = 5\n\n    dense_dim = 512\n    lstm_dim = 512\n    logit_dim = 512\n    num_classes = 1\n\n    # Training\n    loss = \"L1Loss\"  # not used\n    optimizer = \"Adam\"\n    batch_size = 128\n    epochs = 200\n\n    lr = 1e-3\n    warmup_prop = 0\n\n    val_bs = 256\n    first_epoch_eval = 0","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:01:55.379746Z","iopub.execute_input":"2021-09-23T16:01:55.380006Z","iopub.status.idle":"2021-09-23T16:01:55.388002Z","shell.execute_reply.started":"2021-09-23T16:01:55.379977Z","shell.execute_reply":"2021-09-23T16:01:55.387315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_oof, pred_test = k_fold(\n    Config, \n    df_train,\n    df_test,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:01:55.683082Z","iopub.execute_input":"2021-09-23T16:01:55.683604Z","iopub.status.idle":"2021-09-23T17:16:23.061816Z","shell.execute_reply.started":"2021-09-23T16:01:55.683568Z","shell.execute_reply":"2021-09-23T17:16:23.061066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions","metadata":{}},{"cell_type":"code","source":"def plot_prediction(sample_id, df):\n    df_breath = df[df['breath_id'] == sample_id]\n\n    cols = ['u_in', 'u_out', 'pressure'] if 'pressure' in df.columns else ['u_in', 'u_out']\n    \n    plt.figure(figsize=(12, 4))\n    for col in ['pred', 'pressure', 'u_out']:\n        plt.plot(df_breath['time_step'], df_breath[col], label=col)\n        \n    metric = compute_metric(df_breath, df_breath['pred'])\n        \n    plt.legend()\n    plt.title(f'Sample {sample_id} - MAE={metric:.3f}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-23T17:17:15.738848Z","iopub.execute_input":"2021-09-23T17:17:15.739121Z","iopub.status.idle":"2021-09-23T17:17:15.747186Z","shell.execute_reply.started":"2021-09-23T17:17:15.739091Z","shell.execute_reply":"2021-09-23T17:17:15.744726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"pred\"] = pred_oof","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:17:15.938676Z","iopub.execute_input":"2021-09-23T17:17:15.938871Z","iopub.status.idle":"2021-09-23T17:17:15.95552Z","shell.execute_reply.started":"2021-09-23T17:17:15.938849Z","shell.execute_reply":"2021-09-23T17:17:15.954869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df_train['breath_id'].unique()[:5]:\n    plot_prediction(i, df_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:17:16.185855Z","iopub.execute_input":"2021-09-23T17:17:16.186326Z","iopub.status.idle":"2021-09-23T17:17:17.441182Z","shell.execute_reply.started":"2021-09-23T17:17:16.186296Z","shell.execute_reply":"2021-09-23T17:17:17.44052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sub","metadata":{}},{"cell_type":"code","source":"df_test['pred'] = pred_test\n\nfor i in df_test['breath_id'].unique()[:5]:\n    plot_prediction(i, df_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:17:17.442649Z","iopub.execute_input":"2021-09-23T17:17:17.442984Z","iopub.status.idle":"2021-09-23T17:17:18.576097Z","shell.execute_reply.started":"2021-09-23T17:17:17.442946Z","shell.execute_reply":"2021-09-23T17:17:18.57542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['pressure'] = pred_test\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T17:17:18.577658Z","iopub.execute_input":"2021-09-23T17:17:18.577993Z","iopub.status.idle":"2021-09-23T17:17:29.055813Z","shell.execute_reply.started":"2021-09-23T17:17:18.577955Z","shell.execute_reply":"2021-09-23T17:17:29.055029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Thanks for reading !**","metadata":{}}]}