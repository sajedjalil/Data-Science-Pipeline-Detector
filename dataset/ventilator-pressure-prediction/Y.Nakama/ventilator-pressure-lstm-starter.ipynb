{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook  \n- PyTorch RNN starter code with W&B  \n- Pytorch W&B Usage Examples from https://docs.wandb.ai/guides/integrations/pytorch  \n\nIf this notebook is helpful, feel free to upvote :)","metadata":{}},{"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/google/deluca-lung/main/assets/2020-10-02%20Ventilator%20diagram.svg)","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:40:36.0615Z","iopub.execute_input":"2021-09-23T18:40:36.061935Z","iopub.status.idle":"2021-09-23T18:40:36.153697Z","shell.execute_reply.started":"2021-09-23T18:40:36.061815Z","shell.execute_reply":"2021-09-23T18:40:36.153017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    competition='ventilator'\n    _wandb_kernel='nakama'\n    apex=False\n    print_freq=100\n    num_workers=4\n    model_name='rnn'\n    scheduler='CosineAnnealingLR' # ['linear', 'cosine', 'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    batch_scheduler=False\n    #num_warmup_steps=100 # ['linear', 'cosine']\n    #num_cycles=0.5 # 'cosine'\n    #factor=0.2 # ReduceLROnPlateau\n    #patience=4 # ReduceLROnPlateau\n    #eps=1e-6 # ReduceLROnPlateau\n    T_max=50 # CosineAnnealingLR\n    #T_0=50 # CosineAnnealingWarmRestarts\n    epochs=50\n    max_grad_norm=1000\n    gradient_accumulation_steps=1\n    hidden_size=64\n    lr=5e-3\n    min_lr=1e-6\n    weight_decay=1e-6\n    batch_size=64\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]\n    cate_seq_cols=['R', 'C']\n    cont_seq_cols=['time_step', 'u_in', 'u_out'] + ['breath_time', 'u_in_time']\n    train=True\n    inference=True","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:40:36.15526Z","iopub.execute_input":"2021-09-23T18:40:36.155573Z","iopub.status.idle":"2021-09-23T18:40:36.162296Z","shell.execute_reply.started":"2021-09-23T18:40:36.155539Z","shell.execute_reply":"2021-09-23T18:40:36.161464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport sys\nimport json\nimport time\nimport math\nimport random\nfrom datetime import datetime\nfrom collections import Counter, defaultdict\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\nfrom tqdm.auto import tqdm\nimport category_encoders as ce\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.init as init\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nif CFG.apex:\n    from apex import amp\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:40:36.163566Z","iopub.execute_input":"2021-09-23T18:40:36.163907Z","iopub.status.idle":"2021-09-23T18:40:46.011846Z","shell.execute_reply.started":"2021-09-23T18:40:36.163835Z","shell.execute_reply":"2021-09-23T18:40:46.011054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# wandb\n# ====================================================\nimport wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=secret_value_0)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n\n    \ndef class2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\nrun = wandb.init(project=\"Ventilator-Pressure-Public\", \n                 name=CFG.model_name,\n                 config=class2dict(CFG),\n                 group=CFG.model_name,\n                 job_type=\"train\",\n                 anonymous=anony)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:40:46.014008Z","iopub.execute_input":"2021-09-23T18:40:46.01455Z","iopub.status.idle":"2021-09-23T18:40:54.157119Z","shell.execute_reply.started":"2021-09-23T18:40:46.014511Z","shell.execute_reply":"2021-09-23T18:40:54.156311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_trues, y_preds):\n    score = mean_absolute_error(y_trues, y_preds)\n    return score\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:40:54.161695Z","iopub.execute_input":"2021-09-23T18:40:54.163811Z","iopub.status.idle":"2021-09-23T18:40:54.180923Z","shell.execute_reply.started":"2021-09-23T18:40:54.163769Z","shell.execute_reply":"2021-09-23T18:40:54.180153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsub = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nfor c in ['u_in']:\n    train[c] = np.log1p(train[c])\n    test[c] = np.log1p(test[c])\n    \nr_map = {5: 0, 20: 1, 50: 2}\nc_map = {10: 0, 20: 1, 50: 2}\ntrain['R'] = train['R'].map(r_map)\ntest['R'] = test['R'].map(r_map)\ntrain['C'] = train['C'].map(c_map)\ntest['C'] = test['C'].map(c_map)\n\ndisplay(train.head())\ndisplay(test.head())\ndisplay(sub.head())","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:40:54.186006Z","iopub.execute_input":"2021-09-23T18:40:54.188297Z","iopub.status.idle":"2021-09-23T18:41:08.340886Z","shell.execute_reply.started":"2021-09-23T18:40:54.18826Z","shell.execute_reply":"2021-09-23T18:41:08.340206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# FE\n# ====================================================\ndef add_feature(df):\n    # breath_time\n    df['breath_time'] = df['time_step'] - df['time_step'].shift(1)\n    df.loc[df['time_step'] == 0, 'breath_time'] = 0\n    # u_in_time\n    df['u_in_time'] = df['u_in'] - df['u_in'].shift(1)\n    df.loc[df['time_step'] == 0, 'u_in_time'] = 0\n    return df\n\n\ntrain = add_feature(train)\ntest = add_feature(test)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:41:08.342127Z","iopub.execute_input":"2021-09-23T18:41:08.342407Z","iopub.status.idle":"2021-09-23T18:41:08.712125Z","shell.execute_reply.started":"2021-09-23T18:41:08.342373Z","shell.execute_reply":"2021-09-23T18:41:08.71136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CV split\n# ====================================================\nFold = GroupKFold(n_splits=5)\ngroups = train['breath_id'].values\nfor n, (train_index, val_index) in enumerate(Fold.split(train, train['pressure'], groups)):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\nprint(train.groupby('fold').size())","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:41:08.713306Z","iopub.execute_input":"2021-09-23T18:41:08.713574Z","iopub.status.idle":"2021-09-23T18:41:10.351149Z","shell.execute_reply.started":"2021-09-23T18:41:08.71354Z","shell.execute_reply":"2021-09-23T18:41:10.350413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.groups = df.groupby('breath_id').groups\n        self.keys = list(self.groups.keys())\n        \n    def __len__(self):\n        return len(self.groups)\n\n    def __getitem__(self, idx):\n        indexes = self.groups[self.keys[idx]]\n        df = self.df.iloc[indexes]\n        cate_seq_x = torch.LongTensor(df[CFG.cate_seq_cols].values)\n        cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n        u_out = torch.LongTensor(df['u_out'].values)\n        label = torch.FloatTensor(df['pressure'].values)\n        return cate_seq_x, cont_seq_x, u_out, label\n    \n\nclass TestDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.groups = df.groupby('breath_id').groups\n        self.keys = list(self.groups.keys())\n        \n    def __len__(self):\n        return len(self.groups)\n\n    def __getitem__(self, idx):\n        indexes = self.groups[self.keys[idx]]\n        df = self.df.iloc[indexes]\n        cate_seq_x = torch.LongTensor(df[CFG.cate_seq_cols].values)\n        cont_seq_x = torch.FloatTensor(df[CFG.cont_seq_cols].values)\n        return cate_seq_x, cont_seq_x","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:41:10.352412Z","iopub.execute_input":"2021-09-23T18:41:10.353164Z","iopub.status.idle":"2021-09-23T18:41:10.364615Z","shell.execute_reply.started":"2021-09-23T18:41:10.353125Z","shell.execute_reply":"2021-09-23T18:41:10.363746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.hidden_size = cfg.hidden_size\n        self.r_emb = nn.Embedding(3, 2, padding_idx=0)\n        self.c_emb = nn.Embedding(3, 2, padding_idx=0)\n        self.seq_emb = nn.Sequential(\n            nn.Linear(4 + len(cfg.cont_seq_cols), self.hidden_size),\n            nn.LayerNorm(self.hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n        )\n        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, \n                            dropout=0.2, batch_first=True, bidirectional=True)\n        self.head = nn.Sequential(\n            nn.Linear(self.hidden_size * 2, self.hidden_size * 2),\n            nn.LayerNorm(self.hidden_size * 2),\n            nn.ReLU(),\n            nn.Dropout(0.),\n            nn.Linear(self.hidden_size * 2, 1),\n        )\n        for n, m in self.named_modules():\n            if isinstance(m, nn.LSTM):\n                print(f'init {m}')\n                for param in m.parameters():\n                    if len(param.shape) >= 2:\n                        nn.init.orthogonal_(param.data)\n                    else:\n                        nn.init.normal_(param.data)\n            elif isinstance(m, nn.GRU):\n                print(f\"init {m}\")\n                for param in m.parameters():\n                    if len(param.shape) >= 2:\n                        init.orthogonal_(param.data)\n                    else:\n                        init.normal_(param.data)\n\n    def forward(self, cate_seq_x, cont_seq_x):\n        bs = cont_seq_x.size(0)\n        r_emb = self.r_emb(cate_seq_x[:,:,0]).view(bs, 80, -1)\n        c_emb = self.c_emb(cate_seq_x[:,:,1]).view(bs, 80, -1)\n        seq_x = torch.cat((r_emb, c_emb, cont_seq_x), 2)\n        seq_emb = self.seq_emb(seq_x)\n        seq_emb, _ = self.lstm(seq_emb)\n        output = self.head(seq_emb).view(bs, -1)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:41:10.368536Z","iopub.execute_input":"2021-09-23T18:41:10.369005Z","iopub.status.idle":"2021-09-23T18:41:10.384164Z","shell.execute_reply.started":"2021-09-23T18:41:10.368968Z","shell.execute_reply":"2021-09-23T18:41:10.383472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# helper function\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    model.train()\n    losses = AverageMeter()\n    start = end = time.time()\n    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(train_loader):\n        loss_mask = u_out == 0\n        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n        batch_size = cont_seq_x.size(0)\n        pred = model(cate_seq_x, cont_seq_x)\n        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        if CFG.apex:\n            with amp.scale_loss(loss, optimizer) as scaled_loss:\n                scaled_loss.backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            if CFG.batch_scheduler:\n                scheduler.step()\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  'LR: {lr:.6f}  '\n                  .format(\n                   epoch+1, step, len(train_loader),\n                   remain=timeSince(start, float(step+1)/len(train_loader)),\n                   loss=losses,\n                   grad_norm=grad_norm,\n                   lr=scheduler.get_lr()[0],\n                   ))\n        wandb.log({f\"[fold{fold}] loss\": losses.val,\n                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    model.eval()\n    preds = []\n    losses = AverageMeter()\n    start = end = time.time()\n    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(valid_loader):\n        loss_mask = u_out == 0\n        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n        batch_size = cont_seq_x.size(0)\n        with torch.no_grad():\n            pred = model(cate_seq_x, cont_seq_x)\n        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n        losses.update(loss.item(), batch_size)\n        preds.append(pred.view(-1).detach().cpu().numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(\n                   step, len(valid_loader),\n                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n                   loss=losses,\n                   ))\n    preds = np.concatenate(preds)\n    return losses.avg, preds\n\n\ndef inference_fn(test_loader, model, device):\n    model.eval()\n    model.to(device)\n    preds = []\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    for step, (cate_seq_x, cont_seq_x) in tk0:\n        cate_seq_x, cont_seq_x = cate_seq_x.to(device), cont_seq_x.to(device)\n        with torch.no_grad():\n            pred = model(cate_seq_x, cont_seq_x)\n        preds.append(pred.view(-1).detach().cpu().numpy())\n    preds = np.concatenate(preds)\n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:41:10.385554Z","iopub.execute_input":"2021-09-23T18:41:10.385808Z","iopub.status.idle":"2021-09-23T18:41:10.413201Z","shell.execute_reply.started":"2021-09-23T18:41:10.385776Z","shell.execute_reply":"2021-09-23T18:41:10.41254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# train loop\n# ====================================================\ndef train_loop(folds, fold):\n\n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n    \n    train_folds = train.loc[trn_idx].reset_index(drop=True)\n    valid_folds = train.loc[val_idx].reset_index(drop=True)\n    y_true = valid_folds['pressure'].values\n    non_expiratory_phase_val_idx = valid_folds[valid_folds['u_out'] == 0].index # The expiratory phase is not scored\n\n    train_dataset = TrainDataset(train_folds)\n    valid_dataset = TrainDataset(valid_folds)\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=True,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomModel(CFG)\n    model.to(device)\n\n    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n    \n    def get_scheduler(optimizer):\n        if CFG.scheduler=='linear':\n            scheduler = get_linear_schedule_with_warmup(\n                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps\n            )\n        elif CFG.scheduler=='cosine':\n            scheduler = get_cosine_schedule_with_warmup(\n                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=CFG.num_cycles\n            )\n        elif CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n        return scheduler\n\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # apex\n    # ====================================================\n    if CFG.apex:\n        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = nn.L1Loss()\n\n    best_score = np.inf\n\n    for epoch in range(CFG.epochs):\n\n        start_time = time.time()\n\n        # train\n        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score = get_score(y_true[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - MAE Score (without expiratory phase): {score:.4f}')\n        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n                   f\"[fold{fold}] score\": score})\n        \n        if score < best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {score:.4f} Model')\n            torch.save({'model': model.state_dict(),\n                        'preds': preds},\n                        OUTPUT_DIR+f\"fold{fold}_best.pth\")\n            \n    preds = torch.load(OUTPUT_DIR+f\"fold{fold}_best.pth\", map_location=torch.device('cpu'))['preds']\n    valid_folds['preds'] = preds\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return valid_folds","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:41:10.41462Z","iopub.execute_input":"2021-09-23T18:41:10.414915Z","iopub.status.idle":"2021-09-23T18:41:10.442589Z","shell.execute_reply.started":"2021-09-23T18:41:10.414882Z","shell.execute_reply":"2021-09-23T18:41:10.44178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# main\n# ====================================================\ndef main():\n    \n    \"\"\"\n    Prepare: 1.train 2.test\n    \"\"\"\n    \n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df['pressure'].values\n        non_expiratory_phase_val_idx = result_df[result_df['u_out'] == 0].index # The expiratory phase is not scored\n        score = get_score(labels[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n        LOGGER.info(f'Score (without expiratory phase): {score:<.4f}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(train, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n    \n    if CFG.inference:\n        test_dataset = TestDataset(test)\n        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size * 2, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n        for fold in CFG.trn_fold:\n            model = CustomModel(CFG)\n            path = OUTPUT_DIR+f\"fold{fold}_best.pth\"\n            state = torch.load(path, map_location=torch.device('cpu'))\n            model.load_state_dict(state['model'])\n            predictions = inference_fn(test_loader, model, device)\n            test[f'fold{fold}'] = predictions\n            del state, predictions; gc.collect()\n            torch.cuda.empty_cache()\n        # submission\n        test['pressure'] = test[[f'fold{fold}' for fold in range(CFG.n_fold)]].mean(1)\n        test[['id', 'pressure']+[f'fold{fold}' for fold in range(CFG.n_fold)]].to_csv(OUTPUT_DIR+'raw_submission.csv', index=False)\n        test[['id', 'pressure']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n    \n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:41:10.444063Z","iopub.execute_input":"2021-09-23T18:41:10.444336Z","iopub.status.idle":"2021-09-23T18:41:10.462199Z","shell.execute_reply.started":"2021-09-23T18:41:10.444303Z","shell.execute_reply":"2021-09-23T18:41:10.461306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T18:41:10.463743Z","iopub.execute_input":"2021-09-23T18:41:10.464204Z","iopub.status.idle":"2021-09-23T18:43:52.019744Z","shell.execute_reply.started":"2021-09-23T18:41:10.464167Z","shell.execute_reply":"2021-09-23T18:43:52.017762Z"},"trusted":true},"execution_count":null,"outputs":[]}]}