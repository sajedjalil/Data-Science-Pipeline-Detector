{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport os \nimport time \nimport json \nimport requests \nfrom tqdm import tqdm \nimport wandb \nfrom wandb.keras import WandbCallback \nfrom kaggle_secrets import UserSecretsClient \nimport random \nfrom typing import Tuple \nimport gc \n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import RobustScaler \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import LSTM, Input, Bidirectional, Dense \nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.callbacks import Callback\nimport tensorflow.keras.backend as K\n\n\ndef seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything()\npd.set_option(\"display.max_columns\", None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-08T06:00:48.416083Z","iopub.execute_input":"2021-10-08T06:00:48.416633Z","iopub.status.idle":"2021-10-08T06:00:55.556917Z","shell.execute_reply.started":"2021-10-08T06:00:48.416547Z","shell.execute_reply":"2021-10-08T06:00:55.555985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = dict(\n    competition = \"ventilator\", \n    infra = \"kaggle\", \n    train = True, \n    type = \"train\", \n    debug = False, \n    inference = True, \n    \n    model_name = \"lstm\", \n    frame_word = \"tensorflow\", \n    device = \"tpu\", \n    n_fold = 5, \n    early_stopping_rounds = 30, \n    batch_size = 1024, \n    epoch = 299, \n    verbose = 100, \n    seed = 42 \n)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:00:55.559007Z","iopub.execute_input":"2021-10-08T06:00:55.559338Z","iopub.status.idle":"2021-10-08T06:00:55.565508Z","shell.execute_reply.started":"2021-10-08T06:00:55.559305Z","shell.execute_reply":"2021-10-08T06:00:55.564651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nurl = user_secrets.get_secret(\"WEB_HOOK_URL\") \n\nuser_secrets = UserSecretsClient()\napi = user_secrets.get_secret(\"wandb_api\")\n\nwandb.login(key=api)\n\nrun = wandb.init(\n    project = config[\"competition\"], \n    name = config[\"model_name\"], \n    config = config, \n    group = config[\"model_name\"], \n    job_type = config[\"type\"]\n)\n\ndef slack(txt):\n    requests.post(url, data=json.dumps({\n        \"username\": \"kaggle\", \n        \"text\": txt \n    }))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-08T06:00:55.566878Z","iopub.execute_input":"2021-10-08T06:00:55.567194Z","iopub.status.idle":"2021-10-08T06:01:03.011075Z","shell.execute_reply.started":"2021-10-08T06:00:55.567151Z","shell.execute_reply":"2021-10-08T06:01:03.010181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config[\"debug\"]:\n    train = pd.read_csv(\"../input/ventilator-pressure-prediction/train.csv\", nrows=80*100)\n    test = pd.read_csv(\"../input/ventilator-pressure-prediction/test.csv\", nrows=80*100)\nelse:\n    train = pd.read_csv(\"../input/ventilator-pressure-prediction/train.csv\")\n    test = pd.read_csv(\"../input/ventilator-pressure-prediction/test.csv\")\n\nsort = np.sort(train.pressure.unique())\nPRESSURE_MIN = sort[0]\nPRESSURE_MAX = sort[-1]\nPRESSURE_STEP = sort[1] - sort[0]","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:01:03.012507Z","iopub.execute_input":"2021-10-08T06:01:03.01275Z","iopub.status.idle":"2021-10-08T06:01:19.590014Z","shell.execute_reply.started":"2021-10-08T06:01:03.012716Z","shell.execute_reply":"2021-10-08T06:01:19.589137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(train_data):\n    start_mem = train_data.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    for col in train_data.columns:\n        col_type = train_data[col].dtype\n\n        if col_type != object:\n            c_min = train_data[col].min()\n            c_max = train_data[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    train_data[col] = train_data[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    train_data[col] = train_data[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    train_data[col] = train_data[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    train_data[col] = train_data[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    train_data[col] = train_data[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    train_data[col] = train_data[col].astype(np.float32)\n                else:\n                    train_data[col] = train_data[col].astype(np.float64)\n        else:\n            train_data[col] = train_data[col].astype('category')\n\n    end_mem = train_data.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return train_data","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:01:19.592301Z","iopub.execute_input":"2021-10-08T06:01:19.592537Z","iopub.status.idle":"2021-10-08T06:01:19.610069Z","shell.execute_reply.started":"2021-10-08T06:01:19.592509Z","shell.execute_reply":"2021-10-08T06:01:19.609226Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:01:19.611556Z","iopub.execute_input":"2021-10-08T06:01:19.611811Z","iopub.status.idle":"2021-10-08T06:01:20.47398Z","shell.execute_reply.started":"2021-10-08T06:01:19.611777Z","shell.execute_reply":"2021-10-08T06:01:20.473191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lag_feature(df) -> pd.DataFrame:\n    df[\"area\"] = df.time_step * df.u_in \n    df[\"area\"] = df.groupby(\"breath_id\")[\"area\"].cumsum()\n    \n    df[\"u_in_cumsum\"] = df.groupby(\"breath_id\")[\"u_in\"].cumsum()\n    \n    for i in range(4):\n        df[\"u_in_\"+f\"lag{i+1}\"] = df.groupby(\"breath_id\")[\"u_in\"].shift(i+1).fillna(0)\n        df[\"u_out_\"+f\"lag{i+1}\"] = df.groupby(\"breath_id\")[\"u_out\"].shift(i+1).fillna(0)\n\n        df[\"u_in_\"+f\"back{i+1}\"] = df.groupby(\"breath_id\")[\"u_in\"].shift((-1)*(i+1)).fillna(0)\n        df[\"u_out_\"+f\"back{i+1}\"] = df.groupby(\"breath_id\")[\"u_out\"].shift((-1)*(i+1)).fillna(0)\n\n    df[\"u_out_rolling_10\"] = df.groupby(\"breath_id\")[\"u_out\"].rolling(window=10).mean().reset_index(drop=True).fillna(0)\n    df[\"u_in_rolling_10\"] = df.groupby(\"breath_id\")[\"u_in\"].rolling(window=10).mean().reset_index(drop=True).fillna(0)\n    \n    df[\"u_in_max\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"max\")\n    df[\"u_in_min\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"min\")\n    df[\"u_in_mean\"] = df.groupby(\"breath_id\")[\"u_in\"].transform(\"mean\")\n    df[\"u_out_max\"] = df.groupby(\"breath_id\")[\"u_out\"].transform(\"max\")\n    df[\"u_out_min\"] = df.groupby(\"breath_id\")[\"u_out\"].transform(\"min\")\n    df[\"u_out_mean\"] = df.groupby(\"breath_id\")[\"u_out\"].transform(\"mean\")\n    \n    for i in range(4):\n        df[\"u_in\"+f\"_diff{i+1}\"] = df[\"u_in\"] - df[f\"u_in_lag{i+1}\"]\n        df[\"u_in\"+f\"_diff_back{i+1}\"] = df[\"u_in\"] - df[f\"u_in_back{i+1}\"]\n\n        df[\"u_out\"+f\"_diff{i+1}\"] = df[\"u_out\"] - df[f\"u_out_lag{i+1}\"]\n        df[\"u_out\"+f\"_diff_back{i+1}\"] = df[\"u_out\"] - df[f\"u_out_back{i+1}\"]\n\n    df[\"u_in_diff_max\"] = df[\"u_in_max\"] - df[\"u_in\"]\n    df[\"u_in_diff_min\"] = df[\"u_in_min\"] - df[\"u_in\"]\n    df[\"u_in_diff_mean\"] = df[\"u_in_mean\"] - df[\"u_in\"]\n    \n    df[\"cross\"] = df[\"u_in\"] * df[\"u_out\"]\n    df[\"cross2\"] = df[\"time_step\"] * df[\"u_out\"]\n    \n    df[\"time_class\"] = df.groupby(\"breath_id\").cumcount()\n    df[\"R\"] = df.R.astype(str)\n    df[\"C\"] = df.C.astype(str)\n    df[\"R_C\"] = df.R + \"_\" + df.C \n    gc.collect()\n    return df\n\ndef group_feature(train, test) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    # time_class x u_in\n    time_grp = train.groupby(\"time_class\").mean().loc[:, [\"u_in\"]]\n    time_grp = time_grp.rename(columns={\"u_in\": \"u_in_time_class\"})\n    train = pd.merge(train, time_grp, how=\"left\", left_on=\"time_class\", right_index=True)\n    test = pd.merge(test, time_grp, how=\"left\", left_on=\"time_class\", right_index=True)\n    del time_grp \n    gc.collect()\n    \n    print(1)\n    \n    # R x u_in \n    r = train.groupby(\"R\").mean().loc[:, [\"u_in\"]]\n    r = r.rename(columns={\"u_in\": \"u_in_r_mean\"})\n    train = pd.merge(train, r, how=\"left\", left_on=\"R\", right_index=True)\n    test = pd.merge(test, r, how=\"left\", left_on=\"R\", right_index=True)\n    del r \n    gc.collect()\n\n    \n    # c x u_in \n    c = train.groupby(\"C\").mean().loc[:, [\"u_in\"]]\n    c = c.rename(columns={\"u_in\": \"u_in_c_mean\"})\n    train = pd.merge(train, c, how=\"left\", left_on=\"C\", right_index=True)\n    test = pd.merge(test, c, how=\"left\", left_on=\"C\", right_index=True)\n    del c \n    gc.collect()\n    \n    print(2)\n\n    # r_c x u_in \n    rc = train.groupby(\"R_C\").mean().loc[:, [\"u_in\"]]\n    rc = rc.rename(columns={\"u_in\": \"u_in_rc_mean\"})\n    train = pd.merge(train, rc, how=\"left\", left_on=\"R_C\", right_index=True)\n    test = pd.merge(test, rc, how=\"left\", left_on=\"R_C\", right_index=True)\n    del rc \n    gc.collect()\n    \n    print(3)\n\n    # r_c, time_class x u_in \n    rc = train.groupby([\"R_C\", \"time_class\"]).mean().loc[:, [\"u_in\"]]\n    rc = rc.rename(columns={\"u_in\": \"u_in_rc_time_mean\"})\n    train = pd.merge(train, rc, how=\"left\", left_on=[\"R_C\", \"time_class\"], right_index=True)\n    test = pd.merge(test, rc, how=\"left\", left_on=[\"R_C\", \"time_class\"], right_index=True)\n    del rc \n    gc.collect()\n    \n    print(4)\n\n    \n    # get dummmies object\n    last_train_shape = train.shape[0]\n    y = train.pressure.values.ravel()\n    df = pd.concat([train.drop(\"pressure\", axis=1), test])\n    df = pd.get_dummies(data=df, columns=[\"R\", \"C\", \"R_C\"])\n    train, test = df.iloc[:last_train_shape, :], df.iloc[last_train_shape:, :]\n    del df \n    train[\"pressure\"] = y \n    del y \n    gc.collect()\n    return train, test ","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:01:20.476224Z","iopub.execute_input":"2021-10-08T06:01:20.476551Z","iopub.status.idle":"2021-10-08T06:01:20.511323Z","shell.execute_reply.started":"2021-10-08T06:01:20.476511Z","shell.execute_reply":"2021-10-08T06:01:20.510515Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\ntrain = lag_feature(train)\ntest = lag_feature(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:01:20.512505Z","iopub.execute_input":"2021-10-08T06:01:20.512726Z","iopub.status.idle":"2021-10-08T06:02:32.878535Z","shell.execute_reply.started":"2021-10-08T06:01:20.5127Z","shell.execute_reply":"2021-10-08T06:02:32.877771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\ntrain, test = group_feature(train, test)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:02:32.879858Z","iopub.execute_input":"2021-10-08T06:02:32.880085Z","iopub.status.idle":"2021-10-08T06:03:41.301788Z","shell.execute_reply.started":"2021-10-08T06:02:32.88006Z","shell.execute_reply":"2021-10-08T06:03:41.300794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model ","metadata":{}},{"cell_type":"code","source":"@tf.custom_gradient\ndef round_with_gradients(x):\n    def grad(dy):\n        return dy\n    return tf.round(x), grad\n\nclass ScaleLayer(tf.keras.layers.Layer):\n    def __init__(self):\n        super(ScaleLayer, self).__init__()\n        self.min = tf.constant(PRESSURE_MIN, dtype=np.float32)\n        self.max = tf.constant(PRESSURE_MAX, dtype=np.float32)\n        self.step = tf.constant(PRESSURE_STEP, dtype=np.float32)\n\n    def call(self, inputs):\n        steps = tf.math.divide(tf.math.add(inputs, -self.min), self.step)\n        int_steps = round_with_gradients(steps)\n        rescaled_steps = tf.math.add(tf.math.multiply(int_steps, self.step), self.min)\n        clipped = tf.clip_by_value(rescaled_steps, self.min, self.max)\n        return clipped\n    \ndef build_model(input_shape):\n    model = Sequential()\n    model.add(Input(shape=input_shape))\n    for hidden in [1024, 512, 256, 128]:\n        model.add(Bidirectional(LSTM(hidden ,return_sequences=True)))\n    model.add(Dense(128, activation=\"selu\"))\n    model.add(Dense(1))\n    model.add(ScaleLayer())\n    model.compile(optimizer=\"adam\", loss=\"mae\")\n    return model \n\nmodel = build_model((80, train.shape[-1]))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:03:41.303198Z","iopub.execute_input":"2021-10-08T06:03:41.303425Z","iopub.status.idle":"2021-10-08T06:03:46.632145Z","shell.execute_reply.started":"2021-10-08T06:03:41.303399Z","shell.execute_reply":"2021-10-08T06:03:46.631234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train ","metadata":{}},{"cell_type":"code","source":"if config[\"debug\"] is not True and config[\"device\"] == \"tpu\":\n    # detect and init the TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n    # instantiate a distribution strategy\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n\ndef scaler(tr, va, te):\n    RS = RobustScaler()\n    return RS.fit_transform(tr), RS.transform(va), RS.transform(te)\n\n\ndef mae(pred, corr):\n    return np.mean(np.abs(pred - corr))\n\n\ndef submit(pred, name):\n    sub = pd.read_csv(\"../input/ventilator-pressure-prediction/sample_submission.csv\")\n    sub[\"pressure\"] = pred \n    sub.to_csv(f\"submission_lstm_{name}.csv\", index=False)\n    del sub \n    \n    \ndef callbacks_tools(fold) -> Tuple[object, object, object]:\n    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n    es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, \n                           mode=\"min\", restore_best_weights=True)\n    os.makedirs(\"models\", exist_ok=True)\n    checkpoint_filepath = f\"models/{fold}.hdf5\"\n    sv = keras.callbacks.ModelCheckpoint(\n            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n            save_weights_only=False, mode='auto', save_freq='epoch',\n            options=None\n    )\n    wb = WandbCallback(log_weights=True)\n    return lr, es, sv, wb \n\n\ndef viz_predict(corr, pred):\n    plt.figure(figsize=(15, 6))\n    \n    plt.subplot(121)\n    sns.histplot(corr)\n    plt.title(\"Label\")\n    \n    plt.subplot(122)\n    sns.histplot(pred)\n    plt.title(\"Predict\")\n    \n    plt.show()\n    \ndef train_nn(train, test):\n    with tpu_strategy.scope():\n        k = keras.backend\n        \n        predict_val, val_idx, predict_test = [], [], []\n        kf = GroupKFold(config[\"n_fold\"])\n\n        for fold, (tr, va) in enumerate(kf.split(train, train.pressure, train.breath_id)):\n            print(f\"=====================fold: {fold+1}=========================\")\n            x_train, x_val = train.iloc[tr].drop([\"id\", \"breath_id\", \"pressure\"], axis=1), train.iloc[va].drop([\"id\", \"breath_id\", \"pressure\"], axis=1)\n            y_train, y_val = train.iloc[tr][\"pressure\"], train.iloc[va][\"pressure\"]\n            use_col = x_train.columns \n            x_test = test[use_col]\n\n            # transform shape \n            x_train, x_val, x_test = scaler(x_train, x_val, x_test)\n            x_train = x_train.reshape(-1, 80, len(use_col))\n            x_val = x_val.reshape(-1, 80, len(use_col))\n            x_test = x_test.reshape(-1, 80, len(use_col))\n            y_train = y_train.values.reshape(-1, 80, 1)\n            y_val = y_val.values.reshape(-1, 80, 1)\n\n            # setup models\n            model = build_model((80, len(use_col)))\n            lr, es, sv, wb = callbacks_tools(fold+1)\n\n            # training step \n            model.fit(x_train, \n                     y_train, \n                     validation_data=(x_val, y_val), \n                      callbacks=[lr, es, sv, wb], \n                      epochs= 1 if config[\"debug\"] else config[\"epoch\"],\n                      batch_size=config[\"batch_size\"])\n\n            # prediction val test \n            pred_v = model.predict(x_val, batch_size=config[\"batch_size\"], verbose=config[\"verbose\"]).squeeze().reshape(-1, 1).squeeze()\n            pred_t = model.predict(x_test, batch_size=config[\"batch_size\"], verbose=config[\"verbose\"]).squeeze().reshape(-1, 1).squeeze()\n            predict_val.append(pred_v)\n            predict_test.append(pred_t)\n            val_idx.append(va)\n\n            print(f\"fold: {fold+1} | MAE: {mae(pred_v, y_val.squeeze().reshape(-1, 1).squeeze())}\")\n\n            del x_train, x_val, x_test, model\n\n        # concat prediction \n        predict_val = np.concatenate(predict_val)\n        val_idx = np.concatenate(val_idx)\n        val_idx = np.argsort(val_idx)\n        predict_val = predict_val[val_idx]\n        del val_idx\n\n        # finally cv score \n        print(\"#############################################################\")\n        print(f\"LSTM CV: {mae(predict_val, train.pressure.values.ravel())}\")\n        print(\"#############################################################\")\n\n        # predict test transform\n        predict_mean = np.mean(predict_test, 0)\n        predict_median = np.median(predict_test, 0)\n        #### \n        predict_mean_clip = (np.round(predict_mean - PRESSURE_MIN)/PRESSURE_STEP) * PRESSURE_STEP + PRESSURE_MIN\n        predict_mean_clip = np.clip(predict_mean_clip, PRESSURE_MIN, PRESSURE_MAX)\n\n        predict_median_clip = (np.round(predict_median - PRESSURE_MIN)/PRESSURE_STEP) * PRESSURE_STEP + PRESSURE_MIN\n        predict_median_clip = np.clip(predict_median_clip, PRESSURE_MIN, PRESSURE_MAX)\n        ### \n\n        # submit \n        if config[\"debug\"] is not True:\n            submit(predict_mean, \"mean\")\n            submit(predict_median, \"median\")\n            submit(predict_mean_clip, \"mean_clip\")\n            submit(predict_median_clip, \"median_clip\")\n\n        gc.collect()\n        slack(\"lstm done.\")\n        return predict_val \n","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:06:20.71032Z","iopub.execute_input":"2021-10-08T06:06:20.710666Z","iopub.status.idle":"2021-10-08T06:06:26.567021Z","shell.execute_reply.started":"2021-10-08T06:06:20.71063Z","shell.execute_reply":"2021-10-08T06:06:26.566226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_v = train_nn(train, test)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T06:06:26.568688Z","iopub.execute_input":"2021-10-08T06:06:26.569491Z","iopub.status.idle":"2021-10-08T08:28:56.774088Z","shell.execute_reply.started":"2021-10-08T06:06:26.569455Z","shell.execute_reply":"2021-10-08T08:28:56.772257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz_predict(train.pressure.values.ravel(), pred_v)","metadata":{"execution":{"iopub.status.busy":"2021-10-08T08:32:46.519972Z","iopub.execute_input":"2021-10-08T08:32:46.520312Z","iopub.status.idle":"2021-10-08T08:33:00.136172Z","shell.execute_reply.started":"2021-10-08T08:32:46.520268Z","shell.execute_reply":"2021-10-08T08:33:00.133721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}