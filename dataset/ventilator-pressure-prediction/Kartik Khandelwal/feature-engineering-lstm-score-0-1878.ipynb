{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/google/deluca-lung/main/assets/2020-10-02%20Ventilator%20diagram.svg)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom sklearn.metrics import mean_absolute_error as mae","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TPU","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As previous versions failed because of my notebook tried to allocate more memory than is available.\n> This function helps in reducing memory usage by changing unnecessary data type.\n\n> You could learn more about it [here](https://www.kaggle.com/questions-and-answers/282144)","metadata":{}},{"cell_type":"code","source":"def reduce_memory_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))    \n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom Activation Function","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ndata = reduce_memory_usage(data)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Columns\n**id** - globally-unique time step identifier across an entire file\n\n**breath_id** - globally-unique time step for breaths\n\n**R** - lung attribute indicating how restricted the airway is (in cmH2O/L/S). Physically, this is the change in pressure per change in flow (air volume per time). Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n\n**C** - lung attribute indicating how compliant the lung is (in mL/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloonâ€™s latex, with higher C having thinner latex and easier to blow.\ntime_step - the actual time stamp.\n\n**u_in** - the control input for the inspiratory solenoid valve. Ranges from 0 to 100.\n\n**u_out** - the control input for the exploratory solenoid valve. Either 0 or 1.\n\n**pressure** - the airway pressure measured in the respiratory circuit, measured in cmH2O.","metadata":{}},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> There is no null value","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.heatmap(data.corr(), cmap='cool')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see a strong correaltion between :\n> 'pressure' and 'time_step'\n\n> 'pressure' and 'u_out'","metadata":{}},{"cell_type":"markdown","source":"## Splitting of categorical and numerical data.","metadata":{}},{"cell_type":"markdown","source":"![](https://bookdown.org/ejvanholm/Text-Quant/images/DataTypes.png)","metadata":{}},{"cell_type":"code","source":"cat_col = []\nnum_col = []\nfor i in data.columns:\n    if data[i].value_counts().count() > 10:\n        num_col.append(i)\n    else:\n        cat_col.append(i)\nprint(f'categorical columns: {cat_col}')\nprint(f'numerical columns: {num_col}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Categorical Data","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3,figsize=(12,5))\nj=0\nfor i in cat_col:\n    sns.countplot(data[i], palette='cool', ax=ax[j])\n    j+=1\nfig.suptitle('Countplot of Categorical Data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Numerical Data","metadata":{}},{"cell_type":"markdown","source":"Removing 'id' and 'breath_id' from numerical column list.","metadata":{}},{"cell_type":"code","source":"num_col = num_col[2:]\nnum_col","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(18,5))\nj=0\nfor i in num_col:\n    sns.histplot(data[i], ax=ax[j])\n    j+=1\nfig.suptitle('Histplot of Numerical Data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> I can see a skewness in 'pressure', which is our target variable.\n\n> And, a great outliers in 'u_in' and 'pressure'.","metadata":{}},{"cell_type":"markdown","source":"## Outliers\n> Let us have a look at outliers now, by using boxplot.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(18,5))\nj=0\nfor i in num_col:\n    sns.boxplot(data[i], ax=ax[j], palette='cool')\n    j+=1\nfig.suptitle('Boxplot of Numerical Data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> It is always good practice to work with copied dataset. âœ“âœ“","metadata":{}},{"cell_type":"code","source":"train = data.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Removing Skewness of target variable.\n#### Methods tried :-\n1. Log Transformation\n2. Log + 1 Transformation\n3. Square Root\n4. Double Square Root --> This works best.","metadata":{}},{"cell_type":"code","source":"# fig, ax = plt.subplots(1,2, figsize=(12,5))\n# sns.distplot(train['pressure'], ax=ax[0])\n\n# train['pressure'] = np.where(train['pressure'] < 0, 0, train['pressure'])\n# train['pressure'] = np.sqrt(np.sqrt(train['pressure']))\n\n# sns.distplot(train['pressure'], ax=ax[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating New Features","metadata":{}},{"cell_type":"code","source":"def create_new_feat(df):\n    df[\"u_in_sum\"]         = df.groupby(\"breath_id\")[\"u_in\"].transform(\"sum\")\n    df[\"u_in_std\"]         = df.groupby(\"breath_id\")[\"u_in\"].transform(\"std\")\n    df[\"u_in_min\"]         = df.groupby(\"breath_id\")[\"u_in\"].transform(\"min\")\n    df[\"u_in_first\"]       = df.groupby(\"breath_id\")[\"u_in\"].transform(\"first\")\n    df[\"u_in_last\"]        = df.groupby(\"breath_id\")[\"u_in\"].transform(\"last\")\n    df[\"time_passed\"]      = df.groupby(\"breath_id\")[\"time_step\"].diff()\n    df['area']             = df['time_step'] * df['u_in']\n    df['area_2']           = df.groupby('breath_id')['area'].cumsum()\n    df['u_in_cumsum']      = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['u_in_lag1']        = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1']       = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1']   = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1']  = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2']        = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2']       = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2']   = df.groupby('breath_id')['u_in'].shift(-2) \n    df['u_out_lag_back2']  = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3']        = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3']       = df.groupby('breath_id')['u_out'].shift(3) \n    df['u_in_lag_back3']   = df.groupby('breath_id')['u_in'].shift(-3) \n    df['u_out_lag_back3']  = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4']        = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4']       = df.groupby('breath_id')['u_out'].shift(4) \n    df['u_in_lag_back4']   = df.groupby('breath_id')['u_in'].shift(-4) \n    df['u_out_lag_back4']  = df.groupby('breath_id')['u_out'].shift(-4) \n    \n    df = df.fillna(0)\n    \n    df['breath_id__u_in__diffmax']  = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    df['cross']                     = df['u_in']*df['u_out']\n    df['cross2']                    = df['time_step']*df['u_out']\n    df['R']                         = df['R'].astype(str)\n    df['C']                         = df['C'].astype(str)\n    df['R__C']                      = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n#     df['u_in_lag5']  = df.groupby('breath_id')['u_in'].shift(5)  #\n#     df['u_in_lag6']  = df.groupby('breath_id')['u_in'].shift(6)  #\n#     df['u_in_lag7']  = df.groupby('breath_id')['u_in'].shift(7)  #\n#     df['u_in_lag8']  = df.groupby('breath_id')['u_in'].shift(8)  #\n#     df['u_in_lag9']  = df.groupby('breath_id')['u_in'].shift(9)  #\n#     df['u_in_lag10'] = df.groupby('breath_id')['u_in'].shift(10) #\n#     df['u_in_lag11'] = df.groupby('breath_id')['u_in'].shift(11) #\n#     df['u_in_lag12'] = df.groupby('breath_id')['u_in'].shift(12) #\n#     df['u_in_lag13'] = df.groupby('breath_id')['u_in'].shift(13) #\n#     df['u_in_lag14'] = df.groupby('breath_id')['u_in'].shift(14) #\n#     df['u_in_lag15'] = df.groupby('breath_id')['u_in'].shift(15) #\n#     df['u_in_lag16'] = df.groupby('breath_id')['u_in'].shift(16) #\n#     df['u_in_lag17'] = df.groupby('breath_id')['u_in'].shift(17) #\n#     df['u_in_lag18'] = df.groupby('breath_id')['u_in'].shift(18) #\n#     df['u_in_lag19'] = df.groupby('breath_id')['u_in'].shift(19) #\n#     df['u_in_lag20'] = df.groupby('breath_id')['u_in'].shift(20) #\n    df['time_diff']  = (df['time_step']).groupby(df['breath_id']).diff(1)\n    df['time_diff2'] = (df['time_step']).groupby(df['breath_id']).diff(2)\n    df['time_diff3'] = (df['time_step']).groupby(df['breath_id']).diff(3)\n    df['time_diff4'] = (df['time_step']).groupby(df['breath_id']).diff(4)\n    df['time_diff5'] = (df['time_step']).groupby(df['breath_id']).diff(5)\n    df['time_diff6'] = (df['time_step']).groupby(df['breath_id']).diff(6)\n    df['time_diff7'] = (df['time_step']).groupby(df['breath_id']).diff(7)\n    df['time_diff8'] = (df['time_step']).groupby(df['breath_id']).diff(8)\n    df['u_in_diff1']                = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1']               = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2']                = df['u_in'] - df['u_in_lag2'] \n    df['u_out_diff2']               = df['u_out'] - df['u_out_lag2'] \n    df['u_in_diff3']                = df['u_in'] - df['u_in_lag3'] \n    df['u_out_diff3']               = df['u_out'] - df['u_out_lag3'] \n    df['u_in_diff4']                = df['u_in'] - df['u_in_lag4'] \n    df['u_out_diff4']               = df['u_out'] - df['u_out_lag4'] \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = create_new_feat(train)\ntrain = train.fillna(train.min())\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_memory_usage(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Working with Test Data","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\ntest_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(18,5))\nj=0\nfor i in num_col[:2]:\n    sns.histplot(test_data[i], ax=ax[j])\n    j+=1\nfig.suptitle('Histplot of Numerical Data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating New Features","metadata":{}},{"cell_type":"code","source":"test_data = create_new_feat(test_data)\ntest_data = test_data.fillna(test_data.min())\ntest_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = reduce_memory_usage(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\ntargets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest_data = test_data.drop(['id', 'breath_id'], axis=1)\n\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest_data = RS.transform(test_data)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest_data = test_data.reshape(-1, 80, train.shape[-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting of dependent and independent variable.","metadata":{}},{"cell_type":"code","source":"idx_len = round(0.90*len(train))\nX_train, X_valid = train[0:idx_len], train[idx_len:]\ny_train, y_valid = targets[0:idx_len], targets[idx_len:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"EPOCH = 500\nBATCH_SIZE = 256\n\nlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\nes = EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1, mode=\"min\", restore_best_weights=True)\n\nwith strategy.scope():\n    model = keras.models.Sequential([\n    keras.layers.Input(shape=train.shape[-2:]),    \n    keras.layers.Bidirectional(keras.layers.LSTM(2048, return_sequences=True)),\n    keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n    keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n   # keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n    keras.layers.Dense(64, activation='selu'),\n    keras.layers.Dense(1),\n    ])\n\nmodel.compile(optimizer=\"adam\", loss=\"mae\")\n\nhistory = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                    epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,3))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"pred = model.predict(test_data, batch_size=BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n# sample['id'] = test_data['id']\n# sample['pressure'] = pd.DataFrame({'pressure': pred[:]})\n# sample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\nsample['pressure'] = pred.squeeze().reshape(-1, 1).squeeze()\n\nq1 = sample['pressure'].quantile(0.001)\nq2 = sample['pressure'].quantile(0.999)\nsample['pressure'] = sample['pressure'].apply(lambda x: x if x>q1 else x*0.77)\nsample['pressure'] = sample['pressure'].apply(lambda x: x if x<q2 else x*1.1)\nsample.to_csv('submission_LSTM.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thank you!!!\n## Hope you enjoyed this notebook. ðŸ˜Š","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}