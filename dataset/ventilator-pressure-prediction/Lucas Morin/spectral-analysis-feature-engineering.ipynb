{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Spectral Analysis & Feature Engineering\n\nFrom niwashi (@marutama) numerous EDA notebooks we can see that a lot of u_in and pressure exhibit oscillating patterns. This is something we also see in my [error analysis / clusterings notebooks]( https://www.kaggle.com/lucasmorin/u-in-mae-exploration-with-umap-hdbscan ): clusters of MAE often correspond to highly oscillating patterns. I wanted to explore these oscillating aspects so I tried a spectral approach, mainly relying on fourrier transformations.\n\nThis approach mainly result in:\n\n- EDA tools for further spectral exploration\n\n- Some tricks for better spectral analysis (windowsing)\n\n- Some interesting ts features for LSTM model\n\n- An idea to use whole spectrum in 2D architectures\n\n- An attempt at machine re-identification\n\nYou can find everything in this notebook.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom IPython.display import display\n\nimport pickle\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"e331dbcc-0346-4019-9ff6-b890154a878b","_cell_guid":"3e5a0bd1-3e22-4b2c-a565-68985e55f95e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-23T11:28:26.608742Z","iopub.execute_input":"2021-10-23T11:28:26.609733Z","iopub.status.idle":"2021-10-23T11:28:26.61484Z","shell.execute_reply.started":"2021-10-23T11:28:26.609686Z","shell.execute_reply":"2021-10-23T11:28:26.614087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\ndict_types = {\n'id': np.int32,\n'breath_id': np.int32,\n'R': np.int8,\n'C': np.int8,\n'time_step': np.float32,\n'u_in': np.float32,\n'u_out': np.int8, #np.bool ?\n'pressure': np.float32,\n} \n\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv', dtype=dict_types)\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv', dtype=dict_types)\n\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nall_pressure = np.sort(train.pressure.unique())\nPRESSURE_MIN = all_pressure[0]\nPRESSURE_MAX = all_pressure[-1]\nPRESSURE_STEP = (all_pressure[1] - all_pressure[0])\n\nif DEBUG:\n    train = train[:80*1000]\n    test = test[:80*1000]","metadata":{"_uuid":"ca71d87d-6594-4f31-906d-0b53cd4c1374","_cell_guid":"89eb257e-0ed2-4f8b-94d6-462a5e995eb1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-23T11:28:26.617273Z","iopub.execute_input":"2021-10-23T11:28:26.617893Z","iopub.status.idle":"2021-10-23T11:28:40.833006Z","shell.execute_reply.started":"2021-10-23T11:28:26.61785Z","shell.execute_reply":"2021-10-23T11:28:40.832246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fourrier transform\n\nGet a \"weird\" input / output. ","metadata":{}},{"cell_type":"code","source":"idb = train.breath_id.unique()[31]\n\nt1 = train[train.breath_id==idb].u_in\np1 = train[train.breath_id==idb].pressure\n\nplt.plot(t1);\nplt.plot(p1);\nplt.legend(['u_in', 'pressure']);\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:28:40.834397Z","iopub.execute_input":"2021-10-23T11:28:40.834654Z","iopub.status.idle":"2021-10-23T11:28:41.082068Z","shell.execute_reply.started":"2021-10-23T11:28:40.83462Z","shell.execute_reply":"2021-10-23T11:28:41.081404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Base Fourrier Transform","metadata":{}},{"cell_type":"code","source":"import scipy.signal as signal\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, fftfreq\n\nPper_spec_t =  fft(np.append(t1.values,t1.values[0]))\nPper_spec_p =  fft(np.append(p1.values,p1.values[0]))\n\nplt.semilogy(np.log(np.abs(Pper_spec_t))[1:40]);\nplt.semilogy(np.log(np.abs(Pper_spec_p))[1:40]);\nplt.legend(['FFT_u_in', 'FFT_pressure']);\n","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:28:41.083226Z","iopub.execute_input":"2021-10-23T11:28:41.084745Z","iopub.status.idle":"2021-10-23T11:28:42.310816Z","shell.execute_reply.started":"2021-10-23T11:28:41.084703Z","shell.execute_reply":"2021-10-23T11:28:42.310055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see local maxima. ","metadata":{}},{"cell_type":"markdown","source":"# Windowsing","metadata":{}},{"cell_type":"markdown","source":"We have relatively short time series, thus we get very noisy fft. One option is to use windows. ","metadata":{}},{"cell_type":"code","source":"# mostly from the scipy documentation\nfrom scipy.signal import blackman\n\n# Number of sample points\nN = 80\n# sample spacing\nT = 1\n\nx = np.linspace(0.0, N*T+1, N, endpoint=False)\ny = train[train.breath_id==idb].u_in\n\ny = np.append(y.values,y.values[0])\n\n\nyf = fft(y)\nw = blackman(N+1)\nywf = fft(y*w)\nxf = fftfreq(N, T)[:N//2]\n\nplt.semilogy(xf[1:N//2], 2.0/N * np.abs(yf[1:N//2]), '-b')\nplt.semilogy(xf[1:N//2], 2.0/N * np.abs(ywf[1:N//2]), '-r')\nplt.legend(['FFT_u_in', 'FFT_u_in w. window'])\nplt.grid()\nplt.show()\n\nx = np.linspace(0.0, N*T+1, N, endpoint=False)\ny = train[train.breath_id==idb].pressure\ny = np.append(y.values,y.values[0])\n\nyfp = fft(y)\nw = blackman(N+1)\nywfp = fft(y*w)\nxf = fftfreq(N, T)[:N//2]\n\nplt.semilogy(xf[1:N//2], 2.0/N * np.abs(yfp[1:N//2]), '-b')\nplt.semilogy(xf[1:N//2], 2.0/N * np.abs(ywfp[1:N//2]), '-r')\nplt.legend(['FFT_pressure', 'FFT_pressure w. window'])\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:28:42.313168Z","iopub.execute_input":"2021-10-23T11:28:42.3139Z","iopub.status.idle":"2021-10-23T11:28:43.139265Z","shell.execute_reply.started":"2021-10-23T11:28:42.313858Z","shell.execute_reply":"2021-10-23T11:28:43.13846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems better.","metadata":{}},{"cell_type":"markdown","source":"# Envellope, instantaneous phase / frequency","metadata":{}},{"cell_type":"markdown","source":"Oscillations aren't uniform. We want to better identify change in oscillations. The idea here is to get an envellope and instantaneous frequency.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import hilbert, chirp\n\nduration = 80\nfs = 1\nsamples = int(fs*duration)\nt = np.arange(samples) / fs\n#We create a chirp of which the frequency increases from 20 Hz to 100 Hz and apply an amplitude modulation.\n\nsignal = train[train.breath_id==idb].u_in\n#The amplitude envelope is given by magnitude of the analytic signal. The instantaneous frequency can be obtained by differentiating the instantaneous phase in respect to time. The instantaneous phase corresponds to the phase angle of the analytic signal.\n\nanalytic_signal = hilbert(signal)\namplitude_envelope = np.abs(analytic_signal)\ninstantaneous_phase = np.unwrap(np.angle(analytic_signal))\ninstantaneous_frequency = (np.diff(instantaneous_phase) /\n                           (2.0*np.pi) * fs)\n\nfig, (ax0, ax1) = plt.subplots(nrows=2)\nax0.plot(t, signal, label='signal')\nax0.plot(t, amplitude_envelope, label='envelope')\nax0.set_xlabel(\"time in seconds\")\nax0.legend()\nax1.plot(t[1:], instantaneous_frequency)\nax1.set_xlabel(\"time in seconds\")\nax1.set_ylim(0.0, 1)\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:28:43.142288Z","iopub.execute_input":"2021-10-23T11:28:43.142504Z","iopub.status.idle":"2021-10-23T11:28:43.560985Z","shell.execute_reply.started":"2021-10-23T11:28:43.142471Z","shell.execute_reply":"2021-10-23T11:28:43.56026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TS Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Adding envellope and instantaneous frequency in a LSTM make sense to me. It's seems a bit more difficult to add FFT transformation as tim series, but why not try it and see if it works ?","metadata":{}},{"cell_type":"code","source":"%%time\n\nffta = lambda x: np.abs(fft(np.append(x.values,x.values[0]))[:80])\nffta.__name__ = 'ffta'\n\nfftw = lambda x: np.abs(fft(np.append(x.values,x.values[0])*w)[:80])\nfftw.__name__ = 'fftw'\n\ntrain['fft_u_in'] = train.groupby('breath_id')['u_in'].transform(ffta)\ntrain['fft_u_in_w'] = train.groupby('breath_id')['u_in'].transform(fftw)\ntrain['analytical'] = train.groupby('breath_id')['u_in'].transform(hilbert)\ntrain['envelope'] = np.abs(train['analytical'])\ntrain['phase'] = np.angle(train['analytical'])\ntrain['unwrapped_phase'] = train.groupby('breath_id')['phase'].transform(np.unwrap)\ntrain['phase_shift1'] = train.groupby('breath_id')['unwrapped_phase'].shift(1).astype(np.float32)\ntrain['IF'] = train['unwrapped_phase'] - train['phase_shift1'].astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:28:43.562274Z","iopub.execute_input":"2021-10-23T11:28:43.562623Z","iopub.status.idle":"2021-10-23T11:28:44.190079Z","shell.execute_reply.started":"2021-10-23T11:28:43.562571Z","shell.execute_reply":"2021-10-23T11:28:44.189313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Complete spectrum","metadata":{}},{"cell_type":"markdown","source":"If oscillations aren't uniform over time, this means we are interested in the whole spectrum. However using these might require a completely different model. ","metadata":{}},{"cell_type":"code","source":"from scipy import signal\nimport matplotlib.pyplot as plt\n\nfs = 1\nN = 80\n \nx = train[train.breath_id==idb].u_in\n\nf, t, Zxx = signal.stft(x, 1, nperseg=16)\n\namp = np.max(np.log(np.abs(Zxx)))\n\nplt.pcolormesh(t, f, np.log(np.abs(Zxx)), vmin=0, vmax=amp)#, shading='gouraud')\nplt.title('STFT Magnitude')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [id]')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:28:44.191453Z","iopub.execute_input":"2021-10-23T11:28:44.191716Z","iopub.status.idle":"2021-10-23T11:28:44.407147Z","shell.execute_reply.started":"2021-10-23T11:28:44.191676Z","shell.execute_reply":"2021-10-23T11:28:44.406449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not sure how to use that. Maybe some as a feature ? in a 2D NN architecture ?","metadata":{}},{"cell_type":"markdown","source":"# Error Analysis","metadata":{}},{"cell_type":"markdown","source":"(please upvote the hdbscan wheel data set)","metadata":{}},{"cell_type":"code","source":"!mkdir -p /tmp/pip/cache/\n!cp ../input/hdbscan0827-whl/hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ hdbscan","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:28:44.409728Z","iopub.execute_input":"2021-10-23T11:28:44.410018Z","iopub.status.idle":"2021-10-23T11:28:54.80509Z","shell.execute_reply.started":"2021-10-23T11:28:44.409985Z","shell.execute_reply":"2021-10-23T11:28:54.804209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimport hdbscan\nimport umap\nimport pickle\nimport matplotlib.colors as colors\n\n\nMAE_id = pickle.load(open('../input/u-in-mae-exploration-with-umap-hdbscan/MAE_id.pkl', 'rb'))\n\ntrain['time_id'] = [e  for i in range(len(train.breath_id.unique())) for e in range(80)] \nX = train[['breath_id','fft_u_in_w','time_id']].pivot(index='breath_id',columns='time_id',values='fft_u_in_w')\nMAE = MAE_id[:X.shape[0]]\n\nreducer = umap.UMAP(random_state=42, n_components=2)\nembedding = reducer.fit_transform(X)\nclusterer = hdbscan.HDBSCAN(prediction_data=True, min_cluster_size = 50).fit(embedding)\nu, counts = np.unique(clusterer.labels_, return_counts=True)\n\nprint(u)\nprint(counts)\n\nplt.figure(figsize=(10, 8));\nplt.scatter(embedding[:, 0], embedding[:, 1], s=5, c=clusterer.labels_, edgecolors='none', cmap='jet');\nplt.show();\n\nplt.figure(figsize=(10, 8));\nplt.scatter(embedding[:, 0], embedding[:, 1], s=5, c=MAE, edgecolors='none', cmap='jet', norm=colors.LogNorm(vmin=MAE.quantile(0.05), vmax=MAE.quantile(0.95)));\nplt.colorbar();\nplt.show();\n\ndel X","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:28:54.807864Z","iopub.execute_input":"2021-10-23T11:28:54.80869Z","iopub.status.idle":"2021-10-23T11:29:23.35834Z","shell.execute_reply.started":"2021-10-23T11:28:54.80864Z","shell.execute_reply":"2021-10-23T11:29:23.357495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine identification ?","metadata":{}},{"cell_type":"markdown","source":"if we assume some sort of constant behavior, the ratio FFT(pressure)/FFT(u_in) should give the behavior of the machine (up to some shift).","metadata":{}},{"cell_type":"code","source":"plt.semilogy(xf[1:N//2], np.abs(yfp[1:N//2])/np.abs(yf[1:N//2]), '-b')\nplt.semilogy(xf[1:N//2], np.abs(ywfp[1:N//2])/np.abs(ywf[1:N//2]), '-r')\nplt.legend(['FFT_pressure / FFT_u_in', 'FFT_pressure / FFT_u_in w. window'])\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:29:23.360073Z","iopub.execute_input":"2021-10-23T11:29:23.360573Z","iopub.status.idle":"2021-10-23T11:29:23.766508Z","shell.execute_reply.started":"2021-10-23T11:29:23.360534Z","shell.execute_reply":"2021-10-23T11:29:23.765628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine transformation - whole spectrum","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfs = 1\nN = 80\n\nfor i in range(1,8):\n    \n    x = train[train.breath_id==i].u_in\n    y = train[train.breath_id==i].pressure\n    \n    f, t, Zxx = signal.stft(x, fs, nperseg=16)\n    f, t, Zxy = signal.stft(y, fs, nperseg=16)\n    \n    plt.pcolormesh(t, f, np.log(np.abs(Zxy)) - np.log(np.abs(Zxx)))\n    plt.title('STFT p / SFT u_in log Magnitude')\n    plt.ylabel('Frequency [Hz]')\n    plt.xlabel('Time [sec]')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:29:23.768361Z","iopub.execute_input":"2021-10-23T11:29:23.768659Z","iopub.status.idle":"2021-10-23T11:29:25.236185Z","shell.execute_reply.started":"2021-10-23T11:29:23.768621Z","shell.execute_reply":"2021-10-23T11:29:25.235377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Clustering","metadata":{}},{"cell_type":"code","source":"train['fft_u_in_w'] = train.groupby('breath_id')['u_in'].transform(fftw)\ntrain['fft_u_in_w'] = train['fft_u_in_w'].replace(0,1e-6)\n\ntrain['fft_pressure_w'] = train.groupby('breath_id')['pressure'].transform(fftw)\n\ntrain['fft_machine_w'] = np.log(train['fft_pressure_w']/train['fft_u_in_w'])","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:29:25.239341Z","iopub.execute_input":"2021-10-23T11:29:25.239648Z","iopub.status.idle":"2021-10-23T11:29:25.497081Z","shell.execute_reply.started":"2021-10-23T11:29:25.239613Z","shell.execute_reply":"2021-10-23T11:29:25.496202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimport hdbscan\nimport umap\nimport pickle\nimport matplotlib.colors as colors\n\n\nMAE_id = pickle.load(open('../input/u-in-mae-exploration-with-umap-hdbscan/MAE_id.pkl', 'rb'))\n\ntrain['time_id'] = [e  for i in range(len(train.breath_id.unique())) for e in range(80)] \nX = train[['breath_id','fft_machine_w','time_id']].pivot(index='breath_id',columns='time_id',values='fft_machine_w')\nMAE = MAE_id[:X.shape[0]]\n\nreducer = umap.UMAP(random_state=42, n_components=2)\nembedding = reducer.fit_transform(X)\nclusterer = hdbscan.HDBSCAN(prediction_data=True, min_cluster_size = 50).fit(embedding)\nu, counts = np.unique(clusterer.labels_, return_counts=True)\n\nprint(u)\nprint(counts)\n\nplt.figure(figsize=(10, 8));\nplt.scatter(embedding[:, 0], embedding[:, 1], s=5, c=clusterer.labels_, edgecolors='none', cmap='jet');\nplt.show();\n\nplt.figure(figsize=(10, 8));\nplt.scatter(embedding[:, 0], embedding[:, 1], s=5, c=MAE, edgecolors='none', cmap='jet', norm=colors.LogNorm(vmin=MAE.quantile(0.05), vmax=MAE.quantile(0.95)));\nplt.colorbar();\nplt.show();\n\ndel X","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:29:25.498523Z","iopub.execute_input":"2021-10-23T11:29:25.498811Z","iopub.status.idle":"2021-10-23T11:29:30.22427Z","shell.execute_reply.started":"2021-10-23T11:29:25.498777Z","shell.execute_reply":"2021-10-23T11:29:30.223572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cool idea, not sure if exploitable as we don't have well separated clusters (and pressure is not available in test). ","metadata":{}},{"cell_type":"markdown","source":"# Feature importance\n\nUsing @cdeotte LTSM Feature importance: https://www.kaggle.com/cdeotte/lstm-feature-importance\n\nWhich Rely on @tenffe: https://www.kaggle.com/tenffe/finetune-of-tensorflow-bidirectional-lstm","metadata":{}},{"cell_type":"code","source":"import numpy as np, os\nimport pandas as pd\n\nimport optuna\n\n# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717 \nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display\n\nDEBUG = False\nTRAIN_MODEL = True\nINFER_TEST = True\nONE_FOLD_ONLY = True\nCOMPUTE_LSTM_IMPORTANCE = True\n\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\npressure_values = np.sort( train.pressure.unique() )\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*1000]\n    test = test[:80*1000]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-23T11:29:30.225624Z","iopub.execute_input":"2021-10-23T11:29:30.226064Z","iopub.status.idle":"2021-10-23T11:29:40.778412Z","shell.execute_reply.started":"2021-10-23T11:29:30.226021Z","shell.execute_reply":"2021-10-23T11:29:40.777646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.signal import hilbert, chirp\nfrom scipy.signal import blackman\nfrom scipy.fft import fft, fftfreq\n\nN = 80\nw = blackman(N+1)\n\nffta = lambda x: np.abs(fft(np.append(x.values,x.values[0]))[:80])\nffta.__name__ = 'ffta'\n\nfftw = lambda x: np.abs(fft(np.append(x.values,x.values[0])*w)[:80])\nfftw.__name__ = 'fftw'\n\ndef add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    #df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    #df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    #df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    #df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    #df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    #df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    #df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    #df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    #df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df.groupby('breath_id')['u_out'].shift(2)\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    #df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    #df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n\n    df['fft_u_in'] = df.groupby('breath_id')['u_in'].transform(ffta)\n    df['fft_u_in_w'] = df.groupby('breath_id')['u_in'].transform(fftw)\n    df['analytical'] = df.groupby('breath_id')['u_in'].transform(hilbert)\n    df['envelope'] = np.abs(df['analytical'])\n    df['phase'] = np.angle(df['analytical'])\n    df['unwrapped_phase'] = df.groupby('breath_id')['phase'].transform(np.unwrap)\n    df['phase_shift1'] = df.groupby('breath_id')['unwrapped_phase'].shift(1).astype(np.float32)\n    df['IF'] = df['unwrapped_phase'] - df['phase_shift1'].astype(np.float32)\n    df = df.fillna(0)\n    \n    df = df.drop('analytical',axis=1)\n    \n    return df\n\ntrain = add_features(train)\ntest = add_features(test)\n\nprint('Train dataframe shape',train.shape)\ntrain.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-23T11:29:40.779857Z","iopub.execute_input":"2021-10-23T11:29:40.780101Z","iopub.status.idle":"2021-10-23T11:29:42.379805Z","shell.execute_reply.started":"2021-10-23T11:29:40.780069Z","shell.execute_reply":"2021-10-23T11:29:42.378979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)\n\nCOLS = list(train.columns)\nprint('Number of feature columns =', len(COLS) )\n\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])\n\ntrain = np.float32(train)\ntest = np.float32(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:29:42.38148Z","iopub.execute_input":"2021-10-23T11:29:42.382018Z","iopub.status.idle":"2021-10-23T11:29:42.541166Z","shell.execute_reply.started":"2021-10-23T11:29:42.381979Z","shell.execute_reply":"2021-10-23T11:29:42.539684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 10 if DEBUG else 300\nBATCH_SIZE = 1024\nNUM_FOLDS = 10\n\n# detect and init the TPU\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\n#tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# GET GPU STRATEGY\ngpu_strategy = tf.distribute.get_strategy()\n\nwith gpu_strategy.scope():\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        K.clear_session()\n        \n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        \n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        if TRAIN_MODEL:\n            model = keras.models.Sequential([\n                keras.layers.Input(shape=train.shape[-2:]),\n                keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n                keras.layers.Dense(128, activation='selu'),\n                keras.layers.Dense(1),\n            ])\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n            lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n            es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n            sv = keras.callbacks.ModelCheckpoint(\n                checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n                save_weights_only=False, mode='auto', save_freq='epoch',\n                options=None\n            )\n            \n            model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n            \n        else:\n            model = keras.models.load_model('../input/finetune-of-tensorflow-bidirectional-lstm/'+checkpoint_filepath)\n\n        if INFER_TEST:\n            print(' Predicting test data...')\n            test_preds.append(model.predict(test,verbose=0).squeeze().reshape(-1, 1).squeeze())\n                    \n        if COMPUTE_LSTM_IMPORTANCE:\n            results = []\n            print(' Computing LSTM feature importance...')\n            \n            # COMPUTE BASELINE (NO SHUFFLE)\n            oof_preds = model.predict(X_valid, verbose=0).squeeze() \n            baseline_mae = np.mean(np.abs( oof_preds-y_valid ))\n            results.append({'feature':'BASELINE','mae':baseline_mae})           \n\n            for k in tqdm(range(len(COLS))):\n                \n                # SHUFFLE FEATURE K\n                save_col = X_valid[:,:,k].copy()\n                np.random.shuffle(X_valid[:,:,k])\n                        \n                # COMPUTE OOF MAE WITH FEATURE K SHUFFLED\n                oof_preds = model.predict(X_valid, verbose=0).squeeze() \n                mae = np.mean(np.abs( oof_preds-y_valid ))\n                results.append({'feature':COLS[k],'mae':mae})\n                X_valid[:,:,k] = save_col\n         \n            # DISPLAY LSTM FEATURE IMPORTANCE\n            print()\n            df = pd.DataFrame(results)\n            df = df.sort_values('mae')\n            plt.figure(figsize=(10,20))\n            plt.barh(np.arange(len(COLS)+1),df.mae)\n            plt.yticks(np.arange(len(COLS)+1),df.feature.values)\n            plt.title('LSTM Feature Importance',size=16)\n            plt.ylim((-1,len(COLS)+1))\n            plt.plot([baseline_mae,baseline_mae],[-1,len(COLS)+1], '--', color='orange',\n                     label=f'Baseline OOF\\nMAE={baseline_mae:.3f}')\n            plt.xlabel(f'Fold {fold+1} OOF MAE with feature permuted',size=14)\n            plt.ylabel('Feature',size=14)\n            plt.legend()\n            plt.show()\n                               \n            # SAVE LSTM FEATURE IMPORTANCE\n            df = df.sort_values('mae',ascending=False)\n            df.to_csv(f'lstm_feature_importance_fold_{fold+1}.csv',index=False)\n                               \n        # ONLY DO ONE FOLD\n        if ONE_FOLD_ONLY: break","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:29:42.542957Z","iopub.execute_input":"2021-10-23T11:29:42.543237Z","iopub.status.idle":"2021-10-23T11:30:13.829094Z","shell.execute_reply.started":"2021-10-23T11:29:42.543201Z","shell.execute_reply":"2021-10-23T11:30:13.828446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:31:03.784269Z","iopub.execute_input":"2021-10-23T11:31:03.784533Z","iopub.status.idle":"2021-10-23T11:31:03.790512Z","shell.execute_reply.started":"2021-10-23T11:31:03.784503Z","shell.execute_reply":"2021-10-23T11:31:03.78974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not DEBUG:\n    if INFER_TEST:\n        PRESSURE_MIN = pressure_values[0]\n        PRESSURE_MAX = pressure_values[-1]\n        PRESSURE_STEP = pressure_values[1] - pressure_values[0]\n\n        # NAME POSTFIX\n        postfix = ''\n        if ONE_FOLD_ONLY: \n            NUM_FOLDS = 1\n            postfix = '_fold_1'\n\n        # ENSEMBLE FOLDS WITH MEAN\n        submission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\n        submission.to_csv(f'submission_mean{postfix}.csv', index=False)\n\n        # ENSEMBLE FOLDS WITH MEDIAN\n        submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n        submission.to_csv(f'submission_median{postfix}.csv', index=False)\n\n        # ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\n        submission[\"pressure\"] =\\\n            np.round( (submission.pressure - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\n        submission.pressure = np.clip(submission.pressure, PRESSURE_MIN, PRESSURE_MAX)\n        submission.to_csv(f'submission_median_round{postfix}.csv', index=False)\n\n        # DISPLAY SUBMISSION.CSV\n        print(f'submission{postfix}.csv head')\n        display( submission.head() )","metadata":{"execution":{"iopub.status.busy":"2021-10-23T11:31:10.406412Z","iopub.execute_input":"2021-10-23T11:31:10.406968Z","iopub.status.idle":"2021-10-23T11:31:10.415151Z","shell.execute_reply.started":"2021-10-23T11:31:10.406933Z","shell.execute_reply":"2021-10-23T11:31:10.414018Z"},"trusted":true},"execution_count":null,"outputs":[]}]}