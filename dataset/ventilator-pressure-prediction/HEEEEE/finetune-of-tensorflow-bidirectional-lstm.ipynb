{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display","metadata":{"_uuid":"e331dbcc-0346-4019-9ff6-b890154a878b","_cell_guid":"3e5a0bd1-3e22-4b2c-a565-68985e55f95e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-09T04:47:24.105481Z","iopub.execute_input":"2021-10-09T04:47:24.105845Z","iopub.status.idle":"2021-10-09T04:47:31.429125Z","shell.execute_reply.started":"2021-10-09T04:47:24.105757Z","shell.execute_reply":"2021-10-09T04:47:31.428178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/vpp-gru-baseline-median/sub_all.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:47:50.330788Z","iopub.execute_input":"2021-10-09T04:47:50.331521Z","iopub.status.idle":"2021-10-09T04:48:01.611852Z","shell.execute_reply.started":"2021-10-09T04:47:50.331468Z","shell.execute_reply":"2021-10-09T04:48:01.610736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['pressure_median'] = np.median([df[f'pressure_{i}'] for i in range(10)], axis=0)\ndf['pressure_mean'] = np.median([df[f'pressure_{i}'] for i in range(10)], axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:49:22.548499Z","iopub.execute_input":"2021-10-09T04:49:22.548803Z","iopub.status.idle":"2021-10-09T04:49:24.965404Z","shell.execute_reply.started":"2021-10-09T04:49:22.548774Z","shell.execute_reply":"2021-10-09T04:49:24.964289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\nsub_df = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\nall_pressure = np.sort(train_df.pressure.unique())\nPRESSURE_MIN = all_pressure[0].item()\nPRESSURE_MAX = all_pressure[-1].item()\nPRESSURE_STEP = ( all_pressure[1] - all_pressure[0] ).item()\n# sub1 = pd.read_csv('../input/vpp-lstm-320-305-304-299/submission_mean_round_LB153.csv')\n# sub2 = pd.read_csv('../input/vpp-lstm-320-305-304-299/submission_median_round_LB153.csv')\n\nsub_df['pressure'] = df.pressure_median*.75+df.pressure_mean*.25\ndisplay(sub_df.head())\n# sub_df.to_csv('submission_median.csv', index=False)\nsub_df['pressure'] = np.round((sub_df.pressure - PRESSURE_MIN)/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\nsub_df.pressure = np.clip(sub_df.pressure, PRESSURE_MIN, PRESSURE_MAX)\ndisplay(sub_df.head())\nsub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T04:49:59.852285Z","iopub.execute_input":"2021-10-09T04:49:59.852687Z","iopub.status.idle":"2021-10-09T04:50:24.867453Z","shell.execute_reply.started":"2021-10-09T04:49:59.852626Z","shell.execute_reply":"2021-10-09T04:50:24.866533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdada","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy.random import seed\nSEED = 2#021\nseed(SEED)\n\nimport tensorflow as tf\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T08:34:36.149071Z","iopub.execute_input":"2021-10-04T08:34:36.149333Z","iopub.status.idle":"2021-10-04T08:34:36.155086Z","shell.execute_reply.started":"2021-10-04T08:34:36.149303Z","shell.execute_reply":"2021-10-04T08:34:36.154212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 140 352","metadata":{"execution":{"iopub.status.busy":"2021-10-04T08:34:36.156165Z","iopub.execute_input":"2021-10-04T08:34:36.156774Z","iopub.status.idle":"2021-10-04T08:34:36.164322Z","shell.execute_reply.started":"2021-10-04T08:34:36.156742Z","shell.execute_reply":"2021-10-04T08:34:36.163467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\n\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*1000]","metadata":{"_uuid":"ca71d87d-6594-4f31-906d-0b53cd4c1374","_cell_guid":"89eb257e-0ed2-4f8b-94d6-462a5e995eb1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-04T08:34:36.168374Z","iopub.execute_input":"2021-10-04T08:34:36.168622Z","iopub.status.idle":"2021-10-04T08:34:50.344489Z","shell.execute_reply.started":"2021-10-04T08:34:36.168592Z","shell.execute_reply":"2021-10-04T08:34:50.343613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def add_features(df):\n#     # rewritten calculation of lag features from this notebook: https://www.kaggle.com/patrick0302/add-lag-u-in-as-new-feat\n#     # some of ideas from this notebook: https://www.kaggle.com/mst8823/google-brain-lightgbm-baseline\n#     df['last_value_u_in'] = df.groupby('breath_id')['u_in'].transform('last')\n#     df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n#     df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n#     df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n#     df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n#     df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n#     df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n#     df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n#     df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n#     df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n#     df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n#     df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n#     df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n#     df = df.fillna(0)\n\n\n#     df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n\n#     # max value of u_in and u_out for each breath\n#     df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n#     df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n\n#     # difference between consequitive values\n#     df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n#     df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n#     df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n#     df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n#     # from here: https://www.kaggle.com/yasufuminakama/ventilator-pressure-lstm-starter\n#     df.loc[df['time_step'] == 0, 'u_in_diff'] = 0\n#     df.loc[df['time_step'] == 0, 'u_out_diff'] = 0\n\n#     # difference between the current value of u_in and the max value within the breath\n#     df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n#     df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n\n#     # OHE\n#     df = df.merge(pd.get_dummies(df['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\n#     df = df.merge(pd.get_dummies(df['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\n#     df = df.merge(pd.get_dummies(df['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\n#     # https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/273974\n#     df['u_in_cumsum'] = df.groupby(['breath_id'])['u_in'].cumsum()\n#     df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n#     return df","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:19:45.671868Z","iopub.execute_input":"2021-10-04T04:19:45.672165Z","iopub.status.idle":"2021-10-04T04:19:45.67809Z","shell.execute_reply.started":"2021-10-04T04:19:45.672134Z","shell.execute_reply":"2021-10-04T04:19:45.677168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","metadata":{"_uuid":"dc41dbf2-f199-4b9d-bbd9-bf6084162b47","_cell_guid":"13a36b46-7067-4b29-aad3-7e3b15e8415b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-10-04T04:19:45.679268Z","iopub.execute_input":"2021-10-04T04:19:45.679496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)","metadata":{"_uuid":"346bf2c0-96d2-4da5-8837-c0f820294a85","_cell_guid":"01328860-fa2a-421c-9e5f-ea0048246f98","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nimport tensorflow.keras.backend as K\nclass WarmupExponentialDecay(Callback):\n    def __init__(self,lr_base=0.0002,lr_min=0.0,decay=0,warmup_epochs=0):\n        self.num_passed_batchs = 0   #一个计数器\n        self.warmup_epochs=warmup_epochs  \n        self.lr=lr_base #learning_rate_base\n        self.lr_min=lr_min #最小的起始学习率,此代码尚未实现\n        self.decay=decay  #指数衰减率\n        self.steps_per_epoch=0 #也是一个计数器\n        \n    def on_batch_begin(self, batch, logs=None):\n        # params是模型自动传递给Callback的一些参数\n        if self.steps_per_epoch==0:\n            #防止跑验证集的时候呗更改了\n            if self.params['steps'] == None:\n                self.steps_per_epoch = np.ceil(1. * self.params['samples'] / self.params['batch_size'])\n            else:\n                self.steps_per_epoch = self.params['steps']\n        if self.num_passed_batchs < self.steps_per_epoch * self.warmup_epochs:\n            K.set_value(self.model.optimizer.lr,\n                        self.lr*(self.num_passed_batchs + 1) / self.steps_per_epoch / self.warmup_epochs)\n        else:\n            K.set_value(self.model.optimizer.lr,\n                        self.lr*((1-self.decay)**(self.num_passed_batchs-self.steps_per_epoch*self.warmup_epochs)))\n        self.num_passed_batchs += 1\n        \n    def on_epoch_begin(self,epoch,logs=None):\n        #用来输出学习率的,可以删除\n        print(\"learning_rate:\",K.get_value(self.model.optimizer.lr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 300\nBATCH_SIZE = 1024\nNUM_FOLDS = 10\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = keras.models.Sequential([\n            keras.layers.Input(shape=train.shape[-2:]),\n            keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n#             keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n            keras.layers.Dense(128, activation='selu'),\n#             keras.layers.Dropout(0.1),\n            keras.layers.Dense(1),\n        ])\n        model.compile(optimizer=\"adam\", loss=\"mae\")\n\n#         scheduler = ExponentialDecay(1e-3, 40*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n#         lr = LearningRateScheduler(scheduler, verbose=1)\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n#         lr = WarmupExponentialDecay(lr_base=1e-3, decay=1e-5, warmup_epochs=30)\n        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n    \n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        sv = keras.callbacks.ModelCheckpoint(\n            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n            save_weights_only=False, mode='auto', save_freq='epoch',\n            options=None\n        )\n\n        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n        #model.save(f'Fold{fold+1} RNN Weights')\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ./","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"pressure\"] = sum(test_preds)/NUM_FOLDS\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}