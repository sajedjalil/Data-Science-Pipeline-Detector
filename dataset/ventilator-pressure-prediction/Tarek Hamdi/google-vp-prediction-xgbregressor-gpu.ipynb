{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://1.bp.blogspot.com/-zeFUWzrz2FA/YUup-VsSKWI/AAAAAAAAIME/4s_s--D68xEJmBI8VdAaOJXNO3cd8qkqwCLcBGAsYHQ/s1900/header.png)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nfrom tqdm import tqdm\nimport xgboost as xgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-05T00:19:24.598384Z","iopub.execute_input":"2021-10-05T00:19:24.598904Z","iopub.status.idle":"2021-10-05T00:19:25.539677Z","shell.execute_reply.started":"2021-10-05T00:19:24.598799Z","shell.execute_reply":"2021-10-05T00:19:25.538982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#===========================================================================\n# read in the data\n# Original kernel: https://www.kaggle.com/carlmcbrideellis/very-simple-xgboost-regression\n#===========================================================================\ntrain_data = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest_data  = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n\ntest_ids = test_data['id'].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T00:19:25.5439Z","iopub.execute_input":"2021-10-05T00:19:25.5462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing Values Count","metadata":{}},{"cell_type":"code","source":"missing_values_count = train_data.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train_data.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% of missing data = \",(total_missing/total_cells) * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain_data = add_features(train_data)\ntest_data = add_features(test_data)\n\ntrain_data.drop(['id', 'breath_id'], axis=1, inplace=True)\ntest_data = test_data.drop(['id', 'breath_id'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#===========================================================================\n# select some features of interest\n#===========================================================================\nfeatures=[]\nfor i in train_data.columns:\n    if i != 'pressure':\n        features.append(i)\n# features = ['R', 'C', 'time_step', 'u_in', 'u_out']\n\n#===========================================================================\n#===========================================================================\nX_train = train_data[features]\ny_train = train_data[\"pressure\"]\nfinal_X_test = test_data[features]\n\n#===========================================================================\n# XGBoost regression: \n# Parameters: \n# n_estimators  \"Number of gradient boosted trees. Equivalent to number \n#                of boosting rounds.\"\n# learning_rate \"Boosting learning rate (xgb’s “eta”)\"\n# max_depth     \"Maximum depth of a tree. Increasing this value will make \n#                the model more complex and more likely to overfit.\" \n#===========================================================================\n# regressor=xgb.XGBRegressor(n_estimators  = 500,\n#                            learning_rate = 0.1,\n#                            max_depth     = 5)\n# regressor.fit(X_train, y_train)\n\n#===========================================================================\n# To use early_stopping_rounds: \n# \"Validation metric needs to improve at least once in every \n# early_stopping_rounds round(s) to continue training.\"\n#===========================================================================\n# perform a test/train split \nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n\n\nregressor = xgb.XGBRegressor(\n                 tree_method='gpu_hist',\n                 colsample_bytree=0.9,\n                 alpha=0.01563,\n                 #gamma=0.0,\n                 learning_rate=0.5,\n                 max_depth=13,\n                 min_child_weight=257,\n                 n_estimators=1500,                                                                  \n                 #reg_alpha=0.9,\n                 reg_lambda=0.003,\n                 subsample=0.9,\n                 random_state=2020,\n                 metric_period=100,\n                 silent=1)\n\nregressor.fit(X_train, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"#===========================================================================\n# use the model XGB to predict the prices for the test data\n#===========================================================================\npredictions = regressor.predict(final_X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#===========================================================================\n# write out CSV submission file\n#===========================================================================\noutput = pd.DataFrame({\"id\":test_ids, \"pressure\":predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}