{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 0. Introduction\n- Updated 10/15/2021\n- GPU usage\n- This code is a baseline with LighGBM train method.\n- Shown to confirm overfitting\n- Shown Importance feature by lightGBM feature_importance function\n- Finished to submit","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"class Config:\n    def __init__(self):\n        self.config = 0\n        self.gpu_on = 1\n        self.optuna_tuner = 0\n        self.optuna_train = 0\n        self.config_size = 754\n        self.data_dir = '../input/ventilator-pressure-prediction/'\n        self.post_processing = {\n                                'max_pressure': 64.82099173863948,\n                                'min_pressure': -1.8957442945646408,\n                                'diff_pressure': 0.07030215,\n                                }       \nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:59:26.743239Z","iopub.execute_input":"2021-10-14T18:59:26.743821Z","iopub.status.idle":"2021-10-14T18:59:26.845494Z","shell.execute_reply.started":"2021-10-14T18:59:26.74374Z","shell.execute_reply":"2021-10-14T18:59:26.84479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0-1. GPU Prepare\n- You need to turn on \"GPU Accelerator\"\n- You need to turn on Inernet setting\n- https://www.kaggle.com/dromosys/gpu-accelerated-lightgbm-full","metadata":{}},{"cell_type":"code","source":"if config.gpu_on:\n    !rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n    !git clone --recursive https://github.com/Microsoft/LightGBM","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:59:26.847314Z","iopub.execute_input":"2021-10-14T18:59:26.847574Z","iopub.status.idle":"2021-10-14T18:59:54.649577Z","shell.execute_reply.started":"2021-10-14T18:59:26.847541Z","shell.execute_reply":"2021-10-14T18:59:54.648681Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.gpu_on:\n    !apt-get install -y -qq libboost-all-dev","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:59:54.65092Z","iopub.execute_input":"2021-10-14T18:59:54.651161Z","iopub.status.idle":"2021-10-14T18:59:57.161837Z","shell.execute_reply.started":"2021-10-14T18:59:54.651132Z","shell.execute_reply":"2021-10-14T18:59:57.160771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- You need to delete comment out when you wnat to use GPU","metadata":{}},{"cell_type":"code","source":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T18:59:57.165789Z","iopub.execute_input":"2021-10-14T18:59:57.166003Z","iopub.status.idle":"2021-10-14T19:04:36.264225Z","shell.execute_reply.started":"2021-10-14T18:59:57.165978Z","shell.execute_reply":"2021-10-14T19:04:36.263445Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.gpu_on:\n    !cd LightGBM/python-package/;python3 setup.py install --precompile","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:36.266156Z","iopub.execute_input":"2021-10-14T19:04:36.266447Z","iopub.status.idle":"2021-10-14T19:04:37.896416Z","shell.execute_reply.started":"2021-10-14T19:04:36.266409Z","shell.execute_reply":"2021-10-14T19:04:37.89554Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.gpu_on:\n    !mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n    !rm -r LightGBM","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:37.89972Z","iopub.execute_input":"2021-10-14T19:04:37.899949Z","iopub.status.idle":"2021-10-14T19:04:39.391309Z","shell.execute_reply.started":"2021-10-14T19:04:37.899923Z","shell.execute_reply":"2021-10-14T19:04:39.390287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.gpu_on:\n    !nvidia-smi","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0-2. Libarary","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport glob\nimport time\nimport random\nimport pandas as pd\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 100)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport lightgbm as lgb\nimport optuna\nimport optuna.integration.lightgbm as lgbo\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import RobustScaler","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:39.393198Z","iopub.execute_input":"2021-10-14T19:04:39.393493Z","iopub.status.idle":"2021-10-14T19:04:42.499637Z","shell.execute_reply.started":"2021-10-14T19:04:39.393454Z","shell.execute_reply":"2021-10-14T19:04:42.498913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1 EDA & Preprocessing\n### 1-1. Train & Test data","metadata":{}},{"cell_type":"code","source":"# Dtype Changed for low size data\ndtypes = {'id': 'int32',\n          'breath_id': 'int32',\n          'R' : 'int8',\n          'C' : 'int8',\n          'time_step': 'float64',\n          'u_in': 'float64',\n          'u_out': 'int8',\n          'pressure': 'float64'}\n\n# Read train CSV data\ndef read_train():\n    train = pd.read_csv(config.data_dir + 'train.csv')\n    # Select random breath_id for degug\n    if config.config:\n        random.seed(2021)\n        lst_train = random.sample(set(train['breath_id'].unique()), config.config_size)\n        train_tmp = pd.DataFrame()\n        for i in lst_train:\n            train_tmp = pd.concat([train_tmp, train[train['breath_id'] == i]], axis=0)\n        train = train_tmp\n    train = train.astype(dtypes)\n    return train\n\n# Read test CSV data\ndef read_test():\n    test = pd.read_csv(config.data_dir + 'test.csv')\n    # Select random breath_id for degug\n    if config.config:\n        random.seed(2021)\n        lst_test = random.sample(set(test['breath_id'].unique()), config.config_size)\n        test_tmp = pd.DataFrame()\n        for i in lst_test:\n            test_tmp = pd.concat([test_tmp, test[test['breath_id'] == i]], axis=0)\n        test = test_tmp\n    test = test.astype(dtypes)\n    return test  \n\ntrain = read_train()   \ntrain.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:42.500982Z","iopub.execute_input":"2021-10-14T19:04:42.501232Z","iopub.status.idle":"2021-10-14T19:04:52.041024Z","shell.execute_reply.started":"2021-10-14T19:04:42.501198Z","shell.execute_reply":"2021-10-14T19:04:52.040316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-2. Exploratory Data Analysis\n### Feature\n- id - globally-unique time step identifier across an entire file\n- breath_id - globally-unique time step for breaths\n- R - lung attribute indicating how restricted the airway is (in cmH2O/L/S). Physically, this is the change in pressure per change in flow (air volume per time). Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n- C - lung attribute indicating how compliant the lung is (in mL/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloon’s latex, with higher C having thinner latex and easier to blow.\n- time_step - the actual time stamp.\n- u_in - the control input for the inspiratory solenoid valve. Ranges from 0 to 100.\n- u_out - the control input for the exploratory solenoid valve. Either 0 or 1.\n- pressure - the airway pressure measured in the respiratory circuit, measured in cmH2O.","metadata":{}},{"cell_type":"code","source":"## Describe in exclude id columns\ntrain[train.columns[1:]].describe(include='all').round(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:52.042219Z","iopub.execute_input":"2021-10-14T19:04:52.042553Z","iopub.status.idle":"2021-10-14T19:04:52.07831Z","shell.execute_reply.started":"2021-10-14T19:04:52.042516Z","shell.execute_reply":"2021-10-14T19:04:52.077497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-3. Time series data(pressure/ u_in / u_out)\n- from [https://www.kaggle.com/kaitohonda/beginner-lgbm](https://www.kaggle.com/kaitohonda/beginner-lgbm)","metadata":{}},{"cell_type":"code","source":"lst_train = random.sample(set(train['breath_id'].unique()), config.config_size)\nfig, ax = plt.subplots(1, 3, figsize=(30, 6))\nsns.set(font_scale=1.2)\nfor i, num in enumerate(random.sample(lst_train, 3)):\n    df = train[train['breath_id']==num]\n    ax2 = ax[i].twinx()\n\n    sns.lineplot(data=df, x='time_step', y='pressure', label='pressure', ax=ax[i])\n    sns.lineplot(data=df, x='time_step', y='u_in', label='u_in', ax=ax[i])\n    sns.lineplot(data=df, x='time_step', y='u_out', label='u_out', ax=ax2, color='r')\n\n    ax[i].set(xlabel='Timestep', ylabel='pressure, u_in', title=f'breath_id: {num}', xlim=(-0.2, 3.2), ylim=(-5, 105))\n    ax[i].legend(loc=(0.75, 0.7))\n    ax2.legend(loc=(0.75, 0.6))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:52.08098Z","iopub.execute_input":"2021-10-14T19:04:52.081275Z","iopub.status.idle":"2021-10-14T19:04:53.293618Z","shell.execute_reply.started":"2021-10-14T19:04:52.081228Z","shell.execute_reply":"2021-10-14T19:04:53.292842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-4. Preprocessing","metadata":{}},{"cell_type":"code","source":"def log_exp_return(series):\n    return np.exp(np.log1p(series).diff(1).fillna(0))\n\ndef data_clean(df):\n    ## timestepに直線性が無いデータを削除\n    time_step_diff_limit = 0.04\n    non_liner_timestep_breath_ids = list()\n    for k, grp in df.groupby(\"breath_id\"):\n        diff_se = grp[\"time_step\"].diff()\n        diff_chk = diff_se[diff_se > time_step_diff_limit]\n        if len(diff_chk) != 0:\n            non_liner_timestep_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\n    \n    ## 負のpressure値を持つデータを削除\n    minus_pressure_breath_ids = list()\n    for k, grp in df.groupby(\"breath_id\"):\n        m = grp[\"pressure\"].min()\n        if m < 0:\n            minus_pressure_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(minus_pressure_breath_ids)]   \n    \n    ## u_out = 1のstep数が52以上のデータを削除\n    u_out_open_step_counts_over52_breath_ids = list()\n    for k, grp in train.groupby(\"breath_id\"):\n        count = grp.groupby(\"u_out\")[\"id\"].count()[1]\n        if count > 51:\n            u_out_open_step_counts_over52_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(u_out_open_step_counts_over52_breath_ids)] \n    \n    return df\n\n\ndef preprocessing(df):   \n    # time diff\n    df['time_diff'] = df['time_step'].groupby(df['breath_id']).diff(1).fillna(0)\n    \n    # basic parameter\n    df['u_in_ratio'] = df['u_in'].groupby(df['breath_id']).apply(log_exp_return)\n    df['area_unit'] = df['u_in'] * df['time_diff']\n    df['area_ratio'] = df['area_unit'].groupby(df['breath_id']).apply(log_exp_return)\n    \n    # Create Time Windows\n    def create_time_window(df, time_min, time_max, diff_time):\n        feature_dict = {\n                        'u_in': [np.max, np.std], \n                        'area_unit': [np.max, np.std], \n                        'u_in_ratio': [np.prod, np.std],\n                        'area_ratio': [np.prod, np.std]\n                        }\n        for time_stamp in np.arange(time_min, time_max, diff_time):\n            df_tmp = df[['time_step'] + list(feature_dict.keys())][(df['time_step'] >= time_stamp - diff_time) & (df['time_step'] < time_stamp)] \\\n                        .groupby(df['breath_id']).agg(feature_dict)\n            df_tmp.columns = ['_'.join(col) for col in df_tmp.columns]\n            df = pd.merge(df, df_tmp.add_suffix(f'_{time_stamp}_term').reset_index(), on='breath_id', how='left')\n            del df_tmp\n            gc.collect()\n            time.sleep(3)\n\n        return df\n    \n    df = create_time_window(df, 0.5, 2.0, 0.5)\n    \n    # u_in shift change \n    for i in np.arange(1, 5, 1):\n        df[f'u_in_lag_fwrd{i}'] = df['u_in'].groupby(df['breath_id']).shift(i)\n        df[f'u_in_lag_back{i}'] = df['u_in'].groupby(df['breath_id']).shift(int(-i))                                   \n\n        df[f'u_out_lag_fwrd{i}'] = df['u_out'].groupby(df['breath_id']).shift(i)\n        df[f'u_out_lag_back{i}'] = df['u_out'].groupby(df['breath_id']).shift(int(-i))\n        \n        df[f'u_in_diff{i}'] = df['u_in'] - df[f'u_in_lag_fwrd{i}']\n        df[f'u_out_diff{i}'] = df['u_out'] - df[f'u_out_lag_fwrd{i}']      \n\n    # u_in parameter\n    df['last_value_u_in'] = df['u_in'].groupby(df['breath_id']).transform('last')\n    df['first_value_u_in'] = df['u_in'].groupby(df['breath_id']).transform('first')\n    df['u_in_cumsum'] = df['u_in'].groupby(df['breath_id']).cumsum()  \n    df['u_in_diff_max'] = df['u_in'] - df['u_in'].groupby(df['breath_id']).max()\n    df['u_in_diff_ave'] = df['u_in'] - df['u_in'].groupby(df['breath_id']).mean()  \n                                      \n    # u_in area\n    df['last_value_area'] = df['area_unit'].groupby(df['breath_id']).transform('last')\n    df['first_value_area'] = df['area_unit'].groupby(df['breath_id']).transform('first')  \n    \n    df = df.fillna(0)\n    \n    # u_out parameter\n    df['cross_u_in']= df['u_in'] * df['u_out']\n    df['cross_area']= df['area_unit'] * df['u_out']\n    df['cross_time']= df['time_step'] * df['u_out']\n    df['u_out'] = df['u_out'].astype('str')\n    \n    # R, C parameter\n    df['R'] = df['R'].astype('str')\n    df['C'] = df['C'].astype('str')\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df, drop_first=True) \n    \n    return df\n\ntrain = data_clean(train)\ntarget = train[\"pressure\"].values\ntrain = train.drop([\"id\", \"pressure\"], axis=1)\ntrain = preprocessing(train)\ntrain = train.drop(['breath_id'], axis=1)\nfeature_column = train.columns.values","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:53.294622Z","iopub.execute_input":"2021-10-14T19:04:53.295029Z","iopub.status.idle":"2021-10-14T19:04:55.794289Z","shell.execute_reply.started":"2021-10-14T19:04:53.294991Z","shell.execute_reply":"2021-10-14T19:04:55.793562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-5. RobustScaler","metadata":{}},{"cell_type":"code","source":"rs = RobustScaler()\ntrain = rs.fit_transform(train)\nprint(f'train shape: {train.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:55.795677Z","iopub.execute_input":"2021-10-14T19:04:55.796005Z","iopub.status.idle":"2021-10-14T19:04:55.828981Z","shell.execute_reply.started":"2021-10-14T19:04:55.79597Z","shell.execute_reply":"2021-10-14T19:04:55.828072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. LightGBM\n### 2-1. LightGBM class\n- Create Class\n- You can change easier any parameters","metadata":{}},{"cell_type":"code","source":"class LGBM:\n    def __init__(self, feature_column, train, target):\n        self.num_boost_round_optuna = 100\n        if config.optuna_train:\n            self.num_boost_round = 200\n            self.verbose_eval = 100\n        else:\n            self.num_boost_round = 15000\n            self.verbose_eval = 5000\n        self.n_splits = 3\n        self.early_stopping_rounds = 100\n        self.kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=2021)\n        self.boosters = []\n        self.eval_results_lst = []\n        self.feature_column = feature_column\n        self.feature_importance = pd.DataFrame()\n        self.train, self.target = train, target\n        del train, target\n        gc.collect()\n        \n    # Hyperparameter OputunaTunerCV\n    def optuna_tuner(self, params):\n        lgb_trn = lgbo.Dataset(self.train, label=self.target)       \n        study_tuner = optuna.create_study(direction='minimize') \n        tuner =  lgbo.LightGBMTunerCV(params=params, \n                                      train_set=lgb_trn,\n                                      num_boost_round=self.num_boost_round_optuna, \n                                      early_stopping_rounds=self.early_stopping_rounds, \n                                      verbose_eval=self.verbose_eval,\n                                      folds=self.kf,\n                                      study=study_tuner)\n        tuner.run()\n        return tuner.best_params\n        \n    def lgbm_train(self, params, reg):\n        # Lughgbm train\n        for fold, (trn_idx, val_idx) in enumerate(self.kf.split(self.train, self.target)):\n            eval_results = {}\n            print(\"=\"*15 + f' Fold {fold+1} started at {time.ctime()} ' + \"=\"*15)\n            lgb_trn = reg.Dataset(self.train[trn_idx], label=self.target[trn_idx])\n            lgb_val = reg.Dataset(self.train[val_idx], label=self.target[val_idx])\n                        \n            booster = reg.train(params=params, \n                                train_set=lgb_trn, \n                                valid_sets=[lgb_trn, lgb_val],\n                                valid_names=['Train', 'Valid'], \n                                num_boost_round=self.num_boost_round, \n                                early_stopping_rounds=self.early_stopping_rounds, \n                                verbose_eval=self.verbose_eval,\n                                evals_result=eval_results)\n                        \n            self.eval_results_lst.append(eval_results)\n            self.boosters.append(booster)\n            \n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = self.feature_column\n            fold_importance[\"importance\"] = booster.feature_importance()\n            fold_importance[\"fold\"] = fold + 1\n            self.feature_importance = pd.concat([self.feature_importance, fold_importance], axis=0)\n        \n            del lgb_trn, lgb_val, fold_importance, booster, eval_results\n            gc.collect()\n                \n    # Vizualize Importance columns\n    def importance_show(self, top=20):\n        df_tmp = self.feature_importance\n        sns.set(font_scale=1.2)\n        fig, ax = plt.subplots(1, self.n_splits, figsize=(30, 20))\n        for i in range(self.n_splits):\n            df = df_tmp[df_tmp[\"fold\"]==i+1].sort_values('importance', ascending=False)\n            sns.barplot(data=df[:top], x=\"importance\", y=\"feature\", ci=None, ax=ax[i])\n            ax[i].set_title(f\"Fold: {i+1}\")\n        plt.tight_layout()\n        plt.show()\n        \n        del df_tmp\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:55.830667Z","iopub.execute_input":"2021-10-14T19:04:55.830971Z","iopub.status.idle":"2021-10-14T19:04:55.849661Z","shell.execute_reply.started":"2021-10-14T19:04:55.830934Z","shell.execute_reply":"2021-10-14T19:04:55.848808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2-3. LightGBM Train","metadata":{}},{"cell_type":"code","source":"lgbm_inst = LGBM(feature_column, train, target)\n\n# Params base\nbest_params = {\n                'objective': 'regression_l1', \n                'metric': 'l1', \n                'boosting_type': 'gbdt', \n                'verbose': -1, 'random_state': 2021\n              }\n\n# GPU \nif config.gpu_on:\n    best_params.update({'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0})\n\n# TunerCV version\nif config.optuna_tuner:\n    best_params = lgbm_inst.optuna_tuner(best_params)\n\n# Train\nelse:\n    # LightGBM Optuna Train\n    if config.optuna_train:\n        lgbm_inst.lgbm_train(best_params, lgbo)\n    else:\n        best_params.update({\n                            'feature_pre_filter': False, \n                            'lambda_l1': 0.0, \n                            'lambda_l2': 0.0, \n                            'num_leaves': 255, \n                            'feature_fraction': 0.8999999999999999, \n                            'bagging_fraction': 1.0, \n                            'bagging_freq': 0, \n                            'min_child_samples': 20\n                            })\n        lgbm_inst.lgbm_train(best_params, lgb)\n        \ngc.collect()    \nprint(best_params)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:04:56.584855Z","iopub.execute_input":"2021-10-14T19:04:56.585067Z","iopub.status.idle":"2021-10-14T19:10:46.336263Z","shell.execute_reply.started":"2021-10-14T19:04:56.585041Z","shell.execute_reply":"2021-10-14T19:10:46.335538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2-4. Checking overfitting\n- Checking overfitting using eval_results dict","metadata":{}},{"cell_type":"code","source":"if not config.optuna_tuner:\n    fig, ax = plt.subplots(1, lgbm_inst.n_splits, figsize=(30, 6))\n    for i, results in enumerate(lgbm_inst.eval_results_lst):\n        ax[i].plot(np.log(results['Train']['l1']), label='train')\n        ax[i].plot(np.log(results['Valid']['l1']), label='valid')\n        ax[i].set(xlabel=\"Boosting round\", ylabel = 'Log_loss', title = f'Training Fold {i+1}')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:10:46.337489Z","iopub.execute_input":"2021-10-14T19:10:46.337755Z","iopub.status.idle":"2021-10-14T19:10:46.924305Z","shell.execute_reply.started":"2021-10-14T19:10:46.337721Z","shell.execute_reply":"2021-10-14T19:10:46.923651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2-5. Scores & Feature Importance\n- Visualize how each explanatory variable affects the objective function","metadata":{}},{"cell_type":"code","source":"if not config.optuna_tuner:\n    # Score AVE & STD in CV\n    scores = list()\n    for result in lgbm_inst.eval_results_lst:\n        scores.append(result['Valid']['l1'][-1])\n    print('\\n CV mean score: {0:.5f}, std: {1:.5f}.'.format(np.mean(scores), np.std(scores)))\n\n    # Show Importance\n    lgbm_inst.importance_show(top=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:10:46.925459Z","iopub.execute_input":"2021-10-14T19:10:46.925788Z","iopub.status.idle":"2021-10-14T19:10:48.568387Z","shell.execute_reply.started":"2021-10-14T19:10:46.925753Z","shell.execute_reply":"2021-10-14T19:10:48.567664Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2-6. Predict Train data show","metadata":{}},{"cell_type":"code","source":"if  config.config and not config.optuna_tuner:\n    tmp = list()\n    for booster in lgbm_inst.boosters:\n        tmp.append(booster.predict(train, num_iteration=booster.best_iteration))\n\n    train_pred = read_train()\n    train_pred[\"pred_pressure\"] = sum(tmp) /lgbm_inst.n_splits\n    train_pred[\"mae_unit\"] = np.abs(train_pred[\"pred_pressure\"] - train_pred[\"pressure\"])\n    train_pred = pd.merge(train_pred, pd.DataFrame(train_pred.groupby(\"breath_id\")[\"mae_unit\"].mean()).rename(columns={\"mae_unit\": \"mae\"}), how=\"left\", on=\"breath_id\")\n    \n    lst_train_pred = random.sample(set(train_pred['breath_id'].unique()), config.config_size)\n    \n    fig, ax = plt.subplots(2, 3, figsize=(30, 12))\n    sns.set(font_scale=1.2)\n    for i, num in enumerate(random.sample(lst_train_pred , 3)):\n        df = train_pred[train_pred['breath_id']==num]\n\n        sns.lineplot(data=df, x='time_step', y='pressure', label='actual', ax=ax[0, i])\n        sns.lineplot(data=df, x='time_step', y='pred_pressure', label='predict', ax=ax[0, i])\n        sns.lineplot(data=df, x='time_step', y='u_in', label='u_in', ax=ax[0, i])\n        sns.lineplot(x=df['time_step'], y=np.log(df['mae_unit']), label='mae_unit', ax=ax[1, i])\n        ax[0, i].set(xlabel='Timestep', ylabel='pressure, u_in', title=f'breath_id: {num}, MAE: {round(df[\"mae\"].mean(), 3)}', xlim=(-0.2, 3.2))\n        ax[0, i].legend(loc=(0.75, 0.7))\n        ax[1, i].set(xlabel='Timestep', ylabel='mae_unit', title=f'breath_id: {num}, MAE: {round(df[\"mae\"].mean(), 3)}', xlim=(-0.2, 3.2), ylim=(-2.1, 0.6))\n        ax2 = ax[1, i].twinx()\n        sns.lineplot(data=df, x='time_step', y='u_out', label='u_out', ax=ax2, color='r')\n        ax[1, i].legend(loc=(0.75, 0.2))\n        ax2.legend(loc=(0.75, 0.1))\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:12:44.66235Z","iopub.execute_input":"2021-10-14T19:12:44.662615Z","iopub.status.idle":"2021-10-14T19:13:05.320275Z","shell.execute_reply.started":"2021-10-14T19:12:44.662587Z","shell.execute_reply":"2021-10-14T19:13:05.314376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.Submission","metadata":{}},{"cell_type":"code","source":"if not config.optuna_tuner:\n    del train, target\n    gc.collect()\n\n    dtypes.pop(\"pressure\")\n    test = read_test()\n    test = preprocessing(test)\n    test = test.drop([\"id\", 'breath_id'], axis=1)\n    test = rs.transform(test)\n    print(f'test shape: {test.shape}')\n\n    submission = pd.read_csv(config.data_dir + \"sample_submission.csv\")[:test.shape[0]]\n    for booster in lgbm_inst.boosters:\n        submission['pressure'] += booster.predict(test, num_iteration=booster.best_iteration)\n\n    del test\n    gc.collect()\n\n    submission['pressure'] /= lgbm_inst.n_splits\n#   submission[\"pressure\"] = np.round((submission[\"pressure\"] - config.post_processing[\"min_pressure\"]) / config.post_processing[\"diff_pressure\"]) * config.post_processing[\"diff_pressure\"] + config.post_processing[\"min_pressure\"]\n    submission[\"pressure\"] = np.clip(submission[\"pressure\"], config.post_processing[\"min_pressure\"], config.post_processing[\"max_pressure\"])\n    submission.to_csv('submission_lgb.csv', index=False)\n    print(submission.tail(2))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T19:10:48.742675Z","iopub.status.idle":"2021-10-14T19:10:48.743537Z","shell.execute_reply.started":"2021-10-14T19:10:48.743287Z","shell.execute_reply":"2021-10-14T19:10:48.743311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}