{"cells":[{"metadata":{},"cell_type":"markdown","source":"# I) Quick Introduction"},{"metadata":{},"cell_type":"markdown","source":"Why would we complicate things if they are simple? \n\nIs it possible to get great results using one single feature? If yes, how? \n\nWe share this for the diversity and to show that sometimes the usage of advanced ML algorithms is not mandatory.\n\nEventhough the model is simple, it shows good results.\n\nTo understand what that feature is and what is the model that I am using you can check my previous notebook:\nhttps://www.kaggle.com/ffares/exponential-growth-forecasting-using-one-feature where I am explaining the mathematical model, explianing my assumptions and the limits of model.\n\nIf you have any feedback on that please let me know!"},{"metadata":{},"cell_type":"markdown","source":"# II) Preparing the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1) Reading the Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv('../input/covid19-global-forecasting-week-4/train.csv')\ntest = pd.read_csv('../input/covid19-global-forecasting-week-4/test.csv')\n\nY1=train['ConfirmedCases']\nY2=train['Fatalities']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) Modifiying date feature"},{"metadata":{"trusted":false},"cell_type":"code","source":"train['Complete_Date'] = train['Date'].astype('datetime64[ns]')\ntest['Complete_Date'] = test['Date'].astype('datetime64[ns]')\n\nmonth = [int(el[5:7]) for el in list(train['Date'].values)]\nday = [int(el[8:10]) for el in list(train['Date'].values)]\n\nmonth_test = [int(el[5:7]) for el in list(test['Date'].values)]\nday_test = [int(el[8:10]) for el in list(test['Date'].values)]\n\ndf_month= pd.DataFrame(month, columns= ['Month'])\ndf_day= pd.DataFrame(day, columns= ['Day'])\n\ndf_month_test= pd.DataFrame(month_test, columns= ['Month'])\ndf_day_test= pd.DataFrame(day_test, columns= ['Day'])\n\ntrain=pd.concat([train, df_month], axis=1)\ntest=pd.concat([test, df_month_test], axis=1)\n\ntrain=pd.concat([train, df_day], axis=1)\ntest=pd.concat([test, df_day_test], axis=1)\n\ntrain['Date']=train['Month']*100+train['Day']\ntest['Date']=test['Month']*100+test['Day']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3) Combining Province_State and Country_Region in one Feature"},{"metadata":{"trusted":false},"cell_type":"code","source":"train['Province_State'].fillna('',inplace=True)\ntest['Province_State'].fillna('',inplace=True)\n\ntrain['Province_State']=train['Province_State'].astype(str)\ntest['Province_State']=test['Province_State'].astype(str)\n\ny= train['Country_Region']+train['Province_State']\ny= pd.DataFrame(y, columns= ['Place'])\n\ny_test= test['Country_Region']+test['Province_State']\ny_test= pd.DataFrame(y_test, columns= ['Place'])\n\ntrain=pd.concat([train, y], axis=1)\ntest=pd.concat([test, y_test], axis=1)\n\nCountry_df=train[\"Place\"]\nConfirmedCases_df=train[\"ConfirmedCases\"]\nCountry_df.to_numpy()\nConfirmedCases_df.to_numpy()\nCountry=Country_df[0]\nNbDay = pd.DataFrame(columns=['NbDay'])\nday=0\ncount=0\nfor x in train[\"Month\"]:\n    if (ConfirmedCases_df[count]==0):      \n        NbDay = NbDay.append({'NbDay': int(0)}, ignore_index=True)\n        count=count+1 \n    else:\n        if (Country_df[count]==Country):\n            day=day+1\n            NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n            count=count+1\n        else:\n            Country=Country_df[count]\n            day=1\n            NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n            count=count+1\ntrain=pd.concat([train, NbDay], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4) Making a new features counting days since the starting of the pandemic for each region"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Adding NbDay feature to the test data\nNbDay_test_array=np.zeros(test.shape[0])\ni=0\ndf=test[\"Place\"]\nPlace_array=df.to_numpy()\nfor t in test.Date:\n    place=Place_array[i]\n    if t==402:\n        row=train.loc[(train['Place'] == place) & (train['Date'] ==t)]\n        row=row.to_numpy()\n        NbDay_test_array[i]= row[0][10]\n    else: \n        NbDay_test_array[i]=0\n    i=i+1\n\nNbDay=pd.DataFrame(NbDay_test_array, columns=['NbDay1'])\ntest=pd.concat([test,NbDay], axis=1)\n\nCountry_df=test[\"Place\"]\nNbDay_df=test['NbDay1']\nCountry_df.to_numpy()\nday_array=NbDay_df.to_numpy()\nCountry=Country_df[0]\nNbDay = pd.DataFrame(columns=['NbDay'])\nday=0\ncount=0\nfor t in test[\"Date\"]:\n    if (t==402):\n        day=day_array[count] \n        NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)  \n        count=count+1\n    else:\n        day=day+1\n        NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n        count=count+1\ntest=pd.concat([test,NbDay], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5) Taking the essential features for the next steps"},{"metadata":{"trusted":false},"cell_type":"code","source":"train=train[['Place','NbDay','ConfirmedCases','Fatalities']]\ntest=test[['Place','NbDay']]\n\ntrain_data = train\ntest_data = test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# III) Choosing best alphas to fit exponential forecasting "},{"metadata":{},"cell_type":"markdown","source":"## 1) Creating a list of all the countries "},{"metadata":{"trusted":false},"cell_type":"code","source":"country_array=train_data['Place'].to_numpy()\n\ndef distinct_values(country_array):\n    liste=[]\n    liste.append(country_array[0])\n    for i in range(1,len(country_array)): \n        if country_array[i]!=country_array[i-1]:\n            liste.append(country_array[i])\n    return liste\n\n\nCountries_liste=distinct_values(country_array)\n\nlen(Countries_liste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) Finding best alpha1 for each region"},{"metadata":{"trusted":false},"cell_type":"code","source":"def exponentiate_alpha(column,v):\n\n    \n    array=column.to_numpy()\n    \n    string='NbDay'+str(v)\n    \n    array=np.power(v,array)\n        \n    frame=pd.DataFrame(array, columns=[string])\n    \n        \n    return frame\n\nliste_mse_countries=[]\nliste_r2_countries=[]\nresults=[]\n\ni=1\nfor country in Countries_liste:\n    \n    \n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['ConfirmedCases']\n    \n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    alpha=[1+i*0.01 for i in range(1,101)]\n\n    liste_mse_countries=[]\n    liste_r2_countries=[]\n    liste_mse=[]\n    liste_r2=[]\n    liste_rmsle=[]\n    \n    \n    i=i+1\n    \n    for v in alpha: \n    \n        \n        X1=exponentiate_alpha(train_NbDay,v)\n    \n        \n        X_train,X_test,y_train,y_test = train_test_split(X1,y_NbDay,test_size = 0.3, shuffle= False)\n    \n        # Create linear regression object\n        regr = linear_model.LinearRegression()\n\n        # Train the model using the training sets\n        regr.fit(X_train, y_train)\n\n        # Make predictions using the testing set\n        y_pred = regr.predict(X_test)\n        y_pred = np.maximum(y_pred, 0)\n    \n        liste_rmsle.append(np.sqrt(mean_squared_log_error( y_test, y_pred )))\n        \n\n        liste_r2.append(r2_score(y_test, y_pred))\n\n    argmaximum = np.argmax(liste_r2)\n    \n    maximum = liste_r2[argmaximum]\n    minimum = liste_rmsle[argmaximum]\n\n    \n    results.append([country,maximum,minimum,alpha[argmaximum]])\n\ndic_alpha1={}\nfor liste in results: \n    dic_alpha1[liste[0]]=liste[3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3) Finding best alpha2 for each region"},{"metadata":{"trusted":false},"cell_type":"code","source":"liste_mse_countries=[]\nliste_r2_countries=[]\nresults2=[]\n\ni=1\nfor country in Countries_liste:\n    \n    \n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['Fatalities']\n    \n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    alpha=[1+i*0.01 for i in range(1,101)]\n\n    liste_mse_countries=[]\n    liste_r2_countries=[]\n    liste_mse=[]\n    liste_r2=[]\n    liste_rmsle=[]\n    \n    \n    i=i+1\n    \n    for v in alpha: \n    \n        \n        X1=exponentiate_alpha(train_NbDay,v)\n    \n        \n        X_train,X_test,y_train,y_test = train_test_split(X1,y_NbDay,test_size = 0.3, shuffle= False)\n    \n        # Create linear regression object\n        regr = linear_model.LinearRegression()\n\n        # Train the model using the training sets\n        regr.fit(X_train, y_train)\n\n\n        y_pred = regr.predict(X_test)\n        y_pred = np.maximum(y_pred, 0)\n    \n\n        liste_rmsle.append(np.sqrt(mean_squared_log_error( y_test, y_pred )))\n\n        liste_r2.append(r2_score(y_test, y_pred))\n\n    argmaximum = np.argmax(liste_r2)\n    \n    maximum = liste_r2[argmaximum]\n    minimum = liste_rmsle[argmaximum]\n\n    \n    results2.append([country,maximum,minimum,alpha[argmaximum]])\n    \ndic_alpha2={}\nfor liste in results2: \n    dic_alpha2[liste[0]]=liste[3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IV) Forecasting"},{"metadata":{"trusted":false},"cell_type":"code","source":"ConfirmedCasesPredictions=[]\n\ni=1\nfor country in Countries_liste:\n        \n    # Train\n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['ConfirmedCases']\n    \n    \n    # Test\n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    \n    #Best alpha1\n    v= dic_alpha1[country]\n    \n    #Modifiying NbDay for test and train    \n    X1=exponentiate_alpha(train_NbDay,v)\n    X2=exponentiate_alpha(test_NbDay,v)\n\n    \n    # Create linear regression object\n    regr = linear_model.LinearRegression()\n\n    \n    # Train the model using the training sets\n    regr.fit(X1, y_NbDay)\n\n    \n    # Make predictions using the testing set\n    y_pred = regr.predict(X2)\n    y_pred = list(np.maximum(y_pred, 0))\n    ConfirmedCasesPredictions+=y_pred\n    \n    i=i+1\n    \n\n    \nFatalitiesPredictions=[]\n\ni=1\nfor country in Countries_liste:\n        \n    # Train\n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['Fatalities']\n    \n    \n    # Test\n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    \n    #Best alpha1\n    v= dic_alpha2[country]\n    \n    #Modifiying NbDay for test and train    \n    X1=exponentiate_alpha(train_NbDay,v)\n    X2=exponentiate_alpha(test_NbDay,v)\n\n    \n    # Create linear regression object\n    regr = linear_model.LinearRegression()\n\n    \n    # Train the model using the training sets\n    regr.fit(X1, y_NbDay)\n\n    \n    # Make predictions using the testing set\n    y_pred = regr.predict(X2)\n    y_pred = list(np.maximum(y_pred, 0))\n    FatalitiesPredictions+=y_pred\n    \n    i=i+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V) Submission"},{"metadata":{"trusted":false},"cell_type":"code","source":"ConfirmedCases=np.array(ConfirmedCasesPredictions)\nFatalities=np.array(FatalitiesPredictions)\n\nConfirmedCases=pd.DataFrame(ConfirmedCases, columns=['ConfirmedCases'])\nFatalities=pd.DataFrame(Fatalities, columns=['Fatalities'])\n\n# Submission\n\nt = pd.read_csv('../input/covid19-global-forecasting-week-4/test.csv')\n\nId=t['ForecastId']\n\n\nsub = pd.DataFrame()\nsub['ForecastId'] = Id\nsub['ConfirmedCases'] = ConfirmedCases\nsub['Fatalities'] = Fatalities\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}