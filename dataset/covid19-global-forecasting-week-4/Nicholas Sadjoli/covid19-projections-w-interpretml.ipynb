{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Week 4 COVID-19 Prediction with Interpret_ML\nThis notebook will describe attempt at predicting the amount of Confirmed and Fatalities for the 3rd week of the COVID-19 Kaggle Competition, using models created from the [Interpret_ML toolbox](https://github.com/interpretml/interpret)\n\n## Data Sources & Collection\nWe're using data that was collected or scraped from various sources, some of which are courtesy of work already done by other people that will be credited. Other data that we're presenting (and will be appending to the training data) are collected from multiple other sources, using some tools as can be seen in the Github page [here](). The list of sources as well as the sources that we'll be featuring in this notebook are listed here, namely:\n\n1. [Worldometer Coronavirus page](https://www.worldometers.info/coronavirus/), which we believe contains the most updated information on the number of Confirmed and Fatalities that happen globally. As of 5 April, noted to have been updated to contain the latest amount of tests that happen globally, however noted that no time series for all countries are provided yet (in Worldometer itself).\n2. Global climate Data from [Worldbank](https://datahelpdesk.worldbank.org/knowledgebase/articles/902061-climate-data-api). As explained a bit later in the notebook, we believe that a country's current climate condition might have a bit of effect on the spread of the virus.\n3. [Our World in Data](https://ourworldindata.org/covid-testing), who has provided quite an updated time series for the recorded tests conducted by many countries for COVID-19. It is to be noted however, due to not all countries having released test data, only several countries could have their data imputed (and not by region)\n\n## Short Introduction to InterpretML\n[InterpretML](https://github.com/interpretml/interpret) is a Machine Learning toolbox developed by Microsoft Research, with the goal of giving better interpretability to trained Machine Learning models. For COVID-19 forecasting in particular, we believe that this toolbox will provide better understanding of the correlation between many different features and the model's prediction, hopefully helping in answering some of the [scientific questions](https://www.kaggle.com/c/covid19-global-forecasting-week-4/overview/open-scientific-questions) regardng the factors which effect COVID-19 transmission.\n\n[TODO: summarize what InterpretML is, and provide some of the model examples that can be used from the InterpretML toolbox]\n\nFor this notebook, we'll create several models from the [InterpretML toolbox library](https://github.com/interpretml/interpret). These models will be trained using different sets of features (including the default features provided), which will then have their performances be compared to each other.  \n\n## Loading of Interpret_ML.\nFirst ensure that the Interpret_ML toolbox is installed with pip   "},{"metadata":{"tags":["outputPrepend"],"trusted":true},"cell_type":"code","source":"!pip install -U interpret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from interpret import show\nfrom interpret.data import Marginal\nfrom interpret.glassbox import ExplainableBoostingRegressor, LinearRegression, RegressionTree\nfrom interpret.perf import RegressionPerf\n\nimport datetime\nimport math\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\nimport copy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Appending of the the Training Dataset with other Features\nNow that Interpret_ML has been installed, let's first review and take note of the training and test data that has been provided by default, to see what features could be extracted for use later."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \n\ntrain_default_path = \"../input/covid19-global-forecasting-week-4/train.csv\"\ntest_default_path = \"../input/covid19-global-forecasting-week-4/test.csv\"\n\ntrain_default_data = pd.read_csv(train_default_path)\n#train_default_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_default_data = pd.read_csv(test_default_path)\n#test_default_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From looking at these data, it can be seen that the number of previously known number of Confirmed and Fatalities would be the main default features that could be extracted and used. Based on expert opinions as well as various other works however, it seems that these features would not be sufficient in accurately predicting the total amount of Confirmed and Fatalities in the future.\n\nHence, additional data features would be required. In this notebook, several of the additional data features that we've collected can be seen below:\n\n### 1.a. Weather features\nThanks to the work by David Bonin (Kaggle user [davidbn92](https://www.kaggle.com/davidbnn92)) in his [notebook](https://www.kaggle.com/davidbnn92/weather-data/output), a variation of the training data that has been appended with Weather/climate features of all regions has been provided. As noted in their page, these weather data are courtesy of [NOAA GSOD readings](https://www.kaggle.com/noaa/gsod), which has been appended to the training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_appended_df = pd.read_csv(\"../input/training-data-appended/training_data_with_weather_info_week_4.csv\")\nprint(\"Current columns:\", train_appended_df.columns)\n#train_appended_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_unique_regions = train_appended_df['Province_State'].unique()\n#training_data_unique_regions, len(training_data_unique_regions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As per noted by David in his work, the weather features that were added included the following:\n\n- ```temp```: Mean temperature for the day in degrees Fahrenheit to tenths.\n- ```max```: Maximum temperature reported during the day in Fahrenheit to tenths--time of max temp report varies by country and region, so this will sometimes not be the max for the calendar day.\n- ```min```: Minimum temperature reported during the day in Fahrenheit to tenths--time of min temp report varies by country and region, so this will sometimes not be the min for the calendar day.\n- ```stp```: Mean station pressure for the day in millibars to tenths.\n- ```slp```: Mean sea level pressure for the day in millibars to tenths.\n- ```dewp```: Mean dew point for the day in degrees Fahrenheit to tenths.\n- ```wdsp```: Mean wind speed for the day in knots to tenths.\n- ```prcp```: Total precipitation (rain and/or melted snow) reported during the day in inches and hundredths; will usually not end with the midnight observation--i.e., may include latter part of previous day. .00 indicates no measurable precipitation (includes a trace).\n- ```fog```: Indicators (1 = yes, 0 = no/not reported) for the occurrence during the day\n\nThe reason to include weather data for COVID-19 prediction would is because of some previous research (example of such paper [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2916580/)) linking the coronavirus family having [seasonality period](https://www.bbc.com/future/article/20200323-coronavirus-will-hot-weather-kill-covid-19), with indication that warmer weather could [slow down](https://www.theguardian.com/world/2020/apr/05/scientists-ask-could-summer-heat-help-beat-covid-19) the transmission of the virus. However, similarly there has been caution by health experts that this might not be [true](https://www.sciencenews.org/article/coronavirus-warm-weather-will-not-slow-covid-19-transmission). \n\nAs such, we'll investigate using the InterpretML toolbox to see the correlation between any of these weather effect with COVID-19 forecasting.\n\n### 1.b. Population Data \nSpecifically, the Population Density for each region. Hypothetically, a region that has a higher population density should in theory have a higher chance of faster COVID-19 transmission. For consistency, we'll be mainly using the countries' and regions' population and population density data that was recorded by [Worldometer](https://www.worldometers.info/world-population/population-by-country/) from their respective country pages. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"population_df = pd.read_csv(\"../input/covid19populationtestingdataset/Worldometer_Population_Regional_Latest.csv\")\n#population_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#list the unique regions in the population_df DataFrame, while also removing the 'All_Regions' tag (which indicate it's the population of the whole country, and not just a region)\npopdf_unique_regions = population_df['Region'].unique()\npopdf_unique_regions = np.sort(popdf_unique_regions[popdf_unique_regions != 'All_Regions'])\nprint(\"All {} unique regions recorded:\".format(str(len(popdf_unique_regions))))\nprint(popdf_unique_regions, \"True Victoria\" in popdf_unique_regions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(Note that 'All_regions' mean that the data shown in that particular row applies to the whole country, not just a particular region in that country)\n\nHowever, as can be seen it is noted that Worldometer doesn't seem to provide the Population Density features recorded for regional levels. Hence, for countries with regions in the training data, we'll instead use the countries' and regions' population data as of 2019 provided by OECD on their [Region and Cities](https://stats.oecd.org/Index.aspx?DataSetCode=REGION_DEMOGR#) page. It is noted that these would not likley reflect the lates population density for all region/provinces in the training data. However, we believe the difference in population density for these regions between 2019 and 2020 should be minimal enough such that the the difference should be rather minimal. A reliable source that could help with this would be helpful as an input/feedback.\n\nNote that OECD divides the regions into 2 types: T2 (Large) and T3 (Small) Regions. Let's take a glimpse at the population density records for all region types in 2019 first."},{"metadata":{"trusted":true},"cell_type":"code","source":"population_density_area_df = pd.read_csv(\"../input/covid19populationtestingdataset/OECD_PopulationDensity_and_Area-T2_T3_Regions-2018_2019.csv\")\nprint(\"Columns available:\", population_density_area_df.columns)\npopulation_density_area_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Limit to only population density data, and in Year 2019 only\npopulation_density_only = population_density_area_df[population_density_area_df[\"VAR\"] == \"POP_DEN\"]\npopulation_density_only.drop(['SEX', 'Gender', 'POS', 'Position', 'PowerCode Code', 'Reference Period Code', 'Reference Period'], axis=1)\npopulation_density_2019 = population_density_only[population_density_only[\"Year\"] == 2019]\npopulation_density_unique_regions = population_density_2019['Region'].unique()\nprint(\"All unique {} regions recorded for OECD's population density data: \".format(str(len(population_density_unique_regions))), \n                                                                                    population_density_unique_regions)\npopulation_density_2019.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding these population data into the modified training_data:"},{"metadata":{"tags":["outputPrepend"],"trusted":true},"cell_type":"code","source":"#train_appended_df = train_appended_df.copy()\n#Initiate new feature columns\nadded_features = ['Population (2020)', 'Population Density']\nfor feature in added_features:\n    train_appended_df[feature] = 0\n\nfor country in train_appended_df['Country_Region'].unique():\n    #print(train_appended_df['Population (2020)'].unique())\n    country_segment = train_appended_df[train_appended_df['Country_Region'] == country]\n\n    #Sanity check for several countries, as they're apparently named quite differently in Worldometers vs the training data\n    if country == \"Burma\":\n        country = \"Myanmar\" #Burma in Training data is actually Myanmar. History stuff I guess?\n    elif country == \"Korea, South\":\n        country = \"South Korea\" #this one is honestly just trolling at this point...\n    elif country == \"US\":\n        country = \"United States\"\n\n    population_df_country = population_df[population_df['Country (or dependency)'] == country]#['Region'] == 'All_Regions'\n\n    #check whehter the current country has any listed states/regions in the original training data.\n    #If yes: Add regional population and regional population density data\n    #If not: Only add country population and population density data.\n    country_regions_training = list(country_segment['Province_State'].unique())\n\n    #Apparently there are 2 'Congo'-s: Republic of Congo/Brazzaville, vs DEMOCRATIC Republic of Congo/Zaire (as how it's differentiated in Worldometers)\n    if country == \"Congo (Brazzaville)\": \n        country = \"Congo\"\n        country_regions_training = [\"Brazzaville\"]\n    elif country == \"Congo (Kinshasa)\":\n        country = \"Congo\"\n        country_regions_training = [\"Kinshasa\"]\n\n    if country_regions_training == [np.NaN]:\n        #print(country, country_regions_training)\n        \n        #sanity check: in case country isn't listed in the worldometers population data, \n        #then query to the population_df would return DataFrame of 0\n        if len(population_df_country) != 0:\n            try:\n                country_population = int(population_df_country[population_df_country['Region'] == \"All_Regions\"][\"Population (2020)\"].values[0].replace(\",\", \"\")) \n            except:\n                print(\"Problematic country for pop. df\", country, country_regions_training)\n            try:\n                country_population_density = population_df_country[population_df_country['Region'] == \"All_Regions\"][\"Density (P/KmÂ²)\"].values[0]\n            except:\n                print(\"Problematic country for pop_density df\", country, country_regions_training)\n                break\n        else:\n            continue\n            \n        country_ids = country_segment.index.tolist()\n        train_appended_df.loc[country_ids, ['Population (2020)']] = country_population\n        train_appended_df.loc[country_ids, ['Population Density']] = country_population_density\n    else:\n        for region in country_regions_training:\n            region_segment = country_segment[country_segment['Province_State'] == region]\n\n            #sanity check, as apparently the region names are not truly unique to a country in Worldometer's data\n            #(in particular, the region 'Victoria' which is unique to Australia in training data, is not present in Worldometer's Australia,\n            # and instead available for other countries.)\n            if region == \"Australian Capital Territory\":\n                region_popdf_segment = population_df_country[population_df_country['Region'] == \"Canberra\"]\n            else:\n                region_popdf_segment = population_df_country[population_df_country['Region'] == region]\n            region_popdensity_segment = population_density_2019[population_density_2019['Region'] == region]\n\n            if len(region_popdf_segment) == 1: #Means that there is a valid row available in Worldometer's population_data\n                region_population = int(region_popdf_segment[\"Population (2020)\"].values[0].replace(\",\", \"\") )\n                #region_population = int(population_df_country[population_df_country['Region'] == region][\"Population (2020)\"].values[0].replace(\",\", \"\"))\n            else:\n                region_population = np.NaN\n            \n\n            if len(region_popdensity_segment) == 1:\n                region_population_density = region_popdensity_segment['Value'].values[0]#population_density_2019[population_density_2019['Region'] == region]['Value'].values[0]\n            elif len(region_popdensity_segment) > 1:\n                picked_segment = region_popdensity_segment[region_popdensity_segment[\"Territory Level and Typology\"] == \"Large regions (TL2)\"]\n                region_population_density = picked_segment['Value'].values[0]\n            else:\n                region_population_density = np.NaN\n\n            region_ids = region_segment.index.tolist()\n            train_appended_df.loc[region_ids, ['Population (2020)']] = region_population\n            train_appended_df.loc[region_ids,['Population Density']] = region_population_density\ntrain_appended_df\n#print(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.c. Testing Data\nTesting is a very important step in detecting and (hopefully) reducing the spread of COVID-19. In particular, development of *rapid* and *accurate* tests, that is *highly accessible* to the public has been [touted](https://www.heart.org/en/news/2020/04/02/covid-19-science-why-testing-is-so-important) by [a lot](https://www.id-hub.com/2020/04/02/the-importance-of-diagnostic-testing-for-covid-19/) of [experts](https://www.weforum.org/agenda/2020/04/united-states-coronavirus-bill-gates/) as one of the critical key steps that a country should focus on, to combat the COVID-19 spread.\n\nAs such, we suspect a high correlation between the amount of tests (as well as the test accuracy) against the forecasting/prediciton capabilities a model could have for COVID-19, and decided to also include the test data that has been provided by a variety of countries. Of course, it could be argued that increasing amount of tests would logically also increase the amount of *detected* confirmed cases, however faster tests should hypothetically allow for less amount of fatalities since faster and better handling of the confirmed patients should theoretically be doable.\n\nFor this, we'll be using the test data provided from OurWorldinData, which has provided testing data from several countries via their [COVID-19 page](https://ourworldindata.org/covid-testing). The testing data is also available in their [github repo](https://github.com/owid/covid-19-data/tree/master/public/data/testing)\n\nFirst, let's see the testing data from OurWorldinData. It is to be noted that since their dataset is collected from various different sources, OurWorldinData has kindly provided their source details [here](https://github.com/owid/covid-19-data/blob/master/public/data/testing/covid-testing-latest-data-source-details.csv), which is also updated daily. For now, we'll take a look at the dataset numbers taht they've provided instead below."},{"metadata":{"trusted":true},"cell_type":"code","source":"ourworldindata_testing_df = pd.read_csv(\"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/testing/covid-testing-all-observations.csv\")\nourworldindata_testing_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separating the entity into regions and their codes instead would give better readibility"},{"metadata":{"trusted":true},"cell_type":"code","source":"#ourworldindata_testing_df['Entity'].unique()[0].split(\"-\")[0].rstrip().lstrip()\ncolumns_to_be_added = ['Data Type', 'Country']\nfor column in columns_to_be_added:\n    if column not in ourworldindata_testing_df.columns:\n        ourworldindata_testing_df.insert(1, column, '')\nfor i in ourworldindata_testing_df.index:\n    entity_data = ourworldindata_testing_df.loc[i]['Entity'].split(\"-\")\n    ourworldindata_testing_df.loc[i, ['Country']] = entity_data[0].rstrip().lstrip()\n    ourworldindata_testing_df.loc[i, ['Data Type']] = entity_data[1].rstrip().lstrip()\n    \nourworldindata_testing_df = ourworldindata_testing_df.drop(['Entity'], axis=1)\nprint(ourworldindata_testing_df.columns)\nourworldindata_testing_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most interesting and perhaps crucial features that could be extracted from this dataset are the cumulative and daily changes in the number of tests performed by each country. Unfortunately this data doesn't provide the level of testing on a regional level, hence not all not all countries and regions in the training data would have their data points appended properly.\n\nNow we'll be appending all the features from OurWorldinData. We'd like to once again note that the OurWorldinData is not on a regional level, hence only countries not listed with its regions in the training dataset by default would have the OurWorldinData features appended.\n\nAppending OurWorldinData features first:\n(Note: Several countries are noted to be listed with different type of test data provided at once - e.g. include Japan, US and Singapore. For cases like this, we'll be prioritizing test data that shows the total tests performed for the cumulative total instead.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ourworldindata_features_to_append = ['Cumulative Total Tests', 'Daily Change in Cumulative Total Tests', 'Cumulative Tests per Thousand', 'Daily change in Cumulative Tests per Thousand', '3-day rolling mean daily change', '3-day rolling mean daily change per thousand']\n\nfor feature in ourworldindata_features_to_append:\n    train_appended_df[feature] = 0.0\n\nfor country in train_appended_df['Country_Region'].unique():\n    #print(train_appended_df['Population (2020)'].unique())\n    country_segment = train_appended_df[train_appended_df['Country_Region'] == country]\n\n    #Sanity check for South Korea, as they're apparently named quite differently in Worldometers vs the training data\n    if country == \"Korea, South\":\n        country = \"South Korea\" \n    elif country == \"US\":\n        country = \"United States\"\n    \n    #sanity check for case of United Kingdom\n    if country == \"United Kingdom\":\n        country_segment = country_segment[country_segment['Province_State'].isnull()]\n        #print(country_segment)\n\n    #check whehter the current country has any listed states/regions in the original training data. For ourworldindata tests, only countries \n    #*without* regions in the training data will be used and appended.\n    country_regions_training = list(country_segment['Province_State'].unique())\n\n    #OWID dataset only covers country level (and not regional level). Hence, only countries without regions will be appended.\n    if country_regions_training == [np.NaN]:\n        ourworldindata_country_segment = ourworldindata_testing_df[ourworldindata_testing_df['Country'] == country]\n        country_ids = country_segment.index\n\n        #sanity check: in case country isn't listed in the worldometers population data, \n        #then query to the population_df would return DataFrame of 0\n        if len(ourworldindata_country_segment) != 0:\n\n            #print(country_ids) #ourworldindata_country_segment)\n            for cur_id in country_ids:\n                cur_date = train_appended_df.loc[cur_id]['Date']\n                owid_test_data = ourworldindata_country_segment[pd.to_datetime(ourworldindata_country_segment['Date']) == cur_date]\n\n                if country == \"Japan\":\n                    owid_test_data = owid_test_data[owid_test_data['Data Type'] == 'tests performed']\n                elif country == \"Singapore\":\n                    owid_test_data = owid_test_data[owid_test_data['Data Type'] == 'swabs tested']\n                elif country == \"United States\":\n                    owid_test_data = owid_test_data[owid_test_data['Data Type'] == 'inconsistent units (COVID Tracking Project)']\n\n                \n                #sanity check for dates that were not recorded in ourworldindata's dataset\n                if len(owid_test_data) != 0:\n                    train_appended_df.loc[cur_id, ['Cumulative Total Tests']] = owid_test_data['Cumulative total'].values[0]\n                    train_appended_df.loc[cur_id, ['Daily Change in Cumulative Total Tests']] = owid_test_data['Daily change in cumulative total'].values[0]\n                    train_appended_df.loc[cur_id, ['Cumulative Tests per Thousand']] = owid_test_data['Cumulative total per thousand'].values[0]\n                    train_appended_df.loc[cur_id, ['Daily change in Cumulative Tests per Thousand']] = owid_test_data['Daily change in cumulative total per thousand'].values[0]\n                    train_appended_df.loc[cur_id, ['3-day rolling mean daily change']] = owid_test_data['3-day rolling mean daily change'].values[0]\n                    train_appended_df.loc[cur_id, ['3-day rolling mean daily change per thousand']] = owid_test_data['3-day rolling mean daily change per thousand'].values[0]\n                else:\n                    train_appended_df.loc[cur_id, ourworldindata_features_to_append] = 0.0\n\n        else:\n            continue\n            \n    else:\n        pass\n\ntrain_appended_df[train_appended_df['Country_Region'] == \"Korea, South\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Interlude: The Problem of Missing Values\n\nThere are some missing values in some of the appended features. <br> Since interpretml doesn't support missing features, we need to fill these missing values when we can. <br>\n\nWeather:\n* Fill in max, min with temp\n* Too many missing values for slp,dewp,rh,ah, so we won't use it\n\nPopulation: \n* Population (2020): <br>\nUnfortunately the population that we gathered contained quite a number of missing values, since the labelling of the regions from our appended data differ quite greatly from the ones used by the default training data. InterpretML has a limitation in that it cannot really use missing values. Hence, we'll be omitting features related to population for now, with future work hopefully able to resolving this issue.\n\nTesting Data:\nSimilar to the issue noted for Population feature, there are missing values in the Testing Data due to different countries not yet sharing full testing data. We'll be omitting this for now, but the appended training data will be available for use at the end of this notebook, for those who want to improve upon it."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_dummy = \"max\"\nmissing_index = np.where(train_appended_df[feature_dummy].isnull())[0]\ntrain_appended_df.at[missing_index,feature_dummy] = train_appended_df[\"temp\"][missing_index]\n\nfeature_dummy = \"min\"\nmissing_index = np.where(train_appended_df[feature_dummy].isnull())[0]\ntrain_appended_df.at[missing_index,feature_dummy] = train_appended_df[\"temp\"][missing_index]\n\n\"\"\"\nfeature_dummy = \"Population Density\"\nmissing_index = np.where(train_appended_df[feature_dummy].isnull())[0]\nmissing_country_province = train_appended_df[\"country+province\"][missing_index].unique()\nfor reg in missing_country_province:\n    mask_ = train_appended_df[\"country+province\"] == reg\n    mask_ix_ = np.where(mask_)[0]\n    mask_country_ = train_appended_df[\"country+province\"] == reg.split('')\n    if(len(np.where())):\n        replacement = \n    else:\n        print(\"No replacement found for {}\".format(reg))\n    train_appended_df[feature_dummy].at[mask_ix_,feature_dummy] = \n\"\"\"\n#np.where(train_appended_df[\"country+province\"] ==\"Australia\")\n\n#feature_dummy = \"Population (2020)\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Prepare features and observe which feature is significant\nFirst we prepare the features. Note that we also add 'previous confirmed cases' and 'previous fatalities' as additional features. <br>\n\nThen we can observe which feature is significant by looking at the pearson correlation and data visualization using the built in function provided by interpretml."},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df,\n               features = ['Days','Region',\"prev_ConfirmedCases\",\"prev_Fatalities\"],\n               targets = [\"ConfirmedCases\", \"Fatalities\"]):\n\n    # Create category called Region: country_province\n    region_list = [\"{}_{}\".format(df[\"Country_Region\"][i], df[\"Province_State\"][i]) for i in range(df.shape[0])]\n    df[\"Region\"]=region_list\n\n    # Get first day of corona virus for each region\n    unique_region_list = list(set(region_list))\n    unique_region_list.sort()\n    first_date_dict = {}\n    for region in unique_region_list:\n        mask = df[\"Region\"]==region\n        first_ix = np.where(df[mask][\"ConfirmedCases\"]>0)[0][0] -1    \n        first_date = df[mask][\"Date\"].iloc[first_ix]\n        first_date_dict[region] = first_date\n\n    # add column \"Days\": number of days since the first day of case per each region\n    def get_days(dt):\n        return dt.days\n    dummy = [first_date_dict[region] for region in df[\"Region\"]]\n    df[\"Days\"]=(pd.to_datetime(df['Date'])-pd.to_datetime(dummy)).apply(get_days)\n\n    # Add previous confirmed cases and previous fatalities to df\n    loc_group=[\"Region\"]\n    for target in targets:\n        df[\"prev_{}\".format(target)] = df.groupby(loc_group)[target].shift()\n        df[\"prev_{}\".format(target)].fillna(0, inplace=True)\n    \n    for target in targets:\n        df[target] = np.log1p(df[target])\n        df[\"prev_{}\".format(target)] = np.log1p(df[\"prev_{}\".format(target)])\n    \n    X = df[features]\n    Y = df[targets]\n    \n    return X,Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Region',\"prev_ConfirmedCases\",\"prev_Fatalities\",\n            'Days',\"day_from_jan_first\",\n            \"temp\",\"max\",\"min\",\"prcp\",\"stp\",\"prcp\",\"fog\",\"wdsp\", # weather\n            \"Lat\",\"Long\"]\nX,Y = preprocess(train_appended_df,features=features)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"marginal = Marginal().explain_data(X, Y[\"ConfirmedCases\"],\"ConfirmedCases\")\nshow(marginal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observing the data above, we can conclude that the weather data is not significant."},{"metadata":{},"cell_type":"markdown","source":"## Train and Predict with Explainable Boosting Machine (EBM)"},{"metadata":{},"cell_type":"markdown","source":"We will not use all the features we test above. But we use only \"important\" features"},{"metadata":{"trusted":true},"cell_type":"code","source":"important_features = ['Region',\"prev_ConfirmedCases\",\"prev_Fatalities\",\n                        'Days',\n                        \"Lat\",\"Long\"]\nX = X[important_features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To have a prediction of the accuracy of our prediction model, we split the original data into train and validation. We train our model using the train data. Then we make prediction on the validation data and report our validation error. <br>\n\nFor the actual prediction on the test data, we train our model using the whole data (before splitting)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_train_val(X,Y, unique_region_list,num_of_val_days):\n    \n    train_ix = []\n    val_ix = []\n    for region in unique_region_list:\n        \n        mask = X[\"Region\"]==region\n        ix = np.where(mask)[0]\n        \n        train_ix += list(ix[:-num_of_val_days].flatten())\n        val_ix += list(ix[-num_of_val_days:].flatten())\n        \n    return X.iloc[train_ix],X.iloc[val_ix],Y.iloc[train_ix],Y.iloc[val_ix]    \n\n# IMPORTANT NOTE: We can only use prev_ConfirmedCases for the first day to predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTANT NOTE: assuming that X_features is sorted by number of days \"Days\"\nENFORCE_CONSTRAINT = True\nseed = 1\ndef evaluate_rmse(Y_predicted,Y_true):\n    \"\"\"\n    Y_predicted: n-by-d n is the number of data points, d is the number of criteria\n    Y_true: n-by-d\n    OUTPUT\n    d elements\n    \"\"\"\n    return np.sqrt(mean_squared_error(Y_predicted,Y_true,multioutput='raw_values'))\n\ndef predict(X_features,Y,num_validation_days,num_days_to_predict):\n    unique_region_list = list(set(X_features[\"Region\"]))\n    unique_region_list.sort()\n    print(\"No of unique region list: {}\".format(len(unique_region_list)))\n    \n    ##################################################################\n    # Train and Validation\n    ##################################################################\n    # Split to train and validation\n    X_train,X_val,Y_train,Y_val = split_train_val(X,Y, unique_region_list,num_validation_days)\n    \n    # Train\n    model_ConfirmedCases = ExplainableBoostingRegressor(random_state=seed)\n    model_ConfirmedCases.fit(X_train,Y_train[\"ConfirmedCases\"])\n    model_Fatalities = ExplainableBoostingRegressor(random_state=seed)\n    model_Fatalities.fit(X_train,Y_train[\"Fatalities\"])\n    \n    # Predict for val\n    Y_val_predicted = np.zeros((X_val.shape[0],2))\n    \n    for i in range(X_val.shape[0]):\n        \n        if(i==0 or X_val.iloc[i-1][\"Region\"] != X_val.iloc[i][\"Region\"]):\n            pred_ConfirmedCases = model_ConfirmedCases.predict(X_val.iloc[[i]])[0]\n            pred_Fatalities = model_Fatalities.predict(X_val.iloc[[i]])[0]\n            \n            if(ENFORCE_CONSTRAINT):\n                if(pred_ConfirmedCases<X_val.iloc[[i]][\"prev_ConfirmedCases\"].item()):\n                    pred_ConfirmedCases = 1.*X_val.iloc[[i]][\"prev_ConfirmedCases\"].item()\n                if(pred_Fatalities<X_val.iloc[[i]][\"prev_Fatalities\"].item()):\n                    pred_Fatalities = X_val.iloc[[i]][\"prev_Fatalities\"].item()\n                    \n        else:\n            X_dummy  = X_val.iloc[[i]].copy(deep=True)\n            X_dummy[\"prev_ConfirmedCases\"] = pred_ConfirmedCases\n            X_dummy[\"prev_Fatalities\"] = pred_Fatalities\n            pred_ConfirmedCases = model_ConfirmedCases.predict(X_dummy)\n            pred_Fatalities =model_Fatalities.predict(X_dummy)\n        \n            if(ENFORCE_CONSTRAINT):\n                if(pred_ConfirmedCases<X_dummy[\"prev_ConfirmedCases\"].item()):\n                    pred_ConfirmedCases = 1.* X_dummy[\"prev_ConfirmedCases\"].item()\n                if(pred_Fatalities<X_dummy[\"prev_Fatalities\"].item()):\n                    pred_Fatalities = X_dummy[\"prev_Fatalities\"].item()\n                    \n        Y_val_predicted[i,0] = pred_ConfirmedCases\n        Y_val_predicted[i,1] = pred_Fatalities\n        \n    # Report validation accuracy\n    val_rmse = evaluate_rmse(Y_val,Y_val_predicted)\n    \n    ##################################################################\n    # Train w Full Model and Predict for Test\n    ##################################################################\n    # Train with full data\n    model_full_ConfirmedCases = ExplainableBoostingRegressor(random_state=seed)\n    model_full_ConfirmedCases.fit(X_features,Y[\"ConfirmedCases\"])\n    model_full_Fatalities = ExplainableBoostingRegressor(random_state=seed)\n    model_full_Fatalities.fit(X_features,Y[\"Fatalities\"])\n    \n    # Predict for test\n    Y_test_predicted = np.zeros((len(unique_region_list)*num_days_to_predict,2))\n    count=0\n    for region in unique_region_list:\n        mask = X_features[\"Region\"]==region\n        \n        prev_ConfirmedCase_ = Y[mask][\"ConfirmedCases\"].iloc[-1]\n        prev_Fatality_ = Y[mask][\"Fatalities\"].iloc[-1]\n        \n        #print(prev_ConfirmedCase_,np.exp(prev_ConfirmedCase_)-1, prev_Fatality_, np.exp(prev_Fatality_)-1)\n        \n        X_dummy = X[mask].iloc[[-1]].copy(deep=True)\n        X_dummy[\"prev_ConfirmedCases\"] = prev_ConfirmedCase_\n        X_dummy[\"prev_Fatalities\"] = prev_Fatality_\n        X_dummy[\"Days\"] = X_dummy[\"Days\"]+1\n        \n        pred_ConfirmedCases = model_full_ConfirmedCases.predict(X_dummy)\n        pred_Fatalities = model_full_Fatalities.predict(X_dummy)\n        \n        if(ENFORCE_CONSTRAINT):\n            if(pred_ConfirmedCases<X_dummy[\"prev_ConfirmedCases\"].item()):\n                pred_ConfirmedCases = X_dummy[\"prev_ConfirmedCases\"].item()\n            if(pred_Fatalities<X_dummy[\"prev_Fatalities\"].item()):\n                pred_Fatalities = X_dummy[\"prev_Fatalities\"].item()\n                \n        Y_test_predicted[count,0] = pred_ConfirmedCases\n        Y_test_predicted[count,1] = pred_Fatalities\n        count = count+1\n        \n        for days_ahead in range(2,num_days_to_predict+1):\n            \n            X_dummy[\"prev_ConfirmedCases\"] = pred_ConfirmedCases\n            X_dummy[\"prev_Fatalities\"] = pred_Fatalities\n            X_dummy[\"Days\"] = X_dummy[\"Days\"]+1\n            pred_ConfirmedCases = model_full_ConfirmedCases.predict(X_dummy)\n            pred_Fatalities = model_full_Fatalities.predict(X_dummy)\n            \n            if(ENFORCE_CONSTRAINT):\n                if(pred_ConfirmedCases<X_dummy[\"prev_ConfirmedCases\"].item()):\n                    pred_ConfirmedCases = X_dummy[\"prev_ConfirmedCases\"].item()\n                if(pred_Fatalities<X_dummy[\"prev_Fatalities\"].item()):\n                    pred_Fatalities = X_dummy[\"prev_Fatalities\"].item()\n                \n            Y_test_predicted[count,0] = pred_ConfirmedCases\n            Y_test_predicted[count,1] = pred_Fatalities\n            \n            count = count+1\n      \n    assert count==len(Y_test_predicted), \"Something wrong\"\n    \n\n    return unique_region_list,X_val,Y_val,Y_val_predicted,val_rmse,Y_test_predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_days_to_predict = 43\nnum_validation_days = 10\nunique_region_list,X_val,Y_val,Y_val_predicted,val_rmse,Y_test_predicted=predict(X,Y,num_validation_days,num_days_to_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation error\nprint(\"RMSE for ConfirmedCases and Fatalities: {}\".format(val_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is the final value ConfirmedCases and Fatalities\n# Convert back to linear scale\nY_test_predicted_final = np.exp(Y_test_predicted)-1\nY_val_predicted_final = np.exp(Y_val_predicted)-1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Result Visualization"},{"metadata":{},"cell_type":"markdown","source":"We visualize the result of our model here by plotting the actual data, our validation prediction, and the test prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import gridspec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose using region_ix\n#region_ix = 3\n#region = unique_region_list[region_ix]\n\n# Choose using region\nregion = \"Indonesia_nan\"\nregion_ix = unique_region_list.index(region)\n\nUSE_LOG_SCALE=False\nPLOT_LINE = False\n##############################################\n\nmask = X[\"Region\"]==region\nN = Y[mask].shape[0]\nx_ = np.arange(N+num_days_to_predict)\n\nvalidation_confirmed_cases = Y_val_predicted_final[region_ix*num_validation_days:(region_ix+1)*num_validation_days,0]\nvalidation_fatalities = Y_val_predicted_final[region_ix*num_validation_days:(region_ix+1)*num_validation_days,1]\npredicted_confirmed_cases = Y_test_predicted_final[region_ix*num_days_to_predict:(region_ix+1)*num_days_to_predict,0]\npredicted_fatalities = Y_test_predicted_final[region_ix*num_days_to_predict:(region_ix+1)*num_days_to_predict,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sz = 8\ngs  = gridspec.GridSpec(1, 2, width_ratios=[1, 1],wspace=0.25)\nfig = plt.figure(figsize=(12,5))\nax1 = fig.add_subplot(gs[0,0])\nax2 = fig.add_subplot(gs[0,1])\nif(USE_LOG_SCALE):\n    ax1.set_yscale('log')\n    ax2.set_yscale('log')\nax1.scatter(x_[:N],np.exp(Y[mask][\"ConfirmedCases\"])-1, label=\"Real Data\",s=sz)\nax1.scatter(x_[N:],predicted_confirmed_cases, label=\"Predicted\",s=sz)\nax1.scatter(x_[N-num_validation_days:N],validation_confirmed_cases,label=\"Validation\",s=sz)\nif(PLOT_LINE):\n    ax1.plot(x_[:N],np.exp(Y[mask][\"ConfirmedCases\"])-1, label=\"Real Data\")\n    ax1.plot(x_[N:],predicted_confirmed_cases, label=\"Predicted\")\n    ax1.plot(x_[N-num_validation_days:N],validation_confirmed_cases,label=\"Validation\")\nax1.set_title(region+\"Confirmed Cases\")\nax1.legend()\n\nax2.scatter(x_[:N],np.exp(Y[mask][\"Fatalities\"])-1, label=\"Real Data\",s=sz)\nax2.scatter(x_[N:],predicted_fatalities, label=\"Predicted\",s=sz)\nax2.scatter(x_[N-num_validation_days:N],validation_fatalities,label=\"Validation\",s=sz)\nif(PLOT_LINE):\n    ax2.plot(x_[:N],np.exp(Y[mask][\"Fatalities\"])-1, label=\"Real Data\")\n    ax2.plot(x_[N:],predicted_fatalities, label=\"Predicted\")\n    ax2.plot(x_[N-num_validation_days:N],validation_fatalities,label=\"Validation\")\n\nax2.set_title(region+\"Fatalities\")\nax2.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission\nsubmission = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\nsubmission['ConfirmedCases'] = Y_test_predicted_final[:, 0]\nsubmission['Fatalities'] = Y_test_predicted_final[:,1]\ntrain_appended_df.to_csv(\"appended_training_week4.csv\")\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Concluding Notes:\n\nFrom our work, it can be seen that weather data have a low correlation for predicting the spread of COVID-19 overall (Confirmed and Fatalities), thanks to the help of the InterpretML toolbox that was able to estimate the correlation for each features used. There are other features that we'd like to test, however due to the incomplete data that InterpretML currently doesn't support, we're instead omitting those features and have provided the appended training data at the end of this notebook, for use by people who would like to update this better.\n\nWe understand that the data from [The COVID Tracking Project](https://covidtracking.com/ ) exists for the US region specifically. However, since the majority of other countries don't seem to have as detailed features of testing data yet (at least based on data gathered from the OurWorldinData dataset), we have chosen to omit those data for now. Usage of such data would be one step we believe the forecasting/predicition of the COVID-19 spread could be improved. "},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"file_extension":".py","kernelspec":{"display_name":"Python 3.6.9 64-bit ('covid19_forecast': virtualenv)","language":"python","name":"python36964bitcovid19forecastvirtualenvb3ff07c470b54162a144309f090d5d1b"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9-final"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":4}