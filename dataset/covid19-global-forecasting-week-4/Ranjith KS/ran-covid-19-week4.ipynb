{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH_WEEK4 = '/kaggle/input/covid19-global-forecasting-week-4'\n\ndf_Train = pd.read_csv(f'{PATH_WEEK4}/train.csv', parse_dates=[\"Date\"], engine='python')\ndf_Test = pd.read_csv(f'{PATH_WEEK4}/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train.rename(columns={'Country_Region':'Country'}, inplace=True)\ndf_Test.rename(columns={'Country_Region':'Country'}, inplace=True)\n#df_Covid19.rename(columns={'Country/Region':'Country', 'ObservationDate': 'Date'}, inplace=True)\n#df_Covid19.replace({'Country': 'Mainland China'}, 'China', inplace=True)\n#df_Covid19.replace({'Country': 'Taiwan'}, 'Taiwan*', inplace=True)\n\nEMPTY_VAL = \"EMPTY_VAL\"\n\ndf_Train.rename(columns={'Province_State':'State'}, inplace=True)\ndf_Train['State'].fillna(EMPTY_VAL, inplace=True)\ndf_Train['State'] = df_Train.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\ndf_Test.rename(columns={'Province_State':'State'}, inplace=True)\ndf_Test['State'].fillna(EMPTY_VAL, inplace=True)\ndf_Test['State'] = df_Test.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\n#df_Covid19.rename(columns={'Province/State':'State'}, inplace=True)\n#df_Covid19['State'].fillna(EMPTY_VAL, inplace=True)\n#df_Covid19['State'] = df_Test.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n#df_Covid19.replace({'State': 'Taiwan*'}, 'Taiwan*', inplace=True)\n\n#df_Train['Date'] = pd.to_datetime(df_Train['Date'], infer_datetime_format=True) # as pd.read_csv does parsed 'Date' as dates\ndf_Test['Date'] = pd.to_datetime(df_Test['Date'], infer_datetime_format=True) # dtype('Date') would be object, adnd we need to explicitly convert object to date as we did not use parse_dates\n#df_Covid19['Date'] = pd.to_datetime(df_Covid19['Date'], infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_groupByCountry = df_Train.loc[:, ['Country', 'State', 'ConfirmedCases', 'Fatalities']].groupby(['Country', 'State']).max().reset_index().groupby('Country').sum().sort_values(by='ConfirmedCases', ascending=False).reset_index()\ndf_groupByCountry[:15].style.background_gradient(cmap='viridis_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ncountries = df_groupByCountry.Country.unique().tolist()\ndf_plot = df_Train.loc[(df_Train.Country.isin(countries[:10])) & (df_Train.Date >= '2020-03-11'), ['Date', 'Country', 'State', 'ConfirmedCases', 'Fatalities']].groupby(['Date', 'Country', 'State']).max().reset_index().groupby(['Date', 'Country']).sum().sort_values(by='ConfirmedCases', ascending=False).reset_index()\n\nfig = px.bar(df_plot, x=\"Date\", y=\"ConfirmedCases\", color=\"Country\", barmode=\"stack\")\nfig.update_layout(title='Rise of Confirmed Cases around top 10 countries', annotations=[dict(x='2020-03-21', y=150, xref=\"x\", yref=\"y\", text=\"Coronas Rise exponentially from here\", showarrow=True, arrowhead=1, ax=-150, ay=-150)])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train.loc[: , ['Country', 'State', 'ConfirmedCases', 'Fatalities']].groupby(['Country', 'State']).max().reset_index().nlargest(15, \"ConfirmedCases\").style.background_gradient(cmap='nipy_spectral')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ndf_plot = df_Train.loc[: , ['Date', 'Country', 'ConfirmedCases', 'Fatalities']].groupby(['Date', 'Country']).max().reset_index()\n\ndf_plot.loc[:, 'Date'] = df_plot.Date.dt.strftime(\"%Y-%m-%d\")\ndf_plot.loc[:, 'Size'] = np.power(df_plot[\"ConfirmedCases\"]+1,0.3)-1 #np.where(df_plot['Country'].isin(['China', 'Italy']), df_plot['ConfirmedCases'], df_plot['ConfirmedCases']*300)\n\nfig = px.scatter_geo(df_plot,\n                     locations=\"Country\",\n                     locationmode = \"country names\",\n                     hover_name=\"Country\",\n                     color=\"ConfirmedCases\",\n                     animation_frame=\"Date\", \n                     size='Size',\n                     #projection=\"natural earth\",\n                     title=\"Rise of Coronavirus Confirmed Cases\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ncountries = df_groupByCountry.Country.unique().tolist()\ndf_plot = df_Train.loc[df_Train.Country.isin(countries[:10]), ['Date', 'Country', 'ConfirmedCases']].groupby(['Date', 'Country']).max().reset_index()\n\nfig = px.line(df_plot, x=\"Date\", y=\"ConfirmedCases\", color='Country')\nfig.update_layout(title='No.of Confirmed Cases per Day for Top 10 Countries',\n                   xaxis_title='Date',\n                   yaxis_title='No.of Confirmed Cases')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ncountries = df_groupByCountry.Country.unique().tolist()\ndf_plot = df_Train.loc[df_Train.Country.isin(countries[:10]), ['Date', 'Country', 'Fatalities']].groupby(['Date', 'Country']).max().reset_index()\n\nfig = px.scatter(df_plot, x=\"Date\", y=\"Fatalities\", color='Country')\nfig.update_layout(title='No.of Fatalities per Day for Top 10 Countries',\n                   xaxis_title='Date',\n                   yaxis_title='No.of Fatalities')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MIN_TEST_DATE = df_Test.Date.min()\n\ndf_train = df_Train.loc[df_Train.Date < MIN_TEST_DATE, :]\ny1_Train = df_train.iloc[:, -2]\ny2_Train = df_train.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extractDate(df, colName = 'Date'):\n    \"\"\"\n    This function does extract the date feature in to multiple features\n    - week, day, month, year, dayofweek\n    \"\"\"\n    assert colName in df.columns\n    df = df.assign(week = df.loc[:, colName].dt.week,\n                   day = df.loc[:, colName].dt.day,\n                   month = df.loc[:, colName].dt.month,\n                   #year = df.loc[:, colName].dt.year,\n                   dayofweek = df.loc[:, colName].dt.dayofweek)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createNewDataset(df):\n    \"\"\"\n    This function does create a new dataset for modelling.\n    \"\"\"\n    df_New = df.copy()\n    \n    #df_New = extractDate(df_New)\n    #df_New.loc[:, 'Date_Int'] = (df_New.loc[:, 'Date'].dt.strftime(\"%m%d\")).astype('int16')\n    #df_New.drop(columns=['Date'], axis=1, inplace=True)\n    \n    #df_New.loc[:, 'Country_State'] = df_New.loc[:, 'Country'] + '_' + df_New.loc[:, 'State']\n    #df_New.loc[:, 'Country_State'] = df_New[[\"State\", \"Country\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1]),axis=1)\n    #df_New.drop(columns=['Country', 'State'], axis=1, inplace=True)\n    \n    return df_New","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train = createNewDataset(df_train)\nX_Test = createNewDataset(df_Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RMSLE(pred, actual):\n    return np.sqrt(np.mean(np.power((np.log(pred + 1) - np.log(actual + 1)), 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from xgboost import XGBRegressor\nfrom sklearn import preprocessing\n#from sklearn.model_selection import ShuffleSplit, cross_val_score\n\nLEncoder = preprocessing.LabelEncoder()\n#skfold = ShuffleSplit(random_state=7)\n\ncountries = X_Train.Country.unique().tolist()\n\ndf_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nfor country in countries:\n    states = X_Train.loc[X_Train.Country == country, :].State.unique().tolist()\n    for state in states:\n        categoricalFeatures = ['Country', 'State']\n        \n        # Train\n        X_Train_CS = X_Train.loc[(X_Train.Country == country) & (X_Train.State == state), :]\n        #X_Train_CS.loc[:, 'Country_State'] = X_Train_CS.loc[:, [\"State\", \"Country\"]].apply(lambda row: row[0] + \"_\" + row[1],axis=1)\n        \n        y1_Train_CS = X_Train_CS.loc[:, 'ConfirmedCases']\n        y2_Train_CS = X_Train_CS.loc[:, 'Fatalities']\n        X_Train_CS.drop(columns=['Id', 'ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n        #X_Train_CS.drop(columns=categoricalFeatures, axis=1, inplace=True)\n        \n        X_Train_CS.loc[:, 'Country'] = LEncoder.fit_transform(X_Train_CS.loc[:, 'Country'])\n        X_Train_CS.loc[:, 'State'] = LEncoder.fit_transform(X_Train_CS.loc[:, 'State'])\n        #X_Train_CS.loc[:, 'Country_State'] = LEncoder.fit_transform(X_Train_CS.loc[:, 'Country_State'])\n        \n        # Test\n        X_Test_CS = X_Test.loc[(X_Test.Country == country) & (X_Test.State == state), :]\n        #X_Test_CS.loc[:, 'Country_State'] = X_Test_CS.loc[:, [\"State\", \"Country\"]].apply(lambda row: row[0] + \"_\" + row[1],axis=1)\n\n        X_Test_CS_Id = X_Test_CS.loc[:, 'ForecastId']\n        X_Test_CS.drop(columns=['ForecastId'], axis=1, inplace=True)\n        #X_Test_CS.drop(columns=categoricalFeatures, axis=1, inplace=True)\n\n        X_Test_CS.loc[:, 'Country'] = LEncoder.fit_transform(X_Test_CS.loc[:, 'Country'])\n        X_Test_CS.loc[:, 'State'] = LEncoder.fit_transform(X_Test_CS.loc[:, 'State'])\n        #X_Test_CS.loc[:, 'Country_State'] = LEncoder.fit_transform(X_Test_CS.loc[:, 'Country_State'])\n\n        # Model fit & predict\n        model1 = XGBRegressor(n_estimators=1250)\n        #results = cross_val_score(model1, X_Train_CS, y1_Train_CS, cv=skfold)\n        #print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n        \n        model1.fit(X_Train_CS, y1_Train_CS)\n        y1_pred = model1.predict(X_Test_CS)\n\n        model2 = XGBRegressor(n_estimators=1000)\n        #results = cross_val_score(model2, X_Train_CS, y2_Train_CS, cv=skfold)\n        \n        model2.fit(X_Train_CS, y2_Train_CS)\n        y2_pred = model2.predict(X_Test_CS)\n        \n        # Output Dataset\n        df = pd.DataFrame({'ForecastId': X_Test_CS_Id, 'ConfirmedCases': y1_pred, 'Fatalities': y2_pred})\n        df_out = pd.concat([df_out, df], axis=0)\n    # Done for state loop\n# Done for country Loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n\ndf_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\ni = 0\ncountries = X_Train.Country.unique().tolist()\nfor country in countries:\n    states = X_Train.loc[X_Train.Country == country, :].State.unique().tolist()\n    for state in states:       \n        # Train\n        X_Train_CS = X_Train.loc[(X_Train.Country == country) & (X_Train.State == state), :]\n        confirmed = X_Train_CS.groupby('Date')['ConfirmedCases'].sum().reset_index()\n        fatalities = X_Train_CS.groupby('Date')['Fatalities'].sum().reset_index()\n        futureDays = (df_Test.Date.max() - X_Train_CS.Date.max()).days\n        \n        confirmed.columns = ['ds', 'y']\n        confirmed['ds'] = pd.to_datetime(confirmed['ds'])\n        \n        # Confirmed Model fit & predict\n        model1 = Prophet(interval_width=0.95)\n        model1.fit(confirmed)\n        futureConfirmed = model1.make_future_dataframe(periods=futureDays)\n        forecastConfirmed = model1.predict(futureConfirmed)\n        \n        # Fatalities Model fit & predict\n        fatalities.columns = ['ds', 'y']\n        fatalities['ds'] = pd.to_datetime(fatalities['ds'])\n        \n        model2 = Prophet(interval_width=0.95)\n        model2.fit(fatalities)\n        futureFatalities = model2.make_future_dataframe(periods=futureDays)\n        forecastFatalities = model2.predict(futureFatalities)\n        \n        # print(confirmed)\n        # print(forecastConfirmed.loc[:, ['ds', 'yhat', 'yhat_lower', 'yhat_upper']])\n        # print(forecastFatalities.loc[:, ['ds', 'yhat', 'yhat_lower', 'yhat_upper']])\n        \n        # model1.plot(forecastConfirmed)\n        # model1.plot_components(forecastConfirmed)\n        # print(forecastConfirmed[['ds', 'yhat']][(-1 * futureDays):])\n        \n        # Output Dataset\n        X_Test_CS = X_Test.loc[(X_Test.Country == country) & (X_Test.State == state), :]\n        X_Test_CS_Id = X_Test_CS.loc[:, 'ForecastId']\n        \n        y1_pred = forecastConfirmed['yhat'][(-1 * futureDays):].values\n        y2_pred = forecastFatalities['yhat'][(-1 * futureDays):].values\n        df = pd.DataFrame({'ForecastId': X_Test_CS_Id, 'ConfirmedCases': y1_pred, 'Fatalities': y2_pred})\n        df_out = pd.concat([df_out, df], axis=0)\n        \n        i += 1\n        print(f'{i:03}; Predicting the {country} - {state}')\n        # print(df)\n        # break\n    # Done for state loop\n    # break\n# Done for country Loop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.ForecastId = df_out.ForecastId.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_out.iloc[np.r_[42, 45, 97, 143, 175, 267, 327, 350, 420, 450, 540, 590, 680, 730, 2880, 2900, 2960, 3000, 3050, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000], :]\ndf_out.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}