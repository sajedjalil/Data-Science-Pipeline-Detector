{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Hello** Welcome to my kernel this is my first **Proper** kernel with some EDA and choropleth maps  DO UPVOTE IF YOU LIKE IT :D\nlet's dive into what I have done below i have simply loaded the kaggle provided datasets"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Below I have taken the india part out of the dataframe provided and did some plotting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df[\"Country_Region\"]==\"India\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nindia_df=train_df[train_df[\"Country_Region\"]==\"India\"]\n\n#india_df[\"day\"]=india_df[\"Date\"].apply(lambda x:int(x[-2:]) )\n#india_df[\"Month\"]=india_df[\"Date\"].apply(months )\nindia_df[\"ConfirmedCases\"]=india_df[\"ConfirmedCases\"].apply(lambda x: int(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NOW IN THIS WHOLE NOTEBOOK I HAVE SPLIT THE DATE INTO WEEKS.....IF YOU SEE WEEK 4 IT MEANS IT IS THE 4th WEEK OF THE YEAR!!!!! NOT MONTH**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nindia_df[\"Date\"]=india_df['Date'].apply(lambda x:datetime.strptime(x, '%Y-%m-%d'))\n\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below I have made a week column and added it to the dataframe and did some simple plottings I have done  using SEABORN CATPLOT"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nindia_df[\"week\"]=\"week_\"+ str(india_df[\"Date\"].dt.week)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india_df[\"week\"]=india_df[\"Date\"].dt.week.apply(lambda x: x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#fig.set_size_inches(12, 18)\nsns.catplot(data=india_df.groupby([\"week\"]).max().reset_index(),x=\"week\",y=\"ConfirmedCases\",kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"day\"]=train_df[\"Date\"].apply(lambda x:int(x[-2:]) )\n#train_df[\"Month\"]=train_df[\"Date\"].apply(months )\ntrain_df[\"ConfirmedCases\"]=train_df[\"ConfirmedCases\"].apply(lambda x: int(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(data=india_df.groupby([\"week\"]).max().reset_index(),x=\"week\",y=\"Fatalities\",kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.drop(\"Province_State\",axis=1)\nfrom datetime import datetime\nfrom datetime import datetime\ntrain_df[\"Date\"]=train_df['Date'].apply(lambda x:datetime.strptime(x, '%Y-%m-%d'))\n\ntrain_df[\"week\"]=\"week_\"+ str(train_df[\"Date\"].dt.week)\ntrain_df[\"week\"]=train_df[\"Date\"].dt.week.apply(lambda x: x)\ntrain_df[\"day\"]=train_df[\"Date\"].dt.day.apply(lambda x: x)\ntrain_df[\"month\"]=train_df[\"Date\"].dt.month.apply(lambda x: int(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.drop(\"Date\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below I have used Plotly to create a CHOROPLETH Map of The CoronaVirus to the latest week "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\ncountry_df=train_df.groupby(['Country_Region', 'week']).max().reset_index().sort_values('week', ascending=False)\n\ncountry_df = country_df.drop_duplicates(subset = ['Country_Region'])\ncountry_df = country_df[country_df['ConfirmedCases']>0]\n\ndata = dict(type='choropleth',\nlocations = country_df['Country_Region'],\nlocationmode = 'country names', z = country_df['ConfirmedCases'],\ntext = country_df['Country_Region'], colorbar = {'title':'CONFIRMED CASES'},\ncolorscale=[[0, 'rgb(224,255,255)'],\n            [0.01, 'rgb(166,206,227)'], [0.02, 'rgb(31,120,180)'],\n            [0.03, 'rgb(178,223,138)'], [0.05, 'rgb(51,160,44)'],\n            [0.10, 'rgb(251,154,153)'], [0.20, 'rgb(255,255,0)'],\n            [1, 'rgb(227,26,28)']],    \nreversescale = False\n           )\nlayout = dict(title='COVID-19 CASES AROUND THE WORLD',\ngeo = dict(showframe = True, projection={'type':'mercator'}))\nchoromap = go.Figure(data = [data], layout = layout)\niplot(choromap, validate=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This again using plotly I have created the map which you can interact with the slider to see how the spread of coronavirus has affected the Countries starting from the 4th week of the year that was in January and till now in April** YOU CAN HOVER FOR INFO OF THE CASES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countrydate = train_df[train_df['ConfirmedCases']>0]\ndf_countrydate = df_countrydate.groupby(['week','Country_Region']).max().reset_index()\ndf_countrydate\n\nfig = px.choropleth(df_countrydate, \n                    locations=\"Country_Region\", \n                    locationmode = \"country names\",\n                    color=\"ConfirmedCases\", \n                    hover_name=\"Country_Region\", \n                    animation_frame=\"week\",\n                   color_continuous_scale=\"Greens\"\n                   )\nfig.update_layout(\n    title_text = 'Global Spread of Coronavirus',\n    title_x = 0.5,\n    geo=dict(\n        showframe = False,\n        showcoastlines = False,\n    ))\n    \nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countrydate[df_countrydate[\"Country_Region\"]==\"India\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I would like to thank Mr. SRK for the dataset on COVID-19 IN INDIA ===>  https://www.kaggle.com/sudalairajkumar/covid19-in-india which i have used below"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_india=pd.read_csv(\"/kaggle/input/covid19-in-india/covid_19_india.csv\")\n\ndf_india[\"Date\"]=df_india['Date'].apply(lambda x:datetime.strptime(x, '%d/%m/%y'))\n\ndf_india[\"week\"]=\"week_\"+ str(df_india[\"Date\"].dt.week)\ndf_india[\"week\"]=df_india[\"Date\"].dt.week.apply(lambda x: x)\ndf_india.head()\ndf_india_grouped=df_india.groupby([\"State/UnionTerritory\",\"week\"]).max().reset_index().sort_values(\"week\",ascending=False)\ndf_india_grouped=df_india_grouped.drop_duplicates(subset=[\"State/UnionTerritory\"])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The Bar Plot provides info About the Statewise Confirmed Cases, You can hover on them **"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_india_grouped\nfig = px.scatter(df_india_grouped, x=\"Confirmed\", y=\"State/UnionTerritory\", \n                 title=\"COVID CASES CONFIRMED IN INDIAN STATES\",\n                 labels={\"COVID CASES CONFIRMED IN INDIAN STATES\"} # customize axis label\n                )\n\nfig = px.bar(df_india_grouped, x='Confirmed', y='State/UnionTerritory',\n             hover_data=['Confirmed', 'State/UnionTerritory'], color='Confirmed', orientation='h',\n             text=\"Confirmed\", height=1400)\nfig.update_traces( textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='show')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I have added a new column called ***pending*** which is basically how many patients are still being treated , I am going to use this in the below piechart I have created for each state depicting the states and how many cases are cured, deaths and pending"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_india_grouped[\"pending\"]=df_india_grouped[\"Confirmed\"]-df_india_grouped[\"Deaths\"]-df_india_grouped[\"Cured\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''df_india_grouped\nlabels=df_india_grouped[\"State/UnionTerritory\"]\nvalues=df_india_grouped[\"Confirmed\"]\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\nfig.show()'''\n\n\nl=list(df_india_grouped[\"State/UnionTerritory\"])\nfig = make_subplots(rows=11, cols=3,subplot_titles=l,specs=[[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}],[{'type':'domain'}, {'type':'domain'},{'type':'domain'}]])\na=1\nb=1\n\nfor i in l:\n    \n    \n    temp_df=df_india_grouped[df_india_grouped[\"State/UnionTerritory\"]==i]\n    #print(int(temp_df[\"Deaths\"]))\n    values=[int(temp_df[\"Deaths\"]),int(temp_df[\"Cured\"]),int(temp_df[\"pending\"])]\n    labels=[\"Deaths\",\"Cured\",\"pending\"]\n \n    #annot.append(dict(text=i,font_size=10, showarrow=False))\n    \n    fig.add_trace(go.Pie(labels=labels, textposition=\"inside\",values=values, name=i),a, b)\n    \n    if b==3 and a<11:\n        a=a+1\n   \n      \n    if b+1>3:\n        b=1\n    else:\n        b=b+1\n   \n    fig.update_traces(hole=.4)\n\nfig.update_layout(\n    \n    height=1900,width=1000\n)\nfig.update(layout_title_text='StateWise analysis of Positive cases')\n\n\n#fig = go.Figure(fig)\nfig.show()\n#iplot(fig)   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_df=pd.read_csv(\"/kaggle/input/covid19-in-india/StatewiseTestingDetails.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_df[\"Date\"]=testing_df['Date'].apply(lambda x:datetime.strptime(x, '%Y-%m-%d'))\n\ntesting_df[\"week\"]=\"week_\"+ str(testing_df[\"Date\"].dt.week)\ntesting_df[\"week\"]=testing_df[\"Date\"].dt.week.apply(lambda x: x)\ntesting_df.head()\ntesting_df_grouped=testing_df.groupby([\"State\",\"week\"]).max().reset_index().sort_values(\"week\",ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_df_grouped=testing_df_grouped.drop_duplicates(subset=[\"State\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states=list(testing_df_grouped[\"State\"])\n\nfig = go.Figure(data=[\n    \n    go.Bar(name='Negative', x=states, y=list(testing_df_grouped[\"Negative\"])),\n    go.Bar(name='Positive', x=states, y=list(testing_df_grouped[\"Positive\"])),\n])\n\nfig.update_layout(barmode='stack')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it is time to plot another choropleth map but this time for India staetwise, for this I added a dataset containing the shape files indian state "},{"metadata":{"trusted":true},"cell_type":"code","source":"import geopandas as gpd\nshapefile=\"/kaggle/input/india-shape/ind_shape/IND_adm1.shp\"\ngdf=gpd.read_file(shapefile)[[\"NAME_1\",\"geometry\"]]\n\ngdf.columns = ['states','geometry']\ngdf.loc[31,\"states\"]=\"Telengana\"\ngdf.loc[34,\"states\"]=\"Uttarakhand\"\ngdf.loc[25,\"states\"]=\"Odisha\"\n\n#gdf[gdf[\"states\"]==\"Orissa\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below I have merged the Geopandas dataframe containing geometry and state names with our dataset of covid-19 indian states and used a json converted to convert it into json"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_grouped = gdf.merge(df_india_grouped, left_on = 'states', right_on = 'State/UnionTerritory').drop([\"Date\"],axis=1)\nimport json\nmerged_json_grouped = json.loads(merged_grouped.to_json())\njson_data_grouped = json.dumps(merged_json_grouped)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have used Bokeh instaed of plotly  here instead of plotly to demonstarte another method that we can create Choropleth map although we can see it requires more code and can get complicated"},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.io import output_notebook, show, output_file\nfrom bokeh.plotting import figure\nfrom bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar,LabelSet\nfrom bokeh.palettes import brewer\nfrom bokeh.models import Slider, HoverTool\ngeosource = GeoJSONDataSource(geojson = json_data_grouped)\npalette = brewer['YlGnBu'][8]\npalette = palette[::-1]\ncolor_mapper = LinearColorMapper(palette = palette, low = 0, high = max(merged_grouped[\"Confirmed\"]))\n\ntick_labels = {'0': '0', '100': '100', '200':'200', '400':'400', '800':'800', '1200':'1200', '1400':'1400','1800':'1800', '2000': '2000'}\nhover = HoverTool(tooltips = [ ('states','@states'),('Confirmed_Cases', '@Confirmed')])\ncolor_bar = ColorBar(color_mapper=color_mapper, label_standoff=8,width = 500, height = 20,\nborder_line_color=None,location = (0,0), orientation = 'horizontal', major_label_overrides = tick_labels)\n\np = figure(title = 'CoronaVirus Confirmed States(HOVER MOUSE FOR INFO)', plot_height = 600 , plot_width = 950, toolbar_location = None,tools=[hover])\np.xgrid.grid_line_color = None\np.ygrid.grid_line_color = None\n\n\np.patches('xs','ys', source = geosource,fill_color = {'field' :'Confirmed', 'transform' : color_mapper},name=\"states\",\n          line_color = 'black', line_width = 0.25, fill_alpha = 1)\nlabels = LabelSet(x='xs', y='ys', text='states',\n              x_offset=5, y_offset=5, source=geosource)\n\np.add_layout(color_bar, 'below')\noutput_notebook()\n#Display figure.\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_df=df_india.groupby([\"week\",\"State/UnionTerritory\"]).max().reset_index()\ncountry_df.drop([\"Date\",\"ConfirmedIndianNational\",\"ConfirmedForeignNational\",\"Deaths\",\"Cured\",\"Time\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now over here the same way we created the animation of the world map before , we want to create it similary for inidian states, we are using plotly instead of Bokeh because for Bokeh we needed to create a bokeh server to get that interactivity , but we can simply get it more easily with plotly\nALSO NOTE:**** Below in the code i have used geoseries function SIMPLIFY() as the plot created was very laggy due to the multiploygon geometry of the indian states so using SIMPLIFY(Tolerance=0.02) which kind of straightens some wiggles and curves to a line, but still I think a 0.02 tolerance provides an accurate shape of the map "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nshapefile=\"/kaggle/input/india-shape/ind_shape/IND_adm1.shx\"\ngdf=gpd.read_file(shapefile)[[\"NAME_1\",\"geometry\"]]\ngdf[\"geometry\"]=gdf[\"geometry\"].simplify(0.02, preserve_topology=True)\ngdf\ngdf.columns = ['states','geometry']\ngdf.loc[31,\"states\"]=\"Telengana\"\ngdf.loc[34,\"states\"]=\"Uttarakhand\"\ngdf.loc[25,\"states\"]=\"Odisha\"\nmerged_grouped = gdf#.merge(df_india_grouped[[\"State/UnionTerritory\",\"geo\"]], left_on = 'states', right_on = 'State/UnionTerritory')\n\nmerged_json_grouped = json.loads(merged_grouped.to_json())\njson_data_grouped = json.dumps(merged_json_grouped)\nfor i in merged_json_grouped[\"features\"]:\n    i[\"id\"]=i[\"properties\"][\"states\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_df=df_india.groupby([\"State/UnionTerritory\",\"week\"]).max().reset_index().sort_values(\"week\",ascending=True)\n\ncountry_df=country_df.drop(['Sno', 'Date', 'Time',\n       'ConfirmedIndianNational', 'ConfirmedForeignNational', 'Cured',\n       'Deaths',],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This Map created using plotly is interactive starting from week 4 , we can see it started from kerala and within few week it was massively spread over the Indian States"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.choropleth(country_df, geojson=merged_json_grouped,\n                    locations=\"State/UnionTerritory\", \n                    \n                    color=\"Confirmed\", \n                    hover_name=\"State/UnionTerritory\", \n                    animation_frame=\"week\",\n                   color_continuous_scale=[\"yellow\",\"orange\",\"red\"],\n                     labels={'Confirmed':'Confirmed'}\n                    \n                \n                         \n                      \n                   )\nfig.update_geos(fitbounds=\"locations\", visible=False,projection_type=\"natural earth\")   \nfig.update_layout(\n    title_text = 'India Spread of Coronavirus',\n    title_x = 0.5,\n    geo=dict(\n        showframe = False,\n        showcoastlines = False,\n    ))\n \nfig.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we go for modelling our data , I am going to use XGBOOST although I am still working and on different models so this could be updated again , If you have any suggestions please do tell me in the comments :D"},{"metadata":{"trusted":true},"cell_type":"code","source":"newtestdf=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\nnewtestdf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"using inbuilt pandas encoder i encoded the names of the country regions"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I took inspiration of the hyperparamters from here https://www.kaggle.com/pradeepkumarrajkumar/xgb-regressor\n"},{"metadata":{},"cell_type":"markdown","source":"We scale using minmaxscaler and also transform the country data into numeric using label encoding(not get_dummies as i did not get a good score before :D)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler\ntrain_df['ConfirmedCases'] = train_df['ConfirmedCases'].apply(int)\ntrain_df['Fatalities'] = train_df['Fatalities'].apply(int)\ncases = train_df.ConfirmedCases\nfatal=train_df.Fatalities\n\nlb = LabelEncoder()\n\ndel train_df[\"Fatalities\"]\ndel train_df[\"ConfirmedCases\"]\n#del train_df[\"Id\"]\ntrain_df['Country_Region'] = lb.fit_transform(train_df['Country_Region'])\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(train_df.drop([\"Id\",\"week\"],axis=1).values)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nmodel = XGBRegressor(n_estimators = 2500 , random_state = 0 , max_depth = 27)\nmodel.fit(X_train,cases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_train,cases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"newtestdf[\"Date\"]=newtestdf['Date'].apply(lambda x:datetime.strptime(x, '%Y-%m-%d'))\n\nnewtestdf[\"week\"]=\"week_\"+ str(newtestdf[\"Date\"].dt.week)\nnewtestdf[\"week\"]=newtestdf[\"Date\"].dt.week.apply(lambda x: x)\nnewtestdf[\"day\"]=newtestdf[\"Date\"].dt.day.apply(lambda x: x)\nnewtestdf[\"month\"]=newtestdf[\"Date\"].dt.month.apply(lambda x: int(x))\nnewtestdf['Country_Region'] = lb.fit_transform(newtestdf['Country_Region'])\nnewtestdf=newtestdf.drop([\"Province_State\",\"Date\"],axis=1)\nnewtestdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = scaler.fit_transform(newtestdf.drop([\"ForecastId\",\"week\"],axis=1).values)\ncases_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases_pred = np.around(cases_pred,decimals = 0)\nx_train_cas = []\nfor i in range(len(X_train)):\n    x = list(X_train[i])\n    x.append(cases[i])\n    x_train_cas.append(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_cas = np.array(x_train_cas)\nmodel = XGBRegressor(n_estimators = 2500 , random_state = 0 , max_depth = 27)\nmodel.fit(x_train_cas,fatal)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_cas = []\nfor i in range(len(X_test)):\n    x = list(X_test[i])\n    x.append(cases_pred[i])\n    x_test_cas.append(x)\nx_test_cas[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_cas = np.array(x_test_cas)\nfatalities_pred =model.predict(x_test_cas)\nfatalities_pred = np.around(fatalities_pred,decimals = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmission = pd.read_csv(\"../input/covid19-global-forecasting-week-4/submission.csv\")\nsubmission['ConfirmedCases'] = cases_pred\nsubmission['Fatalities'] = fatalities_pred\nsubmission.to_csv(\"submission.csv\" , index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"THANK YOU :D PLEASE DO UPVOTE!!!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"THANK YOU!!!!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}