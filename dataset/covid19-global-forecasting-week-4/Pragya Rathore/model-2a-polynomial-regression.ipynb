{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Necessary Libraries","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"operation_mode = 'final';\n# operation_mode = 'validation';","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import TransformerMixin, BaseEstimator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_log_error","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/train.csv');\ndf_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-4/test.csv');\ndf_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Date'] = pd.to_datetime(df_train['Date'], format = '%Y-%m-%d');\ndf_test['Date'] = pd.to_datetime(df_test['Date'], format = '%Y-%m-%d');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine Country and Province\ndef combine_country_province(df):\n    df.loc[:,'Province_State'] = df['Province_State'].fillna(\"\")\n    df.loc[:,'Region'] = df['Country_Region'] + \" \" + df['Province_State']\n    df.loc[:,'Region'] = df.loc[:,'Region'].str.strip();\n    return df;\n    \ndf_train = combine_country_province(df_train);\ndf_test = combine_country_province(df_test);\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A transformer which will give the number of days as integer for ML methods to work efficiently.\nclass Days_Since_P0_World(BaseEstimator, TransformerMixin):  \n    \"\"\"Add num of days column based on date column , since a integer column will fit Data Techniques better.\n    \"\"\"\n    def __init__(self):\n        self.p_zero_date = None;\n        self.col_name = 'days_since_p0_world';\n        pass\n\n    def fit(self, X, y=None ):\n        self.p_zero_date = X['Date'].min()\n        return self;\n    \n    def transform(self, X ):\n        X[self.col_name] = X['Date']  -  self.p_zero_date;\n        X.loc[:,self.col_name] = X[self.col_name].dt.days;\n        return X;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_since_p0_world = Days_Since_P0_World()\ndf_train = days_since_p0_world.fit_transform(df_train)\ndf_test = days_since_p0_world.transform(df_test)\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A transformer which sets Day 0 to when the first patient was discovered in the region\nclass Days_Since_P0_Country(BaseEstimator, TransformerMixin):  \n    \"\"\"A transformer which sets Day 0 to when the first patient was discovered in the COUNTRY.\n    DOES NOT DROP THE ROWS , RETURNS FULL DATA.\n    \n    gets the min date for P1 to appear in train data set and calculates difference to this date.\n    \"\"\"\n\n    def __init__(self, y_col_name = 'ConfirmedCases'):\n        self.p_zero_date = {};\n        self.col_name = 'days_since_p0_country';\n        self.y_col_name = y_col_name;\n        pass\n\n    def fit(self, X, y=None ):\n        regions = X['Country_Region'].unique();\n        for this_region in regions:\n            this_region_X = X.loc[X['Country_Region'] == this_region,:];\n            self.p_zero_date[this_region] = min(this_region_X.loc[this_region_X[self.y_col_name]>0,'Date']);\n        return self;\n    \n    def transform(self, X ):\n        regions = X['Country_Region'].unique();\n        X[self.col_name] = 0;\n        answer = pd.DataFrame();\n        for this_region in regions:\n            this_region_X = None; # To prevent the bugging warning message.\n            this_region_X = X.loc[X['Country_Region'] == this_region,:];\n            this_region_X.loc[:,self.col_name] = this_region_X['Date'] -  self.p_zero_date[this_region];\n            this_region_X.loc[:,self.col_name] = this_region_X[self.col_name].dt.days;\n            answer = pd.concat([answer, this_region_X], axis='index');\n        return answer;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_since_p0_country = Days_Since_P0_Country()\ndf_train = days_since_p0_country.fit_transform(df_train)\ndf_test = days_since_p0_country.transform(df_test)\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A transformer which sets Day 0 to when the first patient was discovered in the region\nclass Days_Since_P0_Region(BaseEstimator, TransformerMixin):  \n    \"\"\"A transformer which sets Day 0 to when the first patient was discovered in the region.\n    DOES NOT DROP THE ROWS , RETURNS FULL DATA.\n    \n    gets the min date for P1 to appear in train data set and calculates difference to this date.\n    \"\"\"\n\n    def __init__(self, y_col_name = 'ConfirmedCases'):\n        self.p_zero_date = {};\n        self.col_name = 'days_since_p0_region';\n        self.y_col_name = y_col_name;\n        pass\n\n    def fit(self, X, y=None ):\n        regions = X['Region'].unique();\n        for this_region in regions:\n            this_region_X = X.loc[X['Region'] == this_region,:];\n            self.p_zero_date[this_region] = min(this_region_X.loc[this_region_X[self.y_col_name]>0,'Date']);\n        return self;\n    \n    def transform(self, X ):\n        regions = X['Region'].unique();\n        X[self.col_name] = 0;\n        answer = pd.DataFrame();\n        for this_region in regions:\n            this_region_X = None; # To prevent the bugging warning message.\n            this_region_X = X.loc[X['Region'] == this_region,:];\n            this_region_X.loc[:,self.col_name] = this_region_X['Date'] -  self.p_zero_date[this_region];\n            this_region_X.loc[:,self.col_name] = this_region_X[self.col_name].dt.days;\n            answer = pd.concat([answer, this_region_X], axis='index');\n        return answer;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_since_p0_region = Days_Since_P0_Region()\ndf_train = days_since_p0_region.fit_transform(df_train)\ndf_test = days_since_p0_region.transform(df_test)\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[df_train['Province_State'] == 'Alabama',:]\ndf_train.loc[(df_train['Date'] == '2020-01-22') & (df_train['Country_Region'] == 'China'),:]\ndf_train.loc[(df_train['Date'] == '2020-01-23') & (df_train['Country_Region'] == 'China'),:]\n# Check #4873 'China Gansu'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# regions = df_train['Region'].unique();\n# regions = regions[5:15]\n# x_name = 'days_since_p0_region'\n\n# for idx, region in enumerate(regions):\n#     plt.figure(idx);\n#     f, ax = plt.subplots(1, 2, figsize=(20,5*1));\n#     text = \"*\"*10+'INDEX='+str(idx)+\"*\"*10+\"REGION <---->\"+region+\"*\"*10\n#     plt.figtext(.5,.9,text, fontsize=20, color='red', ha='center')\n#     df = df_train.loc[df_train['Region'] == region,:]\n#     sns.regplot(data = df, x=x_name, y='ConfirmedCases', ax=ax[0],order=3)\n#     sns.regplot(data = df, x=x_name, y='Fatalities', ax=ax[1],order=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from collections import Counter\n# India = df_train[df_train['Region'] == 'India'];\n# cc_list = list(India.loc[India['days_since_p0_country'] >= 0,'ConfirmedCases']);\n# cc_rise_day_on_day = []\n# print(len(cc_list))\n# for idx, cc_n in enumerate(cc_list):\n#     if(idx == len(cc_list)-1):\n#         break;\n#     cc_np1= cc_list[idx+1];\n#     ratio=cc_np1/cc_n;\n#     cc_rise_day_on_day.append(ratio);\n\n# cc_rise_day_on_day\n# Counter(cc_rise_day_on_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y_true, y_pred):\n    return mean_squared_log_error(y_true, y_pred)**(1/2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PARAMS\ndegree = 3\n# MODEL\npoly = PolynomialFeatures(degree = degree, include_bias=False)\nmodel1 = LinearRegression()\nmodel2 = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cols = ['days_since_p0_region','days_since_p0_country','days_since_p0_world'];\ny1_col = ['ConfirmedCases']\ny2_col = ['Fatalities']\n\nall_pred_train = pd.DataFrame();\nall_pred_test = pd.DataFrame();\n\nregions = df_train['Region'].unique();\n\nif operation_mode == 'validation':\n    train_test_split_date = '2020-04-01';\n    train = df_train.loc[(df_train['Date'] < train_test_split_date),:];\n    test = df_train.loc[~(df_train['Date'] < train_test_split_date),:];\nelif operation_mode == 'final':\n    train = df_train.copy();\n    test = df_test.copy();\n    \n# TRAIN ON ONLY NON ZEROES\n# train = train.loc[train['days_since_p0_region'] >= 0,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, region in enumerate(regions):\n    scaler = StandardScaler();\n    \n    this_region_train = train['Region'] == region;\n    this_region_test = test['Region'] == region;\n    \n    X0_train_iter = train.loc[this_region_train,X_cols];\n    y1_train_iter = train.loc[this_region_train,y1_col];\n    y2_train_iter = train.loc[this_region_train,y2_col];\n    \n    X0_test_iter = test.loc[this_region_test,X_cols];\n\n    X0_train_iter = poly.fit_transform(X0_train_iter);\n    X0_test_iter = poly.fit_transform(X0_test_iter);\n    \n    X0_train_iter = scaler.fit_transform(X0_train_iter)\n    X0_test_iter = scaler.transform(X0_test_iter)\n    \n#     scaler_y1 = StandardScaler();\n#     scaler_y1.fit_transform(y1_train_iter);\n    \n    model1.fit(X0_train_iter, y1_train_iter);\n    y1_train_iter_pred = model1.predict(X0_train_iter);\n    y1_test_iter_pred = model1.predict(X0_test_iter);\n\n#     scaler_y2 = StandardScaler();\n#     scaler_y2.fit_transform(y2_train_iter);\n    \n    model2.fit(X0_train_iter, y2_train_iter);\n    y2_train_iter_pred = model2.predict(X0_train_iter);\n    y2_test_iter_pred = model2.predict(X0_test_iter);\n    \n    pred_iter_train = pd.DataFrame({\n        'Id': train.loc[this_region_train,'Id'],\n        'ConfirmedCases': y1_train_iter_pred.reshape(-1),\n        'Fatalities': y2_train_iter_pred.reshape(-1)\n    })\n    all_pred_train = pd.concat([all_pred_train, pred_iter_train], axis = 0);\n    \n    if (operation_mode == 'validation'):\n        pred_iter_test = pd.DataFrame({\n            'Id': test.loc[this_region_test,'Id'],\n            'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n            'Fatalities': y2_test_iter_pred.reshape(-1)\n        })\n    elif operation_mode == 'final':\n        pred_iter_test = pd.DataFrame({\n            'ForecastId': test.loc[this_region_test,'ForecastId'],\n            'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n            'Fatalities': y2_test_iter_pred.reshape(-1)\n        })\n    all_pred_test = pd.concat([all_pred_test, pred_iter_test], axis = 0);\n    \nprint(all_pred_train)\nprint(all_pred_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_pred_test = all_pred_test.astype('int')\nall_pred_test.to_csv(\"submission.csv\", index = False);\nall_pred_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# answer = pd.merge(df_test,all_pred_test, left_on = 'ForecastId',right_on = 'ForecastId');\n# days_col = 'days_since_p0_world';\n\n# train_max_date = df_train[days_col].max();\n# test_min_date = test[days_col].min();\n\n# for idx, region in enumerate(regions):\n#     sel1 = ((df_train[days_col] >= test_min_date) & (df_train['Region'] == region));\n#     to_paste = df_train.loc[sel1,['ConfirmedCases','Fatalities']].copy();\n#     sel2 = ((answer[days_col] <= train_max_date) & (answer['Region'] == region))\n#     if to_paste.shape != answer.loc[sel2,['ConfirmedCases','Fatalities']] .shape:\n#         print(df_train.loc[sel1,:]);\n#         print(answer.loc[sel2,:])\n#     answer.loc[sel2,['ConfirmedCases','Fatalities']] = to_paste.loc[:,['ConfirmedCases','Fatalities']].values;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if operation_mode == 'validation':\n    answer = pd.merge(df_train,all_pred_test, left_on = 'Id',right_on = 'Id');\nif operation_mode == 'final':\n    answer = pd.merge(df_train,all_pred_test, left_on = 'Id',right_on = 'ForecastId');\n\nanswer.loc[answer['ConfirmedCases_y'] < 0,:] = 0;\nanswer.loc[answer['Fatalities_y'] < 0,:] = 0;\nprint(rmsle(answer['ConfirmedCases_x'],answer['ConfirmedCases_y']))\nprint(rmsle(answer['Fatalities_x'],answer['Fatalities_y']))\n# answer.loc[answer['Fatalities_y'] < 0,:]\n# answer.loc[answer['Region'] == 'China Beijing']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# answer = answer.loc[:,['ForecastId','ConfirmedCases','Fatalities']]\n# answer = answer.astype('int');\n# answer.to_csv(\"submission.csv\", index = False);\n# answer.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reducing the degree to 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"degree = 2\n\n# MODEL\npoly = PolynomialFeatures(degree = degree, include_bias=False)\nmodel1 = LinearRegression()\nmodel2 = LinearRegression()\n\n\nX_cols = ['days_since_p0_region','days_since_p0_country','days_since_p0_world'];\ny1_col = ['ConfirmedCases']\ny2_col = ['Fatalities']\n\nall_pred_train = pd.DataFrame();\nall_pred_test = pd.DataFrame();\n\nregions = df_train['Region'].unique();\n\nif operation_mode == 'validation':\n    train_test_split_date = '2020-04-01';\n    train = df_train.loc[(df_train['Date'] < train_test_split_date),:];\n    test = df_train.loc[~(df_train['Date'] < train_test_split_date),:];\nelif operation_mode == 'final':\n    train = df_train.copy();\n    test = df_test.copy();\n    \n# TRAIN ON ONLY NON ZEROES\n# train = train.loc[train['days_since_p0_region'] >= 0,:]\n\n\n\nfor idx, region in enumerate(regions):\n    scaler = StandardScaler();\n    \n    this_region_train = train['Region'] == region;\n    this_region_test = test['Region'] == region;\n    \n    X0_train_iter = train.loc[this_region_train,X_cols];\n    y1_train_iter = train.loc[this_region_train,y1_col];\n    y2_train_iter = train.loc[this_region_train,y2_col];\n    \n    X0_test_iter = test.loc[this_region_test,X_cols];\n\n    X0_train_iter = poly.fit_transform(X0_train_iter);\n    X0_test_iter = poly.fit_transform(X0_test_iter);\n    \n    X0_train_iter = scaler.fit_transform(X0_train_iter)\n    X0_test_iter = scaler.transform(X0_test_iter)\n    \n#     scaler_y1 = StandardScaler();\n#     scaler_y1.fit_transform(y1_train_iter);\n    \n    model1.fit(X0_train_iter, y1_train_iter);\n    y1_train_iter_pred = model1.predict(X0_train_iter);\n    y1_test_iter_pred = model1.predict(X0_test_iter);\n\n#     scaler_y2 = StandardScaler();\n#     scaler_y2.fit_transform(y2_train_iter);\n    \n    model2.fit(X0_train_iter, y2_train_iter);\n    y2_train_iter_pred = model2.predict(X0_train_iter);\n    y2_test_iter_pred = model2.predict(X0_test_iter);\n    \n    pred_iter_train = pd.DataFrame({\n        'Id': train.loc[this_region_train,'Id'],\n        'ConfirmedCases': y1_train_iter_pred.reshape(-1),\n        'Fatalities': y2_train_iter_pred.reshape(-1)\n    })\n    all_pred_train = pd.concat([all_pred_train, pred_iter_train], axis = 0);\n    \n    if (operation_mode == 'validation'):\n        pred_iter_test = pd.DataFrame({\n            'Id': test.loc[this_region_test,'Id'],\n            'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n            'Fatalities': y2_test_iter_pred.reshape(-1)\n        })\n    elif operation_mode == 'final':\n        pred_iter_test = pd.DataFrame({\n            'ForecastId': test.loc[this_region_test,'ForecastId'],\n            'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n            'Fatalities': y2_test_iter_pred.reshape(-1)\n        })\n    all_pred_test = pd.concat([all_pred_test, pred_iter_test], axis = 0);\n    \nprint(all_pred_train)\nprint(all_pred_test)\n\n\n\nall_pred_test = all_pred_test.astype('int')\nall_pred_test.to_csv(\"submission.csv\", index = False);\nall_pred_test\n\n\nif operation_mode == 'validation':\n    answer = pd.merge(df_train,all_pred_test, left_on = 'Id',right_on = 'Id');\nif operation_mode == 'final':\n    answer = pd.merge(df_train,all_pred_test, left_on = 'Id',right_on = 'ForecastId');\n\nanswer.loc[answer['ConfirmedCases_y'] < 0,:] = 0;\nanswer.loc[answer['Fatalities_y'] < 0,:] = 0;\nprint(rmsle(answer['ConfirmedCases_x'],answer['ConfirmedCases_y']))\nprint(rmsle(answer['Fatalities_x'],answer['Fatalities_y']))\n# answer.loc[answer['Fatalities_y'] < 0,:]\n# answer.loc[answer['Region'] == 'China Beijing']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Changing the degree to 10","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"degree = 10\n\n# MODEL\npoly = PolynomialFeatures(degree = degree, include_bias=False)\nmodel1 = LinearRegression()\nmodel2 = LinearRegression()\n\n\nX_cols = ['days_since_p0_region','days_since_p0_country','days_since_p0_world'];\ny1_col = ['ConfirmedCases']\ny2_col = ['Fatalities']\n\nall_pred_train = pd.DataFrame();\nall_pred_test = pd.DataFrame();\n\nregions = df_train['Region'].unique();\n\nif operation_mode == 'validation':\n    train_test_split_date = '2020-04-01';\n    train = df_train.loc[(df_train['Date'] < train_test_split_date),:];\n    test = df_train.loc[~(df_train['Date'] < train_test_split_date),:];\nelif operation_mode == 'final':\n    train = df_train.copy();\n    test = df_test.copy();\n    \n# TRAIN ON ONLY NON ZEROES\n# train = train.loc[train['days_since_p0_region'] >= 0,:]\n\n\n\nfor idx, region in enumerate(regions):\n    scaler = StandardScaler();\n    \n    this_region_train = train['Region'] == region;\n    this_region_test = test['Region'] == region;\n    \n    X0_train_iter = train.loc[this_region_train,X_cols];\n    y1_train_iter = train.loc[this_region_train,y1_col];\n    y2_train_iter = train.loc[this_region_train,y2_col];\n    \n    X0_test_iter = test.loc[this_region_test,X_cols];\n\n    X0_train_iter = poly.fit_transform(X0_train_iter);\n    X0_test_iter = poly.fit_transform(X0_test_iter);\n    \n    X0_train_iter = scaler.fit_transform(X0_train_iter)\n    X0_test_iter = scaler.transform(X0_test_iter)\n    \n#     scaler_y1 = StandardScaler();\n#     scaler_y1.fit_transform(y1_train_iter);\n    \n    model1.fit(X0_train_iter, y1_train_iter);\n    y1_train_iter_pred = model1.predict(X0_train_iter);\n    y1_test_iter_pred = model1.predict(X0_test_iter);\n\n#     scaler_y2 = StandardScaler();\n#     scaler_y2.fit_transform(y2_train_iter);\n    \n    model2.fit(X0_train_iter, y2_train_iter);\n    y2_train_iter_pred = model2.predict(X0_train_iter);\n    y2_test_iter_pred = model2.predict(X0_test_iter);\n    \n    pred_iter_train = pd.DataFrame({\n        'Id': train.loc[this_region_train,'Id'],\n        'ConfirmedCases': y1_train_iter_pred.reshape(-1),\n        'Fatalities': y2_train_iter_pred.reshape(-1)\n    })\n    all_pred_train = pd.concat([all_pred_train, pred_iter_train], axis = 0);\n    \n    if (operation_mode == 'validation'):\n        pred_iter_test = pd.DataFrame({\n            'Id': test.loc[this_region_test,'Id'],\n            'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n            'Fatalities': y2_test_iter_pred.reshape(-1)\n        })\n    elif operation_mode == 'final':\n        pred_iter_test = pd.DataFrame({\n            'ForecastId': test.loc[this_region_test,'ForecastId'],\n            'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n            'Fatalities': y2_test_iter_pred.reshape(-1)\n        })\n    all_pred_test = pd.concat([all_pred_test, pred_iter_test], axis = 0);\n    \nprint(all_pred_train)\nprint(all_pred_test)\n\n\n\nall_pred_test = all_pred_test.astype('int')\nall_pred_test.to_csv(\"submission.csv\", index = False);\nall_pred_test\n\n\nif operation_mode == 'validation':\n    answer = pd.merge(df_train,all_pred_test, left_on = 'Id',right_on = 'Id');\nif operation_mode == 'final':\n    answer = pd.merge(df_train,all_pred_test, left_on = 'Id',right_on = 'ForecastId');\n\nanswer.loc[answer['ConfirmedCases_y'] < 0,:] = 0;\nanswer.loc[answer['Fatalities_y'] < 0,:] = 0;\nprint(rmsle(answer['ConfirmedCases_x'],answer['ConfirmedCases_y']))\nprint(rmsle(answer['Fatalities_x'],answer['Fatalities_y']))\n# answer.loc[answer['Fatalities_y'] < 0,:]\n# answer.loc[answer['Region'] == 'China Beijing']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Changing the degree to 20","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Overfitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"degree = 20\n\n# MODEL\npoly = PolynomialFeatures(degree = degree, include_bias=False)\nmodel1 = LinearRegression()\nmodel2 = LinearRegression()\n\n\nX_cols = ['days_since_p0_region','days_since_p0_country','days_since_p0_world'];\ny1_col = ['ConfirmedCases']\ny2_col = ['Fatalities']\n\nall_pred_train = pd.DataFrame();\nall_pred_test = pd.DataFrame();\n\nregions = df_train['Region'].unique();\n\nif operation_mode == 'validation':\n    train_test_split_date = '2020-04-01';\n    train = df_train.loc[(df_train['Date'] < train_test_split_date),:];\n    test = df_train.loc[~(df_train['Date'] < train_test_split_date),:];\nelif operation_mode == 'final':\n    train = df_train.copy();\n    test = df_test.copy();\n    \n# TRAIN ON ONLY NON ZEROES\n# train = train.loc[train['days_since_p0_region'] >= 0,:]\n\n\n\nfor idx, region in enumerate(regions):\n    scaler = StandardScaler();\n    \n    this_region_train = train['Region'] == region;\n    this_region_test = test['Region'] == region;\n    \n    X0_train_iter = train.loc[this_region_train,X_cols];\n    y1_train_iter = train.loc[this_region_train,y1_col];\n    y2_train_iter = train.loc[this_region_train,y2_col];\n    \n    X0_test_iter = test.loc[this_region_test,X_cols];\n\n    X0_train_iter = poly.fit_transform(X0_train_iter);\n    X0_test_iter = poly.fit_transform(X0_test_iter);\n    \n    X0_train_iter = scaler.fit_transform(X0_train_iter)\n    X0_test_iter = scaler.transform(X0_test_iter)\n    \n#     scaler_y1 = StandardScaler();\n#     scaler_y1.fit_transform(y1_train_iter);\n    \n    model1.fit(X0_train_iter, y1_train_iter);\n    y1_train_iter_pred = model1.predict(X0_train_iter);\n    y1_test_iter_pred = model1.predict(X0_test_iter);\n\n#     scaler_y2 = StandardScaler();\n#     scaler_y2.fit_transform(y2_train_iter);\n    \n    model2.fit(X0_train_iter, y2_train_iter);\n    y2_train_iter_pred = model2.predict(X0_train_iter);\n    y2_test_iter_pred = model2.predict(X0_test_iter);\n    \n    pred_iter_train = pd.DataFrame({\n        'Id': train.loc[this_region_train,'Id'],\n        'ConfirmedCases': y1_train_iter_pred.reshape(-1),\n        'Fatalities': y2_train_iter_pred.reshape(-1)\n    })\n    all_pred_train = pd.concat([all_pred_train, pred_iter_train], axis = 0);\n    \n    if (operation_mode == 'validation'):\n        pred_iter_test = pd.DataFrame({\n            'Id': test.loc[this_region_test,'Id'],\n            'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n            'Fatalities': y2_test_iter_pred.reshape(-1)\n        })\n    elif operation_mode == 'final':\n        pred_iter_test = pd.DataFrame({\n            'ForecastId': test.loc[this_region_test,'ForecastId'],\n            'ConfirmedCases': y1_test_iter_pred.reshape(-1),\n            'Fatalities': y2_test_iter_pred.reshape(-1)\n        })\n    all_pred_test = pd.concat([all_pred_test, pred_iter_test], axis = 0);\n    \nprint(all_pred_train)\nprint(all_pred_test)\n\n\n\nall_pred_test = all_pred_test.astype('int')\nall_pred_test.to_csv(\"submission.csv\", index = False);\nall_pred_test\n\n\nif operation_mode == 'validation':\n    answer = pd.merge(df_train,all_pred_test, left_on = 'Id',right_on = 'Id');\nif operation_mode == 'final':\n    answer = pd.merge(df_train,all_pred_test, left_on = 'Id',right_on = 'ForecastId');\n\nanswer.loc[answer['ConfirmedCases_y'] < 0,:] = 0;\nanswer.loc[answer['Fatalities_y'] < 0,:] = 0;\nprint(rmsle(answer['ConfirmedCases_x'],answer['ConfirmedCases_y']))\nprint(rmsle(answer['Fatalities_x'],answer['Fatalities_y']))\n# answer.loc[answer['Fatalities_y'] < 0,:]\n# answer.loc[answer['Region'] == 'China Beijing']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.coef_, model1.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly.powers_","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}