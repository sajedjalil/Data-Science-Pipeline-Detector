{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nHey, thanks for viewing my Kernel!\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! ðŸ˜Š\n\nðŸ‘‰ EDA and FE are done in this [notebook](https://www.kaggle.com/hasanbasriakcay/tps-mar22-eda-fe).","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\n\nwarnings.simplefilter('ignore')\ntrain = pd.read_pickle('../input/tpsmar22-deterministicholidaytime-features/train_featured_v2.pkl')\ntest = pd.read_pickle('../input/tpsmar22-deterministicholidaytime-features/test_featured_v2.pkl')\nsubmission = pd.read_csv('../input/tabular-playground-series-mar-2022/sample_submission.csv')\n\ndisplay(train.head())\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:08:31.665366Z","iopub.execute_input":"2022-03-09T06:08:31.666143Z","iopub.status.idle":"2022-03-09T06:08:35.294832Z","shell.execute_reply.started":"2022-03-09T06:08:31.665974Z","shell.execute_reply":"2022-03-09T06:08:35.293849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-09T06:08:35.297292Z","iopub.execute_input":"2022-03-09T06:08:35.297609Z","iopub.status.idle":"2022-03-09T06:08:35.314637Z","shell.execute_reply.started":"2022-03-09T06:08:35.297566Z","shell.execute_reply":"2022-03-09T06:08:35.313136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:08:35.320343Z","iopub.execute_input":"2022-03-09T06:08:35.320646Z","iopub.status.idle":"2022-03-09T06:08:36.481265Z","shell.execute_reply.started":"2022-03-09T06:08:35.320602Z","shell.execute_reply":"2022-03-09T06:08:36.480092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trend","metadata":{}},{"cell_type":"code","source":"def create_trend(df_train, df_test, time_col, target):\n    from statsmodels.tsa.deterministic import DeterministicProcess\n    from sklearn.linear_model import LinearRegression\n    \n    trend_model_dict = {}\n    trend_train_dict = {}\n    trend_test_dict = {}\n    \n    # Train\n    for direction in df_train['direction'].unique():\n        temp_df = df_train.loc[df_train['direction'] == direction, :]\n        \n        dp = DeterministicProcess(\n            index=temp_df[time_col],\n            constant=True,       \n            order=1,             \n            drop=True,           \n        )\n        X = dp.in_sample()\n        y = temp_df[target]\n        \n        model = LinearRegression(fit_intercept=False)\n        model.fit(X, y)\n        y_pred = pd.Series(model.predict(X), index=X.index)\n        \n        trend_model_dict[direction] = model\n        trend_train_dict[direction] = y_pred\n        \n    # Test\n    for direction in df_train['direction'].unique():\n        model = trend_model_dict[direction]\n        \n        temp_df = df_test.loc[df_test['direction'] == direction, :]\n        dp = DeterministicProcess(\n            index=temp_df[time_col],\n            constant=True,       \n            order=1,             \n            drop=True,           \n        )\n        X = dp.in_sample()\n        \n        y_pred = pd.Series(model.predict(X), index=X.index)\n        trend_test_dict[direction] = y_pred\n    \n    return trend_train_dict, trend_test_dict, _","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-09T06:08:36.482678Z","iopub.execute_input":"2022-03-09T06:08:36.483295Z","iopub.status.idle":"2022-03-09T06:08:36.49758Z","shell.execute_reply.started":"2022-03-09T06:08:36.483248Z","shell.execute_reply":"2022-03-09T06:08:36.496542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_trend(trend_train_dict, trend_test_dict):\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    \n    for key in trend_train_dict.keys():\n        trend_train = trend_train_dict[key]\n        trend_test = trend_test_dict[key]\n        \n        fig, ax = plt.subplots(figsize=(16, 8))\n        sns.lineplot(x=trend_train.index, y=trend_train.values, ax=ax)\n        sns.lineplot(x=trend_test.index, y=trend_test.values, ax=ax)\n        ax.set_title(key)\n        \n        break\n        ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-09T06:08:36.499323Z","iopub.execute_input":"2022-03-09T06:08:36.499579Z","iopub.status.idle":"2022-03-09T06:08:36.515756Z","shell.execute_reply.started":"2022-03-09T06:08:36.499549Z","shell.execute_reply":"2022-03-09T06:08:36.515074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trend_train_dict, trend_test_dict, _ = create_trend(train, test, 'time', 'congestion')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:08:36.516879Z","iopub.execute_input":"2022-03-09T06:08:36.517301Z","iopub.status.idle":"2022-03-09T06:08:40.077383Z","shell.execute_reply.started":"2022-03-09T06:08:36.517257Z","shell.execute_reply":"2022-03-09T06:08:40.076581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot_trend(trend_train_dict, trend_test_dict)\n\ntrain_group = train.groupby('time', as_index=False).agg({'congestion':'mean'})\nmoving_average = train_group['congestion'].rolling(\n    window=182 * 24,       # 182-day 24-hour window\n    center=True,           # puts the average at the center of the window\n    min_periods=91 * 24,   # choose about half the window size\n).mean()  \nmoving_average\n\nax = train_group['congestion'].plot(style=\".\", color=\"0.5\", figsize=(16, 8))\nmoving_average.plot(\n    ax=ax, linewidth=5, title=\"Congestion - 182-Day Moving Average\", legend=False,\n);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-09T06:08:40.07876Z","iopub.execute_input":"2022-03-09T06:08:40.079097Z","iopub.status.idle":"2022-03-09T06:08:40.496768Z","shell.execute_reply.started":"2022-03-09T06:08:40.079054Z","shell.execute_reply":"2022-03-09T06:08:40.495417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import linregress\n\nslope, intercept, r, p, se = linregress(np.arange(0, len(train_group)), train_group['congestion'])\nfx = np.array([0, len(train_group) - 1])\nfy = intercept + slope * fx\nax = train_group['congestion'].plot(style=\".\", color=\"0.5\", figsize=(16, 8))\nax.plot(fx, fy, '-', linewidth=5, color='red')\nax.text(0, 64, 'slope: ' + str(slope), fontsize=18, color=\"red\")\nax.set_title('Linregress Trend');","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:23:28.800323Z","iopub.execute_input":"2022-03-09T06:23:28.800577Z","iopub.status.idle":"2022-03-09T06:23:29.062906Z","shell.execute_reply.started":"2022-03-09T06:23:28.80055Z","shell.execute_reply":"2022-03-09T06:23:29.061956Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lag Features","metadata":{}},{"cell_type":"code","source":"def create_lag_features(df, lags=1, target=''):\n    for direction in train['direction'].unique():\n        for x in train['x'].unique():\n            for y in train['y'].unique():\n                conditions = ((train['x'] == x) & (train['y'] == y) & (train['direction'] == direction))\n                temp_df = train.loc[conditions, [target]]\n                for lag in range(0, lags):\n                    train.loc[conditions, f'lag_{lag + 1}'] = temp_df[target].shift(lag + 1)\n\ndef plot_lag_features(df, lags=1, target='', ncols=1):\n    from matplotlib.offsetbox import AnchoredText\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    \n    nrows = int(lags / ncols)\n    fig, axes = plt.subplots(nrows, ncols, sharex=True, sharey=True, squeeze=False, \n                             figsize=(ncols * 2, nrows * 2 + 0.5))\n    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n    plt.subplots_adjust(hspace=0.2)\n    lag_index = 0\n    for row in range(nrows):\n        for col in range(ncols):\n            scatter_kws = dict(\n                alpha=0.1,\n                s=0.1,\n            )\n            line_kws = dict(color='red')\n            corr = df[target].corr(df[f'lag_{lag_index + 1}'])\n            sns.regplot(x=df[target].values, y=df[f'lag_{lag_index + 1}'].values, scatter_kws=scatter_kws,\n                       line_kws=line_kws, ax=axes[row][col])\n            at = AnchoredText(\n                f\"{corr:.2f}\",\n                prop=dict(size=\"large\"),\n                frameon=True,\n                loc=\"upper left\",\n            )\n            at.patch.set_boxstyle(\"square, pad=0.0\")\n            axes[row][col].add_artist(at)\n            axes[row][col].set_title(f'lag_{lag_index + 1}')\n            \n            if col == 0 and row == 0:\n                axes[row][col].set_ylabel(target)\n            elif col == 0 and row == 1:\n                axes[row][col].set_ylabel(target)\n                axes[row][col].set_xlabel(target)\n            elif row == 1:\n                axes[row][col].set_xlabel(target)\n                \n            lag_index += 1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-09T09:03:48.265561Z","iopub.execute_input":"2022-03-09T09:03:48.265987Z","iopub.status.idle":"2022-03-09T09:03:48.284757Z","shell.execute_reply.started":"2022-03-09T09:03:48.265955Z","shell.execute_reply":"2022-03-09T09:03:48.28385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_lag_features(train, lags=12, target='congestion')\nplot_lag_features(train, lags=12, target='congestion', ncols=6)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:49:06.520179Z","iopub.execute_input":"2022-03-09T06:49:06.52058Z","iopub.status.idle":"2022-03-09T06:49:24.807105Z","shell.execute_reply.started":"2022-03-09T06:49:06.520543Z","shell.execute_reply":"2022-03-09T06:49:24.806161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Rule Based Model","metadata":{}},{"cell_type":"code","source":"def sub_trend(df, trend_dict, target):\n    for direction in df['direction'].unique():\n        df.loc[df['direction'] == direction, target] -= trend_dict[direction].values\n        \ndef add_trend(df, trend_dict, target):\n    for direction in df['direction'].unique():\n        df.loc[df['direction'] == direction, target] += trend_dict[direction].values","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-09T06:08:40.498023Z","iopub.execute_input":"2022-03-09T06:08:40.498274Z","iopub.status.idle":"2022-03-09T06:08:40.505816Z","shell.execute_reply.started":"2022-03-09T06:08:40.498244Z","shell.execute_reply":"2022-03-09T06:08:40.504776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_trend(train, trend_train_dict, 'congestion')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:08:40.50811Z","iopub.execute_input":"2022-03-09T06:08:40.508723Z","iopub.status.idle":"2022-03-09T06:08:41.729328Z","shell.execute_reply.started":"2022-03-09T06:08:40.508684Z","shell.execute_reply":"2022-03-09T06:08:41.728035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"medians = train.groupby(['x', 'y', 'direction', 'weekend', 'hour', 'minute']).agg({'congestion':'median'})\nmedians","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:08:41.731109Z","iopub.execute_input":"2022-03-09T06:08:41.731745Z","iopub.status.idle":"2022-03-09T06:08:42.064366Z","shell.execute_reply.started":"2022-03-09T06:08:41.731685Z","shell.execute_reply":"2022-03-09T06:08:42.06347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['congestion'] = 0\nadd_trend(test, trend_test_dict, 'congestion')\ntest['trend'] = test['congestion']\ntest.drop(['congestion'], 1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:08:42.065605Z","iopub.execute_input":"2022-03-09T06:08:42.065905Z","iopub.status.idle":"2022-03-09T06:08:42.091031Z","shell.execute_reply.started":"2022-03-09T06:08:42.065871Z","shell.execute_reply":"2022-03-09T06:08:42.090083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = test.merge(medians, \n                 left_on=['x', 'y', 'direction', 'weekend', 'hour', 'minute'],\n                 right_index=True)[['congestion']]\nsub.reset_index(inplace=True)\nsub.columns = submission.columns\nsub['congestion'] += test['trend'].values\nsub['congestion'] = sub['congestion'].round()\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:08:42.092247Z","iopub.execute_input":"2022-03-09T06:08:42.092475Z","iopub.status.idle":"2022-03-09T06:08:42.141642Z","shell.execute_reply.started":"2022-03-09T06:08:42.092447Z","shell.execute_reply":"2022-03-09T06:08:42.140502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preds Distribution","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Plot the distribution of the test predictions\n# compared to the other Monday afternoons\nadd_trend(train, trend_train_dict, 'congestion')\nplt.figure(figsize=(16,3))\nplt.hist(train.congestion[((train.time.dt.weekday == 0) &\n                           (train.time.dt.hour >= 12)).values],\n         bins=np.linspace(-0.5, 100.5, 102),\n         density=True, label='Train',\n         color='b')\nplt.hist(sub['congestion'], np.linspace(-0.5, 100.5, 102),\n         density=True, rwidth=0.5, label='Test predictions',\n         color='r')\nplt.xlabel('Congestion')\nplt.ylabel('Frequency')\nplt.title('Congestion on Monday afternoons')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T06:08:42.144452Z","iopub.execute_input":"2022-03-09T06:08:42.144986Z","iopub.status.idle":"2022-03-09T06:08:44.23069Z","shell.execute_reply.started":"2022-03-09T06:08:42.144936Z","shell.execute_reply":"2022-03-09T06:08:44.229748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"References:\n\n[1] [notebook](https://www.kaggle.com/ambrosm/tpsmar22-without-machine-learning/notebook?scriptVersionId=89093653)","metadata":{}}]}