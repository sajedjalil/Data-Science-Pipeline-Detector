{"cells":[{"metadata":{},"cell_type":"markdown","source":"I dont know if everyone have considered that each image in this dataset is a peace of a CT of a patient.  \nEach patient have between 25 to 50 images, and it can be treated as a sequential set of images.  \nBelow I show a very simple notebook reading and sequentiating the images of a pacient id: ID_03613589"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input\n\ndir_csv = '../input/rsna-intracranial-hemorrhage-detection'\n\n\n# Parameters\n\nn_classes = 6\nn_epochs = 2\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport torch, torch.nn as nn\nfrom torchvision import models, transforms, datasets\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport math\nimport pydicom\nfrom collections import Counter\nimport tqdm\n#from apex import amp\nimport cv2\nimport glob\nimport torch.optim as optim\nfrom albumentations import Compose, ShiftScaleRotate, Resize, CenterCrop, HorizontalFlip, RandomBrightnessContrast\nfrom albumentations.pytorch import ToTensor\nfrom torch.utils.data import Dataset\nos.listdir('/kaggle/input/rsna-intracranial-hemorrhage-detection')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import and ajust stage_1_train.csv\ninput_path = '/kaggle/input/rsna-intracranial-hemorrhage-detection/'\ndf_train = pd.read_csv(input_path + 'stage_1_train.csv')\n#df_train['image_ID'] = df_train['ID'].str[:12]\nduplicates_to_remove = [\n        1598538, 1598539, 1598540, 1598541, 1598542, 1598543,\n        312468,  312469,  312470,  312471,  312472,  312473,\n        2708700, 2708701, 2708702, 2708703, 2708704, 2708705,\n        3032994, 3032995, 3032996, 3032997, 3032998, 3032999\n    ]\n    \ndf_train = df_train.drop(index=duplicates_to_remove)\ndf_train.set_index('ID', inplace=True)\nprint(len(df_train))\ndf_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_columns = ['ID',\n              'PatientID',\n              'Modality',\n              'StudyInstance',\n              'SeriesInstance',\n               # 'PhotoInterpretation',\n              'Position0', 'Position1', 'Position2']\n              #'Orientation0', 'Orientation1', 'Orientation2', 'Orientation3', 'Orientation4', 'Orientation5',\n              #'PixelSpacing0', 'PixelSpacing1']\ndef extract_dicom_features(ds):\n    \n    ds_items = [ds.SOPInstanceUID,\n                ds.PatientID,\n                ds.Modality,\n                ds.StudyInstanceUID,\n                ds.SeriesInstanceUID,\n                #ds.PhotometricInterpretation,\n                ds.ImagePositionPatient]\n                #ds.ImageOrientationPatient,\n                #ds.PixelSpacing]\n\n    line = []\n    for item in ds_items:\n        if type(item) is pydicom.multival.MultiValue:\n            line += [float(x) for x in item]\n        else:\n            line.append(item)\n\n    return {x:y for x, y in zip(ds_columns, line)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the dicom features into dataset to load faster\nclass GetCSV(torch.utils.data.Dataset):\n    \n    def __init__(self, folder_path, transform=None):\n        self.folder_path = folder_path\n        self.dcm_files = os.listdir(folder_path)\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.dcm_files)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        path = self.folder_path + self.dcm_files[idx]\n        ds = pydicom.read_file(path)\n        sample = extract_dicom_features(ds)\n        \n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample   \n    \n# Functions\n\nclass IntracranialDataset(Dataset):\n\n    def __init__(self, csv_file, path, labels, transform=None):\n        \n        self.path = path\n        self.data = csv_file\n        self.transform = transform\n        self.labels = labels\n\n    def __len__(self):\n        \n        return len(self.data)\n\n    def __getitem__(self, idx):\n        ID = self.data.loc[idx, 'ID']\n        img_name = os.path.join(self.path, ID + '.png')\n        img = cv2.imread(img_name)   \n        \n        try:\n            if self.transform:       \n                augmented = self.transform(image=img)\n                img = augmented['image']\n        except:\n            img = torch.zeros([3, 200, 200], dtype=torch.float32)\n            \n        return {'image': img, 'ID': ID}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the dcm files to csv\ntrain_path = input_path + 'stage_1_train_images/'\ntrain_dataset = GetCSV(train_path)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=500, shuffle=False, num_workers=4)\ntest_path = input_path + 'stage_1_test_images/'\ntest_dataset = GetCSV(test_path)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=500, shuffle=False, num_workers=4)\n\ndef load_dicom_features(loader):\n\n    df_features = []\n    for datas in tqdm.tqdm_notebook(loader):\n        df_features.append(pd.DataFrame(datas))\n\n    return pd.concat(df_features).reset_index(drop=True)\n    \ndf_features_train = load_dicom_features(train_loader)\ndf_features_test = load_dicom_features(test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inser labels into dataset\ncatgs = ['epidural','intraparenchymal','intraventricular','subarachnoid','subdural','any']\nids = df_features_train['ID'].values\nfor catg in catgs:\n    ids_catg = [ID + '_' + catg for ID in ids]\n    df_features_train[catg] = df_train.loc[ids_catg]['Label'].values\n    \ndf_features_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data loaders\ndir_train_img = '../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x'\ndir_test_img = '../input/rsna-test-stage-1-images-png-224x/stage_1_test_png_224x'\n\ntransform_train = Compose([CenterCrop(200, 200), ToTensor()])\n\ntrain_dataset = IntracranialDataset(csv_file=df_features_train, path=dir_train_img, transform=transform_train, labels=False)\ntest_dataset = IntracranialDataset(csv_file=df_features_test, path=dir_test_img, transform=transform_train, labels=False)\n\ndata_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\ndata_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_path = '../input/res-net-trained-ct/model.weights'\n# Model\n\ndevice = torch.device(\"cuda:0\")\nmodel = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\nmodel.fc = torch.nn.Linear(2048, n_classes)\nmodel.load_state_dict(torch.load(weight_path, map_location='cpu'))\nmodel.eval()\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_preds(data_loader):\n    catgs_pred = [catg + '_pred' for catg in catgs]\n    with torch.no_grad():\n        img_embedding = pd.DataFrame()\n        for sample in tqdm.tqdm_notebook(data_loader):\n            ID = sample['ID']\n            image = sample['image'].to(device)\n            preds = model(image).cpu().numpy()\n            new_df = pd.DataFrame(preds, columns=catgs_pred)\n            new_df['ID'] = ID\n            img_embedding = pd.concat([img_embedding, new_df])\n        return img_embedding\n\nimg_embedding_train = extract_preds(data_loader_train)\nimg_embedding_test = extract_preds(data_loader_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features_test = pd.merge(df_features_test, img_embedding_test, on='ID')\ndf_features_train = pd.merge(df_features_train, img_embedding_train, on='ID')\ndel img_embedding_train, img_embedding_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features_train.reset_index().to_csv('features_train.csv', index=False)\ndf_features_test.reset_index().to_csv('features_test.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}