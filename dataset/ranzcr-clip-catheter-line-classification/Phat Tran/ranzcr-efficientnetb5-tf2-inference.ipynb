{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nimport sys\nimport numpy as np\n\nfrom datetime import datetime as dt\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\n\nW = H = 338\nN_CLASSES = 11\nautotune = tf.data.experimental.AUTOTUNE\n\nfeatures = {\n    'StudyInstanceUID': tf.io.FixedLenFeature([], tf.string),\n    'image': tf.io.FixedLenFeature([], tf.string),\n}\n\n\ntarget_cols = [\n    'CVC - Abnormal',\n    'CVC - Borderline',\n    'CVC - Normal',\n    'ETT - Abnormal',\n    'ETT - Borderline',\n    'ETT - Normal',\n    'NGT - Abnormal',\n    'NGT - Borderline',\n    'NGT - Incompletely Imaged',\n    'NGT - Normal',\n    'Swan Ganz Catheter Present'\n]\n\nlabel_list = list(features.keys())[:11]\n\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\ntest_tfrecords_dir = \"../input/ranzcr-clip-catheter-line-classification/test_tfrecords\"\nweight_dir = \"../input/cassava2020weights\"\ntest_tfrecords = os.listdir(test_tfrecords_dir)\nmodel_map = {\n    \"efficientb3\": [tf.keras.applications.EfficientNetB3, weight_dir + \"/ranzcr_efficientb3.h5\"],\n    \"efficientb5\": [tf.keras.applications.EfficientNetB5, weight_dir + \"/ranzcr_efficientb5.h5\"],\n    \"efficientb7\": [tf.keras.applications.EfficientNetB7, weight_dir + \"/ranzcr_efficientb7.h5\"],\n    \"resnet101\": [tf.keras.applications.ResNet101,  weight_dir + \"/ranzcr_resnet101.h5\"],\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def parse_example(sample):\n    sample= tf.io.parse_single_example(sample, features)\n    image = tf.image.decode_png(sample[\"image\"], channels=3)\n    image = tf.image.resize(image, (H, W))\n\n    image_id = sample[\"StudyInstanceUID\"]\n    \n    return image, image_id\n\ndef preprocess(images, labels):\n    images = tf.cast(images, tf.float32)\n    return images, labels\n    return (images - mean) / std, labels\n\ndef get_count(fname):\n    return 1868 if \"15-1881.tfrec\" in fname else 1881\n\ndef get_tfrecord(indices):\n    files = [test_tfrecords_dir + \"/\"+ train_tfrecords[i] for i in indices]\n    sizes = [get_count(file) for file in files]\\\n\n    return files, sum(sizes)\n\ndef get_model(\n    base_model,\n    baseline_weight=None,\n    init_weight=None,\n    lr=0.001,\n    optimizer=tf.optimizers.Adam):\n    base_model = base_model(include_top=False,\n                           input_shape=(W, H, 3),\n                           pooling=\"avg\",\n                           weights=baseline_weight)\n    base_out = base_model.output\n    out = tf.keras.layers.Dropout(0.3)(base_out)\n    out = tf.keras.layers.Dense(N_CLASSES, activation=\"sigmoid\")(out)\n    model = tf.keras.models.Model(inputs=base_model.input, outputs=out)\n\n    model.compile(optimizer=optimizer(learning_rate=lr),\n                loss=\"binary_crossentropy\",\n                metrics=[tf.keras.metrics.AUC()])\n    if init_weight:\n        try:\n            model.load_weights(init_weight)\n            print(f\"Weight loaded from {init_weight}\")\n        except Exception as e:\n            print(f\"Load weight from {init_weight} failed, {e}\")\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = [test_tfrecords_dir + \"/\"+ c for c in test_tfrecords]\ntest_data = tf.data.TFRecordDataset(files)\ntest_data = test_data.map(parse_example, num_parallel_calls=autotune)\ntest_data = test_data.map(preprocess)\ntest_data = test_data.prefetch(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Display some images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_samples(dataset):\n    rows = cols = 2\n    fig = plt.figure(figsize=(15,15))\n    for i, (img, label) in enumerate(dataset.shuffle(100).take(rows * cols)):\n        fig.add_subplot(rows, cols, i + 1)\n        plt.imshow(img/255)\n    plt.show()\n    \nshow_samples(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_mode, weight_path = model_map[\"resnet101\"]\nmodel = get_model(base_mode, init_weight=weight_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nimage_ids = []\ntest_df = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/sample_submission.csv')[0:0]\n\ndef TTA(image):\n    return tf.stack([\n        image,\n        tf.image.flip_left_right(image),\n    ])\n\nc = 0\nuse_tta = False\n\nfor image, img_id in test_data:\n    img_id = str(img_id.numpy()).replace(\"b\", \"\").replace(\"'\", \"\")\n    image_ids.append(img_id)\n    \n    if use_tta:\n    \n        tta_imgs = TTA(image)\n\n        pred = model.predict_on_batch(tta_imgs).tolist()\n        pred = np.max(pred, axis=0)\n    else:\n        pred = model.predict(image[tf.newaxis, ...]).tolist()[0]\n        \n    preds.append(pred)\n    \n    c += 1\n    if c % 1000 == 0:\n        print(c, \"/3582\")\n    \npreds\ntest_df[target_cols] = preds\ntest_df[[\"StudyInstanceUID\"]] = image_ids\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}