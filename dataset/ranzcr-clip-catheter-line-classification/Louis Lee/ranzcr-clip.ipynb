{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **My Notebook for RANZCR CLiP - Catheter and Line Position Challenge**\n\nThis notebook marks my very first attempt to an image classification competition with the use of a CNN by Keras. I hope this would serve as a reference for myself as well as beginners trying to explore the world of image classification by CNN."},{"metadata":{},"cell_type":"markdown","source":"DEBUG governs whether this run is a playground mode (or exploration stage), or for competition submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"DEBUG = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1 - Import Packages and Modules\n\nThe first step is to import packages and modules that will be used in the rest of this notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import packages and modules\nfrom IPython.display import FileLink\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, Input, MaxPooling2D\nfrom tensorflow.keras.models import Sequential, Model\n\nimport glob\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2 - Read Input Files\n\nThe input files are stored at ../input/ranzcr-clip-catheter-line-classification, and they are:\n1. train.csv: This stores image paths and labels for training\n2. test: This folder stores the testing images\n3. test_tfrecords: This folder stores the testing images in tfrecord format, but I will not be using these tfrecord files\n4. train: This folder stores the training images\n5. train_tfrecords: This folder stores the training images and labels in tfrecord format, but I will not be using these tfrecord files\n\nThe way the training images and labels are loaded:\n1. First I will import train.csv into a Pandas DataFrame, and then the paths to the training images and the training labels are loaded.\n2. During exploration stage (or debug stage), train.csv will be divided into train, validation and test sets. Then when predictions are to be generated for submission, I will skip the test sets.\n3. Pipelines will be created to load the train, valid as test sets into tensor datasets using from_tensor_slices(), with the image files being loaded using the map() function."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read train.csv which contains data pointing to the paths of training images and target labels\ndf_train = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Format paths to training images\ndf_train['path'] = '../input/ranzcr-clip-catheter-line-classification/train/' + df_train['StudyInstanceUID']+'.jpg'\n\n# Define target labels\nlabels = ['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', \n          'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n          'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', \n          'Swan Ganz Catheter Present']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# During \"Debug\" mode, proceed with a smaller train dataset to reduce runtime\nif DEBUG:\n    df_train = df_train.sample(n = df_train.shape[0] // 5).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label in labels:\n    print(\"#\"*25)\n    print(label)\n    print(df_train[label].value_counts(normalize=True) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split training data into train and validating sets\nX_train, X_valid = train_test_split(df_train, test_size = 0.1, stratify=np.argmax(df_train[labels].to_numpy(), axis=1))\n\nif DEBUG:\n    # Split training data into train and test sets\n    X_train, X_test = train_test_split(X_train, test_size = 0.1, stratify=np.argmax(X_train[labels].to_numpy(), axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label in labels:\n    print(\"#\"*25)\n    print(label)\n    print(X_train[label].value_counts(normalize=True) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label in labels:\n    print(\"#\"*25)\n    print(label)\n    print(X_valid[label].value_counts(normalize=True) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DEBUG:\n    for label in labels:\n        print(\"#\"*25)\n        print(label)\n        print(X_test[label].value_counts(normalize=True) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\nprint(X_train.shape)\nprint(X_valid.shape)\nif DEBUG:\n    print(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create trainig and validating tensorflow datasets\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train.path.values, X_train[labels].values))\nvalid_ds = tf.data.Dataset.from_tensor_slices((X_valid.path.values, X_valid[labels].values))\nif DEBUG:\n    # Create test dataset\n    test_ds  = tf.data.Dataset.from_tensor_slices((X_test.path.values, X_test[labels].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nbatch_size = 32\ntarget_size_dim = 224\n\n# Mapping function for trainig and validating datasets (and test set of course)\ndef process_data(image_path, label):\n\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [target_size_dim,target_size_dim])\n        \n    return img, label\n\ndef data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.70, 1.30)\n    image = tf.image.random_contrast(image, 0.80, 1.20)\n    image = tf.image.random_brightness(image, 0.10)\n    return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn trainig and validating datasets into batches (test dataset too of course)\ntrain_ds_batch = train_ds.map(process_data, num_parallel_calls=AUTOTUNE).map(data_augment, num_parallel_calls=AUTOTUNE).shuffle(buffer_size=1024).repeat().batch(batch_size).prefetch(buffer_size=AUTOTUNE)\nvalid_ds_batch = valid_ds.map(process_data, num_parallel_calls=AUTOTUNE).batch(batch_size)\nif DEBUG:\n    test_ds_batch  = test_ds.map(process_data, num_parallel_calls=AUTOTUNE).batch(batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3 - Train a model using Transfer Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the training model using transfer learning\ndef create_model():\n    \n    base_model = keras.applications.EfficientNetB0(weights='../input/keras-pretrained-models/EfficientNetB0_NoTop_ImageNet.h5', \n                                                   include_top=False,\n                                                   drop_connect_rate=0.4)\n    #base_model = keras.applications.NASNetMobile(weights='../input/keras-pretrained-models/NASNetMobile_NoTop_ImageNet.h5', include_top=False)\n    base_model.trainable = True\n    \n    inputs = Input(shape=(target_size_dim, target_size_dim, 3)) \n    #a1     = data_augmentation(inputs)\n    bm1    = base_model(inputs)\n    avg1   = GlobalAveragePooling2D()(bm1)\n    d1     = Dense(32, activation='relu')(avg1)\n    x1     = Dropout(rate=0.4)(d1)\n    d2     = Dense(32, activation='relu')(x1)\n    x2     = Dropout(rate=0.4)(d2)\n    d3     = Dense(32, activation='relu')(x2)\n    x3     = Dropout(rate=0.4)(d3)\n    predictions = Dense(len(labels), activation='sigmoid')(x3)\n    \n    model = Model(inputs=inputs, outputs=predictions)\n    model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC(multi_label=True)])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the training model and show its summary\nmodel = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(\n    patience=5, # how many epochs to wait before stopping\n    monitor='val_loss', \n    mode='min',\n    restore_best_weights=True,\n)\n\nreduceLROnPlat = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.8, \n    patience=2, \n    mode='auto', \n    cooldown=3,\n    min_lr=0.00001\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_ds_batch, \n                    validation_data = valid_ds_batch, \n                    epochs = 30, \n                    steps_per_epoch = len(X_train) // batch_size,\n                    callbacks = [early_stopping, reduceLROnPlat]\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DEBUG:\n    model.evaluate(test_ds_batch)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 4 - This is to import the competition test dataset, predict and generate the submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_data_competition(image_path):\n    # load the raw data from the file as a string\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [target_size_dim,target_size_dim])\n    #img = tf.keras.applications.mobilenet.preprocess_input(img)\n    \n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not DEBUG: \n    comp_images = glob.glob('../input/ranzcr-clip-catheter-line-classification/test/*.jpg')\n\n    df_comp = pd.DataFrame(np.array(comp_images), columns=['Path'])\n    df_comp.head()\n\n    comp_ds = tf.data.Dataset.from_tensor_slices(df_comp.Path.values)\n    comp_ds_batch = comp_ds.map(process_data_competition, num_parallel_calls=AUTOTUNE).batch(batch_size)\n\n    pred_y = model.predict(comp_ds_batch, verbose=1)\n    #pred_y = np.array([[1 if i > 0.5 else 0 for i in j] for j in pred_y])\n\n    df_result = pd.DataFrame(pred_y, columns = labels)\n    df_result['StudyInstanceUID'] = df_comp.Path.str.split('/').str[-1].str[:-4]\n    df_result.head()\n\n    cols_reordered = ['StudyInstanceUID', 'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal',\n           'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal',\n           'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n           'Swan Ganz Catheter Present']\n\n    df_result = df_result[cols_reordered]\n\n    df_result.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reference:\n* EfficientNetB3 tf2/Keras Baseline (https://www.kaggle.com/harveenchadha/efficientnetb3-tf2-keras-baseline)\n* <日本語>RANZCR機械学習初心者向け (https://www.kaggle.com/tomohiroh/ranzcr)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}