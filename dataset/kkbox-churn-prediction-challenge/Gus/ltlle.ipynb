{"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"cells":[{"cell_type":"code","outputs":[],"metadata":{"_uuid":"83b8fb71e5673c3be7d280f7797c6e82cfb9012d","_cell_guid":"f102e61d-c350-48fd-a802-e92e3c452657"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom multiprocessing import Pool, cpu_count\nimport gc; gc.enable()\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nfrom sklearn import *\nimport sklearn","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"548463d0d610a4e6cb518d977f80efdd93727432","collapsed":true,"_cell_guid":"e1e76206-5e35-4878-835b-cb3ebf432ce7"},"source":"train = pd.read_csv('../input/train.csv')\ntrain = pd.concat((train, pd.read_csv('../input/train_v2.csv')), axis=0, ignore_index=True).reset_index(drop=True)\ntest = pd.read_csv('../input/sample_submission_v2.csv')","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"71f40c16d7ab3ef94d78ba1faf6159059f189307","collapsed":true,"_cell_guid":"fe997792-76f6-46d4-8304-1f45e04a928b"},"source":"members = pd.read_csv('../input/members_v3.csv')","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"971ada67f9d8f9eef7db924d347aec4505df8b08","collapsed":true,"_cell_guid":"05a5f9fd-8c12-4a42-8a84-326c5f22e2c1"},"source":"transactions = pd.read_csv('../input/transactions.csv')\ntransactions = pd.concat((transactions, pd.read_csv('../input/transactions_v2.csv')), axis=0, ignore_index=True).reset_index(drop=True)\n#transactions = pd.DataFrame(transactions['msno'].value_counts().reset_index())\ntransactions = transactions.sort_values(by=['transaction_date'], ascending=[False]).reset_index(drop=True)\ntransactions = transactions.drop_duplicates(subset=['msno'], keep='first')","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"0d1286d7ab670041d1ad01dbbbe0c5a606dda090","collapsed":true,"_cell_guid":"16680f4f-3e4a-4d1e-8c21-99657523517f"},"source":"#discount\ntransactions['discount'] = transactions['plan_list_price'] - transactions['actual_amount_paid']\n#amt_per_day\ntransactions['amt_per_day'] = transactions['actual_amount_paid'] / transactions['payment_plan_days']\n#is_discount\ntransactions['is_discount'] = transactions.discount.apply(lambda x: 1 if x > 0 else 0)\n#membership_duration\ntransactions['membership_days'] = pd.to_datetime(transactions['membership_expire_date']).subtract(pd.to_datetime(transactions['transaction_date'])).dt.days.astype(int)","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"ef82645a08e4ab845ee25beeb278e421ee861bce","_cell_guid":"4ada81be-7f6b-4f59-bf18-756bc617fba4"},"source":"train['is_train'] = 1\ntest['is_train'] = 0\ncombined = pd.concat([train, test], axis = 0)\n\ncombined = pd.merge(combined, members, how='left', on='msno')\nmembers = []; print('members merge...') \n\ngender = {'male':1, 'female':2}\ncombined['gender'] = combined['gender'].map(gender)\n\ncombined = pd.merge(combined, transactions, how='left', on='msno')\ntransactions=[]; print('transaction merge...')\n\ntrain = combined[combined['is_train'] == 1]\ntest = combined[combined['is_train'] == 0]\n\ntrain.drop(['is_train'], axis = 1, inplace = True)\ntest.drop(['is_train'], axis = 1, inplace = True)\n\ndel combined","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"cf0cba8b315027da322ff8e9bd0d107d405794f5","_cell_guid":"c2715a18-2139-4836-b5ba-1a0ae57cef21"},"source":"def transform_df(df):\n    df = pd.DataFrame(df)\n    df = df.sort_values(by=['date'], ascending=[False])\n    df = df.reset_index(drop=True)\n    df = df.drop_duplicates(subset=['msno'], keep='first')\n    return df\n\ndef transform_df2(df):\n    df = df.sort_values(by=['date'], ascending=[False])\n    df = df.reset_index(drop=True)\n    df = df.drop_duplicates(subset=['msno'], keep='first')\n    return df\nlast_user_logs = []\n\ndf_iter = pd.read_csv('../input/user_logs.csv', low_memory=False, iterator=True, chunksize=10000000)\n\n\ni = 0 #~400 Million Records - starting at the end but remove locally if needed\nfor df in df_iter:\n    if i>35:\n        if len(df)>0:\n            print(df.shape)\n            p = Pool(cpu_count())\n            df = p.map(transform_df, np.array_split(df, cpu_count()))   \n            df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n            df = transform_df2(df)\n            p.close(); p.join()\n            last_user_logs.append(df)\n            print('...', df.shape)\n            df = []\n    i+=1\n\n\nlast_user_logs.append(transform_df(pd.read_csv('../input/user_logs_v2.csv')))\nlast_user_logs = pd.concat(last_user_logs, axis=0, ignore_index=True).reset_index(drop=True)\nlast_user_logs = transform_df2(last_user_logs)\n\ntrain = pd.merge(train, last_user_logs, how='left', on='msno')\ntest = pd.merge(test, last_user_logs, how='left', on='msno')\nlast_user_logs=[]","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"f2eb9b7b7edbf4cf1899f590ee24830fd5067eef","collapsed":true,"_cell_guid":"3990bc1d-af83-4748-8539-6a88ab7fed87"},"source":"train['autorenew_&_not_cancel'] = ((train.is_auto_renew == 1) == (train.is_cancel == 0)).astype(np.int8)\ntest['autorenew_&_not_cancel'] = ((test.is_auto_renew == 1) == (test.is_cancel == 0)).astype(np.int8)\n\ntrain['notAutorenew_&_cancel'] = ((train.is_auto_renew == 0) == (train.is_cancel == 1)).astype(np.int8)\ntest['notAutorenew_&_cancel'] = ((test.is_auto_renew == 0) == (test.is_cancel == 1)).astype(np.int8)","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"da8a3434b97a008874fe889e956525b9c16f8963","collapsed":true,"_cell_guid":"9a6af72d-62f1-46e6-a0ee-c1a570658523"},"source":"train = train.fillna(0)\ntest = test.fillna(0)\n\ncols = [c for c in train.columns if c not in ['is_churn','msno']]","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"d90cca77a015e93457a74f9d35d32cc481646798","collapsed":true,"_cell_guid":"c5de2723-2987-49c3-bea5-b0aa814b4d13"},"source":"def xgb_score(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'log_loss', metrics.log_loss(labels, preds)\n\nfold = 1\nfor i in range(fold):\n    params = {\n        'eta': 0.02,\n        'min_child_weight': 5,\n        'gamma': 0.3,\n        'max_depth': 7,\n        'objective': 'binary:logistic',\n        'eval_metric': 'logloss',\n        'seed': 17,\n        'silent': True\n    }\n    x1, x2, y1, y2 = model_selection.train_test_split(train[cols], train['is_churn'], test_size=0.3, random_state=i)\n    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n    model = xgb.train(params, xgb.DMatrix(x1, y1), 50,  watchlist, feval=xgb_score, maximize=False, verbose_eval=50, early_stopping_rounds=50) #use 1500\n    if i != 0:\n        pred1 += model.predict(xgb.DMatrix(test[cols]), ntree_limit=model.best_ntree_limit)\n    else:\n        pred1 = model.predict(xgb.DMatrix(test[cols]), ntree_limit=model.best_ntree_limit)\npred1 /= fold","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"794cd72e1d1a5d55762c61e224c368bae49185e7","collapsed":true,"_cell_guid":"45e40b0f-5464-4785-9edd-b0bb866b769f"},"source":"test['is_churn'] = pred1.clip(0.+1e-15, 1-1e-15)\ntest[['msno','is_churn']].to_csv('xgbsub3.csv.gz', index=False, compression='gzip')","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"c8aeaf91f4c983a262e4a8f7c6da941279057b6c","collapsed":true,"_cell_guid":"2d25e0c7-db80-4d1e-ac84-c52c987899c6"},"source":"xgb.plot_importance(booster = model);","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"da4f5c338afeccf595dfe098fe7827a6474aa7fb","collapsed":true,"_cell_guid":"5f1393c6-cc92-499c-a211-cafbbffae86b"},"source":"import pandas as pd \nimport numpy as np \nimport lightgbm as lgb\nfrom sklearn.model_selection import ShuffleSplit\nimport gc","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"05ef8b798e56074a8e7cc70f9e3d915082766299","collapsed":true,"_cell_guid":"ee82c836-abf1-48c5-931d-d0b1aae6b132"},"source":"df_train = train","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"554eb636689986bc0c3cf00cf10e4ba5ce59b049","_cell_guid":"3a6f42a7-0820-4f08-b80c-cd020e23d8a4"},"source":"bst = None \n\nfor train_indices,val_indices in ShuffleSplit(n_splits=1,test_size = 0.1,train_size=0.4).split(df_train): \n    train_data = lgb.Dataset(df_train.drop(['msno','is_churn'],axis=1).loc[train_indices,:],label=df_train.loc[train_indices,'is_churn'])\n    val_data = lgb.Dataset(df_train.drop(['msno','is_churn'],axis=1).loc[val_indices,:],label=df_train.loc[val_indices,'is_churn'])\n    \n    params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting': 'gbdt',\n        'learning_rate': 0.1 , #small learn rate, large number of iterations\n        'verbose': 0,\n        'num_leaves': 108,\n        'bagging_fraction': 0.95,\n        'bagging_freq': 1,\n        'bagging_seed': 1,\n        'feature_fraction': 0.9,\n        'feature_fraction_seed': 1,\n        'max_bin': 128,\n        'max_depth': 10,\n        'num_rounds': 300,\n        } \n    \n    bst = lgb.train(params, train_data, 100, valid_sets=[val_data])","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"91257555355ae01a2ca44f95a55ce9adf839d250","collapsed":true,"_cell_guid":"0b9d2a5e-0049-4668-9fd5-c34a19aeeeee"},"source":"df_test = test","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"67bdd3659744f3ed33082ec88eaf8de83a14d5d3","collapsed":true,"_cell_guid":"784e1a9b-ae3b-4b1e-98bb-a4e8c5a0c8cd"},"source":"predictions = bst.predict(df_test.drop(['msno','is_churn'],axis=1))\ndf_test['is_churn'] = predictions","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"c1222ba9409b45c0554fbacc1d2c307d6231528a","_cell_guid":"72633059-b6a7-4c1f-845e-a0ee0b0c556b"},"source":"df_test11 = df_test[['msno', 'is_churn']]","execution_count":null},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"91ff618e134a6ae7211bb6055b68683f380580ce","collapsed":true,"_cell_guid":"feb7f909-d71f-49cf-8420-375944aaee20"},"source":"df_test11.to_csv('submissions.csv',index=False)","execution_count":null}]}