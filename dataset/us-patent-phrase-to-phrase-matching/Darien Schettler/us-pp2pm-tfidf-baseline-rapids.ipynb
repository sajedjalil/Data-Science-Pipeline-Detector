{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<br>\n\n<h2 style=\"text-align: center; font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: underline; text-transform: none; letter-spacing: 2px; color: gray; background-color: #ffffff;\">US Patent Phrase-to-Phrase Matching - Baseline Solution</h2>\n<h5 style=\"text-align: center; font-family: Verdana; font-size: 12px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; letter-spacing: 1px; color: black; background-color: #ffffff;\">CREATED BY: DARIEN SCHETTLER</h5>\n\n<br>\n\n---\n\n<br>\n\n<center><div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 18px;\">üõë &nbsp; WARNING:</b><br><br><b>THIS IS A WORK IN PROGRESS</b><br>\n</div></center>","metadata":{"papermill":{"duration":0.120561,"end_time":"2021-11-06T21:15:09.611563","exception":false,"start_time":"2021-11-06T21:15:09.491002","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<p id=\"toc\"></p>\n\n<br><br>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: gray; background-color: #ffffff;\">TABLE OF CONTENTS</h1>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#imports\">0&nbsp;&nbsp;&nbsp;&nbsp;IMPORTS</a></h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#background_information\">1&nbsp;&nbsp;&nbsp;&nbsp;BACKGROUND INFORMATION</a></h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#setup\">2&nbsp;&nbsp;&nbsp;&nbsp;SETUP</a></h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#helper_functions\">3&nbsp;&nbsp;&nbsp;&nbsp;HELPER FUNCTIONS</a></h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#dataset_exploration\">4&nbsp;&nbsp;&nbsp;&nbsp;DATASET EXPLORATION</a></h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#model_baseline\">5&nbsp;&nbsp;&nbsp;&nbsp;BASELINE</a></h3>\n\n---","metadata":{"papermill":{"duration":0.085591,"end_time":"2021-11-06T21:15:09.78303","exception":false,"start_time":"2021-11-06T21:15:09.697439","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<br>\n\n<a id=\"imports\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: gray;\" id=\"imports\">0&nbsp;&nbsp;IMPORTS&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a></h1>","metadata":{"papermill":{"duration":0.050527,"end_time":"2021-11-06T21:15:09.894476","exception":false,"start_time":"2021-11-06T21:15:09.843949","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"\\n... IMPORTS STARTING ...\\n\")\n\n\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t‚Äì TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t‚Äì TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport tensorflow_probability as tfp; print(f\"\\t\\t‚Äì TENSORFLOW PROBABILITY VERSION: {tfp.__version__}\");\nimport transformers; print(f\"\\t\\t‚Äì TRANSFORMERS VERSION: {tf.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t‚Äì NUMPY VERSION: {np.__version__}\");\nimport sklearn; print(f\"\\t\\t‚Äì SKLEARN VERSION: {sklearn.__version__}\");\nfrom sklearn.preprocessing import RobustScaler, PolynomialFeatures\nfrom pandarallel import pandarallel; pandarallel.initialize();\nfrom sklearn.feature_extraction.text import TfidfVectorizer as SK_TfidfVectorizer\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.feature_selection import chi2, SelectKBest\nfrom sklearn.decomposition import NMF, LatentDirichletAllocation\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.feature_selection import VarianceThreshold\nfrom scipy.sparse import hstack, vstack\nimport scipy\n\nphysical_devices = tf.config.list_physical_devices('GPU')\ntry:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\nexcept:\n    pass\n\nimport cuml, cudf, cupy\n\nfrom cuml.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom cuml.dask.feature_extraction.text import TfidfTransformer\nfrom cuml.neighbors import NearestNeighbors\nfrom cuml.svm import SVC\n\nimport gensim\nfrom gensim import corpora\nfrom gensim.utils import simple_preprocess\n\nfrom nltk import word_tokenize          \nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\n\nclass LemmaTokenizer:\n    def __init__(self):\n        self.wnl = WordNetLemmatizer()\n    def __call__(self, doc):\n        return \" \".join([i[0] for i in groupby([self.wnl.lemmatize(t) for t in word_tokenize(doc)])])\n\nclass PorterStem:\n    def __init__(self):\n        self.ps = PorterStemmer()\n    def __call__(self, doc):\n        return \" \".join([i[0] for i in groupby([self.ps.stem(t) for t in word_tokenize(doc)])])\n\n# Built In Imports\nfrom collections import Counter\nfrom itertools import groupby \nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport hashlib\nimport imageio\nimport IPython\nimport sklearn\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport json\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image, ImageEnhance\nimport matplotlib; print(f\"\\t\\t‚Äì MATPLOTLIB VERSION: {matplotlib.__version__}\");\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport plotly\nimport PIL\n\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n    \nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")","metadata":{"papermill":{"duration":162.144149,"end_time":"2021-11-06T21:17:52.087371","exception":false,"start_time":"2021-11-06T21:15:09.943222","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-22T15:39:59.969968Z","iopub.execute_input":"2022-03-22T15:39:59.97043Z","iopub.status.idle":"2022-03-22T15:40:14.209793Z","shell.execute_reply.started":"2022-03-22T15:39:59.97033Z","shell.execute_reply":"2022-03-22T15:40:14.208083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n<a id=\"background_information\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: gray; background-color: #ffffff;\" id=\"background_information\">1&nbsp;&nbsp;BACKGROUND INFORMATION&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a></h1>\n\n---\n","metadata":{"papermill":{"duration":0.05019,"end_time":"2021-11-06T21:17:52.231372","exception":false,"start_time":"2021-11-06T21:17:52.181182","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: gray; background-color: #ffffff;\">1.1 BASIC COMPETITION INFORMATION</h3>\n\n---\n\nCan you extract meaning from a large, text-based dataset derived from inventions? Here's your chance to do so.\n\nThe U.S. Patent and Trademark Office (USPTO) offers one of the largest repositories of scientific, technical, and commercial information in the world through its Open Data Portal. Patents are a form of intellectual property granted in exchange for the public disclosure of new and useful inventions. Because patents undergo an intensive vetting process prior to grant, and because the history of U.S. innovation spans over two centuries and 11 million patents, the U.S. patent archives stand as a rare combination of data volume, quality, and diversity.\n\n>‚ÄúThe USPTO serves an American innovation machine that never sleeps by granting patents, registering trademarks, and promoting intellectual property around the globe. The USPTO shares over 200 years' worth of human ingenuity with the world, from lightbulbs to quantum computers. Combined with creativity from the data science community, USPTO datasets carry unbounded potential to empower AI and ML models that will benefit the progress of science and society at large.‚Äù\n\n‚Äî USPTO Chief Information Officer Jamie Holcombe\n\nIn this competition, you will train your models on a novel semantic similarity dataset to extract relevant information by matching key phrases in patent documents. Determining the semantic similarity between phrases is critically important during the patent search and examination process to determine if an invention has been described before. For example, if one invention claims \"television set\" and a prior publication describes \"TV set\", a model would ideally recognize these are the same and assist a patent attorney or examiner in retrieving relevant documents. This extends beyond paraphrase identification; if one invention claims a \"strong material\" and another uses \"steel\", that may also be a match. What counts as a \"strong material\" varies per domain (it may be steel in one domain and ripstop fabric in another, but you wouldn't want your parachute made of steel). We have included the Cooperative Patent Classification as the technical domain context as an additional feature to help you disambiguate these situations.\n\nCan you build a model to match phrases in order to extract contextual information, thereby helping the patent community connect the dots between millions of patent documents?\n\n```\nThis is a Code Competition. Refer to Code Requirements for details.\n```","metadata":{"papermill":{"duration":0.053372,"end_time":"2021-11-06T21:17:52.337029","exception":false,"start_time":"2021-11-06T21:17:52.283657","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<br>\n\n<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: gray; background-color: #ffffff;\">1.2 COMPETITION DATA & EVALUATION</h3>\n\n---\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">GENERAL EVALUATION INFORMATION</b>\n\nSubmissions are evaluated on the **[Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)** between the predicted and actual similarity scores.\n\nSubmission File\nFor each `id` (representing a pair of phrases) in the test set, you must predict the similarity score. The file should contain a header and have the following format:\n\n```\nid,score\n4112d61851461f60,0\n09e418c93a776564,0.25\n36baf228038e314b,1\netc.\n```","metadata":{"papermill":{"duration":0.052259,"end_time":"2021-11-06T21:17:52.443218","exception":false,"start_time":"2021-11-06T21:17:52.390959","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<br>\n\n<a id=\"background_information\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: gray; background-color: #ffffff;\" id=\"setup\">2&nbsp;&nbsp;SETUP&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a></h1>\n\n---\n","metadata":{"papermill":{"duration":0.052944,"end_time":"2021-11-06T21:17:52.65284","exception":false,"start_time":"2021-11-06T21:17:52.599896","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: gray; background-color: #ffffff;\">2.1 ACCELERATOR DETECTION</h3>\n\n---\n\nIn order to use **`TPU`**, we use **`TPUClusterResolver`** for the initialization which is necessary to connect to the remote cluster and initialize cloud TPUs. Let's go over two important points\n\n1. When using TPU on Kaggle, you don't need to specify arguments for **`TPUClusterResolver`**\n2. However, on **G**oogle **C**ompute **E**ngine (**GCE**), you will need to do the following:\n\n<br>\n\n```python\n# The name you gave to the TPU to use\nTPU_WORKER = 'my-tpu-name'\n\n# or you can also specify the grpc path directly\n# TPU_WORKER = 'grpc://xxx.xxx.xxx.xxx:8470'\n\n# The zone you chose when you created the TPU to use on GCP.\nZONE = 'us-east1-b'\n\n# The name of the GCP project where you created the TPU to use on GCP.\nPROJECT = 'my-tpu-project'\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER, zone=ZONE, project=PROJECT)\n```\n\n<div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">üõë &nbsp; WARNING:</b><br><br>- Although the Tensorflow documentation says it is the <b>project name</b> that should be provided for the argument <b><code>`project`</code></b>, it is actually the <b>Project ID</b>, that you should provide. This can be found on the GCP project dashboard page.<br>\n</div>\n\n<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">üìñ &nbsp; REFERENCES:</b><br><br>\n    - <a href=\"https://www.tensorflow.org/guide/tpu#tpu_initialization\"><b>Guide - Use TPUs</b></a><br>\n    - <a href=\"https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/TPUClusterResolver\"><b>Doc - TPUClusterResolver</b></a><br>\n\n</div>","metadata":{"papermill":{"duration":0.053821,"end_time":"2021-11-06T21:17:52.761303","exception":false,"start_time":"2021-11-06T21:17:52.707482","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \nexcept ValueError:\n    TPU = None\n\nif TPU:\n    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n    # Yield the default distribution strategy in Tensorflow\n    #   --> Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy() \n\n# What Is a Replica?\n#    --> A single Cloud TPU device consists of FOUR chips, each of which has TWO TPU cores. \n#    --> Therefore, for efficient utilization of Cloud TPU, a program should make use of each of the EIGHT (4x2) cores. \n#    --> Each replica is essentially a copy of the training graph that is run on each core and \n#        trains a mini-batch containing 1/8th of the overall batch size\nN_REPLICAS = strategy.num_replicas_in_sync\n    \nprint(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\n\nprint(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")","metadata":{"papermill":{"duration":0.07574,"end_time":"2021-11-06T21:17:52.892074","exception":false,"start_time":"2021-11-06T21:17:52.816334","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-22T15:40:14.213321Z","iopub.execute_input":"2022-03-22T15:40:14.213547Z","iopub.status.idle":"2022-03-22T15:40:14.234811Z","shell.execute_reply.started":"2022-03-22T15:40:14.213519Z","shell.execute_reply":"2022-03-22T15:40:14.233889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: gray; background-color: #ffffff;\">2.2 COMPETITION DATA ACCESS</h3>\n\n---\n","metadata":{"papermill":{"duration":0.053551,"end_time":"2021-11-06T21:17:52.999073","exception":false,"start_time":"2021-11-06T21:17:52.945522","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n\nROOT_DIR = \"/kaggle\"\nDATA_DIR = os.path.join(ROOT_DIR, \"input\", \"us-patent-phrase-to-phrase-matching\")\nWORK_DIR = os.path.join(ROOT_DIR, \"working\")\n    \nprint(f\"\\n... DATA DIRECTORY PATH IS:\\n\\t--> {DATA_DIR}\")\nprint(f\"\\n... WORKING DIRECTORY PATH IS:\\n\\t--> {WORK_DIR}\")\n\nprint(f\"\\n... IMMEDIATE CONTENTS OF DATA DIRECTORY IS:\")\nfor file in tf.io.gfile.glob(os.path.join(DATA_DIR, \"*\")): print(f\"\\t--> {file}\")\n\nprint(\"\\n\\n... DATA ACCESS SETUP COMPLETED ...\\n\")","metadata":{"papermill":{"duration":0.0797,"end_time":"2021-11-06T21:17:53.133972","exception":false,"start_time":"2021-11-06T21:17:53.054272","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-22T15:40:14.23656Z","iopub.execute_input":"2022-03-22T15:40:14.237218Z","iopub.status.idle":"2022-03-22T15:40:14.254569Z","shell.execute_reply.started":"2022-03-22T15:40:14.237162Z","shell.execute_reply":"2022-03-22T15:40:14.253775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: gray; background-color: #ffffff;\">2.3 LEVERAGING XLA OPTIMIZATIONS</h3>\n\n---\n\n\n**XLA** (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes. **The results are improvements in speed and memory usage**.\n\n<br>\n\nWhen a TensorFlow program is run, all of the operations are executed individually by the TensorFlow executor. Each TensorFlow operation has a precompiled GPU/TPU kernel implementation that the executor dispatches to.\n\nXLA provides us with an alternative mode of running models: it compiles the TensorFlow graph into a sequence of computation kernels generated specifically for the given model. Because these kernels are unique to the model, they can exploit model-specific information for optimization.<br><br>\n\n<div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">üõë &nbsp; WARNING:</b><br><br>- XLA can not currently compile functions where dimensions are not inferrable: that is, if it's not possible to infer the dimensions of all tensors without running the entire computation<br>\n</div>\n\n<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">üìå &nbsp; NOTE:</b><br><br>- XLA compilation is only applied to code that is compiled into a graph (in <b>TF2</b> that's only a code inside <b><code>tf.function</code></b>).<br>- The <b><code>jit_compile</code></b> API has must-compile semantics, i.e. either the entire function is compiled with XLA, or an <b><code>errors.InvalidArgumentError</code></b> exception is thrown)\n</div>\n\n<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">üìñ &nbsp; REFERENCE:</b><br><br>    - <a href=\"https://www.tensorflow.org/xla\"><b>XLA: Optimizing Compiler for Machine Learning</b></a><br>\n</div>","metadata":{"papermill":{"duration":0.051494,"end_time":"2021-11-06T21:17:53.236017","exception":false,"start_time":"2021-11-06T21:17:53.184523","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(f\"\\n... XLA OPTIMIZATIONS STARTING ...\\n\")\n\nprint(f\"\\n... CONFIGURE JIT (JUST IN TIME) COMPILATION ...\\n\")\n# enable XLA optmizations (10% speedup when using @tf.function calls)\ntf.config.optimizer.set_jit(True)\n\nprint(f\"\\n... XLA OPTIMIZATIONS COMPLETED ...\\n\")","metadata":{"papermill":{"duration":0.128128,"end_time":"2021-11-06T21:17:53.442803","exception":false,"start_time":"2021-11-06T21:17:53.314675","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-22T15:40:14.256904Z","iopub.execute_input":"2022-03-22T15:40:14.257219Z","iopub.status.idle":"2022-03-22T15:40:14.265486Z","shell.execute_reply.started":"2022-03-22T15:40:14.257177Z","shell.execute_reply":"2022-03-22T15:40:14.262529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: gray; background-color: #ffffff;\">2.4 BASIC DATA DEFINITIONS & INITIALIZATIONS</h3>\n\n---\n","metadata":{"papermill":{"duration":0.090507,"end_time":"2021-11-06T21:17:53.624612","exception":false,"start_time":"2021-11-06T21:17:53.534105","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"\\n... BASIC DATA SETUP STARTING ...\\n\\n\")\n\ntrain_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\nprint(\"\\n\\n... TRAIN DATAFRAME ...\\n\")\ndisplay(train_df)\n\ntest_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\nprint(\"\\n\\n... TEST DATAFRAME ...\\n\")\ndisplay(test_df)\n\nss_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\nprint(\"\\n\\n... SAMPLE SUBMISSION DATAFRAME ...\\n\")\ndisplay(ss_df)\n\nprint(\"\\n\\n... BASIC DATA SETUP FINISHING ...\\n\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-03-22T15:40:14.267181Z","iopub.execute_input":"2022-03-22T15:40:14.267667Z","iopub.status.idle":"2022-03-22T15:40:14.408981Z","shell.execute_reply.started":"2022-03-22T15:40:14.267623Z","shell.execute_reply":"2022-03-22T15:40:14.408187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n\n<a id=\"helper_functions\"></a>\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: gray; background-color: #ffffff;\" id=\"helper_functions\">\n    3&nbsp;&nbsp;HELPER FUNCTION & CLASSES&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a>\n</h1>\n\n---","metadata":{"papermill":{"duration":0.054893,"end_time":"2021-11-06T21:17:54.695576","exception":false,"start_time":"2021-11-06T21:17:54.640683","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef get_lr_callback():\n    \"\"\"\n    https://www.kaggle.com/ragnar123/shopee-efficientnetb3-arcmarginproduct\n    \"\"\"\n    lr_start   = 0.000001\n    lr_max     = 0.00075\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 3\n    lr_decay   = 0.95\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max    \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr_callback\n\ndef plot_history(history, fold_num=\"1\", metric_names=(\"f1_score\",)):\n    fig = px.line(history.history, \n                  x=range(len(history.history[\"loss\"])), \n                  y=[\"loss\", \"val_loss\"],\n                  labels={\"value\":\"Loss (log-axis)\", \"x\":\"Epoch #\"},\n                  title=f\"<b>FOLD {fold_num} MODEL - LOSS</b>\", log_y=True\n                  )\n    fig.show(\"png\")\n    \n    for metric_name in metric_names:\n        fig = px.line(history.history, \n                      x=range(len(history.history[metric_name])), \n                      y=[metric_name, f\"val_{metric_name}\"],\n                      labels={\"value\":f\"{metric_name.title()} (log-axis)\", \"x\":\"Epoch #\"},\n                      title=f\"<b>FOLD {fold_num} MODEL - {metric_name.upper()}</b>\", log_y=True)\n        fig.show(\"png\")\n    ","metadata":{"papermill":{"duration":0.098071,"end_time":"2021-11-06T21:17:54.848036","exception":false,"start_time":"2021-11-06T21:17:54.749965","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-22T15:40:14.410727Z","iopub.execute_input":"2022-03-22T15:40:14.411279Z","iopub.status.idle":"2022-03-22T15:40:14.424705Z","shell.execute_reply.started":"2022-03-22T15:40:14.411236Z","shell.execute_reply":"2022-03-22T15:40:14.423874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ltokenizer = LemmaTokenizer()\npstem = PorterStem()\n\ntrain_df[\"anchor\"] = train_df[\"anchor\"].progress_apply(ltokenizer)\ntrain_df[\"anchor\"] = train_df[\"anchor\"].progress_apply(pstem)\n\ntest_df[\"anchor\"] = test_df[\"anchor\"].progress_apply(ltokenizer)\ntest_df[\"anchor\"] = test_df[\"anchor\"].progress_apply(pstem)\n\ntrain_df[\"target\"] = train_df[\"target\"].progress_apply(ltokenizer)\ntrain_df[\"target\"] = train_df[\"target\"].progress_apply(pstem)\n\ntest_df[\"target\"] = test_df[\"target\"].progress_apply(ltokenizer)\ntest_df[\"target\"] = test_df[\"target\"].progress_apply(pstem)\n\ndisplay(train_df)\ndisplay(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:14.425741Z","iopub.execute_input":"2022-03-22T15:40:14.425997Z","iopub.status.idle":"2022-03-22T15:40:39.362673Z","shell.execute_reply.started":"2022-03-22T15:40:14.425969Z","shell.execute_reply":"2022-03-22T15:40:39.361783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n\n<a id=\"dataset_exploration\"></a>\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: gray; background-color: #ffffff;\" id=\"dataset_exploration\">\n    4&nbsp;&nbsp;DATASET EXPLORATION&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;</a>\n</h1>\n\n---","metadata":{"papermill":{"duration":0.056443,"end_time":"2021-11-06T21:17:54.960518","exception":false,"start_time":"2021-11-06T21:17:54.904075","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: gray; background-color: #ffffff;\">4.1 TRAIN METADATA</h3>\n\n---\n","metadata":{"papermill":{"duration":0.053158,"end_time":"2021-11-06T21:17:55.070372","exception":false,"start_time":"2021-11-06T21:17:55.017214","status":"completed"},"tags":[]}},{"cell_type":"code","source":"context_str2int = {\n    k:i for i,k in enumerate(list(set(\n        train_df.context.unique().tolist()+\n        test_df.context.unique().tolist()\n    )))}\ncontext_int2str = {v:k for k,v in context_str2int.items()}\nN_CONTEXT = len(context_str2int)\n\ncontext_info_df = pd.DataFrame(train_df.context.value_counts()).reset_index()\ncontext_info_df.columns=[\"context\", \"count\"]\ncontext_info_df[\"percentage\"] = 100*context_info_df[\"count\"]/context_info_df[\"count\"].sum()\ndisplay(context_info_df)\n\ntrain_df[\"n_anchor_words\"] = train_df[\"anchor\"].apply(lambda x: len(x.split()))\ntrain_df[\"n_target_words\"] = train_df[\"target\"].apply(lambda x: len(x.split()))\ndisplay(train_df)","metadata":{"papermill":{"duration":0.313817,"end_time":"2021-11-06T21:17:55.439001","exception":false,"start_time":"2021-11-06T21:17:55.125184","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-22T15:40:39.363767Z","iopub.execute_input":"2022-03-22T15:40:39.36508Z","iopub.status.idle":"2022-03-22T15:40:39.481005Z","shell.execute_reply.started":"2022-03-22T15:40:39.365037Z","shell.execute_reply":"2022-03-22T15:40:39.479842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n\n<a id=\"model_baseline\"></a>\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: gray; background-color: #ffffff;\" id=\"model_baseline\">\n    5&nbsp;&nbsp;BASELINE<a href=\"#toc\">&nbsp;&nbsp;&nbsp;&nbsp;&#10514;</a>\n</h1>\n\n---\n\nFor my baseline model I plan to do the following:\n- TFIDF\n- Simple MLP","metadata":{}},{"cell_type":"code","source":"K_FOLDS = 10\n\ntrain_df[\"split_y\"] = train_df.context.astype(str)+\"_\"+train_df.score.astype(str)\nskfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True)\n\n_df = train_df.copy()\ntrain_dfs, val_dfs = [], []\nfor train_idxs, val_idxs in skfold.split(_df, _df[\"split_y\"]):\n    val_dfs.append(_df.iloc[val_idxs].reset_index().copy())\n    train_dfs.append(_df.iloc[train_idxs].reset_index().copy())\n    \ntfidf_params = dict(\n    sublinear_tf=False,\n    max_features=10000,\n    min_df=2,\n    max_df=0.95,\n    stop_words = \"english\",\n    analyzer=\"word\",\n    ngram_range=(1,3),\n    smooth_idf=False,\n)\n\nall_sentences = train_df.anchor.to_list()+train_df.target.to_list()+test_df.anchor.to_list()+test_df.target.to_list()\n\nprint(\"\\n... Instantiating TFIDF Object ...\")\ntfidf = TfidfVectorizer(**tfidf_params)\n\nprint(\"... Fit TFIDF On Training Data ...\")\ntfidf.fit(cudf.Series(all_sentences))\n\nprint(\"... Transform Training Data ...\")\nsub_train_anchor = tfidf.transform(cudf.Series(train_dfs[0].anchor))\nsub_train_target = tfidf.transform(cudf.Series(train_dfs[0].target))\n\nprint(\"... Transform Val Data ...\")\nsub_val_anchor = tfidf.transform(cudf.Series(val_dfs[0].anchor))\nsub_val_target = tfidf.transform(cudf.Series(val_dfs[0].target))\n\nprint(\"... Transform Test Data ...\")\ntest_anchor = tfidf.transform(cudf.Series(test_df.anchor))\ntest_target = tfidf.transform(cudf.Series(test_df.target))\n\n# Back to numpy\nsub_train_anchor = sub_train_anchor.get().toarray()\nsub_val_anchor = sub_val_anchor.get().toarray()\ntest_anchor = test_anchor.get().toarray()\n\nsub_train_target = sub_train_target.get().toarray()\nsub_val_target = sub_val_target.get().toarray()\ntest_target = test_target.get().toarray()\n\n# Get context inputs\nsub_train_context = tf.one_hot([context_str2int[x] for x in train_dfs[0].context.to_list()], depth=N_CONTEXT, dtype=tf.float32)\nsub_val_context = tf.one_hot([context_str2int[x] for x in val_dfs[0].context.to_list()], depth=N_CONTEXT, dtype=tf.float32)\ntest_context = tf.one_hot([context_str2int[x] for x in test_df.context.to_list()], depth=N_CONTEXT, dtype=tf.float32)\n\n# Get labels\nsub_train_y = tf.cast(train_dfs[0].score.to_numpy(), tf.float32)\nsub_val_y = tf.cast(val_dfs[0].score.to_numpy(), tf.float32)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:40:39.482452Z","iopub.execute_input":"2022-03-22T15:40:39.487166Z","iopub.status.idle":"2022-03-22T15:41:01.535358Z","shell.execute_reply.started":"2022-03-22T15:40:39.487114Z","shell.execute_reply":"2022-03-22T15:41:01.534465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_simple_model(input_shape_1, input_shape_2, input_shape_3=(106,), dense=256, dropout=0.5, output_activation=\"sigmoid\"):\n    \"\"\" Simple one layer MLP for basic classification \"\"\"\n    # entry\n    _input_1 = tf.keras.layers.Input(shape=input_shape_1, name = 'input_anchor_tfidf', dtype=tf.float32)\n    _input_2 = tf.keras.layers.Input(shape=input_shape_2, name = 'input_target_tfidf', dtype=tf.float32)\n    _input_3 = tf.keras.layers.Input(shape=input_shape_3, name = 'input_context', dtype=tf.float32)\n    \n    # block 1\n    x1 = tf.keras.layers.Dense(dense, activation=\"relu\")(_input_1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Dropout(dropout)(x1)\n    \n    # block 2\n    x2 = tf.keras.layers.Dense(dense, activation=\"relu\")(_input_2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Dropout(dropout)(x2)\n    \n    # block 3\n    x3 = tf.keras.layers.Concatenate()([x1, x2, _input_3])\n    x3 = tf.keras.layers.Dense(dense//2, activation=\"relu\")(x3)\n    x3 = tf.keras.layers.BatchNormalization()(x3)\n    x3 = tf.keras.layers.Dropout(dropout*0.5)(x3)\n        \n    # head\n    _output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x3)\n    \n    return tf.keras.Model(inputs=[_input_1, _input_2, _input_3], outputs=_output)\n\nclass PearsonCorrelation(tf.keras.metrics.Mean):\n    def __init__(self, post_proc_fn=None, **kwargs):\n        \"\"\"Pearson Correlation Coefficient. \n        Args:\n            post_proc_fn (function, optional): Post-processing function for predicted values. Defaults to None.\n        \"\"\"\n\n        super().__init__(name='pearson_correlation', **kwargs)\n\n        self.post_proc_fn = post_proc_fn\n        if self.post_proc_fn is None:\n            self.post_proc_fn = lambda y, y_pred: (y, y_pred)\n    \n    def _compute_correlation(self, y, y_pred):\n        corr = tfp.stats.correlation(y, y_pred, sample_axis=0, event_axis=-1)\n        return corr\n\n    def _nan_to_zero(self, x):\n        is_not_nan = tf.math.logical_not(tf.math.is_nan(x))\n        is_not_nan = tf.cast(is_not_nan, tf.float32)\n\n        return tf.math.multiply_no_nan(x, is_not_nan)\n\n    def update_state(self, y, y_pred, **kwargs):\n        y, y_pred = self.post_proc_fn(y, y_pred)\n\n        corr = self._compute_correlation(y, y_pred)\n        corr = tf.squeeze(corr)\n\n        # remove any nan's that could have been created, e.g. if y or y_pred is a 0-vector\n        corr = self._nan_to_zero(corr)\n\n        # assert that there are no inf's or nan's\n        tf.debugging.assert_all_finite(corr, f'expected finite tensor, got {corr}')\n         \n        super().update_state(corr, **kwargs)\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-03-22T15:41:01.538307Z","iopub.execute_input":"2022-03-22T15:41:01.538914Z","iopub.status.idle":"2022-03-22T15:41:01.556847Z","shell.execute_reply.started":"2022-03-22T15:41:01.538871Z","shell.execute_reply":"2022-03-22T15:41:01.556006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clear memory just in case\ntf.keras.backend.clear_session(); gc.collect(); gc.collect();\n\nbaseline_model = get_simple_model(input_shape_1=sub_train_anchor.shape[-1:],\n                                  input_shape_2=sub_train_target.shape[-1:],\n                                  input_shape_3=(N_CONTEXT,), dense=256)\n\nprint(baseline_model.summary())\ntf.keras.utils.plot_model(baseline_model)\n        \nbaseline_model.compile(optimizer=tf.keras.optimizers.Adam(),\n                       loss=tf.keras.losses.Huber(),\n                       metrics=[\"mae\", PearsonCorrelation()],)\nckpt_cb = tf.keras.callbacks.ModelCheckpoint(f'./model_files', monitor='val_pearson_correlation', save_best_only=True, mode='max')\nearly_cb = tf.keras.callbacks.EarlyStopping(monitor='val_pearson_correlation', mode=\"max\", patience=10, verbose=1, restore_best_weights=False)\n\nBATCH_SIZE=16\nN_EPOCHS=60\n\nhistory = baseline_model.fit(\n    x=(sub_train_anchor, sub_train_target, sub_train_context), y=sub_train_y, \n    validation_data=((sub_val_anchor, sub_val_target, sub_val_context), sub_val_y),\n    batch_size=BATCH_SIZE, epochs=N_EPOCHS, shuffle=True,\n    callbacks=[ckpt_cb, get_lr_callback(), early_cb])","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:41:01.55845Z","iopub.execute_input":"2022-03-22T15:41:01.560328Z","iopub.status.idle":"2022-03-22T15:47:16.118018Z","shell.execute_reply.started":"2022-03-22T15:41:01.560278Z","shell.execute_reply":"2022-03-22T15:47:16.116903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get test predictions and add to dataframe\nbaseline_model.evaluate((sub_val_anchor, sub_val_target, sub_val_context), sub_val_y, verbose=1)\n\ntest_preds = baseline_model.predict((test_anchor, test_target, test_context), verbose=1)\nss_df[\"score\"] = test_preds[:, 0]\n\n# Grab any exact duplicates and force them to be perfect matches (1.0)\ntest_df[\"score\"] = ss_df[\"score\"]\nss_df[\"score\"] = test_df.progress_apply(lambda row: 1.0 if row[\"anchor\"]==row[\"target\"] else row[\"score\"], axis=1)\n\n# Save to file\nss_df.to_csv(\"submission.csv\", index=False)\n\n# Display\nss_df","metadata":{"execution":{"iopub.status.busy":"2022-03-22T15:53:41.089368Z","iopub.execute_input":"2022-03-22T15:53:41.089645Z","iopub.status.idle":"2022-03-22T15:53:43.463075Z","shell.execute_reply.started":"2022-03-22T15:53:41.089614Z","shell.execute_reply":"2022-03-22T15:53:43.462218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}