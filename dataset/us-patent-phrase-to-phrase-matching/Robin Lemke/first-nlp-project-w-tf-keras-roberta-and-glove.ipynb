{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nHi visitor,\nthis is my first NLP project and my first competition on Kaggle. I am familliar with the theoretical basics of NLP but never did a project on this topics especially with some pretrained models. So this is it. \n\nIn this project I tried two approaches of pre-trained model us. One where I load the pre-trained model manually in the embeddings layer and use that layer as a part of my model (glove) and the other one based on HuggingfacesðŸ¤— framework, where I use the from_pretrained() function which loads the whole model (with all layers).\n\nINFO: According to the Kaggle dataset situation, I could find the Deberta base model there for Tensorflow therefore I needed to choose the roBerta model. So it could therefore occur the situation you find some variable / model / checkpoint names that are still named after deberta and not roberta. I will try to fix this one after the other.\nAnd according to the current state of competition I focused on the Deberta/Roberta approach only which made my comment out the Glove model section. I will reactivate it in the final version of this notebook.\n\nI thereforce ask you to bear with?! ðŸ¤—","metadata":{}},{"cell_type":"markdown","source":"# Imports and Datasets","metadata":{}},{"cell_type":"code","source":"import sys\nassert sys.version_info >= (3,5)\nimport os\nimport pathlib\n\n# Is this notebook running on Colab or Kaggle?\nIS_COLAB = \"google.colab\" in sys.modules\nIS_KAGGLE = \"kaggle_secrets\" in sys.modules\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom functools import partial\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import LabelEncoder\n\nimport nltk\nfrom string import punctuation\nfrom collections import Counter\n\nfrom scipy.spatial.distance import cosine\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import layers\nfrom keras.layers import Embedding, LSTM, Dense, Dropout, CuDNNLSTM, Bidirectional\nfrom keras.layers.merge import concatenate\nfrom transformers import BertTokenizer, TFDebertaModel\nfrom transformers import RobertaTokenizer, TFRobertaModel, TFRobertaForSequenceClassification\n\n#import mlflow\n#from mlflow import log_metric, log_param, log_artifacts\n#import mlflow.tensorflow\n#from mlflow import pyfunc\n\nassert tf.__version__ >= \"2.0\"\n\nprint(f\"Tensorflow Version: {tf.__version__}\")\nprint(f\"Keras Version: {keras.__version__}\")\n\nif not tf.config.list_physical_devices('GPU'):\n    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n    if IS_COLAB:\n        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n    if IS_KAGGLE:\n        print(\"Go to Settings > Accelerator and select GPU.\")\nelse:\n    print(f'---Tensorflow is running with GPU Power now---')\n    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n    \n\n\nrandom_state=42\ntf.random.set_seed(random_state)\nnp.random.seed(random_state)\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','')\n#kaggle = 0 # Kaggle path active = 1\n\nMAIN_PATH = os.getcwd()\n\n# change your local path here\nif iskaggle:\n    DATA_PATH = os.path.join(MAIN_PATH, '../input')\n    PHRASES_PATH = os.path.join(DATA_PATH, 'us-patent-phrase-to-phrase-matching')\nelse:\n    DATA_PATH = os.path.join(MAIN_PATH, 'data')\n    PHRASES_PATH = os.path.join(DATA_PATH,'input\\\\us-patent-phrase-to-phrase-matching')\n\n\n\nfor dirname, _, filenames in os.walk(PHRASES_PATH): \n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:20.027605Z","iopub.execute_input":"2022-06-21T04:20:20.028162Z","iopub.status.idle":"2022-06-21T04:20:32.835033Z","shell.execute_reply.started":"2022-06-21T04:20:20.028077Z","shell.execute_reply":"2022-06-21T04:20:32.834128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get the Data","metadata":{}},{"cell_type":"code","source":"# Data path and file\nCSV_FILE_TRAIN='train.csv'\nCSV_FILE_TEST='test.csv'\nCSV_FILE_COMF='sample_submission.csv'\nCSV_FILE_CPC='titles.csv'\nCPC_PATH='cpc-codes'\nDEBERTA_PATH='huggingface-deberta-variants'\nROBERTA_PATH='roberta-base'\n\ndef load_csv_data(path, csv_file):\n    csv_path = os.path.join(path, csv_file)\n    return pd.read_csv(csv_path)\n\ndef load_csv_data_manuel(path, csv_file):\n    csv_path = os.path.join(path, csv_file)\n    csv_file = open(csv_path, 'r')\n    csv_data = csv_file.readlines()\n    csv_file.close()\n    return csv_data\n    \n\ntrain = load_csv_data(PHRASES_PATH,CSV_FILE_TRAIN)\ntest = load_csv_data(PHRASES_PATH,CSV_FILE_TEST)\ncompetition_file = load_csv_data(PHRASES_PATH,CSV_FILE_COMF)\ncpc_code = load_csv_data(os.path.join(DATA_PATH, CPC_PATH), CSV_FILE_CPC)\n\n\nprint(f'Length of loaded trainset: {len(train)}')\nprint(f'Length of loaded testset: {len(test)}')\nprint(f'Length of loaded competition file: {len(competition_file)}')\nprint(f'Length of loaded cpc_codeset: {len(cpc_code)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:32.83704Z","iopub.execute_input":"2022-06-21T04:20:32.837943Z","iopub.status.idle":"2022-06-21T04:20:33.597407Z","shell.execute_reply.started":"2022-06-21T04:20:32.837906Z","shell.execute_reply":"2022-06-21T04:20:33.596494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.join(cpc_code.set_index('code'), on = 'context')\ntest = test.join(cpc_code.set_index('code'), on = 'context')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:33.598611Z","iopub.execute_input":"2022-06-21T04:20:33.599459Z","iopub.status.idle":"2022-06-21T04:20:33.764533Z","shell.execute_reply.started":"2022-06-21T04:20:33.599399Z","shell.execute_reply":"2022-06-21T04:20:33.763708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Model Files","metadata":{}},{"cell_type":"code","source":"# change your local path here\nif iskaggle:\n    path_to_glove_file = os.path.join(DATA_PATH, 'glove6b/glove.6B.300d.txt') # kaggle datasource location\nelse:\n    path_to_glove_file = os.path.join(DATA_PATH,'glove.6B\\\\glove.6B.300d.txt')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:33.766312Z","iopub.execute_input":"2022-06-21T04:20:33.76662Z","iopub.status.idle":"2022-06-21T04:20:33.771075Z","shell.execute_reply.started":"2022-06-21T04:20:33.766595Z","shell.execute_reply":"2022-06-21T04:20:33.770367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if iskaggle:\n    DEBERTA_BASE = os.path.join(DATA_PATH, DEBERTA_PATH + '/deberta-base/deberta-base') # kaggle datasource location\nelse:\n    DEBERTA_BASE = 'microsoft/deberta-base'","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:33.772202Z","iopub.execute_input":"2022-06-21T04:20:33.773795Z","iopub.status.idle":"2022-06-21T04:20:33.779905Z","shell.execute_reply.started":"2022-06-21T04:20:33.773758Z","shell.execute_reply":"2022-06-21T04:20:33.778938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if iskaggle:\n    ROBERTA_BASE = os.path.join(DATA_PATH, ROBERTA_PATH) # kaggle datasource location\nelse:\n    ROBERTA_BASE = 'roberta-base'","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:33.781466Z","iopub.execute_input":"2022-06-21T04:20:33.781943Z","iopub.status.idle":"2022-06-21T04:20:33.790366Z","shell.execute_reply.started":"2022-06-21T04:20:33.781908Z","shell.execute_reply":"2022-06-21T04:20:33.789474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Understanding","metadata":{}},{"cell_type":"markdown","source":"## Given Attributes\n- id - a unique identifier for a pair of phrases\n- anchor - the first phrase\n- target - the second phrase\n- context - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n- score - the similarity. This is sourced from a combination of one or more manual expert ratings.\n\n\n## Score\nThe scores are in the 0-1 range with increments of 0.25 with the following meanings:\n\n- 1.0 - Very close match. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. â€œtheâ€, â€œandâ€, â€œorâ€).\n- 0.75 - Close synonym, e.g. â€œmobile phoneâ€ vs. â€œcellphoneâ€. This also includes abbreviations, e.g. \"TCP\" -> \"transmission control protocol\".\n- 0.5 - Synonyms which donâ€™t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches.\n- 0.25 - Somewhat related, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms.\n- 0.0 - Unrelated.","metadata":{}},{"cell_type":"code","source":"train['anchor'].value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:33.792396Z","iopub.execute_input":"2022-06-21T04:20:33.793143Z","iopub.status.idle":"2022-06-21T04:20:33.810129Z","shell.execute_reply.started":"2022-06-21T04:20:33.793028Z","shell.execute_reply":"2022-06-21T04:20:33.809371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The anchor value has 733 different values. Lets look at the target value.","metadata":{}},{"cell_type":"code","source":"train['target'].value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:33.811335Z","iopub.execute_input":"2022-06-21T04:20:33.811679Z","iopub.status.idle":"2022-06-21T04:20:33.837559Z","shell.execute_reply.started":"2022-06-21T04:20:33.811646Z","shell.execute_reply":"2022-06-21T04:20:33.83692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target looks a little bit different. Here we have 29,340 different values.","metadata":{}},{"cell_type":"code","source":"train['score'].value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:33.838782Z","iopub.execute_input":"2022-06-21T04:20:33.83911Z","iopub.status.idle":"2022-06-21T04:20:33.848808Z","shell.execute_reply.started":"2022-06-21T04:20:33.839078Z","shell.execute_reply":"2022-06-21T04:20:33.84787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['score'].value_counts(dropna=False).sort_index().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:33.853324Z","iopub.execute_input":"2022-06-21T04:20:33.853663Z","iopub.status.idle":"2022-06-21T04:20:34.046684Z","shell.execute_reply.started":"2022-06-21T04:20:33.853631Z","shell.execute_reply":"2022-06-21T04:20:34.045964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(['anchor', 'context']).count()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.048034Z","iopub.execute_input":"2022-06-21T04:20:34.04839Z","iopub.status.idle":"2022-06-21T04:20:34.098232Z","shell.execute_reply.started":"2022-06-21T04:20:34.048353Z","shell.execute_reply":"2022-06-21T04:20:34.097371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"markdown","source":"#### Special Tokens\nDefining the context as special token for the Tokenizer","metadata":{}},{"cell_type":"code","source":"train['context_token'] = '[' + train['context'] + ']'\ntest['context_token'] = '[' + test['context'] + ']'\ncontext_list = list(train['context_token'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.099732Z","iopub.execute_input":"2022-06-21T04:20:34.100084Z","iopub.status.idle":"2022-06-21T04:20:34.118754Z","shell.execute_reply.started":"2022-06-21T04:20:34.10005Z","shell.execute_reply":"2022-06-21T04:20:34.118019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing cpc text \ntrain['title'] = train.title.apply(lambda text: text.split(';'))\ntrain['title'] = train.title.apply(lambda context: ' '.join(context))","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.12Z","iopub.execute_input":"2022-06-21T04:20:34.120407Z","iopub.status.idle":"2022-06-21T04:20:34.334371Z","shell.execute_reply.started":"2022-06-21T04:20:34.12037Z","shell.execute_reply":"2022-06-21T04:20:34.333619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['corpus'] = train['anchor'] + ' ' + train['target']\ntrain['corpus_w_context'] = train['context_token'] + ' ' + train['corpus']\ntrain['corpus_w_full_context'] = train['context_token'] + ' ' + train['corpus'] + ' ' + train['title']\n\ntest['corpus'] = test['anchor'] + ' ' + test['target']\ntest['corpus_w_context'] = test['context_token'] + ' ' + test['corpus']\ntest['corpus_w_full_context'] = train['context_token'] + ' ' + test['corpus'] + ' ' + test['title']","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.335424Z","iopub.execute_input":"2022-06-21T04:20:34.335764Z","iopub.status.idle":"2022-06-21T04:20:34.396248Z","shell.execute_reply.started":"2022-06-21T04:20:34.335732Z","shell.execute_reply":"2022-06-21T04:20:34.395553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Identifing the features and the target.","metadata":{}},{"cell_type":"code","source":"y = train[['id','score']].copy()\nX = train[['id','anchor','target','context', 'corpus', 'title', 'corpus_w_context', 'corpus_w_full_context']].copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.397514Z","iopub.execute_input":"2022-06-21T04:20:34.39801Z","iopub.status.idle":"2022-06-21T04:20:34.416481Z","shell.execute_reply.started":"2022-06-21T04:20:34.397973Z","shell.execute_reply":"2022-06-21T04:20:34.415501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training - Validation Split","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y['score'])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.417913Z","iopub.execute_input":"2022-06-21T04:20:34.418406Z","iopub.status.idle":"2022-06-21T04:20:34.448637Z","shell.execute_reply.started":"2022-06-21T04:20:34.418369Z","shell.execute_reply":"2022-06-21T04:20:34.44791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_target = X_train['target']\nprint(f'Length of training_target - list: {len(training_target)}')\n\ntraining_content = X_train['corpus']\nprint(f'Length of training_content - list: {len(training_content)}')\n\ntraining_content_w_context = X_train['corpus_w_context']\nprint(f'Length of training_content_w_context - list: {len(training_content_w_context)}')\n\ntraining_content_full = X_train['corpus_w_full_context']\nprint(f'Length of training_content_full - list: {len(training_content_full)}')\n\n\nvalidating_content = X_val['corpus']\nprint(f'Length of validating_content - list: {len(validating_content)}')\n\nvalidating_content_w_context = X_val['corpus_w_context']\nprint(f'Length of validating_content_w_context - list: {len(validating_content_w_context)}')\n\nvalidating_content_full = X_val['corpus_w_full_context']\nprint(f'Length of validating_content_full - list: {len(validating_content_full)}')\n\n\ntest_content = test['corpus']\nprint(f'Length of test_content - list: {len(test_content)}')\n\ntest_content_full = test['corpus_w_full_context']\nprint(f'Length of test_content_full - list: {len(test_content_full)}')\n\ntraining_labels = y_train['score']\nvalidating_labels = y_val['score']\n\ntraining_labels = np.asarray(training_labels)\nvalidating_labels = np.asarray(validating_labels)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.449963Z","iopub.execute_input":"2022-06-21T04:20:34.450351Z","iopub.status.idle":"2022-06-21T04:20:34.462106Z","shell.execute_reply.started":"2022-06-21T04:20:34.450314Z","shell.execute_reply":"2022-06-21T04:20:34.461124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Label Encoding","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(y_train['score'])\n\ntraining_labels = encoder.transform(training_labels)\nvalidating_labels = encoder.transform(validating_labels)\n\ntraining_labels = training_labels.reshape(-1, 1)\nvalidating_labels = validating_labels.reshape(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.463622Z","iopub.execute_input":"2022-06-21T04:20:34.464719Z","iopub.status.idle":"2022-06-21T04:20:34.476932Z","shell.execute_reply.started":"2022-06-21T04:20:34.464679Z","shell.execute_reply":"2022-06-21T04:20:34.475794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"### Tokenization, Encoding and Padding","metadata":{}},{"cell_type":"code","source":"def extract_words(document, alpha=True):\n    '''Extracing words from a sentence or full text.\n\n    Parameters\n    ----------\n    document: str\n        Text that needs to be tokenized by nltk word_tokenize.\n    alpha: bool\n        Keep only letters or not. \n    \n    Returns\n    -------\n    set\n        A set of words from the given text.\n    '''\n    if alpha == True:\n        return set(\n            word.lower() for word in nltk.word_tokenize(document)\n            if any(c.isalpha() for c in word)\n        )\n    else:\n        return set(\n            word.lower() for word in nltk.word_tokenize(document)\n        )\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.480126Z","iopub.execute_input":"2022-06-21T04:20:34.480471Z","iopub.status.idle":"2022-06-21T04:20:34.486864Z","shell.execute_reply.started":"2022-06-21T04:20:34.480423Z","shell.execute_reply":"2022-06-21T04:20:34.485776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_docs(docs):\n    content = []\n    for doc in docs:\n        content.append(extract_words(doc))\n    return content\n\ndef max_length(lines):\n    return max([len(s.split()) for s in lines])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.488492Z","iopub.execute_input":"2022-06-21T04:20:34.489036Z","iopub.status.idle":"2022-06-21T04:20:34.49798Z","shell.execute_reply.started":"2022-06-21T04:20:34.488994Z","shell.execute_reply":"2022-06-21T04:20:34.497123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_tokenizer(lines):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(lines)\n    return tokenizer\n\ndef encode_text(tokenizer, lines, length):\n    sequences = tokenizer.texts_to_sequences(lines)\n    padded = pad_sequences(sequences, maxlen=length)\n    return padded\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.500024Z","iopub.execute_input":"2022-06-21T04:20:34.500655Z","iopub.status.idle":"2022-06-21T04:20:34.50701Z","shell.execute_reply.started":"2022-06-21T04:20:34.50058Z","shell.execute_reply":"2022-06-21T04:20:34.506297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = create_tokenizer(training_content_full)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.508167Z","iopub.execute_input":"2022-06-21T04:20:34.508645Z","iopub.status.idle":"2022-06-21T04:20:34.929751Z","shell.execute_reply.started":"2022-06-21T04:20:34.508609Z","shell.execute_reply":"2022-06-21T04:20:34.92896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\nmax_line_length = max_length(training_content_full)\nword_count = tokenizer.word_counts\nword_index = tokenizer.word_index\noov_tok = \"<OOV>\"\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.931179Z","iopub.execute_input":"2022-06-21T04:20:34.931677Z","iopub.status.idle":"2022-06-21T04:20:34.961282Z","shell.execute_reply.started":"2022-06-21T04:20:34.931642Z","shell.execute_reply":"2022-06-21T04:20:34.960489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_content_enc = encode_text(tokenizer, training_content_full, max_line_length)\nprint(f'Shape training set (encoded): {training_content_enc.shape}')\n\nvalidating_content_enc = encode_text(tokenizer, validating_content_full, max_line_length)\nprint(f'Shape validating set (encoded): {validating_content_enc.shape}')\n\nprint(f'Vocabulary size: {vocab_size}')\nprint(f'Max line lenght: {max_line_length}')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:34.962435Z","iopub.execute_input":"2022-06-21T04:20:34.963037Z","iopub.status.idle":"2022-06-21T04:20:35.592815Z","shell.execute_reply.started":"2022-06-21T04:20:34.963008Z","shell.execute_reply":"2022-06-21T04:20:35.591997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpers for Deep Neural Network Training","metadata":{}},{"cell_type":"markdown","source":"#### Params for the Glove based model","metadata":{}},{"cell_type":"code","source":"# Main params for the model\nembedding_dim = 300 # according to the pretrained network\nhits = 0\nmisses = 0\nlr = 0.0000008\nbatch_size = 512\nnum_epochs = 50","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:35.593936Z","iopub.execute_input":"2022-06-21T04:20:35.59472Z","iopub.status.idle":"2022-06-21T04:20:35.600245Z","shell.execute_reply.started":"2022-06-21T04:20:35.594681Z","shell.execute_reply":"2022-06-21T04:20:35.599529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Params for Deberta/Roberta based model","metadata":{}},{"cell_type":"code","source":"lr_roberta = 0.000006   # 0.000006 <-70\nnum_epochs_roberta = 5 #8 #5\nbatch_size_roberta = 16","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:35.601325Z","iopub.execute_input":"2022-06-21T04:20:35.601879Z","iopub.status.idle":"2022-06-21T04:20:35.610929Z","shell.execute_reply.started":"2022-06-21T04:20:35.601843Z","shell.execute_reply":"2022-06-21T04:20:35.610205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\n\n# Tensorboard logging structure function\nroot_logdir = \"../../tensorboard-logs\"\n\ndef get_run_logdir(root_logdir, project):\n    '''\n    Returns logdir to the Tensorboard log for a specific project.\n\n            Parameters:\n                    root_logdir (str) : basic logdir from Tensorboard\n                    project (str): projectname that will be logged in TB\n\n            Returns:\n                    os.path (str): Path to the final logdir\n    '''\n    import time\n    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n    project_logdir = os.path.join(root_logdir,project)\n    return os.path.join(project_logdir, run_id)\n\n\ndef lr_scheduler(epoch):\n  \"\"\"\n  Returns a custom learning rate that decreases as epochs progress.\n  \"\"\"\n  decay = 0.1 #1\n  init_lr = lr_roberta \n  learning_rate = init_lr * (1 / (1 + decay * epoch))\n\n  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n  return learning_rate\n\n\ndef lr_scheduler_2(epoch):\n    learning_rate = 2e-6 # 0.000006\n    if epoch == 0:\n        return learning_rate * 0.06 #0.000006\n    else:\n        return learning_rate * (0.9**epoch)\n\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase\"), histogram_freq=1)\ntensorboard_callback_roberta = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase_roberta\"), histogram_freq=1)\nlr_callback_roberta = tf.keras.callbacks.LearningRateScheduler(lr_scheduler_2)\n\ncheckpoint_cb_roberta = keras.callbacks.ModelCheckpoint(\"trained_model_cp.h5\", save_best_only=True, save_weights_only=True, monitor='val_loss', save_freq='epoch')\nearlystopping_roberta = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:35.612265Z","iopub.execute_input":"2022-06-21T04:20:35.612856Z","iopub.status.idle":"2022-06-21T04:20:36.506001Z","shell.execute_reply.started":"2022-06-21T04:20:35.612822Z","shell.execute_reply":"2022-06-21T04:20:36.505206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([lr_scheduler(e) for e in range(10)])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:36.510725Z","iopub.execute_input":"2022-06-21T04:20:36.51137Z","iopub.status.idle":"2022-06-21T04:20:36.980139Z","shell.execute_reply.started":"2022-06-21T04:20:36.511338Z","shell.execute_reply":"2022-06-21T04:20:36.979319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Development Based on Glove","metadata":{}},{"cell_type":"markdown","source":"## Pre-Trained Embeddings Load","metadata":{}},{"cell_type":"code","source":"embeddings_index = {}\nwith open(path_to_glove_file ,encoding=\"utf8\") as f:\n    for line in f:\n        word, coefs = line.split(maxsplit=1)\n        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n        embeddings_index[word] = coefs\n\nprint(f\"Found {len(embeddings_index)} word vectors.\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:20:36.981275Z","iopub.execute_input":"2022-06-21T04:20:36.981622Z","iopub.status.idle":"2022-06-21T04:21:11.442702Z","shell.execute_reply.started":"2022-06-21T04:20:36.981588Z","shell.execute_reply":"2022-06-21T04:21:11.439957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preparing a corresponding embedding matrix for the Embedding layer in Keras.\n\nAccording to the choosen pre-trained embedding matrix we need to set the embedding dimension on 100.","metadata":{}},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, i in tokenizer.word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n        hits += 1\n    else:\n        misses += 1\n\nprint(f\"Converted {hits} words ({misses} misses)\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:11.447146Z","iopub.execute_input":"2022-06-21T04:21:11.447617Z","iopub.status.idle":"2022-06-21T04:21:11.489923Z","shell.execute_reply.started":"2022-06-21T04:21:11.447571Z","shell.execute_reply":"2022-06-21T04:21:11.488998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building\n### The new Embedding Layer\nNow loading the pre-trained word embedding matrix into the embedding layer. According to the pre-trained embedding load the trainable param needst to be set on \"False\".","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential(\n    [\n    keras.layers.Embedding(    \n        vocab_size,\n        embedding_dim,\n        input_shape = [None],\n        input_length=max_line_length,\n        mask_zero=True,\n        weights=[embedding_matrix],\n        trainable = False),\n    keras.layers.SpatialDropout1D(0.3),\n    keras.layers.LSTM(300, return_sequences=True),\n    keras.layers.LSTM(300),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation('relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(5, activation='softmax' )\n    ]\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:11.493891Z","iopub.execute_input":"2022-06-21T04:21:11.494278Z","iopub.status.idle":"2022-06-21T04:21:13.118544Z","shell.execute_reply.started":"2022-06-21T04:21:11.494241Z","shell.execute_reply":"2022-06-21T04:21:13.117725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy',\n                #optimizer=keras.optimizers.Nadam(learning_rate=lr, beta_1=mmt),\n                optimizer=keras.optimizers.Adam(),\n                metrics=['accuracy']\n                )","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:13.119646Z","iopub.execute_input":"2022-06-21T04:21:13.120103Z","iopub.status.idle":"2022-06-21T04:21:13.135297Z","shell.execute_reply.started":"2022-06-21T04:21:13.120063Z","shell.execute_reply":"2022-06-21T04:21:13.134608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:13.136368Z","iopub.execute_input":"2022-06-21T04:21:13.136814Z","iopub.status.idle":"2022-06-21T04:21:13.142867Z","shell.execute_reply.started":"2022-06-21T04:21:13.136776Z","shell.execute_reply":"2022-06-21T04:21:13.141962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, to_file='multichannel.png')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:13.144148Z","iopub.execute_input":"2022-06-21T04:21:13.144704Z","iopub.status.idle":"2022-06-21T04:21:14.217027Z","shell.execute_reply.started":"2022-06-21T04:21:13.144658Z","shell.execute_reply":"2022-06-21T04:21:14.216096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    np.asarray(training_content_enc),\n    np.asarray(training_labels),\n    batch_size=batch_size,      # small batch size are better but costs a lot of time\n    epochs=num_epochs,\n    validation_data=(\n        np.asarray(validating_content_enc),\n        np.asarray(validating_labels)),\n    verbose=1,\n    callbacks=[tensorboard_callback])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:14.220056Z","iopub.execute_input":"2022-06-21T04:21:14.220498Z","iopub.status.idle":"2022-06-21T04:21:49.452807Z","shell.execute_reply.started":"2022-06-21T04:21:14.220453Z","shell.execute_reply":"2022-06-21T04:21:49.450038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save(\"LSTM_model_label_encoding_4.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.45407Z","iopub.status.idle":"2022-06-21T04:21:49.454545Z","shell.execute_reply.started":"2022-06-21T04:21:49.454303Z","shell.execute_reply":"2022-06-21T04:21:49.454325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Second Model Development based on Deberta ðŸ¤—","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import TFAutoModelForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.457115Z","iopub.status.idle":"2022-06-21T04:21:49.457814Z","shell.execute_reply.started":"2022-06-21T04:21:49.457576Z","shell.execute_reply":"2022-06-21T04:21:49.4576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer_roberta = AutoTokenizer.from_pretrained(ROBERTA_BASE)\ntokenizer_roberta.add_special_tokens({'additional_special_tokens': context_list})","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.458941Z","iopub.status.idle":"2022-06-21T04:21:49.459638Z","shell.execute_reply.started":"2022-06-21T04:21:49.459382Z","shell.execute_reply":"2022-06-21T04:21:49.459407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_roberta = TFAutoModelForSequenceClassification.from_pretrained(ROBERTA_BASE, trainable=True, return_dict=True, num_labels=5, output_hidden_states=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.460902Z","iopub.status.idle":"2022-06-21T04:21:49.462808Z","shell.execute_reply.started":"2022-06-21T04:21:49.462559Z","shell.execute_reply":"2022-06-21T04:21:49.462584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trying around Huggingfaces Model and Tokenizer Structure\nThe following small try and errors for getting familiar with this framework is based on this huggingface documentation: https://huggingface.co/docs/transformers/glossary#:~:text=token%3A%20a%20part%20of%20a,based%20deep%20learning%20model%20architecture.\n\nAnd this might be interesting for the Tokenizer topic as well: https://huggingface.co/docs/transformers/preprocessing\n","metadata":{}},{"cell_type":"markdown","source":"### Experiments with Deberta Tokenizer (ðŸ¤—)\nConverting a test sentence with doberta tokenizer","metadata":{}},{"cell_type":"code","source":"test_text_tok = tokenizer_roberta('This is a Test')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.463892Z","iopub.status.idle":"2022-06-21T04:21:49.464487Z","shell.execute_reply.started":"2022-06-21T04:21:49.464239Z","shell.execute_reply":"2022-06-21T04:21:49.464262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Printing the results","metadata":{}},{"cell_type":"code","source":"test_text_tok","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.465713Z","iopub.status.idle":"2022-06-21T04:21:49.466332Z","shell.execute_reply.started":"2022-06-21T04:21:49.466091Z","shell.execute_reply":"2022-06-21T04:21:49.466115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Printing the encoded results of the test sentence","metadata":{}},{"cell_type":"code","source":"test_text_tok[\"input_ids\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.467473Z","iopub.status.idle":"2022-06-21T04:21:49.468089Z","shell.execute_reply.started":"2022-06-21T04:21:49.467855Z","shell.execute_reply":"2022-06-21T04:21:49.467878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decoding the encoded test sentence back to its original form","metadata":{}},{"cell_type":"code","source":"tokenizer_roberta.decode(test_text_tok[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.469191Z","iopub.status.idle":"2022-06-21T04:21:49.469801Z","shell.execute_reply.started":"2022-06-21T04:21:49.469559Z","shell.execute_reply":"2022-06-21T04:21:49.469582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Attention Mask","metadata":{}},{"cell_type":"code","source":"sentence_a = \"This is a test\"\nsentence_b = \"This is a test as well but its longer, much longer, longer than any other test could be\"","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.470905Z","iopub.status.idle":"2022-06-21T04:21:49.471515Z","shell.execute_reply.started":"2022-06-21T04:21:49.471268Z","shell.execute_reply":"2022-06-21T04:21:49.471291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encoding both sentences and retrieving the ids only","metadata":{}},{"cell_type":"code","source":"encoded_sen_a = tokenizer_roberta(sentence_a)[\"input_ids\"]\nencoded_sen_b = tokenizer_roberta(sentence_b)[\"input_ids\"]\n\nprint(f'sentence a encoded: {encoded_sen_a}')\nprint(f'sentence b encoded: {encoded_sen_b}')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.472618Z","iopub.status.idle":"2022-06-21T04:21:49.473225Z","shell.execute_reply.started":"2022-06-21T04:21:49.472989Z","shell.execute_reply":"2022-06-21T04:21:49.473013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once again tokenizing the sentences but with padding activated","metadata":{}},{"cell_type":"code","source":"padded_sentences = tokenizer_roberta([sentence_a, sentence_b], padding=True)\n\nprint(f'Sentences encoded: {padded_sentences[\"input_ids\"]}')\nprint(f'Sentences att.msk: {padded_sentences[\"attention_mask\"]}')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.474304Z","iopub.status.idle":"2022-06-21T04:21:49.474919Z","shell.execute_reply.started":"2022-06-21T04:21:49.474684Z","shell.execute_reply":"2022-06-21T04:21:49.474709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Processing the Data for Roberta Model","metadata":{}},{"cell_type":"code","source":"MAX_LINE_LENGTH_BERT = len(tokenizer_roberta(X_train['corpus_w_full_context'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")[1])\nprint(f\"Maximum sentence length is: {MAX_LINE_LENGTH_BERT}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.476003Z","iopub.status.idle":"2022-06-21T04:21:49.476609Z","shell.execute_reply.started":"2022-06-21T04:21:49.476358Z","shell.execute_reply":"2022-06-21T04:21:49.476381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer_roberta(examples['corpus_w_full_context'].tolist(), padding='max_length', truncation=True, return_tensors=\"tf\", max_length=MAX_LINE_LENGTH_BERT)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.477721Z","iopub.status.idle":"2022-06-21T04:21:49.478308Z","shell.execute_reply.started":"2022-06-21T04:21:49.478075Z","shell.execute_reply":"2022-06-21T04:21:49.478098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train.map(preprocess_function, batched=True)\ntrain_encoded = preprocess_function(X_train)\nval_encoded = preprocess_function(X_val)\n\nprint(f'Length of the train-sentences [padded]: {train_encoded[\"input_ids\"].shape[1]}')\nprint(f'Length of the val-sentences [padded]: {val_encoded[\"input_ids\"].shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.479404Z","iopub.status.idle":"2022-06-21T04:21:49.48002Z","shell.execute_reply.started":"2022-06-21T04:21:49.479789Z","shell.execute_reply":"2022-06-21T04:21:49.479812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Build\n","metadata":{}},{"cell_type":"code","source":"print(f'Number of labels, that came from deberta model: {model_roberta.num_labels}')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.481105Z","iopub.status.idle":"2022-06-21T04:21:49.481724Z","shell.execute_reply.started":"2022-06-21T04:21:49.481477Z","shell.execute_reply":"2022-06-21T04:21:49.4815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_input_ids_ = tf.keras.Input(shape = (MAX_LINE_LENGTH_BERT, ), dtype = tf.int32)\n_attention_mask_ = tf.keras.Input(shape = (MAX_LINE_LENGTH_BERT, ), dtype = tf.int32)\n\nx = model_roberta(\n                input_ids = _input_ids_,\n                attention_mask = _attention_mask_,\n                output_hidden_states=True\n                )\n#print(x)\n#print('-----------------------------------')\n#print(x.hidden_states)\n#print('-----------------------------------')\n#print(x[0].hidden_states[-1])\n#print('-----------------------------------')\n#print(x.last_hidden_state)\nx = tf.keras.layers.GlobalAveragePooling1D()(x.hidden_states[-1])\nx = tf.keras.layers.Dropout(0.3)(x)\n#x = tf.keras.layers.Dense(32, activation='relu')(x)\noutput = tf.keras.layers.Dense(5, activation='softmax')(x)\n\nmodel2 = tf.keras.Model(inputs = [_input_ids_, _attention_mask_], \n                        outputs = output\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.482828Z","iopub.status.idle":"2022-06-21T04:21:49.483433Z","shell.execute_reply.started":"2022-06-21T04:21:49.483199Z","shell.execute_reply":"2022-06-21T04:21:49.483223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.compile(loss='sparse_categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.484522Z","iopub.status.idle":"2022-06-21T04:21:49.485125Z","shell.execute_reply.started":"2022-06-21T04:21:49.484894Z","shell.execute_reply":"2022-06-21T04:21:49.484917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.486213Z","iopub.status.idle":"2022-06-21T04:21:49.486998Z","shell.execute_reply.started":"2022-06-21T04:21:49.486762Z","shell.execute_reply":"2022-06-21T04:21:49.486785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Fit","metadata":{}},{"cell_type":"code","source":"history_model2 = model2.fit(x=(np.asarray(train_encoded['input_ids']),\n                                np.asarray(train_encoded['attention_mask'])\n                                ),\n                                y=np.asarray(training_labels).ravel(),\n                                validation_data=((np.asarray(val_encoded['input_ids']),\n                                                  np.asarray(val_encoded['attention_mask'])),\n                                                np.asarray(validating_labels)\n                                                ),\n                                epochs=num_epochs_roberta,\n                                batch_size=batch_size_roberta,\n                                callbacks =[tensorboard_callback_roberta,\n                                            lr_callback_roberta,\n                                            checkpoint_cb_roberta,\n                                            earlystopping_roberta]) #lr_callback rlrop","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.488099Z","iopub.status.idle":"2022-06-21T04:21:49.488714Z","shell.execute_reply.started":"2022-06-21T04:21:49.488466Z","shell.execute_reply":"2022-06-21T04:21:49.488491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.save(\"roberta_trained_10_epochs_specialtokens.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.489817Z","iopub.status.idle":"2022-06-21T04:21:49.490405Z","shell.execute_reply.started":"2022-06-21T04:21:49.490171Z","shell.execute_reply":"2022-06-21T04:21:49.490194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from keras.models import load_model\n# Or load the saved model from the callback : deberta_trained_model.h5\n# model2.load_weights('deberta_trained_model.h5') #deberta_trained_10_epochs_decay_lr_1 # deberta_trained_3_epochs_decay_lr","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.491502Z","iopub.status.idle":"2022-06-21T04:21:49.4921Z","shell.execute_reply.started":"2022-06-21T04:21:49.491867Z","shell.execute_reply":"2022-06-21T04:21:49.491891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Test with all Validation Data [Glove]","metadata":{}},{"cell_type":"code","source":"evaluation_glove = model.evaluate(np.asarray(validating_content_enc),\n                             np.asarray(validating_labels), verbose=0)\n    \nprint(f'Models validation loss: {evaluation_glove[0]} - Models validation accuracy: {evaluation_glove[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.493193Z","iopub.status.idle":"2022-06-21T04:21:49.493818Z","shell.execute_reply.started":"2022-06-21T04:21:49.493574Z","shell.execute_reply":"2022-06-21T04:21:49.493598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Accuracy Curve","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.title('lrate='+str(lr), pad=-50)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.4949Z","iopub.status.idle":"2022-06-21T04:21:49.495512Z","shell.execute_reply.started":"2022-06-21T04:21:49.495261Z","shell.execute_reply":"2022-06-21T04:21:49.495284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loss Curve","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.496596Z","iopub.status.idle":"2022-06-21T04:21:49.497203Z","shell.execute_reply.started":"2022-06-21T04:21:49.496969Z","shell.execute_reply":"2022-06-21T04:21:49.496992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test with all Validation Data [Roberta]","metadata":{}},{"cell_type":"code","source":"evaluation_roberta = model2.evaluate((np.asarray(val_encoded['input_ids']),\n                              np.asarray(val_encoded['attention_mask']),\n                             ),\n                             validating_labels, verbose=0)\n\nprint(f'Models validation loss: {evaluation_roberta[0]} - Models validation accuracy: {evaluation_roberta[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.498294Z","iopub.status.idle":"2022-06-21T04:21:49.498908Z","shell.execute_reply.started":"2022-06-21T04:21:49.498673Z","shell.execute_reply":"2022-06-21T04:21:49.498697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Accuracy Curve","metadata":{}},{"cell_type":"code","source":"plt.plot(history_model2.history['accuracy'], label='train')\nplt.plot(history_model2.history['val_accuracy'], label='test')\nplt.title('lrate='+str(lr), pad=-50)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T04:21:49.499985Z","iopub.status.idle":"2022-06-21T04:21:49.500587Z","shell.execute_reply.started":"2022-06-21T04:21:49.500342Z","shell.execute_reply":"2022-06-21T04:21:49.500365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loss Curve","metadata":{}},{"cell_type":"code","source":"plt.plot(history_model2.history['loss'])\nplt.plot(history_model2.history['val_loss'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission File","metadata":{}},{"cell_type":"markdown","source":"## Training on all Data","metadata":{}},{"cell_type":"markdown","source":"## Prediction of Test File Values","metadata":{}},{"cell_type":"code","source":"#competition_file = pd.DataFrame(columns=['score'])\ncompetition_file = pd.read_csv(PHRASES_PATH + \"/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:40:43.359409Z","iopub.execute_input":"2022-06-18T19:40:43.359974Z","iopub.status.idle":"2022-06-18T19:40:43.36843Z","shell.execute_reply.started":"2022-06-18T19:40:43.359941Z","shell.execute_reply":"2022-06-18T19:40:43.367592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_encoded = preprocess_function(test)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:40:49.6908Z","iopub.execute_input":"2022-06-18T19:40:49.69114Z","iopub.status.idle":"2022-06-18T19:40:49.70035Z","shell.execute_reply.started":"2022-06-18T19:40:49.691111Z","shell.execute_reply":"2022-06-18T19:40:49.69962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prediction = model2.predict((np.asarray(test_encoded['input_ids']),\n                                  np.asarray(test_encoded['attention_mask']) \n                                  ))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"competition_file['score'] = encoder.inverse_transform(np.argmax(test_prediction, axis=1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"competition_file['score'].hist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"competition_file.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}