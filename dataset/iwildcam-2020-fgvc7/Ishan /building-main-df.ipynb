{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nimport json\nimport seaborn as sns\nfrom datetime import datetime\nimport os\n%matplotlib inline\n\n# loading datasets as json\nwith open(\"../input/iwildcam-2020-fgvc7/iwildcam2020_megadetector_results.json\") as json_file:\n    megadetector_results = json.load(json_file)\nwith open(\"../input/iwildcam-2020-fgvc7/iwildcam2020_test_information.json\") as json_file:\n    test_information = json.load(json_file)\nwith open(\"../input/iwildcam-2020-fgvc7/iwildcam2020_train_annotations.json\") as json_file:\n    train_annotations = json.load(json_file)\n\n# converting into dataframes\nmegadetector_images = pd.DataFrame(megadetector_results[\"images\"])\nmegadetector_cat = megadetector_results[\"detection_categories\"] # not a dataframe\n\ntest_cat = pd.DataFrame(test_information[\"categories\"])\ntest_images = pd.DataFrame(test_information[\"images\"])\n\ntrain_annot = pd.DataFrame(train_annotations[\"annotations\"])\ntrain_images = pd.DataFrame(train_annotations[\"images\"])\ntrain_cat = pd.DataFrame(train_annotations[\"categories\"])\n\nsample_submission = pd.read_csv(\"/kaggle/input/iwildcam-2020-fgvc7/sample_submission.csv\")\n\n#images\ntrain_jpg = glob.glob('../input/iwildcam-2020-fgvc7/train/*')\ntest_jpg = glob.glob('../input/iwildcam-2020-fgvc7/test/*')\n\n# # some files are giving error later. So its better to get rid of them right now. This takes a lot of time \n# to_remove = []\n# count = 0\n# for i in train_jpg:\n#     count+=1\n#     try:\n#         img = Image.open(i)\n#     except:\n#         to_remove.append(i)\n#     if (count%100) == 0:\n#         print(count)\n\n# to_remove\n\n# for i in to_remove:\n#     train_jpg.remove(i)\n\n# these are the files\nfor i in ['../input/iwildcam-2020-fgvc7/train/87022118-21bc-11ea-a13a-137349068a90.jpg',\n '../input/iwildcam-2020-fgvc7/train/8f17b296-21bc-11ea-a13a-137349068a90.jpg',\n '../input/iwildcam-2020-fgvc7/train/8792549a-21bc-11ea-a13a-137349068a90.jpg',\n '../input/iwildcam-2020-fgvc7/train/883572ba-21bc-11ea-a13a-137349068a90.jpg',\n '../input/iwildcam-2020-fgvc7/train/896c1198-21bc-11ea-a13a-137349068a90.jpg',\n '../input/iwildcam-2020-fgvc7/train/99136aa6-21bc-11ea-a13a-137349068a90.jpg']:\n    train_jpg.remove(i)\n    train_images.drop(train_images[train_images.file_name == i[35:]].index ,axis = 0, inplace= True)\n\n# megadetector\ndef special_func(list_x):\n    '''\n    Will be used below to make sure all bounding boxes are entered when there are multiple animals detected in an image. \n    '''\n    list_return = []\n    for i in list_x:\n        list_return.append(i[\"bbox\"])\n    return list_return\n\nmegadetector_images[\"conf\"] = megadetector_images.detections.apply(lambda x: float(x[0][\"conf\"]) if x!=[] else 0)\nmegadetector_images[\"category\"] = megadetector_images.detections.apply(lambda x: x[0][\"category\"] if x!=[] else 0)\nmegadetector_images[\"bbox\"] = megadetector_images.detections.apply(lambda x: [x[0][\"bbox\"]] if len(x)==1 else (special_func(x) if len(x)>1 else []))\nmegadetector_images[\"cat\"] = megadetector_images.category.map(megadetector_cat)\nmegadetector_images.drop([\"max_detection_conf\", \"detections\"], axis = 1, inplace= True)\nmegadetector_images[\"category\"] = megadetector_images.category.apply(lambda x: int(x))\n\nmega = megadetector_images.copy()\n\n# making final test\ntemp_test = pd.merge(test_images, megadetector_images, how = \"left\", on = \"id\")\n\n# making a unified train dataset\ntrain_images.rename({\"id\":\"image_id\"}, axis = 1, inplace= True)\n\ntrain = train_images.merge(train_annot, on = \"image_id\", how = \"inner\")\n\ntrain = train.merge(train_cat.drop(\"count\", axis=1).rename({\"id\":\"category_id\"}, axis = 1))\n\n# making main df\ndf = train.merge(mega.rename({\"id\":\"image_id\"}, axis = 1), how = \"left\")\n\n# handling null entries\ndf.conf = df.conf.fillna(0.0)\ndf.category = df.category.fillna(0)\ndf.loc[df.bbox[df.bbox.isnull()].index,\"bbox\"] = [[[]] * df.bbox.isnull().sum()]\ndf.loc[df.cat[df.cat.isnull()].index, \"cat\"] = \"none\"\n\ntemp_test.conf = temp_test.conf.fillna(0.0)\ntemp_test.category = temp_test.category.fillna(0)\ntemp_test.loc[temp_test.bbox[temp_test.bbox.isnull()].index,\"bbox\"] = [[[]] * temp_test.bbox.isnull().sum()]\ntemp_test.loc[temp_test.cat[temp_test.cat.isnull()].index, \"cat\"] = \"none\"\n\n# making sure the top 2 bboxes for each image have been included as different rows\nbbox_df = pd.DataFrame.from_records(df.bbox)\nbbox_df = bbox_df.loc[:,:1]\n\nempty_df = pd.DataFrame(columns = df.columns)\ndf = pd.concat([df, bbox_df], axis = 1)\n\ncols = bbox_df.columns\nfor i in cols:\n    remove_list = [x for x in cols if x != i] \n    remove_list.append(\"bbox\")\n    current = df.drop(remove_list, axis = 1)\n    current.rename({i:\"bbox\"}, axis = 1, inplace= True)\n    current.dropna(inplace = True)\n    empty_df = pd.concat([empty_df, current], axis = 0)\n\n# concatenating the records with empty bbox\ndf = pd.concat([empty_df, df.iloc[df.bbox.index[df.bbox.apply(lambda x: x == []) == True],:-2]], axis = 0)\n\nprint(df.shape)\nprint(temp_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_test.to_pickle(\"test.pkl\")\ndf.to_pickle(\"df.pkl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some Exploring that we done (might help later if you wanted to explore and see how the data looked like or what all assumptions we checked for)"},{"metadata":{"trusted":true},"cell_type":"code","source":"### megadetector\n# # checking if conf and max_detection_conf are the same or not\n# sum(megadetector_images.conf == megadetector_images.max_detection_conf) == megadetector_images.shape[0]\n\n# print(megadetector_images.category.unique())\n# print(megadetector_images.cat.unique())\n# print(megadetector_cat)\n\n# def check_megadetector_img(img_id):\n#     complete_id = '../input/iwildcam-2020-fgvc7/train/'+img_id+'.jpg'\n#     plt.figure(figsize = (6,5))\n#     img = Image.open(complete_id)\n#     plt.imshow(img)\n#     print(megadetector_images[megadetector_images.id ==img_id][[\"cat\", \"conf\", \"bbox\"]])\n\n# # check images and respective confidence, category and bbox \n# check_megadetector_img(megadetector_images.loc[4,\"id\"])\n\n# # distribution of categories in megadetector\n# sns.countplot(megadetector_images.fillna(\"missing\").cat)\n\n### train\n# confirming that id column has unique ids\n# print(train_annot.image_id.value_counts()[train_annot.image_id.value_counts()>1])\n# print(train_images.id.value_counts()[train_images.id.value_counts()>1])\n# plt.figure(figsize = (50,10))\n# sns.countplot(train.category_id)\n# plt.title(\"Distirbution of Categories\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rough"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nimport cv2\n\nsub = df.head(100)\n\ndf.datetime = pd.to_datetime(df.datetime)\n\ndf[\"time\"] = df.datetime.apply(lambda x: x.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = df[df.time > datetime.strptime(\"23:00:00\", \"%H:%M:%S\").time()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im = Image.open(\"../input/iwildcam-2020-fgvc7/train/\" + sub[\"file_name\"].iloc[0])\nplt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.iloc[0].bbox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.iloc[62].bbox[1] - sub.iloc[62].bbox[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im = cv2.imread(\"../input/iwildcam-2020-fgvc7/train/\" + sub[\"file_name\"].iloc[62])\nplt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def adjust_gamma(image, gamma=1.0):\n\t# build a lookup table mapping the pixel values [0, 255] to\n\t# their adjusted gamma values\n\tinvGamma = 1.0 / gamma\n\ttable = np.array([((i / 255.0) ** invGamma) * 255\n\t\tfor i in np.arange(0, 256)]).astype(\"uint8\")\n\t# apply gamma correction using the lookup table\n\treturn cv2.LUT(image, table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_gamma = adjust_gamma(im, 1.5)\nplt.imshow(im_gamma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(im)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Problems to fix"},{"metadata":{},"cell_type":"markdown","source":"1. A lot of images are in a sequence and thus all dont need to be used. \n2. Try removing images that do not have a significant portion of the animal based on thier bbox dimensions\n3. Images should be selectively applied gamma function to"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}