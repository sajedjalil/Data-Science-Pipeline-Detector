{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"9aa3ba8b-da90-eac2-bfd8-59d3d7006ae9"},"source":"### Imports"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d85683f-ca36-743b-64ce-1a36ec0d4c5a"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model\nfrom sklearn import tree\nfrom sklearn import neighbors\nfrom sklearn import ensemble\nfrom sklearn import svm\nfrom sklearn import gaussian_process\nfrom sklearn import naive_bayes\nfrom sklearn import neural_network\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"768caeb1-e5f6-d8ec-1012-69eff3ee4928"},"outputs":[],"source":"testset = pd.read_csv(\"../input/test.csv\")\ntrainset = pd.read_csv(\"../input/train.csv\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"f6c77c63-421e-f18f-61ca-570ebc93f4e8"},"source":"### Show feature scatterplot"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"484b3f1f-42c5-8d69-f8b5-c78e34edc3ab"},"outputs":[],"source":"sns.set()\nsns.pairplot(trainset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\", \"type\"]], hue=\"type\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"36030d1c-501e-d175-3d2c-62cf549aef44"},"source":"### Creating additional features\nIt seems as if a combination of the features *has_soul* and *hair_length* can help us classify the monsters better. So therefor I will create an additional column which contains the product of these two."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4918afb-099a-9496-d5f8-3532aca19612"},"outputs":[],"source":"trainset['hair_soul'] = trainset.apply(lambda row: row['hair_length']*row['has_soul'],axis=1)\ntrainset['hair_bone'] = trainset.apply(lambda row: row['hair_length']*row['bone_length'],axis=1)\ntrainset['bone_soul'] = trainset.apply(lambda row: row['bone_length']*row['has_soul'],axis=1)\ntrainset['hair_soul_bone'] = trainset.apply(lambda row: row['hair_length']*row['has_soul']*row['bone_length'],axis=1)\n\ntestset['hair_soul'] = testset.apply(lambda row: row['hair_length']*row['has_soul'],axis=1)\ntestset['hair_bone'] = testset.apply(lambda row: row['hair_length']*row['bone_length'],axis=1)\ntestset['bone_soul'] = testset.apply(lambda row: row['bone_length']*row['has_soul'],axis=1)\ntestset['hair_soul_bone'] = testset.apply(lambda row: row['hair_length']*row['has_soul']*row['bone_length'],axis=1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"668ba171-2be1-8be9-5c0c-229b3e7730dd"},"source":"Let's analyse the new features in a pairplot."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43a52cf6-765a-3125-a753-de02e6f39a6c"},"outputs":[],"source":"sns.set()\nsns.pairplot(trainset[[\"hair_soul\", \"hair_bone\", \"bone_soul\", \"hair_soul_bone\", \"type\"]], hue=\"type\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"247121d3-08b6-0bbb-12d8-000fbe370958"},"source":"### Create dataframes\nSelecting columns and onehot-encoding column \"color\". It seems that the color does not really help the predictions. So I left it out completely. Additionally I created two sets with the artificial features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"924d77a2-2726-656a-4019-fa7ea603a0e9"},"outputs":[],"source":"#x = pd.concat([trainset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\", \"hair_soul\", \"hair_bone\", \"bone_soul\", \"hair_soul_bone\"]], pd.get_dummies(trainset[\"color\"])], axis=1)\nx = trainset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\", \"hair_soul\", \"hair_bone\", \"bone_soul\", \"hair_soul_bone\"]]\nx_original = trainset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\"]]\nx_hair_soul = trainset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\", \"hair_soul\"]]\ny = trainset[[\"type\"]]\n#x_test = pd.concat([testset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\", \"hair_soul\", \"hair_bone\", \"bone_soul\", \"hair_soul_bone\"]], pd.get_dummies(testset[\"color\"])], axis=1)\nx_test = testset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\", \"hair_soul\", \"hair_bone\", \"bone_soul\", \"hair_soul_bone\"]]\nx_test_original = testset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\"]]\nx_test_hair_soul = testset[[\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\", \"hair_soul\"]]"},{"cell_type":"markdown","metadata":{"_cell_guid":"a20cc5ad-f94c-7043-fc2a-57bdc309868e"},"source":"### Creating set of classifiers"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9751a92f-cbe7-33c0-a386-576037b58f40"},"outputs":[],"source":"clfs = {}\n\n#clfs['lr'] = {'clf': linear_model.LogisticRegression(), 'name':'LogisticRegression'}\n#clfs['rf'] = {'clf': ensemble.RandomForestClassifier(n_estimators=750, n_jobs=-1), 'name':'RandomForest'}\nclfs['tr'] = {'clf': tree.DecisionTreeClassifier(), 'name':'DecisionTree'}\n#clfs['knn'] = {'clf': neighbors.KNeighborsClassifier(n_neighbors=4), 'name':'kNearestNeighbors'}\n#clfs['svc'] = {'clf': svm.SVC(kernel='linear'), 'name': 'SupportVectorClassifier'}\nclfs['nusvc'] = {'clf': svm.NuSVC(), 'name': 'NuSVC'}\nclfs['linearsvc'] = {'clf': svm.LinearSVC(), 'name': 'LinearSVC'}\nclfs['SGD'] = {'clf': linear_model.SGDClassifier(), 'name': 'SGDClassifier'}\nclfs['GPC'] = {'clf': gaussian_process.GaussianProcessClassifier(), 'name': 'GaussianProcess'}\nclfs['nb'] = {'clf': naive_bayes.GaussianNB(), 'name':'GaussianNaiveBayes'}\nclfs['bag'] = {'clf': ensemble.BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5, max_features=0.5), 'name': \"BaggingClassifier\"}\nclfs['gbc'] = {'clf': ensemble.GradientBoostingClassifier(), 'name': 'GradientBoostingClassifier'}\n#clfs['mlp'] = {'clf': neural_network.MLPClassifier(hidden_layer_sizes=(100,100,100), alpha=1e-5, solver='lbfgs', max_iter=500), 'name': 'MultilayerPerceptron'}"},{"cell_type":"markdown","metadata":{"_cell_guid":"c4ec06cd-fd4e-cc27-43f1-bf3772fd27d2"},"source":"### Find the best parameters by usig GridSearch\nUsing GridSearch you can find the best parameters for a classifier. You just have to give an array for each parameter and GridSearch will try out every combination. That takes a lot longer to compute of course."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37dcdb0b-48e0-39e8-0dbd-4791a4885b3c"},"outputs":[],"source":"parameters = {'solver': ['lbfgs'], 'max_iter': [1500], 'alpha': 10.0 ** -np.arange(1, 7), 'hidden_layer_sizes':np.arange(5, 12)}\nclfs['mlpgrid'] = {'clf': GridSearchCV(neural_network.MLPClassifier(), parameters), 'name': 'MLP with GridSearch'}\n\nparameters = {'kernel':['linear', 'sigmoid', 'poly', 'rbf'], 'gamma':np.linspace(0.0,2.0,num=21),'C': np.linspace(0.5,1.5,num=11)}\nclfs['svcgrid'] = {'clf': GridSearchCV(svm.SVC(), parameters), 'name': 'SVC with GridSearch'}\n\nparameters = {'n_estimators':np.arange(64, 1024, step=64)}\nclfs['rfgrid'] = {'clf': GridSearchCV(ensemble.RandomForestClassifier(), parameters), 'name': 'Random Forest with GridSearch'}\n\nparameters = {'n_neighbors':np.arange(3, 12)}\nclfs['knngrid'] = {'clf': GridSearchCV(neighbors.KNeighborsClassifier(), parameters), 'name': 'KNN with GridSearch'}\n\nparameters = {'n_estimators':np.arange(3, 12)}\nclfs['adagrid'] = {'clf': GridSearchCV(ensemble.AdaBoostClassifier(), parameters), 'name': 'AdaBoost with GridSearch'}\n\nparameters = {'C':[1],'tol':[0.0001],'solver': ['newton-cg'], 'multi_class': ['multinomial']}\nclfs['lrgrid'] = {'clf': GridSearchCV(linear_model.LogisticRegression(), parameters), 'name': 'LogisticRegression with GridSearch'}"},{"cell_type":"markdown","metadata":{"_cell_guid":"c53e539f-3273-1d7a-0624-a7450b21c7a1"},"source":"### Scoring classifiers with cross validation\nI tried using artificial features here, but in most cases that did not lead to an improvement of the score. To save some computing time I commented the lines out."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fda02d4-79f2-c9d5-c073-5404073b0bee"},"outputs":[],"source":"for clf in clfs:\n    clfs[clf]['score'] = cross_val_score(clfs[clf]['clf'], x_original, y.values.ravel(), cv=5)\n    print(clfs[clf]['name'] + \": %0.4f (+/- %0.4f)\" % (clfs[clf]['score'].mean(), clfs[clf]['score'].std()*2))\n    #clfs[clf]['score'] = cross_val_score(clfs[clf]['clf'], x, y.values.ravel(), cv=5)\n    #print(clfs[clf]['name'] + \" (with all artificial features): %0.4f (+/- %0.4f)\" % (clfs[clf]['score'].mean(), clfs[clf]['score'].std()*2))\n    clfs[clf]['score'] = cross_val_score(clfs[clf]['clf'], x_hair_soul, y.values.ravel(), cv=5)\n    print(clfs[clf]['name'] + \" (with hair_soul feature): %0.4f (+/- %0.4f)\" % (clfs[clf]['score'].mean(), clfs[clf]['score'].std()*2))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7fb9cf52-9127-5d5d-142f-82fa0c2c430d"},"outputs":[],"source":"for clf in clfs:\n    clfs[clf]['score'] = cross_val_score(clfs[clf]['clf'], x, y.values.ravel(), cv=5)\n    print(clfs[clf]['name'] + \": %0.4f (+/- %0.4f)\" % (clfs[clf]['score'].mean(), clfs[clf]['score'].std()*2))   "},{"cell_type":"markdown","metadata":{"_cell_guid":"a2ebd07a-c9e1-d3cf-17e2-3db83b56b168"},"source":"### Create voting classifier with the best 3 models"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53c3e98b-1617-0e85-a662-1a3b0fd2972b"},"outputs":[],"source":"# classifiers using the hair_soul feature\nclfs['vote_hair_soul'] = {'clf': ensemble.VotingClassifier(estimators=[\n            ('svcgrid', clfs['svcgrid']['clf']),\n            ('lrgrid', clfs['lrgrid']['clf']),\n            ('gbc', clfs['gbc']['clf'])\n        ], voting='hard'), 'name': 'VotingClassifierHairSoul'}\n\n# classifiers using the original features\nclfs['vote'] = {'clf': ensemble.VotingClassifier(estimators=[\n            ('svcgrid', clfs['svcgrid']['clf']),\n            ('lrgrid', clfs['lrgrid']['clf']),\n            ('nb', clfs['gbc']['clf'])\n        ], voting='hard'), 'name': 'VotingClassifier'}"},{"cell_type":"markdown","metadata":{"_cell_guid":"f682af2b-3b66-49e1-3d07-96b0af3bd9b4"},"source":"### Fitting classifiers using the whole training set\nFitting the voting classifier. I commented out the old code that was used to fit all classifiers to the complete trainingset. I am using the hair_soul artificial feature here."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c52a4362-b704-ff72-3a9d-300cebb54574"},"outputs":[],"source":"#for clf in clfs:\n#    clfs[clf]['clf'].fit(x, y.values.ravel())\n    \nclfs['vote_hair_soul']['clf'] = clfs['vote_hair_soul']['clf'].fit(x_hair_soul, y.values.ravel())\nclfs['vote']['clf'] = clfs['vote']['clf'].fit(x_original, y.values.ravel())"},{"cell_type":"markdown","metadata":{"_cell_guid":"3a0bd574-2d0b-3c7a-b4a0-1c73a4b5e825"},"source":"### Create predictions"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c82ee3a-6a4b-209d-be2e-691d2874fba5"},"outputs":[],"source":"#for clf in clfs:\n#    clfs[clf]['predictions'] = clfs[clf]['clf'].predict(x_test)\n    \nclfs['vote_hair_soul']['predictions'] = clfs['vote_hair_soul']['clf'].predict(x_test_hair_soul)\nclfs['vote']['predictions'] = clfs['vote']['clf'].predict(x_test_original)"},{"cell_type":"markdown","metadata":{"_cell_guid":"17899d03-066b-a940-98f4-622d8597fa93"},"source":"### Create submission file"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d4086de-0aba-400d-7b38-899dfcbd5464"},"outputs":[],"source":"#for clf in clfs:\n#    sub = pd.DataFrame(clfs[clf]['predictions'])\n#    pd.concat([testset[\"id\"],sub], axis=1).rename(columns = {0: 'type'}).to_csv(\"submission_\" + clfs[clf]['name'] + \".csv\", index=False)\n\nsub = pd.DataFrame(clfs['vote_hair_soul']['predictions'])\npd.concat([testset[\"id\"],sub], axis=1).rename(columns = {0: 'type'}).to_csv(\"submission_\" + clfs['vote_hair_soul']['name'] + \".csv\", index=False)\n\nsub = pd.DataFrame(clfs['vote']['predictions'])\npd.concat([testset[\"id\"],sub], axis=1).rename(columns = {0: 'type'}).to_csv(\"submission_\" + clfs['vote']['name'] + \".csv\", index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}