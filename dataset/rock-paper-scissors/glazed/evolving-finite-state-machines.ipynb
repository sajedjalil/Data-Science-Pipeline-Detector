{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is a follow up to a post I made on the forums. It's intended to be a minimalist example of how to evolve a finite state machine (FSM) to play Roshambo. I would have wrapped it up much sooner, but I got distracted playing with it.\n\n# The Forum Post\nI was describing the contest to someone recently and I brought up the \"Iocaine\" agent with references to the poison wine scene in \"The Princess Bride.\" It's a useful metaphor to help answer: \"why is this even interesting?\"\n\nThe first part of my agent is much like what has been described many times. It has a big bank of prediction filters and a voting scheme to boil it all down. Based on the history of the match so far, it's calculating which action would do best on the next round. It's optimized just for that next round - pure offense. But, as in the wine scene, that's \"just getting started.\" The other guy has the same historical information, and has presumably just made an equivalent calculation.\n\nSo, that predicted best action goes to the second part of my agent which treats it as merely a suggestion. (I'm calling the following the \"survivor bias algorithm, (SBA)\") The SBA has four tactics to choose from: take the predicted best action, the action that would beat it, the action that would lose to it, or disregard it entirely and pick a random action. The tactic is chosen by a finite state machine (FSM). Each state in the FSM has one tactic (one of the four), and three possible conditions: the previous round was a win, loss, or tie. So each state can be represented by four values: the tactic to use and the three new states to transition to based on the previous round's outcome. The FSM, an Nx4 array, is generated by a genetic algorithm, scored against a benchmark of agents I've written, pilfered, or evolved.\n\nThe SBA has some nice properties. In local testing, it wins more matches than just using the predicted best action would. Also, it's modular. I can evolve a FSM using a fast version of the filter bank, but swap in another version later. Or I can swap in a too-slow-to evolve-with published agent, eg. Iocaine. (The result with Iocaine is around the same strength as with my own filter - better against some opponents, not as good against others. It does comparably well on the leaderboard. Not too surprisingly, SBA plus Iocaine wins 100 percent of its matches against Iocaine alone - the \"evil twin effect.\")\n\nThere're a lot of things the SBA is not doing. It's not just taking the predicted actions and throwing in random moves. As is the norm with evolved solutions, I can trace the logic behind decisions the SBA makes, but see no plan or pattern behind them. Presumably, that's the point.\n\n# A quick note about Numba.\nThis notebook makes extensive use of Numba, a just-in-time (JIT) compiler. I've found Numba to be both a blessing and a curse. My code runs two orders of magnitude faster, but plenty of perfectly good Python code doesn't play well with Numba. C-like structure seems to work well for me. YMMV.\n\n\n# And on to the example"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport time\nfrom datetime import timedelta\nfrom numba import njit # A just-in-time (JIT) compiler\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"First, we'll need a simple stand-in for the prediction filter. Always predicting that rock would be the best choice isn't the greatest prediction, but we'll see what the GA can make of it."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n@njit()\ndef box_of_rocks_predictor(step, my_last_action, lastOpponentAction):\n    \"\"\" \n    My prediction filter always predicts that playing rock will surely win this time.\n    It is often in error, never in doubt.\n    \"\"\"\n    return 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, some fast opponents, slightly modified from the versions here: https://www.kaggle.com/ihelon/rock-paper-scissors-agents-comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"@njit()\ndef get_score(friend_move, foe_move):\n    \"\"\" utility function for reactionary and counter_reactionary \"\"\"\n    if (friend_move == foe_move):\n        return(1) #ties+= 1\n    else:\n        wining_move = (foe_move + 1) % 3\n        if (friend_move == wining_move):\n            return(2) #wins += 1\n        else:\n            return(0) #losses += 1\n    print('BADNESS in get_score', friend_move, foe_move)\n    return(-1) #los\n\n@njit()\ndef mirror_agent(step, my_last_action, lastOpponentAction):\n    if step == 0:\n        action = int(np.random.randint(3))\n    else:\n        action = lastOpponentAction\n    return (int(action))\n    \n@njit()\ndef hit_the_last_own_action(step, my_last_action, lastOpponentAction):\n    if (step == 0):\n        return(int(np.random.randint(3)))\n    action = (my_last_action + 1) % 3\n    return action\n    \n@njit()\ndef rock(step, my_last_action, lastOpponentAction):\n    return 0\n   \n@njit()\ndef paper(step, my_last_action, lastOpponentAction):\n    return 1 \n  \n@njit()\ndef scissors(step, my_last_action, lastOpponentAction):\n    return 2\n    \n@njit()\ndef reactionary(step, my_last_action, lastOpponentAction):\n    action = my_last_action\n    if (step == 0):\n        return(int(np.random.randint(3)))\n    elif get_score(my_last_action, lastOpponentAction) <= 1:\n        action = (lastOpponentAction + 1) % 3\n    return action\n    \n@njit()\ndef counter_reactionary(step, my_last_action, lastOpponentAction):\n    action = my_last_action\n    if (step == 0):\n        return(int(np.random.randint(3)))\n    elif get_score(my_last_action, lastOpponentAction) == 1:\n        action = (lastOpponentAction + 2) % 3\n    else: action = (lastOpponentAction + 1) % 3\n    return action\n\n@njit()\ndef switching0(step, my_last_action, lastOpponentAction):\n    q = step // 200\n    if (q == 0):    return (np.random.randint(3) )\n    elif (q == 1):  return( reactionary(step, my_last_action, lastOpponentAction) )\n    elif (q == 2):  return( counter_reactionary(step, my_last_action, lastOpponentAction) )\n    elif (q == 3):  return( counter_reactionary(step, my_last_action, lastOpponentAction) )\n    elif (q == 4):  return( counter_reactionary(step, my_last_action, lastOpponentAction) )   \n    return (np.random.randint(3))\n\n@njit()\ndef switching1(step, my_last_action, lastOpponentAction):\n    q = step // 200\n    if (q == 0):    return (np.random.randint(3) )\n    elif (q == 1):  return(np.random.randint(3))\n    elif (q == 2):  return(np.random.randint(3))\n    elif (q == 3):  return( 1 )\n    elif (q == 4):  return( 0 )   \n    return (np.random.randint(3))\n\n@njit()\ndef switching2(step, my_last_action, lastOpponentAction):\n    q = step // 200\n    if (q == 0):    return (np.random.randint(3) )\n    elif (q == 1):  return( mirror_agent(step, my_last_action, lastOpponentAction) )\n    elif (q == 2):  return( mirror_agent(step, my_last_action, lastOpponentAction) )\n    elif (q == 3):  return( hit_the_last_own_action(step, my_last_action, lastOpponentAction) )\n    elif (q == 4):  return( hit_the_last_own_action(step, my_last_action, lastOpponentAction) )  \n    return (np.random.randint(3))\n\n@njit()\ndef switching3(step, my_last_action, lastOpponentAction):\n    q = step // 200\n    if (q == 0):    return (np.random.randint(3) )\n    elif (q == 1):  return( q )\n    elif (q == 2):  return( q )\n    elif (q == 3):  return( hit_the_last_own_action(step, my_last_action, lastOpponentAction) )\n    elif (q == 4):  return( hit_the_last_own_action(step, my_last_action, lastOpponentAction) )  \n    return (np.random.randint(3))\n\n@njit()\ndef switching4(step, my_last_action, lastOpponentAction):\n    if (step < 800):    return (np.random.randint(3) )\n    return (step % 3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finite state machine (FSM) code"},{"metadata":{"trusted":true},"cell_type":"code","source":"@njit()\ndef FSM_agentX(step, prev_friend_act, prev_foe_act, state, filter_move, state_choices, action_choices):\n    \"\"\" \n    Choose 1 move using finite state machine (FSM) \n    - Test the condition (win, lose, tie)\n    - Move to the new state\n    - Take the strategy (a) from that state\n    - Translate the strategy to an action\n    - Return the new state and the action\n    \"\"\"\n    # num_actions == 3\n    holdoff = 0 # spin at state zero until past this step\n# =============================================================================\n#     4 possible actions:\n#       filter_move\n#       counter to filter_move\n#       counter-counter to filter_move\n#       random\n#     3 possible conditions: win, lose, tie\n# =============================================================================\n    if step == 0:\n        condition = 2 # tie\n        if (state != 0):\n            print(\"FSM_agentX, starting state =\", state)\n    if step <= holdoff:\n        condition = 2 # tie\n        #    action = np.int32(np.random.randint(3))\n        state = state_choices[state, condition] # get next state\n        #a = np.int32(action_choices[state]) # get action to play\n        action = np.int32(np.random.randint(3))\n        state = 0 # remain at state 0\n        #if (showit): print('FSM_agentX() step 0. action', action, 'state', state)\n        return (state, action)\n    \n    # find new state based on condion (win, lose, tie)\n    if (prev_friend_act == prev_foe_act): condition = 2 # tie\n    elif (prev_friend_act == (prev_foe_act +1) % 3): condition = 0 # win\n    else: condition = 1 # lose\n    \n    #if (condition != 0): #only change state on a loss or tie\n    state = state_choices[state, condition] # get next state\n    a = np.int32(action_choices[state]) # get strategy to play\n        \n    if (a < 3): # pick action relative to filter_move\n        action = (filter_move + a) % 3\n    else: action = int(np.random.randint(3))\n    return (state, action)       \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Utilities to play one match against a designated opponent. This is where we set which predictor we'll be using to evolve with."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n@njit()\ndef FSM_move(s, prev_friend_move, prev_foe_move, Astate, states_A, actions_A):\n    \"\"\" \n    Choose the next move, using the prediction filter and the FSM\n    s         -> step\n    Astate    -> current state in the FSM\n    states_A  -> part of FSM\n    actions_A -> the other part of the FSM\n    \"\"\"\n    # THIS IS WHERE THE PREDICTOR GOES. YOUR MESSAGE COULD BE HERE.\n    filter_prediction = box_of_rocks_predictor(s, prev_friend_move, prev_foe_move)\n    # filter_prediction is passed to the FSM which treats it as merely a suggestion. The predictor needs to be able to\n    # make predictions whether its suggested actions are used or not.\n    \n    Astate, friend_move = FSM_agentX(s, prev_friend_move, prev_foe_move, Astate, filter_prediction, states_A, actions_A)\n    # friend_move is the action actually played.\n    return(Astate, friend_move)\n         \n         \n@njit()\ndef run_FSM_bench(states_A, actions_A, opponent):\n    \"\"\" \n    Play one match (1000 rounds) against this opponent, and return the outcome.\n    \n    If you want to add or change the opponents to evolve against, adjust that here.\n    Also update full_benchmarking() if the number of opponents changes.\n    Opponents need to be compatible with Numba and fairly fast.\n    \"\"\"\n    trials = 1000\n    freezing = np.array([34, 40, 44, 48, 51, 54, 57, 59, 61]) # 95% safety if switching to random moves\n    use_mercy_rule = False\n    prev_foe_move = -1\n    prev_friend_move = -1\n    wins = 0\n    losses = 0\n    ties = 0\n    Astate = 0 # We start a match at state zero, by convention.   \n    for s in range(trials):\n        # friend move \n        Astate, friend_move = FSM_move(s, prev_friend_move, prev_foe_move, Astate, states_A, actions_A)\n         \n        # opponent (foe) move\n        if   (opponent == 0):  foe_move = rock                   (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 1):  foe_move = paper                  (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 2):  foe_move = scissors               (s, prev_foe_move, prev_friend_move)           \n        elif (opponent == 3):  foe_move = hit_the_last_own_action(s, prev_foe_move, prev_friend_move)\n        elif (opponent == 4):  foe_move = mirror_agent           (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 5):  foe_move = reactionary            (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 6):  foe_move = counter_reactionary    (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 7):  foe_move = switching0             (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 8):  foe_move = switching1             (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 9):  foe_move = switching2             (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 10): foe_move = switching3             (s, prev_foe_move, prev_friend_move)\n        elif (opponent == 11): foe_move = switching4             (s, prev_foe_move, prev_friend_move)\n        else: print('bad foe in fullbench')\n        \n        # score this round\n        if (friend_move == foe_move):\n            ties+= 1\n        else:\n            wining_move = (foe_move + 1) % 3\n            if (friend_move == wining_move):\n                wins += 1\n            else:\n                losses += 1\n        prev_foe_move = foe_move\n        prev_friend_move = friend_move\n        if (use_mercy_rule and (s > 100)): # early stopping of the match when it's a blowout\n                temp = (1000 - s) // 100\n                freezingPoint = freezing[temp]\n                if ((wins - losses > freezingPoint) or (losses - wins > freezingPoint)): return([wins, losses, ties])\n    #print('opponent', opponent, \"wins. losses\", wins, losses, \"delta\", (wins - losses))\n    return([wins, losses, ties])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Utilities to run multiple matches against the fast opponents"},{"metadata":{"trusted":true},"cell_type":"code","source":"@njit()\ndef run_many_benches(state_choices, action_choices, matches, opponent):\n    \"\"\" Run several matches against this opponent \"\"\"\n    W = np.int32(0)\n    L = np.int32(0)\n    results =  np.zeros(matches, np.int32) \n    for m in range(matches):\n        wins, losses, ties = run_FSM_bench(state_choices, action_choices, opponent)\n        results[m] = wins - losses\n        W += wins\n        L += losses\n    W = W // matches\n    L = L // matches\n    #print(\"run_many_benches W,L\", W, L)\n    return(results)\n\n@njit()\ndef score_matches_thresh(results):\n    \"\"\" \n    Return the score across the results of multiple matches.\n    Assign a match a win if the margin of victory >= 20, etc. \n    \"\"\"\n    wins = np.sum(results >= 20)\n    losses = np.sum(results <= -20)\n    #ties = np.sum(matches == 0)\n    score = np.int32((100 * (wins - losses)) // len(results))\n    return(score)\n\n@njit()\ndef full_benchmarking(state_choices, action_choices, matches, showit = False):\n    \"\"\" \n    Run many matches against all 12 opponents and return a score for the evolver.\n    \"\"\"\n    b = 12 # There are 12 opponents to test against. (Keep compatible with run_FSM_bench())\n    scores = np.zeros(b, np.int32) \n    beauty = np.zeros(b, np.int32) \n    for i in range(b):\n        if (i < 3): reps = matches // 4\n        else: reps = matches\n        results = run_many_benches(state_choices, action_choices, reps, i)\n        scores[i] = score_matches_thresh(results)\n        beauty[i] = np.mean(results)\n    if (showit): \n        print(\"avg. winning percentage\", scores)\n        print(\"avg. margin of victory \", beauty)\n    return(np.mean(scores), np.min(beauty))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The GA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# =============================================================================\n#        INDIVIDUAL\n#        INDIVIDUAL\n#        INDIVIDUAL\n# =============================================================================\n\nclass INDIVIDUAL():\n    \n    \"\"\"\n    This class holds an individual for a GA.\n    It represents a finite state machine to play Roshambo.\n    \"\"\"\n    def __init__(self):\n        self.N = 200 # number of states\n        self.action_choices = np.zeros((self.N), np.int32)   # coded state table (0-4)\n        self.state_choices = np.zeros((self.N, 3), np.int32) # coded state table (0-N)\n        \n \n@njit() \ndef init_individual(N):\n    \"\"\"\n    Create new state_choices[] and action_choices[]\n    action_choices[] 0 <= a < 6\n    state_choices[] 0 <= s <= N\n    \"\"\"\n    num_actions = 4\n    state_choices = np.zeros((N, 3), np.int32) \n    action_choices = np.zeros(N, np.int32) # coded state table (0-4)\n    for k in range(N):\n        action_choices[k] = int(np.random.randint(num_actions)) \n        for i in range(3):\n            state_choices[k, i] = int(np.random.randint(N))\n\n    return(state_choices, action_choices)  \n\n@njit()  \ndef procreate_individual(N, par1_states, par1_actions, par2_states, par2_actions):\n    \"\"\"\n    Crosover and mutation\n    action_choices[] 0 <= a < num_actions\n    state_choices [] 0 <= s < N\n    \"\"\"\n    #print(\"procreate_individual start\")\n    num_actions = 4\n    P_mutate = 3\n    child_states = np.zeros((N, 3), np.int32) \n    child_actions = np.zeros(N, np.int32) # coded state table (0-4)\n    # perform two-point crossover, combined with mutation\n    c1 = np.random.randint(N)\n    c2 = np.random.randint(N)\n    if (c1 > c2):\n       c1, c2 = c2, c1\n    for k in range(N):\n        if ((k <= c1) or (k > c2)):\n            child_actions[k] = par1_actions[k]\n            if (np.random.randint(100) < P_mutate): \n                child_actions[k] = np.random.randint(num_actions)\n            for i in range(3):\n                child_states[k, i] = par1_states[k, i]\n                if (np.random.randint(100) < P_mutate):\n                     child_states[k, i] = np.random.randint(N)\n        else:\n            child_actions[k] = par2_actions[k]\n            if (np.random.randint(100) < P_mutate): \n                child_actions[k] = np.random.randint(num_actions) \n            for i in range(3):\n                child_states[k, i] = par2_states[k, i]\n                if (np.random.randint(100) < P_mutate):\n                    child_states[k, i] = np.random.randint(N)\n    #print(\"procreate_individual finished\")\n    return(child_states, child_actions)   \n\n    \n    \ndef init_ga(popsize):\n    \"\"\" create a new population  \"\"\"\n    pop = []\n    for p in range(popsize):\n        F = INDIVIDUAL()\n        F.state_choices, F.action_choices = init_individual(F.N)\n        pop.append(F)\n    print('new population formed')\n    return(pop)\n\n@njit()\ndef tourn(scores, chances):\n    \"\"\" Select one parent using tournament selection \"\"\"\n    popsize = len(scores)\n    best = np.random.randint(popsize)\n    for p in range(chances):\n        x = np.random.randint(popsize)\n        if (scores[best] < scores[x]): best = x\n    return(best)\n\ndef run_ga(pop, generations):\n    matches = 200 # Number of matches between pairs of agents. (Set lower for faster/noisier evolving.)\n    popsize = len(pop)\n    scores = np.zeros(popsize, np.float32)\n    age = np.zeros(popsize, np.int32)\n    beauty_spot_scores = np.zeros(popsize, np.int32)\n    print(\"starting GA\")\n    start_time = time.time()\n    for g in range(generations): # for every generation\n        ts = time.time()\n        for p in range(popsize): # score every individual\n            scores[p], beauty_spot_scores[p]  = full_benchmarking( pop[p].state_choices, pop[p].action_choices, matches)\n            \n        print('gen', g, \"STATS (min, mean, max)\", np.min(scores), np.mean(scores), np.max(scores), end = ' ')\n        tsA = time.time()\n        print('time for testing pop', timedelta(seconds = (time.time() - ts))) \n        best = np.argmax(scores)\n        print('Performance of best individual')\n        full_benchmarking( pop[best].state_choices, pop[best].action_choices, matches, True)\n        # save the best solution found so far in two files\n        np.save('state_choice', pop[best].state_choices)   \n        np.save('action_choices', pop[best].action_choices) \n        for new_child in range(popsize):\n            p = np.argmin(scores)   # kill off the weakest individual\n            par1 = tourn(scores, 2)\n            par2 = tourn(scores, 2)\n            #par2 = tourn(beauty_spot_scores, 2) # alternative choice for second parent\n            if (np.random.randint(100) < 50): # randomly swap parents\n                par1, par2 = par2, par1\n            # replace the weakest individual with the offspring of the two parents\n            pop[p].state_choices, pop[p].action_choices =  procreate_individual(pop[par1].N, \n                                    pop[par1].state_choices, pop[par1].action_choices, \n                                    pop[par2].state_choices, pop[par2].action_choices)\n            # score the new individual\n            scores[p], beauty_spot_scores[p]  = full_benchmarking( pop[p].state_choices, pop[p].action_choices, matches)\n            \n            age[p] = g\n        #print('gen', g, \"STATS \", np.min(scores), np.mean(scores), np.max(scores), end = ' ')\n        #print('gen', g, \"BEAUTY\", np.min(beauty_spot_scores), \n        #      np.mean(beauty_spot_scores), np.max(beauty_spot_scores))\n        print(\" (\", np.sum(age == g), 'new). Time for this generation',timedelta(seconds = (time.time() - ts))) \n    # swap best into slot zero\n    best = np.argmax(scores)\n    pop[0], pop[best] = pop[best], pop[0] \n    print('FINISHED. run time', timedelta(seconds = (time.time() - start_time)))\n    return(pop)\n\n#pop  = init_ga(200)  \n#pop = run_ga(pop, 20)    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a new population with 200 individuals"},{"metadata":{"trusted":true},"cell_type":"code","source":"pop  = init_ga(200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run the GA for 20 generations. It should take about 10 minutes. We may want to do this a couple times, to make sure the agent beats all the opponents 100 % of the time.\n\n(Each generation takes ~ 30 seconds under the default settings. The population size, number of matches between agents, and the number of opponents all impact how long this will take. A population of 200, playing 200 matches against 12 opponents twice, entails running nearly a million Roshambo matches each generation.)\n\n*OPPONENTS: rock, paper, scissors, hit_the_last_own_action, mirror_agent, reactionary, counter_reactionary, switching0-4*"},{"metadata":{"trusted":true},"cell_type":"code","source":"pop = run_ga(pop, 20)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, now we've established that we can evolve a FSM, with a stopped-clock prediction filter, capable of beating a particular set of not too savvy opponents. That certainly raises more questions than it answers. For now, I will answer just one of them: \"how can we make this agent portable in case we want ot test it somewhere else?\"\n\nFirst we'll set up a template with the required wrapper for this contest. Then we'll cut and paste our new evolved FSM into it.\nThe best individual found is stored in pop[0] (The best FSM found is also stored in two files '/kaggle/working/state_choice.npy' and '/kaggle/working/action_choices.npy', so we could load from files if we wanted)."},{"metadata":{},"cell_type":"markdown","source":"# The Template"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile your_agent.py\nimport numpy as np\nimport pickle\ndef box_of_rocks_predictor(step, my_last_action, lastOpponentAction):\n    \"\"\" \n    My prediction filter always predicts that playing rock will surely win this time.\n    It is often in error, never in doubt.\n    \"\"\"\n    return 0\n\ndef FSM_move_No_Numba(s, prev_friend_move, prev_foe_move, Astate, states_A, actions_A):\n    \"\"\" \n    Choose the next move, using the prediction filter and the FSM\n    s         -> step\n    Astate    -> current state in the FSM\n    states_A  -> part of FSM\n    actions_A -> the other part of the FSM\n    \"\"\"\n    \n    # THIS IS WHERE THE PREDICTOR GOES. YOUR MESSAGE COULD BE HERE.\n    filter_prediction = box_of_rocks_predictor(s, prev_friend_move, prev_foe_move)\n    # filter_prediction is passed to the FSM which treats it as merely a suggestion. The predictor needs to be able to\n    # make predictions whether its suggested actions are used or not.\n    \n    Astate, friend_move = FSM_agentX(s, prev_friend_move, prev_foe_move, Astate, filter_prediction, states_A, actions_A)\n    return(Astate, friend_move)\n\ndef FSM_agentX(step, prev_friend_act, prev_foe_act, state, filter_move, state_choices, action_choices):\n    \"\"\" \n    Choose 1 move using finite state machine (FSM) \n    - Test the condition (win, lose, tie)\n    - Move to the new state\n    - Take the strategy (a) from that state\n    - Translate the strategy to an action\n    - Return the new state and the action\n    \"\"\"\n    # num_actions == 3\n    holdoff = 0 # spin at state zero until past this step\n# =============================================================================\n#     4 possible actions:\n#       filter_move\n#       counter to filter_move\n#       counter-counter to filter_move\n#       random\n#     3 possible conditions: win, lose, tie\n# =============================================================================\n    if step == 0:\n        condition = 2 # tie\n        if (state != 0):\n            print(\"FSM_agentX, starting state =\", state)\n    if step <= holdoff:\n        condition = 2 # tie\n        #    action = np.int32(np.random.randint(3))\n        state = state_choices[state, condition] # get next state\n        #a = np.int32(action_choices[state]) # get action to play\n        action = np.int32(np.random.randint(3))\n        state = 0 # remain at state 0\n        #if (showit): print('FSM_agentX() step 0. action', action, 'state', state)\n        return (state, action)\n    \n    # find new state based on condion (win, lose, tie)\n    if (prev_friend_act == prev_foe_act): condition = 2 # tie\n    elif (prev_friend_act == (prev_foe_act +1) % 3): condition = 0 # win\n    else: condition = 1 # lose\n    \n    #if (condition != 0): #only change state on a loss or tie\n    state = state_choices[state, condition] # get next state\n    a = np.int32(action_choices[state]) # get strategy to play\n        \n    if (a < 3): # pick action relative to filter_move\n        action = (filter_move + a) % 3\n    else: action = int(np.random.randint(3))\n    return (state, action)       \n\nclass INDIVIDUAL():\n    \n    \"\"\"\n    This class holds an individual for a GA.\n    It represents a finite state machine to play Roshambo.\n    \"\"\"\n    def __init__(self):\n        self.N = 200 # number of states\n        self.action_choices = np.zeros((self.N), np.int32)    # coded state table (0-4)\n        self.state_choices  = np.zeros((self.N, 3), np.int32) # coded state table (0-N)\n\nF =  INDIVIDUAL() \n\n#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ CUT HERE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n# THE FOLOWING 2 LINES HOLD AN OLD EVOLVED FSM. REPLACE THEM WITH THE NEW ONES.\nF.action_choices = pickle.loads(b'\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\xc8\\x85q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00i4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89B \\x03\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00\\x00\\x00q\\rtq\\x0eb.')\nF.state_choices  = pickle.loads(b'\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01K\\xc8K\\x03\\x86q\\x06cnumpy\\ndtype\\nq\\x07X\\x02\\x00\\x00\\x00i4q\\x08K\\x00K\\x01\\x87q\\tRq\\n(K\\x03X\\x01\\x00\\x00\\x00<q\\x0bNNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x0cb\\x89B`\\t\\x00\\x00\\x0e\\x00\\x00\\x00\\xb8\\x00\\x00\\x00K\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\"\\x00\\x00\\x00\\x89\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\x93\\x00\\x00\\x00\\x85\\x00\\x00\\x00n\\x00\\x00\\x00L\\x00\\x00\\x00g\\x00\\x00\\x00\\x19\\x00\\x00\\x00\\t\\x00\\x00\\x00\\xa4\\x00\\x00\\x00u\\x00\\x00\\x00w\\x00\\x00\\x00\\x1a\\x00\\x00\\x00~\\x00\\x00\\x00\\xbf\\x00\\x00\\x00\\xb4\\x00\\x00\\x00\\x17\\x00\\x00\\x00G\\x00\\x00\\x00s\\x00\\x00\\x00f\\x00\\x00\\x00[\\x00\\x00\\x00g\\x00\\x00\\x00K\\x00\\x00\\x00\\x96\\x00\\x00\\x00B\\x00\\x00\\x00w\\x00\\x00\\x00|\\x00\\x00\\x00>\\x00\\x00\\x00n\\x00\\x00\\x00T\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\xb9\\x00\\x00\\x00}\\x00\\x00\\x00\\xbe\\x00\\x00\\x00k\\x00\\x00\\x00l\\x00\\x00\\x00\\xa3\\x00\\x00\\x00\\xb1\\x00\\x00\\x00h\\x00\\x00\\x00\\xb8\\x00\\x00\\x00E\\x00\\x00\\x00a\\x00\\x00\\x00<\\x00\\x00\\x00r\\x00\\x00\\x00\\x81\\x00\\x00\\x00\\x8a\\x00\\x00\\x00T\\x00\\x00\\x00\\xbb\\x00\\x00\\x00H\\x00\\x00\\x00\\x91\\x00\\x00\\x00?\\x00\\x00\\x00\\xa1\\x00\\x00\\x00\\x87\\x00\\x00\\x00k\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\xa8\\x00\\x00\\x00}\\x00\\x00\\x00\\x01\\x00\\x00\\x00i\\x00\\x00\\x00\\xa0\\x00\\x00\\x00;\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\xc0\\x00\\x00\\x00\\xac\\x00\\x00\\x00c\\x00\\x00\\x00)\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x83\\x00\\x00\\x00z\\x00\\x00\\x00L\\x00\\x00\\x00_\\x00\\x00\\x00?\\x00\\x00\\x00&\\x00\\x00\\x00\\x80\\x00\\x00\\x00 \\x00\\x00\\x00\\x83\\x00\\x00\\x00<\\x00\\x00\\x00p\\x00\\x00\\x003\\x00\\x00\\x00+\\x00\\x00\\x00\\x89\\x00\\x00\\x00%\\x00\\x00\\x00&\\x00\\x00\\x00D\\x00\\x00\\x00\\xbc\\x00\\x00\\x00g\\x00\\x00\\x00g\\x00\\x00\\x00\\xad\\x00\\x00\\x00\\x82\\x00\\x00\\x00\\x01\\x00\\x00\\x00M\\x00\\x00\\x00>\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x97\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00R\\x00\\x00\\x00\\xaf\\x00\\x00\\x00\\x98\\x00\\x00\\x00\\x91\\x00\\x00\\x00\\'\\x00\\x00\\x00\\xa4\\x00\\x00\\x00\\x9a\\x00\\x00\\x00\\x98\\x00\\x00\\x00H\\x00\\x00\\x00*\\x00\\x00\\x00x\\x00\\x00\\x00\\x0c\\x00\\x00\\x00w\\x00\\x00\\x00 \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x97\\x00\\x00\\x00a\\x00\\x00\\x00^\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x16\\x00\\x00\\x00R\\x00\\x00\\x00\\x18\\x00\\x00\\x00,\\x00\\x00\\x00\\x93\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x85\\x00\\x00\\x00\\x95\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x82\\x00\\x00\\x00\\xa0\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\xb8\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x94\\x00\\x00\\x00\\x0e\\x00\\x00\\x00\\x8b\\x00\\x00\\x00\\xa4\\x00\\x00\\x00R\\x00\\x00\\x001\\x00\\x00\\x003\\x00\\x00\\x00\\x93\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\'\\x00\\x00\\x00N\\x00\\x00\\x00\\x1a\\x00\\x00\\x00v\\x00\\x00\\x00\\x93\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\"\\x00\\x00\\x00R\\x00\\x00\\x00Q\\x00\\x00\\x00B\\x00\\x00\\x00i\\x00\\x00\\x00a\\x00\\x00\\x00\\x85\\x00\\x00\\x00,\\x00\\x00\\x008\\x00\\x00\\x00!\\x00\\x00\\x00{\\x00\\x00\\x00t\\x00\\x00\\x00\\xb0\\x00\\x00\\x00S\\x00\\x00\\x00\\x0c\\x00\\x00\\x00f\\x00\\x00\\x00/\\x00\\x00\\x00\\xa1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\xa5\\x00\\x00\\x00\\xb0\\x00\\x00\\x00\\x98\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x95\\x00\\x00\\x00\\x9a\\x00\\x00\\x00\\x1d\\x00\\x00\\x001\\x00\\x00\\x00\\xaf\\x00\\x00\\x00~\\x00\\x00\\x00Y\\x00\\x00\\x00\\xa0\\x00\\x00\\x00v\\x00\\x00\\x00\\xc3\\x00\\x00\\x00U\\x00\\x00\\x00\\x82\\x00\\x00\\x00\\x7f\\x00\\x00\\x00\\xa0\\x00\\x00\\x00(\\x00\\x00\\x00\\x0b\\x00\\x00\\x00.\\x00\\x00\\x00\\x97\\x00\\x00\\x00^\\x00\\x00\\x00\\x15\\x00\\x00\\x00P\\x00\\x00\\x00c\\x00\\x00\\x00\\xbf\\x00\\x00\\x00t\\x00\\x00\\x00$\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\r\\x00\\x00\\x00\\xa4\\x00\\x00\\x00\\x8c\\x00\\x00\\x00b\\x00\\x00\\x00\\xa5\\x00\\x00\\x00\\xac\\x00\\x00\\x00\\x85\\x00\\x00\\x00\\xc1\\x00\\x00\\x00\\xb1\\x00\\x00\\x00:\\x00\\x00\\x00D\\x00\\x00\\x00d\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\xb9\\x00\\x00\\x00\\x07\\x00\\x00\\x00\"\\x00\\x00\\x00\\xbd\\x00\\x00\\x00\\xbb\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\xb5\\x00\\x00\\x008\\x00\\x00\\x00\\x8e\\x00\\x00\\x00\\xae\\x00\\x00\\x00l\\x00\\x00\\x00(\\x00\\x00\\x00\"\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x9e\\x00\\x00\\x00\\xa6\\x00\\x00\\x00\\xa5\\x00\\x00\\x00\\xaf\\x00\\x00\\x00\\x81\\x00\\x00\\x00_\\x00\\x00\\x00^\\x00\\x00\\x00X\\x00\\x00\\x00$\\x00\\x00\\x00\\x92\\x00\\x00\\x00\\xc6\\x00\\x00\\x00U\\x00\\x00\\x00\\x9d\\x00\\x00\\x00U\\x00\\x00\\x00\\x90\\x00\\x00\\x00\\xaf\\x00\\x00\\x00p\\x00\\x00\\x00k\\x00\\x00\\x00.\\x00\\x00\\x00W\\x00\\x00\\x00\\x81\\x00\\x00\\x00D\\x00\\x00\\x00\\x1f\\x00\\x00\\x00\\xab\\x00\\x00\\x00T\\x00\\x00\\x00\\xa3\\x00\\x00\\x00\\xaf\\x00\\x00\\x00\\xb2\\x00\\x00\\x00\\xb9\\x00\\x00\\x00\\x88\\x00\\x00\\x00\\xa5\\x00\\x00\\x00\\x86\\x00\\x00\\x00b\\x00\\x00\\x00\\xc7\\x00\\x00\\x00\\xac\\x00\\x00\\x00\\xb7\\x00\\x00\\x00X\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x11\\x00\\x00\\x00\\x94\\x00\\x00\\x00z\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\x8a\\x00\\x00\\x00e\\x00\\x00\\x00\\xbb\\x00\\x00\\x00\\x15\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x97\\x00\\x00\\x00\\x86\\x00\\x00\\x00\\x9a\\x00\\x00\\x00a\\x00\\x00\\x00c\\x00\\x00\\x00\\x90\\x00\\x00\\x00c\\x00\\x00\\x00!\\x00\\x00\\x005\\x00\\x00\\x00v\\x00\\x00\\x00\\x18\\x00\\x00\\x00\"\\x00\\x00\\x00P\\x00\\x00\\x006\\x00\\x00\\x00[\\x00\\x00\\x00P\\x00\\x00\\x00\\xc2\\x00\\x00\\x00\\xa5\\x00\\x00\\x00\\x1d\\x00\\x00\\x00_\\x00\\x00\\x00;\\x00\\x00\\x00\\xbe\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x98\\x00\\x00\\x00c\\x00\\x00\\x00\\xbc\\x00\\x00\\x00t\\x00\\x00\\x00i\\x00\\x00\\x00&\\x00\\x00\\x00\\x92\\x00\\x00\\x00 \\x00\\x00\\x00\\x92\\x00\\x00\\x00\\t\\x00\\x00\\x00[\\x00\\x00\\x00\\xb2\\x00\\x00\\x00!\\x00\\x00\\x00t\\x00\\x00\\x00R\\x00\\x00\\x00\\x97\\x00\\x00\\x00O\\x00\\x00\\x00\\x8b\\x00\\x00\\x00 \\x00\\x00\\x00Q\\x00\\x00\\x002\\x00\\x00\\x00=\\x00\\x00\\x00m\\x00\\x00\\x00\\xa8\\x00\\x00\\x00\\x9c\\x00\\x00\\x00h\\x00\\x00\\x006\\x00\\x00\\x00b\\x00\\x00\\x005\\x00\\x00\\x00\\xaf\\x00\\x00\\x00d\\x00\\x00\\x00v\\x00\\x00\\x00&\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\xa6\\x00\\x00\\x00\\xb2\\x00\\x00\\x00&\\x00\\x00\\x00K\\x00\\x00\\x00\\x89\\x00\\x00\\x00\\x99\\x00\\x00\\x00\\x8f\\x00\\x00\\x00#\\x00\\x00\\x00\\x87\\x00\\x00\\x00l\\x00\\x00\\x00B\\x00\\x00\\x00\\t\\x00\\x00\\x00+\\x00\\x00\\x00x\\x00\\x00\\x009\\x00\\x00\\x00h\\x00\\x00\\x00,\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\"\\x00\\x00\\x00}\\x00\\x00\\x00\\x1e\\x00\\x00\\x00\\x93\\x00\\x00\\x00\\x84\\x00\\x00\\x00*\\x00\\x00\\x00\\x89\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\xa0\\x00\\x00\\x00\\x1e\\x00\\x00\\x00\\xa5\\x00\\x00\\x00\\x86\\x00\\x00\\x00\\xac\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\xa4\\x00\\x00\\x00\\xbb\\x00\\x00\\x00\\x87\\x00\\x00\\x00!\\x00\\x00\\x00_\\x00\\x00\\x00\\x8a\\x00\\x00\\x00\\x05\\x00\\x00\\x00$\\x00\\x00\\x00/\\x00\\x00\\x00p\\x00\\x00\\x00f\\x00\\x00\\x00\\xb7\\x00\\x00\\x00P\\x00\\x00\\x00)\\x00\\x00\\x00[\\x00\\x00\\x00\\x02\\x00\\x00\\x00c\\x00\\x00\\x00=\\x00\\x00\\x00G\\x00\\x00\\x00>\\x00\\x00\\x00X\\x00\\x00\\x00<\\x00\\x00\\x009\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\xa8\\x00\\x00\\x00b\\x00\\x00\\x00\\x95\\x00\\x00\\x00\\x8f\\x00\\x00\\x00\\xa2\\x00\\x00\\x00\\xad\\x00\\x00\\x00\\x9b\\x00\\x00\\x00\\x8f\\x00\\x00\\x00`\\x00\\x00\\x00{\\x00\\x00\\x00\\x9f\\x00\\x00\\x009\\x00\\x00\\x00\\xb0\\x00\\x00\\x00f\\x00\\x00\\x00y\\x00\\x00\\x009\\x00\\x00\\x00\\x88\\x00\\x00\\x00s\\x00\\x00\\x00\\xa5\\x00\\x00\\x00\\x1b\\x00\\x00\\x00f\\x00\\x00\\x00\\x9f\\x00\\x00\\x00\\xaf\\x00\\x00\\x00\\r\\x00\\x00\\x00:\\x00\\x00\\x00\\xb4\\x00\\x00\\x00\"\\x00\\x00\\x00\\x7f\\x00\\x00\\x00\\xae\\x00\\x00\\x00\\xbd\\x00\\x00\\x00s\\x00\\x00\\x00L\\x00\\x00\\x00\\xae\\x00\\x00\\x00\\x13\\x00\\x00\\x00\\x96\\x00\\x00\\x00\\x06\\x00\\x00\\x00k\\x00\\x00\\x00\\xaa\\x00\\x00\\x00\\xc3\\x00\\x00\\x003\\x00\\x00\\x00\\xaa\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8f\\x00\\x00\\x00\\xa5\\x00\\x00\\x00J\\x00\\x00\\x00*\\x00\\x00\\x00\\x85\\x00\\x00\\x00\\xb8\\x00\\x00\\x00\\\\\\x00\\x00\\x00L\\x00\\x00\\x00v\\x00\\x00\\x00]\\x00\\x00\\x00l\\x00\\x00\\x00p\\x00\\x00\\x007\\x00\\x00\\x00\\x82\\x00\\x00\\x00q\\x00\\x00\\x00I\\x00\\x00\\x00\\xc3\\x00\\x00\\x00@\\x00\\x00\\x00X\\x00\\x00\\x00&\\x00\\x00\\x00R\\x00\\x00\\x00c\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x03\\x00\\x00\\x00S\\x00\\x00\\x00\\xb6\\x00\\x00\\x00a\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x84\\x00\\x00\\x00\\x8f\\x00\\x00\\x00\\xc5\\x00\\x00\\x007\\x00\\x00\\x00\\x16\\x00\\x00\\x00J\\x00\\x00\\x00\\x14\\x00\\x00\\x00\\x9a\\x00\\x00\\x00q\\x00\\x00\\x00\\x8d\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\xb5\\x00\\x00\\x00)\\x00\\x00\\x00\\x19\\x00\\x00\\x005\\x00\\x00\\x00<\\x00\\x00\\x00,\\x00\\x00\\x00\\x89\\x00\\x00\\x005\\x00\\x00\\x007\\x00\\x00\\x00d\\x00\\x00\\x00x\\x00\\x00\\x005\\x00\\x00\\x00^\\x00\\x00\\x00x\\x00\\x00\\x00\\xa3\\x00\\x00\\x006\\x00\\x00\\x00\\x8c\\x00\\x00\\x00\\x00\\x00\\x00\\x00u\\x00\\x00\\x00(\\x00\\x00\\x00\\xab\\x00\\x00\\x00l\\x00\\x00\\x00]\\x00\\x00\\x00k\\x00\\x00\\x00e\\x00\\x00\\x00\\xab\\x00\\x00\\x00B\\x00\\x00\\x00\\xc5\\x00\\x00\\x00E\\x00\\x00\\x00\\x81\\x00\\x00\\x00\\n\\x00\\x00\\x00&\\x00\\x00\\x00\\x15\\x00\\x00\\x00S\\x00\\x00\\x006\\x00\\x00\\x00a\\x00\\x00\\x00\\x01\\x00\\x00\\x00R\\x00\\x00\\x00*\\x00\\x00\\x00\\xb4\\x00\\x00\\x00\\x13\\x00\\x00\\x00/\\x00\\x00\\x00\\xb4\\x00\\x00\\x00u\\x00\\x00\\x00\\xbe\\x00\\x00\\x00\\x06\\x00\\x00\\x00w\\x00\\x00\\x00\\x8c\\x00\\x00\\x00\\xc5\\x00\\x00\\x00\\x8d\\x00\\x00\\x00\\x13\\x00\\x00\\x00.\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x99\\x00\\x00\\x00!\\x00\\x00\\x00=\\x00\\x00\\x00}\\x00\\x00\\x00\\x14\\x00\\x00\\x00k\\x00\\x00\\x00\\xaf\\x00\\x00\\x00E\\x00\\x00\\x00\\x8d\\x00\\x00\\x00\\x85\\x00\\x00\\x00\\x14\\x00\\x00\\x00A\\x00\\x00\\x00\\x96\\x00\\x00\\x00\\x1a\\x00\\x00\\x00|\\x00\\x00\\x00\\x98\\x00\\x00\\x00r\\x00\\x00\\x00*\\x00\\x00\\x00D\\x00\\x00\\x00~\\x00\\x00\\x00{\\x00\\x00\\x00F\\x00\\x00\\x00)\\x00\\x00\\x00\\x06\\x00\\x00\\x00c\\x00\\x00\\x00y\\x00\\x00\\x00H\\x00\\x00\\x008\\x00\\x00\\x001\\x00\\x00\\x00\\xbd\\x00\\x00\\x00\\x8a\\x00\\x00\\x004\\x00\\x00\\x00\\x82\\x00\\x00\\x00\\xc4\\x00\\x00\\x00\\x1b\\x00\\x00\\x00^\\x00\\x00\\x00\\xba\\x00\\x00\\x00\\xb5\\x00\\x00\\x00\\x12\\x00\\x00\\x007\\x00\\x00\\x00\\xa5\\x00\\x00\\x00j\\x00\\x00\\x00\\xa5\\x00\\x00\\x00\\x12\\x00\\x00\\x00d\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\xa9\\x00\\x00\\x00N\\x00\\x00\\x00\\xb8\\x00\\x00\\x00\\x86\\x00\\x00\\x00&\\x00\\x00\\x008\\x00\\x00\\x00\\x99\\x00\\x00\\x00<\\x00\\x00\\x00\\x88\\x00\\x00\\x00\\x1d\\x00\\x00\\x00`\\x00\\x00\\x00.\\x00\\x00\\x00\\xa1\\x00\\x00\\x00\\xac\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x03\\x00\\x00\\x00?\\x00\\x00\\x00&\\x00\\x00\\x00\\xbe\\x00\\x00\\x00|\\x00\\x00\\x00\\x9e\\x00\\x00\\x00s\\x00\\x00\\x00\\xc3\\x00\\x00\\x00\"\\x00\\x00\\x00D\\x00\\x00\\x00u\\x00\\x00\\x00o\\x00\\x00\\x00w\\x00\\x00\\x00\\x06\\x00\\x00\\x00j\\x00\\x00\\x00i\\x00\\x00\\x00\\xb4\\x00\\x00\\x00w\\x00\\x00\\x00q\\rtq\\x0eb.')        \n#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ CUT HERE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ndef my_agent(observation, configuration):\n    global Gstate, Gprev_friend_move\n    trials = 1000\n    s = observation.step\n    \n    if (s == 0):\n        Gstate = 0\n        # make some dummy sizes\n        Gprev_foe_move = -1\n        Gprev_friend_move = -1\n    if (s > 0):\n        Gprev_foe_move = observation.lastOpponentAction\n        \n    Gstate, Gfriend_move = FSM_move_No_Numba(s, Gprev_friend_move, Gprev_foe_move, Gstate, F.state_choices, F.action_choices) \n    Gprev_friend_move = Gfriend_move\n        \n    return int(Gfriend_move)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A utility for printing two lines to get the FSM into the template. Run the code below. It prints out a couple of very long lines for reading the FSM in the form of a pickled string. Then copy the messy looking output and paste it into the template above, where it will look much like the two lines you will be replacing."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pickle\ndef print_results_F(F): # Spill a lot of gibberish to the screen for cutting and pasting\n    a = pickle.dumps(F.action_choices)\n    s = pickle.dumps(F.state_choices)\n    print(\"F.action_choices = pickle.loads(\", end = \"\")\n    print( a, end = \"\")\n    print(\")\")\n    print(\"F.state_choices  = pickle.loads(\", end = \"\")\n    print( s, end = \"\")\n    print(\")\")\n \nprint_results_F(pop[0])   #pop[0] holds the best individual found by the GA.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And that should do it. This agent isn't going to tear up the leaderboard but it's no longer as dumb as a box of rocks."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}