{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Rock Paper Scissors - Memory Patterns\n\nThis notebook is an independent reimplemention of the high-level ideas in:\n- https://www.kaggle.com/yegorbiryukov/rock-paper-scissors-with-memory-patterns"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%writefile submission.py\n\nimport random\nimport numpy as np \nimport pandas as pd\nfrom typing import List, Dict, Tuple, Any\nfrom operator import itemgetter\nfrom collections import defaultdict\n\n\ndef batch(iterable, n=1):\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]\n\n\nclass MemoryPatterns:\n    def __init__(self, min_memory=2, max_memory=20, threshold=0.5, warmup=5, verbose=True):\n        self.min_memory = min_memory\n        self.max_memory = max_memory\n        self.threshold  = threshold\n        self.warmup     = warmup\n        self.verbose    = verbose\n        self.history = {\n            \"step\":      [],\n            \"reward\":    [],\n            \"opponent\":  [],\n            \"pattern\":   [],\n            \"action\":    [],\n            # \"rotn_self\": [],\n            # \"rotn_opp\":  [],\n        }\n        pass\n    \n    def __call__(self, obs, conf):\n        return self.agent(obs, conf)\n\n    \n    # obs  {'remainingOverageTime': 60, 'step': 1, 'reward': 0, 'lastOpponentAction': 0}\n    # conf {'episodeSteps': 1000, 'actTimeout': 1, 'runTimeout': 1200, 'signs': 3, 'tieRewardThreshold': 20, 'agentTimeout': 60}\n    def agent(self, obs, conf):\n        # print('obs', obs)\n        # print('conf', conf)\n        self.obs  = obs\n        self.conf = conf\n        self.update_state(obs, conf)\n        if obs.step < self.warmup:\n            expected = self.random_action(obs, conf)\n        else:\n            for keys in [ (\"opponent\", \"action\"), (\"opponent\",) ]:\n                # history  = self.generate_history([\"opponent\", \"action\"])  # \"action\" must be last\n                history  = self.generate_history([\"opponent\"])  \n                memories = self.build_memory(history) \n                patterns = self.find_patterns(history, memories)\n                if len(patterns): break\n            score, expected, pattern = self.find_best_pattern(patterns)\n            self.history['pattern'].append(pattern)    \n            if self.verbose:\n                print('keys    ', keys)\n                print('history ', history)\n                print('memories', memories)\n                print('patterns', patterns)\n                print('score   ', score)\n                print('expected', expected)\n                print('pattern ', pattern)\n\n        action = (expected + 1) % conf.signs\n        self.history['action'].append(action)\n        \n        if self.verbose:\n            print('action', action)\n        return int(action) \n    \n    \n    def random_action(self, obs, conf) -> int:\n        return random.randint(0, conf.signs-1)\n\n    def sequential_action(self, obs, conf) -> int:\n        return (obs.step + 1) % conf.signs\n\n    \n    def update_state(self, obs, conf):\n        self.history['step'].append( obs.step )\n        self.history['reward'].append( obs.reward )\n        if obs.step != 0:\n            self.history['opponent'].append( obs.lastOpponentAction )\n            # rotn_self = (self.history['opponent'][-1] - self.history['opponent'][-2]) % conf.signs \n            # rotn_opp  = (self.history['opponent'][-1] - self.history['action'][-1]))  % conf.signs\n            # self.history['rotn_self'].append( rotn_self )\n            # self.history['rotn_opp'].append( rotn_opp )\n        \n        \n    def generate_history(self, keys: List[str]) -> List[Tuple[int]]:\n        # Reverse order to correctly match up arrays\n        history = list(zip(*[ reversed(self.history[key]) for key in keys ]))\n        history = list(reversed(history))\n        return history\n    \n    \n    def build_memory(self, history: List[Tuple[int]]) -> List[ Dict[Tuple[int], List[int]] ]:\n        output    = [ dict() ] * self.min_memory\n        expecteds = self.generate_history([\"opponent\"])\n        for batch_size in range(self.min_memory, self.max_memory+1):\n            if batch_size >= len(history): break  # ignore batch sizes larger than history\n            output_batch    = defaultdict(lambda: [0,0,0])\n            history_batches  = list(batch(history, batch_size+1))\n            expected_batches = list(batch(expecteds, batch_size+1))\n            for n, (pattern, expected_batch) in enumerate(zip(history_batches, expected_batches)):\n                previous_pattern = tuple(pattern[:-1])\n                expected         = (expected_batch[-1][-1] or 0) % self.conf.signs  # assume \"action\" is always last \n                output_batch[ previous_pattern ][ expected ] += 1\n            output.append( dict(output_batch) )\n        return output\n\n    \n    def find_patterns(self, history: List[Tuple[int]], memories: List[ Dict[Tuple[int], List[int]] ]) -> List[Tuple[float, int, Tuple[int]]]:\n        patterns = []\n        for n in range(1, self.max_memory+1):\n            if n >= len(history): break\n                \n            pattern = tuple(history[-n:])\n            if pattern in memories[n]:\n                score    = np.std(memories[n][pattern])\n                expected = np.argmax(memories[n][pattern])\n                patterns.append( (score, expected, pattern) )\n        patterns = sorted(patterns, key=itemgetter(0), reverse=True)\n        return patterns\n    \n    \n    def find_best_pattern(self, patterns: List[Tuple[float, int, Tuple[int]]] ) -> Tuple[float, int, Tuple[int]]:\n        patterns       = sorted(patterns, key=itemgetter(0), reverse=True)\n        pattern_scores = self.get_pattern_scores()\n        for (score, expected, pattern) in patterns:\n            break\n            # if pattern in pattern_scores:\n            #     if pattern_scores[pattern] > self.threshold:\n            #         break\n            #     else:\n            #         expected += 1\n            #         break\n            # else:\n            #     break\n        else:\n            score    = 0.0\n            expected = self.random_action(self.obs, self.conf)\n            pattern  = tuple()\n        return score, expected, pattern\n    \n    \n    def get_pattern_scores(self):\n        pattern_rewards = defaultdict(list)\n        for reward, pattern in self.generate_history([\"reward\", \"pattern\"]):\n            pattern_rewards[pattern].append( reward )\n        pattern_scores = { pattern: np.mean(rewards) for patten, rewards in pattern_rewards.items() }\n        return pattern_scores\n                    \n            \n            \ninstance = MemoryPatterns()\ndef kaggle_agent(obs, conf):\n    return instance(obs, conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sequential_agent(obs, conf) -> int:\n    return (obs.step + 1) % conf.signs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%run submission.py","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils\n\nenv = make(\"rps\", debug=True, configuration={\"episodeSteps\": 20})\n# env.run([ \"submission.py\", \"submission.py\"])\n# env.run([ \"submission.py\", \"../input/rock-paper-scissors-anti-rotn/anti_rotn.py\"])\nenv.run([ \"submission.py\", sequential_agent])\nenv.render(mode=\"ipython\", width=450, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agents = {\n    \"rock\":          0,\n    \"sequential\":    sequential_agent,\n    \"anti-rotn\":     \"../input/rock-paper-scissors-anti-rotn/anti_rotn.py\",\n    \"decision-tree\": \"../input/rock-paper-scissors-decision-tree/submission.py\",\n}\nfor agent_name, agent_script in agents.items():\n    scores = evaluate(\"rps\", [ \"submission.py\", agent_script])[0]\n    print(f'{scores[0]:4.0f} vs {scores[1]:4.0f} | {agent_name}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Further Reading\n\nThis notebook is part of a series exploring Rock Paper Scissors:\n\nPredetermined\n- [PI Bot](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-pi-bot)\n- [Anti-PI Bot](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-anti-pi-bot)\n- [Anti-Anti-PI Bot](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-anti-anti-pi-bot)\n- [De Bruijn Sequence](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-de-bruijn-sequence)\n\nRNG\n- [Random Agent](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-random-agent)\n- [Random Seed Search](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-random-seed-search)\n- [RNG Statistics](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-rng-statistics)\n\nOpponent Response\n- [Anti-Rotn](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-anti-rotn)\n- [Sequential Strategies](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-sequential-strategies)\n\nStatistical \n- [Weighted Random Agent](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-weighted-random-agent)\n- [Statistical Prediction](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-statistical-prediction)\n- [Anti-Rotn Weighted Random](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-anti-rotn-weighted-random)\n\nMemory Patterns\n- [Naive Bayes](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-naive-bayes)\n- [Memory Patterns](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-memory-patterns)\n\nDecision Tree\n- [XGBoost](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-xgboost)\n- [Multi Stage Decision Tree](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-multi-stage-decision-tree)\n- [Decision Tree Ensemble](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-decision-tree-ensemble)\n\nEnsemble\n- [Multi Armed Stats Bandit](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-multi-armed-stats-bandit)\n\nRoShamBo Competition Winners\n- [Iocaine Powder](https://www.kaggle.com/jamesmcguigan/rps-roshambo-comp-iocaine-powder)\n- [Greenberg](https://www.kaggle.com/jamesmcguigan/rock-paper-scissors-greenberg)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}