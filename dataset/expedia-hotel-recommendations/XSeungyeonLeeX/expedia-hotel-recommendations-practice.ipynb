{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## All columns\n''' 'date_time', 'site_name', 'posa_continent', 'user_location_country',\n    'user_location_region', 'user_location_city',\n    'orig_destination_distance', 'user_id', 'is_mobile', 'is_package',\n    'channel', 'srch_ci', 'srch_co', 'srch_adults_cnt', 'srch_children_cnt',\n    'srch_rm_cnt', 'srch_destination_id', 'srch_destination_type_id',\n    'is_booking', 'cnt', 'hotel_continent', 'hotel_country', 'hotel_market',\n    'hotel_cluster'\n'''\n## My opinion - mandatory columns\n'''\nsrch_destination_id, is_booking, hotel_cluster, srch_adults_cnt\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"NUMBER_OF_ROWS = 1000 # Train data is too big, get some rows\ntrain_df = pd.read_csv('/kaggle/input/expedia-hotel-recommendations/train.csv', nrows=NUMBER_OF_ROWS)\n\n# Aggregation data\ngroupby1 = train_df.groupby(['srch_destination_id', 'hotel_cluster'])['is_booking'].agg(['count'])\ngroupby1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert single index dataframe\nsingle_index_df = groupby1.reset_index(level=[0,1])\nsingle_index_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collect hotel_cluster as list\ndef list_2_str(items):\n    if (items is None) or (len(items) <= 0):\n        return ''\n    result = ''\n    for item in items:\n        result = result + str(item) + ','\n    return result[:(len(result) - 1)]\n\ntotal_count_of_hotel_cluster = 0 \ndestination_id_n_cluster_list = dict()\nfor index, row in single_index_df.iterrows():\n    srch_destination_id = row['srch_destination_id']\n    hotel_cluster = row['hotel_cluster']\n    \n    hotel_clusters = list()\n    if srch_destination_id in destination_id_n_cluster_list:\n        hotel_clusters = destination_id_n_cluster_list[srch_destination_id]\n    hotel_clusters.append(hotel_cluster)\n    total_count_of_hotel_cluster += 1\n    destination_id_n_cluster_list[srch_destination_id] = hotel_clusters\n\ndestination_id_n_clusters = dict()\nfor key, value in destination_id_n_cluster_list.items():\n    str_value = list_2_str(value)\n    destination_id_n_clusters[key] = str_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert dict_list to dataframe\nfinal_df = pd.DataFrame(destination_id_n_clusters.items(), columns=['srch_destination_id', 'hotel_clusters'])\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train - Manual Implementation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"NUMBER_OF_ROWS = 5000 # Train data is too big, get some rows\ntest_df = pd.read_csv('/kaggle/input/expedia-hotel-recommendations/train.csv', nrows=NUMBER_OF_ROWS, usecols=['srch_destination_id'])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_test_df = test_df.merge(final_df, how = 'left')\nmerged_test_df[['hotel_clusters']] = merged_test_df[['hotel_clusters']].fillna(value = 'NA')\nmerged_test_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.scatter(merged_test_df['srch_destination_id'].values, merged_test_df['hotel_clusters'].values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train - K-Nearst Neighbor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aggregation data\nNUMBER_OF_ROWS = 5000 # Train data is too big, get some rows\ntrain_df = pd.read_csv('/kaggle/input/expedia-hotel-recommendations/train.csv', nrows=NUMBER_OF_ROWS)\ntest_df = pd.read_csv('/kaggle/input/expedia-hotel-recommendations/test.csv', nrows=NUMBER_OF_ROWS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_nearest_train_points = train_df[['srch_destination_id']]\nk_nearest_train_labels = train_df[['hotel_cluster']]\nk_nearest_test_points = test_df[['srch_destination_id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nk_nearest_classifier = KNeighborsClassifier(n_neighbors = 100)\nk_nearest_classifier.fit(k_nearest_train_points, k_nearest_train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_nearest_result = k_nearest_classifier.predict(k_nearest_test_points)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(k_nearest_test_points, k_nearest_result, s=50, alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train - Agglomerative clustering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"NUMBER_OF_ROWS = 5000 # Train data is too big, get some rows\ntrain_df = pd.read_csv('/kaggle/input/expedia-hotel-recommendations/train.csv', nrows=NUMBER_OF_ROWS)\ntest_df = pd.read_csv('/kaggle/input/expedia-hotel-recommendations/test.csv', nrows=NUMBER_OF_ROWS)\n\nagg_cluster_X = train_df[['srch_destination_id']]\nagg_cluster_Y = train_df[['hotel_cluster']]\nagg_cluster_destination_id = test_df[['srch_destination_id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\n\nagglomerativeCluster = AgglomerativeClustering(n_clusters = 100, linkage = 'ward')\nagglomerativeCluster.fit(agg_cluster_X, agg_cluster_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_recommend_hotel = agglomerativeCluster.fit_predict(agg_cluster_destination_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(agg_cluster_destination_id, agg_recommend_hotel, s = 50, alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}