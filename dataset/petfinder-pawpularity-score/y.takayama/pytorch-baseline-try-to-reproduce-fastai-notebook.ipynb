{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is based on the following notebook, thanks.\n\nhttps://www.kaggle.com/manabendrarout/transformers-classifier-method-starter-train#Train-and-Validation-Functions","metadata":{}},{"cell_type":"markdown","source":"## libraries","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings(\"ignore\")\n#general\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import RobustScaler\nimport pickle\nfrom tqdm.auto import tqdm\nfrom collections import defaultdict\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport gc\nimport cv2\ngc.enable()\nimport glob\npd.set_option('display.max_columns', None) \nfrom sklearn.linear_model import RidgeCV\n\n# visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# augmentation\nfrom albumentations.pytorch import ToTensorV2\nimport albumentations as A\n\n# deep learning\nimport timm\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR, ReduceLROnPlateau, StepLR, LambdaLR\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport imageio\nfrom PIL import Image\nfrom tqdm import tqdm\ntqdm.pandas()\n\n# metrics\nfrom sklearn.metrics import mean_squared_error","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-20T11:54:38.268453Z","iopub.execute_input":"2021-12-20T11:54:38.268754Z","iopub.status.idle":"2021-12-20T11:54:43.41251Z","shell.execute_reply.started":"2021-12-20T11:54:38.268721Z","shell.execute_reply":"2021-12-20T11:54:43.411643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n    os.makedirs('/root/.cache/torch/hub/checkpoints/')\n!cp '../input/swin-transformer/swin_large_patch4_window7_224_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-20T11:54:43.41456Z","iopub.execute_input":"2021-12-20T11:54:43.414866Z","iopub.status.idle":"2021-12-20T11:54:52.709888Z","shell.execute_reply.started":"2021-12-20T11:54:43.414816Z","shell.execute_reply":"2021-12-20T11:54:52.708926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"class Config:\n    base_dir = \"/content/drive/MyDrive/petfinder\"\n    data_dir = \"../input/petfinder-pawpularity-score/\"\n    meta_data_dir = \"../input/trainmeta/\"\n    model_dir = \".\"\n    output_dir = \".\"\n    random_seed = 555\n    n_epoch = 5\n    n_fold = 5\n    tta = 1 # 1 or 4\n    model_path = \"swin_large_patch4_window7_224\"\n    pretrained = True\n    inp_channels = 3\n    im_size =  224\n    lr = 2e-5\n    opt_wd_non_norm_bias = 0.01\n    opt_wd_norm_bias = 0 # same as Adam in Fastai\n    opt_beta1 = 0.9\n    opt_beta2 = 0.99 # same as Adam in Fastai\n    opt_eps = 1e-5 # same as Adam in Fastai\n    batch_size = 32\n    epoch_step_valid = 3\n    num_workers = 8\n    out_features = 1\n    dropout = 0\n    mixup = False\n    mixup_alpha =1.0\n    debug = False\n    if debug:\n        n_epoch = 1\n        n_fold = 2\n        n_sample_debug = 500","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:52.714605Z","iopub.execute_input":"2021-12-20T11:54:52.715326Z","iopub.status.idle":"2021-12-20T11:54:52.7242Z","shell.execute_reply.started":"2021-12-20T11:54:52.715285Z","shell.execute_reply":"2021-12-20T11:54:52.723568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## set up environments & prepare data\n\n- set_seed\nSet random seed for random, torch, and numpy\n\nhttps://docs.fast.ai/torch_core.html#set_seed\n\nif reproducible is True:\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=Config.random_seed):\n    #os.environ['PYTHONSEED'] = str(seed)\n    np.random.seed(seed%(2**32-1))\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic =True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything()\n# device optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:52.728468Z","iopub.execute_input":"2021-12-20T11:54:52.728854Z","iopub.status.idle":"2021-12-20T11:54:53.028302Z","shell.execute_reply.started":"2021-12-20T11:54:52.728819Z","shell.execute_reply":"2021-12-20T11:54:53.02754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_train_dir = os.path.join(Config.data_dir, 'train')\ndef return_imgfilepath(name, folder=img_train_dir):\n    path = os.path.join(folder, f'{name}.jpg')\n    return path\n\ntrain_file_path = os.path.join(Config.data_dir, 'train.csv')\ntrain_df = pd.read_csv(train_file_path)\n\n# set image filepath\ntrain_df['file_path'] = train_df['Id'].progress_apply(lambda x: return_imgfilepath(x))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:53.029597Z","iopub.execute_input":"2021-12-20T11:54:53.029987Z","iopub.status.idle":"2021-12-20T11:54:53.12413Z","shell.execute_reply.started":"2021-12-20T11:54:53.029954Z","shell.execute_reply":"2021-12-20T11:54:53.123371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## StratifiedKFold","metadata":{}},{"cell_type":"code","source":"if Config.debug:\n    train_df = train_df.sample(500).reset_index(drop = True)\ntrain_df['norm_score'] = train_df['Pawpularity'] / 100\n#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['fold'] = -1\n\nskf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state =Config.random_seed)\nfor i, (_, train_index) in enumerate(skf.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:53.125332Z","iopub.execute_input":"2021-12-20T11:54:53.126037Z","iopub.status.idle":"2021-12-20T11:54:53.486235Z","shell.execute_reply.started":"2021-12-20T11:54:53.126001Z","shell.execute_reply":"2021-12-20T11:54:53.485584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['fold']==0].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:53.487415Z","iopub.execute_input":"2021-12-20T11:54:53.48782Z","iopub.status.idle":"2021-12-20T11:54:53.505118Z","shell.execute_reply.started":"2021-12-20T11:54:53.487777Z","shell.execute_reply":"2021-12-20T11:54:53.504316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset & augmentation\n\n### PetDataset\nchannels of image converted to 0-1\n\n### get_transforms\nOnly resizing is applied to both train and valid data ","metadata":{}},{"cell_type":"code","source":"class PetDataset(Dataset):\n    def __init__(self, image_filepaths, targets, transform=None):\n        self.image_filepaths = image_filepaths\n        self.targets = targets\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.image_filepaths[idx]\n        with open(image_filepath, 'rb') as f:\n            image = Image.open(f)\n            image_rgb = image.convert('RGB')\n        image = np.array(image_rgb) / 255 # convert to 0-1\n\n        if self.transform is not None:\n            image = self.transform(image = image)[\"image\"]\n        \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        target = self.targets[idx]\n\n        image = torch.tensor(image, dtype = torch.float)\n        target = torch.tensor(target, dtype = torch.float)\n        return image, target\n    \ndef get_transforms(dim = Config.im_size):\n    return A.Compose(\n        [            \n            A.Resize(height=dim, width=dim)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:53.506557Z","iopub.execute_input":"2021-12-20T11:54:53.506876Z","iopub.status.idle":"2021-12-20T11:54:53.516903Z","shell.execute_reply.started":"2021-12-20T11:54:53.506811Z","shell.execute_reply":"2021-12-20T11:54:53.51622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"class PetNet(nn.Module):\n    def __init__(\n        self,\n        model_name = Config.model_path,\n        out_features = Config.out_features,\n        inp_channels=Config.inp_channels,\n        pretrained=Config.pretrained\n    ):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n    \n    def forward(self, image):\n        output = self.model(image)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:53.518318Z","iopub.execute_input":"2021-12-20T11:54:53.518786Z","iopub.status.idle":"2021-12-20T11:54:53.526456Z","shell.execute_reply.started":"2021-12-20T11:54:53.518749Z","shell.execute_reply":"2021-12-20T11:54:53.525792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## helper function\n\n### divice_norm_bias\nfunction to divide parameters at BatchNorm layer and all bias or not.\n\n### usr_rmse_score\ncalculate competition metrics\n\nreference\n- https://docs.fast.ai/learner.html#Learner\n- https://docs.fast.ai/optimizer.html#Adam\n- https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html\n- https://docs.fast.ai/losses.html#BCEWithLogitsLossFlat\n","metadata":{}},{"cell_type":"code","source":"def divice_norm_bias(model): \n    norm_bias_params = []\n    non_norm_bias_params = []\n    except_wd_layers = ['norm', '.bias']\n    for n, p in model.model.named_parameters():\n        if any([nd in n for nd in except_wd_layers]):\n            norm_bias_params.append(p)\n        else:\n            non_norm_bias_params.append(p)\n    return norm_bias_params, non_norm_bias_params\n\ndef usr_rmse_score(output, target):\n    y_pred = torch.sigmoid(output).cpu()\n    y_pred = y_pred.detach().numpy()*100\n    target = target.cpu()*100\n    \n    return mean_squared_error(target, y_pred, squared=False)\n\ndef rmse_oof(_oof_df, fold=None):\n    oof_df = _oof_df.copy()\n    if fold is not None:\n        oof_df = oof_df[oof_df[\"fold\"] == fold]\n    target = oof_df['Pawpularity'].values\n    y_pred = oof_df['pred'].values\n    if fold is not None:\n        print(f'fold {fold}: {mean_squared_error(target, y_pred, squared=False)}')\n    else:\n        print(f'overall: {mean_squared_error(target, y_pred, squared=False)}')\n\nclass MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"],\n                    float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:53.530016Z","iopub.execute_input":"2021-12-20T11:54:53.530525Z","iopub.status.idle":"2021-12-20T11:54:53.543563Z","shell.execute_reply.started":"2021-12-20T11:54:53.530475Z","shell.execute_reply":"2021-12-20T11:54:53.54268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, epoch):\n    metric_monitor = MetricMonitor()\n    model.train()\n    scaler = GradScaler()\n    stream = tqdm(train_loader)\n\n    for batch_idx, (images, target) in enumerate(stream, start = 1):\n        images = images.to(device, non_blocking = True).float()\n        target = target.to(device, non_blocking = True).float().view(-1, 1)\n\n\n        with autocast(): # mixed precision\n            output = model(images)\n        \n        loss = criterion(output, target)\n        rmse_score = usr_rmse_score(output, target)\n        metric_monitor.update('Loss', loss.item())\n        metric_monitor.update('RMSE', rmse_score)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n        stream.set_description(f'Epoch: {epoch:02}. Train. {metric_monitor}')\n\ndef valid_fn(valid_loader, model, criterion, epoch):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(valid_loader)\n    final_targets = []\n    final_preds = []\n    for i, (images, target) in enumerate(stream, start=1):\n        images = images.to(device, non_blocking = True).float()\n        target = target.to(device, non_blocking = True).float().view(-1, 1)\n        with torch.no_grad():\n            output = model(images)\n        \n        loss = criterion(output, target)\n        rmse_score = usr_rmse_score(output, target)\n        metric_monitor.update('Loss', loss.item())\n        metric_monitor.update('RMSE', rmse_score)\n        stream.set_description(f\"Epoch: {epoch:02}. Valid. {metric_monitor}\")\n        target = (target.detach().cpu().numpy() * 100).ravel().tolist()\n        pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n\n        final_preds.extend(pred)\n        final_targets.extend(target)\n    final_preds = np.array(final_preds)\n    final_targets = np.array(final_targets)\n    del valid_loader, target, output, images\n    gc.collect()\n    torch.cuda.empty_cache()\n    return final_targets, final_preds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-20T11:54:53.544995Z","iopub.execute_input":"2021-12-20T11:54:53.545543Z","iopub.status.idle":"2021-12-20T11:54:53.562507Z","shell.execute_reply.started":"2021-12-20T11:54:53.545504Z","shell.execute_reply":"2021-12-20T11:54:53.561731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## training loop\n\n- scheduler: none\n- optimizer: AdamW\nhyper parameters are the same as Adam in Fastai","metadata":{}},{"cell_type":"code","source":"oof_df = pd.DataFrame()\nfor fold in range(Config.n_fold):\n    print(f'=== fold {fold}: training ===')\n    train = train_df[train_df['fold'] != fold]\n    valid = train_df[train_df['fold'] == fold]\n    valid_idx = valid.index\n    \n    X_train_paths = train['file_path'].values\n    y_train = train['norm_score'].values\n    X_valid_paths = valid['file_path'].values\n    y_valid = valid['norm_score'].values\n    \n    train_dataset = PetDataset(\n      image_filepaths = X_train_paths,\n      targets = y_train,\n      transform = get_transforms()\n    )\n    \n    train_loader = DataLoader(\n      train_dataset,\n      batch_size = Config.batch_size,\n      shuffle = True,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    \n    valid_dataset = PetDataset(\n      image_filepaths = X_valid_paths,\n      targets = y_valid,\n      transform = get_transforms()\n    )\n    \n    valid_loader = DataLoader(\n      valid_dataset,\n      batch_size = Config.batch_size,\n      shuffle = True,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    \n    model = PetNet()\n    model = model.to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    norm_bias_params, non_norm_bias_params = divice_norm_bias(model)\n    optimizer = torch.optim.AdamW(\n      [\n          {'params': norm_bias_params, 'weight_decay': Config.opt_wd_norm_bias},\n          {'params': non_norm_bias_params, 'weight_decay': Config.opt_wd_non_norm_bias},\n      ],\n      betas=(Config.opt_beta1, Config.opt_beta2),\n      eps=Config.opt_eps,\n      lr = Config.lr,\n      amsgrad = False\n    )\n    \n    best_rmse = np.inf\n    for epoch in range(1, Config.n_epoch + 1):\n        print(f'=== fold:{fold} epoch: {epoch}: training ===')\n        train_fn(train_loader, model, criterion, optimizer, epoch)\n        valid_targets, preds = valid_fn(valid_loader, model, criterion, epoch)\n        valid_rmse = round(mean_squared_error(valid_targets, preds, squared=False), 3)\n        print(f'epoch {epoch}: rmse: {valid_rmse}')\n        \n        if valid_rmse < best_rmse:\n            best_rmse = valid_rmse\n            torch.save(model.state_dict(), f'{Config.model_dir}/model_fold{fold}.pth')\n            print(\"saved model.\")\n            _oof_df = pd.DataFrame(data={'Pawpularity':valid_targets, 'pred':preds, 'fold':fold}, index=valid_idx)\n            \n    del model, train_dataset, train_loader, valid_dataset, valid_loader\n    gc.collect()\n    torch.cuda.empty_cache()\n    oof_df = pd.concat([oof_df, _oof_df])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:54:53.56394Z","iopub.execute_input":"2021-12-20T11:54:53.564561Z","iopub.status.idle":"2021-12-20T11:56:03.471778Z","shell.execute_reply.started":"2021-12-20T11:54:53.564524Z","shell.execute_reply":"2021-12-20T11:56:03.470956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## cv score","metadata":{}},{"cell_type":"code","source":"for i in range(Config.n_fold):\n    rmse_oof(oof_df, i)\nrmse_oof(oof_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:56:03.473453Z","iopub.execute_input":"2021-12-20T11:56:03.473999Z","iopub.status.idle":"2021-12-20T11:56:03.484178Z","shell.execute_reply.started":"2021-12-20T11:56:03.473949Z","shell.execute_reply":"2021-12-20T11:56:03.483221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df.sort_index().to_csv('oof.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:58:36.172039Z","iopub.execute_input":"2021-12-20T11:58:36.172375Z","iopub.status.idle":"2021-12-20T11:58:36.183379Z","shell.execute_reply.started":"2021-12-20T11:58:36.172337Z","shell.execute_reply":"2021-12-20T11:58:36.182676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(oof_df['Pawpularity'].values, alpha = 0.4, color = 'b', label = 'target', bins = 50)\nplt.hist(oof_df['pred'].values, alpha = 0.4, color = 'g', label = 'prediction', bins = 50)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:56:03.502235Z","iopub.execute_input":"2021-12-20T11:56:03.502811Z","iopub.status.idle":"2021-12-20T11:56:03.909343Z","shell.execute_reply.started":"2021-12-20T11:56:03.502764Z","shell.execute_reply":"2021-12-20T11:56:03.908222Z"},"trusted":true},"execution_count":null,"outputs":[]}]}