{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Imports cell\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import datasets\nfrom sklearn import model_selection\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-13T17:08:26.809722Z","iopub.execute_input":"2021-11-13T17:08:26.809996Z","iopub.status.idle":"2021-11-13T17:08:29.809485Z","shell.execute_reply.started":"2021-11-13T17:08:26.809964Z","shell.execute_reply":"2021-11-13T17:08:29.808812Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Starter Notebook with Explanations\n\n1. The purpose of this notebook is to analyze the reasoning behind the code in each cell from Abishek Thakur's 4 steps. \n    - https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/274026\n    - all credit for code goes to him. I'm just following along and trying to understand everything.\n2. I wanted to go through line by line and fill in the knowledge gaps I was lacking. Hopefully this helps the next noob. I learned alot. \n\n3. When running the notebook, be sure to turn on accelerator settings to GPU before running or you will get error.","metadata":{}},{"cell_type":"markdown","source":"## Step 1. - Create the folds\n\nHe is doing the following: <br>\n1. Creating a function where inputs are \"data\" and \"num_splits\"\n    - create \"kfolds\" column with all values as -1\n<br>    \n2. int(np.floor(1 + np.log2(len(data)))) - This formula is from [\"Sturges Rule\"](https://answerminer.com/blog/binning-guide-ideal-histogram)\n    - Ideally it can be any of the methods in the website above. He went with Sturges Rule for choice of bin numbers\n    - He also did \"floor\" whereas in other websites they use \"ceil\". It doesn't really matter because we are forcing the number to become an integer.\n<br>    \n3. Using .loc method on data, he makes a change for all rows in the column \"bins\"\n    - He adds a numeric label for each bin range for each value \n        - This is simply part of the method to finally get kfold numbers\n        - The data.bins.values means he will treat the bin.values as \"categories\" to create splits across\n<br>        \n4. [StratifiedKfold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)\n    - Provides train/test indices to split data in train/test sets.\n    - This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.\n    -for the sake of my sanity, i renamed \"kf\" variable to skf to signify \"STRATIFIED K-FOLD\"\n    - In classifications tasks with imbalanced class distributions, we should prefer StratifiedKFold over KFold. The bin labels are treated as \"classes\"\n<br>    \n5. The for loop\n    - Using the Stratified K-fold cross-validation object, he applies \"split\" method with inputs \n        - x = data\n        - y = the numeric label of each bin range, this is our \"df.target\"\n    - this returns the indices of the split data of which he iterates through using \"enumerate\"\n    - for each of the \"f, (t_, v_)\" values, f is the enumerate number, and (t_,v_) is the (x,y) value after split\n        - access the specified index in array \"v_\" with column 'kfold' using .loc method on dataframe\n            - set the specified index value for kfold to indicate which fold dictated by enumerate \"f\" from the split            \n    - WE DONT CARE ABOUT THE [0] TUPLE POSITION. WE CARE ABOUT THE ARRAY OF INDICES FOR [1] TUPLE POSITION WHICH WILL UPDATE TO THE RESPECTIVE KFOLD NUMBER IN KFOLD COLUMN\n<br>    \n6. Once this is done, delete \"bins\" column and you are left with a dataframe with additional column of \"kfold\" which assigns a fold number to each of the rows which reflects a stratified kfold","metadata":{}},{"cell_type":"code","source":"def create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n#     print(num_bins)\n\n    data.loc[:, \"bins\"] = pd.cut(data[\"Pawpularity\"], bins=num_bins, labels=False)\n\n    skf = model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n    \n    for f, (t_, v_) in enumerate(skf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'kfold'] = f\n             \n    data = data.drop(\"bins\", axis=1)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:29.81106Z","iopub.execute_input":"2021-11-13T17:08:29.811311Z","iopub.status.idle":"2021-11-13T17:08:29.818173Z","shell.execute_reply.started":"2021-11-13T17:08:29.811277Z","shell.execute_reply":"2021-11-13T17:08:29.817505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Once the function is defined, call the \"create_folds\" function and generate whatever amount of folds you want to create!\n\n1. In below steps, he arbitrarily chooses 5 and 10 folds. \n    - How would we figure out what is the optimal number of folds?\n2. Once folds are created, save data to csv and proceed onto next step which is to train the model with the folded data\n    - If you don't see that data in the \"output/kaggle/working\" directory, there is a little refresh button next to /kaggle/working on the right side. Click and you will see the data there.","metadata":{}},{"cell_type":"code","source":"# df = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\n\n# #Call \"create_folds\" function\n# df_5 = create_folds(df, num_splits=5)\n# df_10 = create_folds(df, num_splits=10)\n\n# #Save data to csv\n# df_5.to_csv(\"train_5folds.csv\", index=False)\n# df_10.to_csv(\"train_10folds.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:29.819367Z","iopub.execute_input":"2021-11-13T17:08:29.819662Z","iopub.status.idle":"2021-11-13T17:08:29.832282Z","shell.execute_reply.started":"2021-11-13T17:08:29.819616Z","shell.execute_reply":"2021-11-13T17:08:29.831521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2. Train the data","metadata":{}},{"cell_type":"markdown","source":"### Imports\n\n1. <b>Tez</b> - My understanding of Tez is that it is an easier way of putting in parameters requirements when setting up a model in pytorch \n    - I had issues running \"import sys --> sys.path.append(\"../input/tez-lib/\") and sys.path.append(\"../input/timmmaster/\")\n    - As a workaround, I manually clicked \"Add data\" at the top right corner of the notebook\n        - Searched for \"tez-lib\" and \"timmmaster\" in the search box and clicked the blue \"Add\" button\n   \n   - https://github.com/abhishekkrthakur/tez\n2. <b>albumentations</b> - A fast/flexible python library for image augmentations\n    - https://albumentations.ai/\n    - used by industry leaders\n3. <b>pandas</b> - for manipulating dataframes\n4. <b>cv2</b> - OpenCV - A huge open-source library for computer vision, machine learning, and image processing\n5. <b>numpy</b> - python library - allows for large multi-dimensional arrays and do high level math functions on them\n6. <b>timm</b> - Part of pytorch image models is a deep-learning library created by Ross Wightman and is a collection of STATE OF THE ART computer vision models, layers, utilities, optimizers, schedulers, data-loaders, augmentations and also training/validating scripts with ability to reproduce ImageNet training results. \n    - https://fastai.github.io/timmdocs/\n7. <b>torch and torch.nn</b> - PyTorch and .nn is a PyTorch library that simplifies creation of neural net models. We use this instead of making them from scratch.\n8. <b>sklearn.metrics</b> - metrics module implements functions assessing prediction error for specific purposes\n9. <b>tqdm</b> - Used for those fancy looking progress bars in the output cells\n    - https://tqdm.github.io/\n10. <b>Tez.EarlyStopping</b> is used to checkpoint the best model and stop the training prematurely if needed.    ","metadata":{}},{"cell_type":"code","source":"## Keep these in here, I was having issues importing tez and timm even after manually clicking \"Add Data\"\nimport sys\nsys.path.append(\"../input/tez-lib/\")\nsys.path.append(\"../input/timmmaster\")\n##\nimport pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nimport albumentations\nimport cv2\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport tez\nfrom tez.callbacks import EarlyStopping\nimport timm","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:31.892238Z","iopub.execute_input":"2021-11-13T17:08:31.892865Z","iopub.status.idle":"2021-11-13T17:08:31.899324Z","shell.execute_reply.started":"2021-11-13T17:08:31.892824Z","shell.execute_reply":"2021-11-13T17:08:31.898215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The \"Args\" Class \n- will be called in the later functions for albumentations and the neural net model. This is made to simplify the functions and take out the hardcoding of numbers. We can make changes to the args at any time and the functions will use those changes.","metadata":{}},{"cell_type":"code","source":"class args:\n    batch_size = 64\n    image_size = 256\n    epochs = 20\n    fold = 0","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:33.171657Z","iopub.execute_input":"2021-11-13T17:08:33.172658Z","iopub.status.idle":"2021-11-13T17:08:33.177003Z","shell.execute_reply.started":"2021-11-13T17:08:33.172598Z","shell.execute_reply":"2021-11-13T17:08:33.176317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \"PawpularDataset\" Class\nhttps://stackoverflow.com/questions/625083/what-init-and-self-do-in-python\n<br>\nhttps://docs.python.org/3/tutorial/classes.html\n<br>\nhttps://rszalski.github.io/magicmethods/\n1. Basically it is object oriented programming (OOP) where there are oop constructs that are passed in order like loops.\n   - e.g. first it is init, then len, and then finally getitem\n   - looks like a commonly used class structure\n       - https://debuggercafe.com/image-augmentation-using-pytorch-and-albumentations/\n2. within init, he is setting the arguments that he will pass into the next functions below\n3. within len - I don't understand why this is needed. Only 2 occurences of len. I'll ignore for now.\n4. within getitem - __getitem__ is a magic method in python that which when used in a class, allows its instances to use the [] (indexer) operators. Say x is an instance of this class, then x[i] is roughly equivalent to \"type(x).__getitem__(x, i)\"\n    - https://www.geeksforgeeks.org/__getitem__-in-python/\n        - magic method is usually used for list indexing, dictionary lookup, or accessing ranges of values.\n    - he uses OpenCv to read each row's information under \"Id\" column\n    - augmentations will be related to <b>albumentations</b>\n    - np.transpose\n        - he is transposing along the axis (2,0,1). I don't understand this too well but i am guessing he has to make the array a certain shape in order to work with pytorch \"torch.tensor\"\n    - uses torch.tensor to create tensor-matrix of the data\n        - creates 3 tensors: image, features, targets","metadata":{}},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:37.231485Z","iopub.execute_input":"2021-11-13T17:08:37.231936Z","iopub.status.idle":"2021-11-13T17:08:37.242677Z","shell.execute_reply.started":"2021-11-13T17:08:37.231899Z","shell.execute_reply":"2021-11-13T17:08:37.241935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \"PawpularModel\" Class\n\n1. Here, he is setting up the structure of the model without fitting it to any data. This class will have all the params and metrics related to the model. He also uses <b>Tez</b> here to simplify the setup of the model. The stuff he uses in tez are basically the inputs needed to set up a model in pytorch.\n    - All the functions within the class are cut/paste template from <b>Tez</b> https://pypi.org/project/tez/\n2. init(self) - is just part of the code.\n    - He uses \"tf_efficientnet_b0_ns\" as the pytorch model. i could try v2\n        - pretrained = True because we are loading in a pretrained model\n    - He chooses efficientnet_b0. According to the paper, theres b0 all the way up to b7/b8. Maybe see how that improves the efficiency\n        - https://arxiv.org/pdf/1905.11946.pdf\n    - much more can be found on the timm documentation https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py\n    - To understand what \"super\" does: https://rhettinger.wordpress.com/2011/05/26/super-considered-super/\n    - step scheduler changes the learning rate afer each epoch\n    - Epochs and forward pass diagrams - https://www.baeldung.com/cs/epoch-neural-networks\n    - <b>Here we have the network layers. Total 4 layers. Plus the step scheduler<b>\n    - dropout is important - improves regularization, reduces overfitting\n        - https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n        - https://arxiv.org/abs/1207.0580\n    - nn.Linear - I don't understand too well\n        - https://stackoverflow.com/questions/54916135/what-is-the-class-definition-of-nn-linear-in-pytorch\n        - According to this, nn.Linear applies a transformation to the data\n            - the data, \"x\" is already a tensor, but tensors don't have dimension limits. They can be multidimensional arrays\n            - we restrict the tensor size with the argument for out_features where in this notebook the out_features=1\n        - I don't understand the reasoning behind 128 + 12 for in_features.\n            -might be from the classifier line - 128, but where is the 12 coming from?\n3. RMSE is used to track error\n    \n4. Apply gradient descent to the learning rate! Moar efficiency for neural net!\n    - CosineAnnealingWarmRestarts is same as SGDR or \"Stochastic Gradient Descent with Restarts\"\n        - https://github.com/pytorch/pytorch/issues/20028\n        - https://towardsdatascience.com/https-medium-com-reina-wang-tw-stochastic-gradient-descent-with-restarts-5f511975163\n        \n5. \"Adam\" optimizer\n    - https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n        - \"Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure <b>to update network weights iterative based in training data</b>.\n        - It seems this optimizer is really good. Adam was applied to the logistic regression algorithm on the MNIST digit recognition and IMDB sentiment analysis datasets.\n\n6. Forward Pass - basically a forward run of the model. \n    - https://theneuralblog.com/forward-pass-backpropagation-example/\n    - https://deeplizard.com/learn/video/MasG7tZj-hw\n        - forward() method accepts a tensor as input, and then, returns a tensor as output\n        - it runs through the 4 layers\n    - he sets up loss function MSELoss, returns the model, loss and error\n        - If there are targets, return the loss\n        - If there are no more targets, return the output, 0 and empty collection","metadata":{}},{"cell_type":"code","source":"class PawpularModel(tez.Model):\n    def __init__(self):\n        super().__init__()\n\n        self.model = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained=True, in_chans=3)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(128 + 12, 1)\n        \n        self.step_scheduler_after = \"epoch\"\n\n    def monitor_metrics(self, outputs, targets):\n        outputs = outputs.cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        rmse = metrics.mean_squared_error(targets, outputs, squared=False)\n        return {\"rmse\": rmse}\n\n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n        return sch\n\n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=1e-4)\n        return opt\n\n    def forward(self, image, features, targets=None):\n\n        x = self.model(image)\n        x = self.dropout(x)\n        x = torch.cat([x, features], dim=1)\n        x = self.out(x)\n\n        if targets is not None:\n            loss = nn.MSELoss()(x, targets.view(-1, 1))\n            metrics = self.monitor_metrics(x, targets)\n            return x, loss, metrics\n        return x, 0, {}","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:39.451503Z","iopub.execute_input":"2021-11-13T17:08:39.451757Z","iopub.status.idle":"2021-11-13T17:08:39.463309Z","shell.execute_reply.started":"2021-11-13T17:08:39.45173Z","shell.execute_reply":"2021-11-13T17:08:39.462393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using Albumentations to change the photos\n\n1. In the training_aug and validation_aug, he sets up the params which he will pass into \"augmentations\" in PawpularDatasets Class\n    - Compose API in albumentations - https://albumentations.ai/docs/api_reference/core/composition/\n        - Using Compose, he inputs a list of transformations he wants on the images \n    - HueSaturationValue - randomly change the hues of the images\n    - RandomBrightnessContrast - randomly change contrast\n2. The validation set doesnt need any randomization. We are testing the model against test data\n    - Resize and Normalize I am guessing are used so maintain the image size to be standard for all images for better training/testing\n    - The values he put in for Normalize are the exact values in the albumentations documentation\n        - https://albumentations.ai/docs/api_reference/full_reference/#albumentations.augmentations.transforms.Normalize\n3. When the datasets class calls these augmentations, albumentations is called and the transformations are done on the images in the dataset\n    - Which then are passed into the model for training.","metadata":{}},{"cell_type":"code","source":"train_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.HueSaturationValue(\n            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n        ),\n        albumentations.RandomBrightnessContrast(\n            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n        ),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:40.813538Z","iopub.execute_input":"2021-11-13T17:08:40.814388Z","iopub.status.idle":"2021-11-13T17:08:40.822447Z","shell.execute_reply.started":"2021-11-13T17:08:40.814326Z","shell.execute_reply":"2021-11-13T17:08:40.821621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing the dataframes for training\n\n1. I don't need to have a path to give for read_csv since the train_10folds.csv is in my working directory.\n    - My question here is why is df_train 8920 rows and df_valid 992 rows. Shouldn't the ratio be 80/20?\n        - https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7\n        - https://miro.medium.com/max/875/1*Nv2NNALuokZEcV6hYEHdGA.png\n    - To answer my own question, the validation data is used from the training set to test model fit and then the \"gold standard\" will be the test set    \n    - Also how do we know the optimal kfold number to begin with? 5 and 10 sound arbitrary. Maybe the most accurate model lies in the range of folds.\n    \n2. Super fancy guy, he calls args class and then the fold number in args class.\n    - args.fold\n    - He sets aside fold number = 0 for his validation set\n    - the kfolds are numbered from 0-9 as we have 10 folds created. Any kfold can be chosen for validation set, doesn't have to be kfold=0. They're all the same size","metadata":{}},{"cell_type":"code","source":"# df = pd.read_csv(\"train_10folds.csv\")\n# df_train = df[df.kfold != args.fold].reset_index(drop=True)\n# df_valid = df[df.kfold == args.fold].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:42.234222Z","iopub.execute_input":"2021-11-13T17:08:42.234814Z","iopub.status.idle":"2021-11-13T17:08:42.23883Z","shell.execute_reply.started":"2021-11-13T17:08:42.234774Z","shell.execute_reply":"2021-11-13T17:08:42.238134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dense_features, train_img_paths, valid_img_paths\n\n1. Here, he is making a list for each of the variables which will be inputs into the \"PawpularDataset.init\" class\n    - dense_features is the list of columns in the dataset\n    - train_img_paths is the list of all image id names (the first column) in the training dataset\n    - valid_img_paths is the list of all image id names (the first column) in the validation dataset\n        - he uses f strings for both - https://realpython.com/python-f-strings/#python-f-strings-the-pesky-details\n            - f strings execute in runtime. So he can run a for loop with his string to generate list of Id values\n                 - looping using list comprehension - https://www.w3schools.com/python/python_lists_loop.asp","metadata":{}},{"cell_type":"code","source":"# dense_features = [\n#     'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n#     'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n# ]\n# train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n# valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:49.303741Z","iopub.execute_input":"2021-11-13T17:08:49.303999Z","iopub.status.idle":"2021-11-13T17:08:49.307803Z","shell.execute_reply.started":"2021-11-13T17:08:49.303971Z","shell.execute_reply":"2021-11-13T17:08:49.306991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using PawpularDataset class to generate tensors for training and validation \n1. The below cell returns class objects so my guess is that the output is the 3 tensors that were generated at the end of the PawpularDataset.\n    - we get the following instance \"<__main__.PawpularDataset at 0x7f9ec460d2d0>\"\n2. He is creating training and validation data using the PawpularDataset class created in previous cell  \n      - the \"image\", \"features\", \"targets\" variables are used in the PawpularModel class","metadata":{}},{"cell_type":"code","source":"# train_dataset = PawpularDataset(\n#     image_paths=train_img_paths,\n#     dense_features=df_train[dense_features].values,\n#     targets=df_train.Pawpularity.values,\n#     augmentations=train_aug,\n# )\n\n# valid_dataset = PawpularDataset(\n#     image_paths=valid_img_paths,\n#     dense_features=df_valid[dense_features].values,\n#     targets=df_valid.Pawpularity.values,\n#     augmentations=valid_aug,\n# )","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:08:55.536274Z","iopub.execute_input":"2021-11-13T17:08:55.536826Z","iopub.status.idle":"2021-11-13T17:08:55.540241Z","shell.execute_reply.started":"2021-11-13T17:08:55.536788Z","shell.execute_reply":"2021-11-13T17:08:55.539492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting the Model\n1. He runs the PawpularModel class now that we have all the variables\n2. EarlyStopping is used to stop the model early if there is a high accuracy model already found\n    - There was not much documentation on EarlyStopping. But I see Tez's Earlystopping class is similar that found in Keras\n        - Earlystopping is based on validation data rmse\n            - nice pics here - https://towardsdatascience.com/activate-early-stopping-in-boosting-algorithms-to-mitigate-overfitting-9c1b12cc6729\n        - https://theailearner.com/2019/07/15/keras-callbacks-earlystopping/\n        - Monitor - the arguments are like \"val_\" etc so that means similarly in tez it would be from the validation data rmse\n        - Model_path - uses f-string again. Within f string he calls args class, name will be \"model_f0.bin\"\n            - what does it do with this information? I don't see model_f0.bin anywhere as a path or something. Maybe when the model runs it will generate a .bin file?\n        - patience = 3 - this is the number of epochs the funtion will wait before stopping\n        - mode = \"min\" \n            - the model will stop when the quantity monitored reaches a minimum\n            - this from keras documentation but it makes sense here - https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n        - save_weights_only = True - this will save the weights of the best model which was stopped by EarlyStopping\n3. From which import is he calling .fit for model.fit()?    \n    - the tez.model\n        - https://github.com/abhishekkrthakur/tez/blob/main/tez/model/model.py\n            - here there is a .fit subclass, similar to that found in keras\n4. Model is saved as model_f0.bin\n5. I understand the model.fit arguments but I don't know the real documentation behind it. I think it is from the tez.Model which then goes to nn.model, but in the Tez github documentation, the model.fit part says it is similar to keras. So I'm going to assume that these params are similar to keras style model.fit.\n    - Batch size we can also choose to change - might affect speed of model training, probably he chose those batch sized from experience\n        - https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network\n    -fp16 is some float-16 param used with nvidia GPUs\n    - epochs - https://stackoverflow.com/questions/44907377/what-is-epoch-in-keras-models-model-fit","metadata":{}},{"cell_type":"code","source":"# model = PawpularModel()\n\n# es = EarlyStopping(\n#     monitor=\"valid_rmse\",\n#     model_path=f\"model_f{args.fold}.bin\",\n#     patience=3,\n#     mode=\"min\",\n#     save_weights_only=True,\n# )\n\n# model.fit(\n#     train_dataset,\n#     valid_dataset=valid_dataset,\n#     train_bs=args.batch_size,\n#     valid_bs=2*args.batch_size,\n#     device=\"cuda\",\n#     epochs=args.epochs,\n#     callbacks=[es],\n#     fp16=True,\n# )\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:09:01.104568Z","iopub.execute_input":"2021-11-13T17:09:01.104831Z","iopub.status.idle":"2021-11-13T17:09:01.109041Z","shell.execute_reply.started":"2021-11-13T17:09:01.104804Z","shell.execute_reply":"2021-11-13T17:09:01.108198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3. Inference\n\n### Similar to the previous step of training the data\n1. Create new class args which will be utilized by the albumentations and the final for loop for testing on the kfolds\n2. The same class PawpularDataset is used\n3. For PawpularModel class, there are differences. I will rename this class to PawpularModel1\n    - pretrained = False\n    - he adds different Linear transformations. \n        - 140 is 128+12 from before\n        - where and why does he use 64?\n    - what are in_chans=3?","metadata":{}},{"cell_type":"code","source":"class args1:\n    batch_size = 64\n    image_size = 512","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:09:02.096498Z","iopub.execute_input":"2021-11-13T17:09:02.097188Z","iopub.status.idle":"2021-11-13T17:09:02.101906Z","shell.execute_reply.started":"2021-11-13T17:09:02.09715Z","shell.execute_reply":"2021-11-13T17:09:02.101009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PawpularModel1 class\n1. This class is much shorter than the training class. \n2. The forward pass function shows the different layers\n    - uses dropoout to randomly zero out values based on 0.1 probability to reduce overfitting\n        - this is a value we can change to see how it affects the model\n    - he uses torch.cat to add features\n        - features is the torch tensor outputted from the PawpularDataset class from earlier\n    - he applies the first nn.Linear transform\n        - https://ashwinhprasad.medium.com/pytorch-for-deep-learning-nn-linear-and-nn-relu-explained-77f3e1007dbb\n        - He might be using the nn.Linear method to add random weights and biases for that layer of the NN\n    - torch.relu activation function and then another nn.Linear transform for another random weights/biases to apply to tensor\n    - returns the output\n","metadata":{}},{"cell_type":"code","source":"class PawpularDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:09:03.996611Z","iopub.execute_input":"2021-11-13T17:09:03.996884Z","iopub.status.idle":"2021-11-13T17:09:04.006765Z","shell.execute_reply.started":"2021-11-13T17:09:03.996855Z","shell.execute_reply":"2021-11-13T17:09:04.006029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularModel(tez.Model):\n    def __init__(self, model_name):\n        super().__init__()\n\n        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(140, 64)\n        self.dense2 = nn.Linear(64, 1)\n\n    def forward(self, image, features, targets=None):\n\n        x = self.model(image)\n        x = self.dropout(x)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        x = torch.relu(x)\n        x = self.dense2(x)\n        return x, 0, {}","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:09:04.511621Z","iopub.execute_input":"2021-11-13T17:09:04.51188Z","iopub.status.idle":"2021-11-13T17:09:04.51948Z","shell.execute_reply.started":"2021-11-13T17:09:04.511854Z","shell.execute_reply":"2021-11-13T17:09:04.518505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### test_aug - augmenting the test images\n1. He uses the same albumentations standards as used in the training section for validation ","metadata":{}},{"cell_type":"code","source":"test_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:09:05.506683Z","iopub.execute_input":"2021-11-13T17:09:05.5072Z","iopub.status.idle":"2021-11-13T17:09:05.512442Z","shell.execute_reply.started":"2021-11-13T17:09:05.507086Z","shell.execute_reply":"2021-11-13T17:09:05.511554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Prediction and General Steps\n1. Create empty list which will be used to generate the final submission.csv file\n2. Because he used 10 kfolds, he will use a for loop with range 10. We can change the range if we change the number of kfolds.\n3. He loads the pretrained timm model. Here i will use the name PawpularModel1 to indicate the shorter class made during inference section\n4. He creates the variables for test data path, image path, and features list\n5. Similar to the training validation dataset, he runs PawpularDataset class to create the augmented/normalized dataset to run the model on with test data\n    - the targets = np.ones(len(test_img_paths)) he creates an array filled with ones\n        - why?\n6. test_predictions\n    - I understand he is calling predict method for the model\n        - why is batch size 2x the args?\n            - seems batch size is related to memory consumption and model performance\n            - https://datascience.stackexchange.com/questions/12532/does-batch-size-in-keras-have-any-effects-in-results-quality\n            - seems 2x batch size is used to help the gradient\n            - also batch size probably related to the GPU power\n7. model.predict - from tez - within model.py there is predict function which is called\n8. He appends each test prediction to the list super_final_predictions\n    - final_test_predictions.extend(preds.ravel().tolist())\n        - returns a contiguous flattened array which he adds to the finah predictions\n            - https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\n9. np.mean(np.column_stack\n    - he averages the predictions over each fold\n        - then what would the output be? there would be 10 dictionaries with lists nested?\n10. set Pawpularity column to predicted values, add Id column and create submission.csv file.        ","metadata":{}},{"cell_type":"code","source":"super_final_predictions = []\n\nfor fold_ in range(10):\n    model = PawpularModel(model_name=\"tf_efficientnet_b0_ns\")\n    model.load(f\"../input/pawpular-models/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n    df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n    test_img_paths = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n\n    dense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n    ]\n\n    test_dataset = PawpularDataset(\n        image_paths=test_img_paths,\n        dense_features=df_test[dense_features].values,\n        targets=np.ones(len(test_img_paths)),\n        augmentations=test_aug,\n    )\n    test_predictions = model.predict(test_dataset, batch_size=2*args1.batch_size, n_jobs=-1)\n\n    final_test_predictions = []\n    for preds in tqdm(test_predictions):\n        final_test_predictions.extend(preds.ravel().tolist())\n    \n    super_final_predictions.append(final_test_predictions)\n\nsuper_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\ndf_test[\"Pawpularity\"] = super_final_predictions\ndf_test = df_test[[\"Id\", \"Pawpularity\"]]\ndf_test.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T17:09:08.861882Z","iopub.execute_input":"2021-11-13T17:09:08.862422Z","iopub.status.idle":"2021-11-13T17:09:27.386344Z","shell.execute_reply.started":"2021-11-13T17:09:08.862384Z","shell.execute_reply":"2021-11-13T17:09:27.385407Z"},"trusted":true},"execution_count":null,"outputs":[]}]}