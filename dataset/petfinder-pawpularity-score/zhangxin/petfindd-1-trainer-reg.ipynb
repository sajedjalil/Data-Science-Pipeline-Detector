{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Data","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nfrom timm import create_model\nfrom IPython.display import display\nimport gc\nimport os\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\n\nimport kornia as K\nfrom kornia import image_to_tensor, tensor_to_image\nimport kornia.augmentation as aug\n\nfrom transformers import get_cosine_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:21:56.717208Z","iopub.execute_input":"2021-12-26T05:21:56.717713Z","iopub.status.idle":"2021-12-26T05:22:00.179629Z","shell.execute_reply.started":"2021-12-26T05:21:56.717588Z","shell.execute_reply":"2021-12-26T05:22:00.176784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 402\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:22:00.181778Z","iopub.execute_input":"2021-12-26T05:22:00.183267Z","iopub.status.idle":"2021-12-26T05:22:00.19281Z","shell.execute_reply.started":"2021-12-26T05:22:00.183169Z","shell.execute_reply":"2021-12-26T05:22:00.191417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1 Data","metadata":{}},{"cell_type":"markdown","source":"norm_score = [0.01, 1.0]\n\nthe output will be in (0.005, 1.005)\n\nsigmoid(y_hat) + 0.005","metadata":{"execution":{"iopub.status.busy":"2021-12-26T04:43:17.744214Z","iopub.execute_input":"2021-12-26T04:43:17.744527Z","iopub.status.idle":"2021-12-26T04:43:17.75165Z","shell.execute_reply.started":"2021-12-26T04:43:17.744496Z","shell.execute_reply":"2021-12-26T04:43:17.750667Z"}}},{"cell_type":"code","source":"class PetData(Dataset):\n    def __init__(self, df, transform, is_test=False):\n        super(PetData, self).__init__()\n        self.binary_features = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n        self.df = df\n        self.transform = transform\n        self.is_test = is_test\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = row[\"path\"]\n        img = Image.open(image_path).convert(\"RGB\")\n        data = self.transform(img)\n        binary_features = torch.tensor(row[self.binary_features], dtype=torch.long)\n        if self.is_test:\n            return data, binary_features\n        else:\n            label = torch.tensor(row[\"norm_score\"], dtype=torch.float) # [0.01, 1.0]\n            return data, label, binary_features","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:22:00.194993Z","iopub.execute_input":"2021-12-26T05:22:00.195819Z","iopub.status.idle":"2021-12-26T05:22:00.207333Z","shell.execute_reply.started":"2021-12-26T05:22:00.195742Z","shell.execute_reply":"2021-12-26T05:22:00.206154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Data:\n    def __init__(self, batch_size=16, img_size=224, n_split=10):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        \n        self.train_val_df = pd.read_csv(\"../input/petfinder-data-with-10-folds/train_val_df.csv\")\n        self.test_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n        \n        image_mean = [0.38753143, 0.36847523, 0.27735737]\n        image_std = [0.25998375, 0.23844026, 0.2313706]\n        normTransform = T.Normalize(image_mean, image_std)\n        self.trainTransform = T.Compose([\n#             T.RandomResizedCrop((img_size, img_size), (0.8, 1.0)),\n            T.Resize((img_size+32, img_size+32)),\n            T.CenterCrop((img_size, img_size)),\n#             T.Resize((img_size, img_size)),\n            T.RandomRotation(30),\n            T.RandomHorizontalFlip(),\n            T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n            T.ToTensor(),\n            normTransform,\n            T.RandomErasing(scale=(0.02, 0.13)),\n        ])\n        self.validTransform = T.Compose([\n            T.Resize((img_size, img_size)),\n            T.ToTensor(),\n            normTransform\n        ])        \n        self.num_workers = 2\n        \n    def train_dataloader(self, fold):\n        train_df = self.train_val_df.query(f'fold != {fold}')\n        train_ds = PetData(train_df, self.trainTransform, is_test=False)\n        train_dl = DataLoader(train_ds, batch_size=self.batch_size, shuffle=True, pin_memory=True, num_workers=self.num_workers)\n        return train_dl\n        \n    def val_dataloader(self, fold):\n        val_df = self.train_val_df.query(f'fold == {fold}')\n        val_ds = PetData(val_df, self.validTransform, is_test=False)\n        val_dl = DataLoader(val_ds, batch_size=self.batch_size*2, shuffle=False, pin_memory=True, num_workers=self.num_workers)\n        return val_dl\n        \n    def test_dataloader(self):\n        test_ds = PetData(self.test_df, self.validTransform, is_test=True)\n        test_dl = DataLoader(test_ds, batch_size=self.batch_size*2, shuffle=False, pin_memory=True, num_workers=self.num_workers)\n        return test_dl","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:22:00.212049Z","iopub.execute_input":"2021-12-26T05:22:00.212937Z","iopub.status.idle":"2021-12-26T05:22:00.228942Z","shell.execute_reply.started":"2021-12-26T05:22:00.212886Z","shell.execute_reply":"2021-12-26T05:22:00.227753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, backbone_name, binary_features=['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']):\n        super(Model, self).__init__()\n        self.backbone = create_model(model_name, pretrained=True, num_classes=64)\n        self.feat_embeddings = nn.ModuleList(nn.Embedding(2, 1) for _ in range(len(binary_features)))\n        self.fc = nn.Linear(64 + 1*len(binary_features), 1, bias=True)\n    \n    def forward(self, x, feats):\n        x = self.backbone(x)\n#         return torch.sigmoid(x) + 0.005 # (0.005, 1.005)\n        feats_embedding_list = []\n        for idx in range(len(self.feat_embeddings)):\n            embedding_model = self.feat_embeddings[idx]\n            embedding_input = feats[:, idx]\n            feats_embedding_list.append(embedding_model(embedding_input))\n        feats_embedding = torch.cat(feats_embedding_list, dim=-1)\n        return torch.sigmoid(self.fc(torch.cat([x, feats_embedding], dim=-1))) + 0.005 # the output will be (0.005, 1.005) has the scope of [0.01, 1.].\n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:22:00.230734Z","iopub.execute_input":"2021-12-26T05:22:00.23135Z","iopub.status.idle":"2021-12-26T05:22:00.245609Z","shell.execute_reply.started":"2021-12-26T05:22:00.231302Z","shell.execute_reply":"2021-12-26T05:22:00.244445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3 Train","metadata":{}},{"cell_type":"code","source":"from torch.cuda.amp import autocast as autocast","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:22:00.248651Z","iopub.execute_input":"2021-12-26T05:22:00.249521Z","iopub.status.idle":"2021-12-26T05:22:00.260953Z","shell.execute_reply.started":"2021-12-26T05:22:00.249475Z","shell.execute_reply":"2021-12-26T05:22:00.25959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, num_epochs, lr, wd):\n        self.loss_func = nn.MSELoss()\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.num_epochs = num_epochs\n        self.lr = lr\n        self.wd = wd\n        self.min_loss = 1e3\n        \n    def get_fold_data(self, data, fold):\n        train_dl = data.train_dataloader(fold=fold)\n        val_dl = data.val_dataloader(fold=fold)\n        return train_dl, val_dl\n    \n    def train_fold(self, data, fold, model_name='swin_large_patch4_window7_224'):\n        train_dl, val_dl = self.get_fold_data(data, fold)\n        model = Model(model_name)\n        model.to(self.device)\n        no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n        optimizer_grouped_parameters = [\n            {\n                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n                \"weight_decay\": self.wd,\n            },\n            {\n                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.0,\n            },\n        ]\n        optimizer = optim.AdamW(optimizer_grouped_parameters, lr=self.lr)\n        num_training_steps = self.num_epochs * len(train_dl)\n        num_warmup_steps = int(0.1 * num_training_steps)\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n        train_loss_list = [None] * num_training_steps\n        for epoch in range(self.num_epochs):\n            tbar = tqdm(train_dl)\n            epoch_loss = 0.\n            train_step = 0\n            model.train()\n            for batch_idx, batch in enumerate(tbar):\n                x, y, feats = batch\n                x, y, feats = x.to(self.device), y.to(self.device), feats.to(self.device)\n                with autocast():    \n                    y_hat = model(x, feats).squeeze()\n                    loss = self.loss_func(y_hat, y)\n                    loss = torch.sqrt(loss)\n                \n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                \n                train_loss_list[train_step] = loss.detach().cpu().numpy() # petfinder_rmse(y_hat, y)\n                epoch_loss += train_loss_list[train_step]\n                train_step += 1\n                \n                tbar.set_description_str(\"[Train Epoch %d/%d]\"% (epoch+1, self.num_epochs))\n                tbar.set_postfix_str(\"Loss: %.5f, lr: %.6f\"% (100 * epoch_loss / train_step, scheduler.get_last_lr()[0]))\n                \n                del loss, x, y, y_hat, feats\n                gc.collect()\n                \n            val_loss = self.eval_step(val_dl, model, epoch)\n            if val_loss <= self.min_loss:\n                self.min_loss = val_loss\n                torch.save(model.state_dict(), \"model_fold%d.pth\"%fold)\n            \n        del train_dl, val_dl, model, optimizer, scheduler\n        gc.collect()\n        return train_loss_list\n    \n    def eval_step(self, val_dl, model, epoch):\n        tbar = tqdm(val_dl)\n        epoch_loss = 0.\n        eval_step = 0\n        model.eval()\n        for batch_idx, batch in enumerate(tbar):\n            x, y, feats = batch\n            x, y, feats = x.to(self.device), y.to(self.device), feats.to(self.device)\n            with torch.no_grad():\n                y_hat = model(x, feats).squeeze()\n            loss = self.loss_func(y_hat, y)\n            epoch_loss += torch.sqrt(loss).detach().cpu().numpy()\n            eval_step += 1\n            \n            tbar.set_description_str(\"[Val Epoch %d]\"% (epoch+1))\n            tbar.set_postfix_str(\"Loss: %.5f\"% (100 * epoch_loss / eval_step))\n            \n            del x, y, y_hat\n            gc.collect()\n        \n        return epoch_loss / eval_step","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:22:00.263033Z","iopub.execute_input":"2021-12-26T05:22:00.263723Z","iopub.status.idle":"2021-12-26T05:22:00.291371Z","shell.execute_reply.started":"2021-12-26T05:22:00.26367Z","shell.execute_reply":"2021-12-26T05:22:00.290063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nmodel_names = [\n    'swin_large_patch4_window7_224',\n    'swin_large_patch4_window7_224_in22k',\n    'swin_large_patch4_window12_384',\n    'swin_large_patch4_window12_384_in22k'\n]\n```","metadata":{}},{"cell_type":"code","source":"num_epochs, lr, wd = 5, 2e-5, 5e-4\nn_split = 10\nimg_size = 224 # 384\nwith_22k = False\n\nif not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n    os.makedirs('/root/.cache/torch/hub/checkpoints/')\nif img_size == 224:\n    if with_22k:\n        model_name = 'swin_large_patch4_window7_224_in22k'\n        !cp ../input/swin-large-models/swin_large_patch4_window7_224_22k.pth /root/.cache/torch/hub/checkpoints/\n    else:\n        model_name = 'swin_large_patch4_window7_224'\n        !cp ../input/swin-large-models/swin_large_patch4_window7_224_22kto1k.pth /root/.cache/torch/hub/checkpoints/\n    batch_size = 32\nelse:\n    if with_22k:\n        model_name = 'swin_large_patch4_window12_384_in22k'\n        !cp ../input/swin-large-models/swin_large_patch4_window12_384_22k.pth /root/.cache/torch/hub/checkpoints/\n    else:\n        model_name = 'swin_large_patch4_window12_384'\n        !cp ../input/swin-large-models/swin_large_patch4_window12_384_22kto1k.pth /root/.cache/torch/hub/checkpoints/\n    batch_size = 16\n    \ndata = Data(batch_size=batch_size, img_size=img_size, n_split=n_split)\ntrainer = Trainer(num_epochs, lr, wd)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:22:00.294893Z","iopub.execute_input":"2021-12-26T05:22:00.295279Z","iopub.status.idle":"2021-12-26T05:22:02.898276Z","shell.execute_reply.started":"2021-12-26T05:22:00.295204Z","shell.execute_reply":"2021-12-26T05:22:02.897029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(n_split):\n    print(\"---------------------------fold-%d-------------------------------\"%fold)\n    train_loss_list = trainer.train_fold(data, fold, model_name=model_name)\n    plt.plot(train_loss_list)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:22:02.900163Z","iopub.execute_input":"2021-12-26T05:22:02.900659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}