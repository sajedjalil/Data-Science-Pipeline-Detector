{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://cdn-images-1.medium.com/max/800/1*jcZLpgh3gppeFFgcpFSP0w.jpeg)\n\n# End to End Pytorch DNN Walkthrough :\n\nThis notebook holds end to end Pytorch DNN walkthrough covering all the procedures which are needed to do for a competition.","metadata":{"id":"FNk7I2L7v9E_","execution":{"iopub.status.busy":"2021-11-02T04:11:14.565967Z","iopub.execute_input":"2021-11-02T04:11:14.566205Z","iopub.status.idle":"2021-11-02T04:11:15.429716Z","shell.execute_reply.started":"2021-11-02T04:11:14.566135Z","shell.execute_reply":"2021-11-02T04:11:15.428986Z"}}},{"cell_type":"markdown","source":"# Content : \n\n## 1. Primary Visualization.\n## 2. Understanding the solution.\n## 3. Creating Dataset.\n## 4. Creating Deep Neural Net.\n## 5. Model Training.\n## 6. Saving best Model.\n## 7. Testing on testing data.\n## 8. Creating submission.","metadata":{}},{"cell_type":"markdown","source":"# Importing supporting libraries : \n\nAt first we need to import basic libraries that'll help us to find the visualize the data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom glob import glob\nimport os\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:17:51.258339Z","iopub.execute_input":"2021-11-17T05:17:51.258817Z","iopub.status.idle":"2021-11-17T05:17:52.262912Z","shell.execute_reply.started":"2021-11-17T05:17:51.258722Z","shell.execute_reply":"2021-11-17T05:17:52.262262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we have to load the metadata and see whether that can be used for attributes or not.","metadata":{}},{"cell_type":"code","source":"train_metadata = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntrain_metadata.head()","metadata":{"id":"nA4pOdcBxHRk","outputId":"9097c389-b6d8-4c4b-e943-3abbdf1fdfce","execution":{"iopub.status.busy":"2021-11-17T05:17:52.264775Z","iopub.execute_input":"2021-11-17T05:17:52.26529Z","iopub.status.idle":"2021-11-17T05:17:52.328192Z","shell.execute_reply.started":"2021-11-17T05:17:52.265243Z","shell.execute_reply":"2021-11-17T05:17:52.327381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_metadata = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntest_metadata.head()","metadata":{"id":"Xe0Rvpvwy4VA","outputId":"478feff8-6378-4228-f33a-125c0aededc3","execution":{"iopub.status.busy":"2021-11-17T05:17:52.329363Z","iopub.execute_input":"2021-11-17T05:17:52.329606Z","iopub.status.idle":"2021-11-17T05:17:52.350093Z","shell.execute_reply.started":"2021-11-17T05:17:52.329576Z","shell.execute_reply":"2021-11-17T05:17:52.349256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(folder_name, num_images = 9, shape = (3, 3)):\n  row = shape[0]\n  col = shape[1]\n  assert num_images == row*col,\"Total image number is not matching with the size...\"\n  fig, ax = plt.subplots(row, col, figsize = (20, 6))\n  plt.suptitle(f\"Images : {folder_name.split('/')[-2]}\")\n  for index in range(num_images):\n    plt.subplot(row, col, index + 1)\n    img = load_image(glob(f\"{folder_name}/*jpg\")[index])\n    plt.imshow(img)\n  plt.show()\ndef load_image(source):\n  img = cv2.imread(source)\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n  return img\n\nshow_images('../input/petfinder-pawpularity-score/train/')\nshow_images('../input/petfinder-pawpularity-score/test/', 4, (2, 2) )","metadata":{"id":"9zhA5ZNNzgLY","outputId":"6d6a915f-9cc6-4b5f-978a-67795a5afdc0","execution":{"iopub.status.busy":"2021-11-17T05:17:52.352036Z","iopub.execute_input":"2021-11-17T05:17:52.352286Z","iopub.status.idle":"2021-11-17T05:17:55.414956Z","shell.execute_reply.started":"2021-11-17T05:17:52.352257Z","shell.execute_reply":"2021-11-17T05:17:55.411371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = train_metadata.iloc[:,1:-1]\ntrain_features.head()","metadata":{"id":"YJ2HiaIC_ae5","outputId":"09f0df09-560e-4415-faa9-a344e3a781a5","execution":{"iopub.status.busy":"2021-11-17T05:17:55.416773Z","iopub.execute_input":"2021-11-17T05:17:55.417354Z","iopub.status.idle":"2021-11-17T05:17:55.436413Z","shell.execute_reply.started":"2021-11-17T05:17:55.417291Z","shell.execute_reply":"2021-11-17T05:17:55.435706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = train_metadata['Pawpularity']","metadata":{"id":"LXFo4o4RtKCO","execution":{"iopub.status.busy":"2021-11-17T05:17:55.43756Z","iopub.execute_input":"2021-11-17T05:17:55.438292Z","iopub.status.idle":"2021-11-17T05:17:55.450055Z","shell.execute_reply.started":"2021-11-17T05:17:55.438258Z","shell.execute_reply":"2021-11-17T05:17:55.448994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now checking through the **Pawpularity score**  if the data holds any outliers or not.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(Y)","metadata":{"id":"xRNkeJdNwjbA","outputId":"0690ab91-690e-440f-a50e-f6a5eddbcea3","execution":{"iopub.status.busy":"2021-11-17T05:17:55.451443Z","iopub.execute_input":"2021-11-17T05:17:55.4522Z","iopub.status.idle":"2021-11-17T05:17:55.619028Z","shell.execute_reply.started":"2021-11-17T05:17:55.452164Z","shell.execute_reply":"2021-11-17T05:17:55.617864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features.describe()","metadata":{"id":"Iz9aK1I7y12v","outputId":"d92834d8-722b-4b62-fcf3-d27a9425ba63","execution":{"iopub.status.busy":"2021-11-17T05:17:55.621153Z","iopub.execute_input":"2021-11-17T05:17:55.624257Z","iopub.status.idle":"2021-11-17T05:17:55.680553Z","shell.execute_reply.started":"2021-11-17T05:17:55.624193Z","shell.execute_reply":"2021-11-17T05:17:55.679478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features.shape","metadata":{"id":"E9eBu-wM8nFM","outputId":"776c3d11-d85a-47ec-d878-2ea71c36b8e8","execution":{"iopub.status.busy":"2021-11-17T05:17:55.682046Z","iopub.execute_input":"2021-11-17T05:17:55.682454Z","iopub.status.idle":"2021-11-17T05:17:55.691142Z","shell.execute_reply.started":"2021-11-17T05:17:55.682405Z","shell.execute_reply":"2021-11-17T05:17:55.690383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in train_features.columns:\n  print(f\"{column} : \\n{train_features[column].value_counts()}\")","metadata":{"id":"t0tFvm6I83xT","outputId":"e88931ab-4b39-442e-9152-a6f8423f4b6d","execution":{"iopub.status.busy":"2021-11-17T05:17:55.694915Z","iopub.execute_input":"2021-11-17T05:17:55.695732Z","iopub.status.idle":"2021-11-17T05:17:55.716297Z","shell.execute_reply.started":"2021-11-17T05:17:55.695685Z","shell.execute_reply":"2021-11-17T05:17:55.715169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After performing basic EDA on the data now it is time to create the Pytorch dataset that'll generate the dataloader to make batches of data while training.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom torchvision.transforms import transforms\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport math\nimport time\nfrom sklearn.metrics import r2_score\nfrom termcolor import cprint\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"tI5_lYI8A_52","execution":{"iopub.status.busy":"2021-11-17T05:17:55.717594Z","iopub.execute_input":"2021-11-17T05:17:55.718277Z","iopub.status.idle":"2021-11-17T05:17:57.281614Z","shell.execute_reply.started":"2021-11-17T05:17:55.71823Z","shell.execute_reply":"2021-11-17T05:17:57.280743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As in some cases the images are horizontally different we are using the **horizontal flip augmentation** so that the data can be more general.","metadata":{}},{"cell_type":"code","source":"class PawDataset(Dataset):\n  def __init__(self, data_source, metadata, H = 128, W = 128, test_data = False):\n    super(PawDataset, self).__init__()\n    self.data_source = data_source\n    self.metadata = metadata\n    self.H = H\n    self.W = W\n    self.test_data = test_data\n    self.augment = self.transform()\n\n  def transform(self):\n    augmentation = transforms.Compose(\n        [\n            transforms.RandomHorizontalFlip(),\n        ]\n    )\n    return augmentation\n\n  def __len__(self):\n    return len(self.metadata)\n\n  def __getitem__(self, index):\n    # image_link\n    source = self.metadata['Id'][index]\n    source = os.path.join(f\"{self.data_source}{source}.jpg\")\n    # loading the image and tranforming it into a torh tensor\n    image = self.load_image(source)\n    # loading metadata\n    metadata = self.metadata.iloc[index, 1:13].astype('float32').to_numpy().reshape(1,-1)\n    if self.test_data == False:\n        # target output\n        image = self.augment(image)\n        image = transforms.ToTensor()(image)\n        target = self.metadata['Pawpularity'][index] / 100.0\n        return (image, metadata, target)\n    else:\n        image = transforms.ToTensor()(image)\n        return (image, metadata)\n  def load_image(self, source):\n    img = cv2.imread(source)\n    img = cv2.resize(img, (self.H, self.W))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = Image.fromarray(img)\n    return img","metadata":{"id":"uD2H5KlX_rIG","execution":{"iopub.status.busy":"2021-11-17T05:17:57.282933Z","iopub.execute_input":"2021-11-17T05:17:57.283185Z","iopub.status.idle":"2021-11-17T05:17:57.296319Z","shell.execute_reply.started":"2021-11-17T05:17:57.283154Z","shell.execute_reply":"2021-11-17T05:17:57.29549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Batch size is taken 64 , so that it can be more generalized as well as more specific towards the training data.","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64","metadata":{"id":"oYzuMDOkRNzZ","execution":{"iopub.status.busy":"2021-11-17T05:17:57.297605Z","iopub.execute_input":"2021-11-17T05:17:57.29785Z","iopub.status.idle":"2021-11-17T05:17:57.310688Z","shell.execute_reply.started":"2021-11-17T05:17:57.297814Z","shell.execute_reply":"2021-11-17T05:17:57.309721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_ds = PawDataset('../input/petfinder-pawpularity-score/train/', train_metadata)\nTrain_dl = DataLoader(Train_ds, batch_size = BATCH_SIZE, shuffle = True)\ntrain_size = int(0.8 * Train_ds.__len__())\nval_size = Train_ds.__len__() - train_size\ntrain_ds , val_ds = torch.utils.data.random_split(Train_ds, [train_size, val_size ])\ntrain_dl = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True)\nval_dl = DataLoader(val_ds, batch_size = BATCH_SIZE, shuffle = True)\ntest_ds = PawDataset('../input/petfinder-pawpularity-score/test/', test_metadata, test_data = True)\ntest_dl = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False)\nfor patch, metadata, target in train_dl:\n  print(patch.shape, metadata.shape, target.shape)\n  break\nfor patch, metadata, target in val_dl:\n  print(patch.shape, metadata.shape, target.shape)\n  break\nfor patch, target in test_dl:\n  print(patch.shape, target.shape)\n  break","metadata":{"id":"JQwMM1ZME12_","outputId":"6c116b91-7147-4f52-9c33-471acd788fb6","execution":{"iopub.status.busy":"2021-11-17T05:17:57.311768Z","iopub.execute_input":"2021-11-17T05:17:57.312378Z","iopub.status.idle":"2021-11-17T05:17:59.918646Z","shell.execute_reply.started":"2021-11-17T05:17:57.312329Z","shell.execute_reply":"2021-11-17T05:17:59.917576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now , we can see that the dataloaders are created and it is actually creating a batch of data.","metadata":{}},{"cell_type":"markdown","source":"Now, it's time to generate the Model class. This is the general purpose DNN generation process, and followed by every single researcher.","metadata":{}},{"cell_type":"markdown","source":"You can find the model graph [here](https://github.com/sagnik1511/Deep-Learning-Competitions/blob/main/Kaggle/Petfinder%20Pawpularity/assets/petfinder_model_graph.png).","metadata":{}},{"cell_type":"code","source":"class cnn(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = 0):\n    super(cnn, self).__init__()\n    self.cnn = nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n        nn.ReLU(),\n        nn.BatchNorm2d(out_channels, momentum = 0.95)\n    )\n  def forward(self, x):\n    return self.cnn(x)\n\nclass Network(nn.Module):\n  def __init__(self):\n    super(Network, self).__init__()\n    self.fet_ext = nn.Sequential(\n        cnn(3,4),\n        cnn(4, 64),   # 128 -> 126\n        nn.MaxPool2d(2), # 126 -> 63\n        cnn(64, 32),   # 63 -> 61\n        nn.MaxPool2d(2),  # 61 -> 30\n        cnn(32, 16),  # 30 -> 28\n        nn.MaxPool2d(2),\n        nn.Dropout(0.15),\n        nn.Flatten(), # 14*14*16\n    )\n    self.fc1 = nn.Sequential(\n        nn.Linear(12, 64),\n    )\n    self.fc2 = nn.Sequential(\n        nn.Linear(14*14*16, 1024),\n        nn.Linear(1024, 64),\n    )\n    self.fc3 = nn.Sequential(\n        nn.Linear(128, 1),\n    )\n\n  def forward(self, im_patch, mt_patch):\n      mt_patch = mt_patch.squeeze(dim = 2)\n      mt_patch = mt_patch.squeeze(dim = 1)\n      cnn_op = self.fet_ext(im_patch)\n      fc1_op = self.fc1(mt_patch)\n      fc2_op = self.fc2(cnn_op)\n      linear_op = torch.cat([fc1_op, fc2_op], axis = 1)\n      output = self.fc3(linear_op)\n      return output","metadata":{"id":"U34fwrbmtSRs","outputId":"e4f3d873-7c9a-4053-fae0-3c342a032b42","execution":{"iopub.status.busy":"2021-11-02T04:11:22.427421Z","iopub.execute_input":"2021-11-02T04:11:22.427919Z","iopub.status.idle":"2021-11-02T04:11:22.452655Z","shell.execute_reply.started":"2021-11-02T04:11:22.42787Z","shell.execute_reply":"2021-11-02T04:11:22.451976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the training process can be slow using cpu , we are going to process the training inside the **GPU** itself.","metadata":{}},{"cell_type":"code","source":"model = Network()\nmodel = model.cuda()\nmodel","metadata":{"id":"F8qxoefn92Yo","execution":{"iopub.status.busy":"2021-11-02T04:11:22.454726Z","iopub.execute_input":"2021-11-02T04:11:22.454964Z","iopub.status.idle":"2021-11-02T04:11:25.283375Z","shell.execute_reply.started":"2021-11-02T04:11:22.454935Z","shell.execute_reply":"2021-11-02T04:11:25.282625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n  print(f\"{name} | {param.shape} | {param.dtype}\")","metadata":{"id":"xn7IKOj298zA","outputId":"42d9779a-d941-430e-e737-87c8a2518417","execution":{"iopub.status.busy":"2021-11-02T04:11:25.284604Z","iopub.execute_input":"2021-11-02T04:11:25.284947Z","iopub.status.idle":"2021-11-02T04:11:25.294073Z","shell.execute_reply.started":"2021-11-02T04:11:25.284908Z","shell.execute_reply":"2021-11-02T04:11:25.293318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking basic hyerparameters (This has been taken after long nmber of experiments).","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10\ncriterion = nn.MSELoss()\noptm = optim.Adam(model.parameters(), lr = 1e-4)","metadata":{"id":"8c_-2q5rlhl1","execution":{"iopub.status.busy":"2021-11-02T04:11:25.295422Z","iopub.execute_input":"2021-11-02T04:11:25.295838Z","iopub.status.idle":"2021-11-02T04:11:25.301901Z","shell.execute_reply.started":"2021-11-02T04:11:25.2958Z","shell.execute_reply":"2021-11-02T04:11:25.301144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, it's the most important process, we have to train the model, so that it can be well fitted as well as more generalized but overfitted.","metadata":{}},{"cell_type":"code","source":"train_step_loss, val_step_loss = [], []\ntrain_loss, val_loss = [], []\nval_best_loss = np.inf\nfor epoch in range(EPOCHS):\n  start_time = time.time()\n  print(f\"Epoch {epoch + 1} : \")\n  epoch_loss = 0.0\n  model.train()\n  for index, (patch, metadata, target) in enumerate(train_dl):\n    optm.zero_grad()\n    patch = patch.float().cuda()\n    metadata  = metadata.float().cuda()\n    target = target.float().cuda()\n    op = model(patch, metadata)\n    loss = criterion(op, target)\n    epoch_loss += loss.item() * patch.shape[0]\n    train_step_loss.append(loss.item())\n    if index % 10 == 9:\n      print(f\"step {index + 1} Loss: {'%.4f'%(loss.item())}\")\n    loss.backward()\n    optm.step()\n  epoch_loss /= train_size\n  print(f\"training data --> loss : {'%.4f'%(epoch_loss)}\")\n  train_loss.append(epoch_loss)\n  model.eval()\n  val_ep_loss = 0.0\n  with torch.no_grad():\n      for index, (patch, metadata, target) in enumerate(val_dl):\n          patch = patch.float().cuda()\n          metadata  = metadata.float().cuda()\n          target = target.float().cuda()\n          op = model(patch, metadata)\n          loss = criterion(op, target)\n          val_step_loss.append(loss.item())\n          val_ep_loss += loss.item() * patch.shape[0]\n  val_ep_loss /= val_size\n  print(f\"validation data --> loss : {'%.4f'%(val_ep_loss)}\")\n  val_loss.append(val_ep_loss)\n  if val_ep_loss < val_best_loss :\n    val_best_loss = val_ep_loss\n    cprint(\"Success...Model Updated...\", 'green')\n    torch.save(model, 'best_model.pth')\n  else:\n    cprint(\"Failed... Model haven't uploaded...\", 'red')\n  elapsed_time = time.time() - start_time\n  print(f\"Elapsed time : {'%.2f'%(elapsed_time)} seconds...\\n\")\ncprint(\"Training completed...\", 'blue')","metadata":{"id":"Yz35Gbki9znP","outputId":"d040be75-9e6a-4cc9-891a-e95879d9afb6","execution":{"iopub.status.busy":"2021-11-02T04:11:25.303499Z","iopub.execute_input":"2021-11-02T04:11:25.303949Z","iopub.status.idle":"2021-11-02T04:29:05.786724Z","shell.execute_reply.started":"2021-11-02T04:11:25.303914Z","shell.execute_reply":"2021-11-02T04:29:05.785974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the last saved model can have too much varinace with the validation data, we are going to use the best saved model so far.","metadata":{}},{"cell_type":"code","source":"best_model = torch.load('./best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T04:29:05.788053Z","iopub.execute_input":"2021-11-02T04:29:05.788292Z","iopub.status.idle":"2021-11-02T04:29:05.806357Z","shell.execute_reply.started":"2021-11-02T04:29:05.788259Z","shell.execute_reply":"2021-11-02T04:29:05.805684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = best_model.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T04:29:05.808708Z","iopub.execute_input":"2021-11-02T04:29:05.809148Z","iopub.status.idle":"2021-11-02T04:29:05.813526Z","shell.execute_reply.started":"2021-11-02T04:29:05.809109Z","shell.execute_reply":"2021-11-02T04:29:05.812745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, the model is testing on the output data and one can see the data is getting out is in form of tensors, so we have to process that to fit inside the dataframe.","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    for index, (patch, metadata) in enumerate(test_dl):\n        patch = patch.float().cuda()\n        metadata  = metadata.float().cuda()\n        op = best_model(patch, metadata)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T04:29:05.815082Z","iopub.execute_input":"2021-11-02T04:29:05.815344Z","iopub.status.idle":"2021-11-02T04:29:05.853259Z","shell.execute_reply.started":"2021-11-02T04:29:05.81531Z","shell.execute_reply":"2021-11-02T04:29:05.852578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, the final dataframe has been prepared, and ready to be submitted.","metadata":{}},{"cell_type":"code","source":"sub_df = pd.DataFrame({'Id': test_metadata.Id, 'Pawpularity': op.squeeze(dim = 1).cpu().detach().numpy()})\nsub_df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T04:32:35.932824Z","iopub.execute_input":"2021-11-02T04:32:35.933096Z","iopub.status.idle":"2021-11-02T04:32:35.945534Z","shell.execute_reply.started":"2021-11-02T04:32:35.933068Z","shell.execute_reply":"2021-11-02T04:32:35.944687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T04:29:05.871739Z","iopub.execute_input":"2021-11-02T04:29:05.872199Z","iopub.status.idle":"2021-11-02T04:29:05.879389Z","shell.execute_reply.started":"2021-11-02T04:29:05.872162Z","shell.execute_reply":"2021-11-02T04:29:05.87858Z"},"trusted":true},"execution_count":null,"outputs":[]}]}