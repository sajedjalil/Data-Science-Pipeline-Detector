{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"alert alert-success\" role=\"alert\">\nThis work consists of two parts:     \n    <ul>\n        <li> PART 1 - TRAIN MODEL WITH META DATA!!</li>\n        <li> PART 2 - SOME IMAGE RELATED ENHANCEMENT</a></li>\n    </ul>\n    \n</div>\n\n<div class=\"alert alert-warning\">\n<strong>Feel free to use it and enjoy!\n    I really appreciate if you upvote this notebook. Thank you! </strong>\n</div>\n","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nfrom timm import create_model\nfrom fastai.vision.all import *","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(999, reproducible=True)\nBATCH_SIZE = 8\nImage_size = 224\nepoch = 5\nModel_name = \"swin_large_patch4_window7_224\"\ndataset_path = Path('../input/petfinder-pawpularity-score/')\ndataset_path.ls()\ntrain_df = pd.read_csv(dataset_path/'train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T14:51:13.034581Z","iopub.execute_input":"2021-12-12T14:51:13.035456Z","iopub.status.idle":"2021-12-12T14:51:13.078466Z","shell.execute_reply.started":"2021-12-12T14:51:13.035393Z","shell.execute_reply":"2021-12-12T14:51:13.077504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport fastai\nimport timm\nfrom timm import create_model\nfrom fastai.vision.all import *\n# timm.list_models()\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nscale = StandardScaler()\ntrain_df = pd.read_csv(dataset_path/'train.csv')\n\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path/'train'/x)+'.jpg')\ntrain_df = train_df.drop(columns=['Id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head()\n\nmeta =True\nif meta:\n    def size_and_shape(row):\n        img = Image.open(row['path'])\n        return pd.Series([img.size[0], img.size[1], img.size[1]/img.size[0], img.size[0]/img.size[1], os.path.getsize(row['path'])])\n\n    scale = MinMaxScaler()\n\n    train_df[['width', 'height', 'hw_ratio', 'wh_ratio', 'size']] = pd.DataFrame(scale.fit_transform(train_df.apply(size_and_shape, axis=1).values))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T14:51:13.080017Z","iopub.execute_input":"2021-12-12T14:51:13.080384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")\nprint(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['norm_score'] = train_df['Pawpularity']/100\ntrain_df['norm_score']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = Image.open(train_df['path'][1])\nwidth, height = im.size\nprint(width,height)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n    os.makedirs('/root/.cache/torch/hub/checkpoints/')\n!cp '../input/swin-transformer/swin_large_patch4_window7_224_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n# num_bins","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\n\nN_FOLDS = 5\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['fold']==0].head()\ntrain_df[train_df['fold']==0]['bins'].value_counts()\ntrain_df[train_df['fold']==1]['bins'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n                               valid_col='is_valid', #\n                               seed=999, #seed\n                               fn_col='path', #filename/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(Image_size, resamples=(Image.BICUBIC, Image.NEAREST)), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()]))    #pass in batch_tfms\n    \n    return dls\n\n\nmeta_target = train_df.drop(['norm_score','Pawpularity','path', 'fold', 'bins'],1).keys().tolist()\nprint(\"meta len:\",len(meta_target))\n\nif meta:\n    def get_data(fold):\n        train_df_f = train_df.copy()\n        # add is_valid for validation fold\n        if fold != -1:\n            train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n            print(\"Using kfold: \", fold)\n        elif fold == -1:\n            train_df_f['is_valid'] = (train_df_f['fold'].values < 10 ) \n            print(\"Using Whole dataset for LR finder\")\n\n        paw_block = DataBlock(blocks = (ImageBlock, RegressionBlock, RegressionBlock) ,  # input/ output\n                              get_x = [ColReader('path'), ColReader(meta_target)], \n                              get_y = ColReader('norm_score') , \n                              item_tfms = Resize(Image_size, resamples=(Image.BICUBIC, Image.NEAREST)), \n                              batch_tfms = setup_aug_tfms([#Flip(p=0.5),\n                                              Brightness(max_lighting=0.2, p=0.75), \n                                              Contrast(max_lighting=0.2, p=0.75), \n                                              Hue(max_hue=0.1, p=0.75), \n                                              Saturation(max_lighting=0.2, p=0.75)])\n                              # RandomErasing(p=0.5, sl=0.0, sh=0.3, min_aspect=0.3, max_count=1)\n\n\n                             )\n\n        paw_dls = paw_block.dataloaders(train_df_f, batch_size=BATCH_SIZE, y_block=RegressionBlock, num_workers=8)\n        return paw_dls\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Valid Kfolder size\nthe_data = get_data(0)\nprint('finished')\nassert (len(the_data.train) + len(the_data.valid)) == (len(train_df)//BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularModel(nn.Module):\n    def __init__(self, model_name='swin_large_patch4_window7_224', num_classes=[17,1],\n                 n_meta_dim=[256, 128], pretrained=True):\n        super().__init__()\n        out_dim=num_classes[1]\n        n_meta_features=num_classes[0]\n        self.n_meta_features = n_meta_features\n        self.enet = create_model(model_name, pretrained=True, in_chans=3)\n        self.dropouts = nn.ModuleList([\n            nn.Dropout(0.5) for _ in range(5)\n        ])\n        in_ch = self.enet.head.in_features\n        if n_meta_features > 0:\n            self.meta = nn.Sequential(\n                nn.Linear(n_meta_features, n_meta_dim[0]),\n                nn.BatchNorm1d(n_meta_dim[0]),\n                nn.SiLU(),\n                nn.Dropout(p=0.3),\n                nn.Linear(n_meta_dim[0], n_meta_dim[1]),\n                nn.BatchNorm1d(n_meta_dim[1]),\n                nn.SiLU(),\n            )\n            in_ch += n_meta_dim[1]\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.enet.head = nn.Identity()\n\n    def extract(self, x):\n        x = self.enet(x)\n        return x\n\n    def forward(self, image, features):\n        x = self.extract(image).squeeze(-1).squeeze(-1)\n        if self.n_meta_features > 0:\n            x_meta = self.meta(features)\n            x = torch.cat((x, x_meta), dim=1)\n        for i, dropout in enumerate(self.dropouts):\n            if i == 0:\n                out = self.myfc(dropout(x))\n            else:\n                out += self.myfc(dropout(x))\n        out /= len(self.dropouts)\n        return out\n\ndef get_learner(fold_num):\n    data = get_data(fold_num)\n    if meta:\n        print(\"data.c:\", data.c)\n        model = PawpularModel(Model_name, num_classes=data.c)\n    else:    \n        model = create_model(Model_name, pretrained=True, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse).to_fp16()\n    \n    return learn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(dataset_path/'test.csv')\ntest_df.head()\ntest_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\n\nif meta:\n    def size_and_shape(row):\n        img = Image.open(row['path'])\n        return pd.Series([img.size[0], img.size[1], img.size[1]/img.size[0], img.size[0]/img.size[1], os.path.getsize(row['path'])])\n\n    scale_test = MinMaxScaler()\n\n    test_df[['width', 'height', 'hw_ratio', 'wh_ratio', 'size']] = pd.DataFrame(scale_test.fit_transform(test_df.apply(size_and_shape, axis=1).values))\n\n\ntrain_df['norm_score'] = train_df['Pawpularity']/100\n\n# get_learner(fold_num=-1).lr_find(end_lr=3e-2)\n  # SuggestedLRs(valley=0.00017041253158822656\n#get_learner(fold_num=0).lr_find(end_lr=3e-2) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/baseline-224-mata-v2-1/models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Path('./models').mkdir(exist_ok=True, parents=True)\n!cp ../input/baseline-224-mata-v2-1/models/learn_saved_model_fold_0.pth ./models/\nprint(0)\n!cp ../input/baseline-224-mata-v2-1/models/learn_saved_model_fold_1.pth ./models/\n!cp ../input/baseline-224-mata-v2-1/models/learn_saved_model_fold_2.pth ./models/\n!cp ../input/baseline-224-mata-v2-1/models/learn_saved_model_fold_3.pth ./models/\n!cp ../input/baseline-224-mata-v2-1/models/learn_saved_model_fold_4.pth ./models/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gc\n# torch.cuda.empty_cache()\n# all_preds = []\n\n# for i in range(N_FOLDS):  # \n\n#     print(f'Fold {i} results')\n    \n#     learn = get_learner(fold_num=i)\n#     # 2e-5\n#     learn.load('learn_saved_model_fold_{}'.format(i))\n\n#     #learn = learn.to_fp32()\n    \n#     #learn.export(f'model_fold_{i}.pkl')\n#     #learn.save(f'model_fold_{i}.pkl')\n#     if meta:\n#         meta_target = train_df.drop(['norm_score','Pawpularity','path', 'fold', 'bins'], 1).keys().tolist()\n#         dls = get_data(i)\n#     else:\n#         dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n#                                    valid_pct=0.2, #80-20 train-validation random split\n#                                    seed=999, #seed\n#                                    fn_col='path', #filename/path is in the second column of the DataFrame\n#                                    label_col='norm_score', #label is in the first column of the DataFrame\n#                                    y_block=RegressionBlock, #The type of target\n#                                    bs=BATCH_SIZE, #pass in batch size\n#                                    num_workers=8,\n#                                    item_tfms=Resize(Image_size, resamples=(Image.BICUBIC, Image.NEAREST)), #pass in item_tfms\n#                                    batch_tfms=setup_aug_tfms([Brightness(max_lighting=0.2, p=0.75), \n#                                                         Contrast(max_lighting=0.2, p=0.75), \n#                                                         Hue(max_hue=0.1, p=0.75), \n#                                                         Saturation(max_lighting=0.2, p=0.75), FlipItem(p=.5)\n#                                                         ]))   \n#          # RandomErasing(p=0.5, sl=0.0, sh=0.3, min_aspect=0.3, max_count=1) \n\n    \n#     test_dl = dls.test_dl(test_df)\n    \n#     preds, _ = learn.tta(dl=test_dl, n=5, beta=0)    # 'Series' object has no attribute 'widt\n#     all_preds.append(preds)\n    \n#     del learn\n#     torch.cuda.empty_cache()\n#     gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.mean(np.stack(all_preds*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_df = pd.read_csv(dataset_path/'sample_submission.csv')\n# preds = np.mean(np.stack(all_preds), axis=0)\n# sample_df['Pawpularity'] = preds*100\n# sample_df.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.read_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVR head","metadata":{}},{"cell_type":"code","source":"using_svr = True\nimport sys\nsys.path.append(\"../input/tez-lib/\")\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nfrom timm import create_model\nfrom fastai.vision.all import *\nmeta = True\n\n# train part\nimport tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport math\nimport gc\nclass args:\n    batch_size = 16\n    image_size = 224\n    \ndef sigmoid(x):\n    return 1 / (1 + math.exp(-x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(999, reproducible=True)\n\ndataset_path = Path('../input/petfinder-pawpularity-score/')\ndataset_path.ls()\n# train_df = pd.read_csv(dataset_path/'train.csv')\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler#, StandardSaclertrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass SVR_Model(nn.Module):\n    def __init__(self, model_name='swin_large_patch4_window7_224', num_classes=[19,1]):\n        super().__init__()\n        self.model = create_model(model_name, pretrained=True, in_chans=3)\n        #timm.create_model(model_name, pretrained=False, in_chans=3)\n        self.model.head = nn.Sequential()#nn.Linear()  # 128 + 17  # self.model.head.in_features, 128+128\n        self.dropout = nn.Dropout(0.1)\n        self.dense_fc = nn.Linear(num_classes[0], 128)\n        self.dense1 = nn.Linear(1536 + 128, 256)\n        self.dense2 = nn.Linear(256, num_classes[1])\n\n\n\n    def forward(self, image, features, targets=None):\n        x1 = self.model(image)\n        x = self.dropout(x1)\n#         features = nn.sigmoid(self.dense_f1(features))\n        x = torch.cat([x, nn.ReLU()(self.dense_fc(features))], dim=1)  \n        x = self.dense1(x)\n        x = nn.ReLU()(x)       #SiLU\n        x = self.dense2(x)\n        \n        x = torch.cat([x, x1, features], dim=1)\n        return x\n    \n\nclass SVRModel(nn.Module):      \n    def __init__(self, model_name='swin_large_patch4_window7_224', num_classes=[17,1],\n                 n_meta_dim=[256, 128], pretrained=True):\n        super().__init__()\n        out_dim=num_classes[1]\n        n_meta_features=num_classes[0]\n        self.n_meta_features = n_meta_features\n        self.enet = create_model(model_name, pretrained=True, in_chans=3)\n        self.dropouts = nn.ModuleList([\n            nn.Dropout(0.5) for _ in range(5)\n        ])\n        in_ch = self.enet.head.in_features\n        if n_meta_features > 0:\n            self.meta = nn.Sequential(\n                nn.Linear(n_meta_features, n_meta_dim[0]),\n                nn.BatchNorm1d(n_meta_dim[0]),\n                nn.SiLU(),\n                nn.Dropout(p=0.3),\n                nn.Linear(n_meta_dim[0], n_meta_dim[1]),\n                nn.BatchNorm1d(n_meta_dim[1]),\n                nn.SiLU(),\n            )\n            in_ch += n_meta_dim[1]\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.enet.head = nn.Identity()\n\n    def extract(self, x):\n        x = self.enet(x)\n        return x\n\n    def forward(self, image, features):\n        x1 = self.extract(image).squeeze(-1).squeeze(-1)\n        if self.n_meta_features > 0:\n            x_meta = self.meta(features)\n            x = torch.cat((x1, x_meta), dim=1)\n        for i, dropout in enumerate(self.dropouts):\n            if i == 0:\n                out = self.myfc(dropout(x))\n            else:\n                out += self.myfc(dropout(x))\n        out /= len(self.dropouts)\n        \n        x = torch.cat([out, x1, features, x_meta], dim=1)\n#         print(x.shape)\n        return x\n    \n    \ndef get_svr_learner(fold_num):\n    data = get_data(fold_num)\n\n    print(\"data.c:\", data.c)\n    model = SVRModel(Model_name, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse).to_fp16()\n    \n    return learn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cuml, pickle\nfrom cuml.svm import SVR\nfrom sklearn.svm import SVR as skSVR\nprint('RAPIDS version',cuml.__version__,'\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(dataset_path/'test.csv')\ntest_df.head()\ntest_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\n\nif meta:\n    def size_and_shape(row):\n        img = Image.open(row['path'])\n        return pd.Series([img.size[0], img.size[1], img.size[1]/img.size[0], img.size[0]/img.size[1], os.path.getsize(row['path'])])\n\n#     scale_test = MinMaxScaler()\n\n    test_df[['width', 'height', 'hw_ratio', 'wh_ratio', 'size']] = pd.DataFrame(scale.transform(test_df.apply(size_and_shape, axis=1).values))\n\ntrain_df['norm_score'] = train_df['Pawpularity']/100\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Time","metadata":{}},{"cell_type":"code","source":"super_final_predictions = []\nsuper_final_predictions2 = []\nsuper_final_skSVR = []\nsuper_final_oof_predictions = []\nsuper_final_oof_predictions2 = []\nsuper_final_oof_skSVR = []\nsuper_final_oof_true = []\nLOAD_SVR_FROM_PATH = None\n\ntrain_path = pd.read_csv(dataset_path/'train.csv')\ntta_n = 5\nN_FOLDS = 5\n\ndense_features = [\n        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'width', \n        'height' ,'hw_ratio','wh_ratio']\n\n\nfor fold_ in range(N_FOLDS):\n\n    print('#'*25)\n    print('### FOLD',fold_+1)\n    print('#'*25)\n    dls = get_data(fold_)\n    learn = get_svr_learner(fold_num = fold_)\n\n    learn.load('learn_saved_model_fold_{}'.format(fold_))\n\n    \n    train_df_f = train_df.copy()\n    \n    name = f\"SVR_fold_{fold_}.pkl\" \n    \n    if LOAD_SVR_FROM_PATH is None:\n        ##################\n        # EXTRACT TRAIN EMBEDDINGS\n        \n        print('Extracting train embedding...')\n        train_dl = dls.test_dl(  train_df[train_df['fold']!=fold_] )\n        train_predictions, _ = learn.tta(dl=train_dl, n=tta_n, beta=0)   \n        \n        \n        embed = np.array([]).reshape((0,1682))   # 128+ 12\n        for preds in train_predictions:\n            embed = np.concatenate([embed,preds.unsqueeze(0)],axis=0)\n        \n        ##################\n        # FIT RAPIDS SVR\n        print('Fitting SVR...')\n        \n        # C = 1.0\n        clf = SVR(C=5.0)  # 20 ? smaller\n        skclf = skSVR(C=1.0)    # C=1.0\n        \n        \n        # Expected 7930 rows but got 7929 rows\n        clf.fit(embed.astype('float32'), train_df[train_df['fold']!=fold_].norm_score.values.astype('float32'))\n        skclf.fit(embed.astype('float32'), train_df[train_df['fold']!=fold_].norm_score.values.astype('float32'))\n        \n        \n        ##################\n        # SAVE RAPIDS SVR \n        pickle.dump(clf, open(name, \"wb\"))\n        \n    else:\n        ##################\n        # LOAD RAPIDS SVR \n        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n\n    ##################\n    # TEST PREDICTIONS\n    print('Predicting test...')\n \n    test_dl = dls.test_dl( test_df )        \n    test_predictions, _ = learn.tta(dl=test_dl, n=tta_n, beta=0)    # 'Series' object has no attribute 'width\n        \n    final_test_predictions = []\n    embed = np.array([]).reshape((0,1682))\n    for preds in test_predictions: #tqd\n        final_test_predictions.extend(preds[0].ravel().tolist())\n        embed = np.concatenate([embed,preds.unsqueeze(0)],axis=0)\n\n    final_test_predictions = [x * 100 for x in final_test_predictions]   # sigmoid(x)\n    final_test_predictions2 = clf.predict(embed.astype('float32'))\n    final_test_prediction_sklearn = skclf.predict(embed.astype('float32'))\n    \n    super_final_predictions.append(final_test_predictions)\n    super_final_predictions2.append(final_test_predictions2)\n    super_final_skSVR.append(final_test_prediction_sklearn)\n    ##################\n    \n    ##################\n    # OOF PREDICTIONS\n    print('Predicting oof...')\n    val_dl = dls.test_dl( train_df[train_df['fold']==fold_] )     \n    # sigmoid(): argument 'input' (position 1) must be Tensor, not tuple\n    valid_predictions , _ = learn.tta(dl=val_dl, n=tta_n, beta=0)    # 'Series' object has no attribute 'width\n        \n#     valid_predictions = model.predict(valid_dataset, batch_size=2*args.batch_size, n_jobs=-1)\n\n    final_oof_predictions = []\n    embed = np.array([]).reshape((0,1682))\n    for preds in valid_predictions:\n        final_oof_predictions.extend(preds[0].ravel().tolist())\n        embed = np.concatenate([embed,preds.unsqueeze(0)],axis=0)\n\n    final_oof_predictions = [x * 100 for x in final_oof_predictions]    # sigmoid(x)\n    final_oof_predictions2 = clf.predict(embed.astype('float32'))  \n    final_oof_predictions_sklearn = skclf.predict(embed.astype('float32'))\n    super_final_oof_predictions.append(final_oof_predictions)\n    super_final_oof_predictions2.append(final_oof_predictions2)\n    super_final_oof_skSVR.append(final_oof_predictions_sklearn)\n    \n    final_oof_true = train_df[train_df['fold']==fold_]['Pawpularity'].values\n    super_final_oof_true.append(final_oof_true)\n    ##################\n    \n    ##################\n    # COMPUTE RSME\n    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - np.array(super_final_oof_predictions[-1]))**2.0 ) )\n    print('NN RSME =',rsme,'\\n')\n    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - np.array(super_final_oof_predictions2[-1])*100)**2.0 ) )\n    print('SVR RSME =',rsme,'\\n')\n    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - np.array(super_final_oof_skSVR[-1])*100)**2.0 ) )\n    print('SK SVR RSME =',rsme,'\\n')\n    \n    w = 0.3\n\n    oof2 = (1-w)*np.array(super_final_oof_predictions[-1]) + w*np.array(super_final_oof_predictions2[-1])*100\n    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - oof2)**2.0 ) )\n    print('Ensemble RSME =',rsme,'\\n')\n    \n\n    oof3 = (1-w)*np.array(super_final_oof_predictions[-1]) + 0.5*w*np.array(super_final_oof_predictions2[-1])*100 + \\\n    0.5*w*np.array(super_final_oof_skSVR[-1])*100\n    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - oof3)**2.0 ) )\n    print('With Sk Ensemble RSME =',rsme,'\\n')\n\n    del learn, clf\n\n    torch.cuda.empty_cache()\n\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['fold']==fold_][dense_features] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inverse Sigmoid: x = ln(y/(1-y))","metadata":{}},{"cell_type":"code","source":"super_final_oof_predictions = np.array(super_final_oof_predictions)\nsuper_final_oof_true = np.array(super_final_oof_true)\n\nprint(super_final_oof_predictions.shape)\nprint(super_final_oof_true.shape)\n\nrsme = np.sqrt( np.mean( (super_final_oof_predictions[-1] - super_final_oof_true[-1])**2.0 ) )\nprint('RSME =',rsme,'\\n')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true = np.hstack(super_final_oof_true)\n\noof = np.hstack(super_final_oof_predictions)\nrsme = np.sqrt( np.mean( (oof - true)**2.0 ))\nprint('Overall CV NN head RSME =',rsme)\n\noof2 = np.hstack(super_final_oof_predictions2) *100\nrsme = np.sqrt( np.mean( (oof2 - true)**2.0 ))\nprint('Overall CV SVR head RSME =',rsme)\n\noof_sk = np.hstack(super_final_oof_skSVR) *100\nrsme = np.sqrt( np.mean( (oof_sk - true)**2.0 ))\nprint('Overall CV sklearn SVR head RSME =',rsme)\n\noof3 = (1-w)*oof + (w*oof2 + w*oof_sk)*0.5\nrsme = np.sqrt( np.mean( (oof3 - true)**2.0 ))\nprint('Overall CV Ensemble heads RSME with 50% NN and 50% SVR =',rsme)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nscore = []\nfor ww in np.arange(0,1.05,0.05):\n    oof3 = (1-ww)*oof + 0.5*(ww*oof2 + ww*oof_sk)\n    rsme = np.sqrt( np.mean( (oof3 - true)**2.0 ))\n    #print(f'{ww:0.2} CV Ensemble RSME =',rsme)\n    score.append(rsme)\nbest_w = np.argmin(score)*0.05\n\nplt.figure(figsize=(20,5))\nplt.plot(np.arange(21)/20.0,score,'-o')\nplt.plot([best_w],np.min(score),'o',color='black',markersize=15)\nplt.title(f'Best Overall CV RSME={np.min(score):.4} with SVR Ensemble Weight={best_w:.2}',size=16)\nplt.ylabel('Overall Ensemble RSME',size=14)\nplt.xlabel('SVR Weight',size=14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\ndf_test['path'] = df_test['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\n\ndf_test[['width', 'height', 'hw_ratio', 'wh_ratio', 'size']] = pd.DataFrame(scale.transform(df_test.apply(size_and_shape, axis=1).values))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ... oof\n\npredictions = np.mean(np.column_stack(super_final_predictions), axis=1)\npredictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1) *100\npredictions_sk = np.mean(np.column_stack(final_oof_predictions_sklearn), axis=1) *100\n\ndf_test[\"Pawpularity\"] = (1-best_w)*predictions + 0.5 * (best_w*predictions2 + best_w*predictions_sk)\ndf_test = df_test[[\"Id\", \"Pawpularity\"]]\ndf_test.to_csv(\"submission.csv\", index=False)\ndf_test.head()\n# operands could not be broadcast together with shapes (12432,) (8,) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_sk ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[\"Pawpularity\"]","metadata":{},"execution_count":null,"outputs":[]}]}