{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:50px; font-style: normal;background-color: #f6f5f5; color :#c97820; border-radius: 10px 20px; text-align:center\">PetFinder.my - Pawpularity with <span style=\"color: #8532a8\"> Pytorch ‚ö° </span> </h1>\n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/25383/logos/header.png)\n\n<p style=\"color :#006699; font-size:20px\" > Millions of stray animals suffer on the streets or are euthanized in shelters every day around the world. You might expect pets with attractive photos to generate more interest and be adopted faster. But what makes a good picture? With the help of data science, you may be able to accurately determine a pet photo‚Äôs appeal and even suggest improvements to give these rescue animals a higher chance of loving homes.\n</p>\n\n<p style=\"font-size:20px; background-color: #f6f5f5; color :#6666ff; border-radius: 10px 10px; text-align:center\" > \n    What will we learn today?\n</p>\n\n<p style=\"font-size:17px; background-color: #f6f5f5; color :#a85e32; border-radius: 10px 10px; text-align:center\">\n    Developing and Training models with Pytorch Lightning ‚ö° <br>\n    Stratified Kfold with Pytorch Lightning ‚ö°\n    </p>\n    \n    \n <p style=\"font-size:30px; background-color: #f6f5f5; color :#e6cf25; border-radius: 10px 10px; text-align:center\" > \n   üå©Ô∏è Sit back and enjoy the Lightning show! üå©Ô∏è\n</p>\n    \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-24T17:05:32.076083Z","iopub.execute_input":"2021-09-24T17:05:32.076964Z","iopub.status.idle":"2021-09-24T17:05:33.29022Z","shell.execute_reply.started":"2021-09-24T17:05:32.076913Z","shell.execute_reply":"2021-09-24T17:05:33.289128Z"}}},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\">Library Installs</h1>","metadata":{}},{"cell_type":"code","source":"!pip install -q timm\n!pip install -q pytorch-lightning","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-27T05:43:34.691936Z","iopub.execute_input":"2021-09-27T05:43:34.692259Z","iopub.status.idle":"2021-09-27T05:43:50.561778Z","shell.execute_reply.started":"2021-09-27T05:43:34.692181Z","shell.execute_reply":"2021-09-27T05:43:50.560984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\">Imports</h1>","metadata":{"_kg_hide-output":true}},{"cell_type":"code","source":"# Pytorch Lightning Utils\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import WandbLogger\n\n# Pytorch \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.optim.optimizer import Optimizer, required \nimport timm\n\n\n# ML Utils\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\n# Visualization Utils\nfrom matplotlib import pyplot as plt\nimport plotly.graph_objects as go\nimport plotly_express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\n\nimport seaborn as sns\n\nfrom colorama import Fore, Back, Style\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nc_ = Fore.CYAN\ny_ = Fore.YELLOW\nres = Style.RESET_ALL\n\n# Image Augmentation Library\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Misc Utils\nimport os\nimport random\n\n# Hide Warning\nimport warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-27T05:43:50.563846Z","iopub.execute_input":"2021-09-27T05:43:50.564246Z","iopub.status.idle":"2021-09-27T05:44:00.954833Z","shell.execute_reply.started":"2021-09-27T05:43:50.564148Z","shell.execute_reply":"2021-09-27T05:44:00.954001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\">Reading the Data</h1>\n\n<p style=\"font-family: garamound; font-size:20px;\" > Lets read the data and add full file path for easy reading </p>","metadata":{}},{"cell_type":"code","source":"# reading the files\ntrain = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n\n# functions to append full path\ndef get_train_file_path(image_id):\n    return \"../input/petfinder-pawpularity-score/train/{}.jpg\".format(image_id)\n\ndef get_test_file_path(image_id):\n    return \"../input/petfinder-pawpularity-score/test/{}.jpg\".format(image_id)\n\ntrain['file_path'] = train['Id'].apply(get_train_file_path)\ntest['file_path'] = test['Id'].apply(get_test_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:00.95644Z","iopub.execute_input":"2021-09-27T05:44:00.956731Z","iopub.status.idle":"2021-09-27T05:44:01.011136Z","shell.execute_reply.started":"2021-09-27T05:44:00.956695Z","shell.execute_reply":"2021-09-27T05:44:01.010387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: garamound; font-size:20px;\" > Lets see what we are working with </p>","metadata":{}},{"cell_type":"code","source":"print(f\"{r_}TRAINING DATA{res}\")\ntrain.head().style.set_properties(**{'background-color': 'lightyellow',\n                           'color': 'brown'})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-27T05:44:01.012766Z","iopub.execute_input":"2021-09-27T05:44:01.013042Z","iopub.status.idle":"2021-09-27T05:44:01.074255Z","shell.execute_reply.started":"2021-09-27T05:44:01.013007Z","shell.execute_reply":"2021-09-27T05:44:01.073372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"{g_}TESTING DATA{res}\")\ntest.head().style.set_properties(**{'background-color': 'lightyellow',\n                           'color': 'brown'})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-27T05:44:01.076908Z","iopub.execute_input":"2021-09-27T05:44:01.077186Z","iopub.status.idle":"2021-09-27T05:44:01.107276Z","shell.execute_reply.started":"2021-09-27T05:44:01.077151Z","shell.execute_reply":"2021-09-27T05:44:01.106488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\">Visualizing the <span style=\"color: #bf4f26\" > Target Variable </span> </h1>\n\n<p style=\"font-family: garamound; font-size:20px;\" > A Histogram plot of the pawpularity score </p>","metadata":{}},{"cell_type":"code","source":"# create the bins\ncounts, bins = np.histogram(train['Pawpularity'], bins=range(0, 110, 10))\nbins = 0.5 * (bins[:-1] + bins[1:])\n\nfig = px.bar(x=bins, y=counts)\n             \nfig.update_layout(title_text='Pawpularity distribution', \n                  xaxis=dict(title='Pawpularity'),\n                  yaxis=dict(title='Count'),\n                  showlegend=False\n                 )\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-27T05:44:01.108676Z","iopub.execute_input":"2021-09-27T05:44:01.109181Z","iopub.status.idle":"2021-09-27T05:44:01.308111Z","shell.execute_reply.started":"2021-09-27T05:44:01.109144Z","shell.execute_reply":"2021-09-27T05:44:01.307206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\">Configuring the Hyperparameters </h1>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: garamound; font-size:20px;\" > You can change hyperparameters here to see how it affects the final model </p>","metadata":{}},{"cell_type":"code","source":"Config = {\n    'seed' : 2021,  # setting the seed\n    'debug': False,  # debug mode\n    'num_folds': 5, # number of folds to split\n    'trn_folds': [0, ],  # folds to train\n    'batch_size': 12,  # batch size\n    'num_workers' : 8,  # number of cpu workers\n    'img_size': 512,  # image size\n    'model': 'efficientnet_b3',  # model to use\n    'img_ftr_len': 500, # length of vector to encode the images in\n    'epochs': 15,        # numbers of epochs\n    'precision': 16,\n    'weight_decay': 1e-6,\n    \n    # learning\n    'lr': 1e-4,\n    'T_max': 10,\n    'min_lr': 1e-6,\n    'patience_earlystop': 3,\n}   ","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:01.309627Z","iopub.execute_input":"2021-09-27T05:44:01.309933Z","iopub.status.idle":"2021-09-27T05:44:01.316191Z","shell.execute_reply.started":"2021-09-27T05:44:01.309888Z","shell.execute_reply":"2021-09-27T05:44:01.315356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if Config['debug']:\n    train = train[:500].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:01.317619Z","iopub.execute_input":"2021-09-27T05:44:01.317927Z","iopub.status.idle":"2021-09-27T05:44:01.32656Z","shell.execute_reply.started":"2021-09-27T05:44:01.317856Z","shell.execute_reply":"2021-09-27T05:44:01.325799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\">Seeding for Reproducibility</h1>\n\n<p style=\"font-family: garamound; font-size:20px;\" > We seed everything, so that we can reproduce the results everytime </p>","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(Config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:01.327989Z","iopub.execute_input":"2021-09-27T05:44:01.328275Z","iopub.status.idle":"2021-09-27T05:44:01.338908Z","shell.execute_reply.started":"2021-09-27T05:44:01.328242Z","shell.execute_reply":"2021-09-27T05:44:01.338183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\"> Creating Folds </h1>\n\n<p style=\"font-family: garamound; font-size:20px;\" > We create Stratified Kfolds of the data. We first bin values into discrete intervals with <span style=\"font-weight: bold\"> pd.cut </span> and then split</p>","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/abhishek/same-old-creating-folds\ndef create_folds(data, num_splits, seed):\n    data[\"kfold\"] = -1\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n\n    data.loc[:, \"bins\"] = pd.cut(data[\"Pawpularity\"], bins=num_bins, labels=False)\n\n    kf = model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=seed)\n    \n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'kfold'] = f\n    \n    data = data.drop(\"bins\", axis=1)\n\n    return data\n\ntrain = create_folds(train, Config['num_folds'], Config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:01.340475Z","iopub.execute_input":"2021-09-27T05:44:01.341085Z","iopub.status.idle":"2021-09-27T05:44:01.366942Z","shell.execute_reply.started":"2021-09-27T05:44:01.341042Z","shell.execute_reply":"2021-09-27T05:44:01.366288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\"> \nDataset Class</h1>","metadata":{}},{"cell_type":"code","source":"class PetPawpularityDs(Dataset):\n    def __init__(self, df, split='train', transform=None):\n        self.df = df\n        self.transforms = transform\n        self.ftrcols = [col for col in df.columns if col not in ['Id', 'Pawpularity', 'file_path', 'kfold']]\n        self.split = split\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_path = self.df.loc[idx, 'file_path']\n        img = cv2.imread(img_path)\n        \n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        ftrs = torch.Tensor(np.array(self.df.loc[idx, self.ftrcols].values).astype(np.float32))\n        \n        if self.split == 'train':\n            score = torch.Tensor([self.df.loc[idx, 'Pawpularity']])\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n        \n        if self.split=='train':\n            return img, ftrs, score\n        else:\n            return img, ftrs","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:01.368474Z","iopub.execute_input":"2021-09-27T05:44:01.368754Z","iopub.status.idle":"2021-09-27T05:44:01.378781Z","shell.execute_reply.started":"2021-09-27T05:44:01.368719Z","shell.execute_reply":"2021-09-27T05:44:01.377953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\"> \nAugmentations </h1>\n\n<p style=\"font-family: garamound; font-size:20px;\" > We will just use a Horizontal Flip augmentation for Baseline. Feel free to test out more augmentations here</p>","metadata":{}},{"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose([\n                        A.Resize(Config['img_size'], Config['img_size']),\n                        A.HorizontalFlip(p=0.5),\n                        A.Normalize(\n                                mean=[0.485, 0.456, 0.406], \n                                std=[0.229, 0.224, 0.225], \n                            ),\n                        ToTensorV2()\n                    ])\n\n\ndef get_valid_transforms():\n    return A.Compose([\n                        A.Resize(Config['img_size'], Config['img_size']),\n                        A.Normalize(\n                            mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225],\n                        ),\n                        ToTensorV2(),\n                ])\n\ndef get_test_transforms():\n    return A.Compose([\n                    A.Resize(Config['img_size'], Config['img_size']),\n                    A.Normalize(\n                            mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225],\n                        ),\n                    ToTensorV2(),\n                ])","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:01.380396Z","iopub.execute_input":"2021-09-27T05:44:01.380738Z","iopub.status.idle":"2021-09-27T05:44:01.390014Z","shell.execute_reply.started":"2021-09-27T05:44:01.380706Z","shell.execute_reply":"2021-09-27T05:44:01.389202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p p style = \"font-family: garamond; font-size:30px; font-style: normal;background-color: #f6f5f5; color :#6666ff; border-radius: 10px 10px; text-align:center\">Pytorch Lightning DataModule ‚ö°</p>\n\n<p style=\"font-family: garamound; font-size:20px;\" > A datamodule is a shareable, reusable class that encapsulates all the steps needed to process data. Simply put, a DataModule is simply a collection of a train_dataloader, val_dataloader(s), test_dataloader(s) along with the matching transforms and data processing/downloads steps required.</p>","metadata":{}},{"cell_type":"code","source":"# custom collate functions to combine image, features and labels\n\ndef train_collate_fn(data):\n    \n    images = torch.zeros((len(data), 3, Config['img_size'], Config['img_size']))\n    datafeatures = torch.zeros((len(data), 12))\n    scores = torch.zeros((len(data), 1))\n    \n    for i in range(len(data)):\n        images[i, ...] = data[i][0]\n        datafeatures[i, ...] = data[i][1]\n        scores[i, ...] = data[i][2]\n        \n    return images.float(), datafeatures.float(), scores.float()\n\ndef test_collate_fn(data):\n    \n    images = torch.zeros((len(data), 3, Config['img_size'], Config['img_size']))\n    datafeatures = torch.zeros((len(data), 12))\n    \n    for i in range(len(data)):\n        images[i, ...] = data[i][0]\n        datafeatures[i, ...] = data[i][1]\n        \n    return images.float(), datafeatures.float()\n\n\n# Pytorch lightning Data Module\nclass PawpularityDModule(pl.LightningDataModule):\n\n    def __init__(self, df, fld):\n        super().__init__()\n        self.fold = fld\n        self.train_data = df[df['kfold'] != self.fold].reset_index(drop=True)\n        self.val_data = df[df['kfold'] == self.fold].reset_index(drop=True)\n        self.test_data = test\n        \n    def setup(self, stage=None):\n        self.train_dataset = PetPawpularityDs(\n                df = self.train_data,\n                transform = get_train_transforms()    \n            )\n        \n        self.val_dataset = PetPawpularityDs(\n                df = self.val_data,\n                transform = get_valid_transforms(),\n        )\n\n        self.test_dataset = PetPawpularityDs(\n                df = self.test_data,\n                transform = get_test_transforms(),\n                split='test'\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n                self.train_dataset,\n                batch_size=Config['batch_size'],\n                shuffle=True,\n                num_workers=Config['num_workers'],\n                pin_memory=True, \n                collate_fn = train_collate_fn\n            )\n\n    def val_dataloader(self):\n        return DataLoader(\n                self.val_dataset,\n                batch_size = Config['batch_size'],\n                shuffle=False,\n                num_workers = Config['num_workers'],\n                pin_memory=True,\n                collate_fn = train_collate_fn\n            )\n\n    def test_dataloader(self):\n        return DataLoader(\n                self.test_dataset, \n                batch_size = Config['batch_size'],\n                shuffle=False, \n                num_workers = Config['num_workers'],\n                pin_memory=True,\n                collate_fn = test_collate_fn\n            )","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:01.391697Z","iopub.execute_input":"2021-09-27T05:44:01.391996Z","iopub.status.idle":"2021-09-27T05:44:01.409956Z","shell.execute_reply.started":"2021-09-27T05:44:01.391964Z","shell.execute_reply":"2021-09-27T05:44:01.409183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-family: garamond; font-size:45px; font-style: normal; color :#c97821; border-radius: 10px 20px; text-align:left\"> \nTraining Data Visualization </h1>","metadata":{}},{"cell_type":"code","source":"# create a data module and set up\ndm = PawpularityDModule(train, 0)\ndm.setup()\n\n# Plot some training images\nimport torchvision.utils as vutils\nimg, ftrs, targets = next(iter(dm.train_dataloader()))\n\nplt.figure(figsize=(16, 8))\nplt.axis(\"off\")\nplt.title(\"Training Images\", fontsize=30)\n_ = plt.imshow(vutils.make_grid(\n    img[:12], nrow=4, padding=7, normalize=True).cpu().numpy().transpose((1, 2, 0)))\n\nprint(f\"{g_} {targets[:12].reshape((3,4))} {res}\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:01.414064Z","iopub.execute_input":"2021-09-27T05:44:01.414813Z","iopub.status.idle":"2021-09-27T05:44:12.975951Z","shell.execute_reply.started":"2021-09-27T05:44:01.414779Z","shell.execute_reply":"2021-09-27T05:44:12.975277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p p style = \"font-family: garamond; font-size:30px; font-style: normal;background-color: #f6f5f5; color :#6666ff; border-radius: 10px 10px; text-align:center\">Pytorch Lightning Module ‚ö°</p>\n\n<p style=\"font-family: garamound; font-size:20px;\" > A LightningModule organizes your PyTorch code into 5 sections<br>1. Computations (Models).<br>2. Train loop (training_step)<br>3. Validation loop (validation_step)<br>4. Test loop (test_step)<br>5. Optimizers (configure_optimizers) <br> <br>  We define the Model here in the <span style=\"font-weight: bold\"> Trainer </span> class. Here's a snapshot of the model we are going to build, </p>\n","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nImage(filename='../input/imagestore/finalmodel.png') \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-27T07:28:34.976066Z","iopub.execute_input":"2021-09-27T07:28:34.976431Z","iopub.status.idle":"2021-09-27T07:28:35.087782Z","shell.execute_reply.started":"2021-09-27T07:28:34.976332Z","shell.execute_reply":"2021-09-27T07:28:35.086602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer(pl.LightningModule):\n\n    def __init__(self, model_name = Config['model'],out_features=Config['img_ftr_len'],\n                 pretrained=True):\n        super().__init__()\n        \n        # feature extractor\n        self.model = timm.create_model(model_name, pretrained=pretrained,\n                                       num_classes = out_features)\n        \n        # final fc layer\n        self.finalfc = nn.Sequential(\n            nn.Linear(out_features+12, 120),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(120, 1)\n        )\n        \n        self.criterion = nn.MSELoss()\n                \n    def forward(self, img, ftrs):\n        \n        # feature extractor extracts features from the image\n        imgouts = self.model(img)\n \n        # we combine the meta features with the image features given\n        ftrout = torch.cat([imgouts, ftrs], dim=-1)\n        \n        # we then pass the combined feature into final layer\n        output = self.finalfc(ftrout)\n    \n        return output\n\n\n    def training_step(self, batch, batch_idx):\n\n        img, ftrs, score = batch\n        output = self.forward(img, ftrs)\n        \n        loss = self.criterion(output, score)\n        \n        try:\n            rmse = mean_squared_error(score.detach().cpu(), output.detach().cpu(), squared=False) \n\n            self.log(\"RMSE\", rmse, on_step= True, prog_bar=True, logger=True)\n            self.log(\"Train Loss\", loss, on_step= True,prog_bar=False, logger=True)\n        \n        except:\n            pass\n\n        return {\"loss\": loss, \"predictions\": output.detach(), \"labels\": score.detach()}\n\n    def training_epoch_end(self, outputs):\n\n        preds = []\n        labels = []\n        \n        for output in outputs:\n            \n            preds += output['predictions']\n            labels += output['labels']\n\n        labels = torch.stack(labels)\n        preds = torch.stack(preds)\n\n        train_rmse = mean_squared_error(labels.detach().cpu(), preds.detach().cpu(), squared=False)\n        \n        self.print(f'Epoch {self.current_epoch}: Training RMSE: {train_rmse:.4f}')\n        \n        self.log(\"mean_train_rmse\", train_rmse, prog_bar=False, logger=True)\n\n    def validation_step(self, batch, batch_idx):\n        \n        img, ftrs, score = batch\n        \n        with torch.no_grad():\n            output = self.forward(img, ftrs)\n\n            loss = self.criterion(output, score)\n        \n        self.log('val_loss', loss, on_step= True, prog_bar=False, logger=True)\n        return {\"predictions\": output.detach(), \"labels\": score}\n      \n\n    def validation_epoch_end(self, outputs):\n\n        preds = []\n        labels = []\n        \n        for output in outputs:\n            preds += output['predictions']\n            labels += output['labels']\n\n        labels = torch.stack(labels)\n        preds = torch.stack(preds)\n\n        val_rmse = mean_squared_error(labels.detach().cpu(), preds.detach().cpu(), squared=False)\n        \n        self.print(f'Epoch {self.current_epoch}: Validation RMSE: {val_rmse:.4f}')\n\n        \n        self.log(\"val_rmse\", val_rmse, prog_bar=True, logger=True)\n        \n\n    def test_step(self, batch, batch_idx):\n        img, ftrs = batch\n        output = self.forward(img, ftrs)\n        \n        return output   \n\n    def configure_optimizers(self):\n\n        param_optimizer = list(self.model.named_parameters())\n        \n        # configuring parameters\n        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n        optimizer_parameters = [\n            {\n                \"params\": [\n                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n                ],\n                \"weight_decay\": Config['weight_decay'],\n            },\n            {\n                \"params\": [\n                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n                ],\n                \"weight_decay\": 0.0,\n            },\n        ]\n    \n        # we use adam optimizer with Cosine annealing LR\n        optimizer = Adam(optimizer_parameters, lr=Config['lr'])\n        \n        \n        scheduler = CosineAnnealingLR(optimizer,\n                              T_max=Config['T_max'],\n                              eta_min=Config['min_lr'],\n                              last_epoch=-1)\n\n        return dict(\n          optimizer=optimizer,\n          lr_scheduler=scheduler\n        )","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:12.991568Z","iopub.execute_input":"2021-09-27T05:44:12.992046Z","iopub.status.idle":"2021-09-27T05:44:13.029632Z","shell.execute_reply.started":"2021-09-27T05:44:12.992001Z","shell.execute_reply":"2021-09-27T05:44:13.02871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p p style = \"font-family: garamond; font-size:30px; font-style: normal;background-color: #f6f5f5; color :#6666ff; border-radius: 10px 10px; text-align:center\">Pytorch Lightning Trainer ‚ö°</p>\n\n<p style=\"font-family: garamound; font-size:20px;\" > Once you‚Äôve organized your PyTorch code into a LightningModule, the Trainer automates everything else.<br><br> This ensures following:<br><br>1. You maintain control over all aspects via PyTorch code without an added abstraction.<br>2. The trainer uses best practices embedded by contributors and users from top AI labs such as Facebook AI Research, NYU, MIT, Stanford, etc‚Ä¶<br>3. The trainer allows overriding any key part that you don‚Äôt want automated. <br> <br> While keeping track of RMSE we save the model checkpoints </p>","metadata":{}},{"cell_type":"code","source":"model = Trainer()\nTraining_metrics = []\n\nfor fold in Config['trn_folds']:\n      \n    print(f\"{'='*38} Fold: {fold} {'='*38}\")\n    \n    # create data module\n    data_module = PawpularityDModule(train, fold)\n    \n    # stop the training early\n    early_stopping_callback = EarlyStopping(monitor='val_rmse',mode=\"min\", patience=Config['patience_earlystop'])\n    \n    # store model checkpoints\n    checkpoint_callback = ModelCheckpoint(\n      dirpath=\"checkpoints\",\n      filename=\"best-checkpoint-{fold}-{val_rmse:.3f}\",\n      save_top_k = Config['epochs'],\n      verbose=True,\n      monitor=\"val_rmse\",\n      mode=\"min\"\n    )\n    \n    # define trainer\n    trainer = pl.Trainer(\n      gpus = 1,\n      checkpoint_callback=True,\n      callbacks=[early_stopping_callback,checkpoint_callback],\n      max_epochs = Config['epochs'],\n      precision = Config['precision'],\n      progress_bar_refresh_rate=1, \n      num_sanity_val_steps=1 if Config['debug'] else 0,\n      stochastic_weight_avg = True,\n    )\n    \n    # fit\n    trainer.fit(model, data_module) ","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:44:13.030719Z","iopub.execute_input":"2021-09-27T05:44:13.031097Z","iopub.status.idle":"2021-09-27T05:48:34.202059Z","shell.execute_reply.started":"2021-09-27T05:44:13.031064Z","shell.execute_reply":"2021-09-27T05:48:34.201148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls checkpoints","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:48:34.203533Z","iopub.execute_input":"2021-09-27T05:48:34.203905Z","iopub.status.idle":"2021-09-27T05:48:34.911161Z","shell.execute_reply.started":"2021-09-27T05:48:34.203863Z","shell.execute_reply":"2021-09-27T05:48:34.910322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p p style = \"font-family: garamond; font-size:30px; font-style: normal; color :#fcba03; border-radius: 10px 10px; text-align:center\">Acknowledgements</p>\n\n<p style=\"font-family: garamound; font-size:20px;\" > Some notebooks which were extemely helpful in the making of this - <br> <a href=\"https://www.kaggle.com/ligtfeather/pl-1fold-cqt-deepspeed-op-baseline-w-b-84\"> https://www.kaggle.com/ligtfeather/pl-1fold-cqt-deepspeed-op-baseline-w-b-84 </a> <br> <a href=\"https://www.kaggle.com/hmendonca/melanoma-neat-pytorch-lightning-native-amp\"> https://www.kaggle.com/hmendonca/melanoma-neat-pytorch-lightning-native-amp </a> <br>\n<a href=\"https://www.kaggle.com/abhishek/same-old-creating-folds\"> https://www.kaggle.com/abhishek/same-old-creating-folds </a> </p>\n\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}