{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder Competition PyTorch Lightning Training\n## Adapted from\n* [Train Baseline Torch Lightning + GPU&TPU + W&B](https://www.kaggle.com/heyytanay/train-baseline-torch-lightning-gpu-tpu-w-b)","metadata":{}},{"cell_type":"markdown","source":"## Changelog\n\n* V3 \n  - Add Efficientnet_b0 - b2\n  - Early stopping callback. \n  - Increased EPOCHS from 5 to 10\n  - Add augmentation:\n```python\n        A.ColorJitter(p=.2),\n        A.RandomGamma(p=.1),\n        A.Sharpen(p=.1),\n        A.Cutout(p=0.2),\n```\n\n* V2\n    - Save model with `torch.JIT.save`","metadata":{}},{"cell_type":"markdown","source":"## Install and import packages","metadata":{}},{"cell_type":"code","source":"# ! pip install -q torchtext\n! pip install -q torchtext==0.8.0 torch==1.7.1 pytorch-lightning==1.2.2\n# ! pip install -q pytorch-lightning==1.1.8\n! pip install -q timm\n! pip install -q albumentations\n! pip install -q --upgrade wandb","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:02:18.887765Z","iopub.execute_input":"2021-10-26T12:02:18.888365Z","iopub.status.idle":"2021-10-26T12:02:56.204505Z","shell.execute_reply.started":"2021-10-26T12:02:18.888214Z","shell.execute_reply":"2021-10-26T12:02:56.203262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nfrom pathlib import Path\n\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport timm\nimport torch\nimport transformers\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nimport os\nimport cv2\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nimport wandb\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\nimport albumentations as A\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-26T12:02:56.208495Z","iopub.execute_input":"2021-10-26T12:02:56.208858Z","iopub.status.idle":"2021-10-26T12:02:59.976268Z","shell.execute_reply.started":"2021-10-26T12:02:56.208821Z","shell.execute_reply":"2021-10-26T12:02:59.975226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = Path(\"../input/petfinder-pawpularity-score/\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nconfig = dict(\n    SEED =  42,\n    NFOLDS = 5,\n    EPOCHS = 10,\n    LR = 2e-4,\n    IMG_SIZE = (224, 224),\n#     MODEL_NAME = 'tf_efficientnet_b6_ns',\n    MODEL_NAME = timm.list_models(\"tf_efficientnet_b[0-9]\", pretrained=True)[:2],\n    DR_RATE = 0.35,\n    NUM_LABELS = 1,\n    TRAIN_BS = 32,\n    VALID_BS = 16,\n    min_lr = 1e-6,\n    T_max = 20,\n    T_0 = 25,\n    NUM_WORKERS = 4,\n    patience = 5,\n    infra = \"Kaggle\",\n    competition = 'petfinder',\n    _wandb_kernel = 'tanaym',\n    wandb = False\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:02:59.978408Z","iopub.execute_input":"2021-10-26T12:02:59.978756Z","iopub.status.idle":"2021-10-26T12:03:00.010055Z","shell.execute_reply.started":"2021-10-26T12:02:59.978711Z","shell.execute_reply":"2021-10-26T12:03:00.009018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:03:00.01185Z","iopub.execute_input":"2021-10-26T12:03:00.013105Z","iopub.status.idle":"2021-10-26T12:03:00.027143Z","shell.execute_reply.started":"2021-10-26T12:03:00.013061Z","shell.execute_reply":"2021-10-26T12:03:00.02607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset class","metadata":{}},{"cell_type":"code","source":"class PetfinderData(Dataset):\n    def __init__(self, df, is_test=False, augments=None):\n        self.df = df\n        self.is_test = is_test\n        self.augments = augments\n        \n        self.images, self.meta_features, self.targets = self._process_df(self.df)\n    \n    def __getitem__(self, index):\n        img = self.images[index]\n        meta_feats = self.meta_features[index]\n        meta_feats = torch.tensor(meta_feats, dtype=torch.float32)\n        \n        img = cv2.imread(img)\n#         print(f\"img shape 1 {img.shape}\")\n        img = img[:, :, ::-1]\n#         print(f\"img shape 2 {img.shape}\")\n        img = cv2.resize(img, config['IMG_SIZE'])\n        \n        if self.augments:\n            img = self.augments(image=img)['image']\n        \n        if not self.is_test:\n            target = torch.tensor(self.targets[index], dtype=torch.float32)\n            return img, meta_feats, target\n        else:\n            return img, meta_feats\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def _process_df(self, df):\n        \n        if not self.is_test:\n            df['Id'] = df['Id'].apply(lambda x: str(TRAIN_DIR / f\"{x}.jpg\"))\n            \n            meta_features = df.drop(['Id', 'Pawpularity'], axis=1).values\n\n            return df['Id'].tolist(), meta_features, df['Pawpularity'].tolist()            \n        else:\n            df['Id'] = df['Id'].apply(lambda x: str(TEST_DIR / f\"{x}.jpg\"))\n            \n            meta_features = df.drop(['Id'], axis=1).values\n\n            return df['Id'].tolist(), meta_features, None","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:03:00.031911Z","iopub.execute_input":"2021-10-26T12:03:00.03261Z","iopub.status.idle":"2021-10-26T12:03:00.048422Z","shell.execute_reply.started":"2021-10-26T12:03:00.032562Z","shell.execute_reply":"2021-10-26T12:03:00.046894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Augmentation","metadata":{}},{"cell_type":"code","source":"class Augments:\n    \"\"\"\n    Contains Train, Validation Augments\n    \"\"\"\n    train_augments = Compose([\n        Resize(*config['IMG_SIZE'], p=1.0),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        A.ColorJitter(p=.2),\n        A.RandomGamma(p=.1),\n        A.Sharpen(p=.1),\n        A.Cutout(p=0.2),\n        Normalize(\n            mean=[0.485, 0.456, 0.406], \n            std=[0.229, 0.224, 0.225], \n            max_pixel_value=255.0, \n            p=1.0\n        ),\n        ToTensorV2(p=1.0),\n    ],p=1.)\n    \n    valid_augments = Compose([\n        Resize(*config['IMG_SIZE'], p=1.0),\n        Normalize(\n            mean=[0.485, 0.456, 0.406], \n            std=[0.229, 0.224, 0.225], \n            max_pixel_value=255.0, \n            p=1.0\n        ),\n        ToTensorV2(p=1.0),\n    ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:03:00.050187Z","iopub.execute_input":"2021-10-26T12:03:00.052113Z","iopub.status.idle":"2021-10-26T12:03:00.063634Z","shell.execute_reply.started":"2021-10-26T12:03:00.052037Z","shell.execute_reply":"2021-10-26T12:03:00.06255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# timm.list_models(\"*swin*\", pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:03:00.065281Z","iopub.execute_input":"2021-10-26T12:03:00.066389Z","iopub.status.idle":"2021-10-26T12:03:00.078718Z","shell.execute_reply.started":"2021-10-26T12:03:00.066343Z","shell.execute_reply":"2021-10-26T12:03:00.07767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch Lightning Model Class","metadata":{}},{"cell_type":"code","source":"class PetFinderModel(pl.LightningModule):\n    def __init__(self, model_name='tf_efficientnet_b6_ns', pretrained=True):\n        super(PetFinderModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n#         freeze backbone \n        for module in self.model.children():\n                for param in module.parameters():\n                    param.requires_grad = False\n        \n        self.n_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.n_features + 12, config['NUM_LABELS'])\n        \n        self.train_loss = nn.MSELoss()\n        self.valid_loss = nn.MSELoss()\n\n    def forward(self, images, meta):\n        features = self.model(images)\n        features = torch.cat([features, meta], dim=1)\n        output = self.fc(features)\n        return output\n    \n    def training_step(self, batch, batch_idx):\n        imgs = batch[0]\n        meta = batch[1]\n        target = batch[2]\n        \n        out = self(imgs, meta)\n        train_loss = torch.sqrt(self.train_loss(out, target))\n        \n        logs = {'train_loss': train_loss}\n        \n        return {'loss': train_loss, 'log': logs}\n    \n    def test_step(self, batch, batch_idx):\n        imgs = batch[0]\n        meta = batch[1]\n#         target = batch[2]\n        \n        out = self(imgs, meta)\n        return {'test_loss': out}\n    \n    def test_epoch_end(self, outputs):\n        cat = torch.cat([x['test_loss'].squeeze() for x in outputs], axis=0)\n        avg_loss = torch.cat([x['test_loss'] for x in outputs], axis=0).mean()\n        logs = {'test_loss': cat}\n        return {'all': cat}\n\n    def validation_step(self, batch, batch_idx):\n        imgs = batch[0]\n        meta = batch[1]\n        target = batch[2]\n        \n        out = self(imgs, meta)\n        valid_loss = torch.sqrt(self.valid_loss(out, target))\n        \n        return {'val_loss': valid_loss}\n    \n    def validation_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        logs = {'val_loss': avg_loss}\n        \n        print(f\"val_loss: {avg_loss}\")\n        return {'avg_val_loss': avg_loss, 'log': logs}\n    \n    def configure_optimizers(self):\n        opt = torch.optim.Adam(self.parameters(), lr=config['LR'])\n        sch = torch.optim.lr_scheduler.CosineAnnealingLR(\n            opt, \n            T_max=config['T_max'],\n            eta_min=config['min_lr']\n        )\n        \n        return [opt], [sch]\n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:03:00.080759Z","iopub.execute_input":"2021-10-26T12:03:00.081582Z","iopub.status.idle":"2021-10-26T12:03:00.10292Z","shell.execute_reply.started":"2021-10-26T12:03:00.081536Z","shell.execute_reply":"2021-10-26T12:03:00.101586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"for idx, model_name in enumerate(config[\"MODEL_NAME\"]): \n    # Run the Kfolds training loop\n    kf = StratifiedKFold(n_splits=config['NFOLDS'], shuffle=True, random_state=config['SEED'])\n    train_file = pd.read_csv(DATA_DIR / \"train.csv\", \n#                              nrows=50\n                            )\n    test_df = pd.read_csv(DATA_DIR / \"test.csv\")\n\n    test_set = PetfinderData(\n        test_df,\n        is_test=True,\n        augments=Augments.valid_augments\n    )\n\n    test = DataLoader(\n        test_set,\n        batch_size=config['VALID_BS'],\n        shuffle=False,\n        num_workers=config['NUM_WORKERS']\n    )\n\n    set_seed(config['SEED'])\n\n    y_pred = []\n    final_test_predictions = []\n    final_valid_predictions = {}\n    scores = []\n    \n    t_1 = datetime.now()\n    for fold_, (train_idx, valid_idx) in enumerate(kf.split(X=train_file, y=train_file['Pawpularity'])):\n        t_2 = datetime.now()\n        print(f\"{'='*20} {model_name} Fold: {fold_} {'='*20}\")\n\n        train_df = train_file.loc[train_idx]\n        valid_df = train_file.loc[valid_idx]\n\n        valid_ids = valid_df.Id.values.tolist()\n\n        y_train = train_df.Pawpularity\n        y_valid = valid_df.Pawpularity\n\n        train_set = PetfinderData(\n            train_df,\n            augments = Augments.train_augments\n        )\n\n        valid_set = PetfinderData(\n            valid_df,\n            augments = Augments.valid_augments\n        )\n\n        train = DataLoader(\n            train_set,\n            batch_size=config['TRAIN_BS'],\n            shuffle=True,\n            num_workers=config['NUM_WORKERS'],\n            pin_memory=True\n        )\n        valid = DataLoader(\n            valid_set,\n            batch_size=config['VALID_BS'],\n            shuffle=False,\n            num_workers=config['NUM_WORKERS']\n        )\n\n        checkpoint_callback = ModelCheckpoint(\n            monitor=\"val_loss\",\n            dirpath=\"./\",\n            filename=f\"fold_{fold_}_{model_name}\",\n            save_top_k=1,\n            mode=\"min\",\n        )\n        es_callback = pl.callbacks.EarlyStopping(monitor='val_loss', \n                                                patience=config[\"patience\"], \n                                                mode='min')\n        model = PetFinderModel()\n        trainer = pl.Trainer(\n            max_epochs=config['EPOCHS'], \n            gpus=1, \n            callbacks=[es_callback, checkpoint_callback], \n    #         logger= wandb_logger\n        )\n        trainer.fit(model, train, valid)\n\n    #     validation predictions\n        valid_preds = []\n        _valid_preds = []\n        _ids = []\n        for idx, batch in enumerate(valid):\n            model.eval()\n            with torch.no_grad():\n                imgs, meta, target = batch[0], batch[1], batch[2]\n\n                tmp_pred = model(imgs, meta).cpu().numpy().squeeze()\n                valid_preds.extend(tmp_pred)\n                _ids.extend(target.numpy().tolist())\n    #     valid_preds.append(_valid_preds)\n        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n        ids = _ids\n\n\n    #     test predictions\n        test_preds = []\n        _test_preds = []\n        for idx, batch in enumerate(test):\n            model.eval()\n            with torch.no_grad():\n                imgs, meta = batch[0], batch[1]\n\n                tmp_pred = model(imgs, meta).cpu().numpy().squeeze()\n                test_preds.extend(tmp_pred)\n        y_pred.append(test_preds)\n\n        final_test_predictions.append(test_preds)\n        final_valid_predictions.update(dict(zip(valid_ids, valid_preds)))\n        print(f\"fold rmse -> fold: {fold_}, rmse: {rmse}\")\n        scores.append(rmse)\n\n    #     save a traced version of the best model\n        imgs = torch.randn(\n            2, 3, *config['IMG_SIZE'], dtype=torch.float32, requires_grad=True\n        )\n        meta = torch.randn(\n            2, 12, dtype=torch.float32, requires_grad=True\n        )\n        imgs, meta = imgs.to(device=DEVICE), meta.to(device=DEVICE)\n        with torch.no_grad():\n            traced_cell = torch.jit.trace(model.to(DEVICE).forward, (imgs, meta))\n        torch.jit.save(traced_cell, f\"fold_{fold_}_{model_name}_jit\")\n        elapsed_time_2 = datetime.now() - t_2\n        print(f\"Fold {fold_} took {elapsed_time_2} hh:mm:ss\")\n    \n    elapsed_time_1 = datetime.now() - t_1\n    print(f\"Model {model_name} took (hh:mm:ss.ms) {elapsed_time_1} hh:mm:ss\")\n\n    print(f\"scores {model_name} -> mean: {np.mean(scores)}, std: {np.std(scores)}\")\n    final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n    final_valid_predictions.columns = [\"Id\", \"Pawpularity\"]\n    final_valid_predictions.to_csv(f\"train_pred_{model_name}.csv\", index=False)\n    \n    sample_submission = pd.read_csv(f\"{DATA_DIR}/sample_submission.csv\")\n    sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n    sample_submission.columns = [\"Id\", \"Pawpularity\"]\n    sample_submission.to_csv(f\"test_pred_{model_name}.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T12:03:00.107125Z","iopub.execute_input":"2021-10-26T12:03:00.107426Z","iopub.status.idle":"2021-10-26T13:21:23.233618Z","shell.execute_reply.started":"2021-10-26T12:03:00.107367Z","shell.execute_reply":"2021-10-26T13:21:23.231824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(f\"{DATA_DIR}/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:21:23.235278Z","iopub.status.idle":"2021-10-26T13:21:23.237294Z","shell.execute_reply.started":"2021-10-26T13:21:23.236948Z","shell.execute_reply":"2021-10-26T13:21:23.236983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_df = pd.DataFrame(np.stack(y_pred, axis=1))\ny_pred_df[\"mean\"] = y_pred_df.mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:21:23.239055Z","iopub.status.idle":"2021-10-26T13:21:23.240006Z","shell.execute_reply.started":"2021-10-26T13:21:23.239622Z","shell.execute_reply":"2021-10-26T13:21:23.239656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_df.to_csv(\"y_pred.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:21:23.241733Z","iopub.status.idle":"2021-10-26T13:21:23.24266Z","shell.execute_reply.started":"2021-10-26T13:21:23.242334Z","shell.execute_reply":"2021-10-26T13:21:23.242366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"Pawpularity\"] = y_pred_df[\"mean\"]\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-10-26T13:21:23.244292Z","iopub.status.idle":"2021-10-26T13:21:23.245203Z","shell.execute_reply.started":"2021-10-26T13:21:23.244828Z","shell.execute_reply":"2021-10-26T13:21:23.244878Z"},"trusted":true},"execution_count":null,"outputs":[]}]}