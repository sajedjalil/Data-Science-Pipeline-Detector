{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pawpularity with EfficientNetB2 FineTuning\n\n## Table of Contents\n- Summary\n- Set up\n- Import datasets\n- Data Preprocessing\n- Model Development\n- Model Evaluation\n- Submission\n\n\n## Summary\nIn this Notebook, I will:\n* Use EfficientNetB2 as Image Model to fit on Image Data.\n* Use DNN as Tabular Model to fit on Tabular Data.\n* Combine the total result of Image Model and Tabular Model.\n* Use Data Augmentation and Regularization method to prevent overfiting.\n* Use K-Fold training to improve final score.\n\n## Set up","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:48.695355Z","iopub.execute_input":"2022-01-11T18:20:48.695707Z","iopub.status.idle":"2022-01-11T18:20:53.532481Z","shell.execute_reply.started":"2022-01-11T18:20:48.695625Z","shell.execute_reply":"2022-01-11T18:20:53.53177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import datasets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntest = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\nsample_submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.534097Z","iopub.execute_input":"2022-01-11T18:20:53.534337Z","iopub.status.idle":"2022-01-11T18:20:53.581422Z","shell.execute_reply.started":"2022-01-11T18:20:53.534304Z","shell.execute_reply":"2022-01-11T18:20:53.580773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.582635Z","iopub.execute_input":"2022-01-11T18:20:53.582897Z","iopub.status.idle":"2022-01-11T18:20:53.608049Z","shell.execute_reply.started":"2022-01-11T18:20:53.582856Z","shell.execute_reply":"2022-01-11T18:20:53.607293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"file_path\"] = train[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/train/\" + identifier + \".jpg\")\ntest[\"file_path\"] = test[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/test/\" + identifier + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.610016Z","iopub.execute_input":"2022-01-11T18:20:53.610269Z","iopub.status.idle":"2022-01-11T18:20:53.623289Z","shell.execute_reply.started":"2022-01-11T18:20:53.610237Z","shell.execute_reply":"2022-01-11T18:20:53.622645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.624418Z","iopub.execute_input":"2022-01-11T18:20:53.624757Z","iopub.status.idle":"2022-01-11T18:20:53.642162Z","shell.execute_reply.started":"2022-01-11T18:20:53.624722Z","shell.execute_reply":"2022-01-11T18:20:53.641454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of Pawpularities","metadata":{}},{"cell_type":"code","source":"train[\"Pawpularity\"].hist()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.644063Z","iopub.execute_input":"2022-01-11T18:20:53.644246Z","iopub.status.idle":"2022-01-11T18:20:53.876154Z","shell.execute_reply.started":"2022-01-11T18:20:53.644225Z","shell.execute_reply":"2022-01-11T18:20:53.875509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development","metadata":{}},{"cell_type":"code","source":"tabular_columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nimage_size = 260\nbatch_size = 128\nepochs = 10\nAUTO = tf.data.experimental.AUTOTUNE\noutput_dataset_path = \"/kaggle/input/pawpularity-with-efficientnetb2-finetuning-output/\"\nmodes = [\"training\", \"inference\"]\nmode = modes[1]\nis_trainging_mode = mode == modes[0]\nfolds = [0, 1, 2, 3, 4]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:24:45.489136Z","iopub.execute_input":"2022-01-11T18:24:45.489482Z","iopub.status.idle":"2022-01-11T18:24:45.497499Z","shell.execute_reply.started":"2022-01-11T18:24:45.48945Z","shell.execute_reply":"2022-01-11T18:24:45.496613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Blockout Augmentation","metadata":{}},{"cell_type":"code","source":"def random_erasing(img, sl=0.1, sh=0.2, rl=0.4, p=0.3):\n    h = tf.shape(img)[0]\n    w = tf.shape(img)[1]\n    c = tf.shape(img)[2]\n    origin_area = tf.cast(h*w, tf.float32)\n\n    e_size_l = tf.cast(tf.round(tf.sqrt(origin_area * sl * rl)), tf.int32)\n    e_size_h = tf.cast(tf.round(tf.sqrt(origin_area * sh / rl)), tf.int32)\n\n    e_height_h = tf.minimum(e_size_h, h)\n    e_width_h = tf.minimum(e_size_h, w)\n\n    erase_height = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_height_h, dtype=tf.int32)\n    erase_width = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_width_h, dtype=tf.int32)\n\n    erase_area = tf.zeros(shape=[erase_height, erase_width, c])\n    erase_area = tf.cast(erase_area, tf.uint8)\n\n    pad_h = h - erase_height\n    pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n    pad_bottom = pad_h - pad_top\n\n    pad_w = w - erase_width\n    pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n    pad_right = pad_w - pad_left\n\n    erase_mask = tf.pad([erase_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n    erase_mask = tf.squeeze(erase_mask, axis=0)\n    erased_img = tf.multiply(tf.cast(img,tf.float32), tf.cast(erase_mask, tf.float32))\n\n    return tf.cond(tf.random.uniform([], 0, 1) > p, lambda: tf.cast(img, img.dtype), lambda:  tf.cast(erased_img, img.dtype))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.88745Z","iopub.execute_input":"2022-01-11T18:20:53.887873Z","iopub.status.idle":"2022-01-11T18:20:53.900837Z","shell.execute_reply.started":"2022-01-11T18:20:53.887837Z","shell.execute_reply":"2022-01-11T18:20:53.900166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augment(image):\n    image = tf.image.random_flip_left_right(image)\n    image = random_erasing(image)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.902035Z","iopub.execute_input":"2022-01-11T18:20:53.902454Z","iopub.status.idle":"2022-01-11T18:20:53.91141Z","shell.execute_reply.started":"2022-01-11T18:20:53.902418Z","shell.execute_reply":"2022-01-11T18:20:53.910658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess funciton\nI am doing data augmentation on training preprocess function, so that when make evaluation on validation dataset and prediction on test dataset, data augmentation won't be triggered.","metadata":{}},{"cell_type":"code","source":"def preprocess_training(image_url, tabular):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = data_augment(image)\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    return (image, tabular[1:]), tf.cast(tabular[0], tf.float32)\n\ndef preprocess_validation(image_url, tabular):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    return (image, tabular[1:]), tf.cast(tabular[0], tf.float32)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.914273Z","iopub.execute_input":"2022-01-11T18:20:53.914614Z","iopub.status.idle":"2022-01-11T18:20:53.922473Z","shell.execute_reply.started":"2022-01-11T18:20:53.914559Z","shell.execute_reply":"2022-01-11T18:20:53.921751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The Base Model (Efficient Net)","metadata":{}},{"cell_type":"code","source":"def base_model():\n    efficient_net = tf.keras.applications.EfficientNetB2(\n        include_top = False, \n        input_shape = (image_size, image_size, 3)\n    )    \n    efficient_net.trainable = False\n    return efficient_net","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.923939Z","iopub.execute_input":"2022-01-11T18:20:53.924796Z","iopub.status.idle":"2022-01-11T18:20:53.933364Z","shell.execute_reply.started":"2022-01-11T18:20:53.924762Z","shell.execute_reply":"2022-01-11T18:20:53.932673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The Tabular Prediction Model","metadata":{}},{"cell_type":"markdown","source":"I wrote a notebook to find optimal Tabualr Prediciton Model [here](https://www.kaggle.com/lonnieqin/pawpularity-model-with-dnn-on-meta-data?scriptVersionId=79014727).","metadata":{}},{"cell_type":"code","source":"def get_tabular_model(inputs):\n    width = 32\n    depth = 3\n    activation = \"relu\"\n    kernel_regularizer = keras.regularizers.l2()\n    x = keras.layers.Dense(\n            width, \n            activation=activation,\n            kernel_regularizer=kernel_regularizer\n        )(inputs)\n    for i in range(depth):\n        if i == 0:\n            x = inputs\n        x = keras.layers.Dense(\n            width, \n            activation=activation,\n            kernel_regularizer=kernel_regularizer\n        )(x)\n        if (i + 1) % 3 == 0:\n            x = keras.layers.Concatenate()([x, inputs])\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.936226Z","iopub.execute_input":"2022-01-11T18:20:53.936419Z","iopub.status.idle":"2022-01-11T18:20:53.945069Z","shell.execute_reply.started":"2022-01-11T18:20:53.936399Z","shell.execute_reply":"2022-01-11T18:20:53.944295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    image_inputs = tf.keras.Input((image_size, image_size , 3))\n    tabular_inputs = tf.keras.Input(len(tabular_columns))\n    efficient_net = base_model()\n    image_x = efficient_net(image_inputs)\n    image_x = tf.keras.layers.GlobalAveragePooling2D()(image_x)\n    image_x = tf.keras.layers.Dropout(0.5)(image_x)\n    tabular_x = get_tabular_model(tabular_inputs)\n    x = tf.keras.layers.Concatenate(axis=1)([image_x, tabular_x])\n    output = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs=[image_inputs, tabular_inputs], outputs=[output])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.946425Z","iopub.execute_input":"2022-01-11T18:20:53.946803Z","iopub.status.idle":"2022-01-11T18:20:53.955013Z","shell.execute_reply.started":"2022-01-11T18:20:53.94677Z","shell.execute_reply":"2022-01-11T18:20:53.954309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Training\nI will use tensorflow Dataset here to preprocess and cache tensors, first epoch is very slow because it's preprocessing data; after that, it would be must faster.","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodels = []\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\nfor index, (train_indices, val_indices) in enumerate(kfold.split(train)):\n    if index not in folds: \n        continue\n    if not is_trainging_mode:\n        break\n    x_train = train.loc[train_indices, \"file_path\"]\n    tabular_train = train.loc[train_indices, [\"Pawpularity\"] + tabular_columns]\n    x_val= train.loc[val_indices, \"file_path\"]\n    tabular_val = train.loc[val_indices, [\"Pawpularity\"] + tabular_columns]\n    checkpoint_path = \"model_%d.h5\"%(index)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        checkpoint_path, \n        save_best_only=True\n    )\n    early_stop = tf.keras.callbacks.EarlyStopping(\n        min_delta=1e-4, \n        patience=10\n    )\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n        factor=0.3,\n        patience=2, \n        min_lr=1e-5\n    )\n    callbacks = [early_stop, checkpoint, reduce_lr]\n    \n    optimizer = tf.keras.optimizers.Adam(3e-4)\n    \n    train_ds = tf.data.Dataset.from_tensor_slices((x_train, tabular_train)).map(preprocess_training).shuffle(512).batch(batch_size).cache().prefetch(AUTO)\n    val_ds = tf.data.Dataset.from_tensor_slices((x_val, tabular_val)).map(preprocess_validation).batch(batch_size).cache().prefetch(AUTO)\n    model = keras.models.load_model(output_dataset_path +\"model_%d.h5\"%(index))\n    efficientnetb2 = model.get_layer(\"efficientnetb2\")\n    efficientnetb2.trainable = True\n    for i, layer in enumerate(efficientnetb2.layers):\n        if i < len(efficientnetb2.layers) - 20:\n            layer.trainable = False\n        else:\n            if type(layer) != keras.layers.BatchNormalization:\n                layer.trainable = True\n            else:\n                layer.trainable = False\n    rmse = tf.keras.metrics.RootMeanSquaredError(name=\"root_mean_squared_error\")\n    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\", \"mape\", rmse])\n    history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)\n    model.load_weights(checkpoint_path)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.956541Z","iopub.execute_input":"2022-01-11T18:20:53.956873Z","iopub.status.idle":"2022-01-11T18:20:53.985526Z","shell.execute_reply.started":"2022-01-11T18:20:53.956834Z","shell.execute_reply":"2022-01-11T18:20:53.984941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def preprocess_test_data(image_url, tabular):\n    print(image_url, tabular)\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    return (image, tabular), 0","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.986645Z","iopub.execute_input":"2022-01-11T18:20:53.986876Z","iopub.status.idle":"2022-01-11T18:20:53.992275Z","shell.execute_reply.started":"2022-01-11T18:20:53.986837Z","shell.execute_reply":"2022-01-11T18:20:53.991619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = tf.data.Dataset.from_tensor_slices((test[\"file_path\"], test[tabular_columns])).map(preprocess_test_data).batch(batch_size).cache().prefetch(AUTO)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:20:53.993639Z","iopub.execute_input":"2022-01-11T18:20:53.994193Z","iopub.status.idle":"2022-01-11T18:20:55.935743Z","shell.execute_reply.started":"2022-01-11T18:20:53.99416Z","shell.execute_reply":"2022-01-11T18:20:55.934929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_results = []\nif is_trainging_mode:\n    for model in models:\n        total_results.append(model.predict(test_ds).reshape(-1))\nelse:\n    for i in folds:\n        model = keras.models.load_model(output_dataset_path +\"model_%d.h5\"%(i))\n        total_results.append(model.predict(test_ds).reshape(-1))\nresults = np.mean(total_results, axis=0).reshape(-1)\nsample_submission[\"Pawpularity\"] = results\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:24:51.30513Z","iopub.execute_input":"2022-01-11T18:24:51.305384Z","iopub.status.idle":"2022-01-11T18:24:51.33474Z","shell.execute_reply.started":"2022-01-11T18:24:51.305358Z","shell.execute_reply":"2022-01-11T18:24:51.333736Z"},"trusted":true},"execution_count":null,"outputs":[]}]}