{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder (PyTorch + Albumentations) ðŸ¶\n\n> ## (A beginer/learner approach)\n>  #### Task : Given images and raw data try to predict the **Pawpularity** i.e the perception of consumer that he/she/they can get attracted and thus adopt them.\n\n","metadata":{}},{"cell_type":"markdown","source":"## This notebook will cover :-\n> #### 1. Data Preprocessing (How to deal with image classification data)\n> #### 2. Preparing data for PyTorch utils (Datasets and Dataloaders etc.)\n> #### 3. Image Augmentations using Albumentations (and how to incorporate with your training data)\n> #### 4. Modeling and Validations (using PyTorch mainly)\n> #### 5. Preparing data for submissions\n> #### 6. Trying more deep stuff (More techniques such as stacking or trying advanced notebooks techniques from others ðŸ˜)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader\nimport albumentations\nfrom albumentations.pytorch import ToTensorV2\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.695688Z","iopub.execute_input":"2021-11-21T23:10:39.695971Z","iopub.status.idle":"2021-11-21T23:10:39.700811Z","shell.execute_reply.started":"2021-11-21T23:10:39.695939Z","shell.execute_reply":"2021-11-21T23:10:39.700215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.701874Z","iopub.execute_input":"2021-11-21T23:10:39.70256Z","iopub.status.idle":"2021-11-21T23:10:39.730995Z","shell.execute_reply.started":"2021-11-21T23:10:39.702532Z","shell.execute_reply":"2021-11-21T23:10:39.730334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.732457Z","iopub.execute_input":"2021-11-21T23:10:39.733286Z","iopub.status.idle":"2021-11-21T23:10:39.746482Z","shell.execute_reply.started":"2021-11-21T23:10:39.733225Z","shell.execute_reply":"2021-11-21T23:10:39.745654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.747633Z","iopub.execute_input":"2021-11-21T23:10:39.74831Z","iopub.status.idle":"2021-11-21T23:10:39.764473Z","shell.execute_reply.started":"2021-11-21T23:10:39.748251Z","shell.execute_reply":"2021-11-21T23:10:39.763677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.766508Z","iopub.execute_input":"2021-11-21T23:10:39.766722Z","iopub.status.idle":"2021-11-21T23:10:39.77858Z","shell.execute_reply.started":"2021-11-21T23:10:39.766695Z","shell.execute_reply":"2021-11-21T23:10:39.777802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Little preprocessing","metadata":{}},{"cell_type":"code","source":"# for getting filename\ndef file_path(name):\n    folder = \"../input/petfinder-pawpularity-score/train\"\n    filename = str(name) + '.jpg'\n    path = os.path.join(folder, str(filename))\n    return path","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.779693Z","iopub.execute_input":"2021-11-21T23:10:39.779912Z","iopub.status.idle":"2021-11-21T23:10:39.788493Z","shell.execute_reply.started":"2021-11-21T23:10:39.779885Z","shell.execute_reply":"2021-11-21T23:10:39.787558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Appending file path in Dataframe\ntrain_df['image_path'] = train_df['Id'].apply(lambda x: file_path(x))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.789669Z","iopub.execute_input":"2021-11-21T23:10:39.790329Z","iopub.status.idle":"2021-11-21T23:10:39.826421Z","shell.execute_reply.started":"2021-11-21T23:10:39.790262Z","shell.execute_reply":"2021-11-21T23:10:39.825454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making a Pytorch dataset class","metadata":{}},{"cell_type":"code","source":"class pet_dataset:\n    def __init__(self, image_paths, targets, augmentations):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        target = self.targets[idx]\n        image = cv2.imread(self.image_paths[idx])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image = image)\n            image = augmented[\"image\"]\n        \n        image = np.transpose(image, (2,0,1))\n        return {\n            \"image\": torch.tensor(image),\n            \"target\": torch.tensor(target)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.827878Z","iopub.execute_input":"2021-11-21T23:10:39.828166Z","iopub.status.idle":"2021-11-21T23:10:39.835599Z","shell.execute_reply.started":"2021-11-21T23:10:39.828125Z","shell.execute_reply":"2021-11-21T23:10:39.834772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Albumentations (Will try more operations too still learning ðŸ˜…)\n### Various Operations tried\n> * Shifting scale\n> * Random Cropping\n> * Centre Cropping\n> * Horizontal Flip (Avoiding Vertical coz that doesn't make sense in pet data)\n> * RGB shift\n> * Transforms such as Channel Shuffle, Inversion, Blur, Colorjitter\n> * Can try more random stuff\n","metadata":{}},{"cell_type":"code","source":"augmentations = albumentations.Compose(\n    [\n        albumentations.SmallestMaxSize(max_size = 750),\n        albumentations.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=20, p=0.5, border_mode= cv2.BORDER_CONSTANT),\n        albumentations.OneOf(\n            [\n                albumentations.RandomCrop(height = 720, width =720, p = 0.7 ),\n                albumentations.CenterCrop(height= 720, width = 720, p =0.3)\n            ], p = 1.0\n        ),\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.5),\n        albumentations.RandomBrightnessContrast(p=0.5),\n        albumentations.OneOf(\n            [\n                albumentations.Blur(blur_limit = 3, p=0.5),\n                albumentations.ColorJitter(p=0.5)\n            ], p = 0.5\n        ),\n        albumentations.OneOf(\n            [\n                albumentations.ChannelShuffle(p = 0.5),\n                albumentations.InvertImg(p = 0.5)\n            ], p = 0.25\n        ),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.83685Z","iopub.execute_input":"2021-11-21T23:10:39.837662Z","iopub.status.idle":"2021-11-21T23:10:39.849476Z","shell.execute_reply.started":"2021-11-21T23:10:39.837622Z","shell.execute_reply":"2021-11-21T23:10:39.848855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = np.array(train_df['image_path'])\ntargets = np.array(train_df['Pawpularity'])\ntrain_dataset = pet_dataset(images, targets, augmentations)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.85066Z","iopub.execute_input":"2021-11-21T23:10:39.851088Z","iopub.status.idle":"2021-11-21T23:10:39.859203Z","shell.execute_reply.started":"2021-11-21T23:10:39.851043Z","shell.execute_reply":"2021-11-21T23:10:39.858619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 3, ncols = 5, figsize = (20,10))\nplt.suptitle(\"Given Pictures\", fontsize = 16)\n\nfor i in range(0,15):\n    image = cv2.imread(train_df['image_path'][i])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n    x = i//5\n    y = i%5\n        \n    axes[x, y].imshow(image, cmap = plt.cm.bone)\n    axes[x, y].axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:39.861794Z","iopub.execute_input":"2021-11-21T23:10:39.862522Z","iopub.status.idle":"2021-11-21T23:10:42.45712Z","shell.execute_reply.started":"2021-11-21T23:10:39.862478Z","shell.execute_reply":"2021-11-21T23:10:42.456161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 3, ncols = 5, figsize = (20,10))\nplt.suptitle(\"Augmented Pictures\", fontsize = 16)\n\nfor i in range(0,15):\n    image = train_dataset[i]['image'].permute(1,2,0)\n        \n    x = i//5\n    y = i%5\n        \n    axes[x, y].imshow(image, cmap = plt.cm.bone)\n    axes[x, y].axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T23:10:42.458203Z","iopub.execute_input":"2021-11-21T23:10:42.458474Z","iopub.status.idle":"2021-11-21T23:10:44.80391Z","shell.execute_reply.started":"2021-11-21T23:10:42.458444Z","shell.execute_reply":"2021-11-21T23:10:44.802776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Work under construction... (Model Training, validation, tuning, different augmentation techniques etc.)\n\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}