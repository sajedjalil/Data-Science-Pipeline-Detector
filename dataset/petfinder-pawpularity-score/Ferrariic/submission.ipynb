{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport random as rand\nimport math\nimport time\nimport glob\nimport pickle\nimport scipy\nimport cv2\nimport re\nimport plotly.express as px\nimport collections\nimport seaborn as sns\nimport pydot\nimport graphviz\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import RobustScaler, Normalizer\nfrom tensorflow.keras import Sequential\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Conv2D, MaxPooling2D, Flatten, concatenate, add\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model\n\n!pip install keras_tuner\nimport keras_tuner as kt","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-11-07T07:42:20.704556Z","iopub.execute_input":"2021-11-07T07:42:20.704906Z","iopub.status.idle":"2021-11-07T07:42:57.151516Z","shell.execute_reply.started":"2021-11-07T07:42:20.70481Z","shell.execute_reply":"2021-11-07T07:42:57.150734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Images","metadata":{}},{"cell_type":"code","source":"train_path = '../input/petfinder-pawpularity-score/train/*.jpg'\ntest_path = '../input/petfinder-pawpularity-score/test/*.jpg'\ntrain_csv_path = '../input/petfinder-pawpularity-score/train.csv'\ntest_csv_path = '../input/petfinder-pawpularity-score/test.csv'\n\ntrain_images = glob.glob(train_path)\ntest_images = glob.glob(test_path)\ndf_train = pd.read_csv(train_csv_path )\ndf_test = pd.read_csv(test_csv_path)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:42:57.154995Z","iopub.execute_input":"2021-11-07T07:42:57.155328Z","iopub.status.idle":"2021-11-07T07:42:57.430223Z","shell.execute_reply.started":"2021-11-07T07:42:57.15527Z","shell.execute_reply":"2021-11-07T07:42:57.429535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"df_examine = df_train.drop(['Id','Pawpularity'],axis=1).value_counts()\ndf_examine = df_examine.reset_index().rename(columns={0:'Count'})\n\ndf_train.drop(columns=['Id'],axis=1)\ncolumns = list(df_examine.columns)\ncolumns.remove('Count')\n\nk_values = []\nfor row in df_examine[columns].values:\n    mask = df_train[columns].values == row\n    k = df_train[mask.all(axis=1)]['Pawpularity'].mean()\n    k_values.append(k)\n\ndf_examine['k_values'] = k_values\ndf_examine.corr().to_csv('./correlation.csv')\ncorr = df_examine.corr()['k_values']\n\n# finds columns where < 5% contributuion is found to the K-value score. ex. 95% probably that they don't have an effect on the pawpularity scoring metric\nmask = corr.between(-0.05, 0.05) \ncolumns_to_remove = list(corr[mask].index)\ncolumns_to_remove.remove('Count')\ncolumns_to_remove","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:42:57.431489Z","iopub.execute_input":"2021-11-07T07:42:57.431749Z","iopub.status.idle":"2021-11-07T07:42:57.722652Z","shell.execute_reply.started":"2021-11-07T07:42:57.431721Z","shell.execute_reply":"2021-11-07T07:42:57.722016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sq_shape = 128\n\nclass Preprocess:\n    \n    def __init__(self, df, images, columns_to_remove=columns_to_remove, sq_shape=128, is_test=0):\n        self.df = df.drop(columns=columns_to_remove, axis=1)\n        self.images = images\n        self.sq_shape = sq_shape\n        self.is_test = is_test\n        self.X = None\n        self.y = None\n        self.X_meta = None\n        \n        \n    def __process_image(self, image):\n        im = cv2.imread(image, cv2.IMREAD_GRAYSCALE) #reads image as greyscale\n        im = cv2.resize(im, (self.sq_shape, self.sq_shape)) # resizes to 256 x 256 for processing speed\n        im = im/255 # normalizes\n        return im\n        \n    def compile(self):\n\n        self.X = []\n        self.X_meta = []\n        if not self.is_test:\n            self.y = []\n\n        for image_number, image in enumerate(self.images):\n            image_name = image[image.rfind('/')+1:image.rfind('.')]\n            mask = self.df['Id'] == image_name\n            im = self.__process_image(image)\n\n            if self.is_test:\n                X_meta_data = self.df[mask].drop(columns=['Id'],axis=1).values[0]\n            else:\n                Pawpularity_score = self.df[mask]['Pawpularity'].values[0]\n                X_meta_data = self.df[mask].drop(columns=['Pawpularity','Id'],axis=1).values[0]\n                \n            self.X.append(im)\n            self.X_meta.append(X_meta_data)\n            if not self.is_test:\n                self.y.append(Pawpularity_score)\n\n            clear_output(wait=True)\n            print(f'{round(image_number/len(self.images)*100,4)}%, {image_name}')\n\n        self.X = np.asarray(self.X)\n        self.X_meta = np.asarray(self.X_meta)\n        \n        if not self.is_test:\n            self.y = np.asarray(self.y) #/100 \n        \n        if self.is_test:\n            print(\"Processed Testing Data\")\n        else:\n            print(\"Processed Training Data\")\n        return self.X, self.X_meta, self.y\n        \npp_train = Preprocess(df=df_train, images=train_images, columns_to_remove=columns_to_remove, sq_shape=sq_shape, is_test=0)\nX, X_meta, y = pp_train.compile()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:42:57.72475Z","iopub.execute_input":"2021-11-07T07:42:57.725147Z","iopub.status.idle":"2021-11-07T07:45:19.987985Z","shell.execute_reply.started":"2021-11-07T07:42:57.725111Z","shell.execute_reply":"2021-11-07T07:45:19.987181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_meta_train, X_meta_test, y_meta_train, y_meta_test = train_test_split(X_meta, y, test_size=0.2, random_state=42)\n\nprint('Image train',X_train.shape, y_train.shape)\nprint('Image test',X_test.shape, y_test.shape)\n\nprint('Meta train', X_meta_train.shape, y_meta_train.shape)\nprint('Meta test', X_meta_test.shape, y_meta_test.shape)\n\nprint(y_train[:10],y_meta_train[:10])","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:45:19.989491Z","iopub.execute_input":"2021-11-07T07:45:19.989969Z","iopub.status.idle":"2021-11-07T07:45:20.352888Z","shell.execute_reply.started":"2021-11-07T07:45:19.98993Z","shell.execute_reply":"2021-11-07T07:45:20.352161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Define Model","metadata":{}},{"cell_type":"code","source":"def model_builder(hp):\n\n    \"\"\"\n        Image model & Categorical Data Combination Functional API Model\n    \"\"\"\n    min_node = 8\n    max_node = 1000\n    step_size = 20\n    # Image Data\n    image_input = Input(shape=(sq_shape, sq_shape, 1))\n    x = Conv2D(hp.Int('C_1', min_value=min_node, max_value=max_node, step=step_size), kernel_size=4, activation='relu')(image_input)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(0.1)(x)\n    x = Conv2D(hp.Int('C_2', min_value=min_node, max_value=max_node, step=step_size), kernel_size=4, activation='relu')(x)\n    x = Conv2D(hp.Int('C_3', min_value=min_node, max_value=max_node, step=step_size), kernel_size=4, activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(0.1)(x)\n    x = Conv2D(hp.Int('C_4', min_value=min_node, max_value=max_node, step=step_size), kernel_size=4, activation='relu')(x)\n    x = Conv2D(hp.Int('C_5', min_value=min_node, max_value=max_node, step=step_size), kernel_size=4, activation='relu')(x)\n    x = Conv2D(hp.Int('C_6', min_value=min_node, max_value=max_node, step=step_size), kernel_size=4, activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(0.1)(x)\n    image_arm = Flatten()(x)\n\n    # Categorical & Meta Data\n    columns = X_meta_train.shape[1]\n    meta_input = Input(shape=(columns))\n    y = Dense(hp.Int('N_Dense_1', min_value=min_node, max_value=max_node, step=step_size), activation='relu')(meta_input)\n    y = Dense(hp.Int('N_Dense_2', min_value=min_node, max_value=max_node, step=step_size), activation='relu')(y)\n    y = Dense(hp.Int('N_Dense_3', min_value=min_node, max_value=max_node, step=step_size), activation='relu')(y)\n    y = Dense(hp.Int('N_Dense_4', min_value=min_node, max_value=max_node, step=step_size), activation='relu')(y)\n    meta_arm = Dense(10, activation='relu')(y)\n\n    # Merging arms of Model\n    merge = concatenate([image_arm, meta_arm])\n\n    # Finalization and Output\n    z = Dense(hp.Int('N_Dense_5', min_value=min_node, max_value=max_node, step=step_size), activation='relu')(merge)\n    z = Dense(hp.Int('N_Dense_6', min_value=min_node, max_value=max_node, step=step_size), activation='relu')(z)\n    output = Dense(1, activation='linear')(z)\n\n    # Initialize Model as model\n    model = Model(inputs=[image_input, meta_input], outputs=output)\n\n    # Compile Model\n    \n    model.compile(loss='mse', optimizer='adam', metrics=['mean_absolute_percentage_error'])\n    print(model.summary())\n    plot_model(model, to_file=f'./{sq_shape}x{sq_shape}_{columns}_paw_model_design.png')\n    return model\n\ntuner = kt.Hyperband(model_builder,\n                     objective='mean_absolute_percentage_error',\n                     max_epochs=10,\n                     factor=3,\n                     directory='./',\n                     project_name='Paw_model_final')\nprint(\"Model Established\")","metadata":{"execution":{"iopub.status.busy":"2021-11-07T08:08:18.825201Z","iopub.execute_input":"2021-11-07T08:08:18.825501Z","iopub.status.idle":"2021-11-07T08:08:19.533161Z","shell.execute_reply.started":"2021-11-07T08:08:18.825462Z","shell.execute_reply":"2021-11-07T08:08:19.531539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit Model","metadata":{}},{"cell_type":"code","source":"# Adds Early Stopping\ncallback = tf.keras.callbacks.EarlyStopping(monitor=\"mean_absolute_percentage_error\", patience=5, restore_best_weights=True, verbose=1)\n\ntuner.search(\n    [X_train, X_meta_train], y_train,\n    validation_data=([X_test, X_meta_test], y_test),\n    batch_size = 1,\n    shuffle=True,\n    callbacks=[callback],\n    verbose=1\n    )","metadata":{"execution":{"iopub.status.busy":"2021-11-07T08:08:59.083249Z","iopub.execute_input":"2021-11-07T08:08:59.084207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pick Best Model","metadata":{}},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]\nprint(\"Model Loaded\")","metadata":{"execution":{"iopub.status.busy":"2021-11-07T08:07:20.192343Z","iopub.status.idle":"2021-11-07T08:07:20.193287Z","shell.execute_reply.started":"2021-11-07T08:07:20.193046Z","shell.execute_reply":"2021-11-07T08:07:20.193072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate Model","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict([X_test, X_meta_test])\nsns.displot(y_pred)\nsns.displot(y_test)\n\nprint(y_pred, y_test)\nprint(y_pred.max(),y_pred.min())\n\n#with open('./y_pred', 'wb') as pickle_file:\n#    pickle.dump(y_pred, pickle_file)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T08:07:20.194383Z","iopub.status.idle":"2021-11-07T08:07:20.195322Z","shell.execute_reply.started":"2021-11-07T08:07:20.195084Z","shell.execute_reply":"2021-11-07T08:07:20.195109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Example Test [WIP Below]","metadata":{}},{"cell_type":"code","source":"def model_adjusted(prediction, y_pred):\n    min_val = y_pred.min()\n    max_val = (y_pred - y_pred.min()).max()\n    output = ((prediction - min_val)/max_val)*100\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:45:21.893785Z","iopub.status.idle":"2021-11-07T07:45:21.894333Z","shell.execute_reply.started":"2021-11-07T07:45:21.894106Z","shell.execute_reply":"2021-11-07T07:45:21.89413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"model.save(f'./{sq_shape}x{sq_shape}_{columns}_paw_model.h5')\nprint(f\"Model Saved as: {sq_shape}x{sq_shape}_{columns}_paw_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:45:21.89544Z","iopub.status.idle":"2021-11-07T07:45:21.895996Z","shell.execute_reply.started":"2021-11-07T07:45:21.895758Z","shell.execute_reply":"2021-11-07T07:45:21.895784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Training Data","metadata":{}},{"cell_type":"code","source":"model_path = './64x64_greyscaled_paw.h5'\npred_path = './y_pred'\n\npre_trained_model = tf.keras.models.load_model(model_path)\n\nwith open(pred_path, 'rb') as pickle_file:\n    y_pred = pickle.load(pickle_file)\ny_pred\n\n# df_final = pd.DataFrame(zip(Name, outputs)).rename(columns={0:'Id',1:'Pawpularity'}).set_index('Id')\n# df_final.to_csv('submission.csv')\n# df_final","metadata":{"execution":{"iopub.status.busy":"2021-11-07T07:45:21.89712Z","iopub.status.idle":"2021-11-07T07:45:21.897653Z","shell.execute_reply.started":"2021-11-07T07:45:21.897424Z","shell.execute_reply":"2021-11-07T07:45:21.89745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}