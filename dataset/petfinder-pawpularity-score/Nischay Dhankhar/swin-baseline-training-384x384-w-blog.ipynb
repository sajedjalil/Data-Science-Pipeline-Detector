{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Complete training code is explained on the Jarvislabs [Blog](https://jarvislabs.ai/blogs/pet)** \n\nAlso please lower down the batch size if you're planning to training on kaggle.","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master') ## Importing Timm Library","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import fastai\nimport os\nimport warnings\nfrom pprint import pprint\nfrom glob import glob\nfrom tqdm import tqdm\nfrom fastai.vision.all import *\nimport torch\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom timm import create_model\nfrom sklearn.model_selection import StratifiedKFold\nfrom torchvision.io import read_image\nfrom torch.utils.data import DataLoader, Dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport albumentations\n\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\nimport random\n\nimport timm\nimport cv2\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nmodel_output = '/kaggle/working/models/exp0'\nif not os.path.exists(model_output):\n    os.makedirs(model_output)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    model_name='swin_base_patch4_window12_384'\n    pretrained = True\n    train_dir = '../input/petfinder-pawpularity-score/train' # Train Image Directory\n    train_csv = '../input/abhi-folds-petfinder/train_10folds.csv' # Train Csv Location\n    image_size= 384\n    epochs=10\n    num_workers=8\n    targets = 1\n    lr=5e-5\n    batch_size=16\n    weight_decay=1e-4\n    seed=42\n    n_fold=10\n    trn_fold=[0, 1, 2, 3,4,5,6,7,8,9]\n    train=True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=Config.seed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetDataset:\n    def __init__(self, df,image_path, augmentations):\n        self.image_path = image_path\n        self.df = df\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, item):\n        id_ = self.df.Id.iloc[item]\n        path = f'{self.image_path}/{id_}.jpg'\n\n        targets = self.df.Pawpularity.iloc[item] #/100.\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)#.numpy()\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        image = torch.tensor(image, dtype=torch.float) \n        \n#         targets = targets[item]\n        targets = torch.tensor(targets, dtype=torch.float) / 100\n        return image, targets\n            ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(*, data):\n    \n    if data == 'train':\n        return albumentations.Compose(\n                transforms=[\n                albumentations.RandomResizedCrop(Config.image_size, Config.image_size, scale=(0.85, 1.0)),\n\n               albumentations.HorizontalFlip(p=0.5),\n               albumentations.ShiftScaleRotate(p=0.5),\n               albumentations.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1,p=0.4),\n               albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n               albumentations.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n               albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),    \n#             ToTensorV2(),\n\n                \n                ])\n\n    elif data == 'valid':\n        return albumentations.Compose([\n            albumentations.Resize(Config.image_size, Config.image_size),\n            albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),           \n#         ToTensorV2(),\n\n        ])\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        self.eps = eps\n\n    def forward(self, yhat, y):\n        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n        return loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PetModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        self.backbone = timm.create_model(self.config.model_name, pretrained=self.config.pretrained)\n        self.n_features = self.backbone.head.in_features\n        self.backbone.head = nn.Identity()\n        self.fc = nn.Linear(self.n_features, self.config.targets)\n        \n    def forward(self, image):\n#         print('done')\n        feature = self.backbone(image)\n        output = self.fc(feature)\n#         print('done2')\n\n\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# m = PetModel(Config)\n# # \n# del m","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cell\ndef mse(inp,targ):\n    \"Mean squared error between `inp` and `targ`.\"\n    return F.mse_loss(*flatten_check(inp,targ))\n\n# Cell\ndef _rmse(inp, targ): return 100*torch.sqrt(F.mse_loss(F.sigmoid(inp.flatten()), targ))\nrmse = AccumMetric(_rmse)\nrmse.__doc__ = \"rrr\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(Config):\n    for fold_num in Config.trn_fold:    \n        print('*****************************************')\n        print(f'Training Fold {fold_num}')\n        print('*****************************************')\n\n        kernel_type = model_output\n        df = pd.read_csv(Config.train_csv)[['Id', 'Pawpularity', 'kfold']]\n        df['is_valid'] = df.kfold.apply(lambda x: x==fold_num)\n#         df = df.sample(1000)\n\n        training_fold = df.query('is_valid==False').reset_index(drop=True, inplace=False)\n        train_ds = PetDataset(training_fold,Config.train_dir,augmentations = get_transforms(data='train'))\n\n        validation_fold = df.query('is_valid==True').reset_index(drop=True, inplace=False)\n        valid_ds = PetDataset(validation_fold,Config.train_dir,augmentations = get_transforms(data='valid'))\n\n        print(f'- Training samples: {len(train_ds)}\\n- Validation Samples : {len(valid_ds)}')\n\n        bs = Config.batch_size\n        train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, num_workers=Config.num_workers,pin_memory=False)\n        valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs*2, num_workers=Config.num_workers,shuffle=False,pin_memory=False)\n\n        dls = DataLoaders(train_dl, valid_dl)\n        rmse = AccumMetric(_rmse)\n\n\n        model = PetModel(Config)\n\n\n        early_stop = EarlyStoppingCallback(monitor='petfinder_rmse', min_delta=0.1, patience=5)\n        save_callback = SaveModelCallback('petfinder_rmse', every_epoch=True)\n        logger = CSVLogger(f'{model_output}/{fold_num}logs.csv')\n        learn = Learner(dls, model, loss_func=BCEWithLogitsLossFlat(), metrics=[_rmse],cbs=[early_stop,save_callback,logger]).to_fp16()\n\n        learn.fit_one_cycle(Config.epochs, Config.lr, wd=Config.weight_decay)\n\n        learn.save(f'{kernel_type}/fold_{fold_num}')\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run(Config)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}