{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn import model_selection\nimport gc\nfrom fastai.vision.all import *","metadata":{"execution":{"iopub.status.busy":"2022-01-11T06:15:12.356481Z","iopub.execute_input":"2022-01-11T06:15:12.357398Z","iopub.status.idle":"2022-01-11T06:15:15.182906Z","shell.execute_reply.started":"2022-01-11T06:15:12.357276Z","shell.execute_reply":"2022-01-11T06:15:15.182162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","metadata":{"execution":{"iopub.status.busy":"2022-01-11T06:15:15.184783Z","iopub.execute_input":"2022-01-11T06:15:15.185032Z","iopub.status.idle":"2022-01-11T06:15:15.190673Z","shell.execute_reply.started":"2022-01-11T06:15:15.184997Z","shell.execute_reply":"2022-01-11T06:15:15.189932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n    os.makedirs('/root/.cache/torch/hub/checkpoints/')\n!cp '../input/swin-transformer/swin_large_patch4_window7_224_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window7_224_22kto1k.pth'","metadata":{"execution":{"iopub.status.busy":"2022-01-11T06:15:15.192135Z","iopub.execute_input":"2022-01-11T06:15:15.192648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nfrom timm import create_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best ensamble","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(999, reproducible=True)\nBATCH_SIZE = 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check what data is available to us:","metadata":{"editable":false,"id":"sqWTG_VQj7tE"}},{"cell_type":"code","source":"dataset_path = Path('../input/petfinder-pawpularity-score/')\ndataset_path.ls()","metadata":{"editable":false,"id":"1QnC7Qo9j7tE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(dataset_path/'train.csv')\ntrain_df.head()","metadata":{"editable":false,"id":"n-5L27Q6j7tG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['path'] = train_df['Id'].map(lambda x:str(dataset_path/'train'/x)+'.jpg')\ntrain_df = train_df.drop(columns=['Id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head()","metadata":{"editable":false,"id":"NMzpvBHIj7tJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay, let's check how many images are available in the training dataset:","metadata":{"editable":false,"id":"CvII9oKTj7tJ"}},{"cell_type":"code","source":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")","metadata":{"editable":false,"id":"qGrQFO4_j7tK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check the distribution of the Pawpularity Score:","metadata":{"editable":false,"id":"vCEtwcCCj7tK"}},{"cell_type":"code","source":"train_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")","metadata":{"editable":false,"id":"4c2S0hgQj7tL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")","metadata":{"editable":false,"id":"PQ67-1dZj7tM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that the Pawpularity score is an integer, so in addition to being a regression problem, it could also be treated as a 100-class classification problem. Alternatively, it can be treated as a binary classification problem if the Pawpularity Score is normalized between 0 and 1:","metadata":{"editable":false,"id":"5lOzT0Fdj7tM"}},{"cell_type":"code","source":"train_df['norm_score'] = train_df['Pawpularity']/100\ntrain_df['norm_score']","metadata":{"editable":false,"id":"zaBelTLwj7tN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check an example image to see what it looks like:","metadata":{"editable":false,"id":"rDu5zNF5j7tN"}},{"cell_type":"code","source":"im = Image.open(train_df['path'][1])\nwidth, height = im.size\nprint(width,height)","metadata":{"editable":false,"id":"7nd404vgj7tO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im","metadata":{"editable":false,"id":"z96aEMCpj7tO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data loading\nAfter my quick 'n dirty EDA, let's load the data into fastai as DataLoaders objects. We're using the normalized score as the label. I use some fairly basic augmentations here.","metadata":{"editable":false,"id":"QhfVV0xwj7tO"}},{"cell_type":"code","source":"if not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n    os.makedirs('/root/.cache/torch/hub/checkpoints/')\n!cp '../input/swin-large-transformer/swin_large_patch4_window12_384_22kto1k.pth' '/root/.cache/torch/hub/checkpoints/swin_large_patch4_window12_384_22kto1k.pth'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n# num_bins","metadata":{"editable":false,"id":"92Itv1pWj7tP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","metadata":{"editable":false,"id":"XMPQgZPLj7tP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\n\nN_FOLDS = 5\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['fold']==0].head()","metadata":{"editable":false,"id":"z2oQWJnvj7tQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['fold']==0]['bins'].value_counts()","metadata":{"editable":false,"id":"cM6QMjT2j7tQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['fold']==1]['bins'].value_counts()","metadata":{"editable":false,"id":"mCwZ7PKjj7tR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","metadata":{"editable":false,"id":"JkeSgkc3j7tR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data_384(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n                               valid_col='is_valid', #\n                               seed=999, #seed\n                               fn_col='path', #filename/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               shuffle=False,\n                               item_tfms=Resize(384), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n    \n    return dls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data_224(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n                               valid_col='is_valid', #\n                               seed=999, #seed\n                               fn_col='path', #filename/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               shuffle=False,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n    \n    return dls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Valid Kfolder size\nthe_data = get_data_384(0)\n#assert (len(the_data.train) + len(the_data.valid)) == (len(train_df)//BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_learner_384(fold_num):\n    data = get_data_384(fold_num)\n    \n    model = create_model('swin_large_patch4_window12_384', pretrained=True, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse)\n    \n    return learn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_learner_224(fold_num):\n    data = get_data_224(fold_num)\n    \n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse)\n    \n    return learn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(dataset_path/'test.csv')\ntest_df.head()","metadata":{"editable":false,"id":"gCTeqy-Oj7tS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path/'test'/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\ntrain_df['norm_score'] = train_df['Pawpularity']/100","metadata":{"editable":false,"id":"Oj7Z63mqj7tT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get_learner(fold_num=0).lr_find(end_lr=3e-2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc","metadata":{"editable":false,"id":"kCCC4Ysaj7tT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class eval_after_N_steps(Callback):\n    \n    def __init__(self,fold=None,n_step=None,start_epoch=0):\n        self.counter = 0\n        self.start_epoch = start_epoch\n        self.n_step = n_step\n        self.fold = fold\n        self.best_rmse = 100000000\n        \n    def before_batch(self):\n        self.counter = self.counter + 1\n        if self.fold != None:\n            if self.counter % self.n_step == 0 and int(self.counter/247) >= self.start_epoch :\n                preds_list = []\n                targ_list = []\n                current_rmse_loss_list = []\n                with torch.no_grad(): \n                    for xb,yb in learn.dls.valid:\n                        preds = self.learn.model(xb)\n                        current_rmse_loss_list.append(petfinder_rmse(preds,yb))\n                    current_rmse_loss_array = np.array(current_rmse_loss_list,dtype='float')\n                    current_rmse_loss = np.mean(current_rmse_loss_array)\n                if current_rmse_loss < self.best_rmse:\n                    self.best_rmse = current_rmse_loss\n                    self.save(f'best_model_fold_{self.fold}')\n                    print(f'best_rmse ----> {self.best_rmse}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def petfinder_diff(input,target):\n    return torch.sum((100*((input.flatten()-target)))**2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('../input/petfinder-pawpularity-score/test')) == 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = []\nimport numpy as np\nimport joblib\n# Both import methods supported\nfrom cuml import Ridge\nfrom cuml.linear_model import Ridge\n\nif len(os.listdir('../input/petfinder-pawpularity-score/test')) == 8:\n    debug = True\nelse:\n    debug = False\n    \nfor i in range(N_FOLDS):\n    #swin 384\n    print(f'Fold {i} results')\n    print('swin_384')\n    if i == 2:\n        learn = get_learner_384(fold_num=i)    \n        state = torch.load(f'../input/transformer384-fold2/best_model_fold_2.pth')  \n    else:\n        learn = get_learner_384(fold_num=i)    \n        state = torch.load(f'../input/transformer384-fold{i}/models/best_model_fold_{i}.pth')          \n    learn.model.load_state_dict(state['model'])\n    #learn = learn.to_fp32()\n    \n    #learn.export(f'model_fold_{i}.pkl')\n    #learn.save(f'model_fold_{i}.pkl')\n    \n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               fn_col='path', #filename/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               shuffle=False,\n                               item_tfms=Resize(384), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n\n    #val_preds, targs = learn.tta(n=10,beta=0.07)\n    #print(f'rmse fold-{i}={rmse(100*val_preds,100*targs)}')\n    #if len(os.listdir('../input/petfinder-pawpularity-score/test')) == 8:\n    test_dl = dls.test_dl(test_df)\n    test_dl_384 = dls.test_dl(test_df)\n    (preds_test_384_tta,preds_test_384), _ = learn.tta(dl=test_dl_384, n=4,beta=None)\n\n    ###########  ensambling svr-head-preds with swin384-preds #############  \n    \n    def get_activation(name):\n        def hook(model, input, output):\n            activation[name] = output.detach()\n        return hook\n    \n    activation = {}\n    fold_activation = []\n    targs = []\n    preds_test = np.array([])\n    extra_test_features = test_dl.items.iloc[:,:-2].values    \n    with torch.no_grad(): \n         for n,xb in enumerate(test_dl):\n              xb = xb[0]\n              learn.model.avgpool.register_forward_hook(get_activation('avgpool'))\n              preds = learn.model(xb)\n              preds_test =  np.concatenate((preds_test,preds.cpu().data.numpy().reshape(-1)),axis=0)\n              if n == len(test_dl) - 1:\n                 if xb.shape[0] == BATCH_SIZE:\n                    fold_activation.append(activation['avgpool'].cpu().data.numpy())\n                    fold_activation_array = np.array(fold_activation)\n                    fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n                    \n                 else:\n                    \n                    if debug == True:\n                        fold_activation.append(activation['avgpool'].cpu().data.numpy()) \n                        fold_activation_array = np.array(fold_activation)\n                        fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n\n                    else:\n                        fold_activation_array = np.array(fold_activation)\n                        fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n                        last_batch_activations = activation['avgpool'].cpu().data.numpy().reshape(-1,fold_activation_array.shape[1])\n                        fold_activation_array = np.concatenate((fold_activation_array,last_batch_activations),axis=0)\n              else:\n                  fold_activation.append(activation['avgpool'].cpu().data.numpy())\n    X_test =  np.concatenate((fold_activation_array,extra_test_features),axis=1)             \n    NN_preds = 1/(1 + np.exp(- preds_test))                         \n    svr_model = joblib.load(f'../input/petfindder-swin-384-svr-training-with-extra-data/svr_head_model_swin384_fold{i}')\n    svr_preds = svr_model.predict(X_test)\n    svr_preds_head_swin384 = svr_preds\n    ridge = joblib.load(f'../input/petfindder-swin-384-svr-training-with-extra-data/blender_model_for_svr_NN_swin384_fold{i}')\n    X_test =  np.concatenate((svr_preds.reshape(-1,1),NN_preds.reshape(-1,1),extra_test_features),axis=1) \n    blender_svr_and_swin384_test_preds = ridge.predict(X_test)   \n    \n\n    del learn ,ridge, svr_model ,X_test ,NN_preds ,activation ,fold_activation ,extra_test_features ,preds_test\n    torch.cuda.empty_cache()\n    gc.collect()\n   \n    #swin 224\n    print('without_svr_head')\n    learn = get_learner_224(fold_num=i)    \n    state = torch.load(f'../input/swintransformermodels/models/best_model_fold_{i}.pth')\n    learn.model.load_state_dict(state['model'])\n    learn.model.cuda()\n    #learn = learn.to_fp32()\n    #learn.export(f'model_fold_{i}.pkl')\n    #learn.save(f'model_fold_{i}.pkl')\n    \n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               fn_col='path', #filename/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               shuffle=False,\n                               num_workers=8,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n    #val_preds, targs = learn.tta(n=10,beta=0.07)\n    #print(f'rmse fold-{i}={rmse(100*val_preds,100*targs)}')\n    #if len(os.listdir('../input/petfinder-pawpularity-score/test')) == 8:\n    test_dl = dls.test_dl(test_df)\n    test_dl_224 = dls.test_dl(test_df)\n    (preds_test_224_tta,preds_test_224), _ = learn.tta(dl=test_dl_224, n=4,beta=None)\n    ################# ensambling svr-head preds and  swin-224 preds ##################   \n\n    activation = {}\n    fold_activation = []\n    targs = []\n    preds_test = np.array([])\n    extra_test_features = test_dl.items.iloc[:,:-2].values    \n    with torch.no_grad(): \n         for n,xb in enumerate(test_dl):\n              xb = xb[0]\n              learn.model.avgpool.register_forward_hook(get_activation('avgpool'))\n              preds = learn.model(xb)\n              preds_test =  np.concatenate((preds_test,preds.cpu().data.numpy().reshape(-1)),axis=0)\n              if n == len(test_dl) - 1:\n                 if xb.shape[0] == BATCH_SIZE:\n                    fold_activation.append(activation['avgpool'].cpu().data.numpy())\n                    fold_activation_array = np.array(fold_activation)\n                    fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n                    \n                 else:\n                    \n                    if debug == True:\n                        fold_activation.append(activation['avgpool'].cpu().data.numpy()) \n                        fold_activation_array = np.array(fold_activation)\n                        fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n\n                    else:\n                        fold_activation_array = np.array(fold_activation)\n                        fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n                        last_batch_activations = activation['avgpool'].cpu().data.numpy().reshape(-1,fold_activation_array.shape[1])\n                        fold_activation_array = np.concatenate((fold_activation_array,last_batch_activations),axis=0)\n              else:\n                  fold_activation.append(activation['avgpool'].cpu().data.numpy())\n    X_test =  np.concatenate((fold_activation_array,extra_test_features),axis=1)             \n    NN_preds = 1/(1 + np.exp(- preds_test))                         \n    svr_model = joblib.load(f'../input/fork-of-swin-224-svr-training-meta-data/svr_head_model_swin224_fold{i}')\n    svr_preds = svr_model.predict(X_test)\n    svr_preds_head_swin224 = svr_preds\n    ridge = joblib.load(f'../input/fork-of-swin-224-svr-training-meta-data/blender_model_for_svr_NN_swin224_fold{i}')\n    X =  np.concatenate((svr_preds.reshape(-1,1),NN_preds.reshape(-1,1),extra_test_features),axis=1) \n    blender_svr_and_swin224_test_preds = ridge.predict(X)   \n      \n\n    del learn ,ridge, svr_model \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    #ensamble    \n    print('ensamble')\n    result_ridge = joblib.load(f'../input/best-ensamble-with-training-blender/final_blender_model_fold{i}')\n    X = pd.DataFrame()\n    X['preds_test_224'] = np.array(preds_test_224).reshape(-1)\n    X['svr_preds_head_swin224'] = np.array(svr_preds_head_swin224).reshape(-1)\n    X['preds_test_224_tta'] = np.array(preds_test_224_tta).reshape(-1)\n\n    X['preds_test_384'] = np.array(preds_test_384).reshape(-1)\n    X['svr_preds_head_swin384'] = np.array(svr_preds_head_swin384).reshape(-1)\n    X['preds_test_384_tta'] = np.array(preds_test_384_tta).reshape(-1)\n\n    meta_cols = ['Subject_Focus','Eyes','Face','Near','Action','Accessory','Group','Collage','Human','Occlusion','Info','Blur']    \n    X[meta_cols] = np.array(extra_test_features)\n    \n    all_preds.append(X.values)\n    del activation, fold_activation ,fold_activation_array ,X_test ,preds_test_224 ,preds_test_384 ,blender_svr_and_swin224_test_preds ,blender_svr_and_swin384_test_preds\n    gc.collect()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.mean(np.stack(all_preds), axis=0)\nX_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_ridge  = joblib.load(f'../input/best-ensamble-with-training-final-blender/final_blender_model')\nfinal_preds = result_ridge.predict(X_test)\npreds = final_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_2 = preds*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#psudo_labeling","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path('../input/petfinder-pawpularity-score')\ndf_train = pd.read_csv(path/'train.csv')\ndf_test  = pd.read_csv(path/'test.csv')\ndf_train.Id = df_train.Id.map(lambda x:str(path) + '/train/' + x + '.jpg')\ndf_test.Id = df_test.Id.map(lambda x:str(path) + '/test/' + x + '.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['min_Pawpularity'] = df_train['Pawpularity']\ndf_train['max_Pawpularity'] = df_train['Pawpularity']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['Pawpularity'] = preds_2\nmin_test_Pawpularity = []\nmax_test_Pawpularity = []\nfor pred in list(preds_2):\n    if pred - 4 >= 0: \n        if pred + 4 <= 100:\n            min_test_Pawpularity.append(pred - 4)\n            max_test_Pawpularity.append(pred + 4)\n        else:\n            min_test_Pawpularity.append(pred - 4 - (pred + 4 - 100))\n            max_test_Pawpularity.append(100.0)            \n    else:\n        min_test_Pawpularity.append(0)\n        max_test_Pawpularity.append(pred + 4 - (pred - 4))     \ndf_test['min_Pawpularity'] = np.array(min_test_Pawpularity).reshape(-1)\ndf_test['max_Pawpularity'] = np.array(max_test_Pawpularity).reshape(-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ymin = 0.00001\nymax = 100\n\nclass scaledSigmoid(nn.Module):\n    def forward(self, input):\n        return torch.sigmoid(input) * (ymax - ymin) + ymin\n\nclass clampedReLU(nn.Module):\n    def forward(self, input):\n        bottomClamp = input < ymin\n        topClamp = input > ymax\n        input[bottomClamp,] = ymin\n        input[topClamp,] = ymax\n        return input\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def petfinder_rmse(input,target,segmoid=True):\n    if segmoid == True:\n        return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n    else:\n        return 100*torch.sqrt(F.mse_loss(input.flatten(), target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_with_psudolabel = pd.concat((df_train,df_test),axis=0)\ndef get_x(r):return r['Id']\ndef get_y(r):return random.choice(list(np.arange(r['min_Pawpularity'],r['max_Pawpularity'] + 1)))/100\ndef get_dls(bs,size,df,mult=1):\n        dblock = DataBlock(blocks=(ImageBlock, RegressionBlock), #pass in train DataFrame\n                                   splitter=IndexSplitter([1]),\n                                   get_x=get_x, #filename/path is in the second column of the DataFrame\n                                   get_y=get_y, #label is in the first column of the DataFrame\n                                   item_tfms=Resize(224), #pass in item_tfms\n                                   batch_tfms=setup_aug_tfms([Flip()]))\n        dls = dblock.dataloaders(data_with_psudolabel,bs=bs)\n        dsets = dblock.datasets(data_with_psudolabel)\n        return dls,dsets\ndls_psudolabel,dsets = get_dls(bs=8,size=224,df=data_with_psudolabel)\ndls_psudolabel.train.one_batch()[0].shape\ndls_psudolabel.show_batch()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if df_test.shape[0] == 8:\n    debug=False\nelse:\n    debug=True\n\nif debug == True:\n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=1)\n    learn = Learner(dls_psudolabel,model,loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse)\n    learn.unfreeze()\n    learn.fit_one_cycle(17,2e-5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug == True:\n    test_dls = dls_psudolabel.test_dl(df_test)\n    preds_1 = learn.get_preds(dl=test_dls)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug == True:\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv(dataset_path/'sample_submission.csv')\nif debug == True:\n     sample_df['Pawpularity'] = 0.9 * preds_2 + 0.1 * np.array(preds_1[0]*100).reshape(-1) \nelse:\n     sample_df['Pawpularity'] = preds_2\n   \nsample_df.to_csv('submission.csv',index=False)\npd.read_csv('submission.csv').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}