{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"\\n... IMPORTS STARTING ...\\n\")\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t– TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t– TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t– NUMPY VERSION: {np.__version__}\");\nimport sklearn; print(f\"\\t\\t– SKLEARN VERSION: {sklearn.__version__}\");\nfrom sklearn.preprocessing import RobustScaler, PolynomialFeatures\nfrom sklearn.model_selection import GroupKFold, KFold;\n\n!pip install -q keras-cv-attention-models\nimport keras_cv_attention_models\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom multiprocessing import cpu_count\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport sklearn\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\nimport plotly\nimport PIL\nimport cv2\n\n\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n    \nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n    \nprint(\"\\n... SEEDING FOR DETERMINISTIC BEHAVIOUR ...\\n\")\nseed_it_all()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:35:38.696394Z","iopub.execute_input":"2021-10-11T22:35:38.696788Z","iopub.status.idle":"2021-10-11T22:35:50.445697Z","shell.execute_reply.started":"2021-10-11T22:35:38.69672Z","shell.execute_reply":"2021-10-11T22:35:50.444705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \nexcept ValueError:\n    TPU = None\n\nif TPU:\n    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n    # Yield the default distribution strategy in Tensorflow\n    #   --> Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy() \n\n# What Is a Replica?\n#    --> A single Cloud TPU device consists of FOUR chips, each of which has TWO TPU cores. \n#    --> Therefore, for efficient utilization of Cloud TPU, a program should make use of each of the EIGHT (4x2) cores. \n#    --> Each replica is essentially a copy of the training graph that is run on each core and \n#        trains a mini-batch containing 1/8th of the overall batch size\nN_REPLICAS = strategy.num_replicas_in_sync\n    \nprint(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\n\nprint(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:35:50.451505Z","iopub.execute_input":"2021-10-11T22:35:50.452363Z","iopub.status.idle":"2021-10-11T22:35:56.236809Z","shell.execute_reply.started":"2021-10-11T22:35:50.452315Z","shell.execute_reply":"2021-10-11T22:35:56.235338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n\nif TPU:\n    # Google Cloud Dataset path to training and validation images\n    DATA_DIR = KaggleDatasets().get_gcs_path('petfinder-pawpularity-score')\n    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\nelse:\n    # Local path to training and validation images\n    DATA_DIR = \"/kaggle/input/petfinder-pawpularity-score\"\n    save_locally = None\n    \nprint(f\"\\n... DATA DIRECTORY PATH IS:\\n\\t--> {DATA_DIR}\")\n\nprint(f\"\\n... IMMEDIATE CONTENTS OF DATA DIRECTORY IS:\")\nfor file in tf.io.gfile.glob(os.path.join(DATA_DIR, \"*\")): print(f\"\\t--> {file}\")\n    \nprint(\"\\n\\n... DATA ACCESS SETUP COMPLETED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:35:56.23859Z","iopub.execute_input":"2021-10-11T22:35:56.238966Z","iopub.status.idle":"2021-10-11T22:35:57.525495Z","shell.execute_reply.started":"2021-10-11T22:35:56.238915Z","shell.execute_reply":"2021-10-11T22:35:57.524354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n... XLA OPTIMIZATIONS STARTING ...\\n\")\n\nprint(f\"\\n... CONFIGURE JIT (JUST IN TIME) COMPILATION ...\\n\")\n# enable XLA optmizations (10% speedup when using @tf.function calls)\ntf.config.optimizer.set_jit(True)\n\nprint(f\"\\n... XLA OPTIMIZATIONS COMPLETED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:35:57.528105Z","iopub.execute_input":"2021-10-11T22:35:57.52841Z","iopub.status.idle":"2021-10-11T22:35:57.534668Z","shell.execute_reply.started":"2021-10-11T22:35:57.528378Z","shell.execute_reply":"2021-10-11T22:35:57.53363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... BASIC DATA SETUP STARTING ...\\n\\n\")\n\nprint(\"\\n... TRAIN DATAFRAME ..\\n\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\ntrain_df[\"img_path\"] = train_df.Id.apply(lambda x: os.path.join(DATA_DIR, \"train\", x+\".jpg\"))\ntrain_df[\"Q\"] = pd.qcut(train_df['Pawpularity'], q = 15, labels = range(15))\ndisplay(train_df)\n\nprint(\"\\n... TEST DATAFRAME ..\\n\")\nTEST_CSV = os.path.join(DATA_DIR, \"test.csv\")\ntest_df = pd.read_csv(TEST_CSV)\ntest_df[\"img_path\"] = test_df.Id.apply(lambda x: os.path.join(DATA_DIR, \"test\", x+\".jpg\"))\n\ndisplay(test_df)\n\nprint(\"\\n... SAMPLE SUBMISSION DATAFRAME ..\\n\")\nSS_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\nss_df = pd.read_csv(SS_CSV)\ndisplay(ss_df)\n\n# Set Other Variables\nprint(\"\\n... SETTING OTHER VARIABLES ..\\n\")\n\nINPUT_SHAPE = (240, 240, 3)\nN_CLASSES = train_df.Pawpularity.nunique()\nREPLICA_BATCH_SIZE = 8\nOVERALL_BATCH_SIZE = REPLICA_BATCH_SIZE * N_REPLICAS\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(\"\\n\\n... BASIC DATA SETUP FINISHING ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:35:57.536603Z","iopub.execute_input":"2021-10-11T22:35:57.537048Z","iopub.status.idle":"2021-10-11T22:36:06.988031Z","shell.execute_reply.started":"2021-10-11T22:35:57.536979Z","shell.execute_reply":"2021-10-11T22:36:06.987147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\ndef tf_load_image(image, resize_to=INPUT_SHAPE):\n    image = tf.image.decode_jpeg(tf.io.read_file(image), channels=INPUT_SHAPE[-1])\n    image = tf.image.resize(image, size=resize_to[:-1])\n    return image\n\ndef rotate_and_crop(images):\n    \"\"\"Rotate the given image with the given rotation degree and crop for the black edges if necessary\n    Args:\n        image: A `Tensor` representing an image(s) of arbitrary size.\n    \n    Returns:\n        A rotated image.\n    \"\"\"\n    \n    \n    def _largest_rotated_rect(w, h, angle):\n        \"\"\"\n        \n        Given a rectangle of size wxh that has been rotated by 'angle' (in\n        radians), computes the width and height of the largest possible\n        axis-aligned rectangle within the rotated rectangle.\n        Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n        Converted to Python by Aaron Snoswell\n        \n        Source: http://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders\n        \n        \"\"\"\n        \n        quadrant = tf.cast(tf.math.floor(angle / (math.pi/2)), dtype=tf.uint8)\n        quadrant = tf.bitwise.bitwise_and(quadrant, tf.constant(3, dtype=quadrant.dtype))\n        sign_alpha = tf.cond(tf.bitwise.bitwise_and(quadrant, tf.constant(1, dtype=quadrant.dtype))==tf.constant(0, dtype=quadrant.dtype), lambda: angle, lambda: math.pi-angle)\n        alpha = (sign_alpha % math.pi + math.pi) % math.pi\n\n        bb_w = w * tf.math.cos(alpha) + h * tf.math.sin(alpha)\n        bb_h = w * tf.math.sin(alpha) + h * tf.math.cos(alpha)\n\n        gamma = tf.cond(w<h, lambda: tf.math.atan2(bb_w, bb_w), lambda: tf.math.atan2(bb_w, bb_w))\n\n        delta = math.pi - alpha - gamma\n\n        length = tf.cond(w<h, lambda: h, lambda: w)\n\n        d = length * tf.math.cos(alpha)\n        a = d * tf.math.sin(alpha) / tf.math.sin(delta)\n\n        y = a * tf.math.cos(gamma)\n        x = y * tf.math.tan(gamma)\n\n        return (bb_w - 2 * x, bb_h - 2 * y)\n  \n    # Get desired output dimensions\n    output_height, output_width = tf.constant(INPUT_SHAPE[0], dtype=tf.float32), tf.constant(INPUT_SHAPE[1], dtype=tf.float32)\n\n    rotation_degree = (math.pi/180)*tf.random.normal(shape=(), stddev=10)\n    images = tfa.image.rotate(images, rotation_degree, interpolation='BILINEAR')\n\n    # Center crop to ommit black noise on the edges\n    lrr_width, lrr_height = _largest_rotated_rect(output_height, output_width, rotation_degree)\n    lrr_offset_w, lrr_offset_h = tf.cast(tf.math.round((output_width-lrr_width)/2), dtype=tf.int32), tf.cast(tf.math.round((output_height-lrr_height)/2), dtype=tf.int32)\n    lrr_width, lrr_height = tf.cast(tf.math.round(lrr_width), dtype=tf.int32), tf.cast(tf.math.round(lrr_height), dtype=tf.int32)\n\n    images = tf.image.crop_to_bounding_box(images, lrr_offset_h, lrr_offset_w, target_height=lrr_height, target_width=lrr_width)\n    images = tf.image.resize(images, (output_height, output_width))\n    \n    return images\n\n\ndef simple_augmentation(images, labels):\n    # Random Horizontal Flip\n    images = tf.image.random_flip_left_right(images)\n    \n    # images = rotate_and_crop(images)\n    \n    images = tfa.image.random_cutout(images, mask_size=(2*(INPUT_SHAPE[0]//30),2*(INPUT_SHAPE[0]//30)))\n    \n    # Random Saturation\n    images = tf.image.random_saturation(images, 0.975, 1.025)\n\n    # Random Hue\n    images = tf.image.random_hue(images, 0.0125)\n    \n    # Random Brightness\n    images = tf.image.random_brightness(images, 0.125)\n    \n    return images, labels","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:36:06.989886Z","iopub.execute_input":"2021-10-11T22:36:06.990236Z","iopub.status.idle":"2021-10-11T22:36:07.01512Z","shell.execute_reply.started":"2021-10-11T22:36:06.990191Z","shell.execute_reply":"2021-10-11T22:36:07.014281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple Augmentation","metadata":{}},{"cell_type":"code","source":"PLT_N = 4\nplt.figure(figsize=(20,12))\nfor i in range(PLT_N):\n    o_img = tf_load_image(train_df.sample(1).img_path.values[0])\n    a_img = simple_augmentation(tf.expand_dims(o_img, axis=0), None)[0][0]\n    plt.subplot(2,4,i+1)\n    plt.imshow(o_img/255.)\n    plt.title(\"Original Image\", fontweight=\"bold\")\n    plt.axis(False)\n    \n    plt.subplot(2,4,i+5)\n    plt.imshow(a_img/255.)\n    plt.title(\"Random Augmentation\", fontweight=\"bold\")\n    plt.axis(False)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:36:07.016475Z","iopub.execute_input":"2021-10-11T22:36:07.016801Z","iopub.status.idle":"2021-10-11T22:36:09.220912Z","shell.execute_reply.started":"2021-10-11T22:36:07.016758Z","shell.execute_reply":"2021-10-11T22:36:09.218842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function To Create Splits","metadata":{}},{"cell_type":"code","source":"N_FOLDS = 8\nkf = KFold(n_splits=N_FOLDS)\n\ndataset_folds = {}\nfor i, (train_indices, val_indices) in enumerate(kf.split(X=train_df[\"img_path\"], y=train_df[\"Pawpularity\"])):\n    SUB_TRAIN_IMG_PATH_DS = train_df.iloc[train_indices].img_path.values\n    SUB_TRAIN_LABEL_DS = train_df.iloc[train_indices].Pawpularity.values.astype(np.float32)\n    \n    SUB_VAL_IMG_PATH_DS = train_df.iloc[val_indices].img_path.values\n    SUB_VAL_LABEL_DS = train_df.iloc[val_indices].Pawpularity.values.astype(np.float32)\n    \n    sub_train_img_ds = tf.data.Dataset.from_tensor_slices(SUB_TRAIN_IMG_PATH_DS)\n    sub_train_img_ds = sub_train_img_ds.map(tf_load_image, num_parallel_calls=tf.data.AUTOTUNE).cache()\n    sub_train_lbl_ds = tf.data.Dataset.from_tensor_slices(SUB_TRAIN_LABEL_DS)\n    sub_train_ds = tf.data.Dataset.zip((sub_train_img_ds, sub_train_lbl_ds))\n    sub_train_ds = sub_train_ds.shuffle((len(train_df)//N_FOLDS)*(N_FOLDS-1)) \n    sub_train_ds = sub_train_ds.batch(OVERALL_BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n    sub_train_ds = sub_train_ds.map(simple_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    sub_val_img_ds = tf.data.Dataset.from_tensor_slices(SUB_VAL_IMG_PATH_DS)\n    sub_val_img_ds = sub_val_img_ds.map(tf_load_image, num_parallel_calls=tf.data.AUTOTUNE).cache()\n    sub_val_lbl_ds = tf.data.Dataset.from_tensor_slices(SUB_VAL_LABEL_DS)\n    sub_val_ds = tf.data.Dataset.zip((sub_val_img_ds, sub_val_lbl_ds))\n    sub_val_ds = sub_val_ds.shuffle(len(train_df)//N_FOLDS) \n    sub_val_ds = sub_val_ds.batch(OVERALL_BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n\n    dataset_folds[f\"fold_{i}\"] = {\"train_ds\":sub_train_ds, \"val_ds\":sub_val_ds}\n\ntest_img_ds = tf.data.Dataset.from_tensor_slices(test_df.img_path.values)\ntest_ds = test_img_ds.map(tf_load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(OVERALL_BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\ndataset_folds","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:36:09.222762Z","iopub.execute_input":"2021-10-11T22:36:09.223063Z","iopub.status.idle":"2021-10-11T22:36:11.881759Z","shell.execute_reply.started":"2021-10-11T22:36:09.223028Z","shell.execute_reply":"2021-10-11T22:36:11.880779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function To Grab A Keras Model","metadata":{}},{"cell_type":"code","source":"def get_keras_cv_model(bb, pp_fn, make_trainable=False, input_shape=INPUT_SHAPE, head_size=64, dropout_rate=0.3, print_summary=True):\n    \"\"\"\n    \n    Function to get a custom model. This function allows for any model from the \n    keras applications library of models.\n    \n    Args:\n        bb (tf.keras.applications.<model> functional backbone):\n            The specific model backbone function to use (from tf.keras API)\n        pp_fn (tf.keras.applications.<model>.preprocess_input):\n            The specific preprocessing function to use (from tf.keras API)\n        make_trainable (optional, bool):\n            Whether or not to set the bulk of the model to be trainable\n        input_shape(optional, tuple of ints):\n            A tuple of integers describing the input shape the model should expect\n        head_size(optional, int): \n            The number of nodes in the final head FC layer\n        dropout_rate(optional, float): \n            The dropout to be applied between the final head layer and \n            the classification/regression output layer\n        print_summary(optional, bool):\n            Whether or not to print the model summary\n        \n    Returns:\n        Custom model for petfinder\n    \n    \"\"\"\n    # Get the backbone\n    bb_submodel = bb(include_top=False, weights=\"imagenet\", input_shape=INPUT_SHAPE, pooling=\"avg\")\n    \n    # Set trainability\n    if not make_trainable:\n        bb_submodel.trainable=False\n    \n    # Define functional model\n    _inputs = tf.keras.layers.Input(input_shape)\n    preprocessed_inputs = pp_fn(_inputs)\n    \n    x = bb_submodel(preprocessed_inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(head_size, activation='relu')(x)\n    x = tf.keras.layers.Dropout(dropout_rate)(x)\n    _outputs = tf.keras.layers.Dense(1, activation=\"relu\")(x)\n    \n    _model = tf.keras.Model(inputs=_inputs, outputs=_outputs)\n    if print_summary:\n        print(_model.summary())\n    return _model","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:36:57.174212Z","iopub.execute_input":"2021-10-11T22:36:57.174558Z","iopub.status.idle":"2021-10-11T22:36:57.18651Z","shell.execute_reply.started":"2021-10-11T22:36:57.174521Z","shell.execute_reply":"2021-10-11T22:36:57.185464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try With Fold 0","metadata":{}},{"cell_type":"code","source":"N_EPOCHS=25\n\nMODELS_TO_TEST = [\n    tf.keras.applications.EfficientNetB1,\n    tf.keras.applications.MobileNetV2,\n    tf.keras.applications.ResNet50,\n    tf.keras.applications.DenseNet121\n]\nPP_TO_GO_W_TEST = [\n    tf.keras.applications.efficientnet.preprocess_input,\n    tf.keras.applications.mobilenet_v2.preprocess_input,\n    tf.keras.applications.resnet50.preprocess_input,\n    tf.keras.applications.densenet.preprocess_input,\n]\n\nhistories = []\nfor BB, PP_FN in zip(MODELS_TO_TEST, PP_TO_GO_W_TEST):    \n    print(f\"\\n\\n\\n... STARTING TRAINING FOR {BB._keras_api_names[-1].upper()} ...\\n\\n\")\n    with strategy.scope():\n        \n        callback_list = [\n            tf.keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True),\n            tf.keras.callbacks.ReduceLROnPlateau(factor=0.8, patience=2, min_lr=1e-9, verbose=1)\n        ]\n        \n        model = get_keras_cv_model(BB, PP_FN)\n        model.compile(\n            loss=\"mse\",\n            optimizer=tf.keras.optimizers.Adam(0.001),\n            metrics=[tf.keras.metrics.RootMeanSquaredError(),]\n        )\n        \n        histories.append(model.fit(dataset_folds[f\"fold_0\"][\"train_ds\"],\n                                   validation_data=dataset_folds[f\"fold_0\"][\"val_ds\"],\n                                   callbacks=callback_list, epochs=N_EPOCHS,))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T22:37:26.153355Z","iopub.execute_input":"2021-10-11T22:37:26.153705Z","iopub.status.idle":"2021-10-11T22:50:59.132347Z","shell.execute_reply.started":"2021-10-11T22:37:26.153667Z","shell.execute_reply":"2021-10-11T22:50:59.131035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for metric_name in [\"loss\", \"root_mean_squared_error\"]:\n    fig = go.Figure()\n    for name, history, color in zip([\"EfficientNetB1\", \"MobileNetV2\", \"ResNet50\", \"DenseNet121\"], histories, [\"red\", \"blue\", \"orange\", \"green\"]):        \n        fig.add_trace(go.Scatter(\n            x=np.arange(len(history.history[f\"{metric_name}\"])),\n            y=history.history[f\"{metric_name}\"],\n            mode='lines+markers',\n            legendgroup=name,\n            text=f\"<b>Training {name}</b>\",\n            legendgrouptitle_text=f\"<b>{name}</b>\",\n            visible=\"legendonly\",\n            name=f\"<b>Training {metric_name.replace('_', ' ').title()}</b>\",\n            marker=dict(color=f\"{color}\"),\n            line=dict(color=f\"{color}\")\n        ))\n        fig.add_trace(go.Scatter(\n            x=np.arange(len(history.history[f\"{metric_name}\"])),\n            y=history.history[f\"val_{metric_name}\"],\n            mode='lines+markers',\n            legendgroup=name,\n            text=f\"<b>Validation {name}</b>\",\n            legendgrouptitle_text=f\"<b>{name}</b>\",\n            name=f\"<b>Validation {metric_name.replace('_', ' ').title()}</b>\",\n            marker=dict(color=f\"dark{color}\"),\n            line=dict(color=f\"dark{color}\")\n        ))\n        fig.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.995),\n                          title=f\"{name} - {metric_name.replace('_', ' ').title()} Plot\",\n                          xaxis_title=\"Epoch Number\",\n                          yaxis_title=\"Mean Squared Error\" if metric_name==\"loss\" else \"Root Mean Squared Error\",\n                          legend_title=\"<b>LEGEND</b>\",)\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:37:54.061059Z","iopub.execute_input":"2021-10-11T23:37:54.061359Z","iopub.status.idle":"2021-10-11T23:37:54.150515Z","shell.execute_reply.started":"2021-10-11T23:37:54.06133Z","shell.execute_reply":"2021-10-11T23:37:54.149422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, history in zip([\"EfficientNetB1\", \"MobileNetV2\", \"ResNet50\", \"DenseNet121\"], histories):\n    for metric_name in [\"loss\", \"root_mean_squared_error\"]:\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(\n            x=np.arange(len(history.history[f\"{metric_name}\"])),\n            y=history.history[f\"{metric_name}\"],\n            mode='lines+markers',\n            name=f\"<b>Training {metric_name.replace('_', ' ').title()}</b>\"\n        ))\n        fig.add_trace(go.Scatter(\n            x=np.arange(len(history.history[f\"{metric_name}\"])),\n            y=history.history[f\"val_{metric_name}\"],\n            mode='lines+markers',\n            name=f\"<b>Validation {metric_name.replace('_', ' ').title()}</b>\"\n        ))\n        fig.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.995),\n                          title=f\"{name} - {metric_name.replace('_', ' ').title()} Plot\",\n                          xaxis_title=\"Epoch Number\",\n                          yaxis_title=\"Mean Squared Error\" if metric_name==\"loss\" else \"Root Mean Squared Error\",\n                          legend_title=\"<b>LEGEND</b>\",)\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:18:54.849634Z","iopub.execute_input":"2021-10-11T23:18:54.849975Z","iopub.status.idle":"2021-10-11T23:18:54.973782Z","shell.execute_reply.started":"2021-10-11T23:18:54.849943Z","shell.execute_reply":"2021-10-11T23:18:54.973084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try With Another Fold","metadata":{}},{"cell_type":"code","source":"N_EPOCHS=25\n\nMODELS_TO_TEST = [\n    tf.keras.applications.EfficientNetB1,\n    tf.keras.applications.MobileNetV2,\n    tf.keras.applications.ResNet50,\n    tf.keras.applications.DenseNet121\n]\nPP_TO_GO_W_TEST = [\n    tf.keras.applications.efficientnet.preprocess_input,\n    tf.keras.applications.mobilenet_v2.preprocess_input,\n    tf.keras.applications.resnet50.preprocess_input,\n    tf.keras.applications.densenet.preprocess_input,\n]\n\nhistories = []\nfor BB, PP_FN in zip(MODELS_TO_TEST, PP_TO_GO_W_TEST):    \n    print(f\"\\n\\n\\n... STARTING TRAINING FOR {BB._keras_api_names[-1].upper()} ...\\n\\n\")\n    with strategy.scope():\n        \n        callback_list = [\n            tf.keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True),\n            tf.keras.callbacks.ReduceLROnPlateau(factor=0.8, patience=2, min_lr=1e-9, verbose=1)\n        ]\n        \n        model = get_keras_cv_model(BB, PP_FN)\n        model.compile(\n            loss=\"mse\",\n            optimizer=tf.keras.optimizers.Adam(0.001),\n            metrics=[tf.keras.metrics.RootMeanSquaredError(),]\n        )\n        \n        histories.append(model.fit(dataset_folds[f\"fold_5\"][\"train_ds\"],\n                                   validation_data=dataset_folds[f\"fold_5\"][\"val_ds\"],\n                                   callbacks=callback_list, epochs=N_EPOCHS,))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:38:53.493747Z","iopub.execute_input":"2021-10-11T23:38:53.494047Z","iopub.status.idle":"2021-10-11T23:50:01.275873Z","shell.execute_reply.started":"2021-10-11T23:38:53.494017Z","shell.execute_reply":"2021-10-11T23:50:01.274831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for metric_name in [\"loss\", \"root_mean_squared_error\"]:\n    fig = go.Figure()\n    for name, history, color in zip([\"EfficientNetB1\", \"MobileNetV2\", \"ResNet50\", \"DenseNet121\"], histories, [\"red\", \"blue\", \"orange\", \"green\"]):        \n        fig.add_trace(go.Scatter(\n            x=np.arange(len(history.history[f\"{metric_name}\"])),\n            y=history.history[f\"{metric_name}\"],\n            mode='lines+markers',\n            legendgroup=name,\n            text=f\"<b>Training {name}</b>\",\n            legendgrouptitle_text=f\"<b>{name}</b>\",\n            visible=\"legendonly\",\n            name=f\"<b>Training {metric_name.replace('_', ' ').title()}</b>\",\n            marker=dict(color=f\"{color}\"),\n            line=dict(color=f\"{color}\")\n        ))\n        fig.add_trace(go.Scatter(\n            x=np.arange(len(history.history[f\"{metric_name}\"])),\n            y=history.history[f\"val_{metric_name}\"],\n            mode='lines+markers',\n            legendgroup=name,\n            text=f\"<b>Validation {name}</b>\",\n            legendgrouptitle_text=f\"<b>{name}</b>\",\n            name=f\"<b>Validation {metric_name.replace('_', ' ').title()}</b>\",\n            marker=dict(color=f\"dark{color}\"),\n            line=dict(color=f\"dark{color}\")\n        ))\n        fig.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.995),\n                          title=f\"{name} - {metric_name.replace('_', ' ').title()} Plot\",\n                          xaxis_title=\"Epoch Number\",\n                          yaxis_title=\"Mean Squared Error\" if metric_name==\"loss\" else \"Root Mean Squared Error\",\n                          legend_title=\"<b>LEGEND</b>\",)\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:50:01.277496Z","iopub.execute_input":"2021-10-11T23:50:01.277738Z","iopub.status.idle":"2021-10-11T23:50:01.376345Z","shell.execute_reply.started":"2021-10-11T23:50:01.27771Z","shell.execute_reply":"2021-10-11T23:50:01.374582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, history in zip([\"EfficientNetB1\", \"MobileNetV2\", \"ResNet50\", \"DenseNet121\"], histories):\n    for metric_name in [\"loss\", \"root_mean_squared_error\"]:\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(\n            x=np.arange(len(history.history[f\"{metric_name}\"])),\n            y=history.history[f\"{metric_name}\"],\n            mode='lines+markers',\n            name=f\"<b>Training {metric_name.replace('_', ' ').title()}</b>\"\n        ))\n        fig.add_trace(go.Scatter(\n            x=np.arange(len(history.history[f\"{metric_name}\"])),\n            y=history.history[f\"val_{metric_name}\"],\n            mode='lines+markers',\n            name=f\"<b>Validation {metric_name.replace('_', ' ').title()}</b>\"\n        ))\n        fig.update_layout(legend=dict(yanchor=\"top\", y=0.99, xanchor=\"right\", x=0.995),\n                          title=f\"{name} - {metric_name.replace('_', ' ').title()} Plot\",\n                          xaxis_title=\"Epoch Number\",\n                          yaxis_title=\"Mean Squared Error\" if metric_name==\"loss\" else \"Root Mean Squared Error\",\n                          legend_title=\"<b>LEGEND</b>\",)\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:50:01.378603Z","iopub.execute_input":"2021-10-11T23:50:01.378985Z","iopub.status.idle":"2021-10-11T23:50:01.504967Z","shell.execute_reply.started":"2021-10-11T23:50:01.378949Z","shell.execute_reply":"2021-10-11T23:50:01.503961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}