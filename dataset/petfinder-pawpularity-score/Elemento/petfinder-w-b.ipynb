{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder.my\n- Hola amigos, this notebook covers my code for the **PetFinder.my - Pawpularity Contest**, which can be found [here](https://www.kaggle.com/c/petfinder-pawpularity-score).\n- Reference Notebooks:\n    - [[Pytorch + W&B] Pawpularity Training](https://www.kaggle.com/debarshichanda/pytorch-w-b-pawpularity-training?scriptVersionId=75559544)\n    - [Experiment Tracking with Weights & Biases](https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases/notebook)\n    - [Interactive EDA using W&B Tables](https://www.kaggle.com/ayuraj/interactive-eda-using-w-b-tables)\n    - [Continuous Target Stratification](https://www.kaggle.com/tolgadincer/continuous-target-stratification?scriptVersionId=52551118&cellId=6)\n\n<br>\n\n![](https://storage.googleapis.com/kaggle-media/competitions/Petfinder/PetFinder%20-%20Logo.png)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T16:44:24.920858Z","iopub.execute_input":"2021-10-11T16:44:24.921228Z","iopub.status.idle":"2021-10-11T16:44:25.729455Z","shell.execute_reply.started":"2021-10-11T16:44:24.921134Z","shell.execute_reply":"2021-10-11T16:44:25.728372Z"}}},{"cell_type":"markdown","source":"# Installing and Importing Packages","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install timm\n!pip install --upgrade -q wandb","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-17T07:20:00.282994Z","iopub.execute_input":"2021-10-17T07:20:00.28344Z","iopub.status.idle":"2021-10-17T07:20:14.056265Z","shell.execute_reply.started":"2021-10-17T07:20:00.283325Z","shell.execute_reply":"2021-10-17T07:20:14.055379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\nfrom PIL import Image\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\n# Util Imports\n# https://docs.python.org/3/library/collections.htmlos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n# https://stackoverflow.com/questions/5900578/how-does-collections-defaultdict-work\nimport joblib \nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Scikit-Learn Imports\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\n# https://rwightman.github.io/pytorch-image-models/\nimport timm\n\n# Albumentations for Augmentations\n# https://albumentations.ai/docs/\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# `CUDA_LAUNCH_BLOCKING` make cuda report the error where it actually occurs.\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:14.060211Z","iopub.execute_input":"2021-10-17T07:20:14.060442Z","iopub.status.idle":"2021-10-17T07:20:15.720846Z","shell.execute_reply.started":"2021-10-17T07:20:14.060414Z","shell.execute_reply":"2021-10-17T07:20:15.719979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuring the Weights & Biases\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\")\nwandb.login(key = wandb_api)\nanony = None","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-17T07:20:15.722333Z","iopub.execute_input":"2021-10-17T07:20:15.722576Z","iopub.status.idle":"2021-10-17T07:20:16.359573Z","shell.execute_reply.started":"2021-10-17T07:20:15.722542Z","shell.execute_reply":"2021-10-17T07:20:16.358803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Configuration","metadata":{}},{"cell_type":"code","source":"ROOT_DIR = \"../input/petfinder-pawpularity-score\"\nTRAIN_DIR = \"../input/petfinder-pawpularity-score/train\"\nTEST_DIR = \"../input/petfinder-pawpularity-score/test\"","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:16.360879Z","iopub.execute_input":"2021-10-17T07:20:16.361164Z","iopub.status.idle":"2021-10-17T07:20:16.366903Z","shell.execute_reply.started":"2021-10-17T07:20:16.361128Z","shell.execute_reply":"2021-10-17T07:20:16.365977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    seed = 42, model_name = 'tf_efficientnet_b4_ns', train_batch_size = 16,\n    valid_batch_size = 32, img_size = 512, epochs = 5, learning_rate = 1e-4,\n    scheduler = 'CosineAnnealingLR', min_lr = 1e-6, T_max = 20, T_0 = 25,\n    warmup_epochs = 0, weight_decay = 1e-6, n_accumulate = 1, n_fold = 5, \n    num_classes = 1, device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    competition = 'PetFinder', _wandb_kernel = 'ele'\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:16.369575Z","iopub.execute_input":"2021-10-17T07:20:16.370176Z","iopub.status.idle":"2021-10-17T07:20:16.406249Z","shell.execute_reply.started":"2021-10-17T07:20:16.370139Z","shell.execute_reply":"2021-10-17T07:20:16.405523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set Seed for Reproducibility","metadata":{}},{"cell_type":"code","source":"# Sets the seed for the entire notebook, so that we can reproduce our results\ndef set_seed(seed = 42):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    # If True, causes cuDNN to only use deterministic convolutional algorithms\n    torch.backends.cudnn.deterministic = True\n    # If True, causes cuDNN to benchmark multiple convolution algorithms and select the fastest\n    torch.backends.cudnn.benchmark = False\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:16.407976Z","iopub.execute_input":"2021-10-17T07:20:16.408393Z","iopub.status.idle":"2021-10-17T07:20:16.421837Z","shell.execute_reply.started":"2021-10-17T07:20:16.408357Z","shell.execute_reply":"2021-10-17T07:20:16.421069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read the Data","metadata":{}},{"cell_type":"code","source":"def get_train_file_path(id):\n    return f\"{TRAIN_DIR}/{id}.jpg\"","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:16.423124Z","iopub.execute_input":"2021-10-17T07:20:16.42363Z","iopub.status.idle":"2021-10-17T07:20:16.429793Z","shell.execute_reply.started":"2021-10-17T07:20:16.423578Z","shell.execute_reply":"2021-10-17T07:20:16.429023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/train.csv\")\ndf['file_path'] = df['Id'].apply(get_train_file_path)\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:16.431243Z","iopub.execute_input":"2021-10-17T07:20:16.431785Z","iopub.status.idle":"2021-10-17T07:20:16.461932Z","shell.execute_reply.started":"2021-10-17T07:20:16.431739Z","shell.execute_reply":"2021-10-17T07:20:16.461247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding out the feature columns\nfeature_cols = [col for col in df.columns if col not in ['Id', 'Pawpularity', 'file_path']]\nprint(feature_cols)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:16.463066Z","iopub.execute_input":"2021-10-17T07:20:16.463478Z","iopub.status.idle":"2021-10-17T07:20:16.468781Z","shell.execute_reply.started":"2021-10-17T07:20:16.463442Z","shell.execute_reply":"2021-10-17T07:20:16.467849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"# https://docs.wandb.ai/ref/python/init\n# Creating a Weights & Biases Run for Visualization Purposes\nrun = wandb.init(project = 'PetFinder', config = CONFIG, \n    job_type = 'Visualization', anonymous = 'must')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-17T07:20:16.469843Z","iopub.execute_input":"2021-10-17T07:20:16.470289Z","iopub.status.idle":"2021-10-17T07:20:23.243136Z","shell.execute_reply.started":"2021-10-17T07:20:16.470253Z","shell.execute_reply":"2021-10-17T07:20:23.237517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the list of columns for W&B Visualization\ncol_list = list(df.columns)\n# No use of 'file_path'\ncol_list.remove('file_path')\n# Adding a new field (Image retrieved with the help of file_path)\ncol_list.insert(1, 'Image')\nprint(col_list)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:23.244706Z","iopub.execute_input":"2021-10-17T07:20:23.245002Z","iopub.status.idle":"2021-10-17T07:20:23.254818Z","shell.execute_reply.started":"2021-10-17T07:20:23.244963Z","shell.execute_reply":"2021-10-17T07:20:23.254216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preview_table = wandb.Table(columns = col_list)\n\n# Randomly Sampling 100 points for Visualization\ndf_temp = df.sample(100, random_state = CONFIG['seed']).reset_index(drop = True)\n\nfor i in tqdm(range(df_temp.shape[0])):\n    data = df_temp.loc[i]\n    img = Image.open(data.file_path)\n    preview_table.add_data(data[0], wandb.Image(img), *data[1:-1])\n    \nwandb.log({'Visualization': preview_table})\nrun.finish()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-17T07:20:23.260197Z","iopub.execute_input":"2021-10-17T07:20:23.262391Z","iopub.status.idle":"2021-10-17T07:20:58.711096Z","shell.execute_reply.started":"2021-10-17T07:20:23.262363Z","shell.execute_reply":"2021-10-17T07:20:58.710383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is just to display the W&B run page in this interactive session.\nfrom IPython import display\n\n# We create an IFrame and set the width & height\niframe = display.IFrame(run.url, width = 1080, height = 720)\niframe","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:58.712278Z","iopub.execute_input":"2021-10-17T07:20:58.712557Z","iopub.status.idle":"2021-10-17T07:20:58.724628Z","shell.execute_reply.started":"2021-10-17T07:20:58.712514Z","shell.execute_reply":"2021-10-17T07:20:58.723818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Folds","metadata":{}},{"cell_type":"code","source":"# https://pandas.pydata.org/docs/reference/api/pandas.cut.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n\ndef create_folds(df, n_splits = 5, n_groups = None):\n    df['kfold'] = 1\n    \n    # Corresponds to the case when we have a classification setting\n    # Will be creating folds on the basis of the target variable simply\n    if n_groups is None:\n        fold = KFold(n_splits = n_splits, random_state = CONFIG['seed'])\n        target = df['Pawpularity']\n        \n    # Corresponds to the case when we have a regression setting\n    # We will bin the target variable first, which will give us a setting similar to that of\n    # classification, and then, we will create the folds on the basis of the binned target variable\n    else:\n        fold = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state = CONFIG['seed'])\n        target = pd.cut(df['Pawpularity'], n_groups, labels = False)\n        \n    for fold_no, (train_indices, val_indices) in enumerate(fold.split(target, target)):\n        df.loc[val_indices, 'kfold'] = fold_no\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:58.729429Z","iopub.execute_input":"2021-10-17T07:20:58.729638Z","iopub.status.idle":"2021-10-17T07:20:58.73676Z","shell.execute_reply.started":"2021-10-17T07:20:58.729615Z","shell.execute_reply":"2021-10-17T07:20:58.735804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = create_folds(df, n_splits = CONFIG['n_fold'], n_groups = 14)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:58.7387Z","iopub.execute_input":"2021-10-17T07:20:58.739066Z","iopub.status.idle":"2021-10-17T07:20:58.789863Z","shell.execute_reply.started":"2021-10-17T07:20:58.739029Z","shell.execute_reply":"2021-10-17T07:20:58.789151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the Dataset Class","metadata":{}},{"cell_type":"code","source":"# By default, the imread function reads the image in BGR format\n# cvtColor takes the image from one color space to another color space, in this case, from BGR to RGB\nclass PawpularityDataset(Dataset):\n    def __init__(self, root_dir, df, transforms = None):\n        self.root_dir = root_dir\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.targets = df['Pawpularity'].values\n        self.meta = df[feature_cols].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        meta = self.meta[index, : ]\n        target = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image = img)[\"image\"]\n        \n        return img, meta, target","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:58.791455Z","iopub.execute_input":"2021-10-17T07:20:58.791963Z","iopub.status.idle":"2021-10-17T07:20:58.807102Z","shell.execute_reply.started":"2021-10-17T07:20:58.791924Z","shell.execute_reply":"2021-10-17T07:20:58.805964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Augmentations","metadata":{}},{"cell_type":"code","source":"# https://albumentations.ai/docs/\ndata_transforms = {\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.HorizontalFlip(p = 0.5),\n        A.Normalize(),\n        ToTensorV2()\n    ]),\n    \"val\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(),\n        ToTensorV2()\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:20:58.809122Z","iopub.execute_input":"2021-10-17T07:20:58.80971Z","iopub.status.idle":"2021-10-17T07:20:58.822359Z","shell.execute_reply.started":"2021-10-17T07:20:58.809669Z","shell.execute_reply":"2021-10-17T07:20:58.821437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Model Architecture","metadata":{}},{"cell_type":"code","source":"class PawpularityModel(nn.Module):\n    def __init__(self, model_name, pretrained = True):\n        super(PawpularityModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained = pretrained)\n        self.n_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.n_features + 12, CONFIG['num_classes'])\n        self.dropout = nn.Dropout(p = 0.3)\n        \n    def forward(self, images, meta):\n        # features.shape = (batch_size, num_embeddings)\n        features = self.model(images)\n        features = self.dropout(features)\n        \n        # features.shape = (batch_size, num_embeddings + meta)\n        features = torch.cat([features, meta], dim = 1)\n        \n        # outputs = (batch_size, num_classes)\n        output = self.fc(features)\n        return output\n    \nmodel = PawpularityModel(CONFIG['model_name'])\nmodel.to(CONFIG['device'])","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-10-17T07:20:58.825021Z","iopub.execute_input":"2021-10-17T07:20:58.825574Z","iopub.status.idle":"2021-10-17T07:21:02.356956Z","shell.execute_reply.started":"2021-10-17T07:20:58.825537Z","shell.execute_reply":"2021-10-17T07:21:02.356261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Loss Function","metadata":{}},{"cell_type":"code","source":"def criterion(outputs, targets):\n    return torch.sqrt(nn.MSELoss()(outputs.view(-1), targets.view(-1)))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:21:02.358141Z","iopub.execute_input":"2021-10-17T07:21:02.358473Z","iopub.status.idle":"2021-10-17T07:21:02.362968Z","shell.execute_reply.started":"2021-10-17T07:21:02.358435Z","shell.execute_reply":"2021-10-17T07:21:02.362274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Function","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    \n    # GradScaler makes the gradient values have a larger magnitude, so that, they donâ€™t flush to zero.\n    # https://pytorch.org/docs/stable/amp.html#gradient-scaling\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    # Defining the Iterator for TQDM\n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    for step, (images, meta, targets) in bar:\n        images = images.to(device, dtype = torch.float)\n        meta = meta.to(device, dtype = torch.float)\n        targets = targets.to(device, dtype = torch.float)\n        \n        # Defining the Batch Size\n        batch_size = images.size(0)\n        \n        # Enabling Autocast for Automatic Mixed Precision \n        # https://developer.nvidia.com/automatic-mixed-precision\n        with amp.autocast(enabled = True):\n            outputs = model(images, meta)\n            loss = criterion(outputs, targets)\n            loss = loss / CONFIG['n_accumulate']\n        scaler.scale(loss).backward()\n        \n        # When we have to train large models, and use small batch sizes, it takes a lot of computation\n        # time. In order to reduce that, we can do backprop after every few steps, instead of doing it\n        # after every step. In other words, we accumulate gradients for a 'n_accumulate' steps, and then\n        # we perform back-prop. \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            \n            # Zero out the Paraneter Gradients\n            optimizer.zero_grad()\n            \n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss = running_loss / dataset_size\n        \n        # set_postfix allows us to display \n        # https://github.com/tqdm/tqdm\n        bar.set_postfix(Epoch = epoch, Train_Loss = epoch_loss, LR = optimizer.param_groups[0]['lr'])\n        \n    # All objects regardless of how long they have been in memory are considered for collection.\n    # However, objects that are referenced in managed code are not collected. Use this method to\n    # force the system to try to reclaim the maximum amount of available memory.\n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:21:02.36427Z","iopub.execute_input":"2021-10-17T07:21:02.364675Z","iopub.status.idle":"2021-10-17T07:21:02.421476Z","shell.execute_reply.started":"2021-10-17T07:21:02.364642Z","shell.execute_reply":"2021-10-17T07:21:02.420347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Function","metadata":{}},{"cell_type":"code","source":"# Since, we don't want to train the model while iterating on the validation set, hence we have \n# diasbled the gradient calculations in this function.\n# https://pytorch.org/docs/stable/generated/torch.no_grad.html\n@torch.no_grad()\n\ndef val_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    TARGETS = []\n    PREDS = []\n    \n    # Defining the Iterator for TQDM\n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    for step, (images, meta, targets) in bar:\n        images = images.to(device, dtype = torch.float)\n        meta = meta.to(device, dtype = torch.float)\n        targets = targets.to(device, dtype = torch.float)\n        \n        # Defining the Batch Size\n        batch_size = images.size(0)\n        \n        outputs = model(images, meta)\n        loss = criterion(outputs, targets)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss = running_loss / dataset_size\n        \n        PREDS.append(outputs.view(-1).cpu().detach().numpy())\n        TARGETS.append(targets.view(-1).cpu().detach().numpy())\n        \n        # set_postfix allows us to display \n        # https://github.com/tqdm/tqdm\n        bar.set_postfix(Epoch = epoch, Val_Loss = epoch_loss, LR = optimizer.param_groups[0]['lr'])\n    \n    TARGETS = np.concatenate(TARGETS)\n    PREDS = np.concatenate(PREDS)\n    val_rmse = MSE(TARGETS, PREDS, squared=False)\n    \n    # All objects regardless of how long they have been in memory are considered for collection.\n    # However, objects that are referenced in managed code are not collected. Use this method to\n    # force the system to try to reclaim the maximum amount of available memory.\n    gc.collect()\n    \n    return epoch_loss, val_rmse","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:21:02.423068Z","iopub.execute_input":"2021-10-17T07:21:02.42342Z","iopub.status.idle":"2021-10-17T07:21:02.437706Z","shell.execute_reply.started":"2021-10-17T07:21:02.423383Z","shell.execute_reply":"2021-10-17T07:21:02.436832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run Training","metadata":{}},{"cell_type":"code","source":"# train_loader & val_loader are initialized before this function is called\ndef run_training(model, optimizer, scheduler, device, num_epochs):\n    # To automatically log gradients\n    # https://docs.wandb.ai/ref/python/watch\n    wandb.watch(model, log_freq = 100)\n    \n    if torch.cuda.is_available():\n        print('[INFO] Using GPU: {}\\n'.format(torch.cuda.get_device_name()))\n        \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_rmse = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs+1):\n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, dataloader = train_loader,\n            device = CONFIG['device'], epoch = epoch)\n        val_epoch_loss, val_epoch_rmse = val_one_epoch(model, dataloader = val_loader, \n             device = CONFIG['device'], epoch = epoch)\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Valid RMSE'].append(val_epoch_rmse)\n    \n        # Log the Metrics\n        wandb.log({\"Train Loss\": train_epoch_loss})\n        wandb.log({\"Val Loss\": val_epoch_loss})\n        wandb.log({'Valid RMSE': val_epoch_rmse})\n        \n        print(\"Val RMSE:\", val_epoch_rmse)\n        \n        # Deep Copy the Model\n        if val_epoch_rmse <= best_epoch_rmse:\n            print(f\"Validation Loss Improved ({best_epoch_rmse} - {val_epoch_rmse})\")\n            best_epoch_rmse = val_epoch_rmse\n            run.summary[\"Best RMSE\"] = best_epoch_rmse\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"RMSE{:.4f}_epoch{:.0f}.bin\".format(best_epoch_rmse, epoch)\n            torch.save(model.state_dict(), PATH)\n            \n            # Save a model file from the curreny directory\n            wandb.save(PATH)\n            print(\"Model Saved\")\n            \n        print()\n        \n    end = time.time()\n    time_elapsed = end - start\n    print(\"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best RMSE: {:.4f}\".format(best_epoch_rmse))\n    \n    # Load the best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:21:02.440098Z","iopub.execute_input":"2021-10-17T07:21:02.440378Z","iopub.status.idle":"2021-10-17T07:21:02.457465Z","shell.execute_reply.started":"2021-10-17T07:21:02.440351Z","shell.execute_reply":"2021-10-17T07:21:02.456668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(fold):\n    df_train = df[df.kfold != fold].reset_index(drop = True)\n    df_val = df[df.kfold != fold].reset_index(drop = True)\n    \n    train_dataset = PawpularityDataset(TRAIN_DIR, df_train, transforms = data_transforms['train'])\n    val_dataset = PawpularityDataset(TRAIN_DIR, df_val, transforms = data_transforms['train'])\n    \n    train_loader = DataLoader(train_dataset, batch_size = CONFIG['train_batch_size'],\n        num_workers = 4, shuffle = True, pin_memory = True, drop_last = True)\n    val_loader = DataLoader(val_dataset, batch_size = CONFIG['valid_batch_size'],\n        num_workers = 4, shuffle = True, pin_memory = True, drop_last = True)\n    \n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:21:02.461232Z","iopub.execute_input":"2021-10-17T07:21:02.461656Z","iopub.status.idle":"2021-10-17T07:21:02.470535Z","shell.execute_reply.started":"2021-10-17T07:21:02.461624Z","shell.execute_reply":"2021-10-17T07:21:02.469806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = CONFIG['T_max'], \n            eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = CONFIG['T_0'], \n                                                             eta_min = CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:21:02.471752Z","iopub.execute_input":"2021-10-17T07:21:02.472031Z","iopub.status.idle":"2021-10-17T07:21:02.482531Z","shell.execute_reply.started":"2021-10-17T07:21:02.471994Z","shell.execute_reply":"2021-10-17T07:21:02.481744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training & Inferencing","metadata":{}},{"cell_type":"code","source":"# Create Dataloaders\ntrain_loader, val_loader = prepare_loaders(fold = 0)","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-17T07:21:02.483695Z","iopub.execute_input":"2021-10-17T07:21:02.4845Z","iopub.status.idle":"2021-10-17T07:21:02.502817Z","shell.execute_reply.started":"2021-10-17T07:21:02.484463Z","shell.execute_reply":"2021-10-17T07:21:02.501989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Optimizer & Scheduler\noptimizer = optim.Adam(model.parameters(), lr = CONFIG['learning_rate'], \n    weight_decay = CONFIG['weight_decay'])\nscheduler = fetch_scheduler(optimizer)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:21:02.504218Z","iopub.execute_input":"2021-10-17T07:21:02.504516Z","iopub.status.idle":"2021-10-17T07:21:02.517529Z","shell.execute_reply.started":"2021-10-17T07:21:02.504484Z","shell.execute_reply":"2021-10-17T07:21:02.515322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the training run for Weights & Biases\nrun = wandb.init(project = 'PetFinder', config = CONFIG, job_type = 'Train', anonymous = 'must')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-17T07:21:02.51906Z","iopub.execute_input":"2021-10-17T07:21:02.519413Z","iopub.status.idle":"2021-10-17T07:21:08.963051Z","shell.execute_reply.started":"2021-10-17T07:21:02.519376Z","shell.execute_reply":"2021-10-17T07:21:08.961325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start Training\nmodel, history = run_training(model, optimizer, scheduler, CONFIG['device'], CONFIG['epochs'])","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:21:08.964843Z","iopub.execute_input":"2021-10-17T07:21:08.965347Z","iopub.status.idle":"2021-10-17T08:17:28.647926Z","shell.execute_reply.started":"2021-10-17T07:21:08.965307Z","shell.execute_reply":"2021-10-17T08:17:28.647194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finishing the Run\nrun.finish()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:17:28.65071Z","iopub.execute_input":"2021-10-17T08:17:28.651414Z","iopub.status.idle":"2021-10-17T08:17:32.865769Z","shell.execute_reply.started":"2021-10-17T08:17:28.651379Z","shell.execute_reply":"2021-10-17T08:17:32.865103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizations","metadata":{}},{"cell_type":"code","source":"# This is just to display the W&B run page in this interactive session.\nfrom IPython import display\n\n# We create an IFrame and set the width and height\niframe = display.IFrame(run.url, width = 1000, height = 720)\niframe","metadata":{"execution":{"iopub.status.busy":"2021-10-17T08:17:32.866992Z","iopub.execute_input":"2021-10-17T08:17:32.867324Z","iopub.status.idle":"2021-10-17T08:17:32.876474Z","shell.execute_reply.started":"2021-10-17T08:17:32.867286Z","shell.execute_reply":"2021-10-17T08:17:32.875576Z"},"trusted":true},"execution_count":null,"outputs":[]}]}