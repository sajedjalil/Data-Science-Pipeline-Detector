{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder.my\n- Hola amigos, this notebook covers my code for the **PetFinder.my - Pawpularity Contest**, which can be found [here](https://www.kaggle.com/c/petfinder-pawpularity-score).\n- Reference Notebooks:\n    - [[Pytorch + W&B] Pawpularity Training](https://www.kaggle.com/debarshichanda/pytorch-w-b-pawpularity-training?scriptVersionId=75559544)\n    - [Experiment Tracking with Weights & Biases](https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases/notebook)\n    - [Interactive EDA using W&B Tables](https://www.kaggle.com/ayuraj/interactive-eda-using-w-b-tables)\n    - [Continuous Target Stratification](https://www.kaggle.com/tolgadincer/continuous-target-stratification?scriptVersionId=52551118&cellId=6)\n\n<br>\n\n![](https://storage.googleapis.com/kaggle-media/competitions/Petfinder/PetFinder%20-%20Logo.png)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T16:44:24.920858Z","iopub.execute_input":"2021-10-11T16:44:24.921228Z","iopub.status.idle":"2021-10-11T16:44:25.729455Z","shell.execute_reply.started":"2021-10-11T16:44:24.921134Z","shell.execute_reply":"2021-10-11T16:44:25.728372Z"}}},{"cell_type":"markdown","source":"# Installing and Importing Packages","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# !pip install git+https://github.com/rwightman/pytorch-image-models","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:20.310466Z","iopub.execute_input":"2021-10-20T13:19:20.311056Z","iopub.status.idle":"2021-10-20T13:19:20.328604Z","shell.execute_reply.started":"2021-10-20T13:19:20.310945Z","shell.execute_reply":"2021-10-20T13:19:20.327934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport copy\nimport time\nimport random\nfrom PIL import Image\n# from pickle import dump, load\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\n# Util Imports\n# https://docs.python.org/3/library/collections.htmlos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n# https://stackoverflow.com/questions/5900578/how-does-collections-defaultdict-work\nimport joblib \nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Scikit-Learn Imports\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\n# https://rwightman.github.io/pytorch-image-models/\n# import timm\n\n# Albumentations for Augmentations\n# https://albumentations.ai/docs/\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# `CUDA_LAUNCH_BLOCKING` make cuda report the error where it actually occurs.\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:20.33022Z","iopub.execute_input":"2021-10-20T13:19:20.330477Z","iopub.status.idle":"2021-10-20T13:19:26.480503Z","shell.execute_reply.started":"2021-10-20T13:19:20.330445Z","shell.execute_reply":"2021-10-20T13:19:26.479781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # https://www.kaggle.com/kozodoi/timm-pytorch-image-models\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nprint(timm.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:26.481821Z","iopub.execute_input":"2021-10-20T13:19:26.482087Z","iopub.status.idle":"2021-10-20T13:19:27.878745Z","shell.execute_reply.started":"2021-10-20T13:19:26.482052Z","shell.execute_reply":"2021-10-20T13:19:27.877786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Configuration","metadata":{}},{"cell_type":"code","source":"ROOT_DIR = \"../input/petfinder-pawpularity-score\"\nTRAIN_DIR = \"../input/petfinder-pawpularity-score/train\"\nTEST_DIR = \"../input/petfinder-pawpularity-score/test\"","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:27.88027Z","iopub.execute_input":"2021-10-20T13:19:27.88053Z","iopub.status.idle":"2021-10-20T13:19:27.887052Z","shell.execute_reply.started":"2021-10-20T13:19:27.880494Z","shell.execute_reply":"2021-10-20T13:19:27.886352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    seed = 42, model_name = 'tf_efficientnet_b4_ns', train_batch_size = 16,\n    valid_batch_size = 32, img_size = 512, epochs = 5, learning_rate = 1e-4,\n    scheduler = 'CosineAnnealingLR', min_lr = 1e-6, T_max = 20, T_0 = 25,\n    warmup_epochs = 0, weight_decay = 1e-6, n_accumulate = 1, n_fold = 5, \n    num_classes = 1, device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    competition = 'PetFinder', _wandb_kernel = 'ele'\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:27.889714Z","iopub.execute_input":"2021-10-20T13:19:27.889979Z","iopub.status.idle":"2021-10-20T13:19:27.9408Z","shell.execute_reply.started":"2021-10-20T13:19:27.889945Z","shell.execute_reply":"2021-10-20T13:19:27.940031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set Seed for Reproducibility","metadata":{}},{"cell_type":"code","source":"# Sets the seed for the entire notebook, so that we can reproduce our results\ndef set_seed(seed = 42):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    # If True, causes cuDNN to only use deterministic convolutional algorithms\n    torch.backends.cudnn.deterministic = True\n    # If True, causes cuDNN to benchmark multiple convolution algorithms and select the fastest\n    torch.backends.cudnn.benchmark = False\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:27.942138Z","iopub.execute_input":"2021-10-20T13:19:27.942512Z","iopub.status.idle":"2021-10-20T13:19:27.953225Z","shell.execute_reply.started":"2021-10-20T13:19:27.942476Z","shell.execute_reply":"2021-10-20T13:19:27.952527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read the Data","metadata":{}},{"cell_type":"code","source":"def get_train_file_path(id):\n    return f\"{TRAIN_DIR}/{id}.jpg\"","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:27.954228Z","iopub.execute_input":"2021-10-20T13:19:27.956105Z","iopub.status.idle":"2021-10-20T13:19:27.96244Z","shell.execute_reply.started":"2021-10-20T13:19:27.956068Z","shell.execute_reply":"2021-10-20T13:19:27.961734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/train.csv\")\ndf['file_path'] = df['Id'].apply(get_train_file_path)\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:27.963556Z","iopub.execute_input":"2021-10-20T13:19:27.96386Z","iopub.status.idle":"2021-10-20T13:19:28.011075Z","shell.execute_reply.started":"2021-10-20T13:19:27.963827Z","shell.execute_reply":"2021-10-20T13:19:28.010397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding out the feature columns\nfeature_cols = [col for col in df.columns if col not in ['Id', 'Pawpularity', 'file_path']]\nprint(feature_cols)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:28.012213Z","iopub.execute_input":"2021-10-20T13:19:28.012581Z","iopub.status.idle":"2021-10-20T13:19:28.017762Z","shell.execute_reply.started":"2021-10-20T13:19:28.012539Z","shell.execute_reply":"2021-10-20T13:19:28.016912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Folds","metadata":{}},{"cell_type":"code","source":"# https://pandas.pydata.org/docs/reference/api/pandas.cut.html\n# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n\ndef create_folds(df, n_splits = 5, n_groups = None):\n    df['kfold'] = 1\n    \n    # Corresponds to the case when we have a classification setting\n    # Will be creating folds on the basis of the target variable simply\n    if n_groups is None:\n        fold = KFold(n_splits = n_splits, random_state = CONFIG['seed'])\n        target = df['Pawpularity']\n        \n    # Corresponds to the case when we have a regression setting\n    # We will bin the target variable first, which will give us a setting similar to that of\n    # classification, and then, we will create the folds on the basis of the binned target variable\n    else:\n        fold = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state = CONFIG['seed'])\n        target = pd.cut(df['Pawpularity'], n_groups, labels = False)\n        \n    for fold_no, (train_indices, val_indices) in enumerate(fold.split(target, target)):\n        df.loc[val_indices, 'kfold'] = fold_no\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:28.019513Z","iopub.execute_input":"2021-10-20T13:19:28.019824Z","iopub.status.idle":"2021-10-20T13:19:28.029534Z","shell.execute_reply.started":"2021-10-20T13:19:28.019785Z","shell.execute_reply":"2021-10-20T13:19:28.028529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = create_folds(df, n_splits = CONFIG['n_fold'], n_groups = 14)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:28.031327Z","iopub.execute_input":"2021-10-20T13:19:28.031974Z","iopub.status.idle":"2021-10-20T13:19:28.072412Z","shell.execute_reply.started":"2021-10-20T13:19:28.03182Z","shell.execute_reply":"2021-10-20T13:19:28.071587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the Dataset Class","metadata":{}},{"cell_type":"code","source":"# By default, the imread function reads the image in BGR format\n# cvtColor takes the image from one color space to another color space, in this case, from BGR to RGB\nclass PawpularityDataset(Dataset):\n    def __init__(self, root_dir, df, transforms = None, is_test = False):\n        self.root_dir = root_dir\n        self.df = df\n        self.file_names = df['file_path'].values\n        if not is_test:\n            self.targets = df['Pawpularity'].values\n        self.meta = df[feature_cols].values\n        self.transforms = transforms\n        self.is_test = is_test\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        meta = self.meta[index, : ]\n        if not self.is_test:\n            target = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image = img)[\"image\"]\n        \n        if not self.is_test:\n            return img, meta, target\n        else:\n            return img, meta","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:28.073856Z","iopub.execute_input":"2021-10-20T13:19:28.074134Z","iopub.status.idle":"2021-10-20T13:19:28.082877Z","shell.execute_reply.started":"2021-10-20T13:19:28.074102Z","shell.execute_reply":"2021-10-20T13:19:28.081915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Augmentations","metadata":{}},{"cell_type":"code","source":"# https://albumentations.ai/docs/\ndata_transforms = {\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.HorizontalFlip(p = 0.5),\n        A.Normalize(),\n        ToTensorV2()\n    ]),\n    \"val\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(),\n        ToTensorV2()\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:28.084651Z","iopub.execute_input":"2021-10-20T13:19:28.085183Z","iopub.status.idle":"2021-10-20T13:19:28.094599Z","shell.execute_reply.started":"2021-10-20T13:19:28.085149Z","shell.execute_reply":"2021-10-20T13:19:28.093803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Model Architecture","metadata":{}},{"cell_type":"code","source":"# # Only for training, needs to be commented in inference\n# train_model = timm.create_model(CONFIG['model_name'], pretrained = True)\n# torch.save(train_model.state_dict(), 'effnetb4ns.pth')","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:28.098819Z","iopub.execute_input":"2021-10-20T13:19:28.099563Z","iopub.status.idle":"2021-10-20T13:19:28.10323Z","shell.execute_reply.started":"2021-10-20T13:19:28.099526Z","shell.execute_reply":"2021-10-20T13:19:28.102355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularityModel(nn.Module):\n    def __init__(self, model_name, pretrained = True):\n        super(PawpularityModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained = False)\n        self.model.load_state_dict(torch.load(\"../input/petfindermy-pawpularity-contest/effnetb4ns.pth\"),\n              strict = False)   \n        self.n_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.n_features + 12, CONFIG['num_classes'])\n        self.dropout = nn.Dropout(p = 0.3)\n        \n    def forward(self, images, meta):\n        # features.shape = (batch_size, num_embeddings)\n        features = self.model(images)\n        features = self.dropout(features)\n        \n        # features.shape = (batch_size, num_embeddings + meta)\n        features = torch.cat([features, meta], dim = 1)\n        \n        # outputs = (batch_size, num_classes)\n        output = self.fc(features)\n        return output\n    \nmodel = PawpularityModel(CONFIG['model_name'])\nmodel.to(CONFIG['device'])","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-10-20T13:19:28.104612Z","iopub.execute_input":"2021-10-20T13:19:28.105085Z","iopub.status.idle":"2021-10-20T13:19:35.904539Z","shell.execute_reply.started":"2021-10-20T13:19:28.105046Z","shell.execute_reply":"2021-10-20T13:19:35.903867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Loss Function","metadata":{}},{"cell_type":"code","source":"def criterion(outputs, targets):\n    return torch.sqrt(nn.MSELoss()(outputs.view(-1), targets.view(-1)))","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:35.905907Z","iopub.execute_input":"2021-10-20T13:19:35.906388Z","iopub.status.idle":"2021-10-20T13:19:35.910837Z","shell.execute_reply.started":"2021-10-20T13:19:35.906352Z","shell.execute_reply":"2021-10-20T13:19:35.909882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Function","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    \n    # GradScaler makes the gradient values have a larger magnitude, so that, they donâ€™t flush to zero.\n    # https://pytorch.org/docs/stable/amp.html#gradient-scaling\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    # Defining the Iterator for TQDM\n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    for step, (images, meta, targets) in bar:\n        images = images.to(device, dtype = torch.float)\n        meta = meta.to(device, dtype = torch.float)\n        targets = targets.to(device, dtype = torch.float)\n        \n        # Defining the Batch Size\n        batch_size = images.size(0)\n        \n        # Enabling Autocast for Automatic Mixed Precision \n        # https://developer.nvidia.com/automatic-mixed-precision\n        with amp.autocast(enabled = True):\n            outputs = model(images, meta)\n            loss = criterion(outputs, targets)\n            loss = loss / CONFIG['n_accumulate']\n        scaler.scale(loss).backward()\n        \n        # When we have to train large models, and use small batch sizes, it takes a lot of computation\n        # time. In order to reduce that, we can do backprop after every few steps, instead of doing it\n        # after every step. In other words, we accumulate gradients for a 'n_accumulate' steps, and then\n        # we perform back-prop. \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            \n            # Zero out the Paraneter Gradients\n            optimizer.zero_grad()\n            \n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss = running_loss / dataset_size\n        \n        # set_postfix allows us to display \n        # https://github.com/tqdm/tqdm\n        bar.set_postfix(Epoch = epoch, Train_Loss = epoch_loss, LR = optimizer.param_groups[0]['lr'])\n        \n    # All objects regardless of how long they have been in memory are considered for collection.\n    # However, objects that are referenced in managed code are not collected. Use this method to\n    # force the system to try to reclaim the maximum amount of available memory.\n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:35.912275Z","iopub.execute_input":"2021-10-20T13:19:35.912767Z","iopub.status.idle":"2021-10-20T13:19:35.924472Z","shell.execute_reply.started":"2021-10-20T13:19:35.912733Z","shell.execute_reply":"2021-10-20T13:19:35.923771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Function","metadata":{}},{"cell_type":"code","source":"# Since, we don't want to train the model while iterating on the validation set, hence we have \n# diasbled the gradient calculations in this function.\n# https://pytorch.org/docs/stable/generated/torch.no_grad.html\n@torch.no_grad()\n\ndef val_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    TARGETS = []\n    PREDS = []\n    \n    # Defining the Iterator for TQDM\n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    for step, (images, meta, targets) in bar:\n        images = images.to(device, dtype = torch.float)\n        meta = meta.to(device, dtype = torch.float)\n        targets = targets.to(device, dtype = torch.float)\n        \n        # Defining the Batch Size\n        batch_size = images.size(0)\n        \n        outputs = model(images, meta)\n        loss = criterion(outputs, targets)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss = running_loss / dataset_size\n        \n        PREDS.append(outputs.view(-1).cpu().detach().numpy())\n        TARGETS.append(targets.view(-1).cpu().detach().numpy())\n        \n        # set_postfix allows us to display \n        # https://github.com/tqdm/tqdm\n        bar.set_postfix(Epoch = epoch, Val_Loss = epoch_loss, LR = optimizer.param_groups[0]['lr'])\n    \n    TARGETS = np.concatenate(TARGETS)\n    PREDS = np.concatenate(PREDS)\n    val_rmse = MSE(TARGETS, PREDS, squared=False)\n    \n    # All objects regardless of how long they have been in memory are considered for collection.\n    # However, objects that are referenced in managed code are not collected. Use this method to\n    # force the system to try to reclaim the maximum amount of available memory.\n    gc.collect()\n    \n    return epoch_loss, val_rmse","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:35.92574Z","iopub.execute_input":"2021-10-20T13:19:35.92654Z","iopub.status.idle":"2021-10-20T13:19:35.938164Z","shell.execute_reply.started":"2021-10-20T13:19:35.926503Z","shell.execute_reply":"2021-10-20T13:19:35.937477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict Function","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\n\ndef predict_test(model, dataloader, device):\n    model.eval()\n    dataset_size = 0\n    PREDS = []\n    \n    # Defining the Iterator for TQDM\n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    for step, (images, meta) in bar:\n        images = images.to(device, dtype = torch.float)\n        meta = meta.to(device, dtype = torch.float)\n        outputs = model(images, meta)\n\n        PREDS.append(outputs.view(-1).cpu().detach().numpy())\n    PREDS = np.concatenate(PREDS)\n    \n    # All objects regardless of how long they have been in memory are considered for collection.\n    # However, objects that are referenced in managed code are not collected. Use this method to\n    # force the system to try to reclaim the maximum amount of available memory.\n    gc.collect()\n    \n    return PREDS","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:35.939136Z","iopub.execute_input":"2021-10-20T13:19:35.940755Z","iopub.status.idle":"2021-10-20T13:19:35.949871Z","shell.execute_reply.started":"2021-10-20T13:19:35.940674Z","shell.execute_reply":"2021-10-20T13:19:35.949095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run Training","metadata":{}},{"cell_type":"code","source":"# train_loader & val_loader are initialized before this function is called\ndef run_training(model, optimizer, scheduler, device, num_epochs):\n    if torch.cuda.is_available():\n        print('[INFO] Using GPU: {}\\n'.format(torch.cuda.get_device_name()))\n        \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_rmse = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs+1):\n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, dataloader = train_loader,\n            device = CONFIG['device'], epoch = epoch)\n        val_epoch_loss, val_epoch_rmse = val_one_epoch(model, dataloader = val_loader, \n             device = CONFIG['device'], epoch = epoch)\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Valid RMSE'].append(val_epoch_rmse)\n        print(\"Val RMSE:\", val_epoch_rmse)\n        \n        # Deep Copy the Model\n        if val_epoch_rmse <= best_epoch_rmse:\n            print(f\"Validation Loss Improved ({best_epoch_rmse} - {val_epoch_rmse})\")\n            best_epoch_rmse = val_epoch_rmse\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"RMSE{:.4f}_epoch{:.0f}.bin\".format(best_epoch_rmse, epoch)\n            torch.save(model.state_dict(), PATH)\n        \n    end = time.time()\n    time_elapsed = end - start\n    print(\"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best RMSE: {:.4f}\".format(best_epoch_rmse))\n    \n    # Load the best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:35.95271Z","iopub.execute_input":"2021-10-20T13:19:35.953449Z","iopub.status.idle":"2021-10-20T13:19:35.965366Z","shell.execute_reply.started":"2021-10-20T13:19:35.953417Z","shell.execute_reply":"2021-10-20T13:19:35.964086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(fold):\n    df_train = df[df.kfold != fold].reset_index(drop = True)\n    df_val = df[df.kfold != fold].reset_index(drop = True)\n    \n    train_dataset = PawpularityDataset(TRAIN_DIR, df_train, transforms = data_transforms['train'])\n    val_dataset = PawpularityDataset(TRAIN_DIR, df_val, transforms = data_transforms['val'])\n    \n    train_loader = DataLoader(train_dataset, batch_size = CONFIG['train_batch_size'],\n        num_workers = 4, shuffle = True, pin_memory = True, drop_last = True)\n    val_loader = DataLoader(val_dataset, batch_size = CONFIG['valid_batch_size'],\n        num_workers = 4, shuffle = True, pin_memory = True, drop_last = True)\n    \n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:35.966668Z","iopub.execute_input":"2021-10-20T13:19:35.967187Z","iopub.status.idle":"2021-10-20T13:19:35.975496Z","shell.execute_reply.started":"2021-10-20T13:19:35.967153Z","shell.execute_reply":"2021-10-20T13:19:35.974779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = CONFIG['T_max'], \n            eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = CONFIG['T_0'], \n                                                             eta_min = CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:35.976809Z","iopub.execute_input":"2021-10-20T13:19:35.977349Z","iopub.status.idle":"2021-10-20T13:19:35.986025Z","shell.execute_reply.started":"2021-10-20T13:19:35.977313Z","shell.execute_reply":"2021-10-20T13:19:35.985307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training & Inferencing","metadata":{}},{"cell_type":"code","source":"# Create Dataloaders\ntrain_loader, val_loader = prepare_loaders(fold = 0)","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-20T13:19:35.987452Z","iopub.execute_input":"2021-10-20T13:19:35.987941Z","iopub.status.idle":"2021-10-20T13:19:36.010675Z","shell.execute_reply.started":"2021-10-20T13:19:35.987907Z","shell.execute_reply":"2021-10-20T13:19:36.010057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Optimizer & Scheduler\noptimizer = optim.Adam(model.parameters(), lr = CONFIG['learning_rate'], \n    weight_decay = CONFIG['weight_decay'])\nscheduler = fetch_scheduler(optimizer)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:36.013128Z","iopub.execute_input":"2021-10-20T13:19:36.01474Z","iopub.status.idle":"2021-10-20T13:19:36.025063Z","shell.execute_reply.started":"2021-10-20T13:19:36.013618Z","shell.execute_reply":"2021-10-20T13:19:36.02433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start Training\nmodel, history = run_training(model, optimizer, scheduler, CONFIG['device'], CONFIG['epochs'])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T13:19:36.026827Z","iopub.execute_input":"2021-10-20T13:19:36.027092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making the Submission","metadata":{}},{"cell_type":"code","source":"def get_test_file_path(id):\n    return f\"{TEST_DIR}/{id}.jpg\"\n\ndf_test = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf_test['file_path'] = df_test['Id'].apply(get_test_file_path)\nprint(df_test.shape)\n\ntest_dataset = PawpularityDataset(TEST_DIR, df_test, transforms = data_transforms['val'], \n      is_test = True)\ntest_loader = DataLoader(test_dataset,\n        num_workers = 4, shuffle = True, pin_memory = True, drop_last = True)\n\npreds = predict_test(model, test_loader, CONFIG['device'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['Id'] = df_test['Id']\nsubmission['Pawpularity'] = preds\nsubmission.to_csv('submission.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}