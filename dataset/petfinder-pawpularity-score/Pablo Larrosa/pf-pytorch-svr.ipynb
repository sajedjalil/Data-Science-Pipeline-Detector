{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-15T19:17:54.379008Z","iopub.execute_input":"2021-12-15T19:17:54.379264Z","iopub.status.idle":"2021-12-15T19:17:56.001361Z","shell.execute_reply.started":"2021-12-15T19:17:54.379234Z","shell.execute_reply":"2021-12-15T19:17:56.000616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import sys\n\n# Data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Utils\nimport math\nfrom tqdm import tqdm\nimport cv2\nimport gc\nfrom glob import glob\nimport random\n\nsys.path.append('../input/pytorch-install/tez/')\nsys.path.append('../input/pytorch-install/pytorch-image-models/')\n\nimport timm\nimport tez\nfrom tez.callbacks import EarlyStopping\n\n# Augmentations\nimport albumentations\n\n# Pytorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\n# Rapids\nimport cuml, pickle\nfrom cuml.svm import SVR\nprint('RAPIDS version',cuml.__version__,'\\n')\n\n# Boost\nimport xgboost as xgb\n\n# Sklearn\nimport sklearn\n\n# Sklearn model selection\nfrom sklearn.model_selection import StratifiedKFold\n\n# Metrics\nfrom sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, auc, roc_curve, roc_auc_score, classification_report, confusion_matrix\n\n# Wandb\n# import wandb\n\n# try:\n#     from kaggle_secrets import UserSecretsClient\n#     user_secrets = UserSecretsClient()\n#     api_key = user_secrets.get_secret(\"wandb_api\")\n#     wandb.login(key=api_key)\n#     anony = None\n# except:\n#     anony = \"must\"\n#     print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n\n# Set display options\npd.set_option('display.max_rows', 200,'display.max_columns', 300,'display.max_colwidth', None)\n\n# Versions\nprint(f'Python {sys.version}')\nprint(f'NumPy {np.__version__}')\nprint(f'Pandas {pd.__version__}')\nprint(f'Pytorch Version: {torch.__version__}')\nprint(f'Scikit-Learn {sklearn.__version__}')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T19:17:56.005166Z","iopub.execute_input":"2021-12-15T19:17:56.0054Z","iopub.status.idle":"2021-12-15T19:18:00.686846Z","shell.execute_reply.started":"2021-12-15T19:17:56.005366Z","shell.execute_reply":"2021-12-15T19:18:00.686047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Arguments","metadata":{}},{"cell_type":"code","source":"class cfg:\n    image_path = '../input/petfinder-pawpularity-score'\n    pretrained_path = '../input/pf-st-patch4'\n    load_reg_from = None\n    #load_reg_from = '../input/pf-st-patch4'\n    load_train_from = '.'\n    #load_train_from = '../input/pf-st-patch4'\n    target = 'Pawpularity'\n    batch_size = 16\n    image_size = 384\n    seed = 4221\n    kfolds = 10\n    bfolds = 1\n    dweet_channel = 'pytorch-pawpularity'\n    dweet_enabled = False","metadata":{"execution":{"iopub.status.busy":"2021-12-15T19:21:34.994074Z","iopub.execute_input":"2021-12-15T19:21:34.994615Z","iopub.status.idle":"2021-12-15T19:21:35.001052Z","shell.execute_reply.started":"2021-12-15T19:21:34.994564Z","shell.execute_reply":"2021-12-15T19:21:35.000085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load datasets","metadata":{}},{"cell_type":"code","source":"# Load datasets\ntrain = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\ntrain['file_path'] = cfg.image_path + '/train/' + train['Id'] + '.jpg'\ntest['file_path'] = cfg.image_path + '/test/' + test['Id'] + '.jpg' \ndense_features = [col for col in train.columns if col not in ['Id', cfg.target, 'file_path']]\n\ntrain = train.drop(columns=['Id'])\ntest = test.drop(columns=['Id'])\n\ndef create_folds(df, splits=5):\n    df['norm_score'] = df[cfg.target]/100\n    num_bins = int(np.floor(1+(3.3)*(np.log2(len(df)))))\n    df['bins'] = pd.cut(df['norm_score'], bins=num_bins, labels=False)\n    df['bins'].hist()\n    df['kfold'] = -1\n    \n    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=cfg.seed)\n    \n    for fold, (t, v) in enumerate(skf.split(df.index, df['bins'])):\n        df.iloc[v, -1] = fold\n    \n    df['kfold'] = df['kfold'].astype('int')\n    df.kfold.value_counts().plot.bar()\n    \n    df[df['kfold']==0].head()\n    df[df['kfold']==0]['bins'].value_counts()\n    df[df['kfold']==1]['bins'].value_counts()\n    \n    return df\n\ntrain = create_folds(train, splits=cfg.kfolds)\ntrain.to_csv('train.csv', index=False)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T19:22:04.211563Z","iopub.execute_input":"2021-12-15T19:22:04.211992Z","iopub.status.idle":"2021-12-15T19:22:04.672027Z","shell.execute_reply.started":"2021-12-15T19:22:04.211948Z","shell.execute_reply":"2021-12-15T19:22:04.671344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"# Dweet\nclass Logger(object):\n\n    CHANNEL_NAME = cfg.dweet_channel\n\n    def __init__(self):\n        self.terminal = sys.stdout\n\n    def write(self, message):\n        if message != '\\n':\n            self.terminal.write(message + '\\n')\n            payload = {'msg': message}\n            quoted = urlencode(payload)\n            thr = threading.Thread(target=self.send, args=(quoted,), kwargs={})\n            thr.start()\n\n    def flush(self):\n        pass\n\n    @staticmethod\n    def send(msg):\n        msg = 'https://dweet.io/dweet/for/' + Logger.CHANNEL_NAME + '?' + msg\n        print(f'Check on https://dweet.io/get/dweets/for/{Logger.CHANNEL_NAME}')\n        try:\n            request.urlopen(msg).read()\n        except Exception as e:\n            sys.stdout.terminal.write(e)\n\nif cfg.dweet_enabled:\n    #sys.stdout = Logger()\n    mydweet = Logger()\n    mydweet.write('Waiting for metrics...')\n\n# why do you divide target values by 100 and multiply sigmoid(x) by 100\n# This converts the problem from RSME loss to BCE loss\n# Different losses encourage the model to learn in different ways. If you try both RSME (leaving targets as is) and BCE (dividing targets by 100), then we see \n# that BCE achieves better accuracy predictions. Why this is true is hard to say.\ndef sigmoid(x):\n    return 1 / (1 + math.exp(-x))\n\n# RMSE\ndef get_score(y_true, y_preds):\n    return np.sqrt(np.mean((y_true - y_preds)**2))\n    #return 100*torch.sqrt(nn.functional.mse_loss(nn.functional.sigmoid(y_true.flatten()), y_preds))\n\ndef set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(cfg.seed)\n\nclass BuildDataset:\n    def __init__(self, image_paths, dense_features, targets, augmentations):\n        self.image_paths = image_paths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        features = self.dense_features[item, :]\n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }\n\nclass BuildModel(tez.Model):\n    def __init__(self, model_name):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n        self.model.head = nn.Linear(self.model.head.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(140, 64)\n        self.dense2 = nn.Linear(64, 1)\n\n    def forward(self, image, features, targets=None):\n        x1 = self.model(image)\n        x = self.dropout(x1)\n        x = torch.cat([x, features], dim=1)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        \n        x = torch.cat([x, x1, features], dim=1)\n        return x, 0, {}\n\naugs = albumentations.Compose(\n    [\n        albumentations.Resize(cfg.image_size, cfg.image_size, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\ndef inf():\n    super_final_preds = []\n\n    for fold_ in range(10):\n        model = BuildModel(model_name=\"swin_large_patch4_window12_384\")\n        model.load(f\"{pretrained_path}/model_f{fold_}.bin\", device=\"cuda\", weights_only=True)\n\n        test_dataset = BuildDataset(\n            image_paths=test['file_path'].values,\n            dense_features=test[dense_features].values,\n            targets=np.ones(len(test['file_path'].values)),\n            augmentations=augs,\n        )\n        \n        test_preds = model.predict(test_dataset, batch_size=2*cfg.batch_size, n_jobs=-1)\n\n        final_test_preds = []\n        for preds in tqdm(test_preds):\n            final_test_preds.extend(preds.ravel().tolist())\n\n        final_test_preds = [sigmoid(x) * 100 for x in final_test_preds]\n        super_final_preds.append(final_test_preds)\n\n    super_final_preds = np.mean(np.column_stack(super_final_preds), axis=1)\n    submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n    submission[\"Pawpularity\"] = super_final_preds\n    submission.to_csv('submission.csv', index=False)\n    submission.head()\n\ndef inf_test(prefix_dir):\n    #Placeholders\n    final_y_val = []\n    final_o_oof_preds = []\n    final_n_oof_preds = []\n    final_o_test_preds = []\n    final_n_test_preds = []\n    \n    fileid = 0\n    files = glob(f'{prefix_dir}*.bin')\n    nfiles = len(files)\n\n    train = pd.read_csv(f'{cfg.load_train_from}/train.csv')\n    #for fileid in range(nfiles):\n    for fold in range(nfiles):    \n        print(f'Number of files: {nfiles} | Loading file {cfg.pretrained_path}/model_f{fileid}.bin ...')\n        model = BuildModel(model_name=\"swin_large_patch4_window12_384\")\n        model.load(f\"{cfg.pretrained_path}/model_f{fileid}.bin\", device=\"cuda\", weights_only=True)      \n\n        # Set Regression Parameters\n        reg_params = {\n                        'tree_method': 'gpu_hist', \n                        'gpu_id': 0, \n                        'predictor': 'gpu_predictor',\n                        #'tree_method': 'hist',\n                        'booster' : 'gbtree',\n                        'n_estimators' : 10000,\n                        'learning_rate' : 0.03628302216953097,\n                        'reg_lambda' : 0.0008746338866473539,\n                        'reg_alpha' : 23.13181079976304,\n                        'subsample' : 0.7875490025178415,\n                        'colsample_bytree' : 0.11807135201147481,\n                        'max_depth' : 3,\n                        'random_state': cfg.seed+fileid\n        }\n\n        # Create Regression Model\n        #reg_model = cb.CatBoostRegressor(**reg_params)\n        #reg_model = xgb.XGBRegressor(**reg_params)\n        reg_model = SVR(C=20.0)\n\n        #for fold in range(cfg.bfolds):\n        df_train = train[train.kfold != fold].reset_index(drop=True)\n        df_val = train[train.kfold == fold].reset_index(drop=True)\n\n        y_train = df_train[cfg.target].values\n        y_val = df_val[cfg.target].values\n\n        final_y_val.append(y_val)\n\n        print(f'\\n===== File ID: {fileid} | Fold {fold+1}/{cfg.bfolds} ===============================================================================================')\n\n        print('Predicting OOF (Validation) from NN...')\n        valid_dataset = BuildDataset(\n            image_paths=df_val['file_path'].values,\n            dense_features=df_val[dense_features].values,\n            targets=y_val/100.0,\n            augmentations=augs,\n        )\n\n        val_preds = model.predict(valid_dataset, batch_size=2*cfg.batch_size, n_jobs=-1)\n\n        prev_oof_preds = []\n        x_val = np.array([]).reshape((0,128+12))\n        for preds in val_preds:\n            prev_oof_preds.extend(preds[:,:1].ravel().tolist())\n            x_val = np.concatenate([x_val,preds[:,1:]],axis=0)\n\n        prev_oof_preds = [sigmoid(x) * 100 for x in prev_oof_preds]\n\n        # Fit or load model\n        name = f'REG_fold_{fold}.pkl'\n        if cfg.load_reg_from is None:\n            train_dataset = BuildDataset(\n                image_paths=df_train['file_path'].values,\n                dense_features=df_train[dense_features].values,\n                targets=df_train[cfg.target].values/100.0,\n                augmentations=augs,\n            )\n\n            print('Extracting train embedding...')\n            train_preds = model.predict(train_dataset, batch_size=2*cfg.batch_size, n_jobs=-1)\n\n            x_train = np.array([]).reshape((0,128+12))\n            for preds in train_preds: #tqdm\n                x_train = np.concatenate([x_train,preds[:,1:]],axis=0)\n\n            print(f'Train Feature Set Shape: {x_train.shape}')\n\n            # Fit Regression Model\n            #reg_model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds = 100, verbose = 250)\n            reg_model.fit(x_train, y_train)\n\n            # Save Regression model\n            pickle.dump(reg_model, open(name, 'wb'))\n        else:\n            # Load Regression model\n            print(f'Loading Regression model {cfg.load_reg_from}/{name}')\n            reg_model = pickle.load(open(f'{cfg.load_reg_from}/{name}', 'rb'))\n\n        print('Predicting Regression validation...')\n        y_pred = reg_model.predict(x_val)\n\n        final_o_oof_preds.append(prev_oof_preds)\n        final_n_oof_preds.append(y_pred)\n\n        print('Predicting Test from NN...')\n\n        test_dataset = BuildDataset(\n            image_paths=test['file_path'].values,\n            dense_features=test[dense_features].values,\n            targets=np.ones(len(test['file_path'].values)),\n            augmentations=augs\n        )\n\n        test_preds = model.predict(test_dataset, batch_size=2*cfg.batch_size, n_jobs=-1)\n\n        prev_test_preds = []\n        x_test = np.array([]).reshape((0,128+12))\n        for preds in test_preds:\n            prev_test_preds.extend(preds[:,:1].ravel().tolist())\n            x_test = np.concatenate([x_test,preds[:,1:]],axis=0)\n\n        print(f'Test Feature Set Shape: {x_test.shape}')\n\n        prev_test_preds = [sigmoid(x) * 100 for x in prev_test_preds]\n        reg_test_preds = reg_model.predict(x_test)\n\n        final_o_test_preds.append(prev_test_preds)\n        final_n_test_preds.append(reg_test_preds)\n\n        # OOF Score for Regression run\n        nn_oof_score = get_score(final_y_val[-1], final_o_oof_preds[-1])\n        reg_oof_score = get_score(final_y_val[-1], final_n_oof_preds[-1])\n\n        print(f'Model path: {prefix_dir}{fileid}.bin| Fold: {fold+1}/{cfg.bfolds} | NN OOF Score: {nn_oof_score}')\n        print(f'Model path: {cfg.load_reg_from}/{name} | Fold: {fold+1}/{cfg.bfolds} | Regression OOF Score: {reg_oof_score}')\n\n        # Weights\n        w = 0.5\n        oof2 = (1-w)*np.array(final_o_oof_preds[-1]) + w*np.array(final_n_oof_preds[-1])\n        w_score = get_score(final_y_val[-1], oof2)\n        print('Ensemble score =',w_score,'\\n')\n\n        print('Test Predictions Cumulative...')\n        print(final_n_test_preds[:5])\n            \n        # Cleanup\n        del df_train, df_val, y_train, y_val\n        del model, reg_model\n        del val_preds, test_preds\n        gc.collect()\n\n    # Final OOF score for All Feature Models\n    true = np.hstack(final_y_val)\n\n    oof = np.hstack(final_o_oof_preds)\n    score = get_score(true, oof)\n    print('Overall CV NN head score =',score)\n\n    oof2 = np.hstack(final_n_oof_preds)\n    score = get_score(true, oof2)\n    print('Overall CV Regression head score =',score)\n\n    oof3 = (1-w)*oof + w*oof2\n    score = get_score(true, oof3)\n    print('Overall CV Ensemble heads score with 50% NN and 50% Regression =',score)\n\n    scores = []\n    for ww in np.arange(0,1.05,0.05):\n        oof3 = (1-ww)*oof + ww*oof2\n        score = get_score(true, oof3)\n        #print(f'{ww:0.2} CV Ensemble score =',score)\n        scores.append(score)\n    best_w = np.argmin(scores)*0.05\n\n    final_o_test_preds = np.mean(np.column_stack(final_o_test_preds), axis=1)\n    final_n_test_preds = np.mean(np.column_stack(final_n_test_preds), axis=1)\n\n    submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n    submission[\"Pawpularity\"] = (1-best_w)*final_o_test_preds + best_w*final_n_test_preds\n    submission.to_csv('submission.csv', index=False)\n    submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inf():\n    pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"inf_test(prefix_dir='../input/pf-st-patch4/model_f')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}