{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TensorFlow multi-input model + EfficientNet + FE\n\nThis is a first try to build multi model, based on notebooks:\n\nhttps://www.kaggle.com/yamqwe/tf-efficientnet-multi-input\n\nhttps://www.kaggle.com/yamqwe/tf-nfnet-vit-efn-tta-infer/notebook\n\nhttps://www.kaggle.com/awsaf49/tf-petfinder-image-tpu-train\n\n\nAdding cross-featutes idea is from excelent notebook by Ekaterina Dranitsyna: \n\nhttps://www.kaggle.com/ekaterinadranitsyna/xgboost-for-tabular-data\n","metadata":{}},{"cell_type":"code","source":"!pip install ../input/keras-applications/Keras_Applications-1.0.8/ -f ./ --no-index\n!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps","metadata":{"execution":{"iopub.status.busy":"2021-12-15T20:30:02.795887Z","iopub.execute_input":"2021-12-15T20:30:02.796305Z","iopub.status.idle":"2021-12-15T20:30:35.754522Z","shell.execute_reply.started":"2021-12-15T20:30:02.796202Z","shell.execute_reply":"2021-12-15T20:30:35.75371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\n\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import KFold\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler","metadata":{"execution":{"iopub.status.busy":"2021-12-15T20:30:35.756715Z","iopub.execute_input":"2021-12-15T20:30:35.756993Z","iopub.status.idle":"2021-12-15T20:30:41.320025Z","shell.execute_reply.started":"2021-12-15T20:30:35.756956Z","shell.execute_reply":"2021-12-15T20:30:41.319149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import datasets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/petfinder-pawpularity-score/train.csv\")\ntest = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\nsample_submission = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n\n## adding image file names\ntrain[\"file_path\"] = train[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/train/\" + identifier + \".jpg\")\ntest[\"file_path\"] = test[\"Id\"].apply(lambda identifier: \"../input/petfinder-pawpularity-score/test/\" + identifier + \".jpg\")\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T21:04:08.879698Z","iopub.execute_input":"2021-12-15T21:04:08.879978Z","iopub.status.idle":"2021-12-15T21:04:08.941913Z","shell.execute_reply.started":"2021-12-15T21:04:08.879949Z","shell.execute_reply":"2021-12-15T21:04:08.941107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"%%time\n\nFEATURE_COLUMNS = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nCAT_FEATURES = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nTARGET_COLUMN = \"Pawpularity\"\n\ndef add_cross_features(df):\n    for feature1 in FEATURE_COLUMNS:    \n        for feature2 in FEATURE_COLUMNS:\n            if feature1 != feature2:\n                x2_feature_name = f'{feature1}-{feature2}'\n                if x2_feature_name not in df.columns:\n                    df[x2_feature_name] = df[feature1].astype(str) + '_' + df[feature2].astype(str)\n                    CAT_FEATURES.append(x2_feature_name)\n                    for feature3 in FEATURE_COLUMNS:\n                        if feature3 != feature2 and feature3 != feature1:\n                            x3_feature_name = f'{feature1}-{feature2}-{feature3}'\n                            if x3_feature_name not in df.columns:\n                                df[x3_feature_name] = df[feature1].astype(str) + '_' + df[feature2].astype(str) + '_' + df[feature3].astype(str)\n                                CAT_FEATURES.append(x3_feature_name)\n    return df\n                \n                \ntrain = add_cross_features(train)\ntest = add_cross_features(test)\n\n## set all features as categorical\nfor c in CAT_FEATURES:\n    train[c] = keras.utils.to_categorical(train[c])\n    test[c] = keras.utils.to_categorical(test[c])\n\nFEATURE_COLUMNS = np.unique(CAT_FEATURES).tolist()\nprint('features len:', len(FEATURE_COLUMNS))\nprint('train shape:',train.shape)\nprint('test shape:',test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T21:04:10.208085Z","iopub.execute_input":"2021-12-15T21:04:10.2084Z","iopub.status.idle":"2021-12-15T21:08:03.262482Z","shell.execute_reply.started":"2021-12-15T21:04:10.208367Z","shell.execute_reply":"2021-12-15T21:08:03.261699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE=128\n\n## Feature model\ndef build_feature_model(inputs):\n    width = 64\n    depth = 2\n    activation = \"relu\"\n    dropout = 0.1\n    x = keras.layers.Dense(width, activation=activation)(inputs)\n    for i in range(depth):\n        if i == 0:\n            x = inputs\n        x = keras.layers.Dense(width, activation=activation)(x)\n        #x = keras.layers.Dropout(dropout)(x)\n        if (i + 1) % 3 == 0:\n            x = keras.layers.BatchNormalization()(x)\n            x = keras.layers.Concatenate()([x, inputs])\n    return x\n\ndef RMSE(y_true, y_pred):\n    loss = tf.math.sqrt(tf.math.reduce_mean(tf.math.square(tf.subtract(y_true, y_pred))))\n    return loss\n\ndef block(x, filters, kernel_size, repetitions, pool_size=2, strides=2):\n    for i in range(repetitions):\n        x = tf.keras.layers.Conv2D(filters, kernel_size, activation='relu', padding='same')(x)\n    x = tf.keras.layers.MaxPooling2D(pool_size, strides)(x)\n    return x\n\n# CNN + feature model\ndef build_full_model():\n    image_inputs = tf.keras.Input((IMAGE_SIZE, IMAGE_SIZE , 3))\n    tabular_inputs = tf.keras.Input(len(FEATURE_COLUMNS))\n    efficient_model = efn.EfficientNetB4(include_top=False, \n                                weights='../input/efficientnet-weights-for-keras/noisy-student/notop/efficientnet-b4_noisy-student_notop.h5', \n                                pooling=None)\n    image_x = efficient_model(image_inputs)\n    #block(x, filters, kernel_size, 2, pool_size=2, strides=2)\n    image_x = tf.keras.layers.GlobalAveragePooling2D()(image_x)\n    tabular_x = build_feature_model(tabular_inputs)\n    x = tf.keras.layers.Concatenate(axis=1)([image_x, tabular_x])\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(64)(x)\n    output = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs=[image_inputs, tabular_inputs], outputs=[output])\n    return model\n\nmodel = build_full_model()\ntf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T21:08:03.264156Z","iopub.execute_input":"2021-12-15T21:08:03.264671Z","iopub.status.idle":"2021-12-15T21:08:10.276997Z","shell.execute_reply.started":"2021-12-15T21:08:03.264631Z","shell.execute_reply":"2021-12-15T21:08:10.276183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"EPOCHS = 30\nRANDOM_SEED=42\nBATCH_SIZE = 32\nTOTAL_SPLITS = 6\n\ndef preprocess(image_url, tabular, target):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n    return (image, tabular), tf.cast(target, tf.float32)\n\ndef get_dataset(X, train_idx, val_idx):\n\n    X_file = X.loc[train_idx, \"file_path\"]\n    X_features = X.loc[train_idx, FEATURE_COLUMNS ]\n    y = X.loc[train_idx, TARGET_COLUMN ]\n\n    X_val_file = X.loc[val_idx, \"file_path\"]\n    X_val_features = X.loc[val_idx, FEATURE_COLUMNS ]\n    y_val = X.loc[val_idx, TARGET_COLUMN ]\n    \n    dataset = tf.data.Dataset.from_tensor_slices((X_file, X_features, y)).map(preprocess).shuffle(512).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n    val_dataset = tf.data.Dataset.from_tensor_slices((X_val_file, X_val_features, y_val)).map(preprocess).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n    return dataset, val_dataset\n\n# convert tagret to 0-1 range\ntrain[TARGET_COLUMN] = train[TARGET_COLUMN]/100\n\nimage = np.random.normal(size=(1, IMAGE_SIZE, IMAGE_SIZE, 3))\ntabular = np.random.normal(size=(1, len(FEATURE_COLUMNS)))\n\nprint(image.shape, tabular.shape)\nprint(model((image, tabular)).shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T21:12:13.119982Z","iopub.execute_input":"2021-12-15T21:12:13.120294Z","iopub.status.idle":"2021-12-15T21:12:13.254957Z","shell.execute_reply.started":"2021-12-15T21:12:13.120265Z","shell.execute_reply":"2021-12-15T21:12:13.254273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Learning-Rate Scheduler\n\nhttps://www.kaggle.com/awsaf49/tf-petfinder-image-tpu-train#Learning-Rate-Scheduler","metadata":{}},{"cell_type":"code","source":"def get_lr_callback(batch_size=8, plot=False, scheduler='exp', epochs=EPOCHS ):\n    lr_start   = 0.000005\n    lr_max     = 0.00000125 * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        elif scheduler=='exp':\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        elif scheduler=='cosine':\n            decay_total_epochs = epochs - lr_ramp_ep - lr_sus_ep + 3\n            decay_epoch_index = epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            cosine_decay = 0.5 * (1 + math.cos(phase))\n            lr = (lr_max - lr_min) * cosine_decay + lr_min\n        return lr\n    if plot:\n        plt.figure(figsize=(10,5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('learnig rate')\n        plt.title('Learning Rate Scheduler')\n        plt.show()\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\n_=get_lr_callback(BATCH_SIZE, plot=True )","metadata":{"execution":{"iopub.status.busy":"2021-12-15T21:12:14.693591Z","iopub.execute_input":"2021-12-15T21:12:14.694157Z","iopub.status.idle":"2021-12-15T21:12:14.903835Z","shell.execute_reply.started":"2021-12-15T21:12:14.694123Z","shell.execute_reply":"2021-12-15T21:12:14.903077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntf.keras.backend.clear_session()\nearly_stop = tf.keras.callbacks.EarlyStopping(min_delta=1e-4, patience=10)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.3,patience=2, min_lr=1e-7)\noptimizer = tf.keras.optimizers.Adam(0.001)\n\nmodels = []\nhistorys = []\nkfold = KFold(n_splits=TOTAL_SPLITS, shuffle=True, random_state=RANDOM_SEED)\nfor index, (train_idx, val_idx) in enumerate(kfold.split(train)):\n    \n    train_ds, val_ds = get_dataset( train, train_idx, val_idx)\n        \n    checkpoint_path = \"model_%d.h5\"%(index)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)\n    callbacks = [early_stop, checkpoint, get_lr_callback(BATCH_SIZE)]    \n    \n    rmse = tf.keras.metrics.RootMeanSquaredError(name='rmse')\n    model.compile(loss=RMSE, optimizer=optimizer, metrics=[rmse])\n    history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=callbacks)\n    \n    model.load_weights(checkpoint_path)\n    historys.append(history)\n    models.append(model)    ","metadata":{"execution":{"iopub.status.busy":"2021-12-15T21:12:15.786837Z","iopub.execute_input":"2021-12-15T21:12:15.787392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Display metrics","metadata":{}},{"cell_type":"code","source":"xx = range(0, EPOCHS)\ncol_metrics = [\"loss\", \"val_loss\", \"lr\"]\n\nf, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 8))\nfor hist in historys:\n    df = pd.DataFrame(hist.history, columns=col_metrics)\n    ax1.plot( df[[col_metrics[0], col_metrics[1]]])\nax2.plot( df[[col_metrics[2]]])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:13:22.561029Z","iopub.execute_input":"2021-12-14T22:13:22.561288Z","iopub.status.idle":"2021-12-14T22:13:22.873725Z","shell.execute_reply.started":"2021-12-14T22:13:22.561261Z","shell.execute_reply":"2021-12-14T22:13:22.872933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"def preprocess_test_data(image_url, tabular):\n    print(image_url, tabular)\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n    # 0 won't be used in prediction, but it's needed in this senario or the tabular variable is treated as label.\n    return (image, tabular), 0\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test[\"file_path\"], test[FEATURE_COLUMNS])).map(preprocess_test_data).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:13:43.110956Z","iopub.execute_input":"2021-12-14T22:13:43.111236Z","iopub.status.idle":"2021-12-14T22:13:43.222287Z","shell.execute_reply.started":"2021-12-14T22:13:43.111205Z","shell.execute_reply":"2021-12-14T22:13:43.221471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nfor model in models:\n    results.append(model.predict(test_ds).reshape(-1))\n\n# convert back to 100 range\npredictions = np.mean(results, axis=0).reshape(-1)*100\n\nsample_submission[\"Pawpularity\"] = predictions\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:13:44.065128Z","iopub.execute_input":"2021-12-14T22:13:44.065393Z","iopub.status.idle":"2021-12-14T22:13:45.79271Z","shell.execute_reply.started":"2021-12-14T22:13:44.065364Z","shell.execute_reply":"2021-12-14T22:13:45.791903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T22:13:45.794135Z","iopub.execute_input":"2021-12-14T22:13:45.794377Z","iopub.status.idle":"2021-12-14T22:13:45.806014Z","shell.execute_reply.started":"2021-12-14T22:13:45.794344Z","shell.execute_reply":"2021-12-14T22:13:45.805097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}