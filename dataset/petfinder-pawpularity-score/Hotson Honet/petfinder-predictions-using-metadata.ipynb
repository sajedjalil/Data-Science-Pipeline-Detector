{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Modules","metadata":{}},{"cell_type":"code","source":"# Standard imports\nimport os\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import trange\nfrom colorama import Fore\nfrom glob import glob\nimport json\nfrom pprint import pprint\nimport time\nimport cv2\nfrom enum import Enum\nfrom IPython.display import display\n\n# For Data preparation\nfrom sklearn.preprocessing import *\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:12.43705Z","iopub.execute_input":"2021-11-08T20:33:12.437679Z","iopub.status.idle":"2021-11-08T20:33:15.196623Z","shell.execute_reply.started":"2021-11-08T20:33:12.437587Z","shell.execute_reply":"2021-11-08T20:33:15.195922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"class Config(Enum):\n    '''\n    It basically contains all the path location and other stuffs\n    \n    '''\n    \n    def __str__(self):\n        return self.value\n\n    TRAIN_CSV = \"../input/petfinder-pawpularity-score/train.csv\"\n    TEST_CSV = \"../input/petfinder-pawpularity-score/test.csv\"\n    SAMPLE_CSV = \"../input/petfinder-pawpularity-score/sample_submission.csv\"\n    TRAIN_DIR = \"../input/petfinder-pawpularity-score/train\"\n    TEST_DIR = \"../input/petfinder-pawpularity-score/test\"","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:15.198074Z","iopub.execute_input":"2021-11-08T20:33:15.198405Z","iopub.status.idle":"2021-11-08T20:33:15.202997Z","shell.execute_reply.started":"2021-11-08T20:33:15.198376Z","shell.execute_reply":"2021-11-08T20:33:15.202311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Data files","metadata":{}},{"cell_type":"code","source":"data_df = pd.read_csv(Config.TRAIN_CSV.value)\ntest_df = pd.read_csv(Config.TEST_CSV.value)\nsample_df = pd.read_csv(Config.SAMPLE_CSV.value)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:15.204209Z","iopub.execute_input":"2021-11-08T20:33:15.204517Z","iopub.status.idle":"2021-11-08T20:33:15.282083Z","shell.execute_reply.started":"2021-11-08T20:33:15.204479Z","shell.execute_reply":"2021-11-08T20:33:15.281236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:15.284135Z","iopub.execute_input":"2021-11-08T20:33:15.284385Z","iopub.status.idle":"2021-11-08T20:33:15.312868Z","shell.execute_reply.started":"2021-11-08T20:33:15.284354Z","shell.execute_reply":"2021-11-08T20:33:15.312071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:15.314549Z","iopub.execute_input":"2021-11-08T20:33:15.315121Z","iopub.status.idle":"2021-11-08T20:33:15.331018Z","shell.execute_reply.started":"2021-11-08T20:33:15.315076Z","shell.execute_reply":"2021-11-08T20:33:15.330383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:15.331939Z","iopub.execute_input":"2021-11-08T20:33:15.332413Z","iopub.status.idle":"2021-11-08T20:33:15.343116Z","shell.execute_reply.started":"2021-11-08T20:33:15.332371Z","shell.execute_reply":"2021-11-08T20:33:15.342148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets see the label distribution","metadata":{}},{"cell_type":"code","source":"labels = data_df[\"Pawpularity\"]\nprint(f\"min value of Pawpularity is : {min(labels)}\")\nprint(f\"max value of Pawpularity is : {max(labels)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:15.344507Z","iopub.execute_input":"2021-11-08T20:33:15.344984Z","iopub.status.idle":"2021-11-08T20:33:15.357679Z","shell.execute_reply.started":"2021-11-08T20:33:15.344953Z","shell.execute_reply":"2021-11-08T20:33:15.356811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def giveHistogram(df : \"data File\", col_name : str, bins = None, dark = False):\n    \"\"\"\n    To create histogram plots\n\n    \"\"\"\n    fig = px.histogram(df, x = col_name, template = \"plotly_dark\" if dark else \"ggplot2\", nbins = bins if bins != None else 1 + int(np.log2(len(df))))\n    fig.update_layout(\n            title_text = f\"Distribution of {col_name}\",\n            title_x = 0.5,\n    )\n    fig.show()\n\ngiveHistogram(data_df, \"Pawpularity\")","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:15.358926Z","iopub.execute_input":"2021-11-08T20:33:15.359475Z","iopub.status.idle":"2021-11-08T20:33:16.732692Z","shell.execute_reply.started":"2021-11-08T20:33:15.359438Z","shell.execute_reply":"2021-11-08T20:33:16.731803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mapping the images location ","metadata":{}},{"cell_type":"code","source":"data_df[\"path\"] = data_df[\"Id\"].apply(lambda x : Config.TRAIN_DIR.value + f\"/{x}.jpg\")\ntest_df[\"path\"] = test_df[\"Id\"].apply(lambda x : Config.TEST_DIR.value + f\"/{x}.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:16.734212Z","iopub.execute_input":"2021-11-08T20:33:16.734522Z","iopub.status.idle":"2021-11-08T20:33:16.75563Z","shell.execute_reply.started":"2021-11-08T20:33:16.73448Z","shell.execute_reply":"2021-11-08T20:33:16.754879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets see the distribution of widths and heights of the images","metadata":{}},{"cell_type":"code","source":"def widthAndHeightDist(df : \"data_file\", col_name : \"col name that contains the img path\", dark = False):\n    widths = []; heights = []; bins = 1 + int(np.log2(len(df)))\n    total_images = list(df[col_name].values) \n    for idx in trange(len(total_images), desc = \"Collecting widths and heights...\", bar_format=\"{l_bar}%s{bar:50}%s{r_bar}\" % (Fore.CYAN, Fore.RESET), position = 0, leave = True):\n        cur_path = total_images[idx]\n        h, w, _ = cv2.imread(cur_path).shape\n        widths.append(w)\n        heights.append(h)\n\n    figW = px.histogram(widths, nbins = bins, template = \"plotly_dark\" if dark else \"ggplot2\")\n    figW.update_layout(title = 'Distribution of Image Widths', title_x = 0.5)\n    figW.show();\n    \n    figH = px.histogram(heights, nbins = bins, template = \"plotly_dark\" if dark else \"ggplot2\")\n    figH.update_layout(title = 'Distribution of Image Heights', title_x = 0.5)\n    figH.show();\n    \nwidthAndHeightDist(data_df, \"path\")","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:33:16.758576Z","iopub.execute_input":"2021-11-08T20:33:16.758795Z","iopub.status.idle":"2021-11-08T20:35:51.989378Z","shell.execute_reply.started":"2021-11-08T20:33:16.758767Z","shell.execute_reply":"2021-11-08T20:35:51.988537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets look at some images","metadata":{}},{"cell_type":"code","source":"def buildGridImages(df : \"data_file\", img_path_col_name: str, label_col_name: str, nrows = 5, ncols = 4, img_size = 512):\n    \"\"\"\n    To build an image grid\n    \"\"\"\n    \n    df = df.sample(nrows*ncols)\n    paths = df[img_path_col_name].values\n    labels = df[label_col_name].values\n\n    text_color = (255, 255, 255)\n    box_color = (0, 0, 0)\n    \n    plt.figure(figsize=(20,12))\n    for i in range(nrows * ncols):\n        plt.subplot(nrows,ncols,i+1)\n        img = cv2.imread(paths[i])\n        img = cv2.resize(img, (img_size, img_size))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        plt.axis(\"off\")\n        plt.title(str(labels[i]))\n        plt.imshow(img)\n\n\n    plt.tight_layout()\n    plt.show()    \n\nbuildGridImages(data_df, \"path\", \"Pawpularity\", 6, 6, 256)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:35:51.990644Z","iopub.execute_input":"2021-11-08T20:35:51.991403Z","iopub.status.idle":"2021-11-08T20:35:55.05666Z","shell.execute_reply.started":"2021-11-08T20:35:51.991349Z","shell.execute_reply":"2021-11-08T20:35:55.055869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets see the key differences between minimum and maximum marks images\n\n- Minimum is 1\n- Maximum is 100\n- what is **pawpularity** ?\n    - *Feature engineering that the Petfinder team would find valuable would be determining if certain factors from pet profile images increase the popularity of the profile - e.g. \"When dogs wear color collars, their popularity increases by x%\"*\n    - Answered in the [discussion](https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/274025)","metadata":{}},{"cell_type":"code","source":"pp_100_df = data_df.loc[data_df.Pawpularity == 100]\npp_1_df = data_df.loc[data_df.Pawpularity == 1]\n\nprint(f\"Num of images having 100 score : {len(pp_100_df)}\")\nprint(f\"Num of images having 1 score : {len(pp_1_df)}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:35:55.05792Z","iopub.execute_input":"2021-11-08T20:35:55.058634Z","iopub.status.idle":"2021-11-08T20:35:55.067491Z","shell.execute_reply.started":"2021-11-08T20:35:55.058599Z","shell.execute_reply":"2021-11-08T20:35:55.066626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### *Lets look 1 score images*","metadata":{}},{"cell_type":"code","source":"pp_1_df","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:35:55.06856Z","iopub.execute_input":"2021-11-08T20:35:55.068823Z","iopub.status.idle":"2021-11-08T20:35:55.09534Z","shell.execute_reply.started":"2021-11-08T20:35:55.068785Z","shell.execute_reply":"2021-11-08T20:35:55.094395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buildGridImages(pp_1_df, \"path\", \"Pawpularity\", 1, 4, 256)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:35:55.096635Z","iopub.execute_input":"2021-11-08T20:35:55.096975Z","iopub.status.idle":"2021-11-08T20:35:55.879864Z","shell.execute_reply.started":"2021-11-08T20:35:55.096927Z","shell.execute_reply":"2021-11-08T20:35:55.878924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lets some perfect score images","metadata":{}},{"cell_type":"code","source":"pp_100_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:35:55.881461Z","iopub.execute_input":"2021-11-08T20:35:55.881817Z","iopub.status.idle":"2021-11-08T20:35:55.897444Z","shell.execute_reply.started":"2021-11-08T20:35:55.881783Z","shell.execute_reply":"2021-11-08T20:35:55.896489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buildGridImages(pp_100_df, \"path\", \"Pawpularity\", 4, 4, 256)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:35:55.898596Z","iopub.execute_input":"2021-11-08T20:35:55.89882Z","iopub.status.idle":"2021-11-08T20:35:57.607763Z","shell.execute_reply.started":"2021-11-08T20:35:55.898794Z","shell.execute_reply":"2021-11-08T20:35:57.607102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observations\n- Pets in the images are getting blended with their background","metadata":{}},{"cell_type":"markdown","source":"#### Lets see some of the images that are 1 for each meta data","metadata":{}},{"cell_type":"code","source":"req_cols = [\n    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n]\n\nfor col in req_cols:\n    tmp_df = data_df.loc[data_df[col] == 1].sample(5)\n    print(f\"################### {col} ###################\")\n    buildGridImages(tmp_df, \"path\", \"Pawpularity\", 1, 5, 256)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:42.335226Z","iopub.execute_input":"2021-11-08T20:36:42.335518Z","iopub.status.idle":"2021-11-08T20:36:52.029135Z","shell.execute_reply.started":"2021-11-08T20:36:42.335488Z","shell.execute_reply":"2021-11-08T20:36:52.028388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets create folds of our dataset","metadata":{}},{"cell_type":"code","source":"def create_folds_regression(data, target=\"target\", num_splits = 5): \n    \"\"\"\n    Helper function to create folds\n    \n    \"\"\"\n    data[\"kfold\"] = -1 \n    data = data.sample(frac=1).reset_index(drop=True)\n    \n    # Applying Sturg's rule to calculate the no. of bins for target\n    num_bins = int(1 + np.log2(len(data))) \n\n    data.loc[:, \"bins\"] = pd.cut(data[target], bins=num_bins, labels=False) \n    \n    kf = StratifiedKFold(n_splits=num_splits)\n    \n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)): \n        data.loc[v_, 'kfold'] = f\n        \n    data = data.drop([\"bins\"], axis = 1)         \n    return data \n\n\ndata_df = create_folds_regression(data_df, target = 'Pawpularity', num_splits = 5)\ndata_df.kfold.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:06.95867Z","iopub.execute_input":"2021-11-08T20:36:06.959185Z","iopub.status.idle":"2021-11-08T20:36:06.99599Z","shell.execute_reply.started":"2021-11-08T20:36:06.959145Z","shell.execute_reply":"2021-11-08T20:36:06.995252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:06.997169Z","iopub.execute_input":"2021-11-08T20:36:06.997419Z","iopub.status.idle":"2021-11-08T20:36:07.013755Z","shell.execute_reply.started":"2021-11-08T20:36:06.997381Z","shell.execute_reply":"2021-11-08T20:36:07.012662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets automate our training","metadata":{}},{"cell_type":"code","source":"# Regression Models\nfrom sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, VotingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor, StackingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\n# Evalution Metrix\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import cross_validate","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:07.015433Z","iopub.execute_input":"2021-11-08T20:36:07.015731Z","iopub.status.idle":"2021-11-08T20:36:07.725007Z","shell.execute_reply.started":"2021-11-08T20:36:07.015691Z","shell.execute_reply":"2021-11-08T20:36:07.723984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse_score(y_label, y_preds):\n    \"\"\"\n    Gives RMSE score\n    \"\"\"\n    return np.sqrt(mean_squared_error(y_label, y_preds))\n    \n\ndef trainRegModels(df : \"data_file\", features : list, label: str):\n    \"\"\"\n    To automate the training of regression models. Considering\n        > RMSE\n        > R2 score\n    \n    \"\"\"\n    regModels = {\n            \"LinearRegression\": LinearRegression(),\n            \"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=2),\n            \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0, n_estimators=100),\n            \"LGBMRegressor\": LGBMRegressor(),\n            \"Ridge\": Ridge(alpha=1.0),\n            \"ElasticNet\": ElasticNet(random_state=0),\n            \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n            \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n            \"ExtraTreesRegressor\": ExtraTreesRegressor(n_jobs=-1),\n            \"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1),\n            \"XGBRegressor\": XGBRegressor(n_jobs=-1),\n            \"CatBoostRegressor\": CatBoostRegressor(iterations=900, depth=5, learning_rate=0.05, loss_function = 'RMSE'),\n        }\n    \n    # Will return this as a data frame\n    summary = {\n        \"Model\" : [],\n        \"Avg R2 Train Score\" : [],\n        \"Avg R2 Val Score\" : [],\n        \"Avg RSME Train Score\" : [],\n        \"Avg RSME Val Score\" : []\n    }\n    \n    # Training\n    for idx in trange(len(regModels.keys()), desc = \"Models are training...\", bar_format=\"{l_bar}%s{bar:50}%s{r_bar}\" % (Fore.CYAN, Fore.RESET), position = 0, leave = True):\n        name = list(regModels.keys())[idx]\n        model = regModels[name]\n        \n        # Initializing all the scores to 0\n        r2_train = 0; r2_val = 0\n        rmse_train = 0; rmse_val = 0\n        \n        # Running K-fold Cross-validation on every model\n        for fold in range(5):\n            train_df = df.loc[df.kfold != fold].reset_index(drop = True)\n            val_df = df.loc[df.kfold == fold].reset_index(drop = True)\n            \n            train_X = train_df[features]; train_Y = train_df[label]\n            val_X = val_df[features]; val_Y = val_df[label]\n            \n            cur_model = model\n            if name == 'CatBoostRegressor':\n                cur_model.fit(train_X, train_Y,verbose=False)\n            else:\n                cur_model.fit(train_X, train_Y)\n\n            Y_train_preds = model.predict(train_X)\n            Y_val_preds = model.predict(val_X)\n            \n            # Collecting the scores\n            r2_train += r2_score(train_Y, Y_train_preds)\n            r2_val += r2_score(val_Y, Y_val_preds)\n            \n            rmse_train += rmse_score(train_Y, Y_train_preds)\n            rmse_val += rmse_score(val_Y, Y_val_preds)\n        \n        # Pushing the scores and the Model names\n        summary[\"Model\"].append(name)\n        summary[\"Avg R2 Train Score\"].append(r2_train/5)\n        summary[\"Avg R2 Val Score\"].append(r2_val/5)\n        summary[\"Avg RSME Train Score\"].append(rmse_train/5)\n        summary[\"Avg RSME Val Score\"].append(rmse_val/5)\n    \n    # Finally returning the summary dictionary as a dataframe\n    summary_df = pd.DataFrame(summary)\n    return summary_df\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:07.726552Z","iopub.execute_input":"2021-11-08T20:36:07.726777Z","iopub.status.idle":"2021-11-08T20:36:07.745222Z","shell.execute_reply.started":"2021-11-08T20:36:07.72675Z","shell.execute_reply":"2021-11-08T20:36:07.744594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_summary = trainRegModels(data_df, req_cols, \"Pawpularity\")\ntraining_summary","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:07.746395Z","iopub.execute_input":"2021-11-08T20:36:07.746756Z","iopub.status.idle":"2021-11-08T20:36:32.873048Z","shell.execute_reply.started":"2021-11-08T20:36:07.746712Z","shell.execute_reply":"2021-11-08T20:36:32.872115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_summary.sort_values(\"Avg RSME Val Score\", axis = 0, ascending = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:32.874413Z","iopub.execute_input":"2021-11-08T20:36:32.87464Z","iopub.status.idle":"2021-11-08T20:36:32.888835Z","shell.execute_reply.started":"2021-11-08T20:36:32.874611Z","shell.execute_reply":"2021-11-08T20:36:32.888155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Let's see the combined power of top-2 models***","metadata":{}},{"cell_type":"code","source":"en = ElasticNet(random_state=0)\ngbr = GradientBoostingRegressor(random_state=0)\nVR_model = VotingRegressor([('en', en),('gbr', gbr)], n_jobs=-1)\n\nr2_train = 0; r2_val = 0\nrmse_train = 0; rmse_val = 0\n\nmodel = VR_model\nfor fold in trange(5, desc = \"Models are training...\", bar_format=\"{l_bar}%s{bar:50}%s{r_bar}\" % (Fore.CYAN, Fore.RESET), position = 0, leave = True):\n    train_df = data_df.loc[data_df.kfold != fold].reset_index(drop = True)\n    val_df = data_df.loc[data_df.kfold == fold].reset_index(drop = True)\n\n    train_X = train_df[req_cols]; train_Y = train_df[\"Pawpularity\"]\n    val_X = val_df[req_cols]; val_Y = val_df[\"Pawpularity\"]\n    \n    model.fit(train_X, train_Y)\n\n    Y_train_preds = model.predict(train_X)\n    Y_val_preds = model.predict(val_X)\n\n    # Collecting the scores\n    r2_train += r2_score(train_Y, Y_train_preds)\n    r2_val += r2_score(val_Y, Y_val_preds)\n\n    rmse_train += rmse_score(train_Y, Y_train_preds)\n    rmse_val += rmse_score(val_Y, Y_val_preds)\n\nprint(f\"Avg R2 Train Score : {r2_train/5}\")\nprint(f\"Avg R2 Val Score : {r2_val/5}\")\nprint(f\"Avg RSME Train Score : {rmse_train/5}\")\nprint(f\"Avg RSME Val Score : {rmse_val/5}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:32.889954Z","iopub.execute_input":"2021-11-08T20:36:32.890617Z","iopub.status.idle":"2021-11-08T20:36:37.77031Z","shell.execute_reply.started":"2021-11-08T20:36:32.890581Z","shell.execute_reply":"2021-11-08T20:36:37.764739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸ¤” ***Hmm...Nothing much improvement but lets see the submission results***","metadata":{}},{"cell_type":"markdown","source":"# Prediction Time ðŸ˜Ž","metadata":{}},{"cell_type":"code","source":"sample_df","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:36:37.772019Z","iopub.execute_input":"2021-11-08T20:36:37.773884Z","iopub.status.idle":"2021-11-08T20:36:37.789249Z","shell.execute_reply.started":"2021-11-08T20:36:37.773832Z","shell.execute_reply":"2021-11-08T20:36:37.788354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_X = test_df[req_cols]\n\nmodel_preds = model.predict(test_X)\ntest_df[\"Pawpularity\"] = model_preds\n\nsubmission = test_df[[\"Id\", \"Pawpularity\"]]\nsubmission.to_csv(\"submission.csv\", index = False)\ndata_df.to_csv(\"data.csv\", index = False)\ntest_df.to_csv(\"test.csv\", index = False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-08T20:37:19.258256Z","iopub.execute_input":"2021-11-08T20:37:19.258527Z","iopub.status.idle":"2021-11-08T20:37:19.370231Z","shell.execute_reply.started":"2021-11-08T20:37:19.258498Z","shell.execute_reply":"2021-11-08T20:37:19.369302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}