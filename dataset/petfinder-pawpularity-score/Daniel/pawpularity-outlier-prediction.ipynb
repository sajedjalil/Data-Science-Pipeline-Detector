{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style='text-align: center'> Pawpularity Outlier Prediction </h1>","metadata":{}},{"cell_type":"markdown","source":"Today I tried  building a model that predicts outliers from the dataset (regarding their pawpularity score), since this is something a general model should not be too good at.\nI separated the data into 3 different categories: Pawpularity < 10, Pawpularity == 100, and the rest.\nThen I trained the model using an EfficientNet Backbone.\nHaven't done a lot of experiments, but to be honest the approach doesn't seem too promising. CV is not really better, if at all. But if you want more details, take a look at the code.","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/packages/packages')\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nfrom torchvision.io import read_image\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import WandbLogger\nimport wandb\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom box import Box\nimport timm\n\n# wandb.login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-19T14:37:44.418097Z","iopub.execute_input":"2021-10-19T14:37:44.418878Z","iopub.status.idle":"2021-10-19T14:37:52.902719Z","shell.execute_reply.started":"2021-10-19T14:37:44.418785Z","shell.execute_reply":"2021-10-19T14:37:52.90188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"cfg = {\n    'img_size': 240,\n    'n_splits': 5,\n    'ratio': 1,\n    'model': {\n        'name': 'efficientnet_b1',\n        'dropout': 0.5,\n        'out_dim': 3\n    },\n    'train_loader': {\n        'batch_size': 64,\n        'shuffle': True\n    },\n    'val_loader': {\n        'batch_size': 64\n    },\n    'criterion': 'nn.BCEWithLogitsLoss',\n    'optim': {\n        'name': 'torch.optim.Adam',\n        'params': {\n            'lr': 1e-5\n        }\n    },\n    'scheduler': {\n        'name': 'torch.optim.lr_scheduler.CosineAnnealingLR',\n        'params': {\n            'T_max': 6\n        }\n    }\n}\n\ncfg = Box(cfg)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:37:57.336006Z","iopub.execute_input":"2021-10-19T14:37:57.336584Z","iopub.status.idle":"2021-10-19T14:37:57.343245Z","shell.execute_reply.started":"2021-10-19T14:37:57.336543Z","shell.execute_reply":"2021-10-19T14:37:57.342176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset/Module","metadata":{}},{"cell_type":"code","source":"class PDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.img_path = df['img_path'].values\n        self.paw = df['Pawpularity'].values\n        self.y = df[['<10', '100', 'middle']].values\n        self._transform = T.Resize([self.cfg.img_size, self.cfg.img_size])\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        img = read_image(self.img_path[idx])\n        img = self._transform(img)\n        y = self.y[idx]\n        paw = self.paw[idx]\n        return img, y, paw\n        \nclass PDataModule(pl.LightningDataModule):\n    def __init__(self, cfg, df, train_idx, val_idx):\n        super().__init__()\n        self.cfg = cfg\n        self.df = df\n        self.train_idx = train_idx\n        self.val_idx = val_idx\n    \n    def setup(self, stage = None):\n        train, val = get_balanced_split(self.df, self.train_idx, self.val_idx, self.cfg.ratio)\n        self.train = PDataset(self.cfg , train)\n        self.val = PDataset(self.cfg, val)\n        \n    def train_dataloader(self):\n        return DataLoader(self.train, **self.cfg.train_loader)\n    \n    def val_dataloader(self):\n        return DataLoader(self.val, **self.cfg.val_loader)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:37:59.462967Z","iopub.execute_input":"2021-10-19T14:37:59.463494Z","iopub.status.idle":"2021-10-19T14:37:59.474998Z","shell.execute_reply.started":"2021-10-19T14:37:59.463458Z","shell.execute_reply":"2021-10-19T14:37:59.474032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\nIMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n\ndef get_augmentation():\n    return {\n        'train': T.Compose([\n            T.RandomHorizontalFlip(p=0.5),\n            T.RandomVerticalFlip(p=0.2),\n            T.ColorJitter(brightness=.2, contrast=.2, saturation=.2), #about 15% proabablity that image is changed in some way\n            T.ConvertImageDtype(torch.float),\n            T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n        ]),\n        'val': T.Compose([\n            T.ConvertImageDtype(torch.float),\n            T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n        ])\n    }","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:38:02.04067Z","iopub.execute_input":"2021-10-19T14:38:02.040948Z","iopub.status.idle":"2021-10-19T14:38:02.046998Z","shell.execute_reply.started":"2021-10-19T14:38:02.040898Z","shell.execute_reply":"2021-10-19T14:38:02.046323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"class PModel(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.__build_model()\n        self.save_hyperparameters(cfg)\n        self.criterion = eval(self.cfg.criterion)()\n        self._augmentation = get_augmentation()\n        \n    def __build_model(self):\n        self.backbone = timm.create_model(self.cfg.model.name, in_chans=3)\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=self.cfg.model.dropout),\n            nn.Linear(1000, self.cfg.model.out_dim)\n        )\n        \n    def forward(self, x):\n        out = self.backbone(x)\n        out = self.classifier(out)\n        return out\n        \n    def training_step(self, batch, batch_idx):\n        loss = self.__share_step(batch, 'train')\n        self.log('train_loss', loss, on_step = True, on_epoch = True)\n        return loss\n        \n    def validation_step(self, batch, batch_idx):\n        loss = self.__share_step(batch, 'val')\n        self.log('val_loss', loss)\n        \n    def __share_step(self, batch, mode):\n        img, y, paw = batch\n        img = self._augmentation[mode](img)\n        y_hat = self(img).squeeze()\n        loss = self.criterion(y_hat, y.float())\n        return loss\n\n    def configure_optimizers(self):\n        optim = eval(self.cfg.optim.name)(self.parameters(), **self.cfg.optim.params)\n#         scheduler = eval(self.cfg.scheduler.name)(optim, **self.cfg.scheduler.params)\n        return optim #, scheduler\n\n\n    # used for calculating RMSE\n    def predict_step(self, batch, batch_idx): \n        img, y, paw = batch\n        img = self._augmentation['val'](img)\n        y_hat = self(img).squeeze()\n        return {'y_hat': y_hat, 'paw': paw}","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:38:04.178045Z","iopub.execute_input":"2021-10-19T14:38:04.178576Z","iopub.status.idle":"2021-10-19T14:38:04.190453Z","shell.execute_reply.started":"2021-10-19T14:38:04.178537Z","shell.execute_reply":"2021-10-19T14:38:04.189662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data","metadata":{}},{"cell_type":"code","source":"BASE_PATH = '../input/petfinder-pawpularity-score'\nMETA = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n\ndef get_file_path(path):\n    return f'{BASE_PATH}/train/{path}.jpg'\n\ndef get_balanced_split(df, train_idx, val_idx, ratio):\n    train = df.loc[train_idx]\n    train_unpawpular_sum = train['<10'].sum()\n    train_unpawpular_index = train[np.logical_or(train['<10'] == 1, train['100'] == 1)].index\n    train_ratio = train[train['middle'] == 1].sample(train_unpawpular_sum * ratio).index\n    train = train.loc[train_unpawpular_index.append(train_ratio)]\n    \n    val = df.loc[val_idx]\n    val_unpawpular_sum = val['<10'].sum()\n    val_unpawpular_index = val[np.logical_or(val['<10'] == 1, val['100'] == 1)].index\n    val_ratio = val[val['middle'] == 1].sample(val_unpawpular_sum * ratio).index\n    val = val.loc[val_unpawpular_index.append(val_ratio)]\n    \n    return train, val","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:38:06.405779Z","iopub.execute_input":"2021-10-19T14:38:06.406061Z","iopub.status.idle":"2021-10-19T14:38:06.414081Z","shell.execute_reply.started":"2021-10-19T14:38:06.406031Z","shell.execute_reply":"2021-10-19T14:38:06.413398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\ndf['img_path'] = df['Id'].apply(lambda x:get_file_path(x))\ndf['<10'] = df['Pawpularity'].apply(lambda x: 1 if x < 10 else 0)\ndf['100'] = df['Pawpularity'].apply(lambda x: 1 if x == 100 else 0)\ndf['middle'] = df['Pawpularity'].apply(lambda x: 1 if (x > 9 and x < 100) else 0)\ndf = df.drop(columns=META)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:38:08.964139Z","iopub.execute_input":"2021-10-19T14:38:08.964971Z","iopub.status.idle":"2021-10-19T14:38:09.053452Z","shell.execute_reply.started":"2021-10-19T14:38:08.9649Z","shell.execute_reply":"2021-10-19T14:38:09.052767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_base = df['Pawpularity'].mean()\nmean_middle = df[df['middle'] == 1]['Pawpularity'].mean()\nmean_less_10 = df[df['<10'] == 1]['Pawpularity'].mean()\nmean_100 = 100\n\nprint(f'mean_base: {mean_base}, mean_middle: {mean_middle}, mean_less_10: {mean_less_10}, mean_100: {mean_100}')","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:38:11.161565Z","iopub.execute_input":"2021-10-19T14:38:11.161819Z","iopub.status.idle":"2021-10-19T14:38:11.173603Z","shell.execute_reply.started":"2021-10-19T14:38:11.16179Z","shell.execute_reply":"2021-10-19T14:38:11.172573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\n\nPATH_TO_MODELS = '/kaggle/input/outlier-models-paw/models'\n\nskf = StratifiedKFold(n_splits=cfg.n_splits)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df['Id'], df['middle'])):\n    \n    \n    if PATH_TO_MODELS is None:\n    \n        ##############\n        # Initialize #\n        ##############\n\n        dm = PDataModule(cfg, df, train_idx, val_idx)\n        model = PModel(cfg)\n\n        wandb_logger = WandbLogger(\n            project = 'pawpular_outlier_prediction',\n            config = cfg,\n            reinit = True,\n            group = 'aug + CosineAnnealingLR + ratio:1',\n            name = f'fold_{fold}',\n        )\n        checkpoint = ModelCheckpoint(\n            dirpath = '/kaggle/working/models',\n            filename = f'fold_{fold}',\n            monitor = 'val_loss',\n            save_top_k = 1\n        )\n        earlystopping = EarlyStopping(\n            monitor = 'val_loss',\n            patience = 4,\n        )\n\n        trainer = pl.Trainer(\n            fast_dev_run = False,\n            gpus = 1 if torch.cuda.is_available() else 0,\n            logger = wandb_logger,\n            callbacks = [checkpoint, earlystopping],\n            progress_bar_refresh_rate = 5,\n            log_every_n_steps = 3\n        )\n\n        #########\n        # Train #\n        #########\n\n        trainer.fit(model, dm)\n        wandb.finish()\n    \n    ############################\n    # Validate on whole val set#\n    ############################\n    \n    model = PModel.load_from_checkpoint(os.path.join(PATH_TO_MODELS, f'fold_{fold}-v1.ckpt'), cfg=cfg)\n    trainer = pl.Trainer(gpus = 1 if torch.cuda.is_available() else 0)\n    \n    whole_validation_set = PDataset(cfg, df.loc[val_idx])\n    whole_validation_loader = DataLoader(whole_validation_set, batch_size=64)\n    \n    y_hat = trainer.predict(model, whole_validation_loader)\n    preds.append(y_hat)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:38:13.073023Z","iopub.execute_input":"2021-10-19T14:38:13.073331Z","iopub.status.idle":"2021-10-19T14:41:18.768049Z","shell.execute_reply.started":"2021-10-19T14:38:13.073298Z","shell.execute_reply":"2021-10-19T14:41:18.767387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_to_val = {\n    0: mean_less_10,\n    1: mean_100,\n    2: mean_middle\n}\n\ndef compute_rmse(y_hat, threshold):\n    outlier_baseline = []\n    pawpularity = []\n    \n    for output in y_hat:\n        out_y_hat, paw = output['y_hat'], output['paw']\n        pawpularity.append(paw)\n        softmax = torch.nn.Softmax()\n        out_y_hat = softmax(out_y_hat)\n        for i, x in enumerate(out_y_hat):\n            highest_prob = x.max()\n            # If the model is *threshold* certain about it's prediction, we take this prediction; otherwise we don't\n            # want to risk betting on an outlier, and just predict the mean value to be on the 'safe' side\n            if highest_prob > threshold:\n                for k in range(3):\n                    if x[k] == highest_prob:\n                        outlier_baseline.append(pred_to_val[k])\n                        break\n            else:\n                outlier_baseline.append(pred_to_val[2])\n                \n    mean_baseline = torch.tensor(mean_base).repeat(len(outlier_baseline))\n    outlier_baseline = torch.tensor(outlier_baseline)\n    pawpularity = torch.tensor([y for x in pawpularity for y in x])\n    \n    mean_baseline_rmse = torch.sqrt((mean_baseline - pawpularity)**2).mean()\n    outlier_baseline_rmse = torch.sqrt((outlier_baseline - pawpularity)**2).mean()\n    \n    outlier_count = 0\n    for i in outlier_baseline:\n        if i != mean_middle:\n            outlier_count += 1\n    \n    return mean_baseline_rmse, outlier_baseline_rmse, outlier_count","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:41:18.769884Z","iopub.execute_input":"2021-10-19T14:41:18.770158Z","iopub.status.idle":"2021-10-19T14:41:18.780142Z","shell.execute_reply.started":"2021-10-19T14:41:18.770123Z","shell.execute_reply":"2021-10-19T14:41:18.779076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_values = [0, 0.2, 0.4, 0.6, 0.8, 1]\nbaseline_values = []\noutlier_values = []\noutlier_count = []\n\nfor confidence in threshold_values:\n    bv, ov, oc = compute_rmse(y_hat, confidence)\n    baseline_values.append(bv)\n    outlier_values.append(ov)\n    outlier_count.append(oc)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:51:02.321849Z","iopub.execute_input":"2021-10-19T14:51:02.322171Z","iopub.status.idle":"2021-10-19T14:51:03.439454Z","shell.execute_reply.started":"2021-10-19T14:51:02.322128Z","shell.execute_reply":"2021-10-19T14:51:03.438718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(18,7))\n\nax[0].plot(threshold_values, outlier_values, label='Outlier Model')\nax[0].plot(threshold_values, baseline_values, label='Mean Baseline')\nax[0].set_xlabel('Threshold value', fontsize=18)\nax[0].legend(prop={'size': 18})\nax[0].set_title('CV RMSE', fontsize=18)\n\nax[1].bar(np.arange(len(outlier_count)),outlier_count)\nax[1].set(xticks=np.arange(len(outlier_count)), xticklabels=threshold_values)\nax[1].set_xlabel('Threshold value', fontsize=18)\nax[1].set_title('Outliers predicted', fontsize=18)\n\nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T14:51:29.146365Z","iopub.execute_input":"2021-10-19T14:51:29.146631Z","iopub.status.idle":"2021-10-19T14:51:29.614789Z","shell.execute_reply.started":"2021-10-19T14:51:29.146599Z","shell.execute_reply":"2021-10-19T14:51:29.614105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}