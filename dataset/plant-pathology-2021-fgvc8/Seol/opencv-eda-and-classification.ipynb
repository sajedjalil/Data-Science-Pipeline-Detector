{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Load library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array, smart_resize\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.preprocessing import image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.Read csv and EDA","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_name = df['labels'].value_counts().index\nclass_count = df['labels'].value_counts().values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['labels'] = df['labels'].astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label_num'] = df['labels'].cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.pie(class_count,\n        labels=class_name,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Define function","metadata":{}},{"cell_type":"markdown","source":"> Load data function... but this code is not use this code.","metadata":{}},{"cell_type":"code","source":"def load_data(df):    \n    datasets = ['../input/plant-pathology-2021-fgvc8/train_images', '../input/plant-pathology-2021-fgvc8/test_images']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        # Iterate through each image in our folder\n        for file in tqdm(os.listdir(dataset)):\n                # Get the path name of the image\n                img_path = os.path.join(dataset, file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # labeling\n                label = df.loc[df['image']==file, 'label_num']\n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Image display","metadata":{}},{"cell_type":"markdown","source":"> In this code, I want to find how to improve classification using opencv function. But I can't find....","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = (224, 224)\n# IMAGE_SIZE = (600, 600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_examples(df):\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        index = np.random.randint(df.shape[0])\n        img_path = df.loc[index,'image']\n        dataset = '../input/plant-pathology-2021-fgvc8/train_images'\n        img_path = os.path.join(dataset, img_path)\n        img = image.load_img(img_path, target_size=(224, 224))\n        x = image.img_to_array(img)       \n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(x/255., cmap=plt.cm.binary)\n        plt.xlabel(df.loc[index,'labels'])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_examples_canny(df):\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        index = np.random.randint(df.shape[0])\n        img_path = df.loc[index,'image']\n        dataset = '../input/plant-pathology-2021-fgvc8/train_images'\n        img_path = os.path.join(dataset, img_path)\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n        edged = cv2.Canny(gray,30,200)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(edged)\n        plt.xlabel(df.loc[index,'labels'])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_examples_mog2(df):\n    algo = 'MOG2'\n    \n    if algo == 'MOG2':\n        backSub = cv2.createBackgroundSubtractorMOG2()\n    else:\n        backSub = cv2.createBackgroundSubtractorKNN()\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        index = np.random.randint(df.shape[0])\n        img_path = df.loc[index,'image']\n        dataset = '../input/plant-pathology-2021-fgvc8/train_images'\n        img_path = os.path.join(dataset, img_path)\n        image = cv2.imread(img_path)\n        fgMask = backSub.apply(image)\n        mask = cv2.cvtColor(fgMask, cv2.COLOR_BGR2RGB)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(mask)\n        plt.xlabel(df.loc[index,'labels'])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_examples_grabcut(df):\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        index = np.random.randint(df.shape[0])\n        img_path = df.loc[index,'image']\n        dataset = '../input/plant-pathology-2021-fgvc8/train_images'\n        img_path = os.path.join(dataset, img_path)\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, dsize=(600, 600), interpolation=cv2.INTER_AREA)\n        \n        rectangle = (0, 0, 500, 500)\n        mask = np.zeros(image.shape[:2], np.uint8)\n        bgdModel = np.zeros((1, 65), np.float64)\n        fgdModel = np.zeros((1, 65), np.float64)\n        cv2.grabCut(image, mask, rectangle, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n        mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n        image_nobg = image * mask_2[:, :, np.newaxis]\n\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(image_nobg)\n        plt.xlabel(df.loc[index,'labels'])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display_examples(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display_examples_canny(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display_examples_mog2(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display_examples_grabcut(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.Image data generate","metadata":{}},{"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./225,rotation_range=20,\n                                                                width_shift_range=0.2,height_shift_range=0.2,\n                                                                shear_range=0.2,zoom_range=0.2,horizontal_flip=True,\n                                                                validation_split=0.4)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/plant-pathology-2021-fgvc8/train_images'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(dataframe=df,\n                                                    directory=train_dir,\n                                                    subset='training',\n                                                    x_col=\"image\",\n                                                    y_col=\"labels\",\n                                                    shuffle=True,\n                                                    target_size=IMAGE_SIZE,\n                                                    batch_size=64,\n                                                    class_mode='categorical')\n\nval_generator = train_datagen.flow_from_dataframe(dataframe=df,\n                                                    directory=train_dir,\n                                                    subset=\"validation\",\n                                                    x_col=\"image\",\n                                                    y_col=\"labels\",\n                                                    shuffle=True,\n                                                    target_size=IMAGE_SIZE,\n                                                    batch_size=64,\n                                                    class_mode='categorical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist(hist):\n    plt.plot(hist.history[\"accuracy\"])\n    plt.plot(hist.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (224, 224, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(12, activation=tf.nn.softmax)\n])\n\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_callbacks():\n    \n    cpk_path = './best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        mode='max',\n        patience=3, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\n\nhist = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=50,\n                           validation_data=val_generator, validation_steps=20,\n                           callbacks=create_callbacks())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(hist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/plant-pathology-2021-fgvc8/sample_submission.csv\")\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = '../input/plant-pathology-2021-fgvc8/test_images'\npred = []\nmodel = models.load_model('./best_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image in os.listdir(test_dir):\n    path = os.path.join(test_dir, image)\n    img = load_img(path)\n    img = img_to_array(img)\n    img = smart_resize(img, (600,600))\n    img = tf.reshape(img, (-1, 600, 600, 3))\n    temp = model.predict(img/255.)\n    temp = np.argmax(temp)\n    pred = np.append(pred,temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_result = pd.DataFrame({'image' : submission.image, 'labels' : pred})\nsubmission_result['labels'] = submission_result['labels'].astype(int)\nclass_map = dict(sorted(df[['label_num', 'labels']].values.tolist()))\nsubmission_result['labels'] = submission_result['labels'].map(class_map)\nsubmission_result.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Competetion Complete!!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inputs = layers.Input(shape=(600, 600, 3))\n# model = EfficientNetB7(weights='imagenet', input_tensor=inputs, include_top=False)\n# model.trainable = False\n# x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n# x = layers.Flatten(name=\"Flatten\")(model.output)\n# x = layers.Dense(64,activation='relu')(x)\n# x = layers.Dense(32,activation='relu')(x)\n# x = layers.Dense(16,activation='relu')(x)\n# outputs = layers.Dense(12, activation=\"softmax\", name=\"pred\")(x)\n# model = models.Model(inputs, outputs, name=\"EfficientB7\")\n# optimizer = optimizers.Adam(learning_rate=1e-2)\n# model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epochs = 100\n\n# hist = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=10,\n#                            validation_data=val_generator, validation_steps=5, \n#                            callbacks=create_callbacks())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_hist(hist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Iâ€™m working on it.","metadata":{}}]}