{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Reference :** https://www.kaggle.com/khoongweihao/insect-augmentation-et-al","metadata":{}},{"cell_type":"code","source":"#!pip install imutils\nimport sys\nsys.path.append('../input/imutils/imutils-0.5.3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* torchvision.transforms : https://dororongju.tistory.com/144","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom torchvision import transforms\nimport tensorflow as tf\nimport albumentations as A\nimport imgaug.augmenters as iaa\nfrom imgaug import parameters as iap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR = \"../input/plant-pathology-2021-fgvc8/train_images\"\nimage_path = f'{DIR}/800113bb65efe69e.jpg'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chosen_image = cv2.imread(image_path)\nplt.imshow(chosen_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Albumentations Augmentations**","metadata":{}},{"cell_type":"code","source":"albumentation_list = [A.RandomSunFlare(p=1), \n                      A.RandomFog(p=1), \n                      A.RandomBrightness(p=1),\n                      A.RandomCrop(p=1,height = 512, width = 512), \n                      A.Rotate(p=1, limit=90),\n                      A.RGBShift(p=1), \n                      A.RandomSnow(p=1),\n                      A.HorizontalFlip(p=1), \n                      A.VerticalFlip(p=1), \n                      A.RandomContrast(limit = 0.5,p = 1),\n                      A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                      A.Cutout(p=1),\n                      A.Transpose(p=1), \n                      A.JpegCompression(p=1),\n                      A.CoarseDropout(p=1),\n                      A.IAAAdditiveGaussianNoise(loc=0, scale=(2.5500000000000003, 12.75), per_channel=False, p=1),\n                      A.IAAAffine(scale=1.0, translate_percent=None, translate_px=None, rotate=0.0, shear=0.0, order=1, cval=0, mode='reflect', p=1),\n                      A.IAAAffine(rotate=90., p=1),\n                      A.IAAAffine(rotate=180., p=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = chosen_image)['image']\n    img_matrix_list.append(img)\n\nimg_matrix_list.insert(0,chosen_image)    \n\ntitles_list = [\"Original\",\"RandomSunFlare\",\"RandomFog\",\"RandomBrightness\",\n               \"RandomCrop\",\"Rotate\", \"RGBShift\", \"RandomSnow\",\"HorizontalFlip\", \"VerticalFlip\", \"RandomContrast\",\"HSV\",\n               \"Cutout\",\"Transpose\",\"JpegCompression\",\"CoarseDropout\",\"IAAAdditiveGaussianNoise\",\"IAAAffine\",\"IAAAffineRotate90\",\"IAAAffineRotate180\"]\n\ndef plot_multiple_img(img_matrix_list, title_list, ncols, nrows=5,  main_title=\"\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=nrows, ncols=ncols, squeeze=False)\n    fig.suptitle(main_title, fontsize = 30)\n    fig.subplots_adjust(wspace=0.3)\n    fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i // ncols][i % ncols].imshow(img)\n        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()\n    \nplot_multiple_img(img_matrix_list, titles_list, ncols = 4,main_title=\"Different Types of Augmentations with Albumentations\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **imgaug Based Augmentations**","metadata":{}},{"cell_type":"code","source":"ia_trans_list = [iaa.blend.BlendAlpha(factor=(0.2, 0.8),\n                                      foreground=iaa.Affine(rotate=(-30, 30)),\n                                      per_channel=True),\n                 iaa.Fliplr(1.),\n                 iaa.Flipud(1.),\n                 iaa.SimplexNoiseAlpha(iaa.Multiply(iap.Choice([0.5, 1.5]), per_channel=True)),\n                 iaa.Crop(percent=(0., 0.3)),\n                ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_matrix_list = []\nbboxes_list = []\nfor aug_type in ia_trans_list:\n    # convert to tensor\n    chosen_image = cv2.imread(image_path)\n    iaa_seq = iaa.Sequential([aug_type])\n    trans_img = iaa_seq.augment_images(chosen_image)\n    img_matrix_list.append(trans_img)\n\nimg_matrix_list.insert(0, chosen_image)    \n\ntitles_list = [\"Original\",\"Ghost Aug\",\"Flip Left Right\",\"Flip Up Down\",\"SimplexNoiseAlpha\", \"Crop\"]\n\nplot_multiple_img(img_matrix_list, titles_list, ncols = 3, nrows=2, main_title=\"Different Types of Augmentations with Albumentations\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **PyTorch-Based Augmentations (Torchvision)**","metadata":{}},{"cell_type":"code","source":"torch_trans_list = [transforms.CenterCrop((178, 178)),\n                    transforms.Resize(128),\n                    transforms.RandomRotation(45),\n                    transforms.RandomAffine(35),\n                    transforms.RandomCrop(128),\n                    transforms.RandomHorizontalFlip(p=1),\n                    transforms.RandomPerspective(p=1),\n                    transforms.RandomVerticalFlip(p=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_matrix_list = []\nbboxes_list = []\nfor aug_type in torch_trans_list:\n    # convert to tensor\n    chosen_image = cv2.imread(image_path)\n    chosen_tensor = transforms.Compose([transforms.ToTensor()])(chosen_image)\n    chosen_tensor = transforms.Compose([aug_type])(chosen_tensor)\n    trans_img = transforms.ToPILImage()(chosen_tensor)\n    img_matrix_list.append(trans_img)\n\nimg_matrix_list.insert(0, chosen_image)    \n\ntitles_list = [\"Original\",\"CenterCrop\",\"Resize\",\"RandomRotation\",\"RandomAffine\",\"RandomCrop\",\"RandomHorizontalFlip\",\"RandomPerspective\",\n               \"RandomVerticalFlip\"]\n\nplot_multiple_img(img_matrix_list, titles_list, ncols = 3, nrows=3, main_title=\"Different Types of Augmentations with Albumentations\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TensorFlow-Based Augmentations**","metadata":{}},{"cell_type":"code","source":"chosen_image = cv2.imread(image_path)\n\ntf_trans_list = [\n    tf.image.rot90(chosen_image, k=1), # 90 degrees counter-clockwise\n    tf.image.rot90(chosen_image, k=2), # 180 degrees counter-clockwise\n    tf.image.rot90(chosen_image, k=3), # 270 degrees counter-clockwise\n    tf.image.random_brightness(chosen_image, 0.5), \n    tf.image.random_contrast(chosen_image, 0.2, 0.5), \n    tf.image.random_flip_left_right(chosen_image, seed=42),\n    tf.image.random_flip_up_down(chosen_image, seed=42),\n    tf.image.random_hue(chosen_image, 0.5),\n    tf.image.random_jpeg_quality(chosen_image, 35, 50), \n    tf.image.random_saturation(chosen_image, 5, 10), \n    tf.image.transpose(chosen_image),\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_matrix_list = []\nbboxes_list = []\nfor aug_image in tf_trans_list:\n    img_matrix_list.append(aug_image)\n\nimg_matrix_list.insert(0, chosen_image)    \n\ntitles_list = [\"Original\",\"Rotate90\",\"Rotate180\",\"Rotate270\",\"RandomBrightness\",\"RandomContrast\",\"RandomLeftRightFlip\",\"RandomUpDownFlip\",\n               \"RandomHue\",\"RandomJPEGQuality\",\"RandomSaturation\",\"Transpose\"]\n\nplot_multiple_img(img_matrix_list, titles_list, ncols = 3, nrows=4, main_title=\"Different Types of Augmentations with Albumentations\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Mixup**","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.insert(0, \"../input/timm-efficientdet-pytorch\")\nsys.path.insert(0, \"../input/omegaconf\")\nsys.path.insert(0, \"../input/weightedboxesfusion\")\nimport random\nfrom glob import glob\nfrom torch.utils.data import Dataset,DataLoader\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport gc\n#from tqdm import df\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"marking = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"marking.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_ROOT_PATH = '../input/plant-pathology-2021-fgvc8/train_images'\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, marking, image_ids, transforms=None, test=False):\n        super().__init__()\n\n        self.image_ids = image_ids\n        self.marking = marking\n        self.transforms = transforms\n        self.test = test\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n\n        image, boxes = self.load_imagees(index)\n        \n        target = {}\n        target['image_id'] = torch.tensor([index])\n\n        if self.transforms:\n            for i in range(10):\n                sample = self.transforms(**{\n                    'mageage': image,\n                })\n\n        return image\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n\n    def load_images(self, image_id):\n        #image_id = self.image_ids[index]\n        images = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}', cv2.IMREAD_COLOR)\n        #images = cv2.resize(images, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n        images /= 255\n        records = self.marking[self.marking['image'] == image_id]\n        return images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_images(list_images):\n    fig, ax = plt.subplots(4, 2, figsize=(16, 32))\n    for i, image in enumerate(list_images):\n        ax.set_axis_off()\n        ax.imshow(image);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ndf_folds = marking[['image']].copy()\nf_folds = df_folds.groupby('image').count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_valid_transforms():\n    return A.Compose(\n        [\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        bbox_params=A.BboxParams(\n            format='pascal_voc',\n            min_area=0, \n            min_visibility=0,\n            label_fields=['labels']\n        )\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetRetriever(\n    image_ids=df_folds['image'].index.values,\n    marking=marking,\n    transforms=get_valid_transforms(),\n    test=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    r_image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    mixup_image = (image+r_image)/2\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(mixup_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    r_image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    \n    mixup_image = image.copy()\n\n    imsize = image.shape[0]\n    x1, y1 = [int(random.uniform(imsize * 0.0, imsize * 0.45)) for _ in range(2)]\n    x2, y2 = [int(random.uniform(imsize * 0.55, imsize * 1.0)) for _ in range(2)]\n\n    \n    cv2.rectangle(r_image,(x1, y1),(x2,  y2),(0, 1, 1), 5)\n    \n    mixup_image[y1:y2, x1:x2] = (mixup_image[y1:y2, x1:x2] + r_image[y1:y2, x1:x2])/2\n    \n    cv2.rectangle(mixup_image,(x1, y1),(x2,  y2),(0, 1, 1), 5)\n\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(mixup_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    r_image = dataset.load_images(marking.loc[random.randint(0, dataset.image_ids.shape[0] - 1)]['image'])\n    \n\n    imsize = image.shape[0]\n    w,h = imsize, imsize\n    s = imsize // 2\n\n    xc, yc = [int(random.uniform(imsize * 0.4, imsize * 0.6)) for _ in range(2)]\n    direct = random.randint(0, 3)\n\n    result_image = image.copy()\n    result_boxes = []\n\n    if direct == 0:\n        x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n        x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n    elif direct == 1:  # top right\n        x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n        x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n    elif direct == 2:  # bottom left\n        x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n        x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n    elif direct == 3:  # bottom right\n        x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n        x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n\n    padw = x1a - x1b\n    padh = y1a - y1b\n\n\n    result_image[y1a:y2a, x1a:x2a] = (result_image[y1a:y2a, x1a:x2a] + r_image[y1b:y2b, x1b:x2b]) / 2 \n    \n    cv2.rectangle(image,(x1a, y1a),(x2a,  y2a),(0, 1, 1), 5)\n    cv2.rectangle(r_image,(x1b, y1b),(x2b,  y2b),(0, 1, 1), 5)\n    cv2.rectangle(result_image,(x1a, y1a),(x2a,  y2a),(0, 1, 1), 5)\n    \n\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(result_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}