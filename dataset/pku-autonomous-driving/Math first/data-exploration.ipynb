{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Initial Data Exploration\n\nNote that this notebook is a changed version of https://www.kaggle.com/phunghieu/a-quick-simple-eda and https://www.kaggle.com/hocop1/centernet-baseline. Thank you guys!, Also I added two parts by myself."},{"metadata":{},"cell_type":"markdown","source":"# Import modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport json\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom matplotlib.collections import PatchCollection\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Start from Hieu Phungâ€˜s notebook."},{"metadata":{},"cell_type":"markdown","source":"# Configure parameters"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"DATASET_DIR = '/kaggle/input/pku-autonomous-driving/'\nJSON_DIR = os.path.join(DATASET_DIR, 'car_models_json')\nNUM_IMG_SAMPLES = 10 # The number of image samples used for visualization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get annotations"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(DATASET_DIR, 'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_ids = np.array(df['ImageId'])\nprediction_strings = np.array(df['PredictionString'])\nprediction_strings = [\n    np.array(prediction_string.split(' ')).astype(np.float32).reshape(-1, 7) \\\n    for prediction_string in prediction_strings\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Image ID:', image_ids[0])\nprint('Annotations:\\n', prediction_strings[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get all model-types"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# https://raw.githubusercontent.com/ApolloScapeAuto/dataset-api/master/car_instance/car_models.py\nmodels = {\n    #           name                id\n         'baojun-310-2017':          0,\n            'biaozhi-3008':          1,\n      'biaozhi-liangxiang':          2,\n       'bieke-yinglang-XT':          3,\n            'biyadi-2x-F0':          4,\n           'changanbenben':          5,\n            'dongfeng-DS5':          6,\n                 'feiyate':          7,\n     'fengtian-liangxiang':          8,\n            'fengtian-MPV':          9,\n       'jilixiongmao-2015':         10,\n       'lingmu-aotuo-2009':         11,\n            'lingmu-swift':         12,\n         'lingmu-SX4-2012':         13,\n          'sikeda-jingrui':         14,\n    'fengtian-weichi-2006':         15,\n               '037-CAR02':         16,\n                 'aodi-a6':         17,\n               'baoma-330':         18,\n               'baoma-530':         19,\n        'baoshijie-paoche':         20,\n         'bentian-fengfan':         21,\n             'biaozhi-408':         22,\n             'biaozhi-508':         23,\n            'bieke-kaiyue':         24,\n                    'fute':         25,\n                 'haima-3':         26,\n           'kaidilake-CTS':         27,\n               'leikesasi':         28,\n           'mazida-6-2015':         29,\n              'MG-GT-2015':         30,\n                   'oubao':         31,\n                    'qiya':         32,\n             'rongwei-750':         33,\n              'supai-2016':         34,\n         'xiandai-suonata':         35,\n        'yiqi-benteng-b50':         36,\n                   'bieke':         37,\n               'biyadi-F3':         38,\n              'biyadi-qin':         39,\n                 'dazhong':         40,\n          'dazhongmaiteng':         41,\n                'dihao-EV':         42,\n  'dongfeng-xuetielong-C6':         43,\n 'dongnan-V3-lingyue-2011':         44,\n'dongfeng-yulong-naruijie':         45,\n                 '019-SUV':         46,\n               '036-CAR01':         47,\n             'aodi-Q7-SUV':         48,\n              'baojun-510':         49,\n                'baoma-X5':         50,\n         'baoshijie-kayan':         51,\n         'beiqi-huansu-H3':         52,\n          'benchi-GLK-300':         53,\n            'benchi-ML500':         54,\n     'fengtian-puladuo-06':         55,\n        'fengtian-SUV-gai':         56,\n'guangqi-chuanqi-GS4-2015':         57,\n    'jianghuai-ruifeng-S3':         58,\n              'jili-boyue':         59,\n                  'jipu-3':         60,\n              'linken-SUV':         61,\n               'lufeng-X8':         62,\n             'qirui-ruihu':         63,\n             'rongwei-RX5':         64,\n         'sanling-oulande':         65,\n              'sikeda-SUV':         66,\n        'Skoda_Fabia-2011':         67,\n        'xiandai-i25-2016':         68,\n        'yingfeinidi-qx80':         69,\n         'yingfeinidi-SUV':         70,\n              'benchi-SUR':         71,\n             'biyadi-tang':         72,\n       'changan-CS35-2012':         73,\n             'changan-cs5':         74,\n      'changcheng-H6-2016':         75,\n             'dazhong-SUV':         76,\n 'dongfeng-fengguang-S560':         77,\n   'dongfeng-fengxing-SX6':         78\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"models_map = dict((y, x) for x, y in models.items())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cars = []\nfor prediction_string in prediction_strings:\n    for car in prediction_string:\n        cars.append(car)\ncars = np.array(cars)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"unique, counts = np.unique(cars[..., 0].astype(np.uint8), return_counts=True)\nall_model_types = zip(unique, counts)\n\nfor i, model_type in enumerate(all_model_types):\n    print('{}.\\t Model type: {:<22} | {} cars'.format(i, models_map[model_type[0]], model_type[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot some figures"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_figures(\n    sizes,\n    pie_title,\n    start_angle,\n    bar_title,\n    bar_ylabel,\n    labels,\n    explode,\n    colors=None,\n):\n    fig, ax = plt.subplots(figsize=(14, 14))\n\n    y_pos = np.arange(len(labels))\n    barlist = ax.bar(y_pos, sizes, align='center')\n    ax.set_xticks(y_pos, labels)\n    ax.set_ylabel(bar_ylabel)\n    ax.set_title(bar_title)\n    if colors is not None:\n        for idx, item in enumerate(barlist):\n            item.set_color(colors[idx])\n\n    def autolabel(rects):\n        \"\"\"\n        Attach a text label above each bar displaying its height\n        \"\"\"\n        for rect in rects:\n            height = rect.get_height()\n            ax.text(\n                rect.get_x() + rect.get_width()/2., height,\n                '%d' % int(height),\n                ha='center', va='bottom', fontweight='bold'\n            )\n\n    autolabel(barlist)\n    \n    fig, ax = plt.subplots(figsize=(14, 14))\n    \n    pielist = ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=start_angle, counterclock=False)\n    ax.axis('equal')\n    ax.set_title(pie_title)\n    if colors is not None:\n        for idx, item in enumerate(pielist[0]):\n            item.set_color(colors[idx])\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_figures(\n    counts,\n    pie_title='The percentage of the number of cars of each model type',\n    start_angle=170,\n    bar_title='Distribution of cars of each model type',\n    bar_ylabel='Frequency',\n    labels=[label for label in unique],\n    explode=np.zeros(len(unique))\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot all 3D car models\n### Plotting logic for car models is based on this awesome [kernel](https://www.kaggle.com/ebouteillon/load-a-3d-car-model) created by Eric Bouteillon (@ebouteillon)\n### Also, let's check out [3D Interactive Car with Plotly](https://www.kaggle.com/subinium/3d-interactive-car-with-plotly) created by Subin An (@subinium), the visualization of car models in this kernel is absolutely wonderful!!!"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Get all json files\nfiles = [file for file in os.listdir(JSON_DIR) if os.path.isfile(os.path.join(JSON_DIR, file))]\n\n# For each json file, plot figure\nfor file in files:\n    model_path = os.path.join(JSON_DIR, file)\n    with open(model_path) as src:\n        data = json.load(src)\n        car_type = data['car_type']\n        faces = data['faces']\n        vertices = np.array(data['vertices'])\n        triangles = np.array(faces) - 1\n\n        fig = plt.figure(figsize=(16, 5))\n        ax11 = fig.add_subplot(1, 2, 1, projection='3d')\n        ax11.set_title('Model: {} | Type: {}'.format(file.split('.')[0], car_type))\n        ax11.set_xlim([-2, 3])\n        ax11.set_ylim([-3, 2])\n        ax11.set_zlim([0, 3])\n        ax11.view_init(30, -50)\n        ax11.plot_trisurf(vertices[:,0], vertices[:,2], triangles, -vertices[:,1], shade=True, color='lime')\n        \n        ax12 = fig.add_subplot(1, 2, 2, projection='3d')\n        ax12.set_title('Model: {} | Type: {}'.format(file.split('.')[0], car_type))\n        ax12.set_xlim([-2, 3])\n        ax12.set_ylim([-3, 2])\n        ax12.set_zlim([0, 3])\n        ax12.view_init(30, 40)\n        ax12.plot_trisurf(vertices[:,0], vertices[:,2], triangles, -vertices[:,1], shade=True, color='lime')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize some images"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def show_samples(samples):\n    for sample in samples:\n        fig, ax = plt.subplots(figsize=(18, 16))\n        \n        # Get image\n        img_path = os.path.join(DATASET_DIR, 'train_images', '{}.{}'.format(sample, 'jpg'))\n        img = cv2.imread(img_path, 1)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        # Get corresponding mask\n        mask_path = os.path.join(DATASET_DIR, 'train_masks', '{}.{}'.format(sample, 'jpg'))\n        mask = cv2.imread(mask_path, 0)\n\n        patches = []\n        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        for contour in contours:\n            poly_patch = Polygon(contour.reshape(-1, 2), closed=True, linewidth=2, edgecolor='r', facecolor='r', fill=True)\n            patches.append(poly_patch)\n        p = PatchCollection(patches, match_original=True, cmap=matplotlib.cm.jet, alpha=0.3)\n\n        ax.imshow(img/255)\n        ax.set_title(sample)\n        ax.add_collection(p)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Randomly select samples\nsamples = image_ids[np.random.choice(image_ids.shape[0], NUM_IMG_SAMPLES, replace=False)]\n\n# Show images and corresponding masks of too-far-away (not of interest) cars\nshow_samples(samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then go to Ruslan Baynazarov's notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimread = cv2.imread\nPATH = DATASET_DIR\ntrain = df\n\ndef imread(path, fast_mode=False):\n    img = cv2.imread(path)\n    if not fast_mode and img is not None and len(img.shape) == 3:\n        img = np.array(img[:, :, ::-1])\n    return img\n\n# From camera.zip\ncamera_matrix = np.array([[2304.5479, 0,  1686.2379],\n                          [0, 2305.8757, 1354.9849],\n                          [0, 0, 1]], dtype=np.float32)\ncamera_matrix_inv = np.linalg.inv(camera_matrix)\n\ndef str2coords(s, names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']):\n    '''\n    Input:\n        s: PredictionString (e.g. from train dataframe)\n        names: array of what to extract from the string\n    Output:\n        list of dicts with keys from `names`\n    '''\n    coords = []\n    for l in np.array(s.split()).reshape([-1, 7]):\n        coords.append(dict(zip(names, l.astype('float'))))\n        if 'id' in coords[-1]:\n            coords[-1]['id'] = int(coords[-1]['id'])\n    return coords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sin, cos\n\n# convert euler angle to rotation matrix\ndef euler_to_Rot(yaw, pitch, roll):\n    Y = np.array([[cos(yaw), 0, sin(yaw)],\n                  [0, 1, 0],\n                  [-sin(yaw), 0, cos(yaw)]])\n    P = np.array([[1, 0, 0],\n                  [0, cos(pitch), -sin(pitch)],\n                  [0, sin(pitch), cos(pitch)]])\n    R = np.array([[cos(roll), -sin(roll), 0],\n                  [sin(roll), cos(roll), 0],\n                  [0, 0, 1]])\n    return np.dot(Y, np.dot(P, R))\n\ndef draw_line(image, points):\n    color = (255, 0, 0)\n    cv2.line(image, tuple(points[0][:2]), tuple(points[3][:2]), color, 16)\n    cv2.line(image, tuple(points[0][:2]), tuple(points[1][:2]), color, 16)\n    cv2.line(image, tuple(points[1][:2]), tuple(points[2][:2]), color, 16)\n    cv2.line(image, tuple(points[2][:2]), tuple(points[3][:2]), color, 16)\n    return image\n\n\ndef draw_points(image, points):\n    for (p_x, p_y, p_z) in points:\n        cv2.circle(image, (p_x, p_y), int(1000 / p_z), (0, 255, 0), -1)\n#         if p_x > image.shape[1] or p_y > image.shape[0]:\n#             print('Point', p_x, p_y, 'is out of image with shape', image.shape)\n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"lens = [len(str2coords(s)) for s in train['PredictionString']]\n\nplt.figure(figsize=(15,6))\nsns.countplot(lens);\nplt.xlabel('Number of cars in image');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"points_df = pd.DataFrame()\nfor col in ['x', 'y', 'z', 'yaw', 'pitch', 'roll']:\n    arr = []\n    for ps in train['PredictionString']:\n        coords = str2coords(ps)\n        arr += [c[col] for c in coords]\n    points_df[col] = arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['x'], bins=500);\nplt.xlabel('x')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['y'], bins=500);\nplt.xlabel('y')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['z'], bins=500);\nplt.xlabel('z')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['yaw'], bins=500);\nplt.xlabel('yaw')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.distplot(points_df['pitch'], bins=500);\nplt.xlabel('pitch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rotate(x, angle):\n    x = x + angle\n    x = x - (x + np.pi) // (2 * np.pi) * 2 * np.pi\n    return x\n\nplt.figure(figsize=(15,6))\nsns.distplot(points_df['roll'].map(lambda x: rotate(x, np.pi)), bins=500);\nplt.xlabel('roll rotated by pi')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2D Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_img_coords(input_item, input_type=str, output_z=False):\n    '''\n    Input is a PredictionString (e.g. from train dataframe)\n    Output is two arrays:\n        xs: x coordinates in the image (row)\n        ys: y coordinates in the image (column)\n    '''\n    if input_type == str:\n        coords = str2coords(input_item)\n    else:\n        coords = input_item\n    \n    xs = [c['x'] for c in coords]\n    ys = [c['y'] for c in coords]\n    zs = [c['z'] for c in coords]\n    P = np.array(list(zip(xs, ys, zs))).T\n    img_p = np.dot(camera_matrix, P).T\n    img_p[:, 0] /= img_p[:, 2]\n    img_p[:, 1] /= img_p[:, 2]\n    img_xs = img_p[:, 0]\n    img_ys = img_p[:, 1]\n    img_zs = img_p[:, 2] # z = Distance from the camera\n    if output_z:\n        return img_xs, img_ys, img_zs\n    return img_xs, img_ys\n\nplt.figure(figsize=(14,14))\nplt.imshow(imread(PATH + 'train_images/' + train['ImageId'][2217] + '.jpg'))\nplt.scatter(*get_img_coords(train['PredictionString'][2217]), color='red', s=100);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the distribution of all points. Image is here just for reference."},{"metadata":{"trusted":true},"cell_type":"code","source":"xs, ys = [], []\n\nfor ps in train['PredictionString']:\n    x, y = get_img_coords(ps)\n    xs += list(x)\n    ys += list(y)\n\nplt.figure(figsize=(18,18))\nplt.imshow(imread(PATH + 'train_images/' + train['ImageId'][2217] + '.jpg'), alpha=0.3)\nplt.scatter(xs, ys, color='red', s=10, alpha=0.2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3D Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize(img, coords):\n    # You will also need functions from the previous cells\n    x_l = 1.02\n    y_l = 0.80\n    z_l = 2.31\n    \n    img = img.copy()\n    for point in coords:\n        # Get values\n        x, y, z = point['x'], point['y'], point['z']\n        yaw, pitch, roll = -point['pitch'], -point['yaw'], -point['roll']\n        # Math\n        Rt = np.eye(4)\n        t = np.array([x, y, z])\n        Rt[:3, 3] = t\n        Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n        Rt = Rt[:3, :]\n        P = np.array([[x_l, -y_l, -z_l, 1],\n                      [x_l, -y_l, z_l, 1],\n                      [-x_l, -y_l, z_l, 1],\n                      [-x_l, -y_l, -z_l, 1],\n                      [0, 0, 0, 1]]).T\n        img_cor_points = np.dot(camera_matrix, np.dot(Rt, P))\n        img_cor_points = img_cor_points.T\n        img_cor_points[:, 0] /= img_cor_points[:, 2]\n        img_cor_points[:, 1] /= img_cor_points[:, 2]\n        img_cor_points = img_cor_points.astype(int)\n        # Drawing\n        img = draw_line(img, img_cor_points)\n        img = draw_points(img, img_cor_points[-1:])\n    \n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_rows = 6\n\nfor idx in range(n_rows):\n    fig, axes = plt.subplots(1, 2, figsize=(20,20))\n    img = imread(PATH + 'train_images/' + train['ImageId'].iloc[idx] + '.jpg')\n    axes[0].imshow(img)\n    img_vis = visualize(img, str2coords(train['PredictionString'].iloc[idx]))\n    axes[1].imshow(img_vis)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following is my analysis."},{"metadata":{},"cell_type":"markdown","source":"# Correlation Matrices"},{"metadata":{},"cell_type":"markdown","source":"Let's get 5000 samples from the labels to see if some relations are among the dimensions of poses,"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nsample_index_list = random.sample(list(range(len(points_df))), 5000)\nv = np.vstack([points_df['x'][sample_index_list], points_df['y'][sample_index_list], \n               points_df['z'][sample_index_list], points_df['yaw'][sample_index_list], \n               points_df['pitch'][sample_index_list], points_df['roll'][sample_index_list]])\nCM = np.corrcoef(v)\n\nfig, ax = plt.subplots(figsize=(7, 7))\nim = ax.imshow(CM)\nax.set_xticks(np.arange(6))\nax.set_yticks(np.arange(6))\nax.set_xticklabels(['x', 'y', 'z', 'yaw', 'pitch', 'roll'])\nax.set_yticklabels(['x', 'y', 'z', 'yaw', 'pitch', 'roll'])\nfor i in range(6):\n    for j in range(6):\n        text = ax.text(j, i, round(CM[i, j], 2),\n                       ha=\"center\", va=\"center\", color=\"w\")\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and see the relations among coordinates."},{"metadata":{"trusted":true},"cell_type":"code","source":"coords = []\nfor sample_index in sample_index_list:\n    coord = {}\n    coord['x'] = points_df['x'][sample_index] \n    coord['y'] = points_df['y'][sample_index] \n    coord['z'] = points_df['z'][sample_index]\n    coords.append(coord)\nimg_x_list, img_y_list, img_z_list = get_img_coords(coords, input_type=list, output_z=True)\n\nv = np.vstack([points_df['x'][sample_index_list], points_df['y'][sample_index_list], \n               points_df['z'][sample_index_list], img_x_list, img_y_list, img_z_list])\nCM = np.corrcoef(v)\n\nfig, ax = plt.subplots(figsize=(7, 7))\nim = ax.imshow(CM)\nax.set_xticks(np.arange(6))\nax.set_yticks(np.arange(6))\nax.set_xticklabels(['x', 'y', 'z', 'img_x', 'img_y', 'img_z'])\nax.set_yticklabels(['x', 'y', 'z', 'img_x', 'img_y', 'img_z'])\nfor i in range(6):\n    for j in range(6):\n        text = ax.text(j, i, round(CM[i, j], 2),\n                       ha=\"center\", va=\"center\", color=\"w\")\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mask Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_path = os.path.join(DATASET_DIR, 'train_masks', '{}.{}'.format(image_ids[0], 'jpg'))\nmask_accru = cv2.imread(mask_path, 0).astype(np.int) / 255\nfor id in image_ids[1:]:\n    mask_path = os.path.join(DATASET_DIR, 'train_masks', '{}.{}'.format(id, 'jpg'))\n    try:\n        mask = cv2.imread(mask_path, 0).astype(np.int) / 255\n        mask_accru = np.add(mask_accru, mask)\n    except:\n        pass\n\nfig, ax = plt.subplots(figsize=(18, 16))\nax.set_title('mask distribution')\nim = ax.imshow(mask_accru)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"The distribution of car types is imbalanced.\nThe distribution of each other dimension of labels is highly imbalanced.\nThe upper halfs of images are less useful or useless.\nThe dimensions y and z are extremely correlated.\nThe dimensions x and z are less correlated.\nMasks are distributed mostly at far ends."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}