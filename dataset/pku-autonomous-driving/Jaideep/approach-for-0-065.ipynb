{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n    None\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here is the some route ahead after you are stuck between 0.04 and 0.05. I am not going to publish the kernel as it would be against the ethics of this competition at this stage.**\n* 1. I used Hicops Kernel only ,same Dataset ,image scaling ,did dataset cleaning using approach in point 7 \n\n* 2. I used below version of Focal Loss\n* 3. I used effnetb2 in hicops model , You have to   replace 1280+1024 with 1408+1024\n* 4. I used higher image size 512,2048\n* 5. I used One Cycle LR scheduler max lr =1e-3 ,div_factor=8  and monitored mAP for saving best weights.This will help you prevernt overfitting.\n* 6. Stop the Training if you see Mask loss is rising more.\n* 7. I modified the Drop out rate for effnet as per https://www.kaggle.com/isakev/rb-s-centernet-baseline-pytorch-without-dropout"},{"metadata":{},"cell_type":"markdown","source":"**Dont Forget to Upvote if you get benefitted by the approach**\nI will keep updating if i find more approaches."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"def _sigmoid(x):\n    \n    \n    y = torch.clamp(x.sigmoid_(), min=1e-4, max=1-1e-4)\n    return y\n\nclass focal_loss(nn.Module):\n  def __init__(self, gamma=2.0):\n        super().__init__()\n  def forward(self,pred, gt):\n    ''' Modified focal loss. Exactly the same as CornerNet.\n        Runs faster and costs a little bit more memory\n      Arguments:\n        pred (batch x c x h x w)\n        gt_regr (batch x c x h x w)\n    '''\n    pred=_sigmoid(pred)\n    pos_inds = gt.eq(1).float()\n    pos_inds=pos_inds.unsqueeze(1)\n    #print(pos_inds.size())\n    neg_inds = gt.lt(1).float().unsqueeze(1)\n\n    neg_weights = torch.pow(1 - gt, 4).unsqueeze(1)\n\n    loss = 0\n    #print(neg_weights)\n    pos_loss = torch.log(pred+1e-7) * torch.pow(1 - pred, 2) * pos_inds\n    neg_loss = torch.log(1 - pred+1e-7) * torch.pow(pred, 2) * neg_weights * neg_inds\n\n    \n    #.float().sum()\n    pos_loss = pos_loss.view(pred.size(0),-1).sum(-1)\n    neg_loss = neg_loss.view(gt.size(0),-1).sum(-1)\n    #neg_loss.sum(-1)\n    num_pos  = pos_inds.sum()\n    if num_pos == 0:\n      loss = loss - neg_loss\n    else:\n      loss = loss - (pos_loss + neg_loss) #/ num_pos\n    num_pos  = pos_inds.view(gt.size(0),-1).sum(-1)\n    #print('loss',loss.size(),pos_loss.size(),loss.size(),'loss_sum',loss.sum(-1).mean(0),num_pos.size())\n    return loss.mean(0)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}