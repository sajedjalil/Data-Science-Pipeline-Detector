{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81d94f5c-682b-e465-8c8c-f6c7d1e0ab65"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nimport re\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom nltk.tokenize import word_tokenize\nfrom subprocess import check_output\nfrom nltk.stem import WordNetLemmatizer\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2be4438b-3439-3ca0-09c9-bbd475d8cef9"},"outputs":[],"source":"bio = pd.read_csv(\"../input/biology.csv\")\ncook = pd.read_csv(\"../input/cooking.csv\")\ncrypto = pd.read_csv(\"../input/crypto.csv\")\ndiy = pd.read_csv(\"../input/diy.csv\")\nrobot = pd.read_csv(\"../input/robotics.csv\")\ntravel = pd.read_csv(\"../input/travel.csv\")\nsample_sub = pd.read_csv(\"../input/sample_submission.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\n\nall_dat = [bio,cook,crypto,diy,robot,travel]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0dd1cca-a5e0-b58c-c4d6-044761f97892"},"outputs":[],"source":"swords1 = stopwords.words('english')\n\npunctuations = string.punctuation\n\ndef title_clean(data):\n    title = data.title\n    title = title.apply(lambda x: x.lower())\n    print('Remove Punctuations')\n    # title = [' '.join(word.strip(punctuations) for word in i.split()) for i in title]\n    title = title.apply(lambda x: re.sub(r'^\\W+|\\W+$',' ',x))\n    title = title.apply(lambda i: ''.join(i.strip(punctuations))  )\n    print('tokenize')\n    title = title.apply(lambda x: word_tokenize(x))\n    print('Remove stopwords')\n    title = title.apply(lambda x: [i for i in x if i not in swords1 if len(i)>2])\n    print('minor clean some wors')\n    title = title.apply(lambda x: [i.split('/') for i in x] )\n    title = title.apply(lambda x: [i for y in x for i in y])\n    print('Lemmatizing')\n    wordnet_lemmatizer = WordNetLemmatizer()\n    title = title.apply(lambda x: [wordnet_lemmatizer.lemmatize(i,pos='v') for i in x])\n    title = title.apply(lambda x: [i for i in x if len(i)>2])\n    return(title)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d06427b6-a930-eb78-f40f-66e00a0b16aa"},"outputs":[],"source":"test.title = title_clean(test)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b96d328a-dfba-a81f-8417-1a820d7cd947"},"outputs":[],"source":"test.head()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5289758e-4e06-aa13-6fea-ce63f06417bb"},"outputs":[],"source":"tags = test.title.apply(lambda x: nltk.pos_tag(x) )\ntags = tags.apply(lambda x: [i[0] for i in x if i[1][0] in \"N\" ])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3c30d9e-3ff4-0ceb-d323-247566ec7f88"},"outputs":[],"source":"test[\"tags\"] = tags.apply(lambda x: \" \".join(x))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"339c9197-d703-f92f-ec4d-5c2ce7896adf"},"outputs":[],"source":"sub_dat = test.loc[:,[\"id\",\"tags\"]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"875a70c3-cc01-1884-2774-817c074e507b"},"outputs":[],"source":"sample_sub.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2333624-24ba-9768-1fe4-d68e969a8da1"},"outputs":[],"source":"sub_dat.to_csv(\"sub0.csv\",index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc11acbf-d6e9-e055-d8e1-01bfbb279b72"},"outputs":[],"source":"sub_dat.head()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}