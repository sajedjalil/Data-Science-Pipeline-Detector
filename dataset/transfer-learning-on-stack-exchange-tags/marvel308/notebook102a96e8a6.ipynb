{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4e19a17-0d19-a977-d22a-c2d398b85bc8"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport math\nfrom collections import defaultdict, OrderedDict\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d944c232-d98e-c18e-3ffe-a8b4e07a80e2"},"outputs":[],"source":"dataframes = {\n    \"cooking\": pd.read_csv(\"../input/cooking.csv\"),\n    \"crypto\": pd.read_csv(\"../input/crypto.csv\"),\n    \"robotics\": pd.read_csv(\"../input/robotics.csv\"),\n    \"biology\": pd.read_csv(\"../input/biology.csv\"),\n    \"travel\": pd.read_csv(\"../input/travel.csv\"),\n    \"diy\": pd.read_csv(\"../input/diy.csv\"),\n}"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"111283c8-0310-eb20-8988-bb3c6f68669a"},"outputs":[],"source":"print(dataframes[\"robotics\"].iloc[1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bbe74e8b-07b6-088b-087a-f625cb880057"},"outputs":[],"source":"uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))'\n\ndef stripTagsAndUris(x):\n    if x:\n        # BeautifulSoup on content\n        soup = BeautifulSoup(x, \"html.parser\")\n        # Stripping all <code> tags with their content if any\n        if soup.code:\n            soup.code.decompose()\n        # Get all the text out of the html\n        text =  soup.get_text()\n        # Returning text stripping out all uris\n        return re.sub(uri_re, \"\", text)\n    else:\n        return \"\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7fac5960-1e3b-6a55-a5f3-9ff88256875a"},"outputs":[],"source":"for df in dataframes.values():\n    df[\"content\"] = df[\"content\"].map(stripTagsAndUris)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea3f5478-3cea-a56b-a4ac-70133cf81a0d"},"outputs":[],"source":"def removePunctuation(x):\n    # Lowercasing all words\n    x = x.lower()\n    # Removing non ASCII chars\n    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n    # Removing (replacing with empty spaces actually) all the punctuations\n    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4245c650-77c6-1509-c451-7d9846cd22c9"},"outputs":[],"source":"for df in dataframes.values():\n    df[\"title\"] = df[\"title\"].map(removePunctuation)\n    df[\"content\"] = df[\"content\"].map(removePunctuation)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"369b7a34-016f-cd05-2815-a4729248d7f8"},"outputs":[],"source":"print(dataframes[\"robotics\"].iloc[1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22d72c2b-ccf6-b77b-5762-017043547251"},"outputs":[],"source":"stops = set(stopwords.words(\"english\"))\ndef removeStopwords(x):\n    # Removing all the stopwords\n    filtered_words = [word for word in x.split() if word not in stops]\n    return \" \".join(filtered_words)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e5908b3-7b2d-44d6-dd20-3721889b9121"},"outputs":[],"source":"for df in dataframes.values():\n    df[\"title\"] = df[\"title\"].map(removeStopwords)\n    df[\"content\"] = df[\"content\"].map(removeStopwords)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa90852c-87f0-36df-d0aa-66af3df1e094"},"outputs":[],"source":"print(dataframes[\"robotics\"].iloc[1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55edbdf5-ebb9-86a1-3dd8-bad6470887cc"},"outputs":[],"source":"for df in dataframes.values():\n    # From a string sequence of tags to a list of tags\n    df[\"tags\"] = df[\"tags\"].map(lambda x: x.split())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e252312-3676-e084-9a92-25eebb4ad1ec"},"outputs":[],"source":"def get_words(text):\n    word_split = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n    return [word.strip().lower() for word in word_split.split(text)]\nprint(type(get_words(\"Hey How are you\")));"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"559be271-299d-27e8-19ab-80e59dfbeb75"},"outputs":[],"source":"def process_text(doc, idf, text):\n    tf = OrderedDict();\n    word_count = 0.\n    #print(get_words(text));\n    for word in get_words(text):\n        #print(word);\n        #print(type(word));\n        if word not in tf:\n            tf[word] = 0\n        tf[word] += 1\n        idf[word].add(doc)\n        word_count += 1.\n\n    for word in tf:\n        tf[word] = tf[word] / word_count\n\n    return tf, word_count"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a18c083-3741-ae30-2f5d-6d76b478141f"},"outputs":[],"source":"def getString(df):\n    return \"\".join(df.astype('str').tail(1).tolist());"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f55a3497-78ae-ec9b-ca17-1dd2a6a9217b"},"outputs":[],"source":"docs = [];\nidf = defaultdict(set);\ntf = {};\nword_counts = defaultdict(float);\ncount = 0;\nfor df in dataframes.values():\n    count+=1;\n    doc = int(getString(df[\"id\"]));\n    text = getString(df[\"title\"])+\" \"+getString(df[\"content\"]);\n    #print(text);\n    #print(type(text));\n    #docs.append(doc);\n    #tf[doc], word_counts[doc] = process_text(doc, idf, text)\n    myset = set(get_words(text));\n    mynewlist = list(myset);\n    #print(mynewlist);\n    for word in mynewlist:\n        if word not in tf:\n            tf[word] = 0\n        tf[word] += 1\n    #break;\nprint(count);\nprint(tf);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99def218-85aa-81f3-5c38-31d463fed429"},"outputs":[],"source":"nr_docs = len(docs)\nfor doc in docs:\n    for word in tf[doc]:\n        tf[doc][word] *= math.log(nr_docs / len(idf[word]))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}