{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6cc15807-d7a2-6f12-1d4c-038dfe242ce7"},"source":"Ok \ni am mixing here\n\nRAKE\n+ TFIDF ngram(1-3)\nand group together to make a tag.\nThese tags we will see the ranking soon"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0cb1c24c-0638-91b6-020e-b4dc4cf75b08"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport nltk\nimport operator\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import csr_matrix\n\n\ndef dict_to_df(d):\n    df = pd.DataFrame()\n    df['word'] = d.keys()\n    df['count'] = d.values()\n    return df\nRES_DIR = \"../input/\"\ndef load_train_data():\n    categories = ['cooking', 'robotics', 'travel', 'crypto', 'diy', 'biology']\n    train_data = []\n    for cat in categories:\n        data = pd.read_csv(\"{}{}.csv\".format(RES_DIR, cat), usecols=['id', 'title','content' ,'tags'])\n        data['category'] = cat\n        train_data.append(data)\n    return pd.concat(train_data)\ntrain_data = load_train_data()\n#import the test data\n\n#print(train_data.head())\n\n#import test data in same format\ntestdoc = pd.read_csv(\"../input/test.csv\")\ntestdoc['tags'] = ''\ntestdoc['category'] = 'physics'\nprint(testdoc.head())\n#train_data_tot=train_data.append(testdoc)\n# Implementation of RAKE - Rapid Automtic Keyword Exraction algorithm\n\n\nuri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))'\n\ndef stripTagsAndUris(x):\n    if x:\n        # BeautifulSoup on content\n        soup = BeautifulSoup(x, \"html.parser\")\n        # Stripping all <code> tags with their content if any\n        if soup.code:\n            soup.code.decompose()\n        # Get all the text out of the html\n        text =  soup.get_text()\n        # Returning text stripping out all uris\n        return re.sub(uri_re, \"\", text)\n    else:\n        return \"\"\n    \ndef is_number(s):\n    try:\n        float(s) if '.' in s else int(s)\n        return True\n    except ValueError:\n        return False\n\n\ndef load_stop_words(stop_word_file):\n    \"\"\"\n    Utility function to load stop words from a file and return as a list of words\n    @param stop_word_file Path and file name of a file containing stop words.\n    @return list A list of stop words.\n    \"\"\"\n    stop_words = []\n    for line in open(stop_word_file):\n        if line.strip()[0:1] != \"#\":\n            for word in line.split():  # in case more than one per line\n                stop_words.append(word)\n    return stop_words\n\n\ndef separate_words(text, min_word_return_size):\n    \"\"\"\n    Utility function to return a list of all words that are have a length greater than a specified number of characters.\n    @param text The text that must be split in to words.\n    @param min_word_return_size The minimum no of characters a word must have to be included.\n    \"\"\"\n    splitter = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n    words = []\n    for single_word in splitter.split(text):\n        current_word = single_word.strip().lower()\n        #leave numbers in phrase, but don't count as words, since they tend to invalidate scores of their phrases\n        if len(current_word) > min_word_return_size and current_word != '' and not is_number(current_word):\n            words.append(current_word)\n    return words\n\n\ndef split_sentences(text):\n    \"\"\"\n    Utility function to return a list of sentences.\n    @param text The text that must be split in to sentences.\n    \"\"\"\n    sentence_delimiters = re.compile(u'[.!?,;:\\t\\\\\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]|\\\\s\\\\-\\\\s')\n    sentences = sentence_delimiters.split(text)\n    return sentences\n\n\ndef build_stop_word_regex(stop_word_file_path):\n    stop_word_list = load_stop_words(stop_word_file_path)\n    stop_word_regex_list = []\n    for word in stop_word_list:\n        word_regex = r'\\b' + word + r'(?![\\w-])'  # added look ahead for hyphen\n        stop_word_regex_list.append(word_regex)\n    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n    return stop_word_pattern\n\ndef build_stop_word_(stop_word_file_path):\n    stop_word_list = stop_word_file_path\n    stop_word_regex_list = []\n    for word in stop_word_list:\n        word_regex = r'\\b' + word + r'(?![\\w-])'  # added look ahead for hyphen\n        stop_word_regex_list.append(word_regex)\n    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n    return stop_word_pattern\n\ndef generate_candidate_keywords(sentence_list, stopword_pattern):\n    phrase_list = []\n    for s in sentence_list:\n        tmp = re.sub(stopword_pattern, '|', s.strip())\n        phrases = tmp.split(\"|\")\n        for phrase in phrases:\n            phrase = phrase.strip().lower()\n            if phrase != \"\":\n                phrase_list.append(phrase)\n    return phrase_list\n\n\ndef calculate_word_scores(phraseList):\n    word_frequency = {}\n    word_degree = {}\n    for phrase in phraseList:\n        word_list = separate_words(phrase, 0)\n        word_list_length = len(word_list)\n        word_list_degree = word_list_length - 1\n        if word_list_degree > 3: word_list_degree = 3 #exp.\n        for word in word_list:\n            word_frequency.setdefault(word, 0)\n            word_frequency[word] += 1\n            word_degree.setdefault(word, 0)\n            #word_degree[word] += word_list_degree  #orig.\n            word_degree[word] += 1/(word_list_length*1.0) #exp.\n    for item in word_frequency:\n        word_degree[item] = word_degree[item] + word_frequency[item]\n\n    # Calculate Word scores = deg(w)/frew(w)\n    word_score = {}\n    for item in word_frequency:\n        word_score.setdefault(item, 0)\n        # word_score[item] = word_degree[item] / (word_frequency[item] * 1.0)  #orig.\n        word_score[item] = word_frequency[item]/(word_degree[item] * 1.0) #exp.\n    return word_score\n\n\ndef generate_candidate_keyword_scores(phrase_list, word_score):\n    keyword_candidates = {}\n    for phrase in phrase_list:\n        keyword_candidates.setdefault(phrase, 2)\n        word_list = separate_words(phrase, 2)\n        candidate_score = 0\n        for word in word_list:\n            candidate_score += word_score[word]\n        keyword_candidates[phrase] = candidate_score\n    return keyword_candidates\n\n\nclass Rake(object):\n    def __init__(self, stop_words_path):\n        self.stop_words_path = stop_words_path\n        self.__stop_words_pattern = build_stop_word_regex(stop_words_path)\n\n    def run(self, text):\n        sentence_list = split_sentences(text)\n        phrase_list = generate_candidate_keywords(sentence_list, self.__stop_words_pattern)\n        word_scores = calculate_word_scores(phrase_list)\n        keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores)\n        sorted_keywords = sorted(keyword_candidates.items(), key=operator.itemgetter(1), reverse=True)\n        return sorted_keywords\n\ndebug=True\nfor index, row in testdoc.sample(2).iterrows():\n    #print(row[\"title\"], row[\"content\"]    )\n    sentenceList = split_sentences(row['title']+' '+row['content'])\n    #stoppath = \"FoxStoplist.txt\" #Fox stoplist contains \"numbers\", so it will not find \"natural numbers\" like in Table 1.1\n    stoppath = \"SmartStoplist.txt\"  #SMART stoplist misses some of the lower-scoring keywords in Figure 1.5, which means that the top 1/3 cuts off one of the 4.0 score words in Table 1.1\n    #stopwordpattern = build_stop_word_regex(stoppath)\n    stopwordpattern= \"\"\"re.compile(r\"\\ba(?![\\w-])|\\ba's(?![\\w-])|\\bable(?![\\w-])|\\babout(?![\\w-])|\\babove(?![\\w-])|\\baccording(?![\\w-])|\\baccordingly(?![\\w-])|\\bacross(?![\\w-])|\\bactually(?![\\w-])|\\bafter(?![\\w-])|\\bafterwards(?![\\w-])|\\bagain(?![\\w-])|\\bagainst(?![\\w-])|\\bain't(?![\\w-])|\\ball(?![\\w-])|\\ballow(?![\\w-])|\\ballows(?![\\w-])|\\balmost(?![\\w-])|\\balone(?![\\w-])|\\balong(?![\\w-])|\\balready(?![\\w-])|\\balso(?![\\w-])|\\balthough(?![\\w-])|\\balways(?![\\w-])|\\bam(?![\\w-])|\\bamong(?![\\w-])|\\bamongst(?![\\w-])|\\ban(?![\\w-])|\\band(?![\\w-])|\\banother(?![\\w-])|\\bany(?![\\w-])|\\banybody(?![\\w-])|\\banyhow(?![\\w-])|\\banyone(?![\\w-])|\\banything(?![\\w-])|\\banyway(?![\\w-])|\\banyways(?![\\w-])|\\banywhere(?![\\w-])|\\bapart(?![\\w-])|\\bappear(?![\\w-])|\\bappreciate(?![\\w-])|\\bappropriate(?![\\w-])|\\bare(?![\\w-])|\\baren't(?![\\w-])|\\baround(?![\\w-])|\\bas(?![\\w-])|\\baside(?![\\w-])|\\bask(?![\\w-])|\\basking(?![\\w-])|\\bassociated(?![\\w-])|\\bat(?![\\w-])|\\bavailable(?![\\w-])|\\baway(?![\\w-])|\\bawfully(?![\\w-])|\\bb(?![\\w-])|\\bbe(?![\\w-])|\\bbecame(?![\\w-])|\\bbecause(?![\\w-])|\\bbecome(?![\\w-])|\\bbecomes(?![\\w-])|\\bbecoming(?![\\w-])|\\bbeen(?![\\w-])|\\bbefore(?![\\w-])|\\bbeforehand(?![\\w-])|\\bbehind(?![\\w-])|\\bbeing(?![\\w-])|\\bbelieve(?![\\w-])|\\bbelow(?![\\w-])|\\bbeside(?![\\w-])|\\bbesides(?![\\w-])|\\bbest(?![\\w-])|\\bbetter(?![\\w-])|\\bbetween(?![\\w-])|\\bbeyond(?![\\w-])|\\bboth(?![\\w-])|\\bbrief(?![\\w-])|\\bbut(?![\\w-])|\\bby(?![\\w-])|\\bc(?![\\w-])|\\bc'mon(?![\\w-])|\\bc's(?![\\w-])|\\bcame(?![\\w-])|\\bcan(?![\\w-])|\\bcan't(?![\\w-])|\\bcannot(?![\\w-])|\\bcant(?![\\w-])|\\bcause(?![\\w-])|\\bcauses(?![\\w-])|\\bcertain(?![\\w-])|\\bcertainly(?![\\w-])|\\bchanges(?![\\w-])|\\bclearly(?![\\w-])|\\bco(?![\\w-])|\\bcom(?![\\w-])|\\bcome(?![\\w-])|\\bcomes(?![\\w-])|\\bconcerning(?![\\w-])|\\bconsequently(?![\\w-])|\\bconsider(?![\\w-])|\\bconsidering(?![\\w-])|\\bcontain(?![\\w-])|\\bcontaining(?![\\w-])|\\bcontains(?![\\w-])|\\bcorresponding(?![\\w-])|\\bcould(?![\\w-])|\\bcouldn't(?![\\w-])|\\bcourse(?![\\w-])|\\bcurrently(?![\\w-])|\\bd(?![\\w-])|\\bdefinitely(?![\\w-])|\\bdescribed(?![\\w-])|\\bdespite(?![\\w-])|\\bdid(?![\\w-])|\\bdidn't(?![\\w-])|\\bdifferent(?![\\w-])|\\bdo(?![\\w-])|\\bdoes(?![\\w-])|\\bdoesn't(?![\\w-])|\\bdoing(?![\\w-])|\\bdon't(?![\\w-])|\\bdone(?![\\w-])|\\bdown(?![\\w-])|\\bdownwards(?![\\w-])|\\bduring(?![\\w-])|\\be(?![\\w-])|\\beach(?![\\w-])|\\bedu(?![\\w-])|\\beg(?![\\w-])|\\beight(?![\\w-])|\\beither(?![\\w-])|\\belse(?![\\w-])|\\belsewhere(?![\\w-])|\\benough(?![\\w-])|\\bentirely(?![\\w-])|\\bespecially(?![\\w-])|\\bet(?![\\w-])|\\betc(?![\\w-])|\\beven(?![\\w-])|\\bever(?![\\w-])|\\bevery(?![\\w-])|\\beverybody(?![\\w-])|\\beveryone(?![\\w-])|\\beverything(?![\\w-])|\\beverywhere(?![\\w-])|\\bex(?![\\w-])|\\bexactly(?![\\w-])|\\bexample(?![\\w-])|\\bexcept(?![\\w-])|\\bf(?![\\w-])|\\bfar(?![\\w-])|\\bfew(?![\\w-])|\\bfifth(?![\\w-])|\\bfirst(?![\\w-])|\\bfive(?![\\w-])|\\bfollowed(?![\\w-])|\\bfollowing(?![\\w-])|\\bfollows(?![\\w-])|\\bfor(?![\\w-])|\\bformer(?![\\w-])|\\bformerly(?![\\w-])|\\bforth(?![\\w-])|\\bfour(?![\\w-])|\\bfrom(?![\\w-])|\\bfurther(?![\\w-])|\\bfurthermore(?![\\w-])|\\bg(?![\\w-])|\\bget(?![\\w-])|\\bgets(?![\\w-])|\\bgetting(?![\\w-])|\\bgiven(?![\\w-])|\\bgives(?![\\w-])|\\bgo(?![\\w-])|\\bgoes(?![\\w-])|\\bgoing(?![\\w-])|\\bgone(?![\\w-])|\\bgot(?![\\w-])|\\bgotten(?![\\w-])|\\bgreetings(?![\\w-])|\\bh(?![\\w-])|\\bhad(?![\\w-])|\\bhadn't(?![\\w-])|\\bhappens(?![\\w-])|\\bhardly(?![\\w-])|\\bhas(?![\\w-])|\\bhasn't(?![\\w-])|\\bhave(?![\\w-])|\\bhaven't(?![\\w-])|\\bhaving(?![\\w-])|\\bhe(?![\\w-])|\\bhe's(?![\\w-])|\\bhello(?![\\w-])|\\bhelp(?![\\w-])|\\bhence(?![\\w-])|\\bher(?![\\w-])|\\bhere(?![\\w-])|\\bhere's(?![\\w-])|\\bhereafter(?![\\w-])|\\bhereby(?![\\w-])|\\bherein(?![\\w-])|\\bhereupon(?![\\w-])|\\bhers(?![\\w-])|\\bherself(?![\\w-])|\\bhi(?![\\w-])|\\bhim(?![\\w-])|\\bhimself(?![\\w-])|\\bhis(?![\\w-])|\\bhither(?![\\w-])|\\bhopefully(?![\\w-])|\\bhow(?![\\w-])|\\bhowbeit(?![\\w-])|\\bhowever(?![\\w-])|\\bi(?![\\w-])|\\bi'd(?![\\w-])|\\bi'll(?![\\w-])|\\bi'm(?![\\w-])|\\bi've(?![\\w-])|\\bie(?![\\w-])|\\bif(?![\\w-])|\\bignored(?![\\w-])|\\bimmediate(?![\\w-])|\\bin(?![\\w-])|\\binasmuch(?![\\w-])|\\binc(?![\\w-])|\\bindeed(?![\\w-])|\\bindicate(?![\\w-])|\\bindicated(?![\\w-])|\\bindicates(?![\\w-])|\\binner(?![\\w-])|\\binsofar(?![\\w-])|\\binstead(?![\\w-])|\\binto(?![\\w-])|\\binward(?![\\w-])|\\bis(?![\\w-])|\\bisn't(?![\\w-])|\\bit(?![\\w-])|\\bit'd(?![\\w-])|\\bit'll(?![\\w-])|\\bit's(?![\\w-])|\\bits(?![\\w-])|\\bitself(?![\\w-])|\\bj(?![\\w-])|\\bjust(?![\\w-])|\\bk(?![\\w-])|\\bkeep(?![\\w-])|\\bkeeps(?![\\w-])|\\bkept(?![\\w-])|\\bknow(?![\\w-])|\\bknows(?![\\w-])|\\bknown(?![\\w-])|\\bl(?![\\w-])|\\blast(?![\\w-])|\\blately(?![\\w-])|\\blater(?![\\w-])|\\blatter(?![\\w-])|\\blatterly(?![\\w-])|\\bleast(?![\\w-])|\\bless(?![\\w-])|\\blest(?![\\w-])|\\blet(?![\\w-])|\\blet's(?![\\w-])|\\blike(?![\\w-])|\\bliked(?![\\w-])|\\blikely(?![\\w-])|\\blittle(?![\\w-])|\\blook(?![\\w-])|\\blooking(?![\\w-])|\\blooks(?![\\w-])|\\bltd(?![\\w-])|\\bm(?![\\w-])|\\bmainly(?![\\w-])|\\bmany(?![\\w-])|\\bmay(?![\\w-])|\\bmaybe(?![\\w-])|\\bme(?![\\w-])|\\bmean(?![\\w-])|\\bmeanwhile(?![\\w-])|\\bmerely(?![\\w-])|\\bmight(?![\\w-])|\\bmore(?![\\w-])|\\bmoreover(?![\\w-])|\\bmost(?![\\w-])|\\bmostly(?![\\w-])|\\bmuch(?![\\w-])|\\bmust(?![\\w-])|\\bmy(?![\\w-])|\\bmyself(?![\\w-])|\\bn(?![\\w-])|\\bname(?![\\w-])|\\bnamely(?![\\w-])|\\bnd(?![\\w-])|\\bnear(?![\\w-])|\\bnearly(?![\\w-])|\\bnecessary(?![\\w-])|\\bneed(?![\\w-])|\\bneeds(?![\\w-])|\\bneither(?![\\w-])|\\bnever(?![\\w-])|\\bnevertheless(?![\\w-])|\\bnew(?![\\w-])|\\bnext(?![\\w-])|\\bnine(?![\\w-])|\\bno(?![\\w-])|\\bnobody(?![\\w-])|\\bnon(?![\\w-])|\\bnone(?![\\w-])|\\bnoone(?![\\w-])|\\bnor(?![\\w-])|\\bnormally(?![\\w-])|\\bnot(?![\\w-])|\\bnothing(?![\\w-])|\\bnovel(?![\\w-])|\\bnow(?![\\w-])|\\bnowhere(?![\\w-])|\\bo(?![\\w-])|\\bobviously(?![\\w-])|\\bof(?![\\w-])|\\boff(?![\\w-])|\\boften(?![\\w-])|\\boh(?![\\w-])|\\bok(?![\\w-])|\\bokay(?![\\w-])|\\bold(?![\\w-])|\\bon(?![\\w-])|\\bonce(?![\\w-])|\\bone(?![\\w-])|\\bones(?![\\w-])|\\bonly(?![\\w-])|\\bonto(?![\\w-])|\\bor(?![\\w-])|\\bother(?![\\w-])|\\bothers(?![\\w-])|\\botherwise(?![\\w-])|\\bought(?![\\w-])|\\bour(?![\\w-])|\\bours(?![\\w-])|\\bourselves(?![\\w-])|\\bout(?![\\w-])|\\boutside(?![\\w-])|\\bover(?![\\w-])|\\boverall(?![\\w-])|\\bown(?![\\w-])|\\bp(?![\\w-])|\\bparticular(?![\\w-])|\\bparticularly(?![\\w-])|\\bper(?![\\w-])|\\bperhaps(?![\\w-])|\\bplaced(?![\\w-])|\\bplease(?![\\w-])|\\bplus(?![\\w-])|\\bpossible(?![\\w-])|\\bpresumably(?![\\w-])|\\bprobably(?![\\w-])|\\bprovides(?![\\w-])|\\bq(?![\\w-])|\\bque(?![\\w-])|\\bquite(?![\\w-])|\\bqv(?![\\w-])|\\br(?![\\w-])|\\brather(?![\\w-])|\\brd(?![\\w-])|\\bre(?![\\w-])|\\breally(?![\\w-])|\\breasonably(?![\\w-])|\\bregarding(?![\\w-])|\\bregardless(?![\\w-])|\\bregards(?![\\w-])|\\brelatively(?![\\w-])|\\brespectively(?![\\w-])|\\bright(?![\\w-])|\\bs(?![\\w-])|\\bsaid(?![\\w-])|\\bsame(?![\\w-])|\\bsaw(?![\\w-])|\\bsay(?![\\w-])|\\bsaying(?![\\w-])|\\bsays(?![\\w-])|\\bsecond(?![\\w-])|\\bsecondly(?![\\w-])|\\bsee(?![\\w-])|\\bseeing(?![\\w-])|\\bseem(?![\\w-])|\\bseemed(?![\\w-])|\\bseeming(?![\\w-])|\\bseems(?![\\w-])|\\bseen(?![\\w-])|\\bself(?![\\w-])|\\bselves(?![\\w-])|\\bsensible(?![\\w-])|\\bsent(?![\\w-])|\\bserious(?![\\w-])|\\bseriously(?![\\w-])|\\bseven(?![\\w-])|\\bseveral(?![\\w-])|\\bshall(?![\\w-])|\\bshe(?![\\w-])|\\bshould(?![\\w-])|\\bshouldn't(?![\\w-])|\\bsince(?![\\w-])|\\bsix(?![\\w-])|\\bso(?![\\w-])|\\bsome(?![\\w-])|\\bsomebody(?![\\w-])|\\bsomehow(?![\\w-])|\\bsomeone(?![\\w-])|\\bsomething(?![\\w-])|\\bsometime(?![\\w-])|\\bsometimes(?![\\w-])|\\bsomewhat(?![\\w-])|\\bsomewhere(?![\\w-])|\\bsoon(?![\\w-])|\\bsorry(?![\\w-])|\\bspecified(?![\\w-])|\\bspecify(?![\\w-])|\\bspecifying(?![\\w-])|\\bstill(?![\\w-])|\\bsub(?![\\w-])|\\bsuch(?![\\w-])|\\bsup(?![\\w-])|\\bsure(?![\\w-])|\\bt(?![\\w-])|\\bt's(?![\\w-])|\\btake(?![\\w-])|\\btaken(?![\\w-])|\\btell(?![\\w-])|\\btends(?![\\w-])|\\bth(?![\\w-])|\\bthan(?![\\w-])|\\bthank(?![\\w-])|\\bthanks(?![\\w-])|\\bthanx(?![\\w-])|\\bthat(?![\\w-])|\\bthat's(?![\\w-])|\\bthats(?![\\w-])|\\bthe(?![\\w-])|\\btheir(?![\\w-])|\\btheirs(?![\\w-])|\\bthem(?![\\w-])|\\bthemselves(?![\\w-])|\\bthen(?![\\w-])|\\bthence(?![\\w-])|\\bthere(?![\\w-])|\\bthere's(?![\\w-])|\\bthereafter(?![\\w-])|\\bthereby(?![\\w-])|\\btherefore(?![\\w-])|\\btherein(?![\\w-])|\\btheres(?![\\w-])|\\bthereupon(?![\\w-])|\\bthese(?![\\w-])|\\bthey(?![\\w-])|\\bthey'd(?![\\w-])|\\bthey'll(?![\\w-])|\\bthey're(?![\\w-])|\\bthey've(?![\\w-])|\\bthink(?![\\w-])|\\bthird(?![\\w-])|\\bthis(?![\\w-])|\\bthorough(?![\\w-])|\\bthoroughly(?![\\w-])|\\bthose(?![\\w-])|\\bthough(?![\\w-])|\\bthree(?![\\w-])|\\bthrough(?![\\w-])|\\bthroughout(?![\\w-])|\\bthru(?![\\w-])|\\bthus(?![\\w-])|\\bto(?![\\w-])|\\btogether(?![\\w-])|\\btoo(?![\\w-])|\\btook(?![\\w-])|\\btoward(?![\\w-])|\\btowards(?![\\w-])|\\btried(?![\\w-])|\\btries(?![\\w-])|\\btruly(?![\\w-])|\\btry(?![\\w-])|\\btrying(?![\\w-])|\\btwice(?![\\w-])|\\btwo(?![\\w-])|\\bu(?![\\w-])|\\bun(?![\\w-])|\\bunder(?![\\w-])|\\bunfortunately(?![\\w-])|\\bunless(?![\\w-])|\\bunlikely(?![\\w-])|\\buntil(?![\\w-])|\\bunto(?![\\w-])|\\bup(?![\\w-])|\\bupon(?![\\w-])|\\bus(?![\\w-])|\\buse(?![\\w-])|\\bused(?![\\w-])|\\buseful(?![\\w-])|\\buses(?![\\w-])|\\busing(?![\\w-])|\\busually(?![\\w-])|\\buucp(?![\\w-])|\\bv(?![\\w-])|\\bvalue(?![\\w-])|\\bvarious(?![\\w-])|\\bvery(?![\\w-])|\\bvia(?![\\w-])|\\bviz(?![\\w-])|\\bvs(?![\\w-])|\\bw(?![\\w-])|\\bwant(?![\\w-])|\\bwants(?![\\w-])|\\bwas(?![\\w-])|\\bwasn't(?![\\w-])|\\bway(?![\\w-])|\\bwe(?![\\w-])|\\bwe'd(?![\\w-])|\\bwe'll(?![\\w-])|\\bwe're(?![\\w-])|\\bwe've(?![\\w-])|\\bwelcome(?![\\w-])|\\bwell(?![\\w-])|\\bwent(?![\\w-])|\\bwere(?![\\w-])|\\bweren't(?![\\w-])|\\bwhat(?![\\w-])|\\bwhat's(?![\\w-])|\\bwhatever(?![\\w-])|\\bwhen(?![\\w-])|\\bwhence(?![\\w-])|\\bwhenever(?![\\w-])|\\bwhere(?![\\w-])|\\bwhere's(?![\\w-])|\\bwhereafter(?![\\w-])|\\bwhereas(?![\\w-])|\\bwhereby(?![\\w-])|\\bwherein(?![\\w-])|\\bwhereupon(?![\\w-])|\\bwherever(?![\\w-])|\\bwhether(?![\\w-])|\\bwhich(?![\\w-])|\\bwhile(?![\\w-])|\\bwhither(?![\\w-])|\\bwho(?![\\w-])|\\bwho's(?![\\w-])|\\bwhoever(?![\\w-])|\\bwhole(?![\\w-])|\\bwhom(?![\\w-])|\\bwhose(?![\\w-])|\\bwhy(?![\\w-])|\\bwill(?![\\w-])|\\bwilling(?![\\w-])|\\bwish(?![\\w-])|\\bwith(?![\\w-])|\\bwithin(?![\\w-])|\\bwithout(?![\\w-])|\\bwon't(?![\\w-])|\\bwonder(?![\\w-])|\\bwould(?![\\w-])|\\bwould(?![\\w-])|\\bwouldn't(?![\\w-])|\\bx(?![\\w-])|\\by(?![\\w-])|\\byes(?![\\w-])|\\byet(?![\\w-])|\\byou(?![\\w-])|\\byou'd(?![\\w-])|\\byou'll(?![\\w-])|\\byou're(?![\\w-])|\\byou've(?![\\w-])|\\byour(?![\\w-])|\\byours(?![\\w-])|\\byourself(?![\\w-])|\\byourselves(?![\\w-])|\\bz(?![\\w-])|\\bzero(?![\\w-])\",\nre.IGNORECASE|re.UNICODE)\"\"\"\n    # generate candidate keywords\n    phraseList = generate_candidate_keywords(sentenceList, stopwordpattern)\n    if debug: print('_________Phrases',phraseList)\n    # calculate individual word scores\n    wordscores = calculate_word_scores(phraseList)\n    if debug: print('_________wordscores',wordscores)\n    # generate candidate keyword scores\n    keywordcandidates = generate_candidate_keyword_scores(phraseList, wordscores)\n    if debug: print('_________keywcand',keywordcandidates)\n\n    sortedKeywords = sorted(keywordcandidates.items(), key=operator.itemgetter(1), reverse=True)\n    if debug: print('_________sorkeyw',sortedKeywords)\n\n    totalKeywords = len(sortedKeywords)\n    if debug: print('_________totalkeyw',totalKeywords)\n    print (sortedKeywords[0:int(totalKeywords / 3)])\n\n    #rake = Rake(\"E:/input/SmartStoplist.txt\")\n  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bbc8d4c4-5011-3000-3b09-15692af19d2e"},"outputs":[],"source":"# Implementation of RAKE - Rapid Automtic Keyword Exraction algorithm\n# as described in:\n# Rose, S., D. Engel, N. Cramer, and W. Cowley (2010). \n# Automatic keyword extraction from indi-vidual documents. \n# In M. W. Berry and J. Kogan (Eds.), Text Mining: Applications and Theory.unknown: John Wiley and Sons, Ltd.\n#\n# NOTE: The original code (from https://github.com/aneesha/RAKE)\n# has been extended by a_medelyan (zelandiya)\n# with a set of heuristics to decide whether a phrase is an acceptable candidate\n# as well as the ability to set frequency and phrase length parameters\n# important when dealing with longer documents\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nimport re\nimport operator\nimport six\nfrom six.moves import range\n\ndebug = True\ntest = True\n\n\nuri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))'\n\ndef stripTagsAndUris(x):\n    if x:\n        # BeautifulSoup on content\n        soup = BeautifulSoup(x, \"html.parser\")\n        # Stripping all <code> tags with their content if any\n        if soup.code:\n            soup.code.decompose()\n        # Get all the text out of the html\n        text =  soup.get_text()\n        # Returning text stripping out all uris\n        return re.sub(uri_re, \"\", text)\n    else:\n        return \"\"\n    \n\ndef is_number(s):\n    try:\n        float(s) if '.' in s else int(s)\n        return True\n    except ValueError:\n        return False\n\n\ndef load_stop_words(stop_word_file):\n    \"\"\"\n    Utility function to load stop words from a file and return as a list of words\n    @param stop_word_file Path and file name of a file containing stop words.\n    @return list A list of stop words.\n    \"\"\"\n    stop_words = []\n    for line in open(stop_word_file):\n        if line.strip()[0:1] != \"#\":\n            for word in line.split():  # in case more than one per line\n                stop_words.append(word)\n    return stop_words\n\n\ndef separate_words(text, min_word_return_size):\n    \"\"\"\n    Utility function to return a list of all words that are have a length greater than a specified number of characters.\n    @param text The text that must be split in to words.\n    @param min_word_return_size The minimum no of characters a word must have to be included.\n    \"\"\"\n    splitter = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n    words = []\n    for single_word in splitter.split(text):\n        current_word = single_word.strip().lower()\n        #leave numbers in phrase, but don't count as words, since they tend to invalidate scores of their phrases\n        if len(current_word) > min_word_return_size and current_word != '' and not is_number(current_word):\n            words.append(current_word)\n    return words\n\n\ndef split_sentences(text):\n    \"\"\"\n    Utility function to return a list of sentences.\n    @param text The text that must be split in to sentences.\n    \"\"\"\n    sentence_delimiters = re.compile(u'[.!?,;:\\t\\\\\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]|\\\\s\\\\-\\\\s')\n    sentences = sentence_delimiters.split(text)\n    return sentences\n\n\ndef build_stop_word_regex(stop_word_file_path):\n    stop_word_list = load_stop_words(stop_word_file_path)\n    stop_word_regex_list = []\n    for word in stop_word_list:\n        word_regex = '\\\\b' + word + '\\\\b'\n        stop_word_regex_list.append(word_regex)\n    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n    return stop_word_pattern\n\n\ndef generate_candidate_keywords(sentence_list, stopword_pattern, min_char_length=1, max_words_length=5):\n    phrase_list = []\n    for s in sentence_list:\n        tmp = re.sub(stopword_pattern, '|', s.strip())\n        phrases = tmp.split(\"|\")\n        for phrase in phrases:\n            phrase = phrase.strip().lower()\n            if phrase != \"\" and is_acceptable(phrase, min_char_length, max_words_length):\n                phrase_list.append(phrase)\n    return phrase_list\n\n\ndef is_acceptable(phrase, min_char_length, max_words_length):\n\n    # a phrase must have a min length in characters\n    if len(phrase) < min_char_length:\n        return 0\n\n    # a phrase must have a max number of words\n    words = phrase.split()\n    if len(words) > max_words_length:\n        return 0\n\n    digits = 0\n    alpha = 0\n    for i in range(0, len(phrase)):\n        if phrase[i].isdigit():\n            digits += 1\n        elif phrase[i].isalpha():\n            alpha += 1\n\n    # a phrase must have at least one alpha character\n    if alpha == 0:\n        return 0\n\n    # a phrase must have more alpha than digits characters\n    if digits > alpha:\n        return 0\n    return 1\n\n\ndef calculate_word_scores(phraseList):\n    word_frequency = {}\n    word_degree = {}\n    for phrase in phraseList:\n        word_list = separate_words(phrase, 0)\n        word_list_length = len(word_list)\n        word_list_degree = word_list_length - 1\n        #if word_list_degree > 3: word_list_degree = 3 #exp.\n        for word in word_list:\n            word_frequency.setdefault(word, 0)\n            word_frequency[word] += 1\n            word_degree.setdefault(word, 0)\n            word_degree[word] += word_list_degree  #orig.\n            #word_degree[word] += 1/(word_list_length*1.0) #exp.\n    for item in word_frequency:\n        word_degree[item] = word_degree[item] + word_frequency[item]\n\n    # Calculate Word scores = deg(w)/frew(w)\n    word_score = {}\n    for item in word_frequency:\n        word_score.setdefault(item, 0)\n        word_score[item] = word_degree[item] / (word_frequency[item] * 1.0)  #orig.\n    #word_score[item] = word_frequency[item]/(word_degree[item] * 1.0) #exp.\n    return word_score\n\n\ndef generate_candidate_keyword_scores(phrase_list, word_score, min_keyword_frequency=1):\n    keyword_candidates = {}\n\n    for phrase in phrase_list:\n        if min_keyword_frequency > 1:\n            if phrase_list.count(phrase) < min_keyword_frequency:\n                continue\n        keyword_candidates.setdefault(phrase, 0)\n        word_list = separate_words(phrase, 0)\n        candidate_score = 0\n        for word in word_list:\n            candidate_score += word_score[word]\n        keyword_candidates[phrase] = candidate_score\n    return keyword_candidates\n\n\nclass Rake(object):\n    def __init__(self, stop_words_path, min_char_length=1, max_words_length=5, min_keyword_frequency=1):\n        self.__stop_words_path = stop_words_path\n        self.__stop_words_pattern = build_stop_word_regex(stop_words_path)\n        self.__min_char_length = min_char_length\n        self.__max_words_length = max_words_length\n        self.__min_keyword_frequency = min_keyword_frequency\n\n    def run(self, text):\n        sentence_list = split_sentences(text)\n\n        phrase_list = generate_candidate_keywords(sentence_list, self.__stop_words_pattern, self.__min_char_length, self.__max_words_length)\n\n        word_scores = calculate_word_scores(phrase_list)\n\n        keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores, self.__min_keyword_frequency)\n\n        sorted_keywords = sorted(six.iteritems(keyword_candidates), key=operator.itemgetter(1), reverse=True)\n        return sorted_keywords\n\n\ndebug=True\nfor index, row in train_data.sample(2).iterrows():\n    print('____input',row[\"title\"], row[\"content\"] ,row['tags']   )\n    print('___content',stripTagsAndUris(row['content']))\n    sentenceList = split_sentences(row['title']+'. '+stripTagsAndUris(row['content']))\n    #stoppath = \"FoxStoplist.txt\" #Fox stoplist contains \"numbers\", so it will not find \"natural numbers\" like in Table 1.1\n    stoppath = \"SmartStoplist.txt\"  #SMART stoplist misses some of the lower-scoring keywords in Figure 1.5, which means that the top 1/3 cuts off one of the 4.0 score words in Table 1.1\n    #stopwordpattern = build_stop_word_regex(stoppath)\n    stopwordpattern= \"\"\"re.compile(r\"\\ba(?![\\w-])|\\ba's(?![\\w-])|\\bable(?![\\w-])|\\babout(?![\\w-])|\\babove(?![\\w-])|\\baccording(?![\\w-])|\\baccordingly(?![\\w-])|\\bacross(?![\\w-])|\\bactually(?![\\w-])|\\bafter(?![\\w-])|\\bafterwards(?![\\w-])|\\bagain(?![\\w-])|\\bagainst(?![\\w-])|\\bain't(?![\\w-])|\\ball(?![\\w-])|\\ballow(?![\\w-])|\\ballows(?![\\w-])|\\balmost(?![\\w-])|\\balone(?![\\w-])|\\balong(?![\\w-])|\\balready(?![\\w-])|\\balso(?![\\w-])|\\balthough(?![\\w-])|\\balways(?![\\w-])|\\bam(?![\\w-])|\\bamong(?![\\w-])|\\bamongst(?![\\w-])|\\ban(?![\\w-])|\\band(?![\\w-])|\\banother(?![\\w-])|\\bany(?![\\w-])|\\banybody(?![\\w-])|\\banyhow(?![\\w-])|\\banyone(?![\\w-])|\\banything(?![\\w-])|\\banyway(?![\\w-])|\\banyways(?![\\w-])|\\banywhere(?![\\w-])|\\bapart(?![\\w-])|\\bappear(?![\\w-])|\\bappreciate(?![\\w-])|\\bappropriate(?![\\w-])|\\bare(?![\\w-])|\\baren't(?![\\w-])|\\baround(?![\\w-])|\\bas(?![\\w-])|\\baside(?![\\w-])|\\bask(?![\\w-])|\\basking(?![\\w-])|\\bassociated(?![\\w-])|\\bat(?![\\w-])|\\bavailable(?![\\w-])|\\baway(?![\\w-])|\\bawfully(?![\\w-])|\\bb(?![\\w-])|\\bbe(?![\\w-])|\\bbecame(?![\\w-])|\\bbecause(?![\\w-])|\\bbecome(?![\\w-])|\\bbecomes(?![\\w-])|\\bbecoming(?![\\w-])|\\bbeen(?![\\w-])|\\bbefore(?![\\w-])|\\bbeforehand(?![\\w-])|\\bbehind(?![\\w-])|\\bbeing(?![\\w-])|\\bbelieve(?![\\w-])|\\bbelow(?![\\w-])|\\bbeside(?![\\w-])|\\bbesides(?![\\w-])|\\bbest(?![\\w-])|\\bbetter(?![\\w-])|\\bbetween(?![\\w-])|\\bbeyond(?![\\w-])|\\bboth(?![\\w-])|\\bbrief(?![\\w-])|\\bbut(?![\\w-])|\\bby(?![\\w-])|\\bc(?![\\w-])|\\bc'mon(?![\\w-])|\\bc's(?![\\w-])|\\bcame(?![\\w-])|\\bcan(?![\\w-])|\\bcan't(?![\\w-])|\\bcannot(?![\\w-])|\\bcant(?![\\w-])|\\bcause(?![\\w-])|\\bcauses(?![\\w-])|\\bcertain(?![\\w-])|\\bcertainly(?![\\w-])|\\bchanges(?![\\w-])|\\bclearly(?![\\w-])|\\bco(?![\\w-])|\\bcom(?![\\w-])|\\bcome(?![\\w-])|\\bcomes(?![\\w-])|\\bconcerning(?![\\w-])|\\bconsequently(?![\\w-])|\\bconsider(?![\\w-])|\\bconsidering(?![\\w-])|\\bcontain(?![\\w-])|\\bcontaining(?![\\w-])|\\bcontains(?![\\w-])|\\bcorresponding(?![\\w-])|\\bcould(?![\\w-])|\\bcouldn't(?![\\w-])|\\bcourse(?![\\w-])|\\bcurrently(?![\\w-])|\\bd(?![\\w-])|\\bdefinitely(?![\\w-])|\\bdescribed(?![\\w-])|\\bdespite(?![\\w-])|\\bdid(?![\\w-])|\\bdidn't(?![\\w-])|\\bdifferent(?![\\w-])|\\bdo(?![\\w-])|\\bdoes(?![\\w-])|\\bdoesn't(?![\\w-])|\\bdoing(?![\\w-])|\\bdon't(?![\\w-])|\\bdone(?![\\w-])|\\bdown(?![\\w-])|\\bdownwards(?![\\w-])|\\bduring(?![\\w-])|\\be(?![\\w-])|\\beach(?![\\w-])|\\bedu(?![\\w-])|\\beg(?![\\w-])|\\beight(?![\\w-])|\\beither(?![\\w-])|\\belse(?![\\w-])|\\belsewhere(?![\\w-])|\\benough(?![\\w-])|\\bentirely(?![\\w-])|\\bespecially(?![\\w-])|\\bet(?![\\w-])|\\betc(?![\\w-])|\\beven(?![\\w-])|\\bever(?![\\w-])|\\bevery(?![\\w-])|\\beverybody(?![\\w-])|\\beveryone(?![\\w-])|\\beverything(?![\\w-])|\\beverywhere(?![\\w-])|\\bex(?![\\w-])|\\bexactly(?![\\w-])|\\bexample(?![\\w-])|\\bexcept(?![\\w-])|\\bf(?![\\w-])|\\bfar(?![\\w-])|\\bfew(?![\\w-])|\\bfifth(?![\\w-])|\\bfirst(?![\\w-])|\\bfive(?![\\w-])|\\bfollowed(?![\\w-])|\\bfollowing(?![\\w-])|\\bfollows(?![\\w-])|\\bfor(?![\\w-])|\\bformer(?![\\w-])|\\bformerly(?![\\w-])|\\bforth(?![\\w-])|\\bfour(?![\\w-])|\\bfrom(?![\\w-])|\\bfurther(?![\\w-])|\\bfurthermore(?![\\w-])|\\bg(?![\\w-])|\\bget(?![\\w-])|\\bgets(?![\\w-])|\\bgetting(?![\\w-])|\\bgiven(?![\\w-])|\\bgives(?![\\w-])|\\bgo(?![\\w-])|\\bgoes(?![\\w-])|\\bgoing(?![\\w-])|\\bgone(?![\\w-])|\\bgot(?![\\w-])|\\bgotten(?![\\w-])|\\bgreetings(?![\\w-])|\\bh(?![\\w-])|\\bhad(?![\\w-])|\\bhadn't(?![\\w-])|\\bhappens(?![\\w-])|\\bhardly(?![\\w-])|\\bhas(?![\\w-])|\\bhasn't(?![\\w-])|\\bhave(?![\\w-])|\\bhaven't(?![\\w-])|\\bhaving(?![\\w-])|\\bhe(?![\\w-])|\\bhe's(?![\\w-])|\\bhello(?![\\w-])|\\bhelp(?![\\w-])|\\bhence(?![\\w-])|\\bher(?![\\w-])|\\bhere(?![\\w-])|\\bhere's(?![\\w-])|\\bhereafter(?![\\w-])|\\bhereby(?![\\w-])|\\bherein(?![\\w-])|\\bhereupon(?![\\w-])|\\bhers(?![\\w-])|\\bherself(?![\\w-])|\\bhi(?![\\w-])|\\bhim(?![\\w-])|\\bhimself(?![\\w-])|\\bhis(?![\\w-])|\\bhither(?![\\w-])|\\bhopefully(?![\\w-])|\\bhow(?![\\w-])|\\bhowbeit(?![\\w-])|\\bhowever(?![\\w-])|\\bi(?![\\w-])|\\bi'd(?![\\w-])|\\bi'll(?![\\w-])|\\bi'm(?![\\w-])|\\bi've(?![\\w-])|\\bie(?![\\w-])|\\bif(?![\\w-])|\\bignored(?![\\w-])|\\bimmediate(?![\\w-])|\\bin(?![\\w-])|\\binasmuch(?![\\w-])|\\binc(?![\\w-])|\\bindeed(?![\\w-])|\\bindicate(?![\\w-])|\\bindicated(?![\\w-])|\\bindicates(?![\\w-])|\\binner(?![\\w-])|\\binsofar(?![\\w-])|\\binstead(?![\\w-])|\\binto(?![\\w-])|\\binward(?![\\w-])|\\bis(?![\\w-])|\\bisn't(?![\\w-])|\\bit(?![\\w-])|\\bit'd(?![\\w-])|\\bit'll(?![\\w-])|\\bit's(?![\\w-])|\\bits(?![\\w-])|\\bitself(?![\\w-])|\\bj(?![\\w-])|\\bjust(?![\\w-])|\\bk(?![\\w-])|\\bkeep(?![\\w-])|\\bkeeps(?![\\w-])|\\bkept(?![\\w-])|\\bknow(?![\\w-])|\\bknows(?![\\w-])|\\bknown(?![\\w-])|\\bl(?![\\w-])|\\blast(?![\\w-])|\\blately(?![\\w-])|\\blater(?![\\w-])|\\blatter(?![\\w-])|\\blatterly(?![\\w-])|\\bleast(?![\\w-])|\\bless(?![\\w-])|\\blest(?![\\w-])|\\blet(?![\\w-])|\\blet's(?![\\w-])|\\blike(?![\\w-])|\\bliked(?![\\w-])|\\blikely(?![\\w-])|\\blittle(?![\\w-])|\\blook(?![\\w-])|\\blooking(?![\\w-])|\\blooks(?![\\w-])|\\bltd(?![\\w-])|\\bm(?![\\w-])|\\bmainly(?![\\w-])|\\bmany(?![\\w-])|\\bmay(?![\\w-])|\\bmaybe(?![\\w-])|\\bme(?![\\w-])|\\bmean(?![\\w-])|\\bmeanwhile(?![\\w-])|\\bmerely(?![\\w-])|\\bmight(?![\\w-])|\\bmore(?![\\w-])|\\bmoreover(?![\\w-])|\\bmost(?![\\w-])|\\bmostly(?![\\w-])|\\bmuch(?![\\w-])|\\bmust(?![\\w-])|\\bmy(?![\\w-])|\\bmyself(?![\\w-])|\\bn(?![\\w-])|\\bname(?![\\w-])|\\bnamely(?![\\w-])|\\bnd(?![\\w-])|\\bnear(?![\\w-])|\\bnearly(?![\\w-])|\\bnecessary(?![\\w-])|\\bneed(?![\\w-])|\\bneeds(?![\\w-])|\\bneither(?![\\w-])|\\bnever(?![\\w-])|\\bnevertheless(?![\\w-])|\\bnew(?![\\w-])|\\bnext(?![\\w-])|\\bnine(?![\\w-])|\\bno(?![\\w-])|\\bnobody(?![\\w-])|\\bnon(?![\\w-])|\\bnone(?![\\w-])|\\bnoone(?![\\w-])|\\bnor(?![\\w-])|\\bnormally(?![\\w-])|\\bnot(?![\\w-])|\\bnothing(?![\\w-])|\\bnovel(?![\\w-])|\\bnow(?![\\w-])|\\bnowhere(?![\\w-])|\\bo(?![\\w-])|\\bobviously(?![\\w-])|\\bof(?![\\w-])|\\boff(?![\\w-])|\\boften(?![\\w-])|\\boh(?![\\w-])|\\bok(?![\\w-])|\\bokay(?![\\w-])|\\bold(?![\\w-])|\\bon(?![\\w-])|\\bonce(?![\\w-])|\\bone(?![\\w-])|\\bones(?![\\w-])|\\bonly(?![\\w-])|\\bonto(?![\\w-])|\\bor(?![\\w-])|\\bother(?![\\w-])|\\bothers(?![\\w-])|\\botherwise(?![\\w-])|\\bought(?![\\w-])|\\bour(?![\\w-])|\\bours(?![\\w-])|\\bourselves(?![\\w-])|\\bout(?![\\w-])|\\boutside(?![\\w-])|\\bover(?![\\w-])|\\boverall(?![\\w-])|\\bown(?![\\w-])|\\bp(?![\\w-])|\\bparticular(?![\\w-])|\\bparticularly(?![\\w-])|\\bper(?![\\w-])|\\bperhaps(?![\\w-])|\\bplaced(?![\\w-])|\\bplease(?![\\w-])|\\bplus(?![\\w-])|\\bpossible(?![\\w-])|\\bpresumably(?![\\w-])|\\bprobably(?![\\w-])|\\bprovides(?![\\w-])|\\bq(?![\\w-])|\\bque(?![\\w-])|\\bquite(?![\\w-])|\\bqv(?![\\w-])|\\br(?![\\w-])|\\brather(?![\\w-])|\\brd(?![\\w-])|\\bre(?![\\w-])|\\breally(?![\\w-])|\\breasonably(?![\\w-])|\\bregarding(?![\\w-])|\\bregardless(?![\\w-])|\\bregards(?![\\w-])|\\brelatively(?![\\w-])|\\brespectively(?![\\w-])|\\bright(?![\\w-])|\\bs(?![\\w-])|\\bsaid(?![\\w-])|\\bsame(?![\\w-])|\\bsaw(?![\\w-])|\\bsay(?![\\w-])|\\bsaying(?![\\w-])|\\bsays(?![\\w-])|\\bsecond(?![\\w-])|\\bsecondly(?![\\w-])|\\bsee(?![\\w-])|\\bseeing(?![\\w-])|\\bseem(?![\\w-])|\\bseemed(?![\\w-])|\\bseeming(?![\\w-])|\\bseems(?![\\w-])|\\bseen(?![\\w-])|\\bself(?![\\w-])|\\bselves(?![\\w-])|\\bsensible(?![\\w-])|\\bsent(?![\\w-])|\\bserious(?![\\w-])|\\bseriously(?![\\w-])|\\bseven(?![\\w-])|\\bseveral(?![\\w-])|\\bshall(?![\\w-])|\\bshe(?![\\w-])|\\bshould(?![\\w-])|\\bshouldn't(?![\\w-])|\\bsince(?![\\w-])|\\bsix(?![\\w-])|\\bso(?![\\w-])|\\bsome(?![\\w-])|\\bsomebody(?![\\w-])|\\bsomehow(?![\\w-])|\\bsomeone(?![\\w-])|\\bsomething(?![\\w-])|\\bsometime(?![\\w-])|\\bsometimes(?![\\w-])|\\bsomewhat(?![\\w-])|\\bsomewhere(?![\\w-])|\\bsoon(?![\\w-])|\\bsorry(?![\\w-])|\\bspecified(?![\\w-])|\\bspecify(?![\\w-])|\\bspecifying(?![\\w-])|\\bstill(?![\\w-])|\\bsub(?![\\w-])|\\bsuch(?![\\w-])|\\bsup(?![\\w-])|\\bsure(?![\\w-])|\\bt(?![\\w-])|\\bt's(?![\\w-])|\\btake(?![\\w-])|\\btaken(?![\\w-])|\\btell(?![\\w-])|\\btends(?![\\w-])|\\bth(?![\\w-])|\\bthan(?![\\w-])|\\bthank(?![\\w-])|\\bthanks(?![\\w-])|\\bthanx(?![\\w-])|\\bthat(?![\\w-])|\\bthat's(?![\\w-])|\\bthats(?![\\w-])|\\bthe(?![\\w-])|\\btheir(?![\\w-])|\\btheirs(?![\\w-])|\\bthem(?![\\w-])|\\bthemselves(?![\\w-])|\\bthen(?![\\w-])|\\bthence(?![\\w-])|\\bthere(?![\\w-])|\\bthere's(?![\\w-])|\\bthereafter(?![\\w-])|\\bthereby(?![\\w-])|\\btherefore(?![\\w-])|\\btherein(?![\\w-])|\\btheres(?![\\w-])|\\bthereupon(?![\\w-])|\\bthese(?![\\w-])|\\bthey(?![\\w-])|\\bthey'd(?![\\w-])|\\bthey'll(?![\\w-])|\\bthey're(?![\\w-])|\\bthey've(?![\\w-])|\\bthink(?![\\w-])|\\bthird(?![\\w-])|\\bthis(?![\\w-])|\\bthorough(?![\\w-])|\\bthoroughly(?![\\w-])|\\bthose(?![\\w-])|\\bthough(?![\\w-])|\\bthree(?![\\w-])|\\bthrough(?![\\w-])|\\bthroughout(?![\\w-])|\\bthru(?![\\w-])|\\bthus(?![\\w-])|\\bto(?![\\w-])|\\btogether(?![\\w-])|\\btoo(?![\\w-])|\\btook(?![\\w-])|\\btoward(?![\\w-])|\\btowards(?![\\w-])|\\btried(?![\\w-])|\\btries(?![\\w-])|\\btruly(?![\\w-])|\\btry(?![\\w-])|\\btrying(?![\\w-])|\\btwice(?![\\w-])|\\btwo(?![\\w-])|\\bu(?![\\w-])|\\bun(?![\\w-])|\\bunder(?![\\w-])|\\bunfortunately(?![\\w-])|\\bunless(?![\\w-])|\\bunlikely(?![\\w-])|\\buntil(?![\\w-])|\\bunto(?![\\w-])|\\bup(?![\\w-])|\\bupon(?![\\w-])|\\bus(?![\\w-])|\\buse(?![\\w-])|\\bused(?![\\w-])|\\buseful(?![\\w-])|\\buses(?![\\w-])|\\busing(?![\\w-])|\\busually(?![\\w-])|\\buucp(?![\\w-])|\\bv(?![\\w-])|\\bvalue(?![\\w-])|\\bvarious(?![\\w-])|\\bvery(?![\\w-])|\\bvia(?![\\w-])|\\bviz(?![\\w-])|\\bvs(?![\\w-])|\\bw(?![\\w-])|\\bwant(?![\\w-])|\\bwants(?![\\w-])|\\bwas(?![\\w-])|\\bwasn't(?![\\w-])|\\bway(?![\\w-])|\\bwe(?![\\w-])|\\bwe'd(?![\\w-])|\\bwe'll(?![\\w-])|\\bwe're(?![\\w-])|\\bwe've(?![\\w-])|\\bwelcome(?![\\w-])|\\bwell(?![\\w-])|\\bwent(?![\\w-])|\\bwere(?![\\w-])|\\bweren't(?![\\w-])|\\bwhat(?![\\w-])|\\bwhat's(?![\\w-])|\\bwhatever(?![\\w-])|\\bwhen(?![\\w-])|\\bwhence(?![\\w-])|\\bwhenever(?![\\w-])|\\bwhere(?![\\w-])|\\bwhere's(?![\\w-])|\\bwhereafter(?![\\w-])|\\bwhereas(?![\\w-])|\\bwhereby(?![\\w-])|\\bwherein(?![\\w-])|\\bwhereupon(?![\\w-])|\\bwherever(?![\\w-])|\\bwhether(?![\\w-])|\\bwhich(?![\\w-])|\\bwhile(?![\\w-])|\\bwhither(?![\\w-])|\\bwho(?![\\w-])|\\bwho's(?![\\w-])|\\bwhoever(?![\\w-])|\\bwhole(?![\\w-])|\\bwhom(?![\\w-])|\\bwhose(?![\\w-])|\\bwhy(?![\\w-])|\\bwill(?![\\w-])|\\bwilling(?![\\w-])|\\bwish(?![\\w-])|\\bwith(?![\\w-])|\\bwithin(?![\\w-])|\\bwithout(?![\\w-])|\\bwon't(?![\\w-])|\\bwonder(?![\\w-])|\\bwould(?![\\w-])|\\bwould(?![\\w-])|\\bwouldn't(?![\\w-])|\\bx(?![\\w-])|\\by(?![\\w-])|\\byes(?![\\w-])|\\byet(?![\\w-])|\\byou(?![\\w-])|\\byou'd(?![\\w-])|\\byou'll(?![\\w-])|\\byou're(?![\\w-])|\\byou've(?![\\w-])|\\byour(?![\\w-])|\\byours(?![\\w-])|\\byourself(?![\\w-])|\\byourselves(?![\\w-])|\\bz(?![\\w-])|\\bzero(?![\\w-])\",\nre.IGNORECASE|re.UNICODE)\"\"\"\n\n    #stopwordpattern = build_stop_word_regex(stoppath)\n\n    # generate candidate keywords\n    phraseList = generate_candidate_keywords(sentenceList, stopwordpattern)\n    if debug: print('____prhas',phraseList)\n\n\n    # calculate individual word scores\n    wordscores = calculate_word_scores(phraseList)\n    if debug: print('____words',wordscores)\n\n\n    # generate candidate keyword scores\n    keywordcandidates = generate_candidate_keyword_scores(phraseList, wordscores)\n    if debug: print('____keyw',keywordcandidates)\n\n    sortedKeywords = sorted(six.iteritems(keywordcandidates), key=operator.itemgetter(1), reverse=True)\n    if debug: print('____sort',sortedKeywords)\n\n    totalKeywords = len(sortedKeywords)\n    if debug: print('____ total',totalKeywords)\n    print('____result',sortedKeywords[0:(totalKeywords // 3)])\n\n    #rake = Rake(\"SmartStoplist.txt\")\n    #keywords = rake.run(text)\n    #print(keywords)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"437553c3-56ec-928e-0bcf-1ec2012fe40f"},"outputs":[],"source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\ntfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, ngram_range=(1,2),stop_words='english')\n\nsample=train_data.sample(3)\nfor index, row in sample.iterrows():\n    print('____input',row[\"title\"], row[\"content\"] ,'<h1>',row['tags'],'</h1>'   )\n    data=row['title']+'. '+stripTagsAndUris(row['content'])\n    sample[index,'content']=data\n    \ntfidf = tfidf_vectorizer.fit_transform(sample['content'])\nprint(data_samples)\n\nprint(tfidf_vectorizer.vocabulary_)\nwords=pd.DataFrame.from_dict(tfidf_vectorizer.vocabulary_,orient='index')\nprint(words.sort_values(by=0,ascending=[0] ))\n#print(tfidf_vectorizer.idf_)\n#tfinv= tfidf_vectorizer.inverse_transform(tfidf)\n#print(tfinv)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}