{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom bayes_opt import BayesianOptimization\nimport lightgbm as lgb\nimport os, sys\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load data \ntrain = pd.read_csv('../input/bigquery-geotab-intersection-congestion/train.csv')\ntest = pd.read_csv('../input/bigquery-geotab-intersection-congestion/test.csv')\nsubmission = pd.read_csv('../input/bigquery-geotab-intersection-congestion/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style='color:blue;background:yellow'>Data Cleaning and Preprocessing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[\"City\"].unique())\nprint(test[\"City\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test.groupby([\"City\"]).apply(np.unique)\ntest.groupby([\"City\"]).nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <span style='color:blue;background:yellow'>**Fill NAs**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# def fill_na(df):\n#     df['ExitStreetName'] = df.apply(lambda x: x.EntryStreetName if type(x.ExitStreetName) != str else x.ExitStreetName, axis =1)\n#     df['EntryStreetName'] = df.apply(lambda x: x.ExitStreetName if type(x.EntryStreetName) != str else x.EntryStreetName, axis =1)\n#     df.fillna('ffill', inplace=True)\n#     return df\n# train = fill_na(train)\n# test = fill_na(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='color:blue;background:yellow'> Road Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"road_encoding = {\n\"Street\":0,\n \"St\":0,\n \"Avenue\":1,\n \"Ave\":1,\n \"Boulevard\":2,\n \"Road\":3,\n \"Drive\":4,\n \"Lane\":5,\n \"Tunnel\":6,\n \"Highway\":7,\n \"Way\":8,\n \"Parkway\":9,\n \"Parking\":10,\n \"Oval\":11,\n \"Square\":12,\n \"Place\":13,\n \"Bridge\":14}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode(x):\n    if pd.isna(x):\n        return 0\n    for road in road_encoding.keys():\n        if road in x:\n            return road_encoding[road]\n        \n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['EntryType'] = train['EntryStreetName'].apply(encode)\ntrain['ExitType'] = train['ExitStreetName'].apply(encode)\ntest['EntryType'] = test['EntryStreetName'].apply(encode)\ntest['ExitType'] = test['ExitStreetName'].apply(encode)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='color:blue;background:yellow'> add cordinal direction\n##### turn direction: \nThe cardinal directions can be expressed using the equation: $$ \\frac{\\theta}{\\pi} $$\n\nWhere $\\theta$ is the angle between the direction we want to encode and the north compass direction, measured clockwise.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"directions = {\n    'N': 0,\n    'NE': 1/4,\n    'E': 1/2,\n    'SE': 3/4,\n    'S': 1,\n    'SW': 5/4,\n    'W': 3/2,\n    'NW': 7/4\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['EntryHeading'] = train['EntryHeading'].map(directions)\ntrain['ExitHeading'] = train['ExitHeading'].map(directions)\n\ntest['EntryHeading'] = test['EntryHeading'].map(directions)\ntest['ExitHeading'] = test['ExitHeading'].map(directions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['diffHeading'] = train['EntryHeading']-train['ExitHeading']  \ntest['diffHeading'] = test['EntryHeading']-test['ExitHeading'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### <span style='color:blue;background:yellow'>entering street == exit street?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"same_street_exact\"] = (train[\"EntryStreetName\"] ==  train[\"ExitStreetName\"]).astype(int)\ntest[\"same_street_exact\"] = (test[\"EntryStreetName\"] ==  test[\"ExitStreetName\"]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='color:blue;background:yellow'>Make a new columns--> Intersection ID + City name"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Intersection\"] = train[\"IntersectionId\"].astype(str) + train[\"City\"]\ntest[\"Intersection\"] = test[\"IntersectionId\"].astype(str) + test[\"City\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(pd.concat([train[\"Intersection\"],test[\"Intersection\"]]).drop_duplicates().values)\ntrain[\"Intersection\"] = encoder.transform(train[\"Intersection\"])\ntest[\"Intersection\"] = encoder.transform(test[\"Intersection\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='color:blue;background:yellow'> Add temperature (Â°F) of each city by month </span>\n    \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_av = {'Atlanta1': 43, 'Atlanta5': 69, 'Atlanta6': 76, 'Atlanta7': 79, 'Atlanta8': 78, 'Atlanta9': 73,\n              'Atlanta10': 62, 'Atlanta11': 53, 'Atlanta12': 45, 'Boston1': 30, 'Boston5': 59, 'Boston6': 68,\n              'Boston7': 74, 'Boston8': 73, 'Boston9': 66, 'Boston10': 55,'Boston11': 45, 'Boston12': 35,\n              'Chicago1': 27, 'Chicago5': 60, 'Chicago6': 70, 'Chicago7': 76, 'Chicago8': 76, 'Chicago9': 68,\n              'Chicago10': 56,  'Chicago11': 45, 'Chicago12': 32, 'Philadelphia1': 35, 'Philadelphia5': 66,\n              'Philadelphia6': 76, 'Philadelphia7': 81, 'Philadelphia8': 79, 'Philadelphia9': 72, 'Philadelphia10': 60,\n              'Philadelphia11': 49, 'Philadelphia12': 40}\n# Concatenating the city and month into one variable\ntrain['city_month'] = train[\"City\"] + train[\"Month\"].astype(str)\ntest['city_month'] = test[\"City\"] + test[\"Month\"].astype(str)\n\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly temperature\ntrain[\"average_temp\"] = train['city_month'].map(monthly_av)\ntest[\"average_temp\"] = test['city_month'].map(monthly_av)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='color:blue;background:yellow'> Add climate data </span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_rainfall = {'Atlanta1': 5.02, 'Atlanta5': 3.95, 'Atlanta6': 3.63, 'Atlanta7': 5.12, 'Atlanta8': 3.67, 'Atlanta9': 4.09,\n              'Atlanta10': 3.11, 'Atlanta11': 4.10, 'Atlanta12': 3.82, 'Boston1': 3.92, 'Boston5': 3.24, 'Boston6': 3.22,\n              'Boston7': 3.06, 'Boston8': 3.37, 'Boston9': 3.47, 'Boston10': 3.79,'Boston11': 3.98, 'Boston12': 3.73,\n              'Chicago1': 1.75, 'Chicago5': 3.38, 'Chicago6': 3.63, 'Chicago7': 3.51, 'Chicago8': 4.62, 'Chicago9': 3.27,\n              'Chicago10': 2.71,  'Chicago11': 3.01, 'Chicago12': 2.43, 'Philadelphia1': 3.52, 'Philadelphia5': 3.88,\n              'Philadelphia6': 3.29, 'Philadelphia7': 4.39, 'Philadelphia8': 3.82, 'Philadelphia9':3.88 , 'Philadelphia10': 2.75,\n              'Philadelphia11': 3.16, 'Philadelphia12': 3.31}\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly rainfall\ntrain[\"average_rainfall\"] = train['city_month'].map(monthly_rainfall)\ntest[\"average_rainfall\"] = test['city_month'].map(monthly_rainfall)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_snowfall = {'Atlanta1': 0.6, 'Atlanta5': 0, 'Atlanta6': 0, 'Atlanta7': 0, 'Atlanta8': 0, 'Atlanta9': 0,\n              'Atlanta10': 0, 'Atlanta11': 0, 'Atlanta12': 0.2, 'Boston1': 12.9, 'Boston5': 0, 'Boston6': 0,\n              'Boston7': 0, 'Boston8': 0, 'Boston9': 0, 'Boston10': 0,'Boston11': 1.3, 'Boston12': 9.0,\n              'Chicago1': 11.5, 'Chicago5': 0, 'Chicago6': 0, 'Chicago7': 0, 'Chicago8': 0, 'Chicago9': 0,\n              'Chicago10': 0,  'Chicago11': 1.3, 'Chicago12': 8.7, 'Philadelphia1': 6.5, 'Philadelphia5': 0,\n              'Philadelphia6': 0, 'Philadelphia7': 0, 'Philadelphia8': 0, 'Philadelphia9':0 , 'Philadelphia10': 0,\n              'Philadelphia11': 0.3, 'Philadelphia12': 3.4}\n\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly snowfall\ntrain[\"average_snowfall\"] = train['city_month'].map(monthly_snowfall)\ntest[\"average_snowfall\"] = test['city_month'].map(monthly_snowfall)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_daylight = {'Atlanta1': 10, 'Atlanta5': 14, 'Atlanta6': 14, 'Atlanta7': 14, 'Atlanta8': 13, 'Atlanta9': 12,\n              'Atlanta10': 11, 'Atlanta11': 10, 'Atlanta12': 10, 'Boston1': 9, 'Boston5': 15, 'Boston6': 15,\n              'Boston7': 15, 'Boston8': 14, 'Boston9': 12, 'Boston10': 11,'Boston11': 10, 'Boston12': 9,\n              'Chicago1': 10, 'Chicago5': 15, 'Chicago6': 15, 'Chicago7': 15, 'Chicago8': 14, 'Chicago9': 12,\n              'Chicago10': 11,  'Chicago11': 10, 'Chicago12': 9, 'Philadelphia1': 10, 'Philadelphia5': 14,\n              'Philadelphia6': 15, 'Philadelphia7': 15, 'Philadelphia8': 14, 'Philadelphia9':12 , 'Philadelphia10': 11,\n              'Philadelphia11': 10, 'Philadelphia12': 9}\n\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly daylight\ntrain[\"average_daylight\"] = train['city_month'].map(monthly_daylight)\ntest[\"average_daylight\"] = test['city_month'].map(monthly_daylight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_sunsine = {'Atlanta1': 5.3, 'Atlanta5': 9.3, 'Atlanta6': 9.5, 'Atlanta7': 8.8, 'Atlanta8': 8.3, 'Atlanta9': 7.6,\n              'Atlanta10': 7.7, 'Atlanta11': 6.2, 'Atlanta12': 5.3, 'Boston1': 5.3, 'Boston5': 8.6, 'Boston6': 9.6,\n              'Boston7': 9.7, 'Boston8': 8.9, 'Boston9': 7.9, 'Boston10': 6.7,'Boston11': 4.8, 'Boston12': 4.6,\n              'Chicago1': 4.4, 'Chicago5': 9.1, 'Chicago6': 10.4, 'Chicago7': 10.3, 'Chicago8': 9.1, 'Chicago9': 7.6,\n              'Chicago10': 6.2,  'Chicago11': 3.6, 'Chicago12': 3.4, 'Philadelphia1': 5.0, 'Philadelphia5': 7.9,\n              'Philadelphia6': 9.0, 'Philadelphia7': 8.9, 'Philadelphia8': 8.4, 'Philadelphia9':7.9 , 'Philadelphia10': 6.6,\n              'Philadelphia11': 5.2, 'Philadelphia12': 4.4}\n\n# Creating a new column by mapping the city_month variable to it's corresponding average monthly sunsine\ntrain[\"average_sunsine\"] = train['city_month'].map(monthly_sunsine)\ntest[\"average_sunsine\"] = test['city_month'].map(monthly_sunsine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('city_month', axis=1, inplace=True)\ntest.drop('city_month', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='color:blue;background:yellow'> New feature --> is_day"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_day'] = train['Hour'].apply(lambda x: 1 if 5 < x < 20 else 0)\ntest['is_day'] = test['Hour'].apply(lambda x: 1 if 5 < x < 20 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style='color:blue;background:yellow'>  Distance from center of city"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_distance(df):\n    \n    df_center = pd.DataFrame({\"Atlanta\":[33.753746, -84.386330],\n                             \"Boston\":[42.361145, -71.057083],\n                             \"Chicago\":[41.881832, -87.623177],\n                             \"Philadelphia\":[39.952583, -75.165222]})\n    \n    df[\"CenterDistance\"] = df.apply(lambda row: math.sqrt((df_center[row.City][0] - row.Latitude) ** 2 +\n                                                          (df_center[row.City][1] - row.Longitude) ** 2) , axis=1)\n\nadd_distance(train)\nadd_distance(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* <span style='color:blue;background:yellow'>  HotEncoding of cities"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([train,pd.get_dummies(train[\"City\"],dummy_na=False, drop_first=False)],axis=1).drop([\"City\"],axis=1)\ntest = pd.concat([test,pd.get_dummies(test[\"City\"],dummy_na=False, drop_first=False)],axis=1).drop([\"City\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale Log and lat columns\nscaler = StandardScaler()\nfor col in ['Latitude','Longitude']:\n    scaler.fit(train[col].values.reshape(-1, 1))\n    train[col] = scaler.transform(train[col].values.reshape(-1, 1))\n    test[col] = scaler.transform(test[col].values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_road_id = train['RowId']\ntest_road_id = test['RowId']\npreds = train.iloc[:,12:27]\ntrain.drop(['RowId', 'Path','EntryStreetName','ExitStreetName'],axis=1, inplace=True)\ntest.drop(['RowId', 'Path','EntryStreetName','ExitStreetName'],axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(16,12))\nsns.heatmap(train.corr(), color ='BGR4R')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(preds.columns.tolist(), axis=1, inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target1 = preds['TotalTimeStopped_p20']\ntarget2 = preds['TotalTimeStopped_p50']\ntarget3 = preds['TotalTimeStopped_p80']\ntarget4 = preds['DistanceToFirstStop_p20']\ntarget5 = preds['DistanceToFirstStop_p50']\ntarget6 = preds['DistanceToFirstStop_p80']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feat = ['IntersectionId','Hour', 'Weekend','Month', 'same_street_exact', 'Intersection',\n       'Atlanta', 'Boston', 'Chicago', 'Philadelphia', 'EntryType', 'ExitType']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_preds ={0:[],1:[],2:[],3:[],4:[],5:[]}\nall_target = [target1, target2, target3, target4, target5, target6]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reference: https://medium.com/analytics-vidhya/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = lgb.Dataset(data=train, label=target3)\n\n# Objective Function\ndef hyp_lgbm(num_leaves, feature_fraction, bagging_fraction, max_depth, min_split_gain, min_child_weight, lambda_l1, lambda_l2):\n      \n        params = {'application':'regression','num_iterations': 450,\n                  'learning_rate':0.02,\n                  'metric':'rmse'} # Default parameters\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        params['min_split_gain'] = min_split_gain\n        params['min_child_weight'] = min_child_weight\n        params['lambda_l1'] = lambda_l1\n        params['lambda_l2'] = lambda_l2\n        \n        cv_results = lgb.cv(params, dtrain, nfold=5, seed=17,categorical_feature=cat_feat, stratified=False,\n                            verbose_eval =None)\n#         print(cv_results)\n        return -np.min(cv_results['rmse-mean'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Domain space-- Range of hyperparameters\npds = {'num_leaves': (120, 230),\n          'feature_fraction': (0.3, 0.9),\n          'bagging_fraction': (0.8, 1),\n           'lambda_l1': (0,3),\n           'lambda_l2': (0,5),\n          'max_depth': (8, 19),\n          'min_split_gain': (0.001, 0.1),\n          'min_child_weight': (1, 20)\n          }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Surrogate model\noptimizer = BayesianOptimization(hyp_lgbm,pds,random_state=7)\n                                  \n# Optimize\noptimizer.maximize(init_points=5, n_iter=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer.max","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = optimizer.max['params']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {'num_leaves': int(round(p['num_leaves'])),\n         'feature_fraction': p['feature_fraction'],\n         'bagging_fraction': p['bagging_fraction'],\n         'max_depth': int(round(p['max_depth'])),\n         'lambda_l1': p['lambda_l1'],\n         'lambda_l2': p['lambda_l2'],\n         'min_split_gain': p['min_split_gain'],\n         'min_child_weight': p['min_child_weight'],\n         'learning_rate':0.05,\n         'objective': 'regression',\n         'boosting_type': 'gbdt',\n         'verbose': 1,\n         'metric': 'rmse',\n         'seed': 7,\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnfold = 5\nkf = KFold(n_splits=nfold, random_state=227, shuffle=True)\nfor i in range(len(all_preds)):\n    print('Training and predicting for target {}'.format(i+1))\n    oof = np.zeros(len(train))\n    all_preds[i] = np.zeros(len(test))\n    n =1\n    for train_index, valid_index in kf.split(all_target[i]):\n        print(\"fold {}\".format(n))\n        xg_train = lgb.Dataset(train.iloc[train_index],\n                               label=all_target[i][train_index]\n                               )\n        xg_valid = lgb.Dataset(train.iloc[valid_index],\n                               label=all_target[i][valid_index]\n                               )   \n\n        clf = lgb.train(param, xg_train, 15000, valid_sets=[xg_valid],categorical_feature=cat_feat\n                        , verbose_eval=200, early_stopping_rounds=500)\n        oof[valid_index] = clf.predict(train.iloc[valid_index], num_iteration=clf.best_iteration) \n\n        all_preds[i] += clf.predict(test, num_iteration=clf.best_iteration) / nfold\n        n = n + 1\n\n    print(\"\\n\\nCV RMSE: {:<0.4f}\".format(np.sqrt(mean_squared_error(all_target[i], oof))))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = pd.DataFrame(all_preds).stack()\ndata2 = pd.DataFrame(data2)\nsubmission['Target'] = data2[0].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<center><span style='color:blue;background:yellow;font-size:30px'>**Please upvote this notebook if you like my work. **"},{"metadata":{},"cell_type":"markdown","source":"**References:**\n1. https://www.kaggle.com/whatust/fork-of-kernel56e53f4445\n2. https://www.kaggle.com/brokenfulcrum/geotab-baseline\n3. https://www.kaggle.com/danofer/baseline-feature-engineering-geotab-69-5-lb\n4.  https://www.kaggle.com/bgmello/how-one-percentile-affect-the-others"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}