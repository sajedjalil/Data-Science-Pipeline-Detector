{"cells":[{"metadata":{"_uuid":"0cc4e92cc4b55d20f1fcc60bb2ed532f6aca6486"},"cell_type":"markdown","source":"There are many different method's to select the important features from a dataset. In this notebook I will show a quick way to select important features with the use of Boruta.\n\nBoruta tries to find all relevant features that carry information to make an accurate classification. You can read more about Boruta [here](http://danielhomola.com/2015/05/08/borutapy-an-all-relevant-feature-selection-method/)\n\nLet's start by doing all necessary imports."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.ensemble import RandomForestClassifier\nfrom boruta import BorutaPy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec828ecdd72e9db30693401e02a6505e398c37c2"},"cell_type":"markdown","source":"Next we load only the 'application_train' data as this is to demonstrate Boruta only. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"train = pd.read_csv(\"../input/application_train.csv\")\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c0d804c6e7e68c9d04b52f30466454b95542f8f"},"cell_type":"markdown","source":"All categorical values will be one-hot encoded."},{"metadata":{"trusted":true,"_uuid":"93cb173855027664447e440cb86c4773e46a439e"},"cell_type":"code","source":"train = pd.get_dummies(train, drop_first=True, dummy_na=True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41c4522d63eb5d0df62c8fa3e166d504ba2473d6"},"cell_type":"markdown","source":"Get all feature names from the dataset"},{"metadata":{"trusted":true,"_uuid":"6146759b7e93ad38630ebfbb5286ebe4b61de6f6"},"cell_type":"code","source":"features = [f for f in train.columns if f not in ['TARGET','SK_ID_CURR']]\nlen(features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"165c21232b569be72098d6b95336233b492ade3a"},"cell_type":"markdown","source":"Replace all missing values with the Mean."},{"metadata":{"trusted":true,"_uuid":"83b4018f12d2280031cd72921963f33260233ba9"},"cell_type":"code","source":"train[features] = train[features].fillna(train[features].mean()).clip(-1e9,1e9)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81b5dedd4e74a12fb1eb715f789db6a3f43aeb8e"},"cell_type":"markdown","source":"Get the final dataset *X* and labels *Y*"},{"metadata":{"trusted":true,"_uuid":"8f9ae078324f516837c4d5e920a308f2a05d75c7"},"cell_type":"code","source":"X = train[features].values\nY = train['TARGET'].values.ravel()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afb29960c5daa71b8bae15ef462de2de99a058a9"},"cell_type":"markdown","source":"Next we setup the *RandomForrestClassifier* as the estimator to use for Boruta. The *max_depth* of the tree is advised on the Boruta Github page to be between 3 to 7."},{"metadata":{"trusted":true,"_uuid":"d9be9c2d15e228658017865d15f261f1e18e3f23"},"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efb5dde4c2018f209de9dfd0afcd77c3fa8999cb"},"cell_type":"markdown","source":"Next we setup Boruta. It uses the *scikit-learn* interface as much as possible so we can use *fit(X, y), transform(X), fit_transform(X, y)*. I'll let it run for a maximum of *max_iter = 50* iterations. With *perc = 90* a threshold is specified. The lower the threshold the more features will be selected. I usually use a percentage between 80 and 90. "},{"metadata":{"trusted":true,"_uuid":"613175f06ad987527513455ce911ddb7212fb70a"},"cell_type":"code","source":"boruta_feature_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=4242, max_iter = 50, perc = 90)\nboruta_feature_selector.fit(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ab0a855065ebdf857bf9cd605c3c4feaa03f1ce"},"cell_type":"markdown","source":"After Boruta has run we can transform our dataset."},{"metadata":{"trusted":true,"_uuid":"a9cec04cba85457a85164ccacc55fba4e05cbd9c"},"cell_type":"code","source":"X_filtered = boruta_feature_selector.transform(X)\nX_filtered.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9352719a4f7a56ca9741c2f99662aa85fa0f936e"},"cell_type":"markdown","source":"And we create a list of the feature names if we would like to use them at a later stage."},{"metadata":{"trusted":true,"_uuid":"d92229aaf6b15451c538985ed3e4f5f9dd25b33b"},"cell_type":"code","source":"final_features = list()\nindexes = np.where(boruta_feature_selector.support_ == True)\nfor x in np.nditer(indexes):\n    final_features.append(features[x])\nprint(final_features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b2efffc66d89b8ad7deb2d9c0008720e1672498"},"cell_type":"markdown","source":"So I hope you enjoyed my very first Kaggle Kernel :-)\nLet me know if you have any feedback or suggestions."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}