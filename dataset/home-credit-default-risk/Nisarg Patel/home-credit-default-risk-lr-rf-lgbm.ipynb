{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# python 3 ### Input data files are available in the \"../input/\" directory.\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport seaborn as sns\nimport warnings\nimport matplotlib\nimport matplotlib.pyplot as plt # for plotting\n%matplotlib inline\ncolor = sns.color_palette()\nwarnings.filterwarnings('ignore') # Suppress warnings \nfrom sklearn.metrics import roc_curve ## for roc curve\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4621378fd598cb853970d9fa756ec8fd417e4e74"},"cell_type":"markdown","source":"## Problem Statement\nIn this study, we will attempt to solve the following problem statement is: \nCan we predict how capable each applicant is of repaying a loan? \n\nThe objective of this competition is to use historical loan application data to predict whether or not an applicant will be able to repay a loan. This is a standard supervised classification problem where the label is a binary variable, 0 (will repay loan on time), 1 (will have difficulty repaying loan).   \nIn this study, our target variable Y is the probability associated with the lender paying back their loan. Therefore, this is a regression supervised learning problem."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"app_train = pd.read_csv(\"../input/application_train.csv\")\napp_test = pd.read_csv(\"../input/application_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"114b5fdd0b34adf61a141226c22f946e24539355"},"cell_type":"code","source":"data_train = app_train.copy()\ndata_test = app_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17ee3a6c01d4fb80407e0074204c021349d0c393"},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true,"_uuid":"31bea7114b1dd204312124ca39548e494b680d18"},"cell_type":"code","source":"data_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5409f0587e4b92384f6edf2bac705c559a873ce8","scrolled":true},"cell_type":"code","source":"data_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfd48aaa17fd9da9abfb9f2cc8dc4606908f9182"},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"502b76eec88dedf94d4f16384e92f6d6b004f401"},"cell_type":"code","source":"data_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04b02dd9f506ac8adad00188e5151f5317bf9ca4"},"cell_type":"markdown","source":"The training set contains 122 features, including the 'TARGET' variable. The testing set contains the same features minus the Target variable ['TARGET'].  \nFrom an initial look at the 121 features, I intuitively identified 42 variables that I believe would have a non-negligible influence (or correlation) with the ability of a borrower to repay their loan. However, all features will be kept in the dataframe at this initial stage. "},{"metadata":{"_uuid":"8a1f5d326a28a3011502ab98bb9e8a18a1367281"},"cell_type":"markdown","source":"#####  Although not part of this study, an example of an 'inner left join' using Python on key 'SK_ID_BUREAU' is shown below.We might use it later on if possible."},{"metadata":{"trusted":true,"_uuid":"9092220904582c83a488d5dc37daf3ccadee2a8f"},"cell_type":"code","source":"# importing the datasets into Pandas dataframes\nbureau_balance = pd.read_csv('../input//bureau_balance.csv')\nbureau = pd.read_csv('../input//bureau.csv')\n# left joining the dataset on='SK_ID_BUREAU'(left=bureau, right=bureau_balance)\ndf_bureau_joined = bureau.merge(bureau_balance, \n                                on='SK_ID_BUREAU', \n                                how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d145ffb6b5a5ba060970aec9fb0ffd8c74af585"},"cell_type":"code","source":"df_bureau_joined.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cb72d771e252d2541cb411ab42df53f9b5ba985"},"cell_type":"markdown","source":"## Exploratory Visualization "},{"metadata":{"trusted":true,"_uuid":"2cf38b9ee3603718e63cad462f64359a438515b3"},"cell_type":"code","source":"target = data_train['TARGET']\ntarget.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c74373b0b483669afd701c8d8a718748571142c"},"cell_type":"markdown","source":"Plotting the target values.   \n1) plotting target variable's count.   \n2) plotting target variable w.r.t contract type.  "},{"metadata":{"trusted":true,"_uuid":"ddb47f79ee570d0db76f1135ce1327ba2ff45845"},"cell_type":"code","source":"def plot_count_distribution(df,col_name):\n    #define order of bars\n    order = list(df[col_name].value_counts().index)\n    plt.figure(figsize=(5,4))\n    ax = sns.countplot(x=col_name,data=df)\n    plt.title('Target Variable Distribution (Training Dataset)')\n    plt.xlabel('Target')\n    plt.ylabel('Counts')\n\n    #include count labels on top of each bar\n    for p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()),(p.get_x()+0.1,p.get_height()+10))\n    plt.show()\n\nplot_count_distribution(data_train,'TARGET')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96d5afd626a850d31426669f5baabadddb38ab63"},"cell_type":"code","source":"# Count Plot (a.k.a. Bar Plot)\nplt.figure(figsize=(10,5))\nplt.ylabel('Count')\nplt.title('Contract Types by Target Value')\nbar_plot = sns.countplot(x='NAME_CONTRACT_TYPE', hue='TARGET', data=data_train)\nfor p in bar_plot.patches:\n        bar_plot.annotate('{:.0f}'.format(p.get_height()),(p.get_x()+0.1,p.get_height()+10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a99db9e7bd0084d9f37f55fd0829d05fcc293bb"},"cell_type":"markdown","source":"Age might be the features that has great effect on repaying the loan. We will plot some visulization using age as factor for target variable."},{"metadata":{"trusted":true,"_uuid":"17622a89333e091cf8f8619c068135eb0667d563"},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.style.use('seaborn-colorblind')\nplt.grid(True, alpha=0.5)\nsns.kdeplot(data_train.loc[data_train['TARGET'] == 0, 'DAYS_BIRTH'] / -365, label = 'Repaid Loan')\nsns.kdeplot(data_train.loc[data_train['TARGET'] == 1, 'DAYS_BIRTH'] / -365, label = 'Not Repaid Loan')\nplt.xlabel('Age (years)')\nplt.ylabel('Density')\nplt.title('Distribution of Age of Client (in Years)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf5a630962094023ed92fd62a553ea36a3c14487"},"cell_type":"code","source":"# Age information into a separate dataframe\nage_data = data_train[['TARGET', 'DAYS_BIRTH']]\nage_data['YEARS_BIRTH'] = age_data.loc[:,'DAYS_BIRTH'].copy() / -365\nage_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\n# Group by the bin and calculate averages\nage_groups  = age_data.groupby('YEARS_BINNED').mean()\nage_groups.drop(['DAYS_BIRTH'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"097f1ee6fc9be72f1d34f9be4b37d61fbc801d84","scrolled":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.style.use('seaborn-colorblind')\nplt.grid(True, alpha=0.5)\nplt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'])\nplt.xticks(rotation = 75)\nplt.xlabel('Age Group (years)')\nplt.ylabel('Failure to Repay (%)')\nplt.title('Failure to Repay by Client\\'s Age Range');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a872dfd792621c7e7c87da6444f3110a03a013dd"},"cell_type":"code","source":"plt.figure(figsize=(14,5))\nplt.style.use('seaborn-colorblind')\nplt.grid(True, alpha=0.5)\nsns.kdeplot(data_train.loc[data_train['TARGET'] == 0, 'AMT_CREDIT'], \n            label = 'Repaid Loan')\nsns.kdeplot(data_train.loc[data_train['TARGET'] == 1, 'AMT_CREDIT'], \n            label = 'Not Repaid Loan')\nplt.xlabel('Amount of Credit')\nplt.xticks(np.arange(0, 5000000, 500000))\nplt.ylabel('Density')\nplt.title('Distribution of Amount of Credit by Target Value');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cda4c5c1da99717058bfd14c374cb7f6ed7d53dc"},"cell_type":"markdown","source":"## Examine Missing Values\nNext we can look at the number and percentage of missing values in each column."},{"metadata":{"trusted":true,"_uuid":"f91dcf6285ca3cb18d69172a307a9210849e017e"},"cell_type":"code","source":"# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fdd2735acc3b0e35dd608c5dab69a49da5fffd9","scrolled":true},"cell_type":"code","source":"# Missing values statistics\nmissing_values = missing_values_table(app_train)\nmissing_values.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4537f0b7fe2ec9f562ac13ffc628b5ead3ae84cd","scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59e0c4d6226f18a75ccb29726cfab113975c161b"},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.style.use('seaborn-colorblind')\nplt.grid(True, alpha=0.5)\nx = missing_values['% of Total Values']\nx.hist(align='left', bins= 50)\nplt.xticks(np.arange(0, 75, 5))\nplt.xlabel('% of Missing Values')\nplt.yticks(np.arange(0, 12, 2))\nplt.ylabel('Count (Features)')\nplt.title('Distribution of % of Missing Values in Dataset Features');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dee6a175984dddf7f10f445219b060f85c8aba9"},"cell_type":"code","source":"app_train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e15489c4fd24c71d525ddd094935eac04a215cbe","scrolled":true},"cell_type":"code","source":"# Number of unique classes in each object column\napp_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9113d4dc7953fcb45bbe54effb2ca828d62a9d70"},"cell_type":"markdown","source":"## Correlation"},{"metadata":{"trusted":true,"_uuid":"c3ec9f41e6736e80261b784e4d63027c21a4960c"},"cell_type":"code","source":"# Find correlations with the target and sort\ncorrelations = data_train.corr()['TARGET'].sort_values()\nprint('Most Positive Correlations: \\n', correlations.tail(15))\nprint('\\nMost Negative Correlations: \\n', correlations.head(15))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70e029fbd7b61006ec31b4a474a995af03536259"},"cell_type":"markdown","source":"## Label Encoding and One Hot Encoding"},{"metadata":{"trusted":true,"_uuid":"93c290b1946f9edbf6645a53641bbe20d0751ba7"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# Create a label encoder object\nle = LabelEncoder()\nle_count = 0\n\n# Iterate through the columns\nfor col in data_train:\n    if data_train[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        if len(list(data_train[col].unique())) <= 2:\n            # Train on the training data\n            le.fit(data_train[col])\n            # Transform both training and testing data\n            data_train[col] = le.transform(data_train[col])\n            data_test[col] = le.transform(data_test[col])\n            \n            # Keep track of how many columns were label encoded\n            le_count += 1\n            \nprint('%d columns were label encoded.' % le_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ef9d05cbcbc1de73bcc02443e6935cfad1d4177"},"cell_type":"code","source":"# one-hot encoding of categorical variables\ndf_train = pd.get_dummies(data_train)\ndf_test = pd.get_dummies(data_test)\n\nprint('Training Features shape for df_train: ', df_train.shape)\nprint('Testing Features shape for df_test: ', df_test.shape)\nprint('Training Features shape for data_train: ', data_train.shape)\nprint('Testing Features shape for data_test: ', data_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdc99708ac7e75ffc82080d0c9eeb1dcfc6e0abe"},"cell_type":"code","source":"train_labels = df_train['TARGET']\n\n# Align the training and testing data, keep only columns present in both dataframes\ndf_train, df_test = df_train.align(df_test, join = 'inner', axis = 1)\n\n# Add the target back in\ndf_train['TARGET'] = train_labels\n\nprint('Training Features shape: ', df_train.shape)\nprint('Testing Features shape: ', df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"fd1b1c6bc925c409b1c5125f08b6cbc07a7f9f70"},"cell_type":"code","source":"data_train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1329dbaf778fc0857cda9b8c5035e0c0343d86ce"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57ff44cd1f266f430111af4edc3851baaedfbbf4"},"cell_type":"markdown","source":"## Normalize the data"},{"metadata":{"trusted":true,"_uuid":"a2518ea2a7ee8928b837de843022ea547e7209fa"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, Imputer\n\n# Drop the target from the training data\nif 'TARGET' in df_train:\n    train = df_train.drop(columns = ['TARGET'])\nelse:\n    train = df_train.copy()\n    \n# Feature names\nfeatures = list(train.columns)\n\n# Copy of the testing data\ntest = df_test.copy()\n\n# Median imputation of missing values\nimputer = Imputer(strategy = 'median')\n\n# Scale each feature to 0-1\nscaler = MinMaxScaler(feature_range = (0, 1))\n\n# Fit on the training data\nimputer.fit(train)\n\n# Transform both training and testing data\ntrain = imputer.transform(train)\ntest = imputer.transform(df_test)\n\n# Repeat with the scaler\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\n\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85f1c0d6b7355ac182e64318f64731cd29622503"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"026e81020e1c0c5db5c40241f8922e117e0dc435"},"cell_type":"markdown","source":"# Baseline"},{"metadata":{"_uuid":"9aef29ccbc0d5b95b1ef731b6b95f22692e0cb6d"},"cell_type":"markdown","source":"## Building base line model for accuracy using Random Forest\n* Random Forest is a supervised learning algorithm. Like you can already see from it’s name, it creates a forest and makes it somehow random. The „forest“ it builds, is an ensemble of Decision Trees, most of the time trained with the “bagging” method. The general idea of the bagging method is that a combination of learning models increases the overall result."},{"metadata":{"trusted":true,"_uuid":"bb118a2784d24ff8b3d7c7fa7bf3dded3c941cba"},"cell_type":"markdown","source":"Let's build the random forest classifer as the base model on raw data to check how it performs."},{"metadata":{"trusted":true,"_uuid":"e64a5ff1f69e1079b43eb46bbca2a77c92d11201"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"694cbb1fded3346a55dff690f9f767d483bc2cc0"},"cell_type":"code","source":"# Make the random forest classifier\nrandom_forest = RandomForestClassifier(n_estimators = 100, \n                                       random_state = 50, \n                                       verbose = 1, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"081a75c857fc43e8cda136276a324710dede5f6f"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# 70% training and 30% test\nX_train, X_test, y_train, y_test = train_test_split(train, train_labels, test_size=0.3, stratify =train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a311de7f2000aa506faf588c0d6d157a1ee026c3"},"cell_type":"code","source":"# Train on the training data\nrandom_forest.fit(X_train, y_train)\n\n# Extract feature importances\nfeature_importance_values = random_forest.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features,\n                                    'importance': feature_importance_values})\n\n# Make predictions on the test data\npredictions_val = random_forest.predict_proba(X_test)[:, 1]\n#predictions_test = random_forest.predict(test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d2d6b41167d055c3e00612468425deac4c9862e"},"cell_type":"code","source":"predictions_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc1beeaa7ec3492f58fd19d2668d3b4bc7420bee"},"cell_type":"code","source":"from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\n#print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d7a056f51e332a2c8aaf407766ceaad6870192a"},"cell_type":"code","source":"from sklearn.metrics import auc\nfpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, predictions_val)\nauc_rf = auc(fpr_rf, tpr_rf)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1afde03682590feaa6d57b7ef13cdb4ed2166790"},"cell_type":"code","source":"# Train on the training data\nrandom_forest.fit(train, train_labels)\n\n# Extract feature importances\nfeature_importance_values = random_forest.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, \n                                    'importance': feature_importance_values})\n\n# Make predictions on the test data\npredictions_test = random_forest.predict_proba(test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15e3116c70995f12947b1687870dd0736e3a546b"},"cell_type":"code","source":"plot_test = df_test[['SK_ID_CURR','EXT_SOURCE_2','EXT_SOURCE_3']]\nplot_test['TARGET'] = predictions_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43e274dcbd14e798520252d452878cd74c304eca"},"cell_type":"code","source":"#plot_predict_interaction(random_forest, plot_test, \"rm\", \"EX\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37d8d5fddc19500fd26e33837c4108491e8607fa"},"cell_type":"code","source":"# Make a submission dataframe\nsubmit = df_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions_test\n\n# Save the submission dataframe\nsubmit.to_csv('random_forest_baseline.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"623bf5f400a01a356830d66229226eda3f1d6e71"},"cell_type":"markdown","source":"### Model Importance in Random Forest"},{"metadata":{"trusted":true,"_uuid":"396aa549034af6c7d8c5706f7450afd7dbc81de4"},"cell_type":"code","source":"def plot_feature_importances(df):\n    \"\"\"shows a plot of the 15 most importance features\"\"\"\n    \n    # Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    # Normalize the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    # Make a horizontal bar chart of feature importances\n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    \n    # Need to reverse the index to plot most important on top\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    # Set the yticks and labels\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    # Plot labeling\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2abc90e7300038ece9a7e127cef413e8e62e9cff"},"cell_type":"code","source":"# Show the feature importances for the default features\nfeature_importances_sorted = plot_feature_importances(feature_importances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"709a6bc441f4a61c40b999650e23aa0dc779a678"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40b554a8200a419827511e5acff0a527449a35cf"},"cell_type":"markdown","source":"## Light GBM"},{"metadata":{"trusted":true,"_uuid":"1dff4190d3a043258984881264758efb50443ec8"},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport gc\n\ndef model(features, test_features, encoding = 'ohe', n_folds = 5):  \n    \"\"\"\n    Parameters\n    --------\n        features (pd.DataFrame): \n            dataframe of training features to use \n            for training a model. Must include the TARGET column.\n        test_features (pd.DataFrame): \n            dataframe of testing features to use\n            for making predictions with the model. \n        encoding (str, default = 'ohe'): \n            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n            n_folds (int, default = 5): number of folds to use for cross validation\n        \n    Return\n    --------\n        submission (pd.DataFrame): \n            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n            predicted by the model.\n        feature_importances (pd.DataFrame): \n            dataframe with the feature importances from the model.\n        valid_metrics (pd.DataFrame): \n            dataframe with training and validation metrics (ROC AUC) for each fold and overall.        \n    \"\"\"\n    \n    # Extract the ids\n    train_ids = features['SK_ID_CURR']\n    test_ids = test_features['SK_ID_CURR']\n    # Extract the labels for training\n    labels = features['TARGET']\n    \n    # Remove the ids and target\n    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n    \n    \n    # One Hot Encoding\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        \n        # Align the dataframes by the columns\n        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n        \n        # No categorical indices to record\n        cat_indices = 'auto'\n    \n    # Integer label encoding\n    elif encoding == 'le':\n        \n        # Create a label encoder\n        label_encoder = LabelEncoder()\n        \n        # List for storing categorical indices\n        cat_indices = []\n        \n        # Iterate through each column\n        for i, col in enumerate(features):\n            if features[col].dtype == 'object':\n                # Map the categorical features to integers\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n\n                # Record the categorical indices\n                cat_indices.append(i)\n    \n    # Catch error if label encoding scheme is not valid\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n        \n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    \n    # Extract feature names\n    feature_names = list(features.columns)\n    \n    # Convert to np arrays\n    features = np.array(features)\n    test_features = np.array(test_features)\n    \n    # Create the kfold object\n    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n    \n    # Empty array for feature importances\n    feature_importance_values = np.zeros(len(feature_names))\n    \n    # Empty array for test predictions\n    test_predictions = np.zeros(test_features.shape[0])\n    \n    # Empty array for out of fold validation predictions\n    out_of_fold = np.zeros(features.shape[0])\n    \n    # Lists for recording validation and training scores\n    valid_scores = []\n    train_scores = []\n    \n    # Iterate through each fold\n    for train_indices, valid_indices in k_fold.split(features):\n        \n        # Training data for the fold\n        train_features, train_labels = features[train_indices], labels[train_indices]\n        # Validation data for the fold\n        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n        \n        # Create the model\n        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n                                   class_weight = 'balanced', learning_rate = 0.05, \n                                   reg_alpha = 0.1, reg_lambda = 0.1, \n                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n        \n        # Train the model\n        model.fit(train_features, train_labels, eval_metric = 'auc',\n                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n                  early_stopping_rounds = 100, verbose = 200)\n        \n        # Record the best iteration\n        best_iteration = model.best_iteration_\n        \n        # Record the feature importances\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        \n        # Make predictions\n        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n        \n        # Record the out of fold predictions\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n        \n        # Record the best score\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        \n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        \n        # Clean up memory\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n        \n    # Make the submission dataframe\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    \n    # Make the feature importance dataframe\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    \n    # Overall validation score\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    \n    # Add the overall scores to the metrics\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    \n    # Needed for creating dataframe of validation scores\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    \n    # Dataframe of validation scores\n    metrics = pd.DataFrame({'fold': fold_names,\n                            'train': train_scores,\n                            'valid': valid_scores}) \n    \n    return submission, feature_importances, metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8e46835837f49925d8818dbbd3d3183bf1e5e95"},"cell_type":"code","source":"submission, fi, metrics = model(df_train, df_test)\nprint('Baseline metrics')\nprint(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61b422a389874e74b3c5c72d91a0e3f40b6c8c6b"},"cell_type":"code","source":"fi_sorted = plot_feature_importances(fi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a618fd82dbde90a2ea9d4f8b9f9ed7aa3b358d83"},"cell_type":"code","source":"submission.to_csv('baseline_lgb.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"763424eed5a6ef74d29c433d8b23cbda458b6760"},"cell_type":"markdown","source":"## Finding best parameters"},{"metadata":{"trusted":true,"_uuid":"2f5d416d173fe4481bb7e1854b01c5b3930e28ea"},"cell_type":"code","source":"hyperparameter = {'subsample_for_bin': 220000, 'learning_rate': 0.07016445423929361, 'num_leaves': 86, 'metric': 'auc', 'boosting_type': 'gbdt', 'verbose': 1, 'colsample_bytree': 0.6444444444444444, 'subsample': 0.5303030303030303, 'reg_alpha': 0.9591836734693877, 'min_child_samples': 390, 'is_unbalance': True, 'reg_lambda': 0.673469387755102}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c15ac0b617e732c75c0871b70e62ec389e93b97a"},"cell_type":"code","source":"test_ids = df_test['SK_ID_CURR']\ntrain_labels = np.array(df_train['TARGET'].astype(np.int32)).reshape((-1, ))\n\ntrain_random = df_train.drop(columns = ['SK_ID_CURR', 'TARGET'])\ntest_random = df_test.drop(columns = ['SK_ID_CURR'])\n\nprint('Training shape: ', train_random.shape)\nprint('Testing shape: ', test_random.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b18206b9275cc33c508a9ea854ab7d9f691e4c9"},"cell_type":"code","source":"train_set = lgb.Dataset(train_random, label = train_labels)\n\n# Cross validation with n_folds and early stopping\ncv_results = lgb.cv(hyperparameter,\n                    train_set,\n                    num_boost_round = 10000, \n                    early_stopping_rounds = 100,\n                    nfold = 5)\n\nprint('The cross validation score on the full dataset  for Random Search= {:.5f} with std: {:.5f}.'.format(\n    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\nprint('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c19aaf2cfc650321f3a9c56779c5dc49cd798d1"},"cell_type":"code","source":"model = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameter)\nmodel.fit(train_random, train_labels)\n\npreds = model.predict_proba(test_random)[:, 1]\n\nsubmission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': preds})\nsubmission.to_csv('submission_random_search.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3259ea702cc2981b6192509a1d33b7408dc3d5c"},"cell_type":"code","source":"hyper_b = {'learning_rate': 0.07218374731817535, \n           'reg_lambda': 0.7364934411848395, \n           'verbose': 1, 'subsample': 0.6195545022366721, \n           'subsample_for_bin': 60000, 'boosting_type': 'dart',\n           'is_unbalance': True, \n           'num_leaves': 47, 'colsample_bytree': 0.6001712855022151, \n           'reg_alpha': 0.5969339070590824, 'min_child_samples': 485,\n           'metric': 'auc'}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80f035d78b7253ef38ebbc5948073196c86b60f6"},"cell_type":"code","source":"# Cross validation with n_folds and early stopping\ncv_results = lgb.cv(hyper_b, train_set,\n                    num_boost_round = 10000, early_stopping_rounds = 100, \n                    metrics = 'auc', nfold = 5)\n\nprint('The cross validation score on the full dataset for Bayesian optimization = {:.5f} with std: {:.5f}.'.format(\n    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\nprint('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28974d14474fdaf265639a73d31dd3cebf4c9a5c"},"cell_type":"code","source":"model = lgb.LGBMClassifier(n_estimators = 107, **hyper_b)\nmodel.fit(train_random, train_labels)\n\npreds = model.predict_proba(test_random)[:, 1]\n\nsubmission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': preds})\nsubmission.to_csv('submission_bayesian_optimization.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4595405ff8a9279fbd4bb2ea3a39902cde894f7d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}