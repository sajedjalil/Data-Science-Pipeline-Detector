{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom contextlib import contextmanager\nimport multiprocessing as mp\nfrom functools import partial\nfrom scipy.stats import kurtosis, iqr, skew\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport warnings\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"warnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcf1aab939e41e77fa1a85327be6ee1d9656d1bd"},"cell_type":"code","source":"pd.set_option('display.max_rows', 60)\npd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2bb1c61967d2ccaa894b59551aab36d3ebef882"},"cell_type":"code","source":"debug = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55b8284fc3a02f5942ca417ee3852734bdaba39b"},"cell_type":"code","source":"num_rows = 30000 if debug else None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0d34c8008267958182bcdcd65406d9dbe0b9be1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c268a63c39830d90ed752aaaf4fb3916edfb7b3"},"cell_type":"code","source":"# GENERAL CONFIGURATIONS\nNUM_THREADS = 4\nDATA_DIRECTORY = \"../input/\"\nSUBMISSION_SUFIX = \"_model2_04\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b89c5d859b21762feb72864e128a83d9b8213ae"},"cell_type":"code","source":"path = DATA_DIRECTORY\nnum_rows = num_rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c2843aa8d705f6261788ce3a2c5908588c6598a"},"cell_type":"code","source":"train = pd.read_csv(os.path.join(path, 'application_train.csv'), nrows=num_rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71d25931aa5bd12dc700de25ac2759e356b07b88"},"cell_type":"code","source":"test = pd.read_csv(os.path.join(path, 'application_test.csv'), nrows=num_rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85852d8c2588a7a3e30a786de91620d783e05a57"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5446eb0ef782a734d5a43738c86cfce6a5168936"},"cell_type":"code","source":"df = train.append(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"125abce736f42bb62eb5956946924cfdbff5cbe3"},"cell_type":"code","source":"del train, test;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"633d23f6cab52489ccbb7b8356851db8029bd4de"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc0af0f047c7e2163a088fa04a98c418bb72894f"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true,"_uuid":"c97f5042a912a7f9476de3f8c493fe5e2470fa47"},"cell_type":"code","source":"df['CODE_GENDER'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30af3082333eeda7527fc80ade7e923cf0727448"},"cell_type":"code","source":"df = df[df['CODE_GENDER'] != 'XNA']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a25540e290b5670938f9e309c75b7652fda8aecb"},"cell_type":"code","source":"df = df[df['AMT_INCOME_TOTAL']<20000000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7558d50ecc02af0c0b0a1db42d50cc99a5f73a1e"},"cell_type":"code","source":"(df['DAYS_EMPLOYED']==365243).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9068f7209c4cb5c17785655893ca7a99c044c0c"},"cell_type":"code","source":"df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0e070246833d318c1c86928ceb7c18e4074306e"},"cell_type":"code","source":"df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd5e556defbd99c62a90f39592ee72899be162b"},"cell_type":"code","source":"docs = [f for f in df.columns if 'FLAG_DOC' in f]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"368b1a22b0646b09ad767e9df19a8f242dda7a36"},"cell_type":"code","source":"df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bef3f349dc150727a9bbb241c2097994fc9fa4be"},"cell_type":"code","source":"df['DOCUMENT_COUNT'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae197da2af1ffe65c52005b75bf02e39cd5512d7"},"cell_type":"code","source":"df[docs].kurtosis(axis=1).hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52a75335ec2dc1262c380e02fa113a077372e76d"},"cell_type":"code","source":"df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dce8c966231c9d2494859c4b28ec041dd79c265"},"cell_type":"code","source":"def get_age_label(days_birth):\n    \"\"\" Return the age group label (int). \"\"\"\n    age_years = -days_birth / 365\n    if age_years < 27: return 1\n    elif age_years < 40: return 2\n    elif age_years < 50: return 3\n    elif age_years < 65: return 4\n    elif age_years < 99: return 5\n    else: return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09b1cc731a86e16cc8e6939a70aae80ab7adcc03"},"cell_type":"code","source":"df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ce9bd1105cf5327b94041042031bfa73768f4d8"},"cell_type":"code","source":"df['EXT_SOURCE_1'] * df['EXT_SOURCE_2']* df['EXT_SOURCE_3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02c711654a3c108ff7096aecddb6950a6a26594a"},"cell_type":"code","source":"df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\ndf['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a830a4229b0a81b7fde8a69bb2d817e3f425394f"},"cell_type":"code","source":"#credit ratio preprocessing\ndf['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\ndf['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15ecd042699d10d6d00da39519a9024056028f67"},"cell_type":"code","source":"#income ratio preprocessing\ndf['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\ndf['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\ndf['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\ndf['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71b1f6203f473ebcf522ec259b317d08e26cbe61"},"cell_type":"code","source":"#time ratio (period)\ndf['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\ndf['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\ndf['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\ndf['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\ndf['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8debc6b77f666c905b453c1b3b6138a5dd2b987f"},"cell_type":"code","source":"#define functions\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n\n\ndef group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n                               for e in agg_df.columns.tolist()])\n    return agg_df.reset_index()\n\n\ndef group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n\n\ndef do_mean(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_median(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_std(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_sum(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n    original_columns = list(df.columns)\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n    categorical_columns = [c for c in df.columns if c not in original_columns]\n    return df, categorical_columns\n\n\ndef label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns\n\n\ndef add_features(feature_name, aggs, features, feature_names, groupby):\n    feature_names.extend(['{}_{}'.format(feature_name, agg) for agg in aggs])\n\n    for agg in aggs:\n        if agg == 'kurt':\n            agg_func = kurtosis\n        elif agg == 'iqr':\n            agg_func = iqr\n        else:\n            agg_func = agg\n\n        g = groupby[feature_name].agg(agg_func).reset_index().rename(index=str,\n                                                                     columns={feature_name: '{}_{}'.format(feature_name,agg)})\n        features = features.merge(g, on='SK_ID_CURR', how='left')\n    return features, feature_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bab73469a63a9888051116f26be27f977a0845b"},"cell_type":"code","source":"#groupby\ngroup = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\n\n\n\ndf = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\ndf = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\n\ndf = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\ndf = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\n\ndf = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\n\ndf = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\ndf = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3015cf56f4460e271ff996f666bc7b54a82e1207"},"cell_type":"code","source":"# Encode categorical features (LabelEncoder)\ndf, le_encoded_cols = label_encoder(df, None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d70b4caceb113dc6aaff32732bb015612fa22d13"},"cell_type":"code","source":"def drop_application_columns(df):\n    \"\"\" Drop features based on permutation feature importance. \"\"\"\n    drop_list = [\n        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b46e842d243d94fc903a90b952bcdb903081b6e"},"cell_type":"code","source":"df = drop_application_columns(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a32e107d20dfe898ab651247607507bfb7f87e30"},"cell_type":"code","source":"drop_list= ['CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'    \n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b54aa737400b869ac6b6a9abf02a328a021f16c"},"cell_type":"code","source":"for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n                drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\ndf.drop(drop_list, axis=1, inplace=True)\nreturn df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d001ae35585a19957b8b370b8e0aa7fc3614717f"},"cell_type":"code","source":"def get_age_label(days_birth):\n    \"\"\" Return the age group label (int). \"\"\"\n    age_years = -days_birth / 365\n    if age_years < 27: return 1\n    elif age_years < 40: return 2\n    elif age_years < 50: return 3\n    elif age_years < 65: return 4\n    elif age_years < 99: return 5\n    else: return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68fef7bae57a3379fe10ad98e7507eaa254fa1f2"},"cell_type":"code","source":"def get_bureau(path, num_rows= None):\n    bureau = pd.read_csv(os.path.join(path, 'bureau.csv'), nrows=num_rows)\n    \n    bureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n    bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n    \n    bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_CREDIT_SUM_DEBT']\n    bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n    bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_ANNUITY']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fac8feceec5136dd96dd29c5bc4580fa1accfc24"},"cell_type":"code","source":"    # One-hot encoder\n    bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category= False)\n    # Join bureau balance features\n    bureau = bureau.merge(get_bureau_balance(path, num_rows), how='left', on='SK_ID_BUREAU')\n    # Flag months with late payments (days past due)\n    bureau['STATUS_12345'] = 0\n    for i in range(1,6):\n        bureau['STATUS_12345'] += bureau['STATUS_{}'.format(i)]\n\n    # Aggregate by number of months in balance and merge with bureau (loan length agg)\n    features = ['AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM',\n        'AMT_CREDIT_SUM_DEBT', 'DEBT_PERCENTAGE', 'DEBT_CREDIT_DIFF', 'STATUS_0', 'STATUS_12345']\n    agg_length = bureau.groupby('MONTHS_BALANCE_SIZE')[features].mean().reset_index()\n    agg_length.rename({feat: 'LL_' + feat for feat in features}, axis=1, inplace=True)\n    bureau = bureau.merge(agg_length, how='left', on='MONTHS_BALANCE_SIZE')\n    del agg_length; gc.collect()\n\n    # General loans aggregations\n    agg_bureau = group(bureau, 'BUREAU_', BUREAU_AGG)\n    # Active and closed loans aggregations\n    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n    agg_bureau = group_and_merge(active,agg_bureau,'BUREAU_ACTIVE_',BUREAU_ACTIVE_AGG)\n    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n    agg_bureau = group_and_merge(closed,agg_bureau,'BUREAU_CLOSED_',BUREAU_CLOSED_AGG)\n    del active, closed; gc.collect()\n    # Aggregations for the main loan types\n    for credit_type in ['Consumer credit', 'Credit card', 'Mortgage', 'Car loan', 'Microloan']:\n        type_df = bureau[bureau['CREDIT_TYPE_' + credit_type] == 1]\n        prefix = 'BUREAU_' + credit_type.split(' ')[0].upper() + '_'\n        agg_bureau = group_and_merge(type_df, agg_bureau, prefix, BUREAU_LOAN_TYPE_AGG)\n        del type_df; gc.collect()\n    # Time based aggregations: last x months\n    for time_frame in [6, 12]:\n        prefix = \"BUREAU_LAST{}M_\".format(time_frame)\n        time_frame_df = bureau[bureau['DAYS_CREDIT'] >= -30*time_frame]\n        agg_bureau = group_and_merge(time_frame_df, agg_bureau, prefix, BUREAU_TIME_AGG)\n        del time_frame_df; gc.collect()\n\n    # Last loan max overdue\n    sort_bureau = bureau.sort_values(by=['DAYS_CREDIT'])\n    gr = sort_bureau.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].last().reset_index()\n    gr.rename({'AMT_CREDIT_MAX_OVERDUE': 'BUREAU_LAST_LOAN_MAX_OVERDUE'}, inplace=True)\n    agg_bureau = agg_bureau.merge(gr, on='SK_ID_CURR', how='left')\n    # Ratios: total debt/total credit and active loans debt/ active loans credit\n    agg_bureau['BUREAU_DEBT_OVER_CREDIT'] = \\\n        agg_bureau['BUREAU_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_AMT_CREDIT_SUM_SUM']\n    agg_bureau['BUREAU_ACTIVE_DEBT_OVER_CREDIT'] = \\\n        agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM']\n    return agg_bureau\n\n\ndef get_bureau_balance(path, num_rows= None):\n    bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'), nrows= num_rows)\n    bb, categorical_cols = one_hot_encoder(bb, nan_as_category= False)\n    # Calculate rate for each category with decay\n    bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()\n    # Min, Max, Count and mean duration of payments (months)\n    agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}\n    bb_processed = group_and_merge(bb, bb_processed, '', agg, 'SK_ID_BUREAU')\n    del bb; gc.collect()\n    return bb_processed\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd430ab3065b548e9a063cb19d64120523ca69aa"},"cell_type":"code","source":"# ------------------------- PREVIOUS PIPELINE -------------------------\n\ndef get_previous_applications(path, num_rows= None):\n    \"\"\" Process previous_application.csv and return a pandas dataframe. \"\"\"\n    prev = pd.read_csv(os.path.join(path, 'previous_application.csv'), nrows= num_rows)\n    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows= num_rows)\n\n    # One-hot encode most important categorical features\n    ohe_columns = [\n        'NAME_CONTRACT_STATUS', 'NAME_CONTRACT_TYPE', 'CHANNEL_TYPE',\n        'NAME_TYPE_SUITE', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION',\n        'NAME_PRODUCT_TYPE', 'NAME_CLIENT_TYPE']\n    prev, categorical_cols = one_hot_encoder(prev, ohe_columns, nan_as_category= False)\n\n    # Feature engineering: ratios and difference\n    prev['APPLICATION_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n    prev['APPLICATION_CREDIT_RATIO'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n    prev['CREDIT_TO_ANNUITY_RATIO'] = prev['AMT_CREDIT']/prev['AMT_ANNUITY']\n    prev['DOWN_PAYMENT_TO_CREDIT'] = prev['AMT_DOWN_PAYMENT'] / prev['AMT_CREDIT']\n    # Interest ratio on previous application (simplified)\n    total_payment = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n    prev['SIMPLE_INTERESTS'] = (total_payment/prev['AMT_CREDIT'] - 1)/prev['CNT_PAYMENT']\n\n    # Active loans - approved and not complete yet (last_due 365243)\n    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n    active_df = approved[approved['DAYS_LAST_DUE'] == 365243]\n    # Find how much was already payed in active loans (using installments csv)\n    active_pay = pay[pay['SK_ID_PREV'].isin(active_df['SK_ID_PREV'])]\n    active_pay_agg = active_pay.groupby('SK_ID_PREV')[['AMT_INSTALMENT', 'AMT_PAYMENT']].sum()\n    active_pay_agg.reset_index(inplace= True)\n    # Active loans: difference of what was payed and installments\n    active_pay_agg['INSTALMENT_PAYMENT_DIFF'] = active_pay_agg['AMT_INSTALMENT'] - active_pay_agg['AMT_PAYMENT']\n    # Merge with active_df\n    active_df = active_df.merge(active_pay_agg, on= 'SK_ID_PREV', how= 'left')\n    active_df['REMAINING_DEBT'] = active_df['AMT_CREDIT'] - active_df['AMT_PAYMENT']\n    active_df['REPAYMENT_RATIO'] = active_df['AMT_PAYMENT'] / active_df['AMT_CREDIT']\n    # Perform aggregations for active applications\n    active_agg_df = group(active_df, 'PREV_ACTIVE_', PREVIOUS_ACTIVE_AGG)\n    active_agg_df['TOTAL_REPAYMENT_RATIO'] = active_agg_df['PREV_ACTIVE_AMT_PAYMENT_SUM']/\\\n                                             active_agg_df['PREV_ACTIVE_AMT_CREDIT_SUM']\n    del active_pay, active_pay_agg, active_df; gc.collect()\n\n    # Change 365.243 values to nan (missing)\n    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n    # Days last due difference (scheduled x done)\n    prev['DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n    approved['DAYS_LAST_DUE_DIFF'] = approved['DAYS_LAST_DUE_1ST_VERSION'] - approved['DAYS_LAST_DUE']\n\n    # Categorical features\n    categorical_agg = {key: ['mean'] for key in categorical_cols}\n    # Perform general aggregations\n    agg_prev = group(prev, 'PREV_', {**PREVIOUS_AGG, **categorical_agg})\n    # Merge active loans dataframe on agg_prev\n    agg_prev = agg_prev.merge(active_agg_df, how='left', on='SK_ID_CURR')\n    del active_agg_df; gc.collect()\n    # Aggregations for approved and refused loans\n    agg_prev = group_and_merge(approved, agg_prev, 'APPROVED_', PREVIOUS_APPROVED_AGG)\n    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n    agg_prev = group_and_merge(refused, agg_prev, 'REFUSED_', PREVIOUS_REFUSED_AGG)\n    del approved, refused; gc.collect()\n    # Aggregations for Consumer loans and Cash loans\n    for loan_type in ['Consumer loans', 'Cash loans']:\n        type_df = prev[prev['NAME_CONTRACT_TYPE_{}'.format(loan_type)] == 1]\n        prefix = 'PREV_' + loan_type.split(\" \")[0] + '_'\n        agg_prev = group_and_merge(type_df, agg_prev, prefix, PREVIOUS_LOAN_TYPE_AGG)\n        del type_df; gc.collect()\n\n    # Get the SK_ID_PREV for loans with late payments (days past due)\n    pay['LATE_PAYMENT'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n    pay['LATE_PAYMENT'] = pay['LATE_PAYMENT'].apply(lambda x: 1 if x > 0 else 0)\n    dpd_id = pay[pay['LATE_PAYMENT'] > 0]['SK_ID_PREV'].unique()\n    # Aggregations for loans with late payments\n    agg_dpd = group_and_merge(prev[prev['SK_ID_PREV'].isin(dpd_id)], agg_prev,\n                                    'PREV_LATE_', PREVIOUS_LATE_PAYMENTS_AGG)\n    del agg_dpd, dpd_id; gc.collect()\n    # Aggregations for loans in the last x months\n    for time_frame in [12, 24]:\n        time_frame_df = prev[prev['DAYS_DECISION'] >= -30*time_frame]\n        prefix = 'PREV_LAST{}M_'.format(time_frame)\n        agg_prev = group_and_merge(time_frame_df, agg_prev, prefix, PREVIOUS_TIME_AGG)\n        del time_frame_df; gc.collect()\n    del prev; gc.collect()\n    return agg_prev\n\n# ------------------------- POS-CASH PIPELINE -------------------------\n\ndef get_pos_cash(path, num_rows= None):\n    \"\"\" Process POS_CASH_balance.csv and return a pandas dataframe. \"\"\"\n    pos = pd.read_csv(os.path.join(path, 'POS_CASH_balance.csv'), nrows= num_rows)\n    pos, categorical_cols = one_hot_encoder(pos, nan_as_category= False)\n    # Flag months with late payment\n    pos['LATE_PAYMENT'] = pos['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n    # Aggregate by SK_ID_CURR\n    categorical_agg = {key: ['mean'] for key in categorical_cols}\n    pos_agg = group(pos, 'POS_', {**POS_CASH_AGG, **categorical_agg})\n    # Sort and group by SK_ID_PREV\n    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n    gp = sort_pos.groupby('SK_ID_PREV')\n    df = pd.DataFrame()\n    df['SK_ID_CURR'] = gp['SK_ID_CURR'].first()\n    df['MONTHS_BALANCE_MAX'] = gp['MONTHS_BALANCE'].max()\n    # Percentage of previous loans completed and completed before initial term\n    df['POS_LOAN_COMPLETED_MEAN'] = gp['NAME_CONTRACT_STATUS_Completed'].mean()\n    df['POS_COMPLETED_BEFORE_MEAN'] = gp['CNT_INSTALMENT'].first() - gp['CNT_INSTALMENT'].last()\n    df['POS_COMPLETED_BEFORE_MEAN'] = df.apply(lambda x: 1 if x['POS_COMPLETED_BEFORE_MEAN'] > 0\n                                                and x['POS_LOAN_COMPLETED_MEAN'] > 0 else 0, axis=1)\n    # Number of remaining installments (future installments) and percentage from total\n    df['POS_REMAINING_INSTALMENTS'] = gp['CNT_INSTALMENT_FUTURE'].last()\n    df['POS_REMAINING_INSTALMENTS_RATIO'] = gp['CNT_INSTALMENT_FUTURE'].last()/gp['CNT_INSTALMENT'].last()\n    # Group by SK_ID_CURR and merge\n    df_gp = df.groupby('SK_ID_CURR').sum().reset_index()\n    df_gp.drop(['MONTHS_BALANCE_MAX'], axis=1, inplace= True)\n    pos_agg = pd.merge(pos_agg, df_gp, on= 'SK_ID_CURR', how= 'left')\n    del df, gp, df_gp, sort_pos; gc.collect()\n\n    # Percentage of late payments for the 3 most recent applications\n    pos = do_sum(pos, ['SK_ID_PREV'], 'LATE_PAYMENT', 'LATE_PAYMENT_SUM')\n    # Last month of each application\n    last_month_df = pos.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n    # Most recent applications (last 3)\n    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n    gp = sort_pos.iloc[last_month_df].groupby('SK_ID_CURR').tail(3)\n    gp_mean = gp.groupby('SK_ID_CURR').mean().reset_index()\n    pos_agg = pd.merge(pos_agg, gp_mean[['SK_ID_CURR','LATE_PAYMENT_SUM']], on='SK_ID_CURR', how='left')\n\n    # Drop some useless categorical features\n    drop_features = [\n        'POS_NAME_CONTRACT_STATUS_Canceled_MEAN', 'POS_NAME_CONTRACT_STATUS_Amortized debt_MEAN',\n        'POS_NAME_CONTRACT_STATUS_XNA_MEAN']\n    pos_agg.drop(drop_features, axis=1, inplace=True)\n    return pos_agg\n\n# ------------------------- INSTALLMENTS PIPELINE -------------------------\n\ndef get_installment_payments(path, num_rows= None):\n    \"\"\" Process installments_payments.csv and return a pandas dataframe. \"\"\"\n    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows= num_rows)\n    # Group payments and get Payment difference\n    pay = do_sum(pay, ['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER'], 'AMT_PAYMENT', 'AMT_PAYMENT_GROUPED')\n    pay['PAYMENT_DIFFERENCE'] = pay['AMT_INSTALMENT'] - pay['AMT_PAYMENT_GROUPED']\n    pay['PAYMENT_RATIO'] = pay['AMT_INSTALMENT'] / pay['AMT_PAYMENT_GROUPED']\n    pay['PAID_OVER_AMOUNT'] = pay['AMT_PAYMENT'] - pay['AMT_INSTALMENT']\n    pay['PAID_OVER'] = (pay['PAID_OVER_AMOUNT'] > 0).astype(int)\n    # Payment Entry: Days past due and Days before due\n    pay['DPD'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n    pay['DPD'] = pay['DPD'].apply(lambda x: 0 if x <= 0 else x)\n    pay['DBD'] = pay['DAYS_INSTALMENT'] - pay['DAYS_ENTRY_PAYMENT']\n    pay['DBD'] = pay['DBD'].apply(lambda x: 0 if x <= 0 else x)\n    # Flag late payment\n    pay['LATE_PAYMENT'] = pay['DBD'].apply(lambda x: 1 if x > 0 else 0)\n    # Percentage of payments that were late\n    pay['INSTALMENT_PAYMENT_RATIO'] = pay['AMT_PAYMENT'] / pay['AMT_INSTALMENT']\n    pay['LATE_PAYMENT_RATIO'] = pay.apply(lambda x: x['INSTALMENT_PAYMENT_RATIO'] if x['LATE_PAYMENT'] == 1 else 0, axis=1)\n    # Flag late payments that have a significant amount\n    pay['SIGNIFICANT_LATE_PAYMENT'] = pay['LATE_PAYMENT_RATIO'].apply(lambda x: 1 if x > 0.05 else 0)\n    # Flag k threshold late payments\n    pay['DPD_7'] = pay['DPD'].apply(lambda x: 1 if x >= 7 else 0)\n    pay['DPD_15'] = pay['DPD'].apply(lambda x: 1 if x >= 15 else 0)\n    # Aggregations by SK_ID_CURR\n    pay_agg = group(pay, 'INS_', INSTALLMENTS_AGG)\n\n    # Installments in the last x months\n    for months in [36, 60]:\n        recent_prev_id = pay[pay['DAYS_INSTALMENT'] >= -30*months]['SK_ID_PREV'].unique()\n        pay_recent = pay[pay['SK_ID_PREV'].isin(recent_prev_id)]\n        prefix = 'INS_{}M_'.format(months)\n        pay_agg = group_and_merge(pay_recent, pay_agg, prefix, INSTALLMENTS_TIME_AGG)\n\n    # Last x periods trend features\n    group_features = ['SK_ID_CURR', 'SK_ID_PREV', 'DPD', 'LATE_PAYMENT',\n                      'PAID_OVER_AMOUNT', 'PAID_OVER', 'DAYS_INSTALMENT']\n    gp = pay[group_features].groupby('SK_ID_CURR')\n    func = partial(trend_in_last_k_instalment_features, periods= INSTALLMENTS_LAST_K_TREND_PERIODS)\n    g = parallel_apply(gp, func, index_name='SK_ID_CURR', chunk_size=10000).reset_index()\n    pay_agg = pay_agg.merge(g, on='SK_ID_CURR', how='left')\n\n    # Last loan features\n    g = parallel_apply(gp, installments_last_loan_features, index_name='SK_ID_CURR', chunk_size=10000).reset_index()\n    pay_agg = pay_agg.merge(g, on='SK_ID_CURR', how='left')\n    return pay_agg\n\n\ndef trend_in_last_k_instalment_features(gr, periods):\n    gr_ = gr.copy()\n    gr_.sort_values(['DAYS_INSTALMENT'], ascending=False, inplace=True)\n    features = {}\n\n    for period in periods:\n        gr_period = gr_.iloc[:period]\n        features = add_trend_feature(features, gr_period, 'DPD',\n                                           '{}_TREND_'.format(period))\n        features = add_trend_feature(features, gr_period, 'PAID_OVER_AMOUNT',\n                                           '{}_TREND_'.format(period))\n    return features\n\n\ndef installments_last_loan_features(gr):\n    gr_ = gr.copy()\n    gr_.sort_values(['DAYS_INSTALMENT'], ascending=False, inplace=True)\n    last_installment_id = gr_['SK_ID_PREV'].iloc[0]\n    gr_ = gr_[gr_['SK_ID_PREV'] == last_installment_id]\n\n    features = {}\n    features = add_features_in_group(features, gr_, 'DPD',\n                                     ['sum', 'mean', 'max', 'std'],\n                                     'LAST_LOAN_')\n    features = add_features_in_group(features, gr_, 'LATE_PAYMENT',\n                                     ['count', 'mean'],\n                                     'LAST_LOAN_')\n    features = add_features_in_group(features, gr_, 'PAID_OVER_AMOUNT',\n                                     ['sum', 'mean', 'max', 'min', 'std'],\n                                     'LAST_LOAN_')\n    features = add_features_in_group(features, gr_, 'PAID_OVER',\n                                     ['count', 'mean'],\n                                     'LAST_LOAN_')\n    return features\n\n# ------------------------- CREDIT CARD PIPELINE -------------------------\n\ndef get_credit_card(path, num_rows= None):\n    \"\"\" Process credit_card_balance.csv and return a pandas dataframe. \"\"\"\n    cc = pd.read_csv(os.path.join(path, 'credit_card_balance.csv'), nrows= num_rows)\n    cc, cat_cols = one_hot_encoder(cc, nan_as_category=False)\n    cc.rename(columns={'AMT_RECIVABLE': 'AMT_RECEIVABLE'}, inplace=True)\n    # Amount used from limit\n    cc['LIMIT_USE'] = cc['AMT_BALANCE'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n    # Current payment / Min payment\n    cc['PAYMENT_DIV_MIN'] = cc['AMT_PAYMENT_CURRENT'] / cc['AMT_INST_MIN_REGULARITY']\n    # Late payment\n    cc['LATE_PAYMENT'] = cc['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n    # How much drawing of limit\n    cc['DRAWING_LIMIT_RATIO'] = cc['AMT_DRAWINGS_ATM_CURRENT'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n    # Aggregations by SK_ID_CURR\n    cc_agg = cc.groupby('SK_ID_CURR').agg(CREDIT_CARD_AGG)\n    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n    cc_agg.reset_index(inplace= True)\n\n    # Last month balance of each credit card application\n    last_ids = cc.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n    last_months_df = cc[cc.index.isin(last_ids)]\n    cc_agg = group_and_merge(last_months_df,cc_agg,'CC_LAST_', {'AMT_BALANCE': ['mean', 'max']})\n\n    # Aggregations for last x months\n    for months in [12, 24, 48]:\n        cc_prev_id = cc[cc['MONTHS_BALANCE'] >= -months]['SK_ID_PREV'].unique()\n        cc_recent = cc[cc['SK_ID_PREV'].isin(cc_prev_id)]\n        prefix = 'INS_{}M_'.format(months)\n        cc_agg = group_and_merge(cc_recent, cc_agg, prefix, CREDIT_CARD_TIME_AGG)\n    return cc_agg\n\n\n# ------------------------- UTILITY FUNCTIONS -------------------------\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n\n\ndef group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n                               for e in agg_df.columns.tolist()])\n    return agg_df.reset_index()\n\n\ndef group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n\n\ndef do_mean(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_median(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_std(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_sum(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n    original_columns = list(df.columns)\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n    categorical_columns = [c for c in df.columns if c not in original_columns]\n    return df, categorical_columns\n\n\ndef label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns\n\n\ndef add_features(feature_name, aggs, features, feature_names, groupby):\n    feature_names.extend(['{}_{}'.format(feature_name, agg) for agg in aggs])\n\n    for agg in aggs:\n        if agg == 'kurt':\n            agg_func = kurtosis\n        elif agg == 'iqr':\n            agg_func = iqr\n        else:\n            agg_func = agg\n\n        g = groupby[feature_name].agg(agg_func).reset_index().rename(index=str,\n                                                                     columns={feature_name: '{}_{}'.format(feature_name,agg)})\n        features = features.merge(g, on='SK_ID_CURR', how='left')\n    return features, feature_names\n\n\ndef add_features_in_group(features, gr_, feature_name, aggs, prefix):\n    for agg in aggs:\n        if agg == 'sum':\n            features['{}{}_sum'.format(prefix, feature_name)] = gr_[feature_name].sum()\n        elif agg == 'mean':\n            features['{}{}_mean'.format(prefix, feature_name)] = gr_[feature_name].mean()\n        elif agg == 'max':\n            features['{}{}_max'.format(prefix, feature_name)] = gr_[feature_name].max()\n        elif agg == 'min':\n            features['{}{}_min'.format(prefix, feature_name)] = gr_[feature_name].min()\n        elif agg == 'std':\n            features['{}{}_std'.format(prefix, feature_name)] = gr_[feature_name].std()\n        elif agg == 'count':\n            features['{}{}_count'.format(prefix, feature_name)] = gr_[feature_name].count()\n        elif agg == 'skew':\n            features['{}{}_skew'.format(prefix, feature_name)] = skew(gr_[feature_name])\n        elif agg == 'kurt':\n            features['{}{}_kurt'.format(prefix, feature_name)] = kurtosis(gr_[feature_name])\n        elif agg == 'iqr':\n            features['{}{}_iqr'.format(prefix, feature_name)] = iqr(gr_[feature_name])\n        elif agg == 'median':\n            features['{}{}_median'.format(prefix, feature_name)] = gr_[feature_name].median()\n    return features\n\n\ndef add_trend_feature(features, gr, feature_name, prefix):\n    y = gr[feature_name].values\n    try:\n        x = np.arange(0, len(y)).reshape(-1, 1)\n        lr = LinearRegression()\n        lr.fit(x, y)\n        trend = lr.coef_[0]\n    except:\n        trend = np.nan\n    features['{}{}'.format(prefix, feature_name)] = trend\n    return features\n\n\ndef parallel_apply(groups, func, index_name='Index', num_workers=0, chunk_size=100000):\n    if num_workers <= 0: num_workers = NUM_THREADS\n    #n_chunks = np.ceil(1.0 * groups.ngroups / chunk_size)\n    indeces, features = [], []\n    for index_chunk, groups_chunk in chunk_groups(groups, chunk_size):\n        with mp.pool.Pool(num_workers) as executor:\n            features_chunk = executor.map(func, groups_chunk)\n        features.extend(features_chunk)\n        indeces.extend(index_chunk)\n\n    features = pd.DataFrame(features)\n    features.index = indeces\n    features.index.name = index_name\n    return features\n\n\ndef chunk_groups(groupby_object, chunk_size):\n    n_groups = groupby_object.ngroups\n    group_chunk, index_chunk = [], []\n    for i, (index, df) in enumerate(groupby_object):\n        group_chunk.append(df)\n        index_chunk.append(index)\n        if (i + 1) % chunk_size == 0 or i + 1 == n_groups:\n            group_chunk_, index_chunk_ = group_chunk.copy(), index_chunk.copy()\n            group_chunk, index_chunk = [], []\n            yield index_chunk_, group_chunk_\n\n\ndef reduce_memory(df):\n    \"\"\"Reduce memory usage of a dataframe by setting data types. \"\"\"\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    print('Initial df memory usage is {:.2f} MB for {} columns'\n          .format(start_mem, len(df.columns)))\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type != object:\n            cmin = df[col].min()\n            cmax = df[col].max()\n            if str(col_type)[:3] == 'int':\n                # Can use unsigned int here too\n                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    memory_reduction = 100 * (start_mem - end_mem) / start_mem\n    print('Final memory usage is: {:.2f} MB - decreased by {:.1f}%'.format(end_mem, memory_reduction))\n    return df\n\n# ------------------------- CONFIGURATIONS -------------------------\n\n# GENERAL CONFIGURATIONS\nNUM_THREADS = 4\nDATA_DIRECTORY = \"../input/\"\nSUBMISSION_SUFIX = \"_model2_04\"\n\n# INSTALLMENTS TREND PERIODS\nINSTALLMENTS_LAST_K_TREND_PERIODS =  [12, 24, 60, 120]\n\n# LIGHTGBM CONFIGURATION AND HYPER-PARAMETERS\nGENERATE_SUBMISSION_FILES = True\nSTRATIFIED_KFOLD = False\nRANDOM_SEED = 737851\nNUM_FOLDS = 10\nEARLY_STOPPING = 100\n\nLIGHTGBM_PARAMS = {\n    'boosting_type': 'goss',\n    'n_estimators': 10000,\n    'learning_rate': 0.005134,\n    'num_leaves': 54,\n    'max_depth': 10,\n    'subsample_for_bin': 240000,\n    'reg_alpha': 0.436193,\n    'reg_lambda': 0.479169,\n    'colsample_bytree': 0.508716,\n    'min_split_gain': 0.024766,\n    'subsample': 1,\n    'is_unbalance': False,\n    'silent':-1,\n    'verbose':-1\n}\n\n# AGGREGATIONS\nBUREAU_AGG = {\n    'SK_ID_BUREAU': ['nunique'],\n    'DAYS_CREDIT': ['min', 'max', 'mean'],\n    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n    'AMT_ANNUITY': ['mean'],\n    'DEBT_CREDIT_DIFF': ['mean', 'sum'],\n    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n    # Categorical\n    'STATUS_0': ['mean'],\n    'STATUS_1': ['mean'],\n    'STATUS_12345': ['mean'],\n    'STATUS_C': ['mean'],\n    'STATUS_X': ['mean'],\n    'CREDIT_ACTIVE_Active': ['mean'],\n    'CREDIT_ACTIVE_Closed': ['mean'],\n    'CREDIT_ACTIVE_Sold': ['mean'],\n    'CREDIT_TYPE_Consumer credit': ['mean'],\n    'CREDIT_TYPE_Credit card': ['mean'],\n    'CREDIT_TYPE_Car loan': ['mean'],\n    'CREDIT_TYPE_Mortgage': ['mean'],\n    'CREDIT_TYPE_Microloan': ['mean'],\n    # Group by loan duration features (months)\n    'LL_AMT_CREDIT_SUM_OVERDUE': ['mean'],\n    'LL_DEBT_CREDIT_DIFF': ['mean'],\n    'LL_STATUS_12345': ['mean'],\n}\n\nBUREAU_ACTIVE_AGG = {\n    'DAYS_CREDIT': ['max', 'mean'],\n    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM': ['max', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean'],\n    'DAYS_CREDIT_UPDATE': ['min', 'mean'],\n    'DEBT_PERCENTAGE': ['mean'],\n    'DEBT_CREDIT_DIFF': ['mean'],\n    'CREDIT_TO_ANNUITY_RATIO': ['mean'],\n    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n}\n\nBUREAU_CLOSED_AGG = {\n    'DAYS_CREDIT': ['max', 'var'],\n    'DAYS_CREDIT_ENDDATE': ['max'],\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['max', 'sum'],\n    'DAYS_CREDIT_UPDATE': ['max'],\n    'ENDDATE_DIF': ['mean'],\n    'STATUS_12345': ['mean'],\n}\n\nBUREAU_LOAN_TYPE_AGG = {\n    'DAYS_CREDIT': ['mean', 'max'],\n    'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n    'AMT_CREDIT_SUM': ['mean', 'max'],\n    'AMT_CREDIT_SUM_DEBT': ['mean', 'max'],\n    'DEBT_PERCENTAGE': ['mean'],\n    'DEBT_CREDIT_DIFF': ['mean'],\n    'DAYS_CREDIT_ENDDATE': ['max'],\n}\n\nBUREAU_TIME_AGG = {\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n    'AMT_CREDIT_SUM': ['max', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n    'DEBT_PERCENTAGE': ['mean'],\n    'DEBT_CREDIT_DIFF': ['mean'],\n    'STATUS_0': ['mean'],\n    'STATUS_12345': ['mean'],\n}\n\nPREVIOUS_AGG = {\n    'SK_ID_PREV': ['nunique'],\n    'AMT_ANNUITY': ['min', 'max', 'mean'],\n    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n    'RATE_DOWN_PAYMENT': ['max', 'mean'],\n    'DAYS_DECISION': ['min', 'max', 'mean'],\n    'CNT_PAYMENT': ['max', 'mean'],\n    'DAYS_TERMINATION': ['max'],\n    # Engineered features\n    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean', 'var'],\n    'DOWN_PAYMENT_TO_CREDIT': ['mean'],\n}\n\nPREVIOUS_ACTIVE_AGG = {\n    'SK_ID_PREV': ['nunique'],\n    'SIMPLE_INTERESTS': ['mean'],\n    'AMT_ANNUITY': ['max', 'sum'],\n    'AMT_APPLICATION': ['max', 'mean'],\n    'AMT_CREDIT': ['sum'],\n    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n    'DAYS_DECISION': ['min', 'mean'],\n    'CNT_PAYMENT': ['mean', 'sum'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n    # Engineered features\n    'AMT_PAYMENT': ['sum'],\n    'INSTALMENT_PAYMENT_DIFF': ['mean', 'max'],\n    'REMAINING_DEBT': ['max', 'mean', 'sum'],\n    'REPAYMENT_RATIO': ['mean'],\n}\n\nPREVIOUS_APPROVED_AGG = {\n    'SK_ID_PREV': ['nunique'],\n    'AMT_ANNUITY': ['min', 'max', 'mean'],\n    'AMT_CREDIT': ['min', 'max', 'mean'],\n    'AMT_DOWN_PAYMENT': ['max'],\n    'AMT_GOODS_PRICE': ['max'],\n    'HOUR_APPR_PROCESS_START': ['min', 'max'],\n    'DAYS_DECISION': ['min', 'mean'],\n    'CNT_PAYMENT': ['max', 'mean'],\n    'DAYS_TERMINATION': ['mean'],\n    # Engineered features\n    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n    'APPLICATION_CREDIT_DIFF': ['max'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n    # The following features are only for approved applications\n    'DAYS_FIRST_DRAWING': ['max', 'mean'],\n    'DAYS_FIRST_DUE': ['min', 'mean'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n    'DAYS_LAST_DUE': ['max', 'mean'],\n    'DAYS_LAST_DUE_DIFF': ['min', 'max', 'mean'],\n    'SIMPLE_INTERESTS': ['min', 'max', 'mean'],\n}\n\nPREVIOUS_REFUSED_AGG = {\n    'AMT_APPLICATION': ['max', 'mean'],\n    'AMT_CREDIT': ['min', 'max'],\n    'DAYS_DECISION': ['min', 'max', 'mean'],\n    'CNT_PAYMENT': ['max', 'mean'],\n    # Engineered features\n    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean', 'var'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'mean'],\n    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n}\n\nPREVIOUS_LATE_PAYMENTS_AGG = {\n    'DAYS_DECISION': ['min', 'max', 'mean'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n    # Engineered features\n    'APPLICATION_CREDIT_DIFF': ['min'],\n    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n}\n\nPREVIOUS_LOAN_TYPE_AGG = {\n    'AMT_CREDIT': ['sum'],\n    'AMT_ANNUITY': ['mean', 'max'],\n    'SIMPLE_INTERESTS': ['min', 'mean', 'max', 'var'],\n    'APPLICATION_CREDIT_DIFF': ['min', 'var'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n    'DAYS_DECISION': ['max'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['max', 'mean'],\n    'CNT_PAYMENT': ['mean'],\n}\n\nPREVIOUS_TIME_AGG = {\n    'AMT_CREDIT': ['sum'],\n    'AMT_ANNUITY': ['mean', 'max'],\n    'SIMPLE_INTERESTS': ['mean', 'max'],\n    'DAYS_DECISION': ['min', 'mean'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n    # Engineered features\n    'APPLICATION_CREDIT_DIFF': ['min'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n}\n\nPOS_CASH_AGG = {\n    'SK_ID_PREV': ['nunique'],\n    'MONTHS_BALANCE': ['min', 'max', 'size'],\n    'SK_DPD': ['max', 'mean', 'sum', 'var'],\n    'SK_DPD_DEF': ['max', 'mean', 'sum'],\n    'LATE_PAYMENT': ['mean']\n}\n\nINSTALLMENTS_AGG = {\n    'SK_ID_PREV': ['size', 'nunique'],\n    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n    'DPD': ['max', 'mean', 'var'],\n    'DBD': ['max', 'mean', 'var'],\n    'PAYMENT_DIFFERENCE': ['mean'],\n    'PAYMENT_RATIO': ['mean'],\n    'LATE_PAYMENT': ['mean', 'sum'],\n    'SIGNIFICANT_LATE_PAYMENT': ['mean', 'sum'],\n    'LATE_PAYMENT_RATIO': ['mean'],\n    'DPD_7': ['mean'],\n    'DPD_15': ['mean'],\n    'PAID_OVER': ['mean']\n}\n\nINSTALLMENTS_TIME_AGG = {\n    'SK_ID_PREV': ['size'],\n    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n    'DPD': ['max', 'mean', 'var'],\n    'DBD': ['max', 'mean', 'var'],\n    'PAYMENT_DIFFERENCE': ['mean'],\n    'PAYMENT_RATIO': ['mean'],\n    'LATE_PAYMENT': ['mean'],\n    'SIGNIFICANT_LATE_PAYMENT': ['mean'],\n    'LATE_PAYMENT_RATIO': ['mean'],\n    'DPD_7': ['mean'],\n    'DPD_15': ['mean'],\n}\n\nCREDIT_CARD_AGG = {\n    'MONTHS_BALANCE': ['min'],\n    'AMT_BALANCE': ['max'],\n    'AMT_CREDIT_LIMIT_ACTUAL': ['max'],\n    'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n    'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n    'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n    'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n    'AMT_PAYMENT_TOTAL_CURRENT': ['max', 'mean', 'sum', 'var'],\n    'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n    'CNT_DRAWINGS_ATM_CURRENT': ['max', 'mean', 'sum'],\n    'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n    'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n    'SK_DPD': ['mean', 'max', 'sum'],\n    'SK_DPD_DEF': ['max', 'sum'],\n    'LIMIT_USE': ['max', 'mean'],\n    'PAYMENT_DIV_MIN': ['min', 'mean'],\n    'LATE_PAYMENT': ['max', 'sum'],\n}\n\nCREDIT_CARD_TIME_AGG = {\n    'CNT_DRAWINGS_ATM_CURRENT': ['mean'],\n    'SK_DPD': ['max', 'sum'],\n    'AMT_BALANCE': ['mean', 'max'],\n    'LIMIT_USE': ['max', 'mean']\n}\n\n\nif __name__ == \"__main__\":\n    pd.set_option('display.max_rows', 60)\n    pd.set_option('display.max_columns', 100)\n    with timer(\"Pipeline total time\"):\n        main(debug= False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26e5bc3876435f9fd4ee3a1aaac9c1473cda40bb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef1186fb05831249a371064e095e90e7ee384d10"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9a13e38defdbc124a0b8d645ca2b566a343dcef"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"614f33e9e07bcd86b3607308bc44ddf10b1eeed5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"777f6b044c9bafe066ce50d517ca135fbebbc84d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}