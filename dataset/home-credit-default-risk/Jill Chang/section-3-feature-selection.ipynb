{"cells":[{"metadata":{"_uuid":"ed1992a1f4752bb6d720779761d3aecc751e0162"},"cell_type":"markdown","source":"<h1 style=\"text-align:center\"> INFSCI 2595 Machine Learning Project</h1>\n<h2 style=\"text-align:center\">Home Credit Default Risk</h2>\n<h5 style=\"text-align:center\">Members: Chih Ying Chang, Xinghao Huang, Yuanyuan Zhang</h5>"},{"metadata":{"_uuid":"7170b5cc40cc88250687aa8ca4f062c0701b384c"},"cell_type":"markdown","source":"> # Section Three: Feature Selection"},{"metadata":{"_uuid":"d9d5df7e7e111d39352465a190a61844e76646e7"},"cell_type":"markdown","source":"In this section, we will apply feature engineering to the manual engineered features built in two previous kernels. We will reduce the number of features using three methods: \n\n1. Remove collinear features\n2. Remove features with greater than a threshold percentage of missing values\n3. Keep only the most relevant features using feature importances from a model\n\nThen, we will test the performance of the features using a fairly basic gradient boosting machine model."},{"metadata":{"_uuid":"7ad94c9b49252d5d8143b536bec2613b7c862476"},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# pandas and numpy for data manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# featuretools for automated feature engineering\nimport featuretools as ft\n\n# matplotlit and seaborn for visualizations\nimport matplotlib.pyplot as plt\nplt.rcParams['font.size'] = 22\nimport seaborn as sns\n\n# Suppress warnings from pandas\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# modeling \nimport lightgbm as lgb\n\n# utilities\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# memory management\nimport gc\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fd0c0abfc221fa11427fafe6e3c37dc63db2294"},"cell_type":"markdown","source":"* train_bureau is the training features built manually using the bureau and bureau_balance data.\n\nAt fisrt, we will see how many features we built over the manual engineering process. "},{"metadata":{"trusted":true,"_uuid":"15d04701b15c322f9d1294278bd99a1cb44e5311"},"cell_type":"code","source":"# Read in data\ntrain_bureau = pd.read_csv('../input/test-input/train_bureau_raw.csv')\ntest_bureau = pd.read_csv('../input/test-input/test_bureau_raw.csv')\n\n# All columns in dataframes\nbureau_columns = list(train_bureau.columns)\n\n# Bureau features\nbureau_features = list(set(bureau_columns))\nprint('There are %d bureau and bureau balance features.' % len(bureau_features))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbdec9211d5607bec557b441e522afd7075bbf2e","trusted":true},"cell_type":"code","source":"train_labels = train_bureau['TARGET']\ntrain_ids = train_bureau['SK_ID_CURR']\ntest_ids = test_bureau['SK_ID_CURR']\n\ntrain = train_bureau\ntest = test_bureau\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf25cc0d551720ae1b70c019cbd243bb496426ec"},"cell_type":"markdown","source":"Next, we want to one-hot encode the dataframes.\nAn important note in the code cell is where we align the dataframes by the columns. This ensures we have the same columns in the training and testing datasets."},{"metadata":{"trusted":true,"_uuid":"627eb33001cbbe0589d9299114e5a4226e303051"},"cell_type":"code","source":"# One hot encoding\ntrain = pd.get_dummies(train)\ntest = pd.get_dummies(test)\n\n# Match the columns in the dataframes\ntrain, test = train.align(test, join = 'inner', axis = 1)\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a465c3a01ba4a9c0a69b8496eabe4d8d1c86541"},"cell_type":"markdown","source":"Let's remove any columns built on the SK_ID_CURR, since this is a unique identifier for each client, it should not have any predictive power, and we would not want to build a model trained on this \"feature\"."},{"metadata":{"trusted":true,"_uuid":"d391e812c77acfe25851c51c3b6f54ca45d1c4e2"},"cell_type":"code","source":"cols_with_id = [x for x in train.columns if 'SK_ID_CURR' in x]\ncols_with_bureau_id = [x for x in train.columns if 'SK_ID_BUREAU' in x]\ncols_with_previous_id = [x for x in train.columns if 'SK_ID_PREV' in x]\nprint('There are %d columns that contain SK_ID_CURR' % len(cols_with_id))\nprint('There are %d columns that contain SK_ID_BUREAU' % len(cols_with_bureau_id))\nprint('There are %d columns that contain SK_ID_PREV' % len(cols_with_previous_id))\n\ntrain = train.drop(columns = cols_with_id)\ntest = test.drop(columns = cols_with_id)\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a98f035ac407c54e12f9c454b0c44a131814d5b5"},"cell_type":"markdown","source":"After applying this to the full dataset, we **end up with 452 features**. Although, more feature may be a good thing, the irrelevant features, highly correlated features, and missing values can prevent the model from learning and decrease generalization performance on the testing data. Therefore, we perform feature selection to keep only the most useful variables.\n\nWe will start feature selecting by removing Collinear Variables."},{"metadata":{"_uuid":"effe760bfd245cc5f103adf958c88be08e7a00d1"},"cell_type":"markdown","source":"# Remove Collinear Variables"},{"metadata":{"_uuid":"f84417269501cc96f48fcd9afe87a08de287b247"},"cell_type":"markdown","source":"Collinear variables are those variables which are highly correlated with one another. These can decrease the model's availablility to learn, decrease model interpretability, and decrease generalization performance on the test set. \n\nWe will establish an admittedly arbitrary threshold for removing collinear variables, and then remove one out of any pair of variables that is above that threshold."},{"metadata":{"_uuid":"6ccd97caaa3c6c12dfd96f1adf47e5aff2f5af7b"},"cell_type":"markdown","source":"## Identify Correlated Variables"},{"metadata":{"_uuid":"732db482e8e9cf91a138defe09ae32326c3353fa"},"cell_type":"markdown","source":"As the code below, we will identifies the highly correlated variables based on the absolute magnitude of the Pearson correlation coefficient being greater than 0.9."},{"metadata":{"trusted":true,"_uuid":"a7c9a05be0f24c6ee708e8e5b7e85b03bd37300b"},"cell_type":"code","source":"# Threshold for removing correlated variables\nthreshold = 0.9\n\n# Absolute value correlation matrix\ncorr_matrix = train.corr().abs()\ncorr_matrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c81ba68719c30682086f534bc987ac580718695d"},"cell_type":"code","source":"# Upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22daff5c4cf10e9d0876b60c5477d3af4176e5f6"},"cell_type":"code","source":"# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71055b7a75bdfd23933906a2b2bcf784da343385"},"cell_type":"markdown","source":"## Drop Correlated Variables"},{"metadata":{"trusted":true,"_uuid":"359813e37f493eba3a0a68fa070e934891b05ad1"},"cell_type":"code","source":"train = train.drop(columns = to_drop)\ntest = test.drop(columns = to_drop)\n\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75f91af13c27561335fa8ff91323ac42324a3fb6"},"cell_type":"markdown","source":"Applying this on the entire dataset **results in 103 collinear features** removed.\n"},{"metadata":{"_uuid":"4619299d886e2fce6cd9c7bb271d61ec02235633"},"cell_type":"markdown","source":"# Remove Missing Variables"},{"metadata":{"_uuid":"d2f5162cfd935b34d95ce2717a1f0cbc98fa693a"},"cell_type":"markdown","source":"Secondly, We will use removing missing values to select features. We have to decide what percentage of missing values is the minimum threshold for removing a column. In this implementation, we assume that any columns have greater than 75% missing values, they will be removed.\n\nMost models (including those in Sk-Learn) cannot handle missing values, so we will use the Gradient Boosting Machine (at least in LightGBM) to handle missing values. "},{"metadata":{"trusted":true,"_uuid":"1f0c0be52095b7ea2d15eacc33008f27ec839a19"},"cell_type":"code","source":"# Train missing values (in percent)\ntrain_missing = (train.isnull().sum() / len(train)).sort_values(ascending = False)\ntrain_missing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b3f7a380dfa9ae810bdb50e3e2be9f4a7ee6e826"},"cell_type":"code","source":"# Test missing values (in percent)\ntest_missing = (test.isnull().sum() / len(test)).sort_values(ascending = False)\ntest_missing.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a2f52a47921937ba7f57e1943d2c87579d6524e"},"cell_type":"code","source":"# Identify missing values above threshold\ntrain_missing_DataFrame = pd.DataFrame.from_dict(train_missing)\ntest_missing_DataFrame = pd.DataFrame.from_dict(test_missing)\ntrain_missing_DataFrame.columns = ['value']\ntrain_missing_DataFrame[train_missing_DataFrame.value >= 0.75].index.tolist()\ntest_missing_DataFrame.columns = ['value']\ntest_missing_DataFrame[test_missing_DataFrame.value >= 0.75].index.tolist()\n\n# train_missing = train_missing[train_missing > 0.50]\n# test_missing = test_missing[test_missing > 0.50]\n\nall_missing = list(set(set(train_missing_DataFrame) | set(test_missing_DataFrame)))\nprint('There are %d columns with more than 75%% missing values' % len(all_missing))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5bf52bc147e4df6ecb7e63fa242a3e1ae3c398c"},"cell_type":"markdown","source":"Let's drop the columns, one-hot encode the dataframes, and then align the columns of the dataframes."},{"metadata":{"trusted":true,"_uuid":"810a6101916255d08d78197642ea770d5753f4d9"},"cell_type":"code","source":"# # Need to save the labels because aligning will remove this column\n# train_labels = train[\"TARGET\"]\n# train_ids = train['SK_ID_CURR']\n# test_ids = test['SK_ID_CURR']\n\n# train = pd.get_dummies(train.drop(columns = all_missing))\n# test = pd.get_dummies(test.drop(columns = all_missing))\n\n# train, test = train.align(test, join = 'inner', axis = 1)\n\n# print('Training set full shape: ', train.shape)\n# print('Testing set full shape: ' , test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36cc084c503cf1bfbe1f82cd818ffe4b96048841"},"cell_type":"markdown","source":"# Feature Selection through Feature Importances"},{"metadata":{"_uuid":"1d8709c25d8626adb4c291f75f503c6b8c8f98bd"},"cell_type":"markdown","source":"The next method we can employ for feature selection is to use the feature importances of a model.\n\nOne method for doing this automatically is the Recursive Feature Elimination method in Scikit-Learn. It can fits the model repeatedly on the data and iteratively removes the lowest importance features until the desired number of features is left. \n\nWe will use a Gradient Boosted Model from the LightGBM library to assess feature importances. \n\nSince the LightGBM model does not need missing values to be imputed, we can directly fit on the training data. We will use Early Stopping to determine the optimal number of iterations and run the model twice, averaging the feature importances to try and avoid overfitting to a certain set of features.\n"},{"metadata":{"trusted":true,"_uuid":"93c8a37764d2f8987c5e2356b4d979d0c437d6bd"},"cell_type":"code","source":"# Initialize an empty array to hold feature importances\nfeature_importances = np.zeros(train.shape[1])\n\n# Create the model with several hyperparameters\nmodel = lgb.LGBMClassifier(objective='binary', boosting_type = 'goss', n_estimators = 10000, class_weight = 'balanced')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f8d60d4559cb4a5032bb0d5c7411683a4a00dd"},"cell_type":"code","source":"# Fit the model twice to avoid overfitting\nfor i in range(2):\n    \n    # Split into training and validation set\n    train_features, valid_features, train_y, valid_y = train_test_split(train, train_labels, test_size = 0.25, random_state = i)\n    \n    # Train using early stopping\n    model.fit(train_features, train_y, early_stopping_rounds=100, eval_set = [(valid_features, valid_y)], \n              eval_metric = 'auc', verbose = 200)\n    \n    # Record the feature importances\n    feature_importances += model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e94d31913e4ad1b49fbf26294a5d240645b6462c"},"cell_type":"code","source":"# Make sure to average feature importances! \nx = feature_importances / 2\nfeature_importances = pd.DataFrame({'feature': list(train.columns), 'importance': feature_importances}).sort_values('importance', ascending = False)\n\nfeature_importances.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fd3ae0ba92737ff9698b6571ca2b316ef25fc18"},"cell_type":"code","source":"# Find the features with zero importance\nzero_features = list(feature_importances[feature_importances['importance'] == 0.0]['feature'])\nprint('There are %d features with 0.0 importance' % len(zero_features))\nfeature_importances.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b0852019c20e8851c67a040135afecf9d5bd1be"},"cell_type":"markdown","source":"It looks like many of the features we made have literally 0 importance. For the gradient boosting machine, features with 0 importance are not used at all to make any splits. Therefore, we can remove these features from the model with no effect on performance."},{"metadata":{"trusted":true,"_uuid":"97ae10e67ce3dd484788ea55d1a03e225658be64"},"cell_type":"code","source":"def plot_feature_importances(df, threshold = 0.9):\n    \n    plt.rcParams['font.size'] = 18\n    \n    # Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    # Normalize the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    df['cumulative_importance'] = np.cumsum(df['importance_normalized'])\n\n    # Make a horizontal bar chart of feature importances\n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    \n    # Need to reverse the index to plot most important on top\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    # Set the yticks and labels\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    # Plot labeling\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    # Cumulative importance plot\n    plt.figure(figsize = (8, 6))\n    plt.plot(list(range(len(df))), df['cumulative_importance'], 'r-')\n    plt.xlabel('Number of Features'); plt.ylabel('Cumulative Importance'); \n    \n    plt.title('Cumulative Feature Importance');\n    plt.show();\n    \n    importance_index = np.min(np.where(df['cumulative_importance'] > threshold))\n    print('%d features required for %0.2f of cumulative importance' % (importance_index + 1, threshold))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"556873db7783b851c1d26a0986169485a1f1ad6c"},"cell_type":"code","source":"norm_feature_importances = plot_feature_importances(feature_importances)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"304a7220e48fb237c35da66266177bba876b4a62"},"cell_type":"markdown","source":"Let's remove the features that have zero importance."},{"metadata":{"trusted":true,"_uuid":"92e8bd96f46dfd2b82aa6a129608be037b76afbb"},"cell_type":"code","source":"train = train.drop(columns = zero_features)\ntest = test.drop(columns = zero_features)\n\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"939231c175045b8fa36278ec293f9dff04d7f042"},"cell_type":"markdown","source":"At this point, we can re-run the model to see if it identifies any more features with zero importance. In a way, we are implementing our own form of recursive feature elimination. "},{"metadata":{"trusted":true,"_uuid":"b7e8de19a22fac543fd6722cc77824def385db90"},"cell_type":"code","source":"def identify_zero_importance_features(train, train_labels, iterations = 2):\n\n    # Initialize an empty array to hold feature importances\n    feature_importances = np.zeros(train.shape[1])\n\n    # Create the model with several hyperparameters\n    model = lgb.LGBMClassifier(objective='binary', boosting_type = 'goss', n_estimators = 10000,class_weight = 'balanced')\n    \n    # Fit the model multiple times to avoid overfitting\n    for i in range(iterations):\n        \n        # Split into training and validation set\n        train_features, valid_features, train_y, valid_y = train_test_split(train, train_labels, test_size = 0.25, random_state = i)\n\n        # Train using early stopping\n        model.fit(train_features, train_y, early_stopping_rounds=100, eval_set = [(valid_features, valid_y)], \n                  eval_metric = 'auc', verbose = 200)\n\n        # Record the feature importances\n        feature_importances += model.feature_importances_ / iterations\n    \n    feature_importances = pd.DataFrame({'feature': list(train.columns), 'importance': feature_importances}).sort_values('importance', ascending = False)\n    \n    # Find the features with zero importance\n    zero_features = list(feature_importances[feature_importances['importance'] == 0.0]['feature'])\n    print('\\nThere are %d features with 0.0 importance' % len(zero_features))\n    \n    return zero_features, feature_importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb718b203df93fc59921a5fd114b6dcfec3794dd"},"cell_type":"code","source":"second_round_zero_features, feature_importances = identify_zero_importance_features(train, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0edd98935c86f3d60a253a409d16c95bc3c12d9"},"cell_type":"markdown","source":"Now, there are no 0 importance features left. If we want to remove more features, we will create a threshold percentage of importance, such as 95%, to remove less important features."},{"metadata":{"trusted":true,"_uuid":"c0833ef0aa2f1e6545710d6da325e4b36d185351"},"cell_type":"code","source":"norm_feature_importances = plot_feature_importances(feature_importances, threshold = 0.95)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89e56dd7dc64683d861b21af7bddbf2ca0d8a503"},"cell_type":"markdown","source":"We can keep only the features needed for 95% importance. \n\nThen, we can test both versions of the data to see if the extra feature removal step is worthwhile."},{"metadata":{"trusted":true,"_uuid":"42488bc90ed00cdaf21e62c74028db12f3c3737f"},"cell_type":"code","source":"# Threshold for cumulative importance\nthreshold = 0.95\n\n# Extract the features to keep\nfeatures_to_keep = list(norm_feature_importances[norm_feature_importances['cumulative_importance'] < threshold]['feature'])\n\n# Create new datasets with smaller features\ntrain_small = train[features_to_keep]\ntest_small = test[features_to_keep]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1bc14c8851a4c53b0389a9f0a07c0dea1b38e72"},"cell_type":"code","source":"train_small['TARGET'] = train_labels\ntrain_small['SK_ID_CURR'] = train_ids\ntest_small['SK_ID_CURR'] = test_ids\n\ntrain_small.to_csv('m_train_small.csv', index = False)\ntest_small.to_csv('m_test_small.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d964619ec462e258b977f4d3855d1b4006980f9"},"cell_type":"markdown","source":"# Test New FeaturesetsÂ¶"},{"metadata":{"_uuid":"84cf2feb970182dc25e1a22313291dbe4f46447c"},"cell_type":"markdown","source":"Since, the last step of feature removal seems like it may potentially hurt the model the most. Therefore, we want to test the effect of this removal. To do that, we can use a standard model and change the features.\n\nWe will also use LightGBM model with two different datasets to see which one perform better."},{"metadata":{"trusted":true,"_uuid":"8d43c806fc00381b32fa8772bb33f1afaf3e263a"},"cell_type":"code","source":"def model(features, test_features, encoding = 'ohe', n_folds = 5):\n    # Extract the ids\n    train_ids = features['SK_ID_CURR']\n    test_ids = test_features['SK_ID_CURR']\n    \n    # Extract the labels for training\n    labels = features['TARGET']\n    \n    # Remove the ids and target\n    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n    \n    \n    # One Hot Encoding\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        \n        # Align the dataframes by the columns\n        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n        \n        # No categorical indices to record\n        cat_indices = 'auto'\n    \n    # Integer label encoding\n    elif encoding == 'le':\n                # Create a label encoder\n        label_encoder = LabelEncoder()\n        \n        # List for storing categorical indices\n        cat_indices = []\n        \n        # Iterate through each column\n        for i, col in enumerate(features):\n            if features[col].dtype == 'object':\n                # Map the categorical features to integers\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n\n                # Record the categorical indices\n                cat_indices.append(i)\n    \n    # Catch error if label encoding scheme is not valid\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n        \n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    \n    # Extract feature names\n    feature_names = list(features.columns)\n    \n        # Convert to np arrays\n    features = np.array(features)\n    test_features = np.array(test_features)\n    \n    # Create the kfold object\n    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n    \n    # Empty array for feature importances\n    feature_importance_values = np.zeros(len(feature_names))\n    \n    # Empty array for test predictions\n    test_predictions = np.zeros(test_features.shape[0])\n    \n    # Empty array for out of fold validation predictions\n    out_of_fold = np.zeros(features.shape[0])\n    \n    # Lists for recording validation and training scores\n    valid_scores = []\n    train_scores = []\n    \n    # Iterate through each fold\n    for train_indices, valid_indices in k_fold.split(features):\n        \n        # Training data for the fold\n        train_features, train_labels = features[train_indices], labels[train_indices]\n        # Validation data for the fold\n        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n        \n        # Create the model\n        model = lgb.LGBMClassifier(objective = 'binary', boosting_type='goss',\n                                   class_weight = 'balanced', learning_rate = 0.05, \n                                   reg_alpha = 0.1, reg_lambda = 0.1, n_jobs = -1, random_state = 50)\n        \n        # Train the model\n        model.fit(train_features, train_labels, eval_metric = 'auc',\n                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n                  early_stopping_rounds = 100, verbose = 200)\n        \n        # Record the best iteration\n        best_iteration = model.best_iteration_\n        \n        # Record the feature importances\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        \n        # Make predictions\n        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n        \n                # Record the out of fold predictions\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n        \n        # Record the best score\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        \n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        \n        # Clean up memory\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n        \n    # Make the submission dataframe\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    \n    # Make the feature importance dataframe\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    \n    # Overall validation score\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    \n        # Add the overall scores to the metrics\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    \n    # Needed for creating dataframe of validation scores\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    \n    # Dataframe of validation scores\n    metrics = pd.DataFrame({'fold': fold_names,\n                            'train': train_scores,\n                            'valid': valid_scores}) \n    \n    return submission, feature_importances, metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dc7a61d5235cbda58a6a2d74c57f295d4bd0bfd"},"cell_type":"markdown","source":"# Test \"Full\" Dataset"},{"metadata":{"_uuid":"c21254e7542ab1dde7b947bc95603cbf00600228"},"cell_type":"markdown","source":"This is the expanded dataset. To recap the process to make this dataset we:\n\n1. Removed collinear features as measured by the correlation coefficient greater than 0.9\n2. Removed any columns with greater than 75% missing values in the train or test set\n3. Removed all features with non-zero feature importances"},{"metadata":{"trusted":true,"_uuid":"78878c26e8c1a0a67af0af06622b9d65edecd5e7"},"cell_type":"code","source":"train['TARGET'] = train_labels\ntrain['SK_ID_CURR'] = train_ids\ntest['SK_ID_CURR'] = test_ids\n\nsubmission, feature_importances, metrics = model(train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43e459c28fa5348d18332cffe5dc3666a5589231"},"cell_type":"code","source":"metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afbcb98a60166051fc0503fc360998f6d2f07590"},"cell_type":"code","source":"submission.to_csv('selected_features_submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91f50ec94eadbd54dd2a93fd13bc3fb93b30ed33"},"cell_type":"markdown","source":"The full features after feature selection score is 0.74949 as the picture below.\n![](https://i.postimg.cc/c4ytwPzx/Screen-Shot-2018-11-29-at-10-19-29-PM.png)"},{"metadata":{"_uuid":"0f2acef968525246f637f37764b8d90d7f574f19"},"cell_type":"markdown","source":"# Test \"Small\" Dataset"},{"metadata":{"_uuid":"0464a952e8d4b5b9f631d4a6f409e49b4b4c8462"},"cell_type":"markdown","source":"The small dataset requires one additional step over the ful l dataset:\n\nKeep only features needed to reach 95% cumulative importance in the gradient boosting machine"},{"metadata":{"trusted":true,"_uuid":"dd3f38ffc06e1d9f0beddfe5e2da4e35451a14b5"},"cell_type":"code","source":"submission_small, feature_importances_small, metrics_small = model(train_small, test_small)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbee780d922ebd89dd74fce1f76d7c387fda6ef8"},"cell_type":"code","source":"metrics_small","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"407b67f47ba8eaa401cfe9248dee22be9b29ef99"},"cell_type":"code","source":"submission_small.to_csv('selected_features_small_submission.csv', index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee9670e216a39984c004283b9054ca66fb684070"},"cell_type":"markdown","source":"The full features after feature selection score is 0.74949 as the picture below.\n![](https://i.postimg.cc/B60RxS25/Screen-Shot-2018-11-29-at-10-30-14-PM.png)"},{"metadata":{"_uuid":"1df5ba549228d046b1eed9515ab5ef64c6c4c17f"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}