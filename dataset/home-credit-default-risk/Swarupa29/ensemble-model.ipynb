{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory|\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-17T06:05:34.804297Z","iopub.execute_input":"2021-11-17T06:05:34.80473Z","iopub.status.idle":"2021-11-17T06:05:34.838396Z","shell.execute_reply.started":"2021-11-17T06:05:34.804698Z","shell.execute_reply":"2021-11-17T06:05:34.837432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the necessary libraries\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:05:35.633062Z","iopub.execute_input":"2021-11-17T06:05:35.633339Z","iopub.status.idle":"2021-11-17T06:05:35.63769Z","shell.execute_reply.started":"2021-11-17T06:05:35.633306Z","shell.execute_reply":"2021-11-17T06:05:35.637025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function for one hot encoding of the categorical columns\ndef one_hot_encoding_dataframe(df):\n    original_columns = list(df.columns)\n    cat_columns=[x for x in df.columns if df[x].dtype == 'object']\n    df=pd.get_dummies(df,columns=cat_columns,dummy_na= False)\n    new_added_columns=list(set(df.columns).difference(set(original_columns)))\n    return df,new_added_columns,df.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:05:36.449368Z","iopub.execute_input":"2021-11-17T06:05:36.449622Z","iopub.status.idle":"2021-11-17T06:05:36.455604Z","shell.execute_reply.started":"2021-11-17T06:05:36.449595Z","shell.execute_reply":"2021-11-17T06:05:36.454765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the main test and train data\nmain_df=pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\ntest_df=pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')\ntrain_target = main_df[['TARGET', 'SK_ID_CURR']]\ntest_target = test_df['SK_ID_CURR'].copy()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:05:36.996533Z","iopub.execute_input":"2021-11-17T06:05:36.997834Z","iopub.status.idle":"2021-11-17T06:05:41.491667Z","shell.execute_reply.started":"2021-11-17T06:05:36.997767Z","shell.execute_reply":"2021-11-17T06:05:41.490863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We have choosen to use the stacking ensemble technique where an L0 model will be used to get the predictions from each table of the dataset. These predictions will then be combined as an input to the L1 model which will give the final output to be submitted","metadata":{}},{"cell_type":"markdown","source":"# **L0 MODELS**","metadata":{}},{"cell_type":"markdown","source":"### We start by selecting and extracting features from each table, then train it on the L0 models to get the prediction\nSince we are still students with very little domain knowledge in finance, we do not have enough expertise to come up with the features on our own and the model performance is heavily dependent on the feature engineering. So the aggregates and features have been inspired from various existing solutions of the competition","metadata":{}},{"cell_type":"markdown","source":"Here is the list of solutions which inspired our feature selection\n1. https://www.kaggle.com/hikmetsezen/micro-model-174-features-0-8-auc-on-home-credit\n2. https://www.kaggle.com/yakupkaplan/home-credit-default-risk-prediction-model\n3. https://github.com/wins999/Home_Credit_Loan_Prediction\n4. https://www.kaggle.com/jamesdellinger/home-credit-putting-all-the-steps-together\n","metadata":{}},{"cell_type":"markdown","source":"# 1) Credit card balance","metadata":{}},{"cell_type":"code","source":"def credit_card_bal(df):\n    \n    categorical_cols = ['NAME_CONTRACT_STATUS']\n    for col in categorical_cols:\n            enc = LabelEncoder()\n            df[col] = enc.fit_transform(df[col])\n            \n    #Creating new features\n    df['ratio_ab_acl'] = df['AMT_BALANCE'] / df['AMT_CREDIT_LIMIT_ACTUAL']\n    df['sum_draw'] = df[['AMT_DRAWINGS_ATM_CURRENT','AMT_DRAWINGS_CURRENT','AMT_DRAWINGS_OTHER_CURRENT', 'AMT_DRAWINGS_POS_CURRENT']].sum(axis=1)\n    df['ratio_tc_tr'] = df['AMT_PAYMENT_TOTAL_CURRENT'] / df['AMT_TOTAL_RECEIVABLE']\n    df['ratio_pc_ar'] = df['AMT_PAYMENT_CURRENT'] / df['AMT_RECIVABLE']\n    df['sum_cntdraw'] = df[['CNT_DRAWINGS_ATM_CURRENT', 'CNT_DRAWINGS_CURRENT', 'CNT_DRAWINGS_OTHER_CURRENT', 'CNT_DRAWINGS_POS_CURRENT']].sum(axis=1)\n    df['diff_tr_tc'] = df['AMT_TOTAL_RECEIVABLE'] / df['AMT_PAYMENT_TOTAL_CURRENT']\n    df['ratio_pc_ptc'] = df['AMT_PAYMENT_CURRENT'] / df['AMT_PAYMENT_TOTAL_CURRENT']\n    \n    #Creating aggregates\n    aggs = {\n        'MONTHS_BALANCE': ['min', 'max', 'size'],\n        'CNT_DRAWINGS_ATM_CURRENT': ['max'], \n        'CNT_DRAWINGS_CURRENT': ['max'],\n        'CNT_DRAWINGS_POS_CURRENT': ['max'],\n        'CNT_INSTALMENT_MATURE_CUM': ['mean', 'sum'],\n        'AMT_BALANCE': ['min', 'max', 'mean', 'sum'],\n        'AMT_CREDIT_LIMIT_ACTUAL': ['max', 'mean','var'],\n        'AMT_DRAWINGS_ATM_CURRENT': ['max'],\n        'AMT_DRAWINGS_CURRENT': ['max'],\n        'AMT_DRAWINGS_POS_CURRENT': ['max'],\n        'AMT_PAYMENT_CURRENT': ['max'],\n        'AMT_PAYMENT_TOTAL_CURRENT': ['max'],\n        'AMT_RECEIVABLE_PRINCIPAL': ['mean', 'sum'],\n        'AMT_RECIVABLE': ['mean', 'sum'],\n        'AMT_TOTAL_RECEIVABLE': ['mean'],\n        \n        #New features\n        'ratio_ab_acl': ['min', 'max', 'mean'],\n        'ratio_tc_tr': ['min', 'max', 'mean'],\n        'ratio_pc_ar': ['min', 'max', 'mean'],\n        'diff_tr_tc': ['min', 'max', 'mean'],\n        'ratio_pc_ptc': ['min', 'max', 'mean']\n    }\n    #creating n from those aggregates\n    cc_aggs = df.groupby('SK_ID_CURR').agg(aggs)\n    cc_aggs.columns = pd.Index([i[0] + \"_\" + i[1].upper() + '_(CREDIT_CARD)' for i in cc_aggs.columns.tolist()])\n    cc_aggs['CC_COUNT'] = df.groupby('SK_ID_CURR').size()\n    \n    return cc_aggs","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:02:26.598126Z","iopub.execute_input":"2021-11-17T06:02:26.598554Z","iopub.status.idle":"2021-11-17T06:02:26.608949Z","shell.execute_reply.started":"2021-11-17T06:02:26.598507Z","shell.execute_reply":"2021-11-17T06:02:26.607768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"credit_data = pd.read_csv('/kaggle/input/home-credit-default-risk/credit_card_balance.csv')\ndf_credit=credit_card_bal(credit_data)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:02:26.61Z","iopub.execute_input":"2021-11-17T06:02:26.610205Z","iopub.status.idle":"2021-11-17T06:02:42.442588Z","shell.execute_reply.started":"2021-11-17T06:02:26.610181Z","shell.execute_reply":"2021-11-17T06:02:42.441102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The features of the credit table are merged with the main table to get all the indexes on the main table and so that we can use it to train the model. However, only columns corresponding to the credit table were used to train. \nOnce the features are created, the next step is to Impute missing values and normalise the data. All missing values were imputed using median and minmax was used to normalise data","metadata":{}},{"cell_type":"code","source":"df_credit =main_df.merge(df_credit, how='left', on='SK_ID_CURR')\ndf_credit=df_credit[df_credit['TARGET'].notnull()]\n\ny_train=df_credit['TARGET']\ntrain_column=set(df_credit.columns)-set(main_df.columns)\nX_train=df_credit[train_column]\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:02:42.44369Z","iopub.status.idle":"2021-11-17T06:02:42.444692Z","shell.execute_reply.started":"2021-11-17T06:02:42.44443Z","shell.execute_reply":"2021-11-17T06:02:42.444459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After preprocessing the data, it is used to train the Classifier model. We have choosen LightGBM as our model as it was realised from literature review and other solutions that LightGBM trained faster and gave a better AUC score than logistic regression, decision tress or Neural netwroks","metadata":{}},{"cell_type":"markdown","source":"**goss** or gradient based one sided sampling was used as the number of train instances was very high and downsampling will improve the speed of the model while keeping the accuracy good. It is usually used for ensemble models","metadata":{}},{"cell_type":"code","source":"import sklearn\nclasses_zero = main_df[main_df['TARGET'] == 0]\nclasses_one = main_df[main_df['TARGET'] == 1]\n\n# Convert parts into NumPy arrays for weight computation\nzero_numpy = classes_zero['TARGET'].to_numpy()\none_numpy = classes_one['TARGET'].to_numpy()\nall_together = np.concatenate((zero_numpy, one_numpy))\nunique_classes = np.unique(all_together)\n\n# Compute weights\nweights = sklearn.utils.class_weight.compute_class_weight('balanced', unique_classes, all_together)\nweights","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:40:50.299388Z","iopub.execute_input":"2021-11-17T03:40:50.299697Z","iopub.status.idle":"2021-11-17T03:40:50.53726Z","shell.execute_reply.started":"2021-11-17T03:40:50.299668Z","shell.execute_reply":"2021-11-17T03:40:50.536381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poswt = len(classes_zero) / len(classes_one)\nposwt","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:41:43.26214Z","iopub.execute_input":"2021-11-17T03:41:43.263169Z","iopub.status.idle":"2021-11-17T03:41:43.273525Z","shell.execute_reply.started":"2021-11-17T03:41:43.263071Z","shell.execute_reply":"2021-11-17T03:41:43.272631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:42:53.433018Z","iopub.execute_input":"2021-11-17T03:42:53.43329Z","iopub.status.idle":"2021-11-17T03:42:53.438149Z","shell.execute_reply.started":"2021-11-17T03:42:53.433262Z","shell.execute_reply":"2021-11-17T03:42:53.437143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf.predict_proba(X_train)[:,1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:42:54.237427Z","iopub.execute_input":"2021-11-17T03:42:54.23831Z","iopub.status.idle":"2021-11-17T03:53:10.331854Z","shell.execute_reply.started":"2021-11-17T03:42:54.238262Z","shell.execute_reply":"2021-11-17T03:53:10.330909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After training the model, next step is to get its predictions on train data to train it on the L0 model","metadata":{}},{"cell_type":"code","source":"cred_bal=clf.predict_proba(X_train)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:53:30.291871Z","iopub.execute_input":"2021-11-17T03:53:30.292453Z","iopub.status.idle":"2021-11-17T03:56:42.786062Z","shell.execute_reply.started":"2021-11-17T03:53:30.292406Z","shell.execute_reply":"2021-11-17T03:56:42.785201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly, the L0 model is used to predict vales on the test data as well. These values will be used to check the score of the inidvidual table as well as be used as input for the L1 model","metadata":{}},{"cell_type":"code","source":"df_credit2=credit_card_bal(credit_data)\ndf_credit2 =test_df.merge(df_credit2, how='left', on='SK_ID_CURR')\ntest_col=set(df_credit2.columns)-set(test_df.columns)\nX_test=df_credit2[test_col]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:59:51.1479Z","iopub.execute_input":"2021-11-17T03:59:51.14845Z","iopub.status.idle":"2021-11-17T03:59:55.283765Z","shell.execute_reply.started":"2021-11-17T03:59:51.148395Z","shell.execute_reply":"2021-11-17T03:59:55.282953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test=X_test.replace([np.inf, -np.inf],np.nan)\ndf_test=imputer.transform(df_test)\ndf_test=scaler.transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:59:58.782229Z","iopub.execute_input":"2021-11-17T03:59:58.783092Z","iopub.status.idle":"2021-11-17T03:59:58.856643Z","shell.execute_reply.started":"2021-11-17T03:59:58.783051Z","shell.execute_reply":"2021-11-17T03:59:58.855793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp=clf.predict_proba(df_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:00:01.800487Z","iopub.execute_input":"2021-11-17T04:00:01.800935Z","iopub.status.idle":"2021-11-17T04:00:35.651169Z","shell.execute_reply.started":"2021-11-17T04:00:01.800895Z","shell.execute_reply":"2021-11-17T04:00:35.650396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Installments payments balance","metadata":{}},{"cell_type":"markdown","source":"### Feature engineering","metadata":{}},{"cell_type":"code","source":"def install_bal(inst_df):\n          \n    inst_df['late_pay']=inst_df['DAYS_INSTALMENT']-inst_df['DAYS_ENTRY_PAYMENT']\n    inst_df['less_pay']=inst_df['AMT_INSTALMENT']-inst_df['AMT_PAYMENT']\n    inst_df['late_lp']=0.5*inst_df['late_pay']+0.5*inst_df['less_pay']\n    inst_df['ltp_flag']=((inst_df['DAYS_INSTALMENT']-inst_df['DAYS_ENTRY_PAYMENT'])>0).astype(int)\n    inst_df['lsp_flag']=((inst_df['AMT_INSTALMENT']-inst_df['AMT_PAYMENT'])>0).astype(int)\n    \n    for col in inst_df.columns:\n        if col.startswith('DAYS'):\n            inst_df[col].replace(365243, np.nan, inplace= True)\n            \n    inst_df,installments_payments_cat_columns,all_columns=one_hot_encoding_dataframe(inst_df)\n       \n\n    inst_df_agg={}\n    for col in inst_df.columns:\n        if col!='SK_ID_CURR' and col !='SK_ID_PREV':\n            inst_df_agg[col]=['mean']\n            if (col=='late_pay') |  (col=='less_pay') | (col=='NUM_INSTALMENT_VERSION') | (col=='NUM_INSTALMENT_NUMBER'):\n              inst_df_agg[col]=['mean','sum','max','min']\n    \n    inst_agg = inst_df.groupby('SK_ID_CURR').agg(inst_df_agg)\n    \n    modified_col=[]\n    for c in list(inst_agg.columns):\n        modified_col.append(\"INST_\"+c[0]+\"_\"+c[1].upper())\n    inst_agg.columns=modified_col  \n    \n    inst_agg['cnt_inst'] = inst_df.groupby('SK_ID_CURR')['SK_ID_PREV'].count()\n\n    no = -365*3\n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['3365_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['3365_ltp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].min()\n    inst_agg['3365_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    inst_agg['3365_ltp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['ltp_flag'].sum() \n  \n    no = -365*2\n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['2365_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['2365_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    inst_agg['2365_ltp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['ltp_flag'].sum()\n    \n    no = -365 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['365_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['365_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    inst_agg['365_ltp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['ltp_flag'].sum()\n    \n    no = -180 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >= no].copy()\n    inst_agg['180_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['180_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    inst_agg['180_ltp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['ltp_flag'].sum()\n    \n    no = -90 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >= no].copy()\n    inst_agg['90_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['90_ltp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].min()\n    inst_agg['90_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n        \n    no = -365*2\n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['2365_lsp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].mean()\n    inst_agg['2365_lsp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].min()\n    inst_agg['2365_lsp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].max()\n    inst_agg['2365_lsp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['lsp_flag'].sum()\n\n    no = -365 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['365_lsp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].mean()\n    inst_agg['365_lsp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].min()\n    inst_agg['365_lsp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].max()\n    inst_agg['365_lsp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['lsp_flag'].sum()\n    \n    no = -180 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >= no].copy()\n    inst_agg['180_lsp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].mean()\n    inst_agg['180_lsp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].min()\n    inst_agg['180_lsp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].max()\n    \n    no = -90 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >= no].copy()\n    inst_agg['90_lsp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].mean()\n    inst_agg['90_lsp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].min()\n    inst_agg['90_lsp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].max()\n   \n    \n    return inst_agg","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:02:20.515767Z","iopub.execute_input":"2021-11-17T04:02:20.516075Z","iopub.status.idle":"2021-11-17T04:02:20.541996Z","shell.execute_reply.started":"2021-11-17T04:02:20.51604Z","shell.execute_reply":"2021-11-17T04:02:20.540994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normalising and training the model\nWe have used the same L0 models for all the tables using the same parameters","metadata":{}},{"cell_type":"code","source":"inst_data = pd.read_csv('/kaggle/input/home-credit-default-risk/installments_payments.csv')\n\ndf_inst=install_bal(inst_data)\ndf_inst =main_df.merge(df_inst, how='left', on='SK_ID_CURR')\ndf_inst=df_inst[df_inst['TARGET'].notnull()]\n\ny_train=df_inst['TARGET']\ntrain_column=set(df_inst.columns)-set(main_df.columns)\nX_train=df_inst[train_column]\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:02:23.744737Z","iopub.execute_input":"2021-11-17T04:02:23.745035Z","iopub.status.idle":"2021-11-17T04:03:06.001973Z","shell.execute_reply.started":"2021-11-17T04:02:23.745005Z","shell.execute_reply":"2021-11-17T04:03:06.000895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf2=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:03:06.003758Z","iopub.execute_input":"2021-11-17T04:03:06.004636Z","iopub.status.idle":"2021-11-17T04:03:06.008738Z","shell.execute_reply.started":"2021-11-17T04:03:06.004597Z","shell.execute_reply":"2021-11-17T04:03:06.008161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf2.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf2.predict_proba(X_train)[:,1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:03:06.009939Z","iopub.execute_input":"2021-11-17T04:03:06.010241Z","iopub.status.idle":"2021-11-17T04:12:11.234877Z","shell.execute_reply.started":"2021-11-17T04:03:06.010214Z","shell.execute_reply":"2021-11-17T04:12:11.233904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"ROCAUC Score :\",roc_auc_score(y_train,clf2.predict_proba(X_train)[:,1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T15:16:56.115862Z","iopub.execute_input":"2021-11-16T15:16:56.116409Z","iopub.status.idle":"2021-11-16T15:19:10.77299Z","shell.execute_reply.started":"2021-11-16T15:16:56.116372Z","shell.execute_reply":"2021-11-16T15:19:10.771997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predictions on train data","metadata":{}},{"cell_type":"code","source":"inst=clf2.predict_proba(X_train)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:12:11.237259Z","iopub.execute_input":"2021-11-17T04:12:11.237718Z","iopub.status.idle":"2021-11-17T04:15:47.105848Z","shell.execute_reply.started":"2021-11-17T04:12:11.237665Z","shell.execute_reply":"2021-11-17T04:15:47.105108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_inst2=install_bal(inst_data)\ndf_inst2 =test_df.merge(df_inst2, how='left', on='SK_ID_CURR')\ntest_col=set(df_inst2.columns)-set(test_df.columns)\nX_test=df_inst2[test_col]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:15:47.10711Z","iopub.execute_input":"2021-11-17T04:15:47.107443Z","iopub.status.idle":"2021-11-17T04:16:07.475834Z","shell.execute_reply.started":"2021-11-17T04:15:47.107415Z","shell.execute_reply":"2021-11-17T04:16:07.474986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test=X_test.replace([np.inf, -np.inf],np.nan)\ndf_test=imputer1.transform(df_test)\ndf_test=scaler.transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:16:07.477036Z","iopub.execute_input":"2021-11-17T04:16:07.477271Z","iopub.status.idle":"2021-11-17T04:16:07.54572Z","shell.execute_reply.started":"2021-11-17T04:16:07.477242Z","shell.execute_reply":"2021-11-17T04:16:07.544861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-14T13:46:24.161192Z","iopub.execute_input":"2021-11-14T13:46:24.161454Z","iopub.status.idle":"2021-11-14T13:46:24.166023Z","shell.execute_reply.started":"2021-11-14T13:46:24.161425Z","shell.execute_reply":"2021-11-14T13:46:24.16542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting the target values for test data and making a submission file using it","metadata":{}},{"cell_type":"code","source":"yp=clf2.predict_proba(df_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:16:07.547077Z","iopub.execute_input":"2021-11-17T04:16:07.547367Z","iopub.status.idle":"2021-11-17T04:16:44.402707Z","shell.execute_reply.started":"2021-11-17T04:16:07.547337Z","shell.execute_reply":"2021-11-17T04:16:44.401876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) POS application","metadata":{}},{"cell_type":"markdown","source":"### Feature engineering","metadata":{}},{"cell_type":"code","source":"def pos_appl(pos_df):\n    \n    pos_df=pos_df[pos_df['NAME_CONTRACT_STATUS']!='XNA'] \n    pos_df,pos_data_cat_columns,all_columns=one_hot_encoding_dataframe(pos_df)\n     \n    pos_data_agg={}\n    for col in pos_df.columns:\n        if col!='SK_ID_CURR' and col !='SK_ID_PREV':\n            pos_data_agg[col]=['mean']\n        if col=='MONTHS_BALANCE':\n            pos_data_agg[col]=['sum','mean','max']\n            \n    \n    pos_agg = pos_df.groupby('SK_ID_CURR').agg(pos_data_agg)\n    \n    modified_col=[]\n    for col in list(pos_agg.columns):\n        modified_col.append(\"POS_\"+col[0]+\"_\"+col[1].upper())\n    pos_agg.columns=modified_col\n    pos_agg['pos_cnt'] = pos_df.groupby('SK_ID_CURR')['SK_ID_PREV'].count() \n\n    month = -24 \n    pos_temp = pos_df[pos_df.MONTHS_BALANCE >= month].copy()\n    pos_agg['24_c_inst_mean'] = pos_temp.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].mean()\n    pos_agg['24_c_inst_max'] = pos_temp.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].max()\n    \n    month = -12 \n    pos_temp = pos_df[pos_df.MONTHS_BALANCE >= month].copy()\n    pos_agg['12_c_inst_mean'] = pos_temp.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].mean()\n    pos_agg['12_c_inst_max'] = pos_temp.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].max()\n    \n    active = pos_df[pos_df['NAME_CONTRACT_STATUS_Active'] == 1]\n   \n    pos_agg['active_inst_mean'] = active.groupby('SK_ID_CURR')['CNT_INSTALMENT'].mean()\n    pos_agg['active_inst_max'] = active.groupby('SK_ID_CURR')['CNT_INSTALMENT'].max()\n  \n    pos_agg['active_dpd_mean'] = active.groupby('SK_ID_CURR')['SK_DPD'].mean()\n    pos_agg['active_dpd_max'] = active.groupby('SK_ID_CURR')['SK_DPD'].max()\n\n    pos_agg['active_inst_fut_mean'] = active.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].mean()\n    pos_agg['active_inst_fut_max'] = active.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].max()\n  \n    pos_agg['active_dpd_def_mean'] = active.groupby('SK_ID_CURR')['SK_DPD_DEF'].mean()\n    pos_agg['active_dpd_def_max'] = active.groupby('SK_ID_CURR')['SK_DPD_DEF'].max()\n  \n    completed = pos_df[pos_df['NAME_CONTRACT_STATUS_Completed'] == 1]\n    pos_agg['com_dpd_mean'] = completed.groupby('SK_ID_CURR')['SK_DPD'].mean()\n    pos_agg['com_dpd_max'] = completed.groupby('SK_ID_CURR')['SK_DPD'].max()\n\n    pos_agg['com_dpd_def_mean'] = completed.groupby('SK_ID_CURR')['SK_DPD_DEF'].mean()\n    pos_agg['com_dpd_def_max'] = completed.groupby('SK_ID_CURR')['SK_DPD_DEF'].max()\n\n    pos_agg['com_inst_fut_mean'] = completed.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].mean()\n    pos_agg['com_inst_fut_max'] = completed.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].max()\n  \n    pos_agg['com_inst_mean'] = completed.groupby('SK_ID_CURR')['CNT_INSTALMENT'].mean()\n    pos_agg['com_inst_max'] = completed.groupby('SK_ID_CURR')['CNT_INSTALMENT'].max()\n  \n    return pos_agg\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:17:37.841442Z","iopub.execute_input":"2021-11-17T04:17:37.841745Z","iopub.status.idle":"2021-11-17T04:17:37.855917Z","shell.execute_reply.started":"2021-11-17T04:17:37.841711Z","shell.execute_reply":"2021-11-17T04:17:37.854952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_data = pd.read_csv('/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv')\n\ndf_pos=pos_appl(pos_data)\ndf_pos =main_df.merge(df_pos, how='left', on='SK_ID_CURR')\ndf_pos=df_pos[df_pos['TARGET'].notnull()]\n\ny_train=df_pos['TARGET']\ntrain_column=set(df_pos.columns)-set(main_df.columns)\nX_train=df_pos[train_column]\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:17:39.221712Z","iopub.execute_input":"2021-11-17T04:17:39.222027Z","iopub.status.idle":"2021-11-17T04:18:08.176464Z","shell.execute_reply.started":"2021-11-17T04:17:39.221993Z","shell.execute_reply":"2021-11-17T04:18:08.175578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf3=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:18:08.453024Z","iopub.execute_input":"2021-11-17T04:18:08.45329Z","iopub.status.idle":"2021-11-17T04:18:08.458288Z","shell.execute_reply.started":"2021-11-17T04:18:08.453262Z","shell.execute_reply":"2021-11-17T04:18:08.457482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf3.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf3.predict_proba(X_train)[:,1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:18:10.847251Z","iopub.execute_input":"2021-11-17T04:18:10.847762Z","iopub.status.idle":"2021-11-17T04:25:34.836227Z","shell.execute_reply.started":"2021-11-17T04:18:10.847718Z","shell.execute_reply":"2021-11-17T04:25:34.835277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target values for train data","metadata":{}},{"cell_type":"code","source":"pos=clf3.predict_proba(X_train)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:25:34.838186Z","iopub.execute_input":"2021-11-17T04:25:34.838662Z","iopub.status.idle":"2021-11-17T04:28:46.047788Z","shell.execute_reply.started":"2021-11-17T04:25:34.838616Z","shell.execute_reply":"2021-11-17T04:28:46.047041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pos2=pos_appl(pos_data)\ndf_pos2 =test_df.merge(df_pos2, how='left', on='SK_ID_CURR')\ntest_col=set(df_pos2.columns)-set(test_df.columns)\nX_test=df_pos2[test_col]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:28:46.049156Z","iopub.execute_input":"2021-11-17T04:28:46.049575Z","iopub.status.idle":"2021-11-17T04:29:01.809261Z","shell.execute_reply.started":"2021-11-17T04:28:46.049526Z","shell.execute_reply":"2021-11-17T04:29:01.80834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test=X_test.replace([np.inf, -np.inf],np.nan)\ndf_test=imputer1.transform(df_test)\ndf_test=scaler.transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:29:01.811132Z","iopub.execute_input":"2021-11-17T04:29:01.811852Z","iopub.status.idle":"2021-11-17T04:29:01.850388Z","shell.execute_reply.started":"2021-11-17T04:29:01.811793Z","shell.execute_reply":"2021-11-17T04:29:01.849439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target values for test data","metadata":{}},{"cell_type":"code","source":"yp=clf3.predict_proba(df_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:29:01.852152Z","iopub.execute_input":"2021-11-17T04:29:01.8526Z","iopub.status.idle":"2021-11-17T04:29:31.200837Z","shell.execute_reply.started":"2021-11-17T04:29:01.85255Z","shell.execute_reply":"2021-11-17T04:29:31.200103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4) bureau balance data","metadata":{}},{"cell_type":"markdown","source":"### Feature engineering\nThis uses 2 tables - **Bureau balance and Bureau data** . Both the tables have been merged and then aggregated to extract features","metadata":{}},{"cell_type":"code","source":"def bureau_bal(bureau_balance_data,bureau_data):\n    \n    bureau_balance_data,bureau_balance_data_cat_columns,all_columns=one_hot_encoding_dataframe(bureau_balance_data)\n    #Aggregate function to be applied on numerical column \n    bureau_balance_agg = {'MONTHS_BALANCE': ['min', 'max','sum']}\n\n    #Aggregate function to be applied on cat column \n    for col in bureau_balance_data_cat_columns:\n        if (col!='SK_BUREAU_ID'):\n            bureau_balance_agg[col] = ['mean']\n\n    bal_agg = bureau_balance_data.groupby(['SK_ID_BUREAU']).agg(bureau_balance_agg)\n    \n    modified_col=[]\n    for col in list(bal_agg.columns):\n        if (col!='SK_BUREAU_ID'):\n            modified_col.append(col[0]+\"_\"+col[1].upper())\n    bal_agg.columns=modified_col\n    \n    bureau_data,bureau_data_cat_columns,all_columns=one_hot_encoding_dataframe(bureau_data)\n\n    bureau_data['SEC_LOAN_COUNT']=(bureau_data[['CREDIT_TYPE_Car loan','CREDIT_TYPE_Loan for the purchase of equipment','CREDIT_TYPE_Mortgage','CREDIT_TYPE_Real estate loan','CREDIT_TYPE_Loan for purchase of shares (margin lending)'\n                         ]]==1).sum(axis=1)\n    \n    bureau_data['UNSEC_LOAN_COUNT']=(bureau_data[[ 'CREDIT_TYPE_Another type of loan',\n       'CREDIT_TYPE_Cash loan (non-earmarked)', 'CREDIT_TYPE_Consumer credit',\n       'CREDIT_TYPE_Credit card', 'CREDIT_TYPE_Interbank credit',\n       'CREDIT_TYPE_Loan for business development',\n       'CREDIT_TYPE_Loan for working capital replenishment',\n       'CREDIT_TYPE_Microloan', 'CREDIT_TYPE_Mobile operator loan',\n       'CREDIT_TYPE_Unknown type of loan']]==1).sum(axis=1)\n    \n    bureau_data['ex_pay'] = bureau_data['AMT_ANNUITY']-bureau_data['AMT_CREDIT_SUM']\n    bureau_data['debt']=bureau_data['AMT_CREDIT_SUM_DEBT']/bureau_data['AMT_CREDIT_SUM']\n    bureau_data['annu_per_cred']=bureau_data['AMT_ANNUITY']/bureau_data['AMT_CREDIT_SUM']\n    \n    for col in bureau_data.columns:\n        if col.startswith('DAYS'):\n            bureau_data[col].replace(365243, np.nan, inplace= True)\n            \n    bureau_data = bureau_data.join(bal_agg, how='left', on=['SK_ID_BUREAU'])\n     \n    bureau_data_agg={}\n    for col in bureau_data.columns:\n        if (col!='SK_ID_CURR' or col!='SK_BUREAU_ID'):\n            bureau_data_agg[col]=['mean']\n            if (col=='AMT_CREDIT_SUM_DEBT') | (col=='AMT_CREDIT_SUM_OVERDUE') | (col=='UNSEC_LOAN_COUNT') |(col=='SEC_LOAN_COUNT'):\n                bureau_data_agg[col]=['sum']\n            if col=='DAYS_CREDIT':\n                bureau_data_agg[col]=['min']\n            if col=='debt':\n                bureau_data_agg[col]=['mean']\n    \n            \n    bureau_agg = bureau_data.groupby('SK_ID_CURR').agg(bureau_data_agg)\n    \n    modified_col=[]\n    for col in list(bureau_agg.columns):\n        modified_col.append(col[0]+\"_\"+col[1].upper())\n    bureau_agg.columns=modified_col\n    \n    bureau_agg['abs_cre_max']=abs(bureau_agg['DAYS_CREDIT_MIN']/365) \n    bureau_agg['cre_max_od_max'] = bureau_data.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].max()\n    bureau_agg['cnt'] = bureau_data.groupby('SK_ID_CURR')['SK_ID_BUREAU'].count()\n    bureau_data_active = bureau_data[bureau_data['CREDIT_ACTIVE_Active'] == 1]\n    \n    bureau_agg['active_cred_mean'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM'].mean()\n    bureau_agg['active_cred_max'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM'].max()\n    bureau_agg['cred_od_mean'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].mean()\n    bureau_agg['cred_od_max'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].max()   \n    bureau_agg['active_cred_debt_mean'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_DEBT'].mean()\n    bureau_agg['active_cred_debt_max'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_DEBT'].max()\n    bureau_agg['active_cred_limit_mean'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_LIMIT'].mean()\n    bureau_agg['active_cred_limit_max'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_LIMIT'].max()\n    bureau_agg['cred_days_mean'] = bureau_data_active.groupby('SK_ID_CURR')['DAYS_CREDIT'].mean()\n    bureau_agg['cred_days_max'] = bureau_data_active.groupby('SK_ID_CURR')['DAYS_CREDIT'].max()  \n    bureau_agg['cred_ed_mean'] = bureau_data_active.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].mean()\n    bureau_agg['cred_ed_max'] = bureau_data_active.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].max()\n    bureau_data_closed = bureau_data[bureau_data['CREDIT_ACTIVE_Closed'] == 1]\n    bureau_agg['cls_cred_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM'].mean()\n    bureau_agg['cls_cred_max'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM'].max()\n    bureau_agg['B_CLO_AMT_CREDIT_MAX_OVERDUE_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].mean()\n    bureau_agg['B_CLO_AMT_CREDIT_MAX_OVERDUE_max'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].max()\n    bureau_agg['cls_cred_d_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_DEBT'].mean()\n    bureau_agg['cls_cred_d_max'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_DEBT'].max()\n    bureau_agg['cls_cred_d_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_LIMIT'].mean()\n    bureau_agg['cls_cred_d_max'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_LIMIT'].max()\n    bureau_agg['cls_credd_ed_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].mean()\n    bureau_agg['cls_credd_ed_max'] = bureau_data_closed.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].max()\n    bureau_agg['cls_credd_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['DAYS_CREDIT'].mean()\n    bureau_agg['cls_credd_max'] = bureau_data_closed.groupby('SK_ID_CURR')['DAYS_CREDIT'].max()\n    bureau_agg.drop(['SK_ID_CURR_MEAN'], axis=1, inplace= True)\n    bureau_agg.drop(['SK_ID_BUREAU_MEAN'], axis=1, inplace= True)\n    \n    \n    return bureau_agg","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:33:01.309437Z","iopub.execute_input":"2021-11-17T04:33:01.309874Z","iopub.status.idle":"2021-11-17T04:33:01.341824Z","shell.execute_reply.started":"2021-11-17T04:33:01.309787Z","shell.execute_reply":"2021-11-17T04:33:01.340518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_bal_data = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau_balance.csv')\nbureau_data = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau.csv')\n\ndf_bureau=bureau_bal(bureau_bal_data,bureau_data)\ndf_bureau =main_df.merge(df_bureau, how='left', on='SK_ID_CURR')\ndf_bureau=df_bureau[df_bureau['TARGET'].notnull()]\n\ny_train=df_bureau['TARGET']\ntrain_column=set(df_bureau.columns)-set(main_df.columns)\nX_train=df_bureau[train_column]\n\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:33:02.325826Z","iopub.execute_input":"2021-11-17T04:33:02.326113Z","iopub.status.idle":"2021-11-17T04:33:36.065921Z","shell.execute_reply.started":"2021-11-17T04:33:02.326081Z","shell.execute_reply":"2021-11-17T04:33:36.065066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf4=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:33:36.067398Z","iopub.execute_input":"2021-11-17T04:33:36.067619Z","iopub.status.idle":"2021-11-17T04:33:36.072252Z","shell.execute_reply.started":"2021-11-17T04:33:36.067593Z","shell.execute_reply":"2021-11-17T04:33:36.07131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf4.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf4.predict_proba(X_train)[:,1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:33:43.736133Z","iopub.execute_input":"2021-11-17T04:33:43.736397Z","iopub.status.idle":"2021-11-17T04:42:53.305646Z","shell.execute_reply.started":"2021-11-17T04:33:43.736369Z","shell.execute_reply":"2021-11-17T04:42:53.304699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Traget values on train data","metadata":{}},{"cell_type":"code","source":"bureau=clf4.predict_proba(X_train)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:42:53.307409Z","iopub.execute_input":"2021-11-17T04:42:53.307629Z","iopub.status.idle":"2021-11-17T04:45:55.315326Z","shell.execute_reply.started":"2021-11-17T04:42:53.307603Z","shell.execute_reply":"2021-11-17T04:45:55.314416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bureau2=bureau_bal(bureau_bal_data,bureau_data)\ndf_bureau2 =test_df.merge(df_bureau2, how='left', on='SK_ID_CURR')\ntest_col=set(df_bureau2.columns)-set(test_df.columns)\nX_test=df_bureau2[test_col]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:45:55.316751Z","iopub.execute_input":"2021-11-17T04:45:55.317124Z","iopub.status.idle":"2021-11-17T04:46:11.067677Z","shell.execute_reply.started":"2021-11-17T04:45:55.317074Z","shell.execute_reply":"2021-11-17T04:46:11.067017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test=X_test.replace([np.inf, -np.inf],np.nan)\ndf_test=imputer1.transform(df_test)\ndf_test=scaler.transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:46:11.069871Z","iopub.execute_input":"2021-11-17T04:46:11.070122Z","iopub.status.idle":"2021-11-17T04:46:11.174946Z","shell.execute_reply.started":"2021-11-17T04:46:11.070092Z","shell.execute_reply":"2021-11-17T04:46:11.173935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target values on test data","metadata":{}},{"cell_type":"code","source":"yp=clf4.predict_proba(df_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:46:11.17631Z","iopub.execute_input":"2021-11-17T04:46:11.176642Z","iopub.status.idle":"2021-11-17T04:46:39.676066Z","shell.execute_reply.started":"2021-11-17T04:46:11.176608Z","shell.execute_reply":"2021-11-17T04:46:39.675282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5) Previous application","metadata":{}},{"cell_type":"markdown","source":"### Feature engineering","metadata":{}},{"cell_type":"code","source":"def prev_appl(prev_df):\n    \n    for col in prev_df.columns:\n        if col.startswith('DAYS'):\n            prev_df[col].replace(365243, np.nan, inplace= True)\n    \n    prev_df['extra_paid'] = prev_df['CNT_PAYMENT']*prev_df['AMT_ANNUITY']-prev_df['AMT_CREDIT']\n    prev_df['to_pay'] = prev_df['CNT_PAYMENT']*prev_df['AMT_ANNUITY']-prev_df['AMT_DOWN_PAYMENT']\n    prev_df['roi'] = (1/prev_df['CNT_PAYMENT'])*(((prev_df['CNT_PAYMENT']*prev_df['AMT_ANNUITY'])/prev_df['AMT_CREDIT'])-1)\n    prev_df['si']= (prev_df['AMT_CREDIT']*prev_df['roi']*prev_df['CNT_PAYMENT'])/100    \n    prev_df['xap']=((prev_df['CODE_REJECT_REASON']=='XAP')).astype(int)\n    prev_df['dp']=(prev_df['AMT_DOWN_PAYMENT']<=(0.40*prev_df['AMT_CREDIT'])).astype(int) \n    prev_df,prev_df_cat_columns,all_columns=one_hot_encoding_dataframe(prev_df)\n   \n    prev_df_agg={}\n    for col in prev_df.columns:\n        if col!='SK_ID_CURR' and col !='SK_ID_PREV':\n            prev_df_agg[col]=['mean']\n        if (col=='DAYS_TERMINATION') | (col=='DAYS_FIRST_DUE') | (col=='DAYS_LAST_DUE') | (col=='AMT_CREDIT') | (col=='AMT_ANNUITY') | (col=='AMT_DOWN_PAYMENT') | (col=='DAYS_LAST_DUE_1ST_VERSION') |(col=='HOUR_APPR_PROCESS_START') :\n            prev_df_agg[col]=['max','mean']\n            \n    prev_agg = prev_df.groupby('SK_ID_CURR').agg(prev_df_agg)\n    \n    modified_col=[]\n    for col in list(prev_agg.columns):\n        modified_col.append(\"PREV_\"+col[0]+\"_\"+col[1].upper())\n    \n    prev_agg.columns=modified_col\n    \n    ref_canc = prev_df[(prev_df['NAME_CONTRACT_STATUS_Refused'] == 1) | (prev_df['NAME_CONTRACT_STATUS_Canceled'] == 1)]\n    prev_agg['cr_cred_mean'] = ref_canc.groupby('SK_ID_CURR')['AMT_CREDIT'].mean()\n    prev_agg['cr_cred_max'] = ref_canc.groupby('SK_ID_CURR')['AMT_CREDIT'].max()\n    prev_agg['cr_int_mean'] = ref_canc.groupby('SK_ID_CURR')['roi'].mean()\n    prev_agg['cr_int_max'] = ref_canc.groupby('SK_ID_CURR')['roi'].max()\n    prev_agg['cr_annu_mean'] = ref_canc.groupby('SK_ID_CURR')['AMT_ANNUITY'].mean()\n    prev_agg['cr_annu_max'] = ref_canc.groupby('SK_ID_CURR')['AMT_ANNUITY'].max()\n    prev_agg['cr_dp_mean'] = ref_canc.groupby('SK_ID_CURR')['AMT_DOWN_PAYMENT'].mean()\n    prev_agg['cr_dp_max'] = ref_canc.groupby('SK_ID_CURR')['AMT_DOWN_PAYMENT'].max()\n    prev_agg['cr_lp_mean'] = ref_canc.groupby('SK_ID_CURR')['to_pay'].mean()\n    prev_agg['cr_lp_max'] = ref_canc.groupby('SK_ID_CURR')['to_pay'].max()\n \n    appr = prev_df[(prev_df['NAME_CONTRACT_STATUS_Approved'] == 1)]\n    prev_agg['va_cred_mean'] = appr.groupby('SK_ID_CURR')['AMT_CREDIT'].mean()\n    prev_agg['va_cred_max'] = appr.groupby('SK_ID_CURR')['AMT_CREDIT'].max()\n    prev_agg['va_annu_mean'] = appr.groupby('SK_ID_CURR')['AMT_ANNUITY'].mean()\n    prev_agg['va_annu_max'] = appr.groupby('SK_ID_CURR')['AMT_ANNUITY'].max()\n    prev_agg['va_dp_mean'] = appr.groupby('SK_ID_CURR')['AMT_DOWN_PAYMENT'].mean()\n    prev_agg['va_int_mean'] = appr.groupby('SK_ID_CURR')['roi'].mean()\n    prev_agg['va_int_max'] = appr.groupby('SK_ID_CURR')['roi'].max()\n    prev_agg['va_dp_max'] = appr.groupby('SK_ID_CURR')['AMT_DOWN_PAYMENT'].max()\n    prev_agg['va_lp_mean'] = appr.groupby('SK_ID_CURR')['to_pay'].mean()\n    prev_agg['va_lp_max'] = appr.groupby('SK_ID_CURR')['to_pay'].max()\n    \n    \n    return prev_agg","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:53:50.188924Z","iopub.execute_input":"2021-11-17T04:53:50.18958Z","iopub.status.idle":"2021-11-17T04:53:50.207053Z","shell.execute_reply.started":"2021-11-17T04:53:50.189529Z","shell.execute_reply":"2021-11-17T04:53:50.206078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prev_data = pd.read_csv('/kaggle/input/home-credit-default-risk/previous_application.csv')\n\ndf_prevapp=prev_appl(prev_data)\ndf_prevapp =main_df.merge(df_prevapp, how='left', on='SK_ID_CURR')\ndf_prevapp=df_prevapp[df_prevapp['TARGET'].notnull()]\n\ny_train=df_prevapp['TARGET']\ntrain_column=set(df_prevapp.columns)-set(main_df.columns)\nX_train=df_prevapp[train_column]\n\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:53:52.25742Z","iopub.execute_input":"2021-11-17T04:53:52.257993Z","iopub.status.idle":"2021-11-17T04:54:36.438303Z","shell.execute_reply.started":"2021-11-17T04:53:52.257945Z","shell.execute_reply":"2021-11-17T04:54:36.437519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf5=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:54:36.440187Z","iopub.execute_input":"2021-11-17T04:54:36.440715Z","iopub.status.idle":"2021-11-17T04:54:36.446454Z","shell.execute_reply.started":"2021-11-17T04:54:36.440669Z","shell.execute_reply":"2021-11-17T04:54:36.445793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf5.fit(X_train,y_train,eval_metric='auc')\n#yp=lgbm_clf.predict(X_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf5.predict_proba(X_train)[:,1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T04:54:36.447585Z","iopub.execute_input":"2021-11-17T04:54:36.448116Z","iopub.status.idle":"2021-11-17T05:07:49.237298Z","shell.execute_reply.started":"2021-11-17T04:54:36.44808Z","shell.execute_reply":"2021-11-17T05:07:49.236324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target values on train data","metadata":{}},{"cell_type":"code","source":"prevapp=clf5.predict_proba(X_train)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:07:49.23957Z","iopub.execute_input":"2021-11-17T05:07:49.239837Z","iopub.status.idle":"2021-11-17T05:10:53.492101Z","shell.execute_reply.started":"2021-11-17T05:07:49.239784Z","shell.execute_reply":"2021-11-17T05:10:53.491266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prevapp2=prev_appl(prev_data)\n\ndf_prevapp2 =test_df.merge(df_prevapp2, how='left', on='SK_ID_CURR')\ntest_col=set(df_prevapp2.columns)-set(test_df.columns)\nX_test=df_prevapp2[test_col]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test=X_test.replace([np.inf, -np.inf],np.nan)\ndf_test=imputer1.transform(df_test)\ndf_test=scaler.transform(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:11:13.3335Z","iopub.execute_input":"2021-11-17T05:11:13.333728Z","iopub.status.idle":"2021-11-17T05:11:13.526182Z","shell.execute_reply.started":"2021-11-17T05:11:13.333703Z","shell.execute_reply":"2021-11-17T05:11:13.525237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Output on test data","metadata":{}},{"cell_type":"code","source":"yp=clf5.predict_proba(df_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:11:13.527547Z","iopub.execute_input":"2021-11-17T05:11:13.527772Z","iopub.status.idle":"2021-11-17T05:11:44.077782Z","shell.execute_reply.started":"2021-11-17T05:11:13.527746Z","shell.execute_reply":"2021-11-17T05:11:44.077048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6) Application train data","metadata":{}},{"cell_type":"markdown","source":"### Feature engineering","metadata":{}},{"cell_type":"markdown","source":"Here the main application table and the test table are combined to do the feature engineering after which they are seperated back to test and train datasets. \nThen the model is trained on the train data and predicted on test data","metadata":{}},{"cell_type":"code","source":"def appl_train_test(app_train,app_test):\n    \n    df=app_train.append(app_test).reset_index()\n        \n    #as 365243 is an outlier\n    df[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n    df['hdwmqy']=(df[['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n       'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n       'AMT_REQ_CREDIT_BUREAU_YEAR']]).sum(axis=1)\n    \n    #Using domain knowledge \n    #time spent in work\n    df['days_work']=df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['days_unemp']=abs(df['DAYS_BIRTH'])-abs(df['DAYS_EMPLOYED'])\n    df['inc_per_price']=df['AMT_INCOME_TOTAL']/df['AMT_GOODS_PRICE']\n    df['cred_per_price']=df['AMT_CREDIT']/df['AMT_GOODS_PRICE']\n    df['ann_per_price']=df['AMT_ANNUITY']/df['AMT_GOODS_PRICE']\n    #percentage income of person and the credit amount\n    df['inc_per'] = df['AMT_INCOME_TOTAL'] / (df['CNT_FAM_MEMBERS']+1)\n    #income per credit\n    df['inc_per_cred'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n    df['emp_per_cred'] = df['DAYS_EMPLOYED']/ df['AMT_CREDIT']  \n\n    #Anually paid amount to amount credited\n    df['pay_rate'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n    df['loan_pay'] = df['AMT_INCOME_TOTAL']-df['AMT_ANNUITY']\n    df['soc_cir']=((df[['OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n       'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']]).sum(axis=1))//4\n    df['mean_eq']=((df[['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n       'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']]).mean(axis=1))    \n    df['contact']=((df[['FLAG_MOBIL', 'FLAG_EMP_PHONE',\n       'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE','FLAG_PHONE','FLAG_EMAIL']]).sum(axis=1))\n    \n    #Creating features from useful features\n    df['ext_mean']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n       'EXT_SOURCE_3']]).mean(axis=1)   \n    df['ext_med']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n       'EXT_SOURCE_3']]).median(axis=1)  \n    df['ext_min']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n       'EXT_SOURCE_3']]).min(axis=1) \n    df['ext_max']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n       'EXT_SOURCE_3']]).max(axis=1)\n\n    df['DOCUMNNET_COUNT']=(df[['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n       'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']]==1).sum(axis=1)\n    \n    df,cal_cols,acols=one_hot_encoding_dataframe(df)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:18:16.113638Z","iopub.execute_input":"2021-11-17T05:18:16.113978Z","iopub.status.idle":"2021-11-17T05:18:16.128454Z","shell.execute_reply.started":"2021-11-17T05:18:16.11394Z","shell.execute_reply":"2021-11-17T05:18:16.127264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtrain=pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\ndtest=pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')\n\ndf=appl_train_test(dtrain,dtest)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:18:18.008668Z","iopub.execute_input":"2021-11-17T05:18:18.009465Z","iopub.status.idle":"2021-11-17T05:18:27.169882Z","shell.execute_reply.started":"2021-11-17T05:18:18.009418Z","shell.execute_reply":"2021-11-17T05:18:27.168973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting back to test and train data","metadata":{}},{"cell_type":"code","source":"train_data_df=df[df['TARGET'].notnull()]\ntrain_column=set(train_data_df.columns)-set({'TARGET','index','SK_ID_CURR'})","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:18:27.171366Z","iopub.execute_input":"2021-11-17T05:18:27.171649Z","iopub.status.idle":"2021-11-17T05:18:27.597468Z","shell.execute_reply.started":"2021-11-17T05:18:27.171619Z","shell.execute_reply":"2021-11-17T05:18:27.596582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_df=df[df['TARGET'].isnull()]\ntest_column=set(test_data_df.columns)-set({'SK_ID_CURR','TARGET','index'})","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:18:27.598638Z","iopub.execute_input":"2021-11-17T05:18:27.598873Z","iopub.status.idle":"2021-11-17T05:18:27.627085Z","shell.execute_reply.started":"2021-11-17T05:18:27.598843Z","shell.execute_reply":"2021-11-17T05:18:27.626494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ytrain to train the model\ny_train=train_data_df['TARGET']\nlen(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:18:27.628382Z","iopub.execute_input":"2021-11-17T05:18:27.629032Z","iopub.status.idle":"2021-11-17T05:18:27.635027Z","shell.execute_reply.started":"2021-11-17T05:18:27.629Z","shell.execute_reply":"2021-11-17T05:18:27.634339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=train_data_df[train_column]\nfrom sklearn.impute import SimpleImputer\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\n\nscaler = MinMaxScaler(feature_range = (0, 1))\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:19:52.176561Z","iopub.execute_input":"2021-11-17T05:19:52.177086Z","iopub.status.idle":"2021-11-17T05:20:04.7125Z","shell.execute_reply.started":"2021-11-17T05:19:52.177036Z","shell.execute_reply":"2021-11-17T05:20:04.711386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The main table has almost 200 columns after feature engineering. Other tables has lesser features and could be trained in 20minutes. However since the training time for this table would take a lot of time we decided to use lightgbm with default parameters.","metadata":{}},{"cell_type":"code","source":"lgbm_clf = LGBMClassifier(boosting_type= 'goss',\n                          random_state=42,\n                         scale_pos_weight=poswt)\nlgbm_clf.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:20:04.714146Z","iopub.execute_input":"2021-11-17T05:20:04.714456Z","iopub.status.idle":"2021-11-17T05:20:14.539914Z","shell.execute_reply.started":"2021-11-17T05:20:04.714413Z","shell.execute_reply":"2021-11-17T05:20:14.539034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"ROCAUC Score :\",roc_auc_score(y_train,lgbm_clf.predict_proba(X_train)[:,1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:20:14.541448Z","iopub.execute_input":"2021-11-17T05:20:14.541858Z","iopub.status.idle":"2021-11-17T05:20:16.049958Z","shell.execute_reply.started":"2021-11-17T05:20:14.541826Z","shell.execute_reply":"2021-11-17T05:20:16.04903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"prediction on train data","metadata":{}},{"cell_type":"code","source":"\natrain=lgbm_clf.predict_proba(X_train)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:20:16.051252Z","iopub.execute_input":"2021-11-17T05:20:16.051705Z","iopub.status.idle":"2021-11-17T05:20:17.451053Z","shell.execute_reply.started":"2021-11-17T05:20:16.051662Z","shell.execute_reply":"2021-11-17T05:20:17.450371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" prediction on test data","metadata":{}},{"cell_type":"code","source":"X_test=test_data_df[test_column]\nX_test=imputer1.transform(X_test)\nX_test = scaler.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:20:18.981021Z","iopub.execute_input":"2021-11-17T05:20:18.981745Z","iopub.status.idle":"2021-11-17T05:20:19.251976Z","shell.execute_reply.started":"2021-11-17T05:20:18.981696Z","shell.execute_reply":"2021-11-17T05:20:19.250787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp=lgbm_clf.predict_proba(X_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:20:20.12294Z","iopub.execute_input":"2021-11-17T05:20:20.123235Z","iopub.status.idle":"2021-11-17T05:20:20.340733Z","shell.execute_reply.started":"2021-11-17T05:20:20.123199Z","shell.execute_reply":"2021-11-17T05:20:20.340036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the final dataset to train the L1 model using the predictions of target on train data from each table","metadata":{}},{"cell_type":"code","source":"final_df = pd.DataFrame()\nfinal_df.index = main_df['SK_ID_CURR']","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:21:52.70783Z","iopub.execute_input":"2021-11-17T05:21:52.708105Z","iopub.status.idle":"2021-11-17T05:21:52.713406Z","shell.execute_reply.started":"2021-11-17T05:21:52.708076Z","shell.execute_reply":"2021-11-17T05:21:52.712427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df['bal']=cred_bal\nfinal_df['inst']=inst\nfinal_df['pos']=pos\nfinal_df['bureau']=bureau\nfinal_df['prevapp']=prevapp\nfinal_df['train']=atrain","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:22:00.20384Z","iopub.execute_input":"2021-11-17T05:22:00.204563Z","iopub.status.idle":"2021-11-17T05:22:00.216943Z","shell.execute_reply.started":"2021-11-17T05:22:00.204509Z","shell.execute_reply":"2021-11-17T05:22:00.215906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtrain=pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\nls=dtrain['TARGET'].values\nfinal_df['TARGET']=ls","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:22:19.032737Z","iopub.execute_input":"2021-11-17T05:22:19.033196Z","iopub.status.idle":"2021-11-17T05:22:22.627529Z","shell.execute_reply.started":"2021-11-17T05:22:19.033157Z","shell.execute_reply":"2021-11-17T05:22:22.626382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#writing it to a file for future purposes\nfinal_df.to_csv('final-ds.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:22:23.107481Z","iopub.execute_input":"2021-11-17T05:22:23.107756Z","iopub.status.idle":"2021-11-17T05:22:26.133589Z","shell.execute_reply.started":"2021-11-17T05:22:23.107726Z","shell.execute_reply":"2021-11-17T05:22:26.132569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:22:38.406772Z","iopub.execute_input":"2021-11-17T05:22:38.407591Z","iopub.status.idle":"2021-11-17T05:22:38.419387Z","shell.execute_reply.started":"2021-11-17T05:22:38.407554Z","shell.execute_reply":"2021-11-17T05:22:38.418859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Level 1 model**","metadata":{}},{"cell_type":"markdown","source":"### For the L1 model we have choosen to use vanilla artificial neural networks as we need different weights assigned to predictions from different tables to represent the weightage of that table's prediction on the final target and ANN would train do assign weights to each input","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/finaldata/final-train-ds.csv')\ny=df['TARGET']\nx=df.drop(['TARGET','SK_ID_CURR'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:03:11.641164Z","iopub.execute_input":"2021-11-17T06:03:11.641602Z","iopub.status.idle":"2021-11-17T06:03:12.474371Z","shell.execute_reply.started":"2021-11-17T06:03:11.641569Z","shell.execute_reply":"2021-11-17T06:03:12.473564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Importing modules for the model","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:03:15.864024Z","iopub.execute_input":"2021-11-17T06:03:15.864307Z","iopub.status.idle":"2021-11-17T06:03:15.869236Z","shell.execute_reply.started":"2021-11-17T06:03:15.864279Z","shell.execute_reply":"2021-11-17T06:03:15.868219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model building**- We have used only 1 hidden layer to reduce the model complexity and reduce overfitting. The 6 features in each input will be mapped to 6 neurons in the hidden layer and weights will be assigned to them. Activation function used is relu which is a common choice for all hidden layers. The output layer has 1 neuron as we need 1 probablity value. Activation function is sigmoid as the class is binary","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(6, input_dim=6, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:03:22.123559Z","iopub.execute_input":"2021-11-17T06:03:22.123856Z","iopub.status.idle":"2021-11-17T06:03:22.151405Z","shell.execute_reply.started":"2021-11-17T06:03:22.123799Z","shell.execute_reply":"2021-11-17T06:03:22.150495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model compiling** - stocastic gradient descent is the optimiser used, loss is binary cross entrophy as the output class is binary and the preformance metric used is AUC score, same as the metrics used to judge the scores in the competition","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='sgd',\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[tf.keras.metrics.AUC()])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:03:24.34192Z","iopub.execute_input":"2021-11-17T06:03:24.34273Z","iopub.status.idle":"2021-11-17T06:03:24.359464Z","shell.execute_reply.started":"2021-11-17T06:03:24.342691Z","shell.execute_reply":"2021-11-17T06:03:24.358173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It has to be metioned that the distribution of the output classes is not uniform. Lightgbm model has the capablity to assign weights to classes by changing parameters, similarly weights for classes need to be assigned to the Neural network model too. ","metadata":{}},{"cell_type":"code","source":"import sklearn\nclasses_zero = df[df['TARGET'] == 0]\nclasses_one = df[df['TARGET'] == 1]\n\n# Convert parts into NumPy arrays for weight computation\nzero_numpy = classes_zero['TARGET'].to_numpy()\none_numpy = classes_one['TARGET'].to_numpy()\nall_together = np.concatenate((zero_numpy, one_numpy))\nunique_classes = np.unique(all_together)\n\n# Compute weights\nweights = sklearn.utils.class_weight.compute_class_weight('balanced', unique_classes, all_together)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:03:29.779082Z","iopub.execute_input":"2021-11-17T06:03:29.779675Z","iopub.status.idle":"2021-11-17T06:03:29.853464Z","shell.execute_reply.started":"2021-11-17T06:03:29.779619Z","shell.execute_reply":"2021-11-17T06:03:29.852562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:23:37.896641Z","iopub.execute_input":"2021-11-17T05:23:37.897256Z","iopub.status.idle":"2021-11-17T05:23:37.902754Z","shell.execute_reply.started":"2021-11-17T05:23:37.897209Z","shell.execute_reply":"2021-11-17T05:23:37.901879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is more number of instances of class=0 hence it will have a lesser weight than class=1","metadata":{}},{"cell_type":"code","source":"#converting it to a dictionary\nwt={}\nwt[0]=weights[0]\nwt[1]=weights[1]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:32:02.522575Z","iopub.execute_input":"2021-11-17T05:32:02.522921Z","iopub.status.idle":"2021-11-17T05:32:02.52707Z","shell.execute_reply.started":"2021-11-17T05:32:02.522886Z","shell.execute_reply":"2021-11-17T05:32:02.526242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model training** - based on brute force trial, more epoches caused the model to overfit. Upon increasing epoches more than 4 caused the auc score on train data to improve while that of validation reduced","metadata":{}},{"cell_type":"code","source":"train=model.fit(x, y, epochs=3, validation_split = 0.2,class_weight=wt,batch_size=50)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:03:36.832781Z","iopub.execute_input":"2021-11-17T06:03:36.833103Z","iopub.status.idle":"2021-11-17T06:04:01.046295Z","shell.execute_reply.started":"2021-11-17T06:03:36.833067Z","shell.execute_reply":"2021-11-17T06:04:01.045451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the auc score with test split of the train data","metadata":{}},{"cell_type":"markdown","source":"### Preparing the dataset for predicting on test data","metadata":{}},{"cell_type":"code","source":"df1=pd.read_csv('../input/finaltestds/main-appl.csv')\ndf2=pd.read_csv('../input/finaltestds/bureau-bal.csv')\ndf3=pd.read_csv('../input/finaltestds2/cred-b.csv')\ndf4=pd.read_csv('../input/finaltestds/install.csv')\ndf5=pd.read_csv('../input/finaltestds/posapp.csv')\ndf6=pd.read_csv('../input/finaltestds/prev-appl.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:04:11.239175Z","iopub.execute_input":"2021-11-17T06:04:11.239461Z","iopub.status.idle":"2021-11-17T06:04:11.345206Z","shell.execute_reply.started":"2021-11-17T06:04:11.239433Z","shell.execute_reply":"2021-11-17T06:04:11.344554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Merging all predictions of traget from all files","metadata":{}},{"cell_type":"code","source":"ftest=df3.merge(df4,how='left', on='SK_ID_CURR')\nftest=ftest.merge(df5,how='left', on='SK_ID_CURR')\nftest=ftest.merge(df2,how='left', on='SK_ID_CURR')\nftest=ftest.merge(df6,how='left', on='SK_ID_CURR')\nftest=ftest.merge(df1,how='left', on='SK_ID_CURR')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:04:16.472321Z","iopub.execute_input":"2021-11-17T06:04:16.472781Z","iopub.status.idle":"2021-11-17T06:04:16.545472Z","shell.execute_reply.started":"2021-11-17T06:04:16.472733Z","shell.execute_reply":"2021-11-17T06:04:16.544741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=ftest.drop(['SK_ID_CURR'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:04:35.758583Z","iopub.execute_input":"2021-11-17T06:04:35.759032Z","iopub.status.idle":"2021-11-17T06:04:35.765634Z","shell.execute_reply.started":"2021-11-17T06:04:35.758997Z","shell.execute_reply":"2021-11-17T06:04:35.764687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp=model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:04:37.209865Z","iopub.execute_input":"2021-11-17T06:04:37.210133Z","iopub.status.idle":"2021-11-17T06:04:38.243694Z","shell.execute_reply.started":"2021-11-17T06:04:37.210106Z","shell.execute_reply":"2021-11-17T06:04:38.242795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making submissions","metadata":{}},{"cell_type":"markdown","source":"### After getting the target values, it is written into a file to be submitted and get the table's score. \n**It needs to be noted that the next 2 cells will be used for each table as well as the final ensemble model**","metadata":{}},{"cell_type":"code","source":"dtest=pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:04:45.131503Z","iopub.execute_input":"2021-11-17T06:04:45.132299Z","iopub.status.idle":"2021-11-17T06:04:45.65524Z","shell.execute_reply.started":"2021-11-17T06:04:45.132255Z","shell.execute_reply":"2021-11-17T06:04:45.65436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission(x_test, y_test, target):\n    \"\"\"\n    x_test is a dataframe\n    y_test is an array with target values\n    \"\"\"\n    submission = pd.DataFrame()\n    submission.index = dtest['SK_ID_CURR']\n    submission[target] = y_test\n    submission.to_csv('final-new.csv')\n    print(\"Finished writing to submission.csv\")\n    return pd.read_csv('./final-new.csv', index_col=0)\n\ncreate_submission(dtest,yp, 'TARGET')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T06:04:45.67756Z","iopub.execute_input":"2021-11-17T06:04:45.677851Z","iopub.status.idle":"2021-11-17T06:04:45.814663Z","shell.execute_reply.started":"2021-11-17T06:04:45.677817Z","shell.execute_reply":"2021-11-17T06:04:45.813785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thus the final values for TARGET are obtained, and a submission is made","metadata":{}},{"cell_type":"markdown","source":"## Similarly LightGBM was also tried as the L1 model but it did not give a good score","metadata":{}},{"cell_type":"code","source":"fin = LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005134,\n    num_leaves= 54,\n    max_depth= 10,\n    subsample_for_bin= 240000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    colsample_bytree= 0.508716,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    is_unbalance= False,)\n#fin.fit(x,y)\n#print(\"ROCAUC Score :\",roc_auc_score(y_test,fin.predict_proba(x_test)[:,1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T14:25:20.388944Z","iopub.status.idle":"2021-11-14T14:25:20.389634Z","shell.execute_reply.started":"2021-11-14T14:25:20.389382Z","shell.execute_reply":"2021-11-14T14:25:20.389409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#yp=fin.predict_proba(X_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-11-14T14:25:20.390874Z","iopub.status.idle":"2021-11-14T14:25:20.391547Z","shell.execute_reply.started":"2021-11-14T14:25:20.391292Z","shell.execute_reply":"2021-11-14T14:25:20.391319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}