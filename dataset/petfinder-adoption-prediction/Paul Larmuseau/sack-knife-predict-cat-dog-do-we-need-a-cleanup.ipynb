{"cells":[{"metadata":{"_uuid":"ad6a48ec00834546d1979ba8d361a23eb0345bb0"},"cell_type":"markdown","source":"# lets split Cat - Dog\n![https://i5.walmartimages.com/asr/a2f55709-2351-46c9-b0f5-8248e09c6bf6_1.ee5125889d083d7311c70d0783f0b1ee.jpeg?odnHeight=450&odnWidth=450&odnBg=FFFFFF](https://i5.walmartimages.com/asr/a2f55709-2351-46c9-b0f5-8248e09c6bf6_1.ee5125889d083d7311c70d0783f0b1ee.jpeg?odnHeight=450&odnWidth=450&odnBg=FFFFFF)\n\nWanted to know can i predict if its a cat or a dog"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"''' group sum\n'''\n\ndef grouping(df,dtest,grby):\n    agg_col =  df.select_dtypes(include='number').columns.values\n    tot=df.append(test,ignore_index=True)\n    print('stats on',agg_col)\n    for gci in grby:\n    \n        group = tot.groupby(gci)\n        # group count, mean, max, min\n        gCount = group.size()\n        gCount=pd.DataFrame(gCount,columns=[gci+'_count'])\n        gMean = group.mean().rename(columns=lambda s: gci+'_avg.' + s)\n        #print(gMean)\n        gMax = group[agg_col].max().rename(columns=lambda s: gci+'_max.' + s)\n        gMin = group[agg_col].min().rename(columns=lambda s: gci+'_min.' + s)\n        grbij=pd.concat([gCount, gMean, gMax, gMin], axis=1)\n        df=df.merge( grbij,how='left',left_on=gci,right_index=True)\n        dtest=dtest.merge( grbij,how='left',left_on=gci,right_index=True)\n\n    return df,dtest\n\n\n\n\ndef groupvarwithtarget(df,dtest,target):\n    agg_col = [xi for xi in df.select_dtypes(include='number').columns.values if xi not in target]\n    tot=df #.append(test,ignore_index=True)\n    print('stats on',agg_col)\n    for gci in agg_col:\n        if len( tot[gci].unique())<500:\n            group = tot[target+[gci]].groupby(gci)\n            # group count, mean, max, min\n            gCount = group.size()\n            gCount=pd.DataFrame(gCount,columns=[gci+'_count'])\n            gMean = group.mean().rename(columns=lambda s: gci+'_avg.' + s)\n            #print(gMean)\n            gMax = group.quantile(0.75).rename(columns=lambda s: gci+'_max.' + s)\n            gMin = group.min().rename(columns=lambda s: gci+'_min.' + s)\n            grbij=pd.concat([gCount, gMean, gMax, gMin], axis=1)\n            df=df.merge( grbij,how='left',left_on=gci,right_index=True)\n            dtest=dtest.merge( grbij,how='left',left_on=gci,right_index=True)\n\n    return df,dtest\n\n\ndef concatvartotxt(df,dtest,target):\n    agg_col = [xi for xi in df.select_dtypes(include='number').columns.values if xi not in target]\n    train_txt =df.Description.fillna(' ')+' '+df.Name.fillna(' ')+' '\n    test_txt=dtest.Description.fillna(' ')+' '+dtest.Name.fillna(' ')+' '\n    print('stats on',agg_col)\n    for gci in agg_col:\n        if len( df[gci].unique())<500:\n            train_txt+=df[gci].fillna(0).map(str)+gci+' '\n            test_txt+=dtest[gci].fillna(0).map(str)+gci+' '\n    print('concat variables',df.shape,dtest.shape,len(train_txt),len(test_txt))\n    return train_txt,test_txt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"717942d245fd09aafc0d5e7d24e89cfac82a9f3d"},"cell_type":"code","source":"train = pd.read_csv('../input/train/train.csv')\ntest = pd.read_csv('../input/test/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b271ea24df013daaf1a2058d81aaeac99c0704a"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"9935898e71be9b693428dabcdb407106c2673d44"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"830d1dd87e386f9a6080975aee6db93ace977c1b"},"cell_type":"code","source":"import itertools\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nfrom sklearn import datasets\n\n\nfrom mlxtend.plotting import plot_learning_curves\nfrom mlxtend.plotting import plot_decision_regions\n\ndef klassif(Xtrain,Xtes,y):\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.naive_bayes import GaussianNB \n    from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n    from sklearn.neural_network import MLPClassifier\n    from mlxtend.classifier import StackingClassifier\n    from sklearn.svm import SVC\n    from sklearn.model_selection import cross_val_score, train_test_split\n    \n    print('klassify',Xtrain.shape,Xtes.shape,y.shape)\n\n    clf1 = KNeighborsClassifier(n_neighbors=1)\n    clf2 = MLPClassifier(alpha=1,max_iter=400 ) #RandomForestClassifier(random_state=1)\n    clf3 = SVC(kernel=\"linear\", C=0.025,max_iter=400) #GaussianNB()\n    clf4 =ExtraTreesClassifier()\n    lr = LogisticRegression(solver='lbfgs',multi_class='auto')\n    sclf = StackingClassifier(classifiers=[clf1, clf2, clf3,clf4], meta_classifier=lr)\n\n    label = ['KNN', 'MLP', 'SVC', 'Xtree','Stacking Classifier']\n    clf_list = [clf1, clf2, clf3, clf4,sclf]\n    \n    grid = itertools.product([0,1],repeat=2)\n\n    #y=traind.AdoptionSpeed.values\n    clf_cv_mean = []\n    clf_cv_std = []\n    for clf, label, grd in zip(clf_list, label,grid):\n        \n        scores = cross_val_score(clf, Xtr[:len(y)], y, cv=3, scoring='accuracy')\n        print ( \"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label) )\n        \n        clf.fit(Xtrain[:len(y)], y)\n    return pd.DataFrame( clf.predict(Xtes),index=Xtes.index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3be6f164a18c582e32e1d86887a0172ac63a832"},"cell_type":"code","source":"#train = pd.read_csv('../input/train/train.csv')\n#test = pd.read_csv('../input/test/test.csv')\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\n\ndef textmatrix(train1,test1,ncomp):\n    \n    #train_desc,test_desc=concatvartotxt(train1,test1,['AdoptionSpeed','demand'])\n    train_desc,test_desc=concatvartotxt(train1,test1,['Type','AdoptionSpeed'])\n    #print(train_desc[0])\n\n    tfv = TfidfVectorizer(min_df=3,  max_features=50000,\n            strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n            ngram_range=(1, 1), use_idf=1, smooth_idf=1, sublinear_tf=1,\n            stop_words = 'english')\n    #tfv= CountVectorizer()\n\n    # Fit TFIDF\n    #tfv.fit(train_desc)\n    X =  tfv.fit_transform(train_desc.append(test_desc))\n    #svd\n    svd = TruncatedSVD(n_components=ncomp)\n    Xtr = svd.fit_transform(X)\n    print(svd.explained_variance_ratio_.sum())\n    print(svd.explained_variance_ratio_)\n    \n    Xtra = pd.DataFrame(Xtr[:len(train1)], columns=['svd_{}'.format(i) for i in range(ncomp)])\n    Xtes = pd.DataFrame(Xtr[len(train1):], columns=['svd_{}'.format(i) for i in range(ncomp)],index=test1.index)\n    print('tfidf-svd',train1.shape,Xtra.shape,test1.shape,Xtes.shape)\n    return Xtra,Xtes\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7d326d2b8cfe55a1d0fab5ed5d5b426bc22ba15"},"cell_type":"code","source":"def sentimentcatch(train,test,train_id,test_id):\n    import json\n\n    doc_sent_mag = []\n    doc_sent_score = []\n    nf_count = 0\n    for pet in train_id:\n        try:\n            with open('../input/train_sentiment/' + pet + '.json', 'r') as f:\n                sentiment = json.load(f)\n            doc_sent_mag.append(sentiment['documentSentiment']['magnitude'])\n            doc_sent_score.append(sentiment['documentSentiment']['score'])\n        except FileNotFoundError:\n            nf_count += 1\n            doc_sent_mag.append(-1)\n            doc_sent_score.append(-1)\n\n    train.loc[:, 'doc_sent_mag'] = doc_sent_mag\n    train.loc[:, 'doc_sent_score'] = doc_sent_score\n\n    doc_sent_mag = []\n    doc_sent_score = []\n    nf_count = 0\n    for pet in test_id:\n        try:\n            with open('../input/test_sentiment/' + pet + '.json', 'r') as f:\n                sentiment = json.load(f)\n            doc_sent_mag.append(sentiment['documentSentiment']['magnitude'])\n            doc_sent_score.append(sentiment['documentSentiment']['score'])\n        except FileNotFoundError:\n            nf_count += 1\n            doc_sent_mag.append(-1)\n            doc_sent_score.append(-1)\n\n    test.loc[:, 'doc_sent_mag'] = doc_sent_mag\n    test.loc[:, 'doc_sent_score'] = doc_sent_score\n    return train,test\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d39690dae4e21b3f0d925bdf0546c0493d4df92f"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"33bc3a324316a1d5485463f4e82418c95008be67"},"cell_type":"code","source":"trainc=train[train['Type']==2]\ntraind=train[train['Type']==1]\ntestc=test[test['Type']==2]\ntestd=test[test['Type']==1]\nprint(trainc.shape,testc.shape,traind.shape,testd.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2b6a0d5fc99c4164552f3759b889dafa8e14771"},"cell_type":"markdown","source":"# 95% correct forecast pure on txt+features textified tfidf\nthats disappointing..."},{"metadata":{"trusted":true,"_uuid":"7b13a549582d6c920df877422ab4350cad81cb6d","scrolled":true},"cell_type":"code","source":"Xtr,Xtest=textmatrix(train,test,300)\npred=klassif(Xtr,Xtest,train.Type.values)\nprint ('Predicition accuracy cat dog txt',(pred[0]==test.Type).mean() )\npred['PetID']=test['PetID']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"414e766cb277a22e1eb815f88cdaee0eed865154"},"cell_type":"code","source":"print(numcol)\nprint( train[train['Name'].map(lambda x: str(x)[:4])=='Mama']['Name'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"586ebcb62bb676ccf58de93c494da897b54bdffb"},"cell_type":"code","source":"Xtr1,Xtest1=sentimentcatch(train,test,train.PetID,test.PetID)\nnumcol = [xi for xi in test.select_dtypes(include='number').columns.values if xi not in ['Type']]\npred=klassif(Xtr1[numcol],Xtest1[numcol],train.Type.values)\nprint ('Predicition accuracy cat dog txt',(pred[0]==test.Type).mean() )\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5169b6bb9601913fa7a1c52be71a8869d74cde7e"},"cell_type":"markdown","source":"# 98.8% accurate prediction with features\n\nimpressive, but not suprising since the 'breed' should correlate with the type.."},{"metadata":{"trusted":true,"_uuid":"0b2e8c9fd36bb055c209d22fd3b0313fa8de3684"},"cell_type":"code","source":"numcol = [xi for xi in test.select_dtypes(include='number').columns.values if xi not in ['Type']]\npred=klassif(train[numcol],test[numcol],train.Type.values)\nprint ('Predicition accuracy cat dog features',(pred[0]==test.Type).mean() )\npred=klassif(train[['Breed1','Breed2']],test[['Breed1','Breed2']],train.Type.values)\nprint ('Predicition accuracy cat dog features',(pred[0]==test.Type).mean() )\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7ccdd1620f3228a74e7ddc3efd87d90212701b7"},"cell_type":"markdown","source":" ![https://cdn3-www.dogtime.com/assets/uploads/gallery/affenpinscher-dog-breed-pictures/10-floorhappy.jpg](https://cdn3-www.dogtime.com/assets/uploads/gallery/affenpinscher-dog-breed-pictures/10-floorhappy.jpg)\n# WTF... now i understand why this database is so unpredictable there are as in all databases messy records\n\n\n* take 0, three times an affenpÃ®ncher classified as cat... O Actually there is no affenpincher, the field Breed2 is filled instead of Breed1, and the class 0 shouldn't exist... or filled with Nan...\n* what is that class 307  mixed breed ?? an 6/15 40% of the animals are mixedbreed\n* there are animals where the type (dog cat) does not collide with the type in the database\n"},{"metadata":{"trusted":true,"_uuid":"a128398f43f348d6aab267b7aea557365fbfcac6"},"cell_type":"code","source":"train[['Breed1','Type','Quantity']].groupby(['Breed1','Type']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74149a566e31d9383b00153dcf56f0e82cceaa96"},"cell_type":"code","source":"# test is ill in the same bed\ntest[['Breed1','Type','Quantity']].groupby(['Breed1','Type']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a4a967f69d1a839fc979c70d5db0d715193a66f"},"cell_type":"code","source":"breed = pd.read_csv('../input/breed_labels.csv')\n\ntrainbr=train.merge(breed,how='left',left_on='Breed1',right_on='BreedID',suffixes=('','_br'))\ntrainbr[trainbr.Type*1!=trainbr.Type_br].sort_values('Breed1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a8fcaae85f27b0557ad4166ca46a9b1e60be8fd"},"cell_type":"markdown","source":"# Database wise there are 17/15000 records wrong... thas 0.1% \nso we are forecasting 10x worser then reality...\n"},{"metadata":{"trusted":true,"_uuid":"ade64faf7cf5a80ba13833823f41b3566a19ab46"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}