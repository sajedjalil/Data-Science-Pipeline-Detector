{"cells":[{"cell_type":"markdown","metadata":{},"source":"### Table of Contents\n- [Getting started](#Getting-Started)\n    - [Set score baseline](#Set-score-baseline)\n    - [Sampling](#Sampling)\n    - [Feature selection](#Feature-selection)\n- [Feature by Feature Exploration](#Feature-by-Feature-Exploration)\n    - [Type](#Type)\n    - [Photo](#Photo)\n    - Video\n    - Description\n    - Quantity\n    - Age\n    - Health\n    - Breed\n    - Color\n    - Size\n    - Fur\n    - Gender\n    - State\n    - Rescuer\n- External Data\n    - PetFinder.com (vs .my)\n    - What breeds are good with...\n- Model Tweaking"},{"cell_type":"markdown","metadata":{},"source":"# Getting Started"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":"# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import RandomOverSampler\nimport warnings\nimport json\nimport os\n\n# Options\nwarnings.filterwarnings(action='ignore')\nsns.set_palette('YlGnBu')\n%config InlineBackend.figure_format='retina'"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":"def reset_dfs():\n    global train_df, test_df\n    train_df = pd.read_csv('../input/train/train.csv')\n    test_df = pd.read_csv('../input/test/test.csv')\nreset_dfs()"},{"cell_type":"markdown","metadata":{},"source":"## Set score baseline\nLet's put the cart before the horse. \nLet's get our data cleaning and feature building pipeline set up so that as we can progressively validate our hypotheses moving forward. \n\nThe idea here is to produce the simplest, most basic predictions to use as a starting point for the rest of the process of score improvement. \n\n#### Explore the accompanying script, which contains the resulting data cleaning / feature building functions: \nhttps://www.kaggle.com/alhankeser/slow-and-steady-feature-building\n\nAccording to the competition details, the evaluation metric is a **quadratic weighted kappa**, which sounds super complicated. Luckily, there is a function that I found [here](https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/quadratic_weighted_kappa.py) and that is used in few kernels. \n\n**Baseline Local Score: 0.07917**  \nLeaderboard Score: 0.090  \nhttps://www.kaggle.com/alhankeser/slow-and-steady-feature-building?scriptVersionId=9976702"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"'''\nScore:  0.07917\n   AdoptionSpeed  Type_2\n0              2       1\n1              0       1\n''';"},{"cell_type":"markdown","metadata":{},"source":"## Sampling\nIn typical beginner fashion, I'm going to use a new and shiny strategy that I just learned about [here](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets): sampling to overcome issues related to imbalances in the target feature counts.\n\n**Is there an imbalance in the target feature?**"},{"cell_type":"code","execution_count":4,"metadata":{"scrolled":false},"outputs":[],"source":"reset_dfs()\nplt.figure(figsize=(8,5))\nsns.countplot(train_df['AdoptionSpeed']);"},{"cell_type":"code","execution_count":5,"metadata":{"scrolled":false},"outputs":[],"source":"g = sns.catplot(\"AdoptionSpeed\", col=\"Type\",\n                hue=\"Gender\", data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"markdown","metadata":{},"source":"It appears that there is a low proportion of pets who are adopted on the day they was listed on PetFinder.\n\nLet's look into a few oversampling strategies to address the problem statement described [here](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets). \n\n### df.sample()\nThere is a built-in pandas method to quickly under- or over-sample.  \nBelow, I've created a funtion to take a list of lists that contain the target values to resample from/to.  \nThe first item in each list is the target value being sample, either under or over, depending on whether there are more or less of the second item in each list. "},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"def sample(df, target_val_sets):\n    for target_val_set in target_val_sets:\n        df_class_0 = df[df['AdoptionSpeed'] == target_val_set[0]]\n        count_1 = df['AdoptionSpeed'].value_counts()[target_val_set[1]]\n        df_class_0_sampled = df_class_0.sample(count_1,replace='True')\n        df = pd.merge(df.drop(df_class_0.index),\n                      df_class_0_sampled, how='outer')\n    return df\n\n# Over sample where AdoptionSpeed == 0, to match the count of AdoptionSpeed == 1\ntrain_df = sample(train_df, [[0, 1]])"},{"cell_type":"code","execution_count":7,"metadata":{"scrolled":true},"outputs":[],"source":"# Note how counts of 0 and 1 now match:\nsns.countplot(train_df['AdoptionSpeed']);"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"g = sns.catplot(\"AdoptionSpeed\", col=\"Type\",\n                hue=\"Gender\", data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"markdown","metadata":{},"source":"**What effect does randomly sampling using the pandas .sample() method have on our current local score**?  \nCurrent Baseline: 0.07924  \nNew Score:  0.09349  \nhttps://www.kaggle.com/alhankeser/slow-and-steady-feature-building?scriptVersionId=9976791  "},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"'''\nScore:  0.09349\n   AdoptionSpeed  Type_2\n0              2       1\n1              3       0\n''';"},{"cell_type":"markdown","metadata":{},"source":"### RandomOverSampler()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"X = train_df.drop('AdoptionSpeed', axis=1)\ny = train_df['AdoptionSpeed']\nfrom imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler(sampling_strategy='minority',\n                                    random_state=1)\nX_ros, y_ros = ros.fit_sample(X, y)\n\nprint(X_ros.shape[0] - X.shape[0], 'new randomly picked points')"},{"cell_type":"code","execution_count":11,"metadata":{"scrolled":false},"outputs":[],"source":"resampled_df = pd.DataFrame(list(X_ros), columns=train_df.drop('AdoptionSpeed', axis=1).columns)\nresampled_df['AdoptionSpeed'] = list(y_ros)\nresampled_df.head(2)"},{"cell_type":"markdown","metadata":{},"source":"What is different here is that the minority ('AdoptionSpeed' == 0) is getting oversampled to match ('AdoptionSpeed' == 4). Not sure if that is good or bad..."},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"sns.countplot(resampled_df['AdoptionSpeed']);"},{"cell_type":"code","execution_count":13,"metadata":{"scrolled":false},"outputs":[],"source":"sns.catplot(\"AdoptionSpeed\", col=\"Type\",\n                hue=\"Gender\", data=resampled_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"markdown","metadata":{},"source":"That certainly did *something*, right?  \nLet's check our local score. \n\n**What effect does random over-sampling with imbalanced-learn affect have on our local score?**  \nWhat effect does randomly sampling using the pandas .sample() method have on our current local score?  \nCurrent Baseline: 0.09349  \nNew Local Score: 0.12413  \nLeaderboard Score: 0.086  \nhttps://www.kaggle.com/alhankeser/slow-and-steady-feature-building?scriptVersionId=9977273"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"'''\nScore:  0.12413\n   AdoptionSpeed  Type_2\n0              2       1\n1              0       1\n\n''';"},{"cell_type":"markdown","metadata":{},"source":"Sampling at this point may not be the right strategy as it will be difficult to asses its value, given that we have not necessarily provided the random oversampler with much to go by. Increasing the number of samples with only \"Type\" as a feature may reduce accuracy rather than improve it. "},{"cell_type":"markdown","metadata":{},"source":"### Feature selection\nYou may have noticed that we have only one feature that we're using to build our model (Type == 2).  \n\nObviously, we could do with more and get a better score, before even engineering anything new.  \n\nWhat would be nice if we build in some forward feature selection into our workflow so that as we engineer features, we find out if they make the cut or not! (I could be totally wrong here, but come along for the ride anyway)  \nhttps://www.kdnuggets.com/2018/06/step-forward-feature-selection-python.html"},{"cell_type":"markdown","metadata":{},"source":"# Feature by Feature Exploration"},{"cell_type":"markdown","metadata":{},"source":"## Starting to form hypotheses\nIt's easy to jump straight into \"building\" features before thinking through the bigger picture.  \n\nIn this case, it might be a literal picture, since animal photos could very well be the big feature. \n\nBefore jumping into the data, it's useful to take a look at mypetfinder.my to see what features standout as means by which visitors would go about narrowing their options and choosing a pet to adopt. \n\n**What comes across in looking at petfinder.my:**\n- **Insight:** Photos are presented as the primary means to navigate the website.\n    - **So what:** this feature could override other attributes as a predictor for adoption speed. \n- **Insight:** Filtering is quite challenging and hidden. \n    - **So what:** attributes that may *appear* important to us, may not be part of the typical visitor's journey on the website and therefore may not be playing a major role in adoption speeds. \n- **Insight:** Once on a pet detail page, additional photos are found at the bottom (and not easily scannable at top)\n    - **So what:** The first photo may be playing an outsized role. If there's a way to infer what the first photo in the pet's list of photos is, that might be the one to focus on. \n\n**Who would you rather adopt?**\nSome pets might be the ideal breed, in perfect health and just the right age, but if their photo(s) don't do them justice, then they may have a slow adoption speed. "},{"cell_type":"markdown","metadata":{},"source":"Peak Cuteness | Maybe Cute\n- | -\n![Dog 1](../input/train_images/0a9f9f178-7.jpg) | ![Dog 2](../input/train_images/0b3deeb66-2.jpg)\n![Cat 1](../input/train_images/0a7798d2b-8.jpg ) | ![Cat 2](../input/train_images/0a2073b86-2.jpg)"},{"cell_type":"markdown","metadata":{},"source":"## Type"},{"cell_type":"markdown","metadata":{},"source":"## Photo  \n\nQuestions: \n- Is there a way to tell if photos are of good or bad quality? \n- If we can do the above, does it seem to make a difference on speed of adoption?\n- Do most pets have photos? If they don't does it make a big difference? \n- Does it matter if pets have many photos? Too few? "},{"cell_type":"markdown","metadata":{},"source":"Let's get a better understanding of what a \"good\" photo looks like, according to Google's Vision API.\n\nHere is a pretty good image that we could consider as \"good\": \n![Dog 1](../input/train_images/0a9f9f178-7.jpg)"},{"cell_type":"markdown","metadata":{},"source":"What does Google think this photo is about? "},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":"score = 0\nwith open('../input/train_metadata/0a9f9f178-7.json') as f:\n    good_image = json.load(f)\nfor label in good_image['labelAnnotations']:\n    if label['description'] == 'dog':\n        score = label['score']\nprint(score)"},{"cell_type":"markdown","metadata":{},"source":"Let's get a better understanding of what a \"not good\" photo looks like, according to Google's Vision API.\n\nHere is a not so great image that we could consider as \"not so good\": \n![Dog 2](../input/train_images/0b3deeb66-2.jpg)"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":"score = 0\nwith open('../input/train_metadata/0b3deeb66-2.json') as f:\n    good_image = json.load(f)\nfor label in good_image['labelAnnotations']:\n    if label['description'] == 'dog':\n        score = label['score']\nprint(score)"},{"cell_type":"markdown","metadata":{},"source":"The second image did worse than I had expected! Turns out the closest label to \"dog\" is the following: "},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":"{\n    \"description\": \"dog like mammal\",\n    \"score\": 0.77083683,\n};"},{"cell_type":"markdown","metadata":{},"source":"**Watch out:** The latest version of the Google Vision API may have gotten better at labeling images. Running a few of these image through [this page](https://cloud.google.com/vision/) resulted in more precise scores.  "},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":"def get_photo_score(x, match='exact', start=1, stop=2, multiple=False):\n    pet_id = x\n    pet_type = train_df[train_df['PetID'] == pet_id]['Type'].values[0]\n    pet_type_dict = {1: 'dog', 2: 'cat'}\n    pet_type = pet_type_dict[pet_type]\n    scores = []\n    score = 0\n    i = start\n    while (i > 0) & (i < stop):\n        json_file = '../input/train_metadata/' + pet_id + '-' + str(i) + '.json'\n        if os.path.isfile(json_file):\n            with open(json_file) as f:\n                try:\n                    image_data = False\n                    image_data = pd.DataFrame(json.load(f)['labelAnnotations'])\n                except Exception:\n                    pass\n            try:\n                if match == 'exact':\n                    scores.append(image_data[image_data['description'] == pet_type]['score'].values[0])\n                if match == 'contains':\n                    scores.append(image_data[image_data['description'].str.contains(pet_type)]['score'].values.max())\n            except Exception:\n                scores.append(.0)\n                pass\n            i += 1\n        else:\n            break\n    try:\n        if not multiple:\n            if (stop-start) > 1:\n                score = np.array(scores).mean()\n            if (stop-start) == 1:\n                score = np.array(scores).max()\n        if multiple:\n            score = np.array(scores)\n    except Exception:\n        pass\n    return score\n\ntrain_df['FirstPhotoScore'] = train_df['PetID'].apply(lambda x: get_photo_score(x, match='exact', start=1, stop=2, multiple=False))"},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":"train_df['FirstPhotoScore > 0'] = train_df['FirstPhotoScore'] > 0\n\nsns.catplot(\"AdoptionSpeed\", col=\"Type\",\n                hue=\"FirstPhotoScore > 0\", data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":219,"metadata":{},"outputs":[],"source":"def group_photo_score(x):\n    score = x['FirstPhotoScore']\n    pet_type = x['Type']\n    if pet_type == 1:\n        good_threshold = 0.96\n    if pet_type == 2:\n        good_threshold = 0.99\n    if score > good_threshold: \n        return 'Good'\n    if (score < good_threshold) & (score > .5): \n        return 'Okay'\n    return 'Not Great'\ntrain_df['FirstPhotoScoreRange'] = train_df[['Type','FirstPhotoScore']].apply(lambda x: group_photo_score(x), axis=1)\n\nsns.catplot(\"AdoptionSpeed\", col=\"FirstPhotoScoreRange\",\n             data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":"train_df['AllPhotoScores'] = train_df['PetID'].apply(lambda x: get_photo_score(x, match='exact', start=1, stop=99, multiple=False))"},{"cell_type":"code","execution_count":203,"metadata":{"scrolled":false},"outputs":[],"source":"def mean_photo_score(x):\n    mean_score = x['AllPhotoScore'] / x['PhotoAmt']\n    pet_type = x['Type']\n    if pet_type == 1:\n        good_threshold = 0.96\n    if pet_type == 2:\n        good_threshold = 0.99\n    if mean_score > good_threshold: \n        return 'Good'\n    if (mean_score < good_threshold) & (mean_score > 0): \n        return 'Okay'\n    return 'Not Great'\n\ntrain_df['AllPhotoScoreRange'] = train_df[['AllPhotoScore', 'PhotoAmt', 'Type']].apply(lambda x: mean_photo_score(x), axis=1)\n\nsns.catplot(\"AdoptionSpeed\", col=\"AllPhotoScoreRange\",\n                 data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":"train_df['AllPhotoScoresList'] = train_df['PetID']\\\n    .apply(lambda x: get_photo_score(x, match='exact', start=1, stop=99, multiple=True))"},{"cell_type":"code","execution_count":209,"metadata":{},"outputs":[],"source":"train_df['AllPhotoScoresList'].head()"},{"cell_type":"code","execution_count":204,"metadata":{"scrolled":false},"outputs":[],"source":"def count_good_photos(x):\n    count = 0\n    pet_type = x['Type']\n    if pet_type == 1:\n        good_threshold = 0.96\n    if pet_type == 2:\n        good_threshold = 0.99\n    try:\n        count = len(x[x > good_threshold])\n    except Exception:\n        pass\n    if count > 2:\n        count = '> 3'\n    return count\n\ntrain_df['GoodPhotos'] = train_df[['Type', 'AllPhotoScoresList']].apply(lambda x: count_good_photos(x), axis=1)\n\nsns.catplot(\"AdoptionSpeed\", col=\"GoodPhotos\",\n                 data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":213,"metadata":{},"outputs":[],"source":"def count_secondary_good_photos(x):\n    count = 0\n    pet_type = x['Type']\n    scores = x['AllPhotoScoresList']\n    if pet_type == 1:\n        good_threshold = 0.96\n    if pet_type == 2:\n        good_threshold = 0.99\n    try:\n        scores = scores[1:]\n        count = len(scores[scores > good_threshold])\n    except Exception:\n        pass\n    if count > 2:\n        return 'Good'\n    if count > 0:\n        return 'Okay'\n    return 'Not Great'\n\ntrain_df['GoodSecondaryPhotos'] = train_df[['AllPhotoScoresList', 'Type']].apply(lambda x: count_secondary_good_photos(x), axis=1)\n\nsns.catplot(\"AdoptionSpeed\", col=\"GoodSecondaryPhotos\",\n                 data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":216,"metadata":{},"outputs":[],"source":"train_df['FirstAndSecondaryPhotos'] =  train_df['FirstPhotoScoreRange'] + '__' + train_df['GoodSecondaryPhotos']"},{"cell_type":"code","execution_count":221,"metadata":{},"outputs":[],"source":"sns.catplot(\"AdoptionSpeed\", col=\"FirstAndSecondaryPhotos\",col_wrap=4,\n                 data=train_df[train_df['FirstPhotoScoreRange'] == 'Good'],\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":222,"metadata":{},"outputs":[],"source":"sns.catplot(\"AdoptionSpeed\", col=\"FirstAndSecondaryPhotos\",col_wrap=4,\n                 data=train_df[train_df['FirstPhotoScoreRange'] == 'Okay'],\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":223,"metadata":{},"outputs":[],"source":"sns.catplot(\"AdoptionSpeed\", col=\"FirstAndSecondaryPhotos\",col_wrap=4,\n                 data=train_df[train_df['FirstPhotoScoreRange'] == 'Not Great'],\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[],"source":"scores = np.array([34,33,23234,12,45,456,454,6,6])"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"with open('../input/train_metadata/0a9f9f178-7.json') as json_file:\n    json_text = json.load(json_file)"},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":"image_data = pd.DataFrame(json_text['labelAnnotations']).drop(['mid', 'topicality'], axis=1).rename({'description': 'Description', 'score': 'Score'}, axis=1)"},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":"image_data['PetID'] = '0a9f9f178'"},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":"image_data['ImageID'] = 1"},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":"image_data"},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":"file_name = '0a9f9f178-7.json'"},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":"file_name.split('-')[0]"},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":"int(file_name.split('-')[1].split('.')[0])"},{"cell_type":"code","execution_count":112,"metadata":{"scrolled":true},"outputs":[],"source":"def image_data_matches(df, images_df):\n    return len(set(images_df['PetID'].unique()) - set(train_df['PetID'].unique())) == 0\n\ndef create_image_df(df, images_df_file_name):\n    print('Building new image data csv...', df.name)\n    json_folder_path = path + '/input/' + df.name + '_metadata/'\n    json_files = [f_name for f_name in os.listdir(json_folder_path)\n                  if f_name.endswith('.json')]\n    pet_type_dict = {1: 'dog', 2: 'cat'}\n    all_images_list = []\n    for index, f_name in enumerate(json_files):\n        with open(os.path.join(json_folder_path, f_name)) as json_file:\n            json_text = json.load(json_file)\n            try:\n                label_annotations = json_text['labelAnnotations']\n            except:\n                continue\n            image_data = pd.DataFrame(label_annotations)\\\n                .drop(['mid', 'topicality'], axis=1)\\\n                .rename({'description': 'Description',\n                         'score': 'Score'},\n                        axis=1)\n            pet_id = f_name.split('-')[0]\n            image_data['PetID'] = pet_id\n            image_data['ImageID'] = int(f_name.split('-')[1].split('.')[0])\n            image_data['PetLabel'] = pet_type_dict[df[df['PetID'] == pet_id]['Type'].values[0]]\n        all_images_list.append(image_data)\n    images_df = pd.concat(all_images_list)\n    images_df.to_csv(images_df_file_name, index=False)\n    return images_df\n\ndef get_image_data(df, force_new_csv=False):\n    images_df_file_name = path + '/' + df.name + '_image_data.csv'\n    try:\n        images_df = pd.read_csv(images_df_file_name)\n        no_image_file = False\n    except Exception:\n        no_image_file = True\n    if no_image_file or force_new_csv or not image_data_matches(df, images_df):\n        images_df = create_image_df(df, images_df_file_name)\n    return images_df\n\ndef rate_image(x):\n    pet_label = x['PetLabel']\n    score = x['Score']\n    if pet_label == 'dog':\n        good_threshold = 0.96\n    if pet_label == 'cat':\n        good_threshold = 0.99\n    if score > good_threshold:\n        return 2\n    return 1\n    \ndef cap_max_image_rating(x):\n    if x > 2:\n        return 2\n    return x\n        \ndef append_image_data(df):\n    images_df = get_image_data(df)\n    images = images_df[(images_df['PetLabel'] == images_df['Description'])]\\\n                             [['PetID','Score','PetLabel', 'ImageID']]\n    images['ImageRating'] = images[['PetLabel', 'Score']].apply(lambda x: rate_image(x), axis=1)\n    first_images = images[images['ImageID'] == 1][['PetID', 'ImageRating']]\n    first_images.rename({'ImageRating': 'FirstImageRating'}, axis=1, inplace=True)\n    second_images = images[(images['ImageID'] > 1) & (images['ImageRating'] > 1)].groupby('PetID')['ImageRating'].count().reset_index()\n    second_images.rename({'ImageRating': 'SecondImageRating'}, axis=1, inplace=True)\n    second_images['SecondImageRating'] = second_images['SecondImageRating'].apply(lambda x: cap_max_image_rating(x))\n    image_ratings = pd.merge(first_images, second_images, on='PetID', how='left')\n    df = pd.merge(df, image_ratings[['PetID', 'FirstImageRating', 'SecondImageRating']], on='PetID', how='left')\n    df['FirstImageRating'].fillna(0, inplace=True)\n    df['SecondImageRating'].fillna(0, inplace=True)\n    df['TotalImageRating'] = df['FirstImageRating'] + (df['SecondImageRating'] * .1)\n    df.loc[df['TotalImageRating'] == 1.0, 'TotalImageRating'] = 0.0\n    df.loc[(df['TotalImageRating'] == 1.2) | \n           (df['TotalImageRating'] == 1.1), 'TotalImageRating'] = 1.0\n    df.loc[df['TotalImageRating'] == 2.1, 'TotalImageRating'] = 2.0\n    df.loc[df['TotalImageRating'] == 2.2, 'TotalImageRating'] = 3.0\n    return df\n\nreset_dfs()\n\ntrain_df.name = 'train'\ntest_df.name = 'test'\n\ntrain_df = append_image_data(train_df)\ntest_df = append_image_data(test_df)\n\ntrain_df.columns"},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":"images_df = pd.read_csv('../train_image_data.csv')\nlen(set(images_df['PetID'].unique()) - set(train_df['PetID'].unique()))\n\ntrain_df_copy = train_df.copy()"},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":"image_ratings = pd.DataFrame(columns=['PetID', 'ImageRating'])\nimage_ratings"},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":"reset_dfs()\ntrain_df.shape"},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":"sns.catplot(\"AdoptionSpeed\", col=\"FirstImageRating\",col_wrap=4,\n                 data=train_df.log,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":75,"metadata":{"scrolled":false},"outputs":[],"source":"sns.catplot(\"AdoptionSpeed\", col=\"SecondImageRating\",col_wrap=4,\n                 data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":100,"metadata":{"scrolled":false},"outputs":[],"source":"train_df['TotalImageRating'] = train_df['FirstImageRating'] + (train_df['SecondImageRating'] * .01)\nsns.catplot(\"AdoptionSpeed\", col=\"FirstImageRating\",col_wrap=4,\n                 data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":"sns.catplot(\"AdoptionSpeed\", col=\"SecondImageRating\",col_wrap=4,\n                 data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[],"source":"train_df['TotalImageRating'] = train_df['FirstImageRating'] + (train_df['SecondImageRating'] * .1)\ntrain_df.loc[train_df['TotalImageRating'] == 1.0, 'TotalImageRating'] = 0.0\ntrain_df.loc[(train_df['TotalImageRating'] == 1.2) | (train_df['TotalImageRating'] == 1.1), 'TotalImageRating'] = 1.0\ntrain_df.loc[train_df['TotalImageRating'] == 2.1, 'TotalImageRating'] = 2.0\ntrain_df.loc[train_df['TotalImageRating'] == 2.2, 'TotalImageRating'] = 3.0\nsns.catplot(\"AdoptionSpeed\", col=\"TotalImageRating\",col_wrap=4,\n                 data=train_df,\n                kind=\"count\", height=5, aspect=.8);"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"images_df = pd.read_csv('../train_image_data.csv')\ndef get_adoptionspeed(x):\n    return train_df[train_df['PetID'] == x['PetID']]['AdoptionSpeed']\nimages_df['AdoptionSpeed'] = images_df[['PetID']].apply(lambda x: get_adoptionspeed(x), axis=1)\nimages_df.head()\n# images = images_df[(images_df['PetLabel'] == 'dog') & (images_df['ImageID'] == 1)].groupby('Description')[['PetLabel']].count().sort_values('PetLabel', ascending=False)\n# images.head(50)\n\n"},{"cell_type":"markdown","metadata":{},"source":"## Video"},{"cell_type":"markdown","metadata":{},"source":"## Description"},{"cell_type":"markdown","metadata":{},"source":"## Quantity"},{"cell_type":"markdown","metadata":{},"source":"## Age"},{"cell_type":"markdown","metadata":{},"source":"## Health"},{"cell_type":"markdown","metadata":{},"source":"## Breed"},{"cell_type":"markdown","metadata":{},"source":"## Color"},{"cell_type":"markdown","metadata":{},"source":"## Size"},{"cell_type":"markdown","metadata":{},"source":"## Fur"},{"cell_type":"markdown","metadata":{},"source":"## Gender"},{"cell_type":"markdown","metadata":{},"source":"## State"},{"cell_type":"markdown","metadata":{},"source":"## Rescuer"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":2}