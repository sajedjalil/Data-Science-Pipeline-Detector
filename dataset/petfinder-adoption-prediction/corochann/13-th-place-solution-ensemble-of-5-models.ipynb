{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 13-th place solution: 0.44091 on private LB\n\nI will share my 13-th place solution. \nAt first, sorry but the code is not so organized & quite messy (it contains all my effort during 3 months).\n\nSummary of the approach is written at [13-th place solution summary 0.44091 (65-th on public LB: 0.459~0.467)](https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/87733). Please refer it for the detailed explanation.\n\n\n### Model\nThis is ensemble of these 5 models:\n - XGBoost\n - LightGBM\n - CatBoost\n - xlearn\n - Neural Network: xDeepFM based model\n   - xDeepFM is a network for sparse, categorical dataset.\n   - Refer: \"xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems\", https://arxiv.org/abs/1803.05170\n \n### External dataset\n\n\n### Library\nI used some library which is/was not supported in the kaggle default docker.\n\n - [xlearn](https://github.com/aksnzhy/xlearn): As explained in https://www.kaggle.com/bminixhofer/xlearn, we can install library as an \"external dataset\".\n - [optuna](https://github.com/pfnet/optuna): I used it for hyper parameter tuning during local development (not used in the final code). It seems [now supported](https://github.com/Kaggle/docker-python/pull/486).\n - [chainer_chemistry](https://github.com/pfnet-research/chainer-chemistry): I used it as an extension of Chainer, for writing neural network part. I am sending [PR to support it in default docker](https://github.com/Kaggle/docker-python/pull/447).\n In this kernel, I copied some of the module/code from the library to use it.\n\n - [pfnet-research/sngan_projection](https://github.com/pfnet-research/sngan_projection): Some of the codes are copied from this repository to use spectral normalization for regularization of Neural Network.\n\n### External dataset\n - Petfinder.my: this competition's dataset\n - Glove embedding feature: text embedding extraction\n - Keras DenseNet Weights: image feature extraction\n - Cat and dog breeds parameters: breed feature extraction\n - xlearn: to install xlearn library\n \n - Malaysia GDP & population: hard coded.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":2,"outputs":[{"output_type":"stream","text":"['densenet-keras', 'cat-and-dog-breeds-parameters', 'xlearn', 'glove-global-vectors-for-word-representation', 'petfinder-adoption-prediction']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To check the total kernel running time in detail, 2 hours limit for GPU kernel for petfinder.my competition.\nfrom time import time\n\nstart_time = time()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Install xlearn: it takes several minutes."},{"metadata":{"trusted":true,"_uuid":"957440c97ac1568ea4a33fc2829bfa12ce818dfb"},"cell_type":"code","source":"import os\nimport subprocess\n\nos.environ['USER'] = 'root'\nos.system('pip install ../input/xlearn/xlearn/xlearn-0.40a1/')\n#result = subprocess.check_output('pip install ../input/xlearn/xlearn/xlearn-0.40a1/', shell=True)\n\nimport xlearn as xl","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c9f64b86d6b31dab112802fdc7d871c51c0fa9c"},"cell_type":"code","source":"xl.hello()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10abd4b27f308cb5a726e84b50bd7d3845c1109d"},"cell_type":"code","source":"debug = False\n\nprint(os.listdir(\"../input/petfinder-adoption-prediction\"))","execution_count":6,"outputs":[{"output_type":"stream","text":"['train', 'test', 'breed_labels.csv', 'train_sentiment', 'test_sentiment', 'test_metadata', 'train_images', 'train_metadata', 'state_labels.csv', 'color_labels.csv', 'test_images']\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"ffcabb17b6f035eebb6306030418ee605c6d3597"},"cell_type":"code","source":"is_kaggle_kernel = True\npet_dir = '../input/petfinder-adoption-prediction'\nbert_dir = '../input/uncased-l12-h768-a12-bert-config-json'\nvgg16_dir = '../input/vgg16-chainercv'\njson_dir = '../input/cat-and-dog-breeds-parameters'\nglove_dir = '../input/glove-global-vectors-for-word-representation'\ndensenet_dir = '../input/densenet-keras'\ncute_dir = '../input/cute-cats-and-dogs-from-pixabaycom'","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e4ea69b0ebab4a6594509f6895064e409f46418"},"cell_type":"code","source":"# --- utils ---","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4081451d7c7f3857cbdb76d5794b72a055adcd2c"},"cell_type":"code","source":"from contextlib import contextmanager\nfrom time import perf_counter\nimport os\n\nimport numpy\n\n\n@contextmanager\ndef timer(name):\n    t0 = perf_counter()\n    yield\n    t1 = perf_counter()\n    print('[{}] done in {:.3f} s'.format(name, t1-t0))\n\n\ndef _check_path_exist(filepath):\n    if not os.path.exists(filepath):\n        raise IOError('{} not found'.format(filepath))\n\n\ndef save_npz(filepath, datasets):\n    if not isinstance(datasets, (list, tuple)):\n        datasets = (datasets, )\n    numpy.savez(filepath, *datasets)\n\n\ndef load_npz(filepath):\n    _check_path_exist(filepath)\n    load_data = numpy.load(filepath)\n    result = []\n    i = 0\n    while True:\n        key = 'arr_{}'.format(i)\n        if key in load_data.keys():\n            result.append(load_data[key])\n            i += 1\n        else:\n            break\n    if len(result) == 1:\n        result = result[0]\n    return result\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb6ad9b5a3d78ea2288667e4c6e3aa0168689c52"},"cell_type":"code","source":"# --- preprocessing ---","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import json\nimport os\nfrom glob import glob\nfrom time import perf_counter\n\nimport numpy as np\nimport pandas as pd\nfrom joblib import Parallel, delayed\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import cohen_kappa_score\n\n\nimport sys\nimport os\n\n\n\ndef prepare_df(debug=True, animal_type=None):\n    train = pd.read_csv(os.path.join(pet_dir, \"train/train.csv\"))\n    print('Train', train.shape)\n\n    test = pd.read_csv(os.path.join(pet_dir, \"test/test.csv\"))\n    print('Test', test.shape)\n\n    breeds = pd.read_csv(os.path.join(pet_dir, \"breed_labels.csv\"))\n    print('Breeds', breeds.shape)\n\n    colors = pd.read_csv(os.path.join(pet_dir, \"color_labels.csv\"))\n    print('Colors', colors.shape)\n\n    states = pd.read_csv(os.path.join(pet_dir, \"state_labels.csv\"))\n    print('States', states.shape)\n\n    if debug:\n        train = train[:1000]\n        test = test[:500]\n\n    if animal_type is not None:\n        assert animal_type == 1 or animal_type == 2\n        # Only train dog or cat...\n        print('Only use type = {}'.format(animal_type))\n        train = train[train['Type'] == animal_type]\n        test = test[test['Type'] == animal_type]\n\n    return train, test, breeds, colors, states\n\n\ndef process_sentiment(petid, dataset_type='train', num_text=0):\n    \"\"\"preprocessing for sentiment json\n\n    Args:\n        petid (str): petid\n        dataset_type (str): train or test\n        num_text (int): First `num_text` text sentiment is extracted.\n            If 0, only global sentiment is extracted.\n\n    Returns:\n        doc_features (list): [`doc_sent_mag`, `doc_sent_score`] which stores\n            magnitude & score of sentiment.\n    \"\"\"\n    json_filepath = '{}/{}_sentiment/{}.json'.format(pet_dir, dataset_type, petid)\n    ndim = 2 * (num_text + 1)\n    feat = np.zeros((ndim,), dtype=np.float32)\n    if os.path.exists(json_filepath):\n        with open(json_filepath, 'r', encoding='utf-8') as f:\n            sentiment = json.load(f)\n        doc_sent = sentiment['documentSentiment']\n        feat[0] = doc_sent['magnitude']\n        feat[1] = doc_sent['score']\n        doc_sent_list = sentiment['sentences']\n        for i in range(num_text):\n            if i == len(doc_sent_list):\n                break\n            current_index = 2 * (i + 1)\n            feat[current_index] = doc_sent_list[i]['sentiment']['magnitude']\n            feat[current_index + 1] = doc_sent_list[i]['sentiment']['score']\n    return feat\n\n\ndef process_metadata(petid, dataset_type='train'):\n    \"\"\"preprocess for image metadata json\n    Args:\n        petid (str): petid\n        dataset_type (str): train or test\n\n    Returns:\n        metadata_features (list):\n            [vertex_x, vertex_y, bounding_confidence, bounding_importance_frac,\n             dominant_blue, dominant_green, dominant_red, dominant_pixel_frac, dominant_score,\n             label_description, label_score]\n    \"\"\"\n    # Only check first image...\n    json_filepath = '/{}_metadata/{}-1.json'.format(pet_dir, dataset_type, petid)\n    if os.path.exists(json_filepath):\n        with open(json_filepath, 'r', encoding='utf-8') as f:\n            metadata = json.load(f)\n        crop_hints0 = metadata['cropHintsAnnotation']['cropHints'][0]\n        vertex = crop_hints0['boundingPoly']['vertices'][2]\n        vertex_x = vertex['x']\n        vertex_y = vertex['y']\n        bounding_confidence = crop_hints0['confidence']\n        bounding_importance_frac = crop_hints0.get('importanceFraction', -1)\n        colors0 = metadata['imagePropertiesAnnotation']['dominantColors']['colors'][0]\n        dominant_color = colors0['color']\n        dominant_blue = dominant_color['blue']\n        dominant_green = dominant_color['green']\n        dominant_red = dominant_color['red']\n        dominant_pixel_frac = colors0['pixelFraction']\n        dominant_score = colors0['score']\n        if metadata.get('labelAnnotations'):\n            label_description = metadata['labelAnnotations'][0]['description']\n            label_score = metadata['labelAnnotations'][0]['score']\n        else:\n            label_description = 'nothing'\n            label_score = -1\n\n        # TODO: how to return label_description??\n        return [vertex_x, vertex_y, bounding_confidence, bounding_importance_frac,\n                dominant_blue, dominant_green, dominant_red, dominant_pixel_frac, dominant_score,\n                label_score]         # label_description\n    else:\n        return [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n\n\ndef add_gdp(df):\n    \"\"\"Add GDP & population inplace.\"\"\"\n    # Copied from https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/78040\n    # state GDP: https://en.wikipedia.org/wiki/List_of_Malaysian_states_by_GDP\n    state_gdp = {\n        41336: 116.679,\n        41325: 40.596,\n        41367: 23.02,\n        41401: 190.075,\n        41415: 5.984,\n        41324: 37.274,\n        41332: 42.389,\n        41335: 52.452,\n        41330: 67.629,\n        41380: 5.642,\n        41327: 81.284,\n        41345: 80.167,\n        41342: 121.414,\n        41326: 280.698,\n        41361: 32.270\n    }\n\n    # state population: https://en.wikipedia.org/wiki/Malaysia\n    state_population = {\n        41336: 33.48283,\n        41325: 19.47651,\n        41367: 15.39601,\n        41401: 16.74621,\n        41415: 0.86908,\n        41324: 8.21110,\n        41332: 10.21064,\n        41335: 15.00817,\n        41330: 23.52743,\n        41380: 2.31541,\n        41327: 15.61383,\n        41345: 32.06742,\n        41342: 24.71140,\n        41326: 54.62141,\n        41361: 10.35977\n    }\n    df[\"state_gdp\"] = df.State.map(state_gdp)\n    df[\"state_population\"] = df.State.map(state_population)\n\n\ndef add_tfidf(train, test, tfidf_svd_components=120):\n    train_desc = train.Description.values\n    test_desc = test.Description.values\n    # TF-IDF value\n    s = perf_counter()\n    tfv = TfidfVectorizer(\n        min_df=2, max_features=None,\n        strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n        ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1, )\n    # tfv = TfidfVectorizer(\n    #     min_df=3,  max_features=10000,\n    #     strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n    #     ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n    #     stop_words='english')\n    tfv.fit(list(train_desc))\n    train_x_tfidf = tfv.transform(train_desc)\n    test_x_tfidf = tfv.transform(test_desc)\n    e = perf_counter()\n    print('Tfidfvectorizer done {} sec train_desc {}, test_desc {}'\n          .format(e - s, train_x_tfidf.shape, test_x_tfidf.shape))\n\n    s = perf_counter()\n    svd = TruncatedSVD(n_components=tfidf_svd_components)\n    svd.fit(train_x_tfidf)\n    train_x_tfidf_svd = svd.transform(train_x_tfidf).astype(np.float32)\n    test_x_tfidf_svd = svd.transform(test_x_tfidf).astype(np.float32)\n    e = perf_counter()\n    print('TruncatedSVD done {} sec, train_x_tfidf_svd {}'\n          .format(e - s, train_x_tfidf_svd.shape))\n    return train_x_tfidf_svd, test_x_tfidf_svd\n\n\ndef parse_image_size():\n    # https://www.kaggle.com/ranjoranjan/single-xgboost-model\n    from PIL import Image\n    # train_df_ids = train[['PetID']]\n    # test_df_ids = test[['PetID']]\n\n    train_image_files = sorted(glob('{}/train_images/*.jpg'.format(pet_dir)))\n    test_image_files = sorted(glob('{}/test_images/*.jpg'.format(pet_dir)))\n    split_char = '/'\n\n    train_df_imgs = pd.DataFrame(train_image_files)\n    train_df_imgs.columns = ['image_filename']\n    train_imgs_pets = train_df_imgs['image_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n\n    test_df_imgs = pd.DataFrame(test_image_files)\n    test_df_imgs.columns = ['image_filename']\n    test_imgs_pets = test_df_imgs['image_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n\n    train_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\n    test_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n\n    def getSize(filename):\n        st = os.stat(filename)\n        return st.st_size\n\n    def getDimensions(filename):\n        img_size = Image.open(filename).size\n        return img_size\n\n    from joblib import Parallel, delayed\n    n_jobs = 16\n    results = Parallel(n_jobs, verbose=1)(\n        delayed(getDimensions)(filepath) for filepath in train_image_files)\n    results = np.asarray(results)\n    print('results', results.shape)\n\n    train_df_imgs['image_size'] = train_df_imgs['image_filename'].apply(getSize)\n    # train_df_imgs['temp_size'] = train_df_imgs['image_filename'].apply(getDimensions)\n    # train_df_imgs['width'] = train_df_imgs['temp_size'].apply(lambda x: x[0])\n    # train_df_imgs['height'] = train_df_imgs['temp_size'].apply(lambda x: x[1])\n    train_df_imgs['width'] = results[:, 0]\n    train_df_imgs['height'] = results[:, 1]\n    # train_df_imgs = train_df_imgs.drop(['temp_size'], axis=1)\n\n    results = Parallel(n_jobs, verbose=1)(\n        delayed(getDimensions)(filepath) for filepath in test_image_files)\n    results = np.asarray(results)\n\n    test_df_imgs['image_size'] = test_df_imgs['image_filename'].apply(getSize)\n    # test_df_imgs['temp_size'] = test_df_imgs['image_filename'].apply(getDimensions)\n    # test_df_imgs['width'] = test_df_imgs['temp_size'].apply(lambda x: x[0])\n    # test_df_imgs['height'] = test_df_imgs['temp_size'].apply(lambda x: x[1])\n    test_df_imgs['width'] = results[:, 0]\n    test_df_imgs['height'] = results[:, 1]\n    # test_df_imgs = test_df_imgs.drop(['temp_size'], axis=1)\n\n    aggs = {\n        'image_size': ['sum', 'mean', 'var'],\n        'width': ['sum', 'mean', 'var'],\n        'height': ['sum', 'mean', 'var'],\n    }\n\n    agg_train_imgs = train_df_imgs.groupby('PetID').agg(aggs)\n    new_columns = [\n        k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n    ]\n    agg_train_imgs.columns = new_columns\n    agg_train_imgs = agg_train_imgs.reset_index()\n\n    agg_test_imgs = test_df_imgs.groupby('PetID').agg(aggs)\n    new_columns = [\n        k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n    ]\n    agg_test_imgs.columns = new_columns\n    agg_test_imgs = agg_test_imgs.reset_index()\n\n    # agg_imgs = pd.concat([agg_train_imgs, agg_test_imgs], axis=0).reset_index(drop=True)\n    # return agg_imgs\n    return agg_train_imgs, agg_test_imgs\n\n\ndef preprocessing(train, test, breeds, colors, states,\n                  mode='regression', debug=False, use_tfidf=True, use_tfidf_cache=True,\n                  use_sentiment=True, use_metadata=False, cat2num=True,\n                  use_rescuer_id_count=True, use_name_feature=True, use_target_encoding=True,\n                  tfidf_svd_components=120, animal_type=None, num_sentiment_text=0):\n\n    # nan handling...\n    train['Name'].fillna('none', inplace=True)\n    train['Description'].fillna('none', inplace=True)\n    test['Name'].fillna('none', inplace=True)\n    test['Description'].fillna('none', inplace=True)\n\n    train['dataset_type'] = 'train'\n    test['dataset_type'] = 'test'\n    all_data = pd.concat([train, test], axis=0, sort=True)\n    train_indices = (all_data['dataset_type'] == 'train').values\n    test_indices = (all_data['dataset_type'] == 'test').values\n\n    numeric_cols = ['Age', 'MaturitySize', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']\n    if debug:\n        cat_cols = ['Type', 'Breed1', 'Gender', 'Color1', 'Vaccinated', 'Dewormed', 'Sterilized',\n                    'State', 'FurLength', 'Health']\n    else:\n        cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n                    'Vaccinated', 'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health']\n\n    # TODO: process these features properly later...\n    remove_cols = ['RescuerID', 'PetID', 'AdoptionSpeed']\n    other_cols = ['Name', 'Description']\n\n    if mode == 'regression':\n        target = train['AdoptionSpeed'].values.astype(np.float32)[:, None]\n    elif mode == 'classification':\n        target = train['AdoptionSpeed'].values.astype(np.int32)\n    else:\n        raise ValueError(\"[ERROR] Unexpected value mode={}\".format(mode))\n\n    # --- Feature engineering ---\n    # GDP & population\n    use_gdp = False\n    if use_gdp:\n        add_gdp(train)\n        add_gdp(test)\n\n        # Scaling...\n        train[\"state_gdp\"] = train[\"state_gdp\"] / train[\"state_gdp\"].max()\n        test[\"state_gdp\"] = test[\"state_gdp\"] / train[\"state_gdp\"].max()\n        train[\"state_population\"] = train[\"state_population\"] / train[\"state_population\"].max()\n        test[\"state_population\"] = test[\"state_population\"] / train[\"state_population\"].max()\n        numeric_cols.append('state_gdp')\n        numeric_cols.append('state_population')\n\n    if use_rescuer_id_count:\n        print('use_rescuer_id_count...')\n        cutoff_count = 20\n        train['RescuerIDCount'] = train.groupby('RescuerID')[\n            'RescuerID'].transform(lambda s: s.count())\n        test['RescuerIDCount'] = test.groupby('RescuerID')[\n            'RescuerID'].transform(lambda s: s.count())\n\n        train.loc[train['RescuerIDCount'] >= cutoff_count, 'RescuerIDCount'] = cutoff_count\n        test.loc[test['RescuerIDCount'] >= cutoff_count, 'RescuerIDCount'] = cutoff_count\n\n        # \"is_first_time\" feature\n        train['is_first_time'] = (train['RescuerIDCount'] == 1).astype(np.float32)\n        test['is_first_time'] = (test['RescuerIDCount'] == 1).astype(np.float32)\n        numeric_cols.append('RescuerIDCount')\n        numeric_cols.append('is_first_time')\n\n    if use_name_feature:\n        print('create name feature...')\n        # create name feature\n        # 1. no name or not\n        train['No_name'] = 0\n        train.loc[train['Name'] == 'none', 'No_name'] = 1\n        test['No_name'] = 0\n        test.loc[test['Name'] == 'none', 'No_name'] = 1\n\n        # 2. weired name or not\n        train['name_under2'] = train['Name'].apply(lambda x: len(str(x)) < 3).values.astype(np.float32)\n        test['name_under2'] = test['Name'].apply(lambda x: len(str(x)) < 3).values.astype(np.float32)\n\n        # 3. puppy, puppies, kitten, kitty, baby flag.\n        train['is_kitty'] = train['Name'].apply(lambda x: 'kitty' in str(x).lower()).values.astype(np.float32)\n        test['is_kitty'] = test['Name'].apply(lambda x: 'kitty' in str(x).lower()).values.astype(np.float32)\n\n        train['is_kitten'] = train['Name'].apply(lambda x: 'kitten' in str(x).lower()).values.astype(np.float32)\n        test['is_kitten'] = test['Name'].apply(lambda x: 'kitten' in str(x).lower()).values.astype(np.float32)\n\n        train['is_puppy'] = train['Name'].apply(lambda x: 'puppy' in str(x).lower()).values.astype(np.float32)\n        test['is_puppy'] = test['Name'].apply(lambda x: 'puppy' in str(x).lower()).values.astype(np.float32)\n\n        train['is_puppies'] = train['Name'].apply(lambda x: 'puppies' in str(x).lower()).values.astype(np.float32)\n        test['is_puppies'] = test['Name'].apply(lambda x: 'puppies' in str(x).lower()).values.astype(np.float32)\n\n        numeric_cols.append('name_under2')\n        numeric_cols.append('is_kitty')\n        numeric_cols.append('is_kitten')\n        numeric_cols.append('is_puppy')\n        numeric_cols.append('is_puppies')\n\n    if use_target_encoding:\n        print('create target encoding feature...')\n        # 1. --- Breed target encoding ---\n        # breed1 = train.groupby('Breed1')['AdoptionSpeed']\n        # train['breed1_mean'] = breed1.transform(np.mean)\n        # train['breed1_median'] = breed1.transform(np.median)\n        breed1 = all_data.groupby('Breed1')['AdoptionSpeed']\n        all_data['breed1_mean'] = breed1.transform(np.mean)\n        # all_data['breed1_q1'] = breed1.transform(lambda x: np.quantile(x, 0.25))\n        breed2 = all_data.groupby('Breed2')['AdoptionSpeed']\n        all_data['breed2_mean'] = breed2.transform(np.mean)\n        # all_data['breed2_median'] = breed2.transform(np.median)\n\n        # 2. --- State target encoding ---\n        state = all_data.groupby('State')['AdoptionSpeed']\n        all_data['state_mean'] = state.transform(np.mean)\n\n        # Assign values into `train` and `test`...\n        for col in ['breed1_mean', 'breed2_mean', 'state_mean']:\n            train[col] = all_data[train_indices][col]\n            test[col] = all_data[test_indices][col]\n            numeric_cols.append(col)\n\n    # --- is_xxx flag ---\n    train['is_free'] = 0\n    train.loc[train['Fee'] == 0, 'is_free'] = 1\n    test['is_free'] = 0\n    test.loc[test['Fee'] == 0, 'is_free'] = 1\n    numeric_cols.append('is_free')\n\n    train['has_photo'] = 0\n    train.loc[train['PhotoAmt'] > 0, 'has_photo'] = 1\n    test['has_photo'] = 0\n    test.loc[test['PhotoAmt'] > 0, 'has_photo'] = 1\n    numeric_cols.append('has_photo')\n\n    train['age_unknown'] = 0\n    train.loc[train['Age'] == 255, 'age_unknown'] = 1\n    test['age_unknown'] = 0\n    test.loc[test['Age'] == 255, 'age_unknown'] = 1\n    numeric_cols.append('age_unknown')\n\n    # def quantize_age(df):\n    #     # quantize age to multiple of 6 (half year...).\n    #     # DataFrame is replaced inplace.\n    #     age = df['Age'].values\n    #\n    #     # (13, 18)  # seems better not to quantize..\n    #     quantize_list = [(19, 24), (25, 30), (31, 36), (37, 48),\n    #                      (49, 60), (61, 72), (73, 84), (85, 96)]\n    #     for low, high in quantize_list:\n    #         condition = (age >= low) & (age < high)\n    #         print('{} => {} matched for age between {} to {}. quantize to {}...'\n    #               .format(np.sum(condition), np.sum(age == high), low, high-1, high))\n    #         df.loc[condition, 'Age'] = high\n    # print('quantize_age: train')\n    # quantize_age(train)\n    # print('quantize_age: test')\n    # quantize_age(test)\n\n    # --- Cutoff ---\n    # 'Age', max was 255.\n    # TODO: we may need to deal with \"255\" as special (I think this is \"unknown\")\n    # age_cutoff = 54  # TODO: hyperparameter tuning. This affects a lot!!!\n    age_cutoff = 60  # TODO: hyperparameter tuning. This affects a lot!!!\n    print('age_cutoff', age_cutoff)\n    train.loc[train['Age'] >= age_cutoff, 'Age'] = age_cutoff\n    test.loc[test['Age'] >= age_cutoff, 'Age'] = age_cutoff\n    # 'Quantity', max was 20, but most of them are ~10.\n    quantity_cutoff = 11\n    train.loc[train['Quantity'] >= quantity_cutoff, 'Quantity'] = quantity_cutoff\n    test.loc[test['Quantity'] >= quantity_cutoff, 'Quantity'] = quantity_cutoff\n    # 'VideoAmt', max was 8, but most of them are ~1.\n    video_amt_cutoff = 4\n    train.loc[train['VideoAmt'] >= video_amt_cutoff, 'VideoAmt'] = video_amt_cutoff\n    test.loc[test['VideoAmt'] >= video_amt_cutoff, 'VideoAmt'] = video_amt_cutoff\n    # 'PhotoAmt', max was 30, but most of them are ~11.\n    photo_amt_cutoff = 12\n    train.loc[train['PhotoAmt'] >= photo_amt_cutoff, 'PhotoAmt'] = photo_amt_cutoff\n    test.loc[test['PhotoAmt'] >= photo_amt_cutoff, 'PhotoAmt'] = photo_amt_cutoff\n    # 'Fee', max was 3000, but most of them are ~300 or ~500\n    # 300 or 500\n    fee_cutoff = 500\n    train.loc[train['Fee'] >= fee_cutoff, 'Fee'] = fee_cutoff\n    test.loc[test['Fee'] >= fee_cutoff, 'Fee'] = fee_cutoff\n\n    # --- Numeric value processing ---\n    print('numeric value preprocessing...')\n    # There is no nan value, but this is just for make sure no nan exist.\n    train_x_numeric = train[numeric_cols].fillna(0).values.astype(np.float32)\n    test_x_numeric = test[numeric_cols].fillna(0).values.astype(np.float32)\n\n    # --- MinMax scaling ---\n    xmax = np.max(train_x_numeric, axis=0)\n    xmin = np.min(train_x_numeric, axis=0)\n    print('xmax', xmax)\n    print('xmin', xmin)\n    inds = xmax != xmin  # Non-zero indices\n    train_x_numeric[:, inds] = (train_x_numeric[:, inds] - xmin[inds]) / (xmax[inds] - xmin[inds])\n    test_x_numeric[:, inds] = (test_x_numeric[:, inds] - xmin[inds]) / (xmax[inds] - xmin[inds])\n\n    if use_sentiment:\n        print('create sentiment feature...')\n        n_jobs = 16\n        s = perf_counter()\n        # Multiprocessing: around 2 sec. Multithreading: 10 sec. Singlethreading 63 sec.\n        # train_x_sent = Parallel(n_jobs, backend='threading')(\n        #     delayed(process_sentiment, check_pickle=False)\n        #     (petid, 'train') for petid in train['PetID'].values)\n        train_x_sent = Parallel(n_jobs)(\n            delayed(process_sentiment)\n            (petid, 'train', num_sentiment_text) for petid in train['PetID'].values)\n        test_x_sent = Parallel(n_jobs)(\n            delayed(process_sentiment)\n            (petid, 'test', num_sentiment_text) for petid in test['PetID'].values)\n        e = perf_counter()\n        print('sentiment {} sec, n_jobs {}'.format(e-s, n_jobs))\n        train_x_sent = np.array(train_x_sent, dtype=np.float32)\n        test_x_sent = np.array(test_x_sent, dtype=np.float32)\n        print('train_x_numeric {}, train_x_sent {}'\n              .format(train_x_numeric.shape, train_x_sent.shape))\n        train_x_numeric = np.concatenate([train_x_numeric, train_x_sent], axis=1)\n        test_x_numeric = np.concatenate([test_x_numeric, test_x_sent], axis=1)\n\n    if use_metadata:\n        print('create metadata feature...')\n        n_jobs = 16\n        s = perf_counter()\n        train_x_metadata = Parallel(n_jobs)(\n            delayed(process_metadata)\n            (petid, 'train') for petid in train['PetID'].values)\n        test_x_metadata = Parallel(n_jobs)(\n            delayed(process_metadata)\n            (petid, 'test') for petid in test['PetID'].values)\n        e = perf_counter()\n        print('metadata {} sec, n_jobs {}'.format(e-s, n_jobs))\n        train_x_metadata = np.array(train_x_metadata, dtype=np.float32)\n        test_x_metadata = np.array(test_x_metadata, dtype=np.float32)\n        print('train_x_numeric {}, train_x_metadata {}'\n              .format(train_x_numeric.shape, train_x_metadata.shape))\n        train_x_numeric = np.concatenate([train_x_numeric, train_x_metadata], axis=1)\n        test_x_numeric = np.concatenate([test_x_numeric, test_x_metadata], axis=1)\n\n    os.makedirs('./cache', exist_ok=True)\n    if use_tfidf:\n        if animal_type is not None:\n            cache_filepath = './cache/x_tfidf_svd{}_debug{}_animaltype{}.npz'.format(\n                tfidf_svd_components, int(debug), animal_type)\n        else:\n            cache_filepath = './cache/x_tfidf_svd{}_debug{}.npz'.format(\n                tfidf_svd_components, int(debug))\n        if use_tfidf_cache and os.path.exists(cache_filepath):\n            print('load from {}'.format(cache_filepath))\n            train_x_tfidf_svd, test_x_tfidf_svd = load_npz(cache_filepath)\n        else:\n            print('create tfidf feature...')\n            train_x_tfidf_svd, test_x_tfidf_svd = add_tfidf(train, test, tfidf_svd_components=tfidf_svd_components)\n            save_npz(cache_filepath, (train_x_tfidf_svd, test_x_tfidf_svd))\n            print('saved to {}'.format(cache_filepath))\n        train_x_numeric = np.concatenate([train_x_numeric, train_x_tfidf_svd], axis=1)\n        test_x_numeric = np.concatenate([test_x_numeric, test_x_tfidf_svd], axis=1)\n\n    # --- Category value processing ---\n    if cat2num:\n        # convert category value to one-hot vector or other values.\n        # cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n        #             'Vaccinated', 'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health']\n        # all_cat = all_data[cat_cols].astype('category')\n        # all_cat_id = all_cat.apply(lambda x: x.cat.codes)\n\n        # --- 1. category to one-hot vector ---\n        # checked include State or not --> include State seems better.\n        one_hot_cols = ['Type', 'Gender', 'Vaccinated',\n                        'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health']\n        one_hot_list = [pd.get_dummies(all_data[col]).values for col in one_hot_cols]\n        one_hot_array = np.concatenate(one_hot_list, axis=1).astype(np.float32)\n\n        # --- 2. breed ---\n        # deal \"Unspecified\" and \"Unknown\" as same for 2nd breed\n        all_data['Breed2'][all_data['Breed2'] == 0] = 307\n        # is_mixed = (all_data['Breed2'] != 0) & (all_data['Breed2'] != 307)\n        is_mixed = (all_data['Breed2'] != 307).astype(np.float32)[:, None]\n        b1 = all_data['Breed1'].value_counts()\n        major_breeds = b1[b1 >= 100].index.values  # 18 species remain\n        # major_breeds = b1[b1 >= 1000].index.values  # 3 species remain\n        print('major_breeds', major_breeds)\n\n        def breed_onehot(x):\n            if x not in major_breeds:\n                # rare breed\n                return len(major_breeds)\n            else:\n                # major (non-rare) breed\n                breed_id = np.argwhere(x == major_breeds)[0, 0]\n                # return x\n                return breed_id\n\n        b1r = all_data['Breed1'].apply(breed_onehot)\n        b2r = all_data['Breed2'].apply(breed_onehot)\n        breed_ones = np.eye(len(major_breeds) + 1, dtype=np.float32)\n        breed_array = (1.0 * breed_ones[b1r] + 0.7 * breed_ones[b2r]).astype(np.float32)\n        # breed_array = (1.0 * breed_ones[b1r] + 1.0 * breed_ones[b2r]).astype(np.float32)\n\n        # --- 3. color ---\n        # 0 unspecified, 1 black, ... , 7 white.\n        color_ones = np.eye(8)\n        color1_onehot = color_ones[all_data['Color1'].values]\n        color2_onehot = color_ones[all_data['Color2'].values]\n        color3_onehot = color_ones[all_data['Color3'].values]\n        color_array = (1.0 * color1_onehot + 0.7 * color2_onehot + 0.5 * color3_onehot).astype(np.float32)\n        # color_array = (1.0 * color1_onehot + 1.0 * color2_onehot + 1.0 * color3_onehot).astype(np.float32)\n\n        x_cat2num_array = np.concatenate([one_hot_array, is_mixed, breed_array, color_array], axis=1)\n        print('one_hot_array', one_hot_array.shape,\n              'is_mixed', is_mixed.shape,\n              'breed_array', breed_array.shape,\n              'color_array', color_array.shape,\n              'x_cat2num_array', x_cat2num_array.shape, x_cat2num_array.dtype)\n\n        train_x_cat = x_cat2num_array[train_indices]\n        test_x_cat = x_cat2num_array[test_indices]\n        num_cat_id = -1\n    else:\n        all_cat = all_data[cat_cols].astype('category')\n        all_cat_id = all_cat.apply(lambda x: x.cat.codes)\n        all_x_cat = all_cat_id.values.astype(np.int32)\n\n        train_x_cat = all_x_cat[train_indices]\n        test_x_cat = all_x_cat[test_indices]\n\n        num_cat_id = np.max(all_x_cat, axis=0) + 1\n        print('train_x_cat', train_x_cat.shape, 'test_x_cat', test_x_cat.shape, 'num_cat_id', num_cat_id)\n    return train_x_numeric, train_x_cat, target, test_x_numeric, test_x_cat, num_cat_id\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"952a1dbd1516ffee1fcb5e1bd36ac7687a841426"},"cell_type":"code","source":"# --- preprocessing image feature ---","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0218d7ac9f5512bf361af344707b9c1d1ba2f73"},"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport pandas as pd\nfrom chainer import cuda\nfrom sklearn.decomposition import TruncatedSVD\nfrom tqdm import tqdm\n\nfrom keras.applications.densenet import preprocess_input, DenseNet121\nfrom keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nimport keras.backend as K\n\nimport sys\nimport os\n\n\ndef resize_to_square(im, img_size=256):\n    old_size = im.shape[:2]\n    ratio = float(img_size)/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    top, bottom = delta_h//2, delta_h-(delta_h//2)\n    left, right = delta_w//2, delta_w-(delta_w//2)\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n                                value=color)\n    return new_im\n\n\ndef load_image(path, pet_id, image_index=1, img_size=256):\n    image = cv2.imread(f'{path}{pet_id}-{image_index}.jpg')\n    new_image = resize_to_square(image, img_size=img_size)\n    new_image = preprocess_input(new_image)\n    return new_image\n\n\ndef read_image_keras(filepath, img_size=256):\n    image = cv2.imread(filepath)\n    new_image = resize_to_square(image, img_size=img_size)\n    new_image = preprocess_input(new_image)\n    return new_image\n\n\ndef prepare_model_densenet():\n    inp = Input((256, 256, 3))\n    backbone = DenseNet121(input_tensor=inp,\n                           weights=f\"{densenet_dir}/DenseNet-BC-121-32-no-top.h5\",\n                           include_top=False)\n    x = backbone.output\n    x = GlobalAveragePooling2D()(x)\n    x = Lambda(lambda x: K.expand_dims(x, axis=-1))(x)\n    # x = AveragePooling1D(4)(x)  # Remove feature reduction!!\n    out = Lambda(lambda x: x[:, :, 0])(x)\n    m = Model(inp, out)\n    return m\n\n\ndef preprocess_image_densenet(train, test, img_size=256, batch_size=256,\n                              n_components=32, method='svd'):\n    use_cache = True\n    if use_cache:\n        try:\n            # local\n            train_feats = read_feather(\"../input/densenet-keras/train_image_densenet_5.feather\")\n            test_feats = read_feather(\"../input/densenet-keras/test_image_densenet_5.feather\")\n        except:\n            # kaggle kernel\n            train_feats = read_feather(\"./train_image_densenet_10_1024.feather\")\n            test_feats = read_feather(\"./test_image_densenet_10_1024.feather\")\n    else:\n        m = prepare_model_densenet()\n        pet_ids = train['PetID'].values\n        n_batches = len(pet_ids) // batch_size + 1\n\n        features = {}\n        for b in tqdm(range(n_batches)):\n            start = b * batch_size\n            end = (b + 1) * batch_size\n            batch_pets = pet_ids[start:end]\n            batch_images = np.zeros((len(batch_pets), img_size, img_size, 3))\n            for i, pet_id in enumerate(batch_pets):\n                try:\n                    batch_images[i] = load_image(\n                        f\"{pet_dir}/train_images/\",\n                        pet_id, img_size=img_size)\n                except:\n                    pass\n            batch_preds = m.predict(batch_images)\n            for i, pet_id in enumerate(batch_pets):\n                features[pet_id] = batch_preds[i]\n\n        train_feats = pd.DataFrame.from_dict(features, orient='index')\n        train_feats.columns = [f'pic_{i}' for i in range(train_feats.shape[1])]\n\n        pet_ids = test['PetID'].values\n        n_batches = len(pet_ids) // batch_size + 1\n\n        features = {}\n        for b in tqdm(range(n_batches)):\n            start = b * batch_size\n            end = (b + 1) * batch_size\n            batch_pets = pet_ids[start:end]\n            batch_images = np.zeros((len(batch_pets), img_size, img_size, 3))\n            for i, pet_id in enumerate(batch_pets):\n                try:\n                    batch_images[i] = load_image(\n                        f\"{pet_dir}/test_images/\",\n                        pet_id, img_size=img_size)\n                except:\n                    pass\n            batch_preds = m.predict(batch_images)\n            for i, pet_id in enumerate(batch_pets):\n                features[pet_id] = batch_preds[i]\n        test_feats = pd.DataFrame.from_dict(features, orient='index')\n        test_feats.columns = [f'pic_{i}' for i in range(test_feats.shape[1])]\n\n        train_feats = train_feats.reset_index()\n        train_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n\n        test_feats = test_feats.reset_index()\n        test_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n\n    hdim = train_feats.shape[1] - 1\n    fcols = [f'pic_{i}' for i in range(hdim)]\n    print('keras densenet feature: hdim', hdim)\n\n    train_feats.fillna(0, inplace=True)\n    test_feats.fillna(0, inplace=True)\n    features_df = pd.concat([train_feats, test_feats], axis=0, sort=False, ignore_index=True)\n    features = features_df[fcols].values\n\n    if n_components is not None:\n        if method == 'svd':\n            svd_ = TruncatedSVD(n_components=n_components, random_state=1337)\n            svd_col = svd_.fit_transform(features)\n            train_x_image_array = svd_col[:len(train)]\n            test_x_image_array = svd_col[len(train):]\n        else:\n            raise ValueError(\"[ERROR] Unexpected value method={}\".format(method))\n    else:\n        train_x_image_array = train_feats[fcols].values\n        test_x_image_array = test_feats[fcols].values\n\n    num_image = 1\n    num_hidden = train_x_image_array.shape[-1]\n    xp = cuda.get_array_module(train_x_image_array)\n    train_x_image_feat = xp.reshape(train_x_image_array, (len(train), num_image, num_hidden))\n    test_x_image_feat = xp.reshape(test_x_image_array, (len(test), num_image, num_hidden))\n    # train_x_image_feat = xp.reshape(train_x_image_array, (len(train_x_image_array), num_image, num_hidden))\n    # test_x_image_feat = xp.reshape(test_x_image_array, (len(test_x_image_array), num_image, num_hidden))\n\n    print('train_feats', train_feats.shape)\n    print('test_feats', test_feats.shape)\n    assert np.alltrue(train_feats['PetID'].values == train['PetID'].values)\n    assert np.alltrue(test_feats['PetID'].values == test['PetID'].values)\n    return train_x_image_feat, test_x_image_feat\n","execution_count":13,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"798a697eefdfeab9f0561cbda8e16a1ab57253ab","_kg_hide-input":true},"cell_type":"code","source":"# --- preprocessing image ---","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf145aad4c87603af85b8814520bd9397913d4b5","_kg_hide-input":false},"cell_type":"code","source":"\"\"\"\nImage preprocessing using classification model.\n\"\"\"\nimport numpy as np\n\n# import cv2\n\nimport chainer\n# from chainer.iterators import SerialIterator\nfrom chainer import cuda\nimport chainer.functions as F\nfrom chainer.dataset import concat_examples\nfrom chainer.iterators import MultithreadIterator, SerialIterator\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom tqdm import tqdm\n\nimport sys\nimport os\n\n\n# sys.path.append(os.pardir)\n# sys.path.append(os.path.join(os.pardir, os.pardir))\n# from chainercv.links.model.vgg import VGG16\n# from chainercv.links.model.senet.se_resnext import SEResNeXt50\n# from chainercv.links.model.feature_predictor import FeaturePredictor\n# from chainercv.utils.image.read_image import read_image\n# from chainer_chemistry.links.scaler.standard_scaler import StandardScaler\n# from src.models.mlp2 import MLP2\n# from src.rating_eda import load_json\n# from src.pet_image_dataset import PetImageDataset\n# from src.utils import timer, save_npz, load_npz\n# from src.configs import pet_dir, is_kaggle_kernel, vgg16_dir\n\n\ndef prepare_model(arch='vgg16', device=-1):\n    print('prepare_model {}...'.format(arch))\n    if arch == 'vgg16':\n        if is_kaggle_kernel:\n            base_model = VGG16(pretrained_model=os.path.join(\n                vgg16_dir, 'vgg16_imagenet_converted_2017_07_18.npz'))\n        else:\n            base_model = VGG16()\n        # base_model.pick = ['fc7']  # 'fc6'\n        # base_model.pick = ['conv5_3']\n        base_model.pick = ['conv3_3']\n        print('base_model.pick', base_model.pick)\n    elif arch == 'seresnext50':\n        if is_kaggle_kernel:\n            raise NotImplementedError\n            # seresnext50_dir = '../input/seresnext50-chainercv'\n            # base_model = SEResNeXt50(pretrained_model=os.path.join(seresnext50_dir, 'vgg16_imagenet_converted_2017_07_18.npz'))\n        else:\n            base_model = SEResNeXt50()\n        # base_model.pick = ['pool5']  # 'fc6'\n        base_model.pick = ['res3']  # 'fc6'\n        print('base_model.pick', base_model.pick)\n    else:\n        raise ValueError(\"[ERROR] Unexpected value arch={}\"\n                         .format(arch))\n\n    model = FeaturePredictor(\n        base_model, crop_size=224, scale_size=256, crop='center')\n    if device >= 0:\n        chainer.backends.cuda.get_device_from_id(device).use()\n        model.to_gpu()\n    return model\n\n\n# def resize_to_square(im, img_size=256):\n#     old_size = im.shape[:2] # old_size is in (height, width) format\n#     ratio = float(img_size)/max(old_size)\n#     new_size = tuple([int(x*ratio) for x in old_size])\n#     # new_size should be in (width, height) format\n#     im = cv2.resize(im, (new_size[1], new_size[0]))\n#     delta_w = img_size - new_size[1]\n#     delta_h = img_size - new_size[0]\n#     top, bottom = delta_h//2, delta_h-(delta_h//2)\n#     left, right = delta_w//2, delta_w-(delta_w//2)\n#     color = [0, 0, 0]\n#     new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n#     return new_im\n\n\ndef load_image(petid, data_type, num_image=2):\n    image_list = []\n    for index in range(1, num_image + 1):\n        filepath = '{}/{}_images/{}-{}.jpg'.format(pet_dir, data_type, petid, index)\n        if os.path.exists(filepath):\n            image = read_image(filepath)\n            # print('image', type(image), image.dtype, image.shape)\n        else:\n            print('{} not exit'.format(filepath))\n            # image not exist\n            ch = 3\n            h = 256\n            w = 256\n            image = np.zeros((ch, h, w), dtype=np.float32)\n        image_list.append(image)\n    return image_list\n\n\ndef calc_image_features(model, image_list, batch_size=16):\n    pred_list = []\n    for i in tqdm(range(0, len(image_list), batch_size)):\n        pred = model.predict(image_list[i:i+batch_size])\n        # print('pred', pred[0].shape)\n        pred_list.append(pred[0])\n    return np.concatenate(pred_list, axis=0)\n\n\ndef preprocess_image(train, test, num_image=2, device=-1, arch='vgg16',\n                     n_components=None, use_cache=True, animal_type=None,\n                     method='pooling', mode='chainercv'):\n    \"\"\"\n\n    Args:\n        train (): train df\n        test (): test df\n        num_image (int): number of image to extract feature\n        device (int):\n        arch (str): architecture\n        n_components (int or None): if int specified, PCA is applied to\n            reduce dimension.\n        animal_type (None or int): if specified, only use dog or cat images.\n\n    Returns:\n        train_x_image_feat (array): (batch_size, num_image, hidden_dim)\n        test_x_image_feat (array): (batch_size, num_image, hidden_dim)\n    \"\"\"\n    os.makedirs('./cache', exist_ok=True)\n    if animal_type is None:\n        cache_filepath = './cache/x_image_array_arch{}_numimage{}_size{}.npz'\\\n            .format(arch, num_image, len(train))\n    else:\n        cache_filepath = './cache/x_image_array_arch{}_numimage{}_size{}_type{}.npz' \\\n            .format(arch, num_image, len(train), animal_type)\n    if use_cache and os.path.exists(cache_filepath):\n        # load from cache\n        print('loading from cache {}'.format(cache_filepath))\n        train_x_image_array, test_x_image_array = load_npz(cache_filepath)\n    else:\n        # prepare pretrained model\n        if arch == 'densenet':\n            try:\n                from src.preprocessing_image_keras import prepare_model_densenet\n            except:\n                pass\n            model = prepare_model_densenet()\n        else:\n            model = prepare_model(arch=arch, device=device)\n\n        # n_jobs = 8\n        # print('n_jobs', n_jobs)\n        batch_size = 32\n\n        # extract pet id\n        def calc_x_image_array(petids, data_type, num_image, batch_size):\n            image_dataset = PetImageDataset(petids, data_type, num_image, mode=mode)\n            # iterator = MultiprocessIterator(\n            #     image_dataset, batch_size, repeat=False, shuffle=False)\n            iterator = MultithreadIterator(\n                image_dataset, batch_size, repeat=False, shuffle=False)\n            x_image_array = None\n            current_index = 0\n            for batch in tqdm(iterator, total=len(image_dataset) // batch_size):\n                has_image_indices = np.argwhere(np.array([elem is not None for elem in batch]))[:, 0]\n                image_list = [elem for elem in batch if elem is not None]\n                if mode == 'keras':\n                    feats = model.predict(np.array(image_list))\n                else:\n                    if arch in ['vgg16', 'seresnext50']:\n                        feats = model.predict(image_list)[0]\n                        # feats = F.average(feats, axis=(2, 3)).array\n                        feats = np.mean(feats, axis=(2, 3))\n                        # feats = np.max(feats, axis=(2, 3))\n                    else:\n                        feats = model.predict(image_list)[0]\n                if x_image_array is None:\n                    feat_dim = feats.shape[1]\n                    x_image_array = np.zeros((len(image_dataset), feat_dim), dtype=np.float32)\n                x_image_array[has_image_indices + current_index] = feats\n                current_index += batch_size\n            return x_image_array\n\n        train_x_image_array = calc_x_image_array(train['PetID'].values, 'train', num_image, batch_size)\n        test_x_image_array = calc_x_image_array(test['PetID'].values, 'test', num_image, batch_size)\n\n        save_npz(cache_filepath, (train_x_image_array, test_x_image_array))\n        print('saved to {}'.format(cache_filepath))\n\n    # TODO: investigate why it sometimes contains nan...\n    if np.sum(np.isnan(train_x_image_array)) > 0:\n        print('train_x_image_array contains {} nan... replace to 0.'\n              .format(np.sum(np.isnan(train_x_image_array))))\n    train_x_image_array[np.isnan(train_x_image_array)] = 0.\n    test_x_image_array[np.isnan(test_x_image_array)] = 0.\n\n    # # --- DEBUG: cosine distance exp ---\n    import cupy\n    # preprocess_image_cute(device=0, arch='vgg16')\n    x_cute_image_array = train_x_image_array\n\n    print('x_cute_image_array', x_cute_image_array.shape)\n    x_cute_image_array = cupy.asarray(x_cute_image_array)\n    xp = cupy\n\n    # cosine distance experiment...\n    print('calc norm')\n    x_cute_image_array_normlized = x_cute_image_array / xp.sqrt(\n        xp.sum(xp.square(x_cute_image_array), axis=1, keepdims=True))\n    target_index = 0\n    print('calc cosine dist')\n    cosine_distance = xp.sum(\n        x_cute_image_array_normlized[target_index:target_index+1, None, :] * x_cute_image_array_normlized[None, :, :], axis=2)\n    print('cosine_distance', cosine_distance.shape, cosine_distance)\n    import IPython; IPython.embed()\n    # # --- DEBUD end ---\n\n    # train_x_image_array, test_x_image_array = contraction_by_mlp(\n    #     train_x_image_array, test_x_image_array, model_dir='./result', arch=arch)\n    if n_components is not None:\n        train_x_image_array, test_x_image_array = contraction(\n            train_x_image_array, test_x_image_array, n_components,\n            method=method)\n\n    num_hidden = train_x_image_array.shape[-1]\n    xp = cuda.get_array_module(train_x_image_array)\n    train_x_image_feat = xp.reshape(train_x_image_array, (len(train), num_image, num_hidden))\n    test_x_image_feat = xp.reshape(test_x_image_array, (len(test), num_image, num_hidden))\n    return train_x_image_feat, test_x_image_feat\n\n\ndef contraction_by_mlp(train_x_image_array, test_x_image_array, model_dir, device=0,\n                       arch='vgg16'):\n    print('contraction_by_mlp')\n    args_dict = load_json(os.path.join(model_dir, 'args.json'))\n    # scaler = StandardScaler()\n    scaler = None\n    mlp = MLP2(out_dim=1, layer_dims=[args_dict['unit']], use_bn=True,\n               use_sn=False, use_residual=True, scaler=scaler)\n    cute_filepath = os.path.join(model_dir, f'cute_mlp_{arch}.npz')\n    print(f'loading model from {cute_filepath} ...')\n    chainer.serializers.load_npz(cute_filepath, mlp)\n    if device >= 0:\n        mlp.to_gpu(device)\n        chainer.cuda.get_device_from_id(device).use()  # Make a specified GPU current\n    print('forwarding train_x_image_array', train_x_image_array.shape)\n    batch_size = 10240\n    train_h_image = forward(mlp, train_x_image_array, batch_size=batch_size, device=device)\n    test_h_image = forward(mlp, test_x_image_array, batch_size=batch_size, device=device)\n    # train_h_image = mlp.calc(train_x_image_array, extract_hidden=True)\n    # test_h_image = mlp.calc(test_x_image_array, extract_hidden=True)\n    return _to_ndarray(train_h_image), _to_ndarray(test_h_image)\n\n\ndef forward(model, x, batch_size=1024, device=0):\n    iter = SerialIterator(x, batch_size=batch_size, repeat=False, shuffle=False)\n    output_list = []\n    for batch in iter:\n        inputs = concat_examples(batch, device=device)\n        outputs = model.calc(inputs, extract_hidden=True)\n        outputs_array = cuda.to_cpu(outputs.array)\n        output_list.append(outputs_array)\n        if np.sum(np.isnan(outputs_array)) > 0:\n            print('nan detected in forward')\n            import IPython; IPython.embed()\n    return np.concatenate(output_list, axis=0)\n\n\ndef _to_ndarray(x):\n    if isinstance(x, chainer.Variable):\n        x = x.array\n    return cuda.to_cpu(x)\n\n\ndef contraction(train_x_image_array, test_x_image_array, n_components,\n                method='pca', retain_dim=0):\n    contraction_method = method\n    print('contraction_method', contraction_method)\n    if contraction_method == 'pca':\n        with timer('pca image fit n_components={}'.format(n_components)):\n            print('before', train_x_image_array.shape)\n            pca = PCA(n_components=n_components)\n            pca.fit(np.concatenate([train_x_image_array, test_x_image_array], axis=0))\n        with timer('pca image train feature n_components={}'.format(n_components)):\n            train_x_image_array = pca.transform(train_x_image_array).astype(np.float32)\n            print('after', train_x_image_array.shape)\n        with timer('pca image test feature n_components={}'.format(n_components)):\n            test_x_image_array = pca.transform(test_x_image_array).astype(np.float32)\n    elif contraction_method == 'svd':\n        n_test = len(test_x_image_array)\n        svd_ = TruncatedSVD(n_components=n_components, random_state=1337)\n        x_image_array = svd_.fit_transform(np.concatenate([train_x_image_array, test_x_image_array], axis=0))\n        train_x_image_array = x_image_array[:len(train_x_image_array)]\n        test_x_image_array = x_image_array[len(train_x_image_array):]\n        assert len(test_x_image_array) == n_test\n        # with timer('svd image fit n_components={}'.format(n_components)):\n        #     print('before', train_x_image_array.shape)\n        #     svd_.fit(np.concatenate([train_x_image_array, test_x_image_array], axis=0))\n        # with timer('svd image train feature n_components={}'.format(n_components)):\n        #     train_x_image_array = svd_.transform(train_x_image_array).astype(np.float32)\n        #     print('after', train_x_image_array.shape)\n        # with timer('svd image test feature n_components={}'.format(n_components)):\n        #     test_x_image_array = svd_.transform(test_x_image_array).astype(np.float32)\n    elif contraction_method == 'pooling':\n        def pooling(x, n_components):\n            # retain_dim = 6 for detection model, num_person, num_animal, bbox features are remain...\n            x1 = x[:, :retain_dim]  #\n            x2 = x[:, retain_dim:]  # other features.\n            bs, ch = x2.shape\n            p = ch // n_components\n            print('x2', x2.shape, 'n_components', n_components, 'p', p)\n            x2 = np.mean(x2[:, :(n_components * p)].reshape(bs, n_components, p), axis=2)\n            return np.concatenate([x1, x2], axis=1)\n        train_x_image_array = pooling(train_x_image_array, n_components)\n        test_x_image_array = pooling(test_x_image_array, n_components)\n    return train_x_image_array, test_x_image_array\n\n\nif not is_kaggle_kernel and __name__ == '__main__':\n    from src.preprocessing import prepare_df\n\n    debug = False\n    train, test, breeds, colors, states = prepare_df(debug)\n    train_x_image, test_x_image = preprocess_image(\n        train, test, num_image=1, device=0, arch='seresnext50', use_cache=False)\n    print('train_x_image', type(train_x_image), train_x_image.dtype,\n          train_x_image.shape)\n    print('test_x_image', test_x_image.shape)\n    import IPython; IPython.embed()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3772d26d897d2381d308804d6968536f752883a7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fecc1aa4fc721accb46250c3b36fbb944e4c7a8e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e23983431e81b9fa913a1fe23b57c5ad2c9c94ff"},"cell_type":"markdown","source":"## Chainer Chemistry\n\nCodes copied from [chainer_chemistry](https://github.com/pfnet-research/chainer-chemistry), MIT license.\n\nI hope it is supported in kaggle default docker: [PR to support it in default docker](https://github.com/Kaggle/docker-python/pull/447)."},{"metadata":{"trusted":true,"_uuid":"7cb46609e73dc13d1ded033e5397df8d03e7a681"},"cell_type":"code","source":"import chainer\nfrom chainer.functions import relu\nfrom chainer import links\n\n\nclass MLP(chainer.Chain):\n\n    \"\"\"Basic implementation for MLP\n\n    Args:\n        out_dim (int): dimension of output feature vector\n        hidden_dim (int): dimension of feature vector\n            associated to each atom\n        n_layers (int): number of layers\n        activation (chainer.functions): activation function\n    \"\"\"\n\n    def __init__(self, out_dim, hidden_dim=16, n_layers=2, activation=relu):\n        super(MLP, self).__init__()\n        if n_layers <= 0:\n            raise ValueError('n_layers must be a positive integer, but it was '\n                             'set to {}'.format(n_layers))\n        layers = [links.Linear(None, hidden_dim) for i in range(n_layers - 1)]\n        with self.init_scope():\n            self.layers = chainer.ChainList(*layers)\n            self.l_out = links.Linear(None, out_dim)\n        self.activation = activation\n\n    def __call__(self, x):\n        h = x\n        for l in self.layers:\n            h = self.activation(l(h))\n        h = self.l_out(h)\n        return h\n","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f21ccdc119291d173634abeadfdaa3c6b80800ed"},"cell_type":"code","source":"import copy\nfrom logging import getLogger\n\nimport numpy\n\nimport chainer\nfrom chainer import cuda\nfrom chainer.dataset import convert\nfrom chainer import reporter\nfrom chainer.training.extensions import Evaluator\n\n\ndef _get_1d_numpy_array(v):\n    \"\"\"Convert array or Variable to 1d numpy array\n\n    Args:\n        v (numpy.ndarray or cupy.ndarray or chainer.Variable): array to be\n            converted to 1d numpy array\n\n    Returns (numpy.ndarray): Raveled 1d numpy array\n\n    \"\"\"\n    if isinstance(v, chainer.Variable):\n        v = v.data\n    return cuda.to_cpu(v).ravel()\n\n\nclass BatchEvaluator(Evaluator):\n\n    def __init__(self, iterator, target, converter=convert.concat_examples,\n                 device=None, eval_hook=None, eval_func=None, metrics_fun=None,\n                 name=None, logger=None):\n        super(BatchEvaluator, self).__init__(\n            iterator, target, converter=converter, device=device,\n            eval_hook=eval_hook, eval_func=eval_func)\n        self.name = name\n        self.logger = logger or getLogger()\n\n        if callable(metrics_fun):\n            # TODO(mottodora): use better name or infer\n            self.metrics_fun = {\"evaluation\": metrics_fun}\n        elif isinstance(metrics_fun, dict):\n            self.metrics_fun = metrics_fun\n        else:\n            raise TypeError('Unexpected type metrics_fun must be Callable or '\n                            'dict.')\n\n    def evaluate(self):\n        iterator = self._iterators['main']\n        eval_func = self.eval_func or self._targets['main']\n\n        if self.eval_hook:\n            self.eval_hook(self)\n\n        if hasattr(iterator, 'reset'):\n            iterator.reset()\n            it = iterator\n        else:\n            it = copy.copy(iterator)\n\n        y_total = []\n        t_total = []\n        for batch in it:\n            in_arrays = self.converter(batch, self.device)\n            with chainer.no_backprop_mode(), chainer.using_config('train',\n                                                                  False):\n                y = eval_func(*in_arrays[:-1])\n            t = in_arrays[-1]\n            y_data = _get_1d_numpy_array(y)\n            t_data = _get_1d_numpy_array(t)\n            y_total.append(y_data)\n            t_total.append(t_data)\n\n        y_total = numpy.concatenate(y_total).ravel()\n        t_total = numpy.concatenate(t_total).ravel()\n        # metrics_value = self.metrics_fun(y_total, t_total)\n        metrics = {key: metric_fun(y_total, t_total) for key, metric_fun in\n                   self.metrics_fun.items()}\n\n        observation = {}\n        with reporter.report_scope(observation):\n            reporter.report(metrics, self._targets['main'])\n        return observation\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a3ed84d9f29c28e876a4e2eabb0994dff5cf389"},"cell_type":"code","source":"import os\nimport six\n\nimport numpy\n\n# from chainer_chemistry.dataset.indexers.numpy_tuple_dataset_feature_indexer import NumpyTupleDatasetFeatureIndexer  # NOQA\n\n\nclass NumpyTupleDataset(object):\n\n    \"\"\"Dataset of a tuple of datasets.\n\n    It combines multiple datasets into one dataset. Each example is represented\n    by a tuple whose ``i``-th item corresponds to the i-th dataset.\n    And each ``i``-th dataset is expected to be an instance of numpy.ndarray.\n\n    Args:\n        datasets: Underlying datasets. The ``i``-th one is used for the\n            ``i``-th item of each example. All datasets must have the same\n            length.\n\n    \"\"\"\n\n    def __init__(self, *datasets):\n        if not datasets:\n            raise ValueError('no datasets are given')\n        length = len(datasets[0])\n        for i, dataset in enumerate(datasets):\n            if len(dataset) != length:\n                raise ValueError(\n                    'dataset of the index {} has a wrong length'.format(i))\n        self._datasets = datasets\n        self._length = length\n#         self._features_indexer = NumpyTupleDatasetFeatureIndexer(self)\n        self._features_indexer = None  # Hacking. not use it.\n\n    def __getitem__(self, index):\n        batches = [dataset[index] for dataset in self._datasets]\n        if isinstance(index, (slice, list, numpy.ndarray)):\n            length = len(batches[0])\n            return [tuple([batch[i] for batch in batches])\n                    for i in six.moves.range(length)]\n        else:\n            return tuple(batches)\n\n    def __len__(self):\n        return self._length\n\n    def get_datasets(self):\n        return self._datasets\n\n    @property\n    def features(self):\n        \"\"\"Extract features according to the specified index.\n\n        - axis 0 is used to specify dataset id (`i`-th dataset)\n        - axis 1 is used to specify feature index\n\n        .. admonition:: Example\n\n           >>> import numpy\n           >>> from chainer_chemistry.datasets import NumpyTupleDataset\n           >>> x = numpy.array([0, 1, 2], dtype=numpy.float32)\n           >>> t = x * x\n           >>> numpy_tuple_dataset = NumpyTupleDataset(x, t)\n           >>> targets = numpy_tuple_dataset.features[:, 1]\n           >>> print('targets', targets)  # We can extract only target value\n           targets [0, 1, 4]\n\n        \"\"\"\n        return self._features_indexer\n\n    @classmethod\n    def save(cls, filepath, numpy_tuple_dataset):\n        \"\"\"save the dataset to filepath in npz format\n\n        Args:\n            filepath (str): filepath to save dataset. It is recommended to end\n                with '.npz' extension.\n            numpy_tuple_dataset (NumpyTupleDataset): dataset instance\n\n        \"\"\"\n        if not isinstance(numpy_tuple_dataset, NumpyTupleDataset):\n            raise TypeError('numpy_tuple_dataset is not instance of '\n                            'NumpyTupleDataset, got {}'\n                            .format(type(numpy_tuple_dataset)))\n        numpy.savez(filepath, *numpy_tuple_dataset._datasets)\n\n    @classmethod\n    def load(cls, filepath):\n        if not os.path.exists(filepath):\n            return None\n        load_data = numpy.load(filepath)\n        result = []\n        i = 0\n        while True:\n            key = 'arr_{}'.format(i)\n            if key in load_data.keys():\n                result.append(load_data[key])\n                i += 1\n            else:\n                break\n        return NumpyTupleDataset(*result)\n","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdcdf75bcf554b0785d68d3c6410802f592de61c"},"cell_type":"code","source":"import pickle\n\nimport chainer\nfrom chainer import cuda\nfrom chainer.dataset.convert import concat_examples\nfrom chainer.iterators import SerialIterator\nfrom chainer import link\nimport numpy\n\n\ndef _to_tuple(x):\n    if not isinstance(x, tuple):\n        x = (x,)\n    return x\n\n\ndef _extract_numpy(x):\n    if isinstance(x, chainer.Variable):\n        x = x.data\n    return cuda.to_cpu(x)\n\n\nclass BaseForwardModel(link.Chain):\n\n    \"\"\"A base model which supports forward functionality.\n\n    It also supports `device` id management and pickle save/load functionality.\n\n    Args:\n        device (int): GPU device id of this model to be used.\n            -1 indicates to use in CPU.\n\n    Attributes:\n        _dev_id (int): Model's current device id\n\n    \"\"\"\n\n    def __init__(self):\n        super(BaseForwardModel, self).__init__()\n\n        self.inputs = None\n        self._dev_id = None\n\n    def get_device(self):\n        return self._dev_id\n\n    def initialize(self, device=-1):\n        \"\"\"Initialization of the model.\n\n        It must be executed **after** the link registration\n        (often done by `with self.init_scope()` finished.\n\n        Args:\n            device (int): GPU device id of this model to be used.\n            -1 indicates to use in CPU.\n\n        \"\"\"\n        self.update_device(device=device)\n\n    def update_device(self, device=-1):\n        if self._dev_id is None or self._dev_id != device:\n            # reset current state\n            self.to_cpu()\n\n            # update the model to specified device id\n            self._dev_id = device\n            if device >= 0:\n                chainer.cuda.get_device_from_id(device).use()\n                self.to_gpu()  # Copy the model to the GPU\n\n    def _forward(self, data, fn, batchsize=16,\n                 converter=concat_examples, retain_inputs=False,\n                 preprocess_fn=None, postprocess_fn=None):\n        \"\"\"Forward data by iterating with batch\n\n        Args:\n            data: \"train_x array\" or \"chainer dataset\"\n            fn (Callable): Main function to forward. Its input argument is\n                either Variable, cupy.ndarray or numpy.ndarray, and returns\n                Variable.\n            batchsize (int): batch size\n            converter (Callable): convert from `data` to `inputs`\n            retain_inputs (bool): If True, this instance keeps inputs in\n                `self.inputs` or not.\n            preprocess_fn (Callable): Its input is numpy.ndarray or\n                cupy.ndarray, it can return either Variable, cupy.ndarray or\n                numpy.ndarray\n            postprocess_fn (Callable): Its input argument is Variable,\n                but this method may return either Variable, cupy.ndarray or\n                numpy.ndarray.\n\n        Returns (tuple or numpy.ndarray): forward result\n\n        \"\"\"\n        input_list = None\n        output_list = None\n        it = SerialIterator(data, batch_size=batchsize, repeat=False,\n                            shuffle=False)\n        for batch in it:\n            inputs = converter(batch, self._dev_id)\n            inputs = _to_tuple(inputs)\n\n            if preprocess_fn:\n                inputs = preprocess_fn(*inputs)\n                inputs = _to_tuple(inputs)\n\n            outputs = fn(*inputs)\n            outputs = _to_tuple(outputs)\n\n            # Init\n            if retain_inputs:\n                if input_list is None:\n                    input_list = [[] for _ in range(len(inputs))]\n                for j, input in enumerate(inputs):\n                    input_list[j].append(cuda.to_cpu(input))\n            if output_list is None:\n                output_list = [[] for _ in range(len(outputs))]\n\n            if postprocess_fn:\n                outputs = postprocess_fn(*outputs)\n                outputs = _to_tuple(outputs)\n            for j, output in enumerate(outputs):\n                output_list[j].append(_extract_numpy(output))\n\n        if retain_inputs:\n            self.inputs = [numpy.concatenate(\n                in_array) for in_array in input_list]\n\n        result = [numpy.concatenate(output) for output in output_list]\n        if len(result) == 1:\n            return result[0]\n        else:\n            return result\n\n    def save_pickle(self, filepath, protocol=None):\n        \"\"\"Save the model to `filepath` as a pickle file\n\n        This function send the parameters to CPU before saving the model so\n        that the pickled file can be loaded with in CPU-only environment. \n        After the model is saved, it is sent back to the original device.\n\n        Saved pickle file can be loaded with `load_pickle` static method.\n\n        Note that the transportability of the saved file follows the\n        specification of `pickle` module, namely serialized data depends on the\n        specific class or attribute structure when saved. The file may not be\n        loaded in different environment (version of python or dependent\n        libraries), or after large refactoring of the pickled object class.\n        If you want to avoid it, use `chainer.serializers.save_npz`\n        method instead to save only model parameters.\n\n    .. admonition:: Example\n\n       >>> from chainer_chemistry.models import BaseForwardModel\n       >>> class DummyForwardModel(BaseForwardModel):\n       >>> \n       >>>     def __init__(self, device=-1):\n       >>>         super(DummyForwardModel, self).__init__()\n       >>>         with self.init_scope():\n       >>>             self.l = chainer.links.Linear(3, 10)\n       >>>         self.initialize(device)\n       >>> \n       >>>     def __call__(self, x):\n       >>>         return self.l(x)\n       >>>\n       >>> model = DummyForwardModel()\n       >>> filepath = 'model.pkl'\n       >>> model.save_pickle(filepath)  \n\n        Args:\n            filepath (str): file path of pickle file.\n            protocol (int or None): protocol version used in `pickle`.\n                Use 2 if you need python2/python3 compatibility.\n                3 or higher is used for python3.\n                Please refer the official document [1] for more details.\n                [1]: https://docs.python.org/3.6/library/pickle.html#module-interface\n\n        \"\"\"  # NOQA\n        current_device = self.get_device()\n\n        # --- Move the model to CPU for saving ---\n        self.update_device(-1)\n        with open(filepath, mode='wb') as f:\n            pickle.dump(self, f, protocol=protocol)\n\n        # --- Revert the model to original device ---\n        self.update_device(current_device)\n\n    @staticmethod\n    def load_pickle(filepath, device=-1):\n        \"\"\"Load the model from `filepath` of pickle file, and send to `device`\n\n        The file saved by `save_pickle` method can be loaded, but it may fail\n        to load when loading from different develop environment or after\n        updating library version.\n        See `save_pickle` method for the transportability of the saved file.\n\n    .. admonition:: Example\n\n       >>> from chainer_chemistry.models import BaseForwardModel\n       >>> filepath = 'model.pkl'\n       >>> # `load_pickle` is static method, call from Class to get an instance\n       >>> model = BaseForwardModel.load_pickle(filepath)\n\n        Args:\n            filepath (str): file path of pickle file.\n            device (int): GPU device id of this model to be used.\n                -1 indicates to use in CPU.\n\n        \"\"\"\n        with open(filepath, mode='rb') as f:\n            model = pickle.load(f)\n\n        if not isinstance(model, BaseForwardModel):\n            raise TypeError('Unexpected type {}'.format(type(model)))\n\n        # --- Revert the model to specified device ---\n        model.initialize(device)\n        return model\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c31aebfa3b5888b08a2d308806ccfcb27ca818e4"},"cell_type":"code","source":"import numpy\n\nimport chainer\nfrom chainer.dataset.convert import concat_examples\nfrom chainer import cuda, Variable  # NOQA\nfrom chainer import reporter\n#from chainer_chemistry.models.prediction.base import BaseForwardModel\n\n\nclass Regressor(BaseForwardModel):\n    \"\"\"A simple regressor model.\n\n    This is an example of chain that wraps another chain. It computes the\n    loss and metrics based on a given input/label pair.\n\n    Args:\n        predictor (~chainer.Link): Predictor network.\n        lossfun (function): Loss function.\n        metrics_fun (function or dict or None): Function that computes metrics.\n        label_key (int or str): Key to specify label variable from arguments.\n            When it is ``int``, a variable in positional arguments is used.\n            And when it is ``str``, a variable in keyword arguments is used.\n        device (int): GPU device id of this Regressor to be used.\n            -1 indicates to use in CPU.\n\n    Attributes:\n        predictor (~chainer.Link): Predictor network.\n        lossfun (function): Loss function.\n        y (~chainer.Variable): Prediction for the last minibatch.\n        loss (~chainer.Variable): Loss value for the last minibatch.\n        metrics (dict): Metrics computed in last minibatch\n        compute_metrics (bool): If ``True``, compute metrics on the forward\n            computation. The default value is ``True``.\n\n    \"\"\"\n\n    compute_metrics = True\n\n    def __init__(self, predictor,\n                 lossfun=chainer.functions.mean_squared_error,\n                 metrics_fun=None, label_key=-1, device=-1):\n        if not (isinstance(label_key, (int, str))):\n            raise TypeError('label_key must be int or str, but is %s' %\n                            type(label_key))\n        super(Regressor, self).__init__()\n        self.lossfun = lossfun\n        if metrics_fun is None:\n            self.compute_metrics = False\n            self.metrics_fun = {}\n        elif callable(metrics_fun):\n            self.metrics_fun = {'metrics': metrics_fun}\n        elif isinstance(metrics_fun, dict):\n            self.metrics_fun = metrics_fun\n        else:\n            raise TypeError('Unexpected type metrics_fun must be None or '\n                            'Callable or dict. actual {}'\n                            .format(type(metrics_fun)))\n        self.y = None\n        self.loss = None\n        self.metrics = None\n        self.label_key = label_key\n\n        with self.init_scope():\n            self.predictor = predictor\n\n        # `initialize` must be called after `init_scope`.\n        self.initialize(device)\n\n    def _convert_to_scalar(self, value):\n        \"\"\"Converts an input value to a scalar if its type is a Variable,\n        numpy or cupy array, otherwise it returns the value as it is.\n        \"\"\"\n        if isinstance(value, Variable):\n            value = value.array\n        if numpy.isscalar(value):\n            return value\n        if type(value) is not numpy.array:\n            value = cuda.to_cpu(value)\n        return numpy.asscalar(value)\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"Computes the loss value for an input and label pair.\n\n        It also computes metrics and stores it to the attribute.\n\n        Args:\n            args (list of ~chainer.Variable): Input minibatch.\n            kwargs (dict of ~chainer.Variable): Input minibatch.\n\n        When ``label_key`` is ``int``, the correpoding element in ``args``\n        is treated as ground truth labels. And when it is ``str``, the\n        element in ``kwargs`` is used.\n        The all elements of ``args`` and ``kwargs`` except the ground trush\n        labels are features.\n        It feeds features to the predictor and compare the result\n        with ground truth labels.\n\n        Returns:\n            ~chainer.Variable: Loss value.\n\n        \"\"\"\n\n        # --- Separate `args` and `t` ---\n        if isinstance(self.label_key, int):\n            if not (-len(args) <= self.label_key < len(args)):\n                msg = 'Label key %d is out of bounds' % self.label_key\n                raise ValueError(msg)\n            t = args[self.label_key]\n            if self.label_key == -1:\n                args = args[:-1]\n            else:\n                args = args[:self.label_key] + args[self.label_key + 1:]\n        elif isinstance(self.label_key, str):\n            if self.label_key not in kwargs:\n                msg = 'Label key \"%s\" is not found' % self.label_key\n                raise ValueError(msg)\n            t = kwargs[self.label_key]\n            del kwargs[self.label_key]\n        else:\n            raise TypeError('Label key type {} not supported'\n                            .format(type(self.label_key)))\n\n        self.y = None\n        self.loss = None\n        self.metrics = None\n        self.y = self.predictor(*args, **kwargs)\n        self.loss = self.lossfun(self.y, t)\n\n        # When the reported data is a numpy array, the loss and metrics values\n        # are scalars. When the reported data is a cupy array, sometimes the\n        # same values become arrays instead. This seems to be a bug inside the\n        # reporter class, which needs to be addressed and fixed. Until then,\n        # the reported values will be converted to numpy arrays.\n        reporter.report(\n            {'loss': self._convert_to_scalar(self.loss)}, self)\n\n        if self.compute_metrics:\n            # Note: self.metrics_fun is `dict`,\n            # which is different from original chainer implementation\n            self.metrics = {key: self._convert_to_scalar(value(self.y, t))\n                            for key, value in self.metrics_fun.items()}\n            reporter.report(self.metrics, self)\n        return self.loss\n\n    def predict(\n            self, data, batchsize=16, converter=concat_examples,\n            retain_inputs=False, preprocess_fn=None, postprocess_fn=None):\n        \"\"\"Predict label of each category by taking .\n\n        Args:\n            data: input data\n            batchsize (int): batch size\n            converter (Callable): convert from `data` to `inputs`\n            preprocess_fn (Callable): Its input is numpy.ndarray or\n                cupy.ndarray, it can return either Variable, cupy.ndarray or\n                numpy.ndarray\n            postprocess_fn (Callable): Its input argument is Variable,\n                but this method may return either Variable, cupy.ndarray or\n                numpy.ndarray.\n            retain_inputs (bool): If True, this instance keeps inputs in\n                `self.inputs` or not.\n\n        Returns (tuple or numpy.ndarray): Typically, it is 1-dimensional int\n            array with shape (batchsize, ) which represents each examples\n            category prediction.\n\n        \"\"\"\n        with chainer.no_backprop_mode(), chainer.using_config('train', False):\n            predict_labels = self._forward(\n                data, fn=self.predictor, batchsize=batchsize,\n                converter=converter, retain_inputs=retain_inputs,\n                preprocess_fn=preprocess_fn, postprocess_fn=postprocess_fn)\n        return predict_labels\n","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae670b4742bfde962cb87e6262e058b3cafd1c3c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c89dbd6693f4ea48f420214e80ce6e4486ce94c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3c7361a350bef2f91f3d2853b55b086c038627d"},"cell_type":"markdown","source":"## utils for this task"},{"metadata":{},"cell_type":"markdown","source":"Codes from [pfnet-research/sngan_projection](https://github.com/pfnet-research/sngan_projection), under MIT license.\nSome of the codes are copied from this repository to use spectral normalization for regularization of Neural Network."},{"metadata":{"trusted":true,"_uuid":"681fa13d01b937c93b475157e49366087eea56ac"},"cell_type":"code","source":"# --- models.sn.max_sv ---","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cd7359da01362414cb467892dfa1e7630e4fa22"},"cell_type":"code","source":"import chainer.functions as F\nfrom chainer import cuda\n\n\ndef _l2normalize(v, eps=1e-12):\n    norm = cuda.reduce('T x', 'T out',\n                       'x * x', 'a + b', 'out = sqrt(a)', 0,\n                       'norm_sn')\n    div = cuda.elementwise('T x, T norm, T eps',\n                           'T out',\n                           'out = x / (norm + eps)',\n                           'div_sn')\n    return div(v, norm(v), eps)\n\n\ndef max_singular_value(W, u=None, Ip=1):\n    \"\"\"\n    Apply power iteration for the weight parameter\n    \"\"\"\n    if not Ip >= 1:\n        raise ValueError(\"The number of power iterations should be positive integer\")\n\n    xp = cuda.get_array_module(W.data)\n    if u is None:\n        u = xp.random.normal(size=(1, W.shape[0])).astype(xp.float32)\n    _u = u\n    for _ in range(Ip):\n        _v = _l2normalize(xp.dot(_u, W.data), eps=1e-12)\n        _u = _l2normalize(xp.dot(_v, W.data.transpose()), eps=1e-12)\n    sigma = F.sum(F.linear(_u, F.transpose(W)) * _v)\n    return sigma, _u, _v\n\n\ndef max_singular_value_fully_differentiable(W, u=None, Ip=1):\n    \"\"\"\n    Apply power iteration for the weight parameter (fully differentiable version)\n    \"\"\"\n    if not Ip >= 1:\n        raise ValueError(\"The number of power iterations should be positive integer\")\n\n    xp = cuda.get_array_module(W.data)\n    if u is None:\n        u = xp.random.normal(size=(1, W.shape[0])).astype(xp.float32)\n    _u = u\n    for _ in range(Ip):\n        _v = F.normalize(F.matmul(_u, W), eps=1e-12)\n        _u = F.normalize(F.matmul(_v, F.transpose(W)), eps=1e-12)\n    _u = F.matmul(_v, F.transpose(W))\n    norm = F.sqrt(F.sum(_u ** 2))\n    return norm, _l2normalize(_u.data), _v\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cc4c7b3ae5d76739f330d8aeaa4286d81c40ff5"},"cell_type":"code","source":"# --- sn_linear & sn_mlp ---","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6eff4e1b19c206d27646412a362972a887c1926"},"cell_type":"code","source":"import chainer\nimport numpy as np\nfrom chainer import cuda\nfrom chainer.functions.array.broadcast import broadcast_to\nfrom chainer.functions.connection import linear\nfrom chainer.links.connection.linear import Linear\n\n#from src.models.sn.max_sv import max_singular_value\n\n\nclass SNLinear(Linear):\n    \"\"\"Linear layer with Spectral Normalization.\n\n    Args:\n        in_size (int): Dimension of input vectors. If ``None``, parameter\n            initialization will be deferred until the first forward datasets pass\n            at which time the size will be determined.\n        out_size (int): Dimension of output vectors.\n        wscale (float): Scaling factor of the weight matrix.\n        bias (float): Initial bias value.\n        nobias (bool): If ``True``, then this function does not use the bias.\n        initialW (2-D array): Initial weight value. If ``None``, then this\n            function uses to initialize ``wscale``.\n            May also be a callable that takes ``numpy.ndarray`` or\n            ``cupy.ndarray`` and edits its value.\n        initial_bias (1-D array): Initial bias value. If ``None``, then this\n            function uses to initialize ``bias``.\n            May also be a callable that takes ``numpy.ndarray`` or\n            ``cupy.ndarray`` and edits its value.\n        use_gamma (bool): If true, apply scalar multiplication to the\n            normalized weight (i.e. reparameterize).\n        Ip (int): The number of power iteration for calculating the spcetral\n            norm of the weights.\n        factor (float) : constant factor to adjust spectral norm of W_bar.\n\n    .. seealso:: :func:`~chainer.functions.linear`\n\n    Attributes:\n        W (~chainer.Variable): Weight parameter.\n        W_bar (~chainer.Variable): Spectrally normalized weight parameter.\n        b (~chainer.Variable): Bias parameter.\n        u (~numpy.array): Current estimation of the right largest singular vector of W.\n        (optional) gamma (~chainer.Variable): the multiplier parameter.\n        (optional) factor (float): constant factor to adjust spectral norm of W_bar.\n\n    \"\"\"\n\n    def __init__(self, in_size, out_size, use_gamma=False, nobias=False,\n                 initialW=None, initial_bias=None, Ip=1, factor=None):\n        self.Ip = Ip\n        self.use_gamma = use_gamma\n        self.factor = factor\n        super(SNLinear, self).__init__(\n            in_size, out_size, nobias, initialW, initial_bias\n        )\n        self.u = np.random.normal(size=(1, out_size)).astype(dtype=\"f\")\n        self.register_persistent('u')\n\n    @property\n    def W_bar(self):\n        \"\"\"\n        Spectral Normalized Weight\n        \"\"\"\n        sigma, _u, _ = max_singular_value(self.W, self.u, self.Ip)\n        if self.factor:\n            sigma = sigma / self.factor\n        sigma = broadcast_to(sigma.reshape((1, 1)), self.W.shape)\n        self.u[:] = _u\n        if hasattr(self, 'gamma'):\n            return broadcast_to(self.gamma, self.W.shape) * self.W / sigma\n        else:\n            return self.W / sigma\n\n    def _initialize_params(self, in_size):\n        super(SNLinear, self)._initialize_params(in_size)\n        if self.use_gamma:\n            _, s, _ = np.linalg.svd(cuda.to_cpu(self.W.data))\n            with self.init_scope():\n                self.gamma = chainer.Parameter(s[0], (1, 1))\n\n    def __call__(self, x):\n        \"\"\"Applies the linear layer.\n\n        Args:\n            x (~chainer.Variable): Batch of input vectors.\n\n        Returns:\n            ~chainer.Variable: Output of the linear layer.\n\n        \"\"\"\n        if self.W.data is None:\n            self._initialize_params(x.size // x.shape[0])\n        return linear.linear(x, self.W_bar, self.b)\n","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efe6d14fdea18fbd27bfc2ae95c1ebbd761b81d9"},"cell_type":"code","source":"from chainer.functions.connection import embed_id\nfrom chainer.initializers import normal\nfrom chainer import link\nfrom chainer import variable\nfrom chainer.functions.array.broadcast import broadcast_to\nimport numpy as np\n\n# from src.models.sn.max_sv import max_singular_value\n\n\nclass SNEmbedID(link.Link):\n    \"\"\"Efficient linear layer for one-hot input.\n    This is a link that wraps the :func:`~chainer.functions.embed_id` function.\n    This link holds the ID (word) embedding matrix ``W`` as a parameter.\n    Args:\n        in_size (int): Number of different identifiers (a.k.a. vocabulary\n            size).\n        out_size (int): Size of embedding vector.\n        initialW (2-D array): Initial weight value. If ``None``, then the\n            matrix is initialized from the standard normal distribution.\n            May also be a callable that takes ``numpy.ndarray`` or\n            ``cupy.ndarray`` and edits its value.\n        ignore_label (int or None): If ``ignore_label`` is an int value,\n            ``i``-th column of return value is filled with ``0``.\n        Ip (int): The number of power iteration for calculating the spcetral\n            norm of the weights.\n        factor (float) : constant factor to adjust spectral norm of W_bar.\n    .. seealso:: :func:`chainer.functions.embed_id`\n    Attributes:\n        W (~chainer.Variable): Embedding parameter matrix.\n        W_bar (~chainer.Variable): Spectrally normalized weight parameter.\n        u (~numpy.array): Current estimation of the right largest singular vector of W.\n        (optional) gamma (~chainer.Variable): the multiplier parameter.\n        (optional) factor (float): constant factor to adjust spectral norm of W_bar.\n    \"\"\"\n\n    ignore_label = None\n\n    def __init__(self, in_size, out_size, initialW=None, ignore_label=None, Ip=1, factor=None):\n        super(SNEmbedID, self).__init__()\n        self.ignore_label = ignore_label\n        self.Ip = Ip\n        self.factor = factor\n        with self.init_scope():\n            if initialW is None:\n                initialW = normal.Normal(1.0)\n            self.W = variable.Parameter(initialW, (in_size, out_size))\n\n        self.u = np.random.normal(size=(1, in_size)).astype(dtype=\"f\")\n        self.register_persistent('u')\n\n    @property\n    def W_bar(self):\n        \"\"\"\n        Spectral Normalized Weight\n        \"\"\"\n        sigma, _u, _ = max_singular_value(self.W, self.u, self.Ip)\n        if self.factor:\n            sigma = sigma / self.factor\n        sigma = broadcast_to(sigma.reshape((1, 1)), self.W.shape)\n        self.u[:] = _u\n        return self.W / sigma\n\n    def __call__(self, x):\n        \"\"\"Extracts the word embedding of given IDs.\n        Args:\n            x (~chainer.Variable): Batch vectors of IDs.\n        Returns:\n            ~chainer.Variable: Batch of corresponding embeddings.\n        \"\"\"\n        return embed_id.embed_id(x, self.W_bar, ignore_label=self.ignore_label)\n","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neural Network model definition..."},{"metadata":{"trusted":true,"_uuid":"6db38501c9482dad1d4246bae2694ab674a11742"},"cell_type":"code","source":"# --- mlp ---","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f75b760124f89ef24682eaebeef7eaf02f1e366"},"cell_type":"code","source":"import chainer\nfrom chainer.functions import relu\nimport chainer.functions as F\nfrom chainer import links\n\nclass MLP(chainer.Chain):\n\n    \"\"\"Basic implementation for MLP\n\n    Args:\n        out_dim (int): dimension of output feature vector\n        hidden_dim (int): dimension of feature vector\n            associated to each atom\n        n_layers (int): number of layers\n        activation (chainer.functions): activation function\n    \"\"\"\n\n    def __init__(self, out_dim, hidden_dim=16, n_layers=2, activation=relu,\n                 use_bn=False, use_sn=False, use_gamma=True, use_residual=False,\n                 dropout_ratio=0):\n        super(MLP, self).__init__()\n        if n_layers <= 0:\n            raise ValueError('n_layers must be a positive integer, but it was '\n                             'set to {}'.format(n_layers))\n        if use_sn:\n            layers = [SNLinear(None, hidden_dim, use_gamma=use_gamma) for i in range(n_layers - 1)]\n        else:\n            layers = [links.Linear(None, hidden_dim) for i in range(n_layers - 1)]\n        with self.init_scope():\n            self.layers = chainer.ChainList(*layers)\n            if use_sn:\n                self.l_out = SNLinear(None, out_dim, use_gamma=use_gamma)\n            else:\n                self.l_out = links.Linear(None, out_dim)\n            if use_bn:\n                self.bn_layers = chainer.ChainList(\n                    *[links.BatchNormalization(hidden_dim) for i in range(n_layers - 1)])\n\n        self.activation = activation\n        self.use_bn = use_bn\n        self.use_residual = use_residual\n        self.dropout_ratio = dropout_ratio\n\n    def __call__(self, x):\n        h = x\n        if self.use_bn:\n            for l, bn in zip(self.layers, self.bn_layers):\n                if self.dropout_ratio > 0:\n                    h = F.dropout(x, self.dropout_ratio)\n                h2 = self.activation(bn(l(h)))\n                if self.use_residual and h.shape == h2.shape:\n                    h = h + h2\n                else:\n                    h = h2\n        else:\n            for l in self.layers:\n                if self.dropout_ratio > 0:\n                    h = F.dropout(x, self.dropout_ratio)\n                h2 = self.activation(l(h))\n                if self.use_residual and h.shape == h2.shape:\n                    h = h + h2\n                else:\n                    h = h2\n        h = self.l_out(h)\n        return h\n\n\nclass ProjectionMLP(chainer.Chain):\n\n    \"\"\"Basic implementation for MLP\n\n    Args:\n        out_dim (int): dimension of output feature vector\n        hidden_dim (int): dimension of feature vector\n            associated to each atom\n        n_layers (int): number of layers\n        activation (chainer.functions): activation function\n    \"\"\"\n\n    def __init__(self, out_dim, hidden_dim=16, n_layers=2, activation=relu,\n                 use_bn=False, use_sn=False, use_gamma=True, use_residual=False):\n        super(ProjectionMLP, self).__init__()\n        if n_layers <= 0:\n            raise ValueError('n_layers must be a positive integer, but it was '\n                             'set to {}'.format(n_layers))\n        if use_sn:\n            layers = [SNLinear(None, hidden_dim, use_gamma=use_gamma) for i in range(n_layers - 1)]\n        else:\n            layers = [links.Linear(None, hidden_dim) for i in range(n_layers - 1)]\n        with self.init_scope():\n            self.layers = chainer.ChainList(*layers)\n            if use_sn:\n                self.l_out = SNLinear(None, out_dim, use_gamma=use_gamma)\n            else:\n                self.l_out = links.Linear(None, out_dim)\n            if use_bn:\n                self.bn_layers = chainer.ChainList(\n                    *[links.BatchNormalization(hidden_dim) for i in range(n_layers - 1)])\n            cat_size = 2  # dog and cat\n            self.embed = links.EmbedID(cat_size, hidden_dim)\n\n        self.activation = activation\n        self.use_bn = use_bn\n        self.use_residual = use_residual\n\n    def __call__(self, x, cat):\n        h = x\n        h_cat = self.embed(cat)\n        if self.use_bn:\n            for i, (l, bn) in enumerate(zip(self.layers, self.bn_layers)):\n                h2 = self.activation(bn(l(h)))\n                if self.use_residual and h.shape == h2.shape:\n                    h = h + h2\n                else:\n                    h = h2\n                # if i == 0:\n                #     h = h * h_cat\n        else:\n            for i, l in enumerate(self.layers):\n                h2 = self.activation(l(h))\n                if self.use_residual and h.shape == h2.shape:\n                    h = h + h2\n                else:\n                    h = h2\n                # if i == 0:\n                #     h = h * h_cat\n        # h_cat = self.embed(cat)\n        h = h + h * h_cat\n        h = self.l_out(h)\n        return h\n","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2311917091b707778cc6e3d91586f76de2426604"},"cell_type":"code","source":"# --- mlp2 ---\n\nimport chainer\nfrom chainer.functions import relu\nimport chainer.functions as F\nfrom chainer import links\n\n\nclass MLP2(chainer.Chain):\n\n    \"\"\"Basic implementation for MLP\n\n    Args:\n        out_dim (int): dimension of output feature vector\n        hidden_dim (int): dimension of feature vector\n            associated to each atom\n        n_layers (int): number of layers\n        activation (chainer.functions): activation function\n    \"\"\"\n\n    def __init__(self, out_dim, layer_dims=None, activation=relu,\n                 use_bn=False, use_sn=False, use_gamma=True, use_residual=False,\n                 dropout_ratio=0, scaler=None):\n        super(MLP2, self).__init__()\n        if layer_dims is None:\n            layer_dims = [16, 16]\n        n_layers = len(layer_dims) + 1\n        if n_layers <= 0:\n            raise ValueError('n_layers must be a positive integer, but it was '\n                             'set to {}'.format(n_layers))\n        if use_sn:\n            layers = [SNLinear(None, layer_dims[i], use_gamma=use_gamma) for i in range(n_layers - 1)]\n        else:\n            layers = [links.Linear(None, layer_dims[i]) for i in range(n_layers - 1)]\n        with self.init_scope():\n            self.layers = chainer.ChainList(*layers)\n            if use_sn:\n                self.l_out = SNLinear(None, out_dim, use_gamma=use_gamma)\n            else:\n                self.l_out = links.Linear(None, out_dim)\n            if use_bn:\n                self.bn_layers = chainer.ChainList(\n                    *[links.BatchNormalization(layer_dims[i]) for i in range(n_layers - 1)])\n            if scaler is not None:\n                self.scaler = scaler\n        if scaler is None:\n            self.scaler = None\n\n        self.activation = activation\n        self.use_bn = use_bn\n        self.use_residual = use_residual\n        self.dropout_ratio = dropout_ratio\n\n    def calc(self, x, extract_hidden=False):\n        if self.scaler is None:\n            h = x\n        else:\n            h = self.scaler.transform(x)\n        if self.use_bn:\n            for l, bn in zip(self.layers, self.bn_layers):\n                if self.dropout_ratio > 0:\n                    h = F.dropout(x, self.dropout_ratio)\n                h2 = self.activation(bn(l(h)))\n                if self.use_residual and h.shape == h2.shape:\n                    h = h + h2\n                else:\n                    h = h2\n        else:\n            for l in self.layers:\n                if self.dropout_ratio > 0:\n                    h = F.dropout(x, self.dropout_ratio)\n                h2 = self.activation(l(h))\n                if self.use_residual and h.shape == h2.shape:\n                    h = h + h2\n                else:\n                    h = h2\n        if extract_hidden:\n            return h\n        h = self.l_out(h)\n        return h\n\n    def __call__(self, x):\n        return self.calc(x)\n","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1281f5f306ccbd17643cd4307a15836415011c3d"},"cell_type":"code","source":"# --- blendnet ---","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"828df437a62d9b53b0fa1c3477e52b8b7062f778"},"cell_type":"code","source":"import chainer\n\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import functions\n\n\ndef lrelu(x):\n    return functions.leaky_relu(x, slope=0.05)\n\n\nclass BlendNet(chainer.Chain):\n\n    def __init__(self, num_cat_id=None, out_dim=1, activation=lrelu,\n                 dropout_ratio=-1, use_bn=False, use_residual=False,\n                 numeric_hidden_dim=96, embed_dim=10, bert_hidden_dim=32,\n                 image_hidden_dim=96, mlp_hidden_dim=128, mlp_n_layers=6,\n                 cat_hidden_dim=32):\n        \"\"\"\n\n        Args:\n            num_cat_id:\n            out_dim:\n            activation:\n            dropout_ratio:\n            use_bn:\n            numeric_hidden_dim: numerical feature\n            embed_dim: category feature, this is not used when `cat2num=True` at preprocessing.\n            bert_hidden_dim:\n            image_hidden_dim:\n            mlp_hidden_dim:\n            mlp_n_layers:\n        \"\"\"\n        super(BlendNet, self).__init__()\n        print('num_cat_id', num_cat_id)  # len(num_cat_id)\n        projection = False\n        self.projection = projection\n        print('projection', projection)\n        self.use_embed = not isinstance(num_cat_id, (int, float))\n        with self.init_scope():\n            if num_cat_id is not None:\n                if self.use_embed:\n                    self.embed_list = chainer.ChainList(\n                        *[L.EmbedID(insize, embed_dim) for insize in num_cat_id])\n                else:\n                    self.l_cat = L.Linear(None, cat_hidden_dim)\n            self.l_num = L.Linear(None, numeric_hidden_dim)\n            self.l_bert = L.Linear(None, bert_hidden_dim)\n            self.l_image = L.Linear(None, image_hidden_dim)\n            if projection:\n                self.mlp = ProjectionMLP(\n                    out_dim=out_dim, hidden_dim=mlp_hidden_dim,\n                    n_layers=mlp_n_layers, activation=activation,\n                    use_bn=use_bn, use_residual=use_residual)\n            else:\n                self.mlp = MLP(\n                    out_dim=out_dim, hidden_dim=mlp_hidden_dim,\n                    n_layers=mlp_n_layers, activation=activation,\n                    use_bn=use_bn, use_residual=use_residual)\n            # if use_bn:\n            #     self.bn1 = L.BatchNormalization()\n        self.activation = activation\n        self.bert_hidden_dim = bert_hidden_dim\n        self.dropout_ratio = dropout_ratio\n        self.num_cat_id = num_cat_id\n        self.use_bn = use_bn\n\n    def forward(self, x_numeric, x_cat=None, x_bert=None, x_image=None):\n        h_num = self.l_num(x_numeric)\n        h_feat_list = [h_num]\n        if x_cat is not None:\n            if self.use_embed:\n                h_cat_list = [l_cat(x_cat[:, i]) for i, l_cat in enumerate(self.embed_list)]\n                h_feat_list.extend(h_cat_list)\n            else:\n                h_feat_list.append(self.l_cat(x_cat))\n        if x_bert is not None:\n            # x_bert (bs, num_extract_seq, hdim)\n            # --- 1. simply take linear, it will reshape  ---\n            # h_bert = self.l_bert(x_bert)\n            # --- 2. take linear for each element and sum it. ---\n            bs, num_sent, hdim = x_bert.shape\n            h_bert = F.reshape(self.l_bert(F.reshape(x_bert, (bs*num_sent, hdim))),\n                               (bs, num_sent, self.bert_hidden_dim))\n            h_bert = F.sum(h_bert, axis=1)\n            # h_bert (bs, bert_hidden_dim)\n\n            # print('x_bert', x_bert.shape, 'h_bert', h_bert.shape)\n            h_feat_list.append(h_bert)\n        if x_image is not None:\n            h_image = self.l_image(x_image)\n            h_feat_list.append(h_image)\n\n        h = F.concat(h_feat_list, axis=1)\n        # if self.use_bn:\n        #     h = self.bn1(h)\n        if self.dropout_ratio > 0:\n            h = F.dropout(h, ratio=self.dropout_ratio)\n        h = self.activation(h)\n        if self.projection:\n            h = self.mlp(h, x_cat[:, 0].astype(self.xp.int32))\n        else:\n            h = self.mlp(h)\n        return h\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1fd7d2cd8240271867a3ad38b388a9a8dea520c"},"cell_type":"code","source":"# blendnet regressor","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3087e3fde68f8d740b364c04df888f8a815e6825"},"cell_type":"code","source":"import chainer\n\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer.dataset.convert import concat_examples\nfrom chainer import functions, reporter\n\n# from chainer_chemistry.models import Regressor\n# from src.models.mlp import MLP\n\n\ndef lrelu(x):\n    return functions.leaky_relu(x, slope=0.05)\n\n\nclass BlendNetRegressor(Regressor):\n\n    def __init__(self, predictor,\n                 lossfun=chainer.functions.mean_squared_error,\n                 metrics_fun=None, label_key=-1, device=-1,\n                 x_numeric_dim=None, sgnet=None, lam_image_recon=1.0, use_sn=False,\n                 image_encoder_layers=1, image_encoder_hdim=32, mode='normal', image_input_dim=0,\n                 dropout_ratio=0, image_encode=True):\n        assert isinstance(x_numeric_dim, int)\n        super(BlendNetRegressor, self).__init__(\n            predictor, lossfun=lossfun, metrics_fun=metrics_fun,\n            label_key=label_key, device=device)\n\n        cat_size = 2  # dog and cat\n        image_projection = True\n        self.image_projection = image_projection\n        bert_projection = True\n        self.bert_projection = bert_projection\n        print('image_projection', image_projection, 'dropout_ratio', dropout_ratio)\n        print('bert_projection', bert_projection)\n        with self.init_scope():\n            # TODO: compare with MLP\n            # self.image_encoder = L.Linear(None, 64)\n            # self.image_decoder = L.Linear(None, x_numeric_dim)\n            if image_encode:\n                self.image_encoder = MLP(\n                    out_dim=image_encoder_hdim, hidden_dim=image_encoder_hdim,\n                    n_layers=image_encoder_layers, use_sn=use_sn, dropout_ratio=dropout_ratio)\n                self.image_decoder = MLP(out_dim=x_numeric_dim, hidden_dim=image_encoder_hdim, n_layers=image_encoder_layers, use_sn=use_sn)\n            if self.image_projection:\n                self.embed_image_projection = L.EmbedID(cat_size, image_input_dim)  # TODO: remove hard coding...\n            if self.bert_projection:\n                self.embed_bert_projection = L.EmbedID(cat_size, 768)  # TODO: remove hard coding...\n            if sgnet is not None:\n                self.sgnet = sgnet\n\n        if sgnet is None:\n            self.sgnet = sgnet\n\n        self.image_encode = image_encode\n        self.lam_image_recon = lam_image_recon\n        print('self.lam_image_recon', self.lam_image_recon)\n        self.mode = mode\n        print('self.mode', self.mode)\n        self.initialize(device)\n        print('initialize', device)\n\n    def __call__(self, *args, **kwargs):\n        if self.mode == 'normal':\n            x_numeric, x_cat, x_bert, x_image, t = args\n        else:\n            assert self.mode == 'mean'\n            x_numeric, x_cat, x_bert, x_image, t_, indices, target_mean = args\n            t = target_mean\n\n        self.y = None\n        self.loss = None\n        self.metrics = None\n        y, h_image = self.calc(x_numeric, x_cat, x_bert, x_image, *args,\n                               return_all=True)\n\n        if self.lam_image_recon > 0.:\n            x_numeric_recon = self.image_decoder(h_image)\n            recon_loss = F.mean_squared_error(x_numeric_recon, x_numeric)\n        else:\n            recon_loss = 0.\n        reg_loss = self.lossfun(self.y, t)\n        recon_loss = self.lam_image_recon * recon_loss\n\n        self.loss = reg_loss + recon_loss\n        reporter.report(\n            {'loss': self.loss, 'reg_loss': reg_loss, 'recon_loss': recon_loss},\n            self)\n\n        if self.compute_metrics:\n            # Note: self.metrics_fun is `dict`,\n            # which is different from original chainer implementation\n            self.metrics = {key: self._convert_to_scalar(value(self.y, t))\n                            for key, value in self.metrics_fun.items()}\n            reporter.report(self.metrics, self)\n        return self.loss\n\n    def calc(self, x_numeric, x_cat, x_bert, x_image, *args,\n             return_all=False):\n        if self.sgnet is not None:\n            x_numeric, x_cat, x_bert, x_image = self.sgnet(\n                x_numeric, x_cat, x_bert, x_image)\n\n        if self.image_projection and x_image is not None:\n            # TODO: support when num_image > 1\n            x_image = x_image * self.embed_image_projection(x_cat[:, 0].astype(self.xp.int32))[:, None, :]\n        if self.bert_projection and x_bert is not None:\n            # TODO: support when num_sentence > 1\n            x_bert = x_bert * self.embed_bert_projection(x_cat[:, 0].astype(self.xp.int32))[:, None, :]\n\n        if x_image is None:\n            h_image = None\n        elif self.image_encode:\n            h_image = self.image_encoder(x_image)\n        else:\n            h_image = x_image\n        self.y = self.predictor(x_numeric, x_cat, x_bert, h_image)\n        if self.mode == 'mean':\n            assert len(args) == 0\n            indices = args[0]\n            self.y = self.calc_attention_mean(self.y, indices)\n        if return_all:\n            return self.y, h_image\n        else:\n            return self.y\n\n    def scatter_softmax(self, a, indices):\n        # TODO: subtract by scatter_max for computation stability\n        # Currently, just use overall max of `a`.\n        a = a - F.max(a)\n        a = F.exp(a)\n        #  self.xp.zeros(indices.shape, dtype=self.xp.float32)\n        alpha = self.xp.zeros((int(self.xp.max(indices))+1,), dtype=self.xp.float32)\n        alpha = a / (F.scatter_add(alpha, indices, a)[indices] + 1e-16)\n        return alpha\n\n    def calc_attention_mean(self, y, indices):\n        assert y.ndim == 2\n        assert indices.ndim == 1\n        assert y.shape[0] == indices.shape[0]\n        assert y.shape[1] == 2\n        # --- scatter attention by softmax part ---\n        a = y[:, 0]\n        alpha = self.scatter_softmax(a, indices)\n\n        result = self.xp.zeros((int(self.xp.max(indices))+1,), dtype=self.xp.float32)\n        b = y[:, 1]\n        result = F.scatter_add(result, indices, alpha * b)\n        return result[:, None]  # Add second axis, which is same shape with `target_mean`.\n\n    def predict(\n            self, data, batchsize=16, converter=concat_examples,\n            retain_inputs=False, preprocess_fn=None, postprocess_fn=None):\n        \"\"\"Predict label of each category by taking .\n\n        Args:\n            data: input data\n            batchsize (int): batch size\n            converter (Callable): convert from `data` to `inputs`\n            preprocess_fn (Callable): Its input is numpy.ndarray or\n                cupy.ndarray, it can return either Variable, cupy.ndarray or\n                numpy.ndarray\n            postprocess_fn (Callable): Its input argument is Variable,\n                but this method may return either Variable, cupy.ndarray or\n                numpy.ndarray.\n            retain_inputs (bool): If True, this instance keeps inputs in\n                `self.inputs` or not.\n\n        Returns (tuple or numpy.ndarray): Typically, it is 1-dimensional int\n            array with shape (batchsize, ) which represents each examples\n            category prediction.\n\n        \"\"\"\n        with chainer.no_backprop_mode(), chainer.using_config('train', False):\n            predict_labels = self._forward(\n                data, fn=self.calc, batchsize=batchsize,\n                converter=converter, retain_inputs=retain_inputs,\n                preprocess_fn=preprocess_fn, postprocess_fn=postprocess_fn)\n        return predict_labels\n","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0956bbce3e16b81d180bf0cca0161c48cd6d947","_kg_hide-input":true},"cell_type":"code","source":"# blendnet mean regressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afac765dbdc7806d2c55d70ae152476f2549282d","_kg_hide-input":true},"cell_type":"code","source":"import chainer\n\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer.dataset.convert import concat_examples\nfrom chainer import functions, reporter\n\n# from chainer_chemistry.models import Regressor\n# from src.models.mlp import MLP\n\n\ndef lrelu(x):\n    return functions.leaky_relu(x, slope=0.05)\n\n\nclass BlendNetMeanRegressor(Regressor):\n\n    def __init__(self, predictor, mean_predictor,\n                 lossfun=chainer.functions.mean_squared_error,\n                 metrics_fun=None, label_key=-1, device=-1,\n                 x_numeric_dim=None, sgnet=None, lam_image_recon=1.0, use_sn=False,\n                 image_encoder_layers=1, image_encoder_hdim=32, image_input_dim=0,\n                 dropout_ratio=0, image_encode=True):\n        assert isinstance(x_numeric_dim, int)\n        super(BlendNetMeanRegressor, self).__init__(\n            predictor, lossfun=lossfun, metrics_fun=metrics_fun,\n            label_key=label_key, device=device)\n\n        # self.lam_mean = 10.0\n        self.lam_mean = 0.50\n        # self.lam_mean = 0.3\n        image_projection = True\n        cat_size = 2  # dog and cat\n        self.image_projection = image_projection\n        print('image_projection', image_projection)\n        with self.init_scope():\n            # TODO: compare with MLP\n            # self.image_encoder = L.Linear(None, 64)\n            # self.image_decoder = L.Linear(None, x_numeric_dim)\n            self.mean_predictor = mean_predictor\n            hdim = 16\n            # self.set_mlp_block = SetMLPBlock(out_dim=hdim, hidden_dim=hdim, n_layers=0,\n            #                                  use_sn=use_sn)\n            self.mean_predictor_post_mlp = MLP(out_dim=1, hidden_dim=hdim, n_layers=1, use_sn=use_sn)\n            if image_encode:\n                self.image_encoder = MLP(out_dim=image_encoder_hdim, hidden_dim=image_encoder_hdim,\n                                         n_layers=image_encoder_layers, use_sn=use_sn, dropout_ratio=dropout_ratio)\n                self.image_decoder = MLP(out_dim=x_numeric_dim, hidden_dim=image_encoder_hdim,\n                                         n_layers=image_encoder_layers, use_sn=use_sn)\n            if self.image_projection:\n                self.embed_image_projection = L.EmbedID(cat_size, image_input_dim)\n            if sgnet is not None:\n                self.sgnet = sgnet\n\n        if sgnet is None:\n            self.sgnet = sgnet\n\n        self.image_encode = image_encode\n        self.lam_image_recon = lam_image_recon\n        print('self.lam_image_recon', self.lam_image_recon)\n        self.initialize(device)\n        print('initialize', device)\n\n    def __call__(self, *args, **kwargs):\n        x_numeric, x_cat, x_bert, x_image, t, indices, target_mean = args\n\n        self.y = None\n        self.loss = None\n        self.metrics = None\n\n        y, h_image, y_mean = self.calc(x_numeric, x_cat, x_bert, x_image, indices, return_all=True)\n\n        # 1. ImageEncoder loss\n        if h_image is not None:\n            if self.lam_image_recon > 0.:\n                x_numeric_recon = self.image_decoder(h_image)\n                recon_loss = F.mean_squared_error(x_numeric_recon, x_numeric)\n            else:\n                recon_loss = 0.\n        else:\n            recon_loss = 0.\n\n        # 2. target_mean loss\n        # reg_loss_mean = self.lossfun(y_mean, target_mean)\n        reg_loss_mean = self.lossfun(y_mean[indices], target_mean[indices])\n        reg_loss_mean = self.lam_mean * reg_loss_mean\n        # 3. t loss\n        reg_loss = self.lossfun(self.y, t)\n        recon_loss = self.lam_image_recon * recon_loss\n\n        self.loss = reg_loss + reg_loss_mean + recon_loss\n        reporter.report(\n            {'loss': self.loss, 'reg_loss': reg_loss, 'recon_loss': recon_loss,\n             'reg_loss_mean': reg_loss_mean},\n            self)\n\n        if self.compute_metrics:\n            # Note: self.metrics_fun is `dict`,\n            # which is different from original chainer implementation\n            self.metrics = {key: self._convert_to_scalar(value(self.y, t))\n                            for key, value in self.metrics_fun.items()}\n            reporter.report(self.metrics, self)\n        return self.loss\n\n    def calc(self, x_numeric, x_cat, x_bert, x_image, indices, *args,\n             return_all=False):\n        assert len(args) == 0\n        # if len(args) != 0:\n        #     print('args ', len(args))\n        #     import IPython; IPython.embed()\n        if self.sgnet is not None:\n            x_numeric, x_cat, x_bert, x_image = self.sgnet(\n                x_numeric, x_cat, x_bert, x_image)\n        if x_image is None:\n            h_image = None\n        elif self.image_encode:\n            if self.image_projection:\n                h_image = x_image[:, 0, :] * self.embed_image_projection(x_cat[:, 0].astype(self.xp.int32))\n            h_image = self.image_encoder(h_image)\n        else:\n            h_image = x_image\n\n        # --- 1st step: predict target_mean ---\n        h_mean = self.mean_predictor(x_numeric, x_cat, x_bert, h_image, indices)\n        # h_mean = self.mean_predictor(x_numeric, x_cat, x_bert, h_image)\n        # calc softmax mean\n        h_mean_agg = self.calc_attention_mean(h_mean, indices)\n        # h_mean_agg = self.set_mlp_block.calc_agg(h_mean, indices)\n        y_mean = self.mean_predictor_post_mlp(h_mean_agg)\n        # `t` is target_mean in this case...\n\n        # --- 2nd step: predict t ---\n        # h_numeric_agg = F.concat([h_mean_agg, y_mean], axis=1)  # (bs, 1+hdim)\n        h_numeric_agg = y_mean\n        # print('h_numeric_agg', h_numeric_agg.shape, 'indices', indices.shape)\n        h_numeric = h_numeric_agg[indices]\n        # print('h_numeric', h_numeric.shape)\n        h_numeric = F.concat([x_numeric, h_numeric], axis=1)\n        # h_numeric = x_numeric\n\n        self.y = self.predictor(h_numeric, x_cat, x_bert, h_image)\n        if return_all:\n            return self.y, h_image, y_mean\n        else:\n            return self.y\n\n    def scatter_softmax_1d(self, a, indices):\n        \"\"\"\n        Args:\n            a: 1d-array (num_examples,)\n            indices: (num_rescuer_id,)\n\n        Returns:\n            alpha: Array shape is same with `a`, (num_rescuer_id,)\n        \"\"\"\n        # TODO: subtract by scatter_max for computation stability\n        # Currently, just use overall max of `a`.\n        a = a - F.max(a)\n        a = F.exp(a)\n        #  self.xp.zeros(indices.shape, dtype=self.xp.float32)\n        z = self.xp.zeros((int(self.xp.max(indices))+1,), dtype=self.xp.float32)\n        alpha = a / (F.scatter_add(z, indices, a)[indices] + 1e-16)\n        return alpha\n\n    def scatter_softmax_2d(self, a, indices):\n        \"\"\"\n        Args:\n            a: 2d-array (num_examples, hdim)\n            indices: (num_rescuer_id,)\n\n        Returns:\n            alpha: Array shape is same with `a`, (num_rescuer_id, hdim)\n        \"\"\"\n        # TODO: subtract by scatter_max for computation stability\n        # Currently, just use overall max of `a`.\n        a = a - F.max(a, axis=1, keepdims=True)\n        a = F.exp(a)\n        #  self.xp.zeros(indices.shape, dtype=self.xp.float32)\n        hdim = a.shape[1]\n        z = self.xp.zeros((int(self.xp.max(indices))+1, hdim), dtype=self.xp.float32)\n        alpha = a / (F.scatter_add(z, indices, a)[indices] + 1e-16)\n        return alpha\n\n    def calc_attention_mean(self, y, indices):\n        assert y.ndim == 2\n        assert indices.ndim == 1\n        assert y.shape[0] == indices.shape[0]\n        # assert y.shape[1] % 2 == 0  # sometimes this does not guaranteed...\n        # --- scatter attention by softmax part ---\n        outdim = y.shape[1] // 2\n        a = y[:, :outdim]\n        # alpha = self.scatter_softmax(a, indices)\n        alpha = self.scatter_softmax_2d(a, indices)\n\n        result = self.xp.zeros((int(self.xp.max(indices))+1, outdim), dtype=self.xp.float32)\n        b = y[:, outdim:outdim*2]\n        result = F.scatter_add(result, indices, alpha * b)\n        return result\n\n    def predict(\n            self, data, batchsize=16, converter=concat_examples,\n            retain_inputs=False, preprocess_fn=None, postprocess_fn=None):\n        \"\"\"Predict label of each category by taking .\n\n        Args:\n            data: input data\n            batchsize (int): batch size\n            converter (Callable): convert from `data` to `inputs`\n            preprocess_fn (Callable): Its input is numpy.ndarray or\n                cupy.ndarray, it can return either Variable, cupy.ndarray or\n                numpy.ndarray\n            postprocess_fn (Callable): Its input argument is Variable,\n                but this method may return either Variable, cupy.ndarray or\n                numpy.ndarray.\n            retain_inputs (bool): If True, this instance keeps inputs in\n                `self.inputs` or not.\n\n        Returns (tuple or numpy.ndarray): Typically, it is 1-dimensional int\n            array with shape (batchsize, ) which represents each examples\n            category prediction.\n\n        \"\"\"\n        with chainer.no_backprop_mode(), chainer.using_config('train', False):\n            predict_labels = self._forward(\n                data, fn=self.calc, batchsize=batchsize,\n                converter=converter, retain_inputs=retain_inputs,\n                preprocess_fn=preprocess_fn, postprocess_fn=postprocess_fn)\n        return predict_labels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c295d557811fdaef5910e3c9927f58d4e5999c6"},"cell_type":"code","source":"# sn blendnet","execution_count":35,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbdc477568d3ce4c5bc36c4b3dd14aaa08fdaf0f"},"cell_type":"code","source":"import chainer\n\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import functions\n\n# from src.models.mlp import MLP, ProjectionMLP\n# from src.models.sn.sn_embed_id import SNEmbedID\n# from src.models.sn.sn_linear import SNLinear\n\n\ndef lrelu(x):\n    return functions.leaky_relu(x, slope=0.05)\n\n\nclass SNBlendNet(chainer.Chain):\n    \"\"\"BlendNet with Spectral Normalization\"\"\"\n\n    def __init__(self, num_cat_id=None, out_dim=1, activation=lrelu,\n                 dropout_ratio=-1, use_bn=False,\n                 numeric_hidden_dim=96, embed_dim=10, bert_hidden_dim=32,\n                 image_hidden_dim=96, mlp_hidden_dim=128, mlp_n_layers=6,\n                 cat_hidden_dim=32, use_gamma=True, use_residual=False):\n        \"\"\"\n\n        Args:\n            num_cat_id:\n            out_dim:\n            activation:\n            dropout_ratio:\n            use_bn:\n            numeric_hidden_dim: numerical feature\n            embed_dim: category feature, this is not used when `cat2num=True` at preprocessing.\n            bert_hidden_dim:\n            image_hidden_dim:\n            mlp_hidden_dim:\n            mlp_n_layers:\n        \"\"\"\n        super(SNBlendNet, self).__init__()\n        print('num_cat_id', num_cat_id)  # len(num_cat_id)\n        print('spectral normalizaiton ON, use_gamma {}'.format(use_gamma))\n        projection = False\n        self.projection = projection\n        print('projection', projection)\n        self.use_embed = not isinstance(num_cat_id, (int, float))\n        with self.init_scope():\n            if num_cat_id is not None:\n                if self.use_embed:\n                    self.embed_list = chainer.ChainList(\n                        *[SNEmbedID(insize, embed_dim) for insize in num_cat_id])\n                else:\n                    self.l_cat = SNLinear(None, cat_hidden_dim, use_gamma=use_gamma)\n            self.l_num = SNLinear(None, numeric_hidden_dim, use_gamma=use_gamma)\n            self.l_bert = SNLinear(None, bert_hidden_dim, use_gamma=use_gamma)\n            self.l_image = SNLinear(None, image_hidden_dim, use_gamma=use_gamma)\n            if projection:\n                self.mlp = ProjectionMLP(\n                    out_dim=out_dim, hidden_dim=mlp_hidden_dim,\n                    n_layers=mlp_n_layers, activation=activation,\n                    use_bn=use_bn, use_sn=True, use_gamma=use_gamma,\n                    use_residual=use_residual)\n            else:\n                self.mlp = MLP(\n                    out_dim=out_dim, hidden_dim=mlp_hidden_dim,\n                    n_layers=mlp_n_layers, activation=activation,\n                    use_bn=use_bn, use_sn=True, use_gamma=use_gamma,\n                    use_residual=use_residual)\n            # if use_bn:\n            #     self.bn1 = L.BatchNormalization()\n        self.activation = activation\n        self.bert_hidden_dim = bert_hidden_dim\n        self.dropout_ratio = dropout_ratio\n        self.num_cat_id = num_cat_id\n        self.use_bn = use_bn\n\n    def forward(self, x_numeric, x_cat=None, x_bert=None, x_image=None):\n        h_num = self.l_num(x_numeric)\n        h_feat_list = [h_num]\n        if x_cat is not None:\n            if self.use_embed:\n                h_cat_list = [l_cat(x_cat[:, i]) for i, l_cat in enumerate(self.embed_list)]\n                h_feat_list.extend(h_cat_list)\n            else:\n                h_feat_list.append(self.l_cat(x_cat))\n        if x_bert is not None:\n            # x_bert (bs, num_extract_seq, hdim)\n            # --- 1. simply take linear, it will reshape  ---\n            # h_bert = self.l_bert(x_bert)\n            # --- 2. take linear for each element and sum it. ---\n            bs, num_sent, hdim = x_bert.shape\n            h_bert = F.reshape(self.l_bert(F.reshape(x_bert, (bs*num_sent, hdim))),\n                               (bs, num_sent, self.bert_hidden_dim))\n            h_bert = F.sum(h_bert, axis=1)\n            # h_bert (bs, bert_hidden_dim)\n\n            # print('x_bert', x_bert.shape, 'h_bert', h_bert.shape)\n            h_feat_list.append(h_bert)\n        if x_image is not None:\n            h_image = self.l_image(x_image)\n            h_feat_list.append(h_image)\n\n        h = F.concat(h_feat_list, axis=1)\n        # if self.use_bn:\n        #     h = self.bn1(h)\n        if self.dropout_ratio > 0:\n            h = F.dropout(h, ratio=self.dropout_ratio)\n        h = self.activation(h)\n        if self.projection:\n            h = self.mlp(h, x_cat[:, 0].astype(self.xp.int32))\n        else:\n            h = self.mlp(h)\n        return h\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c18b6f71eb5078807b503f96ef694c43e1e4e305","_kg_hide-input":true},"cell_type":"code","source":"# set sn blendnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27d91d01beef7836a854726e6929b6591d59c9ae","_kg_hide-input":true},"cell_type":"code","source":"import chainer\n\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import functions\nfrom chainer.functions.activation import relu\n\n# from src.models.mlp import MLP\n# from src.models.sn.sn_embed_id import SNEmbedID\n# from src.models.sn.sn_linear import SNLinear\n\n\ndef lrelu(x):\n    return functions.leaky_relu(x, slope=0.05)\n\n\ndef scatter_softmax_2d(xp, a, indices):\n    \"\"\"\n    Args:\n        a: 2d-array (num_examples, hdim)\n        indices: (num_rescuer_id,)\n\n    Returns:\n        alpha: Array shape is same with `a`, (num_rescuer_id, hdim)\n    \"\"\"\n    # TODO: subtract by scatter_max for computation stability\n    # Currently, just use overall max of `a`.\n    a = a - F.max(a, axis=1, keepdims=True)\n    a = F.exp(a)\n    #  self.xp.zeros(indices.shape, dtype=self.xp.float32)\n    hdim = a.shape[1]\n    z = xp.zeros((int(xp.max(indices))+1, hdim), dtype=xp.float32)\n    alpha = a / (F.scatter_add(z, indices, a)[indices] + 1e-16)\n    return alpha\n\n\ndef calc_num_examples(xp, indices):\n    ones = xp.ones((indices.shape[0], 1), dtype=xp.float32)\n    num_examples = xp.zeros((int(xp.max(indices)) + 1, 1), dtype=xp.float32)\n    num_examples = F.scatter_add(num_examples, indices, ones)\n    return num_examples\n\n\ndef calc_attention_mean(xp, y, indices):\n    assert y.ndim == 2\n    assert indices.ndim == 1\n    assert y.shape[0] == indices.shape[0]\n    # assert y.shape[1] % 2 == 0\n    # --- scatter attention by softmax part ---\n    outdim = y.shape[1] // 2\n    a = y[:, :outdim]\n    # alpha = self.scatter_softmax(a, indices)\n    alpha = scatter_softmax_2d(xp, a, indices)\n\n    result = xp.zeros((int(xp.max(indices))+1, outdim), dtype=xp.float32)\n    b = y[:, outdim:2*outdim]\n    result = F.scatter_add(result, indices, alpha * b)\n    return result\n\n\nclass SetMLPBlock(chainer.Chain):\n    def __init__(self, out_dim, hidden_dim=16, n_layers=2, activation=relu,\n                 use_bn=False, use_sn=False, use_gamma=True, use_residual=False):\n        super(SetMLPBlock, self).__init__()\n        # assert out_dim % 2 == 0, 'out_dim is {}'.format(out_dim)\n        with self.init_scope():\n            if n_layers > 0:\n                self.mlp = MLP(\n                    out_dim // 2, hidden_dim=hidden_dim, n_layers=n_layers, activation=activation,\n                    use_bn=use_bn, use_sn=use_sn, use_gamma=use_gamma, use_residual=use_residual)\n            self.i_layer = L.Linear(None, out_dim // 2)\n            self.j_layer = L.Linear(None, out_dim // 2)\n        if n_layers <= 0:\n            self.mlp = None\n\n    def calc_agg(self, y, indices):\n        assert y.ndim == 2\n        assert indices.ndim == 1\n        assert y.shape[0] == indices.shape[0]\n        # --- scatter part ---\n        h = F.sigmoid(self.i_layer(y)) * self.j_layer(y)\n        result = self.xp.zeros((int(self.xp.max(indices))+1, h.shape[1]), dtype=self.xp.float32)\n        result = F.scatter_add(result, indices, h)\n\n        num_examples = calc_num_examples(self.xp, indices)\n        # ones = self.xp.ones((h.shape[0], 1), dtype=self.xp.float32)\n        # num_examples = self.xp.zeros((int(self.xp.max(indices)) + 1, 1), dtype=self.xp.float32)\n        # num_examples = F.scatter_add(num_examples, indices, ones)\n\n        # Take mean of features...\n        # return result / num_examples\n        # concat `num_examples` as feature...\n        return F.concat([result / num_examples, num_examples, num_examples], axis=1)\n\n    def __call__(self, x, indices):\n        if self.mlp is not None:\n            h = self.mlp(x)\n        else:\n            h = x\n        # H = self.calc_agg(h, indices)\n        H = calc_attention_mean(self.xp, h, indices)\n        num_examples = calc_num_examples(self.xp, indices)\n        return F.concat([h, H[indices], num_examples[indices]], axis=1)\n\n\nclass SetMLP(chainer.Chain):\n    def __init__(self, out_dim, hidden_dim=16, n_layers=2, activation=relu,\n                 use_bn=False, use_sn=False, use_gamma=True, use_residual=False):\n        super(SetMLP, self).__init__()\n        assert out_dim % 2 == 0, 'out_dim is {}'.format(out_dim)\n        with self.init_scope():\n            self.mlp1 = SetMLPBlock(\n                hidden_dim, hidden_dim=hidden_dim, n_layers=1, activation=activation,\n                use_bn=use_bn, use_sn=use_sn, use_gamma=use_gamma, use_residual=use_residual)\n            self.mlp2 = SetMLPBlock(\n                out_dim, hidden_dim=hidden_dim, n_layers=2, activation=activation,\n                use_bn=use_bn, use_sn=use_sn, use_gamma=use_gamma, use_residual=use_residual)\n            # self.mlp3 = SetMLPBlock(\n            #     out_dim, hidden_dim=hidden_dim, n_layers=2, activation=activation,\n            #     use_bn=use_bn, use_sn=use_sn, use_gamma=use_gamma, use_residual=use_residual)\n\n    def __call__(self, x, indices):\n        h = self.mlp1(x, indices)\n        h = self.mlp2(h, indices)\n        # h = self.mlp3(h, indices)\n        return h\n\n\nclass SetSNBlendNet(chainer.Chain):\n    \"\"\"BlendNet with Spectral Normalization\"\"\"\n\n    def __init__(self, num_cat_id=None, out_dim=1, activation=lrelu,\n                 dropout_ratio=-1, use_bn=False,\n                 numeric_hidden_dim=96, embed_dim=10, bert_hidden_dim=32,\n                 image_hidden_dim=96, mlp_hidden_dim=128, mlp_n_layers=6,\n                 cat_hidden_dim=32, use_gamma=True, use_residual=False):\n        \"\"\"\n\n        Args:\n            num_cat_id:\n            out_dim:\n            activation:\n            dropout_ratio:\n            use_bn:\n            numeric_hidden_dim: numerical feature\n            embed_dim: category feature, this is not used when `cat2num=True` at preprocessing.\n            bert_hidden_dim:\n            image_hidden_dim:\n            mlp_hidden_dim:\n            mlp_n_layers:\n        \"\"\"\n        super(SetSNBlendNet, self).__init__()\n        print('num_cat_id', num_cat_id)  # len(num_cat_id)\n        print('spectral normalizaiton ON, use_gamma {}'.format(use_gamma))\n        self.use_embed = not isinstance(num_cat_id, (int, float))\n        with self.init_scope():\n            if num_cat_id is not None:\n                if self.use_embed:\n                    self.embed_list = chainer.ChainList(\n                        *[SNEmbedID(insize, embed_dim) for insize in num_cat_id])\n                else:\n                    self.l_cat = SNLinear(None, cat_hidden_dim, use_gamma=use_gamma)\n            self.l_num = SNLinear(None, numeric_hidden_dim, use_gamma=use_gamma)\n            self.l_bert = SNLinear(None, bert_hidden_dim, use_gamma=use_gamma)\n            self.l_image = SNLinear(None, image_hidden_dim, use_gamma=use_gamma)\n            self.mlp = SetMLP(\n                out_dim=out_dim, hidden_dim=mlp_hidden_dim,\n                n_layers=mlp_n_layers, activation=activation,\n                use_bn=use_bn, use_sn=True, use_gamma=use_gamma,\n                use_residual=use_residual)\n            # if use_bn:\n            #     self.bn1 = L.BatchNormalization()\n        self.activation = activation\n        self.bert_hidden_dim = bert_hidden_dim\n        self.dropout_ratio = dropout_ratio\n        self.num_cat_id = num_cat_id\n        self.use_bn = use_bn\n\n    def forward(self, x_numeric, x_cat=None, x_bert=None, x_image=None, indices=None):\n        h_num = self.l_num(x_numeric)\n        h_feat_list = [h_num]\n        if x_cat is not None:\n            if self.use_embed:\n                h_cat_list = [l_cat(x_cat[:, i]) for i, l_cat in enumerate(self.embed_list)]\n                h_feat_list.extend(h_cat_list)\n            else:\n                h_feat_list.append(self.l_cat(x_cat))\n        if x_bert is not None:\n            # x_bert (bs, num_extract_seq, hdim)\n            # --- 1. simply take linear, it will reshape  ---\n            # h_bert = self.l_bert(x_bert)\n            # --- 2. take linear for each element and sum it. ---\n            bs, num_sent, hdim = x_bert.shape\n            h_bert = F.reshape(self.l_bert(F.reshape(x_bert, (bs*num_sent, hdim))),\n                               (bs, num_sent, self.bert_hidden_dim))\n            h_bert = F.sum(h_bert, axis=1)\n            # h_bert (bs, bert_hidden_dim)\n\n            # print('x_bert', x_bert.shape, 'h_bert', h_bert.shape)\n            h_feat_list.append(h_bert)\n        if x_image is not None:\n            h_image = self.l_image(x_image)\n            h_feat_list.append(h_image)\n\n        h = F.concat(h_feat_list, axis=1)\n        # if self.use_bn:\n        #     h = self.bn1(h)\n        if self.dropout_ratio > 0:\n            h = F.dropout(h, ratio=self.dropout_ratio)\n        h = self.activation(h)\n        h = self.mlp(h, indices)\n        return h\n\n\nclass SetBlendNet(chainer.Chain):\n\n    def __init__(self, num_cat_id=None, out_dim=1, activation=lrelu,\n                 dropout_ratio=-1, use_bn=False, use_residual=False,\n                 numeric_hidden_dim=96, embed_dim=10, bert_hidden_dim=32,\n                 image_hidden_dim=96, mlp_hidden_dim=128, mlp_n_layers=6,\n                 cat_hidden_dim=32):\n        \"\"\"\n\n        Args:\n            num_cat_id:\n            out_dim:\n            activation:\n            dropout_ratio:\n            use_bn:\n            numeric_hidden_dim: numerical feature\n            embed_dim: category feature, this is not used when `cat2num=True` at preprocessing.\n            bert_hidden_dim:\n            image_hidden_dim:\n            mlp_hidden_dim:\n            mlp_n_layers:\n        \"\"\"\n        super(SetBlendNet, self).__init__()\n        print('num_cat_id', num_cat_id)  # len(num_cat_id)\n        self.use_embed = not isinstance(num_cat_id, (int, float))\n        with self.init_scope():\n            if num_cat_id is not None:\n                if num_cat_id > 0:\n                    self.embed_list = chainer.ChainList(\n                        *[L.EmbedID(insize, embed_dim) for insize in num_cat_id])\n                else:\n                    self.l_cat = L.Linear(None, cat_hidden_dim)\n            self.l_num = L.Linear(None, numeric_hidden_dim)\n            self.l_bert = L.Linear(None, bert_hidden_dim)\n            self.l_image = L.Linear(None, image_hidden_dim)\n            self.mlp = SetMLP(\n                out_dim=out_dim, hidden_dim=mlp_hidden_dim,\n                n_layers=mlp_n_layers, activation=activation,\n                use_bn=use_bn, use_sn=False,\n                use_residual=use_residual)\n            # if use_bn:\n            #     self.bn1 = L.BatchNormalization()\n        self.activation = activation\n        self.bert_hidden_dim = bert_hidden_dim\n        self.dropout_ratio = dropout_ratio\n        self.num_cat_id = num_cat_id\n        self.use_bn = use_bn\n\n    def forward(self, x_numeric, x_cat=None, x_bert=None, x_image=None, indices=None):\n        h_num = self.l_num(x_numeric)\n        h_feat_list = [h_num]\n        if x_cat is not None:\n            if self.use_embed:\n                h_cat_list = [l_cat(x_cat[:, i]) for i, l_cat in enumerate(self.embed_list)]\n                h_feat_list.extend(h_cat_list)\n            else:\n                h_feat_list.append(self.l_cat(x_cat))\n        if x_bert is not None:\n            # x_bert (bs, num_extract_seq, hdim)\n            # --- 1. simply take linear, it will reshape  ---\n            # h_bert = self.l_bert(x_bert)\n            # --- 2. take linear for each element and sum it. ---\n            bs, num_sent, hdim = x_bert.shape\n            h_bert = F.reshape(self.l_bert(F.reshape(x_bert, (bs*num_sent, hdim))),\n                               (bs, num_sent, self.bert_hidden_dim))\n            h_bert = F.sum(h_bert, axis=1)\n            # h_bert (bs, bert_hidden_dim)\n\n            # print('x_bert', x_bert.shape, 'h_bert', h_bert.shape)\n            h_feat_list.append(h_bert)\n        if x_image is not None:\n            h_image = self.l_image(x_image)\n            h_feat_list.append(h_image)\n\n        h = F.concat(h_feat_list, axis=1)\n        # if self.use_bn:\n        #     h = self.bn1(h)\n        if self.dropout_ratio > 0:\n            h = F.dropout(h, ratio=self.dropout_ratio)\n        h = self.activation(h)\n        h = self.mlp(h, indices)\n        return h\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1153c6364b4747f5b263c29bb90c975a11d20e3b"},"cell_type":"code","source":"\"\"\"\nCompressed Interaction Network used in xDeepFM\n\nRef:\n - https://arxiv.org/pdf/1803.05170.pdf\n - https://data.gunosy.io/entry/deep-factorization-machines-2018\n\"\"\"\nimport chainer\nimport chainer.links as L\nimport chainer.functions as F\nfrom chainer import functions\n\n# from src.configs import is_kaggle_kernel\n# from src.models.sn.sn_linear import SNLinear\n\n\nclass CINBlock(chainer.Chain):\n    def __init__(self, hk_dim, hk_prev_dim=None, h0_dim=None,\n                 layer_type='linear', use_sn=False, use_gamma=True):\n        \"\"\"\n\n        Args:\n            num_field (int): `D` in paper. number of\n        \"\"\"\n        super(CINBlock, self).__init__()\n        if hk_prev_dim is None or h0_dim is None:\n            in_size = None\n        else:\n            in_size = hk_prev_dim * h0_dim\n        with self.init_scope():\n            if layer_type == 'linear':\n                if use_sn:\n                    self.l = SNLinear(in_size, hk_dim, use_gamma=use_gamma)\n                else:\n                    self.l = L.Linear(in_size, hk_dim)\n            elif layer_type == 'gru':\n                self.l = L.GRU(in_size, hk_dim)\n            else:\n                raise ValueError(\"[ERROR] Unexpected value layer_type={}\".format(layer_type))\n        self.hk_dim = hk_dim\n        self.hk_prev_dim = hk_prev_dim\n        self.h0_dim = h0_dim\n\n    def forward(self, hk_prev, h0):\n        \"\"\"\n\n        Args:\n            hk_prev: (bs, hdim=D, hk_prev_dim)\n            h0: (bs, hdim=D, h0_dim=m)\n\n        Returns:\n            hk: (bs, hdim=D, hk_dim)\n        \"\"\"\n        h_prod = hk_prev[:, :, :, None] * h0[:, :, None, :]\n        bs, D, hk_prev_dim, h0_dim = h_prod.shape\n        h_prod = F.reshape(h_prod, (bs * D, hk_prev_dim * h0_dim))\n        hk = self.l(h_prod)\n        bs_D, hk_dim = hk.shape\n        hk = F.reshape(hk, (bs, D, hk_dim))\n        return hk\n\n    def reset_state(self):\n        if hasattr(self.l, 'reset_state'):\n            self.l.reset_state()\n\n\nclass CIN(chainer.Chain):\n    def __init__(self, out_dim, hk_dims, use_sn=False, use_gamma=True,\n                 dropout_ratio=0):\n        super(CIN, self).__init__()\n        # hk_dims = [m, ..., hk]\n        pooled_dim = 0\n        for hk in hk_dims[1:]:\n            pooled_dim += hk\n        with self.init_scope():\n            self.cin_layers = chainer.ChainList(\n                *[CINBlock(hk_dims[i], hk_dims[i-1], hk_dims[0],\n                           use_sn=use_sn, use_gamma=use_gamma)\n                  for i in range(1, len(hk_dims))])\n            self.fc = L.Linear(pooled_dim, out_dim)\n        self.out_dim = out_dim\n        self.hk_dims = hk_dims\n        self.dropout_ratio = dropout_ratio\n\n    def forward(self, x):\n        # x (bs, hdim=D, num_field=m)\n        h = x\n        out_list = []\n        for cin_layer in self.cin_layers:\n            h = cin_layer(h, x)\n            # sum pooling\n            # print('[DEBUG]', h.shape)\n            out = F.sum(h, axis=1)\n            out_list.append(out)\n        out = F.concat(out_list, axis=1)\n        if self.dropout_ratio > 0:\n            out = F.dropout(out, ratio=self.dropout_ratio)\n        out = self.fc(out)\n        return out\n\n\nclass CINTying(chainer.Chain):\n    def __init__(self, out_dim, h0_dim, n_layers, layer_type='linear',\n                 use_sn=False, use_gamma=True, activation=functions.identity,\n                 dropout_ratio=0):\n        super(CINTying, self).__init__()\n        print('CINTying: out_dim {}, h0_dim {}, n_layers {} layer_type {}'\n              .format(out_dim, h0_dim, n_layers, layer_type))\n        # hk_dims = [m, ..., hk]\n        pooled_dim = h0_dim * n_layers\n        with self.init_scope():\n            self.cin_layer = CINBlock(\n                h0_dim, h0_dim, h0_dim, layer_type=layer_type,\n                use_sn=use_sn, use_gamma=use_gamma)\n            self.fc = L.Linear(pooled_dim, out_dim)\n            # self.fc = MLP(out_dim, hidden_dim=16, n_layers=2)\n        self.out_dim = out_dim\n        self.h0_dim = h0_dim\n        self.n_layers = n_layers\n        self.activation = activation\n        self.dropout_ratio = dropout_ratio\n\n    def forward(self, x):\n        # x (bs, hdim=D, num_field=m)\n        self.reset_state()\n        h = x\n        out_list = []\n        for i in range(self.n_layers):\n            h = self.cin_layer(h, x)\n            h = self.activation(h)\n            # sum pooling\n            # print('[DEBUG]', h.shape)\n            out = F.sum(h, axis=1)\n            out_list.append(out)\n        out = F.concat(out_list, axis=1)\n        if self.dropout_ratio > 0:\n            out = F.dropout(out, ratio=self.dropout_ratio)\n        out = self.fc(out)\n\n        return out\n\n    def reset_state(self):\n        self.cin_layer.reset_state()\n","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fccc663534428dc06a05be95e0a229b01ceda447"},"cell_type":"code","source":"import chainer\n\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer import functions\n\ndef lrelu(x):\n    return functions.leaky_relu(x, slope=0.05)\n\n\nclass BlendNetXDeepFM(chainer.Chain):\n\n    def __init__(self, num_cat_id=None, out_dim=1, activation=lrelu,\n                 dropout_ratio=-1, use_bn=False, use_residual=False,\n                 numeric_hidden_dim=96, embed_dim=10, bert_hidden_dim=32,\n                 image_hidden_dim=96, mlp_hidden_dim=128, mlp_n_layers=6,\n                 cat_hidden_dim=32, use_sn=False, use_gamma=True,\n                 weight_tying=False):\n        \"\"\"\n\n        Args:\n            num_cat_id:\n            out_dim:\n            activation:\n            dropout_ratio:\n            use_bn:\n            numeric_hidden_dim: numerical feature\n            embed_dim: category feature, this is not used when `cat2num=True` at preprocessing.\n            bert_hidden_dim:\n            image_hidden_dim:\n            mlp_hidden_dim:\n            mlp_n_layers:\n        \"\"\"\n        super(BlendNetXDeepFM, self).__init__()\n        print('num_cat_id', num_cat_id)  # len(num_cat_id)\n        projection = False\n        self.projection = projection\n        print('projection', projection)\n        self.use_embed = not isinstance(num_cat_id, (int, float))\n\n        num_numeric_feat = 0\n        num_image_feat = 0\n        h0_dim = len(num_cat_id) + num_numeric_feat + num_image_feat  # num & image\n        self.num_numeric_feat = num_numeric_feat\n        self.num_image_feat = num_image_feat\n        print('h0_dim', h0_dim)\n        with self.init_scope():\n            # if num_cat_id is not None:\n            if self.use_embed:\n                self.embed_list = chainer.ChainList(\n                    *[L.EmbedID(insize, embed_dim) for insize in num_cat_id])\n            else:\n                if use_sn:\n                    self.l_cat = SNLinear(None, cat_hidden_dim, use_gamma=use_gamma)\n                else:\n                    self.l_cat = L.Linear(None, cat_hidden_dim)\n\n            if use_sn:\n                self.l_num = SNLinear(None, numeric_hidden_dim, use_gamma=use_gamma)\n                self.l_bert = SNLinear(None, bert_hidden_dim, use_gamma=use_gamma)\n                self.l_image = SNLinear(None, image_hidden_dim, use_gamma=use_gamma)\n                self.embed_num = SNLinear(None, embed_dim * num_numeric_feat, use_gamma=use_gamma)\n                self.embed_bert = SNLinear(None, embed_dim, use_gamma=use_gamma)\n                self.embed_image = SNLinear(None, embed_dim * num_image_feat, use_gamma=use_gamma)\n            else:\n                self.l_num = L.Linear(None, numeric_hidden_dim)\n                self.l_bert = L.Linear(None, bert_hidden_dim)\n                self.l_image = L.Linear(None, image_hidden_dim)\n                self.embed_num = L.Linear(None, embed_dim * num_numeric_feat)\n                self.embed_bert = L.Linear(None, embed_dim)\n                self.embed_image = L.Linear(None, embed_dim * num_image_feat)\n\n            if weight_tying:\n                self.cin = CINTying(out_dim, h0_dim, n_layers=2, use_sn=True,\n                                    dropout_ratio=dropout_ratio)  #\n            else:\n                self.cin = CIN(out_dim, hk_dims=[h0_dim, h0_dim], use_sn=True,\n                               dropout_ratio=dropout_ratio)  # [h0_dim, 10, 10]\n            if projection:\n                self.mlp = ProjectionMLP(\n                    out_dim=out_dim, hidden_dim=mlp_hidden_dim,\n                    n_layers=mlp_n_layers, activation=activation,\n                    use_bn=use_bn, use_residual=use_residual)\n            else:\n                self.mlp = MLP(\n                    out_dim=out_dim, hidden_dim=mlp_hidden_dim,\n                    n_layers=mlp_n_layers, activation=activation,\n                    use_bn=use_bn, use_residual=use_residual)\n            # if use_bn:\n            #     self.bn1 = L.BatchNormalization()\n        self.activation = activation\n        self.bert_hidden_dim = bert_hidden_dim\n        self.dropout_ratio = dropout_ratio\n        self.num_cat_id = num_cat_id\n        self.use_bn = use_bn\n        self.embed_dim = embed_dim\n\n    def forward(self, x_numeric, x_cat=None, x_bert=None, x_image=None):\n        bs = x_numeric.shape[0]\n        h_num = self.l_num(x_numeric)\n        h_num_embed = self.embed_num(x_numeric)\n        h_feat_list = [h_num]\n        if x_cat is not None:\n            if self.use_embed:\n                h_cat_list = [l_cat(x_cat[:, i]) for i, l_cat in enumerate(self.embed_list)]\n                h_feat_list.extend(h_cat_list)\n            else:\n                h_feat_list.append(self.l_cat(x_cat))\n                raise NotImplementedError\n        # h_cat_list.append(h_num_embed)\n        h_cat_var = F.stack(h_cat_list, axis=2)\n\n        if x_bert is not None:\n            # x_bert (bs, num_extract_seq, hdim)\n            # --- 1. simply take linear, it will reshape  ---\n            # h_bert = self.l_bert(x_bert)\n            # --- 2. take linear for each element and sum it. ---\n            bs, num_sent, hdim = x_bert.shape\n            h_bert = F.reshape(self.l_bert(F.reshape(x_bert, (bs*num_sent, hdim))),\n                               (bs, num_sent, self.bert_hidden_dim))\n            h_bert = F.sum(h_bert, axis=1)\n            # h_bert (bs, bert_hidden_dim)\n\n            # print('x_bert', x_bert.shape, 'h_bert', h_bert.shape)\n            h_feat_list.append(h_bert)\n\n            h_bert_embed = F.reshape(self.embed_bert(F.reshape(x_bert, (bs*num_sent, hdim))),\n                                     (bs, num_sent, self.bert_hidden_dim))\n            h_bert_embed = F.sum(h_bert_embed, axis=1)\n            # h_cat_list.append(h_bert_embed)\n        if x_image is not None:\n            h_image = self.l_image(x_image)\n            h_feat_list.append(h_image)\n            h_image_embed = self.embed_image(x_image)\n            # h_cat_list.append(h_image_embed)\n\n        # --- CIN part ---\n        h_num_embed = F.reshape(h_num_embed, (bs, self.embed_dim, self.num_numeric_feat))\n        h_image_embed = F.reshape(h_image_embed, (bs, self.embed_dim, self.num_image_feat))\n        h_embed = F.concat([h_num_embed, h_cat_var, h_image_embed], axis=2)\n        h_embed = self.cin(h_embed)\n\n        # --- DNN part ---\n        h = F.concat(h_feat_list, axis=1)\n        # if self.use_bn:\n        #     h = self.bn1(h)\n        if self.dropout_ratio > 0:\n            h = F.dropout(h, ratio=self.dropout_ratio)\n        h = self.activation(h)\n        if self.projection:\n            h = self.mlp(h, x_cat[:, 0].astype(self.xp.int32))\n        else:\n            h = self.mlp(h)\n\n        # FC\n        # h = self.fc(F.concat([h, h_embed], axis=1))\n        h = h + h_embed\n        return h\n","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"212d4e1efcb0c8da161fd8b1f322f6d744e9f1a0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce15fcc6da0166ed17f0e0b268b7b613ffaac247","_kg_hide-input":true},"cell_type":"code","source":"# rescuer id mean dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59cae11a345e8f26ca3b5d2c93ccd269f9fd3e00","_kg_hide-input":true},"cell_type":"code","source":"import chainer\nimport numpy as np\n\nimport sys\nimport os\n\n# from chainer_chemistry.datasets import NumpyTupleDataset\n\n# sys.path.append(os.pardir)\n# sys.path.append(os.path.join(os.pardir, os.pardir))\n# from src.preprocessing import prepare_df\n\n\ndef preprocessing_target_mean(train):\n    train = train.reset_index()\n    train['AdoptionSpeedMean'] = train.groupby('RescuerID')[\n        'AdoptionSpeed'].transform(np.mean)\n    target_mean = train['AdoptionSpeedMean'].values.astype(np.float32)[:, None]\n    rescuer_id_list = []\n    rescuer_id_index_list = []\n    for rescuer_id, df in train.groupby('RescuerID'):\n        rescuer_id_list.append(rescuer_id)\n        rescuer_id_index_list.append(df.index.values)\n    return target_mean, rescuer_id_list, rescuer_id_index_list\n\n\nclass RescuerIDMeanDataset(chainer.dataset.DatasetMixin):\n    def __init__(self, train, dataset, mode='train'):\n        \"\"\"\n        Args:\n            train: train DataFrame\n            dataset: dataset for this\n        \"\"\"\n        print('RescuerIDMeanDataset')\n        target_mean, rescuer_id_list, rescuer_id_index_list = preprocessing_target_mean(train)\n        print('target_mean', target_mean.shape, 'rescuer_id_index_list', len(rescuer_id_index_list))\n        self.rescuer_id = train['RescuerID'].values\n        self.rescuer_id_list = rescuer_id_list  # list of str, unique rescuer_id list\n        self.rescuer_id_index_list = rescuer_id_index_list  # list of list, each element is rescuer's index list\n        self.target_mean = target_mean\n        self.dataset = dataset\n        assert len(target_mean) == len(dataset)\n        self.max_num_sample = 10\n        self.mode = mode\n\n    def __len__(self):\n        \"\"\"return length of this dataset\"\"\"\n        if self.mode == 'train':\n            return len(self.target_mean)\n        else:\n            return len(self.rescuer_id_list)\n\n    def get_example(self, i):\n        \"\"\"Return i-th data\"\"\"\n        if self.mode == 'train':\n            rescuer_id = self.rescuer_id[i]\n        else:\n            rescuer_id = self.rescuer_id_list[i]\n        index_list = self.rescuer_id_index_list[self.rescuer_id_list.index(rescuer_id)]\n        if self.mode == 'train':\n            # sample datasets from `index_list`.\n            size = min(len(index_list), self.max_num_sample)\n            random_indices = np.random.choice(len(index_list), size, replace=False)\n            target_indices = index_list[random_indices]\n            assert self.target_mean[i] == self.target_mean[index_list[0]]\n        else:\n            target_indices = index_list\n        t = self.target_mean[index_list[0]]\n        # print('[DEBUG] rescuer_id', rescuer_id, 'target_indices', target_indices)\n        return self.dataset[target_indices], t\n\n\n# if __name__ == '__main__':\n#     debug = False\n#     train, test, breeds, colors, states = prepare_df(debug)\n#     # target_mean, rescuer_id_list, rescuer_id_index_list = preprocessing_target_mean(train)\n#     dummy_dataset = NumpyTupleDataset(train[['Age', 'MaturitySize']].values, train[['AdoptionSpeed']].values)\n#     d = RescuerIDMeanDataset(train, dummy_dataset)\n#     data0, t0 = d[0]\n#     import IPython; IPython.embed()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"util function to tune optimizer's learning rate during NN training."},{"metadata":{"trusted":true,"_uuid":"640082278788a2e1e08e8f0f208f5b9011ae2948"},"cell_type":"code","source":"# myutils.schedule_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a8fb75a28671208d0c444dde4ba9fff460b50e2"},"cell_type":"code","source":"import os\nimport numpy\n\nimport chainer\nfrom chainer.training import Trainer\n\n\ndef schedule_optimizer_value(epoch_list, value_list, optimizer_name='main',\n                             attr_name='__auto'):\n    \"\"\"Set optimizer's hyperparameter according to value_list, scheduled on epoch_list. \n    \n    Example usage:\n    trainer.extend(schedule_optimizer_value([2, 4, 7], [0.008, 0.006, 0.002]))\n    \n    or \n    trainer.extend(schedule_optimizer_value(2, 0.008))\n\n    Args:\n        epoch_list (list, int or float): list of int. epoch to invoke this extension. \n        value_list (list, int or float): list of float. value to be set.\n        optimizer_name: optimizer's name on trainer\n        attr_name: attr name of optimizer to change value.\n           if '__auto' is set, it will automatically infer learning rate attr name. \n\n    Returns (callable): extension function\n\n    \"\"\"\n    if isinstance(epoch_list, list):\n        if len(epoch_list) != len(value_list):\n            raise ValueError('epoch_list length {} and value_list length {} '\n                             'must be same!'\n                             .format(len(epoch_list), len(value_list)))\n    else:\n        assert isinstance(epoch_list, float) or isinstance(epoch_list, int)\n        assert isinstance(value_list, float) or isinstance(value_list, int)\n        epoch_list = [epoch_list, ]\n        value_list = [value_list, ]\n\n\n    trigger = chainer.training.triggers.ManualScheduleTrigger(epoch_list,\n                                                              'epoch')\n    count = 0\n    _attr_name = attr_name\n\n    @chainer.training.extension.make_extension(trigger=trigger)\n    def set_value(trainer: Trainer):\n        nonlocal count, _attr_name\n        value = value_list[count]\n        optimizer = trainer.updater.get_optimizer(optimizer_name)\n\n        # Infer attr name\n        if count == 0 and _attr_name == '__auto':\n            if isinstance(optimizer, chainer.optimizers.Adam):\n                _attr_name = 'alpha'\n            else:\n                _attr_name = 'lr'\n\n        print('updating {} to {}'.format(_attr_name, value))\n        setattr(optimizer, _attr_name, value)\n        count += 1\n\n    return set_value\n\n\ndef schedule_target_value(epoch_list, value_list, target, attr_name):\n    \"\"\"Set optimizer's hyperparameter according to value_list, scheduled on epoch_list. \n\n    target is None -> use main optimizer\n\n    Example usage:\n    trainer.extend(schedule_target_value([2, 4, 7], [0.008, 0.006, 0.002], iterator, 'batch_size'))\n    \"\"\"\n    if isinstance(epoch_list, list):\n        if not isinstance(value_list, list):\n            assert isinstance(value_list, float) or isinstance(value_list, int)\n            value_list = [value_list, ]\n        if len(epoch_list) != len(value_list):\n            raise ValueError('epoch_list length {} and value_list length {} '\n                             'must be same!'\n                             .format(len(epoch_list), len(value_list)))\n    else:\n        assert isinstance(epoch_list, float) or isinstance(epoch_list, int)\n        assert isinstance(value_list, float) or isinstance(value_list, int)\n        epoch_list = [epoch_list, ]\n        value_list = [value_list, ]\n\n    trigger = chainer.training.triggers.ManualScheduleTrigger(epoch_list,\n                                                              'epoch')\n    count = 0\n\n    @chainer.training.extension.make_extension(trigger=trigger)\n    def set_value(trainer: Trainer):\n        nonlocal count\n        value = value_list[count]\n\n        print('updating {} to {}'.format(attr_name, value))\n        setattr(target, attr_name, value)\n        count += 1\n\n    return set_value\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### optimized rounder\n\nI added some implementation from [public kernel](https://www.kaggle.com/fiancheto/petfinder-simple-lgbm-baseline-lb-0-399) to align prediction data to specified histogram (Final submission is aligned with `train` dataset label histogram)"},{"metadata":{"trusted":true,"_uuid":"f7fc3a5d45fb714fdf4b594c99d20ff938971409"},"cell_type":"code","source":"# optimized rounder","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44839786b79d306530e292eec45edc6556cf9f13"},"cell_type":"code","source":"\"\"\"\nref: https://www.kaggle.com/fiancheto/petfinder-simple-lgbm-baseline-lb-0-399\n\"\"\"\nfrom collections import Counter\nfrom functools import partial\n\nimport numpy as np\nimport numba as nb\nimport scipy as sp\nfrom scipy.optimize import differential_evolution\nfrom sklearn.metrics import cohen_kappa_score\n\n\nclass OptimizedRounder(object):\n    def __init__(self, num_class=5, method='differential_evolution'):\n        \"\"\"\n\n        Args:\n            num_class:\n            method: 'nelder-mead' or 'differential_evolution'\n        \"\"\"\n        self.coef_ = 0\n        self.num_class = num_class\n        self.method = method\n\n    def _kappa_loss(self, coef, X, y):\n        # X_p = calc_threshold_label(X, coef)\n        X_p = calc_threshold_label_numba(X, coef.astype(np.float32))\n        # print('X', X.shape, X.dtype, 'coef', coef.shape, coef.dtype)\n        # print('X_p', X_p.shape, X_p.dtype)\n        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n        # print('coef', coef, 'y', y, 'X_p', X_p, 'll', ll)\n        # ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    def fit(self, X, y):\n        if X.ndim > 1:\n            X = X.ravel()\n        if y.ndim > 1:\n            y = y.ravel()\n        X = X.astype(np.float32)\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        if self.method == 'nelder-mead':\n            initial_coef = self.get_initial_coef()\n            print('fit... initial_coef', initial_coef)\n            self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n            # print('coef_', self.coef_)\n            # print('coef_ x', self.coef_['x'])\n        elif self.method == 'differential_evolution':\n            bounds = [(0., self.num_class-1) for _ in range(self.num_class - 1)]\n            result = differential_evolution(loss_partial, bounds)\n            self.coef_ = result\n        else:\n            raise ValueError(\"[ERROR] Unexpected value method={}\".format(self.method))\n\n    def get_initial_coef(self):\n        return np.arange(self.num_class - 1) + 0.5\n\n    def predict(self, X, coef=None):\n        if X.ndim > 1:\n            X = X.ravel()\n        if coef is None:\n            coef = self.get_initial_coef()\n            print('[WARNING] set initial coef {}'.format(coef))\n        # X_p = calc_threshold_label(X, np.asarray(coef, dtype=np.float32))\n        X_p = calc_threshold_label_numba(X.astype(np.float32),\n                                         np.asarray(coef, dtype=np.float32))\n        return X_p\n\n    def calc_histogram_coef(self, X, y_count):\n        \"\"\"\n\n        Args:\n            X: target predicted values to calculate threshold.\n            y_count (Counter or list): list of each class occurrence count.\n\n        Returns:\n            coef:\n        \"\"\"\n        size_array = np.zeros((self.num_class,), dtype=np.int32)\n        for i in range(self.num_class):\n            # Counter `y_count[i]` returns i-th count.\n            size_array[i] = y_count[i]\n        size_array = size_array.cumsum()\n        hist_array = size_array / size_array[-1]\n        x_size_array = (hist_array * len(X)).astype(np.int32)\n        coef = np.sort(X)[x_size_array[:-1]]\n        return coef\n\n    def fit_and_predict_by_histgram(self, X, y):\n        \"\"\"QWK is not used.\n        simply calculate coefficients to match same histgram with `y`.\n        Args:\n            X: predicted label\n            y: ground truth label\n        Returns:\n        \"\"\"\n        if X.ndim > 1:\n            X = X.ravel()\n        if y.ndim > 1:\n            y = y.ravel()\n        y_count = Counter(y)\n        print('train counter', y_count)\n        coef = self.calc_histogram_coef(X, y)\n        self.coef_ = {'x': coef}\n        print('coefficient', self.coef_)\n        return self.predict(X, coef=self.coefficients())\n\n    def coefficients(self):\n        return self.coef_['x']\n\n\ndef calc_threshold_label(X, coef):\n    X_p = np.copy(X)\n    for i, pred in enumerate(X_p):\n        if pred < coef[0]:\n            X_p[i] = 0\n        elif pred >= coef[0] and pred < coef[1]:\n            X_p[i] = 1\n        elif pred >= coef[1] and pred < coef[2]:\n            X_p[i] = 2\n        elif pred >= coef[2] and pred < coef[3]:\n            X_p[i] = 3\n        else:\n            X_p[i] = 4\n    return X_p\n\n\n@nb.jit(nb.int32[:](nb.float32[:], nb.float32[:]), nopython=True, nogil=True)\ndef calc_threshold_label_numba(X, coef):\n    X_p = np.empty(X.shape, dtype=np.int32)\n    for i, pred in enumerate(X):\n        if pred < coef[0]:\n            X_p[i] = 0\n        elif pred < coef[1]:\n            X_p[i] = 1\n        elif pred < coef[2]:\n            X_p[i] = 2\n        elif pred < coef[3]:\n            X_p[i] = 3\n        else:\n            X_p[i] = 4\n    return X_p\n\n\n","execution_count":41,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"calculate QWK score during NN training, as extension"},{"metadata":{"trusted":true,"_uuid":"86f258256cb138dae84a547f7e2d17149c380f85"},"cell_type":"code","source":"import numpy\n\nfrom chainer.dataset import convert\nfrom sklearn.metrics import cohen_kappa_score\n\n#from chainer_chemistry.training.extensions.batch_evaluator import BatchEvaluator  # NOQA\n\n\ndef _to_list(a):\n    \"\"\"convert value `a` to list\n\n    Args:\n        a: value to be convert to `list`\n\n    Returns (list):\n\n    \"\"\"\n    if isinstance(a, (int, float)):\n        return [a, ]\n    else:\n        # expected to be list or some iterable class\n        return a\n\n\nclass QuadraticWeightedKappaEvaluator(BatchEvaluator):\n\n    \"\"\"Evaluator which calculates quadratic weighted kappa\n\n    Note that this Evaluator is only applicable to binary classification task.\n\n    Args:\n        iterator: Dataset iterator for the dataset to calculate ROC AUC score.\n            It can also be a dictionary of iterators. If this is just an\n            iterator, the iterator is registered by the name ``'main'``.\n        target: Link object or a dictionary of links to evaluate. If this is\n            just a link object, the link is registered by the name ``'main'``.\n        converter: Converter function to build input arrays and true label.\n            :func:`~chainer.dataset.concat_examples` is used by default.\n            It is expected to return input arrays of the form\n            `[x_0, ..., x_n, t]`, where `x_0, ..., x_n` are the inputs to\n            the evaluation function and `t` is the true label.\n        device: Device to which the training data is sent. Negative value\n            indicates the host memory (CPU).\n        eval_hook: Function to prepare for each evaluation process. It is\n            called at the beginning of the evaluation. The evaluator extension\n            object is passed at each call.\n        eval_func: Evaluation function called at each iteration. The target\n            link to evaluate as a callable is used by default.\n        name (str): name of this extension. When `name` is None,\n            `default_name='validation'` which is defined in super class\n            `Evaluator` is used as extension name. This name affects to the\n            reported key name.\n        pos_labels (int or list): labels of the positive class, other classes\n            are considered as negative.\n        ignore_labels (int or list or None): labels to be ignored.\n            `None` is used to not ignore all labels.\n        raise_value_error (bool): If `False`, `ValueError` caused by\n            `roc_auc_score` calculation is suppressed and ignored with a\n            warning message.\n        logger:\n\n    Attributes:\n        converter: Converter function.\n        device: Device to which the training data is sent.\n        eval_hook: Function to prepare for each evaluation process.\n        eval_func: Evaluation function called at each iteration.\n        pos_labels (list): labels of the positive class\n        ignore_labels (list): labels to be ignored.\n\n    \"\"\"\n\n    def __init__(self, iterator, target, converter=convert.concat_examples,\n                 device=None, eval_hook=None, eval_func=None, name=None,\n                 pos_labels=1, ignore_labels=None, raise_value_error=True,\n                 logger=None):\n        metrics_fun = {'qwk': self.quadratic_weighted_kappa}\n        super(QuadraticWeightedKappaEvaluator, self).__init__(\n            iterator, target, converter=converter, device=device,\n            eval_hook=eval_hook, eval_func=eval_func, metrics_fun=metrics_fun,\n            name=name, logger=logger)\n\n        # self.pos_labels = _to_list(pos_labels)\n        # self.ignore_labels = _to_list(ignore_labels)\n        # self.raise_value_error = raise_value_error\n\n    def quadratic_weighted_kappa(self, y_total, t_total):\n        # --- ignore labels if specified ---\n        # if self.ignore_labels:\n        #     valid_ind = numpy.in1d(t_total, self.ignore_labels, invert=True)\n        #     y_total = y_total[valid_ind]\n        #     t_total = t_total[valid_ind]\n\n        y_total = numpy.round(y_total)\n        score = cohen_kappa_score(y_total, t_total, weights='quadratic')\n        return score\n","execution_count":42,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BlendConverter for data augmentation during NN training.\n\nIt includes \n\n- permutation augmentation (used in final submission)\n- mixup data augmentation (not used in final submission)\n- gaussian noise data augmentation (not used in final submission)"},{"metadata":{"trusted":true,"_uuid":"af8ad4743ee41c935210964d8663742c6cdd553e"},"cell_type":"code","source":"# --- blend converter ---","execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60f72d276cc26725b67b7d4566c90aa42d04f2a2"},"cell_type":"code","source":"import numpy\nimport numba as nb\n\nimport chainer\nfrom chainer.dataset import concat_examples, to_device\n\n\n@nb.jit(nb.void(nb.float32[:, :], nb.int64), nopython=True, nogil=True)\ndef permute_cols_2d(x, num_cols):\n    \"\"\"Permute cols of 2d-array `x` inplace.\"\"\"\n    bs, ndim = x.shape\n    col_indices = numpy.random.choice(ndim, num_cols, replace=False)\n    for col_index in col_indices:\n        perm = numpy.random.permutation(bs)\n        x[:, int(col_index)] = x[perm, int(col_index)]\n\n\n@nb.jit(nb.void(nb.int32[:, :], nb.int64), nopython=True, nogil=True)\ndef permute_cols_2d_int(x, num_cols):\n    \"\"\"Permute cols of 2d-array `x` inplace.\"\"\"\n    bs, ndim = x.shape\n    col_indices = numpy.random.choice(ndim, num_cols, replace=False)\n    for col_index in col_indices:\n        perm = numpy.random.permutation(bs)\n        x[:, int(col_index)] = x[perm, int(col_index)]\n\n\n@nb.jit(nb.void(nb.float32[:, :, :], nb.int64), nopython=True, nogil=True)\ndef permute_cols_3d(x, num_cols):\n    \"\"\"Permute cols of 3d-array `x` inplace.\"\"\"\n    bs, n_image, ndim = x.shape\n    col_indices = numpy.random.choice(ndim, num_cols, replace=False)\n    for col_index in col_indices:\n        perm = numpy.random.permutation(bs)\n        x[:, :, int(col_index)] = x[perm, :, int(col_index)]\n\n\n@nb.jit(nb.float32[:, :](nb.float32[:, :], nb.int64[:], nb.int64[:], nb.float32[:]),\n        nopython=True, nogil=True)\ndef mixup_2d(x, ind1, ind2, lam):\n    \"\"\"Mixup `x` between ind1 and ind2, with weight lam. return new `x`\"\"\"\n    # num_mixup = lam.shape[0]\n    # lam2 = numpy.ascontiguousarray(lam).reshape((num_mixup, 1))\n    lam2 = numpy.expand_dims(lam, axis=1)\n    x_mix = (lam2 * x[ind1] + (1. - lam2) * x[ind2]).astype(numpy.float32)\n    return numpy.concatenate((x, x_mix), axis=0)\n\n\n@nb.jit(nb.float32[:, :, :](nb.float32[:, :, :], nb.int64[:], nb.int64[:], nb.float32[:]),\n        nopython=True, nogil=True)\ndef mixup_3d(x, ind1, ind2, lam):\n    \"\"\"Mixup `x` between ind1 and ind2, with weight lam. return new `x`\"\"\"\n    # num_mixup = lam.shape[0]\n    # lam3 = numpy.ascontiguousarray(lam).reshape((num_mixup, 1, 1))\n    lam3 = numpy.expand_dims(numpy.expand_dims(lam, axis=1), axis=1)\n    x_mix = (lam3 * x[ind1] + (1 - lam3) * x[ind2]).astype(numpy.float32)\n    return numpy.concatenate((x, x_mix), axis=0)\n\n\n@nb.jit(nb.void(nb.float32[:, :], nb.float32[:], nb.float64), nopython=True, nogil=True)\ndef add_noise_2d(x, std, noise_ratio):\n    \"\"\"Add Gaussian noise with scale `std * noise_ratio`, Value `x` is overwritten inplace\"\"\"\n    noise = numpy.random.normal(0, 1, size=x.shape).astype(numpy.float32)\n    std = numpy.expand_dims(std, axis=0)\n    x[:] = x + noise * std * noise_ratio\n\n\n@nb.jit(nb.void(nb.float32[:, :, :], nb.float32[:], nb.float64), nopython=True, nogil=True)\ndef add_noise_3d(x, std, noise_ratio):\n    \"\"\"Add Gaussian noise with scale `std * noise_ratio`, Value `x` is overwritten inplace\"\"\"\n    noise = numpy.random.normal(0, 1, size=x.shape).astype(numpy.float32)\n    std = numpy.expand_dims(std, axis=0)\n    std = numpy.expand_dims(std, axis=0)\n    x[:] = x + noise * std * noise_ratio\n\n\nclass BlendConverter(object):\n\n    def __init__(self, use_cat=True, use_bert=True, use_image=True,\n                 augmentation=True, permute_col_ratio_list=0.10, num_cols_choice=False,\n                 mixup_ratio=0., alpha=10., std_list=None, noise_ratio_list=None,\n                 mode='normal', use_embed=False):\n        self.use_cat = use_cat\n        self.use_bert = use_bert\n        self.use_image = use_image\n        self.mode = mode\n        self.use_embed = use_embed\n\n        # --- Permute augmentation ---\n        self.augmentation = augmentation\n        if isinstance(permute_col_ratio_list, float):\n            permute_col_ratio_list = [permute_col_ratio_list for _ in range(4)]\n        self.permute_col_ratio_list = permute_col_ratio_list\n        # If True, `num_cols` is calculated as choice, if `False` always `permute_col_ratio` is used.\n        self.num_cols_choice = num_cols_choice\n\n        # --- Mixup ---\n        # ref: http://wazalabo.com/mixup_1.html, https://qiita.com/yu4u/items/70aa007346ec73b7ff05\n        self.mixup_ratio = mixup_ratio\n        self.alpha = alpha\n\n        # --- Gaussian Noise ---\n        self.std_list = std_list\n        self.noise_ratio_list = noise_ratio_list\n\n        print('BlendConverter: augmentation {} ratio {}, choice {}, mixup_ratio {} alpha {}, '\n              'noise_ratio_list {}, use_embed {}'\n              .format(augmentation, self.permute_col_ratio_list, self.num_cols_choice,\n                      self.mixup_ratio, self.alpha, noise_ratio_list, self.use_embed))\n\n        self.extract_inputs = False\n        self._count = 0\n\n    def __call__(self, batch, device=None):\n        # concat in CPU at first\n        # batch_list: [x_num, x_cat, x_bert, x_image, target]\n        if self.mode == 'mean':\n            from itertools import chain\n            data_list = [b[0] for b in batch]\n            data_len_list = [len(d) for d in data_list]\n            data_flatten_list = list(chain.from_iterable(data_list))\n            batch_list = list(concat_examples(data_flatten_list, device=-1))\n\n            indices = numpy.zeros((len(data_flatten_list),), dtype=numpy.int32)\n            index = 0\n            val = 0\n            for k in data_len_list:\n                indices[index:index+k] = val\n                index += k\n                val += 1\n            assert index == len(indices)\n            # batch_list.append(indices)\n            target_mean = numpy.array([b[1] for b in batch])\n        else:\n            batch_list = list(concat_examples(batch, device=-1))\n        if not self.use_cat:\n            batch_list.insert(1, None)\n        if not self.use_bert:\n            batch_list.insert(2, None)\n        if not self.use_image:\n            batch_list.insert(3, None)\n\n        if self.augmentation and chainer.config.train:\n            # --- Gaussian noise augmentation ---\n            if self.noise_ratio_list is not None:\n                for i, x in enumerate(batch_list[:4]):\n                    if self.use_embed and i == 1:\n                        continue\n                    if x is None or self.noise_ratio_list[i] <= 0.:\n                        continue\n                    elif x.ndim == 2:\n                        # noise = numpy.random.normal(0, 1, size=x.shape).astype(numpy.float32)\n                        # batch_list[i] = x + noise * self.std_list[i][None, :] * self.noise_ratio_list[i]\n                        add_noise_2d(x, self.std_list[i], self.noise_ratio_list[i])\n                    elif x.ndim == 3:\n                        # noise = numpy.random.normal(0, 1, size=x.shape).astype(numpy.float32)\n                        # batch_list[i] = x + noise * self.std_list[i][None, None, :] * self.noise_ratio_list[i]\n                        add_noise_3d(x, self.std_list[i], self.noise_ratio_list[i])\n                    else:\n                        raise ValueError(\"[ERROR] Unexpected value x.shape={}\"\n                                         .format(x.shape))\n\n            # --- mixup ---\n            if self.mixup_ratio > 0:\n                bs = batch_list[0].shape[0]\n                num_mixup = int(bs * self.mixup_ratio)\n                ind1 = numpy.random.choice(bs, num_mixup)\n                ind2 = numpy.random.choice(bs, num_mixup)\n                lam = numpy.random.beta(self.alpha, self.alpha, num_mixup).astype(numpy.float32)\n                if self._count <= 1:\n                    print('num_mixup', num_mixup, 'alpha', self.alpha,\n                          'ind1', ind1.shape, 'ind2', ind2.shape)\n                    print('lam', lam.shape, lam[:10])\n                for i, x in enumerate(batch_list):\n                    # Need to mixup labels as well...\n                    if self.use_embed and i == 1:\n                        continue\n                    if x is None:\n                        continue\n                    elif x.ndim == 2:\n                        if x.dtype is numpy.int32:\n                            raise NotImplementedError('x.dtype {} for {}-th feature'.format(x.dtype, i))\n                        # lam2 = lam.reshape((num_mixup, 1))\n                        # x_mix = lam2 * x[ind1] + (1-lam2) * x[ind2]\n                        # batch_list[i] = numpy.concatenate([x, x_mix], axis=0)\n                        batch_list[i] = mixup_2d(x, ind1, ind2, lam)\n                    elif x.ndim == 3:\n                        # lam3 = lam.reshape((num_mixup, 1, 1))\n                        # x_mix = lam3 * x[ind1] + (1-lam3) * x[ind2]\n                        # batch_list[i] = numpy.concatenate([x, x_mix], axis=0)\n                        batch_list[i] = mixup_3d(x, ind1, ind2, lam)\n                    else:\n                        raise ValueError(\"[ERROR] Unexpected value x.shape={}\"\n                                         .format(x.shape))\n\n            # --- permutation augmentation ---\n            # x_num, x_cat, x_bert, x_image = batch_list[:4]\n            for i, x in enumerate(batch_list[:4]):\n                if x is None:\n                    continue\n                elif x.ndim == 2:\n                    bs, ndim = x.shape\n                    # num_cols = 1\n                    num_cols = int(ndim * self.permute_col_ratio_list[i])\n                    if self.num_cols_choice and num_cols > 0:\n                        num_cols = numpy.random.choice(num_cols)\n                    if self.use_embed and i == 1:\n                        permute_cols_2d_int(x, num_cols)\n                    else:\n                        permute_cols_2d(x, num_cols)\n                    if self._count <= 1:\n                        print('i', i, 'num_cols', num_cols)\n                elif x.ndim == 3:\n                    # n_image for image or n_sentence for bert feature\n                    bs, n_image, ndim = x.shape\n                    # num_cols = 1\n                    num_cols = int(ndim * self.permute_col_ratio_list[i])\n                    if self.num_cols_choice and num_cols > 0:\n                        num_cols = numpy.random.choice(num_cols)\n                    permute_cols_3d(x, num_cols)\n                    if self._count <= 1:\n                        print('i', i, 'num_cols', num_cols)\n                else:\n                    raise ValueError(\"[ERROR] Unexpected value x.shape={}\"\n                                     .format(x.shape))\n        else:\n            # print('skip augmentation...')\n            pass\n\n        # send to device...\n        batch_list = [to_device(device, x) for x in batch_list]\n\n        self._count += 1\n        if self.mode == 'mean':\n            indices = to_device(device, indices)\n            if self.extract_inputs:\n                # During inference, do not return label\n                return tuple(batch_list[:-1]) + (indices, )\n            else:\n                # During training, return label as well\n                target_mean = to_device(device, target_mean)\n                return tuple(batch_list) + (indices, target_mean)\n        elif self.mode == 'normal':\n            if self.extract_inputs:\n                # During inference, do not return label\n                return tuple(batch_list[:-1])\n            else:\n                # During training, return label as well\n                return tuple(batch_list)\n\n","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe9a2d1fd78c4b33fcbba8809f2fba45694e7d82","_kg_hide-input":true},"cell_type":"code","source":"# --- fasttext ---","execution_count":45,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48869e7f2d68b78c23a8b2d9fd51622b34c34883","_kg_hide-input":true},"cell_type":"code","source":"import os\n\nimport numpy\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom tqdm import tqdm\n\n\ndef extract_line(line, i, vec_array):\n    line = line.rstrip()\n    # print('line:', line)\n    tmp = line.split(' ')\n    vocab = tmp[0]\n    vec_array[i:i + 1] = numpy.array(tmp[1:], dtype=numpy.float32)\n    return vocab\n\n\ndef construct_fasttext_vocab_list(filepath):\n    \"\"\"\n\n    Args:\n        filepath (str): fast text embedding file path\n\n    Returns:\n        vocab_list (list): length is `num_vocab` in file\n        vec_array (numpy.ndarray): (num_vocab, hdim)\n    \"\"\"\n    with open(filepath, 'r', encoding='utf-8') as f:\n        a = f.readline()\n        num_vocab, hdim = a.split(' ')\n        num_vocab, hdim = int(num_vocab), int(hdim)\n        print('num_vocab', num_vocab, 'hdim', hdim)\n        all_lines = f.readlines()\n        # print('all_lines:', all_lines)\n        print('all_lines extracted on RAM')\n\n    vec_array = numpy.empty((num_vocab, hdim), dtype=numpy.float32)\n    # from joblib import Parallel, delayed\n    # n_jobs = 16\n    # results = Parallel(n_jobs, backend='threading', verbose=1)(\n    #     delayed(extract_line)(line, i, vec_array) for i, line in enumerate(all_lines))\n    vocab_list = [extract_line(line, i, vec_array) for i, line in tqdm(enumerate(all_lines), total=len(all_lines))]\n    return vocab_list, vec_array\n\n\ndef calc_fasttext_feature(corpus, vocab_list, vec_array,\n                          out_dim=None, col_name=None, method='tfidf',\n                          source='fasttext', contraction_method='svd'):\n    h_sent = None\n    cache_filepath = None\n    if col_name is not None:\n        cache_filepath = f'./cache/{source}_{col_name}_{method}_{len(corpus)}.npz'\n        if os.path.exists(cache_filepath):\n            h_sent = load_npz(cache_filepath)\n    if h_sent is None:\n        if method == 'count':\n            vectorizer = CountVectorizer()\n            X = vectorizer.fit_transform(corpus)\n            print('X', type(X), X.shape)  # sparse matrix\n            num_sent, num_feat = X.shape\n            feat_names = vectorizer.get_feature_names()\n            print('feat_names', len(feat_names))\n            assert num_feat == len(feat_names)\n        elif method == 'tfidf':\n            tfv = TfidfVectorizer(\n                min_df=2, max_features=None,\n                strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n                ngram_range=(1, 1), use_idf=True, smooth_idf=True, sublinear_tf=False)  # min_df=2, ngram_range=(1, 3)\n            with timer('fasttext tfidf fit_transform'):\n                X = tfv.fit_transform(corpus)\n            print('X', type(X), X.shape)  # sparse matrix (num_text, num_vocab)\n            num_sent, num_feat = X.shape\n            feat_names = tfv.get_feature_names()\n            print('feat_names', len(feat_names))\n            assert num_feat == len(feat_names)\n        else:\n            raise ValueError(\"[ERROR] Unexpected value method={}\".format(method))\n\n        unknown_count = 0\n        num_vocab, hdim = vec_array.shape\n        feat_array = numpy.empty((num_feat, hdim), dtype=numpy.float32)\n        for i, name in enumerate(feat_names):\n            try:\n                ind = vocab_list.index(name)\n            except ValueError:\n                ind = len(vocab_list) - 1  # unknown word index???\n                unknown_count += 1\n                # print(f'unknown word: {name}, unknown_count {unknown_count}')\n            feat_array[i] = vec_array[ind]\n\n        # X (num_sentence, num_feat), feat_array (num_feat, hdim)\n        # h_sent = numpy.matmul(X, feat_array)\n        h_sent = X * feat_array\n        assert h_sent.shape == (num_sent, hdim)\n        if cache_filepath is not None:\n            save_npz(cache_filepath, h_sent)\n\n    if out_dim is not None:\n        if contraction_method == 'pooling':\n            num_sent, hdim = h_sent.shape\n            pool_size = hdim // out_dim\n            h_sent = numpy.mean(\n                h_sent[:, :out_dim*pool_size].reshape(num_sent, out_dim, pool_size),\n                axis=2)\n        elif contraction_method == 'svd':\n            svd_ = TruncatedSVD(\n                n_components=out_dim, random_state=1337)\n            h_sent = svd_.fit_transform(h_sent)\n        else:\n            raise ValueError(\"[ERROR] Unexpected value contraction_method={}\".format(contraction_method))\n    return h_sent\n\n\nif not is_kaggle_kernel and __name__ == '__main__':\n    use_cache = True\n    npz_filepath = 'crawl-300d-2M.npz'\n    if use_cache and os.path.exists(npz_filepath):\n        a = numpy.load(npz_filepath)\n        vec_array = a['vec_array']\n        vocab_list = list(a['vocab_list'])\n    else:\n        filepath = './crawl-300d-2M.vec'\n        # filepath = './test_sample.vec'\n        vocab_list, vec_array = construct_fasttext_vocab_list(filepath)\n        numpy.savez_compressed(npz_filepath, vocab_list=vocab_list, vec_array=vec_array)\n\n    corpus = [\n        'This is the first document.',\n        'This document is the second document.',\n        'And this is the third one.',\n        'Is this the first document?',\n    ]\n    h_sent = calc_fasttext_feature(corpus, vocab_list, vec_array)\n    print('h_sent', h_sent.shape)\n    print(h_sent)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Glove text feature embedding extraction"},{"metadata":{"trusted":true,"_uuid":"642aee4ef97a1fb10088c65bf6e0459cd01ee97b"},"cell_type":"code","source":"# --- glove_exp ---","execution_count":46,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc5f57d2ba65d00a71dcef3bbe984cf77143d4b0"},"cell_type":"code","source":"import os\n\nimport numpy\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom tqdm import tqdm\n\nimport sys\nimport os\n\n# sys.path.append(os.pardir)\n# sys.path.append(os.path.join(os.pardir, os.pardir))\n# from src.configs import is_kaggle_kernel\n# from src.utils import save_npz, load_npz, timer\n# from src.fasttext.fasttext_exp import calc_fasttext_feature, extract_line\n\n\ndef construct_glove_vocab_list(filepath, hdim=50):\n    \"\"\"\n\n    Args:\n        filepath (str): fast text embedding file path\n\n    Returns:\n        vocab_list (list): length is `num_vocab` in file\n        vec_array (numpy.ndarray): (num_vocab, hdim)\n    \"\"\"\n    with open(filepath, 'r', encoding='utf-8') as f:\n        # a = f.readline()\n        # num_vocab, hdim = a.split(' ')\n        # num_vocab, hdim = int(num_vocab), int(hdim)\n        # print('num_vocab', num_vocab, 'hdim', hdim)\n        all_lines = f.readlines()\n        # print('all_lines:', all_lines)\n        print('all_lines extracted on RAM')\n    num_vocab = len(all_lines)\n    print('num_vocab', num_vocab, 'hdim', hdim)\n\n    vec_array = numpy.empty((num_vocab, hdim), dtype=numpy.float32)\n    # from joblib import Parallel, delayed\n    # n_jobs = 16\n    # results = Parallel(n_jobs, backend='threading', verbose=1)(\n    #     delayed(extract_line)(line, i, vec_array) for i, line in enumerate(all_lines))\n    vocab_list = [extract_line(line, i, vec_array) for i, line in tqdm(enumerate(all_lines), total=len(all_lines))]\n    return vocab_list, vec_array\n\n\nif not is_kaggle_kernel and __name__ == '__main__':\n    use_cache = True\n    npz_filepath = 'glove-50d-6B.npz'\n    if use_cache and os.path.exists(npz_filepath):\n        a = numpy.load(npz_filepath)\n        vec_array = a['vec_array']\n        vocab_list = list(a['vocab_list'])\n    else:\n        filepath = './glove.6B.50d.txt'\n        # filepath = './test_sample.vec'\n        vocab_list, vec_array = construct_glove_vocab_list(filepath)\n        numpy.savez_compressed(npz_filepath, vocab_list=vocab_list, vec_array=vec_array)\n\n    corpus = [\n        'This is the first document.',\n        'This document is the second document.',\n        'And this is the third one.',\n        'Is this the first document?',\n    ]\n    h_sent = calc_fasttext_feature(corpus, vocab_list, vec_array)\n    print('h_sent', h_sent.shape)\n    print(h_sent)\n","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"266c5f46cfa548acc1d6c45d0c531230bd63940e"},"cell_type":"code","source":"# --- pet finder parser ---","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ae37c4ebfd35ecc2934d10a1d26ca5b0af81916"},"cell_type":"code","source":"\"\"\"\nScripts from: https://www.kaggle.com/wrosinski/baselinemodeling\n\"\"\"\nfrom glob import glob\nimport os\nfrom logging import getLogger\n\nimport feather\nimport pandas as pd\nimport json\nimport numpy as np\nfrom PIL import Image\nfrom joblib import Parallel, delayed\n\nclass PetFinderParser(object):\n\n    def __init__(self, debug=False):\n\n        self.debug = debug\n        self.sentence_sep = ' '\n\n        # Does not have to be extracted because main DF already contains description\n        self.extract_sentiment_text = False\n        # version 1 is from `baselinemodeling` kernel\n        # version 2 is from `simple xgboost model` kernel\n        self.version = 2\n\n    def open_metadata_file(self, filename):\n        \"\"\"\n        Load metadata file.\n        \"\"\"\n        with open(filename, 'r', encoding='utf-8') as f:\n            metadata_file = json.load(f)\n        return metadata_file\n\n    def open_sentiment_file(self, filename):\n        \"\"\"\n        Load sentiment file.\n        \"\"\"\n        with open(filename, 'r', encoding='utf-8') as f:\n            sentiment_file = json.load(f)\n        return sentiment_file\n\n    def open_image_file(self, filename):\n        \"\"\"\n        Load image file.\n        \"\"\"\n        image = np.asarray(Image.open(filename))\n        return image\n\n    def parse_sentiment_file(self, file):\n        \"\"\"\n        Parse sentiment file. Output DF with sentiment features.\n        \"\"\"\n\n        file_sentiment = file['documentSentiment']\n        file_entities = [x['name'] for x in file['entities']]\n        file_entities = self.sentence_sep.join(file_entities)\n\n        if self.version == 1:\n            if self.extract_sentiment_text:\n                file_sentences_text = [x['text']['content'] for x in file['sentences']]\n                file_sentences_text = self.sentence_sep.join(file_sentences_text)\n            file_sentences_sentiment = [x['sentiment'] for x in file['sentences']]\n\n            file_sentences_sentiment = pd.DataFrame.from_dict(\n                file_sentences_sentiment, orient='columns').sum()\n            file_sentences_sentiment = file_sentences_sentiment.add_prefix('document_').to_dict()\n\n            file_sentiment.update(file_sentences_sentiment)\n            df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n            if self.extract_sentiment_text:\n                df_sentiment['text'] = file_sentences_text\n\n            df_sentiment['entities'] = file_entities\n            df_sentiment = df_sentiment.add_prefix('sentiment_')\n        elif self.version == 2:\n            file_sentences_sentiment = [x['sentiment'] for x in file['sentences']]\n            file_sentences_sentiment = pd.DataFrame.from_dict(\n                file_sentences_sentiment, orient='columns')\n            file_sentences_sentiment_df = pd.DataFrame(\n                {\n                    'magnitude_sum': file_sentences_sentiment['magnitude'].sum(axis=0),\n                    'score_sum': file_sentences_sentiment['score'].sum(axis=0),\n                    'magnitude_mean': file_sentences_sentiment['magnitude'].mean(axis=0),\n                    'score_mean': file_sentences_sentiment['score'].mean(axis=0),\n                    'magnitude_var': file_sentences_sentiment['magnitude'].var(axis=0),\n                    'score_var': file_sentences_sentiment['score'].var(axis=0),\n                }, index=[0]\n            )\n            df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n            df_sentiment = pd.concat([df_sentiment, file_sentences_sentiment_df], axis=1)\n\n            df_sentiment['entities'] = file_entities\n            df_sentiment = df_sentiment.add_prefix('sentiment_')\n        else:\n            raise ValueError(\"[ERROR] Unexpected value self.version={}\".format(self.version))\n        return df_sentiment\n\n    def parse_metadata_file(self, file):\n        \"\"\"\n        Parse metadata file. Output DF with metadata features.\n        \"\"\"\n\n        file_keys = list(file.keys())\n\n        if 'labelAnnotations' in file_keys:\n            if self.version == 1:\n                file_annots = file['labelAnnotations'][:int(len(file['labelAnnotations']) * 0.3)]\n            else:\n                file_annots = file['labelAnnotations']\n            # file_top_score = np.asarray([float(x['score']) for x in file_annots]).mean()\n            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n            file_top_desc = [x['description'] for x in file_annots]\n        else:\n            file_top_score = np.nan\n            file_top_desc = ['']\n\n        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n        file_crops = file['cropHintsAnnotation']['cropHints']\n\n        file_color_score = np.asarray([float(x['score']) for x in file_colors]).mean()\n        file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n\n        file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n\n        if 'importanceFraction' in file_crops[0].keys():\n            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n        else:\n            file_crop_importance = np.nan\n\n        df_metadata = {\n            'annots_score': file_top_score,\n            'color_score': file_color_score,\n            'color_pixelfrac': file_color_pixelfrac,\n            'crop_conf': file_crop_conf,\n            'crop_importance': file_crop_importance,\n            'annots_top_desc': self.sentence_sep.join(file_top_desc)\n        }\n\n        df_metadata = pd.DataFrame.from_dict(df_metadata, orient='index').T\n        df_metadata = df_metadata.add_prefix('metadata_')\n\n        return df_metadata\n\n\n# Helper function for parallel data processing:\ndef extract_additional_features(pet_parser, pet_id, mode='train'):\n    sentiment_filename = '{}/{}_sentiment/{}.json'.format(pet_dir, mode, pet_id)\n    try:\n        sentiment_file = pet_parser.open_sentiment_file(sentiment_filename)\n        try:\n            df_sentiment = pet_parser.parse_sentiment_file(sentiment_file)\n            df_sentiment['PetID'] = pet_id\n        except Exception:\n            df_sentiment = []\n    except FileNotFoundError:\n        df_sentiment = []\n\n    dfs_metadata = []\n    metadata_filenames = sorted(glob('{}/{}_metadata/{}*.json'.format(pet_dir, mode, pet_id)))\n    if len(metadata_filenames) > 0:\n        for f in metadata_filenames:\n            try:\n                metadata_file = pet_parser.open_metadata_file(f)\n                df_metadata = pet_parser.parse_metadata_file(metadata_file)\n                df_metadata['PetID'] = pet_id\n                dfs_metadata.append(df_metadata)\n            except Exception:\n                pass\n        dfs_metadata = pd.concat(dfs_metadata, ignore_index=True, sort=False)\n    dfs = [df_sentiment, dfs_metadata]\n\n    return dfs\n\n\nclass SentimentMetadataPreprocessor(object):\n    def __init__(self):\n        self.train_dfs_sentiment, self.train_dfs_metadata = None, None\n        self.test_dfs_sentiment, self.test_dfs_metadata = None, None\n        self.train_sentiment_gr, self.train_metadata_gr = None, None\n        self.test_sentiment_gr, self.test_metadata_gr = None, None\n        self.train_sentiment_desc, self.train_metadata_desc = None, None\n        self.test_sentiment_desc, self.test_metadata_desc = None, None\n        # version 1 is from `baselinemodeling` kernel\n        # version 2 is from `simple xgboost model` kernel\n        self.version = 2\n\n    def preprocess_sentiment_and_metadata(self, train, test, n_jobs=16, use_cache=True):\n        key = 'train{}_test{}_version{}'.format(len(train), len(test), self.version)\n        if use_cache:\n            result = self.load(key)\n            if result:\n                return\n\n        # Unique IDs from train and test:\n        train_pet_ids = train.PetID.unique()\n        test_pet_ids = test.PetID.unique()\n\n        pet_parser = PetFinderParser()\n        # Train set:\n        # Parallel processing of data:\n        dfs_train = Parallel(n_jobs=n_jobs, verbose=1)(\n            delayed(extract_additional_features)(pet_parser, i, mode='train') for i in train_pet_ids)\n\n        # Extract processed data and format them as DFs:\n        train_dfs_sentiment = [x[0] for x in dfs_train if isinstance(x[0], pd.DataFrame)]\n        train_dfs_metadata = [x[1] for x in dfs_train if isinstance(x[1], pd.DataFrame)]\n\n        train_dfs_sentiment = pd.concat(train_dfs_sentiment, ignore_index=True, sort=False)\n        train_dfs_metadata = pd.concat(train_dfs_metadata, ignore_index=True, sort=False)\n\n        print(train_dfs_sentiment.shape, train_dfs_metadata.shape)\n\n        # Test set:\n        # Parallel processing of data:\n        dfs_test = Parallel(n_jobs=n_jobs, verbose=1)(\n            delayed(extract_additional_features)(pet_parser, i, mode='test') for i in test_pet_ids)\n\n        # Extract processed data and format them as DFs:\n        test_dfs_sentiment = [x[0] for x in dfs_test if isinstance(x[0], pd.DataFrame)]\n        test_dfs_metadata = [x[1] for x in dfs_test if isinstance(x[1], pd.DataFrame)]\n\n        test_dfs_sentiment = pd.concat(test_dfs_sentiment, ignore_index=True, sort=False)\n        test_dfs_metadata = pd.concat(test_dfs_metadata, ignore_index=True, sort=False)\n\n        print(test_dfs_sentiment.shape, test_dfs_metadata.shape)\n\n        self.train_dfs_sentiment, self.train_dfs_metadata = train_dfs_sentiment, train_dfs_metadata\n        self.test_dfs_sentiment, self.test_dfs_metadata = test_dfs_sentiment, test_dfs_metadata\n        # --- Group extracted features by PetID ---\n        # Extend aggregates and improve column naming\n        if self.version == 1:\n            aggregates = ['mean', 'sum']\n            sent_agg = ['mean', 'sum']\n        elif self.version == 2:\n            aggregates = ['mean', 'sum', 'var']\n            sent_agg = ['sum']\n\n        # Train\n        train_metadata_desc = train_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n        train_metadata_desc = train_metadata_desc.reset_index()\n        train_metadata_desc[\n            'metadata_annots_top_desc'] = train_metadata_desc[\n            'metadata_annots_top_desc'].apply(lambda x: ' '.join(x))\n\n        prefix = 'metadata'\n        train_metadata_gr = train_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n        for i in train_metadata_gr.columns:\n            if 'PetID' not in i:\n                train_metadata_gr[i] = train_metadata_gr[i].astype(float)\n        train_metadata_gr = train_metadata_gr.groupby(['PetID']).agg(aggregates)\n        if self.version == 1:\n            train_metadata_gr.columns = pd.Index(['{}_{}_{}'.format(\n                prefix, c[0], c[1].upper()) for c in train_metadata_gr.columns.tolist()])\n        elif self.version == 2:\n            train_metadata_gr.columns = pd.Index([f'{c[0]}_{c[1].upper()}' for c in train_metadata_gr.columns.tolist()])\n        train_metadata_gr = train_metadata_gr.reset_index()\n\n        train_sentiment_desc = train_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n        train_sentiment_desc = train_sentiment_desc.reset_index()\n        train_sentiment_desc[\n            'sentiment_entities'] = train_sentiment_desc[\n            'sentiment_entities'].apply(lambda x: ' '.join(x))\n\n        prefix = 'sentiment'\n        train_sentiment_gr = train_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n        for i in train_sentiment_gr.columns:\n            if 'PetID' not in i:\n                train_sentiment_gr[i] = train_sentiment_gr[i].astype(float)\n        train_sentiment_gr = train_sentiment_gr.groupby(['PetID']).agg(sent_agg)\n        if self.version == 1:\n            train_sentiment_gr.columns = pd.Index(['{}_{}_{}'.format(\n                prefix, c[0], c[1].upper()) for c in train_sentiment_gr.columns.tolist()])\n        elif self.version == 2:\n            train_sentiment_gr.columns = pd.Index([f'{c[0]}' for c in train_sentiment_gr.columns.tolist()])\n        train_sentiment_gr = train_sentiment_gr.reset_index()\n\n        # Test\n        test_metadata_desc = test_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n        test_metadata_desc = test_metadata_desc.reset_index()\n        test_metadata_desc[\n            'metadata_annots_top_desc'] = test_metadata_desc[\n            'metadata_annots_top_desc'].apply(lambda x: ' '.join(x))\n\n        prefix = 'metadata'\n        test_metadata_gr = test_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n        for i in test_metadata_gr.columns:\n            if 'PetID' not in i:\n                test_metadata_gr[i] = test_metadata_gr[i].astype(float)\n        test_metadata_gr = test_metadata_gr.groupby(['PetID']).agg(aggregates)\n        if self.version == 1:\n            test_metadata_gr.columns = pd.Index(['{}_{}_{}'.format(\n                prefix, c[0], c[1].upper()) for c in test_metadata_gr.columns.tolist()])\n        elif self.version == 2:\n            test_metadata_gr.columns = pd.Index([f'{c[0]}_{c[1].upper()}'\n                                                 for c in test_metadata_gr.columns.tolist()])\n        test_metadata_gr = test_metadata_gr.reset_index()\n\n        test_sentiment_desc = test_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n        test_sentiment_desc = test_sentiment_desc.reset_index()\n        test_sentiment_desc[\n            'sentiment_entities'] = test_sentiment_desc[\n            'sentiment_entities'].apply(lambda x: ' '.join(x))\n\n        prefix = 'sentiment'\n        test_sentiment_gr = test_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n        for i in test_sentiment_gr.columns:\n            if 'PetID' not in i:\n                test_sentiment_gr[i] = test_sentiment_gr[i].astype(float)\n        test_sentiment_gr = test_sentiment_gr.groupby(['PetID']).agg(sent_agg)\n        if self.version == 1:\n            test_sentiment_gr.columns = pd.Index(['{}_{}_{}'.format(\n                prefix, c[0], c[1].upper()) for c in test_sentiment_gr.columns.tolist()])\n        elif self.version == 2:\n            test_sentiment_gr.columns = pd.Index([f'{c[0]}' for c in test_sentiment_gr.columns.tolist()])\n        test_sentiment_gr = test_sentiment_gr.reset_index()\n        # return train_dfs_sentiment, train_dfs_metadata, test_dfs_sentiment, test_dfs_metadata\n        self.train_sentiment_gr, self.train_metadata_gr = train_sentiment_gr, train_metadata_gr\n        self.test_sentiment_gr, self.test_metadata_gr = test_sentiment_gr, test_metadata_gr\n        self.train_sentiment_desc, self.train_metadata_desc = train_sentiment_desc, train_metadata_desc\n        self.test_sentiment_desc, self.test_metadata_desc = test_sentiment_desc, test_metadata_desc\n\n        self.save(key)\n        return\n\n    def save(self, key):\n        os.makedirs('cache', exist_ok=True)\n        for i, df in enumerate([self.train_dfs_sentiment, self.train_dfs_metadata,\n                   self.test_dfs_sentiment, self.test_dfs_metadata,\n                   self.train_sentiment_gr, self.train_metadata_gr,\n                   self.test_sentiment_gr, self.test_metadata_gr,\n                   self.train_sentiment_desc, self.train_metadata_desc,\n                   self.test_sentiment_desc, self.test_metadata_desc]):\n            df.to_feather('cache/smp_{}_{:03}.feather'.format(key, i))\n\n    def load(self, key):\n        df_list = []\n        for i in range(12):\n            if os.path.exists('cache/smp_{}_{:03}.feather'.format(key, i)):\n                df = read_feather('cache/smp_{}_{:03}.feather'.format(key, i))\n                df_list.append(df)\n            else:\n                return False\n        self.train_dfs_sentiment, self.train_dfs_metadata, \\\n        self.test_dfs_sentiment, self.test_dfs_metadata, \\\n        self.train_sentiment_gr, self.train_metadata_gr, \\\n        self.test_sentiment_gr, self.test_metadata_gr, \\\n        self.train_sentiment_desc, self.train_metadata_desc, \\\n        self.test_sentiment_desc, self.test_metadata_desc = tuple(df_list)\n        return True\n\n\ndef read_feather(filepath):\n    return feather.read_dataframe(filepath)\n\n\n","execution_count":49,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf8f623d582adad6944c2d0f30cdace368c2aff7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature extraction of `rating.json` from external dataset for Breed feature."},{"metadata":{"trusted":true,"_uuid":"a9c11e679bb74459d587fbf17c982198080b33a9"},"cell_type":"code","source":"# --- rating eda ---\nimport json\nimport os\nimport pandas as pd\nimport numpy as np\n\n\ndef load_json(filepath):\n    \"\"\"Load params, which is stored in json format.\n\n    Args:\n        filepath (str): filepath to json file to load.\n\n    Returns (dict or list): params\n    \"\"\"\n    with open(filepath, 'r') as f:\n        params = json.load(f)\n    return params\n\n\ndef calc_breed_rating_feat(breeds, thresh=70):\n    json_path = os.path.join(json_dir, 'rating.json')\n    params = load_json(json_path)\n    cat_df = pd.DataFrame(params['cat_breeds']).T\n    dog_df = pd.DataFrame(params['dog_breeds']).T\n    print('cat_df', cat_df.shape, 'dog_df', dog_df.shape)\n\n    def _extract_rating_feature(breed_name, df):\n        names_in_rating = list(df.index.values)\n        if breed_name in names_in_rating:\n            return df.loc[breed_name, :]\n        else:\n            exist = 0\n            for breed_name_elem in breed_name.split(' '):\n                exist += np.array([(breed_name_elem in names) for names in names_in_rating])\n            if np.sum(exist) > 0:\n                result = df[exist > 0].mean(axis=0)\n                result.name = breed_name\n                return result\n            else:\n                # return all df's mean...\n                result = df.mean(axis=0)\n                result.name = breed_name\n                return result\n\n    def extract_rating_feature(row):\n        # print('row', row)\n        animal_type = row['Type']\n        breed_name = row['BreedName']\n        if animal_type == 1:\n            return _extract_rating_feature(breed_name, dog_df)\n        else:\n            assert animal_type == 2\n            return _extract_rating_feature(breed_name, cat_df)\n\n    # debug\n    feat_list = []\n    # breeds = breeds.iloc[:5]\n    for index, row in breeds.iterrows():\n        # print('row', type(row))\n        feat = extract_rating_feature(row)\n        feat_list.append(feat)\n    # a = breeds.loc[:3, ['Type', 'BreedName']].apply(extract_rating_feature)\n    feat_df = pd.concat(feat_list, axis=1, sort=False).T\n    # thresh = 60  # 67 is big threshold for dog/cat\n    if thresh is not None:\n        feat_df = feat_df.loc[:, feat_df.isna().sum() < thresh]\n    return feat_df\n","execution_count":50,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Language feature extraction\n\nVarious kinds of people are lived in Malaysia (Malay, Chinese), thus I thought it is important feature."},{"metadata":{"trusted":true,"_uuid":"7d1be4f175fe602d3900083ab8ff10625df86a91"},"cell_type":"code","source":"from langdetect import detect\nfrom joblib import Parallel, delayed\nimport pandas as pd\n\n\nimport sys\nimport os\n\ndef detect_wrapper(s):\n    try:\n        lang = detect(s)\n    except Exception:\n        lang = 'unknown'\n    if lang.startswith('zh-'):\n        lang = 'zh-cn'  # consider chinese char as same.\n    if lang not in ['en', 'id', 'da', 'de', 'zh-cn', 'unknown']:\n        lang = 'others'\n    return lang\n\n\ndef process_lang_df(train, test, use_cache=True):\n    train_cache_filepath = './cache/train_lang_df.feather'\n    test_cache_filepath = './cache/test_lang_df.feather'\n    if use_cache and os.path.exists(train_cache_filepath) and os.path.exists(test_cache_filepath):\n        train_df = read_feather(train_cache_filepath)\n        test_df = read_feather(test_cache_filepath)\n    else:\n        n_jobs = 16\n        train_results = Parallel(n_jobs, verbose=1)(\n            delayed(detect_wrapper)(s) for s in train['Description'].values)\n        test_results = Parallel(n_jobs, verbose=1)(\n            delayed(detect_wrapper)(s) for s in test['Description'].values)\n        train_df = pd.DataFrame(train_results, columns=['lang'])\n        test_df = pd.DataFrame(test_results, columns=['lang'])\n        train_df.to_feather(train_cache_filepath)\n        test_df.to_feather(test_cache_filepath)\n    return train_df, test_df\n","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea9a926fdf1697fedc4639d9f8d042802dba321f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"026852568e7fb499fa101dcf4f3689f4a825c2c9"},"cell_type":"code","source":"# --- preprocessing 2 ---","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4d48ee72b85a4de04db6ae2dcc00ab9a9f082a9"},"cell_type":"code","source":"from copy import deepcopy\nfrom time import perf_counter\n\nimport numpy as np\nimport pandas as pd\nfrom joblib import delayed, Parallel\nimport os\n\nimport sys\nimport os\n\nclass Preprocessor(object):\n    def __init__(self, arch='xgb'):\n        if arch == 'xlearn':\n            self.numeric_cols = []\n            self.cat_cols = [\n                'Age', 'MaturitySize', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt',\n                'FurLength', 'Health', 'Vaccinated', 'Dewormed', 'Sterilized',\n                'Gender', 'Color1', 'Color2', 'Color3', 'Type', 'Breed1', 'Breed2', 'State']\n        elif arch == 'xgb':\n            # self.numeric_cols = [\n            #     'PhotoAmt', 'Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n            #     'Vaccinated', 'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health',\n            #     'Age', 'MaturitySize', 'Quantity', 'Fee', 'VideoAmt']\n            # self.cat_cols = []\n            self.numeric_cols = ['Age', 'MaturitySize', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt',\n                                 'FurLength', 'Health', 'Vaccinated', 'Dewormed', 'Sterilized',\n                                 'Gender', 'Color1', 'Color2', 'Color3', 'Type', 'Breed1', 'Breed2', 'State']\n            self.cat_cols = []\n            # self.numeric_cols = ['Age', 'MaturitySize', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']\n            # self.cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n            #                  'Vaccinated', 'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health']\n        elif arch == 'nn':\n            # nn\n            self.numeric_cols = ['Age', 'MaturitySize', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']\n            self.cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n                             'Vaccinated', 'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health']\n            # self.numeric_cols = ['Age', ]\n            # self.cat_cols = ['Fee', 'MaturitySize', 'Quantity', 'PhotoAmt', 'VideoAmt',\n            #     'FurLength', 'Health', 'Vaccinated', 'Dewormed', 'Sterilized',\n            #     'Gender', 'Color1', 'Color2', 'Color3', 'Type', 'Breed1', 'Breed2', 'State']\n        else:\n            # lgbm, cb\n            self.numeric_cols = ['Age', 'MaturitySize', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']\n            self.cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n                             'Vaccinated', 'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health']\n\n        # TODO: process these features properly later...\n        remove_cols = ['RescuerID', 'PetID', 'AdoptionSpeed']\n        other_cols = ['Name', 'Description']\n        self.train_indices = None\n        self.test_indices = None\n        self.target = None\n        self.num_cat_id = None\n        self.arch = arch\n\n    def remove_cols(self, cols):\n        if isinstance(cols, str):\n            cols = [cols]\n\n        for col in cols:\n            if col in self.cat_cols:\n                self.cat_cols.remove(col)\n                print(f'removing {col} from cat_cols...')\n            if col in self.numeric_cols:\n                self.numeric_cols.remove(col)\n                print(f'removing {col} from numeric_cols...')\n\n    def preprocess(self, train, test, breeds, colors, states,\n                   debug=False, use_tfidf=True, use_tfidf_cache=True,\n                   use_sentiment=True, use_metadata=False, cat2num=True,\n                   use_rescuer_id_count=True, use_name_feature=True, use_target_encoding=False,\n                   tfidf_svd_components=120, animal_type=None, num_sentiment_text=0,\n                   use_gdp=False, arch='lgbm',\n                   use_sentiment2=True, use_metadata2=True, use_text=True, use_fasttext=True,\n                   embedding_type_list=None,\n                   use_image_size=True, use_breed_feature=True, add_pred=None,\n                   use_custom_boolean_feature=True):\n        categorical_cols = deepcopy(self.cat_cols)\n\n        print('preproces... arch={}'.format(arch))\n        train['Name'].fillna('none', inplace=True)\n        test['Name'].fillna('none', inplace=True)\n        # train['Description'].fillna('none', inplace=True)\n        # test['Description'].fillna('none', inplace=True)\n\n        train['dataset_type'] = 'train'\n        test['dataset_type'] = 'test'\n        all_data = pd.concat([train, test], axis=0, sort=False)\n        train_indices = (all_data['dataset_type'] == 'train').values\n        test_indices = (all_data['dataset_type'] == 'test').values\n        self.train_indices = train_indices\n        self.test_indices = test_indices\n        assert self.train_indices[len(train):].sum() == 0\n        assert self.test_indices[:len(train)].sum() == 0\n        target = train['AdoptionSpeed'].values.astype(np.float32)[:, None]\n        self.target = target\n\n        if arch in ['xlearn', 'nn']:  #\n            # self.cat_cols = [\n            #     'Age', 'MaturitySize', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt',\n            #     'FurLength', 'Health', 'Vaccinated', 'Dewormed', 'Sterilized',\n            #     'Gender', 'Color1', 'Color2', 'Color3', 'Type', 'Breed1', 'Breed2', 'State']\n            # --- cutoff ---\n            age_cutoff = 84  # TODO: hyperparameter tuning. This affects a lot!!!\n            print('age_cutoff', age_cutoff)\n            all_data.loc[all_data['Age'] >= age_cutoff, 'Age'] = age_cutoff\n            # 'Quantity', max was 20, but most of them are ~10.\n            quantity_cutoff = 15\n            all_data.loc[all_data['Quantity'] >= quantity_cutoff, 'Quantity'] = quantity_cutoff\n            # 'VideoAmt', max was 8, but most of them are ~1.\n            video_amt_cutoff = 5\n            all_data.loc[all_data['VideoAmt'] >= video_amt_cutoff, 'VideoAmt'] = video_amt_cutoff\n            # 'PhotoAmt', max was 30, but most of them are ~11.\n            # photo_amt_cutoff = 12\n            photo_amt_cutoff = 15\n            all_data.loc[all_data['PhotoAmt'] >= photo_amt_cutoff, 'PhotoAmt'] = photo_amt_cutoff\n            # 'Fee', max was 3000, but most of them are ~300 or ~500\n            # 300 or 500\n            fee_cutoff = 500\n            all_data.loc[all_data['Fee'] >= fee_cutoff, 'Fee'] = fee_cutoff\n\n            # --- discretize to bin ---\n            print('discretize...')\n\n            age_cut_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 24, 30, 36, 48, 60, 72, 84]\n            age_array = all_data['Age'].values\n            for i in range(len(age_cut_list) - 1):\n                age_th = age_cut_list[i]\n                age_th2 = age_cut_list[i+1]\n                all_data.loc[(age_array >= age_th) & (age_array < age_th2), 'Age'] = age_th\n            fee_cut_list = [0, 1, 10, 50, 100, 500]\n            fee_array = all_data['Fee'].values\n            for i in range(len(fee_cut_list) - 1):\n                fee_th = fee_cut_list[i]\n                fee_th2 = fee_cut_list[i+1]\n                all_data.loc[(fee_array >= fee_th) & (fee_array < fee_th2), 'Fee'] = fee_th\n            # all_data.loc[:, 'Age'] = pd.cut(\n            #     all_data['Age'], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 24, 30, 36, 48, 60, 72, 84], labels=False)\n            # all_data.loc[:, 'Fee'] = pd.cut(\n            #     all_data['Fee'], [0, 1, 10, 50, 100, 500], labels=False)\n\n            train = all_data.iloc[train_indices].copy()\n            test = all_data.iloc[test_indices].copy()\n\n        if use_gdp:\n            add_gdp(train)\n            add_gdp(test)\n\n            # Scaling... max value must be calculated beforehand!!\n            state_gdp_max = train[\"state_gdp\"].max()\n            state_pop_max = train[\"state_population\"].max()\n            train[\"state_gdp\"] = train[\"state_gdp\"] / state_gdp_max\n            test[\"state_gdp\"] = test[\"state_gdp\"] / state_gdp_max\n            train[\"state_population\"] = train[\"state_population\"] / state_pop_max\n            test[\"state_population\"] = test[\"state_population\"] / state_pop_max\n\n            self.numeric_cols.append('state_gdp')\n            self.numeric_cols.append('state_population')\n\n        if use_rescuer_id_count:\n            cutoff_count = 20  # TODO: check which is better. not use it for now...\n            # cutoff_count = -1  # not cutoff it for now...\n            print(f'use_rescuer_id_count... cutoff {cutoff_count}')\n            rescuer_id_count_col_name = 'RescuerID_COUNT'\n            train[rescuer_id_count_col_name] = train.groupby('RescuerID')[\n                'RescuerID'].transform(lambda s: s.count())\n            test[rescuer_id_count_col_name] = test.groupby('RescuerID')[\n                'RescuerID'].transform(lambda s: s.count())\n\n            if arch == ['xlearn']:  #, 'nn'\n                self.cat_cols.append(rescuer_id_count_col_name)\n            else:\n                self.numeric_cols.append(rescuer_id_count_col_name)\n\n            if cutoff_count > 0:\n                train.loc[train[rescuer_id_count_col_name] >= cutoff_count, rescuer_id_count_col_name] = cutoff_count\n                test.loc[test[rescuer_id_count_col_name] >= cutoff_count, rescuer_id_count_col_name] = cutoff_count\n\n            # \"is_first_time\" feature\n            use_is_first_time = False  # TODO: check\n            if use_is_first_time:\n                train['is_first_time'] = (train[rescuer_id_count_col_name] == 1).astype(np.float32)\n                test['is_first_time'] = (test[rescuer_id_count_col_name] == 1).astype(np.float32)\n                if arch == 'xlearn':\n                    self.cat_cols.append('is_first_time')\n                else:\n                    self.numeric_cols.append('is_first_time')\n\n        if use_name_feature:\n            print('create name feature...')\n            # create name feature\n            # 1. no name or not\n            train['No_name'] = 0\n            train.loc[train['Name'] == 'none', 'No_name'] = 1\n            test['No_name'] = 0\n            test.loc[test['Name'] == 'none', 'No_name'] = 1\n\n            # 2. weired name or not\n            train['name_under2'] = train['Name'].apply(lambda x: len(str(x)) < 3).values.astype(np.float32)\n            test['name_under2'] = test['Name'].apply(lambda x: len(str(x)) < 3).values.astype(np.float32)\n\n            # 3. puppy, puppies, kitten, kitty, baby flag.\n            train['is_kitty'] = train['Name'].apply(lambda x: 'kitty' in str(x).lower()).values.astype(np.float32)\n            test['is_kitty'] = test['Name'].apply(lambda x: 'kitty' in str(x).lower()).values.astype(np.float32)\n\n            train['is_kitten'] = train['Name'].apply(lambda x: 'kitten' in str(x).lower()).values.astype(np.float32)\n            test['is_kitten'] = test['Name'].apply(lambda x: 'kitten' in str(x).lower()).values.astype(np.float32)\n\n            train['is_puppy'] = train['Name'].apply(lambda x: 'puppy' in str(x).lower()).values.astype(np.float32)\n            test['is_puppy'] = test['Name'].apply(lambda x: 'puppy' in str(x).lower()).values.astype(np.float32)\n\n            train['is_puppies'] = train['Name'].apply(lambda x: 'puppies' in str(x).lower()).values.astype(np.float32)\n            test['is_puppies'] = test['Name'].apply(lambda x: 'puppies' in str(x).lower()).values.astype(np.float32)\n\n            if arch in ['xlearn', 'nn']:\n                self.cat_cols.append('No_name')\n                self.cat_cols.append('name_under2')\n                self.cat_cols.append('is_kitty')\n                self.cat_cols.append('is_kitten')\n                self.cat_cols.append('is_puppy')\n                self.cat_cols.append('is_puppies')\n            else:\n                self.numeric_cols.append('No_name')\n                self.numeric_cols.append('name_under2')\n            # self.numeric_cols.append('is_kitty')\n            # self.numeric_cols.append('is_kitten')\n            # self.numeric_cols.append('is_puppy')\n            # self.numeric_cols.append('is_puppies')\n\n        # --- Breed preprocessing ---\n        # deal \"Unspecified\" and \"Unknown\" as same for 2nd breed\n        # --> seems 307 is for mixed type!! and 0 is for unspecified. we should treat different way!\n        breed2_preprocessing = False\n        if breed2_preprocessing:\n            print('breed2_preprocessing')\n            all_data.loc[all_data['Breed2'] == 0, 'Breed2'] = 307\n            train.loc[train['Breed2'] == 0, 'Breed2'] = 307\n            test.loc[test['Breed2'] == 0, 'Breed2'] = 307\n\n        breed12_preprocessing = True\n        if breed12_preprocessing:\n            print('breed12_preprocessing')\n            # # https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/77898\n            train['Breed1'] = np.where((train['Breed1'] == 0) & (train['Breed2'] != 0),\n                                       train['Breed2'], train['Breed1'])\n            train['Breed2'] = np.where((train['Breed1'] == train['Breed2']), 0, train['Breed2'])\n\n        use_is_mixed = False\n        if use_is_mixed:\n            # is_mixed = (all_data['Breed2'] != 0) & (all_data['Breed2'] != 307)\n            is_mixed = (all_data['Breed2'] != 307).astype(np.int32)\n            all_data['is_mixed'] = is_mixed\n            train['is_mixed'] = is_mixed[train_indices]\n            test['is_mixed'] = is_mixed[test_indices]\n            self.cat_cols.append('is_mixed')\n\n        if use_breed_feature:\n            train_breed_main = train[['Breed1']].merge(\n                breeds, how='left',\n                left_on='Breed1', right_on='BreedID',\n                suffixes=('', '_main_breed'))\n\n            train_breed_main = train_breed_main.iloc[:, 2:]\n            train_breed_main = train_breed_main.add_prefix('main_breed_')\n\n            train_breed_second = train[['Breed2']].merge(\n                breeds, how='left',\n                left_on='Breed2', right_on='BreedID',\n                suffixes=('', '_second_breed'))\n\n            train_breed_second = train_breed_second.iloc[:, 2:]\n            train_breed_second = train_breed_second.add_prefix('second_breed_')\n\n            train = pd.concat(\n                [train, train_breed_main, train_breed_second], axis=1, sort=False)\n\n            test_breed_main = test[['Breed1']].merge(\n                breeds, how='left',\n                left_on='Breed1', right_on='BreedID',\n                suffixes=('', '_main_breed'))\n\n            test_breed_main = test_breed_main.iloc[:, 2:]\n            test_breed_main = test_breed_main.add_prefix('main_breed_')\n\n            test_breed_second = test[['Breed2']].merge(\n                breeds, how='left',\n                left_on='Breed2', right_on='BreedID',\n                suffixes=('', '_second_breed'))\n\n            test_breed_second = test_breed_second.iloc[:, 2:]\n            test_breed_second = test_breed_second.add_prefix('second_breed_')\n\n            test = pd.concat(\n                [test, test_breed_main, test_breed_second], axis=1, sort=False)\n            print(train.shape, test.shape)\n\n            X = pd.concat([train, test], ignore_index=True, axis=0, sort=False)\n            X_temp = X.copy()\n            categorical_columns = ['main_breed_BreedName', 'second_breed_BreedName']\n            for i in categorical_columns:\n                X_temp.loc[:, i] = pd.factorize(X_temp.loc[:, i])[0]\n                # Becareful!! must assign `.values` otherwise index does not match and nan is inserted for test!!!\n                train.loc[:, i] = X_temp.loc[train_indices, i].values\n                test.loc[:, i] = X_temp.loc[test_indices, i].values\n            breed_feat_cols = [\n                'main_breed_Type',\n                'main_breed_BreedName',\n                'second_breed_Type',\n                'second_breed_BreedName']\n\n            # dtypes does not match due to nan existent... align to same dtypes.\n            for col in breed_feat_cols:\n                test[col] = test[col].astype(train[col].dtype)\n\n            if arch == 'xgb':\n                self.numeric_cols.extend(breed_feat_cols)\n            else:\n                self.cat_cols.extend(breed_feat_cols)\n            # print('breed_feat_cols', breed_feat_cols)\n            # print(train[breed_feat_cols].dtypes)\n            # print(test[breed_feat_cols].dtypes)\n\n            add_rating_json = True\n            if add_rating_json:\n                # --- rating.json ---\n                feat_df = calc_breed_rating_feat(breeds, thresh=60)\n                # How to fillna? mean is better?? try both way.\n                feat_df.fillna(-1, inplace=True)\n                # feat_df.fillna(feat_df.mean(), inplace=True)\n\n                train_breed_main = train[['Breed1']].merge(\n                    breeds, how='left',\n                    left_on='Breed1', right_on='BreedID',)\n                train_breed_main_feat = train_breed_main[['BreedName']].merge(\n                    feat_df, how='left',\n                    left_on='BreedName', right_index=True, )\n                train_breed_main_feat = train_breed_main_feat.iloc[:, 1:]\n                train_breed_main_feat = train_breed_main_feat.add_prefix('main_breed_feat_')\n\n                train_breed_second = train[['Breed2']].merge(\n                    breeds, how='left',\n                    left_on='Breed2', right_on='BreedID',)\n                train_breed_second_feat = train_breed_second[['BreedName']].merge(\n                    feat_df, how='left',\n                    left_on='BreedName', right_index=True, )\n                train_breed_second_feat = train_breed_second_feat.iloc[:, 1:]\n                train_breed_second_feat = train_breed_second_feat.add_prefix('second_breed_feat_')\n\n                test_breed_main = test[['Breed1']].merge(\n                    breeds, how='left',\n                    left_on='Breed1', right_on='BreedID',)\n                test_breed_main_feat = test_breed_main[['BreedName']].merge(\n                    feat_df, how='left',\n                    left_on='BreedName', right_index=True, )\n                test_breed_main_feat = test_breed_main_feat.iloc[:, 1:]\n                test_breed_main_feat = test_breed_main_feat.add_prefix('main_breed_feat_')\n\n                test_breed_second = test[['Breed2']].merge(\n                    breeds, how='left',\n                    left_on='Breed2', right_on='BreedID',)\n                test_breed_second_feat = test_breed_second[['BreedName']].merge(\n                    feat_df, how='left',\n                    left_on='BreedName', right_index=True, )\n                test_breed_second_feat = test_breed_second_feat.iloc[:, 1:]\n                test_breed_second_feat = test_breed_second_feat.add_prefix('second_breed_feat_')\n\n                train = pd.concat(\n                    [train, train_breed_main_feat, train_breed_second_feat], axis=1, sort=False)\n                test = pd.concat(\n                    [test, test_breed_main_feat, test_breed_second_feat], axis=1, sort=False)\n\n                breed_rating_feat_cols = list(train_breed_main_feat.columns.values)\n                self.numeric_cols.extend(breed_rating_feat_cols)\n\n        use_color_feat = False\n        if use_color_feat:\n            color_array = np.array([\n                [0, 0, 0],  # unspecified\n                [0, 0, 0],  # black\n                [165, 42, 42],  # brown\n                [255, 215, 0],  # golden\n                [255, 255, 0],  # yellow\n                [255, 248, 220],  # cream\n                [128, 128, 128],  # gray\n                [255, 255, 255],  # white\n            ], dtype=np.float32) / 255.\n            for tmp_df in [train, test]:\n                c1 = tmp_df['Color1'].values\n                c2 = tmp_df['Color2'].values\n                c3 = tmp_df['Color3'].values\n                num_color = (c1 > 0).astype(np.float32) + (c2 > 0).astype(np.float32) + (c3 > 0).astype(np.float32)\n                color = (color_array[c1] + color_array[c2] + color_array[c3]) / num_color[:, None]\n                tmp_df['color_r'] = color[:, 0]\n                tmp_df['color_g'] = color[:, 1]\n                tmp_df['color_b'] = color[:, 2]\n                tmp_df['num_color'] = num_color\n            self.numeric_cols.extend(['color_r', 'color_g', 'color_b', 'num_color'])\n            # self.numeric_cols.extend(['num_color'])\n\n        if cat2num:\n            breed_cutoff = -1  # Do not cutoff here, it will be cutoff later...\n        else:\n            if arch in ['xlearn', 'nn']:\n                breed_cutoff = 3  # TODO: check it was best value...\n            else:\n                breed_cutoff = 6  # TODO: check it was best value...\n        if breed_cutoff > 0:\n            # b1 = all_data['Breed1'].value_counts().values\n            breed_counts = pd.concat([all_data['Breed1'], all_data['Breed2']], axis=0).value_counts()\n            minor_breeds = breed_counts[breed_counts < breed_cutoff].index.values\n            # minor_breeds 178/201 for threshold 100.\n            # minor_breeds 123/201 for threshold 10.\n            # minor_breeds 101/201 for threshold 7.\n            # minor_breeds 80/201 for threshold 5.\n            print('minor_breeds {}/{}'.format(len(minor_breeds), len(breed_counts)))\n            # Assign new \"minor breed\" id=308 for minor breeds...\n            all_data['Breed1'] = all_data['Breed1'].apply(lambda s: 308 if s in minor_breeds else s)\n            all_data['Breed2'] = all_data['Breed2'].apply(lambda s: 308 if s in minor_breeds else s)\n\n        if use_target_encoding:\n            # Becareful, it makes info leak and only fits validation data but not in test data!!!\n            print('create target encoding feature...')\n            # 1. --- Breed target encoding ---\n            # breed1 = train.groupby('Breed1')['AdoptionSpeed']\n            # train['breed1_mean'] = breed1.transform(np.mean)\n            # train['breed1_median'] = breed1.transform(np.median)\n            breed1 = all_data.groupby('Breed1')['AdoptionSpeed']\n            all_data['breed1_mean'] = breed1.transform(np.mean)\n            # all_data['breed1_q1'] = breed1.transform(lambda x: np.quantile(x, 0.25))\n            breed2 = all_data.groupby('Breed2')['AdoptionSpeed']\n            all_data['breed2_mean'] = breed2.transform(np.mean)\n            # all_data['breed2_median'] = breed2.transform(np.median)\n\n            # 2. --- State target encoding ---\n            state = all_data.groupby('State')['AdoptionSpeed']\n            all_data['state_mean'] = state.transform(np.mean)\n\n            # Assign values into `train` and `test`...\n            for col in ['breed1_mean', 'breed2_mean', 'state_mean']:\n                train[col] = all_data[train_indices][col]\n                test[col] = all_data[test_indices][col]\n                self.numeric_cols.append(col)\n\n        if use_custom_boolean_feature:\n            # --- is_xxx flag ---\n            train['is_free'] = 0\n            train.loc[train['Fee'] == 0, 'is_free'] = 1\n            test['is_free'] = 0\n            test.loc[test['Fee'] == 0, 'is_free'] = 1\n\n            train['has_photo'] = 0\n            train.loc[train['PhotoAmt'] > 0, 'has_photo'] = 1\n            test['has_photo'] = 0\n            test.loc[test['PhotoAmt'] > 0, 'has_photo'] = 1\n\n            train['age_unknown'] = 0\n            train.loc[train['Age'] == 255, 'age_unknown'] = 1\n            test['age_unknown'] = 0\n            test.loc[test['Age'] == 255, 'age_unknown'] = 1\n            if arch == 'xgb':\n                self.numeric_cols.append('is_free')\n                self.numeric_cols.append('has_photo')\n                self.numeric_cols.append('age_unknown')\n            else:\n                self.cat_cols.append('is_free')\n                self.cat_cols.append('has_photo')\n                self.cat_cols.append('age_unknown')\n\n        # --- Cutoff ---\n        apply_cutoff = (arch not in ['xlearn'])  # 'nn',\n        if apply_cutoff:\n            # 'Age', max was 255.\n            # TODO: we may need to deal with \"255\" as special (I think this is \"unknown\")\n            # age_cutoff = 54  # TODO: hyperparameter tuning. This affects a lot!!!\n            # age_cutoff = 60  # TODO: hyperparameter tuning. This affects a lot!!!\n            # age_cutoff = 72  # TODO: hyperparameter tuning. This affects a lot!!!\n            age_cutoff = 84  # TODO: hyperparameter tuning. This affects a lot!!!\n            print('age_cutoff', age_cutoff)\n            train.loc[train['Age'] >= age_cutoff, 'Age'] = age_cutoff\n            test.loc[test['Age'] >= age_cutoff, 'Age'] = age_cutoff\n            # 'Quantity', max was 20, but most of them are ~10.\n            # quantity_cutoff = 11\n            quantity_cutoff = 15\n            train.loc[train['Quantity'] >= quantity_cutoff, 'Quantity'] = quantity_cutoff\n            test.loc[test['Quantity'] >= quantity_cutoff, 'Quantity'] = quantity_cutoff\n            # 'VideoAmt', max was 8, but most of them are ~1.\n            # video_amt_cutoff = 4\n            video_amt_cutoff = 5\n            train.loc[train['VideoAmt'] >= video_amt_cutoff, 'VideoAmt'] = video_amt_cutoff\n            test.loc[test['VideoAmt'] >= video_amt_cutoff, 'VideoAmt'] = video_amt_cutoff\n            # 'PhotoAmt', max was 30, but most of them are ~11.\n            # photo_amt_cutoff = 12\n            photo_amt_cutoff = 15\n            train.loc[train['PhotoAmt'] >= photo_amt_cutoff, 'PhotoAmt'] = photo_amt_cutoff\n            test.loc[test['PhotoAmt'] >= photo_amt_cutoff, 'PhotoAmt'] = photo_amt_cutoff\n            # 'Fee', max was 3000, but most of them are ~300 or ~500\n            # 300 or 500\n            fee_cutoff = 500\n            train.loc[train['Fee'] >= fee_cutoff, 'Fee'] = fee_cutoff\n            test.loc[test['Fee'] >= fee_cutoff, 'Fee'] = fee_cutoff\n\n        if arch == 'nn':\n            # Neural Network preprocessing...\n            # --- Numeric value processing ---\n            print('numeric value preprocessing...')\n            # There is no nan value, but this is just for make sure no nan exist.\n            scale_cols = deepcopy(self.numeric_cols)\n\n        if use_sentiment:\n            print('create sentiment feature...')\n            n_jobs = 16\n            s = perf_counter()\n            # Multiprocessing: around 2 sec. Multithreading: 10 sec. Singlethreading 63 sec.\n            # train_x_sent = Parallel(n_jobs, backend='threading')(\n            #     delayed(process_sentiment, check_pickle=False)\n            #     (petid, 'train') for petid in train['PetID'].values)\n            train_x_sent = Parallel(n_jobs)(\n                delayed(process_sentiment)\n                (petid, 'train', num_sentiment_text) for petid in train['PetID'].values)\n            test_x_sent = Parallel(n_jobs)(\n                delayed(process_sentiment)\n                (petid, 'test', num_sentiment_text) for petid in test['PetID'].values)\n            e = perf_counter()\n            print('sentiment {} sec, n_jobs {}'.format(e - s, n_jobs))\n            train_x_sent = np.array(train_x_sent, dtype=np.float32)\n            test_x_sent = np.array(test_x_sent, dtype=np.float32)\n            print('train_x_sent {}'\n                  .format(train_x_sent.shape))\n            # TODO: update feature engineering and its name...\n            sentiment_cols = ['sent01', 'sent02']\n            train_sentiment_df = pd.DataFrame(train_x_sent, columns=sentiment_cols)\n            test_sentiment_df = pd.DataFrame(test_x_sent, columns=sentiment_cols)\n            train = pd.concat([train, train_sentiment_df], axis=1)\n            test = pd.concat([test, test_sentiment_df], axis=1)\n            self.numeric_cols.extend(sentiment_cols)\n\n        if use_metadata:\n            print('create metadata feature...')\n            n_jobs = 16\n            s = perf_counter()\n            train_x_metadata = Parallel(n_jobs)(\n                delayed(process_metadata)\n                (petid, 'train') for petid in train['PetID'].values)\n            test_x_metadata = Parallel(n_jobs)(\n                delayed(process_metadata)\n                (petid, 'test') for petid in test['PetID'].values)\n            e = perf_counter()\n            print('metadata {} sec, n_jobs {}'.format(e-s, n_jobs))\n            train_x_metadata = np.array(train_x_metadata, dtype=np.float32)\n            test_x_metadata = np.array(test_x_metadata, dtype=np.float32)\n            metadata_cols = [\n                'meta_vertex_x', 'meta_vertex_y', 'meta_bounding_confidence', 'meta_bounding_importance_frac',\n                'meta_dominant_blue', 'meta_dominant_green', 'meta_dominant_red',\n                'meta_dominant_pixel_frac', 'meta_dominant_score', 'meta_label_score']\n            train_meta_df = pd.DataFrame(train_x_metadata, columns=metadata_cols)\n            test_meta_df = pd.DataFrame(test_x_metadata, columns=metadata_cols)\n            train = pd.concat([train, train_meta_df], axis=1, sort=False)\n            test = pd.concat([test, test_meta_df], axis=1, sort=False)\n            self.numeric_cols.extend(metadata_cols)\n\n        # --- feature engineering in https://www.kaggle.com/wrosinski/baselinemodeling ---\n        if use_sentiment2 or use_metadata2 or use_text:\n            smp = SentimentMetadataPreprocessor()\n            smp.preprocess_sentiment_and_metadata(train, test)\n            # It is necessary to fillna after df merged, because some PetID is missing.\n            # if arch == 'nn':\n            #     # nan handling...\n            #     smp.train_sentiment_gr.fillna(0., inplace=True)\n            #     smp.train_metadata_gr.fillna(0., inplace=True)\n            #     smp.test_sentiment_gr.fillna(0., inplace=True)\n            #     smp.test_metadata_gr.fillna(0., inplace=True)\n            train = train.merge(\n                smp.train_sentiment_gr, how='left', on='PetID')\n            train = train.merge(\n                smp.train_metadata_gr, how='left', on='PetID')\n            train = train.merge(\n                smp.train_metadata_desc, how='left', on='PetID')\n            train = train.merge(\n                smp.train_sentiment_desc, how='left', on='PetID')\n            test = test.merge(\n                smp.test_sentiment_gr, how='left', on='PetID')\n            test = test.merge(\n                smp.test_metadata_gr, how='left', on='PetID')\n            test = test.merge(\n                smp.test_metadata_desc, how='left', on='PetID')\n            test = test.merge(\n                smp.test_sentiment_desc, how='left', on='PetID')\n            if use_sentiment2:\n                sentiment2_cols = list(smp.train_sentiment_gr.columns.values)\n                sentiment2_cols.remove('PetID')\n                if arch == 'nn':\n                    # nan handling...\n                    for col in sentiment2_cols:\n                        train[col].fillna(-1., inplace=True)\n                        test[col].fillna(-1., inplace=True)\n                self.numeric_cols.extend(sentiment2_cols)\n            if use_metadata2:\n                metadata2_cols = list(smp.train_metadata_gr.columns.values)\n                metadata2_cols.remove('PetID')\n                if arch == 'nn':\n                    # nan handling...\n                    for col in metadata2_cols:\n                        train[col].fillna(-1., inplace=True)\n                        test[col].fillna(-1., inplace=True)\n                self.numeric_cols.extend(metadata2_cols)\n\n            if use_text:\n                text_columns = ['Description', 'metadata_annots_top_desc', 'sentiment_entities']\n                from sklearn.feature_extraction.text import TfidfVectorizer\n                from sklearn.decomposition import SparsePCA, TruncatedSVD, LatentDirichletAllocation, NMF\n\n                # n_components = 5  # version 1\n                # text_methods = ['svd', 'nmf']  # version 1\n\n                # n_components = 16  # version 2\n                # text_methods = ['svd']  # version 2\n\n                n_components_list = [16, 8, 8]  # version 3 (self-customized)\n                text_methods = ['svd']  # version 2\n\n                text_features = []\n                # Generate text features:\n                for i, n_components in zip(text_columns, n_components_list):\n                    # Initialize decomposition methods:\n                    print('generating features from: {}'.format(i))\n                    # train.loc[:, i].fillna('<MISSING>', inplace=True)\n                    # test.loc[:, i].fillna('<MISSING>', inplace=True)\n                    train.loc[:, i].fillna('none', inplace=True)\n                    test.loc[:, i].fillna('none', inplace=True)\n                    x_text = np.concatenate([\n                        train.loc[:, i].values, test.loc[:, i].values], axis=0)\n\n                    # tfv = TfidfVectorizer()\n                    tfv = TfidfVectorizer(min_df=2, max_features=None,\n                                          strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n                                          ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1)\n                    # tfidf_col = TfidfVectorizer().fit_transform(X_text.loc[:, i].values)\n                    tfidf_col = tfv.fit_transform(x_text)\n                    if 'svd' in text_methods and n_components > 0:\n                        svd_ = TruncatedSVD(\n                            n_components=n_components, random_state=1337)\n                        svd_col = svd_.fit_transform(tfidf_col)\n                        svd_col = pd.DataFrame(svd_col)\n                        svd_col = svd_col.add_prefix('SVD_{}_'.format(i))\n                        text_features.append(svd_col)\n\n                    if 'nmf' in text_methods and n_components > 0:\n                        nmf_ = NMF(\n                            n_components=n_components, random_state=1337)\n                        nmf_col = nmf_.fit_transform(tfidf_col)\n                        nmf_col = pd.DataFrame(nmf_col)\n                        nmf_col = nmf_col.add_prefix('NMF_{}_'.format(i))\n                        text_features.append(nmf_col)\n\n                    add_length_feat = True  # added version 2\n                    if add_length_feat:\n                        length_col = 'Length_{}'.format(i)\n                        if arch == 'nn':\n                            scale_cols.append(length_col)\n\n                        length_df = pd.DataFrame({length_col: [len(elem) for elem in x_text]})\n                        text_features.append(length_df)\n\n                # Combine all extracted features:\n                text_features_df = pd.concat(text_features, axis=1, sort=False)\n                print('text_features', type(text_features_df), text_features_df.shape)\n                # Concatenate with main DF:\n                train_text_df = text_features_df.iloc[:len(train)].reset_index(drop=True)\n                test_text_df = text_features_df.iloc[len(train):].reset_index(drop=True)\n                train = pd.concat([train, train_text_df], axis=1, sort=False)\n                test = pd.concat([test, test_text_df], axis=1, sort=False)\n\n                text_feat_cols = list(text_features_df.columns.values)\n                self.numeric_cols.extend(text_feat_cols)\n\n        if use_fasttext:\n            if embedding_type_list is None:\n                embedding_type_list = ['glove200d']\n                # embedding_type_list = ['fasttext', 'glove200d']\n        else:\n            embedding_type_list = []\n\n        for embedding_type in embedding_type_list:\n            use_fasttext_cache = True\n            # embedding_type = 'fasttext'  # 'fasttext'\n            if embedding_type == 'glove50d':\n                npz_filepath = './cache/glove-50d-6B.npz'\n            elif embedding_type == 'glove200d':\n                npz_filepath = './cache/glove-200d-6B.npz'\n            elif embedding_type == 'fasttext':\n                npz_filepath = './cache/crawl-300d-2M.npz'\n            else:\n                raise ValueError(\"[ERROR] Unexpected value embedding_type={}\".format(embedding_type))\n\n            t0 = perf_counter()\n            if use_fasttext_cache and os.path.exists(npz_filepath):\n                a = np.load(npz_filepath)\n                vec_array = a['vec_array']\n                vocab_list = list(a['vocab_list'])\n            else:\n                if embedding_type == 'glove50d':\n                    filepath = f'{glove_dir}/glove.6B.50d.txt'\n                    vocab_list, vec_array = construct_glove_vocab_list(filepath, hdim=50)\n                elif embedding_type == 'glove200d':\n                    filepath = f'{glove_dir}/glove.6B.200d.txt'\n                    vocab_list, vec_array = construct_glove_vocab_list(filepath, hdim=200)\n                else:\n                    filepath = f'{glove_dir}/crawl-300d-2M.vec'\n                    vocab_list, vec_array = construct_fasttext_vocab_list(filepath)\n                os.makedirs(os.path.dirname(npz_filepath), exist_ok=True)\n                np.savez_compressed(npz_filepath, vocab_list=vocab_list, vec_array=vec_array)\n\n            t1 = perf_counter()\n            print('fasttext construct_fasttext_vocab_list took {:.3} sec'.format(t1-t0))\n            # out_dim_list = [64, 16]\n            # fasttext_columns = ['metadata_annots_top_desc', 'sentiment_entities']  # 'Description'\n            # out_dim_list = [64, 16, 16]\n            # fasttext_columns = ['metadata_annots_top_desc', 'sentiment_entities', 'Description']  # 'Description'\n            out_dim_list = [64]\n            fasttext_columns = ['metadata_annots_top_desc']  # 'Description'\n            # fasttext_columns = ['metadata_annots_top_desc', 'sentiment_entities', 'Description']  # 'Description'\n            for i, out_dim in zip(fasttext_columns, out_dim_list):\n                # Initialize decomposition methods:\n                print('generating fasttext features from: {}'.format(i))\n                train.loc[:, i].fillna('none', inplace=True)\n                test.loc[:, i].fillna('none', inplace=True)\n                x_fasttext = np.concatenate([\n                    train.loc[:, i].values, test.loc[:, i].values], axis=0)\n                t0 = perf_counter()\n                h_fasttext = calc_fasttext_feature(\n                    x_fasttext, vocab_list, vec_array,\n                    out_dim=out_dim, col_name=i, method='tfidf', source=embedding_type)\n                t1 = perf_counter()\n                print('h_fasttext', h_fasttext.shape)\n                print('fasttext calc_fasttext_feature for {} took {:.3} sec'.format(i, t1 - t0))\n                fasttext_df = pd.DataFrame(h_fasttext)\n                fasttext_df = fasttext_df.add_prefix(f'{embedding_type}_{i}_')\n\n                # Concatenate with main DF:\n                train_fasttext_df = fasttext_df.iloc[:len(train)].reset_index(drop=True)\n                test_fasttext_df = fasttext_df.iloc[len(train):].reset_index(drop=True)\n                train = pd.concat([train, train_fasttext_df], axis=1, sort=False)\n                test = pd.concat([test, test_fasttext_df], axis=1, sort=False)\n\n                fasttext_feat_cols = list(fasttext_df.columns.values)\n                self.numeric_cols.extend(fasttext_feat_cols)\n\n        os.makedirs('./cache', exist_ok=True)\n        if use_tfidf:\n            if animal_type is not None:\n                cache_filepath = './cache/x_tfidf_svd{}_debug{}_animaltype{}.npz'.format(\n                    tfidf_svd_components, int(debug), animal_type)\n            else:\n                cache_filepath = './cache/x_tfidf_svd{}_debug{}.npz'.format(\n                    tfidf_svd_components, int(debug))\n            if use_tfidf_cache and os.path.exists(cache_filepath):\n                print('load from {}'.format(cache_filepath))\n                train_x_tfidf_svd, test_x_tfidf_svd = load_npz(cache_filepath)\n            else:\n                print('create tfidf feature...')\n                train_x_tfidf_svd, test_x_tfidf_svd = add_tfidf(train, test, tfidf_svd_components=tfidf_svd_components)\n                save_npz(cache_filepath, (train_x_tfidf_svd, test_x_tfidf_svd))\n                print('saved to {}'.format(cache_filepath))\n\n            tfidf_cols = ['tfidf_{:04}'.format(i) for i in range(tfidf_svd_components)]\n            train_tfidf_df = pd.DataFrame(train_x_tfidf_svd, columns=tfidf_cols)\n            test_tfidf_df = pd.DataFrame(test_x_tfidf_svd, columns=tfidf_cols)\n            train = pd.concat([train, train_tfidf_df], axis=1, sort=False)\n            test = pd.concat([test, test_tfidf_df], axis=1, sort=False)\n            self.numeric_cols.extend(tfidf_cols)\n\n        if use_image_size:\n            cache_filepath_train = './cache/x_image_size_debug{}_train.feather'.format(int(debug))\n            cache_filepath_test = './cache/x_image_size_debug{}_test.feather'.format(int(debug))\n            if os.path.exists(cache_filepath_train) and os.path.exists(cache_filepath_test):\n                agg_train_imgs = read_feather(cache_filepath_train)\n                agg_test_imgs = read_feather(cache_filepath_test)\n            else:\n                agg_train_imgs, agg_test_imgs = parse_image_size()\n                agg_train_imgs.to_feather(cache_filepath_train)\n                agg_test_imgs.to_feather(cache_filepath_test)\n            train = train.merge(\n                agg_train_imgs, how='left', on='PetID')\n            test = test.merge(\n                agg_test_imgs, how='left', on='PetID')\n            image_size_cols = list(agg_train_imgs.columns)\n            image_size_cols.remove('PetID')\n            for col in image_size_cols:\n                assert col in agg_test_imgs.columns\n                if arch == 'nn':\n                    # nan handling...\n                    train[col].fillna(0., inplace=True)\n                    test[col].fillna(0., inplace=True)\n            self.numeric_cols.extend(image_size_cols)\n            if arch == 'nn':\n                scale_cols.extend(image_size_cols)\n\n        if add_pred is not None:\n            # add_pred = ['xlearn', 'nn', 'xgb']\n            for model_name in add_pred:\n                print(f'Adding {model_name} model pred...')\n                filepath = 'predict_{}_train.csv'.format(model_name)\n                df_train_pred = pd.read_csv(filepath)\n                train = train.merge(\n                    df_train_pred, how='left', on='PetID')\n                filepath = 'predict_{}_test.csv'.format(model_name)\n                df_test_pred = pd.read_csv(filepath)\n                test = test.merge(\n                    df_test_pred, how='left', on='PetID')\n                train.rename({'y': f'y_{model_name}'}, axis=1, inplace=True)\n                test.rename({'y': f'y_{model_name}'}, axis=1, inplace=True)\n                self.numeric_cols.append(f'y_{model_name}')\n\n        if arch == 'nn':\n            # Neural Network preprocessing...\n            # --- Numeric value processing ---\n            print('numeric value preprocessing...')\n            # There is no nan value, but this is just for make sure no nan exist.\n            print('scale_cols', scale_cols)\n            train_x_numeric = train[scale_cols].fillna(0).values.astype(np.float32)\n            test_x_numeric = test[scale_cols].fillna(0).values.astype(np.float32)\n\n            # --- MinMax scaling ---\n            xmax = np.max(train_x_numeric, axis=0)\n            xmin = np.min(train_x_numeric, axis=0)\n            print('xmax', xmax)\n            print('xmin', xmin)\n            inds = xmax != xmin  # Non-zero indices\n            train_x_numeric[:, inds] = (train_x_numeric[:, inds] - xmin[inds]) / (xmax[inds] - xmin[inds])\n            test_x_numeric[:, inds] = (test_x_numeric[:, inds] - xmin[inds]) / (xmax[inds] - xmin[inds])\n            train.loc[:, scale_cols] = train_x_numeric\n            test.loc[:, scale_cols] = test_x_numeric\n\n        add_lang = True\n        if add_lang:\n            train_lang_df, test_lang_df = process_lang_df(train, test)\n            all_data['lang'] = np.concatenate([\n                train_lang_df['lang'].values, test_lang_df['lang'].values], axis=0)\n\n        # --- Category value processing ---\n        if cat2num:\n            # TODO: numeric cols append for lgbm, cat_cols override for nn...\n            # convert category value to one-hot vector or other values.\n            # cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n            #             'Vaccinated', 'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health']\n            # all_cat = all_data[cat_cols].astype('category')\n            # all_cat_id = all_cat.apply(lambda x: x.cat.codes)\n\n            # --- 1. category to one-hot vector ---\n            # checked include State or not --> include State seems better.\n            one_hot_cols = ['Type', 'Gender', 'Vaccinated',\n                            'Dewormed', 'Sterilized', 'State', 'FurLength', 'Health']\n            if add_lang:\n                one_hot_cols.append('lang')\n            one_hot_list = [pd.get_dummies(all_data[col]).values for col in one_hot_cols]\n            one_hot_array = np.concatenate(one_hot_list, axis=1).astype(np.float32)\n            self.remove_cols(one_hot_cols)\n\n            # --- 2. breed ---\n            # deal \"Unspecified\" and \"Unknown\" as same for 2nd breed\n            # all_data['Breed2'][all_data['Breed2'] == 0] = 307\n            # all_data.loc[all_data['Breed2'] == 0, 'Breed2'] = 307\n            # is_mixed = (all_data['Breed2'] != 0) & (all_data['Breed2'] != 307)\n            is_mixed = (all_data['Breed2'] != 0).astype(np.float32)[:, None]\n            b1 = all_data['Breed1'].value_counts()\n            major_breeds = b1[b1 >= 100].index.values  # 18 species remain\n            # major_breeds = b1[b1 >= 1000].index.values  # 3 species remain\n            print('major_breeds', major_breeds)\n\n            def breed_onehot(x):\n                if x not in major_breeds:\n                    # rare breed\n                    return len(major_breeds)\n                else:\n                    # major (non-rare) breed\n                    breed_id = np.argwhere(x == major_breeds)[0, 0]\n                    # return x\n                    return breed_id\n\n            b1r = all_data['Breed1'].apply(breed_onehot)\n            b2r = all_data['Breed2'].apply(breed_onehot)\n            breed_ones = np.eye(len(major_breeds) + 1, dtype=np.float32)\n            # breed_array = (1.0 * breed_ones[b1r] + 0.7 * breed_ones[b2r]).astype(np.float32)\n            breed_array = (1.0 * breed_ones[b1r] + 1.0 * breed_ones[b2r]).astype(np.float32)\n            # self.remove_cols(['Breed1', 'Breed2'])\n\n            # --- 3. color ---\n            # 0 unspecified, 1 black, ... , 7 white.\n            color_ones = np.eye(8)\n            color1_onehot = color_ones[all_data['Color1'].values]\n            color2_onehot = color_ones[all_data['Color2'].values]\n            color3_onehot = color_ones[all_data['Color3'].values]\n            # color_array = (1.0 * color1_onehot + 0.7 * color2_onehot + 0.5 * color3_onehot).astype(np.float32)\n            color_array = (1.0 * color1_onehot + 1.0 * color2_onehot + 1.0 * color3_onehot).astype(np.float32)\n            # self.remove_cols(['Color1', 'Color2', 'Color3'])\n\n            x_cat2num_array = np.concatenate([one_hot_array, is_mixed, breed_array, color_array], axis=1)\n            one_hot_cols = ['one_hot_{:04}'.format(i) for i in range(one_hot_array.shape[1])]\n            is_mixed_cols = ['is_mixed_{:04}'.format(i) for i in range(is_mixed.shape[1])]\n            breed_cols = ['breed_{:04}'.format(i) for i in range(breed_array.shape[1])]\n            color_cols = ['color_{:04}'.format(i) for i in range(color_array.shape[1])]\n\n            cat2num_cols = one_hot_cols + is_mixed_cols + breed_cols + color_cols\n            train_cat2num_df = pd.DataFrame(x_cat2num_array[train_indices], columns=cat2num_cols)\n            test_cat2num_df = pd.DataFrame(x_cat2num_array[test_indices], columns=cat2num_cols)\n            train = pd.concat([train, train_cat2num_df], axis=1)\n            test = pd.concat([test, test_cat2num_df], axis=1)\n            if arch == 'nn':\n                self.cat_cols = cat2num_cols\n            else:\n                self.numeric_cols.extend(cat2num_cols)\n                # self.numeric_cols.extend(breed_cols + is_mixed_cols)\n            print('one_hot_array', one_hot_array.shape,\n                  'is_mixed', is_mixed.shape,\n                  'breed_array', breed_array.shape,\n                  'color_array', color_array.shape,\n                  'x_cat2num_array', x_cat2num_array.shape, x_cat2num_array.dtype)\n            self.num_cat_id = -1\n        else:\n            if add_lang:\n                categorical_cols.append('lang')\n                train['lang'] = 0\n                test['lang'] = 0\n                self.cat_cols.append('lang')\n            if len(categorical_cols) > 0:\n                all_cat = all_data[categorical_cols].astype('category')\n                all_cat_id = all_cat.apply(lambda x: x.cat.codes)\n                all_x_cat = all_cat_id.values.astype(np.int32)\n                # all_cat_id[['Breed1', 'Breed2']].groupby(['Breed1', 'Breed2']).size()\n\n                train_x_cat = all_x_cat[train_indices]\n                test_x_cat = all_x_cat[test_indices]\n                train.loc[:, categorical_cols] = train_x_cat\n                test.loc[:, categorical_cols] = test_x_cat\n                num_cat_id = np.max(all_x_cat, axis=0) + 1\n                print('train_x_cat', train_x_cat.shape, 'test_x_cat', test_x_cat.shape, 'num_cat_id', num_cat_id)\n                print('cat dtypes: ', train.loc[:, categorical_cols].dtypes)\n                self.num_cat_id = num_cat_id\n\n        if arch == 'xlearn':\n            # for col in [self.cat_cols + self.numeric_cols]:\n            for col in self.cat_cols:\n                train.loc[:, col] = train.loc[:, col].values.astype(np.int64)\n                test.loc[:, col] = test.loc[:, col].values.astype(np.int64)\n        elif arch == 'nn':\n            # for col in [self.cat_cols + self.numeric_cols]:\n            for col in self.cat_cols:\n                train.loc[:, col] = train.loc[:, col].values.astype(np.int32)\n                test.loc[:, col] = test.loc[:, col].values.astype(np.int32)\n        return train, test\n        # return train_x_numeric, train_x_cat, target, test_x_numeric, test_x_cat, num_cat_id\n\n    def preprocess_bert(self, train, test, num_extract_sentence=1, layer_indices=[-1, ], device=-1,\n                        use_cache=True, animal_type=None):\n        train_x_bert, test_x_bert = preprocess_bert(\n            train, test, num_extract_sentence=num_extract_sentence, layer_indices=layer_indices, device=device,\n            use_cache=use_cache, animal_type=animal_type)\n        bs, num_sentence, hdim = train_x_bert.shape\n        bs_test, num_sentence, hdim = test_x_bert.shape\n        train_x_bert = np.reshape(train_x_bert, (bs, num_sentence * hdim))\n        test_x_bert = np.reshape(test_x_bert, (bs, num_sentence * hdim))\n        bert_cols = ['bert_{:05}'.format(i) for i in range(train_x_bert.shape[1])]\n        train_bert_df = pd.DataFrame(train_x_bert, columns=bert_cols)\n        test_bert_df = pd.DataFrame(test_x_bert, columns=bert_cols)\n        train = pd.concat([train, train_bert_df], axis=1, sort=False)\n        test = pd.concat([test, test_bert_df], axis=1, sort=False)\n        self.numeric_cols.extend(bert_cols)\n        return train, test\n\n    def preprocess_image_cosine(self, train, test, train_type, test_type, arch='densenet'):\n        # --- debug ---\n        assert arch == 'densenet'\n        train_x_image_full, test_x_image_full = preprocess_image_densenet(\n            train, test, n_components=None)\n        x_cute_image_array = preprocess_image_cute(device=0, arch=arch, batch_size=32, debug=False)\n        d = CuteImageDataset(debug=False)\n        labels_df = d.labels_df\n        all_x_image_full = np.concatenate([train_x_image_full, test_x_image_full], axis=0)\n        all_type = np.concatenate([train_type, test_type], axis=0)\n        all_x_disthists = process_cosine_distance(\n            all_x_image_full, all_type, x_cute_image_array, labels_df)\n        train_x_disthists = all_x_disthists[:len(train)]\n        test_x_disthists = all_x_disthists[len(train):]\n        assert len(test_x_disthists) == len(test)\n        # add numerical features and assign values to df...\n        disthist_cols = ['image_disthist_{:05}'.format(i) for i in range(test_x_disthists.shape[1])]\n        train_disthist_df = pd.DataFrame(train_x_disthists, columns=disthist_cols)\n        test_disthist_df = pd.DataFrame(test_x_disthists, columns=disthist_cols)\n        train = pd.concat([train, train_disthist_df], axis=1, sort=False)\n        test = pd.concat([test, test_disthist_df], axis=1, sort=False)\n        self.numeric_cols.extend(disthist_cols)\n        return train, test\n        # train_x_dists = process_cosine_distance(\n        #     train_x_image_full, train_type, x_cute_image_array, labels_df)\n        # test_x_dists = process_cosine_distance(\n        #     test_x_image_full, test_type, x_cute_image_array, labels_df)\n\n    def preprocess_image(self, train, test, num_image=2, device=-1, arch='vgg16',\n                         n_components=None, use_cache=True, animal_type=None, method='pooling'):\n        if arch == 'densenet':\n            train_x_image, test_x_image = preprocess_image_densenet(\n                train, test, n_components=n_components, method=method)\n        else:\n            train_x_image, test_x_image = preprocess_image(\n                train, test, num_image=num_image, device=device, arch=arch,\n                n_components=n_components, animal_type=animal_type, use_cache=use_cache,\n                method=method)\n        bs, num_image, hdim = train_x_image.shape\n        bs_test, num_image, hdim = test_x_image.shape\n        train_x_image = np.reshape(train_x_image, (bs, num_image * hdim))\n        test_x_image = np.reshape(test_x_image, (bs_test, num_image * hdim))\n        image_cols = ['image_{}_{:05}'.format(arch, i) for i in range(train_x_image.shape[1])]\n        train_image_df = pd.DataFrame(train_x_image, columns=image_cols)\n        test_image_df = pd.DataFrame(test_x_image, columns=image_cols)\n        train = pd.concat([train, train_image_df], axis=1, sort=False)\n        test = pd.concat([test, test_image_df], axis=1, sort=False)\n        self.numeric_cols.extend(image_cols)\n        return train, test\n\n    def preprocess_image_det(self, train, test, num_image=1,\n                             device=-1, arch='faster_rcnn_vgg16', use_cache=True,\n                             n_components=None, animal_type=None):\n\n        train_x_image, test_x_image = preprocess_image_det(\n            train, test, num_image=num_image,\n            device=device, arch=arch, use_cache=use_cache,\n            n_components=n_components, animal_type=animal_type)\n        bs, num_image, hdim = train_x_image.shape\n        bs_test, num_image, hdim = test_x_image.shape\n\n        method = 'animal_mean'\n        if num_image > 1 and method == 'animal_mean':\n            print('num_image', num_image)\n            def calc_valid_mean(x_image):\n                x_exist_animal = x_image[:, :, 1] > 0\n                num_valid_images = np.sum(x_exist_animal, axis=1)\n                x_image_mean = np.sum(np.where(x_exist_animal[:, :, None], x_image, 0), axis=1) / num_valid_images[:, None]\n                return x_image_mean\n            train_x_image = calc_valid_mean(train_x_image)\n            test_x_image = calc_valid_mean(test_x_image)\n            print('calc animal_mean done.', train_x_image.shape, test_x_image.shape)\n        else:\n            train_x_image = np.reshape(train_x_image, (bs, num_image * hdim))\n            test_x_image = np.reshape(test_x_image, (bs_test, num_image * hdim))\n\n        # # --- Try contraction by pearsonr ---  # this makes information leak only for checking maximum performance.\n        # pearson_list = [pearson_corr(train_x_image[:, i], train.AdoptionSpeed.values)\n        #                 for i in range(train_x_image.shape[1])]\n        # pearson_arr = np.array(pearson_list)\n        # inds = np.argsort(np.abs(pearson_arr))[::-1]\n        # print('pearson_arr', pearson_arr[inds[:n_components]])\n        # train_x_image = train_x_image[:, inds[:n_components]]\n        # test_x_image = test_x_image[:, inds[:n_components]]\n\n        image_cols = ['image_{:05}'.format(i) for i in range(train_x_image.shape[1])]\n        train_image_df = pd.DataFrame(train_x_image, columns=image_cols)\n        test_image_df = pd.DataFrame(test_x_image, columns=image_cols)\n        train = pd.concat([train, train_image_df], axis=1, sort=False)\n        test = pd.concat([test, test_image_df], axis=1, sort=False)\n        self.numeric_cols.extend(image_cols)\n        return train, test\n\n\ndef pearson_corr(x, y):\n    x_diff = x - np.mean(x)\n    y_diff = y - np.mean(y)\n    denom = (np.sqrt(np.sum(x_diff ** 2)) * np.sqrt(np.sum(y_diff ** 2)))\n    if denom < 1e-8:\n        return 0\n    else:\n        return np.dot(x_diff, y_diff) / denom\n\n","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"271d75724e432261e38e76d563f3d418ae3fb087","_kg_hide-input":false},"cell_type":"code","source":"# --- pet image dataset ---","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88f573395f0ed6d2d19eab3f2d0cc0cd29e0db7a","_kg_hide-input":false},"cell_type":"code","source":"import os\n\nimport chainer\n\nclass PetImageDataset(chainer.dataset.DatasetMixin):\n    def __init__(self, petids, data_type, num_image=1, mode='chainercv'):\n        self.petids = petids\n        self.data_type = data_type\n        self.num_image = num_image\n        self.mode = mode\n\n    def __len__(self):\n        \"\"\"return length of this dataset\"\"\"\n        return len(self.petids) * self.num_image\n\n    def get_example(self, i):\n        \"\"\"Return i-th data\"\"\"\n        pet_index, image_index = divmod(i, self.num_image)\n        filepath = '{}/{}_images/{}-{}.jpg'.format(\n            pet_dir, self.data_type, self.petids[pet_index], image_index+1)\n        if os.path.exists(filepath):\n            if self.mode == 'chainercv':\n                image = read_image(filepath)\n            elif self.mode == 'keras':\n                image = read_image_keras(filepath)\n            else:\n                raise ValueError(\"[ERROR] Unexpected value mode={}\".format(self.mode))\n            # print('image', type(image), image.dtype, image.shape)\n            return image\n        else:\n            # print('[DEBUG] {} not exist'.format(filepath))\n            return None","execution_count":57,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Start script code\n\nIt is already very long... But above is the \"library code\" scripts.\n\nLet's start actual calculation with some scripts from here!"},{"metadata":{"_uuid":"c093f106a85cb660bffc4dba53f3a4049640dc96"},"cell_type":"markdown","source":"### Densenet image feature extraction...\n\nAt first, calculate image feature and save it with DataFrame using feather.\n\nThe saved files (extracted image feature) are loaded every time I train different models."},{"metadata":{"trusted":true,"_uuid":"69fb08326586631f730533c97cb27c9f42dfafaf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b32a79faace6e27bef3c45131353899a4f7fdda"},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nimport keras.backend as K\n\nimg_size = 256\nbatch_size = 256\n\nimport tensorflow as tf\n#tf_device_str = \"/gpu:0\"  # It seems we face cudnn error with the latest version of docker image... It was fine during competition.\ntf_device_str = \"/cpu:0\"  # it works but very slow...\nwith tf.device(tf_device_str):\n    m = prepare_model_densenet()","execution_count":64,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"957e2282c59c900f7b2fc2b1a78675c451aa8564"},"cell_type":"code","source":"import os\nimport numpy as np\nfrom itertools import chain\n\nimport chainer\nfrom chainer import cuda\nfrom chainer.iterators import MultiprocessIterator, MultithreadIterator\n\nfrom joblib import delayed, Parallel\n\nimport sys\nimport os\n\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom tqdm import tqdm\n\n\ndef calc_x_image_array(petids, data_type, num_image, batch_size):\n    image_dataset = PetImageDataset(petids, data_type, num_image, mode='keras')\n    # iterator = MultiprocessIterator(\n    #     image_dataset, batch_size, repeat=False, shuffle=False)\n    iterator = MultithreadIterator(\n        image_dataset, batch_size, repeat=False, shuffle=False)\n    x_image_array = None\n    current_index = 0\n    for batch in tqdm(iterator, total=len(image_dataset) // batch_size):\n        has_image_indices = np.argwhere(np.array([elem is not None for elem in batch]))[:, 0]\n        image_list = [elem for elem in batch if elem is not None]\n        #feats = model.predict(image_list)[0]\n        feats = model.predict(np.array(image_list))\n        if x_image_array is None:\n            feat_dim = feats.shape[1]\n            x_image_array = np.zeros((len(image_dataset), feat_dim), dtype=np.float32)\n        x_image_array[has_image_indices + current_index] = feats\n        current_index += batch_size\n    return x_image_array\n\n\ntrain, test, breeds, colors, states = prepare_df(debug)\nnum_image = 10\nmodel = m\n\n#train_x_image_array = calc_x_image_array(train['PetID'].values, 'train', num_image, batch_size)\n#test_x_image_array = calc_x_image_array(test['PetID'].values, 'test', num_image, batch_size)\n\nwith tf.device(tf_device_str):\n    train_x_image_array = calc_x_image_array(train['PetID'].values, 'train', num_image, batch_size)\n    test_x_image_array = calc_x_image_array(test['PetID'].values, 'test', num_image, batch_size)","execution_count":null,"outputs":[{"output_type":"stream","text":"\r  0%|          | 0/585 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Train (14993, 24)\nTest (3948, 23)\nBreeds (307, 3)\nColors (7, 2)\nStates (15, 2)\n","name":"stdout"},{"output_type":"stream","text":"  1%|          | 7/585 [06:21<8:40:13, 54.00s/it] ","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"53655871a01929f1cc70c4f46c9791e22686d4c0"},"cell_type":"code","source":"train_image_feat_list = []\nfor i in tqdm(range(len(train))):\n    pet_image_feat = 0\n    pet_image_count = 0\n    for j in range(num_image):\n        index = i * num_image + j\n        this_feat = train_x_image_array[index]\n        if np.sum(this_feat) == 0:\n            pet_image_feat += this_feat\n        else:\n            pet_image_feat += this_feat\n            pet_image_count += 1\n    pet_image_feat_mean = pet_image_feat / pet_image_count\n    if i < 5:\n        print(f'i, {i} pet_image_count {pet_image_count}')\n    train_image_feat_list.append(pet_image_feat_mean)\n    \ntest_image_feat_list = []\nfor i in tqdm(range(len(test))):\n    pet_image_feat = 0\n    pet_image_count = 0\n    for j in range(num_image):\n        index = i * num_image + j\n        this_feat = test_x_image_array[index]\n        if np.sum(this_feat) == 0:\n            pet_image_feat += this_feat\n        else:\n            pet_image_feat += this_feat\n            pet_image_count += 1\n    pet_image_feat_mean = pet_image_feat / pet_image_count\n    if i < 5:\n        print(f'i, {i} pet_image_count {pet_image_count}')\n    test_image_feat_list.append(pet_image_feat_mean)\n    \n","execution_count":60,"outputs":[{"output_type":"stream","text":"  0%|          | 0/14993 [00:00<?, ?it/s]\n","name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"name 'train_x_image_array' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-5532a7726e55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_image\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mthis_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x_image_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_feat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpet_image_feat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mthis_feat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_x_image_array' is not defined"]}]},{"metadata":{"trusted":true,"_uuid":"201edc2744f0554eb8df3a1101d74c156c45a2ae"},"cell_type":"code","source":"features = {}\nfor i,pet_id in enumerate(train['PetID'].values):\n    features[pet_id] = train_image_feat_list[i]\ntrain_feats = pd.DataFrame.from_dict(features, orient='index')\ntrain_feats.columns = [f'pic_{i}' for i in range(train_feats.shape[1])]\ntrain_feats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1ab2714b8591726e01de49e88239ad8272e84ae"},"cell_type":"code","source":"features = {}\nfor i,pet_id in enumerate(test['PetID'].values):\n    features[pet_id] = test_image_feat_list[i]\n\ntest_feats = pd.DataFrame.from_dict(features, orient='index')\ntest_feats.columns = [f'pic_{i}' for i in range(test_feats.shape[1])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8ba1d413f2c6adad0b5cf40797f347ada68403d"},"cell_type":"code","source":"train_feats = train_feats.reset_index()\ntrain_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n\ntest_feats = test_feats.reset_index()\ntest_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e1db2913c7359965eb9219d65f50341a0496a10"},"cell_type":"code","source":"test_feats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f115be57d9d9f7bb780ce1cfc2fef79afebb072"},"cell_type":"code","source":"train_feats.to_feather(f'train_image_densenet_{num_image}_1024.feather')\ntest_feats.to_feather(f'test_image_densenet_{num_image}_1024.feather')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b912c493a2e7da209f0c5f184c1198b476a23af2"},"cell_type":"code","source":"import gc\n\ndel m\ndel train_image_feat_list\ndel test_image_feat_list\ndel train_x_image_array\ndel test_x_image_array\ndel features\ndel train_feats\ndel test_feats\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39bff518862f9746a8f9dfc58dc3996078bab7d4"},"cell_type":"markdown","source":"> ## Main for GBT training..."},{"metadata":{"trusted":true,"_uuid":"6143c6b06a616c3b75cfc311f28af0e014db71fb"},"cell_type":"code","source":"# --- train lgbm ---","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a50afc6c405ef46f2a8ec851648d47e3694bdfc"},"cell_type":"code","source":"import argparse\nfrom collections import Counter\nfrom copy import deepcopy\n\nimport numpy\nimport pandas as pd\nfrom distutils.util import strtobool\n\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n\nimport sys\nimport os\n\n\ndef permutation_augmentation(df, permute_cols_ratio=0.1, augment_scale=4):\n    df_list = [df]\n\n    bs, ndim = df.shape\n    num_permute_cols = int(ndim * permute_cols_ratio)\n    for i in range(augment_scale):\n        df_tmp = deepcopy(df)\n        col_indices = numpy.random.choice(ndim, num_permute_cols, replace=False)\n        for col_index in col_indices:\n            perm = numpy.random.permutation(bs)\n            df_tmp.iloc[:, col_index] = df_tmp.iloc[:, col_index].values[perm]\n        df_list.append(df_tmp)\n    return pd.concat(df_list, axis=0)\n\n\ndef fit_xgb(train, test, pp, train_indices, val_indices,\n            optr=None, predict_y=None, step=0, **kwargs):\n    metric = 'rmse'\n    xgb_params = {\n        'eval_metric': metric,\n        'seed': 1337,\n        'eta': 0.0123,\n        'tree_method': 'gpu_hist',\n        'device': 'gpu',\n        'silent': 1,\n        'depth': 5,\n        'min_child_weight': 1,\n        'subsample': 0.9,\n        # 'subsample': 0.8,\n        'colsample_bytree': 0.85,\n        # 'colsample_bylevel': 0.2,\n        'lambda': 0.6,\n        # 'alpha': 0.4\n    }\n    print('xgb_params', xgb_params)\n\n    # Additional parameters:\n    verbose_eval = 100\n    early_stop = 300\n    # num_rounds = 10000\n    num_rounds = 2500\n    # early_stop = 500\n    # num_rounds = 60000\n\n    target = pp.target\n    # train_x_numeric = x_numeric[train_indices]\n    train_target = target[train_indices]\n\n    # val_x_numeric = x_numeric[val_indices]\n    val_target = target[val_indices]\n\n    feat_cols = pp.numeric_cols + pp.cat_cols\n    X_tr = train.loc[train_indices, feat_cols].copy()\n    if step == 0:\n        print('feat_cols', feat_cols)\n        print('X_tr before augment', X_tr.shape)\n\n    augment_scale = 0\n    if augment_scale > 0:\n        X_tr = permutation_augmentation(\n            X_tr, permute_cols_ratio=0.03,\n            augment_scale=augment_scale)\n        print('X_tr after augment', X_tr.shape)\n    X_val = train.loc[val_indices, feat_cols].copy()\n    # print('X_tr shape {} dtypes {}'.format(X_tr.shape, X_tr.dtypes.values))\n    y_tr = numpy.tile(train_target[:, 0], augment_scale + 1)\n    y_val = val_target[:, 0]\n\n    d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n    d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n\n    if step == 0:\n        print('d_train')\n        for i, (k, v) in enumerate(zip(d_train.feature_names, d_train.feature_types)):\n            print(i, k, v)\n\n    # https://stackoverflow.com/questions/45006341/xgboost-how-to-use-mae-as-objective-function\n    def huber_approx_obj(preds, dtrain):\n        # d = preds - dtrain.get_labels()  # remove .get_labels() for sklearn\n        d = preds - dtrain.get_label()\n        h = 1  # h is delta in the graphic\n        scale = 1 + (d / h) ** 2\n        scale_sqrt = numpy.sqrt(scale)\n        grad = d / scale_sqrt\n        hess = 1 / scale / scale_sqrt\n        return grad, hess\n\n    print('training XGB:')\n    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n    model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n                      early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=xgb_params,\n                      )  # obj=huber_approx_obj\n\n    os.makedirs('tmp', exist_ok=True)\n    # To release GPU memory, we need to delete object.\n    # save & load is necessary for future prediction...\n    # https://github.com/dmlc/xgboost/issues/3045\n    best_score = model.best_score\n    best_ntree_limit = model.best_ntree_limit\n    model.save_model('tmp/xgb.model')\n    model.__del__()\n    model = xgb.Booster()\n    model.load_model('tmp/xgb.model')\n    model.best_ntree_limit = best_ntree_limit\n\n    if optr is not None:\n        with timer('predict'):\n            val_y = model.predict(\n                xgb.DMatrix(X_val, feature_names=X_val.columns),\n                ntree_limit=model.best_ntree_limit)\n        if predict_y is not None:\n            predict_y[val_indices] = val_y\n        with timer('optr.fit'):\n            optr.fit(val_y, val_target)\n        coefficients = optr.coefficients()\n\n        pred_y1_rank = optr.predict(val_y, coefficients)\n        # pred_y1_rank = optr.predict(pred_y1, [0.5, 2.2, 3.2, 3.3])\n        score = cohen_kappa_score(pred_y1_rank, val_target,\n                                  labels=numpy.arange(optr.num_class),\n                                  weights='quadratic')\n        print('optimized score', score, 'coefficients', coefficients,)\n    else:\n        print('optr is not set, skip optimizing threshold...')\n        coefficients = None\n        score = None\n    log = {'valid_rmse': best_score}\n\n    return model, coefficients, log, score\n\n\ndef fit_lgbm(train, test, pp, train_indices, val_indices,\n             optr=None, predict_y=None, step=0, **kwargs):\n\n    # metric = 'huber'  # 'rmse'\n    metric = 'rmse'\n    params = {'application': 'regression',\n              'boosting': 'gbdt',\n              'metric': metric,\n              'num_leaves': 70,\n              'max_depth': 9,\n              'learning_rate': 0.01,\n              'bagging_fraction': 0.85,\n              'feature_fraction': 0.8,\n              'min_split_gain': 0.02,\n              'min_child_samples': 150,\n              'min_child_weight': 0.02,\n              'lambda_l2': 0.0475,\n              'verbosity': -1,\n              'data_random_seed': 17,\n              # 'device': 'gpu',  # need to compile...\n              # 'gpu_device_id': 0\n              }\n\n    # Additional parameters:\n    # early_stop = 500\n    early_stop = 300\n    verbose_eval = 100\n    num_rounds = 10000\n\n    target = pp.target\n    # train_x_numeric = x_numeric[train_indices]\n    train_target = target[train_indices]\n\n    # val_x_numeric = x_numeric[val_indices]\n    val_target = target[val_indices]\n\n    feat_cols = pp.numeric_cols + pp.cat_cols\n    X_tr = train.loc[train_indices, feat_cols]\n    if step == 0:\n        print('feat_cols', feat_cols)\n        print('X_tr before augment', X_tr.shape)\n    augment_scale = 0\n    if augment_scale > 0:\n        X_tr = permutation_augmentation(\n            X_tr, permute_cols_ratio=0.15,\n            augment_scale=augment_scale)\n        print('X_tr after augment', X_tr.shape)\n    X_val = train.loc[val_indices, feat_cols]\n    # print('X_tr shape {} dtypes {}'.format(X_tr.shape, X_tr.dtypes.values))\n    y_tr = numpy.tile(train_target[:, 0], augment_scale + 1)\n    y_val = val_target[:, 0]\n    d_train = lgb.Dataset(X_tr, label=y_tr, categorical_feature=pp.cat_cols)\n    d_valid = lgb.Dataset(X_val, label=y_val, categorical_feature=pp.cat_cols)\n    watchlist = [d_train, d_valid]\n\n    print('training LGB:')\n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n\n    if optr is not None:\n        with timer('predict'):\n            val_y = model.predict(X_val, num_iteration=model.best_iteration)\n        if predict_y is not None:\n            predict_y[val_indices] = val_y\n        with timer('optr.fit'):\n            optr.fit(val_y, val_target)\n        coefficients = optr.coefficients()\n\n        pred_y1_rank = optr.predict(val_y, coefficients)\n        # pred_y1_rank = optr.predict(pred_y1, [0.5, 2.2, 3.2, 3.3])\n        score = cohen_kappa_score(pred_y1_rank, val_target,\n                                  labels=numpy.arange(optr.num_class),\n                                  weights='quadratic')\n        print('optimized score', score, 'coefficients', coefficients,)\n    else:\n        print('optr is not set, skip optimizing threshold...')\n        coefficients = None\n        score = None\n\n    log = {'training_rmse': model.best_score['training'][metric],\n           'valid_rmse': model.best_score['valid_1'][metric]}\n    return model, coefficients, log, score\n\n\ndef fit_cb(train, test, pp, train_indices, val_indices,\n           optr=None, predict_y=None, step=0, **kwargs):\n    # metric = 'huber'  # 'rmse'\n    metric = 'RMSE'  # 'rmse'\n    params = {\n        'loss_function': metric,\n        # 'learning_rate': 0.01,\n        'learning_rate': 0.03,\n        'depth': 6,\n        'l2_leaf_reg': 9,  # 1 ~ 9\n        'iterations': 10000,\n        'od_type': 'Iter',\n        'od_wait': 300,  # early stopping\n        'random_seed': 1337,\n        'task_type': 'GPU',\n    }\n    params['devices'] = '0'\n\n    target = pp.target\n    train_target = target[train_indices]\n    val_target = target[val_indices]\n\n    feat_cols = pp.numeric_cols + pp.cat_cols\n    X_tr = train.loc[train_indices, feat_cols]\n    if step == 0:\n        print('feat_cols', feat_cols)\n        print('X_tr before augment', X_tr.shape)\n\n    augment_scale = 0\n    if augment_scale > 0:\n        X_tr = permutation_augmentation(\n            X_tr, permute_cols_ratio=0.15,\n            augment_scale=augment_scale)\n        if step == 0:\n            print('X_tr after augment', X_tr.shape)\n    X_val = train.loc[val_indices, feat_cols]\n    # print('X_tr shape {} dtypes {}'.format(X_tr.shape, X_tr.dtypes.values))\n    y_tr = numpy.tile(train_target[:, 0], augment_scale + 1)\n    y_val = val_target[:, 0]\n\n    categorical_features_indices = [\n        X_tr.columns.get_loc(cat_col) for cat_col in pp.cat_cols]\n    model = cb.CatBoostRegressor(**params)\n    print('training CatBoost:')\n    model.fit(X_tr, y_tr, cat_features=categorical_features_indices,\n              eval_set=(X_val, y_val), plot=False,\n              use_best_model=True, metric_period=100, early_stopping_rounds=300)\n\n    if optr is not None:\n        with timer('predict'):\n            val_y = model.predict(X_val)\n        if predict_y is not None:\n            predict_y[val_indices] = val_y\n        with timer('optr.fit'):\n            optr.fit(val_y, val_target)\n        coefficients = optr.coefficients()\n\n        pred_y1_rank = optr.predict(val_y, coefficients)\n        # pred_y1_rank = optr.predict(pred_y1, [0.5, 2.2, 3.2, 3.3])\n        score = cohen_kappa_score(pred_y1_rank, val_target,\n                                  labels=numpy.arange(optr.num_class),\n                                  weights='quadratic')\n        print('optimized score', score, 'coefficients', coefficients,)\n    else:\n        print('optr is not set, skip optimizing threshold...')\n        coefficients = None\n        score = None\n    log = {'training_rmse': model.best_score_['learn'][metric],\n           'valid_rmse': model.best_score_['validation_0'][metric]}\n    return model, coefficients, log, score\n\n\ndef main_gbm(debug, device, use_bert, use_image, num_image,\n             use_tfidf=False, animal_type=None,\n             cat2num=True, use_cat=True, image_type='clf',\n             arch='lgbm', fold=4, use_fasttext=True, embedding_type_list=None,\n             postfix='', use_cosine_dist=False):\n    \"\"\"\n\n    Args:\n        debug:\n        device:\n        use_bert:\n        use_image:\n        num_image:\n        use_tfidf:\n        animal_type (int): if specified, only train specific animal_type = 'dog' or 'cat'.\n            If Negative value, both animals are trained same time.\n        cat2num (bool): If True categorical values are converted to numeric values.\n        use_cat (bbol): Use category specific Linear layer or not.\n        mode (str): Training mode type.\n            normal - normal training, regression of AdoptionSpeed.\n            mean - regression of mean AdoptionSpeed on RescuerID.\n\n    Returns:\n\n    \"\"\"\n    num_class = 5\n    print('debug', debug)\n    print('Train data_type {}'.format(animal_type))\n\n    if animal_type < 0:\n        animal_type = None\n    use_cat = not cat2num\n\n    # --- dataset ---\n\n    train, test, breeds, colors, states = prepare_df(debug, animal_type=animal_type)\n    train_type = train['Type'].values.copy()\n    test_type = test['Type'].values.copy()\n    pp = Preprocessor(arch=arch)\n    if arch == 'xlearn':\n        train, test = pp.preprocess(\n            train, test, breeds, colors, states, debug=debug, use_tfidf=use_tfidf,\n            use_metadata=False, use_sentiment=False, use_gdp=False,\n            use_rescuer_id_count=True, use_name_feature=True, use_target_encoding=False,\n            cat2num=cat2num, animal_type=animal_type, use_tfidf_cache=True,\n            tfidf_svd_components=16, num_sentiment_text=0,\n            use_sentiment2=True, use_metadata2=True, use_text=False, use_fasttext=use_fasttext,\n            add_pred=None, use_image_size=False, arch=arch, use_custom_boolean_feature=True,\n            embedding_type_list=embedding_type_list)\n    else:\n        train, test = pp.preprocess(\n            train, test, breeds, colors, states, debug=debug, use_tfidf=use_tfidf,\n            use_metadata=False, use_sentiment=False, use_gdp=True,\n            use_rescuer_id_count=True, use_name_feature=True, use_target_encoding=False,\n            cat2num=cat2num, animal_type=animal_type, use_tfidf_cache=True,\n            tfidf_svd_components=16, num_sentiment_text=0,\n            use_sentiment2=True, use_metadata2=True, use_text=True, use_fasttext=use_fasttext,\n            use_image_size=True, arch=arch, add_pred=None, use_custom_boolean_feature=False,\n            embedding_type_list=embedding_type_list)\n    target = pp.target\n\n#     if use_bert:\n#         print('preprocess bert feature...')\n#         train, test = pp.preprocess_bert(\n#             train, test, num_extract_sentence=2, layer_indices=[-1, ], device=device,\n#             use_cache=True, animal_type=animal_type)\n#     else:\n#         print('skip bert feature')\n#         # train_x_bert, test_x_bert = None, None\n\n    if use_image:\n        print('preprocess image feature... {}'.format(image_type))\n        if image_type == 'clf':\n            clf_arch = 'densenet'\n            # clf_arch = 'vgg16'\n            # clf_arch = 'seresnext50'\n            n_components = 32\n            print(f'using clf_arch {clf_arch}, n_components {n_components}')\n            train, test = pp.preprocess_image(\n                train, test, num_image=num_image, device=device, arch=clf_arch,\n                n_components=n_components, animal_type=animal_type, use_cache=True,\n                method='svd')\n        elif image_type == 'det':\n            det_arch = 'faster_rcnn_vgg16'  # fpn50\n            n_components = 32  # 506 was worse...\n            train, test = pp.preprocess_image_det(\n                train, test, num_image=num_image, device=device, arch=det_arch, use_cache=True,\n                n_components=n_components)\n        else:\n            raise ValueError(\"[ERROR] Unexpected value image_type={}\".format(image_type))\n    else:\n        print('skip image feature...')\n        train_x_image, test_x_image = None, None\n\n    if use_cosine_dist:\n        clf_arch = 'densenet'\n        print('use_cosine_dist, {}'.format(clf_arch))\n        train, test = pp.preprocess_image_cosine(\n            train, test, train_type, test_type, arch=clf_arch)\n\n    print('fillna -1')\n    train = train.fillna(-1)\n    test = test.fillna(-1)\n\n    # --- Setup CV ---\n    num_split = fold\n    kfold_method = 'group'\n    # kfold_method = 'stratified'\n    random_state = 1337\n\n    if kfold_method == 'stratified':\n        print('StratifiedKFold...')\n        kf = StratifiedKFold(n_splits=num_split, random_state=random_state, shuffle=True)\n        # fold_splits = kf.split(train, target)\n        fold_splits = kf.split(numpy.arange(len(train)), target)\n    elif kfold_method == 'group':\n        print('GroupKFold...')\n        kf = GroupKFold(num_split)\n        # kf.random_state = 42\n        groups = train['RescuerID'].astype('category').cat.codes.values\n        fold_splits = kf.split(numpy.arange(len(train)), target, groups)\n    else:\n        raise ValueError(\"[ERROR] Unexpected value kfold_method={}\".format(kfold_method))\n\n    optr = OptimizedRounder(\n        num_class=num_class,\n        # method='differential_evolution'\n        method='nelder-mead')\n\n    regressor_list = []\n    coefficients_list = []\n    log_list = []\n    score_list = []\n\n    # target is (num_rows, 1), predict_y is (num_rows,)\n    predict_y = numpy.ones((len(target),), dtype=numpy.float32) * -1\n    # std_list = calc_std_list(train_x_numeric, train_x_cat, train_x_bert, train_x_image)\n    xlearn_dataset = None\n    if arch == 'lgbm':\n        fit_fn = fit_lgbm\n    elif arch == 'xgb':\n        fit_fn = fit_xgb\n    elif arch == 'cb':\n        fit_fn = fit_cb\n    elif arch == 'xlearn':\n        fit_fn = fit_xlearn\n        # --- convert to dataframe to series... ---\n        feat_cols = pp.numeric_cols + pp.cat_cols\n        xlearn_dataset = XlearnDataset(\n            train.loc[:, feat_cols + ['AdoptionSpeed']],\n            test.loc[:, feat_cols],\n        )\n        print('xlearn_dataset', xlearn_dataset)\n    else:\n        raise ValueError(\"[ERROR] Unexpected value arch={}\".format(arch))\n\n    for k, (train_indices, val_indices) in enumerate(fold_splits):\n        print('---- {} fold / {} ---'.format(k, num_split))\n        regressor, coefficients, log, score = fit_fn(\n            train, test, pp, train_indices, val_indices, optr=optr,\n            predict_y=predict_y, step=k, xlearn_dataset=xlearn_dataset)\n        regressor_list.append(regressor)\n        coefficients_list.append(coefficients)\n        log_list.append(log)\n        score_list.append(score)\n\n    log_df = pd.DataFrame(log_list)\n    print('log_df mean\\n{}'.format(log_df.mean()))\n    if score_list[0] is not None:\n        opt_score_mean = numpy.array(score_list).mean()\n        print('opt_score_mean', opt_score_mean, 'score_list', score_list)\n\n    print('Number of un-predicted example: ', numpy.sum(predict_y <= -1))\n    with timer('optr.fit'):\n        optr.fit(predict_y, target)\n    coefficients = optr.coefficients()\n    pred_y1_rank = optr.predict(predict_y, coefficients)\n    score = cohen_kappa_score(pred_y1_rank, target,\n                              labels=numpy.arange(optr.num_class),\n                              weights='quadratic')\n    print('Total: optimized score', score, 'coefficients', coefficients, )\n\n    # --- create submission ---\n    flag_create_submission = True\n    if flag_create_submission:\n        feat_cols = pp.numeric_cols + pp.cat_cols\n        # print('feat_cols', feat_cols)\n\n        test_dataset = test.loc[:, feat_cols]\n        if arch == 'lgbm':\n            with timer('test predict'):\n                test_predict_list = [reg.predict(test_dataset, num_iteration=reg.best_iteration)\n                                     for reg in regressor_list]\n        elif arch == 'xgb':\n            test_dataset = xgb.DMatrix(test_dataset, feature_names=test_dataset.columns)\n            with timer('test predict'):\n                test_predict_list = [reg.predict(test_dataset, ntree_limit=reg.best_ntree_limit)\n                                     for reg in regressor_list]\n        elif arch == 'cb':\n            with timer('test predict'):\n                test_predict_list = [reg.predict(test_dataset)\n                                     for reg in regressor_list]\n        else:\n            assert arch == 'xlearn'\n            test_predict_list = [reg.predict(xlearn_dataset.test_ffm_series)\n                                 for reg in regressor_list]\n\n        print('train counter', Counter(target[:, 0]))\n        test_predict_mean = numpy.mean(numpy.array(test_predict_list), axis=0)\n        print('test_predict_mean', test_predict_mean.shape)\n\n        test_id = test['PetID']\n        # --- 0. raw float predictions ---\n        predict_df = pd.DataFrame({'PetID': train['PetID'], 'y': predict_y, 't': target.ravel()})\n        predict_df.to_csv('predict_{}{}_train.csv'.format(arch, postfix), index=False)\n        print(f'predict_{arch}{postfix}_train.csv created.')\n        predict_df = pd.DataFrame({'PetID': test_id, 'y': test_predict_mean})\n        predict_df.to_csv('predict_{}{}_test.csv'.format(arch, postfix), index=False)\n        print(f'predict_{arch}{postfix}_test.csv created.')\n\n        # --- 1. mean coefficients ---\n        coefficients_mean = numpy.mean(numpy.array(coefficients_list), axis=0)\n        print('coefficients_mean', coefficients_mean)\n        test_predictions = optr.predict(test_predict_mean, coefficients_mean).astype(int)\n        print('test_predictions counter', Counter(test_predictions))\n        submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n        submission.to_csv(f'submission_mean_{arch}{postfix}.csv', index=False)\n        print(f'submission_mean_{arch}{postfix}.csv created.')\n\n        # --- 2. validation all coefficients ---\n        print('coefficients from all validation ', coefficients)\n        test_predictions = optr.predict(test_predict_mean, coefficients).astype(int)\n        print('test_predictions counter', Counter(test_predictions))\n        submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n        submission.to_csv(f'submission_valcoef_{arch}{postfix}.csv', index=False)\n        print(f'submission_valcoef_{arch}{postfix}.csv created.')\n\n        coefficients3 = coefficients.copy()\n        coefficients3[0] = 1.66\n        coefficients3[1] = 2.13\n        coefficients3[3] = 2.85\n        test_predictions = optr.predict(test_predict_mean, coefficients3).astype(int)\n        submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n        submission.to_csv(f'submission_valcoef3_{arch}{postfix}.csv', index=False)\n        print('test_predictions counter', Counter(test_predictions))\n        print(f'submission_valcoef3_{arch}{postfix}.csv created.')\n\n        # --- 3. same histgram with train... ---\n        test_predictions = optr.fit_and_predict_by_histgram(test_predict_mean, target)\n        print('coefficients to align with train target', optr.coefficients())\n        print('test_predictions counter', Counter(test_predictions))\n        submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n        submission.to_csv(f'submission_{arch}{postfix}.csv', index=False)\n        print(f'submission_{arch}{postfix}.csv created.')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2a5dc6ab2bd426818ff5cc83242a6fc70c2d758"},"cell_type":"code","source":"import argparse\nfrom collections import Counter\nfrom copy import deepcopy\n\nimport numpy\nimport pandas as pd\nfrom distutils.util import strtobool\n\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\n\nimport lightgbm as lgb\n\nimport sys\nimport os\n\ndevice = 0\nepoch = 60\nprint('debug', debug)\nprint('epoch', epoch)\n#print('args', vars(args))\n\nnum_class = 5\nuse_bert = False\nuse_image = True\nnum_image = 1\nout = 'results/tmp'\nanimal_type = None\n\nuse_tfidf=False\n# cat2num=True\nuse_cat=True\nimage_type='clf'\nmode='normal'\n# arch = 'lgbm'\nbatchsize=256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54c5e1f5066d7e483320eb8ae0a5ddbe75dc9f23"},"cell_type":"code","source":"num_class = 5\nprint('debug', debug)\nprint('Train data_type {}'.format(animal_type))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c11c4224236371bb8250ca73486b9bb421448d7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c2edbfd3751d932a00eea9e336169d012bec2d3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73774ef37748e671971fe657f15d8f588de61263"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0375cfeb9cb66578ae32a4221bdcd80cd71f710a"},"cell_type":"code","source":"# train_xlearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbdd6531876bdc923da3ec503d2fcbae0285cea1"},"cell_type":"code","source":"import os\nimport shutil\n\nimport numpy\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport xlearn as xl\nfrom sklearn.metrics import cohen_kappa_score\n'''\nhttps://www.kaggle.com/mpearmain/pandas-to-libffm\nAnother CTR comp and so i suspect libffm will play its part, after all it is an atomic bomb for this kind of stuff.\nA sci-kit learn inspired script to convert pandas dataframes into libFFM style data.\n\nThe script is fairly hacky (hey thats Kaggle) and takes a little while to run a huge dataset.\nThe key to using this class is setting up the features dtypes correctly for output (ammend transform to suit your needs)\n\n'''\n\n\nclass FFMFormatPandas:\n    \"\"\"\n    Convert pandas DataFrame into libffm format (consists of \"field:feature:value\") used in xlearn.\n    DataFrame dtype 'i' and 'O' are treated as categorical value (different feature for each value).\n    'f' are treated as value (same feature for each value).\n    \"\"\"\n    def __init__(self):\n        self.field_index_ = None\n        self.feature_index_ = None\n        self.y = None\n\n    def fit(self, df, y=None):\n        self.y = y\n        df_ffm = df[df.columns.difference([self.y])]\n        if self.field_index_ is None:\n            self.field_index_ = {col: i for i, col in enumerate(df_ffm)}\n\n        if self.feature_index_ is not None:\n            last_idx = max(list(self.feature_index_.values()))\n\n        if self.feature_index_ is None:\n            self.feature_index_ = dict()\n            last_idx = 0\n\n        for col in df.columns:\n            if df[col].dtype.kind in ['O', 'i']:\n                print(f'{col} is treated as categorical...')\n                vals = df[col].unique()\n                for val in vals:\n                    if pd.isnull(val):\n                        continue\n                    name = '{}_{}'.format(col, val)\n                    if name not in self.feature_index_:\n                        self.feature_index_[name] = last_idx\n                        last_idx += 1\n            else:\n                print(f'{col} is treated as float value...')\n            self.feature_index_[col] = last_idx\n            last_idx += 1\n        return self\n\n    def fit_transform(self, df, y=None):\n        self.fit(df, y)\n        return self.transform(df)\n\n    def transform_row_(self, row, t):\n        ffm = []\n        if self.y != None and self.y in row.index:\n            ffm.append(str(row.loc[row.index == self.y][0]))\n        if self.y is None:\n            ffm.append(str(0))\n\n        for col, val in row.loc[row.index != self.y].to_dict().items():\n            col_type = t[col]\n            if isinstance(val, float):\n                val_int = int(val)\n            name = '{}_{}'.format(col, val_int)\n            # ffm.append('{}:{}:1'.format(self.field_index_[col], self.feature_index_[name]))\n            if col_type.kind == 'O':\n                ffm.append('{}:{}:1'.format(self.field_index_[col], self.feature_index_[name]))\n            elif col_type.kind == 'i':\n                ffm.append('{}:{}:1'.format(self.field_index_[col], self.feature_index_[name]))\n            elif col_type.kind == 'f':\n                ffm.append('{}:{}:{}'.format(self.field_index_[col], self.feature_index_[col], val))\n                # print('col_type.kind == f, append', '{}:{}:{}'.format(self.field_index_[col], self.feature_index_[col], val))\n        return ' '.join(ffm)\n\n    def transform(self, df):\n        t = df.dtypes.to_dict()\n        return pd.Series({idx: self.transform_row_(row, t) for idx, row in df.iterrows()})\n\n\nclass XlearnDataset(object):\n    def __init__(self, train_df, test_df, ycol='AdoptionSpeed'):\n        self.train_df = train_df\n        self.test_df = test_df\n        self.ffm_format = FFMFormatPandas()\n\n        all_df = pd.concat([train_df, test_df], axis=0, sort=False)\n        all_df.reset_index(inplace=True)\n        all_df[ycol].fillna(-1, inplace=True)\n        ffm_series = self.ffm_format.fit_transform(all_df, y=ycol)\n        assert len(ffm_series) == len(all_df), f'ffm_series {len(ffm_series)}, all_df {len(all_df)}'\n        self.train_ffm_series = ffm_series.iloc[:len(train_df)]\n        self.test_ffm_series = ffm_series.iloc[len(train_df):]\n\n    def get_train(self, indices=None):\n        if indices is None:\n            return self.train_ffm_series\n        else:\n            return self.train_ffm_series[indices]\n\n\nclass XlearnModel(object):\n    def __init__(self, params, method='ffm', model_filepath='tmp/model.out',\n                 model_txt_filepath=None):  # 'tmp/model.txt'\n        print(f'XlearnModel method={method}')\n        self.params = params\n        self.model_filepath = model_filepath\n        self.model_txt_filepath = model_txt_filepath\n        if method == 'ffm':\n            self.model = xl.create_ffm()\n        elif method == 'fm':\n            self.model = xl.create_fm()\n        else:\n            raise NotImplementedError\n\n    def fit(self, train_ffm_series, val_ffm_series, train_filepath='tmp/train.txt', val_filepath='tmp/val.txt',\n            use_cache=False):\n        train_ffm_series.to_csv(train_filepath, index=False)\n        val_ffm_series.to_csv(val_filepath, index=False)\n\n        self.model.setTrain(train_filepath)  # Training data\n        self.model.setValidate(val_filepath)  # Validation data\n\n        if self.model_txt_filepath is not None:\n            self.model.setTXTModel(self.model_txt_filepath)\n        print('fit start...')\n        self.model.fit(self.params, self.model_filepath)\n        print('fit end...')\n        return self\n\n    def predict(self, ffm_series, filepath='tmp/test.txt', out_filepath='tmp/output.txt'):\n        # self.create_ffm_series(df, filepath)\n        ffm_series.to_csv(filepath, index=False)\n        # Prediction task\n        self.model.setTest(filepath)  # Test data\n        self.model.predict(self.model_filepath, out_filepath)\n        y = pd.read_csv(out_filepath, header=None).values[:, 0]\n        return y\n\n\ndef fit_xlearn(train, test, pp, train_indices, val_indices,\n           optr=None, predict_y=None, step=0, xlearn_dataset=None, **kwargs):\n    # param:\n    #  0. binary classification\n    #  1. learning rate: 0.2\n    #  2. regular lambda: 0.002\n    #  3. evaluation metric: accuracy\n    params = {'task': 'reg', 'lr': 0.20,\n              'lambda': 0.00002, 'metric': 'rmse',\n              'opt': 'adagrad', 'k': 16,\n              'init': 0.50,\n              # 'epoch': 100,\n              # 'stop_window': 5\n              }  # adagrad\n\n    model = XlearnModel(params)\n\n    target = pp.target\n    val_target = target[val_indices]\n\n    feat_cols = pp.numeric_cols + pp.cat_cols\n    feat_y_cols = feat_cols + ['AdoptionSpeed']\n    print('feat_cols', feat_cols)\n    X_tr = xlearn_dataset.train_ffm_series[train_indices]\n    X_val = xlearn_dataset.train_ffm_series[val_indices]\n    model.fit(X_tr, X_val)\n\n    if optr is not None:\n        with timer('predict'):\n            # Start to predict\n            # The output result will be stored in output.txt\n            val_y = model.predict(X_val)\n        if predict_y is not None:\n            predict_y[val_indices] = val_y\n        with timer('optr.fit'):\n            optr.fit(val_y, val_target)\n        coefficients = optr.coefficients()\n\n        pred_y1_rank = optr.predict(val_y, coefficients)\n        # pred_y1_rank = optr.predict(pred_y1, [0.5, 2.2, 3.2, 3.3])\n        score = cohen_kappa_score(pred_y1_rank, val_target,\n                                  labels=numpy.arange(optr.num_class),\n                                  weights='quadratic')\n        print('optimized score', score, 'coefficients', coefficients,)\n    else:\n        print('optr is not set, skip optimizing threshold...')\n        coefficients = None\n        score = None\n    # log = {'training_rmse': model.best_score_['learn'][metric],\n    #        'valid_rmse': model.best_score_['validation_0'][metric]}\n    log = {'dummy': 0}\n    return model, coefficients, log, score\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f58b77abc80c3c27c2deffeb72cb0b59e5c043c"},"cell_type":"code","source":"if debug:\n    fold = 3\nelse:\n    fold = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b976a0ae3efab1b29d0600a91f40cc14c61db7ce","scrolled":false},"cell_type":"code","source":"# --- train lgbm ---\n# use_fasttext takes time.\nmain_gbm(debug, device, use_bert, use_image, num_image,\n         use_tfidf=False, animal_type=-1,\n         cat2num=False, use_cat=True, image_type='clf',\n         arch='lgbm', fold=10, use_fasttext=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc4f5026c8f6309ef5895581b5f330ea930370b6"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2058a3b6429244ace407a57e2cdf2390949048c4"},"cell_type":"code","source":"# --- train cb ---\nmain_gbm(debug, device, use_bert, use_image, num_image,\n         use_tfidf=False, animal_type=-1,\n         cat2num=False, use_cat=True, image_type='clf',\n         arch='cb', fold=10, use_fasttext=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b8f909f27d73a975d0a1d06d510ccdf9c50aea8"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b757a09046cabe2d88028a2207597fb6d5e1ef9a"},"cell_type":"code","source":"# --- train xgb ---\nmain_gbm(debug, device, use_bert, use_image, num_image,\n         use_tfidf=False, animal_type=-1,\n         cat2num=True, use_cat=True, image_type='clf',\n         arch='xgb', fold=fold, use_fasttext=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c45633b214fb0904d6d515f628fa150e64f62264"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a609a8979ebe19f4833cbda840cf20512b062c84"},"cell_type":"markdown","source":"# Xlearn"},{"metadata":{"trusted":true,"_uuid":"e489d445a39803c35b0729d56d4a31a1ff081c58"},"cell_type":"code","source":"# --- train xlearn ---\nos.makedirs('tmp', exist_ok=True)\nmain_gbm(debug, device, use_bert, use_image, num_image,\n         use_tfidf=False, animal_type=-1,\n         cat2num=False, use_cat=True, image_type='clf',\n         arch='xlearn', fold=10, use_fasttext=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6426418d594a21c2a1c749a869f1b0fd6a0e27d"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a54e9271674ff57f180517e47b59087e30e8d03f"},"cell_type":"markdown","source":"# Chainer xDeepFM"},{"metadata":{"trusted":true,"_uuid":"3f6f72dbec5f57bb2be6d75f2782d7ac08a5795f"},"cell_type":"code","source":"import argparse\nfrom collections import Counter\n\nimport numpy\nimport pandas as pd\nfrom itertools import chain\n\nfrom chainer import functions as F, functions\nfrom chainer import iterators\nfrom chainer import optimizers\nfrom chainer import training\nfrom chainer.optimizer_hooks import WeightDecay\nfrom chainer.training import extensions as E\n\nfrom distutils.util import strtobool\n\nfrom chainer.training.extensions import observe_lr\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\n\n\n# from chainer_chemistry.datasets import NumpyTupleDataset\nimport sys\nimport os\n\ndef lrelu05(x):\n    return functions.leaky_relu(x, slope=0.05)\n\n\ndef lrelu20(x):\n    return functions.leaky_relu(x, slope=0.20)\n\n\ndef setup_predictor(num_cat_id=None, dropout_ratio=0.1, use_bn=False, use_sn=False,\n                    numeric_hidden_dim=96, embed_dim=10, bert_hidden_dim=32,\n                    image_hidden_dim=96, mlp_hidden_dim=128, mlp_n_layers=6, activation=lrelu05,\n                    cat_hidden_dim=32, use_residual=False, out_dim=1, use_set=False,\n                    use_xdeepfm=True):\n    print('setup_predictor num_cat_id {} dropout_ratio {}, use_bn {}, use_sn {} embed_dim {}'\n          .format(num_cat_id, dropout_ratio, use_bn, use_sn, embed_dim))\n    kwargs = dict(dropout_ratio=dropout_ratio, use_bn=use_bn,\n                  numeric_hidden_dim=numeric_hidden_dim, embed_dim=embed_dim,\n                  bert_hidden_dim=bert_hidden_dim,\n                  image_hidden_dim=image_hidden_dim, mlp_hidden_dim=mlp_hidden_dim,\n                  mlp_n_layers=mlp_n_layers, activation=activation,\n                  cat_hidden_dim=cat_hidden_dim, use_residual=use_residual,\n                  out_dim=out_dim)\n    if use_xdeepfm:\n        print('BlendNetXDeepFM built!')\n        predictor = BlendNetXDeepFM(num_cat_id, use_sn=use_sn, weight_tying=True, **kwargs)\n    else:\n        if use_sn:\n            if use_set:\n                predictor = SetSNBlendNet(num_cat_id, **kwargs)\n                # predictor = SNBlendNet(num_cat_id, **kwargs)\n            else:\n                predictor = SNBlendNet(num_cat_id, **kwargs)\n        else:\n            if use_set:\n                predictor = SetBlendNet(num_cat_id, **kwargs)\n            else:\n                predictor = BlendNet(num_cat_id, **kwargs)\n    return predictor\n\n\ndef calc_std_list(x_numeric, x_cat, x_bert, x_image):\n    std_list = [None, None, None, None]\n    if x_numeric is not None:\n        std_list[0] = numpy.std(x_numeric, axis=0, dtype=numpy.float32)\n    if x_cat is not None and x_cat.dtype is not numpy.int32:\n        std_list[1] = numpy.std(x_cat, axis=0, dtype=numpy.float32)\n    if x_bert is not None:\n        bs, num_sent, ndim = x_bert.shape\n        x_bert_2dim = numpy.reshape(x_bert, (bs * num_sent, ndim))\n        std_list[2] = numpy.std(x_bert_2dim, axis=0, dtype=numpy.float32)\n    if x_image is not None:\n        bs, num_image, ndim = x_image.shape\n        x_image_2dim = numpy.reshape(x_image, (bs * num_image, ndim))\n        std_list[3] = numpy.std(x_image_2dim, axis=0, dtype=numpy.float32)\n    return std_list\n\n\ndef fit_nn(x_numeric, x_cat, target, num_cat_id, train_indices, val_indices,\n        x_bert=None, x_image=None, batchsize=256, device=-1, epoch=20,\n        out='./results/tmp', debug=False, optr=None, converter=None, decay_rate=1e-4,\n        use_sn=False, dropout_ratio=0.1, use_bn=False, use_residual=False,\n        check_error=False, mode='normal', train_df=None, predict_y=None):\n    assert converter is not None\n    if debug:\n        epoch = 2\n    # Set up the iterators.\n    train_x_numeric = x_numeric[train_indices]\n    train_target = target[train_indices]\n\n    val_x_numeric = x_numeric[val_indices]\n    val_target = target[val_indices]\n\n    extra_train_features = []\n    extra_val_features = []\n\n    use_cat = (x_cat is not None)\n    use_bert = (x_bert is not None)\n    use_image = (x_image is not None)\n    if use_cat:\n        extra_train_features.append(x_cat[train_indices])\n        extra_val_features.append(x_cat[val_indices])\n    if use_bert:\n        train_x_bert = x_bert[train_indices]\n        val_x_bert = x_bert[val_indices]\n        extra_train_features.append(train_x_bert)\n        extra_val_features.append(val_x_bert)\n    if use_image:\n        train_x_image = x_image[train_indices]\n        val_x_image = x_image[val_indices]\n        extra_train_features.append(train_x_image)\n        extra_val_features.append(val_x_image)\n\n    train = NumpyTupleDataset(*([train_x_numeric] + extra_train_features + [train_target]))\n    valid = NumpyTupleDataset(*([val_x_numeric] + extra_val_features + [val_target]))\n    if mode == 'mean':\n        print('creating RescuerIDMeanDataset...')\n        # train = RescuerIDMeanDataset(train_df.iloc[train_indices].copy(), train, mode='train')\n        # valid = RescuerIDMeanDataset(train_df.iloc[val_indices].copy(), valid, mode='eval')\n        train = RescuerIDMeanDataset(train_df.iloc[train_indices].copy(), train, mode='eval')\n        valid = RescuerIDMeanDataset(train_df.iloc[val_indices].copy(), valid, mode='eval')\n\n    train_iter = iterators.SerialIterator(train, batchsize)\n    valid_iter = iterators.SerialIterator(valid, batchsize, repeat=False, shuffle=False)\n\n    # Set up the regressor.\n    image_encode = False\n    print('image_encode', image_encode)\n\n    metrics_fun = {'mae': F.mean_absolute_error}\n    out_dim = 1\n    kwargs = dict(\n        # activation=lrelu20, cat_hidden_dim=64, image_hidden_dim=32,\n        # mlp_n_layers=6, mlp_hidden_dim=512, numeric_hidden_dim=96,\n        activation=lrelu20, cat_hidden_dim=32, image_hidden_dim=32,\n        mlp_n_layers=1, mlp_hidden_dim=16, numeric_hidden_dim=32,\n        embed_dim=16,\n        # activation=lrelu20, cat_hidden_dim=64, image_hidden_dim=66,\n        # mlp_n_layers=4, mlp_hidden_dim=557, numeric_hidden_dim=96,\n        # activation=lrelu20, cat_hidden_dim=38, image_hidden_dim=66,\n        # mlp_n_layers=3, mlp_hidden_dim=557, numeric_hidden_dim=86,\n        )\n    predictor = setup_predictor(\n        num_cat_id=num_cat_id, use_bn=use_bn, use_sn=use_sn,\n        dropout_ratio=dropout_ratio, use_residual=use_residual,\n        out_dim=out_dim, use_xdeepfm=True,\n        **kwargs)\n    # lam_image_recon = 0.010558\n    lam_image_recon = 0.0\n    image_input_dim = train_x_image.shape[2] if train_x_image is not None else 0\n    # if image_encode:\n\n    def lossfun_huber(y, t):\n        return F.mean(F.huber_loss(y, t, delta=1.0))\n\n    def lossfun_custom(y, t):\n        diff = F.absolute_error(y, t)\n        # print('y', y.shape, t.shape, diff.shape)\n        return F.mean(F.leaky_relu(diff - 0.5, slope=0.2)) + 0.1\n\n    # F.mean_absolute_error\n    if mode == 'mean':\n        mean_predictor = setup_predictor(\n            num_cat_id=num_cat_id, use_bn=False, use_sn=use_sn,\n            dropout_ratio=dropout_ratio, use_residual=use_residual,\n            out_dim=64, use_set=True, **kwargs)\n        regressor = BlendNetMeanRegressor(\n            predictor, mean_predictor, lossfun=F.mean_squared_error,  # F.mean_squared_error,\n            metrics_fun=metrics_fun, device=device, x_numeric_dim=x_numeric.shape[1],\n            use_sn=use_sn, image_encoder_hdim=54, image_encoder_layers=2,\n            lam_image_recon=lam_image_recon,\n            image_input_dim=image_input_dim, image_encode=image_encode,\n            dropout_ratio=dropout_ratio)\n        batch_eval_func = regressor.calc\n    else:\n        assert mode == 'normal'\n        regressor = BlendNetRegressor(\n            predictor, lossfun=F.mean_squared_error,   # lossfun_huber\n            metrics_fun=metrics_fun, device=device, x_numeric_dim=x_numeric.shape[1],\n            use_sn=use_sn, mode=mode, lam_image_recon=lam_image_recon,\n            image_input_dim=image_input_dim, image_encode=image_encode,\n            dropout_ratio=dropout_ratio)  #dropout_ratio\n        batch_eval_func = regressor.calc\n    # else:\n    #     regressor = Regressor(predictor, lossfun=F.mean_squared_error,\n    #                           metrics_fun=metrics_fun, device=device)\n    #     batch_eval_func = predictor\n\n    # Set up the optimizer.\n    optimizer = optimizers.Adam(alpha=0.001)\n    # optimizer = optimizers.MomentumSGD(lr=0.001)\n    # optimizer = optimizers.AdaDelta()\n    # optimizer = optimizers.AdaGrad()\n    # optimizer = optimizers.RMSprop()\n\n    print('optimizer', type(optimizer))\n    optimizer.setup(regressor)\n    if decay_rate > 0.:\n        print('add WeightDecay={}'.format(decay_rate))\n        optimizer.add_hook(WeightDecay(decay_rate))\n\n    # Set up the updater.\n    updater = training.StandardUpdater(\n        train_iter, optimizer, device=device, converter=converter)\n\n    # Set up the trainer.\n    trainer = training.Trainer(updater, (epoch, 'epoch'), out=out)\n    trainer.extend(E.Evaluator(valid_iter, regressor, device=device,\n                               converter=converter))\n\n    def batch_converter(batch, device=None):\n        if mode == 'normal':\n            return converter(batch, device)\n        else:\n            assert mode == 'mean'\n            x_num, x_cat, x_bert, x_image, t, indices, target_mean = converter(batch, device)\n            return x_num, x_cat, x_bert, x_image, indices, t\n    trainer.extend(QuadraticWeightedKappaEvaluator(\n        valid_iter, regressor, device=device, eval_func=batch_eval_func, name='val',\n        converter=batch_converter))\n    # trainer.extend(QuadraticWeightedKappaEvaluator(train_iter, regressor, device=device,))\n    # trainer.extend(E.snapshot(), trigger=(epoch, 'epoch'))\n\n    trainer.extend(observe_lr())\n    trainer.extend(schedule_optimizer_value(\n        # [2, 10, 20, 40], [0.005, 0.003, 0.001]))\n        # [2, 10, 25, 45, 50, 55], [0.005, 0.003, 0.001, 0.0003, 0.0001, 0.00001]))\n        [2, 10, 25, 45, 50, 55], [0.005, 0.003, 0.001, 0.0003, 0.0001, 0.00001]))\n        # [2, 10, 25, 45, 50, 55], [0.001, 0.001, 0.001, 0.0003, 0.0001, 0.00001]))\n    log_report = E.LogReport()\n    trainer.extend(log_report)\n    if image_encode:\n        if mode == 'mean':\n            trainer.extend(E.PrintReport([\n                'epoch', 'main/loss', 'main/reg_loss', 'main/reg_loss_mean', 'main/recon_loss', 'main/mae',\n                'validation/main/loss', 'validation/main/reg_loss', 'validation/main/reg_loss_mean',\n                'validation/main/recon_loss',\n                'validation/main/mae', 'val/main/qwk', 'lr',\n                'elapsed_time']))\n        else:\n            trainer.extend(E.PrintReport([\n                'epoch', 'main/loss', 'main/reg_loss', 'main/recon_loss', 'main/mae',\n                'validation/main/loss', 'validation/main/reg_loss', 'validation/main/recon_loss',\n                'validation/main/mae', 'val/main/qwk', 'lr',\n                'elapsed_time']))\n    else:\n        if mode == 'mean':\n            trainer.extend(E.PrintReport([\n                'epoch', 'main/loss', 'main/reg_loss', 'main/reg_loss_mean', 'main/mae',\n                'validation/main/loss', 'validation/main/reg_loss', 'validation/main/reg_loss_mean',\n                'validation/main/mae', 'val/main/qwk', 'lr', 'elapsed_time']))\n        else:\n            trainer.extend(E.PrintReport([\n                'epoch', 'main/loss', 'main/mae',\n                'validation/main/loss', 'validation/main/mae', 'val/main/qwk',\n                'elapsed_time']))\n\n    if not is_kaggle_kernel:\n        trainer.extend(E.ProgressBar())\n    trainer.run()\n\n    # check_error = True\n    if check_error:\n        val_pred = regressor.predict(valid, converter=converter, batchsize=batchsize)\n        if mode == 'mean':\n            assert isinstance(valid, RescuerIDMeanDataset) and valid.mode == 'eval'\n            permute_indices = numpy.argsort(numpy.array(list(chain.from_iterable(valid.rescuer_id_index_list))))\n            val_pred = val_pred[permute_indices]\n        diff = val_pred - val_target\n        diff = diff[:, 0]\n\n        import matplotlib.pyplot as plt\n        fig, ax = plt.subplots()\n        ax.scatter(val_target[:, 0], val_pred[:, 0])\n        y = val_target[:, 0]\n        ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n        ax.set_xlabel('Ground Truth')\n        ax.set_ylabel('Predicted')\n        plt.savefig(os.path.join(out, 'scatter.png'))\n        import seaborn as sns\n        df = pd.DataFrame({'pred': val_pred[:, 0], 'actual': val_target[:, 0]})\n        ax = sns.violinplot(x='actual', y='pred', data=df)\n        plt.savefig(os.path.join(out, 'pred_violin.png'))\n\n        print('saved to ', os.path.join(out, 'pred_violin.png'))\n        # from biggest error, descending order\n        indices = numpy.argsort(diff)\n        # Top 3-error for both side\n        print('val_indices', val_indices[indices[:10]])\n        print('val_indices', val_indices[indices[::-1][:10]])\n\n    # --- optr ---\n    if optr is not None:\n        with timer('predict'):\n            converter.extract_inputs = True  # HACKING\n            val_y = regressor.predict(valid, converter=converter)\n            if mode == 'mean':\n                # scatter operations...\n                assert isinstance(valid, RescuerIDMeanDataset) and valid.mode == 'eval'\n                permute_indices = numpy.argsort(numpy.array(list(chain.from_iterable(valid.rescuer_id_index_list))))\n                val_y = val_y[permute_indices]\n                # val_y = val_y[list(chain.from_iterable(valid.rescuer_id_index_list))]\n                # val_y = valid.target_mean  # DEBUG, this is answer...\n            converter.extract_inputs = False\n            if predict_y is not None:\n                predict_y[val_indices] = val_y\n        with timer('optr.fit'):\n            optr.fit(val_y, val_target)\n        coefficients = optr.coefficients()\n\n        pred_y1_rank = optr.predict(val_y, coefficients)\n        # pred_y1_rank = optr.predict(pred_y1, [0.5, 2.2, 3.2, 3.3])\n        score = cohen_kappa_score(pred_y1_rank, val_target,\n                                  labels=numpy.arange(optr.num_class),\n                                  weights='quadratic')\n        print('optimized score', score, 'coefficients', coefficients,)\n    else:\n        print('optr is not set, skip optimizing threshold...')\n        coefficients = None\n\n    return regressor, coefficients, log_report.log, score\n\n\ndef main_nn(debug, device, epoch, use_bert, use_image, num_image,\n            use_selection_gate=False, use_tfidf=False, use_sn=False,\n            dropout_ratio=0.1, decay_rate=1e-4, use_bn=False, animal_type=None,\n            cat2num=False, use_cat=True, image_type='clf', use_residual=False,\n            mode='normal', batchsize=1024, fold=4):\n    \"\"\"\n\n    Args:\n        debug:\n        device:\n        epoch:\n        use_bert:\n        use_image:\n        num_image:\n        use_selection_gate:\n        use_tfidf:\n        use_sn:\n        dropout_ratio:\n        decay_rate:\n        use_bn:\n        animal_type (int): if specified, only train specific animal_type = 'dog' or 'cat'.\n            If Negative value, both animals are trained same time.\n        cat2num (bool): If True categorical values are converted to numeric values.\n        use_cat (bbol): Use category specific Linear layer or not.\n        mode (str): Training mode type.\n            normal - normal training, regression of AdoptionSpeed.\n            mean - regression of mean AdoptionSpeed on RescuerID.\n\n    Returns:\n\n    \"\"\"\n    num_class = 5\n    print('debug', debug)\n    print('epoch', epoch, 'dropout_ratio', dropout_ratio, 'decay_rate', decay_rate)\n    print('Train data_type {}'.format(animal_type))\n\n    if animal_type < 0:\n        animal_type = None\n    # use_cat = not cat2num\n\n    # --- dataset ---\n\n    train, test, breeds, colors, states = prepare_df(debug, animal_type=animal_type)\n    pp = Preprocessor(arch='nn')\n    train, test = pp.preprocess(\n        train, test, breeds, colors, states, debug=debug, use_tfidf=use_tfidf,\n        use_metadata=False, use_sentiment=False, use_gdp=True,\n        use_rescuer_id_count=True, use_name_feature=True, use_target_encoding=False,\n        cat2num=cat2num, animal_type=animal_type, use_tfidf_cache=True,\n        tfidf_svd_components=16, num_sentiment_text=0,\n        use_sentiment2=True, use_metadata2=True, use_text=True, use_fasttext=True,\n        use_image_size=True, arch='nn', use_custom_boolean_feature=True,\n        add_pred=None)\n    target = pp.target\n    print('target', target.shape)\n    train_x_numeric = train.loc[:, pp.numeric_cols].values.astype(numpy.float32)\n    test_x_numeric = test.loc[:, pp.numeric_cols].values.astype(numpy.float32)\n    # print('num nan in numeric: ', numpy.sum(numpy.isnan(train_x_numeric), axis=0))\n    cat_dtype = numpy.float32 if cat2num else numpy.int32\n    train_x_cat = train.loc[:, pp.cat_cols].values.astype(cat_dtype)\n    # print('num nan in cat', numpy.sum(numpy.isnan(train_x_cat), axis=0))\n    test_x_cat = test.loc[:, pp.cat_cols].values.astype(cat_dtype)\n    num_cat_id = pp.num_cat_id\n    print(f'numeric_cols {pp.numeric_cols}, cat_cols {pp.cat_cols}')\n\n    # train_x_numeric, train_x_cat, target, test_x_numeric, test_x_cat, num_cat_id = preprocessing(\n    #     train, test, breeds, colors, states, debug=debug, use_tfidf=use_tfidf, use_metadata=True,\n    #     cat2num=cat2num, animal_type=animal_type, use_tfidf_cache=True,\n    #     tfidf_svd_components=128, num_sentiment_text=0)\n    if use_bert:\n        print('preprocess bert feature...')\n        train_x_bert, test_x_bert = preprocess_bert(\n            train, test, num_extract_sentence=2, layer_indices=[-1, ], device=device,\n            use_cache=True, animal_type=animal_type)\n    else:\n        print('skip bert feature')\n        train_x_bert, test_x_bert = None, None\n\n    if use_image:\n        print('preprocess image feature... {}'.format(image_type))\n        if image_type == 'clf':\n\n            # clf_arch = 'vgg16'\n            clf_arch = 'densenet'\n            # clf_arch = 'seresnext50'\n            # n_components = None if debug else 506\n            # n_components = 512\n            # n_components = 256\n            n_components = 32\n            # n_components = 16\n            if clf_arch == 'densenet':\n                train_x_image, test_x_image = preprocess_image_densenet(\n                    train, test, n_components=n_components, method='svd')\n                train_x_image = train_x_image.astype(numpy.float32)\n                test_x_image = test_x_image.astype(numpy.float32)\n            else:\n                train_x_image, test_x_image = preprocess_image(\n                    train, test, num_image=num_image, device=device, arch=clf_arch,\n                    n_components=n_components, animal_type=animal_type, use_cache=True,\n                    method='svd')\n        elif image_type == 'det':\n            det_arch = 'faster_rcnn_vgg16'  # fpn50\n            # n_components = None  # 506 was worse...\n            # n_components = 32  # 506 was worse...\n            n_components = 16  # 506 was worse...\n            train_x_image, test_x_image = preprocess_image_det(\n                train, test, num_image=num_image, device=device, arch=det_arch, use_cache=True,\n                n_components=n_components)\n            # train_x_image[numpy.isnan(train_x_image)] = 0.\n            # test_x_image[numpy.isnan(test_x_image)] = 0.\n        else:\n            raise ValueError(\"[ERROR] Unexpected value image_type={}\".format(image_type))\n    else:\n        print('skip image feature...')\n        train_x_image, test_x_image = None, None\n\n    # --- Setup CV ---\n    num_split = fold\n    random_state = 42\n    kfold_method = 'group'\n    # kfold_method = 'stratified'\n\n    # num_split = 5\n    # random_state = 1337\n    # kfold_method = 'stratified'\n\n    if kfold_method == 'stratified':\n        print('StratifiedKFold...')\n        kf = StratifiedKFold(n_splits=num_split, random_state=random_state, shuffle=True)\n        # fold_splits = kf.split(train, target)\n        fold_splits = kf.split(train_x_numeric, target)\n    elif kfold_method == 'group':\n        print('GroupKFold...')\n        kf = GroupKFold(num_split)\n        # kf.random_state = 42\n        groups = train['RescuerID'].astype('category').cat.codes.values\n        fold_splits = kf.split(train_x_numeric, target, groups)\n    else:\n        raise ValueError(\"[ERROR] Unexpected value kfold_method={}\".format(kfold_method))\n\n    optr = OptimizedRounder(num_class=num_class, method='nelder-mead')  # differential_evolution\n\n    regressor_list = []\n    coefficients_list = []\n    log_list = []\n    score_list = []\n\n    if use_selection_gate:\n        fit_fn = fit_nn_sg\n    else:\n        fit_fn = fit_nn\n\n    std_list = calc_std_list(train_x_numeric, train_x_cat, train_x_bert, train_x_image)\n    converter = BlendConverter(\n        use_cat=use_cat,\n        use_bert=use_bert,\n        use_image=use_image,\n        augmentation=True,\n        # permute_col_ratio_list=[0.12930218, 0.197565899, 0.0, 0.023249633],\n        permute_col_ratio_list=[0.15930218, 0.197565899, 0.0, 0.023249633],\n        # permute_col_ratio_list=[0.07930218, 0.107565899, 0.0, 0.],\n        # permute_col_ratio_list=[0., 0., 0.0, 0.],\n        # permute_col_ratio_list=[0.15930218, 0.107565899, 0.0, 0.],\n        num_cols_choice=False,\n        mixup_ratio=0.,\n        std_list=std_list,\n        # noise_ratio_list=[0.01, 0., 0., 0.01],\n        noise_ratio_list=[0.0, 0., 0., 0.0],\n        # noise_ratio_list=[0.1, 0.1, 0.0, 0.0],\n        mode=mode,  # [0.1, 0.1, 0.1, 0.1]\n        use_embed=not cat2num\n    )\n\n    predict_y = numpy.ones(target.shape, dtype=numpy.float32) * -1\n    for k, (train_indices, val_indices) in enumerate(fold_splits):\n        print('---- {} fold / {} ---'.format(k, num_split))\n        regressor, coefficients, log, score = fit_fn(\n            train_x_numeric, train_x_cat, target, num_cat_id,\n            train_indices, val_indices,\n            x_bert=train_x_bert, x_image=train_x_image, debug=debug, device=device,\n            epoch=epoch, optr=optr, out='{}_{}'.format(out, k), converter=converter,\n            use_sn=use_sn, decay_rate=decay_rate, dropout_ratio=dropout_ratio,\n            use_bn=use_bn, use_residual=use_residual,\n            mode=mode, train_df=train, batchsize=batchsize, predict_y=predict_y)\n\n        regressor_list.append(regressor)\n        coefficients_list.append(coefficients)\n        log_list.append(log)\n        score_list.append(score)\n\n    log_df = pd.DataFrame([log[-1] for log in log_list])\n    print('log_df mean\\n{}'.format(log_df.mean()))\n    opt_score_mean = numpy.array(score_list).mean()\n    print('opt_score_mean', opt_score_mean, 'score_list', score_list)\n\n    print('Number of un-predicted example: ', numpy.sum(predict_y <= -1))\n    with timer('optr.fit'):\n        optr.fit(predict_y, target)\n    coefficients = optr.coefficients()\n    pred_y1_rank = optr.predict(predict_y, coefficients)\n    score = cohen_kappa_score(pred_y1_rank, target,\n                              labels=numpy.arange(optr.num_class),\n                              weights='quadratic')\n    print('Total: optimized score', score, 'coefficients', coefficients, )\n\n    # --- create submission ---\n    flag_create_submission = True\n    if flag_create_submission:\n        extra_test_features = []\n        if test_x_cat is not None:\n            extra_test_features.append(test_x_cat)\n        if test_x_bert is not None:\n            extra_test_features.append(test_x_bert)\n        if test_x_image is not None:\n            extra_test_features.append(test_x_image)\n\n        test_dataset = NumpyTupleDataset(*([test_x_numeric] + extra_test_features))\n        coefficients_ = numpy.mean(numpy.array(coefficients_list), axis=0)\n        print('coefficients_', coefficients_)\n        # train_predictions = [r[0] for r in results['train']]\n        # train_predictions = optr.predict(train_predictions, coefficients_).astype(int)\n        # Counter(train_predictions)\n\n        with timer('test predict'):\n            if mode == 'normal':\n                test_predict_list = [reg.predict(test_dataset, converter=converter)\n                                     for reg in regressor_list]\n            elif mode == 'mean':\n                test_dataset = RescuerIDMeanDataset(test.copy(), test_dataset, mode='eval')\n                assert isinstance(test_dataset, RescuerIDMeanDataset) and test_dataset.mode == 'eval'\n                permute_indices = numpy.argsort(numpy.array(list(chain.from_iterable(test_dataset.rescuer_id_index_list))))\n                raise NotImplementedError\n                import IPython; IPython.embed()\n                test_predict_list = [reg.predict(test_dataset, converter=converter, batchsize=batchsize)[permute_indices]\n                                     for reg in regressor_list]\n            else:\n                raise ValueError(\"[ERROR] Unexpected value mode={}\".format(mode))\n        test_predict_mean = numpy.mean(numpy.array(test_predict_list), axis=0)\n        print('test_predict_mean', test_predict_mean.shape)\n        test_id = test['PetID']\n\n        # --- 0. raw float predictions ---\n        predict_df = pd.DataFrame({'PetID': train['PetID'], 'y': predict_y.ravel(), 't': target.ravel()})\n        predict_df.to_csv('predict_nn_train.csv', index=False)\n        print('predict_nn_train.csv created.')\n        predict_df = pd.DataFrame({'PetID': test_id, 'y': test_predict_mean.ravel()})\n        predict_df.to_csv('predict_nn_test.csv', index=False)\n        print('predict_nn.csv created.')\n\n        # --- 1. mean coefficients ---\n        coefficients_mean = numpy.mean(numpy.array(coefficients_list), axis=0)\n        print('coefficients_mean', coefficients_mean)\n        test_predictions = optr.predict(test_predict_mean, coefficients_mean).astype(int)\n        print('test_predictions counter', Counter(test_predictions))\n        submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n        submission.to_csv('submission_mean.csv', index=False)\n        print('submission_mean.csv created.')\n\n        # --- 2. validation all coefficients ---\n        print('coefficients from all validation ', coefficients)\n        test_predictions = optr.predict(test_predict_mean, coefficients).astype(int)\n        print('test_predictions counter', Counter(test_predictions))\n        submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n        submission.to_csv('submission_valcoef.csv', index=False)\n        print('submission.csv created.')\n\n        # --- 3. same histgram with train... ---\n        test_predictions = optr.fit_and_predict_by_histgram(test_predict_mean, target)\n        print('coefficients to align with train target', optr.coefficients())\n        print('test_predictions counter', Counter(test_predictions))\n        submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\n        submission.to_csv('submission.csv', index=False)\n        print('submission.csv created.')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd8e5388a8b13f120d3d1185e5ad1a2d4e4da8c1"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7dce2a5d633034885aa5c27d14a2c08378174ed7"},"cell_type":"code","source":"use_sn = False\ndropout_ratio = 0.08\ndecay_rate = 1e-3\nfold = 10\nuse_bn = False\nuse_residual = True\n\nmain_nn(debug, device, epoch, use_bert, use_image, num_image,\n        use_selection_gate=False, use_tfidf=use_tfidf, use_sn=use_sn,\n        dropout_ratio=dropout_ratio, decay_rate=decay_rate, use_bn=use_bn,\n        image_type=image_type, animal_type=-1, use_residual=use_residual,\n        mode=mode, batchsize=batchsize, fold=fold)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bed930940e5c665c18409cf63764accd0288bfe8"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb650a34b2a8b61620b956a74746084bda067d61"},"cell_type":"markdown","source":"# --- ensemble ---"},{"metadata":{"trusted":true,"_uuid":"6779cba16f611b1499ea6c56942992071dba8395"},"cell_type":"code","source":"from collections import Counter\n\nimport numpy\nimport pandas as pd\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import cohen_kappa_score\n\nimport sys\nimport os\n\nclass MeanPredictor(object):\n    def __init__(self):\n        self.coef_ = None\n\n    def fit(self, x, y):\n        # dummy, no internal parameter\n        pass\n\n    def predict(self, x):\n        if x.ndim == 2:\n            return numpy.mean(x, axis=1)\n        else:\n            raise ValueError(\"[ERROR] Unexpected value x.shape={}\".format(x.shape))\n\n            \noptr = OptimizedRounder(method='nelder-mead')\ntrain, test, breeds, colors, states = prepare_df(debug)\ndog_train_indices = (train['Type'] == 1).values\ncat_train_indices = (train['Type'] == 2).values\ndog_test_indices = (test['Type'] == 1).values\ncat_test_indices = (test['Type'] == 2).values\n\nensemble_archs = ['nn', 'lgbm', 'xgb', 'cb', 'xlearn']\n# ensemble_archs = ['lgbm', 'xgb', 'cb', 'xlearn']\n# ensemble_archs = ['nn', 'lgbm', 'xgb', 'cb']\n# ensemble_archs = ['lgbm', 'xgb', 'cb']\n# ensemble_archs = ['xgb', 'cb']\n\n# --- Train/validation check ---\npet_id = None\ntarget = None\ny_list = []\nfor model_name in ensemble_archs:\n    filepath = 'predict_{}_train.csv'.format(model_name)\n    df = pd.read_csv(filepath)\n    if pet_id is None:\n        pet_id = df['PetID'].values\n        target = df['t'].values\n    else:\n        assert numpy.alltrue(pet_id == df['PetID'].values)\n        assert numpy.alltrue(target == df['t'].values)\n    y = df['y'].values\n    rmse = numpy.sqrt(numpy.mean(numpy.square(y - target)))\n    print('model_name {}, rmse {}'.format(model_name, rmse))\n    y_list.append(y)\n\n# --- 1. Just take mean ---\npredict_y = numpy.mean(numpy.array(y_list), axis=0)\nrmse = numpy.sqrt(numpy.mean(numpy.square(predict_y - target)))\nprint('mean ensemble, rmse {}'.format(rmse))\n\n# --- 2. User ridge regression ---\n# ridge = Ridge()\nridge = MeanPredictor()\nX = numpy.array(y_list).T\nprint('X', X.shape)\nridge.fit(X, target)\npredict_y = ridge.predict(X)\nrmse = numpy.sqrt(numpy.mean(numpy.square(predict_y - target)))\nprint('ridge ensemble, rmse {}'.format(rmse))\nprint('ridge coef_ {}'.format(ridge.coef_))\n\nprint('--- optimize all ---')\nwith timer('optr.fit'):\n    optr.fit(predict_y, target)\ncoefficients1 = optr.coefficients()\nprint('coefficients1', coefficients1)\npred_y1_rank = optr.predict(predict_y, coefficients1)\nscore = cohen_kappa_score(pred_y1_rank, target,\n                          labels=numpy.arange(optr.num_class),\n                          weights='quadratic')\nprint('Total: optimized score', score, 'coefficients1', coefficients1)\nprint('predicted histogram: dog', Counter(pred_y1_rank[dog_train_indices]),\n      'cat', Counter(pred_y1_rank[cat_train_indices]))\n\n# --- if same with train histogram... ---\nprint('--- train histogram ---')\npred_y1_rank = optr.fit_and_predict_by_histgram(predict_y, target)\nscore = cohen_kappa_score(pred_y1_rank, target,\n                          labels=numpy.arange(optr.num_class),\n                          weights='quadratic')\nprint('Total: train_histgram score', score)\nprint('predicted histogram: dog', Counter(pred_y1_rank[dog_train_indices]),\n      'cat', Counter(pred_y1_rank[cat_train_indices]))\n\n# --- test dataset ---\nprint('--- test ---')\nprint('test dog', (test['Type'] == 1).sum(), 'cat', (test['Type'] == 2).sum())\n\ntest_id = None\ny_list = []\nfor model_name in ensemble_archs:\n    filepath = 'predict_{}_test.csv'.format(model_name)\n    df = pd.read_csv(filepath)\n    if test_id is None:\n        test_id = df['PetID'].values\n    else:\n        assert numpy.alltrue(test_id == df['PetID'].values)\n    y = df['y'].values\n    y_list.append(y)\n\n# predict_y = numpy.mean(numpy.array(y_list), axis=0)\nX_test = numpy.array(y_list).T\nprint('X_test', X_test.shape)\npredict_y_test = ridge.predict(X_test)\nprint('predict_y_test', predict_y_test.shape, predict_y_test)\nprint('squared error', numpy.mean(numpy.square(X_test - predict_y_test[:, None]), axis=0))\nprint('abs error', numpy.mean(numpy.abs(X_test - predict_y_test[:, None]), axis=0))\n\nprint('--- test with coefficients1, optimized by all val data ---')\ntest_predictions = optr.predict(predict_y_test, coefficients1)\nsubmission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\nsubmission.to_csv('submission_coef1.csv', index=False)\nprint('test_predictions counter', Counter(test_predictions), test_predictions)\nprint('submission_coef1.csv created.')\n\nprint('--- test with coefficients3, manual tuned from coefficients1 ---')\ncoefficients3 = coefficients1.copy()\ncoefficients3[0] = 1.66\ncoefficients3[1] = 2.13\ncoefficients3[3] = 2.85\ntest_predictions = optr.predict(predict_y_test, coefficients3)\nsubmission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\nsubmission.to_csv('submission_coef3.csv', index=False)\nprint('test_predictions counter', Counter(test_predictions), test_predictions)\nprint('submission_coef3.csv created.')\n\n# coefficients_ = coefficients.copy()\n# pred_y1_rank = optr.predict(predict_y_test, coefficients_)\nprint('--- test align histogram all ---')\ntest_predictions = optr.fit_and_predict_by_histgram(predict_y_test, target)\nprint('coefficients to align with train target', optr.coefficients())\nprint('test_predictions counter', Counter(test_predictions), test_predictions)\nsubmission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\nsubmission.to_csv('submission_histogram.csv', index=False)\nprint('submission_histogram.csv created.')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# calculate threshold for target histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/87037\n# train counter Counter({4.0: 4197, 2.0: 4037, 3.0: 3259, 1.0: 3090, 0.0: 410})\n\n# coefficients_ = coefficients.copy()\n# pred_y1_rank = optr.predict(predict_y_test, coefficients_)\nprint('--- test align histogram all ---')\ncoef = optr.calc_histogram_coef(predict_y_test, [410, 3090, 4037, 3259, 4197])\ntest_predictions = optr.predict(predict_y_test, coef)\nprint('coefficients to align with train target', coef)\nprint('test_predictions counter', Counter(test_predictions), test_predictions)\nsubmission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\nsubmission.to_csv('submission.csv', index=False)\nprint('submission.csv created.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f2460887fbb92b571f960abe310ed9d11ed07bd"},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"end_time = time()\nprint('total took {} sec'.format(end_time - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}