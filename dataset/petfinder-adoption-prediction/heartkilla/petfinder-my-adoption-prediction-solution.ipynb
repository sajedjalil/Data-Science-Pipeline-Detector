{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Kaggle [PetFinder.my Adoption Prediction](https://www.kaggle.com/c/petfinder-adoption-prediction) Competition Solution\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-media/competitions/Petfinder/PetFinder%20-%20Logo.png)\n![](https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12232719/Golden-Retriever-On-White-05.jpg)"},{"metadata":{},"cell_type":"markdown","source":"This is our solution for PetFinder.my Kaggle competition which [me](https://www.kaggle.com/aruchomu) and my teammate [Dmitry Voynov](https://www.kaggle.com/vainof) submitted. <br>\nThe solution scored 0.40767 of [Quadratic Weighted Kappa](https://stats.stackexchange.com/questions/59798/quadratic-weighted-kappa-versus-linear-weighted-kappa?rq=1) (QWK) and reached top 33% on the private leaderboard. <br>\n"},{"metadata":{},"cell_type":"markdown","source":" <a id=\"top\"></a> <br>\n## Contents\n1. [Preparations](#1)\n2. [Feature Extraction from Sentiment and Image Metadata](#2)\n3. [Text and Image Features](#3)\n4. [Modeling](#4)\n5. [Submission](#5)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> \n## 1. Preparations"},{"metadata":{"trusted":true,"_uuid":"c96de47d5eff3e66be72395071d692449f6da626"},"cell_type":"code","source":"# Dependencies\n\nimport numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom joblib import Parallel, delayed\nfrom PIL import Image\nfrom tqdm import tqdm\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.applications.densenet import preprocess_input, DenseNet121\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D, \\\n    MaxPooling1D, Dense, BatchNormalization, Dropout, Embedding, Reshape, Concatenate\nfrom tensorflow.keras import losses\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras.backend as K\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD, NMF\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\n\nimport lightgbm as lgb\n\nfrom gensim.models import KeyedVectors\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ed4b493d39e9531d5d9554ea2ddea4d0e3b6012"},"cell_type":"code","source":"# Random seed function (thanks to Benjamin Minixhofer)\n\nseed = 73\n\ndef seed_everything(seed=seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.set_random_seed(seed)\n    np.random.seed(seed)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fdb1d8b447849e45c4209cda9b773f7c46c0d15"},"cell_type":"code","source":"# Load dataframes\ntrain_df = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ntest_df = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')\n\nbreeds_df = pd.read_csv('../input/petfinder-adoption-prediction/breed_labels.csv')\ncolors_df = pd.read_csv('../input/petfinder-adoption-prediction/color_labels.csv')\nstates_df = pd.read_csv('../input/petfinder-adoption-prediction/state_labels.csv')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c321cff4e80e12ca145c37fa2dd37b376b90ae8"},"cell_type":"code","source":"# Correct possible data errors\n\n# Replace Breed1 with Breed2\ntrain_df['Breed1'].replace(0, train_df['Breed2'], inplace=True)\n\n# Replace Breed1 with 0\nids = ['1bc0f89d8', '15a206d0d', 'f8654865f', '36b20cfb5',\n       '699a81c51', '85ec1aac0','6a72cfda7'] \ntrain_df.loc[train_df['PetID'].isin(ids), 'Breed1'] = 0\n\n# Replace Breed2 with 0\nids = ['f8654865f', '699a81c51', '6a72cfda7']\ntrain_df.loc[train_df['PetID'].isin(ids), 'Breed2'] = 0\n\n# Change Type to 1\ntrain_df.loc[train_df['PetID'] == '6c399cb06', 'Type'] = 1","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"fb85a2bc9042bec614cb9013c0b63c3e2dc2d784"},"cell_type":"markdown","source":"<a id=\"2\"></a> \n## 2. Feature Extraction from Sentiment and Image Metadata"},{"metadata":{"trusted":true,"_uuid":"0755c99657bc1b9dcff628e915c831212303b792"},"cell_type":"code","source":"# Extraction functions\n\ndef get_metadata_features(pet_id, dataset):\n    \"\"\"\n    Collects the following features from the image metadata for profile images.\n    \n    1. Image resolution.\n    2. Top 3 dominant colors by score.\n    \"\"\"\n    json_path = '../input/petfinder-adoption-prediction/{}_metadata/{}-1.json'.format(dataset, pet_id)\n    image_path = '../input/petfinder-adoption-prediction/{}_images/{}-1.jpg'.format(dataset, pet_id)\n    \n    if not os.path.exists(json_path):\n        # Test sample with no profile picture\n        if os.path.exists('../input/petfinder-adoption-prediction/{}_metadata/{}-2.json'.format(dataset, pet_id)):\n            json_path = '../input/petfinder-adoption-prediction/{}_metadata/{}-2.json'.format(dataset, pet_id)\n            image_path = '../input/petfinder-adoption-prediction/{}_images/{}-2.jpg'.format(dataset, pet_id)\n        else:\n            return\n    \n    row = {}\n    \n    row['PetID'] = pet_id\n    \n    with open(json_path) as fp:\n        row_json = json.load(fp)\n    \n    try:\n        image = Image.open(image_path)\n        row['img_width'], row['img_height'] = image.size\n    except:\n        row['img_width'], row['img_height'] = np.nan, np.nan\n    \n    try:\n        colors = row_json['imagePropertiesAnnotation']['dominantColors']['colors']\n        reds, greens, blues, scores = [], [], [], []\n        for color in colors:\n            reds.append(color['color'].get('red', 0))\n            greens.append(color['color'].get('green', 0))\n            blues.append(color['color'].get('blue', 0))\n            scores.append(color.get('score', 0))\n        colors_df = pd.DataFrame({'red': reds, 'green': greens, 'blue': blues, 'score': scores})\n        row.update(dict(zip(['img_color_1_red', 'img_color_1_green', 'img_color_1_blue',\n                             'img_color_2_red', 'img_color_2_green', 'img_color_2_blue',\n                             'img_color_3_red', 'img_color_3_green', 'img_color_3_blue'],\n                            colors_df.sort_values('score', ascending=False).iloc[:3, :-1].values.ravel())))\n    except:\n        row.update(dict(zip(['img_color_1_red', 'img_color_1_green', 'img_color_1_blue',\n                             'img_color_2_red', 'img_color_2_green', 'img_color_2_blue',\n                             'img_color_3_red', 'img_color_3_green', 'img_color_3_blue'], [np.nan] * 9)))\n    \n    return row\n\n\ndef get_sentiment_features(filename, dataset):\n    \"\"\"\n    Collects the following features from the sentiment data.\n    \n    1. Sentences scores mean and variance weighted by magnitude.\n    2. Document sentiment magnitude and score.\n    \"\"\"\n    path = '../input/petfinder-adoption-prediction/' + dataset + '_sentiment'\n    with open(os.path.join(path, filename)) as fp:\n        row_json = json.load(fp)\n    row = {}\n\n    row['PetID'] = filename.replace('.json', '')\n    \n    try:\n        magnitudes, scores = [], []\n        for sentence in row_json['sentences']:\n            magnitudes.append(sentence['sentiment']['magnitude'])\n            scores.append(sentence['sentiment']['score'])\n        sentences_df = pd.DataFrame({'magnitude': magnitudes, 'score': scores})\n        sentences_df['score'] = sentences_df['magnitude'] * sentences_df['score']\n        epsilon = np.finfo(np.float32).eps\n        sentences_df['score'] = sentences_df['magnitude'] / (sentences_df['magnitude'].sum() + epsilon)\n        row['sentence_score_mean'] = sentences_df['score'].mean()\n        row['sentence_score_var'] = sentences_df['score'].var()\n    except:\n        row['sentence_score_mean'] = np.nan\n        row['sentence_score_var'] = np.nan \n\n    try:\n        row['document_magnitude'] = row_json['documentSentiment']['magnitude']\n        row['document_score'] = row_json['documentSentiment']['score']\n    except:\n        row['document_magnitude'] = np.nan\n        row['document_score'] = np.nan\n    \n    return row\n\n# Use parallel processing\ntrain_metadata_rows = Parallel(n_jobs=-1, verbose=2)(\n    delayed(get_metadata_features)(pet_id, 'train') for pet_id in train_df['PetID'])\ntrain_metadata_df = pd.DataFrame([row for row in train_metadata_rows if row is not None])\ntest_metadata_rows = Parallel(n_jobs=-1, verbose=2)(\n    delayed(get_metadata_features)(pet_id, 'test') for pet_id in test_df['PetID'])\ntest_metadata_df = pd.DataFrame([row for row in test_metadata_rows if row is not None])\n\ntrain_sentiment_df = pd.DataFrame(Parallel(n_jobs=-1, verbose=2)(\n    delayed(get_sentiment_features)(filename,'train') for filename in os.listdir(\n        '../input/petfinder-adoption-prediction/train_sentiment')))\ntest_sentiment_df = pd.DataFrame(Parallel(n_jobs=-1, verbose=2)(\n    delayed(get_sentiment_features)(filename, 'test') for filename in os.listdir(\n        '../input/petfinder-adoption-prediction/test_sentiment')))\n\n# Merge everything\ntrain_merged = pd.merge(train_df, train_metadata_df, how='left', on='PetID')\ntrain_merged = pd.merge(train_merged, train_sentiment_df, how='left', on='PetID')\ntest_merged = pd.merge(test_df, test_metadata_df, how='left', on='PetID')\ntest_merged = pd.merge(test_merged, test_sentiment_df, how='left', on='PetID')","execution_count":5,"outputs":[{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    4.0s\n[Parallel(n_jobs=-1)]: Done 2199 tasks      | elapsed:   12.9s\n[Parallel(n_jobs=-1)]: Done 6259 tasks      | elapsed:   29.6s\n[Parallel(n_jobs=-1)]: Done 11919 tasks      | elapsed:   52.0s\n[Parallel(n_jobs=-1)]: Done 14993 out of 14993 | elapsed:  1.1min finished\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done 1054 tasks      | elapsed:    4.4s\n[Parallel(n_jobs=-1)]: Done 3972 out of 3972 | elapsed:   16.2s finished\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done 2132 tasks      | elapsed:    4.9s\n[Parallel(n_jobs=-1)]: Done 10844 tasks      | elapsed:   25.0s\n[Parallel(n_jobs=-1)]: Done 14442 out of 14442 | elapsed:   32.9s finished\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done 2396 tasks      | elapsed:    5.4s\n[Parallel(n_jobs=-1)]: Done 3865 out of 3865 | elapsed:    8.4s finished\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"882a946ee7b72fb1951346b59277af2d992be1c0"},"cell_type":"code","source":"# New features\n\n# Add name length\ntrain_merged['name_len'] = train_merged['Name'].map(len, na_action='ignore')\ntest_merged['name_len'] = test_merged['Name'].map(len, na_action='ignore')\n\n# Add description length\ntrain_merged['desc_len'] = train_merged['Description'].map(len, na_action='ignore')\ntest_merged['desc_len'] = test_merged['Description'].map(len, na_action='ignore')\n\n# Add RescuerID count\ntrain_merged['rescuer_count'] = train_merged['RescuerID'].replace(train_merged.groupby('RescuerID').size())\ntest_merged['rescuer_count'] = test_merged['RescuerID'].replace(test_merged.groupby('RescuerID').size())","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a> \n## 3. Text and Image Features"},{"metadata":{"_uuid":"edc9c88fed42fcf74b039f15f605758516094822"},"cell_type":"markdown","source":"### 3.1. Text Features"},{"metadata":{"trusted":true,"_uuid":"4515255ce17a21a21f06cc23bb33193f25bf4d7a"},"cell_type":"code","source":"# We simply average pretrained FastText vectors for description\n\nmodel = KeyedVectors.load_word2vec_format('../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec')\n\npet_ids = train_df[~train_df['Description'].isna()]['PetID']\nvects = []\nfound_pet_ids = []\nfor pet_id in pet_ids:\n    desc = train_df[train_df['PetID'] == pet_id]['Description'].values[0].split(' ')\n    word_vectors = []\n    for word in desc:\n        try:\n            word_vectors.append(model.get_vector(word))\n        except KeyError:\n            pass\n    if word_vectors:\n        mean_vect = np.mean(word_vectors, axis=0)\n        vects.append(mean_vect)\n        found_pet_ids.append(pet_id)\nfasttext_train_df = pd.DataFrame(np.array(vects)).add_prefix('fasttext_')\nfasttext_train_df['PetID'] = found_pet_ids\ntrain_merged = pd.merge(train_merged, fasttext_train_df, how='left', on='PetID')\n\npet_ids = test_df[~test_df['Description'].isna()]['PetID']\nvects = []\nfound_pet_ids = []\nfor pet_id in pet_ids:\n    desc = test_df[test_df['PetID'] == pet_id]['Description'].values[0].split(' ')\n    word_vectors = []\n    for word in desc:\n        try:\n            word_vectors.append(model.get_vector(word))\n        except KeyError:\n            pass\n    if word_vectors:\n        mean_vect = np.mean(word_vectors, axis=0)\n        vects.append(mean_vect)\n        found_pet_ids.append(pet_id)\nfasttext_test_df = pd.DataFrame(np.array(vects)).add_prefix('fasttext_')\nfasttext_test_df['PetID'] = found_pet_ids\ntest_merged = pd.merge(test_merged, fasttext_test_df, how='left', on='PetID')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e04a93d7b124a3c8f8531f6b3b2344cc544bcfe"},"cell_type":"code","source":"text_columns = ['Description']\n\n# Fill nans with empty text\ntrain_merged[text_columns] = train_merged[text_columns].fillna('')\ntest_merged[text_columns] = test_merged[text_columns].fillna('')\n\n# Text feature extractor class\n# We use TF-IDF vectorizer and then extract SVD and NMF vectors with 13 components each\n\nclass TextFeatureExtractor():\n    \"\"\"Extracts text features from text columns.\"\"\"\n    def __init__(self, n_components):\n        self.tfidf = TfidfVectorizer(min_df=2, max_features=None,\n                          strip_accents='unicode', analyzer='word', token_pattern='\\w+',\n                          ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1)\n        self.svd = TruncatedSVD(n_components=n_components, random_state=seed)\n        self.nmf = NMF(n_components=n_components, random_state=seed)\n        \n    def fit_transform(self, X_text):\n        text_features = []\n        for col in X_text.columns:\n            tfidf_col = self.tfidf.fit_transform(X_text[col])\n            \n            svd_col = self.svd.fit_transform(tfidf_col)\n            svd_col = pd.DataFrame(svd_col)\n            svd_col = svd_col.add_prefix('SVD_{}_'.format(col))\n            text_features.append(svd_col)\n            \n            nmf_col = self.nmf.fit_transform(tfidf_col)\n            nmf_col = pd.DataFrame(nmf_col)\n            nmf_col = nmf_col.add_prefix('NMF_{}_'.format(col))\n            text_features.append(nmf_col)\n            \n        text_features = pd.concat(text_features, axis=1)\n        \n        return text_features\n    \n    def transform(self, X_text):\n        text_features = []\n        for col in X_text.columns:\n            tfidf_col = self.tfidf.transform(X_text[col])\n            \n            svd_col = self.svd.transform(tfidf_col)\n            svd_col = pd.DataFrame(svd_col)\n            svd_col = svd_col.add_prefix('SVD_{}_'.format(col))\n            text_features.append(svd_col)\n            \n            nmf_col = self.nmf.transform(tfidf_col)\n            nmf_col = pd.DataFrame(nmf_col)\n            nmf_col = nmf_col.add_prefix('NMF_{}_'.format(col))\n            text_features.append(nmf_col)\n            \n        text_features = pd.concat(text_features, axis=1)\n        \n        return text_features\n\n    \ntext_feature_extractor = TextFeatureExtractor(n_components=13)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"28ea1a7f8c4cb7cbb2137be64f10a20bb1df679a"},"cell_type":"markdown","source":" ### 3.2 Image Features"},{"metadata":{"trusted":true,"_uuid":"6f9f66e8a47769c3230dd62c6bc2cb63ee1b8e7d"},"cell_type":"code","source":"# We extract image features using DenseNet121 and apply Average Pooling\n# with window_size=4 for profile images and window_size=8 for second images.\n\nweights_path = '../input/densenet121weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nclass ImageFeatureExtractor():\n    def __init__(self,\n                 shape=[256, 256, 3],\n                 average_pooling_window=4):\n        self.shape = shape\n        self.size = self.shape[:2]\n        input_tensor = Input(shape)\n        densenet = DenseNet121(input_tensor=input_tensor,\n                               weights=weights_path,\n                               include_top=False)\n        out = densenet.output\n        out = GlobalAveragePooling2D()(out)\n        out = Lambda(lambda x: K.expand_dims(x, axis=-1))(out)\n        if average_pooling_window:\n            out = AveragePooling1D(average_pooling_window)(out)\n        out = Lambda(lambda x: x[:,:,0])(out)\n        \n        self.model = Model(input_tensor, out)\n        self.feats_shape = list(map(int, self.model.output.shape[1:]))\n\n    def resize_to_square(self, img):\n        return img.resize(self.size) \n\n    def resize_saving_ratio(self, img):\n        # works if self.size represents a square\n        # resize initial image\n        max_dim = max(img.width, img.height)\n        k = self.size[0] / max_dim\n        width = int(img.width * k)\n        height = int(img.height * k)\n        img = img.resize([width, height])\n        # concat with black rectangle\n        res_img = Image.new('RGB', self.size)\n        res_img.paste(img, (0, 0))\n        return res_img\n\n    def load_image_by_path(self, filepath, resize_method='square'):\n        img = Image.open(filepath)\n        if resize_method == 'square':\n            img = self.resize_to_square(img)\n        else:\n            img = self.resize_saving_ratio(img)\n        img = np.array(img).astype(np.float32)\n        img = preprocess_input(img)\n        if len(img.shape) == 2:\n            img = np.repeat(np.expand_dims(img, axis=2), repeats=3, axis=2)\n        return img\n\n    def extract(self, filepath, resize_method='square'):\n        img = self.load_image_by_path(filepath, resize_method='square')\n        return self.model.predict(np.expand_dims(img, axis=0))\n\n    def extract_all(self, filepaths, batch_size=16, resize_method='square'):\n        res_feats = np.empty(shape=[0]+self.feats_shape, dtype=np.float32)\n        num_batches = int(np.ceil(len(filepaths) / batch_size))\n        for it in tqdm(range(num_batches)):\n            batch_filepaths = filepaths[it * batch_size: (it + 1) * batch_size]\n            batch = []\n            for fp in batch_filepaths:\n                img = self.load_image_by_path(fp, resize_method=resize_method)\n                batch.append(img)\n            batch = np.array(batch)\n            feats = self.model.predict(batch)\n            res_feats = np.append(res_feats, feats, axis=0)\n        return res_feats\n\n\ndef get_image_filepaths(pet_ids, dataset, img_number):\n    filepaths = []\n    found_pet_ids = []\n    for pet_id in pet_ids:\n        path = '../input/petfinder-adoption-prediction/{}_images/{}-{}.jpg'.format(dataset,\n                                                                                   pet_id,\n                                                                                   img_number)\n        if os.path.exists(path):\n            filepaths.append(path)\n            found_pet_ids.append(pet_id)\n        elif os.path.exists('../input/petfinder-adoption-prediction/{}_images/{}-2.jpg'.format(dataset, pet_id)):\n            path = '../input/petfinder-adoption-prediction/{}_images/{}-2.jpg'.format(dataset,\n                                                                                      pet_id)\n            filepaths.append(path)\n            found_pet_ids.append(pet_id)\n    return filepaths, found_pet_ids\n\n# Profile images\nimage_feature_extractor = ImageFeatureExtractor()\n\ntrain_img_filepaths, train_found_pet_ids = get_image_filepaths(train_df['PetID'], 'train', 1)\ntest_img_filepaths, test_found_pet_ids = get_image_filepaths(test_df['PetID'], 'test', 1)\n\ntrain_img_feats = image_feature_extractor.extract_all(train_img_filepaths,\n                                                      resize_method='square')\ntrain_img_feats_df = pd.DataFrame(train_img_feats).add_prefix('img_feat_')\ntrain_img_feats_df['PetID'] = train_found_pet_ids\ntest_img_feats = image_feature_extractor.extract_all(test_img_filepaths,\n                                                     resize_method='square')\ntest_img_feats_df = pd.DataFrame(test_img_feats).add_prefix('img_feat_')\ntest_img_feats_df['PetID'] = test_found_pet_ids\n    \ntrain_merged = pd.merge(train_merged, train_img_feats_df, how='left', on='PetID')\ntest_merged = pd.merge(test_merged, test_img_feats_df, how='left', on='PetID')","execution_count":9,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 916/916 [02:31<00:00,  4.77it/s]\n100%|██████████| 242/242 [00:34<00:00,  6.05it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"8b5aa6b3648f0d16d9fd6b6189d18df79662b2c3"},"cell_type":"code","source":"# Second images\nimage_feature_extractor = ImageFeatureExtractor(average_pooling_window=8)\n\ntrain_img_filepaths, train_found_pet_ids = get_image_filepaths(train_df['PetID'], 'train', 2)\ntest_img_filepaths, test_found_pet_ids = get_image_filepaths(test_df['PetID'], 'test', 2)\n\ntrain_img_feats = image_feature_extractor.extract_all(train_img_filepaths,\n                                                      resize_method='square')\ntrain_img_feats_df = pd.DataFrame(train_img_feats).add_prefix('img2_feat_')\ntrain_img_feats_df['PetID'] = train_found_pet_ids\ntest_img_feats = image_feature_extractor.extract_all(test_img_filepaths,\n                                                     resize_method='square')\ntest_img_feats_df = pd.DataFrame(test_img_feats).add_prefix('img2_feat_')\ntest_img_feats_df['PetID'] = test_found_pet_ids\n    \ntrain_merged = pd.merge(train_merged, train_img_feats_df, how='left', on='PetID')\ntest_merged = pd.merge(test_merged, test_img_feats_df, how='left', on='PetID')","execution_count":10,"outputs":[{"output_type":"stream","text":"100%|██████████| 724/724 [02:11<00:00,  4.42it/s]\n100%|██████████| 183/183 [00:31<00:00,  4.88it/s]\n","name":"stderr"}]},{"metadata":{"_uuid":"92306b593c87bc8bf9657c1509082cbce0fbd96f"},"cell_type":"markdown","source":"<a id=\"4\"></a> \n## 4. Modeling"},{"metadata":{"_uuid":"919d40b68e5c86b3c362ecdf8d85a7d527fd7c54"},"cell_type":"markdown","source":"### 4.1. Metrics"},{"metadata":{"trusted":true,"_uuid":"8f72c061680000f0bd7207b353c122a05f2c437f"},"cell_type":"code","source":"# Regression objective\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\n# Competition metric\ndef qwk(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"f3d1d454bdd1536514c7e099019252e57f3472db"},"cell_type":"markdown","source":"### 4.2. Thresholds Optimization"},{"metadata":{"trusted":true,"_uuid":"db578b97008e3f93929ee3f142b2b51a4354a35d"},"cell_type":"code","source":"# We tried different rounding techniques for threshold optimization.\n# For us rounding by following train distribution gave best results.\n\ndef get_thresholds_from_dist(y_true, y_pred):\n    \"\"\"Calculates thresholds for raw predictions\n    so as to follow the true distribution.\n    \"\"\"\n    idxs = np.cumsum(np.bincount(y_true))[:-1]\n    idxs = (idxs * y_pred.size / y_true.size).astype(int)\n    return np.sort(y_pred)[idxs]\n\ndef allocate_to_rate(y_pred, thresholds):\n    \"\"\"Allocates raw predictions to adoption rates.\"\"\"\n    rates = np.zeros(y_pred.size, dtype=int)\n    for i in range(4):\n        rates[y_pred >= thresholds[i]] = i + 1\n    return rates","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"0cba9505fd71c636de1ec369a4592deb213f5cdb"},"cell_type":"markdown","source":"### 4.3. Training"},{"metadata":{},"cell_type":"markdown","source":"#### 4.3.1 Neural Net Embeddings\nWe trained a neural net with embeddings for some categorical features. <br>\nWe then used the embeddings to train the LightGBM model. <br>\nThis part was mainly done by my teammate."},{"metadata":{"trusted":true,"_uuid":"0efe5a42f28bed15ef2dfadcae74e44e9b5b34c7","scrolled":true},"cell_type":"code","source":"# Final datasets arrangement\n\nX_train = train_merged.drop(columns=['PetID', 'AdoptionSpeed'])\ny_train = train_merged['AdoptionSpeed']\n\nX_test = test_merged.drop(columns=['PetID'])\n\n# We also add the most frequent breed of each rescuer as feature.\nX_train['rescuer_breed_mode'] = X_train['RescuerID'].map(X_train.groupby('RescuerID')['Breed1'].agg(\n    lambda x:x.value_counts().index[0]))\nX_test['rescuer_breed_mode'] = X_test['RescuerID'].map(X_test.groupby('RescuerID')['Breed1'].agg(\n    lambda x:x.value_counts().index[0]))\n\ncat_feats = ['Type', 'Breed1', 'Breed2', 'Vaccinated',\n             'Dewormed', 'Sterilized', 'State', 'rescuer_breed_mode']\n\nX_train = X_train.drop(columns=['Name', 'RescuerID', 'Description'])\nX_test = X_test.drop(columns=['Name', 'RescuerID', 'Description'])","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some useful dicts\n\nonehot_feats = ['Type', 'Gender',\n             'Color1', 'Color2', 'Color3', 'Vaccinated',\n             'Dewormed', 'Sterilized']\nonehot_sizes = dict(X_train[onehot_feats].nunique())\nonehot_sizes['Color2'] = onehot_sizes['Color1']\nonehot_sizes['Color3'] = onehot_sizes['Color1']\ncat_feats = ['Breed1', 'Breed2', 'rescuer_breed_mode', 'State']\nX_concat = pd.concat([X_train, X_test])\nembedding_sizes = {\n    'Breed1': 32,\n    'Breed2': 32,\n    'rescuer_breed_mode': 32,\n    'State': 8\n}\ncat_feats_sizes = {\n    'Breed1': X_concat['Breed1'].nunique(),\n    'Breed2': X_concat['Breed2'].nunique(),\n    'rescuer_breed_mode': X_concat['rescuer_breed_mode'].nunique(),\n    'State': X_concat['State'].nunique()\n}\n\ncat_feats_mappings = {}\nfor cat_feat in cat_feats:\n    mapping = {}\n    vals = X_concat[cat_feat].unique()\n    vals.sort()\n    for i, feat in enumerate(vals):\n        mapping[feat] = i\n    cat_feats_mappings[cat_feat] = mapping\n\nimg_feats = ['img_feat_{}'.format(i) for i in range(256)]\ntext_feats = ['fasttext_{}'.format(i) for i in range(300)]\nnumerical_feats = [col for col in X_train.columns \n                   if not col in img_feats and\n                   not col in text_feats and\n                   not col in onehot_feats and\n                   not col in cat_feats]","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numerical feats\nnum_scaler = StandardScaler()\nX_train[numerical_feats] = num_scaler.fit_transform(X_train[numerical_feats])\nX_test[numerical_feats] = num_scaler.transform(X_test[numerical_feats])\n\n# Image feats\nimg_scaler = StandardScaler()\nX_train[img_feats] = img_scaler.fit_transform(X_train[img_feats])\nX_test[img_feats] = img_scaler.transform(X_test[img_feats])\n\n# Text feats\ntext_scaler = StandardScaler()\nX_train[text_feats] = text_scaler.fit_transform(X_train[text_feats])\nX_test[text_feats] = text_scaler.transform(X_test[text_feats])\n\nX_train[X_train.isna()] = 0\nX_test[X_test.isna()] = 0","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    K.clear_session()\n    # Numerical feats\n    num_input = Input(shape=[len(numerical_feats)])\n\n    num_out = Dense(32, activation='relu')(num_input)\n    num_out = BatchNormalization()(num_out)\n    num_out = Dropout(rate=0.66)(num_out)\n\n    # Image feats\n    img_input = Input(shape=[256])\n\n    img_out = Lambda(lambda x: K.expand_dims(x, axis=-1))(img_input)\n    img_out = AveragePooling1D(4)(img_out)\n    img_out = Lambda(lambda x: x[:,:,0])(img_out)\n    img_out = Dense(128, activation='relu')(img_out)\n    img_out = BatchNormalization()(img_out)\n    img_out = Dropout(rate=0.66)(img_out)\n\n    # Text feats\n    text_input = Input(shape=[300])\n\n    text_out = Dense(128, activation='relu')(text_input)\n    text_out = BatchNormalization()(text_out)\n    text_out = Dropout(rate=0.66)(text_out)\n\n    # Categorical feats\n    cat_inputs = []\n    cat_outs = []\n    for cat_feat in cat_feats:\n        cat_input = Input(shape=[1])\n\n        cat_out = Embedding(input_dim=cat_feats_sizes[cat_feat],\n                            output_dim=embedding_sizes[cat_feat],\n                            input_length=1)(cat_input)\n        cat_out = Reshape(target_shape=[embedding_sizes[cat_feat]])(cat_out)\n        cat_out = Dense(embedding_sizes[cat_feat], activation='relu')(cat_out)\n        cat_out = BatchNormalization()(cat_out)\n        cat_out = Dropout(rate=0.66)(cat_out)\n\n        cat_inputs.append(cat_input)\n        cat_outs.append(cat_out)\n\n    feat_inputs = []\n    feat_outs = []\n    for onehot_feat in onehot_feats:\n        feat_input = Input(shape=[onehot_sizes[onehot_feat]])\n\n        feat_out = Dense(8, activation='relu')(feat_input)\n        feat_out = BatchNormalization()(feat_out)\n        feat_out = Dropout(rate=0.66)(feat_out)\n\n        feat_inputs.append(feat_input)\n        feat_outs.append(feat_out)\n\n    cat_outs += feat_outs\n    cats_out = Concatenate()(cat_outs)\n    cats_out = Dense(64, activation='relu')(cats_out)\n    cats_out = BatchNormalization()(cats_out)\n    cats_out = Dropout(rate=0.66)(cats_out)\n\n    # Concatenate dense outputs from different features\n    out = Concatenate()([num_out, img_out, text_out, cats_out])\n    out = Dense(192, activation='relu')(out)\n    out = BatchNormalization()(out)\n    out = Dropout(rate=0.66)(out)\n    out = Dense(64, activation='relu')(out)\n    out = BatchNormalization()(out)\n    out = Dropout(rate=0.66)(out)\n    out = Dense(1)(out)\n\n    inputs = [num_input] + [img_input] + [text_input] + cat_inputs + feat_inputs\n    outputs = [out]\n    model = Model(inputs=inputs,\n                  outputs=outputs)\n\n    return model","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transforming data\ntrain_num_data = X_train[numerical_feats].values\ntrain_img_data = X_train[img_feats].values\ntrain_text_data = X_train[text_feats].values\ntrain_cat_data = X_train[cat_feats].values.T\n\ntrain_onh_data = []\n# Mapping onehot categories to vectors\nfor onh in onehot_feats:\n    vals = X_train[onh].values\n    vals = to_categorical(np.clip(vals - 1, 0, np.inf).astype(np.uint8), num_classes=onehot_sizes[onh])\n    train_onh_data.append(vals)\n\n# Mapping cat_feats using cat_feats_mappings\nfor i, cat_feat in enumerate(cat_feats):\n    train_feats = train_cat_data[i]\n    for j in range(len(train_feats)):\n        train_feats[j] = cat_feats_mappings[cat_feat][train_feats[j]]","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape to list of 15 arrays\ntrain_data = \\\n[train_num_data] + \\\n[train_img_data] + \\\n[train_text_data] + \\\n[d for d in train_cat_data] + \\\ntrain_onh_data","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transforming data\ntest_num_data = X_test[numerical_feats].values\ntest_img_data = X_test[img_feats].values\ntest_text_data = X_test[text_feats].values\ntest_cat_data = X_test[cat_feats].values.T\n\n# categories range should start from 0\n\ntest_onh_data = []\n# Mapping onehot categories to vectors\nfor onh in onehot_feats:\n    vals = X_test[onh].values\n    vals = to_categorical(np.clip(vals - 1, 0, np.inf).astype(np.uint8), num_classes=onehot_sizes[onh])\n    test_onh_data.append(vals)\n\n# Mapping cat_feats using cat_feats_mappings\nfor i, cat_feat in enumerate(cat_feats):\n    test_feats = test_cat_data[i]\n    for j in range(len(test_feats)):\n        test_feats[j] = cat_feats_mappings[cat_feat][test_feats[j]]","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape to list of 15 arrays\ntest_data = \\\n[test_num_data] + \\\n[test_img_data] + \\\n[test_text_data] + \\\n[d for d in test_cat_data] + \\\ntest_onh_data","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse_loss(y_true, y_pred):\n    diff = y_true - y_pred\n    return K.sqrt(K.mean(K.square(diff)))\n\ndef map_to_int(y_true, y_pred, preds):\n    thresholds = get_thresholds_from_dist(y_true, y_pred)\n    return allocate_to_rate(preds, thresholds)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CV\nseed_everything()\n\nn_splits = 5\nearly_stopping_steps = 5\nepochs = 100\n\nX_train = train_data\nX_test = test_data\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               min_delta=1e-4,\n                               patience=early_stopping_steps,\n                               restore_best_weights=True)\ncallbacks = [early_stopping]\n\ngr_kfold_split = GroupKFold(n_splits=n_splits).split([0] * len(train_df),\n                                              y_train,\n                                              groups=train_df['RescuerID'])\n\noof_train = np.zeros(shape=[len(train_df)])\noof_test = np.zeros(shape=[len(test_df), n_splits])\n\nqwks = []\nrmses = []\n\nembeddingses = {}\nfor cat_feat in cat_feats:\n    embeddingses[cat_feat] = []\n    \nfor i, (train_inds, test_inds) in enumerate(gr_kfold_split):\n    print('---- Fold {} ----'.format(i))\n\n    X_tr = []\n    X_val = []\n    for X_inp in X_train:\n        X_tr.append(X_inp[train_inds])\n        X_val.append(X_inp[test_inds])\n        \n    y_tr = np.array(y_train)[train_inds]\n    y_val = np.array(y_train)[test_inds]\n          \n    model = get_model()\n    model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n                  loss='mse')\n    \n    model.fit(X_tr, y_tr,\n              batch_size=32,\n              validation_data=(X_val, y_val),\n              epochs=epochs,\n              callbacks=callbacks)\n    \n    embedding_layers = [l for l in model.layers if isinstance(l, Embedding)]\n    for cat_feat, emb_layer in zip(cat_feats, embedding_layers):\n        embeddingses[cat_feat].append(emb_layer.get_weights()[0])\n    \n    tr_pred = model.predict(X_tr)\n    val_pred = model.predict(X_val)\n    \n    tr_pred = np.squeeze(tr_pred)\n    val_pred = np.squeeze(val_pred)\n    \n    tr_rates = map_to_int(y_tr, tr_pred, tr_pred)\n    val_rates = map_to_int(y_tr, tr_pred, val_pred)\n    \n    tr_rmse = rmse(y_tr, tr_pred)\n    tr_qwk = qwk(y_tr, tr_rates)\n    \n    print('TR___RMSE: {:7.5F}___QWK: {:7.5F}'.format(tr_rmse, tr_qwk))\n    \n    val_rmse = rmse(y_val, val_pred)\n    val_qwk = qwk(y_val, val_rates)\n    \n    print('VAL___RMSE: {:7.5F}___QWK: {:7.5F}'.format(val_rmse, val_qwk))\n    \n# Out-of-fold predictions\n    oof_train[test_inds] = val_pred\n    oof_test_pred = model.predict(X_test)\n    oof_test_pred = np.squeeze(oof_test_pred)\n    oof_test[:, i] = oof_test_pred\n    \n    qwks.append(val_qwk)\n    rmses.append(val_rmse)\n    \nprint('QWK CV: {} +/- {}'.format(np.mean(qwks), np.std(qwks)))\nprint('RMSE CV: {} +/- {}'.format(np.mean(rmses), np.std(rmses)))\n\nfor cat_feat in cat_feats:\n    embeddingses[cat_feat] = np.mean(np.array(embeddingses[cat_feat]), axis=0)","execution_count":31,"outputs":[{"output_type":"stream","text":"---- Fold 0 ----\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 11994 samples, validate on 2999 samples\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/100\n11994/11994 [==============================] - 13s 1ms/sample - loss: 2.2381 - val_loss: 1.2966\nEpoch 2/100\n11994/11994 [==============================] - 8s 654us/sample - loss: 1.4388 - val_loss: 1.2199\nEpoch 3/100\n11994/11994 [==============================] - 8s 659us/sample - loss: 1.3212 - val_loss: 1.2180\nEpoch 4/100\n11994/11994 [==============================] - 8s 660us/sample - loss: 1.2689 - val_loss: 1.1841\nEpoch 5/100\n11994/11994 [==============================] - 8s 663us/sample - loss: 1.2285 - val_loss: 1.1757\nEpoch 6/100\n11994/11994 [==============================] - 8s 653us/sample - loss: 1.1985 - val_loss: 1.1673\nEpoch 7/100\n11994/11994 [==============================] - 8s 686us/sample - loss: 1.1786 - val_loss: 1.1646\nEpoch 8/100\n11994/11994 [==============================] - 9s 710us/sample - loss: 1.1674 - val_loss: 1.1796\nEpoch 9/100\n11994/11994 [==============================] - 8s 701us/sample - loss: 1.1639 - val_loss: 1.1606\nEpoch 10/100\n11994/11994 [==============================] - 9s 727us/sample - loss: 1.1659 - val_loss: 1.1623\nEpoch 11/100\n11994/11994 [==============================] - 8s 664us/sample - loss: 1.1542 - val_loss: 1.1781\nEpoch 12/100\n11994/11994 [==============================] - 8s 660us/sample - loss: 1.1413 - val_loss: 1.1610\nEpoch 13/100\n11994/11994 [==============================] - 8s 658us/sample - loss: 1.1486 - val_loss: 1.1744\nEpoch 14/100\n11994/11994 [==============================] - 9s 713us/sample - loss: 1.1311 - val_loss: 1.1726\nTR___RMSE: 1.01909___QWK: 0.51964\nVAL___RMSE: 1.07731___QWK: 0.36042\n---- Fold 1 ----\nTrain on 11994 samples, validate on 2999 samples\nEpoch 1/100\n11994/11994 [==============================] - 13s 1ms/sample - loss: 2.2240 - val_loss: 1.3337\nEpoch 2/100\n11994/11994 [==============================] - 9s 712us/sample - loss: 1.4126 - val_loss: 1.2593\nEpoch 3/100\n11994/11994 [==============================] - 8s 656us/sample - loss: 1.3263 - val_loss: 1.1895\nEpoch 4/100\n11994/11994 [==============================] - 8s 658us/sample - loss: 1.2751 - val_loss: 1.2345\nEpoch 5/100\n11994/11994 [==============================] - 8s 671us/sample - loss: 1.2360 - val_loss: 1.1836\nEpoch 6/100\n11994/11994 [==============================] - 8s 665us/sample - loss: 1.2045 - val_loss: 1.1696\nEpoch 7/100\n11994/11994 [==============================] - 8s 660us/sample - loss: 1.1810 - val_loss: 1.1522\nEpoch 8/100\n11994/11994 [==============================] - 8s 660us/sample - loss: 1.1678 - val_loss: 1.1674\nEpoch 9/100\n11994/11994 [==============================] - 8s 658us/sample - loss: 1.1648 - val_loss: 1.1599\nEpoch 10/100\n11994/11994 [==============================] - 8s 664us/sample - loss: 1.1627 - val_loss: 1.1591\nEpoch 11/100\n11994/11994 [==============================] - 8s 690us/sample - loss: 1.1493 - val_loss: 1.1757\nEpoch 12/100\n11994/11994 [==============================] - 9s 761us/sample - loss: 1.1396 - val_loss: 1.1795\nTR___RMSE: 1.02436___QWK: 0.48312\nVAL___RMSE: 1.07343___QWK: 0.40456\n---- Fold 2 ----\nTrain on 11994 samples, validate on 2999 samples\nEpoch 1/100\n11994/11994 [==============================] - 12s 1ms/sample - loss: 2.2231 - val_loss: 1.2813\nEpoch 2/100\n11994/11994 [==============================] - 8s 656us/sample - loss: 1.4097 - val_loss: 1.2172\nEpoch 3/100\n11994/11994 [==============================] - 8s 658us/sample - loss: 1.3305 - val_loss: 1.1807\nEpoch 4/100\n11994/11994 [==============================] - 8s 668us/sample - loss: 1.2695 - val_loss: 1.1856\nEpoch 5/100\n11994/11994 [==============================] - 8s 667us/sample - loss: 1.2244 - val_loss: 1.1688\nEpoch 6/100\n11994/11994 [==============================] - 8s 666us/sample - loss: 1.1977 - val_loss: 1.1749\nEpoch 7/100\n11994/11994 [==============================] - 8s 692us/sample - loss: 1.1836 - val_loss: 1.1677\nEpoch 8/100\n11994/11994 [==============================] - 9s 711us/sample - loss: 1.1627 - val_loss: 1.1664\nEpoch 9/100\n11994/11994 [==============================] - 8s 662us/sample - loss: 1.1609 - val_loss: 1.1697\nEpoch 10/100\n11994/11994 [==============================] - 8s 668us/sample - loss: 1.1552 - val_loss: 1.1634\nEpoch 11/100\n11994/11994 [==============================] - 8s 669us/sample - loss: 1.1495 - val_loss: 1.1622\nEpoch 12/100\n11994/11994 [==============================] - 8s 666us/sample - loss: 1.1528 - val_loss: 1.1745\nEpoch 13/100\n11994/11994 [==============================] - 8s 664us/sample - loss: 1.1434 - val_loss: 1.1696\nEpoch 14/100\n11994/11994 [==============================] - 8s 666us/sample - loss: 1.1280 - val_loss: 1.1925\nEpoch 15/100\n11994/11994 [==============================] - 8s 670us/sample - loss: 1.1362 - val_loss: 1.1729\nEpoch 16/100\n11994/11994 [==============================] - 9s 717us/sample - loss: 1.1245 - val_loss: 1.1686\nTR___RMSE: 1.01614___QWK: 0.51387\nVAL___RMSE: 1.07806___QWK: 0.35706\n---- Fold 3 ----\nTrain on 11995 samples, validate on 2998 samples\nEpoch 1/100\n11995/11995 [==============================] - 15s 1ms/sample - loss: 2.2977 - val_loss: 1.3316\nEpoch 2/100\n11995/11995 [==============================] - 8s 668us/sample - loss: 1.4131 - val_loss: 1.2449\nEpoch 3/100\n11995/11995 [==============================] - 8s 664us/sample - loss: 1.3223 - val_loss: 1.2172\nEpoch 4/100\n11995/11995 [==============================] - 8s 668us/sample - loss: 1.2742 - val_loss: 1.2349\nEpoch 5/100\n11995/11995 [==============================] - 9s 715us/sample - loss: 1.2268 - val_loss: 1.2433\nEpoch 6/100\n11995/11995 [==============================] - 8s 674us/sample - loss: 1.1946 - val_loss: 1.1829\nEpoch 7/100\n11995/11995 [==============================] - 8s 672us/sample - loss: 1.1814 - val_loss: 1.1848\nEpoch 8/100\n11995/11995 [==============================] - 8s 674us/sample - loss: 1.1751 - val_loss: 1.1659\nEpoch 9/100\n11995/11995 [==============================] - 9s 711us/sample - loss: 1.1522 - val_loss: 1.1642\nEpoch 10/100\n11995/11995 [==============================] - 9s 712us/sample - loss: 1.1502 - val_loss: 1.1720\nEpoch 11/100\n11995/11995 [==============================] - 8s 669us/sample - loss: 1.1534 - val_loss: 1.1712\nEpoch 12/100\n11995/11995 [==============================] - 8s 670us/sample - loss: 1.1369 - val_loss: 1.1687\nEpoch 13/100\n11995/11995 [==============================] - 8s 673us/sample - loss: 1.1277 - val_loss: 1.1744\nEpoch 14/100\n11995/11995 [==============================] - 9s 720us/sample - loss: 1.1244 - val_loss: 1.2277\nTR___RMSE: 1.02177___QWK: 0.49572\nVAL___RMSE: 1.07899___QWK: 0.39290\n---- Fold 4 ----\nTrain on 11995 samples, validate on 2998 samples\nEpoch 1/100\n11995/11995 [==============================] - 12s 1ms/sample - loss: 2.2950 - val_loss: 1.3662\nEpoch 2/100\n11995/11995 [==============================] - 8s 662us/sample - loss: 1.4251 - val_loss: 1.2875\nEpoch 3/100\n11995/11995 [==============================] - 8s 694us/sample - loss: 1.3315 - val_loss: 1.2516\nEpoch 4/100\n11995/11995 [==============================] - 8s 709us/sample - loss: 1.2663 - val_loss: 1.2255\nEpoch 5/100\n11995/11995 [==============================] - 8s 668us/sample - loss: 1.2232 - val_loss: 1.2317\nEpoch 6/100\n","name":"stdout"},{"output_type":"stream","text":"11995/11995 [==============================] - 8s 668us/sample - loss: 1.1991 - val_loss: 1.2135\nEpoch 7/100\n11995/11995 [==============================] - 8s 672us/sample - loss: 1.1647 - val_loss: 1.2260\nEpoch 8/100\n11995/11995 [==============================] - 8s 668us/sample - loss: 1.1528 - val_loss: 1.2316\nEpoch 9/100\n11995/11995 [==============================] - 8s 667us/sample - loss: 1.1584 - val_loss: 1.2236\nEpoch 10/100\n11995/11995 [==============================] - 8s 666us/sample - loss: 1.1406 - val_loss: 1.2284\nEpoch 11/100\n11995/11995 [==============================] - 9s 727us/sample - loss: 1.1393 - val_loss: 1.2209\nTR___RMSE: 1.02954___QWK: 0.47463\nVAL___RMSE: 1.10159___QWK: 0.36884\nQWK CV: 0.37675589705374773 +/- 0.01871241569185031\nRMSE CV: 1.0818764086134633 +/- 0.010038876863883831\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### 4.3.2 LightGBM Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final datasets arrangement\n\nX_train = train_merged.drop(columns=['PetID', 'AdoptionSpeed'])\ny_train = train_merged['AdoptionSpeed']\n\nX_test = test_merged.drop(columns=['PetID'])\n\n# The most frequent breed of each rescuer as feature.\nX_train['rescuer_breed_mode'] = X_train['RescuerID'].map(X_train.groupby('RescuerID')['Breed1'].agg(\n    lambda x:x.value_counts().index[0]))\nX_test['rescuer_breed_mode'] = X_test['RescuerID'].map(X_test.groupby('RescuerID')['Breed1'].agg(\n    lambda x:x.value_counts().index[0]))\n\ncat_feats = ['Type', 'Vaccinated',\n             'Dewormed', 'Sterilized'] \n\nX_train = X_train.drop(columns=['Name', 'RescuerID'])\nX_test = X_test.drop(columns=['Name', 'RescuerID'])","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting the embeddings and inserting them into the dataframes\n\nbreeds = pd.concat([X_train['Breed1'], X_test['Breed1']]).unique()\nembed_list = []\nfor breed in breeds:\n    embed_list.append(embeddingses['Breed1'][cat_feats_mappings['Breed1'][breed]])\nembed_list = np.array(embed_list)\nbreed1_embed_df = pd.DataFrame(embed_list).add_prefix('breed1_embed_')\nbreed1_embed_df['Breed1'] = breeds\nX_train = X_train.merge(breed1_embed_df, how='left', on='Breed1')\nX_test = X_test.merge(breed1_embed_df, how='left', on='Breed1')\n\nbreeds = pd.concat([X_train['Breed2'], X_test['Breed2']]).unique()\nembed_list = []\nfor breed in breeds:\n    embed_list.append(embeddingses['Breed2'][cat_feats_mappings['Breed2'][breed]])\nembed_list = np.array(embed_list)\nbreed1_embed_df = pd.DataFrame(embed_list).add_prefix('breed2_embed_')\nbreed1_embed_df['Breed2'] = breeds\nX_train = X_train.merge(breed1_embed_df, how='left', on='Breed2')\nX_test = X_test.merge(breed1_embed_df, how='left', on='Breed2')\n\nbreeds = pd.concat([X_train['rescuer_breed_mode'], X_test['rescuer_breed_mode']]).unique()\nembed_list = []\nfor breed in breeds:\n    embed_list.append(embeddingses['rescuer_breed_mode'][cat_feats_mappings['rescuer_breed_mode'][breed]])\nembed_list = np.array(embed_list)\nbreed1_embed_df = pd.DataFrame(embed_list).add_prefix('rescuer_breed_mode_embed_')\nbreed1_embed_df['rescuer_breed_mode'] = breeds\nX_train = X_train.merge(breed1_embed_df, how='left', on='rescuer_breed_mode')\nX_test = X_test.merge(breed1_embed_df, how='left', on='rescuer_breed_mode')\n\nbreeds = pd.concat([X_train['State'], X_test['State']]).unique()\nembed_list = []\nfor breed in breeds:\n    embed_list.append(embeddingses['State'][cat_feats_mappings['State'][breed]])\nembed_list = np.array(embed_list)\nbreed1_embed_df = pd.DataFrame(embed_list).add_prefix('state_embed_')\nbreed1_embed_df['State'] = breeds\nX_train = X_train.merge(breed1_embed_df, how='left', on='State')\nX_test = X_test.merge(breed1_embed_df, how='left', on='State')\n\nX_train = X_train.drop(columns=['Breed1', 'Breed2', 'State', 'rescuer_breed_mode'])\nX_test = X_test.drop(columns=['Breed1', 'Breed2', 'State', 'rescuer_breed_mode'])","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using LightGBM regression\n\nparams = {'objective': 'mse',\n          'boosting': 'gbdt',\n          'metric': 'rmse',\n          'num_leaves': 10,\n          'max_depth': 5,\n          'min_data_in_leaf': 60,\n          'learning_rate': 0.01,\n          'bagging_fraction': 0.5,\n          'bagging_freq': 1,\n          'feature_fraction': 0.3,\n          'feature_fraction_seed': 73,\n          'lambda_l1': 0,\n          'lambda_l2': 0.3,\n          'verbosity': -1,\n          'seed': seed}\n\nseed_everything()\n\ndef cross_validation(X_train, y_train,\n                     params, \n                     n_splits=5,\n                     early_stopping_rounds=500,\n                     verbose_eval=100,\n                     num_boost_round=10000,\n                     seed=seed):\n\n    gr_kfold_split = GroupKFold(n_splits=5).split(X_train, y_train,\n                                                  groups=train_df['RescuerID'])\n\n    oof_train = np.zeros((X_train.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n    qwks, rmses = [], []\n    importances = []\n    i = 0\n    for train_index, valid_index in gr_kfold_split:\n        X_tr = X_train.iloc[train_index, :]\n        y_tr = y_train[train_index].values\n        X_val = X_train.iloc[valid_index, :]\n        y_val = y_train[valid_index].values\n        \n        # Text features \n        X_tr_text = text_feature_extractor.fit_transform(X_tr[text_columns]).set_index(X_tr.index)\n        X_val_text = text_feature_extractor.transform(X_val[text_columns]).set_index(X_val.index)       \n        X_tr = pd.concat([X_tr.drop(columns=text_columns),\n                          X_tr_text], axis=1)\n        X_val = pd.concat([X_val.drop(columns=text_columns),\n                          X_val_text], axis=1) \n        \n        # LGB datasets\n        d_train = lgb.Dataset(X_tr, label=y_tr)\n        d_valid = lgb.Dataset(X_val, label=y_val)\n        valid_sets = [d_train, d_valid]\n\n        # Training\n        print('Fold {}/{}'.format(i + 1, n_splits))\n        model = lgb.train(params,\n                          train_set=d_train,\n                          num_boost_round=num_boost_round,\n                          valid_sets=valid_sets,\n                          verbose_eval=verbose_eval,\n                          early_stopping_rounds=early_stopping_rounds,\n                          categorical_feature=cat_feats)\n\n        # Predictions\n        tr_pred = model.predict(X_tr)\n        val_pred = model.predict(X_val)\n       \n        # Rounding\n        thresholds = get_thresholds_from_dist(y_tr, tr_pred)\n        val_pred_rounded = allocate_to_rate(val_pred, thresholds)\n        \n        # Evaluation\n        qwk_val = qwk(y_val, val_pred_rounded)\n        rmse_val = rmse(y_val, val_pred)\n        qwks.append(qwk_val)\n        rmses.append(rmse_val)\n\n        # Out-of-fold predictions\n        oof_train[valid_index] = val_pred\n        \n        # Test predictions\n        X_test_text = text_feature_extractor.transform(X_test[text_columns]).set_index(X_test.index)\n        X_test_val = pd.concat([X_test.drop(columns=text_columns),\n                                X_test_text], axis=1)\n        test_pred = model.predict(X_test_val)\n        oof_test[:, i] = test_pred\n            \n        importance = model.feature_importance('gain') \n        importances.append(pd.Series(dict(zip(X_tr.columns, importance))))\n\n        i += 1\n\n        print('QWK: {}, RMSE: {}\\n'.format(qwk_val, rmse_val))\n    \n    return qwks, rmses, oof_train, oof_test, importances\n\nqwks, rmses, oof_train, oof_test, importances = cross_validation(X_train, y_train, params)\n\nprint('QWK CV: {} +/- {}'.format(np.mean(qwks), np.std(qwks)))\nprint('RMSE CV: {} +/- {}'.format(np.mean(rmses), np.std(rmses)))","execution_count":37,"outputs":[{"output_type":"stream","text":"Fold 1/5\nTraining until validation scores don't improve for 500 rounds.\n[100]\ttraining's rmse: 1.10141\tvalid_1's rmse: 1.09383\n[200]\ttraining's rmse: 1.06191\tvalid_1's rmse: 1.06861\n[300]\ttraining's rmse: 1.03461\tvalid_1's rmse: 1.05377\n[400]\ttraining's rmse: 1.01402\tvalid_1's rmse: 1.04438\n[500]\ttraining's rmse: 0.997284\tvalid_1's rmse: 1.03885\n[600]\ttraining's rmse: 0.982431\tvalid_1's rmse: 1.03474\n[700]\ttraining's rmse: 0.969258\tvalid_1's rmse: 1.03161\n[800]\ttraining's rmse: 0.956835\tvalid_1's rmse: 1.02992\n[900]\ttraining's rmse: 0.945343\tvalid_1's rmse: 1.02814\n[1000]\ttraining's rmse: 0.934452\tvalid_1's rmse: 1.02731\n[1100]\ttraining's rmse: 0.924119\tvalid_1's rmse: 1.02656\n[1200]\ttraining's rmse: 0.914088\tvalid_1's rmse: 1.02571\n[1300]\ttraining's rmse: 0.904211\tvalid_1's rmse: 1.02538\n[1400]\ttraining's rmse: 0.894588\tvalid_1's rmse: 1.02497\n[1500]\ttraining's rmse: 0.885205\tvalid_1's rmse: 1.02442\n[1600]\ttraining's rmse: 0.876385\tvalid_1's rmse: 1.02421\n[1700]\ttraining's rmse: 0.867779\tvalid_1's rmse: 1.02386\n[1800]\ttraining's rmse: 0.859226\tvalid_1's rmse: 1.0234\n[1900]\ttraining's rmse: 0.850656\tvalid_1's rmse: 1.02347\n[2000]\ttraining's rmse: 0.842563\tvalid_1's rmse: 1.02373\n[2100]\ttraining's rmse: 0.834294\tvalid_1's rmse: 1.02356\n[2200]\ttraining's rmse: 0.826349\tvalid_1's rmse: 1.02345\n[2300]\ttraining's rmse: 0.818526\tvalid_1's rmse: 1.0234\n[2400]\ttraining's rmse: 0.810916\tvalid_1's rmse: 1.02341\n[2500]\ttraining's rmse: 0.80326\tvalid_1's rmse: 1.0236\n[2600]\ttraining's rmse: 0.795831\tvalid_1's rmse: 1.02363\n[2700]\ttraining's rmse: 0.7885\tvalid_1's rmse: 1.02346\n[2800]\ttraining's rmse: 0.781361\tvalid_1's rmse: 1.02365\nEarly stopping, best iteration is:\n[2387]\ttraining's rmse: 0.811934\tvalid_1's rmse: 1.02325\nQWK: 0.43792644197581865, RMSE: 1.0232518129730621\n\nFold 2/5\nTraining until validation scores don't improve for 500 rounds.\n[100]\ttraining's rmse: 1.09633\tvalid_1's rmse: 1.11525\n[200]\ttraining's rmse: 1.05686\tvalid_1's rmse: 1.08692\n[300]\ttraining's rmse: 1.02979\tvalid_1's rmse: 1.07212\n[400]\ttraining's rmse: 1.00947\tvalid_1's rmse: 1.06455\n[500]\ttraining's rmse: 0.992628\tvalid_1's rmse: 1.06002\n[600]\ttraining's rmse: 0.977944\tvalid_1's rmse: 1.05668\n[700]\ttraining's rmse: 0.964771\tvalid_1's rmse: 1.05357\n[800]\ttraining's rmse: 0.952379\tvalid_1's rmse: 1.05174\n[900]\ttraining's rmse: 0.940527\tvalid_1's rmse: 1.05048\n[1000]\ttraining's rmse: 0.929631\tvalid_1's rmse: 1.04946\n[1100]\ttraining's rmse: 0.919193\tvalid_1's rmse: 1.04864\n[1200]\ttraining's rmse: 0.908918\tvalid_1's rmse: 1.04808\n[1300]\ttraining's rmse: 0.899231\tvalid_1's rmse: 1.04769\n[1400]\ttraining's rmse: 0.88968\tvalid_1's rmse: 1.04661\n[1500]\ttraining's rmse: 0.880371\tvalid_1's rmse: 1.04579\n[1600]\ttraining's rmse: 0.871384\tvalid_1's rmse: 1.04579\n[1700]\ttraining's rmse: 0.862548\tvalid_1's rmse: 1.04531\n[1800]\ttraining's rmse: 0.854017\tvalid_1's rmse: 1.04538\n[1900]\ttraining's rmse: 0.8457\tvalid_1's rmse: 1.04458\n[2000]\ttraining's rmse: 0.837288\tvalid_1's rmse: 1.04449\n[2100]\ttraining's rmse: 0.829178\tvalid_1's rmse: 1.04445\n[2200]\ttraining's rmse: 0.8213\tvalid_1's rmse: 1.04453\n[2300]\ttraining's rmse: 0.813483\tvalid_1's rmse: 1.04433\n[2400]\ttraining's rmse: 0.805908\tvalid_1's rmse: 1.04448\n[2500]\ttraining's rmse: 0.798304\tvalid_1's rmse: 1.04448\n[2600]\ttraining's rmse: 0.791063\tvalid_1's rmse: 1.04453\n[2700]\ttraining's rmse: 0.783936\tvalid_1's rmse: 1.04487\n[2800]\ttraining's rmse: 0.777118\tvalid_1's rmse: 1.04432\nEarly stopping, best iteration is:\n[2304]\ttraining's rmse: 0.813151\tvalid_1's rmse: 1.04425\nQWK: 0.4653409015103467, RMSE: 1.0442501784816183\n\nFold 3/5\nTraining until validation scores don't improve for 500 rounds.\n[100]\ttraining's rmse: 1.1003\tvalid_1's rmse: 1.09928\n[200]\ttraining's rmse: 1.05971\tvalid_1's rmse: 1.07435\n[300]\ttraining's rmse: 1.03131\tvalid_1's rmse: 1.06143\n[400]\ttraining's rmse: 1.01048\tvalid_1's rmse: 1.05411\n[500]\ttraining's rmse: 0.993853\tvalid_1's rmse: 1.04944\n[600]\ttraining's rmse: 0.978748\tvalid_1's rmse: 1.04566\n[700]\ttraining's rmse: 0.965254\tvalid_1's rmse: 1.04301\n[800]\ttraining's rmse: 0.952873\tvalid_1's rmse: 1.04144\n[900]\ttraining's rmse: 0.941118\tvalid_1's rmse: 1.04011\n[1000]\ttraining's rmse: 0.930208\tvalid_1's rmse: 1.03879\n[1100]\ttraining's rmse: 0.919681\tvalid_1's rmse: 1.03774\n[1200]\ttraining's rmse: 0.909545\tvalid_1's rmse: 1.03683\n[1300]\ttraining's rmse: 0.899552\tvalid_1's rmse: 1.03631\n[1400]\ttraining's rmse: 0.890349\tvalid_1's rmse: 1.03597\n[1500]\ttraining's rmse: 0.88125\tvalid_1's rmse: 1.0354\n[1600]\ttraining's rmse: 0.8723\tvalid_1's rmse: 1.03437\n[1700]\ttraining's rmse: 0.863692\tvalid_1's rmse: 1.0343\n[1800]\ttraining's rmse: 0.855156\tvalid_1's rmse: 1.03387\n[1900]\ttraining's rmse: 0.84673\tvalid_1's rmse: 1.03435\n[2000]\ttraining's rmse: 0.838481\tvalid_1's rmse: 1.03421\n[2100]\ttraining's rmse: 0.830598\tvalid_1's rmse: 1.03408\n[2200]\ttraining's rmse: 0.822772\tvalid_1's rmse: 1.03428\n[2300]\ttraining's rmse: 0.814915\tvalid_1's rmse: 1.03438\nEarly stopping, best iteration is:\n[1802]\ttraining's rmse: 0.854995\tvalid_1's rmse: 1.03383\nQWK: 0.4278081717387383, RMSE: 1.0338252534710735\n\nFold 4/5\nTraining until validation scores don't improve for 500 rounds.\n[100]\ttraining's rmse: 1.09685\tvalid_1's rmse: 1.11908\n[200]\ttraining's rmse: 1.05781\tvalid_1's rmse: 1.09001\n[300]\ttraining's rmse: 1.03086\tvalid_1's rmse: 1.07347\n[400]\ttraining's rmse: 1.01048\tvalid_1's rmse: 1.0635\n[500]\ttraining's rmse: 0.993962\tvalid_1's rmse: 1.05816\n[600]\ttraining's rmse: 0.979016\tvalid_1's rmse: 1.0541\n[700]\ttraining's rmse: 0.965677\tvalid_1's rmse: 1.05093\n[800]\ttraining's rmse: 0.953332\tvalid_1's rmse: 1.04821\n[900]\ttraining's rmse: 0.941611\tvalid_1's rmse: 1.04669\n[1000]\ttraining's rmse: 0.930644\tvalid_1's rmse: 1.0454\n[1100]\ttraining's rmse: 0.920105\tvalid_1's rmse: 1.04442\n[1200]\ttraining's rmse: 0.909876\tvalid_1's rmse: 1.04401\n[1300]\ttraining's rmse: 0.90018\tvalid_1's rmse: 1.0433\n[1400]\ttraining's rmse: 0.891036\tvalid_1's rmse: 1.04291\n[1500]\ttraining's rmse: 0.881845\tvalid_1's rmse: 1.0431\n[1600]\ttraining's rmse: 0.872876\tvalid_1's rmse: 1.0424\n[1700]\ttraining's rmse: 0.864072\tvalid_1's rmse: 1.04215\n[1800]\ttraining's rmse: 0.85543\tvalid_1's rmse: 1.04216\n[1900]\ttraining's rmse: 0.847261\tvalid_1's rmse: 1.04175\n[2000]\ttraining's rmse: 0.83916\tvalid_1's rmse: 1.04232\n[2100]\ttraining's rmse: 0.831184\tvalid_1's rmse: 1.04187\n[2200]\ttraining's rmse: 0.823335\tvalid_1's rmse: 1.04171\n[2300]\ttraining's rmse: 0.815585\tvalid_1's rmse: 1.04224\n[2400]\ttraining's rmse: 0.808071\tvalid_1's rmse: 1.04221\n[2500]\ttraining's rmse: 0.800543\tvalid_1's rmse: 1.04263\n[2600]\ttraining's rmse: 0.793279\tvalid_1's rmse: 1.04278\nEarly stopping, best iteration is:\n[2194]\ttraining's rmse: 0.823818\tvalid_1's rmse: 1.04161\nQWK: 0.4569743107796783, RMSE: 1.0416103021992942\n\nFold 5/5\nTraining until validation scores don't improve for 500 rounds.\n[100]\ttraining's rmse: 1.09302\tvalid_1's rmse: 1.13047\n[200]\ttraining's rmse: 1.05422\tvalid_1's rmse: 1.10304\n[300]\ttraining's rmse: 1.02737\tvalid_1's rmse: 1.08657\n[400]\ttraining's rmse: 1.00746\tvalid_1's rmse: 1.07718\n[500]\ttraining's rmse: 0.991227\tvalid_1's rmse: 1.0713\n[600]\ttraining's rmse: 0.976905\tvalid_1's rmse: 1.06704\n[700]\ttraining's rmse: 0.96354\tvalid_1's rmse: 1.0635\n[800]\ttraining's rmse: 0.951393\tvalid_1's rmse: 1.06113\n[900]\ttraining's rmse: 0.939934\tvalid_1's rmse: 1.05887\n[1000]\ttraining's rmse: 0.929229\tvalid_1's rmse: 1.05727\n[1100]\ttraining's rmse: 0.919085\tvalid_1's rmse: 1.05595\n[1200]\ttraining's rmse: 0.909089\tvalid_1's rmse: 1.0554\n[1300]\ttraining's rmse: 0.899678\tvalid_1's rmse: 1.05477\n[1400]\ttraining's rmse: 0.890585\tvalid_1's rmse: 1.0534\n[1500]\ttraining's rmse: 0.881529\tvalid_1's rmse: 1.05298\n[1600]\ttraining's rmse: 0.872688\tvalid_1's rmse: 1.05244\n[1700]\ttraining's rmse: 0.86403\tvalid_1's rmse: 1.05229\n[1800]\ttraining's rmse: 0.855514\tvalid_1's rmse: 1.05204\n[1900]\ttraining's rmse: 0.847357\tvalid_1's rmse: 1.05169\n[2000]\ttraining's rmse: 0.839524\tvalid_1's rmse: 1.05162\n[2100]\ttraining's rmse: 0.831699\tvalid_1's rmse: 1.05163\n[2200]\ttraining's rmse: 0.824061\tvalid_1's rmse: 1.05122\n[2300]\ttraining's rmse: 0.816525\tvalid_1's rmse: 1.05118\n[2400]\ttraining's rmse: 0.809056\tvalid_1's rmse: 1.05097\n[2500]\ttraining's rmse: 0.801549\tvalid_1's rmse: 1.05108\n","name":"stdout"},{"output_type":"stream","text":"[2600]\ttraining's rmse: 0.79425\tvalid_1's rmse: 1.05102\n[2700]\ttraining's rmse: 0.787116\tvalid_1's rmse: 1.05115\n[2800]\ttraining's rmse: 0.780031\tvalid_1's rmse: 1.0509\n[2900]\ttraining's rmse: 0.772846\tvalid_1's rmse: 1.05119\n[3000]\ttraining's rmse: 0.765957\tvalid_1's rmse: 1.051\n[3100]\ttraining's rmse: 0.759136\tvalid_1's rmse: 1.05141\n[3200]\ttraining's rmse: 0.752474\tvalid_1's rmse: 1.05136\n[3300]\ttraining's rmse: 0.745801\tvalid_1's rmse: 1.05194\nEarly stopping, best iteration is:\n[2825]\ttraining's rmse: 0.778291\tvalid_1's rmse: 1.05082\nQWK: 0.4593353700046855, RMSE: 1.0508171064210816\n\nQWK CV: 0.4494770392018535 +/- 0.014198690137366143\nRMSE CV: 1.038750930709226 +/- 0.009470958500000667\n","name":"stdout"}]},{"metadata":{"_uuid":"b6b1b57b07de839d94a8e9bf324be7777b382acf"},"cell_type":"markdown","source":"<a id=\"5\"></a> \n## 5. Submission"},{"metadata":{"trusted":true,"_uuid":"63ef79b0d8494db67f997eaca420d39492294eb7"},"cell_type":"code","source":"def submit(oof_train, oof_test):\n    \"\"\"Generates submission from test OOF predictions.\"\"\"\n    preds = oof_test.mean(axis=1)\n    \n    thresholds = get_thresholds_from_dist(y_train, preds)\n    preds = allocate_to_rate(preds, thresholds)\n\n    preds = preds.astype(np.int32)\n    submission = pd.DataFrame({'PetID': test_df['PetID'].values, 'AdoptionSpeed': preds})\n    submission.to_csv('submission.csv', index=False)\n    \n    return preds\n    \npreds = submit(oof_train, oof_test)","execution_count":38,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}