{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a9d11c8641f6ade02a25b93f829f213af75d38c"},"cell_type":"markdown","source":"## References:\nhttps://www.kaggle.com/myltykritik/simple-lgbm-image-features\n\nhttps://stackoverflow.com/questions/47200146/keras-load-images-batch-wise-for-large-dataset\n\nhttps://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n\nhttps://keras.io/models/model/\n\nhttps://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n\nhttps://keras.io/layers/pooling/\n\nhttps://towardsdatascience.com/transfer-learning-and-image-classification-using-keras-on-kaggle-kernels-c76d3b030649\n"},{"metadata":{"trusted":true,"_uuid":"f27b544512c9a5f798471ee13205bf2c51411584"},"cell_type":"code","source":"# !ls ../input/train_images","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6522a4f3a856e8892bc6d40fd0926836443803ec"},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true,"_uuid":"efa202ca2ed6903ea6dfa8960b6f56ef023fde44"},"cell_type":"code","source":"# time\nimport time\n# import OpenCV\nimport cv2\n# random\nimport random\nrandom.seed(1331)\n# viz\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.applications.mobilenet_v2 import MobileNetV2\nconv_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fe8d6191dddf7865d7a2f11ceb9002b6ced13ac"},"cell_type":"code","source":"conv_base.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84944a6a58c639f42a5eb49a14abffd3fdfc495d"},"cell_type":"markdown","source":"## Get as sense of the images shapes"},{"metadata":{"trusted":true,"_uuid":"b7b671f79c74e325af094906cc953eb742d19f21"},"cell_type":"code","source":"print(cv2.imread('../input/train_images/8132fabfd-10.jpg').shape)\nprint(cv2.imread('../input/train_images/beb0f98f7-1.jpg').shape)\nprint(cv2.imread('../input/train_images/d168549f2-4.jpg').shape)\nprint(cv2.imread('../input/train_images/9d6c6055b-2.jpg').shape)\nprint(cv2.imread('../input/train_images/a6593fb48-6.jpg').shape)\nprint(cv2.imread('../input/train_images/ea1736eec-4.jpg').shape)\nprint(cv2.imread('../input/train_images/f205b0649-6.jpg').shape)\nprint(cv2.imread('../input/train_images/f888d5f54-3.jpg').shape)\nprint(cv2.imread('../input/train_images/bcf546cb8-3.jpg').shape)\nprint(cv2.imread('../input/train_images/3fd545213-6.jpg').shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"152059856c6b15bbfd914c7d5601cac17c397493"},"cell_type":"markdown","source":"## View an Image"},{"metadata":{"trusted":true,"_uuid":"9cb0dfd2b057812af129e40aafbf628289714c30"},"cell_type":"code","source":"# read in image\nimg = cv2.imread('../input/train_images/0008c5398-1.jpg')\nimg = cv2.resize(img, (224,224))\n# show image\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4e0f88bf795d4f4ee7f5296b32544c1533af8e8"},"cell_type":"code","source":"np.max(img)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22f44df27f946ba121df687ed4f25d39ff49af13"},"cell_type":"markdown","source":"# Setting up PetID and AdoptionSpeed Lookup Table\n\n- So we want to create a table where we can call the ID# and get the target values\n- We'll also test that we can grab the target value via the ID#"},{"metadata":{"trusted":true,"_uuid":"75cebc114415170f90294978d2feb43a0323500e"},"cell_type":"code","source":"# read in training dataset\ntrain_df = pd.read_csv('../input/train/train.csv')\n# only grab the ID and target\npet_ids_and_target = train_df[['PetID','AdoptionSpeed']]\n# Get one-hot representation using get_dummies\nonehottarget = pd.get_dummies(pet_ids_and_target['AdoptionSpeed'])\n# merge one-hot encodings back to our table\npet_ids_and_target = pet_ids_and_target.join(onehottarget)\n# show our final table\nprint(pet_ids_and_target.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1717867caa47541056ea62430dbba0985cafdfdd"},"cell_type":"code","source":"# test out AdoptionSpeed extraction code\ngetrow = pet_ids_and_target.loc[pet_ids_and_target['PetID'] == 'bec2fe7ad']\nprint(getrow)\nprint(np.asarray(getrow[[0,1,2,3,4]].values[0], dtype=np.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"148bf5474335a422b3948e385085aea75807eba0"},"cell_type":"markdown","source":"## My Data Augmentation Function\n\n- Here we're creating our own custom image augmentation code using OpenCV\n- We'll use this function to augment our images during training\n- With each batch we'll generate a random number which will indicate which augmentation we do.  We pick random augmentations with each batch mainly due to memory constraints.\n- You can customize this to include any augmentations that you want!  Change the random # range, include a new elif or alter the current elif's as you want!\n- You might want to do this if you have some contexual knowledge about the images you'd like to leverage but need more control over the augmentations.\n- Here we're mainly doing specific cropping, rotating, and blurring techniques based on knowledge of the images."},{"metadata":{"trusted":true,"_uuid":"7fc1ff1bb4554a2a81c35863ba756f38eb91c626"},"cell_type":"code","source":"def MyAug(fiximg, shape):\n    auglist = [fiximg]\n    \n    # we can only fit so much into memory\n    # so every round we will randomly select an augmentation to apply for training\n    augshuf = random.randint(1,101)\n    \n    if augshuf in range(1,11):\n    \n        # Augmentation 1\n\n        # blur image using 25x25 kernel\n        blurred = cv2.blur(fiximg, ksize=(25,25))\n        # write out image\n        auglist.append(blurred)\n    \n    elif augshuf in range(11,21):\n    \n        # Augmentation 2\n\n        # covert to HSV\n        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n        # We're going to equalize the value channel\n        hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n        # convert back to RGB\n        eq_color_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n        # write out image\n        auglist.append(eq_color_img)\n    \n    elif augshuf in range(21,31):\n    \n        # Augmentation 3\n\n        y_offsetp1 = int(fiximg.shape[0]*0.25)\n        y_offsetp2 = int(fiximg.shape[0]*0.75)\n        x_offsetp1 = int(fiximg.shape[1]*0.25)\n        x_offsetp2 = int(fiximg.shape[1]*0.75)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n    \n    elif augshuf in range(31,41):\n    \n        # Augmentation 4\n\n        y_offsetp1 = int(fiximg.shape[0]*0)\n        y_offsetp2 = int(fiximg.shape[0]*0.6)\n        x_offsetp1 = int(fiximg.shape[1]*0)\n        x_offsetp2 = int(fiximg.shape[1]*0.6)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n\n    elif augshuf in range(41,51):\n        \n        # Augmentation 5\n\n        y_offsetp1 = int(fiximg.shape[0]*0)\n        y_offsetp2 = int(fiximg.shape[0]*0.6)\n        x_offsetp1 = int(fiximg.shape[1]*0.4)\n        x_offsetp2 = int(fiximg.shape[1]*1)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n    \n    elif augshuf in range(51,61):\n    \n        # Augmentation 6\n\n        y_offsetp1 = int(fiximg.shape[0]*0)\n        y_offsetp2 = int(fiximg.shape[0]*0.6)\n        x_offsetp1 = int(fiximg.shape[1]*0.4)\n        x_offsetp2 = int(fiximg.shape[1]*1)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n    \n    elif augshuf in range(61,71):\n    \n        # Augmentation 7\n    \n        y_offsetp1 = int(fiximg.shape[0]*0.4)\n        y_offsetp2 = int(fiximg.shape[0]*1)\n        x_offsetp1 = int(fiximg.shape[1]*0.4)\n        x_offsetp2 = int(fiximg.shape[1]*1)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n    \n    elif augshuf in range(71,81):\n    \n        # Augmentation 8\n\n        xp1 = min(.15,random.randint(1,100)/100)\n        xp2 = max(.85,random.randint(1,100)/100)\n        yp1 = min(.15,random.randint(1,100)/100)\n        yp2 = max(.85,random.randint(1,100)/100)\n        # create points\n        y_offsetp1 = int(fiximg.shape[0]*yp1)\n        y_offsetp2 = int(fiximg.shape[0]*yp2)\n        x_offsetp1 = int(fiximg.shape[1]*xp1)\n        x_offsetp2 = int(fiximg.shape[1]*xp2)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n        \n    elif augshuf in range(81,91):\n    \n        # Augmentation 9\n        \n        rot = random.choice(np.arange(-180,179,1))\n        if rot ==0:\n            rot = 179\n        rows,cols,_ = fiximg.shape\n        M = cv2.getRotationMatrix2D((cols/2,rows/2),rot,1)\n        dst = cv2.warpAffine(fiximg,M,(cols,rows))\n        # write out image\n        auglist.append(dst)\n        \n    elif augshuf in range(91,101):\n        \n        # Augmentation 10\n\n        rows,cols,ch = fiximg.shape\n        pts1 = np.float32([[50,50],[200,50],[50,200]])\n        pts2 = np.float32([[10,100],[200,50],[100,250]])\n        M = cv2.getAffineTransform(pts1,pts2)\n        dst = cv2.warpAffine(fiximg,M,(cols,rows))\n        # write out image\n        auglist.append(dst)\n    \n    return auglist","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ea527540be687d6a1a8b887512ca5562ac342d8"},"cell_type":"markdown","source":"## Function to Load Images\n\n- The following functions will allow us to take a list of files (saw a batch of files\\images) read them using OpenCV, apply augmentation, grab the corresponding target values, and return for training.\n- In training we apply augmentation, but in validation we don't apply augmentation, so we have 2 functions, one for training and one for validation (with no augmentation)."},{"metadata":{"trusted":true,"_uuid":"7d51df6de3a104561e2140a7a409f23ad701dcf6"},"cell_type":"code","source":"def LoadImagesAndTarget_Train(files, lookup_table, shape):\n    # initialize variables\n    i = 0\n    w = shape[0]\n    h = shape[1]\n    batch_images = np.zeros(((len(files) * 2),w,h,3))\n    targetvals = np.zeros(((len(files) * 2),5))\n    for file in files:\n        # read in image\n        img = cv2.imread('../input/train_images/' + file)\n        # resize\n        img = cv2.resize(img, shape)\n        # apply augmentation\n        newimages = MyAug(img, shape)\n        # normalize\n        newimages = np.array(newimages) / 255.0\n        # 'newimages' should have our original image and an augmented version\n        # so we're creating a new matrix with our original images and augmentations\n        # and we include our target value for each\n        for img in newimages:\n            # add image to batch set\n            batch_images[i] = img\n            # get the filename without extension\n            filename = os.path.splitext(file)[0]\n            # get the id from the filename\n            id_from_filename = filename[0:filename.find('-')]\n            # only keep the row from the lookup table that matches our id\n            getrow = lookup_table.loc[lookup_table['PetID'] == id_from_filename]\n            # change the format to one-hot encoded, and save to target dataset\n            targetvals[i] = np.asmatrix(getrow[[0,1,2,3,4]].values[0], dtype=np.float32)\n            # iterate i\n            i += 1\n    return batch_images, targetvals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a4d26ea93f1dea72d66103f9c01f5cb7621aa41"},"cell_type":"code","source":"def LoadImagesAndTarget_Test(files, lookup_table, shape):\n    # initialize variables\n    i = 0\n    w = shape[0]\n    h = shape[1]\n    batch_images = np.zeros(((len(files)),w,h,3))\n    targetvals = np.zeros(((len(files)),5))\n    for file in files:\n        # read in image\n        img = cv2.imread('../input/train_images/' + file)\n        # resize\n        img = cv2.resize(img, shape)\n        # in validation we don't apply augmentation\n        # normalize\n        img = np.array(img) / 255.0\n        batch_images[i] = img\n        # get the filename without extension\n        filename = os.path.splitext(file)[0]\n        # get the id from the filename\n        id_from_filename = filename[0:filename.find('-')]\n        # only keep the row from the lookup table that matches our id\n        getrow = lookup_table.loc[lookup_table['PetID'] == id_from_filename]\n        # change the format to one-hot encoded, and save to target dataset\n        targetvals[i] = np.asmatrix(getrow[[0,1,2,3,4]].values[0], dtype=np.float32)\n        # get target based on filename\n        i += 1\n    #print(\"returning batches ...\")\n    return batch_images, targetvals","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23e4d21e87fe1d31ff96b69428e8c67cc555fbda"},"cell_type":"markdown","source":"## Create Image Loader\n\n- We're using train_on_batch here because it gives us a bit more control and in this case had a better experience over trying to set up a generator.\n- This is pretty basic, we just have to build a lot from scratch since we're using train_on_batch\n- We set up epochs, batches, loading batches, running train_on_batch, printing feedback, storing results, etc."},{"metadata":{"trusted":true,"_uuid":"b9ad2941b7de4b72b894704c4aaa08462c8a83db"},"cell_type":"code","source":"def KerasModelTrainer(files, batch_size, lookup_table, epochs, test_size, shape):\n    \n    # initialize variables for storing history and calculating batches\n    L = len(files)\n    rnds = L // batch_size\n    training_loss_history_e = []\n    test_loss_history_e = []\n    training_acc_history_e = []\n    test_acc_history_e = []\n\n    for epoch in range(1,epochs + 1):\n        \n        # initialize variables for storing history and calculating batch ranges\n        batch_start = 0\n        batch_end = batch_size\n        test_cases = int(batch_size * test_size)\n        training_loss_history = []\n        test_loss_history = []\n        training_acc_history = []\n        test_acc_history = []\n        mycnt = 0\n        start = time.time()\n        \n        print(\"Epoch {}/{}\".format(epoch,epochs))\n        \n        while batch_start < L:\n            \n            # initialize variables for calculating batch ranges and printing results\n            mycnt += 1\n            pct = int((mycnt / rnds) * 100)\n            limit = min(batch_end, L)\n\n            # load train and test images for training with augmentation\n            Xtrain, Ytrain = LoadImagesAndTarget_Train(files[batch_start:(limit - test_cases)], lookup_table, shape)\n            Xtest, Ytest = LoadImagesAndTarget_Test(files[((limit - test_cases)):limit], lookup_table, shape)    \n\n            # train\n            model.train_on_batch(Xtrain,Ytrain)\n\n            # test on train\n            training_metrics = model.test_on_batch(Xtrain,Ytrain)\n            training_loss = training_metrics[0]\n            training_acc = training_metrics[1]\n            \n            # save model training metrics\n            training_loss_history.append(training_loss)\n            training_acc_history.append(training_acc)\n            \n            # test on test\n            test_metrics = model.test_on_batch(Xtest,Ytest)\n            test_loss = test_metrics[0]\n            test_acc = test_metrics[1]\n            \n            # save model test\\validation metrics\n            test_loss_history.append(test_loss)\n            test_acc_history.append(test_acc)\n            \n            # update batch window\n            batch_start += batch_size   \n            batch_end += batch_size\n            \n            # update overall performance\n            if np.isnan(np.mean(training_acc_history)) == False:\n                train_acc_mean = np.mean(training_acc_history)\n            if np.isnan(np.mean(test_acc_history)) == False:\n                test_acc_mean = np.mean(test_acc_history)\n            \n            # communicate training results so far\n            print(\"Training {}% [\".format(pct), \n                  \"#\" * int(pct/5), \n                  \".\" * (20 - int(pct/5)), \"]\", \n                  \" Train Acc: {0:.3f} | \".format(train_acc_mean), \n                  \" Test Acc: {0:.3f}\".format(test_acc_mean), end='\\r')\n        \n        end = time.time()\n        print(\"\")\n        print(\"Processing Time: {0:.2f} min\".format((end - start) / 60))\n        \n        # storing training history\n        test_loss_history_e.append(np.mean(test_loss_history))\n        test_acc_history_e.append(np.mean(test_acc_history))\n        training_loss_history_e.append(np.mean(training_loss_history))\n        training_acc_history_e.append(np.mean(training_acc_history))\n    \n    return model, training_loss_history_e, test_loss_history_e, training_acc_history_e, test_acc_history_e","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02f2bcd311da1e7b783a1ef8aff70b30feb68ef6"},"cell_type":"markdown","source":"## Define Model"},{"metadata":{"trusted":true,"_uuid":"c121603478db45120fd8aba8504d70de3317f8ee"},"cell_type":"code","source":"#create model\nmodel = Sequential()\n#add model layers\nmodel.add(conv_base)\nmodel.add(Conv2D(60, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(50, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(40, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(30, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(10, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='tanh'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48a85b77f66a553b7c7216d42cccde0191335804"},"cell_type":"code","source":"conv_base.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05622d3e16be4318ad4d4c35d68db64fb17de2ed"},"cell_type":"code","source":"#compile model using accuracy to measure model performance\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"818cb70adafb881341138603a8f889c2f1771526"},"cell_type":"markdown","source":"## Run Model"},{"metadata":{"trusted":true,"_uuid":"32ae0ae368c4cdeb0c926407f13184ddebde38ae"},"cell_type":"code","source":"# Get list of files\nfiles = os.listdir('../input/train_images') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01ab25ad6ca3ea6f8e49140f7030bf40f5953b68","scrolled":false},"cell_type":"code","source":"epochs = 5\nmodel, train_loss_hist, test_loss_hist, train_acc_hist, test_acc_hist = KerasModelTrainer(files=files,\n                                                                                          batch_size=100,\n                                                                                          lookup_table=pet_ids_and_target, \n                                                                                          epochs=epochs, \n                                                                                          test_size=0.1, \n                                                                                          shape=(224,224))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Plots"},{"metadata":{"trusted":true,"_uuid":"99fc066541fa8ead3955d9e08bbbcabd99ebf7a1"},"cell_type":"code","source":"plt.plot(np.arange(1, epochs+1, 1), test_loss_hist)\nplt.plot(np.arange(1, epochs+1, 1), train_loss_hist)\nplt.xlabel('Rounds / Batches')\nplt.ylabel('Loss')\nplt.title('Train / Test Loss History')\nplt.legend(['test', 'train'], loc='upper left')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccb2af27eb09a9b41fa53d31132ffa5386c84b58"},"cell_type":"code","source":"plt.plot(np.arange(1, epochs+1, 1), test_acc_hist)\nplt.plot(np.arange(1, epochs+1, 1), train_acc_hist)\nplt.xlabel('Rounds / Batches')\nplt.ylabel('Accuracy')\nplt.title('Train / Test Acc History')\nplt.legend(['test', 'train'], loc='upper left')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"567b21526505911c29bfb70e60ba044a91ac3dd7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"716f6adb6fed04ccbf861d1f00c9e21c036365b4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5580c328bd6b58f962aa56f747b889f7c314aa27"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8391b9a40305b1c0da299fb3b050c182da41fd3e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}