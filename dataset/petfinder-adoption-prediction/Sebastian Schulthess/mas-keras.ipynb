{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Workbook\n\n| Date       | Version   | Description                                      | Public score  | Commit Version\n|--------------------------------------------------------------------------------------------------------------------------------------------|\n| 2019-06-01 | v1.0        | resnet50 transfer learning, loss='categorical_crossentropy' batch-size: 64   | -  | v6 |\n| 2019-06-07 | v1.1        | resnet50 transfer learning,  kappa score failed.   |   -| v7 |\n| 2019-06-10 | v1.2        | resnet50 transfer learning,  batch_size: 32 (as in book p. 321) |   -| v7 |\n| 2019-06-10 | v1.3        | resnet50 transfer learning,  batch_size: 32, dropout rate 0.2 |   -| v8 |\n| 2019-06-11 | v1.4        | resnet50 transfer learning,  batch_size: 32, dropout rate 0.5, EarlyStop 2 |   -| v9 |\n| 2019-06-15 | v1.5        | resnet50 transfer learning,  batch_size: 32, dropout rate 0.5, EarlyStop 10  | -| v10 |\n| 2019-06-16 | v1.6        | resnet50 transfer learning,  batch_size: 512, dropout rate 0.5, EarlyStop 10, adam | -| https://www.kaggle.com/bravenoob/fork-of-mas-keras?scriptVersionId=15757244 |\n| 2019-06-16 | v1.7        | check kappa   |  -| v11 |\n| 2019-06-20 | v1.8        | submit test (no 0's were concluded)   |  0.25981 | v12 |\n| 2019-06-20 | v1.9        | submit test from best talos experiment params (64, 0.5, 50, 'softmax', 2.08,'categorical_crossentropy', 0.25,Adam') | 0.17356 | 16 |\n| 2019-06-27 | v1.10        | submit test with batch size 512 (0.2, 20, 'softmax', 'None', 0.1, Adam, 512, 'categorical_crossentropy', 0.1, 0] | 0.23107 | v17 |\n | 2019-06-27 | v1.11       | same, but 50 epochs & early stopping (mean) |   0.22490 | v18 |\n | 2019-07-07 | v1.12       | same, classifier matrix prediction | 0.23852 | https://www.kaggle.com/bravenoob/mas-keras-dataframe?scriptVersionId=17063755 |\n | 2019-07-11 | v1.13       | NASNet large, default params, new image folder structure |  0.29894 | v20 |\n | 2019-07-11 | v1.14       | NASNet large, default params,, class_weights, early stopping  |  0.31138 | v21 |\n | 2019-07-13 | v1.15       | same, classifier matrix prediction  |  0.28453 | https://www.kaggle.com/bravenoob/mas-keras-dataframe?scriptVersionId=17157275 |\n | 2019-07-14 | v1.16       | NASNet large, talos params, no class_weights, epoch 20,batch: 16, dropout 0.1, learningrate:0.00109  | 0.25280 | v23 |\n | 2019-07-14 | v1.17       | new layers |  0.19965 | https://www.kaggle.com/bravenoob/mas-keras-kappa?scriptVersionId=17469784 |\n | 2019-07-19 | v1.19       | new layers, with class weight |  0.26575 | v35 |\n | 2019-07-20 | v1.20       | new layers, with class weight, add image augmentation |  0.29932 | v36 \n | 2019-07-21 | v1.21       | new layers, with class weight, add image augmentation (new image split), very promising lcurve, more time needed |  0.30489 | v42 \n | 2019-07-25 | v1.22       | same, classifier matrix prediction, worse than just mean, but why? | 0.28440 | https://www.kaggle.com/bravenoob/mas-keras-dataframe?scriptVersionId=17774299 \n | 2019-07-27 | v1.23       | v1.21 on vast.ai 100 epochs (data: vast.ai submission v2) | 0.28782 | https://www.kaggle.com/bravenoob/mas-keras-dataframe?scriptVersionId=17774299 \n | 2019-07-28 | v1.24       | max pooling sieht schlecht aus | - | v43 \n | 2019-07-29 | v1.25       | vast.ai 100 epochs, mehr augementation (data: vast.ai submission v3) | 0.26451 | code verzeichnis \n | 2019-08-02 | v1.26       | params from v.1.21 with resized images | 0.30519 | v47 \n | 2019-08-04 | v1.27       | matrix classifier | 0.27413 | https://www.kaggle.com/bravenoob/mas-keras-dataframe?scriptVersionId=18264736\n | 2019-08-02 | v1.28       | best talos score lr,batch_size,dropout,optimizer 0.1,32,0.1, Adamax | fail | v50\n | 2019-08-12 | v1.29       | best talos score lr,batch_size,dropout,optimizer 0.1,64,0.25, Adam | - | v52"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the extension and start TensorBoard\n%load_ext tensorboard.notebook\n%tensorboard --logdir logs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time \n\n#let's also import the abstract base class for our callback\nfrom tensorflow.keras.callbacks import Callback\n\n#defining the callback\nclass TimerCallback(Callback):\n    \n    def __init__(self, maxExecutionTime):\n        \n# Arguments:\n#     maxExecutionTime (number): Time in minutes. The model will keep training \n#                                until shortly before this limit\n#                                (If you need safety, provide a time with a certain tolerance)\n        \n        self.maxExecutionTime = maxExecutionTime * 60\n    \n    \n    #Keras will call this when training begins\n    def on_train_begin(self, logs):\n        self.startTime = time.time()\n        self.longestTime = 0            #time taken by the longest epoch or batch\n        self.lastTime = self.startTime  #time when the last trained epoch or batch was finished\n\n    #this is our custom handler that will be used in place of the keras methods:\n        #`on_batch_end(batch,logs)` or `on_epoch_end(epoch,logs)`\n    def on_epoch_end(self, epoch, logs):\n        \n        currentTime      = time.time()                           \n        self.elapsedTime = currentTime - self.startTime    #total time taken until now\n        thisTime         = currentTime - self.lastTime     #time taken for the current epoch\n                                                               #or batch to finish\n        \n        self.lastTime = currentTime\n        \n        #verifications will be made based on the longest epoch or batch\n        if thisTime > self.longestTime:\n            self.longestTime = thisTime\n        \n        \n        #if the (assumed) time taken by the next epoch or batch is greater than the\n            #remaining time, stop training\n        remainingTime = self.maxExecutionTime - self.elapsedTime\n        if remainingTime < self.longestTime:\n            \n            self.model.stop_training = True  #this tells Keras to not continue training\n            print(\"\\n\\nTimerCallback: Finishing model training before it takes too much time. (Elapsed time: \" + str(self.elapsedTime/60.) + \" minutes )\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import NASNetLarge\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam, Nadam, Adamax\n\nnum_classes = 5\nmodel = NASNetLarge(weights='imagenet', include_top=False, pooling='avg')\n\nmy_new_model = Sequential()\nmy_new_model.add(model)\nmy_new_model.add(Dense(512, activation=\"relu\"))\nmy_new_model.add(Dropout(rate=0.25))\nmy_new_model.add(Dense(256, activation=\"relu\"))\nmy_new_model.add(Dropout(rate=0.25))                 \nmy_new_model.add(Dense(num_classes, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_new_model.layers[0].trainable = False\n\n# optimizer\n# descent optimizer (adam lr defaut = 0.001)\nmy_new_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nprint(my_new_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layers = [(layer, layer.name, layer.trainable) for layer in my_new_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.nasnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback\n\nimage_size = 331\nbatch_size = 64\nnb_epochs = 50\n\n# steps_per_epoch: number of yields (batches) before a epoch is over\n# ceil(num_samples / batch_size)\n# epochs: Number of epochs to train the model. An epoch is an iteration over the entire data provided\n# class_weight: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). \n#  This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n\nshift = 0.2\n\n#brightness_range=[0.8,1.2],\n#zoom_range=[0.8,1.2],\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, zoom_range=[0.9,1.1],width_shift_range=0.2, \n                                       height_shift_range=0.2, horizontal_flip=True)\n\n#liefert die trainingsdaten als iterator\n# image aug funktioniert so, dass f체r den aktuellen batch die bilder ge채ndert werden. Nicht dass es mehr Bilder gibt.\n# Somit wird f체r jede Epoche mit anderen Bildenr trainiert.\ntrain_generator = train_datagen.flow_from_directory(\n    '../input/petfinder-images/petfinder_images/images/train',\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode='categorical')\n\n# keine image augmenation f체r validierung\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n#liefert die Validationdaten als iterator\nvalidation_generator = test_datagen.flow_from_directory(\n    '../input/petfinder-images/petfinder_images/images/validation',\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nSTEP_SIZE_TRAIN=math.ceil(train_generator.n//train_generator.batch_size)\nSTEP_SIZE_VALID=math.ceil(validation_generator.n//validation_generator.batch_size)\n\nprint(STEP_SIZE_TRAIN)\nprint(STEP_SIZE_VALID)\n\n\n# Configure the TensorBoard callback and fit the model\ntensorboard_callback = TensorBoard(\"logs\")\n\n# Early stopping against overfit\nearlystopping_callback = EarlyStopping(patience=batch_size/10, monitor='val_acc', mode='auto', restore_best_weights=True)\n        \n# save best model\nmc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='auto', save_best_only=True)\n\nclass_weights = {0: 8.80595533,\n                1: 1.01597481,\n                2: 0.72513282,\n                3: 0.74640867,\n                4: 0.84505298}\n\n\n#import multiprocessing\n#multiprocessing.cpu_count()\n\ntimerCallback = TimerCallback(500)\n\nhistory = my_new_model.fit_generator(\n    train_generator,\n    steps_per_epoch = STEP_SIZE_TRAIN,\n    validation_data = validation_generator, \n    validation_steps = STEP_SIZE_VALID,\n    epochs = nb_epochs,\n    class_weight = class_weights,\n    callbacks=[mc,timerCallback,earlystopping_callback],\n    workers = 2,\n    use_multiprocessing = False,\n    max_queue_size = 40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_training(history):\n    # Plot training & validation accuracy values\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    # Plot training & validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    plt.savefig('acc_vs_epochs.png')\n    \nplot_training(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications.nasnet import preprocess_input, decode_predictions\n\nsaved_model = load_model('../working/best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n\ndef calculate_score_from_predictions(df, PetID):\n    mean = df[df['Filename'].str.contains(PetID)]['Predictions'].mean()\n    if math.isnan(mean):\n        return 4 # if no photo is available, default is Speed 4\n    else: \n        return int(round(mean, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n#liefert die testdaten als iterator\ntest_generator = test_datagen.flow_from_directory(\n    '../input/petfinder-images-331/petfinder_images_331/images_crop/real_test', # expects a single folder within\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode=None,\n    shuffle=False)\n\ntest_generator.reset()\n\ntest_preds = saved_model.predict_generator(test_generator)\ntest_results=pd.DataFrame({\"Filename\":test_generator.filenames,\n                      \"Predictions\":test_preds.argmax(axis=-1)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_results.shape)\ntest_results.Predictions.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit=pd.DataFrame()\nsubmit['PetID']=test['PetID']\nsubmit['AdoptionSpeed']=test['PetID'].apply(lambda x: calculate_score_from_predictions(test_results, x))\nsubmit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}