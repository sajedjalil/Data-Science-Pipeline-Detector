{"cells":[{"metadata":{"_uuid":"1a930704-8dc7-4f58-abf5-baee4f4877e9","_cell_guid":"5a023d87-0f28-4990-b64b-cf11bcaffc1f","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filen|ame))\n\ndef make_submission(patient_week,predictions,confidence):\n    submission = pd.DataFrame({'Patient_Week':new_test.Patient_Week,'FVC':predictions,'Confidence':confidence})\n    submission.to_csv('submission.csv',\n                      index = False)\n    return submission","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f1b7836-7269-4f2b-a4bd-b5aae99d6ade","_cell_guid":"5a5bee07-19b5-4ae7-bd68-4e394105da8c","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\ntest = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n#  also cnsider back time\ntrain_exp = pd.DataFrame()\n\nfor patient in tqdm(train.Patient.unique()):\n    df = train.loc[train.Patient == patient,:]\n\n    for idx,week,percent in zip(df.index,df.Weeks,df.Percent):\n        \n        temp_df_pos            = df.loc[idx:,:'SmokingStatus']\n        temp_df_pos['Percent'] = percent\n        temp_df_pos['Weeks']   = week\n        temp_df_pos['target']  = temp_df_pos['FVC']\n        temp_df_pos['delta']   = df.loc[idx:,'Weeks'] - df.loc[idx,'Weeks']\n        temp_df_pos['FVC']     = temp_df_pos.loc[idx,'FVC']\n        \n        \n        temp_df_neg            = df.loc[:idx,:'SmokingStatus']\n        temp_df_neg['Weeks']   = week\n        temp_df_neg['Percent'] = percent\n        temp_df_neg['target']  = temp_df_neg['FVC']\n        temp_df_neg['delta']   = df.loc[:idx,'Weeks'] - df.loc[idx,'Weeks']\n        temp_df_neg['FVC']     = temp_df_neg.loc[idx,'FVC']\n        \n        train_exp = pd.concat([train_exp,temp_df_pos,temp_df_neg],axis = 0)\n        train_exp = train_exp[train_exp.delta!=0].drop_duplicates().dropna(axis = 0).reset_index(drop =True)        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3640e009-23c0-432f-bf85-7b61f29a4547","_cell_guid":"b3b45b02-83b1-47b4-9a72-32b44b499567","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV,GroupKFold\nfrom sklearn.pipeline        import Pipeline, make_pipeline\nfrom sklearn.compose         import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics         import mean_squared_error,mean_absolute_error\n\nfrom sklearn.preprocessing   import OneHotEncoder,OrdinalEncoder\nfrom sklearn.preprocessing   import MinMaxScaler,StandardScaler,RobustScaler\nfrom sklearn.preprocessing   import FunctionTransformer\nfrom sklearn.ensemble        import RandomForestRegressor,ExtraTreesRegressor,GradientBoostingRegressor\nfrom sklearn.ensemble        import StackingRegressor\nfrom sklearn.linear_model    import LinearRegression\nfrom sklearn.naive_bayes     import MultinomialNB\n\nfrom sklearn.svm             import SVR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def confidence(pipe,regressor,X_val,transformer):\n    \n    val = transformer.transform(X_val)\n    predictions = []\n    for tree in pipe[regressor]:\n        predictions.append(tree.predict(val))\n\n    confidence = np.std(predictions,axis=0)\n    return confidence\n\n\ndef laplace_log_likelihood(actual_fvc, predicted_fvc, confidence, return_values = False):\n    \"\"\"\n    Calculates the modified Laplace Log Likelihood score for this competition.\n    \"\"\"\n    sd_clipped = np.maximum(confidence, 70)\n    delta = np.minimum(np.abs(actual_fvc - predicted_fvc), 1000)\n    metric = - np.sqrt(2) * delta / sd_clipped - np.log(np.sqrt(2) * sd_clipped)\n\n    if return_values:\n        return metric\n    else:\n        return np.mean(metric)\n\ndef pred_ints(model, X, percentile=.95):\n    \n    err_down = []\n    err_up = []\n    for x in range(len(X)):\n        preds = []\n        for pred in model['randomforestregressor'].estimators_:\n            preds.append(pred.predict(X[x].reshape(1,-1))[0])\n        err_down.append(np.percentile(preds, (100 - percentile) / 2. ))\n        err_up.append(np.percentile(preds, 100 - (100 - percentile) / 2.))\n        \n    return err_down, err_up","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_encoding(df, cols, target):\n    for c in cols:\n        means = df.groupby(c)[target].mean()\n        df[c].map(means)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_exp.drop(['Patient','target'],axis = 1) \ny = train_exp['target']\n\nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size = 0.1, \n                                               random_state = 42, \n                                               shuffle = True)\n\ntransformer = make_column_transformer( \n    (MinMaxScaler() , ['Age','Percent','delta','FVC','Weeks']), \n    (OneHotEncoder(),['Sex','SmokingStatus']), \n    remainder = 'passthrough' )\n\nX_train = transformer.fit_transform(X_train) \nX_val = transformer.transform(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf \nimport keras\n\ndef tilted_loss(q,y,f): \n    e = (y-f) \n    return keras.backend.mean(keras.backend.maximum(q*e, (q-1)*e), axis=-1)\n\nmodel = tf.keras.models.Sequential([\n\ntf.keras.layers.Dense(128,activation = 'relu'),\ntf.keras.layers.Dense(128,activation = 'relu'),\ntf.keras.layers.Dense(64,activation = 'relu'),\ntf.keras.layers.Dense(1)\n])\n\nquntiles = [0.25, 0.5, 0.75]\n\ny_val_predictions = [] \ny_train_predictions = [] \nmodels = []\n\nfor q in quntiles: \n    print(q,' quantile')\n    model.compile(loss = lambda y_true,y_pred: tilted_loss(q,y_true,y_pred), \n                  optimizer= tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-07,decay = 0.01,amsgrad=False), \n                  metrics = [tf.keras.metrics.RootMeanSquaredError()])\n\n    model.fit(X_train, y_train, \n              epochs=50, \n              batch_size=32, \n              steps_per_epoch = X_train.shape[0]//32,\n              validation_data = (X_val,y_val),\n              verbose=1)\n\n    y_val_pred_temp = model.predict(X_val)\n    y_train_pred_temp = model.predict(X_train)\n\n\n    y_val_predictions.append(y_val_pred_temp)\n    y_train_predictions.append(y_train_pred_temp)\n    \nprint('Train RMSE score: ',np.sqrt(mean_squared_error(y_train, y_train_predictions[1]))) \nprint('Val RMSE score: ',np.sqrt(mean_squared_error(y_val, y_val_predictions[1])))\n\nconfidence_train = (y_train_predictions[2] - y_train_predictions[0])\nconfidence_val = (y_val_predictions[2] - y_val_predictions[0])\n\nprint('Train OSCI score: ',laplace_log_likelihood(y_train, y_train_predictions[1].reshape(-1,), confidence_train.reshape(-1,), return_values = False)) \nprint('Val OSCI score: ',laplace_log_likelihood(y_val, y_val_predictions[1].reshape(-1,), confidence_val.reshape(-1,), return_values = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sub","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test = pd.DataFrame()\nfor i in np.arange(-12,134,1):\n    temp_df = test.copy()\n    temp_df['stamps'] = i\n    temp_df['delta'] = temp_df['Weeks'] +  temp_df['stamps']\n    new_test = pd.concat([new_test,temp_df])\n\nnew_test.reset_index(drop=True,inplace = True)\nnew_test['Patient_Week'] = new_test['Patient'] + '_' + new_test['stamps'].astype(str)\n\n\nX_test = new_test.drop(['Patient','stamps','Patient_Week'],axis = 1)\n\n\nX_test = transformer.transform(X_test)\n\n\nnew_test = pd.DataFrame()\nfor i in np.arange(-12,134,1):\n    temp_df = test.copy()\n    temp_df['stamps'] = i\n    temp_df['delta'] = temp_df['Weeks'] +  temp_df['stamps']\n    new_test = pd.concat([new_test,temp_df])\n\nnew_test.reset_index(drop=True,inplace = True)\nnew_test['Patient_Week'] = new_test['Patient'] + '_' + new_test['stamps'].astype(str)\n\n\nX_test = new_test.drop(['Patient','stamps','Patient_Week'],axis = 1)\n\n\nX_test = transformer.transform(X_test)\n\npredictions = []\n\nmodel = tf.keras.models.Sequential([\n\ntf.keras.layers.Dense(256,activation = 'relu'),\ntf.keras.layers.Dense(128,activation = 'relu'),\ntf.keras.layers.Dense(32,activation = 'relu'),\ntf.keras.layers.Dense(1)\n])\n\nquntiles = [0.25, 0.5, 0.75]\n\n\nfor q in quntiles:\n    print(q,' quantile')\n    model.compile(loss = lambda y_true,y_pred: tilted_loss(q,y_true,y_pred),\n                 optimizer= tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-07,decay = 0.01,amsgrad=False), \n                 metrics = [tf.keras.metrics.RootMeanSquaredError()])\n\n\n    model.fit(X_train, y_train, \n              epochs=50, \n              batch_size=32, \n              steps_per_epoch = X_train.shape[0]//32,\n              validation_data = (X_val,y_val),\n              verbose=0)\n    \n    pred_temp = model.predict(X_test)    \n    predictions.append(pred_temp)\n\n\nprint('Done')\nconfidence = abs(predictions[2] - predictions[0])\n\nmake_submission(new_test.Patient_Week,predictions[1].reshape(-1,),confidence.reshape(-1,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(confidence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}