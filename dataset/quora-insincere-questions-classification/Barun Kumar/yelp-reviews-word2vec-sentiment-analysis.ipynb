{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\n\nimport gensim\n\nprint(os.listdir(\"../input/\"))\nprint(os.listdir(\"../input//embeddings/GoogleNews-vectors-negative300/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89ac6b9fa535f52a6169e068c590d8ed78be927b"},"cell_type":"code","source":"link = \"../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n\nembeddings = gensim.models.KeyedVectors.load_word2vec_format(link, binary = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ad518ded1db1c4167ec157cff493658c1a87a6f"},"cell_type":"code","source":"## Reading files\n\nurl = \"https://raw.githubusercontent.com/skathirmani/datasets/master/yelp_labelled.csv\"\nyelp = pd.read_csv(url, sep = '\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14360ae36f20ae27f1a40596fb7bdbd3ba5e4553"},"cell_type":"code","source":"yelp = yelp.reset_index()\nyelp = yelp.rename(columns = {'index':'review','review  sentiment':'sentiment'})\nyelp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd394501b567ad0178078c88313b1a1fd47e0f0f"},"cell_type":"code","source":"## Using Stopwords (i.e removed)##\n\nimport nltk\n\ndocs_vectors = pd.DataFrame()  ## empty dataframe\nstopwords = nltk.corpus.stopwords.words('english')   ## !! added later\n\n## in below... all lowercase shall help in covering all the words, instead of adding \"\"A-Z\"\" in RegEx which may not provide suitable outputs\nfor doc in yelp['review'].str.lower().str.replace('[^a-z ]', ''):\n    temp = pd.DataFrame()   ## initially empty, and empty on every iteration\n    for word in doc.split(' '):  ## !!\n        if word not in stopwords: \n            try:\n                word_vec = embeddings[word]  ## if present, the following code applies\n                temp = temp.append(pd.Series(word_vec), ignore_index = True)  ## .Series to make it easier to append \"without\" index labels\n            except:\n                pass\n    doc_vector = temp.mean()\n    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) ## added to the empty data frame\n\n# docs_vectors.shape ## ==> (1000 x 300) order","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f01c90836d33ce56a4cd221319987ac47efcad27"},"cell_type":"code","source":"docs_vectors.head() ## a sparse matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67f620d13e0d322d7ab65ea376390e4048714afa"},"cell_type":"code","source":"## adding a column in docs_vector of \"sentiment\"  + dropping the null values\n\ndocs_vectors['sentiment'] = yelp['sentiment']\ndocs_vectors = docs_vectors.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e2a1b0dcf0166af09d501247f5060c83c424395"},"cell_type":"code","source":"# Adaptive Boost algorithm\n\nfrom sklearn.model_selection import train_test_split \n\n## here vectorization (vectorizer) again shall not come, since we are calculated weights \nfrom sklearn.ensemble import AdaBoostClassifier \n\ntrain_x, test_x, train_y, test_y = train_test_split(docs_vectors.drop('sentiment', axis = 1),\n                                                   docs_vectors['sentiment'],\n                                                   test_size = 0.2,\n                                                   random_state = 1)\n\ntrain_x.shape, test_x.shape, train_y.shape, test_y.shape  ## Test and Train partitions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2656af594fca278ce148bc682817efb049a83c3"},"cell_type":"code","source":"model = AdaBoostClassifier(n_estimators = 900, random_state = 1)\nmodel.fit(train_x, train_y)\n\ntest_pred = model.predict(test_x)\n\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(test_y, test_pred) )  \n\n## == 77.5% accuracy score using AdaBoost algorithm (with Stopwords removed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04599e126e27ebce6538f80ad7f36828f9faeb59"},"cell_type":"markdown","source":"**VADER package :Â¶\nValence Aware Dictionary and sEntiment Reasoner\n\nNOTE: '''presence of punctuations, capitals make impact on the individual / overall score... so DO NOT clean data or change anything in the text to avoid distorting the score\n\nAlso, works well for shorter documents.\n\nSTOPWORDS shall be HEEDED!\n\nSingle letter words are IGNORED! '''"},{"metadata":{"trusted":true,"_uuid":"b7241e3369bc200fcff29c297193914b4e18c3ec"},"cell_type":"code","source":"### Sentiment Analyzer to check out Sentiments\n\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\nsentiment = SentimentIntensityAnalyzer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"155cfe647fd1619d86217c41c84d9a8657f3248b"},"cell_type":"code","source":"reviews = yelp['review'].str.lower().str.replace('[^a-z ]', '')\nreviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0de6ac51672a3d4e9dc21c0bf10686a9f6672e0"},"cell_type":"code","source":"yelp['sentiment'].value_counts()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1435e06005bf223685884cca03fc2876c0e75114"},"cell_type":"code","source":"## Using a user-defined function to find out the sentiment out of Yelp reviews\n\ndef get_sentiment(text):\n    sentiment = SentimentIntensityAnalyzer() #### calling Intensity Analyzer\n    compound = sentiment.polarity_scores(text)['compound']  ### calling the 'compound' score for the \"text\" entered\n    if compound > 0:\n        return 1  ## positive\n    else:\n        return 0 ## negative\n    #else:\n        #return \"Neutral\"     \n    return compound\n\nyelp['sentiment_vader'] = yelp['review'].apply(get_sentiment) \nyelp['sentiment_vader'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c218d2b544c8ba13c757bff99c909b948af3c2d1"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(yelp['sentiment'], yelp['sentiment_vader']) \n\n## ==> improved accuracy using VADER","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}