{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel takes as input the forecast for the accuracy submission. Assuming that saless follow a poisson distribution, we compute the quantiles needed."},{"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_file = pd.read_csv('../input/ensemble-dark-magics/submission.csv')\nsample_submission = pd.read_csv('../input/m5-forecasting-uncertainty/sample_submission.csv')\ntrain_sales = pd.read_csv('/kaggle/input/m5-forecasting-uncertainty/sales_train_validation.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_file_validation = output_file[output_file['id'].str.contains(\"validation\")]\noutput_file_evaluation = output_file[output_file['id'].str.contains(\"evaluation\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_df = train_sales[['id','item_id','dept_id','cat_id','store_id','state_id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_file_validation = pd.merge(output_file_validation, id_df, how = 'left', on = 'id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sales_evaluation = train_sales\ntrain_sales_evaluation['id'] = train_sales_evaluation['id'].str.replace(r'validation$', 'evaluation')\nid_df = train_sales_evaluation[['id','item_id','dept_id','cat_id','store_id','state_id']]\noutput_file_evaluation = pd.merge(output_file_evaluation, id_df, how = 'left', on = 'id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quants = ['0.005', '0.025', '0.165', '0.250', '0.500', '0.750', '0.835', '0.975', '0.995']\ndays = range(1, 29)\nval_eval = ['validation', 'evaluation']\ntime_series_columns = [f'F{i}' for i in days]\ndef CreateSales( train_sales,name_list, group):\n    '''\n    This function returns a dataframe (sales) on the aggregation level given by name list and group\n    '''\n    rows_ve = [(name + \"_X_\" + str(q) + \"_\" + ve, str(q)) for name in name_list for q in quants for ve in val_eval]\n    sales = train_sales.groupby(group)[time_series_columns].sum() #would not be necessary for lowest level\n    return sales\ndef createTrainSet(sales_train_s,train_sales, name, group_level, X = False):\n    sales_total = CreateSales(train_sales,name, group_level)\n    if(X == True):\n        sales_total = sales_total.rename(index = lambda s:  s + '_X')\n    sales_train_s = sales_train_s.append(sales_total)\n    return(sales_train_s)\ndef get_agg_df(train_sales):\n    total = ['Total']\n    train_sales['Total'] = 'Total'\n    train_sales['state_cat'] = train_sales.state_id + \"_\" + train_sales.cat_id\n    train_sales['state_dept'] = train_sales.state_id + \"_\" + train_sales.dept_id\n    train_sales['store_cat'] = train_sales.store_id + \"_\" + train_sales.cat_id\n    train_sales['store_dept'] = train_sales.store_id + \"_\" + train_sales.dept_id\n    train_sales['state_item'] = train_sales.state_id + \"_\" + train_sales.item_id\n    train_sales['item_store'] = train_sales.item_id + \"_\" + train_sales.store_id\n    total = ['Total']\n    states = ['CA', 'TX', 'WI']\n    num_stores = [('CA',4), ('TX',3), ('WI',3)]\n    stores = [x[0] + \"_\" + str(y + 1) for x in num_stores for y in range(x[1])]\n    cats = ['FOODS', 'HOBBIES', 'HOUSEHOLD']\n    num_depts = [('FOODS',3), ('HOBBIES',2), ('HOUSEHOLD',2)]\n    depts = [x[0] + \"_\" + str(y + 1) for x in num_depts for y in range(x[1])]\n    state_cats = [state + \"_\" + cat for state in states for cat in cats]\n    state_depts = [state + \"_\" + dept for state in states for dept in depts]\n    store_cats = [store + \"_\" + cat for store in stores for cat in cats]\n    store_depts = [store + \"_\" + dept for store in stores for dept in depts]\n    prods = list(train_sales.item_id.unique())\n    prod_state = [prod + \"_\" + state for prod in prods for state in states]\n    prod_store = [prod + \"_\" + store for prod in prods for store in stores]\n    cols = [i for i in train_sales.columns if i.startswith('F')]\n    sales_train_s = train_sales[cols]\n    sales_train_s = pd.DataFrame()\n    sales_train_s = createTrainSet(sales_train_s,train_sales, total, 'Total', X=True) #1\n    sales_train_s = createTrainSet(sales_train_s, train_sales,states, 'state_id', X=True) #2\n    sales_train_s = createTrainSet(sales_train_s,train_sales, stores, 'store_id', X=True) #3\n    sales_train_s = createTrainSet(sales_train_s,train_sales, cats, 'cat_id', X=True) #4\n    sales_train_s = createTrainSet(sales_train_s,train_sales, depts, 'dept_id', X=True) #5\n    sales_train_s = createTrainSet(sales_train_s,train_sales, state_cats, 'state_cat') #6\n    sales_train_s = createTrainSet(sales_train_s,train_sales, state_depts, 'state_dept') #7\n    sales_train_s = createTrainSet(sales_train_s,train_sales, store_cats, 'store_cat') #8\n    sales_train_s = createTrainSet(sales_train_s,train_sales, store_depts, 'store_dept') #9\n    sales_train_s = createTrainSet(sales_train_s,train_sales, prods, 'item_id', X=True) #10\n    sales_train_s = createTrainSet(sales_train_s,train_sales, prod_state, 'state_item') #11\n    sales_train_s = createTrainSet(sales_train_s,train_sales, prod_store, 'item_store')\n    sales_train_s['id'] = sales_train_s.index\n    return(sales_train_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import poisson\nop_file = pd.DataFrame()\nfor i in quants:\n    print(i)\n    output_file_validation_i = output_file_validation.copy()\n    if(i!='0.500'):\n        output_file_validation_i[time_series_columns]= output_file_validation_i[time_series_columns].applymap(lambda x: (x%1)*poisson.ppf(float(i), np.ceil(x)) + (1-x%1)*poisson.ppf(float(i), np.floor(x)))\n    output_file_validation_i = get_agg_df(output_file_validation_i)\n    output_file_validation_i['id'] = output_file_validation_i['id'] + '_' + i + '_validation'\n    op_file = pd.concat([op_file, output_file_validation_i], ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in quants:\n    output_file_evaluation_i = output_file_evaluation.copy()\n    if(i!='0.500'):\n\n        output_file_evaluation_i[time_series_columns]= output_file_evaluation[time_series_columns].applymap(lambda x: (x%1)*poisson.ppf(float(i), np.ceil(x)) + (1-x%1)*poisson.ppf(float(i), np.floor(x)))\n    output_file_evaluation_i = get_agg_df(output_file_evaluation_i)\n    output_file_evaluation_i['id'] = output_file_evaluation_i['id'] + '_' + i + '_evaluation'\n    op_file = pd.concat([op_file, output_file_evaluation_i], ignore_index = True)\n\nsample_submission = sample_submission.id.to_frame()\nsample_submission = pd.merge(sample_submission, op_file, on = 'id', how = 'left')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('lgb1_sub.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}