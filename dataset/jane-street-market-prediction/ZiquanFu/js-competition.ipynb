{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import datatable as dt\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, SequentialSampler\nfrom torch.nn import CrossEntropyLoss\nfrom sklearn.metrics import log_loss, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loading data...')\n\ntrain_datatable = dt.fread('/kaggle/input/jane-street-market-prediction/train.csv')\ndf = train_datatable.to_pandas()\ndel train_datatable\n\ndisplay(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def utility_score_bincount(date, weight, resp, action):\n    '''\n    Credits to Kaggle user Lindada with this implementation of the utility score for the competition\n    '''\n    \n    count_i = len(np.unique(date))\n    Pi = np.bincount(date, weight * resp * action)\n    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n    u = np.clip(t, 0, 6) * np.sum(Pi)\n    return u","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(df):\n    \n    # Someone observe that it is better using train.date > 85\n    # train = train.loc[train.date > 85].reset_index(drop=True)\n    \n    # Add action column based on the resp\n    df['action'] = (df['resp'] > 0).astype('int')\n    \n    # NaN values: fill with mean\n    fill_val = df.mean()\n    df = df.fillna(fill_val)\n    \n    # Split the training and validation data, leave the last 50 dates for validation\n    valid = df.loc[(df.date >= 450) & (df.date < 500)].reset_index(drop=True)\n    train = df.loc[df.date < 450].reset_index(drop=True)\n    \n    # Save validation set for testing\n    valid.to_csv('/kaggle/working/val.csv')\n    \n    return train, valid\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Construct dataset for PyTorch training"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset:\n    \n    def __init__(self, data):\n        feat_cols = [f'feature_{i}' for i in range(130)]\n        self.features = data[feat_cols].values\n        self.label = data['action'].values\n        \n    def __getitem__(self, idx):\n        return {\n                'features': torch.tensor(self.features[idx], dtype=torch.float),\n                'label': torch.tensor(self.label[idx], dtype=torch.float)\n                }\n    \n    def __len__(self):\n        return len(self.features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define the neural network I use."},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    \n    def __init__(self):\n        super(Model, self).__init__()\n        \n        self.linear1 = nn.Linear(129, 256)\n        self.dropout1 = nn.Dropout(p=0.1)\n        self.BatchNorm1d_1 = nn.BatchNorm1d(256)\n        \n        self.linear2 = nn.Linear(256, 128)\n        self.dropout2 = nn.Dropout(p=0.2)\n        self.BatchNorm1d_2 = nn.BatchNorm1d(128)\n        \n        self.linear3 = nn.Linear(128, 64)\n        self.dropout3 = nn.Dropout(p=0.1)\n        self.BatchNorm1d_3 = nn.BatchNorm1d(64)\n        \n        self.linear4 = nn.Linear(65,1)\n        \n        self.sigmoid = nn.Sigmoid()\n        \n        self.LeakyReLU = nn.LeakyReLU(inplace=True)\n  \n\n    def forward(self,x):\n        \n        x_continuous = x[:,1:]\n        x_binary = x[:,0] # Take out the only binary variable\n        \n        out = self.linear1(x_continuous)\n        out = self.LeakyReLU(out)\n        out = self.dropout1(out)\n        out = self.BatchNorm1d_1(out)\n        \n        out = self.linear2(out)\n        out = self.LeakyReLU(out)\n        out = self.dropout2(out)\n        out = self.BatchNorm1d_2(out)\n        \n        out = self.linear3(out)\n        out = self.LeakyReLU(out)\n        out = self.dropout3(out)\n        out = self.BatchNorm1d_3(out)\n        \n        \n        out = torch.cat((out, x_binary.unsqueeze(1)),dim=1) # Combine the binary variable back\n        out = self.linear4(out)\n        out = self.sigmoid(out)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_one_epoch(model, optimizer, dataloader, loss_fn, device):\n    '''\n    Train for one epoch and returns training loss\n    '''\n    \n    model.train()\n    total_loss = 0\n    \n    for batch in dataloader:\n        optimizer.zero_grad()\n        x = batch['features'].to(device)\n        y = batch['label'].to(device)\n        \n        output = model(x)\n        loss = loss_fn(output.squeeze(),y.squeeze())\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss\n        \n    return total_loss/len(dataloader)\n\n\ndef validation(model, dataloader, device, valid):\n    \"\"\"\n    Function for validation at the end of each epoch\n    \"\"\"\n    \n    model.eval()\n    prediction = []\n    ground_truth = []\n    \n    for batch in dataloader:\n        x = batch['features'].to(device)\n        y = batch['label'].to(device)\n        with torch.no_grad():\n            output = model(x)\n        prediction.append(output.squeeze().detach().cpu().numpy())\n        ground_truth.append(y.squeeze().detach().cpu().numpy())\n        \n    prediction = np.concatenate(prediction).reshape(-1,1).squeeze()\n    ground_truth = np.concatenate(ground_truth).reshape(-1,1).squeeze()\n    \n    logloss = log_loss(ground_truth, prediction) # Calculate log loss of the predicted probability\n    \n    pred_label = np.where(prediction >= 0.5, 1, 0).astype(int) # Assign label based on predicted probability\n    \n    accuracy = accuracy_score(ground_truth, pred_label) # Calculate accuracy based on predicted label\n    \n    # Calculate utility score (cumulative returns)\n    utility = utility_score_bincount(date=valid.date.values, weight=valid.weight.values,\n                                                   resp=valid.resp.values, action=pred_label)\n        \n    return logloss, accuracy, utility\n    \n\n    \ndef train(df, n_epochs):\n    '''\n    Function for training\n    '''\n    \n    train, valid = preprocessing(df)\n    \n    train_set = Dataset(train)\n    val_set = Dataset(valid)\n    \n    train_loader = DataLoader(train_set, batch_size=4096, shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_set, batch_size=4096, shuffle=False, num_workers=4)\n    \n    device = torch.device(\"cuda\")\n    model = Model()\n    model.to(device)\n    \n    #optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-5)\n    optimizer = torch.optim.SGD(model.parameters(),0.05,0.9) # Use SGD because it empirically performs better according to my experiments\n    loss_fn = nn.BCELoss() # Binary cross entropy loss\n    \n    for epoch in range(n_epochs):\n        epoch_loss = train_one_epoch(model, optimizer, train_loader, loss_fn, device)\n        logloss, accuracy, utility = validation(model, val_loader, device, valid)\n        print(f\"EPOCH: {epoch}\")\n        print(f\"Training loss: {epoch_loss: .5f}  \" \n               f\"Validation logloss: {logloss: .3f}  \"\n                f\"Validation accuracy: {accuracy: .2f}  \"\n                 f\"Utility score: {utility: .2f}\")\n        print('\\n')\n    \n    torch.save(model.state_dict(), '/kaggle/working/model.pt')\n    print('Training finished, model saved!')\n    \n    backtest_set = val_set\n    \n    return backtest_set # Return the validation dataset as the backtest dataset\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"backtest_set = train(df, n_epochs=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define function to do inference. Predict the label on the validation dataset by sequence."},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference(backtest_data, model_path):\n    device = torch.device(\"cuda\")\n    model = Model()\n    model.load_state_dict(torch.load(model_path))\n    model.to(device)\n    model.eval()\n    \n    inf_sampler = SequentialSampler(backtest_data)\n    inf_loader = DataLoader(backtest_data, sampler = inf_sampler)\n    \n    prediction = []\n    ground_truth = []\n    \n    for data in inf_loader:\n        x = data['features'].to(device)\n        y = data['label'].to(device)\n        with torch.no_grad():\n            output = model(x)\n        prediction.append(output.squeeze().detach().cpu().numpy())\n        ground_truth.append(y.squeeze().detach().cpu().numpy())\n        \n    prediction = np.array(prediction).reshape(-1,1).squeeze()\n    pred_label = np.where(prediction >= 0.5, 1, 0).astype(int)\n    \n    return pred_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_label = inference(backtest_set, '/kaggle/working/model.pt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save results for back testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.savetxt('/kaggle/working/prediction_NN.csv', pred_label, delimiter=',')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}