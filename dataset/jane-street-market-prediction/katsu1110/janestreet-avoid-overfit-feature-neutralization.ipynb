{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://numer.ai/homepage/img/Numerai-Logo-Side-Black.png)\n\n(UPDATE)\nThere has been some confusion with this method mainly regarding how to perform feature neutralization in the test data. I add a section about it. Also have a look at [Avoid Overfitting by Feature Neutralization](https://www.kaggle.com/c/jane-street-market-prediction/discussion/215305).\n\n\nIt has been fun to overfit the public LB (historical data) by whatever NN you like (MLP, 1DCNN, ResNet...you name it), but I feel like it is time to consider what we can do to avoid overfitting to perform well in the private test set (future data).\n\nThere are several ways to proceed, and easy ones are:\n\n- increase regularization in a NN model (increase dropout, reduce batch size, add noise, etc)\n- increase the action threshold (from 0.500 to somewhat higher)\n\nIn this notebook, I introduce you a very effective appoarch widely used in the [Numerai Tournament](https://numer.ai/): **Feature Neutralization**. \n\nNumerai Tournament is essentially very similar to this JaneStreet competition where participants submit a model prediction to the weekly tournament data and get paid by its performance. So whatever works in the Numerai Tournament should hopefully work here.\n\nSo what is feature neutralization? How can we avoid overfitting by using it??\n"},{"metadata":{},"cell_type":"markdown","source":"# Feature Neutralization in a Nutshell\n\n![](https://forum.numer.ai/uploads/default/original/1X/e1d39e8f38ae51c1189ee85fd9578a2a555a3c06.jpeg)\n\nFeature neutralization is a technique to keep as much infomration as possible of a vector, simultaneously reducing linear-dependent information on another vector. Essentially we **take the residuals of a vector by linear regression** with another vector as a feature.\n\nHow is it useful?\n\nIt is useful because by applying the feature neutralization to the features on the target, we can get a set of features that contain as much original information as possible but decorrelate with the target.\n\nImagine a situation where one feature is very correlated with the target (which is often the case with ML in finance). When you train a model, the model jumps to the feature and ignores else. This is fine as long as you are validating your model with historical data. You may get a very high utility score.\n\nHowever, when you deploy the model for forecasting, there may be a situation in the future where that very strong feature becomes useless. Like pandemic, war, political affairs, you name it. What if that happens? \n\nMaybe the sign of the strong feature flips. \n\nThen **the sign of your model prediction also flips**...sell when you should buy, buy when you should sell.  \n\nApparently this is a catastrophic scenario for an investor...but this is often the consequence when you use an overfitting model just because no feature is perfect in a financial market. \n\n**You might want to have a model where it is not dependent on single features!**\n\nFeature neutralization helps you to have that kind of model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# code to feature neutralize\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.auto import tqdm\n\ndef neutralize_series(series : pd.Series, by : pd.Series, proportion=1.0):\n    \"\"\"\n    neutralize pandas series (originally from the Numerai Tournament)\n    \"\"\"\n    scores = series.values.reshape(-1, 1)\n    exposures = by.values.reshape(-1, 1)\n    exposures = np.hstack((exposures, np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n    correction = proportion * (exposures.dot(np.linalg.lstsq(exposures, scores)[0]))\n    corrected_scores = scores - correction\n    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n    return neutralized","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By using the above script, you can neutralize your feature vector by another one (e.g. target)."},{"metadata":{},"cell_type":"markdown","source":"# Is our model prediction strongly correlated with a particular feature?\nFirst, let's check this. I use a model prediction from [[JaneStreet] simple LGB with GroupKFold](https://www.kaggle.com/code1110/janestreet-simple-lgb-with-groupkfold?scriptVersionId=52979104)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# load competition data\ntrain = pd.read_feather('../input/janestreet-save-as-feather/train.feather')\ntrain = train.query('weight > 0').reset_index(drop=True)\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load model prediction\noof = np.load('../input/janestreet-simple-lgb-with-groupkfold/oof.npy')\nprint(oof.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add oof prediction to train\ntrain['oof'] = oof\n\n# fillna\nfeatures = train.columns[train.columns.str.startswith('feature')].values.tolist()\nfor f in features:\n    train[f] = train[f].fillna(train[f].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To see how strongly our model prediction is correlated with a particularly feature, we compute **feature exposure**."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr\n\ndef feature_exposures(df, prediction_name='resp'):\n    feature_names = [f for f in df.columns\n                     if f.startswith(\"feature\")]\n    exposures = []\n    for f in feature_names:\n#         fe = spearmanr(df[prediction_name], df[f])[0]\n        fe = np.corrcoef(df[prediction_name], df[f])[0, 1]\n        exposures.append(fe)\n    return np.array(exposures)\n\n\ndef max_feature_exposure(df):\n    return np.max(np.abs(feature_exposures(df)))\n\n\ndef feature_exposure(df):\n    return np.sqrt(np.mean(np.square(feature_exposures(df))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute feature exposure\nfes = feature_exposures(train, 'oof')\nfes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Max feature exposure of the LGB model = {}'.format(np.max(np.abs(fes))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib_venn import venn2\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('fivethirtyeight')\npd.options.display.max_columns = None\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfes_df = pd.DataFrame()\nfes_df['features'] = np.array(features)\nfes_df['features'] = fes_df['features'].apply(lambda x : str(x).split('_')[-1])\nfes_df['corr_to_oof'] = fes\n\nfig, ax = plt.subplots(1, 1, figsize=(20, 5))\nsns.barplot(x='features', y='corr_to_oof', data=fes_df, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow, although the LGB model is not that strong, the prediction is highly correlated with some features! So the LGB model may fail misrablly if those features become useless.\n\nHow does the model overfit? Likely because the provided features are highly correlated with the target in the first place."},{"metadata":{"trusted":true},"cell_type":"code","source":"fes = feature_exposures(train, 'resp')\n\nfes_df = pd.DataFrame()\nfes_df['features'] = np.array(features)\nfes_df['features'] = fes_df['features'].apply(lambda x : str(x).split('_')[-1])\nfes_df['corr_to_resp'] = fes\n\n\nfig, ax = plt.subplots(1, 1, figsize=(20, 5))\nsns.barplot(x='features', y='corr_to_resp', data=fes_df, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exactly. The LGB model just learned the correlation pattern between the features and targets. So if a strong feature flips its sign for whatever reason, we are doomed.\n\n\nLet's perform feature neutralization to avoid such doom. This can be done in the following."},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature neutralization\nfor f in tqdm(features):\n    # neut\n    neut = neutralize_series(train[f], train['resp'], proportion=1.0)\n    \n    # verify\n    original_corr = np.corrcoef(train[f].values, train['resp'].values)[0, 1]\n    neut_corr = np.corrcoef(neut, train['resp'].values)[0, 1]\n    f_corr = np.corrcoef(train[f].values, neut)[0, 1]\n    print('{}: original corr to target={:.3f}, corr to target after neut={:.3f}, corr with old and neut feat={:.3f}'.format(f,\n        original_corr, neut_corr, f_corr))\n    \n    # assign\n    train[f] = neut.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So **by feature neutralization we can effectively decrease the correlation to the target while keeping the correlation to the original feature**.\n\nHow the correlation of each feature with the target change?"},{"metadata":{"trusted":true},"cell_type":"code","source":"fes = feature_exposures(train, 'resp')\n\nfes_df = pd.DataFrame()\nfes_df['features'] = np.array(features)\nfes_df['features'] = fes_df['features'].apply(lambda x : str(x).split('_')[-1])\nfes_df['corr_to_resp'] = fes\n\nfig, ax = plt.subplots(1, 1, figsize=(20, 5))\nsns.barplot(x='features', y='corr_to_resp', data=fes_df, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you compare this figure to the previous one in terms of the y-axis, you realize that after the feature neutralization **the correlation of each feature to the target is decreased a lot**!\n\nIf you think completely neutralizing all the features to the target is too much, you can \n\n- decrease the proportion of neutralization\n- change the sets of features to be neutralized"},{"metadata":{},"cell_type":"markdown","source":"# How can we use feature neutralization in the test data?\nThis is of course what everyone is interested in. Initially I did not want to disclose how to do it but yeah, you can find the answer anyway in this Numerai forum.\n\n[Model Diagnostics: Feature Exposure](https://forum.numer.ai/t/model-diagnostics-feature-exposure/899)\n\nEssentially you need to **neutralize prediction by features** such that your prediction is not sorely dependent on some strong features.\n\nThe following function is what Numeraiers are using every weekend:D"},{"metadata":{"trusted":true},"cell_type":"code","source":"def neutralize(df, target=\"resp\", by=None, proportion=1.0):\n    if by is None:\n        by = [x for x in df.columns if x.startswith('feature')]\n\n    scores = df[target]\n    exposures = df[by].values\n\n    # constant column to make sure the series is completely neutral to exposures\n    exposures = np.hstack((exposures, np.array([np.mean(scores)] * len(exposures)).reshape(-1, 1)))\n\n    scores -= proportion * (exposures @ (np.linalg.pinv(exposures) @ scores.values))\n    return scores / scores.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In conclusion, if you want to avoid overfitting, you might consider feature neutralization. \n\nEnjoy!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}