{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <u>Jane Street Market Prediction Competition</u>\n*Lucian Craciun,*\n*February 7th, 2021*"},{"metadata":{},"cell_type":"markdown","source":"# I. Explanatory Data Analysis\n(section based on the following notebook: https://www.kaggle.com/carlmcbrideellis/jane-street-eda-of-day-0-and-feature-importance)"},{"metadata":{},"cell_type":"markdown","source":"## Initial Setup"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datatable as dt\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport shap\nfrom sklearn import manifold\n\nimport warnings\nimport pickle\nimport gc\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import Trials, STATUS_OK, hp, tpe, fmin\nimport catboost\nfrom catboost import *\nimport lightgbm as lgb\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix, log_loss, precision_recall_curve, auc, roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"experiment_name = 'janestreet_v1_new_wc'","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.set_style(\"darkgrid\")\n\nplt.rcParams['figure.figsize'] = (15, 5)\nplt.rcParams['figure.titlesize'] = 20\nplt.rcParams['axes.titlesize'] = 20\nplt.rcParams['font.size'] = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle_dir = '/kaggle/working/pickle_files/'\nif os.path.isdir(pickle_dir) == False:\n    os.mkdir(pickle_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Import"},{"metadata":{},"cell_type":"markdown","source":"Using the `datatable` library, very suitable for large datasets (as the train data adds up to `~5.77GB`), the data import is done in less than 15 seconds (vs more than 2 minutes using the pandas `read_csv` usual way)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype.name\n\n        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            c_sum = df[col].sum()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_sum < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int16).min and c_sum < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_sum < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_sum < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_sum < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_sum < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = (\n    dt.fread('../input/jane-street-market-prediction/train.csv')\n      .to_pandas()\n      # .query('weight > 0')\n      .pipe(reduce_mem_usage)\n)\n\nfeature_names = df_train.columns[df_train.columns.str.contains('feature')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# df_example_test = (\n#     dt.fread('../input/jane-street-market-prediction/example_test.csv')\n#       .to_pandas()\n#       # .query('weight > 0')\n#       .pipe(reduce_mem_usage)\n# )","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# # Data loading function\n# def load_data():\n#     data_path = '/kaggle/input/jane-street-market-prediction/'\n#     data_files_list = ['train', 'features', 'example_test', 'example_sample_submission']\n    \n#     df_train_datatable = dt.fread(data_path + data_files_list[0] + \".csv\")\n#     df_features_datatable = dt.fread(data_path + data_files_list[1] + \".csv\")\n#     df_example_test_datatable = dt.fread(data_path + data_files_list[2] + \".csv\")\n#     df_example_sample_submission_datatable = dt.fread(data_path + data_files_list[3] + \".csv\")\n    \n#     df_train = df_train_datatable.to_pandas()\n#     df_features = df_features_datatable.to_pandas()\n#     df_example_test = df_example_test_datatable.to_pandas()\n#     df_example_sample_submission = df_example_sample_submission_datatable.to_pandas()\n    \n#     return df_train, df_features, df_example_test, df_example_sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# df_train, df_features, df_example_test, df_example_sample_submission = load_data()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset shape\nprint(\"Train Dataset Shape: \" + str(df_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset columns\ndf_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset fields and types\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dtypes[df_train.dtypes=='int32']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset head\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for duplicates\ndf_train.duplicated().sum() # 0 - no duplicated rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe(include=[np.number]).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validation & Cleaning"},{"metadata":{},"cell_type":"markdown","source":"**Data Quantity**"},{"metadata":{},"cell_type":"markdown","source":"There are 500 days in the data (equivalently, 2 years of data considering ~250 trading days per year for NYSE). Moreover, some patterns seem to change after the 85th day, potentially a change in the Jane Street trading models, fact emphasized in the following sections."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"id_field = 'ts_id'\ndate_field = 'date'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Description of the no. of potential transactions per day (mean, std, quantiles etc.), by date\ndf_train.groupby(date_field).count()[id_field].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft = df_train.set_index(df_train[date_field]).sort_index()\ncount = pd.DataFrame(dft.groupby(dft.index)[id_field].count())\ncount.columns = ['Number of daily entries']\n\nax = count.plot(title = str(len(df_train[id_field].unique())-1) + ' total observations')\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Number of entries\")\nax.legend(loc=\"upper right\")\n\nax.axvline(x=85, linestyle='--', alpha=0.3, c='red', lw=1)\nax.axvspan(0, 85 , color=sns.xkcd_rgb['grey'], alpha=0.1)\n\ndel dft\ndel count\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft = df_train.set_index(df_train[date_field]).sort_index()\ncount = pd.DataFrame(dft.groupby(dft.index)[id_field].count())\n\nfig, ax = plt.subplots(figsize=(15, 5))\nplt.plot(6.5 * 60 * 60 / count)\nax.set_xlabel (\"Day\")\nax.set_ylabel (\"Av. time between trades (s)\", fontsize=18)\nax.set_title (\"Average time between trades for each day (assuming a 6.5h daily trading interval)\")\nax.axvline(x=85, linestyle='--', alpha=0.3, c='red', lw=1)\nax.axvspan(0, 85 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nax.set_xlim(xmin=0)\nax.set_xlim(xmax=500)\nax.set_ylim(ymin=0)\nax.set_ylim(ymax=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_seas = df_train.groupby(date_field)[[id_field]].count()\ndf_seas.hist(bins=100)\n\nplt.xlabel(\"No. of days\")\nplt.ylabel(\"No. of daily entries\")\nplt.title(\"Histogram of the no. of daily entries\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Considering a 'rolling' 30-days window and displaying the evolution over time of the no. of observations covered every day\ndft = df_train.set_index(df_train[date_field]).sort_index()\ncount = pd.DataFrame(dft.groupby(dft.index)[id_field].count().rolling(30, min_periods=1).mean())\ncount.columns = ['30-day rolling mean of number of observations per day']\n\nax = count.plot(title = str(len(df_train[id_field].unique())-1) + ' total observations')\nax.set_xlabel(\"Date\")\nax.set_ylabel(\"Number of entries\")\nax.legend(loc=\"upper right\", prop={'size': 18})\nax.axvline(x=85, linestyle='--', alpha=0.3, c='red', lw=1)\nax.axvspan(0, 85 , color=sns.xkcd_rgb['grey'], alpha=0.1)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"del dft\ndel count\ndel df_seas\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Entries no. autocorrelation\n\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(df_train.groupby(date_field)[id_field].count().values, lags=21) # monthly\nplot_acf(df_train.groupby(date_field)[id_field].count().values, lags=252) # yearly\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing Rates**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the missing entries per field\n\nmissings_df = df_train.isna().sum() * 100 / len(df_train)\nax = missings_df.plot(kind='bar', title='% of data points with missing values')\nax.set_xlabel(\"Data fields\")\nax.set_ylabel('% of missing entries')\n\nax.set_xticklabels([], rotation=30, horizontalalignment='right')\n\ndisplay()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"del missings_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Profiling"},{"metadata":{},"cell_type":"markdown","source":"**1. 'resp' fields**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 5)\n\nax = sns.distplot(df_train['resp'], \n             bins=3000, \n             kde_kws={\"clip\":(-0.05,0.05)}, \n             hist_kws={\"range\":(-0.05,0.05)},\n             color='darkcyan', \n             kde=False);\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the 'resp' values\")\nplt.title(\"'resp' Distribution\")\nplt.show()\n\nprint(\"Minimum value: \" + str(np.round(df_train['resp'].min(), 2)))\nprint(\"Maximum value: \" + str(np.round(df_train['resp'].max(), 2)))\n\n\nplt.rcParams['figure.figsize'] = (15, 5)\nfig, ax = plt.subplots(2, 2, sharex=True, sharey=True)\n\nvar_list = ['resp_1', 'resp_2', 'resp_3', 'resp_4']\nax_list = [ax[0,0], ax[0,1], ax[1,0], ax[1,1]]\n\nfor var, ax in zip(var_list, ax_list):\n    ax = sns.distplot(df_train[var],\n                 label = \"'\" + str(var) + \"' distn\",\n                 ax = ax,\n                 bins = 3000, \n                 kde_kws = {\"clip\":(-0.05,0.05)}, \n                 hist_kws = {\"range\":(-0.05,0.05)},\n                 color = 'darkcyan', \n                 kde = False);\n    values = np.array([rec.get_height() for rec in ax.patches])\n    norm = plt.Normalize(values.min(), values.max())\n    colors = plt.cm.jet(norm(values))\n    for rec, col in zip(ax.patches, colors):\n        rec.set_color(col)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 5))\n\ndf = df_train.copy()\n\nbalance= pd.Series(df['resp']).cumsum()\n\n# Normalizing the longer horizons returns\nresp_1= pd.Series(np.power(df['resp_1'] + 1, 1) - 1).cumsum()\nresp_2= pd.Series(np.power(df['resp_2'] + 1, 1/2) - 1).cumsum()\nresp_3= pd.Series(np.power(df['resp_3'] + 1, 1/3) - 1).cumsum()\nresp_4= pd.Series(np.power(df['resp_4'] + 1, 1/4) - 1).cumsum()\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_title (\"Cumulative resp and time horizons 1, 2, 3, and 4 (500 days)\")\n\nbalance.plot(lw=3)\nresp_1.plot(lw=3)\nresp_2.plot(lw=3)\nresp_3.plot(lw=3)\nresp_4.plot(lw=3)\nplt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5));\n\ndel resp_1\ndel resp_2\ndel resp_3\ndel resp_4\n\ndel df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considering a cumulative sum of daily returns, it seems that best returns are achieved for shorter horizons."},{"metadata":{},"cell_type":"markdown","source":"**2. 'weight'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 5)\n\nax = sns.distplot(df_train['weight'], \n             bins=3000, \n             color='darkcyan', \n             kde=False);\n# ax.set(xscale='log')\nax.set(yscale='log')\n\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the 'weight' values\")\nplt.title(\"'weight' Distribution\")\nplt.show()\n\nprint(\"Minimum value: \" + str(np.round(df_train['weight'].min(), 2)))\nprint(\"Maximum value: \" + str(np.round(df_train['weight'].max(), 2)))\n\nprint(\"% of 0.0 values: \" + \n      str(np.round((df_train['weight'].values == 0).sum() / len(df_train) * 100, 2)) + \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft = df_train.set_index(df_train[date_field]).sort_index()\ncount = pd.DataFrame(dft.groupby(dft.index)[id_field].count())\ncount.columns = ['Number of daily entries']\n\nfrom scipy.stats import pearsonr\n\ndf_corr = df_train.groupby(date_field)[['weight']].sum().merge(count, on='date')\ndf_corr['ratio'] = df_corr['weight'] / df_corr['Number of daily entries']\n\ncorr, _ = pearsonr(df_corr['weight'], df_corr['Number of daily entries'])\nprint('Pearsons correlation: %.3f' % corr)\n\nplt.rcParams['figure.figsize'] = (7, 7)\n\nplt.scatter(df_corr['weight'], df_corr['Number of daily entries'])\nplt.xlabel('cummulative weight')\nplt.ylabel('no. of daily entries')\nplt.show()\n\ndel dft\ndel count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sum of daily weights looks very correlated with the no. of daily potential trades, with a pearsonr coefficient of 0.877."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 5)\ndf_corr['ratio'].plot(title=\"Daily ration between cummulative weight and # potential trades\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,5))\nax = sns.distplot(df_train['weight'], \n             bins=1400, \n             kde_kws={\"clip\":(0.001,1.4)}, \n             hist_kws={\"range\":(0.001,1.4)},\n             color='darkcyan', \n             kde=False);\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of non-zero weights (up to 1.4)\")\nplt.show();\n\ndel values\ndel df_corr\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_nonZero = df_train.query('weight > 0').reset_index(drop = True)\nplt.figure(figsize = (10,4))\nax = sns.distplot(np.log(df_train_nonZero['weight']), \n             bins=1000, \n             kde_kws={\"clip\":(-4,5)}, \n             hist_kws={\"range\":(-4,5)},\n             color='darkcyan', \n             kde=False);\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the logarithm of the non-zero weights\")\nplt.show()\n\ndel df_train_nonZero\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.groupby(date_field)['weight'].sum().plot(title='Cummulative daily weight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Cummulative return: 'weight' * 'resp'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_train.copy()\ndf = df[df['weight'] > 0]\ndf['wr'] = df['weight'] * df['resp']\n\nplt.rcParams['figure.figsize'] = (15, 5)\n\nax = sns.distplot(df['wr'], \n             bins=2000, \n             kde_kws={\"clip\":(-0.02,0.02)}, \n             hist_kws={\"range\":(-0.02,0.02)},\n             color='darkcyan', \n             kde=False);\n# ax.set(yscale='log')\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the 'weight' * 'resp' values\")\nplt.title(\"'weight' * 'resp' Distribution\")\nplt.show()\n\nprint(\"Minimum value: \" + str(np.round(df['wr'].min(), 2)))\nprint(\"Maximum value: \" + str(np.round(df['wr'].max(), 2)))\n\ndel df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_train.copy()\n\ndf['weight_resp']   = df['weight'] * df['resp']\ndf['weight_resp_1'] = df['weight'] * (np.power(df['resp_1'] + 1, 1) - 1)\ndf['weight_resp_2'] = df['weight'] * (np.power(df['resp_2'] + 1, 1/2) - 1)\ndf['weight_resp_3'] = df['weight'] * (np.power(df['resp_3'] + 1, 1/3) - 1)\ndf['weight_resp_4'] = df['weight'] * (np.power(df['resp_4'] + 1, 1/4) - 1) \n\nfig, ax = plt.subplots(figsize=(15, 5))\n\nresp    = pd.Series(1 + df.groupby('date')['weight_resp'].mean()).cumprod()\nresp_1  = pd.Series(1 + df.groupby('date')['weight_resp_1'].mean()).cumprod()\nresp_2  = pd.Series(1 + df.groupby('date')['weight_resp_2'].mean()).cumprod()\nresp_3  = pd.Series(1 + df.groupby('date')['weight_resp_3'].mean()).cumprod()\nresp_4  = pd.Series(1 + df.groupby('date')['weight_resp_4'].mean()).cumprod()\n\nax.set_xlabel (\"Day\", fontsize=18)\nax.set_title (\"Cumulative daily return for resp and time horizons 1, 2, 3, and 4 (500 days)\", fontsize=18)\nresp.plot(lw=3, label='resp x weight')\nresp_1.plot(lw=3, label='resp_1 x weight')\nresp_2.plot(lw=3, label='resp_2 x weight')\nresp_3.plot(lw=3, label='resp_3 x weight')\nresp_4.plot(lw=3, label='resp_4 x weight')\n# day 85 marker\nax.axvline(x=85, linestyle='--', alpha=0.3, c='red', lw=1)\nax.axvspan(0, 85 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nplt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5));\n\ndel df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Features**"},{"metadata":{},"cell_type":"markdown","source":"*> feature_0*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['feature_0'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_0_is_plus_one  = df_train.query('feature_0 ==  1').reset_index(drop = True)\nfeature_0_is_minus_one = df_train.query('feature_0 == -1').reset_index(drop = True)\n# the plot\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4))\nax1.plot((pd.Series(feature_0_is_plus_one['resp']).cumsum()), lw=3, label='resp')\nax1.plot((pd.Series(feature_0_is_plus_one['resp']*feature_0_is_plus_one['weight']).cumsum()), lw=3, label='return')\nax2.plot((pd.Series(feature_0_is_minus_one['resp']).cumsum()), lw=3, label='resp')\nax2.plot((pd.Series(feature_0_is_minus_one['resp']*feature_0_is_minus_one['weight']).cumsum()), lw=3, label='return')\nax1.set_title (\"feature 0 = 1\", fontsize=18)\nax2.set_title (\"feature 0 = -1\", fontsize=18)\nax1.legend(loc=\"lower left\")\nax2.legend(loc=\"upper left\")\n\ndel feature_0_is_plus_one\ndel feature_0_is_minus_one\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that this feature clearly differentiates the type of trades, as they represent distinct return dynamics. One assumption is that it labels a 'long' trade vs a 'short' one."},{"metadata":{},"cell_type":"markdown","source":"*> features_{1...129}*"},{"metadata":{},"cell_type":"markdown","source":"There seem to exist 4 different features types by their value structure."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10))\n\nax1.plot((pd.Series(df_train['feature_1']).cumsum()), lw=3, color='red')\nax1.set_title (\"Linear\", fontsize=20);\nax1.axvline(x=514052, linestyle='--', alpha=0.3, c='green', lw=2)\nax1.axvspan(0, 514052 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nax1.set_xlim(xmin=0)\nax1.set_ylabel (\"feature_1\", fontsize=14);\n\nax2.plot((pd.Series(df_train['feature_3']).cumsum()), lw=3, color='green')\nax2.set_title (\"Noisy\", fontsize=20);\nax2.axvline(x=514052, linestyle='--', alpha=0.3, c='red', lw=2)\nax2.axvspan(0, 514052 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nax2.set_xlim(xmin=0)\nax2.set_ylabel (\"feature_3\", fontsize=14);\n\nax3.plot((pd.Series(df_train['feature_55']).cumsum()), lw=3, color='darkorange')\nax3.set_title (\"Hybrid (Tag 21)\", fontsize=20);\nax3.set_xlabel (\"Trade\", fontsize=18)\nax3.axvline(x=514052, linestyle='--', alpha=0.3, c='green', lw=2)\nax3.axvspan(0, 514052 , color=sns.xkcd_rgb['grey'], alpha=0.1)\nax3.set_xlim(xmin=0)\nax3.set_ylabel (\"feature_55\", fontsize=14);\n\nax4.plot((pd.Series(df_train['feature_73']).cumsum()), lw=3, color='blue')\nax4.set_title (\"Negative\", fontsize=20)\nax4.set_xlabel (\"Trade\", fontsize=18)\nax4.set_ylabel (\"feature_73\", fontsize=14);\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features 41, 42 and 43 (tag 14) look 'stratified':"},{"metadata":{"trusted":true},"cell_type":"code","source":"day_0 = df_train.loc[df_train['date'] == 0]\nday_1 = df_train.loc[df_train['date'] == 1]\nday_3 = df_train.loc[df_train['date'] == 3]\nthree_days = pd.concat([day_0, day_1, day_3])\nthree_days.plot.scatter(x='ts_id', y='feature_41', s=0.5, figsize=(15,3));\nthree_days.plot.scatter(x='ts_id', y='feature_42', s=0.5, figsize=(15,3));\nthree_days.plot.scatter(x='ts_id', y='feature_43', s=0.5, figsize=(15,3));\n\ndel day_0\ndel day_1\ndel day_3\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Features distributions*"},{"metadata":{"trusted":true},"cell_type":"code","source":"featstr = [i for i in df_train.columns if 'feature_' in i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.gridspec as gridspec\n\nplt.rcParams['font.size'] = 14\nfig = plt.figure(figsize=(20,80))\nfig.suptitle('Features Box plot with 0.1% 99.9% whiskers',fontsize=20, y=.89)\ngrid =  gridspec.GridSpec(33,4,figure=fig,hspace=.5,wspace=.05)\ncounter = 0\nfor i in range(33):\n    for j in range(4):\n        if counter < 130:\n            subf = fig.add_subplot(grid[i, j]);\n            sns.boxplot(x= df_train[featstr[counter]],saturation=.5,color= 'blue', ax= subf,width=.5,whis=(.1,99.9));\n            subf.axvline(df_train[featstr[counter]].mean(),color= 'darkorange', label='Mean', linestyle=':',linewidth=3)\n            subf.set_xlabel('')\n            subf.set_title('{}'.format(featstr[counter]),fontsize=16)\n            counter += 1\n            gc.collect()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Features growth*"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['font.size'] = 14\nfeatstr = [i for i in df_train.columns if 'feature_' in i]\ndf_train.groupby('date')[featstr].mean().cumsum().plot(layout=(33,4),subplots=True,figsize=(20,82),xlabel='')\nfig = plt.gcf()\nfig.text(0.5, 0.19, 'Date', ha='center', fontsize=12)\nfig.suptitle('Cumulative features means per day', fontsize=20, y=.886);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Correlation matrix*"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncorr = df_train.sample(100000).loc[:, [c for c in df_train.columns if 'feature_' in str(c)]] \\\n                 .rank().corr(method='pearson')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 16))\n\nsns.heatmap(corr,\n            cmap='RdBu_r', vmin=-1, vmax=1, square=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"del corr\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**t-SNE**"},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"%%time \n\nall_features    = [i for i in range(0,130)]\ntrain_features  = [x+7 for x in all_features]\n\ntsne    = manifold.TSNE(n_components=2, perplexity=50, learning_rate=20)\ntsne_2D = tsne.fit_transform(df_train.iloc[:, train_features].fillna(0).sample(10000)) # increase the sample size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = pd.DataFrame(tsne_2D).values.T\nfig, ax = plt.subplots(figsize=(15, 15))\nax.scatter(x, y, s=3, c=x, cmap=plt.cm.plasma)\nax.set_title('t-SNE plot for all 130 features', fontsize=18)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"del tsne\ndel tsne_2D\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5. Action**"},{"metadata":{},"cell_type":"markdown","source":"The target of the competition is represented by the 'action' binary variable:\n* 1 if the trade is taken\n* 0 if the trade is not performed\n\nFrom the objective function it is easily observed that for a positive return ('resp' > 0), then the action should be 1, else action is 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['action'] = np.where(df_train['resp'] > 0,1,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Discarding \"weight = 0\" trades*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train[df_train.weight > 0.0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_action_sum   = df_train['action'].groupby(df_train['date']).sum()\ndaily_action_count = df_train['action'].groupby(df_train['date']).count()\ndaily_ratio        = daily_action_sum / daily_action_count\n\nfig, ax = plt.subplots(figsize=(15, 5))\nplt.plot(daily_ratio)\nax.set_xlabel (\"Day\", fontsize=18)\nax.set_ylabel (\"ratio\", fontsize=18)\nax.set_title (\"Daily ratio of action to inaction\", fontsize=18)\nplt.axhline(0.5, linestyle='--', alpha=0.85, c='r');\nax.set_xlim(xmin=0)\nax.set_xlim(xmax=500)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_ratio_mean = daily_ratio.mean()\nprint('The mean daily ratio is %.3f' % daily_ratio_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_ratio_max = daily_ratio.max()\nprint('The maximum daily ratio is %.3f' % daily_ratio_max)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"del daily_action_sum\ndel daily_action_count\ndel daily_ratio\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_values_on_bars(axs):\n    def _show_on_single_plot(ax):\n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() / 2\n            _y = p.get_y() + p.get_height() + 2000\n            value = '{:.0f}'.format(p.get_height())\n            ax.text(_x, _y, value, ha=\"center\", fontsize=12, color='black', fontweight='bold') \n        \n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() / 2\n            _y = p.get_y() + p.get_height() / 2\n            value = '{:.1f}%'.format(100 * p.get_height()/len(df_train[['action']].dropna()))\n            ax.text(_x, _y, value, ha=\"center\", fontsize=12, color='white', fontweight='bold') \n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['axes.titlesize'] = 20\nplt.rcParams['font.size'] = 20\nax = df_train['action'].value_counts().sort_index().plot(kind='bar', \n                                            title= \"Data imbalance - action\")\nplt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\nax.set_xticklabels(ax.get_xticklabels(), rotation=0, horizontalalignment='center')\nshow_values_on_bars(ax)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data adjustments**"},{"metadata":{},"cell_type":"markdown","source":"Since the majority of feature values are heavily centerd around the mean, the null values are filled using the mean."},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"df_train.fillna(df_train.mean(axis=0), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.action = df_train.action.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.gridspec as gridspec\n\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['font.size'] = 16\nfig = plt.figure(figsize=(20,80))\n\nfig.suptitle('KDE plot of Features', fontsize=24, transform=fig.transFigure, y=.89)\ngrid = gridspec.GridSpec(33,4,figure=fig,hspace=.5,wspace=.01)\nprops = dict(boxstyle='round', facecolor='white', alpha=0.5)\ncounter = 0\n\nfeatstr = [i for i in df_train.columns if 'feature_' in i]\n\nfor i in range(33):\n    for j in range(4):\n        if counter < 130:\n            subf = fig.add_subplot(grid[i, j]);\n            sns.distplot(df_train[df_train.action==0][featstr[counter]],bins= 100,label='Negative',\n                         color='darkorange', kde_kws={'linewidth':4},ax=subf)\n            sns.distplot(df_train[df_train.action!=0][featstr[counter]],bins= 100,label='Positive',\n                         color='blue', kde_kws={'alpha':.9,'linewidth':2},hist_kws={'alpha':.3},ax=subf)\n            subf.axvline(np.percentile(df_train[featstr[counter]],99.5),\n                         color= 'darkblue', label='99.5%', linestyle=':',linewidth=2)\n            subf.axvline(np.percentile(df_train[featstr[counter]],.5),\n                         color= 'red', label='0.5%', linestyle=':',linewidth=2)\n            subf.legend().set_visible(False)\n            subf.set_xlabel('')\n            subf.set_title('{}'.format(featstr[counter]),fontsize=16)\n            try:\n                kurt=round(df_train[featstr[counter]].kurt(),2)\n                skew=round(df_train[featstr[counter]].skew(),2)\n                subf.text(.6,.92,'Kurt = {:.2f}\\nSkew = {:.2f}'.format(kurt ,skew),\n                      transform=subf.transAxes, verticalalignment='top', bbox=props, fontsize=10)\n            except:\n                pass\n            counter += 1\n\ngc.collect()\nhandles, labels = subf.get_legend_handles_labels()\nfig.legend(handles, labels,ncol=4, bbox_to_anchor=(0.86, 0.893),fontsize=10,\n           title= 'Resp',title_fontsize=14,bbox_transform=fig.transFigure);\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**'Resp'-features correlation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"respcorr =  pd.DataFrame([df_train.resp.corr(df_train[i]) for i in featstr], index=featstr).reset_index()\nrespcorr.columns = ['feature', 'coeff']\n\nfig, ax = plt.subplots()\nsns.barplot(data=respcorr, x='feature', y='coeff', ax=ax)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\nfor i, label in zip(range(130), ax.get_xticklabels()[:]):\n    if i % 5 != 0:\n        label.set_visible(False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"del respcorr\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# II. Model Development"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.set_index(['ts_id', 'date'], inplace=True)\n# df_example_test.set_index(['ts_id', 'date'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_resp = np.mean(df_train['resp'])\nstd_resp = np.std(df_train['resp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'action'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_list = ['weight'] + [feat for feat in df_train.columns if 'feature_' in str(feat)]\n# features_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fillna_dict = df_train.mean(axis=0).to_dict()\n# df_example_test.fillna(value = fillna_dict, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train-validation-test split"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# assign the indices of the full dataset to do multiple subsets later\nsplit_buckets = pd.Series(pd.qcut(x=df_train[target], q=100, duplicates='drop'), index=df_train.index.values)\nprint('The number of distinct target buckets:', split_buckets.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# X_train, X_devtest, y_train, y_devtest = train_test_split(df_train[features_list],\n#                                                           df_train[target],\n#                                                           train_size=0.70, \n#                                                           random_state=27, \n#                                                           stratify=split_buckets)\n# X_val, X_test, y_val, y_test = train_test_split(X_devtest, \n#                                                 y_devtest, \n#                                                 train_size=0.5,\n#                                                 stratify=split_buckets.loc[X_devtest.index], \n#                                                 random_state=27)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrainval_limit = 300\nvaltest_limit = 400\n\nX_train = df_train[df_train.index.get_level_values(1) <= trainval_limit][features_list]\ny_train = df_train[df_train.index.get_level_values(1) <= trainval_limit][target]\n\nX_val = df_train[(df_train.index.get_level_values(1) > trainval_limit) & (df_train.index.get_level_values(1) <= valtest_limit)][features_list]\ny_val = df_train[(df_train.index.get_level_values(1) > trainval_limit) & (df_train.index.get_level_values(1) <= valtest_limit)][target]\n\nX_test = df_train[df_train.index.get_level_values(1) > valtest_limit][features_list]\ny_test = df_train[df_train.index.get_level_values(1) > valtest_limit][target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"print('Train shape:')\nprint(X_train.shape)\nprint(y_train.value_counts())\nprint('Validation shape:')\nprint(X_val.shape)\nprint(y_val.value_counts())\nprint('Test shape:')\nprint(X_test.shape)\nprint(y_test.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reduce the samples size for running faster\nX_train, _, y_train, _ = train_test_split(X_train,\n                                          y_train,\n                                          train_size = 0.5,\n                                          test_size = 0.5,\n                                          stratify = y_train,\n                                          random_state = 27)\nX_val, _, y_val, _ = train_test_split(X_val,\n                                          y_val,\n                                          train_size = 0.5,\n                                          test_size = 0.5,\n                                          stratify = y_val,\n                                          random_state = 27)\nX_test, _, y_test, _ = train_test_split(X_test,\n                                          y_test,\n                                          train_size = 0.5,\n                                          test_size = 0.5,\n                                          stratify = y_test,\n                                          random_state = 27)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train shape:')\nprint(X_train.shape)\nprint(y_train.value_counts())\nprint('Validation shape:')\nprint(X_val.shape)\nprint(y_val.value_counts())\nprint('Test shape:')\nprint(X_test.shape)\nprint(y_test.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Benchmark model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom sklearn.linear_model import LogisticRegression\n\nbaseline_model = LogisticRegression(penalty='none', solver='sag')\nbaseline_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def utility_function(X, model):\n    data = X.copy()\n    data = data.reset_index().set_index('ts_id')\n\n    data['action'] = np.round(model.predict_proba(X)[:, 1])\n    \n    data = data.reset_index().merge(df_train.reset_index()[['ts_id','resp']], how='left', on='ts_id').set_index('ts_id')\n    if 'weight' not in list(data.columns):\n        data = data.reset_index().merge(df_train.reset_index()[['ts_id','weight']], how='left', on='ts_id').set_index('ts_id')\n\n    data['prod'] = data['weight'] * data['resp'] * data['action']\n    data_agg = data.groupby('date')['prod'].sum()\n\n    t = data_agg.sum() / np.sqrt(np.power(data_agg, 2).sum()) * np.sqrt(250 / len(data_agg))\n\n    u = min(max(t, 0), 6) * data_agg.sum()\n    \n    return u ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix, log_loss, precision_recall_curve\n\nprint(\"Train: \")\nbenchmark_proba = baseline_model.predict_proba(X_train)[:, 1]\nprint(\"   ROC-AUC score: \" + str(roc_auc_score(y_train, benchmark_proba)))\nprint(\"   Utility function: \" + str(utility_function(X_train, baseline_model)))\n\nprint(\"Validation: \")\nbenchmark_proba = baseline_model.predict_proba(X_val)[:, 1]\nprint(\"   ROC-AUC score: \" + str(roc_auc_score(y_val, benchmark_proba)))\nprint(\"   Utility function: \" + str(utility_function(X_val, baseline_model)))\n\nprint(\"Test: \")\nbenchmark_proba = baseline_model.predict_proba(X_test)[:, 1]\nprint(\"   ROC-AUC score: \" + str(roc_auc_score(y_test, benchmark_proba)))\nprint(\"   Utility function: \" + str(utility_function(X_test, baseline_model)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CatBoost Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_default_device = 'cpu' # must be lowercase\ncatboost_default_device = 'CPU' # must be uppercase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_hyperopt = X_train.copy()\ny_train_hyperopt = y_train.copy()\nX_test_hyperopt = X_val.copy()\ny_test_hyperopt = y_val.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categ_vars = ['feature_0']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are now ready to make the optimization step.\nHyperopt is a Python library for hyperparameter optimization (http://hyperopt.github.io/hyperopt/). In this way we can let an algorithm detect the best model and the best hyperparameter values for the task.\nAbove, we subseted the base for this task. \nThe steps required are:\n\n1. Define an objective function. That is, at each step, we compute the loss of each model. This loss is left for us to define; we can define it in terms of precision, recall, AUC or a combination of these. The algorithm will try to minimize the loss.\n2. Define the search space. We need to define the arrays of models and hyperparameters. We are also required to specify the a priori distribution of each hyperparameter\n3. Choose an optimization algorithm and perform the run.\n\nThe algorithm we choose is TPE (Tree Parzen of Estimators), a Bayesian optimization algorithm; for more details see https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&ved=2ahUKEwiq097G1cbnAhWSXsAKHTbpCI0QFjADegQIARAB&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4443-algorithms-for-hyper-parameter-optimization.pdf&usg=AOvVaw2WRbRoJUBJ8FU1S3vKmmGM"},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(params):\n    print(\"Fitting \" + str(params['model']))\n    model = params['model'](**params['param'])\n\n    if params['model'] == CatBoostClassifier:\n        print(str(params['param']['iterations']) + ' boosting iterations')\n        model.fit(X_train_hyperopt, y_train_hyperopt, cat_features = categ_vars)\n    elif params['model'] == lgb.LGBMClassifier:\n        print(str(params['param']['n_estimators']) + ' boosting iterations')\n        print('Boosting type ' + str(params['param']['boosting_type']))\n        model.fit(X_train_hyperopt, y_train_hyperopt, categorical_feature = categ_vars)\n    elif params['model'] == RandomForestClassifier:\n        print(str(params['param']['n_estimators']) + ' trees')\n        model.fit(X_train_hyperopt, y_train_hyperopt)\n    else:\n        model.fit(X_train_hyperopt, y_train_hyperopt)\n\n    loss = 0 - utility_function(X_test_hyperopt, model)\n    hyperparameter_set[loss] = params\n\n    print('Loss = ' + str(loss) + '\\n')\n    loss_list.append(loss)\n\n    return {'loss': loss, 'params': params, 'status': STATUS_OK}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will define a function that creates a back-up for the hyperopt trials after a set number of Bayesian search iterations. This is helpful for situations when the kernel crashes, or when more iterations are required at a later point in time. Given the at least partially deterministic nature of the Bayesian search process, this back-up will essentially act as a warm start."},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_trials(pickling_freq, initial_max_trials, filename):\n    # pickling_freq -> how many additional trials to do after loading saved trials. 1 = save after each iteration\n    # initial_max_trials -> how many iterations should be run in the beginning before the first pickle save\n    max_trials = initial_max_trials\n    warnings.warn(\"UserWarning\", UserWarning) #disable UserWarnings while running hyperopt in the run_trials() function\n  \n\n    ############################## This is where you can change the optimization space ##############################\n        \n    dictionar_lgbm = {'model':lgb.LGBMClassifier, \n                      'param': {\n                            'class_weight': {0:1, 1:hp.uniform('class_weight_1', 2, 50)},\n                            'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0, 1.0),\n                            'max_bin': hp.choice('max_bin', np.arange(50, 750, 25, dtype=int)),\n                            'num_leaves': hp.choice('num_leaves', np.arange(4, 256, dtype=int)),\n                            'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n                            'subsample_for_bin': hp.choice('subsample_for_bin', np.arange(1000, X_train_hyperopt.shape[0], dtype=int)),\n                            'min_child_samples': hp.choice('min_child_samples', np.arange(20, 500,5, dtype=int)),\n                            'is_unbalance': hp.choice('is_unbalance', np.array([True, False], dtype = bool)), \n                            'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n                            'feature_fraction': hp.uniform('feature_fraction', 1/X_train_hyperopt.shape[1], 1.0),        \n                            'max_depth': hp.choice('max_depth', np.arange(2, 21,1, dtype=int)),    \n                            'lambda_l1': hp.uniform('lambda_l1', 0.0, 10.0),\n                            'lambda_l2': hp.uniform('lambda_l2', 0.0, 10.0),\n                            'bagging_fraction': hp.uniform('bagging_fraction',1/X_train_hyperopt.shape[0]*10,1.0),\n                            'bagging_freq': hp.choice('bagging_freq', np.arange(1, 11,1, dtype=int)),\n                            'objective' : 'binary',\n                            # 'boost_from_average': False ,\n                            'boost_from_average': hp.choice('boost_from_average', np.array([True, False], dtype=bool)),\n                            'boosting_type': hp.choice('boosting_type', np.array(['gbdt','dart'], dtype = str)),\n                            'n_estimators' : hp.choice('n_estimators', np.arange(50, 5000, 25, dtype=int)),\n                            'device_type': lgb_default_device,\n                        }}\n    \n    dictionar_catboost = {'model':CatBoostClassifier, \n                          'param':{\n                                'iterations': hp.choice('iterations', np.arange(50, 3000, 25, dtype=int)),\n                                'depth': hp.choice('depth', np.arange(2, 11, 1, dtype=int)),\n                                'learning_rate': hp.loguniform('learning_rate_2', np.log(0.001), np.log(0.2)),\n                                'class_weights': [1, hp.uniform('class_weight_3',0.1,4)],\n                                'border_count': hp.choice('border_count', np.arange(1, 255, 1, dtype=int)),\n                                'l2_leaf_reg': hp.uniform('l2_leaf_reg',0,100),\n                                'logging_level': 'Silent',\n                                'task_type': catboost_default_device\n                            }} \n    \n\n    dictionar_sgd = {'model':SGDClassifier, \n                     'param':{\n                                 'loss': hp.choice('loss_5', np.array(['hinge', 'modified_huber', 'squared_hinge', 'perceptron'], dtype = str)),\n                                 'penalty': hp.choice('penalty_5', np.array(['l1', 'l2', 'none', 'elasticnet'], dtype = str)),\n                                 # 'alpha': hp.uniform('alpha', 0, 0.001),\n                                 'l1_ratio': hp.uniform('l1_ratio_5', 0, 1),\n                                 'max_iter': hp.choice('max_iter_7', np.arange(5, 100, 5, dtype=int)),\n                                 'learning_rate': hp.choice('learning_rate_7', np.array(['constant', 'optimal', 'invscaling', 'adaptive'], dtype = str)),\n                                 'eta0': hp.uniform('eta0', 0, 0.1),\n                                 'power_t': hp.uniform('power_t', 0, 1),\n                                 'class_weight': {0:1, 1:hp.uniform('class_weight_8', 2, 50)},\n                                 'n_jobs': -1\n                    }} \n    \n    #############################################################################################################################\n        \n        ######### Comment out the models which you do not want to use #########\n    \n    tested_models =[]\n    # tested_models.append(dictionar_lgbm)\n    tested_models.append(dictionar_catboost)\n    # tested_models.append(dictionar_sgd)\n    \n    space = hp.choice('classifier', tested_models)\n    \n        \n        \n        ############################## Checking if there are any existing Trials to reload ##############################\n    try: \n        # try to load an already saved trials object, and increase the max\n        trials = pickle.load(open(filename, \"rb\"))\n        # print(\"Found saved Trials! Loading...\")\n        max_trials = len(trials.trials) + pickling_freq\n        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, pickling_freq))\n    except:\n        # if no existing object was found, create a new one\n        trials = Trials()\n        #################################################################################################################\n        \n        \n        \n        ###################################### Hyperopt optimization ######################################\n    space = hp.choice('classifier', tested_models)\n    fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = max_trials, trials = trials)\n    best = hyperparameter_set[sorted(hyperparameter_set)[0]]\n    print(\"Best model so far:\", best, \"\\n\")\n        ###################################################################################################\n        \n        \n        \n        ######### Saving the Trials object once optimization is finished #########\n    with open(filename, \"wb\") as f:\n        pickle.dump(trials, f)\n    print(\"Saved Trials! \\n\")  \n        #########################################################################","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Start the optimization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhyperparameter_set = {}\nloss_list = []\ni = 0  \nsave_frequency = 5   # How often do you want your trials to be backed-up?\ninitial_trials = 1    # How many Hyperopt iterations do you want to run before the first back up, if none exists?\nhyperopt_iters = 320   # How many optimization iterations do you want to run (on top of the backe-up ones, if they exist)? Will be a multiple of save_frequency\nsave_path = \"/kaggle/working/my_optimization_prod_\" + experiment_name + \".hyperopt\"\n\n# while i <= hyperopt_iters/save_frequency:\n#     i += 1\n#     with warnings.catch_warnings():\n#         warnings.simplefilter(\"ignore\")  # Do not show any UserWarnings, see def run_trials; they can become annoying if you run many iterations :)\n#         run_trials(pickling_freq = save_frequency, initial_max_trials = initial_trials, filename = save_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load the best model with the best hyparameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# trials = pickle.load(open(save_path, 'rb'))\n# loss = trials.best_trial['result']['loss']\n# save_path = \"/kaggle/working/my_optimization_prod_\" + experiment_name + \".hyperopt\"\n\nmodel = CatBoostClassifier(border_count=145, \n                           class_weights=(1, 0.8763763487405303),\n                           depth=5,\n                           iterations=2325,\n                           l2_leaf_reg=19.8650097679303,\n                           learning_rate=0.020187221403617027,\n                           logging_level='Silent',\n                           task_type=catboost_default_device)\n\nbest_loss = -956.9680483209429\n\ndisplay(model.get_params())\ndisplay(best_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# for i in range(len(trials.trials)):    \n#     if trials.trials[i]['result']['loss'] == loss:\n#         print(\"Loss: \" + str(trials.trials[i]['result']['loss']))\n#         # print(trials.trials[i]['result']['params'])\n#         itera = i\n#         print(itera)\n# best = trials.trials[itera]['result']['params']\n# best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# test = hyperparameter_set[sorted(hyperparameter_set)[0]]\n# test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# # Plotting the losses of each hyperopt iteration\n# plt.figure(figsize=(15, 5))\n# plt.plot(trials.losses())\n# plt.title(\"Hyperopt loss evolution\")\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fitting the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# model = best['model'](**best['param'])\n\nif isinstance(model, CatBoostClassifier):\n    model.fit(X_train_hyperopt, \n              y_train_hyperopt, \n              # eval_set = (X_test_hyperopt, np.ravel(y_test_hyperopt)), \n              # early_stopping_rounds=60,\n              cat_features = categ_vars) \n    \nelif isinstance(model, lgb.LGBMClassifier):\n    model.fit(X_train_hyperopt, \n              np.ravel(y_train_hyperopt), \n              eval_set = (X_test_hyperopt, np.ravel(y_test_hyperopt)), \n              # early_stopping_rounds=60,\n              categorical_feature = categ_vars)\n\nelse:\n    model.fit(X_train_hyperopt, \n              np.ravel(y_train_hyperopt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check\nutility_function(X_test_hyperopt, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_compute_metrics(X, y, model):\n    \n    predictions = model.predict_proba(X)[:, 1]\n    predictions_l = model.predict(X)\n\n    print(\"ROC-AUC score: \" + str(np.round(roc_auc_score(y, predictions), decimals=4)))\n    print(\"Precision score: \" + str(np.round(precision_score(y, predictions_l), decimals=4)))\n    print(\"Utility function: \" + str(np.round(utility_function(X, model), decimals=4)))\n    \n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_train = predict_compute_metrics(X_train, y_train, model)\n# identical with predict_compute_metrics(X_train, y_train, model) - same data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_val = predict_compute_metrics(X_val, y_val, model)\n# identical with predict_compute_metrics(X_test_hyperopt, y_test_hyperopt, model) - same data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = predict_compute_metrics(X_test, y_test, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Confusion matrices*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def confusion_matrix_plot(X, y, model):\n    sns.set(rc={'figure.figsize': (15, 5)})\n    \n    predictions_l = model.predict(X)\n    cm = confusion_matrix(y, predictions_l)\n\n    ax1 = plt.subplot(1, 2, 1)\n    sns.heatmap(cm, annot=True, ax=ax1, fmt='.0f', cmap='Blues')\n\n    # labels, title and ticks\n    ax1.set_xlabel('Predicted labels')\n    ax1.set_ylabel('True labels')\n    ax1.set_title('Confusion Matrix')\n\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    ax2 = plt.subplot(1, 2, 2)\n    sns.heatmap(cm, annot=True, ax=ax2, fmt='.2f', cmap='Blues')\n\n    # labels, title and ticks\n    ax2.set_xlabel('Predicted labels')\n    ax2.set_ylabel('True labels')\n    ax2.set_title('Confusion Matrix %')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix_plot(X_train, y_train, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix_plot(X_val, y_val, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix_plot(X_test, y_test, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*ROC curves*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def roc_curve_plot(X, y, model):\n    sns.set(rc={'figure.figsize': (10, 5)})\n    \n    predictions = model.predict_proba(X)[:, 1]\n    fpr, tpr, thresholds = roc_curve(y, predictions)\n    \n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(15, 5))\n    # Plot ROC\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, 'b', label='AUC = %0.3f' % roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0, 1], [0, 1], 'r--')\n    plt.xlim([0, 1.0])\n    plt.ylim([0, 1.00])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_curve_plot(X_train, y_train, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_curve_plot(X_val, y_val, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_curve_plot(X_test, y_test, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Probabilities histograms*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prob_histogram(X, y, model):\n    X_1 = X.loc[y == 0]\n    X_2 = X.loc[y == 1]\n\n    Zero = model.predict_proba(X_1)[:, 1]\n    One = model.predict_proba(X_2)[:, 1]\n\n    x_locs = [i/20 for i in range(21)]\n    x_labs = [str(i/20) for i in range(21)]\n\n    y_locs = [i for i in range(20) if i%2 ==0]\n    y_labs = [str(i) +'%' for i in range(20) if i%2 ==0]\n\n    bins = np.linspace(0, 1, 20)\n\n    plt.figure(figsize=(15, 5))\n    plt.hist(Zero, bins, weights=np.zeros_like(Zero) + 100. / Zero.size, \n             alpha=0.5, label='Zero', color = 'r')\n    plt.hist(One, bins, weights=np.zeros_like(One) + 100. /One.size, \n             alpha=0.5, label='One', color = 'b')\n    plt.axvline(x=0.5, color = 'black')\n    plt.xlabel('Zero Probability')\n    plt.ylabel('Percentage in group')\n    plt.xticks(x_locs, x_labs)\n    plt.yticks(y_locs, y_labs)\n    plt.xlim(0,1)\n    plt.legend(loc='upper right')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_histogram(X_train, y_train, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_histogram(X_val, y_val, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_histogram(X_test, y_test, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Precision-recall curve*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def precision_recall_curve_plot(X, y, model):\n   \n    predictions = model.predict_proba(X)[:, 1]\n    precision, recall, thresholds = precision_recall_curve(y, predictions)\n\n    f1_scores = 2 * precision * recall / (precision + recall)\n    f1_scores = np.nan_to_num(f1_scores)\n    f1_max = np.max(f1_scores)\n    f1_max_which = np.argmax(f1_scores)\n\n    threshold_optim = thresholds[f1_max_which]\n\n    plt.figure(figsize=(10, 10))\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall Curve - Optimal probability threshold = ' +str(np.round(threshold_optim, 3)) + ', Maximal F1-score = ' + str(np.round(f1_max, 3) ))\n    plt.xticks(ticks = [0.05*i for i in range(21)], labels = [str(round(0.05*i, 2)) for i in range(21)])\n    plt.yticks(ticks = [0.05*i for i in range(21)], labels = [str(round(0.05*i, 2)) for i in range(21)])\n    sns.set_context('notebook', font_scale=1)\n    f1_scores_list_plot=np.array([i*0.05 for i in range(20)])\n    recall_array = np.array([i*0.01 for i in range(101)])\n    for f1_score in f1_scores_list_plot:\n        num = 1000\n        x = np.linspace(0.0001, 1, num=num)\n        y = f1_score * x / (2 * x - f1_score)\n        l, = plt.plot(x[(y >= 0) & (y<=1)], y[(y >= 0) & (y<=1)], alpha=0.3, color = 'grey')\n        plt.annotate('f1={0:0.2f}'.format(f1_score), xy=(0.95, y[num-10]))\n\n    plt.plot(recall, precision, color='red', alpha=0.6)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_recall_curve_plot(X_train, y_train, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_recall_curve_plot(X_val, y_val, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_recall_curve_plot(X_test, y_test, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*T-SNE*"},{"metadata":{},"cell_type":"markdown","source":"Stochasting Neighbourhood Embedding is a non-linear dimensionality reduction technique which we can use to visualiwe high-dimensional data. In this way we can visualise what the model sees in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsne_plot(X):\n    tsne    = manifold.TSNE(n_components=2, perplexity=50, learning_rate=20)\n    tsne_2D = tsne.fit_transform(X_train.sample(5000))\n    \n    x, y = pd.DataFrame(tsne_2D).values.T\n    fig, ax = plt.subplots(figsize=(7, 7))\n    ax.scatter(x, y, s=2, c=x, cmap = plt.cm.plasma)\n    ax.set_title('t-SNE plot', fontsize=18)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \ntsne_plot(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \ntsne_plot(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \ntsne_plot(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model interpretability"},{"metadata":{},"cell_type":"markdown","source":"**Permutation importance**"},{"metadata":{},"cell_type":"markdown","source":"In the Permutation Importance (model agnostic feature importance method) we determine what are the most useful features, the \"drivers\" of the target. \n\nThe procedure is as follows:\n1.  Fix a metric (e.g. AUC / F1-score)\n2.  For each predictor column, shuffle the values. Train a new model on the database with the shuffled column and record the metric delta. Sort the features in the descending  order of the delta.\n\nThe idea behind the method is that features that are important to the prediction, when shuffled, will worsen the performance of the model. The degree of worsening is proportional to the importance of the feature."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def permutation_importances_f1(X, y, model):\n    X = X.sample(100000)\n    y = y[X.index]\n    \n    y_pred = model.predict(X)\n    cm = confusion_matrix(y, y_pred)\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    baseline = (cm[0, 0] + cm[1, 1]) / 2\n    imp = []\n    \n    for col in X.columns:\n        save = X[col].copy()\n        X[col] = np.random.permutation(X[col])\n        cm_2 = confusion_matrix(y, model.predict(X))\n        cm_2 = cm_2.astype('float') / cm_2.sum(axis=1)[:, np.newaxis]\n        m = (cm_2[0, 0] + cm_2[1, 1]) / 2\n        X[col] = save\n        imp.append(baseline - m)\n        \n    return np.array(imp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"%%time\nimp_perm = permutation_importances_f1(X_train, y_train, model)\n\nimp_df = pd.DataFrame()\nimp_df[\"feature\"] = list(X_train)\nimp_df[\"permutation_importance\"] = imp_perm.copy()\nimp_df.sort_values(['permutation_importance'], ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"%%time\nimp_df_2 = imp_df.sort_values(['permutation_importance'], ascending=False)\nsns.set(rc={'figure.figsize': (20, 20)})\nsns.set_context(\"paper\", font_scale=1)    \nsns.barplot(x = 'permutation_importance',\n            y = 'feature',\n            data = imp_df_2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def permutation_importances_ut(X, y, model):\n    X = X.sample(100000)\n    y = y[X.index]\n    \n    y_pred = model.predict(X)\n    baseline = utility_function(X, model)\n    imp = []\n    \n    for col in X.columns:\n        save = X[col].copy()\n        X[col] = np.random.permutation(X[col])\n        m = utility_function(X, model)\n        X[col] = save\n        imp.append(baseline - m)\n        \n    return np.array(imp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimp_perm_ut = permutation_importances_ut(X_train, y_train, model)\n\nimp_df_ut = pd.DataFrame()\nimp_df_ut[\"feature\"] = list(X_train)\nimp_df_ut[\"permutation_importance\"] = imp_perm_ut.copy()\nimp_df_ut.sort_values(['permutation_importance'], ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimp_df_2_ut = imp_df_ut.sort_values(['permutation_importance'], ascending=False)\nsns.set(rc={'figure.figsize': (20, 20)})\nsns.set_context(\"paper\", font_scale=1)    \nsns.barplot(x = 'permutation_importance',\n            y = 'feature',\n            data = imp_df_2_ut)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ut_pos_features = imp_df_ut.loc[imp_df_ut.permutation_importance > 0, 'feature']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-fold cross-validation grouping the data chronologically**"},{"metadata":{},"cell_type":"markdown","source":"In order to perform a cross-validation on the data, one must be certain that there is no forward bias that cannot be achieved using a standard KFold split (or even a Group KFold) from sklearn for example. Moreover, even the TimeSeriesSplit can cause problems as it does not ensure a separation following the last trade of the day (we may end up with some trades as part of train data and the rest part of the test data, all occurring on the same date).\n\nTherefore, the following implementation of the GroupTimeSeriesSplit forces the chronologically selection of data, while splitting trades exactly at the end of the day. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\nclass GroupTimeSeriesSplit(_BaseKFold):\n    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n    Provides train/test indices to split time series data samples\n    that are observed at fixed time intervals according to a\n    third-party provided group.\n    In each split, test indices must be higher than before, and thus shuffling\n    in cross validator is inappropriate.\n    This cross-validation object is a variation of :class:`KFold`.\n    In the kth split, it returns first k folds as train set and the\n    (k+1)th fold as test set.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    Note that unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n    max_train_size : int, default=None\n        Maximum size for a single training set.\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.model_selection import GroupTimeSeriesSplit\n    >>> groups = np.array(['a', 'a', 'a', 'a', 'a', 'a',\\\n                           'b', 'b', 'b', 'b', 'b',\\\n                           'c', 'c', 'c', 'c',\\\n                           'd', 'd', 'd'])\n    >>> gtss = GroupTimeSeriesSplit(n_splits=3)\n    >>> for train_idx, test_idx in gtss.split(groups, groups=groups):\n    ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n    ...     print(\"TRAIN GROUP:\", groups[train_idx],\\\n                  \"TEST GROUP:\", groups[test_idx])\n    TRAIN: [0, 1, 2, 3, 4, 5] TEST: [6, 7, 8, 9, 10]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a']\\\n    TEST GROUP: ['b' 'b' 'b' 'b' 'b']\n    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] TEST: [11, 12, 13, 14]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b']\\\n    TEST GROUP: ['c' 'c' 'c' 'c']\n    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\\\n    TEST: [15, 16, 17]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b' 'c' 'c' 'c' 'c']\\\n    TEST GROUP: ['d' 'd' 'd']\n    \"\"\"\n    @_deprecate_positional_args\n    def __init__(self,\n                 n_splits=5,\n                 *,\n                 max_train_size=None\n                 ):\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.max_train_size = max_train_size\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n        X, y, groups = indexable(X, y, groups)\n        n_samples = _num_samples(X)\n        n_splits = self.n_splits\n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n        group_test_size = n_groups // n_folds\n        group_test_starts = range(n_groups - n_splits * group_test_size,\n                                  n_groups, group_test_size)\n        for group_test_start in group_test_starts:\n            train_array = []\n            test_array = []\n            for train_group_idx in unique_groups[:group_test_start]:\n                train_array_tmp = group_dict[train_group_idx]\n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n            train_end = train_array.size\n            if self.max_train_size and self.max_train_size < train_end:\n                train_array = train_array[train_end -\n                                          self.max_train_size:train_end]\n            for test_group_idx in unique_groups[group_test_start:\n                                                group_test_start +\n                                                group_test_size]:\n                test_array_tmp = group_dict[test_group_idx]\n                test_array = np.sort(np.unique(\n                                              np.concatenate((test_array,\n                                                              test_array_tmp)),\n                                     axis=None), axis=None)\n            yield [int(i) for i in train_array], [int(i) for i in test_array]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classification_kfold(X, y, model):\n    X_ttv = X.reset_index()[['ts_id','date']]\n    X_ttv = X_ttv.sort_values(by=['date','ts_id'])\n    \n    if 'feature_0' in list(X.columns):\n        categ_vars = ['feature_0']\n    else:\n        categ_vars = []\n    \n    i = 1\n    for train_index, valid_index in GroupTimeSeriesSplit().split(X_ttv, groups=X_ttv['date']):\n        print('Fold {}'.format(i))\n        train_index_list = X_ttv.loc[train_index, 'date'].unique()\n        valid_index_list = X_ttv.loc[valid_index, 'date'].unique()\n        print(\"      [Train dates: \" + str(np.min(train_index_list)) + \" ---- \" + str(np.max(train_index_list)) + \"]\")\n        print(\"      [Validation dates: \" + str(np.min(valid_index_list)) + \" ---- \" + str(np.max(valid_index_list)) + \"]\")\n\n        train_cv = X[X.index.get_level_values(1).isin(train_index_list)]\n        y_train_cv = y[X.index.get_level_values(1).isin(train_index_list)]\n        valid_cv = X[X.index.get_level_values(1).isin(list(valid_index_list))]\n        y_valid_cv = y[X.index.get_level_values(1).isin(list(valid_index_list))]\n\n        model.fit(train_cv, \n                  y_train_cv, \n                  # eval_set = (valid_cv, np.ravel(y_valid_cv)), \n                  # early_stopping_rounds=60,\n                  cat_features = categ_vars) \n\n        print(\"   Train: \")\n        pred_trainval = predict_compute_metrics(train_cv, y_train_cv, model)\n        print(\"   Validation: \")\n        pred_test = predict_compute_metrics(valid_cv, y_valid_cv, model)\n        print('')\n\n        i += 1\n        \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel_k = classification_kfold(X_train, y_train, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train: \")\npred_train = predict_compute_metrics(X_train, y_train, model_k)\nprint(\"Validation: \")\npred_val = predict_compute_metrics(X_val, y_val, model_k)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test, y_test, model_k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nif 'feature_0' in list(X_train.loc[:,ut_pos_features].columns):\n    categ_vars = ['feature_0']\nelse:\n    categ_vars = []\n\n# model_pos = best['model'](**best['param'])\nmodel_pos = CatBoostClassifier(border_count=145, \n                           class_weights=(1, 0.8763763487405303),\n                           depth=5,\n                           iterations=2325,\n                           l2_leaf_reg=19.8650097679303,\n                           learning_rate=0.020187221403617027,\n                           logging_level='Silent',\n                           task_type=catboost_default_device)\n\n\nmodel_pos.fit(X_train.loc[:,ut_pos_features], \n              y_train, \n              # eval_set = (X_val, np.ravel(y_val)), \n              # early_stopping_rounds=60,\n              cat_features = categ_vars) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train: \")\npred_train = predict_compute_metrics(X_train.loc[:,ut_pos_features], y_train, model_pos)\nprint(\"Validation: \")\npred_val = predict_compute_metrics(X_val.loc[:,ut_pos_features], y_val, model_pos)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test.loc[:,ut_pos_features], y_test, model_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel_k_pos = classification_kfold(X_train.loc[:,ut_pos_features], y_train, model_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train: \")\npred_train = predict_compute_metrics(X_train.loc[:,ut_pos_features], y_train, model_k_pos)\nprint(\"Validation: \")\npred_val = predict_compute_metrics(X_val.loc[:,ut_pos_features], y_val, model_k_pos)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test.loc[:,ut_pos_features], y_test, model_k_pos)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far, the best model (considering the utility function) seems the initial one fitted on the 'train' data."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# model = best['model'](**best['param'])\n\nmodel = CatBoostClassifier(border_count=145, \n                           class_weights=(1, 0.8763763487405303),\n                           depth=5,\n                           iterations=2325,\n                           l2_leaf_reg=19.8650097679303,\n                           learning_rate=0.020187221403617027,\n                           logging_level='Silent',\n                           task_type=catboost_default_device)\n\nif 'feature_0' in list(X_train.columns):\n    categ_vars = ['feature_0']\nelse:\n    categ_vars = []\n\nif isinstance(model, CatBoostClassifier):\n    model.fit(X_train, \n              y_train, \n              # eval_set = (X_test_hyperopt, np.ravel(y_test_hyperopt)), \n              # early_stopping_rounds=60,\n              cat_features = categ_vars) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Partial dependence plots**"},{"metadata":{},"cell_type":"markdown","source":"After we determined which features are important, we also want to assess how these features influence the outcome. This can be realized using Partial Dependency Plots (PDPs for short).\nIn a PDP, each curve represents a model point, the x-axis denote the feature and the y-axis the Delta in Probability."},{"metadata":{"trusted":true},"cell_type":"code","source":"from pdpbox import pdp\n\nfeatures_for_pdp = list(imp_df_2_ut.sort_values(['permutation_importance'], ascending=False).iloc[:10,0])\nfeatures_for_pdp = [x for x in list(features_for_pdp)]\nfeatures_for_pdp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\n\nsns.set_context(\"paper\", font_scale=1)    \n\ntemp = X_val.iloc[:2000, :]\n\n# def plot_pdp(feat, df, clusters=None, feat_name=None, dummy=False):\n#     feat_name = feat_name or feat\n#     if(dummy == True):\n#         p = pdp.pdp_isolate(model, df, df.columns, feat, percentile_range=(0, 100), grid_type='equal', \n#                             cust_grid_points=df[feat].unique(), n_jobs=-1)\n#         return pdp.pdp_plot(p,\n#                         feat_name,\n#                         plot_lines=True,\n#                         cluster = clusters is not None,\n#                         n_cluster_centers=clusters,\n#                         # plot_pts_dist=True,\n#                         # x_quantile=True,\n#                         show_percentile=True,\n#                            plot_params = {'fontsize':10})\n#     else:    \n#         p = pdp.pdp_isolate(model, df, df.columns, feat, percentile_range=(0, 100),  n_jobs=-1)\n#         return pdp.pdp_plot(p,\n#                         feat_name,\n#                         plot_lines=True,\n#                         cluster=clusters is not None,\n#                         n_cluster_centers=clusters,\n#                         plot_pts_dist=True,\n#                         x_quantile=True,\n#                         show_percentile=True,\n#                         plot_params = {'fontsize':10})\n\n# for i in features_for_pdp:\n#     print('feature: ' + i)\n#     dummy=False\n#     if temp[i].nunique()<=2:\n#         dummy=True\n            \n#     plot_pdp(i, df=temp, dummy=dummy)\n#     plt.tight_layout()\n#     plt.show()\n\n\ndef partial_dependence_plots(df, feats, model):\n    for f in pdp_features:\n        if df[f].nunique() <= 25: \n            pdp_response = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns, feature=f, grid_type='equal',\n                                           cust_grid_points=np.sort(df[f].unique()))\n        else:\n            pdp_response = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns, feature=f, grid_type='equal',\n                                           cust_grid_points=np.arange(df[f].min(), df[f].max(), (df[f].max()-df[f].min())/25))\n    \n        pdp.pdp_plot(pdp_response, f, figsize=(10, 7))\n        plt.show()\n        \npdp_features = features_for_pdp\npartial_dependence_plots(temp, pdp_features, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shap values**"},{"metadata":{},"cell_type":"markdown","source":"This is another interpretation technique inspired by cooperative game theory."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef shap_plot(X, y, model):\n    X = X.sample(5000)\n    y = y[X.index]\n    \n    no_of_features = 20\n    \n    pool1 = Pool(data=X, label=y, cat_features=categ_vars)\n    shap_values = model.get_feature_importance(pool1, type='ShapValues')\n    cols_for_shap = list(X.columns)\n    index_for_shap = [X[cols_for_shap].columns.get_loc(c) for c in cols_for_shap]\n\n    plt.figure(figsize=(20, 5))\n\n    shap.summary_plot(shap_values[:, index_for_shap],\n                      X[cols_for_shap],\n                      max_display = no_of_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nshap_plot(X_train, y_train, model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model fitting on train & validation, then evaluated on test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainval = df_train[df_train.index.get_level_values(1) <= valtest_limit][features_list]\ny_trainval = df_train[df_train.index.get_level_values(1) <= valtest_limit][target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# Free memory\n\ndel X_train\ndel y_train\ndel X_val\ndel y_val\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# model_tv = best['model'](**best['param'])\nmodel_tv = CatBoostClassifier(border_count=145, \n                           class_weights=(1, 0.8763763487405303),\n                           depth=5,\n                           iterations=2325,\n                           l2_leaf_reg=19.8650097679303,\n                           learning_rate=0.020187221403617027,\n                           logging_level='Silent',\n                           task_type=catboost_default_device)\n\nif isinstance(model_tv, CatBoostClassifier):\n    model_tv.fit(X_trainval, \n              y_trainval, \n              # eval_set = (X_test, np.ravel(y_test)), \n              # early_stopping_rounds=60,\n              cat_features = categ_vars) \n    \nelif isinstance(model_tv, lgb.LGBMClassifier):\n    model_tv.fit(X_trainval, \n              np.ravel(y_trainval), \n              eval_set = (X_test, np.ravel(y_test)), \n              # early_stopping_rounds=60,\n              categorical_feature = categ_vars)\n\nelse:\n    model_tv.fit(X_trainval, \n              np.ravel(y_train_hyperopt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train & val: \")\npred_trainval = predict_compute_metrics(X_trainval, y_trainval, model_tv)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test, y_test, model_tv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train & val: \")\nconfusion_matrix_plot(X_trainval, y_trainval, model_tv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test: \")\nconfusion_matrix_plot(X_test, y_test, model_tv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train & val: \")\nroc_curve_plot(X_trainval, y_trainval, model_tv)\nprint(\"Test: \")\nroc_curve_plot(X_test, y_test, model_tv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train & val: \")\nprob_histogram(X_trainval, y_trainval, model_tv)\nprint(\"Test: \")\nprob_histogram(X_test, y_test, model_tv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train & val: \")\nprecision_recall_curve_plot(X_trainval, y_trainval, model_tv)\nprint(\"Test: \")\nprecision_recall_curve_plot(X_test, y_test, model_tv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*K-fold cross-validation grouping the data chronologically*"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def utility_function(X, model):\n    data = X.copy()\n    data = data.reset_index().set_index('ts_id')\n\n    data['action'] = np.round(model.predict_proba(X)[:, 1])\n    \n    data = data.reset_index().merge(df_train.reset_index()[['ts_id','resp']], how='left', on='ts_id').set_index('ts_id')\n    if 'weight' not in list(data.columns):\n        data = data.reset_index().merge(df_train.reset_index()[['ts_id','weight']], how='left', on='ts_id').set_index('ts_id')\n\n    data['prod'] = data['weight'] * data['resp'] * data['action']\n    data_agg = data.groupby('date')['prod'].sum()\n\n    t = data_agg.sum() / np.sqrt(np.power(data_agg, 2).sum()) * np.sqrt(250 / len(data_agg))\n\n    u = min(max(t, 0), 6) * data_agg.sum()\n    \n    return u \n\n\ndef predict_compute_metrics(X, y, model):\n    \n    predictions = model.predict_proba(X)[:, 1]\n    predictions_l = model.predict(X)\n\n    print(\"ROC-AUC score: \" + str(np.round(roc_auc_score(y, predictions), decimals=4)))\n    print(\"Precision score: \" + str(np.round(precision_score(y, predictions_l), decimals=4)))\n    print(\"Utility function: \" + str(np.round(utility_function(X, model), decimals=4)))\n    \n    return predictions\n\n\ndef classification_kfold(X, y, model):\n    X_ttv = X.reset_index()[['ts_id','date']]\n    X_ttv = X_ttv.sort_values(by=['date','ts_id'])\n    \n    if 'feature_0' in list(X.columns):\n        categ_vars = ['feature_0']\n    else:\n        categ_vars = []\n    \n    i = 1\n    for train_index, valid_index in GroupTimeSeriesSplit().split(X_ttv, groups=X_ttv['date']):\n        print('Fold {}'.format(i))\n        train_index_list = X_ttv.loc[train_index, 'date'].unique()\n        valid_index_list = X_ttv.loc[valid_index, 'date'].unique()\n        print(\"      [Train dates: \" + str(np.min(train_index_list)) + \" ---- \" + str(np.max(train_index_list)) + \"]\")\n        print(\"      [Validation dates: \" + str(np.min(valid_index_list)) + \" ---- \" + str(np.max(valid_index_list)) + \"]\")\n\n        train_cv = X[X.index.get_level_values(1).isin(train_index_list)]\n        y_train_cv = y[X.index.get_level_values(1).isin(train_index_list)]\n        valid_cv = X[X.index.get_level_values(1).isin(list(valid_index_list))]\n        y_valid_cv = y[X.index.get_level_values(1).isin(list(valid_index_list))]\n\n        model.fit(train_cv, \n                  y_train_cv, \n                  # eval_set = (valid_cv, np.ravel(y_valid_cv)), \n                  # early_stopping_rounds=60,\n                  cat_features = categ_vars) \n\n        print(\"   Train: \")\n        pred_trainval = predict_compute_metrics(train_cv, y_train_cv, model)\n        print(\"   Validation: \")\n        pred_test = predict_compute_metrics(valid_cv, y_valid_cv, model)\n        print('')\n\n        i += 1\n        \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel_tvk = classification_kfold(X_trainval, y_trainval, model_tv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train & val: \")\npred_trainval = predict_compute_metrics(X_trainval, y_trainval, model_tvk)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test, y_test, model_tvk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"%%time\n# model_tv_pos = best['model'](**best['param'])\nmodel_tv_pos = CatBoostClassifier(border_count=145, \n                           class_weights=(1, 0.8763763487405303),\n                           depth=5,\n                           iterations=2325,\n                           l2_leaf_reg=19.8650097679303,\n                           learning_rate=0.020187221403617027,\n                           logging_level='Silent',\n                           task_type=catboost_default_device)\n\nif 'feature_0' in list(X_trainval.loc[:,ut_pos_features].columns):\n    categ_vars = ['feature_0']\nelse:\n    categ_vars = []\n    \nmodel_tv_pos.fit(X_trainval.loc[:,ut_pos_features], \n              y_trainval, \n              # eval_set = (X_val, np.ravel(y_val)), \n              # early_stopping_rounds=60,\n              cat_features = categ_vars) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train & val: \")\npred_train = predict_compute_metrics(X_trainval.loc[:,ut_pos_features], y_trainval, model_tv_pos)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test.loc[:,ut_pos_features], y_test, model_tv_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel_tvk_pos = classification_kfold(X_trainval.loc[:,ut_pos_features], y_trainval, model_tv_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train & val: \")\npred_train = predict_compute_metrics(X_trainval.loc[:,ut_pos_features], y_trainval, model_tvk_pos)\nprint(\"Test: \")\npred_test = predict_compute_metrics(X_test.loc[:,ut_pos_features], y_test, model_tvk_pos)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nfrom tqdm.notebook import tqdm\n\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    test_df['feature_0'] = test_df['feature_0'].astype('int').astype('category')\n    sample_prediction_df.action = model_tvk_pos.predict(test_df.loc[:,ut_pos_features]) # make your 0/1 prediction here\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r /kaggle/working/catboost_info\n!rm -r /kaggle/working/pickle_files/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# # np.round(model.predict_proba(df_example_test)[:, 1])\n# # np.round(model_tvk_pos.predict_proba(df_example_test.loc[:,ut_pos_features])[:, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# df_example_test_submission = df_example_test.reset_index()[['ts_id']].copy()\n# df_example_test_submission['action'] = np.round(model_tvk_pos.predict_proba(df_example_test.loc[:,ut_pos_features])[:, 1]).astype('bool')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# # Final dataframe to submit\n# display(df_example_test_submission)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}