{"cells":[{"metadata":{},"cell_type":"markdown","source":"# De-anonymization: Buy/Sell/Net/Gross\n\n### Introduction\n\n\n##### Previously\nIt's the 4th, and likely the last notebook for me on this competition. Below are the links of the first three ones: \n1. Time Aggregation tag `tag_{0, 1, 2, 3, 4, 5}` ([Notebook](https://www.kaggle.com/gregorycalvez/de-anonymization-time-aggregation-tags))\n2. Price, Stock and Quantity `tag_{6, 14, 23}` ([Notebook](https://www.kaggle.com/gregorycalvez/de-anonymization-price-quantity-stocks))\n3. Min, Max and Time `tag_{12, 13, 22}` ([Notebook](https://www.kaggle.com/gregorycalvez/de-anonymization-min-max-and-time))\n\n##### Results\nIn this notebook, we will focus on the tags `tag_{24, 25, 26, 27}` and show that they likely correspond to: \n- `tag_24`: Net (ie. Buy - Sell)\n- `tag_25`: Buy\n- `tag_26`: Sell\n- `tag_27`: Gross (ie. Buy + Sell)\n\nThen, we'll also look quickly into `tag_19`, `tag_20` and `tag_28`.   "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"### Imports and data loading \n\nimport pandas as pd\nimport datatable as dt \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport plotly_express as px\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom imp import reload\nimport janest_utility as utility\nreload(utility)\n\nu = utility.Utility('/kaggle/input/jane-street-market-prediction/')\ntrain_datatable = dt.fread(u.filepath_train())\ntrain = train_datatable.to_pandas()\ntrain = u.add_intraday_ts(train)\ntrain = u.add_stock_id_all(train)\nn_trades = u.get_n_trades(train)\ntrain = u.add_feature_0(train)\n\ntrain_date = train[train['date'] == 299]\nstock = train[(train['date'] == 299) & (train['stock_id'] == '5')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Buy / Sell / Net / Gross\n\nI mentionned in other notebooks that `tag_23` is a \"quantity or volume\" tag. \n\nFor each feature associated with `tag_23`, the feature is build as follow: \n- `tag_23`\n- One of `tag_{0, 1, 2, 3, 4, 5}`\n- One of `tag_{24, 25, 26, 27}`\n- One of `tag_{15, 17}`\n\nWe already mentionned earlier that `tag_{0, 1, 2, 3, 4, 5}` is a time-aggregation tag. For this study, we will use `tag_0` features. `tag_0` is a rolling window with a very short characteristic time. We use those features to look into `tag_[24, 27]` as they will be almost \"noiseless\". \n\nFor now, we will only use `tag_15` features. We will look into the difference of `tag_15` and `tag_17` later. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fs = u.get_features('tag_23 & tag_0 & tag_15')\nu.select_tags('tag_23 & tag_0 & tag_15').astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### A lower bound on `tag_{25, 26, 27}` and a center on `tag_24`\nHere we use all the `tag_15` features but the same applies for the equivalent `tag_17` features. \n\nAs seen below on the graphs: \n- `feature_73` is centered around 0 and \"look like\" a normal distribution \n- `feature_85`, `feature_97` have a lower bound and \"look like\" exponential distribution\n- `feature_109` has a lower bound and \"look like\" a Gamma distribution. \n\nBut the interesting part is that the features seem to have some universal constants as show by the `value_counts`. On that day, we have 114 trades with the same exact `feature_{73, 85, 97, 109}`. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 4, figsize=(20, 4))\nfor ax, f in zip(axs, fs): \n    sns.distplot(train_date[f], kde=False, ax=ax)\n    ax.set_title(f'Distrubution of {f}')\nplt.show()\n\ndisplay(train_date[fs].value_counts().head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What are those values ? The answer is the in the title of the notebook section. For `feature_{85, 97, 109}`, the \"magic numbers\" are the minimum of the feature. For `feature_73`, it is the center of the distribution. \n\n\n##### Some pretty plots and a dim-2 manifold\nTo understand the link between those features, I scatter-plotted them. I also colored the points which had any of the magic numbers (for `feature_{85, 97}`). \n\nI did the plots using a full day of data (left) and using a specific stock / day (right). "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"minimums = {f: train[f].min() for f in fs}\n# Coloring \ntrain_date['category'] = np.where(\n    (train_date['feature_97'] == minimums['feature_97']) & (train_date['feature_85'] == minimums['feature_85']), 'black',    # Both 85 and 97 reach a min\n    np.where((train_date['feature_85'] == minimums['feature_85']), 'purple',                                                 # 85 only reach a min\n             np.where((train_date['feature_97'] == minimums['feature_97']), 'red',                                           # 97 only reach a min\n                      'pink'                                                                                                 # None reach a min\n                     )\n            )\n)\n### A single stock\nstock = train_date[(train_date['stock_id'] == '5')]\n# Limit the data to complete grid\nstock_lim = stock[\n    (np.abs(stock[fs[0]]) < 2)\n    & (stock[fs[3]] < 2)\n]\n\n# Plots\nfig, axs = plt.subplots(3, 2, sharex=True, figsize=(20, 20))\naxs[0, 0].scatter(\n    train_date[fs[0]], \n    train_date[fs[3]], \n    marker='+', \n    c=train_date['category'], \n)\naxs[0, 0].set_ylim((-5, 13))\naxs[0, 0].set_ylabel(fs[3])\n\naxs[1, 0].scatter(\n    train_date[fs[0]], \n    train_date[fs[1]], \n    marker='+', \n    c=train_date['category'], \n)\naxs[1, 0].set_ylim((-2, 15))\naxs[1, 0].set_ylabel(fs[1])\n\naxs[2, 0].scatter(\n    train_date[fs[0]], \n    train_date[fs[2]], \n    marker='.', \n    c=train_date['category'], \n)\naxs[2, 0].set_ylim((-2, 15))\naxs[2, 0].set_ylabel(fs[2])\n\n\naxs[2, 0].set_xlabel('feature_73')\naxs[2, 0].set_xlim((-10, 10))\n\n\naxs[0, 0].set_title('Relations between `feature_{73, 85, 97, 109}`}')\n\n\n# Plots\naxs[0, 1].scatter(\n    stock_lim[fs[0]], \n    stock_lim[fs[3]], \n    marker='+', \n    c=stock_lim['category'], \n)\naxs[0, 1].set_ylim((-5, 2))\naxs[0, 1].set_ylabel(fs[3])\n\naxs[1, 1].scatter(\n    stock_lim[fs[0]], \n    stock_lim[fs[1]], \n    marker='+', \n    c=stock_lim['category'], \n)\naxs[1, 1].set_ylim((-2, 3))\naxs[1, 1].set_ylabel(fs[1])\n\naxs[2, 1].scatter(\n    stock_lim[fs[0]], \n    stock_lim[fs[2]], \n    marker='.', \n    c=stock_lim['category'], \n)\naxs[2, 1].set_ylim((-2, 3))\naxs[2, 1].set_ylabel(fs[2])\n\n\naxs[2, 1].set_xlabel('feature_73')\naxs[2, 1].set_xlim((-2, 2))\n\naxs[0, 1].set_title('For one stock')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### What do we see?\n1. I hope that the graphs above help understand the importance of the minimums of `feature_{85, 97}`. \n2. Furthermore, on this stock (chosen carefully), we see that the values of the features are aligned. They are discrete. \n3. For each stock, those 4 features are strongly related to each other. In mathematical terms, I figured that if you define a point by the coordinate on the 4 features, the set of trades lie in a 2-dimension manifold. \n\nI also used a lot of 3d plotting but thsoe render poorly on the notebook and I did not reproduce them. \n\n**In short, only two parameters are enough to fully give `feature_{73, 85, 97, 109}`**"},{"metadata":{},"cell_type":"markdown","source":"### Straighten up the plot - Inverse the host's normalization\n\n\n##### Host's normalization\nTo obfuscate the data and to help us, the host normalized all the features. In mathematical terms, for each feature available to use, say `feature_x`, we have: \n$$ \\text{feature_}x = \\phi_x(\\text{original_feature_}x) $$\nWith $\\phi_x$ being the normalization function of the `feature_x`. I expect those functions $\\phi$ to be usual sklearn scalers (e.g. [StandartScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)).\n\n##### And our four features?\nFor the four features in question, for the stock used in the plots above, the values of the features are definitely discrete. \n\nSo I imagined that the values \"original_features\" in question were simply 0, 1, 2, 3, 4, etc (the set of natural number, the simplest set of discrete values). Moreover, that would explain why the features we have are discrete and why they are lower-bounded for some 3 of them (`original_feature_73` being in $\\mathbb Z$ and `original_feature_{85, 97, 109}` being in $\\mathbb N$). \n\nWith this assumption, it's easy to find and apply $\\phi_x^{-1}$ to our features. The code below does this and show the plots once again. \n\nThe idea is that the normalization makes the relation complicated to \"see\". I hoped that going back to the \"original space\" will help find the relations. And it indeed helped. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"### Phi^{-1}\nfor f in fs: \n    map_f = {v: i for i, v in enumerate(np.sort(stock_lim[f].unique().tolist()))}\n    stock_lim[f'map_{f}'] = stock_lim[f].map(map_f)\n\n### Plots\nfig, axs = plt.subplots(3, 2, figsize=(20, 20))\n# Not straight\naxs[0, 0].scatter(\n    stock_lim[fs[0]], \n    stock_lim[fs[3]], \n    marker='+', \n    c=stock_lim['category'], \n)\naxs[0, 0].set_ylim((-5, 2))\naxs[0, 0].set_ylabel(fs[3])\naxs[1, 0].scatter(\n    stock_lim[fs[0]], \n    stock_lim[fs[1]], \n    marker='+', \n    c=stock_lim['category'], \n)\naxs[1, 0].set_ylim((-2, 3))\naxs[1, 0].set_ylabel(fs[1])\naxs[2, 0].scatter(\n    stock_lim[fs[0]], \n    stock_lim[fs[2]], \n    marker='.', \n    c=stock_lim['category'], \n)\naxs[2, 0].set_ylim((-2, 3))\naxs[2, 0].set_ylabel(fs[2])\naxs[2, 0].set_xlabel('feature_73')\naxs[0, 0].set_xlim((-2, 2))\naxs[1, 0].set_xlim((-2, 2))\naxs[2, 0].set_xlim((-2, 2))\naxs[0, 0].set_title('Plots in feature space')\n### Straight plots\naxs[0, 1].scatter(\n    stock_lim[f'map_{fs[0]}'], \n    stock_lim[f'map_{fs[3]}'], \n    marker='+', \n    c=stock_lim['category'], \n)\naxs[0, 1].set_ylabel(f'map_{fs[3]}')\naxs[1, 1].scatter(\n    stock_lim[f'map_{fs[0]}'], \n    stock_lim[f'map_{fs[1]}'], \n    marker='+', \n    c=stock_lim['category'], \n)\naxs[1, 1].set_ylabel(f'map_{fs[1]}')\n\naxs[2, 1].scatter(\n    stock_lim[f'map_{fs[0]}'], \n    stock_lim[f'map_{fs[2]}'], \n    marker='.', \n    c=stock_lim['category'], \n)\naxs[2, 1].set_ylabel(f'map_{fs[2]}')\n\naxs[2, 1].set_xlabel(f'map_{fs[0]}')\n\naxs[0, 1].set_title('Plots in original space')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2-dimension manifold\n\nI said earlier that the points consisting of the four features as coordinates were on a 2d manifold. So that means, that there exist two mathematical relations between the four features. \n\nThe two mathematical equalities can be checked perfecly in the original space values (`map_feature_x` in the code). Those equalities are: \n* `feature_73` = `feature_85` - `feature_97`\n* `feature_109` = `feature_85` + `feature_97`\n\n\nFor anyone familiar with finance, those equations ring a bell. They are exactly what you would have if: \n- `feature_73` is a Net quantity\n- `feature_109` is a Gross quantity\n- `feature_85` is a Buy quantity\n- `feature_97` is a Sell quantity\n\n\n### Some comments\n\n##### Round lots\nThose plots can be reproduced only for some very specific stocks in the dataset. Why is that and why is it still consistent with my conclusion? \n\n`tag_23` features are quantities. In financial markets, for a given asset, the quantity cannot be anything. Often, it must be a \"round lot\" (ie a multiple of 100) or a integer. ([Round Lot](https://www.investopedia.com/terms/r/roundlot.asp))\\\nBut in practice, if the stock is cheap enough, the usual quantities traded are in the thousands or more, meaning that it actually appears continuous. \nHowever, for some specific assets the price is so large that the trade quantities are usually integers below 10 (eg. [Lindt](https://uk.finance.yahoo.com/quote/lisn.sw/))\n\n##### `tag_15` v. `tag_17`\nI have no proof of this but my assumption for `tag_15` v. `tag_17` is then that one of them is a quantity in number of shares and the other is a quantity in notional (i.e price times number of shares). \n\nExtreme assets like Lindt would explain why having those two variants of the same variable is important. \n\nSee the plot below showing that the `tag_15` features and `tag_17` features are definitely related. But the normalization done by the host makes it impossible to understand the relation. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nfor date, stock_id, in n_trades.head(10)[['date', 'stock_id']].values: \n    stock = train[(train['date'] == date) & (train['stock_id'] == stock_id) & (train['feature_109'] != minimums['feature_109'])].sort_values('feature_112')\n    plt.plot(\n        stock['feature_112'], \n        stock['feature_118'],\n        marker='.', \n        label=f'Date: {date}, Stock ID: {stock_id}'\n    )\nplt.legend()\nplt.xlabel('Tag_15 feature')\nplt.ylabel('Tag_17 feature')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Retrieving $\\phi$\n\nFor those four features, we then can plot the normalization function $\\phi$. \nThis normalization functions definitely depend on the stocks (eg. via the average daily traded volume). So the parameters would be different but the \"shape\" of the normalization functions are the same. \n\nBelow is a plot of what those normalization functions look like. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 2, figsize=(15, 10))\nfor i, f in enumerate(fs): \n    ix = i // 2\n    iy = i % 2\n    axs[ix, iy].scatter(\n        stock_lim[f'map_{f}'], \n        stock_lim[f],\n        marker='+'\n    )\n    axs[ix, iy].set_xlabel('Mapped')\n    axs[ix, iy].set_ylabel('Raw')\n    axs[ix, iy].set_title(f)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Fit $\\phi$, hyperbolic functions?\n- `feature_73`: the normalization function is some kind of [arcsinh](https://reference.wolfram.com/language/ref/ArcSinh.html) function\n- `feature_{85, 97, 109}`: the normalization functions seem to be of the same form (with different params) for those three features. Maybe a [arccosh](https://reference.wolfram.com/language/ref/ArcCosh.html). \n\nOf course, I tried to fit them. But unfortunately, I did not manage to get a 0 error. My hope was that $\\phi$ was dependend on the stock and that those normalizations would help us map the stocks from one day to another. \n\nI think I did not manage to fit a perfect function on those points partly because there is a discontinuity around 0. The $\\phi$ is probably defined piece-wise. I won't expose my failed fitting attempts here. "},{"metadata":{},"cell_type":"markdown","source":"# Quick look at `tag_{19, 20, 28}`\n\n### A graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"stock = train[(train['date'] == 299) & (train['stock_id'] == '5')]\nstock['feature_51_cat'] = np.where(stock['feature_51'] < -1.2, 'orange', 'blue')\nfig, axs = plt.subplots(3, 1, sharex=True, figsize=(20, 10))\naxs[0].scatter(\n    stock['intraday_ts'], \n    stock['feature_51'],\n    marker='+', \n)\naxs[0].set_ylabel('feature_51')\naxs[0].set_title('feature_51')\naxs[1].scatter(\n    stock[stock['feature_51_cat'] == 'orange']['intraday_ts'], \n    stock[stock['feature_51_cat'] == 'orange']['feature_51'],\n    marker='+', \n    color='orange'\n)\naxs[1].set_title('feature_51, lower band')\naxs[1].set_ylabel('feature_51')\naxs[2].scatter(\n    stock['intraday_ts'], \n    stock['feature_3_x0'],\n    marker='+', \n    color='red'\n)\naxs[2].set_ylabel('(Normalized) Price')\naxs[2].set_title('Price (feature_3 x feature_0)')\naxs[2].set_xlabel('Time')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What do we see? \n\nFor that stock, for that day, `feature_51` shows a very singular pattern. It has bands. \nI think that the bands are so visible on this stock thanks to the characteristics of the stock (ie. a large share price). \n\nFor each band, `feature_51` is strongly negatively correlated with the price of this asset as you can see on the price. \n\nThe same happens for most of the features among `tag_{19, 20, 28}`. Some notebooks already showed a relation between `tag_19` and the `weight` values, meaning that `tag_19` could refer to the liquidity available (i.e. size at the first limit) of the stock. "},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\n### On this notebook\nThis notebook was harder to write than the others. Mainly because the main idea rely on four variables being related with two equations and it's hard to visualize. I again resorted to math-like formalization to explain it, I hope it makes sense. \n\nFurthermore, I played so much with the data that I might just be seeing relations that do not actually exist anymore. So any challenging comment is welcomed. \n\n\n### Summary of de-anonymization\nHere's a quick summary of the de-anonymization results. This will likely be the last notebook in that series, I will probably never know how right/wrong those results were... Let me know your thoughts. \\\nIn any case, the process of digging into that data was a lot of fun. \n\n\n- `tag_{0, 1, 2, 3, 4, 5}`: time aggregation tag\n- `tag_6`: price\n- `tag_{7, 8, 9, 10}`: ??? \n- `tag_{12, 13}`: min / max\n- `tag_14`: stock embedding with price\n- `tag_{15, 17}`: number of shares, notional\n- `tag_16`: ??? \n- `tag_18`: Average daily volumes\n- `tag_{19, 20, 28}`: ??? \n- `tag_{23}`: Quantity traded\n- `tag_{24, 25, 26, 27}`: Net, Buy, Sell, Gross"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}