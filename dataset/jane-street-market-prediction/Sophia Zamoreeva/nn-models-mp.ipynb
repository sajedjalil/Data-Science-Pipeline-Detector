{"cells":[{"metadata":{"papermill":{"duration":0.017878,"end_time":"2021-01-19T19:06:27.963826","exception":false,"start_time":"2021-01-19T19:06:27.945948","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Import Libraries ðŸ“‚"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-19T19:06:28.005313Z","iopub.status.busy":"2021-01-19T19:06:28.004769Z","iopub.status.idle":"2021-01-19T19:06:32.956375Z","shell.execute_reply":"2021-01-19T19:06:32.955359Z"},"papermill":{"duration":4.974504,"end_time":"2021-01-19T19:06:32.956489","exception":false,"start_time":"2021-01-19T19:06:27.981985","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.018696,"end_time":"2021-01-19T19:06:32.993987","exception":false,"start_time":"2021-01-19T19:06:32.975291","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Importing Data ðŸ“š\n\n"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-19T19:06:33.039918Z","iopub.status.busy":"2021-01-19T19:06:33.03916Z","iopub.status.idle":"2021-01-19T19:08:12.366508Z","shell.execute_reply":"2021-01-19T19:08:12.365926Z"},"papermill":{"duration":99.354388,"end_time":"2021-01-19T19:08:12.366634","exception":false,"start_time":"2021-01-19T19:06:33.012246","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/jane-street-market-prediction/train.csv')\ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.017759,"end_time":"2021-01-19T19:08:12.404038","exception":false,"start_time":"2021-01-19T19:08:12.386279","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Preparing Data"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-19T19:08:12.450145Z","iopub.status.busy":"2021-01-19T19:08:12.44898Z","iopub.status.idle":"2021-01-19T19:08:13.426514Z","shell.execute_reply":"2021-01-19T19:08:13.426068Z"},"papermill":{"duration":1.004695,"end_time":"2021-01-19T19:08:13.426607","exception":false,"start_time":"2021-01-19T19:08:12.421912","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#ÐÐ°Ð¼ Ð½Ðµ Ð½ÑƒÐ¶Ð½Ñ‹ ÑÐ´ÐµÐ»ÐºÐ¸ Ñ Ð½ÑƒÐ»ÐµÐ²Ñ‹Ð¼ Ð²ÐµÑÐ¾Ð¼, Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð¼Ñ‹ Ð¸Ñ… Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼\ntrain = train.query('weight > 0').reset_index(drop = True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð±ÑƒÐ´ÑƒÑ‚ Ñ 86 Ð´Ð½Ñ\ntrain = train.query('date > 85').reset_index(drop = True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-19T19:08:23.363044Z","iopub.status.busy":"2021-01-19T19:08:23.362541Z","iopub.status.idle":"2021-01-19T19:08:26.949712Z","shell.execute_reply":"2021-01-19T19:08:26.948531Z"},"papermill":{"duration":3.612087,"end_time":"2021-01-19T19:08:26.94983","exception":false,"start_time":"2021-01-19T19:08:23.337743","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#Ð—Ð°Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ ÑÑ€ÐµÐ´Ð½Ð¸Ð¼ \ntrain.fillna(train.mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ 0 Ð¸Ð»Ð¸ 1 Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¹ resp Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ñ… Ð² ÑÑ‚Ð¾Ð»Ð±Ñ†Ðµ 'action'\ntrain['action'] = (train['resp'] > 0 ).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_train_data  = train.iloc[:,7:137]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ÐÐ°Ð¹Ð´ÐµÐ¼ Ð¿Ð°Ñ€Ñ‹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ñ ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸ÐµÐ¹ > |0.9|\ndef corrFilter(x: pd.DataFrame, bound: float):\n    xCorr = x.corr()\n    xFiltered = xCorr[((xCorr >= bound) | (xCorr <= -bound)) & (xCorr !=1.000)]\n    xFlattened = xFiltered.unstack().sort_values().drop_duplicates()\n    return xFlattened\n\nhigh_correlations=corrFilter(features_train_data, .9).to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_drop_cols = set(high_correlations.index.get_level_values(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = features_train_data.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in all_drop_cols:\n#     features.remove(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean = train.loc[:, features].mean()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.020873,"end_time":"2021-01-19T19:08:26.992823","exception":false,"start_time":"2021-01-19T19:08:26.97195","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Creating Train and Test DataFrame "},{"metadata":{"trusted":true},"cell_type":"code","source":"# VALID_DAYS = 50  # using for valid\nVALID_DAYS = 0   # using for LB\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']\n\n# ------------------------------- #\n#            NN sample            #\n# ------------------------------- #\nprint('Make NN sample...')\n# train\nX_train = train[train['date'] <= 499-VALID_DAYS]\ny_train = np.stack([(X_train[c]>0).astype('int') for c in resp_cols]).T\nX_train = X_train.loc[:, features].values\nprint(X_train.shape, y_train.shape)\n\n# valid\nX_valid = train[train['date'] > 499-VALID_DAYS]\ny_valid = np.stack([(X_valid[c]>0).astype('int') for c in resp_cols]).T\nX_valid = X_valid.loc[:, features].values\nprint(X_valid.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------------------------------- #\n#                   model                     #\n# ------------------------------------------- #\nHIDDEN_LAYER_1 = [256, 256]\nHIDDEN_LAYER_2 = [160, 160, 160]\nHIDDEN_LAYER_3 = [128, 128, 128, 128]\nTARGET_NUM = 5   # ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ð¸ 5 Ñ€ÐµÑÐ¿\n\ninput = tf.keras.layers.Input(shape=(X_train.shape[1], ))\n\n#part_1\nx1 = tf.keras.layers.BatchNormalization()(input)\nx1 = tf.keras.layers.Dropout(0.25)(x1)\nfor units in HIDDEN_LAYER_1:\n    x1 = tf.keras.layers.Dense(units)(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.Activation(tf.keras.activations.swish)(x1)\n    x1 = tf.keras.layers.Dropout(0.25)(x1)\n\n# part_2\nx2 = tf.keras.layers.BatchNormalization()(input)\nx2 = tf.keras.layers.Dropout(0.25)(x2)\nfor units in HIDDEN_LAYER_2:\n    x2 = tf.keras.layers.Dense(units)(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.Activation(tf.keras.activations.swish)(x2)\n    x2 = tf.keras.layers.Dropout(0.25)(x2)\n    \n# part_3\nx3 = tf.keras.layers.BatchNormalization()(input)\nx3 = tf.keras.layers.Dropout(0.25)(x3)\nfor units in HIDDEN_LAYER_3:\n    x3 = tf.keras.layers.Dense(units)(x3)\n    x3 = tf.keras.layers.BatchNormalization()(x3)\n    x3 = tf.keras.layers.Activation(tf.keras.activations.swish)(x3)\n    x3 = tf.keras.layers.Dropout(0.25)(x3)\n\nx = tf.keras.layers.concatenate([x1, x2, x3])\nx = tf.keras.layers.Dense(TARGET_NUM)(x)\n\noutput = tf.keras.layers.Activation(\"sigmoid\")(x)\n\nmodel = tf.keras.models.Model(inputs=input, outputs=output)\nmodel.compile(\n    optimizer = tfa.optimizers.RectifiedAdam(learning_rate=1e-3),\n    metrics   = tf.keras.metrics.AUC(name=\"AUC\"),\n    loss      = tf.keras.losses.BinaryCrossentropy(label_smoothing=1e-2),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    x = X_train, \n    y = y_train, \n    epochs=25, \n    batch_size=4096, \n    validation_data=(X_valid, y_valid),\n)\nmodels = []\nmodels.append(model)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.030224,"end_time":"2021-01-19T19:11:08.925962","exception":false,"start_time":"2021-01-19T19:11:08.895738","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"THRESHOLD = 0.502\n\nimport janestreet\nfrom tqdm import tqdm\njanestreet.make_env.__called__ = False\nenv = janestreet.make_env()\n\nprint('predicting...')\n\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        \n        X_test = test_df.loc[:, features].values\n        if np.isnan(X_test.sum()):  # Ð—Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ numpy, ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð±ÑƒÐ´ÐµÑ‚ Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ\n            X_test = np.nan_to_num(X_test) + np.isnan(X_test) * f_mean.values\n        pred = model(X_test, training = False).numpy()\n        pred = np.mean(pred)\n        \n        pred_df.action = np.where(pred >= THRESHOLD, 1, 0).astype(int)\n\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}