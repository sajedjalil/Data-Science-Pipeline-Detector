{"cells":[{"metadata":{},"cell_type":"markdown","source":"kudos hamidtarek"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 500)\nimport cudf as cu\n\nimport xgboost as xgb\nprint(\"XGBoost version:\", xgb.__version__)\n\nimport janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nimport cudf as cu\nfrom sklearn.metrics import classification_report\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.feature_selection import SelectFromModel\nfrom tqdm.notebook import tqdm\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_cudf = cu.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\ndata = train_cudf.to_pandas()\ndel train_cudf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [c for c in data.columns if 'feature' in c]\nfor i in features:\n    x = data[i].mean()     \n    data[i] = data[i].fillna(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I have taked this cell from https://www.kaggle.com/jazivxt/the-market-is-reactive\n# And https://www.kaggle.com/drcapa/jane-street-market-prediction-starter-xgb\n\n#train = train[train['weight'] != 0]\n#train['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\n\n#X_train = train.loc[:, features]\n#X_train = X_train.fillna(-999)\n#y_train = train.loc[:, 'action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\n\n# prepare the data before splitting to train and test\ndata = data[data['weight']!=0]\ndata['action'] = (data['resp']>0)*1\nprint(data.shape)\n#features = data.columns.str.contains('feature')\n\n# with we will create the model\ntrain = data.sample(frac = 0.75, random_state = 73)\nprint(train.shape)\n#train = data.reset_index(drop=True) # if we keep it here it will raise an error in the valid set, cause if the change of the index\n\nvalid = data.drop(train.index) # take the data that does not exist in train\nprint(valid.shape)\n\n\ntrain.reset_index(drop=True, inplace=True)\nvalid.reset_index(drop=True, inplace=True)\n\n# it will help us track the model\n#test  = data.tail(500).reset_index(drop=True)\n\n# split the train set\nX_train = train.loc[:,features] \ny_train = train.loc[:, 'action']\n\n# split the test set\n#X_test = test.loc[:, features]\n#y_test = test.loc[:, 'action']\n\n\nX_valid = valid.loc[:, features]\ny_valid = valid.loc[:, 'action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nselector = CatBoostClassifier(thread_count = -1, task_type = \"GPU\", devices = '-1', random_seed = 73).fit(Pool(X_train, y_train), verbose = 100) # without task_type='GPU' the fit time is 42min with GPU is 46s\nlist_of_tuples = list(zip(X_train.columns.values, selector.get_feature_importance())) \n\ndf = pd.DataFrame(list_of_tuples).sort_values(by = [1]).reset_index(drop = True).rename(columns = {0: 'feat_labels', 1: 'feature_importances'})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.tail(111) # features importance > 0.003\nfeatures = list(df1[\"feat_labels\"])\n\nX_train = X_train.loc[:, features]\n#X_test = X_test.loc[:, features]\n#print(train.shape)\nprint(X_train.shape)\n#print(X_test.shape)\n\nX_valid = X_valid.loc[:, features]\nprint(X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The training part taked from here https://www.kaggle.com/xhlulu/ieee-fraud-xgboost-with-gpu-fit-in-40s\n\nmodel = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=11,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    missing=None,\n    random_state=73,\n    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n)\n\n%time model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in tqdm(iter_test):\n    \n    X_test = test_df.loc[:, features]\n    \n    for i in features:\n        x = X_test[i].mean()     \n        X_test[i] = X_test[i].fillna(x)\n\n    y_preds = model.predict(X_test)\n    \n    sample_prediction_df.action = y_preds\n    env.predict(sample_prediction_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}