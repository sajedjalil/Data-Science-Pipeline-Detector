{"cells":[{"metadata":{},"cell_type":"markdown","source":"Based on the ideas of these notebooks:\n\n[OWN Jane Street with Keras NN](https://www.kaggle.com/tarlannazarov/own-jane-street-with-keras-nn)\n\n[TabNet Starter](https://www.kaggle.com/yifor01/tabnet-starter)\n\n...and so many kernels\n\n\nI believe it is a good model for ensembles with neural network models."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1\n!pip install  ../input/officialpytorchtabnet/pytorch_tabnet-3.0.0-py3-none-any.whl pytorch-tabnet  > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datatable as dt\nimport janestreet\nfrom tqdm.notebook import tqdm\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nimport torch\nfrom sklearn.metrics import roc_auc_score\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas()\nfeatures = [c for c in train.columns if 'feature' in c]\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain = train.query('weight > 0').reset_index(drop = True)\ntrain[features[1:]] = train[features[1:]].fillna(train[features[1:]].mean())\ntrain['action'] = (train['resp'] > 0).astype('int')\nX = train[features].values\ny = train['action'].values\nf_mean = np.mean(train[features[1:]].values,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if TRAINING:\n    tabnet_params = dict(n_d=36, \n                    n_a=36, \n                    n_steps=3,\n                    gamma=1.5,\n                    lambda_sparse=1e-4, \n                    momentum=0.3, \n                    clip_value=2., \n                    mask_type='entmax',\n                    optimizer_fn=torch.optim.Adam,\n                    optimizer_params=dict(lr=1e-3, weight_decay=1e-4),\n                    scheduler_params=dict(mode=\"min\",patience=3,min_lr=1e-5,factor=0.9,),\n                    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n                    epsilon=1e-15,\n                    verbose=2,\n                    seed=8012,\n                    )\n\n    model = TabNetClassifier(**tabnet_params)\n\n    model.fit(X_train=X,\n              y_train=y,\n              max_epochs=50,\n              batch_size=2048,\n              virtual_batch_size=128,\n              num_workers=0, drop_last=False,\n             )\n    pickle.dump(model, open(f'tabnet_model.pickle', 'wb'))\nelse:\n    model = pickle.load(open(f'../input/jane-street-tabnet-model/tabnet_model.pickle',\"rb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numba import jit\nfrom numba import prange\n\n@jit(nopython=True)\ndef fillna_npwhere(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array\n\n@jit(parallel=True,nopython=True)\ndef for_loop(method, matrix, values):\n    for i in prange(matrix.shape[0]):\n        matrix[i] = method(matrix[i], values)\n    return matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = janestreet.make_env()\nenv_iter = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        x_tt[:, 1:] = for_loop(fillna_npwhere, x_tt[:, 1:], f_mean)\n        pred_df.action = model.predict(x_tt)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}