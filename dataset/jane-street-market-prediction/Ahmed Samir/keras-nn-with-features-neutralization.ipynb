{"cells":[{"metadata":{},"cell_type":"markdown","source":"### I implemented feature neutralization suggested by [this kernel](https://www.kaggle.com/code1110/janestreet-avoid-overfit-feature-neutralization) over the awesome [keras kernel](https://www.kaggle.com/tarlannazarov/own-jane-street-with-keras-nn) then added a bunch of plots for cross validation. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport pickle\nfrom tqdm import tqdm\nfrom random import choices\n\n\nSEED = 1111\ninference = False\ncv = False\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\ntrain_pickle_file = '/kaggle/input/pickling/train.csv.pandas.pickle'\ntrain = pickle.load(open(train_pickle_file, 'rb'))\n\ntrain = train.query('date > 85').reset_index(drop = True) \ntrain = train[train['weight'] != 0]\n\ntrain.fillna(train.mean(),inplace=True)\n\ntrain['action'] = ((train['resp'].values) > 0).astype(int)\ntrain['bias'] = 1\n\n\nfeatures = [c for c in train.columns if \"feature\" in c]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Neutralization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# code to feature neutralize\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.auto import tqdm\n\ndef build_neutralizer(train, features, proportion, return_neut=False):\n    \"\"\"\n    Builds neutralzied features, then trains a linear model to predict neutralized features from original\n    features and return the coeffs of that model.\n    \"\"\"\n    neutralizer = {}\n    neutralized_features = np.zeros((train.shape[0], len(features)))\n    target = train[['resp', 'bias']].values\n    for i, f in enumerate(features):\n        # obtain corrected feature\n        feature = train[f].values.reshape(-1, 1)\n        coeffs = np.linalg.lstsq(target, feature)[0]\n        neutralized_features[:, i] = (feature - (proportion * target.dot(coeffs))).squeeze()\n        \n    # train model to predict corrected features\n    neutralizer = np.linalg.lstsq(train[features+['bias']].values, neutralized_features)[0]\n    \n    if return_neut:\n        return neutralized_features, neutralizer\n    else:\n        return neutralizer\n\ndef neutralize_array(array, neutralizer):\n    neutralized_array = array.dot(neutralizer)\n    return neutralized_array\n\n\ndef test_neutralization():\n    dummy_train = train.loc[:100000, :]\n    proportion = 1.0\n    neutralized_features, neutralizer = build_neutralizer(dummy_train, features, proportion, True)\n    dummy_neut_train = neutralize_array(dummy_train[features+['bias']].values, neutralizer)\n    \n#     assert np.array_equal(neutralized_features, dummy_neut_train)\n    print(neutralized_features[0, :10], dummy_neut_train[0, :10])\n    \n\ntest_neutralization()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that it almost predicts it correctly and the offset isn't that huge.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"proportion = 1.0\n\nneutralizer = build_neutralizer(train, features, proportion)\ntrain[features] = neutralize_array(train[features+['bias']].values, neutralizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_mean = np.mean(train[features[1:]].values,axis=0)\n\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n\nX = train.loc[:, train.columns.str.contains('feature')]\n#y_train = (train.loc[:, 'action'])\n\ny = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n\n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n    )\n\n    return model\n\nbatch_size = 5000\nhidden_units = [150, 150, 150]\ndropout_rates = [0.2, 0.2, 0.2, 0.2]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\nepochs = 200\n\nclf = create_mlp(\n    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n    )\n\nif inference:\n    clf = keras.models.load_model('keras_nn')\nelse:\n    clf.fit(X, y, epochs=epochs, batch_size=5000)\n    clf.save('keras_nn')\n\nmodels = []\n\nmodels.append(clf)\n\nth = 0.5000\n\n\nf = np.median\nmodels = models[-3:]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cross Validation using GroupKFold"},{"metadata":{"trusted":true},"cell_type":"code","source":"if cv:\n\n    from sklearn.model_selection import GroupKFold\n    from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, precision_recall_curve\n    import gc\n\n    # oof validation probability array\n    oof_probas = np.zeros(y.shape)\n\n    # validation indices in case of time series split\n    val_idx_all = []\n\n    # cv strategy\n    N_SPLITS = 5\n    gkf = GroupKFold(n_splits=N_SPLITS)\n\n    for fold, (train_idx, val_idx) in enumerate(gkf.split(train.action.values, groups=train.date.values)):\n\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx].values\n        y_train, y_val = y[train_idx], y[val_idx]\n\n\n        # training and evaluation score\n        clf.fit(X_train, y_train, epochs=epochs, batch_size=5000)\n\n        oof_probas[val_idx] += clf(X_val, training=False).numpy()\n\n        score = roc_auc_score(y_val, oof_probas[val_idx])  # classification score\n        print(f'FOLD {fold} ROC AUC:\\t {score}')\n\n        # deleting excess data to avoid running out of memory\n        del X_train, X_val, y_train, y_val\n        gc.collect()\n\n        # appending val_idx in case of group time series split\n        val_idx_all.append(val_idx)\n\n\n    # concatenation of all val_idx for further acessing\n    val_idx = np.concatenate(val_idx_all)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ROC AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"if cv:\n    auc_oof = roc_auc_score(y[val_idx], oof_probas[val_idx])\n    print(auc_oof)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper functions"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef determine_action(df, thresh):\n    \"\"\"Determines action based on defined threshold.\"\"\"\n    action = (df.weight * df.resp > thresh).astype(int)\n    return action\n\ndef date_weighted_resp(df):\n    \"\"\"Calculates the sum of weight, resp, action product.\"\"\"\n    cols = ['weight', 'resp', 'action']\n    weighted_resp = np.prod(df[cols], axis=1)\n    return weighted_resp.sum()\n\ndef calculate_t(dates_p):\n    \"\"\"Calculate t based on dates sum of weighted returns\"\"\"\n    e_1 =  dates_p.sum() / np.sqrt((dates_p**2).sum())\n    e_2 = np.sqrt(250/np.abs(len(dates_p)))\n    return e_1 * e_2\n\ndef calculate_u(df, thresh):\n    \"\"\"Calculates utility score, and return t and u.\"\"\"\n    df = df.copy()\n\n    # calculates sum of dates weighted returns\n    dates_p = df.groupby('date').apply(date_weighted_resp)\n        \n    # calculate t\n    t = calculate_t(dates_p)\n    return t, min(max(t, 0), 6) * dates_p.sum()\n\n\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--', label='Random')  # dashed diagonal\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend(loc='lower right')\n    plt.grid()\n    \n    \ndef plot_precision_recall_curve(precisions, recalls, thresholds):\n    plt.figure(figsize=(8, 6))\n    plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n    plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n    plt.xlabel('Thresholds')\n    plt.legend(loc='lower left')\n    plt.grid()\n\n\n    \ndef plot_thresh_u_t(df, oof):\n    threshs = np.linspace(0, 1, 1000)\n    ts = []\n    us = []\n    \n    for thresh in threshs:\n        df['action'] = np.where(oof >= thresh, 1, 0)\n        t, u = calculate_u(df, thresh)\n        ts.append(t)\n        us.append(u)\n        \n    # change nans into 0\n    ts = np.array(ts)\n    us = np.array(us)\n    ts = np.where(np.isnan(ts), 0.0, ts)\n    us = np.where(np.isnan(us), 0.0, us)\n    \n    tmax = np.argmax(ts)\n    umax = np.argmax(us)\n    \n    print(f'Max Utility Score: {us[umax]}')\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n    axes[0].plot(threshs, ts)\n    axes[0].set_title('Different t scores by threshold')\n    axes[0].set_xlabel('Threshold')\n    axes[0].axvline(threshs[tmax])\n\n    axes[1].plot(threshs, us)\n    axes[1].set_title('Different u scores by threshold')\n    axes[1].set_xlabel('Threshold')\n    axes[1].axvline(threshs[umax], color='r', linestyle='--', linewidth=1.2)\n    \n    print(f'Optimal Threshold: {threshs[umax]}')\n    \n    return threshs[umax]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"if cv:\n    fpr, tpr, thresholds = roc_curve(y[val_idx, 4], oof_probas[val_idx, 4])    \n    plot_roc_curve(fpr, tpr, 'NN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Precision/Recall Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"if cv:\n    precisions, recalls, thresholds = precision_recall_curve(y[val_idx, 4], oof_probas[val_idx, 4])\n    plot_precision_recall_curve(precisions, recalls, thresholds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utility Score Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"if cv:\n    opt_thresh = plot_thresh_u_t(train.iloc[val_idx], oof_probas[val_idx, 4])\nelse:\n    opt_thresh = 0.506","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        \n        x_tt = np.append(x_tt, [[1]], axis=1)  # add bias term\n        x_tt = neutralize_array(x_tt, neutralizer)\n        \n        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n        pred = f(pred)\n        pred_df.action = np.where(pred >= opt_thresh, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's it!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}