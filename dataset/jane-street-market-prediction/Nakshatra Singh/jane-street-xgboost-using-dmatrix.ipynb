{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Jane Street Market Prediction using XGBoost Algorithm with GPU üöÄ‚ö°** \n\nHey everyone, this is my very first competition i'm taking part in. I want to thank Jane Street and Kaggle for making this competition available to all of us. \n\nThanks everyone, and good luck!\n\n**- By Nakshatra Singh**"},{"metadata":{},"cell_type":"markdown","source":"# **1. Loading necessary libraries and dependencies**\n\nAll imports are delineated below for easy reference. Make sure you have selected the **`gpu`** accelerator instance for this notebook. Click on `+Add data` (by toggling the sidebar) and add the the [Jane Street Market dataset](https://www.kaggle.com/c/jane-street-market-prediction/data). \n\nNow, you are all set-up to run this worksheet. ü§ó"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cudf \nimport numpy as np\nimport pandas as pd\n\n#@ Plotly import \nimport plotly.io as pio               \n#@ Not using Plotly express \nimport plotly.graph_objs as go      \n#@ Graph object has more customizations\nfrom plotly.offline import iplot\n#@ ggplot2 theme for plotly\npio.templates.default = \"ggplot2\"  \n\n#@ Importing environment\nimport janestreet\n#@ Initialize the environment\nenv = janestreet.make_env() \n#@ An iterator which loops over the test\niter_test = env.iter_test() \n\n#@ Classifier import\nimport xgboost as xgb\n\n#@ Clean progress bar\nfrom tqdm.notebook import tqdm\n\n#@ Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code\nfrom numba import njit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. Reading the data**\n\nI'll be using the [cuDF library](https://github.com/rapidsai/cudf) by RAPIDSAI. cuDF provides a pandas-like API that will be familiar to data engineers & data scientists, so they can use it to easily accelerate their workflows without going into the details of CUDA programming. This library does a lot of heavy lifting for us."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Reading dataset using CUDA dataframes ...\", end='')\n#@ Parsing the training dataset by using RAPIDSAI cudf library\ntrain_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\n#@ Converting to a pandas dataframe \ntrain_data = train_cudf.to_pandas()\n#@ Deleting training variable to save memory\ndel train_cudf\n\n#@ Parsing the meta-dataset by using RAPIDSAI cudf library\nmeta_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\n#@ Converting to a pandas dataframe \nmeta_data = meta_cudf.to_pandas()\n#@ Deleting meta-data variables to save memory\ndel meta_cudf\n\n#@ Parsing sample predictions\nsample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv') \n\nprint('Finished.\\n')\n\n#@ Printing out training and meta-data shapes\nprint(f'Train shape: {format(train_data.shape)}')\nprint(f'Features meta shape: {format(meta_data.shape)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **3. Preprocessing the data**\n\nFirst, I'll be training the rows with weight > 0 (you can read the [data description](https://www.kaggle.com/c/jane-street-market-prediction/data) for more details), store the mean of indivitual columns, fill the null values with indivitual column means, setup the training dataframes and variables, finally splitting the dataset for model evaluation.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Preprocessing data...', end='')\n\n#@ Storing columns with the word feature included\nfeatures = [c for c in train_data.columns if 'feature' in c]\n\n#@ Trades with weight=0 are not considered for scoring evaluation\ntrain_data = train_data[train_data['weight'] > 0].reset_index(drop = True)\n\n#@ Filling nan using ffill method\ntrain_data[features] = train_data[features].fillna(method = 'ffill').fillna(0)\n\n#@ Only considering the target column values > 0 \ntrain_data['action'] = (train_data['resp'].values > 0).astype(int)\n\nprint('Finished.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. Data Visualization**\n\nWe'll now plot the target column distribution using [plotly](https://plotly.com/python/).\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_data['action'].value_counts().index\ny = train_data['action'].value_counts().values\n\ntrace = go.Bar(x=x,\n               y=y,\n               marker=dict(\n               color=y,\n               colorscale='sunsetdark'))   \n    \ndata = [trace]\nlayout = go.Layout(showlegend=False,\n                   title='<b>Is the target balanced or Not?</b>',\n                   xaxis=dict(title='<b>Action</b>'),\n                   yaxis=dict(title='<b>Count</b>'))\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)  \n\n#@ Deleting unnecessary variables to save memory\ndel(x, y)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **5. XGBoost Classifier** \n\nLet's start by using XGBoost as our first boosting classifier to build our Machine Learning Model. You can also try various **cross-validation techiniques** (like, [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html), [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), and many more..) to optimize your hyperparameters.\n\n{[XGBOOST - Official Documentation](https://xgboost.readthedocs.io/en/latest/)}"},{"metadata":{"trusted":true},"cell_type":"code","source":"#@ XGBoost Classifier with GPU support \nprint('Creating XGBclassifier...\\n', end='')\n\n#@ Setting up hyper-parameters in a pretty formatted way\nparameters = {'max_depth': 8,\n              'learning_rate': 0.015,\n              'random_state': 42,\n              'tree_method': 'gpu_hist',\n              'min_child_weight': 0.30,\n              'subsample': 0.46,\n              'colsample_bytree': 0.99,\n              'eval_metric': 'auc',\n              'gamma': 9.8,\n              'objective': 'binary:logistic'}\n\n#@ Setting up training variables \nX_train = train_data.loc[train_data['date'] > 80, features].values\ny_train = train_data.loc[train_data['date'] > 80, 'action'].values\n\n#@ Loading numpy arrays into DMatrix\nd_train = xgb.DMatrix(X_train, y_train)\n#@ Fitting the classifier with hyper-parameters and training variables\n%time clf = xgb.train(parameters, d_train, 1175)   \n\nprint('Finished training the classifier.') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **6. Submitting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#@ Utitlity function for submittion using njit\n@njit\ndef fast_fillna(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array\n    \ntrain_data.loc[0, features[1:]] = fast_fillna(train_data.loc[0, features[1:]].values, 0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = np.zeros(len(features))\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    if test_df['weight'].item() > 0:\n        X_test = test_df.loc[:, features].values\n        X_test[0, :] = fast_fillna(X_test[0, :], tmp)\n        tmp = X_test[0, :]\n        #@ Converting pandas df to DMatrix\n        d_test = xgb.DMatrix(X_test)\n        #@ Submitting xgb model predictions\n        y_preds = clf.predict(d_test) \n        sample_prediction_df.action = np.where(y_preds >= 0.5, 1, 0).astype(int)\n        \n    else:\n        sample_prediction_df.action = 0\n\n    env.predict(sample_prediction_df) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## If you liked this notebook, please make sure to upvote this kernel ‚¨ÜÔ∏è. üí¨ Connect? Let‚Äôs get social: http://myurls.co/nakshatrasinghh."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}