{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport os, gc, random\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.max_columns', 140) #最大表示列数の指定\n\n\n# fix seed\nseed = 2021\nnp.random.seed(seed)\nrandom.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch import nn\n \nclass JSMP_Dataset(Dataset):\n     \n    def __init__(self, file_path, window_size):\n        # valiables\n        self.file_path = file_path\n        self.window_size = window_size\n        \n        # read csv\n        train = pd.read_csv(file_path)\n        \n        # pre processing\n        train = train.query('date > 85').reset_index(drop = True) \n        #train = train[train['weight'] != 0]\n        train.fillna(train.mean(),inplace=True)\n        train['action'] = ((train['resp'].values) > 0).astype(int)\n        \n        resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n        self.features = [c for c in train.columns if \"feature\" in c]\n        self.f_mean = np.mean(train[self.features[1:]].values,axis=0)\n        \n        self.X_train = train.loc[:, train.columns.str.contains('feature')].values\n        self.y_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n        \n        self.X_train = torch.from_numpy(self.X_train).float()\n        self.y_train = torch.from_numpy(self.y_train).float()\n        \n        # reduce memory\n        del train\n        gc.collect()\n \n    def __len__(self):\n        return len(self.X_train) - self.window_size\n     \n    def __getitem__(self, i):\n        data = self.X_train[i:(i+ self.window_size), :] \n        label = self.y_train[i + self.window_size - 1]\n \n        return data, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"window_size = 5\nfile_path = '/kaggle/input/jane-street-market-prediction/train.csv'\nds = JSMP_Dataset(file_path, window_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Network(TCN)\nhttps://github.com/locuslab/TCN/blob/master/TCN/tcn.py"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn.utils import weight_norm\n\n\nclass Chomp1d(nn.Module):\n    def __init__(self, chomp_size):\n        super(Chomp1d, self).__init__()\n        self.chomp_size = chomp_size\n\n    def forward(self, x):\n        return x[:, :, :-self.chomp_size].contiguous()\n\n\nclass TemporalBlock(nn.Module):\n    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n        super(TemporalBlock, self).__init__()\n        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n                                           stride=stride, padding=padding, dilation=dilation))\n        self.chomp1 = Chomp1d(padding)\n        self.relu1 = nn.ReLU()\n        self.dropout1 = nn.Dropout(dropout)\n\n        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n                                           stride=stride, padding=padding, dilation=dilation))\n        self.chomp2 = Chomp1d(padding)\n        self.relu2 = nn.ReLU()\n        self.dropout2 = nn.Dropout(dropout)\n\n        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n        self.relu = nn.ReLU()\n        self.init_weights()\n\n    def init_weights(self):\n        self.conv1.weight.data.normal_(0, 0.01)\n        self.conv2.weight.data.normal_(0, 0.01)\n        if self.downsample is not None:\n            self.downsample.weight.data.normal_(0, 0.01)\n\n    def forward(self, x):\n        out = self.net(x)\n        res = x if self.downsample is None else self.downsample(x)\n        return self.relu(out + res)\n\n\nclass TemporalConvNet(nn.Module):\n    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n        super(TemporalConvNet, self).__init__()\n        layers = []\n        num_levels = len(num_channels)\n        for i in range(num_levels):\n            dilation_size = 2 ** i\n            in_channels = num_inputs if i == 0 else num_channels[i-1]\n            out_channels = num_channels[i]\n            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n\n        self.network = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.network(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"class TCN(nn.Module):\n    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n        super(TCN, self).__init__()\n        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n        self.fc = nn.Linear(130 * num_channels[-1], output_size)\n\n    def forward(self, inputs):\n        \"\"\"Inputs have to have dimension (N, C_in, L_in)\"\"\"\n        y1 = self.tcn(inputs)  # input should have dimension (N, C, L)\n        #y1 = torch.flatten(y1, start_dim=1)\n        #o = self.fc(y1)\n        return y1#torch.sigmoid(o)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TCN(nn.Module):\n    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n        super(TCN, self).__init__()\n        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n        \n        self.fc1 = nn.Linear(130 * num_channels[-1], 128)\n        self.dropout1 = nn.Dropout(dropout)\n        self.batch_norm1 = nn.BatchNorm1d(128)\n        self.LeakyReLU1 = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        \n        self.fc2 = nn.Linear(128, 128)\n        self.dropout2 = nn.Dropout(dropout)\n        self.batch_norm2 = nn.BatchNorm1d(128)\n        self.LeakyReLU2 = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n        \n        self.fc3 = nn.Linear(128, output_size)\n        \n    def forward(self, inputs):\n        \"\"\"Inputs have to have dimension (N, C_in, L_in)\"\"\"\n        y1 = self.tcn(inputs)  # input should have dimension (N, C, L)\n        y1 = torch.flatten(y1, start_dim=1)\n        \n        y1 = self.fc1(y1)\n        y1 = self.batch_norm1(y1)\n        y1 = self.LeakyReLU1(y1)\n        y1 = self.dropout1(y1)\n        \n        y1 = self.fc2(y1)\n        y1 = self.batch_norm2(y1)\n        y1 = self.LeakyReLU2(y1)\n        y1 = self.dropout2(y1)\n        \n        o = self.fc3(y1)\n        return torch.sigmoid(o)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint('use devise:', device)\n\n# load model\nnet1 = TCN(input_size=5, output_size=5, num_channels=[16, 8, 4, 2], kernel_size=2, dropout=0.5)\nnet2 = TCN(input_size=5, output_size=5, num_channels=[16, 8, 4, 2], kernel_size=2, dropout=0.5)\n\nnet1.load_state_dict(torch.load('/kaggle/input/jsmp-tcn-pytorch/best_accuracy_model.mdl', map_location=torch.device(device)))\nnet2.load_state_dict(torch.load('/kaggle/input/jsmp-tcn-pytorch/best_loss_model.mdl', map_location=torch.device(device)))\n\nnet1.eval()\nnet2.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"th = 0.5\n\nimport janestreet\nenv = janestreet.make_env()\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint('use devise:', device)\n\nfor i, (test_df, pred_df) in enumerate(env.iter_test()):\n    x_tt = test_df.loc[:, ds.features].values\n    if np.isnan(x_tt[:, 1:].sum()):\n        x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * ds.f_mean\n    \n    # make window data\n    if i == 0:\n        x_window = x_tt.copy()\n    elif i < window_size: \n        x_window = np.concatenate([x_window, x_tt], axis=0)\n    else:\n        x_window = np.concatenate([x_window[1:, :], x_tt], axis=0)\n    \n    if i < window_size - 1:\n        # pass \n        pred_df.action = 0\n    else:\n        # prediction\n        if test_df['weight'].item() > 0:\n            inputs = torch.Tensor(x_window).unsqueeze(0).to(device)\n            outputs = (net1(inputs) + net2(inputs)) / 2\n            pred = (torch.median(outputs, axis=1).values > th).long()\n            pred_df.action = pred.item()\n            #print(pred.item())\n        else:\n            pred_df.action = 0\n        \n    env.predict(pred_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}