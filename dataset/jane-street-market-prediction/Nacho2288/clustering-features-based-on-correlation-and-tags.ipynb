{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Description\n\nDuring the description of the challenge it is mentioned that the dataset may contain **potential redundancy & strong feature correlation**, so it may be interesting to analyse the relationship among the different features in the dataset by clustering them following different approaches.\n\nFirstly I will cluster the features in the train set based on how they are correlated with each other. Then I will use the feature's metadata to cluster them based on their tags.\n\nSince first approach requires to work with numerical data and second with categorical, I will use the following technologies:\n\n* kmeans\n* kmodes\n* PCA\n* MCA"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Required installs\n!pip install prince\n\n# Required imports\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None, 'display.max_rows', None, 'display.max_colwidth', -1)  \n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nfrom sklearn.cluster import KMeans\nfrom kmodes import kmodes\n\nfrom sklearn.decomposition import PCA\nimport prince\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1- Clustering Features based on their Correlation\n\n<u>Steps followed</u>:\n\n* 1.1- Calculating the Correlation across the different features.\n* 1.2- Determining the number of clusters\n* 1.3- Clustering the Correlation matrix using Kmeans\n* 1.4- Visualizing features once clustered with a correaltion matrix heatmap\n* 1.5- Visualizing features with a 2D representation after applying PCA on the kmeans results"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/jane-street-market-prediction/train.csv')\nfeat_df = train_data.iloc[:,8:-1]\nfeat_df.fillna(0, inplace = True)\nfeat_names = feat_df.columns\nfeat_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1- Calculating the Correlation across the different features\n\nI dropped ```feature_0``` since it seems to be a sign flag. Below there is a heat map of the correlation matrix of the other features."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Calculating feature correlation\ncorr_feat_df = feat_df.corr()\ncorr_feat_mtx = corr_feat_df.to_numpy()\nplt.figure()\nplt.imshow(corr_feat_mtx, interpolation='nearest')\nplt.colorbar()\nplt.title('Feature correlation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2- Determining the number of clusters\n\nBy plotting the cluster cost evolution when increasing the number of clusters we can see the best **number of cluster is 5**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Determine optimun number of clusters for kmeans\nwcss = []\nmax_num_clusters = 15\nfor i in range(1, max_num_clusters):\n    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n    kmeans.fit(corr_feat_mtx)\n    wcss.append(kmeans.inertia_)\n    \nplt.plot(range(1, max_num_clusters), wcss)\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3- Clustering the Correlation matrix using Kmeans\n\nThe correlation matrix is clustered using 5 cluster in Kmeans. Below you can see to which cluster each feature has been assign to and the distance of each feature to its cluster centroid"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Using kmeans to cluster the features based on their correlation\nn_clusters_kmeans = 5\nkmeans = KMeans(n_clusters = n_clusters_kmeans, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ncorr_feat_labels = kmeans.fit_predict(corr_feat_mtx)\n\n# Preparing a dataframe to collect some cluster stats\ncorr_feat_clust_df = pd.DataFrame(np.c_[feat_names, corr_feat_labels])\ncorr_feat_clust_df.columns = [\"feature\", \"cluster\"]\ncorr_feat_clust_df['feat_list'] = corr_feat_clust_df.groupby([\"cluster\"]).transform(lambda x: ', '.join(x))\ncorr_feat_clust_df = corr_feat_clust_df.groupby([\"cluster\", \"feat_list\"]).size().reset_index(name = 'feat_count')\ncorr_feat_clust_df\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"corr_node_dist = kmeans.transform(corr_feat_df)\ncorr_clust_dist = np.c_[feat_names, np.round(corr_node_dist.min(axis=1),3), np.round(corr_node_dist.min(axis=1)/np.max(corr_node_dist.min(axis=1)),3), corr_feat_labels]\ncorr_clust_dist_df = pd.DataFrame(corr_clust_dist)\ncorr_clust_dist_df.columns = ['feature', 'dist_corr', 'dist_corr_norm', 'cluster_corr']\ncorr_clust_dist_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4- Visualizing features once clustered with a correaltion matrix heatmap\n\nThen the correlation matrix was reordered so features belonging to same cluster stay together in the heatmap."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Method to group together in correlation matrix features with same labels\ndef clustering_corr_matrix(corrMatrix, clustered_features):\n    npm = corrMatrix.to_numpy()\n    npm_zero = np.zeros(shape=(len(npm), len(npm)))\n    n = 0\n    for i in clustered_features:\n        m = 0\n        for j in clustered_features:\n            npm_zero[n, m] = npm[i-1, j-1] # TODO: remove the -1 if including again feature 0\n            m += 1\n        n += 1\n    return npm_zero\n\n# Preprocessing the correlation matrix before starting the the clustering based on labels\ndef processing_clusterd_corr_matrix(feat_labels, corrMatrix):\n    \n    lst_lab = list(feat_labels)\n    lst_feat = corrMatrix.columns\n\n    lab_feat_map = {lst_feat[i].replace(\"feature_\" , \"\") : lst_lab[i] for i in range(len(lst_lab))} \n    lab_feat_map_sorted = {k: v for k, v in sorted(lab_feat_map.items(), key=lambda item: item[1])}\n    \n    clustered_features = list(map(int,lab_feat_map_sorted.keys()))\n    print(len(clustered_features))\n    return clustering_corr_matrix(corrMatrix, clustered_features)\n\n# Function to plot the clustered \ndef plot_clustered_matrix(clust_mtx, feat_clust_list):\n    plt.figure()\n    \n    fig, ax = plt.subplots(1)\n    \n    im = ax.imshow(clust_mtx, interpolation='nearest')\n    \n    corner = 0\n    for s in feat_clust_list:\n        rect = patches.Rectangle((float(corner),float(corner)), float(s), float(s), angle=0.0, linewidth=2,edgecolor='r',facecolor='none')\n        ax.add_patch(rect)\n        corner += s\n        ax.add_patch(rect)\n    \n    fig.colorbar(im)\n    \n    plt.title('Clusterd Feature by Correlation')\n    plt.show()    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plotting Clustered Correlation Matrix Heat Map\nclust_mtx = processing_clusterd_corr_matrix(corr_feat_labels, corr_feat_df)\nplot_clustered_matrix(clust_mtx, corr_feat_clust_df['feat_count'].to_numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.5- Visualizing features with a 2D representation after applying PCA on the kmeans results\nIt was applied PCA to the feature correlation matrix to reduce the number of dimensions to two. The same was applied to the centroids of the cluster. Finally both, features and centroids were plotted together to see the distribution of the different clusters."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Scatter plot of the different centroids along with observations once clusterd\ndef plotting_scatter(n_clusters, centroids, labels_mtx, title):\n    \n    # Size and alpha values \n    obsv_lw, obsv_alp = 2, .9\n    cntr_lw, cntr_apl = 55, .55\n    \n    # Generating cluster names for the legend and colors\n    target_names = ['k'+str(i) for i in range(n_clusters)]\n    colors = colors = cm.rainbow(np.linspace(0, 1, n_clusters))\n    \n    # Printing the centroids\n    for color, i, target_name in zip(colors, range(n_clusters), target_names):\n        plt.scatter(centroids[i, 0], centroids[i, 1], color = color , alpha = cntr_apl,  s = cntr_lw**2)\n    \n    # Printing observation\n    for color, i, target_name in zip(colors, range(n_clusters), target_names):\n        cur_label = labels_mtx[np.where(labels_mtx[:,2] == i)]\n        plt.scatter(cur_label[:, 0], cur_label[:, 1], color = color, alpha = obsv_alp , lw = obsv_lw, label = target_name)\n    \n    plt.legend(loc='best', shadow=False, scatterpoints=1)\n    plt.title(title)\n    plt.figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Visualizing the dispersion of each cluster in \"2D\"\npca_2 = PCA(n_components=2)\ncorr_pca = pca_2.fit(corr_feat_df).transform(corr_feat_df)\ncorr_centr_pca = pca_2.fit(kmeans.cluster_centers_).transform(kmeans.cluster_centers_)\n\n# Concatenating the pca values with their labels\ncorr_labels_mtx = np.c_[corr_pca, corr_feat_labels]\nplotting_scatter(n_clusters_kmeans, corr_centr_pca, corr_labels_mtx,'PCA of Clustered Features')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2- Clustering Features based on their Tags\n\n<u>Steps followed</u>:\n\n* 2.1- Determining the number of clusters\n* 2.2- Clustering the Tag matrix using Kmodes\n* 2.3- Visualizing features with a 2D representation after applying MCA on the Kmodes results"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tags_feat_df = pd.read_csv('../input/jane-street-market-prediction/features.csv', skiprows=[1])\ntags_feat_df.replace({False: \"False\", True: \"True\"}, inplace = True)\ntags_feat_df['feature'] = tags_feat_df['feature'].apply(lambda x : x.replace('eature_', ''))\ntags_feat_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1- Determining the number of clusters\nBy using the Cao initialization method it is determined that 4 is the best number of clusters. The first 6 tags are not taken into account since they show some sort of cycle in most of the features. "},{"metadata":{"_kg_hide-output":true,"trusted":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"# Looking for best number of clusters\ncost = []\nmax_clust = 15\nfor num_clusters in list(range(1,max_num_clusters)):\n    kmode = kmodes.KModes(n_clusters = num_clusters, init = \"Cao\", n_init = 5, verbose=1)\n    kmode.fit_predict(tags_feat_df.iloc[:,7:])\n    cost.append(kmode.cost_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.plot(range(1, max_num_clusters), cost)\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Cost')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2- Clustering the Tags Matrix using Kmodes\n\nThe Tags Matrix is clustered using 4 cluster in Kmodes. Below you can see to which cluster each feature has been assign to and the distance of each feature to its cluster centroid"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"n_clusters_kmodes = 4\nkmode_cao = kmodes.KModes(n_clusters = n_clusters_kmodes, init = \"Cao\", n_init = 10, verbose=1)\ntags_feat_labels = kmode_cao.fit_predict(tags_feat_df.iloc[:,7:])\n\n# Preparing a dataframe to collect some cluster stats\ntags_feat_clust_df = pd.DataFrame(np.c_[feat_names, tags_feat_labels])\ntags_feat_clust_df.columns = [\"feature\", \"cluster\"]\ntags_feat_clust_df['feat_list'] = tags_feat_clust_df.groupby([\"cluster\"]).transform(lambda x: ', '.join(x))\ntags_feat_clust_df = tags_feat_clust_df.groupby([\"cluster\", \"feat_list\"]).size().reset_index(name = 'feat_count')\ntags_feat_clust_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def nodes_distances(nodes_clustered, centroids):\n    distances = [] \n    for node in nodes_clustered:\n        # Centroid value of the current node\n        centroid = centroids[node[-1]]     \n        distances.append([node[0], node[-1], np.sum(centroid != node[1:-1])])\n    return np.array(distances)\n\n\ntags_nodes_clustered = np.c_[tags_feat_df.to_numpy(), tags_feat_labels]\ntags_nodes_dist = nodes_distances(tags_nodes_clustered, kmode_cao.cluster_centroids_)\n\ntag_clust_dist = np.c_[feat_names, tags_nodes_dist[:,2], tags_feat_labels]\ntag_clust_dist_df = pd.DataFrame(tag_clust_dist)\ntag_clust_dist_df.columns = ['feature', 'dist_tags', 'cluster_tags']\ntag_clust_dist_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3- Visualizing features with a 2D representation after applying MCA on the Kmodes results\n\nIt was applied MCA to the feature Clustered Tag Matrix to reduce the number of dimensions to two. The same was applied to the centroids of the cluster. Finally both, features and centroids were plotted together to see the distribution of the different clusters.\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mca = prince.MCA(n_components = 2)\ncentr_kmodes_df = pd.DataFrame(kmode_cao.cluster_centroids_)\n\ntags_mca = mca.fit(tags_feat_df.iloc[:,7:]).transform(tags_feat_df.iloc[:,7:])\ntags_mca_centr = mca.fit(centr_kmodes_df).transform(centr_kmodes_df)\ntags_labels_mtx = np.c_[tags_mca, tags_feat_labels]\nplotting_scatter(n_clusters_kmodes, tags_mca_centr.to_numpy(), tags_labels_mtx, 'MCA for Clustered Features')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}