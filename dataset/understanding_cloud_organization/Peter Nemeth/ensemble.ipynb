{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir efficientnet\n!cp -r ../input/segmentation-masters/efficientnet-master/efficientnet-master/efficientnet/* ./efficientnet\n\n!mkdir classification_models\n!cp -r ../input/segmentation-masters/classification_models-master/classification_models-master/classification_models/* ./classification_models\n\n!mkdir segmentation_models\n!cp -r ../input/segmentation-masters/segmentation_models-master/segmentation_models-master/segmentation_models/* ./segmentation_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport matplotlib.pyplot as plt\nimport random\nimport math as math\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.utils import Sequence\nfrom keras import Model\nfrom keras.losses import binary_crossentropy\nfrom keras.optimizers import Adam\n\nimport segmentation_models as sm\n\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n \n\ndef rle2mask(mask_rle, shape=(2100, 1400)):\n\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    \n    if mask_rle != None and type(mask_rle) is str: \n        s = mask_rle.split()\n\n        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n        starts -= 1\n        ends = starts + lengths\n\n        for lo, hi in zip(starts, ends):\n            img[lo:hi] = 1\n            \n    return img.reshape(shape).T\n\ndef normalize(images):\n    return images/128-1\n    \ndef denormalize(images):\n    return ((images+1)*128).astype('uint8')\n\ndef load_image(Image):\n    path = TEST_PATH + Image\n    #print(path)\n    \n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if (img.shape != (height, width, 3)):\n        img = cv2.resize(img, (width, height))    \n\n    return img\n\ndef resizeMask(mask, w, h):\n    \n    resmask = np.zeros((h, w, mask.shape[2]))\n    for i in range(mask.shape[2]):\n        resmask[...,i] = cv2.resize(mask[...,i], (w,h))\n        \n    return resmask\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Prediction & Plot Prediction Result"},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_PATH = '../input/understanding_cloud_organization/test_images/'\ntest_df = pd.read_csv('../input/understanding_cloud_organization/sample_submission.csv')\ntest_df['Label'] = test_df['Image_Label'].str.split(\"_\", n = 1, expand = True)[1]\ntest_df['Image'] = test_df['Image_Label'].str.split(\"_\", n = 1, expand = True)[0]\n\ntypes = ['Fish', 'Flower', 'Gravel', 'Sugar']\n\n\n#optimized\npixel_thresholds =    [0.5,   0.5,   0.5,   0.5 ]\nmask_sum_threshold  = [10000, 10000, 10000, 9000]\nmask_threshold=[1000, 1000, 1000, 1000]\n\ndef mask_reduce(mask):\n    \n    reduced_mask = np.zeros(mask.shape,np.float32)\n    \n    for idx in range(mask.shape[2]):\n        label_num, labeled_mask = cv2.connectedComponents(mask[:,:, idx].astype(np.uint8))\n        \n\n        for label in range(1, label_num):\n            single_label_mask = (labeled_mask == label)\n\n            if single_label_mask.sum() > mask_threshold[idx]:\n                reduced_mask[single_label_mask, idx] = 1\n\n    return reduced_mask.astype('uint8')\n\ndef mask_filter(mask):\n    \n    lim = np.sum(mask, axis=(0,1)) < mask_sum_threshold\n    \n    for i in range(len(lim)):\n        if lim[i]: mask[..., i] = 0\n    \n    return mask\n\ndef cleanup(pred):\n\n    return (pred>pixel_thresholds).astype('uint8')\n\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/single-models/'\nmodels = []\n\nmodel1 = sm.FPN('resnet34', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel1.load_weights(path+'Deotte-NormalBCEJaccard-FPN-Resnet34-val_loss-256.h5') # 0.6457\nmodels.append({\"model\": model1, 'weight': 1})\n\nmodel2 = sm.Unet('efficientnetb0', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel2.load_weights(path+'Deotte-NormalJackardBCE-NoPseudo-K0-256-ThisisGood-0.6483.h5') #0.6483\nmodels.append({\"model\": model2, 'weight': 1})\n\nmodel3 = sm.FPN('efficientnetb0', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel3.load_weights(path+'Deotte-NormalBCEJaccard-FPN-val_loss-256.h5') # 0.6388\nmodels.append({\"model\": model3, 'weight': 1})\n                                     \nmodel4 = sm.Unet('efficientnetb0', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel4.load_weights(path+'Deotte-perImageBCEJackard_real-noPseudo--256-0.6410.h5') #0.6410\nmodels.append({\"model\": model4, 'weight': 1})\n\n#------ Pseudo\nmodel5 = sm.FPN('efficientnetb0', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel5.load_weights(path+'PerImageBCEJaccard-FPN-pseudo-256.h5') # 0.6421\nmodels.append({\"model\": model5, 'weight': 1})\n\nmodel6 = sm.Unet('efficientnetb0', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel6.load_weights(path+'NormalBCEJackard-Unet-Effnet-pseudo-256.h5') #0.6481\nmodels.append({\"model\": model6, 'weight': 1})\n\nmodel7 = sm.FPN('resnet34', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel7.load_weights(path+'NormalBCEJaccard-FPN-Resnet34-pseudo-256.h5') # 0.6457\nmodels.append({\"model\": model7, 'weight': 1})\n\nmodel8 = sm.Unet('efficientnetb0', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel8.load_weights(path+'NormalBCEJackard-Unet-Effnet-pseudo-K1-256.h5') #0.6481\nmodels.append({\"model\": model8, 'weight': 1})\n\nmodel9 = sm.Unet('resnet34', encoder_weights=None, classes=4, input_shape=(None, None, 3), activation='sigmoid')\nmodel9.load_weights(path+'NormalBCEJackard-Unet-Resnet34-pseudo-K1-256.h5') #0.6481\nmodels.append({\"model\": model9, 'weight': 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l ../input/single-models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import efficientnet.keras as efn \nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.models import Sequential\n\ndef getClassifier(name):\n    base = efn.EfficientNetB3(weights=None, include_top=False, input_shape=(None, None, 3), pooling='avg')\n    base.trainable=True\n\n    dropout_dense_layer = 0.3 # for B0\n\n    classifier_model = Sequential()\n    classifier_model.add(base)\n    classifier_model.add(Dropout(dropout_dense_layer))\n    classifier_model.add(Dense(4, activation='sigmoid'))\n\n    classifier_model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(),\n        metrics=['accuracy']\n    )\n    classifier_model.summary()\n    classifier_model.load_weights(path+name)\n    \n    return classifier_model\n\nclassifier_models = []\n\n#---- without Pseudo Labels\nclassifier_models.append(getClassifier('classifierB3-256.h5'))\nclassifier_models.append(getClassifier('classifierB3-blackout00-smooth0-256.h5'))\nclassifier_models.append(getClassifier('classifierB3-blackout04-256.h5'))\n\n#---- WITH Pseudo Labels","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"ids = test_df['Image'].unique()\ntest_df.EncodedPixels = ''\n\nheight = 256\nwidth = int(height * 1.5)\n\nclass_thresholds = [0.5, 0.5, 0.5, 0.5]\n\nfor picIdx in range(len(ids)):\n    \n    filename = ids[picIdx]\n    img = load_image(filename)\n    \n    if picIdx % 100 == 0: print(picIdx)\n\n    batch = np.zeros((4, height, width, 3))\n    batch[0] = img\n    batch[1] = img[ :, ::-1, :]\n    batch[2] = img[ ::-1, :, :]\n    batch[3] = img[ ::-1, ::-1, :]\n    batch = normalize(batch)\n    \n    predTTA = np.zeros((batch.shape[0], img.shape[0], img.shape[1], 4))\n    for j in range(len(models)):\n\n        predTTA += models[j]['model'].predict(batch) \n        \n    predTTA /= len(models)\n    \n    # average TTA flips\n    pred = (predTTA[0, :, :, :]+predTTA[1, :, ::-1, :]+predTTA[2, ::-1, :, :]+predTTA[3, ::-1, ::-1, :])/4.0\n\n    if len(classifier_models)>0:\n        \n        classpred = np.zeros((batch.shape[0], 4))\n        for j in range(len(classifier_models)):\n            classpred += classifier_models[j].predict(batch)\n        \n        classpred /= len(classifier_models)\n        classpred = np.mean(classpred, axis=0)\n        \n        # avoid 0 masks\n        if np.sum(classpred>class_thresholds) == 0:\n            classpred[np.argmax(classpred)]=1\n        \n        #remove masks by classifier\n        pred = pred * (classpred>class_thresholds)\n\n  \n    #pred_orig = pred.copy()\n    pred = cleanup(pred) # argmax\n    pred = mask_reduce(pred) #remove small patches\n    pred = mask_filter(pred) #remove masks containing too few pixels\n    pred = resizeMask(pred, 525, 350)    \n    \n    for myType in types:\n        name = filename+\"_\"+myType\n        line = test_df[test_df.Image_Label == name].index[0] \n        \n        i=types.index(myType)\n        maskrle = mask2rle(pred[..., i])        \n        \n        test_df.loc[line, 'EncodedPixels'] = maskrle\n\n#Submission\nsub = test_df[['Image_Label', 'EncodedPixels']]\nsub.to_csv('submission.csv', index=False)\nsub.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['Label'] = sub['Image_Label'].str.split(\"_\", n = 1, expand = True)[1]\nsub['Image'] = sub['Image_Label'].str.split(\"_\", n = 1, expand = True)[0]\n\nprint(sub[(sub.Label == 'Fish')&(sub.EncodedPixels != '')]['Image'].count())\nprint(sub[(sub.Label == 'Sugar')&(sub.EncodedPixels != '')]['Image'].count())\nprint(sub[(sub.Label == 'Gravel')&(sub.EncodedPixels != '')]['Image'].count())\nprint(sub[(sub.Label == 'Flower')&(sub.EncodedPixels != '')]['Image'].count())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}