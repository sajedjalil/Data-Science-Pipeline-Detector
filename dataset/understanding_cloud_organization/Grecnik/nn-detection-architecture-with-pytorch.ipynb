{"cells":[{"metadata":{},"cell_type":"markdown","source":"## NN detection with Pytorch"},{"metadata":{},"cell_type":"markdown","source":"In this kernel I'll try to assemble NN architecture for detection task. Firstly, import necessary libraries:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport io\nimport math\nimport gc\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import data and some preprocessing:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/understanding_cloud_organization/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_new = pd.DataFrame()\ntrain_new['img'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\ntrain_new['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\ntrain_new['EncodedPixels'] = train['EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Histogram with existing labels distibution:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.value_counts(train_new[['label','EncodedPixels']].dropna()['label']).plot('barh');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution, how many figures we can find on one photo:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_new.dropna()[['img','label']].groupby(['img']).count().reset_index()['label'].hist();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize detection area and photos:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def detect(train_new, img):\n    image = plt.imread(\"../input/understanding_cloud_organization/train_images/\" + img)\n    rle_string = train_new[(train_new['img']==img)]['EncodedPixels'].iloc[0]\n    rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n    rle_pairs = np.array(rle_numbers).reshape(-1,2)\n    img = np.zeros(1400*2100, dtype=np.uint8)\n    for index, length in rle_pairs:\n        index -= 1\n        img[index:index+length] = 100\n    img = img.reshape(2100,1400)\n    np_mask = img.T\n    np_mask = np.clip(np_mask, 0, 1)\n    return np_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,25))\ndata_vis = train_new[train_new['label']=='Fish'].dropna()\nfor i in range(1,13):\n    fig.add_subplot(4,3,i)\n    mask = detect(data_vis , data_vis.iloc[i]['img'])\n    image = plt.imread(\"../input/understanding_cloud_organization/train_images/\" + data_vis.iloc[i]['img'])\n    plt.imshow(image);\n    plt.imshow(mask, alpha=0.4);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I want to make Neural Network with 4 outputs:\n1. Probability of an object appearing in the picture <br>\nSubsequent paragraphs if first = 1:\n2. X coordinate of detection mask center \n3. Y coordinate of detection mask center\n4. Height of detection mask\n5. Width of detection mask"},{"metadata":{},"cell_type":"markdown","source":"Create function that return height, width, x_center and y_center"},{"metadata":{"trusted":true},"cell_type":"code","source":"def center_grad(label, np_mask):\n    \"\"\"This function return h, w, x_c, y_c of our mask\"\"\"\n    height = np.where(np_mask[:,:]==1)[0][-1]-np.where(np_mask[:,:]==1)[0][0]\n    width = np.where(np_mask[:,:]==1)[1][-1]-np.where(np_mask[:,:]==1)[1][0]\n    x_cen, y_cen = np.where(np_mask[:,:]==1)[0][0] + height//2, np.where(np_mask[:,:]==1)[1][0] + width//2\n    return label, x_cen, y_cen, height, width","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create special 'Fish' dataset for our network"},{"metadata":{"trusted":true},"cell_type":"code","source":"fish_data = train_new[train_new['label']=='Fish']\nfish_data.set_index(np.arange(fish_data.shape[0]), inplace=True)\nfish_data['Label'] = fish_data['EncodedPixels'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fish_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"height, width = 1400, 2100\ndef masks(train_new, name_image):\n    rle_string = train_new[train_new['img']==name_image]['EncodedPixels'].values[0]\n    if pd.isnull(rle_string):\n        return pd.DataFrame([])\n    else:\n        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n        img = np.zeros(height*width, dtype=np.uint8)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 100\n        img = img.reshape(height,width)\n        img = img.T\n\n        np_mask = img\n        np_mask = np.clip(np_mask, 0, 1)\n        return np_mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create DataLoader for this problem:"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CloudDataset(Dataset):\n    def __init__(self, df: pd.DataFrame = train_new, datatype: str = 'train', img_ids: np.array = None,\n                 transforms = transforms.ToTensor(),\n#                 transforms = transforms.Compose([transforms.Resize((256,256)), transforms.ToTensor()]),\n                preprocessing=None):\n        self.df = df\n        if datatype != 'test':\n            self.data_folder = f\"../input/understanding_cloud_organization/train_images\"\n        else:\n            self.data_folder = f\"{path}/test_images\"\n        self.transforms = transforms\n\n    def __getitem__(self, idx):\n        image_name = self.df['img'][idx]\n        mask = masks(self.df, image_name)\n        image_path = os.path.join(self.data_folder, image_name)\n        \n        image = Image.open(image_path)\n        image = self.transforms(image)\n        \n        if mask.shape != (0,0):\n            label = center_grad(self.df.iloc[idx]['Label'],mask)\n            if label[0] == 1:\n                label = (label[0], label[1]/height, label[2]/width,\n                            math.log(abs(label[3]+0.0001)), math.log(abs(label[4]+0.0001)) )\n        else: \n            label = (0,0,0,0,0)\n        return image, label\n    \n    def __len__(self):\n        return self.df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Classes distribution in \"Fish dataset\""},{"metadata":{"trusted":true},"cell_type":"code","source":"fish_data[:100]['Label'].hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = CloudDataset(df=fish_data[:2000], datatype='train')\ntrain_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n#         self.fc1 = nn.Linear(1*5*350*525, 5)\n        self.fc1 = nn.Linear(543402,5)\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5)\n        self.conv2 = nn.Conv2d(in_channels=5, out_channels=3, kernel_size=5)\n        \n    def forward(self,x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1)\n        x = self.fc1(x)\n        x = [F.sigmoid(x[0]),F.sigmoid(x[1]),F.sigmoid(x[2]),x[3],x[4]]\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create the main function for learning with pytorch. I'll learn only 10 epochs to save time."},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = []\n\n# define model\nmodel = Net()\nmodel = model.cuda()\ncrit_mse = nn.MSELoss()\ncrit_bce = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay=1e-5)\n\nfor epoch in range(1, 11):\n    print('epoch = ', epoch)\n    for batch_idx, (data, label) in enumerate(train_loader):\n            # get output\n            data = data.cuda()\n            for i in range(len(label)):\n                label[i] = label[i].cuda()\n            out = model(data)\n            \n            # transform output to our system\n            output = out\n            \n            # define complex LOSS function\n            if label[0].item() == 1:\n                loss = crit_bce(output[0],torch.Tensor([label[0].item()]).cuda() ) + \\\n                    1*(crit_bce(output[1],torch.Tensor([label[1].item()]).cuda() ) +  \n                       crit_bce(output[2],torch.Tensor([label[2].item()]).cuda() ) + \\\n                       crit_mse(output[3],torch.Tensor([label[3].item()]).cuda() ) + \\\n                       crit_mse(output[4],torch.Tensor([label[4].item()]).cuda() ) )\n            else:\n                loss = crit_bce(output[0],torch.Tensor([label[0].item()]).cuda() )\n                \n            if batch_idx % 500 == 0:\n                print('Loss :{:.4f} Epoch - {}/{}'.format(loss.item(), epoch, 10))\n            losses.append(loss)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            torch.cuda.empty_cache()\n    torch.cuda.empty_cache()\n    gc.collect()\n    del data\n    del label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loss plot in train dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(np.arange(len(losses)), losses);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### So, compare model prediction with target mask:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = detect(data_vis , data_vis.iloc[0]['img'])\nimage = plt.imread(\"../input/understanding_cloud_organization/train_images/\" + data_vis.iloc[0]['img'])\nplt.imshow(image);\nplt.imshow(mask, alpha=0.4);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = center_grad(1, mask)\nprint(ss[0], ss[1]/height, ss[2]/width, math.log(ss[3]), math.log(ss[4]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = torch.Tensor(image.reshape(1,3,1400,2100)).cuda()\nmodel(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With same approach we can detect another categories. <br>\nTo be continued..."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}