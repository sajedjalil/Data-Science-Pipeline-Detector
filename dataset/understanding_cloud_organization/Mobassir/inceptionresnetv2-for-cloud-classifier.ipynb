{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U keras-applications","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras_applications\nimport keras\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras_applications.resnext import ResNeXt101","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this kernel was forked from here : https://www.kaggle.com/samusram/cloud-classifier-for-post-processing?scriptVersionId=20265194\n\nhighest  accuracy of that kernel was 0.629 which is same as this one : https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools?scriptVersionId=20202006 of Andrew Lukyanenko (  @artgor) \nthanks a lot to them for their public kernels,i recommend everyone playing with those kernels because those kernels has got solid baseline. my special thanks goes to Andrew Lukyanenko (  @artgor) ,i learnt plenty from his works \n\nHere in this kernel i got 0.63 after trying InceptionResNetV2 so i decided to share it with you guys,please leave your precious comment below,this is just a starting,i will write my own notebook when time permits but i would like to spend more time on @artgor's kernel to observe if i can improve his work little bit,i recommend you the same.\n\nwhats new here?\n1. InceptionResNetV2 instead of densenet121\n2. image height and width 229x229 instead of 224\n3. version 1 has got 0.63 public lb accuracy ,so please upvote this notebok and obviously main author's notebook if you find these helpful\n4.  in version 3 i will try to leave everything as it was before but 5 epochs for initial tuning and 10 epochs for fine tuning"},{"metadata":{},"cell_type":"markdown","source":"**Version 6**\n- replacing this notebook's submission.csv with my trained models submission.csv file(got 0.658 public lb score) which comes from version 13 of this notebook : https://www.kaggle.com/mobassir/keras-efficientnetb2-for-classifying-cloud\n\n- using 0.90 as both precision and recall threshold\n- Rotate(limit=20)\n"},{"metadata":{},"cell_type":"markdown","source":"# version 7\n- using 0.94 as both precision and recall threshold\n- 17% for test set\n- lower learning rate\n- train for less epoches"},{"metadata":{},"cell_type":"markdown","source":"<font color=\"red\">i hope this kernel is helpful and some upvotes are highly appreciated!</font>"},{"metadata":{},"cell_type":"markdown","source":"# version 9\n\ntrying resnext50 model with image size 224x224"},{"metadata":{},"cell_type":"markdown","source":"# version 10(last version)\n\ntrying resnext101 model with image size 224x224"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Intro\nIn this notebook I'd create a classifier to distinguish types of cloud formations. Using this classifier I'd check if it improves currently the best LB score from the great [public notebook by Andrew](https://www.kaggle.com/artgor/segmentation-in-pytorch-using-convenient-tools?scriptVersionId=20202006). "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"# Plan\n1. [Libraries](#Libraries)\n2. [Data Generators](#Data-Generators)\n  * [One-hot encoding classes](#One-hot-encoding-classes)\n  * [Stratified split into train/val](#Stratified-split-into-train/val)\n  * [Generator class](#Generator-class)\n3. [PR-AUC-based Callback](#PR-AUC-based-Callback)\n4. [Classifier](#Classifier)\n  * [Defining a model](#Defining-a-model)\n  * [Initial tuning of the added fully-connected layer](#Initial-tuning-of-the-added-fully-connected-layer)\n  * [Fine-tuning the whole model](#Fine-tuning-the-whole-model)\n  * [Visualizing train and val PR AUC](#Visualizing-train-and-val-PR-AUC)\n5. [Selecting postprocessing thresholds](#Selecting-postprocessing-thresholds)\n6. [Post-processing Andrew's submission](#Post-processing-Andrew's-submission)\n7. [Future work](#Future-work)"},{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import os, glob\nimport random\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport multiprocessing\nfrom copy import deepcopy\nfrom sklearn.metrics import precision_recall_curve, auc\nimport tensorflow.keras as keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import Sequence\nfrom albumentations import Compose, VerticalFlip, HorizontalFlip, Rotate, GridDistortion,CenterCrop\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\nfrom tqdm import tqdm_notebook as tqdm\nfrom numpy.random import seed\nseed(10)\nfrom tensorflow import set_random_seed\nset_random_seed(10)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs_folder = '../input/understanding_cloud_organization/test_images/'\ntrain_imgs_folder = '../input/understanding_cloud_organization/train_images/'\nnum_cores = multiprocessing.cpu_count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One-hot encoding classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/understanding_cloud_organization/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[~train_df['EncodedPixels'].isnull()]\ntrain_df['Image'] = train_df['Image_Label'].map(lambda x: x.split('_')[0])\ntrain_df['Class'] = train_df['Image_Label'].map(lambda x: x.split('_')[1])\nclasses = train_df['Class'].unique()\ntrain_df = train_df.groupby('Image')['Class'].agg(set).reset_index()\nfor class_name in classes:\n    train_df[class_name] = train_df['Class'].map(lambda x: 1 if class_name in x else 0)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dictionary for fast access to ohe vectors\nimg_2_ohe_vector = {img:vec for img, vec in zip(train_df['Image'], train_df.iloc[:, 2:].values)}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stratified split into train/val"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_imgs, val_imgs = train_test_split(train_df['Image'].values, \n                                        test_size=0.1, \n                                        stratify=train_df['Class'].map(lambda x: str(sorted(list(x)))), # sorting present classes in lexicographical order, just to be sure\n                                        random_state=43)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generator class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenenerator(Sequence):\n    def __init__(self, images_list=None, folder_imgs=train_imgs_folder, \n                 batch_size=32, shuffle=True, augmentation=None,\n                 resized_height=224, resized_width=224, num_channels=3):\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.augmentation = augmentation\n        if images_list is None:\n            self.images_list = os.listdir(folder_imgs)\n        else:\n            self.images_list = deepcopy(images_list)\n        self.folder_imgs = folder_imgs\n        self.len = len(self.images_list) // self.batch_size\n        self.resized_height = resized_height\n        self.resized_width = resized_width\n        self.num_channels = num_channels\n        self.num_classes = 4\n        self.is_test = not 'train' in folder_imgs\n        if not shuffle and not self.is_test:\n            self.labels = [img_2_ohe_vector[img] for img in self.images_list[:self.len*self.batch_size]]\n\n    def __len__(self):\n        return self.len\n    \n    def on_epoch_start(self):\n        if self.shuffle:\n            random.shuffle(self.images_list)\n\n    def __getitem__(self, idx):\n        current_batch = self.images_list[idx * self.batch_size: (idx + 1) * self.batch_size]\n        X = np.empty((self.batch_size, self.resized_height, self.resized_width, self.num_channels))\n        y = np.empty((self.batch_size, self.num_classes))\n\n        for i, image_name in enumerate(current_batch):\n            path = os.path.join(self.folder_imgs, image_name)\n            img = cv2.resize(cv2.imread(path), (self.resized_height, self.resized_width)).astype(np.float32)\n            if not self.augmentation is None:\n                augmented = self.augmentation(image=img)\n                img = augmented['image']\n            X[i, :, :, :] = img/255.0\n            if not self.is_test:\n                y[i, :] = img_2_ohe_vector[image_name]\n        return X, y\n\n    def get_labels(self):\n        if self.shuffle:\n            images_current = self.images_list[:self.len*self.batch_size]\n            labels = [img_2_ohe_vector[img] for img in images_current]\n        else:\n            labels = self.labels\n        return np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"albumentations_train = Compose([\n    VerticalFlip(), HorizontalFlip(), Rotate(limit=20), GridDistortion()\n], p=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generator instances"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_generator_train = DataGenenerator(train_imgs, augmentation=albumentations_train)\ndata_generator_train_eval = DataGenenerator(train_imgs, shuffle=False)\ndata_generator_val = DataGenenerator(val_imgs, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PR-AUC-based Callback"},{"metadata":{},"cell_type":"markdown","source":"The callback would be used:\n1. to estimate AUC under precision recall curve for each class,\n2. to early stop after 5 epochs of no improvement in mean PR AUC,\n3. save a model with the best PR AUC in validation,\n4. to reduce learning rate on PR AUC plateau."},{"metadata":{"trusted":true},"cell_type":"code","source":"class PrAucCallback(Callback):\n    def __init__(self, data_generator, num_workers=num_cores, \n                 early_stopping_patience=3, \n                 plateau_patience=3, reduction_rate=0.5,\n                 stage='train', checkpoints_path='checkpoints/'):\n        super(Callback, self).__init__()\n        self.data_generator = data_generator\n        self.num_workers = num_workers\n        self.class_names = ['Fish', 'Flower', 'Sugar', 'Gravel']\n        self.history = [[] for _ in range(len(self.class_names) + 1)] # to store per each class and also mean PR AUC\n        self.early_stopping_patience = early_stopping_patience\n        self.plateau_patience = plateau_patience\n        self.reduction_rate = reduction_rate\n        self.stage = stage\n        self.best_pr_auc = -float('inf')\n        if not os.path.exists(checkpoints_path):\n            os.makedirs(checkpoints_path)\n        self.checkpoints_path = checkpoints_path\n        \n    def compute_pr_auc(self, y_true, y_pred):\n        pr_auc_mean = 0\n        print(f\"\\n{'#'*30}\\n\")\n        for class_i in range(len(self.class_names)):\n            precision, recall, _ = precision_recall_curve(y_true[:, class_i], y_pred[:, class_i])\n            pr_auc = auc(recall, precision)\n            pr_auc_mean += pr_auc/len(self.class_names)\n            print(f\"PR AUC {self.class_names[class_i]}, {self.stage}: {pr_auc:.3f}\\n\")\n            self.history[class_i].append(pr_auc)        \n        print(f\"\\n{'#'*20}\\n PR AUC mean, {self.stage}: {pr_auc_mean:.3f}\\n{'#'*20}\\n\")\n        self.history[-1].append(pr_auc_mean)\n        return pr_auc_mean\n              \n    def is_patience_lost(self, patience):\n        if len(self.history[-1]) > patience:\n            best_performance = max(self.history[-1][-(patience + 1):-1])\n            return best_performance == self.history[-1][-(patience + 1)] and best_performance >= self.history[-1][-1]    \n              \n    def early_stopping_check(self, pr_auc_mean):\n        if self.is_patience_lost(self.early_stopping_patience):\n            self.model.stop_training = True    \n              \n    def model_checkpoint(self, pr_auc_mean, epoch):\n        if pr_auc_mean > self.best_pr_auc:\n            # remove previous checkpoints to save space\n            for checkpoint in glob.glob(os.path.join(self.checkpoints_path, 'classifier_epoch_*')):\n                os.remove(checkpoint)\n        self.best_pr_auc = pr_auc_mean\n        self.model.save(os.path.join(self.checkpoints_path, f'classifier_epoch_{epoch}_val_pr_auc_{pr_auc_mean}.h5'))              \n        print(f\"\\n{'#'*20}\\nSaved new checkpoint\\n{'#'*20}\\n\")\n              \n    def reduce_lr_on_plateau(self):\n        if self.is_patience_lost(self.plateau_patience):\n            new_lr = float(keras.backend.get_value(self.model.optimizer.lr)) * self.reduction_rate\n            keras.backend.set_value(self.model.optimizer.lr, new_lr)\n            print(f\"\\n{'#'*20}\\nReduced learning rate to {new_lr}.\\n{'#'*20}\\n\")\n        \n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict_generator(self.data_generator, workers=self.num_workers)\n        y_true = self.data_generator.get_labels()\n        # estimate AUC under precision recall curve for each class\n        pr_auc_mean = self.compute_pr_auc(y_true, y_pred)\n              \n        if self.stage == 'val':\n            # early stop after early_stopping_patience=4 epochs of no improvement in mean PR AUC\n            self.early_stopping_check(pr_auc_mean)\n\n            # save a model with the best PR AUC in validation\n            self.model_checkpoint(pr_auc_mean, epoch)\n\n            # reduce learning rate on PR AUC plateau\n            self.reduce_lr_on_plateau()            \n        \n    def get_pr_auc_history(self):\n        return self.history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Callback instances"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_metric_callback = PrAucCallback(data_generator_train_eval)\nval_callback = PrAucCallback(data_generator_val, stage='val')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier"},{"metadata":{},"cell_type":"markdown","source":"## Defining a model"},{"metadata":{},"cell_type":"markdown","source":"> Let's us InceptionResNetV2 pretrained on ImageNet."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\ndef get_model():\n    #base_model = InceptionResNetV2(weights='imagenet', include_top=False, pooling='avg')\n    base_model = model = ResNeXt101(..., backend=tf.keras.backend, layers=tf.keras.layers, weights = 'imagenet', models=tf.keras.models, utils=tf.keras.utils)\n    x = base_model.output\n    y_pred = Dense(4, activation='sigmoid')(x)\n    return Model(inputs=base_model.input, outputs=y_pred)\n\nmodel = get_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Initial tuning of the added fully-connected layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"for base_layer in model.layers[:-1]:\n    base_layer.trainable = False\n    \nmodel.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy')\nhistory_0 = model.fit_generator(generator=data_generator_train,\n                              validation_data=data_generator_val,\n                              epochs=15,\n                              callbacks=[train_metric_callback, val_callback],\n                              workers=num_cores,\n                              verbose=1\n                             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine-tuning the whole model"},{"metadata":{},"cell_type":"markdown","source":"After unfreezing all the layers I set a less aggressive initial learning rate and train until early stopping (or 100 epochs max)."},{"metadata":{"trusted":true},"cell_type":"code","source":"for base_layer in model.layers[:-1]:\n    base_layer.trainable = True\n    \nmodel.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy')\nhistory_1 = model.fit_generator(generator=data_generator_train,\n                              validation_data=data_generator_val,\n                              epochs=20,\n                              callbacks=[train_metric_callback, val_callback],\n                              workers=num_cores,\n                              verbose=1,\n                              initial_epoch=1\n                             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing train and val PR AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_with_dots(ax, np_array):\n    ax.scatter(list(range(1, len(np_array) + 1)), np_array, s=50)\n    ax.plot(list(range(1, len(np_array) + 1)), np_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr_auc_history_train = train_metric_callback.get_pr_auc_history()\npr_auc_history_val = val_callback.get_pr_auc_history()\n\nplt.figure(figsize=(10, 7))\nplot_with_dots(plt, pr_auc_history_train[-1])\nplot_with_dots(plt, pr_auc_history_val[-1])\n\nplt.xlabel('Epoch', fontsize=15)\nplt.ylabel('Mean PR AUC', fontsize=15)\nplt.legend(['Train', 'Val'])\nplt.title('Training and Validation PR AUC', fontsize=20)\nplt.savefig('pr_auc_hist.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nplot_with_dots(plt, history_0.history['loss']+history_1.history['loss'])\nplot_with_dots(plt, history_0.history['val_loss']+history_1.history['val_loss'])\n\nplt.xlabel('Epoch', fontsize=15)\nplt.ylabel('Binary Crossentropy', fontsize=15)\nplt.legend(['Train', 'Val'])\nplt.title('Training and Validation Loss', fontsize=20)\nplt.savefig('loss_hist.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I left the model to train longer on my local GPU. I then upload the best model and plots from the model training."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model('../input/clouds-classifier-files/classifier_epoch_45_val_pr_auc_0.8344173287108075.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/clouds-classifier-files/loss_hist.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/clouds-classifier-files/pr_auc_hist.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As a side note, it was interesting to see an overfitting pattern when not using augmentation (learning rate was higher). "},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/clouds-classifier-files/training_hist_no_aug.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Selecting postprocessing thresholds"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = ['Fish', 'Flower', 'Sugar', 'Gravel']\ndef get_threshold_for_recall(y_true, y_pred, class_i, recall_threshold=0.94, precision_threshold=0.95, plot=False):\n    precision, recall, thresholds = precision_recall_curve(y_true[:, class_i], y_pred[:, class_i])\n    i = len(thresholds) - 1\n    best_recall_threshold = None\n    while best_recall_threshold is None:\n        next_threshold = thresholds[i]\n        next_recall = recall[i]\n        if next_recall >= recall_threshold:\n            best_recall_threshold = next_threshold\n        i -= 1\n        \n    # consice, even though unnecessary passing through all the values\n    best_precision_threshold = [thres for prec, thres in zip(precision, thresholds) if prec >= precision_threshold][0]\n    \n    if plot:\n        plt.figure(figsize=(10, 7))\n        plt.step(recall, precision, color='r', alpha=0.3, where='post')\n        plt.fill_between(recall, precision, alpha=0.3, color='r')\n        plt.axhline(y=precision[i + 1])\n        recall_for_prec_thres = [rec for rec, thres in zip(recall, thresholds) \n                                 if thres == best_precision_threshold][0]\n        plt.axvline(x=recall_for_prec_thres, color='g')\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.ylim([0.0, 1.05])\n        plt.xlim([0.0, 1.0])\n        plt.legend(['PR curve', \n                    f'Precision {precision[i + 1]: .2f} corresponding to selected recall threshold',\n                    f'Recall {recall_for_prec_thres: .2f} corresponding to selected precision threshold'])\n        plt.title(f'Precision-Recall curve for Class {class_names[class_i]}')\n    return best_recall_threshold, best_precision_threshold\n\ny_pred = model.predict_generator(data_generator_val, workers=num_cores)\ny_true = data_generator_val.get_labels()\nrecall_thresholds = dict()\nprecision_thresholds = dict()\nfor i, class_name in tqdm(enumerate(class_names)):\n    recall_thresholds[class_name], precision_thresholds[class_name] = get_threshold_for_recall(y_true, y_pred, i, plot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Post-processing Andrew's submission"},{"metadata":{},"cell_type":"markdown","source":"Predicting cloud classes for test."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_generator_test = DataGenenerator(folder_imgs=test_imgs_folder, shuffle=False)\ny_pred_test = model.predict_generator(data_generator_test, workers=num_cores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estimating set of images without masks."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_labels_empty = set()\nfor i, (img, predictions) in enumerate(zip(os.listdir(test_imgs_folder), y_pred_test)):\n    for class_i, class_name in enumerate(class_names):\n        if predictions[class_i] < recall_thresholds[class_name]:\n            image_labels_empty.add(f'{img}_{class_name}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_labels_full = set()\nfor i, (img, predictions) in enumerate(zip(os.listdir(test_imgs_folder), y_pred_test)):\n    for class_i, class_name in enumerate(class_names):\n        if predictions[class_i] > precision_thresholds[class_name]:\n            images_labels_full.add(f'{img}_{class_name}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My predictions from this kernel : https://www.kaggle.com/mobassir/keras-efficientnetb2-for-classifying-cloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/cloudefficientnetb2/submission.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_labels_andrew_nonempty = submission.loc[~submission['EncodedPixels'].isnull(), 'Image_Label'].values\nimage_labels_andrew_empty = submission.loc[submission['EncodedPixels'].isnull(), 'Image_Label'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" I remove the min_size parameter from the post_process function, so that more mask are generated in the submission. I'd add additional masks for the Image_Label pairs predicted by the classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"images_to_refill = images_labels_full.intersection(set(image_labels_andrew_empty))\nsubmission_no_minsize = pd.read_csv('../input/clouds-classifier-files/submission_no_minsize.csv')\nmasks_no_minsize_refillers = submission_no_minsize.loc[submission_no_minsize['Image_Label'].isin(images_to_refill) &\n                                                       ~submission_no_minsize['EncodedPixels'].isnull()]\nprint(f'{len(masks_no_minsize_refillers)} masks would be added.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'{len(image_labels_empty.intersection(set(image_labels_andrew_nonempty)))} masks would be removed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing masks\nsubmission.loc[submission['Image_Label'].isin(image_labels_empty), 'EncodedPixels'] = np.nan\n# adding masks\nimg_labels_to_refill = set(masks_no_minsize_refillers['Image_Label'].values)\nsubmission = submission[~submission['Image_Label'].isin(img_labels_to_refill)]\nsubmission = pd.concat((submission, masks_no_minsize_refillers))\nsubmission.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Future work\n1. estimate distribution of classes in test set using the classifier. Then, if necessary and doable, modify val set accordingly,\n2. use the classifier with explainability technique [Gradient-weighted Class Activation Mapping](http://gradcam.cloudcv.org/) to generate a baseline,\n3. improve the classifier,\n4. use the classifier as backbone for UNet-like solution."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}