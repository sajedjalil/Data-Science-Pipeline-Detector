{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1, Introduction: “Expected Landing Position” of a Punted Football and Its Usage in Modern NFL Game\n\nNFL has been one of the most popular sports in the United States and in the world. The sport, football, mainly consists of three play types: offense, defence and special team plays. For a long time, offense and defence are overwhelmingly emphasized on the field, since these two play types directly enable teams to evaluate their performances and achieve victories. Nevertheless special team plays, especially punting, is often overlooked due to the fact that many people believe that it is only the complementary part of the game. Does punting indeed affect the game and the players on the pitch? \n\nIn this notebook, I am going to introduce a new metric called \"Expected Landing Position\" for a punted football. The function of this metric is to predict the approximate landing position on x and y axis of a punted football based on several selected features that can be extracted from the datasets provided. In order to calculate the \"Expected Landing Position\", I am going to build a machine learning model. This model enables NFL coaching staff and returners to input a set of features and it will return the displacement of the football on both x and y axis as the result. With this new metric and machine learning model, NFL teams and returners are able to know the rough position of a landed football, so that they could perform better at returning and achieve better returning yardage, which could be vital to a game.","metadata":{}},{"cell_type":"markdown","source":"## 2, Dataframe Construction\nThe code below only shows data preparation and cleaning processes of the 2020 tracking data as an example. I am going to process all three dataframes one by one in order to use momory in a more efficient way. The handling process of the 2019 and 2018 tracking data will be performed in an analogous way and in a hidden cell of code.\n\nFirst of all, we are going to read the tracking data and figure out which information are relevant to calculating the displacement of a punted football.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport os\n\ndf = pd.read_csv('../input/nfl-big-data-bowl-2022/tracking2020.csv')\ndf = df.loc[df['team'] == 'football']\ndf = df.drop(columns = ['o', 'dir', 'nflId', 'jerseyNumber', 'position'])\npd.DataFrame(df.groupby(['event']).size().reset_index(name = \"Count\"))","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-11-20T22:08:35.762033Z","iopub.execute_input":"2021-11-20T22:08:35.762418Z","iopub.status.idle":"2021-11-20T22:09:16.373522Z","shell.execute_reply.started":"2021-11-20T22:08:35.762314Z","shell.execute_reply":"2021-11-20T22:09:16.372691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3, Data Cleaning and Target Dataset Construction\n\nThe metric \"Expected Landing Position\" includes two values: dx (displacement of football on the x axis) and dy (displacement of football on the y axis). In order to calculate the \"Expected Landing Position\", a target dataset consisted of both these values needs to be constructed. In this step, we are going to calculate the dx and dy of each punt play that is going to be trained.\n\nFrom this table, we can see that the dataset includes several events that are related to punting. These include \"punt\", \"punt_blocked\", \"punt_downed\", \"punt_fake\", \"punt_land\", \"punt_muffed\", \"punt_play\" and \"punt_received\". Here, we categorize all these events into three categories: \"punt\" is the event of punting itself, \"punt_land\" and \"punt_received\" are defined as successful punts while \"punt_blocked\", \"punt_downed\", \"punt_fake\", \"punt_muffed\" and \"punt_play\" are punts that are incomplete and therefore regarded as unsuccessful punts. Since in this model, we are going to estimate the punt distance and the landing position of a punted football, we are going to omit unsuccessful punts and only select successful punts as features.","metadata":{}},{"cell_type":"code","source":"df = df.loc[(df['event'] == 'punt') | (df['event'] == 'punt_land') | (df['event'] == 'punt_received')]\nsummarized_df = pd.DataFrame(df.groupby(['gameId', 'playId']).size().reset_index(name = \"Count\"))\nsummarized_df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T22:09:16.375001Z","iopub.execute_input":"2021-11-20T22:09:16.375233Z","iopub.status.idle":"2021-11-20T22:09:16.644686Z","shell.execute_reply.started":"2021-11-20T22:09:16.375197Z","shell.execute_reply":"2021-11-20T22:09:16.643872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each punt consists of two events: punt and the result (punt_received or punt_land). If each single play does not include 2 events, we can conclude that this specific punt is unsuccessful and will drop these rows. For the rest of the dataset, we are going to calculate the distance of the punted football for both axes, as well as include a punt position (start_x, start_y). The result will be stored in a new dataframe called \"xy_df\". We will also include play ID, game ID and play direction in this dataset, which could be later used to join with other datasets and to analyze further features.\n\nIn addition, we are going to drop some extra rows here that are imappropriate. Since the size of a football field is 120 yards time 53.3 yards, any starting position that contains an x that is larger than 120 or smaller than 0 and a y that is larger than 53.3 is not correct and therefore invalid. Moreover, since kickers are athletes and are likely to perform inconsistently, outliers definitely exist in this dataset and might affect the performance of the model in a negative way. We are going to use a boxplot to investigate them and drop them.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\n\n# Dropping unsuccessful punts\nfor i in summarized_df.iterrows():\n    if i[1]['Count'] != 2:\n        delete_row = df.loc[(df['gameId'] == i[1]['gameId']) & (df['playId'] == i[1]['playId'])]\n        df = df.drop(delete_row.index)\n        \n        \n        \n# Constructing target data\nxy_dataset = {}\n\nfor i in range(int(len(df) / 2)):\n    if df.iloc[i * 2]['playDirection'] == 'left':\n        x = - (df.iloc[i * 2 + 1]['x'] - df.iloc[i * 2]['x'])\n        y = df.iloc[i * 2 + 1]['y'] - df.iloc[i * 2]['y']\n        start_x = df.iloc[i * 2]['x']\n        start_y = df.iloc[i * 2]['y']\n    else:\n        x = df.iloc[i * 2 + 1]['x'] - df.iloc[i * 2]['x']\n        y = - (df.iloc[i * 2 + 1]['y'] - df.iloc[i * 2]['y'])    \n        start_x = 120 - df.iloc[i * 2]['x']\n        start_y = 53.3 - df.iloc[i * 2]['y']\n    xy_dataset[i] = [x, y, df.iloc[i * 2]['gameId'], df.iloc[i * 2]['playId'], start_x, start_y, df.iloc[i * 2]['playDirection']]\n    \nxy_df = pd.DataFrame(data=xy_dataset).T\nxy_df.columns = ['dx', 'dy', 'gameId', 'playId', 'start_x', 'start_y', 'playDirection']\n\nconvert_cols = ['start_x', 'start_y', 'dx', 'dy']\nfor i in convert_cols:\n    xy_df[i] = xy_df[i].astype(float, errors = 'raise')\n    \n\n\n# Dropping out of range data\nout_of_range_data = []\n\nfor i in xy_df.iterrows():\n    if i[1]['start_y'] > 53.3:\n        out_of_range_data.append(i[0])\n    if i[1]['start_x'] > 120 or i[1]['start_x'] < 0:\n        out_of_range_data.append(i[0])\n\nfor i in out_of_range_data:\n    xy_df = xy_df.drop(i)\n\nxy_df.reset_index(drop=True, inplace=True)\n\n\n\n# Data visualization and handling outliers\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\naxes[0].boxplot(xy_df['dx']);\naxes[0].set_title('Outliers (dx)');\naxes[1].boxplot(xy_df['dy']);\naxes[1].set_title('Outliers (dy)');\n\ndata = xy_df['dx']\n\nmedian = np.median(data)\nupper_quartile = np.percentile(data, 75)\nlower_quartile = np.percentile(data, 25)\n\niqr = upper_quartile - lower_quartile\nupper_whisker = data[data<=upper_quartile+1.5*iqr].max()\nlower_whisker = data[data>=lower_quartile-1.5*iqr].min()\n\nfor i in xy_df.iterrows():\n    if i[1]['dx'] < lower_whisker or i[1]['dx'] > upper_whisker:\n        xy_df = xy_df.drop(i[0])\n        \nxy_df.reset_index(drop=True, inplace=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T22:09:16.646164Z","iopub.execute_input":"2021-11-20T22:09:16.64704Z","iopub.status.idle":"2021-11-20T22:09:19.751737Z","shell.execute_reply.started":"2021-11-20T22:09:16.64699Z","shell.execute_reply":"2021-11-20T22:09:19.750947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4, Working with Features\n\nNow we are going to build the feature dataset which could help train the model and predict the \"Expected Landing Position\". After reading the dataset description, I have decided to include the following features:\n\nkickType (PFFScoutingData.csv) <br />\nsnapTime (PFFScoutingData.csv) <br />\noperationTime (PFFScoutingData.csv) <br />\nhangTime (PFFScoutingData.csv) <br />\nkickDirectionActual (PFFScoutingData.csv) <br />\npuntRushers (PFFScoutingData.csv) <br />\npreSnapHomeScore (plays.csv) <br />\npreSnapVisitorScore (plays.csv) <br />\nheight (players.csv)<br />\nweight (players.csv)<br />\n\nAmong all these selected features, \"puntRushers\" will be used as a numerical data: the number of punt rushers in each occasion will be counted. \"preSnapHomeScore\" and \"preSnapVisitorScore\" will be used to determine whether the punting team is trailing (or tie) or leading while punting the football. Features can be changed or dropped any time depending on the correlation between the features and the target.\n\nAt the same time, we are going to clean the newly added data. We will clear all the columns containing null and investigate the correlation of features and targets using scatter plots. From plotting the graphs, snapTime and operationTime are the two features that have no correlation with the target data (Scatter plots of these two features are provided below). Therefore we will drop these two features. Other features will be used to train the model. ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nimport warnings\nfrom pandas.core.common import SettingWithCopyWarning\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n\n\n# Reading data\npff = pd.read_csv('../input/nfl-big-data-bowl-2022/PFFScoutingData.csv')\nplays_df = pd.read_csv('../input/nfl-big-data-bowl-2022/plays.csv')\nplayers_df = pd.read_csv('../input/nfl-big-data-bowl-2022/players.csv')\n\n\n\n# Merging features from PFF Scouting Data\npff_feature = pff[['gameId', 'playId', 'kickType', 'snapDetail', 'snapTime', 'operationTime', 'hangTime', 'kickDirectionActual', 'puntRushers']]\nxy_df = pd.merge(xy_df, pff_feature, on=['gameId', 'playId'], how='left')\n\n# Merging features from Plays\nkicker_feature = plays_df[['gameId', 'playId', 'kickerId', 'preSnapHomeScore', 'preSnapVisitorScore']]\nxy_df = pd.merge(xy_df, kicker_feature, on=['gameId', 'playId'], how='left')\n\n# Merging features from Players\nplayers_feature = players_df[['height', 'weight', 'nflId']]\nxy_df = pd.merge(xy_df, players_feature, left_on = 'kickerId', right_on = 'nflId', how='left')\n\n#newxydf = xy_df.copy()\n#xy_df = newxydf\n\n# Determining leading or trailing (tie)\nxy_df['leading'] = 0\nfor i in xy_df.iterrows():\n    if i[1]['playDirection'] == 'right':\n        if i[1]['preSnapHomeScore'] > i[1]['preSnapVisitorScore']:\n            xy_df['leading'][i[0]] = 1\n    else:\n        if i[1]['preSnapHomeScore'] < i[1]['preSnapVisitorScore']:\n            xy_df['leading'][i[0]] = 1\n            \n# Counting punt rushers\nxy_df['numPuntRushers'] = 0 # default: 0\nfor i in xy_df.iterrows():\n    if pd.isnull(i[1]['puntRushers']) == False:\n        xy_df['numPuntRushers'][i[0]] = xy_df['puntRushers'][i[0]].count(';') + 1\n        \n# Converting height to decimal form\nxy_df = xy_df.rename(columns={'height': 'height_str'})\nxy_df['height'] = 0.1\nfor i in xy_df.iterrows():\n    xy_df['height'][i[0]] = float(i[1]['height_str'][0]) + float(i[1]['height_str'][2:]) / 12\n\n# Dropping excessive columns\nxy_df = xy_df.drop(columns=['kickerId', 'nflId', 'gameId', 'playId', 'playDirection', 'preSnapHomeScore', 'preSnapVisitorScore', 'puntRushers', 'height_str'])\n\n\n\n# Dropping rows that contain null values\ndelete_rows = []\n\nfor i in xy_df.iterrows():\n    for j in xy_df.columns:\n        if pd.isnull(i[1][j]):\n            delete_rows.append(i[0])\n            \ndelete_rows = list(set(delete_rows))\n\nfor j in delete_rows:\n    xy_df = xy_df.drop(j)\n    \nxy_df.reset_index(drop = True, inplace = True)\n\n\n\n# Data Visualization and dropping features\nf, axes = plt.subplots(1, 2, figsize=(18, 9))\n\nsns.scatterplot(xy_df['snapTime'], xy_df['dx'], ax=axes[0]);\nsns.scatterplot(xy_df['operationTime'], xy_df['dx'], ax=axes[1]);\n\nxy_df = xy_df.drop(columns=['snapTime', 'operationTime'])\nxy_df.reset_index(drop = True, inplace = True)\n\npd.options.mode.chained_assignment = None","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T22:10:03.365326Z","iopub.execute_input":"2021-11-20T22:10:03.365694Z","iopub.status.idle":"2021-11-20T22:10:04.970467Z","shell.execute_reply.started":"2021-11-20T22:10:03.365651Z","shell.execute_reply":"2021-11-20T22:10:04.969788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5, Data cleaning for other datasets\nWe have constructed a dataset containing relevant features based on the 2020 NFL tracking data and cleaned it as well. The hidden cell below is used to handle the 2019 and 2018 NFL tracking data and merge all three datasets together.","metadata":{}},{"cell_type":"code","source":"# Loading NFL 2019 Tracking Data\ndf_2019 = pd.read_csv('../input/nfl-big-data-bowl-2022/tracking2019.csv')\ndf_2019 = df_2019.loc[df_2019['team'] == 'football']\ndf_2019 = df_2019.drop(columns = ['o', 'dir', 'nflId', 'jerseyNumber', 'position'])\ndf_2019 = df_2019.loc[(df_2019['event'] == 'punt') | (df_2019['event'] == 'punt_land') | (df_2019['event'] == 'punt_received')]\nsummarized_df_2019 = pd.DataFrame(df_2019.groupby(['gameId', 'playId']).size().reset_index(name = \"Count\"))\n\n# Dropping unsuccessful punts\nfor i in summarized_df_2019.iterrows():\n    if i[1]['Count'] != 2:\n        delete_row = df_2019.loc[(df_2019['gameId'] == i[1]['gameId']) & (df_2019['playId'] == i[1]['playId'])]\n        df_2019 = df_2019.drop(delete_row.index)\n        \n# Constructing target data\nxy_dataset = {}\nfor i in range(int(len(df_2019) / 2)):\n    if df_2019.iloc[i * 2]['playDirection'] == 'left':\n        x = - (df_2019.iloc[i * 2 + 1]['x'] - df_2019.iloc[i * 2]['x'])\n        y = df_2019.iloc[i * 2 + 1]['y'] - df_2019.iloc[i * 2]['y']\n        start_x = df_2019.iloc[i * 2]['x']\n        start_y = df_2019.iloc[i * 2]['y']\n    else:\n        x = df_2019.iloc[i * 2 + 1]['x'] - df_2019.iloc[i * 2]['x']\n        y = - (df_2019.iloc[i * 2 + 1]['y'] - df_2019.iloc[i * 2]['y'])    \n        start_x = 120 - df_2019.iloc[i * 2]['x']\n        start_y = 53.3 - df_2019.iloc[i * 2]['y']\n    xy_dataset[i] = [x, y, df_2019.iloc[i * 2]['gameId'], df_2019.iloc[i * 2]['playId'], start_x, start_y, df_2019.iloc[i * 2]['playDirection']]\nxy_df_2019 = pd.DataFrame(data=xy_dataset).T\nxy_df_2019.columns = ['dx', 'dy', 'gameId', 'playId', 'start_x', 'start_y', 'playDirection']\nconvert_cols = ['start_x', 'start_y', 'dx', 'dy']\nfor i in convert_cols:\n    xy_df_2019[i] = xy_df_2019[i].astype(float, errors = 'raise')\n\n# Dropping out of range data\nout_of_range_data = []\nfor i in xy_df_2019.iterrows():\n    if i[1]['start_y'] > 53.3:\n        out_of_range_data.append(i[0])\n    if i[1]['start_x'] > 120 or i[1]['start_x'] < 0:\n        out_of_range_data.append(i[0])\nfor i in out_of_range_data:\n    xy_df_2019 = xy_df_2019.drop(i)\nxy_df_2019.reset_index(drop=True, inplace=True)\n\n# Handling outliers\ndata = xy_df_2019['dx']\nmedian = np.median(data)\nupper_quartile = np.percentile(data, 75)\nlower_quartile = np.percentile(data, 25)\niqr = upper_quartile - lower_quartile\nupper_whisker = data[data<=upper_quartile+1.5*iqr].max()\nlower_whisker = data[data>=lower_quartile-1.5*iqr].min()\nfor i in xy_df_2019.iterrows():\n    if i[1]['dx'] < lower_whisker or i[1]['dx'] > upper_whisker:\n        xy_df_2019 = xy_df_2019.drop(i[0])\nxy_df_2019.reset_index(drop=True, inplace=True)\n\n# Reading data\npff = pd.read_csv('../input/nfl-big-data-bowl-2022/PFFScoutingData.csv')\nplays_df = pd.read_csv('../input/nfl-big-data-bowl-2022/plays.csv')\nplayers_df = pd.read_csv('../input/nfl-big-data-bowl-2022/players.csv')\n\n# Merging features from PFF Scouting Data\npff_feature = pff[['gameId', 'playId', 'kickType', 'snapDetail', 'snapTime', 'operationTime', 'hangTime', 'kickDirectionActual', 'puntRushers']]\nxy_df_2019 = pd.merge(xy_df_2019, pff_feature, on=['gameId', 'playId'], how='left')\n\n# Merging features from Plays\nkicker_feature = plays_df[['gameId', 'playId', 'kickerId', 'preSnapHomeScore', 'preSnapVisitorScore']]\nxy_df_2019 = pd.merge(xy_df_2019, kicker_feature, on=['gameId', 'playId'], how='left')\n\n# Merging features from Players\nplayers_feature = players_df[['height', 'weight', 'nflId']]\nxy_df_2019 = pd.merge(xy_df_2019, players_feature, left_on = 'kickerId', right_on = 'nflId', how='left')\n\n# Determining leading or trailing (tie)\nxy_df_2019['leading'] = 0\nfor i in xy_df_2019.iterrows():\n    if i[1]['playDirection'] == 'right':\n        if i[1]['preSnapHomeScore'] > i[1]['preSnapVisitorScore']:\n            xy_df_2019['leading'][i[0]] = 1\n    else:\n        if i[1]['preSnapHomeScore'] < i[1]['preSnapVisitorScore']:\n            xy_df_2019['leading'][i[0]] = 1\n            \n# Counting punt rushers\nxy_df_2019['numPuntRushers'] = 0 # default: 0\nfor i in xy_df_2019.iterrows():\n    if pd.isnull(i[1]['puntRushers']) == False:\n        xy_df_2019['numPuntRushers'][i[0]] = xy_df_2019['puntRushers'][i[0]].count(';') + 1\n        \n# Converting height to decimal form\nxy_df_2019 = xy_df_2019.rename(columns={'height': 'height_str'})\nxy_df_2019['height'] = 0.1\nfor i in xy_df_2019.iterrows():\n    if i[1]['nflId'] == 37267: # After investigation, all columns with nflId 37267 has a height issue and thus must be dropped\n        xy_df_2019 = xy_df_2019.drop(i[0])\n        continue\n    xy_df_2019['height'][i[0]] = float(i[1]['height_str'][0]) + float(i[1]['height_str'][2:]) / 12\n\n# Dropping excessive columns\nxy_df_2019 = xy_df_2019.drop(columns=['kickerId', 'nflId', 'gameId', 'playId', 'playDirection', 'preSnapHomeScore', 'preSnapVisitorScore', 'puntRushers', 'height_str'])\n\n# Dropping rows that contain null values\ndelete_rows = []\nfor i in xy_df_2019.iterrows():\n    for j in xy_df_2019.columns:\n        if pd.isnull(i[1][j]):\n            delete_rows.append(i[0]) \ndelete_rows = list(set(delete_rows))\nfor j in delete_rows:\n    xy_df_2019 = xy_df_2019.drop(j)\nxy_df_2019.reset_index(drop = True, inplace = True)\n\n## Dropping features\nxy_df_2019 = xy_df_2019.drop(columns=['snapTime', 'operationTime'])\nxy_df_2019.reset_index(drop = True, inplace = True)\n\n\n\n\n\n# Loading NFL 2018 Tracking Data\ndf_2018 = pd.read_csv('../input/nfl-big-data-bowl-2022/tracking2018.csv')\ndf_2018 = df_2018.loc[df_2018['team'] == 'football']\ndf_2018 = df_2018.drop(columns = ['o', 'dir', 'nflId', 'jerseyNumber', 'position'])\ndf_2018 = df_2018.loc[(df_2018['event'] == 'punt') | (df_2018['event'] == 'punt_land') | (df_2018['event'] == 'punt_received')]\nsummarized_df_2018 = pd.DataFrame(df_2018.groupby(['gameId', 'playId']).size().reset_index(name = \"Count\"))\nsummarized_df_2018\n\n# Dropping unsuccessful punts\nfor i in summarized_df_2018.iterrows():\n    if i[1]['Count'] != 2:\n        delete_row = df_2018.loc[(df_2018['gameId'] == i[1]['gameId']) & (df_2018['playId'] == i[1]['playId'])]\n        df_2018 = df_2018.drop(delete_row.index)\n\n# Constructing target data\nxy_dataset = {}\nfor i in range(int(len(df_2018) / 2)):\n    if df_2018.iloc[i * 2]['playDirection'] == 'left':\n        x = - (df_2018.iloc[i * 2 + 1]['x'] - df_2018.iloc[i * 2]['x'])\n        y = df_2018.iloc[i * 2 + 1]['y'] - df_2018.iloc[i * 2]['y']\n        start_x = df_2018.iloc[i * 2]['x']\n        start_y = df_2018.iloc[i * 2]['y']\n    else:\n        x = df_2018.iloc[i * 2 + 1]['x'] - df_2018.iloc[i * 2]['x']\n        y = - (df_2018.iloc[i * 2 + 1]['y'] - df_2018.iloc[i * 2]['y'])    \n        start_x = 120 - df_2018.iloc[i * 2]['x']\n        start_y = 53.3 - df_2018.iloc[i * 2]['y']\n    xy_dataset[i] = [x, y, df_2018.iloc[i * 2]['gameId'], df_2018.iloc[i * 2]['playId'], start_x, start_y, df_2018.iloc[i * 2]['playDirection']]\nxy_df_2018 = pd.DataFrame(data=xy_dataset).T\nxy_df_2018.columns = ['dx', 'dy', 'gameId', 'playId', 'start_x', 'start_y', 'playDirection']\nconvert_cols = ['start_x', 'start_y', 'dx', 'dy']\nfor i in convert_cols:\n    xy_df_2018[i] = xy_df_2018[i].astype(float, errors = 'raise')\n    \n# Dropping out of range data\nout_of_range_data = []\nfor i in xy_df_2018.iterrows():\n    if i[1]['start_y'] > 53.3:\n        out_of_range_data.append(i[0])\n    if i[1]['start_x'] > 120 or i[1]['start_x'] < 0:\n        out_of_range_data.append(i[0])\nfor i in out_of_range_data:\n    xy_df_2018 = xy_df_2018.drop(i)\n\nxy_df_2018.reset_index(drop=True, inplace=True)\n\n# Handling outliers\ndata = xy_df_2018['dx']\nmedian = np.median(data)\nupper_quartile = np.percentile(data, 75)\nlower_quartile = np.percentile(data, 25)\niqr = upper_quartile - lower_quartile\nupper_whisker = data[data<=upper_quartile+1.5*iqr].max()\nlower_whisker = data[data>=lower_quartile-1.5*iqr].min()\nfor i in xy_df_2018.iterrows():\n    if i[1]['dx'] < lower_whisker or i[1]['dx'] > upper_whisker:\n        xy_df_2018 = xy_df_2018.drop(i[0])\nxy_df_2018.reset_index(drop=True, inplace=True)\n\n# Reading data\npff = pd.read_csv('../input/nfl-big-data-bowl-2022/PFFScoutingData.csv')\nplays_df = pd.read_csv('../input/nfl-big-data-bowl-2022/plays.csv')\nplayers_df = pd.read_csv('../input/nfl-big-data-bowl-2022/players.csv')\n\n# Merging features from PFF Scouting Data !!!\npff_feature = pff[['gameId', 'playId', 'kickType', 'snapDetail', 'snapTime', 'operationTime', 'hangTime', 'kickDirectionActual', 'puntRushers']]\nxy_df_2018 = pd.merge(xy_df_2018, pff_feature, on=['gameId', 'playId'], how='left')\n\n# Merging features from Plays !!!\nkicker_feature = plays_df[['gameId', 'playId', 'kickerId', 'preSnapHomeScore', 'preSnapVisitorScore']]\nxy_df_2018 = pd.merge(xy_df_2018, kicker_feature, on=['gameId', 'playId'], how='left')\n\n# Merging features from Players !!!\nplayers_feature = players_df[['height', 'weight', 'nflId']]\nxy_df_2018 = pd.merge(xy_df_2018, players_feature, left_on = 'kickerId', right_on = 'nflId', how='left')\n\n# Determining leading or trailing (tie)\nxy_df_2018['leading'] = 0\nfor i in xy_df_2018.iterrows():\n    if i[1]['playDirection'] == 'right':\n        if i[1]['preSnapHomeScore'] > i[1]['preSnapVisitorScore']:\n            xy_df_2018['leading'][i[0]] = 1\n    else:\n        if i[1]['preSnapHomeScore'] < i[1]['preSnapVisitorScore']:\n            xy_df_2018['leading'][i[0]] = 1\n            \n# Counting punt rushers\nxy_df_2018['numPuntRushers'] = 0 # default: 0\nfor i in xy_df_2018.iterrows():\n    if pd.isnull(i[1]['puntRushers']) == False:\n        xy_df_2018['numPuntRushers'][i[0]] = xy_df_2018['puntRushers'][i[0]].count(';') + 1\n    \n# Converting height to decimal form\nxy_df_2018 = xy_df_2018.rename(columns={'height': 'height_str'})\nxy_df_2018['height'] = 0.1\nfor i in xy_df_2018.iterrows():\n    if i[1]['nflId'] == 37267: # After investigation, all columns with nflId 37267 has a height issue and thus must be dropped\n        xy_df_2018 = xy_df_2018.drop(i[0])\n        continue\n    xy_df_2018['height'][i[0]] = float(i[1]['height_str'][0]) + float(i[1]['height_str'][2:]) / 12\nxy_df_2018.reset_index(drop = True, inplace = True)\n\n# Dropping excessive columns\nxy_df_2018 = xy_df_2018.drop(columns=['kickerId', 'nflId', 'gameId', 'playId', 'playDirection', 'preSnapHomeScore', 'preSnapVisitorScore', 'puntRushers', 'height_str'])\n\n# Dropping rows that contain null values\ndelete_rows = []\nfor i in xy_df_2018.iterrows():\n    for j in xy_df_2018.columns:\n        if pd.isnull(i[1][j]):\n            delete_rows.append(i[0])\ndelete_rows = list(set(delete_rows))\nfor j in delete_rows:\n    xy_df_2018 = xy_df_2018.drop(j)\nxy_df_2018.reset_index(drop = True, inplace = True)\n\n## Dropping features\nxy_df_2018 = xy_df_2018.drop(columns=['snapTime', 'operationTime'])\nxy_df_2018.reset_index(drop = True, inplace = True)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-20T22:09:21.00734Z","iopub.status.idle":"2021-11-20T22:09:21.007683Z","shell.execute_reply.started":"2021-11-20T22:09:21.007503Z","shell.execute_reply":"2021-11-20T22:09:21.00752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6, Handling Categorical Variables\n\nLast but not least, we will merge all three cleaned datasets together and use one hot encoder to convert all the categorical variables (\"kickType\", \"snapDetail\", \"kickDirectionActual\") in order to convert them to numerical data types, maintain the consistency of the dataset and fit a training model.","metadata":{}},{"cell_type":"code","source":"# Concatenating all three dataframes\nsdf = pd.concat([xy_df, xy_df_2019, xy_df_2018], axis=0)\n\n\n# OneHotEncoder\nobject_cols = ['kickType', 'snapDetail', 'kickDirectionActual']     # try to use programming variables\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols = pd.DataFrame(OH_encoder.fit_transform(sdf[object_cols]))\nOH_cols.index = sdf.index\nnum_X_train = sdf.drop(object_cols, axis=1)\nOH_sdf = pd.concat([num_X_train, OH_cols], axis=1)\nOH_sdf.reset_index(inplace=True)\nOH_sdf","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T22:09:21.009071Z","iopub.status.idle":"2021-11-20T22:09:21.009547Z","shell.execute_reply.started":"2021-11-20T22:09:21.009288Z","shell.execute_reply":"2021-11-20T22:09:21.009314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7, Model Creation\n\nHere we are going to create a model to predict the \"Expected Landing Position\". We will use two models in this instance: XGBRegressor (which is more efficient but slightly less accurate) and XGBRegressor with BaggingRegessor (which is more accurate but takes much longer time). Test scores of cross validation and mean absolute error of 20% of the dataset will be shown as output.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.multioutput import MultiOutputRegressor \nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.model_selection import cross_val_score\n\n# Divide dataset and train test split\nX = OH_sdf.drop(columns = ['dx', 'dy'])\ny = OH_sdf[['dx', 'dy']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n\n# XGBRegressor\nxgb = MultiOutputRegressor(XGBRegressor(n_estimators=700, learning_rate=0.01, n_jobs=4))\nxgb.fit(X_train, y_train)\npreds = xgb.predict(X_test)\nmae = mean_absolute_error(preds, y_test)\nprint(\"Mean Absoulte Error of XGBRegressor: \" + str(mae))\nscores = -1 * cross_val_score(xgb, X, y, cv=5, scoring='neg_mean_absolute_error')\nprint(\"Cross Valiation Average Mean Absolute Error Score for XGBRegressor: \" + str(scores.mean()))\n\n# XGBRegressor with BaggingRegressor\nxgbbag = MultiOutputRegressor(BaggingRegressor(base_estimator=XGBRegressor(n_estimators=700, learning_rate=0.01, n_jobs=4)))\nxgbbag.fit(X_train, y_train)\npreds = xgbbag.predict(X_test)\nmae = mean_absolute_error(preds, y_test)\nprint(\"Mean Absoulte Error of XGBRegressor with BaggingRegressor: \" + str(mae))\nscores = -1 * cross_val_score(xgbbag, X, y, cv=5, scoring='neg_mean_absolute_error')\nprint(\"Cross Valiation Average Mean Absolute Error Score for XGBRegressor with BaggingRegressor: \" + str(scores.mean()))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T22:09:21.01113Z","iopub.status.idle":"2021-11-20T22:09:21.011956Z","shell.execute_reply.started":"2021-11-20T22:09:21.011654Z","shell.execute_reply":"2021-11-20T22:09:21.01169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8, Example of Model Application: 2016 NFL Season Week 10 Pittsburgh Steelers vs. Dallas Cowboys ","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimg = Image.open('../input/insertimage/IMG_0032.jpg')\nplt.grid(False)\nplt.axis('off')\nplt.figure(figsize = (20, 20))\nplt.axis('off')\nplt.imshow(img);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T22:09:21.013596Z","iopub.status.idle":"2021-11-20T22:09:21.014124Z","shell.execute_reply.started":"2021-11-20T22:09:21.013843Z","shell.execute_reply":"2021-11-20T22:09:21.013869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are going to apply this trained model on a real life instance to evaluate whether the predicted landing spot is in an area which the returner has control. Here we are going to use a return in the game between Pittsburgh Steelers and Dallas Cowboys in week 10 in the 2016 NFL Season as an example. With 3 minutes 17 seconds left in the 2nd quarter, Dallas Cowboys had a chance to punt the ball at around 90.75 yards on the x axis and 23.16 yards on the y axis. For the features, we can observe that there are no punt rushers and the punting team is trailing behind. For other features, I am going to use the most frequent or mean value of all the punts that the player Chris Jones has made in the past, including hangTime, kickType, direction and snapDetail. Here I am going to use the XGBRegressor in order to perform more efficient calculations. After calculation and model prediction, we can observe that the actual landing spot of the football is at around 62 yards on ths x axis and -22 yards (just out of bounds), which was a position that the receiver Antonio Brown could catch the ball. Thus this model is valid and could be used to predict the position of returners before a punt.","metadata":{}},{"cell_type":"code","source":"player = players_df.iloc[players_df.loc[(players_df['displayName'] == 'Chris Jones') & (players_df['collegeName'] == 'Carson-Newman')].index[0]]\nnflId = player['nflId']\nheight = player['height']\nweight = player['weight']\negdf = plays_df.loc[plays_df['kickerId'] == nflId][['gameId', 'playId']]\negdf = pd.merge(egdf, pff[['gameId', 'playId', 'hangTime', 'kickType', 'kickDirectionActual', 'snapDetail']], on=['gameId', 'playId'], how='left')\nhangTime = egdf['hangTime'].mean()\nkickType = egdf['kickType'].mode()[0]\nleading = False\ndirection = egdf['kickDirectionActual'].mode()[0]\nstart_x = 90.75\nstart_y = 23.16333\nsnapDetail = egdf['snapDetail'].mode()[0]\nnumPuntRushers = 0\n\ndef construct(start_x, start_y, kickType, snapDetail, hangTime, direction, weight, leading, numPuntRushers, height):\n    height = float(height[0]) + float(height[2:]) / 12\n    if leading == False:\n        leading = 1\n    else:\n        leading = 0\n    eg_test = pd.DataFrame(data = {'1': [start_x, start_y, kickType, snapDetail, hangTime, direction, weight, leading, numPuntRushers, height]})\n    eg_test = eg_test.T\n    eg_test.columns = ['start_x', 'start_y', 'kickType', 'snapDetail', 'hangTime', 'kickDirectionActual', 'weight', 'leading', 'numPuntRushers', 'height']\n    return eg_test\n\ndef return_test_result(eg_test):\n    global sdf\n    sdf2 = pd.concat([sdf, eg_test], axis=0)\n    sdf2.reset_index(drop = True, inplace = True)\n    object_cols = ['kickType', 'snapDetail', 'kickDirectionActual']     # try to use programming variables\n    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n    OH_cols = pd.DataFrame(OH_encoder.fit_transform(sdf2[object_cols]))\n    OH_cols.index = sdf2.index\n    num_X_train = sdf2.drop(object_cols, axis=1)\n    OH_sdf = pd.concat([num_X_train, OH_cols], axis=1)\n    OH_sdf.reset_index(drop = True, inplace = True)\n    eg_test = OH_sdf.iloc[len(OH_sdf) - 1]\n    OH_sdf = OH_sdf.drop(len(OH_sdf) - 1)\n    y = OH_sdf[['dx', 'dy']]\n    X = OH_sdf.drop(columns = ['dx', 'dy'])\n    eg_test = pd.DataFrame(eg_test.drop(['dx', 'dy'])).T\n    xgb = MultiOutputRegressor(XGBRegressor(n_estimators=700, learning_rate=0.01, n_jobs=4))\n    xgb.fit(X, y)\n    return xgb.predict(eg_test)\n    \neg_test = construct(start_x, start_y, kickType, snapDetail, hangTime, direction, weight, leading, numPuntRushers, height)\npreds = return_test_result(eg_test)\nprint('dx Prediction: ' + str(preds[0][0]))\nprint('dy Prediction: ' + str(preds[0][1]))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T22:09:21.015954Z","iopub.status.idle":"2021-11-20T22:09:21.016706Z","shell.execute_reply.started":"2021-11-20T22:09:21.016406Z","shell.execute_reply":"2021-11-20T22:09:21.016437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9, Conclusion\n\nThis notebook provides a new insight of understanding the importance of punt and predicting the punt yardage. By using the machine learning model in this notebook, one is able to calculate the approximate displacement of a punted football, also known as \"Expected Landing Position\", by gathering data of starting position (on both x and y axis), kick type, hang time, kick direciton, number of punt rushers, whether the opponent is leading or not, the height and the weight of the punter. With the help of this metric, NFL teams could avoid positioning themselves in disadvangeous situations by performing better at returning, gaining more return yardages and facilitate the first offensive possesion after the punt from the opponent. Thank you for reading my notebook and I appreciate your time.\n\nImage Source: https://www.youtube.com/watch?v=9n5UzEek6X8&t=3369s (Timestamp: 56:01) <br />\nStats Source: https://www.pro-football-reference.com/boxscores/201611130pit.htm","metadata":{}}]}