{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Heuristic Goose - New non-NN baseline\n\n- **Intention:** Try simple solutions first.\n- **Notebook For:** Begineers to this Competition OR someone looking for baseline.\n- **Approach:** Define a simple agent which performs following oprations each step, \n    1. Valid transitions: (a) do not collide with any agent, (b) do not make an action which is opposite to your own last action.\n    2. Find the nearest food from my position\n    3. Find the actions (from valid transitions) such that the distance from nearest food becomes smaller.\n- **Where does this fails:** Majority times, due to greedy nature, it colides with an agent when both are at distance of 1 from the food.","attachments":{}},{"metadata":{},"cell_type":"markdown","source":"### Import packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col, translate\nfrom kaggle_environments import evaluate, make, utils\nfrom joblib import Parallel, delayed\nfrom typing import *\nimport numpy as np\nimport random","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Original baseline agent\n\n- As defined in the Problem definition. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def baseline_agent(obs_dict, config_dict):\n    \"\"\"This agent always moves toward observation.food[0] but does not take advantage of board wrapping\"\"\"\n    # convert \n    observation = Observation(obs_dict)\n    configuration = Configuration(config_dict)\n    # get stats\n    player_index = observation.index\n    player_goose = observation.geese[player_index]\n    player_head = player_goose[0]\n    player_row, player_column = row_col(player_head, configuration.columns)\n    food = observation.food[0]\n    food_row, food_column = row_col(food, configuration.columns)\n    # choose action\n    if food_row > player_row:\n        return Action.SOUTH.name\n    if food_row < player_row:\n        return Action.NORTH.name\n    if food_column > player_column:\n        return Action.EAST.name\n    return Action.WEST.name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Our Custom agent -- Heuristic Goose"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile heuristic_goose.py\n\n# import\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col, translate\nfrom kaggle_environments import evaluate, make, utils\nfrom typing import *\nimport numpy as np\nimport random\n\n# my hitorical actions\nmy_actions = [None]\n\ndef find_valid_moves(geese_position, my_goose_index, my_last_action, config_col, config_rows):\n    \"\"\"Return list of valid moves. A valid move is one which \n    1. Doesn't colide with any agent's body \n    2. It isn't the opposite of my last action\n    \"\"\"\n    # all possible actions\n    actions = [Action.NORTH, Action.SOUTH, Action.WEST, Action.EAST]\n    # find opposite of my last action -- invalid move\n    my_last_action_opposite = my_last_action.opposite() if my_last_action is not None else None\n    # get agent's position (head position)\n    my_position = geese_position[my_goose_index][0]\n    # find occupied positions\n    occupied_positions = set([pos for one_goose_position in geese_position for pos in one_goose_position])\n    # find translated position after taking actions\n    possible_transition = [(action, translate(my_position, action, config_col, config_rows)) for action in actions if action is not my_last_action_opposite]\n    # find valid transitions of (action, final_pos) tuples\n    valid_transitions = [trans for trans in possible_transition if trans[1] not in occupied_positions]\n    #\n    return valid_transitions\n    \ndef find_distance(distance_to, distance_from_list, columns):\n    \"\"\"Find the distance to a point from multiple other points.\n    Based on Kaggle original code with same name in hungry_geese.py; \n    \"\"\"\n    row, column = row_col(distance_to, columns)\n    return list(\n        abs(row - pos_row) + abs(column - pos_col)\n        for pos in distance_from_list\n        for pos_row, pos_col in [row_col(pos, columns)]\n    )\n\n# custom agent\ndef agent(obs_dict, config_dict):\n    \"\"\"This is custom heuristic based agent\n    Ver1: Please just don't colide :) -- Skipping dumb moves\n    \"\"\"\n    global my_actions\n    # convert \n    observation = Observation(obs_dict)\n    configuration = Configuration(config_dict)\n    # get stats\n    player_index = observation.index\n    player_goose = observation.geese[player_index]\n    player_head = player_goose[0]\n    player_row, player_column = row_col(player_head, configuration.columns)\n    # find valid transitions\n    valid_transitions = find_valid_moves(observation.geese, player_index, my_actions[-1], configuration.columns, configuration.rows)\n    if len(valid_transitions) != 0:\n        # find nearest food\n        food_distance = find_distance(player_goose[0], observation.food, configuration.columns)\n        nearest_food_pos = observation.food[np.argmin(food_distance)]\n        # find the next valid action which is closest to the nearest food\n        next_position_food_distance = find_distance(nearest_food_pos, [x[1] for x in valid_transitions], configuration.columns)\n        next_action = valid_transitions[np.argmin(next_position_food_distance)][0]\n    else:\n        next_action = my_actions[-1] # we have already lost :(\n    # update my_actions\n    my_actions.append(next_action)\n    #\n    return next_action.name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Play with agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"env = make(\"hungry_geese\", debug=True)\nrun_stats = env.run([\n                baseline_agent,\n                baseline_agent,\n                \"heuristic_goose.py\", \n                \"heuristic_goose.py\",\n            ])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Print the run stats (for debugging)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# run_stats[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate (get reward)"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(\"hungry_geese\", [\n    baseline_agent, \n    baseline_agent,\n    \"heuristic_goose.py\", \n    \"heuristic_goose.py\", \n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parallel evaluate\n\n- Run evaluate 100 times to validate that the current approach is better than original baseline\n- Ideally, the average reward points at the last 2 positions (heuristic) should be higher than first 2 (original baseline)\n- Code inspired by: [Here](https://www.kaggle.com/jamesmcguigan/hungry-geese-go-west)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# variable\ntrials = 100\n\n# run parallel test for 100\nresults = Parallel()( \n    delayed(evaluate)(\"hungry_geese\", [\n        baseline_agent, \n        baseline_agent, \n        \"heuristic_goose.py\",\n        \"heuristic_goose.py\", \n    ], num_episodes=1) \nfor _ in range(trials) )\n\n\nprint(\"mean\", np.mean(results, axis=0).astype(np.int).flatten())\nprint(\"max \", np.max( results, axis=0).astype(np.int).flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}