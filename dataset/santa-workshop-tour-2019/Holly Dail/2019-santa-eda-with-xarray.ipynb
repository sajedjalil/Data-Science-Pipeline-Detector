{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nThis notebook provides exploratory analysis of the scheduling problem and cost function from Kaggle's [Santa's Workshop Tour 2019](http://www.kaggle.com/c/santa-workshop-tour-2019) competition.  Per guidance from the organizers, the notebook does not include scheduling solutions, only an exploration of the problem setup.\n\nThis notebook leans heavily on the [xarray](http://xarray.pydata.org/en/stable/index.html) package, partly as a demonstration of its utility.  xarray is extremely handy for n-dimensional datasets with multiple variables.  Undoubtedly, there are places in the notebook where xarray usage could be improved, e.g. where a conversion to a dataframe has been made and is unnecessary.  Constructive feedback welcome."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xarray as xr\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def precompute_preference_cost(fam_dates, fam_size):\n    \"\"\"Precompute the scheduling cost for assigning each family to\n    each preference level and return as a numpy array.\n    \"\"\"\n\n    n_families, n_choices = fam_dates.shape\n\n    cards = np.array([0, 50, 50, 100, 200, 200, 300, 300, 400, 500, 500])\n    buffet_pp = np.array([0, 0, 9, 9, 9, 18, 18, 36, 36, 36, 36])\n    heli_pp = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 199, 398])\n\n    def row_cost(row_id):\n        return (cards + (buffet_pp + heli_pp) * fam_size[row_id])\n\n    pref_cost = [row_cost(id) for id in np.arange(n_families)]\n    pref_cost = np.array(pref_cost)\n\n    return pref_cost\n\n\ndef date_popularities(ds_fam):\n    \"\"\"Calculate how many families and how many people prefer each date within\n    each preference level and return as xarray data arrays.\n    \"\"\"\n\n    # consider only the original 10 preferences and convert to dataframe\n    ds = ds_fam[['fam_size', 'fam_prefs']].drop(pref=10)\n    ds = ds.rename({'fam_prefs': 'date'})\n    df = ds.to_dataframe()\n\n    # count the number of families interested in each date\n    df_num_fam = (df.groupby(['date', 'pref'])\n                    .count()\n                    .rename(columns={'fam_size': 'families'}))\n    da_num_fam = xr.DataArray(df_num_fam['families'].unstack('pref'))\n\n    # sum on family size to count the people interested in each date \n    df_num_ppl = (df.groupby(['date', 'pref'])\n                    .sum()\n                    .rename(columns={'fam_size': 'people'}))\n    da_num_ppl = xr.DataArray(df_num_ppl['people'].unstack('pref'))\n\n    return da_num_fam, da_num_ppl\n\n\ndef get_occ_linear(da_popularity):\n    \"\"\"Create a linear fit to family occupancy preferences for each date\n    and return as a data array.\n    \"\"\"\n    \n    dates = da_popularity['date'].values\n    pop = da_popularity.mean('pref').values\n    \n    coeff = np.polyfit(x=dates[1:], y=pop[1:], deg=1, full=False)\n    \n    occ_pred = coeff[1] + coeff[0] * dates\n    return xr.DataArray(occ_pred,\n                        coords=[dates],\n                        dims=['date'])\n\n\ndef fam_diff_score(da_fam_prefs, da_date_pop, da_occ_fit):\n    \"\"\"Create data array with same shape as family preferences, but each\n    entry contains the difference between the average popularity for that\n    date and our linear fit to popularity.  Large values indicate\n    families / preference levels that are difficult to schedule.\n    \"\"\"\n\n    # popularity for each of 100 dates, averaged across 10 preferences\n    date_pop = da_date_pop.mean('pref')\n    \n    # dicts with dates as keys and values for popularity or target occupancy\n    pop_map = date_pop.to_dataframe().to_dict()['pop_ppl']\n    target_map = da_occ_fit.to_dataframe().to_dict()['occ_fit']\n\n    # create data array with difficulty score for each family / preference\n    df_fam_prefs = da_fam_prefs.sel(pref=range(10)).to_dataframe()\n    score = df_fam_prefs['fam_prefs'].map(lambda x: pop_map[x] - target_map[x])\n\n    df_fam_score = pd.DataFrame(score)\n    df_fam_score.rename(columns={'fam_prefs': 'pop_ppl'}, inplace=True)\n\n    da_fam_score = xr.DataArray(df_fam_score['pop_ppl'].unstack('pref'))\n\n    return da_fam_score\n\n\ndef family_preprocess(fn_family):\n    \"\"\"Given a path to a family data csv, read in the file, structure the\n    data as an xarray dataset, and add derived variables such as the popularity\n    of each date.\n    \"\"\"\n\n    # read in data and pull out dataframe of family date preferences,\n    # family sizes, # families\n    df = pd.read_csv(fn_family)\n    fam_dates = df.drop(columns=['family_id', 'n_people'])\n    fam_sizes = df['n_people']\n    n_families = df.shape[0]\n    \n    # families select 10 preferred dates, but could also be assigned an\n    # alternative date. make room for one more column to store alternative.\n    n_choices = fam_dates.shape[1] + 1\n    fam_dates['choice_10'] = -1 * np.ones(n_families, dtype='int')\n\n    # pre-compute cost of scheduling families in each preference\n    pref_cost = precompute_preference_cost(fam_dates, fam_sizes)\n\n    # Create xarray dataset\n    ds_fam = xr.Dataset(\n        {'fam_size': (('fam'), fam_sizes),\n         'fam_prefs': (('fam', 'pref'), fam_dates),\n         'pref_cost': (('fam', 'pref'), pref_cost),\n        },\n        {'fam': df['family_id'].values,\n         'pref': np.arange(n_choices)\n        }\n    )\n\n    # compute number of families and people requesting each date for each\n    # preference level, then add to family dataset\n    da_num_fam, da_num_ppl = date_popularities(ds_fam)\n    ds_fam['pop_fam'] = da_num_fam\n    ds_fam['pop_ppl'] = da_num_ppl\n\n    # compute a linear fit to the number of families requesting each date.\n    # nb: day 1 is excluded so occupancy of this fit is low by definition.\n    ds_fam['occ_fit'] = get_occ_linear(ds_fam['pop_ppl'])\n\n    # create scheduling difficulty index (gap between popularity of a\n    # date and the linear fit to popularity)\n    ds_fam['difficulty'] = fam_diff_score(ds_fam['fam_prefs'],\n                                          ds_fam['pop_ppl'],\n                                          ds_fam['occ_fit'])\n\n    # store the total number of people getting scheduled\n    ds_fam['tot_people'] = ds_fam['fam_size'].sum().item()\n\n    return ds_fam","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fn_family = '../input/santa-workshop-tour-2019/family_data.csv'\nds_family = family_preprocess(fn_family)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fun with xarray\n\nWhile the other sections of this notebook are focused on revealing aspects of the scheduling problem, this section demonstrates everyday EDA with xarray.\n\n### First, lets look at a summary of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(ds_family)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can  easily investigate specific aspects of the data by label\n\nTo demonstrate we look at family 1009 and preference level 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at characteristics of family 1009\nprint(ds_family.sel(fam=1009).drop(['occ_fit', 'pop_ppl', 'pop_fam', 'tot_people', 'date']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = ds_family.sel(fam=1009)['difficulty'].plot(marker='*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at characteristics of preference 0\nprint(ds_family.sel(pref=0)[['occ_fit', 'pop_fam', 'pop_ppl']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = ds_family['occ_fit'].plot()\n_ = ds_family.sel(pref=0)['pop_ppl'].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Family size distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fam_size_dists(family_sizes):\n    \"\"\"Show histogram and cumulative distribution of family sizes.  family_sizes\n    should be a list with one size for each family.\n    \"\"\"\n    \n    sizes = list(set(family_sizes))\n    fam_size_bins = np.arange(sizes[0] - 0.5, sizes[-1] + 1.5)\n\n    fig, axes = plt.subplots(ncols=2, figsize=(10, 4))\n\n    # plot histogram of family sizes on left\n    axes[0].hist(family_sizes, bins=fam_size_bins, rwidth=0.9)\n    _ = axes[0].set_ylabel('number of families')\n    _ = axes[0].set_title('Number of families in family size groups')\n    _ = axes[0].set_xlabel('family size')\n\n    # plot cumulative distribution of family sizes on right\n    axes[1].hist(family_sizes, bins=fam_size_bins, rwidth=0.9, cumulative=True, density=True)\n    _ = axes[1].set_ylabel('fraction of families')\n    _ = axes[1].set_title('Cumulative fraction of families in family size groups')\n    _ = axes[0].set_xlabel('family size')\n    \n    return\n    \n\ndef fam_size_people_dists(family_sizes):\n    \"\"\"Calculate and show histogram and cumulative distribution of the number\n    of people in different family size groups.\n    \"\"\"\n    \n    sizes = list(set(family_sizes))\n    bins = np.arange(sizes[0] - 0.5, sizes[-1] + 1.5)\n    hist, _ = np.histogram(family_sizes, bins=bins)\n    people_per_bin = hist * sizes\n\n    # make a cumulative distribution as a density\n    cum_people_per_bin = np.cumsum(people_per_bin)\n    cum_people_per_bin = cum_people_per_bin / cum_people_per_bin[-1]\n    \n    # show distributions\n    fig, axes = plt.subplots(ncols=2, figsize=(10, 4))\n\n    _ = axes[0].bar(x=sizes, height=people_per_bin)\n    _ = axes[0].set_xlabel('family size')\n    _ = axes[0].set_ylabel('number of people')\n    _ = axes[0].set_title('Number of people in family size groups')\n\n    _ = axes[1].bar(x=sizes, height=cum_people_per_bin)\n    _ = axes[1].set_xlabel('family size')\n    _ = axes[1].set_ylabel('fraction of people')\n    _ = axes[1].set_title('Cumulative fraction of people in family size groups')\n    \n    # prepare to show fractions of people in each family size in a human readable format\n    df = pd.DataFrame(\n        {'fam_size': sizes,\n         'pct of people': np.round(100 * people_per_bin / np.sum(people_per_bin)),\n         'cumulative pct': np.round(100 * cum_people_per_bin)})\n    df.set_index('fam_size', inplace=True)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fam_size_dists(ds_family['fam_size'].values)\ndf_show = fam_size_people_dists(ds_family['fam_size'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_show.T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary thoughts on family size distribution\n- Family sizes range from 2 to 8 people.\n- Over 60% of families have between two and four people and less than 40% of families have between five and eight people. The most frequent family size is 4.\n- After adjusting the analysis to consider people counts rather than family counts, the most frequent family size is also four. About half of people are in families between size two and four, and about 70% are in families between size two and five."},{"metadata":{},"cell_type":"markdown","source":"> # Family date preferences"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_preferences(ds_prefs, ds_prefs_demeaned):\n    \"\"\"Show how many families and how many people requested each date in\n    each preference level, and show the deviation from the mean across\n    preference levels to highlight any structure in preference levels.\n    \"\"\"\n    \n    fig, axes = plt.subplots(nrows=4, figsize=(15, 12), sharex=True)\n\n    ds_prefs['pop_fam'].plot.line(x='date', ax=axes[0], add_legend=True)\n    axes[0].set_ylabel('number of families')\n\n    ds_prefs['pop_ppl'].plot.line(x='date', ax=axes[1], add_legend=False)\n    axes[1].set_ylabel('number of people')\n\n    ds_prefs_demeaned['pop_fam'].plot.line(x='date', ax=axes[2], add_legend=False)\n    axes[2].set_ylabel('demean num families')\n\n    ds_prefs_demeaned['pop_ppl'].plot.line(x='date', ax=axes[3], add_legend=False)\n    axes[3].set_ylabel('demean num people')\n    \n    return\n\n\ndef show_preferences_zoom(ds_prefs):\n    \"\"\"Show how many people requested each date in each preference level,\n    focusing on requests for dates near date=1.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(15, 4))\n    ds_prefs['pop_ppl'].plot.line(x='date', ax=ax)\n    ax.set_ylabel('number of people')\n    return\n\n    \ndef get_noise(da_demeaned):\n    \"\"\"Given demeaned preferences by date, return histograms of noise for\n    each preference level.\n    \"\"\"\n    bins = np.arange(-60.5, 61.5, 3)\n    bin_centers = (bins[:-1] + bins[1:]) / 2\n    def helper(da):\n        hist, _ = np.histogram(da.values, bins)\n        da_hist = xr.DataArray(hist, coords=[bin_centers], dims=['anomaly'])\n        return da_hist\n\n    da_ret = da_demeaned.sel(pref=np.arange(10)).groupby('pref').apply(helper)\n    return da_ret\n\n    \ndef print_dayzero_info(ds_prefs):\n    \"\"\"In our re-labelling, day zero is Christmas Eve.  Families strongly\n    prefer that specific day, here we explore how much.\n    \"\"\"\n    mean_prefs = ds_prefs['pop_fam'].mean('pref')\n    day1_mean = mean_prefs[0].item()\n    others_mean = mean_prefs[1:].mean().item()\n    print(f'{day1_mean:.2f} families prefer day one on average')\n    print(f'{others_mean:.2f} families prefer other days, on average')   \n    return\n    \n    \ndef show_sorted_date_popularity(ds_prefs):\n    \"\"\"Show the number of people wanting different dates.\n    \"\"\"\n    \n    prefs = ds_prefs['pop_ppl'].mean('pref').to_dataframe().reset_index('date')\n    prefs = prefs[1:].sort_values(by='pop_ppl')['pop_ppl'].values\n    fig, ax = plt.subplots(figsize=(15, 4))\n    ax.plot(prefs)\n    ax.plot([0, 100], [125, 125], '--g')\n    ax.plot([0, 100], [300, 300], '--g')\n\n    ax.set_xlabel('low popularity to high popularity days')\n    ax.set_ylabel('number of people wanting days')\n    ax.grid(True)\n    \n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_prefs = ds_family[['pop_fam', 'pop_ppl']]\nds_prefs_demeaned = ds_prefs - ds_prefs.groupby('date').mean('pref')\nshow_preferences(ds_prefs, ds_prefs_demeaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_preferences_zoom(ds_prefs.sel(date=np.arange(1, 4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dayzero_info(ds_prefs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"da_noise = get_noise(ds_prefs_demeaned['pop_fam'])\n_ = da_noise.plot.line(x='anomaly', figsize=(8, 4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_sorted_date_popularity(ds_prefs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary of findings on family preferences for different dates\n\n- Date=1 is far more likely to show up in family preference lists than any other date (275 families prefer day 1 versus 48 for other days, on average).\n- For date=1, we see special behavior in terms of where in a family's preference list the day shows up.  If that date is in a family's list, its far more likely to appear near the beginning of the list than near the end.\n- For dates besides date=1, we see two signals superimposed.  The first signal is that more families request weekends and less request weekdays.  The second signal is a trend of increasing numbers of families requesting smaller dates; this trend appears roughly linear in time.  These patterns are consistent across preference levels (except for date=1).\n- For dates besides date=1, we do not see any structure in the variation between preference levels.  Compared to the mean preferences across all preference levels, deviations from the mean appear reasonably gaussian and bias or skew is not apparent."},{"metadata":{},"cell_type":"markdown","source":"# Date preference popularity by family"},{"metadata":{"trusted":true},"cell_type":"code","source":"# show overall histogram of difficulty levels\n_ = ds_family['difficulty'].sel(pref=range(0, 10)).plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show median difficulty level taken across the 10 preference levels,\n# this plot shows some families are easy to schedule (median is very low)\n# and some are not (median difficult is very high)\n_ = ds_family['difficulty'].sel(pref=range(0, 10)).median('pref').plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show difficulty level of the \"easiest\" day for each family, first considering only\n# their top preference, then their top two preferences, and so on.\nbins = np.arange(-100, 1000, 50)\nfig, axes = plt.subplots(ncols=5, nrows=2, figsize=(15, 8), sharex=True, sharey=True)\nfor ind, ax in enumerate(axes.flatten()):\n    if ind == 0:\n        _ = ds_family['difficulty'][:, 0].plot.hist(ax=ax, bins=bins)\n    else:\n        _ = ds_family['difficulty'][:, :(ind + 1)].min('pref').plot.hist(ax=ax, bins=bins)\n    ax.set_title('')\n    ax.set_xlabel(f'easiest day of [0:{ind + 1}]')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary of findings regarding difficulty scheduling families\n- For a few families, all or most of the requested days are popular days.\n- Most families have at least one relatively unpopular days in their top five preferences. "},{"metadata":{},"cell_type":"markdown","source":"# Scheduling basics and scheduling cost"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_sched_basics(total_people, ds_prefs):\n    \"\"\"Calculate and print out some rudimentary information about the\n    scheduling problem.\n    \"\"\"\n    avg_people_per_day = total_people / 100\n\n    print(f'There are {total_people} people total, {avg_people_per_day} people per day')\n\n    pref0_num_too_high = (ds_prefs.sel(pref=0)['pop_ppl'] > 400).values.sum()\n    pref0_num_too_low = (ds_prefs.sel(pref=0)['pop_ppl'] < 125).values.sum()\n    pct_out_compliance = pref0_num_too_high + pref0_num_too_low\n\n    print('If we blindly assign all families their first preference,')\n    print(f'    {pref0_num_too_high} dates have > 400 people')\n    print(f'    {pref0_num_too_low} dates have < 125 people')\n    print(f'    {pct_out_compliance}/100 are out of compliance')\n    \n    return\n\n\ndef show_sched_costs(ds_fam, per_person):\n    \"\"\"Show histogram of costs for each preference level.  If per_person is\n    True, show costs per person, otherwise show cost per family.\n    \"\"\"\n    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 6))\n    if per_person:\n        bins = np.arange(0, 2000, 25)\n        costs = ds_fam['pref_cost'] / ds_fam['fam_size']\n    else:\n        bins = np.arange(0, 5000, 100)\n        costs = ds_fam['pref_cost']\n    for pref_ind in np.arange(11):\n        ax = axes.flatten()[pref_ind]\n        costs[:, pref_ind].plot.hist(ax=ax, bins=bins)\n        ax.set_title('')\n        ax.grid(True)\n    fig.suptitle(f'Scheduling costs by preference level\\nPer-person={per_person}')\n    return\n\n\ndef get_pp_sched_cost(ds_fam):\n    \"\"\"Returns average per person scheduling cost for each family\n    size and each preference level.\n    \"\"\"\n    pp_cost = ds_fam['pref_cost'] / ds_fam['fam_size']\n    pp_cost.name = 'pp_cost'\n    ds_pp_cost = pp_cost.to_dataset()\n    ds_pp_cost['fam_size'] = ds_fam['fam_size']\n    mean_costs_by_fam_pref = ds_pp_cost.groupby('fam_size').mean()\n    return mean_costs_by_fam_pref\n\n\ndef show_pp_sched_cost(mean_costs, heat_map=True):\n    \"\"\"Display average per person scheduling cost for each family\n    and each preference level.\n    \"\"\"\n    if heat_map:\n        fig, axes = plt.subplots(ncols=3, figsize=(15, 5))\n\n        mean_costs['pp_cost'].plot(ax=axes[0], robust=True)\n        mean_costs['pp_cost'].plot(ax=axes[1], vmin=0, vmax=100)\n        mean_costs['pp_cost'].plot(ax=axes[2], vmin=0, vmax=20)\n    else:\n        fig, axes = plt.subplots(ncols=2, figsize=(15, 5))\n        _ = mean_costs['pp_cost'].plot.line(ax=axes[0], x='pref')\n        _ = mean_costs['pp_cost'].plot.line(ax=axes[1], x='fam_size')\n    return\n\n\ndef show_sched_cost_by_size(mean_costs):\n    \"\"\"Show average scheduling cost by family size and preference\n    level with the mean across family sizes removed.\n    \"\"\"\n    diff_from_mean = (mean_costs - mean_costs.mean('fam_size'))\n    ratio_to_mean = (mean_costs / mean_costs.mean('fam_size'))\n    fig, axes = plt.subplots(nrows=2, figsize=(15, 10))\n    _ = diff_from_mean['pp_cost'].plot.line(ax=axes[0], x='pref')\n    axes[0].set_ylabel('Deviation from mean across all family sizes')\n\n    _ = ratio_to_mean['pp_cost'].plot.line(ax=axes[1], x='pref')\n    axes[1].set_ylabel('Ratio to mean across all family sizes')\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_sched_basics(ds_family['tot_people'].item(), ds_prefs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_sched_costs(ds_family, per_person=False)\nshow_sched_costs(ds_family, per_person=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_costs_by_fam_pref = get_pp_sched_cost(ds_family)\nshow_pp_sched_cost(mean_costs_by_fam_pref, heat_map=True)\nshow_pp_sched_cost(mean_costs_by_fam_pref, heat_map=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_sched_cost_by_size(mean_costs_by_fam_pref)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary of findings for schedule preference costs\n- Costs increase markedly for less preferred dates, and choice_9 and choice_10 (\"other\") should be avoided if at all possible\n- Smaller families have a higher per person schedule cost, due to the fixed per-family gift card price.  Since gift card prices go up so quickly with preference level, the per-person surcharge on small families rises with preference level."},{"metadata":{},"cell_type":"markdown","source":"# Accounting cost"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_occupancy_cost(dates, occupancies):\n    \"\"\"Given an array of dates and an array of occupancies,\n    calculate the occupancy cost and return as a dataframe.\n    \"\"\"\n    \n    df = pd.DataFrame(\n        {'date': dates,\n         'occupancy': occupancies\n        }\n    )\n    df.set_index('date', inplace=True)\n    \n    # ensure dataframe is sorted from day 1 to day 100\n    df = df.sort_values(by='date', axis=0, ascending=True)\n\n    # create array of occupancies that provides the initial condition d=100, N101 = N100\n    vals = df['occupancy'].values\n    new_occ = np.concatenate([vals, [vals[-1]]], axis=0)\n    \n    def daily_helper(ind):\n        Nd = new_occ[ind]\n        Nd1 = new_occ[ind + 1]\n        exp = 0.5 + 0.02 * np.abs(Nd - Nd1)\n\n        day_cost = 0.0025 * (Nd - 125) * Nd**(0.5) * Nd**exp\n        return day_cost\n    \n    daily_cost = [daily_helper(ind) for ind in np.arange(0, 100)]\n    df['daily_cost'] = daily_cost\n\n    return df\n\n\ndef get_occ_cost_linear_fit(occ_target):\n    \"\"\"Get cost of the proposed target occupancy (the linear trend with adjustments)\n    \"\"\"\n    return _get_occupancy_cost(np.arange(1, 101), occ_target)\n\n\ndef get_occ_cost_uniform_dist(n_people):\n    \"\"\"Get cost of a uniform distribution of occupancies\n    \"\"\"\n    return _get_occupancy_cost(np.arange(1, 101),\n                               (n_people / 100) * np.ones(100))\n\n\ndef get_occ_cost_random_dist(n_people):\n    \"\"\"Get cost of occupancies that center on the required mean, but also\n    have substantial noise.  We don't want to go outside 125 to 300 people,\n    so we calculate a range for noise around the mean occupancy that will remain\n    inside the allowed occupancy.\n    \"\"\"\n    return _get_occupancy_cost(np.arange(1, 101),\n                               np.random.randint(low=125, high=300, size=(100,)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cost_uniform = get_occ_cost_uniform_dist(ds_family['tot_people'].item())\ntot_cost_uniform = df_cost_uniform['daily_cost'].sum()\nprint(f'Accounting cost uniform occupancy distribution {tot_cost_uniform:.2f}\\n')\n\ndf_cost_target = get_occ_cost_linear_fit(ds_family['occ_fit'])\ntot_cost_target = df_cost_target['daily_cost'].sum()\nprint(f'Accounting cost linearly increasing target occupancy {tot_cost_target:.2f}\\n')\n\ndf_cost_random = get_occ_cost_random_dist(ds_family['tot_people'].item())\ntot_cost_random = df_cost_random['daily_cost'].sum()\nprint(f'Accounting cost random occupancy distribution {tot_cost_random:.2f}\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(15, 5), sharey=True)\n\ndf_cost_target.plot(ax=axes[0])\n_ = axes[0].set_title(f'Total cost target occupancy {tot_cost_target:.2f}')\ndf_cost_uniform.plot(ax=axes[1])\n_ = axes[1].set_title(f'Total cost uniform occupancy {tot_cost_uniform:.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3, figsize=(15, 6))\ndf_cost_random['occupancy'].plot(ax=axes[0])\n_ = axes[0].set_ylabel('Occupancy')\ndf_cost_random['occupancy'].diff().plot(ax=axes[1])\n_ = axes[1].set_ylabel('$\\Delta$ occupancy')\ndf_cost_random['daily_cost'].plot(ax=axes[2])\n_ = axes[2].set_ylabel('cost')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary of findings for occupancy penalties\n- Total occupancy penalty for a linearly increasing target occupancy is 6038, total for a uniform distribution is 4465.\n- If we add random noise around a mean occupancy, the total cost is 239,870,075 -- huge!\n- The largest occupancy costs are for days where the occupancy is high and the change in occupancy is high, due to the Nd^(...(Nd - Nd1)) term.  This is a warning for D=1 scheduling ... if we put a lot of people there (due to the large number of families with D=1 as their top choice) and there's a large change from D=1 to D=2 (because many fewer people want D=2) the occupancy penalty will be huge."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}