{"cells":[{"metadata":{"_uuid":"c12ad1f0277ba4d2c099eaa625f6800b7e209faf"},"cell_type":"markdown","source":"### The majority part of code is based on fastai ML course - https://course.fast.ai/lessonsml1/lesson1.html. This kernel embark on my journey to the universe of kaggle.  My initial draft consists of concepts from the first lecture. I have tried not to use all the functions from fastai, but I still I couldn't completely resist myself from not using them at all and implemented the model as per my understanding.  It is an initial model. I will tune it as I will move ahead with the course materials."},{"metadata":{"trusted":true,"_uuid":"46fbc9e6fe44dfa14b6432f571527280ece0a619"},"cell_type":"code","source":"from fastai.imports import *\nfrom fastai.structured import *\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"542a346865eb326300dba39c132182671bf8c3ef"},"cell_type":"code","source":"import os\nos.listdir(\"../input/train/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"162910657045f31a3ec160cc3a70ae07dc799714"},"cell_type":"code","source":"df=pd.read_csv('../input/train/Train.csv',low_memory=False,parse_dates=[\"saledate\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa5ed707d10591db51033fc8bc68f3e139e6ae04"},"cell_type":"code","source":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52976c534ed32b55815773592146eb0973c0917d"},"cell_type":"code","source":"display_all(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af16de03307e86febcc302c44df5482c518d210d"},"cell_type":"code","source":"df=df.sort_values('saledate').copy()\n## It is necessary to sort time series data.\n#If your dataset has a time piece in it (as is in Blue Book competition), \n#you would likely want to predict future prices/values/etc. \n#What Kaggle did was to give us data representing a particular date range in the training set, \n#and then the test set presented a future set of dates that wasnâ€™t represented in the training set. \n#So we need to create a validation set that has the same properties:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b02b894525c581d55cd73db6e215cd1130302a3"},"cell_type":"code","source":"df['SalePrice']=np.log(df['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6151db49a7b78d619c96546620dfcedcb295de7"},"cell_type":"code","source":"df['saledate'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2694a7817c7f7fd1252e7d74c405a17f5721ed87"},"cell_type":"code","source":"df1=df.copy() ## making a copy of df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2857b81ac282cd93f594202c053779deb65c0385"},"cell_type":"code","source":"#convert object into categorical\nfor i in df.select_dtypes(include='object').columns:\n    df[i]=df[i].astype('category')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ded095ea76218256e71f34f766fee23f4e03b54"},"cell_type":"code","source":"## Find columns with more than 80% missing values\n#s=pd.DataFrame((df.isnull().sum().sort_values(ascending=False))/df.shape[0],columns=['Percentage'])\n#s.reset_index(inplace=True)\n#replaceC=s[s['Percentage'] < 0.80]['index']\n## replaced missing columns\n#df2=df[np.array(replaceC)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d9f3627234072176991a79256d4b31fdaa48822"},"cell_type":"code","source":"df2=df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db59b3e3e7c2984b75daa73932f65695c7706ac1"},"cell_type":"code","source":"#Fill numeric columns with mean\n#intC=df2.select_dtypes(include=['int64','float64']).isna().sum().index\nd=pd.DataFrame(df2.select_dtypes(include=['int64','float64']).isna().sum(),columns=['Count'])\nintC=d[d['Count']>0].index\nfor c in np.array(intC):\n    df2[c+'_na'] = df2[c].isnull()\n    df2[c]=df2[c].fillna(df[c].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913fe3ff559c98b87f526d804fefa24e91dc0655"},"cell_type":"code","source":"df.shape,df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48c95686aee30c4f7da779ff40d8d6a220cf76fb"},"cell_type":"code","source":"# Fill cateogorical columns with cat.codes\nintC=df2.select_dtypes(include='category').columns\n#intC=d2[d2['Count']>0].index\nfor c in intC:\n    df2[c]=df2[c].cat.codes+1 # codes of missing data is -1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53db5dfd1f960964e129aaa513a9b590f8d2c56a"},"cell_type":"code","source":"## Check missing\ndf2.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcf314aa968603333e54eb252e308ec67e032ca3"},"cell_type":"code","source":"display_all(df2.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f886760cb5afe30f976e5f23ef650cd3b7e36d82"},"cell_type":"code","source":"add_datepart(df2, 'saledate')\n##Above function is from fastai.structured.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4f830a2547daf6299138479b8087683dbc832e2"},"cell_type":"code","source":"X=df2.drop(['SalePrice'],axis=1)\nY=df2['SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6191a511fe7fb67fedadaa4e7d390a1b37070cc1"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr=RandomForestRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb39f65c21c69611f576fbdde14feb88d3128051"},"cell_type":"code","source":"rfr.fit(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e48605eeaf9ddbcccce94d1978ccd6fcd6cc864"},"cell_type":"code","source":"rfr.score(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdf5e191a8db2c9efa310d90b2841d7563bcf210"},"cell_type":"code","source":"import math\ndef rmse(x,y): return math.sqrt(((x-y)**2).mean())\nrmse(rfr.predict(X), Y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"470c7e4eb286bb82a42a7442d789f65793cd27a2"},"cell_type":"code","source":"# We can't use the below function as we don't want to split the dataset randomly. \n#from sklearn.model_selection import train_test_split\n#X_Train,X_Test,Y_Train,Y_Test= train_test_split(X,Y,test_size=1200,random_state=10)\n#rr=RandomForestRegressor()\ndef split_vals(a,n): return a[:n].copy(), a[n:].copy()\nn_valid=12000\nn_trn = len(df2)-n_valid\nraw_train, raw_valid = split_vals(df, n_trn)\nX_Train, X_Test = split_vals(X, n_trn)\nY_Train, Y_Test = split_vals(Y, n_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f13c758c097398a20814529ebfc61f7b6e88bf7"},"cell_type":"code","source":"print(X_Train.shape,X_Test.shape,Y_Train.shape,Y_Test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a91448b1deeb1e9651e7f556c1a1f4a6239a042a"},"cell_type":"code","source":"def score(model,X_Train,Y_Train,X_Test,Y_Test):\n    if hasattr(model, 'oob_score_'): \n        print(\"Training Score : \"+ str(model.score(X_Train,Y_Train))  + \" Test Score : \" + str(model.score(X_Test,Y_Test)) + \" OOb score : \" + str(model.oob_score_) + \" RMSE Training : \" + str(rmse(model.predict(X_Train), Y_Train)) + \" RMSE Test : \" + str(rmse(model.predict(X_Test), Y_Test)) )\n    else:\n        print(\"Training Score : \"+ str(model.score(X_Train,Y_Train))  + \" Test Score : \" + str(model.score(X_Test,Y_Test)) + \" RMSE Training : \" + str(rmse(model.predict(X_Train), Y_Train)) + \" RMSE Test : \" + str(rmse(model.predict(X_Test), Y_Test)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebf934aabbaaedf6f7c0161d102aef797b07b19d"},"cell_type":"code","source":"rfr=RandomForestRegressor()\n%time rfr.fit(X_Train,Y_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a98e9c3bc384991d0adffd02d7b670e3acde583"},"cell_type":"code","source":"score(rfr,X_Train,Y_Train,X_Test,Y_Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f6d83f3f4a77f4215698ac636dfad8b037759cb"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"c5b49e1847f5089d88f1045c6ae8058d93eb93b2"},"cell_type":"markdown","source":"We will try to reduce the overfitting now.  \n\n## Out of Box Technique\nIf our training set is small, and it's not possible to get a dev or validation set, RF has a technique called OOB.\nIt recognizes unused rows and treat them  as a validation set\nThus, we will have different validation set for each tree.\nFor prediction, we will average all of the trees where that row is not used for training.\n\n\nWe will also try to change the sample size to 20000 to train the model."},{"metadata":{"trusted":true,"_uuid":"ca7a3fd1e0f8dcebd631ca830d5677f8fad44043"},"cell_type":"code","source":"set_rf_samples(20000) ## Changes Scikit learn's random forests to give each tree a random sample of n random rows.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a33d9ddf5d6646413163178e7b049c03fa29c2a5"},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=20,n_jobs=-1, oob_score=True)\n%time m.fit(X_Train, Y_Train)\nscore(m,X_Train,Y_Train,X_Test,Y_Test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d91f9541ebdf34a39a3c5cd0c74a0377f368f96"},"cell_type":"markdown","source":"Variance between training and test score has been reduced now.\n\nLet's explore other ways to reduce overfitting."},{"metadata":{"trusted":true,"_uuid":"0b164fd0cf30d415c7b1184974f108c9dc5476e5"},"cell_type":"code","source":"reset_rf_samples() ## reset Random forest samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cbdcf5f87bca46fe9d2a81551b809bd81d4a72b"},"cell_type":"code","source":"# Using min_samples_leaf and max_features\nm = RandomForestRegressor(n_estimators=40,n_jobs=-1, oob_score=True, min_samples_leaf=3,max_features=0.5)\n%time m.fit(X_Train, Y_Train)\nscore(m,X_Train,Y_Train,X_Test,Y_Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37af1a1e563e4b9eacfd77bc33fabf6581defdb8"},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=60,n_jobs=-1, oob_score=True, min_samples_leaf=5,max_features=0.5)\n%time m.fit(X_Train, Y_Train)\nscore(m,X_Train,Y_Train,X_Test,Y_Test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05eb9267babadec2192f596e79df5a99f84c4e65"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}