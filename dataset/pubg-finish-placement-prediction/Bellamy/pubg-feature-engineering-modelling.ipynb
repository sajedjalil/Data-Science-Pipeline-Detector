{"cells":[{"metadata":{"_uuid":"1c592418a9ebedbf2d6aadfc819d0c18aa9bc7f2"},"cell_type":"markdown","source":"# Feature Engineering of PUBG data with Model Developement\n\nI previously created a notebook going through some [exploratory anaylsys] of the PUBG data. I went through many of the different features avalailable and displayed an interesting plot describing the data and potential correlation with the target variable.\n\n* I found that there was one missing value for the target variable and decided that this row of data should be removed, as there was only one player for the match identified by the missing value.\n\n* I also made a few decisions about creating new features and one important way of breaking the data up to gain higher correllations with our features for seperate match types.\n\n[exploratory anaylsys]: https://www.kaggle.com/beaubellamy/pubg-eda#"},{"metadata":{"_uuid":"363226b9fe854d7a825a17e6c2eca55ff5c756c7"},"cell_type":"markdown","source":"## Import libraries\nWe import the required libraries and import the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nsns.set()\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train_V2.csv')\ntest = pd.read_csv('../input/test_V2.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc90a34196fbffc09ef9a9f14cc99c1abb275b5d"},"cell_type":"markdown","source":"Lets check out the data again."},{"metadata":{"trusted":true,"_uuid":"59fee04c6a6a4285dfc6b54e3c6e18ff71768a93"},"cell_type":"code","source":"\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb627ae368d79493b831acb7c3b222bf7014d186"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d23e88ceebc824b4d7686fe98dc5c23e6c1bbdf5"},"cell_type":"markdown","source":"## Missing Data\nBased on our EDA, we found a row that had a NULL value for the target variable. We will remove the irrelevant row of data."},{"metadata":{"trusted":true,"_uuid":"90cf3cfbb4f386335af97e836b7e442f940bc9cc"},"cell_type":"code","source":"# Remove the row with the missing target value\ntrain = train[train['winPlacePerc'].isna() != True]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"627ead1a30264239d56af16da9b08925fde68501"},"cell_type":"markdown","source":"## Lets Engineer some features\nWe'll process the testing data the same way we do for the training data so the testing data has the same features and scaling as our training data.\n\n### PlayersJoined\nWe can determine the number of players that joined each match by grouping the data by matchID and counting the players."},{"metadata":{"trusted":true,"_uuid":"db2303527c8ecb0a4fca2b3a430c4295ca7c1796"},"cell_type":"code","source":"# Add a feature containing the number of players that joined each match.\ntrain['playersJoined'] = train.groupby('matchId')['matchId'].transform('count')\ntest['playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e3477d006f25e4b9e01fade4c0917fac70ffcde"},"cell_type":"code","source":"# Lets look at only those matches with more than 50 players.\n#data = train[train['playersJoined'] > 50]\n\n#plt.figure(figsize=(15,15))\n#sns.countplot(data['playersJoined'].sort_values())\n#plt.title('Number of players joined',fontsize=15)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3eae047591d0e6db4f2467bbb3283d47db19fec"},"cell_type":"markdown","source":"You can see that there isn't always 100 players in each match, in fact its more likely to have between 90 and 100 players. It may be benficial to normalise those features that are affected by the number of players.\n\n### Normalised Features\nHere, I am making the assumption that it is easier to find an enemy when there are 100 players, than it is when there are 90 players.\n"},{"metadata":{"trusted":true,"_uuid":"9c25114718a07ecf171f6bbdb3f8c74e966f399b"},"cell_type":"code","source":"def normaliseFeatures(train):\n    train['killsNorm'] = train['kills']*((100-train['playersJoined'])/100 + 1)\n    train['headshotKillsNorm'] = train['headshotKills']*((100-train['playersJoined'])/100 + 1)\n    train['killPlaceNorm'] = train['killPlace']*((100-train['playersJoined'])/100 + 1)\n    train['killPointsNorm'] = train['killPoints']*((100-train['playersJoined'])/100 + 1)\n    train['killStreaksNorm'] = train['killStreaks']*((100-train['playersJoined'])/100 + 1)\n    train['longestKillNorm'] = train['longestKill']*((100-train['playersJoined'])/100 + 1)\n    train['roadKillsNorm'] = train['roadKills']*((100-train['playersJoined'])/100 + 1)\n    train['teamKillsNorm'] = train['teamKills']*((100-train['playersJoined'])/100 + 1)\n    train['damageDealtNorm'] = train['damageDealt']*((100-train['playersJoined'])/100 + 1)\n    train['DBNOsNorm'] = train['DBNOs']*((100-train['playersJoined'])/100 + 1)\n    train['revivesNorm'] = train['revives']*((100-train['playersJoined'])/100 + 1)\n\n    # Remove the original features we normalised\n    train = train.drop(['kills', 'headshotKills', 'killPlace', 'killPoints', 'killStreaks', \n                        'longestKill', 'roadKills', 'teamKills', 'damageDealt', 'DBNOs', 'revives'],axis=1)\n\n    return train\n\ntrain = normaliseFeatures(train)\ntest = normaliseFeatures(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5996305e8c7a615bde60829be74c19c82bbb713"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"565787b793b989b5d51e67326f9df0f99387569e"},"cell_type":"markdown","source":"### TotalDistance\nAn additional feature we can create is the total distance the player travels. This is a combination of all the distance features in the original data set."},{"metadata":{"trusted":true,"_uuid":"7c9cb57049be6172d5c6bd1f7403041824efd7c0"},"cell_type":"code","source":"# Total distance travelled\ntrain['totalDistance'] = train['walkDistance'] + train['rideDistance'] + train['swimDistance']\ntest['totalDistance'] = test['walkDistance'] + test['rideDistance'] + test['swimDistance']\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b37809c8ec4d04e57898b3ada407006e63d4181"},"cell_type":"markdown","source":"# Standardize the matchType feature\nHere I decided that many of the existing 16 seperate modes of game play were just different versions of four types of game.\n\n1. Solo: Hunger Games style, last man/women standing.\n2. Duo: Teams of two against all other players.\n3. Squad: Teams of up to 4 players against All other players\n4. Other: These modes consist of custom and special events modes"},{"metadata":{"trusted":true,"_uuid":"94e0117b066266679ee5643b6b4161797e5f3c4c"},"cell_type":"code","source":"# Normalise the matchTypes to standard fromat\ndef standardize_matchType(data):\n    data['matchType'][data['matchType'] == 'solo'] = 'Solo'\n    data['matchType'][data['matchType'] == 'normal-solo'] = 'Solo'\n    data['matchType'][data['matchType'] == 'solo-fpp'] = 'Solo'\n    data['matchType'][data['matchType'] == 'normal-solo-fpp'] = 'Solo'\n    data['matchType'][data['matchType'] == 'normal-duo-fpp'] = 'Duo'\n    data['matchType'][data['matchType'] == 'normal-duo'] = 'Duo'\n    data['matchType'][data['matchType'] == 'duo'] = 'Duo'\n    data['matchType'][data['matchType'] == 'duo-fpp'] = 'Duo'\n    data['matchType'][data['matchType'] == 'squad'] = 'Squad'\n    data['matchType'][data['matchType'] == 'squad-fpp'] = 'Squad'\n    data['matchType'][data['matchType'] == 'normal-squad'] = 'Squad'\n    data['matchType'][data['matchType'] == 'normal-squad-fpp'] = 'Squad'\n    data['matchType'][data['matchType'] == 'flaretpp'] = 'Other'\n    data['matchType'][data['matchType'] == 'flarefpp'] = 'Other'\n    data['matchType'][data['matchType'] == 'crashtpp'] = 'Other'\n    data['matchType'][data['matchType'] == 'crashfpp'] = 'Other'\n\n    return data\n\n\ntrain = standardize_matchType(train)\ntest = standardize_matchType(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62a6f6b2eeb8c34b70843a5df7d015d85b02a972"},"cell_type":"code","source":"# We need a copy of the test data with the player id later on\ntest_submission = test.copy()\n\ntrain = train.drop(['Id','groupId','matchId'], axis=1)\ntest = test.drop(['Id','groupId','matchId'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24907eae0862b4354706aed72bb7fca29391944f"},"cell_type":"code","source":"# We need to keep a copy of the test data for the test id's later \ntrain_copy = train.copy()\ntest_copy = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"980e01433dbefcb4bd3269669465b3e6c2bccdd5"},"cell_type":"markdown","source":"Now we can transform the matchTypes into dummy values so we can use them in the model."},{"metadata":{"trusted":true,"_uuid":"780310f7f4fc97455589c6a7a915c84ebbaaa08c"},"cell_type":"code","source":"# Transform the matchType into scalar values\nle = LabelEncoder()\ntrain['matchType']=le.fit_transform(train['matchType'])\ntest['matchType']=le.fit_transform(test['matchType'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db727750a32ed96e38a0602b85db869a0700e0b9"},"cell_type":"code","source":"# We can do a sanity check of the data, making sure we have the new \n# features created and the matchType feature is standardised.\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0c82acaa8fecd6b2089ceadf724b4e3c32b7c54"},"cell_type":"markdown","source":"# Scale the features\nSome features have very large values and a vary large variance. For any regresion analysis, it is good practice to scale all features to similar variance. This would not be neccessary if the variance of all features was between 6 and 10."},{"metadata":{"trusted":true,"_uuid":"5d710a638a6cd63130dac34e83c0ebb1102ba0d0"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3202fe27a7d22b7d011068f5b35e3df95645b93f"},"cell_type":"markdown","source":"You can see most features range 0 to 100 or 1000's, but there are two features that doesn't really need scaling, VehicleDestroys and matchType, as they only range between 0 to 5, 6. Its not neccassary to scale these features, but we will any way, because it makes the code easier."},{"metadata":{"trusted":true,"_uuid":"e3478558c107dca6fdc27eb820b5a1b5bdf069e4"},"cell_type":"code","source":"scaler = MinMaxScaler()\ntrain_scaled = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)\n\ntest_scaled = pd.DataFrame(scaler.fit_transform(test), columns=test.columns)\n\ntrain_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc93d5c7f80a56b1c57ab37d2a94d96c1ba35f69"},"cell_type":"code","source":"train_scaled.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6aa9ab0275e5f079210fbbe362d8d61ce4d8185"},"cell_type":"markdown","source":"As you can see, all the features have the same minimum, maximum and standard deviation. All our features are now normalised and scaled for modelling.\n\n# Model Developement\n\nThe great thing about programming is that you can automate so much. That's what we are going to do here, we'll try to fit the data using a group of models with some basic settings. We could try to use a gridsearch method to search for the best hyper parameters for each model to truly define the \"best\" model, but this is a Kernel only competition and I dont have a vast amount of memory on my local machine (only 8GB). So my strategy here will be to;\n\n1. Fit a group of models using the all features available.\n2. Fit a group of models using feature selection. We'll select our features using multicollinearity and the variance inflation factor.\n3. Seperate the matchTypes into four seperate data sets, as described in my [exploratory analysis], and fit the group of models to each matchType data set.\n  * We'll combine the predictions of these into one submission at the end.\n\nEach time we will pick the best model and fit the full data set to obtain the best predictions.\n\nI would expect a linear regression model to perform reasonably well due to what we found in the [exploratory anaylsys].\n\n\n[exploratory anaylsys]: https://www.kaggle.com/beaubellamy/pubg-eda#"},{"metadata":{"trusted":true,"_uuid":"1bdf496f5756dd8ed0a85149e4959021a1327b0d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db497504ad394726c89ad83df5c7c829148285d9"},"cell_type":"code","source":"# Create a master copy of the data, so we can restore the default features.\n#train_master = train_scaled.copy()\n\n# Extract the target variable.\ny = train_scaled['winPlacePerc']\nX = train_scaled.drop(['winPlacePerc'],axis=1)\n\n# Split the data in to training and validation set\nsize = 0.3\nseed = 42\n   \nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=size, random_state=seed)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e79014f87e67abe257c1dda04e82b61ec1a37e4c"},"cell_type":"markdown","source":"Lets create a function to run all the models we want. I'm typically only running this on a Dell laptop (i7 core @ 2.4GHz, 8GB RAM), so it may take an hour or two to complete. \n\nOne way to reduce this is to just subsample the data from the beginning with `train = train[0:1000000]` or even better using random sampling without replacement to select the indecies`train[random.sample(range(0, len(train)), 1000000)]`"},{"metadata":{"trusted":true,"_uuid":"caf2ab4cc2c6b6abedb6bdb6949c2bc462860ec6"},"cell_type":"code","source":"# The function takes the training and validation data to fit and score a group of models\ndef runAllModels(X_train, X_validation, Y_train, Y_validation):\n        \n    linear = LinearRegression(copy_X=True)\n    linear.fit(X_train,Y_train)\n    print(\"Linear Model score: {0:.3f}%\".format(linear.score(X_validation,Y_validation)*100))\n\n    ridge = Ridge(copy_X=True)\n    ridge.fit(X_train,Y_train)\n    print(\"Ridge Model score: {0:.3f}%\".format(ridge.score(X_validation,Y_validation)*100))\n\n    lasso = Lasso(copy_X=True)\n    lasso.fit(X_train,Y_train)\n    print(\"Lasso Model score: {0:.3f}%\".format(lasso.score(X_validation,Y_validation)*100))\n\n    elastic = ElasticNet(copy_X=True)\n    elastic.fit(X_train,Y_train)\n    print(\"ElasticNet Model score: {0:.3f}%\".format(elastic.score(X_validation,Y_validation)*100))\n\n    ada = AdaBoostRegressor(learning_rate=0.8)\n    ada.fit(X_train,Y_train)\n    print(\"AdaBoostRegressor Model score: {0:.3f}%\".format(ada.score(X_validation,Y_validation)*100))\n\n    GBR = GradientBoostingRegressor(learning_rate=0.8)\n    GBR.fit(X_train,Y_train)\n    print(\"GradientBoostingRegressor Model score: {0:.3f}%\".format(GBR.score(X_validation,Y_validation)*100))\n\n    forest = RandomForestRegressor(n_estimators=10)\n    forest.fit(X_train,Y_train)\n    print(\"RandomForestRegressor Model score: {0:.3f}%\".format(forest.score(X_validation,Y_validation)*100))\n\n    tree = DecisionTreeRegressor()\n    tree.fit(X_train,Y_train)\n    print(\"DecisionTreeRegressor Model score: {0:.3f}%\".format(tree.score(X_validation,Y_validation)*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df6e7ba534612c9ea8d6888be8cf015e3ea30096"},"cell_type":"code","source":"train_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"696500a78ad5aa7e32ba74c83937fc56a6578feb"},"cell_type":"code","source":"test_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"668ce998bcd4377fcf20635e1a0fb4588ea3d4d4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86f0743c0f4a8a24892aa373721ef398537c2a14"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7fbc878d5b0155bcc09b2144bf0672949b99f01"},"cell_type":"code","source":"runAllModels(X_train, X_validation, Y_train, Y_validation)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bee0c90c2a06c2342eff062a1f5a492552415cc"},"cell_type":"markdown","source":"The linear regression models performed reasonably well, but it seems there are some better models available, Gradient Boost or Random Forest would be a good choice.\n\nWe'll Choose the **Gradient Boost Regressor** to make our predictions."},{"metadata":{"trusted":true,"_uuid":"d6bab8b4cbeae6fc436c76a954505a1b434bfa4e"},"cell_type":"code","source":"GBR = GradientBoostingRegressor(learning_rate=0.8)\nGBR.fit(X,y)\n\npredictions_all = GBR.predict(test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c68dd021ddefb7c8c99a5b4c5f90ba78fc5c2d6"},"cell_type":"markdown","source":"# Model Development with feature selection\nWe can use Multicolinearity to see what features are collinear with each other to help decide which features to remove.\n\n## Multicollinearity\n[Multicollinearity] exists whenever two or more of the predictors in a regression model are moderately or highly correlated. There are two types of multicollinearity:\n1. **Structural multicollinearity** is a mathematical artifact caused by creating new predictors from other predictors â€” such as, creating the predictor *x*<sup>2</sup> from the predictor *x*.\n2. **Data-based multicollinearity** is a result of a poorly designed experiment, reliance on purely observational data, or the inability to manipulate the system on which the data are collected.\n\nWhat this really means is that when predictor variables are correlated, the estimated regression coefficient of any one variable will depend on which predictor variables, and in which order, are included in the model.\n\n## Variance Inflation Factor\nAs the name suggests, the [variance inflation factor] is a measure of how much the variance of a coefficient is inflated by when multicollinearity exists. We will use this to determine which features to keep and which to discard.\n\nThe general rul of thumb is that a VIF of 4 - 10 should be investigated further, and anything above 10 indicates a serious multicollinearity that needs to be corrected. We will correct it by removeing the features with a VIF >= 10\n\n[Ordinal regresion]: https://en.wikipedia.org/wiki/Ordinal_regression\n[Multicollinearity]: https://onlinecourses.science.psu.edu/stat501/node/344/\n[variance inflation factor]: https://en.wikipedia.org/wiki/Variance_inflation_factor"},{"metadata":{"trusted":true,"_uuid":"eba86818d8d44da1679a7074d3e479bfad8f3f31"},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef display_VIF(data):\n    x_features=list(data)\n    data_mat = data[x_features].as_matrix()                                                                                                              \n    vif = [ variance_inflation_factor( data_mat,i) for i in range(data_mat.shape[1]) ]\n    vif_factors = pd.DataFrame()\n    vif_factors['Feature'] = list(x_features)\n    vif_factors['VIF'] = vif\n    \n    return vif_factors\n\nvif = display_VIF(train_scaled)\nvif.sort_values(by=['VIF'],ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bd33a2a06f007f9ba8022e93131c1df7bfa219f"},"cell_type":"markdown","source":"You can see that there are a number of features that are extremely multicollinear with other features in the data set. We will drop the features with the largest VIF and have another look at the variance inflation factor of the remaining features."},{"metadata":{"trusted":true,"_uuid":"078835c6095815ee06e7b675a914b0dc4f088344"},"cell_type":"code","source":"# Drop the features with the largest VIF and check for multicollinearity\ntrain_scaled = train_scaled.drop(['totalDistance','rideDistance','swimDistance','walkDistance','numGroups','maxPlace',\n                                 'playersJoined','winPoints','rankPoints'], axis=1)\ntest_scaled = test_scaled.drop(['totalDistance','rideDistance','swimDistance','walkDistance','numGroups','maxPlace',\n                                 'playersJoined','winPoints','rankPoints'], axis=1)\n\nvif = display_VIF(train_scaled)\nvif.sort_values(by=['VIF'],ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0109ccb8aa73f4bac298ceb8ee6485f484e68cd5"},"cell_type":"markdown","source":"You can see that removing some the the features with the highest VIF reduces the VIF for most of the remaining features, some more than others. The matchDuration and KillPlaceNorm have almost halved. We'll drop the remaining features with a VIF > 10 and keep the rest to build our model. We may decide to remove more later."},{"metadata":{"trusted":true,"_uuid":"311c22ce6b407756ab9bce1de009c0261c2d8808"},"cell_type":"code","source":"# Drop the the remaining features that have a VIF greater than 10.\ntrain_scaled = train_scaled.drop(['matchDuration','killsNorm','killPlaceNorm'], axis=1)\ntest_scaled = test_scaled.drop(['matchDuration','killsNorm','killPlaceNorm'], axis=1)\n\nvif = display_VIF(train_scaled)\nvif.sort_values(by=['VIF'],ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c91e9812da1b8adcce54e634c30bf3e661d67fef"},"cell_type":"markdown","source":"Lets have a look at the pearson correlation between all the remaining features."},{"metadata":{"trusted":true,"_uuid":"aece5f5246dccbc9a2f5798744ecfc05ce85f5d7"},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(train_scaled.corr(), annot=True, linewidths=.5, fmt= '.2f',ax=ax)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"218e54c80b3de485235db2460fb5525fe769653f"},"cell_type":"code","source":"train_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45e60a46961bd09347cfd0b64609b71a9d0a2437"},"cell_type":"markdown","source":"Because we are removing some features we need to perform the training testing split again on the new features."},{"metadata":{"trusted":true,"_uuid":"269ecd54461d174e664fb9bde9723b4204fc9357"},"cell_type":"code","source":"\n# Train Test Split\ny = train_scaled['winPlacePerc']\nX = train_scaled.drop(['winPlacePerc'],axis=1)\n\n# We will maintain the existing size and random state parameters for repeatability.\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=size, random_state=seed)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99154fa564777c9dd010849b49cfee7a9c475a30"},"cell_type":"code","source":"# Run all models with the reduced set of features.\nrunAllModels(X_train, X_validation, Y_train, Y_validation)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c95d3fea77ce59f605374ab62d5bf2fe2bfbbc39"},"cell_type":"markdown","source":"Dropping all those features we identified as having a high multicolinearity with other features has reduced the accuracey of all the models we tried. So we will reinstate all those features for the next iteration of models. We probably wouldn't use any of these models for predictions since we already have bettor models with all the features.\n\nSo we wont use the reduced set of features to fit to the \"best\" model because we already have a model that does better with all the features."},{"metadata":{"trusted":true,"_uuid":"b1fd1c9071148f3377ae25565740df0ecac58ee0"},"cell_type":"markdown","source":"# Model Development for seperate matchTypes\nAgain, with the insight we learnt from our [EDA], we found that it is likely that we will improve our overall results by creating four seperate models, one for each matchType. This allows us to potentially use a seperate type of model for each matchType.\n\nHere we'll split the data into the matchTypes and see how the models perform for each one.\n\n[EDA]: https://www.kaggle.com/beaubellamy/pubg-eda#"},{"metadata":{"trusted":true,"_uuid":"ce5ca51355ecccadc8d7f4890afe111db432f2d9"},"cell_type":"code","source":"train_copy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da6a24645579f85f2c3f9e5d7546eb03bfb6d6f9"},"cell_type":"code","source":"# Create a data set for each matchType and drop that feature, as there will be no variance, and hence no predictive power.\nsolo = train_copy[train_copy['matchType'] == 'Solo']\nsolo = solo.drop(['matchType'], axis=1)\nduo = train_copy[train_copy['matchType'] == 'Duo']\nduo = duo.drop(['matchType'], axis=1)\nsquad = train_copy[train_copy['matchType'] == 'Squad']\nsquad = squad.drop(['matchType'], axis=1)\nother = train_copy[train_copy['matchType'] == 'Other']\nother = other.drop(['matchType'], axis=1)\n\n# since we used a copy of the trained data that hasn't been scaled, we need to scale the features again.\nscaler = MinMaxScaler()\nsolo_scaled = pd.DataFrame(scaler.fit_transform(solo), columns=solo.columns)\nduo_scaled = pd.DataFrame(scaler.fit_transform(duo), columns=duo.columns)\nsquad_scaled = pd.DataFrame(scaler.fit_transform(squad), columns=squad.columns)\nother_scaled = pd.DataFrame(scaler.fit_transform(other), columns=other.columns)\n\n# Seperate the matchType data\ntest_solo = test_copy[test_copy['matchType'] == 'Solo']\ntest_solo = test_solo.drop(['matchType'], axis=1)\ntest_duo = test_copy[test_copy['matchType'] == 'Duo']\ntest_duo = test_duo.drop(['matchType'], axis=1)\ntest_squad = test_copy[test_copy['matchType'] == 'Squad']\ntest_squad = test_squad.drop(['matchType'], axis=1)\ntest_other = test_copy[test_copy['matchType'] == 'Other']\ntest_other = test_other.drop(['matchType'], axis=1)\n\nsolo_test_scaled = pd.DataFrame(scaler.fit_transform(test_solo), columns=test_solo.columns)\nduo_test_scaled = pd.DataFrame(scaler.fit_transform(test_duo), columns=test_duo.columns)\nsquad_test_scaled = pd.DataFrame(scaler.fit_transform(test_squad), columns=test_squad.columns)\nother_test_scaled = pd.DataFrame(scaler.fit_transform(test_other), columns=test_other.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8e0f92389caea6f65179c5670bb4e3f4385a851"},"cell_type":"code","source":"solo_y = solo_scaled['winPlacePerc']\nsolo_X = solo_scaled.drop(['winPlacePerc'],axis=1)\n\n# We will maintain the existing size and random state parameters for repeatability.\nX_train, X_validation, Y_train, Y_validation = train_test_split(solo_X, solo_y, test_size=size, random_state=seed)\n\nrunAllModels(X_train, X_validation, Y_train, Y_validation)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3d651f87f97a77c9d3c283c427dd047d049c240"},"cell_type":"markdown","source":"The model that performed the best for the solo matches was a GradientBoostingRegressor model with a score of 95.0%"},{"metadata":{"trusted":true,"_uuid":"fc13b72e3952cb2b9903543043339691338a4973"},"cell_type":"code","source":"GBR = GradientBoostingRegressor(learning_rate=0.8)\nGBR.fit(solo_X,solo_y)\nprint(\"GradientBoost Model traininig: {0:.3f}%\".format(GBR.score(solo_X,solo_y)*100))\n\npredictions_solo = GBR.predict(solo_test_scaled)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"691f37089b85549ec6ad3ab462b888ae9f38360d"},"cell_type":"code","source":"duo_y = duo_scaled['winPlacePerc']\nduo_X = duo_scaled.drop(['winPlacePerc'],axis=1)\n\n# We will maintain the existing size and random state parameters for repeatability.\nX_train, X_validation, Y_train, Y_validation = train_test_split(duo_X, duo_y, test_size=size, random_state=seed)\n\nrunAllModels(X_train, X_validation, Y_train, Y_validation)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af262fccd7192f2f6dbdfc1ebe0acc7acb3e93c2"},"cell_type":"markdown","source":"The model that performed the best for the duo matches was a GradientBoostingRegressor model, with a score of 94.4%"},{"metadata":{"trusted":true,"_uuid":"30e9a36ae412bb7ac610b6af956d7b49109f0a84"},"cell_type":"code","source":"GBR = GradientBoostingRegressor(learning_rate=0.8)\nGBR.fit(duo_X,duo_y)\nprint(\"GradientBoost Model traininig: {0:.3f}%\".format(GBR.score(duo_X,duo_y)*100))\n\npredictions_duo = GBR.predict(duo_test_scaled) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62f2d77ab8cc7be6c4f357009d092397650b2bc1"},"cell_type":"code","source":"squad_y = squad_scaled['winPlacePerc']\nsquad_X = squad_scaled.drop(['winPlacePerc'],axis=1)\n\n# We will maintain the existing size and random state parameters for repeatability.\nX_train, X_validation, Y_train, Y_validation = train_test_split(squad_X, squad_y, test_size=size, random_state=seed)\n\nrunAllModels(X_train, X_validation, Y_train, Y_validation)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6714a32addde0afe1b19590be1108a7f4010876"},"cell_type":"markdown","source":"The model that performed the best for the squad matches was GradientBoostRegressor, with a score of 90.7%"},{"metadata":{"trusted":true,"_uuid":"a2b10f468b50ef91379f498987f45f017a68d073"},"cell_type":"code","source":"GBR = GradientBoostingRegressor(learning_rate=0.8)\nGBR.fit(squad_X,squad_y)\nprint(\"GradientBoost Model traininig: {0:.3f}%\".format(GBR.score(squad_X,squad_y)*100))\n\npredictions_squad = GBR.predict(squad_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e99a695d173a29996f38865f8517ca1dddf9a9c7"},"cell_type":"code","source":"other_y = other_scaled['winPlacePerc']\nother_X = other_scaled.drop(['winPlacePerc'],axis=1)\n\n# We will maintain the existing size and random state parameters for repeatability.\nX_train, X_validation, Y_train, Y_validation = train_test_split(other_X, other_y, test_size=size, random_state=seed)\n\nrunAllModels(X_train, X_validation, Y_train, Y_validation)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"542e31d0213680a987157557830b05f12e784cd4"},"cell_type":"markdown","source":"The model that performed the best for the other matches was the simple GradientBoostingRegressor, with a score of 83.1%\n\nThe Linear Regression model probably won here, because there isn't that much data available on these types of matches compared to the other match types."},{"metadata":{"trusted":true,"_uuid":"fec9ec2fee5aa469017066e498f36220803eaf98"},"cell_type":"code","source":" \nGBR = GradientBoostingRegressor(learning_rate=0.8)\nGBR.fit(other_X,other_y)\nprint(\"GradientBoost Model traininig: {0:.3f}%\".format(GBR.score(other_X,other_y)*100))\n\npredictions_other = GBR.predict(other_test_scaled) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1e3b982f25533afab67571c4d8362ee25e93fe0"},"cell_type":"code","source":"def create_submission(submission_Id, predictions, filename):\n    submission = pd.DataFrame({'Id': submission_Id, 'winPlacePerc': predictions})\n    \n    submission.to_csv(filename+'.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4b6723b4a8d02d17be437002c6944d110f69d5f"},"cell_type":"code","source":"test_submission_solo = test_submission[test_submission['matchType'] == 'Solo']\ntest_submission_duo = test_submission[test_submission['matchType'] == 'Duo']\ntest_submission_squad = test_submission[test_submission['matchType'] == 'Squad']\ntest_submission_other = test_submission[test_submission['matchType'] == 'Other']\n\nmatchTypeId = test_submission_solo['Id'].append(test_submission_duo['Id']).append(test_submission_squad['Id']).append(test_submission_other['Id'])\n\npredictions_solo[predictions_solo > 1] = 1\npredictions_solo[predictions_solo < 0] = 0\n\npredictions_duo[predictions_duo > 1] = 1\npredictions_duo[predictions_duo < 0] = 0\n\npredictions_squad[predictions_squad > 1] = 1\npredictions_squad[predictions_squad < 0] = 0\n\npredictions_other[predictions_other > 1] = 1\npredictions_other[predictions_other < 0] = 0\n\n\npredications_matchtype = np.append(np.append(predictions_solo,predictions_duo),np.append(predictions_squad,predictions_other))\n\ncreate_submission(matchTypeId, predications_matchtype, 'submission_matchType')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b964521d90330ffe2d49627fac98becaf1af3729"},"cell_type":"markdown","source":"If you liked this post, please upvote."},{"metadata":{"trusted":true,"_uuid":"91a5398fa241c0122da13c5464ef46f1455232bb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}