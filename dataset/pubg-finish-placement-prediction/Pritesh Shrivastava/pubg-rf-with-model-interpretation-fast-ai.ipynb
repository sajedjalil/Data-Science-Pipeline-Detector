{"cells":[{"metadata":{"_uuid":"ae4310e58190d2a1149f91a5b4604cad804a3e07"},"cell_type":"markdown","source":"## Random Forest Regressor using fast.ai along with Model Interpretation"},{"metadata":{"_uuid":"c09fdd987214e33379322b63d146f878e85a1bff"},"cell_type":"markdown","source":"To ensure no module not found errors"},{"metadata":{"trusted":true,"_uuid":"1c2ce606e7c11e4e8113a1355c2252f084fc114e","_kg_hide-output":true},"cell_type":"code","source":"!pip install fastai==0.7.0 ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom fastai.imports import *\nfrom fastai.structured import *   ## Need to install fastai 0.7 for this \n\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom IPython.display import display\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f12a103dc1eb4f5581a34cc0fa32a4e3ea6f016"},"cell_type":"code","source":"df_raw = pd.read_csv('../input/train_V2.csv', low_memory=False)\ndf_raw_test = pd.read_csv('../input/test_V2.csv', low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ac69db2d600c2505e9cd4ae0049a11ae001fadd"},"cell_type":"code","source":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 100, \"display.max_columns\", 100):\n        display(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"552eb985b9a3aeea0063787b6483be959dc0273a"},"cell_type":"code","source":"display_all(df_raw.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a82e3094fe25b3a4e7ef98c16f98813829e7bdc2","scrolled":true},"cell_type":"code","source":"display_all(df_raw.describe(include='all'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"587dc607e7046c715183f44c90a2d8c7b5d25fe6"},"cell_type":"markdown","source":"## Initial Processing"},{"metadata":{"_uuid":"3a12296e446ee0fe15d10b494597eae4648a1573"},"cell_type":"markdown","source":"Let store Id, groupId, and matchId from the test dataset into an info dataset. This will be later use for submission. We can then drop this 3 fields from both the train and test dataset as it would not help us in building our model."},{"metadata":{"trusted":true,"_uuid":"9f46302576c97501f632cd5728399c4acaaeddf0"},"cell_type":"code","source":"# store test info\ndf_raw_test_info = df_raw_test[['Id', 'groupId', 'matchId']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"268a7443ae6031d04ad8cbf66fe06eec8cc11776"},"cell_type":"code","source":"df_raw.drop(['Id', 'groupId', 'matchId'], axis=1, inplace=True)\ndf_raw_test.drop(['Id', 'groupId', 'matchId'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eec35ad16bd3f8bcc79a181bfc79f870761ed516"},"cell_type":"markdown","source":"fastai library provide train_cats method which change any columns of strings in a dataframe to a column of categorical values. I also use apply_cats method on the test dataset to change any columns of strings into categorical variables using the train dataset (df_raw) as a template."},{"metadata":{"trusted":true,"_uuid":"e5cbfb531cb84c2595a1113ddc09e5b130733655"},"cell_type":"code","source":"train_cats(df_raw)\napply_cats(df_raw_test, df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2bcf90b4322c0d6d45c924be182c34b1c518f11"},"cell_type":"code","source":"display_all(df_raw.isnull().sum().sort_index()/len(df_raw))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34bf637e689a603ee4da46069bf8402ff181b4ed"},"cell_type":"markdown","source":"Apparently, we have na values in the winPlacePerc column. This column is the target variable so it does not make sense to have an na values. Let's check the rows."},{"metadata":{"trusted":true,"_uuid":"c8346a177d3c9dab7351e02c3c3dd12f6921dc9e"},"cell_type":"code","source":"df_raw[pd.isna(df_raw['winPlacePerc'])]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca9bc895d908dcfe0b8e39d7ac75783a15932282"},"cell_type":"markdown","source":"Oh, it's only one row. Let's get rid of the row."},{"metadata":{"trusted":true,"_uuid":"efd7072b03cf2fcbb15f73cd3692678cda35a879"},"cell_type":"code","source":"df_raw.dropna(subset=['winPlacePerc'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20e0a46fd9b4240f0a7fe73a26719267b56bd7a0"},"cell_type":"markdown","source":"Random forest classifier only take entirely numeric dataframe. To make sure our dataset is fit to be passed to the classifier, we can use proc_df to make sure the training and test dataset are set to numeric dataframe. "},{"metadata":{"trusted":true,"_uuid":"e81889993101dd95e83379eb74be1c9f8b4e07c2"},"cell_type":"code","source":"df_trn, y_trn, nas = proc_df(df_raw, 'winPlacePerc')\ndf_test, _, _ = proc_df(df_raw_test, na_dict=nas)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e68b105ac9e19c855dca0c006e1d2ef7127bb275"},"cell_type":"markdown","source":"## Splitting into Validation set\nLet's split the dataset to get a validation dataset to make sure we do not overfit to the training dataset.\n"},{"metadata":{"trusted":true,"_uuid":"1d1132a3def3319c067cf93cdbea8902510d52ff"},"cell_type":"code","source":"# split the data to train valid\n\nX_train, X_valid, y_train, y_valid = train_test_split(df_trn, y_trn, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c913dd34892a725656eea37e6cd146d8dcc9a552"},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\ndef print_score(m):\n    res = [mean_absolute_error(m.predict(X_train), y_train), mean_absolute_error(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ee6eebf1041d7b6e17598ace7cfcf673b2429fd"},"cell_type":"markdown","source":"## Running the model \nRunning the model on the enitre dataset took 7 mins. So we are taking a random sub-sample to be able to iterate faster."},{"metadata":{"trusted":true,"_uuid":"3a6c95fec074e7d7d2cbe47a5be6a9069703b1f8"},"cell_type":"code","source":"set_rf_samples(20000)\nm = RandomForestRegressor(n_jobs=-1, n_estimators = 40, min_samples_leaf = 7, min_samples_split = 7)\n%time m.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0424bace347f67d535f91778a10eff4e598a300"},"cell_type":"code","source":"%time print_score(m)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4ce945ce3de3a40d0c071269f9a9bf43eb32603"},"cell_type":"markdown","source":"Now we can see how good our model is doing. The model is getting a R^2 score of ~0.91 for the validation dataset. "},{"metadata":{"_uuid":"cee065b0e2fcde818a0c911d5afc8ba17c12bd8e"},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true,"_uuid":"49ea515fa9e48ca4b5d6ec2193e638eed99b2e5c"},"cell_type":"code","source":"pred = m.predict(df_test)\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39b597d1bb93b514df6ac0cfee1ef6345ee08cda"},"cell_type":"code","source":"df_sub = df_raw_test_info[['Id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3905e7cd5339b715236fc1c5f66dd62dfb6e9977"},"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn' ## TO remove warning due to assignment below\ndf_sub['winPlacePerc'] = pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd025f563ff12d91d0b73e8e0d698cd07066ab91"},"cell_type":"code","source":"df_sub.to_csv('PUBG_RF_tune.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c70f4c28c0494ccd47b17961c00e2cf16416cd7"},"cell_type":"markdown","source":"## Feature Selection\nLet's check feature importance for each column"},{"metadata":{"trusted":true,"_uuid":"2abfb4f00f3d0bcccf5c0c030bf19be8be432a62"},"cell_type":"code","source":"fi = rf_feat_importance(m, X_train)\nfi[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"550cba56cb3793d26d9f5f7acd4fec4793d87150"},"cell_type":"markdown","source":"So Walk distance is THE most important feature that determines the output of a PUBG game !! Sounds intuitive as well !"},{"metadata":{"trusted":true,"_uuid":"a65e7c9a579a1a9adc9d98b03dcd7a6b33820329"},"cell_type":"code","source":"fi.plot('cols', 'imp', figsize=(10,6), legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b5bf93cf09c367d2561ff294f7885a04b24979f"},"cell_type":"markdown","source":"So not all the columns are useful in the Random Forest model, and we can just drop off the some features without sacrificing in accuracy. Let's see how many of these features do we need."},{"metadata":{"trusted":true,"_uuid":"35d822ef8be227d07e344435161827490ce778f5"},"cell_type":"code","source":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\nplot_fi(fi[:30])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"249a5c488ecc690d90377b698484a7e6b19d7476"},"cell_type":"code","source":"to_keep = fi[fi.imp>0.005].cols; len(to_keep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27e2df7594f7eaa359976dda03dc9519657726f8"},"cell_type":"code","source":"df_keep = df_raw[to_keep].copy()\nX_train, X_valid, y_train, y_valid = train_test_split(df_keep, y_trn, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88d657b33a3efe1f43236014857fb9e3c9c4d11a"},"cell_type":"code","source":"set_rf_samples(20000)\nm = RandomForestRegressor(n_jobs=-1, n_estimators = 40, min_samples_leaf = 7, min_samples_split = 7)\n%time m.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03f6e7f87310aa50864f2b75c0b8d42fc1d4b336"},"cell_type":"code","source":"%time print_score(m)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c0d2ab0672816c03d39d4b88ced02f21faa0d69"},"cell_type":"markdown","source":"We see that the R^2 did not change much after removing the redundant features from our model !!"},{"metadata":{"trusted":true,"_uuid":"f1d09e3d98a8d08335ba7c257359abcea98f6c0d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}