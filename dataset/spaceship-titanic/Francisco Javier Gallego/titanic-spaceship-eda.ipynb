{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b>1 <span style='color:lightseagreen'>|</span> Introduction</b>\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>1.1 | Goal</b></p>\n</div>\n\nWelcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good. The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars. While rounding Alpha Centauri en route to its first destinationâ€”the torrid 55 Cancri Eâ€”the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n\nTo help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceshipâ€™s damaged computer system. Help save them and change history!","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\nimport os\nimport warnings\nfrom pathlib import Path\n\n# Basic libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport seaborn as sns\n\n# Clustering\nfrom sklearn.cluster import KMeans\n\n# Principal Component Analysis (PCA)\nfrom sklearn.decomposition import PCA\n\n#Mutual Information\nfrom sklearn.feature_selection import mutual_info_regression\n\n# Cross Validation\nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, learning_curve\n\n# Encoding\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder\nfrom category_encoders import MEstimateEncoder\nfrom category_encoders import MEstimateEncoder\n\n# Algorithms\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\n# Optuna - Bayesian Optimization \nimport optuna\nfrom optuna.samplers import TPESampler\n\n# Plotly\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport plotly.offline as offline\nimport plotly.graph_objs as go\n\nwarnings.filterwarnings('ignore')\n\ndef load_data():\n    data_dir = Path(\"../input/spaceship-titanic\")\n    df_train = pd.read_csv(data_dir / \"train.csv\")\n    df_test = pd.read_csv(data_dir / \"test.csv\")\n    # Merge the splits so we can process them together\n    df = pd.concat([df_train, df_test])\n    return df\n\ndef plot_feature_importance(importance,names,model_type):\n    \n    #Create arrays from feature importance and feature names\n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n    \n    #Create a DataFrame using a Dictionary\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n    \n    #Sort the DataFrame in order decreasing feature importance\n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n    \n    #Define size of bar plot\n    plt.figure(figsize=(20,10))\n    #Plot Searborn bar chart\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n    #Add chart labels\n    plt.title(model_type + ' FEATURE IMPORTANCE')\n    plt.xlabel('FEATURE IMPORTANCE')\n    plt.ylabel('FEATURE NAMES')\n\ndf_data = load_data()\npp.ProfileReport(df_data)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-16T23:52:23.480726Z","iopub.execute_input":"2022-03-16T23:52:23.481216Z","iopub.status.idle":"2022-03-16T23:52:48.055031Z","shell.execute_reply.started":"2022-03-16T23:52:23.481159Z","shell.execute_reply":"2022-03-16T23:52:48.053973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>1.7 | Reducing Memory Usage</b></p>\n</div>\n\nIn order to not having **<span style='color:lightseagreen'>issues with memory</span>** in the kernel, we are going to reduce its memory usage with the following function. Below, we can appreciate that reduction was successful as we manage to make a **<span style='color:lightseagreen'>reduction of 20%</span>**. ","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df\n\ndf_data = reduce_mem_usage(df_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.057079Z","iopub.execute_input":"2022-03-16T23:52:48.057379Z","iopub.status.idle":"2022-03-16T23:52:48.087009Z","shell.execute_reply.started":"2022-03-16T23:52:48.057339Z","shell.execute_reply":"2022-03-16T23:52:48.085942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>2 <span style='color:lightseagreen'>|</span> Missing Values</b>\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>2.1 | Categorical Features</b></p>\n</div>\n\nFrom the starting profiling report we observe that there are plenty of features having missing values. We are going to focus on filling them along this section. We'll start with those belonging to object category. Let's take a quick look at those features. ","metadata":{}},{"cell_type":"code","source":"df_data.select_dtypes(['object']).head()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.088988Z","iopub.execute_input":"2022-03-16T23:52:48.089559Z","iopub.status.idle":"2022-03-16T23:52:48.115243Z","shell.execute_reply.started":"2022-03-16T23:52:48.089515Z","shell.execute_reply":"2022-03-16T23:52:48.114297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.1 | HomePlanet\n\n> **<span style='color:gray'>HomePlanet description: the planet the passenger departed from, typically their planet of permanent residence.</span>**\n\nLet's focus first on HomePlanet. As it is shown in the report this feature is categorical, with three different values. Those are the following: Mars, Earth and Europa. We are going to calculate mode and we are going to fill missing values with it. ","metadata":{}},{"cell_type":"code","source":"def filling_HomePlanet(df):\n    mode = df['HomePlanet'].value_counts().index[0]\n    df['HomePlanet'] = df['HomePlanet'].fillna(mode)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.11776Z","iopub.execute_input":"2022-03-16T23:52:48.118344Z","iopub.status.idle":"2022-03-16T23:52:48.123739Z","shell.execute_reply.started":"2022-03-16T23:52:48.118299Z","shell.execute_reply":"2022-03-16T23:52:48.122969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.2 | CryoSleep\n\n> **<span style='color:gray'>CryoSleep description: indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.</span>**\n\nLet's focus now on CryoSleep. As it is shown in the report this feature is boolean. Due to the fact that, if passenger had elected to put himself into suspended animation rarely it would have a missing value, we are going to consider the option of replacing missing values with False in this case.  ","metadata":{}},{"cell_type":"code","source":"def filling_CryoSleep(df):\n    df['CryoSleep'] = df['CryoSleep'].fillna(False)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.12537Z","iopub.execute_input":"2022-03-16T23:52:48.125928Z","iopub.status.idle":"2022-03-16T23:52:48.135944Z","shell.execute_reply.started":"2022-03-16T23:52:48.125856Z","shell.execute_reply":"2022-03-16T23:52:48.134988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.3 | Cabin\n\n> **<span style='color:gray'>Cabin description: the cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.</span>**\n\nLet's focus now on Cabin. As it is shown in the report this feature is categorical. As it is almost impossible to estimate cabin number for a passenger with given format, we are going to split cabin number into three different features. Those are going to be describing: desk, number and side. Thus, we'll start Feature Engineering here (continued in detail subsequently). Next, we are going to replace missing values for deck type feature with F (most repeated value). Hereafter, we are going to fill side feature with most repeated value into decks of type F. Finally, we are going to fill cabin number with half of the maximum cabin number (as cabins belonging to one deck type could have more survival rate whether they are one of the first/last cabin).","metadata":{}},{"cell_type":"code","source":"def split_Cabin(df):\n    df['Deck'] = df['Cabin'].str.split(\"/\", n=2, expand=True)[0]\n    df['Number'] = df['Cabin'].str.split(\"/\", n=2, expand=True)[1]\n    df['Side'] = df['Cabin'].str.split(\"/\", n=2, expand=True)[2]\n    df.pop('Cabin')\n    return df\n\ndef filling_Cabin(df):\n    df['Deck'] = df['Deck'].fillna('F')\n    mode = df[df.Deck == 'F']['Side'].value_counts().index[0]\n    df['Side'] = mode\n    df['Number'] = df['Number'].astype(float)\n    df['Number'] = df['Number'].fillna(1796 / 2)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.137841Z","iopub.execute_input":"2022-03-16T23:52:48.138529Z","iopub.status.idle":"2022-03-16T23:52:48.150212Z","shell.execute_reply.started":"2022-03-16T23:52:48.138478Z","shell.execute_reply":"2022-03-16T23:52:48.149167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.4 | Destination\n\n> **<span style='color:gray'>Destination description: the planet the passenger will be debarking to.</span>**\n\nLet's focus now on Destination. As it is shown in the report this feature is categorical. We are going to fill missing values with most repeated value. ","metadata":{}},{"cell_type":"code","source":"def filling_Destination(df):\n    mode = df['Destination'].value_counts().index[0]\n    df['Destination'] = df['Destination'].fillna(mode)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.151423Z","iopub.execute_input":"2022-03-16T23:52:48.151639Z","iopub.status.idle":"2022-03-16T23:52:48.165783Z","shell.execute_reply.started":"2022-03-16T23:52:48.151613Z","shell.execute_reply":"2022-03-16T23:52:48.164788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.5 | VIP\n\n> **<span style='color:gray'>VIP description: whether the passenger has paid for special VIP service during the voyage.</span>**\n\nLet's focus now on VIP. It would seem strange that a customer who has paid for a VIP service deal has not been taken into account in the data collection. This is why I'm going to replace missing values with False. ","metadata":{}},{"cell_type":"code","source":"def filling_VIP(df):\n    df['VIP'] = df['VIP'].fillna(False)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.167152Z","iopub.execute_input":"2022-03-16T23:52:48.167384Z","iopub.status.idle":"2022-03-16T23:52:48.176093Z","shell.execute_reply.started":"2022-03-16T23:52:48.167356Z","shell.execute_reply":"2022-03-16T23:52:48.175375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1.6 | Name\n\n> **<span style='color:gray'>Name description: the first and last names of the passenger.</span>**\n\nLastly, let's focus on Name Feature. We are going to replace it with None, as it is difficult to guess first and last name of a person as you could guess. ","metadata":{}},{"cell_type":"code","source":"def filling_Name(df):\n    df['Name'] = df['Name'].fillna('None')\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.177331Z","iopub.execute_input":"2022-03-16T23:52:48.178018Z","iopub.status.idle":"2022-03-16T23:52:48.187975Z","shell.execute_reply.started":"2022-03-16T23:52:48.17796Z","shell.execute_reply":"2022-03-16T23:52:48.186955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>2.2 | Numerical Features</b></p>\n</div>\n\nFrom the starting profiling report we observe that there are quantitative features having missing values. We are going to focus on filling them along this section.\n\n### 2.2.1 | Age\n> **<span style='color:gray'>Age description: the age of the passenger.</span>**\n\nWe are going to start with Age Feature. We are going to replace missing values with median age. ","metadata":{}},{"cell_type":"code","source":"def filling_Age(df):\n    median = df['Age'].describe()[5]\n    df['Age'] = df['Age'].fillna(median)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.191501Z","iopub.execute_input":"2022-03-16T23:52:48.19219Z","iopub.status.idle":"2022-03-16T23:52:48.199106Z","shell.execute_reply.started":"2022-03-16T23:52:48.19214Z","shell.execute_reply":"2022-03-16T23:52:48.198335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2.2 | Luxury Features\n\n> **<span style='color:gray'>Luxury Features description: amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.</span>**\n\nNow, we are focusing into those VIP features that are related to the amount of money a passenger has paid. As it would be quite unusual to not have recorded payment data from a VIP passenger, we are going to consider that missing values refer to passengers who have not spent anything on those luxuries.","metadata":{}},{"cell_type":"code","source":"def filling_luxury_features(df):\n    luxury_features = ['RoomService','FoodCourt', 'ShoppingMall', 'Spa','VRDeck']\n    df[luxury_features] = df[luxury_features].fillna(0.0)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.200093Z","iopub.execute_input":"2022-03-16T23:52:48.200913Z","iopub.status.idle":"2022-03-16T23:52:48.209383Z","shell.execute_reply.started":"2022-03-16T23:52:48.200861Z","shell.execute_reply":"2022-03-16T23:52:48.208745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>2.3 | Missing Values Filling Function</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"def filling_numerical(df):\n    df = filling_Age(df)\n    df = filling_luxury_features(df)\n    return df\n\ndef filling_categorical(df):\n    df = filling_HomePlanet(df)\n    df = filling_CryoSleep(df)\n    df = split_Cabin(df)\n    df = filling_Cabin(df)\n    df = filling_Destination(df)\n    df = filling_VIP(df)\n    df = filling_Name(df)\n    return df\n\ndef filling_missing(df):\n    df = filling_categorical(df)\n    df = filling_numerical(df)\n    return df\n\ndf_data = filling_missing(df_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:52:48.210422Z","iopub.execute_input":"2022-03-16T23:52:48.211232Z","iopub.status.idle":"2022-03-16T23:52:48.319817Z","shell.execute_reply.started":"2022-03-16T23:52:48.211194Z","shell.execute_reply":"2022-03-16T23:52:48.319075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>3 <span style='color:lightseagreen'>|</span> Exploratory Data Analysis</b>\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.1 | General Analysis</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=2, cols=3, specs=[[{'type':'bar'},{'type':'histogram'}, {'type':'pie'}], [{'type':'pie'}, {'colspan':2},None]], \n                   subplot_titles=('CryoSleep','Age Distribution','HomePlanet','Destination','Deck'),\n                   column_widths=[0.33, 0.33, 0.34], vertical_spacing=0.15, horizontal_spacing=0.05)\n\n# Left Upper Chart\ncryosleep = pd.DataFrame(df_data['CryoSleep'].value_counts()).reset_index()\nfig.add_trace(go.Bar(y=cryosleep['CryoSleep'], x=cryosleep['index'], marker = dict(color=px.colors.sequential.Sunsetdark[3]), \n                     name = 'Day of Week'),row=1, col=1)\n\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=1, col=1)\nfig.update_yaxes(showgrid = False, linecolor='gray',linewidth=2, zeroline = False, row=1, col=1)\n\n# Middle Upper Chart\nfig.add_trace(go.Histogram(x=df_data.Age, name='Age Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[0])), row = 1, col = 2)\n\nfig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=1, col=2)\nfig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=1, col=2)\n\n# Right Upper Chart\nhomeplanet = pd.DataFrame(df_data['HomePlanet'].value_counts())\nfig.add_trace(go.Pie(values=homeplanet['HomePlanet'], labels=homeplanet.index, name='Home Planet',                      \n                     hole=0, pull=[0, 0, 0],\n                      marker = dict(colors = (px.colors.sequential.Sunsetdark[1],px.colors.sequential.Sunsetdark[3], px.colors.sequential.Sunsetdark[0])),\n                     #marker_colors=px.colors.sequential.Sunsetdark,\n                     hoverinfo='label+percent+value', textinfo='label'), row=1, col=3)\n\nfig.update_traces(\nmarker=dict(\n        line=dict(color='#303330',\n                  width=2)\n        ), \n    row = 1, col=3\n)\n\n# Left Bottom Chart\ndestination = pd.DataFrame(df_data['Destination'].value_counts())\nfig.add_trace(go.Pie(values=destination['Destination'], labels=destination.index, name='Home Planet',                      \n                     hole=0, pull=[0, 0, 0],\n                      marker = dict(colors = (px.colors.sequential.Sunsetdark[1],px.colors.sequential.Sunsetdark[3], px.colors.sequential.Sunsetdark[0])),\n                     #marker_colors=px.colors.sequential.Sunsetdark,\n                     hoverinfo='label+percent+value', textinfo='label'), row=2, col=1)\n\nfig.update_traces(\nmarker=dict(\n        line=dict(color='#303330',\n                  width=2)\n        ), \n    row = 2, col=1\n)\n\n\n# Right Bottom Chart\ndeck = pd.DataFrame(df_data.Deck.value_counts())\nfig.add_trace(go.Bar(x=deck['Deck'], y=deck.index,  marker_color=px.colors.sequential.Sunsetdark,\n                     name='Deck', orientation='h'),row=2, col=2)\n\nfig.update_xaxes(visible = False, showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=2, col=2)\nfig.update_yaxes(showgrid = True, gridcolor='gray', gridwidth=0.5, linecolor='gray', linewidth=2, zeroline = False, row=2, col=2)\n\n# General Styling\nfig.update_layout(height=800, bargap=0.2,\n                  margin=dict(b=50,r=30,l=100), xaxis=dict(tickmode='linear'),\n                  title_text=\"General Analysis\",\n                  #template=\"plotly_dark\",\n                  paper_bgcolor=\"#303330\",\n                  plot_bgcolor = \"#303330\",\n                  title_font=dict(size=29, color='floralwhite', family=\"Lato, sans-serif\"),\n                  font=dict(color='floralwhite'), \n                  hoverlabel=dict(bgcolor=\"floralwhite\", font_size=13, font_family=\"Lato, sans-serif\"),\n                  showlegend=False)","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-16T23:52:48.320972Z","iopub.execute_input":"2022-03-16T23:52:48.321184Z","iopub.status.idle":"2022-03-16T23:52:48.452391Z","shell.execute_reply.started":"2022-03-16T23:52:48.321157Z","shell.execute_reply":"2022-03-16T23:52:48.451404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ðŸ“Œ Interpret:** As we can appreeciate, the count of both values for side feature are almost equal. However, in relation with deck types we observe that decks of type F are the most common ones, followed by G and E. Most unusual decks are A and especially T, where just 11 persons are in this type of deck. Taking this into account, we are going to replace missing values for deck type feature with F. Hereafter, we are going to fill side feature with most repeated value into decks of type F. Finally, we are going to fill cabin number with half of the maximum cabin number (as cabins belonging to one deck type could have more survival rate whether they are one of the first/last cabin). ","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.2 | Earth Passengers Analysis</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"def planet_analysis(planet):\n    earth = df_data[df_data.HomePlanet == planet]\n    fig = make_subplots(rows=3, cols=3, specs=[[{'type':'bar'},{'type':'histogram'}, {'type':'pie'}], [{'colspan':2},None, {'type':'histogram'}], \n                                              [{'type':'histogram'},{'type':'histogram'},{'type':'histogram'}]], \n                       subplot_titles=('CryoSleep','Age Distribution','Destination','Deck','Room Service Distribution','Food Court Distribution',\n                                      'Shopping Mall Distribution','Spa Distribution'),\n                       column_widths=[0.33, 0.33, 0.34], vertical_spacing=0.1, horizontal_spacing=0.05)\n\n    # Left Upper Chart\n    cryosleep = pd.DataFrame(earth['CryoSleep'].value_counts()).reset_index()\n    fig.add_trace(go.Bar(y=cryosleep['CryoSleep'], x=cryosleep['index'], marker = dict(color=px.colors.sequential.Sunsetdark[3]), \n                         name = 'Day of Week'),row=1, col=1)\n\n    fig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=1, col=1)\n    fig.update_yaxes(showgrid = False, linecolor='gray',linewidth=2, zeroline = False, row=1, col=1)\n\n    # Middle Upper Chart\n    fig.add_trace(go.Histogram(x=earth.Age, name='Age Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[0])), row = 1, col = 2)\n\n    fig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=1, col=2)\n    fig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=1, col=2)\n\n    # Right Upper Chart\n    destination = pd.DataFrame(earth['Destination'].value_counts())\n    fig.add_trace(go.Pie(values=destination['Destination'], labels=destination.index, name='Home Planet',                      \n                         hole=0, pull=[0, 0, 0],\n                          marker = dict(colors = (px.colors.sequential.Sunsetdark[1],px.colors.sequential.Sunsetdark[3], px.colors.sequential.Sunsetdark[0])),\n                         #marker_colors=px.colors.sequential.Sunsetdark,\n                         hoverinfo='label+percent+value', textinfo='label'), row=1, col=3)\n\n    fig.update_traces(\n    marker=dict(\n            line=dict(color='#303330',\n                      width=2)\n            ), \n        row = 1, col=3\n    )\n\n    # Left Medium Chart\n    deck = pd.DataFrame(earth.Deck.value_counts())\n    fig.add_trace(go.Bar(x=deck['Deck'], y=deck.index,  marker_color=px.colors.sequential.Sunsetdark,\n                         name='Deck', orientation='h'),row=2, col=1)\n\n    fig.update_xaxes(visible = False, showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=2, col=1)\n    fig.update_yaxes(showgrid = True, gridcolor='gray', gridwidth=0.5, linecolor='gray', linewidth=2, zeroline = False, row=2, col=1)\n\n    # Right Medium Chart\n    luxury = earth[(earth.RoomService > 100)]\n    fig.add_trace(go.Histogram(x=luxury.RoomService, name='Room Service Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[3])), row = 2, col = 3)\n\n    fig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=2, col=3)\n    fig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=2, col=3)\n\n    # Left Bottom Chart\n    luxury = earth[(earth.FoodCourt > 100)]\n    fig.add_trace(go.Histogram(x=luxury.FoodCourt, name='Food Court Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[4])), row = 3, col = 1)\n\n    fig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=1)\n    fig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=1)\n\n    # Middle Bottom Chart\n    luxury = earth[(earth.ShoppingMall > 100)]\n    fig.add_trace(go.Histogram(x=luxury.ShoppingMall, name='Shopping Mall Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[5])), row = 3, col = 2)\n\n    fig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=2)\n    fig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=2)\n\n    # Right Bottom Chart\n    luxury = earth[(earth.Spa > 100)]\n    fig.add_trace(go.Histogram(x=luxury.Spa, name='Room Service Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[6])), row = 3, col = 3)\n\n    fig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=3)\n    fig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=3)\n\n    # General Styling\n    fig.update_layout(height=1250, bargap=0.2,\n                      margin=dict(b=50,r=30,l=100), xaxis=dict(tickmode='linear'),\n                      title_text=planet + \" Passengers Analysis\",\n                      #template=\"plotly_dark\",\n                      paper_bgcolor=\"#303330\",\n                      plot_bgcolor = \"#303330\",\n                      title_font=dict(size=29, color='floralwhite', family=\"Lato, sans-serif\"),\n                      font=dict(color='floralwhite'), \n                      hoverlabel=dict(bgcolor=\"floralwhite\", font_size=13, font_family=\"Lato, sans-serif\"),\n                      showlegend=False)\n    return fig\n    \nfig = planet_analysis('Earth')\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-16T23:52:48.454243Z","iopub.execute_input":"2022-03-16T23:52:48.454538Z","iopub.status.idle":"2022-03-16T23:52:48.664655Z","shell.execute_reply.started":"2022-03-16T23:52:48.4545Z","shell.execute_reply":"2022-03-16T23:52:48.663801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.3 | Mars Passengers Analysis</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"fig = planet_analysis('Mars')\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-16T23:52:48.66631Z","iopub.execute_input":"2022-03-16T23:52:48.666599Z","iopub.status.idle":"2022-03-16T23:52:48.843632Z","shell.execute_reply.started":"2022-03-16T23:52:48.666562Z","shell.execute_reply":"2022-03-16T23:52:48.842827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.4 | Europa Passengers Analysis</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"fig = planet_analysis('Europa')\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-16T23:52:48.844795Z","iopub.execute_input":"2022-03-16T23:52:48.845423Z","iopub.status.idle":"2022-03-16T23:52:49.02068Z","shell.execute_reply.started":"2022-03-16T23:52:48.845379Z","shell.execute_reply":"2022-03-16T23:52:49.020097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>3.5 | Transported Passengers Analysis</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"transported = df_data[df_data.Transported == True]\nfig = make_subplots(rows=3, cols=3, specs=[[{'type':'bar'},{'type':'histogram'}, {'type':'pie'}], [{'colspan':2},None, {'type':'histogram'}], \n                                          [{'type':'histogram'},{'type':'histogram'},{'type':'histogram'}]], \n                   subplot_titles=('CryoSleep','Age Distribution','Destination','Deck','Room Service Distribution','Food Court Distribution',\n                                  'Shopping Mall Distribution','Spa Distribution'),\n                   column_widths=[0.33, 0.33, 0.34], vertical_spacing=0.1, horizontal_spacing=0.05)\n\n# Left Upper Chart\ncryosleep = pd.DataFrame(transported['CryoSleep'].value_counts()).reset_index()\nfig.add_trace(go.Bar(y=cryosleep['CryoSleep'], x=cryosleep['index'], marker = dict(color=px.colors.sequential.Sunsetdark[3]), \n                     name = 'Day of Week'),row=1, col=1)\n\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=1, col=1)\nfig.update_yaxes(showgrid = False, linecolor='gray',linewidth=2, zeroline = False, row=1, col=1)\n\n# Middle Upper Chart\nfig.add_trace(go.Histogram(x=transported.Age, name='Age Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[0])), row = 1, col = 2)\n\nfig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=1, col=2)\nfig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=1, col=2)\n\n# Right Upper Chart\ndestination = pd.DataFrame(transported['Destination'].value_counts())\nfig.add_trace(go.Pie(values=destination['Destination'], labels=destination.index, name='Home Planet',                      \n                     hole=0, pull=[0, 0, 0],\n                      marker = dict(colors = (px.colors.sequential.Sunsetdark[1],px.colors.sequential.Sunsetdark[3], px.colors.sequential.Sunsetdark[0])),\n                     #marker_colors=px.colors.sequential.Sunsetdark,\n                     hoverinfo='label+percent+value', textinfo='label'), row=1, col=3)\n\nfig.update_traces(\nmarker=dict(\n        line=dict(color='#303330',\n                  width=2)\n        ), \n    row = 1, col=3\n)\n\n# Left Medium Chart\ndeck = pd.DataFrame(transported.Deck.value_counts())\nfig.add_trace(go.Bar(x=deck['Deck'], y=deck.index,  marker_color=px.colors.sequential.Sunsetdark,\n                     name='Deck', orientation='h'),row=2, col=1)\n\nfig.update_xaxes(visible = False, showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=2, col=1)\nfig.update_yaxes(showgrid = True, gridcolor='gray', gridwidth=0.5, linecolor='gray', linewidth=2, zeroline = False, row=2, col=1)\n\n# Right Medium Chart\nluxury = transported[(transported.RoomService > 100)]\nfig.add_trace(go.Histogram(x=luxury.RoomService, name='Room Service Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[3])), row = 2, col = 3)\n\nfig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=2, col=3)\nfig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=2, col=3)\n\n# Left Bottom Chart\nluxury = transported[(transported.FoodCourt > 100)]\nfig.add_trace(go.Histogram(x=luxury.FoodCourt, name='Food Court Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[4])), row = 3, col = 1)\n\nfig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=1)\nfig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=1)\n\n# Middle Bottom Chart\nluxury = transported[(transported.ShoppingMall > 100)]\nfig.add_trace(go.Histogram(x=luxury.ShoppingMall, name='Shopping Mall Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[5])), row = 3, col = 2)\n\nfig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=2)\nfig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=2)\n\n# Right Bottom Chart\nluxury = transported[(transported.Spa > 100)]\nfig.add_trace(go.Histogram(x=luxury.Spa, name='Room Service Distribution', marker = dict(color = px.colors.sequential.Sunsetdark[6])), row = 3, col = 3)\n\nfig.update_xaxes(showgrid = False, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=3)\nfig.update_yaxes(showgrid = True, gridcolor = 'gray', gridwidth = 0.5, showline = True, linecolor = 'gray', linewidth = 2, row=3, col=3)\n\n# General Styling\nfig.update_layout(height=1250, bargap=0.2,\n                  margin=dict(b=50,r=30,l=100), xaxis=dict(tickmode='linear'),\n                  title_text=\"Transported Passengers Analysis\",\n                  #template=\"plotly_dark\",\n                  paper_bgcolor=\"#303330\",\n                  plot_bgcolor = \"#303330\",\n                  title_font=dict(size=29, color='floralwhite', family=\"Lato, sans-serif\"),\n                  font=dict(color='floralwhite'), \n                  hoverlabel=dict(bgcolor=\"floralwhite\", font_size=13, font_family=\"Lato, sans-serif\"),\n                  showlegend=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-16T23:52:49.022111Z","iopub.execute_input":"2022-03-16T23:52:49.022475Z","iopub.status.idle":"2022-03-16T23:52:49.242554Z","shell.execute_reply.started":"2022-03-16T23:52:49.022443Z","shell.execute_reply":"2022-03-16T23:52:49.24171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>4 <span style='color:lightseagreen'>|</span> Feature Engineering</b>\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>4.1 | Local CV Scoring Dataset Function</b></p>\n</div>\n\nThe first step after EDA for us, is going to be building a reliable **<span style='color:lightseagreen'>local validation strategy</span>**. With reliable I mean a local CV score that **<span style='color:lightseagreen'>correlates</span>** with LB score. Because then we can use our local CV score to evaluate experiments or to tune (hyper)parameters. There are **<span style='color:lightseagreen'>two questions</span>** that I usually try to answer.\n\n- **<span style='color:lightseagreen'>How to split</span>** the data in train and validation (there are a lot of different strategies)?\n- Once a strategy is chosen does LB score moves in the direction of local CV score? If the answer is yes then probably the relationship between your local folds is the same relationship between Kaggle's train and test. If not, try other CV strategy and if you cannot find a reliable local CV then is it probably time to stop taking part in the competition because at the end you might be highly disappointed after the final shake-up.","metadata":{}},{"cell_type":"code","source":"#def score_dataset(X, y, model=XGBRegressor(tree_method='gpu_hist', predictor='gpu_predictor'), model_2 = CatBoostRegressor(task_type = 'GPU', silent=True)):\n#def score_dataset(X, y, model=XGBRegressor(), model_2 = CatBoostRegressor(silent=True)):\ndef score_dataset(X,y,model=XGBClassifier(label_encoder=False)):\n    # Label encoding is good for XGBoost and RandomForest, but one-hot\n    # would be better for models like Lasso or Ridge. The `cat.codes`\n    # attribute holds the category levels.\n    for colname in X.select_dtypes([\"object\",\"bool\"]).columns:\n        X[colname] = LabelEncoder().fit_transform(X[colname])\n    y['Transported'] = LabelEncoder().fit_transform(y['Transported'])\n    # Metric for Titanic SpaceShipt competition is MAE (Mean Absolute Error)\n    score_xgb = cross_val_score(\n        model, X, y, cv=5, scoring=\"accuracy\", n_jobs=-1\n    )\n    \n    score = score_xgb.mean()\n    return score\n\nX = df_data[df_data.Transported.isnull() == False].copy()\ny = pd.DataFrame(X.pop('Transported'))\nbaseline_score = score_dataset(X, y)\nprint(f\"Baseline score: {baseline_score:.5f} Accuracy\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-16T23:52:49.244063Z","iopub.execute_input":"2022-03-16T23:52:49.246129Z","iopub.status.idle":"2022-03-16T23:54:29.601951Z","shell.execute_reply.started":"2022-03-16T23:52:49.246076Z","shell.execute_reply":"2022-03-16T23:54:29.601234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>4.2 | Creating New Features</b></p>\n</div>\n\n### 4.2.1 | Age\nIn this case, what we'll do is making a distinction between several groups of ages. We are doing this, in order to make it easier to our classifier when making predictions and training. ","metadata":{}},{"cell_type":"code","source":"df_data['Age'] = pd.qcut(df_data['Age'], 10)\ndf_data.head().style.set_properties(subset=['Age'], **{'background-color': 'lightseagreen'})","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:29.602976Z","iopub.execute_input":"2022-03-16T23:54:29.603186Z","iopub.status.idle":"2022-03-16T23:54:29.629402Z","shell.execute_reply.started":"2022-03-16T23:54:29.603158Z","shell.execute_reply":"2022-03-16T23:54:29.628543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agebox = df_data[df_data.Transported.isnull() == False].copy()\nagebox['Transported'].replace([False, True], [0,1], inplace = True)\nagebox = agebox.groupby('Age').agg({'Transported':'mean'}).reset_index()\nagebox['Age'] = agebox['Age'].astype(str)\n\nfig = px.bar(agebox, x=\"Age\", y=\"Transported\", color_continuous_scale='Viridis', color=\"Age\")\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False)\nfig.update_yaxes(showgrid = True, gridcolor='gray',gridwidth=0.5, linecolor='gray',linewidth=2, zeroline = False)\nfig.update_layout(margin=dict(b=50,t = 90, r=30,l=100), title_text=\"Transported Probability per Age Group\",paper_bgcolor=\"#303330\", plot_bgcolor = \"#303330\", title_font=dict(size=29, color='floralwhite', family=\"Lato, sans-serif\"),\n                  font=dict(color='floralwhite'), \n                  hoverlabel=dict(bgcolor=\"floralwhite\", font_size=13, font_family=\"Lato, sans-serif\"))\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-16T23:54:29.63095Z","iopub.execute_input":"2022-03-16T23:54:29.631954Z","iopub.status.idle":"2022-03-16T23:54:29.778862Z","shell.execute_reply.started":"2022-03-16T23:54:29.631909Z","shell.execute_reply":"2022-03-16T23:54:29.777976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.2 | Family Features\n\nHereafter we are going to focus in **<span style='color:lightseagreen'>PassengerId</span>** and **<span style='color:lightseagreen'>Name</span>**. Firstly, we are going to take a brief view to both features, in order to study its relation. As we can see below, PassengerId feature is composed of **<span style='color:lightseagreen'>two parts</span>**\n- First one is related to **<span style='color:lightseagreen'>FamilyId</span>**\n- Second one is related to each member of the family. \n\nIn other words, we can appreciate that both Altark Susent and Solam Susent are from the same family. Therefore, in PassengerId feature they have the same FamilyId, concretely 0003. In order to **<span style='color:lightseagreen'>distinguish</span>** them into the family group, their second PassengerId part are 01 and 02 respectively. Thus, we are going to create some new features:\n- One for **<span style='color:lightseagreen'>FamilyId</span>**\n- One for **<span style='color:lightseagreen'>Family Name</span>**\n- One for **<span style='color:lightseagreen'>Family Size</span>**","metadata":{}},{"cell_type":"code","source":"df_data[['Name','PassengerId']].head().style.set_properties(subset=['PassengerId'], **{'background-color': 'lightseagreen'})","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:29.780747Z","iopub.execute_input":"2022-03-16T23:54:29.78138Z","iopub.status.idle":"2022-03-16T23:54:29.794735Z","shell.execute_reply.started":"2022-03-16T23:54:29.781334Z","shell.execute_reply":"2022-03-16T23:54:29.793842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data['FamilyId'] = df_data['PassengerId'].str.split(\"_\", n=2, expand=True)[0]\ndf_data['Family Name'] = df_data['Name'].str.split(' ', n=2, expand=True)[1]\ndf_data = df_data.set_index(['FamilyId','Family Name'])\ndf_data['Family Size'] = 1\nfor i in range(df_data.shape[0]):\n    fam_size = df_data.loc[df_data.index[i],:].shape[0]\n    df_data.loc[df_data.index[i],'Family Size'] = fam_size\n    \ndf_data = df_data.reset_index()\ndf_data[['FamilyId','PassengerId','Family Name','Name','Family Size']].head().style.set_properties(subset=['FamilyId', 'Family Name','Family Size'], **{'background-color': 'lightseagreen'})","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:29.796088Z","iopub.execute_input":"2022-03-16T23:54:29.797047Z","iopub.status.idle":"2022-03-16T23:54:42.093103Z","shell.execute_reply.started":"2022-03-16T23:54:29.796998Z","shell.execute_reply":"2022-03-16T23:54:42.091875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_data[df_data.Transported.isnull() == False].copy()\ny = pd.DataFrame(X.pop('Transported'))\nbaseline_score = score_dataset(X, y)\nprint(f\"Baseline score: {baseline_score:.5f} Accuracy\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:42.094491Z","iopub.execute_input":"2022-03-16T23:54:42.094825Z","iopub.status.idle":"2022-03-16T23:54:42.270381Z","shell.execute_reply.started":"2022-03-16T23:54:42.094789Z","shell.execute_reply":"2022-03-16T23:54:42.269595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.2 | Luxury Features\n\nHereafter, we are going to focus our attention on **<span style='color:lightseagreen'>luxury features</span>**. Those features are: \n\n- Spa\n- VRDeck\n- Food Court\n- Room Service\n- Shopping Mall\n\nThey all reflect the amount of money a passenger has spent on it. We can create a feature for telling us the amount of money a passenger has spent in all these luxuries. Let's call it **<span style='color:lightseagreen'>Luxury Spending</span>**. Hereafter, as it's going to be a continuous numerical feature, in order to make it easier to our model, we are going to split it into 10 groups (each of them related to one of the percentiles). ","metadata":{}},{"cell_type":"code","source":"df_data['Luxury Spending'] = df_data['VRDeck'] + df_data['ShoppingMall'] + df_data['Spa'] + df_data['FoodCourt'] + df_data['RoomService']\nluxury = df_data[df_data.Transported.isnull() == False].copy()\nluxury['Luxury Spending'] = pd.qcut(luxury['Luxury Spending'], 6, duplicates = 'drop')\nluxury = luxury.groupby('Luxury Spending').agg({'Transported':'mean'}).reset_index()\nluxury['Luxury Spending'] = LabelEncoder().fit_transform(luxury['Luxury Spending'])\nfig = px.bar(luxury, x=\"Luxury Spending\", y=\"Transported\", color='Luxury Spending', color_continuous_scale='Sunsetdark')\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False)\nfig.update_yaxes(showgrid = True, gridcolor='gray',gridwidth=0.5, linecolor='gray',linewidth=2, zeroline = False)\nfig.update_layout(margin=dict(b=50,t = 90, r=30,l=100), title_text=\"Transported Probability per Luxury Spending Group\",paper_bgcolor=\"#303330\", plot_bgcolor = \"#303330\", title_font=dict(size=29, color='floralwhite', family=\"Lato, sans-serif\"),\n                  font=dict(color='floralwhite'), \n                  hoverlabel=dict(bgcolor=\"floralwhite\", font_size=13, font_family=\"Lato, sans-serif\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:42.271556Z","iopub.execute_input":"2022-03-16T23:54:42.272294Z","iopub.status.idle":"2022-03-16T23:54:42.391543Z","shell.execute_reply.started":"2022-03-16T23:54:42.272242Z","shell.execute_reply":"2022-03-16T23:54:42.390482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>4.3 | Feature Transformation</b></p>\n</div>\n\n### 4.3.1 | Boolean Features - Target","metadata":{}},{"cell_type":"code","source":"boolean_col = df_data.select_dtypes(['bool']).columns\nfor i in range(len(boolean_col)):\n    df_data[boolean_col[i]].replace([False, True], [0,1], inplace = True)\ndf_data['Transported'].replace([False, True], [0,1], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:42.393352Z","iopub.execute_input":"2022-03-16T23:54:42.393742Z","iopub.status.idle":"2022-03-16T23:54:42.425197Z","shell.execute_reply.started":"2022-03-16T23:54:42.393704Z","shell.execute_reply":"2022-03-16T23:54:42.424354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3.2 | Categorical Features - Label Encoding","metadata":{}},{"cell_type":"code","source":"for colname in df_data.drop('PassengerId',axis=1).select_dtypes([\"object\",\"category\"]).columns:\n    df_data[colname] = LabelEncoder().fit_transform(df_data[colname])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:42.426502Z","iopub.execute_input":"2022-03-16T23:54:42.427395Z","iopub.status.idle":"2022-03-16T23:54:42.563732Z","shell.execute_reply.started":"2022-03-16T23:54:42.427345Z","shell.execute_reply":"2022-03-16T23:54:42.563089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>4.4 | Feature Selection</b></p>\n</div>\n\n### 4.4.1 | Heatmap","metadata":{}},{"cell_type":"code","source":"df_train = df_data[df_data.Transported.isnull() == False].copy()\ncorr = df_train.drop('Side',axis=1).corr()\n\nfig = px.imshow(corr, color_continuous_scale='RdBu_r', origin='lower', text_auto=True, aspect='auto')\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False)\nfig.update_yaxes(showgrid = True, gridcolor='gray',gridwidth=0.5, linecolor='gray',linewidth=2, zeroline = False)\nfig.update_layout(margin=dict(b=50,t = 90, r=30,l=100), title_text=\"Heatmap\",paper_bgcolor=\"#303330\", plot_bgcolor = \"#303330\", title_font=dict(size=29, color='floralwhite', family=\"Lato, sans-serif\"),\n                  font=dict(color='floralwhite'), \n                  hoverlabel=dict(bgcolor=\"floralwhite\", font_size=13, font_family=\"Lato, sans-serif\"))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:42.564866Z","iopub.execute_input":"2022-03-16T23:54:42.565163Z","iopub.status.idle":"2022-03-16T23:54:42.650726Z","shell.execute_reply.started":"2022-03-16T23:54:42.565132Z","shell.execute_reply":"2022-03-16T23:54:42.649871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.4.2 | Mutual Information\n\nMutual information describes **<span style='color:lightseagreen'>relationships</span>** in terms of **<span style='color:lightseagreen'>uncertainty</span>**. The mutual information (MI) between two quantities is a measure of the extent to which knowledge of one quantity reduces uncertainty about the other. If you knew the value of a feature, how much more confident would you be about the target? Scikit-learn has two mutual information **<span style='color:lightseagreen'>metrics</span>** in its feature_selection module: one for **<span style='color:lightseagreen'>real-valued targets</span>** (mutual_info_regression) and one for **<span style='color:lightseagreen'>categorical targets</span>** (mutual_info_classif). Our target, price, is real-valued. The next cell computes the MI scores for our features and wraps them up in a nice dataframe. Hereafter, we are going to define a baseline score which is going to help us to know whether some set of features we've assembled has actually led to any **<span style='color:lightseagreen'>improvement</span>** or not.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import cross_val_score\n\ndef make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    #discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ny = df_data[df_data['Transported'].isnull() == False]['Transported']\nx = df_data[df_data['Transported'].isnull() == False].drop('Transported', axis=1)\nmi_scores = make_mi_scores(x, y)\nmi_scores = pd.DataFrame(mi_scores).reset_index().rename(columns={'index':'Feature'})\n\nfig = px.bar(mi_scores, x='MI Scores', y='Feature', color=\"MI Scores\",\n             color_continuous_scale='Sunsetdark')\n\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False)\nfig.update_yaxes(showgrid = True, gridcolor='gray',gridwidth=0.5, linecolor='gray',linewidth=2, zeroline = False)\nfig.update_layout(height = 750, title_text=\"Mutual Information Scores\",paper_bgcolor=\"#303330\", plot_bgcolor = \"#303330\", font = dict(color='floralwhite'),\n                  title_font=dict(size=29, family=\"Lato, sans-serif\", color='floralwhite'), xaxis={'categoryorder':'category ascending'}, margin=dict(t=80),\n                  hoverlabel=dict(bgcolor=\"floralwhite\", font_size=13, font_family=\"Lato, sans-serif\"))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T23:54:42.655357Z","iopub.execute_input":"2022-03-16T23:54:42.65573Z","iopub.status.idle":"2022-03-16T23:54:43.761811Z","shell.execute_reply.started":"2022-03-16T23:54:42.655697Z","shell.execute_reply":"2022-03-16T23:54:43.760967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>5 <span style='color:lightseagreen'>|</span> Modeling</b>\n\n<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>5.1 | Algorithm Comparison - Cross Validation</b></p>\n</div>\n\nFor the modeling part we will compare **<span style='color:lightseagreen'>12 known algorithms</span>**, and proceed to evaluate them with several different metrics. Those metrics are the following: \n\n- Average accuracy \n- Balanced accuracy\n- F1 score\n- ROC AUC \n\nWe are going to evaluate the algorithms with a **<span style='color:lightseagreen'>stratified kfold cross validation</span>** procedure. Algorithms are included hereafter: \n\n- Support Vector Classifier (SVC)\n- Decision Tree\n- AdaBoost\n- Random Forest\n- Extra Trees\n- Gradient Boosting\n- K-Nearest Neighbours (KNN)\n- Logistic regression\n- Linear Discriminant Analysis\n- Extreme Gradient Boosting (XGBoost)\n- Catboost Classifier\n- LGBM Classifier\n\nTo begin with, we are going to create a cross validate model with Kfold stratified. Then we'll test each of the algorithms that I have mentioned before.","metadata":{}},{"cell_type":"code","source":"X_train = df_data[df_data.Transported.isnull() == False].drop(['Transported','PassengerId'],axis=1)\ny = df_data[df_data.Transported.isnull() == False].Transported\nX_test = df_data[df_data.Transported.isnull() == True].drop(['Transported','PassengerId'],axis=1).copy()\n\nkfold = StratifiedKFold(n_splits=10)\nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LinearDiscriminantAnalysis())\nclassifiers.append(XGBClassifier(random_state = random_state))\nclassifiers.append(CatBoostClassifier(random_state = random_state))\nclassifiers.append(LGBMClassifier(random_state = random_state))\n\ncv_accuracy = []\ncv_balanced_accuracy = []\ncv_f1 = []\ncv_roc = []\nfor classifier in classifiers :\n    cv_accuracy.append(cross_val_score(classifier, X_train, y = y, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n    cv_balanced_accuracy.append(cross_val_score(classifier, X_train, y = y, scoring = \"balanced_accuracy\", cv = kfold, n_jobs=4))\n    cv_f1.append(cross_val_score(classifier, X_train, y = y, scoring = \"f1\", cv = kfold, n_jobs=4))\n    cv_roc.append(cross_val_score(classifier, X_train, y = y, scoring = \"roc_auc\", cv = kfold, n_jobs=4))\n    \naccuracy = []\nbalanced_accuracy = []\nf1 = []\nroc = []\nfor cv_result in cv_accuracy:\n    accuracy.append(cv_result.mean())\nfor cv_result in cv_balanced_accuracy:\n    balanced_accuracy.append(cv_result.mean())\nfor cv_result in cv_f1:\n    f1.append(cv_result.mean())\nfor cv_result in cv_roc:\n    roc.append(cv_result.mean())\n    \ncomparison = pd.DataFrame({\"Accuracy\":accuracy,\"Balanced Accuracy\": balanced_accuracy,\"ROC AUC\":roc,\n                           \"F1 Score\": f1,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\"RandomForest\",\"ExtraTrees\",\n                            \"GradientBoosting\",\"KNeighboors\",\"LinearDiscriminantAnalysis\",'XGBClassifier','CatBoostClassifier','LGBMClassifier']})\nclear_output()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-16T23:54:43.763298Z","iopub.execute_input":"2022-03-16T23:54:43.764045Z","iopub.status.idle":"2022-03-17T00:16:13.117896Z","shell.execute_reply.started":"2022-03-16T23:54:43.763998Z","shell.execute_reply":"2022-03-17T00:16:13.117349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=2, cols=2, specs=[[{'type':'bar'},{'type':'bar'}], [{'type':'bar'}, {'type':'bar'}]], \n                   subplot_titles=('Accuracy','Balanced Accuracy','F1 Score','ROC AUC'),\n                   column_widths=[0.5, 0.5], vertical_spacing=0.15, horizontal_spacing=0.05)\n\n# Accuracy Chart\nfig.add_trace(go.Bar(y=comparison['Accuracy'].sort_values(), x=comparison['Algorithm'], marker = dict(color=px.colors.sequential.Sunsetdark[0]), \n                     name = 'Accuracy'),row=1, col=1)\n\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=1, col=1)\nfig.update_yaxes(showgrid = False, linecolor='gray',linewidth=2, zeroline = False, row=1, col=1)\n\n# Balanced Accuracy Chart\nfig.add_trace(go.Bar(y=comparison['Balanced Accuracy'].sort_values(), x=comparison['Algorithm'], marker = dict(color=px.colors.sequential.Sunsetdark[1]), \n                     name = 'Balanced Accuracy'),row=1, col=2)\n\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=1, col=2)\nfig.update_yaxes(showgrid = False, linecolor='gray',linewidth=2, zeroline = False, row=1, col=2)\n\n# F1 Score Chart\nfig.add_trace(go.Bar(y=comparison['F1 Score'].sort_values(), x=comparison['Algorithm'], marker = dict(color=px.colors.sequential.Sunsetdark[2]), \n                     name = 'F1 Score'),row=2, col=1)\n\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=2, col=1)\nfig.update_yaxes(showgrid = False, linecolor='gray',linewidth=2, zeroline = False, row=2, col=1)\n\n# ROC AUC Chart\nfig.add_trace(go.Bar(y=comparison['ROC AUC'].sort_values(), x=comparison['Algorithm'], marker = dict(color=px.colors.sequential.Sunsetdark[3]), \n                     name = 'ROC AUC'),row=2, col=2)\n\nfig.update_xaxes(showgrid = False, linecolor='gray', linewidth = 2, zeroline = False, row=2, col=2)\nfig.update_yaxes(showgrid = False, linecolor='gray',linewidth=2, zeroline = False, row=2, col=2)\n\n# General Styling\nfig.update_layout(height=800, bargap=0.2,\n                  margin=dict(b=50,r=30,l=100), xaxis=dict(tickmode='linear'),\n                  title_text=\"Model Comparison Analysis\",\n                  #template=\"plotly_dark\",\n                  paper_bgcolor=\"#303330\",\n                  plot_bgcolor = \"#303330\",\n                  title_font=dict(size=29, color='floralwhite', family=\"Lato, sans-serif\"),\n                  font=dict(color='floralwhite'), \n                  hoverlabel=dict(bgcolor=\"floralwhite\", font_size=13, font_family=\"Lato, sans-serif\"),\n                  showlegend=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T00:16:13.119294Z","iopub.execute_input":"2022-03-17T00:16:13.119717Z","iopub.status.idle":"2022-03-17T00:16:13.235409Z","shell.execute_reply.started":"2022-03-17T00:16:13.119687Z","shell.execute_reply":"2022-03-17T00:16:13.234565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>5.2 | Hyperparameter Tuning - Optuna</b></p>\n</div>\n\nIn this case, only for Catboost, we are going to make the tuning with **<span style='color:lightseagreen'>Optuna</span>**. I will add the code for hyperparameter tuning below. However, for not wasting CPU time, since I have run it once, I will simply create the model with the specific features values. I will control whether making hyperparameter tuning or not with **<span style='color:lightseagreen'>allow_optimize</span>** .","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\ndef objective(trial):\n    params = {\n        \"random_state\":trial.suggest_categorical(\"random_state\", [2022]),\n        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.0001, 0.3),\n        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n        \"n_estimators\": 1000,\n        \"max_depth\":trial.suggest_int(\"max_depth\", 4, 16),\n        'random_strength' :trial.suggest_int('random_strength', 0, 100),\n        \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\",1e-8,3e-5),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n        #'task_type': trial.suggest_categorical('task_type', ['GPU']),\n        'eval_metric': trial.suggest_categorical('eval_metric', ['Accuracy'])\n    }\n\n    model = CatBoostClassifier(**params)\n    X_train_tmp, X_valid_tmp, y_train_tmp, y_valid_tmp = train_test_split(X_train, y, test_size=0.3, random_state=42)\n    model.fit(\n        X_train_tmp, y_train_tmp,\n        eval_set=[(X_valid_tmp, y_valid_tmp)],\n        early_stopping_rounds=35, verbose=0\n    )\n        \n    y_train_pred = model.predict(X_train_tmp)\n    y_valid_pred = model.predict(X_valid_tmp)\n    train_mae = accuracy_score(y_train_tmp, y_train_pred)\n    valid_mae = accuracy_score(y_valid_tmp, y_valid_pred)\n    \n    return valid_mae\n\nallow_optimize = 0","metadata":{"execution":{"iopub.status.busy":"2022-03-17T00:16:13.236931Z","iopub.execute_input":"2022-03-17T00:16:13.237315Z","iopub.status.idle":"2022-03-17T00:16:13.248803Z","shell.execute_reply.started":"2022-03-17T00:16:13.23727Z","shell.execute_reply":"2022-03-17T00:16:13.247877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRIALS = 100\nTIMEOUT = 3600\n\nif allow_optimize:\n    sampler = TPESampler(seed=42)\n\n    study = optuna.create_study(\n        study_name = 'cat_parameter_opt',\n        direction = 'maximize',\n        sampler = sampler,\n    )\n    study.optimize(objective, n_trials=TRIALS)\n    print(\"Best Score:\",study.best_value)\n    print(\"Best trial\",study.best_trial.params)\n    \n    best_params = study.best_params\n    \n    X_train_tmp, X_valid_tmp, y_train_tmp, y_valid_tmp = train_test_split(X_train, y, test_size=0.3, random_state=42)\n    model_tmp = CatBoostClassifier(**best_params, n_estimators=30000, verbose=1000).fit(X_train_tmp, y_train_tmp, eval_set=[(X_valid_tmp, y_valid_tmp)], early_stopping_rounds=35)\n    clear_output()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T00:16:13.25022Z","iopub.execute_input":"2022-03-17T00:16:13.250605Z","iopub.status.idle":"2022-03-17T00:16:13.259831Z","shell.execute_reply.started":"2022-03-17T00:16:13.25056Z","shell.execute_reply":"2022-03-17T00:16:13.259133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if allow_optimize:\n    model = CatBoostClassifier(**best_params, n_estimators=model_tmp.get_best_iteration(), verbose=1000).fit(X, y)\nelse:\n    model = CatBoostClassifier(\n        early_stopping_rounds=10,\n        silent = True,\n        random_state = 2022, learning_rate = 0.10851035034096206, bagging_temperature = 1.6587780950847202, max_depth = 4, \n        random_strength = 57, l2_leaf_reg = 1.0527606077755484e-05, min_child_samples = 60, max_bin = 203, eval_metric = 'Accuracy'\n    ).fit(X_train, y)    ","metadata":{"execution":{"iopub.status.busy":"2022-03-17T00:16:13.261091Z","iopub.execute_input":"2022-03-17T00:16:13.261453Z","iopub.status.idle":"2022-03-17T00:16:16.325073Z","shell.execute_reply.started":"2022-03-17T00:16:13.261407Z","shell.execute_reply":"2022-03-17T00:16:16.324266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:8px;\n            background-color:#323232;font-size:150%;\n            font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 8px;color:white;\"><b>5. | Permutation Importance</b></p>\n</div>\n\nOne of the most basic questions we might ask of a model is: **<span style='color:lightseagreen'>What features have the biggest impact on predictions?</span>** This concept is called feature importance. There are multiple ways to measure feature importance. Some approaches answer subtly different versions of the question above. Other approaches have documented shortcomings. In this section, we'll focus on permutation importance. Compared to most other approaches, permutation importance is:\n\n- Fast to calculate,\n- Widely used and understood, and\n- Consistent with properties we would want a feature importance measure to have.\n","metadata":{}},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(model, random_state=1).fit(X_train, y)\npred = model.predict(X_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-17T00:16:16.326209Z","iopub.execute_input":"2022-03-17T00:16:16.326411Z","iopub.status.idle":"2022-03-17T00:16:22.892545Z","shell.execute_reply.started":"2022-03-17T00:16:16.326386Z","shell.execute_reply":"2022-03-17T00:16:22.891757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ðŸ“Œ Interpret:** the values towards the top are the **<span style='color:lightseagreen'>most important features</span>**, and those towards the bottom matter least. The first number in each row shows how much **<span style='color:lightseagreen'>model performance decreased</span>** with a random shuffling (in this case, using \"accuracy\" as the performance metric). Like most things in data science, there is some **<span style='color:lightseagreen'>randomness</span>** to the exact performance change from a shuffling a column. We measure the amount of randomness in our permutation importance calculation by repeating the process with multiple shuffles. The number after the Â± measures how **<span style='color:lightseagreen'>performance varied from one-reshuffling to the next</span>**. You'll occasionally see negative values for permutation importances. In those cases, the predictions on the shuffled (or noisy) data happened to be more accurate than the real data. This happens when the feature didn't matter (should have had an importance close to 0), but random chance caused the predictions on shuffled data to be more accurate. This is more common with small datasets, like the one in this example, because there is more room for luck/chance.","metadata":{}},{"cell_type":"code","source":"submit = pd.DataFrame({'PassengerId': df_data[df_data.Transported.isnull() == True]['PassengerId'].astype(object), 'Transported':pred}).set_index('PassengerId')\nsubmit['Transported'].replace([0,1], [False, True], inplace=True)\nsubmit.to_csv('./submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T00:16:22.893768Z","iopub.execute_input":"2022-03-17T00:16:22.894289Z","iopub.status.idle":"2022-03-17T00:16:22.914953Z","shell.execute_reply.started":"2022-03-17T00:16:22.894237Z","shell.execute_reply":"2022-03-17T00:16:22.914197Z"},"trusted":true},"execution_count":null,"outputs":[]}]}