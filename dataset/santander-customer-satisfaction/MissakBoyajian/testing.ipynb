{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import gc\nimport xgboost as xgb\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics import log_loss, roc_auc_score\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.preprocessing import normalize\nfrom sklearn.decomposition import PCA\n\nif __name__ == \"__main__\":\n    print('Started!')\n    train = pd.read_csv('C:/Users/Brains/Desktop/train.csv')\n    test = pd.read_csv('C:/Users/Brains/Desktop/test.csv')\n    features = train.columns[1:-1]\n    train.insert(1, 'SumZeros', (train[features] == 0).astype(int).sum(axis=1))\n    test.insert(1, 'SumZeros', (test[features] == 0).astype(int).sum(axis=1))\n\n    remove = []\n    c = train.columns\n    for i in range(len(c)-1):\n        v = train[c[i]].values\n        for j in range(i+1, len(c)):\n            if np.array_equal(v, train[c[j]].values):\n                remove.append(c[j])\n\n    train.drop(remove, axis=1, inplace=True)\n    test.drop(remove, axis=1, inplace=True)\n\n    remove = []\n    for col in train.columns:\n        if train[col].std() == 0:\n            remove.append(col)\n\n    train.drop(remove, axis=1, inplace=True)\n    test.drop(remove, axis=1, inplace=True)\n    features = train.columns[1:-1]\n    pca = PCA(n_components=2)\n    x_train_projected = pca.fit_transform(normalize(train[features], axis=0))\n    x_test_projected = pca.transform(normalize(test[features], axis=0))\n    train.insert(1, 'PCAOne', x_train_projected[:, 0])\n    train.insert(1, 'PCATwo', x_train_projected[:, 1])\n    test.insert(1, 'PCAOne', x_test_projected[:, 0])\n    test.insert(1, 'PCATwo', x_test_projected[:, 1])\n    tokeep = ['num_var39_0',  # 0.00031104199066874026\n              'ind_var13',  # 0.00031104199066874026\n              'num_op_var41_comer_ult3',  # 0.00031104199066874026\n              'num_var43_recib_ult1',  # 0.00031104199066874026\n              'imp_op_var41_comer_ult3',  # 0.00031104199066874026\n              'num_var8',  # 0.00031104199066874026\n              'num_var42',  # 0.00031104199066874026\n              'num_var30',  # 0.00031104199066874026\n              'saldo_var8',  # 0.00031104199066874026\n              'num_op_var39_efect_ult3',  # 0.00031104199066874026\n              'num_op_var39_comer_ult3',  # 0.00031104199066874026\n              'num_var41_0',  # 0.0006220839813374805\n              'num_op_var39_ult3',  # 0.0006220839813374805\n              'saldo_var13',  # 0.0009331259720062209\n              'num_var30_0',  # 0.0009331259720062209\n              'ind_var37_cte',  # 0.0009331259720062209\n              'ind_var39_0',  # 0.001244167962674961\n              'num_var5',  # 0.0015552099533437014\n              'ind_var10_ult1',  # 0.0015552099533437014\n              'num_op_var39_hace2',  # 0.0018662519440124418\n              'num_var22_hace2',  # 0.0018662519440124418\n              'num_var35',  # 0.0018662519440124418\n              'ind_var30',  # 0.0018662519440124418\n              'num_med_var22_ult3',  # 0.002177293934681182\n              'imp_op_var41_efect_ult1',  # 0.002488335925349922\n              'var36',  # 0.0027993779160186624\n              'num_med_var45_ult3',  # 0.003110419906687403\n              'imp_op_var39_ult1',  # 0.0037325038880248835\n              'imp_op_var39_comer_ult3',  # 0.0037325038880248835\n              'imp_trans_var37_ult1',  # 0.004043545878693624\n              'num_var5_0',  # 0.004043545878693624\n              'num_var45_ult1',  # 0.004665629860031105\n              'ind_var41_0',  # 0.0052877138413685845\n              'imp_op_var41_ult1',  # 0.0052877138413685845\n              'num_var8_0',  # 0.005598755832037325\n              'imp_op_var41_efect_ult3',  # 0.007153965785381027\n              'num_op_var41_ult3',  # 0.007153965785381027\n              'num_var22_hace3',  # 0.008087091757387248\n              'num_var4',  # 0.008087091757387248\n              'imp_op_var39_comer_ult1',  # 0.008398133748055987\n              'num_var45_ult3',  # 0.008709175738724729\n              'ind_var5',  # 0.009953343701399688\n              'imp_op_var39_efect_ult3',  # 0.009953343701399688\n              'num_meses_var5_ult3',  # 0.009953343701399688\n              'saldo_var42',  # 0.01181959564541213\n              'imp_op_var39_efect_ult1',  # 0.013374805598755831\n              'PCATwo',  # 0.013996889580093312\n              'num_var45_hace2',  # 0.014618973561430793\n              'num_var22_ult1',  # 0.017107309486780714\n              'saldo_medio_var5_ult1',  # 0.017418351477449457\n              'PCAOne',  # 0.018040435458786936\n              'saldo_var5',  # 0.0208398133748056\n              'ind_var8_0',  # 0.021150855365474338\n              'ind_var5_0',  # 0.02177293934681182\n              'num_meses_var39_vig_ult3',  # 0.024572317262830483\n              'saldo_medio_var5_ult3',  # 0.024883359253499222\n              'num_var45_hace3',  # 0.026749611197511663\n              'num_var22_ult3',  # 0.03452566096423017\n              'saldo_medio_var5_hace3',  # 0.04074650077760498\n              'saldo_medio_var5_hace2',  # 0.04292379471228616\n              'SumZeros',  # 0.04696734059097978\n              'saldo_var30',  # 0.09611197511664074\n              'var38',  # 0.1390357698289269\n              'var15']  # 0.20964230171073095\n    features = train.columns[1:-1]\n    todrop = list(set(tokeep).difference(set(features)))\n    train.drop(todrop, inplace=True, axis=1)\n    test.drop(todrop, inplace=True, axis=1)\n    features = train.columns[1:-1]\n    split = 10\n    skf = StratifiedKFold(train.TARGET.values,\n                          n_folds=split,\n                          shuffle=False,\n                          random_state=42)\n\n    train_preds = None\n    test_preds = None\n    visibletrain = blindtrain = train\n    index = 0\n    print('Change num_rounds to 350')\n    num_rounds = 10\n    params = {}\n    params[\"objective\"] = \"binary:logistic\"\n    params[\"eta\"] = 0.03\n    params[\"subsample\"] = 0.8\n    params[\"colsample_bytree\"] = 0.7\n    params[\"silent\"] = 1\n    params[\"max_depth\"] = 5\n    params[\"min_child_weight\"] = 1\n    params[\"eval_metric\"] = \"auc\"\n    for train_index, test_index in skf:\n        print('Fold:', index)\n        visibletrain = train.iloc[train_index]\n        blindtrain = train.iloc[test_index]\n        dvisibletrain = \\\n            xgb.DMatrix(csr_matrix(visibletrain[features]),\n                        visibletrain.TARGET.values,\n                        silent=True)\n        dblindtrain = \\\n            xgb.DMatrix(csr_matrix(blindtrain[features]),\n                        blindtrain.TARGET.values,\n                        silent=True)\n        watchlist = [(dblindtrain, 'eval'), (dvisibletrain, 'train')]\n        clf = xgb.train(params, dvisibletrain, num_rounds,\n                        evals=watchlist, early_stopping_rounds=50,\n                        verbose_eval=False)\n\n        blind_preds = clf.predict(dblindtrain)\n        print('Blind Log Loss:', log_loss(blindtrain.TARGET.values,\n                                          blind_preds))\n        print('Blind ROC:', roc_auc_score(blindtrain.TARGET.values,\n                                          blind_preds))\n        index = index+1\n        del visibletrain\n        del blindtrain\n        del dvisibletrain\n        del dblindtrain\n        gc.collect()\n        dfulltrain = \\\n            xgb.DMatrix(csr_matrix(train[features]),\n                        train.TARGET.values,\n                        silent=True)\n        dfulltest = \\\n            xgb.DMatrix(csr_matrix(test[features]),\n                        silent=True)\n        if(train_preds is None):\n            train_preds = clf.predict(dfulltrain)\n            test_preds = clf.predict(dfulltest)\n        else:\n            train_preds *= clf.predict(dfulltrain)\n            test_preds *= clf.predict(dfulltest)\n        del dfulltrain\n        del dfulltest\n        del clf\n        gc.collect()\n\n    train_preds = np.power(train_preds, 1./index)\n    test_preds = np.power(test_preds, 1./index)\n    print('Average Log Loss:', log_loss(train.TARGET.values, train_preds))\n    print('Average ROC:', roc_auc_score(train.TARGET.values, train_preds))\n    submission = pd.DataFrame({\"ID\": train.ID,\n                               \"TARGET\": train.TARGET,\n                               \"PREDICTION\": train_preds})\n\n    submission.to_csv(\"simplexgbtrain.csv\", index=False)\n    submission = pd.DataFrame({\"ID\": test.ID, \"TARGET\": test_preds})\n    submission.to_csv(\"simplexgbtest.csv\", index=False)\n    print('Finish')\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}