{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Advanced Feature Exploration"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import cluster\nfrom sklearn import ensemble\nfrom sklearn import cross_validation\nfrom sklearn.metrics import roc_auc_score as auc\nimport time\n\nplt.rcParams['figure.figsize'] = (10, 10)\n\n#%% load data and remove constant and duplicate columns  (taken from a kaggle script)\n\ntrainDataFrame = pd.read_csv('../input/train.csv')\n\n# remove constant columns\ncolsToRemove = []\nfor col in trainDataFrame.columns:\n    if trainDataFrame[col].std() == 0:\n        colsToRemove.append(col)\n\ntrainDataFrame.drop(colsToRemove, axis=1, inplace=True)\n\n# remove duplicate columns\ncolsToRemove = []\ncolumns = trainDataFrame.columns\nfor i in range(len(columns)-1):\n    v = trainDataFrame[columns[i]].values\n    for j in range(i+1,len(columns)):\n        if np.array_equal(v,trainDataFrame[columns[j]].values):\n            colsToRemove.append(columns[j])\n\ntrainDataFrame.drop(colsToRemove, axis=1, inplace=True)\n\ntrainLabels = trainDataFrame['TARGET']\ntrainFeatures = trainDataFrame.drop(['ID','TARGET'], axis=1)\n\n\n#%% look at single feature performance\n\nX_train, X_valid, y_train, y_valid = cross_validation.train_test_split(trainFeatures, trainLabels, \n                                                                       test_size=0.5, random_state=1)\nverySimpleLearner = ensemble.GradientBoostingClassifier(n_estimators=20, max_features=1, max_depth=3, \n                                                        min_samples_leaf=100, learning_rate=0.1, \n                                                        subsample=0.65, loss='deviance', random_state=1)\n\nstartTime = time.time()\nsingleFeatureTable = pd.DataFrame(index=range(len(X_train.columns)), columns=['feature','AUC'])\nfor k,feature in enumerate(X_train.columns):\n    trainInputFeature = X_train[feature].values.reshape(-1,1)\n    validInputFeature = X_valid[feature].values.reshape(-1,1)\n    verySimpleLearner.fit(trainInputFeature, y_train)\n    \n    validAUC = auc(y_valid, verySimpleLearner.predict_proba(validInputFeature)[:,1])\n    singleFeatureTable.ix[k,'feature'] = feature\n    singleFeatureTable.ix[k,'AUC'] = validAUC\n        \nprint(\"finished evaluating single features. took %.2f minutes\" %((time.time()-startTime)/60))"},{"cell_type":"markdown","metadata":{},"source":"### Show single feature AUC performace\nthis is the same as in \"Basic Feature Exploration\" script, to be used later"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#%% sort according to AUC and present the table\nsingleFeatureTable = singleFeatureTable.sort_values(by='AUC', axis=0, ascending=False).reset_index(drop=True)\n\nsingleFeatureTable.ix[:15,:]"},{"cell_type":"markdown","metadata":{},"source":"### Generate 400 five-wise random feature combinations and calculate their AUC"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#%% find interesting fivewise combinations\n\nnumFeaturesInCombination = 5\nnumCombinations = 400\nnumBestSingleFeaturesToSelectFrom = 20\n\nX_train, X_valid, y_train, y_valid = cross_validation.train_test_split(trainFeatures, trainLabels, \n                                                                       test_size=0.5, random_state=1)\nweakLearner = ensemble.GradientBoostingClassifier(n_estimators=30, max_features=2, max_depth=3, \n                                                  min_samples_leaf=100,learning_rate=0.1, \n                                                  subsample=0.65, loss='deviance', random_state=1)\n\nfeaturesToUse = singleFeatureTable.ix[0:numBestSingleFeaturesToSelectFrom-1,'feature']\nfeatureColumnNames = ['feature'+str(x+1) for x in range(numFeaturesInCombination)]\nfeatureCombinationsTable = pd.DataFrame(index=range(numCombinations), columns=featureColumnNames + ['combinedAUC'])\n\n# for numCombinations iterations \nstartTime = time.time()\nfor combination in range(numCombinations):\n    # generate random feature combination\n    randomSelectionOfFeatures = sorted(np.random.choice(len(featuresToUse), numFeaturesInCombination, replace=False))\n\n    # store the feature names\n    combinationFeatureNames = [featuresToUse[x] for x in randomSelectionOfFeatures]\n    for i in range(len(randomSelectionOfFeatures)):\n        featureCombinationsTable.ix[combination,featureColumnNames[i]] = combinationFeatureNames[i]\n\n    # build features matrix to get the combination AUC\n    trainInputFeatures = X_train.ix[:,combinationFeatureNames]\n    validInputFeatures = X_valid.ix[:,combinationFeatureNames]\n    # train learner\n    weakLearner.fit(trainInputFeatures, y_train)\n    # store AUC results\n    validAUC = auc(y_valid, weakLearner.predict_proba(validInputFeatures)[:,1])        \n    featureCombinationsTable.ix[combination,'combinedAUC'] = validAUC\n\nvalidAUC = np.array(featureCombinationsTable.ix[:,'combinedAUC'])\nprint(\"(min,max) AUC = (%.4f,%.4f). took %.1f minutes\" % (validAUC.min(),validAUC.max(), (time.time()-startTime)/60))\n\n# show the histogram of the feature combinations performance \nplt.figure(); plt.hist(validAUC, 100, facecolor='blue', alpha=0.75)\nplt.xlabel('AUC'); plt.ylabel('frequency'); plt.title('feature combination AUC histogram'); plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#%% sort according to combination AUC and look at the table\n\nfeatureCombinationsTable = featureCombinationsTable.sort_values(by='combinedAUC', axis=0, ascending=False).reset_index(drop=True)\nfeatureCombinationsTable.ix[:20,:]"},{"cell_type":"markdown","metadata":{},"source":"it's easy to see that this table contains a lot of feature overlap\n### Visualize this by building a Pairwise Overlap Matrix"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#%% visualize the overlap by building a pairwise overlap matrix\n\ncombinationOverlapMatrix = np.zeros((numCombinations,numCombinations))\nfor comb_i in range(numCombinations):\n    for comb_j in range(comb_i+1,numCombinations):\n        # get the features list for each combination        \n        featuresComb_i = [featureCombinationsTable.ix[comb_i,featureColumnNames[x]] for x in range(numFeaturesInCombination)]\n        featuresComb_j = [featureCombinationsTable.ix[comb_j,featureColumnNames[x]] for x in range(numFeaturesInCombination)]\n        # store the number of overlapping features\n        combinationOverlapMatrix[comb_i,comb_j] = 2*numFeaturesInCombination-len(set(featuresComb_i+featuresComb_j))\n        combinationOverlapMatrix[comb_j,comb_i] = combinationOverlapMatrix[comb_i,comb_j]\n\nplt.figure(); plt.imshow(combinationOverlapMatrix,cmap='autumn'); plt.title('combination overlap'); plt.colorbar()"},{"cell_type":"markdown","metadata":{},"source":"#### We would like to remove some of this redundancy\n### Perform k-means on the overlap patterns and reorder the matrix"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#%% we would like to get the top performing but most different feature combinations\n\nnumFeaturesToSelect = 15\n\ncluserer = cluster.KMeans(n_clusters=numFeaturesToSelect)\nclusterInds = cluserer.fit_predict(combinationOverlapMatrix)\n\n#%% reorder features according to their new clusters\n\n# group the rows into clusters\nclusteredRows = {}\nclusterMaxAUC = {}\nclusterMaxInd = {}\nfor clusterInd in np.unique(clusterInds):\n    clusteredRows[clusterInd] = combinationOverlapMatrix[clusterInds == clusterInd,:]\n    clusterMaxAUC[clusterInd] = featureCombinationsTable.ix[clusterInds == clusterInd,'combinedAUC'].max(axis=0)\n    clusterMaxInd[clusterInd] = featureCombinationsTable.ix[clusterInds == clusterInd,'combinedAUC'].idxmax(axis=0)    \n    \nimport operator    \nsortedClustersByMaxAUCTuple = sorted(clusterMaxAUC.items(), key=operator.itemgetter(1),reverse=True)\n\n# calculate the reordering vector\nfinalFeaturesToKeep = []\nreorderedVector = None\nfor k,item in enumerate(sortedClustersByMaxAUCTuple):\n    if k == 0:\n        reorderedVector = np.array((clusterInds == item[0]).nonzero())\n    else:\n        reorderedVector = np.hstack((reorderedVector,np.array((clusterInds == item[0]).nonzero())))\n    finalFeaturesToKeep.append(clusterMaxInd[item[0]])\nreorderedVector = reorderedVector.flatten()\n\n# reorder the matrix by rows and columns\nreorderedMatrix = combinationOverlapMatrix[reorderedVector,:]\nreorderedMatrix = reorderedMatrix[:,reorderedVector]\n\n# show the matrix\nplt.figure(); plt.imshow(reorderedMatrix,cmap='autumn'); plt.title('reordered combination overlap'); plt.colorbar()\n"},{"cell_type":"markdown","metadata":{},"source":"# End Result\n### The 15 Best least redundent five-wise feature combinations"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#%% show the final combinations\n\nfeatureCombinationsTable.ix[finalFeaturesToKeep,:]"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}