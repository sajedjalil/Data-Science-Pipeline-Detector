{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn import ensemble\nfrom sklearn import cross_validation\nfrom sklearn.metrics import roc_auc_score as auc\nimport time\n\nplt.rcParams['figure.figsize'] = (12, 6)\n\n#%% load data and remove constant and duplicate columns  (taken from a kaggle script)\n\ntrainDataFrame = pd.read_csv('../input/train.csv')\n\n# remove constant columns\ncolsToRemove = []\nfor col in trainDataFrame.columns:\n    if trainDataFrame[col].std() == 0:\n        colsToRemove.append(col)\n\ntrainDataFrame.drop(colsToRemove, axis=1, inplace=True)\n\n# remove duplicate columns\ncolsToRemove = []\ncolumns = trainDataFrame.columns\nfor i in range(len(columns)-1):\n    v = trainDataFrame[columns[i]].values\n    for j in range(i+1,len(columns)):\n        if np.array_equal(v,trainDataFrame[columns[j]].values):\n            colsToRemove.append(columns[j])\n\ntrainDataFrame.drop(colsToRemove, axis=1, inplace=True)\n\ntrainLabels = trainDataFrame['TARGET']\ntrainFeatures = trainDataFrame.drop(['ID','TARGET'], axis=1)\n"},{"cell_type":"markdown","metadata":{},"source":"### Build an estimator trying to predict the target for each feature individually\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#%% look at single feature performance\n\nverySimpleLearner = ensemble.GradientBoostingClassifier(n_estimators=10, max_features=1, max_depth=3,\n                                                        min_samples_leaf=100,learning_rate=0.3, subsample=0.65,\n                                                        loss='deviance', random_state=1)\n\nX_train, X_valid, y_train, y_valid = cross_validation.train_test_split(trainFeatures, trainLabels, test_size=0.5, random_state=1)\n        \nstartTime = time.time()\nsingleFeatureAUC_list = []\nsingleFeatureAUC_dict = {}\nfor feature in X_train.columns:\n    trainInputFeature = X_train[feature].values.reshape(-1,1)\n    validInputFeature = X_valid[feature].values.reshape(-1,1)\n    verySimpleLearner.fit(trainInputFeature, y_train)\n    \n    trainAUC = auc(y_train, verySimpleLearner.predict_proba(trainInputFeature)[:,1])\n    validAUC = auc(y_valid, verySimpleLearner.predict_proba(validInputFeature)[:,1])\n        \n    singleFeatureAUC_list.append(validAUC)\n    singleFeatureAUC_dict[feature] = validAUC\n        \nvalidAUC = np.array(singleFeatureAUC_list)\ntimeToTrain = (time.time()-startTime)/60\nprint(\"(min,mean,max) AUC = (%.3f,%.3f,%.3f). took %.2f minutes\" %(validAUC.min(),validAUC.mean(),validAUC.max(), timeToTrain))\n\n# show the scatter plot of the individual feature performance \nplt.figure(); plt.hist(validAUC, 50, normed=1, facecolor='blue', alpha=0.75)\nplt.xlabel('AUC'); plt.ylabel('frequency'); plt.title('single feature AUC histogram'); plt.show()"},{"cell_type":"markdown","metadata":{},"source":"### Show single feature AUC performace"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# create a table with features sorted according to AUC\nsingleFeatureTable = pd.DataFrame(index=range(len(singleFeatureAUC_dict.keys())), columns=['feature','AUC'])\nfor k,key in enumerate(singleFeatureAUC_dict):\n    singleFeatureTable.ix[k,'feature'] = key\n    singleFeatureTable.ix[k,'AUC'] = singleFeatureAUC_dict[key]\nsingleFeatureTable = singleFeatureTable.sort_values(by='AUC', axis=0, ascending=False).reset_index(drop=True)\n\nsingleFeatureTable.ix[:15,:]"},{"cell_type":"markdown","metadata":{},"source":"### Show scatter pltos of (feature, target) for the top performing single features"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"numSubPlotRows = 1\nnumSubPlotCols = 2\nfor plotInd in range(8):\n    plt.figure()\n    for k in range(numSubPlotRows*numSubPlotCols):\n        tableRow = numSubPlotRows*numSubPlotCols*plotInd+k\n        x = X_train[singleFeatureTable.ix[tableRow,'feature']].values.reshape(-1,1)[:,0]\n        \n        # use a huristic to find out if the variable is categorical, and if so add some random noise to it\n        if len(np.unique(x)) < 20:\n            diffVec = abs(x[1:]-x[:-1])\n            minDistBetweenCategories = min(diffVec[diffVec > 0])\n            x = x + 0.12*minDistBetweenCategories*np.random.randn(np.shape(x)[0])\n            \n        y = y_train + 0.12*np.random.randn(np.shape(y_train)[0])\n        # take only 3000 samples to be presented due to plotting issues\n        randPermutation = np.random.choice(len(x), 3000, replace=False)\n        plt.subplot(numSubPlotRows,numSubPlotCols,k+1)\n        plt.scatter(x[randPermutation], y[randPermutation], c=y_train[randPermutation], cmap='jet', alpha=0.25)\n        plt.xlabel(singleFeatureTable.ix[tableRow,'feature']); plt.ylabel('y GT')\n        plt.title('AUC = %.4f' %(singleFeatureTable.ix[tableRow,'AUC']))            \n        plt.ylim(-0.5,1.5); plt.tight_layout()\n"},{"cell_type":"markdown","metadata":{},"source":"### Build an estimator trying to predict the target with pairs of features"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#%% look at performance of pairs of features\n\n# limit run time (on all feature combinations should take a few hours)\nnumFeaturesToUse = 20\nfeaturesToUse = singleFeatureTable.ix[0:numFeaturesToUse-1,'feature']\n\nX_train, X_valid, y_train, y_valid = cross_validation.train_test_split(trainFeatures, trainLabels, test_size=0.5, random_state=1)\n    \nstartTime = time.time()\nfeaturePairAUC_list = []\nfeaturePairAUC_dict = {}\n\nfor feature1Ind in range(len(featuresToUse)-1):\n    featureName1 = featuresToUse[feature1Ind]\n    trainInputFeature1 = X_train[featureName1].values.reshape(-1,1)\n    validInputFeature1 = X_valid[featureName1].values.reshape(-1,1)\n\n    for feature2Ind in range(feature1Ind+1,len(featuresToUse)-1):\n        featureName2 = featuresToUse[feature2Ind]\n        trainInputFeature2 = X_train[featureName2].values.reshape(-1,1)\n        validInputFeature2 = X_valid[featureName2].values.reshape(-1,1)\n\n        trainInputFeatures = np.hstack((trainInputFeature1,trainInputFeature2))\n        validInputFeatures = np.hstack((validInputFeature1,validInputFeature2))\n        \n        verySimpleLearner.fit(trainInputFeatures, y_train)\n        \n        trainAUC = auc(y_train, verySimpleLearner.predict_proba(trainInputFeatures)[:,1])\n        validAUC = auc(y_valid, verySimpleLearner.predict_proba(validInputFeatures)[:,1])\n            \n        featurePairAUC_list.append(validAUC)\n        featurePairAUC_dict[(featureName1,featureName2)] = validAUC\n        \nvalidAUC = np.array(featurePairAUC_list)\ntimeToTrain = (time.time()-startTime)/60\nprint(\"(min,mean,max) AUC = (%.3f,%.3f,%.3f). took %.1f minutes\" % (validAUC.min(),validAUC.mean(),validAUC.max(), timeToTrain))\n\n# show the histogram of the feature combinations performance \nplt.figure(); plt.hist(validAUC, 50, normed=1, facecolor='blue', alpha=0.75)\nplt.xlabel('AUC'); plt.ylabel('frequency'); plt.title('feature pair AUC histogram'); plt.show()"},{"cell_type":"markdown","metadata":{},"source":"### Show AUC performace of best pairs of features"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# create a table with features sorted according to AUC\nfeatureCombinationsTable = pd.DataFrame(index=range(len(featurePairAUC_list)), columns=['feature1','feature2','AUC'])\nfor k,key in enumerate(featurePairAUC_dict):\n    featureCombinationsTable.ix[k,'feature1'] = key[0]\n    featureCombinationsTable.ix[k,'feature2'] = key[1]\n    featureCombinationsTable.ix[k,'AUC'] = featurePairAUC_dict[key]\nfeatureCombinationsTable = featureCombinationsTable.sort_values(by='AUC', axis=0, ascending=False).reset_index(drop=True)\n\nfeatureCombinationsTable.ix[:20,:]"},{"cell_type":"markdown","metadata":{},"source":"### Show the top performing feature pairs\nscatter pltos of (feature1, feature2) with colored labels \n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# show the scatter plot of best feature pair combinations\nnumPlotRows = 1\nnumPlotCols = 2\nfor plotInd in range(8):\n    plt.figure()\n    for k in range(numPlotRows*numPlotCols):\n        tableRow = numPlotRows*numPlotCols*plotInd+k\n        x = X_train[featureCombinationsTable.ix[tableRow,'feature1']].values.reshape(-1,1)[:,0]\n        y = X_train[featureCombinationsTable.ix[tableRow,'feature2']].values.reshape(-1,1)[:,0]\n\n        # use a huristic to find out if the variables are categorical, and if so add some random noise to them\n        if len(np.unique(x)) < 20:\n            diffVec = abs(x[1:]-x[:-1])\n            minDistBetweenCategories = min(diffVec[diffVec > 0])\n            x = x + 0.12*minDistBetweenCategories*np.random.randn(np.shape(x)[0])\n\n        if len(np.unique(y)) < 20:\n            diffVec = abs(y[1:]-y[:-1])\n            minDistBetweenCategories = min(diffVec[diffVec > 0])\n            y = y + 0.12*minDistBetweenCategories*np.random.randn(np.shape(y)[0])\n\n        colors = y_train\n        # take only 3000 samples to be presented due to plotting issues\n        randPermutation = np.random.choice(len(x), 3000, replace=False)\n        plt.subplot(numPlotRows,numPlotCols,k+1)\n        plt.scatter(x[randPermutation], y[randPermutation], s=(3+1.6*colors[randPermutation])**2, c=-colors[randPermutation], cmap='spring', alpha=0.75)\n        plt.xlabel(featureCombinationsTable.ix[tableRow,'feature1']); plt.ylabel(featureCombinationsTable.ix[tableRow,'feature2'])\n        plt.title('AUC = %.4f' %(featureCombinationsTable.ix[tableRow,'AUC'])); plt.tight_layout()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}