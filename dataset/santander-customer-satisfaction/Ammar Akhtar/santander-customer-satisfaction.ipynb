{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Importing Packages"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Loading Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df=pd.read_csv('../input/santander-customer-satisfaction/train.csv').set_index('ID')\ntest_df=pd.read_csv('../input/santander-customer-satisfaction/test.csv').set_index('ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=pd.DataFrame(train_df['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" \n    iterate through all the columns of a dataframe and \n    modify the data type to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage of dataframe is {:.2f}''MB').format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max <np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max <np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max <np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max <np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                #if c_min > np.finfo(np.float16).min and c_max <np.finfo(np.float16).max:\n                    #df[col] = df[col].astype(np.float16)\n                if c_min > np.finfo(np.float32).min and c_max <np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage after optimization is: {:.2f}''MB').format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reducing memory\ntrain_df=reduce_mem_usage(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initially, the database had 76020 records, 369 features and 1 Target Column. The size of the database was reduced significantly from 215.18MB to 62.7MB, i.e. making it 70.9% more optimised by changing the datatypes of the columns. We reduced the memory space by converting 111 float64 and 259 int64 columns/features into 111 float32, 4 int32, 30 int16, 16 int64, 209 int8 columns/features."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Custom Code to Display properties of each column\ndef ldf_f(train_df):\n    l=[]\n    for i in train_df.columns:\n        l.append([i,len(train_df[i].unique()),round(max(train_df[i].unique()),2),round(min(train_df[i].unique()),2),train_df[i].var(),train_df[i].astype(bool).sum(axis=0),train_df[i].count(),sorted(list(train_df[i].unique()))])\n    return pd.DataFrame(l, columns=['Features', 'No_Unique_Values', 'Max_Value','Min_Value','Variance','Non-Zero','Total_Values','Unique_Values'])\nldf=ldf_f(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.set_option('display.max_rows',None)\n#pd.set_option('display.precision',2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf[['Features','No_Unique_Values','Max_Value','Min_Value','Unique_Values','Non-Zero']].astype({'Max_Value': int,'Min_Value':int})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Created a new dataframe describing all data of each columns. We have the following observations from this dataframe:\n* There are no missing values labelled as NaN, rather they have been replaced with highest/lowest values.\n* The missing values are denoted by 10000000000, 9999999999, -999999.\n* Also, 99 is also considered a missing value for var36. Since, 99 seems to be adrift off 0,1,2,3.\n* All these values will be replaced by the mode/maximum_frequency with repect to the target value.\n* There are several columns that have same values through out, i.e., Only one Unique Value.\n* var3 seems to represent country as its values ranged from 0 to 238 with 208 unique values and also  some missing values.\n* var15 seems to be age since its values ranged between 22 to 105 with 100 unique values, a range that seems similar to that age"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_impute=list(ldf[(ldf.Max_Value==9999999999) | (ldf.Max_Value==10000000000)].Features)\nfor i in max_impute:\n    if i in train_df.columns:\n        print (train_df[(train_df[i]==9999999999) | (train_df[i]==10000000000)].shape,'\\t',i)\n    else:\n        print ('Column Removed')\n#missing values in max_impute Columns - 307 rows each - Impute the values - Use mode w.r.t. target\n#max_impute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_impute=list(ldf[ldf.Min_Value==-999999.00].Features)\nfor i in min_impute:\n    if i in train_df.columns:\n        print (train_df[train_df[i]==-999999.00].shape,'\\t',i)\n    else:\n        print ('Column Removed')\n#missing values in min_values Columns - 116 rows - Impute the values - Use mode w.r.t. target\n#min_impute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing missing values\ntrain_df.replace({9999999999:np.NaN,-999999:np.NaN, 10000000000:np.NaN},inplace=True)\ntrain_df['var36'].replace({99:np.NaN},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"miss=pd.DataFrame(train_df.isnull().sum(),columns=['miss']).reset_index()\nmiss_features=list(miss[miss.miss!=0]['index'])\n#All the features with missing values and frequency of it.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.concat([train_df.groupby('TARGET').transform(lambda x: x.fillna(x.value_counts().idxmax())),target],axis=1,sort=False)\n#Replacing missing_values wth mode/most_frequent values w.r.t. TARGET","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_features=list(ldf[ldf.No_Unique_Values==1].Features)\nldf[ldf.No_Unique_Values==1].shape\n#Remove these Columns : No Unique Value/Columns with same values throughout - 34 Columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_ID=list(train_df[train_df.duplicated()==True].index)\ntrain_df[train_df.duplicated()==True].shape\n#Duplicated Records - To be removed - 4961 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=list(train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fea_del_set=set()\nfor i in range(len(columns)):\n    for j in range(i+1,len(columns)):\n        if train_df[columns[i]].equals(train_df[columns[j]]) and columns[j] not in fea_del_set:\n            fea_del_set.add(columns[j])\n#creating a set of all duplicate columns.     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Alternate for above cell.\n\"\"\"fea_del={}\nfor i in range(len(columns)):\n    l=[]\n    for j in range(i+1,len(columns)):\n        if train_df[columns[i]].equals(train_df[columns[j]]):\n            l.append(columns[j])\n    if l!=[]:\n        fea_del[columns[i]]=l\n##Check accuracy\nset1=set()\nfor i in list(fea_del.values()):\n    for j in i:\n        set1.add(j)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_col=fea_del_set.union(del_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=pd.DataFrame(abs(train_df[list(ldf.Features)].corr())['TARGET']).sort_values(by=['TARGET'],ascending=False)\n#dataframe containing correlation between columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#HeatMap of correlation between Feature & Target with less than 300 columns to eliminate extra features\n#I chose a correlation of 0.015 as the threshold value\n#===HEATMAP===\nplt.figure(figsize = (200 ,200))\ncorrmat = train_df[list(ldf[ldf['Non-Zero']<300].Features) + ['TARGET']].corr()\ntop_corr_features = corrmat.index\nsns.heatmap(corrmat[top_corr_features].corr(), annot = True, cmap = 'RdYlGn')\n\ncrr_df=pd.DataFrame(abs(train_df[list(ldf[ldf['Non-Zero']<300].Features) + ['TARGET']].corr()['TARGET']))\ncrr_015=tuple(crr_df[crr_df.TARGET>0.015].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing Features with less than 10% of non-zer values and with less than 0.015 correlation.\nrem_features=set(train_df[list(ldf[ldf['Non-Zero']<300].Features)])\nfor i in crr_015:\n    rem_features.discard(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array([i in corr['TARGET'][:100] for i in rem_features]).any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_col.update(rem_features)\ndel_col.update(('imp_trasp_var33_out_ult1','imp_reemb_var33_ult1'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#del_col - All the columns to be deleted - 204 columns\n\n\"\"\"\n{'delta_imp_amort_var18_1y3',\n 'delta_imp_amort_var34_1y3',\n 'delta_imp_aport_var17_1y3',\n 'delta_imp_aport_var33_1y3',\n 'delta_imp_compra_var44_1y3',\n 'delta_imp_reemb_var13_1y3',\n 'delta_imp_reemb_var17_1y3',\n 'delta_imp_reemb_var33_1y3',\n 'delta_imp_trasp_var17_in_1y3',\n 'delta_imp_trasp_var17_out_1y3',\n 'delta_imp_trasp_var33_in_1y3',\n 'delta_imp_trasp_var33_out_1y3',\n 'delta_imp_venta_var44_1y3',\n 'delta_num_aport_var17_1y3',\n 'delta_num_aport_var33_1y3',\n 'delta_num_compra_var44_1y3',\n 'delta_num_reemb_var13_1y3',\n 'delta_num_reemb_var17_1y3',\n 'delta_num_reemb_var33_1y3',\n 'delta_num_trasp_var17_in_1y3',\n 'delta_num_trasp_var17_out_1y3',\n 'delta_num_trasp_var33_in_1y3',\n 'delta_num_trasp_var33_out_1y3',\n 'delta_num_venta_var44_1y3',\n 'imp_amort_var18_hace3',\n 'imp_amort_var18_ult1',\n 'imp_amort_var34_hace3',\n 'imp_amort_var34_ult1',\n 'imp_aport_var17_hace3',\n 'imp_aport_var17_ult1',\n 'imp_aport_var33_hace3',\n 'imp_aport_var33_ult1',\n 'imp_compra_var44_hace3',\n 'imp_compra_var44_ult1',\n 'imp_op_var40_comer_ult1',\n 'imp_op_var40_ult1',\n 'imp_reemb_var13_hace3',\n 'imp_reemb_var13_ult1',\n 'imp_reemb_var17_hace3',\n 'imp_reemb_var17_ult1',\n 'imp_reemb_var33_hace3',\n 'imp_reemb_var33_ult1',\n 'imp_sal_var16_ult1',\n 'imp_trasp_var17_in_hace3',\n 'imp_trasp_var17_in_ult1',\n 'imp_trasp_var17_out_hace3',\n 'imp_trasp_var17_out_ult1',\n 'imp_trasp_var33_in_hace3',\n 'imp_trasp_var33_in_ult1',\n 'imp_trasp_var33_out_hace3',\n 'imp_trasp_var33_out_ult1',\n 'imp_var7_emit_ult1',\n 'imp_var7_recib_ult1',\n 'imp_venta_var44_hace3',\n 'imp_venta_var44_ult1',\n 'ind_var1',\n 'ind_var13_medio',\n 'ind_var13_medio_0',\n 'ind_var17',\n 'ind_var17_0',\n 'ind_var18',\n 'ind_var18_0',\n 'ind_var2',\n 'ind_var20',\n 'ind_var20_0',\n 'ind_var25',\n 'ind_var26',\n 'ind_var27',\n 'ind_var27_0',\n 'ind_var28',\n 'ind_var28_0',\n 'ind_var29',\n 'ind_var29_0',\n 'ind_var2_0',\n 'ind_var31',\n 'ind_var32',\n 'ind_var32_0',\n 'ind_var32_cte',\n 'ind_var33',\n 'ind_var33_0',\n 'ind_var34',\n 'ind_var34_0',\n 'ind_var37',\n 'ind_var39',\n 'ind_var40',\n 'ind_var41',\n 'ind_var44',\n 'ind_var44_0',\n 'ind_var46',\n 'ind_var46_0',\n 'ind_var6',\n 'ind_var6_0',\n 'ind_var7_emit_ult1',\n 'ind_var7_recib_ult1',\n 'num_aport_var17_hace3',\n 'num_aport_var17_ult1',\n 'num_aport_var33_hace3',\n 'num_aport_var33_ult1',\n 'num_compra_var44_hace3',\n 'num_compra_var44_ult1',\n 'num_meses_var13_medio_ult3',\n 'num_meses_var17_ult3',\n 'num_meses_var29_ult3',\n 'num_meses_var33_ult3',\n 'num_meses_var44_ult3',\n 'num_op_var40_comer_ult1',\n 'num_op_var40_hace2',\n 'num_op_var40_hace3',\n 'num_op_var40_ult1',\n 'num_op_var40_ult3',\n 'num_reemb_var13_hace3',\n 'num_reemb_var13_ult1',\n 'num_reemb_var17_hace3',\n 'num_reemb_var17_ult1',\n 'num_reemb_var33_hace3',\n 'num_reemb_var33_ult1',\n 'num_sal_var16_ult1',\n 'num_trasp_var17_in_hace3',\n 'num_trasp_var17_in_ult1',\n 'num_trasp_var17_out_hace3',\n 'num_trasp_var17_out_ult1',\n 'num_trasp_var33_in_hace3',\n 'num_trasp_var33_in_ult1',\n 'num_trasp_var33_out_hace3',\n 'num_trasp_var33_out_ult1',\n 'num_var1',\n 'num_var13_medio',\n 'num_var13_medio_0',\n 'num_var17',\n 'num_var17_0',\n 'num_var18',\n 'num_var18_0',\n 'num_var20',\n 'num_var20_0',\n 'num_var25',\n 'num_var26',\n 'num_var27',\n 'num_var27_0',\n 'num_var28',\n 'num_var28_0',\n 'num_var29',\n 'num_var29_0',\n 'num_var2_0_ult1',\n 'num_var2_ult1',\n 'num_var31',\n 'num_var32',\n 'num_var32_0',\n 'num_var33',\n 'num_var33_0',\n 'num_var34',\n 'num_var34_0',\n 'num_var37',\n 'num_var39',\n 'num_var40',\n 'num_var41',\n 'num_var44',\n 'num_var44_0',\n 'num_var46',\n 'num_var46_0',\n 'num_var6',\n 'num_var6_0',\n 'num_var7_emit_ult1',\n 'num_var7_recib_ult1',\n 'num_venta_var44_hace3',\n 'num_venta_var44_ult1',\n 'saldo_medio_var13_largo_hace3',\n 'saldo_medio_var13_medio_hace2',\n 'saldo_medio_var13_medio_hace3',\n 'saldo_medio_var13_medio_ult1',\n 'saldo_medio_var13_medio_ult3',\n 'saldo_medio_var17_hace2',\n 'saldo_medio_var17_hace3',\n 'saldo_medio_var17_ult1',\n 'saldo_medio_var17_ult3',\n 'saldo_medio_var29_hace2',\n 'saldo_medio_var29_hace3',\n 'saldo_medio_var29_ult1',\n 'saldo_medio_var29_ult3',\n 'saldo_medio_var33_hace2',\n 'saldo_medio_var33_hace3',\n 'saldo_medio_var33_ult1',\n 'saldo_medio_var33_ult3',\n 'saldo_medio_var44_hace2',\n 'saldo_medio_var44_hace3',\n 'saldo_medio_var44_ult1',\n 'saldo_medio_var44_ult3',\n 'saldo_var1',\n 'saldo_var13_medio',\n 'saldo_var17',\n 'saldo_var18',\n 'saldo_var20',\n 'saldo_var27',\n 'saldo_var28',\n 'saldo_var29',\n 'saldo_var2_ult1',\n 'saldo_var31',\n 'saldo_var32',\n 'saldo_var33',\n 'saldo_var34',\n 'saldo_var40',\n 'saldo_var41',\n 'saldo_var44',\n 'saldo_var46',\n 'saldo_var6'}\n\"\"\"\n\nlen(del_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(del_col, axis=1,inplace=True)\n#deleting columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop_duplicates(keep='first',inplace=True)\n#deleting duplicates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing 204 features and 4961 records, we are left with the 71059 rows and 166 features including the target columns. Features were removed on the basis of duplication, number of zeroes & no. of unique values. Removed all the duplicate records."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf=ldf_f(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_u2=list(ldf[ldf.No_Unique_Values==2].Features)\nf_u3=list(ldf[ldf.No_Unique_Values==3].Features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique_percent(df,column):\n    unique=list(df[column].unique())\n    total=df[column].count()\n    count=[]\n    percent=[]\n    for i in unique:\n        count.append((i,(df[column]==i).sum()))\n        percent.append((i,(df[column]==i).sum()/total*100))\n    return count,percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=[]\npercent=[]\nfor i in f_u2:\n    c,p=unique_percent(train_df[train_df.TARGET==1],i)\n    count.append((i,c))\n    percent.append((i,p))\ncount","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=[]\npercent=[]\nfor i in f_u3:\n    c,p=unique_percent(train_df[train_df.TARGET==1],i)\n    count.append((i,c))\n    percent.append((i,p))\ncount","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FIND CORELATION WITH ALL EQUAL ELEMENTS AT TARGET 1; KEEP THE HIGHEST - CHECK BELOW"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df[(train_df.num_var13_corto==train_df.num_var24)].count()/train_df.count()\ntrain_df[(train_df.num_var1_0==train_df.num_var40_0) & (train_df.TARGET==1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr2=pd.DataFrame(abs(train_df[list(ldf.Features)].corr())['TARGET']).sort_values(by=['TARGET'],ascending=False).drop(['TARGET'])\n#Correlation of Target with every feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr2['TARGET'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr2['TARGET'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (50,50))\nplt.xticks(rotation=90)\nplt.axhline(0.04,label='Threshold',color='r')\nplt.axhline(corr2['TARGET'].mean(),label='Mean',color='g')\nsns.lineplot(y=corr2['TARGET'],x=corr2.index, label='Correlation with Target',)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"above_threshold=list(corr2[corr2['TARGET']>0.04].index)\nfor i in above_threshold:\n    print (ldf[ldf.Features==i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_thresh=train_df[above_threshold+['TARGET']].corr()\nmask = np.zeros_like(corr_thresh, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr_thresh, mask=mask, cmap=\"RdYlGn\",annot=True, square=True, linewidths=.5, center=0, vmax=1);\nfig=plt.gcf()\nfig.set_size_inches(50,50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting a correlation of every features with Target in linegraph. And later we plotted a heatmap of all the features that crossed the threshhold.\n* Mean value of the corelation was found to be 0.02450716296013532.\n* The Threshold we kept was 0.04.\n* Of all the 165 columns, only 14 columns was found to be above threshold.\n* The were - ['var36', 'ind_var30', num_meses_var5_ult3', 'num_var30','num_var42','ind_var5','num_var5','var15', 'num_var4','num_var35','ind_var8_0','num_var8_0','ind_var13','ind_var13_0'].\n* var had the highest correlation of 0.25 followed by ind_var30 and num_messes_var5_ult3 of 0.15 and 0.147.\n* Heatmap indicated alot of high correlations within the features.\n* Highest among them is between now num_var8_0 and ind_var8_0 with a correlation of 1 having 2479 columns with Target=1 same."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df.num_var8_0!=train_df.ind_var8_0].shape[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"fea_corr=[]\nfor i in corr_thresh:\n    fea_corr.append((i,corr_thresh.loc[[corr_thresh[i]>0.9],i]))\nfea_corr\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (50,50))\nplt.xticks(rotation=90)\n\nsns.lineplot(y=ldf['Max_Value'],x=ldf.Features, label='Maximum Value',color='g')\nsns.lineplot(y=ldf['Min_Value'],x=ldf.Features, label='Minimum Value',color='r')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (50,50))\nplt.xticks(rotation=90)\n\nsns.lineplot(y=ldf['No_Unique_Values'],x=ldf.Features, label='Unique_Values',color='g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"div=set()\nfor i in train_df.columns:\n    div.add((i[:3]))\ndiv.remove('TAR')\ndelta=[];imp=[];ind=[];saldo=[];var=[]\nfor i in train_df.columns:\n    if i[:3]=='del':\n        delta.append(i)\n    elif i[:3]=='imp':\n        imp.append(i)\n    elif i[:3]=='ind':\n        ind.append(i)\n    elif i[:3]=='sal':\n        saldo.append(i)\n    elif i[:3]=='var':\n        var.append(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### var15/AGE"},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf[ldf.Features=='var15']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"plt.figure(figsize = (50,50))\nplt.xticks(rotation=90)\n\nsns.distplot(train_df['var15'])\"\"\"\n\nfig, ax = plt.subplots()\nsns.distplot((train_df[train_df.TARGET==1]['var15']),hist=False,kde_kws={'label':'Unhappy Customers',\"linewidth\": 3},color='r')\n\nsns.distplot((train_df[train_df.TARGET==0]['var15']),hist=False,kde_kws={'label':'Happy Customers',\"linewidth\": 3,\"color\":'g'},norm_hist=True,ax=ax,label ='Happy Customers')\n\nsns.distplot((train_df['var15']),hist=False,kde_kws={'label':'All Customers',\"linewidth\": 3, 'color':'b'},ax=ax,label ='All Customers')\n\n#hist_kws={\"histtype\": \"bar\", \"linewidth\": 3}\n\nfig=plt.gcf()\nfig.set_size_inches(20,20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"plt.figure(figsize = (15,15))\nplt.xticks(rotation=90)\n\"\"\"\nfig,ax=plt.subplots()\nsns.distplot(train_df[train_df.TARGET==0]['var15'],bins=np.arange(0,120,10))\n\nx = ax.lines[0].get_xdata() # Get the x data of the distribution\ny = ax.lines[0].get_ydata()\n\nplt.axvline(x[np.argmax(y)],label='Threshold',color='r')\n\nfig.set_size_inches(20,20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[np.argmax(y)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,15))\nplt.xticks(rotation=90)\n\nsns.countplot(train_df[train_df.TARGET==1]['var15'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(train_df[train_df.TARGET==1]['var15'].values,return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[(train_df.TARGET==1) & (train_df.var15>22) & (train_df.var15<50)]['var15'].sum()/((train_df[train_df.TARGET==1]['var15']).sum())*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[(train_df.TARGET==1) & (train_df.var15>25) & (train_df.var15<45)]['var15'].sum()/((train_df[train_df.TARGET==1]['var15']).sum())*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[(train_df.TARGET==0) & (train_df.var15>0) & (train_df.var15<36)]['var15'].sum()/((train_df[train_df.TARGET==0]['var15']).sum())*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[(train_df.TARGET==1) & (train_df.var15>22) & (train_df.var15<50)]['var15'].sum()/train_df[(train_df.var15>22) & (train_df.var15<50)]['var15'].sum()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations\n* var15 seems to be age since its values ranged between 22 to 105 with 100 unique values, a range that seems similar to that age, as mentioned above\n* minimum age of the unhappy customer is 23 and maximum goes upto 102\n* Age of 23 has the highest count of 128\n* On plotting the kdeplot of ages, we found majority unhappy customers are under the age of 50, i.e., 71.1%.\n* The percentage goes down to 52.486% of all the unhappy customers are between the age of 25 and 45 where as almost same percentage of happy customers (52.152%) lies below the age of 36 which can be clearly scene in the kdeplot"},{"metadata":{},"cell_type":"markdown","source":"> ### num_var4/No of Products"},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf[ldf.Features=='num_var4']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_list=[[i,train_df[(train_df.num_var4==i)]['num_var4'].count(),train_df[(train_df.TARGET==1) & (train_df.num_var4==i)]['num_var4'].count(), round((train_df[(train_df.TARGET==1) & (train_df.num_var4==i)]['num_var4'].count()/train_df[(train_df.num_var4==i)]['num_var4'].count())*100,2),round((train_df[(train_df.TARGET==1) & (train_df.num_var4==i)]['num_var4'].count()/train_df[(train_df.TARGET==1)]['num_var4'].count())*100,2)] for i in (train_df.num_var4.unique())]\nprod_df=pd.DataFrame(prod_list,columns=['prod_no','Total_Customer','Unhappy_Customer','Unhappy_Percent_All_Prod','Percent_Prod_Unhappy']).set_index('prod_no')\nprod_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.barplot(x=prod_df.index,y=prod_df.Total_Customer,ax=ax)\nfig.set_size_inches(10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.barplot(x=prod_df.index,y=prod_df.Unhappy_Customer,ax=ax)\nfig.set_size_inches(10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.barplot(x=prod_df.index,y=prod_df.Unhappy_Percent_All_Prod,ax=ax)\nfig.set_size_inches(10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.barplot(x=prod_df.index,y=prod_df.Percent_Prod_Unhappy,ax=ax)\nfig.set_size_inches(10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==0)]['var15'],ax=ax, label=\"Unhappy Customers-0\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==0)]['var15'],ax=ax,label=\"Happy Customers-0\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==1)]['var15'],ax=ax, label=\"Unhappy Customers-1\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==1)]['var15'],ax=ax,label=\"Happy Customers-1\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==2)]['var15'],ax=ax, label=\"Unhappy Customers-2\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==2)]['var15'],ax=ax,label=\"Happy Customers-2\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==3)]['var15'],ax=ax, label=\"Unhappy Customers-3\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==3)]['var15'],ax=ax,label=\"Happy Customers-3\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==4)]['var15'],ax=ax, label=\"Unhappy Customers-4\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==4)]['var15'],ax=ax,label=\"Happy Customers-4\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==5)]['var15'],ax=ax, label=\"Unhappy Customers-5\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==5)]['var15'],ax=ax,label=\"Happy Customers-5\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==6)]['var15'],ax=ax, label=\"Unhappy Customers-6\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==6)]['var15'],ax=ax,label=\"Happy Customers-6\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==7)]['var15'],ax=ax, label=\"Unhappy Customers-7\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==7)]['var15'],ax=ax,label=\"Happy Customers-7\")\nfig.set_size_inches(10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==0)]['var15'],ax=ax, label=\"Unhappy Customers-0\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==1)]['var15'],ax=ax, label=\"Unhappy Customers-1\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==2)]['var15'],ax=ax, label=\"Unhappy Customers-2\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==3)]['var15'],ax=ax, label=\"Unhappy Customers-3\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==4)]['var15'],ax=ax, label=\"Unhappy Customers-4\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==5)]['var15'],ax=ax, label=\"Unhappy Customers-5\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==6)]['var15'],ax=ax, label=\"Unhappy Customers-6\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==7)]['var15'],ax=ax, label=\"Unhappy Customers-7\")\nfig.set_size_inches(10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==0)]['var15'],ax=ax, label=\"Happy Customers-0\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==1)]['var15'],ax=ax, label=\"Happy Customers-1\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==2)]['var15'],ax=ax, label=\"Happy Customers-2\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==3)]['var15'],ax=ax, label=\"Happy Customers-3\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==4)]['var15'],ax=ax, label=\"Happy Customers-4\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==5)]['var15'],ax=ax, label=\"Happy Customers-5\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==6)]['var15'],ax=ax, label=\"Happy Customers-6\")\n\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==7)]['var15'],ax=ax, label=\"Happy Customers-7\")\nfig.set_size_inches(10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==0)]['var15'],ax=ax, label=\"Unhappy Customers-0\")\nsns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==0)]['var15'],ax=ax,label=\"Happy Customers-0\")\nfig.set_size_inches(10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,8,sharey='row')\nfor i in range(8):\n    sns.kdeplot(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==i)]['var15'],ax=ax[i], label=\"Unhappy Customers-%d\"%(i))    \n    \n    if i<6:\n        x = ax[i].lines[0].get_xdata()\n        y = ax[i].lines[0].get_ydata()\n        ax[i].axvline(x[np.argmax(y)],label=\"Unhappy Customer Age Probability: %d\"%(x[np.argmax(y)]),color='r')\n        ax[i].axvline(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==i)]['var15'].mean(),color='g',label=\"Unhappy Customer Age Mean: %d\"%(train_df[(train_df['TARGET']==1) & (train_df['num_var4']==i)]['var15'].mean()))\n        \n    sns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==i)]['var15'],ax=ax[i],label=\"Happy Customers-%d\"%(i))\n\n    ax[i].xaxis.set_ticks(np.arange(0, 120+1,10))\n\nfig.set_size_inches(50,8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,8,sharey='row')\nfor i in range(8):\n    sns.kdeplot(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==i)]['var15'],ax=ax[i], label=\"Happy Customers-%d\"%(i))    \n    x = ax[i].lines[0].get_xdata()\n    y = ax[i].lines[0].get_ydata()\n    ax[i].axvline(x[np.argmax(y)],color='r',label=\"Happy Customer Age Probability: %d\"%(x[np.argmax(y)]))\n    ax[i].axvline(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==i)]['var15'].mean(),color='g',label=\"Happy Customer Age Mean: %d\"%(train_df[(train_df['TARGET']==0) & (train_df['num_var4']==i)]['var15'].mean()))\n    \n    ax[i].legend()\n    ax[i].xaxis.set_ticks(np.arange(0, 120+1,10))\nfig.set_size_inches(50,8)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,8):\n    print ('Product No. %d - Percentage Over Age 40 : %f'%(i, train_df[(train_df['num_var4']==i) & (train_df['var15']>40)]['var15'].count()/train_df[(train_df['num_var4']==i)]['var15'].count()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,8):\n    print ('Product No. %d - Percentage Under Age 30 : %f'%(i, train_df[(train_df['num_var4']==i) & (train_df['var15']<30)]['var15'].count()/train_df[(train_df['num_var4']==i)]['var15'].count()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,8):\n    print ('Product No. %d - Percentage between Age 30 and 40 : %f'%(i, train_df[(train_df['num_var4']==i) & (train_df['var15']>30) & (train_df['var15']<40)]['var15'].count()/train_df[(train_df['num_var4']==i)]['var15'].count()*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations: **\n* num_var4 is speculated to represent a type of product numbered 0 to 7\n* Product 1 has the highest user base(35,922 customers) but comparetively lowest unhappy customers(1.93%) having more than 40 customers, therefore, is the best/most effective product for Santander Bank\n* Product 6  and 7 seems to be newest/latest products among other having the least customers (36 and 6 customers respectively) and hence doesn't have any unhappy customers till now.\n* Product 0 have 1544 unhappy customers making it 54.85% of all unhappy customers(9.19% of all the customers) though it has the second highest customer base of 16792. 54.85\n* On plotting kde of var15 w.r.t num_var4, peak of all the unhappy customers lies around the age of 40 (37 to 42) for all the products except product 1 which lies just below 30 (at 28).\n* This observation lies in line with our previous observation that majority of unhappy customers lies in the age group of 25 to 45\n* The age of happy customers of Product 0,1 & 2 is around 23 & 24 which also happens to have the maximum number of customers. While Product 3,4 & 5 have maximum customers of age 35$\\pm$2 which also happens to be inline with previous observation marking majority of happy customers being under the age of 36\n* The kde curve for happy customers for product 6 and 7 shows their mode and mean, both above the age of 40.\n* It seems Product 5, 6 & 7 happens to target the the people above age of 40 having 54.67%, 61.11% & 66.67% of their users above the age of 40, most probably happens to be the retirement plan or something similar.\n* The Product 0 and 1 has 58.64% and 65.70% of their customer below the age of 30, therefore, the customer base seems to be students mostly.\n* The product 3 & 4 have 41.01% & 42.58% of their customers between the age of 30 & 40, therefore it must be for working class people.\n* The product 2 seems to have customer base distributed in all the 3 groups therefore, it must be a general product  and not designed to target a particular age group."},{"metadata":{},"cell_type":"markdown","source":"> ### var36"},{"metadata":{"trusted":true},"cell_type":"code","source":"above_threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf[ldf.Features=='var36']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(train_df[train_df.TARGET==1]['var36'],return_counts=True)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var36_cat=[[i,train_df[(train_df.var36==i)]['var36'].count(),train_df[(train_df.TARGET==1) & (train_df.var36==i)]['var36'].count(), round((train_df[(train_df.TARGET==1) & (train_df.var36==i)]['var36'].count()/train_df[(train_df.var36==i)]['var36'].count())*100,2),round((train_df[(train_df.TARGET==1) & (train_df.var36==i)]['var36'].count()/train_df[(train_df.TARGET==1)]['var36'].count())*100,2)] for i in (train_df.var36.unique())]\nvar36_df=pd.DataFrame(var36_cat,columns=['Cat','Total_Customer','Unhappy_Customer','Unhappy_Percent_All','Percent_Unhappy']).set_index('Cat')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (50,50))\nplt.xticks(rotation=90)\n\nsns.countplot(train_df['var36'],hue=train_df['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var36_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.kdeplot(train_df[train_df.TARGET==1]['var36'],bw=0.05,ax=ax,shade=True,label='Unhappy Customers')\nsns.kdeplot(train_df[train_df.TARGET==0]['var36'],bw=0.05,ax=ax,label='Happy Customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.violinplot(x='var36',y='var15',hue='TARGET',data=train_df,ax=ax)\nfig.set_size_inches(15,15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.violinplot(train_df['var36'],train_df['num_var4'])\nfig.set_size_inches(15,15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.violinplot(train_df['var36'],train_df['num_var4'],hue=train_df.TARGET)\nfig.set_size_inches(15,15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def var36_Count(train_df,var2,val,var,tar):\n    l=[]\n    for i in (np.unique(train_df[var])):\n        l.append(train_df[train_df[var2]==val][train_df.TARGET==tar][train_df[var]==i].shape[0])\n    return l\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\ncol0=var36_Count(train_df,'num_var4',0,'var36',1)\ncol1=var36_Count(train_df,'num_var4',1,'var36',1)\ncol2=var36_Count(train_df,'num_var4',2,'var36',1)\ncol3=var36_Count(train_df,'num_var4',3,'var36',1)\ncol4=var36_Count(train_df,'num_var4',4,'var36',1)\ncol5=var36_Count(train_df,'num_var4',5,'var36',1)\ncol6=var36_Count(train_df,'num_var4',6,'var36',1)\ncol7=var36_Count(train_df,'num_var4',7,'var36',1)\n\nindx=np.arange(4)\nindy=np.arange(0,2501,100)\n\np0=plt.bar(indx,col0)\np1=plt.bar(indx,col1,bottom=col0)\np2=plt.bar(indx,col2,bottom=[col0[j] + col1[j] for j in range(len(col0))])\np3=plt.bar(indx,col3,bottom=[col0[j] + col1[j] + col2[j] for j in range(len(col0))])\np4=plt.bar(indx,col4,bottom=[col0[j] + col1[j] + col2[j] + col3[j] for j in range(len(col0))])\np5=plt.bar(indx,col5,bottom=[col0[j] + col1[j] + col2[j] + col3[j] + col4[j] for j in range(len(col0))])\np6=plt.bar(indx,col6,bottom=[col0[j] + col1[j] + col2[j] + col3[j] + col4[j] + col5[j] for j in range(len(col0))])\np7=plt.bar(indx,col7,bottom=[col0[j] + col1[j] + col2[j] + col3[j] + col4[j] + col5[j] + col6[j] for j in range(len(col0))])\n\nplt.xticks(indx, ('0', '1', '2', '3'))\nplt.yticks(indy)\n\n\nplt.legend((p0[0], p1[0], p2[0],p3[0], p4[0], p5[0], p6[0], p7[0]), ('P0', 'P1','P2','P3','P4','P5','P6','P7'))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\ncol0=var36_Count(train_df,'num_var4',0,'var36',0)\ncol1=var36_Count(train_df,'num_var4',1,'var36',0)\ncol2=var36_Count(train_df,'num_var4',2,'var36',0)\ncol3=var36_Count(train_df,'num_var4',3,'var36',0)\ncol4=var36_Count(train_df,'num_var4',4,'var36',0)\ncol5=var36_Count(train_df,'num_var4',5,'var36',0)\ncol6=var36_Count(train_df,'num_var4',6,'var36',0)\ncol7=var36_Count(train_df,'num_var4',7,'var36',0)\n\nindx=np.arange(4)\nindy=np.arange(0,50001,2000)\n\np0=plt.bar(indx,col0)\np1=plt.bar(indx,col1,bottom=col0)\np2=plt.bar(indx,col2,bottom=[col0[j] + col1[j] for j in range(len(col0))])\np3=plt.bar(indx,col3,bottom=[col0[j] + col1[j] + col2[j] for j in range(len(col0))])\np4=plt.bar(indx,col4,bottom=[col0[j] + col1[j] + col2[j] + col3[j] for j in range(len(col0))])\np5=plt.bar(indx,col5,bottom=[col0[j] + col1[j] + col2[j] + col3[j] + col4[j] for j in range(len(col0))])\np6=plt.bar(indx,col6,bottom=[col0[j] + col1[j] + col2[j] + col3[j] + col4[j] + col5[j] for j in range(len(col0))])\np7=plt.bar(indx,col7,bottom=[col0[j] + col1[j] + col2[j] + col3[j] + col4[j] + col5[j] + col6[j] for j in range(len(col0))])\n\nplt.xticks(indx, ('0', '1', '2', '3'))\nplt.yticks(indy)\n\n\nplt.legend((p0[0], p1[0], p2[0],p3[0], p4[0], p5[0], p6[0], p7[0]), ('P0', 'P1','P2','P3','P4','P5','P6','P7'))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Observations **\n* var36 is acategorical feature, which initially had 5 values - 0,1,2,3,99. Since 99 seems to be an odd considering the other values(0,1,2,3), I assumed this to be a filler for NaN values, and therefore replaced them with the mode w.r.t the target value.\n* Highest Number of people are in Cat 3 of var36 yet they have the lowest unhappy people (0.81%) in the category with more than 1000 categories.\n* Cat 0 has the lowest number of customers, just 357 which accounts for just 0.005% of all customers and have no unhappy customers\n* On plotting kde. we can see that probability of finding unhappy people is more in Cat 1 while that of happy people is in Cat 3.\n* On plotting violin plot of var36 against var15, we found Cat 3 customers are mostly around the age of 20-25 while for other categoris, it spread almost evenly over the age of 30-50 for Cat 2 and Cat 3.\n* On plotting var36 with num_var4 we see Product 1 is most common among all var36 categories. On splitting based on target value, we find most of the unhappy customers of Cat 1 are using Product 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf[ldf.Features=='var21']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df.var21==900][train_df.TARGET==1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (50,10))\nplt.xticks(rotation=90)\n\nsns.countplot(train_df['var21'],hue=train_df['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (50,10))\nplt.xticks(rotation=90)\n\nsns.countplot(train_df[train_df.var21!=0]['var21'],hue=train_df['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* var21 seems to be a multiple of 300\n* Most of the values of var21 is 0, only 868 values are not 0, i.e. 1.22%\n* Apart from zero, only 900 and 1800 have the hoghest counts which max out at 238 and 206 of which 5.08 amd 6.31% are unhappy."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf[ldf.Features=='var15']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf[ldf.Features=='var38']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (50,50))\nplt.xticks(rotation=90)\nplt.axhline(train_df['var38'][train_df.TARGET==0].mean(),label='Happy Mean - %f'%train_df['var38'][train_df.TARGET==0].mean())\nplt.axhline(train_df['var38'][train_df.TARGET==1].mean(),color='#FF7F00',label='Unhappy Mean - %f'%train_df['var38'][train_df.TARGET==1].mean())\nplt.axhline(train_df['var38'].mean(),color='r',label='Overall Mean - %f'%train_df['var38'].mean())\n\n\nsns.lineplot(y=train_df['var38'],x=train_df['var15'],hue=train_df['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nplt.xticks(rotation=90)\n#plt.axhline()\n\nsns.barplot(y=train_df['var38'],x=train_df['num_var4'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nplt.xticks(rotation=90)\n#plt.axhline()\n\nsns.barplot(y=train_df['var38'],x=train_df['var36'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.axhline(train_df[train_df['TARGET']==0]['var38'].mean(),label='Mean - Happy %s'%train_df[train_df['TARGET']==0]['var38'].mean(),color='b')\n#plt.axhline(train_df[train_df['TARGET']==1]['var38'].mean(),label='Mean - Unhappy %s'%train_df[train_df['TARGET']==1]['var38'].mean(),color='#FF7F00')\n#plt.axhline(train_df['var38'].mean(),label='Mean - Unhappy %s'%train_df['var38'].mean(),color='r')\nfig, ax = plt.subplots()\nsns.distplot(np.log(train_df[train_df.TARGET==1]['var38']),hist_kws={\"histtype\": \"step\", \"linewidth\": 3},kde_kws={'label':'Unhappy Customers',\"linewidth\": 3},color='r')\n#sns.distplot(np.log(train_df[train_df.TARGET==0]['var38']),norm_hist=True,ax=ax,label ='Happy Customers')\nsns.distplot(np.log(train_df['var38']),hist_kws={\"histtype\": \"step\", \"linewidth\": 3},kde_kws={'label':'All Customers',\"linewidth\": 3},ax=ax,label ='All Customers')\nfig=plt.gcf()\nfig.set_size_inches(20,20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* var38 seems to be related to amount either as a bank balance or a debt/credit balance.\n* The Mean of unhappy people (117896.23) is lower than that of happy people (98469.38) and also overall mean.\n* Highest 102 has the highest value of var38.\n* barplot for var38 against num_var4 shows the product is invariant of the amount mentioned in var38, amount seems similar for all product values\n* barplot for var38 against var36 shows the product is invariant of the amount mentioned in var38, amount seems similar for all categories"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}