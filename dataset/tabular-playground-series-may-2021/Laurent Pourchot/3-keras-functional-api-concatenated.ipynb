{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Model\nimport tensorflow as tf\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom keras.models import Sequential\nimport keras \nfrom keras.layers import Dense, Flatten, Conv1D,MaxPooling1D, Dropout,BatchNormalization,Embedding,Concatenate, Activation,Input\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import model_from_json\nfrom keras import backend as K\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Basic data preparation","metadata":{}},{"cell_type":"markdown","source":"<h3> Preparation for the Onehot encoding model","metadata":{}},{"cell_type":"code","source":"# to prepare data, I use my simple package (to clean data and Onehot encode)\n!pip install git+https://github.com/Lpourchot/dfencoding.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dfencoding import utilities # Import package","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del dfe ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dum = train.copy()\ntest_dum = test.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The package works with Object for categories cleaning and encoding, so I need to change the type :\ntrain_dum = train_dum.iloc[:,1:].astype('str')\ntest_dum = test_dum.iloc[:,1:].astype('str')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfe = utilities.dfencoding(train_dum,'target',test_dum, missing_value = 'Y', cat_limit = 150, dummies_limit = 150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfe.get_dummies() # OneHot encoding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparation of the files for training of the OneHot model :\nX_Onehot = dfe.data.iloc[:len(train_dum),1:]\ntest_Onehot = dfe.data.iloc[len(train_dum):,1:]\nprint(X_Onehot.shape)\nprint(test_Onehot.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> Others preparation for Models Embedding and Conv1D","metadata":{}},{"cell_type":"code","source":"# Preparation of the files without labelencoding for the 2 models (embedding and Conv1D) :\ntarget = pd.get_dummies(train['target'])\ny = train['target']\nX = train.iloc[:,1:-1]\ntest = test.iloc[:,1:]\n\n# To avoid negative values (for embedding), we just add 8 to all categories :\nX = X + 8\ntest = test + 8\nX.shape, test.shape, y.shape, target.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = callbacks.EarlyStopping(\n                monitor = 'val_categorical_crossentropy', \n                min_delta = 0.0000001, \n                patience = 6,\n                mode = 'min',\n                baseline = None, \n                restore_best_weights = True,\n                verbose = 1)\n\nplateau  = callbacks.ReduceLROnPlateau(\n                monitor = 'val_categorical_crossentropy',\n                factor = 0.5, \n                patience = 3, \n                mode = 'min', \n                min_delt = 0.0000001,\n                cooldown = 0, \n                min_lr = 1e-7,\n                verbose = 1) \n\nmetrics = [tf.keras.metrics.CategoricalCrossentropy()]\nloss = tf.keras.losses.CategoricalCrossentropy(\n                from_logits=False,\n                label_smoothing=0,\n                reduction=\"auto\",\n                name=\"categorical_crossentropy\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Kfold for 3 streams API : Embedding + Conv1D + Onehot sequential","metadata":{}},{"cell_type":"code","source":"N_FOLDS = 20\nSEED = 2021\noof = np.zeros((X.shape[0],4))\npred = np.zeros((test.shape[0],4))\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(X, y)):\n    print(f\"===== FOLD {fold} =====\")\n       \n    x_tr = X.iloc[tr_idx] # X_train\n    x_Onehot_tr = X_Onehot.iloc[tr_idx] # X for Onehot encoding\n    y_tr = target.iloc[tr_idx] # y_train\n    x_ts = X.iloc[ts_idx] # X_valid\n    x_Onehot_ts = X_Onehot.iloc[ts_idx] # X_valid for Onehot encoding\n    y_ts = target.iloc[ts_idx] # y_valid\n\n    # API functional for OneHot\n    inputs_API_Onehot = Input(shape=(1285,), name = 'API_input_Onehot')\n    w = Dense(1285, activation=\"relu\")(inputs_API_Onehot)\n    w = Dropout(0.3)(w)\n    w = Dense(80, activation=\"relu\")(w)\n    w = Dropout(0.3)(w)\n    w = Dense(20, activation=\"relu\")(w)\n    outputs_API_Onehot = Dense(4, activation=\"relu\")(w)\n    \n    #API functional for Embedding\n    inputs_API_Embedding = Input(shape=(50,), name = 'API_input_Embedding')\n    x = Embedding(80, 10, input_length=50)(inputs_API_Embedding)\n    x = Flatten()(x)\n    x = Dense(80, activation=\"relu\")(x)\n    x = Dense(20, activation='relu')(x)\n    outputs_API_Embedding = Dense(4, activation='relu')(x)\n    \n    #API functional for Conv1D\n    inputs_API_Conv1D = Input(shape=(50,1), name = 'API_input_Conv1D') \n    v = Conv1D(\n            filters=512, #256\n            kernel_size=5, #4\n            padding='same', \n            activation='relu',\n            )(inputs_API_Conv1D)\n    v = MaxPooling1D(pool_size=3)(v)\n    v = Flatten()(v)\n    v = Dense(80, activation='relu')(v)\n    v = Dense(20, activation='relu')(v)\n    outputs_API_Conv1D = Dense(4, activation='relu')(v)\n    \n    # Final step with concatenation of Embedding and Conv1D :\n    z = Concatenate(axis=1)([outputs_API_Conv1D, outputs_API_Embedding,outputs_API_Onehot])\n    out = Dense(4, activation = 'softmax', name = 'out')(z)\n\n    # Creation of the merged model :\n    model_merged = Model(\n                 inputs=[inputs_API_Conv1D,inputs_API_Embedding,inputs_API_Onehot], \n                 outputs=out, \n                 name=\"model_merged\")\n    \n    # Compile and fit of the merged model :\n    model_merged.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),loss=loss ,metrics=metrics)\n    model_merged.fit(\n                    {'API_input_Conv1D':x_tr, 'API_input_Embedding':x_tr,'API_input_Onehot':x_Onehot_tr},\n                    {'out':y_tr},\n                    validation_data = ([x_ts,x_ts,x_Onehot_ts], y_ts),\n                    batch_size=256,\n                    epochs=50,\n                    verbose=1,\n                    callbacks=[es,plateau])\n    \n    oof[ts_idx] = model_merged.predict([x_ts,x_ts,x_Onehot_ts])\n    score = log_loss(y_ts, oof[ts_idx])\n    print(f\"FOLD {fold} Score {score}\\n\")\n    \n    pred += model_merged.predict([test,test,test_Onehot]) / N_FOLDS\n\nscore = log_loss(y, oof)\nprint(f\"Score total {score}\\n\")   ","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame(pred)\nsubmission_df.columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4']\nsubmission_df['id'] = submission['id']\nsubmission_df = submission_df[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4']]\nsubmission_df.to_csv(\"submission_Keras_3.csv\", index=False)\ndisplay(submission_df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}