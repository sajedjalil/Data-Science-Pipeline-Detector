{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"background-color:turquoise; font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 15px 50px;\">Tabular Playground Series  - May 2021 </p>\n\n","metadata":{}},{"cell_type":"markdown","source":"<a id='table-of-contents'></a>\n## <p style=\"background-color:turquoise; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">Table of Content</p>\n\n* [1. Data visualization ðŸ“Š](#1)\n    * [1.1 Target](#1.1)\n    * [1.2 Numerical Columns](#1.2)\n    * [1.3 Correlation matrix](#1.3)\n    * [1.4 Stats and Skewness](#1.4)\n* [2. Feature Engineering ðŸ› ](#2)\n    * [2.1 Binning](#2.1)\n    * [2.2 log transformation](#2.2)\n* [3. Model building](#3)\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2021/test.csv')\nsample_submission = pd.read_csv('../input/tabular-playground-series-may-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the data size of train and test\nprint(train.shape)\nprint(test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"observations:\n\n- column names doesn't make much sense as all of columns are named by integer with prefix as feature.so from domain stand-point, cannot interpret much information from column names.\n- no missing values in the dataset\n- all the columns are of type integer\n- Dimensionality reduction can be a better idea since all 50 columns of the data is of type integer\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"dropping the id value as it doesn't add any value","metadata":{}},{"cell_type":"code","source":"train.drop('id', axis=1, inplace=True)\ntest.drop('id', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='1.1'></a>\n[back to top](#table-of-contents)\n## <p style=\"background-color:turquoise; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">1.1 Target Distribution</p>\n\n","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(\n    train, \n    x=train['target'], \n    color=train['target'],\n)\nfig.update_layout(\n    title_text='Target distribution', # title of plot\n    xaxis_title_text='Value', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    \n)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" - In the target variable, class2 has more data points compared to the remaining labels.so, we probably have to address class imbalance problem.\n ","metadata":{}},{"cell_type":"markdown","source":"<a id='1.2'></a>\n[back to top](#table-of-contents)\n## <p style=\"background-color:turquoise; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">1.2 Correlation Matrix</p>\n\n","metadata":{}},{"cell_type":"code","source":"rename_labels = {val:idx for idx, val in enumerate(sorted(train['target'].unique()))}\ntrain['target'] = train['target'].map(rename_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12 , 12))\ncorr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\"\"\"\nsns.heatmap(corr,\n        square=True, center=0, linewidth=0.2,\n        cmap=sns.diverging_palette(240, 10, as_cmap=True),\n        mask=mask, ax=ax) \n    \"\"\"\n\nsns.heatmap(corr,square=True, center=0, \n            linewidth=0.2, cmap='coolwarm',\n           mask=mask, ax=ax) \n\nax.set_title('Feature Correlation Matrix ', loc='left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"observations:\n- The correlation between the continuos variables are mostly moderate and few of them are highly correlated.\n- The correlation between this continuos features and the target are not strong.\n- The variables are not high correlated with the class, so we are not going to delete any variable.","metadata":{}},{"cell_type":"markdown","source":"<a id='1.3'></a>\n[back to top](#table-of-contents)\n## <p style=\"background-color:turquoise; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">1.3 Stats and Skewness</p>\n\n","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"observations:\n- The mean of the all the features are closer to zero.\n- There is low variance across all the features.\n- The median is mostly 0 except two columns","metadata":{}},{"cell_type":"markdown","source":"<a id='1.4'></a>\n[back to top](#table-of-contents)\n## <p style=\"background-color:turquoise; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">1.4 Numerical Columns</p>\n\n- From the statistical summary, we know that the data range of Feature 38 and Feature 14 column is considerably larger than the other numeric columns.\n- Feature 38 and Feature 14 has median 1 and all the remaining columns median is zero.","metadata":{}},{"cell_type":"markdown","source":"## Feature14","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 300\nfig = plt.figure(figsize=(5, 2))\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\n\nax0.tick_params(axis = \"y\", which = \"both\", left = False)\n\n# KDE plots\nax0_sns = sns.kdeplot(ax=ax0, x=train['feature_14'], zorder=2, shade=True)\nax0_sns = sns.kdeplot(ax=ax0, x=test['feature_14'], zorder=2, shade=True)\n\n# Axis and grid customization\nax0_sns.set_xlabel(\"feature_14\",fontsize=5, weight='bold')\nax0_sns.set_ylabel('')\nax0.grid(which='major', axis='x', zorder=0, color='#EEEEEE')\nax0.grid(which='major', axis='y', zorder=0, color='#EEEEEE')\n\n# Legend params\nax0.legend(['train', 'test'], prop={'size': 5})\nax0_sns.tick_params(labelsize=5)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature38","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 300\nfig = plt.figure(figsize=(5, 2))\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0, hspace=0)\nax0 = fig.add_subplot(gs[0, 0])\n\nax0.tick_params(axis = \"y\", which = \"both\", left = False)\n\n# KDE plots\nax0_sns = sns.kdeplot(ax=ax0, x=train['feature_38'], zorder=2, shade=True)\nax0_sns = sns.kdeplot(ax=ax0, x=test['feature_38'], zorder=2, shade=True)\n\n# Axis and grid customization\nax0_sns.set_xlabel(\"feature_38\",fontsize=5, weight='bold')\nax0_sns.set_ylabel('')\nax0.grid(which='major', axis='x', zorder=0, color='#EEEEEE')\nax0.grid(which='major', axis='y', zorder=0, color='#EEEEEE')\n\n# Legend params\nax0.legend(['train', 'test'], prop={'size': 5})\nax0_sns.tick_params(labelsize=5)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Both the features are left skewed and considerably larger data range compared to other columns.Handling skewness will be a key for better results","metadata":{}},{"cell_type":"code","source":"skewed_features = train.apply(lambda x: x.skew()).sort_values(ascending=False)\nskewed_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observations:\n- Features are highly skewed.Applying feature transformations can help us build a better model.","metadata":{}},{"cell_type":"markdown","source":"<a id='1.4'></a>\n[back to top](#table-of-contents)\n## <p style=\"background-color:turquoise; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">2 Feature Engineering</p>\n\n","metadata":{}},{"cell_type":"markdown","source":"Binning:\n- When you bin, you can use both the bin and the original feature.Binning also enables you to treat numerical features as categorical.","metadata":{}},{"cell_type":"code","source":"# 10 bins\ntrain[\"f14_bin_10\"] = pd.cut(train[\"feature_14\"], bins=10, labels=False)\ntrain[\"f38_bin_100\"] = pd.cut(train[\"feature_38\"], bins=10, labels=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"log transformation\n- All the features except feature 14 and 38 has low variance.Thus, we would want to reduce the variance of these columns, and that can be done by taking a log transformation.\n","metadata":{}},{"cell_type":"code","source":"#Letâ€™s take a look at the variance without and with the log transformation.\nprint(\"Feature 14 variance : \" , train.feature_14.var())\ntrain['feature_14'] = train.feature_14.apply(lambda x: np.log(1 + x))\nprint(\"Feature 14 variance after apply log(1 + x): \" ,train.feature_14.var())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n[back to top](#table-of-contents)\n## <p style=\"background-color:turquoise; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">3 Model Building</p>\n\n# In Progress...","metadata":{}},{"cell_type":"markdown","source":"\n<a id='7'></a>\n[back to top](#table-of-contents)\n## <p style=\"background-color:orange; font-family:newtimeroman; font-size:140%; text-align:center; border-radius: 15px 50px;\">Stay Tuned and upvote if you like this notebook</p>\n\n# Thanks for reading, will keep posting and updating this notebook with more visualizations, Features with diferent techniques.Â¶\n\n\n","metadata":{}}]}