{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7efb3f1-236e-11dc-7fff-fac416a98891"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\n\n\n\nimport matplotlib.pyplot as plt"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60d1e7a0-a590-3cfa-5f2d-75ff826cb2b0"},"outputs":[],"source":"# Let's load both sets\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\n\n# Let's load the sample submission\nsubmission = pd.read_csv('../input/sample_submission.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"775ec1ce-69ff-7ba7-e0b2-ff4e6f95cf78"},"outputs":[],"source":"# Let's take a look at the first 5 entries of the Kaggle training set\ntrain_data.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dfa478f2-e7bb-ac55-9b60-f6237f56fb3a"},"outputs":[],"source":"print(\"Number of observations: %i\" % len(train_data))\nprint(\"List of columns: %s\" % \", \".join(train_data.columns))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b54ab10b-815e-b142-a59d-0cd92226801c"},"outputs":[],"source":"# Let's take a look at the first 5 entries of the Kaggle testing set\ntest_data.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"270eca12-db48-a377-4ac4-2fc4c3faa8d7"},"outputs":[],"source":"print(\"Number of observations: %i\" % len(test_data))\nprint(\"List of columns: %s\" % \", \".join(test_data.columns))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adaa1d7f-9186-7d47-8fe1-f41e6e30045b"},"outputs":[],"source":"submission.head(5)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"938a9ea6-87c9-5396-1af4-877b6c4352c4"},"outputs":[],"source":"print(\"Number of observations: %i\" % len(submission))\nprint(\"List of columns: %s\" % \", \".join(submission.columns))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0802c525-38ba-8495-a5a8-5d8d45a0c759"},"outputs":[],"source":"train_data.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1febc73f-c48e-6493-81ea-c0544e31737e"},"outputs":[],"source":"from sklearn import preprocessing\n\nlabel_encoders = {}\ncategory_labels = {}\n\ndef transform_x(data_df, phase=\"train\"):\n    \"\"\"Transforms the input dataframe to a dataframe containing\n    the input variables (= features)\"\"\"\n    X = data_df.drop(['id'], axis=1)\n    \n    if 'loss' in X.columns:\n        X = X.drop(['loss'], axis=1)\n    \n    # List of categorical features\n    cat_features = X.select_dtypes(include=['object']).columns\n\n    # List of numerical features\n    num_features = X.select_dtypes(exclude=['object']).columns\n    \n    # Replace each categorical feature with encoded labels\n    for cat in cat_features:\n        if phase == \"train\":\n            # Let's store the used labels\n            category_labels[cat] = list(set(X[cat]))     \n  \n            # We need to fit the Label Encoder in the training phase\n            label_encoders[cat] = preprocessing.LabelEncoder()\n            label_encoders[cat].fit(X[cat])\n        \n        # We replace unseen labels by the first label\n        mask = X[cat].apply(lambda x: x not in category_labels[cat])\n        X.loc[mask, cat] = category_labels[cat][0]\n        \n        X[cat] = label_encoders[cat].transform(X[cat])\n    \n    return X\n\ndef transform_y(data_df):\n    \"\"\"Transforms the input dataframe to a dataframe containing\n    the ground truth data\"\"\"\n    y = data_df['loss']\n    \n    # You can do some crazy stuff here\n    # y = np.log(y)\n    \n    return y\n\ndef inverse_transform_y(data):\n    \"\"\"Inverse transforms the y values to match the original\n    Kaggle testing set\"\"\"\n    y = data\n    \n    # You should invert all the crazy stuff\n    # y = np.exp(y)\n    \n    return y"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27f128d2-3352-4dac-5399-77baaaf1d628"},"outputs":[],"source":"X_train_df = transform_x(train_data)\ny_train_df = transform_y(train_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"983218ba-b596-6b6a-c5fe-0f9a509e0f7b"},"outputs":[],"source":"import xgboost as xgb\n\n# Create our DMatrix to make XGBoost more efficient\nxgdmat_train = xgb.DMatrix(X_train_df.values, y_train_df.values)\n\nparams = {'eta': 0.01, 'seed':0, 'subsample': 0.5, 'colsample_bytree': 0.5, \n             'objective': 'reg:linear', 'max_depth':6, 'min_child_weight':3} \n\nnum_rounds = 100\nmdl = xgb.train(params, xgdmat_train, num_boost_round=num_rounds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54830efd-39b3-460e-5d32-eeab4640ae4a"},"outputs":[],"source":"X_test_df = transform_x(test_data, phase=\"test\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd2b20dd-6170-0fb7-e744-8625cfe527dd"},"outputs":[],"source":"xgdmat_test = xgb.DMatrix(X_test_df.values)\ny_pred = mdl.predict(xgdmat_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"591d0279-d193-d48f-8f49-b428a8a73d6e"},"outputs":[],"source":"submission.iloc[:, 1] = inverse_transform_y(y_pred)\nsubmission.to_csv('vienna_kaggle_submission.csv', index=None)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b01f4ff2-8918-b1d2-a985-5c38c906e9cc"},"outputs":[],"source":"import utils\nimport skutils"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa883c6e-f9c2-9e3f-e521-5290cdc2b2c8"},"outputs":[],"source":"skutils.feature_hists(train_data, bins=50)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}