{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab67e5cb-bfa6-cc28-51a7-bb930e997ee9"},"outputs":[],"source":"#################################### AllState Claims Severity ############################################################\n\n# Below is function to encode categorical variables with high cardinality into numeric values such that they can \n# used in modeling exercises. The technique has been inspired from Owen Zhang's method of dealing with categorical variables\n# with high cardinality\n\n\n# Reading in training and test data\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib as plt\n%pylab inline\ndf_train = pd.read_csv(\"../input/train.csv\", index_col='id')\ndf_test = pd.read_csv(\"../input/test.csv\", index_col='id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fcdc3e5d-7c01-3ef0-e636-519cde5b62bc"},"outputs":[],"source":"# Getting all continuous features into a separate dataset\n\ncontfeatures = df_train.select_dtypes(include=[\"float64\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86a3f99b-8f01-b15e-a2ac-497f2b0eacd3"},"outputs":[],"source":"# Getting all categorical features into a separate dataset\ncatfeatures = df_train.select_dtypes(include=[\"object\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5080fa2-077b-5de0-2cfb-b0d54b259bc2","collapsed":true},"outputs":[],"source":"catfeatures_list = list(catfeatures)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33bd5e98-835d-5791-84b9-57559a52ec6e"},"outputs":[],"source":"# We can possibly feed categorical variables with less or eq 10 levels direclty into our model.\n# But, cat variables with >10 levels have to be feature engineered so that their effects can be included into the model\ncatvarbs_10 = list((df_train[catfeatures_list].apply(pd.Series.nunique)>10))\n\ncatvarlist = []\nfor (i, v) in zip(catfeatures_list, catvarbs_10):\n    if(v):\n        catvarlist.append(i)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b81c8c05-5785-7690-9c67-243052d5d959"},"outputs":[],"source":"print(catvarlist)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32f599b3-4273-4298-cee4-a9211b84c5cc"},"outputs":[],"source":"# WE append 'loss' variable to the cat varb dataset to compute means and variance\n\ncatvarlist.append('loss')\ndf_cat_encod = df_train[catvarlist]\ndf_cat_encod.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e46fca36-c518-3f5c-8b1c-d46c94841676"},"outputs":[],"source":"#before running our function to encode, we need to ensure that the list of char variables which we pass to the function\n#does not the 'loss' variable in it\n\ncatvarlist.remove('loss')\ncatvarlist\ntarget=['loss']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"260a8ebe-0823-9e73-edc4-8d7c49e4501a"},"outputs":[],"source":"df_cat_encod.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"566662c4-db49-a517-9bff-1a40af313017"},"outputs":[],"source":"# We define a function which will flatten a multi index column names which are created after aggregation of data\n# This will be useful after creating mean & standard dev of categorical variable levels\n\n\ndef flattenHierarchicalCol(col,sep = ','):\n    if not type(col) is tuple:\n        return col\n    else:\n        new_col = ''\n        for leveli,level in enumerate(col):\n            if not level == '':\n                if not leveli == 0:\n                    new_col += sep\n                new_col += level\n        return new_col"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"147fd930-45d3-9ca9-67b3-9c188ff08cb6"},"outputs":[],"source":"# The function below computes the mean and std dev of the target variable across each level of each categorical variable\n# identified and creates two separate features. This can instead be used as a continuous feature in any models we build\n# We add the std dev too so as to introduce some random variation/noise into the data\ndef cat_encoding(list, dataframe, target):\n    for i in range(len(list)):\n        group_df = dataframe.groupby([list[i]], as_index=False).agg({target:{\"mean\"+list[i]:'mean', \n                                                                    \"stdev\"+list[i]:'std'}})\n        dataframe = pd.merge(dataframe, group_df, on=list[i], how='left')\n    \n    dataframe.columns = dataframe.columns.map(flattenHierarchicalCol)\n    return dataframe"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9477508-0998-7994-3491-3fe3325a4d1f"},"outputs":[],"source":"cat_encoded = cat_encoding(catvarlist,df_cat_encod,target[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb4eabbc-e133-f999-c8cb-ca3a7079328a"},"outputs":[],"source":"cat_encoded.head(5)\n\n# Mean and std dev of all categorical variables identified have been computed and returned as a separate dataset which can be joined\n# to our original training set. The same mean & std dev values can be used to transform the same variables in the test set"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0171948c-78a3-d70e-e257-0b5e25a6851f"},"outputs":[],"source":"names = cat_encoded.columns\nnames"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd5f8e1d-a699-b38c-18d0-ea0f06e242db"},"outputs":[],"source":"del cat_encoded['loss']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa636cf7-6848-4e88-bff0-086ec9b5f95b","collapsed":true},"outputs":[],"source":"# Removing the word 'loss' from the left of the newly created columns\n\ncat_encoded.rename(columns = lambda x: x.replace('loss,',''), inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"00e6981c-167b-c94d-7b0f-391196a034ef"},"outputs":[],"source":"cat_encoded.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e63e3b00-4878-06cc-1707-6b0b59dd723f"},"outputs":[],"source":"# Taking the same categorical variables we encoded in train set from test set\n\ncat_encod_test = df_test[catvarlist]\ncat_encod_test.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db163e25-3b79-6111-0f3a-600139f1ddb8"},"outputs":[],"source":"cat_encod_test = cat_encod_test.reset_index()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d92fc058-7ea8-a50c-48ca-10afab46baf5"},"outputs":[],"source":"del cat_encod_test['id']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6602e77c-d16c-85ee-7110-4479da529dc7"},"outputs":[],"source":"cat_encoded.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e3a0da7-786c-91af-bad5-7eaadd4369ca"},"outputs":[],"source":"cat_encoded2 = cat_encoded"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adf429af-2c70-74d0-7cc4-4f1e6fa2b9dd"},"outputs":[],"source":"cat_encoded2 = cat_encoded2.drop(cat_encoded2[catvarlist],axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8670d8c-8c3e-c19c-a417-6d24923b4746"},"outputs":[],"source":"cat_encoded2.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b837571-3a53-e553-7b90-eb12cd74bdbe"},"outputs":[],"source":"onlystdev = cat_encoded2.filter(like='stdev', axis=1)\nonlystdev.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b99639e6-10e3-eafd-9cd5-1ea90f59e01c","collapsed":true},"outputs":[],"source":"stdev_names  = onlystdev.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"876e797b-221f-5811-5aca-14eac8c5478b"},"outputs":[],"source":"onlymean = cat_encoded2.filter(like='mean', axis=1)\nmean_names = onlymean.columns\nmean_names"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23f8e9f0-9e2a-6afd-be6c-c162d117e8d8"},"outputs":[],"source":"stdev_names.sort\nmean_names.sort"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a1ade96-3c41-be97-5af0-39e734c9fd7e"},"outputs":[],"source":"# Getting a dictionary based on training set encoding and mapping the same encoding to our test dataset\n\n\nfor i in range(len(catvarlist)):\n    mydict = dict(zip(cat_encoded[catvarlist[i]], cat_encoded[mean_names[i]]))\n    cat_encod_test[mean_names[i]] = cat_encod_test[catvarlist[i]].map(mydict)\n    mydict2 = dict(zip(cat_encoded[catvarlist[i]], cat_encoded[stdev_names[i]]))\n    cat_encod_test[stdev_names[i]] = cat_encod_test[catvarlist[i]].map(mydict2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f4aff7b-ab2d-096d-6c2f-fdd93d6524b3"},"outputs":[],"source":"cat_encod_test.head(5)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}