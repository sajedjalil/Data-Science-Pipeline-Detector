{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2cb12e08-8869-a78a-9f0d-8a88c59d1b2a"},"source":"This notebook will do the following:\n- Load the training and test data into a dataframe\n- Convert them to numpy arrays\n- Converting the categorical fields to integer values \n- Transforming skewed numeric features using [BoxCox Transform][1]\n- Training an XGB model from the training data using cross-validation\n- Applying the trained model on the test data and saving the results to a csv file\n\n\n  [1]: http://onlinestatbook.com/2/transformations/box-cox.html"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4530b983-3762-2207-73dd-17276fe12535"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn\nprint('The scikit-learn version is {}.'.format(sklearn.__version__))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c64fa883-d6b8-67b7-c0a2-d3f0fc57789c"},"outputs":[],"source":"#Load the training and test files\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\nprint('training: ', df_train.shape)\nprint('test: ', df_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62e20752-eb29-aed0-516d-d1551c15bc54"},"outputs":[],"source":"#Convert to Numpy arrays and separate features/targets\ntraining_samples = df_train.as_matrix()\ntraining_targets = training_samples[:,-1]\ntraining_samples = training_samples[:,1:-1]\n\ntest_samples = df_test.as_matrix()\ntest_samples = test_samples[:,1:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d42bc66f-940c-10d6-c07b-5995416e5e3d"},"outputs":[],"source":"plt.hist(training_targets[np.where(training_targets < 15000)], bins = 200, color='r', normed=True)\nplt.grid(True)\nplt.xlabel('Target Value')\nplt.ylabel('Normalized Frequency')\nplt.title('Distribution of target values from training set.')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a20aa66-a8bf-f7ca-901e-db2756b9722a"},"outputs":[],"source":"#Encode the Labels of the categorical data\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n# [0:116]\nallLabels = np.concatenate( ( training_samples[:, 0:116].flat , test_samples[:, 0:116].flat ) )\nle.fit( allLabels )\ndel allLabels\nprint(le.classes_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58ba15ca-bf0c-cbfb-d683-398d542331a5"},"outputs":[],"source":"#Transform the labels to int values\nfor colIndex in range(116):\n    training_samples[:, colIndex] = le.transform(training_samples[:, colIndex])\n    test_samples[:, colIndex] = le.transform( test_samples[:, colIndex] )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8d42283-51f6-3715-af1e-58e26f4aceec"},"outputs":[],"source":"training_samples = training_samples.astype(np.float)\ntest_samples = test_samples.astype(np.float)\nprint(training_samples.shape)\nprint(test_samples.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"507d062f-2bb1-c983-4bee-00c811d141e4"},"outputs":[],"source":"from scipy.stats import skew, boxcox\n#Calculate the skew of the features\nfor featureIdx in range( training_samples.shape[1] ):\n    train_test_feature_values = np.concatenate( (training_samples[:,featureIdx], test_samples[:,featureIdx] ), axis=0 )\n    skew_ = skew(train_test_feature_values )\n    #Transform the numeric features with high skew values\n    if abs(skew_) > 0.25 and featureIdx >= 116:\n        print(skew_)\n        train_test_feature_values = train_test_feature_values + 1\n        transformed_feature_values, lm = boxcox( train_test_feature_values )\n        training_samples[:,featureIdx] = transformed_feature_values[0:training_samples.shape[0]]\n        test_samples[:,featureIdx] = transformed_feature_values[training_samples.shape[0]:]\n        "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bea21453-15c9-e5b3-1480-4f7c5aa28852"},"outputs":[],"source":"#Train and Cross-Validate using the splits\n#We will use xgb for regression with CV for grid search\nimport xgboost as xgb\n\n#The parameters are taken from these two kernels: \n#    https://www.kaggle.com/mmueller/allstate-claims-severity/stacking-starter, \n#    https://www.kaggle.com/tilii7/allstate-claims-severity/bias-correction-xgboost\n# with minor changes\nxgb_params = {\n    'seed': 0,\n    'colsample_bytree': 0.3085,\n    'silent': 1,\n    'subsample': 0.7,\n    'learning_rate': 0.01,\n    'objective': 'reg:linear',\n    'max_depth': 7,\n    'num_parallel_tree': 1,\n    'min_child_weight': 4.2922,\n    'eval_metric': 'mae',\n    'eta':0.1,\n    'gamma': 0.5290,\n    'subsample':0.9930,\n    'max_delta_step':0,\n    'booster':'gbtree',\n    'nrounds': 1001\n}\n\ndtrain = xgb.DMatrix( training_samples, label=training_targets)\nxgb_cv_res = xgb.cv(xgb_params, dtrain, num_boost_round=2001, nfold=4, seed = 0, stratified=False,\n             early_stopping_rounds=25, verbose_eval=50, show_stdv=True)\n\nprint('finished cv.')\nxgb_cv_res.plot(y=['test-mae-mean', 'train-mae-mean'], grid=True, logx=True)\nplt.xlabel('Round')\nplt.ylabel('mae')\nplt.show()\n\nbest_nrounds = xgb_cv_res.shape[0] - 1\nxgb_best = xgb.train(xgb_params, dtrain, best_nrounds)   "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34b15a68-5b46-090d-6bb6-9ca5ca7a7b84"},"outputs":[],"source":"#Predit for the test data\ndtest = xgb.DMatrix( test_samples)\npred_test = xgb_best.predict(dtest)\nprint(pred_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3815dab-a05e-a923-a6e5-21fe01cc0de7"},"outputs":[],"source":"#Save results to csv file\ndf_res = pd.DataFrame(df_test, columns=['id'])\ndf_res['loss'] = pred_test\nprint(df_res.iloc[0])\ndf_res.to_csv('result.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}