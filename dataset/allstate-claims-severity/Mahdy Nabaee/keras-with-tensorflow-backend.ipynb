{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"cf6f1ab9-6d4c-6298-96ca-ef704d6c2581"},"source":"This notebook implements a deep learning kernel using Keras with TensorFlow backend:\n- Loading the files into numpy arrays \n- Performing LabelEncoding on categorical fields\n- Building a deep model using Keras wrappers - model is: 130-1000-1000-500-100-20-1 dense model\n- Training the model using ADAM optimizer\n\nAlthough the results using this model are not as good as those using XGBoost in this other [notebook][1] https://www.kaggle.com/mnabaee/allstate-claims-severity/labelencoding-and-xgb-cv, it is a good starting point for deep models.\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9e18ab6-b547-716f-b085-01f15b5057f6"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom __future__ import absolute_import, division, print_function\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nprint('The scikit-learn version is {}.'.format(sklearn.__version__))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83023da4-4c89-d173-6eb5-a2cfdf6f14f8"},"outputs":[],"source":"#Load the training and test files\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\nprint('training: ', df_train.shape)\nprint('test: ', df_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"923af430-2f49-af31-4b56-492bb1efe1b6"},"outputs":[],"source":"#Convert to Numpy arrays and separate features/targets\ntraining_samples = df_train.as_matrix()\ntraining_targets = training_samples[:,-1]\ntraining_samples = training_samples[:,1:-1]\n\ntest_samples = df_test.as_matrix()\ntest_samples = test_samples[:,1:]\n\n#Encode the Labels of the categorical data\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n# [0:116]\nallLabels = np.concatenate( ( training_samples[:, 0:116].flat , test_samples[:, 0:116].flat ) )\nle.fit( allLabels )\ndel allLabels\n#print(le.classes_)\n\n#Transform the labels to int values\nfor colIndex in range(116):\n    training_samples[:, colIndex] = le.transform(training_samples[:, colIndex])\n    test_samples[:, colIndex] = le.transform( test_samples[:, colIndex] )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23ccaafa-9c6c-9c35-d5bc-289687e64dec"},"outputs":[],"source":"#from keras.layers.normalization import BatchNormalization\n\ndef larger_model():\n    model = Sequential()\n    model.add(Dense(1000, input_dim=130, init='normal', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Activation('relu'))\n    #model.add(Dropout(0.5))\n    \n    model.add(Dense(1000, init='normal', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Activation('relu'))\n    #model.add(Dropout(0.5))\n    \n    model.add(Dense(500, init='normal', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Activation('relu'))\n    #model.add(Dropout(0.5))\n    \n    model.add(Dense(100, init='normal', activation='relu'))\n    \n    model.add(Dense(20, init='normal', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Activation('relu'))\n    #model.add(Dropout(0.5))\n    \n    model.add(Dense(1, init='normal'))\n    #model.add(BatchNormalization())\n    #model.add(Activation('relu'))\n    #model.add(Dropout(0.5))\n\n    model.compile(loss='mean_absolute_error', optimizer='adam')\n    return model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff588336-8273-afad-aec1-0ffd260c2f81"},"outputs":[],"source":"np.random.seed(0)\n\n\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasRegressor(build_fn=larger_model, nb_epoch=20, batch_size=50, verbose=1)))\npipeline = Pipeline(estimators)\n\n#Uncomment the following line to run fitting and prediction phases\n#The fitting will take a very long time\n#pipeline.fit(training_samples, training_targets)\n#pred_targets = pipeline.predict(test_samples)\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}