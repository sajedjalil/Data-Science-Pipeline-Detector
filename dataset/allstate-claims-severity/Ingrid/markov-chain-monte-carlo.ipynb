{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ba7b9b53-e773-fa6e-4208-83ff971a9cfd"},"source":"Welcome to the wonderful world of Markov Chain Monte Carlo\n\nHere I present a toy example of how one can use MCMC to get a pretty good improvement over straight averaging"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71120554-87aa-e461-d0d3-d91040b2c482"},"outputs":[],"source":"import numpy as np\nfrom pymc3 import *\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\n%matplotlib inline"},{"cell_type":"markdown","metadata":{"_cell_guid":"78056b59-0436-6f9f-3f42-39d58be4ae61"},"source":"The following cell creates the two models with noise based on a target.\nOne should note that the first model has more noise than the second model so one would expect model 1 to perform worse than model 2"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bfb499a7-5137-637a-04c1-c423f1786764"},"outputs":[],"source":"size = 200\ntrue_intercept = 1\ntrue_slope = 2\nx = np.linspace(0, 1, size)\n# y = a + b*x\ntrue_regression_line = true_intercept + true_slope * x\n# add noise\nmodel1 = true_regression_line + np.random.normal(scale=.5, size=size) #Noisy\nmodel2 = true_regression_line + np.random.normal(scale=.2, size=size) #Less Noisy"},{"cell_type":"markdown","metadata":{"_cell_guid":"d32a7bf8-87a9-4a08-0b8b-c30ed073bfe7"},"source":"Let us see what the MAE looks like"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e290451b-e23d-d38f-4308-9a96a4cd08a9"},"outputs":[],"source":"print(mean_absolute_error(true_regression_line,model1))\nprint(mean_absolute_error(true_regression_line,model2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd672844-7d55-03b1-7afa-c686db58a406"},"source":"As expected the noisier model does worse"},{"cell_type":"markdown","metadata":{"_cell_guid":"1c14c03a-35c4-d4b4-e70c-cb7cae364e67"},"source":"Now let us look at the straight average"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4dd744e-f03c-21ac-bdc2-3408a678dd1a"},"outputs":[],"source":"print(mean_absolute_error(true_regression_line,model1*.5+model2*.5))"},{"cell_type":"markdown","metadata":{"_cell_guid":"ceb449e7-e977-7f0f-98eb-b55ac402722d"},"source":"As one can see this isn't as good as our top model"},{"cell_type":"markdown","metadata":{"_cell_guid":"ebcb3903-ed60-a403-51f2-30a94120d5d3"},"source":"Now comes the cool part.  We are going to use MCMC to draw samples from our data and get stats on how we can obtain a model that gets the best out of our raw models.\n\nImportant:  Please look at the documentation [here][1] (https://pymc-devs.github.io/pymc3/index.html) for details\n\n\n  [1]: https://pymc-devs.github.io/pymc3/index.html"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a23b1bda-4853-a214-c2d9-eb8bdc30fe1a"},"outputs":[],"source":"data = dict(x1=model1, x2=model2, y=true_regression_line)\nwith Model() as model:\n    # specify glm and pass in data. The resulting linear model, its likelihood and \n    # and all its parameters are automatically added to our model.\n    glm.glm('y ~ x1 + x2', data)\n    step = NUTS() # Instantiate MCMC sampling algorithm\n    trace = sample(2000, step, progressbar=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b0e9af59-4534-ec33-a358-03f40ad0419b"},"source":"It takes a while - now is time to look at what goodness it gives to us"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ea87feb-96d1-ac52-09b2-11a90707ad5d"},"outputs":[],"source":"plt.figure(figsize=(7, 7))\ntraceplot(trace)\nplt.tight_layout();"},{"cell_type":"markdown","metadata":{"_cell_guid":"e1d921bb-9c51-9faf-8608-b07494936936"},"source":"One can see that for every drawn sample it gives the parameter values for the intercept, x1 and x2"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3afeac54-5894-738d-5d6c-93a8f87e321f"},"outputs":[],"source":"intercept = np.median(trace.Intercept)\nprint(intercept)\nx1param = np.median(trace.x1)\nprint(x1param)\nx2param = np.median(trace.x2)\nprint(x2param)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7d4c5b45-5e05-1d32-5625-1ba880839cb0"},"source":"Now is the time to see how well we have done!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3f7493b-2612-b30b-af02-6dd774e3b292"},"outputs":[],"source":"print('Model 1:',mean_absolute_error(true_regression_line,model1))\nprint('Model 2:', mean_absolute_error(true_regression_line,model2))\nprint('Average:',mean_absolute_error(true_regression_line,model1*.5+model2*.5))\nprint('MCMC:',mean_absolute_error(true_regression_line,intercept+x1param*model1+x2param*model2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"4a54d6c3-5642-8490-9480-5c73f42965fd"},"source":"I hope this helps!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}