{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b0fd9509-fc6b-4043-dd3b-6c1dcb9b8e07"},"source":"I'm a totally new bee in Kaggle and this is my first competition, got ~1114 in public leaderboard using pure Xgboost in raw features with 5-fold cross_validation. I have learned a lot from kaggle forums and a friend.   I want to share it with all starters. Hope it will be helpful for someone. If there are any mistakes, please do not hesitate to let me know."},{"cell_type":"markdown","metadata":{"_cell_guid":"a73e0239-3ec8-e03e-ea2d-531c42b60afd"},"source":"Due to this NoteBook cannot write files, so If you want to run my code, copy and paste them to your local workspace.  "},{"cell_type":"markdown","metadata":{"_cell_guid":"90038d55-d53f-23d6-dfb7-43186b406ae3"},"source":"###Step 1 \n\nTransform letters of categories in train.csv and test.csv into numbers for computation, using script bellow. you will get two files named train_num.csv and test_num.csv"},{"cell_type":"markdown","metadata":{"_cell_guid":"7ce663df-8ded-b911-7802-92d9d4f8e881"},"source":"    import pandas as pd\n    import numpy as np\n    \n    np.random.seed(1234)\n    def LetterToNumber(data,dest_file):\n        for c in data.columns:\n            if 'cat' in c:\n                print c\n                data[c]=data[c].astype(\"category\")\n                data[c].cat.categories=range(len(set(data[c].values)))\n        data.to_csv(dest_file, index=False)\n    \n    \n    train = pd.read_csv(\"./data/train.csv\")\n    train_dest = \"./data/train_num.csv\"\n    LetterToNumber(train,train_dest)\n    test = pd.read_csv(\"./data/test.csv\")\n    test_dest = \"./data/test_num.csv\"\n    LetterToNumber(test,test_dest)\n\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"027d95ed-aaf4-4a15-1dc5-0f645c41e916"},"source":"###Step 2\n\nrandomly split train data into five parts in preparation for cross_validation. \n"},{"cell_type":"markdown","metadata":{"_cell_guid":"3374a140-5bb1-e86d-d99b-924a2057a308"},"source":"    #split_cv.py\n    \n    import numpy as np\n    \n    np.random.seed(1234)\n    \n    ids=[]\n    for line in open(\"./data/cut_cv\"):\n        ids.append(int(line))\n    train=[0]*5\n    test=[0]*5\n    for i in range(5):\n        train[i]=open(\"./data/train_cv_\"+str(i)+\".csv\",\"w\")\n        test[i]=open(\"./data/test_cv_\"+str(i)+\".csv\",\"w\")\n    for j,line in enumerate(open(\"./data/train_num.csv\")):\n        if j==0:\n            for i in range(5):\n                train[i].write(line)\n                test[i].write(line)\n            continue\n        else:\n            for id in range(5):\n                if id != ids[j-1]:\n                    train[id].write(line)\n            test[ids[j-1]].write(line)"},{"cell_type":"markdown","metadata":{"_cell_guid":"93621df0-d24c-1b0a-ec2a-4be515c3189e"},"source":"### Step 3\n\nusing Xgboost to train and predict. \n\nwe will get five predictions on test_num.csv."},{"cell_type":"markdown","metadata":{"_cell_guid":"920f9c11-2f48-666c-e24a-f922343f888e"},"source":"    #train_predict.py\n    \n    import xgboost\n    import pandas as pd\n    import numpy as np\n    import datetime\n    from sklearn.metrics import mean_absolute_error\n    \n    np.random.seed(1234)\n    \n    def logregobj(preds, dtrain):\n        labels = dtrain.get_label()\n        con = 2\n        x = preds-labels\n        grad = con*x / (np.abs(x)+con)\n        hess = con**2 / (np.abs(x)+con)**2\n        return grad, hess\n    \n    def xg_eval_mae(yhat, dtrain):\n        y = dtrain.get_label()\n        return 'mae', mean_absolute_error(np.exp(y)-shift,\n                                          np.exp(yhat)-shift)\n    \n    \n    for CV in range(5):\n        CV = str(CV)\n        print 'loading...',CV\n        train=pd.read_csv(\"./data/train_cv_\"+CV+\".csv\")\n        test=pd.read_csv(\"./data/test_cv_\"+CV+\".csv\")\n        shift=200\n    \n        print 'droping...'\n        train_X=train.drop(['id','loss'],axis=1)\n        train_Y=np.log(train['loss']+shift)\n        test_X=test.drop(['id','loss'],axis=1)\n        test_Y=np.log(test['loss']+shift)\n    \n        train=xgboost.DMatrix(train_X,label=train_Y)\n        test=xgboost.DMatrix(test_X,label=test_Y)\n        #8 12\n        param = {'max_depth':8 , 'gamma': 0, 'silent': 0, 'boost': 'gbtree', 'objective': 'reg:linear',\n                 'alpha': 1, 'subsample': 0.86, \"min_child_weight\": 50,\n                 \"colsample_bytree\": 0.32, 'colsample_bylevel': 1}\n    \n    \n        param['nthread'] = 1\n        num_round = 200000\n    \n        watchlist = [(train,'train'),(test,'test')]\n    \n        print \"trainning...\"\n        bst = xgboost.train(param.items(),train, num_round,watchlist,learning_rates=[0.02]*num_round,obj=logregobj,\n                            feval=xg_eval_mae,maximize=False,early_stopping_rounds=500)\n    \n        for i,line in enumerate(sorted(bst.get_score().iteritems(),key=lambda d:d[1], reverse=True)):\n            if i>30:\n                break\n            print line\n    \n        print 'loading...'\n        raw_test=pd.read_csv(\"./data/test_num.csv\")\n        test=xgboost.DMatrix(raw_test.drop(['id'],axis=1))\n    \n        print 'predicting...'\n        result=np.exp(bst.predict(test))-200\n        now = datetime.datetime.now()\n        pd.DataFrame({'id':raw_test['id'].values,'loss':result}).to_csv('./result/cv_cls2/'+\n                                                                        now.strftime(\"%Y-%m-%d-%H-%M\")+\n                                                                        \"_\"+CV+\".csv\",index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8a1259b2-3468-eff9-887a-af6ee32e1b36"},"source":"### Step 4\n\nThe last thing is to **average out** above five results on test_num.csv and get the final prediction."},{"cell_type":"markdown","metadata":{"_cell_guid":"2dd0e1da-f559-7e35-d787-3c5af6117e3d"},"source":"    #merge_result.py\n    \n    import os\n    import datetime\n    dir=os.listdir(\"./result/cv_cls2/\")\n    ID=[]\n    temp = []\n    ct=[]\n    for i,file in enumerate(dir):\n        file=\"./result/cv_cls2/\"+file\n        print file\n        for j,line in enumerate(open(file)):\n            if j==0:\n                continue\n            if i==0:\n                ID.append(line.split(\",\")[0])\n                temp.append(float(line.split(\",\")[1]))\n                ct.append(1)\n            else:\n                temp[j-1]+=float(line.split(\",\")[1])\n                ct[j-1]+=1\n    now = datetime.datetime.now()\n    \n    path = './result/' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '_cls2.csv'\n    tow=open(path,\"w\")\n    tow.write(\"id,loss\\n\")\n    for i,line in enumerate(temp):\n        r=temp[i]/ct[i]\n        tow.write(ID[i]+\",\"+str(r)+\"\\n\")\n    tow.close()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}