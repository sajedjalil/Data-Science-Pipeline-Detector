{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c17253e0-77b4-eb1b-f40f-98566083d37e"},"source":"There are already a bunch of awesome Scripts, but I wanted to step back and work with some more rudimentary models to make sure I was doing the right data preparation.\n\nLet's start by loading our packages and data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19f5d752-089f-e8b1-ff2c-e82e076fa649"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew, boxcox\nimport statsmodels.formula.api as smf\n\n# Load Training Data\ntrain = pd.read_csv('../input/train.csv', dtype={'id': np.int32})\n\n# Load Test Data\ntest = pd.read_csv('../input/test.csv', dtype={'id': np.int32})"},{"cell_type":"markdown","metadata":{"_cell_guid":"3e16f0b1-7c27-d32d-7998-897d47f304b3"},"source":"Nomenclature note: The outcome variable for this competition is 'loss'. (If you read much machine learning literature, you've probably heard the term loss as in '[loss function](https://en.wikipedia.org/wiki/Loss_function)'.) That isn't exactly what we mean in this context. The 'loss' variable in this case literally refers to the amount AllState lost on the settlement. Wherever you see 'loss' in this document, assume I'm talking about the amount AllState lost, and not the output of a loss function.\n\nNow, prediction is easier on an outcome that's normally distributed. Let's check to see if this data is:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b8320ec-2d10-dcda-966f-9fd48b011b4d"},"outputs":[],"source":"plt.hist(train['loss'], 30, normed=1)\nplt.xlabel('Loss')\nplt.ylabel('Probability')\nplt.title('Distribution of Losses')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b695414e-3aff-6f82-cb7a-1b19200ef67f"},"source":"Wow. That isn't normally distributed at all: it's super *[skewed](https://en.wikipedia.org/wiki/Skewness)*."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b7ea3d5-856f-6d13-73bc-fc1a8a575c4f"},"outputs":[],"source":"skew(train['loss'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"1c4fa9c4-f801-4ece-0dc3-1864f76abe40"},"source":"Any skew greater than one should probably catch your attention. Luckily, we have a simple counterspell! Let's *log-transform* the 'loss' variable."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1b3a0cf-f020-2c12-abbd-c304e180fc57"},"outputs":[],"source":"train['log_loss'] = np.log(train['loss'])\n\nplt.hist(train['log_loss'], 30, normed=1)\nplt.xlabel('Log(Loss)')\nplt.ylabel('Probability')\nplt.title('Distribution of Log(Loss)es')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e90b49ae-5b8e-d632-0b13-56d86085f2e4"},"source":"Much Better. Now, what about our input variables? Are they similarly skewed?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82ce863f-e4a1-c0b1-16dc-51182057a96e"},"outputs":[],"source":"features_numeric = test.dtypes[test.dtypes != \"object\"].index\nfeatures_skewed = train[features_numeric].apply(lambda x: skew(x.dropna()))\nfeatures_skewed"},{"cell_type":"markdown","metadata":{"_cell_guid":"57bf5d17-6e97-c8a3-42a1-f56d202e1ca3"},"source":"Some of them, yeah. We can fix that by taking their log-transforms as well, but log is sort of a blunt instrument. It's easily reversible, which makes it good for the outcome. But the Box-Cox transform is a better tool for modifying our inputs. Let's apply it to any features with a skew greater than, say, .2"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"375f0216-0940-b168-97b7-3b6daa07bcd3"},"outputs":[],"source":"features_skewed = features_skewed[features_skewed > 0.2]\nfor feat in features_skewed.index:\n    train[feat], lam = boxcox(train[feat] + 1)\n    test[feat] = boxcox(test[feat] + 1, lam)\n\nfeatures_skewed = train[features_numeric].apply(lambda x: skew(x.dropna()))\nfeatures_skewed"},{"cell_type":"markdown","metadata":{"_cell_guid":"378337bc-f12f-d45a-2279-403ea9acbcda"},"source":"That eliminated much of the skewness. Before we move on, however, I'd like to call attention to the way we handle `lam` in the above block. We let `boxcox` figure out the optimal `lam` using our training data, and then force it to use that same `lam` on the test data, even if it isn't necessarily optimal for the test data. The alternative approach is to bind `train` and `test` together, perform these transformations on the entire set, and then split them back apart when it comes time to build models. I've opted not to for the benefit of clarity, but possibly at the cost of some small modeling advantage.\n\nNow, we have some categorical features we need to handle. The textbook approach to Linear Regression says you can leave categorical variables in, provided you do something like *[one-hot encode](https://en.wikipedia.org/wiki/One-hot)* them and leave out the smallest category. Personally, I prefer to replace the category with the arithmetic mean of its corresponding subset of outcomes."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25edd603-a172-820c-ee84-98efd5dd2aed"},"outputs":[],"source":"features_categorical = [feat for feat in test.columns if 'cat' in feat]\n\nfor feat in features_categorical:\n    a = pd.DataFrame(train['log_loss'].groupby([train[feat]]).mean())\n    a[feat] = a.index\n    train[feat] = pd.merge(left=train, right=a, how='left', on=feat)['log_loss_y']\n    test[feat] = pd.merge(left=test, right=a, how='left', on=feat)['log_loss']\n\nfeatures_categorical = test.dtypes[test.dtypes == \"object\"].index"},{"cell_type":"markdown","metadata":{"_cell_guid":"6e4398c0-74b4-8cdd-d3ae-fea624d587fd"},"source":"There's just one more thing to check on. Linear Regression generally doesn't handle missing values very well. Let's see if we have any:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d73d9dd-dd87-b594-5945-18717da35d3d"},"outputs":[],"source":"counts = train.count()\nlen(counts[counts < train.shape[0]])"},{"cell_type":"markdown","metadata":{"_cell_guid":"bda39254-3c42-4389-95f0-dd1b2b3850d2"},"source":"Not in the training dataset. Let's check `test` now:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"21e4d42c-e50b-2e05-ff60-7cd5f8a2b82a"},"outputs":[],"source":"counts = test.count()\nlen(counts[counts < test.shape[0]])"},{"cell_type":"markdown","metadata":{"_cell_guid":"35bfb319-730b-5ca6-f603-38c0e3b3ed13"},"source":"Rats. OK, Rather than design a elaborate solution, I'm just going to drop any columns with missing values."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2e245bb-9016-f41e-96e3-5ae823d8dfc5"},"outputs":[],"source":"temp = test.dropna(1)\ncounts = temp.count()\nlen(counts[counts < temp.shape[0]])"},{"cell_type":"markdown","metadata":{"_cell_guid":"e82983e1-ae55-aa5f-ae75-cc72a3477f84"},"source":"Cool. Now, we're ready to make a model. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e670242-680f-375c-4a2b-a3de1fd2f5b3"},"outputs":[],"source":"model = smf.ols('log_loss ~ ' + ' + '.join(temp.columns), data=train).fit()\nmodel.summary()"},{"cell_type":"markdown","metadata":{"_cell_guid":"69d2010b-9035-df6c-7480-270196d8b9a0"},"source":"There's a lot of useful information here. However, since this is a prediction challenge, I'm not interested in most of it. Instead, I'm interested in how well it can predict new values. To do that..."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7bb6f3e-2dd1-1d23-a1e9-6321bcd61726"},"outputs":[],"source":"yhat = np.exp(model.predict(test))"},{"cell_type":"markdown","metadata":{"_cell_guid":"2410310a-4e40-f587-489c-ff03d67548ba"},"source":"Note that we call `np.exp` on our model predictions. Remember how we log-transformed 'loss' up at the beginning of this script? Exponentiating the outcome sort of undoes that, so our predictions will be on the same scale as 'loss' instead of 'log_loss'. Forgetting this step is a really good way to get a terrible score.\n\nNow that we have some predictions, let's write them out and score them!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a63fe18-2219-4487-9647-d2168e214764"},"outputs":[],"source":"result = pd.DataFrame({'id': test['id'].values, 'loss': yhat})\nresult = result.set_index('id')\nresult.to_csv('simplelmprediction.csv', index=True, index_label='id')"},{"cell_type":"markdown","metadata":{"_cell_guid":"16e05916-d708-cee5-086e-d0ba9188ebaa"},"source":"If you submit that, it should give you a score something like 1245.99. That's a bit worse than the Random Forest Benchmark (which isn't surprising). Onward to greater refinements!\n\nGood luck!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32b889da-8f69-a396-1714-64b9fc258bc9"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}