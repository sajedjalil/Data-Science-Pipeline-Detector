{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1b39fcf-4b81-8e71-754e-ef69f821e1f6"},"source":"This has been beat to death , but I thought I'd share my initial data exploration with everyone still. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"415f4657-1532-ba7e-48e2-3ff96ee13782"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\n\n\n%matplotlib inline\n#sns.set_context('poster')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eddf6d96-81cc-a043-3984-285d4e4fe0c0"},"outputs":[],"source":"data = pd.read_csv('../input/train.csv')\nfeatures = list(data.columns)\nfeatures.remove('id')\nfeatures.remove('loss')\ncat_features = [x for x in features if x.find('cat') != -1]\ncont_features = [x for x in features if x.find('cont') != -1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f5d60ee5-33cc-0c63-1291-28e8a3c10bcd"},"outputs":[],"source":"# No Missing Data ! A MIRACLE\ndata.isnull().any().any()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03b3d0db-5c15-f38c-36ab-c1d550276fd6"},"outputs":[],"source":"correlationMatrix = data.copy()\ncorrelationMatrix.drop(cat_features+['id','loss'],inplace=True,axis=1)\ncorrelationMatrix['logLoss'] = np.log(data.loss)\n\ncorrelationMatrix = correlationMatrix.corr().abs()\nmap = sns.clustermap(correlationMatrix,annot=True,annot_kws={\"size\": 10})\nsns.plt.setp(map.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\nsns.plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cd137a37-a233-cb85-28a6-b43e2849a0ed"},"source":"Some correlated feature : \n\n- [cont1,cont9] \n- [cont11,cont12]\n\nMaybe worth visiting:\n\n- [cont6 , cont10]\n\nThere is a strong pattern with : \n\n- 11 12 , 7 is an outlier to the group \n- 1 9 6 and 10 13 is an outlier\n\nShould investigate further"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74472a8d-8d6f-98bb-1d2a-66f6f0d65fa2"},"outputs":[],"source":"# I think we all know what these look like - I'm not uploading them.\n# cat_dat = data.copy()\n# cat_dat.drop(cont_features,inplace=True,axis = 1)\n# for i in cat_features:\n#     try:\n#         sns.boxplot(data=cat_dat,x=i,y=np.log(data.loss))\n#         sns.plt.show()\n#     except:\n#         print('{} failed for some reason'.format())"},{"cell_type":"markdown","metadata":{"_cell_guid":"9430ccb0-9537-5279-2fec-616e08c40ac8"},"source":"None of the categorical variables are obviously partitioning between loss.\nCat116 especially could make for a VERY sparse matrix"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55ad2854-92de-a8f1-7864-049ae73e9dd5"},"outputs":[],"source":"# Same thing here, if you want to draw them feel free to fork and run\n# for i in cont_features:\n#     try:\n#         sns.distplot(data[i])\n#         sns.plt.show()\n#     except:\n#         print(\"{} failed for some reason\".format(i))"},{"cell_type":"markdown","metadata":{"_cell_guid":"1c4e1dee-91f8-fa36-701a-e6485d9c6471"},"source":"Continuous variables that might be categorical:\n\n- cont2 \n\nAll variables are non-normal and skewed (but do all scale 0-1).\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}