{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ARCifier\n[*Daniel Becker*](https://www.kaggle.com/danielbecker)"},{"metadata":{},"cell_type":"markdown","source":"## Table of Content\n1. [Introduction](#introduction)\n2. [Preparation](#preparation)\n3. [Feature Extraction](#feature_extraction)   \n4. [EDA](#eda)\n    1. [Input and Output shapes](#eda_1)\n    2. [Changes of the input shapes](#eda_2)\n    3. [Distribution of boolean Features](#eda_3)\n    4. [Average color ratio](#eda_4)\n    5. [Features correlation plot](#eda_5)\n5. [Prediction](#prediction)\n    1. [Rotation and Flips](#prediction_1)\n    2. [Vertical or Horizontal Split](#prediction_2)\n    3. [Fill out through symmetries](#prediction_3)\n    4. [Growing Input](#prediction_4)\n    5. [Color changes](#prediction_5)\n    5. [Objects](#prediction_6)\n    6. [Final Score](#final_score)\n6. [Submission](#submission)"},{"metadata":{},"cell_type":"markdown","source":"## 1. Introduction <a id=\"introduction\"></a>  \n**Score **   \nTrain: 0.9207 (33/416)  \nValidation: 0.9451 (23/419)  \nPublic Test: 0.9519 (5/104)  \nPrivate Test: 1.0000 (0/100)"},{"metadata":{},"cell_type":"markdown","source":"## 2. Preparation <a id=\"preparation\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\nimport os\nimport json\nimport random\nimport warnings\nimport datetime","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import Files as DataFrame  \nAll files will be loaded into their corresponding DataFrame. The DataFrames have the following columns:\n* **input:** Input array\n* **output:** Output array\n* **task_id:** Name of the json file to identify the task (e.g. 'a1b2c3d4')\n* **submission_id:** The id for the submission. Is only used for the test data. Contains the task id with an integer suffix (e.g. 'a1b2c3d4_0', 'a1b2c3d4_1'). This is neccesary because some task have multiply input tests for prediction.\n* **type:** training or test"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def get_filenames(directory):\n    \"\"\" Get list with all files in the directory\n\n        param directory: Path to the directory\n        return result: List with filenames\n    \"\"\"   \n    return [os.path.join(dirname, filename) for dirname, _, filenames in os.walk(directory) for filename in filenames]\n\ndef import_json_to_df(filename):\n    \"\"\" Create a DataFrame from the JSON file\n    \n        Columns:\n        - input: Input array of the Task (e.g. [[1]])\n        - output: Output array of the Task (e.q. [[2]])\n        - task_id: Filename (e.g. 'a1b2c3d4')\n        - submission_id: Unique identifier for the test tasks (e.g. '{task_id}_0', '{task_id}_1')\n        - type: train/test\n\n        param filename: Path to the JSON file\n        return result: DataFrame of the JSON file\n    \"\"\" \n    with open(filename, 'r') as f:\n        task = json.load(f)\n    result = []\n    for key in task:\n        df = pd.DataFrame(task[key])\n        df['task_id'] = os.path.splitext(os.path.basename(filename))[0]\n        if key == 'test':\n            df['submission_id'] = df.apply(lambda x: f\"{x['task_id']}_{x.name}\", axis=1)\n        df['type'] = key\n        result.append(df)\n    result = pd.concat(result, ignore_index=True, sort=False)\n    result['input'] = result['input'].apply(np.array)\n    result['output'] = result['output'].apply(np.array)\n    return result\n    \ndata_dir = '/kaggle/input/abstraction-and-reasoning-challenge/'\n\nsubmission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\ntraining_files = sorted(get_filenames(os.path.join(data_dir, 'training')))\nevaluation_files = sorted(get_filenames(os.path.join(data_dir, 'evaluation')))\ntest_files = sorted(get_filenames(os.path.join(data_dir, 'test')))\n\n\ntrain = pd.concat([import_json_to_df(f) for f in training_files], ignore_index=True, sort=False)\nvalidation = pd.concat([import_json_to_df(f) for f in evaluation_files], ignore_index=True, sort=False)\ntest = pd.concat([import_json_to_df(f) for f in test_files], ignore_index=True, sort=False)\n\ntrain.shape, validation.shape, test.shape, submission.shape\nprint(f'Train: {train.shape}')\nprint(f'Validation: {validation.shape}')\nprint(f'Test: {test.shape}')   \nprint(f'Submission: {submission.shape}')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"print('Example with 1 test pair')\ndisplay(train[train['task_id']=='007bbfb7'])\nprint('Example with 2 test pairs')\ndisplay(train[train['task_id']=='e9614598'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Global Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings('ignore')\npd.set_option('display.max_colwidth', -1)\n\n# Random seeds\nSEED = 13\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\n# Max Size of images for padding\nMAX_SIZE = 30\n# Padding\nPAD_ID = -1\nPAD_COLOR = '#FFFFFF'\n# Colors for Plots\nORG_COLOR_MAP = {0:'#000000', 1:'#0074D9', 2:'#FF4136', 3:'#2ECC40', 4:'#FFDC00',\n         5:'#AAAAAA', 6:'#F012BE', 7:'#FF851B', 8:'#7FDBFF', 9:'#870C25'}\nNUM_COLORS = len(ORG_COLOR_MAP)\n\nCOLOR_MAP = {PAD_ID:PAD_COLOR}\nCOLOR_MAP.update(ORG_COLOR_MAP)\n\nDEFAULT_PREDICTION = [[0]]\nDEFAULT_SUBMISSION = '|0| |0| |0|'\n\n# Names of the DataFrame to use for plots or prints\nDF_NAME = {id(train): 'train', id(validation): 'validation', id(test): 'test'}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Helper Functions \nHere are some helpful functions defined. Use the <span style=\"text-decoration:underline\">code</span> button to expand the code.\n* `calculate_score(truth, pred1, pred2=None, pred3=None)`: Calculate the score from the truths and the predictions. At least the first prediction is neccesary.\n* `prediction_to_submission(pred1, pred2=None, pred3=None)`: Creates the submission string from the predictions. Empty predictions will be automatically completed.\n* `submission_to_prediction(sub)`: Creates the output arrays from the submission string.\n* `image_padding(img, size=(MAX_SIZE, MAX_SIZE), pad_int=-1)`: padding the image to the given size with an new \"color\".\n* `plot_task(df, task_id)`: Plot the input and output pairs for a task in a DataFrame."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def calculate_score(truth, pred1, pred2=None, pred3=None):\n    \"\"\" Calculate Score for predictions\n        \n        Checks if truth value exists in one of the predictions\n        \n        param truth: List with truth output arrays\n        param pred1: List with array for 1. predictions\n        param pred2: List with array for 2. predictions\n        param pred3: List with array for 3. predictions\n        return score: Score of the model\n    \"\"\"\n    result = []\n    result.append([np.array_equal(truth[i], pred1[i]) for i in range(len(truth))])\n    if pred2 is not None:\n        result.append([np.array_equal(truth[i], pred2[i]) for i in range(len(truth))])\n    if pred3 is not None:\n        result.append([np.array_equal(truth[i], pred3[i]) for i in range(len(truth))])\n    result = np.vstack(result)\n    result = np.any(result, axis=0)\n    score = (len(result)-np.sum(result))/len(result)\n    print(f'Score: {np.round(score, 4)} (Found {np.sum(result)}/{len(result)})')\n    return score\n\ndef prediction_to_submission(pred1, pred2=None, pred3=None):\n    \"\"\" Creates the submission string from the three predictions.\n\n        param pred1: Array with 1. prediction (e.g. [[1]])\n        param pred2: Array with 2. prediction (default: None)\n        param pred3: Array with 3. prediction (default: None)\n        return result: String for submssion\n    \"\"\"   \n    def list_to_str(pred):\n        return '|'+'|'.join([''.join(map(str, r)) for r in pred])+'|'\n    \n    result = list_to_str(pred1)\n    if pred2 is not None:\n        result += ' '+list_to_str(pred2)\n    else:\n        result += ' '+list_to_str(DEFAULT_PREDICTION)\n    if pred3 is not None:\n        result += ' '+list_to_str(pred3)\n    else:\n        result += ' '+list_to_str(DEFAULT_PREDICTION)\n    return result\n\ndef submission_to_prediction(sub):\n    \"\"\" Creates the three predictions from the submission string\n\n        param sub: Submission String (e.g. '|0| |1| |2|')\n        return pred1: 1. prediction from submission string\n        return pred2: 2. prediction from submission string\n        return pred3: 3. prediction from submission string\n    \"\"\"  \n    pred = [np.array([list(map(int, list(s))) for s in sub.split()[i].split('|')[1:-1]]) for i in range(3)]\n    return pred[0], pred[1], pred[2]\n\ndef image_padding(img, size=(MAX_SIZE, MAX_SIZE), pad_int=-1):\n    \"\"\" Creates a padding around the image\n\n        param img: 2d array\n        param size: max width and height (default (30, 30))\n        param pad_int: integer used for the padding (default: -1)\n        return result: padded image\n    \"\"\" \n    top = int(np.ceil((size[0] - img.shape[0])/2))\n    bottom = int(np.floor((size[0] - img.shape[0])/2))\n    left = int(np.ceil((size[1] - img.shape[1])/2))\n    right = int(np.floor((size[1] - img.shape[1])/2))\n    return np.pad(img, ((top, bottom), (left, right)), constant_values=pad_int)\n\ndef remove_padding(img, pad_int=-1):\n    \"\"\" Removes padding from image, if all values in row or column are the pad value\n\n        param img: 2d array\n        param pad_int: integer used for the padding (default: -1)\n        return result: image\n    \"\"\" \n    row_pad = np.all(img == pad_int, axis=1)\n    img = img[~row_pad,:]\n    col_pad = np.all(img == pad_int, axis=0)\n    img = img[:,~col_pad]\n    return img\n\ndef plot_task(df, task_id):\n    \"\"\" Plot all inputs and outputs for the task\n\n        param df: DataFrame with the input, output and task_id\n        param task_id: id of the task to plot\n    \"\"\" \n    cmap = colors.ListedColormap(COLOR_MAP.values())\n    norm = colors.Normalize(vmin=-1, vmax=9)\n    \n    df_name = DF_NAME[id(df)]\n    df = df[df['task_id'] == task_id].sort_values('type', ascending=False).reset_index()\n    \n    fig, axs = plt.subplots(2, df.shape[0], figsize=(3*df.shape[0],6))\n    axs[0][0].text(0,-10, f'Task ID: {task_id} ({df_name})', fontsize=16)\n    for idx, row in df.iterrows():\n        input_img = row['input']\n        input_img = image_padding(input_img)\n        output_img = row['output']\n        if np.isnan(output_img).any():\n            output_img = np.array([[]])\n        output_img = image_padding(output_img)\n        task_type = row['type'].upper()\n        axs[0][idx].imshow(input_img, cmap=cmap, norm=norm)\n        #axs[0][idx].axis('off')\n        axs[0][idx].set_yticklabels([])\n        axs[0][idx].set_xticklabels([])\n        axs[0][idx].set_title(f'{task_type}\\nInput', color='green' if task_type == 'TRAIN' else 'blue', fontsize=16)\n        axs[1][idx].imshow(output_img, cmap=cmap, norm=norm)\n        #axs[1][idx].axis('off')\n        axs[1][idx].set_yticklabels([])\n        axs[1][idx].set_xticklabels([])\n        axs[1][idx].set_title('Output', color='green' if task_type == 'TRAIN' else 'blue', fontsize=16)\n\n    plt.tight_layout()\n    plt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# Prediction to Submission Example\npred = np.array([[1,0,1], [0,1,0], [1,0,1], [1,1,1]])\nprint(f'Original Prediciton:\\n{pred}')\npred_sub = prediction_to_submission(pred)\nprint(f'\\nPrediction to Submission:\\n{pred_sub}')\nsub_pred = submission_to_prediction(pred_sub)[0]\nprint(f'\\nSubmission to Prediction:\\n{sub_pred}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scoring Example\nfor df in [train, validation, test]:\n    print(f'DataFrame: {DF_NAME[id(df)]}')\n    score = calculate_score(df[df['type'] == 'test']['output'].values, [[[0]]]*df.shape[0], [[[1]]]*df.shape[0], [[[2]]]*df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Plot Example\nplot_task(train, train.loc[0, 'task_id'])\nplot_task(validation, validation.loc[0, 'task_id'])\nplot_task(test, test.loc[0, 'task_id'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Feature Extraction <a id=\"feature_extraction\"></a>  \nHere some features are extracted from the input and output arrays. This is mainly done on the training data. The features for the test data are then derived from the training data. e.g. all training data have *True* for a feature, so it is also used for the test data.  \nCurrently, the features are divided into three separate functions and some have to be tested in detail. This will be updated soon.\n\n\n* **increased_height:** Ratio between input and output height\n* **increased_width:** Ratio between input and output width  \n* **color_ratio_input:** Ratio of used colors for input\n* **color_ratio_output:** Ratio of used colors for output \n* **input_objects:** Extracted objects from input *(under development)*\n* **output_objects:** Extracted objects from output *(under development)*\n* **count_input_objects:** Number of extracted objects from input *(under development)*\n* **count_output_objects:** Number of extracted objects from output *(under development)*\n* **has_vertical_split:** Input array has an vertical line with unique color \n* **has_horizontal_split:** Input array has an horizontal line with unique color   \n* **input_in_output:** The input pattern exists in output \n* **output_in_input:** The output pattern is part of the input\n* **fill_out:** The input exists in output with additional values/colors\n* **fill_out_mask_color::** Expected color from input to fill out\n* **is_most_common_color:** Output used the most commen color from input\n* **unique_output_color:** Color of the output, if only one color is used\n* **same_input_size:** All training tasks have the same input size\n* **same_output_size:** All training tasks have the same output size  \n* **symetries:** Vertical, horizontal and diagonal\n* **color_change**: Same image with new colors\n\nUpcoming Features: \n* added lines: Lines have been added in output\n* line detection: Extract lines from image\n* noise detection: \n* rearranged: Check rearrangement of objects\n* adapted_size: Checks if input is grown or shrunken\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_features(row):\n    def increased_height():\n        \"\"\" Change between output and input height\n        \n            < 0: output is smaller\n            = 0: output has same height\n            > 0: output is higher\n        \"\"\"\n        if row['type'] == 'test':\n            return None\n        else:\n            return row['output'].shape[0] / row['input'].shape[0] - 1 \n    def increased_width():\n        \"\"\" Change between output and input width\n        \n            < 0: output is smaller\n            = 0: output has same width\n            > 0: output is larger\n        \"\"\"\n        if row['type'] == 'test':\n            return None\n        else:\n            return row['output'].shape[1] / row['input'].shape[1] - 1   \n    def color_ratio(frame):\n        \"\"\" Ratio of the colors\n\n            param frame: 2d array\n            return result: dictionary with ratio per color\n        \"\"\"\n        if np.isnan(frame).any():\n            return None\n        else:\n            result = {i:0.0 for i in range(NUM_COLORS)}\n            unique, counts = np.unique(frame, return_counts=True)\n            counts = counts / (frame.shape[0] * frame.shape[1])\n            result.update(dict(zip(unique, counts)))\n            return result\n    def get_objects(img):\n        \"\"\" Get objects from image\n            \n            -- under development --\n            ToDo: Parameter if all or only one color per object\n            ToDo: Check line img[start_y:end_y+1, start_x:end_x+1] = 0  # used to get only rectangles\n\n            param img: 2d array\n            return objects: dictionary with start and object array\n        \"\"\"\n        if np.isnan(img).any():\n            return None\n        else:\n            org = img.copy()\n            img = image_padding(img, (img.shape[0]+2, img.shape[1]+2), 0)\n            objects = []\n            while True:\n                start = np.where(img != 0)\n                if len(start[0]) == 0:\n                    break\n                start_x = start[1][0]\n                start_y = start[0][0]  \n                end_x = start_x\n                end_y = start_y\n                control = set([(start_y, start_x)])\n                while len(control) > 0:\n                    c = control.pop()\n                    act_y = c[0]\n                    act_x = c[1]\n                    if act_y > end_y:  end_y = act_y\n                    if start_y > act_y:  start_y = act_y\n                    if act_x > end_x:  end_x = act_x\n                    if start_x > act_x:  start_x = act_x\n                    img[act_y, act_x] = 0\n                    sub = img[act_y-1:act_y+2, act_x-1: act_x+2]\n                    for n in zip(np.where(sub)[0], np.where(sub)[1]):\n                        n = (n[0]-1+act_y, n[1]-1+act_x)\n                        img[n[0], n[1]] = 0\n                        control = control | set([n])\n                img[start_y:end_y+1, start_x:end_x+1] = 0\n                start_y -= 1; end_y -= 1; start_x -= 1; end_x -= 1\n                obj = org[start_y:end_y+1, start_x:end_x+1]\n                objects.append({'start': (start_y, start_x), 'obj':obj})\n            return objects\n        \n    def has_vertical_split(frame_in=row['input'], frame_out=row['output']):\n        \"\"\" Checks if the input has a vertical split line\n            and the output is part of this\n\n            param frame_in: 2d array to check the split (input)\n            param frame_out: 2d array to check if same size like split (output)\n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        if (np.isnan(frame_in).any()) | (np.isnan(frame_out).any()):\n            return False\n        else:\n            if frame_in.shape[1] % 2 == 0:\n                return False\n            mid = int(np.floor(frame_in.shape[1] / 2))\n            mid_color = np.unique(frame_in[:,mid])\n            if mid_color.shape[0] > 1:\n                return False\n            mid_color = mid_color[0]\n            if mid_color in np.delete(frame_in, mid, 1):\n                return False\n            if frame_out.shape[1] != mid:\n                return False\n            return True\n    def has_horizontal_split(frame_in=row['input'], frame_out=row['output']):\n        \"\"\" Checks if the input has a horizontal split line\n            and the output is part of this\n\n            param frame_in: 2d array to check the split (input)\n            param frame_out: 2d array to check if same size like split (output)\n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        if (np.isnan(frame_in).any()) | (np.isnan(frame_out).any()):\n            return False\n        else:\n            if frame_in.shape[0] % 2 == 0:\n                return False\n            mid = int(np.floor(frame_in.shape[0] / 2))\n            mid_color = np.unique(frame_in[mid,:])\n            if mid_color.shape[0] > 1:\n                return False\n            mid_color = mid_color[0]\n            if mid_color in np.delete(frame_in, mid, 0):\n                return False\n            if frame_out.shape[0] != mid:\n                return False\n            return True\n    def is_subset(frame, subframe):\n        \"\"\" Checks if subframe is part of frame\n\n            param frame: 2d array (full frame)\n            param subframe: 2d array (sub frame)\n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        if (np.isnan(frame).any()) | (np.isnan(subframe).any()):\n            return False\n        else:\n            if (subframe.shape[0] > frame.shape[0]) | (subframe.shape[1] > frame.shape[1]):\n                return False\n            for i in range(frame.shape[0]-subframe.shape[0]+1):\n                for j in range(frame.shape[1]-subframe.shape[1]+1):\n                    match = np.array_equal(subframe, frame[i:i+subframe.shape[0], j:j+subframe.shape[1]])\n                    if match:\n                        return match\n            return False\n    def color_change():\n        \"\"\" Checks if input and output use same cordinates\n        \n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        else:\n            frame1 = np.where(row['input'] > 0, 1, 0)\n            frame2 = np.where(row['output'] > 0, 1, 0)\n            return np.array_equal(frame1, frame2)\n    def adapted_size():\n        # ToDo: Check if other method is better\n        \"\"\" Checks if input is grown or shrunken\n        \n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        else:\n            adapted_input = np.resize(row['input'], row['output'].shape)\n            adapted_input = np.array_equal(adapted_input, row['output'])\n            return adapted_input\n\n\n    \n    result = {\n        'increased_height': increased_height(),\n        'increased_width': increased_width(),\n        #'adapted_size': adapted_size(),\n        'color_ratio_input': color_ratio(row['input']),\n        'color_ratio_output': color_ratio(row['output']),\n        'input_objects': get_objects(row['input']),\n        'output_objects': get_objects(row['output']),        \n        'color_change': color_change(),\n        'has_vertical_split': has_vertical_split(),\n        'has_horizontal_split': has_horizontal_split(),\n        'input_in_output': is_subset(row['output'], row['input']),\n        'output_in_input': is_subset(row['input'], row['output']),\n    }\n    return result\n\ndef get_features2(row):\n    def check_fill_out():\n        \"\"\" Check if output is input with additional values\n        \n            return result: Boolean\n        \"\"\"\n        if (row['increased_width'] == 0) & (row['increased_height'] == 0):\n            output = row['output'].copy()\n            blanks = np.where(row['input'] == 0, True, False)\n            output[blanks == True] = 0\n            return np.array_equal(row['input'], output)\n        else:\n            return False\n    def fill_out_mask_color():\n        \"\"\" Check if output is input with additional values\n        \n            return result: Boolean\n        \"\"\"\n        if (row['increased_width'] == 0) & (row['increased_height'] == 0):\n            diff = np.unique(row['input'][row['input'] != row['output']])\n            if len(diff) == 1:\n                return diff[0]\n            else:\n                return -1\n        else:\n            return -1\n    def is_most_common_color():\n        \"\"\" Check if the output color is the most common input color\n        \n            return result: Boolean\n        \"\"\"\n        if (row['increased_width'] == 0) & (row['increased_height'] == 0):\n            mc_color = np.argmax(list(row['color_ratio_input'].values()))\n            return np.sum(np.where(row['output'] == mc_color, 1, 0)) == row['output'].shape[0]*row['output'].shape[1]\n        else:\n            return False\n    def unique_output_color():\n        \"\"\" Get the color of the output if it is unique\n        \n            return result: Integer for color\n        \"\"\"\n        if row['color_ratio_output'] is None:\n            return -1\n        else:\n            max_color = np.argmax(list(row['color_ratio_output'].values())[1:])+1\n            if len(np.unique(list(row['color_ratio_output'].values())[1:])) > 2:\n                return 0\n            else:\n                return max_color\n    \n    result = {\n        'fill_out': check_fill_out(),\n        'fill_out_mask_color': fill_out_mask_color(),\n        'is_most_common_color': is_most_common_color(),\n        'unique_output_color': unique_output_color()\n    }\n    return result\n\ndef get_features3(row):\n    def left_diagonal_symmetric(frame):\n        \"\"\" Check diagonal symmetric of array (top left to bottom right)\n        \n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        else:\n            return np.array_equal(frame, frame.T)\n    def right_diagonal_symmetric(frame):\n        \"\"\" Check diagonal symmetric of array (top right to bottom left)\n        \n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        else:\n            return np.array_equal(frame, np.flip(frame).T)\n    def horizontal_symmetric(frame):\n        \"\"\" Check diagonal horizontal of array\n        \n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        else:\n            return np.array_equal(frame, np.flipud(frame))\n    def vertical_symmetric(frame):\n        \"\"\" Check diagonal vertical of array\n        \n            return result: Boolean\n        \"\"\"\n        if row['type'] == 'test':\n            return False\n        else:\n            return np.array_equal(frame, np.fliplr(frame))\n    \n    result = {\n        'input_left_diagonal_symmetric': left_diagonal_symmetric(row['input']),\n        'input_right_diagonal_symmetric': right_diagonal_symmetric(row['input']),\n        'input_horizontal_symmetric': horizontal_symmetric(row['input']),\n        'input_vertical_symmetric': vertical_symmetric(row['input']),\n        'output_left_diagonal_symmetric': left_diagonal_symmetric(row['output']),\n        'output_right_diagonal_symmetric': right_diagonal_symmetric(row['output']),\n        'output_horizontal_symmetric': horizontal_symmetric(row['output']),\n        'output_vertical_symmetric': vertical_symmetric(row['output']),\n    }\n    return result\n\ndef same_array_size(df, task_id, column='input'):\n    \"\"\" Checks if all training tasks have same input size\n\n        param df: DataFrame with the task id\n        param task_id: task_id\n        paramt column: Column with array (input/output)\n        return result: boolean\n    \"\"\"\n    result = df[(df['type'] != 'test') & (df['task_id'] == task_id)][column].apply(lambda x: np.array(x).shape).unique()\n    return True if len(result) == 1 else False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Features \nfor df in [train, validation, test]:\n    start_time = datetime.datetime.now()\n    # Features 1\n    features = pd.DataFrame(df.apply(lambda x: get_features(x), axis=1).to_list())\n    df[features.columns] = features\n    # Features 2\n    features = pd.DataFrame(df.apply(lambda x: get_features2(x), axis=1).to_list())\n    df[features.columns] = features\n    # Features 3\n    features = pd.DataFrame(df.apply(lambda x: get_features3(x), axis=1).to_list())\n    df[features.columns] = features\n    # Features 4\n    df['same_input_size'] = df['task_id'].apply(lambda x: same_array_size(df, x, 'input'))\n    df['same_output_size'] = df['task_id'].apply(lambda x: same_array_size(df, x, 'output'))\n    df['count_input_objects'] = df['input_objects'].apply(lambda x: x if x is None else len(x))\n    df['count_output_objects'] = df['output_objects'].apply(lambda x: x if x is None else len(x))        \n    end_time = datetime.datetime.now()\n    print(f'{DF_NAME[id(df)]}: {end_time-start_time}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here the test data is calculated depending on the column data type. For *boolean* or *integer* values, it is checked whether all training data are identical. For *float* values, the average is used."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill None values in test data based on training data\ndef get_train_average(df, task_id, column):\n    \"\"\" Get Average of training data for task and column\n    \n    \"\"\"\n    return df[(df['task_id'] == task_id) & (df['type'] != 'test')][column].mean()\n\ndef check_boolean(df, task_id, column):\n    \"\"\" Checks if all training data have True for task and column\n    \n    \"\"\"\n    return df[(df['task_id'] == task_id) & (df['type'] != 'test')][column].min()\n\ncolumn_types = train.columns.to_series().groupby(train.dtypes).groups\n    \nfor df in [train, validation, test]:\n    start_time = datetime.datetime.now()\n    df_tests = df[df['type'] == 'test']\n    for column in column_types[np.dtype('float64')]:\n        df.loc[df_tests.index, column] = df_tests['task_id'].apply(lambda x: get_train_average(df, x, column))\n    for column in column_types[np.dtype('int64')]:\n        df.loc[df_tests.index, column] = df_tests['task_id'].apply(lambda x: int(get_train_average(df, x, column)) if np.ceil(get_train_average(df, x, column)) == np.floor(get_train_average(df, x, column)) else -1)\n    for column in column_types[np.dtype('bool')]:\n        df.loc[df_tests.index, column] = df_tests['task_id'].apply(lambda x: check_boolean(df, x, column))\n    end_time = datetime.datetime.now()\n    print(f'{DF_NAME[id(df)]}: {end_time-start_time}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. EDA <a id=\"eda\"></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_heatmap(values, x_labels, y_labels, title=None, x_label=None, y_label=None, figsize=(8, 8)):\n    #values = np.round(values/np.sum(values), 4)*100\n    \n    fig, ax = plt.subplots(figsize=figsize)\n    im = ax.imshow(values, cmap='viridis')\n\n    ax.set_xticks(np.arange(len(x_labels)))\n    ax.set_yticks(np.arange(len(y_labels)))\n    ax.set_xticklabels(x_labels)\n    ax.set_yticklabels(y_labels)\n\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n    for i in range(len(y_labels)):\n        for j in range(len(x_labels)):\n            text = ax.text(j, i, None if values[i, j] == 0 else values[i, j] , ha=\"center\", va=\"center\", color=\"w\")\n    ax.set_title(title)\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(y_label)\n    fig.tight_layout()\n    plt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use only train dataset with training data for eda\ndf = train\ndf = df[df['type'] == 'train']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of the input and output shapes <a id=\"eda_1\"></a>\n* **1. Plot:** Input arrays\n* **2. Plot:** Output arrays"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for column in ['input', 'output']:\n    df['width'] = df[column].apply(lambda x: x.shape[1])\n    df['height'] = df[column].apply(lambda x: x.shape[0])\n    plt_data = df.groupby(['width', 'height'])['task_id'].count()\n    x_labels = range(1, df['width'].max()+1)\n    y_labels = range(1, df['height'].max()+1)\n    plt_data = np.array([[plt_data[(y, x)] if (y, x) in plt_data.index else 0 for x in x_labels] for y in y_labels ])\n    create_heatmap(plt_data, x_labels, y_labels, f'{column} Size', 'Width', 'Height')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Change of the array shape between input and output <a id=\"eda_2\"></a>\n* **bigger:** The output width or height has increased\n* **equal:** The output width or height is the same\n* **smaller:** The output width or height is decreased"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Input size\ndf['incr_width'] = df['increased_width'].apply(lambda x: 'bigger' if x > 0 else 'equal' if x == 0 else 'smaller')\ndf['incr_height'] = df['increased_height'].apply(lambda x: 'bigger' if x > 0 else 'equal' if x == 0 else 'smaller')\nplt_data = df.groupby(['incr_width', 'incr_height'])['task_id'].count()\nx_labels = ['bigger', 'equal', 'smaller']\ny_labels = ['bigger', 'equal', 'smaller']\nplt_data = np.array([[plt_data[(y, x)] if (y, x) in plt_data.index else 0 for x in x_labels] for y in y_labels ])\ncreate_heatmap(plt_data, x_labels, y_labels, None, 'Increased Height', 'Increased Width', figsize=(5, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Proportion of values that match the criteria <a id=\"eda_3\"></a>\n* **True per Task:** Every single task alone\n* **The group by Tasks:** Group by Task id and only True if all match"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt_data = pd.DataFrame(index=column_types[np.dtype('bool')])\nplt_data['True per Task'] = [len(df[df[column]]) for column in column_types[np.dtype('bool')]]\nplt_data['True group by Tasks'] = [len(df.groupby('task_id')[column].min()[df.groupby('task_id')[column].min()]) for column in column_types[np.dtype('bool')]]\nplt_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Average of the color ratio <a id=\"eda_4\"></a>\n* **1. Plot:** Input arrays\n* **2. Plot:** Output arrays"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for column in ['input', 'output']:\n    plt_data = pd.DataFrame(df[f'color_ratio_{column}'].to_list())\n    plt_data = plt_data.mean().rename(column)\n    plt_data.plot(kind='pie', autopct='%1.1f%%', figsize=(5, 5))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlations of the feature columns <a id=\"eda_5\"></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"columns = list(column_types[np.dtype('float64')])+list(column_types[np.dtype('int64')])+list(column_types[np.dtype('bool')])\nplt_data = df[columns].corr()\ncreate_heatmap(np.round(plt_data.values, 2), columns, columns, figsize=(12, 12))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Prediction <a id=\"prediction\"></a>  \nIn this section I will make some prediction based on rules and array transformations. It is therefore currently much more a solution to show how specific problems are solved by rules rather than by AI. But the procedure can still be helpful for later usage. Additionally it helps me to understand how the input can be transformed into the output and why this does not work with some rules.\n1. I add three new columns to the DataFrames with a default prediction ([[0]]).\n2. Depending on the rules I want to use, I make a preselection of the tasks, who match some criteria (e.g Task has same input and output shape).\n3. Use a list of transformation functions on the input and check, if it is equal to the output.\n4. If there is a match with all training pairs for a task, then use the transformation on the test input.\n5. Check which prediction column is empty and use this for the new prediction (e.g. If there is already a value in prediction_1, the next empty column will be used, instead of overwrite the current value).\n6. Calculate the score for the predictions.\n\nBecause I don't train a model it doesn't really matter if I use the train or validation dataset. But the advantage is that I only make a prediction for the test input, if it was correct for all training pairs. This reduces the unnecessary use of the three prediction columns. In addition, the method for the next free prediction column is helpful to avoid overwriting predictions that have already been made."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get Output for test dataset from validation dataset\n# Use this only to evaluate the public test dataset\ntest_idx = test[test['type']=='test'].index\ntest.loc[test_idx, 'output'] = test.loc[test_idx, 'submission_id'].apply(lambda x: validation[validation['submission_id'] == x]['output'].values[0] if x in validation['submission_id'].values else None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_prediction_column(df, idx):\n    \"\"\" Get the column name of an unused prediction for the row\n\n        param df: DataFrame\n        param idx: Index of the row\n        return next_prediction: Column name ('prediction_1', 'prediction_2', 'prediction_3')\n    \"\"\"\n    next_prediction = 'prediction_3'\n    for idx, val in df.loc[idx, ['prediction_1', 'prediction_2', 'prediction_3']].iteritems():\n        if np.array_equal(val, DEFAULT_PREDICTION) or val is None:\n            next_prediction = idx\n            break\n    return next_prediction\n\n# Set all Predictions to default [[0]]\nfor df in [train, validation, test]:\n    df['prediction_1'] = [DEFAULT_PREDICTION] * df.shape[0]\n    df['prediction_2'] = [DEFAULT_PREDICTION] * df.shape[0]\n    df['prediction_3'] = [DEFAULT_PREDICTION] * df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rotations and Flips <a id=\"prediction_1\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def check_startpoint(frame_in, frame_out, startpoint):\n    \"\"\" Check if frame exists in corner of seconde frame\n\n        param frame_in: Array Pattern\n        param frame_out: Array to check the corners\n        param startpoint: Corner\n        return boolean: True if match exists\n    \"\"\"\n    if startpoint == 'top_left':\n        return np.array_equal(frame_in, frame_out[:frame_in.shape[0],:frame_in.shape[1]])\n    elif startpoint == 'top_right':\n        return np.array_equal(frame_in, frame_out[:frame_in.shape[0],-frame_in.shape[1]:])\n    elif startpoint == 'bottom_left':\n        return np.array_equal(frame_in, frame_out[-frame_in.shape[0]:,:frame_in.shape[1]])\n    elif startpoint == 'bottom_right':\n        return np.array_equal(frame_in, frame_out[-frame_in.shape[0]:,-frame_in.shape[1]:])\n    else:\n        return False\n    \ndef rotations(frame, horizontal, vertical, start, hmethod='repeat', vmethod='repeat'):\n    \"\"\" Use diffrent rotations and flips on array\n\n        param frame: 2d Array\n        param horizontal: number of horizontal rotations\n        param vertical: number of vertical rotations\n        param start: Startpoint (e.g. top_left)\n        param hmethod: used method for horizontal\n        param vmethod: used method for vertical\n        return result: Transformed 2d Array\n    \"\"\"\n    result = frame\n    tmp = frame   \n    for f in range(int(horizontal)):\n        if hmethod == 'repeat':\n            tmp = tmp\n        elif hmethod == 'flip':\n            tmp = np.flip(tmp)\n        elif hmethod == 'fliplr':\n            tmp = np.fliplr(tmp)\n        elif hmethod == 'flipud':\n            tmp = np.flipud(tmp)\n        elif hmethod == 'rot90_3' and frame.shape[0] == frame.shape[1]:\n            tmp = np.rot90(tmp, 3)\n        elif hmethod == 'rot90_1' and frame.shape[0] == frame.shape[1]:\n            tmp = np.rot90(tmp, 1)\n        else:\n            tmp = tmp\n        if 'left' in start:\n            result = np.append(result, tmp, axis=1)\n        elif 'right' in start:\n            result = np.append(tmp, result, axis=1)\n    tmp = result\n    for f in range(int(vertical)):\n        if vmethod == 'repeat':\n            tmp = tmp\n        elif vmethod == 'flip':\n            tmp = np.flip(tmp)\n        elif vmethod == 'flipud':\n            tmp = np.flipud(tmp)\n        elif vmethod == 'fliplr':\n            tmp = np.fliplr(tmp)\n        elif vmethod == 'rot90_2':\n            tmp = np.rot90(tmp, 2)\n        elif vmethod == 'test' and frame.shape[0] == frame.shape[1]:\n            tmp = np.rot90(frame, 2)\n            tmp = np.append(tmp, np.rot90(frame, 3), axis=1)\n        else:\n            tmp = tmp\n        if 'top' in start:\n            result = np.append(result, tmp, axis=0)\n        elif 'bottom' in start:\n            result = np.append(tmp, result, axis=0)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"if True:\n    for df in [train, validation, test]:\n        tasks = df[(df['type'] == 'test') & (df['input_in_output']) & (np.floor(df['increased_height']) == np.ceil(df['increased_height'])) & (np.floor(df['increased_width']) == np.ceil(df['increased_width']))]['task_id'].unique()\n        df_test = df[(df['type'] == 'test') & (df['task_id'].isin(tasks))].copy()\n        for task in tasks:\n            df_temp = df[(df['type'] != 'test') & (df['task_id'] == task)].copy()\n            df_temp['top_left'] = df_temp.apply(lambda x: check_startpoint(x['input'], x['output'], 'top_left'), axis=1)\n            df_temp['top_right'] = df_temp.apply(lambda x: check_startpoint(x['input'], x['output'], 'top_right'), axis=1)\n            df_temp['bottom_left'] = df_temp.apply(lambda x: check_startpoint(x['input'], x['output'], 'bottom_left'), axis=1)\n            df_temp['bottom_right'] = df_temp.apply(lambda x: check_startpoint(x['input'], x['output'], 'bottom_right'), axis=1)\n            starts = df_temp[['top_left', 'top_right', 'bottom_left', 'bottom_right']].min()\n            starts = list(starts[starts].index)\n            if len(starts) == 0:\n                df_test = df_test[df_test['task_id'] != task]\n                continue\n            found = None\n            for start in starts:\n                for hmethod in ['repeat', 'flip', 'fliplr', 'flipud', 'rot90_3', 'rot90_1']:\n                        for vmethod in ['repeat', 'flip', 'fliplr', 'flipud', 'rot90_2', 'test']:\n                            df_temp[f'pred_{start}'] = df_temp.apply(lambda x: rotations(x['input'], x['increased_width'], x['increased_height'], start, hmethod, vmethod), axis=1)\n                            df_temp[f'pred_{start}'] = df_temp.apply(lambda x: np.array_equal(x[f'pred_{start}'], x['output']), axis=1)\n                            if df_temp[f'pred_{start}'].min():\n                                found = True\n                                break\n                        if found:\n                            break\n                if found:\n                    for idx, row in df_test[df_test['task_id'] == task].iterrows():\n                        prediction = rotations(row['input'], row['increased_width'], row['increased_height'], start, hmethod, vmethod)\n                        df_test.loc[idx, get_prediction_column(df_test, idx)] = [prediction]\n                    break\n            #if not found:\n            #    plot_task(df, task)\n\n        print(f'\\nDataFrame: {DF_NAME[id(df)]}')\n        score = calculate_score(df_test['output'].values, df_test['prediction_1'].values, df_test['prediction_2'].values, df_test['prediction_3'].values)\n        df.loc[df_test.index, ['prediction_1', 'prediction_2', 'prediction_3']] = df_test[['prediction_1', 'prediction_2', 'prediction_3']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vertical or Horizontal Splits <a id=\"prediction_2\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def split_frame(frame, split='vertical'):\n    \"\"\" Splits one frame to two subframes\n        \n        param frame: 2d array\n        param split: vertical/horizontal\n        return frame1: 1. frame of split (left or upper)\n        return frame2: 2. frame of split (right or below)\n    \"\"\"\n    if split=='vertical':\n        mid = int(np.floor(frame.shape[1]/2))\n        frame1 = frame[:,:mid]\n        frame2 = frame[:,mid+1:]\n    else:\n        mid = int(np.floor(frame.shape[0]/2))\n        frame1 = frame[:mid,:]\n        frame2 = frame[mid+1:,:]\n    return frame1, frame2\n\ndef splitting(frame, split='vertical', aggmethod='min', flip_frame1=None, flip_frame2=None, color=None):\n    \"\"\" Use diffrent rotations and aggregation methods on splitted arrays\n\n        param frame: 2d Array with split\n        param split: kind of split (horizontal, vertical)\n        param aggmethod: Method to merge the two splitted arrays\n        param flip_frame1: Method for rotations on first frame\n        param flip_frame2: Method for rotations on second frame\n        param color: Use unique color for output\n        return result: Transformed 2d Array\n    \"\"\"\n    frame1, frame2 = split_frame(frame, split)\n    if flip_frame1 == 'flip':\n        frame1 = np.flip(frame1)\n    elif flip_frame1 == 'fliplr':\n        frame1 = np.fliplr(frame1)\n    elif flip_frame1 == 'flipud':\n        frame1 = np.flipud(frame1)\n        \n    if flip_frame2 == 'flip':\n        frame2 = np.flip(frame2)\n    elif flip_frame2 == 'fliplr':\n        frame2 = np.fliplr(frame2)\n    elif flip_frame2 == 'flipud':\n        frame2 = np.flipud(frame2)\n    \n    if aggmethod == 'min':\n        result = np.min(np.dstack((frame1, frame2)), axis=2)\n    elif aggmethod == 'max':\n        result = np.max(np.dstack((frame1, frame2)), axis=2)\n    elif aggmethod == 'none_match':\n        result = frame1 + frame2\n        result = np.where(result > np.max(np.append(frame1, frame2)), 0, result)\n    elif aggmethod == 'merge_2_in_1':\n        result = frame1 + frame2\n        if np.max(result) > np.max(np.append(frame1, frame2)):\n            result = frame1\n    elif aggmethod == 'merge_1_in_2':\n        result = frame1 + frame2\n        if np.max(result) > np.max(np.append(frame1, frame2)):\n            result = frame2\n    elif aggmethod == 'blanks':\n        result = np.max(np.dstack((frame1, frame2)), axis=2)\n        result = np.where(result == 0, 1, 0)\n    if color:\n        result[result > 0] = color\n    return result","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"if True:\n    for df in [train, validation, test]:\n        tasks = df[(df['type'] == 'test') & ((df['has_vertical_split']) | (df['has_horizontal_split']))]['task_id'].unique()\n        df_test = df[(df['type'] == 'test') & (df['task_id'].isin(tasks))].copy()\n        for task in tasks:\n            df_temp = df[(df['type'] != 'test') & (df['task_id'] == task)].copy()\n            if df_temp['unique_output_color'].min() == df_temp['unique_output_color'].max():\n                output_color = df_temp['unique_output_color'].values[0]\n                if output_color <= 0:\n                    output_color = None\n            else:\n                output_color = None\n            found = None\n            for aggmethod in ['min', 'max', 'blanks', 'none_match', 'merge_2_in_1', 'merge_1_in_2']:\n                for flip_frame1 in [None, 'flip', 'fliplr', 'flipud']:\n                    for flip_frame2 in [None, 'flip', 'fliplr', 'flipud']:\n\n                        if output_color:\n                            df_temp['pred'] = df_temp.apply(lambda x: splitting(x['input'], 'vertical' if x['has_vertical_split'] else 'horizontal', aggmethod, flip_frame1, flip_frame2, output_color), axis=1)\n                        else:\n                            df_temp['pred'] = df_temp.apply(lambda x: splitting(x['input'], 'vertical' if x['has_vertical_split'] else 'horizontal', aggmethod, flip_frame1, flip_frame2), axis=1)\n\n                        df_temp['pred'] = df_temp.apply(lambda x: np.array_equal(x['pred'], x['output']), axis=1)\n                        if df_temp[f'pred'].min():\n                            found = True\n                            break\n                    if found:\n                        break\n                if found:\n                    break\n\n            if found:\n                for idx, row in df_test[df_test['task_id'] == task].iterrows():\n                    if output_color:\n                        prediction = splitting(row['input'], 'vertical' if row['has_vertical_split'] else 'horizontal', aggmethod, flip_frame1, flip_frame2, output_color)\n                    else:\n                        prediction = splitting(row['input'], 'vertical' if row['has_vertical_split'] else 'horizontal', aggmethod, flip_frame1, flip_frame2)\n                    df_test.loc[idx, get_prediction_column(df_test, idx)] = [prediction]\n            #if not found:\n            #    plot_task(df, task)\n\n        print(f'\\nDataFrame: {DF_NAME[id(df)]}')\n        score = calculate_score(df_test['output'].values, df_test['prediction_1'].values, df_test['prediction_2'].values, df_test['prediction_3'].values)\n        df.loc[df_test.index, ['prediction_1', 'prediction_2', 'prediction_3']] = df_test[['prediction_1', 'prediction_2', 'prediction_3']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fill out through symmetries <a id=\"prediction_3\"></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def fill_out(frame, method, mask_color=0):\n    \"\"\" fill out missing values with a mirrored version of itself \n        \n        param frame: 2d array\n        param method: used symmetry\n        return frame: filled image\n    \"\"\"\n    mask = np.where(frame == mask_color)\n    if method == 'output_left_diagonal_symmetric':\n        transpose = frame.T\n    elif method == 'output_right_diagonal_symmetric':\n        transpose = np.flip(frame).T\n    elif method == 'output_horizontal_symmetric':\n        transpose = np.flipud(frame)\n    elif method == 'output_vertical_symmetric':\n        transpose = np.fliplr(frame)\n    for i in range(len(mask[0])):\n        frame[mask[0][i], mask[1][i]] = transpose[mask[0][i], mask[1][i]]\n    return frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"if True:\n    for df in [train, validation, test]:\n        tasks = df[df['type'] == 'test'][df['fill_out_mask_color'] >= 0][(df['output_left_diagonal_symmetric']) | (df['output_right_diagonal_symmetric']) | (df['output_horizontal_symmetric']) | (df['output_vertical_symmetric'])]['task_id'].unique()\n        df_test = df[(df['type'] == 'test') & (df['task_id'].isin(tasks))].copy()\n        for task in tasks:\n            found = None\n            df_temp = df[(df['type'] != 'test') & (df['task_id'] == task)].copy()\n            df_temp['pred_output'] = df_temp['input']\n            methods = df_temp[['output_left_diagonal_symmetric', 'output_right_diagonal_symmetric', 'output_horizontal_symmetric', 'output_vertical_symmetric']].min()\n            methods = list(methods[methods].index)\n            for method in methods*2:\n                df_temp['pred_output'] = df_temp.apply(lambda x: fill_out(x['pred_output'], method, x['fill_out_mask_color']), axis=1)\n                df_temp['pred'] = df_temp.apply(lambda x: np.array_equal(x['pred_output'], x['output']), axis=1)\n                if df_temp[f'pred'].min():\n                    found = True\n                    break\n                    \n            # makes prediction independent from training data... \n            # correct way: if found: \n            if True:\n                for idx, row in df_test[df_test['task_id'] == task].iterrows():\n                    prediction = row['input'].copy()\n                    for method in methods*2:\n                        prediction = fill_out(prediction, method, row['fill_out_mask_color'])\n                    df_test.loc[idx, get_prediction_column(df_test, idx)] = [prediction]        \n            #if not found:\n            #    plot_task(df, task)\n\n        print(f'\\nDataFrame: {DF_NAME[id(df)]}')\n        score = calculate_score(df_test['output'].values, df_test['prediction_1'].values, df_test['prediction_2'].values, df_test['prediction_3'].values)\n        df.loc[df_test.index, ['prediction_1', 'prediction_2', 'prediction_3']] = df_test[['prediction_1', 'prediction_2', 'prediction_3']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Growing Input <a id=\"prediction_4\"></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def grow_array(frame, growing_shape):\n    \"\"\" Grow array according to the shape (height and width)\n        \n        param frame: 2d array\n        param growing_shape: shape (height and width)\n        return frame: grown array\n    \"\"\"\n    frame = np.vstack([np.hstack([np.tile(frame[r, c], growing_shape) for c in range(frame.shape[1])]) for r in range(frame.shape[0])])\n    return frame\n\nif True:\n    for df in [train, validation, test]:\n        tasks = df[(df['type'] == 'test')\n               & (df['increased_height'].apply(np.floor) == df['increased_height'].apply(np.ceil)) \n               & (df['increased_width'].apply(np.floor) == df['increased_width'].apply(np.ceil)) \n               & (df['increased_height'] == df['increased_width']) \n               & (df['increased_height'] > 0) & (df['increased_width'] > 0)]['task_id'].unique()\n        df_test = df[(df['type'] == 'test') & (df['task_id'].isin(tasks))].copy()\n        for task in tasks:\n            df_temp = df[(df['type'] != 'test') & (df['task_id'] == task)].copy()\n            df_temp['pred_output'] = df_temp['input']\n\n            df_temp['pred'] = df_temp.apply(lambda x: grow_array(x['input'], (int(x['increased_height'])+1, int(x['increased_width'])+1)), axis=1)\n            df_temp['pred'] = df_temp.apply(lambda x: np.array_equal(x['pred'], x['output']), axis=1)\n            if df_temp[f'pred'].min():\n                for idx, row in df_test[df_test['task_id'] == task].iterrows():\n                    prediction = grow_array(row['input'], (int(row['increased_height'])+1, int(row['increased_width'])+1))\n                    df_test.loc[idx, get_prediction_column(df_test, idx)] = [prediction]\n            #else:\n            #    plot_task(df, task)\n                \n        print(f'\\nDataFrame: {DF_NAME[id(df)]}')\n        score = calculate_score(df_test['output'].values, df_test['prediction_1'].values, df_test['prediction_2'].values, df_test['prediction_3'].values)\n        df.loc[df_test.index, ['prediction_1', 'prediction_2', 'prediction_3']] = df_test[['prediction_1', 'prediction_2', 'prediction_3']]                ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Color changes <a id=\"prediction_5\"></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_color_mapping(frame_in, frame_out, color_mapping=None):\n    \"\"\" Get Dictionary with color change\n        \n        param frame_in: 2d array Input\n        param frame_out: 2d array Output with new colors\n        param color_mapping: existing start mapping\n        return color_mapping: Dictionary with color change {old_color: new_color}\n    \"\"\"\n    if color_mapping == False:\n        return False\n    if color_mapping is None:\n        color_mapping = dict(zip(range(NUM_COLORS), range(NUM_COLORS)))\n    for key in color_mapping.keys():\n        val = color_mapping[key]\n        new_color = frame_out[np.where(frame_in == key)]\n        new_color = np.unique(new_color)   \n        if len(new_color) > 1:\n            return False\n        elif len(new_color) == 1:\n            new_color = new_color[0]\n            if key == val:\n                color_mapping[key] = new_color\n            elif val != new_color:\n                return False\n    return color_mapping\n\ndef change_colors(frame, color_mapping):\n    \"\"\" Changes the colors according to the mapping\n        \n        param frame: 2d array Input\n        param color_mapping: Dictionary with color mapping {old_color: new_color}\n        return result: recolored frame\n    \"\"\"\n    result = frame.copy()\n    for key in color_mapping.keys():\n        val = color_mapping[key]\n        result[np.where(frame == key)] = val\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"if True:\n    for df in [train, validation, test]:\n        tasks = df[(df['type'] == 'test') & (df['color_change'])]['task_id'].unique()\n        df_test = df[(df['type'] == 'test') & (df['task_id'].isin(tasks))].copy()\n        for task in tasks:\n            color_mapping = dict(zip(range(NUM_COLORS), range(NUM_COLORS)))\n            df_temp = df[(df['type'] != 'test') & (df['task_id'] == task)].copy()\n            df_temp['pred'] = df_temp.apply(lambda x: get_color_mapping(x['input'], x['output']), axis=1)\n            for pred_color_mapping in df_temp['pred'].to_list():\n                if pred_color_mapping == False:\n                    color_mapping = False\n                    break\n                for key in color_mapping.keys():\n                    val = color_mapping[key]\n                    new_color = pred_color_mapping[key]\n                    if key == val and key != new_color:\n                        color_mapping[key] = new_color\n                    elif val != new_color and key != new_color:\n                        color_mapping = False\n                        break\n                if color_mapping == False:\n                    break\n            if color_mapping == False:\n                continue \n            df_temp['pred'] = df_temp['input'].apply(lambda x: change_colors(x, color_mapping))\n            df_temp['pred'] = df_temp.apply(lambda x: np.array_equal(x['pred'], x['output']), axis=1)\n            if df_temp[f'pred'].min():\n                for idx, row in df_test[df_test['task_id'] == task].iterrows():\n                    prediction = change_colors(row['input'], color_mapping)\n                    df_test.loc[idx, get_prediction_column(df_test, idx)] = [prediction]\n                    \n        print(f'\\nDataFrame: {DF_NAME[id(df)]}')\n        score = calculate_score(df_test['output'].values, df_test['prediction_1'].values, df_test['prediction_2'].values, df_test['prediction_3'].values)\n        df.loc[df_test.index, ['prediction_1', 'prediction_2', 'prediction_3']] = df_test[['prediction_1', 'prediction_2', 'prediction_3']] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Objects <a id=\"prediction_6\"></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def object_detection(objects, method):\n    \"\"\" Check extracted input objects\n        \n        param objects: extracted objects from input\n        param method: used method to filter objects\n        return result: object\n    \"\"\"\n    objects = [v['obj'] for v in objects]\n    if method == 'most_common_obj':\n        str_objects = [str(obj.reshape(-1,)) for obj in objects]\n        uobj, ucount = np.unique(str_objects, return_counts=True)\n        str_obj = uobj[np.argmax(ucount)]\n        result = objects[str_objects.index(str_obj)]\n    elif method == 'rarest_obj':\n        str_objects = [str(obj.reshape(-1,)) for obj in objects]\n        uobj, ucount = np.unique(str_objects, return_counts=True)\n        str_obj = uobj[np.argmin(ucount)]\n        result = objects[str_objects.index(str_obj)]\n    elif method == 'rarest_color':\n        colors = [x for o in objects for x in np.unique(o) if x != 0]\n        ucol, ucount = np.unique(colors, return_counts=True)\n        if len(colors) == len(objects) and len(np.where(ucount == 1)) == 1 and len(np.where(ucount == 1)[0]) != 0:\n            result = objects[colors.index(ucol[np.where(ucount == 1)][0])]\n        else:\n            result = objects[0]\n    elif method == 'smallest':\n        sizes = [x.shape[0]*x.shape[1] for x in objects]\n        result = objects[np.argmin(sizes)]\n    elif method == 'biggest':\n        sizes = [x.shape[0]*x.shape[1] for x in objects]\n        result = objects[np.argmax(sizes)]\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"if True:\n    for df in [train, validation, test]:\n        tasks = df[(df['type'] == 'test') & (df['output_in_input'])]['task_id'].unique()\n        df_test = df[(df['type'] == 'test') & (df['task_id'].isin(tasks))].copy()\n        for task in tasks:\n            df_temp = df[(df['type'] != 'test') & (df['task_id'] == task)].copy()\n            found = None\n            for method in ['most_common_obj', 'rarest_obj', 'rarest_color', 'smallest', 'biggest']:\n                df_temp['pred'] = df_temp.apply(lambda x: object_detection(x['input_objects'], method), axis=1)\n\n                df_temp['pred'] = df_temp.apply(lambda x: np.array_equal(x['pred'], x['output']), axis=1)\n                if df_temp[f'pred'].min():\n                    found = True\n                    break\n            if found:\n                for idx, row in df_test[df_test['task_id'] == task].iterrows():\n                    prediction = object_detection(row['input_objects'], method)\n                    df_test.loc[idx, get_prediction_column(df_test, idx)] = [prediction]  \n            #if not found:\n            #    plot_task(df, task)     \n  \n        print(f'\\nDataFrame: {DF_NAME[id(df)]}')\n        score = calculate_score(df_test['output'].values, df_test['prediction_1'].values, df_test['prediction_2'].values, df_test['prediction_3'].values)\n        df.loc[df_test.index, ['prediction_1', 'prediction_2', 'prediction_3']] = df_test[['prediction_1', 'prediction_2', 'prediction_3']] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Score <a id=\"final_score\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for df in [train, validation, test]:\n    print(f'DataFrame: {DF_NAME[id(df)]}')\n    df['match'] = df.apply(lambda x: np.array_equal(x['output'], x['prediction_1']) | np.array_equal(x['output'], x['prediction_2']) | np.array_equal(x['output'], x['prediction_3']), axis=1)\n    df = df[df['type'] == 'test']\n    score = calculate_score(df['output'].values, df['prediction_1'].values, df['prediction_2'].values, df['prediction_3'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Submission <a id=\"submission\"></a>\nFor the submission file I use the example_submission and get the required prediction string by 'apply' function. With this I want to prevent that something is not assigned correctly by a different order when loading the JSON files."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = test[test['type'] == 'test'].copy()\ndf['submission'] = df.apply(lambda x: prediction_to_submission(x['prediction_1'], x['prediction_2'], x['prediction_3']), axis=1)\ndf = df.set_index('submission_id')['submission']\nid_check = len(set(submission['output_id']) & set(df.index))\nprint(f'{df.shape[0]} Test ids \\n{submission.shape[0]} Submssion ids \\n{id_check} Intersection')\n\nsubmission['output'] = submission['output_id'].apply(lambda x: df[x] if x in df.index else DEFAULT_SUBMISSION)\nsubmission.to_csv('submission.csv', index=False)\nsubmission[submission['output'] != DEFAULT_SUBMISSION]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}