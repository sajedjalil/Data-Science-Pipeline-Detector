{"cells":[{"metadata":{},"cell_type":"markdown","source":"### The kernel is ensemble of approaches form public lederboard and object detection based DSL\n\nCredit: https://www.kaggle.com/adityaork/decision-tree-smart-data-augmentation","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nimport pdb\n\nimport pandas as pd\nimport math\nimport sys\nimport cv2\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\nimport random\n\nfrom collections import defaultdict\nfrom itertools import product\nfrom itertools import combinations,permutations\nfrom math import floor\n\nimport copy\n\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\n\ndef plot_result(test_input, test_prediction,\n                input_shape):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 2, figsize=(15,15))\n    test_input = test_input.reshape(input_shape[0],input_shape[1])\n    axs[0].imshow(test_input, cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Actual Target')\n    test_prediction = test_prediction.reshape(input_shape[0],input_shape[1])\n    axs[1].imshow(test_prediction, cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Model Prediction')\n    plt.tight_layout()\n    plt.show()\n    \ndef plot_test(test_prediction, task_name):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 1, figsize=(15,15))\n    axs.imshow(test_prediction, cmap=cmap, norm=norm)\n    axs.axis('off')\n    axs.set_title(f'Test Prediction {task_name}')\n    plt.tight_layout()\n    plt.show()\n    \n# https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook\ndef flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\nsample_sub1 = pd.read_csv(data_path/'sample_submission.csv')\nsample_sub1 = sample_sub1.set_index('output_id')\nsample_sub1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom itertools import product\nfrom itertools import combinations,permutations\nfrom math import floor\n\n\ndef get_moore_neighbours(color, cur_row, cur_col, nrows, ncols):\n\n    if cur_row<=0: top = -1\n    else: top = color[cur_row-1][cur_col]\n        \n    if cur_row>=nrows-1: bottom = -1\n    else: bottom = color[cur_row+1][cur_col]\n        \n    if cur_col<=0: left = -1\n    else: left = color[cur_row][cur_col-1]\n        \n    if cur_col>=ncols-1: right = -1\n    else: right = color[cur_row][cur_col+1]\n        \n    return top, bottom, left, right\n\ndef get_tl_tr(color, cur_row, cur_col, nrows, ncols):\n        \n    if cur_row==0:\n        top_left = -1\n        top_right = -1\n    else:\n        if cur_col==0: top_left=-1\n        else: top_left = color[cur_row-1][cur_col-1]\n        if cur_col==ncols-1: top_right=-1\n        else: top_right = color[cur_row-1][cur_col+1]   \n        \n    return top_left, top_right\n\nfrom itertools import product\ndef getAround(i,j,inp,size=1):\n    #v = [-1,-1,-1,-1,-1,-1,-1,-1,-1]\n    r,c = len(inp),len(inp[0])\n    v = []\n    sc = [0]\n    for q in range(size):\n        sc.append(q+1)\n        sc.append(-(q+1))\n    for idx,(x,y) in enumerate(product(sc,sc)):\n        ii = (i+x)\n        jj = (j+y)\n        v.append(-1)\n        if((0<= ii < r) and (0<= jj < c)):\n            v[idx] = (inp[ii][jj])\n    return v\n\ndef make_features(input_color, size):\n    nrows, ncols = input_color.shape\n    feat = []\n    cur_idx = 0\n    for i in range(nrows):\n        for j in range(ncols):\n            feat.append([])\n            feat[cur_idx].append(i+1)\n            feat[cur_idx].append(j+1)\n            feat[cur_idx].append(input_color[i][j])\n            \n            feat[cur_idx].append(input_color[i][j] in input_color[i,j+1:])\n            feat[cur_idx].append(input_color[i][j] in input_color[i,:j])\n            feat[cur_idx].append(input_color[i][j] in input_color[i+1:,:])\n            feat[cur_idx].append(input_color[i][j] in input_color[:i,:])\n            \n            feat[cur_idx].append(len(np.unique(input_color[i,:])))\n            feat[cur_idx].append(len(np.unique(input_color[:,j])))\n            feat[cur_idx].append((i+j))\n            feat[cur_idx].append((i*j))\n            \n            for m in range(10):\n                feat[cur_idx].append(i%(m+1))\n                feat[cur_idx].append(j%(m+1))\n                \n            feat[cur_idx].append((i+1)/(j+1))\n            feat[cur_idx].append((j+1)/(i+1))\n            feat[cur_idx].append(nrows)\n            feat[cur_idx].append(ncols)\n            \n            around = getAround(i, j, input_color, size)\n            feat[cur_idx].extend(around)\n            feat[cur_idx].append(len(np.unique(around)))\n \n            cur_idx += 1\n        \n    return feat\n\ndef equal(a, b):\n    if a.shape != b.shape:\n        return False\n    if (a == b).all():\n        return True\n    return False\n\ndef getiorc(pair):\n    inp = pair[\"input\"]\n    return pair[\"input\"],pair[\"output\"],len(inp),len(inp[0])\n\ndef getBkgColor(task_json):\n    color_dict = defaultdict(int)\n    \n    for pair in task_json['train']:\n        inp,oup,r,c = getiorc(pair)\n        for i in range(r):\n            for j in range(c):\n                color_dict[inp[i][j]]+=1\n    color = -1\n    max_count = 0\n    for col,cnt in color_dict.items():\n        if(cnt > max_count):\n            color = col\n            max_count = cnt\n    return color\n\ndef get_num_colors(inp,oup,bl_cols):\n    r,c = len(inp),len(inp[0])\n    return \n\ndef replace(inp,uni,perm):\n    # uni = '234' perm = ['5','7','9']\n    #print(uni,perm)\n    r_map = { int(c):int(s) for c,s in zip(uni,perm)}\n    r,c = len(inp),len(inp[0])\n    rp = np.array(inp).tolist()\n    #print(rp)\n    for i in range(r):\n        for j in range(c):\n            if(rp[i][j] in r_map):\n                rp[i][j] = r_map[rp[i][j]]\n    return rp\n            \n    \ndef augment(inp,oup,bl_cols):\n    cols = \"0123456789\"\n    npr_map = [1,9,72,3024,15120,60480,181440,362880,362880]\n    uni = \"\".join([str(x) for x in np.unique(inp).tolist()])\n    for c in bl_cols:\n        cols=cols.replace(str(c),\"\")\n        uni=uni.replace(str(c),\"\")\n\n    exp_size = len(inp)*len(inp[0])*npr_map[len(uni)]\n    \n    mod = floor(exp_size/120000)\n    mod = 1 if mod==0 else mod\n    \n    #print(exp_size,mod,len(uni))\n    result = []\n    count = 0\n    for comb in combinations(cols,len(uni)):\n        for perm in permutations(comb):\n            count+=1\n            if(count % mod == 0):\n                result.append((replace(inp,uni,perm),replace(oup,uni,perm)))\n    return result\n\ndef get_bl_cols(task_json):\n    result = []\n    bkg_col = getBkgColor(task_json);\n    result.append(bkg_col)\n    # num_input,input_cnt,num_output,output_cnt\n    met_map = {}\n    for i in range(10):\n        met_map[i] = [0,0,0,0]\n        \n    total_ex = 0\n    for pair in task_json['train']:\n        inp,oup=pair[\"input\"],pair[\"output\"]\n        u,uc = np.unique(inp, return_counts=True)\n        inp_cnt_map = dict(zip(u,uc))\n        u,uc = np.unique(oup, return_counts=True)\n        oup_cnt_map = dict(zip(u,uc))\n        \n        for col,cnt in inp_cnt_map.items():\n            met_map[col][0] = met_map[col][0] + 1\n            met_map[col][1] = met_map[col][1] + cnt\n        for col,cnt in oup_cnt_map.items():\n            met_map[col][2] = met_map[col][2] + 1\n            met_map[col][3] = met_map[col][3] + cnt\n        total_ex+=1\n    \n    for col,met in met_map.items():\n        num_input,input_cnt,num_output,output_cnt = met\n        if(num_input == total_ex or num_output == total_ex):\n            result.append(col)\n        elif(num_input == 0 and num_output > 0):\n            result.append(col)\n    \n    result = np.unique(result).tolist()\n    if(len(result) == 10):\n        result.append(bkg_col)\n    return np.unique(result).tolist()\n\n\ndef get_flips(inp,oup):\n    result = []\n    n_inp = np.array(inp)\n    n_oup = np.array(oup)\n    result.append((np.fliplr(inp).tolist(),np.fliplr(oup).tolist()))\n    result.append((np.rot90(np.fliplr(inp),1).tolist(),np.rot90(np.fliplr(oup),1).tolist()))\n    result.append((np.rot90(np.fliplr(inp),2).tolist(),np.rot90(np.fliplr(oup),2).tolist()))\n    result.append((np.rot90(np.fliplr(inp),3).tolist(),np.rot90(np.fliplr(oup),3).tolist()))\n    result.append((np.flipud(inp).tolist(),np.flipud(oup).tolist()))\n    result.append((np.rot90(np.flipud(inp),1).tolist(),np.rot90(np.flipud(oup),1).tolist()))\n    result.append((np.rot90(np.flipud(inp),2).tolist(),np.rot90(np.flipud(oup),2).tolist()))\n    result.append((np.rot90(np.flipud(inp),3).tolist(),np.rot90(np.flipud(oup),3).tolist()))\n    result.append((np.fliplr(np.flipud(inp)).tolist(),np.fliplr(np.flipud(oup)).tolist()))\n    result.append((np.flipud(np.fliplr(inp)).tolist(),np.flipud(np.fliplr(oup)).tolist()))\n    return result\n\ndef get_array(x):\n    return np.array(copy.deepcopy(x))\n\ndef features(task, mode='train', name=None, size=1, bl_cols=None):\n    num_train_pairs = len(task[mode])\n    feat, target = [], []\n    \n    global local_neighb\n    for task_num in range(num_train_pairs):\n        flag = 0\n        inp = copy.deepcopy(task[mode][task_num]['input'])\n        out = copy.deepcopy(task[mode][task_num]['output'])\n\n        feat.extend(make_features(get_array(inp), size=size))\n        target.extend(get_array(out).reshape(-1,))\n        \n        flips = get_flips(inp, out)\n        for x, y in flips:\n            feat.extend(make_features(get_array(x), size))\n            target.extend(get_array(y).reshape(-1,))\n        \n        if bl_cols:\n            augs = augment(inp, out, bl_cols)\n            for x, y in augs:\n                feat.extend(make_features(get_array(x), size))\n                target.extend(get_array(y).reshape(-1,))\n            \n    return np.array(feat), np.array(target)\n\ndef check_in_oup_equal(task_json):\n    return all([ len(pair[\"input\"]) == len(pair[\"output\"]) and len(pair[\"input\"][0]) == len(pair[\"output\"][0])\n                for pair in task_json['train']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mode = 'eval'\nmode = 'test'\nif mode=='eval':\n    task_path = evaluation_path\nelif mode=='train':\n    task_path = training_path\nelif mode=='test':\n    task_path = test_path\n\nall_task_ids = sorted(os.listdir(task_path))\n\nlocal_neighb = 5\nvalid_scores = {}\n\nmodel_accuracies = {'ens': []}\npred_taskids = []\n\nfor task_id in all_task_ids:\n\n    task_file = str(task_path / task_id)\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n        \n    if not check_in_oup_equal(task):\n        print(\"Ignoring\", task_file)\n        continue\n    \n    bl_cols = get_bl_cols(task)\n    \n    feat1, target1 = features(task, name=task_file, size=1, bl_cols=bl_cols)\n    feat2, target2 = features(task, name=task_file, size=3, bl_cols=bl_cols)\n    feat3, target3 = features(task, name=task_file, size=5, bl_cols=bl_cols)\n\n    xgb1 =  XGBClassifier(n_estimators=100, n_jobs=-1)\n    xgb2 =  XGBClassifier(n_estimators=100, n_jobs=-1)\n    xgb3 =  XGBClassifier(n_estimators=100, n_jobs=-1)\n    \n    xgb1.fit(feat1, target1, verbose=-1)\n    xgb2.fit(feat2, target2, verbose=-1)\n    xgb3.fit(feat3, target3, verbose=-1)\n\n\n    \n    num_test_pairs = len(task['test'])\n    for task_num in range(num_test_pairs):\n        cur_idx = 0\n        input_color = np.array(task['test'][task_num]['input'])\n        nrows, ncols = len(input_color), len(\n            input_color[0])\n        feat1 = make_features(input_color, 1)\n        feat2 = make_features(input_color, 3)\n        feat3 = make_features(input_color, 5)\n\n        print('Made predictions for ', task_id[:-5])\n\n        preds1 = xgb1.predict(np.array(feat1)).reshape(nrows,ncols)\n        preds2 = xgb2.predict(np.array(feat2)).reshape(nrows,ncols)\n        preds3 = xgb3.predict(np.array(feat3)).reshape(nrows,ncols)\n#         preds1 = preds2\n#         preds3 = preds2\n        if (mode=='train') or (mode=='eval'):                \n            ens_acc = max((np.array(task['test'][task_num]['output'])==preds1).sum()/(nrows*ncols),\n                         (np.array(task['test'][task_num]['output'])==preds2).sum()/(nrows*ncols),\n                         (np.array(task['test'][task_num]['output'])==preds3).sum()/(nrows*ncols))\n\n            model_accuracies['ens'].append(ens_acc)\n\n            pred_taskids.append(f'{task_id[:-5]}_{task_num}')\n\n            print('ensemble accuracy',ens_acc)\n\n          \n        preds1 = preds1.astype(int).tolist()\n        preds2 = preds2.astype(int).tolist()\n        preds3 = preds3.astype(int).tolist()\n#         plot_test(preds1, task_id)\n#         plot_test(preds2, task_id)\n#         plot_test(preds3, task_id)\n        sample_sub1.loc[f'{task_id[:-5]}_{task_num}',\n                       'output'] = flattener(preds1) +' '+ flattener(preds2) +' '+ flattener(preds3) + ' '\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '/kaggle/input/abstraction-and-reasoning-challenge/'\nsubmission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'), index_col='output_id')\nsubmission.output = ''\nsubmission.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_json(name, type_='train'):\n    if type_ == 'train':\n        task_file = os.path.join(training_path, name)\n    elif type_ == 'test':\n        task_file = os.path.join(test_path, name)\n    else:\n        task_file = os.path.join(val_path, name)\n\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n\n    return task\n\ndef get_size(box):\n    return (len(box), len(box[0]))\n\ndef unique(x):\n    return list(set(x))\n\ndef nunique(x):\n    return len(list(set(x)))\n\ndef equal(a, b):\n    if a.shape != b.shape:\n        return False\n    if (a == b).all():\n        return True\n    return False\n\ndef compare_kernel(a, b):\n    if a.shape != b.shape:\n        return -1, -2\n    \n    if equal(a, b):\n        return 1, 101\n    \n    if equal(a[:, ::-1], b):\n        return 1, 106\n\n    if equal(a[::-1, :], b):\n        return 1, 107\n    \n    if equal(a.T, b):\n        return 1, 105\n    \n    if equal(a[::-1, ::-1], b):\n        return 1, 108\n    \n    if equal(np.rot90(a), b):\n        return 1, 102\n    \n    if equal(np.rot90(np.rot90(a)), b):\n        return 1, 103\n    \n    if equal(np.rot90(np.rot90(np.rot90(a))), b):\n        return 1, 104\n    \n    if len(np.unique(b)) == 1:\n        return 0, np.unique(b)[0]\n    \n    else:\n        return -1, -1\n    \n    \ndef perform_rotation(k, f):\n    if f == 101:\n        return k\n    if f == 102:\n        return np.rot90(k)\n    if f == 103:\n        return np.rot90(np.rot90(k))\n    if f == 104:\n        return np.rot90(np.rot90(np.rot90(k)))\n    if f == 105:\n        return k.T\n    if f == 106:\n        return k[:, ::-1]\n    if f == 107:\n        return k[::-1, :]\n    if f == 108:\n        return k[::-1, ::-1]\n\nfrom collections import Counter\ndef get_sq_expansion_ratio(task):\n    x = [(int(get_size(t['output'])[0] / get_size(t['input'])[0]), \\\n     int(get_size(t['output'])[1] / get_size(t['input'])[1])) for t in task['train']]\n    \n    num_test = len(task['test'])\n    \n    if nunique(x) == 1:\n        res = []\n        while len(res) < num_test:\n            res.append(unique(x)[0])\n        return True, res\n    else:\n#         for i, train in enumerate(task['train']):\n            \n            \n        return False, x\n    \ndef check_edge(t):\n    img1 = np.array(t[\"input\"], dtype='uint8')\n    img2 = np.array(t[\"output\"], dtype='uint8')\n    \n    img1 = cv2.resize(img1, (0, 0), fx=30, fy=30, interpolation = cv2.INTER_AREA)\n    img2 = cv2.resize(img2, (0, 0), fx=30, fy=30, interpolation = cv2.INTER_AREA)\n    \n    edge1 = cv2.Canny(img1, 0, 1)\n#     plt.imshow(edge1, cmap=cmap, norm=norm)\n#     plt.show()\n    \n    edge2 = cv2.Canny(img2, 0, 1)\n#     plt.imshow(edge2, cmap=cmap, norm=norm)\n#     plt.show()\n    \n    return (edge1 == edge2).all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener123(pred):\n    \n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(case, task, task_name):\n    prediction = []\n    test_id = int(task_name.split('_')[1])\n    \n    for i, train in enumerate(task['train']):\n        prediction.append(get_prediction(test_id, task, case, i))    \n    \n    prediction = list(set([flattener(pred) if (type(pred) == type([1, 2, 3])) else flattener(pred.astype('int').tolist()) for pred in prediction]))\n    \n    while len(prediction) < 3:\n        prediction.append(prediction[-1])\n    \n    if len(prediction) > 3:\n        prediction = prediction[:3]\n        \n    prediction = ' '.join(prediction)\n#     prediction = prediction[0] + ' '\n    \n    submission.loc[task_name, 'output'] = prediction\n\n#     if 'output' in task['test'][test_id].keys():\n#         print(\"Validation for \", task_name, [(x == test['output']).all() for x in prediction[i]])\n        \n\n    \ndef get_prediction(test_id, task, case, train_index):\n    '''\n    t - train task on whose basis prediction is made\n    '''\n    test_inp = task['test'][test_id]['input']\n#     print(case)\n    if case == 'case BA04':\n        return case_BA04(test_inp, task, case, train_index)\n    \n    if case == 'case BA05':\n        return case_BA05(test_inp, task, case, train_index)\n    \n    if case == 'case BA06':\n        return case_BA06(test_inp, task, case, train_index)\n    \n    else:\n        return test_inp\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    num_rows = int(math.ceil((len(task['train']) + len(task['test'])) / 2))\n    fig, axs = plt.subplots(num_rows, 4, figsize=(15,15))\n    i = 0\n    while i < len(task['train']):\n        axs[int(i/2)][(i%2)*2].imshow(task['train'][i]['input'], cmap=cmap, norm=norm)\n        axs[int(i/2)][(i%2)*2].axis('off')\n        axs[int(i/2)][(i%2)*2].set_title('Train Input')\n        axs[int(i/2)][1 + (i%2)*2].imshow(task['train'][i]['output'], cmap=cmap, norm=norm)\n        axs[int(i/2)][1 + (i%2)*2].axis('off')\n        axs[int(i/2)][1 + (i%2)*2].set_title('Train Output')\n        i += 1\n    j = 0\n    while j < len(task['test']):\n        axs[int(i/2)][(i%2)*2].imshow(task['test'][j]['input'], cmap=cmap, norm=norm)\n        axs[int(i/2)][(i%2)*2].axis('off')\n        axs[int(i/2)][(i%2)*2].set_title('Test Input')\n#         axs[int(i/2)][1 + (i%2)*2].imshow(task['test'][j]['output'], cmap=cmap, norm=norm)\n#         axs[int(i/2)][1 + (i%2)*2].axis('off')\n#         axs[int(i/2)][1 + (i%2)*2].set_title('Test Output')\n        i += 1 \n        j += 1\n        \n    plt.tight_layout()\n    plt.show()\n# plot_task(read_json('00d62c1b.json'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compare_dict(a, b):\n    a_key = list(a.keys())\n    b_key = list(b.keys())\n    a_key.sort()\n    b_key.sort()\n    if a_key != b_key:\n        return False\n    for x in a:\n        if a[x] != b[x]:\n            return False\n    return True\n\ndef get_counter(a):\n    return Counter([y for x in a for y in x])\n\n\ndef get_rectified_kernel(inp):\n    i = 0\n    j = 0\n    k = 0\n    mapping = {}\n    while i < len(inp):\n        j = 0\n        while j < len(inp[0]):\n            if inp[i][j] not in mapping:\n                mapping[inp[i][j]] = k\n                inp[i][j] = k\n                k += 1\n            else:\n                inp[i][j] = mapping[inp[i][j]]\n            j += 1\n        i += 1\n    \n    return inp, mapping\n\ndef Defensive_Copy(A): \n    n = len(A)\n    k = len(A[0])\n    L = np.zeros((n,k), dtype = int)\n    for i in range(n):\n        for j in range(k):\n            L[i,j] = 0 + A[i][j]\n    return L.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def case_three(task_name):\n    print(task_name)\n    global flag123\n#     flag123 = True\n    task = read_json(row.name.split('_')[0]+'.json', 'test')\n\n\n    if ([(get_size(t['output'])[0] % get_size(t['input'])[0] == 0) and \\\n        (get_size(t['output'])[1] % get_size(t['input'])[1] != 0) for t in task['train']]):\n        # case CD01\n        print(task_name, \"case CD01\")\n#             plot_task(read_json(task_name))\n#         flag123 = True\n#             pass\n    else:\n#             print(task_name, \"fffff\")\n        pass\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\ndef check_in(t):\n    inp = copy.deepcopy(np.array(t['input']))\n    out = copy.deepcopy(np.array(t['output']))\n    out_size = out.shape\n    i, j = 0, 0\n    while i < len(inp):\n        j = 0\n        while j < len(inp[0]):\n            if equal(out, inp[i:i+out_size[0], j:j+out_size[1]]):\n                return True\n            j += 1\n        i += 1\n            \n    return False\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef unique_location(t):\n    inp = copy.deepcopy(np.array(t['input']))\n    out = copy.deepcopy(np.array(t['output']))\n    out_size = out.shape\n    i, j = 0, 0\n    res = []\n    while i < len(inp):\n        j = 0\n        while j < len(inp[0]):\n            if equal(out, inp[i:i+out_size[0], j:j+out_size[1]]):\n                res.append((i, j, i+out_size[0], j+out_size[1]))\n            j += 1\n        i += 1\n    \n    return res\n#     if len(res) == 1:\n#     return (res[0][0], res[0][1], res[0][0]+out_size[0], res[0][1]+out_size[1])\n#     else:\n#         return (random.randint(1, 4000), random.randint(1, 4000), random.randint(1, 4000), random.randint(1, 4000))\ndef find_common(lists):\n    index = 0\n    i = 1\n    for i in range(len(lists)):\n        if len(lists[i]) > len(lists[index]):\n            index = i\n    \n    res = []\n    for te in lists[index]:\n        if all([te in lists[i] for i in range(len(lists))]):\n            print(te)\n            res.append(te)\n            \n    if len(res) == 1:\n        return True\n    else:\n        return False\n\n    \ndef self_repeating(t):\n    inp = copy.deepcopy(np.array(t['input']))\n    out = copy.deepcopy(np.array(t['output']))\n    \n    if inp.shape[0] > inp.shape[1]:\n        #vertical\n        key = 2\n        while 2*key <= inp.shape[0]:\n            if inp.shape[0] % key != 0:\n                key += 1\n                continue\n            \n            if equal(inp[0:key, :], inp[key:2*key, :]):\n                return True\n            key += 1\n        return False\n            \n    elif inp.shape[0] < inp.shape[1]:\n        #horizontal\n        key = 2\n        while 2*key <= inp.shape[1]:\n            if inp.shape[1] % key != 0:\n                key += 1\n                continue\n            \n            if equal(inp[:, 0:key], inp[:, key:2*key]):\n                return True\n            key += 1\n        return False\n        \n    else:\n        return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def groupByColor(pixmap):\n    nb_colors = int(pixmap.max()) + 1\n    splited = [(pixmap == i) * i for i in range(1, nb_colors)]\n    return [x for x in splited if np.any(x)]\n\ndef cropToContent(pixmap):\n    true_points = np.argwhere(pixmap)\n    if len(true_points) == 0:\n        return []\n\n    top_left = true_points.min(axis=0)\n    bottom_right = true_points.max(axis=0)\n    pixmap = pixmap[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]\n    return pixmap\n\ndef unique_box(t):\n    inp = copy.deepcopy(np.array(t['input']))\n    out = copy.deepcopy(np.array(t['output']))\n    \n    color_frames = groupByColor(inp)\n    for ori_frame in color_frames:\n        t = np.unique(ori_frame)\n        frame = copy.deepcopy(ori_frame)\n        frame = np.array(frame, dtype='uint8') * 10\n        ret, frame = cv2.threshold(frame,5,255,0)\n\n        contours,hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        frame = frame * 0\n        for c in contours:\n            peri = cv2.arcLength(c, True)\n            approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n            if len(approx) == 4:\n                (x, y, w, h) = cv2.boundingRect(approx)\n                temp = ori_frame[y:y+h, x:x+w]\n                if equal(inp[y:y+h, x:x+w], out):\n                    return True\n                elif equal(inp[y+1:y+h-1, x+1:x+w-1], out):\n                    return True\n    return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def case_BA04(test_inp, task, case, train_index): # Done\n    decision = []\n    for t in task['train']:\n        inp = copy.deepcopy(np.array(t['input']))\n        out = copy.deepcopy(np.array(t['output']))\n\n        color_frames = groupByColor(inp)\n        flag = False\n        res = []\n        area = []\n        color_val = []\n        cou_count = []\n        for ori_frame in color_frames:\n            t = np.unique(ori_frame)\n            frame = copy.deepcopy(ori_frame)\n            uni_val = [x for x in np.unique(ori_frame) if x != 0]\n            \n            frame = np.array(frame, dtype='uint8') * 10\n            ret, frame = cv2.threshold(frame,5,255,0)\n\n            contours,hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n            frame = frame * 0\n            \n            for c in contours:\n                peri = cv2.arcLength(c, True)\n                approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n                if len(approx) == 4:\n                    (x, y, w, h) = cv2.boundingRect(approx)\n                    if w*h != ori_frame.shape[0]*ori_frame.shape[1]:\n                        temp = ori_frame[y:y+h, x:x+w]\n                        sum_ver = np.sum(temp, axis=0) / uni_val[0]\n                        sum_hor = np.sum(temp, axis=1) / uni_val[0]\n                        if (sum_ver[0] == temp.shape[0]) and (sum_ver[-1] == temp.shape[0]) and \\\n                                (sum_hor[0] == temp.shape[1]) and (sum_hor[-1] == temp.shape[1]):\n                            if equal(inp[y:y+h, x:x+w], out):\n                                res.append(((x, y, w, h), True, \"with_border\", w*h, uni_val[0], np.sum(ori_frame)==np.sum(temp), np.sum(sum_hor)))\n                            elif equal(inp[y+1:y+h-1, x+1:x+w-1], out):\n                                res.append(((x, y, w, h), True, \"without_border\", w*h, uni_val[0], np.sum(ori_frame)==np.sum(temp), np.sum(sum_hor)))\n                            else:\n                                res.append(((x, y, w, h), False, \"\", w*h, uni_val[0], np.sum(ori_frame)==np.sum(temp), np.sum(sum_hor)))\n\n        res = list(set(res))\n        print(\"frame\", res)\n        area = [x[3] for x in res]\n        color_val = [x[4] for x in res]\n        cou_count = [x[5] for x in res]\n        cou_sum = [x[6] for x in res]\n        for i in range(len(res)):\n            if res[i][1] == True:\n                if len(area) == 1:\n                    print(\"smalllargest\")\n                    decision.append((res[i], \"smallestlargest\", color_val[i], cou_count[i]))\n                    \n                elif (max(area) == area[i]) and (len([1 for x in area if max(area)==x]) == 1):\n                    print(\"largest\")\n                    decision.append((res[i], \"largest\", color_val[i], cou_count[i]))\n                    \n                elif (max(area) == area[i]) and (len([1 for x in area if max(area)==x]) != 1):\n                    if (max(cou_sum) == cou_sum[i]): \n                        print(\"largest_max\")\n                        decision.append((res[i], \"largest_max\", color_val[i], cou_count[i]))\n                    elif (min(cou_sum) == cou_sum[i]): \n                        print(\"largest_min\")\n                        decision.append((res[i], \"largest_min\", color_val[i], cou_count[i]))\n                    else: \n                        print(\"largest_no\")\n                        decision.append((res[i], \"largest_no\", color_val[i], cou_count[i]))\n                \n                elif (min(area) == area[i]) and (len([1 for x in area if min(area)==x]) == 1):\n                    print(\"smallest\")\n                    decision.append((res[i], \"smallest\", color_val[i], cou_count[i]))\n                    \n                elif (min(area) == area[i]) and (len([1 for x in area if min(area)==x]) != 1):\n                    if (max(cou_sum) == cou_sum[i]): \n                        print(\"smallest_max\")\n                        decision.append((res[i], \"smallest_max\", color_val[i], cou_count[i]))\n                    elif (min(cou_sum) == cou_sum[i]): \n                        print(\"smallest_min\")\n                        decision.append((res[i], \"smallest_min\", color_val[i], cou_count[i]))\n                    else: \n                        print(\"smallest_no\")\n                        decision.append((res[i], \"smallest_no\", color_val[i], cou_count[i]))\n                \n                else:\n                    decision.append((res[i], \"uni\", color_val[i], cou_count[i]))\n                    \n#     predict\n    inp = copy.deepcopy(np.array(test_inp))\n    color_frames = groupByColor(inp)\n    res = []\n    area = []\n    color_val = []\n    cou_count = [] \n    for ori_frame in color_frames:\n        t = np.unique(ori_frame)\n        frame = copy.deepcopy(ori_frame)\n        uni_val = [x for x in np.unique(ori_frame) if x != 0]\n        frame = np.array(frame, dtype='uint8') * 10\n        ret, frame = cv2.threshold(frame,5,255,0)\n\n        contours,hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        frame = frame * 0\n\n        for c in contours:\n            peri = cv2.arcLength(c, True)\n            approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n            if len(approx) == 4:\n                (x, y, w, h) = cv2.boundingRect(approx)\n                if w*h != ori_frame.shape[0]*ori_frame.shape[1]:\n                    temp = ori_frame[y:y+h, x:x+w]\n                    sum_ver = np.sum(temp, axis=0) / uni_val[0]\n                    sum_hor = np.sum(temp, axis=1) / uni_val[0]\n                    if (sum_ver[0] == temp.shape[0]) and (sum_ver[-1] == temp.shape[0]) and \\\n                            (sum_hor[0] == temp.shape[1]) and (sum_hor[-1] == temp.shape[1]):\n\n                        res.append(((x, y, w, h), w*h, uni_val[0], np.sum(ori_frame)==np.sum(temp), np.sum(sum_hor)))\n    \n    res = list(set(res))\n    print(\"-->\", res)\n    print(decision)\n    info = (None, None)\n    \n    if nunique([x[2] for x in decision]) == 1:\n        print(\"color\")\n        for x in res:\n            if x[2] == unique([y[2] for y in decision])[0]:\n                info = (x[0], decision[0][0][2])\n                \n    elif all([True if \"largest\" in x[1] else False for x in decision]):\n        if all([True if \"max\" in x[1] else False for x in decision]):\n            print(\"lar size max\")\n            area = [x[1] for x in res]\n            max_sum = [x[4] if x[1] == max(area) else 0 for x in res ]\n            info = (res[max_sum.index(max(max_sum))][0], decision[0][0][2])\n            \n        elif all([True if \"min\" in x[1] else False for x in decision]):\n            print(\"lar size min\")\n            area = [x[1] for x in res]\n            min_sum = [x[4] if x[1] == max(area) else 9999999 for x in res ]\n            info = (res[min_sum.index(min(min_sum))][0], decision[0][0][2])\n        else:\n            print(\"lar size\")\n            area = [x[1] for x in res]\n            info = (res[area.index(max(area))][0], decision[0][0][2])\n    \n    elif all([True if \"smallest\" in x[1] else False for x in decision]):\n        if all([True if \"max\" in x[1] else False for x in decision]):\n            print(\"small size max\")\n            area = [x[1] for x in res]\n            max_sum = [x[4] if x[1] == min(area) else 0 for x in res ]\n            info = (res[max_sum.index(max(max_sum))][0], decision[0][0][2])\n            \n        elif all([True if \"min\" in x[1] else False for x in decision]):\n            print(\"lar size min\")\n            area = [x[1] for x in res]\n            min_sum = [x[4] if x[1] == min(area) else 9999999 for x in res ]\n            info = (res[min_sum.index(min(min_sum))][0], decision[0][0][2])\n        else:\n            print(\"small size\")\n            area = [x[1] for x in res]\n            info = (res[area.index(min(area))][0], decision[0][0][2])\n    \n    elif (nunique([x[3] for x in decision]) == 1) and (unique([x[3] for x in decision])[0] == True):\n        print(\"unique\")\n        for x in res:\n            if x[3] == True:\n                info = (x[0], decision[0][0][2])\n    else:\n        print(\"fuck\", )\n    if info[0]:\n        (x, y, w, h) = info[0]\n        print(info)\n        if info[1] == \"with_border\":\n            return inp[y:y+h, x:x+w]\n        else:\n            return inp[y+1:y+h-1, x+1:x+w-1]\n                     \n    else:\n        info = (res[min(train_index, len(res)-1)][0], decision[0][0][2])\n        (x, y, w, h) = info[0]\n        if info[1] == \"with_border\":\n            return inp[y:y+h, x:x+w]\n        else:\n            return inp[y+1:y+h-1, x+1:x+w-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique_color(t):\n    inp = copy.deepcopy(np.array(t['input']))\n    out = copy.deepcopy(np.array(t['output']))\n    \n    color_frames = groupByColor(inp)\n    flag = False\n    for ori_frame in color_frames:\n        t = np.unique(ori_frame)\n        frame = copy.deepcopy(ori_frame)\n        \n        true_points = np.argwhere(frame)\n        top_left = true_points.min(axis=0)\n        bottom_right = true_points.max(axis=0)\n        \n        if equal(inp[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1], out):\n            if np.sum(ori_frame[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]) == \\\n                np.sum(ori_frame):\n                return True\n    return False\n\n\ndef is_in(t):\n    inp = copy.deepcopy(np.array(t['input']))\n    out = copy.deepcopy(np.array(t['output']))\n    skeleton = (inp != 0).astype('int')\n\n    frame = copy.deepcopy(skeleton)\n    frame = np.array(frame, dtype='uint8') * 10\n    ret, frame = cv2.threshold(frame,5,255,0)\n    contours,hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n    for c in contours:\n        (x, y, w, h) = cv2.boundingRect(c)\n#         print((x, y, w, h))\n#         tep = np.zeros(frame.shape)\n#         cv2.drawContours(tep, [c], -1, (100, 100, 100), 1)\n#         plt.imshow(tep)\n#         plt.show()\n\n        is_equal, _ = compare_kernel(inp[y:y+h, x:x+w], out)\n#         print(is_equal)\n#         print(inp[y:y+h, x:x+w])\n#         print(out)\n        if is_equal == 1:\n            return True\n    return False\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show(im):\n    plt.imshow(im)\n    plt.show()\n    \ndef case_BA05(test_inp, task, case, train_task): # Done\n    decision = []\n    for t in task['train']:\n        inp = copy.deepcopy(np.array(t['input']))\n        out = copy.deepcopy(np.array(t['output']))\n        color_frames = groupByColor(inp)\n        \n        count = {}\n        for ori_frame in color_frames:\n            skeleton = copy.deepcopy(ori_frame)\n            uni_val = [x for x in np.unique(ori_frame) if x != 0][0]\n            \n            skeleton = (skeleton != 0).astype('int')\n            frame = copy.deepcopy(skeleton)\n\n            frame = np.array(frame, dtype='uint8') * 10\n            ret, frame = cv2.threshold(frame,5,255,0)\n            contours,hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n            \n            count[uni_val] = []\n            for c, hi in zip(contours, hierarchy[0]):\n                x, y, w, h = cv2.boundingRect(c)\n#                 print(x,y,w,h, \"-->\", hi, \"col\", uni_val)\n                if hi[3] == -1:\n                    tep = np.zeros(frame.shape)\n                    cv2.drawContours(tep, [c], -1, (100, 100, 100), 1)\n#                     show(tep)\n                \n                    if equal(inp[y:y+h, x:x+w], out) and (np.sum(ori_frame[y:y+h, x:x+w]) == np.sum(ori_frame)):\n                        count[uni_val].append(((x, y, w, h), True, np.sum(ori_frame)/uni_val))\n                    else:\n                        count[uni_val].append(((x, y, w, h), False, np.sum(ori_frame)/uni_val))\n            \n        decision.append(count)\n    \n#     predict\n    test_count = {}\n    inp = copy.deepcopy(np.array(test_inp))\n    color_frames = groupByColor(inp)\n\n    for ori_frame in color_frames:\n        skeleton = copy.deepcopy(ori_frame)\n        uni_val = [x for x in np.unique(ori_frame) if x != 0][0]\n\n        skeleton = (skeleton != 0).astype('int')\n        frame = copy.deepcopy(skeleton)\n\n        frame = np.array(frame, dtype='uint8') * 10\n        ret, frame = cv2.threshold(frame,5,255,0)\n        contours,hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n        test_count[uni_val] = []\n        for c, hi in zip(contours, hierarchy[0]):\n            x, y, w, h = cv2.boundingRect(c)\n#             print(x,y,w,h, \"-->\", hi, \"col\", uni_val)\n            if hi[3] == -1:\n                tep = np.zeros(frame.shape)\n                cv2.drawContours(tep, [c], -1, (100, 100, 100), 1)\n#                 show(tep)\n\n                if equal(inp[y:y+h, x:x+w], out) and (np.sum(ori_frame[y:y+h, x:x+w]) == np.sum(ori_frame)):\n                    test_count[uni_val].append(((x, y, w, h), True, np.sum(ori_frame)/uni_val))\n                else:\n                    test_count[uni_val].append(((x, y, w, h), False, np.sum(ori_frame)/uni_val))\n#     inp = copy.deepcopy(np.array(test_inp))\n#     # single contour in color\n#     truth_feature = []\n#     for i, frame in enumerate(decision):\n#         truth_feature.append(False)\n#         for col in frame:\n#             for val in frame[col]:\n#                 if val[1] == True:\n#                     if len(frame[col]) == 1:\n#                         truth_feature[i] = True\n#                 else:\n#                     if len(frame[col]) == 1:\n#                         truth_feature[i] = False\n                        \n#     print(truth_feature)\n#     if all(truth_feature):\n#         res = []\n#         for col in test_count:\n#             if len(test_count[col]) == 1:\n#                 res.append(test_count[col][0])\n#         if len(res) == 1:\n#             x, y, w, h = res[0][0]\n#             return inp[y:y+h, x:x+w]\n#         else:\n#             x, y, w, h = res[min(len(res)-1, train_task)][0]\n#             return inp[y:y+h, x:x+w]\n        \n#     inp = copy.deepcopy(np.array(test_inp))\n    # min area in color\n    truth_feature = []\n    for i, frame in enumerate(decision):\n        truth_feature.append(False)\n        frame_area = []\n        for col in frame:\n            frame_area.append(frame[col][0][2])\n            \n        for col in frame:\n            for val in frame[col]:\n                if val[1] == True:\n                    if val[2] == min(frame_area):\n                        truth_feature[i] = True\n                        \n    print(truth_feature)\n    if all(truth_feature):\n        frame_area = []\n        for col in test_count:\n            frame_area.append([col, test_count[col][0][2]])\n            \n        frame_area.sort(key=(lambda x:x[1]))\n        \n        min_area_frame_col = frame_area[0][0]\n        res_skeleton = (test_inp == min_area_frame_col).astype('int')\n\n        true_points = np.argwhere(res_skeleton)\n        top_left = true_points.min(axis=0)\n        bottom_right = true_points.max(axis=0)\n        \n        return inp[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]\n    inp = copy.deepcopy(np.array(test_inp))\n    # max area in color\n    truth_feature = []\n    for i, frame in enumerate(decision):\n        truth_feature.append(False)\n        frame_area = []\n        for col in frame:\n            frame_area.append(frame[col][0][2])\n            \n        for col in frame:\n            for val in frame[col]:\n                if val[1] == True:\n                    if val[2] == max(frame_area):\n                        truth_feature[i] = True\n                        \n    print(truth_feature)\n    if all(truth_feature):\n        frame_area = []\n        for col in test_count:\n            frame_area.append([col, test_count[col][0][2]])\n            \n        frame_area.sort(key=(lambda x:x[1]))\n        \n        min_area_frame_col = frame_area[-1][0]\n        res_skeleton = (test_inp == min_area_frame_col).astype('int')\n\n        true_points = np.argwhere(res_skeleton)\n        top_left = true_points.min(axis=0)\n        bottom_right = true_points.max(axis=0)\n        \n        return inp[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]\n\n#     inp = copy.deepcopy(np.array(test_inp))\n    #failsafe\n    colors = list(test_count.keys())\n    colors.sort(reverse=True)\n#     colors.sort()\n    lucky_frame_col = colors[min(len(colors)-1, train_task)]\n    res_skeleton = (test_inp == lucky_frame_col).astype('int')\n\n    true_points = np.argwhere(res_skeleton)\n    top_left = true_points.min(axis=0)\n    bottom_right = true_points.max(axis=0)\n    show(inp[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1])\n    return inp[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]\n\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_col_profile(d):\n    return Counter(list(d.reshape(-1)))\n\ndef case_BA06(test_inp, task, case, train_task): # Done\n    decision = []\n    for t in task['train']:\n        inp = copy.deepcopy(np.array(t['input']))\n        out = copy.deepcopy(np.array(t['output']))\n\n        skeleton = (inp != 0).astype('int')\n\n        frame = copy.deepcopy(skeleton)\n        frame = np.array(frame, dtype='uint8') * 10\n        ret, frame = cv2.threshold(frame,5,255,0)\n        contours,hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        res = []\n        t = []\n        for c in contours:\n            (x, y, w, h) = cv2.boundingRect(c)\n#             print((x, y, w, h))\n#             tep = np.zeros(frame.shape)\n#             cv2.drawContours(tep, [c], -1, (100, 100, 100), 1)\n#             plt.imshow(tep)\n#             plt.show()\n#             if (x, y, w, h) not in t:\n#                 t.append((x, y, w, h))\n            is_equal, transformation = compare_kernel(inp[y:y+h, x:x+w], out)\n            if is_equal == 1:\n                res.append((inp[y:y+h, x:x+w], True, transformation))\n            else:\n                res.append((inp[y:y+h, x:x+w], False, -1))\n        \n        decision.append(res)\n        \n    \n    # test_res\n    test_res = []\n    test_col = []\n    inp = copy.deepcopy(np.array(test_inp))\n    skeleton = (inp != 0).astype('int')\n\n    frame = copy.deepcopy(skeleton)\n    frame = np.array(frame, dtype='uint8') * 10\n    ret, frame = cv2.threshold(frame,5,255,0)\n    contours,hierarchy = cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    t = []\n    for c in contours:\n        (x, y, w, h) = cv2.boundingRect(c)\n#         print((x, y, w, h))\n#         tep = np.zeros(frame.shape)\n#         cv2.drawContours(tep, [c], -1, (100, 100, 100), 1)\n#         plt.imshow(tep)\n#         plt.show()\n        if (x, y, w, h) not in t:\n            t.append((x, y, w, h))\n            test_res.append(inp[y:y+h, x:x+w])\n    \n#     print(decision)\n    # count\n    findings = []\n    findings_col = []\n    inp = copy.deepcopy(np.array(test_inp))\n    for frame in decision:\n        frame_res = []\n        frame_count = []\n        frame_area = []\n        frame_flag = []\n        frame_color = []\n        for con in frame:\n            frame_res.append(con[0])\n            frame_flag.append(con[1])\n            frame_area.append(con[0].shape[0]*con[0].shape[1])\n            frame_color.append(get_col_profile(con[0]))\n        for i in frame_res:\n            temp_count = 0\n            for j in frame_res:\n                is_equal, _ = compare_kernel(i, j)\n                if is_equal == 1:\n                    temp_count += 1\n            frame_count.append(temp_count)\n        true_index = frame_flag.index(True)\n\n        if nunique(frame_count) != 1 and frame_count[true_index] == min(frame_count):\n            findings.append('min')\n        elif nunique(frame_count) != 1 and frame_count[true_index] == max(frame_count):\n            findings.append('max')\n#         elif nunique(frame_area) != 1 and frame_area[true_index] == min(frame_area):\n#             findings.append('minarea')\n#         elif nunique(frame_area) != 1 and frame_area[true_index] == max(frame_area):\n#             findings.append('maxarea')\n        else:\n            findings.append('---')\n            \n        if all([list(frame_color[0].keys()) == k for k in [list(ccc.keys()) for ccc in frame_color]]):\n#             findings.append('---')\n            color_ress = []\n            print(\"in res\")\n            for col in list(frame_color[0].keys()):\n                temp_125 = []\n                for i in range(len(frame_color)):\n                    temp_125.append(frame_color[i][col])\n                if temp_125[true_index] == min(temp_125) and temp_125.count(min(temp_125)) == 1:\n                    color_ress.append('min_'+str(col))\n                    \n                elif temp_125[true_index] == max(temp_125) and temp_125.count(max(temp_125)) == 1:\n                    color_ress.append('max_'+str(col))\n            findings_col.append(color_ress)\n        \n    \n#     predict\n    print(len(test_res))\n    frame_count = []\n    for i in test_res:\n        temp_count = 0\n        for j in test_res:\n            is_equal, _ = compare_kernel(i, j)\n            if is_equal == 1:\n                temp_count += 1\n        frame_count.append(temp_count)\n#     print(\"-->\", frame_count)\n#     print(findings)\n    if nunique(findings) == 1 and unique(findings)[0] == 'min':\n        return test_res[frame_count.index(min(frame_count))]\n        \n    if nunique(findings) == 1 and unique(findings)[0] == 'max':\n        return test_res[frame_count.index(max(frame_count))]\n      \n    count_col = Counter([c for f in findings_col for c in f])\n    fin_des = []\n#     print(\"22\", count_col)\n    for col in count_col:\n        if count_col[col] == 3:\n            fin_des.append(col)\n    if len(fin_des) == 1:\n        print(\"------------------------------->\", fin_des)\n        frame_col = []\n        for co in test_res:\n            frame_col.append(get_col_profile(co))\n#         print(frame_col)\n        #         col_res = []\n        for col in list(frame_col[0].keys()):\n            if str(col) in fin_des[0]:\n                temp_125 = []\n                for i in range(len(frame_color)):\n                    temp_125.append(frame_col[i][col])\n#                 print(temp_125)\n                if \"min\" in fin_des[0]:\n                    return test_res[temp_125.index(min(temp_125))]\n                elif \"max\" in fin_des[0]:\n                    return test_res[temp_125.index(max(temp_125))]\n        \n    \n    if findings[min(len(findings)-1, train_task)] == 'min':\n        return test_res[frame_count.index(min(frame_count))]\n    \n    if findings[min(len(findings)-1, train_task)] == 'max':\n        return test_res[frame_count.index(max(frame_count))]\n    \n    \n    return test_res[min(len(test_res)-1, train_task)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def case_two(task_name):\n    print(task_name)\n    task = read_json(task_name.split('_')[0]+'.json', 'test')\n   # case 1\n    if all([check_in(t) for t in task['train']]):\n#         plot_task(task)\n        if all([get_size(t['output'])==(1, 1) for t in task['train']]):\n            print(\"case BA01\", task_name)\n            plot_task(task)\n        elif find_common([unique_location(t) for t in task['train']]):\n            print(\"case BA02\", task_name)\n#             print([unique_location(t) for t in task['train']])\n            plot_task(task)\n        elif all([self_repeating(t) for t in task['train']]):\n            print(\"case BA03\", task_name)\n        elif all([unique_box(t) for t in task['train']]):\n            print(\"case BA04\", task_name)\n            plot_task(task)\n            predict(\"case BA04\", task, task_name)\n        elif all([unique_color(t) for t in task['train']]):\n            print(\"case BA05\", task_name)\n            plot_task(task)\n            predict(\"case BA05\", task, task_name)\n\n        elif all([is_in(t) for t in task['train']]):\n            print(\"case BA06\", task_name)\n            \n            predict(\"case BA06\", task, task_name)\n    else:\n        print(\"case ----\", task_name)\n#         plot_task(task)\n#         print(\"case ----\", task_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# case_two('1a6449f1_0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# case_two('2c0b0aff_0')\n# task = read_json('2c0b0aff.json', 'test')\n# plot_task(task)\n# predict(\"case BA06\", task, 'taskname_0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, row in submission.iterrows():\n    task = read_json(row.name.split('_')[0]+'.json', 'test')\n#     plot_task(task)\n    if all([(get_size(t['input']) == get_size(t['output'])) for t in task['train']]):\n        pass\n        \n    elif all([(get_size(t['input']) > get_size(t['output'])) for t in task['train']]):\n        case_two(row.name)\n        pass\n        \n    elif all([(get_size(t['input']) < get_size(t['output'])) for t in task['train']]):\n#         case_three(row.name)\n        pass\n    else:\n        pass\n    \n\n# submission.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub1 = sample_sub1.reset_index()\nsample_sub1 = sample_sub1.sort_values(by=\"output_id\")\n\nsample_sub2 = submission.sort_values(by=\"output_id\")\nout1 = sample_sub1[\"output\"].astype(str).values\nout2 = sample_sub2[\"output\"].astype(str).values\n\nmerge_output = []\nfor o1, o2 in zip(out1, out2):\n    if o2 == '':\n        o = o1\n    else:\n        o = o2\n#         o = o1.strip().split(\" \")[:1] + o2.strip().split(\" \")[:2]\n#         o = \" \".join(o[:3])\n    merge_output.append(o)\nsample_sub1[\"output\"] = merge_output\nsample_sub1[\"output\"] = sample_sub1[\"output\"].astype(str)\nsample_sub1.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}