{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This notebook:   1) identifies all objects in the training pairs, 2) calculates a similarity matrix,\n3) matches each output object with the most similar input object, 4) compares attributes of the matched object pairs, 5) groups object pairs by which attribute changed, and 6) infers a simple rule for which attribute changed.\n    Note: Steps 3) through 6) are very basic in nature, mainly this notebook is to show steps 1) and 2).\n* There are 3 object identification methods, which are included, but I only use method 3 for both color and isolation. (credit to Sokichi's \"ARC Identify Objects\" notebook).\n* The similarity matrix that is calculated is in reference to the aINs and aOUTs, which are the lists of identified input and output objects. \n1. The first similarity matrix, i.e. asimilarity_allpairs[0], might be, for example, of size 2 x 3. The 3 columns are the three input objects and the 2 rows are the 2 output objects, and the value of the coordinates [i, j] is the similarity of the jth output object and the ith input object.\n2. Total similarity between each object is calculated by weighting their similarity of 1) color, 2) location, and 3) shape.\n   * shape similarity compares all permutations (flips, rotates, etc.) of the object's color-less shape. Locations gives higher rating if the x or y coord is close.\n   * there are 5 separate methods of weighting the color, shape, and location similarities. 1st is equal weighting, and the 5th method is a random weight distribution.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* asimilarity_allpairs . . . . . . .  # similarity matrix\n* answer  . . . . . . . . . . . . . . . . # obj pairs with matching attributes removed\n* aaa2_orgnzd_obj_pairs . . .   # obj pairs organized by different attributes\n* total_appnded   . . . . . . . . . .   # reorganizes #(3) in preparation for rule formation\n* total_train_pr_trackd  . . . . .  # corresponding train pair #s for # (4)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# This notebook uses similar rule extraction techniques as my notebook for calculating matrix dimensions that achieves 86%.\nLINK:\nhttps://www.kaggle.com/smurfysannes/matrix-dimensions-calculator-86-accuracy\n* # The types of inferences it makes are:\n     * ### 'multiply or divide by' (such as multiply the height of input matrix by 2),\n     * ### 'add or subtract',\n     * ### and 'static' (such as make height equal to 9 regardless of input matrix size).","execution_count":null},{"metadata":{"_uuid":"41fe6ed1-e000-4694-a059-0004dcad411f","_cell_guid":"61b14fdc-2fd5-47d7-8154-cf28a5b97c75","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport numpy as np\nimport pandas as pd\nimport os\nimport json\nfrom pathlib import Path\nimport pprint\npp = pprint.PrettyPrinter(indent=4)\nfrom os.path import join as path_join\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors, cm\nimport pdb\n#import cv2\nfrom skimage import measure\n\n#from my \"scratch\" notebook\nfrom scipy.stats import mode\n\n#from object notebook\nimport itertools\nimport random\nfrom random import *\n\nimport copy   #makes a copy so old version doesn't change. e.g. dict1 = copy.deepcopy(dict1)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")  #suppress all warnings\n\n#######THIS CODE IS FOR USE WITH ANOCONDA PYTHON EDITOR IN MY DIRECTORY###########\n# training_path = 'kaggle/input/abstraction-and-reasoning-challenge/training/'\n# training_tasks = os.listdir(training_path)\n# Trains = []\n# for i in range(400):\n#     task_file = str(training_path + training_tasks[i])\n#     task = json.load(open(task_file, 'r'))\n#     Trains.append(task)\n# train_tasks = Trains\n##############################################################################\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\ntraining_tasks = sorted(os.listdir(training_path))\neval_tasks = sorted(os.listdir(training_path))\nT = training_tasks\nTrains = []\n\nfor i in range(400):\n    task_file = str(training_path / T[i])\n    task = json.load(open(task_file, 'r'))\n    Trains.append(task)\ndef load_data(path):\n    tasks = pd.Series()\n    for file_path in sorted(os.listdir(path)):\n        task_file = path_join(path, file_path)\n        with open(task_file, 'r') as f:\n            task = json.load(f)\n        tasks[file_path[:-5]] = task\n    return tasks\ntrain_tasks = load_data('../input/abstraction-and-reasoning-challenge/training/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17e6d973-6bbe-4c4a-9c69-296a66264307","_cell_guid":"b30e8dba-9c35-42bc-ab46-e1d18af89329","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\ndef plot_one(ax, i,train_or_test,input_or_output, task):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    input_matrix = task[train_or_test][i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' '+input_or_output)\n\ndef plot_img(input_matrix, title ='no title given'):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    num_train = 1\n    fig, ax = plt.subplots(1, num_train, figsize=(3*num_train,3*2))\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(title)\n\ndef plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(task['train'])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    for i in range(num_train):     \n        plot_one(axs[0,i],i,'train','input', task)\n        plot_one(axs[1,i],i,'train','output', task)        \n    plt.tight_layout()\n    plt.show()        \n    num_test = len(task['test'])\n    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n    if num_test==1: \n        plot_one(axs[0],0,'test','input', task)\n        plot_one(axs[1],0,'test','output', task)     \n    else:\n        for i in range(num_test):      \n            plot_one(axs[0,i],i,'test','input', task)\n            plot_one(axs[1,i],i,'test','output', task)  \n    plt.tight_layout()\n    plt.show() \n\n\n##This ARC_solver is from https://www.kaggle.com/xiaoyuez/arc-identify-objects with slight modifications.\nclass ARC_solver:\n    def __init__(self, task_num):\n        self.task_num = task_num\n        # standardize plotting colors\n        self.cmap = colors.ListedColormap(['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n                                         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n        self.norm = colors.Normalize(vmin = 0, vmax = 9)\n        # initialize objects-related things\n        self.identified_objects = []\n        self.io_inx = [] # the original index of the identified objects (io)\n        self.io_height = [] # height of io\n        self.io_width = [] # width of io\n        self.io_pixel_count = [] # count of non-background pixels\n        self.io_size = [] # overall grid size\n        self.io_unique_colors = [] # number of unique colors\n        self.io_main_color = [] # the dominating color\n        self.zzz_io_inx = []\n    \n    def reset(self):\n        self.identified_objects = []\n        self.io_inx = [] \n        self.io_height = [] \n        self.io_width = [] \n        self.io_pixel_count = [] \n        self.io_size = [] \n        self.io_unique_colors = [] \n        self.io_main_color = []\n        self.zzz_io_inx = []\n        \n    def plot_task(self):\n        # plot examples of task input-output pairs \n        task = train_tasks[self.task_num]\n        cmap = self.cmap\n        norm = self.norm\n        fig, axs = plt.subplots(1, 5, figsize = (8,2))\n        axs[0].text(0.5, 0.5, 'Task', horizontalalignment = 'center', verticalalignment = 'center', fontsize = 15)\n        axs[0].get_xaxis().set_visible(False)\n        axs[0].get_yaxis().set_visible(False)\n        axs[0].axis('off')\n        axs[1].imshow(task['train'][0]['input'], cmap=cmap, norm=norm)\n        axs[1].axis('off')\n        axs[1].set_title('Train Input')\n        axs[2].imshow(task['train'][0]['output'], cmap=cmap, norm=norm)\n        axs[2].axis('off')\n        axs[2].set_title('Train Output')\n        axs[3].imshow(task['test'][0]['input'], cmap=cmap, norm=norm)\n        axs[3].axis('off')\n        axs[3].set_title('Test Input')\n        axs[4].imshow(task['test'][0]['output'], cmap=cmap, norm=norm)\n        axs[4].axis('off')\n        axs[4].set_title('Test Output')\n        plt.tight_layout()\n        plt.show()\n    \n    def plot_identified_objects(self, identified_objects, title = 'objects'):\n        # do not plot anything in the following situations\n        if len(identified_objects) == 0:\n            print('No objects were identified.')\n            return\n        if len(identified_objects) > 20:\n            print('Way too many objects (>20). Not gonna plot them.')\n            return\n        fig, axs = plt.subplots(1, len(identified_objects) + 1, figsize = (8,2))\n        for i in range(len(identified_objects) + 1):\n            if i == 0:\n                axs[0].text(0.5, 0.5, title, horizontalalignment = 'center', verticalalignment = 'center', fontsize = 15)\n                axs[0].get_xaxis().set_visible(False)\n                axs[0].get_yaxis().set_visible(False)\n                axs[0].axis('off')\n            else:\n                obj = identified_objects[i-1]\n                axs[i].imshow(obj, cmap = self.cmap, norm = self.norm)\n                axs[i].axis('off')\n                axs[i].set_title('object{}'.format(i))\n        plt.tight_layout()\n        plt.show()\n    \n    def get_background(self, image):\n        # if image contains 0 \n        \n        if 0 in image:\n          background = 0\n        # else use the most frequent pixel color\n        else: \n            unique_colors, counts = np.unique(image, return_counts = True)\n            background = unique_colors[np.argmax(counts)]\n        #TODO: its posible the if below this is breaking some things.\n            if len(counts) > 1:\n                if counts[np.argmax(counts)] == counts[0] and counts[np.argmax(counts)] == counts[1]:\n                    background = 11\n        return background\n    \n    def check_pairs(self, inx_pairs, this_pair, return_inx = False):\n        # check if this_pair is in inx_pairs\n        match = []\n        for pair in inx_pairs:\n          if pair[0] == this_pair[0] and pair[1] == this_pair[1]:\n            match.append(True)\n          else:\n            match.append(False)\n        if return_inx:\n          return any(match), np.where(match)\n        else:\n          return any(match)\n    \n    def check_neighbors(self, all_pairs, this_pair, objectness, this_object):\n        # all_pairs: an array of index pairs for all nonzero/colored pixels\n        # this_pair: the index pair whose neighbors will be checked\n        # objectness: an array with the shape of original image, storage for how much objectness has been identified\n        # this_object: the current object we are looking at\n        row_inx = this_pair[0]\n        col_inx = this_pair[1]\n        objectness[row_inx, col_inx] = this_object\n        # find if any neighboring pixels contain color\n        if self.check_pairs(all_pairs, [row_inx-1, col_inx-1]): # up-left\n          objectness[row_inx-1, col_inx-1] = this_object\n        if self.check_pairs(all_pairs, [row_inx-1, col_inx]): # up\n          objectness[row_inx-1, col_inx] = this_object \n        if self.check_pairs(all_pairs, [row_inx-1, col_inx+1]): # up-right\n          objectness[row_inx-1, col_inx+1] = this_object\n        if self.check_pairs(all_pairs, [row_inx, col_inx-1]): # left\n          objectness[row_inx, col_inx-1] = this_object\n        if self.check_pairs(all_pairs, [row_inx, col_inx+1]): # right\n          objectness[row_inx, col_inx+1] = this_object\n        if self.check_pairs(all_pairs, [row_inx+1, col_inx-1]): # down-left\n          objectness[row_inx+1, col_inx-1] = this_object\n        if self.check_pairs(all_pairs, [row_inx+1, col_inx]): # down\n          objectness[row_inx+1, col_inx] = this_object\n        if self.check_pairs(all_pairs, [row_inx+1, col_inx+1]): # down-right\n          objectness[row_inx+1, col_inx+1] = this_object\n        return objectness\n\n    def identify_object_by_color(self, true_image, background = 0):\n        # identify obeject by the color only \n        unique_colors = np.unique(true_image)\n        for i, color in enumerate(unique_colors):\n          image = np.copy(true_image) # make a copy from original first\n          if color == background: \n            continue\n          image[image != color] = background\n          inx = np.where(image == color)\n          obj = image[np.min(inx[0]):np.max(inx[0])+1, np.min(inx[1]):np.max(inx[1])+1]\n          # append the object attributes\n          self.identified_objects.append(obj)\n          self.io_inx.append(inx)\n          self.io_height.append(obj.shape[0])\n          self.io_width.append(obj.shape[1])\n          self.io_pixel_count.append(obj[obj != background].shape[0])\n          self.io_size.append(obj.size)\n          nc, c = np.unique(obj, return_counts = True)\n          self.io_unique_colors.append(nc)\n          self.io_main_color.append(nc[np.argmax(c)])\n    \n    def identify_object_by_isolation(self, image, background = 0):\n        # identify all objects by physical isolation on the given image\n        all_pairs = np.array(np.where(image != background)).T\n        objectness = np.zeros(image.shape)\n        this_object = 1\n        while len(all_pairs) >= 1:\n          init_pair = all_pairs[0] # start with the first pair\n          objectness = self.check_neighbors(all_pairs, init_pair, objectness, this_object)\n          # get a list of index pairs whose neghbors haven't been checked\n          unchecked_pairs = np.array(np.where(objectness == this_object)).T\n          checked_pairs = np.zeros((0,2)) \n          # check all the index pairs in the expanding unchecked_pairs untill all have been checked\n          while len(unchecked_pairs) != 0:\n            this_pair = unchecked_pairs[0]\n            objectness = self.check_neighbors(all_pairs, this_pair, objectness, this_object)\n            # append the checked_pairs\n            checked_pairs = np.vstack((checked_pairs, this_pair))\n            # get all index pairs for the currently identified object\n            current_object_pairs = np.array(np.where(objectness == this_object)).T\n            # delete the checked pairs from current object pairs\n            checked_inx = []\n            for pair in checked_pairs:\n              _, inx = self.check_pairs(current_object_pairs, pair, return_inx = True)\n              checked_inx.append(inx[0][0])\n            unchecked_pairs = np.delete(current_object_pairs, checked_inx, axis = 0)\n\n          # store this object to identified_objects\n          current_object_pairs = np.array(np.where(objectness == this_object)).T\n          cop = current_object_pairs.T\n          obj = image[np.min(cop[0]):np.max(cop[0])+1, np.min(cop[1]):np.max(cop[1])+1]\n          # delete the current object pairs from all_pairs \n          cop_inx = []\n          for pair in current_object_pairs:\n            _, this_cop_inx = self.check_pairs(all_pairs, pair, return_inx = True)\n            cop_inx.append(this_cop_inx[0][0])\n          all_pairs = np.delete(all_pairs, cop_inx, axis = 0)\n          # append the object attributes\n          self.identified_objects.append(obj)\n          \n          #my code to get top left coordinates of object\n          #if 'cop' doesn't work, replace cop with current_object_pairs OR objectness\n          if len(inx) < 2:\n              row = min(cop[0])\n              column = min(cop[1])\n              inx = [row, column]\n          self.zzz_io_inx.append(inx)\n          self.io_inx.append(inx)\n          self.io_height.append(obj.shape[0])\n          self.io_width.append(obj.shape[1])\n          self.io_pixel_count.append(obj[obj != background].shape[0])\n          self.io_size.append(obj.size)\n          nc, c = np.unique(obj, return_counts = True)\n          self.io_unique_colors.append(nc)\n          self.io_main_color.append(nc[np.argmax(c)])\n          # start identifying a new object\n          this_object += 1\n        return objectness, \n    \n    def identify_object_by_color_isolation(self, true_image, background = 0):\n        # identify objects first by color then by physical isolation\n        unique_colors = np.unique(true_image)\n        for i, color in enumerate(unique_colors):\n          image = np.copy(true_image) # make a copy from the original first\n          if color == background:\n            continue\n          # identify objects by isolation in this color only \n          image[image != color] = background\n          self.identify_object_by_isolation(image, background = background)\n    \n    def identify_object(self, image, method):\n        # a wrapper of different methods\n        # in the future method can be a parameter to be learned\n        # 1 = by_color, 2 = by_isolation, 3 = by_color_isolation\n        background = self.get_background(image)\n        if method == 1:\n          self.identify_object_by_color(image, background)\n        elif method == 2:\n          self.identify_object_by_isolation(image, background)\n        elif method == 3:\n          self.identify_object_by_color_isolation(image, background)\n          \ndef Vert(M):   #flip function\n    n = len(M)\n    k = len(M[0])\n    ans = np.zeros((n,k), dtype = int)\n    for i in range(n):\n        for j in range(k):\n            ans[i][j] = 0+M[n-1-i][j]\n    return ans.tolist()\n\ndef Hor(M):   #flip function\n    n = len(M)\n    k = len(M[0])\n    ans = np.zeros((n,k), dtype = int)\n    for i in range(n):\n        for j in range(k):\n            ans[i][j] = 0+M[i][k-1-j]\n    return ans.tolist()\n\ndef Rot1(M):\n    n = len(M)\n    k = len(M[0])\n    ans = np.zeros((k,n), dtype = int)\n    for i in range(n):\n        for j in range(k):\n            ans[j][i] = 0 + M[i][k-1-j]\n    return ans.tolist()\n            \ndef Rot2(M):\n    n = len(M)\n    k = len(M[0])\n    ans = np.zeros((k,n), dtype = int)\n    for i in range(n):\n        for j in range(k):\n            ans[j][i] = 0 + M[n-1-i][j]\n    return ans.tolist()\n\ndef check_if_same_size(c, d):\n    a = np.atleast_2d(c) # to allow it to work for 1d arrays\n    b = np.atleast_2d(d) # to allow it to work for 1d arrays\n    x, y = a.shape\n    x2, y2 = b.shape\n    #print('shapes are', x,y,x2,y2)\n    if x ==x2 and y==y2:\n        return True\n    return False\n\ndef are_two_images_equals(c, d):\n    a=np.array(c)\n    b=np.array(d)\n    if tuple(a.shape) == tuple(b.shape):\n        if (np.abs(b-a) < 1).all():\n            return True\n    return False\n\ndef in_out_change(image_matrix_in, image_matrix_out):  #ONLY WORKS WITH ARRAYS  of size at least 2 x 2\n    \"\"\" #I think it works with any array size now, even if height is only 1\n    Calculate the difference between input and output image.\n    (Can have different formats)    \"\"\"   \n    i_pre = np.atleast_2d(image_matrix_in) # to allow it to work for 1d arrays\n    o_pre = np.atleast_2d(image_matrix_out) # to allow it to work for 1d arrays\n    x_in, y_in = i_pre.shape\n    x_out, y_out = o_pre.shape\n    min_x = min(x_in, x_out)\n    min_y = min(y_in, y_out)\n    image_matrix_diff = np.zeros((max(x_in, x_out), max(y_in, y_out)))\n    #print('image matrix diff is:', image_matrix_diff)\n    image_matrix_diff[:x_in, :y_in] -= image_matrix_in\n    image_matrix_diff[:x_out, :y_out] += image_matrix_out\n    a = image_matrix_diff\n    #print('a', a)\n    b = (a != 0)             #return true for all changed cells\n    c = (a != 0).astype(int) #return 1 for all changed cells\n    d = c*image_matrix_in    #return original(input) colors of changed cells\n    e = c*image_matrix_out   #return output colors of changed cells\n    #to fix double bracket problem\n    if b.shape[0] == 1:\n        b = b[0]\n    if c.shape[0] == 1:\n        c = c[0]\n    if d.shape[0] == 1:\n        d = d[0]\n    if e.shape[0] == 1:\n        e = e[0]\n    return b, c, d, e   #true(bolean), 1(int), original color cells that were changed(int), new color cells that were changed(int)\n\ndef SINGLE_PERMS(in2darray):\n    \"\"\"ouputs all permutations (rotates, flips)\"\"\"\n    O = in2darray\n    #various permutations: rotations, flips\n    V = Vert(O)\n    VH = Hor(Vert(O))\n    H = Hor(O)\n    R1 = Rot1(O) #counterclockwise\n    R1V = Vert(Rot1(O))\n    R2 = Rot2(O) #clockwise\n    R2V = Vert(Rot2(O))\n    #TWO_COMPARE_ALL_PERM function relies on the order of these\n    perms = [O, V, VH, H, R1, R1V, R2, R2V] \n    perms = np.array(perms)\n    return perms\n\ndef TWO_COMPARE_ALL_PERM(c, d):\n    \"\"\"compare 2 arrays, including all permuations(flips, rotates)\n    outputs if same size, if exact same, if a permutation of, \n        #and Tranformation needed of c to get to d, if any\"\"\"\n    size = False\n    same = False\n    perm = False # true if any permutations match\n    perm_funcs = False #function needed to get the permutation that matches\n    size = check_if_same_size(c, d)\n    if size == True:\n        same = are_two_images_equals(c, d)\n        if same == True:\n            perm = True\n            answer = [size, same, perm, perm_funcs]\n            return answer\n    #if not the exact same, then check if permutations are\n    cR1 = np.array(Rot1(c))\n    size2 = check_if_same_size(cR1, d)\n    if size2 == True:  #if the transpose the same size\n        perms = SINGLE_PERMS(c)\n        for i in range(len(perms)):\n            perm_c_i = perms[i]  #don't need to check first one, which is original\n            perm_c_i = np.array(perm_c_i)\n            same_perm = are_two_images_equals(perm_c_i, d)\n            if same_perm == True:\n                perm = True\n                if i == 1:\n                    perm_funcs = Vert  #second function of SINGLE_PERMS\n                if i == 2:\n                    perm_funcs = Hor, Vert\n                if i == 3:\n                    perm_funcs = Hor\n                if i == 4:\n                    perm_funcs = Rot1\n                if i == 5:\n                    perm_funcs = Vert, Rot1\n                if i == 6:\n                    perm_funcs = Rot2\n                if i == 7:\n                    perm_funcs = Vert, Rot2\n                answer = [size, same, perm, perm_funcs]\n                return answer\n    else: #if even the transpose isn't the same size, then no perms will match\n        answer = [size, same, perm, perm_funcs]\n        return answer\n    answer = [size, same, perm, perm_funcs]\n    return answer #format: [if same size, if exact same, if same perm, perm_funcs]\n\ndef idntfy_objs_image(image, method=3):\n    \"\"\"This uses the ARC_solver class above to extract objects and attributes\"\"\"\n    in_objs = []\n    in_objs_inx = []\n    in_objs_attr = []    \n    arc.input_objects = []\n    arc.input_objects_inx = []\n    arc.input_objects_attr = {\"height\": [],\n                                \"width\": [],\n                                \"pixel_count\": [],\n                                \"size\": [],\n                                \"unique_colors\": [],\n                                \"in_obj\": [],\n                                \"x_coord\": [],\n                                \"y_coord\": [],\n                                \"shape\": [],\n                                \"main_color\": []} \n    arc.reset()\n    arc.identify_object(image, method = method)\n    #arc.plot_identified_objects(arc.identified_objects, title = ('Task',task_num, 'method', method))\n    arc.input_objects_attr['height'].append(arc.io_height)\n    arc.input_objects_attr['width'].append(arc.io_width)\n    arc.input_objects_attr['pixel_count'].append(arc.io_pixel_count)\n    arc.input_objects_attr['size'].append(arc.io_size)\n    arc.input_objects_attr['unique_colors'].append(arc.io_unique_colors)\n    arc.input_objects_attr['main_color'].append(arc.io_main_color)\n    in_objs_inx = arc.io_inx\n    for o in range(len(in_objs_inx)):\n        x_copy = in_objs_inx[o][1]\n        y_copy = in_objs_inx[o][0]\n        arc.input_objects_attr['x_coord'].append(x_copy)\n        arc.input_objects_attr['y_coord'].append(y_copy)\n        obj = arc.identified_objects[o]\n        obj_shape = (obj != 0).astype(int)\n        arc.input_objects_attr['shape'].append(obj_shape)\n    x_s = arc.input_objects_attr['x_coord']\n    y_s = arc.input_objects_attr['y_coord']\n    shape_s = arc.input_objects_attr['shape']\n    arc.input_objects_attr['x_coord'] = [x_s]\n    arc.input_objects_attr['y_coord'] = [y_s]\n    arc.input_objects_attr['shape'] = [shape_s]\n    arc.input_objects_attr['in_obj'].append(arc.identified_objects)\n    in_objs.append(arc.identified_objects)\n    in_objs_inx.append([arc.io_inx])\n    in_objs_attr.append(arc.input_objects_attr)\n    return in_objs, in_objs_inx, in_objs_attr\n\ndef get_attr_task(task_num, method_num = 3):\n    \"\"\"extracts the objects, and their attributes(e.g. height, location, color), \n    for all training pairs and the test pair of a task\"\"\"\n    arc = ARC_solver(task_num)\n    task = train_tasks[task_num] \n    aINs = []\n    aOUTs = []\n    aPAIRs = []\n    aTEST_PAIR = []\n    aINs_unchgd = []\n    aOUTs_unchgd = []\n    aINs_chgd = []\n    aOUTs_chgd = []\n    # iterate through training examples \n    num_examples = len(train_tasks[task_num]['test'])\n    for i in range(num_examples):\n        # identify all objects\n        input_image = np.array(train_tasks[task_num]['test'][i]['input'])\n        output_image = np.array(train_tasks[task_num]['test'][i]['output'])\n        in_objs, in_inx_unused, A_in_objs_attr = idntfy_objs_image(input_image, method=method_num)\n        out_objs, out_inx_unused, A_out_objs_attr = idntfy_objs_image(output_image, method=method_num)\n        pair = [A_in_objs_attr[0], A_out_objs_attr[0]]\n        aTEST_PAIR.append(pair)\n    # iterate through testing examples \n    num_examples = len(train_tasks[task_num]['train'])\n    for i in range(num_examples):\n        # identify all objects\n        input_image = np.array(train_tasks[task_num]['train'][i]['input'])\n        output_image = np.array(train_tasks[task_num]['train'][i]['output'])\n        in_objs, in_inx_unused, A_in_objs_attr = idntfy_objs_image(input_image, method=method_num)\n        out_objs, out_inx_unused, A_out_objs_attr = idntfy_objs_image(output_image, method=method_num)\n        try:\n            b,c,d,e = in_out_change(input_image, output_image)\n            inv_b = np.invert(b).astype(int) #get the location of pixels that did NOT change, as 0 or 1\n            #d                          #input objects,  DID   change\n            #e                          #output objects, DID   change\n            f = inv_b*input_image      #input objects,  did NOT change\n            g = inv_b*output_image     #output objects, did NOT change\n            in_objs2, in_inx_unused2, A_in_objs_attr2 = idntfy_objs_image(f, method=method_num)\n            out_objs2, out_inx_unused2, A_out_objs_attr2 = idntfy_objs_image(g, method=method_num)\n            in_objs3, in_inx_unused3, A_in_objs_attr3 = idntfy_objs_image(d, method=method_num)\n            out_objs3, out_inx_unused3, A_out_objs_attr3 = idntfy_objs_image(e, method=method_num)\n            aINs_unchgd.append(A_in_objs_attr2[0])\n            aOUTs_unchgd.append(A_out_objs_attr2[0])\n            aINs_chgd.append(A_in_objs_attr3[0])\n            aOUTs_chgd.append(A_out_objs_attr3[0])\n        except:\n            pass\n        aINs.append(A_in_objs_attr[0])\n        aOUTs.append(A_out_objs_attr[0])\n        pair = [A_in_objs_attr[0], A_out_objs_attr[0]]\n        aPAIRs.append(pair)\n    attr_task={'aINs': aINs, 'aOUTs': aOUTs, 'aPAIRs': aPAIRs, 'aTEST_PAIR': aTEST_PAIR,\n               'aINs_unchgd': aINs_unchgd, 'aOUTs_unchgd': aOUTs_unchgd, \n               'aINs_chgd': aINs_chgd, 'aOUTs_chgd': aOUTs_chgd}\n    return  attr_task\n\ndef get_object_similarity(aINs, aOUTs, origin_in = [0,0], origin_out = [0,0], similar_methd = 1):\n    \"\"\"this function outputs a similarity matrix where aOUTs objects are rows, aINs are columns and the [i,j] value is their similarity\"\"\"\n    #note for origins: [-4,-6] values should only be negative (-matrixheight/2 is likely)\n    num_examples = len(aOUTs)\n    all_outs_by_ins = []\n    for train_pair in range(num_examples):\n        aOUTS_this_pair = aOUTs[train_pair] \n        aINS_this_pair = aINs[train_pair] \n        num_input_obj = len(aINs[train_pair]['in_obj'][0])\n        num_output_obj = len(aOUTS_this_pair['pixel_count'][0])\n        outs_by_ins = [] #this will be the answer matrix with input objects on one axis and output objects on the other axis\n        outs_by_ins = np.zeros((num_output_obj, num_input_obj), dtype = object)\n        outs_by_ins_detailed = [] #this will be the answer matrix with input objects on one axis and output objects on the other axis\n        outs_by_ins_detailed = np.zeros((num_output_obj, num_input_obj), dtype = object)\n        for out_obj_num in range(num_output_obj):\n            o_shape = aOUTS_this_pair['shape'][0][out_obj_num]\n            o_obj = aOUTS_this_pair['in_obj'][0][out_obj_num]\n            o_x_coord = aOUTS_this_pair['x_coord'][0][out_obj_num]\n            o_y_coord = aOUTS_this_pair['y_coord'][0][out_obj_num]\n            o_x_coord = o_x_coord + origin_in[0] #re-adjust for origin\n            o_y_coord = o_y_coord + origin_in[1]\n            o_mn_color = aOUTS_this_pair['main_color'][0][out_obj_num]\n            o_pxl_cnt = aOUTS_this_pair['pixel_count'][0][out_obj_num]\n            o_uniq_clrs = sorted(aOUTS_this_pair['unique_colors'][0][out_obj_num])\n            for in_obj_num in range(num_input_obj):\n                shape_similarity = 0\n                color_similarity = 0\n                location_similarity = 0\n                sim_total = 0\n                #print('in_obj_number', in_obj_num)\n                i_shape = aINS_this_pair['shape'][0][in_obj_num]\n                i_obj = aINS_this_pair['in_obj'][0][in_obj_num]\n                #print('i_shape', i_shape)\n                i_x_coord = aINS_this_pair['x_coord'][0][in_obj_num]\n                i_y_coord = aINS_this_pair['y_coord'][0][in_obj_num]\n                i_x_coord = i_x_coord + origin_out[0] #re-adjust for origin\n                i_y_coord = i_y_coord + origin_out[1]\n                i_mn_color = aINS_this_pair['main_color'][0][in_obj_num]\n                i_pxl_cnt = aINS_this_pair['pixel_count'][0][in_obj_num]\n                i_uniq_clrs = sorted(aOUTS_this_pair['unique_colors'][0][out_obj_num])\n                #SHAPE: Check if same or similar\n                #FIRST CHECK IF OBJ IS EXACTLY THE SAME.\n                get_similarity = TWO_COMPARE_ALL_PERM(o_shape, i_shape) #returns [size, same, perm, perm_funcs]\n                pxl_cnt_diff = abs((o_pxl_cnt - i_pxl_cnt)/o_pxl_cnt)\n                if are_two_images_equals(o_obj, i_obj) == True:#if objs are identical in every way\n                    shape_similarity = 100\n                elif get_similarity[1] == True: #if obj shapes are identical\n                    shape_similarity = 100\n                elif get_similarity[2] == True: #if obj in a different orientation, or flipped\n                    #TODO: add code for if no other object exists , \n                    #then shape similarity for this part should be much higher           \n                    shape_similarity = 50\n                elif pxl_cnt_diff < 0.1:\n                    shape_similarity = 10\n                #COLOR: Check if same or similar\n                i_uniq_clrs = len(aINS_this_pair['unique_colors'][0])\n                o_uniq_clrs = len(aOUTS_this_pair['unique_colors'][0]) \n                uniq_clrs_diff = abs((o_uniq_clrs - i_uniq_clrs)/o_uniq_clrs)\n                if i_mn_color == o_mn_color:\n                    color_similarity = 100\n                elif uniq_clrs_diff == 0 and o_uniq_clrs > 2:\n                    #TODO: add code for if differences in color changes were already \n                    #determined to be the same object, then higher score\n                    color_similarity = 20\n                #LOCATION: Check if same or similar\n                x_diff = abs(o_x_coord - i_x_coord)\n                y_diff = abs(o_y_coord - i_y_coord)\n                if x_diff == 0 and y_diff == 0:\n                    location_similarity = 100\n                elif x_diff == 0 or y_diff == 0:\n                    location_similarity = 90\n                elif x_diff <= 1 and y_diff <= 1:\n                    location_similarity = 40\n                elif x_diff <= 3 and y_diff <= 3 and aOUTS_this_pair['width'][0][out_obj_num]>3 and aOUTS_this_pair['height'][0][out_obj_num]>3:\n                    location_similarity = 20\n                elif x_diff <= 1 or y_diff <= 1:\n                    location_similarity = 20\n                #TODO: add location similarity for various origins, such as center of the image\n                #TODO !!! change x and y location of each object to be the center of the object, not the top left.\n                #if origin_location == 'likely center', then use center origins for diff calcs\n                #Calculate overall similarity score\n                s_sim = shape_similarity\n                c_sim = color_similarity\n                l_sim = location_similarity\n                if similar_methd == 1: #for example, method 2 could be to value location very highly\n                    s_sim_weight = 40\n                    c_sim_weight = 40\n                    l_sim_weight = 19\n                if similar_methd == 2: #for example, method 2 could be to value location very highly\n                    s_sim_weight = 9\n                    c_sim_weight = 45\n                    l_sim_weight = 45\n                if similar_methd == 3: #for example, method 2 could be to value location very highly\n                    s_sim_weight = 45\n                    c_sim_weight = 9\n                    l_sim_weight = 45\n                if similar_methd == 4: #for example, method 2 could be to value location very highly\n                    s_sim_weight = 45\n                    c_sim_weight = 45\n                    l_sim_weight = 9\n                if similar_methd == 5: #Random weight method\n                    s = randint(1, 100)\n                    c = randint(1, 100)\n                    l = randint(1, 100)\n                    t = s + c + l \n                    s_sim_weight = int(s/t*100)\n                    c_sim_weight = int(c/t*100)\n                    l_sim_weight = int(l/t*100)\n                    x = s_sim_weight + c_sim_weight + l_sim_weight\n                    if x==98:\n                        s_sim_weight = s_sim_weight+1\n                    if x==100:\n                        s_sim_weight = s_sim_weight-1\n                    if x==101:\n                        s_sim_weight = s_sim_weight-2\n                sim_total = (s_sim*s_sim_weight + c_sim*c_sim_weight + l_sim*l_sim_weight)/100\n                outs_by_ins[out_obj_num][in_obj_num] = sim_total #['sim_total', sim_total, s_sim, c_sim, l_sim]\n                d = np.array([sim_total, s_sim, c_sim, l_sim])\n                f = np.array([out_obj_num, in_obj_num])\n                e = [d,f]\n                outs_by_ins_detailed[out_obj_num][in_obj_num] = e\n        all_outs_by_ins.append(outs_by_ins)\n        #For debug, uncomment the below line to see the detailed color, loc, etc. similarities\n        #all_outs_by_ins.append(outs_by_ins_detailed)\n    #the output is in the format [total similarity, shape similrty, color similrty, locatn similrty]\n    all_outs_by_ins = np.array(all_outs_by_ins)\n    for t in range(len(all_outs_by_ins)):\n        all_outs_by_ins[t] = all_outs_by_ins[t].astype(int)\n    #all_outs_by_ins = all_outs_by_ins.astype(int)\n    return all_outs_by_ins\n\ndef split_dict_objs(dict_objs, obj_num_list): \n    #removes all objects not in obj_num_list, e.g. obj_num_list = [0,1,2]\n    temp_dict = []\n    temp_dict = dict.fromkeys(dict_objs)\n    for key in sorted(dict_objs.keys()):\n        temp_dict[key] = []\n        for j in obj_num_list:\n            temp_dict[key].append(dict_objs[key][0][j])\n        temp_dict[key] = [temp_dict[key]]\n    return temp_dict\n#x = split_dict_objs(aOUTs[0], obj_num_list=[0,1,2])\n\nkey_list_to_reduce = (['in_obj_width','in_obj_height', 'in_obj_pixel_count', 'in_obj_size', 'in_obj_main_color','in_obj', 'input obj num','x_coord', 'y_coord'])  #,, 'train_pair', 'function', 'function_param','in_obj_unique_colors',  'funct_and_param', 'new_obj',\ndef remove_keyvalues_if_in_second_dict(dict1, dict2, key_list_to_reduce_ = key_list_to_reduce):\n    #removes any keyvalues from first dictionary if they are present in the second dict\n    failures_copy = copy.deepcopy(dict1)\n    failures_copy['keys_sometimes_fail_or_succeed'] = []\n    failures_copy['keyname_sometimes_fail_or_succeed'] = []\n    successes_copy = copy.deepcopy(dict2)\n    for i in range(len((key_list_to_reduce_))):\n        key_name = key_list_to_reduce_[i]\n        try:\n            if failures_copy[key_name] == None or failures_copy[key_name] == []:\n                continue\n        except:\n            continue\n        failures_copy2 = copy.deepcopy(failures_copy)\n        fail_key_values = failures_copy2[key_name]\n        #if rule never fails then no need to try and remove failures, because they don't exist\n        success_key_values = successes_copy[key_name]\n        try:\n            if successes_copy[key_name] == None or successes_copy[key_name] == []:\n                continue\n        except:\n            continue\n        unique_success_values = unique_objects_in_listKEY(success_key_values)\n        unique_success_values = unique_objects_in_listKEY(success_key_values)\n        for value_fail in fail_key_values:\n        \n        #TODO: #as currently set up, as objects are removed, then the indexes will become incorrect, so need to removed them a different way\n\n            for value_succeed in unique_success_values:\n                try:\n                    if value_fail == value_succeed:\n                        #print('removing', value_fail, 'from', key_name)\n                        if 'keys_sometimes_fail_or_succeed' not in failures_copy.keys():\n                            failures_copy['keys_sometimes_fail_or_succeed'] = [[key_name, value_fail]]\n                            failures_copy['keyname_sometimes_fail_or_succeed'] = [key_name]\n                        else:\n                            failures_copy[\"keys_sometimes_fail_or_succeed\"].append([key_name, value_fail])\n                            failures_copy[\"keyname_sometimes_fail_or_succeed\"].append(key_name)\n                        failures_copy[key_name].remove(value_fail)\n                except:\n                    x = [value_fail, value_succeed]\n                    x2 = unique_objects_in_listKEY(x)\n                    if len(x2) < len(x): #if the values are identical\n                        #print('removing', value_fail, 'from', key_name)\n                        if 'keys_sometimes_fail_or_succeed' not in failures_copy.keys():\n                            failures_copy['keys_sometimes_fail_or_succeed'] = [[key_name, value_fail]]\n                            failures_copy['keyname_sometimes_fail_or_succeed'] = [key_name]\n                        else:\n                            failures_copy[\"keys_sometimes_fail_or_succeed\"].append([key_name, value_fail])\n                            failures_copy[\"keyname_sometimes_fail_or_succeed\"].append(key_name)\n                        try:\n                            remove_array_from_list(failures_copy[key_name], value_fail)\n                        except Exception as e:\n                            print('Error: spot 1:', e)\n                            try:\n                                failures_copy[key_name].remove(value_fail)   #this fails if it is in_obj that the value is being removed from\n                            except Exception as e:\n                                print('Error: spot 2:', e)\n    return failures_copy\n\ndef remove_array_from_list(base_array, test_array):\n    for index in range(len(base_array)):\n        if np.array_equal(base_array[index], test_array):\n            base_array.pop(index)\n            break\n    return base_array\n\ndef remove_empty_keys(dict_original):\n    dict1 = copy.deepcopy(dict_original)\n    for key in list(dict1):\n        if dict1[key] == [] or dict1[key] == None:\n            del dict1[key]\n    return dict1\n\ndef unique_objects_in_listKEY(key_values_or_list): #works for objects\n    \"\"\"equivalent of list.unique, but also works for objects\"\"\"\n    s_string_not_usable = set()\n    unique_objects = []\n    for value_ in key_values_or_list:\n        for i in range(len(key_values_or_list)):\n            if str(value_) not in s_string_not_usable:\n                s_string_not_usable.add(str(value_))\n                unique_objects.append(value_)\n    return unique_objects\n\ndef match_objs_get_diffs(aINs2, aOUTS2, asimilarity_allpairs, key_list_to_reduce_ = key_list_to_reduce, method = 1):\n    \"\"\" matches output objects with closest input object, then \n    compares differences in their attributes/features\"\"\"\n    exact_matches = [] #in the form of [out_obj_num, in_obj_num]\n    exact_matches_not = []\n    answer = [] #outputs all the different attributes for each matched obj pair in each training pair\n    # object, OR match only with \"objects that haven't been paired yet.\"\n    for train_pair in range(len(aOUTS2)):\n        t = [] # list of keys that are different for the input/ouput object pair.\n        diffs = []\n        for out_obj_num in range(len(aOUTS2[train_pair]['pixel_count'][0])):    #get closest-in-similarity input object to this output object\n            input_obj_clst = asimilarity_allpairs[train_pair][out_obj_num]\n            #MATCH THE OUTPUT OBJECTS TO INPUT OBJECTS: \n                 #highest similarity method:\n            #get the input object number of the closest-in-similarity input object\n            #TODO: add other obj matching methods: e.g. match with the second most similar obj\n            in_obj_num_clse = np.argmax(input_obj_clst) \n            if max(input_obj_clst) > 98: #if exact match (equals 99), then skip?\n                exact_matches.append([out_obj_num, in_obj_num_clse, train_pair])\n                continue\n            else:\n                exact_matches_not.append([out_obj_num, in_obj_num_clse, train_pair])\n            in_obj_dict = split_dict_objs(aINs2[train_pair], [in_obj_num_clse]) #make dict of only the input obj\n            out_obj_dict = split_dict_objs(aOUTS2[train_pair], [out_obj_num]) #make dict of only the output obj\n            #TODO !!!! modify previous dict compare function that removes all duplicates from the output and input dictionaries\n            key_list_to_reduce___ = list(out_obj_dict.keys())\n            diff_keys = remove_keyvalues_if_in_second_dict(in_obj_dict, out_obj_dict, key_list_to_reduce___)\n            diff_keys = remove_empty_keys(diff_keys)\n            if 'keys_sometimes_fail_or_succeed' in diff_keys:\n                del diff_keys['keys_sometimes_fail_or_succeed']\n            if 'keyname_sometimes_fail_or_succeed' in diff_keys:\n                del diff_keys['keyname_sometimes_fail_or_succeed']\n            diffs = copy.deepcopy(diff_keys)\n            for key_nam in list(diff_keys.keys()):\n                if len(aOUTS2[train_pair][key_nam]) != 0:\n                    in_key_val = aINs2[train_pair][key_nam][0][in_obj_num_clse]\n                    out_key_val = aOUTS2[train_pair][key_nam][0][out_obj_num]\n                    diffs[key_nam] = [[in_key_val], [out_key_val]]\n            t.append([diffs, 'out_obj_num', out_obj_num, 'in_obj_num_clse', in_obj_num_clse, 'train_pair', train_pair])   #t is the list of differences between the output and input object\n        answer.append(t) #answer is the list of changed attrs for each object pair.\n    return [answer, exact_matches, exact_matches_not]\n\ndef get_orgnzd_obj_prs_method2(answer, attrs_solved_for = [], keys_check = ['height',\n                                                                            'width',\n                                                                            'pixel_count',\n                                                                            'size',\n                                                                            'unique_colors',\n                                                                            'in_obj',\n                                                                            'x_coord',\n                                                                            'y_coord',\n                                                                            'shape',\n                                                                            'main_color']): \n    #attrs_solved_for can be passed to this so that those attrs are ignored because already solved for earlier\n    \"\"\"separates list of changed attributes of object pairs (answer) \n    into lists of pairs with same attribute changed.\"\"\"\n    answer_2 = []\n    for i in range(10): #searching for list of attributes that are the shortest in length first\n        for key_name_1 in keys_check:\n            key_0_combined = []\n            split_objs = []\n            for train_pair in range(len(answer)):\n                for obj_pair in range(len(answer[train_pair])):\n                    key_list = sorted(list(answer[train_pair][obj_pair][0].keys()))\n                    if key_name_1 in key_list:\n                        if len(key_list) == i:\n                            if len(key_0_combined) == 0: #if original hasn't been added yet.\n                                key_0_combined = [answer[train_pair][obj_pair]]\n                            else:\n                                key_0_combined.append(answer[train_pair][obj_pair])\n            if len(key_0_combined) != 0:\n                answer_2.append([[[key_name_1]], key_0_combined, split_objs])              \n    #split_dict_objs(#dict_objs, obj_num_list)       \n    return answer_2\n\ndef reorganize_key_values_for_rule_extraction(aaa2_orgnzd_obj_pairs):\n    \"\"\"This, for purposes of rule extraction, reorganizes key values in aaa2_orgnzd_obj_pairs.\"\"\"\n    #method 1 is by matching keys within that key list\n    total_appnded = []\n    total_train_pr_trackd = []\n    for key_list in range(len(aaa2_orgnzd_obj_pairs)):\n        key_val_appnded = []\n        train_pr_trackd = []\n        key_name = aaa2_orgnzd_obj_pairs[key_list][0][0][0]\n        #for key_num in range(len(aaa2_orgnzd_obj_pairs[key_list][0][0])):\n            #key_name = aaa2_orgnzd_obj_pairs[key_list][0][0][key_num]\n        for obj_pair in range(len(aaa2_orgnzd_obj_pairs[key_list][1])):\n            try:\n                # key_values = aaa2_orgnzd_obj_pairs[key_list][1][obj_pair][0][key_name]\n                # train_pair_num = aaa2_orgnzd_obj_pairs[key_list][1][obj_pair][6]\n                key_values = aaa2_orgnzd_obj_pairs[key_list][1][obj_pair][0][key_name]\n                train_pair_num = aaa2_orgnzd_obj_pairs[key_list][1][obj_pair][6]\n            except:\n                key_values = []\n            key_val_appnded.append(key_values)\n            train_pr_trackd.append(train_pair_num)\n        total_appnded.append([key_name, key_val_appnded])\n        total_train_pr_trackd.append([key_name, train_pr_trackd])\n    #TODO: write code that can accommodate 'training-pair-specific rules' by using total_train_pr_trackd \n    return [total_appnded, total_train_pr_trackd]\n\ndef get_simple_rule(amatrix_dims):\n    \"\"\"extracts a simple rule for an attribute, # e.g. rule is ('add this much', 4)\"\"\"\n    ##modified to work in format below for ANY attr, not just height:\n    #amatrix_dims = {'in_key': [[1], [2]], \n                 #  'out_key': [[5], [6]]}   \n    matrix_height_is_a_mult_of_input = False\n    multiplier_height = []\n    addition_height = []\n    answer_height = 'unknown'\n    height_param = 30\n    x = sorted(list(amatrix_dims.keys())) #the input key must be listed first alphabetically\n    key_attr_in = x[0]\n    key_attr_out = x[1]\n    num_examples = len(amatrix_dims[key_attr_in])\n        #make sure num_examples is outputting correct length, not just one.\n    for i in range(num_examples):\n        in_height = amatrix_dims[key_attr_in][i]\n        out_height = amatrix_dims[key_attr_out][i]\n        try:\n            if len(in_height) >= 1:\n                in_height = in_height[0]\n        except:\n            pass\n        try:\n            if len(out_height) >= 1:\n                out_height = out_height[0]\n        except:\n            pass\n        mult_height = out_height / in_height\n        multiplier_height.append(mult_height)\n        add_height = out_height - in_height\n        addition_height.append(add_height)\n    mult_height_unique = np.unique(multiplier_height)\n    if len(mult_height_unique) == 1:\n        matrix_height_is_a_mult_of_input = True\n        answer_height = 'multiply by'\n        height_param = mult_height_unique[0]\n    matrix_height_is_static = False\n    #TODO: make this work for objects too, by using unique_obj codde that doesn't fail, made elsewhere\n    #an also putting these other if statements in try blocks so it can still get 'static' right at least\n    height_unique = np.unique(amatrix_dims[key_attr_out])\n    if len(height_unique) == 1:\n        matrix_height_is_static = True\n        answer_height = 'static'\n        height_param = int(height_unique[0])\n    add_height_unique = np.unique(addition_height)\n    if len(add_height_unique) == 1:\n        answer_height = 'add this much'\n        height_param = add_height_unique[0]\n    return answer_height, height_param\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%\n######   TESTING ON A TASK  ###############\n#task_num = 30\nfor task_num in [30, 7, 29]:\n    arc = ARC_solver(task_num)\n    task = train_tasks[task_num] \n    print('task number :', task_num)\n    plot_task(task)\n    attr_task = get_attr_task(task_num)\n    aINs = attr_task['aINs']\n    aOUTs = attr_task['aOUTs']\n    aOUTs_chgd = attr_task['aOUTs_chgd']\n    aINs_chgd = attr_task['aINs_chgd']\n    asimilarity_allpairs = get_object_similarity(aINs, aOUTs, similar_methd = 4) \n    answer_exacts_nonexacts = match_objs_get_diffs(aINs, aOUTs, asimilarity_allpairs)\n    answer = answer_exacts_nonexacts[0]\n    exact_matches = answer_exacts_nonexacts[1]\n    exact_matches_not = answer_exacts_nonexacts[2]\n    aaa2_orgnzd_obj_pairs = get_orgnzd_obj_prs_method2(answer)  #WORKS for two attributes\n    total_appnded = reorganize_key_values_for_rule_extraction(aaa2_orgnzd_obj_pairs)[0] #only works for first key in list\n\n\n    print('object similarity chart for all training pairs is:')\n    print(asimilarity_allpairs)\n\n    # This caculates rule and prints it. e.g. the rule for y_coord is: ('static', 12)\n    for attr in range(len(total_appnded)):\n        aa = []\n        bb = []\n        aa = np.atleast_2d(total_appnded[attr][1])\n        key_name = total_appnded[attr][0]\n        if aa.shape[1] > 0:\n            bb = aa.transpose()\n            try:\n                dict_new = {'in_key': bb[0][0], \n                            'out_key': bb[0][1]} \n                aaaaa2 = get_simple_rule(dict_new)\n                # print(dict_new)\n                print('the rule for', key_name, 'is:', aaaaa2)\n            except:\n                print('ERROR 112: the rule for', key_name, 'is:', aaaaa2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}