{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this approach we use Bag of decision trees.\n**Features:**\n\nSurrouding cells for a given cell.\n\n**Data Augmentation**\n* Background color is detected using custom logic.\n* Custom logic is written to find the colors which need to be excempted from augmentation.\n * All the colors which are present in all the input of training exmaples are marked for excemption.\n * Color which is not present in input but present in output are excepted.\n* For rest of colors all permutations are used to augment.\n\n**Model** \n\n Bag of decision trees are used since, single decision tree have some randomness factor which may give incorrect result.\n \n **Result**\n \n Training: Solved 41/400\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport json\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom itertools import product\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom itertools import combinations,permutations\nfrom sklearn.tree import *\nfrom sklearn import tree\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\nimport random\nfrom math import floor\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_path = Path(\"/kaggle/input/abstraction-and-reasoning-challenge\")\ntrain_path = data_path/'training'\ntest_path = data_path/'test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_result(inp,eoup,oup):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n    \n    axs[0].imshow(inp, cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Input')\n\n    axs[1].imshow(eoup, cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Output')\n    \n    axs[2].imshow(oup, cmap=cmap, norm=norm)\n    axs[2].axis('off')\n    axs[2].set_title('Model prediction')\n    \n    plt.grid()\n    plt.tight_layout()\n    plt.show()\n\ndef plot_mats(mats):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, len(mats), figsize=(15,15))\n    \n    for i in range(len(mats)):\n        axs[i].imshow(mats[i], cmap=cmap, norm=norm)\n        axs[i].axis('off')\n        axs[i].set_title('Fig: '+str(i))\n    \n    plt.rc('grid', linestyle=\"-\", color='white')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getiorc(pair):\n    inp = pair[\"input\"]\n    return pair[\"input\"],pair[\"output\"],len(inp),len(inp[0])\n    \ndef getAround(i,j,inp,size=1):\n    #v = [-1,-1,-1,-1,-1,-1,-1,-1,-1]\n    r,c = len(inp),len(inp[0])\n    v = []\n    sc = [0]\n    for q in range(size):\n        sc.append(q+1)\n        sc.append(-(q+1))\n    for idx,(x,y) in enumerate(product(sc,sc)):\n        ii = (i+x)\n        jj = (j+y)\n        v.append(-1)\n        if((0<= ii < r) and (0<= jj < c)):\n            v[idx] = (inp[ii][jj])\n    return v\n\ndef getDiagonal(i,j,r,c):\n    return\n        \n    \ndef getX(inp,i,j,size):\n    z = []\n    n_inp = np.array(inp)\n    z.append(i)\n    z.append(j)\n    r,c = len(inp),len(inp[0])\n    for m in range(5):\n        z.append(i%(m+1))\n        z.append(j%(m+1))\n    z.append(i+j)\n    z.append(i*j)\n#     z.append(i%j)\n#     z.append(j%i)\n    z.append((i+1)/(j+1))\n    z.append((j+1)/(i+1))\n    z.append(r)\n    z.append(c)\n    z.append(len(np.unique(n_inp[i,:])))\n    z.append(len(np.unique(n_inp[:,j])))\n    arnd = getAround(i,j,inp,size)\n    z.append(len(np.unique(arnd)))\n    z.extend(arnd)\n    return z\n\ndef getXy(inp,oup,size):\n    x = []\n    y = []\n    r,c = len(inp),len(inp[0])\n    for i in range(r):\n        for j in range(c):\n            x.append(getX(inp,i,j,size))\n            y.append(oup[i][j])\n    return x,y\n    \ndef getBkgColor(task_json):\n    color_dict = defaultdict(int)\n    \n    for pair in task_json['train']:\n        inp,oup,r,c = getiorc(pair)\n        for i in range(r):\n            for j in range(c):\n                color_dict[inp[i][j]]+=1\n    color = -1\n    max_count = 0\n    for col,cnt in color_dict.items():\n        if(cnt > max_count):\n            color = col\n            max_count = cnt\n    return color","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_num_colors(inp,oup,bl_cols):\n    r,c = len(inp),len(inp[0])\n    return \n\ndef replace(inp,uni,perm):\n    # uni = '234' perm = ['5','7','9']\n    #print(uni,perm)\n    r_map = { int(c):int(s) for c,s in zip(uni,perm)}\n    r,c = len(inp),len(inp[0])\n    rp = np.array(inp).tolist()\n    #print(rp)\n    for i in range(r):\n        for j in range(c):\n            if(rp[i][j] in r_map):\n                rp[i][j] = r_map[rp[i][j]]\n    return rp\n            \n    \ndef augment(inp,oup,bl_cols):\n    cols = \"0123456789\"\n    npr_map = [1,9,72,3024,15120,60480,181440,362880,362880]\n    uni = \"\".join([str(x) for x in np.unique(inp).tolist()])\n    for c in bl_cols:\n        cols=cols.replace(str(c),\"\")\n        uni=uni.replace(str(c),\"\")\n\n    exp_size = len(inp)*len(inp[0])*npr_map[len(uni)]\n    \n    mod = floor(exp_size/120000)\n    mod = 1 if mod==0 else mod\n    \n    #print(exp_size,mod,len(uni))\n    result = []\n    count = 0\n    for comb in combinations(cols,len(uni)):\n        for perm in permutations(comb):\n            count+=1\n            if(count % mod == 0):\n                result.append((replace(inp,uni,perm),replace(oup,uni,perm)))\n    return result\n            \ndef get_flips(inp,oup):\n    result = []\n    n_inp = np.array(inp)\n    n_oup = np.array(oup)\n    result.append((np.fliplr(inp).tolist(),np.fliplr(oup).tolist()))\n    result.append((np.rot90(np.fliplr(inp),1).tolist(),np.rot90(np.fliplr(oup),1).tolist()))\n    result.append((np.rot90(np.fliplr(inp),2).tolist(),np.rot90(np.fliplr(oup),2).tolist()))\n    result.append((np.rot90(np.fliplr(inp),3).tolist(),np.rot90(np.fliplr(oup),3).tolist()))\n    result.append((np.flipud(inp).tolist(),np.flipud(oup).tolist()))\n    result.append((np.rot90(np.flipud(inp),1).tolist(),np.rot90(np.flipud(oup),1).tolist()))\n    result.append((np.rot90(np.flipud(inp),2).tolist(),np.rot90(np.flipud(oup),2).tolist()))\n    result.append((np.rot90(np.flipud(inp),3).tolist(),np.rot90(np.flipud(oup),3).tolist()))\n    result.append((np.fliplr(np.flipud(inp)).tolist(),np.fliplr(np.flipud(oup)).tolist()))\n    result.append((np.flipud(np.fliplr(inp)).tolist(),np.flipud(np.fliplr(oup)).tolist()))\n    return result\n    \ndef gettaskxy(task_json,aug,around_size,bl_cols,flip=True):    \n    X = []\n    Y = []\n    for pair in task_json['train']:\n        inp,oup=pair[\"input\"],pair[\"output\"]\n        tx,ty = getXy(inp,oup,around_size)\n        X.extend(tx)\n        Y.extend(ty)\n        if(flip):\n            for ainp,aoup in get_flips(inp,oup):\n                tx,ty = getXy(ainp,aoup,around_size)\n                X.extend(tx)\n                Y.extend(ty)\n                if(aug):\n                    augs = augment(ainp,aoup,bl_cols)\n                    for ainp,aoup in augs:\n                        tx,ty = getXy(ainp,aoup,around_size)\n                        X.extend(tx)\n                        Y.extend(ty)\n        if(aug):\n            augs = augment(inp,oup,bl_cols)\n            for ainp,aoup in augs:\n                tx,ty = getXy(ainp,aoup,around_size)\n                X.extend(tx)\n                Y.extend(ty)\n    return X,Y\n\ndef test_predict(task_json,model,size):\n    inp = task_json['test'][0]['input']\n    eoup = task_json['test'][0]['output']\n    r,c = len(inp),len(inp[0])\n    oup = predict(inp,model,size)\n    return inp,eoup,oup\n\ndef predict(inp,model,size):\n    r,c = len(inp),len(inp[0])\n    oup = np.zeros([r,c],dtype=int)\n    for i in range(r):\n        for j in range(c):\n            x = getX(inp,i,j,size)\n            o = int(model.predict([x]))\n            o = 0 if o<0 else o\n            oup[i][j]=o\n    return oup\n\ndef submit_predict(task_json,model,size):\n    pred_map = {}\n    idx=0\n    for pair in task_json['test']:\n        inp = pair[\"input\"]\n        oup = predict(inp,model,size)\n        pred_map[idx] = oup.tolist()\n        idx+=1\n        plot_result(inp,oup,oup)\n    return pred_map\n\ndef dumb_predict(task_json):\n    pred_map = {}\n    idx=0\n    for pair in task_json['test']:\n        inp = pair[\"input\"]\n        pred_map[idx] = [[0,0],[0,0]]\n        idx+=1\n    return pred_map\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_loss(model,task_json,size):\n    total = 0\n    for pair in task_json['train']:\n        inp,oup=pair[\"input\"],pair[\"output\"]\n        eoup = predict(inp,model,size)\n        total+= np.sum((np.array(oup) != np.array(eoup)))\n    return total\n\ndef get_test_loss(model,task_json,size):\n    total = 0\n    for pair in task_json['test']:\n        inp,oup=pair[\"input\"],pair[\"output\"]\n        eoup = predict(inp,model,size)\n        total+= np.sum((np.array(oup) != np.array(eoup)))\n    return total\n\ndef get_a_size(task_json):\n    return 4;\n\ndef get_bl_cols(task_json):\n    result = []\n    bkg_col = getBkgColor(task_json);\n    result.append(bkg_col)\n    # num_input,input_cnt,num_output,output_cnt\n    met_map = {}\n    for i in range(10):\n        met_map[i] = [0,0,0,0]\n        \n    total_ex = 0\n    for pair in task_json['train']:\n        inp,oup=pair[\"input\"],pair[\"output\"]\n        u,uc = np.unique(inp, return_counts=True)\n        inp_cnt_map = dict(zip(u,uc))\n        u,uc = np.unique(oup, return_counts=True)\n        oup_cnt_map = dict(zip(u,uc))\n        \n        for col,cnt in inp_cnt_map.items():\n            met_map[col][0] = met_map[col][0] + 1\n            met_map[col][1] = met_map[col][1] + cnt\n        for col,cnt in oup_cnt_map.items():\n            met_map[col][2] = met_map[col][2] + 1\n            met_map[col][3] = met_map[col][3] + cnt\n        total_ex+=1\n    \n    for col,met in met_map.items():\n        num_input,input_cnt,num_output,output_cnt = met\n        if(num_input == total_ex or num_output == total_ex):\n            result.append(col)\n        elif(num_input == 0 and num_output > 0):\n            result.append(col)\n    \n    result = np.unique(result).tolist()\n    if(len(result) == 10):\n        result.append(bkg_col)\n    return np.unique(result).tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\ndef combine_preds(tid,pm1,pm3,pm5):\n    result = []\n    for i in range(len(pm1)):\n        tk_s = tid+\"_\"+str(i)\n        str_pred = flattener(pm1[i])+\" \"+flattener(pm3[i])+\" \"+flattener(pm5[i])\n        #print(tk_s,str_pred)\n        result.append([tk_s,str_pred])\n    return result\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inp_oup_dim_same(task_json):\n    return all([ len(pair[\"input\"]) == len(pair[\"output\"]) and len(pair[\"input\"][0]) == len(pair[\"output\"][0])\n                for pair in task_json['train']])\n    \n\nsolved_task = 0\ntotal_task = 0\ntask_ids = []\ntask_preds = []\nfor task_path in test_path.glob(\"*.json\"):\n    task_json = json.load(open(task_path))\n    tk_id = str(task_path).split(\"/\")[-1].split(\".\")[0]\n    print(tk_id)\n    if(inp_oup_dim_same(task_json)):\n        a_size = get_a_size(task_json)\n        bl_cols = get_bl_cols(task_json)\n        \n        isflip = False\n        X1,Y1 = gettaskxy(task_json,True,1,bl_cols,isflip)\n        X3,Y3 = gettaskxy(task_json,True,3,bl_cols,isflip)\n        X5,Y5 = gettaskxy(task_json,True,5,bl_cols,isflip)\n        \n        clf_1_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100)\n        clf_1_2 = RandomForestClassifier(n_estimators=300)\n        clf_1_3 = ExtraTreesClassifier(n_estimators=300)\n        \n        clf_2_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100)\n        clf_2_2 = RandomForestClassifier(n_estimators=300)\n        clf_2_3 = ExtraTreesClassifier(n_estimators=300)\n        \n        clf_3_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=100)\n        clf_3_2 = RandomForestClassifier(n_estimators=300)\n        clf_3_3 = ExtraTreesClassifier(n_estimators=300)\n        \n        model_1 = VotingClassifier(estimators=[('dt', clf_1_1), ('rf', clf_1_2), ('et', clf_1_3)], voting='hard').fit(X1, Y1)\n        model_3 = VotingClassifier(estimators=[('dt', clf_2_1), ('rf', clf_2_2), ('et', clf_2_3)], voting='hard').fit(X3, Y3)\n        model_5 = VotingClassifier(estimators=[('dt', clf_3_1), ('rf', clf_3_2), ('et', clf_3_3)], voting='hard').fit(X5, Y5)\n        \n        pred_map_1 = submit_predict(task_json,model_1,1)\n        pred_map_3 = submit_predict(task_json,model_3,3)\n        pred_map_5 = submit_predict(task_json,model_5,5)\n        \n        for tks,str_pred in combine_preds(tk_id,pred_map_1,pred_map_3,pred_map_5):\n            task_ids.append(tks)\n            task_preds.append(str_pred)\n            #print(tks,str_pred)\n        solved_task+=1\n        #break\n    else:\n        pred_map_1 = dumb_predict(task_json)\n        pred_map_3 = dumb_predict(task_json)\n        pred_map_5 = dumb_predict(task_json)\n        \n        for tks,str_pred in combine_preds(tk_id,pred_map_1,pred_map_3,pred_map_5):\n            task_ids.append(tks)\n            task_preds.append(str_pred)\n            #print(tks,str_pred)\n        \n    total_task+=1\n    \nsample_sub1 = pd.DataFrame({\"output_id\":task_ids,'output':task_preds})\nsample_sub1.to_csv(\"submission.csv\", index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}