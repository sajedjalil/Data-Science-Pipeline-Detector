{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1 - Introduction\n\nThe ARC competition host, Francois Chollet, suggested in his paper \"On the Measure of Intelligence\" (https://arxiv.org/abs/1911.01547) that a Domain Specific Language and program synthesis may be a good way to approach this challenge. A number of notebooks were shared with good looking DSLs, capable of encoding the solution to a number of tasks, but it quickly became apparent that the program synthesis part was going to be very hard.\n\nIt would seem ideal to create a DSL where every command does one small thing well. The power of the approach would then be in the program synthesis. However, given the time constraints for the competition and without a background in program synthesis, I thought I'd try something a little different. By making the commands do more, making them more like macros, the composition of commands became easier. This approach would likely limit the overall generality of the solution, but I hoped that as a proof of concept, it would provide a feasible approach to the challenge within the time constraints.\n\nMy initial inspiration came from noticing that many tasks require the input to be split into panels/tiles/objects and then either one panel is selected as the output, or all the panels are combined; for example by a logical operation. The split-filter-combine commands in combination therefore attacked the output smaller than input class of tasks. Although the proof of concept has been extended to have a go at all tasks, the initial split-filter-combine methodology is still very obvious in the program search code.\n\nThe code below is something of a work in progress. There are todos left to do, comments still to be written, etc. But I hope it will provide some insight and inspiration, as I'm sure  further work on ARC will continue.\n\n### 1.1 - Results and Points for Next Time\n\n* Training: 69\n* Evaluation: 61\n* Private Test: 4 (LB 0.96)\n\nSolving 4 leaderboard tasks shows this approach can work, but falls a long way short of what's need to \"solve\" ARC completely. However, it does show that a DSL employing a simple search approach cannot do very well on the ARC challenge, which was really the point of this competition.\n\nKey things I'd do differently next time.\n\n* The DSL needs to be simpler and more generic. \n* The DSL should have a reverse operation for each operation, to enable bi-directional search. \n* The interpreter's datastructure should contain hierarchical array data and keep more metadata. \n* Much more work is needed on the program synthesis part of the approach. Starting with a proper review of the current SOTA.\n* When searching for programs to solve a task, given there are errors in some training examples, allowing programs that solve all but one of the training tasks would be more robust.\n* The approach should find the 3 most likely programs to solve the task, not just the first.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport sys\nimport time\nimport operator\n\nimport json\nimport numpy as np\nimport pandas as pd\n\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom itertools import permutations\nfrom collections import Counter, namedtuple\nfrom copy import deepcopy\n\nimport datetime\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\nfrom multiprocessing import Pool","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# From: https://www.kaggle.com/nagiss/abstraction-and-reasoning-view-all-data\n\ncmap = colors.ListedColormap(\n    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n# 0:black, 1:blue, 2:red, 3:greed, 4:yellow,\n# 5:gray, 6:magenta, 7:orange, 8:sky, 9:brown\nplt.figure(figsize=(5, 2), dpi=200)\nplt.imshow([list(range(10))], cmap=cmap, norm=norm)\nplt.xticks(list(range(10)))\nplt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 - Macro Domain Specific Language\n\nThis DSL uses the syntax of: command sub-command arg1 arg2 ...\n\nThe interpreter keeps a list of numpy arrays as global data. The list is populated with an input array when program execution begins and all commands act on this global array. When a program has been executed it is expected that a single array is left in the list, and that array forms the answer to the input challenge.\n\nThe DSL is specified below in a dict, as a set of commands, with sub-commands, sub-commands with arguments. The arguments have allowed value lists. The intention is that the data structure can be used to help automate the program search step.\n\nIn hindsight, the current proof of concept doesn't make good use of the dsl dict for error handling. Also the DSL definition could have usefully had information about whether a command can increase of decrease the number of objects in the working list, or whether it will leave the length of that list the same, as such information could have helped guide the program synthesis.\n\nIn this proof of concept, error handling is mostly via asserts, so execution of a program should be within a try-catch.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Some constants used throughout. Note that although the input and output data only contains values within range(10), some\n# special values are used in this code. See map_special_values later for definitiions.\nMAX_VALUE = 14\nA_LOT = 20\nTOO_MANY = 100\nLIKELY_BACKGROUNDS = [0,10,11,12,13]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dsl = dict()\n\nCmdDef = namedtuple('CmdDef', 'subcmddict, description')\nSubCmd = namedtuple('SubCmd', 'arglist, description')\nCmdArg = namedtuple('CmdArg', 'placeholder, allowed_values')\n\n### Command: identity\ndsl['identity'] = CmdDef(dict(), \"The identity command applies the identity transform to all arrays in the working list. That is it does nothing. Just for testing, and explanation.\")\n\n\n### Command: abstract\n# TODO - Turn this into a scale command and add upscaling.\nabstract_subcmddict = dict()\nabstract_simple_arglist = [CmdArg('output_size', range(1,6))]\nabstract_subcmddict['simple'] = SubCmd(abstract_simple_arglist, \"Abstract each array in the working list to a square array of the given size, containing just the most common value from the array.\")\ndsl['abstract'] = CmdDef(abstract_subcmddict, \"The abstract command reduces each array in the working list down to some more abstract representation.\")\n\n\n### Command: assemble\nassemble_subcmddict = dict()\nassemble_original_arglist = [CmdArg('base', ['original', 'zeros', 'majority_value'])]\nassemble_subcmddict['original'] = SubCmd(assemble_original_arglist, \"Assemble all arrays in the working list by re-writing them back into their original positions, starting with the original input.\")\nassemble_auto_grid_arglist = []\nassemble_subcmddict['auto_grid'] = SubCmd(assemble_auto_grid_arglist, \"Assemble all arrays in the working list by writing them into a new grid, of automatically determnied configurationn.\")\nassemble_histogram_arglist = [CmdArg('flip', ['none', 'lr', 'ud']),\n                              CmdArg('rot90', range(4))]\nassemble_subcmddict['histogram'] = SubCmd(assemble_histogram_arglist, \"For each panel, take the majority value and create a historgram, with option flip and rotate.\")\ndsl['assemble'] = CmdDef(assemble_subcmddict, \"The assemble command builds an output input from the arrays in the working list by various methods.\")\n\n\n### Command: combine\ncombine_subcmddict = dict()\ncombine_logical_op_arglist = [CmdArg('pre_invert', [True, False]),\n                               CmdArg('logical_op', ['and', 'or', 'xor']),\n                               CmdArg('post_invert', [True, False]),\n                               CmdArg('final_colour', range(10))]\ncombine_subcmddict['logical_op'] = SubCmd(combine_logical_op_arglist, \"Combine all arrays in the working list into a single array by performing logical operations.\")\ncombine_overwrite_arglist = [CmdArg('transparent', range(11)),\n                             CmdArg('permutation', None)]\ncombine_subcmddict['overwrite'] = SubCmd(combine_overwrite_arglist, \"Combine all arrays in the working list by writing arrays in the given permutation into an output array. Later arrays overwrite early arrays. The given transparent value allows the previous output array to be seen through.\")\ndsl['combine'] = CmdDef(combine_subcmddict, \"The combine command combines all arrays in the working list into a single array by various methods.)\")\n\n\n### Command: filter\nfilter_subcmddict = dict()\nfilter_by_value_arglist = [CmdArg('action', ['remove', 'keep']),\n                           CmdArg('value', list(reversed(range(MAX_VALUE)))),\n                           CmdArg('condition', ['most', 'least', 'odd_one_out'])]\nfilter_subcmddict['by_value'] = SubCmd(filter_by_value_arglist, \"Updates the working list to keep/remove the panels with the most/least occurences of the given value.\")\nfilter_by_not_value_arglist = [CmdArg('action', ['remove', 'keep']),\n                               CmdArg('value', list(reversed(range(MAX_VALUE)))),\n                               CmdArg('condition', ['most', 'least', 'odd_one_out'])]\nfilter_subcmddict['by_not_value'] = SubCmd(filter_by_not_value_arglist, \"Updates the working list to keep/remove the panels with the most/least occurences of any value except the given value.\")\nfilter_by_value_gte_arglist = [CmdArg('action', ['remove', 'keep']),\n                               CmdArg('value', list(reversed(range(MAX_VALUE)))),\n                               CmdArg('threshold', range(5))]\nfilter_subcmddict['by_value_gte'] = SubCmd(filter_by_value_gte_arglist, \"Updates the working list to keep/remove the panels with greater than or equal to the given threshold of the given value.\")\nfilter_by_majority_value_arglist = [CmdArg('action', ['remove', 'keep']),\n                                    CmdArg('condition', ['most', 'least'])]\nfilter_subcmddict['by_majority_value'] = SubCmd(filter_by_majority_value_arglist, \"Updates the working list to keep/remove the panels where majority value is is the most or least across the working list.\")\nfilter_by_size_arglist = [CmdArg('action', ['remove', 'keep']),\n                          CmdArg('condition', ['most', 'least', 'odd_one_out'])]\nfilter_subcmddict['by_size'] = SubCmd(filter_by_size_arglist, \"Updates the working list to keep/remove the panels with largest or smallest size.\")\nfilter_unique_values_arglist = [CmdArg('action', ['remove', 'keep']),\n                                CmdArg('condition', ['most', 'least', 'odd_one_out'])]\nfilter_subcmddict['unique_values'] = SubCmd(filter_unique_values_arglist, \"Updates the working list to keep/remove the panels with the most/least unique values.\")\nfilter_by_index_arglist = [CmdArg('action', ['remove', 'keep']),\n                           CmdArg('index', range(30))]\nfilter_subcmddict['by_index'] = SubCmd(filter_by_index_arglist, \"Updates the working list to keep/remove the panels with the given index.\")\nfilter_by_shape_count_arglist = [CmdArg('action', ['remove', 'keep']),\n                                  CmdArg('shape', ['cross', 'x', 'enclosure']),\n                                  CmdArg('background', LIKELY_BACKGROUNDS),\n                                  CmdArg('condition', ['most', 'least', 'odd_one_out'])]\nfilter_subcmddict['by_shape_count'] = SubCmd(filter_by_shape_count_arglist, \"Updates the working list to keep/remove the panels with the most/least occurences of the given object.\")\nfilter_commonality_arglist = [CmdArg('action', ['remove', 'keep']),\n                              CmdArg('most_or_least', ['most', 'least'])]\nfilter_subcmddict['commonality'] = SubCmd(filter_commonality_arglist, \"Updates the working list to keep/remove the most or least common panel.\")\nfilter_has_symmetry_arglist = [CmdArg('action', ['remove', 'keep'])]\nfilter_subcmddict['has_symmetry'] = SubCmd(filter_has_symmetry_arglist, \"Updates the working list to keep/remove the panels with, depending on the argument given.\")\nfilter_rectangular_arglist = [CmdArg('action', ['remove', 'keep']),\n                               CmdArg('min_size', range(2,5))]\nfilter_subcmddict['rectangular'] = SubCmd(filter_rectangular_arglist, \"Updates the working list to keep/remove the panels which are rectangular blocks.\")\nfilter_enclosed_arglist = [CmdArg('action', ['remove', 'keep'])]\nfilter_subcmddict['enclosed'] = SubCmd(filter_enclosed_arglist, \"Updates the working list to keep/remove the panels which are enclosed within another panel.\")\ndsl['filter'] = CmdDef(filter_subcmddict, \"The filter command considers the working list and keeps or removes panels according to the given criteria.\")\n\n\n### Command: move\nmove_subcmddict = dict()\nmove_by_value_arglist = [CmdArg('value', list(reversed(range(MAX_VALUE)))),\n                         CmdArg('direction', ['N', 'E', 'S', 'W']),\n                         CmdArg('distance', range(10))]\nmove_subcmddict['by_value'] = SubCmd(move_by_value_arglist, \"Updates the top corners of the working list to move objects by the given amount depending on their main colour.\")\nmove_by_shape_arglist = [CmdArg('dimension', ['H', 'V', 'HV']),\n                         CmdArg('direction', ['SE', 'NW'])]\nmove_subcmddict['by_shape'] = SubCmd(move_by_shape_arglist, \"Updates the top corners of the working list to move objects by their width or height depending on the given dimension. Objects are move in a south/east diretion (positive) or north/west direction depending on the arguments given.\")\ndsl['move'] = CmdDef(move_subcmddict, \"Move objects in the working list.\")\n\n\n### Command: replicate\nreplicate_subcmddict = dict()\nreplicate_and_merge_arglist = [CmdArg('flip', ['none', 'lr', 'ud', 'all']),\n                               CmdArg('rotation', [True, False]),\n                               CmdArg('offset', ['none', 'auto'])]\nreplicate_subcmddict['and_merge'] = SubCmd(replicate_and_merge_arglist, \"Replicate each panel, with option flip and rotation operations, them immediately merge back into the panel.\")\nreplicate_flower_flip_arglist = [CmdArg('start_pos', range(4))]\nreplicate_subcmddict['flower_flip'] = SubCmd(replicate_flower_flip_arglist, \"Replicate each panel creating a 2x2 grid of flips. Just the starting position needs to be specified.\")\nreplicate_flower_rotate_arglist = [CmdArg('start_pos', range(4))]\nreplicate_subcmddict['flower_rotate'] = SubCmd(replicate_flower_rotate_arglist, \"Replicate each panel creating a 2x2 grid of rotations. Just the starting position needs to be specified.\")\ndsl['replicate'] = CmdDef(replicate_subcmddict, \"Replicate each panel in the working list, according to sub-command specific rules.\")\n\n                                       \n### Command: snake\nsnake_subcmddict = dict()\nsnake_simple_arglist = [CmdArg('start_value', range(12)),\n                       CmdArg('direction', ['away', 'N', 'E', 'S', 'W']),\n                       CmdArg('action_on_0', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_1', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_2', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_3', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_4', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_5', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_6', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_7', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_8', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop']),\n                       CmdArg('action_on_9', ['overwrite', 'turn_right', 'turn_left', 'around_right', 'around_left', 'around_both', 'stop'])]\nsnake_subcmddict['simple'] = SubCmd(snake_simple_arglist, \"Apply a simple snake rule.\")\ndsl['snake'] = CmdDef(snake_subcmddict, \"Draw a 'snake' starting from a given value, according to given rules.\")\n\n\n### Command: sort\nsort_subcmddict = dict()\nsort_by_value_arglist = [CmdArg('value', list(reversed(range(MAX_VALUE)))),\n                         CmdArg('ordering', ['ascending', 'descending'])]\nsort_subcmddict['by_value'] = SubCmd(sort_by_value_arglist, \"Sorts the working list by the number of occurences of a given value. Asserts if the ordering is partial.\")\nsort_unique_values_arglist = [CmdArg('ordering', ['ascending', 'descending'])]\nsort_subcmddict['unique_values'] = SubCmd(sort_unique_values_arglist, \"Sorts the working list by the number of unique values.\")\ndsl['sort'] = CmdDef(sort_subcmddict, \"The sort reorders the working list by a variety of methods.\")\n\n\n### Command: split\nsplit_subcmddict = dict()\nsplit_by_value_arglist = [CmdArg('background', range(11)),\n                          CmdArg('crop', [True, False, 'inclusive'])]\nsplit_subcmddict['by_value'] = SubCmd(split_by_value_arglist, \"Splits the input grid into a list of panels by value. The given background colour is considered as not part of any object to be extracted. The objects are extracted into arrays of size equal to the original, unless optionally cropped.\")\nsplit_fixed_grid_arglist = [CmdArg('rows', range(30)),\n                            CmdArg('columns', range(30)),\n                            CmdArg('divider', [True, False])]\nsplit_subcmddict['fixed_grid'] = SubCmd(split_fixed_grid_arglist, \"Splits the input grid into a list of panels, assumming that the panels form a grid with the given number of rows and columns. If divider is true, leave an extra row/colum after each panel.\")\nsplit_fixed_size_arglist = [CmdArg('rows', range(30)),\n                            CmdArg('columns', range(30)),\n                            CmdArg('divider', [True, False])]\nsplit_subcmddict['fixed_size'] = SubCmd(split_fixed_size_arglist, \"Splits the input grid into a list of panels, assumming that each panels has the given number of rows and columns. If divider is true, leave an extra row/colum after each panel.\")\nsplit_connected_region_arglist = [CmdArg('background', range(11)),\n                                  CmdArg('single_value', [True, False]),\n                                  CmdArg('neighbourhood', [4, 8]),\n                                  CmdArg('crop', [True, False])]\nsplit_subcmddict['connected_region'] = SubCmd(split_connected_region_arglist, \"Splits the input grid into a list of panels, based on connected regions. Extracted regions can contain a single value or multiple values, depending on the single_value argument. The given background colour is considered as not part of any object to be extracted. The objects are extracted into arrays of size equal to the original, unless optionally cropped.\")\nsplit_frame_arglist = [CmdArg('background', range(11)),\n                       CmdArg('keep_frame', [True, False])]\nsplit_subcmddict['frame'] = SubCmd(split_frame_arglist, \"Splits the input grid into a list of panels, based on finding rectangular frames in the input.\")\ndsl['split'] = CmdDef(split_subcmddict, \"The split command takes an input grid and splits it into many panels.\")\n\n\n### Command: transform\ntransform_subcmddict = dict()\ntransform_crop_arglist = [CmdArg('background', LIKELY_BACKGROUNDS)]\ntransform_subcmddict['crop'] = SubCmd(transform_crop_arglist, \"Crop all images in the working list to remove outer rows/colums of the given background colour.\")\ntransform_flip_arglist = [CmdArg('direction', ['lr', 'ud'])]\ntransform_subcmddict['flip'] = SubCmd(transform_flip_arglist, \"Flip all images in the working list, either left-right or up-down.\")\ntransform_invert_arglist = []\ntransform_subcmddict['invert'] = SubCmd(transform_invert_arglist, \"Invert all images in the working list that have 2 colours. Images with more or less than 2 colours are left untouched.\")\ntransform_rot90_arglist = [CmdArg('count', [1, 2, 3])]\ntransform_subcmddict['rot90'] = SubCmd(transform_rot90_arglist, \"Rotate all images in the working list by (count * 90) degrees.\")\ndsl['transform'] = CmdDef(transform_subcmddict, \"The transform command applies simple transforms to all the arrays in the working list.\")\n\n\n### Command: value_map\nvalue_map_subcmddict = dict()\nvalue_map_simple_arg_list = [CmdArg('from', range(MAX_VALUE)),\n                             CmdArg('to', range(MAX_VALUE))]\nvalue_map_subcmddict['simple'] = SubCmd(value_map_simple_arg_list, \"Simply apply a fixed mapping of initial values to final values for all items in the working list.\")\nvalue_map_enclosures_count_arg_list = [CmdArg('background', range(MAX_VALUE)),\n                                       CmdArg('count', range(8)),\n                                       CmdArg('value', range(10))]\nvalue_map_subcmddict['enclosures_count'] = SubCmd(value_map_enclosures_count_arg_list, \"Change the values of objects based on the count of enclosures they have.\")\nvalue_map_shape_match_arg_list = [CmdArg('source_value_not', range(10)),\n                                  CmdArg('allow_rotations', [True, False])]\nvalue_map_subcmddict['shape_match'] = SubCmd(value_map_shape_match_arg_list, \"Match panels by shape, then apply the value from a source panel to all others of the same shape.\")\ndsl['value_map'] = CmdDef(value_map_subcmddict, \"Map from initial values to final values in a variety of ways.\")\n\n\ndef dsl_usage(command=None):\n    if command is None:\n        commands = dsl.keys()\n    else:\n        commands = {command}\n        \n    for cmd in commands:\n        print(f\"Command {cmd}: {dsl[cmd].description}\")        \n        for subcmd in dsl[cmd].subcmddict.keys():\n            args = \"\"\n            for arg in dsl[cmd].subcmddict[subcmd].arglist:\n                args += f\"<{arg.placeholder}> \"\n            print(f\"\\t{cmd} {subcmd} {args}: {dsl[cmd].subcmddict[subcmd].description}\")\n        print(\"\\n\")\n        \ndsl_usage()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1 - The Interpreter\n\nThis runs programs using the DSL, and maintains the program's state.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def split_by_value(input_array, background, crop, debug=False):\n    \"\"\"\n    \"\"\"\n    panels = []\n    top_corners = []\n    values = np.unique(input_array)\n    for v in values:\n        if v != background:\n            new_panel = np.where(input_array == v, v, background)\n            if crop == 'True':\n                new_panel, top_corner = crop_background(new_panel, background)\n            elif crop == 'False':\n                top_corner = (0, 0)\n            elif crop == 'inclusive':\n                temp_panel, top_corner = crop_background(new_panel, background)\n                new_panel = input_array[top_corner[0]:top_corner[0]+temp_panel.shape[0], top_corner[1]:top_corner[1]+temp_panel.shape[1]]\n            else:\n                assert False, f\"Bad value for crop {crop} given to split by_value.\"\n            \n            panels.append(new_panel)\n            top_corners.append(top_corner)\n    if debug:        \n        print(f\"Returning {len(panels)} from split_by_value.\")\n    return panels, top_corners\n    \n\ndef split_fixed_internal(input_array, panel_rows, panel_columns, grid_rows, grid_columns, divider, debug=False):\n    \"\"\"\n    \"\"\"\n    panels = []\n    top_corners = []\n    for gr in range(grid_rows):\n        for gc in range(grid_columns):\n            if divider:\n                panel = input_array[(gr*panel_rows)+gr:((gr+1)*panel_rows)+gr,(gc*panel_columns)+gc:((gc+1)*panel_columns)+gc]\n                top_corner = ((gr*panel_rows)+gr, (gc*panel_columns)+gc)\n            else:\n                panel = input_array[(gr*panel_rows):((gr+1)*panel_rows),(gc*panel_columns):(gc+1)*panel_columns]\n                top_corner = ((gr*panel_rows), (gc*panel_columns))\n          \n            panels.append(panel)\n            top_corners.append(top_corner)\n            if debug:\n                print(f\"Panel {gr} by {gc}:\")\n                print(panel)\n    return panels, top_corners\n\ndef split_fixed_grid(input_array, rows, columns, divider, debug=False):\n    \"\"\"Given a fixed grid we can calculate the size of each panel from the input array shape.\"\"\"\n    input_rows, input_columns = input_array.shape\n    # Using floor division here means we don't need to worry about the presence of a divider.\n    panel_rows = input_rows//rows\n    panel_columns = input_columns//columns    \n    return split_fixed_internal(input_array, panel_rows, panel_columns, rows, columns, divider, debug)\n    \ndef split_fixed_size(input_array, rows, columns, divider, debug=False):\n    \"\"\"Given a fixed panel size we can calculate the dimensions of the grid of panels from the input array shape.\"\"\"\n    input_rows, input_columns = input_array.shape\n    # Using floor division here means we don't need to worry about the presence of a divider.\n    grid_rows = input_rows//rows\n    grid_columns = input_columns//columns    \n    return split_fixed_internal(input_array, rows, columns, grid_rows, grid_columns, divider, debug)\n\ndef find_region(input_array, background, region_value, object_map, visited, row, column, eight_connected=False):\n    if row < 0 or row >= input_array.shape[0] or column < 0 or column >= input_array.shape[1]:\n        return\n    \n    assert background is not None or region_value is not None, \"Can't pass None for both background and region_value.\"\n    \n    if background is None:\n        background = [x for x in range(10) if x != region_value]\n        \n    val = input_array[row,column]\n    if val in background or visited[row,column]:\n        visited[row,column] = True    \n    elif region_value is not None and val != region_value:\n        # We're looking for a region of a single value, and this is a different value. Don't mark visited\n        # as this must belong to another region.\n        pass\n    else:\n        object_map[row,column] = True\n        visited[row,column] = True\n        # Recurse\n        find_region(input_array, background, region_value, object_map, visited, row-1, column, eight_connected=eight_connected)\n        find_region(input_array, background, region_value, object_map, visited, row+1, column, eight_connected=eight_connected)\n        find_region(input_array, background, region_value, object_map, visited, row, column-1, eight_connected=eight_connected)\n        find_region(input_array, background, region_value, object_map, visited, row, column+1, eight_connected=eight_connected)\n        if eight_connected:\n            find_region(input_array, background, region_value, object_map, visited, row-1, column-1, eight_connected=True)\n            find_region(input_array, background, region_value, object_map, visited, row-1, column+1, eight_connected=True)\n            find_region(input_array, background, region_value, object_map, visited, row+1, column-1, eight_connected=True)\n            find_region(input_array, background, region_value, object_map, visited, row+1, column+1, eight_connected=True)\n            \n    \ndef crop_background(input_array, background, single_value=False, debug=False):\n    assert background < 10, \"Un-mapped special value in crop_background.\"\n\n    #print(input_array)\n    crop_coords = np.argwhere(input_array != background)\n    if len(crop_coords) == 0:\n        # Input array must have been all background.\n        return input_array, (0, 0)\n    r_min, c_min = crop_coords.min(axis=0)\n    r_max, c_max = crop_coords.max(axis=0)\n    result = input_array[r_min:r_max+1, c_min:c_max+1]\n    if single_value:\n        result = np.where(result == background, 0, result)\n    return result, (r_min, c_min)\n            \ndef split_connected_region(input_array, background, single_value, crop, eight_connected=False, debug=False):\n    \"\"\"\n    \"\"\"\n    assert background < 10, \"Un-mapped special value in split_connected_region.\"\n\n    objects = []\n    top_corners = []\n    visited = np.zeros_like(input_array, dtype=np.bool)\n    for row in range(input_array.shape[0]):\n        for column in range(input_array.shape[1]):\n            val = input_array[row,column]\n            if val == background or visited[row,column]:\n                visited[row,column] = True\n            else:\n                object_map = np.zeros_like(input_array, dtype=np.bool)\n                region_value = val if single_value else None\n                find_region(input_array, [background], region_value, object_map, visited, row, column, eight_connected=eight_connected)\n                object_array = np.where(object_map, input_array, background)\n                #if debug:\n                #    print(object_array)\n                if crop:\n                    object_array, top_corner = crop_background(object_array, background, single_value)\n                objects.append(object_array)\n                top_corners.append(top_corner)\n    if debug:\n        print(f\"Returning {len(objects)} from split_connected_region.\")\n    return objects, top_corners\n\ndef is_frame(input_array, top_corner, shape):\n    # It's a frame if all values on the boundary of the specified region are the same.\n    left_edge = np.unique(input_array[top_corner[0]:top_corner[0]+shape[0], top_corner[1]])\n    left   = len(left_edge) == 1\n    right  = np.array_equal(left_edge, np.unique(input_array[top_corner[0]:top_corner[0]+shape[0], top_corner[1]+shape[1]-1]))\n    top    = np.array_equal(left_edge, np.unique(input_array[top_corner[0], top_corner[1]:top_corner[1]+shape[1]]))\n    bottom = np.array_equal(left_edge, np.unique(input_array[top_corner[0]+shape[0]-1, top_corner[1]:top_corner[1]+shape[1]]))\n    return left, right, top, bottom\n\ndef split_frames(input_array, background, keep_frame, debug=False):\n    \"\"\"\n    \"\"\"\n    objects = []\n    top_corners = []\n    visited = np.zeros_like(input_array, dtype=np.bool)\n    \n    MIN_FRAME_SIZE = 2\n    if input_array.shape[0] < MIN_FRAME_SIZE or input_array.shape[1] < MIN_FRAME_SIZE:\n        if debug:\n            print(\"Input array too small for split_frames.\")\n        return objects, top_corners\n        \n    for row in range(input_array.shape[0]-(MIN_FRAME_SIZE-1)):\n        for column in range(input_array.shape[1]-(MIN_FRAME_SIZE-1)):\n            val = input_array[row,column]\n            if val == background or visited[row,column]:\n                visited[row,column] = True\n            else:              \n                frame_rows = MIN_FRAME_SIZE\n                frame_cols = MIN_FRAME_SIZE\n                object_array = None\n                viable_frame_rows = None\n                viable_frame_cols = None\n                left, right, top, bottom = is_frame(input_array, (row, column), (frame_rows, frame_cols))\n                while top and left and row + frame_rows <= input_array.shape[0] and column + frame_cols <= input_array.shape[1]:\n                    if np.any(visited[row:row+frame_rows,column:column+frame_cols]):\n                        # We're running over a previous frame, abort.\n                        break\n                    left, right, top, bottom = is_frame(input_array, (row, column), (frame_rows, frame_cols))\n                    if top and left and right and bottom:\n                        # Frame complete!\n                        if debug:\n                            print(f\"Found frame with value: {val} and shape ({frame_rows}, {frame_cols})\")\n                        viable_frame_rows = frame_rows\n                        viable_frame_cols = frame_cols\n                        \n                        # Don't break here, we may extend the panel further.\n                        free_move = None\n                        non_free_move = None\n                        if (row + frame_rows + 1) <= input_array.shape[0]:\n                            left2, right2, top2, bottom2 = is_frame(input_array, (row, column), (frame_rows + 1, frame_cols))\n                            if top2 and left2 and right2 and bottom2:\n                                free_move = (1, 0)\n                            if top2 and left2:\n                                non_free_move = (1, 0)\n                        if (column + frame_cols + 1) <= input_array.shape[1]:\n                            left2, right2, top2, bottom2 = is_frame(input_array, (row, column), (frame_rows, frame_cols + 1))\n                            if top2 and left2 and right2 and bottom2:\n                                free_move = (1, 1) if free_move is not None else (0, 1)\n                            if top2 and left2:\n                                non_free_move = (1, 1) if free_move is not None else (0, 1)\n                        if free_move is not None:\n                            frame_rows += free_move[0]\n                            frame_cols += free_move[1]\n                        elif non_free_move is not None:\n                            frame_rows += non_free_move[0]\n                            frame_cols += non_free_move[1]\n                        else:\n                            break\n                    else:\n                        if not right:\n                            frame_cols += 1\n                        if not bottom:\n                            frame_rows += 1\n                \n                visited[row,column] = True\n                if viable_frame_rows is not None:\n                    frame_rows = viable_frame_rows\n                    frame_cols = viable_frame_cols\n                    visited[row:row+frame_rows,column:column+frame_cols] = True\n                    if keep_frame:\n                        object_array = input_array[row:row+frame_rows,column:column+frame_cols]\n                        top_corner = (row, column)\n                    else:\n                        object_array = input_array[row+1:row+frame_rows-1,column+1:column+frame_cols-1]\n                        top_corner = (row+1, column+1)\n                    # Check for zero dimension.\n                    if object_array.shape[0] > 0 and object_array.shape[1] > 0:\n                        objects.append(object_array)\n                        top_corners.append(top_corner)\n                        \n                        \n        \n        visited[row,column] = True\n\n    if debug:\n        print(f\"Returning {len(objects)} from split_frames.\")\n    return objects, top_corners\n\ndef count_crosses_and_xes(input_array, background, diagonal, debug=False):\n    \"\"\"\n    \"\"\"\n    if background >= 10:\n        assert False, \"Special values should have been mapped already.\"\n\n    count = 0\n    # Iterate over the array, avoiding the boundary. Can't have the centre of a cross on the boundary.\n    for row in range(1,input_array.shape[0]-1):\n        for column in range(1,input_array.shape[1]-1):\n            if input_array[row,column] != background:\n                val = input_array[row,column]\n                if diagonal:\n                    if input_array[row-1,column-1] == val and input_array[row-1,column+1] == val and input_array[row+1,column-1] == val and input_array[row+1,column+1] == val:\n                        count += 1\n                else:\n                    if input_array[row-1,column] == val and input_array[row,column-1] == val and input_array[row+1,column] == val and input_array[row,column+1] == val:\n                        count += 1\n    return count\n\ndef count_enclosures(input_array, background, debug=False):\n    \"\"\"Here we going to look for 4-connected enclosed regions. That is areas of background that are enclosed and do not\n       touch the boundary.\"\"\"\n    if background >= 10:\n        assert False, \"Special values should have been mapped already.\"\n\n    count = 0\n    visited = np.zeros_like(input_array, dtype=np.bool)\n    for row in range(input_array.shape[0]):\n        for column in range(input_array.shape[1]):\n            val = input_array[row,column]\n            if val != background or visited[row,column]:\n                visited[row,column] = True\n            else:\n                object_map = np.zeros_like(input_array, dtype=np.bool)\n                find_region(input_array, None, background, object_map, visited, row, column, eight_connected=False)\n                if np.any(object_map[0,:]) or np.any(object_map[-1,:]) or np.any(object_map[:,0]) or np.any(object_map[:,-1]):\n                    # A region that tocuhes the bounday. Not an enclosure.\n                    pass\n                else:\n                    count += 1\n    if debug:\n        print(f\"Returning {count} from count_enclosures.\")\n    return count\n    \ndef get_most_common_value(input_array, ignore_zero=False):\n    values, counts = np.unique(input_array, return_counts=True)\n    sort_index = np.flip(np.argsort(counts))\n    sorted_values = values[sort_index]\n    most_common = sorted_values[0]\n    if ignore_zero and most_common == 0 and len(sorted_values) > 1:\n        most_common = sorted_values[1]\n    return most_common\n\n\ndef split_auto_grid(input_array, debug=False):\n    # Check every row and column for a unique value. Look for the most common spacing between them to get the size of panels to be extracted.\n    last_row = None\n    divider_row_spacing = []\n    for row in range(input_array.shape[0]):\n        if len(np.unique(input_array[row,:])) == 1:\n            if last_row is None:\n                spacing = row                \n            else:\n                spacing = row - last_row - 1\n            if spacing != 0:\n                divider_row_spacing.append(spacing)\n            last_row = row\n\n    last_col = None\n    divider_col_spacing = []\n    for col in range(input_array.shape[1]):\n        if len(np.unique(input_array[:,col])) == 1:\n            if last_col is None:\n                spacing = col\n            else:\n                spacing = col - last_col - 1\n            if spacing != 0:\n                divider_col_spacing.append(spacing)\n            last_col = col\n\n    if len(divider_row_spacing) == 0 and len(divider_col_spacing) == 0:\n        # No rows/columns with a unique value. Not a grid problem.\n        return [], []\n    \n    if len(divider_row_spacing) == 0:\n        panel_rows = input_array.shape[0]\n    else:\n        panel_rows = Counter(divider_row_spacing).most_common(1)[0][0]\n    if len(divider_col_spacing) == 0:\n        panel_cols = input_array.shape[1]\n    else:      \n        panel_cols = Counter(divider_col_spacing).most_common(1)[0][0]\n        \n    if debug:\n        print(f\"Extracting panels of size ({panel_rows},{panel_cols})\")\n        \n    objects = []\n    top_corners = []\n    row = 0\n    while row < input_array.shape[0]:        \n        if len(np.unique(input_array[row,:])) == 1:\n            row += 1\n        else:\n            col = 0\n            while col < input_array.shape[1]:\n                if len(np.unique(input_array[:,col])) == 1:\n                    col += 1\n                else:\n                    # Must be the start of a panel to extract.\n                    objects.append(input_array[row:row+panel_rows, col:col+panel_cols].copy())\n                    top_corners.append((row, col))\n                    col += panel_cols\n            row += panel_rows\n                \n    if debug:\n        print(f\"Returning {len(objects)} from split_auto_grid.\")\n    return objects, top_corners            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class ScoringHelper:\n    \"\"\"\n    A helper class to store scores and then choose a winner according to a given condition.\n    \"\"\"\n    \n    def __init__(self):\n        self.indicies = []\n        self.scores = []\n        \n    def add_score(self, index, score):\n        self.indicies.append(index)\n        self.scores.append(score)\n        \n    def get_winner(self, condition):\n        # TODO - Add majority and minority as conditions.\n        if condition == 'most' or condition == 'least':\n            best_score = -1 if condition == 'most' else sys.maxsize\n            best_index = None\n            for i in range(len(self.indicies)):\n                if (condition == 'most' and self.scores[i] > best_score) or \\\n                   (condition == 'least' and self.scores[i] < best_score):\n                        best_score = self.scores[i]\n                        best_index = self.indicies[i]\n                elif self.scores[i] == best_score:\n                    # The result needs to be the most or least, if some other item has the same score,\n                    # this could return a winner just based on the order the inputs were seen, which is not stable.\n                    best_index = None\n            return best_index\n        elif condition == \"odd_one_out\":\n            unique_scores = [x for x, n in Counter(self.scores).items() if n == 1]\n            if len(unique_scores) == 1:\n                return self.indicies[self.scores.index(unique_scores[0])]\n            else:\n                return None\n        else:\n            assert False, f\"Bad condition {condition}.\"\n\n    def get_ordering(self, ordering):\n        scores_tuple = zip(self.scores, self.indicies)\n        reverse = (ordering == \"descending\")\n        scores_tuple = sorted(scores_tuple, key = lambda x: x[0], reverse=reverse)\n        result = [i for s, i in scores_tuple]\n        return result\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Most progs start with a split command. Profiling shows that the majority of the runtime goes in split commands. So implement a cache.\n# The cache is only to be used if the split command is the first in the prog. I'd like to key this of task_id, train_or_test and example index\n# but too many places already call the interpreter without having that info and time is short... So, just store one result, and the reference\n# input array, as the searching code tends to go over the same task example over and over.\n# TODO - Implement as an object.\n\nsplit_result_cache_input_array = np.zeros((1,1))\nsplit_result_cache_args = \"\"\nsplit_result_cache_working_list = []\nsplit_result_cache_metadata = []\nsplit_result_cache_accesses = 0\nsplit_result_cache_hits = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Interpreter:\n    \"\"\"\n    This class implements the DSL interpreter. The Interpreter object stores the working list (list of numpy arrays) and a metadata list.\n    The meta data list is currently just used to store the top corner of the arrays relative to a global frame of reference (typically the\n    original input array). The interpreter also stores the original input array.\n    \n    A typical program would split the input array into objects via the split command, filter some of those objects to keep or remove\n    objects meeting certain criteria. Finally, the objects in the working list can be assembled in some way with the assemble command. For\n    example, they could be placed on their original locations, on top of the original input array with 'assemble original original'.\n    \"\"\"\n    \n    def __init__(self):\n        self.original_input_array = None\n        self.working_list = None\n        self.metadata = None\n        \n    def map_special_values(self, input_array, value, debug=False):\n        \"\"\"\n        Given an input_array and a value, map that value to a real value (0-9) according to various special case:\n        - Value 10 goes to most common value from the original input array.\n        - Value 11 goes to least common value from the original input array.\n        - Value 12 goes to most common value from the given input array.\n        - Value 13 goes to least common value from the given input array.\n        - Value 14 goes to the divider colour populated by split. Will assert if no divider colour available.\n        \"\"\"\n        if value < 10:\n            return value\n        \n        if value in [10,11]:\n            array_to_use = self.original_input_array\n        elif value in [12,13]:\n            array_to_use = input_array\n        elif value == 14:\n            # TODO - Implement this.\n            assert False, \"Not implemented yet\"\n            \n        if value in [10, 11, 12, 13]:\n            values, counts = np.unique(array_to_use, return_counts=True)              \n            sort_index = np.flip(np.argsort(counts))\n            sorted_values = values[sort_index]\n            most_common = sorted_values[0]\n            least_common = sorted_values[-1]\n\n            result = value\n            if value in [10, 12]:\n                result = most_common\n            elif value in [11, 13]:\n                result = least_common\n\n        if debug:\n            print(f\"Changed value from {value} to {result}.\")\n        return result\n\n    def execute(self, input_array, prog, partial=False, debug=False):\n        \"\"\"\n        Initialize the interpreter's working list with the given input array and execute the given program.\n        \"\"\"\n        \n        if self.original_input_array is None:\n            self.original_input_array = input_array.copy()\n            self.working_list = [input_array.copy()]\n            self.metadata = [dict(top_corner = (0,0))]\n        \n        line_no = 0\n        for line in prog:\n            line_no += 1\n            if debug:\n                print(f\"{datetime.datetime.now()} Executing: {line}\")\n            line_split = line.split(' ', 1)\n            command = line_split[0]\n            rest = line_split[1] if len(line_split) > 1 else None\n            if command == 'identity':\n                # Take the working_list and apply the identity transform. That is do nothing.\n                pass\n            elif command == 'abstract':\n                self.abstract(rest, debug=debug)\n            elif command == 'assemble':\n                self.assemble(rest, debug=debug)\n            elif command == 'combine':\n                self.combine(rest, debug=debug)\n            elif command == 'filter':\n                self.filter(rest, debug=debug)\n            elif command == 'move':\n                self.move(rest, debug=debug)\n            elif command == 'replicate':\n                self.replicate(rest, debug=debug)\n            elif command == 'snake':\n                self.snake(rest, debug=debug)                \n            elif command == 'sort':\n                self.sort(rest, debug=debug)\n            elif command == 'split':\n                global split_result_cache_input_array\n                global split_result_cache_args\n                global split_result_cache_working_list\n                global split_result_cache_metadata\n                global split_result_cache_accesses\n                global split_result_cache_hits\n\n                if line_no == 1 and len(self.working_list) == 1:\n                    # Consider the cache!\n                    split_result_cache_accesses += 1\n                    if  split_result_cache_args == rest and np.array_equal(self.working_list[0], split_result_cache_input_array):\n                        # We've just done this split, re-use the results.\n                        split_result_cache_hits += 1\n                        self.working_list = deepcopy(split_result_cache_working_list)\n                        self.metadata = deepcopy(split_result_cache_metadata)\n                    else:\n                        # Split and cache the results.\n                        split_result_cache_input_array = self.working_list[0].copy()\n                        split_result_cache_args = rest\n                        self.split(rest, debug=debug)\n                        split_result_cache_working_list = deepcopy(self.working_list)\n                        split_result_cache_metadata = deepcopy(self.metadata)\n                else:\n                    self.split(rest, debug=debug)\n            elif command == 'transform':\n                self.transform(rest, debug=debug)\n            elif command == 'value_map':\n                self.value_map(rest, debug=debug)                \n            else:\n                dsl_usage()\n                assert False, f\"Unknown command: {command}.\"\n            \n        if debug:\n                print(\"Execution complete.\")\n                \n        if partial:\n            return self.working_list\n        else:\n            assert len(self.working_list) == 1, \"Program should complete with exactly 1 item in the working list.\"\n            return self.working_list[0]\n\n        \n    def abstract(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('abstract')\n\n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n\n        new_working_list = []\n        if sub_command == 'simple':\n            assert len(rest.split()) == 1, dsl_usage('abstract')\n            output_size = int(rest.split()[0])\n            \n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                values, counts = np.unique(item, return_counts=True)\n                #print(values, counts)\n                sort_index = np.flip(np.argsort(counts))\n                sorted_values = values[sort_index]\n                most_common = sorted_values[0]\n                result = np.full((output_size, output_size), most_common, dtype=int)\n                new_working_list.append(result)\n        else:\n            dsl_usage('abstract')\n            assert False, f\"Unknown sub-command: {sub_command}.\"\n\n        self.working_list = new_working_list\n\n        \n    def assemble(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('assemble')\n        assert len(self.working_list), \"Cannot assemble with an empty working list!\"\n\n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n        \n        new_working_list = []\n        if sub_command == 'original':\n            assert len(rest.split()) == 1, dsl_usage('assemble')\n            base = rest.split()[0]\n            if base == 'original':\n                result = self.original_input_array.copy()\n            elif base == 'zeros':\n                result = np.zeros(self.original_input_array.shape, dtype=int)\n            elif base == 'majority_value':\n                result = np.full(self.original_input_array.shape, get_most_common_value(self.original_input_array), dtype=int)\n                \n            for i in range(len(self.working_list)):\n                item = self.working_list[i]                \n                # Using the top_corner metadata, write each panel back in it's original place.\n                if debug:                  \n                    print(self.metadata[i])\n                top_corner = self.metadata[i]['top_corner']\n                shape = item.shape\n                resize = np.zeros(self.original_input_array.shape, dtype=int)\n                resize[top_corner[0]:top_corner[0]+shape[0], top_corner[1]:top_corner[1]+shape[1]] = item\n                result = np.where(resize == 0, result, resize)\n            new_working_list.append(result)\n        elif sub_command == 'histogram':\n            assert len(rest.split()) == 2, dsl_usage('assemble')\n            flip = rest.split()[0]\n            rot90 = int(rest.split()[1])\n            \n            scores = [0] * 10\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                most_common = get_most_common_value(item)\n                scores[most_common] += 1\n                scores = np.array(scores)\n            result_shape = (np.count_nonzero(scores), np.max(scores))\n            result = np.zeros(result_shape)\n            row = 0\n            while np.count_nonzero(scores) > 0:\n                val = np.argmax(scores)\n                for col in range(scores[val]):\n                    result[row, col] = val\n                row += 1\n                scores[val] = 0\n            if flip == 'lr':\n                result = np.fliplr(result)\n            elif flip == 'ud':\n                result = np.flipud(result)\n            if rot90 != 0:\n                result = np.rot90(result, rot90, axes=(0, 1))\n            new_working_list.append(result)\n        elif sub_command == 'auto_grid':\n            top_corners = []\n            for md in self.metadata:\n                top_corners.append(md['top_corner'])\n            row_parts = sorted([r for r, c in top_corners])\n            col_parts = sorted([c for r, c in top_corners])\n            \n            # Consider an increasing band. If n top-corners sit inside m bands, we have an n by m grid.\n            grid_rows = 0\n            grid_cols = 0\n            band = 0\n            \n            if len(self.working_list) == 1:\n                # Short-cut for the one panel case.\n                grid_rows = 1\n                grid_cols = 1\n                band = 100                \n                \n            while band < 10:\n                for dir in ['row', 'col']:\n                    if dir == 'row':\n                        parts = row_parts\n                    else:\n                        parts = col_parts\n                    idx = 0\n                    groups = []\n                    while(idx < len(parts)):\n                        part = parts[idx]\n                        group_size = 0\n                        while(idx < len(parts) and parts[idx] - part <= band):\n                            group_size += 1\n                            #print(f\"part: {part}, idx: {idx}, parts[idx] : {parts[idx]}, group_size: {group_size}\")\n                            idx +=1\n                        groups.append(group_size)\n                    # If all groups are the same size, and the number of groups times the size of each group equals the total we have\n                    # a solution. Note that all groups being of size 1 is not a solution - that just means that nothing lines up!\n                    if len(set(groups)) == 1 and len(groups) * set(groups).pop() == len(parts) and set(groups).pop() != 1:\n                        if debug:\n                            print(f\"band: {band}, dir: {dir}, n: {len(groups)}, m: {set(groups).pop()}\")\n                        if dir == 'row':\n                            grid_rows = len(groups)\n                            grid_cols = set(groups).pop()\n                        else:\n                            grid_cols = len(groups)\n                            grid_rows = set(groups).pop()\n                        band = 100 # break out of outer loop\n                        break\n                band += 1    \n                \n            if debug:\n                print(f\"grid_rows: {grid_rows}, grid_cols: {grid_cols}\")\n            first_sort = sorted(top_corners, key=lambda k: [k[0], k[1]])\n            sorted_top_corners = []\n            for gr in range(grid_rows):\n                sorted_top_corners.extend(sorted(first_sort[gr*grid_cols:gr*grid_cols+grid_cols], key=lambda k: [k[1], k[0]]))\n            tc_to_item_dict = {tc: i for i, tc in zip(self.working_list, top_corners)}\n            \n            # Now the top-corners are sorted, simply take items in chunks of grid_cols.\n            # Make the result big enough, we'll crop it later.\n            result = np.full((1000, 1000), -1, dtype=int)\n            offset = (0, 0)\n            idx = 0\n            for gr in range(grid_rows):\n                row_height = 0\n                for gc in range(grid_cols):\n                    tc = sorted_top_corners[idx]                    \n                    item = tc_to_item_dict[tc]\n                    shape = item.shape\n                    row_height = max(row_height,shape[0])\n                    if debug:                  \n                        print(f\"offset: {offset}\")\n                    result[offset[0]:offset[0]+shape[0], offset[1]:offset[1]+shape[1]] = item\n                    offset = (offset[0], offset[1] + item.shape[1])\n                    idx += 1\n                offset = (offset[0] + row_height, 0)\n                assert offset[0] <= 30 and offset[1] <= 30, \"Result beyond 30x30 limit in assemble auto_grid.\"\n                \n            result, _ = crop_background(result, -1, debug=debug)\n            # There should be any of the non-value -1 left, but if there is, replace with 0.\n            result = np.where(result == -1, 0, result)\n            new_working_list.append(result)\n        else:\n            dsl_usage('assemble')\n            assert False, f\"Unknown sub-command: {sub_command}.\"\n\n        self.working_list = new_working_list\n\n\n    def combine(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('combine')\n\n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n        \n        new_working_list = []\n        if sub_command == 'logical_op':\n            assert len(rest.split()) == 4, dsl_usage('combine')\n            pre_invert = rest.split()[0] == 'True'\n            logical_op = rest.split()[1]\n            post_invert = rest.split()[2] == 'True'\n            colour = int(rest.split()[3])           \n            if debug:\n                print(f\"pre_invert: {pre_invert}, logical_op: {logical_op}, post_invert: {post_invert}, colour: {colour}\")\n                \n            output = None\n            for item in self.working_list:\n                # Binarize the current panel.\n                working_panel = np.where(item == 0, False, True)\n                \n                if pre_invert:\n                    working_panel = np.logical_not(working_panel)\n    \n                if output is None:\n                    output = working_panel.copy()\n                elif logical_op == 'and':\n                    output = np.logical_and(output, working_panel)\n                elif logical_op == 'or':\n                    output = np.logical_or(output, working_panel)\n                elif logical_op == 'xor':\n                    output = np.logical_xor(output, working_panel)\n            \n            if post_invert:\n                output = np.logical_not(output)\n\n            output = np.where(output, colour, 0)\n            new_working_list.append(output)\n        elif sub_command == 'overwrite':\n            assert len(rest.split()) == 2, dsl_usage('combine')\n            transparent = int(rest.split()[0])\n            permutation = rest.split()[1].strip('[]').split(',')\n            if len(permutation) == 1 and permutation[0] == '':\n                permutation = range(len(self.working_list))\n            if debug:\n                print(f\"transparent: {transparent}, permutation: {permutation}\")\n\n            output = None\n            # Go through the working list in the given order.\n            for index in permutation:\n                item = self.working_list[int(index)]\n                if output is None:\n                    output = item.copy()\n                else:\n                    # Overwrite the output with the current item, showing the previous output through where the value\n                    # is the given transparent value.\n                    output = np.where(item == transparent, output, item)\n            \n            new_working_list.append(output)\n        else:\n            dsl_usage('combine')\n            assert False, f\"Unknown sub-command: {sub_command}.\"\n\n        self.working_list = new_working_list\n\n        \n    def filter(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('filter')\n\n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n        \n        new_working_list = []\n        new_metadata = []\n        meets_criteria = []\n        if sub_command == 'by_value':\n            assert len(rest.split()) == 3, dsl_usage('filter')\n            action = rest.split()[0]\n            condition = rest.split()[2]            \n            helper = ScoringHelper()\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                value = self.map_special_values(item, int(rest.split()[1]), debug=debug)                \n                values, counts = np.unique(item, return_counts=True)\n                counts_dict = dict(zip(values, counts))\n                helper.add_score(i, counts_dict.get(value, 0))\n            meets_criteria.append(helper.get_winner(condition))\n        elif sub_command == 'by_not_value':\n            assert len(rest.split()) == 3, dsl_usage('filter')\n            action = rest.split()[0]            \n            condition = rest.split()[2]\n            helper = ScoringHelper()\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                value = self.map_special_values(item, int(rest.split()[1]), debug=debug)                \n                values, counts = np.unique(item, return_counts=True)\n                counts_dict = dict(zip(values, counts))\n                # Add up counts, except the given value.\n                count = 0\n                for v in counts_dict.keys():\n                    if v != value:\n                        count += counts_dict[v]\n                helper.add_score(i, count)\n            meets_criteria.append(helper.get_winner(condition))\n        elif sub_command == 'by_value_gte':\n            assert len(rest.split()) == 3, dsl_usage('filter')\n            action = rest.split()[0]\n            threshold = int(rest.split()[2])\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                value = self.map_special_values(item, int(rest.split()[1]), debug=debug)                \n                values, counts = np.unique(item, return_counts=True)\n                counts_dict = dict(zip(values, counts))\n                if value in counts_dict.keys() and counts_dict[value] >= threshold: \n                    meets_criteria.append(i)\n        elif sub_command == 'by_majority_value':\n            assert len(rest.split()) == 2, dsl_usage('filter')\n            action = rest.split()[0]\n            condition = rest.split()[1]\n            scores = [0] * 10\n            indicies = []    # Don't do [[]] * 10, as that gives the SAME LIST 10 times!\n            for i in range(10):\n                indicies.append([])\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                most_common = get_most_common_value(item)\n                scores[most_common] += 1\n                indicies[most_common].append(i)\n                \n            if condition == 'most':\n                val_of_interest = np.argmax(np.array(scores))\n            elif condition == 'least':\n                val_of_interest = np.argmin(np.array(scores))\n            else:\n                assert False, f\"Bad condition in filter {sub_command}: {condition}\"\n            if debug:\n                print(f\"val_of_interest: {val_of_interest}\")\n            meets_criteria.extend(indicies[val_of_interest])\n        elif sub_command == 'by_size':\n            assert len(rest.split()) == 2, dsl_usage('filter')\n            action = rest.split()[0]\n            condition = rest.split()[1]\n            helper = ScoringHelper()\n            for i in range(len(self.working_list)):\n                helper.add_score(i, self.working_list[i].size)\n            meets_criteria.append(helper.get_winner(condition))\n        elif sub_command == 'unique_values':\n            assert len(rest.split()) == 2, dsl_usage('filter')\n            action = rest.split()[0]\n            condition = rest.split()[1]\n            helper = ScoringHelper()\n            for i in range(len(self.working_list)):\n                helper.add_score(i, len(np.unique(self.working_list[i])))\n            meets_criteria.append(helper.get_winner(condition))\n        elif sub_command == 'by_index':\n            assert len(rest.split()) == 2, dsl_usage('filter')\n            action = rest.split()[0]\n            index = int(rest.split()[1])\n            if index < len(self.working_list):\n                meets_criteria.append(index)\n        elif sub_command == 'by_shape_count':\n            assert len(rest.split()) == 4, dsl_usage('filter')\n            action = rest.split()[0]\n            shape = rest.split()[1]\n            condition = rest.split()[3]            \n            helper = ScoringHelper()\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                background = self.map_special_values(item, int(rest.split()[2]), debug=debug)                \n                if shape == 'cross':\n                    helper.add_score(i, count_crosses_and_xes(item, background, False, debug=debug))\n                elif shape == 'x':\n                    helper.add_score(i, count_crosses_and_xes(item, background, True, debug=debug))\n                elif shape == \"enclosure\":\n                    helper.add_score(i, count_enclosures(item, background, debug=debug))\n                    \n            meets_criteria.append(helper.get_winner(condition))\n        elif sub_command == 'commonality':\n            assert len(rest.split()) == 2, dsl_usage('filter')\n            action = rest.split()[0]\n            most_or_least = rest.split()[1]            \n            helper = ScoringHelper()\n            already_matched = [False] * len(self.working_list)\n            for i in range(len(self.working_list)):\n                if not already_matched[i]:\n                    commonality_count = 0\n                    for j in range(len(self.working_list)):\n                        if i != j and not already_matched[j]:\n                            if np.array_equal(self.working_list[i], self.working_list[j]):\n                                if debug:\n                                    print(f\"i: {i}, j: {j}, commonality_count: {commonality_count}\")\n                                commonality_count += 1\n                                already_matched[j] = True\n                \n                    helper.add_score(i, commonality_count)\n                    already_matched[i] = True\n            meets_criteria.append(helper.get_winner(most_or_least))\n        elif sub_command == 'has_symmetry':\n            assert len(rest.split()) == 1, dsl_usage('filter')\n            action = rest.split()[0]\n            chosen_item = None\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                if np.array_equal(item, np.fliplr(item)) or np.array_equal(item, np.flipud(item)):\n                    meets_criteria.append(i)                \n        elif sub_command == 'rectangular':\n            assert len(rest.split()) == 2, dsl_usage('filter')\n            action = rest.split()[0]\n            min_size  = int(rest.split()[1])\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                if item.shape[0] < min_size or item.shape[1] < min_size:\n                    # Too small\n                    pass\n                else:\n                    # If this is rectangular, there will be no background (0) values on the boundary.\n                    if np.count_nonzero(item[0,:]) == item.shape[1] and np.count_nonzero(item[-1,:]) == item.shape[1] and np.count_nonzero(item[:,0]) == item.shape[0]  and np.count_nonzero(item[:,-1]) == item.shape[0]:\n                        meets_criteria.append(i)\n        elif sub_command == 'enclosed':\n            assert len(rest.split()) == 1, dsl_usage('filter')\n            action = rest.split()[0]\n            for i in range(len(self.working_list)):\n                item1 = self.working_list[i]\n                tc1 = self.metadata[i]['top_corner']\n                for j in range(len(self.working_list)):\n                    if i != j:\n                        item2 = self.working_list[j]\n                        tc2 = self.metadata[j]['top_corner']\n                        if tc2[0] < tc1[0] and tc2[1] < tc1[1] and tc2[0]+item2.shape[0] > tc1[0]+item1.shape[0] and tc2[1]+item2.shape[1] > tc1[1]+item1.shape[1]:\n                            # Completely enclosed.\n                            meets_criteria.append(i)\n                            break\n                        elif tc2[0] <= tc1[0] and tc2[1] < tc1[1] and tc2[0]+item2.shape[0] >= tc1[0]+item1.shape[0] and tc2[1]+item2.shape[1] > tc1[1]+item1.shape[1]:\n                            # May overlap up to top or bottom row.\n                            meets_criteria.append(i)\n                            break\n                        elif tc2[0] < tc1[0] and tc2[1] <= tc1[1] and tc2[0]+item2.shape[0] > tc1[0]+item1.shape[0] and tc2[1]+item2.shape[1] >= tc1[1]+item1.shape[1]:\n                            # May overlap up to first or last column.\n                            meets_criteria.append(i)\n                            break\n        else:\n            dsl_usage('filter')\n            assert False, f\"Unknown sub-command: {sub_command}.\"\n\n        # Now apply the action on the filtered items.\n        if debug:\n            print(f\"In filter {sub_command}, meets_criteria = {meets_criteria}\")\n            \n        if action == 'keep':\n            new_working_list = [self.working_list[x] for x in meets_criteria]\n            new_metadata = [self.metadata[x] for x in meets_criteria]\n        elif action == 'remove':\n            for i in range(len(self.working_list)):\n                if i not in meets_criteria:\n                    new_working_list.append(self.working_list[i])\n                    new_metadata.append(self.metadata[i])\n        else:\n            assert False, f\"Bad action {action} given in filter by_value.\"\n\n        self.working_list = new_working_list\n        self.metadata = new_metadata        \n\n        \n    def move(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('move')\n\n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n        \n        new_metadata = []\n        if sub_command == 'by_value':\n            assert len(rest.split()) == 3, dsl_usage('move')            \n            direction = rest.split()[1]\n            distance = int(rest.split()[2])\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                value = self.map_special_values(item, int(rest.split()[0]), debug=debug)\n                \n                majority_val = get_most_common_value(item)\n                new_top_corner = self.metadata[i]['top_corner']\n                if majority_val == value:\n                    if direction == 'N':\n                        new_top_corner = (max(0, new_top_corner[0] - distance), new_top_corner[1])\n                    elif direction == 'S':\n                        new_top_corner = (min(new_top_corner[0] + distance, self.original_input_array.shape[0]), new_top_corner[1])\n                    elif direction == 'E':\n                        new_top_corner = (new_top_corner[0], min(new_top_corner[1] + distance, self.original_input_array.shape[1]))\n                    elif direction == 'W':\n                        new_top_corner = (new_top_corner[0], max(0, new_top_corner[1] - distance))\n                                    \n                nmd = dict(top_corner = new_top_corner)\n                new_metadata.append(nmd)\n\n        elif sub_command == 'by_shape':\n            assert len(rest.split()) == 2, dsl_usage('move')\n            dimension  = rest.split()[0]\n            direction = rest.split()[1]\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                new_top_corner = self.metadata[i]['top_corner']\n                if direction == 'SE':\n                    if dimension == 'V' or dimension == 'HV':\n                        new_top_corner = (new_top_corner[0] + item.shape[0], new_top_corner[1])\n                    elif dimension == 'H' or dimension == 'HV':\n                        new_top_corner = (new_top_corner[0], new_top_corner[1] + item.shape[1])\n                elif direction == 'NW':\n                    if dimension == 'V' or dimension == 'HV':\n                        new_top_corner = (new_top_corner[0] - item.shape[0], new_top_corner[1])\n                    elif dimension == 'H' or dimension == 'HV':\n                        new_top_corner = (new_top_corner[0], new_top_corner[1] - item.shape[1])\n                   \n                nmd = dict(top_corner = new_top_corner)\n                new_metadata.append(nmd)\n        else:\n            dsl_usage('move')\n            assert False, f\"Unknown sub-command: {sub_command}.\"\n        \n        self.metadata = new_metadata        \n\n\n    def replicate(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('replicate')\n        \n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n\n        new_working_list = []\n        new_top_corners = []\n        for i in range(len(self.working_list)):\n            item = self.working_list[i]\n            top_corner = self.metadata[i]['top_corner']\n            if sub_command == 'and_merge':\n                assert len(rest.split()) == 3, dsl_usage('replicate')\n                flips = rest.split()[0]\n                if rest.split()[1] == 'True':\n                    rotations = range(4)\n                else:\n                    rotations = range(1)\n                offset_type = rest.split()[2]\n                \n                replicants = []\n                for rot in rotations:\n                    replicant = np.rot90(item, k=rot, axes=(0, 1))\n                    if flips == 'none':\n                        replicants.append(replicant)\n                    elif flips == 'all':\n                        replicants.append(np.fliplr(replicant))\n                        replicants.append(np.flipud(replicant))\n                    elif flips == 'lr':\n                        replicants.append(np.fliplr(replicant))\n                    elif flips == 'ud':\n                        replicants.append(np.flipud(replicant))\n                    else:\n                        assert False, f\"Bad value {flips} passed for flip argument.\"\n\n                # We don't know that the axis of symmetry was central, so need to try various shifts and pick best.\n                MAX_SHIFT = 0\n                if offset_type == 'auto':\n                    if max(item.shape[0], item.shape[1]) <=5:\n                        MAX_SHIFT = 0\n                    elif max(item.shape[0], item.shape[1]) <=10:\n                        MAX_SHIFT = 1\n                    else:\n                        MAX_SHIFT = 2\n\n                temp_item = np.zeros((2*MAX_SHIFT+item.shape[0], 2*MAX_SHIFT+item.shape[1]), dtype=int)\n                temp_item[MAX_SHIFT:MAX_SHIFT+item.shape[0],MAX_SHIFT:MAX_SHIFT+item.shape[1]] = item\n                for rep in replicants:\n                    shifts = []\n                    helper = ScoringHelper()\n                    idx = 0 \n                    for rshift in range(-MAX_SHIFT, MAX_SHIFT+1):\n                        for cshift in range(-MAX_SHIFT, MAX_SHIFT+1):                                \n                            temp = np.zeros((2*MAX_SHIFT+item.shape[0], 2*MAX_SHIFT+item.shape[1]), dtype=int)\n                            temp[MAX_SHIFT+rshift:MAX_SHIFT+rshift+item.shape[0],MAX_SHIFT+cshift:MAX_SHIFT+cshift+item.shape[1]] = rep\n                            diff = np.where(temp == temp_item, 0, 1)\n                            if debug:\n                                print(f\"rshift: {rshift}, cshift: {cshift}, score: {np.sum(diff)}\")\n                            helper.add_score(idx, np.sum(diff))\n                            shifts.append((rshift, cshift))\n                            idx += 1\n                    best_shift = (0,0)\n                    best_idx = helper.get_winner('least')\n                    if best_idx is not None:\n                        best_shift = shifts[best_idx]\n\n                    rshift, cshift = best_shift\n                    if debug:\n                        print(f\"best_shift: {best_shift}\")\n                        print(f\"rshift: {rshift}, cshift: {cshift}\")\n                    temp = np.zeros((2*MAX_SHIFT+item.shape[0], 2*MAX_SHIFT+item.shape[1]), dtype=int)\n                    temp[MAX_SHIFT+rshift:MAX_SHIFT+rshift+item.shape[0],MAX_SHIFT+cshift:MAX_SHIFT+cshift+item.shape[1]] = rep\n                    temp_item = np.where(temp_item == 0, temp, temp_item)\n                    \n                new_item, offset = crop_background(temp_item, 0, debug=True)    \n                new_working_list.append(new_item)\n                new_top_corners.append((top_corner[0] - MAX_SHIFT + offset[0], top_corner[1] - MAX_SHIFT + offset[1]))\n                if debug:\n                    print(f\"top_corner: {top_corner}, offset: {offset}\")\n                    print(new_top_corners[-1])\n            elif sub_command == 'flower_flip':\n                assert len(rest.split()) == 1, dsl_usage('replicate')\n                starting_pos = int(rest.split()[0])\n                # Starting pos: 0 1\n                #               2 3\n                \n                # Add the original item\n                new_working_list.append(item)\n                new_top_corners.append(top_corner)\n                \n                # The lr-flip\n                new_item = np.fliplr(item)\n                if starting_pos in [0, 2]:\n                    new_top_corner = (top_corner[0], top_corner[1] + item.shape[1])\n                else:\n                    new_top_corner = (top_corner[0], top_corner[1] - item.shape[1])\n                new_working_list.append(new_item)\n                new_top_corners.append(new_top_corner)\n\n                # The ud-flip\n                new_item = np.flipud(item)\n                if starting_pos in [0, 1]:\n                    new_top_corner = (top_corner[0] + item.shape[0], top_corner[1])\n                else:\n                    new_top_corner = (top_corner[0] - item.shape[0], top_corner[1])\n                new_working_list.append(new_item)\n                new_top_corners.append(new_top_corner)\n\n                # The both-flip\n                new_item = np.fliplr(np.flipud(item))\n                if starting_pos == 0:\n                    new_top_corner = (top_corner[0] + item.shape[0], top_corner[1] + item.shape[1])\n                elif starting_pos == 1:\n                    new_top_corner = (top_corner[0] + item.shape[0], top_corner[1] - item.shape[1])\n                elif starting_pos == 2:\n                    new_top_corner = (top_corner[0] - item.shape[0], top_corner[1] + item.shape[1])\n                elif starting_pos == 3:\n                    new_top_corner = (top_corner[0] - item.shape[0], top_corner[1] - item.shape[1])\n                else:\n                    assert False, f\"Bad starting_pos {starting_pos} in replicate flower_flip\"\n                    \n                new_working_list.append(new_item)\n                new_top_corners.append(new_top_corner)\n            elif sub_command == 'flower_rotate':\n                assert len(rest.split()) == 1, dsl_usage('replicate')\n                starting_pos = int(rest.split()[0])\n                # Starting pos: 0 1\n                #               2 3\n                \n                # Add the original item\n                new_working_list.append(item)\n                new_top_corners.append(top_corner)\n                \n                # The 1 rotate\n                new_item = np.rot90(item, k=1, axes=(0, 1))\n                if starting_pos in [0, 2]:\n                    new_top_corner = (top_corner[0], top_corner[1] + item.shape[1])\n                else:\n                    new_top_corner = (top_corner[0], top_corner[1] - item.shape[1])\n                new_working_list.append(new_item)\n                new_top_corners.append(new_top_corner)\n\n                 # The 2 rotate\n                new_item = np.rot90(item, k=2, axes=(0, 1))\n                if starting_pos in [0, 1]:\n                    new_top_corner = (top_corner[0] + item.shape[0], top_corner[1])\n                else:\n                    new_top_corner = (top_corner[0] - item.shape[0], top_corner[1])\n                new_working_list.append(new_item)\n                new_top_corners.append(new_top_corner)\n\n                # The 3 rotate\n                new_item = np.rot90(item, k=3, axes=(0, 1))\n                if starting_pos == 0:\n                    new_top_corner = (top_corner[0] + item.shape[0], top_corner[1] + item.shape[1])\n                elif starting_pos == 1:\n                    new_top_corner = (top_corner[0] + item.shape[0], top_corner[1] - item.shape[1])\n                elif starting_pos == 2:\n                    new_top_corner = (top_corner[0] - item.shape[0], top_corner[1] + item.shape[1])\n                elif starting_pos == 3:\n                    new_top_corner = (top_corner[0] - item.shape[0], top_corner[1] - item.shape[1])\n                else:\n                    assert False, f\"Bad starting_pos {starting_pos} in replicate flower_flip\"\n                    \n                new_working_list.append(new_item)\n                new_top_corners.append(new_top_corner)\n            else:\n                dsl_usage('replicate')\n                assert False, f\"Unknown sub-command: {sub_command}.\"\n                                        \n        self.working_list = new_working_list\n        self.metadata = []\n        for tc in new_top_corners:\n            self.metadata.append(dict(top_corner = tc))\n        \n            \n    def snake(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('snake')\n        DIRECTIONS = {'N', 'E', 'S', 'W'}\n        DIR_AS_OFFSET = dict(N = (-1, 0),\n                             E = ( 0, 1),\n                             S = ( 1, 0),\n                             W = ( 0,-1))\n        TURN_RIGHT = dict(N = 'E',\n                          E = 'S',\n                          S = 'W',\n                          W = 'N')\n        TURN_LEFT  = dict(N = 'W',\n                          E = 'N',\n                          S = 'E',\n                          W = 'S')\n\n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n\n        new_working_list = []\n        for item in self.working_list:\n            if sub_command == 'simple':\n                assert len(rest.split()) == 12, dsl_usage('snake')\n                start_value = int(rest.split()[0])\n                direction = rest.split()[1]\n                actions = []\n                for i in range(2,12):\n                    actions.append(rest.split()[i])\n                if debug:\n                    print(f\"start_value: {start_value}, direction: {direction}, actions: {actions}\")\n                snake_map = np.zeros(item.shape, dtype=bool)\n                safety = 0\n                for row in range(item.shape[0]):\n                    for col in range(item.shape[1]):\n                        val = item[row,col]\n                        if val == start_value and not snake_map[row,col]:\n                            cr = row\n                            cc = col\n                            cd = direction\n                            if cd == 'away':\n                                if row == 0:\n                                    cd = 'S'\n                                elif col == 0:\n                                    cd = 'E'\n                                elif row == item.shape[0]-1:\n                                    cd = 'N'\n                                elif col == item.shape[1]-1:\n                                    cd = 'W'\n                                else:\n                                    assert False, \"Cannot start in free space with direction == 'away'.\"\n                            \n                            starting_dir = cd\n                            going_around = False\n                            other_paths = set()\n                            while(cr + DIR_AS_OFFSET[cd][0] >= 0 and cr + DIR_AS_OFFSET[cd][0] < item.shape[0] and\n                                  cc + DIR_AS_OFFSET[cd][1] >= 0 and cc + DIR_AS_OFFSET[cd][1] < item.shape[1]):\n                                safety += 1\n                                assert safety < 1000, \"Too many iterations in snake, bailing out.\"\n                                \n                                made_early_move = False\n                                consider_shortcut = False\n                                \n                                if going_around:\n                                    if consider_shortcut:\n                                        # Can the snake carry on in the original direction, regardless of the around direction, by cutting across the corner?\n                                        pass \n                                        # TODO - Finish this bit.\n                                        \n                                    lookahead = item[cr + DIR_AS_OFFSET[starting_dir][0], cc + DIR_AS_OFFSET[starting_dir][1]]\n                                    if actions[lookahead] == 'overwrite':\n                                        # We were going around, but now we can go back to the original direction as the way is clear.\n                                        cd = starting_dir\n                                        going_around = False\n\n                                lookahead = item[cr + DIR_AS_OFFSET[cd][0], cc + DIR_AS_OFFSET[cd][1]]\n                                #if debug:\n                                #    print(f\"lookahead: {lookahead}\")\n                                #    print(f\"actions[lookahead]: {actions[lookahead]}\")\n                                if actions[lookahead] == 'overwrite':\n                                    item[cr + DIR_AS_OFFSET[cd][0], cc + DIR_AS_OFFSET[cd][1]] = val\n                                    snake_map[cr + DIR_AS_OFFSET[cd][0], cc + DIR_AS_OFFSET[cd][1]] = True\n                                    cr += DIR_AS_OFFSET[cd][0]\n                                    cc += DIR_AS_OFFSET[cd][1]\n                                    if not (cr + DIR_AS_OFFSET[cd][0] >= 0 and cr + DIR_AS_OFFSET[cd][0] < item.shape[0] and\n                                            cc + DIR_AS_OFFSET[cd][1] >= 0 and cc + DIR_AS_OFFSET[cd][1] < item.shape[1]):\n                                        # About to terminate loop, grab extra paths.\n                                        if len(other_paths) > 0:\n                                            if debug:\n                                                print(\"Taking other paths.\")\n                                            cr, cc, cd, going_around = other_paths.pop()\n                                elif actions[lookahead] == 'turn_right':\n                                    cd = TURN_RIGHT[cd]\n                                elif actions[lookahead] == 'turn_left':\n                                    cd = TURN_LEFT[cd]\n                                elif actions[lookahead] == 'around_right':\n                                    cd = TURN_RIGHT[cd]\n                                    going_around = True\n                                elif actions[lookahead] == 'around_left':\n                                    cd = TURN_LEFT[cd]\n                                    going_around = True\n                                elif actions[lookahead] == 'around_right_sc':\n                                    cd = TURN_RIGHT[cd]\n                                    going_around = True\n                                    consider_shortcut = True\n                                elif actions[lookahead] == 'around_left_sc':\n                                    cd = TURN_LEFT[cd]\n                                    going_around = True\n                                    consider_shortcut = True\n                                elif actions[lookahead] == 'around_both':\n                                    going_around = True                                    \n                                    other_paths.add((cr, cc, TURN_LEFT[cd], going_around))\n                                    cd = TURN_RIGHT[cd]\n                                elif actions[lookahead] == 'stop':\n                                    if len(other_paths) > 0:\n                                        if debug:\n                                            print(\"Taking other paths.\")\n                                        cr, cc, cd, going_around = other_paths.pop()\n                                    else:\n                                        break\n                                else:\n                                    assert False, f\"Bad action {actions[lookahead]} in snake simple.\"\n                                                                                        \n                new_working_list.append(item)\n            else:\n                dsl_usage('snake')\n                assert False, f\"Unknown sub-command: {sub_command}.\"\n                                        \n        self.working_list = new_working_list\n\n        \n    def split(self, args, debug=False):\n        assert args is not None, dsl_usage('split')\n        \n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n        \n        new_working_list = []\n        new_metadata = []\n        for item in self.working_list:\n            if sub_command == 'auto_grid':\n                panels, top_corners = split_auto_grid(item, debug=debug)\n            elif sub_command == 'by_value':\n                assert len(rest.split()) == 2, dsl_usage('split')\n                background = self.map_special_values(item, int(rest.split()[0]), debug=debug)\n                crop = rest.split()[1]\n                panels, top_corners = split_by_value(item, int(background), crop)\n            elif sub_command == 'fixed_grid':\n                assert len(rest.split()) == 3, dsl_usage('split')\n                rows, columns, divider = rest.split()\n                panels, top_corners = split_fixed_grid(item, int(rows), int(columns), divider == 'True')\n            elif sub_command == 'fixed_size':\n                assert len(rest.split()) == 3, dsl_usage('split')\n                rows, columns, divider = rest.split()\n                panels, top_corners = split_fixed_size(item, int(rows), int(columns), divider == 'True')\n            elif sub_command == 'connected_region':\n                assert len(rest.split()) == 4, dsl_usage('split')\n                background = self.map_special_values(item, int(rest.split()[0]), debug=debug)\n                _, single_value, neighbourhood, crop = rest.split()                \n                eight_connected = True if int(neighbourhood) == 8 else False\n                panels, top_corners = split_connected_region(item, background, single_value == 'True', crop == 'True', eight_connected=eight_connected, debug=debug)\n            elif sub_command == 'frame':\n                assert len(rest.split()) == 2, dsl_usage('split')\n                background = self.map_special_values(item, int(rest.split()[0]), debug=debug)                    \n                keep_frame = rest.split()[1]              \n                panels, top_corners = split_frames(item, background, keep_frame == 'True', debug=debug)\n            else:\n                dsl_usage('split')\n                assert False, f\"Unknown sub-command: {sub_command}.\"\n\n            new_working_list.extend(panels)\n            for tc in top_corners:\n                new_metadata.append(dict(top_corner = tc))\n\n        self.working_list = new_working_list\n        self.metadata = new_metadata\n\n    def sort(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('sort')\n\n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n        \n        new_working_list = []\n        if sub_command == 'unique_values':\n            assert len(rest.split()) == 1, dsl_usage('sort')\n            ordering = rest.split()[0]\n            helper = ScoringHelper()\n            for i in range(len(self.working_list)):\n                helper.add_score(i, len(np.unique(self.working_list[i])))\n            new_order = helper.get_ordering(ordering)\n            for idx in new_order:\n                new_working_list.append(self.working_list[idx])\n        elif sub_command == 'by_value':\n            assert len(rest.split()) == 2, dsl_usage('sort')\n            ordering = rest.split()[1]            \n            helper = ScoringHelper()\n            for i in range(len(self.working_list)):\n                item = self.working_list[i]\n                value = self.map_special_values(item, int(rest.split()[0]), debug=debug)                \n                values, counts = np.unique(item, return_counts=True)\n                counts_dict = dict(zip(values, counts))\n                helper.add_score(i, counts_dict.get(value, 0))\n            new_order = helper.get_ordering(ordering)\n            for idx in new_order:\n                new_working_list.append(self.working_list[idx])\n        else:\n            dsl_usage('sort')\n            assert False, f\"Unknown sub-command: {sub_command}.\"\n                \n        self.working_list = new_working_list\n\n    def transform(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('transform')\n        \n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n\n        new_working_list = []\n        for item in self.working_list:\n            if sub_command == 'crop':\n                assert len(rest.split()) == 1, dsl_usage('transform')\n                background = self.map_special_values(item, int(rest.split()[0]), debug=debug)  \n                cropped_item, top_corner = crop_background(item, background, debug=debug)\n                new_working_list.append(cropped_item)\n            elif sub_command == 'flip':\n                assert len(rest.split()) == 1, dsl_usage('transform')\n                if rest.split()[0] == 'lr':                    \n                    new_working_list.append(np.fliplr(item))\n                elif rest.split()[0] == 'ud':\n                    new_working_list.append(np.flipud(item))\n                else:\n                    dsl_usage('transform')\n                    assert False, f\"Bad value ({rest.split()[0]}) given to 'transform flip'.\"\n            elif sub_command == 'invert':\n                values = np.unique(item)\n                if len(values) == 2:\n                    new_working_list.append(np.where(item == values[0], values[1], values[0]))\n                else:\n                    new_working_list.append(item)\n            elif sub_command == 'rot90':\n                assert len(rest.split()) == 1, dsl_usage('transform')\n                new_working_list.append(np.rot90(item, k=int(rest.split()[0]), axes=(0, 1)))\n            else:\n                dsl_usage('transform')\n                assert False, f\"Unknown sub-command: {sub_command}.\"\n                                        \n        self.working_list = new_working_list\n\n        \n    def value_map(self, args, debug=False):\n        \"\"\"\n        \"\"\"\n        assert args is not None, dsl_usage('value_map')\n        \n        args_split = args.split(' ', 1)\n        sub_command = args_split[0]\n        rest = args_split[1] if len(args_split) > 1 else None\n\n        new_working_list = []\n        for idx in range(len(self.working_list)):\n            item = self.working_list[idx]\n            new_item = item.copy()\n            if sub_command == 'simple':\n                assert len(rest.split()) == 2, dsl_usage('value_map')\n                from_val = self.map_special_values(item, int(rest.split()[0]), debug=debug)                \n                to_val = self.map_special_values(item, int(rest.split()[1]), debug=debug)\n                new_item = np.where(new_item == from_val, to_val, new_item)\n                new_working_list.append(new_item)\n            elif sub_command == 'enclosures_count':\n                assert len(rest.split()) == 3, dsl_usage('value_map')\n                background = self.map_special_values(item, int(rest.split()[0]), debug=debug)                \n                count = int(rest.split()[1])\n                value = int(rest.split()[2])\n                if count_enclosures(item, background, debug=debug) == count:\n                    new_item = np.where(new_item != background, value, background)\n                new_working_list.append(new_item)\n            elif sub_command == 'shape_match':\n                assert len(rest.split()) == 2, dsl_usage('value_map')\n                source_value_not = self.map_special_values(item, int(rest.split()[0]), debug=debug)\n                allow_rotations = rest.split()[1] == 'True'\n                most_common = get_most_common_value(item)\n                if most_common == source_value_not:\n                    # This is not a source, so needs mapping. Look for a matching shape.\n                    bin_item = np.where(item == 0, False, True)\n                    for j in range(len(self.working_list)):\n                        if j != idx:\n                            potential_source = self.working_list[j]\n                            source_value = get_most_common_value(potential_source)\n                            if source_value != source_value_not:\n                                # Do we have a match by shape?\n                                bin_source = np.where(potential_source == 0, False, True)\n                                rot90s = range(1)\n                                if allow_rotations:\n                                    rot90s = range(4)\n                                \n                                for rot90 in rot90s:\n                                    if np.array_equal(bin_item, np.rot90(bin_source, k=rot90, axes=(0, 1))):\n                                        # Yes, we have a match. Job done.\n                                        if debug:\n                                            print(f\"Matched item {idx} to source {j}, so changed value to {source_value}.\")\n                                        new_item = np.where(bin_item == True, source_value, 0)\n                                        break\n\n                new_working_list.append(new_item)\n            else:\n                dsl_usage('value_map')\n                assert False, f\"Unknown sub-command: {sub_command}.\"\n                             \n        assert len(self.working_list) == len(new_working_list), \"Have lost items in value_map. This is not allowed.\"\n        self.working_list = new_working_list\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3 - Examples and Testing\n\nSetup paths to the competition data. Also borrow from https://www.kaggle.com/ademiquel/data-preprocessing-correcting-tasks-with-errors to correct some known errors in the competition data. The dataset includes a small custom set of tasks developed for testing - see https://www.kaggle.com/andypenrose/visualize-extra-arc-tasks-for-testing for more details.\n\nWhen developing the DSL, it was important to keep testing it on previous known good examples, so as to avoid breaking anything. A set of tests are therefore built in below. If any previous good example fails to correctly answer a given task, it asserts to avoid wasting time with running beyond when there is a bug.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"root_path = Path('/kaggle/input/abstraction-and-reasoning-challenge')\ntraining_path = root_path / 'training'\nevaluation_path  = root_path / 'evaluation'\ntest_path = root_path / 'test'\nextra_tasks_path = Path('/kaggle/input/extra-arc-tasks-for-testing/')\n\ntrain_tasks = { task.stem: json.load(task.open()) for task in training_path.iterdir() } \nvalid_tasks = { task.stem: json.load(task.open()) for task in evaluation_path.iterdir() } \ntest_tasks = { task.stem: json.load(task.open()) for task in test_path.iterdir() }\nextra_tasks = { task.stem: json.load(task.open()) for task in extra_tasks_path.iterdir() }\n\nprint(f\"Num training tasks: {len(train_tasks)}\")\nprint(f\"Num evaluation tasks: {len(valid_tasks)}\")\nprint(f\"Num test tasks: {len(test_tasks)}\")\nprint(f\"Num extra tasks: {len(extra_tasks)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# From: https://www.kaggle.com/ademiquel/data-preprocessing-correcting-tasks-with-errors\n\n# A discussion thread asks us to list any errors that we have found in the tasks. Since there are quite a few tasks with errors, I think that it's worth it to have them corrected. So I went through all of the tasks reported on that thread and corrected them manually. This is now the first step I take when I preprocess the data. You can find the code below. I hope you find it useful.\n\n# Correct wrong cases:\n# 025d127b\nfor i in range(9, 12):\n    for j in range(3, 8):\n        train_tasks['025d127b']['train'][0]['output'][i][j] = 0\nfor i in range(7, 10):\n    for j in range(3, 6):\n        train_tasks['025d127b']['train'][0]['output'][i][j] = 2\ntrain_tasks['025d127b']['train'][0]['output'][8][4] = 0\n# ef135b50\ntrain_tasks['ef135b50']['test'][0]['output'][6][4] = 9\n# bd14c3bf\nfor i in range(3):\n    for j in range(5):\n        if valid_tasks['bd14c3bf']['test'][0]['input'][i][j] == 1:\n            valid_tasks['bd14c3bf']['test'][0]['input'][i][j] = 2\n# a8610ef7\nfor i in range(6):\n    for j in range(6):\n        if valid_tasks['a8610ef7']['test'][0]['output'][i][j] == 8:\n            valid_tasks['a8610ef7']['test'][0]['output'][i][j] = 5\nvalid_tasks['a8610ef7']['train'][3]['input'][0][1] = 2\nvalid_tasks['a8610ef7']['train'][3]['input'][5][1] = 2\n# 54db823b\nvalid_tasks['54db823b']['train'][0]['output'][2][3] = 3\nvalid_tasks['54db823b']['train'][0]['output'][2][4] = 9\n# e5062a87\nfor j in range(3, 7):\n    train_tasks['e5062a87']['train'][1]['output'][1][j] = 2\n# 1b60fb0c\ntrain_tasks['1b60fb0c']['train'][1]['output'][8][8] = 0\ntrain_tasks['1b60fb0c']['train'][1]['output'][8][9] = 0\n# 82819916\ntrain_tasks['82819916']['train'][0]['output'][4][5] = 4\n# fea12743\nfor i in range(11, 16):\n    for j in range(6):\n        if valid_tasks['fea12743']['train'][0]['output'][i][j] == 2:\n            valid_tasks['fea12743']['train'][0]['output'][i][j] = 8\n# 42a50994\ntrain_tasks['42a50994']['train'][0]['output'][1][0] = 8\ntrain_tasks['42a50994']['train'][0]['output'][0][1] = 8\n# f8be4b64\nfor j in range(19):\n    if valid_tasks['f8be4b64']['test'][0]['output'][12][j] == 0:\n        valid_tasks['f8be4b64']['test'][0]['output'][12][j] = 1\nvalid_tasks['f8be4b64']['test'][0]['output'][12][8] = 0\n# d511f180\ntrain_tasks['d511f180']['train'][1]['output'][2][2] = 9\n# 10fcaaa3\ntrain_tasks['10fcaaa3']['train'][1]['output'][4][7] = 8\n# cbded52d\ntrain_tasks['cbded52d']['train'][0]['input'][4][6] = 1\n# 11852cab\ntrain_tasks['11852cab']['train'][0]['input'][1][2] = 3\n# 868de0fa\nfor j in range(2, 9):\n    train_tasks['868de0fa']['train'][2]['input'][9][j] = 0\n    train_tasks['868de0fa']['train'][2]['input'][10][j] = 1\n    train_tasks['868de0fa']['train'][2]['input'][15][j] = 0\n    train_tasks['868de0fa']['train'][2]['input'][16][j] = 1\ntrain_tasks['868de0fa']['train'][2]['input'][15][2] = 1\ntrain_tasks['868de0fa']['train'][2]['input'][15][8] = 1\n# 6d58a25d\ntrain_tasks['6d58a25d']['train'][0]['output'][10][0] = 0\ntrain_tasks['6d58a25d']['train'][2]['output'][6][13] = 4\n# a9f96cdd\ntrain_tasks['a9f96cdd']['train'][3]['output'][1][3] = 0\n# 48131b3c\nvalid_tasks['48131b3c']['train'][2]['output'][4][4] = 0\n# 150deff5\naux = train_tasks['150deff5']['train'][2]['output'].copy()\ntrain_tasks['150deff5']['train'][2]['output'] = train_tasks['150deff5']['train'][2]['input'].copy()\ntrain_tasks['150deff5']['train'][2]['input'] = aux\n# 17cae0c1\nfor i in range(3):\n    for j in range(3, 6):\n        valid_tasks['17cae0c1']['test'][0]['output'][i][j] = 9\n# e48d4e1a\ntrain_tasks['e48d4e1a']['train'][3]['input'][0][9] = 5\ntrain_tasks['e48d4e1a']['train'][3]['output'][0][9] = 0\n# 8fbca751\nvalid_tasks['8fbca751']['train'][1]['output'][1][3] = 2\nvalid_tasks['8fbca751']['train'][1]['output'][2][3] = 8\n# 4938f0c2\nfor i in range(12):\n    for j in range(6,13):\n        if train_tasks['4938f0c2']['train'][2]['input'][i][j]==2:\n            train_tasks['4938f0c2']['train'][2]['input'][i][j] = 0\nfor i in range(5,11):\n    for j in range(7):\n        if train_tasks['4938f0c2']['train'][2]['input'][i][j]==2:\n            train_tasks['4938f0c2']['train'][2]['input'][i][j] = 0\n# 9aec4887\ntrain_tasks['9aec4887']['train'][0]['output'][1][4] = 8\n# b0f4d537\nfor i in range(9):\n    valid_tasks['b0f4d537']['train'][0]['output'][i][3] = 0\n    valid_tasks['b0f4d537']['train'][0]['output'][i][4] = 1\nvalid_tasks['b0f4d537']['train'][0]['output'][2][3] = 3\nvalid_tasks['b0f4d537']['train'][0]['output'][2][4] = 3\nvalid_tasks['b0f4d537']['train'][0]['output'][5][3] = 2\n# aa300dc3\nvalid_tasks['aa300dc3']['train'][1]['input'][1][7] = 5\nvalid_tasks['aa300dc3']['train'][1]['output'][1][7] = 5\nvalid_tasks['aa300dc3']['train'][1]['input'][8][2] = 5\nvalid_tasks['aa300dc3']['train'][1]['output'][8][2] = 5\n# ad7e01d0\nvalid_tasks['ad7e01d0']['train'][0]['output'][6][7] = 0\n# a8610ef7\nvalid_tasks['a8610ef7']['train'][3]['input'][0][1] = 0\nvalid_tasks['a8610ef7']['train'][3]['input'][5][1] = 0\nvalid_tasks['a8610ef7']['train'][3]['output'][0][1] = 0\nvalid_tasks['a8610ef7']['train'][3]['output'][5][1] = 0\n# 97239e3d\nvalid_tasks['97239e3d']['test'][0]['input'][14][6] = 0\nvalid_tasks['97239e3d']['test'][0]['input'][14][10] = 0\n# d687bc17\ntrain_tasks['d687bc17']['train'][2]['output'][7][1] = 4\n\n\n# I used different variable names...\ntraining_tasks = train_tasks\nevaluation_tasks = valid_tasks\nall_tasks = {**training_tasks, **evaluation_tasks, **extra_tasks}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Used in many notebooks, this version of plot_task is adapted from: https://www.kaggle.com/nanoix9/a-naive-image-manipulation-dsl\n\ndef plot_one(ax, input_matrix, i, train_or_test, input_or_output, title_color='black'):\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title('{} - {:d} - {}'.format(train_or_test, i, input_or_output), color=title_color)\n    \ndef plot_task(task, prog=None, debug=False):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    \n    extra_line = 1 if prog is not None else 0\n\n    def _plot_helper(train_or_test):\n        num_imgs = len(task[train_or_test])\n        fig, axs = plt.subplots(2 + extra_line, num_imgs, figsize=(3*num_imgs,3*2))\n        for i in range(num_imgs):\n            imgs = task[train_or_test][i]\n            input_img = np.array(imgs['input'], dtype=np.int)\n            output_img = np.array(imgs.get('output', np.zeros_like(input_img)), dtype=np.int)\n            if num_imgs > 1:\n                axs_col = axs[:, i]\n            else:\n                axs_col = axs\n            plot_one(axs_col[0], input_img, i,train_or_test,'input')\n            plot_one(axs_col[1], output_img, i,train_or_test,'output')\n            if prog is not None:\n                interp = Interpreter()\n                pred = interp.execute(input_img, prog, debug=debug)\n                color = 'green' if output_img.shape == pred.shape and np.all(output_img == pred) else 'red'\n                plot_one(axs_col[2], pred, i, train_or_test, 'prediction', title_color=color)\n        plt.tight_layout()\n        plt.show()\n    \n    _plot_helper('train')\n    _plot_helper('test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing area...\n\ntask_id = 'f9a67cb5'\nprog = ['snake simple 2 away overwrite stop stop stop stop stop stop stop around_both stop']\n\n\ntask = all_tasks[task_id]\nplot_task(task, prog, debug=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_predictions(task, prog, train_or_test, assert_on_diff=False):\n    \"\"\"\n    Check the given prog solves the given task. Can be used to check train or test parts of the task depending on the\n    train_or_test argument. If used in testing, setting assert_on_diff can be used to halt the run if a previous good\n    example breaks.\n    \"\"\"\n       \n    for input_array, output_array in zip([np.array(x['input']) for x in task[train_or_test]],\n                                         [np.array(x['output']) for x in task[train_or_test]]):\n        \n        interp = Interpreter()\n        try:\n            result = interp.execute(input_array, prog)\n            if not np.array_equal(result, output_array):\n                if assert_on_diff:\n                    assert False, f\"Unexpected prediction failure. prog={prog}\"\n                return False\n        except:\n            if assert_on_diff:\n                assert False, f\"Unexpected prediction failure. prog={prog}\"\n            return False            \n        \n    return True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SHOW_EXAMPLES = False\n\ntest_examples = [('1c0d0a4b', ['split auto_grid', 'value_map simple 8 2', 'transform invert' ,'assemble original zeros']),\n                 ('7953d61e', ['replicate flower_rotate 0' ,'assemble auto_grid']),\n                 ('0c786b71', ['replicate flower_flip 3' ,'assemble auto_grid']),\n                 ('f9a67cb5', ['snake simple 2 away overwrite stop stop stop stop stop stop stop around_both stop']),\n                 ('96a8c0cd', ['snake simple 2 away overwrite around_left overwrite around_right stop stop stop stop stop stop']),\n                 ('3345333e', ['split by_value 0 True', 'filter by_size keep most', 'replicate and_merge lr False auto', 'assemble original zeros']),\n                 ('e88171ec', ['split frame 10 False', 'value_map simple 0 8', 'assemble original original']),\n                 ('5614dbcf', ['split fixed_size 3 3 False', 'abstract simple 1', 'assemble auto_grid']),\n                 ('56ff96f3', ['split by_value 10 True', 'value_map simple 12 13', 'assemble original zeros']),\n                 ('1a6449f1', ['split frame 10 False', 'filter by_size keep most']),\n                 ('f45f5ca7', ['split connected_region 0 True 4 True', 'move by_value 2 E 2', 'move by_value 4 E 3', 'move by_value 3 E 4', 'move by_value 8 E 1', 'assemble original zeros']),\n                 ('1f85a75f', ['split connected_region 0 False 4 True', 'filter by_value keep 11 most']),\n                 ('2dee498d', [\"split fixed_grid 1 3 False\", \"filter by_index keep 0\"]),\n                 ('2dc579da', [\"split fixed_grid 2 2 True\", \"filter unique_values keep most\"]),\n                 ('a87f7484', [\"split fixed_size 3 3 False\", \"filter by_value keep 0 least\"]),\n                 ('ce4f8723', [\"split fixed_grid 2 1 True\", \"combine logical_op False or False 3\"]),\n                 ('cf98881b', [\"split fixed_grid 1 3 True\", \"combine overwrite 0 [2,1,0]\"]),\n                 ('ae4f1146', [\"split connected_region 0 False 4 True\", \"filter by_value keep 1 most\"]),\n                 ('39a8645d', [\"split connected_region 0 True 8 True\", \"filter commonality keep most\"]),\n                 ('e74e1818', [\"split by_value 0 True\", \"transform flip ud\", \"assemble original zeros\"]),\n                 ('54db823b', ['split connected_region 0 False 8 True', 'filter by_value remove 9 least', 'assemble original zeros']),\n                 ('a934301b', ['split connected_region 0 False 8 True', 'filter by_value_gte remove 8 2', 'assemble original zeros']),\n                 ('85b81ff1', ['split connected_region 0 False 4 True', 'sort by_value 0 descending', 'assemble original zeros']),\n                 ('67636eac', ['split connected_region 0 False 8 True', 'assemble auto_grid']),\n                 ('64a7c07e', ['split connected_region 0 True 8 True', 'move by_shape H SE', 'assemble original zeros']),\n                 ('2c0b0aff', ['split connected_region 0 False 4 True', 'filter by_shape_count keep cross 12 most']),\n                 ('73ccf9c2', ['split connected_region 0 True 8 True', 'filter has_symmetry remove']),\n                 ('845d6e51', ['split connected_region 0 True 4 True', 'value_map shape_match 3 True', 'assemble original zeros']),\n                 ('810b9b61', ['split connected_region 0 True 4 True', 'value_map enclosures_count 0 1 3', 'assemble original zeros']),\n                 ('b2862040', ['split connected_region 10 True 8 True', 'value_map enclosures_count 0 1 8', 'assemble original majority_value']),\n                 ('0a1d4ef5', ['split connected_region 0 True 4 True', 'filter rectangular keep 3', 'abstract simple 1', 'assemble auto_grid']),\n                 ('48d8fb45', ['split connected_region 0 False 8 True', 'filter by_value keep 5 most', 'value_map simple 5 0', 'transform crop 0']),\n                 ('9ddd00f0', ['replicate and_merge none True auto']),\n                 ('9f236235', ['split auto_grid', 'abstract simple 1', 'assemble auto_grid', 'transform flip lr']),\n                 ('b8825c91', ['split by_value 0 True', 'filter by_value_gte remove 4 1', 'assemble original zeros', 'replicate and_merge none True none']),\n                 ('aee291af', ['split frame 10 True', 'filter commonality keep least']),\n                 ('c909285e', ['split by_value 0 inclusive', 'filter by_size keep least']),\n                 ('9565186b', ['split connected_region 0 True 4 True', 'filter by_value remove 10 most', 'value_map simple 12 5', 'assemble original original']),\n                 ('bf699163', ['split by_value 10 True', 'filter enclosed keep']),\n                 ('8ee62060', ['transform flip lr', 'split connected_region 0 False 4 True', 'transform flip lr', 'assemble original zeros'])]\n\nfor task_id, prog in test_examples:\n    task = all_tasks[task_id]\n    if SHOW_EXAMPLES:\n        print(prog)\n        plot_task(task, prog, debug=False)\n    try:\n        check_predictions(task, prog, 'train', assert_on_diff=True)\n        check_predictions(task, prog, 'test', assert_on_diff=True)\n    except:\n        print(f\"Error for task_id: {task_id}\")\n        raise\n        \nprint(f\"Checked {len(test_examples)} examples of using the DSL.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4 - Search Algorithm\n\nThe search algorithm finds programs to solve tasks. It is not sophiscated enough to deserve being called a program synthesis engine! The logic is mostly built from observing command patterns that are succesful on the training and evaluation sets, then iterating over argument combinations. Ideally this would be totally replaced with something that actually learnt from the training data.\n\nbuild_prog_for_task_v2 takes the task, and considers the application of numerous split commands. Applicable split commands, filtering out those that create too many arrays in the working list, are then considered. The rest of the program search is carried out by either complete_prog_for_single_frame or complete_prog_for_multiple_frames depending on how many frames are returned from the split command.\n\nBuried in the hidden code section is search_for_final_commands_args. This function takes a starting program and considers permutations of a given command to complete the program. The sub-commands to be used are given. Then all argument permutations are computed using the allow ranges for arguments as given in the DSL definition. Arguments hints can be passed to speed up the search when extra information is already known (like which input values are actually present in all the input arrays for a task). search_for_final_commands_args can also take a list of post-ops to be tried after the main command.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def does_10_map_to_something_other_than_0(task):\n    for train_input in [np.array(x['input']) for x in task['train']]:\n        interp = Interpreter()\n        _ = interp.execute(train_input, ['identity'])\n        if interp.map_special_values(train_input, 10) != 0:\n            return True\n    return False\n\ndef does_11_map_to_something_other_than_0(task):\n    for train_input in [np.array(x['input']) for x in task['train']]:\n        interp = Interpreter()\n        _ = interp.execute(train_input, ['identity'])\n        if interp.map_special_values(train_input, 11) != 0:\n            return True\n    return False\n\ndef do_all_task_inputs_contain_0(task):\n    for train_input in [np.array(x['input']) for x in task['train']]:\n        if np.count_nonzero(train_input == 0) == 0:\n            return False\n    return True\n\n    \ndef determine_split_simple(task, pre_commands=None, debug=False):\n    \"\"\"\n    \"\"\"\n    output_shapes = set()\n    grid_sizes = set()\n    divider = set()\n    for train_input, train_output in zip([np.array(x['input']) for x in task['train']],[np.array(x['output']) for x in task['train']]):\n        if train_input.shape[0] <= train_output.shape[0] and train_input.shape[1] <= train_output.shape[1]:\n            # Output not smaller than input, cannot be a split and select/combine task.\n            return None\n        \n        if pre_commands is not None:            \n            interp = Interpreter()\n            train_input = interp.execute(train_input, pre_commands, debug=debug)\n            if debug:\n                print(f\"Train input:\\n{train_input}\")\n\n        output_shapes.add(train_output.shape)\n        grid_size = ((train_input.shape[0]//train_output.shape[0]),(train_input.shape[1]//train_output.shape[1]))\n        grid_sizes.add(grid_size)\n        if train_output.shape[0]*grid_size[0] == train_input.shape[0] and \\\n           train_output.shape[1]*grid_size[1] == train_input.shape[1]:\n            # This input is exactly made up of a grid of tiles the size of the output. No dividers.\n            divider.add(False)\n        elif train_output.shape[0]*grid_size[0]+grid_size[0]-1 == train_input.shape[0] and \\\n             train_output.shape[1]*grid_size[1]+grid_size[1]-1 == train_input.shape[1]:\n            # There are extra rows and columns enough to account fo dividers.\n            # TODO - Check the divider rows/columns are all a single value to avoid wasting time on cases that are not really\n            # made up of multiple panels.\n            divider.add(True)\n        else:\n            # Inconclusive, probably not made up of multiple panels in a regular grid.\n            return None\n\n    if debug:\n        print(f\"output_shapes: {output_shapes}\")\n        print(f\"grid_sizes: {grid_sizes}\")\n        print(f\"divider: {divider}\")\n\n    if len(divider) != 1:\n        # Search was inconclusive about whether a divider is present. Not supported.\n        return None\n    \n    split_cmd = None\n    if len(output_shapes) == 1:\n        # If all the train outputs have the same shape, assume a grid of fixed sized panels.\n        output_shape = output_shapes.pop()\n        split_cmd = f\"split fixed_size {output_shape[0]} {output_shape[1]} {divider.pop()}\"\n    elif len(grid_sizes) == 1:\n        # If all the train inputs appear to be have the same grid of panels, assume a fixed grid of different sized panels.\n        grid_size = grid_sizes.pop()\n        split_cmd = f\"split fixed_grid {grid_size[0]} {grid_size[1]} {divider.pop()}\"\n        \n    return split_cmd\n\ndef determine_split_connected_region(task, background, single_value, neighbourhood, culling_commands=[], debug=False):\n    \"\"\"\n    \"\"\"\n    split_cmd = f\"split connected_region {background} {single_value} {neighbourhood} True\"\n    prog = None\n    max_panels = 0\n    \n    culling_commands_plus_none = [None]\n    culling_commands_plus_none.extend(culling_commands)\n    \n    for culling_command in culling_commands_plus_none:\n        prog = None\n        max_panels = 0\n        for train_input, train_output in zip([np.array(x['input']) for x in task['train']],[np.array(x['output']) for x in task['train']]):\n            interp = Interpreter()\n            prog = [split_cmd]\n            if culling_command is not None:\n                prog.append(culling_command)\n            panels = interp.execute(train_input, prog, partial=True, debug=debug)\n            if debug:\n                print(f\"Found {len(panels)} panels.\")\n            if len(panels) > 0:\n                max_panels = max(max_panels, len(panels))\n                none_match_shape = True\n                for p in panels:\n                    if p.shape == train_output.shape:\n                        none_match_shape = False\n\n                if none_match_shape:\n                    if debug:\n                        print(f\"No panels match output shape {train_output.shape}.\")                    \n                    if len(panels) > A_LOT:\n                        # Too many panels and none have the correct shape, probably not actual objects that have been extracted.\n                        # break, maybe another culling command will help.\n                        prog = None\n                        break\n                elif len(panels) > TOO_MANY:\n                    # Too many panels, probably not actual objects that have been extracted.\n                    # break, maybe another culling command will help.\n                    prog = None\n                    break\n            else:\n                return None, None\n        \n        if prog is not None:\n            return prog, max_panels\n        \n    return None, None\n    \ndef get_panel_info_for_split(task, input_or_output, split_prog):\n    singular_override = False\n    for line in split_prog:\n        if 'fixed_grid' in line.split() and input_or_output == 'output':\n            singular_override = True\n            \n    result_counts = []\n    result_shapes = []\n    for train_input in [np.array(x[input_or_output]) for x in task['train']]:\n        if singular_override:\n            result_shapes.append({train_input.shape})\n            result_counts.append(1)\n        else:\n            interp = Interpreter()\n            panels = interp.execute(train_input, split_prog, partial=True)\n            result_shapes.append({x.shape for x in panels})\n            result_counts.append(len(panels))\n    return result_counts, result_shapes\n    \ndef get_min_max_panels(task, split_prog):\n    \"\"\"\n    \"\"\"\n    counts, _ = get_panel_info_for_split(task, 'input', split_prog)\n    return min(counts), max(counts)\n\ndef does_prog_give_single_panel_with_same_size_as_output(task, prog):\n    \"\"\"\n    \"\"\"\n    for train_input, train_output in zip([np.array(x['input']) for x in task['train']],[np.array(x['output']) for x in task['train']]):\n        interp = Interpreter()\n        try:\n            prediction = interp.execute(train_input, prog)\n        except:\n            return False\n        else:\n            if prediction.shape != train_output.shape:\n                return False\n\n    # If we go here, the prog runs on all train inputs and gives a single output prediction with the same shape\n    # as the corresponding output.\n    return True\n\ndef panels_same_size_per_input(task, prog):\n    \"\"\"\n    \"\"\"\n    for train_input in [np.array(x['input']) for x in task['train']]:\n        interp = Interpreter()\n        panels = interp.execute(train_input, prog, partial=True)\n        if len(panels) is None:\n            return False\n        \n        panel_shape = None\n        for p in panels:\n            if panel_shape is None:\n                panel_shape = p.shape\n            elif panel_shape != p.shape:\n                return False\n    \n    return True\n\ndef get_output_is_always_an_input_panel(task, pre_commands):\n    output_is_an_input_panel= True\n    for train_input, train_output in zip([np.array(x['input']) for x in task['train']],[np.array(x['output']) for x in task['train']]):\n        interp = Interpreter()\n        panels = interp.execute(train_input, pre_commands, partial=True)\n\n        this_output_is_an_input_panel = False\n        for p in panels:\n            if p.shape == train_output.shape and np.array_equal(p, train_output):\n                this_output_is_an_input_panel = True\n            \n        if not this_output_is_an_input_panel:\n            output_is_an_input_panel = False\n            break\n    \n    return output_is_an_input_panel\n\ndef get_all_input_or_output_values(task, input_or_output):\n    array_values = set()\n    for train_array in [np.array(x[input_or_output]) for x in task['train']]:\n        array_values = array_values.union(set(np.unique(train_array)))\n    return array_values\n\ndef get_values_added_in_diff(task):\n    values_in_diff = set()\n    for train_input, train_output in zip([np.array(x['input']) for x in task['train']],[np.array(x['output']) for x in task['train']]):\n        if train_input.shape != train_output.shape:\n            return None\n        diff = np.where(train_input != train_output, train_output, -1)\n        local_values = set(np.unique(diff))\n        if -1 in local_values:\n            local_values.remove(-1)\n        values_in_diff = values_in_diff.union(local_values)\n    return values_in_diff\n\n\ndef search_for_final_commands_args(task, prog_prefix, command, sub_commands, arg_hints=None, post_ops=None, final_sequence=None, terminate_early=True, use_scoring=False, filter_opt_info=None, debug=False):\n    \"\"\"\n    This function takes a starting program and considers permutations of the given command to complete the program. The sub-commands\n    to be used are given. Then all argument permutations are computed using the allow ranges for arguments as given in the DSL definition.\n    Arguments hints can be passed to speed up the search when extra information is already known (like which input values are actually\n    present in all the input arrays for a task). search_for_final_commands_args can also take a list of post-ops to be tried after\n    the main command.\n    \"\"\"\n    assert not use_scoring or len(sub_commands) == 1, \"use_scoring doesn't currently support multiple post_ops.\"\n    assert not use_scoring or len(sub_commands) == 1, \"use_scoring should only be used with a single sub_command.\"\n    \n    overall_working_cmds = []\n    filter_with_impact = []\n    for subcmd in sub_commands:\n        # Calculate the number of combinations of allowed args for this sub-command.\n        combinations = 1\n        args = dsl[command].subcmddict[subcmd].arglist\n        if len(args) == 0:\n            all_arg_strings = [\"\"]\n        else:\n            for i in range(len(args)):\n                if arg_hints is not None and subcmd in arg_hints.keys() and arg_hints[subcmd][i] is not None:\n                    combinations *= len(arg_hints[subcmd][i])\n                else:\n                    assert args[i].allowed_values is not None, \"Must provide arg_hint for arguments without statically known allowed values.\"\n                    combinations *= len(args[i].allowed_values)\n\n            if debug:\n                print(f\"Arguments combinations for {command} {subcmd} total {combinations}.\")\n        \n            assert combinations < 1000000, \"Too many combinations to search in search_for_final_commands_args.\"\n                \n            # For the first argument, spread the allowed values evenly over the number of cominbations. That means repeating each allowed value \"repeats = combinations//len(allowed_values)\" times.\n            # For the second argument, cycle through the allowed values, repeating each value \"repeats = repeats/len(allowed_values)\" times. And so on...\n            all_arg_strings = [\"\"] * combinations\n            repeats = combinations\n\n            for i in range(len(args)):\n                arg = args[i]\n                allowed_values = []\n                if arg_hints is not None and subcmd in arg_hints.keys() and arg_hints[subcmd][i] is not None:\n                    allowed_values = arg_hints[subcmd][i]\n                else:\n                    allowed_values = arg.allowed_values\n\n                index = 0\n                repeats = repeats//len(allowed_values)\n                while index < combinations:\n                    for v in allowed_values:\n                        for i in range(repeats):\n                            all_arg_strings[index] += \" \" + str(v)\n                            index += 1\n                        \n        #if debug:\n        #    for argcomb in all_arg_strings:\n        #        cmd = f\"{command} {subcmd}{argcomb}\"\n        #        print(cmd)\n\n        num_post_ops = len(post_ops) if post_ops is not None else 0\n\n        working_cmds = None\n        working_idxs = None\n\n        scores = [0] * combinations\n        all_trial_cmds = [\"\"] * combinations\n        train_idx = -1\n        for train_input, train_output in zip([np.array(x['input']) for x in task['train']],[np.array(x['output']) for x in task['train']]):\n            train_idx += 1\n            local_working_cmds = []\n            local_working_idxs = []\n            for argidx in range(combinations):\n                if not use_scoring and working_idxs is not None and len(working_idxs) > 0 and argidx not in working_idxs:\n                    # We're not using scoring, we have a list of working commands from earlier train inputs, and this command\n                    # isn't in the list.\n                    continue\n                    \n                argcomb = all_arg_strings[argidx]\n                for post_op_index in range(-1,num_post_ops):\n                    \n                    cmd = f\"{command} {subcmd}{argcomb}\"\n                    trial_cmds = [cmd]\n                    all_trial_cmds[argidx] = cmd\n                    \n                    if post_op_index >= 0:\n                        if isinstance(post_ops[post_op_index], list):\n                            trial_cmds.extend(post_ops[post_op_index])\n                        else:\n                            trial_cmds.append(post_ops[post_op_index])\n\n                    prog = prog_prefix.copy()                    \n                    prog.extend(trial_cmds)\n\n                    if final_sequence is not None:\n                        prog.extend(final_sequence)\n                        \n                    if debug:\n                        print(prog)\n                        \n                    interp = Interpreter()\n                    try:\n                        objects = interp.execute(train_input, prog, partial=True, debug=debug)\n                        if len(objects) == 1:\n                            prediction = objects[0]\n                            if np.array_equal(prediction, train_output):\n                                local_working_cmds.append(trial_cmds)\n                                local_working_idxs.append(argidx)\n                                # Note that even if we are using scoring, the score increment here is zero as the arrays are equal.\n                            elif use_scoring:\n                                diff = train_output - prediction\n                                scores[argidx] += np.count_nonzero(diff)\n                        elif filter_opt_info is not None and post_op_index == -1 and train_idx == 0:\n                            if len(objects) == 0:\n                                # Filter left no objects left, no point carrying on.\n                                break\n                            elif len(objects) == filter_opt_info[0][train_idx]:\n                                # The filtering didn't change the number of panels from the input. No point trying all post-ops.\n                                break\n                            else:\n                                # Filtering has given a changed number of objects, without removing them all.                                                                \n                                filter_with_impact.append(trial_cmds)\n                    except Exception as inst:                       \n                        if debug:\n                            print(f\"Error executing: {prog}\")\n                            print(type(inst))    # the exception instance\n                            print(inst.args)     # arguments stored in .args\n                            print(inst) \n                        # If this is the first post_op, no point continuing through the others!\n                        #if post_op_index == 0:\n                        #    break\n                        \n            if debug:\n                print(f\"working_cmds: {working_cmds}\")\n                print(f\"local_working_cmds: {local_working_cmds}\")\n                \n            if working_cmds is None:\n                working_cmds = local_working_cmds\n                working_idxs = local_working_idxs\n            else:\n                working_cmds = [x for x in working_cmds if x in local_working_cmds]\n                working_idxs = [x for x in working_idxs if x in local_working_idxs]\n                \n            if working_cmds == [] and not use_scoring:\n                # No consistent command found based on this sub-command; try next.\n                break\n                \n        if not use_scoring and working_cmds is not None and len(working_cmds) > 0 and terminate_early:\n            return working_cmds[0]\n        else:\n            overall_working_cmds.extend(working_cmds)\n    \n    if debug:\n        print(f\"Found {len(overall_working_cmds)} working {command} commands.\")\n        print(overall_working_cmds)\n    \n    if not use_scoring and len(overall_working_cmds) > 0:\n        return overall_working_cmds[0]\n\n    # We may not have found a command that gives a perfect result, but if using scoring, we'll at least return the command that gives the best score.\n    # Even if we have found a perfect result, we must come through here, as otherwise the post-op gets applied incorrectly.\n    if use_scoring:\n        helper = ScoringHelper()\n        for idx in range(len(scores)):\n            helper.add_score(idx, scores[idx])\n        winner = helper.get_winner('least')\n        if winner is not None:\n            if debug:\n                print(f\"Best scoring command: {all_trial_cmds[winner]}\")\n            return all_trial_cmds[winner]\n\n    if debug and len(filter_with_impact) > 0:\n        print(f\"Filter commands with impact: {len(filter_with_impact)}\")\n        \n    return None\n\ndef search_for_simple_value_maps(task, prog, post_op, debug=False):\n    \"\"\"\n    \"\"\"\n    input_values = get_all_input_or_output_values(task, 'input')\n    output_values = get_all_input_or_output_values(task, 'output')\n    input_values.update([10, 11])\n    output_values.update([10, 11])\n\n    pre_prog = prog.copy()\n    middle_cmds = []\n    for in_val in input_values:\n        # This search needs th ability to map x -> x, otherwise it makes bad, 'least worst' matches, that fail.\n        arg_hints = dict(simple = [[in_val], list(output_values)])\n        if debug:\n            print(f\"value_map hints: {arg_hints}\")\n        val_map_cmd = search_for_final_commands_args(task, pre_prog, 'value_map', ['simple'], arg_hints=arg_hints, post_ops=[post_op], use_scoring=True, debug=debug)\n        if val_map_cmd is not None:\n            pre_prog.append(val_map_cmd)\n            middle_cmds.append(val_map_cmd)\n    if len(middle_cmds) > 0:\n        # No need to add middle commands, already added to pre_prog.\n        temp_prog = pre_prog.copy()\n        temp_prog.append(post_op)\n        if debug:\n            print(f\"Trying out: {temp_prog}\")\n        if check_predictions(task, temp_prog, 'train'):\n            if debug:\n                print(\"Success!\")\n            return temp_prog                \n                \ndef try_combine_commands(task, prog, debug=False):\n    # Choose a combine mechanism. Limit the search with some heuristics.\n    post_ops = [\"transform crop 10\", \"transform crop 0\", \"transform flip lr\", \"transform flip ud\", \"transform rot90 1\", \"transform rot90 2\", \"transform rot90 3\", \"transform invert\"]\n    combine_cmds = None\n    output_colours = set()\n    for train_output in [np.array(x['output']) for x in task['train']]:\n        for v in np.unique(train_output):\n            if v != 0:\n                output_colours.add(v)\n    if len(output_colours) == 1:\n        # There is only 1 output colour that isn't black. Therefore assume the input panels are combined logically and the unique output colour corresponds to True.\n        if debug:\n            print(\"Investigating logical combination.\")\n\n        arg_hints = dict()\n        arg_hints['logical_op'] = [None, None, None, [output_colours.pop()]]\n        combine_cmds = search_for_final_commands_args(task, prog,'combine', ['logical_op'], arg_hints=arg_hints, post_ops=post_ops, debug=debug)\n    else:\n        # Multi-colour output. Assume the input panels have been combined in some combination. Try the \"combine overwrite\" commands with black as transparent and\n        ## brute-force all permutations.\n        if debug:\n            print(\"Investigating permutations.\")\n\n        min_panels, max_panels = get_min_max_panels(task, prog)\n        if min_panels != max_panels:\n            # Different number of panels per train input. Just combine in the order they come in.\n            arg_hints = dict()\n            arg_hints['overwrite'] = [[0], [[]]]\n            combine_cmds = search_for_final_commands_args(task, prog,'combine', ['overwrite'], arg_hints=arg_hints, debug=debug)\n        else:\n            if max_panels > 8:\n                if debug:\n                    print(\"Too many panels to brute-force all combinations.\")\n            else:                    \n                # Get all permutations of num_panels, then format as a list of strings with no spaces.\n                l = []\n                for p in permutations(range(max_panels)):\n                    l.append(str(list(p)).replace(' ',''))\n                arg_hints = dict()\n                arg_hints['overwrite'] = [[0], l]\n                combine_cmds = search_for_final_commands_args(task, prog, 'combine', ['overwrite'], arg_hints=arg_hints, debug=debug)\n\n    if combine_cmds is not None:\n        prog.extend(combine_cmds)\n        return prog\n    \n    return None\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def complete_prog_for_single_frame(task, prog, all_output_sizes_equal_or_smaller_than_inputs, all_output_sizes_equal_to_inputs, debug=False):\n\n    if debug:\n        print(f\"In complete_prog_for_single_frame with prog = {prog}\")\n        \n    # Are we done already?\n    if check_predictions(task, prog, 'train'):\n        return prog\n        \n    prog_output_is_right_size = does_prog_give_single_panel_with_same_size_as_output(task, prog)\n    \n    post_ops = None\n    if not prog_output_is_right_size:\n        post_ops = ['assemble original original', 'assemble original zeros']\n        if does_10_map_to_something_other_than_0(task):\n            post_ops.append('assemble original majority_value')\n        \n    scale_cmds = search_for_final_commands_args(task, prog, 'abstract', ['simple'], post_ops=post_ops, debug=debug)\n    if scale_cmds is not None:\n        prog.extend(scale_cmds)\n        return prog            \n\n    middle_cmds = search_for_final_commands_args(task, prog, 'transform', ['crop', 'flip', 'invert', 'rot90'], post_ops=post_ops, debug=debug)\n    if middle_cmds is not None:\n        prog.extend(middle_cmds)\n        return prog\n\n    if prog_output_is_right_size:\n        value_map_prog = search_for_simple_value_maps(task, prog, post_op='identity', debug=debug)\n        if value_map_prog is not None:\n            return value_map_prog\n\n    if prog_output_is_right_size:\n        replicate_sub_cmds = ['and_merge']\n    else:\n        replicate_sub_cmds = ['flower_flip', 'flower_rotate']\n        post_ops.append('assemble auto_grid')        \n    replicate_cmds = search_for_final_commands_args(task, prog, 'replicate', replicate_sub_cmds, post_ops=post_ops, debug=debug)\n    if replicate_cmds is not None:\n        prog.extend(replicate_cmds)\n        return prog\n    \n    return None\n\ndef complete_prog_for_multiple_frames(task, split_prog, all_output_sizes_equal_or_smaller_than_inputs, all_output_sizes_equal_to_inputs, debug=False):\n    \n    input_panel_counts, input_panel_shapes = get_panel_info_for_split(task, 'input', split_prog)\n    output_panel_counts, output_panel_shapes = get_panel_info_for_split(task, 'output', split_prog)\n    \n    same_counts = [x == y for x, y in zip(input_panel_counts, output_panel_counts)]\n    same_shapes = [x == y for x, y in zip(input_panel_shapes, output_panel_shapes)]\n    need_reduction = [y < x for x, y in zip(input_panel_counts, output_panel_counts)]\n    single_output_panel = [x == 1 for x in output_panel_counts]\n    if debug:\n        print(input_panel_counts)\n        print(output_panel_counts)\n        print(same_counts)\n        print(same_shapes)\n        print(need_reduction)\n        print(single_output_panel)\n\n    if all_output_sizes_equal_to_inputs and all(same_counts) and all(same_shapes):\n        # Same objects in input and output. Either need to move, sort, or re-colour them.\n        post_ops = ['assemble original zeros', 'assemble original majority_value', 'assemble original original']\n\n        for post_op in post_ops:\n            value_map_prog = search_for_simple_value_maps(task, split_prog, post_op=post_op, debug=debug)\n            if value_map_prog is not None:\n                return value_map_prog\n                \n        # Try colour by enclosures.\n        output_values = get_all_input_or_output_values(task, 'output')\n        middle_cmds = []\n        for val in output_values:\n            arg_hints = dict(enclosures_count = [[0], None, [val]])\n            val_map_cmd = search_for_final_commands_args(task, split_prog, 'value_map', ['enclosures_count'], arg_hints=arg_hints, post_ops=post_ops, use_scoring=True, debug=debug)\n            if val_map_cmd is not None:\n                middle_cmds.append(val_map_cmd)\n        if len(middle_cmds) > 0:\n            temp_prog = split_prog.copy()\n            temp_prog.extend(middle_cmds)\n            temp_prog.append('assemble original original')\n            if debug:\n                print(f\"Trying out: {temp_prog}\")\n            if check_predictions(task, temp_prog, 'train'):\n                return temp_prog\n\n        # Try colour by shape_match.\n        middle_cmds = search_for_final_commands_args(task, split_prog, 'value_map', ['shape_match'], post_ops=post_ops, debug=debug)\n        if middle_cmds is not None:\n            temp_prog = split_prog.copy()\n            temp_prog.extend(middle_cmds)\n            return temp_prog\n\n        # Try a simple move then assemble.\n        middle_cmds = search_for_final_commands_args(task, split_prog, 'move', ['by_shape'], post_ops=post_ops, debug=debug)\n        if middle_cmds is not None:\n            temp_prog = split_prog.copy()\n            temp_prog.extend(middle_cmds)\n            return temp_prog\n\n        # Try a sort then assemble.\n        middle_cmds = search_for_final_commands_args(task, split_prog, 'sort', ['by_value', 'unique_values'], post_ops=post_ops, debug=debug)\n        if middle_cmds is not None:\n            temp_prog = split_prog.copy()\n            temp_prog.extend(middle_cmds)\n            return temp_prog\n\n        # Try move by colour.\n        output_values = get_all_input_or_output_values(task, 'output')\n        middle_cmds = []\n        for val in output_values:\n            arg_hints = dict(by_value = [[val], None, None])\n            move_by_val_cmd = search_for_final_commands_args(task, split_prog, 'move', ['by_value'], arg_hints=arg_hints, post_ops=['assemble original zeros'], use_scoring=True, debug=debug)\n            if move_by_val_cmd is not None:\n                middle_cmds.append(move_by_val_cmd)\n        if len(middle_cmds) > 0:\n            temp_prog = split_prog.copy()\n            temp_prog.extend(middle_cmds)\n            temp_prog.append('assemble original zeros')\n            if debug:\n                print(f\"Trying out: {temp_prog}\")\n            if check_predictions(task, temp_prog, 'train'):\n                return temp_prog\n                \n        \n    if all(need_reduction) or not all(same_shapes):\n        filter_subcmds = ['by_size', 'commonality', 'unique_values', 'has_symmetry', 'rectangular', 'enclosed', 'by_shape_count', 'by_majority_value', 'by_index', 'by_value', 'by_value_gte', 'by_not_value']\n        arg_hints = dict()\n        for subcmd in filter_subcmds:\n            arg_hints[subcmd] = [None, None, None, None, None, None]\n        arg_hints['by_index'] = [None, range(min(30, max(input_panel_counts)))]\n        if all(single_output_panel):\n            # Post-ops based on not needing assemble.\n            post_ops = [\"transform crop 10\", \"transform crop 0\", \"transform flip lr\", \"transform flip ud\", \"transform rot90 1\", \"transform rot90 2\", \"transform rot90 3\", \"transform invert\", 'abstract simple 1', 'abstract simple 2', 'abstract simple 3']\n        else:\n            if all_output_sizes_equal_to_inputs:\n                post_ops = ['assemble original original', 'assemble original zeros']\n                if does_10_map_to_something_other_than_0(task):\n                    post_ops.append('assemble original majority_value')\n            else:\n                post_ops = ['assemble auto_grid', ['abstract simple 1', 'assemble auto_grid'], ['abstract simple 2', 'assemble auto_grid'], ['abstract simple 3', 'assemble auto_grid']]\n        \n        filter_cmds = search_for_final_commands_args(task, split_prog, 'filter', filter_subcmds, arg_hints=arg_hints, post_ops=post_ops, filter_opt_info=(input_panel_counts, output_panel_counts), debug=debug)\n        if filter_cmds is not None:\n            prog = split_prog.copy()\n            prog.extend(filter_cmds)\n            return prog \n\n    if all(need_reduction) or not all(same_shapes):\n        if all_output_sizes_equal_or_smaller_than_inputs and panels_same_size_per_input(task, split_prog):\n            combine_prog = try_combine_commands(task, split_prog, debug=debug)\n            if combine_prog is not None:\n                return combine_prog\n            \n    # Always try just putting all the objects back together, in combination with some simple transforms!\n    transform_cmds = [None, \"transform flip lr\", \"transform flip ud\", \"transform rot90 1\", \"transform rot90 2\", \"transform rot90 3\", \"transform invert\"]\n    if all_output_sizes_equal_to_inputs:\n        assemble_cmds = ['assemble original original', 'assemble original zeros']\n        if does_10_map_to_something_other_than_0(task):\n            assemble_cmds.append('assemble original majority_value')\n    else:\n        transform_cmds.extend([\"transform crop 10\", \"transform crop 0\"])\n        assemble_cmds = ['assemble auto_grid']    \n    \n    for transform_cmd in transform_cmds:\n        for assemble_cmd in assemble_cmds:\n            prog = split_prog.copy()\n            if transform_cmd is not None:\n                prog.append(transform_cmd)\n            prog.append(assemble_cmd)\n            prog = complete_prog_for_single_frame(task,\n                                                  prog,\n                                                  all_output_sizes_equal_or_smaller_than_inputs=all_output_sizes_equal_or_smaller_than_inputs,\n                                                  all_output_sizes_equal_to_inputs=all_output_sizes_equal_to_inputs)\n            if prog is not None:\n                return prog\n        \n    return None\n\ndef build_prog_for_task_v2(task_id, task, debug=False):\n    prog = None\n\n    all_output_sizes_equal_or_smaller_than_inputs = True\n    all_output_sizes_equal_to_inputs = True\n    for train_input, train_output in zip([np.array(x['input']) for x in task['train']],[np.array(x['output']) for x in task['train']]):\n        if train_input.shape[0] < train_output.shape[0] and train_input.shape[1] < train_output.shape[1]:\n            # inputs are smaller than outputs\n            all_output_sizes_equal_or_smaller_than_inputs = False\n            all_output_sizes_equal_to_inputs = False\n        elif train_input.shape[0] != train_output.shape[0] or train_input.shape[1] != train_output.shape[1]:\n            all_output_sizes_equal_to_inputs = False\n\n    # Special case for snake tasks.\n    if all_output_sizes_equal_to_inputs:\n        values_added_in_diff = get_values_added_in_diff(task)\n        all_input_values = get_all_input_or_output_values(task, 'input')\n        if len(values_added_in_diff) == 1 and len(all_input_values) <= 5:\n            for starting_val in values_added_in_diff:\n                arg_hints = dict()\n                hints = [[starting_val], None]\n                for i in range(10):\n                    if i == starting_val:\n                        # Allow snakes to cross.\n                        hints.append(['overwrite'])\n                    elif i in all_input_values:\n                        # No hint, iteratre therough all options.\n                        hints.append(None)\n                    else:\n                        # Not seen in any input, treat as stop.\n                        hints.append(['stop'])\n                        \n                arg_hints['simple'] = hints\n                snake_cmds = search_for_final_commands_args(task, [], 'snake', ['simple'], arg_hints=arg_hints, debug=debug)\n                if snake_cmds is not None:\n                    return snake_cmds\n                \n    split_progs = [['identity']]\n    split_cmd = determine_split_simple(task, debug=debug)\n    split_progs.append([split_cmd])\n    split_cmd = determine_split_simple(task, ['transform crop 10'], debug=debug)\n    split_progs.append(['transform crop 10', split_cmd])\n    split_progs.append(['split auto_grid'])\n    culling_commands = ['filter rectangular keep 2', 'filter rectangular keep 3']\n    if do_all_task_inputs_contain_0(task):\n        split_progs.extend([[\"split by_value 0 True\"], [\"split by_value 0 inclusive\"], ['split frame 0 False'], ['split frame 0 True']])\n        split_prog, _ = determine_split_connected_region(task, 0, True, 8, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 0, False,  8, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 0, True, 4, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 0, False,  4, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n    if does_10_map_to_something_other_than_0(task):\n        split_progs.extend([[\"split by_value 10 True\"], [\"split by_value 10 inclusive\"], ['split frame 10 False'], ['split frame 10 True']])\n        split_prog, _ = determine_split_connected_region(task, 10, True, 8, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 10, False,  8, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 10, True, 4, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 10, False,  4, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n    if does_11_map_to_something_other_than_0(task):    \n        split_prog, _ = determine_split_connected_region(task, 11, True, 8, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 11, False,  8, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 11, True, 4, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n        split_prog, _ = determine_split_connected_region(task, 11, False,  4, culling_commands=culling_commands, debug=debug)\n        split_progs.append(split_prog)\n\n    # Some of the above commands can contain None. Filter it.\n    new_split_progs = []\n    for prog in split_progs:\n        if prog is not None and None not in prog:\n            new_split_progs.append(prog)\n    if debug:\n        print(f\"{datetime.datetime.now()} len(split_progs): {len(split_progs)}, len(new_split_progs): {len(new_split_progs)}\")\n        print(f\"split_progs: {split_progs}\")\n        print(f\"new_split_progs: {new_split_progs}\")\n    split_progs = new_split_progs\n    \n    for split_prog in split_progs:\n        min_panels, max_panels = get_min_max_panels(task, split_prog)\n        if debug:\n            print(f\"{datetime.datetime.now()} prog: {split_prog} returns min_panels, max_panels = {min_panels}, {max_panels}\")\n        if min_panels == 1 and max_panels == 1:\n            prog = complete_prog_for_single_frame(task,\n                                                  split_prog,\n                                                  all_output_sizes_equal_or_smaller_than_inputs=all_output_sizes_equal_or_smaller_than_inputs,\n                                                  all_output_sizes_equal_to_inputs=all_output_sizes_equal_to_inputs,\n                                                  debug=debug)\n            if prog is not None:\n                return prog\n        elif min_panels > 0:\n            if max_panels <= A_LOT:\n                # Multiple objects extracted from the split. Can we just put them back together?\n                prog = complete_prog_for_multiple_frames(task,\n                                                        split_prog,\n                                                        all_output_sizes_equal_or_smaller_than_inputs=all_output_sizes_equal_or_smaller_than_inputs,\n                                                        all_output_sizes_equal_to_inputs=all_output_sizes_equal_to_inputs,\n                                                        debug=debug)\n                if prog is not None:\n                    return prog\n            \n    return None\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_id = '60b61512'\n\nif task_id in training_tasks:\n    print(\"From training\")\nelif task_id in evaluation_tasks:\n    print(\"From evaluation\")\ntask = all_tasks[task_id]\n\nprog = None\nplot_task(task, prog, debug=False)\n\nbefore_time = time.perf_counter()\nimport cProfile\n# Useful for keeping runtime under control. \n#cProfile.run('build_prog_for_task_v2(\"test\", task, debug=True)')\nprog = build_prog_for_task_v2(\"test\", task, debug=False)\nafter_time = time.perf_counter()\nprint(f\"Time taken: {after_time - before_time}s\")\nprint(f\"Split cache accesses/hits: {split_result_cache_accesses}/{split_result_cache_hits}\")\n\nprint(prog)\nplot_task(task, prog)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5 - Evaluation\n\nNow evaluate the DSL and program search code against the training or evaluation sets.\n\nThis code also monitors \"bad progs\" - that is programs that are found to solve the training examples of a task, but do not solve the test componenets of the task.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#tasks_to_eval = []\n#tasks_to_eval = all_tasks\n#tasks_to_eval = training_tasks\n#tasks_to_eval = evaluation_tasks\ntasks_to_eval = extra_tasks \n\nSLOW = 200\n\n# From training:\nskip_because_slow = []\n# From evaluation:\nskip_because_slow.extend(['af22c60d', 'de493100', '2f0c5170', '981571dc'])\n\ntemp_tasks_to_eval = dict()\nfor task_id in tasks_to_eval.keys():\n    if task_id not in skip_because_slow:\n        temp_tasks_to_eval[task_id] = tasks_to_eval[task_id]\ntasks_to_eval = temp_tasks_to_eval\n\nprint(len(tasks_to_eval))\n\nfound_bad_prog = []\nsuccesses = []\nslow_tasks = []\n\ndef solve_task(task_id):\n    task = tasks_to_eval[task_id]\n    #print(task_id)    \n    before_time = time.perf_counter()\n    prog = build_prog_for_task_v2(task_id, task)\n    after_time = time.perf_counter()\n    \n    success = False\n    if prog is not None and check_predictions(task, prog, 'train') and check_predictions(task, prog, 'test'):\n        success = True            \n    \n    return task_id, prog, success, (after_time - before_time)\n\n# Use multi-processing to speed this up!\npool = Pool()   \nresults = list(tqdm(pool.imap(solve_task, tasks_to_eval.keys()), total=len(tasks_to_eval.keys())))\npool.close()\n\nfor task_id, prog, success, time_taken in results:\n    if prog:\n        if success:\n            successes.append((task_id, prog))\n        else:\n            found_bad_prog.append((task_id, prog))\n    if time_taken > SLOW:\n        slow_tasks.append((task_id, time_taken))\n            \nprint(f\"Built a program for {len(found_bad_prog) + len(successes)} tasks.\")\nprint(f\"Succesfully predicted outputs for {len(successes)} tasks.\")\n\nprint(f\"\\nSlow tasks, over {SLOW}s:\")\nfor task_id, time_taken in slow_tasks:\n    print(f\"{task_id} took {time_taken}s.\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for task_id, prog in found_bad_prog:\n    task = tasks_to_eval[task_id]\n    print(f\"task_id: {task_id}, prog: {prog}\")\n    plot_task(task, prog)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for task_id, prog in successes:\n    print(f\"{task_id}: {prog}\")\n    #plot_task(all_tasks[task_id], prog)\nprint('\\n\\n')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6 - Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(root_path / 'sample_submission.csv')\nsub['output'] = \"|0|\"\n\ndef solve_task_for_test(task_id):\n    task = test_tasks[task_id]\n  \n    result = []\n    prog = build_prog_for_task_v2(task_id, task)\n    if prog is not None:    \n        test_num = -1\n        for test in task['test']:\n            test_num += 1\n\n            # Create solutions\n            test_input = np.array(test['input'])\n            interp = Interpreter()\n            try:\n                solution = interp.execute(test_input, prog)\n\n                task_name = task_id + \"_\" + str(test_num)\n                print(f\"SOLUTION for {task_name}\")\n                print(flattener(solution.tolist()))\n                result.append((task_name, flattener(solution.tolist())))\n            except:\n                pass\n            \n    return result\n    \n# If this is a commit run on the public test set, skip it. That makes it quicker to do the real submit on the private test set.\nif '00576224' in test_tasks.keys():\n    !cp ../input/abstraction-and-reasoning-challenge/sample_submission.csv submission.csv\nelse:\n    pool = Pool()   \n    results = pool.imap(solve_task_for_test, test_tasks.keys())\n    pool.close()\n\n    for result in results:\n        for task_name, solution in result:\n            sub.loc[sub['output_id'] == task_name, ['output']] = solution\n            \n    sub.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}