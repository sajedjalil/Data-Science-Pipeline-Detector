{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is a Fork of https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook.\n# [ARC] Exploring with UNet\nThe assumption in this notebook is that some of the task can be tackled like an Segemntation task, where `output` behaves like a mask with 10 categories. Therefore I try to apply a unet to check this assumption.\n\nThe given tasks in the json files are split into `train` and `test` arrays. My validation set is build upon the `test` arrays, so I'll refere to them as `valid` throughout the notebook.  \n\n## Credits\nElements of this notebooks are taken from:\n\n- Function to plot task, loading tasks: https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook\n\nPlease visit the notebooks and upvote if you like them."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os, shutil\nimport json\nfrom pathlib import Path\nimport sys\nfrom datetime import datetime\n\nimport torch.nn.functional as F\nfrom fastai.vision import *\nfrom fastai.utils.mod_display import *\nfrom torchvision import utils\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\nfrom scipy import stats\nfrom sklearn import metrics\n\nfrom fastai.callbacks.hooks import *\nfrom fastai.utils.mem import *\nfrom fastai.utils.mod_display import *\n\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"kaggle_input_path = '/kaggle/input'\n\nkaggle_arc_path = '/arc/input'\n\n\nfor dirname, _, filenames in os.walk(kaggle_input_path):\n    print(dirname)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from pathlib import Path\n\ndata_path = Path(kaggle_input_path+'/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `training` folder has 400 JSON tasks. `training_tasks` lists some of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"training_tasks = ['ce9e57f2', '868de0fa', 'b6afb2da', \n                  'db3e9e38', '3618c87e', 'bb43febb', \n                  '543a7ed5', '08ed6ac7', '6f8cd79b', \n                  'b1948b0a', '4258a5f9', '00d62c1b',\n                  '1bfc4729',\n                  '25ff71a9', '321b1fc6', '32597951',\n                  '36fdfd69', '3aa6fb7a', '3bdb4ada',\n                  '3befdf3e', '4093f84a', '444801d8',\n                  '4612dd53', '50cb2852', '60b61512',\n                  '67385a82', '6773b310', '694f12f3',\n                  '6c434453', '6cf79266', '6d75e8bb',\n                  '6e82a1ae']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function to plot task\nModified version of plot_task from https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook.\nAdded white (#FFFFFF) as additional color to fill borders."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25' ,'#FFFFFF'])\n\ncnorm = colors.Normalize(vmin=0, vmax=10) #vmax=9\n\ndef plot_task(taskname, train_idx=0, test_index=0, pred_imgs=[], max_train = -1):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    \n    # loading tasks\n    task_file = str(training_path / (taskname+'.json'))\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    \n    \n    if len(pred_imgs) == 0:\n        rows = 2\n    else:\n        rows = 4\n    \n    if max_train == -1:\n        # show all\n        max_train = len(task['train'])  \n    \n    fig, axs = plt.subplots(rows, (max_train+len(task['test']))*2, figsize=(15,2*rows))\n    offset = 0\n    for i in range(max_train):\n        axs[0, i*2].imshow(task['train'][i]['input'], cmap=cmap, norm=cnorm)\n        axs[0, i*2].axis('off')\n        axs[0, i*2].set_title('Train In '+str(i))\n        \n        im = Image.open(f'{kaggle_arc_path}/temp/input/{taskname}/train_{taskname}_'+str(i)+'.png')\n        axs[1, i*2].imshow(im, cmap=cmap, norm=cnorm)\n        axs[1, i*2].set_title('Train In '+str(i)+' image')\n        axs[1, i*2].axis('off')\n        \n        axs[0, i*2+1].imshow(task['train'][i]['output'], cmap=cmap, norm=cnorm)\n        axs[0, i*2+1].axis('off')\n        axs[0, i*2+1].set_title('Train Out '+str(i))\n        \n        im = Image.open(f'{kaggle_arc_path}/temp/output/{taskname}/train_{taskname}_'+str(i)+'.png')\n        axs[1, i*2+1].imshow(im, cmap=cmap, norm=cnorm)\n        axs[1, i*2+1].set_title('Train Mask '+str(i)+' image')\n        axs[1, i*2+1].axis('off')\n        \n        offset+=2\n        \n    for i in range(len(task['test'])):\n        j=i*2+offset\n        axs[0, j].imshow(task['test'][i]['input'], cmap=cmap, norm=cnorm)\n        axs[0, j].set_title('Valid In '+str(i))\n        axs[0, j].axis('off')\n        \n        im = Image.open(f'{kaggle_arc_path}/temp/input/{taskname}/valid_{taskname}_'+str(i)+'.png')\n        axs[1, j].imshow(im, cmap=cmap, norm=cnorm)\n        axs[1, j].set_title('Valid In '+str(i)+' img')\n        axs[1, j].axis('off')\n        \n        axs[0, j+1].imshow(task['test'][i]['output'], cmap=cmap, norm=cnorm)\n        axs[0, j+1].set_title('Valid Out '+str(i))\n        axs[0, j+1].axis('off')\n        \n        im = Image.open(f'{kaggle_arc_path}/temp/output/{taskname}/valid_{taskname}_'+str(i)+'.png')\n        axs[1, j+1].imshow(im, cmap=cmap, norm=cnorm)\n        axs[1, j+1].set_title('Valid Mask '+str(i)+' image')\n        axs[1, j+1].axis('off')\n    \n    if rows == 4:\n        for p, pred_img in enumerate(pred_imgs):\n            y = -2*(len(pred_imgs))+2*p+1\n            axs[2, y].imshow(pred_img, cmap=cmap, norm=cnorm)\n            axs[2, y].set_title('Pred img')\n            #for i in range(len(task['test'])+max_train*2):\n            #    axs[2, i ].axis('off')\n\n            rs_pred_img = resize_unpad(pred_img,task_info[taskname]['max_xy'],\n                                       np.round(task_info[taskname]['test_in_shapes'][p] * \n                                                task_info[taskname]['avg_train_shape_factor']).astype('uint8')\n                                      )\n            acc = metrics.accuracy_score(np.array(task['test'][p]['output']).reshape(1,-1)[0], rs_pred_img.reshape(1,-1)[0])\n        \n            axs[3, y].imshow(rs_pred_img, cmap=cmap, norm=cnorm)\n            axs[3, y].set_title(f'Pred img croped and rescaled (acc: {acc:.4f})')\n        \n        for i in range((len(task['test'])+max_train)*2):\n            axs[2, i].axis('off')\n            axs[3, i].axis('off')\n        \n        #acc = metrics.accuracy_score(np.array(task['test'][0]['output']).reshape(1,-1)[0], rs_pred_img.reshape(1,-1)[0])\n        #print(f\"Accuracy: {acc}\")\n                \n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions to prepare task images\n\nFor convenience the arrays are safed as images, so that the Fastai Dataloader for Segmentation can easily be applied without modification."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def task_sample_arr(taskname, test_train = 'train', in_out = 'input', idx = 0):\n    task_file = str(training_path / (taskname+'.json'))\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    \n    return np.array(task[test_train][idx][in_out])\n\n\ndef pad_to_xy(a, max_xy, color = 10):\n    \n    ''' Center and 0-pad np.array to max_xy-size '''\n\n    y, x = a.shape\n    (max_x, max_y) = max_xy \n    \n    y0 = (max_y-y)//2 #0\n    y1 = (max_y-y)-(max_y-y)//2 #max_xy[1]-y\n    x0 = (max_x-x)//2 #0\n    x1 = (max_x-x)-(max_x-x)//2 #max_xy[0]-x\n    \n    return np.pad(a, ((y0, y1), (x0, x1)), 'constant', constant_values=(color, color)) #F.pad(t, (0,max_xy[0]-x, 0, max_xy[1]-y), mode='constant')\n\n\ndef unpad_xy(img, max_xy=(16,16), org_xy=(15,15)):\n    x_start = (max_xy[0]-org_xy[1])//2\n    x_end = x_start + org_xy[1]\n\n    y_start = (max_xy[1]-org_xy[0])//2\n    y_end = y_start + org_xy[0]\n    \n    return img[y_start:y_end,x_start:x_end]\n\n\ndef resize_unpad(img, max_xy=(16,16), org_xy=(15,15)):\n    t=Image.fromarray(img.astype('uint8'))\n\n    t = np.asarray(t.resize(max_xy, Image.NEAREST))\n\n    return unpad_xy(t,max_xy,org_xy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def export_max_padded(task, taskname):\n    \n    ''' Get max x and max y size of all task images. \n        Center and pad task images to max size\n        Save arrays as images to /temp folder.\n    '''\n    \n    os.makedirs(f'{kaggle_arc_path}/temp/input/{taskname}')\n    os.makedirs(f'{kaggle_arc_path}/temp/output/{taskname}')\n        \n    max_xy=(0,0)\n    max_x=0\n    max_y=0\n    \n    train_in=[]\n    train_out=[]\n    valid_in=[]\n    valid_out=[]\n    all_train_colors=[]\n    \n    num_train = 0\n    num_valid = 0\n    \n    # to array and get max_x, max_y\n    for i, tsk in enumerate(task['train']):\n        t = np.array(tsk['input']).astype('uint8')\n        train_in.append(t)\n        all_train_colors+=t.reshape(1,-1).tolist()\n        max_x = max(t.shape[1], max_x)\n        max_y = max(t.shape[0], max_y)\n        t = np.array(tsk['output']).astype('uint8')\n        train_out.append(t)\n        all_train_colors+=t.reshape(1,-1).tolist()\n        max_x = max(t.shape[1], max_x)\n        max_y = max(t.shape[0], max_y)\n        \n    for i, tsk in enumerate(task['test']):\n        t = np.array(tsk['input']).astype('uint8')\n        valid_in.append(t)\n        max_x = max(t.shape[1], max_x)\n        max_y = max(t.shape[0], max_y)\n        t = np.array(tsk['output']).astype('uint8')\n        valid_out.append(t)\n        max_x = max(t.shape[1], max_x)\n        max_y = max(t.shape[0], max_y)\n        \n        max_xy=(max([int(max_x//0.7),16]), max([int(max_y//0.7),16]))\n        #max_xy=(32,32)\n        #print(f'max_xy: {max_xy}')\n    \n    #flatten\n    all_train_colors = [i for lst in all_train_colors for i in lst]\n    \n    bgcolor = stats.mode(all_train_colors,axis=None)[0]  # 0\n    framecolor = bgcolor\n    \n    # pad and save\n    train_in_shapes = []\n    for i, t in enumerate(train_in):\n        train_in_shapes.append(t.shape)\n        tp = pad_to_xy(t, reversed(tuple(np.add(t.shape,(2,2)))), framecolor) # 0\n        tp = pad_to_xy(tp, max_xy) #t\n        im = Image.fromarray(tp)\n        im.save(f'{kaggle_arc_path}/temp/input/{taskname}/train_{taskname}_'+str(i)+'.png')\n        num_train += 1\n    train_out_shapes = []\n    for i, t in enumerate(train_out):\n        train_out_shapes.append(t.shape)\n        tp = pad_to_xy(t, reversed(tuple(np.add(t.shape,(2,2)))), framecolor)\n        tp = pad_to_xy(tp, max_xy)\n        im = Image.fromarray(tp)\n        im.save(f'{kaggle_arc_path}/temp/output/{taskname}/train_{taskname}_'+str(i)+'.png')\n        \n    valid_shapes = []\n    for i, t in enumerate(valid_in):\n        valid_shapes.append(t.shape)\n        tp = pad_to_xy(t, reversed(tuple(np.add(t.shape,(2,2)))), framecolor)\n        tp = pad_to_xy(tp, max_xy)\n        im = Image.fromarray(tp)\n        im.save(f'{kaggle_arc_path}/temp/input/{taskname}/valid_{taskname}_'+str(i)+'.png')\n        num_valid += 1\n    for i, t in enumerate(valid_out):\n        #print(f'shape of validation output: {t.shape}')\n        tp = pad_to_xy(t, reversed(tuple(np.add(t.shape,(2,2)))), framecolor)\n        tp = pad_to_xy(tp, max_xy)\n        im = Image.fromarray(tp)\n        im.save(f'{kaggle_arc_path}/temp/output/{taskname}/valid_{taskname}_'+str(i)+'.png')\n\n        \n    return {'num_train': num_train, \n            'num_test': num_valid, \n            'max_xy': max_xy, \n            'test_in_shapes': valid_shapes, # in shapes of test\n            'avg_train_shape_factor': np.mean(np.array(train_out_shapes)/np.array(train_in_shapes), axis = 0), # avg factor for train in shape to train outshape \n            'bgcolor': bgcolor}\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create temp folder\nif  os.path.exists(kaggle_arc_path + '/temp'):\n    shutil.rmtree(kaggle_arc_path + '/temp');\n\nos.makedirs(kaggle_arc_path + '/temp/input')\nos.makedirs(kaggle_arc_path + '/temp/output')\n\n# create temp folder\n#if  os.path.exists(kaggle_input_path + '/temp'):\n#    shutil.rmtree(kaggle_input_path + '/temp');\n\n#os.makedirs(kaggle_input_path + '/temp/input')\n#os.makedirs(kaggle_input_path + '/temp/output')\n\ntask_info={}\n\nfor i, taskname in enumerate(training_tasks):\n    # loading tasks\n    task_file = str(training_path / (taskname+'.json'))\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n    \n    # save train and validation arrays as images\n    # all images are padded to the max x and y size of the current task arrays\n    num_tt = export_max_padded(task, taskname)\n    task_info[taskname] = num_tt\n    #print(f'Task info: {task_info}')\n    ## show an example\n    if i==0:\n        print(str(i)+'. Example task '+taskname + ':')\n        plot_task(taskname)#, max_train=2)\n\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling\nApplying the UNet basicly follows the tutorial (https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb). "},{"metadata":{},"cell_type":"markdown","source":"## Data\nSince there are only view train samples, augmentation is used to generate more samples with increasing sice of epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"get_y_fn = lambda x: f'{kaggle_arc_path}/temp/output/{x.stem.split(\"_\")[1]}/{x.stem}{x.suffix}'\n    \ndef data(task = training_tasks[0]):\n    return (SegmentationItemList.from_folder(f'{kaggle_arc_path}/temp/input/{task}')\n        #.split_by_idx(valid_idx=[i for i in range(len(task['train']), len(task['train'])+len(task['test']))])\n        .split_by_files(valid_names = [f'valid_{task}_{i}.png' for i in range(task_info[task]['num_test'])])\n        .label_from_func(get_y_fn, classes = np.array([str(i) for i in range(11)])) #range(10)\n        .transform(get_transforms(), tfm_y=True, size=256, padding_mode = 'border')  #256\n        .databunch(bs=1)\n        .normalize(imagenet_stats)\n       )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Example\n#data(training_tasks[0]).show_batch(rows=2, figsize=(6, 6), alpha=1) #, cmap=cmap, norm=cnorm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\nThe pretrained model gets extended by a SelfAttention-Block (see Module SAI), which works in this experiment better then the one which could be activated as a learner parameter."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nclass SAI(nn.Module):\n    ''' SelfAttention with Identity '''\n    \n    def __init__(self, nf):\n        super(SAI, self).__init__()\n        \n        self.sa = PooledSelfAttention2d(nf)\n        self.bn = nn.BatchNorm2d(nf)\n        self.do = nn.Dropout(0.4)\n        \n        \n    def forward(self, x):\n        ident = x\n        out = self.sa(x)\n        out = ident + out\n        \n        out = self.do(self.bn(out)) #\n        \n        return out\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def learn(task = training_tasks[0], epochs = 150, runs = 2, lr = 5e-5):\n    print(f'Task {task} start..')\n    lrn = unet_learner(data(task), models.resnet18, blur = True, bottle = True) #, wd=1e-3 #bottle off\n    \n    lrn.model[0][4].add_module('sai0_4', SAI(64)) \n    lrn.model[0][5].add_module('sai0_5', SAI(128))\n\n    lrn.model[7].shuf.blur.add_module('sai7', SAI(512)) \n    lrn.model[8].blur.add_module('sai8', SAI(384)) \n    \n    lrn.model = lrn.model.cuda()\n        \n    for i in range(runs):\n        # Disable progressbar from https://forums.fast.ai/t/how-to-run-without-progress-bar/29875/6\n        with progress_disabled_ctx(lrn) as lrn:\n            lrn.fit_one_cycle(epochs, slice(lr))\n        print(f'run #{i} done')\n  \n    return lrn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"%%time\nmeasures = []\n\nfor taskname in training_tasks:\n    try:\n        l = learn(taskname, epochs = 150, runs = 2, lr = 5e-5) #e150 r2\n        t = l.TTA(ds_type=DatasetType.Valid, beta=0.7) # l.get_preds(ds_type=DatasetType.Valid) #\n            \n        ## loop over all predictions\n        pred_imgs=[]\n        acc_avg = 0\n        for p in range(t[0].shape[0]):\n            pred_img = t[0][p].numpy().argmax(axis = 0)\n            pred_imgs.append(pred_img)\n            # zoom to expected size\n            rs_pred_img = resize_unpad(pred_img,task_info[taskname]['max_xy'],\n                                       np.round(task_info[taskname]['test_in_shapes'][p] * \n                                                task_info[taskname]['avg_train_shape_factor']).astype('uint8'))\n            \n            # evaluate\n            y_img = task_sample_arr(taskname, test_train = 'test', in_out = 'output', idx = p).reshape(1,-1)[0]\n            y_hat_img = rs_pred_img.reshape(1,-1)[0]\n            \n            acc = metrics.accuracy_score(y_img, y_hat_img)\n            print(f\"Accuracy {taskname}_{p}: {acc}\")\n            \n            acc_avg = (acc_avg * (p) + acc) / (p+1)\n        \n        measures += [[taskname , round(acc_avg, 4)]]\n        plot_task(taskname, pred_imgs=pred_imgs, max_train = 2)\n        \n    except:\n        measures += [[taskname , np.nan]]\n        plt.show()\n        print('Exception occured!')\n\npd.DataFrame(measures, columns=['taskname', 'accuracy_unet']).to_csv(f'evaluation_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index = False)\n\nprint('Done !')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:fastai]","language":"python","name":"conda-env-fastai-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":4}