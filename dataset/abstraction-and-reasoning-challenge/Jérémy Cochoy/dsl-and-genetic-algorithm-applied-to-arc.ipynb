{"cells":[{"metadata":{},"cell_type":"markdown","source":"# A DSL alongside a Genetic Algorithm applied to the ARC Dataset\n\nIn this notebook, we present a minimalistic *Domain Specific Language* for some of the ARC tasks.\n\nWe instroduce the language and how it can be used to precess the input in complex ways. We then implement an evaluation function able to run a such program against an input image. We also provide a program solution of a task as an exemple.\n\nIn a second time, we implement a simple genetic algorithm (based on a multiobjective and elitist strategy) that is able to generate programs written in this DSL and demonstrate its usage against the same ARC task previously solved by hand."},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:red\">If you like the content of this notebook, please consider upvoting it.</span>\n\nNot only it will show to visitors that this notebook have valuable information, but it will also encourage me to produce more quality notebooks. :)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Usual numpy, panda, matplotlib and python libraries imports\nimport numpy as np\nimport pandas as pd\nimport itertools\nimport random\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\n\ntraining_tasks = sorted(os.listdir(training_path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Domain Specific Language (DSL)\n\nWe will build a domain specific language specialized on processing list of images. To allow easy chaining of keyword from this language together, each *function* provided by this language will be take one or more images and transform it to none, one or more. The final result of our program will then be a list of images.\n\nThe DSL is so constituted by a collection of functions of type `np.array -> [np.array]` and `[np.array] -> [np.array]`.\n\nThe first kind of function take an image, and produce a list of images (for example, the image split by different colors). The second type of function take a list of images and produce a new list (for exemple, intersect).\n[](http://)"},{"metadata":{},"cell_type":"markdown","source":"## DSL Implementation\n\nWe start with the functions that take *one image* and produce an *a list of images*.](http://)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# np.array -> [np.array]\ndef groupByColor_unlifted(pixmap):\n    \"\"\" Split an image into a collection of images with unique color \"\"\"\n    # Count the number of colors\n    nb_colors = int(pixmap.max()) + 1\n    # Create a pixmap for each color\n    splited = [(pixmap == i) * i for i in range(1, nb_colors)]\n    # Filter out empty images\n    return [x for x in splited if np.any(x)]\n\n# np.array -> [np.array]\ndef cropToContent_unlifted(pixmap):\n    \"\"\" Crop an image to fit exactly the non 0 pixels \"\"\"\n    # Op argwhere will give us the coordinates of every non-zero point\n    true_points = np.argwhere(pixmap)\n    if len(true_points) == 0:\n        return []\n    # Take the smallest points and use them as the top left of our crop\n    top_left = true_points.min(axis=0)\n    # Take the largest points and use them as the bottom right of our crop\n    bottom_right = true_points.max(axis=0)\n    # Crop inside the defined rectangle\n    pixmap = pixmap[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]\n    return [pixmap]\n\n# np.array -> [np.array]\ndef splitH_unlifted(pixmap):\n    \"\"\" Split horizontally an image \"\"\"\n    h = pixmap.shape[0]\n    if h % 2 == 1:\n        h = h // 2\n        return [pixmap[:h,:], pixmap[h+1:,:]]\n    else:\n        h = h // 2\n        return [pixmap[:h,:], pixmap[h:,:]]\n\n# np.array -> [np.array]\ndef negative_unlifted(pixmap):\n    \"\"\" Compute the negative of an image (and conserve the color) \"\"\"\n    negative = np.logical_not(pixmap).astype(int)\n    color = max(pixmap.max(), 1)\n    return [negative * color]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now write functions that take a list of images and transform it to a new list."},{"metadata":{"trusted":true},"cell_type":"code","source":"# [np.array] -> [np.array]\ndef identity(x: [np.array]):\n    return x\n\n# [np.array] -> [np.array]\ndef tail(x):\n    if len(x) > 1:\n        return x[1:]\n    else:\n        return x\n\n# [np.array] -> [np.array]\ndef init(x):\n    if len(x) > 1:\n        return x[:1]\n    else:\n        return x\n\n# [np.array] -> [np.array]\ndef union(x):\n    \"\"\" Compute the pixel union of all images in the list. \"\"\"\n    if len(x) < 2:\n        return x\n    \n    # Make sure everybody have the same shape\n    first_shape = tuple(x[0].shape)\n    for pixmap in x[1:]:\n        if first_shape != tuple(pixmap.shape):\n            return []\n    \n    return [np.bitwise_or.reduce(np.array(x).astype(int))]\n    \ndef intersect(x):\n    \"\"\" Compute the pixel intersection of all images in the list. \"\"\"\n    if len(x) < 2:\n        return x\n    \n    # Make sure everybody have the same shape\n    first_shape = tuple(x[0].shape)\n    for pixmap in x[1:]:\n        if first_shape != tuple(pixmap.shape):\n            return []\n    \n    return [(np.prod(np.array(x), axis=0) > 0).astype(int)]\n\ndef sortByColor(xs):\n    \"\"\" Sort pictures by increasing color id. \"\"\"\n    xs = [x for x in xs if len(x.reshape(-1)) > 0]\n    return list(sorted(xs, key=lambda x: x.max()))\n\ndef sortByWeight(xs):\n    \"\"\" Sort images by how many non zero pixels are contained. \"\"\"\n    xs = [x for x in xs if len(x.reshape(-1)) > 0]\n    return list(sorted(xs, key=lambda x: (x>0).sum()))\n\ndef reverse(x):\n    \"\"\" Reverse the order of a list of images. \"\"\"\n    return x[::-1]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Composition of functions\n\nIt is important to make sure we can chain both functions. To compose two functions `f` and `g` of type `[np.array] -> [np.array]` ; We symply call `g(f([input_image]))`.\n\n\nBut for each function of the type `np.array -> [np.array]` some work is required. We need to generated a *lifted version* version of them. A function `f: np.array -> [np.array]` can be turned into a function of type `[np.array] -> [np.array]` by applying `f` on each image of the input list and concatenating the results.\n\n---\nIf you want to know more about the `lift` concept, have a look to the concept of [*monades*](https://en.wikipedia.org/wiki/Monad_%28functional_programming%29). We are indeed using the *list monade*."},{"metadata":{"trusted":true},"cell_type":"code","source":"def lift(fct):\n    # Lift the function\n    def lifted_function(xs):\n        list_of_results = [fct(x) for x in xs]\n        return list(itertools.chain(*list_of_results))\n    # Give a nice name to the lifted function\n    import re\n    lifted_function.__name__ = re.sub('_unlifted$', '_lifted', fct.__name__)\n    return lifted_function\n\ncropToContent = lift(cropToContent_unlifted)\ngroupByColor = lift(groupByColor_unlifted)\nsplitH = lift(splitH_unlifted)\nnegative = lift(negative_unlifted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task\n\nWe now load a simple task and execute one of our functions on it."},{"metadata":{"trusted":true},"cell_type":"code","source":"#\n# This code is used to display a task\n#\n\ncmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\ndef plot_one(ax, i,train_or_test,input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    \n    input_matrix = task[train_or_test][i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' '+input_or_output)\n    \n\ndef plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(task['train'])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    for i in range(num_train):     \n        plot_one(axs[0,i],i,'train','input')\n        plot_one(axs[1,i],i,'train','output')        \n    plt.tight_layout()\n    plt.show()        \n        \n    num_test = len(task['test'])\n    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n    if num_test==1: \n        plot_one(axs[0],0,'test','input')\n        plot_one(axs[1],0,'test','output')     \n    else:\n        for i in range(num_test):      \n            plot_one(axs[0,i],i,'test','input')\n            plot_one(axs[1,i],i,'test','output')  \n    plt.tight_layout()\n    plt.show() \n\n    \n# Display each output of the function\ndef show_image_list(images):\n    \"\"\" Show each image contained in a list. \"\"\"\n    p = plt.figure().subplots(1, len(images))\n    if len(images) > 1:\n        for i, image in enumerate(images):\n            p[i].imshow(image, cmap=cmap, norm=norm)\n    elif len(images) == 1:\n        p.imshow(images[0], cmap=cmap, norm=norm)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load my favorite task\ntask_file = str(training_path / training_tasks[13])\nwith open(task_file, 'r') as f:\n    task = json.load(f)\n    plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Execute the group by color on the first input\ninput_image = np.array(task['train'][0]['input'])\nimages = groupByColor([input_image])\n\n# Show the result of our function\nshow_image_list(images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Program evaluation\n\n\nWe define our building blocks for programs (the functions in our DSL). We will define a program as a list of functions from our DSL ; `program: [[np.array] -> [np.array]]`. The instructions in our programs will be executed *from left to right*. This mean that if we want to first `splitByColor` and then compute the `negative` of the image, we need to write `[splitByColor, negative]` in this order."},{"metadata":{},"cell_type":"markdown","source":"Let's first write an utilitary function to describe a program as a human readable string."},{"metadata":{"trusted":true},"cell_type":"code","source":"def program_desc(program):\n    \"\"\" Create a human readable description of a program. \"\"\"\n    desc = [x.__name__ for x in program]\n    return(' >> '.join(desc))\n\n# Display the program description alongside its output\nprogram = [splitH, groupByColor, negative, intersect]\nprint(program_desc(program))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The evaluation method\nWe want to run and evaluate a such program on a pictures and then recover the result. This logic is realised by the `evaluate` function."},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(program: [], input_image: np.array):\n    # Make sure the input is a np.array\n    input_image = np.array(input_image)\n    assert type(input_image) == np.ndarray\n    \n    # Apply each function on the image\n    image_list = [input_image]\n    for fct in program:\n        # Apply the function\n        image_list = fct(image_list)\n        # Filter out empty images\n        image_list = [img for img in image_list if img.shape[0] > 0 and img.shape[1] > 0]\n        # Break if there is no data\n        if image_list == []:\n            return []\n    return image_list        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple test on a task\nWe apply the simple program `[groupByColor, negative]` on the task we loaded earlier."},{"metadata":{"trusted":true},"cell_type":"code","source":"results = evaluate(program=[groupByColor, negative], input_image=task['train'][0]['input'])\nshow_image_list(results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Program generation (Genetic Algorithm)\n\nWe now have a simple and powerful language to express various transformation on images. But someone or something still have to write the actual program that can solve a task. In this part, we will implement a naive but somewhat efficient genetic algorithm that will be able to find by itself the solution to a task.\n\nThe strategy will be as follow:\n\n* We generate random program with one node, and then run them. We keep the best solution (the *elites* of our population).\n* Starting from this best solutions, we create new program though mutation. We avaluate them again and update our collection of elite.\n* We continue doing this process again and again... until a solution is found.\n\n---\n\nSince we use multiple fitness function, our aproache can be qualified of [multi-objectives](https://en.wikipedia.org/wiki/Multi-objective_optimization) : we try to optimise multiple objectives at the same time.\n\nOur *elites* can be understood as an approximation of the pareto surface (collection of pareto optimal solution). In our specific case, when a solution to the task exists in our DSL, their exists a global minimum that will be smaller than any candidate. In a such case the pareto surface is reduced to a single point. Nethertheless, this is a good image to keep in mind to understand what the collection of *elites* represent."},{"metadata":{},"cell_type":"markdown","source":"## Is a program solution ?\n\nFirst, we need a way to know if a program is a solution of the given examples of a task."},{"metadata":{"trusted":true},"cell_type":"code","source":"def are_two_images_equals(a, b):\n    if tuple(a.shape) == tuple(b.shape):\n        if (np.abs(b-a) < 1).all():\n            return True\n    return False\n\ndef is_solution(program, task, verbose=True):\n    for sample in task: # For each pair input/output\n        i = np.array(sample['input'])\n        o = np.array(sample['output'])\n\n        # Evaluate the program on the input\n        images = evaluate(program, i)\n        if len(images) < 1:\n            return False\n        \n        # The solution should be in the 3 first outputs\n        images = images[:3]\n        \n        # Check if the output is in the 3 images produced\n        is_program_of_for_sample = any([are_two_images_equals(x, o) for x in images])\n        if not is_program_of_for_sample:\n            return False\n    \n    return True\n\nprogram = [groupByColor, cropToContent]\nprint(program_desc(program),\"is a solution of the task:\", is_solution(program, task['train']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitness\n\nTo help our algorithm progress in the right direction, we need a way to give a score to an existing program. The smaller is the score of the program, the closer we are to the solution. One can think of this score as a distance of our program to the optimal solution.\n\nNotice that one can think of this program as a minimization problem (minimize `score`) or maximization problem (minimize `-score`). On machine learning it is common to minimise a distance wereas in genetic algorithm literature you can read that we maximize the fitness of an agent^1. Both convention work perfectly, but it is more convenient if we choose one and stick to it. Therefore, we will MINIMIZE the score of our programs.\n\nBecause we can't really comme up with one single good score function that would describe well the progression of the algorithm on all task of the dataset, we will evaluate how our program perform on different aspects through a collection of them.\n\n---\n\n^1: The reason you see maximization and positive score in Genetic Programming literature is that you need all your values to be positive in order to build a probability distribution over your population. Since we use an elitist algorithm instead of a sampling of the population for reproduction, we do not need this restriction."},{"metadata":{"trusted":true},"cell_type":"code","source":"def width_fitness(predicted, expected_output):\n    \"\"\" How close the predicted image is to have the right width. Less is better.\"\"\"\n    return np.abs(predicted.shape[0] - expected_output.shape[0])\n\ndef height_fitness(predicted, expected_output):\n    \"\"\" How close the predicted image is to have the right height. Less is better.\"\"\"\n    return np.abs(predicted.shape[1] - expected_output.shape[1])\n\ndef activated_pixels_fitness(p, e):\n    \"\"\" How close the predicted image to have the right pixels. Less is better.\"\"\"\n    shape = (max(p.shape[0], e.shape[0]), max(p.shape[1], e.shape[1]))\n    diff = np.zeros(shape, dtype=int)\n    diff[0:p.shape[0], 0:p.shape[1]] = (p > 0).astype(int)\n    diff[0:e.shape[0], 0:e.shape[1]] -= (e > 0).astype(int)\n    \n    return (diff != 0).sum()\n\ndef colors_fitness(p, e):\n    p_colors = np.unique(p)\n    e_colors = np.unique(e)\n    \n    nb_inter = len(np.intersect1d(p_colors, e_colors))\n\n    return (len(p_colors) - nb_inter) + (len(e_colors) - nb_inter)\n\nfitness_functions = [colors_fitness, activated_pixels_fitness, height_fitness, width_fitness]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The fitness score (less is better) of our function will be a 4-dimensional tuple containing the result of each of the fitness functions.\n\nWe want to be able to compare two score. Unfortunately, the *lixocographical order* is not adapted, as there is no reason than having a small `width score` is better than having a small `height score`. We are going to define a partial order that give the same weight to any fitness function.\n\nWhen we compare two tuple with this partial order, `(3, 2, 4, 0) < (3, 2, 5, 0)` and `(3, 2, 4, 0) < (4, 2, 4, 0)`. But there is no way to compare `(3, 2, 5, 0)` and `(4, 2, 4, 0)`. We say this two values are *incomparable*. If two score are incomparable, it means that we cannot say that one program is better than the over."},{"metadata":{"trusted":true},"cell_type":"code","source":"def product_less(a, b):\n    \"\"\" Return True iff the two tuples a and b respect a<b for the partial order. \"\"\"\n    a = np.array(a)\n    b = np.array(b)\n    return (np.array(a) < np.array(b)).all()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now write a function that evaluate the fitness of a program on a task."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ([[np.array] -> [np.array]], Taks) -> (int, int, ..., int)\ndef evaluate_fitness(program, task):\n    \"\"\" Take a program and a task, and return its fitness score as a tuple. \"\"\"\n    score = np.zeros((len(fitness_functions)))\n    \n    # For each sample\n    for sample in task:\n        i = np.array(sample['input'])\n        o = np.array(sample['output'])\n        \n        # For each fitness function\n        for index, fitness_function in enumerate(fitness_functions):\n            images = evaluate(program, i)\n            if images == []: # Penalize no prediction!\n                score[index] += 500\n            else: # Take only the score of the first output\n                score[index] = fitness_function(images[0], o)\n    return tuple(score)\n\nprint(\"Fitness evaluation:\", evaluate_fitness([groupByColor, cropToContent], task['train']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Asexual reproduction\n\nNow that we can compare two programs we need a way to generate some of them. We will generate them randomly from a pool of best candidate.\n\nFor the initial run, and also to be able to evaluate fresh candidates, we will also allow spontaneous generation of new born one instruction programs."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_candidates(allowed_nodes=[identity], best_candidates=[], nb_candidates=200):\n    \"\"\"\n    Create a poll of fresh candidates using the `allowed_nodes`.\n    \n    The pool contain a mix of new single instructions programs\n    and mutations of the best candidates.\n    \"\"\"\n    new_candidates = []\n    length_limit = 4 # Maximal length of a program\n    \n    def random_node():\n        return random.choice(allowed_nodes)\n    \n    # Until we have enougth new candidates\n    while(len(new_candidates) < nb_candidates):\n        # Add 10 new programs\n        for i in range(5):\n            new_candidates += [[random_node()]]\n        \n        # Create new programs based on each best candidate\n        for best_program in best_candidates:\n            # Add one op on its right but limit the length of the program\n            if len(best_program) < length_limit - 1:\n                new_candidates += [[random_node()] + best_program]\n            # Add one op on its left but limit the length of the program\n            if len(best_program) < length_limit - 1:\n                new_candidates += [best_program + [random_node()]]\n            # Mutate one instruction of the existing program\n            new_candidates += [list(best_program)]\n            new_candidates[-1][random.randrange(0, len(best_program))] = random_node()\n   \n    # Truncate if we have too many candidates\n    np.random.shuffle(new_candidates)\n    return new_candidates[:nb_candidates]\n\n# Test the function by building some candidates\nlen(build_candidates(allowed_nodes=[identity], best_candidates=[[identity]], nb_candidates=42))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find a program given a task\n\nThis is the last step to our genetic algorithm. We have all the building blocks:\n * Generating both new programs and mutation of existing solutions\n * Evaluating the fitness score of a program\n * Comparing two programs to know if one perform better than the other\n * Detecting when a solution was found\n \nWe can now write a function that will keep generating programs with increasing complexity until a solution is found.\n\nUsing our partial order, we are going to keep the best candidates. Because the order is partial,\nthere is no bound on how many uncomparables candidates we may have at a given iteration."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(task, max_iterations=20, verbose=True):\n    candidates_nodes = [\n        tail, init, union, intersect,\n        sortByColor, sortByWeight, reverse,\n        cropToContent, groupByColor, splitH,\n        negative\n    ]\n    \n    if verbose:\n        print(\"Candidates nodes are:\", [program_desc([n]) for n in candidates_nodes])\n        print()\n\n    best_candidates = {} # A dictionary of {score:candidate}\n    for i in range(max_iterations):\n        if verbose:\n            print(\"Iteration \", i+1)\n            print(\"-\" * 10)\n        \n        # Create a list of candidates\n        candidates = build_candidates(candidates_nodes, best_candidates.values())\n        \n        # Keep candidates with best fitness.\n        # They will be stored in the `best_candidates` dictionary\n        # where the key of each program is its fitness score.\n        for candidate in candidates:\n            score = evaluate_fitness(candidate, task)\n            is_uncomparable = True # True if we cannot compare the two candidate's scores\n            \n            # Compare the new candidate to the existing best candidates\n            best_candidates_items = list(best_candidates.items())\n            for best_score, best_candidate in best_candidates_items:\n                if product_less(score, best_score):\n                    # Remove previous best candidate and add the new one\n                    del best_candidates[best_score]\n                    best_candidates[score] = candidate\n                    is_uncomparable = False # The candidates are comparable\n                if product_less(best_score, score) or best_score == score:\n                    is_uncomparable = False # The candidates are comparable\n            if is_uncomparable: # The two candidates are uncomparable\n                best_candidates[score] = candidate\n\n        # For each best candidate, we look if we have an answer\n        for program in best_candidates.values():\n            if is_solution(program, task):\n                return program\n            \n        # Give some informations by selecting a random candidate\n        if verbose:\n            print(\"Best candidates lenght:\", len(best_candidates))\n            random_candidate_score = random.choice(list(best_candidates.keys()))\n            print(\"Random candidate score:\", random_candidate_score)\n            print(\"Random candidate implementation:\", program_desc(best_candidates[random_candidate_score]))\n    return None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Solve the task\n\nWe now apply our knowledge to solving the first task presented. We will run our algorithm and see how long it takes to generate a program that can solve the task. You may run the folowing cell multiple times to see the variance into how long the algorithm takes to find the answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"program = build_model(task['train'], verbose=True)\n\nprint()\nif program is None:\n    print(\"No program was found\")\nelse:\n    print(\"Found program:\", program_desc(program))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nThe actual search space is of size `14â€¯641 = 4**11`. This is the total number of programs that can be build under the current restrictions.\nIt is impressive that a simple algorithm as this one can find a solution so fast.\n\nNethertheless, there is a huge room for improvement.\n\nHere is a small list of ideas.\n\n* Add more fitness functions that would allow a faster convergence,\n* Keep more than one candidate per local minima found,\n* Extend the DSL to functions that allow solving more tasks,\n* Rework the dsl as an execution graph (cf: tensorflow / onnx neural net graphs),\n* Add speciation inspired from Neat / Neat-GP\n* Sample the candidate pool with probabilities according to the best candidates scores,\n* Add *sexual reproduction* to the programs, aka crossover.\n\nIf you read all the notebook to this line, you made it! Thanks you for staying with me all along. I hope this can help / inspire you to build your own approach to ARC or an other competitions.\n\nPlease let me know your thoughs in the comments. ðŸ™‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}