{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ARC - Abstraction and Reasoning Corpus - Geometry Simple Solvers\n\nThe Abstraction and Reasoning Corpus (ARC) contains 400+400=800 training + evaluation tasks, with Kaggle testing on 100+100=200 tasks.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Links and Resources\n\nCompetition Data\n- https://github.com/fchollet/ARC - Original Dataset Source\n\nPapers\n- https://arxiv.org/pdf/1911.01547.pdf - On the Measure of Intelligence - Francois Chollet's writeup of the problem space\n\nVisualization of Tasks\n- https://www.kaggle.com/zaharch/visualizing-all-tasks-updated\n- https://www.kaggle.com/boliu0/visualizing-all-task-pairs-with-gridlines\n- https://www.kaggle.com/maxjeblick/play-arc-interactively - Interactive Manual Solver\n\nCode Snippits\n- https://www.kaggle.com/inversion/abstraction-and-reasoning-starter-notebook - Basic Input / Output Code\n- https://www.kaggle.com/nagiss/manual-coding-for-the-first-10-tasks - Manual Coding\n- https://www.kaggle.com/paulorzp/15-tasks-crop-resize-repeat - +15 tasks (Crop, Resize, Repeat)\n\nSuggested Methodologies\n- https://www.kaggle.com/tarunpaparaju/arc-competition-eda-pytorch-cnn - PyTorch Machine Learning CNNs\n- https://www.kaggle.com/arsenynerinovsky/cellular-automata-as-a-language-for-reasoning - Cellular Automata\n- https://www.kaggle.com/zenol42/dsl-and-genetic-algorithm-applied-to-arc - DSL + Genetic Algorithms \n- https://www.kaggle.com/meaninglesslives/using-decision-trees-for-arc - Decision Trees\n\nOther Approaches\n- http://www.cs.toronto.edu/~sheila/2542/w09/A1/introtopddl2.pdf - PDDL (Planning Domain Definition Language) + Astar Search\n- https://stackoverflow.com/questions/613146/computing-the-difference-between-images - Image Differencing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Multi-Model Approach\n\nSome of the above resources suggest a single general-purpose solver algorithm for the entire corpus. However it may be possible to divide the corpus into several different classes of problem, some of which may have simple solutions. \n\nThe first challenge is to identifiy common classes of problems and subproblems, some of which are mentioned in Francois Chollet's paper [On the Measure of Intelligence](https://arxiv.org/pdf/1911.01547.pdf)\n\nProblems\n\n- Geometry\n    - do nothing\n    - rotate / mirror / shift image\n    - crop image background\n    - draw border\n\n\n- Objects\n    - rotate / mirror / shirt objects\n    - move two objects together\n    - move objects to edge\n    - extend / repeat an object\n    - delete an object\n    - count unique objects and select the object that appears the most times\n    - create pattern based on image colors\n    - overlay object\n    - replace objects\n\n\n- Coloring\n    - select colors for objects\n    - select dominant/smallest color in image\n    - denoise\n    - fill in empty spaces\n\n\n- Lines\n    - color edges\n    - extrapolate a straight/diagonal line\n    - draw a line between two dots / or inersections between such lines\n    - draw a spiral\n\n\n- Grids\n    - select grid squares with most pixels\n\n\n- Patterns\n    - complete a symmetrical/repeating pattern \n\n\n- Subtasks\n    - object detection / cohesion / seperation\n    - object persistance\n    - counting or sorting objects\n\n\nIf such problem classes can be correctly detected, it may be possible to get some quick wins by writing a libary of simple solvers for known problems. These could be tried in sequence before resorting to more advanced general purpose algorithms.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Loading the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport sys\nimport os\nimport re\nimport json\nimport cv2\nimport itertools\nimport traceback\nfrom itertools import chain, product, combinations\nfrom glob import glob\nfrom pathlib import Path\nfrom copy import copy, deepcopy\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom typing import List, Union, Callable\n\n\nimport toolz\nimport pydash as py\nfrom pydash import py_ as _","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_files = glob('../input/abstraction-and-reasoning-challenge/**/*.json')\n\ndef load_tasks(task_files):\n    if isinstance(task_files, str): task_files = glob(task_files)\n        \n    tasks = { re.sub(r'^.*/(.*?/.*$)','\\\\1',file): json.load(open(file, 'r')) for file in task_files }\n\n    for file, task in tasks.items():\n        for test_train, specs in task.items():\n            for index, spec in enumerate(specs):\n                for input_output, grid in spec.items():\n                    tasks[file][test_train][index][input_output] = np.array(grid).astype('uint8')  # uint8 required for cv2 \n\n    for file, task in tasks.items():\n        tasks[file]['file'] = file\n    return tasks\n\ntasks = load_tasks(task_files)\ntask = list(tasks.values())[6]; task","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modified from Source: https://www.kaggle.com/zaharch/visualizing-all-tasks-updated\ndef plot_one(task, ax, i,train_or_test,input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    \n    try:\n        input_matrix  = task[train_or_test][i][input_or_output]\n        font_size     = 50 / np.sqrt(input_matrix.shape[0] * input_matrix.shape[1])\n        min_font_size = 6 \n\n        ax.imshow(input_matrix, cmap=cmap, norm=norm)\n        ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n        ax.imshow(input_matrix, cmap=cmap, norm=norm)\n        # DOC: https://stackoverflow.com/questions/33828780/matplotlib-display-array-values-with-imshow\n        if font_size >= min_font_size:\n            for (j,i),label in np.ndenumerate(input_matrix):\n                ax.text(i,j,label,ha='center',va='center', fontsize=font_size, color='black')\n\n        ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n        ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.set_title(train_or_test + ' '+input_or_output)\n    except: pass  # mat throw on tests, as they have not \"output\"\n    \ndef plot_task(task, scale=2):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"   \n    filename = None\n    if isinstance(task, str):   (filename, task) = task, tasks[task]\n    if isinstance(task, tuple): (filename, task) = task\n    if 'file' in task: filename = task['file']\n    \n    num_train = len(task['train']) + len(task['test']) + 1\n    if 'solution' in task: num_train += len(task['solution']) + 1\n    \n    fig, axs = plt.subplots(2, num_train, figsize=(scale*num_train,scale*2))\n    if filename: fig.suptitle(filename)\n        \n    for i in range(len(task['train'])):     \n        plot_one(task, axs[0,i],i,'train','input')\n        plot_one(task, axs[1,i],i,'train','output')            \n\n    axs[0,i+1].axis('off'); axs[1,i+1].axis('off')\n    for j in range(len(task['test'])):      \n        plot_one(task, axs[0,i+2+j],j,'test','input')\n        plot_one(task, axs[1,i+2+j],j,'test','output')  \n    \n    if 'solution' in task:    \n        axs[0,i+j+3].axis('off'); axs[1,i+j+3].axis('off')        \n        for k in range(len(task['solution'])):      \n            plot_one(task, axs[0,i+j+4+k],k,'solution','input')\n            plot_one(task, axs[1,i+j+4+k],k,'solution','output')  \n\n    plt.show()     \n    \nplot_task(list(tasks.items())[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Do Nothing\n\nThe simplest problem is the Do Nothing problem. The input and the output are exactly the same.\n- This didn't find anything","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"solvers = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Solver():\n    verbose = True\n    debug   = False\n    def __init__(self):\n        self.cache = {}\n    \n    @staticmethod\n    def loop_specs(task, test_train='train'):\n        specs = task[test_train]\n        for index, spec in enumerate(specs):\n            yield { 'input': spec['input'], 'output': spec['output'] }\n\n    @staticmethod\n    def is_lambda_valid(_task_, _function_, *args, **kwargs):  # _task_ = avoid namespace conflicts with kwargs=task \n        for spec in Solver.loop_specs(_task_, 'train'):\n            output = _function_(spec['input'], *args, **kwargs)\n            if not np.array_equal( spec['output'], output):\n                return False\n        return True\n\n    @staticmethod\n    def solve_lambda(_task_, _function_, *args, **kwargs):\n        solutions = []\n        for index, spec in enumerate(_task_['test']):\n            result = _function_(spec['input'], *args, **kwargs)\n            solutions.append({ \n                \"input\":  spec['input'],\n                \"output\": result\n            })\n        return solutions\n\n    def action(self, grid, *args):\n        \"\"\"This is the primary method this needs to be defined\"\"\"\n        return grid\n        raise NotImplementedError()\n\n    def detect(self, task):\n        \"\"\"default heuristic is simply to run the solver\"\"\" \n        return self.test(task)\n\n    def test(self, task):\n        \"\"\"test if the given action correctly solves the task\"\"\"\n        args = self.cache.get(task['file'], ())\n        return self.is_lambda_valid(task, self.action, *args, task=task)    \n\n    def solve(self, task, force=False):\n        \"\"\"solve test case and persist\"\"\"\n        try:\n            if self.detect(task) or force:    # may generate cache\n                if self.test(task) or force:  # may generate cache\n                    args = self.cache.get(task['file'], ())\n                    if isinstance(args, dict):\n                        solutions = self.solve_lambda(task, self.action, **args, task=task)                    \n                    else:\n                        solutions = self.solve_lambda(task, self.action, *args, task=task)\n                    task['solution'] = solutions  # TODO: fix for multiple test outputs\n                    self.log_solved(task, args, solutions)\n                    return solutions\n        except Exception as exception:\n            if self.debug: raise exception\n        return None\n            \n    def solve_all(self, tasks, plot=False, solve_detects=False):\n        count = 0\n        for filename, task in tasks.items():    \n            if self.detect(task):\n                solution = self.solve(task, force=solve_detects)\n                if solution or (solve_detects and self.test(task)):\n                    count += 1\n                    if plot == True:\n                        plot_task((filename, task))        \n        return count\n\n    def plot(self, tasks):\n        return self.solve_all(tasks, plot=True, solve_detects=False)\n\n    def plot_detects(self, tasks, unsolved=True):\n        if unsolved:\n            tasks = { file: task for (file,task) in deepcopy(tasks).items() if not 'solution' in task }\n        return self.solve_all(tasks, plot=True, solve_detects=True)\n\n    \n    \n    ### Logging Methods ###\n\n    def format_args(self, args):\n        if isinstance(args, dict):\n            args = dict(zip(args.keys(), map(self.format_args, list(args.values()))))\n        elif isinstance(args, (list,set,tuple)):\n            args = list(args)\n            for index, arg in enumerate(args):\n                if hasattr(arg, '__name__'):\n                    arg = f\"<{type(arg).__name__}:{arg.__name__}>\"\n                if isinstance(arg, (list,set,tuple,dict)):\n                    arg = self.format_args(arg)\n                args[index] = arg\n            args = tuple(args)\n        return args\n\n    def log_solved(self, task, args: Union[list,tuple,set], solutions: List[np.ndarray]):\n        if not self.verbose: return\n        try:\n            task_filename = getattr(task,'filename',task.get('file',''))\n            if 'test' in task_filename:           label = 'test  '\n            elif self.is_solved(task, solutions): label = 'solved'\n            else:                                 label = 'guess '\n\n            args  = self.format_args(args) if len(args) else None\n            print(f'{label}:', task_filename, self.__class__.__name__, args)\n        except Exception as exception: \n            print('Exception:', type(exception), exception)\n            traceback.print_tb(exception.__traceback__)\n\n    \n    def is_solved(self, task, solutions: List):\n        for solution in solutions:\n            for problem in task['test']:\n                if 'output' in solution and np.array_equal(problem['output'], solution['output']):\n                    return True\n        return False\n    \n    ### Helper Methods ###\n    \n    @staticmethod\n    def grid_shape_ratio(grid1, grid2):\n        try:\n            return ( grid2.shape[0] / grid1.shape[0], grid2.shape[1] / grid1.shape[1] )\n        except:\n            return (0, 0)  # For tests\n    \n    @staticmethod\n    def task_grids(task):\n        grids = []\n        for test_train in ['test','train']:\n            for spec in task[test_train]:\n                grids += [ spec.get('input',[]), spec.get('output',[]) ]  # tests not gaurenteed to have outputs\n        return grids\n\n    @staticmethod\n    def task_grid_shapes(task):\n        return [ np.array(grid).shape for grid in Solver.task_grids(task) ]\n    \n    @staticmethod\n    def task_grid_max_dim(task):\n        return max(chain(*Solver.task_grid_shapes(task)))\n    \n    @staticmethod\n    def task_shape_ratios(task):\n        ratios = set([\n            Solver.grid_shape_ratio(spec.get('input',[]), spec.get('output',[]))\n            for spec in Solver.loop_specs(task, 'train')\n        ])\n        # ratios = set([ int(ratio) if ratio.is_integer() else ratio for ratio in chain(*ratios) ])\n        return ratios\n\n    @staticmethod\n    def is_task_shape_ratio_unchanged(task):\n        return Solver.task_shape_ratios(task) == { (1,1) }\n\n    @staticmethod\n    def is_task_shape_ratio_consistant(task):\n        return len(Solver.task_shape_ratios(task)) == 1\n    \n    @staticmethod\n    def is_task_shape_ratio_integer_multiple(task):\n        ratios = Solver.task_shape_ratios(task)\n        return all([ isinstance(d, int) or d.is_integer() for d in chain(*ratios) ])\n        \n    \nprint( 'Solver().task_grid_shapes(task)',                     Solver().task_grid_shapes(task)  )\nprint( 'Solver().task_grid_max_dim(task)',                    Solver().task_grid_max_dim(task) )\nprint( 'Solver().task_shape_ratios(task)',                    Solver().task_shape_ratios(task) )\nprint( 'Solver().is_task_shape_ratio_consistant(task)',       Solver().is_task_shape_ratio_consistant(task) )\nprint( 'Solver().is_task_shape_ratio_unchanged(task)',        Solver().is_task_shape_ratio_unchanged(task)  )\nprint( 'Solver().is_task_shape_ratio_integer_multiple(task)', Solver().is_task_shape_ratio_integer_multiple(task) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DoNothingSolver(Solver):\n    def action(self, grid, task):\n        return grid\n\nsolvers['DoNothingSolver'] = DoNothingSolver()\nsolvers['DoNothingSolver'].plot(tasks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DoNothingSolver found nothing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Rescale Image\n\nZooming in and out can be performed using `cv2.resize()` and `skimage.measure.block_reduce()`. We get 4 matches.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import skimage.measure\n\nclass ZoomSolver(Solver):\n    verbose = True\n    \n    def detect(self, task):\n        ratios = self.task_shape_ratios(task)\n        ratio  = list(ratios)[0] \n        detect = (\n                ratios != { (1,1) }   # not no scaling\n            and len(ratios) == 1      # not multiple scalings\n            and ratio[0] == ratio[1]  # single consistant scaling\n        )\n        return detect\n\n    def get_scale(self, task):\n        return list(self.task_shape_ratios(task))[0][0]\n            \n    def action(self, grid, task):\n        scale = self.get_scale(task)\n        if scale > 1:\n            resize = tuple( int(d*scale) for d in grid.shape )            \n            output = cv2.resize(grid, resize, interpolation=cv2.INTER_NEAREST)\n        else:\n            resize = tuple( int(1/scale) for d in grid.shape )                        \n            output = skimage.measure.block_reduce(grid, resize)\n        if self.debug:\n            print('scale', scale, 'grid.shape', grid.shape, 'output.shape', output.shape)\n            print('grid', grid)\n            print('output', output)            \n        return output\n\nsolvers['ZoomSolver'] = ZoomSolver()\nZoomSolver().plot(tasks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Geometry Problems\n\nHere we just apply a set of prebuilt numpy geometry functions, and get 8 matches","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class GeometrySolver(Solver):\n    optimise = True\n    verbose  = True\n    actions = {\n        \"flip\":      ( np.flip,      [0,1]    ),\n        \"rot90\":     ( np.rot90,     [1,2,3]  ),\n        \"roll\":      ( np.roll,      product(range(-5,5),[0,1]) ),  \n        \"swapaxes\":  ( np.swapaxes,  [(0, 1),(1, 0)] ),             \n        \"transpose\": ( np.transpose, []       ),                      # this doesn't find anything                \n    }\n    \n    def __init__(self):\n        super().__init__()\n        for key, (function, arglist) in self.actions.items():\n            self.actions[key] = (function, [ (args,) if not isinstance(args, tuple) else args for args in arglist ])            \n    \n    def detect(self, task):\n        return self.is_task_shape_ratio_unchanged(task)  # grids must remain the exact same size\n        \n    def test(self, task):\n        if task['file'] in self.cache: return True\n        \n        max_roll = (self.task_grid_max_dim(task) + 1) // 2 \n        for key, (function, arglist) in self.actions.items():\n            if function == np.roll: arglist = product(range(-max_roll,max_roll),[0,1]) \n            for args in arglist:\n                if self.is_lambda_valid(task, function, *args):\n                    self.cache[task['file']] = (function, args)\n                    if self.verbose: print(function, args)\n                    return True\n                \n        # this doesn't find anything\n        if self.optimise: return False        \n        for ((function1, arglist1),(function2, arglist2)) in combinations( self.actions.values(), 2 ):\n            if function1 == np.roll: arglist1 = product(range(-max_roll,max_roll),[0,1]) \n            if function2 == np.roll: arglist2 = product(range(-max_roll,max_roll),[0,1]) \n            for args1, args2 in product(arglist1, arglist2):\n                function = lambda grid, args1, args2: function1(function2(grid, *args2), *args1)                \n                if self.is_lambda_valid(task, function, *(args1,args2)):\n                    self.cache[task['file']] = (function, (args1,args2))\n                    if self.verbose: print(function, (args1,args2))\n                    return True\n        return False\n    \n    def action(self, grid, function=None, args=None, task=None):\n        try:\n            return function(grid, *args)\n        except Exception as exception:\n            if self.debug: print(function, args, exception)\n            return grid\n\nsolvers['GeometrySolver'] = GeometrySolver()\nGeometrySolver().plot(tasks)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tessellation Problems","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import skimage.measure\n# from skimage.measure import block_reduce\nimport inspect\nfrom fastcache import lru_cache\n# from numpy_lru_cache_decorator import np_cache  # https://gist.github.com/Susensio/61f4fee01150caaac1e10fc5f005eb75\n\ndef query_true(grid,x,y):          return True\ndef query_not_zero(grid,x,y):      return grid[x,y]\ndef query_color(grid,x,y,color):   return grid[x,y] == color\n\n# evaluation/15696249.json - max(1d.argmax())\ndef query_max_color(grid,x,y,exclude_zero=True):     \n    return grid[x,y] == max_color(grid, exclude_zero)\n# @lru_cache(1024)\ndef max_color(grid, exclude_zero=True):\n    bincount = np.bincount(grid.flatten())\n    if exclude_zero:    \n        bincount[0] = np.min(bincount)  # exclude 0\n    return bincount.argmax()\n\ndef query_min_color(grid,x,y, exclude_zero=True):     \n    return grid[x,y] == min_color(grid, exclude_zero)\n# @lru_cache(1024)\ndef min_color(grid,exclude_zero=True):\n    bincount = np.bincount(grid.flatten())\n    if exclude_zero:\n        bincount[0] = np.max(bincount)  # exclude 0\n    return bincount.argmin()\n\ndef query_max_color_1d(grid,x,y,exclude_zero=True):     \n    return grid[x,y] == max_color_1d(grid)\n# @lru_cache(16)\ndef max_color_1d(grid,exclude_zero=True):\n    return max(\n        [ max_color(row,exclude_zero) for row in grid ] +\n        [ max_color(col,exclude_zero) for col in np.swapaxes(grid, 0,1) ]        \n    )\ndef query_min_color_1d(grid,x,y):     \n    return grid[x,y] == min_color_1d(grid)\n# @lru_cache(16)\ndef min_color_1d(grid):\n    return min(\n        [ min_color(row) for row in grid ] +\n        [ min_color(col) for col in np.swapaxes(grid, 0,1) ]        \n    )\n\n\ndef query_count_colors(grid,x,y):     \n    return grid[x,y] >= count_colors(grid)    \ndef query_count_colors_row(grid,x,y):     \n    return x + len(grid.shape[0])*y <= count_colors(grid)    \ndef query_count_colors_col(grid,x,y):     \n    return y + len(grid.shape[1])*x <= count_colors(grid)    \n# @lru_cache(16)\ndef count_colors(grid):\n    bincount = np.bincount(grid.flatten())\n    return np.count_nonzero(bincount[1:]) # exclude 0\n\ndef query_count_squares(grid,x,y):     \n    return grid[x,y] >= count_squares(grid)    \ndef query_count_squares_row(grid,x,y):     \n    return x + len(grid.shape[0])*y <= count_squares(grid)    \ndef query_count_squares_col(grid,x,y):     \n    return y + len(grid.shape[1])*x <= count_squares(grid)    \n# @lru_cache(16)\ndef count_squares(grid):\n    return np.count_nonzero(grid.flatten())\n\n# BROKEN?\ndef rotate_loop(grid, start=0):    \n    angle = start\n    while True:\n        yield np.rot90(grid, angle % 4)\n        angle += 1 * np.sign(start)\n\n# BROKEN?\ndef rotate_loop_rows(grid, start=0):    \n    angle = start\n    while True:\n        yield np.rot90(grid, angle % grid.shape[0])\n        angle += 1 * np.sign(start)\n\n# BROKEN?\ndef rotate_loop_cols(grid, start=0):    \n    angle = start\n    while True:\n        yield np.rot90(grid, angle % grid.shape[1])\n        angle += 1 * np.sign(start)\n\ndef flip_loop(grid, start=0):    \n    angle = start\n    while True:\n        if angle % 2: yield np.flip(grid)\n        else:         yield grid\n        angle += 1 * np.sign(start)\n\n# BROKEN?\ndef flip_loop_rows(grid, start=0):    \n    angle = start\n    while True:\n        if angle % grid.shape[0]: yield np.flip(grid)\n        else:                     yield grid\n        angle += 1 * np.sign(start)\n\n# BROKEN?\ndef flip_loop_cols(grid, start=0):    \n    angle = start\n    while True:\n        if angle % grid.shape[1]: yield np.flip(grid)\n        else:                     yield grid\n        angle += 1 * np.sign(start)\n\n# BROKEN?\ndef invert(grid, color=None):\n    if callable(color): color = color(grid)\n    if color is None:   color = max_color(grid)\n    if color:\n        grid        = grid.copy()\n        mask_zero   = grid[ grid == 0 ]\n        mask_square = grid[ grid != 0 ]    \n        grid[mask_zero]   = color\n        grid[mask_square] = 0\n    return grid    \n        \n    \n        \n# Source: https://codereview.stackexchange.com/questions/132914/crop-black-border-of-image-using-numpy         \ndef crop_inner(grid,tol=0): \n    mask = grid>tol; \n    return grid[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_outer(grid,tol=0):\n    mask = grid>tol\n    m,n  = grid.shape\n    mask0,mask1 = mask.any(0),mask.any(1)\n    col_start,col_end = mask0.argmax(),n-mask0[::-1].argmax()\n    row_start,row_end = mask1.argmax(),m-mask1[::-1].argmax()\n    return grid[row_start:row_end,col_start:col_end]\n\ndef make_tuple(args):\n    if isinstance(args, tuple): return args\n    if isinstance(args, list):  return tuple(args)\n    return (args,)\n\n\nclass TessellationSolver(GeometrySolver):\n    verbose = True\n    debug   = False\n    options = {\n        \"preprocess\": { \n            \"np.copy\":    (np.copy, []), \n            \"crop_inner\": (crop_inner, range(0,9)),\n            \"crop_outer\": (crop_outer, range(0,9)),\n        },\n        \"transform\": {  \n            \"none\":              ( np.copy,      []        ),\n            \"flip\":              ( np.flip,      [0,1]     ),\n            \"rot90\":             ( np.rot90,     [1,2,3]   ),\n            \"roll\":              ( np.roll,      product([-1,1],[0,1]) ),  \n            \"swapaxes\":          ( np.swapaxes,  [(0, 1)]  ),                         \n            \"rotate_loop\":       ( rotate_loop,         range(-4,4) ),\n            \"rotate_loop_rows\":  ( rotate_loop_rows,    range(-4,4) ),  # BROKEN ?\n            \"rotate_loop_cols\":  ( rotate_loop_cols,    range(-4,4) ),  # BROKEN ?          \n            \"flip_loop\":         ( flip_loop,           range(0,2)  ),  # BROKEN ?\n            \"flip_loop_rows\":    ( flip_loop_rows,      range(0,2)  ),  # BROKEN ?\n            \"flip_loop_cols\":    ( flip_loop_cols,      range(0,2)  ),  # BROKEN ?\n            \"invert\":            ( invert,              [max_color, min_color, max_color_1d, count_colors, count_squares, *range(1,9)]  ), # BROKEN\n            # TODO: Invert\n        },\n        \"query\": {\n            \"query_true\":              ( query_true,          [] ),\n            \"query_not_zero\":          ( query_not_zero,      [] ),  \n            \"query_max_color\":         ( query_max_color,     [] ),\n            \"query_min_color\":         ( query_min_color,     [] ),\n            \"query_max_color_1d\":      ( query_max_color_1d,  [] ),\n            \"query_min_color_1d\":      ( query_min_color_1d,  [] ),\n            \"query_count_colors\":      ( query_count_colors,      [] ),\n            \"query_count_colors_row\":  ( query_count_colors_row,  [] ),\n            \"query_count_colors_col\":  ( query_count_colors_col,  [] ),            \n            \"query_count_squares\":     ( query_count_squares,     [] ),\n            \"query_count_squares_row\": ( query_count_squares_row, [] ),\n            \"query_count_squares_col\": ( query_count_squares_col, [] ),\n            \"query_color\":             ( query_color,         range(0,10) ),  # TODO: query_max_color() / query_min_color()\n        }\n    }\n\n    \n    def detect(self, task):\n        if self.is_task_shape_ratio_unchanged(task):            return False  # Use GeometrySolver\n        if not self.is_task_shape_ratio_integer_multiple(task): return False  # Not a Tessalation problem   \n        if not all([ count_colors(spec['input']) == count_colors(spec['output']) for spec in task['train'] ]): return False  # Different colors \n        if ZoomSolver().solve(task):                            return False\n        #if not self.is_task_shape_ratio_consistant(task):       return False  # Some inconsistant grids are tessalations\n        return True\n\n\n    \n    def loop_options(self):\n        for (preprocess,p_args) in self.options['preprocess'].values():\n            # print( (preprocess,p_args) )\n            for p_arg in p_args or [()]:\n                p_arg = make_tuple(p_arg)\n                # print( (preprocess,p_args) )\n                for (transform,t_args) in self.options['transform'].values():\n                    for t_arg in t_args or [()]:\n                        t_arg = make_tuple(t_arg)\n                        for (query,q_args) in self.options['query'].values():\n                            for q_arg in q_args or [()]:\n                                q_arg = make_tuple(q_arg)\n                                yield (preprocess, p_arg),(transform,t_arg),(query,q_arg)\n    \n    # TODO: hieraracharical nesting of solves and solutions/rules array generator\n    def test(self, task):\n        if task['file'] in self.cache: return True\n        for (preprocess,p_arg),(transform,t_arg),(query,q_arg) in self.loop_options():         \n            kwargs = {                \n                \"preprocess\": preprocess,\n                \"p_arg\":      p_arg,\n                \"transform\":  transform,  # TODO: invert every other row | copy pattern from train outputs | extend lines\n                \"t_arg\":      t_arg,\n                \"query\":      query,  # TODO: max_colour limit counter\n                \"q_arg\":      q_arg,\n            }                        \n            if self.is_lambda_valid(task, self.action, **kwargs, task=task):\n                self.cache[task['file']] = kwargs\n                if self.verbose: print(self.action, kwargs)\n                return True\n        return False\n        \n       \n    def action(self, grid, preprocess=np.copy, p_arg=(), transform=np.copy, t_arg=(), query=query_true, q_arg=(), task=None):         \n        #print('action', preprocess, transform, query)\n        if inspect.isgeneratorfunction(transform):\n            generator = transform(grid, *t_arg)\n            transform = lambda grid, *args: next(generator)\n        \n        # Some combinations of functions will throw gemoetry             \n        try:                                        \n            grid    = preprocess(grid, *p_arg) \n            output  = self.get_output_grid(grid, task).copy()\n            ratio   = ( int(output.shape[0] / grid.shape[0]), int(output.shape[1] / grid.shape[1]) )\n            (gx,gy) = grid.shape\n            for x,y in product(range(ratio[0]),range(ratio[1])):\n                copy = np.zeros(grid.shape)\n                if query(grid,x%gx,y%gy, *q_arg):            \n                    copy = transform(grid, *t_arg)\n\n                output[x*gx:(x+1)*gx, y*gy:(y+1)*gy] = copy\n        except Exception as exception: \n            if self.debug: print(exception)\n            pass\n        return output\n    \n    \n    def loop_ratio(self, task):\n        ratio = list(self.task_shape_ratios(task))[0]\n        for i in range(int(ratio[0])):\n            for j in range(int(ratio[1])):            \n                yield i,j\n\n                \n    def get_output_grid(self, grid, task):\n        try:\n            #print('get_output_grid(self, grid, task)', grid, task)\n            for index, spec in enumerate(task['train']):\n                if spec['input'] is grid:\n                    return spec['output']\n            else:\n                # No output for tests\n                ratio = list(self.task_shape_ratios(task))[0]\n                ratio = list(map(int, ratio))\n                shape = ( int(grid.shape[0]*ratio[0]), int(grid.shape[1]*ratio[1]) )\n                return np.zeros(shape)\n        except Exception as exception: \n            if self.debug: print(exception)\n            pass\n            \n     \nsolvers['TessellationSolver'] = TessellationSolver()\nsolvers['TessellationSolver'].plot(tasks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from copy import deepcopy\nsolvers['TessellationSolver'].plot_detects(tasks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fill In Blank Areas","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_task('test/31adaf00.json')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Border Problems","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class BorderSolver(Solver):\n    verbose = True\n    debug = True\n    cache = {}\n    queries = [\n        *range(0,10),\n        max_color,     # FAIL: evaluation/fc754716.json\n        max_color_1d,\n        min_color,\n        min_color_1d,\n        count_colors,\n        count_squares,\n        np.count_nonzero,\n    ]\n\n    def task_has_border(self, task): \n        if not self.is_task_shape_ratio_consistant(task): return False        \n        return all([ self.grid_has_border(spec['output']) for spec in task['train'] ])\n        \n    def grid_has_border(self, grid):\n        if min(grid.shape) <= 2:                          return False  # single color problem\n\n        grid_center = grid[1:-1,1:-1]        \n        return np.count_nonzero(grid_center) == 0 and all([\n            np.count_nonzero(border) == len(border)\n            for border in [ grid[0,:], grid[-1,:], grid[:,0], grid[:,-1] ]\n        ])\n    \n    def detect(self, task):\n        return self.task_has_border(task)\n    \n    def test(self, task):\n        if task['file'] in self.cache: return True\n        for query in self.queries:         \n            args = [ query ]\n            if self.is_lambda_valid(task, self.action, *args, task=task):\n                self.cache[task['file']] = args\n                if self.debug: print(self.action, args)\n                return True\n        return False\n        \n    def action(self, grid, query=None, task=None):\n        ratio  = list(self.task_shape_ratios(task))[0]\n        output = np.zeros(( int(grid.shape[0] * ratio[0]), int(grid.shape[1] * ratio[1]) ))\n        color  = query(grid) if callable(query) else query \n        output[:,:] = color\n        output[1:-1,1:-1] = 0\n        return output\n\nsolvers['BorderSolver'] = BorderSolver()\nsolvers['BorderSolver'].plot(tasks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solvers['BorderSolver'].plot_detects(tasks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Single Color Problems","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class SingleColorSolver(Solver):\n    verbose = True\n    debug = True\n    cache = {}\n    queries = [\n        *range(0,10),\n        max_color,     # FAIL: evaluation/fc754716.json\n        max_color_1d,\n        min_color,\n        min_color_1d,\n        count_colors,\n        count_squares,\n        np.count_nonzero,\n    ]\n\n    def grid_unique_colors(self, grid):\n        return np.unique(grid.flatten())\n    \n    def task_is_singlecolor(self, task): \n        if not self.is_task_shape_ratio_consistant(task): return False        \n        return all([ len(self.grid_unique_colors(spec['output'])) == 1 for spec in task['train'] ])\n                \n    def detect(self, task):\n        return self.task_is_singlecolor(task)\n    \n    def test(self, task):\n        if task['file'] in self.cache: return True\n        for query in self.queries:         \n            args = [ query ]\n            if self.is_lambda_valid(task, self.action, *args, task=task):\n                self.cache[task['file']] = args\n                if self.debug: print(self.action, args)\n                return True\n        return False\n        \n    def action(self, grid, query=None, task=None):\n        ratio  = list(self.task_shape_ratios(task))[0]\n        output = np.zeros(( int(grid.shape[0] * ratio[0]), int(grid.shape[1] * ratio[1]) ))        \n        color  = query(grid) if callable(query) else query \n        output[:,:] = color\n        return output\n\nsolvers['SingleColorSolver'] = SingleColorSolver()\nsolvers['SingleColorSolver'].plot(tasks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solvers['SingleColorSolver'].plot_detects(tasks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_task('training/1190e5a7.json')\nplot_task('training/23b5c85d.json')\nplot_task('training/27a28665.json')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scores","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_tasks(tasks: dict, label: str):\n    total  = 0\n    solved = 0\n\n    for task_file, task in tasks.items():\n        for index, spec in enumerate(task['test']): total += 1            \n\n        if 'solution' in task:\n            for index, spec in enumerate(task['solution']): \n                solved += 1                \n        \n    print(f'{label.ljust(11)}| solutions found: {str(solved).rjust(3)}/{total} | error: {round(1-solved/total,4)}')\n    return solved\n\nfor label in ['training', 'evaluation', 'test']:\n    score_tasks({ file: task for (file,task) in tasks.items() if label in file }, label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Test Submission\n\nThe tests are a little more tricky than the simplest problems in the training dataset. As such, all the above work only finds a single solution in the test dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_files = glob('../input/abstraction-and-reasoning-challenge/test/*.json'); \ntests = load_tasks(test_files)\nlen(tests)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, solver in solvers.items():\n    solver.cache = {}\n    solver.plot(tests)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluation Submission Format:\n- https://www.kaggle.com/c/abstraction-and-reasoning-challenge/overview/evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# def output_id(filename, index=0):\n#     return re.sub('^.*/|\\.json$', '', filename) + '_' + str(index);\n\n# def output_grid(grid):\n#     grid   = grid.astype('uint8').tolist()\n#     # output = \" \".join([\n#     #     '|' + \"\".join([ str(int(cell)) for cell in row ]) + '|'\n#     #     for row in grid\n#     # ])\n#     output = (\n#         json.dumps(grid)\n#             .replace(', ', '')\n#             .replace('[[', '|')\n#             .replace('][', '|')\n#             .replace(']]', '|')\n#     )\n#     return output\n\n# def output_csv(tests, submission_file='submission.csv', verbose=True):\n#     output = []\n#     for task_file, test in tests.items():\n#         if 'solution' in test: \n#             for index, spec in enumerate(test['solution']): \n#                 output.append([ output_id(task_file, index), output_grid(spec['output']) ])\n#         else:\n#             for index, spec in enumerate(test['test']):             \n#                 output.append([ output_id(task_file, index), output_grid(spec['input']) ])            \n\n#     output = [['output_id','output']] + sorted(output)\n#     csv = \"\\n\".join([ \",\".join(row) for row in output ])\n\n#     with open(submission_file, 'w') as file:\n#         file.write(csv)\n#         if verbose: print(f'wrote: {submission_file}')\n\n# output_csv(tests, 'submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndef output_id(filename, index=0):\n    return re.sub('^.*/|\\.json$', '', filename) + '_' + str(index);\n\n# Source: https://www.kaggle.com/c/abstraction-and-reasoning-challenge/overview/evaluation\ndef flattener(grid):\n    grid = grid.astype('uint8').tolist()    \n    str_pred = str([row for row in grid])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\ndef write_submission_csv(tests):\n    submission_csv = pd.read_csv('../input/abstraction-and-reasoning-challenge/sample_submission.csv')\n    submission_csv = submission_csv.set_index('output_id')\n\n    total  = 0\n    solved = 0\n    for task_file, test in tests.items():    \n        for index, spec in enumerate(test['test']): total += 1\n        if 'solution' in test:\n            for index, spec in enumerate(test['solution']): \n                submission_csv.loc[ output_id(task_file, index), 'output' ] = flattener(spec['output'])\n                solved += 1                \n        \n                \n    submission_csv.to_csv('submission.csv')\n    print(f'wrote: submission.csv')\n    print(f'solutions found: {solved}/{total} | error: {round(1-solved/total,4)}')\n    return submission_csv\n\nwrite_submission_csv(tests)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}