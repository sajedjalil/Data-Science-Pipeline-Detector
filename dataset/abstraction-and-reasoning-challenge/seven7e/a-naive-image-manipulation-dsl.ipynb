{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this work I'm gonna design & implement a functional-style DSL based on simple image manipulation like movement, flipping, connected region extraction, color separation, etc. It's called \"naive\" because it's intuitive and straightforward.\n\n<p><font color=\"green\" size=3>If you like this kernel please upvote. It encorages me to produce more quality content!</font></p>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'\n\ntraining_tasks = sorted(os.listdir(training_path))\nevaluation_tasks = sorted(os.listdir(evaluation_path))\ntest_tasks = sorted(os.listdir(test_path))\nprint(len(training_tasks), len(evaluation_tasks), len(test_tasks))\n\ndef read_data_file(task_filename):\n    with open(task_filename, 'r') as f:\n        task = json.load(f)\n    return task\n\ndef get_data(dataset, index):\n    if dataset == 'training':\n        p = training_path\n        t = training_tasks\n    elif dataset == 'evaluation':\n        p = evaluation_path\n        t = evaluation_tasks\n    elif dataset == 'test':\n        p = test_path\n        t = test_tasks\n    \n    return read_data_file(str(p / t[index]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This Naive Image Manipulation (NIM) DSL contains a set of basic functions and two form of operations. Function is pure which means it doesn't modify the input.\n\n- `f` is a function that maps input to output. The input and/or output can be\n    + `array`: an image\n    + `[array]`: a list of images\n    + `Color`: color in image\n    + `int`: attributes or statistics of a image\n    + `bool`: conditions or testing\n    + functions: high-order functions\n- two operations:\n    + `>>`: composition, or pipeline. `f >> g` is equivalent to `g(f(x))`\n    + `[]`: parametisation. e.g. `move[1]` shifts input image right by 1. `cgt[1]` checks if input value is greater than 1. Seme functions have zero parameter, e.g. `flipx` flips the input image horizontally\n    \nThe functions can be roughly put into categories (current function set is far from complete, so this DSL can only solve a subset of tasks. More basic operations need to be added):\n\n- image transformation: `array -> array`\n- image separation: `array -> [array]`\n- image merging: `[array] -> array`\n- attribute/statistics: `array -> int`\n- testing: `array -> bool`, `int -> bool`, `[bool] -> bool`\n- high order: like map, filter, etc\n\nIn the following, each function only has one input appearing at the first place in the parameter list of a Python's function. The rest are parameterisable ones which should be passed with a constant value in the form of `foo[parameter]`. This is a drawback in cases where functions require two inputs, like `mask` which applys a mask to an image. In such case, the function has to take a list of images (actually it should be a list of two elements in the case of `mask`). I'm not sure this one-input constraint is sufficient for this task. I would appreciate if you come up with an idea to support or improve it."},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import Any, List, Callable, TypeVar, NewType\nImage = np.ndarray\nColor = NewType('Color', str)\nT = TypeVar('T', Image, List, Color, int, bool)\nS = TypeVar('S', Image, List, Color, int, bool)\n\ncolor_codes = ['k',     'b',    'r',   'g',     'y',      'e',    'p',      'o',      'z',     'n']\ncolor_names = ['black', 'blue', 'red', 'green', 'yellow', 'gray', 'purple', 'orange', 'azure', 'brown']\ncolor_indices = {}\nfor i, (n, c) in enumerate(zip(color_names, color_codes)):\n    color_indices[n] = i\n    color_indices[c] = i\ncolor_indices['grey'] = color_indices['gray']\n\nTYPE_NAMES = {\n    Image: 'Image',\n    List: 'List',\n    Color: 'Color',\n    int: 'Int',\n    bool: 'Bool',\n    Any: 'Any',\n    T: 'T',\n    S: 'S'\n}\n\ndef _get_type_name(typ):\n    if hasattr(typ, '__origin__') and typ.__origin__ is List:\n        return '{}[{}]'.format(TYPE_NAMES[typ.__origin__],\n            ','.join(_get_type_name(a) for a in typ.__args__))\n    return TYPE_NAMES.get(typ, str(typ))\n\ndef _is_type_compatible(t, s):\n#     print(t, s)\n#     print(t.__origin__, s.__origin__)\n#     print(t.__origin__ is list, s.__origin__ is list)\n    if t == s:\n        return True\n    if t in (T, S) or s in (T, S):\n        return True\n    if (t is List or t.__origin__ is List) \\\n        and (s is List or s.__origin__ is List):\n        return True\n    return False\n\nBACKGROUND = 0\n\n_neighbor_offsets = {\n    4: [(1, 0), (-1, 0), (0, 1), (0, -1)],\n    8: [(1, 0), (-1, 0), (0, 1), (0, -1), (-1, -1), (-1, 1), (1, -1), (1, 1)]\n}\ndef _expand_region_indices(img, i, j, neighbor=4):\n    h, w = img.shape\n    seed_color = img[i, j]\n    idx = np.zeros_like(img, dtype=np.bool)\n    region = []\n    region.append((i, j))\n    while len(region) > 0:\n        ii, jj = region.pop()\n        if img[ii, jj] != seed_color:\n            continue\n        idx[ii, jj] = True\n        for di, dj in _neighbor_offsets[neighbor]:\n            ni, nj = ii + di, jj + dj\n            if ni >= 0 and ni < h and nj >= 0 and nj < w \\\n                    and not idx[ni, nj]:\n                region.append((ni, nj))\n    return idx\n\n\nclass _Func(object):\n    def __init__(self, func, *args):\n        #print(func, args)\n        self._func = func\n        if not isinstance(func, _Func):\n            self._input_type = func.__annotations__[func.__code__.co_varnames[0]]\n            self._output_type = func.__annotations__['return']\n        else:\n            raise ValueError('should not reach here')\n        self._args = args\n        \n    def __call__(self, x):\n        #print(self)\n        #print(self._args)\n        return self._func(x, *self._args)\n    \n    def __getitem__(self, args):\n        # print(self, self._args, args)\n        if type(args) == tuple:\n            return _Func(self._func, *self._args, *args)\n        else:\n            return _Func(self._func, *self._args, args)\n        \n    def __rshift__(self, other):\n        if not _is_type_compatible(other._input_type, self._output_type):\n            raise ValueError('Cannot compose functions: {}: {}, {}: {}' \\\n                             .format(self, self._get_type_anno(), \n                                     other, other._get_type_anno()))\n        f = lambda x: other(self(x))\n        f.__name__ = str(self) + ' >> ' + str(other)\n        f.__annotations__['x'] = self._input_type\n        f.__annotations__['return'] = other._output_type\n        return _Func(f)\n        \n    def __str__(self):\n        if len(self._args) > 0:\n            s = self._func.__name__ + '[' + ', '.join(\n                ('<A>' if isinstance(s, np.ndarray) else str(s)) for s in self._args) + ']'\n        else:\n            s = self._func.__name__\n        #s += ': ' + self._get_type_anno()\n        return s\n    \n    def _get_type_anno(self):\n        return '{} -> {}'.format(_get_type_name(self._input_type), _get_type_name(self._output_type))\n\n    def to_str_with_anno(self):\n        return '{}: {}'.format(self, self._get_type_anno())\n    \ndef Func(func):\n    f = _Func(func)\n    print('func created:\\t' + f.to_str_with_anno().replace(': ', ':\\t'))\n    return f\n    \ndef _creator(func, debug=False):\n    def _func(inp):\n        f = func(inp)\n        if debug:\n            print(f)\n        return f(inp)\n    return _func\n\n# Func creator is a lazy initialisation of functions with the input image as parameter\nFCreator = _creator\nFCreatorD = lambda f: _creator(f, True)\n\ndef zeros_image(w, h) -> Image:\n    return np.zeros(h, w, dtype=np.int)\n\n@Func\ndef ident(img: T) -> T:\n    return img\n    \n########### size #############\n\n@Func\ndef zoom_out(img: Image, nx, ny=None, xofst=0, yofst=None) -> Image:\n    if ny is None:\n        ny = nx\n    if yofst is None:\n        yofst = xofst\n        \n    if xofst == 0 and yofst == 0:\n        return np.array(np.kron(img, np.ones((ny, nx))), dtype=np.int)\n    else:\n        h, w = img.shape\n        th = h * ny + yofst * (h - 1)\n        tw = w * nx + xofst * (w - 1)\n        # print(h, w, th, tw)\n        ret = np.zeros((th, tw), dtype=img.dtype)\n        for iiy, iy in enumerate(range(0, th, ny+yofst)):\n            for iix, ix in enumerate(range(0, tw, nx+xofst)):\n                #print(ix, iy)\n                ret[iy:iy+ny, ix:ix+nx] = img[iiy, iix]\n        return ret\n    \n@Func\ndef tile(img: Image, nx, ny=None, xofst=0, yofst=None) -> Image:\n    if ny is None:\n        ny = nx\n    if yofst is None:\n        yofst = xofst\n        \n    if xofst == 0 and yofst == 0:\n        #return np.array(np.kron(np.ones((n, n)), img), dtype=np.int)\n        return np.tile(img, (ny, nx))\n    else:\n        h, w = img.shape\n        th = h * ny + yofst * (ny - 1)\n        tw = w * nx + xofst * (nx - 1)\n        # print(h, w, th, tw)\n        ret = np.zeros((th, tw), dtype=img.dtype)\n        for iy in range(0, th, h+yofst):\n            for ix in range(0, tw, w+xofst):\n                #print(ix, iy)\n                ret[iy:iy+h, ix:ix+w] = img\n        return ret\n    \n@Func\ndef extend(img: Image, x, y) -> Image:\n    h, w = img.shape\n    ret = np.zeros((h + y, w + x), dtype=img.dtype)\n    ret[0:h, 0:w] = img\n    return ret\n\n########### copy #############\n\n@Func\ndef dup(img: T, n) -> List[T]:\n    return [img for i in range(n)]\n\n# @Func\n# def dup2d(img, n, m):\n#     return [[np.array(img) for i in range(m)] for j in range(n)]\n\n########### split #############\n\n@Func\ndef split_color(img: Image) -> List[Image]:\n    ''' Split an image into a list of single-colored images'''\n    \n    color = np.unique(img)\n    return [np.where(img == c, c, 0) for c in color if c > BACKGROUND]\n\ndef _split_conn(img, neighbor=4):\n    regions = []\n    mem = np.zeros_like(img, dtype=np.bool)\n    h, w = img.shape\n    for j in range(w):\n        for i in range(h):\n            p = img[i, j]\n            if p <= BACKGROUND or mem[i, j]:\n                continue\n            conn_idx = _expand_region_indices(img, i, j, neighbor)\n            mem[conn_idx] = True\n            regions.append(np.where(conn_idx, img, BACKGROUND))\n    return regions\n\n@Func\ndef split_conn(img: Image) -> List[Image]:\n    ''' Split an image into a list of images each containing a single connected region'''\n    \n    return _split_conn(img, 4)\n\n@Func\ndef split_conn8(img: Image) -> List[Image]:\n    ''' Split an image into a list of images each containing a single connected region.\n      Pixels of 8 neighbors are all considered \"connected\"\n    '''\n    \n    return _split_conn(img, 8)\n\nsplit = split_conn  # alias\n\n@Func\ndef split_even(img: Image, nx: int, ny: int) -> List[Image]:\n    '''Split an image evenly'''\n    \n    h, w = img.shape\n    if h % ny != 0 or w % nx != 0:\n        raise ValueError('can not split image evenly to {}x{}'.format(nx, ny))\n    dh = h // ny\n    dw = w // nx\n    res = []\n    for x in range(nx):\n        for y in range(ny):\n            #s = np.zeros_like(img)\n            #print(img)\n            #print(img[(y*dh):((y+1)*dh), (x*dw):((x+1)*dw)])\n            #s[(y*dh):((y+1)*dh), (x*dw):((x+1)*dw)] = img[(y*dh):((y+1)*dh), (x*dw):((x+1)*dw)]\n            s = img[(y*dh):((y+1)*dh), (x*dw):((x+1)*dw)]\n            res.append(s)\n    return res\n\n############ position ############\n\n########### transform ##########\n\n# @Func\ndef move_right(img: Image, ofst) -> Image:\n    h, w = img.shape\n    ret = np.zeros_like(img)\n    ret[:, ofst:w] = img[:, 0:w-ofst]\n    return ret\n\n# @Func\ndef move_left(img: Image, ofst) -> Image:\n    h, w = img.shape\n    ret = np.zeros_like(img)\n    ret[:, 0:w-ofst] = img[:, ofst:w]\n    return ret\n\n# @Func\ndef move_down(img: Image, ofst) -> Image:\n    h, w = img.shape\n    ret = np.zeros_like(img)\n    ret[ofst:h, :] = img[0:h-ofst, :]\n    return ret\n\n# @Func\ndef move_up(img: Image, ofst) -> Image:\n    h, w = img.shape\n    ret = np.zeros_like(img)\n    ret[0:h-ofst, :] = img[ofst:h, :]\n    return ret\n\n@Func\ndef move(img: Image, dx: int, dy: int) -> Image:\n    a = img\n    if dx > 0:\n        a = move_right(img, dx)\n    elif dx < 0:\n        a = move_left(img, -dx)\n    \n    if dy > 0:\n        a = move_down(a, dy)\n    elif dy < 0:\n        a = move_up(a, -dy)\n    \n    return a\n    \n@Func\ndef flipx(img: Image) -> Image:\n    return np.flip(img, 1)\n\n@Func\ndef flipy(img: Image) -> Image:\n    return np.flip(img, 0)\n\n############# high order ##############\n\n@Func\ndef fmap(imgs: List[T], func: Callable[[T], S]) -> List[S]:\n    ''' Just map. Add \"f\" at the front to avoid conflict'''\n    \n    return list(map(func, imgs))\n    \n@Func\ndef fzip(list_of_lists: List[List[T]]) -> List[List[T]]:\n    ''' Just zip. Add \"f\" at the front to avoid conflict'''\n    \n    return [list(row) for row in zip(*list_of_lists)]\n    \n@Func\ndef dfzip(list_and_value: List) -> List[List]:\n    ''' Similar to `zip` but only contains two elements. The first one is a list and \n      the second one a single value which will be duplicated into the same length\n      as the first.\n    '''\n    \n    if len(list_and_value) != 2:\n        raise NotImplementedError()\n    arr, value = list_and_value\n    l1 = [value] * len(arr)\n    return [list(row) for row in zip(arr, l1)]\n    \n@Func\ndef mfmap(imgs: List, *funcs: Callable) -> List:\n    '''Multi function map. This one is a bit trick. I think the correct signature should be\n        imgs: Tuple<T1, T2, ..., Tn>\n        funcs: Tuple<T1->S1, T2->S2, ..., Tn->Sn>\n        returns: Tuple<S1, S2, ..., Sn>\n    '''\n    \n    if not (type(imgs) == list and len(imgs) == len(funcs)):\n        raise ValueError('function lists and argument lists must be in same length')\n    return [f(i) for f, i in zip(funcs, imgs)]\n    \n# @Func\n# def dmfmap(imgs, *funcs):\n#     if not isinstance(imgs, np.ndarray)\n#         raise ValueError('argument should be a single image')\n#     return [f(imgs) for f in funcs]\n\n@Func\ndef ffilter(imgs: List[T], func: Callable[[T], bool]) -> List[T]:\n    return list(filter(func, imgs))\n    \n@Func\ndef access(imgs: List[T], index: int) -> T:\n    return imgs[index]\n\nfirst = access[0]\n\n# work with operation\n@Func\ndef apply_on(img: T, func: Callable[[List[T]], S], param: T) -> S:\n    return func([img, param])\n\n@Func\ndef apply_under(img: T, func: Callable[[List[T]], S], param: T) -> S:\n    return func([param, img])\n\n@Func\ndef lapply_on(imgs: List[T], func: Callable[[List[T]], S], param: T) -> S:\n    if type(imgs) != list:\n        raise ValueError('input must be a list of arrays')\n    return func(imgs + [param])\n\n@Func\ndef lapply_under(imgs: List[T], func: Callable[[List[T]], S], param: T) -> S:\n    if type(imgs) != list:\n        raise ValueError('input must be a list of arrays')\n    return func([param] + imgs)\n\n################## color ###################\n\n@Func\ndef set_color(img: Image, c: Color) -> Image:\n    ret = np.zeros_like(img)\n    ret[img > BACKGROUND] = color_indices.get(c, c)\n    return ret\n\n@Func\ndef has_color(img: Image, c: Color) -> bool:\n    return np.any(img == color_indices.get(c, c))\n\n################## shape #################\ndef _get_bound(img):\n    h, w = img.shape\n    x0 = w - 1\n    x1 = 0\n    y0 = h - 1\n    y1 = 0\n    for x in range(w):\n        for y in range(h):\n            if img[y, x] == BACKGROUND:\n                continue\n            x0 = min(x0, x)\n            x1 = max(x1, x)\n            y0 = min(y0, y)\n            y1 = max(y1, y)\n    return x0, x1, y0, y1\n\n@Func\ndef bound(img: Image) -> Image:\n    x0, x1, y0, y1 = _get_bound(img)\n    bound = np.zeros_like(img)\n    bound[y0:(y1+1), x0:(x1+1)] = 1\n    return bound\n\n################## operation ################\n\n@Func\ndef inot(img: Image) -> Image:\n    return np.array(np.logical_not(img), dtype=img.dtype)\n\n@Func\ndef mask(param: List[Image]) -> Image:\n    if len(param) != 2:\n        raise ValueError('parameter must be a list of two images')\n    mask, img = param\n    return np.where(mask > BACKGROUND, img, BACKGROUND)\n\n@Func\ndef mask_color(param: List[Image]) -> Image:\n    if len(param) != 2:\n        raise ValueError('parameter must be a list of two images')\n    mask, img = param\n    colors = np.unique(mask[mask > BACKGROUND])\n    if len(colors) > 1:\n        raise ValueError('mask must be single colored')\n    return np.where(img > BACKGROUND, colors[0], BACKGROUND)\n\n@Func\ndef crop(param: List[Image]) -> Image:\n    if len(param) != 2:\n        raise ValueError('parameter must be a list of two images')\n    mask, img = param\n    x0, x1, y0, y1 = _get_bound(mask)\n    return img[y0:(y1+1), x0:(x1+1)]\n    \n@Func\ndef ior(imgs: List[Image]) -> Image:\n    r = imgs[0]\n    for i in imgs[1:]:\n        r = np.where(r > BACKGROUND, r, i)\n    return r\n\n@Func\ndef iand(imgs: List[Image]) -> Image:\n    r = imgs[0]\n    for i in imgs[1:]:\n        r = np.where(r == BACKGROUND, BACKGROUND, i)\n    return r\n\n@Func\ndef ixor(imgs: List[Image]) -> Image:\n    r = np.where(imgs[0] > BACKGROUND, 1, 0)\n    for i in imgs[1:]:\n        r = r ^ np.where(i > BACKGROUND, 1, 0)\n    return r\n\n@Func\ndef binarise(img: Image) -> Image:\n    return np.array(np.where(img > BACKGROUND, 1, BACKGROUND), dtype=img.dtype)\n\n############# numerics (counting function) ###########\n\n@Func\ndef num_borders(img: Image) -> int:\n    idx = [ np.any(img[0, :] > BACKGROUND),\n            np.any(img[-1, :] > BACKGROUND),\n            np.any(img[:, 0] > BACKGROUND),\n            np.any(img[:, -1] > BACKGROUND) ]\n    val = np.ones(4, dtype=np.int)\n    return sum(val[idx])\n    \n@Func\ndef count_nonzero(img: Image) -> int:\n    return np.count_nonzero(img)\n    \n############ booleans (testing function) ##############\n@Func\n# def cnot(img: T, func: Callable[[T], bool]) -> bool:\ndef cnot(b: bool) -> bool:\n    return not b\n\n@Func\ndef cgt(a: int, b: int) -> bool:\n    return a > b\n\n@Func\ndef clt(a: int, b: int) -> bool:\n    return a < b\n\n@Func\ndef cge(a: int, b: int) -> bool:\n    return a >= b\n\n@Func\ndef cle(a: int, b: int) -> bool:\n    return a <= b\n\n@Func\ndef ceq(a: int, b: int) -> bool:\n    return a == b\n\n@Func\ndef cneq(a: int, b: int) -> bool:\n    return a != b\n\n############## combinations #############\n\nclass Lambda(object):\n    def __init__(self, create):\n        self._create = create\n        \n    def __getitem__(self, args):\n        if type(args) == tuple:\n            return self._create(*args)\n        else:\n            return self._create(args)\n    \n@Lambda\ndef divide_by_color(i):\n    return split >> ffilter[has_color[i]] >> first >> inot >> split_conn\n\n@Lambda\ndef get_color(i):\n    return split_color >> ffilter[has_color[i]] >> first\n\n@Lambda\ndef fzmap(f):\n    return fzip >> fmap[f]\n\n@Lambda\ndef dfzmap(f):\n    return dfzip >> fmap[f]\n\n@Lambda\ndef dmfmap(*funcs):\n    return dup[len(funcs)] >> mfmap[funcs]\n\n@Lambda\ndef mfzmap(*funcs):\n    return fzip >> mfmap[funcs]\n\n@Lambda\ndef dmfzmap(*funcs):\n    return dfzip >> mfmap[funcs]\n\n@Lambda\ndef sq_tile(n, ofst=0):\n    return tile[n, n, ofst, ofst]\n\n@Lambda\ndef sq_zoom_out(n, ofst=0):\n    return zoom_out[n, n, ofst, ofst]\n\ncrop_space = dmfmap[bound, ident] >> crop\n\n@Lambda\ndef bounded_op(f):\n    return dmfmap[bound, f] >> mask\n\n@Lambda\ndef is_on_border(n):\n    return num_borders >> cgt[n]\n\n@Lambda\ndef get_first(f):\n    return ffilter[f] >> first\n\n@Lambda\ndef movex(dx):\n    return move[dx, 0]\n\n@Lambda\ndef movey(dy):\n    return move[0, dy]\n\ndilate4 = dmfmap[ident, movex[-1], movex[1], movey[-1], movey[1]] >> ior\ndilate_corner = dmfmap[ident, move[-1, -1], move[-1, 1], move[1, -1], move[1, 1]] >> ior\ndilate8 = dmfmap[dilate4, dilate_corner] >> ior\n\nerode = dmfmap[ident, movex[-1], movex[1], movey[-1], movey[1]] >> iand\n\n# print(split_by_color)\n# print(split_by_color[2])\n\ndef printa(arrays):\n    if len(arrays) == 0:\n        print(arrays)\n        return\n    \n    if isinstance(arrays[0], np.ndarray):\n        for a in arrays:\n            print(a)\n    elif isinstance(arrays[0][0], np.ndarray):\n        for i, arrs in enumerate(arrays):\n            arrs_txt = [str(a).split('\\n') for a in arrs]\n            # print(arrs_txt)\n            for j, row in enumerate(zip(*arrs_txt)):\n                print('{}\\t'.format(i if j == 0 else ' ') + '\\t'.join(row))\n    else:\n        print(arrays)\n\ncodes = [\n#     split_color,\n#     split_conn,\n#     split_even[3, 1],\n#     move_right[1],\n#     move_left[1],\n#     move_up[1],\n#     move_down[1],\n#     zoom_out[3],\n#     zoom_out[4, 5, 3, 1],\n#     tile[3, 2, 1],\n#     extend[3, 3],\n]\n\n# codes = [\n# #     #move_right[1] >> move_up[1] >> move_left[1],\n# #     #move_right[1] >> move_left[1],\n# #     #dup[2] >> fmap[move_down[2]],\n# #     #dup[4] >> mfmap[move_down[0], move_down[1], move_down[2], move_down[3]] >> fmap[inot],\n# #     split >> fmap[binarise] >> fmap[inot]\n#     dmfmap[sq_tile[3], zoom_out[3]] >> mask\n# #     split >> ffilter[cnot[is_on_border]],\n# #     dup[2] >> mfmap[(split >> fmap[bound]), ident] >> fzip >> fmap[crop]\n# ]\n\nx = np.array([[1, 1, 2], [1, 3, 2], [0, 2, 2]])\n# printa(x)\nfor code in codes:\n    print('------ {} -------'.format(code))\n    printa(code(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n    \ndef plot_one(ax, input_matrix, i, train_or_test, input_or_output, title_color='black'):\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title('{} - {:d} - {}'.format(train_or_test, i, input_or_output), color=title_color)\n    \ndef plot_task(task, solve=None):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    \n    extra_line = 1 if solve is not None else 0\n    if isinstance(solve, _Func):\n        print(solve.to_str_with_anno())\n    \n    def _plot_helper(train_or_test):\n        num_imgs = len(task[train_or_test])\n        fig, axs = plt.subplots(2 + extra_line, num_imgs, figsize=(3*num_imgs,3*2))\n        for i in range(num_imgs):\n            imgs = task[train_or_test][i]\n            input_img = np.array(imgs['input'], dtype=np.int)\n            output_img = np.array(imgs.get('output', np.zeros_like(input_img)), dtype=np.int)\n            if num_imgs > 1:\n                axs_col = axs[:, i]\n            else:\n                axs_col = axs\n            plot_one(axs_col[0], input_img, i,train_or_test,'input')\n            plot_one(axs_col[1], output_img, i,train_or_test,'output')\n            if solve is not None:\n                pred = solve(input_img)\n                color = 'green' if output_img.shape == pred.shape and np.all(output_img == pred) else 'red'\n                plot_one(axs_col[2], pred, i, train_or_test, 'predication', title_color=color)\n        plt.tight_layout()\n        plt.show()\n    \n    _plot_helper('train')\n    _plot_helper('test')\n\ndef check_solution(dataset_name, index, solution=None):\n    task = get_data(dataset_name, index)\n    plot_task(task, solution)\n    \ndef debug_solution(dataset_name, index, solution, train_or_test='train', sample_index=0):\n    task = get_data(dataset_name, index)\n    matrix = task[train_or_test][sample_index]['input']\n    print('------ {} -------'.format(solution.to_str_with_anno()))\n    printa(solution(np.array(matrix)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check_solution('test', 99)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Solutions \n\nThe following are hand-crafted solutions for some tasks viable by this DSL as demostrations for its capability. "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pgm = dmfmap[zoom_out[3], tile[3]] >> mask\ncheck_solution('training', 0, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@FCreatorD\ndef pgm_tr1(inp):\n    return inot >> split >> ffilter[is_on_border[1] >> cnot] >> ior >> set_color['yellow'] >> apply_on[ior, inp]\n\n# debug_solution('training', 1, pgm)\ncheck_solution('training', 1, pgm_tr1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# solution not found yet\n# pgm = extend[0, 3]\n# debug_solution('training', 2, pgm)\n# check_solution('training', 2, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pgm = mfmap[(split >> ffilter[has_color[5]] >> first >> inot >> split_conn), ident] \\\n@FCreator\ndef pgm_tr5(inp):\n    return divide_by_color['gray'] >> fmap[apply_on[crop, inp]] \\\n        >> iand >> set_color['red'] \n# debug_solution('training', 5, pgm_tr5)\ncheck_solution('training', 5, pgm_tr5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pgm = dmfmap[\n    get_color['gray'],\n    dmfmap[divide_by_color['gray'], ident] >> dfzmap[crop] >> ffilter[has_color['azure'] >> cnot] >> first >> sq_zoom_out[3, 1]\n] >> ior\n# debug_solution('training', 10, pgm)\ncheck_solution('training', 10, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pgm = mfmap[(split >> ffilter[has_color[5]] >> first >> inot >> split_conn), ident] \\\npgm = dmfmap[divide_by_color['blue'], ident] \\\n        >> dfzmap[crop] \\\n        >> ior \\\n        >> inot \\\n        >> set_color['azure'] \n# debug_solution('training', 25, pgm)\ncheck_solution('training', 25, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pgm = crop_space\ncheck_solution('training', 30, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pattern(inp):\n    return split_conn >> get_first[num_borders >> ceq[4]] \\\n            >> dmfmap[\n                ident,\n                inot >> split_conn >> first] \\\n            >> mfmap[ident, apply_on[crop, inp]] \\\n            >> mask_color\n    \n@FCreatorD\ndef pgm_tr32(inp):\n     return get_pattern(inp) >> sq_tile[3, 1] >> apply_under[ior, inp]\n    \n# pgm = get_pattern\n# debug_solution('training', 32, pgm)\ncheck_solution('training', 32, pgm_tr32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pgm = crop_space >> split_even[2, 2] >> access[0]\n# debug_solution('training', 38, pgm)\ncheck_solution('training', 38, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pgm = move[0, 1]\n# debug_solution('training', 52, pgm)\ncheck_solution('training', 52, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@FCreatorD\ndef pgm_tr54(inp):\n    return divide_by_color['azure'] >> mfmap[\n            set_color['black'],\n            set_color['yellow'],\n            set_color['black'],\n            set_color['red'],\n            set_color['purple'],\n            set_color['blue'],\n            set_color['black'],\n            set_color['green'],\n            set_color['black'],\n        ] \\\n        >> lapply_on[ior, inp]\n\n# debug_solution('training', 54, pgm_tr54)\ncheck_solution('training', 54, pgm_tr54)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pgm = crop_space >> tile[2, 1]\n# debug_solution('training', 56, pgm)\ncheck_solution('training', 56, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pgm = split_even[3, 1] >> access[0]\n# debug_solution('training', 66, pgm)\ncheck_solution('training', 66, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@FCreatorD\ndef pgm_tr69(inp):\n    return split_color >> get_first[has_color['azure']] \\\n        >> bounded_op[inot >> set_color['green']] \\\n        >> apply_on[ior, inp]\n# debug_solution('training', 69, pgm_tr69)\ncheck_solution('training', 69, pgm_tr69)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@FCreatorD\ndef pgm_tr71(inp):\n    return divide_by_color['yellow'] >> fmap[apply_on[crop, inp]] >> ixor >> set_color['green']\n# debug_solution('training', 71, pgm_tr71)\ncheck_solution('training', 71, pgm_tr71)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fill = split_conn >> fmap[bounded_op[inot >> set_color['blue']]] >> ior\npgm = dmfmap[fill, ident] >> ior\n# debug_solution('training', 80, pgm)\ncheck_solution('training', 80, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@FCreatorD\ndef pgm_tr94(inp):\n    return set_color['blue'] >> dilate8 >> apply_under[ior, inp]\n# debug_solution('training', 94, pgm_tr94)\ncheck_solution('training', 94, pgm_tr94)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pgm = split_conn8 >> ffilter[count_nonzero >> cgt[1]] >> ior\n# debug_solution('training', 96, pgm)\ncheck_solution('training', 96, pgm)\n# is there something wrong with the first sample? I think the two dots at top left corner \n# should be included in the output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@FCreatorD\ndef pgm_tr97(inp):\n    return erode >> inot >> apply_on[mask, inp]\n\n# debug_solution('training', 97, pgm_tr97)\ncheck_solution('training', 97, pgm_tr97)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pgm = split_color >> dmfmap[ident, fmap[bound]] >> fzmap[mask_color] >> ior\n# debug_solution('training', 131, pgm)\ncheck_solution('training', 131, pgm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@FCreatorD\ndef pgm_tr146(inp):\n    return split_conn >> ffilter[count_nonzero >> cgt[1]] >> ior >> set_color['azure'] >> apply_on[ior, inp]\n\n# debug_solution('training', 146, pgm_tr146)\ncheck_solution('training', 146, pgm_tr146)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@FCreatorD\ndef pgm_tr165(inp):\n    return bounded_op[inot] >> set_color['red'] >> apply_under[ior, inp]\n# debug_solution('training', 165, pgm_tr165)\ncheck_solution('training', 165, pgm_tr165)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}