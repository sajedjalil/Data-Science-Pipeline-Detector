{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Abstraction and Reasoning Starter Notebook\n\nThis notebook will get you started on on the basics of this competition"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# input_path = \"../input/abstraction-and-reasoning-challenge/\"\ninput_path = \"/kaggle/input/abstraction-and-reasoning-challenge\"\n\nfor dirname, _, filenames in os.walk(input_path):\n    print(dirname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I like to use the `Path` class for my paths."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from pathlib import Path\n\ndata_path = Path(input_path)\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntest_path = data_path / 'test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `training` folder has 400 JSON tasks. The names of the first three are shown below."},{"metadata":{"trusted":true},"cell_type":"code","source":"training_tasks = sorted(os.listdir(training_path))\nprint(training_tasks[:3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In each task, there are two dictionary keys, `train` and `test`. You learn the pattern from the train input-output pairs, and then apply the pattern to the `test` input, to predict an output."},{"metadata":{"trusted":true},"cell_type":"code","source":"task_file = str(training_path / '00d62c1b.json')\n\nwith open(task_file, 'r') as f:\n    task = json.load(f)\n\nprint(task.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tasks have multiple `train` input-output pairs. Most tasks have a single `test` input-output pair, although some have more than one."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train_pairs = len(task['train'])\nn_test_pairs = len(task['test'])\n\nprint(f'task contains {n_train_pairs} training pairs')\nprint(f'task contains {n_test_pairs} test pairs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function to plot the first train/test input/output pairs of a task\n\nYou can use this function to plot the first `train` and `test` grids. The color aligns with what is found on the ARC app. Note though, the ARC app presents the grids to scale, where these display the grids in the same size, regardless of their dimension."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 4, figsize=(15,15))\n    axs[0].imshow(task['train'][0]['input'], cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Train Input')\n    axs[1].imshow(task['train'][0]['output'], cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Train Output')\n    axs[2].imshow(task['test'][0]['input'], cmap=cmap, norm=norm)\n    axs[2].axis('off')\n    axs[2].set_title('Test Input')\n    axs[3].imshow(task['test'][0]['output'], cmap=cmap, norm=norm)\n    axs[3].axis('off')\n    axs[3].set_title('Test Output')\n    plt.tight_layout()\n    plt.show()\n    \ndef plot_task_sub(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n    axs[0].imshow(task['train'][0]['input'], cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Train Input')\n    axs[1].imshow(task['train'][0]['output'], cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Train Output')\n    axs[2].imshow(task['test'][0]['input'], cmap=cmap, norm=norm)\n    axs[2].axis('off')\n    axs[2].set_title('Test Input')\n    plt.tight_layout()\n    plt.show()\n    \ndef plot_task_item(task, idx):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n    axs[0].imshow(task['train'][idx]['input'], cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Train Input')\n    axs[1].imshow(task['train'][idx]['output'], cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Train Output')\n    axs[2].imshow(task['test'][0]['input'], cmap=cmap, norm=norm)\n    axs[2].axis('off')\n    axs[2].set_title('Test Input')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_task(task)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using the correct prediction format"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `output_id` is the `id` of the task, followed by the index of the `test` input that you should use to make your prediction. The `output` is the predicted output of the corresponding `test` input, reformatted into a string representation. (You can make three predictions per `output_id`, delineated by a space.) Use the following function to convert from a 2d python list to the string representation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_grid = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndisplay(example_grid)\nprint(flattener(example_grid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Re-creating the sample submission output\n\nThis demonstrates how to loop over the sample submission and make predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_json_file(fileName):\n    with open(fileName, 'r') as f:\n        return json.load(f) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def task_train001(df_input):\n    \n    df_input = np.array(df_input)\n    df_output = np.array(df_output)\n\n    color_input, color_output = input_all_colors[0], new_colors[0]\n\n    def get_closed_area(arr):\n        # depth first search\n        H, W = arr.shape\n        Dy = [0, -1, 0, 1]\n        Dx = [1, 0, -1, 0]\n        arr_padded = np.pad(arr, ((1, 1), (1, 1)), \"constant\", constant_values=0)\n        searched = np.zeros(arr_padded.shape, dtype=bool)\n        searched[0, 0] = True\n        q = [(0, 0)]\n        while q:\n            y, x = q.pop()\n            for dy, dx in zip(Dy, Dx):\n                y_, x_ = y + dy, x + dx\n                if not 0 <= y_ < H + 2 or not 0 <= x_ < W + 2:\n                    continue\n                if not searched[y_][x_] and arr_padded[y_][x_] == 0:\n                    q.append((y_, x_))\n                    searched[y_, x_] = True\n        res = searched[1:-1, 1:-1]\n        res |= arr == color_input\n        return ~res\n\n    output = df_input.copy()\n    output[get_closed_area(df_input)] = color_output\n    \n    return output\n\ndef wrapper_task_train001(df_train, df_test_item):\n\n    # 新增一种颜色\n    for df in df_train:\n        input_all_colors = [x for x in list(np.unique(df['input'])) if x != 0]\n        output_all_colors = [x for x in list(np.unique(df['output'])) if x != 0]\n        new_colors = [x for x in output_all_colors if x not in input_all_colors]\n        assert (len(new_colors) == 1)\n    #         print(input_all_colors, output_all_colors)\n\n    # 判断是否要删除边框\n    remove_border = False\n    if len(output_all_colors) - len(input_all_colors) == 0:\n        remove_border = True\n\n    def task_train001(x):\n        x = np.array(x)\n        green, yellow = input_all_colors[0], new_colors[0]\n\n        def get_closed_area(arr):\n            # depth first search\n            H, W = arr.shape\n            Dy = [0, -1, 0, 1]\n            Dx = [1, 0, -1, 0]\n            arr_padded = np.pad(arr, ((1, 1), (1, 1)), \"constant\", constant_values=0)\n            searched = np.zeros(arr_padded.shape, dtype=bool)\n            searched[0, 0] = True\n            q = [(0, 0)]\n            while q:\n                y, x = q.pop()\n                for dy, dx in zip(Dy, Dx):\n                    y_, x_ = y + dy, x + dx\n                    if not 0 <= y_ < H + 2 or not 0 <= x_ < W + 2:\n                        continue\n                    if not searched[y_][x_] and arr_padded[y_][x_] == 0:\n                        q.append((y_, x_))\n                        searched[y_, x_] = True\n            res = searched[1:-1, 1:-1]\n            res |= arr == green\n            return ~res\n\n        y = x.copy()\n        y[get_closed_area(x)] = yellow\n\n        if remove_border:\n            y[y == input_all_colors[0]] = 0\n\n        return y\n\n    for df in df_train:\n        assert (np.array_equal(task_train001(df['input']), df['output']) == True)\n    print(np.array_equal(task_train001(df_test_item['input']), df_test_item['output']))\n\n    return task_train001(df_test_item['input'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm, tqdm_notebook \n\nfor output_id in tqdm_notebook(['00d62c1b_0', 'd5d6de2d_0', 'a5313dff_0'], total = 3):\n\n#     print(output_id)\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    \n    fileName = str(training_path / str(task_id + '.json'))\n\n    task = read_json_file(fileName)\n    plot_task_sub(task)\n\n    try:\n        res = wrapper_task_train001(task['train'], task['test'][pair_id])\n        pred_1 = flattener(res.tolist())\n        print(\"wrapper_task_train001 success\", pred_1)\n    except:\n        data = task['test'][pair_id]['input']\n        pred_1 = flattener(data)\n\n    # concatenate and add to the submission output\n    pred = pred_1\n    \n    submission.loc[output_id, 'output'] = pred\n\nsubmission.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\nused_k = len(submission)\n\nfor output_id in tqdm_notebook(submission.index[:used_k], total = len(submission.index[:used_k])):\n# for output_id in tqdm_notebook(['00d62c1b_0', 'd5d6de2d_0', 'a5313dff_0'], total = 3):\n\n#     print(output_id)\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    \n    fileName = str(test_path / str(task_id + '.json'))\n#     fileName = str(training_path / str(task_id + '.json'))\n\n    task = read_json_file(fileName)\n#     plot_task_sub(task)\n\n    try:\n        res = wrapper_task_train001(task['train'], task['test'][pair_id])\n        pred_1 = flattener(res.tolist())\n        print(\"wrapper_task_train001 success\", pred_1)\n    except:\n        data = task['test'][pair_id]['input']\n        pred_1 = flattener(data)\n\n    # concatenate and add to the submission output\n    pred = pred_1\n    \n    submission.loc[output_id, 'output'] = pred\n\nsubmission.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}