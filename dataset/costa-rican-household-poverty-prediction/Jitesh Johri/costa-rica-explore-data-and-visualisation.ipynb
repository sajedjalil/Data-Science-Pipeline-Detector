{"cells":[{"metadata":{},"cell_type":"markdown","source":"Objective\n\n\nThe objective is to predict poverty on a household level. We are given data on the individual level with each individual having unique features but also information about their household. In order to create a dataset for the task, we'll have to perform some aggregations of the individual data for each household. Moreover, we have to make a prediction for every individual in the test set, but \"ONLY the heads of household are used in scoring\" which means we want to predict poverty on a household basis.\n\nImportant note: while all members of a household should have the same label in the training data, there are errors where individuals in the same household have different labels. In these cases, we are told to use the label for the head of each household, which can be identified by the rows where parentesco1 == 1.0. We will cover how to correct this in the notebook (for more info take a look at the competition main discussion).\n\nThe Target values represent poverty levels as follows:\n\n1 = extreme poverty \n2 = moderate poverty \n3 = vulnerable households \n4 = non vulnerable households\n\nThe explanations for all 143 columns can be found in the competition documentation, but a few to note are below:\n\nId: a unique identifier for each individual, this should not be a feature that we use!\nidhogar: a unique identifier for each household. This variable is not a feature, but will be used to group individuals by household as all individuals in a household will have the same identifier.\nparentesco1: indicates if this person is the head of the household.\nTarget: the label, which should be equal for all members in a household\nWhen we make a model, we'll train on a household basis with the label for each household the poverty level of the head of household. The raw data contains a mix of both household and individual characteristics and for the individual data, we will have to find a way to aggregate this for each household. Some of the individuals belong to a household with no head of household which means that unfortunately we can't use this data for training. These issues with the data are completely typical of real-world data and hence this problem is great preparation for the datasets you'll encounter in a data science job!\n"},{"metadata":{},"cell_type":"markdown","source":"Imports\n\nWe'll use a familiar stack of data science libraries: Pandas, numpy, matplotlib, seaborn, and eventually sklearn for modeling."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set a few plotting defaults\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 18\nplt.rcParams['patch.edgecolor'] = 'k'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read in Data and Look at Summary Information"},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.options.display.max_columns = 150\n\n# Read in data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That gives us a look at all of the columns which don't appear to be in any order. To get a quick overview of the data we use df.info()."},{"metadata":{"trusted":false},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This tells us there are 130 integer columns, 8 float (numeric) columns, and 5 object columns. The integer columns probably represent Boolean variables (that take on either 0 or 1) or ordinal variables with discrete ordered values. The object columns might pose an issue because they cannot be fed directly into a machine learning model.\n\nLet's glance at the test data which has many more rows (individuals) than the train. It does have one fewer column because there's no Target!"},{"metadata":{"trusted":false},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Integer Columns\nLet's look at the distribution of unique values in the integer columns. For each column, we'll count the number of unique values and show the result in a bar plot."},{"metadata":{"trusted":false},"cell_type":"code","source":"train.select_dtypes(np.int64).nunique().value_counts().sort_index().plot.bar(color = 'blue', \n                                                                             figsize = (8, 6),\n                                                                            edgecolor = 'k', linewidth = 2);\nplt.xlabel('Number of Unique Values'); plt.ylabel('Count');\nplt.title('Count of Unique Values in Integer Columns');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The columns with only 2 unique values represent Booleans (0 or 1). In a lot of cases, this boolean information is already on a household level. "},{"metadata":{},"cell_type":"markdown","source":"The following graphs shows the distributions of the float columns colored by the value of the Target. With these plots, we can see if there is a significant difference in the variable distribution depending on the household poverty level."},{"metadata":{"trusted":false},"cell_type":"code","source":"from collections import OrderedDict\n\nplt.figure(figsize = (20, 16))\nplt.style.use('fivethirtyeight')\n\n# Color mapping\ncolors = OrderedDict({1: 'red', 2: 'orange', 3: 'blue', 4: 'green'})\npoverty_mapping = OrderedDict({1: 'extreme', 2: 'moderate', 3: 'vulnerable', 4: 'non vulnerable'})\n\n# Iterate through the float columns\nfor i, col in enumerate(train.select_dtypes('float')):\n    ax = plt.subplot(4, 2, i + 1)\n    # Iterate through the poverty levels\n    for poverty_level, color in colors.items():\n        # Plot each poverty level as a separate line\n        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(), \n                    ax = ax, color = color, label = poverty_mapping[poverty_level])\n        \n    plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}'); plt.ylabel('Density')\n\nplt.subplots_adjust(top = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Object Columns\nThe last column type is object which we can view as follows."},{"metadata":{"trusted":false},"cell_type":"code","source":"train.select_dtypes('object').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Id and idhogar object types make sense because these are identifying variables. However, the other columns seem to be a mix of strings and numbers which we'll need to address before doing any machine learning.\nFor these three variables, \"yes\" = 1 and \"no\" = 0. We can correct the variables using a mapping and convert to floats."},{"metadata":{"trusted":false},"cell_type":"code","source":"mapping = {\"yes\": 1, \"no\": 0}\n\n# Apply same operation to both train and test\nfor df in [train, test]:\n    # Fill in the values with the correct mapping\n    df['dependency'] = df['dependency'].replace(mapping).astype(np.float64)\n    df['edjefa'] = df['edjefa'].replace(mapping).astype(np.float64)\n    df['edjefe'] = df['edjefe'].replace(mapping).astype(np.float64)\n\ntrain[['dependency', 'edjefa', 'edjefe']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (16, 12))\n\n# Iterate through the float columns\nfor i, col in enumerate(['dependency', 'edjefa', 'edjefe']):\n    ax = plt.subplot(3, 1, i + 1)\n    # Iterate through the poverty levels\n    for poverty_level, color in colors.items():\n        # Plot each poverty level as a separate line\n        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(), \n                    ax = ax, color = color, label = poverty_mapping[poverty_level])\n        \n    plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}'); plt.ylabel('Density')\n\nplt.subplots_adjust(top = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These variables are now correctly represented as numbers and can be fed into a machine learning model.\n\nTo make operations like that above a little easier, we'll join together the training and testing dataframes."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Add null Target column to test\ntest['Target'] = np.nan\ndata = train.append(test, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring Label Distribution\nNext, we can get an idea of how imbalanced the problem is by looking at the distribution of labels. \nThe bar plot below shows the distribution of training labels (since there are no testing labels).\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Heads of household\nheads = data.loc[data['parentesco1'] == 1].copy()\n\n# Labels for training\ntrain_labels = data.loc[(data['Target'].notnull()) & (data['parentesco1'] == 1), ['Target', 'idhogar']]\n\n# Value counts of target\nlabel_counts = train_labels['Target'].value_counts().sort_index()\n\n# Bar plot of occurrences of each label\nlabel_counts.plot.bar(figsize = (8, 6), \n                      color = colors.values(),\n                      edgecolor = 'k', linewidth = 2)\n\n# Formatting\nplt.xlabel('Poverty Level'); plt.ylabel('Count'); \nplt.xticks([x - 1 for x in poverty_mapping.keys()], \n           list(poverty_mapping.values()), rotation = 60)\nplt.title('Poverty Level Breakdown');\n\nlabel_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Groupby the household and figure out the number of unique values\nall_equal = train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\n\n# Households where targets are not all equal\nnot_equal = all_equal[all_equal != True]\nprint('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"households_leader = train.groupby('idhogar')['parentesco1'].sum()\n\n# Find households without a head\nhouseholds_no_head = train.loc[train['idhogar'].isin(households_leader[households_leader == 0].index), :]\n\nprint('There are {} households without a head.'.format(households_no_head['idhogar'].nunique()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Find households without a head and where labels are different\nhouseholds_no_head_equal = households_no_head.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\nprint('{} Households with no head have different labels.'.format(sum(households_no_head_equal == False)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we can look at the percentage of missing values in each column."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Number of missing in each column\nmissing = pd.DataFrame(data.isnull().sum()).rename(columns = {0: 'total'})\n\n# Create a percentage missing\nmissing['percent'] = missing['total'] / len(data)\n\nmissing.sort_values('percent', ascending = False).head(10).drop('Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"v18q1: Number of tablets\n\nLet's start with v18q1 which indicates the number of tablets owned by a family."},{"metadata":{"trusted":false},"cell_type":"code","source":"#Function to Plot Value Counts\n\ndef plot_value_counts(df, col, heads_only = False):\n    \"\"\"Plot value counts of a column, optionally with only the heads of a household\"\"\"\n    # Select heads of household\n    if heads_only:\n        df = df.loc[df['parentesco1'] == 1].copy()\n        \n    plt.figure(figsize = (8, 6))\n    df[col].value_counts().sort_index().plot.bar(color = 'blue',\n                                                 edgecolor = 'k',\n                                                 linewidth = 2)\n    plt.xlabel(f'{col}'); plt.title(f'{col} Value Counts'); plt.ylabel('Count')\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_value_counts(heads, 'v18q1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"heads.groupby('v18q')['v18q1'].apply(lambda x: x.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['v18q1'] = data['v18q1'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Variables indicating home ownership\nown_variables = [x for x in data if x.startswith('tipo')]\n\n\n# Plot of the home ownership variables for home missing rent payments\ndata.loc[data['v2a1'].isnull(), own_variables].sum().plot.bar(figsize = (10, 8),\n                                                                        color = 'green',\n                                                              edgecolor = 'k', linewidth = 2);\nplt.xticks([0, 1, 2, 3, 4],\n           ['Owns and Paid Off', 'Owns and Paying', 'Rented', 'Precarious', 'Other'],\n          rotation = 60)\nplt.title('Home Ownership Status for Households Missing Rent Payments', size = 18);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Fill in households that own the house with 0 rent payment\ndata.loc[(data['tipovivi1'] == 1), 'v2a1'] = 0\n\n# Create missing rent payment column\ndata['v2a1-missing'] = data['v2a1'].isnull()\n\ndata['v2a1-missing'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Let's test this out by finding the ages of those who have a missing value in this column and the ages of those who do not have a missing value.\n\ndata.loc[data['rez_esc'].notnull()]['age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Checking the age for which there is any missing values\n\ndata.loc[data['rez_esc'].isnull()]['age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# If individual is over 19 or younger than 7 and missing years behind, set it to 0\ndata.loc[((data['age'] > 19) | (data['age'] < 7)) & (data['rez_esc'].isnull()), 'rez_esc'] = 0\n\n# Add a flag for those between 7 and 19 with a missing value\ndata['rez_esc-missing'] = data['rez_esc'].isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Setting the value = 5 where values is > 5\n\ndata.loc[data['rez_esc'] > 5, 'rez_esc'] = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot_categoricals(x, y, data, annotate = True):\n    \"\"\"Plot counts of two categoricals.\n    Size is raw count for each grouping.\n    Percentages are for a given value of y.\"\"\"\n    \n    # Raw counts \n    raw_counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = False))\n    raw_counts = raw_counts.rename(columns = {x: 'raw_count'})\n    \n    # Calculate counts for each group of x and y\n    counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = True))\n    \n    # Rename the column and reset the index\n    counts = counts.rename(columns = {x: 'normalized_count'}).reset_index()\n    counts['percent'] = 100 * counts['normalized_count']\n    \n    # Add the raw count\n    counts['raw_count'] = list(raw_counts['raw_count'])\n    \n    plt.figure(figsize = (14, 10))\n    # Scatter plot sized by percent\n    plt.scatter(counts[x], counts[y], edgecolor = 'k', color = 'lightgreen',\n                s = 100 * np.sqrt(counts['raw_count']), marker = 'o',\n                alpha = 0.6, linewidth = 1.5)\n    \n    if annotate:\n        # Annotate the plot with text\n        for i, row in counts.iterrows():\n            # Put text with appropriate offsets\n            plt.annotate(xy = (row[x] - (1 / counts[x].nunique()), \n                               row[y] - (0.15 / counts[y].nunique())),\n                         color = 'navy',\n                         s = f\"{round(row['percent'], 1)}%\")\n        \n    # Set tick marks\n    plt.yticks(counts[y].unique())\n    plt.xticks(counts[x].unique())\n    \n    # Transform min and max to evenly space in square root domain\n    sqr_min = int(np.sqrt(raw_counts['raw_count'].min()))\n    sqr_max = int(np.sqrt(raw_counts['raw_count'].max()))\n    \n    # 5 sizes for legend\n    msizes = list(range(sqr_min, sqr_max,\n                        int(( sqr_max - sqr_min) / 5)))\n    markers = []\n    \n    # Markers for legend\n    for size in msizes:\n        markers.append(plt.scatter([], [], s = 100 * size, \n                                   label = f'{int(round(np.square(size) / 100) * 100)}', \n                                   color = 'lightgreen',\n                                   alpha = 0.6, edgecolor = 'k', linewidth = 1.5))\n        \n    # Legend and formatting\n    plt.legend(handles = markers, title = 'Counts',\n               labelspacing = 3, handletextpad = 2,\n               fontsize = 16,\n               loc = (1.10, 0.19))\n    \n    plt.annotate(f'* Size represents raw count while % is for a given y value.',\n                 xy = (0, 1), xycoords = 'figure points', size = 10)\n    \n    # Adjust axes limits\n    plt.xlim((counts[x].min() - (6 / counts[x].nunique()), \n              counts[x].max() + (6 / counts[x].nunique())))\n    plt.ylim((counts[y].min() - (4 / counts[y].nunique()), \n              counts[y].max() + (4 / counts[y].nunique())))\n    plt.grid(None)\n    plt.xlabel(f\"{x}\"); plt.ylabel(f\"{y}\"); plt.title(f\"{y} vs {x}\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_categoricals('rez_esc', 'Target', data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_categoricals('escolari', 'Target', data, annotate = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_value_counts(data[(data['rez_esc-missing'] == 1)], \n                  'Target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_value_counts(data[(data['v2a1-missing'] == 1)], \n                  'Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features Plot\nFor the final exploration of the household level data, we can make a plot of some of the most correlated variables with the Target. This shows scatterplots on the upper triangle, kernel density estimate (kde) plots on the diagonal, and 2D KDE plots on the lower triangle.\n\nDefine Variable Categories\n\nThere are several different categories of variables:\n\n\nIndividual Variables: these are characteristics of each individual rather than the household\n\nBoolean: Yes or No (0 or 1)\n\nOrdered Discrete: Integers with an ordering\n\nHousehold variables\n\nBoolean: Yes or No\n\nOrdered Discrete: Integers with an ordering\n\nContinuous numeric\n\nSquared Variables: derived from squaring variables in the data\n\nId variables: identifies the data and should not be used as features\n\nBelow we manually define the variables in each category."},{"metadata":{"trusted":false},"cell_type":"code","source":"id_ = ['Id', 'idhogar', 'Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ind_bool = ['v18q', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', \n            'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n            'parentesco1', 'parentesco2',  'parentesco3', 'parentesco4', 'parentesco5', \n            'parentesco6', 'parentesco7', 'parentesco8',  'parentesco9', 'parentesco10', \n            'parentesco11', 'parentesco12', 'instlevel1', 'instlevel2', 'instlevel3', \n            'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', \n            'instlevel9', 'mobilephone', 'rez_esc-missing']\n\nind_ordered = ['rez_esc', 'escolari', 'age']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"hh_bool = ['hacdor', 'hacapo', 'v14a', 'refrig', 'paredblolad', 'paredzocalo', \n           'paredpreb','pisocemento', 'pareddes', 'paredmad',\n           'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisoother', \n           'pisonatur', 'pisonotiene', 'pisomadera',\n           'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', \n           'abastaguadentro', 'abastaguafuera', 'abastaguano',\n            'public', 'planpri', 'noelec', 'coopele', 'sanitario1', \n           'sanitario2', 'sanitario3', 'sanitario5',   'sanitario6',\n           'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', \n           'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', \n           'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3',\n           'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', \n           'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', \n           'computer', 'television', 'lugar1', 'lugar2', 'lugar3',\n           'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'v2a1-missing']\n\nhh_ordered = [ 'rooms', 'r4h1', 'r4h2', 'r4h3', 'r4m1','r4m2','r4m3', 'r4t1',  'r4t2', \n              'r4t3', 'v18q1', 'tamhog','tamviv','hhsize','hogar_nin',\n              'hogar_adul','hogar_mayor','hogar_total',  'bedrooms', 'qmobilephone']\n\nhh_cont = ['v2a1', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'overcrowding']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sqr_ = ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', \n        'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Checking for duplication\n\nx = ind_bool + ind_ordered + id_ + hh_bool + hh_ordered + hh_cont + sqr_\n\nfrom collections import Counter\n\nprint('There are no repeats: ', np.all(np.array(list(Counter(x).values())) == 1))\nprint('We covered every variable: ', len(x) == data.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.lmplot('age', 'SQBage', data = data, fit_reg=False);\nplt.title('Squared Age versus Age');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remove squared variables as the variables are highly correlated\ndata = data.drop(columns = sqr_)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"heads = data.loc[data['parentesco1'] == 1, :]\nheads = heads[id_ + hh_bool + hh_cont + hh_ordered]\nheads.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create correlation matrix\ncorr_matrix = heads.corr()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n\nto_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corr_matrix.loc[corr_matrix['tamhog'].abs() > 0.9, corr_matrix['tamhog'].abs() > 0.9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.heatmap(corr_matrix.loc[corr_matrix['tamhog'].abs() > 0.9, corr_matrix['tamhog'].abs() > 0.9],\n            annot=True, cmap = plt.cm.autumn_r, fmt='.3f');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"heads = heads.drop(columns = ['tamhog', 'hogar_total', 'r4t3'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.lmplot('tamviv', 'hhsize', data, fit_reg=False, size = 8);\nplt.title('Household size vs number of persons living in the household');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"heads['hhsize-diff'] = heads['tamviv'] - heads['hhsize']\nplot_categoricals('hhsize-diff', 'Target', heads)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corr_matrix.loc[corr_matrix['coopele'].abs() > 0.9, corr_matrix['coopele'].abs() > 0.9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"elec = []\n\n# Assign values\nfor i, row in heads.iterrows():\n    if row['noelec'] == 1:\n        elec.append(0)\n    elif row['coopele'] == 1:\n        elec.append(1)\n    elif row['public'] == 1:\n        elec.append(2)\n    elif row['planpri'] == 1:\n        elec.append(3)\n    else:\n        elec.append(np.nan)\n        \n# Record the new variable and missing flag\nheads['elec'] = elec\nheads['elec-missing'] = heads['elec'].isnull()\n\n# Remove the electricity columns\n# heads = heads.drop(columns = ['noelec', 'coopele', 'public', 'planpri'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_categoricals('elec', 'Target', heads)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"heads = heads.drop(columns = 'area2')\n\nheads.groupby('area1')['Target'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Wall ordinal variable\nheads['walls'] = np.argmax(np.array(heads[['epared1', 'epared2', 'epared3']]),\n                           axis = 1)\n\n# heads = heads.drop(columns = ['epared1', 'epared2', 'epared3'])\nplot_categoricals('walls', 'Target', heads)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Roof ordinal variable\nheads['roof'] = np.argmax(np.array(heads[['etecho1', 'etecho2', 'etecho3']]),\n                           axis = 1)\nheads = heads.drop(columns = ['etecho1', 'etecho2', 'etecho3'])\n\n# Floor ordinal variable\nheads['floor'] = np.argmax(np.array(heads[['eviv1', 'eviv2', 'eviv3']]),\n                           axis = 1)\n# heads = heads.drop(columns = ['eviv1', 'eviv2', 'eviv3'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create new feature\nheads['walls+roof+floor'] = heads['walls'] + heads['roof'] + heads['floor']\n\nplot_categoricals('walls+roof+floor', 'Target', heads, annotate=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"counts = pd.DataFrame(heads.groupby(['walls+roof+floor'])['Target'].value_counts(normalize = True)).rename(columns = {'Target': 'Normalized Count'}).reset_index()\ncounts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# No toilet, no electricity, no floor, no water service, no ceiling\nheads['warning'] = 1 * (heads['sanitario1'] + \n                         (heads['elec'] == 0) + \n                         heads['pisonotiene'] + \n                         heads['abastaguano'] + \n                         (heads['cielorazo'] == 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nsns.violinplot(x = 'warning', y = 'Target', data = heads);\nplt.title('Target vs Warning Variable');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Owns a refrigerator, computer, tablet, and television\nheads['bonus'] = 1 * (heads['refrig'] + \n                      heads['computer'] + \n                      (heads['v18q1'] > 0) + \n                      heads['television'])\n\nsns.violinplot('bonus', 'Target', data = heads,\n                figsize = (10, 6));\nplt.title('Target vs Bonus Variable');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Per Capita Features\nAdditional features we can make calculate the number of certain measurements for each person in the household."},{"metadata":{"trusted":false},"cell_type":"code","source":"\n\nheads['phones-per-capita'] = heads['qmobilephone'] / heads['tamviv']\nheads['tablets-per-capita'] = heads['v18q1'] / heads['tamviv']\nheads['rooms-per-capita'] = heads['rooms'] / heads['tamviv']\nheads['rent-per-capita'] = heads['v2a1'] / heads['tamviv']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from scipy.stats import spearmanr","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot_corrs(x, y):\n    \"\"\"Plot data and show the spearman and pearson correlation.\"\"\"\n    \n    # Calculate correlations\n    spr = spearmanr(x, y).correlation\n    pcr = np.corrcoef(x, y)[0, 1]\n    \n    # Scatter plot\n    data = pd.DataFrame({'x': x, 'y': y})\n    plt.figure( figsize = (6, 4))\n    sns.regplot('x', 'y', data = data, fit_reg = False);\n    plt.title(f'Spearman: {round(spr, 2)}; Pearson: {round(pcr, 2)}');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x = np.array(range(100))\ny = x ** 2\n\nplot_corrs(x, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Spearman correlation is often considered to be better for ordinal variables such as the Target or the years of education. Most relationshisp in the real world aren't linear, and although the Pearson correlation can be an approximation of how related two variables are, it's inexact and not the best method of comparison."},{"metadata":{"trusted":false},"cell_type":"code","source":"x = np.array([1, 1, 1, 2, 3, 3, 4, 4, 4, 5, 5, 6, 7, 8, 8, 9, 9, 9])\ny = np.array([1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 3, 3, 2, 4, 2, 2, 4])\n\nplot_corrs(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x = np.array(range(-19, 20))\ny = 2 * np.sin(x)\n\nplot_corrs(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Use only training data\ntrain_heads = heads.loc[heads['Target'].notnull(), :].copy()\n\npcorrs = pd.DataFrame(train_heads.corr()['Target'].sort_values()).rename(columns = {'Target': 'pcorr'}).reset_index()\npcorrs = pcorrs.rename(columns = {'index': 'feature'})\n\nprint('Most negatively correlated variables:')\nprint(pcorrs.head())\n\nprint('\\nMost positively correlated variables:')\nprint(pcorrs.dropna().tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore', category = RuntimeWarning)\n\nfeats = []\nscorr = []\npvalues = []\n\n# Iterate through each column\nfor c in heads:\n    # Only valid for numbers\n    if heads[c].dtype != 'object':\n        feats.append(c)\n        \n        # Calculate spearman correlation\n        scorr.append(spearmanr(train_heads[c], train_heads['Target']).correlation)\n        pvalues.append(spearmanr(train_heads[c], train_heads['Target']).pvalue)\n\nscorrs = pd.DataFrame({'feature': feats, 'scorr': scorr, 'pvalue': pvalues}).sort_values('scorr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('Most negative Spearman correlations:')\nprint(scorrs.head())\nprint('\\nMost positive Spearman correlations:')\nprint(scorrs.dropna().tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corrs = pcorrs.merge(scorrs, on = 'feature')\ncorrs['diff'] = corrs['pcorr'] - corrs['scorr']\n\ncorrs.sort_values('diff').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corrs.sort_values('diff').dropna().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.lmplot('dependency', 'Target', fit_reg = True, data = train_heads, x_jitter=0.05, y_jitter=0.05);\nplt.title('Target vs Dependency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"variables = ['Target', 'dependency', 'warning', 'walls+roof+floor', 'meaneduc',\n             'floor', 'r4m1', 'overcrowding']\n\n# Calculate the correlations\ncorr_mat = train_heads[variables].corr().round(2)\n\n# Draw a correlation heatmap\nplt.rcParams['font.size'] = 18\nplt.figure(figsize = (12, 12))\nsns.heatmap(corr_mat, vmin = -0.5, vmax = 0.8, center = 0, \n            cmap = plt.cm.RdYlGn_r, annot = True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features Plot\n\nFor the final exploration of the household level data, we can make a plot of some of the most correlated variables with the Target. This shows scatterplots on the upper triangle, kernel density estimate (kde) plots on the diagonal, and 2D KDE plots on the lower triangle."},{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# Copy the data for plotting\nplot_data = train_heads[['Target', 'dependency', 'walls+roof+floor',\n                         'meaneduc', 'overcrowding']]\n\n# Create the pairgrid object\ngrid = sns.PairGrid(data = plot_data, size = 4, diag_sharey=False,\n                    hue = 'Target', hue_order = [4, 3, 2, 1], \n                    vars = [x for x in list(plot_data.columns) if x != 'Target'])\n\n# Upper is a scatter plot\ngrid.map_upper(plt.scatter, alpha = 0.8, s = 20)\n\n# Diagonal is a histogram\ngrid.map_diag(sns.kdeplot)\n\n# Bottom is density plot\ngrid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);\ngrid = grid.add_legend()\nplt.suptitle('Feature Plots Colored By Target', size = 32, y = 1.05);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"household_feats = list(heads.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ind = data[id_ + ind_bool + ind_ordered]\nind.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create correlation matrix\ncorr_matrix = ind.corr()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n\nto_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ind = ind.drop(columns = 'male') # Removing the flag ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ind[[c for c in ind if c.startswith('instl')]].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ind['inst'] = np.argmax(np.array(ind[[c for c in ind if c.startswith('instl')]]), axis = 1)\n\nplot_categoricals('inst', 'Target', ind, annotate = False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ind['escolari/age'] = ind['escolari'] / ind['age']\n\nplt.figure(figsize = (10, 8))\nsns.violinplot('Target', 'escolari/age', data = ind);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ind['inst/age'] = ind['inst'] / ind['age']\nind['tech'] = ind['v18q'] + ind['mobilephone']\nind['tech'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define custom function\nrange_ = lambda x: x.max() - x.min()\nrange_.__name__ = 'range_'\n\n# Group and aggregate\nind_agg = ind.drop(columns = 'Target').groupby('idhogar').agg(['min', 'max', 'sum', 'count', 'std', range_])\nind_agg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Rename the columns\nnew_col = []\nfor c in ind_agg.columns.levels[0]:\n    for stat in ind_agg.columns.levels[1]:\n        new_col.append(f'{c}-{stat}')\n        \nind_agg.columns = new_col\nind_agg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ind_agg.iloc[:, [0, 1, 2, 3, 6, 7, 8, 9]].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Selection\n\nAs a first round of feature selection, we can remove one out of every pair of variables with a correlation greater than 0.95."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create correlation matrix\ncorr_matrix = ind_agg.corr()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n\nprint(f'There are {len(to_drop)} correlated columns to remove.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### drop the columns and then merge with the heads data to create a final dataframe.\n\nind_agg = ind_agg.drop(columns = to_drop)\nind_feats = list(ind_agg.columns)\n\n# Merge on the household id\nfinal = heads.merge(ind_agg, on = 'idhogar', how = 'left')\n\nprint('Final features shape: ', final.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corrs = final.corr()['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corrs.sort_values().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corrs.sort_values().dropna().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nsns.boxplot(x = 'Target', y = 'escolari-max', data = final);\nplt.title('Max Schooling by Target');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"head_gender = ind.loc[ind['parentesco1'] == 1, ['idhogar', 'female']]\nfinal = final.merge(head_gender, on = 'idhogar', how = 'left').rename(columns = {'female': 'female-head'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"final.groupby('female-head')['Target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.violinplot(x = 'female-head', y = 'Target', data = final);\nplt.title('Target by Female Head of Household');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"final.groupby('female-head')['meaneduc'].agg(['mean', 'count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Machine Learning ModelingÂ¶\n\nOnce feature engineering/construction is done, we can get started with the machine learning! \nAll of our data (both training and testing) is aggregated for each household and so can be directly used in a model. To first show the process of modeling, we'll use the capable Random Forest Classifier in Scikit-Learn."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\n\n# Custom scorer for cross validation\nscorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Labels for training\ntrain_labels = np.array(list(final[final['Target'].notnull()]['Target'].astype(np.uint8)))\n\n# Extract the training data\ntrain_set = final[final['Target'].notnull()].drop(columns = ['Id', 'idhogar', 'Target'])\ntest_set = final[final['Target'].isnull()].drop(columns = ['Id', 'idhogar', 'Target'])\n\n# Submission base which is used for making submissions to the competition\nsubmission_base = test[['Id', 'idhogar']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"features = list(train_set.columns)\n\npipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n                      ('scaler', MinMaxScaler())])\n\n# Fit and transform training data\ntrain_set = pipeline.fit_transform(train_set)\ntest_set = pipeline.transform(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=100, random_state=10, \n                               n_jobs = -1)\n# 10 fold cross validation\ncv_score = cross_val_score(model, train_set, train_labels, cv = 10, scoring = scorer)\n\nprint(f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Importances\n\nWith a tree-based model, we can look at the feature importances which show a relative ranking of the usefulness of features in the model. These represent the sum of the reduction in impurity at nodes that used the variable for splitting.\n\nIf we want to view the feature importances, we'll have to train a model on the whole training set. Cross validation does not return the feature importances."},{"metadata":{"trusted":false},"cell_type":"code","source":"model.fit(train_set, train_labels)\n\n# Feature importances into a dataframe\nfeature_importances = pd.DataFrame({'feature': features, 'importance': model.feature_importances_})\nfeature_importances.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Below is a short function we'll use to plot the feature importances. \n\ndef plot_feature_importances(df, n = 10, threshold = None):\n    \"\"\"Plots n most important features. Also plots the cumulative importance if\n    threshold is specified and prints the number of features needed to reach threshold cumulative importance.\n    Intended for use with any tree-based feature importances. \n    \n    Args:\n        df (dataframe): Dataframe of feature importances. Columns must be \"feature\" and \"importance\".\n    \n        n (int): Number of most important features to plot. Default is 15.\n    \n        threshold (float): Threshold for cumulative importance plot. If not provided, no plot is made. Default is None.\n        \n    Returns:\n        df (dataframe): Dataframe ordered by feature importances with a normalized column (sums to 1) \n                        and a cumulative importance column\n    \n    Note:\n    \n        * Normalization in this case means sums to 1. \n        * Cumulative importance is calculated by summing features from most to least important\n        * A threshold of 0.9 will show the most important features needed to reach 90% of cumulative importance\n    \n    \"\"\"\n    plt.style.use('fivethirtyeight')\n    \n    # Sort features with most important at the head\n    df = df.sort_values('importance', ascending = False).reset_index(drop = True)\n    \n    # Normalize the feature importances to add up to one and calculate cumulative importance\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    df['cumulative_importance'] = np.cumsum(df['importance_normalized'])\n    \n    plt.rcParams['font.size'] = 12\n    \n    # Bar plot of n most important features\n    df.loc[:n, :].plot.barh(y = 'importance_normalized', \n                            x = 'feature', color = 'darkgreen', \n                            edgecolor = 'k', figsize = (12, 8),\n                            legend = False, linewidth = 2)\n\n    plt.xlabel('Normalized Importance', size = 18); plt.ylabel(''); \n    plt.title(f'{n} Most Important Features', size = 18)\n    plt.gca().invert_yaxis()\n    \n    \n    if threshold:\n        # Cumulative importance plot\n        plt.figure(figsize = (8, 6))\n        plt.plot(list(range(len(df))), df['cumulative_importance'], 'b-')\n        plt.xlabel('Number of Features', size = 16); plt.ylabel('Cumulative Importance', size = 16); \n        plt.title('Cumulative Feature Importance', size = 18);\n        \n        # Number of features needed for threshold cumulative importance\n        # This is the index (will need to add 1 for the actual number)\n        importance_index = np.min(np.where(df['cumulative_importance'] > threshold))\n        \n        # Add vertical line to plot\n        plt.vlines(importance_index + 1, ymin = 0, ymax = 1.05, linestyles = '--', colors = 'red')\n        plt.show();\n        \n        print('{} features required for {:.0f}% of cumulative importance.'.format(importance_index + 1, \n                                                                                  100 * threshold))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"norm_fi = plot_feature_importances(feature_importances, threshold=0.95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def kde_target(df, variable):\n    \"\"\"Plots the distribution of `variable` in `df` colored by the `Target` column\"\"\"\n    \n    colors = {1: 'red', 2: 'orange', 3: 'blue', 4: 'green'}\n\n    plt.figure(figsize = (12, 8))\n    \n    df = df[df['Target'].notnull()]\n    \n    for level in df['Target'].unique():\n        subset = df[df['Target'] == level].copy()\n        sns.kdeplot(subset[variable].dropna(), \n                    label = f'Poverty Level: {level}', \n                    color = colors[int(subset['Target'].unique())])\n\n    plt.xlabel(variable); plt.ylabel('Density');\n    plt.title('{} Distribution'.format(variable.capitalize()));","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"kde_target(final, 'meaneduc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model imports\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, RidgeClassifierCV\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings \nfrom sklearn.exceptions import ConvergenceWarning\n\n# Filter out warnings from models\nwarnings.filterwarnings('ignore', category = ConvergenceWarning)\nwarnings.filterwarnings('ignore', category = DeprecationWarning)\nwarnings.filterwarnings('ignore', category = UserWarning)\n\n# Dataframe to hold results\nmodel_results = pd.DataFrame(columns = ['model', 'cv_mean', 'cv_std'])\n\ndef cv_model(train, train_labels, model, name, model_results=None):\n    \"\"\"Perform 10 fold cross validation of a model\"\"\"\n    \n    cv_scores = cross_val_score(model, train, train_labels, cv = 10, scoring=scorer, n_jobs = -1)\n    print(f'10 Fold CV Score: {round(cv_scores.mean(), 5)} with std: {round(cv_scores.std(), 5)}')\n    \n    if model_results is not None:\n        model_results = model_results.append(pd.DataFrame({'model': name, \n                                                           'cv_mean': cv_scores.mean(), \n                                                            'cv_std': cv_scores.std()},\n                                                           index = [0]),\n                                             ignore_index = True)\n\n        return model_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results = cv_model(train_set, train_labels, LinearSVC(), \n                         'LSVC', model_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results = cv_model(train_set, train_labels, \n                         GaussianNB(), 'GNB', model_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results = cv_model(train_set, train_labels, \n                         MLPClassifier(hidden_layer_sizes=(32, 64, 128, 64, 32)),\n                         'MLP', model_results)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results = cv_model(train_set, train_labels, \n                          LinearDiscriminantAnalysis(), \n                          'LDA', model_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results = cv_model(train_set, train_labels, \n                         RidgeClassifierCV(), 'RIDGE', model_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for n in [5, 10, 20]:\n    print(f'\\nKNN with {n} neighbors\\n')\n    model_results = cv_model(train_set, train_labels, \n                             KNeighborsClassifier(n_neighbors = n),\n                             f'knn-{n}', model_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\nmodel_results = cv_model(train_set, train_labels, \n                         ExtraTreesClassifier(n_estimators = 100, random_state = 10),\n                         'EXT', model_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Comparing Model Performance\n\nmodel_results = cv_model(train_set, train_labels,\n                          RandomForestClassifier(100, random_state=10),\n                              'RF', model_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results.set_index('model', inplace = True)\nmodel_results['cv_mean'].plot.bar(color = 'orange', figsize = (8, 6),\n                                  yerr = list(model_results['cv_std']),\n                                  edgecolor = 'k', linewidth = 2)\nplt.title('Model F1 Score Results');\nplt.ylabel('Mean F1 Score (with error bar)');\nmodel_results.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_ids = list(final.loc[final['Target'].isnull(), 'idhogar'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The function below takes in a model, a training set, the training labels, and a testing set and performs the following operations:\n\n\nTrains the model on the training data using fit\n\nMakes predictions on the test data using predict\n\nCreates a submission dataframe that can be saved and uploaded to the competition"},{"metadata":{"trusted":false},"cell_type":"code","source":"def submit(model, train, train_labels, test, test_ids):\n    \"\"\"Train and test a model on the dataset\"\"\"\n    \n    # Train on the data\n    model.fit(train, train_labels)\n    predictions = model.predict(test)\n    predictions = pd.DataFrame({'idhogar': test_ids,\n                               'Target': predictions})\n\n     # Make a submission dataframe\n    submission = submission_base.merge(predictions, \n                                       on = 'idhogar',\n                                       how = 'left').drop(columns = ['idhogar'])\n    \n    # Fill in households missing a head\n    submission['Target'] = submission['Target'].fillna(4).astype(np.int8)\n\n    return submission ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# submission with the Random Forest.\n\nrf_submission = submit(RandomForestClassifier(n_estimators = 100, \n                                              random_state=10, n_jobs = -1), \n                         train_set, train_labels, test_set, test_ids)\n\nrf_submission.to_csv('rf_submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_set = pd.DataFrame(train_set, columns = features)\n\n# Create correlation matrix\ncorr_matrix = train_set.corr()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(abs(upper[column]) > 0.95)]\n\nto_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_set = train_set.drop(columns = to_drop)\ntrain_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_set = pd.DataFrame(test_set, columns = features)\ntrain_set, test_set = train_set.align(test_set, axis = 1, join = 'inner')\nfeatures = list(train_set.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recursive Feature Elimination with Random Forest\n\nThe RFECV in Sklearn stands for Recursive Feature Elimination with Cross Validation. The selector operates using a model with feature importances in an iterative manner. At each iteration, it removes either a fraction of features or a set number of features. The iterations continue until the cross validation score no longer improves."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\n# Create a model for feature selection\nestimator = RandomForestClassifier(random_state = 10, n_estimators = 100,  n_jobs = -1)\n\n# Create the object\nselector = RFECV(estimator, step = 1, cv = 3, scoring= scorer, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we fit the selector on the training data as with any other sklearn model. "},{"metadata":{"trusted":false},"cell_type":"code","source":"selector.fit(train_set, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(selector.grid_scores_);\n\nplt.xlabel('Number of Features'); plt.ylabel('Macro F1 Score'); plt.title('Feature Selection Scores');\nselector.n_features_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rankings = pd.DataFrame({'feature': list(train_set.columns), 'rank': list(selector.ranking_)}).sort_values('rank')\nrankings.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_selected = selector.transform(train_set)\ntest_selected = selector.transform(test_set)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert back to dataframe\nselected_features = train_set.columns[np.where(selector.ranking_==1)]\ntrain_selected = pd.DataFrame(train_selected, columns = selected_features)\ntest_selected = pd.DataFrame(test_selected, columns = selected_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results = cv_model(train_selected, train_labels, model, 'RF-SEL', model_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results.set_index('model', inplace = True)\nmodel_results['cv_mean'].plot.bar(color = 'orange', figsize = (8, 6),\n                                  yerr = list(model_results['cv_std']),\n                                 edgecolor = 'k', linewidth = 2)\nplt.title('Model F1 Score Results');\nplt.ylabel('Mean F1 Score (with error bar)');\nmodel_results.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Upgrading Our Model: Gradient Boosting Machine"},{"metadata":{"trusted":false},"cell_type":"code","source":"def macro_f1_score(labels, predictions):\n    # Reshape the predictions as needed\n    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n    \n    metric_value = f1_score(labels, predictions, average = 'macro')\n    \n    # Return is name, value, is_higher_better\n    return 'macro_f1', metric_value, True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Light Gradient Boosting Machine Implementation\n\nThe function below implements training the gradient boosting machine with Stratified Kfold cross validation and early stopping to prevent overfitting to the training data (although this can still occur). The function performs training with cross validation and records the predictions in probability for each fold. "},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom IPython.display import display\n\ndef model_gbm(features, labels, test_features, test_ids, \n              nfolds = 5, return_preds = False, hyp = None):\n    \"\"\"Model using the GBM and cross validation.\n       Trains with early stopping on each fold.\n       Hyperparameters probably need to be tuned.\"\"\"\n    \n    feature_names = list(features.columns)\n\n    # Option for user specified hyperparameters\n    if hyp is not None:\n        # Using early stopping so do not need number of esimators\n        if 'n_estimators' in hyp:\n            del hyp['n_estimators']\n        params = hyp\n    \n    else:\n        # Model hyperparameters\n        params = {'boosting_type': 'dart', \n                  'colsample_bytree': 0.88, \n                  'learning_rate': 0.028, \n                   'min_child_samples': 10, \n                   'num_leaves': 36, 'reg_alpha': 0.76, \n                   'reg_lambda': 0.43, \n                   'subsample_for_bin': 40000, \n                   'subsample': 0.54, \n                   'class_weight': 'balanced'}\n    \n    # Build the model\n    model = lgb.LGBMClassifier(**params, objective = 'multiclass', \n                               n_jobs = -1, n_estimators = 10000,\n                               random_state = 10)\n    \n    # Using stratified kfold cross validation\n    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n    \n    # Hold all the predictions from each fold\n    predictions = pd.DataFrame()\n    importances = np.zeros(len(feature_names))\n    \n    # Convert to arrays for indexing\n    features = np.array(features)\n    test_features = np.array(test_features)\n    labels = np.array(labels).reshape((-1 ))\n    \n    valid_scores = []\n    \n    # Iterate through the folds\n    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n        \n        # Dataframe for fold predictions\n        fold_predictions = pd.DataFrame()\n        \n        # Training and validation data\n        X_train = features[train_indices]\n        X_valid = features[valid_indices]\n        y_train = labels[train_indices]\n        y_valid = labels[valid_indices]\n        \n        # Train with early stopping\n        model.fit(X_train, y_train, early_stopping_rounds = 100, \n                  eval_metric = macro_f1_score,\n                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n                  eval_names = ['train', 'valid'],\n                  verbose = 200)\n        \n        # Record the validation fold score\n        valid_scores.append(model.best_score_['valid']['macro_f1'])\n        \n        # Make predictions from the fold as probabilities\n        fold_probabilitites = model.predict_proba(test_features)\n        \n        # Record each prediction for each class as a separate column\n        for j in range(4):\n            fold_predictions[(j + 1)] = fold_probabilitites[:, j]\n            \n        # Add needed information for predictions \n        fold_predictions['idhogar'] = test_ids\n        fold_predictions['fold'] = (i+1)\n        \n        # Add the predictions as new rows to the existing predictions\n        predictions = predictions.append(fold_predictions)\n        \n        # Feature importances\n        importances += model.feature_importances_ / nfolds   \n        \n        # Display fold information\n        display(f'Fold {i + 1}, Validation Score: {round(valid_scores[i], 5)}, Estimators Trained: {model.best_iteration_}')\n\n    # Feature importances dataframe\n    feature_importances = pd.DataFrame({'feature': feature_names,\n                                        'importance': importances})\n    \n    valid_scores = np.array(valid_scores)\n    display(f'{nfolds} cross validation score: {round(valid_scores.mean(), 5)} with std: {round(valid_scores.std(), 5)}.')\n    \n    # If we want to examine predictions don't average over folds\n    if return_preds:\n        predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n        predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n        return predictions, feature_importances\n    \n    # Average the predictions over folds\n    predictions = predictions.groupby('idhogar', as_index = False).mean()\n    \n    # Find the class and associated probability\n    predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n    predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n    predictions = predictions.drop(columns = ['fold'])\n    \n    # Merge with the base to have one prediction for each individual\n    submission = submission_base.merge(predictions[['idhogar', 'Target']], on = 'idhogar', how = 'left').drop(columns = ['idhogar'])\n        \n    # Fill in the individuals that do not have a head of household with 4 since these will not be scored\n    submission['Target'] = submission['Target'].fillna(4).astype(np.int8)\n    \n    # return the submission and feature importances along with validation scores\n    return submission, feature_importances, valid_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%capture --no-display\npredictions, gbm_fi = model_gbm(train_set, train_labels, test_set, test_ids, return_preds=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.rcParams['font.size'] = 18\n\n# Kdeplot\ng = sns.FacetGrid(predictions, row = 'fold', hue = 'Target', size = 3, aspect = 4)\ng.map(sns.kdeplot, 'confidence');\ng.add_legend();\n\nplt.suptitle('Distribution of Confidence by Fold and Target', y = 1.05);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Average the predictions over folds\npredictions = predictions.groupby('idhogar', as_index = False).mean()\n\n# Find the class and associated probability\npredictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\npredictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\npredictions = predictions.drop(columns = ['fold'])\n\n# Plot the confidence by each target\nplt.figure(figsize = (10, 6))\nsns.boxplot(x = 'Target', y = 'confidence', data = predictions);\nplt.title('Confidence by Target');\n\nplt.figure(figsize = (10, 6))\nsns.violinplot(x = 'Target', y = 'confidence', data = predictions);\nplt.title('Confidence by Target');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%capture\nsubmission, gbm_fi, valid_scores = model_gbm(train_set, train_labels, \n                                             test_set, test_ids, return_preds=False)\n\nsubmission.to_csv('gbm_baseline.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"_ = plot_feature_importances(gbm_fi, threshold=0.95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%capture --no-display\nsubmission, gbm_fi_selected, valid_scores_selected = model_gbm(train_selected, train_labels, \n                                                               test_selected, test_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results = model_results.append(pd.DataFrame({'model': [\"GBM\", \"GBM_SEL\"], \n                                                   'cv_mean': [valid_scores.mean(), valid_scores_selected.mean()],\n                                                   'cv_std':  [valid_scores.std(), valid_scores_selected.std()]}),\n                                                sort = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results.set_index('model', inplace = True)\nmodel_results['cv_mean'].plot.bar(color = 'orange', figsize = (8, 6),\n                                  yerr = list(model_results['cv_std']),\n                                 edgecolor = 'k', linewidth = 2)\nplt.title('Model F1 Score Results');\nplt.ylabel('Mean F1 Score (with error bar)');\nmodel_results.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%capture\nsubmission, gbm_fi, valid_scores = model_gbm(train_set, train_labels, test_set, test_ids, \n                                             nfolds=10, return_preds=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.to_csv('gbm_10fold.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%capture\nsubmission, gbm_fi_selected, valid_scores_selected = model_gbm(train_selected, train_labels, test_selected, test_ids,\n                                                               nfolds=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.to_csv('gmb_10fold_selected.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results = model_results.append(pd.DataFrame({'model': [\"GBM_10Fold\", \"GBM_10Fold_SEL\"], \n                                                   'cv_mean': [valid_scores.mean(), valid_scores_selected.mean()],\n                                                   'cv_std':  [valid_scores.std(), valid_scores_selected.std()]}),\n                                    sort = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_results.set_index('model', inplace = True)\nmodel_results['cv_mean'].plot.bar(color = 'orange', figsize = (8, 6), \n                                  edgecolor = 'k', linewidth = 2,\n                                  yerr = list(model_results['cv_std']))\nplt.title('Model F1 Score Results');\nplt.ylabel('Mean F1 Score (with error bar)');\nmodel_results.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(f\"There are {gbm_fi_selected[gbm_fi_selected['importance'] == 0].shape[0]} features with no importance.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dimension Reduction\n\nAs a final exploration of the problem, we can apply a few different dimension reductions methods to the selected data set. These methods can be used for visualization or as a preprocessing method for machine learning. We'll look at four different methods:\n\n1. PCA: Principal Components Analysis. Finds the dimensions of greatest variation in the data\n2. ICA: Independent Components Analysis. Attempts to separate a mutltivariate signal into independent signals.\n3. TSNE: T-distributed Stochastic Neighbor Embedding. Maps high-dimensional data to a low-dimensional manifold attempting to maintain the local structure within the data. It is a non-linear technique and generally only used for visualization.\n4. UMAP: Uniform Manifold Approximation and Projection: A relatively new technique that also maps data to a low-dimensional manifold but tries to preserve more global structure than TSNE.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.decomposition import PCA, FastICA\nfrom sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"n_components = 3\n\n#umap = UMAP(n_components=n_components)\npca = PCA(n_components=n_components)\nica = FastICA(n_components=n_components)\ntsne = TSNE(n_components=n_components)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import time\n\ntrain_df = train_selected.copy()\ntest_df = test_selected.copy()\n\nfor method, name in zip([ pca, ica, tsne], \n                        [ 'pca', 'ica', 'tsne']):\n    \n    # TSNE has no transform method\n    if name == 'tsne':\n        start = time.time()\n        reduction = method.fit_transform(train_selected)\n        end = time.time()\n    \n    else:\n        start = time.time()\n        reduction = method.fit_transform(train_selected)\n        end = time.time()\n        \n        test_reduction = method.transform(test_selected)\n    \n        # Add components to test data\n        test_df['%s_c1' % name] = test_reduction[:, 0]\n        test_df['%s_c2' % name] = test_reduction[:, 1]\n        test_df['%s_c3' % name] = test_reduction[:, 2]\n\n    # Add components to training data for visualization and modeling\n    train_df['%s_c1' % name] = reduction[:, 0]\n    train_df['%s_c2' % name] = reduction[:, 1]\n    train_df['%s_c3' % name] = reduction[:, 2]\n    \n    print(f'Method: {name} {round(end - start, 2)} seconds elapsed.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\n\ndef discrete_cmap(N, base_cmap=None):\n    \"\"\"Create an N-bin discrete colormap from the specified input map\n    Source: https://gist.github.com/jakevdp/91077b0cae40f8f8244a\"\"\"\n\n    base = plt.cm.get_cmap(base_cmap)\n    color_list = base(np.linspace(0, 1, N))\n    cmap_name = base.name + str(N)\n    return base.from_list(cmap_name, color_list, N)\n\ncmap = discrete_cmap(4, base_cmap = plt.cm.RdYlBu)\n\ntrain_df['label'] = train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot each method\nfor method, name in zip([ pca, ica, tsne], \n                        [ 'pca', 'ica', 'tsne']):\n    \n    fig = plt.figure(figsize = (8, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    p = ax.scatter(train_df['%s_c1' % name], train_df['%s_c2'  % name], train_df['%s_c3'  % name], \n                   c = train_df['label'].astype(int), cmap = cmap)\n    \n    plt.title(f'{name.capitalize()}', size = 22)\n    fig.colorbar(p, aspect = 4, ticks = [1, 2, 3, 4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize Single Decision Tree"},{"metadata":{"trusted":false},"cell_type":"code","source":"model = RandomForestClassifier(max_depth = 3, n_estimators=10)\nmodel.fit(train_selected, train_labels)\nestimator_limited = model.estimators_[5]\nestimator_limited","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import export_graphviz\n\nexport_graphviz(estimator_limited, out_file='tree_limited.dot', feature_names = train_selected.columns,\n                class_names = ['extreme', 'moderate' , 'vulnerable', 'non-vulnerable'],\n                rounded = True, proportion = False, precision = 2, filled = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"!dot -Tpng tree_limited.dot -o tree_limited.png","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Display in jupyter notebook\nfrom IPython.display import Image\nImage(filename = 'tree_limited.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# No maximum depth\nmodel = RandomForestClassifier(max_depth = None, n_estimators=10)\nmodel.fit(train_selected, train_labels)\nestimator_nonlimited = model.estimators_[5]\n\nexport_graphviz(estimator_nonlimited, out_file='tree_nonlimited.dot', feature_names = train_selected.columns,\n                class_names = ['extreme', 'moderate' , 'vulnerable', 'non-vulnerable'],\n                rounded = True, proportion = False, precision = 2)\n\n!dot -Tpng tree_nonlimited.dot -o tree_nonlimited.png -Gdpi=600","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Image(filename = 'tree_nonlimited.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}