{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello, here is juste a simple scrapper of kenpom 2021 data in python. I also added the TeamID."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imports\n!pip install bs4\nimport pandas as pd\nimport numpy as np\nimport re\nfrom bs4 import BeautifulSoup\nimport requests\n\n\n#--------------------------------------------------\n# Scrapper\n\nbase_urls=[\n          'https://kenpom.com/index.php?y=2021'\n         ]\n\ndef scrap_archive(url,year):\n    \"\"\"\n    Imports raw data from a kenpom archive into a dataframe\n    \"\"\"\n    \n    page = requests.get(url)\n    soup = BeautifulSoup(page.text)\n    table_full = soup.find_all('table', {'id': 'ratings-table'})\n\n    thead = table_full[0].find_all('thead')\n    table = table_full[0]\n    \n    for weird in thead:\n        table = str(table).replace(str(weird), '')\n\n    df = pd.read_html(table)[0]\n    df['year'] = year\n    \n    return df\n    \n    \n#------------------------------------------------------\n# scraping\ndef scraping(df,year):\n    \n    for url in base_urls:\n    \n        print(f'Scrapping: {url}')\n        archive=scrap_archive(url,year)\n        \n        df = pd.concat( (df, archive), axis=0) \n        year+=1\n    \n    df.columns = ['Rank', 'Team', 'Conference', 'W-L', 'Pyth', \n             'AdjustO', 'AdjustO Rank', 'AdjustD', 'AdjustD Rank',\n             'AdjustT', 'AdjustT Rank', 'Luck', 'Luck Rank', \n             'SOS Pyth', 'SOS Pyth Rank', 'SOS OppO', 'SOS OppO Rank',\n             'SOS OppD', 'SOS OppD Rank', 'NCSOS Pyth', 'NCSOS Pyth Rank', 'Year']\n    \n    df=df[[ 'Year', 'Team', 'AdjustO', 'AdjustD', 'Luck']]\n    df.columns=[ 'Season', 'TeamName', 'adj_o', 'adj_d', 'luck']\n\n    df.TeamName=df.TeamName.apply(lambda x: re.sub('\\d', '', x).strip()).replace('.','')\n             \n        \n    return df\n\n\n\n#------------------------------------------------------\n# Scrap data for 2021\n\ndf=None\n\nyear=2021\n\ndf=scraping(df,year)\n\ndf.TeamName=df.TeamName.apply(lambda x: x.replace('-',' '))\ndf.TeamName=df.TeamName.apply(lambda x: x.lower())\ndf.TeamName=df.TeamName.replace('mississippi valley st.','mississippi valley state')\ndf.TeamName=df.TeamName.replace('texas a&m corpus chris','texas a&m corpus christi')\ndf.TeamName=df.TeamName.replace('dixie st.','dixie st')\ndf.TeamName=df.TeamName.replace('st. francis pa','st francis pa')\ndf.TeamName=df.TeamName.replace('ut rio grande valley','texas rio grande valley')\ndf.TeamName=df.TeamName.replace('southeast missouri st.','southeast missouri state')\ndf.TeamName=df.TeamName.replace('tarleton st.','tarleton st')\ndf.TeamName=df.TeamName.replace('liu','liu brooklyn')\ndf.TeamName=df.TeamName.replace('cal st. bakersfield','cal state bakersfield')\n\n#-------------------------------------------------------\n# merge with spelling file to get the TeamID\nspelling=pd.read_csv('../input/ncaam-march-mania-2021/MTeamSpellings.csv',encoding='cp1252')\nspelling.columns=['TeamName','TeamID']\nspelling.TeamName=spelling.TeamName.apply(lambda x: x.replace('-',' '))\n\n\ndf=df.merge(spelling[['TeamName','TeamID']],on='TeamName',how='left')\n\n#-------------------------------------------------------\n# Save the file\ndf.to_csv('kenpom_2021.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}