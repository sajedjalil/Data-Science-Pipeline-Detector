{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict \nfrom pathlib import Path \nfrom tqdm import tqdm \nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom xgboost import plot_importance\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import OneHotEncoder\nimport gc\nimport json\nimport shap\nimport os\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom lightgbm import LGBMClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tourney_result = pd.read_csv('../input/ncaam-march-mania-2021/MDataFiles_Stage2/MNCAATourneyCompactResults.csv')\ntourney_seed = pd.read_csv('../input/ncaam-march-mania-2021/MDataFiles_Stage2/MNCAATourneySeeds.csv')\nseason_result = pd.read_csv('../input/ncaam-march-mania-2021/MDataFiles_Stage2/MRegularSeasonCompactResults.csv')\ntest_df = pd.read_csv('../input/ncaam-march-mania-2021/MDataFiles_Stage2/MSampleSubmissionStage2.csv')\nsubmission_df = pd.read_csv('../input/ncaam-march-mania-2021/MDataFiles_Stage2/MSampleSubmissionStage2.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# deleting unnecessary columns\ntourney_result = tourney_result.drop(['DayNum', 'WScore', 'LScore', 'WLoc', 'NumOT'], axis=1)\n# Merge Seed\ntourney_result = pd.merge(tourney_result, tourney_seed, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Seed':'WSeed'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\ntourney_result = pd.merge(tourney_result, tourney_seed, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Seed':'LSeed'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\n\ndef get_seed(x):\n    return int(x[1:3])\n\ntourney_result['WSeed'] = tourney_result['WSeed'].map(lambda x: get_seed(x))\ntourney_result['LSeed'] = tourney_result['LSeed'].map(lambda x: get_seed(x))\n# Merge Score\nseason_win_result = season_result[['Season', 'WTeamID', 'WScore']]\nseason_lose_result = season_result[['Season', 'LTeamID', 'LScore']]\nseason_win_result.rename(columns={'WTeamID':'TeamID', 'WScore':'Score'}, inplace=True)\nseason_lose_result.rename(columns={'LTeamID':'TeamID', 'LScore':'Score'}, inplace=True)\nseason_result = pd.concat((season_win_result, season_lose_result)).reset_index(drop=True)\nseason_score = season_result.groupby(['Season', 'TeamID'])['Score'].sum().reset_index()\ntourney_result = pd.merge(tourney_result, season_score, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Score':'WScoreT'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\ntourney_result = pd.merge(tourney_result, season_score, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Score':'LScoreT'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\ntourney_win_result = tourney_result.drop(['Season', 'WTeamID', 'LTeamID'], axis=1)\ntourney_win_result.rename(columns={'WSeed':'Seed1', 'LSeed':'Seed2', 'WScoreT':'ScoreT1', 'LScoreT':'ScoreT2'}, inplace=True)\ntourney_lose_result = tourney_win_result.copy()\ntourney_lose_result['Seed1'] = tourney_win_result['Seed2']\ntourney_lose_result['Seed2'] = tourney_win_result['Seed1']\ntourney_lose_result['ScoreT1'] = tourney_win_result['ScoreT2']\ntourney_lose_result['ScoreT2'] = tourney_win_result['ScoreT1']\ntourney_win_result['Seed_diff'] = tourney_win_result['Seed1'] - tourney_win_result['Seed2']\ntourney_win_result['ScoreT_diff'] = tourney_win_result['ScoreT1'] - tourney_win_result['ScoreT2']\ntourney_lose_result['Seed_diff'] = tourney_lose_result['Seed1'] - tourney_lose_result['Seed2']\ntourney_lose_result['ScoreT_diff'] = tourney_lose_result['ScoreT1'] - tourney_lose_result['ScoreT2']\ntourney_win_result['result'] = 1\ntourney_lose_result['result'] = 0\ntourney_result = pd.concat((tourney_win_result, tourney_lose_result)).reset_index(drop=True)\ntrain_df = tourney_result\n# Get Test\ntest_df['Season'] = test_df['ID'].map(lambda x: int(x[:4]))\ntest_df['WTeamID'] = test_df['ID'].map(lambda x: int(x[5:9]))\ntest_df['LTeamID'] = test_df['ID'].map(lambda x: int(x[10:14]))\ntest_df = pd.merge(test_df, tourney_seed, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Seed':'Seed1'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, tourney_seed, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Seed':'Seed2'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, season_score, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Score':'ScoreT1'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, season_score, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Score':'ScoreT2'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df['Seed1'] = test_df['Seed1'].map(lambda x: get_seed(x))\ntest_df['Seed2'] = test_df['Seed2'].map(lambda x: get_seed(x))\ntest_df['Seed_diff'] = test_df['Seed1'] - test_df['Seed2']\ntest_df['ScoreT_diff'] = test_df['ScoreT1'] - test_df['ScoreT2']\ntest_df = test_df.drop(['ID', 'Pred', 'Season', 'WTeamID', 'LTeamID'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['result']=np.NaN\nclass Base_Model(object):\n    \n    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=False):\n        self.train_df = train_df\n        self.test_df = test_df\n        self.features = features\n        self.n_splits = n_splits\n        self.categoricals = categoricals\n        self.target = 'result'\n        self.cv = self.get_cv()\n        self.verbose = verbose\n        self.params = self.get_params()\n        self.y_pred, self.model = self.fit()\n        \n    def train_model(self, train_set, val_set):\n        raise NotImplementedError\n        \n    def get_cv(self):\n        cv = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n        return cv.split(self.train_df, self.train_df[self.target])\n    \n    def get_params(self):\n        raise NotImplementedError\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        raise NotImplementedError\n        \n    def convert_x(self, x):\n        return x\n        \n    def fit(self):\n        oof_pred = np.zeros((len(train_df), ))\n        y_pred = np.zeros((len(test_df), ))\n        for fold, (train_idx, val_idx) in enumerate(self.cv):\n            print('Fold:',fold+1)\n            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n            model = self.train_model(train_set, val_set)\n            \n            conv_x_val = self.convert_x(x_val)\n            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n            \n            x_test = self.convert_x(self.test_df[self.features])\n            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n        return y_pred, model\n    \n    \nclass Lgb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 100 if self.verbose else 0\n        return lgb.train(self.params, train_set, 10000, valid_sets=[train_set, val_set])\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n        return train_set, val_set\n        \n    def get_params(self):\n        params = {'num_leaves': 400,\n                  'min_child_weight': 0.034,\n                \n                  'bagging_fraction': 0.418,\n                  'min_data_in_leaf': 160,\n                  'objective': 'binary',\n                  'max_depth': -1,\n                  'learning_rate': 0.03,\n                  \"boosting_type\": \"gbdt\",\n                  \"bagging_seed\": 11,\n                  \"metric\": 'logloss',\n                  'reg_alpha': 0.3899,\n                  'reg_lambda': 0.648,\n                  'random_state': 47,\n            }\n        return params\n    \nclass Xgb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 100 if self.verbose else 0\n        return xgb.train(self.params, train_set, \n                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n                         verbose_eval=verbosity, early_stopping_rounds=100)\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = xgb.DMatrix(x_train, y_train)\n        val_set = xgb.DMatrix(x_val, y_val)\n        return train_set, val_set\n    \n    def convert_x(self, x):\n        return xgb.DMatrix(x)\n        \n    def get_params(self):\n        params = { 'colsample_bytree': 0.8,                 \n                   'learning_rate': 0.01,\n                   'max_depth': 3,\n                   'subsample': 1,\n                   'objective':'binary:logistic',\n                   'eval_metric':'logloss',\n                   'min_child_weight':3,\n                   'gamma':0.25,\n                   'n_estimators':5000}\n        return params\nclass Catb_Model(Base_Model):\n    \n    def train_model(self, train_df, test_df):\n        verbosity = 100 if self.verbose else 0\n        clf = CatBoostClassifier(**self.params)\n        clf.fit(train_df['X'], \n                train_df['y'], \n                eval_set=(test_df['X'], test_df['y']),\n                verbose=verbosity, \n                cat_features=self.categoricals)\n        return clf\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = {'X': x_train, 'y': y_train}\n        val_set = {'X': x_val, 'y': y_val}\n        return train_set, val_set\n        \n    def get_params(self):\n        params = {'loss_function': 'Logloss',\n                   'task_type': \"CPU\",\n                   'iterations': 5000,\n                   'od_type': \"Iter\",\n                    'depth': 3,\n                  'colsample_bylevel': 0.5, \n                   'early_stopping_rounds': 300,\n                    'l2_leaf_reg': 18,\n                   'random_seed': 42,\n                    'use_best_model': True\n                    }\n        return params\n    \nfeatures = train_df.columns\nfeatures = [x for x in features if x not in ['result']]\nprint(features)\ncategoricals = []\n\ncat_model = Catb_Model(train_df, test_df, features, categoricals=categoricals)\nlgb_model = Lgb_Model(train_df, test_df, features, categoricals=categoricals)\n#xgb_model = Xgb_Model(train_df, test_df, features, categoricals=categoricals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = {\n    'lgb_model': 16, \n    \n    'cat_model': 4\n}\nfinal_preds = (lgb_model.y_pred * weights['lgb_model'] +cat_model.y_pred * weights['cat_model']) / (weights['lgb_model'] + weights['cat_model'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/ncaam-march-mania-2021/MDataFiles_Stage2/MSampleSubmissionStage2.csv')\nsubmission.Pred = final_preds\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}