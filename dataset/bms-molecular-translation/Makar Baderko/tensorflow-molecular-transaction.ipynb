{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/bms-molecular-translation/\"\n\nlabels_path = path + \"train_labels.csv\"\ndf_train_labels = pd.read_csv(labels_path)\ndf_train_labels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(path + 'sample_submission.csv', index_col=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fully_qualified_path = path + \"train/{}/{}/{}/{}.png\"\nconvert_image_id_to_path = lambda image_id_details :fully_qualified_path.format(image_id_details[0], image_id_details[1], image_id_details[2], image_id_details) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels['image_path']=df_train_labels['image_id'].apply(convert_image_id_to_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_labels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Denoise images","metadata":{}},{"cell_type":"code","source":"def convert_image_id_2_path(image_id: str) -> str:\n    return path + \"test/{}/{}/{}/{}.png\".format(\n        image_id[0], image_id[1], image_id[2], image_id \n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_image(image_id, label):\n    plt.figure(figsize=(10, 8))\n    \n    image = cv2.imread(convert_image_id_2_path(image_id))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    plt.imshow(image)\n    plt.title(f\"{label}\", fontsize=14)\n    plt.axis(\"off\")\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_image_denoise(image_id):\n    plt.figure(figsize=(10, 8))  \n    image = cv2.imread(convert_image_id_2_path(image_id), cv2.IMREAD_GRAYSCALE)\n    _, blackAndWhite = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(blackAndWhite, None, None, None, 8, cv2.CV_32S)\n    sizes = stats[1:, -1] #get CC_STAT_AREA component\n    img2 = np.zeros((labels.shape), np.uint8)\n    for i in range(0, nlabels - 1):\n        if sizes[i] >= 2:   #filter small dotted regions\n            img2[labels == i + 1] = 255\n    image = cv2.bitwise_not(img2)\n    plt.imshow(image)    \n    plt.axis(\"off\")\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=0\nvisualize_image(test.index[i], test.index[i])\nvisualize_image_denoise(test.index[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=1\nvisualize_image(test.index[i], test.index[i])\nvisualize_image_denoise(test.index[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=3\nvisualize_image(test.index[i], test.index[i])\nvisualize_image_denoise(test.index[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=4\nvisualize_image(test.index[i], test.index[i])\nvisualize_image_denoise(test.index[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_train_batch(image_ids, labels):\n    plt.figure(figsize=(16, 12))\n    \n    for ind, (image_id, label) in enumerate(zip(image_ids, labels)):\n        plt.subplot(3, 3, ind + 1)\n        image = cv2.imread(convert_image_id_to_path(image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(f\"{label[:30]}...\", fontsize=10)\n        plt.axis(\"off\")\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_df = df_train_labels[:9]\nimage_ids = tmp_df['image_id']\nlabels = tmp_df[\"InChI\"].values\nvisualize_train_batch(image_ids, labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_df = df_train_labels[:9]\nimage_ids = tmp_df['image_id']\nlabels = tmp_df[\"InChI\"].values\nvisualize_train_batch(image_ids, labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Length of training-data:',len(df_train_labels))\nprint('Number of unique chemical identifier:',len(df_train_labels['InChI'].value_counts().index))\nprint('Max count of any chemical identifier in trainign data:',max(df_train_labels['InChI'].value_counts().values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_shape=[]\nw_shape=[]\naspect_ratio=[]\nfor idx,image_id in enumerate(df_train_labels.image_id.values[:1000]):\n    image = cv2.imread(df_train_labels['image_path'][idx])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    h_shape.append(image.shape[0])\n    w_shape.append(image.shape[1])\n    aspect_ratio.append(1.0 * (image.shape[1] / image.shape[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nplt.subplots_adjust(top = 0.5, bottom=0.01, hspace=1, wspace=0.4)\nplt.subplot(2, 2, 1)\nplt.hist(np.array(h_shape) * np.array(w_shape), bins=50)\nplt.xticks(rotation=45)\nplt.title(\"Area Image Distribution\", fontsize=14)\nplt.subplot(2, 2, 2)\nplt.hist(h_shape, bins=50)\nplt.title(\"Height Image Distribution\", fontsize=14)\nprint()\nplt.subplot(2, 2, 3)\nplt.hist(w_shape, bins=50)\nplt.title(\"Width Image Distribution\", fontsize=14)\nplt.subplot(2, 2, 4)\nplt.hist(aspect_ratio, bins=50)\nplt.title(\"Aspect Ratio Distribution\", fontsize=14);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pickle import dump\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications import DenseNet121, ResNet50\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.densenet import preprocess_input\nfrom keras.models import Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract features from each image\ndef extract_features():\n    \n # load the model\n    model = DenseNet121()\n    # re-structure the model\n    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n    # summarize\n    print(model.summary())\n # extract features from each image\n    features = dict()\n    for idx,name in enumerate(df_train_labels['image_path'].values[:100]):\n        filename = name\n        image = load_img(filename, target_size=(224, 224))\n         # convert the image pixels to a numpy array\n        image = img_to_array(image)\n         # reshape data for the model\n        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n         # prepare the image for the DenseNet121 model\n        image = preprocess_input(image)\n         # get features\n        feature = model.predict(image, verbose=0)\n         # store feature\n        features[df_train_labels['image_id'][idx]] = feature\n        #print('>%s' % name)\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#same but with ResNet50\n# extract features from each image\ndef extract_features():\n    model = ResNet50()\n    # re-structure the model\n    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n    # summarize\n    print(model.summary())\n # extract features from each image\n    features = dict()\n    for idx,name in enumerate(df_train_labels['image_path'].values[:100]):\n        filename = name\n        image = load_img(filename, target_size=(224, 224))\n         # convert the image pixels to a numpy array\n        image = img_to_array(image)\n         # reshape data for the model\n        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n         # prepare the image for the DenseNet121 model\n        image = preprocess_input(image)\n         # get features\n        feature = model.predict(image, verbose=0)\n         # store feature\n        features[df_train_labels['image_id'][idx]] = feature\n        #print('>%s' % name)\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = extract_features()\nprint('Extracted Features: %d' % len(features))\n# save to file\ndump(features, open('features.pkl', 'wb'))","metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract texts for images\ndef load_text():\n    mapping = dict()\n    for idx,text in enumerate(df_train_labels['InChI'].values[:101]):\n        mapping[df_train_labels['image_id'][idx]]=text\n    return mapping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_vocabulary(descriptions):\n    all_desc = set()\n    for key,value in descriptions.items():\n        all_desc.update([value])\n    return all_desc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = load_text()\nvocabulary  = to_vocabulary(texts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Loaded: %d ' % len(texts))\nprint('Vocabulary Size: %d' % len(vocabulary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport Levenshtein","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(path + 'sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=df_train_labels\ntrain['InChI_list'] = train['InChI'].progress_apply(lambda x: x.split('/'))\ntrain['InChI_length'] = train['InChI_list'].progress_apply(len)\nInChI_df = train['InChI_list'].progress_apply(pd.Series)\ntrain = pd.concat([train, InChI_df.add_prefix('InChI_')], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    scores = []\n    for true, pred in zip(y_true, y_pred):\n        score = Levenshtein.distance(true, pred)\n        scores.append(score)\n    avg_score = np.mean(scores)\n    return avg_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode_concat_string = ''\nfor i in range(11):\n    mode_string = train[f'InChI_{i}'].fillna('nan').mode()[0]\n    if mode_string != 'nan':\n        if i == 0:\n            mode_concat_string += mode_string\n        else:\n            mode_concat_string += '/' + mode_string","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mode_concat_string)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = train['InChI'].values\ny_pred = [mode_concat_string] * len(train)\nscore = get_score(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['InChI'] = mode_concat_string\noutput_cols = ['image_id', 'InChI']\ndisplay(test[output_cols])\ntest[output_cols].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}