{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Vector to Sequence RNN (Part-ii)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CONFIG(object):\n  \"\"\"CONFIG\"\"\"\n  def __init__(self):\n    self.img_size = (256,256)\n    self.base= '../input/bms-molecular-translation/'\n    self.df= '../input/bms-molecular-translation/train_labels.csv'\n    self.train='../input/bmsdataversion2/BMS-Datav2/train/'\n    self.batch_size= 16\n    self.lr= 0.001\n    self.val_split= 0.1\n    self.seed= 22\n    self.n_epochs= 4\n    self.vocab_size= 600\n    \n    \ncfg= CONFIG()\n\ndef load_path(img_id):\n    return img_id[0] +'/'+img_id[1]+'/'+img_id[2] +'/'+img_id+'.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab= ['<start>', '<end>', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n        '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28',\n        '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43',\n        '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58',\n        '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73',\n        '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88',\n        '89', '90', '91', '92', '(', ')', '-', 'c']\nlen(vocab)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## INPUT DATA\n<img src=\"https://camo.githubusercontent.com/c73259c22376b40060d05571a8731781d1058771/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6a656666686561746f6e2f7438315f3535385f646565705f6c6561726e696e672f6d61737465722f696d616765732f63617074696f6e2d322e706e67\" height=\"300\" align=\"left\">"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_paths= np.load('../input/bmsdataversion2/BMS-Datav2/path.npy')\nX= np.load('../input/bmsdataversion2/BMS-Datav2/X.npy')\nY= np.load('../input/bmsdataversion2/BMS-Datav2/Y.npy')\n\nX.shape, Y.shape, img_paths.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y= Y.astype(np.float32)\nX= X.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_paths= (pd.Series(img_paths).apply(lambda x: x.split('/')[-1]))\nimg_paths[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(list(range(98)),Y.sum(0))\nplt.title('Class Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(list(range(94)),Y.sum(0)[0:-4])\nplt.title('Class Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_imgext():\n    img_base= tf.keras.applications.ResNet50V2(include_top=False)\n    inp= layers.Input((cfg.img_size[0], cfg.img_size[1], 3))\n    x= img_base(inp)\n    x= layers.Dropout(0.3)(x)\n    x= layers.GlobalAveragePooling2D()(x)\n    x= layers.Dense(512, 'relu')(x)\n    return tf.keras.Model(inp, x)\n\ndef build_model():\n    img_base= build_imgext()\n    inp1= layers.Input((cfg.img_size[0], cfg.img_size[1], 3))\n    fc1= img_base(inp1)\n    \n    inp2 = layers.Input(shape=(len(vocab)))\n    se1 = layers.Embedding(len(vocab), cfg.vocab_size, mask_zero=True)(inp2)\n    se2 = layers.Dropout(0.25)(se1)\n    se3 = layers.LSTM(512)(se2)\n    \n    decoder1 = layers.add([fc1, se3])\n    decoder2 = layers.Dense(512, activation='relu')(decoder1)\n    out = layers.Dense(len(vocab), activation='softmax')(decoder2)\n    \n    return tf.keras.Model([inp1, inp2], out)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TPU PIPELINE"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"img_size= cfg.img_size[0]\ndef build_decoder(with_labels=True, target_size=(img_size, img_size), ext='png'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path) # Reads and outputs the entire contents of the input filename.\n\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3) # Decode a PNG-encoded image to a uint8 or uint16 tensor\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3) # Decode a JPEG-encoded image to a uint8 tensor\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32) / 255.0 # Casts a tensor to the type float32 and divides by 255.\n        img = tf.image.resize(img, target_size) # Resizing to target size\n        return img\n    \n    def decode_with_labels(path, x, label):\n        return (decode(path), x), label\n    \n    return decode_with_labels if with_labels else decode","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_saturation(img, 0.8, 1.2)\n        img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\ndef build_dataset(paths, x=None, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, x, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    #dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize, drop_remainder=False).prefetch(AUTO)\n    # dset = dset.batch(bsize, drop_remainder=False).prefetch(AUTO) #overlaps data preprocessing and model execution while training\n    return dset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_NAME = \"bmsdataversion2\"\nstrategy = auto_select_accelerator()\nbatch_size = strategy.num_replicas_in_sync * cfg.batch_size\nprint('batch size', batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(DATASET_NAME)\nGCS_DS_PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"Ydf= pd.DataFrame(Y)\n# end tags\nind= Ydf[Ydf[1]==1].index\nsp= ind[12000] +1","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"img_paths= GCS_DS_PATH + '/BMS-Datav2/train/' + img_paths\n#img_paths= '../input/bmsdataversion2/BMS-Datav2/train/' + img_paths\nimg_paths[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data\n(train_paths, valid_paths, \n train_labels, valid_labels,\n X_train, X_valid) = (img_paths[:sp], img_paths[sp:], Y[:sp], Y[sp:], X[:sp], X[sp:])\n\nprint(train_paths.shape, valid_paths.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder = build_decoder(with_labels=True, target_size=(img_size, img_size))\n\n# Build the tensorflow datasets\ndtrain = build_dataset(\n    train_paths, X_train, train_labels, bsize=batch_size, decode_fn=decoder)\n\ndvalid = build_dataset(\n    valid_paths, X_valid, valid_labels, bsize=batch_size, \n    repeat=False, shuffle=False, augment=False, decode_fn=decoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data, _ = dtrain.take(2)\nimages = data[0][0].numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 4, figsize=(15,10))\naxes = axes.flatten()\nfor img, ax in zip(images, axes):\n    ax.imshow(img, aspect= True)\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model= build_model()\n    loss= tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.0)\n    \n    model.compile(tf.keras.optimizers.Adam(lr=cfg.lr),\n                  loss= loss, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name= 'img_capv1.h5'\n\nrlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, \n                                min_delta = 1e-4, min_lr = 1e-6, mode = 'min', cooldown=1)\n        \nckp = ModelCheckpoint(name,monitor = 'val_loss',\n                      verbose = 1, save_best_only = True, mode = 'min')\n        \nes = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n                    restore_best_weights = True, verbose = 1)\n\nsteps_per_epoch = (train_paths.shape[0] // batch_size)//2\nsteps_per_epoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(dtrain,                      \n                    validation_data=dvalid,                                       \n                    epochs=cfg.n_epochs,\n                    callbacks=[rlr,es,ckp],\n                    steps_per_epoch=steps_per_epoch,\n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.plot( history.history[\"loss\"], label = \"Training Loss\", marker='o')\nplt.plot( history.history[\"val_loss\"], label = \"Validation Loss\", marker='+')\nplt.grid(True)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"ACC\")\nplt.plot( history.history[\"accuracy\"], label = \"Training ACC\" , marker='o')\nplt.plot( history.history[\"val_accuracy\"], label = \"Validation ACC\", marker='+')\nplt.grid(True)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://i.gifer.com/7ImI.gif)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}