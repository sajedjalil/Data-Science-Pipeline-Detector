{"cells":[{"metadata":{},"cell_type":"markdown","source":"This submission will focus on submission predictions, particularly using different datas, and different models for each feature. Please look at my previous notebook on Domain Explanation and Visualizations below:\n\nhttps://www.kaggle.com/dhuang718/domain-explanation-visualization-modeling\n    ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport statistics as s ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the datasets","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#import dataset and specify X (independent variables) and y (dependent variable)\ndf_icn = pd.read_csv('/kaggle/input/trends-assessment-prediction/ICN_numbers.csv')\ndf_fnc = pd.read_csv('/kaggle/input/trends-assessment-prediction/fnc.csv')\ndf_loading = pd.read_csv('/kaggle/input/trends-assessment-prediction/loading.csv')\ndf_reveal = pd.read_csv('/kaggle/input/trends-assessment-prediction/reveal_ID_site2.csv')\ndf_sample = pd.read_csv('/kaggle/input/trends-assessment-prediction/sample_submission.csv')\ndf_train = pd.read_csv('/kaggle/input/trends-assessment-prediction/train_scores.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#impute missing training values\nfrom sklearn.impute import KNNImputer\n\n#separate Id column and attributes\ndf_train2 = df_train[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']]\n\n#impute\nimputer = KNNImputer(n_neighbors = 3, weights=\"uniform\")\ndf_train2 = imputer.fit_transform(df_train2)\n\n#convert the 2d array back to the dataframe and add back the Id column\ndf_train2 = pd.DataFrame(df_train2, columns = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2'])\ndf_train2 = pd.concat([df_train['Id'], df_train2], axis =1)\n\ndf_train_imputed = df_train2.copy()\n\ndf_train_imputed","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#specify the datasets to be tested in the model, \n\n#option 1\ndf_combine_fnc = df_train_imputed.join(df_fnc.set_index('Id'), on = 'Id')\n\n#option 2\ndf_combine_loading = df_train_imputed.join(df_loading.set_index('Id'), on = 'Id')\n\n#option 3\ndf_combine = df_train_imputed.join(df_fnc.set_index('Id'), on = 'Id')\ndf_combine = df_combine.join(df_loading.set_index('Id'), on = 'Id')\n\n#current testing\ndf = df_combine\nfrom termcolor import colored\ntext = colored('Currently testing ICs and FNCs as predictors',  'red', attrs=['reverse', 'blink'])\nprint(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#X for df_combine_fnc\nX = df.iloc[:, 6:]\n\n#specify the y's\ny = df.iloc[:, 0:6]\ny_age = df.iloc[:, 1]\ny_1_1 = df.iloc[:, 2].round(2)\ny_1_2 = df.iloc[:, 3]\ny_2_1 = df.iloc[:, 4]\ny_2_2 = df.iloc[:, 5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scaling the fnc data","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#less importance to fnc dataframe\nFNC_SCALE = 1/350\n\nX = df.iloc[:, 6:]\nX.iloc[:,:1378] *= FNC_SCALE\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#specify features to predict\ntargets = [y_age, y_1_1, y_1_2, y_2_1, y_2_2]\n\n#weights from TRENDS\nweights = [.3, .175, .175, .175, .175]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ensemble Model - Diferrent Models for Each y's","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#framework to be able to run different models on each feature\nfrom sklearn.model_selection import train_test_split\n\n#select models \nfrom sklearn.svm import SVR\n\n#score holding\nscores_storage = []\n\nfor i in targets:\n    #split the data\n    X_train, X_test, y_train, y_test = train_test_split(X, i, test_size=0.3, random_state=0)\n    \n    #run the model\n    if i.equals(y_age):\n        model = SVR(kernel='linear')\n    elif i.equals(y_1_1):\n        model = SVR(kernel='linear')\n    elif i.equals(y_1_2):\n        model = SVR(kernel='linear')\n    elif i.equals(y_2_1):\n        model = SVR(kernel='linear')\n    elif i.equals(y_2_2):\n        model = SVR(kernel='linear')\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    #get scores of each target\n    unweighted_score = (abs(y_test-y_pred)).sum()/y_pred.sum()\n    scores_storage.append(unweighted_score)\n\n#multiple scores with weights and sum for final score\ngrand_score = [scores_storage[i] * weights[i] for i in range(len(scores_storage))]\nsum(grand_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#get the ID's of the submission\ndf_sub_id = df_sample.copy()\n\ndf_sub_id['Id'] = df_sub_id['Id'].str.slice(0,5,1)\ndf_sub_id = df_sub_id['Id'].unique()\n\ndf_sub_id = pd.DataFrame({'Id' : df_sub_id , 'hold' : np.zeros(len(df_sub_id))})\ndf_sub_id['Id'] = df_sub_id['Id'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#create the features dataframe for submission Ids\ndf_sub_combine = df_fnc.join(df_loading.set_index('Id'), on = 'Id')\ndf_sub_combine = df_sub_combine.join(df_sub_id.set_index('Id'), on = 'Id')\ndf_sub_combine = df_sub_combine.dropna()\n\n#create the features only dataframe for submission Ids\ndf_sub_test = df_sub_combine.drop(columns = ['Id', 'hold'])\n\n#less importance to fnc portion\nFNC_SCALE = 1/350\ndf_sub_test.iloc[:,:1378] *= FNC_SCALE\ndf_sub_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#model\ntargets = [y_age, y_1_1, y_1_2, y_2_1, y_2_2]\ntargets_names = ['y_age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\ntarget_models = [SVR(kernel='linear'),\n                 SVR(kernel='linear'),\n                 SVR(kernel='linear'),\n                 SVR(kernel='linear'),\n                 SVR(kernel='linear')]\n\nint_index = [0, 1, 2, 3, 4]\n\n#create empty submission dataframe\nsubmission = pd.DataFrame()\n\n#create submission \nfor i in int_index:\n    #for i in targets:\n\n    #train the model on the training set\n    model = target_models[i]\n    model.fit(X, targets[i])\n\n    #predict \n    y_pred = model.predict(df_sub_test)\n    \n    #add predictions by column\n    submission[targets_names[i]] = y_pred\n    \nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#turn dataframe prediction values into one long series\npredicted = pd.Series([], dtype = 'float')\nfor i in range(submission.shape[0]):\n    row_values = pd.Series(submission.iloc[i].values)\n    predicted = predicted.append(row_values, ignore_index= True)\n\n#add the series to the submission file\ndf_submission_ensemble = df_sample.copy()\ndf_submission_ensemble['Predicted'] = predicted\ndf_submission_ensemble.to_csv('submission_ensemble_linear.csv', index = False)\ndf_submission_ensemble","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}