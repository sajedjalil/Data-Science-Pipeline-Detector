{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Feature exploration and engineering\n\n\nAfter taking a closer look at the targets (see [here](https://www.kaggle.com/miykael/trends-exploration-of-the-targets)), let's also take a closer look at the features.\n\n**First**, lets look at the two feature sets (IC from morphological data) and FNC (from a functional connectivity analysis). In a **second**, step we will take a closer look at the 3-dimension MRI images.\n\n- [1. Load targets](#1.-Load-targets)\n- [2. IC and FNC features](#2.-IC-and-FNC-features)\n    - [2.1. Loading features](#2.1.-Loading-features)\n    - [2.2. Explore features](#2.2.-Explore-features)\n        - [2.2.1. Explore correlations within feature types](#2.2.1.-Explore-correlations-within-feature-types)\n        - [2.2.2. Explore correlations between feature types and targets](#2.2.2.-Explore-correlations-between-feature-types-and-targets)\n        - [2.2.3. Explore pairplots between feature types and targets](#2.2.3.-Explore-pairplots-between-feature-types-and-targets)\n        - [2.2.4. Visualize all values within a feature](#2.2.4.-Visualize-all-values-within-a-feature)\n- [3. Feature engineering using the MRI maps](#3.-Feature-engineering-using-the-MRI-maps)\n    - [3.1 Transformation of mat files to NIfTIs (standard for MRI images)](#3.1-Transformation-of-mat-files-to-NIfTIs-(standard-for-MRI-images))\n    - [3.2. Extraction of within subject correlations](#3.2.-Extraction-of-within-subject-correlations)\n    - [3.3. Extraction of between subject correlations](#3.3.-Extraction-of-between-subject-correlations)\n    - [3.4. Additional feature exploration 1: More MRI quality measurements](#3.4.-Additional-feature-exploration-1:-More-MRI-quality-measurements)\n    - [3.5. Additional feature exploration 2: Find voxels with high correlation to targets](#3.5.-Additional-feature-exploration-2:-Find-voxels-with-high-correlation-to-targets)\n- [4. Dataset merging and outlier removal](#4.-Dataset-merging-and-outlier-removal)\n- [5. PCA and UMap exploration](#5.-PCA-and-UMap-exploration)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom os.path import join as opj\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/trends-assessment-prediction/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Load targets\n\nHowever, before anything else, let's quickly recreate the targets from the [other](https://www.kaggle.com/miykael/trends-exploration-of-the-targets)).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load targets\ntargets = pd.read_csv(opj(path, 'train_scores.csv')).set_index('Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's also create the rotated domain2 targets\nrot = 0.90771256655\n\ndef rotate_origin(x, y, radians):\n    \"\"\"Rotate a point around the origin (0, 0).\"\"\"\n    xx = x * np.cos(radians) + y * np.sin(radians)\n    yy = -x * np.sin(radians) + y * np.cos(radians)\n    return np.array([xx, yy]).T\n\nd2 = rotate_origin(targets.iloc[:, 3].values, targets.iloc[:, 4].values, rot)\ntargets['d21_rot'] = d2[:, 0]\ntargets['d22_rot'] = d2[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's apply the power transformation to make the value distribution gaussian\npow_age = 1.0\npow_d1v1 = 1.5\npow_d1v2 = 1.5\npow_d2v1 = 1.5\npow_d2v2 = 1.5\npow_d21 = 1.5\npow_d22 = 1\npowers = [pow_age, pow_d1v1, pow_d1v2, pow_d2v1, pow_d2v2, pow_d21, pow_d22 ]\n\nfor i, col in enumerate(targets.columns):\n    targets[col] = np.power(targets[col], powers[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# And last but not least, let's scale the target features using ab\nscaler = StandardScaler()\ntargets.iloc[:, :] = scaler.fit_transform(targets)\ntargets.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. IC and FNC features\n\n## 2.1. Loading features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract ID to separate train and test set\ntrain_id = targets.index.values\nsample_submission = pd.read_csv(opj(path, 'sample_submission.csv'))\ntest_id = np.unique(sample_submission.Id.str.split('_', expand=True)[0].astype('int'))\nprint(train_id.shape, test_id.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load ICs from the loading file and separate them into train and test set\ndf_ic = pd.read_csv(opj(path, 'loading.csv'))\nic_train = df_ic[df_ic.Id.isin(train_id)].set_index('Id')\nic_test = df_ic[df_ic.Id.isin(test_id)].set_index('Id')\nprint(ic_train.shape, ic_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load FNCs from file and separate them into train and test set\ndf_fnc = pd.read_csv(opj(path, 'fnc.csv'))\nfnc_train = df_fnc[df_fnc.Id.isin(train_id)].set_index('Id')\nfnc_test = df_fnc[df_fnc.Id.isin(test_id)].set_index('Id')\nprint(fnc_train.shape, fnc_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Explore features\n\n### 2.2.1. Explore correlations within feature types","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_corr_matrix(df_train, df_test, c_restrict=200):\n\n    # Correlation matrix for ICA components\n    fig, ax = plt.subplots(ncols=3, figsize=(20, 10))\n    abs_max = 1.0\n    sns.heatmap(df_train.iloc[:, :c_restrict].corr(), square=True, vmin=-abs_max, vmax=abs_max, cbar=False, ax=ax[0]);\n    sns.heatmap(df_test.iloc[:, :c_restrict].corr(), square=True, vmin=-abs_max, vmax=abs_max, cbar=False, ax=ax[1]);\n    sns.heatmap(df_train.iloc[:, :c_restrict].corr()-df_test.iloc[:, :c_restrict].corr(),\n                square=True, vmin=-0.33, vmax=0.33, cbar=False, ax=ax[2]);\n    ax[0].set_title('Train')\n    ax[1].set_title('Test')\n    ax[2].set_title('Difference (Train - Test)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix for IC features\nplot_corr_matrix(ic_train, ic_test, c_restrict=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix for FNC features\nplot_corr_matrix(fnc_train, fnc_test, c_restrict=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.2. Explore correlations between feature types and targets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_corr_matrix_target(targets, df_train, c_restrict=100):\n\n    # Merge target and feature matrix\n    df_temp = pd.merge(targets.reset_index(), df_train.reset_index())\n    df_temp = df_temp.set_index('Id').iloc[:, :c_restrict]\n    \n    # Correlation matrix for ICA components\n    plt.figure(figsize=(16, 3))\n    sns.heatmap(df_temp.corr().iloc[:7, 7:], square=True,\n                vmin=-0.5, vmax=0.5, cbar=False, cmap='Spectral');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between IC features and targets\nplot_corr_matrix_target(targets, ic_train, c_restrict=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between FNC features and targets\nplot_corr_matrix_target(targets, fnc_train, c_restrict=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation 1\n\nFor both feature types, the correlation with age seems to be the highest. Let's explore this in a bit more detail. What is the highest correlation features can reach with the 5 targets?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show highest correlation with target variables and IC dataset\ndf_corr = pd.concat([np.abs(ic_train.corrwith(targets.iloc[:, i])).sort_values(ascending=False).reset_index(drop=True) for i in range(7)], axis=1)\ndf_corr.columns = targets.columns\ndf_corr.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show highest correlation with target variables and FNC dataset\ndf_corr = pd.concat([np.abs(fnc_train.corrwith(targets.iloc[:, i])).sort_values(ascending=False).reset_index(drop=True) for i in range(7)], axis=1)\ndf_corr.columns = targets.columns\ndf_corr.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Side note: Exploration of correlation after rotation \n\nFor fun (and because I was hoping it could help), I've rotated the two targets in domain2, to see which rotation leads to the highest correlation within the two datasets (IC and FNC).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_rotation_correlations(df_data, targets, ttt=3):\n\n    corr_max = []\n    for r in np.linspace(0, 3.14, 100):\n\n        bla = targets.iloc[:, i].copy()\n        bla.iloc[:] = rotate_origin(targets.iloc[:, ttt].values, targets.iloc[:, ttt+1].values, r)[:, 0]\n        corr_max.append([np.rad2deg(r), df_data.corrwith(bla).sort_values(ascending=False).reset_index(drop=True).abs().max()])\n\n    corr_max1 = np.array(corr_max)\n    plt.figure(figsize=(14, 4))\n    plt.scatter(corr_max1[:, 0], corr_max1[:, 1], s=3);\n\n    corr_max = []\n    for r in np.linspace(0, 3.14, 100):\n\n        bla = targets.iloc[:, i].copy()\n        bla.iloc[:] = rotate_origin(targets.iloc[:, ttt].values, targets.iloc[:, ttt+1].values, r)[:, 1]\n        corr_max.append([np.rad2deg(r), df_data.corrwith(bla).sort_values(ascending=False).reset_index(drop=True).abs().max()])\n\n    corr_max2 = np.array(corr_max)\n    plt.scatter(corr_max2[:, 0], corr_max2[:, 1], s=3);\n\n    best_corr = corr_max1[np.argmin(np.abs(corr_max1[:, 1] - corr_max2[:, 1])), 1]\n    best_rot = corr_max1[np.argmin(np.abs(corr_max1[:, 1] - corr_max2[:, 1])), 0]\n    plt.title('Equal correlation of %.4f\\nat rotation of %.4f radians' % (best_corr, best_rot))\n    plt.legend(['domain2_var1_rot', 'domain2_var2_rot'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_rotation_correlations(ic_train, targets, ttt=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_rotation_correlations(fnc_train, targets, ttt=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not sure what this kind of exploration can bring to the game. My assumption was, if I have equally high correlation on both target features, I might be able to predict the values well and inverse the rotation. But it never lead to anything useful.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.2.3. Explore pairplots between feature types and targets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of columns to investigate\nn_invest = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(ic_train.iloc[:, :n_invest], diag_kind=\"kde\", corner=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(fnc_train.iloc[:, :n_invest], diag_kind=\"kde\", corner=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There seem to be a few interesting correlations between features, but exploring all of them would just take too much time.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.2.4. Visualize all values within a feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_markers(key, df_temp, ncolmarker=5, split_at=5, plot_max=15):\n\n    # Restrict dataframe to first X features\n    df_temp = df_temp.iloc[:, :plot_max]\n\n    # Compute dataset selecters\n    ncolumns = np.arange(df_temp.shape[1])\n    selecter = np.split(ncolumns, ncolumns[::split_at][1:])\n\n    for s in selecter:\n\n        print(key, s)\n        df_temp.iloc[:, s].plot(kind='line',subplots=True, sharex=True, marker='.', lw=0,\n                                ms=10, markeredgecolor='k', markeredgewidth=0.3,\n                     figsize=(5 * ncolmarker, 4 * df_temp.iloc[:, s].shape[1]//ncolmarker), layout=(-1,ncolmarker));\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_markers('Visualization of IC features:', ic_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_markers('Visualization of fNC features:', fnc_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion 1\n\n\nThe datasets seem to contain a few outliers. We will take care of them at the very end.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3. Feature engineering using the MRI maps\n\nGetting the right features from the MRI images is difficult, as the ICA maps themselves are already a derivate from the original fMRI images. Nonetheless, I've explored multiple approaches of which two seemed to be useful.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Note concerning computation time for feature extraction\nExecuting this notebook in it's entirety would take more than 9 hours (due to the feature extraction from the individual MRI maps), I therefore went ahead and included the output files to this kernel. I nonetheless left the code in here, for those who are interested.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# To bypass feature extraction and load precomputed files\nload_pre_computed_files = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Transformation of mat files to NIfTIs (standard for MRI images)\n\nFirst things first, let's transform the data into proper MRI images so that we can profit from the nilearn package.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import h5py\nimport nilearn as nl\nfrom nilearn import image, plotting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load brain mask\nmask = nl.image.load_img(opj(path, 'fMRI_mask.nii'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function was inspired by a fellow kaggler, who I can't find the source anymore\ndef read_img(filename, mask):\n    with h5py.File(filename, 'r') as f:\n        data = np.array(f['SM_feature'], dtype='float32')\n\n    # It's necessary to reorient the axes, since h5py flips axis order\n    data = np.moveaxis(data, [0, 1, 2, 3],\n                             [3, 2, 1, 0])\n\n    img = nl.image.new_img_like(mask, data, affine=mask.affine, copy_header=True)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only convert every n-th subject\nsub_sample = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This `sub_sample` step is needed for this Kaggle kernel as it otherwise would take too long (and take too much space) to transfer all mat files to NIfTIs.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rewrite mat file to compressed NIfTI\ndirectory='fMRI_train'\nif not os.path.exists(directory):\n    os.makedirs(directory)\nfor fname in tqdm(sorted(glob(opj(path, directory, '*.mat')))[::sub_sample]):\n    new_filename = fname.replace('.mat', '.nii.gz')\n    new_filename = new_filename.replace('/kaggle/input/trends-assessment-prediction/', '')\n    read_img(fname, mask).to_filename(new_filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rewrite mat file to compressed NIfTI\ndirectory='fMRI_test'\nif not os.path.exists(directory):\n    os.makedirs(directory)\nfor fname in tqdm(sorted(glob(opj(path, directory, '*.mat')))[::sub_sample]):\n    new_filename = fname.replace('.mat', '.nii.gz')\n    new_filename = new_filename.replace('/kaggle/input/trends-assessment-prediction/', '')\n    read_img(fname, mask).to_filename(new_filename)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Extraction of within subject correlations\n\nMy first idea for feature extraction was to take the 53 maps from each subject and just compute the correlations between all of these maps. Hopefully these kind of features will somehow encode within subject variabilities.\n\nAs an example, for one subject, the output would look something like this:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data from one subject\nimg = image.load_img(sorted(glob('fMRI_train/*.nii.gz'))[0])\n\n# Mask the image to only look at correlation within voxels which have a value\ndata = img.get_fdata()[mask.get_fdata()>0]\n\n# Compute correlation matrix\ncorr_matrix = np.corrcoef(data.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 6))\nsns.heatmap(corr_matrix, square=True, cbar=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the upper triangle is a duplication of the lower one, lets ignore one and lets only keep one part of it:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only keep upper triangular correlation matrix without diagonal\ntriangular_mask = np.ravel(np.triu(np.ones((53, 53)), k=1))>0.5\ncorr_values = np.ravel(corr_matrix)[triangular_mask]\nprint(corr_values.shape, corr_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we know what we want to do, let's repeat that for all NIfTI images in the training and test set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create an output folder to store the new features\ndirectory='datasets'\nif not os.path.exists(directory):\n    os.makedirs(directory)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if load_pre_computed_files:\n\n    # Load precomputed intra subject correlation data for the training set\n    hdf_path = opj('/kaggle', 'input', 'corr-features', 'intra_corr_train.h5')\n    df_corr_intra_train = pd.read_hdf(hdf_path)\n\nelse:\n\n    # Collect results\n    corr_results = {}\n\n    # Collect all train files\n    train_files = sorted(glob('fMRI_train/*.nii.gz'))\n\n    for t in tqdm(train_files):\n\n        try:\n            # Load mean image\n            img = image.load_img(t)\n            data = img.get_fdata()[mask.get_fdata()>0]\n\n            t_id = t.split('/')[1].split('.')[0]\n            corr_results[t_id] = np.ravel(np.corrcoef(data.T))\n\n        except:\n                print(\"Wasn't able to load: \", t)\n\n    df_corr = pd.DataFrame(corr_results).T\n    df_corr.columns = ['c%02d_c%02d' % (i + 1, j + 1)\n                       for i in range(53) for j in range(53)]\n\n    # Only keep upper triangular correlation matrix without diagonal\n    triangular_mask = np.ravel(np.triu(np.ones((53, 53)), k=1))>0.5\n    df_corr_intra_train = df_corr.loc[:, triangular_mask]\n\n    # Save everything in CSV file\n    df_corr_intra_train.to_hdf('datasets/df_corr_intra_train.hdf5', key='df_corr_intra_train', mode='w')\n\n# Plopt head of dataframe\ndf_corr_intra_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if load_pre_computed_files:\n\n    # Load precomputed intra subject correlation data for the training set\n    hdf_path = opj('/kaggle', 'input', 'corr-features', 'intra_corr_test.h5')\n    df_corr_intra_test = pd.read_hdf(hdf_path)\n\nelse:\n\n    # Collect results\n    corr_results = {}\n\n    # Collect all test files\n    test_files = sorted(glob('fMRI_test/*.nii.gz'))\n\n    for t in tqdm(test_files):\n\n        try:\n            # Load mean image\n            img = image.load_img(t)\n            data = img.get_fdata()[mask.get_fdata()>0]\n\n            t_id = t.split('/')[1].split('.')[0]\n            corr_results[t_id] = np.ravel(np.corrcoef(data.T))\n\n        except:\n                print(t)\n\n    df_corr = pd.DataFrame(corr_results).T\n    df_corr.columns = ['c%02d_c%02d' % (i + 1, j + 1)\n                       for i in range(53) for j in range(53)]\n\n    # Only keep upper triangular correlation matrix without diagonal\n    triangular_mask = np.ravel(np.triu(np.ones((53, 53)), k=1))>0.5\n    df_corr_intra_test = df_corr.loc[:, triangular_mask]\n\n    # Save everything in CSV file\n    df_corr_intra_test.to_hdf('datasets/intra_corr_test.hdf5', key='intra_corr_test', mode='w')\n\n# Plopt head of dataframe\ndf_corr_intra_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the intra correlation features are generated, let's take a closer look at them! Just as we did for the IC and FNC features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix for IC features\nplot_corr_matrix(df_corr_intra_train, df_corr_intra_test, c_restrict=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between IC features and targets\nplot_corr_matrix_target(targets, df_corr_intra_train, c_restrict=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show highest correlation with target variables and IC dataset\ndf_corr = pd.concat([np.abs(df_corr_intra_train.corrwith(targets.iloc[:, i])).sort_values(ascending=False).reset_index(drop=True) for i in range(7)], axis=1)\ndf_corr.columns = targets.columns\ndf_corr.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pairplots between intra correlation values and targets\nsns.pairplot(df_corr_intra_train.iloc[:, :n_invest], diag_kind=\"kde\", corner=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of values in dataset\nplot_markers('Visualization of intra correlation features:', df_corr_intra_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation 2\n\nThese intra subject correlation features seem to have high correlation with age, but they also seem to be very outlier ridden. This needs to be cleaned at the end!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3.3. Extraction of between subject correlations\n\nSimilarly to the previous approach, in the \"between subject\" approach, I was creating 53 features per subject which represented the correlation between the ICA component and the average ICA component from all subjects. Hopefully these kind of features will somehow encode between subject variabilities.\n\nTo do this, I first had to compute the average MRI map per component:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nilearn import image, plotting, masking\nfrom nilearn.regions import connected_regions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creates the mean image for a given component\ndef get_mean_component(filenames, comp_ID=0):\n    mean = image.math_img('img * 0', img=mask)\n    for f in filenames:\n        img = image.load_img(f).slicer[..., comp_ID]\n        mean = image.math_img('mean + img', mean=mean, img=img)\n    mean = image.math_img('img / %f' % len(filenames), img=mean)\n    return mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating an output folder to store the average maps\ndirectory='fMRI_maps'\nif not os.path.exists(directory):\n    os.makedirs(directory)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the mean images\nn_maps = 8    # Change this parameter to 53 to get all components\n\nfilenames = sorted(glob('fMRI_train/*.nii.gz'))\nfor idx in tqdm(range(n_maps)):\n    mean = get_mean_component(filenames, comp_ID=idx)\n    mean.to_filename('fMRI_maps/mean_%02d.nii.gz' % (idx + 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's plot the first n-th average maps (threshold at 95% max value)\nfor idx in range(n_maps):\n    img = image.load_img('fMRI_maps/mean_%02d.nii.gz' % (idx + 1))\n    data = img.get_fdata()\n    threshold = np.percentile(data[data!=0], 95)\n    img_thr = image.threshold_img(img, threshold=threshold)\n    img_regions = image.mean_img(connected_regions(img_thr, min_region_size=4000)[0])\n    plotting.plot_glass_brain(img_regions, black_bg=True, display_mode='lyrz',\n                              title='mean_%02d' % (idx + 1))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have these average maps ready, let's go through the training and test set and collect the correlation between the subject map and the average population map.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_brain_values(didx='train'):\n    \"\"\"Helper function to combine all 53 component CSV files into one big one\"\"\"\n\n    # List of file names\n    csv_files = sorted(glob('datasets/inter_corr_*_%s_*.csv' % didx))\n\n    # Create empty ID list\n    merger = pd.read_csv(csv_files[0]).set_index('Id')\n    merger.columns = [c + '_%02d' % 1 for c in merger.columns]\n\n    # Go through files and concatenate them\n    for i, f in enumerate(csv_files[1:]):\n\n        new_df = pd.read_csv(f).set_index('Id')\n        new_df.columns = [c + '_%02d' % (i + 2) for c in new_df.columns]\n\n        merger = pd.merge(merger, new_df, on='Id')\n\n    return merger\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if load_pre_computed_files:\n\n    # Load precomputed inter subject correlation data for the training set\n    hdf_path = opj('/kaggle', 'input', 'corr-features', 'inter_corr_train.h5')\n    df_corr_inter_train = pd.read_hdf(hdf_path)\n\nelse:\n\n    # Collect value metrics from images\n    train_files = sorted(glob('fMRI_train/*.nii.gz'))\n\n    for idx in tqdm(range(n_maps)):\n\n        # Load mean image\n        mean = image.load_img('fMRI_maps/mean_%02d.nii.gz' % (idx + 1))\n        data_mean = mean.get_fdata()[mask.get_fdata()>0]\n\n        # Compute binary mask for region\n        mask_region = data_mean > np.percentile(data_mean, 99)\n\n        # Store results in results file\n        results = {}\n\n        for t in train_files:\n\n            try:\n                # Get file name\n                t_id = t.split('/')[1].split('.')[0]\n\n                # Load current volume\n                img = image.index_img(t, idx)\n\n                # Only extract data values from within mask\n                data_img = img.get_fdata()[mask.get_fdata()>0]\n\n                # Collect correlation coefficient to mean image\n                corr_coef = np.corrcoef(data_img, data_mean)[0, 1]\n\n                results[t_id] = [t_id, corr_coef]\n            except:\n                print(t)\n\n        # Store result in CSV file\n        df_results = pd.DataFrame(results).T\n        df_results.columns = ['Id', 'corr_coef']\n        df_results.to_csv('datasets/inter_corr_train_%02d.csv' % (idx + 1), index=False)\n\n    # Load brain value components\n    df_corr_inter_train = combine_brain_values(didx='train')\n        \ndf_corr_inter_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if load_pre_computed_files:\n\n    # Load precomputed inter subject correlation data for the training set\n    hdf_path = opj('/kaggle', 'input', 'corr-features', 'inter_corr_test.h5')\n    df_corr_inter_test = pd.read_hdf(hdf_path)\n\nelse:\n\n    # Collect results\n    test_files = sorted(glob('fMRI_test/*.nii.gz'))\n\n    for idx in tqdm(range(n_maps)):\n\n        # Load mean image\n        mean = image.load_img('fMRI_maps/mean_%02d.nii.gz' % (idx + 1))\n        data_mean = mean.get_fdata()[mask.get_fdata()>0]\n\n        # Compute binary mask for region\n        mask_region = data_mean > np.percentile(data_mean, 99)\n\n        # Store results in results file\n        results = {}\n\n        for t in test_files:\n\n            try:\n                # Get file name\n                t_id = t.split('/')[1].split('.')[0]\n\n                # Load current volume\n                img = image.index_img(t, idx)\n\n                # Only extract data values from within mask\n                data_img = img.get_fdata()[mask.get_fdata()>0]\n\n                # Collect correlation coefficient to mean image\n                corr_coef = np.corrcoef(data_img, data_mean)[0, 1]\n\n                results[t_id] = [t_id, corr_coef]\n            except:\n                print(t)\n\n        # Store result in CSV file\n        df_results = pd.DataFrame(results).T\n        df_results.columns = ['Id', 'corr_coef']\n        df_results.to_csv('datasets/inter_corr_test_%02d.csv' % (idx + 1), index=False)\n        \n    # Load brain value components\n    df_corr_inter_test = combine_brain_values(didx='test')\n        \ndf_corr_inter_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the inter correlation features are generated, let's take a closer look at them! Just as we did for the IC and FNC features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix for IC features\nplot_corr_matrix(df_corr_inter_train, df_corr_inter_test, c_restrict=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between IC features and targets\nplot_corr_matrix_target(targets, df_corr_inter_train, c_restrict=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show highest correlation with target variables and IC dataset\ndf_corr = pd.concat([np.abs(df_corr_inter_train.corrwith(targets.iloc[:, i])).sort_values(ascending=False).reset_index(drop=True) for i in range(7)], axis=1)\ndf_corr.columns = targets.columns\ndf_corr.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pairplots between intra correlation values and targets\nsns.pairplot(df_corr_inter_train.iloc[:, :n_invest], diag_kind=\"kde\", corner=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of values in dataset\nplot_markers('Visualization of inter correlation features:', df_corr_intra_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation 3\n\nAlso these inter subject correlation features seem to have high correlation with age, and the var1 features. But also here, a lot of outliers are still present.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3.4. Additional feature exploration 1: More MRI quality measurements\n\nThere are a multitude of additional features one can extract from structural and functional MRI images. Luckily, there exists already a great toolbox that can extract them automatically, called [MRIQC](https://mriqc.readthedocs.io/en/latest/measures.html). Even though these metrics are not meant for ICA maps, I've nonetheless investigated a few, such as:\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Collect euclidean distance to mean image\n    euclide_whole = np.linalg.norm(np.subtract(data_img, data_mean))\n    euclide_region = np.linalg.norm(np.subtract(data_img[mask_region], data_mean[mask_region]))","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Collect percentiles from whole image and region\n    perc_to_check_r = [0.1, 1, 5, 50, 95, 99, 99.9]\n    percentiles_whole = [np.percentile(data_img, p) for p in perc_to_check_r]\n    percentiles_region = [np.percentile(data_img[mask_region], p) for p in perc_to_check_r]","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Download GM, WM and CSF probability maps from ICBM 2009c asymmetric template\n    # From: http://www.bic.mni.mcgill.ca/ServicesAtlases/ICBM152NLin2009\n    template_gm = nl.image.load_img('templates/mni_icbm152_nlin_asym_09c/mni_icbm152_gm_tal_nlin_asym_09c.nii')\n    template_gm = image.resample_to_img(template_gm, mask)\n    pve_gm = image.math_img('img * mask', img=template_gm, mask=mask)\n\n    template_wm = nl.image.load_img('templates/mni_icbm152_nlin_asym_09c/mni_icbm152_wm_tal_nlin_asym_09c.nii')\n    template_wm = image.resample_to_img(template_wm, mask)\n    pve_wm = image.math_img('img * mask', img=template_wm, mask=mask)\n\n    template_csf = nl.image.load_img('templates/mni_icbm152_nlin_asym_09c/mni_icbm152_csf_tal_nlin_asym_09c.nii')\n    template_csf = image.resample_to_img(template_csf, mask)\n    pve_csf = image.math_img('img * mask', img=template_csf, mask=mask)\n\n    # Create pve mask\n    pve_concat = image.concat_imgs([pve_gm, pve_wm, pve_csf])\n    pve_mask = image.math_img('np.sum(img, axis=-1)>0.5', img=pve_concat)\n\n    # Find pve binary masks per tissue\n    pve_argmax = image.math_img('np.argmax(img, axis=-1) * mask', img=pve_concat, mask=mask)\n    pve_mask_gm, pve_mask_wm, pve_mask_csf = [image.math_img('(img==%d)*mask' % i, img=pve_argmax, mask=mask) for i in range(3)]\n\n    # Extract volume data from within PVE masks\n    pve_masked_gm_values = img.get_fdata()[pve_mask_gm.get_fdata().astype('bool')]\n    pve_masked_wm_values = img.get_fdata()[pve_mask_wm.get_fdata().astype('bool')]\n    pve_masked_csf_values = img.get_fdata()[pve_mask_csf.get_fdata().astype('bool')]","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Collect percentiles from tissue masks\n    perc_to_check_t = [1, 5, 50, 95, 99]\n    percentiles_gm = [np.percentile(pve_masked_gm_values, p) for p in perc_to_check_t]\n    percentiles_wm = [np.percentile(pve_masked_wm_values, p) for p in perc_to_check_t]\n    percentiles_csf = [np.percentile(pve_masked_csf_values, p) for p in perc_to_check_t]","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Compute smoothness to original image difference\n    smoothness = np.linalg.norm(image.math_img(\n        'img-smooth', img=img, smooth=image.smooth_img(\n            img, 6)).get_fdata()[mask.get_fdata()>0])","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Compute coefficient of joint variation (CJV) within GM and WM\n    cjv = (pve_masked_wm_values.std() + pve_masked_gm_values.std()) / \\\n           np.abs(pve_masked_wm_values.mean() - pve_masked_gm_values.mean())","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Compute signal to noise ratio\n    snr_gm = pve_masked_gm_values.mean() / (pve_masked_gm_values.std() * np.sqrt(len(pve_masked_gm_values)/(len(pve_masked_gm_values)-1)))\n    snr_wm = pve_masked_wm_values.mean() / (pve_masked_wm_values.std() * np.sqrt(len(pve_masked_wm_values)/(len(pve_masked_wm_values)-1)))\n    snr_csf = pve_masked_csf_values.mean() / (pve_masked_csf_values.std() * np.sqrt(len(pve_masked_csf_values)/(len(pve_masked_csf_values)-1)))","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Compute wm2max values\n    muWM = pve_masked_wm_values.mean()\n    wm2max_gm = muWM/np.percentile(pve_masked_gm_values, 99.95)\n    wm2max_wm = muWM/np.percentile(pve_masked_wm_values, 99.95)\n    wm2max_csf = muWM/np.percentile(pve_masked_csf_values, 99.95)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"    # Collect standard deviation from whole image and region\n    whole_std = data_img.std()\n    region_std = data_img[mask_region].std()","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"However, none of them seemed to have helped with the final score.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3.5. Additional feature exploration 2: Find voxels with high correlation to targets\n\nA second approach I've tried out was to look for voxels in the brain which have a high correlation with the target features. Within each of the 53 component and for each target feature, I looked for the top 10 correlating voxels and chose those two that themselves are the least correlated. At the end I've extracted the values within all of these \"top correlating voxels\".\n\nThis approach was very promising and let to incredible improvments in the score (locally) and the dream collapsed when I realized that it was helplessly overfitting and reached horrible scores in the public test set.\n\nHere's nonetheless the code connected to this:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"    # Compute correlation between data and target\n    data_corr = []\n    for v in range(data_set.shape[1]):\n        dfocus = data_set[:, v]\n        dfocus -= np.median(dfocus)\n        chigh, clow = np.percentile(dfocus[dfocus>0], 99), np.percentile(dfocus[dfocus<0], 1)\n        cselecter = np.logical_and(dfocus<chigh, dfocus>clow)\n\n        data_corr.append(np.corrcoef(dfocus[cselecter], target_set[cselecter])[0, 1])\n    data_corr = np.array(data_corr)\n\n    # Find voxels with top target correlation\n    top_sort = np.argsort(np.abs(data_corr))[::-1][:10]\n\n    # Find voxel id of orthogonal (most uncorrelated voxel with top correlated voxel)\n    orth_corr_id = np.argmin(np.abs(np.corrcoef(data_collection[:, top_sort].T)[0, :]))\n\n    # Specify which voxels to look at\n    vox_select = [top_sort[0], top_sort[orth_corr_id]]\n\n    # Add top voxels to voxel_idx\n    voxel_to_extract.append(vox_select)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 4. Dataset merging and outlier removal\n\nNow that the 4 datasets are ready (IC, FNC, inter-corr and intra-corr), let's merge them together and remove some outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create merged dataset\nmerge_train = pd.merge(ic_train.reset_index(), fnc_train.reset_index()).set_index('Id')\nmerge_train = pd.merge(merge_train, df_corr_intra_train, left_index=True, right_index=True)\nmerge_train = pd.merge(merge_train, df_corr_inter_train, left_index=True, right_index=True)\nprint(merge_train.shape)\n\nmerge_test = pd.merge(ic_test.reset_index(), fnc_test.reset_index()).set_index('Id')\nmerge_test = pd.merge(merge_test, df_corr_intra_test, left_index=True, right_index=True)\nmerge_test = pd.merge(merge_test, df_corr_inter_test, left_index=True, right_index=True)\nprint(merge_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now remove samples that have more than x-times an outlier above a z-score of y.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect very frequent extrem values with z-score outliers\ndf_zscore = (merge_train - merge_train.mean())/merge_train.std()\n\nextrem_ids = []\nfor above_std, how_many_times in [[4, 8], [5, 4], [6, 2]]:\n\n    # Detect extrem values\n    extrem_values = np.sum(df_zscore.abs()>=above_std, axis=1)>=how_many_times\n    new_extrems = list(np.array(merge_train[extrem_values].index))\n    extrem_ids.extend(new_extrems)\n    print('Found %d outliers with an absolute z-score above %d, at least %d times.' % (len(new_extrems), above_std, how_many_times))\n\nextrem_ids = np.unique(extrem_ids)\nprint('Total of unique outliers found: %d' % len(extrem_ids))\nextrem_ids","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be sure, let's also look for outliers due to missing values in the features (potentially due to feature extraction).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values discovered within the features.\noutliers = np.ravel([np.array([t for t in train_id if not np.isin(t, ic_train.index.values)])])\noutliers = np.hstack((outliers, np.array([t for t in train_id if not np.isin(t, fnc_train.index.values)])))\noutliers = np.hstack((outliers, np.array([t for t in train_id if not np.isin(t, df_corr_intra_train.index.values)])))\noutliers = np.hstack((outliers, np.array([t for t in train_id if not np.isin(t, df_corr_inter_train.index.values)])))\noutliers = np.hstack((outliers, extrem_ids))\noutliers = np.unique(outliers)\nprint(len(outliers))\noutliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers from features\nic_train = ic_train.drop(outliers, errors='ignore')\nfnc_train = fnc_train.drop(outliers, errors='ignore')\ndf_corr_intra_train = df_corr_intra_train.drop(outliers, errors='ignore')\ndf_corr_inter_train = df_corr_inter_train.drop(outliers, errors='ignore')\nmerge_train = merge_train.drop(outliers, errors='ignore')\nprint(ic_train.shape, fnc_train.shape, df_corr_intra_train.shape, df_corr_inter_train.shape, merge_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers from target\ntargets = targets.drop(outliers, errors='ignore')\ntargets.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perfect, so let's store all of this in easy accessible files:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store datasets as hdf5 files\nmerge_train.to_hdf('datasets/merge_train.h5', key='merge_train', mode='w')\nmerge_test.to_hdf('datasets/merge_test.h5', key='merge_test', mode='w')\ntargets.to_hdf('datasets/targets.h5', key='targets', mode='w')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store scaler in a pickle file\nimport joblib\njoblib.dump(scaler, 'datasets/targets_scaler.pkl');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before quitting, be conscious about space and let's clean our working directory\n!rm -rf fMRI* datasets/intra* datasets/inter*","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. PCA and UMap exploration\n\nAnd just to finish this, let's quickly look at some scree plots from PCA and UMap plots from the four datasets.","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfor key, df_temp in [['ic features', ic_train],\n                     ['fnc features', fnc_train],\n                     ['intra corr features', df_corr_intra_train],\n                     ['inter corr features', df_corr_inter_train],\n                    ]:\n\n    # Explore explained variance on PCA components\n    s = StandardScaler()\n    X_scaled = s.fit_transform(df_temp)\n\n    # Create PCA reduced dataset\n    pca = PCA()\n    pca_train = pca.fit_transform(X_scaled)\n\n    # Explore PCA components\n    pve_cumsum = np.cumsum(pca.explained_variance_ratio_)\n    plt.figure(figsize=(10, 5))\n    plt.title('PCA Explained Variance Ratio: %s' % key)\n    plt.step(range(len(pve_cumsum)), pve_cumsum)\n    plt.show();\n    \n    for thresh in [0.8, 0.9, 0.95, 0.99]:\n        txt = 'Explained Variance for {}: {}% | Components: {}'.format(\n            key, int(thresh * 100),\n            np.argmax(pve_cumsum>=thresh))\n        print(txt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import umap\nfor key, df_temp in [['ic features', ic_train],\n                     ['fnc features', fnc_train],\n                     ['intra corr features', df_corr_intra_train],\n                     ['inter corr features', df_corr_inter_train],\n                     ['merged features', merge_train],\n                    ]:\n\n    # Explore explained variance on PCA components\n    s = StandardScaler()\n    X_scaled = s.fit_transform(df_temp)\n\n    # Create PCA reduced dataset\n    pca = PCA(20)\n    pca_train = pca.fit_transform(X_scaled)\n    \n    # Transform data with UMAP\n    transf = umap.UMAP(n_neighbors=10)\n    X_umap = transf.fit_transform(pca_train)\n\n    # Plot Umap's with target colorization\n    print('Plotting', key)\n    fig, ax = plt.subplots(nrows=1, ncols=7, figsize=(21, 3))\n    for i, c in enumerate(targets.columns):\n        ax[i].scatter(X_umap[:, 0], X_umap[:, 1], s=1, c=targets[c].values, cmap='Spectral')\n        ax[i].set_title(c)\n        ax[i].axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observation 4\n\nHmm... I've never seen these two clusters in the \"intra corr features\". That is new and very interesting. Perhaps somebody will find an explanation for that?","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}