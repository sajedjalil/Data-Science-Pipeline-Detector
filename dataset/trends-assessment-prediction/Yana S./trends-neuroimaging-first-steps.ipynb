{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install --upgrade pip","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install h5py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installing the nilearn\n#!wget https://github.com/Chaogan-Yan/DPABI/raw/master/Templates/ch2better.nii","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import h5py #reading .mat files and weights files .h5\nimport numpy as np # linear algebra\nimport pandas as pd  # data processing\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nilearn as nl #statistical learning on NeuroImaging data\nimport nilearn.plotting as nlplt\nimport nibabel as nib\nfrom nilearn import image\nfrom nilearn import plotting\nfrom nilearn import datasets\nfrom nilearn import surface\n\nimport os \n\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import KFold #consider using GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDir = '/kaggle/input/trends-assessment-prediction/'\nworkDir = '/kaggle/working/'\nos.listdir(dataDir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Functional network connectivity (FNC) \nfnc_df = pd.read_csv(os.path.join(dataDir,'fnc.csv'))\nfnc_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(fnc_df.shape)\n#fnc_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sMRI SBM loadings\nsmri_sbm_df = pd.read_csv(os.path.join(dataDir, 'loading.csv'))\nsmri_sbm_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#smri_sbm_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(smri_sbm_df.shape)\n#smri_sbm_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#target features\nlabels_df = pd.read_csv(os.path.join(dataDir, 'train_scores.csv'))\nlabels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Nan values in domain1_var1: ', labels_df.domain1_var1.isnull().sum())\nprint('Nan values in domain1_var2: ', labels_df.domain1_var2.isnull().sum())\nprint('Nan values in domain2_var1: ', labels_df.domain2_var1.isnull().sum())\nprint('Nan values in domain2_var2: ', labels_df.domain2_var2.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TODO: make it interactive\nfig, ax = plt.subplots(1, 4, figsize=(25, 5))\n\n# sns.distplot(labels_df['age'], ax = ax[0],\n#                   kde_kws = {\"color\": \"green\", \"lw\": 3},\n#                   hist_kws = {\"histtype\": \"bar\", \"linewidth\": 3,\n#                             \"alpha\": 1, \"color\": \"orange\"})\n\nsns.distplot(labels_df['domain1_var1'], ax = ax[0],\n                  kde_kws = {\"color\": \"green\", \"lw\": 3},\n                  hist_kws = {\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"orange\"})\n\nsns.distplot(labels_df['domain1_var2'], ax = ax[1],\n                  kde_kws = {\"color\": \"green\", \"lw\": 3},\n                  hist_kws = {\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"orange\"})\n\nsns.distplot(labels_df['domain2_var1'], ax = ax[2],\n                  kde_kws = {\"color\": \"green\", \"lw\": 3},\n                  hist_kws = {\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"orange\"})\n\nsns.distplot(labels_df['domain2_var2'], ax = ax[3],\n                  kde_kws = {\"color\": \"green\", \"lw\": 3},\n                  hist_kws = {\"histtype\": \"bar\", \"linewidth\": 3,\n                            \"alpha\": 1, \"color\": \"orange\"}) \n\nfig.suptitle('Labels Visualization', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_bar(df, feature, title='', show_percent = False, size=2):\n    f, ax = plt.subplots(1,1, figsize=(4 * size,3 * size))\n    total = float(len(df))\n    sns.barplot(np.round(df[feature].value_counts().index).astype(int),\n                df[feature].value_counts().values, \n                palette='cubehelix')\n\n    plt.title(title)\n    \n    if show_percent:\n        for p in ax.patches:\n            height = p.get_height()\n            ax.text(p.get_x() + p.get_width()/2.,\n                    height + 3,\n                    '{:1.2f}%'.format(100 * height / total),\n                    ha = \"center\", rotation = 45) \n    plt.xlabel(feature, fontsize=12, )\n    plt.ylabel('Number of Occurrences', fontsize=12)\n    plt.xticks(rotation = -45)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar(labels_df, 'age', 'Age Label Count and % Plot', show_percent = True, size = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_data =  labels_df.drop(['Id'], axis = 1)\n\nplt.figure(figsize = (15, 15))\nsns.heatmap(temp_data.corr(), annot = True, cmap='Paired')\nplt.yticks(rotation=0) \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnc_features, loading_features = list(fnc_df.columns[1:]), list(smri_sbm_df.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_df['is_train'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = fnc_df.merge(smri_sbm_df, on='Id')\ndf = df.merge(labels_df, how='left', on='Id')\n\ndf.loc[df['is_train'].isnull(), 'is_train'] = 0\ndf['is_train'] = df['is_train'].astype(np.uint8)\n#TODO: split to train-test based on last column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = df[df['is_train'] == 1]\ntest_data = df[df['is_train'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## About FNC Features\n*Functional Network Connectivity (FNC) are correlation values that summarize the overall connection between independent brain maps over time. Therefore, the FNC feature gives a picture of the connectivity pattern over time between independent networks (or brain maps). The provided FNC information was obtained from functional magnetic resonance imaging (fMRI) from a set of schizophrenic patients and healthy controls at rest, using group independent component analysis (GICA). The GICA decomposition of the fMRI data resulted in a set of brain maps, and corresponding timecourses. These timecourses indicated the activity level of the corresponding brain map at each point in time. The FNC feature are the correlations between these timecourses. In a way, FNC indicates a subject's overall level of 'synchronicity' between brain areas. Because this information is derived from functional MRI scans, FNCs are considered a functional modality feature (i.e., they describe patterns of the brain function).*\n\n## About SBM Loadings\n*Source-Based Morphometry (SBM) loadings correspond to the weights of brain maps obtained from the application of independent component analysis (ICA) on the gray-matter concentration maps of all subjects. Gray-matter corresponds to the outer-sheet of the brain; it is the brain region in which much of the brain signal processing actually occurs. In a way, the concentration of gray-matter is indicative of the \"computational power\" available in a certain region of the brain. Processing gray-matter concentration maps with ICA yields independent brain maps whose expression levels (i.e., loadings) vary across subjects. Simply put, a near-zero loading for a given ICA-derived brain map indicates that the brain regions outlined in that map are lowly present in the subject (i.e., the gray-matter concentration in those regions are very low in that subject). Because this information is derived from structural MRI scans, SBM loadings are considered a structural modality feature (i.e., they describe patterns of the brain structure).*\n\nhttps://www.kaggle.com/anshumoudgil/brain-s-network-activation-via-eda/comments\nThe paper above gives information about some basic definitions such as FNC, ICM, etc.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### TODO: Add more explanations for the features\n### TODO: Fill NaN-s appropriately\nShould I drop the missing values, fill them with a test statistic or use ML algorithm(knn, other)\n### TODO: Plot distributions\n### TODO: Plot correlations\n### TODO: Show more interesting scans. Check this out: https://www.kaggle.com/soham1024/visualization-using-nilearn\n### TODO: Try basic NN \n### TODO: Run this on local machine and install RAPIDs to check how fast it works on GPU (if possible to load 160GB+ data to local)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### What is .nii file format?\nThe [.nii] file type is primarily associated with NIfTI-1 Data Format by Neuroimaging Informatics Technology Initiative. \nNIfTI-1 is adapted from the widely used ANALYZE 7.5 file format. NIfTI-1 uses the empty space in the ANALYZE 7.5 header to add several new features.\n\nCredit: https://www.kaggle.com/saife245/neuroimaging-in-depth-understanding-eda-model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fmri_mask = os.path.join(dataDir, 'fMRI_mask.nii')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#smri = 'ch2better.nii'\n\nmask_img = nl.image.load_img(fmri_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_subject(filename, mask_img):\n    subject_data = None\n    with h5py.File(filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n    # It's necessary to reorient the axes, since h5py flips axis order\n    subject_data = np.moveaxis(subject_data, [0,1,2,3], [3,2,1,0])\n    subject_img = nl.image.new_img_like(mask_img, subject_data, affine=mask_img.affine, copy_header=True)\n\n    return subject_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = random.choices(os.listdir('../input/trends-assessment-prediction/fMRI_train/'), k = 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting 4D probabilistic atlas maps...\nProbabilistic atlasing is a research strategy whose goal is to generate anatomical templates that retain quantitative information on inter-subject variations in brain architecture","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for file in files:\n    subject = os.path.join('../input/trends-assessment-prediction/fMRI_train/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    nlplt.plot_prob_atlas(subject_img, view_type='filled_contours', #bg_img=smri\n                          draw_cross=False, title='All %d spatial maps' % num_components, threshold='auto')\n    print(\"-\"*50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting a statistical map...\nStatistical parametric mapping or SPM is a statistical technique for examining differences in brain activity recorded during functional neuroimaging experiments.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"files = random.choices(os.listdir('../input/trends-assessment-prediction/fMRI_train/'), k = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for file in files:\n    subject = os.path.join('../input/trends-assessment-prediction/fMRI_train/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)\n    plotting.plot_stat_map(first_rsn)\n    print(\"-\"*50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = random.choices(os.listdir('../input/trends-assessment-prediction/fMRI_train/'), k = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for file in files:\n    subject = os.path.join('../input/trends-assessment-prediction/fMRI_train/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)\n    for img in image.iter_img(rsn):\n        # img is now an in-memory 3D img\n        plotting.plot_stat_map(img, threshold=3)\n    print(\"-\"*50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Glass brain visualization...\nGlass Brain is a tool that maps the electrical activity of your brain in realtime.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for file in files:\n    subject = os.path.join('../input/trends-assessment-prediction/fMRI_train/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)     \n    plotting.plot_glass_brain(first_rsn,display_mode='lyrz')\n    print(\"-\"*50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Base model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"%%time\n\nNUM_FOLDS = 7\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\n\nfeatures = loading_features + fnc_features\n\noveral_score = 0\n\n#The weights are [.3, .175, .175, .175, .175] corresponding to features [age, domain1_var1, domain1_var2, domain2_var1, domain2_var2].\nfor target, c, w in [(\"age\", 100, 0.3), (\"domain1_var1\", 10, 0.175), (\"domain1_var2\", 10, 0.175), (\"domain2_var1\", 10, 0.175), (\"domain2_var2\", 10, 0.175)]:    \n    y_oof = np.zeros(train_data.shape[0])\n    y_test = np.zeros((test_data.shape[0], NUM_FOLDS))\n    \n    #consider gridsearchcv for doing the following :)\n    for f, (train_ind, val_ind) in enumerate(kf.split(train_data, train_data)):\n        train_df, val_df = train_data.iloc[train_ind], train_data.iloc[val_ind]\n        train_df = train_df[train_df[target].notnull()]\n\n        model = SVR(C=c, cache_size=3000.0)\n        model.fit(train_df[features], train_df[target])\n\n        y_oof[val_ind] = model.predict(val_df[features])\n        y_test[:, f] = model.predict(test_data[features])\n        \n    train_data[\"pred_{}\".format(target)] = y_oof\n    test_data[target] = y_test.mean(axis=1)\n    \n    score = metric(train_data[train_data[target].notnull()][target].values, train_data[train_data[target].notnull()][\"pred_{}\".format(target)].values)\n    overal_score += w * score\n    print(target, np.round(score, 4))\n    print()\n    \nprint(\"Overal score:\", np.round(overal_score, 4))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"sub_df = pd.melt(test_data[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\") \nassert sub_df.shape[0] == test_data.shape[0]*5\nsub_df.head(10)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"sub_df.to_csv(\"submission.csv\", index = False)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}