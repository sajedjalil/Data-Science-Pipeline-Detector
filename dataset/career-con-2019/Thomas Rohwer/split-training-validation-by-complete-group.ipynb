{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a simple kernel, that splits the training data set into a real training set and a validation data set, so that no groups are split between them. This is useful to get realistic validation measurements, because the data within a group is correlated."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain_x = pd.read_csv('../input/X_train.csv')\ntrain_y = pd.read_csv('../input/y_train.csv')\n\nnum_test=500\n\ndef prepare_data(t):\n    def f(d):\n        d=d.sort_values(by=['measurement_number'])\n        return pd.DataFrame({\n         'lx':[ d['linear_acceleration_X'].values ],\n         'ly':[ d['linear_acceleration_Y'].values ],\n         'lz':[ d['linear_acceleration_Z'].values ],\n         'ax':[ d['angular_velocity_X'].values ],\n         'ay':[ d['angular_velocity_Y'].values ],\n         'az':[ d['angular_velocity_Z'].values ],\n         'ox':[ d['orientation_X'].values ],\n         'oy':[ d['orientation_Y'].values ],\n         'oz':[ d['orientation_Z'].values ],\n         'ow':[ d['orientation_W'].values ],\n        })\n\n    t= t.groupby('series_id').apply(f)\n    return t\n\n\ndef split_shuffle_groups(t):\n    t= t.copy()\n\n    # select randomly some groups (should be weighted by # of samples)\n\n    aggcol='surface' # arbitrary; just to get size\n    gstat= t.groupby('group_id')[aggcol].agg(np.size)\n    gstat= gstat.reset_index()\n\n    import random\n    random.shuffle\n\n    groups = list(zip(gstat['group_id'].values, gstat[aggcol].values))\n    random.shuffle(groups)\n    \n    test_groups= set()\n    c=0\n    for gid,len in groups:\n        if c>=num_test: break\n        c+=len\n        test_groups.add(gid)\n    print(\"test groups:\", test_groups)\n\n    ctest = [ i for i,gid in enumerate(t['group_id']) if (gid in test_groups) ]\n    ctrain = [ i for i,gid in enumerate(t['group_id']) if not (gid in test_groups) ]\n\n    random.shuffle(ctrain)\n    random.shuffle(ctest)\n\n    return t.iloc[ctrain], t.iloc[ctest]\n\n\ntrain= prepare_data(train_x)\n\n# merge\ntrain=pd.merge(train,train_y[['series_id','group_id','surface']],on='series_id')\n\ntrain_part_df, validation_part_df= split_shuffle_groups(train)\n\nprint(\"training part of training data set:\", train_part_df.describe())\nprint(\"validation part of training data set:\",validation_part_df.describe())\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}