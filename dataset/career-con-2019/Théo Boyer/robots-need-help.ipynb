{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"<h1><center><font size=\"6\">Robots need help!</font></center></h1>\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/df/RobotsMODO.jpg\" width=\"400\"></img>\n\n<br>\n\n# <a id='0'>Content</a>\n\n- <a href='#1'>Introduction</a>  \n- <a href='#2'>Prepare the data analysis</a>  \n- <a href='#3'>Data exploration</a>   \n - <a href='#31'>Check the data</a>   \n - <a href='#32'>Distribution of target feature `surface`</a>   \n - <a href='#33'>Density plots of features</a>   \n- <a href='#4'>Feature engineering</a>\n- <a href='#5'>Model</a>\n- <a href='#6'>Submission</a>  \n- <a href='#7'>References</a>"},{"metadata":{"_uuid":"9784cc8ed4bceb3bb0ee60778bab3b3355518f37"},"cell_type":"markdown","source":"# <a id='1'>Introduction</a>  \n\n## Competition\nIn this competition, we willl help robots recognize the floor surface theyâ€™re standing on. The floor could be of various types, like carpet, tiles, concrete.\n\n## Data\nThe data provided by the organizers  is collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises.  \n\n## Kernel\nIn this Kernel we perform EDA on the data, explore with feature engineering and build a predictive model."},{"metadata":{"_uuid":"abdb16570ed4a120ab7d9822c12fd3cf5c2339da"},"cell_type":"markdown","source":"# <a id='2'>Prepare for data analysis</a>  \n\n\n## Load packages\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import gc\nimport os\nimport logging\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error, confusion_matrix\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1baf9418913d861c75106802ec96ec409ed9c7d"},"cell_type":"markdown","source":"## Load data   \n\nLet's check what data files are available."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"660a0cee494565f5cabec59168e932d43ca037f1"},"cell_type":"code","source":"IS_LOCAL = False\nif(IS_LOCAL):\n    PATH=\"../input/careercon/\"\nelse:\n    PATH=\"../input/\"\nos.listdir(PATH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d87a4413ad47c4f1eebba4275f99a731e1ae191"},"cell_type":"markdown","source":"Let's load the data."},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":true,"_uuid":"ddbbd73634939a6633428bed86290aece4f2b04c"},"cell_type":"code","source":"%%time\nX_train = pd.read_csv(os.path.join(PATH, 'X_train.csv'))\nX_test = pd.read_csv(os.path.join(PATH, 'X_test.csv'))\ny_train = pd.read_csv(os.path.join(PATH, 'y_train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"70f03694af7770fc55246d4fbf133b824369ce50"},"cell_type":"code","source":"print(\"Train X: {}\\nTrain y: {}\\nTest X: {}\".format(X_train.shape, y_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b37dc2ee7a3054c9f7a9d6d120a087208027532"},"cell_type":"markdown","source":"We can observe that train data and labels have different number of rows."},{"metadata":{"_uuid":"d8b1e19622d059e03ff7250d4f76198c254936ec"},"cell_type":"markdown","source":"# <a id='3'>Data exploration</a>  \n\n## <a id='31'>Check the data</a>  \n\nLet's check the train and test set."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"aebb41b2152f76491b80b70e2c838d433993d242"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66c5e3028a2a8160529a165a8908901920d504e9","_kg_hide-input":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"10a2f9b4e0034866ec9eb1fe5f8f74cf3d6fe6f4"},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ad951cc65c7cafcf1a5cb987775c691116e5354"},"cell_type":"markdown","source":"X_train and X_test datasets have the following entries:  \n\n* series and measurements identifiers: **row_id**, **series_id**, **measurement_number**: these identify uniquely a series and measurement; there are 3809 series, each with max 127 measurements;  \n* measurement orientations: **orientation_X**, **orientation_Y**, **orientation_Z**, **orientation_W**;   \n* angular velocities: **angular_velocity_X**, **angular_velocity_Y**, **angular_velocity_Z**;\n* linear accelerations: **linear_acceleration_X**, **linear_acceleration_Y**, **linear_acceleration_Z**.\n\ny_train has the following columns:  \n\n* **series_id** - this corresponds to the series in train data;  \n* **group_id**;  \n* **surface** - this is the surface type that need to be predicted.\n\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"10f26f3760a7d5b15b7587edb452a5d71539e3aa"},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"5db2dadb11bfa6f0e130ae566099c7ca8a2baf74"},"cell_type":"code","source":"missing_data(X_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f73a4fe3ded19c5096a0d532d96e48dd73917b62"},"cell_type":"code","source":"missing_data(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c4f949ea6d589c07ae2ffc46f5f16e77a4cd493"},"cell_type":"markdown","source":"There are no missing values in train and test data."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"d352ded04b435b79969f654835e53cc843949f30"},"cell_type":"code","source":"missing_data(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06ae1576a757f0e80397df975c5a246140faaed5","_kg_hide-input":true},"cell_type":"markdown","source":"Also, train labels has no missing data."},{"metadata":{"trusted":true,"_uuid":"f415baee23e3f48ec22811f0d9a5266f3693c664","_kg_hide-input":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b49d454bf0edba43d2618091260d37101a90857","_kg_hide-input":true},"cell_type":"code","source":"X_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78747516fd066a70f0f4db78f9543d08b93334d1","_kg_hide-input":true},"cell_type":"code","source":"y_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f62c1341e7d69716f0a599c80ead90d41e0f7473"},"cell_type":"markdown","source":"There is the same number of series in X_train and y_train, numbered from 0 to 3809 (total 3810). Each series have 128 measurements.   \nEach series in train dataset is part of a group (numbered from 0 to 72, 72 being the half of 128).  \nThe number of rows in X_train and X_test differs with 6 x 128, 128 being the number of measurements for each group.  "},{"metadata":{"_uuid":"a449515fe43d68dbbcf1d70cec8d663ddf7d5dfb"},"cell_type":"markdown","source":"## <a id='32'>Distribution of target feature - surface</a>  \n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"8d0db47428faaa50c9a7a6002dd7e08ca953ca57"},"cell_type":"code","source":"f, ax = plt.subplots(1,1, figsize=(16,4))\ng = sns.countplot(y_train['surface'])\ng.set_title(\"Number of labels for each class\")\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42ed8502739e99aaa472c3c36ba70ef2fcb95ebc"},"cell_type":"markdown","source":"## <a id='32'>Density plots of features</a>  \n\nLet's show now the density plot of variables in train and test dataset. \n\nWe represent with different colors the distribution for values with different values of **surface**."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2e0f6a8ca0e6f1c64b24f5d4b9e033516e59d8ec"},"cell_type":"code","source":"def plot_feature_distribution(df1, df2, label1, label2, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(2,5,figsize=(16,8))\n\n    for feature in features:\n        i += 1\n        plt.subplot(2,5,i)\n        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f1260bd87f03984fe5573323837a9f9961a8d25","_kg_hide-input":true},"cell_type":"code","source":"features = X_train.columns.values[3:]\nplot_feature_distribution(X_train, X_test, 'train', 'test', features)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"85d698f6a2898d01f51717be90e4d467eed6ce64"},"cell_type":"code","source":"def plot_feature_class_distribution(classes,tt, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(5,2,figsize=(16,24))\n\n    for feature in features:\n        i += 1\n        plt.subplot(5,2,i)\n        for clas in classes:\n            ttc = tt[tt['surface']==clas]\n            sns.kdeplot(ttc[feature], bw=0.5,label=clas)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"479d3b7b152a5dae5a07fba203381aa43d973a97"},"cell_type":"code","source":"classes = (y_train['surface'].value_counts()).index\ntt = X_train.merge(y_train, on='series_id', how='inner')\nplot_feature_class_distribution(classes, tt, features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"394b783f6bbfcaf18a43c41faf11f7de121ba2eb"},"cell_type":"markdown","source":"# <a id='4'>Feature engineering</a>  \n"},{"metadata":{"_uuid":"a9ab8347dd0fc263d6a81e2316b0939bfa25f2da"},"cell_type":"markdown","source":"This section is heavily borrowing from: https://www.kaggle.com/vanshjatana/help-humanity-by-helping-robots Kernel."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"6735b8e29eeeb48a635a907355fca4f91b34d95d"},"cell_type":"code","source":"# https://stackoverflow.com/questions/53033620/how-to-convert-euler-angles-to-quaternions-and-get-the-same-euler-angles-back-fr?rq=1\ndef quaternion_to_euler(x, y, z, w):\n    import math\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z\n\ndef perform_feature_engineering(actual):\n    new = pd.DataFrame()\n    actual['total_angular_velocity'] = (actual['angular_velocity_X'] ** 2 + actual['angular_velocity_Y'] ** 2 + actual['angular_velocity_Z'] ** 2) ** 0.5\n    actual['total_linear_acceleration'] = (actual['linear_acceleration_X'] ** 2 + actual['linear_acceleration_Y'] ** 2 + actual['linear_acceleration_Z'] ** 2) ** 0.5\n    \n    actual['acc_vs_vel'] = actual['total_linear_acceleration'] / actual['total_angular_velocity']\n    \n    x, y, z, w = actual['orientation_X'].tolist(), actual['orientation_Y'].tolist(), actual['orientation_Z'].tolist(), actual['orientation_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    actual['euler_x'] = nx\n    actual['euler_y'] = ny\n    actual['euler_z'] = nz\n    \n    actual['total_angle'] = (actual['euler_x'] ** 2 + actual['euler_y'] ** 2 + actual['euler_z'] ** 2) ** 5\n    actual['angle_vs_acc'] = actual['total_angle'] / actual['total_linear_acceleration']\n    actual['angle_vs_vel'] = actual['total_angle'] / actual['total_angular_velocity']\n    \n    def mean_change_of_abs_change(x):\n        return np.mean(np.diff(np.abs(np.diff(x))))\n\n    def mean_abs_change(x):\n        return np.mean(np.abs(np.diff(x)))\n    \n    for col in actual.columns:\n        if col in ['row_id', 'series_id', 'measurement_number']:\n            continue\n        new[col + '_mean'] = actual.groupby(['series_id'])[col].mean()\n        new[col + '_min'] = actual.groupby(['series_id'])[col].min()\n        new[col + '_max'] = actual.groupby(['series_id'])[col].max()\n        new[col + '_std'] = actual.groupby(['series_id'])[col].std()\n        new[col + '_max_to_min'] = new[col + '_max'] / new[col + '_min']\n        \n        # Change. 1st order.\n        new[col + '_mean_abs_change'] = actual.groupby('series_id')[col].apply(mean_abs_change)\n        \n        # Change of Change. 2nd order.\n        new[col + '_mean_change_of_abs_change'] = actual.groupby('series_id')[col].apply(mean_change_of_abs_change)\n        \n        new[col + '_abs_max'] = actual.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n        new[col + '_abs_min'] = actual.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n\n    return new","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"310409206394429b14bf60e7bd759234bd2d81c5"},"cell_type":"code","source":"%%time\nX_train = perform_feature_engineering(X_train)\nX_test = perform_feature_engineering(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"eef14b6a9b05bdeca2e8dd2f6bca98e7915ecfdd"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0103613591cb8146a2c20fc0471c8da5d37cd82b"},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1de959929ee5a7f643ba02c00390cf8428a0ad90"},"cell_type":"markdown","source":"# <a id='5'>Model</a>  \n"},{"metadata":{"trusted":true,"_uuid":"3c0a07575a08df25acf3c2d648f2c15dcbc1de5f"},"cell_type":"code","source":"le = LabelEncoder()\ny_train['surface'] = le.fit_transform(y_train['surface'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"67b8bfb18f66307f15270b8fa7fcf0827f3ebe17"},"cell_type":"code","source":"X_train.fillna(0, inplace = True)\nX_train.replace(-np.inf, 0, inplace = True)\nX_train.replace(np.inf, 0, inplace = True)\nX_test.fillna(0, inplace = True)\nX_test.replace(-np.inf, 0, inplace = True)\nX_test.replace(np.inf, 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"613d0b00834f0ed248556b858b4a4d793b8e8180"},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d869738e4f09cab1f6f2176f8de89bc252a7ad3"},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n#               'max_features': max_features,\n               'max_depth': max_depth,\n#               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n#               'bootstrap': bootstrap\n              }\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75149993be4a4290eac94a8aa66f9fce63044e84"},"cell_type":"code","source":"params = {'n_estimators': 800, 'min_samples_leaf': 1, 'max_depth': 20}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3b31725e5e353783a5625542936c00175059405"},"cell_type":"markdown","source":"We use a Random Forest Classifier model."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"fedc8cba976a3640613080a5e379033090c6d4b3","scrolled":true},"cell_type":"code","source":"sub_preds_rf = np.zeros((X_test.shape[0], 9))\noof_preds_rf = np.zeros((X_train.shape[0]))\nscore = 0\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train['surface'])):\n    clf =  RandomForestClassifier(**params)\n    #rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n    # Fit the random search model\n    #rf_random.fit(X_train.iloc[trn_idx], y_train['surface'][trn_idx])\n    #print(rf_random.best_params_)\n    #clf = rf_random.best_estimator_\n    clf.fit(X_train.iloc[trn_idx], y_train['surface'][trn_idx])\n    oof_preds_rf[val_idx] = clf.predict(X_train.iloc[val_idx])\n    sub_preds_rf += clf.predict_proba(X_test) / folds.n_splits\n    score += clf.score(X_train.iloc[val_idx], y_train['surface'][val_idx])\n    print('Fold: {} score: {}'.format(fold_,clf.score(X_train.iloc[val_idx], y_train['surface'][val_idx])))\nprint('Avg Accuracy', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6849fb0f877d73e91820a46b732c35c4d81f8b63"},"cell_type":"markdown","source":"# <a id='6'>Submission</a>  \n\nWe submit the solution."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"410056706ec800a78050d6850c2620a96ae3a70c"},"cell_type":"code","source":"submission = pd.read_csv(os.path.join(PATH,'sample_submission.csv'))\nsubmission['surface'] = le.inverse_transform(sub_preds_rf.argmax(axis=1))\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7664ec331050ab5aefd2cf26c898f7c9c6c7e352"},"cell_type":"markdown","source":"# <a id='7'>References</a>    \n\n[1] https://www.kaggle.com/vanshjatana/help-humanity-by-helping-robots-4e306b  \n[2] https://www.kaggle.com/artgor/where-do-the-robots-drive  \n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}