{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# installing efficientnet\n!pip install efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.layers import Dense , Activation , GlobalAveragePooling2D , Dropout ,Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing import image\nimport efficientnet.tfkeras as efn\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold ,KFold\nfrom PIL import Image\nimport io\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now first lets create a function to read TFRecords","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_DIMS = 64\nCHANNELS = 3\nBATCH_SIZE = 32\nSEED = 42\nSPLITS = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_TFR_data_labelled(sample):\n    features = {\n      'image': tf.io.FixedLenFeature([] , tf.string , default_value = ''),\n      'image_name': tf.io.FixedLenFeature([] , tf.string , default_value=''),\n      'patient_id': tf.io.FixedLenFeature([] , tf.int64 , default_value=0),\n      'sex': tf.io.FixedLenFeature([] , tf.int64 , default_value=0),\n      'age_approx': tf.io.FixedLenFeature([] , tf.int64 , default_value=0),\n      'anatom_site_general_challenge':tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 ),\n      'diagnosis': tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 ),\n      'target': tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 ),\n      'width': tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 ),\n      'height': tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 )\n    }\n    \n    p = tf.io.parse_single_example(sample , features)\n    \n    img = p['image']\n    target = p['target']\n    \n    return img , target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_img(img , IMG_DIMS):\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img , [IMG_DIMS , IMG_DIMS])\n    img = img/255\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = {\n  'image': tf.io.FixedLenFeature([] , tf.string , default_value = ''),\n  'image_name': tf.io.FixedLenFeature([] , tf.string , default_value=''),\n  'patient_id': tf.io.FixedLenFeature([] , tf.int64 , default_value=0),\n  'sex': tf.io.FixedLenFeature([] , tf.int64 , default_value=0),\n  'age_approx': tf.io.FixedLenFeature([] , tf.int64 , default_value=0),\n  'anatom_site_general_challenge':tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 ),\n  'diagnosis': tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 ),\n  'target': tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 ),\n  'width': tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 ),\n  'height': tf.io.FixedLenFeature([] ,tf.int64 , default_value=0 )\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('melanoma-256x256')\ntrain_datasets = tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n\nprint(len(train_datasets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parsed_TFR_unlabelled(sample):\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n        'image_name': tf.io.FixedLenFeature([], tf.string, default_value=''),\n        'target': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n    }\n    p = tf.io.parse_single_example(sample , feature_description)\n    img = p['image']\n    \n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_ds(files , shuffle=True , labelled=True , repeat=True , img_dims=64 , batch_size=32):\n    ds = tf.data.TFRecordDataset(files , num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    if labelled:\n        ds = ds.map(parse_TFR_data_labelled , num_parallel_calls=AUTO)\n        ds = ds.map(lambda img , label:(decode_img(img , img_dims) , label) , num_parallel_calls=AUTO)\n    else:\n        ds = ds.map(parsed_TFR_unlabelled , num_parallel_calls=AUTO)\n        ds = ds.map(lambda img : decode_img(img, img_dims) , num_parallel_calls=AUTO)\n    \n    ds = ds.batch(batch_size*REPLICAS)\n    ds = ds.prefetch(AUTO)\n    return ds\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" the function **_get_ds,** **lr_schedule** and **count_data_items** is copied from this [notebook](https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords) published by chris deotte you can go and check out his notebook\n learning rate scheduler is very important because if you will start training an efficient net or MobileNetV2 without a learning rate schedule you will face the problem of exploding gradient your loss will go nan and accuracy zero. so while traing a pre trained model especially like efficient net we need to initialize leraning rate with a very small value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#lr_schedule\ndef lr_schedule(batch_size= 16):\n    lr_start = 0.000005\n    lr_max = 0.00000125 * REPLICAS * batch_size\n    lr_min = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep = 0\n    lr_decay = 0.8\n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n\n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n         for filename in filenames]\n    return np.sum(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(input_dim , efnt=True , efnt_n=0):\n    efnt_b=[efn.EfficientNetB0 , efn.EfficientNetB1 , efn.EfficientNetB2 , efn.EfficientNetB3]\n    if efnt:\n        base = efnt_b[efnt_n](input_shape = (input_dim , input_dim , 3), weights = 'imagenet' , include_top=False)\n    else:\n        base = tf.keras.applications.MobileNetV2(input_shape=(input_dim , input_dim,3),\n                                               include_top=False,\n                                               weights='imagenet')\n    for layers in base.layers[15:]:\n        layers.trainable = True\n    in_put = Input(shape = (input_dim , input_dim , 3))\n    x = base(in_put)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(64 , activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(32 , activation='relu')(x)\n    x = Dense(1 , activation='sigmoid')(x)\n    model = Model(inputs=in_put , outputs=x)\n    model.compile(optimizer='adam' ,loss='binary_crossentropy' , metrics=['Accuracy' , 'AUC'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets initialize our TPU","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TPU = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(TPU)\ntf.tpu.experimental.initialize_tpu_system(TPU)\nstrategy = tf.distribute.experimental.TPUStrategy(TPU)\n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Efficientnet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=SPLITS)\nkf = KFold(n_splits=SPLITS)\noof_pred =[]\noof_train =[]\noof_val = []\noof_hist = []\nf = 0\nfor idxT , idxV in kf.split(train_datasets):\n    #print(idxT , idxV)\n    train = []\n    val = []\n    for idx in idxT:\n        train.append(train_datasets[idx])\n    for idx in idxV:\n        val.append(train_datasets[idx])\n        \n    with strategy.scope():\n        lr_callback = lr_schedule(BATCH_SIZE)\n        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = 'model_weights_fold_'+str(f)+'.hdf5' , \n                                                     save_best_only=True , verbose=1)\n    \n        es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc' , verbose=1, \n                                                   patience=5 , mode='max' ,\n                                                   restore_best_weights=True)\n\n        model = create_model(IMG_DIMS)\n        history = model.fit(_get_ds(train), \n                            epochs=20 ,\n                            steps_per_epoch= count_data_items(train)/BATCH_SIZE//REPLICAS, \n                            validation_data = _get_ds(val ,repeat=False),\n                            callbacks = [lr_callback ,cp_callback , es_callback],\n                            verbose=0)\n\n        oof_hist.append(history)\n        x_val = _get_ds(val , labelled=False , repeat=False)\n        oof_val.append(x_val)\n        preds = model.predict(x_val)\n        oof_pred.append(preds)\n    \n    f +=1\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now lets analyze our models of each fold","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\ni = 1\nfor p in oof_hist:\n    fig.add_subplot(2,2,i)\n    plt.plot(p.history['loss'])\n    plt.plot(p.history['val_loss'])\n    plt.title('fold '+str(i)+ ' LOSS')\n    i +=1\n\nplt.legend(labels= ['loss' ,'val_loss'])\nfig.tight_layout(pad=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\ni = 1\nfor p in oof_hist:\n    fig.add_subplot(2,2,i)\n    plt.plot(p.history['auc'])\n    plt.plot(p.history['val_auc'])\n    plt.title('fold '+str(i) + ' AUC')\n    i +=1\n\nplt.legend(labels= ['auc' ,'val_auc'])\nfig.tight_layout(pad=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\ni = 1\nfor p in oof_hist:\n    fig.add_subplot(2,2,i)\n    plt.plot(p.history['accuracy'])\n    plt.plot(p.history['val_accuracy'])\n    plt.title('fold '+str(i) + ' ACCURACY')\n    i +=1\n\nplt.legend(labels= ['accuracy' ,'val_accuracy'])\nfig.tight_layout(pad=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so we can that all our models have an identical performance thus this means that our data is well normalized and don't have any outliers\n\nnow lets make a prediction and check hoe it performs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets modify our parse function to also save the image name\ndef parsed_TFR_unlabelled_2(sample):\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n        'image_name': tf.io.FixedLenFeature([], tf.string, default_value=''),\n        'target': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n    }\n    p = tf.io.parse_single_example(sample , feature_description)\n    img = p['image']\n    name = p['image_name']\n    return name , img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\ntrain_datasets = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\n\nprint(len(train_datasets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data= tf.data.TFRecordDataset(train_datasets)\ntest_data = test_data.map(parsed_TFR_unlabelled_2 , num_parallel_calls=AUTO)\ntest_data = test_data.map(lambda name , img: (name , decode_img(img , 64)))\n\nsub_df = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_dict = {}\nfor p in test_data:\n    temp = {p[0].numpy().decode() : p[1].numpy()}\n    x_dict.update(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\nfor i in sub_df['image_name']:\n    test.append(x_dict[i])\n    del(x_dict[i])\n    \ntest = np.array(test)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('test.npy' , test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df['target'] = preds\nsub_df.set_index('image_name' , inplace=True)\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training MobileNET","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"the training process with mobile net is same we just need to turn the efnt arguent of our create model function to false in order to use the MobileNetV2 we will use the KFold cross validation again","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=SPLITS)\noof_pred2 =[]\noof_train2 =[]\noof_val2 = []\noof_hist2 = []\nf = 0\nfor idxT , idxV in kf.split(train_datasets):\n    #print(idxT , idxV)\n    train = []\n    val = []\n    for idx in idxT:\n        train.append(train_datasets[idx])\n    for idx in idxV:\n        val.append(train_datasets[idx])\n        \n    with strategy.scope():\n        lr_callback = lr_schedule(BATCH_SIZE)\n        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = 'model2_weights_fold_'+str(f)+'.hdf5' , \n                                                     save_best_only=True , verbose=1)\n    \n        es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc' , verbose=1, \n                                                   patience=5 , mode='max' ,\n                                                   restore_best_weights=True)\n\n        model2 = create_model(IMG_DIMS ,efnt=False)\n        history = model2.fit(_get_ds(train), \n                            epochs=20 ,\n                            steps_per_epoch= count_data_items(train)/BATCH_SIZE//REPLICAS, \n                            validation_data = _get_ds(val ,repeat=False),\n                            callbacks = [lr_callback ,cp_callback , es_callback],\n                            verbose=0)\n\n        oof_hist2.append(history)\n        x_val = _get_ds(val , labelled=False , repeat=False)\n        oof_val2.append( _get_ds(val ,repeat=False))\n        preds = model.predict(x_val)\n        oof_pred2.append(preds)\n    \n    f +=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\ni = 1\nfor p in oof_hist2:\n    fig.add_subplot(2,2,i)\n    plt.plot(p.history['loss'])\n    plt.plot(p.history['val_loss'])\n    plt.title('fold '+str(i)+ ' LOSS')\n    i +=1\n\nplt.legend(labels= ['loss' ,'val_loss'])\nfig.tight_layout(pad=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\ni = 1\nfor p in oof_hist2:\n    fig.add_subplot(2,2,i)\n    plt.plot(p.history['auc'])\n    plt.plot(p.history['val_auc'])\n    plt.title('fold '+str(i) + ' AUC')\n    i +=1\n\nplt.legend(labels= ['auc' ,'val_auc'])\nfig.tight_layout(pad=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\ni = 1\nfor p in oof_hist2:\n    fig.add_subplot(2,2,i)\n    plt.plot(p.history['accuracy'])\n    plt.plot(p.history['val_accuracy'])\n    plt.title('fold '+str(i) + ' ACCURACY')\n    i +=1\n\nplt.legend(labels= ['accuracy' ,'val_accuracy'])\nfig.tight_layout(pad=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2 = model2.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df['target'] = preds2\n# sub_df.set_index('image_name' , inplace=True)\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('submission2.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now with the auc being zero for MobileNetV2 we can see that it is not suitable for this task probably because of the dropouts so we will stick with the eifficent net \n\n# Image Augumentation\nnow to improve the accuracy with the efficientent we can use image augumentation to make the familiar to the diverse data and help it generalise well on the training data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"a = tf.data.TFRecordDataset(train_datasets[:2])\na = a.map(parse_TFR_data_labelled)\na = a.map(lambda img,label:(decode_img(img ,64) , label))\nfig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0].numpy()\n    l = p[1].numpy()\n    plt.imshow(img)\n    plt.title('Normal Image '+str(i)+'\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now lets see different types of augumentation\n\n1. Random Brightness","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tf.image.random_brightness(img , 0.3)\n    plt.imshow(img.numpy())\n    plt.title('Random Brightness '+ str(i)+'\\n Label = '+str(l))\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Random Contrast","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tf.image.random_contrast(img , 1 ,4)\n    plt.imshow(img.numpy())\n    plt.title('Random Contrast ' + str(i) + '\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Grayscale -- note that converting the images to grayscale will reshape the images from (x,x,3) to (x,x,1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tf.image.rgb_to_grayscale(img)\n    plt.imshow(img.numpy().reshape(64,64) , cmap='gray')\n    plt.title('GrayScale ' + str(i)+ '\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Random Saturation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tf.image.random_saturation(img , 1,3)\n    plt.imshow(img.numpy())\n    plt.title('flip left right ' + str(i) + '\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Gaussian Blur --\n    * 5a. Gaussian blur on rgb","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tfa.image.gaussian_filter2d(img , sigma=1)\n    plt.imshow(img.numpy())\n    plt.title('Gaussian Blur - RGB ' + str(i) + '\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*      5b. Gaussian bloor on grayscale","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tf.image.rgb_to_grayscale(img)\n    img = tfa.image.gaussian_filter2d(img, sigma=1)\n    plt.imshow(img.numpy().reshape(64,64) , cmap='gray')\n    plt.title('Gaussian Blur - GrayScale ' + str(i)+ '\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so these are some of the augumentations we can use there are other augumentation too like\n* Flip\n* Rotation\n* scaling\n* crop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# FLIP\nfig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tf.image.random_flip_left_right(img)\n    plt.imshow(img.numpy())\n    plt.title('flip left right ' + str(i) + '\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rotation Random\nfig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tf.image.rot90(img)\n    plt.imshow(img.numpy())\n    plt.title('flip left right ' + str(i) + '\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# central crop\nfig = plt.figure(figsize=(12,10))\ni = 1\nfor p in a.take(6):\n    fig.add_subplot(2,3,i)\n    img = p[0]\n    l = p[1].numpy()\n    img = tf.image.central_crop(img , 0.7)\n    img = tf.image.resize(img , (64, 64))\n    plt.imshow(img.numpy())\n    plt.title('flip left right ' + str(i) + '\\n Label = '+str(l))\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}