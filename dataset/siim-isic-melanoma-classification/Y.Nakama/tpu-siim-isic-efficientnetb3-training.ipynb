{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this kernel\n- TPU tensorflow EfficientNetB3 starter code\n- 4 folds\n- References are below\n- https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n- https://www.kaggle.com/xhlulu/alaska2-efficientnet-on-tpus ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport math\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\nimport efficientnet.tfkeras as efn\n\nfrom kaggle_datasets import KaggleDatasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TPU Strategy and other configs ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n\n# Configuration\nDEBUG = False\nN_FOLD = 4\nEPOCHS = 1 if DEBUG else 7\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [1024, 1024]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Data & Loader","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec')\nTRAINING_FILENAMES_LIST = [TRAINING_FILENAMES[:4], TRAINING_FILENAMES[4:8], TRAINING_FILENAMES[8:12], TRAINING_FILENAMES[12:]]\nprint(TRAINING_FILENAMES_LIST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['target'], tf.int32)\n    return image, label\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['image_name']\n    return image, idnum\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    return dataset\n\ndef data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    return image, label\n\ndef get_training_dataset(train_files):\n    dataset = load_dataset(train_files, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_validation_dataset(valid_files, ordered=False):\n    dataset = load_dataset(valid_files, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    #dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(test_files, ordered=False):\n    dataset = load_dataset(test_files, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Model into TPU","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    \n    with strategy.scope():\n        model = tf.keras.Sequential([\n            efn.EfficientNetB3(\n                input_shape=(*IMAGE_SIZE, 3),\n                weights='imagenet',\n                include_top=False\n            ),\n            L.GlobalAveragePooling2D(),\n            L.Dense(1, activation='sigmoid')\n        ])\n\n    model.compile(\n        optimizer='adam',\n        loss = 'binary_crossentropy',\n        #metrics=['accuracy'],\n        metrics=[tf.keras.metrics.AUC()],\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(fold, debug=False):\n    if debug:\n        valid = TRAINING_FILENAMES_LIST[fold][0:1]\n        train = TRAINING_FILENAMES_LIST[fold-1][0:1]\n    else:\n        valid = TRAINING_FILENAMES_LIST[fold]\n        train = sum([TRAINING_FILENAMES_LIST[i] for i in range(N_FOLD) if i not in [fold]], [])\n    num_train = count_data_items(train)\n    steps_per_epoch = num_train // BATCH_SIZE\n    model = get_model()\n    saving_callback = tf.keras.callbacks.ModelCheckpoint(f\"fold{fold}_model.h5\", verbose=1, \n                                                         save_weights_only=True, save_best_only=True)\n    history = model.fit(\n            get_training_dataset(train), \n            steps_per_epoch=steps_per_epoch,\n            epochs=EPOCHS,\n            callbacks=[saving_callback],\n            validation_data=get_validation_dataset(valid),\n            verbose=1,\n    )\n    #model.save(f\"fold{fold}_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold in range(N_FOLD):\n    train_model(fold, debug=DEBUG)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    \n    with strategy.scope():\n        model = tf.keras.Sequential([\n            efn.EfficientNetB3(\n                input_shape=(*IMAGE_SIZE, 3),\n                weights=None,\n                include_top=False\n            ),\n            L.GlobalAveragePooling2D(),\n            L.Dense(1, activation='sigmoid')\n        ])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\noof_df = pd.DataFrame()\n\ntk0 = tqdm(range(N_FOLD), total=N_FOLD)\n\nfor fold in tk0:\n    if DEBUG:\n        test_files = TRAINING_FILENAMES_LIST[fold-1][0:1]\n    else:\n        test_files = TRAINING_FILENAMES_LIST[fold]\n    num_test = count_data_items(test_files)\n    test_ds = get_test_dataset(test_files, ordered=True)\n    test_images_ds = test_ds.map(lambda image, idnum: image)\n    model = get_model()\n    model.load_weights(f\"fold{fold}_model.h5\")\n    probabilities = model.predict(test_images_ds)\n    test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n    test_ids = next(iter(test_ids_ds.batch(num_test))).numpy().astype('U')\n    _oof_df = pd.DataFrame({'image_name': test_ids, 'oof': np.concatenate(probabilities)})\n    oof_df = pd.concat([oof_df, _oof_df])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntrain_df = train_df.merge(oof_df, on='image_name')\ntrain_df.to_csv('oof_df.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nscore = roc_auc_score(train_df['target'].values, train_df['oof'].values)\nprint(f'CV AUC: {score}')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}