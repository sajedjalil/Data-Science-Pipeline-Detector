{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{},"source":"# Features importances with Random Forest classifier\n\nThe aim of this notebook is to get the importance of each features. To do this I used features_importances \nfrom random_forest classifier in scikit learn\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test = pd.read_csv('../input/test.csv')\ntrain = pd.read_csv('../input/train.csv')\ntrain.columns.values"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[['Product_Info_1','Product_Info_2', 'Product_Info_3','Product_Info_4',\n       'Product_Info_5','Product_Info_6','Product_Info_7' ]].head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[['Employment_Info_1','Employment_Info_2', \n       'Employment_Info_3', 'Employment_Info_4',\n       'Employment_Info_5', 'Employment_Info_6']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[['InsuredInfo_1',\n       'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5',\n       'InsuredInfo_6', 'InsuredInfo_7']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[['Insurance_History_1',\n       'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4',\n       'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8',\n       'Insurance_History_9']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[['Family_Hist_1', 'Family_Hist_2',\n       'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[['Medical_History_1', 'Medical_History_2', 'Medical_History_3',\n       'Medical_History_4', 'Medical_History_5', 'Medical_History_6',\n       'Medical_History_7', 'Medical_History_8', 'Medical_History_9',\n       'Medical_History_10', 'Medical_History_11', 'Medical_History_12',\n       'Medical_History_13', 'Medical_History_14', 'Medical_History_15',\n       'Medical_History_16', 'Medical_History_17', 'Medical_History_18',\n       'Medical_History_19', 'Medical_History_20', 'Medical_History_21',\n       'Medical_History_22', 'Medical_History_23', 'Medical_History_24',\n       'Medical_History_25', 'Medical_History_26', 'Medical_History_27',\n       'Medical_History_28', 'Medical_History_29', 'Medical_History_30',\n       'Medical_History_31', 'Medical_History_32', 'Medical_History_33',\n       'Medical_History_34', 'Medical_History_35', 'Medical_History_36',\n       'Medical_History_37', 'Medical_History_38', 'Medical_History_39',\n       'Medical_History_40', 'Medical_History_41']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.preprocessing import Imputer"},{"cell_type":"markdown","metadata":{},"source":"# Parse data \n\n* Separation of Product_Info_2 \n* BMI times INs_Age\n* Count NA by row\n* Count medical keywords by row \n* Impute missing values with mean"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def parse_data(X):\n    \n    X['BMI_Ins_age'] = X.BMI*X.Ins_Age\n    \n    X['Product_Info2_let'] =X.Product_Info_2.str[0]\n    X['Product_Info2_num'] = X.Product_Info_2.str[1]\n    \n    X['Product_Info2_let'] = pd.factorize(X.Product_Info2_let)[0]+1\n    X['Product_Info_2'] = pd.factorize(X.Product_Info_2)[0]+1\n    \n    X['Medical_KW'] = X[['Medical_Keyword_1',\n       'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4',\n       'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7',\n       'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10',\n       'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13',\n       'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16',\n       'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19',\n       'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22',\n       'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25',\n       'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28',\n       'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31',\n       'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34',\n       'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37',\n       'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40',\n       'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43',\n       'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46',\n       'Medical_Keyword_47', 'Medical_Keyword_48']].sum(axis = 1)\n    \n    X['Na_Num'] = X.isnull().sum(axis = 1)\n\n\n\n    \n    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n    col = X.columns.values    \n    X = pd.DataFrame(imp.fit_transform(X))\n    X.columns = col\n    \n\n    return X"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test = pd.read_csv('../input/test.csv')\ntrain = pd.read_csv('../input/train.csv')\nX = parse_data(train)\ny = X.Response"},{"cell_type":"markdown","metadata":{},"source":"# Random Forest model \n\nTrain a random forest model with \"n_estimators=300\" and other parameters by default"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"columns_to_drop = ['Id', 'Response']\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nrf = ExtraTreesClassifier(n_estimators=300,\n                              random_state=0)\nrf.fit(X.drop(columns_to_drop, axis = 1), y)"},{"cell_type":"markdown","metadata":{},"source":"# Display the 20th first features by importances"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"importances =pd.DataFrame({'features' :X.drop(columns_to_drop, axis = 1).columns,\n                           'importances' : rf.feature_importances_})\nimportances.sort_values(by = 'importances', ascending = False).head(20)"},{"cell_type":"markdown","metadata":{},"source":"#Display the 20th last features"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"importances.sort_values(by = 'importances', ascending = False).tail(20)\n"},{"cell_type":"markdown","metadata":{},"source":"#Plot the features importances "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#plot importances\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimportances.sort_values(by = 'importances', ascending = True, inplace = True)\nval = importances.importances*100    # the bar lengths\npos = np.arange(importances.shape[0])+.5 \n\nplt.figure(figsize = (13,28))\nplt.barh(pos,val, align='center')\nplt.yticks(pos, importances.features.values)\nplt.xlabel('Importances')\nplt.title('Features importances')\nplt.grid(True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#cumsum of importances\nimportances.sort_values(by = 'importances', ascending = False, inplace = True)\n\nimportances['cumul'] = np.cumsum(importances.importances, axis = 0)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"importances.sort_values(by = 'importances', ascending = True, inplace = True)\n\nval = importances.cumul*100    # the bar lengths\npos = np.arange(importances.shape[0])+.5 \n\nplt.figure(figsize = (13,28))\nplt.barh(pos,val, align='center')\nplt.yticks(pos, importances.features.values)\nplt.xlabel('Importances')\nplt.title('Features importances')\nplt.grid(True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"for i in np.arange(50,100,5):\n    print('Nombre de variables pour avoir {0} % d\\' \\\"importance\\\" des variables  : {1} sur {2}'.format(i,importances.features[importances.cumul<i/100].shape[0],\n                                                                                                    importances.features.shape[0]))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Variables ro remove to get X % of importances \n\nX = 90\n\nimportances.features[importances.cumul>X/100].values"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}