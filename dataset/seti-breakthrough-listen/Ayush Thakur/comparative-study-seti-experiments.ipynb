{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This kernel is created to run few experiments of my own to answer two very important questions:\n\n* **What's the best way to use the cadence snippet?** Should we use it **channel-wise or spatially?** **Should we use all 6 spectrograms or just the ones with aliens' signal?**\n\n* **Mixup** is giving a significant performance boost. But what's the **gain in percentage**? How much are the models trained with Mixup dependent on random initialization?\n\nYou can find the detailed summary in this discussion post [here](https://www.kaggle.com/c/seti-breakthrough-listen/discussion/245152). For an interactive summary check out this [W&B report](http://wandb.me/seti-img-mixup-exp). ","metadata":{}},{"cell_type":"markdown","source":"# üß∞ Imports and Setups","metadata":{}},{"cell_type":"code","source":"!pip install -q --upgrade wandb\nimport wandb\nprint(wandb.__version__)\nfrom wandb.keras import WandbCallback\n\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T06:21:50.125249Z","iopub.execute_input":"2021-06-14T06:21:50.125646Z","iopub.status.idle":"2021-06-14T06:22:19.135551Z","shell.execute_reply.started":"2021-06-14T06:21:50.125565Z","shell.execute_reply":"2021-06-14T06:22:19.134786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import mixed_precision\n\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\n\nimport os\nimport gc\nimport json\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom functools import partial\n\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-06-14T06:22:21.208022Z","iopub.execute_input":"2021-06-14T06:22:21.208414Z","iopub.status.idle":"2021-06-14T06:22:22.656569Z","shell.execute_reply.started":"2021-06-14T06:22:21.20838Z","shell.execute_reply":"2021-06-14T06:22:22.655676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T06:22:22.658012Z","iopub.execute_input":"2021-06-14T06:22:22.658331Z","iopub.status.idle":"2021-06-14T06:22:24.292277Z","shell.execute_reply.started":"2021-06-14T06:22:22.658294Z","shell.execute_reply":"2021-06-14T06:22:24.291249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìÄ Hyperparameters","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = '../input/seti-breakthrough-listen/train/'\nAUTOTUNE = tf.data.AUTOTUNE\n\nCONFIG = dict (\n    img_width = 224,\n    img_height = 224,\n    batch_size = 32,\n    epochs = 100,\n    learning_rate = 1e-3,\n    competition = 'seti',\n    _wandb_kernel = 'ayut',\n    architecture = \"CNN\",\n    infra = \"Kaggle\",\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T06:22:30.378115Z","iopub.execute_input":"2021-06-14T06:22:30.378434Z","iopub.status.idle":"2021-06-14T06:22:30.383425Z","shell.execute_reply.started":"2021-06-14T06:22:30.378403Z","shell.execute_reply":"2021-06-14T06:22:30.382391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üî® Build Input Pipeline","metadata":{}},{"cell_type":"code","source":"# Note: Please run this cell once and run all your experiments using the train_df and valid_df.\ndf = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ndf = df.sample(5000).reset_index(drop=True)\nprint(f'Number of train images: {len(df)}')\ndf['img_path'] = df['id'].apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')\n\ntrain_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['target'].values)\nprint(len(train_df), len(valid_df))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:02:35.659058Z","iopub.execute_input":"2021-06-13T06:02:35.659568Z","iopub.status.idle":"2021-06-13T06:02:35.730703Z","shell.execute_reply.started":"2021-06-13T06:02:35.659512Z","shell.execute_reply":"2021-06-13T06:02:35.72997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = compute_class_weight('balanced', \n                                    classes=np.unique(train_df['target'].values),\n                                    y=train_df['target'].values)\n\nclass_weights_dict = {key: val for key, val in zip(np.unique(train_df['target'].values), class_weights)}\nclass_weights_dict                                                         ","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:02:36.957481Z","iopub.execute_input":"2021-06-13T06:02:36.957821Z","iopub.status.idle":"2021-06-13T06:02:36.969808Z","shell.execute_reply.started":"2021-06-13T06:02:36.957777Z","shell.execute_reply":"2021-06-13T06:02:36.968708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_npy(path, mode):\n    # load npy data\n    data = np.load(path.numpy()).astype(np.float32)\n    \n    if mode==0:\n        # channel wise full stack\n        data = np.dstack((data[0], data[1], data[2], data[3], data[4], data[5])) \n        return data # (273, 256, 6)\n    \n    elif mode==1:\n        # channel wise target stack\n        data = np.dstack((data[0], data[2], data[4]))\n        return data # (273, 256, 3)\n    \n    elif mode==2:\n        # Spatially stack spectrograms\n        data = np.vstack(data).transpose((1, 0))\n        data = tf.expand_dims(data, -1)\n        return data # (256, 1638, 1)\n    \n    elif mode==3:\n        # Spatially stack target spectrograms\n        data = np.vstack((data[0], data[2], data[4])).transpose((1, 0))\n        data = tf.expand_dims(data, -1)\n        return data # (256, 819, 1)\n    \n    elif mode==4:\n        # Spatially stack target and normalize\n        data = np.vstack((data[0], data[2], data[4])).transpose((1, 0))\n        data = ((data - np.mean(data, axis=0)) / np.std(data, axis=0))\n        data = tf.expand_dims(data, -1)\n        return data # (256, 819, 1)\n    \n    elif mode==5:\n        # Spatially stack target spectrograms, clip and then normalize\n        data = np.vstack((data[0], data[2], data[4])).transpose((1, 0))\n        data = ((np.clip(data, -1, 3) + 1) / 4 * 255).astype(np.uint8)\n        data = tf.image.convert_image_dtype(data, tf.float32)\n        data = tf.expand_dims(data, -1)\n        return data # (256, 819, 1)\n    \n@tf.function\ndef load_resize_spec(df_dict, mode):\n    # Load image\n    [image,] = tf.py_function(load_npy, [df_dict['img_path'], mode], [tf.float32])\n    \n    if mode==0:\n        image.set_shape((273, 256, 6))\n    elif mode==1:\n        image.set_shape((273, 256, 3))\n    elif mode==2:\n        image.set_shape((256, 1638, 1))\n    elif mode==3 or mode==4 or mode==5:\n        image.set_shape((256, 819, 1))\n    \n    # Resize image\n    image = tf.image.resize(image, (CONFIG['img_height'], CONFIG['img_width'])) # (224, 224, channel)\n    # Simple augmentations\n    image = tf.image.random_flip_left_right(image)\n    \n    # Parse label\n    label = df_dict['target']\n    label = tf.one_hot(label, depth=2)\n    \n    return image, label\n\n# Mixup\n@tf.function\ndef mixup(a, b, alpha=1.0):\n    # unpack (image, label) pairs\n    (image1, label1), (image2, label2) = a, b\n\n    # define beta distribution\n    dist = tfd.Beta([alpha], [alpha])\n    # sample from this distribution\n    l = dist.sample(1)[0][0]\n\n    # mixup augmentation\n    img = l*image1+(1-l)*image2\n    lab = l*label1+(1-l)*label2\n\n    return img, lab","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:02:38.90757Z","iopub.execute_input":"2021-06-13T06:02:38.907901Z","iopub.status.idle":"2021-06-13T06:02:38.925735Z","shell.execute_reply.started":"2021-06-13T06:02:38.907869Z","shell.execute_reply":"2021-06-13T06:02:38.924836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ndef get_dataloaders(train_df, valid_df, mode):\n    # Train Loader\n    trainloader = tf.data.Dataset.from_tensor_slices(dict(train_df))\n    # Valid Loader\n    validloader = tf.data.Dataset.from_tensor_slices(dict(valid_df))\n\n    trainloader = (\n        trainloader\n        .shuffle(1024)\n        .map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n\n    validloader = (\n        validloader\n        .map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n    \n    return trainloader, validloader\n\n\ndef get_mixup_dataloaders(train_df, valid_df, mode, alpha=1.0):\n    # Train Loader\n    trainloader1 = tf.data.Dataset.from_tensor_slices(dict(train_df)).shuffle(1024).map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n    trainloader2 = tf.data.Dataset.from_tensor_slices(dict(train_df)).shuffle(1024).map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n\n    trainloader = tf.data.Dataset.zip((trainloader1, trainloader2))\n\n    # Valid Loader\n    validloader = tf.data.Dataset.from_tensor_slices(dict(valid_df))\n\n    trainloader = (\n        trainloader\n        .shuffle(1024)\n        .map(partial(mixup, alpha=alpha), num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n\n    validloader = (\n        validloader\n        .map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n    \n    return trainloader, validloader","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:02:41.355056Z","iopub.execute_input":"2021-06-13T06:02:41.355402Z","iopub.status.idle":"2021-06-13T06:02:41.365236Z","shell.execute_reply.started":"2021-06-13T06:02:41.355372Z","shell.execute_reply":"2021-06-13T06:02:41.364062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sanity check\n# Prepare dataloaders\ntrainloader, validloader = get_mixup_dataloaders(train_df, valid_df, 5)\nimgs, labels = next(iter(trainloader))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:08:33.793822Z","iopub.execute_input":"2021-06-13T04:08:33.794151Z","iopub.status.idle":"2021-06-13T04:08:42.744417Z","shell.execute_reply.started":"2021-06-13T04:08:33.794123Z","shell.execute_reply":"2021-06-13T04:08:42.743602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üê§ Model","metadata":{}},{"cell_type":"code","source":"def get_model(mode):\n    base_model = tf.keras.applications.EfficientNetB0(input_shape=(CONFIG['img_height'], CONFIG['img_width'], 3), include_top=False, weights='imagenet')\n    base_model.trainabe = True\n\n    if mode==0:\n        inputs = layers.Input((CONFIG['img_height'], CONFIG['img_width'], 6))\n        x = layers.Conv2D(3, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(inputs)\n    elif mode==1:\n        inputs = layers.Input((CONFIG['img_height'], CONFIG['img_width'], 3))\n        x = inputs\n    else:\n        inputs = layers.Input((CONFIG['img_height'], CONFIG['img_width'], 1))\n        x = layers.Conv2D(3, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(inputs)\n        \n    x = base_model(x, training=True)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.5)(x)\n    \n    outputs = layers.Dense(2)(x)\n    outputs = layers.Activation('sigmoid', dtype='float32', name='predictions')(outputs)\n    \n    return models.Model(inputs, outputs)\n\ntf.keras.backend.clear_session() \nmodel = get_model(mode=1)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:02:49.7311Z","iopub.execute_input":"2021-06-13T06:02:49.731442Z","iopub.status.idle":"2021-06-13T06:02:52.328251Z","shell.execute_reply.started":"2021-06-13T06:02:49.731412Z","shell.execute_reply":"2021-06-13T06:02:52.327305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Callbacks","metadata":{}},{"cell_type":"code","source":"# Callbacks\nearlystopper = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=5, verbose=0, mode='min',\n    restore_best_weights=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:02:59.667533Z","iopub.execute_input":"2021-06-13T06:02:59.66788Z","iopub.status.idle":"2021-06-13T06:02:59.674717Z","shell.execute_reply.started":"2021-06-13T06:02:59.667849Z","shell.execute_reply":"2021-06-13T06:02:59.67332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiments to Run: Select the experiment mode","metadata":{}},{"cell_type":"code","source":"MODES = {\n    'channel-wise-full': 0,\n    'channel-wise-target': 1, \n    'spatial-full': 2,\n    'spatial-target': 3, \n    'spatial-target-normalize': 4,\n    'spatial-target-clip': 5\n}\nMODES_ID_TO_EXP = {val: key for key, val in MODES.items()}\n\nUSE_MIXUP = True\nmode = MODES['spatial-target-clip'] # Please change the key here\nexp_name = MODES_ID_TO_EXP[mode]\n\nprint(f'Running the experiment : {exp_name} and with/without mixup: {USE_MIXUP}')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:03:02.605775Z","iopub.execute_input":"2021-06-13T06:03:02.606111Z","iopub.status.idle":"2021-06-13T06:03:02.612523Z","shell.execute_reply.started":"2021-06-13T06:03:02.606079Z","shell.execute_reply":"2021-06-13T06:03:02.611568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üöÑ Train to find best image arrangement\n\nYou can find the detailed summary in this discussion post [here](https://www.kaggle.com/c/seti-breakthrough-listen/discussion/245152). For an interactive summary check out this [W&B report](http://wandb.me/seti-img-mixup-exp). ","metadata":{}},{"cell_type":"code","source":"# Prepare dataloaders\nif USE_MIXUP:\n    trainloader, validloader = get_dataloaders(train_df, valid_df, mode=mode)\nelse:\n    trainloader, validloader = get_mixup_dataloaders(train_df, valid_df, mode=mode)\n\nSEEDS = [42, 64, 524]\n\nfor i in range(3):\n    # Initialize model\n    tf.keras.backend.clear_session()\n    tf.random.set_seed(SEEDS[i])\n    model = get_model(mode=mode)\n\n    # Compile model\n    optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['learning_rate'])\n    model.compile(optimizer, \n                  loss='binary_crossentropy',\n                  metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n\n    # Update CONFIG dict with the name of the model.\n    CONFIG['seed'] = SEEDS[i]\n    CONFIG['model_name'] = 'EfficientNetB0'\n    CONFIG['group'] = exp_name\n    print('Training configuration: ', CONFIG)\n\n    # Initialize W&B run\n    run = wandb.init(project='kaggle-seti-exp', \n                     config=CONFIG,\n                     group=CONFIG['group'], \n                     job_type='train')\n\n    # Train\n    _ = model.fit(trainloader, \n                  epochs=CONFIG['epochs'],\n                  validation_data=validloader,\n                  class_weight=class_weights_dict,\n                  callbacks=[WandbCallback(),\n                             earlystopper])\n\n    # Evaluate\n    loss, auc = model.evaluate(validloader)\n    wandb.log({'Val AUC-ROC': auc})\n\n    # Close W&B run\n    run.finish()\n\n    del model\n    _ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [Check out the dasbhboard here $\\rightarrow$](https://wandb.ai/ayush-thakur/kaggle-seti-exp?workspace=user-ayush-thakur) \n\n## [Experiment summary report here $\\rightarrow$](http://wandb.me/seti-img-mixup-exp)\n\n![img](https://i.imgur.com/InH4hEi.gif)","metadata":{}},{"cell_type":"markdown","source":"# Find the best alpha value for Mixup\n\nThe mixup augmentation mixes two images pixel-wise and mixes their labels as well. This is done by weighted element-wise sum where the weight is sampled from the [Beta Distribution](https://en.wikipedia.org/wiki/Beta_distribution). \n\nThe Beta distribution depends on two parameters - `alpha` and `beta`. In the context of Mixup, the `alpha` and `beta` takes the same value and the value is less or equal to 1.0. You can play with this interactive chart [here](https://keisan.casio.com/exec/system/1180573226).\n\nIn this experiment we will use different values of alpha (beta) and find out:\n* if there is any effect of alpha on this dataset, <br>\n* if yes, what's the optimal value to use. ","metadata":{}},{"cell_type":"code","source":"ALPHAS = [0.2, 0.4, 0.6, 0.8, 1.0]\nVAL_AUC_ROC = []\nSEEDS = [42, 64, 524]\n\nfor alpha in ALPHAS:\n    # Prepare dataloaders\n    trainloader, validloader = get_mixup_dataloaders(train_df, valid_df, mode=mode, alpha=alpha)\n    # Run the experiment 3 times.\n    for i in range(3):\n        # Initialize model\n        tf.keras.backend.clear_session()\n        tf.random.set_seed(SEEDS[i])\n        model = get_model(mode=mode)\n\n        # Compile model\n        optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['learning_rate'])\n        model.compile(optimizer, \n                      loss='binary_crossentropy',\n                      metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n\n        # Update CONFIG dict with the name of the model.\n        CONFIG['seed'] = SEEDS[i]\n        CONFIG['model_name'] = 'EfficientNetB0'\n        CONFIG['group'] = f'Mixup-Alpha-{alpha}'\n        print('Training configuration: ', CONFIG)\n\n        # Initialize W&B run\n        run = wandb.init(project='kaggle-seti-exp2', \n                         config=CONFIG,\n                         group=CONFIG['group'], \n                         job_type='train')\n\n        # Train\n        _ = model.fit(trainloader, \n                      epochs=CONFIG['epochs'],\n                      validation_data=validloader,\n                      class_weight=class_weights_dict,\n                      callbacks=[WandbCallback(),\n                                 earlystopper])\n\n        # Evaluate\n        loss, auc = model.evaluate(validloader)\n        VAL_AUC_ROC.append(auc)\n        wandb.log({'Val AUC-ROC': auc})\n\n        # Close W&B run\n        run.finish()\n\n        del model\n        _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:03:13.382518Z","iopub.execute_input":"2021-06-13T06:03:13.382853Z","iopub.status.idle":"2021-06-13T10:58:14.133706Z","shell.execute_reply.started":"2021-06-13T06:03:13.382819Z","shell.execute_reply":"2021-06-13T10:58:14.132777Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [Check out the W&B Dashboard here $\\rightarrow$](http://wandb.me/kaggle-seti-alpha-mixup)\n\n![img](https://i.imgur.com/Ca02x9U.gif)","metadata":{}}]}