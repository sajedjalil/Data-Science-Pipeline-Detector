{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SETI Signal Search - CNN - 20\n\n## Specific\n\n* Try to understand the overfitting based on:\n* CNN-19 3 epochs on the first 2 Folds training effv2 b1 from pretrained timm\n* CNN-18 6th epoch on the all 5 Folds training effv2 b1 from pretrained timm\n\n## Global\n\nTry to predict the presence of \"needles\" with a CNN using PyTorch.\n\nFor transfer learning, look at TF EfficientNet and TF EfficientNet V2\n\nIn the list of Pytorch Image models https://paperswithcode.com/lib/timm/ and sorting them by TOP 1 Accuracy, the EfficientNet is the first model that goes under 10 Billion Flops. Also, there are variations from b0 to b8 that I presume will make it possible to trade-off compute cost vs. accuracy.\n\nVery recently (14 May) the V2 was ported to this PyTorch repo. Maybe also testing tf_efficientnetv2_b0 up to tf_efficientnetv2_b3 ?\n\nInspired by https://www.kaggle.com/piantic/train-seti-pytorch-starter-chans-vs-spatial from https://www.kaggle.com/piantic\n\nKFold and initial Convolutional filter inspired by Salman https://www.kaggle.com/micheomaano/mixup-training-5fold-spatial/execution","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T20:03:54.280487Z","iopub.execute_input":"2021-05-24T20:03:54.281095Z","iopub.status.idle":"2021-05-24T20:03:54.291082Z","shell.execute_reply.started":"2021-05-24T20:03:54.281042Z","shell.execute_reply":"2021-05-24T20:03:54.28971Z"}}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import os\n\nprint(\"os.walk in part of /kaggle/input/\")\n\ndef walk_kaggle_input(dir):\n    for dirname, _, filenames in os.walk(f\"/kaggle/input/{dir}/output\"):\n        for filename in filenames[0:10]:\n            print(os.path.join(dirname, filename))\n\nwalk_kaggle_input(\"seti-signal-search-cnn-18\")\nwalk_kaggle_input(\"seti-signal-search-cnn-19\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:09:56.623051Z","iopub.execute_input":"2021-06-13T19:09:56.62343Z","iopub.status.idle":"2021-06-13T19:09:56.646172Z","shell.execute_reply.started":"2021-06-13T19:09:56.623382Z","shell.execute_reply":"2021-06-13T19:09:56.645109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nprint(timm.__version__)\n\nimport os\nimport datetime as dt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport matplotlib.ticker as ticker\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast\nfrom torch.optim import Adam\n\nimport cv2\nimport albumentations as A\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:09:56.665131Z","iopub.execute_input":"2021-06-13T19:09:56.665662Z","iopub.status.idle":"2021-06-13T19:10:02.050065Z","shell.execute_reply.started":"2021-06-13T19:09:56.665619Z","shell.execute_reply":"2021-06-13T19:10:02.048916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data","metadata":{}},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/seti-breakthrough-listen'\n\ndef get_file_path(image_id, category):\n    return f\"{BASE_DIR}/{category}/{image_id[0]}/{image_id}.npy\"\n\ndef get_train_file_path(image_id):\n    return get_file_path(image_id, \"train\")\n\ndef get_test_file_path(image_id):\n    return get_file_path(image_id, \"test\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:02.051505Z","iopub.execute_input":"2021-06-13T19:10:02.051799Z","iopub.status.idle":"2021-06-13T19:10:02.057611Z","shell.execute_reply.started":"2021-06-13T19:10:02.05177Z","shell.execute_reply":"2021-06-13T19:10:02.055921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(f\"{BASE_DIR}/train_labels.csv\")\n\ntrain['img_path'] = train['id'].apply(get_train_file_path)\n\ndisplay(train.head(1))\nprint(train.head(1)['img_path'].values)\n\ndisplay(train['target'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:02.059987Z","iopub.execute_input":"2021-06-13T19:10:02.060623Z","iopub.status.idle":"2021-06-13T19:10:02.182139Z","shell.execute_reply.started":"2021-06-13T19:10:02.060578Z","shell.execute_reply":"2021-06-13T19:10:02.181186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(f\"{BASE_DIR}/sample_submission.csv\")\n\ntest['img_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(test.head(1))\nprint(test.head(1)['img_path'].values)\n\ndisplay(test['target'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:02.183721Z","iopub.execute_input":"2021-06-13T19:10:02.18402Z","iopub.status.idle":"2021-06-13T19:10:02.259853Z","shell.execute_reply.started":"2021-06-13T19:10:02.18399Z","shell.execute_reply":"2021-06-13T19:10:02.258891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling\n\nInitial Exploratory Data Analysis was done in https://www.kaggle.com/peterv1/seti-signal-search-data-exploration/\n\nUsing the EfficientNet ports to Pytorch from Ross Wightman Ref. https://github.com/rwightman/pytorch-image-models","metadata":{}},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    debug = False\n\n    epochs = 6\n    \n    model_name = 'tf_efficientnet_b0' # pretrained b0, b1, b2, b3 increasing size\n    model_size = 224\n    test_model_size = 224\n\n    model_name = 'tf_efficientnetv2_b0'\n    # input_size=(3, 192, 192), test_input_size=(3, 224, 224), pool_size=(6, 6)\n    model_size = 192\n    test_model_size = 224\n\n    model_name = 'tf_efficientnetv2_b1'\n    # input_size=(3, 192, 192), test_input_size=(3, 240, 240), pool_size=(6, 6)\n    model_size = 192\n    test_model_size = 240\n    \n    batch_size = 64\n    inference_batch_size = 64\n    num_workers = 8\n    \n    criterion = nn.BCEWithLogitsLoss()\n    \n    seed = 45\n    \n    N_FOLDS = 5\n    p_horizontal_flip = 0.30\n    \n    lr = 5e-5\n\nif CFG.debug:\n    print('debug!')\n    CFG.epochs = 1\n    CFG.N_FOLDS = 4\n    CFG.batch_size = 8\n    CFG.inference_batch_size = 16\n    CFG.num_workers = 4\n\n    train = train.sample(n=193, random_state=CFG.seed).reset_index(drop=True)\n    test = test.head(153)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:02.261076Z","iopub.execute_input":"2021-06-13T19:10:02.261342Z","iopub.status.idle":"2021-06-13T19:10:02.280037Z","shell.execute_reply.started":"2021-06-13T19:10:02.261317Z","shell.execute_reply":"2021-06-13T19:10:02.279182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make output dir\nOUTPUT_DIR = './output/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:02.281171Z","iopub.execute_input":"2021-06-13T19:10:02.281595Z","iopub.status.idle":"2021-06-13T19:10:02.286889Z","shell.execute_reply.started":"2021-06-13T19:10:02.281554Z","shell.execute_reply":"2021-06-13T19:10:02.28621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"ttransform = A.Compose([\n    A.RandomCrop(height=1638, width=250), # cut-off random 6 horizontally\n    A.Resize(CFG.model_size, CFG.model_size, cv2.INTER_NEAREST),\n    A.HorizontalFlip(p=CFG.p_horizontal_flip),\n])\nvtransform = A.Compose([\n    A.Resize(CFG.test_model_size, CFG.test_model_size, cv2.INTER_NEAREST)\n])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:02.287918Z","iopub.execute_input":"2021-06-13T19:10:02.288584Z","iopub.status.idle":"2021-06-13T19:10:02.299734Z","shell.execute_reply.started":"2021-06-13T19:10:02.288538Z","shell.execute_reply":"2021-06-13T19:10:02.298781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class ClassificationDataset:\n    \n    def __init__(self, img_paths, targets, tr): \n        self.img_paths = img_paths\n        self.targets = targets\n        self.tr = tr\n\n    def __len__(self):\n        return len(self.img_paths)\n    \n    def __getitem__(self, item):\n        img_path = self.img_paths[item]\n        image = np.load(img_path)\n        image = np.vstack(image).astype(float)\n        image = self.tr(image = image)[\"image\"][np.newaxis, ]\n        \n        target = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"target\": torch.tensor(target, dtype=torch.float),\n            \"img_id\": img_path.split('/')[-1].split('.')[0]\n        }","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:02.302515Z","iopub.execute_input":"2021-06-13T19:10:02.302851Z","iopub.status.idle":"2021-06-13T19:10:02.312057Z","shell.execute_reply.started":"2021-06-13T19:10:02.302783Z","shell.execute_reply":"2021-06-13T19:10:02.311083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preview","metadata":{}},{"cell_type":"code","source":"# Preview 5 training images via the ClassificationDataset\nX = train.img_path.values\ny = train.target.values\n\nsample_size = 5\ntrain_index = 130 # some random image\ntrain_images = X[train_index:train_index+sample_size]\ntrain_targets = y[train_index:train_index+sample_size]\n\n# Validation transformation (this Notebook is about analysis, not training)\ntrain_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=ttransform)\n\nfor i in range(sample_size):\n    image_target = train_dataset[i]\n    image, target = image_target['image'], image_target['target']\n    # transpose back from torch format to imshow format\n    plt.imshow(image.numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n    plt.title(f'target: {target}')\n    plt.show()\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:02.313995Z","iopub.execute_input":"2021-06-13T19:10:02.314303Z","iopub.status.idle":"2021-06-13T19:10:03.425479Z","shell.execute_reply.started":"2021-06-13T19:10:02.314275Z","shell.execute_reply":"2021-06-13T19:10:03.42453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview 2 test images via the ClassificationDataset\nX = test.img_path.values\ny = test.target.values\n\nsample_size = 2\ntest_index = 27 # some random image\ntest_images = X[test_index:test_index+sample_size]\ntest_targets = y[test_index:test_index+sample_size]\n\ntest_dataset = ClassificationDataset(img_paths=test_images, targets=test_targets, tr=vtransform, ) # vtransform !\n\nfor i in range(sample_size):\n    image_target = test_dataset[i]\n    image, target = image_target['image'], image_target['target']\n    # transpose back from torch format to imshow format\n    plt.imshow(image.numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n    plt.title(f'target: {target}')\n    plt.show()\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:03.426729Z","iopub.execute_input":"2021-06-13T19:10:03.427012Z","iopub.status.idle":"2021-06-13T19:10:03.835944Z","shell.execute_reply.started":"2021-06-13T19:10:03.426986Z","shell.execute_reply":"2021-06-13T19:10:03.834656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class timmv2(nn.Module):\n    def __init__(self, model_name, pretrained):\n        super().__init__()\n        \n        # Existing EfficientNet fixed at 3 channels\n        self.enet = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        \n        # Added a trainable 1 to 3 conv1 layer before\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=3, bias=True)\n        \n        # set the output classifier to 1 feature\n        nb_ft = self.enet.classifier.in_features\n        self.enet.classifier = nn.Linear(nb_ft, 1)\n\n    @autocast()\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.enet(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:03.837542Z","iopub.execute_input":"2021-06-13T19:10:03.837841Z","iopub.status.idle":"2021-06-13T19:10:03.845011Z","shell.execute_reply.started":"2021-06-13T19:10:03.837813Z","shell.execute_reply":"2021-06-13T19:10:03.843948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_make(model_name):\n    model = timmv2(model_name, True) # Start from pre-trained\n    state_dict = {\n        'weight':torch.tensor(\n            [[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]],[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]],[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]]], requires_grad=True    \n        ),\n        'bias':torch.tensor(\n            [0.2, 0.2, 0.2], requires_grad=True\n        )}\n    model.conv1.load_state_dict(state_dict, strict=True)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:03.847059Z","iopub.execute_input":"2021-06-13T19:10:03.847738Z","iopub.status.idle":"2021-06-13T19:10:03.860063Z","shell.execute_reply.started":"2021-06-13T19:10:03.8477Z","shell.execute_reply":"2021-06-13T19:10:03.858914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_make_custom(model_name, cnn_version, fold=0, epoch=-1):\n    model = timmv2(model_name, False) # Start from SELF-trained\n    \n    prefix = f\"/kaggle/input/seti-signal-search-cnn-{cnn_version}/output\"\n    if epoch >= 0:\n        file_name = f\"{prefix}/tf_efficientnetv2_b1_fold_{fold:02d}_epoch_{epoch:02d}_state.pth\"\n    else:\n        file_name = f\"{prefix}/tf_efficientnetv2_b1_fold_{fold:02d}_state.pth\"\n        \n    # TODO: is map_location cuda OK when model is not yet loaded in GPU ?\n    model.load_state_dict(torch.load(file_name, map_location=torch.device(device))['model'])    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:03.861844Z","iopub.execute_input":"2021-06-13T19:10:03.862293Z","iopub.status.idle":"2021-06-13T19:10:03.881431Z","shell.execute_reply.started":"2021-06-13T19:10:03.862247Z","shell.execute_reply":"2021-06-13T19:10:03.88043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model_make_custom(CFG.model_name, cnn_version=\"18\")\n\nlist(model.conv1.parameters())","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:03.882459Z","iopub.execute_input":"2021-06-13T19:10:03.882743Z","iopub.status.idle":"2021-06-13T19:10:04.9206Z","shell.execute_reply.started":"2021-06-13T19:10:03.882716Z","shell.execute_reply":"2021-06-13T19:10:04.919526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.img_path.values\ny = train.target.values\n\nsample_size = 30\ntrain_index = 0 # some random image\ntrain_images = X[train_index:train_index+sample_size]\ntrain_targets = y[train_index:train_index+sample_size]\ntrain_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=vtransform)\n\nFIG_SIZE = 6\n\nmodel.eval() # from model_make_custom\n\nfor i in range(sample_size):\n    image_target = train_dataset[i]\n    image, target = image_target['image'].unsqueeze(0), image_target['target']\n    if target == torch.tensor(1.0):\n        output = model(image).view(-1)\n        print(output.detach().numpy(), target.detach().numpy(), image_target['img_id'])\n \n        plt.figure(figsize=(FIG_SIZE, FIG_SIZE))\n        plt.axes().yaxis.set_major_locator(ticker.MultipleLocator(40))\n        plt.imshow(image.squeeze(0).numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n        plt.title(f'target: {target}')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:04.922352Z","iopub.execute_input":"2021-06-13T19:10:04.922673Z","iopub.status.idle":"2021-06-13T19:10:07.265957Z","shell.execute_reply.started":"2021-06-13T19:10:04.922641Z","shell.execute_reply":"2021-06-13T19:10:07.264872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:07.267398Z","iopub.execute_input":"2021-06-13T19:10:07.267754Z","iopub.status.idle":"2021-06-13T19:10:07.275175Z","shell.execute_reply.started":"2021-06-13T19:10:07.267722Z","shell.execute_reply":"2021-06-13T19:10:07.274055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training with folds","metadata":{}},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, criterion, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data['image']\n        targets = data['target']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        targets = targets.unsqueeze(1)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        \n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:07.278927Z","iopub.execute_input":"2021-06-13T19:10:07.279296Z","iopub.status.idle":"2021-06-13T19:10:07.28665Z","shell.execute_reply.started":"2021-06-13T19:10:07.27924Z","shell.execute_reply":"2021-06-13T19:10:07.285547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(data_loader, model, device):\n    \n    model.eval()\n    \n    final_outputs = []\n    final_targets = []\n    final_img_ids = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data['image']\n            targets = data['target']\n            img_ids = data['img_id']\n\n            inputs = inputs.to(device, dtype=torch.float)\n            output = model(inputs)\n            \n            output = output.detach().cpu().numpy().tolist()\n            targets = targets.numpy().tolist()\n\n            final_outputs.extend(output)\n            final_targets.extend(targets)\n            final_img_ids.extend(img_ids)\n            \n    return final_outputs, final_targets, final_img_ids","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:07.288303Z","iopub.execute_input":"2021-06-13T19:10:07.288748Z","iopub.status.idle":"2021-06-13T19:10:07.299427Z","shell.execute_reply.started":"2021-06-13T19:10:07.288698Z","shell.execute_reply":"2021-06-13T19:10:07.298522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train models for each fold\nmodels = []\n\nX = train.img_path.values\ny = train.target.values\nskf = StratifiedKFold(n_splits=CFG.N_FOLDS)\n\nfold = 0\nfor train_index, valid_index in skf.split(X, y):\n    \n    # **********************  BREAK  ********************\n    # DEBUG don't do training for real\n    break\n    # **********************  BREAK  ********************\n    \n    print(f\"Starting Fold {fold:02d}\")\n    \n    train_images, valid_images = X[train_index], X[valid_index]\n    train_targets, valid_targets = y[train_index], y[valid_index]\n\n    train_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=ttransform)\n    valid_dataset = ClassificationDataset(img_paths=valid_images, targets=valid_targets, tr=vtransform)\n    \n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True , num_workers=CFG.num_workers)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n\n    model = model_make(CFG.model_name)\n    model.to(device)\n\n    for epoch in range(CFG.epochs):\n        train_fn(train_loader, model, optimizer, criterion, device=device)\n        predictions, valid_targets, _ = eval_fn(valid_loader, model, device=device)\n        roc_auc = get_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        # print(list(model.conv1.parameters()))\n        \n        # Save model after each fold and epoch\n        torch.save({'model': model.state_dict()},\n                   OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_state.pth\")\n        \n    # append the latest model\n    # TODO: select the \"best\" model (after each epoch), not the last epoch\n    models.append(model)\n    fold += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:07.30065Z","iopub.execute_input":"2021-06-13T19:10:07.300942Z","iopub.status.idle":"2021-06-13T19:10:07.32076Z","shell.execute_reply.started":"2021-06-13T19:10:07.300912Z","shell.execute_reply":"2021-06-13T19:10:07.319783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate models on validation AND training data for each fold and epoch\n# try to see if and when overfittigng occurs\n\nimport csv\n\nvalid_results = []\ntrain_results = []\n\nX = train.img_path.values\ny = train.target.values\nskf = StratifiedKFold(n_splits=CFG.N_FOLDS)\n\nfold = 0\nfor train_index, valid_index in skf.split(X, y):\n    print(f\"Starting Fold {fold:02d}\")\n\n    print(len(train_index), len(valid_index))\n    print(train_index[0:5])\n    print(valid_index[0:5])\n    \n    train_images, valid_images = X[train_index], X[valid_index]\n    train_targets, valid_targets = y[train_index], y[valid_index]\n\n    train_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=ttransform)\n    valid_dataset = ClassificationDataset(img_paths=valid_images, targets=valid_targets, tr=vtransform)\n\n    # Here, since validation, shuffle False\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n\n    valid_results_per_fold = []\n    train_results_per_fold = []\n    \n    # First 3 (0,1,2) from CNN-19\n    # epoch 6 (faked here as epoch 4) from CNN-18\n    for epoch in range(4):\n        if (epoch < 3):\n            model = model_make_custom(CFG.model_name, \"19\", fold=fold, epoch=epoch)\n        elif (epoch == 3):\n            epoch = 5 # only the sixth one was saved in CNN-18\n            model = model_make_custom(CFG.model_name, \"18\", fold=fold)\n            \n        model.to(device)\n\n        # Validation over VALID data\n        predictions, targets, img_ids = eval_fn(valid_loader, model, device=device)\n        roc_auc = get_score(targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n\n        # predictions need to be flattened\n        flat_predictions = []\n        list(map(flat_predictions.extend, predictions))\n        valid_results_per_fold_per_epoch = np.dstack((flat_predictions, targets, img_ids))[0]\n\n        filename = OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_validation.csv\"\n        \n        with open(filename, 'w') as f:\n            csv.writer(f).writerows(valid_results_per_fold_per_epoch)\n        \n        valid_results_per_fold.append(valid_results_per_fold_per_epoch)\n\n        # Validation over TRAIN data\n        predictions, targets, img_ids = eval_fn(train_loader, model, device=device)\n        roc_auc = get_score(targets, predictions)\n        print(f\"Epoch={epoch}, Train ROC AUC={roc_auc}\")\n\n        # predictions need to be flattened\n        flat_predictions = []\n        list(map(flat_predictions.extend, predictions))\n        train_results_per_fold_per_epoch = np.dstack((flat_predictions, targets, img_ids))[0]\n\n        filename = OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_training.csv\"\n        \n        with open(filename, 'w') as f:\n            csv.writer(f).writerows(train_results_per_fold_per_epoch)\n        \n        train_results_per_fold.append(train_results_per_fold_per_epoch)\n        \n    valid_results.append(valid_results_per_fold)\n    train_results.append(train_results_per_fold)\n\n    fold += 1\n    \n    # DEBUG only 2 folds have this models calculated\n    if fold == 2:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:10:07.322238Z","iopub.execute_input":"2021-06-13T19:10:07.322632Z","iopub.status.idle":"2021-06-13T19:11:16.431189Z","shell.execute_reply.started":"2021-06-13T19:10:07.32259Z","shell.execute_reply":"2021-06-13T19:11:16.428587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(valid_results_per_fold[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:12:58.703414Z","iopub.execute_input":"2021-06-13T19:12:58.703936Z","iopub.status.idle":"2021-06-13T19:12:58.709337Z","shell.execute_reply.started":"2021-06-13T19:12:58.703904Z","shell.execute_reply":"2021-06-13T19:12:58.708553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_results_per_fold[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:13:02.550926Z","iopub.execute_input":"2021-06-13T19:13:02.551333Z","iopub.status.idle":"2021-06-13T19:13:02.556086Z","shell.execute_reply.started":"2021-06-13T19:13:02.551293Z","shell.execute_reply":"2021-06-13T19:13:02.555469Z"},"trusted":true},"execution_count":null,"outputs":[]}]}