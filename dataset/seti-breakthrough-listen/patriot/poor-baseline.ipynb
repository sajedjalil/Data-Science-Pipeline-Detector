{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nI think 3rd ch may work.\nhttps://www.kaggle.com/c/seti-breakthrough-listen/discussion/245950\nthnaks!! please check above discussion!!\n\ncode_factory is this [https://github.com/abebe9849/code_factory]\n\nI will update& clean below code if I have time. sorry.\n\n[0,2,4][1,3,5]\n3ch(NMF)\nadd old data (pos only)\n\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport hydra\nfrom omegaconf import DictConfig, OmegaConf\nimport sys,gc,os,random,time,math\nimport matplotlib.pyplot as plt\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nfrom  torch.cuda.amp import autocast, GradScaler \nimport timm\nimport ttach as tta\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom functools import partial\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score,recall_score,f1_score,log_loss\nfrom  sklearn.metrics import accuracy_score as acc\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau,CosineAnnealingWarmRestarts\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip,RandomGamma, RandomRotate90,GaussNoise,Cutout,RandomBrightnessContrast,RandomContrast,Resize\nfrom albumentations.pytorch import ToTensorV2\n\nfrom code_factory.pooling import GeM,AdaptiveConcatPool2d\nfrom code_factory.fmix import *\nfrom code_factory.loss_func import SmoothCrossEntropy,MyCrossEntropyLoss,FocalLoss_CE,FocalCosineLoss\n#from code_factory.visualisation import *\nfrom code_factory.specaug import *\n\nimport logging\n#from mylib.\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nimport math\nimport torch\nfrom torch.optim.optimizer import Optimizer\n\n\"\"\"\n#of cource,torchlibrosa is fast(6８0s/epoch→6４0s)\n\ndef spec_augment(spec: np.ndarray,\n                 num_mask=2,\n                 freq_masking=0.15,\n                 time_masking=0.20,\n                 value=0):\n    spec = spec.copy()\n    num_mask = random.randint(1, num_mask)\n    for i in range(num_mask):\n        all_freqs_num, all_frames_num  = spec.shape\n        freq_percentage = random.uniform(0.0, freq_masking)\n\n        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n        f0 = int(f0)\n        spec[f0:f0 + num_freqs_to_mask, :] = value\n\n        time_percentage = random.uniform(0.0, time_masking)\n\n        num_frames_to_mask = int(time_percentage * all_frames_num)\n        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n        t0 = int(t0)\n        spec[:, t0:t0 + num_frames_to_mask] = value\n    return spec\n\nclass SpecAug(ImageOnlyTransform):\n\n    def __init__(self, num_mask=2,freq_masking=0.15,time_masking=0.20, value=0, always_apply=False, p=0.5):\n        super().__init__(always_apply, p)\n        self.value = value\n        self.num_mask = num_mask\n        self.freq_masking = freq_masking\n        self.time_masking = time_masking\n\n    def apply(self, image, **params):\n        image = spec_augment(image,\n                 num_mask=self.num_mask,\n                 freq_masking=self.freq_masking,\n                 time_masking=self.time_masking,\n                 value=self.value)\n        return image\n\ndef spec_augment_m(spec: np.ndarray,\n                 num_mask=2,\n                 freq_masking=0.15,\n                 time_masking=0.20,\n                 value=0):\n    spec = spec.copy()\n    num_mask = random.randint(1, num_mask)\n    for i in range(num_mask):\n        n_channel, all_freqs_num, all_frames_num  = spec.shape # unpack channel\n        freq_percentage = random.uniform(0.0, freq_masking)\n        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n        f0 = int(f0)\n        spec[:, f0:f0 + num_freqs_to_mask, :] = value # augment all channels\n        time_percentage = random.uniform(0.0, time_masking) \n        num_frames_to_mask = int(time_percentage * all_frames_num)\n        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n        t0 = int(t0)\n        spec[:, :, t0:t0 + num_frames_to_mask] = value # augment all channels\n    return spec\n\nclass SpecAug_m(ImageOnlyTransform):\n\n    def __init__(self, num_mask=2,freq_masking=0.15,time_masking=0.20, value=0, always_apply=False, p=0.5):\n        super().__init__(always_apply, p)\n        self.value = value\n        self.num_mask = num_mask\n        self.freq_masking = freq_masking\n        self.time_masking = time_masking\n\n    def apply(self, image, **params):\n        image = spec_augment_m(image,\n                 num_mask=self.num_mask,\n                 freq_masking=self.freq_masking,\n                 time_masking=self.time_masking,\n                 value=self.value)\n        return image\n\n\n\n\n\n\n\"\"\"\n\n\n\nfrom sklearn.decomposition import NMF\nfrom sklearn.preprocessing import normalize\ndef show_cleaned_image_individually(image,plus=50):\n    image_on = None\n    image_off = None\n    clean_image = None\n    for i in range(0,6,2):\n        temp_on = image[i]\n        temp_off = image[i+1]\n        temp_on = temp_on + plus\n        temp_off = temp_off + plus\n        \n        model = NMF(init = 'random',\n                    n_components = 2,\n                    solver = 'mu',\n                    alpha = 0.01,\n                    random_state = 0,\n                   )\n        \n        W_on = model.fit_transform(temp_on)\n        H_on = model.components_\n\n        W_off = model.fit_transform(temp_off)\n        H_off = model.components_\n        \n        temp_clean = normalize(temp_on - np.matmul(W_on, H_off))\n        \n        if image_off is None:\n            image_off = image[i+1]\n        else:\n            image_off = np.concatenate((image_off, image[i+1]))\n\n        if image_on is None:\n            image_on = image[i]\n        else:\n            image_on = np.concatenate((image_on, image[i]))\n            \n        if clean_image is None:\n            clean_image = temp_clean\n        else:\n            clean_image = np.concatenate((clean_image, temp_clean))\n    return clean_image\n\ndef preprocess_image_plus(img,ch_3rd):\n    \"\"\"\n    024 as one channel, 135 as the other channel\n    \"\"\"\n    information_channels = np.concatenate([img[0], img[2], img[4]])\n    helper_channels = np.concatenate([img[1], img[3], img[5]])\n    #print(information_channels.shape,c.shape)\n    return np.array([ch_3rd,information_channels, helper_channels])\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, df,CFG,train=True,transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        self.CFG = CFG\n        self.train = train\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['file_path'].values[idx]\n        image = np.load(file_path).astype(np.float32)\n        p = file_path.split(\"/\")[-1]\n        domain = self.df['from_old'].values[idx]\n        ## ch_3rd is https://www.kaggle.com/c/seti-breakthrough-listen/discussion/245950\n        if domain==0:\n            ch_3rd = np.load(f\"/home/abebe9849/ET/new_src/clean/new_50/train/{p}\")\n        else:\n            ch_3rd = np.load(f\"/data/RSNA/ET/new_data_all/clean_wl/50/old/{p}\")\n        image = preprocess_image_plus(image,ch_3rd)\n        image = image.transpose(2,1,0)\n        #if self.train:\n        image = self.transform(image=image)['image']\n        #image = cv2.resize(image,(768,768))\n        image = torch.from_numpy(image.transpose(2,0,1)).float()\n        #print(image.shape)\n\n        label_ = self.df[\"target\"].values[idx]\n        label = torch.tensor(label_)\n        return image, label,torch.tensor(idx)\ndef sharpen(pred, T):\n    pred = pred**T\n    pred = pred / np.sum(pred)\n    return pred\n\nclass semi_test_Dataset(Dataset):\n    def __init__(self, df,CFG,train=True,transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        self.CFG = CFG\n        self.train = train\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['file_path'].values[idx]\n\n        image = np.load(file_path).astype(np.float32)[[0, 2, 4]]\n        image = np.vstack(image).transpose((1, 0))\n        if self.train:\n            image = self.transform(image=image)['image']\n        #image = cv2.resize(image,(self.CFG.preprocess.size,self.CFG.preprocess.size))\n        image = torch.from_numpy(image[None,:,:]).float()\n        #print(image.shape)\n\n        label_ = self.df[\"target\"].values[idx]\n        pred = np.array([1-label_,label_])\n        pred =sharpen(pred, 2)\n        label = torch.tensor(pred).float()\n        return image, label\n\nSEQ_POOLING = {\n    'gem': GeM(dim=2),\n    'concat': AdaptiveConcatPool2d(),\n    'avg': nn.AdaptiveAvgPool2d(1),\n    'max': nn.AdaptiveMaxPool2d(1)\n}\n\nclass Model(nn.Module):\n    def __init__(self,CFG, num_classes=2, base_model='tf_efficientnet_b0_ns',pool=\"avg\",pretrain=True):\n        super(Model, self).__init__()\n        self.base_model = base_model #\"str\"\n        self.CFG = CFG\n        self.model = timm.create_model(self.base_model, pretrained=pretrain, num_classes=2,in_chans=3)\n        #self.model.conv_stem = nn.Conv2d(2, 32, kernel_size=3, padding=1, stride=1, bias=False)\n        nc = self.model.num_features\n        if pool in ('avg','concat','gem','max'):\n            self.avgpool = SEQ_POOLING[pool]\n            if pool == \"concat\":\n                nc *= 2\n        self.last_linear = nn.Linear(nc,num_classes)\n    def forward(self, input1):\n        x = self.model.forward_features(input1)\n        if \"swin\" in self.CFG.model.name:\n            feature = x\n        else:\n            feature = self.avgpool(x).view(input1.size()[0], -1)\n        y = self.last_linear(feature)\n        return y,feature\n\n\nfrom  sklearn.metrics import roc_auc_score,accuracy_score\ndef AUC(y_true,y_pred,onehot=False):\n    if y_pred.shape[1]==2:\n        auc = roc_auc_score(y_true,y_pred[:,1])\n    else:\n        if onehot:\n            auc=0\n            n_col = y_pred.shape[1]\n            print(n_col,y_true[:,i].shape)\n            for i in range(n_col):\n                auc += roc_auc_score(y_true[:,i],y_pred[:,i])/n_col\n\n        else:\n            auc = roc_auc_score(y_true,y_pred,multi_class = \"ovr\")\n    return auc\n\n\n\ndef train_fn(CFG,fold,folds,test):\n\n    torch.cuda.set_device(CFG.general.device)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"### fold: {fold} ###\")\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n    train_dataset = TrainDataset(folds.loc[trn_idx].reset_index(drop=True),train=True, \n                                 transform1=get_transforms1(data='train',CFG=CFG),transform2=to_tensor(),CFG=CFG)#\n    valid_dataset = TrainDataset(folds.loc[val_idx].reset_index(drop=True),train=False,\n                                 transform1=get_transforms1(data='valid',CFG=CFG),transform2=to_tensor(),CFG=CFG)#\n\n    train_loader = DataLoader(train_dataset, batch_size=CFG.train.batch_size, shuffle=True, num_workers=4)\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.train.batch_size, shuffle=False, num_workers=4)\n    #if \n    test_dataset = semi_test_Dataset(test,train=True,transform1=get_transforms1(data='train',CFG=CFG),transform2=to_tensor(),CFG=CFG)#\n    test_loader = DataLoader(test_dataset, batch_size=CFG.train.batch_size, shuffle=True, num_workers=4)\n\n\n    ###  model select ============\n    if CFG.model.type==\"cnn\":\n        model = Model(num_classes=CFG.model.n_classes,base_model=CFG.model.name,pool=CFG.model.pooling,CFG=CFG)\n    elif CFG.model.type==\"vit\":\n        model = Model_vit(num_classes=CFG.model.n_classes,base_model=CFG.model.name,CFG=CFG)\n    model.to(device)\n    # ============\n\n    ###  optim select ============\n    if CFG.train.optim==\"adam\":\n        optimizer = Adam(model.parameters(), lr=CFG.train.lr, amsgrad=False)\n    elif CFG.train.optim==\"radam\":\n        optimizer = RAdam(model.parameters(), lr=CFG.train.lr)\n    elif CFG.train.optim==\"adam_w\":\n        optimizer = AdamW(model.parameters(), lr=CFG.train.lr)\n    # ============\n\n    ###  scheduler select ============\n    if CFG.train.scheduler.name==\"cosine\":\n        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.train.epochs, eta_min=CFG.train.scheduler.min_lr)\n    elif CFG.train.scheduler.name==\"cosine_warm\":\n        scheduler = CosineAnnealingWarmRestarts(optimizer,T_0=CFG.train.scheduler.t_0, T_mult=1, eta_min=CFG.train.scheduler.min_lr, last_epoch=-1)\n    elif CFG.train.scheduler.name==\"reduce\":\n        scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n    elif CFG.train.scheduler.name==\"one\":\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, total_steps=CFG.train.epochs)\n    # ============\n    \n    ###  loss select ============\n    if CFG.augmentation.mix_p>0:\n        criterion = SmoothCrossEntropy(smoothing =CFG.loss.smooth_a,one_hotted=True)\n    elif CFG.loss.name==\"ce\" and CFG.loss.weights ==False:\n        log.info(f\"~~~~class smooth_a{CFG.loss.smooth_a}~~~~~\")\n        criterion = SmoothCrossEntropy(smoothing =CFG.loss.smooth_a)\n    elif CFG.loss.name==\"ce\" and CFG.loss.weights!=False:\n        log.info(f\"~~~~class weight{CFG.loss.weights}~~~~~\")\n        weights = torch.Tensor(CFG.loss.weights).to(device).float()\n        #criterion = MyCrossEntropyLoss(weight=weights)\n        criterion = nn.CrossEntropyLoss(weight=weights)\n    elif CFG.loss.name==\"focal\" and CFG.loss.weights!=None:\n        criterion = FocalLoss_CE(gamma=CFG.loss.focal_gamma)\n    elif CFG.loss.name==\"focal_cosine\":\n        criterion = FocalCosineLoss(gamma=CFG.loss.focal_gamma)\n    # ============\n    print(criterion)\n    mse_loss = nn.MSELoss()\n    \n    softmax = nn.Softmax(dim = 1)\n    scaler = torch.cuda.amp.GradScaler()\n    best_score = 0\n    best_loss = np.inf\n    best_preds = None\n    \n    \n    for epoch in range(CFG.train.epochs):\n        start_time = time.time()\n        model.train()\n        avg_loss = 0.\n\n        tk0 = tqdm(enumerate(train_loader), total=len(train_loader))\n\n        for i, (images, labels,indexes) in tk0:\n            optimizer.zero_grad()\n            images = images.to(device)\n            #print(images.shape)\n            labels = labels.to(device)\n            onehot_label = torch.eye(CFG.model.n_classes)[labels].to(device)\n\n            if CFG.semi_SL.type==\"soft\":\n                input_test, target_test = iter(test_loader).__next__()\n                input_test = input_test.to(device)\n                target_test = target_test.to(device)\n\n\n            ### mix系のaugumentation=========\n            rand = np.random.rand()\n            if epoch+1 >=CFG.train.without_hesitate:\n                rand=0\n\n            if CFG.augmentation.mix_p>rand and CFG.augmentation.do_mixup:\n                images, y_a, y_b, lam = mixup_data(images, onehot_label,alpha=CFG.augmentation.mix_alpha)\n            elif CFG.augmentation.mix_p>rand and CFG.augmentation.do_cutmix:\n                images, y_a, y_b, lam = cutmix_data(images, onehot_label,alpha=CFG.augmentation.mix_alpha)\n            elif CFG.augmentation.mix_p>rand and CFG.augmentation.do_resizemix:\n                images, y_a, y_b, lam = resizemix_data(images, onehot_label,alpha=CFG.augmentation.mix_alpha)\n            elif CFG.augmentation.mix_p>rand and CFG.augmentation.do_fmix:\n                images, y_a, y_b, lam = fmix_data(images, onehot_label,alpha=CFG.augmentation.mix_alpha)\n            ### mix系のaugumentation おわり=========\n\n            if CFG.train.amp:\n                with autocast():\n                    y_preds,_ = model(images.float())\n                    if CFG.semi_SL.type==\"soft\":\n                        y_preds_test,_ = model(input_test.float())\n                        loss_mse = mse_loss(y_preds_test,target_test)\n                    if CFG.augmentation.mix_p>rand:\n                        loss_ = mixup_criterion(criterion, y_preds, y_a, y_b, lam)\n                    elif CFG.augmentation.mix_p<=rand and CFG.augmentation.mix_p>0:\n                        loss_ = criterion(y_preds,onehot_label) \n                    else:\n                        loss_ = criterion(y_preds, labels)\n\n                    if CFG.semi_SL.type==\"soft\":\n                        #print(loss_.dtype,loss_mse.dtype,y_preds_test.dtype,target_test.dtype)\n                        loss = loss_+loss_mse*0.05 #\n                    else:\n                        loss=loss_\n\n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n        if CFG.train.scheduler.name!=\"none\":\n            scheduler.step()\n\n\n            avg_loss += loss.item() / len(train_loader)\n        model.eval()\n        avg_val_loss = 0.\n        preds = []\n        valid_labels = []\n        tk1 = tqdm(enumerate(valid_loader), total=len(valid_loader))\n\n        for i, (images, labels,indexes) in tk1:\n            images = images.to(device)\n            labels = labels.to(device)\n            onehot_label = torch.eye(CFG.model.n_classes)[labels].to(device)\n            if CFG.loss.name==\"ce\" and CFG.loss.weights!=None:\n                labels = labels.long()\n            with torch.no_grad():\n                with autocast():\n                    y_preds,_ = model(images.float())\n                    if CFG.augmentation.mix_p>0:\n                        loss = criterion(y_preds,onehot_label)\n                    else:\n                        loss = criterion(y_preds,labels)\n            valid_labels.append(labels.to('cpu').numpy())\n            softmax = nn.Softmax(dim = 1)\n            y_preds = softmax(y_preds)\n            preds.append(y_preds.to('cpu').numpy())\n            avg_val_loss += loss.item() / len(valid_loader)\n        preds = np.concatenate(preds)\n        valid_labels = np.concatenate(valid_labels)\n\n        print(preds.shape,valid_labels.shape)\n\n\n        #else:\n        auc_score = AUC(valid_labels,preds)\n\n        elapsed = time.time() - start_time\n        log.info(f'  Epoch {epoch+1} - avg_train_loss: {avg_loss:.6f}  avg_val_loss: {avg_val_loss:.6f}  time: {elapsed:.0f}s')\n        log.info(f'  Epoch {epoch+1} - AUC : {auc_score:.6f}')\n        if auc_score>best_score:#pr_auc best\n            best_score = auc_score\n            best_preds = preds\n            log.info(f'  Epoch {epoch+1} - Save Best AUC: {auc_score:.4f}')\n            torch.save(model.state_dict(), f'fold{fold}_{CFG.general.exp_num}_baseline.pth')\n    return best_preds, valid_labels\n\n##only shift work\n\ndef get_transforms1(*, data,CFG):\n    if data == 'train':\n        return Compose([\n            HorizontalFlip(p=CFG.augmentation.hflip_p),\n            VerticalFlip(p=CFG.augmentation.vflip_p),\n            albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.0, rotate_limit=0, p=0.75),\n            RandomContrast(p=CFG.augmentation.contrast_p),\n            #GaussNoise(p=0.5),\n            RandomRotate90(p=CFG.augmentation.rotate_90_p),\n            #RandomGamma(p=0.5),\n            RandomBrightnessContrast(p=CFG.augmentation.bright_contrast_p),\n            #GaussianBlur(p=0.5),\n            albumentations.Sharpen(alpha=(0.01, 0.1), lightness=(0.01, 0.1), p=0.5),\n            GridMask(num_grid=CFG.augmentation.grdimask_n, p=CFG.augmentation.grdimask_p),\n            Cutout(p=CFG.augmentation.cutout_p),\n            SpecAug_m(num_mask=CFG.augmentation.specAug.num_mask,freq_masking=CFG.augmentation.specAug.freq_masking,\n            time_masking=CFG.augmentation.specAug.time_masking,p=CFG.augmentation.specAug.p),\n            Resize(CFG.preprocess.size,CFG.preprocess.size),\n            #Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n        ])\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG.preprocess.size,CFG.preprocess.size),\n            #Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225],\n            ])\n\nclass TestDataset(Dataset):\n    def __init__(self, df,CFG,transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        self.CFG = CFG\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['file_path'].values[idx]\n        image = np.load(file_path).astype(np.float32)[[0, 2, 4]]\n        image = np.vstack(image).transpose((1, 0))\n        #image = self.transform(image=image)['image']\n        #image = cv2.resize(image,(self.CFG.preprocess.size,self.CFG.preprocess.size))\n        image = torch.from_numpy(image[None,:,:]).float()\n        return image\n\ndef inference(model, test_loader, device,CFG):\n    model.to(device) \n    model.eval()\n    probs = []\n    features = []\n    scaler = torch.cuda.amp.GradScaler()\n\n    for i, images in tqdm(enumerate(test_loader), total=len(test_loader)):\n        images = images.to(device)\n        with torch.no_grad():\n            y_preds,feature = model(images)\n            softmax = nn.Softmax(dim = 1)\n            y_preds = softmax(y_preds)  \n        probs.append(y_preds.to('cpu').numpy())\n        features.append(feature.to('cpu').numpy())\n\n    probs = np.concatenate(probs)\n    features = np.concatenate(features)\n    return probs,features\n\ndef inference_tta(model, test_loader, device,CFG):\n    transforms = tta.Compose([\n        tta.HorizontalFlip(),\n        tta.VerticalFlip(),\n        #tta.Rotate90(angles=[0, 180]),\n        #tta.Multiply(factors=[0.9, 1, 1.1]),        \n    ])\n    model.to(device) \n    model.eval()\n    probs = []\n\n    for i, images in tqdm(enumerate(test_loader), total=len(test_loader)):\n        images = images.to(device)\n        with torch.no_grad():\n            labels = []\n            for transformer in transforms:\n                augmented_image = transformer.augment_image(images)\n                y_preds,_ = model(augmented_image)\n                y_preds = transformer.deaugment_label(y_preds)\n                softmax = nn.Softmax(dim = 1)\n                y_preds = softmax(y_preds)\n                labels.append(y_preds)\n            labels = torch.stack(labels)\n            labels = torch.mean(labels,axis=0)\n        probs.append(labels.to('cpu').numpy())\n\n    probs = np.concatenate(probs)\n    return probs\n\n\n\ndef submit(test,CFG):\n        print('run inference')\n        torch.cuda.set_device(CFG.general.device)\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        test_dataset = TestDataset(test,transform1=get_transforms1(data='valid',CFG=CFG),transform2=to_tensor(),CFG=CFG)\n        test_loader = DataLoader(test_dataset, batch_size=CFG.train.batch_size, shuffle=False)\n        probs = []\n        features = []\n        for fold in range(5):\n            weights_path = f'fold{fold}_{CFG.general.exp_num}_baseline.pth'\n            if CFG.model.type==\"cnn\":\n                model = Model(num_classes=CFG.model.n_classes,base_model=CFG.model.name,pool=CFG.model.pooling,CFG=CFG)\n            elif CFG.model.type==\"vit\":\n                model = Model_vit(num_classes=CFG.model.n_classes,base_model=CFG.model.name,CFG=CFG)\n            state_dict = torch.load(weights_path,map_location=device)\n            model.load_state_dict(state_dict)\n            if CFG.tta.do:\n                _probs = inference_tta(model, test_loader, device,CFG)\n                _features = 0\n            else:\n                _probs,_features = inference(model, test_loader, device,CFG)\n            probs.append(_probs)\n            features.append(_features)\n        probs = np.mean(probs, axis=0)\n        features = np.mean(features, axis=0)\n        return probs,features\n\ndef get_test_file_path(image_id):\n    return \"/home/abebe9849/ET/data/test/{}/{}.npy\".format(image_id[0], image_id)\n\nlog = logging.getLogger(__name__)\n@hydra.main(config_path=\"/home/abebe9849/ET/config\", config_name=\"config3\")\ndef main(CFG : DictConfig) -> None:\n    #CFG = OmegaConf.to_yaml(cfg)\n\n    seed_torch(seed=42)\n    DIR = \"/home/abebe9849/ET/new_data\"\n    log.info(f\"===============exp_num{CFG.general.exp_num}============\")\n    folds = pd.read_csv(f\"{DIR}/folds.csv\")\n\n    folds[\"from_old\"]=0\n    pos = pd.read_csv(\"/home/abebe9849/ET/new_data/old_cat.csv\")\n    pos[\"from_old\"]=1\n    pos[\"fold\"]=-1\n    pos = pos[pos[\"target\"]==1].reset_index(drop=True)\n    folds = pd.concat([folds,pos]).reset_index(drop=True)\n    test = pd.read_csv(f\"{DIR}/test.csv\")\n    sub = pd.read_csv(f\"{DIR}/sample_submission.csv\")\n\n    if CFG.semi_SL.psuedo_label!=-1 and CFG.semi_SL.type==\"pl\":\n        inner_test = pd.read_csv(f\"{CFG.semi_SL.psuedo_label}/submission.csv\")\n        inner_test['file_path'] = inner_test['id'].apply(get_test_file_path)\n\n        test2p0 = inner_test[inner_test['target']<CFG.semi_SL.psuedo_th]\n        test2p0[\"target\"] = 0\n        test2p0[\"fold\"] = -1\n        test2p1 = inner_test[inner_test['target']>CFG.semi_SL.psuedo_th_1]\n        test2p1[\"target\"] = 1\n        test2p0[\"fold\"] = -1\n\n\n\n        if len(test2p0)+len(test2p1)>1:\n            folds = pd.concat([folds,test2p1,test2p0]).reset_index(drop=True)\n        log.info(f\"==how many add for PL {len(test2p0)},{len(test2p1)}===\")\n\n    if CFG.semi_SL.psuedo_label!=-1 and CFG.semi_SL.type==\"soft\":\n        pre_test = pd.read_csv(f\"{CFG.semi_SL.psuedo_label}/submission.csv\")\n        pre_test['file_path'] = pre_test['id'].apply(get_test_file_path)\n\n\n    preds = []\n    valid_labels = []\n    for fold in range(5):\n        if CFG.semi_SL.type==\"soft\":\n            _preds, _valid_labels = train_fn(CFG,fold,folds,pre_test)\n        else:\n            _preds, _valid_labels = train_fn(CFG,fold,folds,test)\n        preds.append(_preds)\n        valid_labels.append(_valid_labels)\n    preds = np.concatenate(preds)\n    valid_labels = np.concatenate(valid_labels)\n\n    auc_score = AUC(valid_labels,preds)\n\n    log.info(f'  =====AUC(CV)====== {auc_score}')\n\n\n    \n    if CFG.semi_SL.type==\"none\":\n        folds[\"pred\"] = preds[:,1]\n        folds.to_csv(\"predict.csv\",index = False)\n    \n\n    \n\n    fpr, tpr, thresholds = metrics.roc_curve(valid_labels, preds[:,1])\n    score = metrics.roc_auc_score(valid_labels,preds[:,1])\n    plt.plot(fpr, tpr, label=f'AUC={score}')\n    plt.legend()\n    plt.title(f'ROC curve_train exp{CFG.general.exp_num}')\n    plt.xlabel('False Positive Rate(1-Specificity)')\n    plt.ylabel('True Positive Rate(Recall)')\n    plt.grid(True)\n    plt.show()\n    plt.savefig(\"TRAIN_{0}_.png\".format(CFG.general.exp_num))\n\n\n    \n\n    pred,features = submit(test,CFG)\n\n    sub[\"target\"] = pred[:,1]\n    sub.to_csv(\"submission.csv\",index = False)\n\nif __name__ == \"__main__\":\n    main()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used this config.public LB may 0.832,cv=0.8890965123456791\nit takes 57min/epoch by q rtx 8000.","metadata":{}},{"cell_type":"code","source":"\"\"\"\ngeneral:\n  debug: false\n  exp_num: n032_last\n  device: 0\n  task:\n    name: clf\nloss:\n  name: ce\n  weights: false\n  smooth_a: 0\n  focal_gamma: 0\npreprocess:\n  size: 768\naugmentation:\n  grdimask_p: 0\n  grdimask_n: 3\n  hflip_p: 0.5\n  vflip_p: 0.5\n  cutout_p: 0.5\n  contrast_p: 0\n  bright_contrast_p: 0\n  rotate_90_p: 0\n  bright_p: 0\n  do_mixup: true\n  do_fmix: false\n  do_cutmix: false\n  do_snapmix: false\n  do_resizemix: false\n  mix_p: 0.5\n  mix_alpha: 1\n  specAug:\n    p: 0.5\n    num_mask: 2\n    freq_masking: 0.15\n    time_masking: 0.1\ntta:\n  do: false\nmodel:\n  name: tf_efficientnet_b5_ns\n  type: cnn\n  pooling: gem\n  n_classes: 2\n  features_num: 1280\nsemi_SL:\n  type: none\n  psuedo_label: none\n  psuedo_th: 0.003\n  psuedo_th_1: 0.88\ntrain:\n  amp: true\n  amp_inf: false\n  optim: adam\n  lr: 0.001\n  epochs: 20\n  without_hesitate: 15# stop mixup after several epochs\n  batch_size: 24\n  scheduler:\n    name: cosine\n    min_lr: 0.00001\n    t_0: 3\n\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]}]}