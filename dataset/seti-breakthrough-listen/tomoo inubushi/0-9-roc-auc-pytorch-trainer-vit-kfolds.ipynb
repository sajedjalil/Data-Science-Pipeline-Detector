{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This is a folk of [this notebook](https://www.kaggle.com/heyytanay/0-9-auc-pytorch-training-amp-vit-kfolds).\nI omitted AMP (Automatic Mixed Precision), and found trainng speed becomes faster (2.18it/s -> 2.30it/s). Do you know why?","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center' style='background: #1eeacf'>1. Imports and Data Loading</h1>","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/timmeffnetv2\")","metadata":{"execution":{"iopub.status.busy":"2021-05-30T17:08:30.246755Z","iopub.execute_input":"2021-05-30T17:08:30.247114Z","iopub.status.idle":"2021-05-30T17:08:30.255132Z","shell.execute_reply.started":"2021-05-30T17:08:30.247038Z","shell.execute_reply":"2021-05-30T17:08:30.254068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import platform\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport cv2\nimport gc\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-30T17:08:30.259558Z","iopub.execute_input":"2021-05-30T17:08:30.259837Z","iopub.status.idle":"2021-05-30T17:08:34.487729Z","shell.execute_reply.started":"2021-05-30T17:08:30.259812Z","shell.execute_reply":"2021-05-30T17:08:34.486697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntrain_labels['path'] = train_labels['id'].apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')\ntrain_labels.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:34:37.59181Z","iopub.execute_input":"2021-05-29T06:34:37.592156Z","iopub.status.idle":"2021-05-29T06:34:37.671573Z","shell.execute_reply.started":"2021-05-29T06:34:37.592118Z","shell.execute_reply":"2021-05-29T06:34:37.670656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotFromFoldScores(score_dict, colors=None):\n    if colors is None:\n        colors = ['r', 'g', 'y', 'b', 'm']\n    \n    plt.figure(figsize=(10, 7))\n    for fold_num, scores in score_dict.items():\n        plt.plot(scores, f'{colors[fold_num]}o-', label=f'Fold {fold_num}')\n    \n    plt.ylabel(\"Validation ROC-AUC Score\")\n    plt.xlabel(\"Epochs\")\n    plt.title(\"Val ROC-AUC Scores in all Folds\")\n    plt.legend()\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-30T17:13:58.854977Z","iopub.execute_input":"2021-05-30T17:13:58.855329Z","iopub.status.idle":"2021-05-30T17:13:58.861327Z","shell.execute_reply.started":"2021-05-30T17:13:58.855298Z","shell.execute_reply":"2021-05-30T17:13:58.860356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    N_SPLITS = 5\n    model_name = 'vit_base_patch16_224'\n    resize = (224, 224)\n    TRAIN_BS = 32\n    VALID_BS = 16\n    num_workers = 8\n    NB_EPOCHS = 5\n    scaler = GradScaler()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T15:11:23.071439Z","iopub.execute_input":"2021-05-30T15:11:23.071783Z","iopub.status.idle":"2021-05-30T15:11:23.132239Z","shell.execute_reply.started":"2021-05-30T15:11:23.071752Z","shell.execute_reply":"2021-05-30T15:11:23.131355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='background: #1eeacf'>2. Trainer Class - Training and Validation Code</h1>","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, optimizer, scheduler, train_dataloader, valid_dataloader, device):\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.train_data = train_dataloader\n        self.valid_data = valid_dataloader\n        self.loss_fn = self.yield_loss\n        self.val_loss_fn = self.yield_loss\n        self.device = device\n        \n    def yield_loss(self, outputs, targets):\n        return nn.BCEWithLogitsLoss()(outputs, targets)\n    \n    def train_one_epoch(self):\n        prog_bar = tqdm(enumerate(self.train_data), total=len(self.train_data))\n        self.model.train()\n        avg_loss = 0\n        #with autocast():\n        for idx, inputs in prog_bar:\n            image = inputs[0].to(self.device, dtype=torch.float)\n            targets = inputs[1].to(self.device, dtype=torch.float)\n\n            outputs = self.model(image)\n\n            loss = self.loss_fn(outputs, targets.view(-1, 1))\n            prog_bar.set_description('loss: {:.2f}'.format(loss.item()))\n\n            loss.backward()\n            self.optimizer.step()\n            #Config.scaler.scale(loss).backward()\n            #Config.scaler.step(self.optimizer)\n            #Config.scaler.update()\n            self.optimizer.zero_grad(set_to_none=True)\n\n            avg_loss += loss.item()\n                \n        return avg_loss / len(self.train_data)\n    \n    def valid_one_epoch(self):\n        prog_bar = tqdm(enumerate(self.valid_data), total=len(self.valid_data))\n        self.model.eval()\n        all_targets = []\n        all_predictions = []\n        avg_loss = 0\n        with torch.no_grad():\n            for idx, inputs in prog_bar:\n                image = inputs[0].to(self.device, dtype=torch.float)\n                targets = inputs[1].to(self.device, dtype=torch.float)\n\n                outputs = self.model(image)\n                \n                val_loss = self.val_loss_fn(outputs, targets.view(-1, 1))\n                prog_bar.set_description('val_loss: {:.2f}'.format(val_loss.item()))\n                \n                all_targets.extend(targets.cpu().detach().numpy().tolist())\n                all_predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n                \n                avg_loss += val_loss.item()\n        val_roc_auc = roc_auc_score(all_targets, all_predictions)\n        return val_roc_auc, avg_loss / len(self.valid_data)\n    \n    def get_model(self):\n        return self.model","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:34:52.139337Z","iopub.execute_input":"2021-05-29T06:34:52.139654Z","iopub.status.idle":"2021-05-29T06:34:52.155762Z","shell.execute_reply.started":"2021-05-29T06:34:52.139623Z","shell.execute_reply":"2021-05-29T06:34:52.154782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='background: #1eeacf'>3. Custom Dataset - SETIData</h1>","metadata":{}},{"cell_type":"code","source":"class SETIData(Dataset):\n    def __init__(self, images, targets, is_test=False, augmentations=None): \n        self.images = images\n        self.targets = targets\n        self.is_test = is_test\n        self.augmentations = augmentations\n        \n    def __getitem__(self, index):\n        image = np.load(self.images[index]).astype(np.float32)\n        image = np.vstack(image).transpose((1, 0))\n        image = cv2.resize(image, dsize=Config.resize, interpolation=cv2.INTER_CUBIC)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n        else:\n            image = image[np.newaxis, :, :]\n            \n        if self.is_test:\n            return image\n        \n        else:\n            target = self.targets[index]\n            return image, target\n    \n    def __len__(self):\n        return len(self.images)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:34:54.156052Z","iopub.execute_input":"2021-05-29T06:34:54.156382Z","iopub.status.idle":"2021-05-29T06:34:54.163646Z","shell.execute_reply.started":"2021-05-29T06:34:54.156349Z","shell.execute_reply":"2021-05-29T06:34:54.162727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='background: #1eeacf'>4. Model Classes - ViT and EffNetV2</h1>","metadata":{}},{"cell_type":"code","source":"print(\"You can see the available models from EfficientNetV2 family here:\")\ntimm.list_models('*vit*_224*')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:35:08.678142Z","iopub.execute_input":"2021-05-29T06:35:08.678474Z","iopub.status.idle":"2021-05-29T06:35:08.685605Z","shell.execute_reply.started":"2021-05-29T06:35:08.678442Z","shell.execute_reply":"2021-05-29T06:35:08.684775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EffNetV2(nn.Module):\n    def __init__(self, pretrained=True) -> None:\n        super(EffNetV2, self).__init__()\n        self.backbone = timm.create_model(Config.model_name, pretrained=pretrained, in_chans=1)\n        self.backbone.classifier = nn.Linear(self.backbone.classifier.in_features, 1)\n        \n    def forward(self, x) -> torch.Tensor:\n        out = self.backbone(x)\n        return out\n    \nclass VITModel(nn.Module):\n    \"\"\"\n    Model Class for VIT Model\n    \"\"\"\n    def __init__(self, model_name=Config.model_name, pretrained=True):\n        super(VITModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained, in_chans=1)\n        self.model.head = nn.Linear(self.model.head.in_features, 1)\n    \n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:38:46.480552Z","iopub.execute_input":"2021-05-29T06:38:46.480958Z","iopub.status.idle":"2021-05-29T06:38:46.489756Z","shell.execute_reply.started":"2021-05-29T06:38:46.480924Z","shell.execute_reply":"2021-05-29T06:38:46.488711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center' style='background: #1eeacf'>5. Main Training Code</h1>","metadata":{}},{"cell_type":"code","source":"# Training Code\nif __name__ == '__main__':\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n        DEVICE = torch.device('cuda:0')\n    else:\n        print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n        DEVICE = torch.device('cpu')\n    \n    kfold = StratifiedKFold(n_splits=Config.N_SPLITS, shuffle=True, random_state=2021)\n    \n    fold_scores = {}\n    \n    for fold_, (trn_idx, val_idx) in enumerate(kfold.split(train_labels, train_labels['target'])):\n        print(f\"{'='*40} Fold: {fold_} {'='*40}\")\n        \n        train_data = train_labels.loc[trn_idx]\n        valid_data = train_labels.loc[val_idx]\n        \n        print(f\"[INFO] Training on {trn_idx.shape[0]} samples and validating on {valid_data.shape[0]} samples\")\n\n        # Make Training and Validation Datasets\n        training_set = SETIData(\n            images=train_data['path'].values,\n            targets=train_data['target'].values\n        )\n\n        validation_set = SETIData(\n            images=valid_data['path'].values,\n            targets=valid_data['target'].values\n        )\n\n        train = DataLoader(\n            training_set,\n            batch_size=Config.TRAIN_BS,\n            shuffle=True,\n            num_workers=8,\n            pin_memory=True\n        )\n\n        valid = DataLoader(\n            validation_set,\n            batch_size=Config.VALID_BS,\n            shuffle=False,\n            num_workers=8\n        )\n\n        model = VITModel().to(DEVICE)\n        print(f\"[INFO] Training Model: {Config.model_name}\")\n        nb_train_steps = int(len(train_data) / Config.TRAIN_BS * Config.NB_EPOCHS)\n        optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n\n        trainer = Trainer(model, optimizer, None, train, valid, DEVICE)\n        \n        per_fold_score = []\n        for epoch in range(1, Config.NB_EPOCHS+1):\n            print(f\"\\n{'--'*5} EPOCH: {epoch} {'--'*5}\\n\")\n\n            # Train for 1 epoch\n            tr_lss = trainer.train_one_epoch()\n            \n            # Validate for 1 epoch\n            current_roc, vl_lss = trainer.valid_one_epoch()\n            print(f\"Validation ROC-AUC: {current_roc:.4f}\")\n            \n            per_fold_score.append(current_roc)\n            torch.save(trainer.get_model().state_dict(), f\"{Config.model_name}_fold_{fold_}.pt\")\n        \n        fold_scores[fold_] = per_fold_score\n        del training_set, validation_set, train, valid, model, optimizer, trainer, current_roc\n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T06:38:47.05406Z","iopub.execute_input":"2021-05-29T06:38:47.054393Z","iopub.status.idle":"2021-05-29T06:38:51.607976Z","shell.execute_reply.started":"2021-05-29T06:38:47.054364Z","shell.execute_reply":"2021-05-29T06:38:51.599951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot validation roc-auc scores for all 5 epochs from all 5 folds\nplotFromFoldScores(fold_scores)","metadata":{},"execution_count":null,"outputs":[]}]}