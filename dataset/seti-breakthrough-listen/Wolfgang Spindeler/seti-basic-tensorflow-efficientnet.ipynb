{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## SETI Breakthrough Listen - Single Tensorflow Model Efficient Net\n\nGetting a good score with a single model. Code for basic model evaluation and submission.\n\nVersion for training score: https://www.kaggle.com/wspinkaggle/seti-basic-tensorflow-efficientnet?scriptVersionId=64315935","metadata":{}},{"cell_type":"markdown","source":"## Libs","metadata":{}},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport math\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.layers as L\nimport efficientnet.tfkeras as efn\n\nimport os\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nSettings for training\n\"\"\"\n\n# data splits\nTRAIN_DATA_LIMIT = 50165 #50165  # limit data for faster testing, set to a value >= 50165 to include all train data (in particular advised when submitting)\nSUBMISSION_RUN = True  # set to True when wanting to create submission file `submission.csv` as output. This will result in not creating a holdout set or validation set. \nTEST_SIZE = 0.1  # ratio of all train images (with respect to TRAIN_DATA_LIMIT) used for holdout test set for final scoring. Only considered on non-submission run.\nVALIDATION_SIZE = 0.1  # ratio of all train images (with respect to TRAIN_DATA_LIMIT) used for validation set (after possible holdout set), only used on non-submission run\n\n# training params\nSEED=43\nBATCH_SIZE=32\nNUMBER_TRAIN_EPOCHS = 20  # number epochos in model evaluation run (submission_run = False). Note that we also use early stopping in training, so this number of epochs may not be reached\nNUMBER_SUBMISSION_EPOCHS = 8  # Number of epochs to run on a submission run. Value of 8 set here based on exploration of model in version 14 of notebook","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check GPU and limit GPU memory growth\n#gpu = tf.config.list_physical_devices('GPU')\n#print(\"Num GPUs Available: \", len(gpu))\n#if len(gpu) > 0:\n#    tf.config.experimental.set_memory_growth(gpu[0], True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare data sources","metadata":{}},{"cell_type":"code","source":"data_dir = Path('../input/seti-breakthrough-listen/')\ntrain_data_dir = data_dir / 'train'\ntest_data_dir = data_dir / 'test'\n\ntrain_label_file = data_dir / 'train_labels.csv'\nsample_file = data_dir / 'sample_submission.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_labels = pd.read_csv(train_label_file, index_col='id')\ndf_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def id_to_path(file_id, train=True):\n    data_dir = train_data_dir if train else test_data_dir\n    return data_dir / file_id[0] / f'{file_id}.npy'\n\n# simple test\nid_to_path(\"00047dfc96a9\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basic data overview","metadata":{}},{"cell_type":"code","source":"#check class imbalance \ndf_labels.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shape of a sample\nnp.load(id_to_path(df_labels.iloc[0].name)).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function for visualizing a sample\ndef show_cadence(filename, label):\n    \"\"\"\n    taken from https://www.kaggle.com/ihelon/signal-search-exploratory-data-analysis\n    \"\"\"\n    plt.figure(figsize=(16,10))\n    arr = np.load(filename)\n    for i in range(6):\n        plt.subplot(6, 1, i + 1)\n        if i == 0:\n            plt.title(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n        plt.imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        plt.xticks([])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show some example. Will show a random positive example on every execution\nindex, label = df_labels.query(\"target == 1\").sample(1).reset_index().values[0]\nshow_cadence(id_to_path(index), label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Input Pipeline","metadata":{}},{"cell_type":"code","source":"class SETISequence(Sequence):\n    \"\"\"\n    Taken from this nice starter notebook https://www.kaggle.com/kenjirokiyono/seti-simple-code-for-beginners-tensorflow\n    \"\"\"\n    def __init__(self, x_set, y_set=None, batch_size=BATCH_SIZE):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n        self.is_train = False if y_set is None else True\n    \n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n    \n    def __getitem__(self, idx):\n        batch_ids = self.x[idx * self.batch_size: (idx + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[idx * self.batch_size: (idx + 1) * self.batch_size]\n        \n        # taking channels \n        list_x = [np.load(id_to_path(x, train=self.is_train)) for x in batch_ids]\n        batch_x = np.moveaxis(list_x,1,-1)\n        batch_x = batch_x.astype(\"float\") / 255\n        \n        if self.is_train:\n            return batch_x, batch_y\n        else:\n            return batch_x\n        \n# small output test\nSETISequence([\"00047dfc96a9\"], [1], batch_size=2).__getitem__(0)[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model\n\n[arXiv : Efficientnet](https://arxiv.org/abs/1905.11946)","metadata":{}},{"cell_type":"code","source":"# list of file_ids for training, limited to TRAIN_DATA_LIMIT parameter which allows fast sandboxing\ntrain_ids = df_labels.index.values[:TRAIN_DATA_LIMIT]\ntrain_y = df_labels['target'].values[:TRAIN_DATA_LIMIT]\n\n# we create a holdout set for scoring only when not creating a submission output\nif not SUBMISSION_RUN:\n    print(\"Not a submission run, creating holdout set for scoring...\")\n    train_ids, test_ids, train_y, test_y = train_test_split(train_ids, train_y, test_size=TEST_SIZE, random_state=SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# architecture based on https://www.kaggle.com/kenjirokiyono/seti-simple-code-for-beginners-tensorflow\n# some tuning guidelines: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n\n# vertical flipping images probably is a meaningful augmentation for this dataset\ndata_augmentation = tf.keras.Sequential([\n  L.experimental.preprocessing.RandomFlip(\"vertical\"),\n])\n\nmodel = tf.keras.Sequential([\n        L.Conv2D(3,(3,3), strides=(1,1), padding=\"same\", activation='relu', input_shape=(273,256,6)),\n        data_augmentation,\n        efn.EfficientNetB1(input_shape=(273, 256, 3), weights='imagenet', include_top=False, drop_connect_rate=0.4),\n        L.GlobalAveragePooling2D(),\n        L.Dense(1, activation='sigmoid')\n        ])\n\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n              loss='binary_crossentropy', metrics=[keras.metrics.AUC()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# we create a validation set for training only when not submitting, so submission is trained on full data (but taking into account TRAIN_DATA_LIMIT!)\nif not SUBMISSION_RUN:\n    train_ids, val_ids, train_y, val_y = train_test_split(train_ids, train_y, test_size=VALIDATION_SIZE, random_state=SEED)\n    val = SETISequence(val_ids, val_y, batch_size=BATCH_SIZE)\n\ntrain = SETISequence(train_ids, train_y, batch_size=BATCH_SIZE)\n\nif not SUBMISSION_RUN:\n    callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=2, restore_best_weights=True, mode='max')\n    history = model.fit(train, validation_data=val, epochs=NUMBER_TRAIN_EPOCHS, callbacks=[callback])\n    \nelse:\n    history = model.fit(train, epochs=NUMBER_SUBMISSION_EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check training loss\ndef plot_history(h):\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    for key in h:\n        i = 0 if \"loss\" in key else 1\n        ax[i].plot(h[key], marker='o', label=key)\n    \n    for a in ax:\n        a.legend()\n    \n    plt.show()\n\nplot_history(history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n\"\"\"\ncreate submisison on submission run, else evaluate on holdout set\n\"\"\"\n\nif SUBMISSION_RUN: # takes about 11minutes\n    df_submission = pd.read_csv(sample_file, index_col='id')\n    submission_ids = df_submission.index.values\n    submission_pipe = SETISequence(submission_ids, batch_size=BATCH_SIZE)\n    df_submission['target'] = model.predict(submission_pipe).flatten()\n\n    df_submission.to_csv(\"submission.csv\")\n    display(pd.read_csv(\"submission.csv\"))\n    \nelse:\n    test = SETISequence(test_ids, test_y, batch_size=BATCH_SIZE)\n    test_prediction = model.predict(test).flatten()\n    \n    print(f\"\"\"\n    AUC score: {\n    roc_auc_score(\n        y_true=df_labels.loc[test_ids].values.reshape(-1),\n        y_score=test_prediction\n    )}\n    \"\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}