{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"####    In this notebook I used two 'efficientnet-b4' Neural Networks (NN). First one was trained on each separate image. Second NN was trained using 6 given images as 6 dimension input. This way I got 7 predictions for each observation (first NN gives 6 predictions (since each observation includes 6 seperate images) and second NN gives one prediction (since it uses the same observtion but considering all 6 pictures as 6 dimnsion input)).¶\n\n####    After that I created DataFrame whre each column is prediction of NN. So I got 7 columns of predictions and 8th column is target. Then RandomForest and CatBoost Classifier used this DataFrame for training. A simple average of RandomForest and CatBoost Classifier was used as a final answer.","metadata":{}},{"cell_type":"markdown","source":"1. [First NN](#section-one)\n  - [Training](#section-oneB)\n2. [Second NN](#section-two)\n  - [Training](#section-twoB)\n3. [Random Forest ](#section-three)\n4. [CatBoostClassifier](#section-four)\n5. [Composition and submission](#section-five)\n","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport tqdm\nimport copy\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport os\nimport pandas as pd\nimport seaborn as sns\n#import matplotlib\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nfrom efficientnet_pytorch import EfficientNet\nfrom torch.optim.lr_scheduler import StepLR","metadata":{"execution":{"iopub.status.busy":"2021-08-14T16:35:18.965016Z","iopub.execute_input":"2021-08-14T16:35:18.965441Z","iopub.status.idle":"2021-08-14T16:35:22.543753Z","shell.execute_reply.started":"2021-08-14T16:35:18.965405Z","shell.execute_reply":"2021-08-14T16:35:22.542569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First NN\n<a id=\"section-one\"></a>","metadata":{}},{"cell_type":"code","source":"#prepare data for training first NN\ndf = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ndf['img_path'] = df['id'].apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')\nX = df['img_path'].values\nY = df['target'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.05, stratify = Y, random_state = 1)\n\ndf = pd.DataFrame({'image': X_train,\n                      'target': y_train})\ndf = df.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T16:37:08.266231Z","iopub.execute_input":"2021-08-14T16:37:08.266629Z","iopub.status.idle":"2021-08-14T16:37:08.419358Z","shell.execute_reply.started":"2021-08-14T16:37:08.266586Z","shell.execute_reply":"2021-08-14T16:37:08.418192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>","metadata":{}},{"cell_type":"code","source":"class make_tensor:\n    \n    def __init__(self, images, labels, mode = 'train'):\n        self.image = images\n        self.label = labels\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.image)\n\n    def __getitem__(self, idx):\n        im = self.image[idx]\n        lb = self.label[idx]\n        sample = {\"image\":  torch.tensor(im, dtype=torch.float), \n                  \"label\":  torch.tensor(lb).item()}\n            \n        return sample","metadata":{"execution":{"iopub.status.busy":"2021-08-14T16:37:10.46204Z","iopub.execute_input":"2021-08-14T16:37:10.462447Z","iopub.status.idle":"2021-08-14T16:37:10.470009Z","shell.execute_reply.started":"2021-08-14T16:37:10.462417Z","shell.execute_reply":"2021-08-14T16:37:10.468565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []\nY = []\n\nfor path, target in zip(X_test, y_test): \n    temp = np.load(path)\n    if target == 1:\n        for t in range(6):\n            label = [1,0][t % 2]\n            im = temp[t].astype(np.float32)\n            im = cv2.resize(im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n            im1 = cv2.flip(im, 1)\n                        \n            X.append(im)\n            X.append(im1)\n            Y.append(label)\n            Y.append(label)\n        \n    else:\n         for t in range(6):\n                label = 0\n                im = temp[t].astype(np.float32)\n                im = cv2.resize(im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                        \n                X.append(im)\n                Y.append(label)\n    del(temp)\n\nprint(np.shape(X))\nvalid_data = make_tensor(X, Y)\nvalid_data = DataLoader(valid_data, batch_size=64, shuffle=True, drop_last = True)\n\ndel(X, Y)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T16:37:12.903788Z","iopub.execute_input":"2021-08-14T16:37:12.904246Z","iopub.status.idle":"2021-08-14T16:37:36.447092Z","shell.execute_reply.started":"2021-08-14T16:37:12.904213Z","shell.execute_reply":"2021-08-14T16:37:36.445686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, name, output_dim):\n        super(CNN, self).__init__()\n        self.model = EfficientNet.from_pretrained(name)\n        self.model._fc = nn.Linear(in_features = self.model._fc.in_features, out_features=output_dim)\n        self.conv =  nn.Conv2d(1, 3, kernel_size=1, stride=1, bias=False)\n        \n        \n    def forward(self, image):\n        image.requires_grad_(True)\n        image = torch.unsqueeze(image, 1)\n        image = self.conv(image)\n        \n        output = self.model(image)\n        \n        return(output)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T16:37:36.450073Z","iopub.execute_input":"2021-08-14T16:37:36.45073Z","iopub.status.idle":"2021-08-14T16:37:36.460008Z","shell.execute_reply.started":"2021-08-14T16:37:36.450682Z","shell.execute_reply":"2021-08-14T16:37:36.458466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CNN(name = 'efficientnet-b4', output_dim = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T16:37:36.463522Z","iopub.execute_input":"2021-08-14T16:37:36.464125Z","iopub.status.idle":"2021-08-14T16:37:39.120966Z","shell.execute_reply.started":"2021-08-14T16:37:36.46407Z","shell.execute_reply":"2021-08-14T16:37:39.119467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training of the first NN model\n<a id=\"section-oneB\"></a>\n","metadata":{}},{"cell_type":"code","source":"best_model_wts = []\nauc_fin_tr = []\nacc_fin_tr = []\nauc_fin_val = []\nacc_fin_val = []\nlos_fin_train = []\nlos_fin_test = []\n\ndef train(df, x_valid, model, learning_rate = 0.0001, num_epochs = 1, max_num = 512):\n    loss_fn = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    scheduler = StepLR(optimizer, step_size = 2, gamma=0.1, verbose=True)\n    \n\n    best_auc = 0.0\n    auc_tr_eph = []\n    acc_tr_eph = []    \n        \n    for epoch in tqdm.tqdm(range(num_epochs), position=0, leave=True, desc='Epoch'):\n        \n        running_loss_tr = 0.0\n        running_loss_test = 0.0\n        \n        acc_tr = []\n        auc_tr = []\n        \n        start = -max_num\n        end = 0\n        \n        model.train()\n        \n        for batch_counter in tqdm.tqdm(range(int(len(df)/max_num)),position=0, leave=True, desc='Load batch'):\n            #print(\"Batch counter:\", batch_counter)\n            start += max_num\n            end += max_num\n            X = []\n            Y = [] \n            auc_tr_mb = []\n            acc_tr_mb = []\n        \n            for path, target in zip(df['image'][start:end], df['target'][start:end].values): \n                temp = np.load(path)\n                if target == 1:\n                    for t in range(6):\n                        label = [1,0][t % 2]\n                        im = temp[t].astype(np.float32)\n                        im = cv2.resize(im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                        im1 = cv2.flip(im, 1)\n                        \n                        X.append(im)\n                        X.append(im1)\n                        Y.append(label)\n                        Y.append(label)\n        \n                else:\n                    for t in range(6):\n                        label = 0\n                        im = temp[t].astype(np.float32)\n                        im = cv2.resize(im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                        \n                        X.append(im)\n                        Y.append(label)\n        \n        \n            \n            x_train = make_tensor(X,Y)\n            x_oversam = [x['image'].numpy() for x in x_train]\n            y_oversam = [x['label'] for x in x_train]\n            \n            n, xd, yd = np.shape(x_oversam)\n            #print(n)\n            y_oversam = np.reshape(y_oversam, (-1, 1))\n            x_oversam = np.reshape(x_oversam, (n,xd*yd))\n            \n            overrsample = RandomOverSampler(sampling_strategy=1)\n            X, Y = overrsample.fit_resample(x_oversam, y_oversam)\n            n, _ = np.shape(X)\n            #print(n)\n            X = np.reshape(X, (n, xd, yd))\n            Y = np.reshape(Y, (-1,))\n            \n            \n            x_train = make_tensor(X,Y)\n            x_train = DataLoader(x_train, batch_size=32, shuffle=True, drop_last = True)\n            del(X, Y)\n            del(x_oversam, y_oversam)\n        \n            for data in tqdm.tqdm(x_train, position=0, leave=True, desc='Training'):\n                model.zero_grad()\n                x = data['image']\n                y = data['label']\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device, dtype=torch.float)\n        \n                output =  model(x)\n            #print('Выход обучения: ', output[:3] )\n                loss = loss_fn(output, torch.unsqueeze(y, 1))\n                loss.backward()\n                optimizer.step()\n                running_loss_tr += loss.item()\n            \n                y = torch.unsqueeze(y, 1).detach().cpu().numpy().tolist()\n                output = output.detach().cpu().numpy().tolist()\n                output = sum(output, [])\n            \n                for i in range(len(output)):\n                    if output[i] >= 0:\n                        output[i] = int(1)\n                    else:\n                        output[i] = int(0)\n                \n                roc = roc_auc_score(y, output)\n                acc = accuracy_score(y, output)\n                auc_tr_mb.append(roc)\n                acc_tr_mb.append(acc)\n                                     \n            \n            auc_tr.append(np.mean(auc_tr_mb))\n            acc_tr.append(np.mean(acc_tr_mb))\n        \n        auc_tr_eph = np.mean(auc_tr)\n        acc_tr_eph = np.mean(acc_tr)\n    \n        del(auc_tr, acc_tr)\n        \n        auc_val = []\n        acc_val = []\n    \n        model.eval()\n        with torch.no_grad():\n            \n            \n            for data in tqdm.tqdm(x_valid, position=0, leave=True, desc='Testing'):\n                x = data['image']\n                y = data['label']\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device, dtype=torch.float)\n            \n                output =  model(x)\n                loss = loss_fn(output, torch.unsqueeze(y, 1))\n                running_loss_test += loss.item()\n                y = torch.unsqueeze(y, 1).detach().cpu().numpy().tolist()\n                output = output.detach().cpu().numpy().tolist()\n                output = sum(output, [])\n            \n                for i in range(len(output)):\n                    if output[i] >= 0:\n                        output[i] = int(1)\n                    else:\n                        output[i] = int(0)\n                \n                try:\n                    auc_val.append(roc_auc_score(y, output))\n                    acc_val.append(accuracy_score(y, output))\n                except ValueError:\n                    pass\n\n            auc_val = np.mean(auc_val)\n            acc_val = np.mean(acc_val)\n         \n        if best_auc < auc_val:\n            best_auc = auc_val\n            torch.save(model.state_dict(), f'./best_us_model-epoch-{epoch+1}.pth')\n            print(\"This model is saved.\")\n    \n    \n        auc_fin_tr.append(auc_tr_eph)\n        acc_fin_tr.append(acc_tr_eph)\n        auc_fin_val.append(auc_val)\n        acc_fin_val.append(acc_val)\n        los_fin_train.append(running_loss_tr)\n        los_fin_test.append(running_loss_test)\n        \n        print(f'Epoch: {epoch} \\n  Train loses = {running_loss_tr}, \\n Train accur = {acc_tr_eph}, \\n \\\n        Train AUC = {auc_tr_eph} \\n Val loses = {running_loss_test}, \\n \\\n        Val accur = {acc_val} \\n Val AUC = {auc_val}, ') \n        scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T16:37:39.123274Z","iopub.execute_input":"2021-08-14T16:37:39.123737Z","iopub.status.idle":"2021-08-14T16:37:39.164408Z","shell.execute_reply.started":"2021-08-14T16:37:39.123691Z","shell.execute_reply":"2021-08-14T16:37:39.163057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train(df, valid_data, model = model, learning_rate = 0.001, num_epochs = 5, max_num = 256)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/usmodel5epoch/new_SETI_us_5epoch.pth'))","metadata":{"execution":{"iopub.status.busy":"2021-08-14T16:37:39.166197Z","iopub.execute_input":"2021-08-14T16:37:39.166824Z","iopub.status.idle":"2021-08-14T16:37:46.833877Z","shell.execute_reply.started":"2021-08-14T16:37:39.166776Z","shell.execute_reply":"2021-08-14T16:37:46.832735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Second NN\n<a id=\"section-two\"></a>","metadata":{}},{"cell_type":"code","source":"#prepare data for training second NN\noverrsample = RandomOverSampler(sampling_strategy=1)\nX_train, y_train = overrsample.fit_resample(X_train.reshape(-1,1), y_train)\nX_train = X_train.reshape(-1,)\n\ndf1 = pd.DataFrame({'image': X_train,\n                      'target': y_train})\ndf1 = df1.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T21:21:05.153014Z","iopub.execute_input":"2021-08-12T21:21:05.153401Z","iopub.status.idle":"2021-08-12T21:21:05.232974Z","shell.execute_reply.started":"2021-08-12T21:21:05.153369Z","shell.execute_reply":"2021-08-12T21:21:05.231912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class make_tensor1:\n    \n    def __init__(self, images, labels):\n        self.image = images\n        self.label = labels\n        \n    def __len__(self):\n        return len(self.image)\n\n    def __getitem__(self, idx):\n        im = np.load(self.image[idx])\n        lb = self.label[idx]\n        sample = {\"image\":  torch.tensor(im, dtype=torch.float), \n                  \"label\":  torch.tensor(lb).item()}\n            \n        return sample","metadata":{"execution":{"iopub.status.busy":"2021-08-08T18:37:07.068134Z","iopub.execute_input":"2021-08-08T18:37:07.068493Z","iopub.status.idle":"2021-08-08T18:37:07.075209Z","shell.execute_reply.started":"2021-08-08T18:37:07.068457Z","shell.execute_reply":"2021-08-08T18:37:07.074226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_data1 = make_tensor1(X_test, y_test)\nvalid_data1 = DataLoader(valid_data1, batch_size=64, shuffle=True, drop_last = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T18:37:07.076868Z","iopub.execute_input":"2021-08-08T18:37:07.077222Z","iopub.status.idle":"2021-08-08T18:37:07.085126Z","shell.execute_reply.started":"2021-08-08T18:37:07.077187Z","shell.execute_reply":"2021-08-08T18:37:07.08398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class common_CNN(nn.Module):\n    def __init__(self, name, output_dim):\n        super(common_CNN, self).__init__()\n        self.model = EfficientNet.from_pretrained(name)\n        self.model._fc = nn.Linear(in_features = self.model._fc.in_features, out_features=output_dim)\n        self.conv =  nn.Conv2d(6, 3, kernel_size=1, stride=1, bias=False)\n        \n        \n    def forward(self, image):\n        image.requires_grad_(True)\n        #image = torch.unsqueeze(image, 1)\n        image = self.conv(image)\n        \n        output = self.model(image)\n        \n        return(output)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T18:37:07.086575Z","iopub.execute_input":"2021-08-08T18:37:07.086962Z","iopub.status.idle":"2021-08-08T18:37:07.095865Z","shell.execute_reply.started":"2021-08-08T18:37:07.086925Z","shell.execute_reply":"2021-08-08T18:37:07.095008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = common_CNN(name = 'efficientnet-b4', output_dim = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T18:37:07.098302Z","iopub.execute_input":"2021-08-08T18:37:07.098669Z","iopub.status.idle":"2021-08-08T18:37:07.467602Z","shell.execute_reply.started":"2021-08-08T18:37:07.098635Z","shell.execute_reply":"2021-08-08T18:37:07.466603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training of the first NN model\n<a id=\"section-twoB\"></a>\n","metadata":{}},{"cell_type":"code","source":"best_model_wts = []\nauc_fin_tr = []\nacc_fin_tr = []\nauc_fin_val = []\nacc_fin_val = []\nlos_fin_test = []\n\n\ndef common_train(df,x_valid, model, epoch = 1, max_num = 256, learning_rate = 0.0001):\n    loss_fn = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    scheduler = StepLR(optimizer, step_size = 1, gamma=0.1, verbose=True) \n    best_auc = 0\n    \n    for ep in range(epoch):\n        start = -max_num\n        end = 0\n        auc_tr = []\n        acc_tr = []\n    \n        for batch_counter in tqdm.tqdm(range(int(len(df)/max_num)),position=0, leave=True, desc='Load batch'):\n            #print(\"Batch counter:\", batch_counter, 'from', int(len(df)/max_num))\n            start += max_num\n            end += max_num\n            \n            x = df['image'][start:end].values \n            y = df['target'][start:end].values\n                \n            x_train = make_tensor1(x,y)\n            x_train = DataLoader(x_train, batch_size=32, shuffle=True, drop_last = True)\n            del(x, y)\n            \n            auc_tr_mb = []\n            acc_tr_mb = []\n            \n            model.train()\n            for data in tqdm.tqdm(x_train, position=0, leave=True, desc='Training'):\n                model.zero_grad()\n                x = data['image']\n                y = data['label']\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device, dtype=torch.float)\n        \n                output =  model(x)\n                loss = loss_fn(output, torch.unsqueeze(y, 1))\n                loss.backward()\n                optimizer.step()\n            \n                y = torch.unsqueeze(y, 1).detach().cpu().numpy().tolist()\n                output = output.detach().cpu().numpy().tolist()\n                output = sum(output, [])\n            \n                for i in range(len(output)):\n                    if output[i] >= 0:\n                        output[i] = int(1)\n                    else:\n                        output[i] = int(0)\n                 \n                try:\n                    auc_tr_mb.append(roc_auc_score(y, output))\n                    acc_tr_mb.append(accuracy_score(y, output))\n                except ValueError:\n                    pass\n                                     \n            \n            auc_tr.append(np.mean(auc_tr_mb))\n            acc_tr.append(np.mean(acc_tr_mb))\n        \n        auc_tr_eph = np.mean(auc_tr)\n        acc_tr_eph = np.mean(acc_tr)\n    \n        del(auc_tr, acc_tr)\n        \n        auc_val = []\n        acc_val = []\n        running_loss_test = 0\n    \n        model.eval()\n        with torch.no_grad():   \n            for data in tqdm.tqdm(x_valid, position=0, leave=True, desc='Testing'):\n                x = data['image']\n                y = data['label']\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device, dtype=torch.float)\n            \n                output =  model(x)\n                #print('Выход валидации: ', output[:3] )\n                loss = loss_fn(output, torch.unsqueeze(y, 1))\n                running_loss_test += loss.item()\n                y = torch.unsqueeze(y, 1).detach().cpu().numpy().tolist()\n                output = output.detach().cpu().numpy().tolist()\n                output = sum(output, [])\n            \n                for i in range(len(output)):\n                    if output[i] >= 0:\n                        output[i] = int(1)\n                    else:\n                        output[i] = int(0)\n                \n                try:\n                    auc_val.append(roc_auc_score(y, output))\n                    acc_val.append(accuracy_score(y, output))\n                except ValueError:\n                    pass\n        \n            auc_val = np.mean(auc_val)\n            acc_val = np.mean(acc_val)\n         \n        if best_auc < auc_val:\n            best_auc = auc_val\n            torch.save(model.state_dict(), f'./com_model_epoh{ep+6}.pth')\n            print(\"This model is saved.\")\n    \n    \n        auc_fin_tr.append(auc_tr_eph)\n        acc_fin_tr.append(acc_tr_eph)\n        auc_fin_val.append(auc_val)\n        acc_fin_val.append(acc_val)\n        los_fin_test.append(running_loss_test)\n        \n        print(f'Epoch: {ep+1} \\n Train accur = {acc_tr_eph}, \\n \\\n        Train AUC = {auc_tr_eph} \\n Val loses = {running_loss_test}, \\n \\\n        Val accur = {acc_val} \\n Val AUC = {auc_val}') \n        scheduler.step()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#common_train(df = df1,x_valid = valid_data1, model = model1, learning_rate = 0.0001, epoch = 1, max_num = 512)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.load_state_dict(torch.load('../input/com-model-epoch1/com_model_epoh1.pth'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Random Forest prediction\n<a id=\"section-three\"></a>","metadata":{}},{"cell_type":"code","source":"#Create Data Frame where each column is prediction of first and second NN\nfeature0 = []\nfeature1 = []\nfeature2 = []\nfeature3 = []\nfeature4 = []\nfeature5 = []\nfeature6 = []\ntarget = []\n\ndef feature_table(x, y, model, model1):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model1.to(device)\n    \n    valid = make_tensor1(x, y)\n    valid = DataLoader(valid, batch_size=64, shuffle=False, drop_last = False)\n    \n    with torch.no_grad():\n        model.eval()\n        model1.eval()\n        for data in valid:\n            \n            x = data[\"image\"]\n            y = data['label']\n            x = x.to(device, dtype=torch.float)\n            y = y.to(device, dtype=torch.float)\n            target.extend(y.tolist())\n            \n            output =  model1(x)\n                \n            output = torch.sigmoid(output)\n            output = output.reshape(-1,) \n            feature0.extend(output.tolist())\n            \n            \n            for im in x:\n                temp = []\n                for sub_im in im:\n                    sep_im = sub_im.cpu().numpy().astype(np.float32)\n                    sep_im = cv2.resize(src = sep_im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                    temp.append(sep_im)\n                    \n                in_put = make_tensor(temp, y[range(6)])\n                in_put = DataLoader(in_put, batch_size=6, shuffle=False, drop_last = False)\n                    #sep_im = torch.tensor(sep_im, dtype=torch.float)\n                    #sep_im  = torch.unsqueeze(sep_im , 0)\n                    \n                out = model(next(iter(in_put))['image'].to(device, dtype=torch.float))\n                out = out.reshape(-1,) \n                out = torch.sigmoid(out)\n                for n in range(6):\n                    globals()[\"feature{}\".format(n+1)].append(out[n].item())\n            \n    \n    feature_df1 = pd.DataFrame(data= zip(feature1, feature2, feature3, feature4, feature5,\n                                      feature6, target),columns=['feature1', 'feature2','feature3', \n                                                          'feature4', 'feature5', 'feature6', 'target'])\n    \n    feature_df1.insert(0, value = feature0, column = 'feature0')\n    \n    return feature_df1","metadata":{"execution":{"iopub.status.busy":"2021-08-08T18:37:15.667786Z","iopub.execute_input":"2021-08-08T18:37:15.668086Z","iopub.status.idle":"2021-08-08T18:37:15.684056Z","shell.execute_reply.started":"2021-08-08T18:37:15.66806Z","shell.execute_reply":"2021-08-08T18:37:15.681375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature_df = feature_table(x = X_test, y = y_test, model = model, model1 = model1)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T15:13:08.644545Z","iopub.execute_input":"2021-08-08T15:13:08.644858Z","iopub.status.idle":"2021-08-08T15:16:26.418329Z","shell.execute_reply.started":"2021-08-08T15:13:08.644828Z","shell.execute_reply":"2021-08-08T15:16:26.417336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_df = pd.read_csv('../input/feature-df-5us-1com/feature_df_5us_1com.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T18:39:39.724406Z","iopub.execute_input":"2021-08-08T18:39:39.724777Z","iopub.status.idle":"2021-08-08T18:39:39.746713Z","shell.execute_reply.started":"2021-08-08T18:39:39.724746Z","shell.execute_reply":"2021-08-08T18:39:39.745854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use GridSearch to find best parametrs for Random Forest Classifier\n\nparam_grid = { \n    'n_estimators': [150, 350],\n    'max_features': [4,5,6,7],\n    'max_depth' : [5, 10, 15, None],\n    'min_samples_split': [2, 3, 7, 10],\n    'bootstrap' : [True],\n    'criterion' :['gini', 'entropy']\n}\n\n\n#rf = RandomForestClassifier(random_state=0, n_jobs = -1)\n#clf = GridSearchCV(rf, param_grid, cv = 3, refit='AUC')\n#clf.fit(feature_df.iloc[:, 0:7], feature_df['target'])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-08T18:39:51.15394Z","iopub.execute_input":"2021-08-08T18:39:51.15427Z","iopub.status.idle":"2021-08-08T19:08:23.355759Z","shell.execute_reply.started":"2021-08-08T18:39:51.154239Z","shell.execute_reply":"2021-08-08T19:08:23.354773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nclf = pickle.load(open('../input/forest-5us-1com/forest_5us_1com.sav', 'rb'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(feature_df.target, clf.predict(feature_df.iloc[:, 0:7]))\ncm","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:08:23.35749Z","iopub.execute_input":"2021-08-08T19:08:23.357903Z","iopub.status.idle":"2021-08-08T19:08:23.476104Z","shell.execute_reply.started":"2021-08-08T19:08:23.357863Z","shell.execute_reply":"2021-08-08T19:08:23.475269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(feature_df.target, clf.predict(feature_df.iloc[:, 0:7]))","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:08:23.47807Z","iopub.execute_input":"2021-08-08T19:08:23.47863Z","iopub.status.idle":"2021-08-08T19:08:23.594299Z","shell.execute_reply.started":"2021-08-08T19:08:23.478588Z","shell.execute_reply":"2021-08-08T19:08:23.593476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CatBoost\n<a id=\"section-four\"></a>","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\ncatb = CatBoostClassifier(random_state=42,\n                                 thread_count=4,\n                                 verbose=False,\n                                 loss_function='Logloss',\n                                 od_type=\"Iter\",\n                                 early_stopping_rounds=500,\n                                 iterations=5000)\ncatb.fit(feature_df.iloc[:, 0:7], feature_df['target'])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:08:23.617201Z","iopub.execute_input":"2021-08-08T19:08:23.617713Z","iopub.status.idle":"2021-08-08T19:08:44.628911Z","shell.execute_reply.started":"2021-08-08T19:08:23.617616Z","shell.execute_reply":"2021-08-08T19:08:44.628033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SUBMISSION\n<a id=\"section-five\"></a>","metadata":{}},{"cell_type":"markdown","source":"prepare data for submission","metadata":{}},{"cell_type":"code","source":"#prepare data for submission\npath = []\nid = []\narr = os.listdir('../input/seti-breakthrough-listen/test')\nfor folder in arr:\n    content = os.listdir(f'../input/seti-breakthrough-listen/test/{folder}')\n    for t in range(len(content)):\n        path.append(f'../input/seti-breakthrough-listen/test/{folder}/{content[t]}')\n        id.append(content[t][:-4])\nsubmission = pd.DataFrame(data = zip(id, path), columns = ['id','im_path'])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:08:45.261187Z","iopub.execute_input":"2021-08-08T19:08:45.261537Z","iopub.status.idle":"2021-08-08T19:08:48.02626Z","shell.execute_reply.started":"2021-08-08T19:08:45.261484Z","shell.execute_reply":"2021-08-08T19:08:48.025388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature0_sub = []\nfeature1_sub = []\nfeature2_sub = []\nfeature3_sub = []\nfeature4_sub = []\nfeature5_sub = []\nfeature6_sub = []\n\ndef feature_table_sub(x, model, model1):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model1.to(device)\n    y = np.zeros(len(submission))\n    \n    valid = make_tensor1(x, y)\n    valid = DataLoader(valid, batch_size=64, shuffle=False, drop_last = False)\n    \n    with torch.no_grad():\n        model.eval()\n        model1.eval()\n        for data in valid:\n            \n            x = data[\"image\"]\n            x = x.to(device, dtype=torch.float)\n            \n            output =  model1(x)\n                \n            output = torch.sigmoid(output)\n            output = output.reshape(-1,) \n            feature0_sub.extend(output.tolist())\n            \n            \n            for im in x:\n                temp = []\n                for sub_im in im:\n                    sep_im = sub_im.cpu().numpy().astype(np.float32)\n                    sep_im = cv2.resize(src = sep_im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                    temp.append(sep_im)\n                \n                in_put = make_tensor(temp, y[range(6)])\n                in_put = DataLoader(in_put, batch_size=6, shuffle=False, drop_last = False)\n                    #sep_im = torch.tensor(sep_im, dtype=torch.float)\n                    #sep_im  = torch.unsqueeze(sep_im , 0)\n                \n                out = model(next(iter(in_put))['image'].to(device, dtype=torch.float))\n                out = out.reshape(-1,) \n                out = torch.sigmoid(out)\n                for n in range(6):\n                    globals()[\"feature{}_sub\".format(n+1)].append(out[n].item())\n            \n    \n    feature_df1_sub = pd.DataFrame(data= zip(feature1_sub, feature2_sub, feature3_sub, feature4_sub,\n                                             feature5_sub,feature6_sub),columns=['feature1', 'feature2','feature3', \n                                                          'feature4', 'feature5', 'feature6'])\n    \n    feature_df1_sub.insert(0, value = feature0_sub, column = 'feature0')\n    \n    return feature_df1_sub","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:08:48.028414Z","iopub.execute_input":"2021-08-08T19:08:48.028704Z","iopub.status.idle":"2021-08-08T19:08:48.04362Z","shell.execute_reply.started":"2021-08-08T19:08:48.028677Z","shell.execute_reply":"2021-08-08T19:08:48.041959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature_df_sub = feature_table_sub(submission.im_path, model = model, model1 = model1)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:08:48.045102Z","iopub.execute_input":"2021-08-08T19:08:48.045471Z","iopub.status.idle":"2021-08-08T20:09:41.83625Z","shell.execute_reply.started":"2021-08-08T19:08:48.045433Z","shell.execute_reply":"2021-08-08T20:09:41.830658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_df_sub = pd.read_csv('../input/df-sub-5us-1-com/df_sub_5us_1com.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_df_sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submis1 = catb.predict_proba(feature_df_sub.iloc[:, 0:7])[:,1]\nsubmis2 = clf.predict_proba(feature_df_sub.iloc[:, 0:7])[:,1]\nsubmis = (submis1 + submis2)/2\n\nsub_cat_forest_5us_1com = pd.DataFrame({'id': submission.id,\n                    'target' : submis2})\nsub_cat_forest_5us_1com.to_csv('forest_5us_1com.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}