{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport os\nimport time\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, AdamW, get_scheduler","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"config = {\n    'fold_num': 5,\n    'seed': 1234,\n    #'model': 'roberta-base',\n    #'model': '../input/robertalarge',\n    'model': 'allenai/longformer-base-4096',\n    #'model': 'allenai/longformer-large-4096',\n    'max_len': 1024,\n    'epochs': 5,\n    'train_bs': 6,\n    'valid_bs': 16,\n    'lr': 3e-5,\n    'num_workers': 0,\n    'weight_decay': 1e-2,\n    'num_warmup_steps': 1000,\n    'lr_scheduler_type': 'linear',\n    'gradient_accumulation_steps': 1,\n}\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim',\n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\nlabels2index = {\n    'Lead': 1, 'Position': 3, 'Claim': 5, 'Counterclaim': 7, 'Rebuttal': 9, 'Evidence': 11, 'Concluding Statement': 13\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nset_seed(config['seed'])\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Train Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain_df.head(2)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_names, train_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n    train_names.append(f.replace('.txt', ''))\n    with open('../input/feedback-prize-2021/train/' + f, 'r', encoding='utf-8') as f:\n        text = ''\n        for line in f.readlines():\n            #text += line.replace('\\n', '').replace('\\xa0', '')\n            text += line.replace('\\n', ' ')\n        train_texts.append(text)\ntrain_texts = pd.DataFrame({'id': train_names, 'text': train_texts})\ntrain_texts['text'] = train_texts['text'].apply(lambda x: x.split())","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_texts = train_texts.sort_values(by='id').reset_index(drop=True)\ntrain_df = train_df.sort_values(by=['id', 'discourse_start']).reset_index(drop=True)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_index = dict.fromkeys(train_texts['id'].values.tolist())\nfor i in range(len(train_df)):\n    id = train_df.iloc[i]['id']\n    if not text_index[id]:\n        text_index[id] = [i]\n    else:\n        text_index[id].append(i)\n    if (i+1) % 20000 == 0:\n        print(\"Processed {0} discourses.\".format(i+1))","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"taggings = []\nessays = 0\nfor i in range(len(train_texts)):\n    text_id = train_texts.iloc[i]['id']\n    text = train_texts.iloc[i]['text']\n    tagging = [0] * config['max_len']\n    for k in text_index[text_id]:\n        if train_df.iloc[k]['id'] != train_texts.iloc[i]['id']:\n            break\n\n        discourse_type = train_df.iloc[k]['discourse_type']\n        predictionstring = train_df.iloc[k]['predictionstring'].split(' ')\n        label = labels2index[discourse_type]\n        if int(predictionstring[0]) > config['max_len'] - 2:\n            break\n        else:\n            tagging[int(predictionstring[0]) + 1] = label\n        for m in range(int(predictionstring[0]) + 2, int(predictionstring[-1]) + 2):\n            if m > config['max_len'] - 2:\n                break\n            else:\n                tagging[m] = label + 1\n    tagging[-1] = 0\n    taggings.append(tagging)\n    essays += 1\n    if essays % 2000 == 0:\n        print(\"Processed {0} essays.\".format(essays))","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"is_executing":true,"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_texts['tagging'] = taggings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config['model'], add_prefix_space=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, phase='Train'):\n        self.df = df\n        self.phase = phase\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        text = self.df.text.values[idx]\n        if self.phase == 'Train':\n            label = self.df.tagging.values[idx]\n            return {'text': text, 'label': label}\n        else:\n            return {'text': text}\n\n\ndef collate_fn(data):\n    input_ids, attention_mask = [], []\n    text = [item['text'] for item in data]\n    tokenized_inputs = tokenizer(\n        text,\n        max_length=config['max_len'],\n        padding='max_length',\n        truncation=True,\n        is_split_into_words=True,\n        return_tensors='pt'\n    )\n\n    words = []\n    for i in range(len(data)):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        words.append(word_ids)\n\n    tokenized_inputs[\"word_ids\"] = words\n    if 'label' in data[0].keys():\n        label = [item['label'] for item in data]\n        tokenized_inputs['labels'] = torch.LongTensor(label)\n\n    return tokenized_inputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = MyDataset(train_texts, phase='Train')\ntrain_iter = DataLoader(train_dataset, batch_size=config['train_bs'], collate_fn=collate_fn, shuffle=False,\n                        num_workers=config['num_workers'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Model and Prepare Optimizer and LR Scheduler","metadata":{}},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(config['model'], num_labels=15).to(device)\n\n\nno_decay = [\"bias\", \"LayerNorm.weight\"]\noptimizer_grouped_parameters = [\n    {\"params\": [p for n, p in model.named_parameters()\n                if not any(nd in n for nd in no_decay)],\n     \"weight_decay\": config['weight_decay'],\n     },\n    {\"params\": [p for n, p in model.named_parameters()\n                if any(nd in n for nd in no_decay)],\n     \"weight_decay\": 0.0,\n     },\n]\noptimizer = AdamW(optimizer_grouped_parameters,\n                  lr=config['lr'],\n                  betas=(0.9, 0.999),\n                  eps=1e-6\n                  )\nlr_scheduler = get_scheduler(\n    name=config['lr_scheduler_type'],\n    optimizer=optimizer,\n    num_warmup_steps=config['num_warmup_steps'],\n    num_training_steps=config['epochs'] * len(train_iter) /  config['gradient_accumulation_steps'], )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start Training!","metadata":{}},{"cell_type":"code","source":"tk = tqdm(train_iter, total=len(train_iter), position=0, leave=True)\nmodel.train()\nstep = 0\nfor epoch in range(config['epochs']):\n    losses = []\n    print(\"Epoch {}/{}\".format(epoch+1, config['epochs']))\n    for batch in tk:\n        batch = {k: v.to(device) for k, v in batch.items() if k != 'word_ids'}\n        loss = model(input_ids=batch['input_ids'],\n                     attention_mask=batch['attention_mask'],\n                     labels=batch['labels']).loss\n        loss /= config['gradient_accumulation_steps']\n        loss.backward()\n        if (step + 1) % config['gradient_accumulation_steps'] == 0:\n            optimizer.step()\n            lr_scheduler.step()\n            optimizer.zero_grad()\n\n        step += 1\n        losses.append(loss.item() * config['gradient_accumulation_steps'])\n    # print average loss\n    print(\"Epoch {}/{}  Average Training Loss:{:6f}\".format(\n        epoch+1,\n        config['epochs'],\n        np.mean(losses)))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save Model","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(f'./roberta_trained')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(config['model'], num_labels=15).to(device)\nmodel.load_state_dict(torch.load('./roberta_trained/pytorch_model.bin'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Test Data","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\ntest_df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n    test_names.append(f.replace('.txt', ''))\n    with open('../input/feedback-prize-2021/test/' + f, 'r', encoding='utf-8') as f:\n        text = ''\n        for line in f.readlines():\n            #text += line.replace('\\n', '').replace('\\xa0', '')\n            text += line.replace('\\n', ' ')\n        test_texts.append(text)\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\ntest_texts['text'] = test_texts['text'].apply(lambda x: x.split())\ntest_texts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = MyDataset(test_texts, phase='Test')\ntest_iter = DataLoader(test_dataset, batch_size=config['valid_bs'], collate_fn=collate_fn, shuffle=False,\n                        num_workers=config['num_workers'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"y_pred = []\nwords = []\n\nwith torch.no_grad():\n    model.eval()\n    tk = tqdm(test_iter, total=len(test_iter), position=0, leave=True)\n    for step, batch in enumerate(tk):\n        word_ids = batch['word_ids']\n        words.extend(word_ids)\n        batch = {k: v.to(device) for k, v in batch.items() if k != 'word_ids'}\n\n        output = model(input_ids=batch['input_ids'],\n                       attention_mask=batch['attention_mask']).logits\n\n        y_pred.extend(output.argmax(-1).cpu().numpy())\n        \ny_pred = np.array(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = []\n\nfor i in tqdm(range(len(test_texts))):\n    idx = test_texts.id.values[i]\n    pred = ['']*len(y_pred[i]-2)\n\n    for j in range(1, len(y_pred[i])):\n        pred[j-1] = labels[y_pred[i][j]]\n\n    pred = [x.replace('B-','').replace('I-','') for x in pred]\n    \n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n        if cls == 'O':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'O' and cls != '' and end - j > 10:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end\n        \nfinal_preds[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}