{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Code taken from [https://www.kaggle.com/abhishek/bert-multi-lingual-tpu-training-8-cores-w-valid](http://) and modified for this comeptetion. Thank you [Abhishek](http://www.kaggle.com/abhishek) :)"},{"metadata":{},"cell_type":"markdown","source":"# Prolouge:\n### Welcome to my kaggle adventures of learning how to use a tpu in kaggle. Let's learn together.\nHey there, This is a kernel to teach you how to train on a tpu in kaggle on all cores parellely. This a work in progress kernel as I will keep it updating as I learn new things!  "},{"metadata":{},"cell_type":"markdown","source":"### Torch XLA setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for TPU\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch > /dev/null\n!pip install albumentations > /dev/null","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imports required for TPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport torch_xla\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.data_parallel as dp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.test.test_utils as test_utils\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport operator\nfrom PIL import Image \nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom torchvision.transforms import ToTensor, RandomHorizontalFlip, Resize\nfrom efficientnet_pytorch import EfficientNet\nfrom transformers import AdamW, get_cosine_schedule_with_warmup\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensor\nfrom tqdm import tqdm\nimport json\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = '../input/plant-pathology-2020-fgvc7/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(BASE_DIR +'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### make training labels by taking argmax\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['image_id'] = BASE_DIR + 'images/' + train_df['image_id'] + '.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['label'] = [np.argmax(label) for label in train_df[['healthy','multiple_diseases','rust','scab']].values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple PyTorch Training\n\n1. In this part let's try simple pytorch model and train it for 20 epochs straight without CV.\n2. The model of my choice is: 'EfficientNet-b5'.\n3. Parellely training on all 8 cores"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SimpleDataset(Dataset):\n    def __init__(self, image_ids_df, labels_df, transform=None):\n        self.image_ids = image_ids_df\n        self.labels = labels_df\n        self.transform = transform\n        \n    def __getitem__(self, idx):\n        image = cv2.imread(self.image_ids.values[idx])\n        label = self.labels.values[idx]\n        \n        sample = {\n            'image': image,\n            'label': label\n        }\n        \n        if self.transform:\n            sample = self.transform(**sample)\n        \n        image, label = sample['image'], sample['label']\n        \n        return image, label\n    \n    def __len__(self):\n        return len(self.image_ids)\n    \n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_ids = train_df['image_id']\nlabels = train_df['label']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the dataset:\nI split the datset simply using sklearn's train_test_split()"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(image_ids, labels, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = Compose(\n    [\n        Resize(224, 224),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n#         ShiftScaleRotate(rotate_limit=25.0, p=0.7),\n#         OneOf(\n#             [\n#                 IAAEmboss(p=1),\n#                 IAASharpen(p=1),\n#                 Blur(p=1)\n#             ], \n#             p=0.5\n#         ),\n#         IAAPiecewiseAffine(p=0.5),\n        Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225), always_apply=True),\n        ToTensor()\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = EfficientNet.from_pretrained('efficientnet-b5', num_classes=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# My observations:\n1. torch.xla has it's own specific requirements. U can't simply make a device using `xm.xla_device()` and pass the model to it. \n<br/><br/>\nWith that:\n    1. Optimizer has to stepped with `xm.optimizer_step(optimizer)`.\n    2. You have to save the model with `xm.save(model.state_dict(), '<your-model-name>)`\n    3. You have to use `xm.master_print(...)` to print. This you can try for yourself below. Try to change \n       the `xm.master_print(f'Batch: {batch_idx}, loss: {loss.item()}')` in the training function(`train_fn()`) to simple \n       `print(f'Batch: {batch_idx}, loss: {loss.item()}')`. You will see it deos not get printed.\n    4. For parellel training we first define the distributed train & valid sampler, then we wrap the dataloaders in `torch_xla.distributed.parallel_loader(<your-data-loader>)` and create a `torch_xla.distributed.parallel_loader` object \n    5. While passing it to training and validation function we specify this `para_loader.per_device_loader(device)`. This is what you will iterate over in the training function, i.e. we pass a parelleloader and not a dataloader (for parellel training only)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def _run(model):\n     \n    def train_fn(epoch, train_dataloader, optimizer, criterion, scheduler, device):\n\n        running_loss = 0\n        total = 0\n        model.train()\n\n        for batch_idx, (images, labels) in enumerate(train_dataloader, 1):\n\n            optimizer.zero_grad()\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n\n            loss = criterion(outputs, labels)\n\n            xm.master_print(f'Batch: {batch_idx}, loss: {loss.item()}')\n\n            loss.backward()\n            xm.optimizer_step(optimizer)\n\n            lr_scheduler.step()\n\n    def valid_fn(epoch, valid_dataloader, criterion, device):\n\n        running_loss = 0\n        total = 0\n        preds_acc = []\n        labels_acc = []\n\n        model.eval()\n\n        for batch_idx, (images, labels) in enumerate(valid_dataloader, 1):\n\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n\n            loss = criterion(outputs, labels)\n            \n            xm.master_print(f'Batch: {batch_idx}, loss: {loss.item()}')\n\n            running_loss += loss.item()\n    \n    \n    EPOCHS = 20\n    BATCH_SIZE = 64\n    \n    train_dataset = SimpleDataset(X_train, y_train, transform=train_transform)\n    valid_dataset = SimpleDataset(X_test, y_test, transform=train_transform)\n    \n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n          train_dataset,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=True)\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n          valid_dataset,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=False)\n\n    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=1)\n    valid_dataloader = DataLoader(valid_dataset, batch_size=32, sampler=valid_sampler, num_workers=1)\n    \n    device = xm.xla_device()\n    model = model.to(device)\n    \n    lr = 0.4 * 1e-5 * xm.xrt_world_size()\n    criterion = nn.CrossEntropyLoss()\n    \n    optimizer = AdamW(model.parameters(), lr=lr)\n    num_train_steps = int(len(train_dataset) / BATCH_SIZE / xm.xrt_world_size() * EPOCHS)\n    xm.master_print(f'num_train_steps = {num_train_steps}, world_size={xm.xrt_world_size()}')\n    num_train_steps = int(len(train_dataset) / BATCH_SIZE * EPOCHS)\n    lr_scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=0,\n        num_training_steps=num_train_steps\n    )\n    \n    train_loss = []\n    valid_loss = []\n    best_loss = 1\n    \n    train_begin = time.time()\n    for epoch in range(EPOCHS):\n        \n        para_loader = pl.ParallelLoader(train_dataloader, [device])\n\n        start = time.time()\n        print('*'*15)\n        print(f'EPOCH: {epoch+1}')\n        print('*'*15)\n\n        print('Training.....')\n        train_fn(epoch=epoch+1, \n                                  train_dataloader=para_loader.per_device_loader(device), \n                                  optimizer=optimizer, \n                                  criterion=criterion,\n                                  scheduler=lr_scheduler,\n                                  device=device)\n\n\n        \n        with torch.no_grad():\n            \n            para_loader = pl.ParallelLoader(valid_dataloader, [device])\n            \n            print('Validating....')\n            valid_fn(epoch=epoch+1, \n                                      valid_dataloader=para_loader.per_device_loader(device), \n                                      criterion=criterion, \n                                      device=device)\n            xm.save(\n                model.state_dict(),\n                f'efficientnet-b0-bs-8.pt'\n            )\n    \n        print(f'Epoch completed in {(time.time() - start)/60} minutes')\n    print(f'Training completed in {(time.time() - train_begin)/60} minutes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Below cell is what makes the model train on all 8 cores! Run yourself to see the magic"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Start training processes\ndef _mp_fn(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    a = _run(model)\n\nFLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"# Epilouge: \n\n1. With parellely running on all 8 cores, my training time was 15 minutes (20 epochs) with a batch size of 64 for training and 32 for validation, as opposed to 1 hr on my local device (which has a gtx 1050 with 4 gb memory) with a batch size of 8 for both training and validation. Okay I get it, it's not a fair comparison as we have a more powerful gpu on kaggle, but I am guessing you get what I am trying to say. :P  \n2. This kernel was for me to keep as a future reference, but I want to share it with all of you. You are the ones from whom I learn so much.\n3. About the accuracy and inference that I haven't done and I am currently working on. I just ran it once to see how long it takes. :P\n\nYou're free to correct me, make suggestions and tell me on what I can improve on. :) \nLastly if u found it any useful please consider to upvote :)\n\nAlso for more information: [Torch XLA documentation](https://pytorch.org/xla/release/1.5/index.html#)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":4}