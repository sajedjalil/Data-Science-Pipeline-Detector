{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Steps I would be following\n\n1. Understand what I need to do\n2. Load and visualize the data\n3. EDA on the dataset\n3. Choose the architecture (do the research)\n5. Train and validate the achitecture\n6. Test the architecture"},{"metadata":{},"cell_type":"markdown","source":"### What I need to do?\n\n1. Accurately classify an image into different diseased category or a healthy leaf\n2. Accurately distinguish between many diseases, sometimes more than one on a leaf\n3. Deal with the rare classes and novel symptoms \n4. Address depth perception, angle, light, shade, physiological age of the leaf\n5. ncorporate expert knowledge in identification, annotation, quantification, and guiding computer vision to search for relevant features during learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the depedencies\n\nimport time\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom collections import OrderedDict\n\nimport cv2 as cv\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models, transforms\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the CSV files"},{"metadata":{"trusted":true},"cell_type":"code","source":"root = '/kaggle/input/plant-pathology-2020-fgvc7/'\ntrain = pd.read_csv(os.path.join(root,'train.csv'))\ntest = pd.read_csv(os.path.join(root,'test.csv'))\nsubmission = pd.read_csv(os.path.join(root,'sample_submission.csv'))\nimages = os.path.join(root,'images')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(images,typ):\n    fig = plt.figure(figsize=(16,4))\n    num = len(images)\n    for i in range(num):\n        a = fig.add_subplot(1,num,i+1)\n        a.set_title(typ,fontsize=10)\n        image = imread(os.path.join(root,'images',images[i]))\n        plt.imshow(image)\n        plt.axis('off')\n        \ncol = ['healthy','multiple_diseases','rust','scab']\nprint(col)\n\nfor column in col:\n    images = (train[train[column].apply(lambda x: x==1)]['image_id'].sample(4).values)+'.jpg'\n    show_images(images,column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading the data into the dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_path(image):\n    return os.path.join(root,'images',str(image)+'.jpg')\n\ntrain_data = train.copy()\ntrain_data['image_path'] = train_data['image_id'].apply(get_path)\ntrain_labels = train.loc[:,'healthy':'scab']\n\ntest_data = test.copy()\ntest_data['image_path'] = test_data['image_id'].apply(get_path)\ntest_paths = test_data['image_path']\n\ntrain_paths,valid_paths,train_labels,valid_labels = train_test_split(train_data['image_path'],train_labels,test_size=0.2,random_state=23,stratify=train_labels)\n\ntrain_paths.reset_index(drop=True,inplace=True)\ntrain_labels.reset_index(drop=True,inplace=True)\nvalid_paths.reset_index(drop=True,inplace=True)\nvalid_labels.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transformations on the image dataset\nmytransform = {\n    'train': A.Compose([\n        A.RandomResizedCrop(height=256,width=256,p=1.0),\n        A.Flip(),\n        A.ShiftScaleRotate(rotate_limit=1.0,p=0.8),\n        A.Normalize(p=1.0),\n        ToTensorV2(p=1.0),\n    ]),\n    'validation': A.Compose([\n        A.RandomResizedCrop(height=256,width=256,p=1.0),\n        A.Normalize(p=1.0),\n        ToTensorV2(p=1.0),\n    ])\n    \n}\n\n#custom dataset loader\nclass ImageDataset(torch.utils.data.Dataset):\n    def __init__(self,image_path,labels=None,test=False,transform=None):\n        super().__init__()\n        self.image_path = image_path\n        self.test = test\n        if self.test == False:\n            self.labels = labels\n            \n        self.images_transforms = transform\n        \n    def __getitem__(self,index):\n        if self.test == False:\n            labels = self.labels.loc[index,['healthy', 'multiple_diseases', 'rust', 'scab']].values\n            labels = torch.from_numpy(labels.astype(np.uint8))\n            labels = labels.unsqueeze(-1)\n            \n        image = cv.imread(self.image_path[index])\n        image = cv.cvtColor(image,cv.COLOR_BGR2RGB)\n        image_transformed = self.images_transforms(image=image)\n            \n        if self.test ==False:\n            return image_transformed['image'], labels\n            \n        return image_transformed['image']\n        \n    def __len__(self):\n        return self.image_path.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nepochs = 20 \nTRAIN_SIZE = train_labels.shape[0]\nVALID_SIZE = valid_labels.shape[0]\nlearning_rate = 5e-5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the dataset into the dataloaders"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_images = ImageDataset(image_path=train_paths, labels=train_labels, transform=mytransform[\"train\"])\ntrain_loader = torch.utils.data.DataLoader(train_images, shuffle=True, batch_size = BATCH_SIZE)\n\nvalid_images = ImageDataset(image_path=valid_paths, labels=valid_labels, transform=mytransform[\"validation\"])\nvalid_loader = torch.utils.data.DataLoader(valid_images, shuffle=False, batch_size = BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, labels =next(iter(train_loader))\nprint(images[1].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n\nfor param in model.parameters():\n    param.require_grad = False\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_ftrs = model.fc.in_features\nmodel.fc = nn.Sequential(nn.Linear(num_ftrs,512),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.3),\n                        nn.Linear(512,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DenseCrossEntropy(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n    def forward(self,logits,labels):\n        logits = logits.float()\n        labels = labels.float()\n        \n        logprobs = F.log_softmax(logits,dim=1)\n        \n        loss =-labels*logprobs\n        loss = loss.sum(-1)\n        \n        return loss.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and Validating "},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import optim\ncriterion = DenseCrossEntropy()\noptimizer = optim.Adam(model.parameters(),lr=learning_rate)\nnum_classes = torch.tensor([0,1,2,3])\nfrom sklearn.metrics import roc_auc_score\n\ntraining_loss = []\nvalidation_loss = []\nepochs = 20\nmodel.to(device)\nmin_val_loss = np.Inf\nto_break = 0\nfor e in range(epochs):\n    model.train()\n    train_loss = 0\n    for images,labels in train_loader:\n        images,labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        output = model(images)\n        \n\n        loss = criterion(output,labels.squeeze(-1))\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()*labels.shape[0]\n        \n    model.eval()\n    valid_loss = 0\n    for images, labels in valid_loader:\n        images, labels = images.to(device), labels.to(device)\n        output = model(images)\n        loss = criterion(output,labels.squeeze(-1))\n        valid_loss += loss.item()*labels.shape[0]\n        \n    print(f'{e+1}/{epochs}... Training Loss {train_loss/len(train_loader)}.... Validation Loss {valid_loss/len(valid_loader)}')\n    if min_val_loss >= valid_loss:\n        min_val_loss = valid_loss\n        torch.save(model.state_dict(),'checkpoiny.pth')\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing on the validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nmodel.to('cpu')\nscore = []\nmodel.eval()\nfor images, labels in valid_loader:\n    output = model(images)\n    preds = torch.softmax(output,dim=1).data\n    preds = preds.numpy()\n    labels = labels.numpy()\n    try:\n        val= roc_auc_score(labels.squeeze(-1),preds,average='macro')\n        score.append(val)\n        print(val)\n    except:\n        pass\n    \nprint('roc score: ',sum(score)/len(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = ImageDataset(image_path=test_paths,test=True, transform=mytransform[\"validation\"])\ntest_loader = torch.utils.data.DataLoader(test_images, shuffle=False, batch_size = BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds =None\nsubmission_df = pd.read_csv(os.path.join(root,\"sample_submission.csv\"))\nmodel.eval()\nmodel.to(device)\nfor  images in test_loader:\n    images = images.to(device)\n    with torch.no_grad():\n        output = model(images)\n        \n        if test_preds is None:\n            test_preds = output.data.cpu()\n        \n        else:\n            test_preds = torch.cat((test_preds,output.data.cpu()),dim=0)\n\nsubmission_df[['healthy','multiple_diseases','rust','scab']] = torch.softmax(test_preds,dim=1)\nsubmission_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), 'checkpoint.pth')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This notebook was able to achieve the score of 0.94167"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}