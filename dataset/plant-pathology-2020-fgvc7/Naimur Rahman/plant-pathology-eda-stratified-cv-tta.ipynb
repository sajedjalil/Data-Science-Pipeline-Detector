{"cells":[{"metadata":{},"cell_type":"markdown","source":"![image](https://i.pinimg.com/originals/c9/2f/c9/c92fc9abdcb11028dd0448d36c580f83.jpg)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Key Features :\n> * TPU as the accelerator\n* Efficient Architecture\n* EfficientNetB3 as a base model\n* Tensorflow's Data Augmentation\n* Focal Loss and Label Smoothening\n* Bilinear Layer\n* F1 Score\n* 'imagenet' and 'noisy-student' as weights\n* Stratified K-fold Cross-Validation\n* Test Time Augmentation (TTA)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Dependencies","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras import optimizers\nfrom kaggle_datasets import KaggleDatasets\nimport efficientnet.tfkeras as efn\nimport random\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport hashlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.models import model_from_json, Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Convolution2D,Activation,MaxPooling2D,Flatten,Dense,Dropout,Input,Reshape,Lambda\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Seeding","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* If one wants to generate a sequence of random numbers and then be able to reproduce that same sequence of random numbers later one can set the random number seed generator with set.seed(). This is a critical aspect of reproducible research.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed=13):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['TF_KERAS'] = '1'\n    random.seed(seed)\n    \nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* TPU expedites the ability of training speed. For more, you can have a look at this [documentation.](https://www.kaggle.com/docs/tpu)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## TPU Configuration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def TPU():\n    # Detect hardware, return appropriate distribution strategy\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    else:\n        strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n    return strategy\n\n\nstrategy = TPU()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* load input path by means of TPU","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nAUTO = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE_h = 512 \nIMG_SIZE_w = 512\nFOLDS = 5\nSEED = 42\nEPOCHS = 50\nBATCH_SIZE = 8*strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Path Delineation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Items\npath='../input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(path+'train.csv')\ntrain_id = train['image_id']\ntrain.pop('image_id')\n\ny_train = train.to_numpy().astype('float32')\ncategory_names = ['healthy','multiple_diseases','rust','scab']\nroot = 'images'\n\nimages_paths = [(os.path.join(GCS_DS_PATH,root,idee+'.jpg')) for idee in train_id]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_INPUT = '/kaggle/input/plant-pathology-2020-fgvc7'\ntrain_df = pd.read_csv(DIR_INPUT + '/train.csv')\ntest_df = pd.read_csv(DIR_INPUT + '/test.csv')\ncols = list(train_df.columns[1:])\n\ntrain_paths = train_df['image_id'].apply(lambda x: os.path.join(GCS_DS_PATH , 'images' , x + '.jpg')).values\ntest_paths = test_df['image_id'].apply(lambda x: os.path.join(GCS_DS_PATH , 'images' , x + '.jpg')).values\n\ntrain_labels = train_df.iloc[:,1:].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"(len(train_df), len(test_df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* It seems like both(train and test) data frames have the same size, but how different categories contribute in the training dataset?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LABEL_COLS = ['healthy', 'multiple_diseases', 'rust', 'scab']\n\n_, axes = plt.subplots(ncols=4, nrows=1, constrained_layout=True, figsize=(10, 3))\nfor ax, column in zip(axes, LABEL_COLS):\n    train_df[column].value_counts().plot.bar(title=column, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Label distribution')\ntrain_df[LABEL_COLS].idxmax(axis=1).value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how many times the labels appear together.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.iloc[:,1:-1].sum(axis=1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['healthy', 'multiple_diseases', 'rust', 'scab']].sum(axis=1).unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like never. So this appears to be multiclass but not multilabel classification. I copied few code fragments from this well-articulated [EDA Notebook](https://www.kaggle.com/pestipeti/eda-plant-pathology-2020). From where I got several insights that will unravel whether I should use k-fold or stratified k-fold cross fold and whether there are any noisy/duplicate images or not.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Image Metadata","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_hash(im):\n    md5 = hashlib.md5()\n    md5.update(np.array(im).tostring())\n    \n    return md5.hexdigest()\n    \ndef get_image_meta(image_id, image_src, dataset='train'):\n    im = Image.open(image_src)\n    extrema = im.getextrema()\n\n    meta = {\n        'image_id': image_id,\n        'dataset': dataset,\n        'hash': calculate_hash(im),\n        'r_min': extrema[0][0],\n        'r_max': extrema[0][1],\n        'g_min': extrema[1][0],\n        'g_max': extrema[1][1],\n        'b_min': extrema[2][0],\n        'b_max': extrema[2][1],\n        'height': im.size[0],\n        'width': im.size[1],\n        'format': im.format,\n        'mode': im.mode\n    }\n    return meta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\n\nfor i, image_id in enumerate(tqdm(train_df['image_id'].values, total=train_df.shape[0])):\n    data.append(get_image_meta(image_id, DIR_INPUT + '/images/{}.jpg'.format(image_id)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, image_id in enumerate(tqdm(test_df['image_id'].values, total=test_df.shape[0])):\n    data.append(get_image_meta(image_id, DIR_INPUT + '/images/{}.jpg'.format(image_id), 'test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_df = pd.DataFrame(data)\nmeta_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Orientations\n\nIt looks like we have both portrait and landscape modes in the train and the test set as well. The image size is always 2048x1368px (or 1365x2048).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_df.groupby(by='dataset')[['width', 'height']].aggregate(['min', 'max'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* I will resize the image later.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Duplications\nWe have a few duplications:\n\n* train Train_379 and Train_1173\n* test Test_683 and Test_1691\n* test Test_570 and Test_1212\n* mixed Train_1703 and Test_1407\n* mixed Train_1505 and Test_829","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicates = meta_df.groupby(by='hash')[['image_id']].count().reset_index()\nduplicates = duplicates[duplicates['image_id'] > 1]\nduplicates.reset_index(drop=True, inplace=True)\n\nduplicates = duplicates.merge(meta_df[['image_id', 'hash']], on='hash')\n\nduplicates.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5, 2, figsize=(8, 16))\nax = ax.flatten()\n\nfor i in range(0, min(duplicates.shape[0], 10), 2):\n    image_i = cv2.imread(DIR_INPUT + '/images/{}.jpg'.format(duplicates.iloc[i, 2]), cv2.IMREAD_COLOR)\n    image_i = cv2.cvtColor(image_i, cv2.COLOR_BGR2RGB)\n    ax[i].set_axis_off()\n    ax[i].imshow(image_i)\n    ax[i].set_title(duplicates.iloc[i, 2])\n    \n    image_i_1 = cv2.imread(DIR_INPUT + '/images/{}.jpg'.format(duplicates.iloc[i + 1, 2]), cv2.IMREAD_COLOR)\n    image_i_1 = cv2.cvtColor(image_i_1, cv2.COLOR_BGR2RGB)\n    ax[i + 1].set_axis_off()\n    ax[i + 1].imshow(image_i_1)\n    ax[i + 1].set_title(duplicates.iloc[i + 1, 2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The image is the same. I must use Cross-Validation; otherwise, overfitting may occur.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Target Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(image_ids):\n    \n    col = 5\n    row = min(len(image_ids) // col, 5)\n    \n    fig, ax = plt.subplots(row, col, figsize=(16, 8))\n    ax = ax.flatten()\n\n    for i, image_id in enumerate(image_ids):\n        image = cv2.imread(DIR_INPUT + '/images/{}.jpg'.format(image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        ax[i].set_axis_off()\n        ax[i].imshow(image)\n        ax[i].set_title(image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Pie(labels=train_df.columns[1:],\n           values=train_df.iloc[:, 1:].sum().values)\n])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As the label distribution is not the same, I must use stratified k-fold cross-validation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Random Images","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### from train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(train_df.sample(n=15)['image_id'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### from test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(test_df.sample(n=15)['image_id'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Healthy Images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(train_df[train_df['healthy'] == 1].sample(n=15)['image_id'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Infected with Rust","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(train_df[train_df['rust'] == 1].sample(n=15)['image_id'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Have Scab","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(train_df[train_df['scab'] == 1].sample(n=15)['image_id'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multiple Diseases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(train_df[train_df['multiple_diseases'] == 1].sample(n=15)['image_id'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Needed Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_train(train_paths, train_labels):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((train_paths, train_labels))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .map(data_augment, num_parallel_calls=AUTO)\n        .repeat()\n        .shuffle(512)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n    return data\n\ndef prepare_val(val_paths, val_labels):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((val_paths, val_labels))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n    return data\n\ndef prepare_test(test_paths):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((test_paths))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n    )\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(IMG_SIZE_h, IMG_SIZE_w)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    #convert to numpy and do some cv2 staff mb?\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None, seed=5050):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n    image = tf.image.random_crop(image,size=[IMG_SIZE_h,IMG_SIZE_w,3],seed=seed )\n    image = tf.image.random_brightness(image,max_delta=0.5, seed=seed )\n           \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* To know what I've done in the following four cells, you might read this awesome [notebook](https://www.kaggle.com/jimitshah777/bilinear-efficientnet-focal-loss-label-smoothing)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### i)Focal Loss + Label Smoothing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.25,ls=0.1,classes=4.0):\n    \"\"\"\n    Implementation of Focal Loss from the paper in multiclass classification\n    Formula:\n        loss = -alpha*((1-p)^gamma)*log(p)\n        y_ls = (1 - Î±) * y_hot + Î± / classes\n    Parameters:\n        alpha -- the same as wighting factor in balanced cross entropy\n        gamma -- focusing parameter for modulating factor (1-p)\n        ls    -- label smoothing parameter(alpha)\n        classes     -- No. of classes\n    Default value:\n        gamma -- 2.0 as mentioned in the paper\n        alpha -- 0.25 as mentioned in the paper\n        ls    -- 0.1\n        classes     -- 4\n    \"\"\"\n    def focal_loss(y_true, y_pred):\n        # Define epsilon so that the backpropagation will not result in NaN\n        # for 0 divisor case\n        epsilon = K.epsilon()\n        # Add the epsilon to prediction value\n        #y_pred = y_pred + epsilon\n        #label smoothing\n        y_pred_ls = (1 - ls) * y_pred + ls / classes\n        # Clip the prediction value\n        y_pred_ls = K.clip(y_pred_ls, epsilon, 1.0-epsilon)\n        # Calculate cross entropy\n        cross_entropy = -y_true*K.log(y_pred_ls)\n        # Calculate weight that consists of  modulating factor and weighting factor\n        weight = alpha * y_true * K.pow((1-y_pred_ls), gamma)\n        # Calculate focal loss\n        loss = weight * cross_entropy\n        # Sum the losses in mini_batch\n        loss = K.sum(loss, axis=1)\n        return loss\n    \n    return focal_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ii) BiLinear Layer (outer_product())","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def outer_product(x):\n    #Einstein Notation  [batch,1,1,depth] x [batch,1,1,depth] -> [batch,depth,depth]\n    phi_I = tf.einsum('ijkm,ijkn->imn',x[0],x[1])\n    \n    # Reshape from [batch_size,depth,depth] to [batch_size, depth*depth]\n    phi_I = tf.reshape(phi_I,[-1,x[0].shape[3]*x[1].shape[3]])\n    \n    # Divide by feature map size [sizexsize]\n    size1 = int(x[1].shape[1])\n    size2 = int(x[1].shape[2])\n    phi_I = tf.divide(phi_I, size1*size2)\n    \n    # Take signed square root of phi_I\n    y_ssqrt = tf.multiply(tf.sign(phi_I),tf.sqrt(tf.abs(phi_I)+1e-12))\n    \n    # Apply l2 normalization\n    z_l2 = tf.nn.l2_normalize(y_ssqrt, axis=1)\n    return z_l2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### iii)F1 Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Denoting My Base Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![image](https://1.bp.blogspot.com/-oNSfIOzO8ko/XO3BtHnUx0I/AAAAAAAAEKk/rJ2tHovGkzsyZnCbwVad-Q3ZBnwQmCFsgCEwYBhgL/s1600/image3.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* I'm going to use the efficient net as I said earlier. As the accuracies of base models provided by EfficientNet architecture are much better in contrast with others, I'm going to use them accordingly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    \n    input_tensor = Input(shape=(IMG_SIZE_h,IMG_SIZE_w,3))\n    \n    model1 = efn.EfficientNetB3(weights='imagenet', include_top=False, input_tensor=input_tensor,input_shape=(IMG_SIZE_h, IMG_SIZE_w, 3))\n    model2 = efn.EfficientNetB3(weights='noisy-student', include_top=False, input_tensor=input_tensor,input_shape=(IMG_SIZE_h, IMG_SIZE_w, 3))\n    \n    for i, layer in enumerate(model1.layers):\n        layer._name = 'model1_' + layer.name\n\n    last_layer1 = model1.get_layer('model1_top_conv')\n    last_output1 = last_layer1.output\n\n    for i, layer in enumerate(model2.layers):\n        layer._name = 'model2_' + layer.name\n\n    last_layer2 = model2.get_layer('model2_top_conv')\n    last_output2 = last_layer2.output\n    \n    \n    model1_ = Model(inputs=model1.input, outputs=last_output1)\n    model2_ = Model(inputs=model2.input, outputs=last_output2)\n   \n    \n    model1_.compile(Adam(lr=0.0003, decay=1e-3),loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0))\n    model2_.compile(Adam(lr=0.0003, decay=1e-3),loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0))\n    \n    d1=model1_.output\n    d2=model2_.output\n\n    bilinear = Lambda(outer_product, name='outer_product1')([d1,d2])\n    \n    predictions=Dense(4, activation='softmax', name='predictions')(bilinear)\n    model = Model(inputs=model1.input, outputs=predictions)\n    \n    opt = Adam(lr=0.0003, decay=1e-3)\n    model.compile(optimizer=opt, loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0),metrics=[f1,'categorical_accuracy'])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Callbacks():\n    erl = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', \n                        restore_best_weights=True)\n    rdc = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='min')\n    return [erl,rdc]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\ntest_pred = []\nval_roc_auc = []\n\nfor i, (train_idx, val_idx) in enumerate(skf.split(train_paths, train_labels.argmax(1))):\n    print(); print('#'*25)\n    print('###      FOLD',i+1)\n    print('#'*25)\n    X_train, X_val = train_paths[train_idx], train_paths[val_idx]\n    y_train, y_val = train_labels[train_idx], train_labels[val_idx]\n    \n    strategy = TPU()\n    with strategy.scope():\n        model = get_model()\n        history = model.fit(\n                    prepare_train(X_train,y_train),\n                    steps_per_epoch=y_train.shape[0] // BATCH_SIZE,\n                    validation_data=prepare_val(X_val, y_val),\n                    validation_steps=y_val.shape[0] // BATCH_SIZE,\n                    callbacks=Callbacks(),\n                    epochs=EPOCHS,\n                    verbose=1\n                )\n\n    test_pred.append(model.predict(prepare_test(test_paths), verbose=1))\n    val_roc_auc.append(roc_auc_score(y_val,model.predict(prepare_val(X_val, y_val), verbose=1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing and Saving Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"Model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"Model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import model_from_json\n\n# load json and create model\njson_file = open('Model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"Model.h5\")\n# loaded_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_roc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_test = 0\nfor i in range(FOLDS):\n    all_test += test_pred[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#If I want to predict on particular test_pred\n\n#best_2_models = test_pred[0]*.7 + test_pred[3]*.3\n#best_2_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_models = all_test/FOLDS\nall_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_2_models gives me better score on LB\nsumb = pd.read_csv('../input/plant-pathology-2020-fgvc7/sample_submission.csv')\n#sumb.iloc[:,1:] = best_2_models \nsumb.iloc[:,1:] = all_models\nsumb.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sumb.to_csv('submission.csv', index=False)\npd.Series(np.argmax(sumb[cols].values,axis=1)).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess for TTA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df,test=False):\n    paths = df.image_id.apply(lambda x: GCS_DS_PATH + '/images/' + x + '.jpg').values\n    labels = df.loc[:,'healthy':].values\n    if test==False:\n        return paths,labels\n    else:\n        return paths","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Time Augmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TTA = 4\n\ntest_pred_tta = np.zeros((len(test_df),4))\nfor i in range(TTA):\n    test_dataset_tta = (tf.data.Dataset\n    .from_tensor_slices(preprocess(test_df,test=True))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)    \n    .batch(BATCH_SIZE))\n    test_pred_tta += model.predict(test_dataset_tta, verbose=1)\nsumb = pd.read_csv(DIR_INPUT + '/sample_submission.csv')\nsumb[['healthy', 'multiple_diseases', 'rust', 'scab']] = test_pred_tta/TTA\nsumb.to_csv('submission_TTA.csv', index=False)\npd.Series(np.argmax(sumb[cols].values,axis=1)).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sumb.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color='#774633'>I very much appreciate the time you spent on reading this notebook. Please let me know if I messed up anything. Thank You! ðŸ™‚ </font>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}