{"cells":[{"metadata":{},"cell_type":"markdown","source":"## In this notebook, we will perform transfer learning and ensembling with EfficientNet to perform image classification for the Plant Pathology 2020 - FGVC7 competition.\n\nThis is a straightforward tutorial in PyTorch! <span style=\"color:red\">Please upvote if you found this useful :)</span>\n\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip install efficientnet_pytorch\n\nfrom efficientnet_pytorch import EfficientNet\n\nimport torch\nimport torch.utils.data as Data\nimport torch.nn as nn\nfrom torchvision import transforms, models\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom scipy.special import softmax\nimport cv2\nfrom transformers import get_cosine_schedule_with_warmup\nfrom transformers import AdamW\nfrom tqdm.notebook import tqdm\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensor\nimport gc\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize a leaf of each category\n\nThe categories include \"healthy\", \"scab\", \"rust\", and \"multiple diseases\". Solving this problem is important because diagnosing plant diseases early can save tonnes of agricultural produce every year. This will benefit not only the general population by reducing hunger, but also the farmers by ensuring they get the harvest they deserve.\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"im_healthy = plt.imread('../input/plant-pathology-2020-fgvc7/images/Train_2.jpg', format = 'jpg')\nim_multi = plt.imread('../input/plant-pathology-2020-fgvc7/images/Train_1.jpg', format = 'jpg')\nim_rust = plt.imread('../input/plant-pathology-2020-fgvc7/images/Train_3.jpg', format = 'jpg')\nim_scab = plt.imread('../input/plant-pathology-2020-fgvc7/images/Train_0.jpg', format = 'jpg')\n\nfig = plt.figure(figsize=(16,10))\nax = fig.add_subplot(2, 2, 1)\nax.imshow(im_healthy)\nax.set_title('Healthy', fontsize = 20)\n\nax = fig.add_subplot(2, 2, 2)\nax.imshow(im_multi)\nax.set_title('Multiple Diseases', fontsize = 20)\n\nax = fig.add_subplot(2, 2, 3)\nax.imshow(im_rust)\nax.set_title('Rust', fontsize = 20)\n\nax = fig.add_subplot(2, 2, 4)\nax.imshow(im_scab)\nax.set_title('Scab', fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load image paths and labels into DataFrame\n\nThe dataset images are loaded, resized to the desired size and saved as .npy files. This allows them to be loaded up really fast, preventing the data loading process from bottlenecking the GPU training.\n\n[The .npy files can be accessed here](http://www.kaggle.com/dataset/cbf0d20bb9deea2b794018659843387bd18e2a8638fae654e996c2b660cfdffb)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_FOLDER = '../input/plant-pathology-npy-images/kaggle/working/image_pickles/'\n\ndef get_image_path(filename):\n    return (IMAGE_FOLDER + filename + '.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\n\ntrain['image_path'] = train['image_id'].apply(get_image_path)\ntest['image_path'] = test['image_id'].apply(get_image_path)\ntrain_labels = train.loc[:, 'healthy':'scab']\ntrain_paths = train.image_path\ntest_paths = test.image_path","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create train-validation split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(train_paths, train_labels, test_size = 0.2, random_state=23, stratify = train_labels)\ntrain_paths.reset_index(drop=True,inplace=True)\ntrain_labels.reset_index(drop=True,inplace=True)\nvalid_paths.reset_index(drop=True,inplace=True)\nvalid_labels.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a custom dataset class\n\nTransforms for data augmentation are defined here.\n\nWe use Albumentations library instead of Torchvision transforms because:\n* It is faster.\n* It can operate on NumPy arrays directly instead of PIL Images.\n* It has more options for transformations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class LeafDataset(Data.Dataset):\n    def __init__(self, image_paths, labels = None, train = True, test = False):\n        self.paths = image_paths\n        self.test = test\n        if self.test == False:\n            self.labels = labels\n        self.train = train\n        self.train_transform = Compose([HorizontalFlip(p=0.5),\n                                  VerticalFlip(p=0.5),\n                                  ShiftScaleRotate(rotate_limit=25.0, p=0.7),\n                                  OneOf([IAAEmboss(p=1),\n                                         IAASharpen(p=1),\n                                         Blur(p=1)], p=0.5),\n                                  IAAPiecewiseAffine(p=0.5)])\n        self.test_transform = Compose([HorizontalFlip(p=0.5),\n                                       VerticalFlip(p=0.5),\n                                       ShiftScaleRotate(rotate_limit=25.0, p=0.7)])\n        self.default_transform = Compose([Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225), always_apply=True),\n                                         ToTensor()]) #normalized for pretrained network\n        \n    def __len__(self):\n        return self.paths.shape[0]\n    \n    def __getitem__(self, i):\n        image = np.load(self.paths[i]) #load from .npy file!\n        if self.test==False:\n            label = torch.tensor(np.argmax(self.labels.loc[i,:].values)) #loss function used later doesnt take one-hot encoded labels, so convert it using argmax\n        if self.train:\n            image = self.train_transform(image=image)['image']\n            image = self.default_transform(image=image)['image']\n        elif self.test:\n            image = self.test_transform(image=image)['image']\n            image = self.default_transform(image=image)['image']\n        else:\n            image = self.default_transform(image=image)['image']\n        \n        if self.test==False:\n            return image, label\n        return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define training, validation and test functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fn(net, loader):\n    \n    running_loss = 0\n    preds_for_acc = []\n    labels_for_acc = []\n    \n    pbar = tqdm(total = len(loader), desc='Training')\n    \n    for _, (images, labels) in enumerate(loader):\n        \n        images, labels = images.to(device), labels.to(device)\n        net.train()\n        optimizer.zero_grad()\n        predictions = net(images)\n        loss = loss_fn(predictions, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        running_loss += loss.item()*labels.shape[0]\n        labels_for_acc = np.concatenate((labels_for_acc, labels.cpu().numpy()), 0)\n        preds_for_acc = np.concatenate((preds_for_acc, np.argmax(predictions.cpu().detach().numpy(), 1)), 0)\n        \n        pbar.update()\n        \n    accuracy = accuracy_score(labels_for_acc, preds_for_acc)\n    \n    pbar.close()\n    return running_loss/TRAIN_SIZE, accuracy\n\ndef valid_fn(net, loader):\n    \n    running_loss = 0\n    preds_for_acc = []\n    labels_for_acc = []\n    \n    pbar = tqdm(total = len(loader), desc='Validation')\n    \n    with torch.no_grad():       #torch.no_grad() prevents Autograd engine from storing intermediate values, saving memory\n        for _, (images, labels) in enumerate(loader):\n            \n            images, labels = images.to(device), labels.to(device)\n            net.eval()\n            predictions = net(images)\n            loss = loss_fn(predictions, labels)\n            \n            running_loss += loss.item()*labels.shape[0]\n            labels_for_acc = np.concatenate((labels_for_acc, labels.cpu().numpy()), 0)\n            preds_for_acc = np.concatenate((preds_for_acc, np.argmax(predictions.cpu().detach().numpy(), 1)), 0)\n            \n            pbar.update()\n            \n        accuracy = accuracy_score(labels_for_acc, preds_for_acc)\n        conf_mat = confusion_matrix(labels_for_acc, preds_for_acc)\n    \n    pbar.close()\n    return running_loss/VALID_SIZE, accuracy, conf_mat\n\ndef test_fn(net, loader):\n\n    preds_for_output = np.zeros((1,4))\n    \n    with torch.no_grad():\n        pbar = tqdm(total = len(loader))\n        for _, images in enumerate(loader):\n            images = images.to(device)\n            net.eval()\n            predictions = net(images)\n            preds_for_output = np.concatenate((preds_for_output, predictions.cpu().detach().numpy()), 0)\n            pbar.update()\n    \n    pbar.close()\n    return preds_for_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initialize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 8\nNUM_EPOCHS = 30\nTRAIN_SIZE = train_labels.shape[0]\nVALID_SIZE = valid_labels.shape[0]\nMODEL_NAME = 'efficientnet-b5'\ndevice = 'cuda'\nlr = 8e-4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = LeafDataset(train_paths, train_labels)\ntrainloader = Data.DataLoader(train_dataset, shuffle=True, batch_size = BATCH_SIZE, num_workers = 2)\n\nvalid_dataset = LeafDataset(valid_paths, valid_labels, train = False)\nvalidloader = Data.DataLoader(valid_dataset, shuffle=False, batch_size = BATCH_SIZE, num_workers = 2)\n\ntest_dataset = LeafDataset(test_paths, train = False, test = True)\ntestloader = Data.DataLoader(test_dataset, shuffle=False, batch_size = BATCH_SIZE, num_workers = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EfficientNetB5\n\nB5 is the largest EfficientNet variant that fits in GPU memory with batch size 8.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = EfficientNet.from_pretrained(MODEL_NAME)\n\nnum_ftrs = model._fc.in_features\nmodel._fc = nn.Sequential(nn.Linear(num_ftrs,1000,bias=True),\n                          nn.ReLU(),\n                          nn.Dropout(p=0.5),\n                          nn.Linear(1000,4, bias = True))\n\nmodel.to(device)\noptimizer = AdamW(model.parameters(), lr = lr, weight_decay = 1e-3)\nnum_train_steps = int(len(train_dataset) / BATCH_SIZE * NUM_EPOCHS)\nscheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=len(train_dataset)/BATCH_SIZE*5, num_training_steps=num_train_steps)\nloss_fn = torch.nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Main training loop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss = []\nvalid_loss = []\ntrain_acc = []\nval_acc = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    \n    tl, ta = train_fn(model, loader = trainloader)\n    vl, va, conf_mat = valid_fn(model, loader = validloader)\n    train_loss.append(tl)\n    valid_loss.append(vl)\n    train_acc.append(ta)\n    val_acc.append(va)\n    \n    if (epoch+1)%10==0:\n        path = 'epoch' + str(epoch) + '.pt'\n        torch.save(model.state_dict(), path)\n    \n    printstr = 'Epoch: '+ str(epoch) + ', Train loss: ' + str(tl) + ', Val loss: ' + str(vl) + ', Train acc: ' + str(ta) + ', Val acc: ' + str(va)\n    tqdm.write(printstr)\n    \n'''Output hidden. Unhide to see training log'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plots of training and validation loss and accuracy","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure()\nplt.ylim(0,1.5)\nsns.lineplot(list(range(len(train_loss))), train_loss)\nsns.lineplot(list(range(len(valid_loss))), valid_loss)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train','Val'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure()\nsns.lineplot(list(range(len(train_acc))), train_acc)\nsns.lineplot(list(range(len(val_acc))), val_acc)\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train','Val'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion matrix\n\nComputed on the validation set on the last epoch","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"labels = ['Healthy', 'Multiple','Rust','Scab']\nsns.heatmap(conf_mat, xticklabels=labels, yticklabels=labels, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Perform inference on test data\n\nTTA (Test Time Augmentation): perform inference on augmented versions of the test data and average the scores.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"subs = []\nfor i in range(5): #average over 5 runs\n    out = test_fn(model, testloader)\n    output = pd.DataFrame(softmax(out,1), columns = ['healthy','multiple_diseases','rust','scab']) #the submission expects probability scores for each class\n    output.drop(0, inplace = True)\n    output.reset_index(drop=True,inplace=True)\n    subs.append(output)\n\nsub_eff1 = sum(subs)/5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1 = sub_eff1.copy()\nsub1['image_id'] = test.image_id\nsub1 = sub1[['image_id','healthy','multiple_diseases','rust','scab']]\nsub1.to_csv('submission_efficientnet1.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clear GPU memory\n\nDelete the model from memory to restart the training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"del model\ndel optimizer\ndel scheduler\ntorch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Second run\n\nCells hidden, it is the same as above.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"model = EfficientNet.from_pretrained(MODEL_NAME)\n\nnum_ftrs = model._fc.in_features\nmodel._fc = nn.Sequential(nn.Linear(num_ftrs,1000,bias=True),\n                          nn.ReLU(),\n                          nn.Dropout(p=0.5),\n                          nn.Linear(1000,4, bias = True))\n\nmodel.to(device)\noptimizer = AdamW(model.parameters(), lr = lr, weight_decay = 1e-3)\nscheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=len(train_dataset)/BATCH_SIZE*5, num_training_steps=num_train_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_loss = []\nvalid_loss = []\ntrain_acc = []\nval_acc = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    \n    tl, ta = train_fn(model, loader = trainloader)\n    vl, va, conf_mat = valid_fn(model, loader = validloader)\n    train_loss.append(tl)\n    valid_loss.append(vl)\n    train_acc.append(ta)\n    val_acc.append(va)\n    \n    if (epoch+1)%10==0:\n        path = 'epoch' + str(epoch) + '.pt'\n        torch.save(model.state_dict(), path)\n    \n    printstr = 'Epoch: '+ str(epoch) + ', Train loss: ' + str(tl) + ', Val loss: ' + str(vl) + ', Train acc: ' + str(ta) + ', Val acc: ' + str(va)\n    tqdm.write(printstr)\n    \n'''Output hidden. Unhide to see training log'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure()\nplt.ylim(0,1.5)\nsns.lineplot(list(range(len(train_loss))), train_loss)\nsns.lineplot(list(range(len(valid_loss))), valid_loss)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train','Val'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure()\nsns.lineplot(list(range(len(train_acc))), train_acc)\nsns.lineplot(list(range(len(val_acc))), val_acc)\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train','Val'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"labels = ['Healthy', 'Multiple','Rust','Scab']\nsns.heatmap(conf_mat, xticklabels=labels, yticklabels=labels, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"subs = []\nfor i in range(5): #average over 5 runs\n    out = test_fn(model, testloader)\n    output = pd.DataFrame(softmax(out,1), columns = ['healthy','multiple_diseases','rust','scab']) #the submission expects probability scores for each class\n    output.drop(0, inplace = True)\n    output.reset_index(drop=True,inplace=True)\n    subs.append(output)\n\nsub_eff2 = sum(subs)/5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sub2 = sub_eff2.copy()\nsub2['image_id'] = test.image_id\nsub2 = sub2[['image_id','healthy','multiple_diseases','rust','scab']]\nsub2.to_csv('submission_efficientnet2.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble process\n\nAverage the predictions from the two models and create submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = (sub_eff1 + sub_eff2)/2\nsub['image_id'] = test.image_id\nsub = sub[['image_id','healthy','multiple_diseases','rust','scab']]\nsub.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *Thanks for reading!*\n\n### <span style=\"color:red\">Please upvote if you found this useful :)</span>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}