{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Image segmentation using Detectron2\n\n## Using Detectron2 and mask R-CNN it is possible to isolate each leaf from the input image and extract the most prominent one for later analysis.\n\n### Steps involved:\n\n* Download and install detectron2 and other dependancies\n\n* Hand annotate images with the objects mask (not covered in this kernel) - google \"labelme\" and \"training detectron2 on custom dataset\" \n\n* Train detectron2 (not covered in this kernel) \n\n* Load pretrained weights into detectron2\n\n* Infer image masks and identifiy prominent objects\n\n* Mask and extract from original image\n\n* Crop and rotate object to fit\n\n![Masked1](https://i.imgur.com/tnC1ljY.jpg \"Masked Leaf 1\")\n\n![Masked](https://i.imgur.com/nemK62H.jpg \"Masked Leaf\")\n\n\n### To Do:\n\n* Futher training of the mask R-CNN model to improve segmentation.\n\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# How to!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Basic recipe for inferance ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### First we will list out all the files in the directory for later use.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Imports","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfile_list = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/plantpathology-apple-dataset'):\n    for filename in filenames:\n        file_list.append(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n!pip install cython pyyaml==5.1\n!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n!gcc --version","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# install detectron2:\n!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the required libraries.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import sys\n#sys.path.append('/content/detectron2_repo')\nimport os\nimport numpy as np\n\nimport math  \nimport detectron2 \nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\nfrom PIL import Image\nimport cv2\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Detectron2 uses pytorch and makes it amazingly easy to retrain its pretrained model on a custom dataset. I won't go into the method of doing this but there is a wealth of information online. \n\n## The python tool \"labelme\" is great for drawing the masks over your images.\n\n![labelme](https://i.imgur.com/phNlpnX.jpg \"Label Me\")\n\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Model Collection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Below code is to download the pretrained weights from my google drive.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport requests\n\ndef download_file_from_google_drive(id, destination):\n    URL = \"https://docs.google.com/uc?export=download\"\n\n    session = requests.Session()\n\n    response = session.get(URL, params = { 'id' : id }, stream = True)\n    token = get_confirm_token(response)\n\n    if token:\n        params = { 'id' : id, 'confirm' : token }\n        response = session.get(URL, params = params, stream = True)\n\n    save_response_content(response, destination)    \n\ndef get_confirm_token(response):\n    for key, value in response.cookies.items():\n        if key.startswith('download_warning'):\n            return value\n\n    return None\n\ndef save_response_content(response, destination):\n    CHUNK_SIZE = 32768\n\n    with open(destination, \"wb\") as f:\n        for chunk in response.iter_content(CHUNK_SIZE):\n            if chunk: # filter out keep-alive new chunks\n                f.write(chunk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## download the pretrained weights for leaf segmentation.\n\nfile_id = '17AHanttKcR9B4A0m7QZqwAvaWxGrYYQp'\ndestination = './model.pth'\ndownload_file_from_google_drive(file_id, destination)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the predictor\ndef get_predictor():\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n    cfg.DATASETS.TRAIN = ()\n    cfg.DATALOADER.NUM_WORKERS = 16\n\n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (8)  # faster, and good enough for this toy dataset\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # 3 classes (data, fig, hazelnut)\n\n    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n    \n    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/kaggle/working/model.pth\")\n    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n    predictor = DefaultPredictor(cfg)\n    return predictor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image manipulations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to get the leaf image.\n\ndef get_cropped_leaf(img,predictor,return_mapping=False,resize=None):\n    #convert to numpy    \n    img = np.array(img)[:,:,::-1]\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    \n    #get prediction\n    outputs = predictor(img)\n    \n    #get boxes and masks\n    ins = outputs[\"instances\"]\n    pred_masks = ins.get_fields()[\"pred_masks\"]\n    boxes = ins.get_fields()[\"pred_boxes\"]    \n    \n    #get main leaf mask if the area is >= the mean area of boxes and is closes to the centre \n    \n    masker = pred_masks[np.argmin([calculateDistance(x[0], x[1], int(img.shape[1]/2), int(img.shape[0]/2)) for i,x in enumerate(boxes.get_centers()) if (boxes[i].area()>=torch.mean(boxes.area()).to(\"cpu\")).item()])].to(\"cpu\").numpy().astype(np.uint8)\n\n    #mask image\n    mask_out = cv2.bitwise_and(img, img, mask=masker)\n    \n    #find contours and boxes\n    contours, hierarchy = cv2.findContours(masker.copy() ,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    contour = contours[np.argmax([cv2.contourArea(x) for x in contours])]\n    rotrect = cv2.minAreaRect(contour)\n    box = cv2.boxPoints(rotrect)\n    box = np.int0(box)\n    \n\n    #crop image\n    cropped = get_cropped(rotrect,box,mask_out)\n\n    #resize\n    rotated = MakeLandscape()(Image.fromarray(cropped))\n    \n    if not resize == None:\n        resized = ResizeMe((resize[0],resize[1]))(rotated)\n    else:\n        resized = rotated\n        \n    if return_mapping:\n        img = cv2.drawContours(img, [box], 0, (0,0,255), 10)\n        img = cv2.drawContours(img, contours, -1, (255,150,), 10)\n        return resized, ResizeMe((int(resize[0]),int(resize[1])))(Image.fromarray(img))\n    \n    return resized\n\n#function to crop the image to boxand rotate\n\ndef get_cropped(rotrect,box,image):\n    \n    width = int(rotrect[1][0])\n    height = int(rotrect[1][1])\n\n    src_pts = box.astype(\"float32\")\n    # corrdinate of the points in box points after the rectangle has been\n    # straightened\n    dst_pts = np.array([[0, height-1],\n                        [0, 0],\n                        [width-1, 0],\n                        [width-1, height-1]], dtype=\"float32\")\n\n    # the perspective transformation matrix\n    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n\n    # directly warp the rotated rectangle to get the straightened rectangle\n    warped = cv2.warpPerspective(image, M, (width, height))\n    return warped\n\ndef calculateDistance(x1,y1,x2,y2):  \n    dist = math.hypot(x2 - x1, y2 - y1)\n    return dist  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image manipulations \n\nclass ResizeMe(object):\n    #resize and center image in desired size \n    def __init__(self,desired_size):\n        \n        self.desired_size = desired_size\n        \n    def __call__(self,img):\n    \n        img = np.array(img).astype(np.uint8)\n        \n        desired_ratio = self.desired_size[1] / self.desired_size[0]\n        actual_ratio = img.shape[0] / img.shape[1]\n\n        desired_ratio1 = self.desired_size[0] / self.desired_size[1]\n        actual_ratio1 = img.shape[1] / img.shape[0]\n\n        if desired_ratio < actual_ratio:\n            img = cv2.resize(img,(int(self.desired_size[1]*actual_ratio1),self.desired_size[1]),None,interpolation=cv2.INTER_AREA)\n        elif desired_ratio > actual_ratio:\n            img = cv2.resize(img,(self.desired_size[0],int(self.desired_size[0]*actual_ratio)),None,interpolation=cv2.INTER_AREA)\n        else:\n            img = cv2.resize(img,(self.desired_size[0], self.desired_size[1]),None, interpolation=cv2.INTER_AREA)\n            \n        h, w, _ = img.shape\n\n        new_img = np.zeros((self.desired_size[1],self.desired_size[0],3))\n        \n        hh, ww, _ = new_img.shape\n\n        yoff = int((hh-h)/2)\n        xoff = int((ww-w)/2)\n        \n        new_img[yoff:yoff+h, xoff:xoff+w,:] = img\n\n        \n        return Image.fromarray(new_img.astype(np.uint8))\n\nclass MakeLandscape():\n    #flip if needed\n    def __init__(self):\n        pass\n    def __call__(self,img):\n        \n        if img.height > img.width:\n            img = np.rot90(np.array(img))\n            img = Image.fromarray(img)\n        return img\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(file_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference Method","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Load the predictor ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor = get_predictor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get Images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img, img1 = get_cropped_leaf(Image.open(\"/kaggle/input/plantpathology-apple-dataset/images/Train_128.jpg\"),predictor,return_mapping=True,resize = (800,int(800)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if img1.height > img1.width:\n    img1 = np.rot90(np.array(img1))\n    img1 = Image.fromarray(img1)\nimg1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nkek = np.array(img)\nkek_mask = np.array(img1)\nplt.imshow(kek)\nplt.show()\nplt.imshow(kek_mask)\nplt.show()\n\nprint(kek.dtype)\nprint(kek_mask.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Display of multiple images stacked","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_image = []\n\nfor x in range(75):\n    #select random image\n    file_loc = file_list[np.random.randint(0,len(file_list))]\n    #get outputs from predictor\n    img, img1 = get_cropped_leaf(Image.open(file_loc),predictor,return_mapping=True,resize = (600,int(600*.65)))\n    #stack horizontally\n    stacked = np.hstack([img,img1])\n    #append images\n    final_image.append(stacked)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in final_image:\n    fig = plt.figure(figsize=(20,10))\n    plt.imshow(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs('images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rmdir 'output'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = 'images/'\n\nfrom tqdm import tqdm\n\nfor i in range(1,len(file_list)):\n    img,img1 = get_cropped_leaf(Image.open(file_list[i]),predictor,return_mapping=True,resize = (800,int(800)))\n    kek = os.path.split(file_list[i])[1]\n    img.save(path+kek) \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im = Image.open('images/train_add_127.jpg')\nim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.path.split(file_list[1])[1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I hope this has been some help to anyone who reads it. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}