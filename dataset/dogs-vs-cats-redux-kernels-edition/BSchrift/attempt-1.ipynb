{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"90eaf568-1a48-c37f-26bd-de793b07d11b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb861484-ed9e-5bfc-30e9-9a7e249271d2"},"outputs":[],"source":"import tensorflow as tf\nimport scipy.misc\nimport os\n\ndef batches(size : int, num : int, dir : str = '../input/train/'):\n    fnames = np.random.permutation(os.listdir(dir))\n    #print(fnames[0:3])\n    i = 0\n    for _ in range(num):\n        batch = []\n        for _ in range(size):\n            batch.append(scipy.misc.imread(dir + fnames[i]))\n            i += 1\n        yield batch\n        "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa452576-5ebf-6256-a1b2-08a5f9f3d4bd"},"outputs":[],"source":"class PetClassNN:\n    def __init__(self):\n        print('...')\n        \n    def build(self, images, train : bool = False):\n        self.x = tf.placeholder(tf.float32)\n        in_w, in_h, n_in_c, n_f = images[0].shape\n        self.conv_1 = self.conv(self.x, in_w, in_h, n_in_c, n_f, name='conv_1')\n        \n    def new_weights(self, shape):\n        print(shape)\n        return tf.Variable(tf.truncated_normal(shape, stddev=0.5))\n\n    def new_biases(self,length):\n        return tf.Variable(tf.constant(0.5, shape=[length]))\n    \n    def conv(self, in_layer, input_width, input_height, num_input_channels, num_filters, name : str, pooling : bool = True):\n        weights = self.new_weights(shape=[input_width, input_height, num_input_channels, num_filters])\n        biases = self.new_biases(length=num_filters)\n        \n        conv = tf.conv2d(in_layer,weights,[1,1,1,1],'SAME',True)\n        conv += biases\n        \n        if pooling:\n            pool = tf.nn.max_pool(value=conv,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n        \n        relu = tf.nn.relu(pool)\n        \n        return relu\n\nbatch = batches(2,2)\nPetClassNN().build(next(batch))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}