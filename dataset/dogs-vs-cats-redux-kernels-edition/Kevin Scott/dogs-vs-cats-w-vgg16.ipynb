{"nbformat_minor":1,"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport cv2                 # working with, mainly resizing, images\nimport numpy as np         # dealing with arrays\nimport os                  # dealing with directories\nfrom random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\nfrom tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BÃ¼hler for this suggestion\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n\n%cd /kaggle/working\n\nTRAIN_DIR = '../input/dogs-vs-cats-redux-kernels-edition/train'\nTEST_DIR = '../input/dogs-vs-cats-redux-kernels-edition/test'\n\n#print(check_output([\"ls\", \"./\"]).decode(\"utf8\"))\n\nIMG_SIZE = 50\nLR = 1e-3\n\n#MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic') # just so we remember which saved model is which, sizes must match","outputs":[],"cell_type":"code","metadata":{"_uuid":"cc070c244403405160c4023979ce35e28f32bc4e","_cell_guid":"93c82a19-bf92-4a75-a769-cee9dbbba7e7"},"execution_count":4},{"source":"def label_img(img):\n    word_label = img.split('.')[-3]\n    # conversion to one-hot array [cat,dog]\n    #                            [much cat, no dog]\n    if word_label == 'cat': return [1]\n    #                             [no cat, very doggo]\n    elif word_label == 'dog': return [0]\n    \ndef create_train_data():\n    training_data = []\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        label = label_img(img)\n        path = os.path.join(TRAIN_DIR,img)\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        \n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        training_data.append([img,label])\n    \n    #cv2.imshow(\"foo\", img)\n    shuffle(training_data)\n    \n    training_data = np.array(training_data)\n    np.save('train_data.npy', training_data)\n    return training_data\n\ndef process_test_data():\n    testing_data = []\n    for img in tqdm(os.listdir(TEST_DIR)):\n        path = os.path.join(TEST_DIR,img)\n        img_num = img.split('.')[0]\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        testing_data.append([np.array(img), img_num])\n        \n    shuffle(testing_data)\n    np.save('test_data.npy', testing_data)\n    return testing_data\n\n\ntrain_data = create_train_data()\ntest_data = process_test_data()\n# If you have already created the dataset:\n#train_data = np.load('train_data.npy')\n#test_data = np.load('test_data.npy')","outputs":[],"cell_type":"code","metadata":{"_uuid":"8e50b666fb34222b8f71acdec84188a8092156f3","_cell_guid":"d60c7add-f6f6-4b2c-8d0a-27415840b2b8"},"execution_count":5},{"source":"from matplotlib import pyplot as plt\n\nfrom PIL import Image\n#plt.imshow(train_data[0][0])\nImage.fromarray(train_data[2][0])","outputs":[],"cell_type":"code","metadata":{"_uuid":"fb5458a7e8ff27d36300471544899b56252477e3","_cell_guid":"3d5012c7-19f8-432e-9567-a810a33af8f4"},"execution_count":6},{"source":"from keras.models import Sequential, Model, load_model\nfrom keras.applications.vgg16 import VGG16\n\nfrom keras import optimizers\nfrom keras.layers import Dropout, Flatten, Dense, Activation\n\nfrom keras.models import Sequential\nfrom keras import utils","outputs":[],"cell_type":"code","metadata":{"_uuid":"ae60c5cbf9c8ad8825dae3e9c80a9e7b9c6448a7","_cell_guid":"7ad8adac-fcaf-483a-a50e-f9d38d3a77d3"},"execution_count":7},{"source":"# Weights for VGG16\nfrom os import listdir, makedirs\nfrom os.path import join, exists, expanduser\n\nimg_rows, img_cols, img_channel = IMG_SIZE, IMG_SIZE, 3\n\nWEIGHTS_DIR = '../input/vgg16'\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\nprint(check_output([\"ls\", WEIGHTS_DIR]).decode(\"utf8\"))\n!cp ../input/vgg16/*notop* ~/.keras/models/\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"695e7a9337aa581c3693f8ec256bfb31c9fef8e6","_cell_guid":"dbe0f870-bb02-445a-93a8-0bbd053fac85"},"execution_count":8},{"source":"train = train_data[:-500]\ntest = train_data[-500:]","outputs":[],"cell_type":"code","metadata":{"_uuid":"bcae10be1e9b5edf45ee0bba18f01c210956a933","collapsed":true,"_cell_guid":"3ec60324-6c0c-48a6-85e4-5622990358bd"},"execution_count":9},{"source":"X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nY = [i[1] for i in train]","outputs":[],"cell_type":"code","metadata":{"_uuid":"90279ef517be5a6ca3664bcadc18c9b17498ad72","collapsed":true,"_cell_guid":"ad76373c-4f2a-486b-a628-ecdeaf122b5e"},"execution_count":10},{"source":"test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\ntest_y = np.array([i[1] for i in test])","outputs":[],"cell_type":"code","metadata":{"_uuid":"0fe93af2dc1d753dd81c56918382ddbf0211c994","collapsed":true,"_cell_guid":"2872278b-0fa3-45b3-ab66-1a63b29c1661"},"execution_count":11},{"source":"from keras import backend as K\n\n#model = VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n#model.add(Activation('relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Flatten())\n#model.add(Dense(64))  # we now have numbers not 'images'\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\n\n    # Output Layer\nmodel.add(Dense(1))\n#model.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\nmodel.fit(X[:600], np.array(Y)[:600], epochs=1, batch_size=600, verbose=1)","outputs":[],"cell_type":"code","metadata":{"_uuid":"a00acf1997d6d6ec3e36862ca7dfd1e9bad0bf56","scrolled":true,"_cell_guid":"4860395d-4fce-4233-88f2-a79a9a7ed0a3"},"execution_count":32},{"source":"from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\nfrom keras.models import Sequential\n\n\ndef shallow_net():\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(32, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    # this converts our 3D feature maps to 1D feature vectors\n    model.add(Flatten())\n\n    model.add(Dense(64))  # we now have numbers not 'images'\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n\n    # Output Layer\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    \n    return model\n\nmodel = shallow_net()\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n#model.summary()\n\n\nmodel.fit(X, np.array(Y), epochs=1, batch_size=6000, verbose=1)\n\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"6f99435d9623b8143a35d775d6ac6c98da41f5f5","_cell_guid":"4b8cd14b-af8f-4ba8-ad9f-eeb9f154f2ab"},"execution_count":13},{"source":"\nimport random\n\nd = random.choice(test_data)\nimg_data, img_num = d\ndata = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\nprediction = model.predict(np.array([data]))[0]\n\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_subplot(111)\nax.imshow(img_data, cmap=\"gray\")\nprint(f\"{prediction[0]}% likelihood it is a cat\")","outputs":[],"cell_type":"code","metadata":{},"execution_count":26},{"source":"","outputs":[],"cell_type":"code","metadata":{"collapsed":true},"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","version":"3.6.4","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"}}},"nbformat":4}