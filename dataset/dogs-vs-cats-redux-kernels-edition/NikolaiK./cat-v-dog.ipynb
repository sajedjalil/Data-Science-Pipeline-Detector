{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2135f09d-953a-c925-4f48-49b3f233770b"},"source":"# Dog vs. Cat Detection\n\n## Import libraries"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd259d66-41ba-4ed8-96a5-3d2ad756d0ee"},"outputs":[],"source":"#Pre do something"},{"cell_type":"markdown","metadata":{"_cell_guid":"6d32a1f6-ce4d-ceac-f1cf-6d56d2605f7a"},"source":"## Import Data\nthe next step is to import the data\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ac2d061-7c82-829b-de97-240a1b3ae2f1"},"outputs":[],"source":"TRAIN_DIR = '../input/train/' #training directory\nTEST_DIR = '../input/test/' #testing directory\n\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"60b97bbf-3812-5b2e-60e3-98b88257d7e1"},"source":"Pre-define a function that will take the labels from the image name (thanks to other kernels on Kaggle)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76003fc7-60d8-7307-f9f9-c36b9f8ee4a6"},"outputs":[],"source":"def label_img(img):\n    word_label = img.split('.')[-3]\n    if word_label == 'cat': return [1,0] #[cat, not dog]\n    elif word_label == 'dog': return [0,1] #[not cat, dog]"},{"cell_type":"markdown","metadata":{"_cell_guid":"0c6afd7b-13b9-4b00-4e2f-82b576115099"},"source":"## Retrieve training data\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e8af393-1893-0bf4-d0b4-88546a295ef5"},"outputs":[],"source":"from tqdm import tqdm      # percentage progress bar\ndef create_train_data():\n    training_data = []\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        label = label_img(img)\n        path = os.path.join(TRAIN_DIR,img)\n        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        training_data.append([np.array(img),np.array(label)])\n    shuffle(training_data)\n    np.save('train_data.npy', training_data)\n    return training_data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d97ff5f-8830-ff83-f684-2b3026294c5a"},"outputs":[],"source":"import cv2\nimport os\nimport numpy as np\nfrom tqdm import tqdm \nIMG_SIZE=50 #Define short image size\n\ndef create_train_data():\n    X = [] #training images\n    Y = [] #training labels\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        label = label_img(img)\n        path=os.path.join(TRAIN_DIR, img)\n        im=cv2.imread(path)\n        sh=im.shape\n        if sh[0] < sh[1]:  # Find the shortest dimension\n            im1=im[0:sh[0],0:sh[0]]\n            im2=im[0:sh[0],(sh[1]-sh[0]):sh[1]]\n            #rint(\"\"\n        else:\n            im1=im[0:sh[1],0:sh[0]]\n            im2=im[(sh[0]-sh[1]):sh[0],0:sh[1]]\n        #Resize images to make them smaller\n        im1 = cv2.resize(im1, (IMG_SIZE,IMG_SIZE))\n        im2 = cv2.resize(im2, (IMG_SIZE,IMG_SIZE))\n        #Append the two images together\n        imn=np.append(im1,im2,axis=0)\n        X.append(np.array(imn))\n        Y.append(np.array(label))\n    return(X,Y)\n    \n"},{"cell_type":"markdown","metadata":{"_cell_guid":"d8b19ef9-746b-31b4-e9a9-d0faeb50cfed"},"source":"Run the new function to create the training data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e469c5a1-b968-0d41-980c-268d0a4150aa"},"outputs":[],"source":"X,Y = create_train_data()\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"2b29abe9-1370-7dee-58d2-7a40207efa4f"},"source":"Try some of the images to make sure what they look like:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"94a189f1-a664-3d81-9f2a-1fa1cbda5224"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport random\nindex=random.randint(0,25000-1)\nplt.imshow(X[index])\nY[index]\nX[index].shape\n\nX, Y = shuffle(X, Y)\nXtrain=X[0:20000-1]\nYtrain=Y[0:20000-1]\nXtest=X[(20000-1):25000-1]\nYtest=Y[(20000-1):25000-1]\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"0c4e1642-cf25-283e-38b1-c2cd76255859"},"source":"## Define the Neural Network\nThis next section will define the neural network for the detector"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e745b294-a800-8f43-f0e0-e0ce924e14bb"},"outputs":[],"source":"import tflearn\nfrom tflearn.data_utils import shuffle, to_categorical\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.estimator import regression\nfrom tflearn.data_preprocessing import ImagePreprocessing\nfrom tflearn.data_augmentation import ImageAugmentation\n\n#Pre-process the images\n# Real-time data preprocessing\nimg_prep = ImagePreprocessing()\nimg_prep.add_featurewise_zero_center()\nimg_prep.add_featurewise_stdnorm()\n\n# Real-time data augmentation\nimg_aug = ImageAugmentation()\nimg_aug.add_random_flip_leftright()\nimg_aug.add_random_rotation(max_angle=25.)\n\n\n# Convolutional network building\nnetwork = input_data(shape=[None, 100, 50, 3], #Define input layer\n                     data_preprocessing=img_prep, #set data_preprocessing\n                     data_augmentation=img_aug)\n\nnetwork = conv_2d(network, 32,3, activation='relu') #convolve data once\nnetwork = max_pool_2d(network,2) #down sample (reduce data)\nnetwork = conv_2d(network, 64, 3, activation='relu')\nnetwork = conv_2d(network, 64, 3, activation='relu')\nnetwork = max_pool_2d(network,2) #down sample (reduce data)\nnetwork = max_pool_2d(network, 2)\nnetwork = fully_connected(network, 512, activation='relu')\nnetwork = dropout(network, 0.5)\nnetwork = fully_connected(network, 2, activation='softmax')\nnetwork = regression(network, optimizer='adam',\n                     loss='categorical_crossentropy',\n                     learning_rate=0.001)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d325747c-d885-b4d6-03f0-8645f9fcb735"},"source":"Run the training iterations repeatedly"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bee3eaa9-767c-9b26-39ff-03ec9e6b394f"},"outputs":[],"source":"#Define the model\nmodel = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='dog-cat.tfl.ckpt')\nmodel.fit(Xtrain, Ytrain, n_epoch=3, \n          shuffle=True, \n          validation_set=(Xtest, Ytest),\n          show_metric=True, \n          batch_size=96, \n          run_id='catvdog')"},{"cell_type":"markdown","metadata":{"_cell_guid":"02bd0cc6-681b-9f8d-2b33-004332f191f9"},"source":"import tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.estimator import regression\n\nconvnet = input_data(shape=[None, 2*IMG_SIZE, IMG_SIZE, 3], name='input')\n\nconvnet = conv_2d(convnet, 32, 5, activation='relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 64, 5, activation='relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = fully_connected(convnet, 1024, activation='relu')\nconvnet = dropout(convnet, 0.8)\n\nconvnet = fully_connected(convnet, 2, activation='softmax')\nconvnet = regression(convnet, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy', name='targets')\n\nmodel = tflearn.DNN(convnet, tensorboard_dir='log')\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"43cfff9e-06b6-371c-4c9d-800e40550c4f"},"source":"model.fit(Xtrain, Ytrain, \n          n_epoch=2, \n          validation_set=(Xtest, Ytest),\n          snapshot_step=50000, \n          show_metric=True, \n          run_id='catvdog')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}