{"nbformat_minor":1,"nbformat":4,"cells":[{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Though the accuracy is less but written this program just for sake of writing the single \n# hidden layer neural network from scratch","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"import cv2\nimport numpy as np \nimport os \nfrom random import shuffle\nfrom tqdm import tqdm\nimport scipy\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"train_directory = \"/Users/Mak/Desktop/dogvscat/train\"\ntest_directory = \"/Users/Mak/Desktop/dogvscat/test\"","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def label_img(img):\n    name = img.split('.')[0]\n    if name == \"dog\":\n        return 1\n    elif name == \"cat\":\n        return 0","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def create_train_data():\n    training_data = []\n    for img in tqdm(os.listdir(train_directory)):\n        label = label_img(img)\n        path = os.path.join(train_directory,img)\n        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (32,32))\n        training_data.append([np.array(img),np.array(label)])\n    shuffle(training_data)\n    np.save('train_data.npy', training_data)\n    return training_data","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def create_test_data():\n    testing_data = []\n    for img in tqdm(os.listdir(test_directory)):\n        img_num = img.split('.')[0]\n        path = os.path.join(test_directory,img)\n        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (32,32))\n        testing_data.append([np.array(img),img_num])\n    shuffle(testing_data)\n    np.save('testing_data.npy', testing_data)\n    return testing_data","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# will only run once if training/test.npy is not created \ndf_train= create_train_data()\ndf_test = create_test_data()","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# df_test  = np.load(\"testing_data.npy\") # given by source [test]\n# df_train = np.load(\"train_data.npy\")\n# # only dealing with training data ","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df_train_feature = np.array([i[0] for i in df_train])\ndf_train_label   = [i[1] for i in df_train] #gives list \ndf_train_label = np.asarray(df_train_label) #gives a array  with shape (123121...,)\n# .reshape(-1,32,32)\nprint df_train_feature.shape\nprint df_train_label.shape\n# (25000, 32, 32)\n# (25000,)\n","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df_train_label = df_train_label.reshape(df_train_label.shape[0], 1)\ndf_train_label.shape","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"df_train_feature = df_train_feature.reshape(df_train_feature.shape[0],-1) # flatten the feature matrix \nprint df_train_feature.shape\nprint df_train_label.shape","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"from sklearn.cross_validation import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(df_train_feature, df_train_label, test_size=0.3)","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"x_train = x_train.T\ny_train = y_train.T\nx_test = x_test.T\ny_test = y_test.T\n","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"print x_train.shape\nprint y_train.shape\nprint x_test.shape \nprint y_test.shape\n# Data has been created \n# 17500 images are in training data and 7500 images in testing data ","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"x_train = x_train/255\nx_test = x_test/255","metadata":{"collapsed":true}},{"cell_type":"markdown","source":"# MODEL [SINGLE HIDDEN LAYER @NEURAL NETWORK ]","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def sigmoid(x):\n    sig = 1/(1 + np.exp(-x))\n    return sig ","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def layer_size(x,y):\n    nx = x.shape[0]\n    nhl = 4\n    ny = y.shape[0]\n    return nx , nhl , ny","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def initialize_parameter(nx,nhl,ny,factor):\n    w1 = np.random.randn(nhl,nx)*factor\n    b1 = np.zeros((nhl,1))\n    w2 = np.random.randn(ny,nhl)*factor\n    b2 = np.zeros((ny,1))\n    parameters = {\n        \"w1\":w1,\n        \"w2\":w2,\n        \"b1\":b1,\n        \"b2\":b2   \n    }\n    return parameters  ","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def forward_prop(x, parameters):\n    w1 = parameters[\"w1\"]\n    b1 = parameters[\"b1\"]\n    w2 = parameters[\"w2\"]\n    b2 = parameters[\"b2\"]\n    z1 = np.dot(w1, x)+b1\n    a1 = np.tanh(z1)\n    z2 = np.dot(w2,a1)+b2\n    a2 = sigmoid(z2)\n    cache = {\"a1\":a1,\n             \"a2\":a2,\n             \"z1\":z1,\n             \"z2\":z2\n            }\n    return a2 , cache","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def costfunction(y, a2, parameters):\n    m = y.shape[1]\n    cost = (1/(-m))*(np.sum(np.multiply(np.log(a2),y) + np.multiply(np.log(1-a2),1-y)))\n    cost = np.squeeze(cost)\n    return cost \n\n","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def backward_propagation(parameters, cache , x, y):\n    m = x.shape[1]\n    w1=parameters[\"w1\"]\n    w2=parameters[\"w2\"]\n    a1=cache[\"a1\"]\n    a2=cache[\"a2\"]\n    dz2 = (a2-y)\n    dw2 = (1.0/m)*np.dot(dz2,a1.T)\n    db2 = (1.0/m)*np.sum(dz2, axis=1, keepdims=True)\n    dz1 = np.dot(w2.T,dz2)*(1 - np.power(a1, 2))\n#     print dz1.shape,\"helllllooo\", x.T.shape\n#     print pd.DataFrame(dz1).describe()\n#     df__ = x.T\n#     print df__.describe()\n    dw1 = np.dot(dz1,x.T)/m*1.0\n#     print dw1,\"identity\"\n    db1 = (1.0/m)*np.sum(dz1, axis=1, keepdims=True)\n    grads = {\"dw1\": dw1,\n             \"db1\": db1,\n             \"dw2\": dw2,\n             \"db2\": db2}\n    return grads","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def update_parameters(parameters, grads, learning_rate):\n    dw1 = grads[\"dw1\"]\n    dw2 = grads[\"dw2\"]\n    db1 = grads[\"db1\"]\n    db2 = grads[\"db2\"]\n    w1 = parameters[\"w1\"]\n    b1 = parameters[\"b1\"]\n    w2 = parameters[\"w2\"]\n    b2 = parameters[\"b2\"]\n    w1 = w1 - learning_rate*dw1\n    w2 = w2 - learning_rate*dw2\n    b1 = b1 - learning_rate*db1\n    b2 = b2 - learning_rate*db2\n    parameters = {\n             \"w1\":w1,\n             \"w2\":w2,\n             \"b1\":b1,\n             \"b2\":b2\n            }\n    return parameters","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def nn_model(x, y, nhl, iterations = 1000, learning_rate = 2,  print_cost = False):\n    nx= x.shape[0]\n    ny= y.shape[0]\n    parameters = initialize_parameter(nx,nhl,ny,0.1)\n    w1 = parameters[\"w1\"]\n    b1 = parameters[\"b1\"]\n    w2 = parameters[\"w2\"]\n    b2 = parameters[\"b2\"]\n    costs=[]\n    iteration =[]\n    for i in range(iterations):\n        a2 , param = forward_prop(x , parameters)\n        cost = costfunction(y, a2, parameters)\n        if i % 100 == 0:\n            costs.append(cost)\n            iteration.append(i)\n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n        grads =backward_propagation(parameters,param, x, y)\n        parameters =update_parameters(parameters, grads, learning_rate )\n    plt.plot(iteration, costs)\n    plt.xlabel('iter_num')\n    plt.ylabel('COST')\n    plt.title('LEARNING_PERIOD')\n    plt.grid(True)\n    plt.show()\n    print cost \n    return parameters ","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"parameter = nn_model(x_train, y_train, nhl = 4 , iterations = 1000, print_cost=True)","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def predict1(parameters, X):\n    a2, cache = forward_prop(X, parameters)\n    print a2.shape\n    y_predict = np.zeros((1,a2.shape[1]))\n    for i in range(a2.shape[1]):\n        if  a2[0,i] <= 0.5:\n            y_predict[0][i]=0\n        elif a2[0,i]>0.5:\n            y_predict[0][i]=1\n    return y_predict","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"prediction_test  = predict1(parameter, x_test)\nprint prediction_test\nprediction_train  = predict1(parameter, x_train)\nprint prediction_train\nprint(\"test accuracy: {} %\".format(100 - (np.mean(np.abs(prediction_test - y_test)) * 100)))\nprint(\"train accuracy: {} %\".format(100 - (np.mean(np.abs(prediction_train - y_train)) * 100)))","metadata":{"scrolled":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"","metadata":{"collapsed":true}}],"metadata":{"kernelspec":{"language":"python","name":"python2","display_name":"Python 2"},"language_info":{"pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python"}}}