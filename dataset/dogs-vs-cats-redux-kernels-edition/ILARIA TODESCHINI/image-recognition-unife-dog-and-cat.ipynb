{"cells":[{"metadata":{"_uuid":"36ec27b9-9c5a-4939-b920-d73ae865d3fa","_cell_guid":"17c10bee-b089-4912-82aa-f0a53f190b7c","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport pprint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"2ecceccf-de39-4a97-987e-eaec28cf4b8b","_cell_guid":"3ff564e1-8a10-4096-9811-859db13d46a8","trusted":true},"cell_type":"code","source":"# unzip given input files\nimport zipfile\n\nwith zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/train.zip') as z:\n    z.extractall()\n    \nwith zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/test.zip') as z:\n    z.extractall()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b3a6eec-b499-4c80-8eff-42d0ee82c370","_cell_guid":"0bf9fbb5-f391-4fcc-9702-71096e104a0f","trusted":true},"cell_type":"code","source":"## creating base directory directories\n#base_dir = './cats_and_dogs_small'\n#os.mkdir(base_dir)\n## creat sub directories(train,validation and test) under base directory\n#train_dir = os.path.join(base_dir, 'train')\n#os.mkdir(train_dir)\n#\n#validation_dir = os.path.join(base_dir, 'validation')\n#os.mkdir(validation_dir)\n#\n#test_dir = os.path.join(base_dir, 'test')\n#os.mkdir(test_dir)\n## create sub-directories(cats and dogs) under each sub directories(train,validation and test) created above\n#train_cats_dir = os.path.join(train_dir, 'cats')\n#os.mkdir(train_cats_dir)\n#\n#train_dogs_dir = os.path.join(train_dir, 'dogs')\n#os.mkdir(train_dogs_dir)\n#\n#validation_cats_dir = os.path.join(validation_dir, 'cats')\n#os.mkdir(validation_cats_dir)\n#\n#validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n#os.mkdir(validation_dogs_dir)\n#\n#test_cats_dir = os.path.join(test_dir, 'cats')\n#os.mkdir(test_cats_dir)\n#\n#test_dogs_dir = os.path.join(test_dir, 'dogs')\n#os.mkdir(test_dogs_dir)\n## save the path of train and test directories where we saved cats and dogs images after unzipping the input files\noriginal_dataset_train_dir = './train'\noriginal_dataset_test_dir = './test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* stampa la lista dei contenuti di tutti i file e cartelle prensenti nella cartella original_dataset_train_dir (variabile  a cui ho assegnato un percorso)"},{"metadata":{"_uuid":"9445f900-df13-4e59-b85f-bc7550d73e09","_cell_guid":"f3965bd7-e366-41e9-b530-4be517186f83","trusted":true},"cell_type":"code","source":"a =  os.listdir(original_dataset_train_dir)\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4ff24e0-ae56-44ae-9d36-5e72fa395a47","_cell_guid":"b72b2f7e-15ca-431d-816b-84859cbb6c0d","trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n# %matplotlib inline\n\nimport os\nimport random\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f2092fe-0adc-41dd-bdd9-715ba65066c9","_cell_guid":"caac6659-852c-4e5c-b816-b386879de554","trusted":true},"cell_type":"code","source":"for file_name in os.listdir(original_dataset_train_dir):\n    print(file_name)\n    if ('dog' in file_name): \n        print('dog_1')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9cce583-75c3-4b2c-80e9-5e5917adafc2","_cell_guid":"28487c1b-246b-43cc-a663-b93eddd99f73","trusted":true},"cell_type":"code","source":"train_dogs = [os.path.join(original_dataset_train_dir, file_name) for file_name in os.listdir(original_dataset_train_dir) if 'dog' in file_name ]\ntrain_cats = [os.path.join(original_dataset_train_dir, file_name) for file_name in os.listdir(original_dataset_train_dir) if 'cat' in file_name ]\n\nprint('Dogs n. elements:{cnt}'.format(cnt=len(train_dogs)))\nprint('Cats n. elements:{cnt}'.format(cnt=len(train_cats)))\n\n\ntest_imgs = [os.path.join(original_dataset_test_dir, file_name) for file_name in os.listdir(original_dataset_test_dir)] # da controllare -> percorso sbagliato\nprint('Test n. elements:{cnt}'.format(cnt=len(test_imgs)))\n\n\ntrain_imgs = train_dogs[:2000] + train_cats[:2000]\nrandom.shuffle(train_imgs)\nprint('Train n. elements:{cnt}'.format(cnt=len(train_imgs)))\n\n#cancella le variabili non necessarie\ndel train_dogs\ndel train_cats\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e8deeb7-9dad-416c-b498-b444bd7bddbc","_cell_guid":"b84a1853-e0a2-4099-935e-75af8ad9b86b","trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\nfor ima_path in train_imgs[0:3]:\n    print(ima_path)\n    img = mpimg.imread(ima_path)\n    imgplot = plt.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6488b9d5-e9f0-4674-856d-24502e5fdebc","_cell_guid":"6802592b-e05f-4375-a955-e79fe3e67243","trusted":true},"cell_type":"code","source":"nrows = 150\nncolumns = 150\nchannels = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definisco una funzione per leggere e processare una lista di immagini.\nInput: list_of_image_paths -> lista contenente i percorsi delle immagini da processare\n\nNella funzione creo due liste contenenti una le immagini processate e un altra contenente le labels assegnate alle varie immagini.\n(nel ciclo for: per ogni file nella lista in input vado ad aggiungere un nuovo elemento all'array IMAGE che rappresenta l'immagine letta e scalata; aggiungo un nuovo elemento anche all'array delle label che indica se l'immagine è di un cane o gatto ( 1 o 0))"},{"metadata":{"_uuid":"a41de18a-f52e-4c6f-aed1-3869ae9e5dd2","_cell_guid":"d0cb5df6-d957-4696-a06a-68f258748bc3","trusted":true},"cell_type":"code","source":"def read_and_process_image(list_of_image_paths): \n    IMAGES_1 = []  #array\n    labels_1 = []  #array\n    \n    for image_path in list_of_image_paths:\n        IMAGES_1.append(cv2.resize(cv2.imread(image_path, cv2.IMREAD_COLOR), (nrows,ncolumns), interpolation=cv2.INTER_CUBIC))\n        if 'dog' in image_path:\n            labels_1.append(1)\n        if 'cat' in image_path:\n            labels_1.append(0)\n    return IMAGES_1, labels_1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b28df4a-475d-466c-8431-a53078604a2e","_cell_guid":"4208b078-cc8d-45b6-96df-eae829711e43","trusted":true},"cell_type":"code","source":"IMAGES_out, labels_out = read_and_process_image(train_imgs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4110a357-62ff-46d5-9a8b-69dc88b25bbd","_cell_guid":"13c249d3-0230-400d-a406-5080d1c83dc3","trusted":true},"cell_type":"code","source":"IMAGES_out[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bdbac65-a9d1-44a9-a92a-ef2ade0f55b6","_cell_guid":"6470a33f-217f-4e4d-9579-12f6bfb9bac0","trusted":true},"cell_type":"code","source":"labels_out","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88856a52-c233-4c24-b15d-c6f02b889e3d","_cell_guid":"e1362704-3824-43b8-b3e4-fefc1ec36a69","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\ncolumns = 6\nfor i in range(columns):\n    plt.subplot(6/columns +1, columns, i+1)\n    plt.imshow(IMAGES_out[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcfdfc98-3ae7-44ba-b2d1-c61743ebdc58","_cell_guid":"ec75c51d-71ba-4b9f-8337-e6b36c56e4c1","trusted":true},"cell_type":"code","source":"#controllo contenuti \n\nimport seaborn as sns\ndel train_imgs\ngc.collect()\n\nIMAGES = np.array(IMAGES_out)\nlabels = np.array(labels_out)\n\nsns.countplot(labels)\nplt.title('Labels for Cats and Dogs')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8f99db0-444c-4a56-b917-7283fd8f0912","_cell_guid":"fa52787d-e23a-45f3-83ad-27fac3c44dee","trusted":true},"cell_type":"code","source":"print(\"Shape of train images is:\", IMAGES.shape)\nprint(\"Shape of labels is:\", labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae5a7dc6-536b-4670-b433-7567e431b6e1","_cell_guid":"6839f0a1-a7cb-492b-808b-821e6f07b876","trusted":true},"cell_type":"code","source":"#fase di train e test\nfrom sklearn.model_selection import train_test_split\nIMAGES_train, IMAGES_val, labels_train, labels_val = train_test_split(IMAGES, labels, test_size=0.20, random_state=2)\n\nprint(\"Shape of train images is:\", IMAGES_train.shape)\nprint(\"Shape of validation images is:\", IMAGES_val.shape)\nprint(\"Shape of train labes is:\", labels_train.shape)\nprint(\"Shape of validation labels is:\", labels_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e89fdfd-6699-4b40-9646-e1a584af4aed","_cell_guid":"cca706ae-a48c-4928-a2f8-cf4916ae2a6c","trusted":true},"cell_type":"code","source":"del IMAGES\ndel labels\ngc.collect()\n\nlenghttrain=len(IMAGES_train)\nlenghtval=len (IMAGES_val)\n\nbatch_size=32","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34bebb4c-d34d-49d9-9aca-055817d0278f","_cell_guid":"60c221cc-d71c-4f06-adb1-05e5c8c794e1","trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models \nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c5671ef-7891-4e2e-9da1-f99f909aa2d5","_cell_guid":"01d4148c-e049-4ad1-a031-9552b818a643","trusted":true},"cell_type":"code","source":"model=models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53dcb9bb-4e59-4fab-bef9-b6d9fef8ba9d","_cell_guid":"dc6e4046-ff03-42d2-be72-621186ae76b6","trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c72b49bd-fba5-4d35-b477-4cd0f74d3825","_cell_guid":"b5a3db5a-a6e8-4d11-9ba8-515e1daf5f8f","trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0a34667-d57f-4944-8f48-929aa8193fe1","_cell_guid":"cde77ecc-a5a0-4f74-9c79-341fed30ca28","trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255, \n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,)\nval_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88dec9f8-f11c-4c50-99b5-803fdbe3a57c","_cell_guid":"cc69e5c5-5e6d-4835-999c-ab0e748640c4","trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow(IMAGES_train, labels_train, batch_size=batch_size)\nval_generator = val_datagen.flow(IMAGES_val, labels_val, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ec3edfd-22c5-4b3b-af0e-78365fcf6872","_cell_guid":"d56fe23b-7a78-46aa-b650-f07a13c24f9f","trusted":true},"cell_type":"code","source":"print(lenghttrain // batch_size)\nprint(val_generator)\nprint(lenghtval // batch_size)\n\n\nhistory = model.fit_generator(train_generator,\n                             steps_per_epoch=lenghttrain // batch_size,\n                             epochs = 64,\n                             validation_data=val_generator,\n                             validation_steps=lenghtval // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights ('model_weights.h5')\nmodel.save ('model_keras.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) +1)\n\nplt.plot(epochs, acc, 'b', label='Training accuracy')\nplt.plot(epochs,val_acc, 'r', label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\n\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs,val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGES_test, labels_test = read_and_process_image(test_imgs[0:10])  #labels_test vuoto perchè non ci sono labels, perchè nel file name non ci sono ne cat ne dog quindi non assegna\nx= np.array(IMAGES_test)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n#IMAGES_test[0]\n#test_imgs[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i= 0\ntext_labels = []\nplt.figure(figsize=(30,20))\nfor batch in test_datagen.flow(x, batch_size=1):\n    pred = model.predict(batch)\n    if pred > 0.5:\n        text_labels.append('dog')\n    else:\n        text_labels.append('cat')\n    plt.subplot(6/columns + 1, columns, i+1)\n    plt.title('This is a ' + text_labels[i])\n    imgplot = plt.imshow(batch[0])\n    i += 1\n    if i % 10 ==0:\n        break\nplt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}