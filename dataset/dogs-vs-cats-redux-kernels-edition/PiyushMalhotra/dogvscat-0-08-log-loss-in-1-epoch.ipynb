{"nbformat_minor":1,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","version":"3.6.3","file_extension":".py","nbconvert_exporter":"python"}},"cells":[{"cell_type":"markdown","source":"## The Directory Structure\n```\nProject\n|-- datasets\n|   |-- dev_set\n|   |-- test\n|   |-- test_set\n|   |-- train\n|   `-- train_set\n|-- model\n|-- pretrained-model\n|-- submissions\n|-- datalab.py\n|-- dataset_clusterer.py\n|-- make_file.py\n|-- model.py\n|-- vgg16.py\n|-- predict.py\n|-- test.py\n`-- train.py\n```\n\n**Code with proper differentiation in scripts can be found [here](https://github.com/piyush2896/Transfer-Learning-Vgg-16)**","metadata":{"_cell_guid":"54360db6-6718-48f3-8180-65adaea6188a","_uuid":"8a88a278356fa0340fae17d2bd71e39a704ee2e4"}},{"cell_type":"markdown","source":"## Preprocessing and Batches Creation\nUnfortunately we cannot directly feed data into the model as it is huge for machine and is of variable size.\n\nMaking each image of size (224, 224, 3) and creating batches of the images. Run [dataset_clusterer.py](https://github.com/piyush2896/Transfer-Learning-Vgg-16/blob/master/dataset_clusterer.py) to get through it","metadata":{"_cell_guid":"4372024c-cb32-4ecb-ab0a-d1da5700de93","_uuid":"b2b86bbf618e5d7e3ab7a4afb845dba2bd83af76"}},{"cell_type":"markdown","source":"## VGG-16 Pretrained\nI used [vgg-16](http://arxiv.org/abs/1409.1556.pdf) pretrained model and fine-tuned the last layer. The checkpoint file used in code of [vgg16.py](https://github.com/piyush2896/Transfer-Learning-Vgg-16/blob/master/vgg16.py) can be downloaded from [here](http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz)","metadata":{"_cell_guid":"542e48ca-db92-4851-aa1f-283f24c8b036","_uuid":"ddb39b248761f74a876223cfcd0a9fa2e7052f37"}},{"cell_type":"markdown","source":"## Generators as Pipeline\nI created a pipeline to feed data into model. This ensured that I donot load the complete dataset in the memory. There are two generators \n1. DataLabTrain - used for train and dev set\n2. DataLabTest - used for test set\n\nThey simply load the batches made by dataset_clusterer.py and make them available using a generator method. Code can be found in [datalab.py](https://github.com/piyush2896/Transfer-Learning-Vgg-16/blob/master/datalab.py).","metadata":{"_cell_guid":"8063a7e8-27df-43b8-b850-0d527d9adbcf","_uuid":"069fb23f04a55be2d1afd2dc98cadac84a895d59"}},{"cell_type":"markdown","source":"## Training time\nI just trained for 1 epoc and got a dev set loss of around ~0.04. And a test set loss at kaggle of 0.08426. The code of train.py is displaye below","metadata":{"_cell_guid":"f2877969-6cb7-4679-b6d7-ef8ba28ee3d1","_uuid":"ed5ad9fa8885f0646784d212c63c074c71e9ada9"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom vgg16 import vgg16\nimport numpy as np\nimport os\nfrom datalab import DataLabTrain","execution_count":null,"metadata":{"_cell_guid":"d804a30c-cf6f-487c-8f3d-43f48ea48129","_uuid":"8c4bb1f955311ec1aa7fa88d3004989bb99ce7d0","collapsed":true,"_kg_hide-output":true},"outputs":[]},{"cell_type":"code","source":"def train(n_iters):\n    model, params = vgg16(fine_tune_last=True, n_classes=2)\n    X = model['input']\n    Z = model['out']\n    Y = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z[:, 0, 0, :], labels=Y))\n    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n        try:\n            sess.run(tf.global_variables_initializer())\n            for i in range(n_iters):\n                dl = DataLabTrain('./datasets/train_set/')\n                train_gen = dl.generator()\n                dev_gen = DataLabTrain('./datasets/dev_set/').generator()\n                for X_train, Y_train in train_gen:\n                    print('Samples seen: '.format(dl.cur_index), end='\\r')\n                    sess.run(train_step, feed_dict={X: X_train, Y: Y_train})\n                print()\n                l = 0\n                count = 0\n                for X_test, Y_test in dev_gen:\n                    count += 1\n                    l += sess.run(loss, feed_dict={X: X_test, Y: Y_test})\n\n                print('Epoch: {}\\tLoss: {}'.format(i, l/count))\n                saver.save(sess, './model/vgg16-dog-vs-cat.ckpt')\n                print(\"Model Saved\")\n\n        finally:\n            sess.close()","execution_count":null,"metadata":{"_cell_guid":"d0545e6a-a35a-44fe-9c0b-c6be0524f064","_uuid":"500b98974d921e997d0dfa93cd5bc57719eb17c5","collapsed":true},"outputs":[]},{"cell_type":"code","source":"train(n_iters=1)","execution_count":null,"metadata":{"_cell_guid":"1d49d537-abe6-4921-9017-27006c9d4a95","_uuid":"069bc0128a31f966c271f7a67882f9d962ed3fd5","collapsed":true,"_kg_hide-output":true},"outputs":[]},{"cell_type":"markdown","source":"## Prediction Time\nThe training script saves the model in \"model\" folder which can be restored and used for prediction. Code of predict.py is displayed below","metadata":{"_cell_guid":"e5df5926-0143-498b-8d9e-4803df04eb23","_uuid":"c3e80561debae54352baf06d7576aa5cbf443476"}},{"cell_type":"code","source":"from make_file import make_sub\n\n\ndef predict(model_path, batch_size):\n    model, params = vgg16(fine_tune_last=True, n_classes=2)\n    X = model['input']\n    Y_hat = tf.nn.softmax(model['out'])\n\n    saver = tf.train.Saver()\n\n    dl_test = DataLabTest('./datasets/test_set/')\n    test_gen = dl_test.generator()\n\n    Y = []\n    with tf.Session() as sess:\n        saver.restore(sess, model_path)\n        for i in range(12500//batch_size+1):\n            y = sess.run(Y_hat, feed_dict={X: next(test_gen)})\n            #print(y.shape, end='   ')\n            Y.append(y[:,0, 0, 1])\n            print('Complete: {}%'.format(round(len(Y) / dl_test.max_len * 100, 2)), end='\\r')\n    Y = np.concatenate(Y)\n\n    print()\n    print('Total Predictions: '.format(Y.shape))\n    return Y\n\nY = predict('./model/vgg16-dog-vs-cat.ckpt', 16)\nnp.save('out.npy', Y)\nmake_sub('sub_1.csv')","execution_count":null,"metadata":{"_cell_guid":"bf95d493-771f-4f7f-a994-3e978a38bfb5","_uuid":"9dc833ba6365d31c33fa50baec86b0205f5ea361","collapsed":true,"_kg_hide-output":true},"outputs":[]},{"cell_type":"markdown","source":"[make_file.py](https://github.com/piyush2896/Transfer-Learning-Vgg-16/blob/master/make_file.py) is a helper script used to create submission file.","metadata":{"_cell_guid":"959e67f9-dea8-4a02-af47-2d8c506e5d31","_uuid":"2b7c3d135a200db76f17ea5743587564f823cc92"}}],"nbformat":4}