{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","file_extension":".py","nbconvert_exporter":"python","version":"3.6.1","pygments_lexer":"ipython3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":0,"cells":[{"execution_count":null,"source":"Hello! Implementation below is not end solution and require addition program. All of this will be added later.","metadata":{"collapsed":false,"_uuid":"a40a91bb7ffdc58e548f2697ef174de4613d22c8","_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"dc60816ad096529e67b383b7c89464de938f01ca","_cell_guid":"f183ad76-20e3-4e84-a284-daba9007337e","trusted":false},"outputs":[],"source":"import cv2\nimport glob\nimport numpy as np\nimport tensorflow as tf\nimport datetime\nimport random\n\nDOG = 1\nCAT = 0\npath_to_train = \"data/resize256/\"\npath_to_log = 'logs/train'\nIMAGE_SIZE = 256\n\ndef getBatch(step, input_size):\n    count = step * 25\n    labels = np.zeros((50, 2))\n    data = np.zeros((50, input_size, input_size, 3))\n    position = 0\n    for i in range(count, count + 25):\n        cat_file = glob.glob(path_to_train + \"cat.\" + str(i) + \".jpg\")\n        cat_file = cv2.imread(cat_file[0])\n        data[position] = cat_file\n        labels[position][CAT] = 1\n        position = position + 1\n\n        dog_file = glob.glob(path_to_train + \"dog.\" + str(i) + \".jpg\")\n        dog_file = cv2.imread(dog_file[0])\n        data[position] = dog_file\n        labels[position][DOG] = 1\n        position = position + 1\n    return data, labels\n\ndef create_net(input_plh):\n\n    size_1 = int(IMAGE_SIZE / 2)\n    size_2 = int(IMAGE_SIZE / 4)\n    size_3 = int(IMAGE_SIZE / 8)\n    FCL_1_number_of_nodes = 1000\n    FCL_2_number_of_nodes = 500\n    \n    with tf.name_scope(\"Layer_1\"):\n        weight = tf.truncated_normal([3, 3, 3, 32], stddev=0.1)\n        weight = tf.Variable(weight, name=\"Weight_L1\")\n        variable_summaries(weight)\n        bias = tf.Variable(tf.constant(0.1, shape=[32]), name=\"Bias_L1\")\n        variable_summaries(bias)\n        conv_layer = tf.nn.conv2d(input_plh, weight, strides=[1, 1, 1, 1], padding='SAME', name=\"CNN_L1\")\n        conv_layer = conv_layer + bias\n        conv_layer = tf.nn.relu(conv_layer, name=\"ReLU_L1\")\n        pool = tf.nn.max_pool(conv_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=\"Max_pool_L1\")\n\n        with tf.name_scope('C_1_images_summary'):\n            image_shaped_input = tf.reshape(conv_layer, [-1, IMAGE_SIZE, IMAGE_SIZE, 1])\n            tf.summary.image('c_1_activation_maps', image_shaped_input, 10)\n\n        with tf.name_scope('P_1_images_summary'):\n            image_shaped_input = tf.reshape(pool, [-1, 32, 32, 1])\n            tf.summary.image('pool_1', image_shaped_input, 10)\n\n    with tf.name_scope(\"Layer_2\"):\n        weight = tf.truncated_normal([3, 3, 32, 64], stddev=0.1)\n        weight = tf.Variable(weight, name=\"Weight_L2\")\n        variable_summaries(weight)\n        bias = tf.Variable(tf.constant(0.1, shape=[64]), name=\"Bias_L2\")\n        variable_summaries(bias)\n        conv_layer = tf.nn.conv2d(pool, weight, strides=[1, 1, 1, 1], padding='SAME', name=\"CNN_L2\")\n        conv_layer = conv_layer + bias\n        conv_layer = tf.nn.relu(conv_layer, name=\"ReLU_L2\")\n        pool = tf.nn.max_pool(conv_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=\"Max_pool_L2\")\n\n        with tf.name_scope('C_2_images_summary'):\n\n            image_shaped_input = tf.reshape(conv_layer, [-1, size_1, size_1, 1])\n            tf.summary.image('c_2_activation_maps', image_shaped_input, 10)\n\n        with tf.name_scope('P_2_images_summary'):\n            image_shaped_input = tf.reshape(pool, [-1, size_2, size_2, 1])\n            tf.summary.image('pool_2', image_shaped_input, 10)\n\n    with tf.name_scope(\"Layer_3\"):\n        weight = tf.truncated_normal([3, 3, 64, 128], stddev=0.1)\n        weight = tf.Variable(weight, name=\"Weight_L3\")\n        variable_summaries(weight)\n        bias = tf.Variable(tf.constant(0.1, shape=[128]), name=\"Bias_L3\")\n        variable_summaries(bias)\n        conv_layer = tf.nn.conv2d(pool, weight, strides=[1, 1, 1, 1], padding='SAME', name=\"CNN_L3\")\n        conv_layer = conv_layer + bias\n        conv_layer = tf.nn.relu(conv_layer, name=\"ReLU_L3\")\n        pool = tf.nn.max_pool(conv_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=\"Max_pool_L3\")\n\n        with tf.name_scope('C_3_images_summary'):\n            image_shaped_input = tf.reshape(conv_layer, [-1, size_2, size_2, 1])\n            tf.summary.image('c_3_activation_maps', image_shaped_input, 10)\n\n        with tf.name_scope('P_3_images_summary'):\n            image_shaped_input = tf.reshape(pool, [-1, size_3, size_3, 1])\n            tf.summary.image('pool_3', image_shaped_input, 10)\n\n    \n    with tf.name_scope(\"FC_Layer_1\"):\n        fc1_flat_image_size = size_3 * size_3 * 128\n        weight = tf.truncated_normal([fc1_flat_image_size, FCL_1_number_of_nodes])\n        weight = tf.Variable(weight, name=\"Weight_FC_L1\")\n        variable_summaries(weight)\n        bias = tf.Variable(tf.constant(0.1, shape=[FCL_1_number_of_nodes]), name=\"Bias_FC_L1\")\n        variable_summaries(bias)\n        flat_fc1 = tf.reshape(pool, shape=[-1, fc1_flat_image_size], name=\"Reshape_FC_L1\")\n        FC_layer = tf.nn.relu(tf.matmul(flat_fc1, weight) + bias, name=\"ReLU_FC_L1\")\n\n    \n    with tf.name_scope(\"FC_Layer_2\"):\n        weight = tf.truncated_normal([FCL_1_number_of_nodes, FCL_2_number_of_nodes])\n        weight = tf.Variable(weight, name=\"Weight_FC_L2\")\n        variable_summaries(weight)\n        bias = tf.Variable(tf.constant(0.1, shape=[FCL_2_number_of_nodes]), name=\"Bias_FC_L2\")\n        variable_summaries(bias)\n        FC_layer = tf.nn.relu(tf.matmul(FC_layer, weight) + bias, name=\"ReLU_FC_L2\")\n\n    with tf.name_scope(\"FC_Layer_3\"):\n        weight = tf.truncated_normal([FCL_2_number_of_nodes, 2])\n        weight = tf.Variable(weight, name=\"Weight_FC_L3\")\n        variable_summaries(weight)\n        bias = tf.Variable(tf.constant(0.1, shape=[2]), name=\"Bias_FC_L3\")\n        variable_summaries(bias)\n        FC_layer = tf.nn.relu(tf.matmul(FC_layer, weight) + bias, name=\"ReLU_FC_L3\")\n\n    return FC_layer\n\n# Thanks to Google for this method!\ndef variable_summaries(var):\n    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n    with tf.name_scope('summaries'):\n      mean = tf.reduce_mean(var)\n      tf.summary.scalar('mean', mean)\n      with tf.name_scope('stddev'):\n        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n      tf.summary.scalar('stddev', stddev)\n      tf.summary.scalar('max', tf.reduce_max(var))\n      tf.summary.scalar('min', tf.reduce_min(var))\n      tf.summary.histogram('histogram', var)\n\n\ndef main():\n    sess = tf.InteractiveSession()\n\n    input_images = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, 3], name=\"Input_images\")\n    truth_labels = tf.placeholder(tf.float32, [None, 2], name=\"Truth_labels\")\n\n    with tf.name_scope('input_images_summary'):\n        image_shaped_input = tf.reshape(input_images, [-1, IMAGE_SIZE, IMAGE_SIZE, 3])\n        tf.summary.image('input_images', image_shaped_input, 10)\n\n    cnn = create_net(input_images)\n\n    with tf.name_scope('cross_entropy'):\n        diff = tf.nn.softmax_cross_entropy_with_logits(labels=truth_labels, logits=cnn)\n        cross_entropy = tf.reduce_mean(diff)\n        tf.summary.scalar('cross_entropy', cross_entropy)\n\n    with tf.name_scope(\"train_step\"):\n        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\n    with tf.name_scope('accuracy'):\n        with tf.name_scope('correct_prediction'):\n            correct_prediction = tf.equal(tf.argmax(truth_labels, 1), tf.argmax(cnn, 1))\n        with tf.name_scope('accuracy'):\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    tf.summary.scalar('accuracy', accuracy)\n\n    merged = tf.summary.merge_all()\n    train_writer = tf.summary.FileWriter(path_to_log, sess.graph)\n\n    sess.run(tf.global_variables_initializer())\n    start = datetime.datetime.today()\n    print(\"Start time: \" + str(start))\n    for i in range(499):\n        print(\"Getting data\")\n        data, labels = getBatch(i, IMAGE_SIZE)\n        print(\"Got data\")\n        if i % 50 == 0:\n            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n            run_metadata = tf.RunMetadata()\n            operations = {\"merged\": merged, \"train_step\": train_step, \"accuracy\": accuracy}\n            result_dictionary = sess.run(operations, feed_dict={input_images: data, truth_labels: labels}, options=run_options, run_metadata=run_metadata)\n            train_writer.add_run_metadata(run_metadata, 'step%03d' % i)\n        else:\n            operations = {\"merged\": merged, \"train_step\": train_step}\n            result_dictionary = sess.run(operations, feed_dict={input_images: data, truth_labels: labels})\n\n        train_writer.add_summary(result_dictionary[\"merged\"], i)\n        if result_dictionary.get(\"accuracy\", None) is not None:\n            print(str(datetime.datetime.today()) + ': Step %d, training accuracy %g' % (i, result_dictionary[\"accuracy\"]))\n    train_writer.close()\n    finish = datetime.datetime.today()\n    print(\"Finish time: \" + str(finish))\n    print(\"Total: \" + str(finish-start))\n\n\nmain()\n"}],"nbformat":4}