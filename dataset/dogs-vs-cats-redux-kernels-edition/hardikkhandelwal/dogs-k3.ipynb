{"metadata":{"language_info":{"nbconvert_exporter":"python","mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","file_extension":".py"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4,"cells":[{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"3b38ca60-d1e5-4e0b-bdf9-9b4b4c306b20","_uuid":"916e3ca81c6e9b9edb573b73b2803862917b1586"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code"},{"metadata":{"_cell_guid":"c183d775-71ba-4cde-9d3a-1c4e201acf55","_uuid":"f97d85cde71d889d0e0047f54d24604156e328aa"},"source":"We are going to classify cats and dogs using a convolution neural network. <br>\nFor this purpose we will first need to load our dataset, as it comprises of images. We will need to first load it as an array of pixels.","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"e612de27-c408-4cb3-bd24-ad116245fad3","collapsed":true,"_uuid":"51d958c6e48f0a7269370d418b6a2ccc0bd5d51f"},"source":"#importing dependecies to create dataset\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport random","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"5e01ae8a-b434-4a7d-af88-eae5fe5344d9","collapsed":true,"_uuid":"f78b9d21046ec96770440c0844ccc39fc822578e"},"source":"#function takes a file name and returns output label in the form of one hot vector\n#[0,1]=dog [1,0]=cat\ndef output_label(l):\n    lb=l.split('.')[0]\n    #print(ar)\n    if str(lb)==str('cat'):\n        return [1,0]\n    else:\n        return [0,1]\n   \n#function below loads an image, resizes it and returns corresponding numpy array\ndef load_image(path,width):\n    img=Image.open(path)\n    img = img.resize((width,width))  \n    a=np.array(img)\n    return a","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"2aa8d3d7-c766-404e-8be5-5d0656683b5d","collapsed":true,"_uuid":"af00d38c19368377165d6859ef764f55dc6fb619"},"source":"#defining constants to be used to prepare our dataset\nTRAINING_PATH='../input/train'\nls_train=os.listdir(TRAINING_PATH)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"643bd37a-9bee-4171-984b-e38848bd22a4","_uuid":"b992303f40a134fb719c9414dba0fd171127d558"},"source":"#let's make our training set now\ntrain_set=[]\ni=0\nfor s in ls_train:\n    train_set.append([np.array(load_image(os.path.join(TRAINING_PATH,s),64))\n                      ,output_label(s)])\n    i=i+1\n    if i%1000==0:\n        print('images processed so far',i)","cell_type":"code"},{"metadata":{"_cell_guid":"23084a38-f4c5-4473-a0ef-edb84043ceb2","_uuid":"46da10693afc7af1f51fb18558440ccd5bd4d4c4"},"source":"Similar to mnist we are going to follow a 3 layer cnn\n(conv2d+relu+maxPooling)-->(conv2D+relu+maxPooling)---> (flatten to a fully connected layer with softmax regressor)","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"680df313-338b-4f84-8a93-9c6291bc3ef8","_uuid":"261dd7908c418659632c22217fa237b925e9c7ae"},"source":"import tensorflow as tf","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"9490235e-8e95-4962-be82-63acc0d7d0fd","collapsed":true,"_uuid":"63d803076377042e96842bafcab2ca749b77c2ed"},"source":"#defining placeholders\nX=tf.placeholder(tf.float32,shape=(None,64,64,3))\nY_=tf.placeholder(tf.float32,shape=[None,2]) #one hot vectors","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"f08e2114-9207-4f6c-819d-726e933bbd38","collapsed":true,"_uuid":"6106f9da063eef43c90cd6544965114e62716aea"},"source":"#defining helper functions for conv2d and max_pooling\ndef conv2d(x,W):\n    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n\ndef max_pooling(x):\n    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"5a8ced62-43be-4538-b584-5847d0969242","collapsed":true,"_uuid":"02eb4f95d47a1643b9e0f0c6b1b2c6506c02d7e7"},"source":"#defining helper functions for weights and bias\ndef weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\ndef bias_variable(shape):\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"7c8bf232-22d7-4dde-9b84-32601356a60b","collapsed":true,"_uuid":"11448a2ace7867646e9aa4c00a4a80cd18ccb398"},"source":"w1=weight_variable([5,5,3,32])\nb1=bias_variable([32])\n#now reshaping images from a image_count*784 vector to image_count*28*28*1\n#X_image=tf.reshape(X,[-1,28,28,1])\n\nh_conv1=tf.nn.relu(conv2d(X,w1)+b1)\nh_pool1=max_pooling(h_conv1)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"50f10c8f-a122-4813-9d45-2b7a6fd74d5d","collapsed":true,"_uuid":"61d6a22d5bef68ef2dc97f5e59949f3925584350"},"source":"#defininf second layer of cnn\nw2=weight_variable([5,5,32,64])\nb2=bias_variable([64])\nh_conv2=tf.nn.relu(conv2d(h_pool1,w2)+b2)\nh_pool2=max_pooling(h_conv2)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"67314141-9efc-42cb-ad15-22de7133cc37","collapsed":true,"_uuid":"46f816c3b0ea380c036b2859f217ae25406bca90"},"source":"h_pool_flat=tf.reshape(h_pool2,[-1,16*16*64])\nw3=weight_variable([16*16*64,1024])\nb3=bias_variable([1024])\n\nh_fc1 = tf.nn.relu(tf.matmul(h_pool_flat,w3)+b3)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"eef65cc9-07c9-4af1-9c92-c00f02741391","collapsed":true,"_uuid":"15decf5bb49626789293afc59eb7be5cbf4df439"},"source":"w4=weight_variable([1024,2])\nb4=bias_variable([2])\ny_conv= tf.matmul(h_fc1,w4)+b4","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"159af907-2956-43a4-a6e5-d2953968355d","collapsed":true,"_uuid":"bea0d514749cd09fa14069125b6b0a8940e8284a"},"source":"cross_entropy = tf.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=y_conv))\ntrain_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(Y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"b82d6334-d3bf-4ad3-a105-5b2a29461871","collapsed":true,"_uuid":"c0420d5aac58ca69b19d00dcba70a0cb51cccd12"},"source":"#creating training and testing sets\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split as tts\ntrain_set = shuffle(train_set)\ntrain, test=tts(train_set,test_size=0.1,random_state=1)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"2a670ee2-ca31-4cce-9f9c-47374347d25b","_uuid":"354184d6c6be88a8c68ef3bc945fbf13f8924efb"},"source":"print(len(train),len(test))","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"68259cc8-ab81-4111-85c8-0e8c4c335c02","_uuid":"152bb84a455a025092e5d50382f913ed0b0504a7"},"source":"train_features=np.array([i[0]/255.0 for i in train])\ntrain_labels=np.array([i[1] for i in train])\nprint(train_features.shape,train_labels.shape)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"98720ce2-7fda-4aad-ae27-db926e3cad29","_uuid":"ad66725bbca5a50b92a156b7e8b950e2cf8aba59"},"source":"print('yo')\ninit=tf.global_variables_initializer()\nsess=tf.Session()\nsess.run(init)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"11cb3ba5-3057-414f-8b1d-c5dc23a19ff6","collapsed":true,"_uuid":"89150cad3d6bb3c52db632ba8382621d62193530"},"source":"","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"a3f94a5c-7a46-4808-a792-da779ff1d554","_uuid":"4449a520a97405c96d9ddb86d592aa9ad8a10ed9"},"source":"print(\"now entering training\")\ncosts=[]\n#training with learning rate 0.0001 for 30 epochs to start with \nfor i in range (30):   \n    j=0\n    batch_cost=0\n    for j in range (100):\n        batch_x=(train_features[(j*225):(j+1)*225])\n        batch_y=(train_labels[j*225:(j+1)*225])\n        _,cost_batch=sess.run([train_step,cross_entropy],{X:batch_x,Y_:batch_y})\n        batch_cost+=cost_batch/100.0   \n        if j==99 and j!=0:\n            costs.append(batch_cost)\n            print(batch_cost)\n        if j%49==0:\n            print('on minibatch iteration ',j)\n    #_x.append(i)  \n    #costs.append(float(cost))\n    #if i%5==0:\n    print(\"iteration= \",i)\n    #print(cost,costs)\nplt.plot(costs)\nplt.show()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"f39027a2-2e08-4c15-9994-32e274645d01","_uuid":"98c824755a68f9b5d61b84aa0483a7add4a19efb"},"source":"\ntest_features=np.array([i[0]/255 for i in test])\ntest_labels=np.array([i[1] for i in test])\nprint('starting to predict test accuracy')\nprint(sess.run(accuracy,{X:test_features,Y_:test_labels}))","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"2dae44ba-3416-44ab-9458-7cd76e0b373c","_uuid":"76de57c11959c129e887c918c60817e84f667485"},"source":"#now trying to predict results for real test set\n#loading testing images\nTEST_PATH='../input/test'\nls_test=sorted(os.listdir(TEST_PATH))\nprint(len(ls_test))","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"af9b5de0-c586-4cf8-8b6b-8d289d5d06c1","collapsed":true,"_uuid":"533e4a641d28bb9329ca6422921f3ef48ead6788"},"source":"test_dict={}\nfor i in ls_test:\n    s=i.split('.')[0]\n    test_dict[s]=i","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{},"source":"#test_features\ntest_features=[]\nfor i in range(1,12501):\n    test_features.append(load_image(os.path.join(TEST_PATH,test_dict[str(i)]),64))\n    if i%1000==0:\n        print('features loaded successfully',i)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{},"source":"test_features=np.array(test_features)\nprint(test_features.shape)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{},"source":"ans=tf.argmax(y_conv, 1)\ntest_result=[]\nfor i in range(125):\n    f1=test_features[i*100:(i+1)*100]/255\n    pred=sess.run(ans,{X:f1})\n    for j in range(len(pred)):\n        test_result.append(pred[j])\nprint(len(test_result))","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"test_result=np.array(test_result)\nlabels=[]\nfor x in range (1,12501):\n    labels.append(x)\nlabels=np.array(labels)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{},"source":"df={\n    'id':labels,\n    'label':test_result\n}\nprint(len(labels),len(test_result))\npd_df=pd.DataFrame(data=df)\npd_df.to_csv('cnn_regularized2.csv',index=False)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"","cell_type":"code"}],"nbformat_minor":1}