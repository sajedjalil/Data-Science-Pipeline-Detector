{"cells":[{"metadata":{"_cell_guid":"74c46061-c516-4c91-8a6e-a16d59d7bfa9","_execution_state":"idle","_uuid":"a601727a7e19a7f5c8d2f0dfdc30d459c718beb0","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c83b8d2c-8938-4a0e-971f-95641bb879ea","_execution_state":"idle","_uuid":"55a52bfbb9e8e45f033aad5eb49e66558ff5a02d","trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nfrom random import shuffle\nfrom tqdm import tqdm\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f0893f82-3d3d-4df3-aac7-784ab0f7f5ea","_execution_state":"idle","_uuid":"7bd3d5603f003f840e6cbf3d9c19932418851e7d","trusted":false},"cell_type":"code","source":"TRAIN_DIR = '../input/train/'\nTEST_DIR = '../input/test/'\nIMG_SIZE = 50\nLR = 1e-3\n\nMODEL_NAME = \"dogsvscats-{}-{}.model\".format(LR, '6conv-basic')\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3e2db19e-d68b-4347-b5f5-45786a080cc7","_execution_state":"idle","_uuid":"dbdfe8c767b684b92b461b7aade6131e8009488e","trusted":false},"cell_type":"code","source":"def label_image(img):\n    world_label = img.split('.')[0]\n    if world_label == \"dog\": return [1, 0]\n    elif world_label == 'cat': return [0, 1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2a998a6a-8d24-452b-bad9-1290cc79aac4","_execution_state":"idle","_uuid":"202d95a69f2e90dca4599f332590afd2cfdbf628","trusted":false},"cell_type":"code","source":"def create_training_data():\n    training_data = []\n    for img in os.listdir(TRAIN_DIR):\n        label = label_image(img)\n        path = os.path.join(TRAIN_DIR, img)\n        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n        training_data.append([np.array(img), np.array(label)])\n    shuffle(training_data)\n    #np.save(\"training_data.npy\", training_data)\n    return training_data\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aa2ce581-985a-4c94-909b-8cf8b559717c","_execution_state":"idle","_uuid":"4467fbc0de94c8bf9bcf9205bde6a2f590b2d9b6","trusted":false},"cell_type":"code","source":"def process_test_data():\n    testing_data = []\n    for img in os.listdir(TEST_DIR):\n        path = os.path.join(TEST_DIR, img)\n        img_num = img.split('.')[0]\n        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n        testing_data.append([np.array(img), np.array(img_num)])\n    np.save(\"testing_data.npy\", testing_data)\n    return testing_data    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"99d449c9-73e4-485c-ad6f-3b16d01c482b","_execution_state":"idle","_uuid":"a6a4b5cbd509b968897078eba523c142901bbcd2","trusted":false},"cell_type":"code","source":"training_data = create_training_data()\n#training_data = np.load('training_data.npy')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"542f4ad7-4c63-4ca9-ac9b-52edeccefddc","_execution_state":"idle","_uuid":"4537e3a9b60bf993d21e063b6d406860afae170d","trusted":false},"cell_type":"code","source":"import tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.estimator import regression\n\nconvnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n\nconvnet = conv_2d(convnet, 32, 2, activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 64, 2, activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 32, 2, activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 64, 2, activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 32, 2, activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 64, 2, activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = fully_connected(convnet, 1024, activation='relu')\nconvnet = dropout(convnet, 0.8)\n\nconvnet = fully_connected(convnet, 2, activation='softmax')\nconvnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n\nmodel = tflearn.DNN(convnet)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"37a94c58-f16d-42a1-b47c-df524a6e32d7","_execution_state":"idle","_uuid":"54db31f6309921dc9536cb45760b68fe758ff5de","trusted":false},"cell_type":"code","source":"train = training_data[: -500]\ntest = training_data[-500:]\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"de0448d0-2647-4ea5-a084-70148641dd1f","_execution_state":"idle","_uuid":"886f2d27c75f541c2a451c4f55f7ead063b8f401","trusted":false},"cell_type":"code","source":"X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\nY = np.array([i[1] for i in train])\ntest_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ntest_y = np.array([i[1] for i in test])\nprint(len(X), len(Y), len(test_y), len(test_y))\nprint(np.shape(X), len(Y), len(test_y), len(test_y))\nmodel.fit({'input': X}, {'targets': Y}, n_epoch=5, validation_set=({'input': test_x}, {'targets': test_y}), \n    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"225da432-808b-4b7c-8c99-6e168cabe09b","_execution_state":"idle","_uuid":"ad4d0c13bd181f6361d793f5ded07a5ec71e1075","trusted":false},"cell_type":"code","source":"model.save(MODEL_NAME)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8e10e8db-026e-4c5b-bdfc-9b63f4745845","_execution_state":"idle","_uuid":"939fcdcb329495c4f647935846e6dfdcd5f257f8","trusted":false},"cell_type":"code","source":"#import matplotlib.pyplot as plt\n#test_data = process_test_data()\n#test_data = np.load(\"testing_data.npy\")\n#fig = plt.figure()\n#i = 100\n#model.load(MODEL_NAME)\n#for num, data in enumerate(test_data[i:i+12]):\n    #img_num = data[1]\n    #img_data = data[0]\n    #y = fig.add_subplot(3, 4, num+1)\n    #orig = img_data\n    #data = img_data.reshape(IMG_SIZE, IMG_SIZE,1)\n    #model_out = model.predict([data])[0]\n    #if np.argmax(model_out) == 1: str_label = \"Cat\"\n    #else: str_label = \"Dog\"\n    #y.imshow(orig, cmap='gray')    \n    #plt.title(str_label)\n    #y.axes.get_xaxis().set_visible(False)\n    #y.axes.get_yaxis().set_visible(False)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d55c44a0-9c19-4447-af3d-103f07d27824","_execution_state":"idle","_uuid":"0774290944faed7a8520710e2c0f4cf1fff549a9","trusted":false},"cell_type":"code","source":"test_data = process_test_data()\nwith open(\"submission-file.csv\",'w') as f:\n    f.write('id,label\\n')\nwith open(\"submission-file.csv\",'a') as f:\n    for num, data in enumerate(test_data):\n        if num%1000 == 0: print('write {} line'.format(num))\n        img_num = data[1]\n        img_data = data[0]\n        orig = img_data\n        data = img_data.reshape(IMG_SIZE, IMG_SIZE,1)\n        model_out = model.predict([data])[0]\n        f.write('{},{}\\n'.format(img_num, model_out[0]))\nprint('done')","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}