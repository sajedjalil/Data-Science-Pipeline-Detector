{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"fdc9a491-7738-e791-a56b-d1f1a8ec4eae","_active":false},"source":"**Lets have fun!**","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"109c6eb0-5ac3-ad96-a78d-e987a2315960","_active":false,"collapsed":false},"outputs":[],"source":"# Python 3 Environment\n# Kaggle/Python docker image: https://github.com/kaggle/docker-python\n\n# IMPORTS DUH!\nimport os\nimport csv\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\n\n# cool ones\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, Dense, Dropout, Flatten, Activation\n\n#from keras.optimizers import RMSprop, SGD\n#from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n#from keras.utils import np_utils\n#from keras.regularizers import l2\n#from keras.utils.np_utils import to_categorical\n\nfrom keras.utils import np_utils\nfrom keras import backend as K\nK.set_image_dim_ordering('th')\n\n# set a random seed\nnp.random.seed(1)\n\nprint(\"let's go!\")","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a1bf5c7-65a0-ef4f-758a-0953a9f4bd0e","_active":false},"outputs":[],"source":"# set the training path\ntrain_path = \"../input/train\"\ntest_path = \"../input/test\"\nbase_path = \".\"\n\nprint(train_path)\nprint(test_path)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7be3a979-24dd-d683-17ed-62ad192ea174","_active":false},"outputs":[],"source":"# load filenames\nimages_dog = [img for img in os.listdir(train_path) if \"dog\" in img] # creates a list of all the dog filenames\nimages_cat = [img for img in os.listdir(train_path) if \"cat\" in img] # creates a list of all the dog filenames\nimages_test = [img for img in os.listdir(test_path)] # creates a list of all the file names\n\ntrain_dog = images_dog[:100] # select sample of dog filenames\ntrain_cat = images_cat[:100] # select sample of cat filenames\nvalid_dog = images_dog[101:201]\nvalid_cat = images_cat[101:201]\n\ntrain_list = train_dog + train_cat # join sample filenames\nvalid_list = valid_dog + valid_cat # join sample filenames\ntest_list = images_test[:100]\n\nprint(\"train list: \", train_list[:10])\nprint()\nprint(\"valid list: \", valid_list[:10])\nprint()\nprint(\"test list: \", test_list[:10])","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"408f9468-96da-5323-076a-d3fe0d598f93","_active":false},"outputs":[],"source":"# set image variables for when loading\nimg_size_row = 224\nimg_size_col = 224\n\nprint(\"row:\", img_size_row, \"col:\", img_size_col)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f3af473e-c584-1965-a358-76e1a97d710f","_active":false},"outputs":[],"source":"# create arrays for training and labels\ntrain = np.ndarray(shape=(len(train_list), img_size_row, img_size_col))\ntrain_labels = np.ndarray(len(train_list))\n\nvalid = np.ndarray(shape=(len(valid_list), img_size_row, img_size_col))\nvalid_labels = np.ndarray(len(valid_list))\n\ntest = np.ndarray(shape=(len(test_list), img_size_row, img_size_col))\n\nprint(\"train array shape: \", train.shape)\nprint(\"train_labels array shape: \", train_labels.shape)\nprint()\nprint(\"valid array shape: \", valid.shape)\nprint(\"valid_labels array shape: \", valid_labels.shape)\nprint()\nprint(\"test array shape: \", test.shape)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"e3f2a170-13f5-343a-7a7e-ff1e246fc9b1","_active":false},"source":"**PreProcess**","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d87b40f9-fd14-185e-5ce2-5148b64c0273","_active":false},"outputs":[],"source":"#### for loop to bring in the images and proces\n\n##################################            \n#### train #######################\n##################################\nfor i, img_path in enumerate(train_list): # only for images in the train list\n\n        # read in image\n        img = cv2.imread(os.path.join(train_path, img_path), 0) # the 0 indicates grayscale!\n\n        # create a canvas for the image for cropping and resziing while maintain image shape\n        if img.shape[0] < img.shape[1]:\n            img.resize([np.max(img.shape), np.max(img.shape)])\n\n        elif img.shape[0] > img.shape[1]:\n            img = np.array(img, order ='F')\n            img.resize([np.max(img.shape), np.max(img.shape)])\n\n        else:\n            img\n            \n        # resize each image\n        img = cv2.resize(img, (img_size_row, img_size_col), interpolation=cv2.INTER_CUBIC)\n\n        #scale between 0 and 1\n        img = (img-np.min(img))/(np.max(img)-np.min(img))\n\n        # load the img into train\n        train[i] = img\n\n        # for each img in train label 1 if dog else 0 (cat)\n        if \"dog\" in img_path:\n            train_labels[i] = 1\n        else:\n            train_labels[i] = 0\n\n            \n##################################            \n#### valid #######################\n##################################\n\nfor i, img_path in enumerate(valid_list): # only for images in the train list\n\n        # read in image (valid list also come from train path)\n        img = cv2.imread(os.path.join(train_path, img_path), 0) # the 0 indicates grayscale!\n\n        # create a canvas for the image for cropping and resziing while maintain image shape\n        if img.shape[0] < img.shape[1]:\n            img.resize([np.max(img.shape), np.max(img.shape)])\n\n        elif img.shape[0] > img.shape[1]:\n            img = np.array(img, order ='F')\n            img.resize([np.max(img.shape), np.max(img.shape)])\n\n        else:\n            img\n            \n        # resize each image\n        img = cv2.resize(img, (img_size_row, img_size_col), interpolation=cv2.INTER_CUBIC)\n\n        #scale between 0 and 1\n        img = (img-np.min(img))/(np.max(img)-np.min(img))\n\n        # load the img into valid\n        valid[i] = img\n\n        # for each img in train label 1 if dog else 0 (cat)\n        if \"dog\" in img_path:\n            valid_labels[i] = 1\n        else:\n            valid_labels[i] = 0\n            \n##################################            \n#### test ########################\n##################################\n\nfor i, img_path in enumerate(test_list): # only for images in the train list\n\n        # read in image\n        img = cv2.imread(os.path.join(test_path, img_path), 0) # the 0 indicates grayscale!\n\n        # create a canvas for the image for cropping and resziing while maintain image shape\n        if img.shape[0] < img.shape[1]:\n            img.resize([np.max(img.shape), np.max(img.shape)])\n\n        elif img.shape[0] > img.shape[1]:\n            img = np.array(img, order ='F')\n            img.resize([np.max(img.shape), np.max(img.shape)])\n\n        else:\n            img\n            \n        # resize each image\n        img = cv2.resize(img, (img_size_row, img_size_col), interpolation=cv2.INTER_CUBIC)\n\n        #scale between 0 and 1\n        img = (img-np.min(img))/(np.max(img)-np.min(img))\n\n        # load the img into valid\n        test[i] = img","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3adffe7b-520b-b37a-e3be-fc9017f63239","_active":false},"outputs":[],"source":"#show processed image train\nn = 50\ntrain_check = cv2.imread(os.path.join(train_path, train_list[n]))\nprint(\"train label: \", train_labels[n])\nprint(\"train before min: \", np.min(train_check), \"train before max: \", np.max(train_check))\nprint(\"train after min: \", np.min(train[n]), \"train after max: \", np.max(train[n]))\nplt.subplot(1,2,1)\nplt.imshow(train_check)\nplt.subplot(1,2,2)\nplt.imshow(train[n])\nplt.show()","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d2c18e8-232c-3591-0acc-b4698132293c","_active":false},"outputs":[],"source":"#show processed image valid\nn = 50\nvalid_check = cv2.imread(os.path.join(train_path, valid_list[n]))\nprint(\"valid label: \", valid_labels[n])\nprint(\"valid before min: \", np.min(valid_check), \"valid before max: \", np.max(valid_check))\nprint(\"valid after min: \", np.min(valid[n]), \"valid after max: \", np.max(valid[n]))\nplt.subplot(1,2,1)\nplt.imshow(valid_check)\nplt.subplot(1,2,2)\nplt.imshow(valid[n])\nplt.show()","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"90c2a748-0647-e47b-48ca-e64e1740086c","_active":false},"outputs":[],"source":"#show processed image test\nn = 50\ntest_check = cv2.imread(os.path.join(test_path, test_list[n]))\nprint(\"test before min: \", np.min(test_check), \"test before max: \", np.max(test_check))\nprint(\"test after min: \", np.min(test[n]), \"test after max: \", np.max(test[n]))\nplt.subplot(1,2,1)\nplt.imshow(test_check)\nplt.subplot(1,2,2)\nplt.imshow(test[n])\nplt.show()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"832c8289-b704-01e2-244d-78a950de0db4","_active":false},"source":"**Define Model**","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e3e6b2c-5f76-809e-aec0-60a9ec5674d1","_active":false},"outputs":[],"source":"#copied\nmodel = Sequential()\n\nmodel.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same', input_shape=(224, 224, 1)))\nmodel.add(Convolution2D(64, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\nmodel.add(Convolution2D(128, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same'))\nmodel.add(Convolution2D(256, 3, 3, activation='relu'))\nmodel.add(Convolution2D(256, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ad60efe-e46e-ebac-fef6-e0e52e6866eb","_active":false},"outputs":[],"source":"# basic! v1\n\n#always start with:\nmodel = Sequential()\n\n# add a 2D convolutional layer\n# has 20 feature maps that are 50x50 and uses a rectifier (relu) activation function\n# input shape defines the shape\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(img_size_row, img_size_col, 1), activation='relu'))\n\n# next is a pooling layer (pools all the convolutions back together)\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# next is the drop out layer\nmodel.add(Dropout(0.2))\n\n# next is the flattening which allows a full connected layer\nmodel.add(Flatten())\n\n# next is the dense fully connected layer with 128 neurons\nmodel.add(Dense(128, activation='relu'))\n\n# then activation\nmodel.add(Activation('softmax'))\n\n# then compile the beast\nmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9cb9686d-1437-de20-b381-752b4e410c7a","_active":false},"outputs":[],"source":"# run model on training set\ntrain_labels_ = np.to_categorical(train_labels) #convert labels to a matrix representation\n#train_labels_ = train_labels\ntrain_ = np.resize(train, (len(train), img_size_row, img_size_col, 1)) # adding the extra dimension for no rgb\n\nmodel.fit(train_, train_labels_, nb_epoch=1, batch_size=32)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d324cc2c-99cd-ea6d-c482-9c6dcab4b912","_active":false},"outputs":[],"source":"# run model on validate set\nvalid_labels_ = to_categorical(valid_labels, 2)\nvalid_ = np.resize(valid, (len(valid), img_size_row, img_size_col, 1))\n\nprint(\"train set :\", model.evaluate(train_, train_labels_, verbose=False)[1]*100, \"%\")\nprint(\"--------------------\")\nprint(\"valid set :\", model.evaluate(valid_, valid_labels_, verbose=False)[1]*100, \"%\")","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"5318b63f-2ff5-ad2c-42b2-15bebdf96d2c","_active":false},"source":"**Score out the final test set!!!**","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba5b9410-ca46-1af2-6179-b64db25add3b","_active":false},"outputs":[],"source":"# run model on test set\ntest_ = np.resize(test, (len(test), img_size_row, img_size_col, 1))\nmodel_out = model.predict([test_])\n\n# save predictions\npredictions = model_out[:,0] # only want the 1st column (index[0])","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b4c233e-844f-5205-2d5f-9f23cc86c102","_active":true},"outputs":[],"source":"print(\"test list length: \", len(test_list))\nprint()\nprint(test_list[:10])\nprint()\nprint(\"test score length: \", len(predictions))  \nprint()\nprint(predictions[:10])","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dea0119a-aaf2-7edb-86ca-bacb309de142","_active":false},"outputs":[],"source":"submission = pd.DataFrame({\"id\":test_list, \"label\": predictions})\nsubmission.to_csv('submission.csv', index=False)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c53af3c6-d8eb-b3e4-4c7c-6333f3037ce9","_active":false},"outputs":[],"source":"for i in range(0,10):\n    if predictions[i] >= 0.5: \n        print('I am {:.2%} sure this is a Dog'.format(predictions[i]))\n    else: \n        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i]))\n                     \n    plt.imshow(test[i])\n    plt.show()","execution_state":"idle"}]}