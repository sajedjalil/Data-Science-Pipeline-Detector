{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ab217a2-de9f-5857-cdad-420014932417"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport os\nimport PIL\n\ntrain_dir = \"../input/train/\"\nlabels = []\ntrain_imgs = []\nfrom PIL import Image\n\nfor filename in os.listdir(train_dir):\n    label, _, _ = filename.strip().split('.')\n    img = PIL.Image.open(train_dir + filename)\n    I = np.asarray(img.resize([128, 128]))\n    if label == 'cat':\n        labels.append(0)\n    else:\n        labels.append(1)\n    train_imgs.append(I)\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11214b33-56a2-1fc2-247b-54b8ef0f94a4"},"outputs":[],"source":"train_imgs = np.asarray(train_imgs)\nlabels = np.asarray(labels)\nprint(train_imgs.shape)\nprint(labels.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0f08529-e661-93c8-f8d2-5199026756f4"},"outputs":[],"source":"import tensorflow as tf\n\ndef cnn_model(imgs, is_training = True):\n    \n    \n    conv1 = tf.layers.conv2d(imgs, 64, [5, 5], [2, 2], padding = 'same', activation = tf.nn.relu)\n    bn1 = tf.layers.batch_normalization(conv1, axis = 1)\n    conv2 = tf.layers.conv2d(bn1, 128, [5, 5], [2, 2], padding = 'same', activation = tf.nn.relu)\n    bn2 = tf.layers.batch_normalization(conv2, axis = 1)\n    flat = tf.reshape(bn2, [tf.shape(imgs)[0], 32*32*128])\n    a1 = tf.layers.dense(flat, 1024, activation = tf.nn.relu)\n    logtis = tf.layers.dense(a1, 2)\n    return logtis\n    \n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae07c794-a32f-e9e3-f3fe-321f09cd4c16"},"outputs":[],"source":"\nwith tf.Session() as sess:\n    imgs = tf.placeholder(tf.float32, [None, 128, 128, 3])\n    y = tf.placeholder(tf.int32, [None])\n    logtis = cnn_model(imgs)\n    onehot_labels = tf.one_hot(y, depth=2)\n    loss = tf.losses.softmax_cross_entropy(onehot_labels, logtis)\n\n    optimizer = tf.train.AdamOptimizer()\n    optimizer.minimize(loss)\n\n    pred = tf.argmax(logtis, axis = 1)\n    print(type(labels))\n    _loss = sess.run([loss], {imgs : train_imgs[0:100], y : labels[0:100]})\n    print(_loss)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}