{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"391652ee-6f94-fb15-871d-541ccbe5f2d5"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2e5a958-f766-633c-509a-c5f04c61a1b6"},"outputs":[],"source":"# Standard-ish includes\nimport kagglegym\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nimport xgboost as xgb\nimport math\n\nimport time\n\n#from sklearn.preprocessing import PolynomialFeatures\n#from sklearn.pipeline import make_pipeline\n#from sklearn.linear_model import Ridge\n\nfrom operator import itemgetter"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d44f7ef2-02a2-85c8-1981-7fa7d4911b15"},"outputs":[],"source":"localrun = False     # keep data structures that (might) get freed to save memory\nusepublic = False    # Load the second half of training data, to get a better idea \nvmode = False        # Trains on whole data, exports a file with validation predictions \nall_features = False # Overrides feature list, for feature selection"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff30e8be-a445-d77f-b306-359c1d2de57d"},"outputs":[],"source":"# This is taken from Frans Slothoubers post on the contest discussion forum.\n# https://www.kaggle.com/slothouber/two-sigma-financial-modeling/kagglegym-emulation\n\ndef r_score(y_true, y_pred, sample_weight=None, multioutput=None):\n    r2 = r2_score(y_true, y_pred, sample_weight=sample_weight,\n                  multioutput=multioutput)\n    r = (np.sign(r2)*np.sqrt(np.abs(r2)))\n    if r <= -1:\n        return -1\n    else:\n        return r\n\n# From the xgboost script (along with the param settings)\n# https://www.kaggle.com/jacquespeeters/two-sigma-financial-modeling/xgboost-0-007-lb\n    \n# Functions for XGBOOST ########################################################\ndef xgb_obj_custom_r(y_pred, dtrain):\n    y_true = dtrain.get_label()\n    y_mean = np.mean(y_true)\n    y_median = np.median(y_true)\n    c1 = y_true\n    #c1 = y_true - y_mean\n    #c1 = y_true - y_median\n    grad = 2*(y_pred-y_true)/(c1**2)\n    hess = 2/(c1**2)\n    return grad, hess\n\ndef xgb_eval_custom_r(y_pred, dtrain):\n    #y_pred = np.clip(y_pred, -0.075, .075)\n#    y_pred[y_pred > .075] = .075\n#    y_pred[y_pred < -.075] = -.075\n    y_true = dtrain.get_label()\n    ybar = np.sum(y_true)/len(y_true)\n    ssres = np.sum((y_true - y_pred) ** 2)\n    sstot = np.sum((y_true - ybar)**2)\n    r2 = 1 - ssres/sstot\n    error = np.sign(r2) * np.absolute(r2)**0.5\n    return 'error', error\n\nenv = kagglegym.make()\no = env.reset()\n\n# Kagglegym emulator didn't provide these:\n# excl = [env.ID_COL_NAME, env.SAMPLE_COL_NAME, env.TARGET_COL_NAME, env.TIME_COL_NAME]\nexcl = ['id', 'sample', 'y', 'timestamp']\nbasecols = [c for c in o.train.columns if c not in excl]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"434bc419-6351-a59c-acfc-5bf7c1af010c"},"outputs":[],"source":"# Reduced columns\nrcol_orig = ['Dtechnical_20', 'y_prev_pred_avg_diff', 'Dtechnical_21', 'technical_43_prev', 'technical_20', 'y_prev_pred_avgT0', 'y_prev_pred_mavg5', 'y_prev_pred_avgT1', 'fundamental_8_prev', 'Dtechnical_40', 'technical_7_prev', 'technical_7', 'fundamental_5', 'Dtechnical_30', 'technical_32_prev', 'technical_14_prev', 'fundamental_1', 'fundamental_43_prev', 'Dfundamental_22', 'Dtechnical_35', 'Dtechnical_6', 'Dtechnical_17', 'Dtechnical_27', 'Dfundamental_42', 'fundamental_1_prev', 'Dtechnical_0', 'technical_40', 'technical_40_prev', 'fundamental_36', 'Dfundamental_33', 'Dfundamental_48', 'technical_27_prev', 'fundamental_62_prev', 'fundamental_41_prev', 'Dfundamental_50', 'fundamental_48', 'derived_2_prev', 'Dtechnical_18', 'fundamental_35', 'Dfundamental_49', 'fundamental_26_prev', 'technical_28_prev', 'Dfundamental_63', 'fundamental_10_prev', 'fundamental_36_prev', 'fundamental_16', 'Dfundamental_8', 'fundamental_32', 'fundamental_40_prev', 'derived_0', 'Dfundamental_32', 'fundamental_17', 'Dtechnical_7', 'fundamental_25', 'technical_35', 'Dtechnical_19', 'technical_35_prev', 'fundamental_8', 'Dtechnical_32', 'Dfundamental_18', 'Dtechnical_37', 'fundamental_33_prev', 'Dtechnical_28', 'fundamental_46', 'Dfundamental_1', 'Dfundamental_45', 'fundamental_18', 'technical_12', 'technical_44', 'fundamental_22', 'Dtechnical_5', 'technical_17_prev', 'Dfundamental_25']\nrcol = rcol_orig.copy()\n\nif all_features:\n    rcol = []\n    for c in basecols:\n        rcol.append(c)\n        rcol.append(c + '_prev')\n        rcol.append('D' + c)\n\n# Features used to compute previous Y value\nbacky_fset = ['technical_13', 'technical_20', 'technical_13_prev', 'technical_20_prev', 'technical_30_prev', 'technical_30']\nfor f in backy_fset:\n    if f not in rcol:\n        rcol.append(f)\n        \n# convert column name to base column\ndef get_basecol(r):\n    corename = r[1:] if r[0] == 'D' else r[0:]\n    corename = corename.split('_')\n    corename = corename[0] + '_' + corename[1]\n\n    return corename\n\ndef get_basecols(rcol):\n    duse = {}\n\n    for r in rcol:\n        if 'y' in r:\n            continue\n            \n        duse[get_basecol(r)] = True\n        \n    return [k for k in duse.keys()]\n\nbasecols_touse = get_basecols(rcol)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35193128-df78-3869-bea3-80107c7ac0a6"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"d2eb748b-bca7-0a39-8b5f-f0900655381c"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"841beb24-0370-0583-180c-c5091a9713ff"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b9c02db-27ce-63c9-82d5-cb79c22ac929"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"3f2137ed-fd0c-d084-5a94-8dc2ac48f705"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf566fe0-bfde-0417-2a46-503d0946954b"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"5e7a73dd-2124-ca39-a336-781a5964fa4c"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2d506213-05b1-713b-f91e-e710acbf9f8b"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"a60d35e2-8cc0-bdbb-7e06-8837be85c62c"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae2ad2ab-b5b8-ab16-6524-e81d9bdd7366"},"outputs":[],"source":"if vmode:\n    preds_xgb = model[0].predict(valid_xgb, ntree_limit=model[0].best_ntree_limit)\n    preds_linear = model2.predict(prep_linear(xvalid))\n    \n    preds = (preds_xgb * 0.7) + (preds_linear * 0.3)\n    #preds = preds_xgb\n    \n    rs = kagglegym.r_score(xvalid.y, preds)\n    \n    ID = 'expv-{0}.pkl'.format(int(rs * 10000000))\n    print(rs, ID)\n    \n    #ID = 'subv-203172.pkl' # if actual submission\n    \n    output = xvalid[['id', 'timestamp', 'y']].copy()\n    output['y_hat'] = preds\n    output['y_hat_xgb'] = preds_xgb\n    output['y_hat_linear'] = preds_linear\n    \n    output.to_pickle(ID)\n\n# Not the final version I used, this just shows which features actually got picked up at all...\nif all_features:\n    m = model[0]\n\n    fs = m.get_fscore()\n    fsl = [(f,fs[f]) for f in fs.keys()]\n    fsl = sorted(fsl, key=itemgetter(1), reverse=True)\n\n    print('rcol =', [f[0] for f in fsl])"},{"cell_type":"markdown","metadata":{"_cell_guid":"273b7afa-c8a9-3c36-bfe0-9c7ebe1ed8b9"},"source":"The code below is meant to be run with local/usepublic/allfeatures all set to True.  It then multiplies normalized train+test and keeps everything above 0.  \n\nIt's inspired by the xgboost refresh updater kernel: https://www.kaggle.com/tks0123456789/two-sigma-financial-modeling/xgboost-refresh-updater-oob-feature-importance"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08ea2922-d44e-b758-cbbc-6b483b1f5bae"},"outputs":[],"source":"def update_model(m, params_in, cols_to_use):\n\n    params = params_in.copy()\n    \n    params.update({'process_type': 'update',\n                       'updater'     : 'refresh',\n                       'refresh_leaf': False})\n\n    m_train = xgb.train(params, train_xgb, m.best_ntree_limit, xgb_model=m)\n    m_test = xgb.train(params, public_xgb, m.best_ntree_limit, xgb_model=m)\n\n    imp = pd.DataFrame(index=cols_to_use)\n    imp['train'] = pd.Series(m_train.get_score(importance_type='gain'), index=cols_to_use)\n#    imp['valid'] = pd.Series(m_valid.get_score(importance_type='gain'), index=cols_to_use)\n    imp['test'] = pd.Series(m_test.get_score(importance_type='gain'), index=cols_to_use)\n\n    imp = imp.fillna(0)\n    \n    return m_train, m_test, imp\n\nm_train, m_test, imp_orig = update_model(model[0], params, cols_to_use)\n\nimp = imp_orig.copy()\n\nimp.train = imp.train / imp.train.max()\nimp.test = imp.test / imp.test.max()\n\nimp['train_test'] = imp.train * imp.test\n\nimp = imp.sort_values('train_test', ascending=False)\nimpr = imp[imp.train_test > 0]\n\nprint(list(impr.index))\n\n# features output from above\n# ['Dtechnical_20', 'technical_7', 'technical_20', 'technical_7_prev', 'Dtechnical_21', 'fundamental_1', 'Dtechnical_40', 'fundamental_36', 'technical_14_prev', 'Dtechnical_30', 'fundamental_1_prev', 'fundamental_5', 'technical_35', 'Dtechnical_35', 'technical_35_prev', 'Dtechnical_19', 'technical_40', 'Dfundamental_49', 'fundamental_41_prev', 'fundamental_36_prev', 'technical_40_prev', 'fundamental_8', 'Dfundamental_48', 'Dtechnical_0', 'derived_2_prev', 'fundamental_46', 'Dfundamental_22', 'fundamental_43_prev', 'Dtechnical_17', 'Dfundamental_33', 'Dfundamental_50', 'technical_43_prev', 'Dfundamental_63', 'technical_27_prev', 'technical_17_prev', 'Dtechnical_18', 'fundamental_10_prev', 'Dtechnical_27', 'Dfundamental_18', 'fundamental_25', 'fundamental_18', 'Dfundamental_8', 'fundamental_35', 'fundamental_8_prev', 'technical_12', 'technical_32_prev', 'fundamental_17', 'Dtechnical_7', 'fundamental_26_prev', 'fundamental_33_prev', 'Dtechnical_32', 'derived_0', 'Dfundamental_32', 'Dfundamental_42', 'fundamental_16', 'fundamental_32', 'Dtechnical_28', 'technical_28_prev', 'fundamental_40_prev', 'fundamental_62_prev', 'technical_44', 'Dfundamental_25', 'fundamental_48']"},{"cell_type":"markdown","metadata":{"_cell_guid":"08f7a6fa-432a-d1f3-6b37-4b71b42b8096"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0719444-275a-8ec8-ebfc-2e1d0ebf98be"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}