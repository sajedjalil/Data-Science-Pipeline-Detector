{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c68b870f-eed6-ade2-34f2-c273e421192b"},"source":"Big Picture Data Look\n\nOne of the things I ALWAYS like to do is just look at the data.  Not try and find and patterns, correlations just yet--just look at \"my\" data. So per usual--here we go--found some unusual fun with this set so I thought I would share as I learn mostly by looking at other people's code."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9b28a85-ee06-814b-e6a6-a3a14a4c0e69"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n#I like to add silly comments to see if people read them\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline  \n\n\n# read that data in!\ntrain = pd.read_hdf('../input/train.h5')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"553835c8-549b-1656-07d1-3a378f2c2a48"},"outputs":[],"source":"print(train.shape)\ntrain.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df4e8b83-b8a0-219e-363d-6238c0c824d7"},"outputs":[],"source":"#well well well, my old friend NaN is here.  I know how to deal with him though.\n#lets make a bunch of histograms and look at how my data is distributed\ncolnames=list(train.columns.values)\n#since I know what is about to happen, I'll save you 90 graphs of repeats\ncolnames=colnames[1:5]\nfor i in colnames:\n    data=train.loc[train.loc[:,i].notnull(),i]\n    #data=data.loc[(data>np.percentile(data,1)) & (data<np.percentile(data,99))]\n    sns.distplot(data,kde=False,hist=True)\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75ee431a-632d-ccd5-d1c5-4cfd8c313f79"},"outputs":[],"source":"#that did not look good.  lets take a look at a cdf for one of those \"spikes\"\nsorted_data = np.sort(train['derived_0'])  \nplt.step(sorted_data, np.arange(sorted_data.size)/sorted_data.size) \nplt.title('derived_0 CDF')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa46be0e-4aa6-2238-c5cb-9cd16b94cf3b"},"outputs":[],"source":"#hmm it looks like we need to zoom in and will see that near zero we have a normal variable\n#this means we have large valued outliers.\nsorted_data = np.sort(train['derived_0'])  \nplt.step(sorted_data, np.arange(sorted_data.size)/sorted_data.size) \nplt.title('derived_0 CDF')\nplt.xlim(-1,1)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69859ce7-4179-220a-ecfe-f60c8721c35b"},"outputs":[],"source":"#Well that was not cool.  It looks like we have outliers.  \n#since we are just looking, lets kill those outliers and do it dynamically.\n#use np.percentile(x,n) to get six-sigma worth of data\ncolnames=list(train.columns.values)\nfor i in colnames:\n    data=train.loc[train.loc[:,i].notnull(),i]\n    data=data.loc[(data>np.percentile(data,0.5)) & (data<np.percentile(data,99.5))]\n    sns.distplot(data,kde=False,hist=True)\n    plt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}