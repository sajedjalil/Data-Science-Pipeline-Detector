{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"596dd48b-5460-a0ab-6273-0f33b4bda3f3"},"source":"I was trying to figure out how all the kaggle gym works so I could work offline and reproduce scoring.  So I took one of the initial scripts and ran it piece by piece to see if I could reproduce the scoring.  I find this helpful when trying to learn new things with coding--run it bit by bit and watch what happens."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6eed7272-3a0a-3d02-dec7-9eddf9fcbfd4"},"outputs":[],"source":"#not my code.  Please direct your thanks to Yunfeng Zhu\nimport kagglegym\nimport numpy as np\nimport pandas as pd\n# from sklearn import linear_model as lm\nfrom sklearn.linear_model import Ridge\n\ntarget = 'y'\n\n# The \"environment\" is our interface for code competitions\nenv = kagglegym.make()\n\n# We get our initial observation by calling \"reset\"\nobservation = env.reset()\n\n# Get the train dataframe\ntrain = observation.train\nmean_values = train.mean(axis=0)\ntrain.fillna(mean_values, inplace=True)\n\n# cols_to_use = ['technical_30', 'technical_20', 'fundamental_11']\n\n# Observed with histograns:\nlow_y_cut = -0.086093\nhigh_y_cut = 0.093497\n\ny_is_above_cut = (train.y > high_y_cut)\ny_is_below_cut = (train.y < low_y_cut)\ny_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)\n\nridge1 = Ridge() ## f11 only\nridge2 = Ridge() ## t30 and f11\nridge3 = Ridge() ## t20 and f11\nridge4 = Ridge() ## t30, t20, f11\n\ntrain = train.loc[y_is_within_cut]\n\nindex1 = train.query(\"technical_30 == 0.0 & technical_20 == 0.0\").index\nindex2 = train.query(\"technical_30 != 0.0 & technical_20 == 0.0\").index\nindex3 = train.query(\"technical_30 == 0.0 & technical_20 != 0.0\").index\nindex4 = train.query(\"technical_30 != 0.0 & technical_20 != 0.0\").index\n\nridge1.fit(train.loc[index1, [\"fundamental_11\"]].values, train.loc[index1].y)\nridge2.fit(train.loc[index2, ['technical_30', 'fundamental_11']].values, train.loc[index2].y)\nridge3.fit(train.loc[index3, ['technical_20', 'fundamental_11']].values, train.loc[index3].y)\nridge4.fit(train.loc[index4, ['technical_30', 'technical_20', 'fundamental_11']].values, train.loc[index4].y)\n\n\n# model = Ridge()\n# model.fit(np.array(train.loc[y_is_within_cut, cols_to_use].values), train.loc[y_is_within_cut, target])\n\n# ymean_dict = dict(train.groupby([\"id\"])[\"y\"].mean())\nymedian_dict = dict(train.groupby([\"id\"])[\"y\"].median())\n\n\ndef get_weighted_y(series):\n    id, y = series[\"id\"], series[\"y\"]\n    # return 0.95 * y + 0.05 * ymean_dict[id] if id in ymean_dict else y\n    return 0.95 * y + 0.05 * ymedian_dict[id] if id in ymedian_dict else y"},{"cell_type":"markdown","metadata":{"_cell_guid":"f4f4a451-d4de-0fec-d950-0a3ba271a092"},"source":"So now instead of looping, I am going to do a single iteration.  The psuedo-test set starts at timestamp \"906\" (reminder for submission as I understand the whole training set is used, before for example kaggle gym, it is spit into 2 to provide a sample \"test\" set)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ede0c2fd-58b7-661b-6d31-a39448512112"},"outputs":[],"source":"    observation.features.fillna(mean_values, inplace=True)\n    # test_x = np.array(observation.features[cols_to_use].values)\n    # observation.target.y = model.predict(test_x).clip(low_y_cut, high_y_cut)\n    \n    index1 = observation.features.query(\"technical_30 == 0.0 & technical_20 == 0.0\").index\n    index2 = observation.features.query(\"technical_30 != 0.0 & technical_20 == 0.0\").index\n    index3 = observation.features.query(\"technical_30 == 0.0 & technical_20 != 0.0\").index\n    index4 = observation.features.query(\"technical_30 != 0.0 & technical_20 != 0.0\").index\n    \n    if len(index1) > 0:\n        observation.target.loc[index1, 'y'] = ridge1.predict(observation.features.loc[index1, [\"fundamental_11\"]].values).clip(low_y_cut, high_y_cut)\n    if len(index2) > 0:\n        observation.target.loc[index2, 'y'] = ridge2.predict(observation.features.loc[index2, ['technical_30', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n    if len(index3) > 0:\n        observation.target.loc[index3, 'y'] = ridge3.predict(observation.features.loc[index3, ['technical_20', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n    if len(index4) > 0:\n        observation.target.loc[index4, 'y'] = ridge4.predict(observation.features.loc[index4, ['technical_30', 'technical_20', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n\n    ## weighted y using average value\n    observation.target.y = observation.target.apply(get_weighted_y, axis = 1)\n    \n    #observation.target.fillna(0, inplace=True)\n    target = observation.target\n    timestamp = observation.features[\"timestamp\"][0]"},{"cell_type":"markdown","metadata":{"_cell_guid":"b1bc95fe-f8ad-de37-7542-ae5c927ce705"},"source":"So now i am going to look at the y predicted.  I added in a timestamp just for clarity."},{"cell_type":"markdown","metadata":{"_cell_guid":"6b3c834a-d405-8e15-85d4-ba5ee3d9cfb4"},"source":"Lets load in the \"real\" data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18416a59-9656-ddd4-d13e-4fef13dea932"},"outputs":[],"source":"real_y=pd.read_hdf(\"../input/train.h5\")\nreal_y=real_y.iloc[:,[0,1,-1]]\nreal_y=real_y[real_y.timestamp>905]\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"9ff0b6fe-a16e-1bd9-0e34-33bcdf0f266f"},"source":"Ok so i am going to try and replicate the score.  Early on I missed that we sum over the square of the difference.    One will note that the \"Score\" returned and calculated match nicely."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"027ba70a-9d6c-168a-3b6b-1d9d5c160cf0"},"outputs":[],"source":"u=np.mean(real_y[real_y.timestamp==906].y)\nnum=np.sum((real_y[real_y.timestamp==906].y.values-observation.target.y)**2)\ndem=np.sum((real_y[real_y.timestamp==906].y-u)**2)\nr2=1-num/dem\nif r2<0:\n    print(-np.sqrt(-r2))\nelse:\n    print(np.sqrt(r2))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0c736a8-e152-f012-4477-1cd6ea575e7a"},"outputs":[],"source":"observation, reward, done, info = env.step(target)\nprint(reward)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b7c0993f-159d-7ec6-fa61-bc42e3af563e"},"source":"Ok lets try a second iteration (timestamp 907)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce8a6cb4-3134-e886-3450-2f6339aac7ea"},"outputs":[],"source":"    observation.features.fillna(mean_values, inplace=True)\n    # test_x = np.array(observation.features[cols_to_use].values)\n    # observation.target.y = model.predict(test_x).clip(low_y_cut, high_y_cut)\n    \n    index1 = observation.features.query(\"technical_30 == 0.0 & technical_20 == 0.0\").index\n    index2 = observation.features.query(\"technical_30 != 0.0 & technical_20 == 0.0\").index\n    index3 = observation.features.query(\"technical_30 == 0.0 & technical_20 != 0.0\").index\n    index4 = observation.features.query(\"technical_30 != 0.0 & technical_20 != 0.0\").index\n    \n    if len(index1) > 0:\n        observation.target.loc[index1, 'y'] = ridge1.predict(observation.features.loc[index1, [\"fundamental_11\"]].values).clip(low_y_cut, high_y_cut)\n    if len(index2) > 0:\n        observation.target.loc[index2, 'y'] = ridge2.predict(observation.features.loc[index2, ['technical_30', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n    if len(index3) > 0:\n        observation.target.loc[index3, 'y'] = ridge3.predict(observation.features.loc[index3, ['technical_20', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n    if len(index4) > 0:\n        observation.target.loc[index4, 'y'] = ridge4.predict(observation.features.loc[index4, ['technical_30', 'technical_20', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n\n    ## weighted y using average value\n    observation.target.y = observation.target.apply(get_weighted_y, axis = 1)\n    \n    #observation.target.fillna(0, inplace=True)\n    target = observation.target\n    timestamp = observation.features[\"timestamp\"][0]"},{"cell_type":"markdown","metadata":{"_cell_guid":"09871408-71aa-ec88-108a-a7fca32597c1"},"source":"Once again, we see the scoring matches. for this iteration"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bd61839-b48d-a82a-df49-8608d5ea45dc"},"outputs":[],"source":"u=np.mean(real_y[real_y.timestamp==907].y)\nnum=np.sum((real_y[real_y.timestamp==907].y.values-observation.target.y)**2)\ndem=np.sum((real_y[real_y.timestamp==907].y-u)**2)\nr2=1-num/dem\nif r2<0:\n    print(-np.sqrt(-r2))\nelse:\n    print(np.sqrt(r2))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2461c3d-e905-c61b-e3e6-3b8ecfe46e86"},"outputs":[],"source":"observation, reward, done, info = env.step(target)\nprint(reward)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b2a0d2e3-883f-9728-0473-31a7c1a35fca"},"source":" Now according to William Cukierski the final \"submission\" score is across all of the data not an average of each day[sic]/timestamp. (https://www.kaggle.com/c/two-sigma-financial-modeling/discussion/26579#155126)\nThus to estimate your score, you will need a \"holding\" variable of the numerator."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce4a3a6a-9e75-1b30-e287-0d648a0b59f9"},"outputs":[],"source":"import kagglegym\nimport numpy as np\nimport pandas as pd\n# from sklearn import linear_model as lm\nfrom sklearn.linear_model import Ridge\nreal_y=pd.read_hdf(\"../input/train.h5\")\nreal_y=real_y.iloc[:,[0,1,-1]]\nreal_y=real_y[real_y.timestamp>905]\n\ntarget = 'y'\n\n# The \"environment\" is our interface for code competitions\nenv = kagglegym.make()\n\n# We get our initial observation by calling \"reset\"\nobservation = env.reset()\n\n# Get the train dataframe\ntrain = observation.train\nmean_values = train.mean(axis=0)\ntrain.fillna(mean_values, inplace=True)\n\n# cols_to_use = ['technical_30', 'technical_20', 'fundamental_11']\n\n# Observed with histograns:\nlow_y_cut = -0.086093\nhigh_y_cut = 0.093497\n\ny_is_above_cut = (train.y > high_y_cut)\ny_is_below_cut = (train.y < low_y_cut)\ny_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)\n\nridge1 = Ridge() ## f11 only\nridge2 = Ridge() ## t30 and f11\nridge3 = Ridge() ## t20 and f11\nridge4 = Ridge() ## t30, t20, f11\n\ntrain = train.loc[y_is_within_cut]\n\nindex1 = train.query(\"technical_30 == 0.0 & technical_20 == 0.0\").index\nindex2 = train.query(\"technical_30 != 0.0 & technical_20 == 0.0\").index\nindex3 = train.query(\"technical_30 == 0.0 & technical_20 != 0.0\").index\nindex4 = train.query(\"technical_30 != 0.0 & technical_20 != 0.0\").index\n\nridge1.fit(train.loc[index1, [\"fundamental_11\"]].values, train.loc[index1].y)\nridge2.fit(train.loc[index2, ['technical_30', 'fundamental_11']].values, train.loc[index2].y)\nridge3.fit(train.loc[index3, ['technical_20', 'fundamental_11']].values, train.loc[index3].y)\nridge4.fit(train.loc[index4, ['technical_30', 'technical_20', 'fundamental_11']].values, train.loc[index4].y)\n\n\n# model = Ridge()\n# model.fit(np.array(train.loc[y_is_within_cut, cols_to_use].values), train.loc[y_is_within_cut, target])\n\n# ymean_dict = dict(train.groupby([\"id\"])[\"y\"].mean())\nymedian_dict = dict(train.groupby([\"id\"])[\"y\"].median())\n\n\ndef get_weighted_y(series):\n    id, y = series[\"id\"], series[\"y\"]\n    # return 0.95 * y + 0.05 * ymean_dict[id] if id in ymean_dict else y\n    return 0.95 * y + 0.05 * ymedian_dict[id] if id in ymedian_dict else y\n\ntot=0\nwhile True:\n    observation.features.fillna(mean_values, inplace=True)\n    # test_x = np.array(observation.features[cols_to_use].values)\n    # observation.target.y = model.predict(test_x).clip(low_y_cut, high_y_cut)\n    \n    index1 = observation.features.query(\"technical_30 == 0.0 & technical_20 == 0.0\").index\n    index2 = observation.features.query(\"technical_30 != 0.0 & technical_20 == 0.0\").index\n    index3 = observation.features.query(\"technical_30 == 0.0 & technical_20 != 0.0\").index\n    index4 = observation.features.query(\"technical_30 != 0.0 & technical_20 != 0.0\").index\n    \n    if len(index1) > 0:\n        observation.target.loc[index1, 'y'] = ridge1.predict(observation.features.loc[index1, [\"fundamental_11\"]].values).clip(low_y_cut, high_y_cut)\n    if len(index2) > 0:\n        observation.target.loc[index2, 'y'] = ridge2.predict(observation.features.loc[index2, ['technical_30', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n    if len(index3) > 0:\n        observation.target.loc[index3, 'y'] = ridge3.predict(observation.features.loc[index3, ['technical_20', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n    if len(index4) > 0:\n        observation.target.loc[index4, 'y'] = ridge4.predict(observation.features.loc[index4, ['technical_30', 'technical_20', 'fundamental_11']].values).clip(low_y_cut, high_y_cut)\n\n    ## weighted y using average value\n    observation.target.y = observation.target.apply(get_weighted_y, axis = 1)\n    \n    #observation.target.fillna(0, inplace=True)\n    target = observation.target\n    timestamp = observation.features[\"timestamp\"][0]\n    ###here is the only thing I changed###\n    tot=np.sum((real_y[real_y['timestamp']==timestamp].y.values-observation.target.y)**2)+tot\n    if timestamp % 100 == 0:\n        print(\"Timestamp #{}\".format(timestamp))\n\n    observation, reward, done, info = env.step(target)\n    if done:\n        break\n    \nprint(info)"},{"cell_type":"markdown","metadata":{"_cell_guid":"5b6a5ce9-5730-4470-6918-ad913e4b91cc"},"source":"Since we kept all the predicted values in the variable \"tot\"  (aka we have the numerator of r), we just use are the formula for an overall score.  And we find things match nicely.  Hopefully that clears things up for people, I know it took me a while to figure out what was going on."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e93644ee-4af9-c06e-61f9-8ca24eb6c98b"},"outputs":[],"source":"u=np.mean(real_y.y)\ndem=np.sum((real_y.y.values-u)**2)\nr2=1-tot/dem\nif r2<0:\n    print(-np.sqrt(-r2))\nelse:\n    print(np.sqrt(r2))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}