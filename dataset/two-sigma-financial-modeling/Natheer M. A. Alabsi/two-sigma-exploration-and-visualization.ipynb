{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3a59bf59-0e19-5a4f-cf2b-16b148377369"},"source":"This is an initial exploration of the dataset to find the parameters which has a strong correlation with the target variable. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"484f8ff7-a40f-5d45-a670-f936f506a4ff"},"outputs":[],"source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport plotly.plotly as py\nimport seaborn as sns\n\n%matplotlib inline\n\npd.set_option('display.max_columns', 120)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e726dde6-5bb6-6422-a6f8-70c6de3fd3f4"},"outputs":[],"source":"# read-in the training data\nwith pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n    df = train.get(\"train\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca3af82c-0ef2-3084-33e0-f727dea90549"},"outputs":[],"source":"# I will keep a copy of the dataframe for later use\ndf1 = df.copy()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e8e2804-e09b-06a3-70c2-8f29916708c5"},"outputs":[],"source":"df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e654c66-aa19-3e4b-8482-5c612d94881b"},"outputs":[],"source":"# let's check the size of the dataframe\nprint(\"Number of rows:\", df.shape[0])\nprint(\"Number of columns:\", df.shape[1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"017c16c2-5aeb-51cc-d491-7f8405578b16"},"outputs":[],"source":"# Extract the basic statistics \ndf.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ca2aa400-3962-b3ba-c931-4257d6a09864"},"source":"**Number of the missing values**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb8c5d09-ad8d-3fe7-a149-fda980e24226"},"outputs":[],"source":"# Let's look how many missing values in each column \n# We will sort missing values to bring column with the highest number of missing values at the top\n# We will see the number of missing values in each of the first 30 columns\n\ndf.isnull().sum().sort(axis=0, ascending=False, inplace=False).head(30)"},{"cell_type":"markdown","metadata":{"_cell_guid":"4bbb4420-271e-99e6-8ffe-cab0eb1d1cd2"},"source":"Since we have a lot of missing values, we should find a strategy to replace them with some correlated values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac94db18-1bfd-6c4d-8f73-c0409ee9ff20"},"outputs":[],"source":"# But for now I am going to inpute any missing values with the mean\n# I will deal with this major issue later on\n\ndf = df.fillna(df.mean()['derived_0':'y'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dfe1767e-9864-c38f-2de2-dcce7cb01e7d"},"outputs":[],"source":"# Double check the missing values\ndf.isnull().sum().head(30)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e64a2df0-f681-f859-605a-9563b0361d71"},"outputs":[],"source":"# Let's see the distribution of the target variable\n\ndf[\"y\"].hist(bins = 30, color = \"orange\")\nplt.xlabel(\"Target Variable\")\nplt.ylabel(\"Frequency\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9dcbb9e-f3b9-1518-fcac-9dfe1c1a1203"},"outputs":[],"source":"# Take absolute values \n#df.loc[:, \"derived_0\": \"technical_44\"] = df.loc[:, \"derived_0\": \"technical_44\"].abs()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29fccb61-de24-eb0b-6cbe-9dad1aa83e26"},"outputs":[],"source":"# Groupby the target variable\ndf_f = (df.groupby(pd.cut(df[\"y\"], [-0.087,-0.067,-0.047,-0.027,-0.007,0.013,0.033,0.053,0.073,0.094], right=False))\n        .mean())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88a0d8bd-535f-0cd6-d1aa-3efbbfe1d74d"},"outputs":[],"source":"df_f.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a7baaf1-9630-569f-63da-0dbb7171a19c"},"outputs":[],"source":"# The correlation matrix\ncor_mat = df_f.corr(method='pearson', min_periods=1).sort(axis=0, ascending=False, inplace=False)\ncor_mat.head(20) # Look at the first 20 columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2cb7a3a6-22d4-69b4-9fb3-73e1be6e1741"},"outputs":[],"source":"# The correlation with the target variable sorted in a descending order\n# Look at the first 30 parameters\ncor_mat.iloc[0,:].sort(axis=0, ascending=False, inplace=False).head(30) "},{"cell_type":"markdown","metadata":{"_cell_guid":"ec58c1b6-5ca7-2d43-c829-76a18d75d57a"},"source":"Let's plot the most correlated variables with the target variable\nThe most correlated variables in a descending order:\ntechnical_0\"  \ntechnical_24  \ntechnical_44"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2647c49-79bb-515f-f55c-cc41e98e0981"},"outputs":[],"source":"alpha = plt.figure()\nplt.scatter(df_f[\"technical_0\"], df_f[\"y\"], alpha=.1, s=400)\nplt.xlabel(\"technical_0\") \nplt.ylabel(\"Target variable\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6907152a-c44d-1331-978a-92ebf7ad65f8"},"outputs":[],"source":"alpha = plt.figure()\nplt.scatter(df_f[\"technical_24\"], df_f[\"y\"], alpha=.1, s=400)\nplt.xlabel(\"technical_24\") \nplt.ylabel(\"Target variable\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b518d172-8fb7-bba1-e1f7-19f00d1df9aa"},"outputs":[],"source":"alpha = plt.figure()\nplt.scatter(df_f[\"technical_44\"], df_f[\"y\"], alpha=.1, s=400)\nplt.xlabel(\"technical_44\") \nplt.ylabel(\"Target variable\")\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7b999d8f-5e1d-1a19-d80b-fd5e69559cae"},"source":"The correlation is not clear yet and this is maybe due to the issue of the missing values.\nI am going to remove the missing values once to check the correlations with the target variables in case we used only clean data without missing values."},{"cell_type":"markdown","metadata":{"_cell_guid":"8c62d120-7fee-92c6-2931-8a1c1aa545d3"},"source":"**Remove the missing values**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e5a0a1d-03a8-35a1-3380-218d1103664f"},"outputs":[],"source":"df_a = df1.dropna(axis=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f9feaec-eb61-9f1a-0bdc-2b147c5f5425"},"outputs":[],"source":"len(df_a)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f0910f92-0b7b-6756-a060-107bb05cf5d5"},"source":"We have 223040 observations left after we removed the missing values. Let's use this clean data for exploration and later I will deal with the issue of the missing values in a reasonable way."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2da145b7-863d-bbb8-fbdb-5a3c08b981c8"},"outputs":[],"source":"# Again groupby the target variable\ndf_f = (df_a.groupby(pd.cut(df_a[\"y\"], [-0.087,-0.067,-0.047,-0.027,-0.007,0.013,0.033,0.053,0.073,0.094], right=False))\n        .mean())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d37ce46-bf01-6567-a086-29e24de3157a"},"outputs":[],"source":"# The correlation matrix\ncor_mat = df_f.corr(method='pearson', min_periods=1).sort(axis=0, ascending=False, inplace=False)\ncor_mat.head(20)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b68ab901-901e-cf22-fca1-80827120480d"},"outputs":[],"source":"# The correlation with the target variable sorted in a descending order\ncor_mat.iloc[0,:].sort(axis=0, ascending=False, inplace=False).head(20)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f4e30a3f-d0f6-7e06-b3aa-d3c1dc842d87"},"source":"Nice! We have got a better correlation than before. It seems that inputting the missing values with the means has degraded the correlation with the target variable."},{"cell_type":"markdown","metadata":{"_cell_guid":"77061d61-3cba-bc8d-008f-c853f52ca33e"},"source":"Let's plot the most correlated variables with the target variable. Still the most correlated variables are the same even after the missing data is removed. The most correlated variables in a descending order:\ntechnical_0\"\ntechnical_24\ntechnical_44"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cbc55272-07d3-f64b-e8d0-d56fa291e18d"},"outputs":[],"source":"cor_matt = cor_mat.iloc[0,:].sort(axis=0, ascending=False, inplace=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"720b7568-20dc-9034-278a-50f5de4f29fd"},"outputs":[],"source":"# Extract the most 10 correlated variables\ncor_matt = cor_matt.keys()[1:10]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0bcb94c9-0e28-fbb2-9653-9f2722d3b44e"},"outputs":[],"source":"for i in cor_matt:\n    alpha = plt.figure()\n    plt.scatter(df_f[i], df_f[\"y\"], alpha=.1, s=400)\n    plt.xlabel(i) \n    plt.ylabel(\"Target Variable\")\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b99deb95-caa6-5598-cfc6-1caf305dbb53"},"outputs":[],"source":"# Let's take a 1000 sample of the data to explore \n# We will use raw data which has the missing data removed from it\ndf_m = df_a.sample(n=1000)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2941916-b5b9-8c1a-cafd-8c9b2a9488da"},"outputs":[],"source":"# Plot the most correlated variables \nfor i in cor_matt:\n    alpha = plt.figure()\n    plt.scatter(df_m[\"timestamp\"], df_m[i], alpha=.5)\n    plt.xlabel(\"timestamp\") \n    plt.ylabel(i)\n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"4248fa9c-9e89-c322-2ee9-8a57af8cba75"},"source":"**Thanks for visiting. This was a first glimpse on the data and more is coming shortly**"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}