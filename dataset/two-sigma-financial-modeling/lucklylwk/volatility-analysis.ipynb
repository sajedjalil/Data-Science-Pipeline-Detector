{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f174637d-2a9e-a6d4-d517-3841a3c3cf33"},"source":"## Basic start to volatility analysis ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36d9aa01-631a-3b77-6104-c0c33f7a8329"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a059f4b-44e2-839e-133a-125b05d8fa0d"},"outputs":[],"source":"with pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n    # Note that the \"train\" dataframe is the only dataframe in the file\n    df = train.get(\"train\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d797ee82-870f-d416-44ec-f193ec1582d1"},"outputs":[],"source":"print(df.shape) # Size of the dataset\nprint(df.timestamp.unique().shape[0]) # How many distinct days?\nprint(df.id.unique().shape[0]) # How many distinct assets?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66592de3-858a-745a-0270-a4de847d9b93"},"outputs":[],"source":"plt.figure(figsize=(9,2))\ndf.groupby('id').size().hist(bins=200) # How many days per asset."},{"cell_type":"markdown","metadata":{"_cell_guid":"7baecdf0-0eeb-6ba2-a9b8-04bf0931a3e8"},"source":"## Volatility ##\n\nLets look at the rolling volatility for the individual assets. To make sure we have enough data to work with we'll only use assets with a minimum number of days."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52c4479c-106e-3cb1-6921-d242f79660ff"},"outputs":[],"source":"# Lets take all assets with at least 100 days.\nmin_days = 100\n\nids_tmp = df.groupby('id').size() > min_days\nprint(ids_tmp.shape)\nids = ids_tmp.index.values[np.where(ids_tmp.values==True)]\nprint(ids.shape)\n\nids_tmp = None"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8bf7f3ac-1f69-9956-f1f1-d376f9e1d7c8"},"outputs":[],"source":"# For these assets we will calculate the 30 day rolling volatility.\ndf['Vol-20d'] = np.nan\ndf['Vol-30d'] = np.nan\ndf['Vol-60d'] = np.nan\ndf['Vol-90d'] = np.nan\n\n\n# Function to calculate the annualised volatility\ndef calculate_volatility(series_y, size=30):\n    return np.sqrt(260) * series_y.rolling(window=size, min_periods=size, center=False).std()\n\n\nfor assetId in ids:\n    ix = df.id == assetId\n    df.loc[ix, 'Vol-20d'] = calculate_volatility(df.loc[ix, 'y'], size=20)\n    df.loc[ix, 'Vol-30d'] = calculate_volatility(df.loc[ix, 'y'], size=30)\n    df.loc[ix, 'Vol-60d'] = calculate_volatility(df.loc[ix, 'y'], size=60)\n    df.loc[ix, 'Vol-90d'] = calculate_volatility(df.loc[ix, 'y'], size=90)\n\nprint('Done!')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f906eb7a-de1c-41d2-1b0b-9ad27213bc84"},"outputs":[],"source":"# Lets plot the volatility versus the returns...\nplt.figure(figsize=(9,2))\ndf[df['Vol-20d'].notnull()].plot(x='Vol-20d', y='y', kind='scatter', alpha=0.0025)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"64524694-1936-b83a-ba20-b219988b2bb4"},"outputs":[],"source":"plt.figure(figsize=(9,2))\ndf[df['Vol-30d'].notnull()].plot(x='Vol-30d', y='y', kind='scatter', alpha=0.0025)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e045a801-60b1-375f-db04-7b3c32f779e4"},"outputs":[],"source":"plt.figure(figsize=(9,2))\ndf[df['Vol-60d'].notnull()].plot(x='Vol-60d', y='y', kind='scatter', alpha=0.0025)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2c81365-3685-4d3b-ada8-52770ad1f772"},"outputs":[],"source":"plt.figure(figsize=(9,2))\ndf[df['Vol-90d'].notnull()].plot(x='Vol-90d', y='y', kind='scatter', alpha=0.0025)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"edcdd8a7-49cb-7a6f-b195-9a18cf19ded8"},"outputs":[],"source":"df.loc[:,df.columns[-4:]].describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6285aa96-07f5-b367-d5bf-505f442ddf7d"},"source":"Lets see if any of these correlate with any of the indicators.\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7fcabab-154b-2876-4001-44b8d1df6d2e"},"outputs":[],"source":"correlations = pd.DataFrame()\n\nfeat_cols = df.columns[2:-5]\n\nfor col in df.columns[-4:]:\n    corrs = []\n    for f_col in feat_cols:\n        corrs.append( df.loc[df[col].notnull(), col].corr(df.loc[df[col].notnull(), f_col]) )\n    correlations[col] = corrs\n    \n# Set index to columns.\ncorrelations.set_index(feat_cols, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54a0859f-6600-fc16-56af-b31f43da71ff"},"outputs":[],"source":"import seaborn as sns\n\nplt.figure(figsize=(8,15))\nsns.heatmap(correlations, vmin=-1.0, vmax=1.0)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}