{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ca155b58-c33f-3a9b-df30-28b94f5f3344"},"source":"Here is my attempt to use Tensorflow for this dataset using the kagglegym API. The notebook is still under construction."},{"cell_type":"markdown","metadata":{"_cell_guid":"2e91102a-d0ec-190b-18f3-aedee719cc82"},"source":"Kagglegym import..."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d2d707b-a279-1baa-1b47-e40667711964"},"outputs":[],"source":"import kagglegym\n# Create environment\nenv = kagglegym.make()\n# Get first observation\nobservation = env.reset()"},{"cell_type":"markdown","metadata":{"_cell_guid":"79e92bd4-c9fb-9445-760a-4026c2f11a7a"},"source":"One major problem of this dataset is the number of missing values. First, we want to make sure that there is enough complete data to learn something meaningful."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c4aca5f-e815-1fa6-1462-4f922d481e32"},"outputs":[],"source":"observation.train.dropna().shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4c617fd-5f81-ce04-f14c-e9389e8451d3"},"outputs":[],"source":"for col in observation.train.columns:\n    print(col)"},{"cell_type":"markdown","metadata":{"_cell_guid":"0a0eb182-2321-d7cf-b502-381b89d868b9"},"source":"Analyze of the output to design the network output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06e901dc-787f-4a7a-3af6-233147454215"},"outputs":[],"source":"observation.train[\"y\"].hist(bins=100)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d81383a-b2a2-c626-c586-ced1098a18c0"},"outputs":[],"source":"observation.train.dropna()[\"technical_5\"].hist(bins=100)"},{"cell_type":"markdown","metadata":{"_cell_guid":"dc79eda8-455a-36f6-da6a-e1b8c6aa9885"},"source":"The output seems to have a zero mean making sense to take a sigmoid as an output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e693be53-933c-79de-2a4f-8c04ed438dcb"},"outputs":[],"source":"import tensorflow as tf\nprint(tf.__version__)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a9c61d0f-991e-7426-3ba5-76279942a91c"},"source":"Simple two layer neural net minimizing the mean squared value. I am trying to switch to R2 loss later (see my attempt in the code)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23043282-5c5d-96ea-6c57-a60ecb2199b7"},"outputs":[],"source":"import tensorflow.contrib.layers as layers\nimport tensorflow.contrib.losses as losses\n\nN_FEATURES=108\nLEARNING_RATE = 0.001\n\nx = tf.placeholder(tf.float32, shape=(None, N_FEATURES))\ny = tf.placeholder(tf.float32, shape=(None,1))\np = tf.placeholder(tf.float32)\nlogits = layers.fully_connected(x, 56, activation_fn=tf.nn.relu)\nlogits = layers.dropout(logits, keep_prob=p)\nlogits = layers.fully_connected(x, 56, activation_fn=tf.nn.relu)\nlogits = layers.dropout(logits, keep_prob=p)\ny_ = layers.fully_connected(logits, 1)\n\nloss = losses.mean_squared_error(y, y_)\n\n# loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-y_)) / tf.square(y_ - tf.reduce_mean(y_))) # Equivalent to minimize R2\n\ntrain_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3a09f846-dea9-fb5e-6e83-acb369e11d9a"},"source":"Numpy arrays for feeding the network. Splitting into train and test sets."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e7317f4-af95-8be1-477a-d0c762f43c55"},"outputs":[],"source":"from sklearn.cross_validation import train_test_split\ntraindf, testdf = train_test_split(observation.train.drop(axis=1, labels=[\"id\", \"timestamp\"]).dropna(),\n                                  train_size=0.8,\n                                  test_size=0.2)\n\nY_train = traindf[\"y\"]\nX_train = traindf.drop(axis=1, labels=[\"y\"])\n\nY_test = testdf[\"y\"]\nX_test = testdf.drop(axis=1, labels=[\"y\"])"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b32c554-bf36-fb83-dfef-8c1e4b16788d"},"source":"Training process by batch."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa829688-3765-c6c5-ec70-e8ad2f230261"},"outputs":[],"source":"num_examples = X_train.shape[0]\nbatch_size = 32\nn_epoch = 2\nn_batch = int(num_examples / batch_size)\nprint(\"Feeding {} batches per epoch\".format(n_batch))\nstart = 0\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\n\nfor _ in range(n_epoch):\n    start = 0\n    for batch_idx in range(n_batch-1):\n    #for batch_idx in range(15):\n        feeding_dict = { x: X_train.iloc[start:(start+batch_size)].values,\n                        y: Y_train.iloc[start:(start+batch_size)].values.reshape(-1, 1),\n                       p:0.5}\n        start+=batch_size\n\n        _, l  = sess.run([train_op, loss], feed_dict=feeding_dict)\n\n        if not(batch_idx%1000):\n            print(\"Loss on batch {}: {}\".format(batch_idx, l))\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c01cec7-16e9-0084-059a-3f6f42dd4551"},"outputs":[],"source":"import tensorflow.contrib.metrics as metrics\n\nsmse, smse_update_op = metrics.streaming_mean_squared_error(y, y_)\n\nnum_examples = X_test.shape[0]\nbatch_size = 32\nn_batch = int(num_examples / batch_size)\nprint(\"Feeding {} batches per epoch\".format(n_batch))\nstart = 0\n\nsess.run(tf.initialize_local_variables())\n\nfor batch_idx in range(n_batch-1):\n    feeding_dict = { x: X_test.iloc[start:(start+batch_size)].values,\n    y: Y_test.iloc[start:(start+batch_size)].values.reshape(-1, 1),\n                   p:1.}\n    start+=batch_size\n    sess.run(smse_update_op, feed_dict=feeding_dict)\nprint(\"Total loss: {}\".format(sess.run(smse)))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}