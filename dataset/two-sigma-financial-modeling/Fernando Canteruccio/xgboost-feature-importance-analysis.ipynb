{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c0eedc17-b6b8-3ab2-6dcb-e8061b661532"},"source":"# Feature Engineering with XGBoost\n\nRecently [\"refresh\" updater](https://github.com/dmlc/xgboost/pull/1670) was introduced in XGBoost which can update an existing tree model without chainging the tree structure. Lets use it to find out the features importance in our training dataset ."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b68fd8d2-0ba3-6292-9b7b-e4c4b35e1cac"},"outputs":[],"source":"# Import all the necessary packages \nimport kagglegym\nimport numpy as np\nimport pandas as pd\nimport time\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\n\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69a8cd23-1642-3054-4ffc-72a0c4ed5b09"},"outputs":[],"source":"# Read the full data set stored as HDF5 file\ntrain = pd.read_hdf('../input/train.h5')"},{"cell_type":"markdown","metadata":{"_cell_guid":"410ef004-c08c-42b9-1845-2df6e8393979"},"source":"As seen in [this kernel](https://www.kaggle.com/bguberfain/two-sigma-financial-modeling/univariate-model-with-clip/run/482189/code), because the targe data is clipped, using only the timestamps within the clipping range helps the model to perform better, so lets try to find about the feature importance within this range. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50c32b49-2f7c-627a-ad7b-28109fdfa2d2"},"outputs":[],"source":"# Observed with histograms:\nlow_y_cut = -0.086093\nhigh_y_cut = 0.093497\n\ny_is_above_cut = (train.y > high_y_cut)\ny_is_below_cut = (train.y < low_y_cut)\ny_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"339060ba-4ebd-b40e-7c08-ab8ce1b98ef5"},"outputs":[],"source":"excl = ['id', 'sample', 'y', 'timestamp']\ncols = [c for c in train.columns if c not in excl]\ntarget_var = 'y'\n\nfeatures = train.loc[y_is_within_cut, cols]\ntargets = train.loc[y_is_within_cut, target_var]\n\nX_train = features[train.timestamp <= 905].values\ny_train = targets[train.timestamp <= 905].values\nX_valid = features[train.timestamp > 905].values\ny_valid = targets[train.timestamp > 905].values\nfeature_names = features.columns\ndel features, train, targets, cols, excl, target_var"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b61b500-f8ad-6dea-7b20-f7005ef408eb"},"outputs":[],"source":"print(\"train features shape:\",X_train.shape)\nprint(\"train label shape:\",y_train.shape)\nprint(\"validation features shape:\",X_valid.shape)\nprint(\"validation labels shape:\",y_valid.shape)\nprint(\"feature_names shape:\", feature_names.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b661a5ab-5e7f-1f67-58ed-2ac55d6a08ff"},"outputs":[],"source":"xgmat_train = xgb.DMatrix(X_train, label=y_train, feature_names=feature_names)\nxgmat_valid = xgb.DMatrix(X_valid, label=y_valid, feature_names=feature_names)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"026df292-8264-15fb-5c34-0a174cd462b9"},"outputs":[],"source":"params_xgb = {'objective':'reg:linear',\n              'eta'             : 0.1,\n              'max_depth'       : 4,\n              'subsample'       : 0.9,\n              'min_child_weight': 1000,\n              'base_score':0\n              }"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"becd6ebf-1968-559e-03f0-049a971dab2c"},"outputs":[],"source":"print (\"Training\")\nt0 = time.time()\nbst = xgb.train(params_xgb, xgmat_train, 10)\nprint(\"Done: %.1fs\" % (time.time() - t0))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8603034d-5b26-f0ed-bda3-97d3b0d83921"},"outputs":[],"source":"params_xgb.update({'process_type': 'update',\n                   'updater'     : 'refresh',\n                   'refresh_leaf': False})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74ccc861-05de-ecf0-badb-c00506191e07"},"outputs":[],"source":"t0 = time.time()\nprint(\"Refreshing\")\nbst_after = xgb.train(params_xgb, xgmat_valid, 10, xgb_model=bst)\nprint(\"Done: %.1fs\" % (time.time() - t0))"},{"cell_type":"markdown","metadata":{"_cell_guid":"1be2ee6b-33ad-da98-a5a8-07ad9743c05a"},"source":"It only updated gain and cover values. The leaf values remain fixed."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fab2b95-f632-369e-2482-2e3aaf66dcaa"},"outputs":[],"source":"imp = pd.DataFrame(index=feature_names)\nimp['train'] = pd.Series(bst.get_score(importance_type='gain'), index=feature_names)\n\n# OOB feature importance\nimp['OOB'] = pd.Series(bst_after.get_score(importance_type='gain'), index=feature_names)\nimp = imp.fillna(0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c6446ef-9244-abea-c4c3-6940a657b627"},"outputs":[],"source":"ax = imp.sort_values('train').tail(10).plot.barh(title='Feature importances sorted by train', figsize=(10,6))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ccd6e89c-64a8-1d52-6603-72c25118e707"},"outputs":[],"source":"ax = imp.sort_values('OOB').tail(10).plot.barh(title='Feature importances sorted by OOB', xlim=(0,0.04), figsize=(10,6))"},{"cell_type":"markdown","metadata":{"_cell_guid":"5593a143-4ef4-0162-7b46-722007fe6445"},"source":"This is a fairly different result from the [original notebook](https://www.kaggle.com/tks0123456789/two-sigma-financial-modeling/xgboost-refresh-updater-oob-feature-importance). Also, the most important features found here are quite different from the simple linear models exploration notebooks so, maybe, there is something going on."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}