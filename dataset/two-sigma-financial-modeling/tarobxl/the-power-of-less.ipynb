{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"fc300fc4-0cd2-0156-5c8d-909443703a6b"},"source":"I have found that the proportion of new asserts in the test set is higher than in the train set. One of my model has improved from 0.0141 to 0.147. I could share it after the deadline. In the meantime you could find the approach in this notebook. I believe even the local score is lower than the original one by Hamed https://www.kaggle.com/pinocchio/two-sigma-financial-modeling/tensorflow-lr/run/903884 this script should give a slightly higher score in the LB. Hope you could use this information to get out of the public-script score. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"addedb41-e29a-eb28-1115-63fb37dff2e2"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07769336-c494-4fdb-691a-179d32b53ce8"},"outputs":[],"source":"import kagglegym\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing as pp\n\nenv = kagglegym.make()\no = env.reset()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2d9b6e1-e524-cedf-bfab-7fbddb4a711a"},"outputs":[],"source":"col = ['technical_20']\ntrain = o.train[col + ['id', 'timestamp', 'y']].copy(deep=True)\n\nim = pp.Imputer(strategy='median')\ntrain[col] = im.fit_transform(train[col])\nsX = pp.StandardScaler()\ntrain[col] = sX.fit_transform(train[col])\ntrain['b'] = 1\n\ny_min = train.y.min()\ny_max = train.y.max()\n\ndf_id = train[['id', 'timestamp']].groupby('id').agg([np.min])\ndf_id.reset_index(level=0, inplace=True)\ntrain = pd.merge(train, df_id, on='id', how='inner')\ntrain = train.rename(columns={train.columns[len(train.columns)-1]: 'min_ts'})\ntrain = train.loc[(train.min_ts > 1) & (train.y<y_max) & (train.y>y_min)].copy(deep=True)\n\n\nfeatures = ['b']+col\nn = len(features)\n\nlearning_rate = 0.01\ntraining_epochs = 1000\ncost_history = np.empty(shape=[1],dtype=float)\n\nX = tf.placeholder(tf.float32,[None,n])\nY = tf.placeholder(tf.float32,[None,1])\nW = tf.Variable(tf.zeros([n,1]))\n\ninit = tf.global_variables_initializer()\n\ny_ = tf.matmul(X, W)\n\ncost = tf.add(tf.reduce_mean(tf.square(y_ - Y)), tf.reduce_mean(tf.square(W)))\ntraining_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\nsess = tf.Session()\nsess.run(init)\n\nfor epoch in range(training_epochs):\n    sess.run(training_step,feed_dict={X: train[features], Y: train[['y']].values})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"77a14f3a-9dee-26a9-99c8-1567cef15530"},"outputs":[],"source":"while True:\n    o.features[col] = im.transform(o.features[col])\n    o.features[col] = sX.transform(o.features[col])\n    o.features['b'] = 1\n    \n    o.target.y = sess.run(y_, feed_dict={X:o.features[features]})\n    o.target.y = np.clip(o.target.y, y_min, y_max)\n    \n    o, reward, done, info = env.step(o.target)\n    if done:\n        print(info)\n        break\n    if o.features.timestamp[0] % 100 == 0:\n        print(reward)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}