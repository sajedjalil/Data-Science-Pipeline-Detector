{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3eaaa3fa-5a99-0ed7-87d0-bc98e34934cb"},"source":"Yash Data Analysis"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a3c8acf-8ea5-10a5-b3dc-d210be84e396"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\n\n%matplotlib inline\n\nwith pd.HDFStore('../input/train.h5') as train:\n    df = train.get('train')\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0b1a8b3-e5c3-e492-799b-82689ea6b5df"},"outputs":[],"source":"df.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0142cd6b-a9bd-e5de-b51a-c63953e65608"},"source":"So there are 111 columns present in the dataset.\n\n- 1 id column\n- 1 timestamp column\n- 5 columns with name prefix 'derived'\n- 63 columns with name prefix 'fundamental' - fundamental_0 to fundamental_63 - 'fundamental_4' is missing. Any specific reasons?\n- 40 columns with name prefix 'technical' - technical_0 to technical_44 - technical_4, technical_8, technical_15, technical_23, technical_26 are missing.  \n- 1 target variable named 'y'\n\nNow let us look at the distribution of data in each of these columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98a8bd11-82af-c32c-ad17-9a40429f038b"},"outputs":[],"source":"df.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"bd0fd8f5-3599-d9ff-89c8-f82742512579"},"source":"It seems NaN values are present in all input columns but  for two (technical_22 and technical_34).\n\nSo let us count the number of missing values in each of the columns."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"953257ad-0fb0-cb3f-636a-87cb772ea007"},"outputs":[],"source":"labels = []\nvalues = []\nfor col in df.columns:\n    labels.append(col)\n    values.append(df[col].isnull().sum())\n    print(col, values[-1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73cb57f8-7d4f-cfed-ee89-de5febf0c85f"},"outputs":[],"source":"ind = np.arange(len(labels))\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,50))\nrects = ax.barh(ind, np.array(values), color='y')\nax.set_yticks(ind+((width)/2.))\nax.set_yticklabels(labels, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\n#autolabel(rects)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"30dcb695-e7d2-c12f-5c1b-3b18f0c68c30"},"source":"Fundamental_5 has the most number of missing values followed by fundamental_38."},{"cell_type":"markdown","metadata":{"_cell_guid":"d809f59d-1e6e-8f36-207d-8751af6a429f"},"source":"Perform univariate analysis. For now, impute missing values with mean"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5218b86f-f0a2-7e55-f2d0-5c5e1e2749d4"},"outputs":[],"source":"mean_values = df.mean(axis=0)\ndf_mean = df\ndf_mean.fillna(mean_values, inplace=True)\n\nlabels = []\nvalues = []\nfor col in df_mean.columns:\n    labels.append(col)\n    values.append(df_mean[col].isnull().sum())\n    print(col, values[-1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d90b733-0b71-ea05-4631-279d150e223a"},"outputs":[],"source":"# Now let us look at the correlation coefficient of each of these variables #\nx_cols = [col for col in df_mean.columns if col not in ['id','timestamp','y']]\n\nlabels = []\nvalues = []\nfor col in x_cols:\n    labels.append(col)\n    values.append(np.corrcoef(df_mean[col].values, df_mean.y.values)[0,1])\n    \nind = np.arange(len(labels))\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,40))\nrects = ax.barh(ind, np.array(values), color='y')\nax.set_yticks(ind+((width)/2.))\nax.set_yticklabels(labels, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient\")\n#autolabel(rects)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"8758ae82-e340-4bff-ce64-485bc72db3eb"},"source":"Most important variables appear to be technical_30, technical_20, fundamental_11, technical_19. \n\nFor more on univariate analysis, https://www.kaggle.com/ysharma1126/two-sigma-financial-modeling/univariate-analysis-regression-lb-0-006/editnb\n\nLet's look at the distribution plots for the top 4 variables. Using df with NAs, or df with imputed mean didn't make any difference. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a57fe286-b384-8622-d61d-04163b0bfb95"},"outputs":[],"source":"cols_to_use = ['technical_30', 'technical_20', 'fundamental_11', 'technical_19']\nfig = plt.figure(figsize=(8, 20))\nplot_count = 0\nfor col in cols_to_use:\n    plot_count += 1\n    plt.subplot(4, 1, plot_count)\n    plt.scatter(range(df.shape[0]), df[col].values)\n    plt.title(\"Distribution of \"+col)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"223f2071-ca70-c77b-a970-01e651722acd"},"source":"Some of the observations from the distribution plot are:\n\n- The top two variables (technical_30 and technical_20) range between 0 and 0.8 and there are no major outliers\n- Fundamental_11 has few outliers at the beginning and then looks more or less fine with two small peaks\n- Technical_19 has few high values towards the end\n\n**Target Distribution:**\n\nNow let us scatter plot the target variable.\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec93996b-9f49-373b-c0de-03b2fc0a7d63"},"outputs":[],"source":"plt.figure(figsize=(8, 5))\nplt.scatter(range(df.shape[0]), df.y.values)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"8ad2985c-4ad0-96cf-b678-c9a349755a07"},"source":"Target values range between -0.086 to 0.093. \n\nAs we can see the target graph is more darker at the middle, suggesting more values are concentrated in those region. \n\nAlso there seems to be some hard stop at both the ends (probably capping the target to remain within the limits?!) - this could be inferred from the two dark lines at the top and bottom.\n\nAlso there seems to be some change in the target distribution with respect to time. As we move from left to right, initially the target is evenly distributed in the given range (-0.08 to 0.09) and then in the middle it is not so.\n\n**Timestamp:**\n\nNow let us look at the counts for each of the timestamps present in the data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a417e99-5def-8b6a-66d2-e85e003a384b"},"outputs":[],"source":"fig = plt.figure(figsize=(12, 6))\nsns.countplot(x='timestamp', data=df)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"3e8de87b-5818-c901-ce84-178b6209f2fd"},"source":"So there is an increasing trend in the number of rows for each of the time stamps. Also there are some sudden jumps in between at intervals. More done in https://www.kaggle.com/ysharma1126/two-sigma-financial-modeling/two-sigma-portfolio-returns-eda/editnb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06e07d23-a7b5-6049-ec4a-d2e2f5f03985"},"outputs":[],"source":"print('Shape : {}'.format(df.shape))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be088ce8-7c7d-24cc-cbab-bbeb7be1a494"},"outputs":[],"source":"len(df.id.unique()) # how many assets (instruments) are we tracking?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0115c2ba-5ff4-e853-acdc-bf16527e8a3f"},"outputs":[],"source":"len(df.timestamp.unique()) # how many periods?"},{"cell_type":"markdown","metadata":{"_cell_guid":"bfff1f00-f34e-0c14-2f90-d3f39b106dda"},"source":"So we have 1424 unique assets in the dataset. As we can see from the previous plot of timestamp, ~1100 assets is the maximum number of assets at any given timestamp. So there are few assets that are dropped in between.\n\nNow we can check the 'y' distribution of some of the assets. Let us first look at ids with high negative mean target values. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08e807b7-2d58-7975-ec8b-71509e94b6df"},"outputs":[],"source":"temp_df = df.groupby('id')['y'].agg('mean').reset_index().sort_values(by='y')\ntemp_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"edff3470-6381-d363-8d2c-7b98d0d9e718"},"outputs":[],"source":"id_to_use = [1431, 93, 882, 1637, 1118]\nfig = plt.figure(figsize=(8, 25))\nplot_count = 0\nfor id_val in id_to_use:\n    plot_count += 1\n    plt.subplot(5, 1, plot_count)\n    temp_df = df.ix[df['id']==id_val,:]\n    plt.plot(temp_df.timestamp.values, temp_df.y.values)\n    plt.plot(temp_df.timestamp.values, temp_df.y.cumsum())\n    plt.title(\"Asset ID : \"+str(id_val))\n    \nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6f28907d-d414-d322-7481-deb57908cbba"},"source":"Blue line represents the distribution of 'y' variable in the given time stamp. Green line represents the cumulative 'y' value\n\nSo 4 out these 5 assets are dropped (as they are not present till the last time stamp which is 1812), when the cumulative negative target value falls steeply. \n\nNow let us take the assets with high positive mean target value and see their distribution."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8770d5a-790d-4c73-1983-8ab23579bdd1"},"outputs":[],"source":"temp_df = df.groupby('id')['y'].agg('mean').reset_index().sort_values(by='y')\ntemp_df.tail()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a34d5843-3470-410e-1ae0-2c24035a6f2d"},"outputs":[],"source":"id_to_use = [767, 226, 824, 1809, 1089]\nfig = plt.figure(figsize=(8, 25))\nplot_count = 0\nfor id_val in id_to_use:\n    plot_count += 1\n    plt.subplot(5, 1, plot_count)\n    temp_df = df.ix[df['id']==id_val,:]\n    plt.plot(temp_df.timestamp.values, temp_df.y.values)\n    plt.plot(temp_df.timestamp.values, temp_df.y.cumsum())\n    plt.title(\"Asset ID : \"+str(id_val))\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"516c0e19-ebca-1ef4-19f4-8ad10b2581a4"},"source":"Interestingly 2 of these 5 good performing assets are also dropped (Assets 824 and 1089). Not sure about the reasons though.\n\nNow let us take some assets which are present across all the timestamps and see their distribution."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ddfdf80b-64d8-c28f-fa8c-f9b254210f09"},"outputs":[],"source":"temp_df = df.groupby('id')['y'].agg('count').reset_index().sort_values(by='y')\ntemp_df.tail()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e19321b-0188-86d0-5261-c6fc03ce239a"},"outputs":[],"source":"id_to_use = [1548, 699, 697, 704, 1066]\nfig = plt.figure(figsize=(8, 25))\nplot_count = 0\nfor id_val in id_to_use:\n    plot_count += 1\n    plt.subplot(5, 1, plot_count)\n    temp_df = df.ix[df['id']==id_val,:]\n    plt.plot(temp_df.timestamp.values, temp_df.y.values)\n    plt.plot(temp_df.timestamp.values, temp_df.y.cumsum())\n    plt.title(\"Asset ID : \"+str(id_val))\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0c7f36f8-4822-3ebd-ec7a-ece97f180836"},"source":"Asset 699 looks like a very good asset.! \n\nTo know more about assets, refer to https://www.kaggle.com/ysharma1126/two-sigma-financial-modeling/when-why-are-stocks-bought-and-sold/editnb"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}