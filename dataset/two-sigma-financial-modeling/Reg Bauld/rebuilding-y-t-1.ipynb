{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"e7093727-e671-c080-d45f-a7697b2cd742"},"source":"The goal of this notebook is to show you how to build a feature that is ***very*** close to the value of the response, y, at the previous timestep.\n\nThis notebook builds chiefly upon the work in these two notebooks:\n\n[https://www.kaggle.com/chenjx1005/two-sigma-financial-modeling/physical-meanings-of-technical-20-30/discussion][1]\n\n\n[https://www.kaggle.com/luckylwk/two-sigma-financial-modeling/moving-average-macd-analysis][2]\n\n\n  [1]: https://www.kaggle.com/chenjx1005/two-sigma-financial-modeling/physical-meanings-of-technical-20-30/discussion\n  [2]: https://www.kaggle.com/luckylwk/two-sigma-financial-modeling/moving-average-macd-analysis\n\n\nWe can make two conclusions from these:\n\n1) The feature set is shifted. IE the features actually are derived from y(t-1)\n\n2) Many of the features are strongly related to the moving average of of y (or y(t-1) )\n\nTo re-iterate these points, in the following code block I load the data set and build some derived quantities from y. In particular I look at the moving averages of y and the moving averages of y(t-1).\n\nI then examine their correlations with the feature set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7fe110e-4409-fb3d-623c-b2ce9b7dd8fb"},"outputs":[],"source":"###################################################################\n# Import libraries\n###################################################################\n\nimport kagglegym\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\nimport sklearn as sk\nfrom sklearn import preprocessing\nfrom sklearn import cluster\nfrom sklearn import linear_model\nfrom sklearn import ensemble\n\npd.options.mode.chained_assignment = None  # default='warn'\n\n%matplotlib inline\n\n# The \"environment\" is our interface for code competitions\nenv = kagglegym.make()\n\n# We get our initial observation by calling \"reset\"\nobservation = env.reset()\ndata_df = observation.train\n\n    \n###################################################################\n# Get train data frame, do some pre-processing\n###################################################################\n\ndata = data_df[data_df['timestamp'] < 906]\n\nmean_values = data.mean(axis=0)\ndata.fillna(mean_values, inplace=True)\n\ntrain = data[data['timestamp'] < 906/2]\ntest  = data[data['timestamp'] > 906/2]\n\n# Fill na values\nmean_values = test.mean(axis=0)\ntest.fillna(mean_values, inplace=True)\nmean_values = test.mean(axis=0)\ntrain.fillna(mean_values, inplace=True)\n\ndef ewm_mean(x,span_in):\n    return(x.ewm(span=span_in).mean())\n\n#Build EWM parameters\ntrain['EWM_9_mean']   = train.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=9))\ntrain['EWM_12_mean']  = train.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=12))\ntrain['EWM_26_mean']  = train.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=26))\ntrain['EWM_40_mean']  = train.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=40))\n\ntest['EWM_9_mean']   = test.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=9))\ntest['EWM_12_mean']  = test.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=12))\ntest['EWM_26_mean']  = test.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=26))\ntest['EWM_40_mean']  = test.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=40))\n\n# Build shifted parameters\ntrain['y_shifted']      = train.groupby('id')['y'].shift(1).fillna(0)\ntrain['EWM_9_mean_s']   = train.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=9))\ntrain['EWM_12_mean_s']  = train.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=12))\ntrain['EWM_26_mean_s']  = train.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=26))\ntrain['EWM_40_mean_s']  = train.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=40))\n\ntest['y_shifted']      = test.groupby('id')['y'].shift(1).fillna(0)\ntest['EWM_9_mean_s']   = test.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=9))\ntest['EWM_12_mean_s']  = test.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=12))\ntest['EWM_26_mean_s']  = test.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=26))\ntest['EWM_40_mean_s']  = test.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=40))\n\n\n# Plot corrilation matrix\ncols = [x for x in train.columns if x not in ['id','timestamp']]\n\nmain_cols = ['y','EWM_9_mean','EWM_12_mean','EWM_26_mean','EWM_40_mean',\n            'EWM_9_mean_s','EWM_12_mean_s','EWM_26_mean_s','EWM_40_mean_s']\nmain_ix =  train[cols].columns.get_indexer(main_cols)\n\ncor_mat = np.corrcoef(train[cols], rowvar=0)[:,main_ix]\n\ncorr_df = pd.DataFrame(cor_mat,columns=main_cols,index=[cols])\n\nplt.figure(figsize=(20,40))\nsns.heatmap(corr_df, vmin=-1.0, vmax=1.0, linewidths=.5, annot=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"01310fa8-58fc-dda8-a51c-3c2dec0bc8e9"},"source":"Again we see our friends technical_30 and technical_20. In addition some other features appear to also be related to the moving averages. In addition the shifted moving averages are, in general, more strongly correlated to the feature set. \n\n\nNow, to \"rebuild\" y(t-1) I will employ the following strategy.\n\n1) We transform y(t-1) via an exponentially weighted average\n\n2) We build a model to predict the transformed quantity (EWM_26_mean_s) from the feature set, called say EWM_26s_pred\n\n3) We perform an inverse transformation on EWM_26s_pred. We utilize the fact that exponential weighted averages can be computed in an iterative fashion.\n\nThat is, S_t = alpha*Y_t +(1-alpha)*S_(t-1)\n\nwhere S_t is the exponentially weighted average at time t, Y_t is the response at time t, and S_t-1 is the EWA for time t-1\n\nClearly this equation can be re-arranged to yield\n\nY_t = (S_t - (1-alpha)*S_(t-1))/alpha\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef287320-e92b-76f4-137e-b12f9c84a39d"},"outputs":[],"source":"ewm_features = ['technical_30','technical_20','technical_21','technical_19','technical_17','technical_11','technical_2']\nmy_model = sk.ensemble.GradientBoostingRegressor(loss='ls', max_depth=5, learning_rate=0.05)\nmy_model.fit(X=train[ewm_features],y=train['EWM_26_mean_s'])\ntrain['EWM_26s_pred'] = my_model.predict(X=train[ewm_features]) \ntest['EWM_26s_pred'] = my_model.predict(X=test[ewm_features])\n\ndef ewm_reverse(data,span=26):\n    alpha = 2/(span+1)\n    return (data-(1-alpha)*data.shift(1).fillna(0))/alpha\n\n# Inverse transform\ntrain['yEWM_26'] = train.groupby('id')['EWM_26s_pred'].apply(lambda x: ewm_reverse(x, span=26))\ntest['yEWM_26'] = test.groupby('id')['EWM_26s_pred'].apply(lambda x: ewm_reverse(x, span=26))"},{"cell_type":"markdown","metadata":{"_cell_guid":"aa851760-72a2-ec00-62b7-1828e6ca2afd"},"source":"If all went well yEWM_26 should corrispond quite strongly to y(t-1). Lets test it out."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75ede8fa-ccc6-b653-2d9a-971b06cf8d63"},"outputs":[],"source":"def find_R_value(y_predict,y_actual):\n    mean = np.mean(y_actual)\n    Rrr = 1 - sum((y_predict-y_actual)**2)/sum((y_actual-mean)**2)\n    return np.sign(Rrr)*np.sqrt(np.abs(Rrr))  \n\nfind_R_value(test['yEWM_26'],test.groupby('id')['y'].shift(1).fillna(0))"},{"cell_type":"markdown","metadata":{"_cell_guid":"9f2ac90b-2c9a-975e-21b9-4c4a8892e51c"},"source":"Not bad! Granted it is not perfect as there is some noise in the features, but this might be a decent feature for determining y(t).\n\nFor fun, lets look at the plots for a few IDs to see how they match up."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96d7e997-8c62-26ea-d89f-fd01bd9ea6e1"},"outputs":[],"source":"tmp_df = test[(test['timestamp'] < 500) & (test['id'] == test['id'].iloc[10])]\ntmp_df.plot(x='timestamp',y=['yEWM_26','y_shifted'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c65185c3-9a3f-dab6-1a63-4132074c7d70"},"outputs":[],"source":"tmp_df = test[(test['timestamp'] < 500) & (test['id'] == test['id'].iloc[1])]\ntmp_df.plot(x='timestamp',y=['yEWM_26','y_shifted'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"8ab90242-7176-3318-8fd1-38f654efd72e"},"source":"There is some slight distortion at the start due to how yEWM_26 is calculated, but generally it seems to match quite well.\n\nI think this can prove useful as a feature than can perhaps enable the use of some more conventional time series techniques.\n\nNow, I know what you might be thinking. Why not try this procedure on y(t) instead of y(t-1). Well I have tried this, and surprisingly you get back something that looks more like y(t-1) than y(t)."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}