{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"7ef787d4-3b22-a519-cb2e-47e17edb0066"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99508910-31f0-4712-0bb5-c84db0e84f54"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6cef15db-1f07-0c33-bb54-b89b3097b38e"},"outputs":[],"source":"import os\nimport math\nimport cv2\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nfrom PIL import Image\n\nimport seaborn as sns\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Lambda\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras.callbacks import ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a8c4ac8-c27d-d785-3e58-ea4fd990eed1"},"outputs":[],"source":"filenames = os.listdir('../input/train-jpg')\ndf = pd.read_csv('../input/train.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66f8e984-b612-1acf-b63d-53f933fe9a31"},"outputs":[],"source":"df.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a866e67a-16e1-0624-ee6c-ac98132a7418"},"outputs":[],"source":"df.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"977da6f4-348f-aa8a-c41a-0dae8c8c175a"},"outputs":[],"source":"df['tag_set'] = df['tags'].map(lambda s: set(s.split(' ')))\n\ntags = set()\nfor t in df['tags']:\n    s = set(t.split(' '))\n    tags = tags | s\n\ntag_list = list(tags)\ntag_list.sort()\ntag_columns = ['tag_' + t for t in tag_list]\nfor t in tag_list:\n    df['tag_' + t] = df['tag_set'].map(lambda x: 1 if t in x else 0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06dd8dcf-3dcd-44d7-21e0-0a9f6040d755"},"outputs":[],"source":"df.info()\ndf.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d411dc7-63c1-b3cb-3a15-9f0280381894"},"outputs":[],"source":"df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3aab2a71-8012-5372-8acb-3c0983c0c506"},"outputs":[],"source":"df[tag_columns].sum()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"851ad0fd-9293-aa11-8b9d-c1b478a9e62a"},"outputs":[],"source":"df[tag_columns].sum().sort_values().plot.bar()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d97827d-6fbb-84ba-da9e-b9e9ae29c351"},"outputs":[],"source":"tags_count = df.groupby('tags').count().sort_values(by='image_name', ascending=False)['image_name']\nprint('There are {} unique tag combinations'.format(len(tags_count)))\nprint()\nprint(tags_count)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abfb47f9-2e78-dea8-9c97-572c579731c0"},"outputs":[],"source":"from textwrap import wrap\n\ndef display(images, cols=None, maxcols=10, width=14, titles=None):\n    if cols is None:\n        cols = len(images)\n    n_cols = cols if cols < maxcols else maxcols\n    plt.rc('axes', grid=False)\n    fig1 = plt.figure(1, (width, width * math.ceil(len(images)/n_cols)))\n    grid1 = ImageGrid(\n                fig1,\n                111,\n                nrows_ncols=(math.ceil(len(images)/n_cols), n_cols),\n                axes_pad=(0.1, 0.6)\n            )\n\n    for index, img in enumerate(images):\n        grid1[index].grid = False\n        if titles is not None:\n            grid1[index].set_title('\\n'.join(wrap(titles[index], width=25)))\n        if len(img.shape) == 2:\n            grid1[index].imshow(img, cmap='gray')\n        else:\n            grid1[index].imshow(img)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4f9efa7-6627-ea75-1cf4-d2983ffb1f4b"},"outputs":[],"source":"def load_image(filename, resize=True, folder='train-jpg'):\n    img = mpimg.imread('../input/{}/{}.jpg'.format(folder, filename))\n    if resize:\n        img = cv2.resize(img, (64, 64))\n    return np.array(img)\n\ndef mean_normalize(img):\n    return (img - img.mean()) / (img.max() - img.min())\n\ndef normalize(img):\n    return img / 127.5 - 1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6604505-c1cf-669a-5cc3-d53fa60170ce"},"outputs":[],"source":"samples = df.sample(16)\nsample_images = [load_image(fn) for fn in samples['image_name']]\nINPUT_SHAPE = sample_images[0].shape\nprint(INPUT_SHAPE)\ndisplay(\n    sample_images,\n    cols=4,\n    titles=[t for t in samples['tags']]\n)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fde3db34-bfc5-871c-7c0a-d98effb51c47"},"outputs":[],"source":"def preprocess(img):\n    img = normalize(img)\n    return img\n\ndisplay(\n    [(127.5 * (preprocess(img) + 1)).astype(np.uint8) for img in sample_images],\n    cols=4,\n    titles=[t for t in samples['tags']]\n)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3476a683-d9b8-abfa-0f41-e4d34376270d"},"source":"# Learn"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7bfe0084-81a9-7c4d-6ecd-e07f23b12511"},"outputs":[],"source":"df_train = df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84bd0c01-4c0f-4921-0cb7-dd7ed704f2ab"},"outputs":[],"source":"X = df_train['image_name'].values\ny = df_train[tag_columns].values\n\nn_features = 1\nn_classes = y.shape[1]\n\nX, y = shuffle(X, y)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)\n\nprint('We\\'ve got {} feature rows and {} labels'.format(len(X_train), len(y_train)))\nprint('Each row has {} features'.format(n_features))\nprint('and we have {} classes'.format(n_classes))\nassert(len(y_train) == len(X_train))\nprint('We use {} rows for training and {} rows for validation'.format(len(X_train), len(X_valid)))\nprint('Each image has the shape:', INPUT_SHAPE)\nprint('So far, so good')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7746f07-8533-a624-be6c-a7dda16e97ad"},"outputs":[],"source":"print('Memory usage (train) kB', X_train.nbytes//(1024))\nprint('Memory usage (valid) kB', X_valid.nbytes//(1024))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7d93f36-b75f-2564-2ee3-19a2786ec2b3"},"outputs":[],"source":"def generator(X, y, batch_size=32):\n    X_copy, y_copy = X, y\n    while True:\n        for i in range(0, len(X_copy), batch_size):\n            X_result, y_result = [], []\n            for x, y in zip(X_copy[i:i+batch_size], y_copy[i:i+batch_size]):\n                rx, ry = [load_image(x)], [y]\n                rx = np.array([preprocess(x) for x in rx])\n                ry = np.array(ry)\n                X_result.append(rx)\n                y_result.append(ry)\n            X_result, y_result = np.concatenate(X_result), np.concatenate(y_result)\n            yield shuffle(X_result, y_result)\n        X_copy, y_copy = shuffle(X_copy, y_copy)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33af6d60-7e6e-a4d5-6651-11daf350cf91"},"outputs":[],"source":"from keras import backend as K\n\ndef fbeta(y_true, y_pred, threshold_shift=0):\n    beta = 2\n\n    # just in case of hipster activation at the final layer\n    y_pred = K.clip(y_pred, 0, 1)\n\n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    beta_squared = beta ** 2\n    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n\n# ---------------------------------- #\n\nmodel = Sequential()\n\nmodel.add(Conv2D(48, (8, 8), strides=(2, 2), input_shape=INPUT_SHAPE, activation='elu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (8, 8), strides=(2, 2), activation='elu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(96, (5, 5), strides=(2, 2), activation='elu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(96, (3, 3), activation='elu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(256, activation='elu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(64, activation='elu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(n_classes, activation='sigmoid'))\n\n    \nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[fbeta, 'accuracy']\n)\n\nmodel.summary()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0561a61b-ee47-d683-39f1-1e814d59a4e8"},"outputs":[],"source":"EPOCHS = 6\nBATCH = 32\nPER_EPOCH = 256\n\nX_train, y_train = shuffle(X_train, y_train)\nX_valid, y_valid = shuffle(X_valid, y_valid)\n\nfilepath=\"weights-improvement-{epoch:02d}-{val_fbeta:.3f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_fbeta', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit_generator(\n    generator(X_train, y_train, batch_size=BATCH),\n    steps_per_epoch=PER_EPOCH,\n    epochs=EPOCHS,\n    validation_data=generator(X_valid, y_valid, batch_size=BATCH),\n    validation_steps=len(y_valid)//(4*BATCH),\n    callbacks=callbacks_list\n)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fcd7e82a-798a-b709-f3db-0d93fa621da5"},"outputs":[],"source":"X_test = os.listdir('../input/test-jpg')\nX_test = [fn.replace('.jpg', '') for fn in X_test]\n\nresult = []\nTEST_BATCH = 128\nfor i in range(0, len(X_test), TEST_BATCH):\n    X_batch = X_test[i:i+TEST_BATCH]\n    X_batch = np.array([preprocess(load_image(fn, folder='test-jpg')) for fn in X_batch])\n    p = model.predict(X_batch)\n    result.append(p)\n    \nr = np.concatenate(result)\nr = r > 0.5\n\ntable = []\nfor row in r:\n    t = []\n    for b, v in zip(row, tag_columns):\n        if b:\n            t.append(v.replace('tag_', ''))\n    table.append(' '.join(t))\n\ndf_pred = pd.DataFrame.from_dict({'image_name': X_test, 'tags': table})\ndf_pred.to_csv('submission.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}