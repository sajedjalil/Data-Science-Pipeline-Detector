{"cells":[{"metadata":{"_cell_guid":"27b833ed-e7b1-43dd-b903-a9f9e21cb4ed","_uuid":"5d30568abcdc27c8da9fdb9113d2705bd42be9ab"},"cell_type":"markdown","source":"### Loading required libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom collections import Counter\nprint(os.listdir(\"../input\"))\nprint(os.listdir('../input/planet-understanding-the-amazon-from-space'))\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"labels_df = pd.read_csv('../input/planet-understanding-the-amazon-from-space/train_v2.csv')\nprint('images in training set :', labels_df.shape[0])\nlabels_df = labels_df.sample(frac = 1)\nlabels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"106c9f8d-d472-4c0f-92bd-1c42120b703e","_uuid":"082962faa3d171b9d8ccb8551333a94783ffd899","trusted":true},"cell_type":"code","source":"counter = Counter([])\nfor tag_list in labels_df['tags'].apply(lambda x:x.split(' ')):\n   counter.update(tag_list)\nlabel_names,count = zip(*counter.items())\nfig = plt.figure(figsize = (15,6))\nax = plt.gca()\nax.bar(np.arange(0,len(label_names),1),count, tick_label = label_names)\nplt.xticks(rotation = 90)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"76f07691-8850-434b-a9f4-4323b3af82f8","_uuid":"f7924daa81aae9fafee44adf7b7f3e750a4c8a1c","trusted":true},"cell_type":"code","source":"column_df = pd.DataFrame(np.zeros((labels_df.shape[0],17)), columns = label_names)\nlabels_df = pd.concat([labels_df,column_df],axis =1, join = 'inner')\nlabels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc0a414f-0c91-4186-a0b9-64c8ea497930","_uuid":"745ca8a4c068065027a8a4e34515c9eb8b6a1235","trusted":true},"cell_type":"code","source":"labels_df = pd.read_feather('../input/labels-df/labels_df.feather')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"18de0c80-5535-4597-93b1-dc75cd5d6be2","_uuid":"253113b53246ddbed8da1dc4391a6165587433a5","trusted":true},"cell_type":"code","source":"labels_df.drop(['tags'],inplace = True, axis=1)\nlabels_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"003d6a42-a245-47ea-8d04-79e662c99db2","_uuid":"c3df09eff31d9a9914636310016b9bae49d3c4e8","trusted":true},"cell_type":"code","source":"labels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a8dd05df-e9cb-41dd-8b61-02c1ba5d9885","_uuid":"63591f03ddcbf16bda79a231d60c4fc665e24962","scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_labels, valid_labels = train_test_split(labels_df, test_size = 0.2)\ntrain_labels.shape, valid_labels.shape\ntrain_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"47b18642-f18c-4518-a59f-8206c03691e1","_uuid":"5fafead2245a0d25cfb7605904f1e557906e029d","collapsed":true,"trusted":true},"cell_type":"code","source":"img_path = '../input/planet-understanding-the-amazon-from-space/train-jpg/{}.jpg' \ntrain_images = train_labels['image_name'].apply(lambda x: img_path.format(x)).values\nvalid_images = valid_labels['image_name'].apply(lambda x:img_path.format(x)).values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"adf17be6-c760-4565-8dae-8161efc54723","_uuid":"503c33737d6bc98392234684bca24e756eca105b","scrolled":false,"trusted":true},"cell_type":"code","source":"train_images.shape, valid_images.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"31f20fd5-c5ca-4f14-ba4c-3746bdcff8b2","_uuid":"464e2e680363a346e39e16b464f43135b3c6d8a0"},"cell_type":"markdown","source":"### Preparing images(data augmentation)"},{"metadata":{"_cell_guid":"7e560c8b-2922-4146-b7a5-083343410e4d","_uuid":"700d8ab777b905428025d56a9093c066722f9f23","scrolled":true,"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\ndef get_data_iter(data_gen, img_size,label_df, img_list, batch_size, shuffle = True):\n    generator = data_gen.flow_from_directory(directory = '../input/planet-understanding-the-amazon-from-space/train-jpg', target_size = (img_size,img_size), \n                                                             batch_size = batch_size, class_mode = 'sparse', shuffle = shuffle)\n    generator.filenames = img_list\n    generator.classes =  label_df.loc[:,label_df.columns !='image_name'].values\n    generator.samples = label_df.loc[:,label_df.columns !='image_name'].values.shape[0]\n    generator.n = label_df.loc[:,label_df.columns !='image_name'].values.shape[0]\n    generator.directory = ''\n    generator._set_index_array()\n    return generator","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8003a098-4767-49ae-b70b-a73f67cca204","_uuid":"84b25e295747d65ae1fcda6730e082dfd7f9df12","trusted":true},"cell_type":"code","source":"data_generator_aug = ImageDataGenerator( rescale = 1./255, horizontal_flip = True,  vertical_flip = True, \n                                        width_shift_range = 0.1, height_shift_range = 0.1, rotation_range = 10)\n\ntrain_generator = get_data_iter(data_generator_aug, 128, train_labels, train_images,64, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"422011a5-9013-4916-9b3b-f0334ae54baa","_uuid":"b3438d5e1f441fa74b13dd1d3c93b0eeecbdc35f","trusted":true,"scrolled":true},"cell_type":"code","source":"data_generator_no_aug = ImageDataGenerator(rescale = 1./255)\nvalid_generator =  get_data_iter(data_generator_no_aug, 128, valid_labels, valid_images, 2048, shuffle = False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4dd64262e75e5874bf58b53e1d59893004925b5"},"cell_type":"code","source":"train_generator_no_aug =  get_data_iter(data_generator_no_aug, 128, train_labels, train_images,64, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"48ef4143-4342-48e8-85b4-9d8e2745a965","_uuid":"226d556e454306c23d5099d574616a82ea2f404e","scrolled":true,"trusted":true},"cell_type":"code","source":"t_imgs, t_labels = next(train_generator_no_aug)\n\naug_imgs, aug_labels = next(train_generator)\n\nlabels = train_labels.columns[1:]\n\nfixed_val_imgs,fixed_val_labels = next(valid_generator)\nfixed_val_imgs.shape, fixed_val_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5310ebe7c0f36c321c1f14df949ae384e4d53c1d","collapsed":true},"cell_type":"code","source":"t_imgs.shape, t_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d9c02a1f5a0ad17ff543edf20c5838ff8c1640d","collapsed":true},"cell_type":"code","source":"aug_imgs.shape, aug_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"acaeb6ad3dfb5ae8de0a329636715d27d0b30ef7","collapsed":true},"cell_type":"code","source":"def get_label(x):\n    s = np.where(x==1)\n    k = s[0]\n    strings = ', '.join(labels[k])\n    return(strings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb77e3478cabdd61557b110615e2e8e6e8a7c4a6"},"cell_type":"code","source":"fig,ax = plt.subplots(1,2, figsize = (15,15))\ni = np.random.randint(0,aug_labels.shape[0])\ni = 36\nx = np.apply_along_axis(get_label, 1, aug_labels)\nimage_original = t_imgs[i]\nimage_aug = aug_imgs[i]\nax[0].imshow(image_original)\nax[0].set_title('Original-' + x[i], fontsize =15)\nax[1].imshow(image_aug)\nax[1].set_title('Augmented-' + x[i], fontsize =15)\nfig.savefig('orig_aug1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"52ebb904ae142d8d0bdf981bf7d371ea65487c22","collapsed":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2, figsize = (15,15))\ni = 59\nx = np.apply_along_axis(get_label, 1, aug_labels)\nimage_original = t_imgs[i]\nimage_aug = aug_imgs[i]\nax[0].imshow(image_original)\nax[0].set_title('Original-' + x[i], fontsize =15)\nax[1].imshow(image_aug)\nax[1].set_title('Augmented-' + x[i], fontsize =15)\nfig.savefig('orig_aug2.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"beac087b04e4f7cc1f4b476d30143497a569108f","collapsed":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2, figsize = (15,15))\ni = np.random.randint(0,aug_labels.shape[0])\ni = 56\nx = np.apply_along_axis(get_label, 1, aug_labels)\nimage_original = t_imgs[i]\nimage_aug = aug_imgs[i]\nax[0].imshow(image_original)\nax[0].set_title('Original-' + x[i], fontsize =15)\nax[1].imshow(image_aug)\nax[1].set_title('Augmented-' + x[i], fontsize =15)\nfig.savefig('orig_aug3.png')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"83a63f0c-c3d1-4395-83ae-de9e5471887a","_uuid":"fd7e2c308b0af76292feee35b6f0a0a99853e580","collapsed":true,"trusted":true},"cell_type":"code","source":"def set_non_trainable_layers(model, range_from, range_to):\n    for i in range(0, len(model.layers)):\n        if range_from <=  i <= range_to:\n            model.layers[i].trainable = False\n        else:\n            model.layers[i].trainable = True","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0d06a5fc-81f1-4219-a623-2f342000dbcb","_uuid":"a4cb622e6cb1e06e2194dc4983a8f5d300953688"},"cell_type":"markdown","source":"# Building model"},{"metadata":{"_cell_guid":"0b327b0e-f8b9-40c9-ae60-886d20738064","_uuid":"97716bb202881a662a1b447595cac6b16f32f999","scrolled":false,"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, BatchNormalization\nfrom tensorflow.python.keras.models import Sequential, Model\nfrom tensorflow.python.keras.applications.vgg19 import VGG19\n\nimg_size = 128 #64\nnum_classes = 17\n\n\nweights_path = '../input/vgg19-weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model  = VGG19(include_top=False, weights= weights_path,  input_shape= (img_size, img_size, 3) )\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\npredictions = Dense(num_classes, activation = 'sigmoid')(x)\n\nmodel = Model(inputs = base_model.input, outputs = predictions)   #check if input size can be turned off\nset_non_trainable_layers(base_model, 0, 21)\n\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"88277859-1a2c-4eb3-a03e-c2158d8e0d2f","_uuid":"0f2f94fadf8d3f09f425494f2a62324fd831fbf9"},"cell_type":"markdown","source":"### Callbacks for weights saving "},{"metadata":{"_cell_guid":"5b41f978-06ef-4d89-86c0-e8eda55d9476","_uuid":"e03b67296b9d024420c24e4d3955d244c92c9bd7","collapsed":true,"trusted":false},"cell_type":"code","source":"from tensorflow.python.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nweights_path = 'adam_weights.hd5'\ncheckpoint = ModelCheckpoint(weights_path, monitor = 'val_loss', save_best_only = True, save_weights_only = True, mode = 'min', verbose =1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"255b8f29-1cdc-4de8-8d40-5350073cc443","_uuid":"63187133e9397390077e6ddbf687cfe17104186a","_kg_hide-input":true,"collapsed":true,"trusted":false},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.keras import backend as K\n\nclass LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n        self.lrs = []\n        self.batches = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        #lr = self.model.optimizer.lr\n        #self.lrs.append(K.cast(lr, 'float32'))\n\n    def on_train_end(self, logs = None):\n        plt.rcParams[\"figure.figsize\"] = (8,15)\n        plt.plot(np.arange(0,len(self.losses),1)[::5],self.losses[::5], color = 'blue')\n        plt.title('Loss with batches')\n        plt.xlabel('batch')\n        plt.ylabel('mse loss')\n        plt.show()\n        \n    \nclass LRFinder(Callback):  #ignore \n    def __init__(self, max_batches = 5000, base_lr = 1e-4, max_lr = 0.1, lr_step_size = 1e-4):\n        self.max_batches = max_batches\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.lr_step_size = lr_step_size\n        self.lr = 0\n        self.lrs = []\n        self.losses = []\n        self.batches = []\n        \n    def on_batch_end(self, batch, logs={}):\n        current_batch = logs.get('batch')\n        self.batches.append(current_batch)\n        #print(current_batch)\n        '''\n        if current_batch >= self.max_batches or self.lr >= self.max_lr:\n            self.model.stop_training = True\n        else:\n            self.lr = self.lr + (current_batch * self.lr_step_size)\n            K.set_value(self.model.optimizer.lr, self.lr)\n            self.losses.append(logs.get('loss'))\n            self.lrs.append(self.lr)\n    '''\n    def on_train_end(self, logs = None):\n        plt.rcParams[\"figure.figsize\"] = (20,10)\n        plt.plot(self.batches[10::5], self.losses[10::5])\n        plt.xlabel('learning rate')\n        plt.ylabel('loss')\n        plt.title('learning rate finder curve')\n        plt.show()\n\nhistory = LossHistory()\nlrf = LRFinder()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a6762871-e5a4-490c-be14-90b4d4adfe96","_uuid":"b6c1f8047da63b82c873933283f2e7292e500e01"},"cell_type":"markdown","source":"### Learning rate scheduler for step decay (ignore for adam only for sgd)"},{"metadata":{"_cell_guid":"b72134a8-8959-497d-b3eb-9d09802afbee","_uuid":"2c13db6577cc27696212437f240d5f7fd72b8b45","collapsed":true,"trusted":false},"cell_type":"code","source":"def step_decay_schedule(initial_lr = 0.01, decay_factor = 0.5, step_size = 2):   #decay_factor =0.5  and step_size = 2 \n    def schedule(epoch):\n        print(initial_lr * (decay_factor ** np.floor(epoch/step_size)))\n        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n    \n    return LearningRateScheduler(schedule)\n\nlr_sched = step_decay_schedule()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0b69c635-7193-4b78-89ab-a2d68b8af9ef","_uuid":"7919fd1e4a5ed9661c672dda1cf906787f1c12ce"},"cell_type":"markdown","source":"### Reducing learning rate when no improvement in loss "},{"metadata":{"_cell_guid":"118c4a47-f4cb-4e5a-9b03-6e291fc25417","_uuid":"1ab39a0ce018126fbef43a20f04aa75c2ed0a9d5","collapsed":true,"trusted":false},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n                              patience=1, min_lr=1e-7, epsilon = 0.001, verbose =1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"716c0daf-3105-418f-b4cc-7a6985d348bb","_uuid":"fd003f64405533e23a360e4472514404bbc34c67"},"cell_type":"markdown","source":"### define the f2_score metric:"},{"metadata":{"_cell_guid":"8a9a0784-343d-4911-940f-97fffee5ac5b","_uuid":"b7ce4214530d6b0ba3c6c245e107f2ab3d1a7d24","collapsed":true,"trusted":false},"cell_type":"code","source":"import tensorflow as tf\n\ndef f2_score(y_true, y_preds):\n    beta = 2\n    y_true = K.cast(y_true, \"int32\")\n    y_preds = K.cast(K.round(y_preds), \"int32\") # implicit 0.5 threshold via tf.round\n    y_correct = y_true * y_preds\n    sum_true = tf.reduce_sum(y_true, axis=1)   ##actual positives\n    sum_pred = tf.reduce_sum(y_preds, axis=1)   ##predicted positives\n    sum_correct = tf.reduce_sum(y_correct, axis=1)  ##true positives \n    precision = sum_correct / sum_pred             \n    recall = sum_correct / sum_true\n    f_score = (beta**2 +1) * precision * recall / ((beta**2) * precision + recall)\n    f_score = tf.where(tf.is_nan(f_score), K.zeros_like(f_score), f_score)\n    return tf.reduce_mean(f_score)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"641e1e42-f6a9-41da-8924-3cc1f66e1502","_uuid":"717e706a41de9bf67fd6936ed76b9014e1161958"},"cell_type":"markdown","source":"### Define optimizer and compile"},{"metadata":{"_cell_guid":"36b45141-08c6-47eb-b824-86944a7122cc","_uuid":"bf7d7f0281d00ae057aa865bb80f210e12929765","collapsed":true,"trusted":false},"cell_type":"code","source":"from tensorflow.python.keras.optimizers import SGD, Adam\n\nmodel.compile(optimizer= Adam(lr = 0.001) , loss='binary_crossentropy', metrics = [f2_score])\n#model.compile(optimizer= SGD(lr = 0.01, momentum = 0.9) , loss='binary_crossentropy', metrics = [f2_score])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f94c30b0-acb7-4384-a97e-30588c96c9d9","_uuid":"240ebd20e48be9cb48325b89e45f56e59b44d8d8"},"cell_type":"markdown","source":"### Train it"},{"metadata":{"_cell_guid":"c864e3f7-85b4-4bd1-b02c-0e646b7eede2","_uuid":"4da0ed1543a7d0c08d96dfa0952b09cd9fb4b30f","scrolled":true,"collapsed":true},"cell_type":"markdown","source":"model.fit_generator(train_generator, steps_per_epoch = 506, epochs = 12, verbose = 1, validation_data = valid_generator , \n                    validation_steps =127 , callbacks = [checkpoint, history, reduce_lr], workers = 4)"},{"metadata":{"_cell_guid":"5eeb021d-47f7-43ff-8c43-c74174c250cf","_uuid":"e8e9eb6a07feac7e99a99f254b758186059c9f08","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"model.fit_generator(train_generator, steps_per_epoch = 506, epochs = 3 , verbose = 1, validation_data = (fixed_val_imgs,fixed_val_labels) ,\n                     callbacks = [checkpoint, reduce_lr], workers = 4)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b9a378c8-1d2b-47d9-86f0-3b2a1ca1b679","_uuid":"3fcbf5097c1252fb43d9bcba8decac5a70a36d72","trusted":false,"collapsed":true},"cell_type":"code","source":"set_non_trainable_layers(model, 0, 16)\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"beaa8f05-29e8-4c0e-85a4-e128917e77fd","_uuid":"ad8d809ec1a13ccd7ccd5240d306eda89bef9816","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"model.compile(optimizer= Adam(lr=1e-4) , loss='binary_crossentropy', metrics = [f2_score])\n#model.compile(optimizer= SGD(lr = 1e-4, momentum = 0.9) , loss='binary_crossentropy', metrics = [f2_score])\nmodel.fit_generator(train_generator, steps_per_epoch = 506, epochs = 7 , verbose = 1, validation_data = (fixed_val_imgs,fixed_val_labels) , \n                     callbacks = [checkpoint, reduce_lr], workers = 4)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4e7df09c-f856-4ecd-9c95-74b48fd13957","_uuid":"7c5bc4ae85fd9fe8e0698c2bda404be0d4209953","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"set_non_trainable_layers(model, 0, 11)\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ec9bab7-666c-4c09-b047-a193686c047d","_uuid":"cd4b21f9edf81764a3ef28c2e713a4c3520ef1a7","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"model.compile(optimizer= Adam(lr=1e-5) , loss='binary_crossentropy', metrics = [f2_score])\n#model.compile(optimizer= SGD(lr = 1e-5, momentum = 0.9) , loss='binary_crossentropy', metrics = [f2_score])\nmodel.fit_generator(train_generator, steps_per_epoch = 506, epochs = 13, verbose = 1, validation_data = (fixed_val_imgs,fixed_val_labels) , \n                     callbacks = [checkpoint, reduce_lr, history], workers = 4)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1cf6c6d3-f639-4406-b2d7-6cea13d4f772","_uuid":"dbe8d5ab230a112756a59096c74c12af50fa96e9","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (8,4)\nplt.plot(np.arange(0,len(history.losses)-1000,80), history.losses[10:-1000:80])\nplt.xlabel('iterations')\nplt.ylabel('loss')\nplt.title('training loss curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5fd54871-7834-438d-a483-47a7bdb2439e","_uuid":"b2b47b87c018c44976920a1dd4b9f5714df95700","collapsed":true,"trusted":false},"cell_type":"code","source":"#model.load_weights('best_weights.hd5')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"908eec39-dfad-4c14-aa43-632885dced87","_uuid":"fe27152a1f7005a1853799923b29b2fdb9790da2"},"cell_type":"markdown","source":"# predicting on test set"},{"metadata":{"_cell_guid":"bd0c7453-3887-4461-8b88-51ce54fa4ac8","_uuid":"cec7f893f13bd4c3788e7f0cc3b1c1d2ca8def06","collapsed":true,"trusted":false},"cell_type":"code","source":"test_dir_path = '../input/planet-understanding-the-amazon-from-space/test-jpg-v2'\n\ntest_images_names = os.listdir(test_dir_path)\ntest_images_paths = [os.path.join(test_dir_path, img_name) for img_name in test_images_names]\n\ntest_data_gen = ImageDataGenerator(rescale = 1./255)\n\nimg_size = 128\ntest_generator = test_data_gen.flow_from_directory(directory = '../input/planet-understanding-the-amazon-from-space/test-jpg-v2', \n                                                   target_size = (img_size,img_size), \n                                                    batch_size = 64,  class_mode = None, shuffle = False)\ntest_generator.filenames = test_images_paths\n#test_generator.samples = label_df.loc[:,label_df.columns !='image_name'].values.shape[0]\ntest_generator.n = len(test_images_paths)\ntest_generator.directory = ''\ntest_generator._set_index_array()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ad585214-dc83-4977-9324-9e2342c61b26","_uuid":"be23f75c2136d4c4cf98050ac340a5b3300135f4","collapsed":true,"trusted":false},"cell_type":"code","source":"rand_images = next(test_generator)\nrand_images.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4ccc9b2f-8c4e-45fc-9496-1d04636e8628","_uuid":"fbdeef82117ce3c186cc2490b8cf7b1090489fa8","scrolled":true,"collapsed":true,"trusted":false},"cell_type":"code","source":"predictions = model.predict_generator(test_generator, verbose=1)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a7a936c0-80a6-4edc-8834-1ad94fa128ab","_uuid":"c2b81cdc73565e741c3272271a1008058f1e6164","collapsed":true,"trusted":false},"cell_type":"code","source":"predictions = np.rint(predictions)\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0dca24bc-ba06-43b7-86b3-297695ae37bc","_uuid":"acd7d9e3f95650fd4035d6acb553f93f612d22b6","collapsed":true,"trusted":false},"cell_type":"code","source":"test_images_series = pd.Series([test_image_name.split('.')[0] for test_image_name in test_images_names])\ntest_images_series.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2b3b6ee1-7127-4354-b0bd-a5b1e12245c7","_uuid":"6ae9ae386d12a45cf1065b66abb4d94b7b899db1","collapsed":true,"trusted":false},"cell_type":"code","source":"\npreds_df = pd.DataFrame(predictions)\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1ef922b5-205d-400b-b457-cbd90df6108c","_uuid":"4b93adb06f84b66c05f34af4379703774220848f","collapsed":true,"trusted":false},"cell_type":"code","source":"def get_tags(row):\n    a = np.where(row ==1)\n    tags = np.array(label_names)[a[0]]\n    return ' '.join(tags)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6b0ae638-f851-4527-976b-e829aae01f16","_uuid":"d5837b0fcf652af23c64b0648b8321ab32d60c87","scrolled":false,"collapsed":true,"trusted":false},"cell_type":"code","source":"tags_series = preds_df.apply(get_tags, axis=1)\ntags_series.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ca293ee7-e242-4cfd-995f-931825f1bd6d","_uuid":"8972a3b57c1f4fe98a89ac1ec5e273b27f0b035b","collapsed":true,"trusted":false},"cell_type":"code","source":"sub_df = pd.concat([test_images_series,tags_series], axis = 1)\nsub_df.columns = ['image_name', 'tags']\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"493266a4-a9d3-411f-87cc-48ba85a20c48","_uuid":"161545e45c6fe925a8cd245ed4a9ee3c687291aa","collapsed":true,"trusted":false},"cell_type":"code","source":"sub_df.to_csv('sub1.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cb9d9176-c5e7-4e8f-a0dc-4fe185174104","_uuid":"42636b6068968be0ae35bd9cde53ba3a3a358ec8"},"cell_type":"markdown","source":"### Predictions distribution"},{"metadata":{"_cell_guid":"be40ca19-c3bf-44e6-9b8c-7a79774c5098","_uuid":"b48f79e62e2199f1968ded9cab085bc9be1946b4","collapsed":true,"trusted":false},"cell_type":"code","source":"counter = Counter([])\nfor tag_list in sub_df['tags'].apply(lambda x:x.split(' ')):\n   counter.update(tag_list)\nlabel_names,count = zip(*counter.items())\nfig = plt.figure(figsize = (15,6))\nax = plt.gca()\nax.bar(np.arange(0,len(label_names),1),count, tick_label = label_names)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c605e5538c8f8b460cf0bb062dcc2d90f4ca1c37"},"cell_type":"markdown","source":"### Predicting on random images from training data "},{"metadata":{"trusted":true,"_uuid":"83129db9c32c89d176c6e6fb453ac6e7f8d08edf"},"cell_type":"code","source":"model.load_weights('../input/satellite-amazon-model-keras-vgg19-adam/adam_weights.hd5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb884dd837b7fa867db3e9b0b6dd593ed21a46c1"},"cell_type":"code","source":"train_generator_no_aug =  get_data_iter(data_generator_no_aug, 128, train_labels, train_images,512, shuffle = 1)\nrand_imgs, rand_labels = next(train_generator_no_aug)\nrand_imgs.shape, rand_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7429fa4af2024efaf515fdf902c3bda4af32f9e"},"cell_type":"code","source":"predictions = model.predict_on_batch(rand_imgs)\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a28e359e69c8c8b48ac52745d091718a4022a1d8"},"cell_type":"code","source":"predictions = np.rint(predictions)\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba4525c04a395a67181d6dd0fbb74b1693e115ee"},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.keras import backend as K\n\ndef f2_score(y_true, y_preds):\n    beta = 2\n    y_true = K.cast(y_true, \"int32\")\n    y_preds = K.cast(K.round(y_preds), \"int32\") # implicit 0.5 threshold via tf.round\n    y_correct = y_true * y_preds\n    sum_true = tf.reduce_sum(y_true, axis=1)   ##actual positives\n    sum_pred = tf.reduce_sum(y_preds, axis=1)   ##predicted positives\n    sum_correct = tf.reduce_sum(y_correct, axis=1)  ##true positives \n    precision = sum_correct / sum_pred\n    print(K.eval(tf.reduce_mean(precision)))\n    recall = sum_correct / sum_true\n    print(K.eval(tf.reduce_mean(recall)))\n    f_score = (beta**2 +1) * precision * recall / ((beta**2) * precision + recall)\n    f_score = tf.where(tf.is_nan(f_score), K.zeros_like(f_score), f_score)\n    return tf.reduce_mean(f_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"49d6a9ad3a7f91f7c42ba0ef63bc391df60d7be7"},"cell_type":"code","source":"K.eval(f2_score(rand_labels, predictions))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}