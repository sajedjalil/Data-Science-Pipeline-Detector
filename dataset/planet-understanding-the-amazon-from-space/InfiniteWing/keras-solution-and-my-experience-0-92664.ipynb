{"metadata":{"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","name":"python","file_extension":".py","version":"3.6.1"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0,"cells":[{"metadata":{"_cell_guid":"438cb39b-452a-4a89-9807-fcc5ecac7ee6","collapsed":false,"_uuid":"389e43b488404ff5a33f7691bf22242cdfc6e34a","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# **Keras solution with my experience[Private LB ~0.92664]**\n### *InfiniteWing*\n### *2017-07-21*\n\nHello, this notebook records my experiences and my solution. I will also attach my pre-trained keras h5 models at the end. \n\nFirst of all I want to thank Tuatini GODARD, kelexu, anokas and so many people who share their experience on forum. I study on their code and experiences, which helps me a lot.\n\nHere's my solution, hope it'll help some of you.\n\nPS:\n\nIt's basically base on Kelexu's kernel - [Keras LB 0.913\n](https://www.kaggle.com/kelexu/keras-lb-0-913)","cell_type":"markdown"},{"metadata":{"_cell_guid":"5762ec6a-3240-4021-8dbe-9b0315b06acc","collapsed":false,"_uuid":"686da57e558fe2daa606be247356211fe1cd56ad","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# Load libraries","cell_type":"markdown"},{"metadata":{"_cell_guid":"b44af871-a0cf-41f7-bd29-989dbf084775","_uuid":"aa0849743d4772bbffb5f95f2c74997f768ece01","trusted":false,"_execution_state":"busy"},"execution_count":null,"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tqdm import tqdm\nfrom keras import optimizers\n\nfrom sklearn.cross_validation import KFold\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.utils import shuffle","cell_type":"code"},{"metadata":{"_cell_guid":"181b1958-4599-47c7-b1e9-a249a42ee985","collapsed":false,"_uuid":"89bd395a38d2426c684668bcb19f3330be390039","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# Define Amazon labels and image size","cell_type":"markdown"},{"metadata":{"_cell_guid":"b906675d-2d17-4738-b595-c18c04b28961","collapsed":false,"_uuid":"e223d212020952d1e9751055a06e3fa467e8e256","trusted":false,"_execution_state":"busy"},"execution_count":null,"outputs":[],"source":"labels = ['blow_down',\n 'bare_ground',\n 'conventional_mine',\n 'blooming',\n 'cultivation',\n 'artisinal_mine',\n 'haze',\n 'primary',\n 'slash_burn',\n 'habitation',\n 'clear',\n 'road',\n 'selective_logging',\n 'partly_cloudy',\n 'agriculture',\n 'water',\n 'cloudy']\n\nlabel_map = {'agriculture': 14,\n 'artisinal_mine': 5,\n 'bare_ground': 1,\n 'blooming': 3,\n 'blow_down': 0,\n 'clear': 10,\n 'cloudy': 16,\n 'conventional_mine': 2,\n 'cultivation': 4,\n 'habitation': 9,\n 'haze': 6,\n 'partly_cloudy': 13,\n 'primary': 7,\n 'road': 11,\n 'selective_logging': 12,\n 'slash_burn': 8,\n 'water': 15}\n\nimage_size=128\n","cell_type":"code"},{"metadata":{"_cell_guid":"44edbfb8-dd14-4f2d-8b42-21348d07139f","collapsed":false,"_uuid":"6d2901a3686b2662952f9a3ee512553fb2641746","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# Define the Keras Model\nYou can also use VGG16, VGG19, ResNet50 and so many model structures. You can take a look on [this discussion](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/33559).","cell_type":"markdown"},{"metadata":{"_cell_guid":"712c35a5-ffff-4357-8c0a-fe3287a4f925","collapsed":false,"_uuid":"439204172d6521f3c84471cd5664daf1b30b63a1","trusted":false,"_execution_state":"busy"},"execution_count":null,"outputs":[],"source":"def Amazon_Model(input_shape=(128, 128,3),weight_path=None):\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=input_shape))\n        \n    model.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n        \n    model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n        \n    model.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu'))\n    model.add(Conv2D(256, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n        \n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid'))\n    if(weight_path!=None):\n        if os.path.isfile(weight_path):\n            model.load_weights(weight_path)\n    return model","cell_type":"code"},{"metadata":{"collapsed":false,"_cell_guid":"2abcd752-6076-4fe2-bef9-cab67673c4fa","_uuid":"f87f7f9de14f7b5e13c0894b6877ee817eb5d8af","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# VGG16 / VGG19\nTake VGG16/VGG19 for example, it's easy to add these models from Keras. If you want to train on these models, just call these functions.\n\nNoted that base on [this discussion](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36091#202629), I don't use dropout to avoid overfitting because it might get higher score on LB. And also I don't add two 4096 Dense layer because the same reason.","cell_type":"markdown"},{"metadata":{"collapsed":false,"_cell_guid":"cca3ee90-581d-4a87-a575-c54220ff13dc","_uuid":"46d9710c11721cee0ba455b67a3cefb5bbd2a826","trusted":false,"_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"def Amazon_Model_VGG19(input_shape=(128, 128,3),weight_path=None):\n    from keras.applications.vgg19 import VGG19\n    base_model=VGG19(include_top=False,\n                   weights='imagenet',\n                   input_shape=input_shape)\n\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=input_shape))\n    model.add(base_model)\n    model.add(Flatten())\n    # I don't use 4096 Dense layer because it might get higher score on LB.\n    # Source: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36091#202629\n    #model.add(Dense(4096, activation='relu'))\n    #model.add(Dense(4096, activation='relu'))\n    model.add(Dense(17, activation='sigmoid'))\n    if(weight_path!=None):\n        if os.path.isfile(weight_path):\n            model.load_weights(weight_path)\n    return model\n\ndef Amazon_Model_VGG16(input_shape=(128, 128,3),weight_path=None):\n    from keras.applications.vgg16 import VGG16\n    base_model=VGG19(include_top=False,\n                   weights='imagenet',\n                   input_shape=input_shape)\n\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=input_shape))\n    model.add(base_model)\n    model.add(Flatten())\n    # I don't use 4096 Dense layer because it might get higher score on LB.\n    # Source: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36091#202629\n    #model.add(Dense(4096, activation='relu'))\n    #model.add(Dense(4096, activation='relu'))\n    model.add(Dense(17, activation='sigmoid'))\n    if(weight_path!=None):\n        if os.path.isfile(weight_path):\n            model.load_weights(weight_path)\n    return model","cell_type":"code"},{"metadata":{"_cell_guid":"cef47b7b-75ac-49eb-a0bb-b875288cdcae","collapsed":false,"_uuid":"1ac8ac5d10be90f73fba843375916d293db46926","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# Use N-Fold on Training and Predicting\nIt will help you avoid some over-fitting, and the ensemble result will perform better than single model in general.  \n\n( I forgot what's the learning rate setting here, maybe something like these. )","cell_type":"markdown"},{"metadata":{"_cell_guid":"6a1bee0a-e015-4b71-9815-9ec5964827dd","collapsed":false,"_uuid":"d660989b5162faad574ad31e6800e8ee379f6fc8","trusted":false,"_execution_state":"busy"},"execution_count":null,"outputs":[],"source":"def KFold_Train(x_train,y_train,nfolds=5,batch_size=128):\n    model = Amazon_Model()\n    kf = KFold(len(y_train), n_folds=nfolds, shuffle=False, random_state=1)\n    num_fold = 0\n    for train_index, test_index in kf:\n    \n        X_train = x_train[train_index]\n        Y_train = y_train[train_index]\n        X_valid = x_train[test_index]\n        Y_valid = y_train[test_index]\n\n        num_fold += 1\n        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n        print('Split train: ', len(X_train), len(Y_train))\n        print('Split valid: ', len(X_valid), len(Y_valid))\n        weight_path = os.path.join('', '../h5_128_rotate_uint8/weights_kfold_' + str(num_fold) + '.h5')\n        if os.path.isfile(weight_path):\n            model.load_weights(weight_path)\n        \n        # I forgot what's the setting here\n        # Maybe like these\n        epochs_arr = [60, 15, 15]\n        learn_rates = [0.001, 0.0001, 0.00001]\n\n        for learn_rate, epochs in zip(learn_rates, epochs_arr):\n            opt  = optimizers.Adam(lr=learn_rate)\n            model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n            callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n            ModelCheckpoint(weight_path, monitor='val_loss', save_best_only=True, verbose=0)]\n\n            model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n                  batch_size=batch_size,verbose=2, epochs=epochs,callbacks=callbacks,shuffle=True)\n        \n        p_valid = model.predict(X_valid, batch_size = batch_size, verbose=2)\n        print(fbeta_score(Y_valid, np.array(p_valid) > 0.18, beta=2, average='samples'))","cell_type":"code"},{"metadata":{"_cell_guid":"e3648800-36df-455b-bea3-09397a9954ac","collapsed":false,"_uuid":"a916a5d74c1adc824d831cf42560d3ae13db8e81","trusted":false,"_execution_state":"busy"},"execution_count":null,"outputs":[],"source":"def KFold_Predict(x_test,nfolds=5,batch_size=128):\n    model = Amazon_Model()\n    yfull_test = []\n    for num_fold in range(1,nfolds+1):\n        weight_path = os.path.join('', '../h5_128_rotate_uint8/weights_kfold_' + str(num_fold) + '.h5')\n        if os.path.isfile(weight_path):\n            model.load_weights(weight_path)\n            \n        p_test = model.predict(x_test, batch_size = batch_size, verbose=2)\n        yfull_test.append(p_test)\n        \n    result = np.array(yfull_test[0])\n    for i in range(1, nfolds):\n        result += np.array(yfull_test[i])\n    result /= nfolds\n    return result","cell_type":"code"},{"metadata":{"_cell_guid":"eb93a0c2-a549-4611-8fa1-1c0ac636a053","collapsed":false,"_uuid":"8cd5b9fe99d714db728221d316c1c08499161103","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# Train / Predict \nHere's some tricks which can help you to avoid OOM. You can use datagenerator to read image on each batch rather than read them all in the beginning. You can read [this kernel](https://www.kaggle.com/sashakorekov/end-to-end-resnet50-with-tta-lb-0-93) for more information.\n\nAnd also you can use DA(data augmentation) when training, that can help you get a better model.\nI only use basic rotation and flip here.","cell_type":"markdown"},{"metadata":{"_cell_guid":"d3b3c91c-8ef3-410c-a10f-673ae044eb39","collapsed":false,"_uuid":"6ed146be3a4c2ff2ae3c1e8b8170cedcd760e303","trusted":false,"_execution_state":"busy"},"execution_count":null,"outputs":[],"source":"def Train():\n    x_train = []\n    y_train = []\n\n    df_train = pd.read_csv('../input/train_v2.csv')\n    df_train = shuffle(df_train,random_state=0)\n    for f, tags in tqdm(df_train.values, miniters=400):\n        img = cv2.imread('C:/train-jpg/{}.jpg'.format(f))\n        targets = np.zeros(17)\n        for t in tags.split(' '):\n            targets[label_map[t]] = 1 \n        img = cv2.resize(img, (image_size, image_size))\n        flipped_img=cv2.flip(img,1)\n        rows,cols,channel = img.shape\n        # regular\n        x_train.append(img)\n        y_train.append(targets)\n        \n        # flipped\n        x_train.append(flipped_img)\n        y_train.append(targets)\n        # rotated\n        for rotate_degree in [90,180,270]:\n            M = cv2.getRotationMatrix2D((cols/2,rows/2),rotate_degree,1)\n            dst = cv2.warpAffine(img,M,(cols,rows))\n            x_train.append(dst)\n            y_train.append(targets)\n            \n            dst = cv2.warpAffine(flipped_img,M,(cols,rows))\n            x_train.append(dst)\n            y_train.append(targets)\n        \n    y_train = np.array(y_train, np.uint8)\n    x_train = np.array(x_train, np.uint8)\n    KFold_Train(x_train,y_train)","cell_type":"code"},{"metadata":{"_cell_guid":"1281c122-067a-4e6a-85cc-5a955cee83c9","collapsed":false,"_uuid":"166e843c00ca4e789f3cf36910482b89a70641c2","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# About the thresholds\nI use [anokas method](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/32475) to find my thresholds, which helps me to get better score\n\n(Public LB: 0.92720 -> 0.92767, Private LB: 0.92585 -> 0.92664)","cell_type":"markdown"},{"metadata":{"_cell_guid":"a81f0b27-3e9e-43a8-93b6-fdf33e97811d","collapsed":false,"_uuid":"1fea6ae8aeabf7ac47d0340b6857ed2364494a19","trusted":false,"_execution_state":"busy"},"execution_count":null,"outputs":[],"source":"def Predict():\n    df_test = pd.read_csv('../input/sample_submission_v2.csv')\n    \n    x_test = []\n    for f, tags in tqdm(df_test.values, miniters=400):\n        img = cv2.imread('C:/test-jpg/{}.jpg'.format(f))\n        x_test.append(cv2.resize(img, (image_size, image_size)))\n    x_test  = np.array(x_test, np.uint8)\n    \n    result = KFold_Predict(x_test)\n    result = pd.DataFrame(result, columns = labels)\n    \n    \n    thres = {   'blow_down':0.2,\n                'bare_ground':0.138,\n                'conventional_mine':0.1,\n                'blooming':0.168,\n                'cultivation':0.204,\n                'artisinal_mine':0.114,\n                'haze':0.204,\n                'primary':0.204,\n                'slash_burn':0.38,\n                'habitation':0.17,\n                'clear':0.13,\n                'road':0.156,\n                'selective_logging':0.154,\n                'partly_cloudy':0.112,\n                'agriculture':0.164,\n                'water':0.182,\n                'cloudy':0.076}\n    \n    \n    preds = []\n    for i in tqdm(range(result.shape[0]), miniters=1000):\n        a = result.ix[[i]]\n        pred_tag=[]\n        for k,v in thres.items():\n            if(a[k][i]>=v):\n                pred_tag.append(k)\n        preds.append(' '.join(pred_tag))\n        \n    df_test['tags'] = preds\n    df_test.to_csv('sub.csv', index=False)","cell_type":"code"},{"metadata":{"_cell_guid":"54ccea38-0b63-4333-a840-83d2bee35c41","collapsed":false,"_uuid":"03b9c0afa7ae679fb5a88fe759448b7e34722e4b","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# Main","cell_type":"markdown"},{"metadata":{"_cell_guid":"9fafa873-e22a-4318-8897-2eccd0526b05","collapsed":false,"_uuid":"406d136b76bbadd941774ecf7a5266092e1d1ad5","trusted":false,"_execution_state":"busy"},"execution_count":null,"outputs":[],"source":"def main():\n    #Train()\n    Predict()\nif __name__ == '__main__':\n    main()","cell_type":"code"},{"metadata":{"_cell_guid":"131693af-e1ca-47f5-a282-0fe0b03ce355","collapsed":false,"_uuid":"2539b6cf1d348d6bef1c5ed82729b913985a394c","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# For more improvement\nYou can try test time augmentation, ensemble different models' predictions. Also take a look on [this discussion](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36091).","cell_type":"markdown"},{"metadata":{"_cell_guid":"123bc5d9-84d6-4832-adff-33a04abb213d","collapsed":false,"_uuid":"8c3a0d24704e77aea708b4783ed035f63631ef91","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"# Pre-Trained keras h5 models\nFor this Amazon_Model, I already upload my pre-trained h5 files to github. You can download them from the following links:\n\n- [weights_kfold_1.h5](https://github.com/InfiniteWing/Kaggle/blob/master/Amazon/h5_128_rotate_uint8/weights_kfold_1.h5)\n- [weights_kfold_2.h5](https://github.com/InfiniteWing/Kaggle/blob/master/Amazon/h5_128_rotate_uint8/weights_kfold_2.h5)\n- [weights_kfold_3.h5](https://github.com/InfiniteWing/Kaggle/blob/master/Amazon/h5_128_rotate_uint8/weights_kfold_3.h5)\n- [weights_kfold_4.h5](https://github.com/InfiniteWing/Kaggle/blob/master/Amazon/h5_128_rotate_uint8/weights_kfold_4.h5)\n- [weights_kfold_5.h5](https://github.com/InfiniteWing/Kaggle/blob/master/Amazon/h5_128_rotate_uint8/weights_kfold_5.h5)","cell_type":"markdown"},{"metadata":{"_cell_guid":"41ff483c-9988-48de-a6dd-d58e094f78fb","collapsed":false,"_uuid":"c5d83d657d3cf6e69bb48ef55c8cb41f8666a883","_execution_state":"idle"},"execution_count":null,"outputs":[],"source":"### Thanks for your watching, hope this will give you some help :)\n\n### See you next competition!","cell_type":"markdown"}]}