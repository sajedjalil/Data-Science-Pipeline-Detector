{"cells":[{"metadata":{"_uuid":"c8fc6c3e84f282d0e6f664caf9848297b6c62a16"},"cell_type":"markdown","source":"### U-net with simple Resnet Blocks\n#### update log\n1. Correct the errors to in function iou_metric,  use \"my_iou_metric\" to moniter the training\n2. Use image size 101 x 101, no resizing\n3. Last layer dropout reduced by half\n4. replace conv2D with 2 basic resnet blocks in each level of U-net\n5.  Use faster rle_encode (> 10 times fater than RLenc ) from (https://www.kaggle.com/lpachuong/apply-crf-unet-bn-diceloss)\n6. set  random_state= 1234 \n\nReference kernels:\n\nhttps://www.kaggle.com/phoenigs/u-net-dropout-augmentation-stratification\n\nhttps://www.kaggle.com/tgibbons/u-net-without-resizing-images\n\nhttps://www.kaggle.com/lpachuong/apply-crf-unet-bn-diceloss\n\nThe results seems not reproducible,  sometimes good (best around IOU0.79 ), sometimes  not as good!\nAny suggestions to improve the results?"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\n%matplotlib inline\n\n# import cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"# Set some parameters\nim_width = 101\nim_height = 101\nim_chan = 1\nbasicpath = '../input/'\npath_train = basicpath + 'train/'\npath_test = basicpath + 'test/'\n\npath_train_images = path_train + 'images/'\npath_train_masks = path_train + 'masks/'\npath_test_images = path_test + 'images/'\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"63c469280793719bf311d51e6ba2cdaea157d175"},"cell_type":"code","source":"img_size_ori = 101\nimg_size_target = 101\n\ndef upsample(img):# not used\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n    #res[:img_size_ori, :img_size_ori] = img\n    #return res\n    \ndef downsample(img):# not used\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n    #return img[:img_size_ori, :img_size_ori]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a64babef03b9a0dbc94387a1dad54971c3e028d"},"cell_type":"code","source":"# Loading of training/testing ids and depths\n\ntrain_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\nlen(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80c3768717007fb5f087d3e01619f1a9f9a3beac"},"cell_type":"code","source":"train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f55103f7daad6f03ec874c643077fe686c31bee"},"cell_type":"code","source":"train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"010066dd50ef4fdfa7dabe2c946fd7491f9556fd","collapsed":true},"cell_type":"code","source":"train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ad5ac1576277fc54d768933c36efd1f9ff01acd"},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15,5))\nsns.distplot(train_df.coverage, kde=False, ax=axs[0])\nsns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\nplt.suptitle(\"Salt coverage\")\naxs[0].set_xlabel(\"Coverage\")\naxs[1].set_xlabel(\"Coverage class\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f34c4263989a3d95af1e5922c1b7d2126655610"},"cell_type":"code","source":"#Plotting the depth distributionsÂ¶\n\nsns.distplot(train_df.z, label=\"Train\")\nsns.distplot(test_df.z, label=\"Test\")\nplt.legend()\nplt.title(\"Depth distribution\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"51981795f0dd6b8ca7abe4db367f48313b63811e"},"cell_type":"code","source":"# Create train/validation split stratified by salt coverage\n\nids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7fb577cdf27f365d4a912728c2a7654d0e60fac8"},"cell_type":"code","source":"def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = BatchNormalization()(x)\n    if activation == True:\n        x = Activation('relu')(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = Activation('relu')(blockInput)\n    x = BatchNormalization()(x)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (1,1), activation=False)\n    x = Add()([x, blockInput])\n    return x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"02967d71ee7f936254ab54acf2aa7c2e038a2b21"},"cell_type":"code","source":"# Build model\ndef build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n    # 101 -> 50\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = Activation('relu')(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(DropoutRatio/2)(pool1)\n\n    # 50 -> 25\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = Activation('relu')(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(DropoutRatio)(pool2)\n\n    # 25 -> 12\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = Activation('relu')(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(DropoutRatio)(pool3)\n\n    # 12 -> 6\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = Activation('relu')(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(DropoutRatio)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = Activation('relu')(convm)\n    \n    # 6 -> 12\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(DropoutRatio)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = Activation('relu')(uconv4)\n    \n    # 12 -> 25\n    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(DropoutRatio)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = Activation('relu')(uconv3)\n\n    # 25 -> 50\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n        \n    uconv2 = Dropout(DropoutRatio)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = Activation('relu')(uconv2)\n    \n    # 50 -> 101\n    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    \n    uconv1 = Dropout(DropoutRatio)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = Activation('relu')(uconv1)\n    \n    uconv1 = Dropout(DropoutRatio/2)(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return output_layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b9d158f567c829c55139acc9e79a41761d911726"},"cell_type":"code","source":"#Score the model and do a threshold optimization by the best IoU.\n\n# src: https://www.kaggle.com/aglotero/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n\n\n    true_objects = 2\n    pred_objects = 2\n\n    # Jiaxin fin that if all zeros, then, the background is treated as object\n    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n    #print(temp1)\n    intersection = temp1[0]\n    #print(\"temp2 = \",temp1[1])\n    #print(intersection.shape)\n   # print(intersection)\n    # Compute areas (needed for finding the union between all objects)\n    #print(np.histogram(labels, bins = true_objects))\n    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n    #print(\"area_true = \",area_true)\n    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n  \n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    intersection[intersection == 0] = 1e-9\n    \n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    y_pred_in = y_pred_in > 0.5 # added by sgx 20180728\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    #print(\"metric = \",metric)\n    return np.mean(metric)\n\ndef my_iou_metric(label, pred):\n    metric_value = tf.py_func(iou_metric_batch, [label, pred], tf.float64)\n    return metric_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"072ab621d38cc93d26998f391357cb6efc791600"},"cell_type":"code","source":"#Data augmentation\n#x_train2 = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n#y_train2 = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n\n\n## Image Augmentation\n# Vertical Image\nVx = [np.flip(x, axis=0) for x in x_train]\nVy = [np.flip(x, axis=0) for x in y_train]\n\n# Horizontal Image\nHx = [np.flip(x, axis=1) for x in x_train]\nHy = [np.flip(x, axis=1) for x in y_train]\n\n# Horizontal Vertical Image\nHVx = [np.flip(x, axis=1) for x in Vx]\nHVy = [np.flip(x, axis=1) for x in Vy]\n\n# Appending the augmented image and mask to the main dataset.\nx_train = np.append(x_train, Vx, axis=0)\ny_train = np.append(y_train, Vy, axis=0)\n\nx_train = np.append(x_train, Hx, axis=0)\ny_train = np.append(y_train, Hy, axis=0)\n\nx_train2 = np.append(x_train, HVx, axis=0)\ny_train2 = np.append(y_train, HVy, axis=0)\n\n\n\nprint(x_train2.shape)\nprint(y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30622932f68888e895a9b8cac91810a1bb3c5e75","scrolled":true},"cell_type":"code","source":"# model\ninput_layer = Input((img_size_target, img_size_target, 1))\n# input_layer2 = Input((img_size_target, img_size_target, 1))\noutput_layer = build_model(input_layer, 32,0.5)\n\n# del model\nmodel = Model(input_layer, output_layer)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[my_iou_metric])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41699081be465c14e193ffad4fd00bd56840f156","scrolled":true},"cell_type":"code","source":"\nearly_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=20, verbose=1)\nmodel_checkpoint = ModelCheckpoint(\"./unet_best1.model\",monitor='val_my_iou_metric', \n                                   mode = 'max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n#reduce_lr = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n\nepochs = 200\nbatch_size = 32\n\nhistory = model.fit(x_train2, y_train2,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81aba20e2904bcab1c3ac601f28a880f856e491b","collapsed":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n# summarize history for loss\nplt.plot(history.history['my_iou_metric'][1:])\nplt.plot(history.history['val_my_iou_metric'][1:])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='upper left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"347c6567c95430f28ec51b94f42603e37a4056db","collapsed":true},"cell_type":"code","source":"fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\nax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a081f8f61a713457c8c8f3979a78f75541875456"},"cell_type":"code","source":"model = load_model(\"./unet_best1.model\",custom_objects={'my_iou_metric': my_iou_metric})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5da2648534e6f8a4d2fbd8995cf9e6a1c9c0d227"},"cell_type":"code","source":"def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n    preds_test1 = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n    preds_test2 = np.array([ np.fliplr(x) for x in preds_test2_refect] )\n    preds_avg = (preds_test1 +preds_test2)/2\n    return preds_avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7a061700364ea17735f953d6bd3c835bc3dc630","collapsed":true},"cell_type":"code","source":"preds_valid = predict_result(model,x_valid,img_size_target)\npreds_valid2 = np.array([downsample(x) for x in preds_valid])\n\ny_valid2 = np.array([downsample(x) for x in y_valid])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91b1be75d7e8ff74db956c8c846c47ed7576ecb2","collapsed":true},"cell_type":"code","source":"## Scoring for last model\nthresholds = np.linspace(0.3, 0.7, 31)\nious = np.array([iou_metric_batch(y_valid2, np.int32(preds_valid2 > threshold)) for threshold in tqdm_notebook(thresholds)])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1beb285910aa6532d7a69a70afa6a9671e6d347d","collapsed":true},"cell_type":"code","source":"threshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2c4852ecf2c504a4ce30e975f5e36b534c2111e6"},"cell_type":"code","source":"\"\"\"\nused for converting the decoded image to rle mask\nFast compared to previous one\n\"\"\"\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21bb50645b1c67d907e42c262d92f975668fccac","collapsed":true},"cell_type":"code","source":"x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ce8185fa64aafbe42ebde98aba984b4f22b0050e"},"cell_type":"code","source":"preds_test = predict_result(model,x_test,img_size_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ccac81a492b9caaff4a25401165e145cf2c6f8e","collapsed":true},"cell_type":"code","source":"import time\nt1 = time.time()\npred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\nt2 = time.time()\n\nprint(f\"Usedtime = {t2-t1} s\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"770d7d596656f4f1ad17a6063ad662ac80e11b24"},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission4.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"031bc2ef4548059939fae54c06f24f68e0ad3330"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}