{"nbformat":4,"nbformat_minor":1,"cells":[{"source":"This kernel is aimed to improve the solution quality of your current submission via Hungarian method. \n\nThis kernel is largely inspired by beluga's previous kernel on the original problem (before the competition relaunch)         \nImprove with the Hungarian method [0.9375]      \nhttps://www.kaggle.com/gaborfodor/improve-with-the-hungarian-method-0-9375    \n\n<s>\nFor demonstration purpose, I also used the1owl's kernel - Santas ACME Optimizer Needs Optimizing, which has a relatively good score of 0.8922217472 to start improving upon.        \nhttps://www.kaggle.com/the1owl/santas-acme-optimizer-needs-optimizing   \n</s>\n\n**Kernel Updates:**      \nFor demonstration purpose, I also used ZFTurbo's recent kernel - Max Flow with Min Cost v2 [0.9267], which has a great  score of 0.9264476351 to start improving upon.        \nhttps://www.kaggle.com/zfturbo/max-flow-with-min-cost-v2-0-9267   \n","metadata":{"_cell_guid":"6903f5f4-bc3e-463f-9cd9-3b329d35eeb2","_uuid":"9e653d644ccb77e14c2d5fc297513545087181f6"},"cell_type":"markdown"},{"outputs":[],"source":"import os, operator, math\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import linear_sum_assignment\nfrom collections import defaultdict, Counter","metadata":{"_cell_guid":"8c0ad573-3d8a-4f35-b018-d997b6564f6a","_uuid":"a61b1856ebf88df20e83d0061e3ee26fb63cee0e","collapsed":true},"execution_count":null,"cell_type":"code"},{"outputs":[],"source":"child_data = pd.read_csv('../input/santa-gift-matching/child_wishlist_v2.csv', \n                         header=None).drop(0, 1).values\ngift_data = pd.read_csv('../input/santa-gift-matching/gift_goodkids_v2.csv', \n                        header=None).drop(0, 1).values\n\nn_children = 1000000\nn_gift_type = 1000 \nn_gift_quantity = 1000\nn_child_wish = 100\ntriplets = 5001\ntwins = 40000\ntts = triplets + twins ","metadata":{"_cell_guid":"02324b90-d1da-4f07-8728-0f32e80cc72c","_uuid":"5c1d6975a1f614b44073f107388451e6d61097a2","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":">## Happiness calcuation","metadata":{"_cell_guid":"5c53aab8-84cf-4585-9a74-44e2f8ffe6a7","_uuid":"4a0ad45daea0e54b9f8b659c54c83d513d1f4f50"},"cell_type":"markdown"},{"outputs":[],"source":"gift_happiness = (1. / (2 * n_gift_type)) * np.ones(\n    shape=(n_gift_type, n_children), dtype = np.float32)\n\nfor g in range(n_gift_type):\n    for i, c in enumerate(gift_data[g]):\n        gift_happiness[g,c] = -2. * (n_gift_type - i)  \n\nchild_happiness = (1. / (2 * n_child_wish)) * np.ones(\n    shape=(n_children, n_gift_type), dtype = np.float32)\n\nfor c in range(n_children):\n    for i, g in enumerate(child_data[c]):\n        child_happiness[c,g] = -2. * (n_child_wish - i) \n\ngift_ids = np.array([[g] * n_gift_quantity for g in range(n_gift_type)]).flatten()","metadata":{"_cell_guid":"d1682b20-c05c-4b00-b3b6-50b0fe8ac5c7","_uuid":"9f523b4a106b53dcb3921fe2df655fe540924e15","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":">## Function to evaluate performance score","metadata":{"_cell_guid":"9bad44d5-a513-4055-bc3d-adc5bc9097de","_uuid":"eec84eb8374e0c0df94f4b8e2e315dd40f692ba8"},"cell_type":"markdown"},{"outputs":[],"source":"def lcm(a, b):\n    \"\"\"Compute the lowest common multiple of a and b\"\"\"\n    # in case of large numbers, using floor division\n    return a * b // math.gcd(a, b)\n\ndef avg_normalized_happiness(pred, gift, wish):\n    \n    n_children = 1000000 \n    n_gift_type = 1000 \n    n_gift_quantity = 1000 \n    n_gift_pref = 100 \n    n_child_pref = 1000\n    twins = math.ceil(0.04 * n_children / 2.) * 2   \n    triplets = math.ceil(0.005 * n_children / 3.) * 3   \n    ratio_gift_happiness = 2\n    ratio_child_happiness = 2\n\n    # check if triplets have the same gift\n    for t1 in np.arange(0, triplets, 3):\n        triplet1 = pred[t1]\n        triplet2 = pred[t1+1]\n        triplet3 = pred[t1+2]\n        assert triplet1 == triplet2 and triplet2 == triplet3\n                \n    # check if twins have the same gift\n    for t1 in np.arange(triplets, triplets+twins, 2):\n        twin1 = pred[t1]\n        twin2 = pred[t1+1]\n        assert twin1 == twin2\n\n    max_child_happiness = n_gift_pref * ratio_child_happiness\n    max_gift_happiness = n_child_pref * ratio_gift_happiness\n    total_child_happiness = 0\n    total_gift_happiness = np.zeros(n_gift_type)\n    \n    for i in range(len(pred)):\n        child_id = i\n        gift_id = pred[i]\n        \n        # check if child_id and gift_id exist\n        assert child_id < n_children\n        assert gift_id < n_gift_type\n        assert child_id >= 0 \n        assert gift_id >= 0\n        child_happiness = (n_gift_pref - np.where(wish[child_id]==gift_id)[0]\n                          ) * ratio_child_happiness\n        if not child_happiness:\n            child_happiness = -1\n\n        gift_happiness = ( n_child_pref - np.where(gift[gift_id]==child_id)[0]\n                         ) * ratio_gift_happiness\n        if not gift_happiness:\n            gift_happiness = -1\n\n        total_child_happiness += child_happiness\n        total_gift_happiness[gift_id] += gift_happiness\n        \n    denominator1 = n_children*max_child_happiness\n    denominator2 = n_gift_quantity*max_gift_happiness*n_gift_type\n    common_denom = lcm(denominator1, denominator2)\n    multiplier = common_denom / denominator1\n\n    ret = float(math.pow(total_child_happiness*multiplier,3) \n                + math.pow(np.sum(total_gift_happiness),3)\n               ) / float(math.pow(common_denom,3))\n\n    return ret","metadata":{"_cell_guid":"ba576d33-836e-44c3-b343-f77614178b2a","_uuid":"69739db98922408b109ecad0c23cc62a78c1c65f","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"> ## Load the result file from ZFTurbo's kernel - Max Flow with Min Cost v2\nhttps://www.kaggle.com/zfturbo/max-flow-with-min-cost-v2-0-9267 ","metadata":{"_cell_guid":"6ffd1a2a-0daf-404c-9718-2f345a061f34","_uuid":"3739d33f91673d00568de831103c0b7765504882","collapsed":true},"cell_type":"markdown"},{"outputs":[],"source":"initial_sub = '../input/max-flow-with-min-cost-v2-0-9267/subm_0.926447635166.csv'\nsubm = pd.read_csv(initial_sub)\nsubm['gift_rank'] = subm.groupby('GiftId').rank() - 1\nsubm['gift_id'] = subm['GiftId'] * 1000 + subm['gift_rank']\nsubm['gift_id'] = subm['gift_id'].astype(np.int64)\ncurrent_gift_ids = subm['gift_id'].values","metadata":{"_cell_guid":"b80299ca-ff14-41b7-9858-2446bd89bcd1","_uuid":"d75292d6a919faed224421f46cc91fdf2004a853","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"> ## Evalute performace score for current ZFTurbo's solution","metadata":{"_cell_guid":"945635e4-1754-425d-82c1-891de2a562cf","_uuid":"30a7f3000b5738dc12f445725c42091afd23304f"},"cell_type":"markdown"},{"outputs":[],"source":"wish = pd.read_csv('../input/santa-gift-matching/child_wishlist_v2.csv', \n                   header=None).as_matrix()[:, 1:]\ngift_init = pd.read_csv('../input/santa-gift-matching/gift_goodkids_v2.csv', \n                        header=None).as_matrix()[:, 1:]\ngift = gift_init.copy()\nansw_org = np.zeros(len(wish), dtype=np.int32)\nansw_org[subm[['ChildId']]] = subm[['GiftId']]\nscore_org = avg_normalized_happiness(answ_org, gift, wish)\nprint('Predicted score: {:.8f}'.format(score_org))","metadata":{"_cell_guid":"a225a5cf-b5a6-460b-806c-5b30014fa479","_uuid":"12cee03d52d36db38afed26269dcf911256b089c"},"execution_count":null,"cell_type":"code"},{"source":">   # Define optimization block","metadata":{"_cell_guid":"be467eb2-1703-4de0-b641-bc9a284c38c2","_uuid":"2caddc1a07fe7fedc64779472c331384d8f5a5c6"},"cell_type":"markdown"},{"source":"The optimize block only takes child happiness to optimize first, then to verify each step if there is an improvement in the overall performance.  As the objective function is in cubic form - nonlinear, adding child happiness and gift happiness may not work quite well, unless doing some approximation work (like this discussion: https://www.kaggle.com/c/santa-gift-matching/discussion/46559). ","metadata":{"_cell_guid":"062da31e-8212-406f-82a3-32ad1f3ce8d3","_uuid":"858d0b48e7f970c8c50e1b8871e0f002739adfdc"},"cell_type":"markdown"},{"outputs":[],"source":"def optimize_block(child_block, current_gift_ids):\n    gift_block = current_gift_ids[child_block]\n    C = np.zeros((block_size, block_size))\n    for i in range(block_size):\n        c = child_block[i]\n        for j in range(block_size):\n            g = gift_ids[gift_block[j]]\n            C[i, j] = child_happiness[c][g]\n    row_ind, col_ind = linear_sum_assignment(C)\n    return (child_block[row_ind], gift_block[col_ind])","metadata":{"_cell_guid":"a531c8bc-dc03-498c-84a8-caf7fb0450c7","_uuid":"f0e17cadee4a0ca42fe203ecf5ce515d4c537483","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"># Initialize the parameters (e.g. block size, etc.)","metadata":{"_cell_guid":"0e4d2db7-1654-437c-b55e-3e2e424566c2","_uuid":"b54fc600577a7bc07aa5e3e3d19a497a28ec1a8b"},"cell_type":"markdown"},{"source":"The block size can be twisted - considering the algorithm complexity in Hungarian method. Be warned that the solving speed is not linearly aligned with the block size.  As I experimented offline, increasing the block size tends to improve the solution quality during each iteration, but it slows down the optimization process (balance the trade-offs here).","metadata":{"_cell_guid":"ec4aa965-859f-43b3-b84b-751f0df39692","_uuid":"0608a9142d8b37429b4ae4e7e975b2835fbf3901"},"cell_type":"markdown"},{"outputs":[],"source":"block_size = 1500\nn_blocks = int((n_children - tts) / block_size)\nchildren_rmd = 1000000 - 45001 - n_blocks * block_size\nprint('block size: {}, num blocks: {}, children reminder: {}'.\n      format(block_size, n_blocks, children_rmd))","metadata":{"_cell_guid":"660814f1-27e0-40e1-8ff7-bcb755c8d21f","_uuid":"c7581347de5add55e1353f54b500d64bed6db63d"},"execution_count":null,"cell_type":"code"},{"source":"># Start optimizing...","metadata":{"_cell_guid":"216b522b-87e2-4c91-b20d-6ee77313b106","_uuid":"f82dc263a6ae1f6d88f9e8267c43069025f6e712"},"cell_type":"markdown"},{"source":"This code block consumes most of the computational time for this kernel. Given Kaggle kernel's limited capbility, a small set of runs are used.  Two parameters to twist for further performance improvement: 1. perm_len 2. block_len (perm_len and block_len control the number of shuffles and the running length, respectively, feel free to adjust them to run the program as long as you can afford).\n","metadata":{"_cell_guid":"1f9e3f39-5932-40e8-8d80-4df3aed1b84a","_uuid":"b57da47118c894cab127937e176aec71860fc672"},"cell_type":"markdown"},{"outputs":[],"source":"answ_iter = np.zeros(len(wish), dtype=np.int32)\nscore_best = score_org\nsubm_best = subm\nperm_len = 2\nblock_len = 5\nfor i in range(perm_len):  \n    print('Current permutation step is: %d' %(i+1))\n    child_blocks = np.split(np.random.permutation\n                            (range(tts, n_children - children_rmd)), n_blocks)\n    for child_block in tqdm(child_blocks[:block_len]):\n        start_time = dt.datetime.now()\n        cids, gids = optimize_block(child_block, current_gift_ids=current_gift_ids)\n        current_gift_ids[cids] = gids\n        end_time = dt.datetime.now()\n        print('Time spent to optimize this block in seconds: {:.2f}'.\n              format((end_time-start_time).total_seconds()))\n        ## need evaluation step for every block iteration \n        subm['GiftId'] = gift_ids[current_gift_ids]\n        answ_iter[subm[['ChildId']]] = subm[['GiftId']]\n        score_iter = avg_normalized_happiness(answ_iter, gift, wish)\n        print('Score achieved in current iteration: {:.8f}'.format(score_iter))\n        if score_iter > score_best:\n            subm_best['GiftId'] = gift_ids[current_gift_ids]\n            score_best = score_iter\n            print('This is a performance improvement!')\n        else: print('No improvement at this iteration!')\n            \nsubm_best[['ChildId', 'GiftId']].to_csv('improved_sub.csv', index=False)\nprint('Best score achieved is: {:.8f}'.format(score_best))","metadata":{"_cell_guid":"95bfe320-2591-44f2-bba2-06c59761280f","_uuid":"ef9c4f83f4df0c83b39794252590d935eca1acf2"},"execution_count":null,"cell_type":"code"},{"source":"## Given the problem size and a bit slowness of the hungarian method - if you are patient, you should surely see performance improvement at the end! ","metadata":{"_cell_guid":"1fa7233d-8383-44f0-9bf4-2a53e23fed0d","_uuid":"f1724f53fa3177d17721638470c82064b5db0c9e","collapsed":true},"cell_type":"markdown"}],"metadata":{"language_info":{"pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.6.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}