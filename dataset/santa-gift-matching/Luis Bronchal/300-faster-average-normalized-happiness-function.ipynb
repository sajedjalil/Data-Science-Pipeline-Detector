{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","version":"3.6.3","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python"}},"cells":[{"metadata":{"_uuid":"60a2cddb5047a327188737aa4efde2d30f904203","_cell_guid":"8801e2e5-920b-470e-82fa-d796ccb37771"},"source":"## Summary\nThis is not a typical machine learning problem, but it's a very interesting optimization one. The possibility to evaluate fast the solutions it's going to be very important. The following implementation of the **Average Normalized Happiness** function was originally provided by organizers [here](https://www.kaggle.com/wendykan/average-normalized-happiness-demo) but with small changes it can run in almost **70% less time** \n\nupdate:\n\nI have added a more extended analysis of the time execution comparison and changed the name of the kernel. The original one was confusing: \"70% Faster Average Normalized Happiness Function\". The optimized script takes 70% less time to execute than the original one, but that means it is about 300% faster.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"a8ae2537afe8afc1760f1eb6ecc039477cb1fee1","_cell_guid":"fd0fc0cc-293d-45eb-9a1c-6febcc9395d9"},"execution_count":null,"source":"import numpy as np \nimport pandas as pd ","cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"36cf3c5bdc58383f33a34266e3e7df782da4d5a6","_cell_guid":"d68c1540-ca0e-48c3-be94-3166f6f5ea9d"},"execution_count":null,"source":"gift_pref = pd.read_csv('../input/child_wishlist.csv',header=None).drop(0, 1).values\nchild_pref = pd.read_csv('../input/gift_goodkids.csv',header=None).drop(0, 1).values\nrandom_sub = pd.read_csv('../input/sample_submission_random.csv').values.tolist()","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"4337dc50ea46092fc443f80d8ade4fb55386db1c","_cell_guid":"dabb9ad7-fdc7-4551-972e-23a8708d1d87"},"source":"The original function from [here](https://www.kaggle.com/wendykan/average-normalized-happiness-demo):","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"f75cd99829c6c74c9cd6a8194dd490a8509e4311","_cell_guid":"2f3e98e4-c849-4342-9da2-c138ac927658"},"execution_count":null,"source":"# https://www.kaggle.com/wendykan/average-normalized-happiness-demo\n\nfrom collections import Counter\n\nn_children = 1000000 # n children to give\nn_gift_type = 1000 # n types of gifts available\nn_gift_quantity = 1000 # each type of gifts are limited to this quantity\nn_gift_pref = 10 # number of gifts a child ranks\nn_child_pref = 1000 # number of children a gift ranks\ntwins = int(0.004 * n_children)    # 0.4% of all population, rounded to the closest even number\nratio_gift_happiness = 2\nratio_child_happiness = 2\n\n\ndef avg_normalized_happiness(pred, child_pref, gift_pref):\n    \n    # check if number of each gift exceeds n_gift_quantity\n    gift_counts = Counter(elem[1] for elem in pred)\n    for count in gift_counts.values():\n        assert count <= n_gift_quantity\n                \n    # check if twins have the same gift\n    for t1 in range(0,twins,2):\n        twin1 = pred[t1]\n        twin2 = pred[t1+1]\n        assert twin1[1] == twin2[1]\n    \n    max_child_happiness = n_gift_pref * ratio_child_happiness\n    max_gift_happiness = n_child_pref * ratio_gift_happiness\n    total_child_happiness = 0\n    total_gift_happiness = np.zeros(n_gift_type)\n    \n    for row in pred:\n        child_id = row[0]\n        gift_id = row[1]\n        \n        # check if child_id and gift_id exist\n        assert child_id < n_children\n        assert gift_id < n_gift_type\n        assert child_id >= 0 \n        assert gift_id >= 0\n        child_happiness = (n_gift_pref - np.where(gift_pref[child_id]==gift_id)[0]) * ratio_child_happiness\n        if not child_happiness:\n            child_happiness = -1\n\n        gift_happiness = ( n_child_pref - np.where(child_pref[gift_id]==child_id)[0]) * ratio_gift_happiness\n        if not gift_happiness:\n            gift_happiness = -1\n\n        total_child_happiness += child_happiness\n        total_gift_happiness[gift_id] += gift_happiness\n    \n    # print(max_child_happiness, max_gift_happiness \n    print('normalized child happiness=',float(total_child_happiness)/(float(n_children)*float(max_child_happiness)) , \\\n        ', normalized gift happiness',np.mean(total_gift_happiness) / float(max_gift_happiness*n_gift_quantity))\n    return float(total_child_happiness)/(float(n_children)*float(max_child_happiness)) + np.mean(total_gift_happiness) / float(max_gift_happiness*n_gift_quantity)\n","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"8cdb68cb4228e1de5814fd1725d2254e0ba497ee","_cell_guid":"726a5644-88d9-424e-b8d3-b89f0ee4355f"},"source":"Some changes using [numba](https://numba.pydata.org/):","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"01de223a0c5ba0051d4a6326ac615c718e91ee04","_cell_guid":"1210a000-7688-47c4-8aa2-8d1f459aa2f8"},"execution_count":null,"source":"from numba import jit\n\n@jit(nopython=True)\ndef avg_normalized_happiness_fast(pred, child_pref, gift_pref):\n    \n    n_children = 1000000 # n children to give\n    n_gift_type = 1000 # n types of gifts available\n    n_gift_quantity = 1000 # each type of gifts are limited to this quantity\n    n_gift_pref = 10 # number of gifts a child ranks\n    n_child_pref = 1000 # number of children a gift ranks\n    twins = int(0.004 * n_children)    # 0.4% of all population, rounded to the closest even number\n    ratio_gift_happiness = 2\n    ratio_child_happiness = 2\n\n    # check if number of each gift exceeds n_gift_quantity\n    tmp_dict = np.zeros(n_gift_quantity, dtype=np.uint16)\n    for i in np.arange(len(pred)):\n        tmp_dict[pred[i][1]] += 1\n    for count in np.arange(n_gift_quantity):\n        assert count <= n_gift_quantity    \n                \n    # check if twins have the same gift\n    for t1 in np.arange(0,twins,2):\n        twin1 = pred[t1]\n        twin2 = pred[t1+1]\n        assert twin1[1] == twin2[1]\n    \n    max_child_happiness = n_gift_pref * ratio_child_happiness\n    max_gift_happiness = n_child_pref * ratio_gift_happiness\n    total_child_happiness = 0\n    total_gift_happiness = np.zeros(n_gift_type, dtype=np.float32)\n\n    for i in np.arange(len(pred)):\n        row = pred[i]\n        child_id = row[0]\n        gift_id = row[1]\n        \n        # check if child_id and gift_id exist\n        assert child_id < n_children\n        assert gift_id < n_gift_type\n        assert child_id >= 0 \n        assert gift_id >= 0\n        \n        child_happiness = (n_gift_pref - np.where(gift_pref[child_id]==gift_id)[0]) * ratio_child_happiness\n        if (len(child_happiness) == 0):\n            tmp_child_happiness = -1\n        else:\n            tmp_child_happiness = child_happiness[0]\n\n        gift_happiness = ( n_child_pref - np.where(child_pref[gift_id]==child_id)[0]) * ratio_gift_happiness\n        if (len(gift_happiness) == 0):\n            tmp_gift_happiness = -1\n        else:\n            tmp_gift_happiness = gift_happiness[0]\n            \n        total_child_happiness += tmp_child_happiness    \n        total_gift_happiness[gift_id] += tmp_gift_happiness    \n        \n    # print(max_child_happiness, max_gift_happiness  \n    print('normalized child happiness=',float(total_child_happiness)/(float(n_children)*float(max_child_happiness)) , \\\n        ', normalized gift happiness',np.mean(total_gift_happiness) / float(max_gift_happiness*n_gift_quantity))\n    return float(total_child_happiness)/(float(n_children)*float(max_child_happiness)) + np.mean(total_gift_happiness) / float(max_gift_happiness*n_gift_quantity)\n            ","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"2da2c14f625247be1f2f5a3e19b8e03a311b63a2","_cell_guid":"ebdeb54b-0d8f-4e5b-9016-bf5b9f13ee64"},"source":"Let's compare performance:","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"feceefbc02344721e7aa6a70fea62e50d640a194","_cell_guid":"ba0ec542-5e15-4cf7-8ec4-b28a0eb9b601"},"execution_count":null,"source":"time_original = %timeit -r 10 -o avg_normalized_happiness(random_sub, child_pref, gift_pref)","cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"bff4187582a4c58f64dabffa95bb11c4bea520a0","_cell_guid":"cd087fba-8920-462f-a511-e7e632b7c690"},"execution_count":null,"source":"time_fast = %timeit -r 10 -o avg_normalized_happiness_fast(np.array(random_sub), child_pref, gift_pref)","cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"793ea1a61f46f06b9297e37e0f0c2d88a6703299","_cell_guid":"81c6a2c9-8e31-4c11-841b-a372429e8fe4"},"execution_count":null,"source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ntime_result = pd.DataFrame({'time_original': time_original.all_runs,\n                            'time_fast': time_fast.all_runs})\ntime_result.describe()","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"e8afc3c05d9518f9feb518131862cd7842f23a53","_cell_guid":"87d216b8-0287-472d-a927-f58eaa2f3010"},"source":"The original version takes 20.53 seconds in mean, while the optimized one with numba takes about 6.45 seconds in mean. That's 14.08 seconds less, almost 70% less time (68.58%). That means that the optimized script is more than 300% faster (100/31.42  = 3.18)","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"5cb0ca633121614f84179fca6d9803cc36a5d979","_cell_guid":"537e25a3-61b9-4ecb-be17-42177e7120f2"},"execution_count":null,"source":"time_result.plot.box(figsize=(12,10))\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8f866273f406a00a3c7a87b238e34c07ac07d28e","_cell_guid":"5ad6ccec-236a-421c-9db4-d028ac91b4a3"},"execution_count":null,"source":"time_result.plot(figsize=(12,10))\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"3a0b0cf94f02840497a680df1dfbc15a31126042","_cell_guid":"9d5c8d72-5184-466a-a3b0-3211adf12e90"},"source":"The new function is faster, but I'm sure there is still room for more improvement. \nAlthough both functions produce almost the same result, there is a small deifference because of float representation:","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"143a1ec9f69c4f6ee2a33bbbb6537da2cf3f551a","_cell_guid":"e797b6f9-ea21-4800-81b5-31b66312830d"},"execution_count":null,"source":"avg_normalized_happiness(np.array(random_sub), child_pref, gift_pref)","cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"4954245645e9b737c3151962a67ee133f9328fba","_cell_guid":"6756bb39-a086-479c-bab3-d99b10a1850d"},"execution_count":null,"source":"avg_normalized_happiness_fast(np.array(random_sub), child_pref, gift_pref)","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"cfc0188d7897fcd8193382f4dad89be638f5c353","_cell_guid":"071b980a-e2d5-40f9-9728-e38bad1d6824"},"source":"## Conclusion\nWith small changes, we have built an more than **300% faster Average Normalized Happiness function** with the [numba](https://numba.pydata.org/) package, and it is possible to even get better performance. Other alternatives could be to use [cython](http://cython.org/) and even better, in case of not using python,  to use C++ with CUDA support.","cell_type":"markdown"}],"nbformat_minor":1,"nbformat":4}