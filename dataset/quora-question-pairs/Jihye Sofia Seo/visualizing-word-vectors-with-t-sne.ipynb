{"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"# Visualizing Word Vectors with t-SNE\n\nTSNE is pretty useful when it comes to visualizing similarity between objects. It works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words. \n\n### Steps\n\n1. Clean the data\n2. Build a corpus\n3. Train a Word2Vec Model\n4. Visualize t-SNE representations of the most common words \n\nCredit: Some of the code was inspired by this awesome [NLP repo][1]. \n\n\n\n\n  [1]: https://github.com/rouseguy/DeepLearningNLP_Py","metadata":{"_cell_guid":"e8acc802-80ba-e4b0-403c-df40ce20cf20","_uuid":"e5fe6d38878391cfd64a79f6ace83d7663cfcfd6"}},{"cell_type":"code","outputs":[],"source":"import pandas as pd\npd.options.mode.chained_assignment = None \nimport numpy as np\nimport re\nimport nltk\n\nfrom gensim.models import word2vec\n\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndata = pd.read_csv('../input/train.csv').sample(50000, random_state=23)","metadata":{"_cell_guid":"327a2a48-c101-959c-af2d-cabd82276e65","_uuid":"d11607b121e544156f838efeb3df884520143e77","collapsed":true},"execution_count":null},{"cell_type":"code","outputs":[],"source":"STOP_WORDS = nltk.corpus.stopwords.words()\n\ndef clean_sentence(val):\n    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n    regex = re.compile('([^\\s\\w]|_)+')\n    sentence = regex.sub('', val).lower()\n    sentence = sentence.split(\" \")\n    \n    for word in list(sentence):\n        if word in STOP_WORDS:\n            sentence.remove(word)  \n            \n    sentence = \" \".join(sentence)\n    return sentence\n\ndef clean_dataframe(data):\n    \"drop nans, then apply 'clean_sentence' function to question1 and 2\"\n    data = data.dropna(how=\"any\")\n    \n    for col in ['question1', 'question2']:\n        data[col] = data[col].apply(clean_sentence)\n    \n    return data\n\ndata = clean_dataframe(data)\ndata.head(5)","metadata":{"_cell_guid":"c5d7458b-d380-8af7-13cf-5ed65fb42a83","_uuid":"6b42983b5c826eb4ec298ca03d3c5b9da29fdadf","collapsed":true},"execution_count":null},{"cell_type":"code","outputs":[],"source":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for col in ['question1', 'question2']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(data)        \ncorpus[0:2]","metadata":{"_cell_guid":"e72326d7-e707-d4e9-928a-519a9193bfc5","_uuid":"6c66b614038c49b03428c4b44e717cc4f04af63f","collapsed":true},"execution_count":null},{"cell_type":"markdown","source":"# Word 2 Vec\n\nThe Word to Vec model produces a vocabulary, with each word being represented by an n-dimensional numpy array (100 values in this example)","metadata":{"_cell_guid":"c652ad03-be65-f4e6-0afd-02c237449b43","_uuid":"ff8af5f446f4cf4c941953bf115476075d60323f"}},{"cell_type":"code","outputs":[],"source":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\nmodel.wv['trump']","metadata":{"_cell_guid":"ee9f9d57-5b3a-16c0-916f-169ef6d7b920","_uuid":"f4e3863c7d0111533a9e35eddc0048c7c324471c","collapsed":true},"execution_count":null},{"cell_type":"code","outputs":[],"source":"def tsne_plot(model):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 16)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","metadata":{"_cell_guid":"4512c76e-f4da-c793-be73-5b18b5bb70e9","_uuid":"86fdd32e2780ad05e7c487eb8d8f7b5956a6e5fc","collapsed":true},"execution_count":null},{"cell_type":"code","outputs":[],"source":"tsne_plot(model)","metadata":{"_cell_guid":"19ec33d2-5160-6556-c8da-a5a53316619a","_uuid":"0d95120d425dab64bd612d96bfe806565fc3e332","collapsed":true},"execution_count":null},{"cell_type":"code","outputs":[],"source":"# A more selective model\nmodel = word2vec.Word2Vec(corpus, size=100, window=20, min_count=500, workers=4)\ntsne_plot(model)","metadata":{"_cell_guid":"b5ffb880-585d-6ea8-51a5-a6351ea2ff20","_uuid":"d8a2dd5e15caf6279ba8e693acd4add1f5a1cbab","collapsed":true},"execution_count":null},{"cell_type":"code","outputs":[],"source":"# A less selective model\nmodel = word2vec.Word2Vec(corpus, size=100, window=20, min_count=100, workers=4)\ntsne_plot(model)","metadata":{"_cell_guid":"9f64e341-1967-617f-4004-ef7c6d109277","_uuid":"e02d3b2895ce982be120f9352877e19741d4716e","collapsed":true},"execution_count":null},{"cell_type":"markdown","source":"# It's Becoming Hard to Read\n\nWith a dataset this large, its difficult to make an easy-to-read TSNE visualization. What you can do is use the model to look up the most similar words from any given point. ","metadata":{"_cell_guid":"2ba89a55-30b7-15ea-c571-9e402e1c03d2","_uuid":"84f2710029e399b8fe56710e48ac5b84098d969e"}},{"cell_type":"code","outputs":[],"source":"model.most_similar('trump')","metadata":{"_cell_guid":"109ae353-5679-6f7a-74f6-ae13d7042639","_uuid":"bc731814739cc9f3922387cd51ab1f7b8961255d","collapsed":true},"execution_count":null},{"cell_type":"code","outputs":[],"source":"model.most_similar('universe')","metadata":{"_cell_guid":"67a0844e-83d6-22ab-a89b-ae15c19860a8","_uuid":"3e53277a9ee97327e12c375893a63852471b3a8a","collapsed":true},"execution_count":null},{"cell_type":"markdown","source":"# The End\n\nGood luck!","metadata":{"_cell_guid":"a88070c7-87cd-0daa-61f7-b2d5ab1ca6ad","_uuid":"a16278a58aa7edd5c00bf2084a2b39c30f42006a"}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","mimetype":"text/x-python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python"},"_is_fork":false,"_change_revision":0},"nbformat":4}