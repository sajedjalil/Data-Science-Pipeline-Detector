{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Quora Duplicate Questions Detection\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn import model_selection","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nDIR = '/kaggle/input'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!unzip /kaggle/input/quora-question-pairs/train.csv.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"train.csv\")\ndf['kfold'] = -1\n\ndf = df.sample(frac=1.,random_state=2021).reset_index(drop=True)\n\nkf = model_selection.StratifiedKFold(n_splits=5, shuffle=False)\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X=df, y = df.is_duplicate.values)):\n    print(len(train_idx), len(val_idx))\n    df.loc[val_idx, 'kfold'] = fold","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fix`nan` in `train`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.question1.isna().sum(), df.question2.isna().sum(), df.question1.isnull().sum(), df.question2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"train_folds.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fold = pd.read_csv(\"train_folds.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check sentence length distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sent_len(input_str: str):\n    input_str = str(input_str)\n    return len(input_str.strip().split(\" \"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fold[\"question1_len\"] = list(map(sent_len, df_fold.question1.values.tolist()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fold[\"question2_len\"] = list(map(sent_len, df_fold.question2.values.tolist()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_fold.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fold.question1_len.plot.hist(bins=20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fold.question2_len.plot.hist(bins=20);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Universal Sentence Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow_hub as hub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = embed([\n    \"The quick brown fox jumps over the lazy dog.\",\n    \"I am a sentence for which I would like to get its embedding\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensure reproducibility"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reproducing same results\nSEED = 2021\n\n#Torch\ntorch.manual_seed(SEED)\n\n#Cuda algorithms\ntorch.backends.cudnn.deterministic = True  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 256","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Design Train Dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuoraTrainData(Dataset):\n    def __init__(self, df: pd.DataFrame):\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        q1 = self.df.iloc[idx].question1\n        q2 = self.df.iloc[idx].question2\n        label = self.df.iloc[idx].is_duplicate\n        \n        return {\"q1\": q1, \"q2\": q2, \"label\": label}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nFOLD_MAPPPING = {\n    0: [1, 2, 3, 4],\n    1: [0, 2, 3, 4],\n    2: [0, 1, 3, 4],\n    3: [0, 1, 2, 4],\n    4: [0, 1, 2, 3]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLD = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = df_fold[df_fold.kfold.isin(FOLD_MAPPPING.get(FOLD))].reset_index(drop=True)\nvalid_df = df_fold[df_fold.kfold==FOLD].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, valid_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"valid_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = QuoraTrainData(train_df)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_dataset = QuoraTrainData(valid_df)\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check train dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5th example\ntrain_dataset.__getitem__(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_dataset.__getitem__(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check train dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iter = iter(train_loader)\nres = train_iter.next()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Design Model"},{"metadata":{},"cell_type":"markdown","source":"## Simple multilayer perceptron - no nonlinearity "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class IsDuplicate(nn.Module):\n    def __init__(self, output_dim: int, emb_dim: int, hid_dim=512):\n        \"\"\"Simple MultiLayerPerceptron\n            Linear model\n        \"\"\"\n        super().__init__()\n        #dense layer\n        self.fc1 = nn.Linear(emb_dim * 2, hid_dim)\n        \n        self.fc2 = nn.Linear(hid_dim, output_dim)\n        \n        #activation function\n        self.act = nn.Sigmoid()\n        \n    def forward(self, text1:[str], text2:[str]):\n        \"\"\"\n        text1: list of strings from question1, len: batch_size\n        text2: list of strings from question2, len: batch_size\n        \"\"\"\n        \n        emb1 = embed(text1)\n        e1 = torch.from_numpy(emb1.numpy()).to(device)\n        # e1.size()\n        \n        emb2 = embed(text2)\n        e2 = torch.from_numpy(emb2.numpy()).to(device)\n        # e2.size()\n        \n        hidden = torch.cat((e1, e2), dim = 1)\n        \n        #hidden = [batch size, hid dim * num directions]\n        dense_outputs1=self.fc1(hidden)\n        dense_outputs2=self.fc2(dense_outputs1)\n\n        #Final activation function\n        outputs=self.act(dense_outputs2)\n        \n        return outputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding deeper non-linear model\n\n- The original architecture idea came from [here](https://www.linkedin.com/pulse/duplicate-quora-question-abhishek-thakur/). But the original architecture is heavily simplified to the below structure with the use of transfer learning using `Universal Sentence Encoder`\n\n<center>\n<img src='https://raw.githubusercontent.com/msank00/Kaggle_202101_Quora_Duplicate_Questions/main/images/NN_Architecture.jpg' width='400'>    \n</center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class IsDuplicateAdv(nn.Module):\n    def __init__(self, output_dim: int, emb_dim: int, hid_dim=512):\n        \"\"\"Non Linear model\n        \"\"\"\n        super().__init__()\n        #dense layer\n        \n        self.batchnorm1 = nn.BatchNorm1d(emb_dim * 2)\n        self.dropout = nn.Dropout(p=0.2)\n        self.nonlinear = nn.PReLU()\n        \n        self.fc1 = nn.Linear(emb_dim * 2, hid_dim)\n        self.batchnorm2 = nn.BatchNorm1d(hid_dim)\n        self.fc2 = nn.Linear(hid_dim, output_dim)\n        \n        #activation function\n        self.act = nn.Sigmoid()\n        \n    def forward(self, text1:[str], text2:[str]):\n        \"\"\"\n        text1: list of strings from question1, len: batch_size\n        text2: list of strings from question2, len: batch_size\n        \"\"\"\n        \n        emb1 = embed(text1)\n        e1 = torch.from_numpy(emb1.numpy()).to(device)\n        \n        emb2 = embed(text2)\n        e2 = torch.from_numpy(emb2.numpy()).to(device)\n        \n        # merged\n        x = torch.cat((e1, e2), dim = 1)\n        x = self.batchnorm1(x)\n        \n        \n        x=self.fc1(x)\n        x = self.nonlinear(x)\n        x = self.dropout(x)\n        x = self.batchnorm2(x)\n        \n        x=self.fc2(x)\n\n        #Final activation function\n        outputs=self.act(x)\n        \n        return outputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = IsDuplicateAdv(output_dim=2, emb_dim=512).to(device)\n\nprob = model(text1= res['q1'], text2 = res['q2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\n\ndef count_parameters(model):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad: continue\n        param = parameter.numel()\n        table.add_row([name, param])\n        total_params+=param\n    print(table)\n    print(f\"Total Trainable Params: {total_params}\")\n    return total_params\n    \ncount_parameters(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\n#define optimizer and loss\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.BCELoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# `BCEWithLogitLoss()` more stable than `Sigmoid()` + `BCELoss()`. Why?\n\n> `Sigmoid()` + `BCELoss()` = `BCEWithLogitLoss()`\n\n\n\n- [Ans](https://discuss.pytorch.org/t/bce-loss-vs-cross-entropy/97437/2)\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#define metric\ndef binary_accuracy(preds, y):\n    #round predictions to the closest integer\n    rounded_preds = torch.argmax(preds, dim=1)\n    \n    correct = (rounded_preds == y).float() \n    acc = correct.sum() / len(correct)\n    return acc\n    \n#push to cuda if available\nmodel = model.to(device)\ncriterion = criterion.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def train(model, train_data_loader, optimizer, criterion):\n    \n    #initialize every epoch \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    #set the model in training phase\n    model.train()  \n    \n    n_batch = len(train_data_loader)\n    for i, batch in enumerate(train_data_loader):\n        \n        #resets the gradients after every batch\n        optimizer.zero_grad()   \n        \n        #retrieve text and no. of words\n        q1, q2, label = batch['q1'], batch['q2'], batch['label'] \n        \n        label = label.to(device)\n        #convert to 1D tensor\n        predictions = model(q1, q2)\n        \n        #print(predictions.dtype)\n        #print(label.float().dtype)\n        #compute the loss\n        loss = criterion(predictions[:,1], label.float())        \n        \n        #compute the binary accuracy\n        acc = binary_accuracy(predictions, label.float())   \n        \n        #backpropage the loss and compute the gradients\n        loss.backward()       \n        \n        #update the weights\n        optimizer.step()      \n        \n        #loss and accuracy\n        batch_loss = loss.item()\n        batch_acc = acc.item() \n        epoch_loss += batch_loss  \n        epoch_acc +=  batch_acc  \n        if i % 100 == 0:\n            print(f\"\\t\\t\\t > trn batch_no: {i}/{n_batch}, batch_loss: {np.round(batch_loss, 4)}, batch_acc: {np.round(batch_acc, 4)}\")\n        \n    return epoch_loss / len(train_data_loader), epoch_acc / len(train_data_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def evaluate(model, valid_data_loader, criterion):\n    \n    #initialize every epoch\n    epoch_loss = 0\n    epoch_acc = 0\n\n    #deactivating dropout layers\n    model.eval()\n    \n    #deactivates autograd\n    n_batch = len(valid_data_loader)\n    with torch.no_grad():\n    \n        for i, batch in enumerate(valid_data_loader):\n        \n            #retrieve question pair and labels\n            q1, q2, label = batch['q1'], batch['q2'], batch['label']\n            label = label.to(device)\n            #convert to 1d tensor\n            predictions = model(q1, q2)\n            \n            #compute loss and accuracy\n            \n            loss = criterion(predictions[:,1], label.float())\n            acc = binary_accuracy(predictions, label.float())\n            \n            #loss and accuracy\n            batch_loss = loss.item()\n            batch_acc = acc.item() \n            epoch_loss += batch_loss  \n            epoch_acc +=  batch_acc \n            if i % 50 == 0:\n                print(f\"\\t\\t\\t > val batch_no: {i}/{n_batch}, batch_loss: {np.round(batch_loss,4)}, batch_acc: {np.round(batch_acc, 4)}\")\n            \n        \n    return epoch_loss / len(valid_data_loader), epoch_acc / len(valid_data_loader)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"N_EPOCHS = 5\nbest_valid_loss = float('inf')\n\nhistory = {\n    \"train_loss\": [],\n    \"train_acc\": [],\n    \"valid_loss\": [],\n    \"valid_acc\": []\n}\n\nfor epoch in range(N_EPOCHS):\n     \n    #train the model\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    \n    #evaluate the model\n    valid_loss, valid_acc = evaluate(model, valid_loader, criterion)\n    \n    train_loss = np.round(train_loss,4)\n    train_acc = np.round(train_acc, 4)\n    valid_loss = np.round(valid_loss, 4)\n    valid_acc = np.round(valid_acc, 4)\n    \n    history[\"train_loss\"].append(train_loss)\n    history[\"train_acc\"].append(train_acc)\n    history[\"valid_loss\"].append(valid_loss)\n    history[\"valid_acc\"].append(valid_acc)\n    \n    #save the best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'saved_weights.pt')\n    \n    print(f'Epoch: {epoch+1}/{N_EPOCHS} \\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n    print(f'\\t\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot training performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.plot(history[\"train_loss\"], label=\"train\")\nplt.plot(history[\"valid_loss\"], label=\"val\")\nplt.title(\"Loss vs Epoch\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.grid(alpha=0.3)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.plot(history[\"train_acc\"], label=\"train\")\nplt.plot(history[\"valid_acc\"], label=\"val\")\nplt.title(\"Accuracy vs Epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.grid(alpha=0.3)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}