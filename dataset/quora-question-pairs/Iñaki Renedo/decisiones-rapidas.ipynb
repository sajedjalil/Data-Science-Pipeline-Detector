{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"cac1babc-e217-b7e9-0e65-8ff2f95074b2"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c8e4764-af57-dfca-7bb8-c6253085fa6f"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\n\nstops = set(stopwords.words(\"english\"))\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\npal = sns.color_palette()\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f12bbcf8-83e9-3bee-b388-5581576d8a89"},"outputs":[],"source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"643def06-8ba1-cb2d-be17-9460dddf4f56"},"outputs":[],"source":"train_qs = pd.Series(df_train['question1'].tolist() + df_train['question2'].tolist()).astype(str)\ntest_qs = pd.Series(df_test['question1'].tolist() + df_test['question2'].tolist()).astype(str)\nq1 = pd.Series(df_train['question1'][0]) #para sacar la primera pregunta de question1\nprint(q1)\ndist_train = train_qs.apply(len)\ndist_test = test_qs.apply(len)\n#plt.figure(figsize=(15, 10))\n#plt.hist(dist_train, bins=200, range=[0, 200], color=pal[2], normed=True, label='train')\n#plt.hist(dist_test, bins=200, range=[0, 200], color=pal[1], normed=True, alpha=0.5, label='test')\n#plt.title('Normalised histogram of character count in questions', fontsize=15)\n#plt.legend()\n#plt.xlabel('Number of characters', fontsize=15)\n#plt.ylabel('Probability', fontsize=15)\n\n#print('mean-train {:.2f} std-train {:.2f} mean-test {:.2f} std-test {:.2f} max-train {:.2f} max-test {:.2f}'.format(dist_train.mean(), \n#                          dist_train.std(), dist_test.mean(), dist_test.std(), dist_train.max(), dist_test.max()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"226fc83b-f22f-bb6b-dfe6-1232046b55f6"},"outputs":[],"source":"from nltk.corpus import stopwords\n\nstops = set(stopwords.words(\"english\"))\n\ndef word_match_share(row):\n    q1words = {}\n    q2words = {}\n    for word in str(row['question1']).lower().split():\n        if word not in stops:\n            q1words[word] = 1\n    for word in str(row['question2']).lower().split():\n        if word not in stops:\n            q2words[word] = 1\n    if len(q1words) == 0 or len(q2words) == 0:\n        # The computer-generated chaff includes a few questions that are nothing but stopwords\n        return 0\n    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n    return R\n#print(stops)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6dc42c6-a54b-6435-7696-f751aa1d6f3f"},"outputs":[],"source":"train_word_match = df_train.apply(word_match_share, axis=1, raw=True)\ndecision = {} #tabla con los datos estimados, duplicados o no.\nacierto =  {}#tabla para porcentajes de aciertos en la estimación\nduplicados = df_train['is_duplicate'] #tabla con los datos de pares duplicados\nlen(df_train)\n#print(duplicados)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"060120e1-d565-e4dd-b17e-04cfb6ff704c"},"outputs":[],"source":"for index in range(len(train_word_match)):\n    if (train_word_match[index] > 0.35):\n        decision[index] = 1\n    else:\n        decision[index] = 0\n#print (decision) \ncounter = 0\nfor index in range(len(train_word_match)):\n    if (decision[index] == duplicados[index]):\n        acierto[index]=1\n        counter = counter +1\n    else:\n        acierto[index]=0\n        \nporcentaje = (counter*100)/404290\nprint(porcentaje)\nprint(len(decision))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"87047d78-ab7c-9c15-e7b5-9fd96c11e14d"},"outputs":[],"source":"from collections import Counter\n\n# If a word appears only once, we ignore it completely (likely a typo)\n# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\ndef get_weight(count, eps=10000, min_count=2):\n    if count < min_count:\n        return 0\n    else:\n        return 1 / (count + eps)\n\neps = 5000 \nwords = (\" \".join(train_qs)).lower().split()\nwords_q1 = (\" \".join(q1)).lower().split()\nfor w in range(len(words_q1)):\n    print(words_q1[w])\n \n\n    \ncounts = Counter(words)\nweights = {word: get_weight(count) for word, count in counts.items()}#estudiar bien que hace"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f59cf23-fe89-f138-d82b-beabafaa21c0"},"outputs":[],"source":"#df_train['q1_n_words'] = df_train['question1'].apply(lambda row: len(row.split(\" \")))\n#df_train['q2_n_words'] = df_train['question2'].apply(lambda row: len(row.split(\" \")))\n\nstops = set(stopwords.words(\"english\"))\nratiow = []\n\nfor i in range(404290):\n    n_words = 0\n    q1 = pd.Series(df_train['question1'][i]).astype(str) #para sacar la primera pregunta de question1\n    q2 = pd.Series(df_train['question2'][i]).astype(str)\n    words_q1 = (\" \".join(q1)).lower().split()\n    words_q2 = (\" \".join(q2)).lower().split()\n    media = (len(words_q1) + len(words_q2))/2\n    minimo = min(len(words_q1), len(words_q2))\n    for w1 in words_q1:\n        for w2 in words_q2:\n            if (w1==w2) and (w1 not in stops):\n                n_words = n_words + 1\n    #print(n_words)            \n    r = n_words/minimo\n    ratiow.append(r)\n\nfor w in range(20):\n    print(ratiow[w])\n    \n#print(len(ratiow))                \ndf_train.head()                                   \n                "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"971301fe-9cf8-dca2-64c6-2cb4e3476dee"},"outputs":[],"source":"stops = set(stopwords.words(\"english\"))\n\n\ndef same_word_ratio(row):\n    \n    ratiow = []\n    for i in range(404290):\n        n_words = 0\n        q1 = pd.Series(row['question1'][i]).astype(str) #para sacar la primera pregunta de question1\n        q2 = pd.Series(row['question2'][i]).astype(str)\n        words_q1 = (\" \".join(q1)).lower().split()\n        words_q2 = (\" \".join(q2)).lower().split()\n        media = (len(words_q1) + len(words_q2))/2\n        minimo = min(len(words_q1), len(words_q2))\n        for w1 in words_q1:\n            for w2 in words_q2:\n                if (w1==w2) and (w1 not in stops):\n                    n_words = n_words + 1\n        #print(n_words)            \n        r = n_words/minimo\n        ratiow.append(r)\n    return ratiow\n    \n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34d23256-c121-bae4-fa30-11ca1806aa89"},"outputs":[],"source":"decision2 = {} #tabla con los datos estimados, duplicados o no.\n\nacierto2 =  {} #tabla para porcentajes de aciertos en la estimación\nduplicados2 = df_train['is_duplicate'] #tabla con los datos de pares duplicados\n#print(duplicados)\nratiow = same_word_ratio(df_train)#llamada a la funcion hecha\n\n\nfor index in range(len(ratiow)):\n    if (ratiow[index] > 0.25):\n        decision2[index] = 1\n    else:\n        decision2[index] = 0\n#print (decision) \ncounter = 0\nfor index in range(len(ratiow)):\n    if (decision2[index] == duplicados2[index]):\n        acierto2[index]=1\n        counter = counter +1\n    else:\n        acierto2[index]=0\n        \nporcentaje = (counter*100)/404290 \nprint(porcentaje)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4937922-35c1-f4de-9781-8760610b5904"},"outputs":[],"source":"decision2_test = {}\nratiow_test = same_word_ratio(df_test)\n\nfor index in range(len(ratiow_test)):\n    if (ratiow_test[index] > 0.25):\n        decision2_test[index] = 1\n    else:\n        decision2_test[index] = 0\n\nfor w in range(20):\n    print(decision2_test[w])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62fb1c51-b114-b91e-f9d2-41ece1ebf262"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f1cbe90-aa52-ca2f-f669-7dee88c3e5d7"},"outputs":[],"source":"print('Most common words and weights: \\n')\nprint(sorted(weights.items(), key=lambda x: x[1] if x[1] > 0 else 9999)[:10])\nprint('\\nLeast common words and weights: ')\n(sorted(weights.items(), key=lambda x: x[1], reverse=True)[:10])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c578dd54-c11a-825e-5682-c3671d06b814"},"outputs":[],"source":"def tfidf_word_match_share(row):\n    q1words = {}\n    q2words = {}\n    for word in str(row['question1']).lower().split():\n        if word not in stops:\n            q1words[word] = 1\n    for word in str(row['question2']).lower().split():\n        if word not in stops:\n            q2words[word] = 1\n    if len(q1words) == 0 or len(q2words) == 0:\n        # The computer-generated chaff includes a few questions that are nothing but stopwords\n        return 0\n    \n    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n    \n    R = np.sum(shared_weights) / np.sum(total_weights)\n    return R"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62730395-0912-eee2-ab2b-7b0da1cb15fb"},"outputs":[],"source":"tfidf_train_word_match = df_train.apply(tfidf_word_match_share, axis=1, raw=True)\ndecision_tfidf = {} #tabla con los datos estimados, duplicados o no.\nacierto_tfidf =  {} #tabla para porcentajes de aciertos en la estimación\nduplicados_tfidf = df_train['is_duplicate'] #tabla con los datos de pares duplicados\nprint(duplicados_tfidf)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b82c473f-0b4a-5521-8de3-30aaa22e84d2"},"outputs":[],"source":"for index in range(len(tfidf_train_word_match)):\n    if (tfidf_train_word_match[index] > 0.35):\n        decision_tfidf[index] = 1\n    else:\n        decision_tfidf[index] = 0\n#print (decision_tfidf) \n\ncounter = 0\nfor index in range(len(tfidf_train_word_match)):\n    if (decision_tfidf[index] == duplicados_tfidf[index]):\n        acierto_tfidf[index]=1\n        counter = counter +1\n    else:\n        acierto_tfidf[index]=0\n        \nporcentaje_tfidf = (counter*100)/404265 \nprint(porcentaje_tfidf)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fc0d859-2b22-60e0-5669-22ccbdfee7bf"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a693f760-4548-5e9d-bed0-fec1449ab23a"},"outputs":[],"source":"word_match_test = df_test.apply(word_match_share, axis=1, raw=True)\ndecision_test = {} #tabla con los datos estimados, duplicados o no.\n#duplicados = df_train['is_duplicate'] #tabla con los datos de pares duplicados\nlen(df_test)\n#print(duplicados)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c36d2fb-79f2-16ec-f9f2-b073914239ac"},"outputs":[],"source":"for index in range(len(word_match_test)):\n    if (word_match_test[index] > 0.35):\n        decision_test[index] = 1\n    else:\n        decision_test[index] = 0\n#print (decision) \nfor w in range(20):\n    print(decision_test[w])\nlen(decision_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9093ae2-1813-8198-9073-de8ab9e9e51b"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2457179-179f-8595-227c-a87384a400c2"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3e96e96-e70a-7cfe-3cde-2eb7b09a05d8"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"caef5022-53f6-0884-4696-eba74dadee98"},"outputs":[],"source":"submission = pd.DataFrame({'is_duplicate': decision2_test, 'test_id': df_test['test_id']})\nsubmission.to_csv(\"submission.csv\", index=False)\n#sub = pd.DataFrame()\n#sub['test_id'] = df_test['test_id']\n#sub['is_duplicate'] = decision_test\n#sub.to_csv('simple_counw.csv', index=False)\nsubmission.head()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}