{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"57a9cc6d-aa2b-d962-98af-5284227e32cb"},"source":"**Some context to start with!**\n-------------------------------\n\n\nPageRank is an ingenious algorithm, developed by *Larry and Sergey*, arguably the biggest game-changer in the this world that we live in! Pagerank basically ranks the nodes in a graph structure, based on the linkages between them. An edge shared with an important node makes you important as well, a link with the spam node makes you spam too!\n\n## Why here? ##\n\nIn our context, every node is a question in our dataset and an edge represents a question pair. More often than not, an edge is shared by somehow related questions(topically), but may not be semantically equivalent -- This edge is however useful to visualize clusters of topics, and importance of certain nodes.\n\nThus, if a question is paired with a rather famous(higher pageranked) question, the question becomes relevant in itself.\n\nNote: The implementation of a Pagerank in this context was inspired by this [discussion][1] from Krzysztof Dziedzic\n\n\n  [1]: https://www.kaggle.com/c/quora-question-pairs/discussion/33664"},{"cell_type":"markdown","metadata":{"_cell_guid":"85e87516-71f9-1a06-470a-0df0ea59f357"},"source":"Let's get started, shall we!\n----------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7aa87a8c-2a7f-05fc-ffd1-d8ed50f397eb"},"outputs":[],"source":"import pandas as pd\n\ndf_train = pd.read_csv('../input/train.csv').fillna(\"\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"368f8c29-3848-0b2c-0486-50026729e10a"},"source":"The small function below computes a dictionary of questions, where each key-value pair is a question and its neighboring questions(in a list). This is necessary before we get along with calculating each question's pagerank! "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f68fb2d-78ed-2546-4b02-842d5adde948"},"outputs":[],"source":"#Generating a graph of Questions and their neighbors\ndef generate_qid_graph_table(row):\n\n    hash_key1 = row[\"qid1\"]\n    hash_key2 = row[\"qid2\"]\n        \n    qid_graph.setdefault(hash_key1, []).append(hash_key2)\n    qid_graph.setdefault(hash_key2, []).append(hash_key1)\n\nqid_graph = {}\ndf_train.apply(generate_qid_graph_table, axis = 1); #You should apply this on df_test too. Avoiding here on the kernel."},{"cell_type":"markdown","metadata":{"_cell_guid":"e28bd007-536f-178d-6f86-4f901befc77e"},"source":"## Cut to the chase! ##\n\nWithout getting into a lot of details, pagerank of a node is defined as the sum of a certain ratio of all its neighbors -- a complete dependence on adjacent vertices. The ratio is basically, the pagerank of the neighbor divided by the degree of the neighbor(edges incident on it). \n\nMathematically speaking,\nPR(n) = PR(n1)/num_neighbors(n1) + ... + PR(n_last)/num_neighbors(n_last)\n\nHowever, a damping factor is also induced in this formula, so as to account for how often the edge is to be taken(within the context of a random surfer on the web)\n\nThus, \n**PR(n) = (1-d)/N + d*(PR(n1)/num_neighbors(n1) + ... + PR(n_last)/num_neighbors(n_last))**\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f3d7aa53-2b4a-1165-fdec-58c5a5ac15fb"},"outputs":[],"source":"def pagerank():\n\n    MAX_ITER = 20 #Let me know if you find an optimal iteration number!\n    d = 0.85\n    \n    #Initializing -- every node gets a uniform value!\n    pagerank_dict = {i:1/len(qid_graph) for i in qid_graph}\n    num_nodes = len(pagerank_dict)\n    \n    for iter in range(0, MAX_ITER):\n        \n        for node in qid_graph:    \n            local_pr = 0\n            \n            for neighbor in qid_graph[node]:\n                local_pr += pagerank_dict[neighbor]/len(qid_graph[neighbor])\n            \n            pagerank_dict[node] = (1-d)/num_nodes + d*local_pr\n\n    return pagerank_dict\n\npagerank_dict = pagerank()"},{"cell_type":"markdown","metadata":{"_cell_guid":"35f7e41f-9d47-3f19-c3f8-201e9d937190"},"source":"We initially begin with a uniform pagerank value to all nodes, and with every iteration the pageranks begin to converge. You can also introduce a minimum difference between iterations to ensure convergence."},{"cell_type":"markdown","metadata":{"_cell_guid":"98e46d71-248a-a227-2096-a2d823cf7987"},"source":"## Getting the pageranks ##\n\nFinally, a getter function to concatenate the features with the rest of the dataframe."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a25a4ce-199e-a6bf-6502-e2efa53b321e"},"outputs":[],"source":"def get_pagerank_value(row):\n    return pd.Series({\n        \"q1_pr\": pagerank_dict[row[\"qid1\"]],\n        \"q2_pr\": pagerank_dict[row[\"qid2\"]]\n    })\n\npagerank_feats_train = df_train.apply(get_pagerank_value, axis = 1);"},{"cell_type":"markdown","metadata":{"_cell_guid":"6f34dac5-0a79-297a-6425-4b63cd6b0509"},"source":"## Result ##\n\nThese features gave me a slight 0.002 bump on a 100-nround xgboost, not a magic feature by any means ;)\n\nFork away :)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}