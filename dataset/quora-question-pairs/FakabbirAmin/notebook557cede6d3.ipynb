{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ded48a8c-937a-f15a-3ff6-c66cf93231bd"},"source":"Quora Question Pair Kernl"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca8035f1-3738-0b46-dc46-a0df8cc2fd37"},"outputs":[],"source":"import time\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport networkx as nx\n\nfrom sklearn import model_selection\nfrom sklearn import linear_model\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nmatplotlib.style.use('fivethirtyeight')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9b5803a0-c8de-4ff8-1f48-b2a1e0638f41"},"outputs":[],"source":"trainDF = pd.read_csv('../input/train.csv')\ntrainDF = trainDF.dropna(how=\"any\").reset_index(drop=True)\n\ntrainDF.ix[:7,3:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4b101dc9-87ba-d2c4-186e-f76d4ddc73ca"},"outputs":[],"source":"#%% create dictionary and extract BOW features from questions\n\nfeatureExtractionStartTime = time.time()\n\nmaxNumFeatures = 300\n\n# bag of letter sequences (chars)\nBagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=1000, max_features=maxNumFeatures, \n                                      analyzer='char', ngram_range=(1,2), \n                                      binary=True, lowercase=True)\n# bag of words\n#BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=10, max_features=maxNumFeatures, \n#                                      analyzer='word', ngram_range=(1,6), stop_words='english', \n#                                      binary=True, lowercase=True)\n\nBagOfWordsExtractor.fit(pd.concat((trainDF.ix[:,'question1'],trainDF.ix[:,'question2'])).unique())\n\ntrainQuestion1_BOW_rep = BagOfWordsExtractor.transform(trainDF.ix[:,'question1'])\ntrainQuestion2_BOW_rep = BagOfWordsExtractor.transform(trainDF.ix[:,'question2'])\nlables = np.array(trainDF.ix[:,'is_duplicate'])\n\nfeatureExtractionDurationInMinutes = (time.time()-featureExtractionStartTime)/60.0\nprint(\"feature extraction took %.2f minutes\" % (featureExtractionDurationInMinutes))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f70ae54-72c7-9807-cb3f-909a9d142e87"},"outputs":[],"source":"#%% prefrom cross validation\n\ncrossValidationStartTime = time.time()\n\nnumCVSplits = 8\nnumSplitsToBreakAfter = 2\n\nX = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int)\n#X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int) + \\\n#      trainQuestion1_BOW_rep.multiply(trainQuestion2_BOW_rep)\ny = lables\n\nlogisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag')\n\nlogRegAccuracy = []\nlogRegLogLoss = []\nlogRegAUC = []\n\nprint('---------------------------------------------')\nstratifiedCV = model_selection.StratifiedKFold(n_splits=numCVSplits, random_state=2)\nfor k, (trainInds, validInds) in enumerate(stratifiedCV.split(X, y)):\n    foldTrainingStartTime = time.time()\n\n    X_train_cv = X[trainInds,:]\n    X_valid_cv = X[validInds,:]\n\n    y_train_cv = y[trainInds]\n    y_valid_cv = y[validInds]\n\n    logisticRegressor.fit(X_train_cv, y_train_cv)\n\n    y_train_hat =  logisticRegressor.predict_proba(X_train_cv)[:,1]\n    y_valid_hat =  logisticRegressor.predict_proba(X_valid_cv)[:,1]\n\n    logRegAccuracy.append(accuracy_score(y_valid_cv, y_valid_hat > 0.5))\n    logRegLogLoss.append(log_loss(y_valid_cv, y_valid_hat))\n    logRegAUC.append(roc_auc_score(y_valid_cv, y_valid_hat))\n    \n    foldTrainingDurationInMinutes = (time.time()-foldTrainingStartTime)/60.0\n    print('fold %d took %.2f minutes: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (k+1,\n             foldTrainingDurationInMinutes, logRegAccuracy[-1],logRegLogLoss[-1],logRegAUC[-1]))\n\n    if (k+1) >= numSplitsToBreakAfter:\n        break\n\n\ncrossValidationDurationInMinutes = (time.time()-crossValidationStartTime)/60.0\n\nprint('---------------------------------------------')\nprint('cross validation took %.2f minutes' % (crossValidationDurationInMinutes))\nprint('mean CV: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (np.array(logRegAccuracy).mean(),\n                                                                 np.array(logRegLogLoss).mean(),\n                                                                 np.array(logRegAUC).mean()))\nprint('---------------------------------------------')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6004a132-9cb3-8485-907b-eb49aaae8ae6"},"outputs":[],"source":"#%% show prediction distribution and \"feature importance\"\n\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10,10)\n\nplt.figure(); \nsns.kdeplot(y_valid_hat[y_valid_cv==0], shade=True, color=\"b\", bw=0.01)\nsns.kdeplot(y_valid_hat[y_valid_cv==1], shade=True, color=\"g\", bw=0.01)\nplt.legend(['non duplicate','duplicate'],fontsize=24)\nplt.title('Validation Accuracy = %.3f, Log Loss = %.4f, AUC = %.3f' %(logRegAccuracy[-1],\n                                                                      logRegLogLoss[-1],\n                                                                      logRegAUC[-1]))\nplt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n\n\nnumFeaturesToShow = 30\n\nsortedCoeffients = np.sort(logisticRegressor.coef_)[0]\nfeatureNames = BagOfWordsExtractor.get_feature_names()\nsortedFeatureNames = [featureNames[x] for x in list(np.argsort(logisticRegressor.coef_)[0])]\n\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10,12)\n\nplt.figure()\nplt.suptitle('Feature Importance',fontsize=24)\nax = plt.subplot(1,2,1); plt.title('top non duplicate predictors'); \nplt.xlabel('minus logistic regression coefficient')\nax.barh(range(numFeaturesToShow), -sortedCoeffients[:numFeaturesToShow][::-1], align='center'); \nplt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \nax.set_yticklabels(sortedFeatureNames[:numFeaturesToShow][::-1],fontsize=20)\n\nax = plt.subplot(1,2,2); plt.title('top duplicate predictors'); \nplt.xlabel('logistic regression coefficient')\nax.barh(range(numFeaturesToShow), sortedCoeffients[-numFeaturesToShow:], align='center'); \nplt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \nax.set_yticklabels(sortedFeatureNames[-numFeaturesToShow:],fontsize=20)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"085d6edd-3d70-83a0-0b06-40f26750d663"},"outputs":[],"source":"#%% train on full training data\n\ntrainingStartTime = time.time()\n\nlogisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag', \n                                                    class_weight={1: 0.46, 0: 1.32})\nlogisticRegressor.fit(X, y)\n\ntrainingDurationInMinutes = (time.time()-trainingStartTime)/60.0\nprint('full training took %.2f minutes' % (trainingDurationInMinutes))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98a61188-00b1-d3e3-76e9-d646d4a55595"},"outputs":[],"source":"#%% load test data, extract features and make predictions\n\ntestPredictionStartTime = time.time()\n\ntestDF = pd.read_csv('../input/test.csv')\ntestDF.ix[testDF['question1'].isnull(),['question1','question2']] = 'random empty question'\ntestDF.ix[testDF['question2'].isnull(),['question1','question2']] = 'random empty question'\n\ntestQuestion1_BOW_rep = BagOfWordsExtractor.transform(testDF.ix[:,'question1'])\ntestQuestion2_BOW_rep = BagOfWordsExtractor.transform(testDF.ix[:,'question2'])\n\nX_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int)\n#X_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int) + \\\n#           testQuestion1_BOW_rep.multiply(testQuestion2_BOW_rep)\n\n#testPredictions = logisticRegressor.predict_proba(X_test)[:,1]\n\n# quick fix to avoid memory errors\nseperators= [750000,1500000]\ntestPredictions1 = logisticRegressor.predict_proba(X_test[:seperators[0],:])[:,1]\ntestPredictions2 = logisticRegressor.predict_proba(X_test[seperators[0]:seperators[1],:])[:,1]\ntestPredictions3 = logisticRegressor.predict_proba(X_test[seperators[1]:,:])[:,1]\ntestPredictions = np.hstack((testPredictions1,testPredictions2,testPredictions3))\n\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (9,9)\n\nplt.figure(); \nplt.subplot(2,1,1); sns.kdeplot(y_valid_hat, shade=True, color=\"b\", bw=0.01); \nplt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\nplt.title('mean valid prediction = ' + str(np.mean(y_valid_hat)))\nplt.subplot(2,1,2); sns.kdeplot(testPredictions, shade=True, color=\"b\", bw=0.01);\nplt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"703e7a43-c3d5-ef3d-292c-268a3061619a"},"outputs":[],"source":"Bag = CountVectorizer(max_df=0.999, min_df=50, max_features=300, \n                                      analyzer='char', ngram_range=(1,2), \n                                      binary=True, lowercase=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"258f9ee9-8164-4699-4865-f7e1954c662a"},"outputs":[],"source":"Bag.fit(pd.concat((train.question1,train.question2)).unique())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8746cadc-48e7-2ae3-54bb-043a9349d031"},"outputs":[],"source":"question1 = Bag.transform(train['question1'])\nquestion2 = Bag.transform(train['question2'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7fffb19c-e08f-6937-ddc6-643b6eecc42b"},"outputs":[],"source":"question1 = question1.toarray()\nquestion2 = question2.toarray()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40bee776-ce63-1c7f-e30c-10869389877e"},"outputs":[],"source":"question1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7926589-8886-077d-e8df-adf2b483a371"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}