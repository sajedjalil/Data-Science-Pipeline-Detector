{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"426ff61f-037e-ee11-cc38-05f46d272b19"},"source":"Make my hand dirty with Quora challenge.This is my first competition.Please suggest me to do better and it if helpful then don't forget to up vote and leave you feedback  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9330326e-3de2-026d-168c-462e111ec625"},"outputs":[],"source":"#Import Initial Packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport gensim\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\nfrom nltk.stem import WordNetLemmatizer\nimport re \nfrom collections import namedtuple\nimport multiprocessing\nimport datetime\nimport os\n\ntokenizer = RegexpTokenizer(r'\\w+')\nstopwords = stopwords.words(\"english\")\nlemmatizer = WordNetLemmatizer()\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"39e85dac-c0ca-f3b6-b1d4-dc28fd247da9"},"source":"**Data Analysis and Natural Language processing**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"425f14f1-f0fd-f83a-c960-203c500da2f2"},"outputs":[],"source":"df_train = pd.read_csv(\"../input/train.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f83ba52b-7e69-864c-a8e6-05eb51742573"},"outputs":[],"source":"df_train.head(3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be8486b3-6739-21b2-d250-59ebd3fd8aec"},"outputs":[],"source":"df_train_set1 = df_train[[\"qid1\",\"question1\"]]\ndf_train_set2 = df_train[[\"qid2\",\"question2\"]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d23772d5-e04b-9c27-08bb-ebcd1a980c03"},"outputs":[],"source":"df_train_set1.columns = [\"qid\",\"question\"]\ndf_train_set2.columns =[\"qid\",\"question\"]\ndf_train_set = pd.concat([df_train_set1,df_train_set2],axis=0)\nprint(\"df_train_set_1 :\",df_train_set1.shape)\nprint(\"df_train_set_2 :\",df_train_set1.shape)\nprint(\"df_train_set :\",df_train_set.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e1fcaf7-0dbe-bb22-af75-e2fa266b258a"},"outputs":[],"source":"df_train_set1.head(3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7275c7d-25b0-ccf4-dc47-417330d7fce5"},"outputs":[],"source":"df_train_set2.head(3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ffbed50-0160-6c80-ccc5-a211f74dd34c"},"outputs":[],"source":"df_train_set.head(3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"04ed9886-6348-a17e-8c9f-dbe4a084a974"},"outputs":[],"source":"print(df_train_set1[\"question\"].describe())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29fab861-fe52-2fd1-053e-785f7e23be3a"},"outputs":[],"source":"print(df_train_set2[\"question\"].describe())\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4cd13056-3c60-12b2-e9aa-fa58331d15a8"},"outputs":[],"source":"print(df_train_set[\"question\"].describe())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae318b67-a5ef-1ec6-19b1-1e9f9c2761ec"},"outputs":[],"source":"#Lemmatizing words.Ex - consider cats and cat are different word even they both are mostly similar cotext or reffer to similar things\nprint(lemmatizer.lemmatize(\"cats\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7807c022-9e81-aa25-4cf9-a087cde45733"},"outputs":[],"source":"#Language Processing\ndef get_processed_text(text=\"\"):\n    \"\"\"\n    Remove stopword,lemmatizing the words and remove special character to get important content\n    \"\"\"\n    clean_text = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', text)\n    tokens = tokenizer.tokenize(clean_text)\n    tokens = [lemmatizer.lemmatize(token.lower().strip()) for token in tokens\n              if token not in stopwords and len(token) >= 2]\n    return tokens"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46569a8e-dbab-3871-7883-a3c033ba9af9"},"outputs":[],"source":"text = \"What is the best phone to buy below 15k\"\nprint (\"Original Text : \",text)\nprocessed_text = \" \".join(get_processed_text(text))\nprint (\"Processed Text : \",processed_text) #Remove special character(?),english stop words(is,the,by,to,in) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7561da8-3d15-36a7-e178-bbb7ca069c53"},"outputs":[],"source":"df_train_set.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45731233-f092-5332-7c9a-7e7058feaa63"},"outputs":[],"source":"#Process and clean up traing set\nalldocuments = []\nanalyzedDocument = namedtuple('AnalyzedDocument', 'words tags')       \nkeywords = []\nfor index,record in df_train_set[0:100].iterrows():\n    qid = str(record[\"qid\"])\n    question = str(record[\"question\"])\n    tokens = get_processed_text(question)\n    words = tokens\n    words_text = \" \".join(words)\n    words = gensim.utils.simple_preprocess(words_text)\n    tags = [qid]\n    alldocuments.append(analyzedDocument(words, tags))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51b44434-217c-19f9-4212-6f0b81131bce"},"outputs":[],"source":"alldocuments[0:3]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3fc5dc0a-8a87-bd93-fdf0-138bd7dd6b0f"},"outputs":[],"source":"def train_and_save_doc2vec_model(alldocuments,document_model=\"model1\",m_iter=100,m_min_count=2,m_size=100,m_window=5):\n            print (\"Start Time : %s\" %(str(datetime.datetime.now())))\n            #Train Model\n            cores = multiprocessing.cpu_count()\n            abs_path = os.getcwd()\n            saved_model_name = \"doc_2_vec_%s\" %(document_model)\n            doc_vec_file = \"%s\" %(saved_model_name)\n            if document_model == \"model1\":\n                # PV-DBOW \n                model_1 = gensim.models.Doc2Vec(alldocuments,dm=0,workers=cores,size=m_size, window=m_window,min_count=m_min_count,iter=m_iter,dbow_words=1)\n                model_1.save(\"%s\" %(doc_vec_file))\n                print (\"model training completed : %s\" %(doc_vec_file))\n            elif document_model == \"model2\":\n                # PV-DBOW \n                model_2 = gensim.models.Doc2Vec(alldocuments,dm=0,workers=cores,size=m_size, window=m_window,min_count=m_min_count,iter=m_iter,dbow_words=0)\n                model_2.save(\"%s\" %(doc_vec_file))\n                print (\"model training completed : %s\" %(doc_vec_file))\n            elif document_model == \"model3\":\n                # PV-DM w/average\n                model_3 = gensim.models.Doc2Vec(alldocuments,dm=1, dm_mean=1,size=m_size, window=m_window,min_count=m_min_count,iter=m_iter)\n                model_3.save(\"%s\" %(doc_vec_file))\n                print (\"model training completed : %s\" %(doc_vec_file))\n\n            elif document_model == \"model4\":\n                # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n                model_4 = gensim.models.Doc2Vec(alldocuments,dm=1, dm_concat=1,workers=cores, size=m_size, window=m_window,min_count=m_min_count,iter=m_iter)\n                model_4.save(\"%s\" %(doc_vec_file))\n                print (\"model training completed : %s\" %(doc_vec_file))\n            print (\"Record count %s\" %len(alldocuments))\n            print (\"End Time %s\" %(str(datetime.datetime.now())))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0191d569-1dc5-c4f5-d698-5b162193d486"},"outputs":[],"source":"#Train model\ntrain_and_save_doc2vec_model(alldocuments)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"04cd886a-4332-f260-4018-e4e3cf3cf73e"},"outputs":[],"source":"ls -ltr"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a1d7a9e-2eee-ebea-5ea8-97a0698fbb74"},"outputs":[],"source":"def get_question_similarity_score(question1=\"\",question2=\"\"):\n    print (\"question1 - \",question1)\n    print (\"question2 - \",question2)\n    model_name = \"%s\" %(\"doc_2_vec_model1\")\n    model_saved_file = \"%s\" %(model_name)\n    model = gensim.models.doc2vec.Doc2Vec.load(model_saved_file)\n    \n    question_token1 = get_processed_text(question1)\n    tokenize_text1 = ' '.join(question_token1)\n    tokenize_text1 = gensim.utils.simple_preprocess(tokenize_text1)\n    infer_vector_of_question1 = model.infer_vector(tokenize_text1)\n    \n    print(\"tokenize_text1\",tokenize_text1,\"infer_vector_of_question1\",infer_vector_of_question1)\n    \n    question_token2 = get_processed_text(question2)\n    tokenize_text2 = ' '.join(question_token2)\n    tokenize_text2 = gensim.utils.simple_preprocess(tokenize_text2)\n    infer_vector_of_question2 = model.infer_vector(tokenize_text2)\n    \n    print(\"tokenize_text2\",tokenize_text2,\"infer_vector_of_question2\",infer_vector_of_question2)\n    similarity_score = 1\n    #similarity_score = model.docvecs.most_similar(infer_vector_of_question1)\n    msg= \"question : %s model_name : %s \" %(question,model_name)\n   \n    return similarity_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ccb128b3-22e8-6e48-e2c4-f011e4aa04a8"},"outputs":[],"source":"test_id_list = []\nsimilarity_score_list = []\ndf_test = pd.read_csv(\"../input/test.csv\")\nfor index,record in df_test[0:10].iterrows():\n    test_id = str(record[\"test_id\"])\n    question1 = str(record[\"question1\"])\n    question2 = str(record[\"question2\"])\n    similarity_score = get_question_similarity_score(question1,question2)\n    test_id_list.append(test_id)\n    similarity_score_list.append(similarity_score)\n    \n#submission = pd.DataFrame({\n#\"test_id\": test_id_list,\n#\"is_duplicate\": similarity_score_list})\n#submission.to_csv('./first_submition.csv', index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ac0871eb-9bad-78fe-ff0c-2f4713dea423"},"source":"**Final Submition yet to come.Shorty i will update**"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}