{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8a810e8b-adbd-ec04-1102-6389c5c5e305"},"source":"# The Importance of Cleaning the Text"},{"cell_type":"markdown","metadata":{"_cell_guid":"6c83e387-0dcd-c376-d297-3b346e091b90"},"source":"After a few different iterations, I think that I have found a pretty good way to clean the questions to improve the performance of a model. I was able to reduce my loss value by a few points because of this method.  Feel free to use this code and improve upon the method!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ed647af-7bd2-6381-bd08-8d7fbce13175"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nimport re\nfrom string import punctuation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2571fee8-966a-7781-31fd-0b67ca74cc09"},"outputs":[],"source":"train = pd.read_csv(\"../input/train.csv\")[:100]\ntest = pd.read_csv(\"../input/test.csv\")[:100]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d5076218-27e7-bdbe-d156-f19fa1b42511"},"outputs":[],"source":"# Check for any null values\nprint(train.isnull().sum())\nprint(test.isnull().sum())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3dcc0bd-4810-f3c5-173f-e57d5c08ba75"},"outputs":[],"source":"# Add the string 'empty' to empty strings\ntrain = train.fillna('empty')\ntest = test.fillna('empty')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"afee6957-0045-f900-14ad-e357799327ee"},"outputs":[],"source":"# Preview some of the pairs of questions\na = 0 \nfor i in range(a,a+10):\n    print(train.question1[i])\n    print(train.question2[i])\n    print()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b848afd6-2704-160e-0707-a3018f0921cf"},"outputs":[],"source":"stop_words = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n              'Is','If','While','This']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff0de941-13ce-990d-2e1f-27db513655fa"},"outputs":[],"source":"def text_to_wordlist(text, remove_stop_words=True, stem_words=False):\n    # Clean the text, with the option to remove stop_words and to stem words.\n\n    # Clean the text\n    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n    text = re.sub(r\"what's\", \"\", text)\n    text = re.sub(r\"What's\", \"\", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"I'm\", \"I am\", text)\n    text = re.sub(r\" m \", \" am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"60k\", \" 60000 \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e-mail\", \"email\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = re.sub(r\"quikly\", \"quickly\", text)\n    text = re.sub(r\" usa \", \" America \", text)\n    text = re.sub(r\" USA \", \" America \", text)\n    text = re.sub(r\" u s \", \" America \", text)\n    text = re.sub(r\" uk \", \" England \", text)\n    text = re.sub(r\" UK \", \" England \", text)\n    text = re.sub(r\"india\", \"India\", text)\n    text = re.sub(r\"switzerland\", \"Switzerland\", text)\n    text = re.sub(r\"china\", \"China\", text)\n    text = re.sub(r\"chinese\", \"Chinese\", text) \n    text = re.sub(r\"imrovement\", \"improvement\", text)\n    text = re.sub(r\"intially\", \"initially\", text)\n    text = re.sub(r\"quora\", \"Quora\", text)\n    text = re.sub(r\" dms \", \"direct messages \", text)  \n    text = re.sub(r\"demonitization\", \"demonetization\", text) \n    text = re.sub(r\"actived\", \"active\", text)\n    text = re.sub(r\"kms\", \" kilometers \", text)\n    text = re.sub(r\"KMs\", \" kilometers \", text)\n    text = re.sub(r\" cs \", \" computer science \", text) \n    text = re.sub(r\" upvotes \", \" up votes \", text)\n    text = re.sub(r\" iPhone \", \" phone \", text)\n    text = re.sub(r\"\\0rs \", \" rs \", text) \n    text = re.sub(r\"calender\", \"calendar\", text)\n    text = re.sub(r\"ios\", \"operating system\", text)\n    text = re.sub(r\"gps\", \"GPS\", text)\n    text = re.sub(r\"gst\", \"GST\", text)\n    text = re.sub(r\"programing\", \"programming\", text)\n    text = re.sub(r\"bestfriend\", \"best friend\", text)\n    text = re.sub(r\"dna\", \"DNA\", text)\n    text = re.sub(r\"III\", \"3\", text) \n    text = re.sub(r\"the US\", \"America\", text)\n    text = re.sub(r\"Astrology\", \"astrology\", text)\n    text = re.sub(r\"Method\", \"method\", text)\n    text = re.sub(r\"Find\", \"find\", text) \n    text = re.sub(r\"banglore\", \"Banglore\", text)\n    text = re.sub(r\" J K \", \" JK \", text)\n    \n    # Remove punctuation from text\n    text = ''.join([c for c in text if c not in punctuation])\n    \n    # Optionally, remove stop words\n    if remove_stop_words:\n        text = text.split()\n        text = [w for w in text if not w in stop_words]\n        text = \" \".join(text)\n    \n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n    \n    # Return a list of words\n    return(text)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4c3b53d-f02a-979f-bc09-1c5bccbbf1be"},"outputs":[],"source":"def process_questions(question_list, questions, question_list_name, dataframe):\n    '''transform questions and display progress'''\n    for question in questions:\n        question_list.append(text_to_wordlist(question))\n        if len(question_list) % 100000 == 0:\n            progress = len(question_list)/len(dataframe) * 100\n            print(\"{} is {}% complete.\".format(question_list_name, round(progress, 1)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d58248eb-f5b6-94df-ee49-34fd442e5cba"},"outputs":[],"source":"train_question1 = []\nprocess_questions(train_question1, train.question1, 'train_question1', train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9ec0ed1e-5add-50d5-47a1-46290d895be4"},"outputs":[],"source":"train_question2 = []\nprocess_questions(train_question2, train.question2, 'train_question2', train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7906e1a7-e7b3-a80c-94bb-c112966c01d1"},"outputs":[],"source":"test_question1 = []\nprocess_questions(test_question1, test.question1, 'test_question1', test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8410fa8-b381-d9a7-e38d-e3356ef40025"},"outputs":[],"source":"test_question2 = []\nprocess_questions(test_question2, test.question2, 'test_question2', test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e84f3837-b714-9ee8-df9c-2be091755cee"},"outputs":[],"source":"# Preview some transformed pairs of questions\na = 0 \nfor i in range(a,a+10):\n    print(train_question1[i])\n    print(train_question2[i])\n    print()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed5d21f4-1b2c-0645-58e1-886f3aef0f12"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}