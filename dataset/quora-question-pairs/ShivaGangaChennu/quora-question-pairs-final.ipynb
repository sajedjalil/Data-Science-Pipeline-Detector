{"cells":[{"metadata":{"_uuid":"d98a6e305023a05d2bc9fae7a2b025eaeec0225f","_cell_guid":"d8bbe49f-f24f-a607-79ef-76955d2a1f3f"},"outputs":[],"cell_type":"code","source":"#importing libraries numpy,pandas,mathplotlib for extracting, modifying and visualizing the data\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1},{"metadata":{"_uuid":"644bd97c9d438ae64cef7aabb387c278c9c5e956","_cell_guid":"9aea78d4-b1ca-b06e-a794-a04b8043eee6"},"outputs":[],"cell_type":"code","source":"#loading input train file to train\ntrain = pd.read_csv(\"../input/train.csv\")\n#loading iput test file to test\ntest = pd.read_csv(\"../input/test.csv\")\n#printing the top\ntrain.head()","execution_count":2},{"metadata":{"_uuid":"83951624df9392def469b2cbf2c605a25dfc178f","_cell_guid":"657778b7-c3eb-6a90-b2b4-a2311bdfc2a9"},"cell_type":"markdown","source":"This is how the training data is given. "},{"metadata":{"_uuid":"32747d0d7cae69191037875c835a0389c75e6826","_cell_guid":"88c2983a-a3a4-4d98-ce11-509caa0868b2"},"outputs":[],"cell_type":"code","source":"test.head()","execution_count":3},{"metadata":{"_uuid":"aef3130ee7756bc79015b10ca03e2c36ee4d932e","_cell_guid":"1f777703-2302-577e-9998-416f945f3441"},"cell_type":"markdown","source":"The test data only contains questions but not their id's as in train data, as you can see above. "},{"metadata":{"_uuid":"42575c2d36a0e6a4721afb1e90a463c690f139b2","_cell_guid":"f8bcc6a9-4281-9ba0-5f0a-8242ed24a121"},"outputs":[],"cell_type":"code","source":"train.info()","execution_count":4},{"metadata":{"_uuid":"ed2151c4ee0d14e2314a198c0509297c09ad6898","_cell_guid":"17d80d7a-7e31-f370-effe-ade7206ebfe8"},"cell_type":"markdown","source":"The training data has 404290 instances. "},{"metadata":{"_uuid":"6f086566575002f60d823dae80cc7202d1073568","_cell_guid":"425fa328-57e6-4e65-91cc-dc808293c15f"},"outputs":[],"cell_type":"code","source":"test.info()","execution_count":5},{"metadata":{"_uuid":"bb9c09bbaf48967662e82a75e08f7b62c188a2c4","_cell_guid":"e1d207af-e5cf-a3b7-09a7-e4899d19d889"},"cell_type":"markdown","source":"The test data has 2345796 instances."},{"metadata":{"_uuid":"ed648e2c4ad18b82a004b883277c6b4a7d77d521","_cell_guid":"b15677da-57ed-ce42-bb6a-afb704fd00d7"},"outputs":[],"cell_type":"code","source":"train_duplicate_mean = train['is_duplicate'].mean()\nprint (\"mean of train data is_duplicate column\",train_duplicate_mean)","execution_count":6},{"metadata":{"_uuid":"b33f30a7d66d568a974e4979747a1c7332b7ca72","_cell_guid":"e962f7e6-3102-f786-98c2-6191e36913c7"},"cell_type":"markdown","source":"By finding the mean on the is_duplicate field of train data, we see that about 37% of the train data have pair of questions, which are labeled is_duplicate as 1. "},{"metadata":{"_uuid":"7a3dc1681ae0402bf800ff2afe38b68c990364e3","_cell_guid":"02115075-2a2e-f666-93b9-aa8cce7d1fa9"},"outputs":[],"cell_type":"code","source":"pt = train.groupby('is_duplicate')['id'].count()\npt.plot.bar()","execution_count":7},{"metadata":{"_uuid":"9df5e8df684d48be570db279884d2e3dc7e4d6f4","_cell_guid":"9a4aaff7-d9b7-8189-64f5-128b1f442129"},"cell_type":"markdown","source":"The plot shows the is_duplicate distribution in the train data. "},{"metadata":{"_uuid":"3b8315bec7e41f205ceb9725d9beadae0f58b66c","_cell_guid":"d10950bc-6ed8-c93b-1e27-9bf21ade3a51"},"outputs":[],"cell_type":"code","source":"\nquestion_id_1 = train['qid1'].tolist()\nquestion_id_2 = train['qid2'].tolist()\nquestion_id = pd.Series(question_id_1+question_id_2)\nplt.figure(figsize=(15,6))\nplt.hist(question_id.value_counts(), bins= 30)\nplt.yscale('log', nonposy='clip')","execution_count":8},{"metadata":{"_uuid":"39a1a885ab531a15abbe8fc7858da8edb2a8a8e8","_cell_guid":"e243a9c9-a8a0-b20c-23b8-484c9a2957ac"},"cell_type":"markdown","source":"By plotting the no. of questions vs no. of occurences of the question, we observe that most of the questions only appear a few times, except very few. "},{"metadata":{"_uuid":"b30982ddd18e67d0b46a99a83e5ae9c186287ca6","collapsed":true,"_cell_guid":"d38631e0-6f37-eee2-c6d3-83071169bcdd"},"outputs":[],"cell_type":"code","source":"from nltk.corpus import stopwords as st\nstopwords_set = set(st.words(\"english\"))\n\ndef word_dict(sentence):\n    question_words_dict = {}\n    for word in sentence.lower().split():\n        if word not in stopwords_set:\n            question_words_dict[word] = 1\n    return question_words_dict\ndef common_words_percentage(entry):\n    question_1_words = word_dict(str(entry['question1']))\n    question_2_words = word_dict(str(entry['question2']))\n     \n    if len(question_1_words) == 0 or len(question_2_words) == 0:\n        return 0\n    shared_in_q1 = [word for word in question_1_words.keys() if word in question_2_words]\n    feature_Ratio = ( 2*len(shared_in_q1) )/(len(question_1_words)+len(question_2_words))\n    return feature_Ratio","execution_count":9},{"metadata":{"_uuid":"b6022a5180f783ab2669b8e8752054c795f72f55","collapsed":true,"_cell_guid":"43561a09-df10-2b0c-fa0b-4d262e9be955"},"outputs":[],"cell_type":"code","source":"def tfidf_weights(entry):\n    question_1_words = word_dict(str(entry['question1']))\n    question_2_words = word_dict(str(entry['question2']))\n    if len(question_1_words) == 0 or len(question_2_words) == 0:\n        return 0\n    \n    common_wts_1 = [weights.get(w, 0) for w in question_1_words.keys() if w in question_2_words]  \n    common_wts_2 = [weights.get(w, 0) for w in question_2_words.keys() if w in question_2_words]\n    common_wts = common_wts_1 + common_wts_2\n    whole_wts = [weights.get(w, 0) for w in question_1_words] + [weights.get(w, 0) for w in question_2_words]\n    \n    feature_tfidf = np.sum(common_wts) / np.sum(whole_wts)\n    return feature_tfidf","execution_count":10},{"metadata":{"_uuid":"69ef02d470cba87f39ae88d5f578c7cc54a4c7c4","collapsed":true,"_cell_guid":"8291f544-c69f-457a-6e84-2a82ee86e424"},"outputs":[],"cell_type":"code","source":"list_of_questions = (train['question1'].str.lower().astype('U').tolist() + train['question2'].str.lower().astype('U').tolist())\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(min_df = 50,max_features = 3000000,ngram_range = (1,10))\nX = vectorizer.fit_transform(list_of_questions)\nidf = vectorizer.idf_\nweights = (dict(zip(vectorizer.get_feature_names(), idf)))","execution_count":11},{"metadata":{"_uuid":"f975d51961e3eec9a03f224bca81ddb93f918457","_cell_guid":"db115ace-a429-5c73-8b5e-5ae832c55603"},"outputs":[],"cell_type":"code","source":"X_TrainData = pd.DataFrame()\nX_TestData = pd.DataFrame()\nX_TrainData['common_word_percent'] = train.apply(common_words_percentage, axis=1, raw=True)\nX_TrainData['feature_ifidf'] = train.apply(tfidf_weights, axis = 1, raw = True)\nY_TrainData = train['is_duplicate'].values\nX_TestData['common_word_percent'] = test.apply(common_words_percentage, axis = 1, raw = True)\nX_TestData['feature_ifidf'] = test.apply(tfidf_weights, axis = 1, raw = True)","execution_count":12},{"metadata":{"_uuid":"610715232ca55667bb5bc8e20be5699567f54512","collapsed":true,"_cell_guid":"74ab10da-131d-da09-f1b8-34d534ac223a"},"outputs":[],"cell_type":"code","source":"import nltk\ndef jaccard_similarity_coefficient(row):\n    if (type(row['question1']) is str) and (type(row['question2']) is str):\n        words_1 = row['question1'].lower().split()\n        words_2 = row['question2'].lower().split()\n    else:\n        words_1 = nltk.word_tokenize(str(row['question1']))\n        words_2 = nltk.word_tokenize(str(row['question2']))\n   \n    joint_words = set(words_1).union(set(words_2))\n    intersection_words = set(words_1).intersection(set(words_2))\n    return len(intersection_words)/len(joint_words)","execution_count":13},{"metadata":{"_uuid":"bedc6fd25d7cc8e13da6adf3b53f3313d62e1d5d","collapsed":true,"_cell_guid":"8881b656-ef74-29ee-376d-f8e5e68b9fd1"},"outputs":[],"cell_type":"code","source":"train = train.fillna(\"\")","execution_count":null},{"metadata":{"_uuid":"0dcd06be93fa62d0c0c958b9d3368310414e6419","collapsed":true,"_cell_guid":"d81f1878-e045-c343-f156-0ea216e422fb"},"outputs":[],"cell_type":"code","source":"X_TrainData['Jacard_Distance'] = train.apply(jaccard_similarity_coefficient, axis = 1, raw = True)\nX_TestData['Jacard_Distance'] = test.apply(jaccard_similarity_coefficient, axis = 1, raw = True)","execution_count":null},{"metadata":{"_uuid":"35f1fb43140acd5d3d55396b82d5e98f56e04a50","collapsed":true,"_cell_guid":"7884b847-bf83-1d37-298c-b9dc40780f22"},"outputs":[],"cell_type":"code","source":"\nfrom sklearn.metrics.pairwise import cosine_similarity as cs\nimport re, math\nfrom collections import Counter\n\nWORD = re.compile(r'\\w+')\ndef _cosine_similarity(vector_1, vector_2):\n     intersection = set(vector_1.keys()) & set(vector_2.keys())\n     numerator = sum([vector_1[x] * vector_2[x] for x in intersection])\n\n     sum1 = sum([vector_1[x]**2 for x in vector_1.keys()])\n     sum2 = sum([vector_2[x]**2 for x in vector_2.keys()])\n     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n\n     if not denominator:\n        return 0.0\n     else:\n        return float(numerator) / denominator\n\ndef sentence_transform(sentence):\n     words = WORD.findall(sentence)\n     return Counter(words)\n\ndef cosine_sim(row):\n    vector1 = sentence_transform(str(row['question1']))\n    vector2 = sentence_transform(str(row['question2']))\n    sim = _cosine_similarity(vector1,vector2)\n    return sim\n\nX_TrainData['cosine_sim'] = train.apply(cosine_sim,axis = 1,raw = True )","execution_count":null},{"metadata":{"_uuid":"c9c7123e2e73e3b8bcd544e6eedd0939a8ea787d","collapsed":true,"_cell_guid":"c10381d3-da99-44a9-54c0-525cb7239696"},"outputs":[],"cell_type":"code","source":"X_TestData['cosine_sim'] = test.apply(cosine_sim,axis = 1,raw = True )","execution_count":null},{"metadata":{"_uuid":"75f91af808b9001f5c0df44ee701c19d0378ea0f","collapsed":true,"_cell_guid":"54b267dd-fc99-72e1-e1b9-bb291e49c2e0"},"outputs":[],"cell_type":"code","source":"\nX_TrainData","execution_count":null},{"metadata":{"_uuid":"33b063ca82fd51cfb4720b4cc39891c783d6ac2f","collapsed":true,"_cell_guid":"15994432-ced5-6df1-1f53-5704961146ff"},"outputs":[],"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\n\nX_TrainData, X_ValidData, Y_TrainData, Y_ValidData = train_test_split(X_TrainData, Y_TrainData, test_size=0.20, random_state=4242)","execution_count":null},{"metadata":{"_uuid":"6cf5951579521c7eaf094faf6eb894bce81f5096","collapsed":true,"_cell_guid":"62d37261-8ac9-1dcc-ccc3-2db02726033f"},"outputs":[],"cell_type":"code","source":"import xgboost as xgb\n\nxg_TrainData = xgb.DMatrix(X_TrainData, label=Y_TrainData)\nxg_ValidData = xgb.DMatrix(X_ValidData, label=Y_ValidData)\n\nwatchlist = [(xg_TrainData, 'train'), (xg_ValidData, 'valid')]\n\nbst = xgb.train({'objective':'binary:logistic','eval_metric':'logloss','eta':0.02,'max_depth' :5}, xg_TrainData, 500, watchlist, early_stopping_rounds=50, verbose_eval=10)","execution_count":null},{"metadata":{"_uuid":"92e6ca626bf222c91d9233e3b1b1671e2813adda","collapsed":true,"_cell_guid":"fa825ef9-c56d-d1a3-5d9e-ca01afc3110d"},"outputs":[],"cell_type":"code","source":"X_TestData.info()","execution_count":null},{"metadata":{"_uuid":"00cda7a4460206cc7cbee51b08bcacb826f1d663","collapsed":true,"_cell_guid":"77504acf-2d85-1f51-bd4a-fd5b0194f973"},"outputs":[],"cell_type":"code","source":"xg_TestData = xgb.DMatrix(X_TestData)\nxg_ValidData = xgb.DMatrix(X_ValidData)\n\nPredict_TestData = bst.predict(xg_TestData)\nPredict_ValidData = bst.predict(xg_ValidData)\n\n","execution_count":null},{"metadata":{"_uuid":"44aae37318a44e063b4eb348c427639262a1a1dc","collapsed":true,"_cell_guid":"ca5687fe-2acb-3a5a-cf4c-1fde2b2b2439"},"outputs":[],"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, auc, roc_curve\nfpr, tpr, _ = roc_curve(Y_ValidData, Predict_ValidData)\nroc_area = auc(fpr, tpr)\nplt.plot(fpr, tpr, lw=1)\nnp.round(roc_area, 10)","execution_count":null},{"metadata":{"_uuid":"85c53e140f426bea3e5c1817ab7a283c66acca07","collapsed":true,"_cell_guid":"9f54b908-a6c2-8f5b-e88c-798be694c70f"},"outputs":[],"cell_type":"code","source":"precison, recall, _ = precision_recall_curve(Y_ValidData, Predict_ValidData)\nplt.figure(figsize=(10,5))\n\nplt.plot(recall, precison)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nauc(recall, precison)","execution_count":null},{"metadata":{"_uuid":"d71837ace4be392b36474e934ee6e122c2b5b320","collapsed":true,"_cell_guid":"c79288af-5194-7867-2c20-e0a8ce2721bc"},"outputs":[],"cell_type":"code","source":"result = pd.DataFrame()\nresult['test_id'] = test['test_id']\nresult['is_duplicate'] = Predict_TestData\nresult.to_csv('result.csv', index=False)","execution_count":null},{"metadata":{"_uuid":"12f23cab86ee7e039ce03c119bdfa264aaefda0e","collapsed":true,"_cell_guid":"a4f6855a-56bf-4860-d864-5d2d8bcd1108"},"outputs":[],"cell_type":"code","source":"Predict_TestData","execution_count":null}],"nbformat":4,"metadata":{"_is_fork":false,"_change_revision":0,"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":1}