{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"7427ebee-e1ef-69d9-8716-4c3ab0d15471"},"source":"## Shallow Benchmark ##\n\nin this script we will explore perhaps the most trivial benchmark one can think of:\n\nextraction of \"bag of words\"/\"bag of letter sequences\" features followed by a logistic regression classifier\n\n\n----------\n**Note:** due to runtime limitation in the kernels platform one cannot really run this script to get a reasonable LB score, so **you will have to run it locally on your computer** and change some of the script parameters in CountVectorizer:\n\n - max_features = 300000 \n - min_df = 50\n - ngram_range = (1,10)\n\nOn my laptop, this script with the above parameters runs for a little less than an hour, and achieves a LB score of 0.31675"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e10dc37-1221-e94d-dca7-2d5163ebda6f"},"outputs":[],"source":"import time\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport networkx as nx\n\nfrom sklearn import model_selection\nfrom sklearn import linear_model\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nmatplotlib.style.use('fivethirtyeight')"},{"cell_type":"markdown","metadata":{"_cell_guid":"0b06a93e-de0a-f661-7dac-8291033a5c6e"},"source":"Load data and show some samples of the data\n-------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"673cdfe0-18d1-affb-c98b-3a38175f3e37"},"outputs":[],"source":"#%% load train data\n\ntrainDF = pd.read_csv('../input/train.csv')\ntrainDF = trainDF.dropna(how=\"any\").reset_index(drop=True)\n\ntrainDF.ix[:7,3:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"628f8925-df02-f77a-30cb-8864dc88ed45"},"source":"Create dictionary and extract Bag of Words features from each question\n----------------------------------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1b57ff2-8de3-92be-e910-41b553ac9bcb"},"outputs":[],"source":"#%% create dictionary and extract BOW features from questions\n\nfeatureExtractionStartTime = time.time()\n\nmaxNumFeatures = 3000\n\n# bag of letter sequences (chars)\nBagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=1000, max_features=maxNumFeatures, \n                                      analyzer='char', ngram_range=(1,2), \n                                      binary=True, lowercase=True)\n# bag of words\n#BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=10, max_features=maxNumFeatures, \n#                                      analyzer='word', ngram_range=(1,6), stop_words='english', \n#                                      binary=True, lowercase=True)\n\nBagOfWordsExtractor.fit(pd.concat((trainDF.ix[:,'question1'],trainDF.ix[:,'question2'])).unique())\n\ntrainQuestion1_BOW_rep = BagOfWordsExtractor.transform(trainDF.ix[:,'question1'])\ntrainQuestion2_BOW_rep = BagOfWordsExtractor.transform(trainDF.ix[:,'question2'])\nlables = np.array(trainDF.ix[:,'is_duplicate'])\n\nfeatureExtractionDurationInMinutes = (time.time()-featureExtractionStartTime)/60.0\nprint(\"feature extraction took %.2f minutes\" % (featureExtractionDurationInMinutes))"},{"cell_type":"markdown","metadata":{"_cell_guid":"73804e3a-8822-af41-cb8a-2430bae34a01"},"source":"Cross Validation\n----------------\n\ncombine the word representation to a single feature vector and run cross validation with logistic regression classifier\n\n**The first version of a possible feature is:**\n\n - take the value  \" 0\" if the particular letter sequence is either present or not present in both questions\n - take the value  \"-1\" if the particular letter sequence is present in one question but not the other question\n\n\n**The second version of a possible feature is:**\n\n - take the value  \" 1\" if the particular letter sequence is present in both questions\n - take the value  \" 0\" if the particular letter sequence is not present in any question\n - take the value \"-1\" if the particular letter sequence is present in one question but not the other question"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"152b4460-aaa0-6021-70a3-c7968ef60ea7"},"outputs":[],"source":"0#%% prefrom cross validation\n\ncrossValidationStartTime = time.time()\n\nnumCVSplits = 8\nnumSplitsToBreakAfter = 2\n\nX = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int)\n#X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int) + \\\n#      trainQuestion1_BOW_rep.multiply(trainQuestion2_BOW_rep)\ny = lables\n\nlogisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag')\n\nlogRegAccuracy = []\nlogRegLogLoss = []\nlogRegAUC = []\n\nprint('---------------------------------------------')\nstratifiedCV = model_selection.StratifiedKFold(n_splits=numCVSplits, random_state=2)\nfor k, (trainInds, validInds) in enumerate(stratifiedCV.split(X, y)):\n    foldTrainingStartTime = time.time()\n\n    X_train_cv = X[trainInds,:]\n    X_valid_cv = X[validInds,:]\n\n    y_train_cv = y[trainInds]\n    y_valid_cv = y[validInds]\n\n    logisticRegressor.fit(X_train_cv, y_train_cv)\n\n    y_train_hat =  logisticRegressor.predict_proba(X_train_cv)[:,1]\n    y_valid_hat =  logisticRegressor.predict_proba(X_valid_cv)[:,1]\n\n    logRegAccuracy.append(accuracy_score(y_valid_cv, y_valid_hat > 0.5))\n    logRegLogLoss.append(log_loss(y_valid_cv, y_valid_hat))\n    logRegAUC.append(roc_auc_score(y_valid_cv, y_valid_hat))\n    \n    foldTrainingDurationInMinutes = (time.time()-foldTrainingStartTime)/60.0\n    print('fold %d took %.2f minutes: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (k+1,\n             foldTrainingDurationInMinutes, logRegAccuracy[-1],logRegLogLoss[-1],logRegAUC[-1]))\n\n    if (k+1) >= numSplitsToBreakAfter:\n        break\n\n\ncrossValidationDurationInMinutes = (time.time()-crossValidationStartTime)/60.0\n\nprint('---------------------------------------------')\nprint('cross validation took %.2f minutes' % (crossValidationDurationInMinutes))\nprint('mean CV: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (np.array(logRegAccuracy).mean(),\n                                                                 np.array(logRegLogLoss).mean(),\n                                                                 np.array(logRegAUC).mean()))\nprint('---------------------------------------------')"},{"cell_type":"markdown","metadata":{"_cell_guid":"6065b41d-555b-2748-2f1b-8ff8c9d91941"},"source":"Show predictions and \"feature importance\"\n----------------------------------------\n\nShow prediction distribution on the validation set vs the ground truth \n\nShow the letter sequences that correspond to the largest positive coefficients and the largest negative (in absolute value) coefficients of the logistic regressor"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c8152fc-972f-29d9-9393-69e51c5c2741"},"outputs":[],"source":"9#%% show prediction distribution and \"feature importance\"\n\n\n\nnumFeaturesToShow = 30\n\nsortedCoeffients = np.sort(logisticRegressor.coef_)[0]\nfeatureNames = BagOfWordsExtractor.get_feature_names()\nsortedFeatureNames = [featureNames[x] for x in list(np.argsort(logisticRegressor.coef_)[0])]\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"23bc169f-f1f6-6935-ee19-a1f3fd74c7af"},"source":"Train on the full training data\n-------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3fcca600-6314-88f9-217f-0a73b7ce3afd"},"outputs":[],"source":"#%% train on full training data\n\ntrainingStartTime = time.time()\n\nlogisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag', \n                                                    class_weight={1: 0.46, 0: 1.32})\nlogisticRegressor.fit(X, y)\n\ntrainingDurationInMinutes = (time.time()-trainingStartTime)/60.0\nprint('full training took %.2f minutes' % (trainingDurationInMinutes))"},{"cell_type":"markdown","metadata":{"_cell_guid":"51575bb5-e7e3-6d31-bdbb-02e3b88beb45"},"source":"Extract features and make predictions on the test data\n------------------------------------------------------\n\nshow the distribution of the validation predictions and the test predictions to make sure that the distributions are in fact different due to changing of the \"class weight\" argument in the logistic regression class definition"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd409e0f-1819-e4ae-04fa-ade2aac87ca6"},"outputs":[],"source":"0#%% load test data, extract features and make predictions\n\ntestPredictionStartTime = time.time()\n\ntestDF = pd.read_csv('../input/test.csv')\ntestDF.ix[testDF['question1'].isnull(),['question1','question2']] = 'random empty question'\ntestDF.ix[testDF['question2'].isnull(),['question1','question2']] = 'random empty question'\n\ntestQuestion1_BOW_rep = BagOfWordsExtractor.transform(testDF.ix[:,'question1'])\ntestQuestion2_BOW_rep = BagOfWordsExtractor.transform(testDF.ix[:,'question2'])\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6ce1e7d-4e2c-263a-99c0-62b45705fad6"},"outputs":[],"source":"X_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int)\n#X_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int) + \\\n#           testQuestion1_BOW_rep.multiply(testQuestion2_BOW_rep)\n\n#testPredictions = logisticRegressor.predict_proba(X_test)[:,1]\n\n# quick fix to avoid memory errors\nseperators= [750000,1500000]\ntestPredictions1 = logisticRegressor.predict_proba(X_test[:seperators[0],:])[:,1]\ntestPredictions2 = logisticRegressor.predict_proba(X_test[seperators[0]:seperators[1],:])[:,1]\ntestPredictions3 = logisticRegressor.predict_proba(X_test[seperators[1]:,:])[:,1]\ntestPredictions = np.hstack((testPredictions1,testPredictions2,testPredictions3))"},{"cell_type":"markdown","metadata":{"_cell_guid":"20dd38fc-dbf3-cfa9-234f-cac33bbbdf5a"},"source":"Create a Submission\n-------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d7eb295-d4db-d7e7-1f1f-56016e33e960"},"outputs":[],"source":"#%% create a submission\n\nsubmissionName = 'shallowBenchmark'\n\nsubmission = pd.DataFrame()\nsubmission['test_id'] = testDF['test_id']\nsubmission['is_duplicate'] = testPredictions\nsubmission.to_csv(submissionName + '.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}