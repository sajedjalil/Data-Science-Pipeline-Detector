{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"341e994b-022e-3682-7ca7-600a59772e76"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\n\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"963de902-205d-70a4-9444-5ae68ff7f3c5"},"outputs":[],"source":"train_df = pd.read_csv('../input/train.csv', sep=',').fillna('Nan_question')\ninitial_train_df = train_df.copy()\ntrain_df.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"9cafc2e9-f372-e815-d486-efc2624b210a"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a72fb251-033d-5548-81df-55639a67563d"},"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d9b5728c-91ab-5ead-3371-9f991b0e8762"},"outputs":[],"source":"maxNumFeatures = 300\n\n# bag of letter sequences (chars)\nBagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=1000, max_features=maxNumFeatures, stop_words='english',\n                                      analyzer='char', ngram_range=(1,2), \n                                      binary=True, lowercase=True)\n\nBagOfWordsExtractor.fit(pd.concat((train_df.question1, train_df.question2)).unique())\n\ntrainQuestion1_BOW_rep = BagOfWordsExtractor.transform(train_df.question1)\ntrainQuestion2_BOW_rep = BagOfWordsExtractor.transform(train_df.question2)\ny = train_df.is_duplicate.values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8e140e5-d4a3-4f26-8334-c4ae7a72a89e"},"outputs":[],"source":"X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d4761188-50d8-5c5d-9aaa-ee536479fe53"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38a34328-a1b1-928b-628f-40186c5b111a"},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8c090d8-b65e-1d36-83bd-f7e3e7dc233a"},"outputs":[],"source":"clf = LogisticRegression(C=0.1, solver='newton-cg')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c94a3e71-1f25-20e3-0748-38061a47741c"},"outputs":[],"source":"logRegAccuracy = []\nlogRegLogLoss = []\nlogRegAUC = []\n\nstratifiedCV = StratifiedKFold(n_splits=10, random_state=2)\nfor it, (trainInds, validInds) in enumerate(stratifiedCV.split(X, y)):\n    X_train_cv = X[trainInds,:]\n    X_valid_cv = X[validInds,:]\n\n    y_train_cv = y[trainInds]\n    y_valid_cv = y[validInds]\n\n    clf.fit(X_train_cv, y_train_cv)\n\n    y_train_hat = clf.predict_proba(X_train_cv)[:,1]\n    y_valid_hat = clf.predict_proba(X_valid_cv)[:,1]\n\n    logRegAccuracy.append(accuracy_score(y_valid_cv, y_valid_hat > 0.5))\n    logRegLogLoss.append(log_loss(y_valid_cv, y_valid_hat))\n    logRegAUC.append(roc_auc_score(y_valid_cv, y_valid_hat))\n    print ('%d done'%it)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"616dc074-683a-cf0c-8efd-10546aec07e6"},"outputs":[],"source":"plt.plot(logRegAccuracy, c='r')\nplt.plot(logRegLogLoss, c='g')\nplt.plot(logRegAUC, c='b')"},{"cell_type":"markdown","metadata":{"_cell_guid":"bc499282-e7fe-5ab9-06e3-edb9aad8545f"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4fdfb36-0cec-c6bd-dbdd-a94b8060ac6a"},"outputs":[],"source":"test_df = pd.read_csv('../input/test.csv', sep=',').fillna('Nan_question')\ntest_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ede4e97-dc94-6aba-e67d-2e56b0e34a3c"},"outputs":[],"source":"testQuestion1_BOW_rep = BagOfWordsExtractor.transform(test_df.question1)\ntestQuestion2_BOW_rep = BagOfWordsExtractor.transform(test_df.question2)\n\nX_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43ff82fa-5344-a100-ead9-44834d94adc4"},"outputs":[],"source":"predicted = clf.predict_proba(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae44fa2f-04a3-fa0d-a941-53b2a74e8dc5"},"outputs":[],"source":"predicted[:, 1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9eb137d0-e3f0-59e0-a749-edf33ee9edde"},"outputs":[],"source":"submission = pd.DataFrame()\nsubmission['test_id'] = test_df['test_id']\nsubmission['is_duplicate'] = predicted[:, 1]\nsubmission.to_csv('my_attempt.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dacbacf6-298f-5a37-7bfc-dadc632f2293"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}