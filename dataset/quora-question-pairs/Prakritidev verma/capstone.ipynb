{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8fe1fed0-845c-2477-684b-4678c1475fac"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"00a034a1-d42b-ea50-4552-e946c225fa59"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import ensemble\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\n\ncolor = sns.color_palette()"},{"cell_type":"markdown","metadata":{"_cell_guid":"362a4cd2-ab20-fbd1-9814-49fb64f6b3bf"},"source":"## Read Data ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c034876-7d33-61b7-648d-cf134e1d7afe"},"outputs":[],"source":"df_train = pd.read_csv('../input/train.csv', encoding='utf-8')\ndf_train['id'] = df_train['id'].apply(str)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29fc71a4-c3cb-4042-8772-bbee71969e27"},"outputs":[],"source":"df_train.drop_duplicates(inplace=True)\ndf_train.dropna(inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6fbf3f4-0b2d-ac1d-7194-71845d706ed7"},"outputs":[],"source":"df_test = pd.read_csv('../input/test.csv', encoding='utf-8')\ndf_test['test_id'] = df_test['test_id'].apply(str)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9720c66d-589f-e471-7d95-072d957e825d"},"outputs":[],"source":"df_all = pd.concat((df_train, df_test))\ndf_all['question1'].fillna('', inplace=True)\ndf_all['question2'].fillna('', inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c82a72b-eb0b-4e48-1469-5d165cbfd8b5"},"outputs":[],"source":"df_train.groupby(\"is_duplicate\")['id'].count().plot.bar()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef0e07e7-ad0e-edcf-e5be-43350eb5318d"},"outputs":[],"source":"import nltk\n\nfrom gensim.models import word2vec\nSTOP_WORDS = nltk.corpus.stopwords.words()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1933c29c-cad9-740d-0928-cf46e9615106"},"outputs":[],"source":"corpus = []\nfor col in ['question1', 'question2']:\n    for sentence in df_train[col].iteritems():\n        word_list = sentence[1].split(\" \")\n        corpus.append(word_list)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e15d48c-9741-5fc7-7cb2-49654127624b"},"outputs":[],"source":"corpus[0:2]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89abb719-4821-3fbe-dccb-bc5639266f68"},"outputs":[],"source":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\nmodel.wv['india']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"144c99d9-9313-89a3-06c8-65e3eb73e522"},"outputs":[],"source":"from sklearn.manifold import TSNE\ndef dataplot(data):\n    labels = []\n    tokens = []\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    model_tnse = TSNE(n_components=2, random_state=0)\n    np.set_printoptions(suppress=True)\n    new_tokens = model_tnse.fit_transform(tokens)\n    x_axis = []\n    y_axis = []\n    for i in range(len(x_axis)):\n        plt.scatter(x_axis[i],y_axis[i])\n        plt.annotate(labels[i],\n                     xy=(x_axis[i], y_axis[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"209c422b-95f6-5935-6328-55624fbaedef"},"outputs":[],"source":"dataplot(model)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8313d66-f587-2f7c-35d4-18fff6466990"},"outputs":[],"source":"model.most_similar('trump')"},{"cell_type":"markdown","metadata":{"_cell_guid":"3e61f266-254a-4dae-5e87-1a6460456023"},"source":"## Create Vocab ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7edf8cb-63de-86f7-1b4b-a24b9b5ff070"},"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer\nimport itertools"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18737244-f58e-0ff5-3ec2-ba7eb898d893"},"outputs":[],"source":"counts_vectorizer = CountVectorizer(max_features=10000-1).fit(\n    itertools.chain(df_all['question1'], df_all['question2']))\nother_index = len(counts_vectorizer.vocabulary_)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3830fdce-b7a1-05e4-ac70-4f450e3940ee"},"source":"##Prep Data##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0980bc7-b305-d950-fb78-0392d38ee2a8"},"outputs":[],"source":"import re\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"655b3f0b-36d2-72b0-39c1-67a0ae421ccc"},"outputs":[],"source":"words_tokenizer = re.compile(counts_vectorizer.token_pattern)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df71c37f-3b3a-7b8d-9123-f64be9892c6e"},"outputs":[],"source":"def create_padded_seqs(texts, max_len=10):\n    seqs = texts.apply(lambda s: \n        [counts_vectorizer.vocabulary_[w] if w in counts_vectorizer.vocabulary_ else other_index\n         for w in words_tokenizer.findall(s.lower())])\n    return pad_sequences(seqs, maxlen=max_len)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dff0d239-d393-251c-f468-36e0a75b8804"},"outputs":[],"source":"df_all = df_all.sample(1000) # Just for debugging"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2f9a4fb5-0431-0541-2e21-ae9869daf69f"},"outputs":[],"source":"X1_train, X1_val, X2_train, X2_val, y_train, y_val = \\\n    train_test_split(create_padded_seqs(df_all[df_all['id'].notnull()]['question1']), \n                     create_padded_seqs(df_all[df_all['id'].notnull()]['question2']),\n                     df_all[df_all['id'].notnull()]['is_duplicate'].values,\n                     stratify=df_all[df_all['id'].notnull()]['is_duplicate'].values,\n                     test_size=0.3, random_state=1989)"},{"cell_type":"markdown","metadata":{"_cell_guid":"05d261a2-b176-7190-455a-79e5284e6545"},"source":"##Training##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6dd4bd1e-eeb9-0a20-f96f-214b0e9845c8"},"outputs":[],"source":"import keras.layers as lyr\nfrom keras.models import Model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa0caf3a-509a-2bbe-3365-94013f18569c"},"outputs":[],"source":"input1_tensor = lyr.Input(X1_train.shape[1:])\ninput2_tensor = lyr.Input(X2_train.shape[1:])\n\nwords_embedding_layer = lyr.Embedding(X1_train.max() + 1, 100)\nseq_embedding_layer = lyr.LSTM(256, activation='tanh')\n\nseq_embedding = lambda tensor: seq_embedding_layer(words_embedding_layer(tensor))\n\nmerge_layer = lyr.multiply([seq_embedding(input1_tensor), seq_embedding(input2_tensor)])\n\ndense1_layer = lyr.Dense(16, activation='sigmoid')(merge_layer)\nouput_layer = lyr.Dense(1, activation='sigmoid')(dense1_layer)\n\nmodel = Model([input1_tensor, input2_tensor], ouput_layer)\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\nmodel.summary()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18853bca-60fa-d4f8-ced7-9a40a84c1f52"},"outputs":[],"source":"model.fit([X1_train, X2_train], y_train, \n          validation_data=([X1_val, X2_val], y_val), \n          batch_size=128, epochs=6, verbose=2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3dd431f7-d8af-734b-d82b-565810b43f71"},"source":"##Extract Features From Model##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f462071f-ca0e-1445-2653-6992d69e143c"},"outputs":[],"source":"features_model = Model([input1_tensor, input2_tensor], merge_layer)\nfeatures_model.compile(loss='mse', optimizer='adam')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f322533-15c3-dde3-7c2c-3ab879b5b286"},"outputs":[],"source":"F_train = features_model.predict([X1_train, X2_train], batch_size=128)\nF_val = features_model.predict([X1_val, X2_val], batch_size=128)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2611a562-499a-3436-5491-988b65ab74a4"},"source":"##Train XGBoost##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6165f0bb-29f8-7c1d-b92e-60fd24d18d6e"},"outputs":[],"source":"import xgboost as xgb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f40ca07f-2971-588a-4e2f-6882a37f8a05"},"outputs":[],"source":"dTrain = xgb.DMatrix(F_train, label=y_train)\ndVal = xgb.DMatrix(F_val, label=y_val)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d2b3691-08bc-30f5-4783-9c9ceab4c03c"},"outputs":[],"source":"import xgboost as xgb\n\n# Set our parameters for xgboost\nparams = {}\nparams['objective'] = 'binary:logistic'\nparams['eval_metric'] = 'logloss'\nparams['eta'] = 0.02\nparams['max_depth'] = 4\n\n\n\nwatchlist = [(dTrain, 'train'), (dVal, 'valid')]\n\nbst = xgb.train(params, dTrain, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b16eb2b8-3016-c363-2660-38983194ff11"},"source":"##Predict Test##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34f3fef5-b30c-20f2-2105-7164a83bef7d"},"outputs":[],"source":"X1_test = create_padded_seqs(df_all[df_all['test_id'].notnull()]['question1'])\nX2_test = create_padded_seqs(df_all[df_all['test_id'].notnull()]['question2'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"794ad521-42df-a1ae-604c-dc03e41f4c4c"},"outputs":[],"source":"F_test = features_model.predict([X1_test, X2_test], batch_size=128)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ba7e6ef-b1ea-a061-7d54-a0adee79a29d"},"outputs":[],"source":"dTest = xgb.DMatrix(F_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7e3da29-55d7-28d7-6c27-abcb4f6bbd12"},"outputs":[],"source":"df_sub = pd.DataFrame({\n        'test_id': df_all[df_all['test_id'].notnull()]['test_id'].values,\n        'is_duplicate': bst.predict(dTest, ntree_limit=bst.best_ntree_limit)\n    }).set_index('test_id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35357642-74fe-a9f4-3c26-cb64d8c15e96"},"outputs":[],"source":"df_sub.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"13b7a6dc-ff58-5f8d-c3d5-784b08973887"},"outputs":[],"source":"'df_sub['is_duplicate'].hist(bins=100)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36b3fabe-40e4-5d8a-9f90-641dd30aa6c0"},"outputs":[],"source":"df_sub.to_csv('final.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c065ae7b-6cb2-a258-e373-f701b058e8e1"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}