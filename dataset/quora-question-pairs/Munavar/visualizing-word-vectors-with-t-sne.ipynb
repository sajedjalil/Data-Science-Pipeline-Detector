{"cells":[{"metadata":{"_cell_guid":"e8acc802-80ba-e4b0-403c-df40ce20cf20"},"cell_type":"markdown","source":"# Visualizing Word Vectors with t-SNE\n\nTSNE is pretty useful when it comes to visualizing similarity between objects. It works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words. \n\n### Steps\n\n1. Clean the data\n2. Build a corpus\n3. Train a Word2Vec Model\n4. Visualize t-SNE representations of the most common words "},{"metadata":{"_cell_guid":"327a2a48-c101-959c-af2d-cabd82276e65","trusted":false},"cell_type":"code","source":"import pandas as pd\npd.options.mode.chained_assignment = None \nimport numpy as np\nimport re\nimport nltk\n\nfrom gensim.models import word2vec\n\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndata = pd.read_csv('../input/train.csv').sample(50000, random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c5d7458b-d380-8af7-13cf-5ed65fb42a83","trusted":false},"cell_type":"code","source":"STOP_WORDS = nltk.corpus.stopwords.words()\n\ndef clean_sentence(val):\n    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n    regex = re.compile('([^\\s\\w]|_)+')\n    sentence = regex.sub('', val).lower()\n    sentence = sentence.split(\" \")\n    \n    for word in list(sentence):\n        if word in STOP_WORDS:\n            sentence.remove(word)  \n            \n    sentence = \" \".join(sentence)\n    return sentence\n\ndef clean_dataframe(data):\n    \"drop nans, then apply 'clean_sentence' function to question1 and 2\"\n    data = data.dropna(how=\"any\")\n    \n    for col in ['question1', 'question2']:\n        data[col] = data[col].apply(clean_sentence)\n    \n    return data\n\ndata = clean_dataframe(data)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e72326d7-e707-d4e9-928a-519a9193bfc5","trusted":false},"cell_type":"code","source":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for col in ['question1', 'question2']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(data)        \ncorpus[0:2]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c652ad03-be65-f4e6-0afd-02c237449b43"},"cell_type":"markdown","source":"# Word 2 Vec\n\nThe Word to Vec model produces a vocabulary, with each word being represented by an n-dimensional numpy array (100 values in this example)"},{"metadata":{"_cell_guid":"ee9f9d57-5b3a-16c0-916f-169ef6d7b920","trusted":false},"cell_type":"code","source":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4512c76e-f4da-c793-be73-5b18b5bb70e9","trusted":false},"cell_type":"code","source":"def tsne_plot(model):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 16)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"19ec33d2-5160-6556-c8da-a5a53316619a","trusted":false},"cell_type":"code","source":"tsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b5ffb880-585d-6ea8-51a5-a6351ea2ff20","trusted":false},"cell_type":"code","source":"# A more selective model\nmodel = word2vec.Word2Vec(corpus, size=100, window=20, min_count=500, workers=4)\ntsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9f64e341-1967-617f-4004-ef7c6d109277","trusted":false},"cell_type":"code","source":"# A less selective model\nmodel = word2vec.Word2Vec(corpus, size=100, window=20, min_count=100, workers=4)\ntsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2ba89a55-30b7-15ea-c571-9e402e1c03d2"},"cell_type":"markdown","source":"# It's Becoming Hard to Read\n\nWith a dataset this large, its difficult to make an easy-to-read TSNE visualization. What you can do is use the model to look up the most similar words from any given point. "},{"metadata":{"_cell_guid":"109ae353-5679-6f7a-74f6-ae13d7042639","trusted":false},"cell_type":"code","source":"model.most_similar('trump')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"67a0844e-83d6-22ab-a89b-ae15c19860a8","trusted":false},"cell_type":"code","source":"model.most_similar('universe')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a88070c7-87cd-0daa-61f7-b2d5ab1ca6ad"},"cell_type":"markdown","source":"# The End\n\nGood luck!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":1}