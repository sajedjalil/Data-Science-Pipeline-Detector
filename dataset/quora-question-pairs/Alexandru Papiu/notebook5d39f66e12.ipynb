{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"136fc876-5258-04b6-cced-91f0c34dc73e"},"source":"Trying some things out. \nMostly from here: https://www.kaggle.com/anokas/quora-question-pairs/data-analysis-xgboost-starter-0-35460-lb for now."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53e67f4a-30c2-0bc2-cdde-adb86938bf5b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom nltk.corpus import stopwords\nfrom sklearn.ensemble import RandomForestClassifier\n\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca482e68-378d-4cd3-ce0e-b735690bec0c"},"outputs":[],"source":"def word_match_share(row):\n    q1words = {}\n    q2words = {}\n    for word in str(row['question1']).lower().split():\n        if word not in stops:\n            q1words[word] = 1\n    for word in str(row['question2']).lower().split():\n        if word not in stops:\n            q2words[word] = 1\n    if len(q1words) == 0 or len(q2words) == 0:\n        # The computer-generated chaff includes a few questions that are nothing but stopwords\n        return 0\n    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n    return R\n\n\ndef similarity(q1, q2, use_tokenizer = False, remove_stop_words = True):\n    #this does slightly worse than word_match\n    \"\"\"\n    look at the jaccard distance between the sets of unique elements\n    \"\"\"\n    if use_tokenizer:\n        q1 = nltk.word_tokenize(q1.lower())\n        q2 = nltk.word_tokenize(q2.lower())\n    else:\n        q1 = q1.lower().split()\n        q2 = q2.lower().split()\n\n    if remove_stop_words:\n        q1 = [word for word in q1 if word not in stop_words]\n        q2 = [word for word in q2 if word not in stop_words]\n\n\n    n = len(np.union1d(q1, q1))\n    if n != 0:\n        sim = len(np.intersect1d(q1, q2))/n\n    else:\n        sim = 0\n    return sim"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6cba4a6-b56c-8bef-a12c-9e3f2a597d2d"},"outputs":[],"source":"stops = stop_words = stopwords.words('english')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a002c13-6511-ca2e-b6c2-33cbad8d300b"},"outputs":[],"source":"df = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bada6589-0604-8f8c-40b0-2cae7e81b215"},"outputs":[],"source":"df = df.dropna()\n#Rebalance the classes:\n#pos_boostrap_sample = df[df[\"is_duplicate\"] == 0].sample(n = 500000, replace = True)\n#df = pd.concat((pos_boostrap_sample, df))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"00b510a4-7583-bf21-f3bb-e504c9a68063"},"outputs":[],"source":"df[\"word_share\"] = df.apply(word_match_share, axis = 1, raw=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a87f8ae-0f80-334c-d98f-2af36f3eed4a"},"outputs":[],"source":"df_test[\"word_share\"] = df_test.apply(word_match_share, axis = 1, raw=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40bc5807-c0c4-f173-eec7-79a4408030e8"},"outputs":[],"source":"X = df[\"word_share\"].values.reshape(-1,1)\nX_test = df_test[\"word_share\"].values.reshape(-1,1)\ny = df[\"is_duplicate\"]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2852b08a-f6f2-91fd-99de-1cee92754cbd"},"outputs":[],"source":"model = RandomForestClassifier(n_estimators = 200, max_features = True)\nmodel.fit(X, y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"189fc9d2-bd29-eb96-8898-a1f01db1c090"},"outputs":[],"source":"preds = model.predict_proba(X_test)[:,1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c906b514-05f5-08a2-fd49-c8eb089b29e9"},"outputs":[],"source":"sub = pd.DataFrame()\nsub['test_id'] = df_test['test_id']\nsub['is_duplicate'] = preds\nsub.to_csv('rf_pred.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b39d23c8-52ee-378c-84e0-26106d5df356"},"outputs":[],"source":"sub.is_duplicate.hist()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}