{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2776f027-17c3-cc4f-85eb-819f97285960"},"source":"Its my last take on Quora\n----"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca0f1a00-5e22-80e9-fb7b-ef66940c8c5e"},"outputs":[],"source":"import numpy as np \nimport pandas as pd \nimport re\n# timing function\nimport time   \nstart = time.clock() #_________________ measure efficiency timing\n\n\ntrain=pd.read_csv('../input/train.csv')[:20000].fillna(\"\")\n\ndef cleanup(x):\n    # Pad punctuation with spaces on both sides\n    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n        x = x.replace(char, ' ' + char + ' ')\n    return x\n\n\ndef edit_distance(s1, s2):\n    m=len(s1)+1\n    n=len(s2)+1\n\n    tbl = {}\n    for i in range(m): tbl[i,0]=i\n    for j in range(n): tbl[0,j]=j\n    for i in range(1, m):\n        for j in range(1, n):\n            cost = 0 if s1[i-1] == s2[j-1] else 1\n            tbl[i,j] = min(tbl[i, j-1]+1, tbl[i-1, j]+1, tbl[i-1, j-1]+cost)\n\n    return tbl[i,j]\n\ndef leve3(string_1, string_2):\n    len_1 = len(ngrams_split(string_1,3)) + 1\n    len_2 = len(ngrams_split(string_2,3)) + 1\n    d=[0]\n    if len_1>3 and len_2>3:\n        d = [0] * (len_1 * len_2)\n\n        for i in range(len_1):\n            d[i] = i\n        for j in range(len_2):\n            d[j * len_1] = j\n\n        for j in range(1, len_2):\n            for i in range(1, len_1):\n                if string_1[i - 3] == string_2[j - 3]:\n                    d[i + j * len_1] = d[i - 1 + (j - 1) * len_1]\n                else:\n                    d[i + j * len_1] = min(\n                       d[i - 1 + j * len_1] + 1,        # deletion\n                       d[i + (j - 1) * len_1] + 1,      # insertion\n                       d[i - 1 + (j - 1) * len_1] + 1,  # substitution\n                    )\n\n    return d[-1]\n\nquestions = train['question1'].tolist() + train['question2'].tolist()\ntrain=cleanup(train)\nprint(train.head())\nend = time.clock()\nprint('open:',end-start)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7d97d2c-d047-2228-30dc-12112a1de2e9"},"outputs":[],"source":"import nltk #language functions\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity,euclidean_distances,laplacian_kernel,sigmoid_kernel,polynomial_kernel,rbf_kernel\nfrom sklearn.decomposition import TruncatedSVD\nimport scipy\n\ndef ngram(lst):\n    woorden=nltk.word_tokenize(lst.lower())\n    gra_ret=[]\n    for woo in woorden:\n        zip_lst=list(woo)\n        grams=zip(zip_lst, zip_lst[1:], zip_lst[2:])\n        trigram=[]\n        for gr in grams:\n            trigram.append(''.join(gr))    \n        gra_ret+=trigram\n\n    return ' '.join(gra_ret)\n\ndef intersecting(a, b):\n    return ' '.join(list(set(a.split()) & set(b.split())))\n\ndef differencing(a, b):\n    return ' '.join(list(set(a.split()) ^ set(b.split())))\n\n\ndef get_fea(df_fea):\n    print('3gramming')\n    df_fea['q13g'] = df_fea['question1'].apply(lambda x: ngram(x))\n    df_fea['q23g'] = df_fea['question2'].apply(lambda x: ngram(x))        \n    df_fea['inte'] = df_fea[['q13g','q23g']].apply(lambda x: intersecting(*x), axis=1)\n    df_fea['diffe'] = df_fea[['q13g','q23g']].apply(lambda x: differencing(*x), axis=1)    \n    df_fea['q1di'] = df_fea[['q13g','diffe']].apply(lambda x: intersecting(*x), axis=1)    \n    df_fea['q2di'] = df_fea[['q23g','diffe']].apply(lambda x: intersecting(*x), axis=1)        \n        \n    return df_fea.fillna(0.0)\n    \ndf_train = get_fea(train)\n#print(df_train)\nend = time.clock()\nprint('gramming:',len(df_train)*1.0/(end-start))\n\nquestions = train['q13g'].tolist() + train['q23g'].tolist()\ntfidf = TfidfVectorizer( ngram_range=(2, 3))\ntfidf.fit_transform(questions)\n\nprint(tfidf)\n\ndef get_feaT(df_feaT):\n    question1_tfidf = tfidf.transform(df_feaT.q13g.tolist())\n    print('Q1')    \n    question2_tfidf = tfidf.transform(df_feaT.q23g.tolist())    \n    print('Q2')        \n    questionI_tfidf = tfidf.transform(df_feaT.inte.tolist())    \n    questionD_tfidf = tfidf.transform(df_feaT.diffe.tolist()) \n    questionQ1D_tfidf = tfidf.transform(df_feaT.q1di.tolist())    \n    questionQ2D_tfidf = tfidf.transform(df_feaT.q2di.tolist())  \n\n    print('sum mean len....')\n    df_feaT['tfidfSum1'] = scipy.sparse.csr_matrix(question1_tfidf).sum(axis=1)\n    df_feaT['tfidfSum2'] = scipy.sparse.csr_matrix(question2_tfidf).sum(axis=1)\n    df_feaT['tfidfSumI'] = scipy.sparse.csr_matrix(questionI_tfidf).sum(axis=1)   \n    df_feaT['tfidfSumD'] = scipy.sparse.csr_matrix(questionD_tfidf).sum(axis=1)\n    df_feaT['tfidfSum1D'] = scipy.sparse.csr_matrix(questionQ1D_tfidf).sum(axis=1)     \n    df_feaT['tfidfSum2D'] = scipy.sparse.csr_matrix(questionQ2D_tfidf).sum(axis=1)    \n    \n    df_feaT['tfidfMean1'] = scipy.sparse.csr_matrix(question1_tfidf).mean(axis=1)\n    df_feaT['tfidfMean2'] = scipy.sparse.csr_matrix(question2_tfidf).mean(axis=1)\n    df_feaT['tfidfMeanI'] = scipy.sparse.csr_matrix(questionI_tfidf).mean(axis=1)    \n    df_feaT['tfidfMeanD'] = scipy.sparse.csr_matrix(questionD_tfidf).mean(axis=1)    \n    df_feaT['tfidfMean1D'] = scipy.sparse.csr_matrix(questionQ1D_tfidf).mean(axis=1)    \n    df_feaT['tfidfMean2D'] = scipy.sparse.csr_matrix(questionQ2D_tfidf).mean(axis=1)    \n    \n    df_feaT['tfidfLen1'] = (question1_tfidf != 0).sum(axis = 1)\n    df_feaT['tfidfLen2'] = (question2_tfidf != 0).sum(axis = 1)\n    df_feaT['tfidfLenI'] = (questionI_tfidf != 0).sum(axis = 1)\n    df_feaT['tfidfLenD'] = (questionD_tfidf != 0).sum(axis = 1)\n    df_feaT['tfidfLen1D'] = (questionQ1D_tfidf != 0).sum(axis = 1)\n    df_feaT['tfidfLen2D'] = (questionQ2D_tfidf != 0).sum(axis = 1)\n    \n    #(question1_tfidf.getrow())*(question1_tfidf.getrow())\n    print('simil')    \n    df_feaT['sim12'] = df_feaT['id'].apply(lambda i: (question1_tfidf.getrow(i)*question2_tfidf.getrow(i).T).toarray()[0][0])    \n    df_feaT['sim1I'] = df_feaT['id'].apply(lambda i: (question1_tfidf.getrow(i)*questionI_tfidf.getrow(i).T).toarray()[0][0] )      \n    df_feaT['sim1D'] = df_feaT['id'].apply(lambda i: (question1_tfidf.getrow(i)*questionD_tfidf.getrow(i).T).toarray()[0][0]  )      \n    df_feaT['sim2I'] = df_feaT['id'].apply(lambda i: (question2_tfidf.getrow(i)*questionI_tfidf.getrow(i).T).toarray()[0][0]  )      \n    df_feaT['sim2D'] = df_feaT['id'].apply(lambda i: (question2_tfidf.getrow(i)*questionD_tfidf.getrow(i).T).toarray()[0][0]  )          \n    df_feaT['sim11D'] = df_feaT['id'].apply(lambda i: (question1_tfidf.getrow(i)*questionQ1D_tfidf.getrow(i).T).toarray()[0][0] )       \n    df_feaT['sim22D'] = df_feaT['id'].apply(lambda i: (question2_tfidf.getrow(i)*questionQ2D_tfidf.getrow(i).T).toarray()[0][0] )           \n    \n    #df_feaT['cos12'] = df_feaT['id'].apply(lambda i: cosine_similarity(question1_tfidf.getrow(i),question2_tfidf.getrow(i))[0][0]) \n    #df_feaT['cos1I'] = df_feaT['id'].apply(lambda i: cosine_similarity(question1_tfidf.getrow(i),questionI_tfidf.getrow(i))[0][0])      \n    #df_feaT['cos1D'] = df_feaT['id'].apply(lambda i: cosine_similarity(question1_tfidf.getrow(i),questionD_tfidf.getrow(i))[0][0])         \n    print('similD')      \n    #df_feaT['cos2I'] = df_feaT['id'].apply(lambda i: cosine_similarity(question2_tfidf.getrow(i),questionI_tfidf.getrow(i))[0][0])      \n    #df_feaT['cos2D'] = df_feaT['id'].apply(lambda i: cosine_similarity(question2_tfidf.getrow(i),questionD_tfidf.getrow(i))[0][0])          \n    #df_feaT['cos11D'] = df_feaT['id'].apply(lambda i: cosine_similarity(question1_tfidf.getrow(i),questionQ1D_tfidf.getrow(i))[0][0])      \n    #df_feaT['cos22D'] = df_feaT['id'].apply(lambda i: cosine_similarity(question2_tfidf.getrow(i),questionQ2D_tfidf.getrow(i))[0][0])      \n    print('eucl') \n    df_feaT['euc12'] = df_feaT['id'].apply(lambda i: euclidean_distances(question1_tfidf.getrow(i),question2_tfidf.getrow(i))[0][0]) \n    df_feaT['euc1D'] = df_feaT['id'].apply(lambda i: euclidean_distances(question1_tfidf.getrow(i),questionD_tfidf.getrow(i))[0][0])         \n    df_feaT['euc2D'] = df_feaT['id'].apply(lambda i: euclidean_distances(question2_tfidf.getrow(i),questionD_tfidf.getrow(i))[0][0])         \n    print('svd')     \n    svd = TruncatedSVD(n_components=20, n_iter=30, random_state=42)\n    tempi=pd.DataFrame(svd.fit_transform(questionI_tfidf))\n    tempi.rename(columns=lambda x: str(x)+'_i', inplace=True) #nog eens zoeken omcolumns te renamen\n    df_feaT=df_feaT.join(tempi,how='inner')\n    print('tempi',tempi.shape)\n    \n    svd = TruncatedSVD(n_components=20, n_iter=30, random_state=42)\n    tempd=pd.DataFrame(svd.fit_transform(questionD_tfidf))\n    tempd.rename(columns=lambda x: str(x)+'_d', inplace=True) #nog eens zoeken omcolumns te renamen\n    df_feaT=df_feaT.join(tempd,how='inner')\n    print('tempd',tempd.shape)\n    \n    return df_feaT\n\ndf_train = get_feaT(df_train)\nend = time.clock()\nprint('tfidf-sim:',len(df_train)*1.0/(end-start))\n\nprint(df_train.head(10))\n\ny=train['is_duplicate']        \nfeats = df_train.columns.values.tolist()\nfeats=[x for x in feats if x not in ['question1','question2','q13g','q23g','inte','diffe','q1di','q2di','id','qid1','qid2','is_duplicate']]\nprint(\"features\",feats)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"faa29386-22a3-0ae9-0332-a72d8a175b3b"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nimport scipy\nimport xgboost as xgb\nimport difflib\n\nx_train, x_valid, y_train, y_valid = train_test_split(df_train[feats], y, test_size=0.1, random_state=0)\n#XGBoost model\nparams = {\"objective\":\"binary:logistic\",'eval_metric':'logloss',\"max_depth\":7}\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\nbst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=200,verbose_eval=25) #change to higher #s\nprint('training done')\n\nprint(\"log loss for training data set\",log_loss(y, bst.predict(xgb.DMatrix(df_train[feats]))))\n#Predicting for test data set\nsub = pd.DataFrame() # Submission data frame\nsub['test_id'] = []\nsub['is_duplicate'] = []\nheader=['test_id','question1','question2','id','qid1','qid2','is_duplicate']\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14748d2a-6e47-958a-4539-c63277af35c2"},"outputs":[],"source":"sub = pd.DataFrame() # Submission data frame\nsub['test_id'] = []\nsub['is_duplicate'] = []\nheader=['test_id','question1','question2','id','qid1','qid2','is_duplicate']\ntest=pd.read_csv('../input/test.csv')[:10000].fillna(\"\")\ntest.columns=['id','question1','question2']\n\nprint(\"cleaning test\")\ndf_test=cleanup(test)\nprint('cleaned',df_test.head())\ndf_test = get_fea(df_test)\ndf_test = get_feaT(df_test)\nprint('engineered',df_test.head())\n\nsub=pd.DataFrame({'test_id':df_test['id'], 'is_duplicate':bst.predict(xgb.DMatrix(df_test[feats]))})\nprint(sub.head())\n\nsub.to_csv('../quora_submission_svd_xgb.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}