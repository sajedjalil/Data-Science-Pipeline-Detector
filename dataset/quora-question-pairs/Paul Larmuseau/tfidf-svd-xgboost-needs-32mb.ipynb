{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"578452b5-ef7c-f147-192b-db843175ea6e"},"source":"Its a rather pure model\n-----\n\nYou do a TFIDF on the Q1, Q2, intersection, and difference\nThan we compact the TFIDF matrix with SVD.\nIt runs very fast, except with the big testfile you have to parse the fitting"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ec4a4e5-b2b6-afa7-87bd-83b136aef4c1"},"outputs":[],"source":"import numpy as np \nimport pandas as pd \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nimport scipy\nimport xgboost as xgb\nimport difflib\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.metrics import jaccard_distance\n\n\n#Reading and processing of data\ntrain=pd.read_csv('../input/train.csv')[:20000].fillna(\"\")\n#train=pd.read_csv('../input/train.csv').dropna()\nstops = set(stopwords.words(\"english\"))\ny=train['is_duplicate']\ntrain=train.drop(['id', 'qid1', 'is_duplicate','qid2'], axis=1)\n\n#Cleaning up the data\n#Removing ? mark and non ASCII characters\ndef cleanup(data):\n    data['question1'] = data['question1'].apply(lambda x: x.rstrip('?'))\n    data['question2'] = data['question2'].apply(lambda x: x.rstrip('?'))\n    # Removing non ASCII chars\n    data['question1']=data['question1'].apply(lambda x: x.replace(r'[^\\x00-\\x7f]',r' '))\n    data['question2']=data['question2'].apply(lambda x: x.replace(r'[^\\x00-\\x7f]',r' ')) \n    # Pad punctuation with spaces on both sides\n    '''\n    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n        x = x.replace(char, ' ' + char + ' ')\n    '''\n    return data\n\nquestions = train['question1'].tolist() + train['question2'].tolist()\ntrain=cleanup(train)\nprint(train.head())"},{"cell_type":"markdown","metadata":{"_cell_guid":"ecfbb0c7-04ca-bafd-b023-720efa3c65bc"},"source":"TFIDF\n----\n4 matrixes= Q1,Q2,intersection, and difference\n\nSVD\n---\nCompress TFIDF and find singular values."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0b1b59f-8932-b821-5581-2d3f89eb5adc"},"outputs":[],"source":"from sklearn.metrics.pairwise import cosine_similarity,euclidean_distances,laplacian_kernel,sigmoid_kernel,polynomial_kernel,rbf_kernel\nfrom sklearn.decomposition import TruncatedSVD\n\ndef intersecting(a, b):\n    return ' '.join(list(set(a.split()) & set(b.split())))\n\ndef differencing(a, b):\n    return ' '.join(list(set(a.split()) ^ set(b.split())))\n\ntfidf = TfidfVectorizer( ngram_range=(1, 3))\ntfidf.fit_transform(questions)\n#print(tfidf.vocabulary_)\n\ndef get_features(df_features):    \n    df_features['interseq'] = df_features[['question1','question2']].apply(lambda x: intersecting(*x), axis=1)\n    df_features['diffseq'] = df_features[['question1','question2']].apply(lambda x: differencing(*x), axis=1)    \n    df_features['q1d'] = df_features[['question1','diffseq']].apply(lambda x: intersecting(*x), axis=1)    \n    df_features['q2d'] = df_features[['question2','diffseq']].apply(lambda x: intersecting(*x), axis=1)        \n    \n    print('tfidf')    \n    question1_tfidf = tfidf.transform(df_features.question1.tolist())\n    question2_tfidf = tfidf.transform(df_features.question2.tolist())    \n    questionI_tfidf = tfidf.transform(df_features.interseq.tolist())    \n    questionD_tfidf = tfidf.transform(df_features.diffseq.tolist()) \n    questionQ1D_tfidf = tfidf.transform(df_features.q1d.tolist())    \n    questionQ2D_tfidf = tfidf.transform(df_features.q2d.tolist()) \n    print(question1_tfidf.shape)\n        \n    print('SVD')\n    svd = TruncatedSVD(n_components=30)\n    df_features=df_features.join(pd.DataFrame(svd.fit_transform(questionI_tfidf)),how='inner')\n    print(svd.explained_variance_ratio_)\n    print(svd.get_params(deep=True))\n    \n    svd = TruncatedSVD(n_components=30)\n    temp=pd.DataFrame(svd.fit_transform(questionD_tfidf))\n    temp.rename(columns=lambda x: str(x)+'_d', inplace=True) #nog eens zoeken omcolumns te renamen\n    df_features=df_features.join(temp,how='inner')  \n\n    \n    svd = TruncatedSVD(n_components=30)\n    temp=pd.DataFrame(svd.fit_transform(question1_tfidf))\n    temp.rename(columns=lambda x: str(x)+'_q1', inplace=True) #nog eens zoeken omcolumns te renamen\n    df_features=df_features.join(temp,how='inner') \n\n    print(temp.shape)\n    \n    svd = TruncatedSVD(n_components=30)\n    temp=pd.DataFrame(svd.fit_transform(question2_tfidf))\n    temp.rename(columns=lambda x: str(x)+'_q2', inplace=True) #nog eens zoeken omcolumns te renamen\n    df_features=df_features.join(temp,how='inner')     \n \n    svd = TruncatedSVD(n_components=30)\n    temp=pd.DataFrame(svd.fit_transform(questionQ1D_tfidf))\n    temp.rename(columns=lambda x: str(x)+'_q1d', inplace=True) #nog eens zoeken omcolumns te renamen\n    df_features=df_features.join(temp,how='inner')   \n    \n    svd = TruncatedSVD(n_components=30)\n    temp=pd.DataFrame(svd.fit_transform(questionQ2D_tfidf))\n    temp.rename(columns=lambda x: str(x)+'_q2d', inplace=True) #nog eens zoeken omcolumns te renamen\n    df_features=df_features.join(temp,how='inner')   \n    \n    return df_features.fillna(0.0)\n\n\n\ndf_train = get_features(train)\nfeats = df_train.columns.values.tolist()\nfeats=[x for x in feats if x not in ['question1','question2','Q1seq','Q2seq','q1d','q2d','interseq','diffseq','id','qid1','qid2','is_duplicate']]\nprint(\"features\",feats)\nprint(df_train.head())"},{"cell_type":"markdown","metadata":{"_cell_guid":"69c1a6e4-fc36-8db2-52e4-372ecd37b256"},"source":"XGBoost train the data\n----"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70ef8577-60b7-183a-d841-a7e74dc27ac9"},"outputs":[],"source":"x_train, x_valid, y_train, y_valid = train_test_split(df_train[feats], y, test_size=0.3, random_state=0)\n#XGBoost model\nparams = {\"objective\":\"binary:logistic\",'eval_metric':'logloss',\"eta\": 0.11,\n          \"subsample\":0.7,\"min_child_weight\":1,\"colsample_bytree\": 0.7,\n          \"max_depth\":5,\"silent\":1,\"seed\":2017}\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\nbst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=200,verbose_eval=25) #change to higher #s\nprint('training done')\n\nprint(\"log loss for training data set\",log_loss(y, bst.predict(xgb.DMatrix(df_train[feats]))))\n#Predicting for test data set\nsub = pd.DataFrame() # Submission data frame\nsub['test_id'] = []\nsub['is_duplicate'] = []\nheader=['test_id','question1','question2','id','qid1','qid2','is_duplicate']\ntest=pd.read_csv('../input/test.csv')[:20000].fillna(\"\")\nprint(\"cleaning test\")\ndf_test=cleanup(test)\nprint(\"feature engineering for test\")\ndf_test = get_features(df_test)\nsub=pd.DataFrame({'test_id':df_test['test_id'], 'is_duplicate':bst.predict(xgb.DMatrix(df_test[feats]))})\nsub.to_csv('quora_submission_xgb_11.csv', index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f4848cee-3bb6-ba43-f94c-5c1d12e593f5"},"source":"[1825]\ttrain-logloss:0.305957\tvalid-logloss:0.420252\n[1850]\ttrain-logloss:0.304641\tvalid-logloss:0.420013\n[1875]\ttrain-logloss:0.30305\tvalid-logloss:0.419738\n[1900]\ttrain-logloss:0.301473\tvalid-logloss:0.419478\n[1925]\ttrain-logloss:0.299964\tvalid-logloss:0.41919"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}