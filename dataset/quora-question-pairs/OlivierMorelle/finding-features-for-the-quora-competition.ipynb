{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"5604d949-2583-8d43-82fd-64fffd97024c"},"source":"The Quora competition is my first competition"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0cf0ab31-d8b2-4924-f045-e78b0d1d0a82"},"outputs":[],"source":"# data analysis\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"48b16f7e-4a63-6fdc-b026-ea51e7c8107a"},"outputs":[],"source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\ncombine = [train_df, test_df]\ntrain_df[train_df.isnull().values]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"243f4d7e-ee7b-c9e9-ea5c-778d338904d0"},"outputs":[],"source":"train_df = train_df.drop([105780, 201841])\ntrain_df[train_df.isnull().values]\ntrain_df.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"80a10333-9c8d-7d42-1124-9ca0181b8f45"},"source":"For two question pairs there was only one question given. Those question pairs were droped from the training data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb9e496b-1ea3-20b0-d905-0c6db14ccd5e"},"outputs":[],"source":"test_df.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ac9a66e0-0062-752e-0055-6359565d383d"},"source":"# Normalize the questions"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98974f30-f874-29f5-7667-61c0b5eefb51"},"outputs":[],"source":"from nltk.corpus import stopwords\nfrom nltk.stem.snowball import EnglishStemmer\nfrom nltk.stem import RegexpStemmer\nfrom nltk.stem import LancasterStemmer\n\nimport string\nstops = set(stopwords.words(\"english\"))\n\ndef normalize_question(question, stopwords_remove=True, stem=True, \n                       punctuation_remove=True, stem_method='default'):\n    \n    # Remove punctuation\n    if punctuation_remove:\n        question = question.translate(str.maketrans(\"\",\"\",string.punctuation))\n    \n    words = question.lower().split()\n    # Remove stopwords\n    if stopwords_remove:\n        words = [w for w in words if w not in stops]\n        \n    # Stem the words\n    if stem:\n        if stem_method == 'default':\n            st = EnglishStemmer()        \n        elif stem_method == 'snowball':\n            st = EnglishStemmer()            \n        elif stem_method == 'lancaster':\n            st = LancasterStemmer()        \n        elif stem_method == 'regexp':\n             st = RegexpStemmer()\n        else:\n            print('Enter a valid expression for stem_method.')      \n\n        words = [st.stem(w) for w in words]\n        \n    return ' '.join(words)\n\n\ndef get_word_match(row):\n    count = 0\n    set2 = set(row['question2'].split())\n    for w in set(row['question1'].split()):\n        if w in set2:\n            count += 1\n    return count   \n\n\ndef get_combined_word_set_length(row):\n    # The more equal words two questions have the smaller is the resulting\n    # set as they do not add up.\n    return len(set(row['question1'].split()) + set(row['question2'].split()))\n\n\n# Replace negations with antonyms\n\n# Run a spellchecker - autocorrection\n\n# Lemmatize instead of stemming\n\n# Calculate hight information words (tf-itf)\n\n# Calculate word similarities using wordnet\nfrom nltk.corpus import wordnet"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e66ee028-49b8-9c82-4ddb-34f219427eb6"},"outputs":[],"source":"train_df['question1'] = [normalize_question(q) for q in train_df['question1']]\ntrain_df['question2'] = [normalize_question(q) for q in train_df['question2']]\ntrain_df['word_match'] = [get_word_match(row) for index, row in train_df.iterrows()]\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88e7b129-748f-a8b1-02d6-4884e2e02783"},"outputs":[],"source":"X_train = train_df.drop([\"is_duplicate\",'id', 'qid1', 'qid2','question1','question2'], axis=1)\nY_train = train_df[\"is_duplicate\"]\nX_test  = test_df.drop(\"test_id\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8ef20bf6-2992-53fa-6a47-ccb0257ed894"},"outputs":[],"source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\n#Y_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}