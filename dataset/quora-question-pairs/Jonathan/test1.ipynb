{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c13b7f5-9318-4874-7a64-b0e0ee1a69b5"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom difflib import SequenceMatcher\n\n\nfrom nltk.corpus import stopwords\nstops = set(stopwords.words(\"english\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed830bda-5b1f-d869-d759-9f1dcf13d8ac"},"outputs":[],"source":"## Training set\ntrain_df = pd.read_csv('../input/train.csv', nrows=1000)\n\n## Test Set\",\ntest_df = pd.read_csv('../input/test.csv', nrows=1000)\n\ntrain_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1e1f839-a6c4-c1bb-2fc6-5e8ddf528af2"},"outputs":[],"source":"def word_match_share(row):\n    q1words = {}\n    q2words = {}\n    for word in str(row['question1']).lower().split():\n        if word not in stops:\n            q1words[word] = 1\n    for word in str(row['question2']).lower().split():\n        if word not in stops:\n            q2words[word] = 1\n    if len(q1words) == 0 or len(q2words) == 0:\n        # The computer-generated chaff includes a few questions that are nothing but stopwords\n        return 0\n    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n    return R"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"193aa9db-156d-fda8-545b-811c222357a8"},"outputs":[],"source":"from collections import Counter\n# If a word appears only once, we ignore it completely (likely a typo)\n# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n\ndef get_weight(count, eps=10000, min_count=2):\n    if count < min_count:\n        return 0\n    else:\n        return 1 / (count + eps)\n\neps = 5000 \ntrain_qs = pd.Series(train_df['question1'].tolist() + train_df['question2'].tolist()).astype(str)\nwords = (\" \".join(train_qs)).lower().split()\ncounts = Counter(words)\nweights = {word: get_weight(count) for word, count in counts.items()}"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8796293e-6a23-00c0-aff1-c03161c62294"},"outputs":[],"source":"def tfidf_word_match_share(row):\n    q1words = {}\n    q2words = {}\n    for word in str(row['question1']).lower().split():\n        if word not in stops:\n            q1words[word] = 1\n    for word in str(row['question2']).lower().split():\n        if word not in stops:\n            q2words[word] = 1\n    if len(q1words) == 0 or len(q2words) == 0:\n        # The computer-generated chaff includes a few questions that are nothing but stopwords\n        return 0\n    \n    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n    \n    R = np.sum(shared_weights) / np.sum(total_weights)\n    return R"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0369a399-2119-526e-92f9-a5c996d79d81"},"outputs":[],"source":"def stop_ratio(question):\n    q = set(question)\n    if len(q) == 0:\n        return 0\n    qwords = q.difference(stops)\n    qstops = q.intersection(stops)\n    return len(qstops) / len(q)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23755709-876d-5375-2600-9fbb425b89a7"},"outputs":[],"source":"def uniq1_ratio(row):\n    uniq_1 = set(row[\"question1\"].lower().replace(\" \",\"\"))\n    uniq_2 = set(row[\"question2\"].lower().replace(\" \",\"\"))\n    return len(uniq_1) / len(uniq_1 | uniq_2)\n\ndef uniq2_ratio(row):\n    uniq_1 = set(row[\"question1\"].lower().replace(\" \",\"\"))\n    uniq_2 = set(row[\"question2\"].lower().replace(\" \",\"\"))\n    return len(uniq_2) / len(uniq_1 | uniq_2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93395a87-f27d-c6c0-dca0-f946be5e44c0"},"outputs":[],"source":"def create_features(df):\n    df[\"question1\"].fillna(\"\", inplace=True)\n    df[\"question2\"].fillna(\"\", inplace=True)\n\n    df[\"question1\"] = df[\"question1\"].apply(str)\n    df[\"question2\"] = df[\"question2\"].apply(str)\n    \n    print(\"len\")\n    df[\"q1_len\"] = df[\"question1\"].apply(len)\n    df[\"q2_len\"] = df[\"question1\"].apply(len)\n    df[\"diff_len\"] = abs(df[\"q1_len\"] - df[\"q2_len\"])\n    \n    print(\"len word\")\n    df[\"q1_len_word\"] = df[\"question1\"].apply(lambda x: len(x.split()))\n    df[\"q2_len_word\"] = df[\"question1\"].apply(lambda x: len(x.split()))\n    df[\"diff_len_word\"] = abs(df[\"q1_len_word\"] - df[\"q2_len_word\"])\n    \n    print(\"avg len word\")\n    df['q1_avg_len_word'] = df['q1_len'] / df['q1_len_word']\n    df['q2_avg_len_word'] = df['q2_len'] / df['q2_len_word']\n    df['diff_avg_len_word'] = abs(df['q1_avg_len_word'] - df['q2_avg_len_word'])\n    \n    print(\"unique char\")\n    df[\"q1_n_uniquechar\"] = df[\"question1\"].apply(lambda x: len(\"\".join(set(x.replace(\" \",\"\")))))\n    df[\"q2_n_uniquechar\"] = df[\"question2\"].apply(lambda x: len(\"\".join(set(x.replace(\" \",\"\")))))\n    df[\"diff_n_uniquechar\"] = abs(df[\"q1_n_uniquechar\"] - df[\"q2_n_uniquechar\"])\n\n    print(\"W word\")\n    df[\"q1_how\"]   = df[\"question1\"].apply(lambda x : \"how\"   in x.lower())\n    df[\"q1_who\"]   = df[\"question1\"].apply(lambda x : \"who\"   in x.lower())\n    df[\"q1_why\"]   = df[\"question1\"].apply(lambda x : \"why\"   in x.lower())\n    df[\"q1_what\"]  = df[\"question1\"].apply(lambda x : \"what\"  in x.lower())\n    df[\"q1_where\"] = df[\"question1\"].apply(lambda x : \"where\" in x.lower())\n    df[\"q1_which\"] = df[\"question1\"].apply(lambda x : \"which\" in x.lower())\n\n    df[\"q2_how\"]   = df[\"question2\"].apply(lambda x : \"how\"   in x.lower())\n    df[\"q2_who\"]   = df[\"question2\"].apply(lambda x : \"who\"   in x.lower())\n    df[\"q2_why\"]   = df[\"question2\"].apply(lambda x : \"why\"   in x.lower())\n    df[\"q2_what\"]  = df[\"question2\"].apply(lambda x : \"what\"  in x.lower())\n    df[\"q2_where\"] = df[\"question2\"].apply(lambda x : \"where\" in x.lower())\n    df[\"q2_which\"] = df[\"question2\"].apply(lambda x : \"which\" in x.lower())\n    \n    df[\"q1q2_how\"]   = df[\"q1_how\"]   == df[\"q2_how\"]\n    df[\"q1q2_who\"]   = df[\"q1_who\"]   == df[\"q2_who\"]\n    df[\"q1q2_why\"]   = df[\"q1_why\"]   == df[\"q2_why\"]\n    df[\"q1q2_what\"]  = df[\"q1_what\"]  == df[\"q2_what\"]\n    df[\"q1q2_where\"] = df[\"q1_where\"] == df[\"q2_where\"]\n    df[\"q1q2_which\"] = df[\"q1_which\"] == df[\"q2_which\"]\n    \n    print(\"stop ratio\")\n    df[\"q1_stop_ratio\"] = df[\"question1\"].apply(stop_ratio)\n    df[\"q2_stop_ratio\"] = df[\"question2\"].apply(stop_ratio)\n    df[\"diff_stop_ratio\"] = abs(df[\"q1_stop_ratio\"] - df[\"q2_stop_ratio\"])\n\n    print(\"math\")\n    df[\"q1_math\"] = df[\"question1\"].apply(lambda x: '[math]' in x)\n    df[\"q2_math\"] = df[\"question2\"].apply(lambda x: '[math]' in x)\n    df[\"q1q2_math\"] = df[\"q1_math\"] == df[\"q2_math\"]\n    \n    print(\"nqmark\")\n    df[\"q1_nqmark\"] = df[\"question1\"].apply(lambda x: x.count('?'))\n    df[\"q2_nqmark\"] = df[\"question2\"].apply(lambda x: x.count('?'))\n    df[\"diff_nqmark\"] = abs(df[\"q1_nqmark\"] - df[\"q2_nqmark\"])\n    \n    print(\"nperiod\")\n    df[\"q1_nperiod\"] = df[\"question1\"].apply(lambda x: x.count('.'))\n    df[\"q2_nperiod\"] = df[\"question2\"].apply(lambda x: x.count('.'))\n    df[\"diff_nperiod\"] = abs(df[\"q1_nperiod\"] - df[\"q2_nperiod\"])\n\n    print(\"capitalfirst\")\n    df[\"q1_capitalfirst\"] = df[\"question1\"].apply(lambda x: x[0].isupper() if len(x) > 0 else False)\n    df[\"q2_capitalfirst\"] = df[\"question2\"].apply(lambda x: x[0].isupper() if len(x) > 0 else False)\n    df[\"q1q2_capitalfirst\"] = df[\"q1_capitalfirst\"] == df[\"q2_capitalfirst\"]\n\n    print(\"has capital\")\n    df[\"q1_has_capital\"] = df[\"question1\"].apply(lambda x: any([l.isupper() for l in x]))\n    df[\"q2_has_capital\"] = df[\"question2\"].apply(lambda x: any([l.isupper() for l in x]))\n    df[\"q1q2_has_capital\"] = df[\"q1_has_capital\"] == df[\"q2_has_capital\"]\n\n    print(\"n capitals\")\n    df[\"q1_n_capitals\"] = df[\"question1\"].apply(lambda x: sum([1 for c in x if c.isupper()]))\n    df[\"q2_n_capitals\"] = df[\"question2\"].apply(lambda x: sum([1 for c in x if c.isupper()]))\n    df[\"diff_n_capitals\"] = abs(df[\"q1_n_capitals\"] - df[\"q2_n_capitals\"])\n    \n    print(\"is identical\")\n    df[\"is_identical\"] = (df[\"question1\"].apply(lambda x: x.lower()) == df[\"question2\"].apply(lambda x: x.lower()))    \n\n    print(\"unique ratio\")\n    df[\"q1_unique_ratio\"] = df.apply(uniq1_ratio ,axis=1)\n    df[\"q2_unique_ratio\"] = df.apply(uniq2_ratio ,axis=1)\n\n    #df[\"similarity_prob\"] = df.apply(lambda row: SequenceMatcher(None, row[\"question1\"],row[\"question2\"]).ratio(),axis=1)\n    \n    print(\"text prop\")\n    df[\"q1_isalnum\"]   =  df[\"question1\"].apply(lambda x: x.isalnum())\n    df[\"q1_isalpha\"]   =  df[\"question1\"].apply(lambda x: x.isalpha())\n    df[\"q1_isdecimal\"] =  df[\"question1\"].apply(lambda x: x.isdecimal())\n    df[\"q1_isdigit\"]   =  df[\"question1\"].apply(lambda x: x.isdigit())\n    df[\"q1_islower\"]   =  df[\"question1\"].apply(lambda x: x.islower())\n    df[\"q1_isnumeric\"] =  df[\"question1\"].apply(lambda x: x.isnumeric())\n    df[\"q1_isspace\"]   =  df[\"question1\"].apply(lambda x: x.isspace())\n    df[\"q1_isupper\"]   =  df[\"question1\"].apply(lambda x: x.isupper())\n    \n    df[\"q2_isalnum\"]   =  df[\"question2\"].apply(lambda x: x.isalnum())\n    df[\"q2_isalpha\"]   =  df[\"question2\"].apply(lambda x: x.isalpha())\n    df[\"q2_isdecimal\"] =  df[\"question2\"].apply(lambda x: x.isdecimal())\n    df[\"q2_isdigit\"]   =  df[\"question2\"].apply(lambda x: x.isdigit())\n    df[\"q2_islower\"]   =  df[\"question2\"].apply(lambda x: x.islower())\n    df[\"q2_isnumeric\"] =  df[\"question2\"].apply(lambda x: x.isnumeric())\n    df[\"q2_isspace\"]   =  df[\"question2\"].apply(lambda x: x.isspace())\n    df[\"q2_isupper\"]   =  df[\"question2\"].apply(lambda x: x.isupper())\n    \n    df[\"q1q2_isalnum\"]   = df[\"q1_isalnum\"]   == df[\"q2_isalnum\"]\n    df[\"q1q2_isalpha\"]   = df[\"q1_isalpha\"]   == df[\"q2_isalpha\"]\n    df[\"q1q2_isdecimal\"] = df[\"q1_isdecimal\"] == df[\"q2_isdecimal\"]\n    df[\"q1q2_isdigit\"]   = df[\"q1_isdigit\"]   == df[\"q2_isdigit\"]\n    df[\"q1q2_islower\"]   = df[\"q1_islower\"]   == df[\"q2_islower\"]\n    df[\"q1q2_isnumeric\"] = df[\"q1_isnumeric\"] == df[\"q2_isnumeric\"]\n    df[\"q1q2_isspace\"]   = df[\"q1_isspace\"]   == df[\"q2_isspace\"]\n    df[\"q1q2_isupper\"]   = df[\"q1_isupper\"]   == df[\"q2_isupper\"]\n    \n    print(\"word share\")\n    df[\"word_match_share\"] = df.apply(lambda row: word_match_share(row), axis=1)\n    df[\"tfidf_word_match_share\"] = df.apply(lambda row: tfidf_word_match_share(row), axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"926d83c5-4740-bdb4-1251-976bf7b5cb3f"},"outputs":[],"source":"plt.figure()\nplt.hist(train_df[train_df[\"is_duplicate\"]==0][\"tfidf_word_match_share\"],bins=100,range=(0,1),alpha=0.5,normed=True)\nplt.hist(train_df[train_df[\"is_duplicate\"]==1][\"tfidf_word_match_share\"],bins=100,range=(0,1),alpha=0.5,normed=True)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dec76cfc-8f32-6dfe-bc54-e487e311fe2a"},"outputs":[],"source":"# bag of letter sequences (chars)\nBagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=1000, max_features=300, \n                                      analyzer='char', ngram_range=(1,2),\n                                      binary=True, lowercase=True)\n\nBagOfWordsExtractor.fit(train_qs.unique())\n\ntrainQuestion1_BOW_rep = BagOfWordsExtractor.transform(train_df.ix[:,'question1'])\ntrainQuestion2_BOW_rep = BagOfWordsExtractor.transform(train_df.ix[:,'question2'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff5f0a19-8a69-95b0-f886-851c26531cc8"},"outputs":[],"source":"X = (trainQuestion1_BOW_rep + trainQuestion2_BOW_rep).astype(int)/2.\nprint(X[0].todense())\nprint(X.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4348611f-5e31-a7ff-348b-3b4d8cd2c53c"},"outputs":[],"source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Merge, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom keras.preprocessing.sequence import pad_sequences"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d1af746-e125-5e27-9976-6eb50cbc06bf"},"outputs":[],"source":"model = Sequential()\nmodel.add(Dense(X.shape[1], input_dim=X.shape[1]))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam')\n\nhistory = model.fit(X.toarray(),train_df.is_duplicate.values,\n                    batch_size=1,\n                    epochs=20,\n                    validation_split=0.2)\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}