{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor\nfrom sklearn.model_selection import KFold\nfrom catboost import CatBoostRegressor\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.neural_network import MLPRegressor\nfrom catboost import CatBoost, Pool\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.preprocessing import RobustScaler,PowerTransformer,QuantileTransformer,Normalizer,MinMaxScaler\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')\ntest  = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')\nsub = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv')\nsoumaya_sub = pd.read_csv('../input/soumaya-sub/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = [col for col in train.columns.to_list() if col not in ['id','target']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Xgboost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"param1={'tree_method':'gpu_hist','lambda': 0.0045523892919572, 'alpha': 0.005803668702291496,\n            'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 0.007, 'max_depth': 20,\n            'random_state': 24, 'min_child_weight': 264,'n_estimators': 8200}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1 = np.zeros(test.shape[0])\nkf = KFold(n_splits=12,random_state=48,shuffle=True)\nrmse=[]  ## list contains rmse for each fold\nn=0\nfor trn_idx, test_idx in kf.split(train[columns],train['target']):\n    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n    y_tr,y_val=train['target'].iloc[trn_idx],train['target'].iloc[test_idx]\n    model = xgb.XGBRegressor(**param1)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    preds1+=model.predict(test[columns])/kf.n_splits\n    rmse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n    print(n+1,rmse[n])\n    n+=1  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Xgb results : \n* CV = 0.69537\n* LB result = 0.69712\n* Private = 0.69608"},{"metadata":{},"cell_type":"markdown","source":"## lgb model"},{"metadata":{"trusted":true},"cell_type":"code","source":"param2={'metric': 'rmse','lambda_l1': 6.177646935770319, 'lambda_l2': 8.267630169831212e-05, \n            'min_sum_hessian_in_leaf': 0.06121961712341018, 'min_data_in_leaf': 17, 'num_leaves': 256,'max_bin':456,\n            'feature_fraction': 0.4808176760171774, 'bagging_fraction': 0.8799188937155665, 'learning_rate': 0.005, \n            'bagging_freq': 1, 'n_estimators': 15898, 'max_depth': 120, 'min_data_per_group': 53, 'random_state': 100, 'cat_smooth': 23}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2 = np.zeros(test.shape[0])      \nkf = KFold(n_splits=12,random_state=48,shuffle=True)   \nrmse=[]     ## list contains rmse for each fold\nn=0\nfor trn_idx, test_idx in kf.split(train[columns],train['target']): \n    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n    y_tr,y_val=train['target'].iloc[trn_idx],train['target'].iloc[test_idx] \n    lgb = LGBMRegressor(**param2)\n    lgb.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=False)\n    preds2+=lgb.predict(test[columns])/kf.n_splits\n    rmse.append(mean_squared_error(y_val, lgb.predict(X_val), squared=False))\n    print(n+1,rmse[n])    \n    n+=1    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Xgb results : \n* CV = 0.69494\n* LB result = 0.69696\n* Private = 0.69564"},{"metadata":{},"cell_type":"markdown","source":"## Notes :\n* I use ensemble of xgb and lgb (0.4xgb+0.6lgb) which gives me : LB result =  0.69686 and Private = 0.69565 !!! ğŸ¤·â€\n* the LB score improoved ğŸ˜€ but the private nope ğŸ˜•\n* I used also the output of [Somayyeh](https://www.kaggle.com/somayyehgholami) public kernel [LB result = 0.69652 and Private = 0.69529] and make ensemble with my work. [kernel of Somayyeh](https://www.kaggle.com/somayyehgholami/results-driven-tabular-playground-series-201).\n* So my final submission was : 0.18 * lgb_output + 0.12 * xgb_output + 0.7 * soumayyeh_submission ==> \nLB result =  0.69648 and Private = 0.69525 ğŸ„ğŸ¾â€â™‚ï¸"},{"metadata":{},"cell_type":"markdown","source":"##  This result ranked me 11/1728 in this competition ğŸ„ğŸ½â€â™‚ï¸\n## I shouldn't forget to thank [Somayyeh](https://www.kaggle.com/somayyehgholami) ğŸ‘ğŸ‘ğŸ‘"},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=0.18*preds1+0.12*preds2+0.7*soumaya_sub['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}