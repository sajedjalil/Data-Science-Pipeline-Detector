{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this notebook, we are going to see if one of the classes of Auto ML tools (namely, Rapid EDA Automation tools) can be effectively used on the problems/datasets of a type proposed to tackle in this competition.\n\nFor future experiments, we are going to use *AutoViz* (https://github.com/AutoViML/AutoViz).\n\nAutoViz stands out of the crowd of freeware Pythonic Rapid EDA Automation tools, doing things in a very fast way, the way better than its close freeware rivals like *SweetViz* or *Pandas Profiling*\n\n*Notes:* \n\n- You can find the motivation of why I try to use AutoViz, when feasible, in one of my earlier case studies per https://www.kaggle.com/c/lish-moa/discussion/190647 \n- I also put a few references to the blog posts about AutoViz in the *References* Section at the bottom of this notebook"},{"metadata":{},"cell_type":"markdown","source":"# Preparation Activities\n\nFirst of all, we are going to do a few usual preparation steps\n\n- install the latest stable version of AutoViz\n- import the packages we need to work with in the course of the current analytical effort\n- read the competion data in memory for future manipulations"},{"metadata":{"trusted":true,"collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install git+git://github.com/AutoViML/AutoViz.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as dt\nfrom typing import Tuple\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.offline\n\n\n# read data\nin_kaggle = True\n\n\ndef get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n    train_path = ''\n    test_path = ''\n    sample_submission_path = ''\n\n    if is_in_kaggle:\n        # running in Kaggle, inside the competition\n        train_path = '../input/tabular-playground-series-jan-2021/train.csv'\n        test_path = '../input/tabular-playground-series-jan-2021/test.csv'\n        sample_submission_path = '../input/tabular-playground-series-jan-2021/sample_submission.csv'\n    else:\n        # running locally\n        train_path = 'data/train.csv'\n        test_path = 'data/test.csv'\n        sample_submission_path = 'data/sample_submission.csv'\n\n    return train_path, test_path, sample_submission_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# main flow\nstart_time = dt.datetime.now()\nprint(\"Started at \", start_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# get the training set and labels\ntrain_set_path, test_set_path, sample_subm_path = get_data_file_path(in_kaggle)\n\ndf_train = pd.read_csv(train_set_path)\ndf_test = pd.read_csv(test_set_path)\n\nsubm = pd.read_csv(sample_subm_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before running the AutoViz-based EDA discoveries, we will check the basic info about our training dataset (records count, data types of variables, % of missing values etc.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# AutoViz-based EDA\n\nNow we are ready to set up an AutoViz-based EDA discovery - it is as simple as the code fragment below\n\n*Note*: You can check the documentation at https://github.com/AutoViML/AutoViz , *Usage* section, for more information of each of the attributes used in *AV.AutoViz* method invokation."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom autoviz.AutoViz_Class import AutoViz_Class\n\nAV = AutoViz_Class()\ndftc = AV.AutoViz(\n    filename='', \n    sep='' , \n    depVar='target', \n    dfte=df_train, \n    header=0, \n    verbose=1, \n    lowess=False, \n    chart_format='png', \n    max_rows_analyzed=300000, \n    max_cols_analyzed=30\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, as we can see, it took it a few minutes to actually run the EDA discovery flow as well as generate the relevant data visualization charts (105 charts generated in fact). \n\nThen, in 20 min, I could review the charts to quickly grasp on the data-driven insights below\n\n- there are no missing values for any of the feature variables in any observations in the training set\n- most of the feature variables are polynomially distributed\n- values of *count5* variable seem to be extremely skewed\n- there are potential outliers in the training set with values of *target* below 5 (so it could be reasonable to drop such records from the training set down the road, as a part of the respective ML experiments)\n- there is a set of highly correlated features detected (these are *count1*, *count6*, *count9*, and *count10* variables, namely) - we may want to drop all of them but one with the highest absolute value of the correlation coefficient vs. *target* (it seems to be *count1* in fact)\n- there are also some other pairs of highly correlated features detected (*count6* and *count11*, *count6* and *count12*), and dropping *count6* from the training set could resolve such a correlation issue with such feature pairs down the road in ML experiments\n- *count11* and *count12* are also highly correlated so we may want to leave just one of them in the training set during the ML experiments down the road (retaining *count11* seems to be a better option though as it has higher absolute value of the correlation coefficient vs. *target*)\n- *count2* and *count14* seem to have a nice separation of values into relatively contained clusters vs. the values of *target*\n\n\n*Note:* It could take me around 3 h to build the EDA and data visualizations of the comparable granularity/level of details if I did it manually with some of the mainstream data visualization libraries."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('We are done. That is all, folks!')\nfinish_time = dt.datetime.now()\nprint(\"Finished at \", finish_time)\nelapsed = finish_time - start_time\nprint(\"Elapsed time: \", elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References\n\nThe references to the blog posts below may be helpful in your deeper delve into the universe of AutoViz\n\n* Dan Roth, AutoViz: A New Tool for Automated Visualization - https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad\n* George Vyshnya, PROs and CONs of Rapid EDA Tools - https://medium.com/sbc-group-blog/pros-and-cons-of-rapid-eda-tools-e1ccd159ab07"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}