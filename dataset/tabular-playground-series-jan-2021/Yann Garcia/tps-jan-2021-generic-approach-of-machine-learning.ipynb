{"cells":[{"metadata":{},"cell_type":"markdown","source":"As a beginner, I made this notebook to present a generic approach to \"play\" with the concepts of machine learning and neural network. I have also tried to provide some clean Python code. To sum up, it is a synthesis of my current knowledge (and sorry for my English).\n\nThis is a first version which will be improved compete after compete.\n\nThe basic steps to define a 'Generic approach of Machine Learning' are:\n1. Define the problem, I mean understand the data you got and define what are the inputs (attributes) and what is the output (target) of your Machine Learning\n2. Summarize the dataset content in a statistical form\n3. Prepare the dataset for your Machine Learning processing\n4. Evaluate a set of algorithms based on you understanding of the data\n5. Improve the results of your Machine Learning by refining the algorithms\n6. Present the results of your Machine Learning\n7. Deploy or save your Machine Learning\n\n**NOTE: Please, feel free to correct and enhance this notebook ;)**"},{"metadata":{},"cell_type":"markdown","source":"To define the problem, we have first to choose the subject we will work on. The point 1.b provides different datasets we can use to play. For each dataset, a comment describes the problem to address. \nWe will consider two different problems:\n1. One about classification (the basic one is the Iris classification)\n2. One about regression (Melbourne housing prices)\n\nThis is the part that cannot be generic. The generic behavior proposed here is parameterized by the set of parameters defined in point b.1.\n\nNote: In point b.1, to swith to another problem, just comment the current one and uncomment the problem to play with\n\nSwitching to Python code, the first step is to load all the required libraries (1.a) and to choose the problem to solve, let's say Iris classification."},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import division # Import floating-point division (1/4=0.25) instead of Euclidian division (1/4=0)\n\n# 1. Prepare Problem\n\n# a) Load libraries\nimport os, warnings, argparse, io, operator, requests\nfrom datetime import datetime\n\nimport numpy as np # Linear algebra\nimport matplotlib.pyplot as plt # Data visualization\nimport seaborn as sns  # Enhanced data visualization\nimport pandas as pd # Data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom pandas_profiling import ProfileReport\n\nimport sklearn\nfrom sklearn import model_selection\nfrom sklearn import linear_model # Regression\nfrom sklearn import discriminant_analysis\nfrom sklearn import neighbors # Clustering\nfrom sklearn import naive_bayes\nfrom sklearn import tree # Decisional tree learning\nfrom sklearn import svm # Support Vector Machines\nfrom sklearn import ensemble # Support RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n\nimport xgboost as xgb # Gradient Boosted Decision Trees algorithm\n\nimport lightgbm as lgb # Light Gradient Boost model\n\nfrom sklearn.base import is_classifier, is_regressor # To check if the model is for regression or classification (do not work for Keras)\n\nfrom sklearn.impute import SimpleImputer \n\nfrom sklearn.preprocessing import LabelEncoder # Labelling categorical feature from 0 to N_class - 1('object' type)\nfrom sklearn.preprocessing import LabelBinarizer # Binary labelling of categorical feature\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.preprocessing import StandardScaler # Data normalization\nfrom sklearn.preprocessing import MinMaxScaler # Data normalization\nfrom sklearn.preprocessing import MaxAbsScaler # Data normalization\n\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.inspection import permutation_importance\n\nimport pickle # Use to save and load models\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\n# Neural Network\nimport tensorflow as tf\nimport keras\nfrom keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First of all, we have to define the problem:\n1. Understand the data, see point b.1) below\n2. Prepare the basics of your code such as loading the libraries and your data, see points a) and b) below\n\nIn point b.1, we have a set of parameters strongly linked to the problem to solve. These parameters are used to configure the execution of 'Generic approach of Machine Learning':\n- DATABASE_NAME: The URI of the dataset\n- COLUMNS_LABEL: Columns label of the dataset. Default: None, means that labels are already present in the loaded dataset- COLUMNS_TO_DROP: The useless columns to drop after loading the dataset\n- FEATURES_SELECTION: The list of the features for the ML inputs. Default: None, means - all columns (excepted the output columns) are concidered as features\n- TARGET_COLUMNS: The output columns\n- OUTPUT_IS_REGRESSION: Indicates if the ML is about either regression (True) or classification (False)\n- DATE_TIME_COLUMNS: The list of the date/time column in customized format such as string format\n- FEATURES_POST_LOAD_PROCESSING: This dictionary attaches a lamdba function to apply to a column. The Lambda function is a processing to apply to the column just after loading the dataset (point 1.c).\n- FEATURES_PROCESSING: This dictionary attaches a lamdba function to apply to a column. The Lambda function is a processing to apply to the column just before to start data engineering (point 3.a).\n- FEATURES_CREATION:  This dictionary attaches a lamdba function for features creation. The Key shall be the name of the new column\n- FEATURES_DELETION: This list contains the features to be removed after FEATURES_CREATION processing\n- NON_TRANSFORMABLE_COLUMNS: Indicates a list of columns which shall not be included in the transformation process (point 3.b)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# b) Helpers\n\n# b.1) Define global parameters\n# Regression\n\n# Jan Tabular Playground Competition\nDATABASE_NAME = None\nCOLUMNS_LABEL = None\nCOLUMNS_TO_DROP = ['id'] # Id is useless\nFEATURES_SELECTION = None\nTARGET_COLUMNS = ['target']\nOUTPUT_IS_REGRESSION = True\nDATE_TIME_COLUMNS = None\nFEATURES_POST_LOAD_PROCESSING = None\nFEATURES_PRE_PROCESSING = None\nFEATURES_CREATION = None\nFEATURES_PROCESSING = None\nFEATURES_DELETION = None\nNON_TRANSFORMABLE_COLUMNS = None\n\n# To predict house price using the famous Melbourne housing dataset\n#DATABASE_NAME = 'https://raw.githubusercontent.com/nagoya-foundation/r-functions-performance/master/data/Melbourne_housing_FULL.csv'\n#COLUMNS_LABEL = None\n#COLUMNS_TO_DROP = ['Address', 'Method', 'Postcode', 'CouncilArea', 'Propertycount', 'Regionname', 'SellerG']\n#FEATURES_SELECTION = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']\n#TARGET_COLUMN = 'Price'\n#OUTPUT_IS_REGRESSION=True\n#DATE_TIME_COLUMNS = ['Date']\n#FEATURES_PRE_PROCESSING = None\n#FEATURES_CREATION = None\n#FEATURES_DELETION = None\n#NON_TRANSFORMABLE_COLUMNS = None\n# Suburb\n# Address\n# Rooms\n# Type\n# Price\n# Method\n# SellerG\n# Date\n# Distance\n# Postcode\n# Bedroom2\n# Bathroom\n# Car\n# Landsize\n# BuildingArea\n# YearBuilt\n# CouncilArea\n# Lattitude\n# Longtitude\n# Regionname\n# Propertycount\n\n# Classification\n# To categorize an iris flower according to the dimensions of its sepals & petals \n# Famous database; from Fisher, 1936\n#DATABASE_NAME = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n#COLUMNS_TO_DROP = None\n#FEATURES_SELECTION = None\n#TARGET_COLUMN = 'class'\n#OUTPUT_IS_REGRESSION=False\n#DATE_TIME_COLUMNS = None\n#COLUMNS_LABEL = ['sepal length in cm', 'sepal width in cm', 'petal length in cm', 'petal width in cm', 'class']\n\n# To predict survival on the Titanic\n#DATABASE_NAME = 'https://raw.githubusercontent.com/alexisperrier/packt-aml/master/ch4/titanic.csv'\n#COLUMNS_LABEL = None\n#COLUMNS_TO_DROP = ['PassengerId', 'Name', 'Ticket'] # PassengerId is useless, Name and Ticket will be processed in future version\n#    # We assume that Name,Ticket and are not relevant information\n#    # This can be confirm by the correlation matrix\n#FEATURES_SELECTION = None\n#TARGET_COLUMNS = ['Survived']\n#OUTPUT_IS_REGRESSION=False\n#DATE_TIME_COLUMNS = None\n#FEATURES_POST_LOAD_PROCESSING = {\n#    'Cabin': lambda p_value : p_value[0:1] if not p_value is np.NaN else 'U', \n#        # Create a category U for Unknown and just keep the deck indetifier\n#}\n#FEATURES_PROCESSING = {\n#    'Embarked': lambda p_value : p_value[0:1] if not p_value is np.NaN else 'S', \n#        # S has the higher cardinality (see kaggle_summurize_data: distribution of categorical features)\n#}\n#FEATURES_CREATION = {\n#    'FamilySize': lambda p_df : p_df['SibSp'] + p_df['Parch'] + 1,\n#    'AgeClass': lambda p_df : 'Senior' if p_df['Age'] >= 60 else 'Adult' if p_df['Age'] >= 35 else 'Young Adult' if p_df['Age'] >= 25 else 'Teen' if p_df['Age'] >= 14 else 'Child' if p_df['Age'] >= 4 else 'Baby',\n#        # Create class of ages based on common Age distribution\n#    'FareClass': lambda p_df : 'Very Expensive' if p_df['Fare'] >= (3*512/4) else 'Expensive' if p_df['Fare'] >= (512/2) and p_df['Fare'] < (3*512/4) else 'Chip' if p_df['Fare'] < (512/2) and p_df['Fare'] >= (512/4) else 'Very Chip' # Create Age class, NaN values will be imputed\n#        # Create class of fare based on discussion below\n#}\n#FEATURES_DELETION = ['SibSp', 'Parch', 'Age', 'Fare'] # SibSp and Parch were repaced by FamilySize, Age by AgeClass and Fare by FareClass\n#NON_TRANSFORMABLE_COLUMNS = None\n#  PassengerId: Unique passenger id\n#  Survived: Survival status ('Yes' or 'No')\n#  Pclass: The class the passeger belong (1st, 2nd or 3rd class)\n#  Name: Name of the passenger\n#  Sex: The sex of the passenger ('male' of 'female')\n#  Age: The age of the passenger (in years)\n#  SibSp: # of siblings / spouses aboard the Titanic\n#  Parch: # of parents / children aboard the Titanic\n#  Ticket: No description available for this field, perhaps the travel company identifier\n#  Fare: Ticket price\n#  Cabin: Identifier of the cabin. The first character identifies the deck.\n#         This could be interesting fo the ML, creating a new feature Deck\n#  Embarked: Port of Embarkation\n\n# This dataset describes the medical records for Pima Indians and whether or not each patient will have an onset of diabetes within \fve years.\n# NOTE: Disable flag DATA_CLEANING_FLAG, this dataset is already ready to be used by ML \n#DATABASE_NAME = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'\n#COLUMNS_TO_DROP = None\n#FEATURES_SELECTION = None\n#TARGET_COLUMN = 'class'\n#OUTPUT_IS_REGRESSION=False\n#DATE_TIME_COLUMNS = None\n#FEATURES_PRE_PROCESSING = None\n#COLUMNS_LABEL = ['preg', 'plas', 'pres (mm Hg)', 'skin (mm)', 'test (mu U/ml)', 'mass', 'pedi', 'age (years)', 'class']\n#  preg = Number of times pregnant\n#  plas = Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n#  pres = Diastolic blood pressure\n#  skin = Triceps skin fold thickness (mm)\n#  test = 2-Hour serum insulin (mu U/ml)\n#  mass = Body mass index (weight in kg/(height in m)^2)\n#  pedi = Diabetes pedigree function\n#  age = Age (years)\n#  class = Class variable (1:tested positive for diabetes, 0: tested negative for diabetes)\n\n# This dataset collects information from 100k medical appointments in Brazil and is focused on the question of whether or not patients show up for their appointment. A number of characteristics about the patient are included in each row\n#DATABASE_NAME = 'https://github.com/jbrownlee/Datasets/blob/master/pima-indians-diabetes.data.csv'\n#COLUMNS_TO_DROP = None\n#FEATURES_SELECTION = None\n#TARGET_COLUMN = 'No-show'\n#OUTPUT_IS_REGRESSION=False\n#DATE_TIME_COLUMNS = None\n#FEATURES_PRE_PROCESSING = None\n#COLUMNS_LABEL = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before to load and to examine our dataset, we are just going to set a number of defaults such as the settings for the plotting operation, Deep Learning parameters... (point b.2)\n\nNote: Point b.3 shall be used if you want to 'reassemble the notebook code and create a standalone Python scrypt"},{"metadata":{"trusted":true},"cell_type":"code","source":"# b.2) Set some defaults\ndef kaggle_set_mp_default() -> None:\n    \"\"\"\n    Some default setting for Matplotlib plots\n    \"\"\"\n    warnings.filterwarnings(\"ignore\") # to clean up output cells\n    pd.set_option('precision', 3)\n    # Set Matplotlib defaults\n    plt.rc('figure', autolayout=True)\n    plt.rc('axes', labelweight='bold', labelsize='large', titleweight='bold', titlesize=18, titlepad=10)\n    plt.rc('image', cmap='magma')\n    # End of function set_mp_default\n\n# Basic Deep Learning parameters\nDL_BATCH_SIZE = 32\nDL_EPOCH_NUM = 128\nDL_DROP_RATE = 0.3\n\n# Fix random values for reproductibility\nSEED_HARCODED_VALUE = 0\n\ndef kaggle_set_seed(p_seed: int = SEED_HARCODED_VALUE) -> None:\n    \"\"\"\n    Random reproducability\n    :parameter p_seed: Set the seed value for random functions\n    \"\"\"\n    np.random.seed(p_seed)\n    sklearn.utils.check_random_state(p_seed)\n    tf.random.set_seed(p_seed)\n    os.environ['PYTHONHASHSEED'] = str(p_seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    # End of function set_seed\n\ndef kaggle_modules_versions() -> None:\n    \"\"\"\n    Print the different modules version\n    \"\"\"\n    print('----------------------------- modules_versions -----------------------------')\n    print(\"Numpy version: \" + np.__version__)\n    print('seaborn: %s' % sns.__version__)\n    print(\"Pandas version: \" + pd.__version__)\n    print(\"Sklearn version: \" + sklearn.__version__)\n    print(\"Tensorflow version: \" + tf.__version__)\n    print('modules_versions: Done')\n    # End of function modules_versions\n    \ndef kaggle_tpu_detection():\n    \"\"\"\n    TPU detection\n    :return: The appropriate distribution strategy\n    \"\"\"\n    print('----------------------------- kaggle_tpu_detection -----------------------------')\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n        print('kaggle_tpu_detection: Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    else:\n        strategy = tf.distribute.get_strategy() \n    print('kaggle_tpu_detection: %s' % str(strategy.num_replicas_in_sync))\n    print('kaggle_tpu_detection: %s' % str(type(strategy)))\n    print('kaggle_tpu_detection Done')\n    return strategy\n    # End of function kaggle_tpu_detection\n\n# b.3) Set execution control flags\nfrom enum import IntFlag\n\nclass ExecutionFlags(IntFlag):\n    \"\"\"\n    This class provides some execution control flags to enable/disable some part of the whole script execution\n    \"\"\"\n    NONE                     = 0b00000000 # All flags disabled\n    ALL                      = 0b11111111 # All flags enabled\n    DATA_STAT_SUMMURIZE_FLAG = 0b00000001 # Enable statitistical analyzis\n    DATA_VISUALIZATION_FLAG  = 0b00000010 # Enable data visualization\n    DATA_CLEANING_FLAG       = 0b00000100 # Enable data cleaning (feature engineering)\n    DATA_TRANSFORM_FLAG      = 0b00001000 # Enable data transformation\n    USE_NEURAL_NETWORK_FLAG  = 0b00010000 # Enable neural network models\n    # End of class ExecutionFlags","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we are ready to load our dataset and examine it to understand the data it contains. This function accept any URI (e.g. file:///... or http://... or https://...).\n\nLoading the dataset, you can specify or overwrite columns labels.\n\nAccording to the data analyzing, you can also define some post loading processing using lambda function (see FEATURES_POST_LOAD_PROCESSING).\n\nThe function kaggle_load_datasets() splits the data into three datasets:\n- Training dataset used to train the model(size fixed by p_train_size, default is 90%)\n- Test dataset use to test the mode with unseen data (size is (100 - p_train_size), default is 10%)\n- Training dataset is splitted again into Training dataset (80%) and  Validation dataset used to fit the model (size is 20%)\n\nNote: The Test dataset does not contain taget features (see TARGET_COLUMNS)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# c) Load dataset\ndef kaggle_load_datasets(p_url: str, \n                         p_labels: list = None, \n                         p_train_path: str = None, \n                         p_validation_path: str = None,\n                         p_train_size: float = 0.9,\n                         p_seed:int = SEED_HARCODED_VALUE\n                        ) -> pd.core.frame.DataFrame:\n    \"\"\"\n    This function load the dataset specified by p_url or (p_train_path, p_validation_path) ina case of Kaggle compete.\n    It also add the labels if required and apply post load processing of the datatsets if required\n    :parameters p_url: The URI of the dataset (http:// or file://)\n    :parameters p_labels: The label of the columns to be used. Default: None\n    :parameters p_train_path: Kaggle specific path for train dataset\n    :parameters p_validation_path: Kaggle specific path for validation dataset\n    :return: Three datasets: The Training, Test and Validation datasets\n    :exception: Raised if specified link is not correct\n    \"\"\"\n    print('----------------------------- kaggle_load_datasets -----------------------------')\n    df = None\n    train_df = None\n    test_df = None\n    validation_df = None \n    if not p_train_path is None and not p_validation_path is None:\n        # Kaggle compete spcific\n        train_df = pd.read_csv(p_train_path)\n        test_df = pd.read_csv(p_validation_path)\n        # Set labels\n        if not p_labels is None:\n            df.columns = p_labels\n        # Split train_df into Training and Test datasets\n        y_train_df = train_df[TARGET_COLUMNS]\n        x_train_df = train_df.drop(TARGET_COLUMNS, axis = 1)\n        X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(x_train_df, y_train_df, train_size = 0.8, random_state = p_seed)               \n        train_df = pd.concat([X_train, Y_train], axis = 1)\n        validation_df = pd.concat([X_validation, Y_validation], axis = 1)       \n    else:\n        # Get the data\n        if p_url.startswith('file://'):\n            df = pd.read_csv(p_url[7:])\n        elif p_url.startswith('http'):\n            ds = requests.get(p_url).content\n            df = pd.read_csv(io.StringIO(ds.decode('utf-8')))\n        if df is None:\n            raise Exception('kaggle_load_datasets: Failed to load data frame', 'url=%s' % (url))\n        # Set labels\n        if not p_labels is None:\n            df.columns = p_labels\n        # Split them into Training, Test and Validation datasets\n        y_df = df[TARGET_COLUMNS]\n        x_df = df.drop(TARGET_COLUMNS, axis = 1)\n        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(x_df, y_df, train_size = p_train_size, random_state = p_seed)\n        train_df = pd.concat([X_train, Y_train], axis = 1)\n        test_df = X_test\n\n        y_df = train_df[TARGET_COLUMNS]\n        x_df = train_df.drop(TARGET_COLUMNS, axis = 1)\n        X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(x_df, y_df, train_size = 0.8, random_state = p_seed)\n        train_df = pd.concat([X_train, Y_train], axis = 1)\n        validation_df = pd.concat([X_validation, Y_validation], axis = 1)\n\n    #print('----------------------------- kaggle_load_datasets: training dataset')\n    #print(train_df.describe().T)\n    #print('----------------------------- kaggle_load_datasets: test dataset')\n    #print(test_df.describe().T)\n    #print('----------------------------- kaggle_load_datasets: validation dataset')\n    #print(validation_df.describe().T)\n    \n    # Apply post processing after loading dataset\n    if not FEATURES_POST_LOAD_PROCESSING is None and isinstance(FEATURES_POST_LOAD_PROCESSING, dict):\n        for key in FEATURES_POST_LOAD_PROCESSING.keys():\n            if key in train_df:\n                train_df[key] = train_df[key].apply(FEATURES_POST_LOAD_PROCESSING[key])\n            if key in validation_df:\n                validation_df[key] = validation_df[key].apply(FEATURES_POST_LOAD_PROCESSING[key])\n            if key in test_df:\n                test_df[key] = test_df[key].apply(FEATURES_POST_LOAD_PROCESSING[key])\n        # End of 'for' statement\n\n    # Drop columns if any\n    if not COLUMNS_TO_DROP is None:\n        train_df.drop(COLUMNS_TO_DROP, inplace = True, axis = 1)\n        validation_df.drop(COLUMNS_TO_DROP, inplace = True, axis = 1)\n        test_df.drop(COLUMNS_TO_DROP, inplace = True, axis = 1)\n\n    print('----------------------------- kaggle_load_datasets: training dataset')\n    print(train_df.head())\n    print('----------------------------- kaggle_load_datasets: validation dataset')\n    print(validation_df.head())\n    print('----------------------------- kaggle_load_datasets: test dataset')\n    print(test_df.head())\n\n    print('kaggle_load_datasets: Done: %s' % (p_url if not p_url is None else p_train_path))\n    return train_df, validation_df, test_df\n    # End of function kaggle_load_datasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Examining the dataset means get a global overview of its data from statistical point of view, using:\n1. Some basics statistical tools such as means, stds, quartiles and correlation (2.a)\n2. Some visualization tools such as histograms, density plots (2.b)\n\nUnderstanding the data is the most important step. The kaggle_summurize_data() function provide you a lot of information to help you in this task:\n- Dataset info: It provides information about the structure of the data:\n1) The number of features (or attributes or columns), and the name (or label) of each. Here, it is important to understand what each feature means, what can be the values for this feature, take care of the units... A lot of research work to understand our problem,\n2) The types of each feature. 'object' type indicates categorical features, it means we should have to do some imputations,\n3) One or several of these feature will be our ML output and some of them could be removed later because of poor interest to solve our problem (e.g. features with huge correlation, feature reduction using ACP...),\n3) The number of observations (or samples) in the dataset. This will be useful to split our datatset into training, validation and test dataset.\n- Dataset columns labels: It indicates the name (or label) of each attributes\n- Means: It provides you the mean value for each features (also provided by statistical abstract, see below)\n- Dataset statistical abstract: It provides, for each feature, basic statistical metrics such as means, stds, quartiles...\n- Dataset Head: It displays the fisrt samples of the dataset. It provides you some indication of the value of each observation. Note that it is not suffisient to detect specific values such as NULL or NaN values, zeros, string values, categorical values... \n- Unique possible columns: It provides, for each feature, the list of the unique values. This will help you during the data transformation to rescale and center the feature values (see point 3.c). Very often, a feature with few unique values (e.g. 2 or 3) indicates also a categorical fetaure,\n- Correlation table: It provides the correlation between all couple of features and the list of the correlation values in the range > 0.7 and < -0.7. The will be used to reduce the number of features due to strong link between some features (see p_correlation_threshold parameter)\n\nNote: Here we use pandas_profiling to generate an analyze report in HTML format. This report is higly valuable because of the information it provides for each columns:\n1. Specific value indicators such as zeros, NaN...\n2. Distincts values\n3. Statistical values such as mean, min/max..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Summarize the dataset content in a statistical form\n# a) Descriptive statistics\ndef kaggle_summurize_data(p_df: pd.core.frame.DataFrame, p_correlation_threshold: float = 0.7) -> None:\n    \"\"\"\n    This function provides a statistical view of the current dataset\n    :parameters p_df: The dataset handle\n    \"\"\"\n    print('----------------------------- kaggle_summurize_data -----------------------------')\n    # General information\n    print('Dataset info:')\n    print(p_df.info())\n    print('----------------------------- kaggle_summurize_data: Dataset columns labels:')\n    print(p_df.columns)\n    print('----------------------------- kaggle_summurize_data: Means:')\n    print(p_df.mean())\n    print('----------------------------- kaggle_summurize_data: Dataset statistical abstract:')\n    print(p_df.describe().T)\n    print('----------------------------- kaggle_summurize_data: Dataset Head:')\n    print(p_df.head(20))\n    # NaN values\n    print('----------------------------- kaggle_summurize_data: NaN values distribution:')\n    print(p_df.isnull().sum().sort_values(ascending = False))\n    print(\"----------------------------- kaggle_summurize_data: Number of rows with NaN: \", p_df.isnull().any(axis = 1).sum())\n    # Zeros per columns\n    print('----------------------------- kaggle_summurize_data: Zeros per columns distribution:')\n    for column in p_df.columns:\n        if p_df[column].dtype == 'int64' or p_df[column].dtype == 'float64':\n            zeros = p_df[column].isin([0]).sum()\n            s = p_df[column].sum()\n            print('{}: {}'.format(column, zeros, 100 * zeros / s))\n        else:\n            print('%s: Not numerical column' % column)\n    # End of 'for' statement\n    # Distribution of categorical features\n    print('----------------------------- kaggle_summurize_data: Distribution of categorical features:')\n    categorical_columns = [col for col in p_df.columns if p_df[col].dtype == 'object']\n    for c in categorical_columns:\n        print('Distribution  for %s' % c)\n        print(p_df[c].describe())\n    # End of 'for' statement\n    # Distribution of categorical features\n    print('----------------------------- kaggle_summurize_data: Distribution of numerical features:')\n    numerical_columns = [col for col in p_df.columns if p_df[col].dtype == 'int64' or p_df[col].dtype == 'float64']\n    for c in numerical_columns:\n        print('Distribution  for %s' % c)\n        print(p_df[c].describe())\n    # End of 'for' statement\n    #  Unique possible columns\n    print('----------------------------- kaggle_summurize_data: Unique possible columns:')\n    for column in p_df.columns:\n        print('{}: {}'.format(column, p_df[column].unique()))\n    # End of 'for' statement\n    # Build Correlation matrix\n    print('----------------------------- kaggle_summurize_data: Correlation table:')\n    print(p_df.corr(method = 'pearson'))\n    # Extract correlation > 0.7 and < -0.7\n    print('----------------------------- kaggle_summurize_data: Correlations in range > %f and < -%f:' % (p_correlation_threshold, p_correlation_threshold))\n    corr = p_df.corr().unstack().reset_index() # Group together pairwise\n    corr.columns = ['var1', 'var2', 'corr'] # Rename columns to something readable\n    print(corr[ (corr['corr'].abs() > p_correlation_threshold) & (corr['var1'] != corr['var2']) ] )\n    # Finally, create Pandas Profiling\n    #print('----------------------------- kaggle_summurize_data: Pandas Profiling:')\n    #file = ProfileReport(p_df) # Need to many times\n    #file.to_file('./eda.html')\n    #file.to_notebook_iframe()\n    print('kaggle_summurize_data: Done')\n    # End of function kaggle_summurize_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The kaggle_visualization() function provides different plot to explore the data distrubution (gaussian, exponecial...) and to detect outlier values. It will help 1) during the data cleaning and 2) later, to choose the ML algorithms (e.g. Outliers do not affect a tree-based algorithm).\nThere are two kind of data visualition:\n- The Univariate Plots which are related to each features, and\n- The Multivariate Plots which are related to interaction between features\n\nThe Univariate Plots:\n- Histograms: It provides a graphical representation of the distribution of a dataset. For a continuous numerical, it show the underlying frequency distribution or the probability  distribution of signal (see https://towardsdatascience.com/histograms-why-how-431a5cfbfcd5)\n- Density: It is the continuous form of the histogram (see above) and it shows an estimate of the continuous distribution of a feature (Gaussian distribution, exponential distribution...)\n\nThe Multivariate Plots\n- Correlationan: It provides indications about the changes between two features\n- scatter_matrix: It shows how much one feature is affected by another or the relationship between them"},{"metadata":{},"cell_type":"markdown","source":"The functions below are some helpers for data visualization. They provides different kind of univariate and multivariate plots. Two special functions provide features vs. target plots and training/validation dataset comparison plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_grid(p_df: pd.core.frame.DataFrame, p_features:list = None, p_nun_plot_per_lane:int = 3) -> list:\n    \"\"\"\n    Create the grid in preparation of the plots\n    \"\"\"\n    # Create figure\n    if p_features is None:\n        features = p_df.columns\n    else:\n        features = p_features\n    sns.set_style('darkgrid')\n    l = len(features) // p_nun_plot_per_lane + (1 if len(features) % p_nun_plot_per_lane != 0 else 0)\n    #print('==> l=', l)\n    fig = plt.figure(figsize = (l * 3, p_nun_plot_per_lane * 3))\n    gs = fig.add_gridspec(l, p_nun_plot_per_lane)\n    gs.update(wspace = 0.1, hspace = 0.4)\n    background_color = '#fbfbfb'\n    # Prepare the grid\n    fig_desc = dict()\n    run_no = 0\n    for row in range(0, l):\n        for col in range(0, p_nun_plot_per_lane):\n            fig_desc['ax' + str(run_no)] = fig.add_subplot(gs[row, col])\n            fig_desc['ax' + str(run_no)].set_facecolor(background_color)\n            fig_desc['ax' + str(run_no)].tick_params(axis = 'y', left = True)\n            fig_desc['ax' + str(run_no)].get_yaxis().set_visible(True)\n            for s in ['top', 'right']:\n                fig_desc['ax' + str(run_no)].spines[s].set_visible(False)\n            run_no += 1\n        # End of 'for' statement\n    # End of 'for' statement\n    #print('==> #plots=', len(fig_desc))\n    \n    return (fig, gs, fig_desc)\n    # End of function create_grid\n\ndef finalize_grid(p_figure_desc: list, p_df: pd.core.frame.DataFrame, p_features:list = None, p_title:str = None, p_comment:str = None) -> None:\n    \"\"\"\n    Finalize the grid after the plot\n    \"\"\"\n    if p_features is None:\n        features = p_df.columns\n    else:\n        features = p_features\n    fig, gs, fig_desc = p_figure_desc\n    # Add Titles\n    fig_desc['ax0'].text(-0.2, 0.4, p_title, fontsize = 20, fontweight = 'bold', fontfamily = 'serif')\n    fig_desc['ax0'].text(-0.2, 0.3, p_comment, fontsize = 13, fontweight = 'light', fontfamily = 'serif')\n    # Cleanup unused plots\n    for t in range(len(features), len(fig_desc)):\n        for s in ['top', 'bottom', 'right', 'left']:\n            fig_desc['ax' + str(t)].spines[s].set_visible(False)\n        fig_desc['ax' + str(t)].tick_params(axis='x', bottom = False)\n        fig_desc['ax' + str(t)].get_xaxis().set_visible(False)\n        # End of 'for' statement\n\n    plt.show()\n\n    fig = None\n    gs = None\n    fig_desc = None\n    # End of function finalize_grid\n\ndef show_counts(p_df: pd.core.frame.DataFrame, p_features:list = None, p_hue:str = None, p_title:str = None, p_comment:str = None) -> None:\n    if p_features is None:\n        features = p_df.columns\n    else:\n        features = p_features\n    # Create the grid\n    fig, gs, fig_desc = create_grid(p_df)\n    # Draw plots\n    run_no = 0\n    for feature in features:\n        sns.countplot(p_df[feature], hue = p_hue, ax = fig_desc['ax' + str(run_no)], color='#ffd100')\n        run_no += 1\n    # End of 'for' statement\n    # Finalyze the figure\n    finalize_grid((fig, gs, fig_desc), p_df, features, p_title, p_comment)\n    # End of function show_distributions\n\ndef show_modes(p_df: pd.core.frame.DataFrame, p_features:list = None, p_title:str = None, p_comment:str = None) -> None:\n    if p_features is None:\n        features = p_df.columns\n    else:\n        features = p_features\n    # Create the grid\n    fig, gs, fig_desc = create_grid(p_df[features])\n    # Draw plots\n    run_no = 0\n    for feature in features:\n        try:\n            sns.distplot(p_df.loc[:,feature], ax = fig_desc['ax' + str(run_no)], hist = False, color='#ffd100')\n        except RuntimeError:\n            sns.distplot(p_df.loc[:,feature], ax = fig_desc['ax' + str(run_no)], kde = False, hist = False, color='#ffd100')            \n        run_no += 1\n    # End of 'for' statement\n    # Finalyze the figure\n    finalize_grid((fig, gs, fig_desc), p_df, features, p_title, p_comment)\n    # End of function show_distributions\n\ndef show_distributions(p_df: pd.core.frame.DataFrame, p_features:list = None, p_title:str = None, p_comment:str = None) -> None:\n    if p_features is None:\n        features = p_df.columns\n    else:\n        features = p_features\n    # Create the grid\n    fig, gs, fig_desc = create_grid(p_df[features])\n    # Draw plots\n    run_no = 0\n    for feature in features:\n        try:\n            sns.distplot(p_df.loc[:,feature], ax = fig_desc['ax' + str(run_no)], color='#ffd100')\n        except RuntimeError:\n            sns.distplot(p_df.loc[:,feature], ax = fig_desc['ax' + str(run_no)], kde = False, color='#ffd100')    \n        run_no += 1\n    # End of 'for' statement\n    # Finalyze the figure\n    finalize_grid((fig, gs, fig_desc), p_df, features, p_title, p_comment)\n    # End of function show_distributions\n\ndef show_trends(p_df: pd.core.frame.DataFrame, p_features:list = None, p_title:str = None, p_comment:str = None) -> None:\n    if p_features is None:\n        features = p_df.columns\n    else:\n        features = p_features\n    # Create the grid\n    fig, gs, fig_desc = create_grid(p_df[features])\n    # Draw plots\n    run_no = 0\n    for feature in features:\n        sns.lineplot(data = p_df[feature], ax = fig_desc['ax' + str(run_no)], color='#ffd100')\n        run_no += 1\n    # End of 'for' statement\n    # Finalyze the figure\n    finalize_grid((fig, gs, fig_desc), p_df, features, p_title, p_comment)\n    # End of function show_trends\n\ndef show_correlations(p_df: pd.core.frame.DataFrame, p_title:str = None, p_comment:str = None) -> None:\n    # Create the grid\n    fig = plt.figure(figsize = (3, 3))\n    gs = fig.add_gridspec(1, 1)\n    background_color = \"#fbfbfb\"\n    # Prepare the grid\n    fig_desc = dict()\n    fig_desc['ax0'] = fig.add_subplot(gs[0, 0])\n    fig_desc['ax0'].set_facecolor(background_color)\n    fig_desc['ax0'].tick_params(axis = 'y', left=False)\n    fig_desc['ax0'].get_yaxis().set_visible(False)\n    for s in [\"top\", \"right\", \"left\"]:\n        fig_desc['ax0'].spines[s].set_visible(False)\n    # Draw plots\n    sns.heatmap(data = p_df.corr(), annot=True)\n    # Finalyze the figure\n    # Add Titles\n    fig_desc['ax0'].text(-0.2, 0.4, p_title, fontsize = 20, fontweight = 'bold', fontfamily = 'serif')\n    fig_desc['ax0'].text(-0.2, 0.3, p_comment, fontsize = 13, fontweight = 'light', fontfamily = 'serif')   \n    plt.show()\n    # End of function show_correlations\n\ndef show_outliers(p_df: pd.core.frame.DataFrame, p_title:str = None, p_comment:str = None) -> None:\n    features = p_df.columns\n    # Create the grid\n    fig, gs, fig_desc = create_grid(p_df[features])\n    # Draw plots\n    run_no = 0\n    for feature in features:\n        ds = p_df[feature].value_counts()\n        sns.boxplot(ds, ax = fig_desc['ax' + str(run_no)], color='#ffd100')\n        run_no += 1\n    # End of 'for' statement\n    # Finalyze the figure\n    finalize_grid((fig, gs, fig_desc), p_df, features, p_title, p_comment)\n    # End of function show_outliers\n\ndef show_features_vs_target(p_df: pd.core.frame.DataFrame, p_target:str, p_features:list = None, p_title:str = None, p_comment:str = None) -> None:\n    if p_features is None:\n        features = p_df.columns.tolist() # Using tolist() for removing p_target\n    else:\n        features = p_features\n    if p_target in features:\n        features.remove(p_target)\n    # Create the grid\n    fig, gs, fig_desc = create_grid(p_df[features])\n    # Draw plots\n    run_no = 0\n    for feature in features:\n        sns.relplot(x = p_target, y = feature, data = p_df, ax = fig_desc['ax' + str(run_no)], color='#ffd100')\n        run_no += 1\n    # End of 'for' statement\n    # Finalyze the figure\n    finalize_grid((fig, gs, fig_desc), p_df, features, p_title, p_comment)\n    # End of function show_features_vs_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# b) Data visualizations\ndef kaggle_visualization(p_df: pd.core.frame.DataFrame) -> None:\n    \"\"\"\n    This method provides different views of the dataset (plot)\n    :parameters p_df: The dataset handle\n    \"\"\"\n    print('----------------------------- kaggle_visualization_data -----------------------------')\n    features = list(set(p_df.columns) - set(TARGET_COLUMNS))\n    categorical_columns = [col for col in p_df.columns if p_df[col].dtype == 'object']\n    if not DATE_TIME_COLUMNS is None:\n        categorical_columns = list(set(categorical_columns) - set(DATE_TIME_COLUMNS))\n    numerical_columns = [col for col in p_df.columns if p_df[col].dtype == 'int64' or p_df[col].dtype == 'float64']\n    print('kaggle_visualization: Features Distribution plots')\n    show_counts(p_df, p_hue = None)\n    raise Exception('Stop')\n    # Histogram plots\n    print('kaggle_visualization: Numerical features Distribution plots')\n    show_distributions(p_df, p_features = numerical_columns)\n    print('kaggle_visualization: Features outliers plots')\n    show_outliers(p_df, p_title = 'Features Distribution')\n    #show_trends(p_df, p_title = 'Features Distribution', p_comment = 'All features have bimodal or multimodal distribution')\n    print('kaggle_visualization: Histogram of each attributes regarding targets')\n    show_correlations(p_df)\n    print('kaggle_visualization: Features VS target distribution plots')\n    show_features_vs_target(p_df, p_target = TARGET_COLUMNS)#, p_features = numerical_columns)    \n    print('kaggle_visualization: Done')\n    # End of function kaggle_visualization\n\ndef cross_dataset_visualization(p_dfs: list) -> None:\n\n    print('cross_dataset_visualization: Done')\n    # End of function cross_dataset_visualization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TODO: Add data analyze results"},{"metadata":{},"cell_type":"markdown","source":"The function kaggle_ml_quick_and_dirty() provides a 'quick and dirty' evaluation of a ML based on RandomForestClassifier algorithm with estimators parameter set to 128. All rows with NaN values are removed and all categorical attributes are excluded."},{"metadata":{"trusted":true},"cell_type":"code","source":"# c) Basic ML for a quick & dirty evaluation\ndef kaggle_ml_quick_and_dirty(p_train_df: pd.core.frame.DataFrame, \n                              p_validation_df: pd.core.frame.DataFrame, \n                              p_test_df: pd.core.frame.DataFrame = None,\n                              p_seed:int = SEED_HARCODED_VALUE\n                             ) -> np.ndarray:\n    \"\"\"\n    This method provides a first ML evalulation based on RandomForest algorithm\n    :parameters p_train_df: The Training dataset (to fit the model)\n    :parameters p_validation_df: The Training dataset (to validate the model)\n    :parameters p_train_df: The Training dataset (to do prediction)\n    :parameter p_seed: The seed value\n    :return: The machine learning model  \n    \"\"\"\n    print('----------------------------- kaggle_ml_quick_and_dirty -----------------------------')\n    # Build training & validation datasets\n    p = p_train_df.copy()\n    # Remove NaN values\n    p.dropna(axis = 0, inplace = True)\n    # Ignore categorical values\n    p = p.select_dtypes(exclude=['object'])\n    Y_train = p[TARGET_COLUMNS]\n    if FEATURES_SELECTION is None:\n        X_train = p.drop(TARGET_COLUMNS, axis = 1)\n    else:\n        X_train = p[FEATURES_SELECTION]\n\n    p = p_validation_df.copy()\n    # Remove NaN values\n    p.dropna(axis = 0, inplace = True)\n    # Ignore categorical values\n    p = p.select_dtypes(exclude=['object'])\n    Y_validation = p[TARGET_COLUMNS]\n    if FEATURES_SELECTION is None:\n        X_validation = p.drop(TARGET_COLUMNS, axis = 1)\n    else:\n        X_validation = p[FEATURES_SELECTION]\n\n    # Use classical model\n    model = None\n    if OUTPUT_IS_REGRESSION:\n        model = ensemble.RandomForestRegressor(n_estimators = 128, max_depth = 16, max_features = 4, random_state = p_seed)\n    else:\n        model = ensemble.RandomForestClassifier(n_estimators = 128, max_depth = 16, max_features = 4, random_state = p_seed)\n    # Train the model\n    if len(TARGET_COLUMNS) == 1:\n        model.fit(X_train, Y_train[TARGET_COLUMNS[0]].ravel())\n    else:\n        model.fit(X_train, Y_train)\n    # Do predictions\n    y_predictions = model.predict(X_validation)\n    # Get scoring\n    if OUTPUT_IS_REGRESSION:\n        print('kaggle_ml_quick_and_dirty: Model R2 score=%f' % (r2_score(Y_validation, y_predictions)))\n        print('kaggle_ml_quick_and_dirty: : Model Mean absolute error regression loss (MAE): %0.4f' % mean_absolute_error(Y_validation, y_predictions))\n        print('kaggle_ml_quick_and_dirty: : Model Mean squared error regression loss (MSE): %0.4f' % mean_squared_error(Y_validation, y_predictions))\n        print('kaggle_ml_quick_and_dirty: : Mean squared error regression loss (RMSE): %0.4f' % np.sqrt(mean_squared_error(Y_validation, y_predictions)))\n    else:\n        print('kaggle_ml_quick_and_dirty: Model accuracy score: %0.4f' % accuracy_score(Y_validation, y_predictions))\n        print('kaggle_ml_quick_and_dirty: ROC=%s' %(roc_auc_score(Y_validation, y_predictions)))\n        print('kaggle_ml_quick_and_dirty: Model F1 score=%f' % (f1_score(Y_validation, y_predictions)))\n        print('kaggle_ml_quick_and_dirty: Confusion matrix: %s' % str(confusion_matrix(Y_validation, y_predictions)))\n        print('kaggle_ml_quick_and_dirty: Classification report:\\n%s' % str(classification_report(Y_validation, y_predictions)))\n    \n    # Do prediction with unseen data\n    if not p_test_df is None:\n        p = p_test_df.copy()\n        # Remove NaN values\n        p.dropna(axis = 0, inplace = True)\n        # Ignore categorical values\n        p = p.select_dtypes(exclude=['object'])\n        if FEATURES_SELECTION is None:\n            X_validation = p\n        else:\n            X_validation = p[FEATURES_SELECTION]\n        y_predictions = model.predict(X_validation)\n        # FIXME Evaluate the results?\n\n    print('kaggle_ml_quick_and_dirty: Done')\n    return model\n    # End of function kaggle_ml_quick_and_dirty","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, the next step is to prepare the data for ML. Usually, you have better result when all the features (features and outputs) are in numerical format (int or float).\n\n1. Feature engineering. It eliminates NULL or NaN values, duplicate values, and it transforms date/time column, categorical columns into numerical fetures. It identifies & handles outliers... (3.a). Categorical columns are usually of type object and the objective here is to transform these categorical columns into numerical columns. Date/time columns can be either object (e.g. date/time in string format) of type datetime64[ns]. For sepcific features such as 'Age', it is possible to create new feature grouping the Age values per range, between from the lower Age value to the upper Age value\n2. Data transformation. It applies some numerical transformation such as standardization of features... (3.b)\n3. Features selection. It selects and prepares the dataset for the training and the validation (3.c)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3. Prepare the dataset for your Machine Learning processing\n# a) Data Cleaning\nEncoders = dict()\nEncoder_Instance = LabelEncoder() # Use global variable for future reverse features engineering\nImputer_Instance = None\ndef kaggle_features_engineering(p_df: pd.core.frame.DataFrame,                               \n                                p_missing_value_method: str = 'drop_columns', \n                                p_duplicated_value_method: str = 'drop_columns', \n                                p_categorical_onehot_threshold: int = 10, \n                                p_date_time_columns: list = None, \n                                p_date_time_engineering: str = 'python_time') -> pd.core.frame.DataFrame:\n    \"\"\"\n    This function performs a cleaning of the dataset to remove null values, duplicate values, based on the specified method\n    :parameters p_df: The dataset handle\n    :parameters p_missing_value_method: The method to cleanup NaN values in the dataset ('drop_columns', 'drop_lines', 'mean', 'median'). Default: 'drop_columns'\n    :parameters p_duplicated_value_method: The method to cleanup duplicated in the dataset ('drop_columns', 'drop_lines', 'mean', 'median'). Default: 'drop_columns'\n    :parameters p_categorical_onehot_threshold: The maximum cardinality to apply OneHotEncoder to a categorical variable. Defaut: 10\n    :parameters p_date_time_engineering: The method to convert Date/Time. Default: 'python_time'\n    :return: The dataset after the cleanup process\n    \"\"\"\n    global Encoders, Encoder_Instance, Imputer_Instance\n    \n    print('----------------------------- kaggle_features_engineering -----------------------------')\n    # Cleanup dataset\n    old_shape = p_df.shape\n    p = p_df.copy() # The final dataset\n\n    # Apply feature processing resulting of the data analyzing\n    if not FEATURES_PROCESSING is None and isinstance(FEATURES_PROCESSING, dict):\n        for key in FEATURES_PROCESSING.keys():\n            if key in p.columns:\n                p[key] = p[key].apply(FEATURES_PROCESSING[key])\n        # End of 'for' statement\n\n    # Build the list of categorical and numerical features\n    categorical_columns = [col for col in p.columns if p[col].dtype == 'object']\n    numerical_columns = [col for col in p.columns if p[col].dtype == 'int64' or p[col].dtype == 'float64']\n    print('kaggle_features_engineering: Initial categorical_columns:')\n    print(categorical_columns)\n    print('kaggle_features_engineering: Initial numerical_columns:')\n    print(numerical_columns)\n    if p_date_time_columns is not None:\n        if len(categorical_columns) != 0:\n            categorical_columns = list(set(categorical_columns) - set(p_date_time_columns))\n        numerical_columns = list(set(numerical_columns) - set(p_date_time_columns))\n\n    # Convert Date/time columns\n    # dtype = 'datetime64[ns]'\n    print('----------------------------- kaggle_features_engineering: Processing Date/Time columns')\n    if p_date_time_columns is not None: # Process specified columns\n        # Check date/time formats\n        for column in p_date_time_columns: # TODO Check if all DateTime values have the same format, i.e. same length\n            date_lengths = p[column].str.len().value_counts()\n            print('kaggle_features_engineering: %s lengths:' % column)\n            print('%s - %d' % (str(date_lengths), len(date_lengths)))\n        # End of 'for' statement\n        p[p_date_time_columns] = p[p_date_time_columns].astype('datetime64[ns]')\n        p[p_date_time_columns] = p[p_date_time_columns].astype('int64')\n        print('kaggle_features_engineering: Date/time columns processed')\n    else:\n        print('kaggle_features_engineering: No date/time values')\n    # Be sure there is no more 'datetime64[ns]' types in the dataset\n    datetime_columns = [col for col in p.columns if p[col].dtype == 'datetime64[ns]']\n    if len(datetime_columns) != 0:\n        raise Exception('kaggle_features_engineering: There still has datetime64[ns] type in dataset', 'method=%s' % str(p.info()))\n\n    # Find N/A values for categorical columns and replace them by the value with the higher frequency\n    print('----------------------------- kaggle_features_engineering: Processing NaN values')\n    categorical_columns_with_nan = [col for col in p.columns if p[col].dtype == 'object' and p[col].isna().sum() != 0]\n    if len(categorical_columns_with_nan) != 0:\n        print('----------------------------- kaggle_features_engineering: Impute NaN values for categorical columns with MAX value')\n        for col in categorical_columns_with_nan:\n            p[col].fillna(p[col].value_counts().idxmax(), inplace = True)\n        # End of 'for'statement\n        # Check that there are no more categorical columns with NaN\n        categorical_columns_with_nan = [col for col in p.columns if p[col].dtype == 'object' and p[col].isna().sum() != 0]\n        if len(categorical_columns_with_nan) != 0:\n            raise Exception('kaggle_features_engineering: There still has categorical columns with NaN value in dataset', 'method=%s' % str(categorical_columns_with_nan))\n    else:\n        print('----------------------------- kaggle_features_engineering: No NaN value in categorical columns')\n    # Use Imputation to replace NaN in numerical columns\n    print('----------------------------- kaggle_features_engineering: Impute NaN values for numerical columns with %s method' % p_missing_value_method)\n    numerical_columns_with_nan = [col for col in p.columns if (p[col].dtype == 'int64' or p[col].dtype == 'float64') and p[col].isna().sum() != 0]\n    if len(numerical_columns_with_nan) != 0:\n        print('kaggle_features_engineering: cols_with_missing: %s' % (str(numerical_columns_with_nan)))\n        # Find rows with missing values\n        rows_with_null = p[numerical_columns_with_nan].isnull().any(axis=1)\n        rows_with_missing = p[rows_with_null]\n        print('kaggle_features_engineering: rows_with_missing: %s/%s' % (rows_with_missing.shape[0], p.shape[0]))\n        # Impute missimg values\n        if p_missing_value_method == 'drop_columns': # Impute removing columns\n            p = p.drop(numerical_columns_with_nan, axis = 1)\n        elif p_missing_value_method == 'drop_lines' and len(rows_with_null) != 0: # Impute removing rows\n            p = p.dropna()\n        else: # Imputate using SimpleImputer\n            if Imputer_Instance is None:\n                if p_missing_value_method == 'mean':\n                    Imputer_Instance = SimpleImputer(strategy='mean')\n                elif p_missing_value_method == 'median':\n                    Imputer_Instance = SimpleImputer(strategy='median')\n                else:\n                    raise Exception('kaggle_features_engineering: Invalid method', 'method=%s' % (p_missing_value_method))\n            # else, nothing to do\n            labels = p.columns # Save labels\n            Imputer_Instance = Imputer_Instance.fit(p[numerical_columns_with_nan])\n            p[numerical_columns_with_nan] = Imputer_Instance.transform(p[numerical_columns_with_nan])\n            #p[numerical_columns_with_nan] = pd.DataFrame(Imputer_Instance.fit_transform(p))\n            # Restore column names\n            p.columns = labels\n            print('kaggle_features_engineering: Cleaning NaN values: old_shape: %s / new shape: %s' % (str(old_shape), str(p.shape)))\n            print(p.head())\n            numerical_columns_with_nan = [col for col in p.columns if (p[col].dtype == 'int64' or p[col].dtype == 'float64') and p[col].isna().sum() != 0]\n            if len(numerical_columns_with_nan) != 0:\n                raise Exception('kaggle_features_engineering: There still has numerical columns with NaN value in dataset', 'method=%s' % str(numerical_columns_with_nan))\n    else:\n        print('kaggle_features_engineering: No missing values in numerical columns')\n    print('----------------------------- kaggle_features_engineering: After First round:')\n    #print(p.head())\n    print(p.describe().T)\n\n    print('----------------------------- kaggle_features_engineering: Features creation/deletion:')\n    if not FEATURES_CREATION is None or not FEATURES_DELETION is None:\n        # Features creation\n        if not FEATURES_CREATION is None:\n            for key in FEATURES_CREATION.keys():\n                p[key] = p.apply(FEATURES_CREATION[key], axis = 1)\n                # End of 'for' statement\n        if not FEATURES_DELETION is None:\n            p.drop(FEATURES_DELETION, inplace = True, axis = 1)\n        categorical_columns = [col for col in p.columns if p[col].dtype == 'object']\n        numerical_columns = [col for col in p.columns if p[col].dtype == 'int64' or p[col].dtype == 'float64']\n        print('kaggle_features_engineering: Rebuild categorical_columns:')\n        print(categorical_columns)\n        print('kaggle_features_engineering: Rebuild numerical_columns:')\n        print(numerical_columns)\n    print('----------------------------- kaggle_features_engineering: After Second round:')\n    #print(p.head())\n    print(p.describe().T)\n\n    # Search for categorical variables\n    print('----------------------------- kaggle_features_engineering: Encoding categorical columns:')\n    new_categorical_columns = []\n    if len(categorical_columns) != 0:\n        print('kaggle_features_engineering: categorical_columns: ' + str(categorical_columns))\n        # Compute cardinalities of the categorical vairiables\n        categorical_columns_cardinalities = list(map(lambda col: p[col].nunique(), categorical_columns))\n        print('kaggle_features_engineering: categorical_columns_cardinalities: ')\n        print(categorical_columns_cardinalities)\n        print('kaggle_features_engineering: OneHotEncoder thresholds: %d' % p_categorical_onehot_threshold)\n        # Apply OneHot encoding to categorical value with very low cardinality\n        cols_processed = []\n        new_categorical_columns = categorical_columns.copy()\n        for i in range(0, len(categorical_columns)):\n            if categorical_columns_cardinalities[i] <= p_categorical_onehot_threshold:\n                print('kaggle_features_engineering: OneHotEncoder: %s' % categorical_columns[i])\n                if not Encoders is None:\n                    if not categorical_columns[i] in Encoders:\n                        Encoders[categorical_columns[i]] = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n                else:\n                    Encoders[categorical_columns[i]] = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n                new_col = Encoders[categorical_columns[i]].fit_transform(pd.DataFrame(p[categorical_columns[i]]))\n                new_col = pd.DataFrame(new_col, columns = [(categorical_columns[i] + \"_\" + str(j)) for j in range(new_col.shape[1])])\n                new_col.index = p[categorical_columns[i]].index\n                p.drop(categorical_columns[i], inplace = True, axis = 1)\n                p = pd.concat((p, new_col), axis = 1)\n                cols_processed.append(categorical_columns[i])\n                # Update the list of the categorical columns\n                new_categorical_columns.remove(categorical_columns[i])\n                new_categorical_columns.extend(new_col.columns.tolist())\n            else:\n                print('!!!!!!!!!!!!!!!!!!!! kaggle_features_engineering: Cannot process %s' % categorical_columns[i])\n                # Just drop them for the time being\n                # FIXME To be refined using TargetEncoder\n                p.drop(categorical_columns[i], axis = 1, inplace = True)\n                # Update the list of the categorical columns\n                new_categorical_columns.remove(categorical_columns[i])\n        # End of 'for' statement\n        if len(cols_processed) != 0:\n            print('kaggle_features_engineering: Encoders applied on %s' % str(cols_processed))\n            print('kaggle_features_engineering: New datase structure:')\n            #print(p.head())\n            print(p.describe().T)\n            categorical_columns = [col for col in p.columns if p[col].dtype == 'object']\n            print('kaggle_features_engineering: Cleaning categorical values: old_shape: %s / new shape: %s' % (str(old_shape), str(p.shape)))\n            print('kaggle_features_engineering: new Categorical columns:')\n            print(categorical_columns)\n            # Compute new cardinalities of the categorical vairiables\n            categorical_columns_cardinalities = list(map(lambda col: p[col].nunique(), categorical_columns))\n            print('kaggle_features_engineering: New categorical_columns_cardinalities: ')\n            print(categorical_columns_cardinalities)\n        # TODO: Drop categorical variables with extrem cardinalities\n        # Encode categorical variables using numerical mapping\n        for col in categorical_columns:\n            p[col] = Encoder_Instance.fit_transform(p[col].astype(str))\n            # End of 'for' statement\n            print('kaggle_features_engineering: Labelling:')\n            #print(p.head())\n            print(p.describe().T)\n        # End of 'for' statement\n    else:\n        print('kaggle_features_engineering: No categorical values')\n    # Be sure there is no more 'object' types in the dataset\n    categorical_columns = [col for col in p.columns if p[col].dtype == 'object']\n    if len(categorical_columns) != 0:\n        raise Exception('kaggle_features_engineering: There still has object type in dataset', 'method=%s' % str(categorical_columns))\n    print('----------------------------- kaggle_features_engineering: After Third round:')\n    #print(p.head())\n    print(p.describe().T)\n\n    # Identifying & handling outliers\n    print('----------------------------- kaggle_features_engineering: Identifying & handling outliers:')\n    for c in numerical_columns:\n        q25, q75 = np.percentile(p[c], 25), np.percentile(p[c], 75)\n        iqr = q75 - q25\n        print('kaggle_features_engineering: IRQ range %f' % iqr)\n        # Outlier cutoff threshold\n        cut_off = iqr * 1.5\n        if not cut_off == 0:\n            lower_bound, upper_bound = q25 - cut_off, q75 + cut_off\n            print('kaggle_features_engineering: Outliers thresholds for %s: (%f, %f)' % (c, lower_bound, upper_bound))\n            outliers = [x for x in p[c] if x < lower_bound or x > upper_bound]\n            mean = p[c].mean()\n            if len(outliers) != 0:\n                print('kaggle_features_engineering: Outliers for %s' % c)\n                print(outliers)\n                p[c] = p[c].apply(lambda x: mean if x < lower_bound or x > upper_bound else x)\n            else:\n                print('No outliers for %s' % c)\n        else:\n            print('No outliers for %s' % c)\n    print('----------------------------- kaggle_features_engineering: After Fourth round:')\n    #print(p.head())\n    print(p.describe().T)\n    \n#    raise Exception('Stop', 'Stop')\n\n    # Rebuild the list of categorical and numerical features\n    categorical_columns = [col for col in p.columns if p[col].dtype == 'object']\n    numerical_columns = [col for col in p.columns if p[col].dtype == 'int64' or p[col].dtype == 'float64']\n    if p_date_time_columns is not None:\n        if len(categorical_columns) != 0:\n            categorical_columns = list(set(categorical_columns) - set(p_date_time_columns))\n        numerical_columns = list(set(numerical_columns) - set(p_date_time_columns))\n    print('----------------------------- kaggle_features_engineering: Categorical columns after: ', categorical_columns)\n    print('----------------------------- kaggle_features_engineering: Nunmerical columns after: ', numerical_columns)\n\n    print('kaggle_features_engineering: ', list(new_categorical_columns)) \n    print('kaggle_features_engineering: Done') \n    return p, new_categorical_columns, numerical_columns\n    # End of function kaggle_features_engineering","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TODO: Add data engineering results"},{"metadata":{},"cell_type":"markdown","source":"There are different kinds of data transformation:\n- Standardization: It removes the mean and scaling to unit variance of the feature (see point 2.a)\n- Scaling: It rescales the feature values in a range of 0 and 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# b) Data Transforms\nTransform = dict()\ndef kaggle_data_transform(p_df: pd.core.frame.DataFrame, p_columns:list = None, p_transform: str = 'standard') -> pd.core.frame.DataFrame:\n    \"\"\"\n    Apply data transformation to the provided dataset\n    :parameters p_df: The dataset handle\n    :parameters p_columns: The columns to apply transformation (e.g. we don't apply transformation on categorical column)\n    :parameter p_transform: The type of transormation. Default: 'standard'\n                            'standard': Remove the mean and scaling to unit variance\n                            'scale': Scale feature to a Min/max range\n                            'abs_scale': Scale feature to a range [-1, 1]\n    :return: The dataset after features selection\n    \"\"\"\n    print('----------------------------- kaggle_data_transform -----------------------------')\n    global Transform\n    \n    p = None\n    size = str(p_df.shape[1])\n    if not size in Transform:\n        if p_transform == 'standard':\n            # Standardization, or mean removal and variance scaling\n            Transform[size] = StandardScaler()\n        elif p_transform == 'scale':\n            # Scaling features to a range\n            Transform[size] = MinMaxScaler()\n        elif p_transform == 'abs_scale':\n            # Scaling features to a range\n            Transform[size] = MaxAbsScaler()\n        else:\n            raise Exception('kaggle_data_transform: Wrong parameters', 'p_transform=%s' % p_transform)\n        if p_columns is None: # Apply transformamtion to the whole dataset\n            p = Transform[size].fit_transform(p_df)\n            p = pd.DataFrame(data = p, columns = p_df.columns)\n        else:\n            p = p_df.copy() \n            p[p_columns] = Transform[size].fit_transform(p_df[p_columns])\n    else:\n        if p_columns is None: # Apply transformamtion to the whole dataset\n            p = Transform[size].transform(p_df)\n            p = pd.DataFrame(data = p, columns = p_df.columns)\n        else:\n            #print('==> p_df[p_columns].shape=', p_df[p_columns].shape)\n            #print('==> p_df[p_columns].columns=', p_df[p_columns].columns)            \n            p = Transform[size].transform(p_df[p_columns])\n            #print('==> p.shape=', p.shape)\n            p = pd.DataFrame(data = p, columns = p_df[p_columns].columns)\n    print('kaggle_data_transform: Dataset Head:')\n    print(p.head())\n    \n    print('kaggle_data_transform: Done')\n    return p\n    # End of function kaggle_data_transform","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The kaggle_features_selection() function splits the dataset into the input features and the target features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# b) Features Selection\ndef kaggle_features_selection(p_df: pd.core.frame.DataFrame, p_correlation_threshold:float = 0.7) -> pd.core.frame.DataFrame:\n    \"\"\"\n    Reorganize the dataset to keep only provided attributes, the target column is the last column of the new dataset\n    :parameters p_df: The dataset handle\n    :parameters p_correlation_threshold: Correlation threshold to calculate lower bound and upper bound for feature removing\n    :return: The dataset after features selection\n    \"\"\"\n    if not FEATURES_SELECTION is None:\n        print('----------------------------- kaggle_features_selection: Features selection is forced, skip it')\n        print('kaggle_features_selection: Done')\n        return p_df[FEATURES_SELECTION], []\n\n    # Build Correlation matrix\n    print('----------------------------- kaggle_features_selection: Correlation table:')\n    p = p_df.copy()\n    p_corr = p.drop(TARGET_COLUMNS, axis = 1)\n    # Extract correlation > 0.7 and < -0.7\n    cor_matrix = p_corr.corr(method = 'pearson')\n    print('----------------------------- kaggle_features_selection: cor_matrix:')\n    print(cor_matrix)\n    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k = 1).astype(np.bool))\n    print('----------------------------- kaggle_features_selection: Correlations in range > %f and < -%f:' % (p_correlation_threshold, p_correlation_threshold))\n    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > p_correlation_threshold)]\n    print('kaggle_features_selection: Drop ', to_drop)\n    if len(to_drop) != 0:\n        # Drop correlated columns\n        p.drop(to_drop, axis = 1, inplace = True)\n        print('----------------------------- kaggle_features_selection: new dataset:')\n        print(p.head())\n        print(p.describe().T)\n\n    print('kaggle_features_selection: Done')\n    return p, to_drop \n    # End of function kaggle_features_selection","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TODO Add features selection comments"},{"metadata":{},"cell_type":"markdown","source":"After cleaning and transforming the initial dataset, we can use it to train and validate our ML. So, The next step is to shuffle our dataset in three different 'sub-datasets' (point 4.a):\n1. The training dataset, used to evaluate the ML models\n2. The validation dataset, used to validate the selected model\n3. The test dataset, use to test the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Evaluate Algorithms\n# a) Split-out validation dataset\ndef kaggle_split_dataset(p_df: pd.core.frame.DataFrame, p_target: list = TARGET_COLUMNS) -> list:\n    \"\"\"\n    Split the into input features and target features\n    :parameters p_df: The dataset handle\n    :parameter p_target The outputs of the Machine Learning\n    :return: The list of input features and target features\n    \"\"\"\n    print('----------------------------- kaggle_split_dataset -----------------------------')\n    y_values = None\n    x_values = None\n    if set(p_target).issubset(set(p_df.columns)):\n        y_values = p_df[p_target]\n        x_values = p_df.drop(p_target, axis = 1)\n    else:\n        x_values = p_df\n    \n    # Re-order column by column name\n    x_values = x_values.reindex(sorted(x_values.columns), axis = 1)\n    \n    print('----------------------------- kaggle_split_dataset: x_values:')\n    print(x_values.head())\n    if not y_values is None:\n        print('----------------------------- kaggle_split_dataset: y_values:')\n        print(y_values.head())\n\n    print('kaggle_split_dataset: Done')\n    return x_values, y_values\n    # End of function kaggle_split_dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can apply different models (linear, non-linear, ensemble...) to build our ML and evaluate their efficiency (4.b)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# b) Check models\ndef kaggle_check_models(p_models: list, p_inputs_training_df: pd.core.frame.DataFrame, p_outputs_training_df: pd.core.frame.DataFrame, p_kparts: int = 10, p_random_state: int = SEED_HARCODED_VALUE, p_cross_validation: str = 'k-fold', p_scoring: str = 'accuracy') -> list:\n    \"\"\"\n    Apply different models to train our Machine Learning and evaluate their efficiency\n    :parameter p_models: A list of models to use for to train the Machine Learning\n    :parameter p_inputs_training_df: The training inputs dataset (training attributes)\n    :parameter p_outputs_training_df: The training output dataset (training target)\n    :parameter p_inputs_valid_df: The validation inputs dataset (validation attributes)\n    :parameter p_outputs_valid_df: The validation output dataset (validation target)\n    :parameter p_kparts: The size of the KFolds\n    :parameter p_random_state: \n    :parameter p_cross_validation:  KFold or StratifiedKFold. Default: k-fold\n    :parameter p_scoring: \n    :return: The list of couple (result, model name)\n    \"\"\"\n    print('----------------------------- kaggle_check_models -----------------------------')\n    results = []\n    names = []\n    for name, model in p_models:\n        print('kaggle_check_models: Processing %s with type %s' % (name, type(model)))\n        # Create train/test indices to split data in train/test sets\n        if p_cross_validation == 'k-fold':\n            kfold = model_selection.KFold(n_splits = p_kparts, random_state = p_random_state, shuffle = True) # K-fold Cross Validation\n        elif p_cross_validation == 's-k-fold':\n            kfold = model_selection.StratifiedKFold(n_splits = p_kparts, random_state = p_random_state, shuffle = True) # K-fold Cross Validation\n        else:\n            raise Exception('kaggle_check_models: Wrong parameters', 'p_cross_validation:%s' % p_cross_validation)\n        cv_results = None\n        # Evaluate model performance\n        if p_outputs_training_df.shape[1] == 1:\n            p = p_outputs_training_df[TARGET_COLUMNS[0]].ravel()\n        else:\n            p = p_outputs_training_df\n        if p_cross_validation == 'k-fold' or p_cross_validation == 's-k-fold':\n            cv_results = model_selection.cross_val_score(model, p_inputs_training_df, p, cv = kfold, scoring = p_scoring)\n        else:\n            cv_results = model_selection.cross_val_score(model, p_inputs_training_df, p, cv = LeaveOneOut(), scoring = p_scoring)\n        print('kaggle_check_models: cv_result=%s' % str(cv_results))\n        results.append(cv_results)\n        names.append(name)\n        msg = 'kaggle_check_models: %s metric: %s: %f (%f)' % (p_scoring, name, cv_results.mean(), cv_results.std())\n        print(msg)\n        # End of 'for' loop\n\n    print('kaggle_check_models: Done')\n    return results, names\n    # End of function kaggle_check_models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, we select the best model based on the scoring (4.c)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def kaggle_compare_algorithms_perf(p_names: list, p_metrics: list, p_title: str, p_x_label: str, p_y_label:str) -> int:\n    \"\"\"\n    Compare and return the model with the best results\n    :parameter p_names: The list of models executed\n    :parameter p_metrics: The scorimng obtained by each model\n    :parameter p_title: Performance plot title\n    :parameter p_x_label: Performance plot X-axis label\n    :parameter p_y_label: Performance plot Y-axis label\n    :return: The index of the model with the higher scoring\n    \"\"\"\n    print('----------------------------- kaggle_compare_algorithms_perf -----------------------------')\n    # Extract means & std\n    means = []\n    stds = []\n    for i in range (len(p_names)):\n        cv_results = p_metrics[i]\n        means.append(cv_results.mean())\n        stds.append(cv_results.std())\n        # End of 'for' statement\n    # Display means/standard deviation\n    plt.title(p_title)\n    plt.xlabel(p_x_label)\n    plt.ylabel(p_y_label)\n    plt.errorbar(p_names, means, stds, linestyle='None', marker='^')\n    #plt.savefig('kaggle_algorithms_comparison.png')\n    plt.show()\n    # Select the best algorithm\n    m = np.array(means)\n    maxv = np.amax(m)\n    idx = np.where(m == maxv)[0][0]\n    print('kaggle_compare_algorithms_perf: Max value: %d:%f +/- %f ==> %s' % (idx, maxv, 2 * stds[idx], p_names[idx]))\n\n    print('kaggle_compare_algorithms_perf: Done')\n    return idx\n    # End of function kaggle_compare_algorithms_perf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we will use the GridSearchCV() function to find the best model parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5. Improve Accuracy\n# a) Algorithm Tuning\ndef kaggle_algorithm_tuning(p_algorithm: list, p_inputs_training_df: pd.core.frame.DataFrame, p_outputs_training_df: pd.core.frame.DataFrame, p_validation_data: list = None):\n    \"\"\"\n    Tuning model parameters\n    :parameter p_algorithm: The ML model to tune\n    :parameter p_inputs_training_df: The input training tada\n    :parameter p_outputs_training_df: The target for the training data\n    :parameter p_validation_data: The input validation data\n    :return: The tuned model\n    \"\"\"\n    print('----------------------------- kaggle_algorithm_tuning -----------------------------')\n    model = p_algorithm[1]\n    print('----------------------------- kaggle_algorithm_tuning: %s' % model.__class__.__name__)\n    print('----------------------------- kaggle_algorithm_tuning: model summary:')\n    print(model)\n    print(model.get_params())\n\n    # Fit the model\n    if model.__class__.__name__ == 'LinearRegression': # No Hyper parameters tuning\n        print('kaggle_algorithm_tuning: No Hyper parameters tuning for LinearRegression')\n        model.fit(p_inputs_training_df, p_outputs_training_df)\n        return model\n    elif not model.__class__.__name__.startswith('Keras'):\n        # Hyper parameters tuning\n        print('----------------------------- kaggle_algorithm_tuning: Hyper parameters tuning')\n        if model.__class__.__name__.startswith('SV'):\n            param_grid = {\n                'C': [0.1, 1, 10, 100], \n                'gamma': [1, 0.1, 0.01, 0.001],\n                'kernel': ['rbf', 'poly', 'sigmoid']\n            }\n        elif model.__class__.__name__.startswith('KNeighbors'):\n            param_grid = {\n                'n_neighbors': [4, 8, 16, 32], \n                'weights': ['uniform', 'distance'],\n                'algorithm': ['ball_tree', 'kd_tree', 'brute']\n            }\n        elif model.__class__.__name__.startswith('LGBM'):\n            param_grid = {\n                'num_leaves': [32, 128],\n                'reg_alpha': [0.1, 0.5],\n                'min_data_in_leaf': [32, 64, 128, 256],\n                'lambda_l1': [0, 1, 1.5],\n                'lambda_l2': [0, 1],\n                'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.4, 0.6],\n            }\n        else:\n            # Global grid parameters\n            param_grid = {\n                'n_estimators': [256, 512, 1024],\n                'max_depth': [16, 24 , 32],\n                'max_leaf_nodes': [64, 128, 256],\n                'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.4, 0.6],\n                #'loss': ['deviance'],\n                #'min_samples_split': np.linspace(0.1, 0.5, 3),\n                #'min_samples_leaf': np.linspace(0.1, 0.5, 3),\n                #'max_features': ['log2', 'sqrt'],\n                #'criterion': ['friedman_mse',  'mae'],\n                #'subsample': np.linspace(0.5, 1.0, 3),\n            }\n            # Remove unsupported parameters\n            if model.__class__.__name__.startswith('RandomForest'):\n                del param_grid['learning_rate']\n\n        tunning = GridSearchCV(\n            estimator = model,\n            param_grid = param_grid, \n            cv = 5, \n            n_jobs = 5, \n            scoring = 'neg_mean_squared_error',\n            verbose = 2\n        )\n        if p_outputs_training_df.shape[1] == 1:\n            model = tunning.fit(p_inputs_training_df, p_outputs_training_df[TARGET_COLUMNS[0]].ravel())\n        else:\n            model = tunning.fit(p_inputs_training_df, p_outputs_training_df)\n        print('----------------------------- kaggle_algorithms_tuning: Hyper parameters tuning ended:')\n        print('kaggle_algorithm_tuning: Hyper parameters tuning: best_score_=', model.best_score_)\n        print('kaggle_algorithm_tuning: Hyper parameters tuning: best_params_=', model.best_params_)\n        print('kaggle_algorithm_tuning: Hyper parameters tuning: best_estimator_=', model.best_estimator_)\n        model = model.best_estimator_\n    else:\n        early_stopping = keras.callbacks.EarlyStopping(patience = 5, min_delta = 0.001, restore_best_weights = True)\n        history = model.fit(p_inputs_training_df, p_outputs_training_df, validation_data = p_validation_data, epochs = DL_EPOCH_NUM, batch_size = DL_BATCH_SIZE * strategy.num_replicas_in_sync, callbacks = [early_stopping])\n        print('----------------------------- kaggle_algorithm_tuning: loss/val_loss plot')\n        history = pd.DataFrame(history.history)\n        history.loc[:, ['loss', 'val_loss']].plot(title=\"loss/val_loss\")\n        print('kaggle_algorithm_tuning: Minimum Validation Loss: {:0.4f}' & history_df['val_loss'].min())\n    \n    print('kaggle_algorithm_tuning: Done')\n    return model\n    # End of function kaggle_algorithm_tuning","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we reached the point where we can evaluate our model with Validation and/or Test datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# b) Ensembles\n# 6. Finalize Model\n# a) Predictions on validation dataset\ndef kaggle_validation_prediction(p_model, p_inputs, p_expected_outputs) -> np.ndarray:\n    \"\"\"\n    Executes prediction (p_inputs) and compares outputs against expected outputs (Validation) using the specified ML model\n    :parameter p_model: \n    :parameter p_inputs: \n    :parameter p_expected_outputs: \n    \"\"\"\n    print('----------------------------- kaggle_validation_prediction -----------------------------')\n    print('kaggle_validation_prediction: model=%s - is_class:%s - is_regr:%s' % (p_model.__class__.__name__, str(is_classifier(p_model)), str(is_regressor(p_model))))\n    y_predictions = p_model.predict(p_inputs)\n    print('kaggle_validation_prediction: Score: ', round(p_model.score(p_inputs, p_expected_outputs) * 100, 2), \" %\")\n    if is_regressor(p_model) or p_model.__class__.__name__ == 'KerasRegressor': # Regression metrics (continuous target values)\n        print('kaggle_validation_prediction: Model R2 score=%f' % (r2_score(p_expected_outputs, y_predictions)))\n        print('kaggle_validation_prediction: : Model Mean absolute error regression loss (MAE): %0.4f' % mean_absolute_error(p_expected_outputs, y_predictions))\n        print('kaggle_validation_prediction: : Model Mean squared error regression loss (MSE): %0.4f' % mean_squared_error(p_expected_outputs, y_predictions))\n        print('kaggle_validation_prediction: : Mean squared error regression loss (RMSE): %0.4f' % np.sqrt(mean_squared_error(p_expected_outputs, y_predictions)))\n        # Analyze residual errors\n        plt.scatter(p_expected_outputs, y_predictions)\n        plt.show()\n        # TODO Interpreting the Cofficients if possible\n    elif is_classifier(p_model) or p_model.__class__.__name__ == 'KerasClassifier': # Classification metrics (class target values)\n        print('kaggle_validation_prediction: accuracy=%s' %(accuracy_score(p_expected_outputs, y_predictions)))\n        print('kaggle_validation_prediction: Model F1 score=%f' % (f1_score(p_expected_outputs, y_predictions)))\n        print('kaggle_validation_prediction: ROC=%s' %(roc_auc_score(p_expected_outputs, y_predictions)))\n        print('kaggle_validation_prediction: Confusion_matrix:%s' % str(confusion_matrix(p_expected_outputs, y_predictions)))\n        print('kaggle_validation_prediction: Classification report:\\n%s' % str(classification_report(p_expected_outputs, y_predictions)))\n    else:\n        raise Exception('kaggle_validation_prediction: Invalid model')\n    print('kaggle_validation_prediction: prediction is %s' % (str(y_predictions)))\n\n    print('kaggle_validation_prediction: Done')\n    return y_predictions\n    # End of function kaggle_validation_prediction\n\ndef kaggle_prediction(p_model, p_inputs) -> np.ndarray:\n    \"\"\"\n    Executes prediction (p_inputs) using the specified ML model\n    :parameter p_model: \n    :parameter p_inputs:  \n    \"\"\"\n    print('----------------------------- kaggle_prediction -----------------------------')\n    y_prediction = p_model.predict(p_inputs)\n    print('kaggle_prediction: prediction is %s' %(str(y_prediction)))\n    print('kaggle_prediction: Done')\n    return y_prediction\n# b) Create standalone model on entire training dataset\n# TODO","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The functions below are some helper to save the model and to save our Machine Learning outcomes in Kaggle compete format."},{"metadata":{"trusted":true},"cell_type":"code","source":"# c) Save model for later use\ndef kaggle_save_model(p_model, p_paths: str, p_file_name:str) -> None:\n    \"\"\"\n    Save the provided model in binary/pickle format and the Encoders/Imputers\n    :parameter p_model: The ML model to save\n    :parameter p_paths: The path to save the files, ending with a '/' (e.g. ./)\n    :parameter p_file_name: The file name woithout extension file (e.g. './MyModel')\n    \"\"\"\n    global Encoders, Encoder_Instance, Imputer_Instance, Transform\n\n    print('----------------------------- kaggle_save_model -----------------------------')\n    # Serialize the model\n    pickle.dump(p_model, open(p_paths + p_file_name + '.pkl', 'wb'))\n    print('kaggle_save_model: Done: %s' % (p_file_name + '.pkl'))\n    # Save Encoders, Encoder_Instance and Imputer_Instance\n    if not Encoders is None and len(Encoders) != 0:\n        pickle.dump(Encoders, open(p_paths + 'Encoders.pkl', 'wb'))\n    if not Encoder_Instance is None:\n        pickle.dump(Encoder_Instance, open(p_paths + 'Encoder_Instance.pkl', 'wb'))\n    if not Imputer_Instance is None:\n        pickle.dump(Imputer_Instance, open(p_paths + 'Imputer_Instance.pkl', 'wb'))\n    if not Transform is None:\n        pickle.dump(Transform, open(p_paths + 'Transform.pkl', 'wb'))\n\n    print('kaggle_save_model: Done')\n    # End of function kaggle_save_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load model\ndef kaggle_load_model(p_paths: str, p_file_name:str):\n    \"\"\"\n    Load a model in binary/pickle format and the Encoders/Imputers\n    :parameter p_model: The ML model to save\n    :parameter p_paths: The path to save the files, ending with a '/' (e.g. ./)\n    :parameter p_file_name: The file name woithout extension file (e.g. './MyModel')\n    \"\"\"\n    global Encoders, Encoder_Instance, Imputer_Instance, Transform\n\n    print('----------------------------- kaggle_load_model -----------------------------')\n    try:\n        Encoders = pickle.load(open(p_paths + 'Encoders.pkl', 'rb'))\n    except:\n        Encoders = Dict()\n    try:\n        Encoder_Instance = pickle.load(open(p_paths + 'Encoder_Instance.pkl', 'rb'))\n    except:\n        Encoder_Instance = LabelEncoder()\n    try:\n        Imputer_Instance = pickle.load(open(p_paths + 'Imputer_Instance.pkl', 'rb'))\n    except:\n        Imputer_Instance = None\n    try:\n        Transform = pickle.load(open(p_paths + 'Transform.pkl', 'rb'))\n    except:\n        Transform = None\n    model = pickle.load(open(p_paths + p_file_name + '.pkl', 'rb'))\n    \n    print('kaggle_load_model: Done')\n    return model\n    # End of function kaggle_load_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The function kaggle_explore_ml() provides some insights from our ML."},{"metadata":{"trusted":true},"cell_type":"code","source":"def kaggle_explore_ml(p_model, p_x_validation: pd.core.frame.DataFrame, p_y_validation: pd.core.frame.DataFrame, p_random_state:int = SEED_HARCODED_VALUE) -> None:\n    \"\"\"\n    Apply feature importance concept to our ML \n    :parameter p_model: The predictions to save\n    \"\"\"\n    print('----------------------------- kaggle_explore_ml -----------------------------')\n    result = permutation_importance(p_model, p_x_validation, p_y_validation, n_repeats = 32, random_state = p_random_state)\n    sorted_idx = result.importances_mean.argsort()\n    print('----------------------------- kaggle_explore_ml: result:')\n    print(sorted_idx)\n\n    fig, ax = plt.subplots()\n    ax.boxplot(result.importances[sorted_idx].T, vert = False, labels = p_x_validation.columns[sorted_idx])\n    ax.set_title(\"Permutation Importances (Validation set)\")\n    fig.tight_layout()\n    plt.show()\n    print('kaggle_explore_ml: Done')\n    # End of function kaggle_explore_ml","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The function kagge_save_result() saves prediction results in Kaggle format for submission to Kaggle Compete"},{"metadata":{"trusted":true},"cell_type":"code","source":"def kaggle_save_result(p_model, p_column:str, p_predictions: np.ndarray, p_validation_df: str, p_file_name:str) -> None:\n    \"\"\"\n    Save prediction results in Kaggle format for submission to compete\n    :parameter p_model: The predictions to save\n    :parameter p_column: The index column name\n    :parameter p_predictions: The prediction results based on Test dataset\n    :parameter p_validation_df: The original validation dataset, to extract the index for Kaggle submission (see p_column)\n    :parameter p_file_name: The file name without extension file (e.g. './MyResults.csv')\n    \"\"\"\n    print('----------------------------- kaggle_save_result -----------------------------')\n    # Reload PassengerID list\n    validation_df = pd.read_csv(p_validation_df)\n    p = validation_df[[p_column]].astype(int)\n    # FIXME How to proceed with multiple outputs?\n    print(p.shape)\n    print(p_predictions.shape)\n    print(len(p_predictions.squeeze()))\n    pred = pd.DataFrame({p_column: list(p.squeeze()), TARGET_COLUMNS[0]: p_predictions.astype(int).squeeze()})\n    pred.to_csv(p_file_name, index = False)\n    print('kaggle_save_result: Done')\n    # End of function kaggle_save_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code below is specific to machine learning. It provides callbacks to create DL models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Start of main application\nDL_INPUT_SHAPE = None\n\ndef kaggle_create_sequential_classifier_model(p_optimizer:str = 'adam', p_loss:str = 'binary_crossentropy', p_metrics:list = ['accuracy']) -> tf.keras.Sequential:\n    \"\"\"\n    Build a Neural network model for classification\n    \"\"\"\n    print('----------------------------- kaggle_create_sequential_classifier_model -----------------------------')\n    model = tf.keras.Sequential([\n            tf.keras.layers.BatchNormalization(input_shape = DL_INPUT_SHAPE),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dropout(rate = DL_DROP_RATE),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dropout(rate = DL_DROP_RATE),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dropout(rate = DL_DROP_RATE),\n            tf.keras.layers.Dense(1, activation='sigmoid'),\n    ])\n    model.compile(optimizer=p_optimizer, loss = p_loss, metrics = p_metrics)\n    return model\n    # End of function kaggle_create_sequential_classifier_model\n\ndef kaggle_create_sequential_regressor_model(p_optimizer:str = 'adam', p_loss:str = 'mae', p_metrics:list = ['mae']) -> tf.keras.Sequential:\n    \"\"\"\n    Build a Neural network model for regression\n    \"\"\"\n    print('----------------------------- kaggle_create_sequential_regressor_model -----------------------------')\n    model = tf.keras.Sequential([\n            tf.keras.layers.BatchNormalization(input_shape = DL_INPUT_SHAPE),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dropout(rate = DL_DROP_RATE),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dropout(rate = DL_DROP_RATE),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dropout(rate = DL_DROP_RATE),\n            tf.keras.layers.Dense(1, activation='relu'),\n    ])\n    model.compile(optimizer=p_optimizer, loss = p_loss, metrics = p_metrics)\n    return model\n    # End of function kaggle_create_sequential_regressor_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finaly, here is the entry point function and the main call:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def kaggle_main() -> None:\n    global DL_INPUT_SHAPE\n    \n    # Set defaults\n    kaggle_set_seed()\n    kaggle_set_mp_default()\n    \n    # Current path\n    print(os.path.abspath(os.getcwd()))\n    # Kaggle current path and files\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n    # Modules version\n    kaggle_modules_versions()\n\n    # Parse arguments. Used only if this notebook code is used as a standalone Python script\n    #flags = ExecutionFlags.NONE\n    flags = ExecutionFlags.ALL \\\n            & ~ExecutionFlags.USE_NEURAL_NETWORK_FLAG \\\n            & ~ExecutionFlags.DATA_STAT_SUMMURIZE_FLAG \\\n            & ~ExecutionFlags.DATA_VISUALIZATION_FLAG \\\n            & ~ExecutionFlags.DATA_TRANSFORM_FLAG\n    #parser = argparse.ArgumentParser()\n    #parser.add_argument('--summarize', help = 'Process statistical analyze', action='store_true')\n    #parser.add_argument('--summarize-only', help = 'Process only statistical analyze', action='store_true')\n    #parser.add_argument('--visualize', help = 'Generate different plots based on statistical analyze', action='store_true')\n    #parser.add_argument('--no-data-cleaning', help = 'Do not apply Data Cleaning', action='store_true')\n    #parser.add_argument('--neural-network', help = 'Use neural network as ML', action='store_true')\n    #args = parser.parse_args()\n    #if args.summarize or args.summarize_only:\n    #    flags |= ExecutionFlags.DATA_STAT_SUMMURIZE_FLAG\n    #if args.visualize:\n    #    flags |= ExecutionFlags.DATA_VISUALIZATION_FLAG\n    #if args.no_data_cleaning:\n    #    flags |= ~ExecutionFlags.DATA_CLEANING_FLAG\n    #if args.neural_network:\n    #    flags |= ExecutionFlags.USE_NEURAL_NETWORK_FLAG\n    \n    # TODO Uncomment if using Pima Indians iabetes dataset\n    #flags &= ~ExecutionFlags.DATA_CLEANING_FLAG\n    print('generic template approach to ''play'' with the Machine Learning concepts: flags=%s' % str(flags))\n\n    strategy = None\n    if flags & ExecutionFlags.USE_NEURAL_NETWORK_FLAG == ExecutionFlags.USE_NEURAL_NETWORK_FLAG:\n        strategy = kaggle_tpu_detection()\n\n    train_df, validation_df, test_df = kaggle_load_datasets(p_url = None, p_train_path = '../input/tabular-playground-series-jan-2021/train.csv', p_validation_path = '../input/tabular-playground-series-jan-2021/test.csv')\n    #print('Main: training dataset')\n    #print(train_df.head())\n    #print('Main: validation dataset')\n    #print(validation_df.head())\n    #print('Main: test dataset')\n    #print(test_df.head())\n\n    # Do a basic ML evaluation as reference for the end\n    # Take too many time - y_basic_predictions = kaggle_ml_quick_and_dirty(train_df, validation_df, test_df)\n\n    numerical_columns = None\n    categorical_columns = None\n    if flags & ExecutionFlags.DATA_STAT_SUMMURIZE_FLAG == ExecutionFlags.DATA_STAT_SUMMURIZE_FLAG:\n        print('Main: Summurize data for training dataset')\n        kaggle_summurize_data(train_df)\n        print('Main: Summurize data for validation dataset')\n        kaggle_summurize_data(validation_df)\n        print('Main: Summurize data for test dataset')\n        kaggle_summurize_data(test_df)\n    #    if args.summarize_only:\n    #        return\n\n    if flags & ExecutionFlags.DATA_VISUALIZATION_FLAG == ExecutionFlags.DATA_VISUALIZATION_FLAG:\n        print('Main: Visualisation for train dataset')\n        kaggle_visualization(train_df)\n\n    categorical_features = None\n    numerical_features = None\n    if flags & ExecutionFlags.DATA_CLEANING_FLAG == ExecutionFlags.DATA_CLEANING_FLAG:\n        train_df, new_categorical_features, numerical_features = kaggle_features_engineering(train_df, p_date_time_columns = DATE_TIME_COLUMNS, p_missing_value_method = 'mean')\n        print(train_df.columns)\n        validation_df, _, _ = kaggle_features_engineering(validation_df, p_date_time_columns = DATE_TIME_COLUMNS, p_missing_value_method = 'mean')\n        print(validation_df.columns)\n        if len(train_df.columns) != len(validation_df.columns):\n            l = list(set(train_df.columns) - set(validation_df.columns))\n            print('Main: Features unaligned for validation_df: ', l)\n            validation_df[l] = 0\n            print(validation_df.columns)\n        test_df, _, _ = kaggle_features_engineering(test_df, p_date_time_columns = DATE_TIME_COLUMNS, p_missing_value_method = 'mean')\n        print(test_df.columns)\n        if len(train_df.columns) != len(test_df.columns):\n            l = list(set(train_df.columns) - set(test_df.columns) - set(TARGET_COLUMNS))\n            print('Main: Features unaligned for test_df: ', l)\n            test_df[l] = 0\n            print(test_df.columns)\n        print('Main: training dataset after data engineering')\n        print(train_df.head())\n        print('Main: validation dataset after data engineering')\n        print(validation_df.head())\n        print('Main: test dataset after data engineering')\n        print(test_df.head())\n        # Do a basic ML evaluation as reference for the end\n        # Take too many time - y_basic_predictions = kaggle_ml_quick_and_dirty(train_df, validation_df, test_df)\n\n    if flags & ExecutionFlags.DATA_TRANSFORM_FLAG == ExecutionFlags.DATA_TRANSFORM_FLAG:\n        # Extract non  categorical columns based on categorical_column list\n        if not numerical_features is None:\n            columns_to_transform = numerical_features\n            if not NON_TRANSFORMABLE_COLUMNS is None:\n                columns_to_transform = list(set(columns_to_transform) - set(NON_TRANSFORMABLE_COLUMNS))\n            if not OUTPUT_IS_REGRESSION:\n                # Remove TARGET_COLUMNS from columns_to_transform list\n                columns_to_transform = list(set(columns_to_transform) - set(TARGET_COLUMNS))\n            print('Main: columns_to_transform: %s' % str(columns_to_transform))\n            print('Main: columns_to_transform: ')\n            print(train_df.describe())\n            train_df = kaggle_data_transform(train_df, columns_to_transform, p_transform = 'scale')\n            validation_df = kaggle_data_transform(validation_df, columns_to_transform, p_transform = 'scale')\n            if OUTPUT_IS_REGRESSION:\n                # Remove TARGET_COLUMNS from columns_to_transform list\n                columns_to_transform = list(set(columns_to_transform) - set(TARGET_COLUMNS))\n            test_df = kaggle_data_transform(test_df, columns_to_transform, p_transform = 'scale')\n            print('Main: training dataset after features transformations')\n            print(train_df.head())\n            print('Main: validation dataset after features transformations')\n            print(validation_df.head())\n            print('Main: test dataset after features transformations')\n            print(test_df.head())\n            # Do a basic DL evaluation as reference for the end\n            # Take too many time - y_basic_predictions = kaggle_ml_quick_and_dirty(train_df, validation_df, test_df)\n\n    train_df, dropped_features = kaggle_features_selection(train_df)\n    #dropped_features = []\n    if len(dropped_features) != 0:\n        if set(dropped_features).issubset(set(validation_df.columns)):\n            validation_df.drop(dropped_features, inplace = True, axis = 1)\n        if set(dropped_features).issubset(set(test_df.columns)):\n            test_df.drop(dropped_features, inplace = True, axis = 1)\n        print('Main: training dataset after features selection')\n        print(train_df.head())\n        print('Main: validation dataset after features selection')\n        print(validation_df.head())\n        print('Main: test dataset after features selection')\n        print(test_df.head())\n\n    # Build training & validation datasets\n    ml_inputs_training_df, ml_outputs_training_df = kaggle_split_dataset(train_df)\n    ml_inputs_validation_df, ml_outputs_validation_df = kaggle_split_dataset(validation_df)\n    ml_inputs_test_df, _ = kaggle_split_dataset(test_df)\n    print('Main: ml_inputs_training_df')\n    print(ml_inputs_training_df.head())\n    print('Main: ml_outputs_training_df')\n    print(ml_outputs_training_df.head())\n    print('Main: ml_inputs_validation_df')\n    print(ml_inputs_validation_df.head())\n    print('Main: ml_outputs_validation_df')\n    print(ml_outputs_validation_df.head())\n    print('Main: ml_inputs_test_df')\n    print(ml_inputs_test_df.head())\n\n    # Checking models\n    models = []\n    scoring = None\n    if OUTPUT_IS_REGRESSION: # Use regression algorithms\n        scoring = 'r2' # 'r2' or 'neg_mean_absolute_error'\n        # Take too many time - models.append(('LR', linear_model.LinearRegression()))\n        # Take too many time - models.append(('SGDC', linear_model.SGDRegressor(random_state = SEED_HARCODED_VALUE)))\n        # Take too many time - models.append(('LASSO', linear_model.Lasso()))\n        # Take too many time - models.append(('EN', linear_model.ElasticNet()))\n        # Take too many time - models.append(('KNN', neighbors.KNeighborsRegressor(n_neighbors = 8)))\n        # Take too many time - models.append(('CART', tree.DecisionTreeRegressor(max_leaf_nodes = 256, random_state = SEED_HARCODED_VALUE)))\n        models.append(('LGBMR', lgb.LGBMRegressor(n_estimators = 1024, num_leaves = 128, max_depth = 32, learning_rate=0.05, random_state = SEED_HARCODED_VALUE)))\n        models.append(('XGB', xgb.XGBRegressor(n_estimators = 1024, learning_rate=0.5, random_state = SEED_HARCODED_VALUE)))\n        # Take too many time - models.append(('BGK', ensemble.GradientBoostingRegressor(n_estimators = 256, max_depth = 16, random_state = SEED_HARCODED_VALUE)))\n        # Take too many time - models.append(('RF', ensemble.RandomForestRegressor(n_estimators = 1024, max_depth = 32, max_features = 4, random_state = SEED_HARCODED_VALUE)))\n        # Take too many time - models.append(('SVR', svm.SVR()))\n    else: # Use classifier algorithms\n        scoring = 'accuracy'\n        models.append(('LR', linear_model.LogisticRegression(random_state = SEED_HARCODED_VALUE)))\n        models.append(('SGDC', linear_model.SGDClassifier(random_state = SEED_HARCODED_VALUE)))\n        models.append(('LDA', discriminant_analysis.LinearDiscriminantAnalysis()))\n        models.append(('KNN', neighbors.KNeighborsClassifier(n_neighbors = 8)))\n        models.append(('CART', tree.DecisionTreeClassifier(max_leaf_nodes = 256, random_state = SEED_HARCODED_VALUE)))\n        models.append(('LGBMC', lgb.LGBMClassifier(n_estimators = 1024, num_leaves = 128, max_depth = 8, learning_rate=0.05, random_state = SEED_HARCODED_VALUE)))\n        models.append(('XGB', xgb.XGBClassifier(n_estimators = 1024, learning_rate=0.5, random_state = SEED_HARCODED_VALUE)))\n        models.append(('BGK', ensemble.GradientBoostingClassifier(n_estimators = 256, max_depth = 32, random_state = SEED_HARCODED_VALUE)))\n        models.append(('RF', ensemble.RandomForestClassifier(n_estimators = 1024, max_depth = 32, max_features = 4, random_state = SEED_HARCODED_VALUE)))\n        models.append(('NB', naive_bayes.GaussianNB()))\n        models.append(('SVC', svm.SVC(random_state = SEED_HARCODED_VALUE)))\n\n    results, names = kaggle_check_models(models, ml_inputs_training_df, ml_outputs_training_df, p_cross_validation = 'k-fold', p_scoring = scoring)\n    best_alg = kaggle_compare_algorithms_perf(names, results, 'Algorithms Comparison', 'Algorithms', 'Accuracy')\n    # Take too many time - ml = kaggle_algorithm_tuning(models[best_alg], ml_inputs_training_df, ml_outputs_training_df, (ml_inputs_validation_df, ml_outputs_validation_df))\n    ml = models[best_alg][1]\n    ml.fit(ml_inputs_training_df, ml_outputs_training_df)\n\n    y_predictions = kaggle_validation_prediction(ml, ml_inputs_validation_df, ml_outputs_validation_df)\n    # Take too many time - kaggle_explore_ml(ml, ml_inputs_validation_df, y_predictions)\n\n    y_predictions = kaggle_prediction(ml, ml_inputs_test_df)\n    # Take too many time - kaggle_explore_ml(ml, ml_inputs_test_df, y_predictions)\n\n    print('Main: Save the model')\n    file_name = ml.__class__.__name__\n    kaggle_save_model(ml, '/kaggle/working/', file_name)\n\n    print('Main: Save Kaggel compete submission')\n    kaggle_save_result(ml, 'id', y_predictions, '../input/tabular-playground-series-jan-2021/test.csv', '/kaggle/working/result.csv')\n\n    ## Take too many time - print('Main: Reload the model')\n    # Take too many time - ml = kaggle_load_model('/kaggle/working/', file_name)\n    #y_predictions = kaggle_validation_prediction(ml, ml_inputs_validation_df, ml_outputs_validation_df)\n    #kaggle_explore_ml(ml, ml_inputs_validation_df, y_predictions)\n\n    print('Main: End of processing')\n    # End of function kaggle_main","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ouf, now, we can execute all the sequences described above and get some results:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Entry point\nprint(\"Starting at \", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\nkaggle_main()\nprint(\"Ending at \", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If you liked this Notebook, please upvote.\nGives Motivation to make new Notebooks :)**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}