{"nbformat_minor":0,"cells":[{"outputs":[],"metadata":{"_execution_state":"idle","_cell_guid":"d7b18e3e-4f08-4794-9577-d8f439cae184","collapsed":false,"_uuid":"f9869ab22b5ac85fb9fd8ad67a7aec8880b5ac84"},"execution_count":null,"source":"I create s notebook to see why PCA ,may not work well if not combine with original data( the part of for loop may be take\nsome times)","cell_type":"markdown"},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"59d4c8a8-b1c8-4cd4-95c0-d86dbcc1841c","_uuid":"e4c7d17722deb995826bd76de9b9a1dc9f56df9b"},"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code"},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"7541e77f-4f15-477f-b099-e36a41a91244","collapsed":false,"_uuid":"96e50f1c441793dfdc560da5390f6631f61b4193"},"execution_count":null,"source":"from sklearn.decomposition import PCA, FastICA,KernelPCA,TruncatedSVD\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder","cell_type":"code"},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"3479b523-a963-49b9-9bb9-10d100df42ae","collapsed":false,"_uuid":"ea5ecfb18eee5810eb1b4dc008d83a07ff48425a"},"execution_count":null,"source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain=train[train.y<250]\ny_train = train['y']\ntrain=train.sort_values(['ID'])\ntest=test.sort_values(['ID'])\ntrain=train.drop(['y'],axis=1)\n\ndf=pd.concat([train,test])\n\npd.get_dummies(df).shape\n\n\n\n# process columns, apply LabelEncoder to categorical features\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\n\n\nnew_train=train.drop(['ID'],axis=1)\nnew_test=test.drop(['ID'],axis=1)\n\n\ndata = pd.concat([new_train,new_test])\n\ndata.shape\n","cell_type":"code"},{"source":"#VIF  analysis:\nX=data .values\n\nC=np.linalg.pinv(np.dot(X.T,X))\n\nfactor=[]\nfor i in range(0,C.shape[0]):\n    factor.append(C[i][i])\n\nplt.clf()\nplt.plot(factor)\nplt.show()","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"ab37a00b-5b20-414e-88cd-28e89b8049b3","collapsed":false,"_uuid":"8fd7289ec9327fef2635bf84b579191fa27ac51c"},"execution_count":null,"cell_type":"code","outputs":[]},{"source":"A little bit high in some regressor, but I think it's no needs to remove(  or can be done more detail)\n","metadata":{"_execution_state":"idle","_cell_guid":"ee2cde9e-40e6-42c1-9c3f-53081a828dea","collapsed":false,"_uuid":"b827d31b536f86fe768df80bdd20d40ed7a7b91a"},"execution_count":null,"cell_type":"markdown","outputs":[]},{"outputs":[],"metadata":{"_execution_state":"busy","trusted":false,"_cell_guid":"599e8ccb-90b6-4766-9d00-2badc5664593","collapsed":false,"_uuid":"1c36005616535b1c4e07cf9d85001d2d7735b92a"},"execution_count":null,"source":"from numpy import linalg as LA\nmax_comp=100\nstart=20\nerror_record=[]\nfor i in range(start,max_comp):\n    pca = PCA(n_components=i, random_state=42)\n    pca2_results = pca.fit_transform(data)\n    pca2_proj_back=pca.inverse_transform(pca2_results)\n    total_loss=LA.norm((data-pca2_proj_back),None)\n    error_record.append(total_loss)\n\nplt.clf()\nplt.figure(figsize=(15,15))\nplt.title(\"reconstruct error of pca\")\nplt.plot(error_record,'r')\nplt.xticks(range(len(error_record)), range(start,max_comp), rotation='vertical')\nplt.xlim([-1, len(error_record)])\nplt.show()\n","cell_type":"code"},{"outputs":[],"metadata":{"_execution_state":"idle","_cell_guid":"2f9acbea-090d-40d8-9ace-12cf6cae8df9","collapsed":false,"_uuid":"84ed4edfd85ba765e43399eb6dc4b46eb0b43c2c"},"execution_count":null,"source":"The error is very large .That's why some script combine the PCA with original data will get the good score,up 100 still have many error  . I guess........","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.6.1","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4}