{"cells":[{"outputs":[],"execution_count":null,"source":"Its the mathematical perfect solution\n---\nSo don't believe me...\n----\ni know a solution that has to minimize the time spend on a car has to minimize not the mean square error, but minimize the time spend on a car... Its only the solution that minimizes the spend time that will minimize the pollution. Now you have to think in 'human quality of life' or 'human way of working'. If you see you have to catchup some time, you will speed up the tests. If you see you have some time leftover, you can spend 20 seconds more on a test.... That is what is happening IMHO... Probably the best forecast of the extra time spend on a car could be the time below the average 100seconds you spend on the previous car;.. (see if i can make a predictor of that too-)\n\nSo I use the most apted method: that is doing a LP solution. LP with the complete training model as constraints... will minimize the time spend on the cars. Averaging out all constrainted solutions indead. Now as you see he clusters the predicted times in 4 groups more or less like the clustering-XGBoost is doing. The difference is that i really pick the lowest time available as constraint.\n\n\n\nYes don't laugh , i have a splendid LB score of -1.4\nBut this model has some room for improvement... so probably the LB can be alittle bit lower. I finished with a LB -8.6  and think its the right position.","metadata":{"_uuid":"1eac3c48c9f3b5095ef24ebbe3499a0ba9ab114b","_cell_guid":"da72121e-cb4c-4866-8b91-f96285fa011d","collapsed":false,"_execution_state":"idle"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport xgboost as xgb \nfrom sklearn.metrics import r2_score\n\n%matplotlib inline\n\nfrom IPython.display import display, HTML\n# Shows all columns of a dataframe\ndef show_dataframe(X, rows = 2):\n    display(HTML(X.to_html(max_rows=rows)))\n\n# Datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')    ","metadata":{"_uuid":"e263fe3910ff4459e868283569659493df057f31","_cell_guid":"a5d2ab01-2f57-4789-bbc7-e3cad261a3c6","trusted":false,"_execution_state":"idle"},"cell_type":"code"},{"outputs":[],"execution_count":null,"source":"Making categories and combinations of categories\n----","metadata":{"_uuid":"f95b23f9fc332651ba4f0dbcb9d00ac040d23f4d","_cell_guid":"06de48e3-0dd8-432c-9b2a-21f049b46e64","collapsed":false,"_execution_state":"idle"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"source":"#add X0-8 combinations\nfor xi in ['X1','X2','X3','X4','X5','X6','X8']:\n    nieuwveld='X0'+xi\n    train[nieuwveld]=train['X0']+'-'+train[xi]\n    test[nieuwveld]=test['X0']+'-'+test[xi]\n\n# Categorical features\ncat_cols = []\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        cat_cols.append(c)\nprint('Categorical columns:', cat_cols)\n\n# Dublicate features\nd = {}; done = []\ncols = train.columns.values\nfor c in cols: d[c]=[]\nfor i in range(len(cols)):\n    if i not in done:\n        for j in range(i+1, len(cols)):\n            if all(train[cols[i]] == train[cols[j]]):\n                done.append(j)\n                d[cols[i]].append(cols[j])\ndub_cols = []\nfor k in d.keys():\n    if len(d[k]) > 0: \n        # print k, d[k]\n        dub_cols += d[k]        \nprint('Dublicates:', dub_cols)\n\n# Constant columns\nconst_cols = []\nfor c in cols:\n    if len(train[c].unique()) == 1:\n        const_cols.append(c)\nprint('Constant cols:', const_cols)","metadata":{"_uuid":"8bf4ad405b3ed53dddc9c787a3adf36a71d8173c","_cell_guid":"de5d2f9a-4eba-4e56-9624-d9300267264e","trusted":false,"collapsed":false,"_execution_state":"idle"},"cell_type":"code"},{"outputs":[],"execution_count":null,"source":"# Glue train + test\ntrain['eval_set'] = 0; test['eval_set'] = 1\ndf = pd.concat([train, test], axis=0, copy=True)\n# Reset index\ndf.reset_index(drop=True, inplace=True)\n\ndef add_new_col(x):\n    if x not in new_col.keys(): \n        # set n/2 x if is contained in test, but not in train \n        # (n is the number of unique labels in train)\n        # or an alternative could be -100 (something out of range [0; n-1]\n        return int(len(new_col.keys())/2)\n    return new_col[x] # rank of the label\n\nfor c in cat_cols:\n    # get labels and corresponding means\n    new_col = train.groupby(c).y.quantile(q=0.05).sort_values().to_dict()\n    df[c+'new'] = df[c].apply(add_new_col)\n\n# show the result\n#show_dataframe(df, 10)\nprint('Shape df',df.shape)\nX = df.drop(list((set(const_cols) | set(dub_cols) | set(cat_cols))), axis=1)\n\n# Train\nX_train = X[X.eval_set == 0]\ny_train = X_train.pop('y'); \nX_train = X_train.drop(['eval_set', 'ID'], axis=1)\nshow_dataframe(X_train, 10)\n# Test\nX_test = X[X.eval_set == 1]\nX_test = X_test.drop(['y', 'eval_set', 'ID'], axis=1)\n\n# Base score\ny_mean = -y_train.median() #q0.01 LB 0.5546 q=0.25 0.5549\n# Shapes\n\nprint('Shape X_train: {}\\nShape X_test: {}'.format(X_train.shape, X_test.shape))","metadata":{"_uuid":"0d5e867cb39794005fc53dbe551aa65b1c4d1c33","_cell_guid":"491f8895-703b-4202-9f0c-c51b7ce60931","trusted":false,"collapsed":false,"_execution_state":"idle"},"cell_type":"code"},{"outputs":[],"execution_count":null,"source":"Create LP matrix\n----\n\n 1.  that is the categories of X_train - concat a constant column\n 2. append a positive X_train and a negative X_train (upper and lower limit) call it XX_train\n 3. making a slack diagonal identity matrix and concat XXtrain with slack I creating XXI_train\n 4. concat 2x  a negative Z identity matrix to force the solution to 0 or any target you want.\n 5. create a b matrix with the 'real y-times' and the 'minimum y-times'\n\n![matrix annotation][1]\n\n\n  [1]: https://latex.codecogs.com/gif.latex?pinv%20%5Cbegin%7Bvmatrix%7D%20%5Cbegin%7Bvmatrix%7D%20aX%20%26%20.%20%26%20.%5C%5C%20.%20%26%20.%20%26%20.%5C%5C%20.%20%26%20.%20%26%20.%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%201b%5C%5C%201b%5C%5C%201b%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%201s%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%5C%5C%20%26%201s%20%26%20%26%20%26%20%26%20%5C%5C%20%26%20%26%201s%26%20%26%20%26%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%20-1z%5C%5C%20-1z%5C%5C%20-1z%20%5Cend%7Bvmatrix%7D%20%5C%5C%20%5Cbegin%7Bvmatrix%7D%20-aX%20%26%20.%20%26%20.%5C%5C%20.%20%26%20.%20%26%20.%5C%5C%20.%20%26%20.%20%26%20.%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%20-1b%5C%5C%20-1b%5C%5C%20-1b%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%200%20%26%200%20%26%200%20%26%201s%20%26%200%20%260%20%5C%5C%20%26%20%26%20%26%20%261s%20%26%20%5C%5C%20%26%20%26%20%26%20%26%20%26%201s%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%20-1z%5C%5C%20-1z%5C%5C%20-1z%20%5Cend%7Bvmatrix%7D%20%5C%5C%20%5Cbegin%7Bvmatrix%7D%200%20%26%200%20%26%200%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%200%20%26%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%5Cend%7Bvmatrix%7D%20%26%20%5Cbegin%7Bvmatrix%7D%200%20%26%20%5Cend%7Bvmatrix%7D%20%5Cend%7Bvmatrix%7D%20%5Ccdot%20%5Cbegin%7Bvmatrix%7D%20%5Cbegin%7Bmatrix%7D%20-y_%7Bmin%7D%5C%5C%20.%5C%5C%20.%20%5Cend%7Bmatrix%7D%5C%5C%20%5Cbegin%7Bmatrix%7D%20&plus;y_%7Bmin2%7D%5C%5C%20.%5C%5C%20.%20%5Cend%7Bmatrix%7D%20%5C%5C%20target%200%20%5Cend%7Bvmatrix%7D","metadata":{"_uuid":"1182b9a7560196a16dd5f9b7e7158548786e358e","_cell_guid":"63a88cf8-d507-4932-aa18-2e94c0b571a8","collapsed":false,"_execution_state":"idle"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"source":"maxlen=1000   # change this limit ot 4000 if you have enough memory\n#construct Matrix with slacks Z \ncat_cols_new = []\nfor c in cat_cols:\n    temp=c+'new'\n    cat_cols_new.append(temp)\nprint('New Categorical columns:', cat_cols_new)\n\nXc_train=X_train[:maxlen] #[cat_cols_new]\nXc_train['b_']=1.0\nXXI_train = pd.concat([Xc_train.append(-Xc_train).reset_index(),   pd.DataFrame(np.identity(len(Xc_train)*2) ) ], axis=1)\nX2_train=XXI_train*XXI_train\n\nZident=-pd.DataFrame(np.identity(len(Xc_train)),columns=[str(xz)+'z' for xz in range(len(Xc_train))] )\nZZident=Zident.append(Zident).reset_index()\nXXIZZ_train= pd.concat([XXI_train,ZZident], axis=1)\nprint(XXIZZ_train.shape)\nprint(len(Xc_train)*3+16)\nprint(len(XXI_train)+len(Xc_train))\nfv=pd.DataFrame( [0.0 for xi in range(len(Xc_train.columns)+len(Xc_train)*2+2)] + [1.0 for xi in range(len(Xc_train))],columns=['fv']) \n\nXXIZZ_train=XXIZZ_train.append(fv.set_index(XXIZZ_train.columns ).T).reset_index()\n\n# the real y\nb= -y_train[:maxlen].append(-y_train[:maxlen])\nb= b.append(pd.DataFrame([0]) ) # find 0 point\n\n# the minima from 'X0'\n#b2 = -y_train[:maxlen].append(-X_train['X0new'][:maxlen])\n#b2= b2.append(pd.DataFrame([0]) )\n\nb2 = -X_train['X0X5new'][:maxlen].append(-X_train['X0X8new'][:maxlen])\nb2= b2.append(pd.DataFrame([0]) )\n#do the math\n\n","metadata":{"_uuid":"be63e41789fdeea8fcc50ab0f353bf1fff37dd0f","_cell_guid":"89988136-27bf-4405-8cd6-9d7ced69a5b8","trusted":false,"collapsed":false,"_execution_state":"idle"},"cell_type":"code"},{"outputs":[],"execution_count":null,"source":"do the math\n----\nits the inverse of that XXIZZ matrix  and multiplication with the 'time'","metadata":{"_uuid":"cbe7c95afce9a1e6f75f7f9c7f805926903e77a7","_cell_guid":"d7d5e035-2340-4753-a61b-120cad060858","collapsed":false,"_execution_state":"idle"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"source":"print(XXIZZ_train.shape)\n#print(b.shape)\n\nXXIZZ_train=XXIZZ_train.drop(['index','level_0'],axis=1)\n\n# regression solution\nsolution=np.linalg.pinv(XXIZZ_train).dot(b)\n# minimal solution\nsolution2=np.linalg.pinv(XXIZZ_train).dot(b2)\n\nshow_dataframe(pd.DataFrame(solution.T))\nshow_dataframe(pd.DataFrame(solution2.T))\nshow_dataframe(pd.DataFrame(y_train).T)\ncoeff=solution[:327]\ncoeff2=solution2[:327]\n#print(coeff)\n#print(coeff2)\nprint('slack',(solution[326:3016]).sum(),(solution[326:3016]*solution[326:3016]).sum())\nprint('slack2',(solution2[326:3016]).sum(),(solution2[326:3016]*solution2[326:3016]).sum())","metadata":{"_uuid":"836d314c6b0240e6773178f83f2a75850b4a57c7","_cell_guid":"547ed845-76ad-4255-aa53-f056e38b779c","trusted":false,"collapsed":false,"_execution_state":"busy"},"cell_type":"code"},{"outputs":[],"execution_count":null,"source":"Use the matrix to make the prediction, \n---\n\n**look at the graph, amazing, the predictions are all sticking on the diagonal, its perfect. Thats a real good prediction.**\nlook at the slack... the sum of square of the slack2 is really genious low.\n\nI stick to this solution..\n\n","metadata":{"_uuid":"6f9408fb55203bb4786098edf771e2d392e0939a","_cell_guid":"4a57e994-b267-48e6-890b-066bbefdf011","collapsed":false,"_execution_state":"idle"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"source":"Xc_test=X_test #[cat_cols_new]\nXc_test['b_']=1.0\nXd_train=X_train #[cat_cols_new]\nXd_train['b_']=1.0\n\ny_pred=-Xc_test.dot(coeff2)\ny_train_pred=-Xd_train.dot(coeff2)\n\nplt.figure(figsize=(10,10))\nsns.distplot(y_train, kde=False, color='g')\nsns.distplot(y_pred, kde=False, color='b')\nplt.title('Distr. of train and pred. test')\n\nplt.figure(figsize=(10,10))\nplt.title('True vs. Pred. train')\nplt.plot([80,265], [80,265], color='g', alpha=0.3)\nplt.scatter(x=y_train, y=y_train_pred, marker='.', alpha=0.5)\nplt.scatter(x=[np.mean(y_train)], y=[np.mean(y_train_pred)], marker='o', color='red')\nplt.xlabel('Real train'); plt.ylabel('Pred. train')\n\ny_pr=pd.DataFrame(y_pred).reset_index()\ny_pr.columns=['index','y']\ntest['y_pr']=y_pr['y']\n\noutput = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': test['y_pr'] })\noutput.to_csv('submLP.csv', index=False)\n","metadata":{"_uuid":"644ff6bcc981403e25b5f4478728ff1a28d14af3","_cell_guid":"10fa4e0b-1ab0-4517-a064-6398effc3493","trusted":false,"collapsed":false,"_execution_state":"busy"},"cell_type":"code"},{"outputs":[],"execution_count":null,"source":"What is the room for improvement ?\n----\n\n - The time spend on a car per category X0-X8 is not perfectly linear, outliers are in the begin and the end\nsee Yohan's notebook  https://www.kaggle.com/yohanb/categorical-features-encoding-xgb-0-554?scriptVersionId=1280085\n\n - The time spend on a car is function of ID see. SO you should 'detrend' the 'y' to make a perfect prediction\nhttps://www.kaggle.com/plarmuseau/visualizing-the-id-trend\n","metadata":{"_uuid":"bb03a64ef422e3c4bccc98cc1ae028b76a60b470","_cell_guid":"1c4dbc79-8e9c-454a-a7d0-1cc56478fa69","collapsed":false,"_execution_state":"idle"},"cell_type":"markdown"}],"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.1","file_extension":".py","name":"python","pygments_lexer":"ipython3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4}