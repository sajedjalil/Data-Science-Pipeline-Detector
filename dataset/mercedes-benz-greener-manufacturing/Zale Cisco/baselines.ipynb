{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"42f56561-2bf8-d63b-f0f4-80bad6f10205"},"source":"Hi, Kagglers!\n\nHereafter I will try to publish **some basic approaches to climb up the Leaderboard**\n\n**Competition goal**\n\nIn this competition, Daimler is challenging Kagglers to tackle the curse of dimensionality and reduce the time that cars spend on the test bench.\n<br>Competitors will work with a dataset representing different permutations of Mercedes-Benz car features to predict the time it takes to pass testing. <br>Winning algorithms will contribute to speedier testing, resulting in lower carbon dioxide emissions without reducing Daimlerâ€™s standards. \n\n**The Notebook adopts skeleton from (maybe?) this script: https://www.kaggle.com/ermolushka/starter-xgboost**\n\n### Stay tuned, this notebook will be updated on a regular basis\n**P.s. Upvotes and comments would let me update it faster and in a more smart way :)**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f56612b7-5e56-a982-e444-2e803d037696"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"9b0c5167-5916-1295-6c9a-dd1f6398c2ce"},"source":"### Import"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1860d05-f575-5b2b-af7e-53478e209504"},"outputs":[],"source":"# read datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# process columns, apply LabelEncoder to categorical features\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))"},{"cell_type":"markdown","metadata":{"_cell_guid":"e1b670a7-996f-1b2c-4f94-46fbac0ff748"},"source":"### Add decomposed components: PCA / ICA etc."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4d2a6a5-f3fb-241f-ff1b-27206031e5d5"},"outputs":[],"source":"from sklearn.decomposition import PCA, FastICA\nn_comp = 8\n\n# PCA\npca = PCA(n_components=n_comp, random_state=42)\npca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\npca2_results_test = pca.transform(test)\n\n# ICA\nica = FastICA(n_components=n_comp, random_state=42)\nica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\nica2_results_test = ica.transform(test)\n\n# Append decomposition components to datasets\nfor i in range(1, n_comp+1):\n    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n    \n    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n    \ny_train = train[\"y\"]\ny_mean = np.mean(y_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"48fabb21-c780-c666-74f1-9fd1dbfe3c4e"},"source":"### Preparing Regressor"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29b158b3-ce67-f979-31d4-11103dd0b968"},"outputs":[],"source":"# mmm, xgboost, loved by everyone ^-^\nimport xgboost as xgb\n\n\n# prepare dict of params for xgboost to run with\nxgb_params = {\n    'n_trees': 500, \n    'eta': 0.0051,\n    'max_depth': 4,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'base_score': y_mean, # base prediction = mean(target)\n    'silent': 1\n}\n\n# form DMatrices for Xgboost training\ndtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\ndtest = xgb.DMatrix(test)\n\n# xgboost, cross-validation\ncv_result = xgb.cv(xgb_params, \n                   dtrain, \n                   num_boost_round=650, # increase to have better results (~700)\n                   early_stopping_rounds=50,\n                   verbose_eval=10, \n                   show_stdv=False\n                  )\n\nnum_boost_rounds = len(cv_result)\nprint(num_boost_rounds)\n\n# train model\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f634dac-4ad8-7c09-9603-5fa817140136"},"outputs":[],"source":"# check f2-score (to get higher score - increase num_boost_round in previous cell)\nfrom sklearn.metrics import r2_score\n\n# now fixed, correct calculation\nprint(r2_score(dtrain.get_label(), model.predict(dtrain)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"169562ea-efbe-92b1-6f13-08f34b6597a5"},"outputs":[],"source":"# make predictions and save results\ny_pred = model.predict(dtest)\noutput = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\noutput.to_csv('xgboost-depth{}-pca-ica.csv'.format(xgb_params['max_depth']), index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"31691d5d-ba34-4650-416d-723b4bd89a84"},"source":"### Prepare Predictions"},{"cell_type":"markdown","metadata":{"_cell_guid":"ffe421af-bc48-91a5-a0da-7cb6ad0f74e4"},"source":"### Stay tuned, this notebook will be updated on a regular basis\n**P.s. Upvotes and comments would let me update it faster and in a more smart way :)**"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}