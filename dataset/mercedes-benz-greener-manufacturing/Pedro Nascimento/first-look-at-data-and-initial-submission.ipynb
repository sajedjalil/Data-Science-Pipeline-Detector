{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6f5fb748-e0e4-1868-cafa-911d92846cc0"},"source":"In this notebook we are going to look at just exactly what the datasets consists of and do an initial submition with a very simple neural network\n\nIf you fork this or think it was useful please upvote"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ee1ae7e-5e43-ff28-b2c8-7eab5f8d6678"},"outputs":[],"source":"\"\"\"Initial exploratory analysis\"\"\"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Constants\nPATH = '../input/'\nTRAIN = 'train.csv'\nTEST = 'test.csv'\n\n# Load Data\ntrain_df = pd.read_csv(PATH + TRAIN)\n\nprint('Train Set')\ntrain_df.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"5d75d0de-c159-c8bd-6474-b21e1e49d74d"},"source":"Our dataset has 378 columns, consisting of the example ID, the target variable ***y*** and 376 feature, some of them appear to be categorical, with letters as categories and others appear to be binary.\n\nThe feature names also don't prove very insightful, consisting mostly of **X0**, **X1**,... **X385**, but skipping some numbers (eg. **X7**, **X9**, ...)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"520b72e6-dee9-61f4-721e-78bf9b2ff1c9"},"outputs":[],"source":"# Simple Metrics of Dataset\nprint('Number of examples: {}'.format(train_df.shape[0]))\nprint('Number of Features: {}'.format(train_df.shape[1] - 2))\n\n# Distribution of target variable\nprint('\\nMean of target variable: {}'.format(train_df['y'].mean()))\nprint('Unbiased Variance of target variable {}'.format(train_df['y'].var()))\nplt.figure(figsize=(12,8))\nsns.distplot(train_df['y'].values, bins=50, kde=False)\nplt.xlabel('y variable', fontsize=12)\nplt.ylabel('Frequency')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"fc67093f-47d2-389d-e617-ca89550a91aa"},"source":"We have only 4209 examples !!\nThis is quite a small dataset, which does not come as a surprise since the train and test set combined are 343.21 KB\n\nThe distribution of the target variable appears to be centered mostly around 100, with quite some variance.\nLet's now have a look at our Features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ad627f3-a09a-8f19-9ea8-7b5bf4d19da4"},"outputs":[],"source":"# Feature types and distributions\nprint('Feature Types and #')\nprint(train_df.dtypes.value_counts())\n\n# Categorical Features\ncategoricals = train_df.columns[train_df.dtypes == object]\nprint('\\nCategorical Features:')\nprint(categoricals.values,'\\n')\n\n# Let's Look at how many categories there are\nfor feature in categoricals:\n    print('Feature {}: {} Categories'.format(str(feature), len(train_df[feature].unique())))"},{"cell_type":"markdown","metadata":{"_cell_guid":"2925948b-792b-0193-792a-0151b12c9e68"},"source":"We have 369 64-bit integer features and 8 categoricals, the float refers to the target variable.\n\nFurthermore, we see that our categorical features are **X0**, **X1**, **X2**, **X3**, **X4**, **X5**, **X6** and **X8**\nand each feature has between 4 and 47 categories, and together this 8 features encode 195 bits of information.\n\nLet's now have a look at the integer features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c6cd81d-8f4b-4437-0002-daab8f240b39"},"outputs":[],"source":"# Let's Now look at the values for the int64 features\nint_features = train_df.columns[train_df.dtypes == 'int64']\n\nvalues_dict = {}\n\nfor feature in int_features:\n    values_dict[str(feature)] = len(train_df[feature].unique())\n\ndel values_dict['ID']\nprint('# Of unique Values for each int Feature')\nprint(values_dict)"},{"cell_type":"markdown","metadata":{"_cell_guid":"640dfaa4-ded1-7c38-86f1-2444dc1fa1aa"},"source":"As we suspected, the integer variables are in fact binary, even more, some features have a constant unique state and these can be drop since they don't add any information to our model (constant state means 0 bits of information)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a87df251-b686-e34b-1559-cd327fffd07e"},"outputs":[],"source":"drop = []\nfor key in values_dict:\n    if values_dict[key] == 1:\n        drop.append(key)\n        \nfor feature in drop:\n    print('Dropped Feature {}'.format(feature))\n    del values_dict[feature]"},{"cell_type":"markdown","metadata":{"_cell_guid":"4efb18a4-7d01-0abe-1975-7244bef189ab"},"source":"We dropped the 12 features which did not encode any information into our model, we need to keep track of which features were dropped because we gotta drop them in the test set as well\n now we are left with 357 binary features and 8 categoricals, making up to 552 bits. Quite manageable. If we use a sparse \"One-hot\" representation to encode our categorical features, our feature vector will be 552x1\n\nNow let's have a quick look at the test set just to be sure that it is not very different from our training set"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0c4f7f9-48d3-0a76-2618-1b9b427dd556"},"outputs":[],"source":"# Loading Test Set\n\ntest_df = pd.read_csv(PATH + TEST)\nprint('TEST SET')\nprint(test_df.head())\nprint('shape = ',test_df.shape,'\\n')\n\ntest_categoricals = test_df.columns[test_df.dtypes == object]\n\nfor feature in test_categoricals:\n    print('Feature {}: {} Categories'.format(str(feature), len(test_df[feature].unique())))"},{"cell_type":"markdown","metadata":{"_cell_guid":"ca23387c-9b85-0672-51b8-0aabf437df52"},"source":"Oops, Features X0, X2 and X5 don't quite seem to agree on the number of categories between the train and test set, let's have a better look:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fad3fa2-7c87-a427-44e9-4687288ee877"},"outputs":[],"source":"for feature in categoricals:\n    test_feature = test_df[feature].unique()\n    train_feature = train_df[feature].unique()\n    union = pd.Series(test_df[feature].tolist() + train_df[feature].tolist()).unique()\n    \n    test_feature.sort()\n    train_feature.sort()\n    union.sort()\n    \n    print('\\n\\nTest {}: {}'.format(feature,test_feature))\n    print('\\nTrain {}: {}'.format(feature,train_feature))\n    print('\\nUnion size: ',len(union))\n    \n    \n    \n    "},{"cell_type":"markdown","metadata":{"_cell_guid":"b999e753-60ac-c3d4-0e71-e7a6e21583b9"},"source":"We can see that the Train and the Test Set each have some exclusive categories not seen in both sets. It would be wise to also check the other categorical feature.\n\nWe are then left with two options, we can encode the categorical features with a number of categories corresponding to the union of the test and the train categories for each feature, or we can drop the examples on which the categories are exclusive to either set\n\n**MORE TO COME**\n\n**KEEP ON THE LOOKOUT**"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}