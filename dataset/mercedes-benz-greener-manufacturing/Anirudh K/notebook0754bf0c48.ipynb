{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2cc4f231-5f78-8b10-f1c7-72a2afe6ac1b"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96391f6f-932c-e4bc-3d74-7527c16219a8"},"outputs":[],"source":"data_train = pd.read_csv(\"../../data/train.csv\")\ndata_test = pd.read_csv(\"../../data/test.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34d347ee-6e09-e30f-b217-a0721e9b6a76"},"outputs":[],"source":"print(\"Train data dims:\", data_train.shape)\nprint(\"Test data dims:\", data_test.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a65fd715-1b8d-d47a-71b6-4e8e75e8c755"},"source":"## Graph Exploration"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"540e0474-d714-633f-b8f7-2069a9e94cbc"},"outputs":[],"source":"plt.figure(figsize=(8,6))\nplt.scatter(range(data_train.shape[0]), np.sort(data_train.y.values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('y', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08a59d62-5983-5f89-74f3-fd0de44951a3"},"outputs":[],"source":"var_name = \"ID\"\nplt.figure(figsize=(12,6))\nsns.regplot(x=var_name, y='y', data=data_train, scatter_kws={'alpha':0.5, 's':30})\nplt.xlabel(var_name, fontsize=12)\nplt.ylabel('y', fontsize=12)\nplt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08539eb0-282b-ce67-1487-aecaaf11d731"},"outputs":[],"source":"plt.figure(figsize=(12,8))\nsns.distplot(data_train.y.values, bins=50, kde=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aec531dc-2b8a-8bef-9c1c-067f6964ab46"},"outputs":[],"source":"dtype_df = data_train.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"00c4776d-dbb9-6201-69b2-41f8094c91bb"},"outputs":[],"source":"dtype_df.ix[:10,:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23bacf82-b0cf-a3c6-bf20-930a8da66e33"},"outputs":[],"source":"unique_values_dict = {}\nfor col in data_train.columns:\n    if col not in [\"ID\", \"y\", \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n        unique_value = str(np.sort(data_train[col].unique()).tolist())\n        tlist = unique_values_dict.get(unique_value, [])\n        tlist.append(col)\n        unique_values_dict[unique_value] = tlist[:]\nfor unique_val, columns in unique_values_dict.items():\n    print(\"Columns containing the unique values : \",unique_val)\n    print(columns)\n    print(\"--------------------------------------------------\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"ea0c8339-fcc4-5e2a-60cb-0147aa40ee52"},"source":"Descartamos las variables que solo tienen un 0, no nos van a ser muy utiles que digamos para predecir Y."},{"cell_type":"markdown","metadata":{"_cell_guid":"3e4a600c-802d-e8c3-7922-91518ba4daf2"},"source":"## Attributes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9b2356a-69eb-b993-a49b-d21763560eb9"},"outputs":[],"source":"data = data_train"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b91e382d-c1d2-5b08-7ba2-4d10feede2bb","collapsed":true},"outputs":[],"source":"del data['ID']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81da1a06-3a60-1bc7-ef1e-ef55ad5e8d6c"},"outputs":[],"source":"data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f23699f4-ed02-0dc2-9ecf-38eb572f32e4"},"outputs":[],"source":"data = pd.get_dummies(data, prefix=['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6',' X8'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a332d098-8ad8-0261-cda7-29bd18921ddd"},"outputs":[],"source":"data.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ecbd52d5-5387-c572-29bc-91d04b4b859f"},"source":"At this point all variables are either 0 or 1\n\ndivide the train dataset into 2 datasets, one part to train, another part to test what to train"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef2b7da6-90c5-c133-98aa-b288015c5ee8"},"outputs":[],"source":"msk = np.random.rand(len(data)) < 0.8\ntrain = data[msk]\ntest = data[~msk]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"21ba5b94-9a16-3614-f7b0-04ee0660b7f4"},"outputs":[],"source":"train_x = train[train.columns[1:600]]\ntrain_y = train[train.columns[0:1]]\ntest_x = test[test.columns[1:600]]\ntest_y = test[test.columns[0:1]]\n\n\nX_train = train_x\nY_train = train_y\nX_test = test_x\nY_test = test_y"},{"cell_type":"markdown","metadata":{"_cell_guid":"a8025473-3516-0e84-21b1-924bf177a688"},"source":"## Simple linear regression"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e8b5c6b-3e84-1d15-9cb9-1c0cc875246d"},"outputs":[],"source":"regr = linear_model.LinearRegression()\nregr.fit(train_x, train_y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5632b4d6-88a1-48e9-38fb-c41d43524e76"},"outputs":[],"source":"print(\"Intercept: %.2f\" %regr.intercept_)\nprint(\"Mean squared error: %.2f\" % np.mean((regr.predict(test_x) - test_y) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('R-squared score: %.2f' % regr.score(test_x, test_y))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"840a3a1e-66b2-7a61-1826-df985301c1c9"},"outputs":[],"source":"regr.score(test_x, test_y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe35162b-6b82-66dc-7264-10c2098d687e"},"outputs":[],"source":"train_y.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1fe49b3d-e78f-6ad1-0a84-965547aff886"},"outputs":[],"source":"(regr.predict(test_x) - test_y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9e37d23-2f28-a97d-7cb7-7bf232b7b0ff"},"outputs":[],"source":"import tensorflow as tf"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a1a85ef-a2cb-6376-db74-ee54824ba3bf","collapsed":true},"outputs":[],"source":"# Parameters\nlearning_rate = 0.001\ntraining_epochs = 500\nbatch_size = 300\ndisplay_step = 1\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of features\nn_hidden_2 = 128 # 2nd layer number of features\nn_input = 563 # MNIST data input (img shape: 28*28)\nn_classes = 1 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nx = tf.placeholder(\"float\", [None, n_input])\ny = tf.placeholder(\"float\", [None, n_classes])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a35b356-d9c5-b3ad-7d9d-bc9860e90df2","collapsed":true},"outputs":[],"source":"def multilayer_perceptron(x, weights, biases):\n    # Hidden layer with sigmoid activation\n    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n    layer_1 = tf.nn.sigmoid(layer_1)\n    # Hidden layer with sigmoid activation\n    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n    layer_2 = tf.nn.sigmoid(layer_2)\n    # Output layer with linear activation\n    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n    return out_layer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f869f82b-afbe-92d6-180b-30c5d448071c","collapsed":true},"outputs":[],"source":"# Store layers weight & bias\nweights = {\n    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n}\nbiases = {\n    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}\n\n# Construct model\npred = multilayer_perceptron(x, weights, biases)\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.square(pred-y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Initializing the variables\ninit = tf.global_variables_initializer()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a4eaa39-8d25-3efb-27a6-80bc7d93c5db"},"outputs":[],"source":"total_len = X_train.shape[0]\n\n# Launch the graph\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(total_len/batch_size)\n        # Loop over all batches\n        for i in range(total_batch-1):\n            batch_x = X_train[i*batch_size:(i+1)*batch_size]\n            batch_y = Y_train[i*batch_size:(i+1)*batch_size]\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c, p = sess.run([optimizer, cost, pred], feed_dict={x: batch_x, y: batch_y})\n            # Compute average loss\n            avg_cost += c / total_batch\n\n        # sample prediction\n        label_value = batch_y\n        estimate = p\n        err = label_value-estimate\n        print \"num batch:\", total_batch\n\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print \"Epoch:\", (epoch+1), \"cost=\", avg_cost\n            print (\"[*]----------------------------\")\n            #for i in xrange(3):\n            #    print \"label value:\" + label_value[i] + \"estimated value:\" + estimate[i]\n            print \"[*]============================\"\n\n    print \"Optimization Finished!\"\n\n    # Test model\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n    print \"Accuracy:\", accuracy.eval({x: X_test, y: Y_test})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52a9f65d-f093-a038-4bfc-99dcbec07b39"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f45acd9-ae0e-19a5-0d35-ef0096b4b37d","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}