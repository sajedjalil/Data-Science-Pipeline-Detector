{"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"version":"3.6.1","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"}}},"cells":[{"source":"## Here we'll try to encode categorical features...","cell_type":"markdown","metadata":{"_uuid":"b90dae453f1bc0d53ff0080c51a3a4fbbf712b2a","_execution_state":"idle","_cell_guid":"1baf944f-0a93-4f4a-babb-9c58cd4e78c9"}},{"source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport xgboost as xgb \nfrom sklearn.metrics import r2_score\n\nfrom IPython.display import display, HTML\n# Shows all columns of a dataframe\ndef show_dataframe(X, rows = 2):\n    display(HTML(X.to_html(max_rows=rows)))","cell_type":"code","metadata":{"_uuid":"69f55f2a1d3e594834856d997e5d9049d26df7ff","_execution_state":"idle","collapsed":true,"_cell_guid":"83158ee7-602f-4b5c-89f8-4f9438d06dfc"},"execution_count":null,"outputs":[]},{"source":"# Datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","cell_type":"code","metadata":{"_uuid":"001bd35fb90497e6c7aeb374920f9cf8b6ca50a3","_execution_state":"idle","collapsed":true,"_cell_guid":"d599a9d3-d2cb-4dc1-b9ca-e2cb89abd63d"},"execution_count":null,"outputs":[]},{"source":"# Categorical features\ncat_cols = []\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        cat_cols.append(c)\nprint('Categorical columns:', cat_cols)\n\n# Dublicate features\nd = {}; done = []\ncols = train.columns.values\nfor c in cols: d[c]=[]\nfor i in range(len(cols)):\n    if i not in done:\n        for j in range(i+1, len(cols)):\n            if all(train[cols[i]] == train[cols[j]]):\n                done.append(j)\n                d[cols[i]].append(cols[j])\ndub_cols = []\nfor k in d.keys():\n    if len(d[k]) > 0: \n        # print k, d[k]\n        dub_cols += d[k]        \nprint('Dublicates:', dub_cols)\n\n# Constant columns\nconst_cols = []\nfor c in cols:\n    if len(train[c].unique()) == 1:\n        const_cols.append(c)\nprint('Constant cols:', const_cols)","cell_type":"code","metadata":{"_uuid":"ace0a1497c1adc835c9ef8a00f04a24578309198","_execution_state":"idle","_cell_guid":"d29b4cd8-5339-4239-987d-9d34c5f822b3"},"execution_count":null,"outputs":[]},{"source":"Figures below show categorical features (on the left) sorted by means of **y**'s grouped by labels. On the right there are corresponding **mean**'s, **std**'s (filled blue), **max**'s (green line) and **min**'s (red line).","cell_type":"markdown","metadata":{"_uuid":"48db05580ee3e100ac8065d1f1272ffcbbd80f81","_execution_state":"idle","_cell_guid":"f698f747-e1c2-46aa-b5c0-4dce42c01af0"}},{"source":"plt.figure(figsize=(20,32))\nfor i in range(len(cat_cols)):\n    c = cat_cols[i]\n    \n    means = train.groupby(c).y.mean()\n    stds = train.groupby(c).y.std().fillna(0)\n    maxs = train.groupby(c).y.max()\n    mins = train.groupby(c).y.min()\n    \n    ddd = pd.concat([means, stds, maxs, mins], axis=1); \n    ddd.columns = ['means', 'stds', 'maxs', 'mins']\n    ddd.sort_values('means', inplace=True)\n    \n    plt.subplot(8,2,2*i+1)\n    ax = sns.countplot(train[c], order=ddd.index.values)\n    for p in ax.patches:\n        x=p.get_bbox().get_points()[:,0]\n        y=p.get_bbox().get_points()[1,1]\n        ax.annotate('{:.0f}'.format(y), (x.mean(), y), ha='center', va='bottom')\n    \n    plt.subplot(8,2,2*i+2)\n    plt.fill_between(range(len(train[c].unique())), \n                     ddd.means.values - ddd.stds.values,\n                     ddd.means.values + ddd.stds.values,\n                     alpha=0.3\n                    )\n    plt.xticks(range(len(train[c].unique())), ddd.index.values)\n    plt.plot(ddd.means.values, color='b', marker='.', linestyle='dashed', linewidth=0.7)\n    plt.plot(ddd.maxs.values, color='g', linestyle='dashed', linewidth=0.7)\n    plt.plot(ddd.mins.values, color='r', linestyle='dashed', linewidth=0.7)\n    plt.xlabel(c + ': Maxs, Means, Mins and +- STDs')\n    plt.ylim(55, 270)","cell_type":"code","metadata":{"_uuid":"04812a16839d59f815bd5dbd000734ab5c620afd","_execution_state":"idle","_cell_guid":"7a58392b-c0ce-45aa-a846-ba834992c0d0"},"execution_count":null,"outputs":[]},{"source":"# Glue train + test\ntrain['eval_set'] = 0; test['eval_set'] = 1\ndf = pd.concat([train, test], axis=0, copy=True)\n# Reset index\ndf.reset_index(drop=True, inplace=True)","cell_type":"code","metadata":{"_uuid":"87732c13a13692c926bc445460cad7dbae024b7f","_execution_state":"idle","collapsed":true,"_cell_guid":"134404c2-d1ea-4d39-ba10-5ae6326a3ced"},"execution_count":null,"outputs":[]},{"source":"### Categorical feature encoding\nIn the next cell for every categorical column from **cat_cols** we'll find **mean** of **y's** for every label using **.groupby()**. Then we sort labels by values of **means**. Now, when labels are sorted, they can be encoded by numbers from *0* to *numbers of labels - 1*.","cell_type":"markdown","metadata":{"_uuid":"203b4e78e6b03e589ea7d4b143a8266a9e4adb68","_execution_state":"idle","_cell_guid":"09f31dc8-a5d9-43e6-a661-2fd2cc9db634"}},{"source":"def add_new_col(x):\n    if x not in new_col.keys(): \n        # set n/2 x if is contained in test, but not in train \n        # (n is the number of unique labels in train)\n        # or an alternative could be -100 (something out of range [0; n-1]\n        return int(len(new_col.keys())/2)\n    return new_col[x] # rank of the label\n\nfor c in cat_cols:\n    # get labels and corresponding means\n    new_col = train.groupby(c).y.mean().sort_values().reset_index()\n    # make a dictionary, where key is a label and value is the rank of that label\n    new_col = new_col.reset_index().set_index(c).drop('y', axis=1)['index'].to_dict()\n    # add new column to the dataframe\n    df[c + '_new'] = df[c].apply(add_new_col)\n\n# drop old categorical columns\ndf_new = df.drop(cat_cols, axis=1)\n\n# show the result\nshow_dataframe(df_new, 5)","cell_type":"code","metadata":{"_uuid":"6b0320bf70db6a0d581943410b3fa57eb6029cc0","_execution_state":"idle","_cell_guid":"5428c9c8-8a5c-462d-a19e-43f0fd5119d2"},"execution_count":null,"outputs":[]},{"source":"### Train-test split","cell_type":"markdown","metadata":{"_uuid":"9e57c7ce586a95f0702914a379fd4e2fc9ae152f","_execution_state":"idle","_cell_guid":"d6c69d70-e78d-4c79-9fa8-bb3715c31bad"}},{"source":"X = df.drop(list((set(const_cols) | set(dub_cols) | set(cat_cols))), axis=1)\n\n# Train\nX_train = X[X.eval_set == 0]\ny_train = X_train.pop('y'); \nX_train = X_train.drop(['eval_set', 'ID'], axis=1)\n\n# Test\nX_test = X[X.eval_set == 1]\nX_test = X_test.drop(['y', 'eval_set', 'ID'], axis=1)\n\n# Base score\ny_mean = y_train.mean()\n# Shapes\n\nprint('Shape X_train: {}\\nShape X_test: {}'.format(X_train.shape, X_test.shape))","cell_type":"code","metadata":{"_uuid":"822c0ef3a44266e882ed62fb58f251ad1a37c3d3","_execution_state":"idle","_cell_guid":"424034b6-9710-4c9d-b0a3-c062a19efbe7"},"execution_count":null,"outputs":[]},{"source":"### Model (XGBoost)","cell_type":"markdown","metadata":{"_uuid":"cbdbb86cadbe2343114ad69485944cf1889800ec","_execution_state":"idle","_cell_guid":"03d8d8d9-ac63-460d-b99f-9b20ebb35ec1"}},{"source":"### Regressor\n\n# prepare dict of params for xgboost to run with\nxgb_params = {\n    'n_trees': 100, \n    'eta': 0.005,\n    'max_depth': 3,\n    'subsample': 0.95,\n    'colsample_bytree': 0.6,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'base_score': np.log(y_mean),\n    'silent': 1\n}\n\n# form DMatrices for Xgboost training\ndtrain = xgb.DMatrix(X_train, np.log(y_train))\ndtest = xgb.DMatrix(X_test)\n\n# evaluation metric\ndef the_metric(y_pred, y):\n    y_true = y.get_label()\n    return 'r2', r2_score(y_true, y_pred)\n\n# xgboost, cross-validation\ncv_result = xgb.cv(xgb_params, \n                   dtrain, \n                   num_boost_round=2000, \n                   nfold = 3,\n                   early_stopping_rounds=50,\n                   feval=the_metric,\n                   verbose_eval=100, \n                   show_stdv=False\n                  )\n\nnum_boost_rounds = len(cv_result)\nprint('num_boost_rounds=' + str(num_boost_rounds))\n\n# train model\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n\n# Predict on trian and test\ny_train_pred = np.exp(model.predict(dtrain))\ny_pred = np.exp(model.predict(dtest))\n\nprint('First 5 predicted test values:', y_pred[:5])","cell_type":"code","metadata":{"_uuid":"ab64bea8868f097869bcb44fe8b95cd823ce9b51","_execution_state":"idle","_cell_guid":"0a919200-4dd4-4418-8640-32b9c48082a8"},"execution_count":null,"outputs":[]},{"source":"plt.figure(figsize=(16,4))\n\nplt.subplot(1,4,1)\ntrain_scores = cv_result['train-r2-mean']\ntrain_stds = cv_result['train-r2-std']\nplt.plot(train_scores, color='green')\nplt.fill_between(range(len(cv_result)), train_scores - train_stds, \n                 train_scores + train_stds, alpha=0.1, color='green')\ntest_scores = cv_result['test-r2-mean']\ntest_stds = cv_result['test-r2-std']\nplt.plot(test_scores, color='red')\nplt.fill_between(range(len(cv_result)), test_scores - test_stds, \n                 test_scores + test_stds, alpha=0.1, color='red')\nplt.title('Train and test cv scores (R2)')\n\nplt.subplot(1,4,2)\nplt.title('True vs. Pred. train')\nplt.plot([80,265], [80,265], color='g', alpha=0.3)\nplt.scatter(x=y_train, y=y_train_pred, marker='.', alpha=0.5)\nplt.scatter(x=[np.mean(y_train)], y=[np.mean(y_train_pred)], marker='o', color='red')\nplt.xlabel('Real train'); plt.ylabel('Pred. train')\n\nplt.subplot(1,4,3)\nsns.distplot(y_train, kde=False, color='g')\nsns.distplot(y_train_pred, kde=False, color='r')\nplt.title('Distr. of train and pred. train')\n\nplt.subplot(1,4,4)\nsns.distplot(y_train, kde=False, color='g')\nsns.distplot(y_pred, kde=False, color='b')\nplt.title('Distr. of train and pred. test')\n\n\n\nplt.figure(figsize=(18,1))\nplt.plot(y_train_pred[:200], color='r', linewidth=0.7)\nplt.plot(y_train[:200], color='g', linewidth=0.7)\nplt.title('First 200 true and pred. trains')\n\nprint('Mean error =', np.mean(y_train - y_train_pred))\nprint('Train r2 =', r2_score(y_train, y_train_pred))","cell_type":"code","metadata":{"_uuid":"3c4b390bedcc58f385cd69d58f7ef5f410046b7a","_execution_state":"idle","_cell_guid":"319fad38-39f5-45d1-b90a-b8a9bd44584b"},"execution_count":null,"outputs":[]},{"source":"### Feature importance","cell_type":"markdown","metadata":{"_uuid":"60d5c28e7a917bcc1711db5400077395ddbf7c57","_execution_state":"idle","_cell_guid":"2929a782-3769-46ee-9344-dcd4c1c47fd3"}},{"source":"# First 50 features\nfeatures_score = pd.Series(model.get_fscore()).sort_values(ascending=False)[:50]\nplt.figure(figsize=(7,10))\nsns.barplot(x=features_score.values, y=features_score.index.values, orient='h')","cell_type":"code","metadata":{"_uuid":"31246a6f15e500d55e785e13d6b532e43a9361bf","_execution_state":"idle","_cell_guid":"3880a8ea-abf0-4661-9ca0-d4ea928d9ab5"},"execution_count":null,"outputs":[]},{"source":"# output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n# output.to_csv('subm.csv', index=False)","cell_type":"code","metadata":{"_uuid":"92da3e03044f7daebfd36ed9b52b9c828a77ba54","_execution_state":"idle","collapsed":true,"_cell_guid":"124bb6ee-474e-448e-a1cc-9f3aa2f2a1bd"},"execution_count":null,"outputs":[]}],"nbformat":4}