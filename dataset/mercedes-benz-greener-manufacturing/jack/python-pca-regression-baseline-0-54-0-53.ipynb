{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"_is_fork":false,"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","name":"python"},"_change_revision":0},"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"a92643e84565fa3426ce981b3c1e0467c37c2b93","_cell_guid":"03929b38-8ebe-0966-801e-1c5d5b81b3a5"},"outputs":[],"source":"","execution_count":null},{"cell_type":"code","metadata":{"_uuid":"2f34c15e20b6f9aa65d76df531e69e3e7ad9652a","_cell_guid":"23cc9322-2fa6-dbd0-cc9f-bb054e877052","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1},{"cell_type":"code","metadata":{"_uuid":"52b85e14e4334640fe8cb693ccc52f44323b03e5","_cell_guid":"c9ecb172-a248-34b1-d781-84d1e69bb13a","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# read datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# process columns, apply LabelEncoder to categorical features\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\ntrain.head()\n#(Initial code borrowed from this notebook: https://www.kaggle.com/uluumy/mercedez-baseline-2)","execution_count":2},{"cell_type":"code","metadata":{"_uuid":"747a0922d021ef9a6dedb55be728867f2649beb5","_cell_guid":"26bb7f3b-0069-731d-cc2f-283d3b25d4b2","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"X_train = train.drop('y', axis = 1)\nY_train = train['y']","execution_count":3},{"cell_type":"code","metadata":{"_uuid":"2be80f6a2af679ac54a76524e8937822b6b6646e","_cell_guid":"2911118b-0dc6-a333-dbe6-206928003992","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn import linear_model, decomposition, datasets\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import make_scorer\n    \nr2 = make_scorer(r2_score)\nn_components = [100, 200, 300, 350]\n\nregr = linear_model.Ridge()\npca = decomposition.PCA()\npipe = Pipeline(steps=[('pca', pca), ('linear', regr)])\n\nestimator = GridSearchCV(pipe,dict(pca__n_components=n_components, linear__alpha = [0.0, 1.0, 2.0, 4.0, 16.0, 32.0, 64.0, 128.0, 256.0]),verbose = 1, scoring = r2)\n\nestimator.fit(X_train, Y_train)\n\nplt.axvline(estimator.best_estimator_.named_steps['pca'].n_components,\n            linestyle=':', label='n_components chosen')\nplt.legend(prop=dict(size=12))\nplt.show()","execution_count":null},{"cell_type":"code","metadata":{"_uuid":"51900be9da28a18828886527a393122a479c7a4b","_cell_guid":"58508845-984d-aaa1-7eb9-73b029a114bf","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"y_pred = estimator.predict(test)","execution_count":7},{"cell_type":"code","metadata":{"_uuid":"ff82235c46af4515ef1b43cd288219feba17bddb","_cell_guid":"4154d98e-c853-301e-5504-d751eff1ff01","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"ID = list(test['ID'])\ny_pred = list(y_pred)\nprint (y_pred[:5], ID[:5])","execution_count":8},{"cell_type":"code","metadata":{"_uuid":"36d16e1ada89b009e4f53003598f212842e89307","_cell_guid":"9d64a7db-40c4-9c7f-0238-c9adcc13b823","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"outputfile = open('result.csv', \"w+\")\noutputfile.write(\"ID,y\\n\")\nprint (len(ID), len(y_pred))\nfor i in range(len(ID)):\n    outputfile.write(str(ID[i])+ \",\" + str(y_pred[i])+\"\\n\" )\noutputfile.close()    \n    ","execution_count":9},{"cell_type":"code","metadata":{"_uuid":"3cdeae17f0398b354481dbb3d95b6a10488b7843","collapsed":false,"_cell_guid":"cfbf4bd6-31a6-429e-9092-595736b76270","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"estimator.cv_results_","execution_count":6},{"cell_type":"code","metadata":{"_uuid":"c41c2dc4109404ccbc44cf7a92935a9c69db0a24","collapsed":false,"_cell_guid":"c8680609-7815-4ab9-94d1-beffbc8d0ae2","trusted":false,"_execution_state":"idle"},"outputs":[],"source":"","execution_count":null}],"nbformat":4}