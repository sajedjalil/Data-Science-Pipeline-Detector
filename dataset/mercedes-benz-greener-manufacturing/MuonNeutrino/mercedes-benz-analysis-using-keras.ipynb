{"metadata":{"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","version":"3.6.1","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":2,"nbformat":4,"cells":[{"metadata":{"deletable":true,"_uuid":"3d01cbe8d59b5b0c5e54c276bbf2c06afe3a4b95","editable":true},"outputs":[],"source":"# Method 1: Use X0 value to make predictions\n\nWe see that there are many values of X0. It turns out that this is actually a pretty good predictor by itself, so we can start out by looking only at this variable. We don't need to do any fitting: just an X0-->y map using the mean y. It's possible that the median might be better.","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":true,"editable":true,"_uuid":"015b2bd53315a8bad6bdcb8266840a217229d00d"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"f9749d92c345789653cb4b89ed375e875d9c4c87"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\ntrain = pd.read_csv('../input/train.csv',index_col=0)\ntest = pd.read_csv('../input/test.csv',index_col=0)\ntrain = train[['X0','y']]\ntrain, val = train_test_split(train,test_size=0.3,random_state=1234)\ntest = test['X0']\n\ngroups = train.groupby('X0')\nymap = {}\nfor name,group in groups:\n    ymap[name] = group.y.mean()\n\ntrain['ypred'] = train.X0.map(ymap)\nval['ypred'] = val.X0.map(ymap)    \nval['ypred'] = val.ypred.fillna(train.y.mean())\n\ntrain_score = r2_score(train.y,train.ypred)\nval_score = r2_score(val.y,val.ypred)\n\nprint('Training score: ' + str(train_score))\nprint('Validate score: ' + str(val_score))\n\nytest = test.map(ymap)\nytest = ytest.fillna(train.y.mean())\n        \n        \nytest = pd.DataFrame({'y':ytest})\nytest.to_csv('submission_X0.csv')","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"_uuid":"753caf0f9ad8a9c3c8841fbc33a84ac58debe2ef","editable":true},"outputs":[],"source":"# Method 2: Linear Regression with Keras\n\nI don't have much experience with neural nets, so I'll start by setting up a trivial neural net in Keras.\n\nA single linear output node with no hidden layers is equivalent to linear regression. It should give results that are equivalent to the previous method up to any uncertainties from the minimization procedure. As long as we don't do anything crazy, optimization shouldn't do much to improve things.","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":true,"editable":true,"_uuid":"e602c2fb590028272a1a8a6befa93b5f18fdceaa"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\n\n###\nvalidate = False\n###\n\ntrain = pd.read_csv('../input/train.csv',index_col=0)\ntrain.head()\ntest = pd.read_csv('../input/test.csv',index_col=0)\n\nxtrain = pd.get_dummies(train.X0)\nytrain = train.y\nxtest = pd.get_dummies(test.X0)\n\n# Get list of columns\nfor col in xtrain.columns:\n    if col not in xtest.columns:\n        xtest[col] = 0\n        \nfor col in xtest.columns:\n    if col not in xtrain.columns:\n        xtest = xtest.drop(col,axis=1)\n        \n\nif validate is True: \n    xtrain, xval, ytrain, yval = train_test_split(xtrain,ytrain,test_size=0.3,random_state=1234)\nxtest = xtest.sort_index(axis=1)\nprint(xtrain.head())\nprint(xtest.head())","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":true,"editable":true,"_uuid":"f9f74b5989bc0415235a3c2319fd698f6fa11cbf"},"outputs":[],"source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers.core import Dropout\nfrom keras import optimizers\nfrom keras import regularizers","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":true,"editable":true,"_uuid":"ac18c27d7678098d6f2f02f5308df18d2e0491ba"},"outputs":[],"source":"print('Building Model')\nmodel = Sequential()\nmodel.add(Dense(units=1,input_dim=xtrain.shape[1]))\nmodel.add(Activation('linear')) # Linear to get fit\nprint('Compiling Model')\nsgd = optimizers.SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error',optimizer=sgd)\nprint('Fit Model')\nmodel.fit(xtrain.as_matrix(), ytrain.as_matrix(), epochs=1000, batch_size=512)\nprint('Evaluating and predicting')\n#loss = model.evaluate(xtrain.as_matrix(),ytrain.as_matrix(),batch_size=128)\ntrain_vals = model.predict(xtrain.as_matrix(),batch_size=128)\nif validate is True:\n    val_vals = model.predict(xval.as_matrix(), batch_size=128)\ntest_vals = model.predict(xtest.as_matrix(),batch_size=128)","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":true,"editable":true,"_uuid":"4c3fbad689a1a7e4e2d280bf8f042d3174981a88"},"outputs":[],"source":"from sklearn.metrics import r2_score\nif validate is True:\n    val_score = r2_score(yval,val_vals)\n    print('Validation score: '+ str(val_score))\n\ntrain_score = r2_score(ytrain,train_vals)\nprint('Training score: ' + str(train_score))\n#model.get_weights()[0] + model.get_weights()[1][0]","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":true,"editable":true,"_uuid":"b39ca2c8abd4e1e71ecd9c07e96c0d377f32a84f"},"outputs":[],"source":"test['y'] = test_vals\ntest_out = test[['y']]\ntest_out.to_csv('submission_linearfit.csv')","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"_uuid":"9c6f802a10177276ba3a2ee8b68ba841af9e3e01","editable":true},"outputs":[],"source":"# Method 3: Keras/Theano Fully Connected Feed-Forward Neural Net\n\nNext, we'll try out a neural net using Keras. I'm using the Theano backend, but the code for TensorFlow should be the same in Keras. To do this, we'll first subtract the X0 predictions from y so that we only fit for the difference. We'll see why this might be a good idea later.\n","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"06dd0e49a40ea53c928d0ee2fe69a880fa4a0553"},"outputs":[],"source":"train = pd.read_csv('../input/train.csv',index_col=0)\ntrain.head()\ntest = pd.read_csv('../input/test.csv',index_col=0)\n","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"bb7a3877a74a9cba738c24429b5b3d6971a7663e"},"outputs":[],"source":"dum = pd.get_dummies(train.X0,drop_first = True)\ntrain = pd.merge(train,dum,left_index=True,right_index=True,suffixes=('','_x0'))\ndum = pd.get_dummies(test.X0,drop_first = True)\ntest = pd.merge(test,dum,left_index=True,right_index=True,suffixes=('','_x0'))\ntrain.head()\n\n# Get list of columns\nfor col in train.columns:\n    if col not in test.columns:\n        test[col] = 0\n        \nfor col in test.columns:\n    if col not in train.columns:\n        test = test.drop(col,axis=1)\n        \ngroups = train.groupby('X0')\nymap = {}\nfor name,group in groups:\n    ymap[name] = group.y.mean()\n\ntrain['yX0'] = train.X0.map(ymap)\ntrain['ydiff'] = train.y - train.yX0\ntest['yX0'] = test.X0.map(ymap)\ntest['yX0'] = test['yX0'].fillna(train.y.mean())\n        \nprint(test.shape)\nprint(train.shape)","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"_uuid":"20520fea858693777382604a654162e644bb5d73","editable":true},"outputs":[],"source":"## Validation\n\nTo make things faster, I'll just use a regular train/test split rather than k-fold cross validation. 30% of the training data set will go into the validation set.","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"cb814340e32fa265053646e8c07616da607b07d3"},"outputs":[],"source":"validate = True\n\nfrom sklearn.model_selection import train_test_split\nif validate is True:\n    train, val = train_test_split(train,test_size=0.3,random_state=1234)\n","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"_uuid":"8467923e76c788ec0a519319e1b8a264e9a5321a","editable":true},"outputs":[],"source":"## Plotting\n\nWhen we plot the value of y, we see that the distribution has a lot of structure. There are a number of different peaks that are all smeared together.\n\nHowever, when we look at $y-y_{X0pred}$, we get a much cleaner distribution. There is still a long high-value tail that may be responsible for much of the $R^2$ value from just the $X_0$ prediction.","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"f951025994b7a3b024f1878715ce87be87f5a6cd"},"outputs":[],"source":"fig = plt.figure(1,figsize=(10,10))\nax = fig.add_subplot(221)\nplt.hist(train.y,bins=80)\nplt.xlabel('y')\nplt.ylabel('Number of Entries')\nax = fig.add_subplot(222)\nplt.hist(np.log(train.y),bins=80)\nplt.xlabel('log(y)')\nplt.ylabel('Number of Entries')\nax = fig.add_subplot(223)\nplt.hist(train.ydiff,bins=80)\nplt.xlabel('y-y(X0)')\nplt.show()","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"_uuid":"a943e30eaff9f4cb26abf035138111c4a0b0be37","editable":true},"outputs":[],"source":"# Drop duplicate columns\n\nMany columns are just duplicates on the training set, so we should find these and remove them. I'll take duplicates as any pair of columns where standard deviation is less than 0.02 (I just chose this arbitrarily - could be optimized).","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"2a1ba106816c52011e3adf0c2caf1a77f916602a"},"outputs":[],"source":"dupl_cols = []\nfor i in range(10,386):\n    for j in range(i+1,386):\n        try:\n            label1 = 'X%i'%(i)\n            label2 = 'X%i'%(j)\n            vals = (train[label1]==train[label2])\n            if vals.std()<0.02:\n                dupl_cols.append(label2)\n        except:\n            pass\n#print(dupl_cols)\ndupl_cols = {x for x in dupl_cols} # unique set\nprint('# of duplicate columns: ' +str(len(dupl_cols)))\n\ntrain = train.drop(dupl_cols,axis=1)\nif validate is True:\n    val = val.drop(dupl_cols,axis=1)\ntest = test.drop(dupl_cols,axis=1)","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"_uuid":"52cbaf31ca45b5865dc13f02f50c257505e38184","editable":true},"outputs":[],"source":"# Look for Binary Fields with Large y Differences\n\nThere are hundreds of binary features here, so we'll look over them and find the ones which have the largest difference between the $y$ residuals for the two values of the feature. Here, I save the features with at least 10 entries in each class and with a difference of at least $\\sigma/20$  where $\\sigma$ is taken from the standard deviations of the two distributions.","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"b90429eb21492914ffc88dde860426ba60d28d5f"},"outputs":[],"source":"diff = []\nname = []\nc0 = []\nc1 = []\nmean0 = []\nmean1 = []\nstd0 = []\nstd1 = []\nfor i in range(10,386):\n    try:\n        yy = train.groupby('X%i'%(i)).ydiff\n        diff0 = np.abs(yy.mean()[1] - yy.mean()[0])/np.sqrt(yy.var()[1]+yy.var()[0])\n        #c0 = yy.count()[0]\n        #c1 = yy.count()[1]\n        c0.append(yy.count()[0])\n        c1.append(yy.count()[1])\n        mean0.append(yy.mean()[0])\n        mean1.append(yy.mean()[1])\n\n        std0.append(yy.std()[0])\n        std1.append(yy.std()[1])\n        diff.append(diff0)\n        name.append('X%i'%(i))\n\n    except:\n        pass\ndf = pd.DataFrame({'c0':c0,'c1':c1,'diff':diff,'mean0':mean0,'std0':std0,'mean1':mean1,'std1':std1},index=name)\nindices = df[((df.c0<=10) | (df.c1<=10) | (df['diff']<=0.05))].index\n#df = df[((df.c0>50) & (df.c1>50) & (df['diff']>0.2))].sort_values(by='diff',ascending=False)\ndf = df[(df.c0>10) & (df.c1>10) & (df['diff']>0.05)].sort_values(by='diff',ascending=False)\ndf.head(100)","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"ffa81ffd4a2c4df4fbcf3092476cec72dda45b10"},"outputs":[],"source":"## Set up output data frames\n\nWe'll fit to $y-y_{X0pred}$ so we need to add $y_{X0pred}$ back in to get the prediction for $y$.","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"7c45b43cf63ac06b4024e1e1872506b0f9e78e88"},"outputs":[],"source":"ytrain = train.loc[:,['y','yX0','ydiff']]\ncols = [x for x in df.index]\nif validate is True:\n    xval = val[cols]\n    yval = val.loc[:,['y','yX0','ydiff']]\nytest = test.loc[:,['yX0']]\nxtrain = train[cols]\nxtest = test[cols]","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"214f20ba1139cd1242855f97f17ca3f139777817"},"outputs":[],"source":"xtrain.head()","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"b4eb8a4258cc2d8a98fab8999fb55515dfeb7c95"},"outputs":[],"source":"## Setting up the Keras model\n\nWe'll use a simple sequential model with a single densely-connected hidden layer. I've tested both L2 regularization and dropout and similar results are obtained with both. As far as I can tell, it will be feature development that makes most of the difference between models.","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"1a0b389950c8172ecbe18708d6fcfb8f649e4249"},"outputs":[],"source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers.core import Dropout\nfrom keras import optimizers\nfrom keras import regularizers","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"scrolled":true,"_uuid":"c954085cf8f7060bf4affd7fb3f5cd365fd43fa7"},"outputs":[],"source":"print('Building Model')\nmodel = Sequential()\nl2reg = 0.0\nmodel.add(Dropout(0.2,input_shape=(xtrain.shape[1],)))\nmodel.add(Dense(units=10,kernel_regularizer=regularizers.l2(l2reg)))\nmodel.add(Activation('relu')) # These are all categorical so probably doesn't matter\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=1,kernel_regularizer=regularizers.l2(l2reg)))\n#model.add(Dropout(0.5))\nmodel.add(Activation('linear')) # Linear to get fit\nprint('Compiling Model')\nsgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=False)\nmodel.compile(loss='mean_squared_error',optimizer=sgd)\nprint('Fit Model')\nmodel.fit(xtrain.as_matrix(), ytrain.ydiff.as_matrix(), epochs=1000, batch_size=64)\nprint('Evaluating and predicting')\n#loss = model.evaluate(xtrain.as_matrix(),ytrain.as_matrix(),batch_size=128)\ntrain_vals = model.predict(xtrain.as_matrix(),batch_size=128)\ntest_vals = model.predict(xtest.as_matrix(),batch_size=128)\n\nytrain['ypred'] = train_vals\nif validate is True:\n    val_vals = model.predict(xval.as_matrix(), batch_size=128)\n    yval['ypred'] = val_vals\n    yval['ypred'] = yval.ypred+yval.yX0\n\nytest['ypred'] = test_vals\nytrain['ypred'] = ytrain.ypred+ytrain.yX0\nytest['ypred'] = ytest.ypred+ytest.yX0","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"2be0ae246c8df60b92e9496223df2b604ca25d97"},"outputs":[],"source":"from sklearn.metrics import r2_score\ntrain_score = r2_score(ytrain.y,ytrain.ypred)\ntrain_score2 = r2_score(ytrain.ydiff,ytrain.ypred-ytrain.yX0)\nprint('Training score (X0 diff): ' + str(train_score2))\nprint('Training score (full): ' + str(train_score))\n\nif validate is True:\n    val_score2 = r2_score(yval.ydiff,yval.ypred-yval.yX0)\n    val_score = r2_score(yval.y,yval.ypred)\n    print('Validation score (X0 diff): '+ str(val_score2))\n    print('Validation score (full): '+ str(val_score))","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"30470fe106de18fe41227343edb107b5bdeeccf7"},"outputs":[],"source":"test_out = ytest[['ypred']]\ntest_out = test_out.sort_index(ascending=True)\ntest_out['y'] = test_out.ypred\ntest_out = test_out[['y']]\ntest_out.to_csv('submission.csv')","execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"526b2a209d110f95bf915d1275f6ed00e12fe082"},"outputs":[],"source":"So, after all that work using neural nets, we've actually gained almost nothing in the validation set. This result is a tiny bit better on the public leaderboard than just using X0 but not by much. Looking at the current leaders, it looks like it's possible to get maybe another 0.01 increase or so in R^2 but this actually isn't so far off the leaders. So, basically everyone is only possibly getting minor gains from a very simple model.\n\n# So What Now?\n\nWell, we haven't looked at the other categorical variables. Maybe some of those will help.\n\nI also didn't do any cleaning of X0. If we look at it, there are some values of X0 with very few entries. We probably don't have a good sense of what the mean y should be for these, so we might want to come up with replacement values for these.\n\nFinally, let's look at the $y-y_{X0pred}$ distribution. It looks like a Gaussian with a long positive tail. How much of our remaining error comes from the tail?","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"1819553454b52b47d5ee15d6e8896151251fd9e5"},"outputs":[],"source":"train.ydiff.std()\nquantiles = train.ydiff.quantile([0.16,0.84])\n0.25*(quantiles.iloc[1]- quantiles.iloc[0])**2 / train.ydiff.var()","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"88ab5422c56cfad44e09bf17f5e49fdd01fcc9cd"},"outputs":[],"source":"Evidently, the variance calculated from the central 68% percent region and from the actual sample variance are quite different. It looks like the tail might even provide half the remaining error. If we really want to push this analysis, it may be most useful to see if we can find some way to separate the tail events from the main peak and then do an analysis on the tail events only.","execution_count":null,"cell_type":"markdown"},{"metadata":{"deletable":true,"collapsed":false,"editable":true,"_uuid":"740a1f9e0259f7c687e371753890e10bad56b6d6"},"outputs":[],"source":"","execution_count":null,"cell_type":"code"},{"metadata":{"deletable":true,"collapsed":true,"editable":true,"_uuid":"1914c2781c1297e66f69611836daa394ac175dff"},"outputs":[],"source":"","execution_count":null,"cell_type":"code"}]}