{"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, minmax_scale\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\nfrom sklearn.linear_model import LassoLarsCV, ElasticNet, SGDRegressor\n\nfrom sklearn.tree import ExtraTreeRegressor\n\nfrom sklearn.svm import SVR\n\nfrom sklearn.decomposition import PCA, FastICA\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.random_projection import SparseRandomProjection\n\nfrom sklearn.neural_network import MLPRegressor\n\nimport xgboost as xgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"metadata":{"_uuid":"3423aad5b893acee5848933f8706806400ebd387","_cell_guid":"0a956332-7062-4b17-a520-f8a061e92d6a","trusted":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\n\ntrain_y = train_df['y']\ntrain_id = train_df['ID']\ntrain_df = train_df.drop(\"y\", 1)\ntrain_df = train_df.drop(\"ID\", 1)\n\ntest_id = test_df['ID']\ntest_df = test_df.drop(\"ID\", 1)\n\nnum_train = len(train_df)\n\ndf_all = pd.concat([train_df, test_df])\ndf_all = pd.get_dummies(df_all, drop_first=True)\n\ntrain_df = df_all[:num_train]\ntest_df = df_all[num_train:]\n\n#############################\n\nn_comp = 12\n\n# tSVD\ntsvd = TruncatedSVD(n_components=n_comp, random_state=420)\ntsvd_results_train = tsvd.fit_transform(train_df)\ntsvd_results_test = tsvd.transform(test_df)\n\n# PCA\npca = PCA(n_components=n_comp, random_state=420)\npca2_results_train = pca.fit_transform(train_df)\npca2_results_test = pca.transform(test_df)\n\n# ICA\nica = FastICA(n_components=n_comp, random_state=420)\nica2_results_train = ica.fit_transform(train_df)\nica2_results_test = ica.transform(test_df)\n\n# GRP\ngrp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\ngrp_results_train = grp.fit_transform(train_df)\ngrp_results_test = grp.transform(test_df)\n\n# SRP\nsrp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\nsrp_results_train = srp.fit_transform(train_df)\nsrp_results_test = srp.transform(test_df)\n\n# Append decomposition components to datasets\nfor i in range(1, n_comp+1):\n    train_df['pca_' + str(i)] = pca2_results_train[:,i-1]\n    test_df['pca_' + str(i)] = pca2_results_test[:, i-1]\n    \n    train_df['ica_' + str(i)] = ica2_results_train[:,i-1]\n    test_df['ica_' + str(i)] = ica2_results_test[:, i-1]\n\n    train_df['tsvd_' + str(i)] = tsvd_results_train[:,i-1]\n    test_df['tsvd_' + str(i)] = tsvd_results_test[:, i-1]\n    \n    train_df['grp_' + str(i)] = grp_results_train[:,i-1]\n    test_df['grp_' + str(i)] = grp_results_test[:, i-1]\n    \n    train_df['srp_' + str(i)] = srp_results_train[:,i-1]\n    test_df['srp_' + str(i)] = srp_results_test[:, i-1]\n\nX_dtrain, X_test, y_dtrain, y_test = train_test_split(train_df, train_y, random_state=7, test_size=0.3)","execution_count":null,"metadata":{"_uuid":"7c64d2bab278872b9fa6685af5f8f3e16038da97","_cell_guid":"5a174037-ef99-4bdb-9c3a-5134b18cc81d","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"We will try to train some models, and stack them with a super-model to obtain better combined predictions.\nAll the algorithms parameters above have been pre-optimized.","execution_count":null,"metadata":{"_uuid":"24a1be8c11593e2b4e470e552829abd4e30038ec","_cell_guid":"c62b8803-9a31-40c0-920f-d070ec226689","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"RandomForest\n------------","execution_count":null,"metadata":{"_uuid":"965aca7c4758358bb22cdcd6f356bd017be0f293","_cell_guid":"10c6d645-6051-4984-b81b-465a07568d62","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"model_rfr = RandomForestRegressor(n_estimators=600, max_depth=3, min_samples_split=4, min_samples_leaf=60)\n\n# Let's see the feature importance for this model\nimportances = model_rfr.fit(train_df, train_y).feature_importances_\nfeatures = pd.DataFrame()\nfeatures['feature'] = train_df.columns\nfeatures['importance'] = importances\n\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\n#features[features.size-100:].plot(kind='barh', figsize=(12,24))\n\n\n#results = cross_val_score(model_rfr, train_df, train_y, cv=10)\n#print(\"RandomForest score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))","execution_count":null,"metadata":{"_uuid":"3a1e6231ae9293f9570c7efc51ce7984274ab0a7","_cell_guid":"42f915e5-9da9-4137-99e4-06ef94d1b3c5","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"best_feature='X314'\ntodrop = features.loc[features['importance'] == 0].index\nnew_train_df = train_df.drop(todrop, 1)\nnew_train_df.head()\nnew_train_df.shape\n\nnew_test_df = test_df.drop(todrop, 1)","execution_count":null,"metadata":{"_uuid":"9555b33869848a51edd2cb5a6efa78e58a1523b5","_cell_guid":"8e69cb0e-b295-48e1-8415-76fd35a66c46","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"model_rfr = RandomForestRegressor(n_estimators=600, max_depth=3, min_samples_split=4, min_samples_leaf=60)\n#results = cross_val_score(model_rfr, new_train_df, train_y, cv=10)\n#print(\"RandomForest score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\n#print(results)","execution_count":null,"metadata":{"_uuid":"b2cf3124aca385fdffd83aba3f259ac5f5a857fc","_cell_guid":"abfc41a2-4d22-4bd3-9902-ef436b53a37e","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"SVR\n---","execution_count":null,"metadata":{"_uuid":"9bcc8efef3e899e9ca47732a9cfa7381a049111b","_cell_guid":"92c3f7f1-79dd-48a9-86e5-5e4edcf8850b","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"model_svr = SVR(kernel='rbf',gamma=0.005, C=10, epsilon=5.0)\n\n'''\nresults = cross_val_score(model_svr, train_df, train_y, cv=10)\nprint(\"SVR score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n\nresults = cross_val_score(model_svr, new_train_df, train_y, cv=10)\nprint(\"SVR score (only on most important features): %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n'''","execution_count":null,"metadata":{"_uuid":"d7002b84e608cc338bae17018044649778060b55","_cell_guid":"a01a5c6c-df20-4a9d-b48f-6737a08870e4","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"GBR\n---","execution_count":null,"metadata":{"_uuid":"b4b0ba3c00d28e46660c778cbd0b0ee575b8b84a","_cell_guid":"85198610-ac6b-431e-8791-3b86c9e67c23","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"model_gbr = GradientBoostingRegressor(n_estimators=500, learning_rate=0.007, max_depth=3, min_samples_split=6, \n                                      min_samples_leaf=60)\n#results = cross_val_score(model_gbr, train_df, train_y, cv=10)\n#print(\"GBR score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\n#print(results)\n\n#results = cross_val_score(model_gbr, new_train_df, train_y, cv=10)\n#print(\"GBR score (imp features): %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\n#print(results)","execution_count":null,"metadata":{"_uuid":"cc5ccb0a4902a9ece894e3feeec9d8c00ca5088f","_cell_guid":"fe9390b3-b75c-4141-8ffb-74549f084742","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"'''\nimportances = model_gbr.fit(new_train_df, train_y).feature_importances_\nfeatures = pd.DataFrame()\nfeatures['feature'] = new_train_df.columns\nfeatures['importance'] = importances\n\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(12,24))\n'''","execution_count":null,"metadata":{"_uuid":"8186f6842c39143d7d37cd2989fe2c19c48d4ac3","_cell_guid":"1563c525-9313-42c0-a62e-18d44bc52626","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"'''\ntodrop = features.loc[features['importance'] == 0].index\nnew_train_df2 = new_train_df.drop(todrop, 1)\nnew_train_df2.head()\nnew_train_df2.shape\n'''","execution_count":null,"metadata":{"_uuid":"5278cd31417a9ddf95e16189010dd322d932a141","_cell_guid":"e41d34ee-4b79-4d7e-9b3e-de9014f65e1f","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"model_gbr = GradientBoostingRegressor(n_estimators=500, learning_rate=0.007, max_depth=3, min_samples_split=6, \n                                      min_samples_leaf=60)\n'''\nresults = cross_val_score(model_gbr, new_train_df, train_y, cv=10)\nprint(\"GBR score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n\nresults = cross_val_score(model_gbr, new_train_df2, train_y, cv=10)\nprint(\"GBR score (imp features): %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n'''","execution_count":null,"metadata":{"_uuid":"b94a9eddafce2c8809348dc05f0ee4853536431b","_cell_guid":"0ec516ef-02c5-4a19-b7b5-64cc915b67c8","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"MLPRegressor\n------------","execution_count":null,"metadata":{"_uuid":"472911b6bf79ee0939cf73558e9c4e8b94ec2508","_cell_guid":"f0b1a7aa-d4a3-4ced-b656-74fdac64598f","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"model_mlp = MLPRegressor(max_iter=200, solver='adam', learning_rate=\"constant\")\n\n'''\nresults = cross_val_score(model_mlp, train_df, train_y, cv=10)\nprint(\"MLP score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n\nresults = cross_val_score(model_mlp, new_train_df, train_y, cv=10)\nprint(\"MLP score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n'''","execution_count":null,"metadata":{"_uuid":"5d007afbc51d9cab5a53f94f990f488c8f2d3b90","_cell_guid":"7489dd7a-61b0-493b-814b-32882fcddea4","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"ExtraTreeRegressor\n------------------","execution_count":null,"metadata":{"_uuid":"fedf78e9878382c6a876c5525e6571feb6817165","_cell_guid":"34eec49a-375c-49f5-bf5b-3d84e36e6ead","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"model_ex = ExtraTreesRegressor(n_estimators=700, max_depth=3, min_samples_split=24, min_samples_leaf=5, bootstrap=True, oob_score=True)\n\n'''\nresults = cross_val_score(model_ex, train_df, train_y, cv=10)\nprint(\"EXR score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n\nresults = cross_val_score(model_ex, new_train_df, train_y, cv=10)\nprint(\"EXR score (only on most important features): %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n'''","execution_count":null,"metadata":{"_uuid":"0bc31d03624a7ac71d2388f95b56378aad19ffa6","_cell_guid":"f8da48b6-5786-4c66-89d8-2f598444d469","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"AdaBoost\n--------","execution_count":null,"metadata":{"_uuid":"0723427879f9ae0c0e61d4458e11213d97dee25f","_cell_guid":"dfae0540-012a-498f-b59b-1db8d17a0ece","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"model_ada = AdaBoostRegressor(n_estimators=50, learning_rate=0.01)\n\n'''\nresults = cross_val_score(model_ada, train_df, train_y, cv=10)\nprint(\"ADA score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n\nresults = cross_val_score(model_ada, new_train_df, train_y, cv=10)\nprint(\"ADA score (only on most important features): %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n'''","execution_count":null,"metadata":{"_uuid":"78b59260d1e4607421bdbf7ac9878bae515e3451","_cell_guid":"01b6f404-256c-46aa-b5ee-cc010e565b3c","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"XGBoost\n-------","execution_count":null,"metadata":{"_uuid":"c0b66a319c481c9c8a8595061097f8851f63d8b0","_cell_guid":"5a4013a1-ad52-4d6f-aff3-550344101786","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"model_xgb = xgb.XGBRegressor(objective='reg:linear', n_estimators=50, max_depth=3, learning_rate=0.1, min_child_weight=30, subsample=0.9, colsample_bytree=0.7, reg_alpha=0.01)\n\n'''\nresults = cross_val_score(model_xgb, train_df, train_y, cv=10)\nprint(\"XGB score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n\nresults = cross_val_score(model_xgb, new_train_df, train_y, cv=10)\nprint(\"XGB score (only on most important features): %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n'''","execution_count":null,"metadata":{"_uuid":"80fa6a56c28a5ff74d0fea0ed857437c0bc82ae1","_cell_guid":"82e4f50a-3bf9-4263-b275-8ffe1aa00d99","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"SGDRegressor\n------------","execution_count":null,"metadata":{"_uuid":"f396533fb3981ccf5e15e38496017a8c4a5ac648","_cell_guid":"cfecf334-5896-4651-9c7f-4ab8b990f05c","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"model_sgd = SGDRegressor(alpha=0.02, penalty='l1', n_iter=10, power_t=0.2, average=False)\n\n'''\nresults = cross_val_score(model_sgd, train_df, train_y, cv=10)\nprint(\"SGD score: %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n\nresults = cross_val_score(model_sgd, new_train_df, train_y, cv=10)\nprint(\"SGD score (only on most important features): %.4f (%.4f)\" % (results.mean()*100, results.std()*100))\nprint(results)\n'''","execution_count":null,"metadata":{"_uuid":"f196457b4c436ff42f64d4e6fbbffc6c58c97432","_cell_guid":"2e69503c-8801-407a-bdf6-627bf9b1d066","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"Ensembling\n----------","execution_count":null,"metadata":{"_uuid":"b4397c17b27b9cf2e3fc856a09df62e9bbf00bfd","_cell_guid":"9c67cd63-7872-40b8-94f9-f0d60f18c075","collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"markdown"},{"source":"'''\n    This code was borrowed and adapted\n'''\nclass Stacking(object):\n    def __init__(self, n_folds, stacker, base_models):\n        self.n_folds = n_folds\n        self.stacker = stacker\n        self.base_models = base_models\n    def fit_predict(self, X, X2, y, T, T2):\n        X = np.array(X)\n        X2 = np.array(X2)\n        y = np.array(y)\n        T = np.array(T)\n        T2 = np.array(T2)\n        folds = KFold(n_splits=self.n_folds, shuffle=True, random_state=2016)\n        S_train = np.zeros((X.shape[0], len(self.base_models)))\n        S_test = np.zeros((T.shape[0], len(self.base_models)))\n        \n        for i, clf in enumerate(self.base_models):\n            print(\"Predicting with: \", clf[0])\n            S_test_i = np.zeros((T.shape[0], self.n_folds))\n            for j, (train_idx, test_idx) in enumerate(folds.split(X)):\n                y_train = y[train_idx]  \n                if clf[1] == 1:\n                    X_train=X2[train_idx]\n                    X_holdout = X2[test_idx]\n                else:\n                    X_train=X[train_idx]\n                    X_holdout = X[test_idx]\n                        \n                clf[0].fit(X_train, y_train)\n                y_pred = clf[0].predict(X_holdout)[:]\n                S_train[test_idx, i] = y_pred\n                if clf[1] == 1:\n                    S_test_i[:, j] = clf[0].predict(T2)[:]\n                else:\n                    S_test_i[:, j] = clf[0].predict(T)[:]        \n            S_test[:, i] = S_test_i.mean(1)\n            \n        #self.stacker.fit(S_train, y)\n        #y_pred = self.stacker.predict(S_test)[:]\n        \n        return S_train, S_test","execution_count":null,"metadata":{"_uuid":"209c5118c34dc372639b523e0eb21dfeb8fc8d2d","_cell_guid":"b03b9fc6-55b3-451b-b6c0-2d2e3bda1c29","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"We'll first get the combined predictions of the different models we have. And then try to optimize another model using these new data. ","metadata":{"_uuid":"8571bfda4a89e16be5f385caa6609b7823878456","collapsed":false,"_execution_state":"idle"},"outputs":[],"execution_count":null,"cell_type":"markdown"},{"source":"base_models=[(model_rfr, 0), (model_gbr, 0), (model_xgb, 1), (model_ada, 0), (model_ex, 0)]\n\nens = Stacking(n_folds=10, stacker=model_gbr, base_models=base_models)\ns_train, s_test = ens.fit_predict(train_df, new_train_df, train_y, test_df, new_test_df)","metadata":{"_uuid":"a0953467564a8fd595e8564c474ba398eeef36ae","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"new_train = pd.DataFrame({\n        \"rfr\": s_train[:, 0],\n        \"gbr\": s_train[:, 1],\n        \"xgb\": s_train[:, 2],\n        \"ada\": s_train[:, 3],\n        \"ex\": s_train[:, 4],\n        \"y\": train_y\n    })\nnew_train.to_csv('new_train.csv', index=False)","metadata":{"_uuid":"ffa6cf0edcf955aa95f2a80496a9b00ed6abed04","collapsed":false,"_execution_state":"idle"},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"new_test = pd.DataFrame({\n        \"rfr\": s_test[:, 0],\n        \"gbr\": s_test[:, 1],\n        \"xgb\": s_test[:, 2],\n        \"ada\": s_test[:, 3],\n        \"ex\": s_test[:, 4]\n    })\nnew_test.to_csv('new_test.csv', index=False)","metadata":{"_uuid":"21d2dc8131863256f7f5d03cb3574dfde9be5cd6","collapsed":false,"_execution_state":"idle"},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"\nstacker = ElasticNet(normalize=True)\nbase_models=[(model_rfr, 0), (model_gbr, 0), (model_xgb, 1), (model_ada, 0), (model_ex, 0)]\n\nens = Stacking(n_folds=10, stacker=model_gbr, base_models=base_models)\n\ny_pred=ens.fit_predict(train_df, new_train_df, train_y, test_df, new_test_df)\n","execution_count":null,"metadata":{"_uuid":"fb0c7f4fa9dfc73b200585ea6224f94ddf8f89eb","_cell_guid":"3c88e79e-e251-4775-b3a4-b70051d86587","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"},{"source":"\nsubmission = pd.DataFrame({\n        \"ID\": test_id,\n        \"y\": y_pred\n    })\nsubmission.to_csv('mercedes_ens_opt.csv', index=False)\n","execution_count":null,"metadata":{"_uuid":"592ce4d229e98d3cfb92b16211eb86e6d94dc6b7","_cell_guid":"73124cd1-2bda-41fb-8a9c-124cc3dcdbc4","trusted":false,"collapsed":false,"_execution_state":"idle"},"outputs":[],"cell_type":"code"}],"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.1","file_extension":".py","name":"python","pygments_lexer":"ipython3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4}