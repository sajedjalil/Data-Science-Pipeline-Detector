{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ffeb3c9a-991c-690b-dc92-8184f6c7a27f"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n\nimport xgboost as xgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e88f8d4-f28e-ad55-1482-e63316af9af1"},"outputs":[],"source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f44b31b-589e-b062-6e35-3b0936d9a2a1"},"outputs":[],"source":"print('Size of training set: {} rows and {} columns'.format(*train_df.shape))\ntrain_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9206caa8-e9ca-c6f5-b6dc-38c59653124a"},"outputs":[],"source":"cols = [c for c in train_df.columns if 'X' in c]\nsingle_val = []\n\nnewcols = []\n\nfor c in cols:\n    print(\"Feature: \", c)\n    vals = train_df[c].unique()\n    print(vals)\n    if vals.size == 1:\n        print(\"---------------> Single value\")\n        single_val.append(c)\n    else:\n        newcols.append(c)\n        \nprint(single_val)"},{"cell_type":"markdown","metadata":{"_cell_guid":"075fdc0d-e1a5-430c-2d77-b1a7d6654242"},"source":"Some features have only one value. We may drop them as they would'nt have any impact:\n['X11', 'X93', 'X107', 'X233', 'X235', 'X268', 'X289', 'X290', 'X293', 'X297', 'X330', 'X347'] "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c85d74f9-c314-e6a3-8914-d75ee03bea57"},"outputs":[],"source":"train_df.drop(single_val, axis=1, inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c24f3d0b-be09-9e2a-5f7f-771080875829"},"source":"**Data preparation**\n--------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e56101d2-869f-7c24-b93a-547533b5caf0"},"outputs":[],"source":"# Save target column\n# IDs do not correspond to line number, so we need to save it as well\ntrain_y = train_df['y']\ntrain_id = train_df['ID']\n\ntrain_df = train_df.drop(\"y\", 1)\ntrain_df = train_df.drop(\"ID\", 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14e1906e-1be4-d312-ebff-962099df3cb8"},"outputs":[],"source":"print('Feature types:')\ntrain_df[newcols].dtypes.value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"65c8d2a4-caf3-1204-bfd9-da5d4966c91c"},"outputs":[],"source":"# Data need to be int or float, but we have int and object\n# We use the LabelEncoder function for that\n\nlabel_encoder = LabelEncoder()\n\nfor c in newcols:\n    typ = train_df[c].dtype\n    if typ != np.int64:\n        label_encoder = label_encoder.fit(train_df[c])\n        train_df[c] = label_encoder.transform(train_df[c])\n        "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db3c2473-6fe5-145c-0734-18a536b19e88"},"outputs":[],"source":"# Let's check the feature types now\nprint('Feature types:')\ntrain_df[newcols].dtypes.value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2fe481e-8636-f6e2-9904-4ae9424025e8"},"outputs":[],"source":"X_dtrain, X_test, y_dtrain, y_test = train_test_split(train_df, train_y, random_state=7, test_size=0.3)\ndtrain = xgb.DMatrix(X_dtrain, label=y_dtrain)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"780bea63-bb34-c471-9e85-f8fe1a1d9b34"},"outputs":[],"source":"params = {\"objective\": \"reg:linear\", \"booster\":\"gblinear\", \"max_depth\":\"4\", \"nb_estimator\":\"1000\"}\nmodel_xgb = xgb.train(dtrain=dtrain,params=params)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d59460d-b5db-70c2-4633-fc5644ffc261"},"outputs":[],"source":"y_pred = model_xgb.predict(dtrain)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3194aceb-6ae6-23c6-5a94-c208ec1d735f"},"outputs":[],"source":"mean_squared_error(y_dtrain, y_pred)"},{"cell_type":"markdown","metadata":{"_cell_guid":"038caed8-49ad-1f67-7313-912f7ced701b"},"source":"Random Forest\n-------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e864b67-6213-cd1c-cd7a-b7687e492386"},"outputs":[],"source":"model_rfr = RandomForestRegressor(n_estimators=100, max_features='log2').fit(X_dtrain, y_dtrain)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f55b5f82-a6b6-bc22-ca34-1cb70ad2483c"},"outputs":[],"source":"y_pred_rfr = model_rfr.predict(X_dtrain)\nmean_squared_error(y_dtrain, y_pred_rfr)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5af5dc70-4ac1-efc6-c312-35e1b6e9286f"},"outputs":[],"source":"importances = model_rfr.feature_importances_\nfeatures = pd.DataFrame()\nfeatures['feature'] = train_df.columns\nfeatures['importance'] = importances\n\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(5, 60))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3ba66b2-c25b-04da-8c75-405b4f597092"},"outputs":[],"source":"# Trying to remove some features\ntodrop = features.loc[features['importance'] < 0.000331].index.tolist()\ntrain_df = train_df.drop(todrop, 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e750d3c-1728-976a-f238-765a2f2346f4"},"outputs":[],"source":"print('Size of training set: {} rows and {} columns'.format(*train_df.shape))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7c2dcf20-188d-c5ae-df2f-b76ef2678714"},"outputs":[],"source":"model_rfr = RandomForestRegressor(n_estimators=100, max_features='log2').fit(X_dtrain, y_dtrain)\ny_pred_rfr = model_rfr.predict(X_dtrain)\nmean_squared_error(y_dtrain, y_pred_rfr)"},{"cell_type":"markdown","metadata":{"_cell_guid":"54ed0a2d-5f92-7bd6-5247-5675b00f133e"},"source":"GradientBoostingRegressor\n-------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e0ec40d-24ab-e2a0-b112-96f7957b55f5"},"outputs":[],"source":"model_gbr = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1,max_depth=1, random_state=0, loss='ls').fit(X_dtrain, y_dtrain)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"240535e0-1f3b-a2f4-729c-baa578a6f73b"},"outputs":[],"source":"y_pred_gbr = model_gbr.predict(X_dtrain)\nmean_squared_error(y_dtrain, y_pred_gbr)"},{"cell_type":"markdown","metadata":{"_cell_guid":"73c9802f-76cc-a89a-2fb6-2eeaa41ac0ef"},"source":"Ensembling\n----------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63fc33a8-eb42-c197-6e32-a2cbba0e2eca"},"outputs":[],"source":"y_glob = (y_pred_rfr + y_pred_gbr + y_pred)/3\nmean_squared_error(y_dtrain, y_glob)"},{"cell_type":"markdown","metadata":{"_cell_guid":"04a3a7ad-bbc5-d43a-ed16-f415aecf6324"},"source":"Predictions from test_df\n------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26ad71ab-d25e-2c8b-3e93-fb631827122f"},"outputs":[],"source":"test_id = test_df['ID']\ntest_df = test_df.drop(\"ID\", 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b19e2de3-1341-3cad-cc89-889954ede1b6"},"outputs":[],"source":"test_df.drop(single_val, axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16443acc-6961-e9c4-445e-da5588b43815"},"outputs":[],"source":"label_encoder = LabelEncoder()\n\nfor c in newcols:\n    typ = test_df[c].dtype\n    if typ != np.int64:\n        label_encoder = label_encoder.fit(test_df[c])\n        test_df[c] = label_encoder.transform(test_df[c])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08222d97-978a-d4e3-b28a-cffbe11249d8"},"outputs":[],"source":"d_test = xgb.DMatrix(test_df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fecf42c1-62bd-a843-94fd-a96ff077aa42"},"outputs":[],"source":"y_test1 = model_xgb.predict(d_test)\ny_test2 = model_rfr.predict(test_df)\ny_test3 = model_gbr.predict(test_df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1a0ada8-91a8-4c69-3dcf-de377dbcf024"},"outputs":[],"source":"submission = pd.DataFrame({\n        \"ID\": test_id,\n        \"y\": (y_test1 + y_test2 + y_test3)/3\n    })\nsubmission.to_csv('mercedes4.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}