{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"906f462c-bd3e-8150-b91f-bea2b5706890"},"source":"Effect of the metric r^2 to regression\n\nbased on scikit-learn -http://scikit-learn.org/stable/auto_examples/linear_model/plot_robust_fit.html#sphx-glr-auto-examples-linear-model-plot-robust-fit-py\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b6e1c98-11af-7d20-e719-7f3db356e574"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom sklearn.linear_model import (\n    LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor)\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\nnp.random.seed(42)\n\nX = np.random.normal(size=400)\ny = np.sin(X)\n# Make sure that it X is 2D\nX = X[:, np.newaxis]\n\nX_test = np.random.normal(size=200)\ny_test = np.sin(X_test)\nX_test = X_test[:, np.newaxis]\n\ny_errors = y.copy()\ny_errors[::3] = 3\n\nX_errors = X.copy()\nX_errors[::3] = 3\n\ny_errors_large = y.copy()\ny_errors_large[::3] = 10\n\nX_errors_large = X.copy()\nX_errors_large[::3] = 10"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3a70892-d6f1-53ba-e071-f1ebb7686739"},"outputs":[],"source":"estimators = [('OLS', LinearRegression()),\n              ('Theil-Sen', TheilSenRegressor(random_state=42)),\n              ('RANSAC', RANSACRegressor(random_state=42)),\n              ('HuberRegressor', HuberRegressor())]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14424a84-f3ec-bc38-5ba5-850d65ef765b"},"outputs":[],"source":"colors = {'OLS': 'turquoise', 'Theil-Sen': 'gold', 'RANSAC': 'lightgreen', 'HuberRegressor': 'black'}\nlinestyle = {'OLS': '-', 'Theil-Sen': '-.', 'RANSAC': '--', 'HuberRegressor': '--'}\nlw = 3\n        \nx_plot = np.linspace(X.min(), X.max())\nfor title, this_X, this_y in [\n        ('Modeling Errors Only', X, y),\n        ('Corrupt X, Small Deviants', X_errors, y),\n        ('Corrupt y, Small Deviants', X, y_errors),\n        ('Corrupt X, Large Deviants', X_errors_large, y),\n        ('Corrupt y, Large Deviants', X, y_errors_large)]:\n    plt.figure(figsize=(5, 4))\n    plt.plot(this_X[:, 0], this_y, 'b+')\n    \n    print(\"\\n\", title)\n\n    for name, estimator in estimators:\n        model = make_pipeline(PolynomialFeatures(3), estimator)\n        model.fit(this_X, this_y)\n        mse = mean_squared_error(model.predict(X_test), y_test)\n        r2 = r2_score(model.predict(X_test), y_test)\n        print('r2=%.6f, mse:%.6f %s' % (r2, mse, name))\n        y_plot = model.predict(x_plot[:, np.newaxis])\n        plt.plot(x_plot, y_plot, color=colors[name], linestyle=linestyle[name],\n                 linewidth=lw, label='%s: error = %.3f r^2=%.5f' % (name, mse, r2))\n\n    legend_title = 'Error of Mean\\nAbsolute Deviation\\nto Non-corrupt Data'\n    legend = plt.legend(loc='upper right', frameon=False, title=legend_title,\n                        prop=dict(size='x-small'))\n    plt.xlim(-4, 10.2)\n    plt.ylim(-2, 10.2)\n    plt.title(title)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b19a5635-8a2b-c7f9-26f4-1376059d8a2b"},"outputs":[],"source":"'''\nNotable is the strange r^2 values for the OLS, e.g. with r2=-11.154863. \nHuber-Regression looks like the best for the metric r^2 which is used in this competition.\nRANSAC as second, though everything depends on the error scale in y.\n'''"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}