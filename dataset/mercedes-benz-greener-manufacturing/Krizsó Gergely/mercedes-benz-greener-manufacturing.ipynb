{"nbformat_minor":1,"cells":[{"source":"DecisionTreeClassifier\n\nMercedes-Benz Competition","cell_type":"markdown","metadata":{"_cell_guid":"436dc1c7-6c00-4b5d-bf19-1ed04e7e62a1","_uuid":"9853b2486178a01178e9cf842e56fa5a6478c112","collapsed":true}},{"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"fa271f9a-5eb6-4cd9-a775-f3656673d5e9","_uuid":"6485b4a39dbebb55fb340bea92c44c6ffd0f0b98","collapsed":true}},{"source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nprint(\"Train shape : \", train.shape)\nprint(\"Test shape : \", test.shape)","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"0b6ece06-2fb4-43b4-a15d-751839883197","_uuid":"fe779d89084b22ffd52af303f263462737b2d93d","collapsed":true}},{"source":"PM = [101]\n\nfor prime in PM:\n    \n    # process columns, apply LabelEncoder to categorical features\n    for c in train.columns:\n        if train[c].dtype == 'object':\n            lbl = LabelEncoder() \n            lbl.fit(list(train[c].values) + list(test[c].values)) \n            train[c] = lbl.transform(list(train[c].values))\n            test[c] = lbl.transform(list(test[c].values))\n\n    # shape        \n    #print('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\n\n    train.y = train.y.astype(int)\n\n    X = train.values[0:, 2:377] # X0 - X385\n    Y = train.y.values\n    #Y = np.asarray(balance_data['y'], dtype=\"|S6\")\n\n    #X  #values\n    #Y #values\n    #Let’s split our data into training and test set. We will use sklearn’s train_test_split() method.\n\n    X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.5, random_state = 100)\n    #Decision Tree Classifier with criterion gini index\n\n    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n                                      random_state = 100, \n                                      max_depth=prime, \n                                      min_samples_leaf=80)\n    clf_gini.fit(X_train, y_train)\n\n    #Decision Tree Classifier with criterion information gain \n\n    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", \n                                         random_state = 100, \n                                         max_depth=prime*1000, \n                                         min_samples_leaf=38)\n    clf_entropy.fit(X_train, y_train)\n    print(clf_entropy)\n\n    y_pred = clf_gini.predict(X_test)\n    print(y_pred)\n    \n    y_pred_en = clf_entropy.predict(X_test)\n    print(y_pred_en)\n\n    print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100)\n    print(\"Accuracy is \", accuracy_score(y_test,y_pred_en)*100)\n    print(prime)","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"a0f78e41-e3f4-49b1-9d2c-cf6cae9c512b","_uuid":"4e4eab11a9cc1bd90080e626317129ae8ddc9d87","collapsed":true}}],"nbformat":4,"metadata":{"language_info":{"mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","version":"3.6.1"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}}}