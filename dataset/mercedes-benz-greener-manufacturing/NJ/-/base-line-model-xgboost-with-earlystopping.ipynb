{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c987ebb9-63bf-e5cd-0303-38d5c7afebb0"},"source":"A simple XGboost model with basic preprocessing is done!."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56aabeb3-d52e-6738-c080-aaf0bfebe4a2"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nnp.random.seed(1133)\nimport itertools\n\nimport xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import r2_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d719fb2-2cee-33d6-4b47-1b5a3903a010"},"outputs":[],"source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8fdb138-2b9d-0cd3-207a-0352b028f8f5"},"outputs":[],"source":"#copy the target variable and drop the coloumn\ntarget = train_data['y'].copy()\ntrain_data.drop(['y'],inplace=True,axis=1)\n\n#save test_id and drop ID from both train and test\n\ntest_id = test_data.ID.values.copy()\ntrain_data.drop(['ID'],inplace=True,axis=1)\ntest_data.drop(['ID'],inplace=True,axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6633466-31e8-81ac-d8dd-99dfaf9fa355"},"outputs":[],"source":"# remove constant columns,there are 12 features like dat\nremove_const = []\nfor col in train_data.columns:\n    if train_data[col].dtype !='object':\n        \n        if train_data[col].std() == 0:\n            remove_const.append(col)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e98e7f8a-444f-0bd5-dd78-ddaf102693c9"},"outputs":[],"source":"#remove those constant coloumns\n\n\ntrain_data.drop(remove_const, axis=1, inplace=True)\ntest_data.drop(remove_const, axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12e92aee-a68b-8c5e-722c-4578c0911207"},"outputs":[],"source":"#from an old script in santander competition\ndef remove_feat_identicals(data_frame):\n    # Find features having the same values in the same order and\n    # remove one of those redundant features.\n    print(\"\")\n    print(\"identical features...\")\n    n_features = data_frame.shape[1]\n    # Find the names of identical features by going through all the\n    # combinations of features (each pair is compared only once).\n    feat_delete = []\n    for feat_1, feat_2 in itertools.combinations(\n            iterable=data_frame.columns, r=2):\n        if np.array_equal(data_frame[feat_1], data_frame[feat_2]):\n            feat_delete.append(feat_2)\n    feat_names_delete = np.unique(feat_delete)\n    n_features_deleted = len(feat_names_delete)\n    print(\"  - Delete %s / %s features (~= %.1f %%)\" % (\n        n_features_deleted, n_features,\n        100.0 * (np.float(n_features_deleted) / n_features)))\n    return feat_names_delete"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"edc22526-bebd-394a-a5b3-6a889c98cc6a"},"outputs":[],"source":"#get the features that occuring in the same order\nfeature_to_delete = remove_feat_identicals(train_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38ee9f6d-46e1-0abc-e225-82166f7891d4"},"outputs":[],"source":"#delete the features\ntrain_data.drop(feature_to_delete, axis=1, inplace=True)\ntest_data.drop(feature_to_delete, axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f136ab0c-5d8f-3165-4788-eb3972041484"},"outputs":[],"source":"#convert categorical values to one-hot encoding(since we are using xgboost,this may give better score)\n\ntrain_dummies = pd.get_dummies(train_data)\ntest_dummies = pd.get_dummies(test_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"402b6b6f-9589-9928-7675-de34940e1879"},"outputs":[],"source":"def diff_list(first, second):\n    second = set(second)\n    return [item for item in first if item not in second]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e506a40-2e45-e91d-2e33-87c13491d170"},"outputs":[],"source":"#There are some coloumn that exist in train but not in test(vice-versa)\n#find them and drop \ntrain_dummies.drop(diff_list(train_dummies.columns,test_dummies.columns),inplace=True,axis=1)\ntest_dummies.drop(diff_list(test_dummies.columns,train_dummies.columns),inplace=True,axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d37cbf89-68da-b0e0-fb84-91bd8e1011b4"},"outputs":[],"source":"#Split the dataset to train and test\ntrain_X,test_X,train_y,test_y = train_test_split(train_dummies,target,test_size=0.2,random_state=142)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c64e397-9764-cc67-6616-e6aa6c419672"},"outputs":[],"source":"#Find the mean of target variable to set as the base score for xgboost\ny_mean = np.mean(target)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d41aa7a-3105-c215-d89a-4e43d2145c3e"},"outputs":[],"source":"\n\nxgb_params = {\n    'eta': 0.02,\n    'max_depth': 4,\n    'subsample': 0.95,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'base_score': y_mean,\n    'min_child_weight' : 1\n}\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8cde9e6-43f9-5a0d-23ac-35dfcb86efa7"},"outputs":[],"source":"dtrain = xgb.DMatrix(train_X, train_y)\ndtest = xgb.DMatrix(test_X,test_y)\nevallist = [(dtrain,'train'),(dtest,'test')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad001293-f6e5-123f-7aea-b81ac71ab6eb"},"outputs":[],"source":"def xgb_r2_score(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'r2', r2_score(labels, preds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6175218-aca5-931e-ef28-1610eef76531"},"outputs":[],"source":"model = xgb.train(dict(xgb_params, silent=0),dtrain=dtrain,num_boost_round=1000,evals=evallist,\n                  feval=xgb_r2_score,early_stopping_rounds=10,maximize=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"539eeedc-8b9d-5554-e21c-6550220cb871"},"outputs":[],"source":"#Make prediction and save results\nxg_check = xgb.DMatrix(test_dummies)\ntest_pred = model.predict(xg_check)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3fe85087-4e33-68b2-d738-bf43baa4e30e"},"outputs":[],"source":"\n# make predictions and save results\noutput = pd.DataFrame({'ID':test_id, 'y': test_pred})\noutput.to_csv('xgboost-categorical_sub.csv', index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"798341f5-eafe-60d8-9c88-61ca38457076"},"source":"Please upvote if you like it.!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}