{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d317244d-eb04-2370-5456-1fa627fe08e9"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport pandas as pd\nimport numpy as np\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline, Pipeline, _name_estimators\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import r2_score\nimport xgboost as xgb\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51baf0af-6257-8593-c1af-04b7cf85a4fd"},"outputs":[],"source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ny_train = train['y'].values\nid_test = test['ID']\nnum_train = len(train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"754dad7d-2ae7-9c13-3b9c-a39740a2f3b6"},"outputs":[],"source":"df_all = pd.concat([train, test])\ndf_all.drop(['y'], axis=1, inplace=True)\n\n# One-hot encoding of categorical/strings\ndf_all = pd.get_dummies(df_all, drop_first=True)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8ee6b53-3934-4f0c-f7b6-711c42d4d7d1"},"outputs":[],"source":"df_all.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86cee2a0-086c-5865-5f03-8861e4609d7e"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"427b7c42-f9ea-12b4-8f06-d63b400802ed"},"outputs":[],"source":"from sklearn.decomposition import PCA, FastICA\nn_comp = 10\n\n# PCA\npca = PCA(n_components=n_comp, random_state=42)\npca2_results_train = pca.fit_transform(df_all)\n#pca2_results_test = pca.transform(test)\n\n# ICA\nica = FastICA(n_components=n_comp, random_state=42)\nica2_results_train = ica.fit_transform(df_all)\n#ica2_results_test = ica.transform(test)\n\n# Append decomposition components to datasets\nfor i in range(1, n_comp+1):\n    df_all['pca_' + str(i)] = pca2_results_train[:,i-1]\n    #test['pca_' + str(i)] = pca2_results_test[:, i-1]\n    \n    df_all['ica_' + str(i)] = ica2_results_train[:,i-1]\n    #test['ica_' + str(i)] = ica2_results_test[:, i-1]\n    \n#y_train = train[\"y\"]\ny_mean = np.mean(y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0ed2d629-0e59-603f-32d6-1866c78a6ae5"},"outputs":[],"source":"train = df_all[:num_train]\ntest = df_all[num_train:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e0a251d-5168-d6e6-04a7-c21544f38dad"},"outputs":[],"source":"import xgboost as xgb\n\n# prepare dict of params for xgboost to run with\nxgb_params = {\n    'n_trees': 500, \n    'eta': 0.005,\n    'max_depth': 4,\n    'subsample': 0.95,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'base_score': y_mean, # base prediction = mean(target)\n    'silent': 1\n}\n\n# form DMatrices for Xgboost training\ndtrain = xgb.DMatrix(train, y_train)\ndtest = xgb.DMatrix(test)\n\n# xgboost, cross-validation\ncv_result = xgb.cv(xgb_params, \n                   dtrain, \n                   num_boost_round=2000, # increase to have better results (~700)\n                   early_stopping_rounds=50,\n                   verbose_eval=50, \n                   show_stdv=False\n                  )\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"954bc712-1b33-931f-84de-b3579820a82b"},"outputs":[],"source":"num_boost_rounds = len(cv_result)\nprint(num_boost_rounds)\n\n# train model\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47af628f-1012-a4cd-0520-7311334e39ef"},"outputs":[],"source":"# check f2-score (to get higher score - increase num_boost_round in previous cell)\nfrom sklearn.metrics import r2_score\n\n# now fixed, correct calculation\nprint(r2_score(dtrain.get_label(), model.predict(dtrain)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6529817f-c004-ecc9-7d0a-3aa7c7f81fcc"},"outputs":[],"source":"# make predictions and save results\ny_pred = model.predict(dtest)\noutput = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\noutput.to_csv('xgboost-dummy.csv'.format(xgb_params['max_depth']), index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}