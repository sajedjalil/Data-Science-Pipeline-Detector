{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":2},"nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython2","name":"python","file_extension":".py","version":"2.7.12"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":2,"cells":[{"metadata":{"_uuid":"89cc62c604aae65bc474f8f49fb36f52627c7d4b","_cell_guid":"2207021e-3f3e-487f-837a-40c01fffbfe2"},"source":"Would be really interested if people have ideas on how to improve this!","outputs":[],"cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"d93c05d6952802af17e43b4699419e5795e03f40","collapsed":false,"_cell_guid":"bf38a08a-6123-4c08-a2d6-14800aeeef75"},"source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import ShuffleSplit\nimport numpy as np\nimport tensorflow as tf\nimport tflearn","outputs":[],"cell_type":"code","execution_count":51},{"metadata":{"_uuid":"9592a5a67c09c37d8b1164e0f9a7a4be876dccf6","collapsed":false,"_cell_guid":"8863ea18-206d-4dbc-8aff-1152fabc9bd7"},"source":"train_df = pd.read_csv(\"../input/train.csv\")\ntrain_df.drop('ID', axis=1, inplace=True)\ntest_df = pd.read_csv(\"../input/test.csv\")\ntest_df.drop('ID', axis=1, inplace=True)\nprint(\"Train shape : \", train_df.shape)\nprint(\"Test shape : \", test_df.shape)","outputs":[],"cell_type":"code","execution_count":52},{"metadata":{"_uuid":"265ef6d16d444460dc71046bf6782611cd9bbc06","collapsed":false,"_cell_guid":"f15bb60c-1a67-432b-ac30-505df8fced63"},"source":"dtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = ['name','type']\ndtype_df.groupby('type').aggregate('count').reset_index()","outputs":[],"cell_type":"code","execution_count":53},{"metadata":{"_uuid":"1f208e4615482e38b243392d53c49898a53fc0df","collapsed":true,"_cell_guid":"9619c44a-e89a-457a-9847-7cffd4c04221"},"source":"def get_dummy_values(dummy_fields, base_df):\n    # This will create dummy values for all categorical features\n    # and remove the original features from the dataset\n    for each in dummy_fields:\n        dummies = pd.get_dummies(base_df[each], prefix=each, drop_first=False)\n        base_df = pd.concat([base_df, dummies], axis=1)\n    data = base_df.drop(dummy_fields, axis=1)\n    return data\n\ndef get_scaled_values(quant_features, data):\n    # Store scalings in a dictionary so we can convert back later\n    scaled_features = {}\n    for each in quant_features:\n        mean, std = data[each].mean(), data[each].std()\n        scaled_features[each] = [mean, std]\n        data.loc[:, each] = (data[each] - mean)/std\n    return scaled_features, data","outputs":[],"cell_type":"code","execution_count":54},{"metadata":{"_uuid":"2dcacd602b6c73c6291e3fd87e7ba18c3edcfdc9","collapsed":false,"_cell_guid":"c7db35b2-0417-46bb-bd04-49830364bf92"},"source":"# ID all the categoical and numerical features\ncat_vars = dtype_df.name[dtype_df.type=='object'].tolist()\nprint(cat_vars)\nnum_vars = dtype_df.name[dtype_df.type=='float64'].tolist()\nprint(num_vars)","outputs":[],"cell_type":"code","execution_count":55},{"metadata":{"_uuid":"f96f79284fd4d5eaca21bcceff5b0ee709539e9b","collapsed":false,"_cell_guid":"f58188f8-bafb-4929-8a47-238838321e8a"},"source":"# We want to create dummy variables for all categorical features\ndata = get_dummy_values(cat_vars, train_df)\n# We only need to scale the target variable. All other numerical features \n# are binary categories so no need to scale them\nscaled_features, data = get_scaled_values(num_vars, data)\n\n# just need to get the categorical variables for the test data\ntest_data = get_dummy_values(cat_vars, test_df)\n\nprint(data.shape, test_data.shape)\ndata.head()","outputs":[],"cell_type":"code","execution_count":56},{"metadata":{"_uuid":"021fbefa2dc2a356f93da09b73a31a577bf2f871","collapsed":false,"_cell_guid":"2c1a0b6b-6ea3-411e-a2f2-5a966d1df6e7"},"source":"# Create train and test sets. In this case we'll set the test size to 0 as we want to use all the data for training\nss = ShuffleSplit(n_splits=1, test_size=0.0)\ntarget_fields = ['y']\nfeatures, targets = data.drop(target_fields, axis=1), data[target_fields]\nfor train_index, test_index in ss.split(features, targets):\n    train_x, test_x = features.values[train_index], features.values[test_index]\n    train_y, test_y = targets.values[train_index], targets.values[test_index]","outputs":[],"cell_type":"code","execution_count":57},{"metadata":{"_uuid":"c4c0c915a1eda7740f3d62af851f435c4d5c5e5a","collapsed":false,"_cell_guid":"fb27f08c-e51e-4943-a6f1-faa3e7872f0d"},"source":"print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\nprint(\"Test shapes (x, y):\", test_x.shape, test_y.shape)","outputs":[],"cell_type":"code","execution_count":58},{"metadata":{"_uuid":"4518e174d6d110072916407635d16da8d38cb25c","collapsed":true,"_cell_guid":"949569dc-1afc-4240-8c87-e22977ab69a8"},"source":"# Define the neural network\ndef build_model():\n    # This resets all parameters and variables, leave this here\n    tf.reset_default_graph()\n    \n    # Inputs\n    net = tflearn.input_data([None, train_x.shape[1]])\n\n    # Hidden layer(s)\n    net = tflearn.fully_connected(net, 100, activation='ReLU')\n    net = tflearn.fully_connected(net, 100, activation='ReLU')\n    net = tflearn.fully_connected(net, 100, activation='ReLU')\n    \n    # Output layer and training model\n    net = tflearn.fully_connected(net, 1, activation='linear')\n    \n    # The regression layer is used in TFLearn to apply a regression (linear or logistic) to the provided input. \n    # It requires to specify a TensorFlow gradient descent optimizer 'optimizer' that will minimize the provided \n    # loss function 'loss' (which calculate the errors). A metric can also be provided, to evaluate the model performance.\n    net = tflearn.regression(net, optimizer='adam', learning_rate=0.001, loss='mean_square', metric='R2')\n    \n    model = tflearn.DNN(net, tensorboard_verbose=3)\n    return model","outputs":[],"cell_type":"code","execution_count":59},{"metadata":{"_uuid":"3747fcb66b679071f9b04f24beff8fae814d8f1c","collapsed":true,"_cell_guid":"05964d59-1bd1-4c8c-9cae-360dc2e9ea10"},"source":"model = build_model()","outputs":[],"cell_type":"code","execution_count":60},{"metadata":{"_uuid":"8ac6c27ec24594ffcc42e34027bf19e3d1c9b76c","collapsed":false,"_cell_guid":"486ed41c-5f83-4614-98b9-6ad23ad1e660"},"source":"# Training\nmodel.fit(train_x, train_y, validation_set=0.1, show_metric=True, batch_size=None, n_epoch=100)","outputs":[],"cell_type":"code","execution_count":61},{"metadata":{"_uuid":"f194ed90a8d259c4ae643fbf42ea143aeb8d04bf","collapsed":false,"_cell_guid":"8ba38052-b375-4aae-98fd-9c8a834ec576"},"source":"# There are differences between the trainging and test sets provided\ndlist = data.columns.tolist()\ntlist = test_data.columns.tolist()\n# This tells us which features are in training and not in test\nbuffer_list_one = list(set(dlist)-set(tlist))\n# Add these to test with 0 value\nbuffer_list_one.remove('y')\nfor each in buffer_list_one:\n    test_data[each] = 0","outputs":[],"cell_type":"code","execution_count":62},{"metadata":{"_uuid":"eb31246a0605272ead66b74db94eb9be12fe1b83","collapsed":false,"_cell_guid":"698e5a63-5ee9-4968-9d1f-b1df717077e8"},"source":"# This tells us which features are in test and not in training\nbuffer_list_two = list(set(tlist)-set(dlist))\n# drop these columns from the test data set\ntest_data.drop(buffer_list_two, axis=1, inplace=True)","outputs":[],"cell_type":"code","execution_count":63},{"metadata":{"_uuid":"9b6b950cf02166b58df0eff9b09c8cebb67ceb89","collapsed":false,"_cell_guid":"d36c7a07-9063-44b9-a9d1-0c3113dd67de"},"source":"test_data.shape","outputs":[],"cell_type":"code","execution_count":64},{"metadata":{"_uuid":"34ffd3cbe75156cb85ff0a46b721354375f782ee","collapsed":true,"_cell_guid":"2c20e0e5-7b4f-49b3-9aa9-e53930c65a20"},"source":"mean, std = scaled_features['y']\npredictions = np.array(model.predict(test_data))*std + mean","outputs":[],"cell_type":"code","execution_count":65},{"metadata":{"_uuid":"a0fc18b04b03b7c31d8b5c36e0084cfb783361fb","collapsed":false,"_cell_guid":"9ec7c622-37f1-437a-86c5-3d701b514e27"},"source":"predictions","outputs":[],"cell_type":"code","execution_count":66},{"metadata":{"_uuid":"3143605e6e72a052037280536ecb26c790d90508","collapsed":true,"_cell_guid":"f1dc3347-02f3-4dab-81c9-760fc67099f2"},"source":"submission_data = pd.read_csv('../input/test.csv')\nsubmission_data['y'] = np.absolute(predictions)\nsubmission_data.to_csv('submission.csv',columns=['ID','y'],header=['ID','y'],index=False)","outputs":[],"cell_type":"code","execution_count":67},{"metadata":{"_uuid":"cacbe5375f4c50aecb5f44014b5db94f7d237626","collapsed":true,"_cell_guid":"db34efca-6c01-441c-9604-577edfe70b74"},"source":"","outputs":[],"cell_type":"code","execution_count":null}]}