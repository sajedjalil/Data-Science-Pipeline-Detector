{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"file_extension":".py","mimetype":"text/x-python","version":"3.6.1","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":0,"cells":[{"metadata":{"_uuid":"c52c10c6655a3343e151d3908cb484604d32e7b1","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"So, I decided to determine chance for row to be outlier ( i.e. label greater than some high percentile ). In order to do that, I've built classifier based on naive Bayes principle, stacked on feature selector - logistic regression equipped with L1 penalty"},{"metadata":{"_uuid":"bda1d984e915d3754b928711337c2b8e6d77b1bc","_execution_state":"idle"},"outputs":[],"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ny = train.pop('y')\nID = train.pop('ID')","execution_count":1},{"metadata":{"_uuid":"4b4fce846894163f8e4a19578a22fd65768f2bbb","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.linear_model import RandomizedLogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.base import TransformerMixin\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.pipeline import make_pipeline, make_union"},{"metadata":{"_uuid":"911432118cea926d44fda4f1a84a9866d91ff351","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')"},{"metadata":{"_uuid":"0a97ba55fadc3d4cc2d9ce75157743a1878ee68a","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix"},{"metadata":{"_uuid":"118e3cc8c0dfc4231e8666567d2ec6e3341a3af0","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"ints = train.select_dtypes(['int']).columns.tolist()\nobjs = train.select_dtypes(['object']).columns.tolist()\n\nfor col in ints:\n    if np.var(train[col])==0:\n        train.pop(col)\n        ints.remove(col)\n"},{"metadata":{"_uuid":"599604d0076bd172e5dfc737e23463f910f3245a","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"outs = (y>120).as_matrix().astype(int)\n\n#let's define outliers as labels greater than 120"},{"metadata":{"_uuid":"bd19e216b2aed79c4456b97d3f9697c3d96e4cb9","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"def evaluate(y_true, pred, thresh=.5):\n    print('precision', precision_score(y_true, pred[:, 1]>thresh))\n    print('recall', recall_score(y_true, pred[:, 1]>thresh))\n    print('roc', roc_auc_score(y_true, pred[:, 1]))\n    print('f1', f1_score(y_true, pred[:, 1]>thresh))"},{"metadata":{"_uuid":"069de2e33ce5c7fdbed09f6515f3b0ab3394520f","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"cv_preds = cross_val_predict(BernoulliNB(), train[ints], outs, cv=10, method='predict_proba')"},{"metadata":{"_uuid":"c58abec24b1187597330a0b5426cf4e38917bcce","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"evaluate(outs, cv_preds)"},{"metadata":{"_uuid":"f0d96767479fe17c4d53642df834bec40adad6e6","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"Okay, that's quite bad. Let's include some feature selection pipeline"},{"metadata":{"_uuid":"678fd5579829a22bbda3233f884d19d6feae35fe","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"pip = make_pipeline(RandomizedLogisticRegression(C=5), BernoulliNB())\n\nselection_preds = cross_val_predict(pip, train[ints], outs, cv=10, method='predict_proba')\nevaluate(outs, cv_preds)"},{"metadata":{"_uuid":"8a0abcf140b93e94e36106a8e0f042e956cbe370","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"This takes quite long, so I've settled on C=5 ( intuition, possibly flawed ) and did not test any other hyperparameteres. We see that feature selection improves ROC, but hits f1. "},{"metadata":{"_uuid":"3237a4dec588bc8db9f5f1434a791184bc220a0e","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"Nonetheless, it's now time to perform some analysis of non-binary features. I will build transform that will decide whether to decode feature as promising or not, based on proportion of outliers associated with level of feature. "},{"metadata":{"_uuid":"3304144d720286f3faf450ebb5b486e3d4ac7dda","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"class OutlierThresholder(TransformerMixin):\n    \n    def __init__(self, thresh=1.5):\n        self.th = thresh\n    \n    def fit(self, X, y):\n        \n        X = np.asarray(X)\n        maps = []\n        for col in range(X.shape[1]):\n            \n            val = X[:, col].copy()\n            useful = []\n            not_useful = []\n            for u in np.unique(X[:, col]):\n                \n                o, no = y[val==u].mean(), y[val!=u].mean()\n                q = o/no if no else 0\n                \n                if q > self.th:\n                    useful.append(u)\n                else:\n                    not_useful.append(u)\n                    \n            col_map = dict(zip(useful+not_useful, [0]*len(useful)+[1]*len(not_useful)))\n            maps.append(col_map)\n            \n        self.maps = maps\n        return self\n        \n    def transform(self, X, y=None):\n        \n        X = X.copy()\n        X = np.asarray(X)\n        for col in range(X.shape[1]):\n            \n            X[:, col] = [self.maps[col][x] if x in self.maps[col] else 1 for x in X[:, col]]\n            \n        return X"},{"metadata":{"_uuid":"0ecc45f96425d044a9d446e850c18f4437aa91c7","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"def sel_obj(X):\n    return X[:, :8]\n\ndef sel_ints(X):\n    return X[:, 8:]"},{"metadata":{"_uuid":"0bae03907bcf670d562468e7d45fe4f1a262e768","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"pip = make_pipeline(OutlierThresholder(), BernoulliNB())\n\noutlier_obj_preds = cross_val_predict(pip, train[objs], outs, method='predict_proba', cv=10)\nevaluate(outs, outlier_obj_preds)"},{"metadata":{"_uuid":"6e1c26c5f33242b2df75266c10072af8a73bf6c7","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"Very, very bad. Let's include binary features"},{"metadata":{"_uuid":"b46cab8ec229e70c09dead9141e9a0f81b690bfe","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"un = make_union(make_pipeline(FunctionTransformer(sel_obj), OutlierThresholder()), FunctionTransformer(sel_ints))\n\nfor col in objs:\n    train[col] = pd.factorize(train[col])[0]\n\nbinary_with_obj = make_pipeline(un, BernoulliNB())"},{"metadata":{"_uuid":"ebaffb4b2521a168607c32710101ec929432c644","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"full_preds = cross_val_predict(binary_with_obj, train, outs, method='predict_proba', cv=10)"},{"metadata":{"_uuid":"57277db7ecffce8ef7d95b551e23a7725f00290d","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"evaluate(outs, full_preds)"},{"metadata":{"_uuid":"fd4b0b789360adf7e14807a75d6667a8b973235b","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"comparable with model based solely on binary features. not worth the hassle"},{"metadata":{"_uuid":"b3236493f9138af84b1489a8a50cabd3358e9d2f","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"upd_binary_with_obj = make_pipeline(un, RandomizedLogisticRegression(C=5), BernoulliNB())\n\nfull_upd_preds = cross_val_predict(upd_binary_with_obj, train, outs, method='predict_proba', cv=10)\nevaluate(outs, full_upd_preds)"},{"metadata":{"_uuid":"c2d8ff4e4eb176e722b9634c99ad688fcef6c327","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"Another bad score. Before I include these in final model, I would like to plot probability curves. Intuitively, we would like for our model to be n% right for every sample it assigns n% of confidence. Such curve will be called \"properly calibrated probability\". In case of such an event, we should see straight line of equation y=x on our plots"},{"metadata":{"_uuid":"bf38e418bc87ca5c5737f260f31bceff7996d2db","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.calibration import calibration_curve"},{"metadata":{"_uuid":"57a1b37769c0e81f921a02f84e68fdee449aea07","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"plt.plot(*calibration_curve(outs, full_upd_preds[:, 1], n_bins=5)[::-1])\nplt.xlabel('mean predicted probability')\nplt.ylabel('percent of correctly assigned labels')\nplt.show()"},{"metadata":{"_uuid":"8004e1a689db9dcb06255b9903759e20ef788fbf","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"But we see that assumption does not hold. Let's check earlier models"},{"metadata":{"_uuid":"d8aafeccb60819bb1e68ebd2b0891e4b805999ec","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"plt.plot(*calibration_curve(outs, outlier_obj_preds[:, 1], n_bins=5)[::-1])\nplt.xlabel('mean predicted probability')\nplt.ylabel('percent of correctly assigned labels')\nplt.show()"},{"metadata":{"_uuid":"09cb618820870a960f4ee14c6e40658ed6c860a2","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"plt.plot(*calibration_curve(outs, cv_preds[:, 1], n_bins=5)[::-1])\nplt.xlabel('mean predicted probability')\nplt.ylabel('percent of correctly assigned labels')\nplt.show()"},{"metadata":{"_uuid":"bc7fe579f68438cddaeaebe9340732a8e8e8be02","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"plt.plot(*calibration_curve(outs, selection_preds[:, 1], n_bins=5)[::-1])\nplt.xlabel('mean predicted probability')\nplt.ylabel('percent of correctly assigned labels')\nplt.show()"},{"metadata":{"_uuid":"130ba312bf24d4e86a0086771c0fc4b751fbddba","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"Let's build some xgboost models"},{"metadata":{"_uuid":"9722619196fe45414a3368a36d078cfe39be1d73","_execution_state":"busy","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom functools import partial\n\nxgb_params = dict(max_depth=3, learning_rate=0.05, n_estimators=100, subsample=.7, colsample_bytree=.7)\nxgbr = XGBRegressor(**xgb_params)\nmy_cv = partial(cross_val_score, scoring='r2', cv=10)\ncv_ordinary = my_cv(xgbr, train, y)\ncv_add = my_cv(xgbr, np.hstack([train, cv_preds[:, 1].reshape(-1, 1)]), y)"},{"metadata":{"_uuid":"640f0626b53d1c926bc3ad7e0453b0d0d6a8591b","_execution_state":"busy","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"code","source":"cv_ordinary.mean(), cv_add.mean()"},{"metadata":{"_uuid":"1244b5bd1abd255e00dfc8a48e368251a9a72610","_execution_state":"idle","collapsed":false},"execution_count":null,"outputs":[],"cell_type":"markdown","source":"Doesn't look very helpful. On the other hand, I didn't put a lot of effort into choosing hyperparameters.\n\n( for some reason I two cells above won't run. On my computer results are ~ 0.57 with second one being slightly worse )"}]}