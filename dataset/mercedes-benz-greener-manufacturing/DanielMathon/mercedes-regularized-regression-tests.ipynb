{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"_is_fork":false,"language_info":{"name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","file_extension":".py"},"_change_revision":0},"nbformat_minor":0,"cells":[{"metadata":{"_uuid":"8d8bcfdaf0c2104442af8cb7458fc7aade4a7d83","_cell_guid":"d0a037a6-6e20-ab59-2455-c6e28ae3d056"},"execution_count":null,"source":"# Different regularized regression tests\n#### Some functions and examples used are courtesy of Datacamp (www.datacamp.com)","outputs":[],"cell_type":"markdown"},{"metadata":{"trusted":false,"_uuid":"3eb4a5eee649555efc61d8fd77da2f9318025d42","_cell_guid":"cf98585a-c141-0f8b-ba57-53b9c1ca280f"},"execution_count":null,"source":"# Importing main packages and settings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"cdf16df1ee6fc832ccbb58daef2a5a4dbf19c814","_cell_guid":"6f89960e-22b1-4d20-c90a-d1c1cb4fa08c"},"execution_count":null,"source":"# Import the relevant sklearn packages\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.feature_selection import SelectFromModel, VarianceThreshold, SelectKBest, f_regression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV, LarsCV, LassoLarsCV\nfrom sklearn.linear_model import MultiTaskElasticNetCV, MultiTaskLassoCV, OrthogonalMatchingPursuitCV\nfrom sklearn.metrics import mean_squared_error","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"b371c750c97e98942c1bc3f3fb96e28bf7398025","_cell_guid":"d9ca82b5-c8e4-b47d-2019-702e543e7ed9"},"execution_count":null,"source":"# Function for plotting the scores for different alphas used in Ridge regression\ndef display_plot(cv_scores, cv_scores_std):\n    fig = plt.figure()\n    ax = fig.add_subplot(1,1,1)\n    ax.plot(alpha_space, cv_scores)\n\n    std_error = cv_scores_std / np.sqrt(10)\n\n    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n    ax.set_ylabel('CV Score +/- Std Error')\n    ax.set_xlabel('Alpha')\n    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n    ax.set_xscale('log')\n    plt.show()","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"34995653b70a20f6bf7d57dff1cf659ab8a4b1ec","_cell_guid":"63babe32-7650-0ab2-ccaa-4c7ba2655366"},"execution_count":null,"source":"# Loading the training dataset\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"46185cabcb424d1b3b65cc9c5a3374e8ada9c423","_cell_guid":"7aa8abd6-5992-a0ed-79c6-f78fe3cd0cfc"},"execution_count":null,"source":"# turning object features into dummy variables\ndf_train_dummies = pd.get_dummies(df_train, drop_first=True)\ndf_test_dummies = pd.get_dummies(df_test, drop_first=True)\n\n# dropping ID and the target variable\ndf_train_dummies = df_train_dummies.drop(['ID','y'], axis=1)\ndf_test_dummies = df_test_dummies.drop('ID', axis=1)\n\nprint(\"Clean Train DataFrame With Dummy Variables: {}\".format(df_train_dummies.shape))\nprint(\"Clean Test DataFrame With Dummy Variables: {}\".format(df_test_dummies.shape))","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"3c5f6a65b672d8060d47d9561c7fff047291cb6d","_cell_guid":"213c956f-57a7-d2b9-ba1d-3a78f1c16423"},"execution_count":null,"source":"# concatenate to only include columns in both data sets\n# the number should be based on the number of columns. Original is 30471. Now set to 15471 after outlier handling etc.\ndf_temp = pd.concat([df_train_dummies, df_test_dummies], join='inner')\ndf_temp_train = df_temp[:len(df_train.index)]\ndf_temp_test = df_temp[len(df_train.index):]\n\n# check shapes of combined df and split out again\nprint(df_temp.shape)\nprint(df_temp_train.shape)\nprint(df_temp_test.shape)","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"8eec549641b9144871e6238c3d740d19d68298ea","_cell_guid":"f7f3b97d-ca55-a9d9-d65e-6c51e56a826b"},"execution_count":null,"source":"# defining X and y\nX = df_temp_train\ntest_X = df_temp_test\ny = df_train['y']","outputs":[],"cell_type":"code"},{"metadata":{"_uuid":"1bd54c7b8d961bcca6d0127005fe64a1dc9dd3f4","_cell_guid":"3a96e212-eb9a-03fe-82ce-35f3a4934b2c"},"execution_count":null,"source":"# Determining best alpha for Ridge regression","outputs":[],"cell_type":"markdown"},{"metadata":{"trusted":false,"_uuid":"92333cf23e1e8639dbc2530df520665b91258add","_cell_guid":"6fd39e93-a2d1-0b3c-d639-993c88b75ed3"},"execution_count":null,"source":"# Setup the array of alphas and lists to store scores\nalpha_space = np.logspace(-4, 0, 20)\nridge_scores = []\nridge_scores_std = []\n\n# Create a ridge regressor: ridge\nridge = Ridge(normalize=True)\n\n# Compute scores over range of alphas\nfor alpha in alpha_space:\n\n    # Specify the alpha value to use: ridge.alpha\n    ridge.alpha = alpha\n    \n    # Perform 10-fold CV: ridge_cv_scores\n    ridge_cv_scores = cross_val_score(ridge, X, y, cv=5)\n    \n    # Append the mean of ridge_cv_scores to ridge_scores\n    ridge_scores.append(np.mean(ridge_cv_scores))\n    \n    # Append the std of ridge_cv_scores to ridge_scores_std\n    ridge_scores_std.append(np.std(ridge_cv_scores))\n\n# Display the plot\ndisplay_plot(ridge_scores, ridge_scores_std)","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"17dd41312d2da199f7f02b56c847ed299e0003d4","_cell_guid":"7dab635b-edf2-b706-9732-22b4bab396b3"},"execution_count":null,"source":"ridgescores = pd.DataFrame({'alpha':alpha_space, 'score':ridge_scores})\nridgescores","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"1b43e46966e00d133902d6b19c484a4d3dfee9ad","_cell_guid":"9f2e72a2-13e0-34f3-3633-9cd8e49adca9"},"execution_count":null,"source":"# Setup the hyperparameter grid\nalpha_space = np.logspace(-4, 0, 20)\nparam_grid = {'alpha': alpha_space}\n\n# Instantiate a logistic regression classifier: ridge\nridge = Ridge()\n\n# Instantiate the GridSearchCV object: ridge_cv\nridge_cv = GridSearchCV(ridge, param_grid, cv=5)\n\n# Fit it to the data\nridge_cv.fit(X, y)\n\n# Print the tuned parameters and score\nprint(\"Tuned Logistic Regression Parameters: {}\".format(ridge_cv.best_params_)) \nprint(\"Best score is {}\".format(ridge_cv.best_score_))","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"82ce06b61a4f4a6a2b86c2cc38bc2eb039fe304b","_cell_guid":"fc0fb45e-54cb-71eb-b7cf-dedd1cd15a61"},"execution_count":null,"source":"# instantiating\nrcv = RidgeCV()\n\n# setting up steps for the pipeline\nsteps = [('RidgeCV', rcv)]\n\n# instantiating the pipeline\npipe = Pipeline(steps)\n\n# creating train and test sets using train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# fitting and predicting\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\n\n# Compute and print R^2 and RMSE\nprint(\"R^2: {}\".format(pipe.score(X_test, y_test)))\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean Squared Error: {}\".format(mse))","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"22f05582e5b1ad1b72e8d9366f70c2d5a312424a","_cell_guid":"a97de349-7bea-193c-4bf3-db87cb3d38ea"},"execution_count":null,"source":"'''\n# Setup the hyperparameter grid\nalpha_space = np.logspace(-4, 0, 5)\nl1_l2_space = np.linspace(0,1,11)\n\nparam_grid = {'alpha': alpha_space,\n             'l1_ratio': l1_l2_space}\n\n# Instantiate a logistic regression classifier: elas\nelas = ElasticNet()\n\n# Instantiate the GridSearchCV object: elas_cv\nelas_cv = GridSearchCV(elas, param_grid, cv=5)\n\n# Fit it to the data\nelas_cv.fit(X, y)\n\n# Print the tuned parameters and score\nprint(\"Tuned Logistic Regression Parameters: {}\".format(elas_cv.best_params_)) \nprint(\"Best score is {}\".format(elas_cv.best_score_))\n'''","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"10b1910ff8494494bc34fd8140eba154f145d749","_cell_guid":"d4a45cee-020d-2f65-a9e5-7f0bf0ec87c3"},"execution_count":null,"source":"# instantiating different regressors\nrcv = RidgeCV()\nlcv = LassoCV()\nllrcv = LassoLarsCV()\necv = ElasticNetCV()\nompcv = OrthogonalMatchingPursuitCV()","outputs":[],"cell_type":"code"},{"metadata":{"trusted":false,"_uuid":"8863a8e6c736afaf65072ca87d92c3e70f8df401","_cell_guid":"11904e90-290c-26f2-e3a8-04a2a7ba6fa5"},"execution_count":null,"source":"# bad for but just for now:\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Compute 10-fold cross-validation scores: cv_scores\ncv_scores_rcv = cross_val_score(rcv, X, y, cv=10)\ncv_scores_lcv = cross_val_score(lcv, X, y, cv=10)\ncv_scores_llrcv = cross_val_score(llrcv, X, y, cv=10)\ncv_scores_ecv = cross_val_score(ecv, X, y, cv=10)\ncv_scores_ompcv = cross_val_score(ompcv, X, y, cv=10)\n\n# Print the 10-fold cross-validation scores\nprint(cv_scores_rcv)\nprint(cv_scores_lcv)\nprint(cv_scores_llrcv)\nprint(cv_scores_ecv)\nprint(cv_scores_ompcv)\n\nprint(\"Average 10-Fold RidgeCV CV Score: {}\".format(np.mean(cv_scores_rcv)))\nprint(\"Average 10-Fold LassoCV CV Score: {}\".format(np.mean(cv_scores_lcv)))\nprint(\"Average 10-Fold LassoLarsCV CV Score: {}\".format(np.mean(cv_scores_llrcv)))\nprint(\"Average 10-Fold ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_ecv)))\nprint(\"Average 10-Fold OrthogonalMatchingPursuitCV CV Score: {}\".format(np.mean(cv_scores_ompcv)))","outputs":[],"cell_type":"code"}],"nbformat":4}