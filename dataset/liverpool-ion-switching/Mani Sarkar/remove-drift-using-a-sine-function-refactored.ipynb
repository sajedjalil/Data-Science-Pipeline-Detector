{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Full credits to the author [Eun Ho Lee](https://www.kaggle.com/eunholee) of the [original notebook](https://www.kaggle.com/eunholee/remove-drift-using-a-sine-function).\n\n#### I have just reorganised and refactored the code for my curiosity and learnings. Added console logs, and re-wrote datastructure to understand how the splits and batching is occuring\n\n### Find other such refactored notebooks [here](https://www.kaggle.com/c/liverpool-ion-switching/discussion/153653).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this notebook, I'll share my approach to finding synthetic drift function. It is no secret that the drift has been artificially added. In this competition's paper [here][1], you can find the description of the data like below:\n> *\"In some datasets additional drift was applied to the final data with MATLAB\"*\n\nThere's an excellent explanation for the drift. Please check Chris' explanation: [What is Drift?][2] \n\n\n\n[1]:https://www.nature.com/articles/s42003-019-0729-3\n[2]:https://www.kaggle.com/c/liverpool-ion-switching/discussion/133874\n[3]:https://www.kaggle.com/friedchips/clean-removal-of-data-drift","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Two types of drift\n\nAs you can see in the blow, there are two types of drift in our dataset, linear and parabolic drift.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.optimize import curve_fit\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prettify plots\nsns.set_palette(sns.color_palette(\"muted\"))\nsns.set_style(\"ticks\")\n\n\n# prettify plots\nplt.rcParams['figure.figsize'] = [20.0, 5.0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf_train = pd.read_csv(\"../input/liverpool-ion-switching/train.csv\")\ndf_test  = pd.read_csv(\"../input/liverpool-ion-switching/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Batching","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The below datastrutures give a better idea of how the splits happened across the training and test data-frames. Easy to visualise when we can see the range of values. The `make_batches()` is also easier to read and change.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"training_batch_size = 500_000\ntraining_batch_range = [\n    [0, 500000],\n    [500000, 1000000],\n    [1000000, 1500000],\n    [1500000, 2000000],\n    [2000000, 2500000],\n    [2500000, 3000000],\n    [3000000, 3500000],\n    [3500000, 4000000],\n    [4000000, 4500000],\n    [4500000, 5000000]\n]\n\ntest_batch_size = 100_000\ntest_batch_range = [\n    [0, 100000],\n    [100000, 200000],\n    [200000, 300000],\n    [300000, 400000],\n    [400000, 500000],\n    [500000, 600000],\n    [600000, 700000],\n    [700000, 800000],\n    [800000, 900000],\n    [900000, 1000000],\n    [1000000, 1500000], # 11th batch (500_000)\n    [1500000, 2000000]  # 12th batches (500_000)\n]\n\ndef make_batches(df, batch_range):\n    batches = []\n    for start_batch, end_batch in batch_range:\n        print(f\"[start_batch: {start_batch}, end_batch: {end_batch}],\")\n        batches.append(df[start_batch: end_batch])\n        \n    return batches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_batched = make_batches(df_train, training_batch_range)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_batched = make_batches(df_test, test_batch_range)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"def plot_all(name, dataset, sublplot_index, start, end, increment):\n    plt.figure(figsize=(25, 5))\n    plt.subplot(sublplot_index)\n    plt.title(name)\n    plt.ylabel(\"Signal\")\n    plt.xticks(np.arange(start, end, increment))\n    for x in dataset:\n        plt.plot(x['time'], x['signal'], linewidth=.1)\n    plt.grid()\n\nplot_all(\"Train Original\",df_train_batched, 211, 0, 501, 50)\nplot_all(\"Test Original\", df_test_batched, 212, 500, 701, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear drift (code)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ---- Linear drift \n\nlinear_train_idx = [1]\nlinear_test_idx = [0, 1, 4, 6, 7, 8]\n\n\ndef poly1(x, a, b):\n    return a * (x - b)\n\n\ndef linear_drift_fit(x, y):\n    popt, _ = curve_fit(poly1, x, y)\n    print(\"Linear drift, popt:\", popt)\n    return popt\n\n\ndef linear_drift(x, x0):\n    return 0.3 * (x - x0)\n\n\ndef my_sin(x, A, ph, d):\n    frequency = 0.01\n    omega = 2 * np.pi * frequency\n    return A * np.sin(omega * x + ph) + d\n\n\ndef remove_linear_drift(linear_idx, data, time_column_name, signal_column_name, batch_start, batch_end):\n    for idx in linear_idx:\n        data[idx].loc[data[idx].index[batch_start: batch_end], signal_column_name] = \\\n            data[idx][signal_column_name][batch_start: batch_end].values - linear_drift(\n            data[idx][time_column_name][batch_start: batch_end].values, data[idx][time_column_name][0:1].values)\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear drift\n\n~~It's easy to~~ figure out what linear drift function looks like.\n\n(**Update:** It turns out it's not easy...! Linear drift is not actually linear. Check here[1]. )\n\n[1]:https://www.kaggle.com/c/liverpool-ion-switching/discussion/137537","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 4))\nplt.subplot(\"171\")\nplt.title(\"Train 1 (part)\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.plot(df_train_batched[1]['time'][0:100000], df_train_batched[1]['signal'][0:100000], linewidth=.1)\nplt.grid()\nplt.ylim([np.min(df_train_batched[1]['signal'][0:100000]), np.min(df_train_batched[1]['signal'][0:100000]) + 15])\nfor n, idx in enumerate(linear_test_idx):\n    plt.subplot(\"17\" + str(n + 2))\n    plt.title(\"Test \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.ylim([np.min(df_test_batched[idx]['signal']), np.min(df_test_batched[idx]['signal']) + 15])\n    plt.plot(df_test_batched[idx]['time'], df_test_batched[idx]['signal'], linewidth=.1)\n    plt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_params = []\ntrain_data = df_test_batched[linear_train_idx[0]][0:100000]\nlinear_params.append(linear_drift_fit(train_data['time'], train_data['signal']))\nfor idx in linear_test_idx:\n    linear_params.append(linear_drift_fit(df_test_batched[idx]['time'], df_test_batched[idx]['signal']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 4))\nplt.subplot(\"171\")\nplt.title(\"Train 1 (part)\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.plot(df_train_batched[1]['time'][0:100000], df_train_batched[1]['signal'][0:100000], linewidth=.1)\nplt.plot(df_train_batched[1]['time'][0:100000], poly1(df_train_batched[1]['time'][0:100000], *linear_params[0]), 'y')\nplt.grid()\nplt.ylim([np.min(df_train_batched[1]['signal'][0:100000]), np.min(df_train_batched[1]['signal'][0:100000]) + 15])\nfor n, idx in enumerate(linear_test_idx):\n    plt.subplot(\"17\" + str(n + 2))\n    plt.title(\"Test \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.ylim([np.min(df_test_batched[idx]['signal']), np.min(df_test_batched[idx]['signal']) + 15])\n    plt.plot(df_test_batched[idx]['time'], df_test_batched[idx]['signal'], linewidth=.1)\n    plt.plot(df_test_batched[idx]['time'], poly1(df_test_batched[idx]['time'], *linear_params[1 + n]), 'y')\n    plt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is ~~almost certain~~ that all data have the same slope => **0.3**. Let's remove it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_linear_drift_removed = remove_linear_drift([1], df_train_batched, 'time', 'signal', 0, test_batch_size)\ndf_test_linear_drift_removed = remove_linear_drift(linear_test_idx, df_test_batched, 'time', 'signal', 0, test_batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_all(\"Train - Linear Drift Removed\", df_train_linear_drift_removed, \"211\", 0, 501, 50)\nplot_all(\"Test - Linear Drift Removed\", df_test_linear_drift_removed, \"212\", 500, 701, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parabolic drift (code)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# --- Parabolic drift\n\nparabola_train_idx = [6, 7, 8, 9]\nparabola_train_time = [0, 1, 0, 1]\nparabola_test_idx = [10]\n\ndef parabolic_drift_fit(x, y):\n    frequency = 0.01\n    omega = 2 * np.pi * frequency\n    M = np.array([[np.sin(omega * t), np.cos(omega * t), 1] for t in x])\n    y = np.array(y).reshape(len(y), 1)\n\n    (theta, _, _, _) = np.linalg.lstsq(M, y)\n\n    A = np.sqrt(theta[0, 0] ** 2 + theta[1, 0] ** 2)\n    ph = math.atan2(theta[1, 0], theta[0, 0])\n    d = theta[2, 0]\n\n    popt = [A, ph, d]\n    print(\"Parabolic drift, popt\", popt)\n    return popt\n\n\ndef parabolic_drift(x, t=0):\n    f = 0.01\n    omega = 2 * np.pi * f\n    return 5 * np.sin(omega * x + t * np.pi)\n\n\ndef remove_parabolic_drift(parabola_idx, parabola_time, data, time_column_name, signal_column_name, batch_start, batch_end):\n    for idx, ctr in zip(parabola_idx, range(len(parabola_idx))):\n        target_index = data[idx].index[batch_start:batch_end]\n        target_values = data[idx][time_column_name][batch_start:batch_end].values\n        data[idx].loc[target_index, signal_column_name] = \\\n            data[idx][signal_column_name][batch_start:batch_end].values - \\\n            parabolic_drift(target_values, parabola_time[ctr])\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Parabolic drift\n\nThis kind of drift has more candidates. It could be a polynomial, a trigonometric, or something else. In this notebook, I'll assume it as a **sine function.**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_parabolic_drift(dataframe, name, subplot, parabola_indices):\n    for n, idx in enumerate(parabola_indices):\n        plt.subplot(str(subplot + n + 1))\n        plt.title(name.strip() + \" \" + str(idx))\n        plt.ylabel(\"Signal\", fontsize=8)\n        plt.plot(dataframe[idx]['time'], dataframe[idx]['signal'], linewidth=.1)\n        plt.grid()\n        plt.ylim([np.min(dataframe[idx]['signal']), np.min(dataframe[idx]['signal']) + 18])\n\nplt.figure(figsize=(30, 4))\nplot_parabolic_drift(df_train_linear_drift_removed, \"Train\", 150, parabola_train_idx)\nplot_parabolic_drift(df_test_linear_drift_removed, \"Test\", 154, parabola_test_idx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to fit a sine function\n\n$$\n\\hat{y} = A \\sin (\\omega x + \\varphi) + \\delta\n$$\n\nBecause each batch has the same length (50s), omega should be \\\\( \\omega = \\frac{2\\pi}{50 \\times 2} \\\\).\nBut it's not easy to find \\\\(A\\\\) and \\\\(\\varphi\\\\) with this form. \n\nLet's apply harmonic addition to the equation above.\n\n$$\n\\begin{align}\n\\hat{y} &= A \\sin (\\omega x + \\varphi) + \\delta \\\\\n&= A \\sin (\\omega x) \\cos (\\varphi) + A \\cos (\\omega x) \\sin (\\varphi) + \\delta \\\\\n&= A \\cos (\\varphi) \\sin (\\omega x) + A \\sin (\\varphi) \\cos (\\omega x) + \\delta \n\\end{align}\n$$\n\nNow we can represent it as a linear system.\n\n$$\n\\begin{bmatrix}\n\\sin(\\omega x_1) & \\cos(\\omega x_1) & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\sin(\\omega x_N) & \\cos(\\omega x_N) & 1\n\\end{bmatrix}\n\\begin{bmatrix}\nA\\cos(\\varphi) \\\\\nA\\sin(\\varphi) \\\\\n\\delta\n\\end{bmatrix} = \n\\begin{bmatrix}\ny_1 \\\\ \\vdots \\\\ y_N\n\\end{bmatrix}\n$$\n\nwhere \\\\(\\mathbf{x} = (x_1, \\cdots, x_N) \\\\) is  ```df['time']``` and \\\\(\\mathbf{y} = (y_1, \\cdots, y_N) \\\\) is ```df['signal']``` with \\\\(N=500000 \\\\)\n\nor simply,\n$$\n\\mathbf{M}\\mathbf{\\theta} = \\mathbf{y}\n$$\n\n\nWe can find \\\\(\\mathbf{\\theta} \\\\) that minimizes the squared Euclidean 2-norm.\nThen, we can find our target parameters \\\\( A \\\\) and \\\\( \\varphi \\\\) from \\\\( \\mathbf{\\theta} = (\\theta_1, \\theta_2, \\theta_3) \\\\)\n\n$$\nA = \\sqrt{\\theta_1^2 + \\theta_2^2} \\\\\n\\varphi = \\arctan(\\frac{\\theta_2}{\\theta_1})\n$$","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parabola_params = []\nfor idx in parabola_train_idx:\n    data = df_train_linear_drift_removed[idx]\n    parabola_params.append(parabolic_drift_fit(data['time'], data['signal']))\ndata = df_test_linear_drift_removed[parabola_test_idx[0]]\nparabola_params.append(parabolic_drift_fit(data['time'], data['signal']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 4))\nfor n, idx in enumerate(parabola_train_idx):\n    plt.subplot(\"15\" + str(n + 1))\n    plt.title(\"Train \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.plot(df_train_linear_drift_removed[idx]['time'], df_train_linear_drift_removed[idx]['signal'], linewidth=.1)\n    plt.plot(df_train_linear_drift_removed[idx]['time'], my_sin(df_train_linear_drift_removed[idx]['time'], *parabola_params[n]), 'y')\n    plt.grid()\n    plt.ylim([np.min(df_train_linear_drift_removed[idx]['signal']), np.min(df_train_linear_drift_removed[idx]['signal']) + 18])\nplt.subplot(\"155\")\nplt.title(\"Test 10\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.ylim([np.min(df_test_linear_drift_removed[10]['signal']), np.min(df_test_linear_drift_removed[10]['signal']) + 18])\nplt.plot(df_test_linear_drift_removed[10]['time'], df_test_linear_drift_removed[10]['signal'], linewidth=.1)\nplt.plot(df_test_linear_drift_removed[10]['time'], my_sin(df_test_linear_drift_removed[10]['time'], *parabola_params[-1]), 'y')\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The optimum A is 5 for all batches and the optimum phase is 0 or \\\\(\\pi\\\\) \n\n$$\n\\begin{align}\nA_{opt} &= 5 \\\\\n\\varphi_{opt} &= \n\\begin{cases}\n0 & \\text{ if train 6, train 8, test 10} \\\\ \n\\pi & \\text{ if train 7, train 9} \n\\end{cases}\n\\end{align}\n$$\n\nLet's remove this drift.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_parabolic_drift_removed = remove_parabolic_drift(parabola_train_idx, parabola_train_time, df_train_linear_drift_removed, 'time', 'signal', 0, training_batch_size)\ndf_test_parabolic_drift_removed = remove_parabolic_drift([10], [0], df_test_linear_drift_removed, 'time', 'signal', 0, training_batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_all(\"Train - Without Drift (linear or parabolic)\", df_train_parabolic_drift_removed, \"211\", 0, 501, 50)\nplot_all(\"Test - Without Drift (linear or parabolic)\", df_test_parabolic_drift_removed, \"212\", 500, 701, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparison of distributions\n\nLet's see if the distribution of a clean version matches the distribution of existing data in the same model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_dist(data, labels, m):\n    plt.title(\"Signal Distribution Model \" + str(m))\n    for i, x in enumerate(data):\n        x = x['signal']\n        sns.distplot(x, label=labels[i], kde=True, bins=np.arange(np.min(x), np.max(x), 0.01))\n#         sns.distplot(x, label=labels[i], kde=True)\n    plt.xlabel(\"signal value\")\n    plt.ylabel(\"frequency\")\n    plt.legend(loc=\"best\")    \n    \n\nM = [[df_train_parabolic_drift_removed[0], df_train_parabolic_drift_removed[1], df_test_parabolic_drift_removed[0], df_test_parabolic_drift_removed[3], df_test_parabolic_drift_removed[8], df_test_parabolic_drift_removed[10], df_test_parabolic_drift_removed[11]],\n     [df_train_parabolic_drift_removed[2], df_train_parabolic_drift_removed[6], df_test_parabolic_drift_removed[4]],\n     [df_train_parabolic_drift_removed[3], df_train_parabolic_drift_removed[7], df_test_parabolic_drift_removed[1], df_test_parabolic_drift_removed[9]],\n     [df_train_parabolic_drift_removed[4], df_train_parabolic_drift_removed[9], df_test_parabolic_drift_removed[5], df_test_parabolic_drift_removed[7]],\n     [df_train_parabolic_drift_removed[5], df_train_parabolic_drift_removed[8], df_test_parabolic_drift_removed[2], df_test_parabolic_drift_removed[6]]]\nlabels = [[\"train 0\", \"train 1 (line)\", \"test 0 (line)\", \"test 3\", \"test 8 (line)\", \"test 10 (sine)\", \"test 11\"],\n          [\"train 2\", \"train 6 (sine)\", \"test 4 (line)\"],\n          [\"train 3\", \"train 7 (sine)\", \"test 1 (line)\", \"test 9\"],\n          [\"train 4\", \"train 9 (sine)\", \"test 5\", \"test 7 (line)\"],\n          [\"train 5\", \"train 8 (sine)\", \"test 2\", \"test 6 (line)\"]]\n\nplt.figure(figsize=(25, 8))\nfor i in range(5):\n    plt.subplot(\"15\" + str(i + 1))\n    plot_dist(M[i], labels[i], i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save data\n\nI uploaded this data to [here][1]\n\n[1]:https://www.kaggle.com/eunholee/iondatawithoutdrift","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_dataframe(dataframe: pd.DataFrame,\n                   filename_with_path: str,\n                   force_overwrite=False):\n    print(\"Shape:\", dataframe.shape)\n    print(\"Contents:\\n\", dataframe)\n    print()\n    print(f'force_overwrite = {force_overwrite}')\n    if force_overwrite or (not os.path.exists(filename_with_path)):\n        print(f\"Saving dataframe to {filename_with_path}.\")\n        dataframe.to_csv(filename_with_path, index=False, float_format='%.9f',\n                                       chunksize=100000, compression='gzip', encoding='utf-8')\n    else:\n        print(f\"{filename_with_path} already exists, not overwriting. Remove it and try again.\")\n\n\ndf_train_clean = df_train_parabolic_drift_removed[0]\ndf_test_clean = df_test_parabolic_drift_removed[0]\nfor df in df_train_parabolic_drift_removed[1:]:\n    df_train_clean = pd.concat([df_train_clean, df], ignore_index=True)\nfor df in df_test_parabolic_drift_removed[1:]:\n    df_test_clean = pd.concat([df_test_clean, df], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_dataframe(df_train_clean, \"train_wo_drift_sine.csv.gz\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_dataframe(df_test_clean, \"test_wo_drift_sine.csv.gz\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+) I'm not a native English speaker. Please let me know if there's a wrong sentence or anything you don't understand.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}