{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1. Data Processing -- features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#most successful model was 1 Conv1D layer 2 LSTMs and 3 Dense layers","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn import *\nfrom sklearn.metrics import f1_score,make_scorer\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport xgboost as xgb\nfrom catboost import Pool,CatBoostRegressor\nimport datetime\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GROUP_BATCH_SIZE = 4000\nWINDOWS = [10, 50]\n\n\nBASE_PATH = '/kaggle/input/liverpool-ion-switching'\nDATA_PATH = '/kaggle/input/data-without-drift'\nRFC_DATA_PATH = '/kaggle/input/ion-shifted-rfc-proba'\nMODELS_PATH = '/kaggle/input/ensemble-models'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef create_rolling_features(df):\n    for window in WINDOWS:\n        df[\"rolling_mean_\" + str(window)] = df['signal'].rolling(window=window).mean()\n        df[\"rolling_std_\" + str(window)] = df['signal'].rolling(window=window).std()\n        df[\"rolling_var_\" + str(window)] = df['signal'].rolling(window=window).var()\n        df[\"rolling_min_\" + str(window)] = df['signal'].rolling(window=window).min()\n        df[\"rolling_max_\" + str(window)] = df['signal'].rolling(window=window).max()\n        df[\"rolling_min_max_ratio_\" + str(window)] = df[\"rolling_min_\" + str(window)] / df[\"rolling_max_\" + str(window)]\n        df[\"rolling_min_max_diff_\" + str(window)] = df[\"rolling_max_\" + str(window)] - df[\"rolling_min_\" + str(window)]\n\n    df = df.replace([np.inf, -np.inf], np.nan)    \n    df.fillna(0, inplace=True)\n    return df\n\n\ndef create_features(df, batch_size):\n    \n    df['group'] = df.groupby(df.index//batch_size, sort=False)['signal'].agg(['ngroup']).values\n    df['group'] = df['group'].astype(np.uint16)\n    for window in WINDOWS:    \n        df['signal_shift_pos_' + str(window)] = df.groupby('group')['signal'].shift(window).fillna(0)\n        df['signal_shift_neg_' + str(window)] = df.groupby('group')['signal'].shift(-1 * window).fillna(0)\n        \n    df['signal_2'] = df['signal'] ** 2\n    return df   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## reading data\ntrain = pd.read_csv(f'{DATA_PATH}/train_clean.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\ntest  = pd.read_csv(f'{DATA_PATH}/test_clean.csv', dtype={'time': np.float32, 'signal': np.float32})\nsub  = pd.read_csv(f'{BASE_PATH}/sample_submission.csv', dtype={'time': np.float32})\n\n# loading and adding shifted-rfc-proba features\ny_train_proba = np.load(f\"{RFC_DATA_PATH}/Y_train_proba.npy\")\ny_test_proba = np.load(f\"{RFC_DATA_PATH}/Y_test_proba.npy\")\n\nfor i in range(11):\n    train[f\"proba_{i}\"] = y_train_proba[:, i]\n    test[f\"proba_{i}\"] = y_test_proba[:, i]\n\n    \ntrain = create_rolling_features(train)\ntest = create_rolling_features(test)   \n    \n## normalizing features\ntrain_mean = train.signal.mean()\ntrain_std = train.signal.std()\ntrain['signal'] = (train.signal - train_mean) / train_std\ntest['signal'] = (test.signal - train_mean) / train_std\n\n\nprint('Shape of train is ',train.shape)\nprint('Shape of test is ',test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## create features\n\nbatch_size = GROUP_BATCH_SIZE\n\ntrain = create_features(train, batch_size)\ntest = create_features(test, batch_size)\n\ncols_to_remove = ['time','signal','open_channels','batch','batch_index','batch_slices','batch_slices2', 'group']\ncols = [c for c in train.columns if c not in cols_to_remove]\nX_train = train[cols]\ny = train['open_channels']\nX_test = test[cols]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##from sklearn.model_selection import train_test_split\n##X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.40, random_state=101)\n##converting to np arrays\nX_train = X_train.values\ny_train = y.values\nX_test = X_test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train\ndel test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"id5\"></a> <br> \n# 2. Model 1-- Conv1D+LSTM layer\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv1D\nfrom keras.layers import Bidirectional\nfrom keras.layers import Input\nfrom keras.layers import GRU\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling and onehot encoding\nfrom sklearn.preprocessing import MinMaxScaler\nonh = OneHotEncoder(sparse=False)\nsc = MinMaxScaler(feature_range = (0,1))\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\ny_train = y_train.reshape(len(y_train),1)\ny_train = onh.fit_transform(y_train)\n\nprint('Shape of X_train is ',X_train.shape)\nprint('Shape of y_train is ',y_train.shape)\nprint('Shape of X_test is ',X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##for converting input into 3D data\nX_train= X_train.reshape((X_train.shape[0],X_train.shape[1],1))\nX_test= X_test.reshape((X_test.shape[0],X_test.shape[1],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build and compile model\ndef build_clf(optimizer):\n    model = Sequential()\n    model.add(Conv1D(128,16, strides=6, activation='relu', input_shape = (X_train.shape[1],X_train.shape[2])))\n    model.add(LSTM(256,return_sequences=True))\n    model.add(Dropout(0.2))\n    model.add(LSTM(256))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu',kernel_initializer='uniform'))\n    model.add(Dense(128, activation='relu',kernel_initializer='uniform'))\n    model.add(Dense(128, activation='relu',kernel_initializer='uniform'))\n    model.add(Dense(units = 11, activation='softmax', kernel_initializer='uniform'))\n    model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics =['accuracy'])\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compile and fit model--96.25 rmsprop, 96.71--adadelta\nmodel = build_clf('adam')\nmodel.fit(X_train, y_train,epochs = 10, batch_size=256)                        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction and reversing One Hot Encoding\ny_pred=model.predict(X_test)\ny_pred =onh.inverse_transform(y_pred)\ny_pred.max() #Should be 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making submission\nsub = pd.read_csv('../input/liverpool-ion-switching/sample_submission.csv')\nsub.iloc[:,1] = y_pred[:,0]\nsub.to_csv('submission.csv',index=False,float_format='%.4f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Model 2 -- Temporal Convolutional Network(TCN)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dense\nfrom tensorflow.keras import Input, Model\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Tuning parameters to find best choice for model using Grid Search\n#from keras.wrappers.scikit_learn import KerasClassifier\n#from sklearn.model_selection import GridSearchCV\n#scorer = make_scorer(f1_score, average = 'weighted')\n#model = KerasClassifier(build_fn = build_clf)\n#parameters = {'batch_size': [500,10000], 'epochs': [5, 200],'optimizer': ['adam', 'rmsprop','nadam','adadelta']}\n#grid_search = GridSearchCV(estimator = model,param_grid = parameters,scoring = scorer,cv = 3, return_train_score= True)\n#grid_search = grid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#best_parameters = grid_search.best_params_\n#best_accuracy = grid_search.best_score_\n#best_parameters\n\n#Grid Search for multiclass classification failed","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}