{"cells":[{"metadata":{},"cell_type":"markdown","source":"A Simple EDA with minimal Description. The model is just some minor changes to [physically-possible](https://www.kaggle.com/jazivxt/physically-possible)\n\nOne of the charts (plot_rolling_window) is from [eda-ion-switching](https://www.kaggle.com/pestipeti/eda-ion-switching) and the denoising functions are from [dwt-signal-denoising](https://www.kaggle.com/jackvial/dwt-signal-denoising)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from statsmodels.tsa.ar_model import AutoReg, ar_select_order\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.api import acf, pacf, graphics\nfrom typing import List, Tuple, Union, NoReturn\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\nimport cufflinks as cf\nimport plotly\nfrom statsmodels.robust import mad\nimport matplotlib.pyplot as plt\nfrom scipy.signal import butter\nfrom scipy import signal\nimport lightgbm as lgb\nimport seaborn as sns\nfrom sklearn import *\nimport pandas as pd \nimport numpy as np\nimport warnings\nimport scipy\nimport pywt\nimport os\n\ncf.go_offline()\npy.init_notebook_mode()\ncf.getThemes()\ncf.set_config_file(theme='ggplot')\nwarnings.simplefilter('ignore')\npd.plotting.register_matplotlib_converters()\nsns.mpl.rc('figure',figsize=(16, 6))\nplt.style.use('ggplot')\nsns.set_style('darkgrid')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = os.path.abspath('/kaggle/input/liverpool-ion-switching/')\ntrain = pd.read_csv(os.path.join(base + '/train.csv'))\ntest  = pd.read_csv(os.path.join(base + '/test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape[0], test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_bathing_to_data(df : pd.DataFrame) -> pd.DataFrame :\n    batches = df.shape[0] // 500000\n    df['batch'] = 0\n    for i in range(batches):\n        idx = np.arange(i*500000, (i+1)*500000)\n        df.loc[idx, 'batch'] = i + 1\n    return df\n\ndef p5( x : pd.Series) -> pd.Series : return x.quantile(0.05)\ndef p95(x : pd.Series) -> pd.Series : return x.quantile(0.95)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = add_bathing_to_data(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('batch')[['signal','open_channels']].agg(['min', 'max', 'median', p5, p95])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('open_channels')[['signal','batch']].agg(['min', 'max', 'median', p5, p95])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(['batch','open_channels'])[['signal']].agg(['min', 'max', 'median', p5, p95])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"partial = train.iloc[::250, :]\npartial.signal = np.round(partial.signal.values, 2)\npartial['shifted_signal'] = (partial.signal.values + 10) ** 2\nfig = px.scatter(partial, x='signal', y='open_channels', color='open_channels',size='shifted_signal',  title='Signal vs Channels')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.box(partial, x='open_channels', y='signal', color='open_channels', title='Signal vs Channels')\nfig.update_traces(quartilemethod='exclusive')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.box(partial, x='open_channels', y='signal', color='batch', title='Signal vs Channels for Batches')\nfig.update_traces(quartilemethod='exclusive')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.density_heatmap(train.iloc[::50, :], x='signal', y='open_channels')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=5, cols=2,  subplot_titles=[f'Batch no {i+1}' for i in range(10)])\ni = 1\nfor row in range(1, 6):\n    for col in range(1, 3):\n        data = train[train.batch==i]['open_channels'].value_counts(sort=False).values\n        fig.add_trace(go.Bar(x=list(range(11)), y=data), row=row, col=col)       \n        i += 1\nfig.update_layout(width=800, height=1500, title_text=\"Target for each batch\", showlegend=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.open_channels.value_counts(sort=False).iplot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_by_batch_summaries(df : pd.DataFrame) -> NoReturn :\n    by_batch = df.groupby(['batch']).agg(['min', 'max', 'median', p5, p95]).reset_index(drop=True).iloc[:,5:]\n    by_batch.columns = ['MIN-SIG','MAX-SIG', 'MED-SIG', '5P-SIG', '95P-SIG', 'MIN-CHANNEL','MAX-CHANNEL', 'MED-CHANNEL', '5P-CHANNEL', '95P-CHANNEL']\n    by_batch.iloc[:,:5].iplot(kind='bar',xTitle='Batch', yTitle='Signal')\n    by_batch.iloc[:,5:].iplot(kind='bar', xTitle='Batch', yTitle='Channel')\n\nplot_by_batch_summaries(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_by_channel_summaries(df : pd.DataFrame) -> NoReturn :\n    by_channel = train.groupby(['open_channels']).agg(['min', 'max', 'median', p5, p95]).reset_index(drop=True).iloc[:,5:]\n    by_channel.columns = ['MIN-SIG','MAX-SIG', 'MED-SIG', '5P-SIG', '95P-SIG', 'MIN-BATCH','MAX-BATCH', 'MED-BATCH', '5P-BATCH', '95P-BATCH']\n    by_channel.iloc[:,5:].iplot(kind='bar' ,xTitle='Channel', yTitle='Batch')\n    by_channel.iloc[:,:5].iplot(kind='bar' )\n\nplot_by_channel_summaries(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_by_channel_summaries(df : pd.DataFrame, resample : int) -> NoReturn :\n    train_resampled = df.iloc[::resample, :]\n    train_resampled[['signal','open_channels']].plot(subplots=True)\n    plt.show()\n    \nplot_by_channel_summaries(train, 10000)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_smoothed_batch(i : int, window : int) -> NoReturn:\n    batch_resampled = train[train.batch==i].iloc[::1000, :]\n    ts = batch_resampled['signal']\n    plt.plot(ts, 'r-', color='royalblue')\n    plt.ylabel('Signal')\n    smooth_data = pd.Series(ts).rolling(window=window).mean().plot(style='k')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef high_pass_filter(x, low_cutoff=1000, sample_rate=10000):\n\n    nyquist = 0.5 * sample_rate\n    norm_low_cutoff = low_cutoff / nyquist\n    print(norm_low_cutoff)\n    sos = butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n    filtered_sig = signal.sosfilt(sos, x)\n\n    return filtered_sig\n\ndef denoise_signal( x, wavelet='db4', level=1):\n    \n    coeff = pywt.wavedec( x, wavelet, mode=\"per\" )\n    sigma = (1/0.6745) * maddest( coeff[-level] )\n    uthresh = sigma * np.sqrt( 2*np.log( len( x ) ) )\n    coeff[1:] = ( pywt.threshold( i, value=uthresh, mode='hard' ) for i in coeff[1:] )\n    return pywt.waverec( coeff, wavelet, mode='per' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_acf_pacf(i : int, lag : int, resample : int) -> NoReturn:\n    batch_resampled = train[train.batch==i].iloc[::resample, :]\n    plot_acf( batch_resampled['signal'], lags=lag)\n    plot_pacf(batch_resampled['signal'], lags=lag)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_rooling_data(df : pd.DataFrame) -> pd.DataFrame:\n    window_sizes = [10, 50, 100, 1000]\n    for window in window_sizes:\n        df[\"rolling_mean_\" + str(window)] = df['signal'].rolling(window=window).mean()\n        df[\"rolling_std_\" + str(window)] = df['signal'].rolling(window=window).std()\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = add_rooling_data(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_rolling_window(i : int, resample : int) -> NoReturn:\n    window_sizes = [10, 50, 100, 1000]\n    fig, ax = plt.subplots(len(window_sizes),1,figsize=(20, 6 * len(window_sizes)))\n    n = 0\n    for col in train.columns.values:\n        if 'rolling_' in col:\n            if 'mean' in col:\n                mean_df = train[train.batch==i].iloc[::resample,:][col]\n                ax[n].plot(mean_df, label=col, color='navy')\n            if 'std' in col:\n                std = train[train.batch==i].iloc[::resample,:][col].values\n                ax[n].fill_between(mean_df.index.values,\n                               mean_df.values-std, mean_df.values+std,\n                               facecolor='lightskyblue',\n                               alpha = 0.5, label=col)\n                ax[n].legend()\n                n+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_batch(i : int, resample : int) -> NoReturn:\n    batch_resampled = train[train.batch==i].iloc[::resample, :]\n    batch_resampled[['signal','open_channels']].plot(subplots=True)\n    plt.show()\n    ax = sns.distplot(batch_resampled[['signal']], rug=True)\n    ax.set_title(f'  Signal Distribution Batch=={i}', fontsize=13)\n    mod = AutoReg(batch_resampled['signal'], 3)\n    res = mod.fit(cov_type=\"HC0\")\n    sel = ar_select_order(batch_resampled['signal'], 3, glob=True)\n    sel.ar_lags\n    res = sel.model.fit()\n    fig = plt.figure(figsize=(16,9))\n    fig = res.plot_diagnostics(fig=fig, lags=25)\n    plot_rolling_window(i, resample)\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_signal_distribution_by_target(i : int) -> NoReturn :\n    data_by_target = train[train.open_channels==0]\n    ax = sns.distplot(data_by_target[['signal']], rug=True)\n    ax.set_title(f'Signal Distribution for Target=={i}', fontsize=13)\n    plt.show()\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_denoided_batch(i : int, resample : int) -> NoReturn : \n    batch_resampled = train[train.batch==i].iloc[::5000, :]  \n    batch_resampled['x_dn_1'] = denoise_signal(batch_resampled['signal'], wavelet='db4', level=1)\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=batch_resampled.time, mode='lines+markers', y=batch_resampled.signal, marker=dict(color=\"lightskyblue\"), name=\"Original signal\"))\n    fig.add_trace(go.Scatter(x=batch_resampled.time, y=batch_resampled.x_dn_1, mode='lines', marker=dict(color=\"navy\"), name=\"Denoised signal\"))\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Different plots for each batch, denoised batch signal and Signal Distribution for each Target\n\nFor showing each batch or eatch target distribution just call the function with the batch nymber"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_batch(1, resample=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_smoothed_batch(1, window=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_denoided_batch(1, resample=5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_acf_pacf(1, lag=25, resample=5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_signal_distribution_by_target(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = os.path.abspath('/kaggle/input/liverpool-ion-switching/')\ntrain = pd.read_csv(os.path.join(base + '/train.csv'))\ntest  = pd.read_csv(os.path.join(base + '/test.csv'))\n\ndef features(df):\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    df['batch'] = df.index // 25_000\n    df['batch_index'] = df.index  - (df.batch * 25_000)\n    df['batch_slices'] = df['batch_index']  // 2500\n    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n    \n    for c in ['batch','batch_slices2']:\n        d = {}\n        d['mean'+c] = df.groupby([c])['signal'].mean()\n        d['median'+c] = df.groupby([c])['signal'].median()\n        d['max'+c] = df.groupby([c])['signal'].max()\n        d['min'+c] = df.groupby([c])['signal'].min()\n        d['std'+c] = df.groupby([c])['signal'].std()\n        d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n        d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n        d['range'+c] = d['max'+c] - d['min'+c]\n        d['maxtomin'+c] = d['max'+c] / d['min'+c]\n        d['abs_avg'+c] = (d['abs_min'+c] + d['abs_max'+c]) / 2\n        for v in d:\n            df[v] = df[c].map(d[v].to_dict())\n\n    \n    #add shifts\n    df['signal_shift_+1'] = [0,] + list(df['signal'].values[:-1])\n    df['signal_shift_-1'] = list(df['signal'].values[1:]) + [0]\n    for i in df[df['batch_index']==0].index:\n        df['signal_shift_+1'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n        df['signal_shift_-1'][i] = np.nan\n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]:\n        df[c+'_msignal'] = df[c] - df['signal']\n        \n    return df\n\ntrain = features(train)\ntest = features(test)\n\ncol = [c for c in train.columns if c not in ['time', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]\nx1, x2, y1, y2 = model_selection.train_test_split(train[col], train['open_channels'], test_size=0.3, random_state=7)\n\ndef MacroF1Metric(preds, dtrain):\n    labels = dtrain.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = metrics.f1_score(labels, preds, average = 'macro')\n    return ('MacroF1Metric', score, True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'learning_rate': 0.1, 'max_depth': -1, 'num_leaves':2**7+1, 'metric': 'rmse', 'random_state': 7, 'n_jobs':-1, 'sample_fraction':0.33} \nmodel = lgb.train(params, lgb.Dataset(x1, y1), 2000,  lgb.Dataset(x2, y2), verbose_eval=0, early_stopping_rounds=100, feval=MacroF1Metric)\ntrain_preds = model.predict(train[col], num_iteration=model.best_iteration)\npreds = model.predict(test[col], num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\nimport scipy as sp\nclass OptimizedRounder(object):\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize F1 (Macro) score\n    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n    def _f1_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \n        :param coef: A list of coefficients that will be used for rounding\n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n        return -metrics.f1_score(y, X_p, average = 'macro')\n\n    def fit(self, X, y):\n        \"\"\"\n        Optimize rounding thresholds\n        \n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        loss_partial = partial(self._f1_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \n        :param X: The raw predictions\n        :param coef: A list of coefficients that will be used for rounding\n        \"\"\"\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n\n    def coefficients(self):\n        \"\"\"\n        Return the optimized coefficients\n        \"\"\"\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optR = OptimizedRounder()\noptR.fit(train_preds.reshape(-1,), train['open_channels'])\ncoefficients = optR.coefficients()\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimize_prediction(prediction):\n    prediction[prediction <= coefficients[0]] = 0\n    prediction[np.where(np.logical_and(prediction > coefficients[0], prediction <= coefficients[1]))] = 1\n    prediction[np.where(np.logical_and(prediction > coefficients[1], prediction <= coefficients[2]))] = 2\n    prediction[np.where(np.logical_and(prediction > coefficients[2], prediction <= coefficients[3]))] = 3\n    prediction[np.where(np.logical_and(prediction > coefficients[3], prediction <= coefficients[4]))] = 4\n    prediction[np.where(np.logical_and(prediction > coefficients[4], prediction <= coefficients[5]))] = 5\n    prediction[np.where(np.logical_and(prediction > coefficients[5], prediction <= coefficients[6]))] = 6\n    prediction[np.where(np.logical_and(prediction > coefficients[6], prediction <= coefficients[7]))] = 7\n    prediction[np.where(np.logical_and(prediction > coefficients[7], prediction <= coefficients[8]))] = 8\n    prediction[np.where(np.logical_and(prediction > coefficients[8], prediction <= coefficients[9]))] = 9\n    prediction[prediction > coefficients[9]] = 10\n    \n    return prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['open_channels'] = optimize_prediction(preds).astype(int)\ntest[['time','open_channels']].to_csv('submission.csv', index=False, float_format='%.4f')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}