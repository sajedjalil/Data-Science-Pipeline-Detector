{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Sklearn\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import f1_score\n\n# Graphing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\ndf = pd.read_csv('../input/liverpool-ion-switching-ds/train.csv')\n\n\n\nPERIODS = [1 , 2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(first notebook, have mercy on me)\n# One vs. All Modeling\n\nOne vs. all modeling builds an individual classifier for each class and is fitted against all other classes. E.g it builds a binary classifier for (class-6, class-not-6) and so on. It allows an additional layer of interpretability and allows us to gain some knowledge about the class. I thought it might be good to try this in addition to @cdeotte work. This kernel tries to answer a couple simple questions:\n\n1. Can we build a good classifer with very few features?\n2. Can we reduce misclassifications with a feature or two?"},{"metadata":{},"cell_type":"markdown","source":"## Predefined Functions"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PERIODS = [1]\n\ndef _signal_shift(signal, periods):\n    '''Returns signal shifted for a set number of periods.\n    '''\n    return signal.shift(periods=periods)\n\n\ndef signal_shifts(df, signal):\n    '''Calculates all signal shifts positive (forward) and negative (backwards)\n    given the predefined shift periods.\n    '''\n    for period in PERIODS:\n        neg = period\n        pos = -period\n        df[f'{signal}_shift_pos_{period}'] = _signal_shift(df[signal], pos)\n        df[f'{signal}_shift_neg_{period}'] = _signal_shift(df[signal], neg)\n\n    return df\n\n\ndef signal_shift_perc(df, signal):\n    '''Calculates the percentage or ratio of the shifted signal relative to\n    the current signal.\n    '''\n    for period in PERIODS:\n        df[f'{signal}_shift_pos_{period}_perc'] = \\\n            df[f'{signal}_shift_pos_{period}'] / df[signal]\n\n        df[f'{signal}_shift_neg_{period}_perc'] = \\\n            df[f'{signal}_shift_neg_{period}'] / df[signal]\n\n    return df\n\n\ndef single_decision_tree(X, y):\n    '''Trains single decision tree, prints the F1 macro scores and\n    and returns cross validaiton scores in one fold across dataframe.'''\n    kf = KFold(n_splits=5, random_state=348, shuffle=True)\n    \n    # Keep track of the predictions across each fold\n    cv            = pd.DataFrame() \n    cv['actual']  = pd.Series(y.values)\n    cv['predict'] = pd.Series()\n    fold          = 1\n    \n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n        # Build basic decision tree with low depth.\n        dtc = DecisionTreeClassifier(max_depth=8, class_weight='balanced')\n        \n        # Fit and predict on the test fold\n        dtc.fit(X_train, y_train)\n        predict = dtc.predict(X_test)\n        \n        # Calculate f1 macro on single fold and display\n        fold_cv = pd.DataFrame()\n        fold_cv['actual']  = pd.Series(y_test.values)\n        fold_cv['predict'] = pd.Series(predict)\n        \n        print(f'Fold {fold} F1 Macro: ', f1_score(fold_cv['actual'], fold_cv['predict'], average='weighted'))\n        \n        cv.loc[test_index, 'predict'] = predict\n        \n        fold += 1\n    \n    print(f'Total F1 Macro: ', f1_score(cv['actual'], cv['predict'], average='weighted'))\n    \n    return cv\n\n\ndef one_versus_all(X, y):\n    '''Trains single decision tree for each class, prints the F1 macro scores and\n    returns cross validation scores. Returns a out-of-fold scores and individual\n    probability per class.'''\n    kf = KFold(n_splits=5, random_state=348, shuffle=True)\n    \n    # Keep track of the predictions across each fold\n    cv            = pd.DataFrame() \n    cv['actual']  = pd.Series(y.values)\n    cv['predict'] = pd.Series()\n    for class_ in range(0, 11):\n        cv[f'proba_class_{class_}'] = pd.Series()\n        \n    fold          = 1\n    \n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        \n        # Build the one versus all classifiers (decision tree)\n        dtc = DecisionTreeClassifier(max_depth=8,\n                                     class_weight='balanced')\n        clf = OneVsRestClassifier(dtc).fit(X_train, y_train)\n        \n        # Fit and predict on the test fold\n        clf.fit(X_train, y_train)\n        predict = clf.predict(X_test)\n        predict_proba = clf.predict_proba(X_test)\n        \n        # Calculate f1 macro on single fold and display\n        fold_cv = pd.DataFrame()\n        fold_cv['actual']  = pd.Series(y_test.values)\n        fold_cv['predict'] = pd.Series(predict)\n        \n        print(f'Fold {fold} F1 Macro: ', f1_score(fold_cv['actual'], fold_cv['predict'], average='weighted'))\n        \n        for class_ in clf.classes_:\n            cv.loc[test_index, f'proba_class_{class_}'] = predict_proba[:, class_]\n            cv.loc[test_index, 'predict'] = predict\n        \n        fold += 1\n    \n    print(f'Total F1 Macro: ', f1_score(cv['actual'], cv['predict'], average='weighted'))\n    \n    return cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Take a look at the columns we are working with\nfor col in df.columns:\n    print(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Single Decision Tree\nLet's just build a single decision tree (max depth 8, balanced) to see what our baseline is for a decision tree classifier. We will then fit a single decision tree for each class to see where we are having a problems classifying between to different classes.\n\nThe point of the excercise is to find some individual features that might be beneficial in identifying misclassifications. The F1 scores will be pretty bad the model isn't very complex. "},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"cv = single_decision_tree(df.drop(['open_channels'], axis = 1), df['open_channels'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_v_all_oof = one_versus_all(df.drop(['open_channels'], axis = 1), df['open_channels'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Misclassified signals\n\nFor the misclassified signals, what was the probability measured for the opposing classes. Here we just calculate the mean probability values. For the most part it seems like the misclassified classes have highest probability in adjacent classes.\n\nFew exceptions / hypotheses based on the heatmap:\n\n- Class 3 Seems to have high misclassification of class 8\n- Class 1 has high misclassification of class 6\n- Class 2 has high misclassification as class 6\n- Class 4 has high misclassification as class 2\n- Class 7 has high misclassificaiton as class 2\n- Class 0 has high misclassification with class 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,8))\n\naggs = {}\n\nfor class_ in range(0,11):\n    aggs[f'proba_class_{class_}'] = 'mean'\n\nsns.heatmap(one_v_all_oof[one_v_all_oof['actual'] != one_v_all_oof['predict']].groupby(['actual']).agg(aggs), cmap='Blues', annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing above hypotheses\n\n- Class 3 Seems to have high misclassification of class 8\n- Class 1 has high misclassification of class 6\n- Class 2 has high misclassification as class 6\n- Class 4 has high misclassification as class 2\n- Class 7 has high misclassificaiton as class 2\n- Class 0 has high misclassification with class 3\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"misclassified = one_v_all_oof[one_v_all_oof['actual'] != one_v_all_oof['predict']]\nmisclassified_classes = [0, 1, 2, 3, 4, 7]\n\nf, axes = plt.subplots(2, 3, figsize=(24, 12), sharex=True)\norder = [x for x in range(0, 11)]\naxes_list = [axes[0,0], axes[0,1], axes[0,2], axes[1,0], axes[1,1], axes[1,2]]\nsns.set_style(\"whitegrid\")\nsns.despine(left = True)\n\nfor class_, axs in zip(misclassified_classes, axes_list):\n    mis_graph = misclassified[misclassified['actual'] == class_] \\\n                             .groupby(['predict'], as_index=False) \\\n                             .agg({'proba_class_0' : 'count'}) \\\n                             .rename(columns={'proba_class_0' : 'count'})\n    \n    sns.barplot(mis_graph['predict'], mis_graph['count'], ax=axs, order=order,palette='Blues').set_title(f'Misclassifications for class {class_}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add signal shifts to reduce misclassifications\n\nBut first we take note of the misclassifed indexes to ensure we build the second heatmap correctly."},{"metadata":{"trusted":true},"cell_type":"code","source":"orig_misclassified_index = misclassified.index.copy() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = signal_shifts(df, 'signal_sans_drift_avg_center')\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_v_all_oof = one_versus_all(df.drop(['open_channels'], axis = 1).fillna(0), df['open_channels'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,8))\n\naggs = {}\n\nfor class_ in range(0,11):\n    aggs[f'proba_class_{class_}'] = 'mean'\n\nsns.heatmap(one_v_all_oof[one_v_all_oof.isin(orig_misclassified_index)].groupby(['actual']).agg(aggs), cmap='Blues', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}