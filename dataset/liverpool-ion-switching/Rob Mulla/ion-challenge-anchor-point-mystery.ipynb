{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Anchor Point Mystery\n\nHelp me solve this mystery.\n\nDuring the ion challenge I found something interesting in the data that I still can't explain. Hopefully someone has a good explaination for it.\n\nMy attempt during the competition was to shift the \"drift\" sections of the data to maximize these points. I was successful but it didn't end up providing any fruitful to my model.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom scipy.optimize import minimize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/data-without-drift/train_clean.csv')\ntest = pd.read_csv('../input/data-without-drift/test_clean.csv')\ntt = pd.concat([train, test], sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_model_groups(tt):\n    tt.loc[(tt['time'] > 0) & (tt['time'] <= 10), 'sbatch'] = 0\n    tt.loc[(tt['time'] > 10) & (tt['time'] <= 50), 'sbatch'] = 1\n    tt.loc[(tt['time'] > 50) & (tt['time'] <= 60), 'sbatch'] = 2\n    tt.loc[(tt['time'] > 60) & (tt['time'] <= 100), 'sbatch'] = 3\n    tt.loc[(tt['time'] > 100) & (tt['time'] <= 150), 'sbatch'] = 4\n    tt.loc[(tt['time'] > 150) & (tt['time'] <= 200), 'sbatch'] = 5\n    tt.loc[(tt['time'] > 200) & (tt['time'] <= 250), 'sbatch'] = 6\n    tt.loc[(tt['time'] > 250) & (tt['time'] <= 300), 'sbatch'] = 7\n    tt.loc[(tt['time'] > 300) & (tt['time'] <= 350), 'sbatch'] = 8\n    tt.loc[(tt['time'] > 350) & (tt['time'] <= 400), 'sbatch'] = 9\n    tt.loc[(tt['time'] > 400) & (tt['time'] <= 450), 'sbatch'] = 10\n    tt.loc[(tt['time'] > 450) & (tt['time'] <= 500), 'sbatch'] = 11\n    # Test\n    tt.loc[(tt['time'] > 500) & (tt['time'] <= 510), 'sbatch'] = 12\n    tt.loc[(tt['time'] > 510) & (tt['time'] <= 520), 'sbatch'] = 13\n    tt.loc[(tt['time'] > 520) & (tt['time'] <= 530), 'sbatch'] = 14\n    tt.loc[(tt['time'] > 530) & (tt['time'] <= 540), 'sbatch'] = 15\n    tt.loc[(tt['time'] > 540) & (tt['time'] <= 550), 'sbatch'] = 16\n    tt.loc[(tt['time'] > 550) & (tt['time'] <= 560), 'sbatch'] = 17\n    tt.loc[(tt['time'] > 560) & (tt['time'] <= 570), 'sbatch'] = 18\n    tt.loc[(tt['time'] > 570) & (tt['time'] <= 580), 'sbatch'] = 19\n    tt.loc[(tt['time'] > 580) & (tt['time'] <= 590), 'sbatch'] = 20\n    tt.loc[(tt['time'] > 590) & (tt['time'] <= 600), 'sbatch'] = 21\n    tt.loc[(tt['time'] > 600) & (tt['time'] <= 610), 'sbatch'] = 22\n    tt.loc[(tt['time'] > 610) & (tt['time'] <= 630), 'sbatch'] = 23\n    tt.loc[(tt['time'] > 630) & (tt['time'] <= 650), 'sbatch'] = 24\n    tt.loc[(tt['time'] > 650) & (tt['time'] <= 670), 'sbatch'] = 25\n    tt.loc[(tt['time'] > 670) & (tt['time'] <= 700), 'sbatch'] = 26\n    return tt\n\ndef had_drift(tt):\n    \"\"\"\n    I dentify if section had drift in the original dataset\n    \"\"\"\n    tt.loc[(tt['time'] > 0) & (tt['time'] <= 10), 'drift'] = False\n    tt.loc[(tt['time'] > 10) & (tt['time'] <= 50), 'drift'] = False\n    tt.loc[(tt['time'] > 50) & (tt['time'] <= 60), 'drift'] = True\n    tt.loc[(tt['time'] > 60) & (tt['time'] <= 100), 'drift'] = False\n    tt.loc[(tt['time'] > 100) & (tt['time'] <= 150), 'drift'] = False\n    tt.loc[(tt['time'] > 150) & (tt['time'] <= 200), 'drift'] = False\n    tt.loc[(tt['time'] > 200) & (tt['time'] <= 250), 'drift'] = False\n    tt.loc[(tt['time'] > 250) & (tt['time'] <= 300), 'drift'] = False\n    tt.loc[(tt['time'] > 300) & (tt['time'] <= 350), 'drift'] = True\n    tt.loc[(tt['time'] > 350) & (tt['time'] <= 400), 'drift'] = True\n    tt.loc[(tt['time'] > 400) & (tt['time'] <= 450), 'drift'] = True\n    tt.loc[(tt['time'] > 450) & (tt['time'] <= 500), 'drift'] = True\n    # Test\n    tt.loc[(tt['time'] > 500) & (tt['time'] <= 510), 'drift'] = True\n    tt.loc[(tt['time'] > 510) & (tt['time'] <= 520), 'drift'] = True\n    tt.loc[(tt['time'] > 520) & (tt['time'] <= 530), 'drift'] = False\n    tt.loc[(tt['time'] > 530) & (tt['time'] <= 540), 'drift'] = False\n    tt.loc[(tt['time'] > 540) & (tt['time'] <= 550), 'drift'] = True\n    tt.loc[(tt['time'] > 550) & (tt['time'] <= 560), 'drift'] = False\n    tt.loc[(tt['time'] > 560) & (tt['time'] <= 570), 'drift'] = True\n    tt.loc[(tt['time'] > 570) & (tt['time'] <= 580), 'drift'] = True\n    tt.loc[(tt['time'] > 580) & (tt['time'] <= 590), 'drift'] = True\n    tt.loc[(tt['time'] > 590) & (tt['time'] <= 600), 'drift'] = False\n    tt.loc[(tt['time'] > 600) & (tt['time'] <= 610), 'drift'] = True\n    tt.loc[(tt['time'] > 610) & (tt['time'] <= 630), 'drift'] = True\n    tt.loc[(tt['time'] > 630) & (tt['time'] <= 650), 'drift'] = True\n    tt.loc[(tt['time'] > 650) & (tt['time'] <= 670), 'drift'] = False\n    tt.loc[(tt['time'] > 670) & (tt['time'] <= 700), 'drift'] = False\n    return tt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt = had_drift(tt)\ntt = add_model_groups(tt)\nFILTER_TRAIN = '(time <= 47.6 or time > 48) and (time <= 364 or time > 382.4)'\ntt = tt.query(FILTER_TRAIN)\ntt['drift'] = tt['drift'].astype('bool')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, d in tt.groupby('open_channels'):\n    d.query('not drift')['signal'].value_counts() \\\n        .plot(figsize=(15, 5), style='.', label=i,\n              title='Value Counts by Signal (Excluding Drift Sections)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We wee a high number of values with these signal values:\n- Each corresponding to open channels:\n```\n    open_channels -> signal\n    0 -> -2.5002\n    1 -> -1.2502\n    2 -> -0.0002\n    3 -> 1.2498\n    4 -> 2.4998\n    5 -> 3.7498\n```","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lets look at the value count of these in the data:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"anchors = [-2.5002, -1.2502, -0.0002, 1.2498, 2.4998, 3.7498]\ntt.query('drift == False and signal in @anchors').groupby(['signal','open_channels'])[['time']].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting only the anchor points","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\ntt.query('drift == False and signal in @anchors') \\\n    .groupby('open_channels') \\\n    .plot(x='time', y='signal', style='.', figsize=(15, 5), ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I attempted to \"shift\" the drift sections to maximize the number of these values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tt['signal_shift'] = np.nan\ntt.loc[~tt['drift'], 'signal_shift'] = tt.loc[~tt['drift']]['signal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify the batches with drift\ndrift_batches = tt.query('drift')['sbatch'].unique()\nprint(drift_batches)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First attempt: maximize anchor count.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for db in drift_batches:\n    d = tt.query('sbatch == @db')\n    def shift_and_anchor_count(shift):\n        anchor_count = 0\n        shifted_signal = (d['signal'] + shift).round(4)\n        for a in anchors:\n    #         print(a)\n            n_anchors = (shifted_signal == a).sum()\n    #         print(n_anchors)\n            anchor_count += n_anchors\n    #     print(f'Shift {shift} ---> anchor count: {anchor_count}')\n    \n\n        return -anchor_count\n    res = minimize(shift_and_anchor_count, [0], method='Powell', tol=1e-6)\n    opt_shift = res['x']\n    print(f'Drift batch {db} - optimal shift {opt_shift}')\n    tt.loc[tt['sbatch'] == db, 'signal_shift'] = (tt.loc[tt['sbatch'] == db]['signal'] - opt_shift).round(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Second attempt + max and minimize surrounding values.\n- This was a better way is to also minize if surrounding values of \"anchors\" have high value counts:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for db in drift_batches:\n    d = tt.query('sbatch == @db')\n    def shift_and_anchor_count(shift):\n        shift = shift/1000\n        anchor_count = 0\n        shifted_signal = (d['signal'] + shift).round(4)\n        for a in anchors:\n            n_anchors = (shifted_signal == a).sum()\n            anchor_count += n_anchors\n            # Penalize for high counts neighbors numbers being high\n            pprior = round(a - 0.0002, 4)\n            prior = round(a - 0.0001, 4)\n            post = round(a + 0.0001, 4)\n            ppost = round(a + 0.0002, 4)\n            n_anchor_prior = (shifted_signal == prior).sum()\n            n_anchor_pprior = (shifted_signal == pprior).sum()\n#             print(n_anchor_prior)\n            anchor_count -= (prior - pprior)\n            n_anchor_post = (shifted_signal == post).sum()\n            n_anchor_ppost = (shifted_signal == ppost).sum()\n            anchor_count -= (post - ppost)\n#         print()\n        return -anchor_count\n    res = minimize(shift_and_anchor_count, [0], method='Powell') #, bounds=(-0.0001, 0.0001))\n    opt_shift = res['x']\n    print(f'Drift batch {db} - optimal shift {opt_shift}')\n    tt.loc[tt['sbatch'] == db, 'signal_shift'] = (tt.loc[tt['sbatch'] == db]['signal'] + (opt_shift/1000)).round(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt['signal_round4'] = tt['signal_shift'].round(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We now have a high value count of our anchor points in non-drift areas","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"anchors = [-2.5002, -1.2502, -0.0002, 1.2498, 2.4998, 3.7498]\ntt.query('drift and signal_shift in @anchors').groupby(['signal_shift','open_channels'])[['time']].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets plot the drift sections before and after this shift:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, d in tt.groupby('open_channels'):\n    d.query('drift')['signal'].round(4) \\\n        .value_counts() \\\n        .plot(figsize=(15, 5), style='.', label=i,\n              title='Unique Value Counts in Drift Segments before shifting')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This looks much cleaner, right?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, d in tt.groupby('open_channels'):\n    d.query('drift')['signal_round4'] \\\n        .round(4).value_counts() \\\n        .plot(figsize=(15, 5), style='.', label=i,\n             title='Unique Value Counts in Drift Data after Shifting to Optimize Anchors')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## In the end this \"shifted\" data did not improve my CV/LB Score and I'm still confused by why it exists.\n- Can you solve this mystery for me?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}