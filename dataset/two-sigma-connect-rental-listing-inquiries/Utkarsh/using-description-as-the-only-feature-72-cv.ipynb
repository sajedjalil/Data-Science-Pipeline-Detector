{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"df89a24e-7f2b-c7e4-d8bd-143e825b120f"},"source":"This notebook shows how you can use description to improve your model. We will be using description, as the only feature for now."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c99a12fb-9db6-470e-8fec-d7796fb6b684"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d13d410-c4e9-a4c0-da18-ccded6ff6ac2"},"outputs":[],"source":"train = pd.read_json(\"../input/train.json\")\ntest = pd.read_json(\"../input/test.json\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb6798d0-b85f-ccb5-730c-162680e3caae"},"outputs":[],"source":"# We need listing_id, description and interest_level for this notebook\ntrain = train[['listing_id','description','interest_level']]\ntest = test[['listing_id','description']]\n\ntrain['flag'] = 'train'\ntest['flag'] = 'test'\nfull_data = pd.concat([train,test])\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ab762f5-b231-ec0f-953b-0850983c6efb"},"outputs":[],"source":"from nltk.stem import PorterStemmer\nimport re"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b9e1ada-7ef5-f7d4-4e46-bdef5dde445d"},"source":"> Stemming is the process of reducing inflected (or sometimes derived) words to their word stem. Example: gardens to garden."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4143321c-43e2-c607-05ed-ce9030f5593c"},"outputs":[],"source":"# Removes symbols, numbers and stem the words to reduce dimentional space\nstemmer = PorterStemmer()\n\ndef clean(x):\n    regex = re.compile('[^a-zA-Z ]')\n    # For user clarity, broken it into three steps\n    i = regex.sub(' ', x).lower()\n    i = i.split(\" \") \n    i= [stemmer.stem(l) for l in i]\n    i= \" \".join([l.strip() for l in i if (len(l)>2) ]) # Keeping words that have length greater than 2\n    return i"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"015450db-fe3b-6183-75b5-9d121af07522"},"outputs":[],"source":"# This takes some time to run. It would be helpful if someone can help me optimize clean() function.\nfull_data['description_new'] = full_data.description.apply(lambda x: clean(x))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5cad277c-d263-43c6-d37f-68c65f2f3606"},"outputs":[],"source":"full_data[['description','description_new']].head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"68a40924-2496-d610-21c2-a7112e3af6cf"},"source":"We have removed all punctuation and numbers, as we are only interested in words for now."},{"cell_type":"markdown","metadata":{"_cell_guid":"8165ac23-2acd-d50b-1a00-ebc515e7da85"},"source":"### Using CountVectorizer\nWe can use CountVectorizer or tfidfvectorizer for building a word matrix. For me countvectorizer gave better performance."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c419401-ae92-3644-ac80-868b7c0bd0ae"},"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer #Can use tfidffvectorizer as well\n\ncvect_desc = CountVectorizer(stop_words='english', max_features=200)\nfull_sparse = cvect_desc.fit_transform(full_data.description_new)\n # Renaming words to avoid collisions with other feature names in the model\ncol_desc = ['desc_'+ i for i in cvect_desc.get_feature_names()] \ncount_vect_df = pd.DataFrame(full_sparse.todense(), columns=col_desc)\nfull_data = pd.concat([full_data.reset_index(),count_vect_df],axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"67625d28-40c0-b2e2-f102-6e77a6af7bd0"},"outputs":[],"source":"full_data.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f3a1bf52-baea-8e8e-dc83-7cea90558207"},"source":"### Running Cross Validation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"90ef0b2c-efb0-ac7a-7e0a-852757083c15"},"outputs":[],"source":"train =(full_data[full_data.flag=='train'])\ntest =(full_data[full_data.flag=='test'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5390381f-4bcf-6014-5e5e-e231ae487ece"},"outputs":[],"source":"labels = {'high':0, 'medium':1, 'low':2}\ntrain['interest_level'] = train.interest_level.apply(lambda x: labels[x])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"367fadf9-3fc3-08fe-3381-4df7fe006dcb"},"outputs":[],"source":"feat = train.drop(['interest_level','flag','listing_id','description','index','description_new'],axis=1).columns.values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3e534cff-57f8-1b69-e290-8b3f9e97b25e"},"outputs":[],"source":"from sklearn.ensemble import GradientBoostingClassifier  as GBM\nfrom sklearn.ensemble import RandomForestClassifier  as RF\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3051e9e6-6636-b1df-26aa-74791cdf1454"},"outputs":[],"source":"def run_mod(train_X, test_X,train_Y):\n    reg = GBM(max_features = 'auto',n_estimators=200,random_state=1)\n    reg.fit(train_X,train_Y)\n    pred = reg.predict_proba(test_X)\n    imp = reg.feature_importances_\n    return pred,imp"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f079c8f8-3e6b-59e2-7cf4-28b600357101"},"outputs":[],"source":"def cross_val(train,feat,split):\n    cv_scores = []\n    importances = []\n    # Cross Validation preprocessing\n    train_X = train[feat]\n    train_Y = train['interest_level']\n\n    train_X = train_X.as_matrix()\n    train_Y = train_Y.as_matrix()\n\n    test_X = test[feat]\n    test_X = test_X.as_matrix()\n\n    kf = StratifiedKFold(n_splits=split, shuffle=True, random_state=1)\n    for dev_index, val_index in kf.split(train_X,train_Y):\n            train_X_X, test_X_X = train_X[dev_index,:], train_X[val_index,:]\n            train_Y_Y, test_Y_Y = train_Y[dev_index,], train_Y[val_index,]\n            pred,imp = run_mod(train_X_X, test_X_X,train_Y_Y)\n            cv_scores.append(log_loss(test_Y_Y, pred))\n            importances.append(imp)\n    return np.mean(cv_scores),importances\n#print np.average(importances,axis=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f032c46a-d567-bfc9-491b-0b284027b58c"},"outputs":[],"source":"cv_score,imp = cross_val(train,feat,3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"caefc629-b598-0617-04d0-869429dee2d1"},"outputs":[],"source":"cv_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60b98eb6-3cdb-279f-89ce-b4706a5fc514"},"outputs":[],"source":"# Lets chaeck the importance of words\nimportances = list(np.average(imp,axis=0))\nfeatures = cvect_desc.get_feature_names()\ndf = pd.DataFrame({'words':features,'imp':importances}).sort_values(by='imp',ascending=False).head(30)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a2dbbeb-f044-fcf5-255e-6fcd72b473c2"},"outputs":[],"source":"plt.figure(figsize=(12,15))\nsns.barplot(y=df.words,x=df.imp)\n# Remember, these are stemmed words"},{"cell_type":"markdown","metadata":{"_cell_guid":"db714d32-d6b8-f5bc-a6fe-9d17729a838a"},"source":"* Well, the score is using description and an untuned GBM. But a tuned one dies on me in this kernal (though it has score of 0.71). \n* It would be great if someone can post what score they get using XGB.\n* I think it is a good start for someone just starting out with text data. Similar transformation can be done with column feature.\n* It would be great if someone can help me optimize the clean() function.\n\nThanks!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b84450aa-0b5c-e97c-0950-b97c944bc149"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}