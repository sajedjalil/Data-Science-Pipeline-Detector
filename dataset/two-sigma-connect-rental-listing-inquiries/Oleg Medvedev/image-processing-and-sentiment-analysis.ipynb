{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"798683c3-f055-06e4-89d2-161dcc0bb00e"},"source":"Description sentiment and image processing."},{"cell_type":"markdown","metadata":{"_cell_guid":"9489cf1d-9cbc-cdc3-5c47-80a310b52bd9"},"source":"### Reading data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f545f94-97da-d549-d657-1c5a53707566"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import pearsonr\nfrom PIL import Image"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51be4aad-3c81-b89f-e795-3f1564a07ed9"},"outputs":[],"source":"df = pd.read_json('../input/train.json')\ndf.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0153f3cc-8c1f-324e-d071-0e17e2d94bac"},"source":"### Description sentiment\nLet's use nltk and Vader sentiment analyzer. It takes quite a while, so I will sample only a portion of the full dataset."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3a133370-2e8b-47a9-c7c4-c1731235b750"},"outputs":[],"source":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.tokenize import sent_tokenize"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"577aa88c-b15f-03e6-35dc-1b093571f3b6"},"outputs":[],"source":"def description_sentiment(sentences):\n    analyzer = SentimentIntensityAnalyzer()\n    result = []\n    for sentence in sentences:\n        vs = analyzer.polarity_scores(sentence)\n        result.append(vs)\n    return pd.DataFrame(result).mean()\n\nsdf = df.sample(5000)\nsdf['description_tokens'] = sdf['description'].apply(sent_tokenize)\nsdf = pd.concat([sdf,sdf['description_tokens'].apply(description_sentiment)],axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"604ffb69-1658-d271-6107-df1733a08c2a"},"outputs":[],"source":"fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, sharex=True,figsize=(8,16))\nsns.violinplot(x=\"interest_level\",y=\"compound\",data=sdf,ax=ax1,order =['low','medium','high'])\nsns.violinplot(x=\"interest_level\",y=\"neg\",data=sdf,ax=ax2)\nsns.violinplot(x=\"interest_level\",y=\"pos\",data=sdf,ax=ax3)\nsns.violinplot(x=\"interest_level\",y=\"neu\",data=sdf,ax=ax4)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bf25a8f7-5479-ac14-7043-99c689f8aa1f"},"source":"### Photo properties"},{"cell_type":"markdown","metadata":{"_cell_guid":"212e4c92-87cd-7cd8-5900-47adf87256c5"},"source":"Let's also explore the possible correlations between features and simple high-level properties of images without going into NN. Let's look at the number of images, image size, brightness, hue and saturation."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9057c72-0393-6bef-5ef0-97013279987a"},"outputs":[],"source":"# Get available images\nfrom subprocess import check_output\nimages = [int(x) for x in check_output([\"ls\", \"../input/images_sample\"]).decode(\"utf8\").strip().split('\\n')]\n\n# Read the train set and choose those which have images only\ndf = df[df.listing_id.isin(images)]\nprint(df.shape)\n\n# Add number of images\ndf['n_images'] = df.apply(lambda x: len(x['photos']), axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fd7c23b-008b-1e1c-625a-5013dfbbaac1"},"outputs":[],"source":"# this is what we are after\ncheck_output([\"ls\", \"../input/images_sample/6812223\"]).decode(\"utf8\").strip().split('\\n')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"022806f7-ce1a-48d4-8725-e975c6e1993d"},"outputs":[],"source":"#function to process one image\ndef process_image(path):\n    path = '../input/images_sample/'+path[0:7]+'/'+path\n    im = np.array(Image.open(path))\n\n    #get dims\n    width = im.shape[1]\n    height = im.shape[0]\n    \n    #flatten image\n    im = im.transpose(2,0,1).reshape(3,-1)\n   \n    \n    #brightness is simple, assign 1 if zero to avoid divide\n    brg = np.amax(im,axis=0)\n    brg[brg==0] = 1\n    \n    #hue, same, assign 1 if zero, not working atm due to arccos\n    denom = np.sqrt((im[0]-im[1])**2-(im[0]-im[2])*(im[1]-im[2]))\n    denom[denom==0] = 1\n    #hue = np.arccos(0.5*(2*im[0]-im[1]-im[2])/denom)\n    \n    #saturation\n    sat = (brg - np.amin(im,axis=0))/brg\n    \n    #return mean values\n    return width,height,np.mean(brg),np.mean(sat)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"724d4138-d4d5-3f5b-85cb-6030f93f3f9b"},"outputs":[],"source":"#second helper function - process a row of a dataset\n#return mean of each property for all images\ndef process_row(row):\n    images = check_output([\"ls\", \"../input/images_sample/\"+str(row.listing_id)]).decode(\"utf8\").strip().split('\\n')\n    res = np.array([process_image(x) for x in images])\n    res = np.mean(res,axis=0)\n    row['img_width'] = res[0]\n    row['img_height'] = res[1]\n    row['img_brightness'] = res[2]\n    row['img_saturation'] = res[3]\n    return row"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2770f9d-4e45-871d-7a1e-6b407e3ced71"},"outputs":[],"source":"#Now we can process the dataset\ndf = df.apply(lambda row: process_row(row),axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ada0b56c-7814-3f21-82f1-1eed5c7635cb"},"outputs":[],"source":"#Some plots\nd = df[['img_width','n_images','img_height','img_brightness','img_saturation','interest_level']]\nsns.pairplot(d, hue=\"interest_level\",size=1.5)"},{"cell_type":"markdown","metadata":{"_cell_guid":"aa3bae5d-d0dd-d2cc-93d2-e6922d3899b3"},"source":"Looks like it is all over the place, so it is unlikely to be a good feature. It is easy to calculate so perhaps still worth a try on a full image dataset."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}