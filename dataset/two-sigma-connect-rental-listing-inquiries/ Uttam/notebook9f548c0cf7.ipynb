{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"920b7055-9739-3b9c-165c-b9023d26e9f9"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b30e6f58-e339-03bf-778e-5f3a6d36e8ab"},"outputs":[],"source":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport re\n\nstop_words = set(stopwords.words('english'))\nregex_for_removing_numbers = \"^[0-9]\"\n\n\ndef tokenize(sentence):\n    '''\n    parse the sentence in to words\n    :param sentence:\n    :return:\n    '''\n    words = word_tokenize(sentence)\n    return words\n\n\ndef tokenize_list_sentences(sentences):\n    '''\n    parse a list of sentence to words\n    :param sentences: list of sentences\n    :return:\n    '''\n    words = []\n    for sentence in sentences:\n        word = word_tokenize(sentence)\n        words.append(word)\n    return words\n\n\ndef stopwords_remove(words):\n    '''\n    remove stop-words from the list of words and return a filtered words\n    :param words:\n    :return:\n    '''\n    filtered_sentence = []\n    for w in words:\n        w = w.lower()\n        # removes all the words starting with numbers\n        match = re.search(regex_for_removing_numbers, w)\n        if w not in stop_words and not match:\n            # removes all special charecters\n            new_word = ''.join(e for e in w if e.isalnum())\n            if new_word != '':\n                filtered_sentence.append(new_word)\n    return filtered_sentence\n\n\ndef stemming(words):\n    '''\n    stem the verbs and adverbs into simple nouns\n    :param words:\n    :return:\n    '''\n    ps = PorterStemmer()\n    stem_words = []\n    for w in words:\n        stem_words.append(ps.stem(w))\n    return stem_words\n\n\ndef create_corpus(sentences):\n    '''\n    create a corpus/bag of words\n    :param filepath:\n    :return:\n    '''\n    corpus = set()\n    for sentence in sentences:\n        corpus.update(tokenize(sentence))\n\n    print \"corpus size:\", corpus.__len__()\n    filtered_stopwords = stopwords_remove(corpus)\n\n    print \"corpus size after removing stop words :\", filtered_stopwords.__len__()\n    filtered_stemming = stemming(filtered_stopwords)\n\n    return filtered_stemming\n\n\ndef create_corpus_from_sentence(sentence):\n    '''\n    create a corpus with removed stop words and stemming.\n    :param sentence:\n    :return:\n    '''\n    corpus = tokenize(sentence)\n    filtered_stopwords = stopwords_remove(corpus)\n\n    filtered_stemming = stemming(filtered_stopwords)\n\n    return filtered_stemming\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2805d679-3267-93e3-602f-946b5394d931"},"outputs":[],"source":"import pandas as pd\n\nimport corpora_generator\n\ndef freq_gen(corpus):\n    return reduce(lambda d, c: d.update([(c, d.get(c, 0) + 1)]) or d, corpus, {})\n\n\ndef hashing_fun(desc):\n    '''\n    convert each description into a hash value\n    :param desc:\n    :return:\n    '''\n    desHashMap = {}\n    for key in desc.keys():\n        sentence = desc[key]\n        corpus = corpora_generator.create_corpus_from_sentence(sentence)\n        hashcode = hash(frozenset((freq_gen(corpus))))\n        desHashMap[key] = hashcode\n    return desHashMap\n\n\ndef df_convert_desc(df):\n    '''\n    convert the description features content to hash values\n    :param df: dataframe\n    :return:\n    '''\n    hashcodesmap = hashing_fun(df[\"description\"])\n    df[\"description\"] = hashcodesmap\n\ndf=pd.read_json(\"/input/train.json\")\ndf_convert_desc(df)\n\nprint df[\"description\"]\n\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}