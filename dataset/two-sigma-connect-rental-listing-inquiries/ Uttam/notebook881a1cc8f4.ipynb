{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fdafd08a-d2f5-07ff-1c5f-aa5a5bf2ed4a"},"outputs":[],"source":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport re\n\nstop_words = set(stopwords.words('english'))\nregex_for_removing_numbers = \"^[0-9]\"\n\n\ndef tokenize(sentence):\n    '''\n    parse the sentence in to words\n    :param sentence:\n    :return:\n    '''\n    words = word_tokenize(sentence)\n    return words\n\n\ndef tokenize_list_sentences(sentences):\n    '''\n    parse a list of sentence to words\n    :param sentences: list of sentences\n    :return:\n    '''\n    words = []\n    for sentence in sentences:\n        word = word_tokenize(sentence)\n        words.append(word)\n    return words\n\n\ndef stopwords_remove(words):\n    '''\n    remove stop-words from the list of words and return a filtered words\n    :param words:\n    :return:\n    '''\n    filtered_sentence = []\n    for w in words:\n        w = w.lower()\n        # removes all the words starting with numbers\n        match = re.search(regex_for_removing_numbers, w)\n        if w not in stop_words and not match:\n            # removes all special charecters\n            new_word = ''.join(e for e in w if e.isalnum())\n            if new_word != '':\n                filtered_sentence.append(new_word)\n    return filtered_sentence\n\n\ndef stemming(words):\n    '''\n    stem the verbs and adverbs into simple nouns\n    :param words:\n    :return:\n    '''\n    ps = PorterStemmer()\n    stem_words = []\n    for w in words:\n        stem_words.append(ps.stem(w))\n    return stem_words\n\n\ndef create_corpus(sentences):\n    '''\n    create a corpus/bag of words\n    :param filepath:\n    :return:\n    '''\n    corpus = set()\n    for sentence in sentences:\n        corpus.update(tokenize(sentence))\n\n    print \"corpus size:\", corpus.__len__()\n    filtered_stopwords = stopwords_remove(corpus)\n\n    print \"corpus size after removing stop words :\", filtered_stopwords.__len__()\n    filtered_stemming = stemming(filtered_stopwords)\n\n    return filtered_stemming\n\n\ndef create_corpus_from_sentence(sentence):\n    '''\n    create a corpus with removed stop words and stemming.\n    :param sentence:\n    :return:\n    '''\n    corpus = tokenize(sentence)\n    filtered_stopwords = stopwords_remove(corpus)\n\n    filtered_stemming = stemming(filtered_stopwords)\n\n    return filtered_stemming\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37b43929-ce0c-cc01-067b-d1b48ad5f8fc"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50716f15-f6d0-acf0-13d9-becf1010ffc3"},"outputs":[],"source":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport re\n\nstop_words = set(stopwords.words('english'))\nregex_for_removing_numbers = \"^[0-9]\"\n\n\ndef tokenize(sentence):\n    '''\n    parse the sentence in to words\n    :param sentence:\n    :return:\n    '''\n    words = word_tokenize(sentence)\n    return words\n\n\ndef tokenize_list_sentences(sentences):\n    '''\n    parse a list of sentence to words\n    :param sentences: list of sentences\n    :return:\n    '''\n    words = []\n    for sentence in sentences:\n        word = word_tokenize(sentence)\n        words.append(word)\n    return words\n\n\ndef stopwords_remove(words):\n    '''\n    remove stop-words from the list of words and return a filtered words\n    :param words:\n    :return:\n    '''\n    filtered_sentence = []\n    for w in words:\n        w = w.lower()\n        # removes all the words starting with numbers\n        match = re.search(regex_for_removing_numbers, w)\n        if w not in stop_words and not match:\n            # removes all special charecters\n            new_word = ''.join(e for e in w if e.isalnum())\n            if new_word != '':\n                filtered_sentence.append(new_word)\n    return filtered_sentence\n\n\ndef stemming(words):\n    '''\n    stem the verbs and adverbs into simple nouns\n    :param words:\n    :return:\n    '''\n    ps = PorterStemmer()\n    stem_words = []\n    for w in words:\n        stem_words.append(ps.stem(w))\n    return stem_words\n\n\ndef create_corpus(sentences):\n    '''\n    create a corpus/bag of words\n    :param filepath:\n    :return:\n    '''\n    corpus = set()\n    for sentence in sentences:\n        corpus.update(tokenize(sentence))\n\n    print \"corpus size:\", corpus.__len__()\n    filtered_stopwords = stopwords_remove(corpus)\n\n    print \"corpus size after removing stop words :\", filtered_stopwords.__len__()\n    filtered_stemming = stemming(filtered_stopwords)\n\n    return filtered_stemming\n\n\ndef create_corpus_from_sentence(sentence):\n    '''\n    create a corpus with removed stop words and stemming.\n    :param sentence:\n    :return:\n    '''\n    corpus = tokenize(sentence)\n    filtered_stopwords = stopwords_remove(corpus)\n\n    filtered_stemming = stemming(filtered_stopwords)\n\n    return filtered_stemming\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}