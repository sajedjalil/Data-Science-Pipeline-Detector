{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6137345b-0759-7fc3-9295-a52c12d14ed6"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport scipy\n\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\ndf=pd.read_json(\"../input/train.json\")\ndf['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\ndf['created']=df['created'].astype(np.datetime64)\ndf['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\ndf['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\ndf['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\ndf['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\ndf['features_count']=df.features.apply(lambda x: len(x))\ndf['photos_count']=df.photos.apply(lambda x: len(x))\n\ncategorical = [\"display_address\", \"building_id\", \"street_address\"]\nfor f in categorical:\n        if df[f].dtype=='object':\n            lbl = preprocessing.LabelEncoder()\n            lbl.fit(list(df[f].values) + list(df[f].values))\n            df[f] = lbl.transform(list(df[f].values))\n            \nlbl = preprocessing.LabelEncoder()\nlbl.fit(list(df['manager_id'].values))\ndf['manager_id'] = lbl.transform(list(df['manager_id'].values))\n\nfeature_list=['no fee', 'hardwood floors', 'laundry in building']\ndf['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\nfor feature in feature_list:\n        df[feature]=df['features'].apply(lambda x: feature in x)\nvectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n                                 stop_words='english')\nvectorizer.fit(df.description.values)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dbffc094-d676-a861-0999-a9279875a7dd"},"outputs":[],"source":"df_tv, df_test = train_test_split(df, random_state=0)\ndf_train, df_val = train_test_split(df_tv, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a00b3cf5-34c1-3a32-0b39-697c52f62a15"},"outputs":[],"source":"temp = pd.concat([df_train.manager_id,pd.get_dummies(df_train.interest_level)], axis = 1\n                ).groupby('manager_id').mean()\ntemp.columns = ['high_frac','low_frac', 'medium_frac']\ntemp['count'] = df_train.groupby('manager_id').count().iloc[:,1]\n\ntemp['manager_skill'] = temp['high_frac']*2 + temp['medium_frac']\nunranked_managers_ixes = temp['count']<20\nranked_managers_ixes = ~unranked_managers_ixes\nmean_values = temp.loc[ranked_managers_ixes, [\n    'high_frac','low_frac', 'medium_frac','manager_skill']].mean()\ntemp.loc[unranked_managers_ixes,['high_frac','low_frac', 'medium_frac','manager_skill']] = mean_values.values\n\ndf_train = df_train.merge(temp.reset_index(),how='left', on='manager_id')\ndf_val = df_val.merge(temp.reset_index(),how='left', on='manager_id')\nnew_manager_ixes = df_val['high_frac'].isnull()\ndf_val.loc[new_manager_ixes,['high_frac','low_frac', 'medium_frac','manager_skill'\n                            ]] = mean_values.values\ndf_test = df_test.merge(temp.reset_index(),how='left', on='manager_id')\nnew_manager_ixes = df_test['high_frac'].isnull()\ndf_test.loc[new_manager_ixes,['high_frac','low_frac', 'medium_frac','manager_skill'\n                            ]] = mean_values.values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"311b3c0a-300d-3d92-70e8-3bcd58081a59"},"outputs":[],"source":"derived_cols = ['derived_'+str(i) for i in range(5)]\ncols=['price', 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'priceperbed','created_hour', \n      'desc_count', 'photos_count', 'features_count', 'no fee', 'hardwood floors', \n      'laundry in building', 'manager_skill', 'listing_id']+categorical\n\nsvd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\nX_train = svd.fit_transform(vectorizer.transform(df_train.description))\nX_train=np.hstack([X_train, df_train[cols].values])\nX_val = svd.transform(vectorizer.transform(df_val.description))\nX_val=np.hstack([X_val, df_val[cols].values])\nX_test = svd.transform(vectorizer.transform(df_test.description))\nX_test=np.hstack([X_test, df_test[cols].values])\ntarget_num_map = {'high':0, 'low':1, 'medium':2}\ny_train = np.array(df_train['interest_level'].apply(lambda x: target_num_map[x]))\ny_test = np.array(df_test['interest_level'].apply(lambda x: target_num_map[x]))\ny_val = np.array(df_val['interest_level'].apply(lambda x: target_num_map[x]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"72c46273-7910-ce7e-f3c5-1dda605b84ae"},"outputs":[],"source":"dtrain = xgb.DMatrix(data=X_train, label=y_train)\nxgval = xgb.DMatrix(X_val, y_val)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8625ec2-c4ea-6d3b-20d7-76285c2cb1f7"},"outputs":[],"source":"import xgboost as xgb\nSEED = 0\n\nparams = {\n    'eta':.15,\n    'max_depth':6,\n    'min_child_weight':3,\n    'colsample_bytree':.8,\n    'subsample':.8,\n    'seed':0,\n    'nthread':16,\n    'objective':'multi:softprob',\n    'eval_metric':'mlogloss',\n    'num_class':3,\n    'silent':1\n}\n\nbst = xgb.train(params, dtrain, 130, verbose_eval=25)\ny_pred = bst.predict(dtrain)\nscore=log_loss(df_train['interest_level'].values, y_pred)\nprint(score)\ny_pred = bst.predict(xgval)\nscore=log_loss(df_val['interest_level'].values, y_pred)\nprint(score)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c12dd77-142b-d5c0-2d98-81af92b4c9e9"},"outputs":[],"source":"#pd.Series(index = derived_cols + cols, data = clf.feature_importances_).sort_values().plot(\n#    kind = 'bar')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}