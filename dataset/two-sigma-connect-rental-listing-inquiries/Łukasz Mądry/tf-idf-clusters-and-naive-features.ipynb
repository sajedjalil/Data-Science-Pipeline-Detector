{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"573548f8-38be-3bcf-7227-7974e654f0a9"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"475c9ee7-6e4d-e256-fe1f-17424fbd3e2e"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3285c31d-39ad-5b6a-4a8c-0b049a1e6a5d"},"outputs":[],"source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import StandardScaler, scale\nfrom sklearn.linear_model import LogisticRegression\n\nvectorizer = TfidfVectorizer(stop_words='english', max_features=2048).fit(df['description'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0cc8b40-dc18-ba9e-dc26-68b159a88bee"},"outputs":[],"source":"words_pipe = make_pipeline(\n    TfidfVectorizer(stop_words='english', max_features=2048),\n    LogisticRegression(C=5)\n)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec799258-2595-3e24-c4f0-59e75d57d6cd"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81a2699f-402c-5496-f3c0-92ade8e4dfd5"},"outputs":[],"source":"descs2vec = vectorizer.transform(df['description'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7110c37b-490b-2dd6-1e60-7e03a8d796eb"},"outputs":[],"source":"def avenue_or_street(x):\n    \n    if 'avenue' in x.lower() or ' ave' in x.lower():\n        return 1\n    if 'street' in x.lower() or 'st.' in x.lower() or ' st' in x.lower():\n        return 0\n    else:\n        return -1\n\ndef transform(df):\n\n    price = scale(df['price'].tolist())\n    bedrooms = df['bedrooms'].as_matrix()\n    baths = df['bathrooms'].as_matrix()\n    nr_of_features = df['features'].apply(len).as_matrix()\n    avn_str = df['display_address'].apply(avenue_or_street).as_matrix()\n    prop_bed = scale(df['price'].as_matrix()/(1+df['bedrooms'].as_matrix()))\n    prop_bath = scale(df['price'].as_matrix()/(1+df['bathrooms'].as_matrix()))\n    descr_log_length = scale(df['description'].fillna('0').apply(lambda x: np.log(1+len(x))))\n    descr_length = scale(df['description'].apply(len))\n    nr_of_photos = df['photos'].apply(len).as_matrix()\n    \n    \n    return np.hstack([avn_str[None].T, \n                   nr_of_features[None].T, \n                   baths[None].T, \n                   price[None].T, \n                   bedrooms[None].T, \n                   nr_of_photos[None].T,\n                  prop_bed[None].T,\n                  prop_bath[None].T,\n                  descr_log_length[None].T,\n                  descr_length[None].T])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b08a21f-1b7d-a78f-d77f-eff6573aa117"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50a08603-8720-5e04-8607-389c3bb8c151"},"outputs":[],"source":"from collections import defaultdict\n\ndef build_feature_tfidf(series, max_feats=512):\n    \n    feat_counts = defaultdict(int)\n\n    for f in series:\n\n        for feat in f:\n            feat_counts[feat] += 1\n            \n    D = min(max_feats, len(feat_counts))\n    feat_counts = dict(sorted(feat_counts.items(), key=lambda x: x[1], reverse=True)[:D])\n    ind_dict = dict(zip(feat_counts.keys(), range(D)))\n    \n    idf = np.log(series.shape[0]/(1+np.asarray(list(feat_counts.values()))))\n    matrix = np.zeros((series.shape[0], D))\n    for i, f in enumerate(series):\n        \n        for feat in f:\n            if feat in ind_dict:\n                matrix[i, ind_dict[feat]] = 1/len(f)*idf[ind_dict[feat]]\n                \n            \n    return matrix, ind_dict, idf\n\nind_dict, idf = build_feature_tfidf(df['features'])[1:]\n\ndef transform_to_tfidf(series, ind_dict, idf):\n    \n    matrix = np.zeros((series.shape[0], len(ind_dict)))\n    for i, f in enumerate(series):\n        \n        for feat in f:\n            \n            if feat in ind_dict:\n                matrix[i, ind_dict[feat]] = 1/len(f)*idf[ind_dict[feat]]\n                \n    return matrix"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c721987b-fcf5-81ca-c451-fa47ec730dd3"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a2d750c5-5dfd-c8a6-e82b-b9a2f8faa8a2"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa4b57ad-6480-ff14-a692-7c3790c26f56"},"outputs":[],"source":"def cut_outliers(matrix, perc=[.5, 99.5]):\n    \n    for i in range(matrix.shape[1]):\n        \n        matrix[:, i] = np.clip(matrix[:, i], np.percentile(matrix[:, i], perc[0]), \n                               np.percentile(matrix[:, i], perc[1]))\n        \n    return matrix"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86439900-34fe-27f7-d349-0f8cbf076c42"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7d47bb3-a4bf-539b-3cd4-26ae3f86efac"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66cd0aeb-52fe-69f9-b8d7-f09b7292c769"},"outputs":[],"source":"def get_avg_prices_wrt_clusters(to_cluster, return_stats=False, **params):\n    \n    km = KMeans(**params)\n    clusters = km.fit_predict(to_cluster)\n    \n    all_prices = df['price'].as_matrix().flatten()\n    \n    n_clust = km.get_params()['n_clusters']\n    \n    stats = []\n    \n    final = np.zeros(df.shape[0])\n    \n    for i in range(n_clust):\n        \n        wh = np.where(clusters==i)[0]\n        prices = all_prices[wh]\n        z = [np.mean(prices), np.std(prices), np.median(prices)] \n        \n        final[wh] = (prices - z[0])/(1e-3+z[1])\n        \n        stats.append(z)\n        \n        \n    return (final, clusters, stats) if return_stats else (final, clusters)\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9990ab76-daf5-76c7-e4e8-1f137f161056"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f208aadd-2719-8af6-6e0b-382859a5265f"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a04b233-8c27-ebdc-9ffc-097d86427685"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"747aef51-969e-cead-4aa2-b898849c852c"},"outputs":[],"source":"month = todate.dt.month\nday = todate.dt.day\nhour = todate.dt.hour"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"278d86cb-3711-99e2-e316-0732b9d1651d"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8796faa2-45d6-ffd6-eeb5-abc2eb242497"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef8c4d5b-e187-9af1-b405-0e13ce6b8b41"},"outputs":[],"source":"def create_data(df, with_tfidf=False):\n    fin, cls = get_avg_prices_wrt_clusters(cut_outliers(df[['latitude', 'longitude']].as_matrix()))\n    data = np.hstack([transform(df), fin.reshape(-1,1), cls.reshape(-1,1), cut_outliers(df[['latitude', 'longitude']].as_matrix())])\n    \n    return data\n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4bd40a4-0c4d-6e55-dad1-f08af16f25d2"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fb33cf4-dd80-af27-db95-376c4af9cdca"},"outputs":[],"source":"import xgboost as xgb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20af6fe5-8f54-ca65-3e46-dfdf50ef7e4c"},"outputs":[],"source":"def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n    param = {}\n    param['objective'] = 'multi:softprob'\n    param['eta'] = 0.03\n    param['max_depth'] = 6\n    param['silent'] = 1\n    param['num_class'] = 3\n    param['eval_metric'] = \"mlogloss\"\n    param['min_child_weight'] = 1\n    param['subsample'] = 0.7\n    param['colsample_bytree'] = 0.7\n    param['seed'] = seed_val\n    num_rounds = num_rounds\n\n    plst = list(param.items())\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n\n    pred_test_y = model.predict(xgtest)\n    return pred_test_y, model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2970ff1-500c-622a-9e12-ff6a2f3f3c17"},"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder, label"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b30e8b7-2aaf-768f-071b-c8ecc9db96e5"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce15115c-2774-afb4-fc63-2b1586a3c5cb"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82f62444-e3be-8719-06ed-9b787f5a6c33"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af218666-46de-b543-cde8-92b18de78f95"},"outputs":[],"source":"test = pd.read_json('test.json')"},{"cell_type":"markdown","metadata":{"_cell_guid":"43006a4b-039d-f32b-dfde-5b3f754a053a"},"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}