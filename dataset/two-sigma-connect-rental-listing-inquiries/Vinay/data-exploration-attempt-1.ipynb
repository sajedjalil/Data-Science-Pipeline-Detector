{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"733be703-76eb-61c8-3e84-45276539d828"},"source":"Loading of libraries"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d387fa77-f6af-c24c-e882-9bfeb3e428b4"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\nimport os\nimport sys\nimport operator\nfrom scipy import sparse\nimport xgboost as xgb\nfrom sklearn import model_selection, preprocessing, ensemble\nfrom sklearn.metrics import log_loss\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"},{"cell_type":"markdown","metadata":{"_cell_guid":"3d8f51c4-3e62-2bd6-5ae2-e71753677e1d"},"source":"Required for this round of exploration"},{"cell_type":"markdown","metadata":{"_cell_guid":"73a8bc41-4cec-5249-9eaf-34d4a54161c2"},"source":"Read files"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0583b311-f820-910d-0aa4-ef701b92dbfe"},"outputs":[],"source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ntrain_df=pd.read_json('../input/train.json')\ntest_df=pd.read_json('../input/test.json')\nprint('Training data dimensions:',train_df.shape)\nprint('Testing data dimensions:',test_df.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f007ed4c-77f7-c311-3164-2fe5608f64d1"},"source":"Set up for KNN longitude and lattitiude"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ed01f8e-bd26-aef9-a574-92c8b9681b68"},"outputs":[],"source":"neigh = KNeighborsClassifier(n_neighbors=39)\ndef LongLatLoc(train_df,model,mode) :\n    X=pd.concat([train_df['latitude'],train_df['longitude']],axis=1)\n    if mode==1:\n        y=train_df['interest_level']\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=45)\n        model.fit(X_train, y_train)\n        predVal=model.predict(X_test)\n    else :\n        predVal=model.predict(X)\n        y_test='N/A'\n    return predVal, model, y_test    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d7e4082-1912-8bc1-d55b-6bc5ec2a9991"},"outputs":[],"source":"def checkpred(predVal,y_test,mode):\n    if mode==1:\n        mat=[predVal,y_test]\n    else :\n        mat='N/A'\n    df=pd.DataFrame(mat).transpose()\n    df.columns=('h0','y')\n    df['diff']=np.where(df.h0==df.y,1,0)\n    print('% correct =',sum(df['diff'])/len(df['diff'])*100)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"954fbf7b-4591-ada3-edc6-ec6017ad3081"},"outputs":[],"source":"\n\ndef addnewcol(df,ary,fieldname):\n\tdf['tem2349field']=ary\n\ttarget_num_map = {'high':0, 'medium':1, 'low':2}\n\tdf[fieldname]=df['tem2349field'].apply(lambda x: target_num_map[x])\n    df.drop('tem2349field', axis=1, inplace=True)\n    return df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e910e40-35e0-7da1-f4be-b08feff8792c"},"outputs":[],"source":"def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n    param = {}\n    param['objective'] = 'multi:softprob'\n    param['eta'] = 0.1\n    param['max_depth'] = 6\n    param['silent'] = 1\n    param['num_class'] = 3\n    param['eval_metric'] = \"mlogloss\"\n    param['min_child_weight'] = 1\n    param['subsample'] = 0.7\n    param['colsample_bytree'] = 0.7\n    param['seed'] = seed_val\n    num_rounds = num_rounds\n    plst = list(param.items())\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n\n    pred_test_y = model.predict(xgtest)\n    return pred_test_y, model"},{"cell_type":"markdown","metadata":{"_cell_guid":"036c5dfc-48a8-a0ef-d847-595e68cc856e"},"source":"check with splitting the input as test and train"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a270143-aa68-8a0c-f8a4-f74bfa7f235a"},"outputs":[],"source":"predVal,neigh,y_test=LongLatLoc(train_df,neigh,1)\ncheckpred(predVal,y_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8be6c409-99be-4498-13de-104c47cc7229"},"source":"Generate the field for all test data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7039d5a8-97aa-c7d5-2da9-dd1f55f5389a"},"outputs":[],"source":"predVal,neigh,y_test=LongLatLoc(train_df,neigh,0)\ny_test=train_df['interest_level']\ncheckpred(predVal,y_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"36a2862b-322d-6e6e-9f73-559f30076261"},"source":"Add the prediction to the features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad8365b5-8f3a-37a6-deaf-379b338683b6"},"outputs":[],"source":"\"\"\"\ntrainDF['locvalst']=predVal\ntarget_num_map = {'high':0, 'medium':1, 'low':2}\ntrainDF['locval']=trainDF['locvalst'].apply(lambda x: target_num_map[x])\n\"\"\"\ntrain_df=addnewcol(train_df,predVal,'locval')\n#train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c01f7ce6-5391-da98-76cb-7c3ce859b90b"},"outputs":[],"source":"predVal,neigh,y_test=LongLatLoc(test_df,neigh,0)\ntest_df=addnewcol(test_df,predVal,'locval')\n\"\"\"\ntestDF['locvalst']=predVal\ntestDF['locval']=testDF['locvalst'].apply(lambda x: target_num_map[x])\n\"\"\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca6d058f-f552-12b8-01a1-1b0ee18bb2f7"},"outputs":[],"source":"print(train_df.shape)\nprint(test_df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d60fe38-01eb-18c8-cbec-e51ef986dcfa"},"outputs":[],"source":"features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\", \"locval\"]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49d7f4fa-87c3-e7fc-e3b6-ce1c23a466f8"},"outputs":[],"source":"# count of photos #\ntrain_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\ntest_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n\n# count of \"features\" #\ntrain_df[\"num_features\"] = train_df[\"features\"].apply(len)\ntest_df[\"num_features\"] = test_df[\"features\"].apply(len)\n\n# count of words present in description column #\ntrain_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\ntest_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n\n# convert the created column to datetime object so as to extract more features \ntrain_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\ntest_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n\n# Let us extract some features like year, month, day, hour from date columns #\ntrain_df[\"created_year\"] = train_df[\"created\"].dt.year\ntest_df[\"created_year\"] = test_df[\"created\"].dt.year\ntrain_df[\"created_month\"] = train_df[\"created\"].dt.month\ntest_df[\"created_month\"] = test_df[\"created\"].dt.month\ntrain_df[\"created_day\"] = train_df[\"created\"].dt.day\ntest_df[\"created_day\"] = test_df[\"created\"].dt.day\ntrain_df[\"created_hour\"] = train_df[\"created\"].dt.hour\ntest_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n\n# adding all these new features to use list #\nfeatures_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\", \"created_month\", \"created_day\", \"listing_id\", \"created_hour\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c50dd99-9503-6437-3454-348f72a5c2df"},"outputs":[],"source":"categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\nfor f in categorical:\n        if train_df[f].dtype=='object':\n            #print(f)\n            lbl = preprocessing.LabelEncoder()\n            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n            train_df[f] = lbl.transform(list(train_df[f].values))\n            test_df[f] = lbl.transform(list(test_df[f].values))\n            features_to_use.append(f)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07a0315a-cc54-058b-4069-0ce18547b015"},"outputs":[],"source":"train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\ntest_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\nprint(train_df[\"features\"].head())\ntfidf = CountVectorizer(stop_words='english', max_features=200)\ntr_sparse = tfidf.fit_transform(train_df[\"features\"])\nte_sparse = tfidf.transform(test_df[\"features\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c106560-5030-0fed-ca7a-1a695bf5fafb"},"outputs":[],"source":"train_X = sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\ntest_X = sparse.hstack([test_df[features_to_use], te_sparse]).tocsr()\n\ntarget_num_map = {'high':0, 'medium':1, 'low':2}\ntrain_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\nprint(train_X.shape, test_X.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf4473c1-f7e8-a9da-d8ad-e2cbd5f76509"},"outputs":[],"source":"cv_scores = []\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\nfor dev_index, val_index in kf.split(range(train_X.shape[0])):\n        dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n        dev_y, val_y = train_y[dev_index], train_y[val_index]\n        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n        cv_scores.append(log_loss(val_y, preds))\n        print(cv_scores)\n        break"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d910edf9-fde0-b6f5-47f3-33fd91db6afe"},"outputs":[],"source":"preds, model = runXGB(train_X, train_y, test_X, num_rounds=400)\nout_df = pd.DataFrame(preds)\nout_df.columns = [\"high\", \"medium\", \"low\"]\nout_df[\"listing_id\"] = test_df.listing_id.values\nout_df.to_csv(\"xgb_starter2.csv\", index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}