{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d3c3aba2-7519-ca0f-a7c3-81ddb0520a9d"},"source":"In this notebook, we will be trying the naives bayes algorithm to make a submission."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bfc795ca-5091-152a-83d4-9ad03a6c7484"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12ffc1f6-65ba-e1a7-2aec-a9f484f9e1c6"},"outputs":[],"source":"# objective is to predict a number of listing enquiries based on features\ntrain = pd.read_json(\"../input/train.json\", \"r\")\ntest = pd.read_json(\"../input/test.json\", \"r\")\nsample_sub = pd.read_csv(\"../input/sample_submission.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"01fd7711-9c58-acf7-30ce-9df1d69d46ba"},"outputs":[],"source":"sample_sub.head()\n# the above is what our submission is supposed to look like"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"09d0f362-d523-7d5a-f715-6721e78b456c"},"outputs":[],"source":"train = train[['price', 'listing_id', 'bathrooms', 'bedrooms', 'interest_level', 'latitude', 'longitude']]\ntest = test[['price', 'listing_id', 'bathrooms', 'bedrooms', 'latitude', 'longitude']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b83cdbba-4cbb-b0e6-609e-c90f33b8cc8b"},"outputs":[],"source":"train_target = train['interest_level']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb72663f-d9c3-18a8-081e-870d59ffb47c"},"outputs":[],"source":"from sklearn.naive_bayes import GaussianNB"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b3928e3-f1c6-5f08-b6b3-f449794728b6"},"outputs":[],"source":"gnb = GaussianNB()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4aa06944-6e0f-8faa-5fd8-ec0d43319042"},"outputs":[],"source":"train.index = train['listing_id']\ntrain = train.drop('interest_level', 1)\nmodel = gnb.fit(train, train_target)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5cefb4c2-be8f-44d5-eea1-c150996e3cbb"},"outputs":[],"source":"test.index = test['listing_id']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55cd35cc-f6a2-ca40-ce86-7d5d7f5be91f"},"outputs":[],"source":"y = model.predict_proba(test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"557a6cf3-5b5b-7936-a863-4fcd67bcb552"},"outputs":[],"source":"y_dat = pd.DataFrame(y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c15a4bed-66a7-8daa-1aed-7e81cfc77872"},"outputs":[],"source":"#y_dat.copy(deep = False)\ny_dat.loc[:,'listing_id'] = test.index"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d41a9937-5e8a-155e-fa0d-b2f6d91f830c"},"outputs":[],"source":"y_dat.rename(columns = {'0':'medium', '1':'low', '2':'high'}, inplace = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7421dc0-a742-0a4f-1056-f579bef7ef83"},"outputs":[],"source":"y_dat.columns = ['medium', 'low', 'high', 'listing_id']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4822d39-0343-a31c-45ac-706d71ce8603"},"outputs":[],"source":"data = y_dat[['listing_id', 'high', 'medium', 'low']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a90760a5-a6d9-5a0f-5eb1-b7167224acf1"},"outputs":[],"source":"data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"774dc626-e11e-7c0b-d76f-133c4a5b623f"},"outputs":[],"source":"#medium, low, high\n#writer = pd.ExcelWriter('/Users/reshmasekar/Desktop/sub.xlsx', engine='xlsxwriter')\n# Convert the dataframe to an XlsxWriter Excel object.\ndata.to_csv(\"sub_rf_4.csv\", index = False)\n#y_dat.to_excel(\"/Users/reshmasekar/Desktop\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63ee2319-2e51-b417-d6f1-7b3486d2cf35"},"outputs":[],"source":"# improving predictive accuracy"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e1e3c49-ad75-2d72-e129-f6700258153a"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bc1e038-6991-1b72-2132-98b1e4a4a369"},"outputs":[],"source":"# objective is to predict a number of listing enquiries based on features\ntrain = pd.read_json(\"../input/train.json\", \"r\")\ntest = pd.read_json(\"../input/test.json\", \"r\")\nsample_sub = pd.read_csv(\"../input/sample_submission.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2fa48deb-9e6a-b8fd-b679-c77103ce1340"},"outputs":[],"source":"train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ca3334d-507d-3bc0-5bb2-01984e420a0a"},"outputs":[],"source":"# splitting words from description\ndescription=train['description']\nfrom nltk.tokenize import RegexpTokenizer\ntokenizer = RegexpTokenizer(r'\\w+')\nwords_total=\"\"\nfor word in description:\n    words_total = words_total +word\ntokens=tokenizer.tokenize(words_total)\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer=CountVectorizer(tokens)\ndtm=vectorizer.fit_transform(train['description'])\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc8ebdb9-e69d-1fa1-ddc9-5fe4a81e2bbc"},"outputs":[],"source":"#Need to remove stop words and also use three tokens? \n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}