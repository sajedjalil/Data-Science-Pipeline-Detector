{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"1e27919f-b9dd-6cc8-e08a-17b527e8e5c8"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8bb54bda-137c-4a7d-727c-70bcdf42a9d1"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport json\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nimport hashlib\nimport random\nfrom math import exp\nimport xgboost as xgb\nfrom sklearn.decomposition import PCA\nfrom math import sin, cos, sqrt, atan2, radians\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import Birch\n\n\ndef dist(list_one, list_two):\n    # approximate radius of earth in km\n    R = 6373.0\n\n    lat1 = radians(list_one['latitude'])\n    lon1 = radians(list_one['longitude'])\n    lat2 = radians(list_two['latitude'])\n    lon2 = radians(list_two['longitude'])\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    distance = R * c\n    \n    return distance\n\n\n\ndef cluster_latlon(n_clusters, data):  \n    #split the data between \"around NYC\" and \"other locations\" basically our first two clusters \n    data_c=data[(data.longitude>-74.05)&(data.longitude<-73.75)&(data.latitude>40.4)&(data.latitude<40.9)]\n    data_e=data[~((data.longitude>-74.05)&(data.longitude<-73.75)&(data.latitude>40.4)&(data.latitude<40.9))]\n    #put it in matrix form\n    coords=data_c.as_matrix(columns=['latitude', \"longitude\"])\n    \n    brc = Birch(branching_factor=100, n_clusters=n_clusters, threshold=0.01,compute_labels=True)    \n    #brc2 = Birch(branching_factor=100, n_clusters=n_clusters / 2, threshold=0.005,compute_labels=True)\n    #brc4 = Birch(branching_factor=100, n_clusters=n_clusters / 4, threshold=0.005,compute_labels=True)\n    brc.fit(coords)\n    clusters=brc.predict(coords)\n    #print clusters\n    data_c[\"cluster_\"+str(n_clusters)]=clusters\n    data_e[\"cluster_\"+str(n_clusters)]=-1 #assign cluster label -1 for the non NYC listings \n    #brc2.fit(coords)\n    #clusters=brc2.predict(coords)\n    #print clusters\n    #data_c[\"cluster_\"+str(n_clusters/2)]=clusters\n    #data_e[\"cluster_\"+str(n_clusters/2)]=-1 #assign cluster label -1 for the non NYC listings \n    #brc4.fit(coords)\n    #clusters=brc4.predict(coords)\n    #print clusters\n    #data_c[\"cluster_\"+str(n_clusters/4)]=clusters\n    #data_e[\"cluster_\"+str(n_clusters/4)]=-1 #assign cluster label -1 for the non NYC listings \n\n\n    data=pd.concat([data_c,data_e])\n    #plt.scatter(data_c[\"longitude\"], data_c[\"latitude\"], c=data_c[\"cluster_\"+str(n_clusters)], s=10, linewidth=0.1)\n    #plt.title(str(n_clusters)+\" Neighbourhoods from clustering\")\n    #plt.show()\n    return data \n\n\n\n\ndef preprocess(train_df, test_df):\n    \"\"\"Just a generic preprocessing function, feel free to substitute it with your custom function\"\"\"\n    # encode target variable\n    train_df['interest_level'] = train_df['interest_level'].apply(lambda x: {'high': 2, 'medium': 1, 'low': 0}[x])   \n    index=list(range(train_df.shape[0]))\n    random.shuffle(index)\n    manager_score = [np.nan]*len(train_df)\n    manager_low = [np.nan]*len(train_df)\n    manager_medium = [np.nan]*len(train_df)\n    manager_high = [np.nan]*len(train_df)\n    manager_low_pct = [np.nan]*len(train_df)\n    manager_medium_pct = [np.nan]*len(train_df)\n    manager_high_pct = [np.nan]*len(train_df)    \n    building_score = [np.nan]*len(train_df)\n    building_low = [np.nan]*len(train_df)\n    building_medium = [np.nan]*len(train_df)\n    building_high = [np.nan]*len(train_df)\n    building_low_pct = [np.nan]*len(train_df)\n    building_medium_pct = [np.nan]*len(train_df)\n    building_high_pct = [np.nan]*len(train_df)\n    pct_low =  [np.nan]*len(train_df)\n    pct_medium =  [np.nan]*len(train_df)\n    pct_high =  [np.nan]*len(train_df)\n    neigh_count = [np.nan]*len(train_df)\n    for j in range(5):\n        print j\n        manager_sum = {}\n        manager_high_tmp = {}\n        manager_medium_tmp = {}\n        manager_low_tmp = {}\n        manager_count = {}        \n        building_sum = {}\n        building_high_tmp = {}\n        building_medium_tmp = {}\n        building_low_tmp = {}\n        building_count = {}\n        high_total = 0.0\n        medium_total = 0.0\n        low_total = 0.0\n        manager_ct = 0.0 \n        building_ct = 0.0\n        sm = 0.0\n        ct = 0.0        \n        test_ind = index[int((j*train_df.shape[0])/5):int(((j+1)*train_df.shape[0])/5)]\n        train_ind = list(set(index).difference(test_ind))\n        print 'train ind'\n        for i in train_ind:\n            x = train_df.iloc[i]\n            if x['manager_id'] not in manager_sum:\n                manager_sum[x['manager_id']] = 0.0\n                manager_count[x['manager_id']] = 0.0\n                manager_ct += 1\n            if x['building_id'] not in building_sum:\n                building_sum[x['building_id']] = 0.0\n                building_count[x['building_id']] = 0.0\n                building_ct += 1\n            building_sum[x['building_id']] += x['interest_level']\n            manager_sum[x['manager_id']] += x['interest_level']\n            if  x['interest_level'] == 0.0:\n                if x['manager_id'] not in manager_low_tmp:\n                    manager_low_tmp[x['manager_id']] = 0.0\n                if x['building_id'] not in building_low_tmp:\n                    building_low_tmp[x['building_id']] = 0.0\n                manager_low_tmp[x['manager_id']] += 1\n                building_low_tmp[x['building_id']] += 1\n                low_total += 1.0\n            if  x['interest_level'] == 1:\n                if x['manager_id'] not in manager_medium_tmp:\n                    manager_medium_tmp[x['manager_id']] = 0.0\n                if x['building_id'] not in building_medium_tmp:\n                    building_medium_tmp[x['building_id']] = 0.0\n                manager_medium_tmp[x['manager_id']] += 1\n                building_medium_tmp[x['building_id']] += 1\n                medium_total += 1.0\n            if  x['interest_level'] == 2:\n                if x['manager_id'] not in manager_high_tmp:\n                    manager_high_tmp[x['manager_id']] = 0.0\n                if x['building_id'] not in building_high_tmp:\n                    building_high_tmp[x['building_id']] = 0.0\n                manager_high_tmp[x['manager_id']] += 1\n                building_high_tmp[x['building_id']] += 1\n                high_total += 1.0\n            manager_count[x['manager_id']] += 1.0\n            building_count[x['building_id']] += 1\n            sm += x['interest_level']        \n            ct += 1.0\n        avg = sm / ct        \n        neigh_low = {}\n        neigh_medium = {}\n        neigh_high = {}\n        for i in train_ind:\n            x = train_df.iloc[i]\n            round_lat = round(x['latitude'], 2)\n            round_long = round(x['longitude'], 2)\n            hsh = str(round_lat) + \"#\" + str(round_long)\n            if x['interest_level'] == 0.0:\n                if hsh not in neigh_low:\n                    neigh_low[hsh] = 0.0\n                neigh_low[hsh] += 1\n            if x['interest_level'] == 1:\n                if hsh not in neigh_medium:\n                    neigh_medium[hsh] = 0.0\n                neigh_medium[hsh] += 1\n            if x['interest_level'] == 2:\n                if hsh not in neigh_high:\n                    neigh_high[hsh] = 0.0\n                neigh_high[hsh] += 1        \n        neigh_pct_low_tmp = {}\n        neigh_pct_medium_tmp = {}\n        neigh_pct_high_tmp = {}\n        neigh_count_tmp = {} \n        for i in train_ind:\n            x = train_df.iloc[i]\n            round_lat = round(x['latitude'], 2)\n            round_long = round(x['longitude'], 2)\n            lat_down = round_lat - 0.01\n            lat_up = round_lat + 0.01\n            long_down = round_long - 0.01\n            long_up = round_long + 0.01            \n            low_sum = 0.0    \n            md_sum = 0.0\n            high_sum = 0.0            \n            pos = [str(lat_down) + \"#\" + str(long_down),  \n                   str(round_lat) + \"#\" + str(long_down),  \n                   str(lat_up) + \"#\" + str(long_down), \n                   str(lat_down) + \"#\" + str(round_long),\n                   str(round_lat)  + \"#\" + str(round_long),\n                   str(lat_up) + \"#\" + str(round_long),\n                   str(lat_down)  + \"#\" + str(long_up), \n                   str(round_lat)  + \"#\" + str(long_up),\n                   str(lat_up)+ \"#\" + str(long_up)]\n            for ps in pos:\n                if ps in neigh_low:    \n                    low_sum += neigh_low[ps]\n                if ps in neigh_medium:\n                    md_sum += neigh_medium[ps]\n                if ps in neigh_high:\n                    high_sum += neigh_high[ps]\n            hsh =  str(round_lat)  + \"#\" + str(round_long)\n            neigh_pct_low_tmp[hsh] = low_sum / (low_sum + md_sum + high_sum + 1.0)\n            neigh_pct_medium_tmp[hsh] = md_sum / (low_sum + md_sum + high_sum + 1.0)\n            neigh_pct_high_tmp[hsh] = high_sum / (low_sum + md_sum + high_sum + 1.0) \n            neigh_count_tmp[hsh] = low_sum + md_sum + high_sum                \n        for i in test_ind:\n            x = train_df.iloc[i]\n            manager_id = x['manager_id']      \n            building_id = x['building_id']   \n            round_lat = round(x['latitude'], 2)\n            round_long = round(x['longitude'], 2)\n            hsh =  str(round_lat)  + \"#\" + str(round_long)\n            pct_low[i] = neigh_pct_low_tmp[hsh] if hsh in neigh_pct_low_tmp  else 0.6\n            pct_medium[i] = neigh_pct_medium_tmp[hsh] if hsh in neigh_pct_medium_tmp else 0.3\n            pct_high[i] =   neigh_pct_high_tmp[hsh] if hsh in neigh_pct_high_tmp else 0.1\n            manager_score[i] = manager_sum[manager_id] / manager_count[manager_id] if manager_id in manager_count else avg\n            manager_low[i] = manager_low_tmp[manager_id]  if manager_id in manager_low_tmp else low_total / manager_ct\n            manager_medium[i] = manager_medium_tmp[manager_id] if manager_id in manager_medium_tmp else medium_total / manager_ct\n            manager_high[i] = manager_high_tmp[manager_id] if manager_id in manager_high_tmp  else high_total / manager_ct\n            manager_low_pct[i] = manager_low_tmp[manager_id] / manager_count[manager_id]  if manager_id in manager_low_tmp else low_total / ct\n            manager_medium_pct[i] = manager_medium_tmp[manager_id] / manager_count[manager_id] if manager_id in manager_medium_tmp else medium_total / ct            \n            manager_high_pct[i] = manager_high_tmp[manager_id] / manager_count[manager_id] if manager_id in manager_high_tmp else high_total / ct   \n            neigh_count[i] =  neigh_count_tmp[hsh] if hsh in neigh_count_tmp else 0 \n            building_score[i] = building_sum[building_id] / building_count[building_id] if building_id in building_count else avg\n            building_low[i] = building_low_tmp[building_id] if building_id in building_low_tmp else low_total / building_ct\n            building_medium[i] = building_medium_tmp[building_id] if building_id in building_medium_tmp else medium_total / building_ct\n            building_high[i] = building_high_tmp[building_id] if building_id in building_high_tmp else high_total / building_ct\n            building_low_pct[i] = building_low_tmp[building_id] / building_count[building_id] if building_id in building_low_tmp else 0.6\n            building_medium_pct[i] = building_medium_tmp[building_id] / building_count[building_id] if building_id in building_medium_tmp else 0.3\n            building_high_pct[i] = building_high_tmp[building_id] / building_count[building_id] if building_id in building_high_tmp else 0.1\n    train_df['manager_score'] = manager_score \n    #train_df['manager_low'] = manager_low \n    #train_df['manager_medium'] = manager_medium\n    #train_df['manager_high'] =  manager_high\n    train_df['manager_low_pct'] = manager_low_pct\n    train_df['manager_medium_pct'] = manager_medium_pct\n    train_df['manager_high_pct'] = manager_high_pct\n    train_df['neigh_low_pct'] = pct_low\n    train_df['neigh_medium_pct'] = pct_medium\n    train_df['neigh_high_pct'] = pct_high\n    train_df['neigh_low_ct'] = np.array(pct_low) * np.array(neigh_count)\n    train_df['neigh_medium_ct'] = np.array(pct_medium) * np.array(neigh_count)\n    train_df['neigh_high_ct'] = np.array(pct_high) * np.array(neigh_count)\n    train_df['building_score'] = building_score \n    #train_df['building_low'] = building_low \n    # train_df['building_medium'] = building_medium\n    #train_df['building_high'] =  building_high\n    train_df['building_low_pct'] = building_low_pct\n    train_df['building_medium_pct'] = building_medium_pct\n    train_df['building_high_pct'] = building_high_pct\n    train_index = train_df.index\n    test_index = test_df.index   \n    manager_score = []\n    manager_low = []\n    manager_medium = []\n    manager_high = []\n    manager_low_pct = []\n    manager_medium_pct = []\n    manager_high_pct = []        \n    building_score = []\n    building_low = []\n    building_medium = []\n    building_high = []\n    building_low_pct = []\n    building_medium_pct = []\n    building_high_pct = []\n    pct_low =  []\n    pct_medium =  []\n    pct_high =  []\n    neigh_count = []\n    manager_sum = {}\n    manager_high_tmp = {}\n    manager_medium_tmp = {}\n    manager_low_tmp = {}\n    manager_count = {}\n    building_sum = {}\n    building_count = {}            \n    building_sum = {}\n    building_high_tmp = {}\n    building_medium_tmp = {}\n    building_low_tmp = {}\n    building_count = {}\n    high_total = 0.0\n    medium_total = 0.0\n    low_total = 0.0\n    manager_ct = 0.0 \n    sm = 0.0\n    ct = 0.0        \n    print 'cv statistics computed'\n    for i in range(train_df.shape[0]):\n        x = train_df.iloc[i]\n        if x['manager_id'] not in manager_sum:\n            manager_sum[x['manager_id']] = 0.0\n            manager_count[x['manager_id']] = 0.0\n            manager_ct += 1\n        if x['building_id'] not in building_sum:\n            building_sum[x['building_id']] = 0.0\n            building_count[x['building_id']] = 0.0\n            building_ct += 1\n        building_sum[x['building_id']] += x['interest_level']\n        manager_sum[x['manager_id']] += x['interest_level']\n        if  x['interest_level'] == 0.0:\n            if x['manager_id'] not in manager_low_tmp:\n                manager_low_tmp[x['manager_id']] = 0.0\n            if x['building_id'] not in building_low_tmp:\n                building_low_tmp[x['building_id']] = 0.0\n            manager_low_tmp[x['manager_id']] += 1\n            building_low_tmp[x['building_id']] += 1\n            low_total += 1.0\n        if  x['interest_level'] == 1:\n            if x['manager_id'] not in manager_medium_tmp:\n                manager_medium_tmp[x['manager_id']] = 0.0\n            if x['building_id'] not in building_medium_tmp:\n                building_medium_tmp[x['building_id']] = 0.0\n            manager_medium_tmp[x['manager_id']] += 1\n            building_medium_tmp[x['building_id']] += 1\n            medium_total += 1.0\n        if  x['interest_level'] == 2:\n            if x['manager_id'] not in manager_high_tmp:\n                manager_high_tmp[x['manager_id']] = 0.0\n            if x['building_id'] not in building_high_tmp:\n                building_high_tmp[x['building_id']] = 0.0\n            manager_high_tmp[x['manager_id']] += 1\n            building_high_tmp[x['building_id']] += 1\n            high_total += 1.0\n        manager_count[x['manager_id']] += 1.0\n        building_count[x['building_id']] += 1\n        sm += x['interest_level']        \n        ct += 1.0\n    neigh_low = {}\n    neigh_medium = {}\n    neigh_high = {}\n    for i in train_ind:\n        x = train_df.iloc[i]\n        round_lat = round(x['latitude'], 2)\n        round_long = round(x['longitude'], 2)\n        hsh = str(round_lat) + \"#\" + str(round_long)\n        if x['interest_level'] == 0.0:\n            if hsh not in neigh_low:\n                neigh_low[hsh] = 0.0\n            neigh_low[hsh] += 1\n        if x['interest_level'] == 1:\n            if hsh not in neigh_medium:\n                neigh_medium[hsh] = 0.0\n            neigh_medium[hsh] += 1\n        if x['interest_level'] == 2:\n            if hsh not in neigh_high:\n                neigh_high[hsh] = 0.0\n            neigh_high[hsh] += 1\n    neigh_pct_low_tmp = {}\n    neigh_pct_medium_tmp = {}\n    neigh_pct_high_tmp = {}\n    neigh_count_tmp = {}\n    for i in train_ind:\n        x = train_df.iloc[i]\n        round_lat = round(x['latitude'], 2)\n        round_long = round(x['longitude'], 2)\n        lat_down = round_lat - 0.01\n        lat_up = round_lat + 0.01\n        long_down = round_long - 0.01\n        long_up = round_long + 0.01        \n        low_sum = 0.0    \n        md_sum = 0.0\n        high_sum = 0.0        \n        pos = [str(lat_down) + \"#\" + str(long_down),  \n               str(round_lat) + \"#\" + str(long_down),  \n               str(lat_up) + \"#\" + str(long_down), \n               str(lat_down) + \"#\" + str(round_long),\n               str(round_lat)  + \"#\" + str(round_long),\n               str(lat_up) + \"#\" + str(round_long),\n               str(lat_down)  + \"#\" + str(long_up), \n               str(round_lat)  + \"#\" + str(long_up),\n               str(lat_up)+ \"#\" + str(long_up)]\n        for ps in pos:\n            if ps in neigh_low:    \n                low_sum += neigh_low[ps]\n            if ps in neigh_medium:\n                md_sum += neigh_medium[ps]\n            if ps in neigh_high:\n                high_sum += neigh_high[ps]\n        hsh =  str(round_lat)  + \"#\" + str(round_long)\n        neigh_pct_low_tmp[hsh] = low_sum / (low_sum + md_sum + high_sum + 1.0)\n        neigh_pct_medium_tmp[hsh] = md_sum / (low_sum + md_sum + high_sum + 1.0)\n        neigh_pct_high_tmp[hsh] = high_sum / (low_sum + md_sum + high_sum + 1.0)\n        neigh_count_tmp[hsh] = low_sum + md_sum + high_sum  \n    for index, row in test_df.iterrows():\n        x = row\n        manager_id = row['manager_id']\n        building_id = row['building_id']\n        round_lat = round(x['latitude'], 2)\n        round_long = round(x['longitude'], 2)\n        hsh =  str(round_lat)  + \"#\" + str(round_long)\n        manager_score.append(manager_sum[manager_id] / manager_count[manager_id] if manager_id in manager_count else avg)\n        manager_low.append(manager_low_tmp[manager_id]  if manager_id in manager_low_tmp else low_total / manager_ct)\n        manager_medium.append(manager_medium_tmp[manager_id] if manager_id in manager_medium_tmp else medium_total / manager_ct)\n        manager_high.append(manager_high_tmp[manager_id] if manager_id  in manager_high_tmp  else high_total / manager_ct)\n        manager_low_pct.append(manager_low_tmp[manager_id] / manager_count[manager_id]  if manager_id in manager_low_tmp else low_total / ct)\n        manager_medium_pct.append(manager_medium_tmp[manager_id] / manager_count[manager_id] if manager_id in manager_medium_tmp else medium_total / ct)\n        manager_high_pct.append(manager_high_tmp[manager_id] / manager_count[manager_id] if manager_id in manager_high_tmp else high_total / ct)  \n        pct_low.append(neigh_pct_low_tmp[hsh] if hsh in neigh_pct_low_tmp else 0.6)\n        pct_medium.append(neigh_pct_medium_tmp[hsh] if hsh in neigh_pct_medium_tmp else 0.3)\n        pct_high.append(neigh_pct_high_tmp[hsh] if hsh in neigh_pct_high_tmp else 0.1)\n        neigh_count.append(neigh_count_tmp[hsh] if hsh in neigh_count_tmp else 0)\n        building_score.append(building_sum[building_id] / building_count[building_id] if building_id in building_count else avg)\n        building_low.append(building_low_tmp[building_id] if building_id in building_low_tmp else low_total / building_ct)\n        building_medium.append(building_medium_tmp[building_id] if building_id in building_medium_tmp else medium_total / building_ct)\n        building_high.append(building_high_tmp[building_id] if building_id in building_high_tmp else high_total / building_ct)\n        building_low_pct.append(building_low_tmp[building_id] / building_count[building_id] if building_id in building_low_tmp else 0.6)\n        building_medium_pct.append(building_medium_tmp[building_id] / building_count[building_id] if building_id in building_medium_tmp else 0.3)\n        building_high_pct.append(building_high_tmp[building_id] / building_count[building_id] if building_id in building_high_tmp else 0.1)\n    test_df['manager_score'] = manager_score \n    #test_df['manager_low'] = manager_low \n    #test_df['manager_medium'] = manager_medium\n    #test_df['manager_high'] =  manager_high\n    test_df['manager_low_pct'] = manager_low_pct\n    test_df['manager_medium_pct'] = manager_medium_pct\n    test_df['manager_high_pct'] = manager_high_pct\n    test_df['neigh_low_pct'] = pct_low\n    test_df['neigh_medium_pct'] = pct_medium\n    test_df['neigh_high_pct'] = pct_high\n    test_df['neigh_low_ct'] = np.array(pct_low) * np.array(neigh_count)\n    test_df['neigh_medium_ct'] = np.array(pct_medium) * np.array(neigh_count)\n    test_df['neigh_high_ct'] = np.array(pct_high) * np.array(neigh_count)\n    test_df['building_score'] = building_score \n    #test_df['building_low'] = building_low \n    #test_df['building_medium'] = building_medium\n    #test_df['building_high'] =  building_high\n    test_df['building_low_pct'] = building_low_pct\n    test_df['building_medium_pct'] = building_medium_pct\n    test_df['building_high_pct'] = building_high_pct\n    data_df = pd.concat((train_df, test_df), axis=0)  \n    manager_price = {}\n    manager_count = {}\n    for j in range(data_df.shape[0]):  \n        x=data_df.iloc[j]\n        if x['manager_id'] not in manager_price:\n            manager_price[x['manager_id']] = 0.0\n            manager_count[x['manager_id']] = 0.0\n        manager_price[x['manager_id']] += x['price']\n        manager_count[x['manager_id']] += 1\n    data_df['manager_count'] = data_df['manager_id'].apply(lambda x: manager_count[x])\n    data_df['avg_manager_price'] = data_df['manager_id'].apply(lambda x: manager_price[x] / manager_count[x])\n    # add counting features \n    data_df['num_photos'] = data_df['photos'].apply(len)\n    data_df['num_features'] = data_df['features'].apply(len)\n    data_df['num_description'] = data_df['description'].apply(lambda x: len(x.split(' ')))\n    data_df['num_display_address'] = data_df['display_address'].apply(lambda x: len(x.split(' ')))\n    data_df['num_street_address'] = data_df['street_address'].apply(lambda x: len(x.split(' ')))\n    data_df['photo_description_ratio'] =  data_df['num_photos'] * 1.0 / data_df['num_description']\n    data_df.drop('photos', axis=1, inplace=True)\n    # naive feature engineering\n    data_df['room_difference'] = data_df['bedrooms'] - data_df['bathrooms']\n    data_df['room_ratio'] = data_df['bedrooms'] * 1.0 / data_df['bathrooms']\n    data_df['total_rooms'] = data_df['bedrooms'] + data_df['bathrooms']\n    data_df['price_per_room'] = data_df['price'] / (data_df['total_rooms'] + 1)\n    data_df['price_per_bedroom'] = data_df['price'] / (data_df['bedrooms'] + 1)\n    data_df['price_per_bedroom'] = data_df['price'] / (data_df['bathrooms'] + 1)\n    # add datetime features\n    data_df['created'] = pd.to_datetime(data_df['created'])\n    data_df['c_month'] = data_df['created'].dt.month\n    data_df['c_day'] = data_df['created'].dt.day\n    data_df['c_hour'] = data_df['created'].dt.hour\n    data_df['c_dayofyear'] = data_df['created'].dt.dayofyear\n    data_df['longitude'] = data_df['longitude'].apply(lambda x: round(x, 3))\n    data_df['latitude'] = data_df['latitude'].apply(lambda x: round(x, 3))\n    data_df.drop('created', axis=1, inplace=True)  \n    # encode categorical features\n    for col in ['display_address', 'street_address', 'manager_id', 'building_id']:\n        data_df[col] = LabelEncoder().fit_transform(data_df[col])\n    data_df.drop('description', axis=1, inplace=True)\n    # get text features\n    data_df['features'] = data_df['features'].apply(lambda x: ' '.join(['_'.join(i.split(' ')) for i in x]))\n    textcv = CountVectorizer(stop_words='english', max_features=200)\n    text_features = pd.DataFrame(textcv.fit_transform(data_df['features']).toarray(),\n                                                               columns=['f_' + format(x, '03d') for x in range(1, 201)], index=data_df.index)\n    data_df = pd.concat(objs=(data_df, text_features), axis=1)\n    data_df.drop('features', axis=1, inplace=True)\n    feature_cols = [x for x in data_df.columns if x not in {'interest_level'}]\n    del train_df, test_df\n    return data_df.loc[train_index, feature_cols], data_df.loc[train_index, 'interest_level'],\\\n        data_df.loc[test_index, feature_cols]\n\ntrain = pd.read_json(open(\"train.json\", \"r\"))\ntest = pd.read_json(open(\"test.json\", \"r\"))\ntrain_X, train_y, test_df = preprocess(train, test)\n\ntrain_X.drop('listing_id', axis=1, inplace=True)\nparam = {}\nparam['objective'] = 'multi:softprob'\nparam['eta'] = 0.02\nparam['max_depth'] = 6\nparam['silent'] = 1\nparam['num_class'] = 3\nparam['eval_metric'] = \"mlogloss\"\nparam['min_child_weight'] = 1\nparam['subsample'] = 0.7\nparam['colsample_bytree'] = 0.7\nparam['seed'] = 321\nparam['nthread'] = 4\nparam['num_rounds'] = 2300\n\nprint 'training'\nxgtrain = xgb.DMatrix(train_X, label=train_y)\n#xgb.cv(param, xgtrain, 10000, nfold=3, verbose_eval = True, early_stopping_rounds=10)\n\nmodel = xgb.train(param, xgtrain, 1100, verbose_eval = True)\nlisting_id = test_df['listing_id'].ravel()\ntest_df.drop('listing_id', axis=1, inplace=True)\nxgtest = xgb.DMatrix(test_df)\n\npreds = model.predict(xgtest)\nsub = pd.DataFrame(data = {'listing_id': listing_id})\nsub['low'] = preds[:, 0]\nsub['medium'] = preds[:, 1]\nsub['high'] = preds[:, 2]\nsub.to_csv(\"submission2.csv\", index = False, header = True)\n\n\n# we simply have to run the following code each time we modify the hyperparameters:\nX = cross_validate_lgbm()\n\n\nparam['eta'] = 0.02\nparam['max_depth'] = 6\nparam['silent'] = 1\nparam['num_class'] = 3\nparam['eval_metric'] = \"mlogloss\"\nparam['min_child_weight'] = 1\nparam['subsample'] = 0.0.7\nparam['colsample_bytree'] = 0.0.7\nparam['seed'] = 321\nparam['nthread'] = 4\nparam['num_rounds'] = 2300\nmodel1low = [np.nan]*len(train_X)\nmodel2low = [np.nan]*len(train_X)\nmodel3low = [np.nan]*len(train_X)\nmodel4low = [np.nan]*len(train_X)\nmodel1medium = [np.nan]*len(train_X)\nmodel2medium = [np.nan]*len(train_X)\nmodel3medium = [np.nan]*len(train_X)\nmodel4medium = [np.nan]*len(train_X)\nmodel1high = [np.nan]*len(train_X)\nmodel2high = [np.nan]*len(train_X)\nmodel3high = [np.nan]*len(train_X)\nmodel4high = [np.nan]*len(train_X)\nfor j in range(5):\n    print j \n    index=list(range(train_X.shape[0]))\n    test_ind = index[int((j*train_X.shape[0])/5):int(((j+1)*train_X.shape[0])/5)]\n    train_ind = list(set(index).difference(test_ind))\n    train_Xfold = train_X.iloc[train_ind]\n    train_YFold = train_y.iloc[train_ind]\n    xgtrain = xgb.DMatrix(train_Xfold, label=train_YFold)\n    model = xgb.train(param, xgtrain, 1150, verbose_eval = True)\n    #param['max_depth'] = 5\n    #model2 = xgb.train(param, xgtrain, 1700, verbose_eval = True)\n    model3 = RandomForestClassifier(n_estimators=100)\n    print 'model 2'\n    model3.fit(train_Xfold, train_YFold)    \n    model4 = KNeighborsClassifier(n_neighbors = 25)\n    model4.fit(train_Xfold, train_YFold)    \n    pred1 = model.predict(train_X.iloc[test_ind])\n    #pred2 = model2.predict(train_X.iloc[test_ind])\n    pred3 = model3.predict(train_X.iloc[test_ind])\n    pred4 = model4.predict(train_X.iloc[test_ind])\n    k = 0.0\n    for i, row in test_ind.iterrows():\n        x = pred1[k] \n        #x2 = pred2[k]\n        x3 = pred3[k]\n        x4 = pred4[k]   \n        model1low[i] = x[0]\n        #model2low[i] = x2[0]\n        model3low[i] = x3[0]\n        model4low[i] = x4[0]        \n        model1medium[i] = x[1]\n        #model2medium[i] = x2[1]\n        model3medium[i] = x3[1]\n        model4medium[i] = x4[1]        \n        model1high[i] = x[1]\n        #model2high[i] = x2[1]\n        model3high[i] = x3[1]\n        model4high[i] = x4[1]\n        k += 1\ntrain_X['model1low'] = model1low  \n#train_X['model2low'] = model2low \ntrain_X['model3low'] = model3low \ntrain_X['model4low'] = model4low\ntrain_X['model1medium'] = model1medium\n#train_X['model2medium'] = model2medium\ntrain_X['model3medium'] = model3medium \ntrain_X['model4medium'] = model4medium\ntrain_X['model1high'] = model1high\n#train_X['model2high'] = model2high\ntrain_X['model3high'] = model3high\ntrain_X['model4high'] = model4\nhighlm = LogisticRegression(multi_class='multinomial')\nlm.fit(train_df, label=train_y)preds = lm.predict(xgtest)\nsub = pd.DataFrame(data = {'listing_id': listing_id})\nsub['low'] = preds[:, 0]\nsub['medium'] = preds[:, 1]\nsub['high'] = preds[:, 2]\nsub.to_csv(\"submission3.csv\", index = False, header = True)\n    \n    \n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}