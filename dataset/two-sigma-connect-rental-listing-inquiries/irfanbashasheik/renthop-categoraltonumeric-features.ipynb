{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c59ae77e-c641-9111-0556-536adb50741d"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c2a053-a453-ecca-3c88-6c3f829eadc2"},"outputs":[],"source":"# Read the training and test data\ntrain_df = pd.read_json(\"../input/train.json\")\ntest_df = pd.read_json(\"../input/test.json\")\n\n#Look at the size of test and train data\nprint(\"train data shape: \", train_df.shape[0]);\nprint(\"test data shape: \", test_df.shape[0]);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b6d1def-59ca-733e-77af-b9dce5b1a2e2"},"outputs":[],"source":"def string2numeric_hash(text):\n    import hashlib\n    return int(hashlib.md5(text).hexdigest()[:8], 16)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b49de21-8efe-72fa-8d33-295a0ff0f3c4"},"outputs":[],"source":"# Convert the features like features, photos, description into numeric by computing their length\n# Generate hash for the building_id, manager_id\ntrain_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\ntrain_df[\"num_features\"] = train_df[\"features\"].apply(len)\ntrain_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\ntrain_df[\"building_gen_id\"] = train_df[\"building_id\"].apply(lambda x: x.encode('utf-8'))\ntrain_df[\"building_gen_id\"] = train_df[\"building_gen_id\"].apply(lambda x: string2numeric_hash(x))\ntrain_df[\"manager_gen_id\"] = train_df[\"manager_id\"].apply(lambda x: x.encode('utf-8'))\ntrain_df[\"manager_gen_id\"] = train_df[\"manager_gen_id\"].apply(lambda x: string2numeric_hash(x))\n\n\ntest_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\ntest_df[\"num_features\"] = test_df[\"features\"].apply(len)\ntest_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\ntest_df[\"building_gen_id\"] = test_df[\"building_id\"].apply(lambda x: x.encode('utf-8'))\ntest_df[\"building_gen_id\"] = test_df[\"building_gen_id\"].apply(lambda x: string2numeric_hash(x))\ntest_df[\"manager_gen_id\"] = test_df[\"manager_id\"].apply(lambda x: x.encode('utf-8'))\ntest_df[\"manager_gen_id\"] = test_df[\"manager_gen_id\"].apply(lambda x: string2numeric_hash(x))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9cebd395-adc1-6ee5-edf4-1f3c253ccdad"},"outputs":[],"source":"# Select the features and prepare the Input and target variables\nselected_features = [\"bedrooms\", \"bathrooms\", \"price\", \"num_photos\", \"num_features\", \"num_description_words\", \"building_gen_id\", \"manager_gen_id\"]\n\nX = train_df[selected_features]\nY = train_df[\"interest_level\"]\n\nX.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb647db6-b042-59ca-0078-6d8cbb1b90ac"},"outputs":[],"source":"#Split the input into training and validation sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.33)\n#Pass the input to the algo and calculate the loss\nfrom sklearn.ensemble import RandomForestClassifier\nalgo = RandomForestClassifier(n_estimators=100)\nalgo.fit(X_train, Y_train)\ny_predict_val = algo.predict_proba(X_val)\nfrom sklearn.metrics import log_loss\nlog_loss(Y_val, y_predict_val)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68014419-4d5f-c5a0-1ace-9b00cf1b604f"},"outputs":[],"source":"X_test = test_df[selected_features]\ny_predict_test = algo.predict_proba(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ae05950-d995-f9e4-10fb-ee5e38b2d36a"},"outputs":[],"source":"labels2idx = {label: i for i, label in enumerate(algo.classes_)}\nlabels2idx"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91256dbe-4bd3-9f4b-0f34-c5604e2373fa"},"outputs":[],"source":"sub = pd.DataFrame()\nsub[\"listing_id\"] = test_df[\"listing_id\"]\nfor label in [\"high\", \"medium\", \"low\"]:\n    sub[label] = y_predict_test[:, labels2idx[label]]\nsub.to_csv(\"categoral_numeric.csv\", index=False)\nprint(\"process is done1\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"19703ffc-ffb4-4476-9391-09f76b6a6334"},"source":"**Public Score: 1.29721**"},{"cell_type":"markdown","metadata":{"_cell_guid":"9004766d-8963-08f9-2d4a-340f4b440deb"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8399427-3d6a-56ca-f596-9a94c3ca6d8b"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}