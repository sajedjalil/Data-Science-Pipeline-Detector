{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4f7bf15-d1bb-cace-8f58-2e72369084a5"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"1494d25e-06eb-9e44-edc2-9b0c941ef3e1"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd7eb51d-1fd2-d91e-267b-c7616846831a"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83171af7-d552-60e6-2de9-bafb45d1526f"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.neural_network import MLPClassifier\n#from sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns"},{"cell_type":"markdown","metadata":{"_cell_guid":"1bb2ecea-dd8e-a0f0-218b-8b2f4d754d70"},"source":"# read data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1d8d3fd-fc87-ea48-9a9c-64fc5d25bef7"},"outputs":[],"source":"df = pd.read_json(open(\"../input/train.json\", \"r\"))\n\ndf['response'] = 0.\ndf.loc[df.interest_level=='medium', 'response'] = 0.5\ndf.loc[df.interest_level=='high', 'response'] = 1\ndf['mm']=df['response']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fea7922-7597-f180-421e-353876a5e2a2"},"outputs":[],"source":"print(df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da08c3c8-6150-f7d3-9400-12e399dc1488"},"outputs":[],"source":"#df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d7e5fd3-63c2-290e-fff4-6c12aaafb963"},"outputs":[],"source":"res = 10 # grid size\nmin_n = 30 # minimum size to perform inference\n\n# Define grids\nnx = np.linspace(df.longitude.min(), df.longitude.max(), res)\nny = np.linspace(df.latitude.min(), df.latitude.max(), res)\n# Encode\nY = pd.DataFrame()\nfor i in range(res-1):\n    for j in range(res-1):\n        # Identify listings within the square\n        ix = (df.longitude >= nx[i])&(df.longitude < nx[i+1])&(df.latitude >= ny[j])&(df.latitude < ny[j+1])\n        # Compute mean interest if the number of listings is greated than 'min_n'\n        if ix.sum() > min_n:\n            y = df.loc[ix, :].mean() # mean interest\n            y['n'] = ix.sum() # volume\n            Y = pd.concat([Y, y], axis=1)\n        #print(y['response'])\n            df['mm']=df['mm']+y['response']*ix"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b384315-65e0-baff-a1ee-1e219058b6f9"},"outputs":[],"source":"# Show location coordinates before oulier removal\nfig, ax = plt.subplots(1, 2, figsize=(9,6))\nprint('Length before removing ouliers', len(df))\nax[0].plot(df.longitude, df.latitude, '.');\nax[0].set_title('Before outlier removal');\nax[0].set_xlabel('Longitude');\nax[0].set_ylabel('Latitude');\n# Outlier removal\nfor i in ['latitude', 'longitude']:\n    while(1):\n        \n        x = df[i].median()\n        ix = abs(df[i] - x) > 3*df[i].std()\n        \n        if ix.sum()==0: # no more outliers -> stop\n            break\n        \n        df.loc[ix, i] = np.nan # exclude outliers\n\n# Keep only non-outlier listings\ndf = df.loc[df[['latitude', 'longitude']].isnull().sum(1) == 0, :]\nprint('Length after removing ouliers', len(df))\n# Show location coordinates after outlier removal\nax[1].plot(df.longitude, df.latitude, 'r.');\nax[1].set_title('After outlier removal');\nax[1].set_xlabel('Longitude');\nax[1].set_ylabel('Latitude');"},{"cell_type":"markdown","metadata":{"_cell_guid":"b26d2d9f-47a1-b71a-329d-fdc97decf22d"},"source":"# naive feature engineering"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d04af23a-04d0-9383-8553-0409e8618223"},"outputs":[],"source":"    r = KMeans(20, random_state=1)\n    # Normalize (longitude, latitude) before K-means\n    temp = df[['longitude', 'latitude']].copy()\n    temp['longitude'] = (temp['longitude']-temp['longitude'].mean())/temp['longitude'].std()\n    temp['latitude'] = (temp['latitude']-temp['latitude'].mean())/temp['latitude'].std()\n    # Fit k-means and get labels\n    r.fit(temp[['longitude', 'latitude']])\n    df['labels'] = r.labels_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"003d9942-7ffb-cf58-1fc8-da02c92dd110"},"outputs":[],"source":"df[\"num_photos\"] = df[\"photos\"].apply(len)\ndf[\"num_features\"] = df[\"features\"].apply(len)\ndf[\"num_description_words\"] = df[\"description\"].apply(lambda x: len(x.split(\" \")))\ndf[\"created\"] = pd.to_datetime(df[\"created\"])\ndf[\"created_year\"] = df[\"created\"].dt.year\ndf[\"created_month\"] = df[\"created\"].dt.month\ndf[\"created_day\"] = df[\"created\"].dt.day"},{"cell_type":"markdown","metadata":{"_cell_guid":"fca3e213-36f7-4be2-0245-229b416b5ab3"},"source":"plot the k-mean cluster"},{"cell_type":"markdown","metadata":{"_cell_guid":"b91a5734-06bf-7743-3328-d675104f22ff"},"source":"    # Plot results\n    ncomp=20\n    cols = sns.color_palette(\"Set2\", n_colors=ncomp, desat=.5)\n    cl = [cols[i] for i in r.labels_]\n    area = 12\n    ax[ix].scatter(df.longitude, df.latitude, s=area, c=cl, alpha=0.5);\n    ax[ix].set_title('Number of components: ' + str(20))\n    ax[ix].set_xlabel('Longitude')\n    ax[ix].set_ylabel('Latitude')\n    # Show aggregated volume and interest at each neighborhood\n    x = df.groupby('labels')[['longitude','latitude','response']].mean().sort_values(['response'])\n    x = pd.concat([x, df['labels'].value_counts()], axis=1).sort_values(['response'])\n    cols = sns.color_palette(\"RdBu_r\", ncomp)[::-1]\n    for i in range(20):\n        props = dict(boxstyle='round', facecolor=cols[i], alpha=0.8)\n        ax[ix].text(x.longitude.values[i], x.latitude.values[i], \n                str(np.array(np.round(x.response.values,2), '|S8')[i])+'\\n'+str(np.array(x['labels'].values, '|S8')[i]), \n                fontsize=9, verticalalignment='center', horizontalalignment='center', bbox=props);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e82075da-e02d-30e3-cf18-1178cf40a028"},"outputs":[],"source":"# cheng, if you want to change feature just modify following staff\n#num_feats = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\",\n#             \"num_photos\", \"num_features\", \"num_description_words\",\n#             \"created_year\", \"created_month\", \"created_day\"]\nnum_feats = [\"bathrooms\", \"bedrooms\", \"num_photos\",\"price\",'mm']\nX = df[num_feats]\ny = df[\"interest_level\"]\nX.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"507c0b47-5a0e-0262-9e8a-7fa440fdf892"},"source":"# train model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e7dd858-4296-5cd5-1db6-f93f7a9d07e2"},"outputs":[],"source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1735304b-a29c-c104-75f7-8d47581c885b"},"outputs":[],"source":"#clf=SVC(probability=True)\nclf = RandomForestClassifier(n_estimators=1000)\n#clf=MLPClassifier(hidden_layer_sizes=(10, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nclf.fit(X_train, y_train)\ny_val_pred = clf.predict_proba(X_val)\nlog_loss(y_val, y_val_pred)"},{"cell_type":"markdown","metadata":{"_cell_guid":"128df239-83fa-fbec-1a43-fb55d101bcbf"},"source":"# make prediction"},{"cell_type":"markdown","metadata":{"_cell_guid":"91e8d2e2-77b1-5ce0-6083-985a80076d96"},"source":"df = pd.read_json(open(\"../input/test.json\", \"r\"))\nprint(df.shape)\nr = KMeans(20, random_state=1)\n# Normalize (longitude, latitude) before K-means\ntemp = df[['longitude', 'latitude']].copy()\ntemp['longitude'] = (temp['longitude']-temp['longitude'].mean())/temp['longitude'].std()\ntemp['latitude'] = (temp['latitude']-temp['latitude'].mean())/temp['latitude'].std()\n# Fit k-means and get labels\nr.fit(temp[['longitude', 'latitude']])\ndf['labels'] = r.labels_\n\n\n\n\ndf[\"num_photos\"] = df[\"photos\"].apply(len)\ndf[\"num_features\"] = df[\"features\"].apply(len)\ndf[\"num_description_words\"] = df[\"description\"].apply(lambda x: len(x.split(\" \")))\ndf[\"created\"] = pd.to_datetime(df[\"created\"])\ndf[\"created_year\"] = df[\"created\"].dt.year\ndf[\"created_month\"] = df[\"created\"].dt.month\ndf[\"created_day\"] = df[\"created\"].dt.day\nX = df[num_feats]\n\ny = clf.predict_proba(X)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d07cb69-be32-684c-ef48-a245e291618d"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"0b813509-ec6f-64f9-f017-367c0eebdab7"},"source":"labels2idx = {label: i for i, label in enumerate(clf.classes_)}\nlabels2idx"},{"cell_type":"markdown","metadata":{"_cell_guid":"1f7922de-9997-31df-cc3f-c88d12778ad0"},"source":"sub = pd.DataFrame()\nsub[\"listing_id\"] = df[\"listing_id\"]\nfor label in [\"high\", \"medium\", \"low\"]:\n    sub[label] = y[:, labels2idx[label]]\nsub.to_csv(\"submission_rf.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c16f3d53-4f60-5943-6860-8dfecb83a110"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f27ad02c-067d-2ac2-6aaf-f1befb7452d6"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"a0dc747a-bf19-adb1-de64-984c5cefb0eb"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"318415a9-2d3f-705e-d71d-f9c52498d529"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ef24e7e-b3cf-3ec3-e551-f6778fe3d309"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.neural_network import MLPClassifier\n#from sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns"},{"cell_type":"markdown","metadata":{"_cell_guid":"0e227887-fe7a-2568-3a23-d246b25c0a6c"},"source":"# read data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d8bc0ae-d495-2e7d-8f17-368260a22e43"},"outputs":[],"source":"df = pd.read_json(open(\"../input/train.json\", \"r\"))\n\ndf['response'] = 0.\ndf.loc[df.interest_level=='medium', 'response'] = 0.5\ndf.loc[df.interest_level=='high', 'response'] = 1\ndf['mm']=df['response']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3cbdf973-7bd2-a318-5c8c-a27b81c1318e"},"outputs":[],"source":"print(df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad2e9694-6314-09df-a5c5-3b53f1ebedc6"},"outputs":[],"source":"#df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"809d75df-f5f7-1bcc-6b1d-b217b3ec95b8"},"outputs":[],"source":"res = 10 # grid size\nmin_n = 30 # minimum size to perform inference\n\n# Define grids\nnx = np.linspace(df.longitude.min(), df.longitude.max(), res)\nny = np.linspace(df.latitude.min(), df.latitude.max(), res)\n# Encode\nY = pd.DataFrame()\nfor i in range(res-1):\n    for j in range(res-1):\n        # Identify listings within the square\n        ix = (df.longitude >= nx[i])&(df.longitude < nx[i+1])&(df.latitude >= ny[j])&(df.latitude < ny[j+1])\n        # Compute mean interest if the number of listings is greated than 'min_n'\n        if ix.sum() > min_n:\n            y = df.loc[ix, :].mean() # mean interest\n            y['n'] = ix.sum() # volume\n            Y = pd.concat([Y, y], axis=1)\n        #print(y['response'])\n            df['mm']=df['mm']+y['response']*ix"},{"cell_type":"markdown","metadata":{"_cell_guid":"a1cb8e5d-c037-65a4-ecc4-8541e4ac4ecc"},"source":"# Show location coordinates before oulier removal\nfig, ax = plt.subplots(1, 2, figsize=(9,6))\nprint('Length before removing ouliers', len(df))\nax[0].plot(df.longitude, df.latitude, '.');\nax[0].set_title('Before outlier removal');\nax[0].set_xlabel('Longitude');\nax[0].set_ylabel('Latitude');\n# Outlier removal\nfor i in ['latitude', 'longitude']:\n    while(1):\n        \n        x = df[i].median()\n        ix = abs(df[i] - x) > 3*df[i].std()\n        \n        if ix.sum()==0: # no more outliers -> stop\n            break\n        \n        df.loc[ix, i] = np.nan # exclude outliers\n\n# Keep only non-outlier listings\ndf = df.loc[df[['latitude', 'longitude']].isnull().sum(1) == 0, :]\nprint('Length after removing ouliers', len(df))\n# Show location coordinates after outlier removal\nax[1].plot(df.longitude, df.latitude, 'r.');\nax[1].set_title('After outlier removal');\nax[1].set_xlabel('Longitude');\nax[1].set_ylabel('Latitude');"},{"cell_type":"markdown","metadata":{"_cell_guid":"ef08cb54-9f2c-3c84-5263-ff33e1d9a66c"},"source":"# naive feature engineering"},{"cell_type":"markdown","metadata":{"_cell_guid":"ffa59189-2cfd-301b-f5e7-e4f422eac38b"},"source":"    r = KMeans(20, random_state=1)\n    # Normalize (longitude, latitude) before K-means\n    temp = df[['longitude', 'latitude']].copy()\n    temp['longitude'] = (temp['longitude']-temp['longitude'].mean())/temp['longitude'].std()\n    temp['latitude'] = (temp['latitude']-temp['latitude'].mean())/temp['latitude'].std()\n    # Fit k-means and get labels\n    r.fit(temp[['longitude', 'latitude']])\n    df['labels'] = r.labels_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ef250ef-e826-be6c-9e84-ad50b6b1f4fe"},"outputs":[],"source":"df[\"num_photos\"] = df[\"photos\"].apply(len)\ndf[\"num_features\"] = df[\"features\"].apply(len)\ndf[\"num_description_words\"] = df[\"description\"].apply(lambda x: len(x.split(\" \")))\ndf[\"created\"] = pd.to_datetime(df[\"created\"])\ndf[\"created_year\"] = df[\"created\"].dt.year\ndf[\"created_month\"] = df[\"created\"].dt.month\ndf[\"created_day\"] = df[\"created\"].dt.day"},{"cell_type":"markdown","metadata":{"_cell_guid":"7e58a9e7-92d0-f6c5-ab75-86dd858c0d47"},"source":"plot the k-mean cluster"},{"cell_type":"markdown","metadata":{"_cell_guid":"ebecc8ff-ac6c-566b-0462-4077a30afe57"},"source":"    # Plot results\n    ncomp=20\n    cols = sns.color_palette(\"Set2\", n_colors=ncomp, desat=.5)\n    cl = [cols[i] for i in r.labels_]\n    area = 12\n    ax[ix].scatter(df.longitude, df.latitude, s=area, c=cl, alpha=0.5);\n    ax[ix].set_title('Number of components: ' + str(20))\n    ax[ix].set_xlabel('Longitude')\n    ax[ix].set_ylabel('Latitude')\n    # Show aggregated volume and interest at each neighborhood\n    x = df.groupby('labels')[['longitude','latitude','response']].mean().sort_values(['response'])\n    x = pd.concat([x, df['labels'].value_counts()], axis=1).sort_values(['response'])\n    cols = sns.color_palette(\"RdBu_r\", ncomp)[::-1]\n    for i in range(20):\n        props = dict(boxstyle='round', facecolor=cols[i], alpha=0.8)\n        ax[ix].text(x.longitude.values[i], x.latitude.values[i], \n                str(np.array(np.round(x.response.values,2), '|S8')[i])+'\\n'+str(np.array(x['labels'].values, '|S8')[i]), \n                fontsize=9, verticalalignment='center', horizontalalignment='center', bbox=props);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38eaa531-575c-8042-b92e-e5dde8f02d38"},"outputs":[],"source":"# cheng, if you want to change feature just modify following staff\n#num_feats = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\",\n#             \"num_photos\", \"num_features\", \"num_description_words\",\n#             \"created_year\", \"created_month\", \"created_day\"]\nnum_feats = [\"bathrooms\", \"bedrooms\", \"num_photos\",\"price\",'mm']\nX = df[num_feats]\ny = df[\"interest_level\"]\nX.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"4da1505d-fbdc-b929-d94e-cdab9cfc0545"},"source":"# train model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce649904-0f69-4051-587e-28b845e171b2"},"outputs":[],"source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49303c13-a7fb-739c-f1ae-0df2da727635"},"outputs":[],"source":"#clf=SVC(probability=True)\nclf = RandomForestClassifier(n_estimators=1000)\n#clf=MLPClassifier(hidden_layer_sizes=(10, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nclf.fit(X_train, y_train)\ny_val_pred = clf.predict_proba(X_val)\nlog_loss(y_val, y_val_pred)"},{"cell_type":"markdown","metadata":{"_cell_guid":"cea49d4c-bad9-ffbf-e70f-0cdb46cd810d"},"source":"# make prediction"},{"cell_type":"markdown","metadata":{"_cell_guid":"85d83825-6dd5-5111-1705-3cdae43443b7"},"source":"df = pd.read_json(open(\"../input/test.json\", \"r\"))\nprint(df.shape)\nr = KMeans(20, random_state=1)\n# Normalize (longitude, latitude) before K-means\ntemp = df[['longitude', 'latitude']].copy()\ntemp['longitude'] = (temp['longitude']-temp['longitude'].mean())/temp['longitude'].std()\ntemp['latitude'] = (temp['latitude']-temp['latitude'].mean())/temp['latitude'].std()\n# Fit k-means and get labels\nr.fit(temp[['longitude', 'latitude']])\ndf['labels'] = r.labels_\n\n\n\n\ndf[\"num_photos\"] = df[\"photos\"].apply(len)\ndf[\"num_features\"] = df[\"features\"].apply(len)\ndf[\"num_description_words\"] = df[\"description\"].apply(lambda x: len(x.split(\" \")))\ndf[\"created\"] = pd.to_datetime(df[\"created\"])\ndf[\"created_year\"] = df[\"created\"].dt.year\ndf[\"created_month\"] = df[\"created\"].dt.month\ndf[\"created_day\"] = df[\"created\"].dt.day\nX = df[num_feats]\n\ny = clf.predict_proba(X)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"523fe4fb-ff12-e4a6-24bc-f35bee1886fe"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"bf678b87-1c06-c52f-5dff-fa0a93337cfa"},"source":"labels2idx = {label: i for i, label in enumerate(clf.classes_)}\nlabels2idx"},{"cell_type":"markdown","metadata":{"_cell_guid":"cbbb8254-d502-0f24-ce32-cf0051844831"},"source":"sub = pd.DataFrame()\nsub[\"listing_id\"] = df[\"listing_id\"]\nfor label in [\"high\", \"medium\", \"low\"]:\n    sub[label] = y[:, labels2idx[label]]\nsub.to_csv(\"submission_rf.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9b4c7b5-7a0f-7c99-d783-fd9741f8f708"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}