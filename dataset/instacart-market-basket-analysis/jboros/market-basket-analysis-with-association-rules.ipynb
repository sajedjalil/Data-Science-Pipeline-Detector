{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About MBA with Association Rules\n\nMarket Basket Analysis with Association Rules is a technique that enables one to find sets of items that are often found together within a customer's basket (a transaction) across all orders.\nIt is primarily used in business (albeit recently less so) to create, augument or improve:\n* bundles of products\n* cashier suggestions for in-store clients after a completed product scan but before payment\n* in-store product placement","metadata":{}},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"from zipfile import ZipFile  # working with zipped input\nfrom mlxtend.frequent_patterns import fpgrowth, association_rules  # MBA\nfrom scipy import sparse  # sparse matrices\nimport numpy as np\nimport pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:15:49.591098Z","iopub.execute_input":"2021-09-09T07:15:49.591479Z","iopub.status.idle":"2021-09-09T07:15:49.779306Z","shell.execute_reply.started":"2021-09-09T07:15:49.591399Z","shell.execute_reply":"2021-09-09T07:15:49.778064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading & processing data\n\ndef preDot(text):\n    return text.rsplit('.', 1)[0]\n\nnp.random.seed(73)\npd.options.mode.chained_assignment = None\ndataDict = {}\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        with ZipFile(os.path.join(dirname, filename), 'r') as zipf:\n            unzipped_fn = preDot(filename)\n            with zipf.open(unzipped_fn) as f:\n                dataDict[preDot(unzipped_fn)] = pd.read_csv(f)\n\ntrain_orders = dataDict['orders'][dataDict['orders']['eval_set'] == 'train'].drop('eval_set', axis=1)\nprior_orders = dataDict['orders'][dataDict['orders']['eval_set'] == 'prior'].drop('eval_set', axis=1)\ntest_orders = dataDict['orders'][dataDict['orders']['eval_set'] == 'test'].drop('eval_set', axis=1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T07:15:49.822546Z","iopub.execute_input":"2021-09-09T07:15:49.822963Z","iopub.status.idle":"2021-09-09T07:16:08.458554Z","shell.execute_reply.started":"2021-09-09T07:15:49.822928Z","shell.execute_reply":"2021-09-09T07:16:08.457699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transactional Table Prep","metadata":{}},{"cell_type":"code","source":"# limiting and splitting the dataframe into three relatively equal parts for memory efficiency below\nsmall_train = dataDict['order_products__train'][['order_id', 'product_id']]\nsmall_train_split = (small_train[:461543], small_train[461543:461543*2-1], small_train[461543*2-1:])","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:16:08.459714Z","iopub.execute_input":"2021-09-09T07:16:08.459968Z","iopub.status.idle":"2021-09-09T07:16:08.470287Z","shell.execute_reply.started":"2021-09-09T07:16:08.459945Z","shell.execute_reply":"2021-09-09T07:16:08.469097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# heuristical prep of data\n# use of sparse matrices for memory efficency\n\npivots = []\nfor df in small_train_split:\n    pvt = ~(df.pivot(index='order_id', columns='product_id', values='product_id').isna())\n    pivots.append(pvt.astype(pd.SparseDtype(bool)))\ndel pvt\n\nproduct_cols = sorted(small_train.product_id.unique())","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:16:08.472373Z","iopub.execute_input":"2021-09-09T07:16:08.472783Z","iopub.status.idle":"2021-09-09T07:17:25.563698Z","shell.execute_reply.started":"2021-09-09T07:16:08.472742Z","shell.execute_reply":"2021-09-09T07:17:25.562576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(pivots)):\n    # reindexing to add extra columns and standardize the format for vstack\n    # we sparse them again here b/c otherwise we would end up having regular boolean columns\n    pivots[i] = pivots[i].reindex(columns=product_cols, fill_value=False).astype(pd.SparseDtype(bool))\n    pivots[i] = sparse.csr_matrix(pivots[i])\n# concat vertically\npivots = sparse.vstack(pivots)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:17:25.565219Z","iopub.execute_input":"2021-09-09T07:17:25.565494Z","iopub.status.idle":"2021-09-09T07:18:23.587348Z","shell.execute_reply.started":"2021-09-09T07:17:25.565467Z","shell.execute_reply":"2021-09-09T07:18:23.586377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# re-map and densify for algos\ntruth_table = pd.DataFrame(pivots.todense(), index=small_train.order_id.unique(), columns=product_cols)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:18:23.588565Z","iopub.execute_input":"2021-09-09T07:18:23.588863Z","iopub.status.idle":"2021-09-09T07:18:27.226683Z","shell.execute_reply.started":"2021-09-09T07:18:23.588835Z","shell.execute_reply":"2021-09-09T07:18:27.225916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating Frequent Item Sets","metadata":{"execution":{"iopub.status.busy":"2021-09-05T08:21:53.974983Z","iopub.execute_input":"2021-09-05T08:21:53.975634Z","iopub.status.idle":"2021-09-05T08:21:53.983149Z","shell.execute_reply.started":"2021-09-05T08:21:53.975586Z","shell.execute_reply":"2021-09-05T08:21:53.981868Z"}}},{"cell_type":"markdown","source":"It essentially means removing infrequent itemsets (i.e., those below the minimum support specfied at 5 occurences in the transactional table).\n\nQuestions to keep in mind while mining rules:\n* how to determine the minimum support value?\n* how many item sets / rules should be obtained?\n* what metric to pick for rules? what should be its threshold value?\n* should one focus on account for the the base popularity of antecendents (*confidence*) or should consequents be involved as well (*lift*)?\n\n[Here](https://paginas.fe.up.pt/~ec/files_0506/slides/04_AssociationRules.pdf) one can find a short summary of how association rule mining works.","metadata":{}},{"cell_type":"code","source":"# takes less than a minute to execute\nfrequent_itemsets = fpgrowth(truth_table, min_support=5/len(truth_table), use_colnames=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:43:23.463846Z","iopub.execute_input":"2021-09-09T07:43:23.464159Z","iopub.status.idle":"2021-09-09T07:44:31.772003Z","shell.execute_reply.started":"2021-09-09T07:43:23.464132Z","shell.execute_reply":"2021-09-09T07:44:31.771003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequent_itemsets","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:44:31.774179Z","iopub.execute_input":"2021-09-09T07:44:31.774791Z","iopub.status.idle":"2021-09-09T07:44:31.78978Z","shell.execute_reply.started":"2021-09-09T07:44:31.774741Z","shell.execute_reply":"2021-09-09T07:44:31.789097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating Association Rules","metadata":{}},{"cell_type":"markdown","source":"Setting up rules from item sets with 80% confidence.","metadata":{}},{"cell_type":"code","source":"rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.8)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:44:31.791384Z","iopub.execute_input":"2021-09-09T07:44:31.79163Z","iopub.status.idle":"2021-09-09T07:44:40.714028Z","shell.execute_reply.started":"2021-09-09T07:44:31.791606Z","shell.execute_reply":"2021-09-09T07:44:40.713139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"μ number of consequents:\", rules['consequents'].apply(len).mean())\nrules","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:44:40.71554Z","iopub.execute_input":"2021-09-09T07:44:40.715813Z","iopub.status.idle":"2021-09-09T07:44:40.754324Z","shell.execute_reply.started":"2021-09-09T07:44:40.715788Z","shell.execute_reply":"2021-09-09T07:44:40.753344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# selecting out rules that might potentially not be enhancing\nrules = rules[rules.lift > 1]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:44:40.75557Z","iopub.execute_input":"2021-09-09T07:44:40.755845Z","iopub.status.idle":"2021-09-09T07:44:40.766831Z","shell.execute_reply.started":"2021-09-09T07:44:40.75582Z","shell.execute_reply":"2021-09-09T07:44:40.765866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recommendations","metadata":{}},{"cell_type":"code","source":"# a simplification of the table\nrules_ante_cons = rules[['antecedents', 'consequents']]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:44:40.768032Z","iopub.execute_input":"2021-09-09T07:44:40.768305Z","iopub.status.idle":"2021-09-09T07:44:40.775193Z","shell.execute_reply.started":"2021-09-09T07:44:40.76828Z","shell.execute_reply":"2021-09-09T07:44:40.77421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating customers' baskets\nbaskets = small_train.groupby('order_id')['product_id'].apply(frozenset)\nbaskets.name = \"basket\"  # antecedents","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:44:40.776668Z","iopub.execute_input":"2021-09-09T07:44:40.776934Z","iopub.status.idle":"2021-09-09T07:44:44.345242Z","shell.execute_reply.started":"2021-09-09T07:44:40.776908Z","shell.execute_reply":"2021-09-09T07:44:44.344188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommendations = train_orders.join(baskets, on=\"order_id\")\nrecommendations[\"recommendations\"] = [frozenset() for _ in range(len(recommendations))]","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:44:44.34804Z","iopub.execute_input":"2021-09-09T07:44:44.348354Z","iopub.status.idle":"2021-09-09T07:44:44.418047Z","shell.execute_reply.started":"2021-09-09T07:44:44.348325Z","shell.execute_reply":"2021-09-09T07:44:44.417209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We need to check if antecedents of each rule are **a subset** (<=) of some client's basket, e.g.\n\n```recommendations.loc[frozenset({4605, 21903, 47626, 49683}) <= recommendations.recommendations, \"basket\"]```.","metadata":{"execution":{"iopub.status.busy":"2021-09-04T20:21:15.576808Z","iopub.execute_input":"2021-09-04T20:21:15.577192Z","iopub.status.idle":"2021-09-04T20:21:15.635273Z","shell.execute_reply.started":"2021-09-04T20:21:15.577159Z","shell.execute_reply":"2021-09-04T20:21:15.633881Z"}}},{"cell_type":"code","source":"# computationally-intensive; might require an optimization\nfor idx, antecedent in enumerate(rules_ante_cons[\"antecedents\"]):\n    lookup = antecedent <= recommendations.basket, \"recommendations\"\n    recommendations.loc[lookup] = recommendations.loc[lookup].apply(\n        frozenset.union,\n        args=(rules_ante_cons.loc[idx, \"consequents\"],)\n    )\n# recommendations = recommendations.rename(columns={\"antecedents\": \"basket\"})\n# this may be changed earlier\nrecommendations.loc[:, \"recommendations\"] = recommendations.recommendations - recommendations.basket","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:44:44.41945Z","iopub.execute_input":"2021-09-09T07:44:44.419727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# non-empty recommendations\nnon_empty_recs = recommendations[recommendations.recommendations.apply(bool)]\nprint(\"1 out of approx.\", round(1/(len(non_empty_recs) / len(recommendations))), \"transactions will result in a recommendation being suggested to a customer.\")\n# mapping codes to product names\ndef map_products(codes):\n    if isinstance(codes, pd.Series):\n        return codes.apply(map_products)\n    return frozenset(map(products.get, codes))\n\nproducts = dataDict[\"products\"]\nproducts = products.set_index(\"product_id\")[\"product_name\"].to_dict()\nnon_empty_recs.loc[:, [\"basket\", \"recommendations\"]] = non_empty_recs[[\"basket\", \"recommendations\"]].apply(map_products)\ndisplay(non_empty_recs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Practical single-basket MBA Example","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:17:43.549164Z","iopub.execute_input":"2021-09-05T10:17:43.549609Z","iopub.status.idle":"2021-09-05T10:17:43.557381Z","shell.execute_reply.started":"2021-09-05T10:17:43.549573Z","shell.execute_reply":"2021-09-05T10:17:43.55613Z"}}},{"cell_type":"code","source":"def mba_diagram(sample_basket, sample_recommendation):\n    import matplotlib.pyplot as plt\n\n    def get_text_box_coords(txt):\n        we = plt.Text.get_window_extent(txt, renderer=fig.canvas.get_renderer())\n        return ax.transAxes.inverted().transform(we)\n    def get_rightmost_vmid(box):\n        return box[1][0], (box[0][1] + box[1][1]) / 2\n\n    fig, ax = plt.subplots(figsize=(20,10))\n    title = ax.set_title(\"An illustration of a recommendation system for a sample customer basket\\n(basket ← suggestion)\", fontsize=18)\n    ax.axis('off')\n    basket_txt = ax.text(.05, .95, sample_basket, ha='left', va='top', wrap=True,size=12,\n                  bbox=dict(boxstyle='round,pad=1', fc='w', ec='lightblue'))\n\n    basket_rightmost, basket_vmid = get_rightmost_vmid(get_text_box_coords(basket_txt))\n\n    arrow_txt = ax.text(\n        basket_rightmost*1.4, basket_vmid, \"Add\", ha=\"center\", va=\"center\", size=35,\n        bbox=dict(boxstyle=\"larrow,pad=0.6\", fc=\"lightgreen\", ec=\"g\", lw=2))\n    arrow_rightmost, arrow_vmid = get_rightmost_vmid(get_text_box_coords(arrow_txt))\n\n    recommendation_txt = ax.text(arrow_rightmost * 1.14, arrow_vmid, sample_recommendation, ha='left', va='top', wrap=True, fontsize=25,\n                  bbox=dict(boxstyle='round,pad=1', fc='w', ec='r'))\n    recommendation_txt_pos = recommendation_txt.get_position()\n    recommendation_txt.set_position((\n        recommendation_txt_pos[0],\n        recommendation_txt_pos[1] + (get_text_box_coords(recommendation_txt)[1][1]-get_text_box_coords(recommendation_txt)[0][1]) / 2\n    ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_index = np.random.randint(len(non_empty_recs))\nsample_basket = \"\\n\".join(non_empty_recs.iloc[sample_index].loc[\"basket\"])\nsample_recommendation = \"\\n\".join(non_empty_recs.iloc[sample_index].loc[\"recommendations\"])\nmba_diagram(sample_basket, sample_recommendation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}