{"nbformat_minor":1,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","version":"3.6.3","name":"python","codemirror_mode":{"version":3,"name":"ipython"}}},"nbformat":4,"cells":[{"metadata":{"_uuid":"8f95891dfeff0f64d48d9c136cada2a01df4f2ac","collapsed":true,"_cell_guid":"4996099f-0aa7-4e14-8dcd-05fa84524e4c"},"cell_type":"markdown","source":"# INDEX\n1. Introduction\n2. Data\n3. Preprocessing\n4. Training & Result\n6. Discuss\n\n\n\n# 1. INTRODUCTION\n\nWe executed classification by improving [Simple Keras FastText](https://www.kaggle.com/nzw0301/simple-keras-fasttext-val-loss-0-31) model.\nwe've got significantly high accuracy by improving baseline model by additional feature engineering method(multi n-gram. text mining methods...) & collecting more data.\n\nDuring these process, we had ambitions to utilizing and analyzing the concept of author identification with large corpus of data. \n\n+ Luckily, we obtained  [Toronto Book Corpus](http://yknzhu.wixsite.com/mbweb) (containing lot of books with several authors), so we could check our hypothesis: ’Can we recommend similar author based on one’s sentence or paragraph?’\n\nAccording to our competition and great kernels, many contributors proved that a sentence can be classified to unique author. \nWe interpreted the result of classification as ‘unique writing style of authors’. \n\nLet’s check out if there exists some insights base on the Author and Theme classification with Toronto Book Corpus  dataset.\n\n\n\n# 2. Additional Data\n\nOur data is based on  [Toronto Book Corpus](http://yknzhu.wixsite.com/mbweb).\n\nWe extracted 11,038 books & 16 different genres from corpus. \n\nWe decided to consider only 10 out of 16 genres: We excluded (Themes, Young_Adult,New_Adult, Historical , Other,Vampires) from 16 genres (Adventure, Horror, Mystery, Romance, Themes, Young_Adult,Fantasy ,Humor,New_Adult,Science_fiction,Thriller,Historical , Literature, Other, Teen ,Vampires) because the data of those topic were less then other genre.\n\n\n\n# 3. Preprocessing Data\n\nWe found that there might be no clue for author in some of the books, so we checked if we can access book author or not. We extracted the books author by using Regular Expression.\n\nWe covered two simple rule covers by regular expression :\n    1. There is a sentence starting with 'by' or 'By' in the book\n    2. There is a sentence starting with 'Copyright' in the book\nIn this way, we obtained 2,711 books out of total 11,038 books and finally 1788 authors.\n\n\n## 3-a. How many books are exist in each genre\n \n\n"},{"execution_count":null,"metadata":{"_uuid":"d2774f411c29db00c0869e0eb05ae37674a3c2d6","_kg_hide-input":false,"_cell_guid":"aa977445-536e-4a0f-8bb8-db021d0b2e3b","_kg_hide-output":false,"collapsed":true},"cell_type":"code","outputs":[],"source":"import pickle\nimport matplotlib.pyplot as plt\nimport sys\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n\nD = { 'Adventure': 284, 'Fantasy': 312, 'Horror': 209, 'Humor': 202, 'Literature': 234,\n    'Mystery': 242, 'Romance': 304, 'SF': 350, 'Teen': 286, 'Thriller': 288 }\n\nplt.bar(range(len(D)), D.values(), align='center')\nplt.xticks(range(len(D)), D.keys())\nplt.title(\"Books by Topic\")\nplt.show()\n\ntotal = 0\n\nfor key in D:\n    total += D[key]\n\nprint( \"Total: %d\"%(total) )"},{"metadata":{"_uuid":"65902ddfee771c12f4682982cc276c1fc1e4df6b","_cell_guid":"8696983b-2263-4ecf-9f65-64591b37ff88"},"cell_type":"markdown","source":"## 3-b. How many books an Author wrote"},{"execution_count":null,"metadata":{"_uuid":"99d8324aa1cd00c03661636b71eb9f02a0b583a9","collapsed":true,"_cell_guid":"bbf6a727-2151-406f-92f0-995c5328fd6d"},"cell_type":"code","outputs":[],"source":"import pickle\nimport os,sys,re,shutil\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n\nwith open('../input/book-len/book_dict.pickle', 'rb') as handle:\n    book_dict = pickle.load(handle)\nwrote_list = []\nfor author in book_dict:\n    wrote_list.append( book_dict[author]['num'] )\n\nplt.hist(wrote_list, bins=25)\nplt.title(\"How many books each author wrote (total)\")\nplt.show()\nplt.clf()\n\n#Except 1\nwrote_list.clear()\nfor author in book_dict:\n    if( book_dict[author]['num'] > 2):\n        wrote_list.append( book_dict[author]['num'] )\n\nplt.hist(wrote_list, bins=20)\nplt.title(\"How many books each author wrote (except 1)\")\nplt.show()\nplt.clf()"},{"metadata":{"_uuid":"232e36559831353e1abee69722ef37f3959810bb","_cell_guid":"a2758dcb-cabb-407c-b46c-9ee45e5a35d4"},"cell_type":"markdown","source":"## 3-c. How many lines exist in each book"},{"execution_count":null,"metadata":{"_uuid":"fc740e0f2cf6424482bafbce5ec606df91df0c45","_kg_hide-input":false,"collapsed":true,"_cell_guid":"04e3e97b-013c-421f-a9c2-e1d5637e2c3a"},"cell_type":"code","outputs":[],"source":"\nimport pickle\nimport matplotlib.pyplot as plt\nimport sys\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 5\n\nwith open(\"../input/book-len/book_len.pickle\", \"rb\") as handle:\n    data = pickle.load( handle)\n\ndata= sorted(data)[:-1]\n\nplt.hist(data, bins=100)\nplt.title(\"How many lines exist in each book\")\nplt.show()\nplt.clf()\n"},{"metadata":{"_uuid":"ffe22f438fb4c4b3c842cfad0edcfb2439a7260f","_cell_guid":"259958bf-bb31-404e-a136-d6b693c4799d"},"cell_type":"markdown","source":"There are about 20000 sentence by 3 authors in the original train data. Each author has about 6,000 sentences. \nSo we choose books which has about 6,000(from 5,000 to 10,000) lines from the book corpus.\n\nIn addition, There are multi-topic books in the book corpus. we exclude these books for the convenience. we've got 112 authors. we exclude 5 authors among the authors: 'All authors named in this book', 'Rusty Fischer, author of Zombies Don’t Cry', 'Gavin Chappell James Rhodes Gav Roach', 'Author:', 'Serenity Valley Publishing'.\n\nFinally, we have 110 authors ( 107 from the corpus + 3 from the original data )."},{"execution_count":null,"metadata":{"_uuid":"e10908f7c0696f215ef30bb99db4c3cf4752e6c5","collapsed":true,"_cell_guid":"5dc9e10d-64c7-4182-9ec2-3dadb7a10ea2"},"cell_type":"code","outputs":[],"source":"\nimport pickle\nimport matplotlib.pyplot as plt\nimport sys\nimport operator\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n\nwith open(\"../input/book-len/author_dict.pickle\", \"rb\") as handle:\n    dict_ = pickle.load( handle)\nbook_dict= {}\n\nnew_dict = { \"multi_topic\": 0, \"single_topic\":0, \"above5000_below10000\":0}\ntopic_list = [0] * 10\ncount = []\nauthor_list = []\nfor author in dict_:\n    if(dict_[author][\"total_sentence\"] == dict_[author][\"no_dup_sentence\"]):\n        new_dict[\"single_topic\"] += 1\n        count.append( dict_[author][\"no_dup_sentence\"])\n        if( dict_[author][\"no_dup_sentence\"] > 5000 and dict_[author][\"no_dup_sentence\"] < 10000):\n            new_dict[\"above5000_below10000\"] += 1\n            author_list.append(author)\n    else:\n        new_dict[\"multi_topic\"] += 1\n        \nplt.bar(range(len(new_dict)), new_dict.values(), align='center')\nplt.xticks(range(len(new_dict)), new_dict.keys())\n\nplt.show()\nprint( \"authors: %d\" %(len( author_list)) )\n"},{"metadata":{"_uuid":"e418eeebdf9b2a1e71c659291fa23844ecba8458","_cell_guid":"58aa73af-786f-4ed2-ae01-7b17ffa0e44c"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"f9cdb7570df9ea486703cb42fdf0a0094cd5d15b","_cell_guid":"3cdd96ea-62ca-48ca-9929-762ab10f4cd2"},"cell_type":"markdown","source":"## 3-d. How long each sentence is"},{"execution_count":null,"metadata":{"_uuid":"832e2096cf7938dc1acf4bf456e8daa1acc36aa4","collapsed":true,"_cell_guid":"1b4b5bbd-1adf-4fba-9c8b-b3bfe8f8fabd"},"cell_type":"code","outputs":[],"source":"import os\nimport pickle\nimport matplotlib.pyplot as plt\nimport sys\nimport operator\n\n\nwith open(\"../input/book-len/sent_length_dict.pickle\", \"rb\") as handle:\n    dict_ = pickle.load( handle)\n\n        \nplt.hist(dict_[\"original\"], bins=1000)\nplt.title(\"sentence length (Total) \")\n# Show and clear plot again\nplt.show()\nplt.clf()       \n\nlist_ = []\nfor num in dict_[\"original\"]:\n    if( num < 500 and num > 30):\n        list_.append(num)\nplt.hist(list_, bins=50)\nplt.title(\"sentence length ( 30< x < 500) \")\n# Show and clear plot again\nplt.show()\nplt.clf()         \n\nlist_ = []\nfor num in dict_[\"original\"]:\n    if( num < 300 and num > 30):\n        list_.append(num)\nplt.hist(list_, bins=50)\nplt.title(\"sentence length ( 30< x < 300) \")\n# Show and clear plot again\nplt.show()\nplt.clf()   \n"},{"metadata":{"_uuid":"c0db6935b2fd08c62240f2a719c6c64c3af6ab9d","_cell_guid":"ee59efba-053e-4768-8333-b2fd238dbe00"},"cell_type":"markdown","source":"We exclude sentences less than 30 characters, and more than 300 characters."},{"metadata":{"_uuid":"2c28e689bfec387544d500994e4ac087973c2051","_cell_guid":"073b0ece-650f-4c9f-a7e1-29aae941e9f3"},"cell_type":"markdown","source":"# 4. Training & Result\n\nAfter the preprocessing step, we've got 464,500 sentence with 110 authors.\nwe trained our model with these data, and got a softmax value per each sentence.\n\nTo get author embedding, we sum all softmax vectors labeled with same author. We reduce the dimensionality of the vectors by T-SNE to 2D, and make scatter plots using pyplot. Each topic has different color."},{"metadata":{"_uuid":"c246e33159c53709be4d1edcd1d6c7a578714a14","_kg_hide-input":true,"_cell_guid":"a064b2a9-f45e-4a40-a729-403ef3bbbeba","_kg_hide-output":false,"collapsed":true},"cell_type":"markdown","source":"\n![dd](https://www.kaggle.com/jinsooyeo/images/image-preview/sojong_result7.png)"}]}