{"nbformat_minor":1,"cells":[{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"14d12b8f6e695864a14d404d3de8e0374cc06994","_cell_guid":"7eb55977-219b-47d9-b1b5-6c34fe97fe74"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e5415beaba2997b542af15d9341a09a354825f6d","_cell_guid":"16164bb7-bb03-4ef9-8195-7c407e52e73c"},"outputs":[],"source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nprint ('There are {0} rows and {1} attributes.'.format(train.shape[0], train.shape[1]))\nprint ('There are {0} rows and {1} attributes.'.format(test.shape[0], test.shape[1]))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e8b4bcc4d11b0292b208bff1899c9b80640cba57","_cell_guid":"a4cbfc6b-c2da-4d3f-aa7a-3eae724b28fb"},"outputs":[],"source":"train.info()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"348b247c08b11cbdda957e14c2f9ca26a257c364","_cell_guid":"86309d43-4d16-450c-a58c-c389b417bef2","collapsed":true},"outputs":[],"source":"if len(train['id'].unique()) == train.shape[0]:\n    train.set_index(['id'], drop=False)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"43a5a934e3f8917725f8f12ae7e92f44295c0b7c","_cell_guid":"2cfdde3f-6dc7-4ed0-a65f-2415e600a9df","collapsed":true},"outputs":[],"source":"train_by_author = train.groupby('author')['text'].agg(lambda col: ''.join(col))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b97c3d897e74bb33fa42135c4618303961789ead","_cell_guid":"baae5765-456e-4e6e-8067-4129aa37d90c"},"outputs":[],"source":"import os, re, math\nfrom collections import Counter\nfrom nltk.corpus import stopwords\n\ndef tokenizer(contents):\n#     tokens = [] \n    parse = contents.replace('\"','').replace(',','').replace('.','')\n    tokens = re.sub('[^a-zA-Z0-9]', ' ', parse)\n    tokens = tokens.lower().split()\n    # remove remaining tokens that are not alphabetic\n    tokens = [word for word in tokens if word.isalpha()]\n    # filter out stop words\n    stop_words = set(stopwords.words('english'))\n    tokens = [w for w in tokens if not w in stop_words]\n    # filter out short tokens\n    tokens = [word for word in tokens if len(word) > 2]\n    return tokens\n   \nEAP = tokenizer(train_by_author['EAP'])\nMWS = tokenizer(train_by_author['MWS'])\nHPL = tokenizer(train_by_author['HPL'])\n\nvocab_EAP = Counter(list(EAP))\nvocab_MWS = Counter(list(MWS))\nvocab_HPL = Counter(list(HPL))\n\n# print the size of the vocab\nprint ('EAP: {0}, MWS: {1}, HPL: {2} \\n\\n'.format(len(vocab_EAP), len(vocab_MWS), len(vocab_HPL)))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"1718fe36e16b6812b92949b8c068ab6b66c27c70","_cell_guid":"c2fa4f7e-e54f-45a6-b948-5bb23f524178","collapsed":true},"outputs":[],"source":"def naive_bayes_classifier(x):\n    count = 0\n    prob = 0\n    for val in x:\n        if count == 0:\n#             prob = (math.log(0.33)) + (math.log(val))\n            prob = 0.33 * val\n        else:\n#             prob = prob + (math.log(val))\n            prob = prob * val\n\n        count += 1\n        \n    return prob\n\ndef frequency_prob(x, couter, contents, smoothing):\n    word_counts = []\n    for word in x:\n        word_counts.append((couter.setdefault(word, 0) + (math.pow(10, -200))) / (len(contents) + smoothing))\n        \n    return naive_bayes_classifier(word_counts)\n\nsv_EAP = len(vocab_EAP) * (math.pow(10, -200))\nsv_MWS  = len(vocab_MWS) * (math.pow(10, -200))\nsv_HPL = len(vocab_HPL) * (math.pow(10, -200))\n    \ntrain['sentiment'] = train.apply(lambda row: tokenizer(row['text']), axis=1)\ntrain['EAP'] = train.apply(lambda row: frequency_prob(row['sentiment'], vocab_EAP, EAP, sv_EAP), axis=1) \ntrain['MWS'] = train.apply(lambda row: frequency_prob(row['sentiment'], vocab_MWS, MWS, sv_MWS), axis=1) \ntrain['HPL'] = train.apply(lambda row: frequency_prob(row['sentiment'], vocab_HPL, HPL, sv_HPL), axis=1) "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"c3399adecac15a0a0ed2c2f1ed87afeeb74b2841","_cell_guid":"fab5216f-4060-4cfb-9361-d2e4490f8ba4","collapsed":true},"outputs":[],"source":"def classifier(x, y, z):\n    max_value = max(x, y, z)\n    if x == max_value:\n        return 'EAP'\n    if y == max_value:\n        return 'MWS'\n    else:\n        return 'HPL'\n\ntrain['classifier'] = train.apply(lambda row: classifier(row['EAP'], row['MWS'], row['HPL']), axis=1)"},{"execution_count":null,"cell_type":"code","metadata":{},"outputs":[],"source":"# need to figure it out how to put into right probabilistic values (sum to 1)\ntrain[['EAP', 'MWS', 'HPL']].head(20)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"93ece166f25a40c5d07c38735d2273a417408d43","_cell_guid":"2abcc326-cad5-4b57-ae24-822a86afae65"},"outputs":[],"source":"train['correctly_classified'] = np.where(train['author'] == train['classifier'], 1, 0)\nans = train[['correctly_classified']].values.sum()\nprint ('The accuracy of NB classifier model is {0}/{1}={2}.'.format(ans,\n                                                                   train.shape[0],\n                                                                   100*ans/train.shape[0]))"}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.3","name":"python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}}}