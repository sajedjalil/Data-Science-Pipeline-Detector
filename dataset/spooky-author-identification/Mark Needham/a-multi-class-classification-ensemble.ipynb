{"cells":[{"metadata":{"_cell_guid":"8121adda-2b1a-45a5-80e3-81a0373e5164","_uuid":"95b188bb97330cea434f4c6ec8c5dd4a822e8bfd"},"cell_type":"markdown","source":"I'd read a lot about ensemble models but I've never created one myself so I used this competition as an opportunity to figure out how to do it.\n\n# Libraries\n\nLet's first import our libraries."},{"execution_count":null,"metadata":{"_cell_guid":"638c82e8-b789-4200-a98f-da450455bc42","_uuid":"60276106e569e24cb7f26e4070ee87574cc5af6c","collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import linear_model, metrics\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, KFold\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline","outputs":[]},{"metadata":{"_cell_guid":"2692f1da-62b5-4445-85d9-299fd9406ddd","_uuid":"0c140e5374e7f110627512c767a6b203b9f7cd74"},"cell_type":"markdown","source":"# Load our data\n\nNow we'll read the data into a Pandas dataframe."},{"execution_count":null,"metadata":{"_cell_guid":"c5d2cda6-ccfb-4fac-ad14-87227861b797","_uuid":"5b9d4b7f8a71333908dc5ee578c5fe2dc9ce98e5","collapsed":true},"cell_type":"code","source":"Y_COLUMN = \"author\"\nTEXT_COLUMN = \"text\"\ntrain_df = pd.read_csv(\"../input/train.csv\", usecols=[Y_COLUMN, TEXT_COLUMN])\ntrain_df.head()","outputs":[]},{"metadata":{"_cell_guid":"891a206f-d88a-43d7-9e24-b5f6d1b3d3f9","_uuid":"3d7dcd479c333f8912b92651a40fd8c73e2728e7"},"cell_type":"markdown","source":"So far so good.\n\n# Building our classifiers\n\nNext we'll create a few different classifiers that create different text based features. I quite like sklearn's Pipeline abstraction as it makes it really easy to try out lots of different models. "},{"execution_count":null,"metadata":{"_cell_guid":"4f08e14b-2efe-4132-b258-7f3606d4c753","_uuid":"0552aaf751c576cc19140d109c4ac406204a621e","collapsed":true},"cell_type":"code","source":"tfidf_pipe = Pipeline([\n    ('tfidf', TfidfVectorizer(min_df=3, max_features=None,\n                              strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n                              ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n                              stop_words='english')),\n    ('mnb', MultinomialNB())\n])\n\nunigram_pipe = Pipeline([\n    ('cv', CountVectorizer()),\n    ('mnb', MultinomialNB())\n])\n\nngram_pipe = Pipeline([\n    ('cv', CountVectorizer(ngram_range=(1, 2))),\n    ('mnb', MultinomialNB())\n\n])","outputs":[]},{"metadata":{"_cell_guid":"c14143d8-fcc5-42a4-9e0b-dbe98e849310","_uuid":"5b2ea19648e60a6d1e47d15d19529090f9b9fb05"},"cell_type":"markdown","source":"# Testing our model\n\nNow we'll create a function to test our models. This function is from [Sohier Dane's tutorial](https://www.kaggle.com/sohier/intermediate-tutorial-python/)."},{"execution_count":null,"metadata":{"_cell_guid":"d8abf401-5d55-4722-8eae-0afa7cf3c258","_uuid":"b3434a317e03b1c0e7312d7e82c150e44f6da049","collapsed":true},"cell_type":"code","source":"def test_pipeline(df, nlp_pipeline):\n    y = df[Y_COLUMN].copy()\n    X = pd.Series(df[TEXT_COLUMN])\n    rskf = StratifiedKFold(n_splits=5, random_state=1)\n    losses = []\n    accuracies = []\n    for train_index, test_index in rskf.split(X, y):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        nlp_pipeline.fit(X_train, y_train)\n        losses.append(metrics.log_loss(y_test, nlp_pipeline.predict_proba(X_test)))\n        accuracies.append(metrics.accuracy_score(y_test, nlp_pipeline.predict(X_test)))\n\n    print(\"kfolds log losses: {0}, mean log loss: {1} mean accuracy: {2}\".format(\n        str([str(round(x, 3)) for x in sorted(losses)]),\n        round(np.mean(losses), 3),\n        round(np.mean(accuracies), 3)\n    ))","outputs":[]},{"metadata":{"_cell_guid":"c7f046aa-f4be-4a52-a901-7914bc50fbda","_uuid":"717fbfe95572bfdbd78db3bfe3e05dfabebabd36"},"cell_type":"markdown","source":"Now let's run the test function against our models."},{"execution_count":null,"metadata":{"_cell_guid":"6874b37e-5795-4b62-8bd8-bed9ad2e6ca7","_uuid":"eaabe8bee17ecfb15aa0e7591429271c58c715c9","collapsed":true},"cell_type":"code","source":"test_pipeline(train_df, unigram_pipe)","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"867734f5-e645-4f02-92aa-d288be8b27d6","_uuid":"9936aaea90564026e2cb2eb0499bfd296ce63117","collapsed":true},"cell_type":"code","source":"test_pipeline(train_df, ngram_pipe)","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"59e33736-2ee9-4e75-8ab6-9c7aabd1ac33","_uuid":"5e56ad88c3870db8401dac35b824c0ef328349b9","collapsed":true},"cell_type":"code","source":"test_pipeline(train_df, tfidf_pipe)","outputs":[]},{"metadata":{"_cell_guid":"3378b002-70f2-491e-b5d5-2708f80fee92","_uuid":"6f9614afecc5ea05d05303972535a17707bc10f2"},"cell_type":"markdown","source":"# Building our ensemble model\n\nWe can combine this classifiers together into an ensemble classifier using sklearn's VotingClassifier"},{"execution_count":null,"metadata":{"_cell_guid":"4176d3f9-f61b-41b0-bb79-8ba2464942a0","_uuid":"4d3840e33c189c720b7d110ea462591cf4b86e20","collapsed":true},"cell_type":"code","source":"classifiers = [\n    (\"tfidf\", tfidf_pipe),\n    (\"ngram\", ngram_pipe),\n    (\"unigram\", unigram_pipe),\n]\n\nmixed_pipe = Pipeline([\n    (\"voting\", VotingClassifier(classifiers, voting=\"soft\"))\n])","outputs":[]},{"metadata":{"_cell_guid":"6a353f63-eb91-4816-ac5e-8923413bcfb5","_uuid":"80a24a959c63e8195a37439346da358f160d5da8"},"cell_type":"markdown","source":"Let's see how this one fares:"},{"execution_count":null,"metadata":{"_cell_guid":"ff3d0ca5-ade6-433b-a586-d08473e60aff","_uuid":"27dac729bce2b82c95107d79bd1ee5d47d23bdb6","collapsed":true},"cell_type":"code","source":"test_pipeline(train_df, mixed_pipe)","outputs":[]},{"metadata":{"_cell_guid":"ef6d8607-2af1-4cb0-972f-b3bad25747d2","_uuid":"9c335a0b8883ab780f2a6cc4c2d70f04b8f61e7e"},"cell_type":"markdown","source":"It's an improvement on any of the individual models, but I was curious whether I needed all the individual models in the ensemble model. We can use GridScan to work this out:"},{"execution_count":null,"metadata":{"_cell_guid":"cf14ad1b-bbff-4f98-b506-86ec67808dac","_uuid":"5cd6d5d9253d7d6c3dc74a7ef50a721e7847ee2f","collapsed":true},"cell_type":"code","source":"# This function generates all possible combinations of the classifiers\n# e.g. \n# [0 0 0] all turned off\n# [1 1 1] all turned on\n# [1 0 1] the first and last ones turned on, the middle one turned off\ndef combinations_on_off(num_classifiers):\n    return [[int(x) for x in list(\"{0:0b}\".format(i).zfill(num_classifiers))]\n            for i in range(1, 2 ** num_classifiers)]\n\nparam_grid = dict(\n        voting__weights=combinations_on_off(len(classifiers)),\n)\n\ngrid_search = GridSearchCV(mixed_pipe, param_grid=param_grid, n_jobs=-1, verbose=10, scoring=\"neg_log_loss\")\n\ny = train_df[Y_COLUMN].copy()\nX = pd.Series(train_df[TEXT_COLUMN])\n\ngrid_search.fit(X, y)\n\ncv_results = grid_search.cv_results_\n\nfor mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n    print(params, mean_score)\n\nprint(\"Best score: %0.3f\" % grid_search.best_score_)\nprint(\"Best parameters set:\")\nbest_parameters = grid_search.best_estimator_.get_params()\nfor param_name in sorted(param_grid.keys()):\n    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))","outputs":[]},{"metadata":{"_cell_guid":"daca6d9d-aa0c-40bc-ab21-ab8360d76581","_uuid":"4c621638e51bcc7d3b7a12a36244887cae320bf5"},"cell_type":"markdown","source":"It looks like we can do without the first classifier - tfidf_pipe - in our final model. The next thing to explore is whether we get a better model by giving one of the remaining classifiers greater voting rights in the VotingClassifier."},{"metadata":{"_cell_guid":"1a22a188-6dd3-4084-8c97-6fefb52e7ade","_uuid":"7d6046e78eef46a824070bafb01eb7f56241f1fb"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","file_extension":".py","mimetype":"text/x-python","version":"3.6.3","pygments_lexer":"ipython3"}},"nbformat_minor":1,"nbformat":4}