{"cells":[{"source":"**1. Project objective: **Identify the author of the sentences in the test set.\n\n**2. Dataset:**  Works of fiction written by spooky authors of the public domain: Edgar Allan Poe, HP Lovecraft and Mary Shelley\n\n**3. Initial EDA: **Variable distributions, correlations, etc\n\n**4.Train/Test Split**\n\n**5.Preprocessing performed on Training set:** data types converted, missing data handled, dummy variables created, data parsed for errors\n\n**6.-Initial model created**\n\n**7.-Initial model evaluated appropriately (R^2, RMSE, MAE, or Precision/Recall/F1)**\n\nsome reference: https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb","metadata":{"_uuid":"14e7f4c7d2fefdf41d615db1202a468ab0f2e616","_cell_guid":"0ce6c553-4a20-456f-bdbb-832ef9daaf33"},"cell_type":"markdown"},{"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom textblob import TextBlob\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\n","metadata":{"_uuid":"8808078966f54742cd89bd27e53234b44118cddc","_cell_guid":"1e55867a-f217-4b94-8df0-c30d101e9a8c"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"from keras.preprocessing import sequence\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Embedding\nfrom keras.layers import LSTM","metadata":{"_uuid":"18e02d1efa9af4c3e6f05ecb5aa05c4f19b0dca7","_cell_guid":"3626b583-2adc-446f-9582-489734656c28"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"#Import the train data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest=pd.read_csv(\"../input/test.csv\")\n","metadata":{"collapsed":true,"_uuid":"d6ac454966deb57a5b484345b629dc9d6f282928","_cell_guid":"b8f95573-d48d-4d4f-97d3-7639dc505751"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"train.head()","metadata":{"_uuid":"a90badee36b5a8e2aa66119b6579a666531704f0","_cell_guid":"e2ac0dcc-329e-4019-9f13-1412949b39b7"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"train.author.unique()","metadata":{"_uuid":"6635ff4833d5ff4f9535da86255b85da145b8692","_cell_guid":"115e960b-e80b-4a6c-a5e7-8447d994387d"},"cell_type":"code","outputs":[]},{"source":"id: row id\n\ntext: authors' writings\n\nauthor: The 3 authors in the author column are represented by 'EAP', 'HPL' and 'MWS'\n","metadata":{"_uuid":"476e40c0c3caf33f7da392aa7b269ac2293ff526","_cell_guid":"3dcf3b82-5e07-4f86-ace6-6659733b0b19"},"cell_type":"markdown"},{"source":"**Some Visualizations **","metadata":{"_uuid":"1c21b3138499c7e5be97db3135de9ca1f6ea9213","_cell_guid":"0f3a2397-4a6a-484e-a46a-bbd08640ba46"},"cell_type":"markdown"},{"execution_count":null,"source":"#count the author frequencies of training data\nplt.hist(train.author)\nplt.title(\"Frequency of Authors Occurence\",fontsize=15)\nplt.xticks(np.arange(3),(['Edgar Allen Poe', 'Mary Shelley', 'HP Lovecraft']))\nx_coor = [0,1.8,1]\nfor idx, label in enumerate(train.author.value_counts().index):\n    cnt = train.author.value_counts()[idx]\n    plt.text(x_coor[idx], cnt, str(cnt), color='black', fontweight='bold')","metadata":{"_uuid":"cea93147b4167cacc2aa49fa30bb22df6d33506a","_cell_guid":"095166c7-9458-4345-a1e4-7792ba1ffcaa"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"train_qs = pd.Series(train['text'].tolist()).astype(str)\ndist_train = train_qs.apply(len)\nplt.figure(figsize=(15, 10))\nplt.hist(dist_train, bins=200, range=[0, 200], normed=True,alpha=.7)\nplt.title('Normalized histogram of character count in text', fontsize=15)\nplt.legend()\nplt.xlabel('Number of characters', fontsize=15)\nplt.ylabel('Probability', fontsize=15)","metadata":{"_uuid":"597449d9a8cc96e962fcea4fb136ddf71c3b43fe","_cell_guid":"1800fabd-277e-4584-bb59-8e2176860d5a"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"print('mean num',dist_train.mean(),'\\n','std num', dist_train.std(),'\\n',\n      'min num',dist_train.min(),'\\n','max num', dist_train.max())","metadata":{"scrolled":false,"_uuid":"bf1ab086c882e4997cc0831e379bc520125a902a","_cell_guid":"531095d0-3516-4e1f-acd7-518686d1ae31"},"cell_type":"code","outputs":[]},{"source":"The number of characters in each text ranges from 21 to 4663.","metadata":{"_uuid":"9df1db6c6e5992b2c1b9d5564ac999fd7e3c36dd","_cell_guid":"eea54f97-54ed-4e0f-b615-a20b88dc80ad"},"cell_type":"markdown"},{"execution_count":null,"source":"dist_train = train_qs.apply(lambda x: len(x.split(' ')))\nplt.figure(figsize=(15, 10))\nplt.hist(dist_train, bins=50, range=[0, 50], normed=True,alpha=.7)\nplt.title('Normalised histogram of word count in texts', fontsize=15)\nplt.legend()\nplt.xlabel('Number of words', fontsize=15)\nplt.ylabel('Probability', fontsize=15)\n","metadata":{"_uuid":"bd4d5ab9dc93a41167168f838e0e446e9b0b7fd0","_cell_guid":"4ad5708f-a6eb-49c9-9594-7b7e2d281d92"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"print('mean num',dist_train.mean(),'\\n','std num', dist_train.std(),'\\n',\n      'min num',dist_train.min(),'\\n','max num', dist_train.max())","metadata":{"_uuid":"512bd328c69d3a921ae16f389726e2977dd9ad8d","_cell_guid":"dd4d3c2f-002b-4858-b294-09ee0375e291"},"cell_type":"code","outputs":[]},{"source":"The number of words in each text ranges from 2 to 861.","metadata":{"_uuid":"b4b8511d6b504fe595d8cefcd0b91f38325d83c9","_cell_guid":"fe6cd026-03fa-4e49-bc53-9ac69b7edf83"},"cell_type":"markdown"},{"source":"**Wordclouds**","metadata":{"_uuid":"02b51ca9afd8d9cb10f9b1367c8850f558072cfa","_cell_guid":"f511e48f-4736-455d-a5f6-49aac88df0d7"},"cell_type":"markdown"},{"source":"wordcloud of text of all 3 authors ","metadata":{"_uuid":"1f141e1044bb94db72c89e53c3248177b81b90e3","_cell_guid":"1c8b2011-f2ee-4019-821b-d52d70cc3397"},"cell_type":"markdown"},{"execution_count":null,"source":"from wordcloud import WordCloud\nfrom stop_words import get_stop_words\n\nstop_words = get_stop_words('en')\nstop_words = get_stop_words('english')\ncloud = WordCloud(width=1440, height=1080,stopwords=stop_words).generate(\" \".join(train.text.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud)\nplt.axis('off')","metadata":{"_uuid":"16b0d14eb103ca9833e67b4811dafc60d87cb3c0","_cell_guid":"d387487c-37b5-4fdb-86c3-1c6d7743e2c3"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"","metadata":{"collapsed":true,"_uuid":"2c8e96c779fac7181d4631e04685ab91050cd890","_cell_guid":"87b51fe9-4305-4699-bda9-f368c6215e82"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"#Store the text of each author in a Python list\neap = train[train.author==\"EAP\"][\"text\"].values\nhpl = train[train.author==\"HPL\"][\"text\"].values\nmws = train[train.author==\"MWS\"][\"text\"].values","metadata":{"collapsed":true,"_uuid":"2f288b28b6583dace03d3f804700d0537d6e2259","_cell_guid":"75ad92d9-5877-46ac-8e07-964673abaed4"},"cell_type":"code","outputs":[]},{"source":"Edgar Allen Poe","metadata":{"_uuid":"452b443790630cd622b5ba9bc4b4c730c4b24b93","_cell_guid":"f1719a41-13b7-4d25-b45d-191a31c0a746"},"cell_type":"markdown"},{"execution_count":null,"source":"cloud = WordCloud(width=1440, height=1080,stopwords=stop_words).generate(\" \".join(eap.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud)\nplt.axis('off')","metadata":{"_uuid":"20ae9e4fe4c629770db02631f65163b149b98fd7","_cell_guid":"167cbcc6-1197-47cd-8e18-529d7c9f153c"},"cell_type":"code","outputs":[]},{"source":"HP Lovecraft","metadata":{"_uuid":"35b56e7d2dcdb11e15a735bb1039934da783be94","_cell_guid":"2dbefca1-dea0-4418-8815-7617b8f55abf"},"cell_type":"markdown"},{"execution_count":null,"source":"cloud = WordCloud(width=1440, height=1080,stopwords=stop_words).generate(\" \".join(hpl.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud)\nplt.axis('off')","metadata":{"_uuid":"29f8cc2a3f569d146dd4cb3030bfe114d4e02b66","_cell_guid":"c87900ab-a6ae-4dbe-b727-b73f06f8002a"},"cell_type":"code","outputs":[]},{"source":"Mary Shelley","metadata":{"_uuid":"cc0eb300b60c34712c1c99f83253489fcaaa8b7a","_cell_guid":"a37bcbb8-bede-42b9-9bb4-8d9e752eb725"},"cell_type":"markdown"},{"execution_count":null,"source":"cloud = WordCloud(width=1440, height=1080,stopwords=stop_words).generate(\" \".join(mws.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud)\nplt.axis('off')","metadata":{"_uuid":"35df11ff40ee30f8f7e6ef74be9dc977c596a5a7","_cell_guid":"03a2ef33-dfd1-4f24-840a-b7499f837c3d"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"","metadata":{"collapsed":true,"_uuid":"6364617167b064823bb1b6ef7867ae8698963f97","_cell_guid":"0e6432de-9d52-4732-9246-655a09002ea5"},"cell_type":"code","outputs":[]},{"source":"Preprocessing","metadata":{"_uuid":"b1177c3c6bfd8c00aed699e9f10dd1968c602cdf","_cell_guid":"36917b5d-3283-4f27-a14e-61c7b38a6bef"},"cell_type":"markdown"},{"execution_count":null,"source":"train['author_num']=train['author'].apply({'EAP':0,  'MWS':1,  'HPL':2}.get)","metadata":{"collapsed":true,"_uuid":"a1c9b82eb34332a1f245da0f4ccc0f42013d3568","_cell_guid":"0acb1d18-5aa8-4096-a3e9-ac7c13961496"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"train.head()","metadata":{"_uuid":"b6d3056a51c9f49fec5addbced01d384fab33087","_cell_guid":"5e108737-fae4-4567-a9e2-e861031f0167"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"raw_text_train=train['text'].values\nraw_text_test=test['text'].values\nauthor_train=train['author_num'].values\nnum_labels = len(np.unique(author_train))","metadata":{"collapsed":true,"_uuid":"36e8cbc9e60a215a0035f345c69b4eeb8c811598","_cell_guid":"6d7c0945-9ce1-4f40-a1a4-de85aebc42f7"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"num_labels","metadata":{"_uuid":"35868786086f899e75ef23dda818f83878910434","_cell_guid":"d9e7bbce-9143-40e1-886a-47add9d6b4f1"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":" #text pre-processing\nstop_words = set(stopwords.words('english'))\nstop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\nstemmer = SnowballStemmer('english')\n","metadata":{"collapsed":true,"_uuid":"2a3e064fef287bc55a25e3b6a22b8e5f97b06476","_cell_guid":"8fd783c0-0e8b-4a77-8c9c-ec0de56adf75"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"print (\"pre-processing train docs...\")\nprocessed_train = []\nfor doc in raw_text_train:\n    tokens = word_tokenize(doc)\n    filtered = [word for word in tokens if word not in stop_words]\n    stemmed = [stemmer.stem(word) for word in filtered]\n    processed_train.append(stemmed)","metadata":{"_uuid":"f1e3dfa74eee61c0570ef8bf350779f56bdcc5a1","_cell_guid":"c68da5d0-3692-4529-8783-227cf9754be2"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"print (\"pre-processing test docs...\")\nprocessed_test = []\nfor doc in raw_text_test:\n    tokens = word_tokenize(doc)\n    filtered = [word for word in tokens if word not in stop_words]\n    stemmed = [stemmer.stem(word) for word in filtered]\n    processed_test.append(stemmed)","metadata":{"_uuid":"d9767c8b41771fba2e5c959078d15719b5e30cc5","_cell_guid":"ca9a55e7-523d-4061-ac2f-0948c442d813"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"processed_docs_all = np.concatenate((processed_train, processed_test), axis=0)","metadata":{"collapsed":true,"_uuid":"0009af143a7baf4fd6ac9f5b0512bb2fe95f46ec","_cell_guid":"5f01df4b-81d8-4f50-bb7e-7081ab037eb4"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"\nfrom gensim import corpora\ndictionary = corpora.Dictionary(processed_docs_all)\ndictionary_size = len(dictionary.keys())\nprint (\"dictionary size: \", dictionary_size )\n    #dictionary.save('dictionary.dict')\n    #corpus = [dictionary.doc2bow(doc) for doc in processed_docs]","metadata":{"_uuid":"25dc05893f29f3e60903aa802f0b1709dc0a890e","_cell_guid":"8db681df-c0b1-454b-9816-12268c697649"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"print (\"converting to token ids...\")\nword_id_train, word_id_len = [], []\nfor doc in processed_train:\n    word_ids = [dictionary.token2id[word] for word in doc]\n    word_id_train.append(word_ids)\n    word_id_len.append(len(word_ids))","metadata":{"_uuid":"96e3b5cca99d154bfc7e1a6181d4479e37d0921c","_cell_guid":"2f0f3394-d94b-43ef-af7e-0aec0fb96b03"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"word_id_test, word_ids = [], []\nfor doc in processed_test:\n    word_ids = [dictionary.token2id[word] for word in doc]\n    word_id_test.append(word_ids)\n    word_id_len.append(len(word_ids))","metadata":{"collapsed":true,"_uuid":"8de5c38fcea0cd77d2b4070d5e8ab6b4cc3ec948","_cell_guid":"7bf5feba-94c9-4a3e-9542-5f5f68dbfbb5"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"seq_len = np.round((np.mean(word_id_len) + 2*np.std(word_id_len))).astype(int)","metadata":{"collapsed":true,"_uuid":"6ca7959427f626dcdce8c6b46f81c58cfab55e41","_cell_guid":"3f3324cc-13f2-41e6-92a0-6fcb56bca7c9"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"#pad sequences\nword_id_train = sequence.pad_sequences(np.array(word_id_train), maxlen=seq_len)\nword_id_test = sequence.pad_sequences(np.array(word_id_test), maxlen=seq_len)\ny_train_enc = np_utils.to_categorical(author_train,num_labels)","metadata":{"collapsed":true,"_uuid":"1a6a98c33c19af446b37d73492f74e34ee10af2f","_cell_guid":"de9d0733-46dc-4d75-a937-d524e1b6efed"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"print (\"fitting LSTM ...\")\nmodel = Sequential()\nmodel.add(Embedding(dictionary_size, 128, dropout=0.2))\nmodel.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"_uuid":"a09dd826e07ecdb6943ff46acb6d075545044eeb","_cell_guid":"ceeef2e2-a9ab-48a1-b517-fc8b93f38795"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"model.fit(word_id_train, y_train_enc, nb_epoch=1, batch_size=250, verbose=1)\ntest_pred = model.predict_classes(word_id_test)","metadata":{"_uuid":"50c8fed61218fec3c98332cd481989267f8ee768","_cell_guid":"d0d560e9-b761-489e-829f-421f8b102685"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"test_pred = model.predict_proba(word_id_test)","metadata":{"collapsed":true,"_uuid":"6670064af7a6f20fde0170bebee3f17112c57ae7","_cell_guid":"cac5b43a-a7a0-4d16-8d36-e0fd26346fc4"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"","metadata":{"collapsed":true},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"prob=pd.DataFrame(test_pred,columns=['EAP','HPL','MWS'])","metadata":{},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"prob.shape","metadata":{},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"test.head()","metadata":{"_uuid":"a94a05129833fa57efbe258dcc0e712471592b22","_cell_guid":"dc0561d5-b929-4c6e-8e54-02a8c6fac747"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"submit1=pd.concat([test, prob], axis=1)\ndel submit1['text']","metadata":{"_uuid":"b665e4b20abbe72f8412e36a482f8951405d4ba3","_cell_guid":"c6b2221d-fba4-4b09-874b-91ae7e6d818b"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"submit1.to_csv('./lstm_sentiment.csv', index=True, header=True)","metadata":{"scrolled":true,"_uuid":"166f0023c1fa2169bf8372b8a5009eefb386981d","_cell_guid":"83356ab3-856c-41d8-9ef1-41fe4eed264a"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"\n\n","metadata":{"collapsed":true,"_uuid":"af825bb786391fb80af408a4b13ad6721a450407","_cell_guid":"1264c3a8-5301-48bf-a344-47895c5d6bb3"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"","metadata":{"collapsed":true,"_uuid":"97424b1ed416cd5dcbacb0ae5b1866ac4acc90ae","_cell_guid":"7937bacd-119b-4093-bc0a-1bf3ccfbdeaf"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"","metadata":{"collapsed":true,"_uuid":"af01f7e6dbda713f9e6f4f07f5fe00c4dc4ba559","_cell_guid":"4f602e12-6ebe-45c0-a5b3-d83bc9b934db"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"","metadata":{"collapsed":true,"_uuid":"79c14e6388a1f07a64efa5ab1b774619923c0ebf","_cell_guid":"7be5305f-4184-4b5f-82e1-e1ed14342e75"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"","metadata":{"collapsed":true,"_uuid":"88fedb76b487867466a3c4d389cacdf974d0fe2b","_cell_guid":"9ebfbf6f-daa2-41cc-aefb-81c1fdd89cd2"},"cell_type":"code","outputs":[]},{"execution_count":null,"source":"","metadata":{"collapsed":true,"_uuid":"e41fadf16b4d451080fc7b32b325280ae77f0051","_cell_guid":"f06122da-5128-4f55-8cae-3e19a2647d8c"},"cell_type":"code","outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}