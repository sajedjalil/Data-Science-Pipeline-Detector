{"nbformat_minor":1,"cells":[{"source":"# Benchmarking different Sklearn classifiers\n\nInspired by the sklearn sample code here: http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html\n\n\"This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.\"\n\nIt helps us choose the best classifier for this problem from the different sklearn algos.","cell_type":"markdown","metadata":{"_cell_guid":"9b3f522d-2ea3-4407-86bc-7fd88bcd416a","_uuid":"b5ba1fa166eeca4e37450ab1211e1dbd695e7a72"}},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"3d486dd0-9cc8-4f8f-ac56-7ac12ab60a19","_uuid":"99eb520adf1db66748b8d4931123fc9887562bf4"},"execution_count":null,"source":"import pandas as pd"},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"6d1f1e10-d8e3-4524-902a-43d11bc858a9","_uuid":"b31b32a5919e6a23b31196ec3f8159e6e6de3673"},"execution_count":null,"source":"# Loading in the training data with Pandas\ntrain = pd.read_csv(\"../input/train.csv\")"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"84961f71-bbce-4461-bfff-ca132ca9d80d","_uuid":"e2ecaa7953edd59e7796324336ef34ec9a36e445"},"execution_count":null,"source":"train.head()\nprint(train.groupby('author')['id'].count().sort_values(ascending=False).head())\ntrain.groupby('author')['id'].count().plot(kind='bar',figsize=(16,4))"},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"f8803647-5425-4f81-a241-f143aea31e8e","_uuid":"1ebd34815e652888049b16155f569fe835a6099f"},"execution_count":null,"source":"# convert to dictionary and split into 30% 70%\nimport random"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"1f0160e3-f99a-426f-a8e7-5a81aaba06ce","_uuid":"298e504ea124e1ed9625699f2478b5202c44b5cd"},"execution_count":null,"source":"documents = train.to_dict(orient='records')\nlabels = list(train.author.unique())\nprint(documents[0], labels)"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"6f4a01c9-26f6-4222-b16d-87e36cb75050","_uuid":"b097fa1c81142e7e8dfcbc46a94ecdb1543bdef1"},"execution_count":null,"source":"train_set = []\ntest_set = []\n\n# make sure our sets are balanced take the same amount for each label\nfor label in labels:        \n    partition = int(len(documents) * 0.7)\n    # randomly split documents between test and training\n    random.shuffle(documents)\n    train_set += documents[:partition]\n    test_set += documents[partition:]\n\nprint('training set:', len(train_set),'test set', len(test_set))"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"17fc654b-9077-4c40-b4b0-a9ff09291f9e","_uuid":"1a40c04aa9af48dc1138a6e311ca5685a802bfc1"},"execution_count":null,"source":"# benchmark multiple algos\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.extmath import density\nfrom sklearn import metrics\nfrom time import time\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline"},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"e3a65868-369b-44a2-93d4-1a6c7c007890","_uuid":"1189c60ebfcb679a5f0439f9f83c645dc6e2fc20"},"execution_count":null,"source":"#  map to \n\nopts = dict()\nopts['n_features'] = 2 ** 16\n\nX_train = [x['text'] for x in train_set]\ny_train = [x['author'] for x in train_set]\nX_test = [x['text'] for x in test_set]\ny_test = [x['author'] for x in test_set]\ntarget_names = set(y_train)"},{"source":"Do a little preprocessing: turn the text into vectors and select the most important features using TF-IDF","cell_type":"markdown","metadata":{"_cell_guid":"408028fe-107d-4a94-a534-dedec810dbd9","_uuid":"1689db0340f57407d6ea33d12993c33c671d6330"}},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"6b60508d-e103-429c-9f18-b3aa6525fb84","_uuid":"e39c1b7590b30c5d40792559a1344805b4a5f436"},"execution_count":null,"source":"token_pattern = r\"[a-zA-Z]+\"\nvectorizer = CountVectorizer(token_pattern=token_pattern,\n                             stop_words = 'english',\n                              max_features=None,\n                              max_df=0.5,\n                              ngram_range=(1, 2))\n\nX_train = vectorizer.fit_transform(X_train)\nX_test = vectorizer.transform(X_test)\n\nprint(X_train.shape, X_test.shape)"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"11842a76-05bf-4b29-8d80-37e586b22819","_uuid":"4df21a57ac5d853ed944ac22db7c1b120812249b"},"execution_count":null,"source":"%%time\n\ntfidf = TfidfTransformer(norm='l2')\nX_train = tfidf.fit_transform(X_train)\nX_test = tfidf.transform(X_test)\nprint(\"n_samples: %d, n_features: %d\" % X_train.shape)\nprint()"},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"1e14cc78-00f6-49cb-8653-da6b351bc1f3","_uuid":"b75d5480de7586c8fcb8c451fe6b2dfd9cae96e5"},"execution_count":null,"source":"def trim(s):\n    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n    return s if len(s) <= 80 else s[:77] + \"...\""},{"source":"Define the benchmarking function which takes a classifier as input and outputs the metrics and confusion metrics obtained using the classifier.","cell_type":"markdown","metadata":{"_cell_guid":"478dcbf0-d9e3-4b60-bf9e-e5cd35cac579","_uuid":"dc40016e9c3179eb0cebf65de56ac8b6b0542f67"}},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"b7121733-97fb-4def-bfb3-f3c0eff9db1c","_uuid":"ef18c29621e214452fea4dbf2d3205e8e055cca5"},"execution_count":null,"source":"def benchmark(clf):\n    print('_' * 80)\n    print(\"Training: \")\n    print(clf)\n    t0 = time()\n    clf.fit(X_train, y_train)\n    train_time = time() - t0\n    print(\"train time: %0.3fs\" % train_time)\n\n    t0 = time()\n    pred = clf.predict(X_test)\n    test_time = time() - t0\n    print(\"test time:  %0.3fs\" % test_time)\n\n    score = metrics.accuracy_score(y_test, pred)\n    print(\"accuracy:   %0.3f\" % score)\n\n    if hasattr(clf, 'coef_'):\n        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n        print(\"density: %f\" % density(clf.coef_))\n    \n    print(\"classification report:\")\n    print(metrics.classification_report(y_test, pred,\n                                        target_names=target_names))\n\n    print(\"confusion matrix:\")\n    print(metrics.confusion_matrix(y_test, pred))\n\n    print()\n    clf_descr = str(clf).split('(')[0]\n    return clf_descr, score, train_time, test_time\n\n\n"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"06aa96da-b44b-4cbb-a880-81173f4eef45","scrolled":false,"_uuid":"7e35e2f90707bfa1e3b6ea11792cd81ea4aee8d0"},"execution_count":null,"source":"results = []\nfor clf, name in (\n        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n        (Perceptron(n_iter=50), \"Perceptron\"),\n        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n    print('=' * 80)\n    print(name)\n    results.append(benchmark(clf))\n\nfor penalty in [\"l2\", \"l1\"]:\n    print('=' * 80)\n    print(\"%s penalty\" % penalty.upper())\n    # Train Liblinear model\n    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n                                       tol=1e-3)))\n\n    # Train SGD model\n    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n                                           penalty=penalty)))\n\n# Train SGD with Elastic Net penalty\nprint('=' * 80)\nprint(\"Elastic-Net penalty\")\nresults.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n                                       penalty=\"elasticnet\")))\n\n# Train NearestCentroid without threshold\nprint('=' * 80)\nprint(\"NearestCentroid (aka Rocchio classifier)\")\nresults.append(benchmark(NearestCentroid()))\n\n# Train sparse Naive Bayes classifiers\nprint('=' * 80)\nprint(\"Naive Bayes\")\nresults.append(benchmark(MultinomialNB(alpha=.01)))\nresults.append(benchmark(BernoulliNB(alpha=.01)))\n\nprint('=' * 80)\nprint(\"LinearSVC with L1-based feature selection\")\n# The smaller C, the stronger the regularization.\n# The more regularization, the more sparsity.\nresults.append(benchmark(Pipeline([\n  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n                                                  tol=1e-3))),\n  ('classification', LinearSVC(penalty=\"l2\"))])))"},{"source":"## Plot the results","cell_type":"markdown","metadata":{"_cell_guid":"759da6e6-c4fc-4da2-af41-f0911de659ce","_uuid":"e67b0c62e9aa88e5bc15c725feb82c5321ee6b16"}},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"35571d1b-128e-402c-b954-50cc68b7aa0d","_uuid":"54129030c04a613edd0443528b599fea31775b5b"},"execution_count":null,"source":"# make some plots\n\nindices = np.arange(len(results))\n\nresults = [[x[i] for x in results] for i in range(4)]\n\nclf_names, score, training_time, test_time = results\ntraining_time = np.array(training_time) / np.max(training_time)\ntest_time = np.array(test_time) / np.max(test_time)\n\nplt.figure(figsize=(12, 8))\nplt.title(\"Score\")\nplt.barh(indices, score, .2, label=\"score\", color='navy')\nplt.barh(indices + .3, training_time, .2, label=\"training time\",\n         color='c')\nplt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\nplt.yticks(())\nplt.legend(loc='best')\nplt.subplots_adjust(left=.25)\nplt.subplots_adjust(top=.95)\nplt.subplots_adjust(bottom=.05)\n\nfor i, c in zip(indices, clf_names):\n    plt.text(-.3, i, c)\n\nplt.show()"},{"source":"","cell_type":"markdown","metadata":{"collapsed":true,"_cell_guid":"1dbe78a4-ebb5-4b7f-85c1-96d699e7075e","_uuid":"4d70a388708615c8a8bc9dea58da718bba6edd82"}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","version":"3.6.3","name":"python","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python"}},"nbformat":4}