{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"version":"3.6.3","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python","name":"python"}},"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"02adde30-2633-41f1-a672-af8ff83a1b02","_uuid":"22754d0cc0847be93bf947c7998d7fb65a2817d7"},"source":"**Objective of the competition:**\n\nThe competition dataset contains text from works of fiction written by spooky authors of the public domain: \n 1. Edgar Allan Poe (EAP)\n 2. HP Lovecraft (HPL)\n 3. Mary Wollstonecraft Shelley (MWS)\n \nThe objective  is to accurately identify the author of the sentences in the test set.\n\n**Objective of the notebook:**\n\nIn this notebook, we discover lime explorer package to understand the predictions and checking some examples with lime explainer package. Lime explainer is based on this research paper https://arxiv.org/abs/1602.04938 and supported by H2Oai. Lime explainer mission is to help human to understand decisions made by machine learning. Basically, lime explainer create a local linear model around the prediction and try to explain factor influence.\n\nYou can download lime explainer here\nhttps://github.com/marcotcr/lime\n\nLime: Explaining the predictions of any machine learning classifier.\nFor the moment, lime explainer packages are not installed into docker python image. How to ask an docker image upgrage ? \n"},{"cell_type":"code","metadata":{"_cell_guid":"b31f62fb-bde8-410e-972c-3c092f22d497","_uuid":"0fcdf81ce439d2215892af58f839edfc0ca80a91","collapsed":true},"outputs":[],"execution_count":null,"source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import ensemble, metrics, model_selection, naive_bayes\nfrom sklearn.pipeline import make_pipeline\n\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\nimport itertools  \n%matplotlib inline\nimport warnings\nwarnings.simplefilter('ignore')\n"},{"cell_type":"code","metadata":{"_cell_guid":"dfed78e1-76c8-4042-8cb4-62d7b0c62c79","_uuid":"a40aa2abe5e7f878b49fedcdb1a7fe9b0078483f","collapsed":true},"outputs":[],"execution_count":null,"source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"3f69fb4e-c75b-4bc0-bc19-77a17c01e537","_uuid":"5f7695a251ed13a94a88e7375fdd1ff50a1ec236"},"source":"# Explainer with basic model"},{"cell_type":"markdown","metadata":{"_cell_guid":"9608de00-cc2b-4397-8513-9c547378afe2","_uuid":"bd0d5250163be5ca113227c26adb85c7442edc9f"},"source":"## Using explainer with tfdif vectorizer"},{"cell_type":"markdown","metadata":{"_cell_guid":"45e4ac6f-6dfa-469d-b1e0-4d8a9071e05f","_uuid":"25179c62732db71989de659503e8e47b7c13f3e6"},"source":"In this section, we implement a basic model based on naive bayes to show how to use Lime. For the example, we use tfidf vectorizer (it could be also countvectorizer)."},{"cell_type":"code","metadata":{"_cell_guid":"338c2ee4-77cb-43f9-917e-f8ebbe7d6a6a","_uuid":"a2556d493a9de8d971df88f0a7fd8d5a6f62c0cb","collapsed":true},"outputs":[],"execution_count":null,"source":"class_names = ['EAP', 'HPL', 'MWS']\ncols_to_drop = ['id', 'text']\ntrain_X = train_df.drop(cols_to_drop+['author'], axis=1)\n\n## Prepare the data for modeling ###\nauthor_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\ntrain_y = train_df['author'].map(author_mapping_dict)\ntrain_id = train_df['id'].values\n"},{"cell_type":"code","metadata":{"_cell_guid":"69a1d93f-fd34-46bb-a05f-6c11f2aa27a7","_uuid":"d25f6139b753f93c0a1b59b5902779561ff77a64","collapsed":true},"outputs":[],"execution_count":null,"source":"tfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='char')\nfull_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())"},{"cell_type":"code","metadata":{"_cell_guid":"56a736cd-bd79-4b20-a813-4ce69724f57b","_uuid":"d9a30792adb9cd59e43f8aacb687d9d912648c95"},"outputs":[],"execution_count":null,"source":"X_train, X_test, y_train, y_test = train_test_split(train_tfidf, train_y, test_size=0.33, random_state=14)\nmodel_tf = naive_bayes.MultinomialNB()\nmodel_tf.fit(X_train, y_train)"},{"cell_type":"code","metadata":{"_cell_guid":"b66b9f39-de04-40d9-9d04-723baaaa6dd3","_uuid":"015324bf28cdb3c3ab185698d3fd8daafb7e41a2","collapsed":true},"outputs":[],"execution_count":null,"source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')"},{"cell_type":"code","metadata":{"_cell_guid":"5ab49bec-3340-4f1e-828d-fed90fbcb17a","_uuid":"41d9c7914cf99b06345586ccf5cf5cb2afbc834d"},"outputs":[],"execution_count":null,"source":"y_pred = model_tf.predict(X_test)\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, without normalization')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"2b40c7d8-42c0-4c09-bb78-a4a377e59b1a","_uuid":"61cf5985f2246f3da6feefe9e9578ab73d87905e"},"source":"# Preparing lime explainer"},{"cell_type":"code","metadata":{"_cell_guid":"d0b0c432-a4d8-4aa6-a647-43fcad017813","_uuid":"39f23f3f7c4fc60c8d39172d37bbe6b30975d1e3","collapsed":true},"outputs":[],"execution_count":null,"source":"c_tf = make_pipeline(tfidf_vec, model_tf)\nexplainer_tf = LimeTextExplainer(class_names=class_names)"},{"cell_type":"code","metadata":{"_cell_guid":"2e6aeeb7-5f66-4bf4-91bb-14f99d5e30c8","_uuid":"9276bf6d4e994ab22829abd1dfaff9de56b841c1","collapsed":true},"outputs":[],"execution_count":null,"source":"comp = y_test.to_frame()\ncomp['idx'] = comp.index.values\ncomp['pred'] = y_pred\ncomp.rename(columns={'author': 'real'}, inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c5138e41-d0f7-451a-82f4-8dad9ba5651e","_uuid":"20caa4173039c78c88ab6e00d452d2f46cf3b0ab"},"source":"This is the comparison matrix showing predicted and real classes."},{"cell_type":"markdown","metadata":{"_cell_guid":"ec4b56c7-dd1e-48f0-aa75-c29363f9c990","_uuid":"ede871b776583695856070a65eb7c368e7fcca0c"},"source":"# Explaining errors"},{"cell_type":"markdown","metadata":{"_cell_guid":"bd999453-d2d0-4d99-9075-94db2b8f6928","_uuid":"fe599d3f1e3f996829e91860bbcb825c1c1da5df"},"source":"## True POE but classified in HPL"},{"cell_type":"code","metadata":{"_cell_guid":"5bcd77bb-d64b-424b-ad15-1c06ec431d40","_uuid":"4df1a63bd15fa207862c075977d6ad4a1be113e0"},"outputs":[],"execution_count":null,"source":"wrong_poe_hpl = comp[(comp.real ==0) & (comp.pred ==1)]\nwrong_poe_hpl.shape\nprint(wrong_poe_hpl.idx)\nidx = wrong_poe_hpl.idx.iloc[1]"},{"cell_type":"markdown","metadata":{"_cell_guid":"33d8c0c0-4c25-4c0b-92f0-13a095abc925","_uuid":"5bfd01e237e3aac133c50ee762a2de96d25776a7"},"source":"OK, we got 4 as shown by the confusion matrix above."},{"cell_type":"markdown","metadata":{"_cell_guid":"425959b0-0985-4ea4-af32-d2d4072259bc","_uuid":"2ec866692194d689c238443b20d3bcf18e2f2d6c"},"source":"**Using Lime explainer.**"},{"cell_type":"code","metadata":{"_cell_guid":"2c0bc9dc-a26d-4b82-ab31-c793baf3d6ca","_uuid":"71af3aab9a7d4826c62bdd7817e48ed025536396"},"outputs":[],"execution_count":null,"source":"exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=2)\nexp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"},{"cell_type":"markdown","metadata":{"_cell_guid":"9e09ca3f-d809-4cf1-9b54-f3a3bb560132","_uuid":"17bcbd2da817bfa0c6809949802bb8001acc2965"},"source":"**This error is created by the use of ancient greek words. Possible to improve the model ? **"},{"cell_type":"code","metadata":{"_cell_guid":"6d8e9b24-f76d-44ea-b0e6-313c2f22812e","_uuid":"941ff8e46f7baecfa121bb94a2bb5a3e48693592"},"outputs":[],"execution_count":null,"source":"idx = wrong_poe_hpl.idx.iloc[3]\nexp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=2)\nexp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"},{"cell_type":"markdown","metadata":{"_cell_guid":"34ca22be-8f2d-40d2-93d3-86f92253308f","_uuid":"42803ad38654a06c7df11a1292fda5ffc405f5c9"},"source":"**OK, very difficult case. Only three words > Not enough to properly classify. No improvement possible.**"},{"cell_type":"markdown","metadata":{"_cell_guid":"7ff950ac-9c84-4921-ac8b-4146c5621bb6","_uuid":"c3106c0c2ac1a748d1fdebe7aa0ea261d814e0fe"},"source":"# True POE but classified in MWS"},{"cell_type":"code","metadata":{"_cell_guid":"7af0e1cf-48ac-4791-8a59-59f7b6b7a598","_uuid":"4bdcc2b14dca1b6006270f275d51dbbac9edb0fb"},"outputs":[],"execution_count":null,"source":"wrong_poe_mws = comp[(comp.real ==0) & (comp.pred ==2)]\nprint(wrong_poe_mws.shape)\nidx = wrong_poe_mws.idx.iloc[12]"},{"cell_type":"code","metadata":{"_cell_guid":"4549ff55-7cfe-463f-90d0-7ed9ec31a040","_uuid":"f63649cfd44732b75515f5f2bfdd95ed1691b592"},"outputs":[],"execution_count":null,"source":"exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\nexp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"},{"cell_type":"markdown","metadata":{"_cell_guid":"a280df74-915a-4a94-8aef-ea8b3c378749","_uuid":"ba58ff5965edd116eba01fbbe78c496ff050fec1"},"source":"**OK, this text contains anaphora, possible to improve the model with anaphora feature.**"},{"cell_type":"code","metadata":{"_cell_guid":"3b9a6f8b-13e2-4972-b75b-643be16ce976","_uuid":"63b8afc39989fae0324574fc0aee66405ce300b1"},"outputs":[],"execution_count":null,"source":"idx = wrong_poe_mws.idx.iloc[18]\nexp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\nexp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"53e0abf0-cbef-40f2-a1f3-c4d07e047562","_uuid":"1ce6bf195df6511ea16739b4d6e67882db12aedb"},"source":"**OK, probabilities (EAP and MWS) are very close. Possible to improve the model.**"},{"cell_type":"markdown","metadata":{"_cell_guid":"9e89d235-1e75-408c-a0e1-4e3d0208826b","_uuid":"5b85834833a47aea1ebfbb49c30165dd85dc6312"},"source":"# True MWS but classified in HPL"},{"cell_type":"code","metadata":{"_cell_guid":"3b678712-de13-4924-b8e2-4e18744258d7","_uuid":"31ddbbc392c978c1b0f5a79f26d8328e9c84b46d"},"outputs":[],"execution_count":null,"source":"wrong_mws_hpl = comp[(comp.real ==2) & (comp.pred ==1)]\nprint(wrong_mws_hpl.shape)\nidx = wrong_mws_hpl.idx.iloc[8]"},{"cell_type":"code","metadata":{"_cell_guid":"d2296f71-406d-4eb1-a02e-3e7501745a8a","_uuid":"2a8f8f8353cf8cc3d78f0f3bf729d07321765795"},"outputs":[],"execution_count":null,"source":"exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\nexp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"a5ccbc33-52de-4cf0-b862-7fef62327d5c","_uuid":"4623511c45c0bb49dd181afd941c77529deb00e9"},"source":"**OK, probabilities (HPL and MWS) are very close. Possible to improve the model.**"},{"cell_type":"code","metadata":{"_cell_guid":"337753c3-da01-4871-9182-4f7fb75cc2d0","_uuid":"afd5810cd7c82dd706bde2d9acc738473747b96e"},"outputs":[],"execution_count":null,"source":"idx = wrong_mws_hpl.idx.iloc[5]\nexp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\nexp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"45404814-a361-4529-b47c-4e374fb56e15","_uuid":"daf03f54f7c6ed95ce5ce576cfdcc70592b6dd71"},"source":"**OK, probabilities (EAP, HPL, MWS ) are all very close. Possible to improve the model (using repetition pattern ?).**"},{"cell_type":"markdown","metadata":{"_cell_guid":"1dedaf5c-9c9b-4af3-9f69-3636376c6cc1","_uuid":"6d753f6de3f0b29c9acbdc46ccb826334abe80f1"},"source":"# Conclusions and future steps"},{"cell_type":"markdown","metadata":{"_cell_guid":"fcb5ac14-2655-473c-a3fb-1e22d62010f7","_uuid":"a2eafe18ada2f94c6c907c37144dd39dc76cb96d"},"source":"It is easy with lime explorer to understand why the model is mistaken.\nNext steps are to extract bad features and creating new features to improve the model but it is a long and difficult work. \n**That's why I need your help ! **"},{"cell_type":"code","metadata":{"_cell_guid":"83cce447-2c4f-44f0-8d51-1ddc6544b140","_uuid":"8e1c674fd8efca5d7bb66e535f351465ff6e2512","collapsed":true},"outputs":[],"execution_count":null,"source":""}]}