{"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"metadata":{"_uuid":"f13c617f9d6752189e26b41dc60aeb38ea61ddb6","_cell_guid":"33dcffc7-63e8-4f35-bd69-e9e9f2fffa36"},"execution_count":null,"cell_type":"code"},{"source":"df = pd.read_csv('../input/train.csv')","outputs":[],"metadata":{"_uuid":"6e61e47927ad7ad937c197bc1f1cd4a91432f89d","_cell_guid":"6c3b934d-ab00-453d-9a1f-0ab845a1e0a1","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"df","outputs":[],"metadata":{"_uuid":"8e8cf652ed253c0d0eecf487d8593819e3e780e2","_cell_guid":"0b2fc296-c613-4b6c-a006-70f003e38e5b"},"execution_count":null,"cell_type":"code"},{"source":"df['text'] = [x.replace(',', ' , ') for x in df['text']]\ndf['text'] = [x.replace(\"'\", \" ' \") for x in df['text']]\ndf['text'] = [x.replace(\".\", \" . \") for x in df['text']]\ndf","outputs":[],"metadata":{"_uuid":"c029e3a9b23d8d3e5b509f05dbe174b357913828","_cell_guid":"a3eee5b7-23a5-4f21-8fbb-898b51ade547"},"execution_count":null,"cell_type":"code"},{"source":"import gensim\nsentences = [x.split() for x in df['text']]\nmodel_w2v = gensim.models.Word2Vec(sentences, min_count=1)","outputs":[],"metadata":{"_uuid":"046cfa8a4b9a7bdc43c5b385395a80810c0e6708","_cell_guid":"af9c9f2e-e2fb-4812-9188-a02bdc0645aa","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#sentences[:3]\nprint(model_w2v.wv.most_similar(positive=['heart']))\nprint(len(model_w2v.wv['heart']))","outputs":[],"metadata":{"_uuid":"892e6ee2eb426f2716ef569999d99c43211089d5","_cell_guid":"87bff86b-d014-4e86-83e5-021b64b487b4"},"execution_count":null,"cell_type":"code"},{"source":"df['words'] = [x.split() for x in df['text']]\nw2v = []\nzerovec = 100*[0]\nmax_length = 256\n\nfor x in df['words']:\n    vec = []\n    #print(len(x))\n    for w in x[:max_length]:\n        vec.extend(model_w2v.wv[w])\n    #print(len(vec))\n    remaining = max_length*100 - len(vec)\n    if remaining > 0 :\n        padding = remaining*[0]\n        vec.extend(padding)\n        w2v.append(vec)\n    elif remaining > 0 :\n        w2v.append(vec[:max_length])\n    else :\n        w2v.append(vec)","outputs":[],"metadata":{"_uuid":"27544ba90a6ff661d63c1543b1663f0432ef3661","_cell_guid":"6b99a9a8-e329-45cf-b25d-7db4423ec93b","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"print(len(w2v[0]))","outputs":[],"metadata":{"_uuid":"559b5d0286d82cd9a8133c5e5d8084283ac1cf6d","_cell_guid":"1b9b84b3-2b11-4742-8214-a3b175255f2e"},"execution_count":null,"cell_type":"code"},{"source":"from keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding\n#vocab_size = 500\n#df['encoded_text'] = [one_hot(x, vocab_size) for x in df['text']]\nprint(len(w2v))\nprint(len(w2v[0]))","outputs":[],"metadata":{"_uuid":"0414a755f74e61a538524a0cd4238c00789bcbe5","_cell_guid":"4a36167d-2637-4d94-91a4-fb57dc14d10d"},"execution_count":null,"cell_type":"code"},{"source":"# pad documents to a max length of 4 words\n#max_length = 256000\n#padded_text = pad_sequences(w2v, maxlen=max_length, padding='post')\nclass PaddedText2Vec(object):\n    def __init__(self, t2v, maxlen):\n        self.t2v = t2v\n        self.maxlen = maxlen\n \n    def __iter__(self):\n        for v in self.t2v:\n            remaining = self.maxlen - len(v)\n            if remaining > 0 :\n                padding = remaining*[0]\n                v.extend(padding)\n                yield v\n            elif remaining > 0 :\n                yield v[:self.maxlen]\n            else :\n                yield v","outputs":[],"metadata":{"_uuid":"6521abffd5ec504005c0bc6ff523ccc572fa1f71","_cell_guid":"17b78d45-8f29-4924-b723-586864069100","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#paddedt2v = PaddedText2Vec(w2v, 256000)","outputs":[],"metadata":{"_uuid":"651e1cf9e8e5f05954296edbb9cd0966db86944f","_cell_guid":"bfbb1a6e-082a-4c3d-bf1e-8cbef0e734b2","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#for x in paddedt2v:\n#    print(len(x))\n#    break","outputs":[],"metadata":{"_uuid":"d04c59db44620a0615f3c35c5b71bad02ca3a5da","_cell_guid":"a463b4d6-cd4e-4e7a-9da6-f9814b78a37d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from keras import regularizers, optimizers\nfrom keras.layers import BatchNormalization\n# define the model\nmax_length = 256\nmodel = Sequential()\nmodel.add(Dense(150, input_shape=(max_length*100,)))\n#model.add(Embedding(vocab_size, 100, input_length=max_length))\n#model.add(Flatten())\n#model.add(BatchNormalization())\nmodel.add(Dense(150, activation='elu', kernel_regularizer=regularizers.l2(0.01)))\n#model.add(Dense(200, activation='elu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(Dense(3, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n# compile the model\nsgd = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True)\n#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n# summarize the model\nprint(model.summary())","outputs":[],"metadata":{"_uuid":"972d91a674d31a4d15fa1e3778cb71be4af38eb4","_cell_guid":"c6df8d84-13d3-47a2-8003-85eb688c52ea"},"execution_count":null,"cell_type":"code"},{"source":"import keras\nfrom keras.layers import Dense, GlobalAveragePooling1D, Embedding\nimport keras.backend as K\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\na2c = {'EAP':0, 'HPL':1, 'MWS':2}\nlabels = to_categorical([a2c[x] for x in df['author']])","outputs":[],"metadata":{"_uuid":"deaed9e968379b49282625458591146b1d6176a3","_cell_guid":"728695be-ba9e-490e-97d2-9c2d64c9a806","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"labels[:10]","outputs":[],"metadata":{"_uuid":"f20e40430201235dc0b195ed3b25fc2c505b6b04","_cell_guid":"3b1ee2ae-5401-4e26-bf74-efb229d453c0"},"execution_count":null,"cell_type":"code"},{"source":"# fit the model\nmodel.fit(w2v, labels, epochs=20, verbose=1, batch_size=128, validation_split=0.15)","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"670d94eaeca058a26383d653f6fe7ada24f9eb40","_cell_guid":"4ba652c5-ce98-4535-bebf-5bd0dd33ea4f","scrolled":false,"_kg_hide-output":false},"execution_count":null,"cell_type":"code"},{"source":"df_test = pd.read_csv('../input/test.csv')\ndf_test['words'] = [x.split() for x in df_test['text']]\nw2v_test = []\nzerovec = 100*[0]\nmax_length = 256\n\nfor x in df_test['words']:\n    vec = []\n    #print(len(x))\n    for w in x[:max_length]:\n        try:\n            vec.extend(model_w2v.wv[w])\n        except:\n            continue\n    #print(len(vec))\n    remaining = max_length*100 - len(vec)\n    if remaining > 0 :\n        padding = remaining*[0]\n        vec.extend(padding)\n        w2v_test.append(vec)\n    elif remaining > 0 :\n        w2v_test.append(vec[:max_length])\n    else :\n        w2v_test.append(vec)","outputs":[],"metadata":{"_uuid":"b1571693779c19b9ceb54cf8d654a8ca707bdf9a","_cell_guid":"fce25926-1f09-49ed-8047-0963c491886f"},"execution_count":null,"cell_type":"code"},{"source":"y_pred = model.predict_proba(w2v_test)\n\nresult = pd.read_csv('../input/sample_submission.csv')\nfor a, i in a2c.items():\n    result[a] = y_pred[:, i]","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"result.to_csv('out.csv', index=False)","outputs":[],"metadata":{"_uuid":"10b1b4545f3c425aa06448fc5b88aacc9a1b0cfa","_cell_guid":"f510c850-605b-42f1-b0bb-11fce906256b","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"print(one_hot('man', 2))\nprint(one_hot('woman', 2))\n","outputs":[],"metadata":{"_uuid":"7850e99286971e6986bbfd8fe1aadd33b6af6e59","_cell_guid":"edf980a1-c793-4b77-8090-30044322d25e","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"","outputs":[],"metadata":{"_uuid":"ca882d3fca9b817de673c99040b1a50a098e27b2","_cell_guid":"b4d10c37-3717-49b0-9366-d79dba40e5f7","collapsed":true},"execution_count":null,"cell_type":"code"}],"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"file_extension":".py","mimetype":"text/x-python","version":"3.6.3","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"}},"nbformat_minor":1}