{"cells":[{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"39d17f96-4842-412a-ac5d-78d8140bf0a0","_uuid":"08e48b15d299cee47d867887485ba08958312379"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom nltk.stem.porter import *\nfrom string import punctuation\nimport copy\nimport itertools\n\nimport sklearn.ensemble\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, log_loss\n\n# Any results you write to the current directory are saved as output."},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"39d773d4-6961-4a94-990f-a0398f1b33ec","_uuid":"36330fb49a3bac4d0ac63e25fc0f4ed42fb28d60"},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train.csv\")\ntest_data = pd.read_csv(\"../input/test.csv\")\nhead_count = 2\nstops = set(stopwords.words(\"english\"))\naccuracy_lst = list()\nlogloss_lst = list()"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"3ec4ad58-caa9-44d7-abe2-daa5e6a3e92c","_uuid":"76b12a2258d72b0c7c2e44456d3163e3ca39c8df"},"cell_type":"code","source":"auth_vc = train_data['author'].value_counts()\ntrain_data['author_lbl'] = train_data['author'].map({\n    'EAP': 1,\n    'MWS': 2,\n    'HPL': 3\n})"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"05d14bbf-204d-4731-a5e3-e993cb967fbe","_uuid":"924ee9fcdfb284bd5dc577a255392eeaf53c9968"},"cell_type":"code","source":"def tokenize(text):\n    word_tokens = nltk.word_tokenize(text)\n    word_tokens = [w for w in word_tokens if not w in stops]\n    word_tokens = list(map(str.lower, word_tokens))\n    return word_tokens\n\ndef get_bag_of_words(row):\n    return Counter(row['tokens'])\n\ndef total_punctuations(row):\n    return len([p for p in row['tokens'] if p in list(punctuation)])\n                   \ndef total_stopwords(row):\n    return len([p for p in row['tokens'] if p in stops])\n\ndef get_random_idx(df):\n    return np.random.choice(df.index.values)"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"9a9d0936-79fb-4e98-858a-d053371cbeff","_uuid":"4e867c302c25b5ef666dddf71858147053024fda"},"cell_type":"code","source":"def generate_text_features(df):\n    df['n_words']               = df.apply(lambda row: len(row['text']), axis=1)\n    df['tokens']                = df.apply(lambda row: tokenize(row['text']), axis=1)\n    df['n_tokens']              = df['tokens'].map(len)\n    df['bow']                   = df.apply(lambda row: get_bag_of_words(row), axis=1)\n    df['n_puncts']              = df.apply(lambda row: total_punctuations(row), axis=1)\n    df['#,']                    = df.apply(lambda row: row['bow'][','], axis=1)\n    df['#;']                    = df.apply(lambda row: row['bow'][';'], axis=1)\n    return df"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"1eaeec96-7062-4c0d-9d37-d82e371fa5bd","_uuid":"2db146dbfa772ee0075f3960cf5357ef7952cf38"},"cell_type":"code","source":"train_data = generate_text_features(train_data)"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"fe5c033d-a6dc-4c5d-93e2-7d3277deacd1","_uuid":"53706d0b2f5b2e93f90db67658f48db3873e03a2"},"cell_type":"code","source":"punctuation"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"deabe2a2-6a3f-440e-a4bd-fce4bbe62540","_uuid":"a7f438afc4082b7f139393b78af6b922f66ecc24"},"cell_type":"code","source":"features = ['n_puncts', '#;']\nX = train_data[features]\n\ny = train_data['author_lbl']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nclf = RandomForestClassifier(random_state=0)\nclf = clf.fit(X_train, y_train)\n\ny_proba = clf.predict_proba(X_test)\nlog_loss_score = log_loss(y_test, y_proba)\nlogloss_lst.append(\"{:>5.3f}\".format(log_loss_score))\n\ny_predict = clf.predict(X_test)\npredict_df = pd.DataFrame({'actual': y_test.ravel(), 'predicts': y_predict})\npredict_df['score'] = predict_df.apply(lambda x: 1 if x['actual'] == x['predicts'] else 0, axis=1)\naccuracy = predict_df['score'].sum() / len(predict_df)\naccuracy = accuracy * 100\naccuracy_lst.append(\"{:>5.3f}\".format(accuracy))\n\nprint(\"Logloss \", \", \".join(logloss_lst))\nprint(\"Accuracy \", \", \".join(accuracy_lst))"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"06b641e6-8212-48cc-aae1-8d46d74bc94d","_uuid":"4d9d7dc76a8c7078817c2502b44325e9e5303452"},"cell_type":"code","source":""}],"nbformat_minor":1,"metadata":{"language_info":{"file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.3","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4}