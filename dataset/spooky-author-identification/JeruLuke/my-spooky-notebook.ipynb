{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","file_extension":".py","version":"3.6.3","name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python"}},"nbformat_minor":1,"cells":[{"metadata":{"_uuid":"aee09a0f202507c9fae503758c411cee28c39bc5","_cell_guid":"e7e8c5dd-6ae8-450a-82c2-b9061681d88b"},"source":"## Sneak peek into the data","cell_type":"markdown"},{"metadata":{"_uuid":"7d0bbc8108a5087e358905407f52be396cec8fa6","_cell_guid":"6ffa00a7-d833-4d26-96ca-8609003b21a6","collapsed":true},"execution_count":null,"outputs":[],"source":"glove_file = '../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'","cell_type":"code"},{"metadata":{"_uuid":"b0853e96fa195b8cf452dc5a7e4c8d97e0549cb5","_cell_guid":"8f06437b-aed2-4f3b-8ee8-9623bbc0cbac","collapsed":true},"execution_count":null,"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\n\ndf_train = pd.read_csv('../input/spooky-author-identification/train.csv')\ndf_test = pd.read_csv('../input/spooky-author-identification/test.csv')\ndf_sample = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\n\n#df.dropna(axis=0)\n#df.set_index('id', inplace = True)\n\ndf_sample.head()","cell_type":"code"},{"metadata":{"_uuid":"55d3b16ac4c718394c0722b525db498f7754e3b9","_cell_guid":"b474d8fc-8a88-4a58-8ec1-396fba9d33be","collapsed":true},"execution_count":null,"outputs":[],"source":"df_test.head()","cell_type":"code"},{"metadata":{"_uuid":"3615eb91fbd93b7eaee74c18a0c928f54f0f23cb","_cell_guid":"98b9dcac-3d5a-4944-a6ab-1f90ccda8e32","collapsed":true},"execution_count":null,"outputs":[],"source":"print(df_train.shape)\nprint(df_test.shape)","cell_type":"code"},{"metadata":{"_uuid":"47d31e5db08a001aca8c443ab534a9fc8f17fe30","_cell_guid":"5087c98c-c938-4d4c-8fc5-da71685d7f16"},"source":"## NLP modelling!","cell_type":"markdown"},{"metadata":{"_uuid":"7f2d0df15b768853113ba7c465c35ee1704b8cc0","_cell_guid":"8302859a-db73-4561-aa17-69e067fb6982","collapsed":true},"execution_count":null,"outputs":[],"source":"import re\nfrom nltk.corpus import stopwords\n\nstopWords = set(stopwords.words('english'))","cell_type":"code"},{"metadata":{"_uuid":"2ae890379177816f591b51a62b0e00dfedd17f7a","_cell_guid":"0ac19c57-49c4-47ea-bd13-fa744887233e","collapsed":true},"execution_count":null,"outputs":[],"source":"len(df_train.columns)","cell_type":"code"},{"metadata":{"_uuid":"ae918bef7291db2dc0bd89ffdc124875d80597c2","_cell_guid":"c9237834-cb78-40e6-9f10-0d648e1f1861"},"source":"## Feature Engineering","cell_type":"markdown"},{"metadata":{"_uuid":"419af00aa6e1b4247c2f82da258d61d96a4f992e","_cell_guid":"ac3ec91d-c545-45a2-84fe-9e3e2839fa06","collapsed":true},"execution_count":null,"outputs":[],"source":"#creating a function to encapsulate preprocessing, to mkae it easy to replicate on  submission data\ndef processing(df):\n    #lowering and removing punctuation\n    df['processed'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n    \n    #numerical feature engineering\n    #total length of sentence\n    df['length'] = df['processed'].apply(lambda x: len(x))\n    \n    #get number of words\n    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n    \n    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n    \n    # number of unique words\n    df[\"num_unique_words\"] = df[\"text\"].apply(lambda x: len(set(str(x).split())))\n    \n    # number of characters\n    df[\"num_chars\"] = df[\"text\"].apply(lambda x: len(str(x)))\n    \n    # nmber of punctuations\n    #df[\"num_punctuations\"] = df[\"text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n    \n    # number of upper case \n    df[\"num_words_upper\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n    \n    #number of titles characters\n    df[\"num_words_title\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n    \n    #get the average word length\n    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n    \n    #get number of commas\n    df['commas'] = df['text'].apply(lambda x: x.count(','))\n\n    return(df)\n\ndf_train = processing(df_train)\n\ndf_train.head()","cell_type":"code"},{"metadata":{"_uuid":"bd8fe58935a2d6b7f37c8463292371773d538cb4","_cell_guid":"29ace5cc-5cb6-48ef-a5ee-a3591dc2fc39"},"source":"## Pipelining","cell_type":"markdown"},{"metadata":{"_uuid":"5b1efa096eec5cf3ea4d93687f057f793153baaf","_cell_guid":"0aef98e7-be50-4567-9f57-84d253e0a288","collapsed":true},"execution_count":null,"outputs":[],"source":"df_train.columns","cell_type":"code"},{"metadata":{"_uuid":"0274417d3ee78c298ab962b2f38323e1f4aff318","_cell_guid":"77924c24-1796-4a0e-b932-f8f1dacc1fab","collapsed":true},"execution_count":null,"outputs":[],"source":"from sklearn.model_selection import train_test_split\n\nfeatures= [c for c in df_train.columns.values if c  not in ['id','text','author']]\nnumeric_features= [c for c in df_train.columns.values if c  not in ['id','text','author','processed']]\ntarget = 'author'\n\nX_train, X_test, y_train, y_test = train_test_split(df_train[features], df_train[target], test_size=0.40, random_state=42)\nX_train.head()","cell_type":"code"},{"metadata":{"_uuid":"bce70f7ea9cf41352c56a1263eb1d0ec0f858f31","_cell_guid":"1df7d25f-7c8a-49db-8bf0-383b7d4472d9","collapsed":true},"execution_count":null,"outputs":[],"source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass TextSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to select a single column from the data frame to perform additional transformations on\n    Use on text columns in the data\n    \"\"\"\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[self.key]\n    \nclass NumberSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to select a single column from the data frame to perform additional transformations on\n    Use on numeric columns in the data\n    \"\"\"\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[[self.key]]","cell_type":"code"},{"metadata":{"_uuid":"f1772595dc088a1895e0b2800faf7d24ac133d3e","_cell_guid":"aeed9aa7-a20d-459a-80bb-74705e24fdd9","collapsed":true},"execution_count":null,"outputs":[],"source":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntext = Pipeline([\n                ('selector', TextSelector(key='processed')),\n                ('tfidf', TfidfVectorizer( stop_words='english'))\n            ])\n\ntext.fit_transform(X_train)","cell_type":"code"},{"metadata":{"_uuid":"3468644c8b12fefb9852664700380c8e6790e932","_cell_guid":"5c727563-838b-4102-8cc1-6e5cfc798c7c","collapsed":true},"execution_count":null,"outputs":[],"source":"from sklearn.preprocessing import StandardScaler\n\nlength =  Pipeline([\n                ('selector', NumberSelector(key='length')),\n                ('standard', StandardScaler())\n            ])\n\nwords =  Pipeline([\n                ('selector', NumberSelector(key='words')),\n                ('standard', StandardScaler())\n            ])\n\nwords_not_stopword =  Pipeline([\n                ('selector', NumberSelector(key='words_not_stopword')),\n                ('standard', StandardScaler())\n            ])\n\nnum_unique_words =  Pipeline([\n                ('selector', NumberSelector(key='num_unique_words')),\n                ('standard', StandardScaler()),\n            ])\n\nnum_chars =  Pipeline([\n                ('selector', NumberSelector(key='num_chars')),\n                ('standard', StandardScaler()),\n            ])\n\nnum_words_upper =  Pipeline([\n                ('selector', NumberSelector(key='num_words_upper')),\n                ('standard', StandardScaler()),\n            ])\n\nnum_words_title =  Pipeline([\n                ('selector', NumberSelector(key='num_words_title')),\n                ('standard', StandardScaler()),\n            ])\n\navg_word_length =  Pipeline([\n                ('selector', NumberSelector(key='avg_word_length')),\n                ('standard', StandardScaler())\n            ])\n\ncommas =  Pipeline([\n                ('selector', NumberSelector(key='commas')),\n                ('standard', StandardScaler()),\n            ])","cell_type":"code"},{"metadata":{"_uuid":"d8176c34d69d54bd411453f44ff732b87f3624f0","_cell_guid":"e25f5313-dbb6-4c25-b12c-79c8f56d5f09","collapsed":true},"execution_count":null,"outputs":[],"source":"from sklearn.pipeline import FeatureUnion\n\nfeats = FeatureUnion([('text', text), \n                      ('length', length),\n                      ('words', words),\n                      ('num_unique_words', num_unique_words),\n                      ('num_chars', num_chars),\n                      ('num_words_upper', num_words_upper),\n                      ('num_words_title', num_words_title),\n                      ('words_not_stopword', words_not_stopword),\n                      ('avg_word_length', avg_word_length),\n                      ('commas', commas)])\n\nfeature_processing = Pipeline([('feats', feats)])\nfeature_processing.fit_transform(X_train)","cell_type":"code"},{"metadata":{"_uuid":"412ca6e0fe546c01464c0c89f9d01400f5ba0fbd","_cell_guid":"e566019a-90f2-40f0-8485-7cf2d01e71c0"},"source":"## Random Forest","cell_type":"markdown"},{"metadata":{"_uuid":"d632511136985b0bdc651a68995ba350f7bf2e17","_cell_guid":"01815a9e-14c6-4480-98af-7a371b0a19b4","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\nfrom sklearn.ensemble import RandomForestClassifier\n\npipeline = Pipeline([\n    ('features',feats),\n    ('classifier', RandomForestClassifier(random_state = 42)),\n])\n\npipeline.fit(X_train, y_train)\n\npreds = pipeline.predict(X_test)\nnp.mean(preds == y_test)\n'''","cell_type":"code"},{"metadata":{"_uuid":"90e66c8d8e87948eb16e946c469447e524ec68ba","_cell_guid":"b62a82d0-82ee-4aa8-83f5-512c3058d3e1"},"source":"## Gradient Boosting Classifier","cell_type":"markdown"},{"metadata":{"_uuid":"1790458ae610077230892bd95031fabaa2f2777c","_cell_guid":"cb2dc7fa-7871-42a7-88ef-5b2dabc7469d","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbpipeline = Pipeline([\n    ('features',feats),\n    ('gbclassifier', GradientBoostingClassifier(random_state = 42)),\n])\n\ngbpipeline.fit(X_train, y_train)\n\npreds = gbpipeline.predict(X_test)\nnp.mean(preds == y_test)\n'''","cell_type":"code"},{"metadata":{"_uuid":"cf3161449c5cc64dff54a5371e4d5eee8f7ad468","_cell_guid":"584f742a-7b7f-4f09-9045-4ac78dcdd0c1"},"source":"## Crossvalidation","cell_type":"markdown"},{"metadata":{"_uuid":"a112c5da6f8c4a196393e0f59cff3033ace38453","_cell_guid":"82cdbcd7-c9ae-42d4-90a8-e3d07a7776a5","collapsed":true},"execution_count":null,"outputs":[],"source":"# pipeline.get_params().keys()","cell_type":"code"},{"metadata":{"_uuid":"235d7311916469d15d786fb8ca9f114bc358e17e","_cell_guid":"3b63a58a-5ae6-4f7f-afa5-00acbfa7187c","collapsed":true},"execution_count":null,"outputs":[],"source":"# gbpipeline.get_params().keys()","cell_type":"code"},{"metadata":{"_uuid":"2f208433ea909774975a9f250749142340e03ee3","_cell_guid":"7bfd8575-046b-41f8-a626-582e78846ffb","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\nfrom sklearn.model_selection import GridSearchCV\n\nhyperparameters = { 'features__text__tfidf__max_df': [0.9],\n                    'features__text__tfidf__ngram_range': [(1,1)],\n                   'classifier__max_depth': [160, 170, 180],\n                    'classifier__min_samples_leaf': [4]\n                  }\nclf = GridSearchCV(pipeline, hyperparameters, cv=5)\n \n# Fit and tune model\nclf.fit(X_train, y_train)\n'''","cell_type":"code"},{"metadata":{"_uuid":"c28d3eef26f38233d175cc8b495c8d2eec0cb7b8","_cell_guid":"5aa40c34-621a-44ad-b94c-4b157261601d","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\nfrom sklearn.model_selection import GridSearchCV\n\ngbhyperparameters = { 'features__text__tfidf__max_df': [0.9],\n                      'features__text__tfidf__ngram_range': [(1,1)],\n                      'gbclassifier__n_estimators': [50, 100, 150],\n                      'gbclassifier__min_samples_split': [2, 3], \n                      'gbclassifier__min_samples_leaf' : [2, 4]\n                  }\ngbclf = GridSearchCV(gbpipeline, gbhyperparameters, cv=5)\n \n# Fit and tune model\ngbclf.fit(X_train, y_train)\n'''\n","cell_type":"code"},{"metadata":{"_uuid":"cc85edb90e22325bdf5613ccebe9038f639a5279","_cell_guid":"9e9e5c71-fc10-4741-9bbc-f4bcdc21da66"},"source":"**Seeing the best parameters**","cell_type":"markdown"},{"metadata":{"_uuid":"02086f8ff06597181b0bc0cde87c696612d04675","_cell_guid":"16b6befb-d9ee-4c79-aead-35a9c5987a61","collapsed":true},"execution_count":null,"outputs":[],"source":"#clf.best_params_","cell_type":"code"},{"metadata":{"_uuid":"0399ad841b660838c2cb69c73a7a60c0738aa961","_cell_guid":"a765e7a0-f13f-4293-ac86-90b0cc9ac8e7","collapsed":true},"execution_count":null,"outputs":[],"source":"# gbclf.best_params_","cell_type":"code"},{"metadata":{"_uuid":"324aa2dfd0814296985f49523ba5720a21db43bc","_cell_guid":"e690bc0a-da81-4dff-bea8-8df17ef2ea6c","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\n#refitting on entire training data using best settings\nclf.refit\n\npreds = clf.predict(X_test)\nprobs = clf.predict_proba(X_test)\n\nnp.mean(preds == y_test)\n'''","cell_type":"code"},{"metadata":{"_uuid":"f19de79864d919083e795ac5bb434c5da78a85dc","_cell_guid":"b957d029-15a3-4595-967b-6a3379679e85","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\n#refitting on entire training data using best settings\ngbclf.refit\n\npreds = gbclf.predict(X_test)\nprobs = gbclf.predict_proba(X_test)\n\nnp.mean(preds == y_test)\n'''","cell_type":"code"},{"metadata":{"_uuid":"926f727687c1b7e37a078d7a7fba4b62516d0223","_cell_guid":"3d089063-1c05-4813-810a-d83686773b5e"},"source":"## Submission File","cell_type":"markdown"},{"metadata":{"_uuid":"da262bccc3e6aeb88b78bbc4295c863a76eb1eab","_cell_guid":"9233469f-68c1-4cd6-a2ba-1bed56970958","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\nsubmission = pd.read_csv('../input/test.csv')\n\n#preprocessing\nsubmission = processing(submission)\npredictions = clf.predict_proba(submission)\n\npreds = pd.DataFrame(data=predictions, columns = clf.best_estimator_.named_steps['classifier'].classes_)\n\n#generating a submission file\nresult = pd.concat([submission[['id']], preds], axis=1)\n#result.set_index('id', inplace = True)\nresult.head()\n'''\n","cell_type":"code"},{"metadata":{"_uuid":"8d8daaea5a7c0645e49e196c345bf14b4624ec16","_cell_guid":"c78fa4ab-510a-43fe-b787-1318464132f4","collapsed":true},"execution_count":null,"outputs":[],"source":"#result.to_csv('random_forest.csv', index=False)","cell_type":"code"},{"metadata":{"_uuid":"0c1d35626735b726a242a4ce5ee904e7dbe4e4b8","_cell_guid":"71efb200-caa2-4bb4-8ae4-3b163b23eb40","collapsed":true},"execution_count":null,"outputs":[],"source":"''' \nsubmission = pd.read_csv('../input/test.csv')\n\n#preprocessing\nsubmission = processing(submission)\npredictions = gbclf.predict_proba(submission)\n\npreds = pd.DataFrame(data=predictions, columns = gbclf.best_estimator_.named_steps['classifier'].classes_)\n\n#generating a submission file\nresult = pd.concat([submission[['id']], preds], axis=1)\n#result.set_index('id', inplace = True)\nresult.head()\n\n'''","cell_type":"code"},{"metadata":{"_uuid":"0f9fd1d5a3cc3d79bedc7574723236b7972a1c16","_cell_guid":"6d58408a-adc2-457c-ac81-433b8b7dab29","collapsed":true},"execution_count":null,"outputs":[],"source":"# result.to_csv('gradient_boost.csv', index=False)","cell_type":"code"},{"metadata":{"_uuid":"46065c58910c8c9b239b756176827ec22988de62","_cell_guid":"2d708afd-a188-4a73-865f-9c2ee006ea9c"},"source":"## Naive Bayes","cell_type":"markdown"},{"metadata":{"_uuid":"8a2322ae13152059097517a9a96b69ed1d55dc00","_cell_guid":"5ba85a30-bdd0-4896-aa02-1cea24fc1758","collapsed":true},"execution_count":null,"outputs":[],"source":"\ntrain_corpus = []\nfor i in range(len(df_train)):\n    review = re.sub('[^a-zA-Z0-9]', ' ', df_train['text'][i])\n    review = review.lower()\n    review = review.split()\n    review = [word for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    train_corpus.append(review)\n\ntest_corpus = []\nfor i in range(len(df_test)):\n    review = re.sub('[^a-zA-Z0-9]', ' ', df_test['text'][i])\n    review = review.lower()\n    review = review.split()\n    review = [word for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    test_corpus.append(review)\n    \nX_Train = np.array(train_corpus)\nX_Test = np.array(test_corpus)\ny = df_train.iloc[:, 2].values    \n\n\n\n","cell_type":"code"},{"metadata":{"_uuid":"89353c2ecce4465c3aa711ade4c9e7f008b83226","_cell_guid":"ea9af525-75db-4988-bdb9-717752655f59"},"source":"## Stemming\n\nReplacing similar words like ran, run and running as the same word.","cell_type":"markdown"},{"metadata":{"_uuid":"51ff4ead1f45aaaf69def206194f9c462dbda550","_cell_guid":"0e1d6277-71aa-492f-bf01-18f3b10bd830","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\nimport nltk.stem as stm # Import stem class from nltk\n    import re\n    stemmer = stm.PorterStemmer()\n\n    # Crazy one-liner code here...\n    # Explanation above...\n    df_train.text = df_train.text.apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n    df_test.text = df_test.text.apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n'''","cell_type":"code"},{"metadata":{"_uuid":"1b9f22ee8b75c1b4a0eed766e29294618526807b","_cell_guid":"a6e0b463-dbee-4111-a7f8-db832750d01a","collapsed":true},"execution_count":null,"outputs":[],"source":"'''\nX_Train = pd.DataFrame(X_Train)\nX_Train.columns = ['text']\n\nX_Train.head()\n''' ","cell_type":"code"},{"metadata":{"_uuid":"75612ee79db90359a014f6b767d878bdc3ed4207","_cell_guid":"ebfe3265-9edf-4976-86da-25136141df1f","collapsed":true},"execution_count":null,"outputs":[],"source":"#''' \nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nclassifier = Pipeline([('vect', CountVectorizer()),\n                      ('tfidf', TfidfTransformer()),\n                      ('clf', MultinomialNB()),\n                       #('clf', GradientBoostingClassifier(random_state = 42))\n])\n\nclassifier.fit(X_Train, y)\n#'''","cell_type":"code"},{"metadata":{"_uuid":"55cf1e3679cd98aea5df6f1f44020551ab4b3f73","_cell_guid":"bb89ccac-f6a2-4f9a-bd99-48d7609f0366","collapsed":true},"execution_count":null,"outputs":[],"source":"#'''\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n              'tfidf__use_idf': (True, False),\n              'clf__alpha': (0.05, 1.0)\n              #'clf__min_samples_split': [2, 3]\n}\n\ngs_clf = GridSearchCV(classifier, parameters)\ngs_clf.fit(X_Train, y)\n#'''","cell_type":"code"},{"metadata":{"_uuid":"26c5d9d5a7a37239b95ce0a04edf0e8d0ff3a297","_cell_guid":"187e69f3-c689-462a-bb10-1a0e1b806bc1","collapsed":true},"execution_count":null,"outputs":[],"source":"gs_clf.best_params_","cell_type":"code"},{"metadata":{"_uuid":"7e9bd432a4057eba5949def533380aff7b7156fe","_cell_guid":"e60e6f11-af0a-4b03-9854-4179e06bd7e4","collapsed":true},"execution_count":null,"outputs":[],"source":"#'''\n\n\ngs_clf.refit\n\n\n\n# Predicting the Test set results\ny_pred_proba = gs_clf.predict_proba(X_Test)\n\ntdf = pd.DataFrame(y_pred_proba)\ntdf.columns = ['EAP', 'HPL', 'MWS']\n\nsubmission = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\nresult = pd.concat([submission[['id']], tdf], axis=1)\nresult.head()\n\nresult.to_csv('naive_bayes_old.csv', index=False)\n#'''","cell_type":"code"},{"metadata":{"_uuid":"f28281dd30befde2a2cad367a7e527c0743dcb0a","_cell_guid":"3ff329de-3d54-4466-b99a-b8b699371949"},"source":"## NLP","cell_type":"markdown"},{"metadata":{"_uuid":"8bad5ff9c847d274e16a873b7c370a6b29f3e043","_cell_guid":"901b518f-662f-4240-bca8-cf1dd7457ed5","collapsed":true},"execution_count":null,"outputs":[],"source":"import xgboost as xgb\nfrom tqdm import tqdm\nfrom sklearn.svm import SVC\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')","cell_type":"code"},{"metadata":{"_uuid":"4adcf613d37632f8fb1df1ef93f06ccb20a4d108","_cell_guid":"ec61cf8a-f449-45e8-afab-719e3e087a2e","collapsed":true},"execution_count":null,"outputs":[],"source":"df_train.head()\n","cell_type":"code"},{"metadata":{"_uuid":"626860d1383f98be4be723ceeb5ecd882bc041ac","_cell_guid":"5a057d67-e3ef-4599-b4a8-2471664fb38f","collapsed":true},"execution_count":null,"outputs":[],"source":"df_test.head()","cell_type":"code"},{"metadata":{"_uuid":"633f0dcf3c493d2a79decb4286145b596cca5b63","_cell_guid":"91345a25-e22b-47bf-8536-8f48ca38d168","collapsed":true},"execution_count":null,"outputs":[],"source":"def multiclass_logloss(actual, predicted, eps=1e-15):\n    \"\"\"Multi class version of Logarithmic Loss metric.\n    :param actual: Array containing the actual target classes\n    :param predicted: Matrix with class predictions, one probability per class\n    \"\"\"\n    # Convert 'actual' to a binary array if it's not already:\n    if len(actual.shape) == 1:\n        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n        for i, val in enumerate(actual):\n            actual2[i, val] = 1\n        actual = actual2\n\n    clip = np.clip(predicted, eps, 1 - eps)\n    rows = actual.shape[0]\n    vsota = np.sum(actual * np.log(clip))\n    return -1.0 / rows * vsota","cell_type":"code"},{"metadata":{"_uuid":"fbc5cdbed611c77c167343b2e66d25087f5c3b0c","_cell_guid":"6e333ac8-ac0b-4250-84ca-b32403a34409","collapsed":true},"execution_count":null,"outputs":[],"source":"lbl_enc = preprocessing.LabelEncoder()\ny = lbl_enc.fit_transform(df_train.author.values)\ny","cell_type":"code"},{"metadata":{"_uuid":"f91a900a8f7c742594ad48b8aa30e4432d3093b6","_cell_guid":"c19761a9-62a7-45b6-bde3-95fa03a4eda4","collapsed":true},"execution_count":null,"outputs":[],"source":"xtrain, xvalid, ytrain, yvalid = train_test_split(df_train.text.values, y, \n                                                  stratify = y, \n                                                  random_state = 42, \n                                                  test_size = 0.1, shuffle = True)","cell_type":"code"},{"metadata":{"_uuid":"f564c1ccd1ee4caac592cc48af8236e360ac2de0","_cell_guid":"05f4534f-d6a6-4c2a-a6bd-ca90974c2d6e","collapsed":true},"execution_count":null,"outputs":[],"source":"type(xvalid)","cell_type":"code"},{"metadata":{"_uuid":"0424099e621fc6dcf29f7083a0a3d8685db94aa4","_cell_guid":"d2c8394c-37e8-45c0-adc6-7228b99f1f7c","collapsed":true},"execution_count":null,"outputs":[],"source":"type(xtrain)","cell_type":"code"},{"metadata":{"_uuid":"ab8da977c736be40e9cbae629c2934919e0148d3","_cell_guid":"8f6fee09-432c-41af-8a24-20bc420700c4","collapsed":true},"execution_count":null,"outputs":[],"source":"xtrain","cell_type":"code"},{"metadata":{"_uuid":"a0dfad651cad9236a2c7f20f8349417caf39cb19","_cell_guid":"a653d50b-6fb1-4974-908d-b6341622e543","collapsed":true},"execution_count":null,"outputs":[],"source":"print('Train and output {} & {}'.format( xtrain.shape, ytrain.shape))","cell_type":"code"},{"metadata":{"_uuid":"b7cb0d843cfb3b63a1cf5d4f467a3927c570682b","_cell_guid":"f3975a91-45e3-4db8-864d-d1d4df7cfe93","collapsed":true},"execution_count":null,"outputs":[],"source":"print('Validation and output {} & {}'.format( xvalid.shape, yvalid.shape))","cell_type":"code"},{"metadata":{"_uuid":"77c4f29ab349ce56c6261c7b3975426b03eb14ae","_cell_guid":"c92e2cf8-12a4-4284-b12a-3beba4e5196f"},"source":"## **TF-IDF followed by Logistic Regression**","cell_type":"markdown"},{"metadata":{"_uuid":"73e9a270b27fd9fd5d6d5a9963e70de18ad5702b","_cell_guid":"9256a331-9eaa-471d-847e-f8acb344c0b6","collapsed":true},"execution_count":null,"outputs":[],"source":"tfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n            stop_words = 'english')\n\ntfv","cell_type":"code"},{"metadata":{"_uuid":"96c56d452beb5132e23f14154b3c7d68277b4cce","_cell_guid":"90aacca0-ae9d-4773-9d79-f5c9c6f72627","collapsed":true},"execution_count":null,"outputs":[],"source":"tfv.fit(list(xtrain) + list(xvalid))\nxtrain_tfv =  tfv.transform(xtrain) \nxvalid_tfv = tfv.transform(xvalid)\n\nxvalid_tfv.shape","cell_type":"code"},{"metadata":{"_uuid":"c29474577e46f56cc3b54e7299011dafa45565e2","_cell_guid":"b56db9d3-5697-4bdc-8404-d172a0a478ca","collapsed":true},"execution_count":null,"outputs":[],"source":"clf = LogisticRegression(C=1.0)\nclf.fit(xtrain_tfv, ytrain)\npredictions = clf.predict_proba(xvalid_tfv)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","cell_type":"code"},{"metadata":{"_uuid":"483bdf95efbc1d6e5fe289e2a0842b14bb9a90ab","_cell_guid":"3f1606ec-4eb7-44c0-8a11-2135e8209a62","collapsed":true},"execution_count":null,"outputs":[],"source":"test_predictions = clf.predict_proba(xvalid_tfv)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","cell_type":"code"},{"metadata":{"_uuid":"46a6f334afae2ca1f9b5661642013301e0422eeb","_cell_guid":"0c255edf-f7b7-4948-887a-43e732d1d48a","collapsed":true},"execution_count":null,"outputs":[],"source":"test_tfv =  tfv.transform(df_test['text']) ","cell_type":"code"},{"metadata":{"_uuid":"2615ef95a2bafc52f7c6577783e70495f2b561f4","_cell_guid":"104d44dc-8077-40ac-8be1-31f45f40bc73","collapsed":true},"execution_count":null,"outputs":[],"source":"test_predictions = clf.predict_proba(test_tfv)\ntest_predictions.shape","cell_type":"code"},{"metadata":{"_uuid":"2e70fa63046da4ef6cf3a2971750a8d494bf922f","_cell_guid":"a1725664-b6e0-4981-9ace-fb2fdec9df71","collapsed":true},"execution_count":null,"outputs":[],"source":"tdf = pd.DataFrame(test_predictions)\ntdf.columns = ['EAP', 'HPL', 'MWS']\n\nsubmission = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\nresult = pd.concat([submission[['id']], tdf], axis=1)\nresult.head()\n\nresult.to_csv('naive_tf_idf.csv', index=False)","cell_type":"code"},{"metadata":{"_uuid":"ea5915f7cf444537261c4fe4d54a229532cbf066","_cell_guid":"94ab12b1-d87c-4e46-b18b-e5aa5bafd96a"},"source":"## **Count Vectorizer**","cell_type":"markdown"},{"metadata":{"_uuid":"d2bfcfb484ddfeb03624b30a50bbdc04ae6cb6f6","_cell_guid":"b34f6e64-b7dd-487a-a81c-08eb1c683fc9","collapsed":true},"execution_count":null,"outputs":[],"source":"ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), stop_words = 'english')\n\n# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\nctv.fit(list(xtrain) + list(xvalid))\nxtrain_ctv =  ctv.transform(xtrain) \nxvalid_ctv = ctv.transform(xvalid)\n","cell_type":"code"},{"metadata":{"_uuid":"a4de355381ce884c25c87a9e983a903fa929f414","_cell_guid":"d34c53e5-a324-40d2-a9a7-8cade61be4d4","collapsed":true},"execution_count":null,"outputs":[],"source":"clf = LogisticRegression(C=1.0)\nclf.fit(xtrain_ctv, ytrain)\npredictions = clf.predict_proba(xvalid_ctv)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","cell_type":"code"},{"metadata":{"_uuid":"97c0bc9cb6ab5bfb147cdd75cf74411716977df3","_cell_guid":"4d8c3655-b1ac-493d-99f8-bcc5862cce65","collapsed":true},"execution_count":null,"outputs":[],"source":"test_predictions = clf.predict_proba(xvalid_ctv)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","cell_type":"code"},{"metadata":{"_uuid":"5d9f580dbf7adac0e2ae47d156dc8a40c695e97d","_cell_guid":"9a7cb920-56c9-470c-86d5-3d363635f31f","collapsed":true},"execution_count":null,"outputs":[],"source":"test_ctv =  ctv.transform(df_test['text']) ","cell_type":"code"},{"metadata":{"_uuid":"b33d26d45ec55305c0180222528721226ec6e946","_cell_guid":"adda992d-e2ab-4097-89e5-868df9e09f28","collapsed":true},"execution_count":null,"outputs":[],"source":"test_predictions = clf.predict_proba(test_ctv)\ntest_predictions.shape","cell_type":"code"},{"metadata":{"_uuid":"f34a186f09213f67dceba372f5f1e7bfa393d7ae","_cell_guid":"50919fc5-bea4-4cef-9187-e22932141bbf","collapsed":true},"execution_count":null,"outputs":[],"source":"tdf = pd.DataFrame(test_predictions)\ntdf.columns = ['EAP', 'HPL', 'MWS']\n\nsubmission = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\nresult = pd.concat([submission[['id']], tdf], axis=1)\nresult.head()\n\nresult.to_csv('naive_ctv.csv', index=False)","cell_type":"code"},{"metadata":{"_uuid":"ad0243ce83919130a5b1e0cedf6ab9e5b0e70e12","_cell_guid":"5e2b03e5-c91a-459d-b712-93bf58efff42"},"source":"## **Naive Bayes 2 **\n\n### **NB on tf-idf**","cell_type":"markdown"},{"metadata":{"_uuid":"ffedc207a0d684fe9b41af2ab73a4f03144a7a34","_cell_guid":"d8a65269-97e4-4e8e-a900-9e0b99f36455","collapsed":true},"execution_count":null,"outputs":[],"source":"clf = MultinomialNB()\nclf.fit(xtrain_tfv, ytrain)\npredictions = clf.predict_proba(xvalid_tfv)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","cell_type":"code"},{"metadata":{"_uuid":"d40847949361738407ef8ef244d987a3bda06d82","_cell_guid":"f310c232-c2f9-49b8-9241-726ec881b1e3"},"source":"### **NB on count vectorizer**","cell_type":"markdown"},{"metadata":{"_uuid":"6b653b0e70be05c92740bcbe0341cbf2db736b31","_cell_guid":"8e075241-01b4-4821-a0cf-9d4cca5973db","collapsed":true},"execution_count":null,"outputs":[],"source":"clf = MultinomialNB()\nclf.fit(xtrain_ctv, ytrain)\npredictions = clf.predict_proba(xvalid_ctv)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","cell_type":"code"},{"metadata":{"_uuid":"a99d26be65a90da41bbefc01c884dcd895d5fc44","_cell_guid":"2e6f9fd8-bd76-4acf-b11d-e3b8ed60e950","collapsed":true},"execution_count":null,"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nclassifier = Pipeline([('vect', CountVectorizer()),\n                      ('tfidf', TfidfTransformer()),\n                      ('clf', MultinomialNB()),\n                       #('clf', GradientBoostingClassifier(random_state = 42))\n])\n\nclassifier.fit(xvalid, yvalid)\n\n","cell_type":"code"},{"metadata":{"_uuid":"4b4c19414b5215b2f2a3e3df3502de1efd27def5","_cell_guid":"9c37a0d8-5e2b-4e0a-92dc-fe330230e204","collapsed":true},"execution_count":null,"outputs":[],"source":"from sklearn.model_selection import GridSearchCV\n\nparameters = {'vect__ngram_range': [(1, 1)],\n              'tfidf__use_idf': [True],\n              'clf__alpha': ( 0.05, 0.01)\n              #'clf__min_samples_split': [2, 3]\n             }               \n\n\n'''parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n              'tfidf__use_idf': (True, False),\n              'clf__alpha': (0.5, 1.0)\n              #'clf__min_samples_split': [2, 3]\n             } '''\n\ngs_clf = GridSearchCV(classifier, parameters)\ngs_clf.fit(xtrain, ytrain)","cell_type":"code"},{"metadata":{"_uuid":"02ef15089131b6085e9db83613b5e64de7a22845","_cell_guid":"42c70cf2-92f0-4961-8586-b277e13430e2","collapsed":true},"execution_count":null,"outputs":[],"source":"gs_clf.best_params_","cell_type":"code"},{"metadata":{"_uuid":"ace2b8109e8b09c1cd6a5b3473e0718c7b0a3e51","_cell_guid":"306f3125-6473-45ed-9231-3fc7ae8476a4","collapsed":true},"execution_count":null,"outputs":[],"source":"\n\ngs_clf.refit\n\ngs_clf.fit(xtrain, ytrain)\n\n# Predicting the validation set results\ny_pred_valid = gs_clf.predict_proba(xvalid)\n\n#predictions = clf.predict_proba(xvalid_ctv)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(y_pred_valid, predictions))\n\ny_pred_valid_f1 = gs_clf.predict(xvalid)\n\nfrom sklearn.metrics import classification_report\nprint (classification_report(yvalid, y_pred_valid_f1))\n\n# Predicting the Test set results\ny_pred_proba = gs_clf.predict_proba(X_Test)\n\ntdf = pd.DataFrame(y_pred_proba)\ntdf.columns = ['EAP', 'HPL', 'MWS']\n\nsubmission = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\nresult = pd.concat([submission[['id']], tdf], axis=1)\nresult.head()\n\nresult.to_csv('naive_bayes__2.csv', index=False)","cell_type":"code"},{"metadata":{"_uuid":"4a4f0e1264b6e9dc49a5d6ba95e3df9b2a29fa88","_cell_guid":"a49e2df4-40de-4b62-8ffb-ee7379b2e5a8"},"source":"### **Word Vectors**","cell_type":"markdown"},{"metadata":{"_uuid":"74cdd0b86a127342dee5c9981c30e855032dd75d","_cell_guid":"976a2c0a-0066-4901-8f91-d164b8f94fab","collapsed":true},"execution_count":null,"outputs":[],"source":"from nltk import word_tokenize\n\nembeddings_index = {}\nf = open(glove_file)\nfor line in tqdm(f):\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","cell_type":"code"},{"metadata":{"_uuid":"4990ee20dce3788152700ed92531372f7deab726","_cell_guid":"c002aee1-e4a0-4e85-9e62-bd521739b899","collapsed":true},"execution_count":null,"outputs":[],"source":"# this function creates a normalized vector for the whole sentence\ndef sent2vec(s):\n    #words = str(s).lower().decode('utf-8')\n    words = str(s).lower()\n    words = word_tokenize(words)\n    words = [w for w in words if not w in stop_words]\n    words = [w for w in words if w.isalpha()]\n    M = []\n    for w in words:\n        try:\n            M.append(embeddings_index[w])\n        except:\n            continue\n    M = np.array(M)\n    v = M.sum(axis=0)\n    if type(v) != np.ndarray:\n        return np.zeros(300)\n    return v / np.sqrt((v ** 2).sum())","cell_type":"code"},{"metadata":{"_uuid":"b9a6265b16af35bc5dd4bab343777919806c3656","_cell_guid":"526e620c-ebf3-40a9-a64e-bddbead46b83","collapsed":true},"execution_count":null,"outputs":[],"source":"xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\nxvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]\n\ntype(xtrain_glove)\nlen(xvalid_glove[1])\nxvalid_glove[0].shape","cell_type":"code"},{"metadata":{"_uuid":"e8a61d9b5c4a3d3787ef4285360b696c1e737f91","_cell_guid":"638c4c0c-85c9-4be5-a742-afac0fcc6a5c","collapsed":true},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"_uuid":"e8ef0ba4339e09e5fbbe2f24470d396df65437be","_cell_guid":"e9a13c4d-95f1-42bd-a226-ca3f7065e16d","collapsed":true},"execution_count":null,"outputs":[],"source":"xtrain_glove1 = np.array(xtrain_glove)\nxvalid_glove1 = np.array(xvalid_glove)\n\nxvalid_glove1.shape\n\nxvalid_glove1.reshape(1, -1)\nxvalid_glove1.shape","cell_type":"code"},{"metadata":{"_uuid":"2937147ece40c070f5cce58a6c348f47ed1e8811","_cell_guid":"182079f4-7835-4627-8807-96874f1b75d3","collapsed":true},"execution_count":null,"outputs":[],"source":"xtrain_glove.shape","cell_type":"code"},{"metadata":{"_uuid":"a35d54ae461f1c3f8a01173012c7350f5ab55ebc","_cell_guid":"4ab39d35-5d8b-41e0-9bef-db67b7516371","collapsed":true},"execution_count":null,"outputs":[],"source":"#clf = xgb.XGBClassifier(nthread=10, silent=False)\nclf = MultinomialNB()\n\n#clf.fit(xtrain_glove[0], ytrain)\n#predictions = clf.predict_proba(xvalid_glove[0])\n\nclf.fit(xtrain_glove1, ytrain)\npredictions = clf.predict_proba(xvalid_glove1)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","cell_type":"code"},{"metadata":{"_uuid":"3add749f80b119a6730b036467ef9ba29ef035c1","_cell_guid":"5c004a9a-f0f5-4579-8849-0d9f82a2c01f","collapsed":true},"execution_count":null,"outputs":[],"source":"\nclf.fit(xtrain_ctv, ytrain)\npredictions = clf.predict_proba(xvalid_ctv)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","cell_type":"code"},{"metadata":{"_uuid":"38a6a88508a05c5df1129b5df607dc7b798d692a","_cell_guid":"66b6300d-db4b-4e20-a2c3-2cfe8f411fee","collapsed":true},"execution_count":null,"outputs":[],"source":"","cell_type":"code"},{"metadata":{"_uuid":"44df0d9c23135729594450e5059961b5bf630280","_cell_guid":"fc0a4e07-ecef-4121-97cd-3e10a9faffe3","collapsed":true},"execution_count":null,"outputs":[],"source":"","cell_type":"code"}],"nbformat":4}