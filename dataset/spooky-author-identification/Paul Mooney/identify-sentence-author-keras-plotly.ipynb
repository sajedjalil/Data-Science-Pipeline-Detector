{"cells":[{"metadata":{"_cell_guid":"16bf83a3-1ffd-43b8-af62-a496ba3db95b","_uuid":"934e230bee5866e2ff84750a71c190e36b410a76"},"cell_type":"markdown","source":"**In this year's Halloween playground competition, you're challenged to predict the author of excerpts from horror stories by Edgar Allan Poe, Mary Shelley, and HP Lovecraft**"},{"metadata":{"_cell_guid":"989470ff-7461-483a-b4c8-99fb6dab440c","_uuid":"98fd938730c615f8c568d91fb2d435e069e33b2c","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nimport keras\nimport keras.backend as K\nfrom keras.layers import Dense, GlobalAveragePooling1D, Embedding\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"30fa123d-08de-43de-a42e-ffd230bee7d2","_uuid":"458a644c07358804a2af1adbb782d61e86fce409","collapsed":true,"trusted":false},"cell_type":"code","source":"df = pd.read_csv('./../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"31c8d188-4fc4-4036-a05d-5e4ec6344715","_uuid":"eefc1b0eff8d4a6111c45611b71ba02759885657"},"cell_type":"markdown","source":"**This is what the data looks like. It is a CSV file. \n\n**We have a column titled \"text\" containing sentences and a column titled \"author\" containing author initials.****"},{"metadata":{"_cell_guid":"3b758626-32e2-4e68-82e9-6a0fd7301daa","_uuid":"2a5d251576fcb8403a9b7bc99e5e8fbcf300f8e1","trusted":false,"collapsed":true},"cell_type":"code","source":"sample = df.values[0:3]\nprint(sample)\ndf.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"34d3233f-5351-4ac1-875c-65f089ecac26","_uuid":"089f1c4bdf362be9089f81e2e263ced74e8b04d0"},"cell_type":"markdown","source":"**Preprocess Text:**    \n    1) Add a space on both sides of punctuation to avoid forming new words based off of punctuation.\n    2) Convert author label to categorical label for better compatability with classification algorithms."},{"metadata":{"_cell_guid":"f28a8999-6853-499a-a0c9-389039269a83","_uuid":"e2f1f3c903a79adb62206a63f17fdad090699395","collapsed":true,"trusted":false},"cell_type":"code","source":"def preprocess(text):\n    text = text.strip()\n    text = text.replace(\"' \", \" ' \")\n    signs = set(',.:;\"?!')\n    prods = set(text) & signs\n    if not prods:\n        return text\n\n    for sign in prods:\n        text = text.replace(sign, ' {} '.format(sign) )\n    return text","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8eea0ca4-6023-400e-bc63-259379c84102","_uuid":"2c09477faeee8cbc12cb77c7540c1a021372b075","collapsed":true,"trusted":false},"cell_type":"code","source":"a2c = {'EAP': 0, 'HPL' : 1, 'MWS' : 2}\ny = np.array([a2c[a] for a in df.author])\ny = to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"66346abd-3765-4068-82fb-06421d6514af","_uuid":"4b0a82732778e7d78387eb6a94a772a0d401c5c3"},"cell_type":"markdown","source":"**An N-gram is a contiguous sequence of n items from a given sequence of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application (e.g. 2-gram sequence: \"to be, be or, or not, not to, to be\"; 3-gram sequence: \"to be or, be or not, or not to, not to be\".\n\n**Next I visualize some N-grams for Edgar Allan Poe.****"},{"metadata":{"_cell_guid":"10a77415-e725-4b9e-94be-3cb34f57c1a9","_uuid":"60e4821e56141d7f5175de9696246080cee0310f","collapsed":true,"trusted":false},"cell_type":"code","source":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\nimport plotly.plotly as py\nfrom collections import Counter\nfrom nltk.util import ngrams\nfrom nltk.corpus import stopwords\nimport re\n\n\ntokenize_regex = re.compile(\"[\\w]+\")\nsw = set(stopwords.words(\"english\"))\n\ndef preprocessText(text, ngram_order):\n    \"\"\"\n    Transform text into a list of ngrams. Feel free to play with the order parameter\n    \"\"\"\n    text = text.lower()\n    \n    text = [\" \".join(ngram) for ngram in ngrams((tokenize_regex.findall(text)), ngram_order) \\\n            if (set(ngram) - sw)] # instead of filtering stopwords, let's just filter out the ngrams\n                                  # with nothing but stopwords\n    return text\n\ndef draw_word_histogram(texts, title, bars=30):\n    \"\"\"\n    Draw a barplot for word frequency distribution.\n    \"\"\"\n    # first, do the counting\n    ngram_counter = Counter()\n    for text in texts:\n        ngram_counter.update(text)\n    # for plotly, we need two lists: xaxis values and the corresponding yaxis values\n    # this is how we split a list of two-element tuples into two lists\n    features, counts = zip(*ngram_counter.most_common(bars))\n    # now let's define the barplot\n    bars = go.Bar(\n        x=counts[::-1],  # inverse the values to have the largest on the top\n        y=features[::-1],\n        orientation=\"h\",  # this makes it a horizontal barplot \n        marker=dict(\n            color='rgb(128, 0, 32)'  # this color is called oxblood... spooky, isn't it?\n        )\n    )\n    # this is how we customize the looks of our barplot\n    layout = go.Layout(\n        paper_bgcolor='rgb(0, 0, 0)',  # color of the background under the title and in the margins\n        plot_bgcolor='rgb(0, 0, 0)',  # color of the plot background\n        title=title,\n        autosize=False,  # otherwise the plot would be too small to contain axis labels\n        width=600,\n        height=800,\n        margin=go.Margin(\n            l=120, # to make space for y-axis labels\n        ),\n        font=dict(\n            family='Serif',\n            size=13, # a lucky number\n            color='rgb(200, 200, 200)'\n        ),\n        xaxis=dict(\n            showgrid=True,  # all the possible lines - try switching them off\n            zeroline=True,\n            showline=True,\n            zerolinecolor='rgb(200, 200, 200)',\n            linecolor='rgb(200, 200, 200)',\n            gridcolor='rgb(200, 200, 200)',\n        ),\n        yaxis=dict(\n            ticklen=8  # to add some space between yaxis labels and the plot\n        )\n        \n    )\n    fig = go.Figure(data=[bars], layout=layout)\n    iplot(fig, filename='h-bar')\n    return\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"14d6c03a-3093-4ff6-8a52-f69bb448345c","_uuid":"df9e30bcc046ea020f659a5e6728051784c81a8b","trusted":false,"collapsed":true},"cell_type":"code","source":"init_notebook_mode(connected=True)\n\n\npoe = df[df.author==\"EAP\"].text.apply(preprocessText, ngram_order=1)\ndraw_word_histogram(poe, \"Edgar Allan Poe Most Common Mono-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"22bb06fa-93fc-4dba-81ff-48bc140be3cf","_uuid":"d2d0954ffee9fb3ad78ffc824f09e27a4f77b3ce","trusted":false,"collapsed":true},"cell_type":"code","source":"poe = df[df.author==\"EAP\"].text.apply(preprocessText, ngram_order=2)\ndraw_word_histogram(poe, \"Edgar Allan Poe Most Common Bi-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"73f2c6ad-d744-40e6-bff8-96adfd4ac18b","_uuid":"209b15264cdc51425fe3a8c00ddab453c5d890d4","trusted":false,"collapsed":true},"cell_type":"code","source":"poe = df[df.author==\"EAP\"].text.apply(preprocessText, ngram_order=3)\ndraw_word_histogram(poe, \"Edgar Allan Poe Most Common Tri-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8cd2ce6a-be80-4ec2-ab64-4a69e01523ef","_uuid":"64ff0d157067409b62b37a1c6de10d73aeab710e","trusted":false,"collapsed":true},"cell_type":"code","source":"poe = df[df.author==\"EAP\"].text.apply(preprocessText, ngram_order=4)\ndraw_word_histogram(poe, \"Edgar Allan Poe Most Common Quad-grams\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"14f7170f-837f-4f63-a763-ff834cb32b59","_uuid":"7bd7c3f28bdf74152b3ea4a33bce6fba07964880"},"cell_type":"markdown","source":"Here we create N-grams for N = (1 to 4) for each author.  These N-grams will be our features for classification."},{"metadata":{"_cell_guid":"e5588c12-eba7-4958-a0b3-03b0df265390","_uuid":"c345433eaf65a2bb867809c3c6cc3d543fcc11ef","collapsed":true,"trusted":false},"cell_type":"code","source":"def create_docs(df, n_gram_max=4):\n    def add_ngram(q, n_gram_max):\n            ngrams = []\n            for n in range(1, n_gram_max+1):\n                for w_index in range(len(q)-n+1):\n                    ngrams.append('--'.join(q[w_index:w_index+n]))\n            return q + ngrams\n        \n    docs = []\n    for doc in df.text:\n        doc = preprocess(doc).split()\n        docs.append(' '.join(add_ngram(doc, n_gram_max)))\n    \n    return docs","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f5133ac-af7c-41dd-84e2-5a118125ad97","_uuid":"6e52f8cf0525e05dea7baae3429a5fdbaeff524c","collapsed":true,"trusted":false},"cell_type":"code","source":"min_count = 15\n\ndocs = create_docs(df)\ntokenizer = Tokenizer(lower=True, filters='')\ntokenizer.fit_on_texts(docs)\nnum_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n\ntokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\ntokenizer.fit_on_texts(docs)\ndocs = tokenizer.texts_to_sequences(docs)\n\nmaxlen = None\n\ndocs = pad_sequences(sequences=docs, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"25151208-3394-4564-a7c0-2c6bcc29496e","_uuid":"972de057eb39e900210081aa1a03e6c0163dcc06"},"cell_type":"markdown","source":"**Here I use Keras to build a custom neural network for this natural language processing problem.  \n\n**Note that accuracy can be improved by increasing the number of epochs while speed can be improved by decreasing the number of epochs.****"},{"metadata":{"_cell_guid":"56422a4b-56c3-438f-94c1-3fa23f7a7506","_uuid":"4a0d20bd5dd6faf9e837597755c35c8954a81b74","collapsed":true,"trusted":false},"cell_type":"code","source":"input_dim = np.max(docs) + 1\nembedding_dims = 20","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"600d7b35-410b-47e6-b6d3-fb9d45298d89","_uuid":"ca3a6a889887d9d907cb567d2c25b7231f6baf02","collapsed":true,"trusted":false},"cell_type":"code","source":"def create_model(embedding_dims=20, optimizer='adam'):\n    model = Sequential()\n    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n    model.add(GlobalAveragePooling1D())\n    model.add(Dense(3, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizer,\n                  metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c068fbf2-7a71-4927-9d3e-1b6c72d27307","_uuid":"2d8568a0b6a469ec66d3dd69d4d9ee0c82c9f3cf","trusted":false,"collapsed":true},"cell_type":"code","source":"epochs = 20\nx_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n\nmodel = create_model()\nhist = model.fit(x_train, y_train,\n                 batch_size=16,\n                 validation_data=(x_test, y_test),\n                 epochs=epochs,\n                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ddb0dcb9-2ba6-4b3a-a4a9-64b9fc1f05dd","_uuid":"8db463ef000c1185c67b50be5dfd1a4e8448783e"},"cell_type":"markdown","source":"**>80% Accuracy!  Great!  Next, we can improve the accuracy by increasing the number of epochs.**"},{"metadata":{"_cell_guid":"37fdec5c-188f-4599-90c0-475459c4bbec","_uuid":"1daa34677b9f5e1fc906663360b03d2ea2c0632b","collapsed":true,"trusted":false},"cell_type":"code","source":"# test_df = pd.read_csv('../input/test.csv')\n# docs = create_docs(test_df)\n# docs = tokenizer.texts_to_sequences(docs)\n# docs = pad_sequences(sequences=docs, maxlen=maxlen)\n# y = model.predict_proba(docs)\n\n# result = pd.read_csv('../input/sample_submission.csv')\n# for a, i in a2c.items():\n#     result[a] = y[:, i]\n# result.to_csv('_new_submission_1.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"285f86d523946381ba800e211bffab085ad7e103"},"cell_type":"markdown","source":"**Credit:** Note that many of the functions are adaptations from https://www.kaggle.com/nzw0301/simple-keras-fasttext-val-loss-0-31 and https://www.kaggle.com/mamamot/human-intelligible-machine-learning."}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}