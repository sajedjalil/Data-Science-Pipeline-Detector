{"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","version":"3.6.3","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"cells":[{"outputs":[],"metadata":{"_cell_guid":"60193de3-44f8-45f2-ab95-2a53c2291ab0","collapsed":true,"_uuid":"6bd74c7f851695cc2d1ea38f9ffeb25c57512a80"},"cell_type":"code","execution_count":null,"source":"import warnings \nwarnings.filterwarnings('ignore')\nimport nltk \nimport pandas as pd \nfrom nltk.tokenize import RegexpTokenizer #will use this to remove puntuation and tokenize the text\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndf = pd.read_csv(\"../input/train.csv\")"},{"metadata":{"_cell_guid":"28d4d541-e8bc-4fa0-8a45-97f01ea59515","_uuid":"21fb6027c97dc4f3be9a0bc573db2f7bdff7cfd2"},"cell_type":"markdown","source":"The goal of this analysis is to examine how much differnce there is between the authors for different word types: adjectives, nouns and verbs. It is possible to distinguish between authors with word-usage but are some word types better for making the distinction?\n\nThe analysis will require using parts of speech (pos) tagging to identify and extract the adjectives, nouns and verbs. The steps I followed are:\n\nseparate the 3 authors into 3 pandas datasets\n\nconcatenate all rows for the 'text' column in each dataset, remove punctuation and tokenize the text\n\ntag the parts of speech\n\nextract the adjectives, verbs and nouns for each author\n\ninvestigate how each author uses different word types"},{"outputs":[],"metadata":{"_cell_guid":"42ada2da-a935-440d-8151-a145a9ac4ba0","collapsed":true,"_uuid":"8ef5daa32cb8b93609cf0839899f29a8f3c7935a"},"cell_type":"code","execution_count":null,"source":"df_eap = df[df['author'] == 'EAP'] #separate the 3 authors\ndf_hpl = df[df['author'] == 'HPL']\ndf_mws = df[df['author'] == 'MWS']\n\ntext_eap = df_eap['text'].str.cat(sep = ' ').lower() #concatenate all sentences for each author and set all characters to lower case\ntext_hpl = df_hpl['text'].str.cat(sep = ' ').lower()\ntext_mws = df_mws['text'].str.cat(sep = ' ').lower()\n\n#I am changing everything to lower case because I will do some word frequency analysis, \n#I don't want things like 'Old' and 'old counted as different words\n\ntokenizer = RegexpTokenizer(r'\\w+') \ntokens_eap = tokenizer.tokenize(text_eap) #this will return a list of tokens(words) in lower case with punctuation removed\ntokens_hpl = tokenizer.tokenize(text_hpl)\ntokens_mws = tokenizer.tokenize(text_mws)\n#note: one problem with the above approach is phrases like the \"man's hat\" will be tokenized into 3 tokens (man, s, hat)\npos_list_eap = nltk.pos_tag(tokens_eap) #this step will add the pos tags\npos_list_hpl = nltk.pos_tag(tokens_hpl)\npos_list_mws = nltk.pos_tag(tokens_mws)"},{"metadata":{"_cell_guid":"7218f484-f5db-4c52-bf6c-928ca45f8384","_uuid":"c0c6df1f3ae963f3d07d9ef64d7b908080395610"},"cell_type":"markdown","source":"The above code generates a list where each element in the list is of the form (word,pos-tag). The next step is to extract the adjectives so pull out each element where pos-tag = JJ, JJR or JJS. You can get a complete list of tags by running: print(nltk.help.upenn_tagset())"},{"outputs":[],"metadata":{"_cell_guid":"1dafe748-f552-4844-8995-6c4dd5883e90","collapsed":true,"_uuid":"2bdbbab41f71c1b8e38549393efa40750efc76c5"},"cell_type":"code","execution_count":null,"source":"# function to test if something is an adjective, comparitive or superlatives\ndef is_adj(pos):\n    result = False\n    if pos in ('JJ','JJR','JJS'):\n        result = True\n    return result\n\nadj_eap = [word for word, pos in pos_list_eap if is_adj(pos) and len(word) > 1] #this is just a list of all adjectives for EAP\nadj_hpl = [word for word, pos in pos_list_hpl if is_adj(pos) and len(word) > 1]\nadj_mws = [word for word, pos in pos_list_mws if is_adj(pos) and len(word) > 1]\n\n# I added the > 1 test because 'i' is sometimes marked as JJ. I think this is because JJ also covers numerals and ordinals, maybe \n#'i' is being seen as Roman numeral for one(?)\n\nfreq_eap = nltk.FreqDist(adj_eap) #this gets the frequency distribution for the adjectives in the list adj_eap\nfreq_hpl = nltk.FreqDist(adj_hpl)\nfreq_mws = nltk.FreqDist(adj_mws)\n\n#if you want to print out the top twenty list use:\n#print(freq_eap.most_common(20))\n#print(freq_hpl.most_common(20))\n#print(freq_mws.most_common(20))"},{"metadata":{"_cell_guid":"528208d6-ccee-4cc1-93a4-56f2241aee66","_uuid":"00b440401919d39099788b1822ea5819bd0c89b2"},"cell_type":"markdown","source":"Visualising the ratio of adjectives used to total words used."},{"outputs":[],"metadata":{"_cell_guid":"2c4b6cb1-e282-4e8e-9ab4-0998343a0df7","_uuid":"b2d8920e03553bdd704727d1029069b8ec8ea831"},"cell_type":"code","execution_count":null,"source":"eap = len(adj_eap)/len(tokens_eap)#number of adjectives divided by total number of words for EAP\nhpl = len(adj_hpl)/len(tokens_hpl)\nmws = len(adj_mws)/len(tokens_mws)\n\nd = {'EAP':eap, 'HPL': hpl, 'MWS':mws} \n\nplt.bar(range(len(d)), d.values(), align='center')\nplt.xticks(range(len(d)), d.keys())\nplt.title(\"Adjectives used as a fraction of total words for each author\")\n\nplt.show()"},{"metadata":{"_cell_guid":"cf82509a-4928-40ba-939a-83370c912069","_uuid":"9d80cf06084fc7e7d255cb8731a8ce6e7b9358b3"},"cell_type":"markdown","source":"Note: the pos tagger is not 100% accurate, some of the words it marked as 'JJ' include: 'adrian' which is a name not an adjective. Also words like 'such' and 'other' which I think are determiners not adjectives. So we can't assume that all values returned by the tagger are what we expect them to be. \n\nBased on the test data HPL uses adjectives the most (just under 10% of all words) and MWS the least (about 7.5% of all words). "},{"metadata":{"_cell_guid":"d83144a6-f60a-4218-90b5-8315958ce0ed","_uuid":"dd4db81af0bc72154aa304deb02e85105d393b3a"},"cell_type":"markdown","source":"Top 20 adjectives for each author"},{"outputs":[],"metadata":{"_cell_guid":"d9c28156-a255-431d-8745-783cac8fd6f0","_uuid":"f4714696d5095b7b4e824b1d77286434393718c8"},"cell_type":"code","execution_count":null,"source":"freq_eap.plot(20,cumulative=False,title='top 20 adjectives for EAP') #looking just at top 20 adjectives  for EAP"},{"outputs":[],"metadata":{"_cell_guid":"290fed85-8724-47a5-bd7d-5e20c9d0aaea","_uuid":"4ca262fb4c0fe5eeae9a49f5f1c47021eb051875"},"cell_type":"code","execution_count":null,"source":"freq_hpl.plot(20,cumulative=False,title='top 20 adjectives for HPL')  # HPL"},{"metadata":{"_cell_guid":"5cf4ca99-b4e9-4618-a506-6351e4bd8931","_uuid":"23609d80290b4cfcacca782f93406327d0481a87"},"cell_type":"markdown","source":"Note HPL's use of the word 'old', he really does like that word."},{"outputs":[],"metadata":{"_cell_guid":"7971edb3-ab11-4222-b3ce-fc458f3a0a4a","_uuid":"78efa9c1cdefc924027a4fe4f235610560df4bdb"},"cell_type":"code","execution_count":null,"source":"freq_mws.plot(20,cumulative=False, title='top 20 adjectives for MWS')  # MWS"},{"metadata":{"_cell_guid":"9c59c120-fbfb-44cc-b791-4d4d2ccb7928","_uuid":"5a3983fcc32907c94ffac96a36a400a4a516f1f2"},"cell_type":"markdown","source":"To further investigate the degree of similarity in adjectives used by the different authors I will convert the lists of adjectives to sets and calculate the Jaccard similarities."},{"outputs":[],"metadata":{"_cell_guid":"3ea2614b-38d4-43c3-a580-064ddc2d3796","_uuid":"48e78985a0cbc60081e408122e876195741f6aba"},"cell_type":"code","execution_count":null,"source":"from math import*\n \ndef jaccard_similarity(x,y):\n    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n    union_cardinality = len(set.union(*[set(x), set(y)]))\n    return intersection_cardinality/float(union_cardinality)\n\nset_eap = set(adj_eap)\nset_hpl = set(adj_hpl)\nset_mws = set(adj_mws)\nprint('Jaccard Similarity scores for adjectives used by each pair of authors')\nprint('EAP - HPL: ' + str(jaccard_similarity(set_eap,set_hpl)))\nprint('EAP - MWS: ' + str(jaccard_similarity(set_eap,set_mws)))\nprint('MWS - HPL: ' + str(jaccard_similarity(set_hpl,set_mws)))"},{"metadata":{"_cell_guid":"7eafb463-dcb9-4b71-a0e4-b9a14fc7bea7","_uuid":"bdf23ad211d5f101b3b7b0c8c15cd664cf7a4ff2"},"cell_type":"markdown","source":"These numbers are quite low, this is good news for everyone using word-usage to distinguish authors, at least for the adjectives. High numbers would mean lots of overlap in word-usage. It looks like the adjectives used by HPL and MWS are the most divergent. While those used by EAP and MWS are the most similar.\n\n**Verb usage:**"},{"outputs":[],"metadata":{"_cell_guid":"64219502-380f-46f4-9fc4-5a3b50782070","collapsed":true,"_uuid":"a745125862823691a96f5d5a350238966345f38b"},"cell_type":"code","execution_count":null,"source":"def is_verb(pos):\n    result = False\n    if pos in ('VB','VBD','VBG','VBN','VBP','VBZ'):\n        result = True\n    return result\n\nverb_eap = [word for word, pos in pos_list_eap if is_verb(pos) and len(word) > 1] \nverb_hpl = [word for word, pos in pos_list_hpl if is_verb(pos) and len(word) > 1]\nverb_mws = [word for word, pos in pos_list_mws if is_verb(pos) and len(word) > 1]\n#the >1 test prevents things like 'i' being tagged, there are no verbs in English with just 1 character\nfreq_eap_verb = nltk.FreqDist(verb_eap) \nfreq_hpl_verb = nltk.FreqDist(verb_hpl)\nfreq_mws_verb = nltk.FreqDist(verb_mws)\n\n#if you want to print out the top twenty list use:\n#print(freq_eap_verb.most_common(20))\n#print(freq_hpl_verb.most_common(20))\n#print(freq_mws_verb.most_common(20))"},{"outputs":[],"metadata":{"_cell_guid":"735dc2ad-06a2-4cef-a3e3-b68fbe3762ef","_uuid":"472d1227dee8e890a206dc9946814c8683c60642"},"cell_type":"code","execution_count":null,"source":"eap = len(verb_eap)/len(tokens_eap)\nhpl = len(verb_hpl)/len(tokens_hpl)\nmws = len(verb_mws)/len(tokens_mws)\n\nd = {'EAP':eap, 'HPL': hpl, 'MWS':mws} \n\nplt.bar(range(len(d)), d.values(), align='center')\nplt.xticks(range(len(d)), d.keys())\nplt.title(\"Verbs used as a fraction of total words for each author\")\nplt.show()"},{"metadata":{"_cell_guid":"19cdb780-6723-4452-b072-92f986072fd1","_uuid":"54315c7f340fa8273926a81d253236a968826480"},"cell_type":"markdown","source":"Note that each author uses a lot more verbs than adjectives.\n\nTop twenty verbs:"},{"outputs":[],"metadata":{"_cell_guid":"b165a723-d2bd-47fa-8fe1-d032fc5a47bc","_uuid":"7e6e2b248c441a53d33e0be2321a778d06d68657"},"cell_type":"code","execution_count":null,"source":"freq_eap_verb.plot(20,cumulative=False,title='top 20 verbs for EAP')"},{"outputs":[],"metadata":{"_cell_guid":"b6e41364-78e0-41ac-aa17-7f4b12d497ce","_uuid":"8fbec3f391f54992c0f7696f225b1ab9183bc038"},"cell_type":"code","execution_count":null,"source":"freq_hpl_verb.plot(20,cumulative=False,title='top 20 verbs for HPL')"},{"outputs":[],"metadata":{"_cell_guid":"9577a059-cf40-440d-8f9a-d47121fd4a2f","_uuid":"35344f7e9e9a4dac8d4e6efd16252ae9e51de098"},"cell_type":"code","execution_count":null,"source":"freq_mws_verb.plot(20,cumulative=False,title='top 20 verbs for MWS')"},{"outputs":[],"metadata":{"_cell_guid":"01c0ee49-039b-4c19-8ddf-6cb1e4b79d91","_uuid":"8a4be0a93be95f60624109ca866ffde77b85d1e0"},"cell_type":"code","execution_count":null,"source":"from math import*\n \ndef jaccard_similarity(x,y):\n    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n    union_cardinality = len(set.union(*[set(x), set(y)]))\n    return intersection_cardinality/float(union_cardinality)\n\nset_eap = set(verb_eap)\nset_hpl = set(verb_hpl)\nset_mws = set(verb_mws)\n \nprint('Jaccard Similarity scores for verbs used by each pair of authors')\nprint('EAP - HPL: ' + str(jaccard_similarity(set_eap,set_hpl)))\nprint('EAP - MWS: ' + str(jaccard_similarity(set_eap,set_mws)))\nprint('MWS - HPL: ' + str(jaccard_similarity(set_hpl,set_mws)))"},{"metadata":{"_cell_guid":"4abcf7e0-2375-42d6-91f8-7de5a6b39b35","_uuid":"fc0c62200380457a1e703e9a42c6ac7d4ebbea70"},"cell_type":"markdown","source":"These values are higher than for adjectives - there is more overlap in the verbs used. Or put it another way, adjectives are better at distinguishing authors.\n\n**Noun usage:**"},{"outputs":[],"metadata":{"_cell_guid":"e27771b1-f86f-4f73-b3a5-dec6f3107285","collapsed":true,"_uuid":"79cdbb5b4dd49068f623c0af183ba83b342fc1e8"},"cell_type":"code","execution_count":null,"source":"def is_noun(pos):\n    result = False\n    if pos in ('NN','NNP','NNPS','NNS'):\n        result = True\n    return result\n\nnoun_eap = [word for word, pos in pos_list_eap if is_noun(pos) and len(word) > 1]\nnoun_hpl = [word for word, pos in pos_list_hpl if is_noun(pos) and len(word) > 1]\nnoun_mws = [word for word, pos in pos_list_mws if is_noun(pos) and len(word) > 1]\n#the >1 test gets rid of the 's' problem mentioned above, it also gets rid of the pronoun 'i' which dominates\n#the plots\nfreq_eap_noun = nltk.FreqDist(noun_eap) \nfreq_hpl_noun = nltk.FreqDist(noun_hpl)\nfreq_mws_noun = nltk.FreqDist(noun_mws)\n\n#if you want to print out the top twenty list use:\n#print(freq_eap_noun.most_common(20))\n#print(freq_hpl_noun.most_common(20))\n#print(freq_mws_noun.most_common(20))"},{"outputs":[],"metadata":{"_cell_guid":"241d0179-e535-41ff-80be-f9cc88fb8de1","_uuid":"0fb8bc82445e8808b52637972ceedbabdd89a2d5"},"cell_type":"code","execution_count":null,"source":"eap = len(noun_eap)/len(tokens_eap)\nhpl = len(noun_hpl)/len(tokens_hpl)\nmws = len(noun_mws)/len(tokens_mws)\n\nd = {'EAP':eap, 'HPL': hpl, 'MWS':mws} \n\nplt.bar(range(len(d)), d.values(), align='center')\nplt.xticks(range(len(d)), d.keys())\nplt.title(\"Nouns used as a fraction of total words for each author\")\nplt.show()"},{"metadata":{"_cell_guid":"f138a1ce-ed14-4834-881c-7d923582535f","_uuid":"dda0125072a38e892e5aca70960364f8f09cbfc3"},"cell_type":"markdown","source":"Nouns are used more than either verbs or adjectives. There isn't any significant difference in the ratio of nouns used by any author."},{"outputs":[],"metadata":{"_cell_guid":"58773a02-5b3b-49fe-baef-73169cd06c0e","_uuid":"b732b0a39a1e972a6e2e9c0e09701ebcafa99850"},"cell_type":"code","execution_count":null,"source":"freq_eap_noun.plot(20,cumulative=False,title='top 20 nouns for EAP')"},{"outputs":[],"metadata":{"_cell_guid":"ef10b9dd-9ce4-44ca-b038-e8a0f2f9da35","_uuid":"3cef6a6a616ca0eb717b570454a4b8d6a50e957c"},"cell_type":"code","execution_count":null,"source":"freq_hpl_noun.plot(20,cumulative=False,title='top 20 nouns for HPL')"},{"outputs":[],"metadata":{"_cell_guid":"54818c45-11f0-4d70-b53a-d7827dae5b3e","_uuid":"e0aeb1d0fd53bd2669b71f6dcbd25d5fb629159b"},"cell_type":"code","execution_count":null,"source":"freq_mws_noun.plot(20,cumulative=False,title='top 20 nouns for MWS')"},{"outputs":[],"metadata":{"_cell_guid":"07582471-901d-4bbb-87b4-a0cd2a88fe65","_uuid":"2568cb50f14ccdd636cd8afd9f84c960b2a64d74"},"cell_type":"code","execution_count":null,"source":"from math import*\n \ndef jaccard_similarity(x,y):\n    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n    union_cardinality = len(set.union(*[set(x), set(y)]))\n    return intersection_cardinality/float(union_cardinality)\n\nset_eap = set(noun_eap)\nset_hpl = set(noun_hpl)\nset_mws = set(noun_mws)\n \nprint('Jaccard Similarity scores for nouns used by each pair of authors')\nprint('EAP - HPL: ' + str(jaccard_similarity(set_eap,set_hpl)))\nprint('EAP - MWS: ' + str(jaccard_similarity(set_eap,set_mws)))\nprint('MWS - HPL: ' + str(jaccard_similarity(set_hpl,set_mws)))"},{"metadata":{"_cell_guid":"119522ab-3ac2-4f88-bd7d-e7806189f6cb","_uuid":"6e3522f5cb29ad492293c6307f444672d470bfef"},"cell_type":"markdown","source":"MWS and HPL have the lowest overlap in terms of the nouns they use. EAP and MWS are closest in their use of nouns. I find it interesting that all three authors have the nouns man/men and time in their top six nouns even though they are writing about different things, and two of them have 'eyes' in the top six nouns. \n\n"},{"metadata":{"_cell_guid":"6f14becb-00c2-45d6-a188-06bc74f844ff","_uuid":"50a6c5f187a236ddfa017adeff89f7c7d5d3d21d"},"cell_type":"markdown","source":"**Analysis of stopwords:**"},{"outputs":[],"metadata":{"_cell_guid":"0ced1384-dd43-4df6-8b9e-24806c6a0b8f","_uuid":"5324b627de9378a80ca6effc88e18dbf3507f60a"},"cell_type":"code","execution_count":null,"source":"stopwords = nltk.corpus.stopwords.words('english')\n\neap_stop = [t for t in tokens_eap if t in stopwords]\nhpl_stop = [t for t in tokens_hpl if t in stopwords]\nmws_stop = [t for t in tokens_mws if t in stopwords]\n\nfreq_eap_stop = nltk.FreqDist(eap_stop) \nfreq_hpl_stop = nltk.FreqDist(hpl_stop)\nfreq_mws_stop = nltk.FreqDist(mws_stop)\n\nfreq_eap_stop.plot(20,cumulative=False,title='top 20 stop words for EAP')"},{"outputs":[],"metadata":{"_cell_guid":"2b1d5393-e0b3-4d41-8d61-35732e6ca8bf","_uuid":"a67e9f24e1d84f9f013288ce706f0906fc3c12a5"},"cell_type":"code","execution_count":null,"source":"freq_hpl_stop.plot(20,cumulative=False,title='top 20 stop words for HPL')"},{"outputs":[],"metadata":{"_cell_guid":"5967b74f-de65-44ee-b5c6-4d4127b8c3b8","_uuid":"6480b4dd2ccb11ed6e1e02d5c8f290f0ff915de0"},"cell_type":"code","execution_count":null,"source":"freq_mws_stop.plot(20,cumulative=False,title='top 20 stop words for MWS')"},{"metadata":{"_cell_guid":"d3fb27c0-6bc4-4277-ae4d-cc3fc6574019","_uuid":"5f5bcf760e138ab033ff2e2bc2a754439f25e10c"},"cell_type":"markdown","source":"Note the similarities in the graphs and the frequency distributions for the top stopwords. There is a lot less choice in words used when it comes to stopwords."},{"outputs":[],"metadata":{"_cell_guid":"6f8f61b6-a1f1-4531-8429-88e1ba2f9469","_uuid":"b7cb9b210c9bd096ebe14700529f73880e4b1757"},"cell_type":"code","execution_count":null,"source":"from math import*\n \ndef jaccard_similarity(x,y):\n    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n    union_cardinality = len(set.union(*[set(x), set(y)]))\n    return intersection_cardinality/float(union_cardinality)\n\nset_eap = set(eap_stop)\nset_hpl = set(hpl_stop)\nset_mws = set(mws_stop)\n \nprint('Jaccard Similarity scores for nouns used by each pair of authors')\nprint('EAP - HPL: ' + str(jaccard_similarity(set_eap,set_hpl)))\nprint('EAP - MWS: ' + str(jaccard_similarity(set_eap,set_mws)))\nprint('MWS - HPL: ' + str(jaccard_similarity(set_hpl,set_mws)))"},{"metadata":{"_cell_guid":"65ab5f95-d48c-4037-8f0d-5542d120c208","_uuid":"12375c7ead8aa14d28acd0f3e2461f2fe9b4a334"},"cell_type":"markdown","source":"These numbers are much higher than for other parts of speech, this is not surprising because the set of stopwords is quite small and authors often have little or no choice in the words they can use - stopwords often perform grammatical functions so are not optional or interchangable.\n\n**Third person (male v female) pronoun usage:**"},{"outputs":[],"metadata":{"_cell_guid":"4712afec-b98c-40bf-b8a9-25cfc85ad2e0","collapsed":true,"_uuid":"f1e48b2bf88f9216c0a2c32ffd979c66e0681682"},"cell_type":"code","execution_count":null,"source":"pronoun = ['he','she','him','her','his']\n\neap_pronoun = [t for t in tokens_eap if t in pronoun]\nhpl_pronoun = [t for t in tokens_hpl if t in pronoun]\nmws_pronoun = [t for t in tokens_mws if t in pronoun]\n\nfreq_eap_pronoun = nltk.FreqDist(eap_pronoun) \nfreq_hpl_pronoun = nltk.FreqDist(hpl_pronoun)\nfreq_mws_pronoun = nltk.FreqDist(mws_pronoun)"},{"outputs":[],"metadata":{"_cell_guid":"78fdc90e-3fa5-4c44-a13c-5dadc4096dac","_uuid":"16266e1afb7de3a4d2e34ded89c62baff31ed589"},"cell_type":"code","execution_count":null,"source":"freq_eap_pronoun.plot(5,cumulative=False,title='top third person pronouns for EAP')"},{"outputs":[],"metadata":{"_cell_guid":"3ec57998-0a83-4858-88c6-f1d68ab66267","_uuid":"8b1e41f4dab75b5d53cec793fe2330398e02503c"},"cell_type":"code","execution_count":null,"source":"freq_hpl_pronoun.plot(5,cumulative=False,title='top third person pronouns for HPL')"},{"outputs":[],"metadata":{"_cell_guid":"f190feca-03c9-4330-8cfc-0cc6cc5620e9","_uuid":"d6801c409871871b122faf58a19620c63d73871e"},"cell_type":"code","execution_count":null,"source":"freq_mws_pronoun.plot(5,cumulative=False,title='top third person pronouns for MWS')"},{"metadata":{"_cell_guid":"9c31c8c3-210a-4b04-94e2-0d7977d03bac","_uuid":"dc32c4bf7dc763cb4fdfd22559116da3d38b19ae"},"cell_type":"markdown","source":"If you chose to remove stopwords before making your predictions how much data will you lose?\nWhat percentage of all words used do stopwords represent for each author?"},{"outputs":[],"metadata":{"_cell_guid":"09278d13-e2b1-4c42-81be-681bbb8caae0","_uuid":"066ca9db46b3ae736197fcb562b78c7e33d75604"},"cell_type":"code","execution_count":null,"source":"eap = len(eap_stop)/len(tokens_eap)\nhpl = len(hpl_stop)/len(tokens_hpl)\nmws = len(mws_stop)/len(tokens_mws)\n\nd = {'EAP':eap, 'HPL': hpl, 'MWS':mws} \n\nplt.bar(range(len(d)), d.values(), align='center')\nplt.xticks(range(len(d)), d.keys())\nplt.title(\"Stopwords as a fraction of total words for each author\")\nplt.show()"},{"metadata":{"_cell_guid":"99f645d5-7b64-48e9-89ac-545072ba919c","_uuid":"c33d2ac88a974213b7bc25ac6aa24d7d497aea8b"},"cell_type":"markdown","source":"If you remove stopwords you will lose around 40% to 50% of the available data.\n\nTo test the effect of this I created two submission files using the code in Sohier Dane's kernel: How to Generate & Format a Simple Submission. I slightly changed the code by adding a function that removed stopwords before generating the submission file.\n"},{"metadata":{"_cell_guid":"c46762a5-0a27-4df6-8a86-e2d9dcc84cd2","_uuid":"67199999f936ea3586b7be960af8b0dd406418a5"},"cell_type":"markdown","source":"**Results of testing**\nThe first submission (included stopwords) generated a score of 0.46887 and put me in 330th place. The second submission generated a score of 0.45376 and put me in 300th position so an improvement of about 3% in the score and 30 places on the leaderboard. For multinomial naive bayes removing the stopwords seems to result in a small improvement in the final result.\n\n**Summary:** I think adjectives are the best words (at least based on the training dataset) to use in order to distinguish between the authors, they show the most divergence between authors. However adjectives account for less than 10% of the total words used. So nouns and verbs cannot be discarded. Stopwords show the least divergence, it is a small set of words which are grammatically essential so authors can't avoid using them and have little or no choice in the words they use (for example there are no synonyms for 'the' or 'a' or 'is'...). My testing indicates a modest improvement for multinomial naive bayes when stopwords are removed.\nOverall MWS and HPL are the most divergent in terms of the sets of words they use so they should be a little easier to distinguish. EAP and MWS are the least divergent so they might be more difficult to distinguish."},{"metadata":{"_cell_guid":"b8ec7545-a94c-403b-990a-d3927b48edd9","_uuid":"d98aa70226053addf9d324c0a64d4d0bea67a3da"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"73365bff-6948-4773-97f1-460fef92b67f","_uuid":"c920765f4f34ad4f9c5b3daa80116be190fc8205"},"cell_type":"markdown","source":""}],"nbformat_minor":1,"nbformat":4}