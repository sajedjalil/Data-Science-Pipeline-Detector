{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"c860dfe730a9e3d31c53bb54fd8d6aa92d6fc6d5","_cell_guid":"5fe9af2a-1275-4c2a-abd8-30de796034a7"},"source":"This is a approach i am experimenting on, If its possible to get decent result by using pattern in the way sentence are created rather than the traditional Tfidf or word vec and other conventional methord.\nI would give credit to kaggle for helping me get more features than i know . Altough right now the model is not good and gives less than 40 performance, I am working on it improve performance. Anyway the no of features i pulled out can be used with any NLP project. Some are common some are creative. Anyone is open how i can improve the model.  "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"d59bf73eae24a74ada87ece4abff88cf1642d5ea","_cell_guid":"0025ed29-6892-44fa-bc50-aaac5559a4b2","collapsed":true},"outputs":[],"source":"\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/train.csv\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"a902406593419b6cd61ab03673e73251f071c015","_cell_guid":"5cb967ec-9907-4b82-b30c-dca49626596e","collapsed":true},"outputs":[],"source":"import numpy as np # to do mathametical operation\nimport string #for text pre-processing\nfrom nltk.corpus import stopwords #for removing stopwords\nimport re #Regular expression operations\nimport xgboost as xgb #For predicting the values\nfrom sklearn.model_selection import KFold #for cross validations(CV)\nfrom sklearn import metrics #for getting CV score\nfrom collections import Counter #counting of words in the texts\nimport operator\nfrom nltk import ngrams\nimport nltk # major package for language processing\nfrom nltk import word_tokenize # for toconizing\nimport matplotlib.pyplot as plt"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"1192c748f07f0dfa8909b48690283e1df0563913","_cell_guid":"c5163faf-77b1-4cd2-81e3-3d4b95e89c19","collapsed":true},"outputs":[],"source":"training_df = pd.read_csv(\"../input/train.csv\")"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"09f98e01486ec7a53920d8e296b22d5b3cc8b6c8","_cell_guid":"e9786c2b-f30b-4866-b826-22444ef1543f","collapsed":true},"outputs":[],"source":"training_df.head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0e7d163d978b01c86a6f476504fd6fa3f8c8245a","_cell_guid":"079bba55-b6ee-4721-b5fb-f871e98649aa","collapsed":true},"outputs":[],"source":"training_author_df=training_df.groupby('author',as_index=False).count()\ntraining_author_df"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"10473ce4a8ff70fc7857502be09ca836755f8b0b","_cell_guid":"bcd9e194-0057-4866-9218-98f18aa2f8e8","collapsed":true},"outputs":[],"source":"# taking in the first field\ntext_string=training_df.iloc[0]['text']\ntext_string"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"d277c86d618ccc62ac386a4d8ba7a6bf4e74b906","_cell_guid":"2ba03044-5f3a-4865-bcd7-09ca0ee129cd","collapsed":true},"outputs":[],"source":"string.punctuation\ndef remove_punctuation_from_string(string1):\n    string1=string1.lower() # changing to lower case\n    translation_table=dict.fromkeys(map(ord,string.punctuation),' ')\n    string2=string1.translate(translation_table)\n    return string2\nprint('After processing')\ntest_string=remove_punctuation_from_string(text_string)\ntest_string"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e9b1cd31c6bcaf4cdd901beca30e1204da38b895","_cell_guid":"91b6b6f8-3681-40de-9f77-dec2fed02c14","collapsed":true},"outputs":[],"source":"def remove_stopwords_from_string(string1):\n    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*') #compiling all stopwords.\n    string2 = pattern.sub('', string1) #replacing the occurrences of stopwords in string1\n    return string2\n\nprint('After processing')\ntest_string = remove_stopwords_from_string(test_string)\ntest_string"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"bfb1ae6985e569b3c61bcbdc50c4747d44e5e69c","_cell_guid":"d8e3ad4c-3639-4ae7-966e-f26d371a5b65","collapsed":true},"outputs":[],"source":"training_df['text_backup']=training_df['text']"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"aa88eeed9208f822452442e2b293503d81451106","_cell_guid":"4acb3874-5715-4c5d-8f02-00dc20025f25","collapsed":true},"outputs":[],"source":"# usiing apply to remove the unwanted words.\ntraining_df['text']=training_df['text'].apply(lambda x: remove_punctuation_from_string(x))\ntraining_df['text']=training_df['text'].apply(lambda x: remove_stopwords_from_string(x))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"fa881ff81ab56bc1b151f57f06747e0695d26141","_cell_guid":"c7d383a0-c4b4-4af4-a4de-0645012056f8","collapsed":true},"outputs":[],"source":"# now I have cleaned the data. Its time for processing the data and create features from it.\n#Feature 1 : Finding total words in the sentance\ntraining_df['feature1']=training_df['text_backup'].apply(lambda x: len(str(x).split()))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"162021811e012dfb989242baefef151a2bc43245","_cell_guid":"7bdf346a-173c-4c3c-975b-cee8e8b2aadf","collapsed":true},"outputs":[],"source":"#Feature 2 : Counting no of charecter in a variable\ntraining_df['feature2']=training_df['text_backup'].apply(lambda x: len(str(x)))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"92beca948394b0903ef208e5420a022c1ff7f207","_cell_guid":"ce5a1e64-be90-4a46-9ede-9a91e60d3ec2","collapsed":true},"outputs":[],"source":"#Feature 3 : Avg leangth of words used in the sentance.\ntraining_df['feature3']=training_df['feature2']/training_df['feature1']"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"bd6c71021d7218bd67573ba1c8d4f84d81123898","_cell_guid":"5a889d21-c6a0-454a-bc4a-b0a0d2490f4d","collapsed":true},"outputs":[],"source":"# Feature 4: Count total stop words  in a sentence.\nstop_words=set(stopwords.words('english'))\ntraining_df['Feature4']=training_df['text_backup'].apply(lambda x: len([w for w in str(x).lower().split() \n                                                                       if w in stop_words ]))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"ed8554efcdcfd0fc7c506a90af68033f023f13a1","_cell_guid":"76426dfd-8e5a-44f2-9114-2afefb935ae1","collapsed":true},"outputs":[],"source":"#finding the words that are used the most \nall_text_without_sw= ''\nfor i in training_df.itertuples():\n    all_text_without_sw = all_text_without_sw +str(i.text)\n    #getting count of each word\n    counts=Counter(re.findall(r\"[\\w']+\", all_text_without_sw))\n    #deleting from counts\n    del counts[\"'\"]\n    # getting top 50 words\n    sorted_x=dict(sorted(counts.items(), key=operator.itemgetter(1), reverse = True)[:50])\n    \n# Feature 5 : The count of top words\n    \ntraining_df['Feature5']= training_df['text'].apply(lambda x: len([w for w in str(x).lower().split() \n                                                                     if w in sorted_x]))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"23a7e5368de55c0ba30d38bf7b77a80cbfdd842f","_cell_guid":"020836d4-2758-4710-b134-d25d8db1b044","collapsed":true},"outputs":[],"source":"# Feature 6 : least used words\nreverted_x=dict(sorted(counts.items(), key=operator.itemgetter(1))[:1000])\n\ntraining_df['Feature6']=training_df['text'].apply(lambda x: len ([w for w in str(x).lower().split() \n                                                                  if w in reverted_x]))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"155e299ba2241acae73ba3cf5c59bdac0fe4dc18","_cell_guid":"82f3e30e-ce1c-4a13-bd5b-8e29855bf4fd","collapsed":true},"outputs":[],"source":"# Feature 7 : Find the total no of puntuation\ntraining_df['Feature7']= training_df['text_backup'].apply(lambda x: len([w for w in str(x) \n                                                                         if w in string.punctuation]))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"29ed951108d2ecb9eb966a0ab01aa785d9973b4f","_cell_guid":"9a0da503-bac9-4eae-a008-c7e597750ce3","collapsed":true},"outputs":[],"source":"#Feature-8: Count of UPPER case words.\n\ntraining_df['Feature8']=training_df['text'].apply(lambda x: \n                                                  len([w for w in str(x).replace('I','i')\n                                                                 .replace('A','a').split() if w.isupper()==True])) "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"1939653f33ec2d1277dec941d328ba49dc38e8f1","_cell_guid":"99539534-1702-499d-b5ce-533c116373f4","collapsed":true},"outputs":[],"source":"#Feature-9: Count of Title case words\n\ntraining_df['Feature9']= training_df['text'].apply(lambda x: len([w for w in str(x).replace('I','i')\n                                                                  .replace('A','a').split() if w.istitle==True]))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"9122d413ef46a7d1f1bdf941e31742729e08e8c6","_cell_guid":"7c0dc3d8-9667-4ff4-b11d-e0cf7e14dad0","collapsed":true},"outputs":[],"source":"starting_words = sorted(list(map(lambda word : word[:2],filter(lambda word :\n                                                               len(word) > 3,all_text_without_sw.split()))))\nsw_counts = Counter(starting_words)\ntop_30_sw = dict(sorted(sw_counts.items(), key=operator.itemgetter(1),reverse=True)[:30])\n\n\n\n#Feature-10: Count of (Most words start with)\ntraining_df['Feature_10'] = training_df['text'].apply(lambda x: \n                                                      len([w for w in str(x).lower().split()\n                                                           if w[:2] in top_30_sw and w not in stop_words]) )"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"c71b2c555fd5a43932cff9717cab960578cc9d77","_cell_guid":"42493562-27a2-46f9-bf49-65a65232b5b7","collapsed":true},"outputs":[],"source":"#Feature-11: Count of (Most words end with)\nending_words = sorted(list(map(lambda word : word[-2:],filter(lambda word : len(word) > 3,all_text_without_sw.split()))))\new_counts = Counter(ending_words)\ntop_30_ew = dict(sorted(sw_counts.items(), key=operator.itemgetter(1),reverse=True)[:30])\ntraining_df['Feature_11'] = training_df['text'].apply(lambda x: len([w for w in str(x).lower().split() \n                                                                     if w[:2] in top_30_ew and w not in stop_words]) )"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6fad415d1048a53c90d3bcd9de0abc73fa126c0c","_cell_guid":"0511e326-6a66-4c8d-803e-f1d8602d56da","collapsed":true},"outputs":[],"source":"di = {'EAP': 0,'HPL':1, 'MWS':2}\ntraining_df=training_df.replace({\"author\": di})\ntesting_df=testing_df.replace({\"author\": di})"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b7ba95176fa3cfb80c943e348ca511dbcb605641","_cell_guid":"9fcbdc4f-d7dc-4484-bcea-00b695e618b9","collapsed":true},"outputs":[],"source":"y=training_df['author']\nX=training_df.drop(['author'],1)\ny=pd.get_dummies(y)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"74b18c3f0d8ab5bbe03fd84e56f48c1fcbea214f","_cell_guid":"d838e004-8647-4119-8037-061930e1cc8b","collapsed":true},"outputs":[],"source":"y.head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"c21cb7353762433619da371510ba922e50cd7c41","_cell_guid":"06d05ecd-cefc-42e7-aaae-ec1a0705a319","collapsed":true},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nXtrain,Xtest,ytrain,ytest=train_test_split(X,y, test_size=0.33, random_state=42)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"793c103794c1c219d860aad674cf1b51fc748294","_cell_guid":"c86ff709-f48e-4eca-a662-6900eb53d6ec","collapsed":true},"outputs":[],"source":"#converting to matrix\nXtrain=Xtrain.values\nytrain=ytrain.values\nXtest=Xtest.values\nytest=ytest.values"},{"cell_type":"markdown","metadata":{"_uuid":"f4674be9290bd0c9a73b7d778e2579b52f48e103","_cell_guid":"5a300c78-49ee-46bd-b09a-502c8a39cd08"},"source":"Builing a keras architecture. "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6299c7b86974ce30a4060d53067ef1267de2d30c","_cell_guid":"5b117c09-70ee-41a6-b8d8-6b89bdc253e0","collapsed":true},"outputs":[],"source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"9fd34473e50f37db9856caa6094b84328e39e07a","_cell_guid":"09b467a7-50dd-4a9a-bb5d-812c9ca4f056","collapsed":true},"outputs":[],"source":"classifier=Sequential() \ntraining_df.shape"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"858c2d5e050d6deb263b9770c74023ea1bf450d7","_cell_guid":"79e2a211-c442-4ca3-ba9a-7cf3e73da60e","collapsed":true},"outputs":[],"source":"classifier.add(Dense(units=10, kernel_initializer=\"uniform\",activation='relu',input_dim=11))\nclassifier.add(Dense(units=8, kernel_initializer=\"uniform\", activation='softmax'))\nclassifier.add(Dense(units=6, kernel_initializer=\"uniform\", activation='relu'))\nclassifier.add(Dense(units=3, activation='softmax'))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"8ace14a00f639fcdd218dd8e7f03d28d66c04cab","_cell_guid":"c512c491-8a5b-4fb6-8d07-963f345f1d68","collapsed":true},"outputs":[],"source":"classifier.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nclassifier.fit(Xtrain,ytrain,batch_size=5, epochs=10)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"8c4443e48c3e605da2e10459052a2be716388a5d","_cell_guid":"3735daef-990d-4ecc-8090-c85ba8c59da0","collapsed":true},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\nry=training_df['author']\nrX=training_df.drop(['author'],1)\nrXtrain,rXtest,rytrain,rytest=train_test_split(rX,ry, test_size=0.33, random_state=42)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"dd9d33eb2c87cb7e225be73e1df6ab46a520d675","_cell_guid":"61c05223-f9d7-45e0-99ed-a63b182b3c16","collapsed":true},"outputs":[],"source":"clf=RandomForestClassifier()\nclf.fit(rXtrain,rytrain)\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"7f3fe01bc1507e9d84e29781dd7600513f40a2fa","_cell_guid":"132b5a7c-da2b-4d67-a5d4-962a5db50196","collapsed":true},"outputs":[],"source":"from sklearn.model_selection import cross_val_score\nprint(cross_val_score(clf, rXtrain, rytrain))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e7daeb150b4eb96cdab3b733820e4b1c9837922e","_cell_guid":"ecd140cd-cdf9-48ab-8325-f448c033037e","collapsed":true},"outputs":[],"source":""}],"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.3","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":1}