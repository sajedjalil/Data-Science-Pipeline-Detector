{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%ls ../input","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageFont\nfrom pathlib import Path\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\ninput_path = Path(\"../input\")\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference\n# https://www.kaggle.com/anokas/kuzushiji-visualisation\ndf_train = pd.read_csv( input_path / 'train.csv')\nunicode_trans = pd.read_csv( input_path / 'unicode_translation.csv')\ntrain_image_path = input_path / \"train_images\"\ntest_image_path = input_path / \"test_images\"\nunicode_map = {codepoint: char for codepoint, char in unicode_trans.values}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The string should be read as space separated series of values where **Unicode character, X, Y, Width, and Height are repeated** as many times as necessary."},{"metadata":{"trusted":true},"cell_type":"code","source":"length = 5\nsplit_labels = df_train[\"labels\"][0].split()\nfor idx in range(len(split_labels) // length):\n    start_idx = idx * length\n    print(split_labels[start_idx : start_idx + length])\n    if idx == 4:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class KuzushijiDataset(Dataset):\n    def __init__(self, img_path, mode=\"train\"):\n        self.img_path = img_path\n        self.img_paths = list(self.img_path.glob(\"*jpg\"))\n        self.unicode_trans = pd.read_csv( input_path / 'unicode_translation.csv')\n        self.unicode_map = {codepoint: char for codepoint, char in unicode_trans.values}\n        self.unicode2labels = dict(zip(self.unicode_map.keys(),\n                                      range(len(self.unicode_map.keys()))))\n        self.label_length = 5\n        self.transform = transforms.ToTensor()\n        if mode == \"train\":\n            self.mode = \"train\"\n            self.mask = pd.read_csv( input_path / 'train.csv')\n        else:\n            self.mode = \"test\"\n    \n    def get_label_and_mask(self, image_id):\n#         assert type(image_id) == str\n        split_labels = self.mask[self.mask[\"image_id\"] == image_id][\"labels\"].str.split(\" \").values[0]\n        ll = len(split_labels) // length\n        masks = np.zeros((ll, 4))\n        labels = np.zeros((ll))\n        for idx in range(ll):\n            start_idx = idx * self.label_length\n            labels[idx] = self.unicode2labels[split_labels[start_idx]]\n            masks[idx] = split_labels[start_idx+1:start_idx+self.label_length]\n        return labels, masks\n    \n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        img_path = self.img_paths[index]\n        image = Image.open(img_path)\n        if self.mode == \"train\":\n            labels, masks = self.get_label_and_mask(img_path.stem)\n#             data = {\"image\": np.array(image), \"mask\": masks}\n#         else:\n#             data = {\"image\": np.array(image)}\n#         transformed = self.transform(**data)\n#         image = transformed['image'] / 255\n#         image = np.transpose(image, (2, 0, 1))\n        if self.mode == 'train':\n            return self.transform(image), labels, masks\n        else:\n            return image\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return len(self.img_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_train = KuzushijiDataset(img_path=train_image_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference\n# https://www.kaggle.com/anokas/kuzushiji-visualisation\n# This function takes in a filename of an image, and the labels in the string format given in train.csv, and returns an image containing the bounding boxes and characters annotated\ndef visualize_training_data(image_fn, masks):\n    imsource = Image.fromarray(np.uint8(image_fn * 255)).convert('RGBA')\n    bbox_canvas = Image.new('RGBA', imsource.size)\n    bbox_draw = ImageDraw.Draw(bbox_canvas) # Separate canvases for boxes and chars so a box doesn't cut off a character\n\n    for idx in range(masks.shape[1]):\n        x, y, w, h = masks[0][idx]\n        x, y, w, h = int(x), int(y), int(w), int(h)\n\n        # Draw bounding box around character, and unicode character next to it\n        bbox_draw.rectangle((x, y, x+w, y+h),\n                            fill=(255, 255, 255, 0),\n                            outline=(255, 0, 0, 255))\n    imsource = Image.alpha_composite(imsource, bbox_canvas)\n    imsource = imsource.convert(\"RGB\") # Remove alpha for saving in jpg format.\n    return np.asarray(imsource)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 1\n\n# Use the torch dataloader to iterate through the dataset\nloader = DataLoader(k_train, batch_size=batch_size, shuffle=False, num_workers=0)\n\n# functions to show an image\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# get some images\ndataiter = iter(loader)\nimages, label, masks  = dataiter.next()\nprint(\"image.shape: {}\".format(images.shape))\nprint(\"mask.shape: {}\".format(masks.shape))\n\n# show images\nplt.figure(figsize=(12,12))\nnp_img = images.numpy()[0].transpose((1, 2, 0))\nnew_img = visualize_training_data(np_img, masks)\nplt.imshow(new_img, interpolation='lanczos')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, label, masks  = dataiter.next()\nprint(\"image.shape: {}\".format(images.shape))\nprint(\"mask.shape: {}\".format(masks.shape))\n\n# show images\nplt.figure(figsize=(12,12))\nnp_img = images.numpy()[0].transpose((1, 2, 0))\nnew_img = visualize_training_data(np_img, masks)\nplt.imshow(new_img, interpolation='lanczos')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, label, masks  = dataiter.next()\nprint(\"image.shape: {}\".format(images.shape))\nprint(\"mask.shape: {}\".format(masks.shape))\n\n# show images\nplt.figure(figsize=(12,12))\nnp_img = images.numpy()[0].transpose((1, 2, 0))\nnew_img = visualize_training_data(np_img, masks)\nplt.imshow(new_img, interpolation='lanczos')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}