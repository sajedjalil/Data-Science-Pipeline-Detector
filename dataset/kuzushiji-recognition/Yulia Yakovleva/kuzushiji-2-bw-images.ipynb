{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Converting scanned kuzushiji sheets to bw images with a single character   "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport re\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualisiung the training data\nDon't forget to add dataset!\nhttps://www.kaggle.com/c/kuzushiji-recognition"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/kuzushiji-recognition/train.csv')\nunicode_map = {codepoint: char for codepoint, char in \n               pd.read_csv('../input/kuzushiji-recognition/unicode_translation.csv').values}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_labels_set(labels_str):\n    labels = []\n    for one_label_str in re.findall(r'U\\+\\S+\\s\\S+\\s\\S+\\s\\S+\\s\\S+', labels_str):\n        charcode, x, y, w, h = one_label_str.split(' ')\n        labels.append([charcode, int(x), int(y), int(w), int(h)])\n    return labels\n\ndef visualize_training_data(image_path, labels):\n    fs = 8\n    # Read image\n    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    for label in convert_labels_set(labels):\n        _, x, y, w, h = label\n        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 3)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_sheets = 2\n\nfor _ in range(n_sheets):\n    img_filename, labels = df_train.values[np.random.randint(len(df_train))]\n    viz_img = visualize_training_data('../input/kuzushiji-recognition/train_images/{}.jpg'.format(img_filename), labels)\n    \n    plt.figure(figsize=(15, 15))\n    plt.title(img_filename)\n    plt.imshow(viz_img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_labels = 0\nchars_counts = {}\n\nfor labels_set in df_train.values[:, 1]:\n    if type(labels_set) is not str:\n        continue\n\n    labels = convert_labels_set(labels_set)\n    n_labels += len(labels)\n    for label in labels:\n        try:\n            chars_counts[label[0]] += 1\n        except KeyError:\n            chars_counts.update({label[0]: 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chars_counts_list = [chars_counts[k] for k in chars_counts]\nn_classes = len([k for k in chars_counts])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of labels:                  {}'.format(n_labels))\nprint('Number of classes:                 {}'.format(n_classes))\nprint('Min max number of items per class: {} {}'.format(np.min(chars_counts_list), np.max(chars_counts_list)))\nprint('Median number of items per class:  {}'.format(np.median(chars_counts_list)))\nprint('Mean number of items per class:    {}'.format(np.mean(chars_counts_list)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kuzushiji images mining"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_char_images_from_sheet(src_image_path, labels_str, blur_kernel_size=3, img_size=64):\n    src_img = cv2.imread(src_image_path, cv2.IMREAD_COLOR)\n\n    char_imgs = []\n    for label in convert_labels_set(labels_str):\n        char_img = np.zeros((img_size, img_size), dtype=np.uint8)\n        _, x, y, w, h = label\n\n        label_img = src_img[y:y + h, x:x + w, :]\n        label_img = cv2.GaussianBlur(label_img, \n                                     (blur_kernel_size, blur_kernel_size), \n                                     cv2.BORDER_DEFAULT)\n        label_img = cv2.cvtColor(label_img, cv2.COLOR_RGB2GRAY)\n        _, label_img = cv2.threshold(label_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n        label_img = 255 - label_img\n        \n        if w > h:\n            label_img = cv2.resize(label_img, (img_size, int(img_size * h / w)))\n            dy = int((img_size - int(img_size * h / w)) / 2)\n            char_img[dy:dy + int(img_size * h / w), :] += label_img\n        \n        else:\n            label_img = cv2.resize(label_img, (int(img_size * w / h), img_size))            \n            dx = int((img_size - int(img_size * w / h)) / 2)\n            char_img[:, dx:dx + int(img_size * w / h)] += label_img\n        \n        char_imgs.append(char_img)\n    return char_imgs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_filename, labels = df_train.values[np.random.randint(len(df_train))]\n\nchar_imgs = get_char_images_from_sheet('../input/kuzushiji-recognition/train_images/{}.jpg'.format(img_filename), labels)\n\nfor i in np.random.choice(len(char_imgs), 10):\n    plt.figure(figsize=(2, 2))\n    plt.imshow(char_imgs[i], cmap='Greys')\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}