{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I've modified [this notebook](https://www.kaggle.com/stanleyjzheng/deepinsight-b3-training-gpu) to test a simple baseline: using a random mapping (from features to pixels) for DeepInsight.\nThe original 5-fold CV score was 0.0178, and using random mappings it fell to  0.0191.\n","metadata":{}},{"cell_type":"code","source":"kernel_mode = True\n\n#!cp ../input/lish-moa-utils/utils.py .\nimport sys\n!pip install geffnet\n!pip install iterative-stratification\nif kernel_mode:\n    sys.path.insert(0, \"../input/iterative-stratification\")\n    #sys.path.insert(0, './')\n    sys.path.insert(0, \"../input/gen-efficientnet-pytorch\")\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport time\nimport random\nimport torch\nimport math\nimport pytorch_lightning as pl\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom sklearn.metrics import log_loss\npd.options.display.max_columns = None\nimport geffnet\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.manifold import TSNE\nimport pickle\nimport seaborn as sns\nimport cv2\nsns.set(style=\"darkgrid\")\nimport gc\ngc.enable()\nexperiment_name='pleasework'\n\nmodel_info = {\n    \"model_path\": f\"../input/deepinsight-transformers-perplexity-5\"\n    #f\"../input/deepinsight-efficientnet-v4-b3/{experiment_name}\"\n    #if kernel_mode else\n    #f\"/workspace/Kaggle/MoA/completed/deepinsight_efficientnet_v4_b3/{experiment_name}\"\n}\n\nmodel_type='b3'\n\npretrained_model = f\"tf_efficientnet_{model_type}_ns\"\n\nmodel_output_folder = '.'\nrand_seed = 42\nperplexity = 24\npatience=3\nepochs=12\nweight_decay=0.05 #0.1 at first (too much)\n\ndrop_connect_rate = 0.3 #0.2 at first\nfc_size = 512\n\n# Swap Noise\nswap_prob = 0.15\nswap_portion = 0.1\n\n\nnum_workers = 4\ngpus = [0]\n\nif model_type == \"b0\":\n    batch_size = 48 # default 128\n    infer_batch_size = 256\n    image_size = 224  # B0\n    drop_rate = 0.4  # B0\n    resolution = 224\nelif model_type == \"b3\":\n    batch_size = 48 \n    infer_batch_size = 128 # 256 results in OOM\n    image_size = 300  # B3\n    drop_rate = 0.4  # B3\n    resolution = 300\nelif model_type == \"b5\":\n    batch_size = 8\n    infer_batch_size = 16\n    image_size = 456  # B5\n    drop_rate = 0.75  # B5\n    resolution = 456\nelif model_type == \"b7\":\n    batch_size = 2\n    infer_batch_size = 4\n    image_size = 800  # B7\n    image_size = 772  # B7\n    drop_rate = 0.5  # B7\n    resolution = 772","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modified from DeepInsight Transform\n# https://github.com/alok-ai-lab/DeepInsight/blob/master/pyDeepInsight/image_transformer.py\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.manifold import TSNE\nfrom scipy.spatial import ConvexHull\nfrom matplotlib import pyplot as plt\nimport inspect\n\nclass random_mapper():\n    def fit_transform(self,X):\n        return np.random.random_sample((X.shape[0], 2))\n\n\nclass DeepInsightTransformer:\n    \"\"\"Transform features to an image matrix using dimensionality reduction\n\n    This class takes in data normalized between 0 and 1 and converts it to a\n    CNN compatible 'image' matrix\n\n    \"\"\"\n    def __init__(self,\n                 feature_extractor='random',\n                 perplexity=30,\n                 pixels=100,\n                 random_state=None,\n                 n_jobs=None):\n        \"\"\"Generate an ImageTransformer instance\n\n        Args:\n            feature_extractor: string of value ('tsne', 'pca', 'kpca') or a\n                class instance with method `fit_transform` that returns a\n                2-dimensional array of extracted features.\n            pixels: int (square matrix) or tuple of ints (height, width) that\n                defines the size of the image matrix.\n            random_state: int or RandomState. Determines the random number\n                generator, if present, of a string defined feature_extractor.\n            n_jobs: The number of parallel jobs to run for a string defined\n                feature_extractor.\n        \"\"\"\n        self.random_state = random_state\n        self.n_jobs = n_jobs\n\n        if isinstance(feature_extractor, str):\n            fe = feature_extractor.casefold()\n            if fe == 'tsne_exact'.casefold():\n                fe = TSNE(n_components=2,\n                          metric='cosine',\n                          perplexity=perplexity,\n                          n_iter=1000,\n                          method='exact',\n                          random_state=self.random_state,\n                          n_jobs=self.n_jobs)\n            elif fe == 'tsne'.casefold():\n                fe = TSNE(n_components=2,\n                          metric='cosine',\n                          perplexity=perplexity,\n                          n_iter=1000,\n                          method='barnes_hut',\n                          random_state=self.random_state,\n                          n_jobs=self.n_jobs)\n            elif fe == 'pca'.casefold():\n                fe = PCA(n_components=2, random_state=self.random_state)\n            elif fe == 'kpca'.casefold():\n                fe = KernelPCA(n_components=2,\n                               kernel='rbf',\n                               random_state=self.random_state,\n                               n_jobs=self.n_jobs)\n            elif fe == 'random'.casefold():\n                fe = random_mapper()\n            else:\n                raise ValueError((\"Feature extraction method '{}' not accepted\"\n                                  ).format(feature_extractor))\n            self._fe = fe\n        elif hasattr(feature_extractor, 'fit_transform') and \\\n                inspect.ismethod(feature_extractor.fit_transform):\n            self._fe = feature_extractor\n        else:\n            raise TypeError('Parameter feature_extractor is not a '\n                            'string nor has method \"fit_transform\"')\n\n        if isinstance(pixels, int):\n            pixels = (pixels, pixels)\n\n        # The resolution of transformed image\n        self._pixels = pixels\n        self._xrot = None\n\n    def fit(self, X, y=None, plot=False):\n        \"\"\"Train the image transformer from the training set (X)\n\n        Args:\n            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n            y: Ignored. Present for continuity with scikit-learn\n            plot: boolean of whether to produce a scatter plot showing the\n                feature reduction, hull points, and minimum bounding rectangle\n\n        Returns:\n            self: object\n        \"\"\"\n        # Transpose to get (n_features, n_samples)\n        X = X.T\n\n        # Perform dimensionality reduction\n        x_new = self._fe.fit_transform(X)\n\n        # Get the convex hull for the points\n        chvertices = ConvexHull(x_new).vertices\n        hull_points = x_new[chvertices]\n\n        # Determine the minimum bounding rectangle\n        mbr, mbr_rot = self._minimum_bounding_rectangle(hull_points)\n\n        # Rotate the matrix\n        # Save the rotated matrix in case user wants to change the pixel size\n        self._xrot = np.dot(mbr_rot, x_new.T).T\n\n        # Determine feature coordinates based on pixel dimension\n        self._calculate_coords()\n\n        # plot rotation diagram if requested\n        if plot is True:\n            # Create subplots\n            fig, ax = plt.subplots(1, 1, figsize=(10, 7), squeeze=False)\n            ax[0, 0].scatter(x_new[:, 0],\n                             x_new[:, 1],\n                             cmap=plt.cm.get_cmap(\"jet\", 10),\n                             marker=\"x\",\n                             alpha=1.0)\n            ax[0, 0].fill(x_new[chvertices, 0],\n                          x_new[chvertices, 1],\n                          edgecolor='r',\n                          fill=False)\n            ax[0, 0].fill(mbr[:, 0], mbr[:, 1], edgecolor='g', fill=False)\n            plt.gca().set_aspect('equal', adjustable='box')\n            plt.show()\n        return self\n\n    @property\n    def pixels(self):\n        \"\"\"The image matrix dimensions\n\n        Returns:\n            tuple: the image matrix dimensions (height, width)\n\n        \"\"\"\n        return self._pixels\n\n    @pixels.setter\n    def pixels(self, pixels):\n        \"\"\"Set the image matrix dimension\n\n        Args:\n            pixels: int or tuple with the dimensions (height, width)\n            of the image matrix\n\n        \"\"\"\n        if isinstance(pixels, int):\n            pixels = (pixels, pixels)\n        self._pixels = pixels\n        # recalculate coordinates if already fit\n        if hasattr(self, '_coords'):\n            self._calculate_coords()\n\n    def _calculate_coords(self):\n        \"\"\"Calculate the matrix coordinates of each feature based on the\n        pixel dimensions.\n        \"\"\"\n        ax0_coord = np.digitize(self._xrot[:, 0],\n                                bins=np.linspace(min(self._xrot[:, 0]),\n                                                 max(self._xrot[:, 0]),\n                                                 self._pixels[0])) - 1\n        ax1_coord = np.digitize(self._xrot[:, 1],\n                                bins=np.linspace(min(self._xrot[:, 1]),\n                                                 max(self._xrot[:, 1]),\n                                                 self._pixels[1])) - 1\n        self._coords = np.stack((ax0_coord, ax1_coord))\n\n    def transform(self, X, empty_value=0):\n        \"\"\"Transform the input matrix into image matrices\n\n        Args:\n            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n                where n_features matches the training set.\n            empty_value: numeric value to fill elements where no features are\n                mapped. Default = 0 (although it was 1 in the paper).\n\n        Returns:\n            A list of n_samples numpy matrices of dimensions set by\n            the pixel parameter\n        \"\"\"\n\n        # Group by location (x1, y1) of each feature\n        # Tranpose to get (n_features, n_samples)\n        img_coords = pd.DataFrame(np.vstack(\n            (self._coords, X.clip(0, 1))).T).groupby(\n                [0, 1],  # (x1, y1)\n                as_index=False).mean()\n\n        img_matrices = []\n        blank_mat = np.zeros(self._pixels)\n        if empty_value != 0:\n            blank_mat[:] = empty_value\n        for z in range(2, img_coords.shape[1]):\n            img_matrix = blank_mat.copy()\n            img_matrix[img_coords[0].astype(int),\n                       img_coords[1].astype(int)] = img_coords[z]\n            img_matrices.append(img_matrix)\n\n        return img_matrices\n\n    def fit_transform(self, X, empty_value=0):\n        \"\"\"Train the image transformer from the training set (X) and return\n        the transformed data.\n\n        Args:\n            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n            empty_value: numeric value to fill elements where no features are\n                mapped. Default = 0 (although it was 1 in the paper).\n\n        Returns:\n            A list of n_samples numpy matrices of dimensions set by\n            the pixel parameter\n        \"\"\"\n        self.fit(X)\n        return self.transform(X, empty_value=empty_value)\n\n    def feature_density_matrix(self):\n        \"\"\"Generate image matrix with feature counts per pixel\n\n        Returns:\n            img_matrix (ndarray): matrix with feature counts per pixel\n        \"\"\"\n        fdmat = np.zeros(self._pixels)\n        # Group by location (x1, y1) of each feature\n        # Tranpose to get (n_features, n_samples)\n        coord_cnt = (\n            pd.DataFrame(self._coords.T).assign(count=1).groupby(\n                [0, 1],  # (x1, y1)\n                as_index=False).count())\n        fdmat[coord_cnt[0].astype(int),\n              coord_cnt[1].astype(int)] = coord_cnt['count']\n        return fdmat\n\n    @staticmethod\n    def _minimum_bounding_rectangle(hull_points):\n        \"\"\"Find the smallest bounding rectangle for a set of points.\n\n        Modified from JesseBuesking at https://stackoverflow.com/a/33619018\n        Returns a set of points representing the corners of the bounding box.\n\n        Args:\n            hull_points : an nx2 matrix of hull coordinates\n\n        Returns:\n            (tuple): tuple containing\n                coords (ndarray): coordinates of the corners of the rectangle\n                rotmat (ndarray): rotation matrix to align edges of rectangle\n                    to x and y\n        \"\"\"\n\n        pi2 = np.pi / 2.\n\n        # Calculate edge angles\n        edges = hull_points[1:] - hull_points[:-1]\n        angles = np.arctan2(edges[:, 1], edges[:, 0])\n        angles = np.abs(np.mod(angles, pi2))\n        angles = np.unique(angles)\n\n        # Find rotation matrices\n        rotations = np.vstack([\n            np.cos(angles),\n            np.cos(angles - pi2),\n            np.cos(angles + pi2),\n            np.cos(angles)\n        ]).T\n        rotations = rotations.reshape((-1, 2, 2))\n\n        # Apply rotations to the hull\n        rot_points = np.dot(rotations, hull_points.T)\n\n        # Find the bounding points\n        min_x = np.nanmin(rot_points[:, 0], axis=1)\n        max_x = np.nanmax(rot_points[:, 0], axis=1)\n        min_y = np.nanmin(rot_points[:, 1], axis=1)\n        max_y = np.nanmax(rot_points[:, 1], axis=1)\n\n        # Find the box with the best area\n        areas = (max_x - min_x) * (max_y - min_y)\n        best_idx = np.argmin(areas)\n\n        # Return the best box\n        x1 = max_x[best_idx]\n        x2 = min_x[best_idx]\n        y1 = max_y[best_idx]\n        y2 = min_y[best_idx]\n        rotmat = rotations[best_idx]\n\n        # Generate coordinates\n        coords = np.zeros((4, 2))\n        coords[0] = np.dot([x1, y2], rotmat)\n        coords[1] = np.dot([x2, y2], rotmat)\n        coords[2] = np.dot([x2, y1], rotmat)\n        coords[3] = np.dot([x1, y1], rotmat)\n\n        return coords, rotmat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LogScaler:\n    \"\"\"Log normalize and scale data\n\n    Log normalization and scaling procedure as described as norm-2 in the\n    DeepInsight paper supplementary information.\n    \n    Note: The dimensions of input matrix is (N samples, d features)\n    \"\"\"\n    def __init__(self):\n        self._min0 = None\n        self._max = None\n\n    \"\"\"\n    Use this as a preprocessing step in inference mode.\n    \"\"\"\n    def fit(self, X, y=None):\n        # Min. of training set per feature\n        self._min0 = X.min(axis=0)\n\n        # Log normalized X by log(X + _min0 + 1)\n        X_norm = np.log(\n            X +\n            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n            1).clip(min=0, max=None)\n\n        # Global max. of training set from X_norm\n        self._max = X_norm.max()\n\n    \"\"\"\n    For training set only.\n    \"\"\"\n    def fit_transform(self, X, y=None):\n        # Min. of training set per feature\n        self._min0 = X.min(axis=0)\n\n        # Log normalized X by log(X + _min0 + 1)\n        X_norm = np.log(\n            X +\n            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n            1).clip(min=0, max=None)\n\n        # Global max. of training set from X_norm\n        self._max = X_norm.max()\n\n        # Normalized again by global max. of training set\n        return (X_norm / self._max).clip(0, 1)\n\n    \"\"\"\n    For validation and test set only.\n    \"\"\"\n    def transform(self, X, y=None):\n        # Adjust min. of each feature of X by _min0\n        for i in range(X.shape[1]):\n            X[:, i] = X[:, i].clip(min=self._min0[i], max=None)\n\n        # Log normalized X by log(X + _min0 + 1)\n        X_norm = np.log(\n            X +\n            np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n            1).clip(min=0, max=None)\n\n        # Normalized again by global max. of training set\n        return (X_norm / self._max).clip(0, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = pd.read_csv(\"../input/lish-moa/train_features.csv\")\ntrain_labels = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\ntrain_extra_labels = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\ntest_features = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n\ndel train_labels['sig_id']\n\ncategory_features = [\"cp_type\", \"cp_dose\"]\nnumeric_features = [c for c in train_features.columns if c != \"sig_id\" and c not in category_features]\nall_features = category_features + numeric_features\ngene_experssion_features = [c for c in numeric_features if c.startswith(\"g-\")]\ncell_viability_features = [c for c in numeric_features if c.startswith(\"c-\")]\nlen(numeric_features), len(gene_experssion_features), len(cell_viability_features)\n\ntrain_classes = [c for c in train_labels.columns if c != \"sig_id\"]\ntrain_extra_classes = [c for c in train_extra_labels.columns if c != \"sig_id\"]\nlen(train_classes), len(train_extra_classes)\n\nfor df in [train_features, test_features]:\n    df['cp_type'] = df['cp_type'].map({'ctl_vehicle': 0, 'trt_cp': 1})\n    df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n    df['cp_time'] = df['cp_time'].map({24: 0, 48: 0.5, 72: 1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(num_starts, num_splits, control=True):\n    folds = []\n\n    # LOAD FILES\n    train_feats = pd.read_csv('../input/lish-moa/train_features.csv')\n    scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n    drug = pd.read_csv('../input/lish-moa/train_drug.csv')\n    if not control:\n        scored = scored.loc[train_feats['cp_type'] == 'trt_cp', :]\n        drug = drug.loc[train_feats['cp_type'] == 'trt_cp', :]\n    targets = scored.columns[1:]\n    scored = scored.merge(drug, on='sig_id', how='left') \n\n    # LOCATE DRUGS\n    vc = scored.drug_id.value_counts()\n    vc1 = vc.loc[vc <= 18].index\n    vc2 = vc.loc[vc > 18].index\n\n    for seed in range(num_starts):\n\n        # STRATIFY DRUGS 18X OR LESS\n        dct1 = {}; dct2 = {}\n        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state = seed)\n        tmp = scored.groupby('drug_id')[targets].mean().loc[vc1]\n        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[targets])):\n            dd = {k:fold for k in tmp.index[idxV].values}\n            dct1.update(dd)\n\n        # STRATIFY DRUGS MORE THAN 18X\n        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state = seed)\n        tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop = True)\n        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[targets])):\n            dd = {k:fold for k in tmp.sig_id[idxV].values}\n            dct2.update(dd)\n\n        # ASSIGN FOLDS\n        scored['fold'] = scored.drug_id.map(dct1)\n        scored.loc[scored.fold.isna(),'fold'] =\\\n            scored.loc[scored.fold.isna(),'sig_id'].map(dct2)\n        scored.fold = scored.fold.astype('int8')\n        folds.append(scored.fold.values)\n\n        del scored['fold']\n\n    return np.stack(folds) \n\ndef plot_embed_2D(X, title=None):\n    sns.set(style=\"darkgrid\")\n\n    # Create subplots\n    fig, ax = plt.subplots(1, 1, figsize=(10, 7), squeeze=False)\n    ax[0, 0].scatter(X[:, 0],\n                     X[:, 1],\n                     cmap=plt.cm.get_cmap(\"jet\", 10),\n                     marker=\"x\",\n                     alpha=1.0)\n    plt.gca().set_aspect('equal', adjustable='box')\n\n    if title is not None:\n        ax[0, 0].set_title(title, fontsize=20)\n\n    plt.rcParams.update({'font.size': 14})\n    plt.show()\n\ndef tsne_transform(data, perplexity=30, plot=True):\n    # Transpose to get (n_features, n_samples)\n    data = data.T\n\n    tsne = TSNE(n_components=2,\n                metric='cosine',\n                perplexity=perplexity,\n                n_iter=1000,\n                method='exact',\n                random_state=rand_seed,\n                n_jobs=-1)\n    # Transpose to get (n_features, n_samples)\n    transformed = tsne.fit_transform(data)\n\n    if plot:\n        plot_embed_2D(\n            transformed,\n            f\"All Feature Location Matrix of Training Set (Perplexity: {perplexity})\"\n        )\n    return transformed\n\ndef save_pickle(obj, model_output_folder, fold_i, name):\n    pickle.dump(obj, open(f\"{model_output_folder}/fold{fold_i}_{name}.pkl\", 'wb'),\n         pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_weight_goog(m, n='', fix_group_fanout=True):\n    # weight init as per Tensorflow Official impl\n    # https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_model.py\n    if isinstance(m, torch.nn.Conv2d):\n        fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        if fix_group_fanout:\n            fan_out //= m.groups\n        m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif isinstance(m, torch.nn.BatchNorm2d):\n        m.weight.data.fill_(1.0)\n        m.bias.data.zero_()\n    elif isinstance(m, torch.nn.Linear):\n        fan_out = m.weight.size(0)  # fan-out\n        fan_in = 0\n        if 'routing_fn' in n:\n            fan_in = m.weight.size(1)\n        init_range = 1.0 / math.sqrt(fan_in + fan_out)\n        m.weight.data.uniform_(-init_range, init_range)\n        m.bias.data.zero_()\n\ndef initialize_weight_default(m, n=''):\n    if isinstance(m, torch.nn.Conv2d):\n        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n    elif isinstance(m, torch.nn.BatchNorm2d):\n        m.weight.data.fill_(1.0)\n        m.bias.data.zero_()\n    elif isinstance(m, torch.nn.Linear):\n        torch.nn.init.kaiming_uniform_(m.weight,\n                                 mode='fan_in',\n                                 nonlinearity='linear')\n\nclass MoAEfficientNet(pl.LightningModule):\n    def __init__(\n            self,\n            pretrained_model_name,\n            training_set=(None, None),  # tuple\n            valid_set=(None, None),  # tuple\n            test_set=None,\n            transformer=None,\n            num_classes=206,\n            in_chans=3,\n            drop_rate=0.,\n            drop_connect_rate=0.,\n            fc_size=512,\n            learning_rate=1e-3,\n            weight_init='goog'):\n        super(MoAEfficientNet, self).__init__()\n\n        self.train_data, self.train_labels = training_set\n        self.valid_data, self.valid_labels = valid_set\n        self.test_data = test_set\n        self.transformer = transformer\n\n        self.backbone = getattr(geffnet, pretrained_model)(\n            pretrained=True,\n            in_chans=in_chans,\n            drop_rate=drop_rate,\n            drop_connect_rate=drop_connect_rate,\n            weight_init=weight_init)\n\n        self.backbone.classifier = torch.nn.Sequential(\n            torch.nn.Linear(self.backbone.classifier.in_features, fc_size,\n                      bias=True), torch.nn.ELU(),\n            torch.nn.Linear(fc_size, num_classes, bias=True))\n\n        if self.training:\n            for m in self.backbone.classifier.modules():\n                initialize_weight_goog(m)\n\n        # Save passed hyperparameters\n        self.save_hyperparameters(\"pretrained_model_name\", \"num_classes\",\n                                  \"in_chans\", \"drop_rate\", \"drop_connect_rate\",\n                                  \"weight_init\", \"fc_size\", \"learning_rate\")\n\n    def forward(self, x):\n        return self.backbone(x)\n\n    def training_step(self, batch, batch_idx):\n        x = batch[\"x\"]\n        y = batch[\"y\"]\n        x = x.float()\n        y = y.type_as(x)\n        logits = self(x)\n\n        loss = F.binary_cross_entropy_with_logits(logits, y, reduction=\"mean\")\n\n        self.log('train_loss',\n                 loss,\n                 on_step=True,\n                 on_epoch=True,\n                 prog_bar=True,\n                 logger=True)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x = batch[\"x\"]\n        y = batch[\"y\"]\n        x = x.float()\n        y = y.type_as(x)\n        logits = self(x)\n\n        val_loss = F.binary_cross_entropy_with_logits(logits,\n                                                      y,\n                                                      reduction=\"mean\")\n\n        self.log('val_loss',\n                 val_loss,\n                 on_step=True,\n                 on_epoch=True,\n                 prog_bar=True,\n                 logger=True)\n\n        return val_loss\n\n    def test_step(self, batch, batch_idx):\n        x = batch[\"x\"]\n        y = batch[\"y\"]\n        x = x.float()\n        y = y.type_as(x)\n        logits = self(x)\n        return {\"pred_logits\": logits}\n\n    def test_epoch_end(self, output_results):\n        all_outputs = torch.cat([out[\"pred_logits\"] for out in output_results],\n                                dim=0)\n        print(\"Logits:\", all_outputs)\n        pred_probs = F.sigmoid(all_outputs).detach().cpu().numpy()\n        print(\"Predictions: \", pred_probs)\n        return {\"pred_probs\": pred_probs}\n\n    def setup(self, stage=None):\n        #         self.train_dataset = MoAImageDataset(self.train_data,\n        #                                              self.train_labels,\n        #                                              self.transformer)\n        self.train_dataset = MoAImageSwapDataset(self.train_data,\n                                                 self.train_labels,\n                                                 self.transformer,\n                                                 swap_prob=swap_prob,\n                                                 swap_portion=swap_portion)\n\n        self.val_dataset = MoAImageDataset(self.valid_data, self.valid_labels,\n                                           self.transformer)\n\n        self.test_dataset = TestDataset(self.test_data, None, self.transformer)\n\n    def train_dataloader(self):\n        train_dataloader = torch.utils.data.DataLoader(self.train_dataset,\n                                      batch_size=batch_size,\n                                      shuffle=True,\n                                      num_workers=num_workers,\n                                      pin_memory=False,\n                                      drop_last=False)\n        print(f\"Train iterations: {len(train_dataloader)}\")\n        return train_dataloader\n\n    def val_dataloader(self):\n        val_dataloader = torch.utils.data.DataLoader(self.val_dataset,\n                                    batch_size=infer_batch_size,\n                                    shuffle=False,\n                                    num_workers=num_workers,\n                                    pin_memory=False,\n                                    drop_last=False)\n        print(f\"Validate iterations: {len(val_dataloader)}\")\n        return val_dataloader\n\n    def test_dataloader(self):\n        test_dataloader = torch.utils.data.DataLoader(self.test_dataset,\n                                     batch_size=infer_batch_size,\n                                     shuffle=False,\n                                     num_workers=num_workers,\n                                     pin_memory=False,\n                                     drop_last=False)\n        print(f\"Test iterations: {len(test_dataloader)}\")\n        return test_dataloader\n\n    def configure_optimizers(self):\n        print(f\"Initial Learning Rate: {self.hparams.learning_rate:.6f}\")\n        optimizer = torch.optim.Adam(self.parameters(),\n                               lr=self.hparams.learning_rate,\n                               weight_decay=weight_decay)\n\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n                                                         T_max=T_max,\n                                                         eta_min=0,\n                                                         last_epoch=-1)\n\n        return [optimizer], [scheduler]\n\nclass MoAImageSwapDataset(torch.utils.data.Dataset):\n    def __init__(self,\n                 features,\n                 labels,\n                 transformer,\n                 swap_prob=0.15,\n                 swap_portion=0.1):\n        self.features = features\n        self.labels = labels\n        self.transformer = transformer\n        self.swap_prob = swap_prob\n        self.swap_portion = swap_portion\n\n    def __getitem__(self, index):\n        normalized = self.features[index, :]\n\n        # Swap row featurs randomly\n        normalized = self.add_swap_noise(index, normalized)\n\n        normalized = np.expand_dims(normalized, axis=0)\n\n        # Note: we are setting empty_value=1 to follow the setup in the paper\n        image = self.transformer.transform(normalized, empty_value=1)[0]\n\n        # Resize to target size\n        gene_cht = cv2.resize(image, (image_size, image_size),\n                              interpolation=cv2.INTER_CUBIC)\n\n        # Convert to 3 channels\n        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n\n        return {\"x\": image.astype(float), \"y\": self.labels[index, :].astype(float)}\n\n    def add_swap_noise(self, index, X):\n        if np.random.rand() < self.swap_prob:\n            swap_index = np.random.randint(self.features.shape[0], size=1)[0]\n            # Select only gene expression and cell viability features\n            swap_features = np.random.choice(\n                np.array(range(3, self.features.shape[1])),\n                size=int(self.features.shape[1] * self.swap_portion),\n                replace=False)\n            X[swap_features] = self.features[swap_index, swap_features]\n\n        return X\n\n    def __len__(self):\n        return self.features.shape[0]\n\nclass MoAImageDataset(torch.utils.data.Dataset):\n    def __init__(self, features, labels, transformer):\n        self.features = features\n        self.labels = labels\n        self.transformer = transformer\n\n    def __getitem__(self, index):\n        normalized = self.features[index, :]\n        normalized = np.expand_dims(normalized, axis=0)\n\n        # Note: we are setting empty_value=1 to follow the setup in the paper\n        image = self.transformer.transform(normalized, empty_value=1)[0]\n\n        # Resize to target size\n        gene_cht = cv2.resize(image, (image_size, image_size),\n                              interpolation=cv2.INTER_CUBIC)\n\n        # Convert to 3 channels\n        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n\n        return {\"x\": image.astype(float), \"y\": self.labels[index, :].astype(float)}\n\n    def __len__(self):\n        return len(self.features)\n\nclass TestDataset(torch.utils.data.Dataset):\n    def __init__(self, features, labels, transformer):\n        self.features = features\n        self.labels = labels\n        self.transformer = transformer\n\n    def __getitem__(self, index):\n        normalized = self.features[index, :]\n        normalized = np.expand_dims(normalized, axis=0)\n\n        # Note: we are setting empty_value=1 to follow the setup in the paper\n        image = self.transformer.transform(normalized, empty_value=1)[0]\n\n        # Resize to target size\n        gene_cht = cv2.resize(image, (image_size, image_size),\n                              interpolation=cv2.INTER_CUBIC)\n\n        # Convert to 3 channels\n        image = np.repeat(gene_cht[np.newaxis, :, :], 3, axis=0)\n\n        return {\"x\": image.astype(float), \"y\": -1}\n\n    def __len__(self):\n        return len(self.features)\n\ndef get_infer_model(model_path, test_set, transformer):\n    model = MoAEfficientNet.load_from_checkpoint(\n        model_path,\n        pretrained_model_name=pretrained_model,\n        training_set=(None, None),  # tuple\n        valid_set=(None, None),  # tuple\n        test_set=test_set,\n        transformer=transformer,\n        drop_rate=drop_rate,\n        drop_connect_rate=drop_connect_rate,\n        fc_size=fc_size,\n        weight_init='goog')\n\n    model.freeze()\n    model.eval()\n    return model\n\ndef get_train_model(training_set, valid_set, transformer, test_set=None):\n    model = MoAEfficientNet(\n        pretrained_model_name=pretrained_model,\n        training_set=training_set,  # tuple\n        valid_set=valid_set,  # tuple\n        test_set=test_set,\n        transformer=transformer,\n        drop_rate=drop_rate,\n        drop_connect_rate=drop_connect_rate,\n        fc_size=fc_size,\n        weight_init='goog', learning_rate=1e-3)\n    return model\n\ndef mean_logloss(y_pred, y_true):\n    logloss = (1 - y_true) * np.log(1 - y_pred +\n                                    1e-15) + y_true * np.log(y_pred + 1e-15)\n    return np.mean(-logloss)\n\ndef load_pickle(model_output_folder, fold_i, name):\n    return pickle.load(open(f\"{model_output_folder}/fold{fold_i}_{name}.pkl\", 'rb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfolds = 5\ncreatetransformer=True\n\nfold = create_folds(1, kfolds)\nres = train_labels.copy()\nres.loc[:, train_labels.columns] = 0\n\nfor i in range(kfolds):\n    \n    train_index, val_index = np.where(fold!=i)[1], np.where(fold==i)[1]\n\n    train_all_features = train_features.loc[train_index, all_features].copy().reset_index(drop=True).values\n    t_labels = train_labels.iloc[train_index].copy().reset_index(drop=True).values\n    valid_all_features = train_features.loc[val_index, all_features].copy().reset_index(drop=True).values\n    v_labels = train_labels.iloc[val_index].copy().reset_index(drop=True).values\n    test_all_features = train_features[all_features].copy().reset_index(drop=True).values\n    print(train_all_features.shape, t_labels.shape, valid_all_features.shape, v_labels.shape, test_all_features.shape)\n\n    T_max = math.floor(len(t_labels)/batch_size)\n\n    if createtransformer:\n        all_scaler = LogScaler()\n        train_all_features = all_scaler.fit_transform(train_all_features)\n        valid_all_features = all_scaler.transform(valid_all_features)\n        test_all_features = all_scaler.transform(test_all_features)\n        save_pickle(all_scaler, model_output_folder, i, \"log-scaler\")\n\n        transformer= DeepInsightTransformer(pixels=resolution,\n                                        perplexity=perplexity)\n        transformer=transformer.fit(train_all_features)\n        save_pickle(transformer, model_output_folder, i, \"deepinsight-transform\")\n    else: \n        scaler = load_pickle(model_info['model_path'], i, \"log-scaler\")\n        train_all_features = scaler.transform(train_all_features)\n        valid_all_features = scaler.transform(valid_all_features)\n        transformer = load_pickle(model_info['model_path'], i, \"deepinsight-transform\")\n    model = get_train_model(training_set=(train_all_features, t_labels), valid_set=(valid_all_features, v_labels), test_set=valid_all_features, transformer=transformer)\n    callbacks = [\n        pl.callbacks.EarlyStopping(monitor='val_loss_epoch',\n                    min_delta=1e-6,\n                    patience=patience,\n                    verbose=True,\n                    mode='min',\n                    strict=True),\n        pl.callbacks.LearningRateMonitor(logging_interval='step')\n    ]\n\n    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n        filepath=f\"{model_output_folder}/fold{i}\" +\n        \"/{epoch}-{train_loss_epoch:.6f}-{val_loss_epoch:.6f}\" +\n        f\"-image_size={image_size}-resolution={resolution}-perplexity={perplexity}-fc={fc_size}\",\n        save_top_k=1,\n        save_weights_only=False,\n        save_last=False,\n        verbose=True,\n        monitor='val_loss_epoch',\n        mode='min',\n        prefix='')\n\n    trainer = pl.Trainer(\n        gpus=gpus,\n        distributed_backend=\"dp\",  # multiple-gpus, 1 machine\n        max_epochs=epochs,\n        benchmark=False,\n        deterministic=True,\n        checkpoint_callback=checkpoint_callback,\n        callbacks=callbacks,\n        #accumulate_grad_batches=accumulate_grad_batches,\n        #gradient_clip_val=gradient_clip_val,\n        precision=16,\n        #logger=logger\n        )\n    trainer.fit(model)\n\n    output = trainer.test(model, verbose=False)[0]\n    res.iloc[val_index] += output[\"pred_probs\"]\n\nres.to_csv('res.csv', index=False)\n\nres.loc[train_features['cp_type'] == 0, train_labels.columns] = 0\n\nmetrics = []\nfor _target in train_labels.columns:\n    metrics.append(log_loss(train_labels.loc[:, _target], res.loc[:, _target]))\nprint(f'OOF Metric with postprocessing: {np.mean(metrics)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}