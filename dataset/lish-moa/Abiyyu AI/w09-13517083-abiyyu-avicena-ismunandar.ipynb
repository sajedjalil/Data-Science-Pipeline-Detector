{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Week 09 Handson\nIn this week handson, we'll try to play with Kaggle, which is one of the biggest data science community platforms. We will try to join a Kaggle competition by building a model that can predict MoA (Mechanisms of Action) in drugs development. General guide about what you need to do:\n1. Register to Kaggle (if you haven't had an account yet) with your full name,\n2. Download the dataset,\n3. Build a model,\n4. Perform an inference to the given testing data,\n5. Submit the inference result\n\nCompetition link: [cick here](https://www.kaggle.com/c/lish-moa/overview)\n\nSubmission:\n1. This jupyter notebook: there are at least three blocks of codes, which are data preparation, modelling and inference. However, you are free to modify, e.g., further breaking down the data prepration block to EDA and data preprocessing, etc.\n2. Csv file that is submitted to the competition.\n3. Screenshot of your posisition in the leaderboard (jpg file).\n\nZip those three files above, with a file name of \"W09_your-student-id_your-name.zip\" and submit to the course portal. In case the allowable size is exceeded, you can upload to, e.g., gdrive first, then upload a txt file containing that download url to the course portal. In such case, please make sure that the url is publicly open."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ndisplay(df_train.head(3))\nprint('train data size', df_train.shape)\n\ndf_target_ns = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ndisplay(df_target_ns.head(3))\nprint('train target nonscored size', df_target_ns.shape)\n\n\ndf_target_s = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ndisplay(df_target_s.head(3))\nprint('train target scored size', df_target_s.shape)\n\n\ndf_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ndisplay(df_test.head(3))\nprint('test data size', df_test.shape)\n\ndf_sample = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\ndisplay(df_sample.head(3))\nprint('sample submission size', df_sample.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"There is a better EDA that has been done by the community in the following links: <br> -https://www.kaggle.com/sinamhd9/mechanisms-of-action-moa-tutorial <br> - https://www.kaggle.com/gunesevitan/mechanisms-of-action-moa-prediction-eda"},{"metadata":{},"cell_type":"markdown","source":"From the EDA it can be inferred that there are rows which are called controlled groups and always results in 0. I will always predict 0 for cp_type == cntrl_vehichle. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# cp_time and cp_dose are two categorical data and will be preprocessed as follows\ndef preprocess(df):\n    df['cp_time'] = df['cp_time'].map({24:1, 48:2, 72:3})\n    df['cp_dose'] = df['cp_dose'].map({'D1':0, 'D2':1})\n    return df\n\ndf_train = preprocess(df_train)\ndf_test = preprocess(df_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom category_encoders import CountEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import log_loss\nfrom sklearn.multioutput import MultiOutputClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NFOLDS = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping ID column\nX = df_train.iloc[:,1:].to_numpy()\nX_test = df_test.iloc[:,1:].to_numpy()\ny = df_target_s.iloc[:,1:].to_numpy() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n\nclf = Pipeline([('encode', CountEncoder(cols=[0, 2])),\n                ('classify', classifier)\n               ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'classify__estimator__colsample_bytree': 0.6522,\n          'classify__estimator__gamma': 3.6975,\n          'classify__estimator__learning_rate': 0.0503,\n          'classify__estimator__max_delta_step': 2.0706,\n          'classify__estimator__max_depth': 10,\n          'classify__estimator__min_child_weight': 31.5800,\n          'classify__estimator__n_estimators': 166,\n          'classify__estimator__subsample': 0.8639\n         }\n\n_ = clf.set_params(**params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_preds = np.zeros(y.shape)\ntest_preds = np.zeros((df_test.shape[0], y.shape[1]))\noof_losses = []\nkf = KFold(n_splits=NFOLDS)\nfor fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n    print('Starting fold: ', fn)\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n    \n    # drop where cp_type==ctl_vehicle (baseline)\n    ctl_mask = X_train[:,0]=='ctl_vehicle'\n    X_train = X_train[~ctl_mask,:]\n    y_train = y_train[~ctl_mask]\n    \n    clf.fit(X_train, y_train)\n    val_preds = clf.predict_proba(X_val) # list of preds per class\n    val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n    oof_preds[val_idx] = val_preds\n    \n    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n    oof_losses.append(loss)\n    preds = clf.predict_proba(X_test)\n    preds = np.array(preds)[:,:,1].T # take the positive class\n    test_preds += preds / NFOLDS\n    \nprint(oof_losses)\nprint('Mean OOF loss across folds', np.mean(oof_losses))\nprint('STD OOF loss across folds', np.std(oof_losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"control_mask = df_train['cp_type']=='ctl_vehicle'\noof_preds[control_mask] = 0\n\nprint('OOF log loss: ', log_loss(np.ravel(y), np.ravel(oof_preds)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"control_mask = df_test['cp_type']=='ctl_vehicle'\n\ntest_preds[control_mask] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample.iloc[:,1:] = test_preds\ndf_sample.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"dsdm","language":"python","name":"dsdm"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}