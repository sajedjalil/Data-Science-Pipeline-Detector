{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Description:\n* In this notebook effectivity of ***1D,2D and 3D CNNs*** is evaluated\n* In order to apply CNNs efficiently to the data, it is aranged into arrays in a way that genes with a high covariance are close to each other\n* This is done by projecting the data into a 1-,2- or 3 dimensional space using ***t-sne***\n* It turns out that this way of aranging the data yields significantly better results for the 1D and 2D CNN\n* The 3D CNN generally yields bad results "},{"metadata":{},"cell_type":"markdown","source":"# Table of contents\n1. [Dimensionality reduction by t-sne](#section-one)\n2. [Arranging the data into arrays](#section-two)\n3. [Dataloading](#section-three)\n4. [Models](#section-four)\n5. [Training](#section-five)\n6. [Evaluating arrangement and models](#section-six)\n    - [Train-, validation and testsets](#subsection-one)\n    - [Training models](#subsection-two)\n    - [Testing and comparing arangement models](#subsection-three)\n7. [Conclusion](#section-seven)"},{"metadata":{"trusted":true},"cell_type":"code","source":"DoTrain = False\nDoTrain3D = False\nDoCV = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport sklearn\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom sklearn.manifold import TSNE\nimport sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_labels_df = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\nsubmission = pd.read_csv('../input/lish-moa/sample_submission.csv')\ntrain_df = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catnames = train_features_df.columns[1:4]\ncatnames = [str(c) for c in catnames]\n\ncontnames = train_features_df.columns[4:]\ncontnames = [str(c) for c in contnames]\n\nynames = train_labels_df.columns[1:]\nynames = [y for y in ynames]\n\njoined = pd.concat([train_features_df, train_labels_df], axis=1, join='inner')\njoined = joined.drop(columns = 'sig_id')\njoined = joined[joined['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# 1.) Dimensionality reduction by t-sne"},{"metadata":{},"cell_type":"markdown","source":"* In the following sections the g- and c-data is aranged into a 1-,2- or 3-dimensional cubic grid of length n_sqrt\n* For this the absolute of the entries of the covariance matrix (here named cov) are interpreted as the pairwise distances between the data columns\n* When applying t-sne to the absolute covariance matrix the data columns with higher absolute covariance will be closer to each other in the lower diomensional projected space\n* The lower diomensional projected space is then divided into equidistantly spaced 'pixels' \n* Then, while iterating over the 'pixels', the data column with the closest distance to the 'pixel' in the projected space is assigned to the respective 'pixel' \n* This assignment to pixels is stored into a dictionary by the GetIndexMapND functions in the Map section\n* To these 'images' a CNN is then applied\n* As a reference, another 'image' is generated by assigning data columns to each pixel according to the order they appear in the data frame \n* This random arangement of the data columns is supposed determine if the arangement according to covariance is of any use \n* The random arangement is stored into a dictionary by the GetUnityMapND functions in the Map section"},{"metadata":{"trusted":true},"cell_type":"code","source":"cov = np.cov(train_features_df[train_features_df.columns[4:]].to_numpy().transpose())\nplt.imshow(cov)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cov = 1 / cov","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dim = 2\ntsne_em = TSNE(n_components=dim, perplexity=40.0, n_iter=1000, verbose=1, metric='precomputed').fit_transform(np.abs(cov))\nif dim == 1:\n    plt.hist(*[tsne_em[:,i] for i in range(dim)])\nelse:\n    plt.scatter(*[tsne_em[:,i] for i in range(dim)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# 2.) Arranging the data into arrays\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def GetIndexMap1D(tsne_em, n_sqrt):\n    mini = np.min(tsne_em,axis = 0)\n    maxi = np.max(tsne_em,axis = 0)\n    d = (maxi - mini) / n_sqrt\n    dic={}\n    indexhelper = np.arange(0,tsne_em.shape[0])\n    tsnecopy = tsne_em.copy()\n    count = 0\n    for i in range(n_sqrt):        \n            pos = mini + np.array([i*d[0]])\n            ds = []\n            for s in range(tsne_em.shape[0]):\n                ds.append(np.linalg.norm(tsnecopy[s] - pos))\n            ds = np.array(ds)\n            mindindex = indexhelper[ds == np.min(ds)]\n            tsnecopy[mindindex] = np.array([np.inf])\n            if count <  len(train_df.columns) - 4:\n                dic[i] = mindindex[0]\n            count += 1\n    return dic\n\n\ndef GetIndexMap2D(tsne_em, n_sqrt):\n    mini = np.min(tsne_em,axis = 0)\n    maxi = np.max(tsne_em,axis = 0)\n    d = (maxi - mini) / n_sqrt\n    dic={}\n    indexhelper = np.arange(0,tsne_em.shape[0])\n    tsnecopy = tsne_em.copy()\n    count = 0\n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            pos = mini + np.array([i*d[0],j*d[1]])\n            ds = []\n            for s in range(tsne_em.shape[0]):\n                ds.append(np.linalg.norm(tsnecopy[s] - pos))\n            ds = np.array(ds)\n            mindindex = indexhelper[ds == np.min(ds)]\n            tsnecopy[mindindex] = np.array([np.inf,np.inf])\n            if count <  len(train_df.columns) - 4:\n                dic[(i,j)] = mindindex[0]\n            count += 1\n    return dic\n\n\ndef GetIndexMap3D(tsne_em, n_sqrt):\n    mini = np.min(tsne_em,axis = 0)\n    maxi = np.max(tsne_em,axis = 0)\n    d = (maxi - mini) / n_sqrt\n    dic={}\n    indexhelper = np.arange(0,tsne_em.shape[0])\n    tsnecopy = tsne_em.copy()\n    count = 0\n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            for k in range(n_sqrt):\n                pos = mini + np.array([i*d[0],j*d[1],k*d[2]])\n                ds = []\n                for s in range(tsne_em.shape[0]):\n                    ds.append(np.linalg.norm(tsnecopy[s] - pos))\n                ds = np.array(ds)\n                mindindex = indexhelper[ds == np.min(ds)]\n                tsnecopy[mindindex] = np.array([np.inf,np.inf,np.inf])\n                if count <  len(train_df.columns) - 4:\n                    dic[(i,j,k)] = mindindex[0]\n                count += 1\n    return dic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def GetUnityMap1D(n_sqrt):\n    dic = {}\n    for i in range(n_sqrt):\n        dic[i] = i\n    return dic\n\ndef GetUnityMap2D(n_sqrt):\n    dic = {}\n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            dic[(i,j)] = i * n_sqrt + j\n    return dic\n\ndef GetUnityMap3D(n_sqrt):\n    dic = {}\n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            for k in range(n_sqrt):\n                dic[(i,j,k)] = i * n_sqrt * n_sqrt + j * n_sqrt + k            \n    return dic","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# 3.) Dataloading"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getBatchNormalized(inds,dic,mini,maxi,dim):    \n    if dim == 1:          \n        return getBatchNormalized1D(inds,dic,mini,maxi,872).astype(np.single)\n    if dim == 2:\n        return getBatchNormalized2D(inds,dic,mini,maxi,30).astype(np.single)\n    if dim == 3:\n        return getBatchNormalized3D(inds,dic,mini,maxi,10).astype(np.single)\n    \ndef getStats(dic,dim):    \n    if dim == 1:          \n        return getStats1D(dic,872)\n    if dim == 2:\n        return getStats2D(dic,30)\n    if dim == 3:\n        return getStats3D(dic,10)\n\ndef getBatchNormalized1D(inds,dic,mini,maxi,n_sqrt):    \n        \n    image = np.zeros((len(inds),1,n_sqrt))\n    rows = joined[contnames].iloc[inds].to_numpy()   \n    \n    for i in range(n_sqrt):        \n        try:\n            image[:,0,i] = rows[:,dic[i]]\n        except:                \n            continue\n                \n    ampl = (maxi - mini)\n    ampl[ampl == 0] = 1\n    \n    result = (image - mini) / ampl\n    \n    return result   \n\ndef getBatchNormalized2D(inds,dic,mini,maxi,n_sqrt):    \n        \n    image = np.zeros((len(inds),1,n_sqrt,n_sqrt))\n    rows = joined[contnames].iloc[inds].to_numpy()  \n    \n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            try:\n                image[:,0,i,j] = rows[:,dic[(i,j)]]\n            except:                \n                continue\n                \n    ampl = (maxi - mini)\n    ampl[ampl == 0] = 1\n    \n    result = (image - mini) / ampl\n    \n    return result   \n\ndef getBatchNormalized3D(inds,dic,mini,maxi,n_sqrt):    \n        \n    image = np.zeros((len(inds),1,n_sqrt,n_sqrt,n_sqrt))\n    rows = joined[contnames].iloc[inds].to_numpy()  \n    \n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            for j in range(n_sqrt):            \n                try:\n                    image[:,0,i,j,k] = rows[:,dic[(i,j,k)]]\n                except:                \n                    continue\n                \n    ampl = (maxi - mini)\n    ampl[ampl == 0] = 1\n    \n    result = (image - mini) / ampl\n    \n    return result   \n\ndef getStats1D(dic,n_sqrt):\n    image = np.zeros((joined.shape[0],1,n_sqrt))\n    row = joined[contnames].to_numpy()    \n    for i in range(n_sqrt):        \n        try:\n            image[:,0,i] = row[:,dic[i]]\n        except:                \n            continue                \n                \n    return np.min(image,axis = 0), np.max(image,axis = 0)    \n\n\ndef getStats2D(dic,n_sqrt):\n    image = np.zeros((joined.shape[0],1,n_sqrt,n_sqrt))\n    row = joined[contnames].to_numpy()    \n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            try:\n                image[:,0,i,j] = row[:,dic[(i,j)]]\n            except:                \n                continue                \n                \n    return np.min(image,axis = 0), np.max(image,axis = 0)    \n\ndef getStats3D(dic,n_sqrt):\n    image = np.zeros((joined.shape[0],1,n_sqrt,n_sqrt,n_sqrt))\n    row = joined[contnames].to_numpy()    \n    for i in range(n_sqrt):\n        for j in range(n_sqrt):\n            for k in range(n_sqrt):\n                try:\n                    image[:,0,i,j,k] = row[:,dic[(i,j,k)]]\n                except:                \n                    continue                \n                \n    return np.min(image,axis = 0), np.max(image,axis = 0)    \n\ndef getLabelBatch(inds):\n    entry = joined.iloc[inds]\n    return entry[ynames].to_numpy().astype(np.single)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BatchLoader:\n    def __init__(self,trainInds,valInds,dim,dic,bs):\n        self.trainIndices = trainInds\n        self.valInds = valInds\n        self.dim = dim\n        self.dic = dic\n        self.min,self.max = getStats(dic,dim)\n        self.its = trainIndices.shape[0] // bs\n        self.bs = bs\n        if self.trainIndices.shape[0] - self.its * bs > 0:\n            self.its += 1\n        \n    def randomize(self):\n        self.pmt = np.random.permutation(range(self.trainIndices.shape[0]))\n        \n    def __len__(self):\n        return self.its      \n    \n    def getValidationSet(self):        \n        inpBatch = getBatchNormalized(self.valInds,self.dic,self.min,self.max,self.dim) \n        tgtBatch = getLabelBatch(self.valInds)    \n        \n        return torch.from_numpy(inpBatch), torch.from_numpy(tgtBatch)      \n        \n    def __getitem__(self, index):\n        start = index * self.bs\n        end = min((index+1)*self.bs,self.trainIndices.shape[0])\n        inds = self.trainIndices[self.pmt][start:end]\n        inpBatch = getBatchNormalized(inds,self.dic,self.min,self.max,self.dim) \n        tgtBatch = getLabelBatch(inds)    \n        \n        return torch.from_numpy(inpBatch), torch.from_numpy(tgtBatch)      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# 4.) Models\n* Here the 1-,2- and 3-dimensional CNN models are defined\n* These models are very simple and consist of two convolutional layers, with number of channels and filter size can be set varied"},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuickModelBase(nn.Module):\n    def __init__(self):\n        super(QuickModelBase, self).__init__()  \n        \n        \n    def forward(self, x, dbg = False, dropout = True):        \n        x = self.bn1(x)\n        x = self.conv1(x)\n        x = self.act1(x)\n        if dropout: x = self.do1(x)\n        \n        x = self.bn2(x)\n        x = self.conv2(x)\n        x = self.act2(x)\n        if dropout: x = self.do2(x)\n        \n        x = self.bn3(x)\n        x = self.conv3(x)\n        x = self.act3(x)\n        if dropout: x = self.do3(x)\n        \n        x = self.bn4(x)                \n        x = torch.flatten(x,start_dim = 1)        \n        x = self.full1(x)\n        x = self.act4(x)       \n                \n        return x\n    \n    \nclass QuickModel1DGen(QuickModelBase):\n    def __init__(self,feat_num,filter_size,n_sqrt):\n        super(QuickModel1DGen, self).__init__()\n        self.bn1 = torch.nn.BatchNorm1d(1)\n        self.conv1 = nn.Conv1d(1,feat_num[0],filter_size[0],1)\n        self.act1 = nn.PReLU()\n        self.do1 = nn.Dropout(p=0.2)\n        self.bn2 = torch.nn.BatchNorm1d(feat_num[0])\n        self.conv2 = nn.Conv1d(feat_num[0],feat_num[1],filter_size[1],1)\n        self.act2 = nn.PReLU()  \n        self.do2 = nn.Dropout(p=0.2)\n        self.bn3 = torch.nn.BatchNorm1d(feat_num[1])\n        self.conv3 = nn.Conv1d(feat_num[1],feat_num[2],n_sqrt-filter_size[0]-filter_size[1]+2,1)\n        self.act3 = nn.PReLU()\n        self.do3 = nn.Dropout(p=0.2)\n        self.bn4 = torch.nn.BatchNorm1d(feat_num[2])\n        self.full1 = torch.nn.Linear(feat_num[2], 206)\n        self.act4 = nn.PReLU()\n        \n\nclass QuickModel2DGen(QuickModelBase):\n    def __init__(self,feat_num,filter_size,n_sqrt):\n        super(QuickModel2DGen, self).__init__()\n        self.bn1 = torch.nn.BatchNorm2d(1)\n        self.conv1 = nn.Conv2d(1,feat_num[0],filter_size[0],1)\n        self.act1 = nn.PReLU()  \n        self.do1 = nn.Dropout(p=0.2)\n        self.bn2 = torch.nn.BatchNorm2d(feat_num[0])\n        self.conv2 = nn.Conv2d(feat_num[0],feat_num[1],filter_size[1],1)\n        self.act2 = nn.PReLU()  \n        self.do2 = nn.Dropout(p=0.2)\n        self.bn3 = torch.nn.BatchNorm2d(feat_num[1])\n        self.conv3 = nn.Conv2d(feat_num[1],feat_num[2],n_sqrt-filter_size[0]-filter_size[1]+2,1)\n        self.act3 = nn.PReLU()\n        self.do3 = nn.Dropout(p=0.2)\n        self.bn4 = torch.nn.BatchNorm2d(feat_num[2])\n        self.full1 = torch.nn.Linear(feat_num[2], 206)\n        self.act4 = nn.PReLU()    \n        \n        \nclass QuickModel3DGen(QuickModelBase):\n    def __init__(self,feat_num,filter_size, n_sqrt):\n        super(QuickModel3DGen, self).__init__()\n        self.bn1 = torch.nn.BatchNorm3d(1)\n        self.conv1 = nn.Conv3d(1,feat_num[0],filter_size[0],1)\n        self.act1 = nn.PReLU()        \n        self.do1 = nn.Dropout(p=0.2)\n        self.bn2 = torch.nn.BatchNorm3d(feat_num[0])\n        self.conv2 = nn.Conv3d(feat_num[0],feat_num[1],filter_size[1],1)\n        self.act2 = nn.PReLU()  \n        self.do2 = nn.Dropout(p=0.2)\n        self.bn3 = torch.nn.BatchNorm3d(feat_num[1])\n        self.conv3 = nn.Conv3d(feat_num[1],feat_num[2],n_sqrt-filter_size[0]-filter_size[1]+2,1)\n        self.act3 = nn.PReLU() \n        self.do3 = nn.Dropout(p=0.2)\n        self.bn4 = torch.nn.BatchNorm3d(feat_num[2])\n        self.full1 = torch.nn.Linear(feat_num[2], 206)\n        self.act4 = nn.PReLU()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n# 5.) Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def TrainEpoch(valloss,model,opt,sch,dim,dl,valInds,loss,istest,fold=None):\n    count = 0\n    modelname = f\"BestModel{dim}D\" if not istest else f\"BestRefModel{dim}D\"\n    if fold != None: modelname = modelname + f\"Fold{fold}\"\n    modelname = modelname + \".pth\"\n    \n    for i in range(len(dl)): \n        (inp,tgt) = dl[i]\n        opt.zero_grad()       \n        fwd = model(inp.cuda())\n        ys = tgt.cuda()\n        output = loss(fwd, ys)        \n        output.backward()\n        opt.step()   \n        \n        if count % 1 == 0:           \n            batchVal,ysVal = dl.getValidationSet()\n            fwdVal = model(batchVal.cuda())            \n            currentvalloss = loss(fwdVal, ysVal.cuda()).detach().cpu().numpy()   \n            \n            if currentvalloss < valloss:\n                valloss = currentvalloss\n                torch.save(model.state_dict(), modelname)\n                \n        count += 1\n                \n    return currentvalloss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Train(dim, dic, bs, trainInds, valInds, model,istest,fold = None):    \n    dl = BatchLoader(trainInds,valInds, dim, dic,bs)\n\n    loss = nn.BCEWithLogitsLoss().cuda()    \n\n    lrstart = 0.1\n    optimizer = optim.Adam(model.parameters(), lr=lrstart)\n    scheduler = ReduceLROnPlateau(optimizer, 'min')\n\n    valloss = np.inf\n    for e in range(70):\n        if e % 3 == 0: print('Epoch: ' + str(e)) \n        dl.randomize()\n        currentvalloss = TrainEpoch(valloss,model,optimizer,scheduler,dim,dl,valIndices,loss,istest,fold)\n        scheduler.step(currentvalloss)\n        if abs(currentvalloss - valloss) < 0.0000001: break\n        if currentvalloss < valloss: \n            valloss = currentvalloss\n            print('BestLoss: ' + str(currentvalloss))\n    \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-six\"></a>\n# 6.) Evaluating arrangement and models"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-one\"></a>\n# 6.1) Train-, validation and testsets "},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = joined.copy()\nFold = MultilabelStratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n\nindices = {}\nfor n, (trainidx, validx) in enumerate(Fold.split(joined, joined[ynames])):    \n    indices[n] = (trainidx, validx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valIndices = indices[0][1]\ntestIndices = indices[4][1]\ntrainIndices =  indices[0][0]\ntrainIndices = trainIndices[np.isin(trainIndices,testIndices,invert=True)]\nvalIndices = valIndices[np.isin(valIndices,testIndices,invert=True)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-two\"></a>\n# 6.2) Training models"},{"metadata":{},"cell_type":"markdown","source":"# 1D"},{"metadata":{"trusted":true},"cell_type":"code","source":"if DoTrain or DoCV:\n    tsne1D = TSNE(n_components=1, perplexity=40.0, n_iter=1000, verbose=1, metric='precomputed').fit_transform(np.abs(cov))\n    np.save('tsne1D',tsne1D)\nelse: \n    tsne1D = np.load('../input/t-sne-for-applying-nd-cnns/tsne1D.npy')    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dicRef1D = GetUnityMap1D(872)\ndic1D = GetIndexMap1D(tsne1D,872)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 512\nmodelRef1D = QuickModel1DGen([10,20,40],[5,30],872).cuda()\nif DoTrain: Train(1, dicRef1D, bs, trainIndices, valIndices, modelRef1D,True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1D = QuickModel1DGen([10,20,40],[5,30],872).cuda()\nif DoTrain: Train(1, dic1D, bs, trainIndices, valIndices, model1D,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DoCV:\n    fold = 0\n    for i in indices:\n        print(f\"Fold: {i}\")\n        model1D = QuickModel1DGen([10,20,40],[5,30],872).cuda()\n        valInds = indices[i][1]\n        trainInds = indices[i][0]\n        Train(1, dicRef1D, bs, trainInds, valInds, model1D,True,fold)\n        fold += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2D"},{"metadata":{"trusted":true},"cell_type":"code","source":"if DoTrain or DoCV:\n    tsne2D = TSNE(n_components=2, perplexity=40.0, n_iter=1000, verbose=1, metric='precomputed').fit_transform(np.abs(cov))\n    np.save('tsne2D',tsne2D)\nelse: tsne2D = np.load('../input/t-sne-for-applying-nd-cnns/tsne2D.npy')    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dicRef2D = GetUnityMap2D(30)\ndic2D = GetIndexMap2D(tsne2D,30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 512\nmodelRef2D = QuickModel2DGen([10,20,40],[10,10],30).cuda()\nif DoTrain: Train(2, dicRef2D, bs, trainIndices, valIndices, modelRef2D,True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2D = QuickModel2DGen([10,20,40],[10,10],30).cuda()\nif DoTrain: Train(2, dic2D, bs, trainIndices, valIndices, model2D,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DoCV:\n    fold = 0\n    for i in indices:\n        print(f\"Fold: {i}\")\n        model2D = QuickModel2DGen([10,20,40],[10,10],30).cuda()\n        valInds = indices[i][1]\n        trainInds = indices[i][0]\n        Train(2, dic2D, 512, trainInds, valInds, model2D,False,fold)\n        fold += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3D"},{"metadata":{"trusted":true},"cell_type":"code","source":"if DoTrain3D:\n    tsne3D = TSNE(n_components=3, perplexity=40.0, n_iter=1000, verbose=1, metric='precomputed').fit_transform(np.abs(cov))\n    np.save('tsne3D',tsne3D)\nelse: tsne3D = np.load('../input/t-sne-for-applying-nd-cnns/tsne3D.npy')    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dicTest3D = GetUnityMap3D(10)\ndic3D = GetIndexMap3D(tsne3D,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 64\nmodelRef3D = QuickModel3DGen([20,40,80],[3,5],10).cuda()\nif DoTrain3D: Train(3, dicTest3D, bs, trainIndices, valIndices, modelRef3D,True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3D = QuickModel3DGen([10,20,40],[3,5],10).cuda()\nif DoTrain3D: Train(3, dic3D, 256, trainIndices, valIndices, model3D,False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three\"></a>\n# 6.3) Testing and comparing arangement models"},{"metadata":{},"cell_type":"markdown","source":"# 1D"},{"metadata":{"trusted":true},"cell_type":"code","source":"mini, maxi = getStats(dic1D,1)\nbatch1D = getBatchNormalized(testIndices,dic1D,mini,maxi,1) \nmini, maxi = getStats(dicRef1D,1)\nbatchRef1D = getBatchNormalized(testIndices,dicRef1D,mini,maxi,1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DoTrain: \n    model1D.load_state_dict(torch.load(\"./BestModel1D.pth\"))\n    modelRef1D.load_state_dict(torch.load(\"./BestRefModel1D.pth\"))\nelse: \n    model1D.load_state_dict(torch.load(\"../input/t-sne-for-applying-nd-cnns/BestModel1D.pth\"))\n    modelRef1D.load_state_dict(torch.load(\"../input/t-sne-for-applying-nd-cnns/BestRefModel1D.pth\"))\n    \nloss = nn.BCEWithLogitsLoss().cuda()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch1DTorch = torch.from_numpy(batch1D.astype(np.single)).cuda()\nbatchRef1DTorch = torch.from_numpy(batchRef1D.astype(np.single)).cuda()\nfwdVal = model1D.forward(batch1DTorch,False,False)\nfwdRefVal = modelRef1D.forward(batchRef1DTorch,False,False)\nysVal = torch.from_numpy(getLabelBatch(testIndices)).cuda()\ntestloss1D = loss(fwdVal, ysVal).detach().cpu().numpy()\ntestlossRef1D = loss(fwdRefVal, ysVal).detach().cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('1D: ')\nprint('Test loss: ')\nprint(testloss1D)\nprint('Test loss unaranged reference model: ')\nprint(testlossRef1D)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2D"},{"metadata":{"trusted":true},"cell_type":"code","source":"mini, maxi = getStats(dic2D,2)\nbatch2D = getBatchNormalized(testIndices,dic2D,mini,maxi,2) \nmini, maxi = getStats(dicRef2D,2)\nbatchRef2D = getBatchNormalized(testIndices,dicRef2D,mini,maxi,2) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DoTrain:\n    model2D.load_state_dict(torch.load(\"./BestModel2D.pth\"))\n    modelRef2D.load_state_dict(torch.load(\"./BestRefModel2D.pth\"))\nelse:\n    model2D.load_state_dict(torch.load(\"../input/t-sne-for-applying-nd-cnns/BestModel2D.pth\"))\n    modelRef2D.load_state_dict(torch.load(\"../input/t-sne-for-applying-nd-cnns/BestRefModel2D.pth\"))\n    \nloss = nn.BCEWithLogitsLoss().cuda()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch2DTorch = torch.from_numpy(batch2D.astype(np.single)).cuda()\nbatchRef2DTorch = torch.from_numpy(batchRef2D.astype(np.single)).cuda()\nfwdVal = model2D.forward(batch2DTorch,False,False)\nfwdRefVal = modelRef2D.forward(batchRef2DTorch,False,False)\nysVal = torch.from_numpy(getLabelBatch(testIndices)).cuda()\ntestloss2D = loss(fwdVal, ysVal).detach().cpu().numpy()\ntestlossRef2D = loss(fwdRefVal, ysVal).detach().cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('2D: ')\nprint('Test loss: ')\nprint(testloss2D)\nprint('Test loss unaranged reference model: ')\nprint(testlossRef2D)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-seven\"></a>\n# 7.) Conclusion & Outlook"},{"metadata":{},"cell_type":"markdown","source":"* The arangement of the data columns into 2D arrays has a large impact on the performance of 1D and 2D CNNs\n* The method of aranging the data into multidimensional arrays investigated here seems promising\n* Overall the 1D CNN tried out here seems to perform slightly better then the 2D CNN\n* It should be investigated if this holds for deeper models and other train-/testset combinations\n* 3D CNN perform poorly"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}