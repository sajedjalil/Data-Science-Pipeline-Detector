{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import *\nfrom keras import callbacks\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\nfrom tensorflow.keras.losses import BinaryCrossentropy\nimport tensorflow_addons as tfa\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom tqdm.notebook import tqdm\n\nimport math\n\n\n# Classifiers\n# RF\nfrom sklearn.ensemble import RandomForestClassifier\n# Logistic \nfrom sklearn.linear_model import LogisticRegression\n# N Bayes\nfrom sklearn.naive_bayes import GaussianNB\n# Supp Vec\nfrom sklearn.svm import LinearSVC\n# XGB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\n#LGBM\nfrom lightgbm import LGBMClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '/kaggle/input/lish-moa/test_features.csv'\ntest_features = pd.read_csv(path)\n\npath = '/kaggle/input/lish-moa/train_features.csv'\ntrain_features = pd.read_csv(path)\n\npath = '/kaggle/input/lish-moa/train_drug.csv'\ntrain_drug = pd.read_csv(path)\n\npath = \"/kaggle/input/lish-moa/train_targets_scored.csv\"\ntrain_targets = pd.read_csv(path)\n\npath = '/kaggle/input/lish-moa/sample_submission.csv'\nsample_sub = pd.read_csv(path)\n\npath = \"/kaggle/input/lish-moa/train_targets_nonscored.csv\"\ntargets_nonscored = pd.read_csv(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_control_index = test_features.query('cp_type == \"ctl_vehicle\"').index\ntest_trt_index = test_features.query('cp_type == \"trt_cp\"').index\n\ntrain_control_index = train_features.query('cp_type == \"ctl_vehicle\"').index\ntrain_trt_index = train_features.query('cp_type == \"trt_cp\"').index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 1, 'ctl_vehicle': 0})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})    \n    df = pd.get_dummies(df, columns=['cp_time','cp_dose'])\n    del df['sig_id']\n    return df\n\ntrain = preprocess(train_features)\ntrain = train.query('cp_type == 1').reset_index(drop=True)\ndel train['cp_type']\n\ntest = preprocess(test_features)\ntest = test.query('cp_type == 1').reset_index(drop=True)\ndel test['cp_type']\ndel train_targets['sig_id']\n\nGENES = [col for col in train.columns if col.startswith('g-')]\nCELLS = [col for col in train.columns if col.startswith('c-')]\n\n\n# PCA with sklearn\n\n# Genes\n\ndata = pd.concat([pd.DataFrame(train[GENES]), pd.DataFrame(test[GENES])])\n\n# use 515 from biplot\ndata2 = (PCA(n_components=515, random_state=11).fit_transform(data[GENES]))\n\n# Train Components\ntrain2 = data2[:train.shape[0]]\n\n# Test Components\ntest2 = data2[-test.shape[0]:]\n\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(515)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(515)])\n\ntrain_features = pd.concat([train, train2], axis=1)\ntest_features = pd.concat([test, test2], axis=1)\n\n# Cells\n\ndata = pd.concat([pd.DataFrame(train[CELLS]), pd.DataFrame(test[CELLS])])\n\n# One principle component explains 80+ % of the variance\n# using 3 \ndata2 = (PCA(n_components=3, random_state=42).fit_transform(data[CELLS]))\n\n# Train Components \ntrain2 = data2[:train.shape[0]]\n\n# Test Components\ntest2 = data2[-test.shape[0]:]\n\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(3)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(3)])\n\ntrain_features = pd.concat([train_features, train2], axis=1)\ntest_features = pd.concat([test_features, test2], axis=1)\n\nassert len(train_features.columns) == len(test_features.columns), \"data incorrectly formatted\"\n\n\nGENES_pca = [col for col in train_features.columns if col.startswith('pca_G')]\nCELLS_pca = [col for col in train_features.columns if col.startswith('pca_C')]\n\n# Numeric Columns\n# Don't want to do this to dummy vars\n# Might not make a difference\nnumeric_cols = GENES + GENES_pca + CELLS + CELLS_pca\n\n# Min Max Scalar\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(train_features[numeric_cols].append(test_features[numeric_cols]))\n\ntrain_trans = scaler.transform(train_features[numeric_cols])\ntest_trans = scaler.transform(test_features[numeric_cols])\n\n# put back into df format\ntrain = pd.DataFrame(train_trans, columns=train_features[numeric_cols].columns)\ntest = pd.DataFrame(test_trans, columns=test_features[numeric_cols].columns)\n\n# Add dummy vars\ntrain = pd.concat([train,train_features.drop(numeric_cols,axis=1)],axis=1)\ntest = pd.concat([test,test_features.drop(numeric_cols,axis=1)],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\ntrain_targs = train_targets[train_targets.index.isin(train_trt_index)]\n\n\nfor j in range(train_targs.shape[1]):\n    X_train = train.to_numpy()\n    y_train = train_targs.iloc[:,j].to_numpy()\n\n    print(\"XGBoost Fit on column:\",j)\n    XGB = XGBClassifier(n_estimators = 150, \n                  max_depth = 3, reg_alpha = 2, min_child_weight = 2,\n                  gamma = 3, learning_rate = 0.05, \n                  colsample_bytree = 0.6)\n    \n    XGB.fit(X_train,y_train)\n    XGB_preds = XGB.predict_proba(test)[:,1]\n    predictions.append(XGB_preds)\n    print(\"---\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = sample_sub.drop(['sig_id'],axis=1).columns\nsubmission = pd.DataFrame(data=predictions).transpose()\nsubmission.columns = cols\nsubmission.set_index(test_trt_index,inplace=True)\n\ncontrols = pd.DataFrame(np.zeros((len(test_control_index),(sample_sub.shape[1] - 1))), columns=cols)\ncontrols.set_index((test_control_index),inplace=True)\n\nfin = pd.concat([submission,controls],axis=0)\nfin.sort_index(inplace=True)\nfin.insert(0,'sig_id',sample_sub['sig_id'])\nfin.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}