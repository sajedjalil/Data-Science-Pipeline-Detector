{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <h1 align='center'><font color = 'red'> ðŸ’ŠMechanisms of Action (MoA) PredictionðŸ’Š </font></h1>\n![](https://www.uicc.org/sites/main/files/styles/uicc_news_main_image/public/iStock_PIlls_1024x.jpg?itok=0LOJZO4I)"},{"metadata":{},"cell_type":"markdown","source":"# _<h1 align='center'><font color='orange'>1. Introduction</font></h1>_\n\n## _Quick Navigation_\n\n* [1. Introduction](#1)\n  * [1.1 About the Competition](#2)\n  * [1.2 Importing relevant packages](#3)\n* [2. EDA](#4)\n  * [2.1 Basic Data Overview](#5)\n  * [2.2 Categories Data Insight](#6)\n    * [2.2.1 cp_type](#7)\n    * [2.2.1 cp_time](#8)\n    * [2.2.1 cp_dose](#9)\n  * [2.3 Gene Expression and Cell Viability features](#10)\n  * [2.4 Multivariate Analysis](#11)\n    * [2.4.1 cptype / cp_time](#12)\n    * [2.4.2 cp_type / cp_dose](#13)\n    * [2.4.3 cp_time / cp_dose](#14)\n  * [2.5 Correlations](#15)\n    * [2.5.1 Correlation b/w g- features](#16)\n    * [2.5.2 Correlation b/w c- features](#17)\n    * [2.5.3 High Correlation features](#18)\n  * [2.6 Target Data Analysis](#19)\n* [3. Baseline Model](#20)\n  * [3.1 Import data](#21)\n  * [3.2 Train model](#22)\n  * [3.3 Compute log loss](#23)\n  * [3.4 Submission](#24)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n## _1.1 About the Competition_\n\n\n**<font color='red'>Q. What is Mechanism of Action (MoA) of a drug ? And why is it important ?</font>**<br><br>\nToday, with the advent of more powerful technologies, drug discovery has changed from the serendipitous approaches of the past to a more targeted model based on an understanding of the underlying biological mechanism of a disease. In this new framework, scientists seek to identify a protein target associated with a disease and develop a molecule that can modulate that protein target. As a shorthand to describe the biological activity of a given molecule, scientists assign a label referred to as mechanism-of-action or MoA for short.\n\n**<font color='red'>Q. How do we determine the MoAs of a new drug?</font>**<br><br>\nIn this competition, you will have access to a unique dataset that combines gene expression and cell viability data. The data is based on a new technology that measures simultaneously (within the same samples) human cellsâ€™ responses to drugs in a pool of 100 different cell types (thus solving the problem of identifying ex-ante, which cell types are better suited for a given drug). In addition, you will have access to MoA annotations for more than 5,000 drugs in this dataset.\n\n**<font color='red'>Q.How to evaluate the accuracy of a solution?</font>**<br><br>\nBased on the MoA annotations, the accuracy of solutions will be evaluated on the average value of the logarithmic loss function applied to each drug-MoA annotation pair.\n\nTo know more about evaluation metric , [click here](https://www.kaggle.com/c/lish-moa/overview/evaluation)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n## _1.2 Importing relevant packages_"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import log_loss\nfrom category_encoders import CountEncoder\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nimport random\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n# _<h1 align='center'><font color='orange'>2. EDA</font></h1>_\n\n<a id=\"5\"></a>\n## _2.1 Basic Data Overview_\nFirst lets see what all files our working directory contains and the data description"},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT = '../input/lish-moa'\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Files -\n- **train_features.csv** - Features for the training set. Features **g- signify gene expression** data, and **c- signify cell viability data**. cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle); control perturbations have no MoAs; cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) and dose (high or low).\n- **train_targets_scored.csv** - The binary MoA targets that are scored.\n- **train_targets_nonscored.csv** - Additional (optional) binary MoA responses for the training data. These are not predicted nor scored.\n- **test_features.csv** - Features for the test data. You must predict the probability of each scored MoA for each row in the test data.\n- **sample_submission.csv** - A submission file in the correct format."},{"metadata":{"trusted":true},"cell_type":"code","source":"# training data\ntrain = pd.read_csv(f'{ROOT}/train_features.csv')\n\n# training data targets\ntarget = pd.read_csv(f'{ROOT}/train_targets_scored.csv')\n\n# testing data\ntest = pd.read_csv(f'{ROOT}/test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No. of rows in training set : {}\".format(train.shape[0]))\nprint('No. of columns in training set : {}'.format(train.shape[1]))\nprint('No. of rows in target set : {}'.format(target.shape[0]))\nprint('No. of columns in target set : {}'.format(target.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = train.columns\ng_cols = [x for x in cols if x.startswith('g-')]\nc_cols = [x for x in cols if x.startswith('c-')]\nprint(f\"There are {train.shape[1]} columns in training and test set out of which :- \")\nprint(f\"There are {len(g_cols)} columns starting with 'g-' i.e. gene expression features.\")\nprint(f\"There are {len(c_cols)} columns starting with 'c-' i.e. cell viability features.\")\nprint(\"'sig_id', 'cp_type', 'cp_time', 'cp_dose' account for the remaining 4 columns.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['g-','c-','sig_id','cp_type', 'cp_time', 'cp_dose']\nvalues = [len(g_cols), len(c_cols), 1, 1, 1, 1]\n\n# Use `hole` to create a donut-like pie chart\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.5)])\n\nfig.update_layout(title_text=\"Distribution of columns in train and test features.\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique values for features\nprint(\"There are {} unique values in 'sig_id' column. So, there are no duplicate rows\".format(train.sig_id.nunique()))\nprint(\"There are {} unique values in 'cp_type' column having values : {}\".format(train.cp_type.nunique(), train.cp_type.unique()))\nprint(\"There are {} unique values in 'cp_time' column having values : {}\".format(train.cp_time.nunique(), train.cp_time.unique()))\nprint(\"There are {} unique values in 'cp_dose' column having values : {}\".format(train.cp_dose.nunique(), train.cp_dose.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n## _2.2 Categories Data Insight_\n<a id=\"7\"></a>\n### _2.2.1 cp_type_"},{"metadata":{"trusted":true},"cell_type":"code","source":"trt_cp_count = train.cp_type.value_counts()[0]\nctl_vehicle_count = train.cp_type.value_counts()[1]\nprint(f\"In 'cp_type' feature there are {trt_cp_count} records with value 'trt_cp' and {ctl_vehicle_count} records \" \n      + \"with value 'ctl_vehicle'\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=train.cp_type.unique()\ny_train=[trt_cp_count,ctl_vehicle_count]\ny_test=[test.cp_type.value_counts()[0], test.cp_type.value_counts()[1]]\n\nfig = go.Figure(data=[\n    go.Bar(name='test', x=x, y=y_test),\n    go.Bar(name='train', x=x, y=y_train)\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a>\n### _2.2.2 cp_time_"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are {} distinct values for 'cp_time' : {}\".format(train.cp_time.nunique(), train.cp_time.unique()))\nprint('No. of records where cp_time=24 : {}'.format(train[train.cp_time == 24].shape[0]))\nprint('No. of records where cp_time=48 : {}'.format(train[train.cp_time == 48].shape[0]))\nprint('No. of records where cp_time=72 : {}'.format(train[train.cp_time == 72].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=train.cp_time.unique()\ny_train = [train[train.cp_time == 24].shape[0],train[train.cp_time == 72].shape[0],train[train.cp_time == 48].shape[0]]\ny_test=[test[test.cp_time == 24].shape[0],test[test.cp_time == 72].shape[0],test[test.cp_time == 48].shape[0]]\nfig = go.Figure(data=[\n    go.Bar(name='test', x=x, y=y_test),\n    go.Bar(name='train', x=x, y=y_train)\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a>\n### _2.2.3 cp_dose_"},{"metadata":{"trusted":true},"cell_type":"code","source":"d1_count = train.cp_dose.value_counts()[0]\nd2_count = train.cp_dose.value_counts()[1]\nprint(f\"In 'cp_dose' feature there are {d1_count} records with value 'D1' and {d2_count} records \" \n      + \"with value 'D2'\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=train.cp_dose.unique()\ny_train=[d1_count,d2_count]\ny_test=[test.cp_dose.value_counts()[0], test.cp_dose.value_counts()[1]]\n\nfig = go.Figure(data=[\n    go.Bar(name='test', x=x, y=y_test),\n    go.Bar(name='train', x=x, y=y_train)\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\"></a>\n## _2.3 Gene Expression and Cell Viability features_\n\nIn this section, we will randomly pick a few columns of gene expression(g-) and cell viability(c-) features and gain insight from them."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# distributions of few random g- features\nrandom_g_cols = random.sample(g_cols, 10)\n\nfig = make_subplots(rows=5, cols=2, subplot_titles=random_g_cols)\n\nfig.add_trace(go.Histogram(x=train[random_g_cols[0]], name=random_g_cols[0]), row=1, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[1]], name=random_g_cols[1]), row=1, col=2)\nfig.add_trace(go.Histogram(x=train[random_g_cols[2]], name=random_g_cols[2]), row=2, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[3]], name=random_g_cols[3]), row=2, col=2)\nfig.add_trace(go.Histogram(x=train[random_g_cols[4]], name=random_g_cols[4]), row=3, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[5]], name=random_g_cols[5]), row=3, col=2)\nfig.add_trace(go.Histogram(x=train[random_g_cols[6]], name=random_g_cols[6]), row=4, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[7]], name=random_g_cols[7]), row=4, col=2)\nfig.add_trace(go.Histogram(x=train[random_g_cols[8]], name=random_g_cols[8]), row=5, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[9]], name=random_g_cols[9]), row=5, col=2)\n\nfig.update_layout(\n    title_text='Distribution of a few random Gene Expression features',\n    height = 1200,\n    width=675\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distributions of few random c- features\nrandom_c_cols = random.sample(c_cols, 10)\n\nfig = make_subplots(rows=5, cols=2, subplot_titles=random_c_cols)\n\nfig.add_trace(go.Histogram(x=train[random_c_cols[0]], name=random_c_cols[0]), row=1, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[1]], name=random_c_cols[1]), row=1, col=2)\nfig.add_trace(go.Histogram(x=train[random_c_cols[2]], name=random_c_cols[2]), row=2, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[3]], name=random_c_cols[3]), row=2, col=2)\nfig.add_trace(go.Histogram(x=train[random_c_cols[4]], name=random_c_cols[4]), row=3, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[5]], name=random_c_cols[5]), row=3, col=2)\nfig.add_trace(go.Histogram(x=train[random_c_cols[6]], name=random_c_cols[6]), row=4, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[7]], name=random_c_cols[7]), row=4, col=2)\nfig.add_trace(go.Histogram(x=train[random_c_cols[8]], name=random_c_cols[8]), row=5, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[9]], name=random_c_cols[9]), row=5, col=2)\n\nfig.update_layout(\n    title_text='Distribution of a few random Cell Viability features',\n    height = 1200,\n    width=675\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ***It is good to see that both g- and c- features are normally distributed with some features having skewness.<br>(OUTLIERS ALERT!)***"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<a id=\"11\"></a>\n## _2.4 Multivariate Analysis_\n#### *Now we are going to perform analysis between :*\n- *cp_type / cp_time*\n- *cp_type / cp_dose*\n- *cp_time / cp_dose*"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"12\"></a>\n### _2.4.1 cp_type / cp_time_"},{"metadata":{"trusted":true},"cell_type":"code","source":"trt_cp_24 = train[(train.cp_type == 'trt_cp') & (train.cp_time == 24)].shape[0]\ntrt_cp_48 = train[(train.cp_type == 'trt_cp') & (train.cp_time == 48)].shape[0]\ntrt_cp_72 = train[(train.cp_type == 'trt_cp') & (train.cp_time == 72)].shape[0]\nctl_veh_24 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_time == 24)].shape[0]\nctl_veh_48 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_time == 48)].shape[0]\nctl_veh_72 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_time == 72)].shape[0]\n\nrel_df = pd.DataFrame([['trt_cp', trt_cp_24, trt_cp_48, trt_cp_72],\n                       ['ctl_vehicle', ctl_veh_24, ctl_veh_48, ctl_veh_72]], \n                      columns = ['cp_type', '24', '48', '72'])\n\nfig = px.bar(rel_df, x=\"cp_type\", y=[\"24\", \"48\", \"72\"], title=\"Cp_type V/S Cp_time\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"13\"></a>\n### _2.4.2 cp_type/ cp_dose_"},{"metadata":{"trusted":true},"cell_type":"code","source":"trt_cp_d1 = train[(train.cp_type == 'trt_cp') & (train.cp_dose == 'D1')].shape[0]\ntrt_cp_d2 = train[(train.cp_type == 'trt_cp') & (train.cp_dose == 'D2')].shape[0]\nctl_veh_d1 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_dose == 'D1')].shape[0]\nctl_veh_d2 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_dose == 'D2')].shape[0]\n\nrel_df = pd.DataFrame([['trt_cp', trt_cp_d1, trt_cp_d2],\n                       ['ctl_vehicle', ctl_veh_d1, ctl_veh_d2]], \n                      columns = ['cp_type', 'D1', 'D2'])\n\nfig = px.bar(rel_df, x=\"cp_type\", y=['D1', 'D2'], title=\"Cp_type V/S Cp_dose\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"14\"></a>\n### _2.4.3 cp_time/ cp_dose_"},{"metadata":{"trusted":true},"cell_type":"code","source":"d1_24 = train[(train.cp_dose == 'D1') & (train.cp_time == 24)].shape[0]\nd1_48 = train[(train.cp_dose == 'D1') & (train.cp_time == 48)].shape[0]\nd1_72 = train[(train.cp_dose == 'D1') & (train.cp_time == 72)].shape[0]\nd2_24 = train[(train.cp_dose == 'D2') & (train.cp_time == 24)].shape[0]\nd2_48 = train[(train.cp_dose == 'D2') & (train.cp_time == 48)].shape[0]\nd2_72 = train[(train.cp_dose == 'D2') & (train.cp_time == 72)].shape[0]\n\nrel_df = pd.DataFrame([['D1', d1_24, d1_48, d1_72],\n                       ['D2', d2_24, d2_48, d2_72]], \n                      columns = ['cp_dose', '24', '48', '72'])\n\nfig = px.bar(rel_df, x=\"cp_dose\", y=[\"24\", \"48\", \"72\"], title=\"Cp_dose V/S Cp_time\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"15\"></a>\n## _2.5 Correlations_\nIn this section, we will look at feature correlations and see some insights :)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"16\"></a>\n### _2.5.1 Correlation b/w 'g-' features_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation b/w random 40 g- features\n\ng_df = train[random.sample(g_cols, 40)]\nf = plt.figure(figsize=(19, 15))\nplt.matshow(g_df.corr(), fignum=f.number)\nplt.xticks(range(g_df.shape[1]), g_df.columns, fontsize=14, rotation=50)\nplt.yticks(range(g_df.shape[1]), g_df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"17\"></a>\n### _2.5.2 Correlation b/w 'c-' features_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation b/w random 40 c- features\n\nc_df = train[random.sample(c_cols, 40)]\nf = plt.figure(figsize=(19, 15))\nplt.matshow(c_df.corr(), fignum=f.number)\nplt.xticks(range(c_df.shape[1]), c_df.columns, fontsize=14, rotation=50)\nplt.yticks(range(c_df.shape[1]), c_df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Lets now find out pairs of features with high correlation.\n\n<a id=\"18\"></a>\n### _2.5.3 Features with high correlations_\nHere we will use 0.9 as the threshold value to consider a correlation as a high correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['cp_time'] + g_cols + c_cols\nall_columns = []\nfor i in range(0, len(cols)):\n    for j in range(i+1, len(cols)):\n        if abs(train[cols[i]].corr(train[cols[j]])) > 0.9:\n            all_columns.append(cols[i])\n            all_columns.append(cols[j])\n\nall_columns = list(set(all_columns))\nprint('Number of columns: ', len(all_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_cols_df = train[all_columns]\nf = plt.figure(figsize=(19, 15))\nplt.matshow(all_cols_df.corr(), fignum=f.number)\nplt.xticks(range(all_cols_df.shape[1]), all_cols_df.columns, fontsize=14, rotation=50)\nplt.yticks(range(all_cols_df.shape[1]), all_cols_df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"19\"></a>\n### _2.6 Target Data Analysis_"},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No. of rows : {}\".format(target.shape[0]))\nprint(\"No. of columns : {}\".format(target.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that our target dataframe is like a sparse matrix having a lot of zeros and only a few ones.<br><br>\nSo lets count the number of ones."},{"metadata":{},"cell_type":"markdown","source":"### _2.6.1 Check rows and columns for all same values_"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_copy = target.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking columns for all same values\n\nsame_value_cols = []\ncolwise_sum = ['colwise_sum']\nmoa_df = target_copy.iloc[:, 1:]\nfor col in moa_df.columns:\n    colwise_sum.append(moa_df[col].sum())\n    if moa_df[col].sum() == 0:\n        same_value_cols.append(col)\n        \nprint(f\"There are {len(same_value_cols)} column(s) with all values same.\")\n\n# Append the colwise_sum list as last row to our target dataframe. We will use this row later.\ntarget_copy.loc[len(target_copy)] = colwise_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking rows for all same values\n\nmoa_df = target_copy.iloc[:-1,1:]\nrowwise_sum = moa_df.sum(axis=1)\nrowsum_zero_idx = []\nfor i, sum in enumerate(rowwise_sum):\n    if sum == 0:\n        rowsum_zero_idx.append(i)\n\nprint(f\"There are {len(rowsum_zero_idx)} drug samples having all same values i.e all zero MoA labels.\")\n\n# Append this rowwise sum to target dataframe. We will use this column later.\ntarget_copy['rowwise_sum'] = rowwise_sum","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### _2.6.2 Non-zero elements_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# counting the number of non-zeros\nprint(\"Total number of elements in target set : {}\".format(target.shape[0] * target.shape[1]))\nprint(\"No. of non-zero elements in target set : {}\".format(np.count_nonzero(target)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This means that target set rows are having more than one non-zero value (since the number of non-zero elements is greater than no. of rows i.e 23814) indicating -> a drug sample can have more than one MoA label.<br><br>\n\n#### Lets look at :-\n- 50 drug samples having most MoA labels under them."},{"metadata":{},"cell_type":"markdown","source":"### _2.6.3 Top 50 - Drug samples with highest number of MoA labels under them_"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_copy = target_copy.sort_values('rowwise_sum', ascending=False)\ntemp_df = target_copy.iloc[:50,:]\nfig = px.bar(temp_df, x='sig_id', y='rowwise_sum')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of activations in targets for every sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Work in progress..."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"20\"></a>\n# _<h1 align='center'><font color='orange'>3.Baseline Model</font></h1>_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize variables\nSEED = 42\nNFOLDS = 5\nnp.random.seed(SEED)\nROOT = '../input/lish-moa/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"21\"></a>\n## _3.1 Import data_"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(ROOT + 'train_features.csv')\ntargets = pd.read_csv(ROOT + 'train_targets_scored.csv')\n\ntest = pd.read_csv(ROOT + 'test_features.csv')\nsub = pd.read_csv(ROOT + 'sample_submission.csv')\n\n# drop id col\nX = train.iloc[:,1:].to_numpy()\nX_test = test.iloc[:,1:].to_numpy()\ny = targets.iloc[:,1:].to_numpy() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Build the ML Pipeline\n\nclassifier = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n\nclf = Pipeline([('encode', CountEncoder(cols=[0, 2])),\n                ('classify', classifier)\n               ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set parameters for Pipeline classifier\n\nparams = {'classify__estimator__colsample_bytree': 0.6522,\n          'classify__estimator__gamma': 3.6975,\n          'classify__estimator__learning_rate': 0.0503,\n          'classify__estimator__max_delta_step': 2.0706,\n          'classify__estimator__max_depth': 10,\n          'classify__estimator__min_child_weight': 31.5800,\n          'classify__estimator__n_estimators': 166,\n          'classify__estimator__subsample': 0.8639\n         }\n\n_ = clf.set_params(**params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"22\"></a>\n## _3.2 Train model_"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_preds = np.zeros(y.shape)\ntest_preds = np.zeros((test.shape[0], y.shape[1]))\noof_losses = []\nkf = KFold(n_splits=NFOLDS)\nfor fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n    print('Starting fold: ', fn)\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n    \n    # drop where cp_type==ctl_vehicle (baseline)\n    ctl_mask = X_train[:,0]=='ctl_vehicle'\n    X_train = X_train[~ctl_mask,:]\n    y_train = y_train[~ctl_mask]\n    \n    clf.fit(X_train, y_train)\n    val_preds = clf.predict_proba(X_val) # list of preds per class\n    val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n    oof_preds[val_idx] = val_preds\n    \n    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n    oof_losses.append(loss)\n    preds = clf.predict_proba(X_test)\n    preds = np.array(preds)[:,:,1].T # take the positive class\n    test_preds += preds / NFOLDS\n    \nprint(oof_losses)\nprint('Mean OOF loss across folds', np.mean(oof_losses))\nprint('STD OOF loss across folds', np.std(oof_losses))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"23\"></a>\n## _3.3 Compute log loss_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set control train preds to 0\ncontrol_mask = train['cp_type']=='ctl_vehicle'\noof_preds[control_mask] = 0\n\nprint('OOF log loss: ', log_loss(np.ravel(y), np.ravel(oof_preds)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"24\"></a>\n## _3.4 Submission_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set control test preds to 0\ncontrol_mask = test['cp_type']=='ctl_vehicle'\ntest_preds[control_mask] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the submission file\nsub.iloc[:,1:] = test_preds\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### <font color='blue'>Thanks for reading this kernel. I hope you gained as much insights from reading it as I got from writing it. If you liked it, an UPVOTE is highly appreciated. If you are interested in more such content, feel free to follow me! ;)</font>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}