{"cells":[{"metadata":{},"cell_type":"markdown","source":"# A Visual Guide to Mechanism of Action#\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fbiologydictionary.net%2Fwp-content%2Fuploads%2F2017%2F05%2FAgonist-and-Antagonist.jpg&f=1&nofb=1)\nSource: biologydictionary.net"},{"metadata":{},"cell_type":"markdown","source":"**Basic Idea**\n\nThis competition attempts to predict how drug molecules will affect different proteins on a cell.  As shown in the diagram above, drugs usually work by binding to a receptor and upregulating (agonist) or downregulating (antagonist) the production of some downstream cellular activity.\n\nIf we know a disease affects some particular receptor or downstream set of cell activity, we can develop drugs faster if we can predict how cells and genes affect various receptor sites.  \n\n**Get started with these discussions and kernels**\n* **\"Competition Insights\" by Matthew Masters** - This post has pulled together some of the best kernels, literature review, github pages, and insights available on the competition so far.   https://www.kaggle.com/c/lish-moa/discussion/184005\n* **MoA EDA by HeadsorTails** - The master continues to share his inspiring insights and EDA for the rest of us.  Check out his beautiful EDA here - https://www.kaggle.com/headsortails/explorations-of-action-moa-eda\n* **Amin's beautiful explanation of the datasets and exploration** - https://www.kaggle.com/amiiiney/drugs-classification-mechanisms-of-action"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Kaggle Comments:\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nSHOW_DIRS = False\n\nif SHOW_DIRS:\n    import os\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Pipeline Project Parameters****"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Number these with headings... 1.1, 2.4, 3.6\n\n# Preliminary / Exploratory Data Analysis\n\nLOAD_DATA = True               # 1.0\nVERIFY_DATA = True             # 1.1\nDO_PANDAS_PROFILING = False    # 1.2\nDO_EDA = True                  # 1.4\nSHOW_CORR = True               # 1.42\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Imports**"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import random\nfrom typing import Callable\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\n\n#\nfrom scipy.stats import spearmanr\n\n# https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.svm import SVC\n\n# ML Visualization\nfrom yellowbrick.classifier import ConfusionMatrix, ROCAUC, PrecisionRecallCurve, ClassificationReport, ClassPredictionError, DiscriminationThreshold\n\n# Encoders\n# Category encoders: https://contrib.scikit-learn.org/category_encoders/\n# https://contrib.scikit-learn.org/category_encoders/count.html\nfrom category_encoders import CountEncoder, TargetEncoder, BinaryEncoder\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# import networkx as nx\nimport matplotlib.pyplot as plt\n# import statsmodels\nimport seaborn as sns\nimport plotly.express as px\n\nfrom tqdm import tqdm\n\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Project Constants**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Display to two decimal places\n# Change maxrows and maxcols to 50?\n\n# OS Constants\nPATH = \"/kaggle/input/lish-moa/\"\n\nTEST_PATH = PATH + \"test_features.csv\"\nTRAIN_PATH = PATH + \"train_features.csv\"\nTRAIN_Y_PATH = PATH + \"train_targets_scored.csv\"\nTRAIN_UNSCORED_PATH = PATH + \"train_targets_nonscored.csv\"\n\nSUBMISSION_PATH = PATH + \"sample_submission.csv\"\n\n# Dataframe Constants\nINDEX_COL = \"sig_id\"\nCATEGORICAL_COLS = [\"\"]\nNUMERICAL_COLS = []\n\n# Pandas Constants\n\n# Graphical Constants\n\n# sns.set()\nsns.set_style('whitegrid')\nsns.set_context('poster')\n\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (16,12)\nplt.rcParams['axes.titlesize'] = 16\n\n\n# Warnings\nIGNORE_WARNINGS = False\n\nif IGNORE_WARNINGS:\n    import warnings\n    warnings.filterwarnings('ignore')\n\n# Reproducability\nSEED = 42\nnp.random.seed(42)\n# tf.random.set_seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = pd.read_csv(TRAIN_PATH, index_col = INDEX_COL)\ntrain_y = pd.read_csv(TRAIN_Y_PATH, index_col = INDEX_COL)\n\ntrain_unscored = pd.read_csv(TRAIN_UNSCORED_PATH, index_col = INDEX_COL)\n\ntest_X = pd.read_csv(TEST_PATH, index_col = INDEX_COL)\n\nsubmission_df = pd.read_csv(SUBMISSION_PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tour of Data Files ###"},{"metadata":{},"cell_type":"markdown","source":"### Y Training Set - The Targets We Have To Predict ###\n\nThe targets we have to predict are basically probabilities of activation for each of these proteins.  \n\n* **Agonists: Agonists increase the production of downstream molecules.**\n* **Antagonists and Inhibitors**:  Inhibit the production of downstream molecules by competing with other molecules for the binding site.  Antagonists are specific types of inhibitors and the difference between these terms is often domain specific.\n"},{"metadata":{},"cell_type":"markdown","source":"![y_train_moa](https://deeptestprep.com/wp-content/uploads/2020/09/y_train_moa.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"y_train shape: \", train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### X_Train - Cell and Gene Predictor Variables ###\n\n"},{"metadata":{},"cell_type":"markdown","source":"![X_train_moa](https://deeptestprep.com/wp-content/uploads/2020/09/X_train_moa.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train shape: \", train_X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### A quick look at gene data ###"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    # sample_cols = ['g-0']\n    # Create a sampled dataframe and use hue to denote different histograms?\n\n    sns.set_context('poster')\n\n    ax = sns.distplot(train_X['g-0'])\n    ax2 = sns.distplot(train_X['g-100'])\n    ax3 = sns.distplot(train_X['g-200'])\n    ax4 = sns.distplot(train_X['g-300'])\n    ax5 = sns.distplot(train_X['g-400'])\n    ax6 = sns.distplot(train_X['g-500'])\n    ax7 = sns.distplot(train_X['g-600'])\n    ax8 = sns.distplot(train_X['g-700'])\n    ax9 = sns.distplot(train_X['g-750'])\n    ax10 = sns.distplot(train_X['g-150'])\n\n\n    ax.set(title = \"Regulation of 10 Random Genes\",\n          xlabel = \"Upregulation or Downregulation\",\n          ylabel = \"Percent of Sample\")\n\n    plt.annotate(\"Gene Deeply Downregulated\", xy = (-9.9, .01), xytext = (-7.8, 0.21),\n                 size = 16,\n                 arrowprops = {'facecolor':'grey', 'width':3})\n\n    plt.annotate(\"Somewhat Downregulated\", xy = (-5, 0.05), xytext = (-7.8, 0.11), size = 16,\n                arrowprops = {'facecolor':'grey', 'width':3},\n                backgroundcolor = 'white')\n\n    plt.annotate(\"Genes Upregulated.  Slight Right Skew\", xy = (2.5, 0.06), xytext = (2.5, 0.11), size = 16,\n                arrowprops = {'facecolor':'grey', 'width':3},\n                backgroundcolor = 'white')\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    sns.set_context('poster')\n\n    ax = sns.distplot(train_X['c-0'])\n    ax2 = sns.distplot(train_X['c-10'])\n    ax3 = sns.distplot(train_X['c-20'])\n    ax4 = sns.distplot(train_X['c-30'])\n    ax5 = sns.distplot(train_X['c-40'])\n    ax6 = sns.distplot(train_X['c-50'])\n    ax7 = sns.distplot(train_X['c-60'])\n    ax8 = sns.distplot(train_X['c-70'])\n    ax9 = sns.distplot(train_X['c-80'])\n    ax10 = sns.distplot(train_X['c-90'])\n\n    ax.set(title = \"Viability of 10 Random Cell Samples\",\n          xlabel = \"Increased or decreased viability\",\n          ylabel = \"Percent of Sample\")\n\n    plt.annotate(\"Drug effective at killing cells / Error?\", xy = (-9.9, .08), xytext = (-7.8, 0.21),\n                 size = 16,\n                 arrowprops = {'facecolor':'grey', 'width':3})\n\n    plt.annotate(\"More cells are killed in general\", xy = (-4, 0.02), xytext = (-7.8, 0.11), size = 16,\n                arrowprops = {'facecolor':'grey', 'width':3},\n                backgroundcolor = 'white')\n\n    plt.annotate(\"Cell viability enhanced less often\", xy = (1.5, 0.06), xytext = (2.5, 0.11), size = 16,\n                arrowprops = {'facecolor':'grey', 'width':3},\n                backgroundcolor = 'white')\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pandas Profiling**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"if DO_PANDAS_PROFILING:\n    import pandas_profiling as pp\n    \n    train_features = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\n    train_report = pp.ProfileReport(train_features, title = \"train_dataset_profile\")\n\nif DO_PANDAS_PROFILING:\n    train_report.to_file(\"train_report.html\")\n    train_report.to_notebook_iframe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mechanism of Action EDA**\n\nQuestions I'd like to answer:\n* Do any of the categorical variables (such as time or dosage level) affect gene expression and cell viability outcomes in a predictable / linear / correlated way?\n* The unscored training set are the ligands we don't know the value of.  The scored values are the ligands we do know the value of.\n\nWhat is the relationship between these sets and the test set?\n\nFor the following, it also may be useful to generate simply hypotheses using domain knowledge:\n\n* Are certain gene responses correlated with each other?\n\n* Are certain cell viability responses correlated with each other?\n\n* Are certain gene / cell responses correlated?\n\n* What is the relationship between antagonists / agonists with the same treatment protocol?\n\n* What data transformations may make sense here?\n\n* What data denoising do we have to worry about?"},{"metadata":{},"cell_type":"markdown","source":"**EDA Helper Functions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"DO_EDA = True","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def explore_df(df: pd.DataFrame,\n               df_name : str) -> None:\n    \n    # print name and shape\n    # print describe\n    # print info\n    pass","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Training Set X: \", train_X.shape)\nprint(\"Training Set y: \", train_y.shape)\nprint(\"Unlabeled Set X: \", train_unscored.shape)\nprint(\"Testing Set X: \", test_X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 876 features which include gene activations, cell viability, and specifics about the treatment protocol.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    train_X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Correlations In the Dataset ##\n\nThis section will show linear correlations that are above a certain threshold. You can use the second interactive chart to mouse-over to see the two features that have strong correlations."},{"metadata":{"trusted":true},"cell_type":"code","source":"def color_above_threshold_green(val):\n    \"\"\"\n    Colors any cell above a threshold green.\n    \"\"\"\n    \n    if np.abs(val) > 0.65:\n        color = 'green'\n    else:\n        color = 'black'\n        \n    return 'color: %s' % color","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gene_cols = [col for col in train_X if col.startswith('g-')]\ngene_train_df = train_X[gene_cols]\n\ncell_cols = [col for col in train_X if col.startswith('c-')]\ncell_train_df = train_X[cell_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nif SHOW_CORR and DO_EDA:\n    corr_threshold = 0.75\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_CORR and DO_EDA:\n    gene_corr = gene_train_df.corr()    \n    gene_corr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_CORR and DO_EDA:\n    gene_has_corr = gene_corr[(gene_corr > corr_threshold) | (gene_corr < -corr_threshold)]\n\n    gene_has_corr.dropna(axis = 0, thresh = 2, inplace = True)\n    gene_has_corr.dropna(axis = 1, thresh = 2, inplace = True)\n    \n    gene_has_corr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_CORR and DO_EDA:\n    mask = np.zeros_like(gene_has_corr)\n    mask[np.triu_indices_from(mask)] = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_CORR and DO_EDA:\n    ax = sns.heatmap(gene_has_corr, cmap = 'vlag', linewidths=4, mask = mask)\n    ax.set(title = 'Genes with High Linear Correlation > 0.75')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_CORR and DO_EDA:\n    fig = px.imshow(gene_has_corr, template = 'ggplot2', \n                    title = 'Interactive heatmap of linearly correlated genes',\n                    width=900, height=600)\n    fig.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"------------------------------------------------------------------------------------------------\n\n# Basic Walkthrough - BELOW THIS POINT - IN PROGRESS - #\n\nThanks for reading my walkthrough - if you like it, please upvote as it is a good habit that inspires our community to continue publishing its work publically.\n\n------------------------------------------------------------------------------------------------\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    # Use 3 examples to illustrate what this graph means\n    # With annotations.\n\n    ax = sns.distplot(train_y.describe().T['mean'], kde = False)\n    ax.set(title = \"Density of Positive Classifications Across Ligand Bindings\",\n          xlabel = \"Mean value of each ligand in y_train\",\n          ylabel = \"Number of ligands with that mean\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    ax = sns.distplot(train_y.describe().T['std'], kde = False)\n    ax.set(title = \"Density of Standard Deviations Across Ligand Bindings\",\n          xlabel = \"Std.Dev of each ligand in y_train\",\n          ylabel = \"Number of ligands with that Std Dev\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    # As mean increases (the number of positives), the standard deviation also increases.\n    # This makes sense, but can the shape tell us anything.\n\n    ax = sns.scatterplot(train_y.describe().T['mean'], train_y.describe().T['std'])\n\n    ax.set(title = \"Mean vs. Std Dev of y_train\",\n          xlabel = \"Mean Value\",\n          ylabel = \"Std Dev\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full = train_X.merge(train_y, left_index = True, right_index = True)\ntrain_full.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_CORR and DO_EDA:\n    full_corr = train_full.corr()\n    full_corr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sub Function \n\ndef get_strong_correlations(corr_matrix: pd.DataFrame,\n                            corr_threshold : float = 0.70):\n    \n    # Utility function for other functions.\n    \n    strong_corr = corr_matrix[(corr_matrix > corr_threshold) | (corr_matrix < -corr_threshold)]\n    \n    strong_corr.dropna(axis = 0, thresh = 2, inplace = True)\n    strong_corr.dropna(axis = 1, thresh = 2, inplace = True)\n\n    return strong_corr\n\ndef show_strong_correlations(corr_matrix: pd.DataFrame,\n                             corr_threshold : float = 0.70,\n                             show_corr : bool = True,\n                             interactive : bool = True) -> pd.DataFrame:\n    \n    strong_corr = get_strong_correlations(corr_matrix, corr_threshold)\n    print(\"Found\" , strong_corr.shape[0], \"Features with strong Correlations\")\n    \n    mask = np.zeros_like(strong_corr)\n    mask[np.triu_indices_from(mask)] = True\n\n    if show_corr:\n        \n        if interactive:\n            fig = px.imshow(strong_corr, template = 'ggplot2', \n                    title = 'Heatmap with High Correlations',\n                    width=900, height=600)\n            fig.show()\n            \n        else:\n            ax = sns.heatmap(strong_corr, mask = mask)\n\n            ax.set(title = 'Heatmap with Correlations')\n\n            # plt.show()\n        \n    return strong_corr\n\ndef get_dict_of_correlated_features(corr_matrix: pd.DataFrame,\n                                    corr_threshold : float = 0.70) -> dict:\n    \n    \"\"\"\n    Returns a dictionary of each feature and its associated correlated features\n    ranked in order of most correlated to least correlated along with their\n    correlation values.\n    \"\"\"\n    \n    strong_corr = get_strong_correlations(corr_matrix, corr_threshold)\n\n    print(\"Found\" , strong_corr.shape[0], \"Features with strong Correlations\")\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_CORR and DO_EDA:\n    show_strong_correlations(full_corr, corr_threshold = 0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# spearman_corr, pval = spearmanr(train_full)\n# show_strong_correlations(pd.DataFrame(spearman_corr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_CORR and DO_EDA:\n    sns.distplot(full_corr.vitamin_b)\n    sns.distplot(full_corr.kit_inhibitor)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Network Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"DO_NETWORK_ANALYSIS = False\n\nif DO_NETWORK_ANALYSIS:\n    G = nx.from_pandas_adjacency(gene_has_corr)\n\n    #positions=nx.circular_layout(G)\n\n    # nx.draw_networkx_nodes(G,positions,node_color='#DA70D6',\n    #                           node_size=500,alpha=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use Pandas Styling\n# s = gene_corr.style.applymap(color_above_threshold_green)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotter Helper Functions**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    def disp_boxplot(data, title, xlabel, ylabel):\n        sns.set_style('whitegrid')\n        sns.set_context('poster')\n        palette = sns.color_palette(\"mako_r\", 6)\n\n        ax = sns.boxplot(data=data, palette = palette)\n\n        ax.set(title = title,\n              xlabel = xlabel,\n              ylabel = ylabel)\n\n        try:\n            ax.axhline(y = data.mean().mean(), color = 'b', label = 'Mean of all datapoints', linestyle = '--', linewidth = 1.5)\n            ax.ahline(y = data.median().median(), color = 'g', label = 'Median of all datapoints', linestyle = '--', linewidth = 1.5)\n        except:\n            pass\n\n        ax.set_xticklabels(ax.get_xticklabels(), rotation = 45)\n\n        plt.legend()\n        plt.show()\n\n    print('Plotting Helper Functions:')\n    print(\"disp_boxplot() - function will display a nicely formatted box plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create Statistical Dataframe Summaries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Create a helper function\n# Graph a few notable genes and cell lines.\n# Anything stand out?\n\nstatistical_df = pd.DataFrame()\nstatistical_df['median'] = train_X.median(axis = 0)\nstatistical_df['mean'] = train_X.mean(axis = 0)\nstatistical_df['std_dev'] = train_X.std(axis = 0)\nstatistical_df['min'] = train_X.min(axis = 0)\nstatistical_df['max'] = train_X.max(axis = 0)\n\ngene_cols = [col for col in statistical_df.T if col.startswith('g-')]\ngene_train_stats_df = statistical_df.T[gene_cols].T\n\ncell_cols = [col for col in statistical_df.T if col.startswith('c-')]\ncell_train_stats_df = statistical_df.T[cell_cols].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# statistical_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cell_train_stats_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    # Kurtosis / Skew\n    # Mean vs. Median\n    # Make ECDF Comparison next To it too.\n\n    sns.set_context('poster')\n\n    ax = sns.distplot(cell_train_stats_df['mean'], label = 'Mean', kde = False)\n    ax2 = sns.distplot(cell_train_stats_df['median'], label = 'Median', kde = False)\n\n    ax.set(title = \"Cell Lines: Aggregate Mean vs. Median Distribution\",\n          xlabel = \"Cell Viability\",\n          ylabel = \"Num Samples\")\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    # Kurtosis / Skew\n    # Mean vs. Median\n\n    sns.set_context('poster')\n\n    ax = sns.distplot(gene_train_stats_df['mean'], label = 'Mean', kde = False)\n    ax2 = sns.distplot(gene_train_stats_df['median'], label = 'Median', kde = False)\n\n    ax.set(title = \"Gene Expression: Aggregate Mean vs. Median Distribution\",\n          xlabel = \"Upregulation & Downregulation\",\n          ylabel = \"Num Samples\")\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    # Kurtosis / Skew\n    # Mean vs. Median\n\n    sns.set_context('poster')\n\n    ax = sns.distplot(cell_train_stats_df['std_dev'], label = 'Cell Std Dev', kde = False)\n    ax2 = sns.distplot(gene_train_stats_df['std_dev'], label = 'Gene Std Dev', kde = False)\n\n    ax.set(title = \"Gene Expression: Aggregate Standard Deviations\",\n          xlabel = \"Standard Deviation\",\n          ylabel = \"Num Samples with this Std Dev\")\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    # Kurtosis / Skew\n    # Mean vs. Median\n\n    sns.set_context('poster')\n\n    ax = sns.distplot(cell_train_stats_df['min'], label = 'Cell Min', kde = False)\n    ax2 = sns.distplot(gene_train_stats_df['min'], label = 'Gene Min', kde = False)\n\n    ax.set(title = \"Cell and Gene Minimums\",\n          xlabel = \"Minimum Value\",\n          ylabel = \"How many Samples\")\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    # Kurtosis / Skew\n    # Mean vs. Median\n\n    sns.set_context('poster')\n\n    ax = sns.distplot(cell_train_stats_df['max'], label = 'Cell Max', kde = False)\n    ax2 = sns.distplot(gene_train_stats_df['max'], label = 'Gene Max', kde = False)\n\n    ax.set(title = \"Cell and Gene Maximums\",\n          xlabel = \"Maximum Value\",\n          ylabel = \"How many Samples\")\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    cat_sum = train_X.groupby(['cp_type']).sum().T.reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_EDA:\n    train_unscored.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_for_models(df : pd.DataFrame) -> pd.DataFrame:\n    # Categorical Encoding\n    # Target Encoding\n    \n    pass\n\ndef remove_non_numerical(df: pd.DataFrame) -> pd.DataFrame:\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Encode Categorical Variables**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = BinaryEncoder(cols=['cp_type', 'cp_dose', 'cp_time'], return_df = True)\ntrain_X_encoded = encoder.fit_transform(train_X)\ntest_X_encoded = encoder.fit_transform(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dimensionality Reduction ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"DO_DIM_REDUCE = True\n\nif DO_DIM_REDUCE:\n    from sklearn.decomposition import PCA, SparsePCA, KernelPCA\n    \n    # Put in preprocessing\n    min_max_X_train = MinMaxScaler().fit_transform(train_X_encoded)\n    min_max_X_test = MinMaxScaler().fit_transform(test_X_encoded)\n    \n    print(\"Linear PCA explained variance:\")\n    lin_pca_X_train = PCA(n_components = 25).fit(min_max_X_train)\n    print(lin_pca_X_train.explained_variance_ratio_)\n    print(\"Total Variance:\", sum(lin_pca_X_train.explained_variance_ratio_))\n    \n    # FIX this inefficiency\n    lin_pca_X_train = PCA(n_components = 25).fit_transform(min_max_X_train)\n    print(\"\\n\")\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use Subsample ##\nSince there are so many outputs to predict in this model, it may make sense to prototype different models on a subset of the data.  This would allow for faster prototyping while still seeing if some models can work very well on limited portions of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"USE_SUBSAMPLE_ONLY = True\nn_subsample = 50  # Just predict n ligands for faster analysis and prototyping.\n\nif USE_SUBSAMPLE_ONLY:\n    \n    # Option to use same subset...\n    \n    targets_to_use = random.sample(range(1, len(train_y.columns)), n_subsample)\n    train_X_subsample = train_X_encoded\n    train_y_subsample = train_y.iloc[:, targets_to_use]\n    \n    print(\"Using subsample of targets for faster exploration\")\n    print(\"Using the following target columns \\n\")\n    print(list(train_y_subsample.columns))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validation Splits ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ONE_VALIDATION SPLIT\n\nfrom sklearn.model_selection import train_test_split\n\n# SET What you want to split here.\nX_to_split = train_X_encoded\ny_to_split = train_y_subsample\n\ntry:\n    X_train_v, X_test_v, y_train_v, y_test_v = train_test_split(X_to_split, \n                                                                y_to_split, \n                                                                test_size=0.33, \n                                                                random_state=42, \n                                                                stratify = train_y_subsample)\nexcept:   # Stratify doesn't work on all classes.\n    X_train_v, X_test_v, y_train_v, y_test_v = train_test_split(X_to_split, \n                                                                y_to_split, \n                                                                test_size=0.33, \n                                                                random_state=42)\n\nprint(\"Validation Data Train Set - X_train_v: \", X_train_v.shape)\nprint(\"Validation Data Test Set - X_test_v: \", X_test_v.shape)\n\nprint(\"Validation Target Train Set - y_train_v: \", y_train_v.shape)\nprint(\"Validation Target Test Set - y_test_v: \", y_test_v.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show Counts of targets in validation sets.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Anomaly Detection ##\n\nBecause the classes are so sparse, it might make sense to try to understand if the data signatures of the 0's and 1's are different. Can anomaly detection detect when an incoming sample will have a MoA?\n"},{"metadata":{},"cell_type":"markdown","source":"## Modeling ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"DO_BASELINE = False\nLOAD_CLASSIFIER = False\nDO_CLASSIFIER = True\nDO_NN = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Helper Functions ###"},{"metadata":{},"cell_type":"markdown","source":"**Create Submission File**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create empty submission file\noutputs_df = submission_df.copy()\noutputs_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Multi Output Target Helper Function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import NewType # Or Generic?\nClassifier = NewType('Classifier', str)  # Make this work for any classifier.\n\ndef use_voting_classifier(X_train : pd.DataFrame, \n                         y_train : pd.DataFrame,\n                         X_test: pd.DataFrame,\n                         clfs ) -> pd.DataFrame:\n    \n    \n    voting_clf = VotingClassifier(clfs, voting = 'soft')\n    multi_voting_clf = MultiOutputClassifier(voting_clf).fit(X_train, y_train)\n    \n    # Predict Probas...\n    # return probas\n    \n\ndef classify_with_multiclassifier(X_train : pd.DataFrame, \n                         y_train : pd.DataFrame,\n                         X_test: pd.DataFrame,\n                         clf : Classifier,\n                         save_classifier : bool = True) -> np.array:\n    \n    \"\"\"Uses SKLearn MultiOutput Classifier instead of a loop\"\"\"\n    \n    multi_clf = MultiOutputClassifier(clf).fit(X_train, y_train)\n    \n    preds = multi_clf.predict_proba(X_test)\n    \n    if save_classifier:\n        dump(multi_clf, 'model.joblib')\n    \n    return preds\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Baseline Models ###"},{"metadata":{"trusted":true},"cell_type":"code","source":"LOAD_CLASSIFIER = False\n\nif LOAD_CLASSIFIER:\n    extra_preds_path = \"extra_preds.csv\"\n    extra_preds = pd.read_csv(extra_preds_path)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Run Classifier Here**"},{"metadata":{"trusted":true},"cell_type":"code","source":"DO_CLASSIFIER = True\n\nif DO_CLASSIFIER:\n    \n    from joblib import dump, load   # For Saving Model\n    from sklearn.svm import SVC\n    \n    \n    # Create Classifiers Here\n    \n    xgb_clf = XGBClassifier(n_jobs = -1, max_depth = 5)\n    lgb_clf = LGBMClassifier()\n    rf_clf = RandomForestClassifier(n_jobs = -1)\n    extra_clf = ExtraTreesClassifier(n_jobs = -1, max_depth = 7, min_samples_split = 3, n_estimators = 500,\n                                    class_weight = 'balanced')\n    sk_gb_reg = GradientBoostingRegressor()\n    \n    svc_clf = SVC(class_weight='balanced')\n    svc_linear_clf = SVC(class_weight='balanced', kernel = 'linear')\n    \n    svclinear_proba_clf = SVC(class_weight='balanced', kernel = 'linear', probability=True)\n    svc_proba_clf = SVC(class_weight='balanced', probability=True)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set what train and test sets you want to use.\nclassify_X_train = X_train_v\nclassify_X_test = X_test_v\nclassify_y_train = y_train_v\nclassify_y_test = y_test_v\n\nif DO_CLASSIFIER:\n    # CHOOSE CLASSIFIER AND METHOD HERE.\n    use_this_classifier = extra_clf\n    used_classifier_name = 'extra_clf'\n    \n    print(\"Classifier set to: \", used_classifier_name)\n    print(use_this_classifier)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BASELINE\n# all_preds_gb = classify_prob_all_targets(train_X_encoded, train_y, test_X_encoded, outputs_df, use_this_classifier)\n# preds = classify_with_multiclassifier(classify_X_train, classify_y_train, classify_X_test, use_this_classifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_preds_to_dataframe(preds: list,\n                               clf_name : str,\n                              save_array : bool = True,\n                              save_df: bool = True,\n                              verbose : int = 1) -> pd.DataFrame:\n    \n    \"\"\"\n    Sometimes a multidimensional list is created with MultiOutputClassifier\n    This function will convert that output to just the positive predictions\n    and return a dataframe\n    \n    save_array: saves the array as an np_y format\n    save_df: saves the dataframe as a csv.\"\"\"\n    \n    preds_arr = np.array(preds)\n    pos_clf_preds = preds_arr[:,:,1]   # Preserve only positive binary prediction.\n    pos_clf_preds = pos_clf_preds.T    # The output is the transpose of the shape we want\n    \n    if save_array:\n        np.save(clf_name, pos_clf_preds)\n        \n        if verbose:\n            print(\"Numpy Array saved: \" + clf_name + \".npy\")\n    \n    preds_df = pd.DataFrame(pos_clf_preds)\n    \n    if save_df:\n        csv_name = clf_name + \".csv\"\n        preds_df.to_csv(csv_name, index = False)\n        \n        if verbose:\n            print(\"CSV Saved as \" + csv_name)\n    \n    if verbose:\n        print(\"head of new dataframe: \")\n        print(preds_df.head())\n        print(preds_df.shape)\n    \n    return preds_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BASELINE\n# if DO_CLASSIFIER:\n#    preds_df = convert_preds_to_dataframe(preds, clf_name = used_classifier_name, verbose = 1)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validation Set Analysis ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_for_validation():\n    pass\n\ndef analyze_validation(y_true, y_pred):\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_clfs(true_df, preds_df):\n    from sklearn.metrics import accuracy_score\n\n    wrongs = true_df.compare(preds_df)\n\n    n_wrongs = len(wrongs.notna()) # Do I divide this by 2 because it has 'self' and 'other'?  FIX\n    n_samples = true_df.shape[0]\n    n_correct = n_samples - n_wrongs\n\n    print(\"Total Targets: \", n_samples)\n    print(\"Number Correct: \", n_correct)\n    print(\"Number Wrong: \", n_wrongs)\n    print(\"Accuracy: \", round(100 * (n_correct / n_samples), 2), \"%\")\n    print(\"Sklearn Acc: \", round(100 * (accuracy_score(true_df, preds_df)), 2), \"%\")\n\n    print(\"Log Loss: \", round(log_loss(true_df, preds_df), 2))\n\ndef analyze_clf_results():\n    pass\n\ndef multiclass_stratified_cv(X : pd.DataFrame, \n                             y : pd.DataFrame, \n                             clf : Callable[[pd.DataFrame, pd.DataFrame], None]) -> None:\n    \n    skf = IterativeStratification(n_splits=5)\n    skf.get_n_splits(X, y)\n\n    for train_index, test_index in skf.split(X, y):\n        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n        y_train, y_test = y.iloc[train_index,:], y.iloc[test_index,:]\n\n        # Fit Function\n        clf.fit(X_train, y_train)\n        \n        # Create Predictions\n        y_preds_arr = clf.predict(X_test)\n        \n        # Convert preds to a dataframe.\n        y_preds = pd.DataFrame(y_preds_arr, columns = y_test.columns, index = y_test.index)\n        \n        # Score Function\n        score_clfs(y_test, y_preds)\n        \n        # Analyze Function\n        # analyze_clf_results(y_test, y_preds)\n        \n        print(\"\\n\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DO_CV = False\n\nif DO_CV:\n    # CV_VALIDATION_SPLIT\n    from sklearn.model_selection import StratifiedKFold\n    from skmultilearn.model_selection import IterativeStratification \n    \n    # Use whole training set for cross validation\n    X = train_X_encoded\n    y = train_y\n    \n    multiclass_stratified_cv(X, y, use_this_classifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For validation, we actually predict the classes\nprint(\"Fitting\", use_this_classifier, \"to classes for validation analysis.\")\n\npreds_arr = use_this_classifier.fit(X_train_v, y_train_v).predict(X_test_v)\n\npreds = pd.DataFrame(preds_arr, columns = y_test_v.columns, index = y_test_v.index)\npreds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ax = sns.distplot(y_test_v, kde = False)\n#ax.set(title = \"Class Balance of Validation Set\")\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multi Label Confusion Matrix ##\n\nIn this section, we are doing our post prediction analysis on the validation set to see what samples and features the classifier had the hardest time with.   \n\nIn the future, we will do this for each classifier and ensemble a set of local models models so that each classifier will predict those samples it is best at.  If it performs reasonably well, it may be ensembled with other models later on.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"show_confusion_matrix = False\n\nif show_confusion_matrix:\n    from sklearn.metrics import multilabel_confusion_matrix\n\n    conf_mat = multilabel_confusion_matrix(y_test_v, preds)\n    conf_mat.shape\n\n    for i in range(y_test_v.shape[1]):\n        name = y_test_v.columns[i]\n\n        display(name)\n        conf_mat_small = pd.DataFrame(conf_mat[i], index = [\"True 0\", \"True 1\"], columns = [\"Predicted 0\", \"Predicted 1\"])\n\n        display(conf_mat_small)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do post_model_analysis\n# Def ___\n\nfrom sklearn.metrics import accuracy_score\n\nwrongs = y_test_v.compare(preds)\n\nn_wrongs = len(wrongs.notna()) # Do I divide this by 2 because it has 'self' and 'other'?  FIX\nn_samples = y_test_v.shape[0]\nn_correct = n_samples - n_wrongs\n\nprint(\"Total Targets: \", n_samples)\nprint(\"Number Correct: \", n_correct)\nprint(\"Number Wrong: \", n_wrongs)\nprint(\"Accuracy: \", round(100 * (n_correct / n_samples), 2), \"%\")\nprint(\"Sklearn Acc: \", round(100 * (accuracy_score(y_test_v, preds)), 2), \"%\")\n\nprint(\"Log Loss: \", round(log_loss(y_test_v, preds), 2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do post_model_analysis\n\nsns.heatmap(wrongs, cbar = False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrongs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrong_sums = pd.DataFrame(wrongs.sum(axis = 0))\nwrong_sums","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wrong_sums.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_confusion_matrix():\n    pass\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Full Set Training #"},{"metadata":{},"cell_type":"markdown","source":"**Neural Network Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute Class Weights\n# def...\n\nsum_classes = np.array(list((train_y.sum())))\nn_samples = 23814\nweights = n_samples / sum_classes\n\nclass_weights_dict = dict(enumerate(weights))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DO_NN = True\n\n# Imports\nif DO_NN:\n    from keras import Input, layers\n    from keras.models import Model\n    from keras.layers import Dense, BatchNormalization, Dropout, Embedding\n    from tensorflow_addons.layers import WeightNormalization\n    from keras.regularizers import l2\n    \n# Preprocess Data\n# Set the X and y\nif DO_NN:\n    \n    \n    std_scaler = StandardScaler()\n    mm_scaler = MinMaxScaler()\n    \n    # Use this scaler\n    scaler = std_scaler\n    \n    X_nn = scaler.fit_transform(train_X_encoded)\n    y_nn = train_y\n    X_test_nn = scaler.fit_transform(test_X_encoded)\n    \n\n# Set NN Parameters\nif DO_NN:\n\n    EPOCHS = 100\n    BATCH_SIZE = 128\n    INPUT_SHAPE = X_nn.shape[1]\n    OUTPUT_SHAPE = y_nn.shape[1]\n    \n    NUM_LAYERS = 5  # NUM_HIDDEN - 1  # Rename NUM_HIDDEN\n    SIZE_LAYER = 1024 \n    STEP_DOWN = 128\n    DROPOUT_AMOUNT = 0.5\n\n# Create Model\n\nif DO_NN:\n    \n    input_tensor = Input(shape = (INPUT_SHAPE, ))\n    \n    layer = Dense(SIZE_LAYER, activation = 'selu', kernel_initializer = 'he_normal')(input_tensor)\n    layer = BatchNormalization(input_shape = (INPUT_SHAPE, ))(layer)\n    layer = Dropout(0.2)(layer)\n    \n    for i in range(NUM_LAYERS - 1): \n        layer = WeightNormalization(Dense(SIZE_LAYER, activation = 'selu', \n                                          kernel_initializer = 'he_normal',\n                                          use_bias = False))(layer)\n        layer = BatchNormalization()(layer)\n        #layer = Dense(SIZE_LAYER, activation = 'relu',\n        #              kernel_regularizer = l2(0.05))(layer)\n        layer = Dropout(DROPOUT_AMOUNT)(layer)\n\n        SIZE_LAYER -= STEP_DOWN\n\n    \n    output_tensor = Dense(OUTPUT_SHAPE, activation = 'sigmoid')(layer)\n    \n    model = Model(input_tensor, output_tensor)\n    model.summary()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_NN:\n    from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n    from keras.optimizers import Adam, Nadam, SGD\n    \n    # Optimizer is stochastic gradient descent with nesterov acceleration and momentum.\n    sgd_opt = SGD(lr = 0.01, momentum = 0.9, nesterov = True, decay = 1e-4)\n    \n    # Callbacks\n    reduce_lr = ReduceLROnPlateau(patience=2, mode='min', monitor='val_loss', factor = 0.5)\n    early_stop = EarlyStopping(patience = 10, monitor = 'val_loss')\n    \n    model.compile(optimizer = sgd_opt,\n                 loss = 'binary_crossentropy',\n                 metrics = ['acc'])\n    \n    # This model pre-loads the class-weights.  Then the model continues fitting\n    # without the class weights\n    \n    model.fit(X_nn, \n              y_nn,\n              epochs = 50,\n              batch_size = BATCH_SIZE,\n              class_weight = class_weights_dict,\n              validation_split = 0.3,\n              callbacks = [reduce_lr, early_stop])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running again without class_weight after partial training.\n# Real effect or leakage into validation set?\n\nif DO_NN:\n    # Optimizer is stochastic gradient descent with nesterov acceleration and momentum.\n    sgd_opt = SGD(lr = 0.01, momentum = 0.9, nesterov = True, decay = 1e-4)\n    \n    # Callbacks\n    reduce_lr = ReduceLROnPlateau(patience=2, mode='min', monitor='val_loss', factor = 0.5)\n    early_stop = EarlyStopping(patience = 10, monitor = 'val_loss')\n    \n    model.compile(optimizer = sgd_opt,\n                 loss = 'binary_crossentropy',\n                 metrics = ['acc'])\n    \n    model.fit(X_nn, \n              y_nn,\n              epochs = 50,\n              batch_size = BATCH_SIZE,\n              # class_weight = class_weights_dict,\n              validation_split = 0.3,\n              callbacks = [reduce_lr, early_stop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_NN:\n    model.save('keras_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_NN:\n    preds_nn = model.predict(X_test_nn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_NN:\n    # THIS IS NOW AT END.  \n    \n    preds_nn_df = pd.DataFrame(preds_nn)\n    print(preds_nn_df.shape)\n\n    new_submission = submission_df.copy()  # This is a duplicate\n    print(new_submission.shape)\n    print(preds_nn_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DO_NN:\n    ax = sns.distplot(preds_nn_df, label = 'NN Preds', kde = False)\n    ax.set(title = \"Predictions\", \n          xlabel = \"Prediction Probability\",\n          ylabel = \"Number of samples\")\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission FIle ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"SUBMIT_FILE = True\nSUBMIT_FROM_KERNEL = True\n\nif SUBMIT_FILE and SUBMIT_FROM_KERNEL:\n    # Set module parameters here.\n    \n    preds_df = preds_nn_df\n    submission_df = submission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_to_submission(pred_csv: pd.DataFrame, \n                     submission_df: pd.DataFrame,\n                     verbose : bool = True,\n                     export_df : bool = True) -> pd.DataFrame:\n    \"\"\"\n    \n    This function takes a df of positive prediction\n    outputs and merges it with the submission dataframe\n    so it is in the correct format for Kaggle's submission\"\"\"\n\n    new_submission = submission_df.copy()\n    \n    column_labels = new_submission.drop(columns = 'sig_id')\n    column_labels = column_labels.columns\n    \n    if verbose:\n        print(\"Submission Shape: \")\n        print(new_submission.shape)\n        print(\"Preds Shape: \")\n        print(pred_csv.shape)\n    \n    pred_csv.columns = column_labels\n    \n    merged_df = new_submission.merge(pred_csv, how = 'right')\n    merged_df['sig_id'] = new_submission['sig_id']\n    \n    if verbose:\n        print(\"Merged Shape: \")\n        print(merged_df.shape)\n        print(\"Preview of Merged DF: \")\n        print(merged_df.head(1))\n    \n    if export_df:\n        merged_df.to_csv('submission.csv', index=False)\n        \n        if verbose:\n            print(\"Submission file created: submission.csv\")\n    return merged_df\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if SUBMIT_FILE:\n    final_submission_csv = df_to_submission(preds_df, submission_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}