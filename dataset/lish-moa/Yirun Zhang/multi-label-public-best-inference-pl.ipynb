{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/pytorch16gpu/torch-1.6.0cu101-cp37-cp37m-linux_x86_64.whl --quiet","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-09-06T18:32:08.877939Z","iopub.status.busy":"2020-09-06T18:32:08.877228Z","iopub.status.idle":"2020-09-06T18:32:14.972831Z","shell.execute_reply":"2020-09-06T18:32:14.972235Z"},"papermill":{"duration":6.107558,"end_time":"2020-09-06T18:32:14.972944","exception":false,"start_time":"2020-09-06T18:32:08.865386","status":"completed"},"tags":[],"id":"aI8-T6rjZD5_","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nsys.path.insert(0, \"../input/tabnetdevelop/tabnet-develop\")\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport os\nimport gc\nimport math\nimport random\nimport datetime\nimport numpy as np\nimport pandas as pd\nfrom joblib import dump, load\nfrom numba import njit\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nimport tensorflow_addons as tfa\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import log_loss\nfrom scipy.optimize import minimize\nfrom tqdm.notebook import tqdm\nfrom time import time\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import roc_auc_score\n\nN_STARTS = 3\nN_SPLITS = 7\nCALCULATE_OOF = False\nCALCULATE_OOF_PL = True\nFINETUNE = True\nPOST_PROCESS = True","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def seed_everything(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        \nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"id":"EHkVsCptoNfT"},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-09-06T18:32:14.997376Z","iopub.status.busy":"2020-09-06T18:32:14.996643Z","iopub.status.idle":"2020-09-06T18:32:20.482365Z","shell.execute_reply":"2020-09-06T18:32:20.483409Z"},"papermill":{"duration":5.505878,"end_time":"2020-09-06T18:32:20.48361","exception":false,"start_time":"2020-09-06T18:32:14.977732","status":"completed"},"tags":[],"id":"5DxCXDYIZD6C","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\nss = pd.read_csv('../input/lish-moa/sample_submission.csv')\n\ncols = [c for c in ss.columns.values if c != 'sig_id']\nGENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def preprocess(df):\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    del df['sig_id']\n    return df\n\ndef log_loss_metric(y_true, y_pred):\n    y_pred_clip = np.clip(y_pred, 1e-15, 1 - 1e-15)\n    return - np.mean(y_true * np.log(y_pred_clip) + (1 - y_true) * np.log(1 - y_pred_clip))\n\ntrain = preprocess(train_features)\ntest = preprocess(test_features)\n\ndel train_targets['sig_id']\ndel train_targets_nonscored['sig_id']\n\n# qt = QuantileTransformer(output_distribution = 'normal', random_state = 42)\n# qt.fit(pd.concat([pd.DataFrame(train[GENES+CELLS]), pd.DataFrame(test[GENES+CELLS])]))\nqt = load('../input/moa-preprocess/qt')\ntrain[GENES+CELLS] = qt.transform(train[GENES+CELLS])\ntest[GENES+CELLS] = qt.transform(test[GENES+CELLS])\n\n# GENES\nn_comp_genes = 600  #<--Update\n\ndata = pd.concat([pd.DataFrame(train[GENES]), pd.DataFrame(test[GENES])])\n# pca_genes = PCA(n_components = n_comp_genes, random_state = 42)\n# data2 = pca_genes.fit_transform(data[GENES])\npca_genes = load('../input/moa-preprocess/pca_genes')\ndata2 = pca_genes.transform(data[GENES])\ntrain2 = data2[:train.shape[0]]; test2 = data2[-test.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns = [f'pca_G-{i}' for i in range(n_comp_genes)])\ntest2 = pd.DataFrame(test2, columns = [f'pca_G-{i}' for i in range(n_comp_genes)])\n\ntrain = pd.concat((train, train2), axis = 1)\ntest = pd.concat((test, test2), axis = 1)\n\n#CELLS\nn_comp_cells = 50  #<--Update\n\ndata = pd.concat([pd.DataFrame(train[CELLS]), pd.DataFrame(test[CELLS])])\n# pca_cells = PCA(n_components = n_comp_cells, random_state = 42)\n# data2 = pca_cells.fit_transform(data[CELLS])\npca_cells = load('../input/moa-preprocess/pca_cells')\ndata2 = pca_cells.transform(data[CELLS])\ntrain2 = data2[:train.shape[0]]; test2 = data2[-test.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns = [f'pca_C-{i}' for i in range(n_comp_cells)])\ntest2 = pd.DataFrame(test2, columns = [f'pca_C-{i}' for i in range(n_comp_cells)])\n\ntrain = pd.concat((train, train2), axis = 1)\ntest = pd.concat((test, test2), axis = 1)\n\ndata = train.append(test)\n# var_thresh = VarianceThreshold(0.8)  #<-- Update\n# data_transformed = var_thresh.fit_transform(data.iloc[:, 3:])\nvar_thresh = load('../input/moa-preprocess/var_thresh')\ndata_transformed = var_thresh.transform(data.iloc[:, 3:])\n\ntrain_transformed = data_transformed[ : train.shape[0]]\ntest_transformed = data_transformed[-test.shape[0] : ]\n\ntrain = pd.DataFrame(train[['cp_type','cp_time','cp_dose']].values.reshape(-1, 3),\\\n                     columns=['cp_type','cp_time','cp_dose'])\n\ntrain = pd.concat([train, pd.DataFrame(train_transformed)], axis=1)\n\ntest = pd.DataFrame(test[['cp_type','cp_time','cp_dose']].values.reshape(-1, 3),\\\n                    columns=['cp_type','cp_time','cp_dose'])\n\ntest = pd.concat([test, pd.DataFrame(test_transformed)], axis=1)\n\nprint(train.shape)\nprint(test.shape)\n\ntrain_targets = train_targets.loc[train['cp_type'] == 0].reset_index(drop = True)\ntrain_targets_nonscored = train_targets_nonscored.loc[train['cp_type'] == 0].reset_index(drop = True)\ntrain = train.loc[train['cp_type'] == 0].reset_index(drop = True)\n\nprint(train.shape)\n\ntop_feats = np.arange(1, train.shape[1])\nprint(top_feats)\n\ncat_tr, cat_test, numerical_tr, numerical_test = train.loc[:, train.columns[1:3]], test.loc[:, test.columns[1:3]], train.loc[:, train.columns[3:]].values, test.loc[:, test.columns[3:]].values\ncat_tr.loc[:, 'cp_time'] = cat_tr.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\ncat_test.loc[:, 'cp_time'] = cat_test.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\ncat_tr = cat_tr.values\ncat_test = cat_test.values\ntargets_tr = train_targets[cols].values.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def evals(model, X, y, verbose=True):\n    with torch.no_grad():\n        y_preds = model.predict(X)\n        y_preds = torch.clamp(y_preds, 0.0,1.0).detach().numpy()\n    score = log_loss_multi(y, y_preds)\n    #print(\"Logloss = \", score)\n    return y_preds, score\n\n\ndef inference_fn(model, X ,verbose=True):\n    with torch.no_grad():\n        y_preds = model.predict( X )\n        y_preds = torch.sigmoid(torch.as_tensor(y_preds)).numpy()\n    return y_preds\n\ndef log_loss_score(actual, predicted,  eps=1e-15):\n\n        \"\"\"\n        :param predicted:   The predicted probabilities as floats between 0-1\n        :param actual:      The binary labels. Either 0 or 1.\n        :param eps:         Log(0) is equal to infinity, so we need to offset our predicted values slightly by eps from 0 or 1\n        :return:            The logarithmic loss between between the predicted probability assigned to the possible outcomes for item i, and the actual outcome.\n        \"\"\"\n\n        \n        p1 = actual * np.log(predicted+eps)\n        p0 = (1-actual) * np.log(1-predicted+eps)\n        loss = p0 + p1\n\n        return -loss.mean()\ndef log_loss_multi(y_true, y_pred):\n    M = y_true.shape[1]\n    results = np.zeros(M)\n    for i in range(M):\n        results[i] = log_loss_score(y_true[:,i], y_pred[:,i])\n    return results.mean()\ndef check_targets(targets):\n    ### check if targets are all binary in training set\n    \n    for i in range(targets.shape[1]):\n        if len(np.unique(targets[:,i])) != 2:\n            return False\n    return True\ndef auc_multi(y_true, y_pred):\n    M = y_true.shape[1]\n    results = np.zeros(M)\n    for i in range(M):\n        try:\n            results[i] = roc_auc_score(y_true[:,i], y_pred[:,i])\n        except:\n            pass\n    return results.mean()\n\nimport torch\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\nclass SmoothBCEwLogits(_WeightedLoss):\n    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n\n    @staticmethod\n    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n        assert 0 <= smoothing < 1\n        with torch.no_grad():\n            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n        return targets\n\n    def forward(self, inputs, targets):\n        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n            self.smoothing)\n        loss = F.binary_cross_entropy_with_logits(inputs, targets, self.weight)\n\n        if  self.reduction == 'sum':\n            loss = loss.sum()\n        elif  self.reduction == 'mean':\n            loss = loss.mean()\n\n        return loss\n    \nsbcewlogits = SmoothBCEwLogits(smoothing = 0.0008)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TabNet"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"## TABNET\n\nimport torch\nimport numpy as np\nfrom scipy.sparse import csc_matrix\nimport time\nfrom abc import abstractmethod\nfrom pytorch_tabnet import tab_network\nfrom pytorch_tabnet.multiclass_utils import unique_labels\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, accuracy_score\nfrom torch.nn.utils import clip_grad_norm_\nfrom pytorch_tabnet.utils import (PredictDataset,\n                                  create_dataloaders,\n                                  create_explain_matrix)\nfrom sklearn.base import BaseEstimator\nfrom torch.utils.data import DataLoader\nfrom copy import deepcopy\nimport io\nimport json\nfrom pathlib import Path\nimport shutil\nimport zipfile\n\nclass TabModel(BaseEstimator):\n    def __init__(self, n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1,\n                 n_independent=2, n_shared=2, epsilon=1e-15,  momentum=0.02,\n                 lambda_sparse=1e-3, seed=0,\n                 clip_value=1, verbose=1,\n                 optimizer_fn=torch.optim.Adam,\n                 optimizer_params=dict(lr=2e-2),\n                 scheduler_params=None, scheduler_fn=None,\n                 mask_type=\"sparsemax\",\n                 input_dim=None, output_dim=None,\n                 device_name='auto'):\n        \"\"\" Class for TabNet model\n        Parameters\n        ----------\n            device_name: str\n                'cuda' if running on GPU, 'cpu' if not, 'auto' to autodetect\n        \"\"\"\n\n        self.n_d = n_d\n        self.n_a = n_a\n        self.n_steps = n_steps\n        self.gamma = gamma\n        self.cat_idxs = cat_idxs\n        self.cat_dims = cat_dims\n        self.cat_emb_dim = cat_emb_dim\n        self.n_independent = n_independent\n        self.n_shared = n_shared\n        self.epsilon = epsilon\n        self.momentum = momentum\n        self.lambda_sparse = lambda_sparse\n        self.clip_value = clip_value\n        self.verbose = verbose\n        self.optimizer_fn = optimizer_fn\n        self.optimizer_params = optimizer_params\n        self.device_name = device_name\n        self.scheduler_params = scheduler_params\n        self.scheduler_fn = scheduler_fn\n        self.mask_type = mask_type\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n\n        self.batch_size = 1024\n\n        self.seed = seed\n        torch.manual_seed(self.seed)\n        # Defining device\n        if device_name == 'auto':\n            if torch.cuda.is_available():\n                device_name = 'cuda'\n            else:\n                device_name = 'cpu'\n        self.device = torch.device(device_name)\n        print(f\"Device used : {self.device}\")\n\n    @abstractmethod\n    def construct_loaders(self, X_train, y_train, X_valid, y_valid,\n                          weights, batch_size, num_workers, drop_last):\n        \"\"\"\n        Returns\n        -------\n        train_dataloader, valid_dataloader : torch.DataLoader, torch.DataLoader\n            Training and validation dataloaders\n        -------\n        \"\"\"\n        raise NotImplementedError('users must define construct_loaders to use this base class')\n\n    def init_network(\n                     self,\n                     input_dim,\n                     output_dim,\n                     n_d,\n                     n_a,\n                     n_steps,\n                     gamma,\n                     cat_idxs,\n                     cat_dims,\n                     cat_emb_dim,\n                     n_independent,\n                     n_shared,\n                     epsilon,\n                     virtual_batch_size,\n                     momentum,\n                     device_name,\n                     mask_type,\n                     ):\n        self.network = tab_network.TabNet(\n            input_dim,\n            output_dim,\n            n_d=n_d,\n            n_a=n_a,\n            n_steps=n_steps,\n            gamma=gamma,\n            cat_idxs=cat_idxs,\n            cat_dims=cat_dims,\n            cat_emb_dim=cat_emb_dim,\n            n_independent=n_independent,\n            n_shared=n_shared,\n            epsilon=epsilon,\n            virtual_batch_size=virtual_batch_size,\n            momentum=momentum,\n            device_name=device_name,\n            mask_type=mask_type).to(self.device)\n\n        self.reducing_matrix = create_explain_matrix(\n            self.network.input_dim,\n            self.network.cat_emb_dim,\n            self.network.cat_idxs,\n            self.network.post_embed_dim)\n\n    def fit(self, X_train, y_train, X_valid=None, y_valid=None, loss_fn=None,\n            weights=0, max_epochs=100, patience=10, batch_size=1024,\n            virtual_batch_size=128, num_workers=0, drop_last=False, pretrain=False, optimizer_params=None):\n        \"\"\"Train a neural network stored in self.network\n        Using train_dataloader for training data and\n        valid_dataloader for validation.\n        Parameters\n        ----------\n            X_train: np.ndarray\n                Train set\n            y_train : np.array\n                Train targets\n            X_train: np.ndarray\n                Train set\n            y_train : np.array\n                Train targets\n            weights : bool or dictionnary\n                0 for no balancing\n                1 for automated balancing\n                dict for custom weights per class\n            max_epochs : int\n                Maximum number of epochs during training\n            patience : int\n                Number of consecutive non improving epoch before early stopping\n            batch_size : int\n                Training batch size\n            virtual_batch_size : int\n                Batch size for Ghost Batch Normalization (virtual_batch_size < batch_size)\n            num_workers : int\n                Number of workers used in torch.utils.data.DataLoader\n            drop_last : bool\n                Whether to drop last batch during training\n        \"\"\"\n        # update model name\n\n        self.update_fit_params(X_train, y_train, X_valid, y_valid, loss_fn,\n                               weights, max_epochs, patience, batch_size,\n                               virtual_batch_size, num_workers, drop_last)\n\n        train_dataloader, valid_dataloader = self.construct_loaders(X_train,\n                                                                    y_train,\n                                                                    X_valid,\n                                                                    y_valid,\n                                                                    self.updated_weights,\n                                                                    self.batch_size,\n                                                                    self.num_workers,\n                                                                    self.drop_last)\n        if not pretrain:\n            self.init_network(\n                input_dim=self.input_dim,\n                output_dim=self.output_dim,\n                n_d=self.n_d,\n                n_a=self.n_a,\n                n_steps=self.n_steps,\n                gamma=self.gamma,\n                cat_idxs=self.cat_idxs,\n                cat_dims=self.cat_dims,\n                cat_emb_dim=self.cat_emb_dim,\n                n_independent=self.n_independent,\n                n_shared=self.n_shared,\n                epsilon=self.epsilon,\n                virtual_batch_size=self.virtual_batch_size,\n                momentum=self.momentum,\n                device_name=self.device_name,\n                mask_type=self.mask_type\n            )\n            self.optimizer = self.optimizer_fn(self.network.parameters(),\n                                               **self.optimizer_params)\n        else:\n            self.optimizer = self.optimizer_fn(self.network.parameters(),\n                                               **optimizer_params)\n\n        if self.scheduler_fn:\n            self.scheduler = self.scheduler_fn(self.optimizer, **self.scheduler_params)\n        else:\n            self.scheduler = None\n\n        self.losses_train = []\n        self.losses_valid = []\n        self.learning_rates = []\n        self.metrics_train = []\n        self.metrics_valid = []\n\n        if self.verbose > 0:\n            print(\"Will train until validation stopping metric\",\n                  f\"hasn't improved in {self.patience} rounds.\")\n            msg_epoch = f'| EPOCH |  train  |   valid  | total time (s)'\n            print('---------------------------------------')\n            print(msg_epoch)\n\n        total_time = 0\n        while (self.epoch < self.max_epochs and\n               self.patience_counter < self.patience):\n            starting_time = time.time()\n            # updates learning rate history\n            self.learning_rates.append(self.optimizer.param_groups[-1][\"lr\"])\n\n            fit_metrics = self.fit_epoch(train_dataloader, valid_dataloader)\n\n            # leaving it here, may be used for callbacks later\n            self.losses_train.append(fit_metrics['train']['loss_avg'])\n            self.losses_valid.append(fit_metrics['valid']['total_loss'])\n            self.metrics_train.append(fit_metrics['train']['stopping_loss'])\n            self.metrics_valid.append(fit_metrics['valid']['stopping_loss'])\n\n            stopping_loss = fit_metrics['valid']['stopping_loss']\n            if stopping_loss < self.best_cost:\n                self.best_cost = stopping_loss\n                self.patience_counter = 0\n                # Saving model\n                self.best_network = deepcopy(self.network)\n                has_improved = True\n            else:\n                self.patience_counter += 1\n                has_improved=False\n            self.epoch += 1\n            total_time += time.time() - starting_time\n            if self.verbose > 0:\n                if self.epoch % self.verbose == 0:\n                    separator = \"|\"\n                    msg_epoch = f\"| {self.epoch:<5} | \"\n                    msg_epoch += f\" {fit_metrics['train']['stopping_loss']:.5f}\"\n                    msg_epoch += f' {separator:<2} '\n                    msg_epoch += f\" {fit_metrics['valid']['stopping_loss']:.5f}\"\n                    msg_epoch += f' {separator:<2} '\n                    msg_epoch += f\" {np.round(total_time, 1):<10}\"\n                    msg_epoch += f\" {has_improved}\"\n                    print(msg_epoch)\n\n        if self.verbose > 0:\n            if self.patience_counter == self.patience:\n                print(f\"Early stopping occured at epoch {self.epoch}\")\n            print(f\"Training done in {total_time:.3f} seconds.\")\n            print('---------------------------------------')\n\n        self.history = {\"train\": {\"loss\": self.losses_train,\n                                  \"metric\": self.metrics_train,\n                                  \"lr\": self.learning_rates},\n                        \"valid\": {\"loss\": self.losses_valid,\n                                  \"metric\": self.metrics_valid}}\n        # load best models post training\n        self.load_best_model()\n\n        # compute feature importance once the best model is defined\n        self._compute_feature_importances(train_dataloader)\n\n    def save_model(self, path):\n        \"\"\"\n        Saving model with two distinct files.\n        \"\"\"\n        saved_params = {}\n        for key, val in self.get_params().items():\n            if isinstance(val, type):\n                # Don't save torch specific params\n                continue\n            else:\n                saved_params[key] = val\n\n        # Create folder\n        Path(path).mkdir(parents=True, exist_ok=True)\n\n        # Save models params\n        with open(Path(path).joinpath(\"model_params.json\"), \"w\", encoding=\"utf8\") as f:\n            json.dump(saved_params, f)\n\n        # Save state_dict\n        torch.save(self.network.state_dict(), Path(path).joinpath(\"network.pt\"))\n        shutil.make_archive(path, 'zip', path)\n        shutil.rmtree(path)\n        print(f\"Successfully saved model at {path}.zip\")\n        return f\"{path}.zip\"\n\n    def load_model(self, filepath):\n\n        try:\n            try:\n                with zipfile.ZipFile(filepath) as z:\n                    with z.open(\"model_params.json\") as f:\n                        loaded_params = json.load(f)\n                    with z.open(\"network.pt\") as f:\n                        try:\n                            saved_state_dict = torch.load(f)\n                        except io.UnsupportedOperation:\n                            # In Python <3.7, the returned file object is not seekable (which at least\n                            # some versions of PyTorch require) - so we'll try buffering it in to a\n                            # BytesIO instead:\n                            saved_state_dict = torch.load(io.BytesIO(f.read()))\n                            \n            except:\n                with open(os.path.join(filepath, \"model_params.json\")) as f:\n                        loaded_params = json.load(f)\n\n                saved_state_dict = torch.load(os.path.join(filepath, \"network.pt\"), map_location=\"cpu\")\n \n        except KeyError:\n            raise KeyError(\"Your zip file is missing at least one component\")\n\n        #print(loaded_params)\n        if torch.cuda.is_available():\n            device_name = 'cuda'\n        else:\n            device_name = 'cpu'\n        loaded_params[\"device_name\"] = device_name\n        self.__init__(**loaded_params)\n\n        self.init_network(\n            input_dim=self.input_dim,\n            output_dim=self.output_dim,\n            n_d=self.n_d,\n            n_a=self.n_a,\n            n_steps=self.n_steps,\n            gamma=self.gamma,\n            cat_idxs=self.cat_idxs,\n            cat_dims=self.cat_dims,\n            cat_emb_dim=self.cat_emb_dim,\n            n_independent=self.n_independent,\n            n_shared=self.n_shared,\n            epsilon=self.epsilon,\n            virtual_batch_size=1024,\n            momentum=self.momentum,\n            device_name=self.device_name,\n            mask_type=self.mask_type\n        )\n        self.network.load_state_dict(saved_state_dict)\n        self.network.eval()\n        return\n\n    def fit_epoch(self, train_dataloader, valid_dataloader):\n        \"\"\"\n        Evaluates and updates network for one epoch.\n        Parameters\n        ----------\n            train_dataloader: a :class: `torch.utils.data.Dataloader`\n                DataLoader with train set\n            valid_dataloader: a :class: `torch.utils.data.Dataloader`\n                DataLoader with valid set\n        \"\"\"\n        train_metrics = self.train_epoch(train_dataloader)\n        valid_metrics = self.predict_epoch(valid_dataloader)\n\n        fit_metrics = {'train': train_metrics,\n                       'valid': valid_metrics}\n\n        return fit_metrics\n\n    @abstractmethod\n    def train_epoch(self, train_loader):\n        \"\"\"\n        Trains one epoch of the network in self.network\n        Parameters\n        ----------\n            train_loader: a :class: `torch.utils.data.Dataloader`\n                DataLoader with train set\n        \"\"\"\n        raise NotImplementedError('users must define train_epoch to use this base class')\n\n    @abstractmethod\n    def train_batch(self, data, targets):\n        \"\"\"\n        Trains one batch of data\n        Parameters\n        ----------\n            data: a :tensor: `torch.tensor`\n                Input data\n            target: a :tensor: `torch.tensor`\n                Target data\n        \"\"\"\n        raise NotImplementedError('users must define train_batch to use this base class')\n\n    @abstractmethod\n    def predict_epoch(self, loader):\n        \"\"\"\n        Validates one epoch of the network in self.network\n        Parameters\n        ----------\n            loader: a :class: `torch.utils.data.Dataloader`\n                    DataLoader with validation set\n        \"\"\"\n        raise NotImplementedError('users must define predict_epoch to use this base class')\n\n    @abstractmethod\n    def predict_batch(self, data, targets):\n        \"\"\"\n        Make predictions on a batch (valid)\n        Parameters\n        ----------\n            data: a :tensor: `torch.Tensor`\n                Input data\n            target: a :tensor: `torch.Tensor`\n                Target data\n        Returns\n        -------\n            batch_outs: dict\n        \"\"\"\n        raise NotImplementedError('users must define predict_batch to use this base class')\n\n    def load_best_model(self):\n        if self.best_network is not None:\n            self.network = self.best_network\n\n    @abstractmethod\n    def predict(self, X):\n        \"\"\"\n        Make predictions on a batch (valid)\n        Parameters\n        ----------\n            data: a :tensor: `torch.Tensor`\n                Input data\n            target: a :tensor: `torch.Tensor`\n                Target data\n        Returns\n        -------\n            predictions: np.array\n                Predictions of the regression problem or the last class\n        \"\"\"\n        raise NotImplementedError('users must define predict to use this base class')\n\n    def explain(self, X):\n        \"\"\"\n        Return local explanation\n        Parameters\n        ----------\n            data: a :tensor: `torch.Tensor`\n                Input data\n            target: a :tensor: `torch.Tensor`\n                Target data\n        Returns\n        -------\n            M_explain: matrix\n                Importance per sample, per columns.\n            masks: matrix\n                Sparse matrix showing attention masks used by network.\n        \"\"\"\n        self.network.eval()\n\n        dataloader = DataLoader(PredictDataset(X),\n                                batch_size=self.batch_size, shuffle=False)\n\n        for batch_nb, data in enumerate(dataloader):\n            data = data.to(self.device).float()\n\n            M_explain, masks = self.network.forward_masks(data)\n            for key, value in masks.items():\n                masks[key] = csc_matrix.dot(value.cpu().detach().numpy(),\n                                            self.reducing_matrix)\n\n            if batch_nb == 0:\n                res_explain = csc_matrix.dot(M_explain.cpu().detach().numpy(),\n                                             self.reducing_matrix)\n                res_masks = masks\n            else:\n                res_explain = np.vstack([res_explain,\n                                         csc_matrix.dot(M_explain.cpu().detach().numpy(),\n                                                        self.reducing_matrix)])\n                for key, value in masks.items():\n                    res_masks[key] = np.vstack([res_masks[key], value])\n        return res_explain, res_masks\n\n    def _compute_feature_importances(self, loader):\n        self.network.eval()\n        feature_importances_ = np.zeros((self.network.post_embed_dim))\n        for data, targets in loader:\n            data = data.to(self.device).float()\n            M_explain, masks = self.network.forward_masks(data)\n            feature_importances_ += M_explain.sum(dim=0).cpu().detach().numpy()\n\n        feature_importances_ = csc_matrix.dot(feature_importances_,\n                                              self.reducing_matrix)\n        self.feature_importances_ = feature_importances_ / np.sum(feature_importances_)\n        \n        \nclass TabNetRegressor(TabModel):\n\n    def construct_loaders(self, X_train, y_train, X_valid, y_valid, weights,\n                          batch_size, num_workers, drop_last):\n        \"\"\"\n        Returns\n        -------\n        train_dataloader, valid_dataloader : torch.DataLoader, torch.DataLoader\n            Training and validation dataloaders\n        -------\n        \"\"\"\n        if isinstance(weights, int):\n            if weights == 1:\n                raise ValueError(\"Please provide a list of weights for regression.\")\n        if isinstance(weights, dict):\n            raise ValueError(\"Please provide a list of weights for regression.\")\n\n        train_dataloader, valid_dataloader = create_dataloaders(X_train,\n                                                                y_train,\n                                                                X_valid,\n                                                                y_valid,\n                                                                weights,\n                                                                batch_size,\n                                                                num_workers,\n                                                                drop_last)\n        return train_dataloader, valid_dataloader\n\n    def update_fit_params(self, X_train, y_train, X_valid, y_valid, loss_fn,\n                          weights, max_epochs, patience,\n                          batch_size, virtual_batch_size, num_workers, drop_last):\n\n        if loss_fn is None:\n            self.loss_fn = torch.nn.functional.mse_loss\n        else:\n            self.loss_fn = loss_fn\n\n        assert X_train.shape[1] == X_valid.shape[1], \"Dimension mismatch X_train X_valid\"\n        self.input_dim = X_train.shape[1]\n\n        if len(y_train.shape) == 1:\n            raise ValueError(\"\"\"Please apply reshape(-1, 1) to your targets\n                                if doing single regression.\"\"\")\n        assert y_train.shape[1] == y_valid.shape[1], \"Dimension mismatch y_train y_valid\"\n        self.output_dim = y_train.shape[1]\n\n        self.updated_weights = weights\n\n        self.max_epochs = max_epochs\n        self.patience = patience\n        self.batch_size = batch_size\n        self.virtual_batch_size = virtual_batch_size\n        # Initialize counters and histories.\n        self.patience_counter = 0\n        self.epoch = 0\n        self.best_cost = np.inf\n        self.num_workers = num_workers\n        self.drop_last = drop_last\n\n    def train_epoch(self, train_loader):\n        \"\"\"\n        Trains one epoch of the network in self.network\n        Parameters\n        ----------\n            train_loader: a :class: `torch.utils.data.Dataloader`\n                DataLoader with train set\n        \"\"\"\n\n        self.network.train()\n        y_preds = []\n        ys = []\n        total_loss = 0\n\n        for data, targets in train_loader:\n            batch_outs = self.train_batch(data, targets)\n            y_preds.append(batch_outs[\"y_preds\"].cpu().detach().numpy())\n            ys.append(batch_outs[\"y\"].cpu().detach().numpy())\n            total_loss += batch_outs[\"loss\"]\n\n        y_preds = np.vstack(y_preds)\n        ys = np.vstack(ys)\n\n        #stopping_loss = mean_squared_error(y_true=ys, y_pred=y_preds)\n        stopping_loss =log_loss_multi(ys, torch.sigmoid(torch.as_tensor(y_preds)).numpy()  )\n        total_loss = total_loss / len(train_loader)\n        epoch_metrics = {'loss_avg': total_loss,\n                         'stopping_loss': total_loss,\n                         }\n\n        if self.scheduler is not None:\n            self.scheduler.step()\n        return epoch_metrics\n\n    def train_batch(self, data, targets):\n        \"\"\"\n        Trains one batch of data\n        Parameters\n        ----------\n            data: a :tensor: `torch.tensor`\n                Input data\n            target: a :tensor: `torch.tensor`\n                Target data\n        \"\"\"\n        self.network.train()\n        data = data.to(self.device).float()\n\n        targets = targets.to(self.device).float()\n        self.optimizer.zero_grad()\n\n        output, M_loss = self.network(data)\n\n        loss = self.loss_fn(output, targets)\n        \n        loss -= self.lambda_sparse*M_loss\n\n        loss.backward()\n        if self.clip_value:\n            clip_grad_norm_(self.network.parameters(), self.clip_value)\n        self.optimizer.step()\n\n        loss_value = loss.item()\n        batch_outs = {'loss': loss_value,\n                      'y_preds': output,\n                      'y': targets}\n        return batch_outs\n\n    def predict_epoch(self, loader):\n        \"\"\"\n        Validates one epoch of the network in self.network\n        Parameters\n        ----------\n            loader: a :class: `torch.utils.data.Dataloader`\n                    DataLoader with validation set\n        \"\"\"\n        y_preds = []\n        ys = []\n        self.network.eval()\n        total_loss = 0\n\n        for data, targets in loader:\n            batch_outs = self.predict_batch(data, targets)\n            total_loss += batch_outs[\"loss\"]\n            y_preds.append(batch_outs[\"y_preds\"].cpu().detach().numpy())\n            ys.append(batch_outs[\"y\"].cpu().detach().numpy())\n\n        y_preds = np.vstack(y_preds)\n        ys = np.vstack(ys)\n\n        stopping_loss =log_loss_multi(ys, torch.sigmoid(torch.as_tensor(y_preds)).numpy()  ) #mean_squared_error(y_true=ys, y_pred=y_preds)\n\n        total_loss = total_loss / len(loader)\n        epoch_metrics = {'total_loss': total_loss,\n                         'stopping_loss': stopping_loss}\n\n        return epoch_metrics\n\n    def predict_batch(self, data, targets):\n        \"\"\"\n        Make predictions on a batch (valid)\n        Parameters\n        ----------\n            data: a :tensor: `torch.Tensor`\n                Input data\n            target: a :tensor: `torch.Tensor`\n                Target data\n        Returns\n        -------\n            batch_outs: dict\n        \"\"\"\n        self.network.eval()\n        data = data.to(self.device).float()\n        targets = targets.to(self.device).float()\n\n        output, M_loss = self.network(data)\n       \n        loss = self.loss_fn(output, targets)\n        #print(self.loss_fn, loss)\n        loss -= self.lambda_sparse*M_loss\n        #print(loss)\n        loss_value = loss.item()\n        batch_outs = {'loss': loss_value,\n                      'y_preds': output,\n                      'y': targets}\n        return batch_outs\n\n    def predict(self, X):\n        \"\"\"\n        Make predictions on a batch (valid)\n        Parameters\n        ----------\n            data: a :tensor: `torch.Tensor`\n                Input data\n            target: a :tensor: `torch.Tensor`\n                Target data\n        Returns\n        -------\n            predictions: np.array\n                Predictions of the regression problem\n        \"\"\"\n        self.network.eval()\n        dataloader = DataLoader(PredictDataset(X),\n                                batch_size=self.batch_size, shuffle=False)\n\n        results = []\n        for batch_nb, data in enumerate(dataloader):\n            data = data.to(self.device).float()\n\n            output, M_loss = self.network(data)\n            predictions = output.cpu().detach().numpy()\n            results.append(predictions)\n        res = np.vstack(results)\n        return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config(object):\n    def __init__(self):\n        self.num_class = targets_tr.shape[1]\n        self.verbose=False\n        #\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.SPLITS = N_SPLITS\n        self.EPOCHS = 200\n        self.num_ensembling = N_STARTS\n        self.seed = 0\n        # Parameters model\n        self.cat_emb_dim=[1] * cat_tr.shape[1] #to choose\n        self.cats_idx = list(range(cat_tr.shape[1]))\n        self.cat_dims = [len(np.unique(cat_tr[:, i])) for i in range(cat_tr.shape[1])]\n        self.num_numericals = numerical_tr.shape[1]\n        # save\n        self.save_name = \"../input/multilabel-pbestpre-tabnet/tabnet_raw_step1\"\n        \n        self.strategy = \"KFOLD\" # \n        \ncfg = Config()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_test = np.concatenate([cat_test, numerical_test], axis=1)\nif cfg.strategy == \"KFOLD\":\n    oof_preds_all = []\n    oof_targets_all = []\n    scores_all =  []\n    scores_auc_all= []\n    preds_test = []\n    res = np.zeros(targets_tr.shape)\n    for nums, seed in enumerate(range(cfg.num_ensembling)):\n        print(\"## SEED : \", seed)\n        mskf = MultilabelStratifiedKFold(n_splits=cfg.SPLITS, random_state=cfg.seed+seed, shuffle=True)\n        oof_preds = []\n        oof_targets = []\n        scores = []\n        scores_auc = []\n        p = []\n        for j, (train_idx, val_idx) in enumerate(mskf.split(np.zeros(len(cat_tr)), targets_tr)):\n            print(\"FOLDS : \", j)\n\n            ## model\n            X_train, y_train = torch.as_tensor(np.concatenate([cat_tr[train_idx], numerical_tr[train_idx] ], axis=1)), torch.as_tensor(targets_tr[train_idx])\n            X_val, y_val = torch.as_tensor(np.concatenate([cat_tr[val_idx], numerical_tr[val_idx] ], axis=1)), torch.as_tensor(targets_tr[val_idx])\n            model = TabNetRegressor(n_d=24, n_a=24, n_steps=1, gamma=1.3, lambda_sparse=0, cat_dims=cfg.cat_dims, cat_emb_dim=cfg.cat_emb_dim, cat_idxs=cfg.cats_idx, optimizer_fn=torch.optim.Adam,\n                                   optimizer_params=dict(lr=2e-2), mask_type='entmax', device_name=cfg.device, scheduler_params=dict(milestones=[ 50,100,150], gamma=0.9), scheduler_fn=torch.optim.lr_scheduler.MultiStepLR)\n            #'sparsemax'\n            \n            name = cfg.save_name + f\"_fold{j}_{seed}\"\n            model.load_model(name)\n            if CALCULATE_OOF:\n            # preds on val\n                preds = model.predict(X_val)\n                preds = torch.sigmoid(torch.as_tensor(preds)).detach().cpu().numpy()\n                score = log_loss_multi(y_val, preds)\n                res[val_idx] += preds / cfg.num_ensembling\n\n                ## save oof to compute the CV later\n                oof_preds.append(preds)\n                oof_targets.append(y_val)\n                scores.append(score)\n                scores_auc.append(auc_multi(y_val,preds))\n                print(f\"validation fold {j} : {score}\")\n                \n                \n            # preds on test\n            temp = model.predict(X_test)\n            p.append(torch.sigmoid(torch.as_tensor(temp)).detach().cpu().numpy())\n                \n        p = np.stack(p)\n        preds_test.append(p)\n        \n        if CALCULATE_OOF:\n            oof_preds_all.append(np.concatenate(oof_preds))\n            oof_targets_all.append(np.concatenate(oof_targets))\n            scores_all.append(np.array(scores))\n            scores_auc_all.append(np.array(scores_auc))\n            \n    preds_test = np.stack(preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if CALCULATE_OOF:\n\n    if cfg.strategy == \"KFOLD\":\n\n        for i in range(cfg.num_ensembling): \n            print(\"CV score fold : \", log_loss_multi(oof_targets_all[i], oof_preds_all[i]))\n            print(\"auc mean : \", sum(scores_auc_all[i])/len(scores_auc_all[i]))\n        \n    # Overall OOF CV Score\n    tr_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv').drop('sig_id', axis = 1)\n    res_all = np.zeros(tr_targets[cols].shape)\n    res_all[train_features['cp_type'] == 0] = res\n    overall_oof_score = log_loss_metric(tr_targets[cols].values, res_all)\n    print(f'TabNet Overall OOF CV Score:', overall_oof_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_tabnet = pd.read_csv('../input/lish-moa/sample_submission.csv')\nsubmission_tabnet[cols] = preds_test.mean(1).mean(0)\nsubmission_tabnet.loc[test['cp_type'] == 1, cols] = 0","execution_count":null,"outputs":[]},{"metadata":{"id":"l9086lcvni30"},"cell_type":"markdown","source":"# Model Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp_elu(num_columns, hidden_units, dropout_rates, lr):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ), name = 'inp')\n    x = tf.keras.layers.BatchNormalization(name = 'bn0')(inp)\n    x = tf.keras.layers.Dropout(0.3, name = 'dp0')(x)\n    \n    for i, units in enumerate(hidden_units):\n        \n        x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(units, activation = 'elu', name = f'd{i}'), name = f'w{i}')(x)\n        x = tf.keras.layers.Dropout(dropout_rates, name = f'dp{i + 1}')(x)\n        x = tf.keras.layers.BatchNormalization(name = f'bn{i + 1}')(x)\n        \n    out = tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation = 'sigmoid', \n                                                               bias_initializer=tf.keras.initializers.Constant(6.3), \n                                                               name = 'out206'), name = 'wn_out206')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    \n    metrics = [tf.keras.losses.BinaryCrossentropy(name = 'mean_loss')]\n    model.compile(optimizer = tfa.optimizers.AdamW(weight_decay = 1e-5, learning_rate = lr),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.0008), \n                  metrics = metrics, \n                  )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_resnet(num_columns, hidden_units, dropout_rates, lr):\n    inp = layers.Input(shape = (num_columns,), name = 'inp')\n\n    head_1 = tf.keras.models.Sequential([\n        layers.BatchNormalization(),\n        layers.Dropout(dropout_rates[0]),\n        layers.Dense(hidden_units[0], activation = \"elu\"), \n        layers.BatchNormalization(),\n        layers.Dense(hidden_units[1], activation = \"elu\")\n        ], name = 'Head1') \n\n    inp1 = head_1(inp)\n\n    head_2 = tf.keras.models.Sequential([\n        layers.BatchNormalization(),\n        layers.Dropout(dropout_rates[0]),\n        layers.Dense(hidden_units[2], \"relu\"),\n        layers.BatchNormalization(),\n        layers.Dense(hidden_units[2], \"elu\"),\n        layers.BatchNormalization(),\n        layers.Dense(hidden_units[1], \"relu\"),\n        layers.BatchNormalization(),\n        layers.Dense(hidden_units[1], \"elu\")\n        ], name = 'Head2')\n\n    inp2 = head_2(inp1)\n    inp2_avg = layers.Average(name = 'average')([inp1, inp2]) \n\n    head_3 = tf.keras.models.Sequential([\n        layers.BatchNormalization(),\n        layers.Dense(hidden_units[3], kernel_initializer = 'lecun_normal', activation = 'selu'),\n        layers.BatchNormalization(),\n        layers.Dense(206, kernel_initializer = 'lecun_normal', activation = 'selu'),\n        layers.BatchNormalization(),\n        ], name = 'Head3')\n\n    out0 = head_3(inp2_avg)\n    out = layers.Dense(206, activation = \"sigmoid\", name = 'out_206')(out0)\n\n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tfa.optimizers.AdamW(weight_decay = 1e-5, learning_rate = lr), \n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.0008), \n                  metrics = tf.keras.losses.BinaryCrossentropy(name = 'mean_loss'),\n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, lr):\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ), name = 'inp')\n    x = tf.keras.layers.BatchNormalization(name = 'bn0')(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0], name = 'dp0')(x)\n    for i in range(len(hidden_units)): \n        x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(hidden_units[i], name = f'd{i}'), name = f'wn{i}')(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish, name = f'a{i}')(x)\n        x = tf.keras.layers.BatchNormalization(name = f'bn{i+1}')(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1], name = f'dp{i+1}')(x)    \n        \n    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(num_labels, \n                                                             bias_initializer = tf.keras.initializers.Constant(6.3), \n                                                             name = f'output_d{num_labels}'), \n                                       name = f'output_wn{num_labels}')(x)\n    out = tf.keras.layers.Activation('sigmoid', name = f'output_a{num_labels}')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tfa.optimizers.AdamW(weight_decay = 1e-5, learning_rate = lr),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.0008), \n                  metrics = tf.keras.losses.BinaryCrossentropy(name = 'mean_loss'), \n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_rtn(num_columns, num_labels, rethink_iter, num_layers, hidden_units, dropout_rates, lr):\n    inp = tf.keras.layers.Input(shape = (num_columns, ), name = 'inp')\n    x = tf.keras.layers.BatchNormalization(name = 'bn0')(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0], name = 'dp0')(x)\n    x = tf.keras.layers.RepeatVector(rethink_iter, name = 'rv')(x)\n\n    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(hidden_units[0], name = 'd0'), name = 'wn0')(x)\n    x = tf.keras.layers.Activation('swish', name = 'a0')(x)\n    \n    for i in range(num_layers):\n        if i != num_layers - 1:\n            x = tf.keras.layers.LSTM(hidden_units[1], return_sequences = True, dropout = dropout_rates[1], name = f'lstm{i}')(x)\n        else:\n            x = tf.keras.layers.LSTM(hidden_units[1], return_sequences = False, dropout = dropout_rates[1], name = f'lstm{i}')(x)\n\n    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(num_labels, name = f'd{num_labels}'), name = f'wn{num_labels}')(x)\n    out = tf.keras.layers.Activation('sigmoid', name = f'out{num_labels}')(x)\n\n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tfa.optimizers.AdamW(weight_decay = 1e-5, learning_rate = lr), \n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.0008), \n                  metrics = tf.keras.losses.BinaryCrossentropy(name = 'mean_loss'),\n                 )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"ol334uu2oSUO"},"cell_type":"markdown","source":"# Inference Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference_model(X_train, Y_train_2, Y_nonscored, features, model_name, model_name_2, save_path, num_seeds, num_splits, \n                    model_params, X_test = None, sample_sub_path = None, verbose = 0):\n    start_time_all = time()\n    oof = Y_train_2.copy()\n    oof.loc[:, Y_train_2.columns] = 0\n    overall_score = []\n    if X_test is not None:\n        sub = pd.read_csv(sample_sub_path)\n        sub.loc[:, Y_train_2.columns] = 0\n    else:\n        sub = None\n    if 'RTN' in model_name_2:\n        model = create_rtn(len(features), 206, **model_params)\n    elif 'RESNET' in model_name_2:\n        model = create_resnet(len(features), **model_params)\n    elif 'ELU' in model_name_2:\n        model = create_mlp_elu(len(features), **model_params)\n    elif 'MLP' in model_name_2:\n        model = create_mlp(len(features), 206, **model_params)\n    for nums, seed in enumerate(range(num_seeds)):\n        start_time_seed = time()\n        tf.random.set_seed(seed)\n        np.random.seed(seed)\n        random.seed(seed) \n        mean_score = 0\n        skf = MultilabelStratifiedKFold(n_splits = num_splits, random_state = seed, shuffle = True)\n        for n, (tr, te) in enumerate(skf.split(Y_train_2, Y_train_2)):\n            print(f'Model:{model_name}, Seed:{seed}, Fold:{n}', end = '\\r')\n            start_time_fold = time()\n            if CALCULATE_OOF:\n                x_tr, x_val = X_train.values[tr][:, features], X_train.values[te][:, features]\n                y_tr, y_val = Y_train_2.values[tr], Y_train_2.values[te]\n                \n            if 'ELU' in model_name_2:\n                ckp_path = save_path + f'{model_name}_{seed}_{n}.hdf5' \n            else:\n                ckp_path = save_path + f'{model_name}_Seed_{seed}_Fold_{n}.hdf5' \n            model.load_weights(ckp_path)\n            \n            if X_test is not None:\n                x_tt = X_test.values[:, features]\n                test_predict = model.predict(x_tt, batch_size = 1024)\n                sub.loc[:, Y_train_2.columns] += test_predict / (num_splits * num_seeds)\n            \n            if CALCULATE_OOF:\n                val_predict = model.predict(x_val, batch_size = 1024)\n#                 fold_score = hist['val_mean_loss'].min()\n                fold_score = log_loss_metric(y_val, val_predict)\n                mean_score += fold_score / num_splits\n                oof.loc[te, Y_train_2.columns] += val_predict / num_seeds\n#                 print(f'[{str(datetime.timedelta(seconds = time() - start_time_fold))[0:7]}] {model_name} Seed {seed}, Fold {n}:', fold_score)\n            \n#             del model\n#             x = gc.collect()\n#             K.clear_session()\n            \n        if CALCULATE_OOF:\n            pass\n#             print(f'[{str(datetime.timedelta(seconds = time() - start_time_seed))[0:7]}] {model_name} Seed {seed} Mean Score:', mean_score)\n    \n    if X_test is not None:\n        sub.loc[X_test['cp_type'] == 1, Y_train_2.columns] = 0\n    \n    if CALCULATE_OOF:\n        oof.loc[X_train['cp_type'] == 1, Y_train_2.columns] = 0\n        overall_score = log_loss_metric(Y_train_2.values, oof[Y_train_2.columns].values)\n        print(f'[{str(datetime.timedelta(seconds = time() - start_time_all))[0:7]}] {model_name} OOF Score:', overall_score)\n        \n    return overall_score, oof, sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference_ensemble(X_train, Y_train_2, model_name, model_name_2, save_path, num_seeds, num_splits, \n                       model_params, X_test = None, sample_sub_path = None, verbose = 0):\n    start_time_all = time()\n    oof = Y_train_2.copy()\n    oof.loc[:, Y_train_2.columns] = 0\n    overall_score = []\n    if X_test is not None:\n        sub = pd.read_csv(sample_sub_path)\n        sub.loc[:, Y_train_2.columns] = 0\n    else:\n        sub = None\n    if 'RTN' in model_name_2:\n        model = create_rtn(X_train.shape[1], 206, **model_params)\n    elif 'RESNET' in model_name_2:\n        model = create_resnet(X_train.shape[1], **model_params)\n    elif 'ELU' in model_name_2:\n        model = create_mlp_elu(X_train.shape[1], **model_params)\n    elif 'MLP' in model_name_2:\n        model = create_mlp(X_train.shape[1], 206, **model_params)\n    for seed in range(num_seeds):\n        start_time_seed = time()\n        tf.random.set_seed(seed)\n        np.random.seed(seed)\n        random.seed(seed) \n        mean_score = 0\n        skf = MultilabelStratifiedKFold(n_splits = num_splits, random_state = seed, shuffle = True)\n        for n, (tr, te) in enumerate(skf.split(Y_train_2, Y_train_2)):\n            print(f'Model:{model_name}, Seed:{seed}, Fold:{n}', end = '\\r')\n            start_time_fold = time()\n            if CALCULATE_OOF:\n                x_tr, x_val = X_train[tr], X_train[te]\n                y_tr, y_val = Y_train_2.values[tr], Y_train_2.values[te]\n                \n            if 'ELU' in model_name_2:\n                ckp_path = save_path + f'{model_name}_{seed}_{n}.hdf5' \n            else:\n                ckp_path = save_path + f'{model_name}_Seed_{seed}_Fold_{n}.hdf5'\n            model.load_weights(ckp_path)\n            \n            if X_test is not None:\n                x_tt = X_test\n                test_predict = model.predict(x_tt, batch_size = 1024)\n                sub.loc[:, Y_train_2.columns] += test_predict / (num_splits * num_seeds)\n            \n            if CALCULATE_OOF:\n                val_predict = model.predict(x_val, batch_size = 1024)\n#                 fold_score = hist['val_mean_loss'].min()\n                fold_score = log_loss_metric(y_val, val_predict)\n                mean_score += fold_score / num_splits\n                oof.loc[te, Y_train_2.columns] += val_predict / num_seeds\n#                 print(f'[{str(datetime.timedelta(seconds = time() - start_time_fold))[0:7]}] {model_name} Seed {seed}, Fold {n}:', fold_score)\n            \n#             del model\n#             x = gc.collect()\n#             K.clear_session()\n\n        if CALCULATE_OOF:\n            pass\n#             print(f'[{str(datetime.timedelta(seconds = time() - start_time_seed))[0:7]}] {model_name} Seed {seed} Mean Score:', mean_score)\n    \n    if X_test is not None:\n        sub.loc[test['cp_type'] == 1, Y_train_2.columns] = 0\n    \n    if CALCULATE_OOF:\n        oof.loc[train['cp_type'] == 1, Y_train_2.columns] = 0\n        overall_score = log_loss_metric(Y_train_2.values, oof[Y_train_2.columns].values)\n        print(f'[{str(datetime.timedelta(seconds = time() - start_time_all))[0:7]}] {model_name} OOF Score:', overall_score)\n        \n    return overall_score, oof, sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"model_names = ['ELU_0', 'ELU_1', 'ELU_2', 'RESNET_0', 'RESNET_1', 'RESNET_2', 'MLP_0', 'MLP_1', 'MLP_2', 'RTN']\n\nmodel_params = [{'hidden_units': [512, 512, 4096],  \n                 'dropout_rates': 0.45,\n                 'lr': 1e-4,\n                }, \n                {'hidden_units': [512, 1024],  \n                 'dropout_rates': 0.463,\n                 'lr': 1e-4,\n                },\n                {'hidden_units': [1024, 1024],  \n                 'dropout_rates': 0.5, \n                 'lr': 1e-4,\n                },\n                {'hidden_units': [128, 896, 256, 1024], \n                 'dropout_rates': [0.5615750059111406, 0.381766362379825], \n                 'lr': 1e-4,\n                } , \n                {'hidden_units': [256, 1024, 512, 896], \n                 'dropout_rates': [0.5493076960151594, 0.5121645764863383], \n                 'lr': 1e-4,\n                }, \n                {'hidden_units': [384, 1024, 256, 896], \n                 'dropout_rates': [0.5923827297670073, 0.37098621422772815], \n                 'lr': 1e-4,\n                }, \n                {'hidden_units': [128, 1024],  \n                 'dropout_rates': [0.41458519175008285, 0.38992411412605404, 0.10265155152086326], \n                 'lr': 1e-4,\n                }, \n                {'hidden_units': [896, 128, 1664],  \n                 'dropout_rates': [0.532412647744322, 0.2498368055693044, 0.36619131749273925, 0.1386672227832089], \n                 'lr': 1e-4,\n                }, \n                {'hidden_units': [128, 896, 1024, 1792],  \n                 'dropout_rates': [0.4131287697962003, 0.33921841003415876, 0.13058255266781393, 0.20075775903486198, 0.3354496944535896],\n                 'lr': 1e-4,\n                }, \n                {'rethink_iter': 3,  \n                 'num_layers': 1, \n                 'hidden_units': [128, 512],  \n                 'dropout_rates': [0.3, 0.4], \n                 'lr': 1e-4,\n                },]","execution_count":null,"outputs":[]},{"metadata":{"id":"YpJRV0O5cxV8","executionInfo":{"status":"ok","timestamp":1602953542287,"user_tz":-60,"elapsed":4372657,"user":{"displayName":"Yirun Zhang","photoUrl":"","userId":"05891579764514658952"}},"outputId":"bd1f6ab2-ca29-4eaf-aff0-c678b1b7f494","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from time import time\n\nVERBOSE = 0\nsample_sub_path = '../input/lish-moa/sample_submission.csv'\n\noverall_oof_scores = []\noof_elu = []\noof_resnet = []\noof_mlp = []\nsubmission_elu = []\nsubmission_resnet = []\nsubmission_mlp = []\nfor m in range(len(model_params)):\n    print(model_names[m], model_params[m])\n    if 'ELU' in model_names[m]:\n        model_idx = model_names[m].split('_')[1]\n        save_path = '../input/multilabel-v2/'\n        model_name = f'Model_{model_idx}'\n    elif 'RESNET' in model_names[m]:\n        model_idx = model_names[m].split('_')[1]\n        save_path = '../input/multilabel-v4/'\n        model_name = f'Model{model_idx}'\n    elif 'MLP' in model_names[m]:\n        model_idx = model_names[m].split('_')[1]\n        save_path = '../input/miltilabel-mlpstack/'\n        model_name = f'Model{model_idx}'\n    else:\n        save_path = '../input/multilabel-rtn-single/'\n        model_name = f'Model0'        \n        \n    oof_score, res, ss = inference_model(train, train_targets, train_targets_nonscored, top_feats, model_name, model_names[m], \n                                         save_path, N_STARTS, N_SPLITS, model_params[m], test, sample_sub_path, VERBOSE)\n    if 'ELU' in model_names[m]:\n        oof_elu.append(res)\n        submission_elu.append(ss)\n    elif 'RESNET' in model_names[m]:\n        oof_resnet.append(res)\n        submission_resnet.append(ss)\n    elif 'MLP' in model_names[m]:\n        oof_mlp.append(res)\n        submission_mlp.append(ss)\n    else:\n        oof_rtn = res\n        submission_rtn = ss\n    \n    if CALCULATE_OOF:\n        # Overall OOF CV Score\n        tr_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv').drop('sig_id', axis = 1)\n        res_all = np.zeros(tr_targets[cols].shape)\n        res_all[train_features['cp_type'] == 0] = res[cols].values\n        overall_oof_score = log_loss_metric(tr_targets[cols].values, res_all)\n        overall_oof_scores.append(overall_oof_score)\n        print(f'{model_names[m]} Overall OOF CV Score:', overall_oof_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if CALCULATE_OOF:\n    for n, name in enumerate(model_names):\n        print(f'{name} OOF:\\t', overall_oof_scores[n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if CALCULATE_OOF:\n    train_new_elu = np.concatenate([oof0[cols].values for oof0 in oof_elu], axis = 1)\n    train_new_resnet = np.concatenate([oof0[cols].values for oof0 in oof_resnet], axis = 1)\n    train_new_mlp = np.concatenate([oof0[cols].values for oof0 in oof_mlp], axis = 1)\nelse:\n    train_new_elu = np.zeros((train.shape[0], len(cols) * 3))\n    train_new_resnet = np.zeros((train.shape[0], len(cols) * 3))\n    train_new_mlp = np.zeros((train.shape[0], len(cols) * 3))\n    \ntest_new_elu = np.concatenate([sub[cols].values for sub in submission_elu], axis = 1)\ntest_new_resnet = np.concatenate([sub[cols].values for sub in submission_resnet], axis = 1)\ntest_new_mlp = np.concatenate([sub[cols].values for sub in submission_mlp], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names = ['ELU_stack', 'RESNET_stack', 'MLP_stack']\n\nmodel_params = [{'hidden_units': [1024, 1024],  \n                 'dropout_rates': 0.336, \n                 'lr': 1e-4,\n                },\n                {'hidden_units': [1024, 896, 896, 256], \n                 'dropout_rates': [0.5398428318872255, 0.5734093398641228], \n                 'lr': 1e-4, \n                },\n                {'hidden_units': [1920, 768],  \n                 'dropout_rates': [0.36130273975713795, 0.38130486900003896, 0.44485672673556004], \n                 'lr': 1e-4,\n                },]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overall_oof_stack_scores = []\nfor m in range(len(model_params)):\n    print(model_names[m], model_params[m])\n    if 'ELU' in model_names[m]:\n        save_path = '../input/multilabel-v2/'\n        model_name = f'EModel'\n        oof_score, res, ss = inference_ensemble(train_new_elu, train_targets, model_name, model_names[m], save_path, \n                                                N_STARTS, N_SPLITS, model_params[m], test_new_elu, sample_sub_path, VERBOSE)\n        oof_elu_stack = res.copy()\n        submission_elu_stack = ss.copy()\n        \n    elif 'RESNET' in model_names[m]:\n        save_path = '../input/multilabel-v4/'\n        model_name = f'EModel_Stack'\n        oof_score, res, ss = inference_ensemble(train_new_resnet, train_targets, model_name, model_names[m], save_path, \n                                                N_STARTS, N_SPLITS, model_params[m], test_new_resnet, sample_sub_path, VERBOSE)\n        oof_resnet_stack = res.copy()\n        submission_resnet_stack = ss.copy()\n        \n    elif 'MLP' in model_names[m]:\n        save_path = '../input/miltilabel-mlpstack/'\n        model_name = f'EModel_Stack'\n        oof_score, res, ss = inference_ensemble(train_new_mlp, train_targets, model_name, model_names[m], save_path, \n                                                N_STARTS, N_SPLITS, model_params[m], test_new_mlp, sample_sub_path, VERBOSE)\n        oof_mlp_stack = res.copy()\n        submission_mlp_stack = ss.copy()\n    \n    if CALCULATE_OOF:\n        # Overall OOF CV Score\n        tr_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv').drop('sig_id', axis = 1)\n        res_all = np.zeros(tr_targets[cols].shape)\n        res_all[train_features['cp_type'] == 0] = res[cols].values\n        overall_oof_score = log_loss_metric(tr_targets[cols].values, res_all)\n        overall_oof_stack_scores.append(overall_oof_score)\n        print(f'{model_names[m]} Overall OOF CV Score:', overall_oof_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if CALCULATE_OOF:\n    for n, name in enumerate(model_names):\n        print(f'{name} OOF:\\t', overall_oof_stack_scores[n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"@njit\ndef post_process(pred, low, high):\n    pred_copy = pred.copy()\n    num_idx = 0\n    for i in range(pred_copy.shape[0]):\n        flag = np.zeros(pred_copy.shape[1])\n        array = pred_copy[i].copy()\n        for j in range(pred_copy.shape[1]):\n            if (pred_copy[i, j] <= low) or (pred_copy[i, j] >= high):\n                flag[j] = 1\n            array[j] = round(array[j])\n        if flag.all() and pred_copy[i].any(): #array.any()\n            pred_copy[i] = array\n            num_idx += 1\n    return pred_copy, num_idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv('../input/lish-moa/sample_submission.csv')\nss[cols] = 0.0877289129911273 * submission_elu_stack[cols].values + \\\n           0.026620985745766827 * submission_resnet_stack[cols].values + \\\n           0.04467573105638814 * submission_mlp_stack[cols].values + \\\n           0.3382592931952609 * submission_rtn[cols].values + \\\n           0.5027150770114568 * submission_tabnet[cols].values\nss.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if POST_PROCESS:\n    low = 0.012\n    high = 0.98\n\n    ss[cols], num_idx = post_process(ss[cols].values, low, high)\n    print(num_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del data, data2, train2, test2, data_transformed, train_transformed, test_transformed\nif CALCULATE_OOF:\n    del tr_targets, overall_oof_score, overall_oof_scores, oof_preds, oof_preds_all, oof_targets, oof_targets_all, oof_score\n    del oof_elu_stack, oof_resnet_stack, oof_mlp_stack, oof_elu, oof_resnet, oof_mlp, oof_rtn\nrubbish = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pseudo Labelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n    pseudo_targets = ss.loc[test['cp_type'] == 0, cols].values\n    pseudo_train = test.loc[test['cp_type'] == 0, test.columns].values","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"if FINETUNE:\n    import time\n    if cfg.strategy == \"KFOLD\":\n        oof_preds_all = []\n        oof_targets_all = []\n        scores_all =  []\n        scores_auc_all= []\n        preds_test = []\n        res = np.zeros(targets_tr.shape)\n        for nums, seed in enumerate(range(cfg.num_ensembling)):\n            print(\"## SEED : \", seed)\n            mskf = MultilabelStratifiedKFold(n_splits=cfg.SPLITS, random_state=cfg.seed+seed, shuffle=True)\n            oof_preds = []\n            oof_targets = []\n            scores = []\n            scores_auc = []\n            p = []\n            for j, (train_idx, val_idx) in enumerate(mskf.split(np.zeros(len(cat_tr)), targets_tr)):\n                print(\"FOLDS : \", j)\n\n                ## model\n                x_tr, y_tr = np.concatenate([cat_tr[train_idx], numerical_tr[train_idx]], axis=1), targets_tr[train_idx]\n                x_tr, y_tr = np.concatenate([x_tr, X_test[test['cp_type'] == 0, :]]), np.concatenate([y_tr, pseudo_targets])\n\n                X_train, y_train = torch.as_tensor(x_tr), torch.as_tensor(y_tr)\n                X_val, y_val = torch.as_tensor(np.concatenate([cat_tr[val_idx], numerical_tr[val_idx]], axis=1)), torch.as_tensor(targets_tr[val_idx])\n\n                model = TabNetRegressor(n_d=24, n_a=24, n_steps=1, gamma=1.3, lambda_sparse=0, cat_dims=cfg.cat_dims, cat_emb_dim=cfg.cat_emb_dim, cat_idxs=cfg.cats_idx, optimizer_fn=torch.optim.Adam,\n                                        optimizer_params=dict(lr=2e-2, weight_decay=1e-5), mask_type='entmax', device_name=cfg.device, scheduler_params=dict(milestones=[100, 150], gamma=0.9), \n                                        scheduler_fn=torch.optim.lr_scheduler.MultiStepLR)\n                name = cfg.save_name + f\"_fold{j}_{seed}\"\n                model.load_model(name)\n                model.fit(X_train=X_train, y_train=y_train, X_valid=X_val, y_valid=y_val, max_epochs=200, patience=5, batch_size=1024, virtual_batch_size=128,\n                          num_workers=0, drop_last=False, loss_fn=sbcewlogits, pretrain=True, optimizer_params=dict(lr=1e-4, weight_decay=1e-5))\n                model.load_best_model()\n                save_name = f\"PL_tabnet_raw_step1_fold{j}_{seed}\"\n                model.save_model(save_name)\n                \n                # preds on test\n                temp = model.predict(X_test)\n                p.append(torch.sigmoid(torch.as_tensor(temp)).detach().cpu().numpy())\n                \n                if CALCULATE_OOF_PL:\n                    preds = model.predict(X_val)\n                    preds = torch.sigmoid(torch.as_tensor(preds)).detach().cpu().numpy()\n                    score = log_loss_multi(y_val, preds)\n                    res[val_idx] += preds / cfg.num_ensembling\n\n                    ## save oof to compute the CV later\n                    oof_preds.append(preds)\n                    oof_targets.append(y_val)\n                    scores.append(score)\n                    scores_auc.append(auc_multi(y_val,preds))\n                    print(f\"validation fold {j} : {score}\")\n\n            p = np.stack(p)\n            preds_test.append(p)\n            if CALCULATE_OOF_PL:\n                oof_preds_all.append(np.concatenate(oof_preds))\n                oof_targets_all.append(np.concatenate(oof_targets))\n                scores_all.append(np.array(scores))\n                scores_auc_all.append(np.array(scores_auc))\n\n        preds_test = np.stack(preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n    if CALCULATE_OOF_PL:\n\n        if cfg.strategy == \"KFOLD\":\n\n            for i in range(cfg.num_ensembling): \n                print(\"CV score fold : \", log_loss_multi(oof_targets_all[i], oof_preds_all[i]))\n                print(\"auc mean : \", sum(scores_auc_all[i])/len(scores_auc_all[i]))\n\n        # Overall OOF CV Score\n        tr_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv').drop('sig_id', axis = 1)\n        res_all = np.zeros(tr_targets[cols].shape)\n        res_all[train_features['cp_type'] == 0] = res\n        overall_oof_score = log_loss_metric(tr_targets[cols].values, res_all)\n        print(f'TabNet Overall OOF CV Score:', overall_oof_score)\n        oof_tabnet2 = res_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n\n    submission_tabnet2 = pd.read_csv('../input/lish-moa/sample_submission.csv')\n    submission_tabnet2[cols] = preds_test.mean(1).mean(0)\n    submission_tabnet2.loc[test['cp_type'] == 1, cols] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom time import time\n\ndef train_model(X_train, Y_train_2, Y_nonscored, features, model_name, model_name_2, save_path, num_seeds, num_splits, \n                model_params, X_test = None, sample_sub_path = None, pseudo_labeling = True, verbose = 0):\n    start_time_all = time()\n    oof = Y_train_2.copy()\n    oof.loc[:, Y_train_2.columns] = 0\n    overall_score = []\n    if X_test is not None:\n        sub = pd.read_csv(sample_sub_path)\n        sub.loc[:, Y_train_2.columns] = 0\n    else:\n        sub = None\n    if 'RTN' in model_name_2:\n        model = create_rtn(len(features), 206, **model_params)\n    elif 'RESNET' in model_name_2:\n        model = create_resnet(len(features), **model_params)\n    elif 'ELU' in model_name_2:\n        model = create_mlp_elu(len(features), **model_params)\n    elif 'MLP' in model_name_2:\n        model = create_mlp(len(features), 206, **model_params)\n    for nums, seed in enumerate(range(num_seeds)):\n        start_time_seed = time()\n        tf.random.set_seed(seed)\n        np.random.seed(seed)\n        random.seed(seed) \n        mean_score = 0\n        skf = MultilabelStratifiedKFold(n_splits = num_splits, random_state = seed, shuffle = True)\n        for n, (tr, te) in enumerate(skf.split(Y_train_2, Y_train_2)):\n            print(f'Model:{model_name}, Seed:{seed}, Fold:{n}', end = '\\r')\n            start_time_fold = time()\n            x_tr, x_val = X_train.values[tr][:, features], X_train.values[te][:, features]\n            y_tr, y_val = Y_train_2.values[tr], Y_train_2.values[te]\n            if pseudo_labeling:\n                x_tr = np.concatenate([x_tr, pseudo_train[:, features]])\n                y_tr = np.concatenate([y_tr, pseudo_targets])\n\n            if X_test is not None:\n                x_tt = X_test.values[:, features]\n            \n            if 'ELU' in model_name_2:\n                ckp_path = save_path + f'{model_name}_{seed}_{n}.hdf5' \n            else:\n                ckp_path = save_path + f'{model_name}_Seed_{seed}_Fold_{n}.hdf5'\n                \n            model.load_weights(ckp_path)\n\n            rlr = ReduceLROnPlateau(monitor = 'val_mean_loss', factor = 0.1, patience = 3, \n                                    verbose = verbose, min_delta = 1e-4, mode = 'min')\n            ckp = ModelCheckpoint(f'{model_name}_Seed_{seed}_Fold_{n}.hdf5', monitor = 'val_mean_loss', verbose = 0, \n                                  save_best_only = True, save_weights_only = True, mode = 'min')\n            es = EarlyStopping(monitor = 'val_mean_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n                               baseline = None, restore_best_weights = True, verbose = verbose)\n            history = model.fit(x_tr, y_tr, validation_data = (x_val, y_val), epochs = 1000, \n                                batch_size = 128, callbacks = [rlr, ckp, es], verbose = verbose)\n            hist = pd.DataFrame(history.history)\n            model.load_weights(f'{model_name}_Seed_{seed}_Fold_{n}.hdf5')\n            \n            if X_test is not None:\n                test_predict = model.predict(x_tt, batch_size = 1024)\n                sub.loc[:, Y_train_2.columns] += test_predict / (num_splits * num_seeds)\n            \n            if CALCULATE_OOF_PL:\n                val_predict = model.predict(x_val, batch_size = 1024)\n                fold_score = hist['val_mean_loss'].min()\n#                 fold_score = log_loss_metric(y_val, val_predict)\n                mean_score += fold_score / num_splits\n                oof.loc[te, Y_train_2.columns] += val_predict / num_seeds\n                print(f'[{str(datetime.timedelta(seconds = time() - start_time_fold))[0:7]}] {model_name} Seed {seed}, Fold {n}:', fold_score)\n                  \n#             del model\n#             x = gc.collect()\n#             K.clear_session()\n            \n        if CALCULATE_OOF_PL:\n            print(f'[{str(datetime.timedelta(seconds = time() - start_time_seed))[0:7]}] {model_name} Seed {seed} Mean Score:', mean_score)\n    \n    if X_test is not None:\n        sub.loc[X_test['cp_type'] == 1, Y_train_2.columns] = 0\n    \n    if CALCULATE_OOF_PL:\n        oof.loc[X_train['cp_type'] == 1, Y_train_2.columns] = 0\n        overall_score = log_loss_metric(Y_train_2.values, oof[Y_train_2.columns].values)\n        print(f'[{str(datetime.timedelta(seconds = time() - start_time_all))[0:7]}] {model_name} OOF Score:', overall_score)\n        \n    return overall_score, oof, sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names = ['ELU_0', 'ELU_1', 'ELU_2', 'RTN']\n\nmodel_params = [{'hidden_units': [512, 512, 4096],  \n                 'dropout_rates': 0.45,\n                 'lr': 1e-4,\n                }, \n                {'hidden_units': [512, 1024],  \n                 'dropout_rates': 0.463,\n                 'lr': 1e-4,\n                },\n                {'hidden_units': [1024, 1024],  \n                 'dropout_rates': 0.5, \n                 'lr': 1e-4,\n                },\n                {'rethink_iter': 3,  \n                 'num_layers': 1, \n                 'hidden_units': [128, 512],  \n                 'dropout_rates': [0.3, 0.4], \n                 'lr': 1e-4,\n                },]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n    Pseudo_Labeling = True\n    VERBOSE = 0\n    sample_sub_path = '../input/lish-moa/sample_submission.csv'\n\n    overall_oof_scores = []\n    oof_elu2 = []\n    submission_elu2 = []\n    for m in range(len(model_params)):\n        print(model_names[m], model_params[m])        \n        if 'ELU' in model_names[m]:\n            model_idx = model_names[m].split('_')[1]\n            save_path = '../input/multilabel-v2/'\n            model_name = f'Model_{model_idx}'\n        elif 'RTN' in model_names[m]:\n            save_path = '../input/multilabel-rtn-single/'\n            model_name = f'Model0' \n        \n        oof_score, res, ss = train_model(train, train_targets, train_targets_nonscored, top_feats, model_name, model_names[m], save_path, \n                                         N_STARTS, N_SPLITS, model_params[m], test, sample_sub_path, Pseudo_Labeling, VERBOSE)        \n        if 'ELU' in model_names[m]:\n            oof_elu2.append(res)\n            submission_elu2.append(ss)\n        elif 'RTN' in model_names[m]:\n            oof_rtn2 = res\n            submission_rtn2 = ss\n        \n        if CALCULATE_OOF_PL:\n            # Overall OOF CV Score\n            tr_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv').drop('sig_id', axis = 1)\n            res_all = np.zeros(tr_targets[cols].shape)\n            res_all[train_features['cp_type'] == 0] = res[cols].values\n            overall_oof_score = log_loss_metric(tr_targets[cols].values, res_all)\n            overall_oof_scores.append(overall_oof_score)\n            print(f'{model_name} Overall OOF CV Score:', overall_oof_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n    if CALCULATE_OOF_PL:\n        print(f'{model_names} OOF:\\t', overall_oof_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_ensemble(X_train, Y_train_2, model_name, model_name_2, save_path, num_seeds, num_splits, \n                   model_params, X_test = None, sample_sub_path = None, verbose = 0):\n    start_time_all = time()\n    oof = Y_train_2.copy()\n    oof.loc[:, Y_train_2.columns] = 0\n    overall_score = []\n    if X_test is not None:\n        sub = pd.read_csv(sample_sub_path)\n        sub.loc[:, Y_train_2.columns] = 0\n    else:\n        sub = None\n    if 'RTN' in model_name_2:\n        model = create_rtn(X_train.shape[1], 206, **model_params)\n    elif 'RESNET' in model_name_2:\n        model = create_resnet(X_train.shape[1], **model_params)\n    elif 'ELU' in model_name_2:\n        model = create_mlp_elu(X_train.shape[1], **model_params)\n    elif 'MLP' in model_name_2:\n        model = create_mlp(X_train.shape[1], 206, **model_params)\n    for seed in range(num_seeds):\n        start_time_seed = time()\n        tf.random.set_seed(seed)\n        np.random.seed(seed)\n        random.seed(seed) \n        mean_score = 0\n        skf = MultilabelStratifiedKFold(n_splits = num_splits, random_state = seed, shuffle = True)\n        for n, (tr, te) in enumerate(skf.split(Y_train_2, Y_train_2)):\n            print(f'Model:{model_name}, Seed:{seed}, Fold:{n}', end = '\\r')\n            start_time_fold = time()\n            x_tr, x_val = X_train[tr], X_train[te]\n            y_tr, y_val = Y_train_2.values[tr], Y_train_2.values[te]\n                \n            if 'ELU' in model_name_2:\n                ckp_path = save_path + f'{model_name}_{seed}_{n}.hdf5' \n            else:\n                ckp_path = save_path + f'{model_name}_Seed_{seed}_Fold_{n}.hdf5'\n            model.load_weights(ckp_path)\n            \n            rlr = ReduceLROnPlateau(monitor = 'val_mean_loss', factor = 0.1, patience = 3, \n                                    verbose = verbose, min_delta = 1e-4, mode = 'min')\n            ckp = ModelCheckpoint(f'{model_name}_Seed_{seed}_Fold_{n}.hdf5', monitor = 'val_mean_loss', verbose = 0, \n                                  save_best_only = True, save_weights_only = True, mode = 'min')\n            es = EarlyStopping(monitor = 'val_mean_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n                               baseline = None, restore_best_weights = True, verbose = verbose)\n            history = model.fit(x_tr, y_tr, validation_data = (x_val, y_val), epochs = 1000, \n                                batch_size = 128, callbacks = [rlr, ckp, es], verbose = verbose)\n            hist = pd.DataFrame(history.history)\n            model.load_weights(f'{model_name}_Seed_{seed}_Fold_{n}.hdf5')\n            \n            if X_test is not None:\n                x_tt = X_test\n                test_predict = model.predict(x_tt, batch_size = 1024)\n                sub.loc[:, Y_train_2.columns] += test_predict / (num_splits * num_seeds)\n            \n            if CALCULATE_OOF_PL:\n                val_predict = model.predict(x_val, batch_size = 1024)\n                fold_score = hist['val_mean_loss'].min()\n#                 fold_score = log_loss_metric(y_val, val_predict)\n                mean_score += fold_score / num_splits\n                oof.loc[te, Y_train_2.columns] += val_predict / num_seeds\n                print(f'[{str(datetime.timedelta(seconds = time() - start_time_fold))[0:7]}] {model_name} Seed {seed}, Fold {n}:', fold_score)\n            \n#             del model\n#             x = gc.collect()\n#             K.clear_session()\n\n        if CALCULATE_OOF_PL:\n            print(f'[{str(datetime.timedelta(seconds = time() - start_time_seed))[0:7]}] {model_name} Seed {seed} Mean Score:', mean_score)\n    \n    if X_test is not None:\n        sub.loc[test['cp_type'] == 1, Y_train_2.columns] = 0\n    \n    if CALCULATE_OOF_PL:\n        oof.loc[train['cp_type'] == 1, Y_train_2.columns] = 0\n        overall_score = log_loss_metric(Y_train_2.values, oof[Y_train_2.columns].values)\n        print(f'[{str(datetime.timedelta(seconds = time() - start_time_all))[0:7]}] {model_name} OOF Score:', overall_score)\n        \n    return overall_score, oof, sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n    if CALCULATE_OOF_PL:\n        train_new_elu2 = np.concatenate([oof0[cols].values for oof0 in oof_elu2], axis = 1)\n    else:\n        train_new_elu2 = np.zeros((train.shape[0], len(cols) * 3))\n\n    test_new_elu2 = np.concatenate([sub[cols].values for sub in submission_elu2], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names = ['ELU_stack']\n\nmodel_params = [{'hidden_units': [1024, 1024],  \n                 'dropout_rates': 0.336, \n                 'lr': 1e-4,\n                },]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n    overall_oof_stack_scores = []\n    for m in range(len(model_params)):\n        print(model_names[m], model_params[m])\n        if 'ELU' in model_names[m]:\n            save_path = '../input/multilabel-v2/'\n            model_name = f'EModel'\n            oof_score, res, ss = train_ensemble(train_new_elu2, train_targets, model_name, model_names[m], save_path, \n                                                N_STARTS, N_SPLITS, model_params[m], test_new_elu2, sample_sub_path, VERBOSE)\n            oof_elu_stack2 = res.copy()\n            submission_elu_stack2 = ss.copy()\n\n        if CALCULATE_OOF_PL:\n            # Overall OOF CV Score\n            tr_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv').drop('sig_id', axis = 1)\n            res_all = np.zeros(tr_targets[cols].shape)\n            res_all[train_features['cp_type'] == 0] = res[cols].values\n            overall_oof_score = log_loss_metric(tr_targets[cols].values, res_all)\n            overall_oof_stack_scores.append(overall_oof_score)\n            print(f'{model_names[m]} Overall OOF CV Score:', overall_oof_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if CALCULATE_OOF_PL:\n    for n, name in enumerate(model_names):\n        print(f'{name} OOF:\\t', overall_oof_stack_scores[n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n    ss = pd.read_csv('../input/lish-moa/sample_submission.csv')\n    ss[cols] = 0.0877289129911273 * submission_elu_stack2[cols].values + \\\n               0.026620985745766827 * submission_resnet_stack[cols].values + \\\n               0.04467573105638814 * submission_mlp_stack[cols].values + \\\n               0.3382592931952609 * submission_rtn2[cols].values + \\\n               0.5027150770114568 * submission_tabnet2[cols].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if FINETUNE:\n    if POST_PROCESS:\n        low = 0.012\n        high = 0.98\n\n        ss[cols], num_idx = post_process(ss[cols].values, low, high)\n        print(num_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv', index = False)\nss.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}