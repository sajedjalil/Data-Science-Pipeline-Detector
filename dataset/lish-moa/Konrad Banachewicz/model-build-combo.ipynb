{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom joblib import dump, load\nimport pickle\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import log_loss\n\nfrom datetime import date\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nfrom xgboost import XGBClassifier\n\nfrom category_encoders import CountEncoder\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# settings\ndata_folder = '../input/'\ndata_folder = '../input/lish-moa/'\noutput_folder = ''\n\nxseed = 42\n\nnfolds = 5\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'xgb'\n\n## Data\nxtrain = pd.read_csv(data_folder + 'train_features.csv')\nxtest = pd.read_csv(data_folder + 'test_features.csv')\nytrain = pd.read_csv(data_folder + 'train_targets_scored.csv')\n\n## FE\n\n# summary statistics per row per group of columns\ngcols = [f for f in xtrain.columns if 'g-' in f]\nccols = [f for f in xtrain.columns if 'c-' in f]\n\nxtrain['g_min'] = xtrain[gcols].min(axis = 1)\nxtrain['g_max'] = xtrain[gcols].max(axis = 1)\nxtrain['g_mean'] = xtrain[gcols].mean(axis = 1)\nxtrain['g_sd'] = xtrain[gcols].std(axis = 1)\n\nxtrain['c_min'] = xtrain[ccols].min(axis = 1)\nxtrain['c_max'] = xtrain[ccols].max(axis = 1)\nxtrain['c_mean'] = xtrain[ccols].mean(axis = 1)\nxtrain['c_sd'] = xtrain[ccols].std(axis = 1)\nxtrain['c_median'] = xtrain[ccols].std(axis = 1)\n\n\nxtest['g_min'] = xtest[gcols].min(axis = 1)\nxtest['g_max'] = xtest[gcols].max(axis = 1)\nxtest['g_mean'] = xtest[gcols].mean(axis = 1)\nxtest['g_sd'] = xtest[gcols].std(axis = 1)\n\nxtest['c_min'] = xtest[ccols].min(axis = 1)\nxtest['c_max'] = xtest[ccols].max(axis = 1)\nxtest['c_mean'] = xtest[ccols].mean(axis = 1)\nxtest['c_sd'] = xtest[ccols].std(axis = 1)\nxtest['c_median'] = xtest[ccols].std(axis = 1)\n\n# categorical cols\n\nenc = LabelEncoder()\nenc_cnt = CountEncoder()\ncategory_cols = ['cp_dose', 'cp_type']\nprint(category_cols)\n\nfor cols in category_cols:\n    xtrain[cols] = enc.fit_transform(xtrain[cols])\n    xtest[cols] = enc.transform(xtest[cols])\n    \n    enc_cnt.fit(xtrain[cols] + xtest[cols])\n    xtrain[cols+'_cnt'] = enc_cnt.transform(xtrain[cols])\n    xtest[cols+'_cnt'] = enc_cnt.transform(xtest[cols])\n    \n    \n## Model    \n\n# prepare split\nkf = KFold(n_splits = nfolds)\n\n# separation\nid_train = xtrain['sig_id']; id_test = xtest['sig_id']\nytrain.drop('sig_id', axis = 1, inplace = True) \nxtrain.drop('sig_id', axis = 1, inplace = True)\nxtest.drop('sig_id', axis = 1, inplace = True)\n\n\nprval = np.zeros(ytrain.shape)\nprfull = np.zeros((xtest.shape[0], ytrain.shape[1]))\n\n# classifier \n\nclassifier = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n\nclf = Pipeline([\n                ('classify', classifier)\n               ])\n\nparams = {'classify__estimator__colsample_bytree': 0.6522,\n          'classify__estimator__gamma': 3.6975,\n          'classify__estimator__learning_rate': 0.0503,\n          'classify__estimator__max_delta_step': 2.0706,\n          'classify__estimator__max_depth': 10,\n          'classify__estimator__min_child_weight': 31.5800,\n          'classify__estimator__n_estimators': 166,\n          'classify__estimator__subsample': 0.8639\n         }\n\n_ = clf.set_params(**params)\n\n## Fitting\nfor (ff, (id0, id1)) in enumerate(kf.split(xtrain)):\n     \n    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n    y0, y1 = ytrain.loc[id0], ytrain.loc[id1]\n    \n    # drop where cp_type==ctl_vehicle (baseline)\n    ctl_mask = np.where(x0['cp_type'] != 0)[0]\n\n    x0 = x0.iloc[ctl_mask]\n    x1 = x1\n    y0 = y0.iloc[ctl_mask]\n    \n    # fit model\n    classifier.fit(x0, y0)\n    \n    # generate predictions\n    vpreds = clf.predict_proba(x1) # list of preds per class\n    vpreds = np.array(vpreds)[:,:,1].T # take the positive class\n    \n    fpreds = clf.predict_proba(xtest)\n    fpreds = np.array(fpreds)[:,:,1].T # take the positive class\n        \n    # normalize the probabilities \n    for ii in range(0, ytrain.shape[1]):\n        m1 = y0.iloc[:,ii].mean()\n        \n        m2 = vpreds[:,ii].mean()\n        vpreds[:,ii] = vpreds[:,ii] - m2 + m1\n\n        m2 = fpreds[:,ii].mean()\n        fpreds[:,ii] = fpreds[:,ii] - m2 + m1\n\n    prval[id1,:] = vpreds\n    prfull += fpreds / nfolds\n\n\n## prep files\nprval = pd.DataFrame(prval); prval.columns = ytrain.columns\nprval['sig_id'] = id_train\n\nprfull = pd.DataFrame(prfull); prfull.columns = ytrain.columns\nprfull['sig_id'] = id_test\n\nxcols = list(ytrain.columns); xcols.insert(0, 'sig_id')\nprval = prval[xcols]\nprfull = prfull[xcols]\n\ntodate = date.today().strftime(\"%d%m\")\nprint(todate)\n\nprval.to_csv(output_folder + 'prval_'+model_name+'_'+todate+'.csv', index = False)\nprfull.to_csv(output_folder + 'prfull_'+model_name+'_'+todate+'.csv', index = False)\n\nprval_xgb = prval.copy()\nprfull_xgb = prfull.copy()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LR"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'lr'\n\n## Data\n\nxtrain = pd.read_csv(data_folder + 'train_features.csv')\nxtest = pd.read_csv(data_folder + 'test_features.csv')\nytrain = pd.read_csv(data_folder + 'train_targets_scored.csv')\n\n## FE\n# categorical columns - cp_time, cp_dose. we can dump cp_type\nprint(set(xtrain['cp_time']), set(xtest['cp_time']) )\n\n# cp_time\nxtrain['cp_time_24'] = (xtrain['cp_time'] == 24) + 0\nxtrain['cp_time_48'] = (xtrain['cp_time'] == 48) + 0\nxtest['cp_time_24'] = (xtest['cp_time'] == 24) + 0\nxtest['cp_time_48'] = (xtest['cp_time'] == 48) + 0\nxtrain.drop('cp_time', axis = 1, inplace = True)\nxtest.drop('cp_time', axis = 1, inplace = True)\n\n# cp_dose\nprint(set(xtrain['cp_dose']), set(xtest['cp_dose']) )\nxtrain['cp_dose_D1'] = (xtrain['cp_dose'] == 'D1') + 0\nxtest['cp_dose_D1'] = (xtest['cp_dose'] == 'D1') + 0\nxtrain.drop('cp_dose', axis = 1, inplace = True)\nxtest.drop('cp_dose', axis = 1, inplace = True)\n\n# cp_type\nxtrain['cp_type_control'] = (xtrain['cp_type'] == 'ctl_vehicle') + 0\nxtest['cp_type_control'] = (xtest['cp_type'] == 'ctl_vehicle') + 0\n\nxtrain.drop('cp_type', axis = 1, inplace = True)\nxtest.drop('cp_type', axis = 1, inplace = True)\n\n# summary statistics per row per group of columns\ngcols = [f for f in xtrain.columns if 'g-' in f]\nccols = [f for f in xtrain.columns if 'c-' in f]\n\nxtrain['g_min'] = xtrain[gcols].min(axis = 1)\nxtrain['g_max'] = xtrain[gcols].max(axis = 1)\nxtrain['g_mean'] = xtrain[gcols].mean(axis = 1)\nxtrain['g_sd'] = xtrain[gcols].std(axis = 1)\n\nxtrain['c_min'] = xtrain[ccols].min(axis = 1)\nxtrain['c_max'] = xtrain[ccols].max(axis = 1)\nxtrain['c_mean'] = xtrain[ccols].mean(axis = 1)\nxtrain['c_sd'] = xtrain[ccols].std(axis = 1)\nxtrain['c_median'] = xtrain[ccols].std(axis = 1)\n\n\nxtest['g_min'] = xtest[gcols].min(axis = 1)\nxtest['g_max'] = xtest[gcols].max(axis = 1)\nxtest['g_mean'] = xtest[gcols].mean(axis = 1)\nxtest['g_sd'] = xtest[gcols].std(axis = 1)\n\nxtest['c_min'] = xtest[ccols].min(axis = 1)\nxtest['c_max'] = xtest[ccols].max(axis = 1)\nxtest['c_mean'] = xtest[ccols].mean(axis = 1)\nxtest['c_sd'] = xtest[ccols].std(axis = 1)\nxtest['c_median'] = xtest[ccols].std(axis = 1)\n\n## Model\n\nkf = KFold(n_splits = nfolds)\n\n# separation\nid_train = xtrain['sig_id']; id_test = xtest['sig_id']\nytrain.drop('sig_id', axis = 1, inplace = True) \nxtrain.drop('sig_id', axis = 1, inplace = True)\nxtest.drop('sig_id', axis = 1, inplace = True)\n\n\nprval = np.zeros(ytrain.shape)\nprfull = np.zeros((xtest.shape[0], ytrain.shape[1]))\n\n#  model definition\npca = PCA(n_components = 350)\n# set the tolerance to a large value to make the example faster\nlogistic = LogisticRegression(max_iter=10000, tol=0.1, C = 0.25)\nbase_model = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n\nmo_base = MultiOutputClassifier(base_model, n_jobs=-1)\n\n# fitting\nfor (ff, (id0, id1)) in enumerate(kf.split(xtrain)):\n     \n    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n    y0, y1 = np.array(ytrain.loc[id0]), np.array(ytrain.loc[id1])\n    \n    # stupid fix for empty columns - LogisticRegression blows up otherwise\n    check_for_empty_cols = np.where(y0.sum(axis = 0) == 0)[0]\n    if len(check_for_empty_cols):\n        y0[0,check_for_empty_cols] = 1\n\n    # fit model\n    mo_base.fit(x0,y0)\n    \n    # generate the prediction\n    vpred = mo_base.predict_proba(x1)\n    fpred = mo_base.predict_proba(xtest)\n    \n    for ii in range(0,ytrain.shape[1]):\n        \n        prval[id1,ii] = vpred[ii][:,1]\n        prfull[:,ii] += fpred[ii][:,1]/nfolds   \n\n# prep files\nprval = pd.DataFrame(prval); prval.columns = ytrain.columns\nprval['sig_id'] = id_train\n\nprfull = pd.DataFrame(prfull); prfull.columns = ytrain.columns\nprfull['sig_id'] = id_test\n\n\nxcols = list(ytrain.columns); xcols.insert(0, 'sig_id')\nprval = prval[xcols]\nprfull = prfull[xcols]\n\n\ntodate = date.today().strftime(\"%d%m\")\nprint(todate)\n\nprval.to_csv(output_folder + 'prval_'+model_name+'_'+todate+'.csv', index = False)\nprfull.to_csv(output_folder + 'prfull_'+model_name+'_'+todate+'.csv', index = False)\n\nprval_lr = prval.copy()\nprfull_lr = prfull.copy()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = 0.9\n\nmetrics1 = []\nmetrics2 = []\nmetrics3 = []\nmetrics_combo = []\n\nfor _target in ytrain.columns:\n    metrics1.append(log_loss(ytrain.loc[:, _target], prval_xgb.loc[:, _target]))\n    metrics2.append(log_loss(ytrain.loc[:, _target], prval_lr.loc[:, _target]))\n    prcombo = alpha * prval_xgb.loc[:, _target] + (1- alpha) * alpha * prval_lr.loc[:, _target]\n    metrics3.append(log_loss(ytrain.loc[:, _target], prcombo   ))\n    prval.loc[:, _target] = prcombo\n    prfull.loc[:, _target] = alpha * prfull_xgb.loc[:, _target] + (1- alpha) * alpha * prfull_lr.loc[:, _target]\n    \nprint(f'OOF Metric: {np.round(np.mean(metrics1),4)}')\nprint(f'OOF Metric: {np.round(np.mean(metrics2),4)}')\nprint(f'OOF Metric: {np.round(np.mean(metrics3),4)}')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'ens'\ntodate = date.today().strftime(\"%d%m\")\nprint(todate)\n\nprval.to_csv(output_folder + 'prval_'+model_name+'_'+todate+'.csv', index = False)\nprfull.to_csv(output_folder + 'prfull_'+model_name+'_'+todate+'.csv', index = False)\nprfull.to_csv(output_folder + 'submission.csv', index = False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}