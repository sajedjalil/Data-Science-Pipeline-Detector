{"cells":[{"metadata":{"toc":true},"cell_type":"markdown","source":"<h1>Sommaire<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-data\" data-toc-modified-id=\"Import-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import data</a></span></li><li><span><a href=\"#Prepare-data\" data-toc-modified-id=\"Prepare-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepare data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-functions\" data-toc-modified-id=\"Prepare-functions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Prepare functions</a></span></li><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pipeline</a></span></li></ul></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>LightGBM</a></span><ul class=\"toc-item\"><li><span><a href=\"#Metric\" data-toc-modified-id=\"Metric-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Metric</a></span></li><li><span><a href=\"#Find-best-hyper-parameters-by-cross-validation-and-sub-sampling\" data-toc-modified-id=\"Find-best-hyper-parameters-by-cross-validation-and-sub-sampling-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Find best hyper-parameters by cross-validation and sub-sampling</a></span></li><li><span><a href=\"#Train-LGBM,-cross-validation-evaluation-and-predict-on-test-set\" data-toc-modified-id=\"Train-LGBM,-cross-validation-evaluation-and-predict-on-test-set-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Train LGBM, cross-validation evaluation and predict on test set</a></span></li></ul></li><li><span><a href=\"#Neural-network\" data-toc-modified-id=\"Neural-network-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Neural network</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compute-MoA-weights-from-train-set\" data-toc-modified-id=\"Compute-MoA-weights-from-train-set-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Compute MoA weights from train set</a></span></li><li><span><a href=\"#Weight-features-from-LGBM-features-importances\" data-toc-modified-id=\"Weight-features-from-LGBM-features-importances-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Weight features from LGBM features importances</a></span></li><li><span><a href=\"#Define-model-and-weighted-loss\" data-toc-modified-id=\"Define-model-and-weighted-loss-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Define model and weighted loss</a></span></li><li><span><a href=\"#Dataset-generator\" data-toc-modified-id=\"Dataset-generator-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Dataset generator</a></span></li><li><span><a href=\"#Train-folds\" data-toc-modified-id=\"Train-folds-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Train folds</a></span></li></ul></li><li><span><a href=\"#Stacking-:-LGBM-+-NN\" data-toc-modified-id=\"Stacking-:-LGBM-+-NN-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Stacking : LGBM + NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-dataset\" data-toc-modified-id=\"Train-dataset-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Train dataset</a></span></li><li><span><a href=\"#Test-set\" data-toc-modified-id=\"Test-set-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Test set</a></span></li><li><span><a href=\"#Check-LGBM-and-NN-performance-on-val-folds\" data-toc-modified-id=\"Check-LGBM-and-NN-performance-on-val-folds-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Check LGBM and NN performance on val folds</a></span></li><li><span><a href=\"#Train-Logistic-Regression-on-LGBM+NN-features\" data-toc-modified-id=\"Train-Logistic-Regression-on-LGBM+NN-features-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Train Logistic Regression on LGBM+NN features</a></span></li></ul></li><li><span><a href=\"#Postprocess-prediction\" data-toc-modified-id=\"Postprocess-prediction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Postprocess prediction</a></span></li><li><span><a href=\"#Plot-results\" data-toc-modified-id=\"Plot-results-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Plot results</a></span></li></ul></div>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom scipy.special import softmax\nfrom sklearn.model_selection import KFold\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n\nfrom lightgbm import LGBMClassifier\n\nfrom joblib import dump, load\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import data"},{"metadata":{"trusted":false},"cell_type":"code","source":"# data path\ndata_path = '../input/lish-moa/'\nfeatures_file = 'train_features.csv'\ntargets_file = 'train_targets_scored.csv'\nno_targets_file = 'train_targets_nonscored.csv'\ntest_file = 'test_features.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# get train data\ndf_features = pd.read_csv(os.path.join(data_path, features_file))\ndf_targets = pd.read_csv(os.path.join(data_path, targets_file))\ndf_no_targets = pd.read_csv(os.path.join(data_path, no_targets_file))\n\n# get test data\ndf_test = pd.read_csv(os.path.join(data_path, test_file))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# keep columns names lists\n# columns names = 'sig_id' + 'cp_type' + features_quali + features_quanti + scored_targets + no_scored_targets\nscored_targets = list(set(df_targets.columns) - set(['sig_id']))\nno_scored_targets = list(set(df_no_targets.columns) - set(['sig_id']))\nfeatures_quali = ['cp_time', 'cp_dose']\nfeatures_quanti = list(set(df_features.columns)\n                       - set(scored_targets)\n                       - set(no_scored_targets)\n                       - set(features_quali)\n                       - set(['sig_id', 'cp_type']))\nprint('Scored targets count : {}'.format(len(scored_targets)))\nprint('No scored targets count : {}'.format(len(no_scored_targets)))\nprint('Features quali count : {}'.format(len(features_quali)))\nprint('Features quanti count : {}'.format(len(features_quanti)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# separate features_quanti : gene expression and cell viability features\ncells = [feature_name for feature_name in features_quanti if feature_name.find(\n    'c-') != -1]\ngenes = [feature_name for feature_name in features_quanti if feature_name.find(\n    'g-') != -1]\nprint('Features genes count : {}'.format(len(genes)))\nprint('Features cells count : {}'.format(len(cells)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# check sig_id is unique\ntest = df_features['sig_id'].is_unique\nprint('sig_id unique : {}'.format(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# check nan\ntest = df_features.isnull().values.any()\nprint('Missing data : {}'.format(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare data"},{"metadata":{},"cell_type":"markdown","source":"## Prepare functions"},{"metadata":{"trusted":false},"cell_type":"code","source":"# merge features and targets\ndef merge_features_targets(df_features, df_targets, df_no_targets):\n    df_data = df_features.merge(\n        df_targets, how='left', on='sig_id', validate='one_to_one')\n    df_data = df_data.merge(df_no_targets, how='left',\n                            on='sig_id', validate='one_to_one')\n    print('- Merge features and targets')\n    print('   Data shape : {}'.format(df_data.shape))\n    return df_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# separate compound and control\ndef separate_compound_control(df_data):\n    '''\n    input : dataframe features and targets\n    '''\n    df_compound = df_data[df_data['cp_type'] == 'trt_cp']\n    df_control = df_data[df_data['cp_type'] == 'ctl_vehicle']\n    print('- Separate compound and control')\n    print('   Compound shape : {}'.format(df_compound.shape))\n    print('   Control shape : {}'.format(df_control.shape))\n    return df_compound, df_control","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# onehot encoding qualitatives variables\ndef onehot(df_compound, features_quali, mean=None, std=None, train=True):\n    onehot_data = pd.get_dummies(\n        df_compound[features_quali], columns=['cp_dose'])\n    features_onehot = list(onehot_data.columns)\n    # standardisation 'cp_time'\n    if mean == None:\n        mean = onehot_data['cp_time'].mean()\n    if std == None:\n        std = onehot_data['cp_time'].std()\n    onehot_data['cp_time'] = (onehot_data['cp_time'] - mean) / std\n    # add onehot\n    if train:\n        df_compound = pd.concat([onehot_data, df_compound[[\n                                'sig_id'] + features_quanti + scored_targets + no_scored_targets]], axis=1)\n    else:\n        df_compound = pd.concat(\n            [onehot_data, df_compound[['sig_id'] + features_quanti]], axis=1)\n    print('- Onehot encoding qualitatives variables')\n    return df_compound, mean, std, features_onehot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pipeline"},{"metadata":{"trusted":false},"cell_type":"code","source":"# train set : prepare data pipeline\ndf_data = merge_features_targets(df_features, df_targets, df_no_targets)\ndf_compound_train, df_control_train = separate_compound_control(df_data)\nfeatures = genes + cells\ndf_compound_train, mean, std, features_onehot = onehot(\n    df_compound_train, features_quali)\nprint('Train set : compound shape : {}'.format(df_compound_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# test set : prepare data pipeline\ndf_compound_test, df_control_test = separate_compound_control(df_test)\ndf_compound_test, mean, std, features_onehot = onehot(\n    df_compound_test, features_quali, mean, std, train=False)\nprint('Compound shape : {}'.format(df_compound_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# keep features list\n#features = features_onehot + genes + cells + ['pca_cells']\nfeatures = features_onehot + genes + cells","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# train set\nX_train = df_compound_train[['sig_id'] + features]\nprint(X_train.shape)\nY_train = df_compound_train[scored_targets]\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# test set\nX_test = df_compound_test[['sig_id'] + features]\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# X_train = X_train.head(100)\n# Y_train = Y_train.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LightGBM"},{"metadata":{},"cell_type":"markdown","source":"## Metric"},{"metadata":{"trusted":false},"cell_type":"code","source":"def moa_metric(y_true, y_pred):\n    y_true = y_true.astype('float64')\n    y_pred = y_pred.astype('float64')\n    y_pred = np.maximum(np.minimum(y_pred, 1. - 1e-15), 1e-15)\n    return - np.mean((y_true * np.log(y_pred)) + ((1. - y_true) * np.log(1. - y_pred)))\n\n\n# scikit scorer\nmetric = make_scorer(moa_metric, greater_is_better=False, needs_proba=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find best hyper-parameters by cross-validation and sub-sampling"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Best hyper-parameters\nparameters = {\n    'estimator__n_estimators': [100, 200, 500], \n    'estimator__learning_rate': [0.01, 0.001, 0.0001], \n    'estimator__max_depth': [4, 6, 8],\n    'estimator__subsample': [0.5, 0.75, 1.],  \n    'estimator__colsample_bytree': [0.6, 0.8, 1.]}  \n\n# LigtGBM classifier\nclf_gb = OneVsRestClassifier(LGBMClassifier(), n_jobs=-1)\n\nclf = GridSearchCV(clf_gb,\n                   cv=5,\n                   scoring=metric,\n                   verbose=1,\n                   n_jobs=-1,\n                   return_train_score=True,\n                   param_grid=parameters)\n\n# %time clf.fit(X_train[features].values[:200,...], Y_train[scored_targets].values[:200,...])\n# pd.DataFrame(clf.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# print('Best hyper-parameters : {}'.format(clf.best_params_))\n# print('Metric on val set : {}'.format(clf.best_score_))\n\n# Best hyper-parameters : {'estimator__colsample_bytree': 0.6, 'estimator__learning_rate': 0.01, 'estimator__max_depth': 4, 'estimator__n_estimators': 100, 'estimator__subsample': 0.5}\n# Metric on val set : -0.05989294552932979","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##Â Train LGBM, cross-validation evaluation and predict on test set"},{"metadata":{"trusted":false},"cell_type":"code","source":"# folds\nn_splits = 5\nskf = KFold(n_splits=n_splits, random_state=1, shuffle=True)\n\nlgbm_models = {}\nfeatures_importances = {}\n\n# train each folds\nfor n_fold, (train_index, test_index) in enumerate(skf.split(X_train.values, Y_train.values)):\n    X_train_fold = X_train[features].values[train_index]\n    Y_train_fold = Y_train[scored_targets].values[train_index]\n    X_val_fold = X_train[features].values[test_index]\n    Y_val_fold = Y_train[scored_targets].values[test_index]\n    # define model\n    clf_lgbm = OneVsRestClassifier(LGBMClassifier(colsample_bytree=0.6, # best hyper-parameters\n                                                  learning_rate=0.01,\n                                                  max_depth=4,\n                                                  n_estimators=100,\n                                                  subsample=0.5), n_jobs=-1)\n    # train on train set fold\n    print('Train fold : {}'.format(n_fold + 1))\n    clf_lgbm.fit(X=X_train_fold,\n                 y=Y_train_fold)\n\n    # get features importance for each estimators\n    importances = np.zeros((X_train_fold.shape[1],))\n    for i in range(len(scored_targets)):\n        count_estimators = 0\n        try:  # sometimes no label in dataset and no estimator...\n            importances = importances + \\\n                clf_lgbm.estimators_[i].feature_importances_\n            count_estimators = count_estimators + 1\n        except:\n            pass\n    if count_estimators > 0:\n        importances = importances / count_estimators\n    else:\n        importances = None\n    # save features importance for each fold\n    features_importances['fold_{}'.format(n_fold + 1)] = importances\n\n    # evaluation on train fold\n    Y_pred_train_fold = clf_lgbm.predict_proba(X_train_fold)\n    metric_train_fold = moa_metric(Y_train_fold, Y_pred_train_fold)\n    print('Metric on train fold : {}'.format(metric_train_fold))\n\n    # prediction and evaluation on val fold\n    Y_pred_val_fold = clf_lgbm.predict_proba(X_val_fold)\n    metric_val_fold = moa_metric(Y_val_fold, Y_pred_val_fold)\n    Y_pred_val_fold = pd.DataFrame(Y_pred_val_fold, columns=scored_targets)\n    Y_pred_val_fold['sig_id'] = X_train['sig_id'].values[test_index]\n    print('Metric on validation fold : {}'.format(metric_val_fold))\n\n    # prediction on test set\n    Y_pred_test_fold = clf_lgbm.predict_proba(X_test[features])\n    Y_pred_test_fold = pd.DataFrame(Y_pred_test_fold, columns=scored_targets)\n    Y_pred_test_fold['sig_id'] = X_test['sig_id'].values\n\n    # keep predictions and metric\n    lgbm_models['fold_{}'.format(n_fold + 1)] = [metric_train_fold,\n                                                 metric_val_fold,\n                                                 Y_pred_val_fold[[\n                                                     'sig_id'] + scored_targets],\n                                                 Y_pred_test_fold[['sig_id'] + scored_targets]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# get features importances (used by neural network model)\nimportances = np.array(\n    [importance_fold for importance_fold in features_importances.values()])\nimportances = np.sum(importances, axis=0) / importances.shape[0]\nimportances = importances / np.max(importances)\nimportances.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.hist(importances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"features = features_onehot + genes + cells\ndf_importances = pd.DataFrame(\n    importances, index=features, columns=['importance'])\ndf_importances = df_importances.sort_values(by='importance', ascending=False)\ndf_plot_imp_max = df_importances.head(20)\ndf_plot_imp_min = df_importances.tail(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ax = df_plot_imp_max.plot.bar()\nax.set_title('Features importance from LGBM\\n(10 most important features)')\nax.set_ylabel('Importance')\nax.set_xlabel('Features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ax = df_plot_imp_min.plot.bar()\nax.set_title('Features importance from LGBM\\n(10 least important features)')\nax.set_ylabel('Importance')\nax.set_xlabel('Features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# concatenate prediction on train set folds (used as features during stacking)\ndf_lgbm_pred = pd.concat([model[2] for model in lgbm_models.values()])\ndf_lgbm_pred.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural network"},{"metadata":{},"cell_type":"markdown","source":"## Compute MoA weights from train set\n(needed during loss)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# get moa weights from train set\n# weight : ]0,1] 1 is for less present class\noccurence = np.sum(Y_train[scored_targets].values, axis=0)\nmax_occurence = np.max(occurence)\nweights = 1 + (max_occurence - occurence) / max_occurence\nweights","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weight features from LGBM features importances"},{"metadata":{"trusted":false},"cell_type":"code","source":"# weight features\nX_train[features] = X_train[features].copy() * importances\nX_test[features] = X_test[features].copy() * importances","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define model and weighted loss"},{"metadata":{"trusted":false},"cell_type":"code","source":"# nn architecture\n\n\ndef get_model(input_shape):\n\n    inputs = tf.keras.Input(input_shape)\n    x = tf.keras.layers.BatchNormalization()(inputs)\n    x = tf.keras.layers.Dropout(0.6)(x)\n    x = tf.keras.layers.Dense(2048, activation=\"relu\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.6)(x)\n    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.6)(x)\n    outputs = tf.keras.layers.Dense(\n        len(scored_targets), activation=\"sigmoid\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def tf_moa_metric(y_true, y_pred):\n    y_true = tf.cast(y_true, dtype='float64')\n    y_pred = tf.cast(y_pred, dtype='float64')\n    y_pred = tf.maximum(tf.minimum(y_pred, 1. - 1e-15), 1e-15)\n    return - tf.math.reduce_mean((y_true * tf.math.log(y_pred)) + ((1. - y_true) * tf.math.log(1. - y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# custom loss = weighted loss\ndef tf_moa_loss(y_true, y_pred):\n    y_true = tf.cast(y_true, dtype='float64')\n    y_pred = tf.cast(y_pred, dtype='float64')\n    y_pred = tf.maximum(tf.minimum(y_pred, 1. - 1e-15), 1e-15)\n    log_loss = (y_true * tf.math.log(y_pred)) + \\\n        ((1. - y_true) * tf.math.log(1. - y_pred))\n    log_loss_weighted = log_loss * weights\n    return - tf.math.reduce_mean(log_loss_weighted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset generator"},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_dataset(X_train, Y_train, X_test, Y_test, batch_size):\n    #  train dataset\n    ds_train = tf.data.Dataset.from_tensor_slices(\n        (X_train.astype(float), Y_train.astype(float)))\n    ds_train = ds_train.shuffle(X_train.shape[0])\n    ds_train = ds_train.batch(batch_size)\n    ds_train = ds_train.prefetch(batch_size * 2)\n    # test dataset\n    ds_test = tf.data.Dataset.from_tensor_slices(\n        (X_test.astype(float), Y_test.astype(float)))\n    ds_test = ds_test.batch(X_test.shape[0])\n\n    return ds_train, ds_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train folds"},{"metadata":{"trusted":false},"cell_type":"code","source":"batch_size = 32\nepochs = 75\n\nskf = KFold(n_splits=n_splits, random_state=1, shuffle=True)\nnn_models = {}\n\n# train each folds\nfor n_fold, (train_index, test_index) in enumerate(skf.split(X_train.values, Y_train.values)):\n    X_train_fold = X_train[features].values[train_index]\n    Y_train_fold = Y_train[scored_targets].values[train_index]\n    X_val_fold = X_train[features].values[test_index]\n    Y_val_fold = Y_train[scored_targets].values[test_index]\n\n    # get dataset\n    ds_train, ds_val = get_dataset(\n        X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, batch_size)\n\n    # get model\n    model = get_model(X_train_fold.shape[1])\n\n    # optimizer\n    model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n        loss=tf_moa_loss,\n        metrics=[tf_moa_metric])\n\n    # callback\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, mode='min',\n                                                     patience=5, min_lr=0.00001, verbose=1)\n    checkpoint_path = 'weights_fold_{}.hdf5'.format(n_fold)\n    cb_checkpt = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=0, save_best_only=True,\n                                                    save_weights_only=True, mode='min')\n\n    # train\n    print('Train fold : {}'.format(n_fold + 1))\n    history = model.fit(x=ds_train, epochs=epochs,\n                        validation_data=ds_val, callbacks=[reduce_lr, cb_checkpt])\n\n    # load best weights\n    model.load_weights(checkpoint_path)\n\n    # evaluate on train fold\n    Y_pred_train_fold = model.predict(X_train_fold)\n    metric_train_fold = tf_moa_metric(Y_train_fold, Y_pred_train_fold)\n    print('Metric on train fold : {}'.format(metric_train_fold))\n\n    # predict and evaluate on val fold\n    Y_pred_val_fold = model.predict(X_val_fold)\n    metric_val_fold = tf_moa_metric(Y_val_fold, Y_pred_val_fold)\n    Y_pred_val_fold = pd.DataFrame(Y_pred_val_fold, columns=scored_targets)\n    Y_pred_val_fold['sig_id'] = X_train['sig_id'].values[test_index]\n    print('Metric on validation fold : {}'.format(metric_val_fold))\n\n    # predict on test set\n    Y_pred_test_fold = model.predict(X_test[features])\n    Y_pred_test_fold = pd.DataFrame(Y_pred_test_fold, columns=scored_targets)\n    Y_pred_test_fold['sig_id'] = X_test['sig_id'].values\n\n    # keep predictions and metric\n    nn_models['fold_{}'.format(n_fold + 1)] = [metric_train_fold,\n                                               metric_val_fold,\n                                               Y_pred_val_fold[[\n                                                   'sig_id'] + scored_targets],\n                                               Y_pred_test_fold[['sig_id'] + scored_targets]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# concatenate prediction on train set folds (used as features during stacking)\ndf_nn_pred = pd.concat([nn_model[2] for nn_model in nn_models.values()])\ndf_nn_pred.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stacking : LGBM + NN"},{"metadata":{},"cell_type":"markdown","source":"## Train dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"# sort datasets before merge\ndf_nn_pred = df_nn_pred.sort_values(by='sig_id')\ndf_lgbm_pred = df_lgbm_pred.sort_values(by='sig_id')\n\n# add sig_id features to Y_train\nY_train['sig_id'] = df_compound_train['sig_id'].copy()\nY_train_stack = Y_train.sort_values(by='sig_id')\n\n# merge lgbm and nn\nX_train_stack = df_nn_pred.merge(\n    df_lgbm_pred, how='left', on='sig_id', validate='one_to_one')\nX_train_stack = X_train_stack.sort_values(by='sig_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# define features names\n\nfeatures_stack = list(set(X_train_stack.columns) - set(['sig_id']))\nprint(len(features_stack))\n\nfeatures = list(set(df_lgbm_pred.columns) - set(['sig_id']))\nprint(len(features))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test set"},{"metadata":{"trusted":false},"cell_type":"code","source":"# concatenate and mean LGBM and NN predictions on test set\n\n# nn model\nX_test_nn = pd.concat([nn_model[3] for nn_model in nn_models.values()])\nX_test_nn = X_test_nn.groupby('sig_id').mean()\nX_test_nn = X_test_nn.reset_index(col_fill='sig_id')\n# lgbm model\nX_test_lgbm = pd.concat([lgbm_model[3] for lgbm_model in lgbm_models.values()])\nX_test_lgbm = X_test_lgbm.groupby('sig_id').mean()\nX_test_lgbm = X_test_lgbm.reset_index(col_fill='sig_id')\n\n# merge LGBM and NN features\nX_test_stack = X_test_nn.merge(\n    X_test_lgbm, how='left', on='sig_id', validate='one_to_one')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check LGBM and NN performance on val folds"},{"metadata":{"trusted":false},"cell_type":"code","source":"# val metric nn\nnp.mean([nn_model[1] for nn_model in nn_models.values()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# val metric lgbm\nnp.mean([lgbm_model[1] for lgbm_model in lgbm_models.values()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Logistic Regression on LGBM+NN features"},{"metadata":{"trusted":false},"cell_type":"code","source":"n_splits = 5\nskf = KFold(n_splits=n_splits, random_state=1, shuffle=True)\n\nmodels_stack = {}\n\nfor n_fold, (train_index, test_index) in enumerate(skf.split(X_train_stack.values, Y_train_stack.values)):\n    X_train_fold = X_train_stack[features_stack].values[train_index]\n    Y_train_fold = Y_train[scored_targets].values[train_index]\n    X_val_fold = X_train_stack[features_stack].values[test_index]\n    Y_val_fold = Y_train[scored_targets].values[test_index]\n\n    # get model\n    clf_rl = OneVsRestClassifier(LogisticRegression(n_jobs=-1))\n\n    # train\n    print('Train fold : {}'.format(n_fold + 1))\n    clf_rl.fit(X=X_train_fold,\n               y=Y_train_fold)\n\n    # evaluate on train fold\n    Y_pred_train_fold = clf_rl.predict_proba(X_train_fold)\n    metric_train_fold = moa_metric(Y_train_fold, Y_pred_train_fold)\n    print('Metric on train fold : {}'.format(metric_train_fold))\n\n    # predict and evaluate on val fold\n    Y_pred_val_fold = clf_rl.predict_proba(X_val_fold)\n    metric_val_fold = moa_metric(Y_val_fold, Y_pred_val_fold)\n    Y_pred_val_fold = pd.DataFrame(Y_pred_val_fold, columns=scored_targets)\n    Y_pred_val_fold['sig_id'] = X_train['sig_id'].values[test_index]\n    print('Metric on validation fold : {}'.format(metric_val_fold))\n\n    # predict on test set\n    Y_pred_test_fold = clf_rl.predict_proba(X_test_stack[features_stack])\n    Y_pred_test_fold = pd.DataFrame(Y_pred_test_fold, columns=scored_targets)\n    Y_pred_test_fold['sig_id'] = X_test_stack['sig_id'].values\n\n    # keep predictions and metric\n    models_stack['fold_{}'.format(n_fold + 1)] = [metric_train_fold,\n                                                  metric_val_fold,\n                                                  Y_pred_val_fold[[\n                                                      'sig_id'] + scored_targets],\n                                                  Y_pred_test_fold[['sig_id'] + scored_targets]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"np.mean([model[0] for model in models_stack.values()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Postprocess prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"# concatenate and mean prediction on test dataset\npred_compound = pd.concat([stack_model[3]\n                           for stack_model in models_stack.values()])\npred_compound = pred_compound.groupby('sig_id').mean()\npred_compound = pred_compound.reset_index(col_fill='sig_id')\n\n# add control prediction (equal 0 !) to compound prediction\nY_pred_control = np.zeros((df_control_test.shape[0], len(scored_targets)))\n\n# get sig_id\n#pred_compound = np.concatenate((np.expand_dims(df_compound_test['sig_id'].values, axis=1), Y_pred_compound[:,0:len(scored_targets)]), axis=1)\npred_control = np.concatenate((np.expand_dims(\n    df_control_test['sig_id'].values, axis=1), Y_pred_control), axis=1)\npred_control = pd.DataFrame(pred_control, columns=['sig_id'] + scored_targets)\n\n# merge control pred and control pred\ndf_pred = pd.concat([pred_compound, pred_control], axis=0)\n\n# write submission file\ndf_pred.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot results"},{"metadata":{"trusted":false},"cell_type":"code","source":"# plot\nmodels = ['LGBM', 'NN', 'Stacking']\ntrain = [\n    np.mean([model[0] for model in lgbm_models.values()]),\n    np.mean([model[0] for model in nn_models.values()]),\n    np.mean([model[0] for model in models_stack.values()])\n]\nval = [\n    np.mean([model[1] for model in lgbm_models.values()]),\n    np.mean([model[1] for model in nn_models.values()]),\n    np.mean([model[1] for model in models_stack.values()])\n]\ntest = [0, 0, 0]\n\nx = np.arange(len(models))  # the label locations\nwidth = 1 / len(train)  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(8, 5))\nrects1 = ax.bar(x - width, train, width, label='train')\nrects2 = ax.bar(x, val, width, label='val')\nrects3 = ax.bar(x + width, test, width, label='test')\n\nax.set_ylabel('loss')\nax.set_title('log loss for train, val and test dataset')\nax.set_xticks(x)\nax.set_xticklabels(models)\nax.legend()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}