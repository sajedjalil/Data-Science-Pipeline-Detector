{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing Libraries for EDA\n\n#Importing Libraries\n\n#data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport math\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv',nrows = 200000,parse_dates=[\"pickup_datetime\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(data_train));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data exploration\ndata_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Problem Statement**\n\nIn this playground competition, hosted in partnership with Google Cloud and Coursera, you are tasked with predicting the fare amount (inclusive of tolls) for a taxi ride in New York City given the pickup and dropoff locations. While you can get a basic estimate based on just the distance between the two points, this will result in an RMSE of 5-8 ($)\n\nOur challenge is to do better than this using Machine Learning techniques!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Null value exploration code\nprint(data_train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So we will enter there a median value.\n\nmedian1 = data_train['dropoff_longitude'].median()\ndata_train['dropoff_longitude'].fillna(median1, inplace=True)\n\nmedian2 = data_train['dropoff_latitude'].median()\ndata_train['dropoff_latitude'].fillna(median2, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Its very important to extract distance of a single trip through pickup and drop off locations**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train[\"pickup_longitude\"] = pd.to_numeric(data_train.pickup_longitude, errors='coerce')\ndata_train[\"pickup_latitude\"] = pd.to_numeric(data_train.pickup_latitude, errors='coerce')\ndata_train[\"dropoff_longitude\"] = pd.to_numeric(data_train.dropoff_longitude, errors='coerce')\ndata_train[\"dropoff_latitude\"] = pd.to_numeric(data_train.dropoff_latitude, errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> First of all, We need to calculate the distacne from pickup Latitude,longitude to dropoff latitude,longitude.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import pi,sqrt,sin,cos,atan2\n\ndef haversine(pickUp_lat,pickUp_long,dropOff_lat,dropOff_long):\n    lat1 = pd.to_numeric(pickUp_lat, errors='coerce')\n    long1 = pd.to_numeric(pickUp_long, errors='coerce')\n\n    lat2 = pd.to_numeric(dropOff_lat, errors='coerce')\n    long2 = pd.to_numeric(dropOff_long, errors='coerce')\n\n    #lat1 = pickUp_lat\n    #long1 = pickUp_long\n    #lat2 = dropOff_lat\n    #long2 = dropOff_long\n\n\n    #degree_to_rad = float(pi / 180.0)\n    degree_to_rad =  0.017453292519943295\n    d_lat = (lat2 - lat1) * degree_to_rad\n    d_long = (long2 - long1) * degree_to_rad\n\n    a = pow(np.sin(d_lat / 2), 2) + np.cos(lat1 * degree_to_rad) * np.cos(lat2 * degree_to_rad) * pow(np.sin(d_long / 2), 2)\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n    km = 6367 * c\n    #mi = 3956 * c\n\n    #return km#\"km\":km, \"miles\":mi}\n    return km","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = haversine(40.721319,-73.844311,40.712278,-73.841610)\nprint(\"Distance is {} km\".format(round(res)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Our Function gives correct results, We have tested it through different websites as well. Now the challenge is to apply this formula in data set and extract distance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# add new column to dataframe with distance in miles\ndata_train['distance_km'] = haversine(data_train.pickup_latitude, data_train.pickup_longitude,data_train.dropoff_latitude, data_train.dropoff_longitude)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cool! We got the distance.. Now as suggested, Take information from pickup_datetime as well.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train['year'] = data_train.pickup_datetime.apply(lambda t: t.year)\ndata_train['month'] = data_train.pickup_datetime.apply(lambda t: t.month)\ndata_train['weekday'] = data_train.pickup_datetime.apply(lambda t: t.weekday())\ndata_train['hour'] = data_train.pickup_datetime.apply(lambda t: t.hour)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Some statisitcs\n\n\nstatistics_of_data = []\nfor col in data_train.columns:\n  statistics_of_data.append((col,\n                             data_train[col].nunique(),\n                             data_train[col].isnull().sum()*100/data_train.shape[0],\n                             data_train[col].value_counts(normalize=True, dropna=False).values[0] * 100, \n                             data_train[col].dtype\n                             ))\nstats_df = pd.DataFrame(statistics_of_data, columns=['Feature', 'Uniq_val', 'missing_val', 'val_biggest_cat', 'type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_df.sort_values('val_biggest_cat', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations Are:**\n\npassenger_count have up to 7 unique values, which means 0-6.\n\nWe have data of 7 years\n\nfare amount has 1215 unique values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Now lets explore features one by one\n\ndef exploreFeatures(col):\n  top_n=10\n  top_n = top_n if data_train[col].nunique() > top_n else data_train[col].nunique()\n  #print(f\"{col} has {data_train[col].nunique()} unique values and type: {data_train[col].dtype}.\")\n  #txt2 = \"My name is {0}, I'am {1}\".format(\"John\",36)\n  print(\"col has {0} unique values and type {1}:\".format(data_train[col].nunique(),data_train[col].dtype))\n  print(data_train[col].value_counts(normalize=True, dropna=False).head(10))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('passenger_count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('fare_amount')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('weekday')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('hour')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('distance_km')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('pickup_latitude')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('pickup_longitude')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('dropoff_longitude')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('dropoff_latitude')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exploreFeatures('month')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, Now we need to cater 2 things:\n\nRemove columns having 0 distance covered.\n\nRemove columns having latitudes and longitudes = 0.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train[data_train['distance_km'] == 0.00]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## SO, We will remove them\n\ndata_train = data_train[data_train['distance_km'] != 0.00]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Lets test it\nexploreFeatures('distance_km')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now as we have removed incorrect data, We need to do EDA. Critical thinking for this project may leads to:**\n\nAre there any coordiante which are wrongly planted. i.e. sea comes in between ?\n\nAre there any fare which is absolute. i.e. to and from airport, universty, or at food point ?\n\nAre there any fare which involved having festival on that data, For eg. Christmas.\n\nIs fare amount gradually increased in these years ? i.e. what impact have created form 2009-2015 ? Petrol gets high or low in this period ?\n\nTraffic ? Does traffic have impact on fare ?\n\npassenger_count has any impact or not ?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Any coordiantes wrongly planted ??\n## Does New York City have a beach?\n\n#New York City has 14 miles of beaches, from beauties in the Bronx, to the historical sands of Brooklyn, to surfing in Queens.\n\n#First of all we need to create a boundary (Bounding Box). NYC boundary is:\n\ndata_test = pd.read_csv('../input/new-york-city-taxi-fare-prediction/test.csv')\n\nmindatapoints = min(data_test.pickup_longitude.min(), data_test.dropoff_longitude.min())\nmaxdatapoints = max(data_test.pickup_longitude.max(), data_test.dropoff_longitude.max())\n\nprint(\"minimum LONGITUDE data points {0} maximum data points {1} in NYC\".format(mindatapoints,maxdatapoints))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mindatapointsLAT = min(data_test.pickup_latitude.min(), data_test.dropoff_latitude.min())\nmaxdatapointsLAT = max(data_test.pickup_latitude.max(), data_test.dropoff_latitude.max())\n\nprint(\"minimum LATITUDE data points {0} maximum data points {1} in NYC\".format(mindatapointsLAT,maxdatapointsLAT))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now Creating a Boundary.\n\ndef select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Boundary is :\nBB = (-74.5, -72.8, 40.5, 41.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Old size: %d' % len(data_train))\ndata_train = data_train[select_within_boundingbox(data_train, BB)]\nprint('New size: %d' % len(data_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We have successfully removed all data points which are not in the boundary of NYC.Now we need to remove data points in water, as they are Noisy data-points.\n\ndef remove_datapoints_from_water(df):\n    def lonlat_to_xy(longitude, latitude, dx, dy, BB):\n        return (dx*(longitude - BB[0])/(BB[1]-BB[0])).astype('int'), \\\n               (dy - dy*(latitude - BB[2])/(BB[3]-BB[2])).astype('int')\n\n    # define bounding box\n    BB = (-74.5, -72.8, 40.5, 41.8)\n    \n    # read nyc mask and turn into boolean map with\n    # land = True, water = False\n    nyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\n    \n    # calculate for each lon,lat coordinate the xy coordinate in the mask map\n    pickup_x, pickup_y = lonlat_to_xy(df.pickup_longitude, df.pickup_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)\n    dropoff_x, dropoff_y = lonlat_to_xy(df.dropoff_longitude, df.dropoff_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)    \n    # calculate boolean index\n    idx = nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x]\n    \n    # return only datapoints on land\n    return df[idx]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Old size: %d' % len(data_train))\ndata_train = remove_datapoints_from_water(data_train)\nprint('New size: %d' % len(data_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have removed data points in water successfully. 32 data points were detected.\n\nAre there any fare which is absolute. i.e. to and from airport, universty, or at food point ?\n\n##Working on absolute data points","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"New York City is serviced by three major airports:\n\n> John F. Kennedy International Airport (JFK)\n> \n> LaGuardia Airport (LGA)\n> \n> Newark International Airport (EWR)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Famous Colleges/Universities in NY are:\n\n> Columbia University.\n> \n> Cornell University.\n> \n> New York University.\n> \n> University of Rochester.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Famoous Resturants in NY:\n\n> Bamonte's. Williamsburg. ...\n\n> Balthazar. SoHo. ...\n\n> Di Fara. Midwood. ...\n\n> Gramercy Tavern. Flatiron. ...\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Strat From Airport, Did we find any lead ?\njfkAirport_Corrd = (-73.7822222222, 40.6441666667)\nLGAAirport_Corrd = (-73.87, 40.77)\nEWRAirport_Coord = (-74.175, 40.69)\nnyc = (-74.0063889, 40.7141667)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def absoluteDataPoint(loc, name):\n    range=1.5\n    idx0 = (haversine(data_train.pickup_latitude, data_train.pickup_longitude, loc[1], loc[0]) < range)\n    idx1 = (haversine(data_train.dropoff_latitude, data_train.dropoff_longitude, loc[1], loc[0]) < range)\n    fareAmount_Pickup = data_train[idx0].fare_amount\n    fareAmount_DropOff = data_train[idx1].fare_amount\n    distance_pickup = data_train[idx0].distance_km\n    distance_dropoff = data_train[idx1].distance_km\n    return idx0,idx1,fareAmount_Pickup,fareAmount_DropOff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx0,idx1,fareAmount_Pickup,fareAmount_DropOff = absoluteDataPoint(jfkAirport_Corrd,\"JFK Airport\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx0,idx1,fareAmount_Pickup,fareAmount_DropOff = absoluteDataPoint(EWRAirport_Coord,\"Newark Airport\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx0,idx1,fareAmount_Pickup,fareAmount_DropOff = absoluteDataPoint(LGAAirport_Corrd, 'LaGuardia Airport')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_ToAndFro_airport_JFK_Airport = data_train[(data_train.fare_amount == 57.33) | (data_train.fare_amount == 49.80) | (data_train.fare_amount == 49.57)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_ToAndFro_airport_JFK_Airport.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to this, We see that prices to and from airport was fixed i.e.  49.57ð‘–ð‘›2009âˆ’10,  49.80 in 2011-12 and $ 57.33 in 2013-15. It seems that gas prices were hiked from the end of 2012\n\nFebruary 2012: Concerns about a potential military action against Iran, by either Israel or even the United States, caused high oil prices. Second, some U.S. oil refineries were closing, according to an Environmental Impact Assessment report. Third, oil and gas prices tend to rise every spring, in anticipation of increased demand during the summer.\n\nMarch 2013: Iran started war games near the Strait of Hormuz early in 2013. Almost 20% of the world's oil flows through this narrow checkpoint bordering Iran and Oman. If Iran threatened to close the Strait, it would have raised the fear of a dramatic decline in oil supply. In anticipation of such a crisis, oil traders bid up the price, which reached  118.90ð‘Žð‘ð‘Žð‘Ÿð‘Ÿð‘’ð‘™ð‘œð‘›ð¹ð‘’ð‘ð‘Ÿð‘¢ð‘Žð‘Ÿð‘¦8.ðºð‘Žð‘ ð‘ð‘Ÿð‘–ð‘ð‘’ð‘ ð‘ ð‘œð‘œð‘›ð‘“ð‘œð‘™ð‘™ð‘œð‘¤ð‘’ð‘‘,ð‘Ÿð‘–ð‘ ð‘–ð‘›ð‘”ð‘¡ð‘œ 3.85 a gallon by February 25. These rose again in August 2013 because oil prices hit a 15-month high that summer. That spike was created by political unrest in Egypt.\n\nSources: https://www.thebalance.com/why-are-gas-prices-so-high-3305653","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This is the end of EDA of NYC Taxi Fare, I have enjoyed and learned a lot while creating this notebook. A note book which helped me alot is the masterpiece by **\"Albert van Breemen\"**, His notebook's link is:  https://www.kaggle.com/breemen/nyc-taxi-fare-data-exploration. \n\nI have worked hard for this notebook, Hope this will be helpful for you. Up vote this notebook if you like it. Thanks.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}