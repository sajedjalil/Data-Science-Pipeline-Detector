{"cells":[{"metadata":{"_uuid":"b4578d48b219735043a4d2102119fb307d2fc83f"},"cell_type":"markdown","source":"# This is a basic Starter Kernel for the New York City Taxi Fare Prediction Playground Competition \nHere we'll use a simple linear model based on the travel vector from the taxi's pickup location to dropoff location which predicts the `fare_amount` of each ride.\n\nThis kernel uses some `pandas` and mostly `numpy` for the critical work.  There are many higher-level libraries you could use instead, for example `sklearn` or `statsmodels`.  "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Initial Python environment setup...\nimport numpy as np # linear algebra\nimport pandas as pd # CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport time\nimport os # reading the input files we have access to\n\nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb969a26e52931bcaced3cbb7a36d8d8b1b04556"},"cell_type":"markdown","source":"### Setup training data\nFirst let's read in our training data.  Kernels do not yet support enough memory to load the whole dataset at once, at least using `pd.read_csv`.  The entire dataset is about 55M rows, so we're skipping a good portion of the data, but it's certainly possible to build a model using all the data."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df =  pd.read_csv('../input/train.csv', nrows = 10_000_000)\ntrain_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/test.csv')\ntest_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25df18156ed90f583efdbbc028c58a9d2bdfdc7b"},"cell_type":"markdown","source":"Let's create two new features in our training set representing the \"travel vector\" between the start and end points of the taxi ride, in both longitude and latitude coordinates.  We'll take the absolute value since we're only interested in distance traveled. Use a helper function since we'll want to do the same thing for the test set later."},{"metadata":{"trusted":true,"_uuid":"59f0595db44dd60044cfd0404824651a7c2bee87"},"cell_type":"code","source":"# Given a dataframe, add two new features 'abs_diff_longitude' and\n# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n# the pickup location to the dropoff location.\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(train_df)\nadd_travel_vector_features(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Before Dropping null values: {len(train_df)}')\ntrain_df.dropna(inplace=True)\nprint(f'After Dropping null values: {len(train_df)}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1dbc7610bd467f1dfaf9042b5ec638eb2014aaf"},"cell_type":"markdown","source":"### Explore and prune outliers\nFirst let's see if there are any `NaN`s in the dataset."},{"metadata":{"trusted":true,"_uuid":"e808c7e75338b45ca30f9f261dfbc90845700624"},"cell_type":"code","source":"print(train_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29bc86f2fa8baa37f0c4eb4300f77a8cb69f12aa"},"cell_type":"markdown","source":"There are a small amount, so let's remove them from the dataset."},{"metadata":{"trusted":true,"_uuid":"9d8f28e24f3d4ca55ad93692329680774c341376"},"cell_type":"code","source":"print('Old size: %d' % len(train_df))\ntrain_df = train_df.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(train_df))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a045ef14c636ec726a5e8c349ca7e5fbb3a87c1"},"cell_type":"markdown","source":"Now let's quickly plot a subset of our travel vector features to see its distribution."},{"metadata":{"trusted":true,"_uuid":"97d0aa1deab1c6cf0c97a4a3a12ba7007aada6c5"},"cell_type":"code","source":"plot = train_df.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22277d77f75e3177a5acaec9b820e0de6e869663"},"cell_type":"markdown","source":"We expect most of these values to be very small (likely between 0 and 1) since it should all be differences between GPS coordinates within one city.  For reference, one degree of latitude is about 69 miles.  However, we can see the dataset has extreme values which do not make sense.  Let's remove those values from our training set. Based on the scatterplot, it looks like we can safely exclude values above 5 (though remember the scatterplot is only showing the first 2000 rows...)"},{"metadata":{"trusted":true,"_uuid":"9703895e6c7e67b32c504f843b5ef19be2023964"},"cell_type":"code","source":"print('Old size: %d' % len(train_df))\ntrain_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\nprint('New size: %d' % len(train_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb752441a1c1ce3e01d78452389ec48c95d52dc6"},"cell_type":"code","source":"def creating_time(df):\n    ls1=list(df['pickup_datetime'])\n    for i in range(len(ls1)):\n        ls1[i]=ls1[i][11:-7:]\n    df['pickuptime']=ls1    \n\ncreating_time(train_df)\ncreating_time(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def creating_weekdays(df):\n    ls1=list(df['pickup_datetime'])\n    for i in range(len(ls1)):\n        ls1[i]=ls1[i][:-4:]\n        ls1[i]=pd.Timestamp(ls1[i])\n        ls1[i]=ls1[i].weekday()\n    df['Weekday']=ls1\n\ncreating_weekdays(train_df)\ncreating_weekdays(test_df)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop('pickup_datetime',inplace=True,axis=1)\ntest_df.drop('pickup_datetime',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_weekday(df):\n    df['Weekday'].replace(to_replace=[i for i in range(0,7)],\n                                value=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],\n                                  inplace=True)\nreplace_weekday(train_df)\nreplace_weekday(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_one_hot=pd.get_dummies(train_df['Weekday'])\ntest_one_hot=pd.get_dummies(test_df['Weekday'])\ntrain_df=pd.concat([train_df,train_one_hot],axis=1)\ntest_df=pd.concat([test_df,test_one_hot],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop('Weekday',axis=1,inplace=True)\ntest_df.drop('Weekday',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def creating_pickupdate(df):\n    ls1=list(df['pickuptime'])\n    for i in range(len(ls1)):\n        z=ls1[i].split(':')\n        ls1[i]=int(z[0])*100+int(z[1])\n    df['pickuptime']=ls1\n\ncreating_pickupdate(train_df)\ncreating_pickupdate(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def finding_distance(df):\n    R = 6373.0\n    lat1 =np.asarray(np.radians(df['pickup_latitude']))\n    lon1 = np.asarray(np.radians(df['pickup_longitude']))\n    lat2 = np.asarray(np.radians(df['dropoff_latitude']))\n    lon2 = np.asarray(np.radians(df['dropoff_longitude']))\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    ls1=[] \n    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/ 2)**2\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n    distance = R * c\n\n    \n    df['Distance']=np.asarray(distance)*0.621\n\nfinding_distance(train_df)\nfinding_distance(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def creating_pickup_dropoff_distance(df):\n    R = 6373.0\n    lat1 =np.asarray(np.radians(df['pickup_latitude']))\n    lon1 = np.asarray(np.radians(df['pickup_longitude']))\n    lat2 = np.asarray(np.radians(df['dropoff_latitude']))\n    lon2 = np.asarray(np.radians(df['dropoff_longitude']))\n\n    lat3=np.zeros(len(df))+np.radians(40.6413111)\n    lon3=np.zeros(len(df))+np.radians(-73.7781391)\n    dlon_pickup = lon3 - lon1\n    dlat_pickup = lat3 - lat1\n    d_lon_dropoff=lon3 -lon2\n    d_lat_dropoff=lat3-lat2\n    a1 = np.sin(dlat_pickup/2)**2 + np.cos(lat1) * np.cos(lat3) * np.sin(dlon_pickup/ 2)**2\n    c1 = 2 * np.arctan2(np.sqrt(a1), np.sqrt(1 - a1))\n    distance1 = R * c1\n    df['Pickup_Distance_airport']=np.asarray(distance1)*0.621\n\n    a2=np.sin(d_lat_dropoff/2)**2 + np.cos(lat2) * np.cos(lat3) * np.sin(d_lon_dropoff/ 2)**2\n    c2 = 2 * np.arctan2(np.sqrt(a2), np.sqrt(1 - a2))\n    distance2 = R * c2\n\n    \n    df['Dropoff_Distance_airport']=np.asarray(distance2)*0.621\n\ncreating_pickup_dropoff_distance(train_df)\ncreating_pickup_dropoff_distance(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Distance']=np.round(train_df['Distance'],2)\ntrain_df['Pickup_Distance_airport']=np.round(train_df['Pickup_Distance_airport'],2)\ntrain_df['Dropoff_Distance_airport']=np.round(train_df['Dropoff_Distance_airport'],2)\ntest_df['Distance']=np.round(test_df['Distance'],2)\ntest_df['Pickup_Distance_airport']=np.round(test_df['Pickup_Distance_airport'],2)\ntest_df['Dropoff_Distance_airport']=np.round(test_df['Dropoff_Distance_airport'],2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)\ntest_df.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['abs_diff_longitude']=np.abs(train_df['abs_diff_longitude']-np.mean(train_df['abs_diff_longitude']))\ntrain_df['abs_diff_longitude']=train_df['abs_diff_longitude']/np.var(train_df['abs_diff_longitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['abs_diff_latitude']=np.abs(train_df['abs_diff_latitude']-np.mean(train_df['abs_diff_latitude']))\ntrain_df['abs_diff_latitude']=train_df['abs_diff_latitude']/np.var(train_df['abs_diff_latitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['abs_diff_longitude']=np.abs(test_df['abs_diff_longitude']-np.mean(test_df['abs_diff_longitude']))\ntest_df['abs_diff_longitude']=test_df['abs_diff_longitude']/np.var(test_df['abs_diff_longitude'])\n\ntest_df['abs_diff_latitude']=np.abs(test_df['abs_diff_latitude']-np.mean(test_df['abs_diff_latitude']))\ntest_df['abs_diff_latitude']=test_df['abs_diff_latitude']/np.var(test_df['abs_diff_latitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=train_df.drop(['key','fare_amount'],axis=1)\ny=train_df['fare_amount']\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.01,random_state=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression(normalize=True)\nlr.fit(X_train,y_train)\nprint(lr.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=np.round(lr.predict(test_df.drop('key',axis=1)),2)\nprint(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission = pd.DataFrame(data = pred,columns = ['fare_amount'])\nSubmission['key'] = test_df['key']\nSubmission = Submission[['key','fare_amount']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.set_index('key', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.to_csv('Submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}