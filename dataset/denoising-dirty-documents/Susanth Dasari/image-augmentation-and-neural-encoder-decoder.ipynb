{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip uninstall imgaug\n!pip install --upgrade albumentations\n!pip install git+https://github.com/aleju/imgaug.git\n# !pip install --upgrade imgaug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport glob \n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\n\nimport imageio\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\nimport cv2\n\nfrom keras.preprocessing import image\nfrom keras.models import Model, load_model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, LeakyReLU\nfrom keras.layers import MaxPooling2D, Dropout, UpSampling2D\nfrom keras import regularizers\nimport keras.backend as K\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 5.0) # set default size of plots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"!unzip ../input/denoising-dirty-documents/test.zip\n!unzip ../input/denoising-dirty-documents/train.zip\n!unzip ../input/denoising-dirty-documents/train_cleaned.zip"},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\n\n# Will unzip the files so that you can see them..\nzipfiles = ['train','test','train_cleaned', 'sampleSubmission.csv']\n\nfor each_zip in zipfiles:\n    with zipfile.ZipFile(\"../input/denoising-dirty-documents/\"+each_zip+\".zip\",\"r\") as z:\n        z.extractall(\".\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bsb = img.imread('/kaggle/working/train/216.png')\n# test = img.imread('../kaggle/working/test/1.png')\nplt.imshow(bsb, cmap=plt.cm.gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_width = 540\ntarget_height = 420","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image_from_dir(img_path):\n    file_list = glob.glob(img_path+'/*.png')\n    file_list.sort()\n    img_list = np.empty((len(file_list), target_height, target_width, 1))\n    for i, fig in enumerate(file_list):\n        img = image.load_img(fig, color_mode='grayscale', target_size=(target_height, target_width))\n        img_array = image.img_to_array(img).astype('float32')\n        img_array = img_array / 255.0\n        img_list[i] = img_array\n    \n    return img_list\n\ndef train_test_split(data,random_seed=55,split=0.75):\n    set_rdm = np.random.RandomState(seed=random_seed)\n    dsize = len(data)\n    ind = set_rdm.choice(dsize,dsize,replace=False)\n    train_ind = ind[:int(0.75*dsize)]\n    val_ind = ind[int(0.75*dsize):]\n    return data[train_ind],data[val_ind]\n\ndef augment_pipeline(pipeline, images, seed=5):\n    ia.seed(seed)\n    processed_images = images.copy()\n    for step in pipeline:\n        temp = np.array(step.augment_images(images))\n        processed_images = np.append(processed_images, temp, axis=0)\n    return(processed_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_train = load_image_from_dir('/kaggle/working/train')\nfull_target = load_image_from_dir('/kaggle/working/train_cleaned')\n# test = load_image_from_dir('/kaggle/working/test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rotate90 = iaa.Rot90(1, name=\"Rotate90\") # rotate image 90 degrees\nrotate180 = iaa.Rot90(2, name=\"Rotate180\") # rotate image 180 degrees\nrotate270 = iaa.Rot90(3, name=\"Rotate270\") # rotate image 270 degrees\nrandom_rotate = iaa.Rot90((1,3), name=\"RandomRotate\") # randomly rotate image from 90,180,270 degrees\nperc_transform = iaa.PerspectiveTransform(scale=(0.02, 0.1), name=\"Perc_transform\") # Skews and transform images without black bg\nrotate10 = iaa.Affine(rotate=(10), name=\"Rotate10\") # rotate image 10 degrees\nrotate10r = iaa.Affine(rotate=(-10), name=\"Rotate10r\") # rotate image 30 degrees in reverse\ncrop = iaa.Crop(px=(5, 32), name=\"RandomCrop\") # Crop between 5 to 32 pixels\nhflip = iaa.Fliplr(1, name=\"Flip_horizontal\") # horizontal flips for 100% of images\nvflip = iaa.Flipud(1, name=\"Filp_vertical\") # vertical flips for 100% of images\ngblur = iaa.GaussianBlur(sigma=(1, 1.5), name=\"Gaussian_blur\") # gaussian blur images with a sigma of 1.0 to 1.5\nmotionblur = iaa.MotionBlur(8, name=\"Motion_blur\") # motion blur images with a kernel size 8\n\nseq_rp = iaa.Sequential([\n    iaa.Rot90((1,3)), # randomly rotate image from 90,180,270 degrees\n    iaa.PerspectiveTransform(scale=(0.02, 0.1)) # Skews and transform images without black bg\n], name=\"Combination1\")\n\nseq_cfg = iaa.Sequential([\n    iaa.Crop(px=(5, 32)), # crop images from each side by 5 to 32px (randomly chosen)\n    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n    iaa.GaussianBlur(sigma=(0, 1.5)) # blur images with a sigma of 0 to 1.5\n], name=\"Combination2\")\n\nseq_fm = iaa.Sequential([\n    iaa.Flipud(1), # vertical flips all the images\n    iaa.MotionBlur(k=6) # motion blur images with a kernel size 6\n], name=\"Combination3\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_autoencoder(optimizer):\n    K.clear_session()\n    ### Multi layer auto encoder with LeakyRelu and Normalization\n    input_layer = Input(shape=(None,None,1))\n\n    # encoder\n    e = Conv2D(32, (3, 3), padding='same')(input_layer)\n    e = LeakyReLU(alpha=0.3)(e)\n    e = BatchNormalization()(e)\n    e = Conv2D(64, (3, 3), padding='same')(e)\n    e = LeakyReLU(alpha=0.3)(e)\n    e = BatchNormalization()(e)\n    e = Conv2D(64, (3, 3), padding='same')(e)\n    e = LeakyReLU(alpha=0.3)(e)\n    e = MaxPooling2D((2, 2), padding='same')(e)\n\n    # decoder\n    d = Conv2D(64, (3, 3), padding='same')(e)\n    d = LeakyReLU(alpha=0.3)(d)\n    d = BatchNormalization()(d)\n\n    d = Conv2D(64, (3, 3), padding='same')(d)\n    d = LeakyReLU(alpha=0.3)(d)\n    # e = BatchNormalization()(e)\n    d = UpSampling2D((2, 2))(d)\n    d = Conv2D(32, (3, 3), padding='same')(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # d = Conv2D(128, (3, 3), padding='same')(d)\n    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(d)\n\n    model = Model(input_layer,output_layer)\n    model.compile(loss='mse', optimizer=optimizer)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment_testing(pipeline, train_images, target_images, seed=6):\n    results = []\n    ia.seed(seed)\n    train, val = train_test_split(train_images, random_seed=seed, split=0.8)\n    target_train, target_val = train_test_split(target_images, random_seed=seed, split=0.8)\n\n\n    optimizer = Adam(lr=1e-4)\n    AEmodel = build_autoencoder(optimizer)\n    AEmodel.fit(train, target_train, batch_size=8, epochs=20, verbose=0)\n    val_loss = AEmodel.evaluate(val, target_val, verbose=0)\n    train_loss = AEmodel.evaluate(train, target_train, verbose=0)\n    results.append({'Augmentation':'Original','Val_mse':val_loss,'Train_mse':train_loss})\n    \n    processed_train = train.copy()\n    processed_target = target_train.copy()\n    for step in pipeline:\n\n        temp1 = np.array(step.augment_images(train))\n        processed_train = np.append(processed_train, temp1, axis=0)\n        temp2 = np.array(step.augment_images(target_train))\n        processed_target = np.append(processed_target, temp2, axis=0)\n        \n#         print(processed_train.shape)\n\n        AEmodel = build_autoencoder(optimizer)\n        AEmodel.fit(processed_train, processed_target,\n                    validation_data = (val, target_val), batch_size=8, epochs=20, verbose=0)\n\n        val_loss = AEmodel.evaluate(val, target_val, verbose=0)\n        train_loss = AEmodel.evaluate(processed_train, processed_target, verbose=0)\n        results.append({'Augmentation':step.name,'Val_mse':val_loss,'Train_mse':train_loss})\n\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pipeline = []\n# pipeline.append(rotate90)\n# pipeline.append(rotate180)\n# pipeline.append(rotate270)\n# # pipeline.append(random_rotate)\n# pipeline.append(perc_transform)\n# # pipeline.append(rotate10)\n# # pipeline.append(rotate10r)\n# pipeline.append(crop)\n# pipeline.append(hflip)\n# pipeline.append(vflip)\n# pipeline.append(gblur)\n# pipeline.append(motionblur)\n# # pipeline.append(seq_rp)\n# pipeline.append(seq_cfg)\n# pipeline.append(seq_fm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = []\npipeline.append(perc_transform)\npipeline.append(motionblur)\npipeline.append(seq_rp)\npipeline.append(seq_cfg)\npipeline.append(rotate180)\npipeline.append(random_rotate)\n# pipeline.append(rotate10)\n# pipeline.append(rotate10r)\n# pipeline.append(crop)\npipeline.append(hflip)\npipeline.append(vflip)\npipeline.append(gblur)\npipeline.append(seq_fm)\npipeline.append(rotate90)\npipeline.append(rotate270)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nresults = augment_testing(pipeline, full_train, full_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultsdf = pd.DataFrame(results)\nresultsdf.to_csv(\"Progressive Augment results.csv\")\nresultsdf.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(resultsdf.shape[0]), resultsdf['Val_mse'])\nplt.plot(range(resultsdf.shape[0]), resultsdf['Train_mse'])\nplt.title('Progressive Augmentation vs Loss')\nplt.ylabel('MSE')\nplt.xlabel('Number of Augmentations')\nplt.xticks(range(resultsdf.shape[0]), range(resultsdf.shape[0]))\nplt.legend(['Train','Val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# processed_train = augment_pipeline(pipeline, full_train.reshape(-1,target_height,target_width))\n# processed_target = augment_pipeline(pipeline, full_target.reshape(-1,target_height,target_width))\n\n# processed_train = processed_train.reshape(-1,target_height,target_width,1)\n# processed_target = processed_target.reshape(-1,target_height,target_width,1)\n\n# processed_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train, val = train_test_split(processed_train, random_seed=9, split=0.8)\n# target_train, target_val = train_test_split(processed_target, random_seed=9, split=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train, val = train_test_split(full_train, random_seed=9, split=0.8)\n# target_train, target_val = train_test_split(full_target, random_seed=9, split=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# pre_train, pre_val = train_test_split(full_train, random_seed=9, split=0.7)\n# pre_target_train, pre_target_val = train_test_split(full_target, random_seed=9, split=0.7)\n\n# print(pre_train.shape,pre_val.shape)\n\n# train = augment_pipeline(pipeline, pre_train.reshape(-1,target_height,target_width), seed=10)\n# target_train = augment_pipeline(pipeline, pre_target_train.reshape(-1,target_height,target_width), seed=10)\n\n# train = train.reshape(-1,target_height,target_width,1)\n# target_train = target_train.reshape(-1,target_height,target_width,1)\n\n# val_pipeline = pipeline + [seq_fm]\n\n# val = augment_pipeline(val_pipeline, pre_val.reshape(-1,target_height,target_width))\n# target_val = augment_pipeline(val_pipeline, pre_target_val.reshape(-1,target_height,target_width))\n\n# val = val.reshape(-1,target_height,target_width,1)\n# target_val = target_val.reshape(-1,target_height,target_width,1)\n\n# print(\"Shape of Train set:\",train.shape)\n# print(\"Shape of Validation set:\",val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimizer = Adam(lr=9e-4, decay=1e-5)\n# # optimizer = Adam(lr=1e-4, decay=7e-6)\n# # AEmodel = Model(input_layer,output_layer)\n# AEmodel = build_autoencoder(optimizer)\n# # AEmodel.compile(loss='mse', optimizer=optimizer)\n# AEmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# early_stopping = EarlyStopping(monitor='val_loss',\n#                                min_delta=0,\n#                                patience=30,\n#                                verbose=1, \n#                                mode='auto')\n\n# checkpoint1 = ModelCheckpoint('best_val_loss.h5',\n#                              monitor='val_loss',\n#                              save_best_only=True)\n\n# checkpoint2 = ModelCheckpoint('best_loss.h5',\n#                              monitor='loss',\n#                              save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = AEmodel.fit(processed_train, processed_target,\n#                       batch_size=16,\n#                       epochs=300,\n# #                       validation_split=0.2,\n#                       callbacks=[checkpoint2])\n# #                                      validation_data=(val, target_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('Model loss')\n# plt.ylabel('Loss')\n# plt.xlabel('Epoch')\n# plt.legend(['Train','Val'], loc='upper left')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AEmodel.save('AutoEncoderModelFull.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # full_model_preds = AEmodel.predict(test)\n# full_train_preds = AEmodel.predict(full_train)\n\n# AEmodel.load_weights('best_loss.h5')\n# AEmodel.compile(loss='mse', optimizer=optimizer)\n# # preds = AEmodel.predict(test)\n# train_preds = AEmodel.predict(full_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AEmodel.evaluate(full_train, full_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AEmodel.save('AutoEncoderModelBestLoss.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bsb = img.imread('https://github.com/sampath9dasari/GSU/raw/master/denoise_test.png')\n# # test = img.imread('../kaggle/working/test/1.png')\n# plt.imshow(bsb, cmap=plt.cm.gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # ii = cv2.imread(\"https://github.com/sampath9dasari/GSU/raw/master/denoise_test.png\")\n# gray_image = cv2.cvtColor(bsb, cv2.COLOR_BGR2GRAY)\n# # print(gray_image)\n# plt.imshow(gray_image,cmap=plt.cm.gray)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gpred = AEmodel.predict(gray_image.reshape(1,1599,1200,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(1,2,figsize=(22,12))\n# ax[0].imshow(gray_image, cmap=plt.cm.gray)\n# ax[1].imshow(gpred.reshape(1600,1200), cmap=plt.cm.gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(3,2,figsize=(22,16))\n# ax[0][0].imshow(full_train[42].reshape(target_height,target_width), cmap=plt.cm.gray)\n# ax[0][1].imshow(full_target[42].reshape(target_height,target_width), cmap=plt.cm.gray)\n# ax[1][0].imshow(full_train_preds[42].reshape(target_height,target_width), cmap=plt.cm.gray)\n# ax[1][1].imshow(train_preds[42].reshape(target_height,target_width), cmap=plt.cm.gray)\n# reshape = cv2.resize(full_train_preds[42],(target_width,258))\n# ax[2][0].imshow(reshape.reshape(258,target_width), cmap=plt.cm.gray)\n# reshape = cv2.resize(train_preds[42],(target_width,258))\n# ax[2][1].imshow(reshape.reshape(258,target_width), cmap=plt.cm.gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# ids = []\n# vals = []\n# file_list = glob.glob('/kaggle/working/test/*.png')\n# file_list.sort()\n# for i, f in enumerate(file_list):\n#     file = os.path.basename(f)\n#     imgid = int(file[:-4])\n#     test_img = cv2.imread(f, 0)\n#     img_shape = test_img.shape\n# #     print('processing: {}'.format(imgid))\n# #     print(img_shape)\n#     preds_reshaped = cv2.resize(preds[i], (img_shape[1], img_shape[0]))\n#     for r in range(img_shape[0]):\n#         for c in range(img_shape[1]):\n#             ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n#             vals.append(preds_reshaped[r, c])\n\n# print('Writing to csv file')\n# pd.DataFrame({'id': ids, 'value': vals}).to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Load and Scale test images into one big list.\n# file_list = glob.glob('/kaggle/working/test/*.png')\n# file_list.sort()\n# test_size = len(file_list)\n\n# #initailize data arrays.\n# img_ids = []\n# test = []\n\n# #read data\n# for i, img_dir in enumerate(file_list):\n#     file = os.path.basename(img_dir)\n#     imgid = int(file[:-4])\n#     img_ids.append(imgid)\n#     img_pixels = image.load_img(img_dir, color_mode='grayscale')\n#     w, h = img_pixels.size\n#     test.append(np.array(img_pixels).reshape(1, h, w, 1) / 255.)\n    \n# print('Test sample shape: ', test[0].shape)\n# print('Test sample dtype: ', test[0].dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Predict test images one by one and store them into a list.\n# test_preds = []\n# for img in test:\n#     test_preds.append(AEmodel.predict(img)[0, :, :, 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(1,2,figsize=(22,12))\n# ax[0].imshow(test[45].reshape(test[45].shape[1],test[45].shape[2]), cmap=plt.cm.gray)\n# ax[1].imshow(test_preds[45].reshape(test[45].shape[1],test[45].shape[2]), cmap=plt.cm.gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(1,2,figsize=(16,8))\n# ax[0].imshow(test[42].reshape(test[42].shape[1],test[42].shape[2]), cmap=plt.cm.gray)\n# ax[1].imshow(test_preds[42].reshape(test[42].shape[1],test[42].shape[2]), cmap=plt.cm.gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # First column will be raw data, second column will be the corresponding cleaned images.\n# f, ax = plt.subplots(2,3, figsize=(20,10))\n# f.subplots_adjust(hspace = .1, wspace=.05)\n# for i, (img, lbl) in enumerate(zip(test[:3], test_preds[:3])):\n#     ax[0, i].imshow(img[0,:,:,0], cmap='gray')\n#     ax[0, i].title.set_text('Original Image')\n#     ax[0, i].axis('off')\n\n#     ax[1, i].imshow(lbl, cmap='gray')\n#     ax[1, i].title.set_text('Cleaned Image')\n#     ax[1, i].axis('off')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Flatten the 'test_preds' list into 1-d list for submission.\n# submit_vector = []\n# submit_ids = []\n# for imgid, img in zip(img_ids,test_preds):\n#     h, w = img.shape\n#     for c in range(w):\n#         for r in range(h):\n#             submit_ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n#             submit_vector.append(img[r,c])\n# print(len(submit_vector))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(submit_vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_csv = pd.read_csv('/kaggle/working/sampleSubmission.csv')\n# sample_csv.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# id_col = sample_csv['id']\n# value_col = pd.Series(submit_vector, name='value')\n# submission = pd.concat([id_col, value_col], axis=1)\n# submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import shutil\n\n# shutil.rmtree('/kaggle/working/train')\n# shutil.rmtree('/kaggle/working/test')\n# shutil.rmtree('/kaggle/working/train_cleaned')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}