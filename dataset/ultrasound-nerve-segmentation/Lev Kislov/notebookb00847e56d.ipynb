{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Installs","metadata":{}},{"cell_type":"code","source":"!pip install segmentation_models_pytorch\n!git clone https://github.com/Bjarten/early-stopping-pytorch.git\n!mv ./early-stopping-pytorch ./lib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import torch, torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nimport random\nimport os \nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n\nimport math\nimport sys\nimport cv2\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as mpplot\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\n\nimport segmentation_models_pytorch as smp\nfrom lib.pytorchtools import *\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\ntorch.backends.cudnn.deterministic = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/ultrasound-nerve-segmentation/\"\n\ntrain_path = os.path.join(path, \"train\")\ntest_path = os.path.join(path, \"test\")\n\nmasks = [os.path.join(train_path,i) for i in os.listdir(train_path) if \"mask\" in i]\nimgs = [i.replace(\"_mask\",\"\") for i in masks]\n\ndf = pd.DataFrame({\"images\":imgs,\"masks\":masks})\n\ntrain_df, val_df = train_test_split(df,test_size = 0.20)\n\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.images = df.images.tolist()\n        self.masks = df.masks.tolist()\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        image_name = self.images[idx]\n        mask_name = self.masks[idx]\n       \n        image = Image.open(image_name)\n        mask = Image.open(mask_name)  \n    \n        if self.transform:\n            image = self.transform(image)\n            mask = self.transform(mask)\n    \n        return image, mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = transforms.Compose([\n    transforms.Resize(size=(224, 224)),\n    transforms.ToTensor()\n])\n\nbatch_size = 16\n\ntrain_dataset = Dataset(train_df, data_transforms)\nval_dataset = Dataset(val_df, data_transforms)\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint('train', len(train_dataloader), len(train_dataset))\nprint('val', len(val_dataloader), len(val_dataset))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_input(data, n):\n    fig = plt.figure(figsize=(5, 5))\n        \n    for i in range(1, n + 1):\n        img_ax = fig.add_subplot(2, n, i)\n        msk_ax = fig.add_subplot(2, n, i + n)\n        \n        image = data[i-1][0].permute(1, 2, 0).numpy()\n        mask = data[i-1][1].permute(1, 2, 0).numpy()\n        \n        img_ax.imshow(image, cmap='gray')\n        msk_ax.imshow(mask, cmap='gray')\n        \n    fig.show()\n\nshow_input(train_dataset, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"model = smp.Unet(\n    encoder_name='resnet34',\n    encoder_weights='imagenet',\n    in_channels=1,\n    classes=1,\n    activation='sigmoid'\n)\n\nloss = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU()]\n\nlearning_rate = 0.001\nepochs = 50\n\nstopper = EarlyStopping(patience=3)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n\nloss_function = smp.utils.losses.DiceLoss()\n\ntrain_epoch = smp.utils.train.TrainEpoch(model,\n                                          loss=loss_function,\n                                          optimizer=optimizer,\n                                          metrics=metrics,\n                                          device=device,\n                                          verbose=True)\nval_epoch = smp.utils.train.ValidEpoch(model,\n                                          loss=loss_function,\n                                          metrics=metrics,\n                                          device=device,\n                                          verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"model.to(device)\ntrain_loss_history = []\nval_loss_history= []\n\ntrain_iou_history = []\nval_iou_history = []\n\nfor epoch in range(epochs):\n    print('\\nEpoch: {}'.format(epoch))\n    train_log = train_epoch.run(train_dataloader)\n    val_log = val_epoch.run(val_dataloader)\n\n    scheduler.step()\n\n    train_loss_history.append(train_log[loss_function.__name__])\n    val_loss_history.append(val_log[loss_function.__name__])\n\n    train_iou_history.append(train_log['iou_score']) \n    val_iou_history.append(val_log['iou_score'])\n\n    stopper(val_log[loss_function.__name__], model)\n    if stopper.early_stop:\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Vizualize","metadata":{}},{"cell_type":"code","source":"def visualize_train(train, val, title):\n    plt.plot(range(len(train)), train, label = 'Train')\n    plt.plot(range(len(val)), val, label = 'Val')\n    \n    plt.ylabel(title)\n    plt.xlabel('epoch')\n    \n    plt.legend(title)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_train(train_loss_history, val_loss_history, 'Loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_train(train_iou_history, val_iou_history, 'IoU')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encoding(x):\n    dots = np.where(x.T.flatten()==1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs = [f for f in os.listdir(test_path)]\nimgs = sorted( imgs, key=lambda s: int(s.split('.')[0]))\n\nsubmission_df = pd.DataFrame(columns=['img', 'pixels'])\nmodel.to(device)\nmodel.eval()\n\nfor i, img in enumerate(tqdm(imgs)):\n    x = Image.open(os.path.join(test_path, img))\n\n    x = data_transforms(x)\n\n    x = x.unsqueeze(0).to(device)\n    prediction = model.predict(x)\n\n    prediction = prediction.cpu()\n    prediction = transforms.Resize(size=(420, 580))(prediction)\n\n    encoding = rle_encoding(prediction)\n\n    pixels = ' '.join(map(str, encoding))\n    submission_df.loc[i] = [str(i+1), pixels]\n\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}