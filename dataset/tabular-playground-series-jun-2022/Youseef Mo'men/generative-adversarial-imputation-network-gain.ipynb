{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This NoteBook implements a state of art  Generative Adversarial Imputation Network (GAIN)  a paper for this approach could be found here: [GAIN](http://proceedings.mlr.press/v80/yoon18a.html?ref=https://githubhelp.com)  please leave a comment for your feedback ","metadata":{"id":"pX_aTDX79EE6"}},{"cell_type":"markdown","source":"# Installing and Importing","metadata":{"id":"hpw9-zV9urIz"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import backend as K","metadata":{"id":"s3swOOSetaw0","execution":{"iopub.status.busy":"2022-06-30T23:36:49.244077Z","iopub.execute_input":"2022-06-30T23:36:49.245333Z","iopub.status.idle":"2022-06-30T23:36:59.886243Z","shell.execute_reply.started":"2022-06-30T23:36:49.245202Z","shell.execute_reply":"2022-06-30T23:36:59.884711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Few EDA","metadata":{"id":"ivHyzylIuybn"}},{"cell_type":"code","source":"df = pd.read_csv('../input/tabular-playground-series-jun-2022/data.csv')","metadata":{"id":"kYOyebK0tgwH","execution":{"iopub.status.busy":"2022-06-30T23:37:40.87488Z","iopub.execute_input":"2022-06-30T23:37:40.875278Z","iopub.status.idle":"2022-06-30T23:37:59.732954Z","shell.execute_reply.started":"2022-06-30T23:37:40.875246Z","shell.execute_reply":"2022-06-30T23:37:59.732076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"kPYgoP-godr5","outputId":"e03b5928-e4a8-4ebb-9265-6364c4fc6e7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"6F_BhBfctiog","outputId":"7645c3cb-8638-4b88-baa1-0ca59b1b2770"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"id":"KaydzTMcBkOJ","outputId":"f2140874-579e-4841-ad46-d57e1b8dfe34"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_nans = df.loc[:, np.isnan(df).sum() > 0]\nnp.isnan(df_nans).sum() / df_nans.shape[0]","metadata":{"id":"7IO-S74PsoKy","outputId":"0a39e1fc-7231-40c8-852e-3da3a635b42c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = df_nans.columns\nfig = plt.figure(figsize=(30, 10))\nplt.bar(x=columns, height = np.isnan(df_nans).sum())\nplt.show()","metadata":{"id":"j5wzKdh9ub-P","outputId":"953f2554-5002-4eba-d9fa-d8d8743649dd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_nans.plot.hist(figsize=(30, 10), bins = 50)\nplt.show()","metadata":{"id":"SdpViL5GujBm","outputId":"b8e2838c-8a89-4f2d-d920-1afb2aa280d2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_nans.hist(figsize=(30, 20))\nplt.show()","metadata":{"id":"3f5y2RQMuluF","outputId":"ffdcff47-1231-4872-bd0a-a50fff01a438"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain_data = scaler.fit_transform(df.drop('row_id', axis = 1))","metadata":{"id":"J5ZsyTq-jDZv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE = 900000\nBATCH_SIZE = 128\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)","metadata":{"id":"_wz1dY3juO8b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the GAIN","metadata":{"id":"P07hm5v2vE68"}},{"cell_type":"markdown","source":"## Define the Generator","metadata":{"id":"eKUlz8f5vLMp"}},{"cell_type":"code","source":"def generator_builder(num_fet = 80):\n  # 80 * 2 = 162\n  generator = keras.models.Sequential([\n    keras.layers.Input(shape = num_fet * 2), \n    keras.layers.Dense(150, 'relu'),\n    keras.layers.Dense(100, 'relu'),\n    keras.layers.Dense(80, 'sigmoid')\n  ])\n  return generator","metadata":{"id":"Wc3ANekoBfiL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the Discriminator","metadata":{"id":"Gak4x29HvPjJ"}},{"cell_type":"code","source":"def discriminator_builder(num_fet = 80):\n  # 80 * 2 = 162\n  discriminator = keras.models.Sequential([\n      keras.layers.Input(shape = num_fet * 2),\n      keras.layers.Dense(150, 'relu'),\n      keras.layers.Dense(100, 'relu'),\n      keras.layers.Dense(80, 'sigmoid'),\n  ])\n\n  return discriminator","metadata":{"id":"OljtT_k7CgbO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Discriminarot Loss ","metadata":{"id":"QlDipY85v0LE"}},{"cell_type":"code","source":"def discriminator_loss(m, m_hat):\n  temp = tf.math.multiply(m, tf.math.log(m_hat + 1e-8))\n  temp += tf.math.multiply(tf.ones_like(m) - m , tf.math.log(tf.ones_like(m_hat) - m_hat + 1e-8))\n  return -tf.reduce_mean(temp)","metadata":{"id":"EnEn5QsmINrj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generator Loss","metadata":{"id":"NXSj5LXMvbg4"}},{"cell_type":"code","source":"def generator_loss(m, m_hat, x, x_hat, alpha = 10):\n  loss = -tf.math.multiply((tf.ones_like(m)-m), tf.math.log(m_hat+1e-8))\n  loss += alpha * tf.multiply(m, (x - x_hat) ** 2)\n  return tf.reduce_mean(loss)","metadata":{"id":"cRqWOjjDJjL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hint_smapler(batch_size = 128, num_fet = 80, hint_rate = 0.9):\n    A = np.random.uniform(0., 1., size = [batch_size, num_fet])\n    B = hint_rate > A\n    C = 1.*B\n    return C","metadata":{"id":"du85IiWT-pKo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the Optimizers and build the models","metadata":{"id":"l088pSlOvhRY"}},{"cell_type":"code","source":"generator_optimizer = keras.optimizers.SGD(1e-4)\ndiscriminator_optimizer = keras.optimizers.SGD(1e-4)","metadata":{"id":"rLPEzdrGPe-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = generator_builder()\ndiscriminator = discriminator_builder()","metadata":{"id":"_mJ35HFAC_hO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(batch, epoch_num):\n    \n  m = tf.where(tf.math.is_nan(batch), tf.zeros_like(batch), tf.ones_like(batch))\n  batch_C = tf.where(tf.math.is_nan(batch), tf.zeros_like(batch), batch)\n  z = np.random.uniform(0, 0.01, size = batch.shape)\n  batch = tf.math.multiply(batch_C, m) + tf.math.multiply((tf.ones_like(m) - m), z)\n  \n  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n\n    X_temp = tf.cast(generator(tf.concat([batch, m], 1), training = True), tf.float64)\n    X_hat = tf.math.multiply(m, batch) + tf.math.multiply((tf.ones_like(m) - m), X_temp)\n\n    H = tf.math.multiply(hint_smapler(),  m)\n    M_hat = tf.cast(discriminator(tf.concat([X_hat, H], 1), training = True), tf.float64)\n\n    disc_loss = discriminator_loss(m, M_hat)\n    gen_loss = generator_loss(m, M_hat, batch, X_hat, alpha = 10)\n\n  gen_grad = gen_tape.gradient(gen_loss, generator.trainable_variables)\n  disc_grad = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n  generator_optimizer.apply_gradients(zip(gen_grad, generator.trainable_variables))\n  discriminator_optimizer.apply_gradients((zip(disc_grad, discriminator.trainable_variables)))\n  return gen_loss, disc_loss","metadata":{"id":"jBHdkUVOioLu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataset, EPOCHS):\n  losses_gen = []\n  losses_disc  = []\n  for epoch in range(1, EPOCHS+1):\n    print(f'Epoch {epoch} / {EPOCHS}:', end=' ')\n    t0 = time.time()\n    for batch in dataset:\n      gen_loss, disc_loss = train_step(batch, epoch)\n      losses_gen.append(gen_loss)\n      losses_disc.append(disc_loss)\n    t1 = time.time()\n    print(f'gen_loss = {gen_loss}, disc_loss = {disc_loss}, time = {t1 - t0}')\n  return losses_gen, losses_disc","metadata":{"id":"Qf0u7dn4QZpG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_loss, disc_loss = train(train_dataset, EPOCHS = 10)","metadata":{"id":"a8yArfiVu1mj","outputId":"bf9e1b68-c024-472a-a2ad-da45b352a7d3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20, 10))\nplt.plot(gen_loss, color = 'orange')\nplt.title('Generator Loss')\nplt.xlabel('Iter')\nplt.ylabel('Loss')\nplt.show()","metadata":{"id":"tAPAoWTNKqwR","outputId":"a200b61a-abc6-4357-bd1d-90a762debcc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20, 10))\nplt.plot(disc_loss, color = 'orange')\nplt.title('Disciriminator Loss')\nplt.xlabel('Iter')\nplt.ylabel('Loss')\nplt.show()","metadata":{"id":"IIReQZto8TRc","outputId":"8532ab1d-3cac-4657-84d5-1721c8878747"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = tf.where(tf.math.is_nan(train_data), tf.zeros_like(train_data), tf.ones_like(train_data))\ntrain_data_C = tf.where(tf.math.is_nan(train_data), tf.zeros_like(train_data), train_data)\nz = np.random.uniform(0, 0.01, size = train_data.shape)\ntrain_data = tf.math.multiply(train_data_C, m) + tf.math.multiply((tf.ones_like(m) - m), z)","metadata":{"id":"OxZMbxlY8VJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_temp = tf.cast(generator(tf.concat([train_data, m], 1), training = True), tf.float64)\nX_hat = tf.math.multiply(m, train_data) + tf.math.multiply((tf.ones_like(m) - m), X_temp) ","metadata":{"id":"QlUzsP3JIm_I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = scaler.inverse_transform(X_hat)\ndf_ = df.drop(['row_id'], axis = 1)\ntest = []\nfor idx_col, col in enumerate(df):\n  for idx_row, row in enumerate(df.loc[:, col]):\n    if np.isnan(row):\n      test.append(f'{idx_row}-{col}')\nres = []\nfor col_idx, col in enumerate(df_):\n  for row_idx, row in enumerate(df_.loc[:, col]):\n    if np.isnan(row):\n      res.append(pred[row_idx, col_idx])","metadata":{"id":"3OzzAb1hIprs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = np.array([test, res])\nout = pd.DataFrame(out.T)\nout = out.rename({0: 'row-col', 1: 'value'}, axis = 1)\nout.to_csv('sub3_temp.csv', index = False)","metadata":{"id":"SXvK_SDsMBkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!kaggle competitions submit -c tabular-playground-series-jun-2022 -f sub3_temp.csv -m \"Message\"","metadata":{"id":"MQtaNs_dPIKq","outputId":"b42b14b9-ebba-40cf-a403-200f5432852e"},"execution_count":null,"outputs":[]}]}