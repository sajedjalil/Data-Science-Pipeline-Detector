{"cells":[{"metadata":{},"cell_type":"markdown","source":"Taken help from : https://www.kaggle.com/nanditab35/diabetic-retinopathy-inception-v3","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport os\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport psutil\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom math import ceil\nfrom sklearn.model_selection import train_test_split\n# from tensorflow import set_random_seed\nimport tensorflow as tf\nimport keras\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Flatten, Dense\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Input\nfrom keras import backend as K\nfrom sklearn.utils import shuffle\n\nprint(os.listdir('/kaggle/input'))\n# print(os.listdir('/kaggle/input/inceptionv3/'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"SEED = 7\n# np.random.seed(SEED)\n# set_random_seed(SEED)\ndir_path = \"/kaggle/input/\"\nIMG_DIM = 299  # 224\nBATCH_SIZE = 8\nCHANNEL_SIZE = 3\nNUM_EPOCHS = 60\nTRAIN_DIR = 'train_images'\nTEST_DIR = 'test_images'\nFREEZE_LAYERS = 2  # freeze the first this many layers for training\nCLASSS = {0: \"No DR\", 1: \"Mild\", 2: \"Moderate\", 3: \"Severe\", 4: \"Proliferative DR\"}\nNUM_CLASSS = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT_PATH = '/kaggle/input/aptos2019-blindness-detection'\nTRAIN_PATH = '/kaggle/input/aptos2019-blindness-detection/' + TRAIN_DIR \nTEST_PATH = '/kaggle/input/aptos2019-blindness-detection/' + TEST_DIR \ndir_path = ROOT_PATH + '/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def class_imbalance(df_train):    \n    new_df = df_train[df_train['diagnosis']==0].sample(295,random_state = SEED)\n    df1 = df_train[df_train['diagnosis']==1].sample(295,random_state = SEED)\n    df2 = df_train[df_train['diagnosis']==2].sample(295,random_state = SEED)\n    df4 = df_train[df_train['diagnosis']==4].sample(295,random_state = SEED)\n    df3 = df_train[df_train['diagnosis']==3]\n    new_df = new_df.append(df1,ignore_index = True)\n    new_df = new_df.append(df2,ignore_index = True)\n    new_df = new_df.append(df3,ignore_index = True)\n    new_df = new_df.append(df4,ignore_index = True)\n    return new_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print names of train images\ntrain_img_names = glob.glob(TRAIN_PATH + '/*.png')\n#print(train_img_names)\n\ndf_train = pd.read_csv(ROOT_PATH + '/train.csv')\ndf_train = class_imbalance(df_train)\ndf_train = shuffle(df_train)\ndf_train.head()\n#print(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# print names of test images\ntest_img_names = glob.glob(TEST_PATH + '/*.png')\n#print(test_img_names)\ndf_test = pd.read_csv(ROOT_PATH + '/test.csv')\n#print(df_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_img(imgs, target_dir, class_label='0'):\n    for row in enumerate(imgs.iterrows()):\n        name = row[1][1]['id_code'] + '.png'\n        print(name)\n        plt.figure(figsize=(15,10))\n        img = plt.imread(dir_path + target_dir + '/' + name)\n        plt.imshow(img)\n        plt.title(class_label)\n        plt.show()\n        del img\n        gc.collect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Showing the class 0 image randomly\n# CLASS_ID = 0\n# draw_img(df_train[df_train.diagnosis == CLASS_ID].sample(n=1), 'train_images', CLASSS[CLASS_ID])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Showing the class 1 image randomly\n# CLASS_ID = 1\n# draw_img(df_train[df_train.diagnosis == CLASS_ID].sample(n=1), 'train_images', CLASSS[CLASS_ID])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# Split Dataset\n\nx_train, x_test, y_train, y_test = train_test_split(df_train.id_code, df_train.diagnosis, test_size=0.2,\n                                                    random_state=SEED, stratify=df_train.diagnosis)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ninput_tensor = Input(shape = (299, 299, 3))\n\n# create the base pre-trained model\nbase_model = InceptionV3(include_top=False, input_tensor=input_tensor, weights = 'imagenet')\n# base_model.load_weights('/kaggle/input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n# add a global spatial average pooling layer\nx = base_model.output\noutput = BatchNormalization()(x)\nx = GlobalAveragePooling2D()(x)\n\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(NUM_CLASSS, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nfor layer in model.layers:\n    layer.trainable = True\n    \nprint(model.summary())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 25\nlrate = 0.01\ndecay = lrate/epochs\nsgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"available RAM:\", psutil.virtual_memory())\ngc.collect()\nprint(\"available RAM:\", psutil.virtual_memory())\n\ndf_train.id_code = df_train.id_code.apply(lambda x: x + \".png\")\ndf_test.id_code = df_test.id_code.apply(lambda x: x + \".png\")\ndf_train['diagnosis'] = df_train['diagnosis'].astype('str')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n      \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n  #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n  #         print(img.shape)\n        return img\ndef histogram_equalization(img_in):# segregate color streams\n    b,g,r = cv2.split(img_in)\n    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])# calculate cdf    \n    cdf_b = np.cumsum(h_b)  \n    cdf_g = np.cumsum(h_g)\n    cdf_r = np.cumsum(h_r)\n    \n# mask all pixels with value=0 and replace it with mean of the pixel values \n    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n  \n    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n\n    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')# merge the images in the three channels    img_b = cdf_final_b[b]\n    img_g = cdf_final_g[g]\n    img_r = cdf_final_r[r]\n    img_b = cdf_final_b[b]\n  \n    img_out = cv2.merge((img_b, img_g, img_r))# validation\n    equ_b = cv2.equalizeHist(b)\n    equ_g = cv2.equalizeHist(g)\n    equ_r = cv2.equalizeHist(r)\n    equ = cv2.merge((equ_b, equ_g, equ_r))\n    return equ\n\ndef load_ben_color(image, sigmaX):\n    # image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#     image = histogram_equalization(image)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_DIM, IMG_DIM))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n\n    return image\n\ndef preprocess(image):\n    return load_ben_color(image, sigmaX=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clahe_bgr(img):\n    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    lab_planes = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=2.0)\n    lab_planes[0] = clahe.apply(lab_planes[0])\n    lab = cv2.merge(lab_planes)\n    rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n    return rgb\n\ndef crop_image_from_gray(img,tol=59):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n\n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n        #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n        #         print(img.shape)\n            return img\n\ndef something(img):\n    # img = crop_image_from_gray(img)\n    img = clahe_bgr(img)\n    # image = histogram_equalization(image)\n    # image = crop_image_from_gray(image)\n    img = cv2.resize(image, (IMG_DIM, IMG_DIM))\n    image=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX = 30) ,-4,0)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Generator\ntrain_datagen = image.ImageDataGenerator(rescale=1. / 255, \n                                         validation_split=0.15, \n                                         horizontal_flip=True,\n                                         vertical_flip=True, \n                                         rotation_range=360, \n                                         zoom_range=0.2, \n                                         shear_range=0.1,\n                                         preprocessing_function = preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    directory= TRAIN_PATH + '/',\n                                                    x_col='id_code',\n                                                    y_col='diagnosis',\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode='categorical',\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='training',\n                                                    shaffle=True,\n                                                    seed=SEED\n                                                    )\nvalid_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    directory= TRAIN_PATH + '/',\n                                                    x_col='id_code',\n                                                    y_col='diagnosis',\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode='categorical',\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='validation',\n                                                    shaffle=True,\n                                                    seed=SEED\n                                                    )\n#del x_train\n# # del x_test\n#del y_train\n# del y_test\ngc.collect()\n#  color_mode= \"grayscale\",","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nNUB_TRAIN_STEPS = train_generator.n // train_generator.batch_size\nNUB_VALID_STEPS = valid_generator.n // valid_generator.batch_size\n\nNUB_TRAIN_STEPS, NUB_VALID_STEPS\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\neraly_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n# Reducing the Learning Rate if result is not improving. \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',\n                              verbose=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(generator=train_generator,\n                                     steps_per_epoch=NUB_TRAIN_STEPS,\n                                     validation_data=valid_generator,\n                                     validation_steps=NUB_VALID_STEPS,\n                                     epochs=NUM_EPOCHS,\n                                     #                            shuffle=True,  \n                                     callbacks=[eraly_stop, reduce_lr],\n                                     verbose=1)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accu = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.figure(figsize=(8, 8))\nplt.plot(accu, label=\"Accuracy\")\nplt.plot(val_acc)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(['Acc', 'val_acc'])\nplt.plot(np.argmax(history.history[\"val_accuracy\"]), np.max(history.history[\"val_accuracy\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(history.history[\"loss\"], label=\"loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}