{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports, settings and references"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nimport pandas as pd \nimport numpy as np\nimport time \nimport cv2 \nfrom PIL import Image \n\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms \n\nimport xgboost as xgb\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.preprocessing import quantile_transform\n\nDEVICE = torch.device('cuda:0')\nDATA_SOURCE = os.path.join('..', 'input', 'aptos2019-blindness-detection')\nMODEL_SOURCE = os.path.join('..', 'input', 'torchvisionmodelspartial1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing\nInspired by: # https://www.kaggle.com/ratthachat/aptos-updated-preprocessing-ben-s-cropping"},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image(img,tol=7):\n    w, h = img.shape[1],img.shape[0]\n    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray_img = cv2.blur(gray_img,(5,5))\n    shape = gray_img.shape \n    gray_img = gray_img.reshape(-1,1)\n    quant = quantile_transform(gray_img, n_quantiles=256, random_state=0, copy=True)\n    quant = (quant*256).astype(int)\n    gray_img = quant.reshape(shape)\n    xp = (gray_img.mean(axis=0)>tol)\n    yp = (gray_img.mean(axis=1)>tol)\n    x1, x2 = np.argmax(xp), w-np.argmax(np.flip(xp))\n    y1, y2 = np.argmax(yp), h-np.argmax(np.flip(yp))\n    if x1 >= x2 or y1 >= y2 : # something wrong with the crop\n        return img # return original image\n    else:\n        img1=img[y1:y2,x1:x2,0]\n        img2=img[y1:y2,x1:x2,1]\n        img3=img[y1:y2,x1:x2,2]\n        img = np.stack([img1,img2,img3],axis=-1)\n    return img\n\ndef process_image(image, size=512):\n    image = cv2.resize(image, (size,int(size*image.shape[0]/image.shape[1])))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    try:\n        image = crop_image(image, tol=15)\n    except Exception as e:\n        image = image\n        print( str(e) )\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedir('goog')\nos.listdir('./')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PyTorch's style data loader defintion\nadapted from : https://www.kaggle.com/abhishek/very-simple-pytorch-training-0-59"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTrain(Dataset):\n\n    def __init__(self, transform, eval_set=False, eval_frac=0.5, random_state=42):\n        if not os.path.exists(\"cache\"): os.mkdir(\"cache\")\n        self.transform = transform\n        self.base_transform = transforms.Resize((224, 224))        \n        # read data list, split in train and eval, select the set\n        csv_file = os.path.join(DATA_SOURCE, \"train.csv\")\n        df = pd.read_csv(csv_file)\n        df_train = df.sample(n=int(df.shape[0]*(1-eval_frac)), random_state=random_state)\n        ix=[i for i in df.index if i not in df_train.index.values.tolist()]  \n        df_eval = df.loc[ix]            \n        if eval_set : df = df_eval\n        else :        df = df_train\n        self.data = df.reset_index(drop=True)\n            \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # get image and process it to tensor ready for the model, extract features\n        folder = os.path.join(DATA_SOURCE, \"train_images\")\n        code = str(self.data.loc[idx, 'id_code'])\n        file = code + \".png\"\n        cache_path = os.path.join(\"cache\",code+\".png\")\n        cached = os.path.exists(cache_path)\n        if not cached : \n            path = os.path.join(folder, file)\n            image = cv2.imread(path)\n            image = process_image(image)\n            imgpil = Image.fromarray(image)\n            imgpil = self.base_transform(imgpil)\n            imgpil.save(cache_path,\"PNG\")\n        imgpil = Image.open(cache_path)\n        img_tensor = self.transform(imgpil)\n        label = self.data.loc[idx, \"diagnosis\"]\n        return {'image': img_tensor, 'label': label}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTest(Dataset):\n\n    def __init__(self, eval_set=False, random_state=42):\n        # read data list, split in train and eval, select the set\n        csv_file = os.path.join(DATA_SOURCE, \"test.csv\")\n        df = pd.read_csv(csv_file)\n        print(df)\n        self.data = df.reset_index(drop=True)\n        self.transform = transforms.Compose(\n                        [transforms.Resize((224, 224)),\n                        transforms.ToTensor(),\n                        transforms.Normalize([0.485, 0.456, 0.406], \n                                             [0.229, 0.224, 0.225])])\n            \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # get image and process it to tensor ready for the model, extract features\n        folder = os.path.join(DATA_SOURCE, \"test_images\")\n        code = str(self.data.loc[idx, 'id_code'])\n        file = code + \".png\"\n        path = os.path.join(folder, file)\n        image = cv2.imread(path)\n        image = process_image(image)\n        imgpil = Image.fromarray(image)\n        img_tensor = self.transform(imgpil)\n        return {'image': img_tensor}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Re-train the pre-trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training loops\ndef train_model(model, optimizer, train_data_loader, eval_data_loader, \n                file_name, num_epochs = 50, patience = 7, prev_loss = 1000.00):\n    criterion = nn.CrossEntropyLoss()\n    countdown = patience\n    best_loss = 1000.00\n    since = time.time()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        counter = 0\n        for bi, d in enumerate(train_data_loader):\n            counter += 1\n            inputs = d[\"image\"].to(DEVICE, dtype=torch.float)\n            labels = d[\"label\"].to(DEVICE, dtype=torch.long)\n            model.to(DEVICE)\n            model.train()\n            optimizer.zero_grad()\n            outputs = model(inputs) \n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n            loss_val=(running_loss / (counter * train_data_loader.batch_size))\n            print(\"{:3} {:.4f} {:.4f}\".format(counter, loss.item()*1, loss_val), end=\"\\r\")\n        epoch_loss = running_loss / ( len(train_data_loader) * train_data_loader.batch_size)\n        time_elapsed = time.time() - since\n        print(\" T{:3}/{:3} loss: {:.4f} ({:3.0f}m {:2.0f}s) \".format( \n            epoch, num_epochs - 1, epoch_loss,time_elapsed // 60, time_elapsed % 60))\n        running_loss = 0.0\n        counter = 0\n        for bi, d in enumerate(eval_data_loader):\n            counter += 1\n            inputs = d[\"image\"].to(DEVICE, dtype=torch.float)\n            labels = d[\"label\"].to(DEVICE, dtype=torch.long)\n            model.to(DEVICE)\n            model.eval()\n            with torch.no_grad():\n                outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * inputs.size(0)\n            loss_val=(running_loss / (counter * eval_data_loader.batch_size))\n            print(\"{:3} {:.4f} {:.4f}\".format(counter, loss.item()*1, loss_val), end=\"\\r\")\n        epoch_loss = running_loss / ( len(eval_data_loader) * eval_data_loader.batch_size)\n        if epoch_loss < best_loss : \n            best_loss = epoch_loss\n            if epoch_loss < prev_loss:\n                torch.save(model.state_dict(), file_name)\n                prev_loss = epoch_loss\n                print(\"*\", end=\"\")\n            else:\n                print(\".\", end=\"\")\n            countdown = patience\n        else:\n            print(\"{:1}\".format(countdown), end=\"\")\n            countdown -= 1\n        time_elapsed = time.time() - since\n        print(\"E{:3}/{:3} loss: {:.4f} ({:3.0f}m {:2.0f}s)\".format( \n            epoch, num_epochs - 1, epoch_loss,time_elapsed // 60, time_elapsed % 60 ))\n\n        if countdown <= 0 : break\n\n    return prev_loss\n    print(\"done.\")\n# Model training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aug_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbase_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nbatch_size = 48\ndata_train = RetinopathyDatasetTrain(aug_transform, eval_frac=0.25, random_state=69)\ndata_loader_train = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n                                                shuffle=True, num_workers=0, \n                                                drop_last=False)\ndata_eval = RetinopathyDatasetTrain(base_transform, eval_set=True, \n                                    eval_frac=0.25, random_state=69)\ndata_loader_eval = torch.utils.data.DataLoader(data_eval,batch_size=batch_size, \n                                               shuffle=False, num_workers=0, \n                                               drop_last=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_base_model():\n    model = torchvision.models.densenet161(pretrained=False)\n    model_path = os.path.join(MODEL_SOURCE, \"densenet161.pth\")\n    model.load_state_dict(torch.load(model_path))\n    model.classifier = nn.Sequential(\n        nn.BatchNorm1d(2208),\n        nn.Dropout(p=0.25),\n        nn.Linear(in_features=2208, out_features=2048, bias=True),\n        nn.ReLU(),\n        nn.BatchNorm1d(2048),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=2048, out_features=5, bias=True),\n    )\n    model = model.to(DEVICE)\n    model.eval()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bst_loss = 10000.00\nfor no in range(5):\n    print(\"-\"*22,no)\n    model = get_base_model()\n    plist = [{'params': model.features.denseblock2.parameters()},\n             {'params': model.features.denseblock3.parameters()},\n             {'params': model.features.denseblock4.parameters()},\n             {'params': model.classifier.parameters()}]\n    optimizer = optim.Adam(plist, lr=0.001)\n    bst_loss = train_model(model, optimizer, data_loader_train, data_loader_eval, \"tmp.pth\", prev_loss=bst_loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract train features from CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the pretrained CNN used as feature extractor\n# no classifier defined, we will take the raw output from the CNN layers\nextractor = torchvision.models.densenet161(pretrained=False)\nextractor.classifier = nn.Sequential(\n    nn.BatchNorm1d(2208),\n    nn.Dropout(p=0.25),\n    nn.Linear(in_features=2208, out_features=2048, bias=True),\n    nn.ReLU(),\n    nn.BatchNorm1d(2048),\n    nn.Dropout(p=0.5),\n    nn.Linear(in_features=2048, out_features=5, bias=True),\n)\nmodel_path = os.path.join(\"tmp.pth\")\nextractor.load_state_dict(torch.load(model_path))\nextractor.classifier = nn.Identity()\nextractor = extractor.to(DEVICE)\nextractor.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loader_train = torch.utils.data.DataLoader(RetinopathyDatasetTrain(base_transform), \n                            batch_size=64, shuffle=True, num_workers=0, drop_last=False)\ndata_loader_eval = torch.utils.data.DataLoader(RetinopathyDatasetTrain(base_transform, \n                                                                       eval_set=True), \n                            batch_size=64, shuffle=True, num_workers=0, drop_last=False)\n\ndef get_train_features(data_loader):\n    for bi, d in enumerate(data_loader):\n        print(\".\", end=\"\")\n        img_tensor = d[\"image\"].to(DEVICE)\n        target = d[\"label\"].numpy()\n        with torch.no_grad(): feature = extractor(img_tensor)\n        feature = feature.cpu().detach().squeeze(0).numpy()\n        if bi == 0 :\n            features = feature \n            targets = target \n        else :\n            features = np.concatenate([features, feature], axis=0)\n            targets = np.concatenate([targets, target], axis=0)\n    print(\"\")\n    return features, targets\n\nprint(\".............................\")\nfeatures_train, targets_train = get_train_features(data_loader_train)\nfeatures_eval, targets_eval = get_train_features(data_loader_eval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit the XGBoost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"XGBOOST_PARAM = {\n    \"random_state\" : 42,\n    'objective': 'multi:softmax',\n    \"num_class\" : 5,\n    \"n_estimators\" : 200,\n    \"eval_metric\" : \"mlogloss\"\n}\n\nxgb_model_1 = xgb.XGBClassifier(**XGBOOST_PARAM)\nxgb_model_1 = xgb_model_1.fit(features_train,targets_train.reshape(-1),\n                        eval_set=[(features_eval, targets_eval.reshape(-1))],\n                        early_stopping_rounds=20,\n                        verbose=True)\nprediction = xgb_model_1.predict(features_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model_2 = xgb.XGBClassifier(**XGBOOST_PARAM)\nxgb_model_2 = xgb_model_2.fit(features_eval,targets_eval.reshape(-1),\n                        eval_set=[(features_train, targets_train.reshape(-1))],\n                        early_stopping_rounds=20,\n                        verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Cohen Kappa quadratic score\", \n      cohen_kappa_score(targets_eval, prediction, weights=\"quadratic\"))\n_ = xgb.plot_importance(xgb_model_1, max_num_features=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction1 = xgb_model_1.predict(features_eval)\nprediction2 = xgb_model_2.predict(features_train)\ntargets = np.concatenate([targets_eval, targets_train], axis=0)\nprediction = np.concatenate([prediction1, prediction2], axis=0)\nprint(\"Cohen Kappa quadratic score\", \n      cohen_kappa_score(targets, prediction, weights=\"quadratic\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract test features from CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loader = torch.utils.data.DataLoader(RetinopathyDatasetTest(), \n                            batch_size=2, shuffle=False, num_workers=0, drop_last=False)\n\ndef get_test_features(data_loader):\n    for bi, d in enumerate(data_loader):\n        if bi % 32 == 0 : print(\".\", end=\"\")\n        img_tensor = d[\"image\"].to(DEVICE)\n        with torch.no_grad(): feature = extractor(img_tensor)\n        feature = feature.cpu().detach().squeeze(0).numpy()\n        if bi == 0 :\n            features = feature \n        else :\n            features = np.concatenate([features, feature], axis=0)\n    print(\"\")\n    return features\n\nprint(\"...............................\")\nfeatures = get_test_features(data_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction using XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction1 = xgb_model_1.predict_proba(features)\nprediction2 = xgb_model_2.predict_proba(features)\nprediction = (prediction1 + prediction2).argmax(axis=1)\ncsv_file = os.path.join(DATA_SOURCE, \"sample_submission.csv\")\ndf = pd.read_csv(csv_file)\ndf[\"diagnosis\"] = prediction\ndf.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cleaning\nfor e in os.listdir(\"cache\"):\n    os.remove(os.path.join(\"cache\", e))\nos.rmdir(\"cache\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}