{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls '../input/aptos2019-blindness-detection/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '../input/aptos2019-blindness-detection/'\ntrain_label_dir = os.path.join(DATA_DIR, 'train.csv')\ntest_label_dir = os.path.join(DATA_DIR, 'test.csv')\n\ndf_train = pd.read_csv(train_label_dir)\ndf_test = pd.read_csv(test_label_dir)\n\nprint(df_train.head())\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"os.listdir(DATA_DIR+'train_images')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the images are named as value in the *id_code* column of *train.csv* and '.png'"},{"metadata":{},"cell_type":"markdown","source":"The *DATA_DIR* folder contains:\n* train_images - images to train on or images whose category of diabetic retinopathy is provided(in train.csv)\n* test_images - images to test our model on \n* train.csv - csv file with two columns: 1)id_code - referring to the image  2) diagnosis - category of the image\n* test.csv - csv file with one column: 1) id_code - referring to the image\n\nThe labels for test data aren't provided - we upload our model to kaggle for getting the test accuracy"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset\n\nfrom torchvision import transforms\n\nfrom PIL import Image\n\nDATA_DIR = '../input/aptos2019-blindness-detection/'\nMODEL_DIR = '../input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class that loads the Train/Validation dataset\nclass DRDatasetTrain(Dataset):\n    def __init__(self, val_set=False, val_size=0.2, random_state=42):\n        train_label_dir = os.path.join(DATA_DIR, 'train.csv')       # save path to train.csv file - DATA_DIR + 'train.csv'\n        \n        df = pd.read_csv(train_label_dir)                           # load train.csv to a Pandas dataframe \n        \n        train_size = int((1 - val_size) * len(df)   )               # save size of training data to use - has to be an integer\n        df_train = df.sample(train_size, random_state=random_state) # save a sample of size train_size from the df dataframe\n                                                                    # random state allows us to get the same sample data if we run the code again later\n        idx = [i for i in df.index if i not in df_train.index]      # save the indices of data not in df_train\n        \n        if val_set:\n            df_train = df[idx]     # if we have set val_set=True \n        \n        # saves the dataframe to be used later\n        # drop=True avoids keeping the current index as a new column\n        self.data = df_train.reset_index(drop=True) \n        \n    # this function is called when len() function is called on this class' objects\n    # >>> train_data = DRDatasetTrain()   >>> len(train_data) \n    def __len__(self):\n        return len(self.data)\n    \n    # this function is called when this class' object is index\n    # >>> train_data = DRDatasetTrain()   >>> train_data[2]\n    def __getitem__(self, idx):\n        # idx - the index of the datapoint we have to return\n        id_code = str(self.data.loc[idx, 'id_code'])                      # save the 'id_code' field in the row no. 'idx' in the train.csv file\n        file_name = id_code + '.png'\n        \n        img_file = os.path.join(DATA_DIR, 'train_images', file_name)  # save path of the image file\n        img = Image.open(img_file)                                         # open the image file using PIL libraries Image class\n        \n        # transforms to be used on the image data\n        transform = transforms.Compose([transforms.Resize((224, 224)),                    # resize images to 224x224\n                                         transforms.ToTensor(),                           # convert PIL image to torch Tensor\n                                         transforms.Normalize([0.485, 0.456, 0.406],      # normalize image pixels - two lists correspond to mean and std\n                                                              [0.229, 0.224, 0.225])])\n        img_tensor = transform(img) # transform the image to be returned\n        label = self.data.loc[idx, 'diagnosis']  # save the label of the image to be returned\n        \n        return (img_tensor, label)# return the image and label as a dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class that loads the Test dataset\nclass DRDatasetTest(Dataset):\n    def __init__(self, val_set=False, val_size=0.2, random_state=42):\n        test_label_dir = os.path.join(DATA_DIR, 'train.csv') # save path to train.csv file - DATA_DIR + 'test.csv'\n        df = pd.read_csv(test_label_dir)                     # load test.csv to a Pandas dataframe \n        self.data = df.reset_index(drop=True)\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        id_code = str(self.data.loc[idx, 'id_code'])                     # save the 'id_code' field in the row no. 'idx' in the train.csv file\n        file_name = id_code + '.png'\n        \n        img_file = os.path.join(DATA_DIR, 'test_images', file_name)  # save path of the image file\n        img = Image.open(img_file)    # open the image file using PIL libraries Image class\n        \n        # transforms to be used on the image data\n        transform = transforms.Compose([transforms.Resize((224, 224)),\n                                         transforms.ToTensor(),\n                                         transforms.Normalize([0.485, 0.456, 0.406], \n                                                                   [0.229, 0.224, 0.225])])\n        img_tensor = transform(img) # transform the image to be returned\n        \n        return {'image': img_tensor} # return the image as a dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DataLoader class is used to return data from the dataset in a controlled manner\n# batch_size - how many datapoints are returned in each iteration(try reducing this if model takes too much time in each epoch)\n# drop_last - should we drop the last batch of data if it's length not equal to batch_size\n# shuffle - whether to shuffle the datapoints when returned in each epoch(one complete iteration over entire data)\ntrainloader = torch.utils.data.DataLoader(DRDatasetTrain(), batch_size=32, drop_last=False, shuffle=False) \ntestloader = torch.utils.data.DataLoader(DRDatasetTest(), batch_size=32, drop_last=False, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize some images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make an iterator out of trainloader and use next() to get a batch(batch_size) of data\nimages, labels = next(iter(trainloader))\nprint(images.shape)\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}