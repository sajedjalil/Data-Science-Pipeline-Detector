{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This kernel implements VGG on APTOS data **"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc\nimport cv2\nfrom tqdm import tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n##############################################################\n\nimport xgboost as xgb\nimport sklearn.ensemble as ensem\nfrom keras.preprocessing.image import ImageDataGenerator\n\n###############################################################\n\nimport sklearn.metrics as metrics\nfrom sklearn.utils import shuffle\n##############################################################\n\n\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import GRU\nfrom keras.layers import LSTM\nfrom keras.layers import TimeDistributed\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.utils import plot_model\nfrom keras.models import Sequential\nfrom keras.layers import MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers.merge import concatenate\nfrom keras.utils import to_categorical\nfrom keras import optimizers\nfrom keras.applications import VGG16, ResNet50,Xception, InceptionResNetV2\nfrom keras.applications import VGG19, InceptionV3,MobileNet\nfrom keras.applications import DenseNet121, DenseNet169,DenseNet201\nfrom keras.applications import NASNetLarge, NASNetMobile,MobileNetV2\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.optimizers as optim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colorcode = cv2.COLOR_BGR2RGB\ninterpolateVal = cv2.INTER_AREA\nimgsize = 150\nchannle = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntest = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n\npaths = train.id_code\ncurr = paths[0]\nimages = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{curr}.png')\nimages = cv2.cvtColor(images, colorcode)\nimages = cv2.resize(images,(imgsize,imgsize),\n                    interpolation=interpolateVal)\nimages = images.reshape((1,imgsize,imgsize,channle))\npaths = paths[1:]\nfor path in tqdm(paths) :\n    img = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{path}.png')\n    img = cv2.cvtColor(img, colorcode)\n    img = cv2.resize(img,(imgsize,imgsize),\n                     interpolation=interpolateVal)\n    img = img.reshape((1,imgsize,imgsize,channle))\n    images = np.vstack((images,img))\n    \nimages = images/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx = images\ntrainy = train.diagnosis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_gen = ImageDataGenerator(rotation_range=10,\n                               width_shift_range=0.1,\n                               height_shift_range=0.1,\n                               shear_range=0.01,\n                               zoom_range=[0.9, 3],\n                               horizontal_flip=True,\n                               vertical_flip=False,\n                               fill_mode='reflect',\n                               data_format='channels_last'\n                              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data0 = trainx[trainy ==0]\nimg0diag = np.repeat(0,data0.shape[0])\n\n\ndata1 = trainx[trainy ==1]\nfor imag in tqdm(data1) :\n    it = image_gen.flow(imag.reshape((1,imgsize,imgsize,3)))\n    for i in range(5) :\n        data1 = np.append(data1,it.next().reshape((1,imgsize,imgsize,3)),axis=0)\nimg1diag = np.repeat(1,data1.shape[0])\n\n\n\ndata2 = trainx[trainy ==2]\nfor imag in tqdm(data2) :\n    it = image_gen.flow(imag.reshape((1,imgsize,imgsize,3)))\n    for i in range(1) :\n        data2 = np.append(data2,it.next().reshape((1,\n                                                   imgsize,imgsize,3)),\n                          axis=0)\nimg2diag = np.repeat(2,data2.shape[0])\n\n\ndata3 = trainx[trainy ==3]\nfor imag in tqdm(data3) :\n    it = image_gen.flow(imag.reshape((1,imgsize,imgsize,3)))\n    for i in range(8) :\n        data3 = np.append(data3,it.next().reshape((1,\n                                                   imgsize,imgsize,3)),\n                          axis=0)\nimg3diag = np.repeat(3,data3.shape[0])\n\n\ndata4 = trainx[trainy ==4]\nfor imag in tqdm(data4) :\n    it = image_gen.flow(imag.reshape((1,imgsize,imgsize,3)))\n    for i in range(5) :\n        data4 = np.append(data4,it.next().reshape((1,\n                                                   imgsize,imgsize,3)),\n                          axis=0)\nimg4diag = np.repeat(4,data4.shape[0])\n\n\ntrainx = np.append(data0,data1,axis=0)\ntrainx = np.append(trainx,data2,axis=0)\ntrainx = np.append(trainx,data3,axis=0)\ntrainx = np.append(trainx,data4,axis=0)\n\ntrainy = np.append(img0diag,img1diag,axis=0)\ntrainy = np.append(trainy,img2diag,axis=0)\ntrainy = np.append(trainy,img3diag,axis=0)\ntrainy = np.append(trainy,img4diag,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pathk='../input/keraspretrainedmodel/keras-pretrain-model/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodeli = InceptionV3(include_top=False,\n                           weights=pathk,\n                           input_tensor=None,\n                           input_shape=(imgsize,imgsize, 3)\n                          )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modeli.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modeli.trainable = True\nsetTrainable = False\nfor layer in modeli.layers:\n    if layer.name in ['conv2d_86','conv2d_94','batch_normalization_94']:\n        setTrainable = True\n    if setTrainable:\n        layer.trainable = True\n        setTrainable = False\n    else:\n        layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(modeli)\nmodel.add(Flatten())\nmodel.add(Dense(2096, activation='relu'))\nmodel.add(Dense(1096, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* conv2d_94\n* conv2d_86\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainy = to_categorical(trainy , \n                        num_classes=None, \n                        dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.optimizers as optim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer=optim.RMSprop(lr=2e-6), \n              metrics=['accuracy'])\nmodel.fit(trainx, trainy,\n           epochs=70, batch_size=100, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pathst = test.id_code\ncurrt = pathst[0]\nimagest = cv2.imread(f'../input/aptos2019-blindness-detection/test_images/{currt}.png')\nimagest = cv2.cvtColor(imagest, colorcode)\nimagest = cv2.resize(imagest,(imgsize,imgsize),\n                     interpolation=interpolateVal)\nimagest = imagest.reshape((1,imgsize,imgsize,3))\npathst = pathst[1:]\nfor patht in pathst :\n    imgt = cv2.imread(f'../input/aptos2019-blindness-detection/test_images/{patht}.png')\n    imgt = cv2.cvtColor(imgt, colorcode)\n    imgt = cv2.resize(imgt,(imgsize,imgsize),\n                      interpolation=interpolateVal)\n    imgt = imgt.reshape((1,imgsize,imgsize,3))\n    imagest = np.vstack((imagest,imgt))\n    \nimagest = imagest/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predValTemp  = model.predict(imagest)\npredVal = predValTemp.argmax(axis=-1)\ntest['diagnosis'] = predVal\ntest.to_csv(\"submission.csv\",index=False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}