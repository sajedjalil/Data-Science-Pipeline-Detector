{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Credits and references : The complete code is taken from [this kernel](https://www.kaggle.com/mathormad/aptos-resnet50-baseline).Changed the model,added some augmentations and retrained it.Thanks to the Author of the kernel","metadata":{}},{"cell_type":"markdown","source":"#### BEFORE YOU FORK, PLEASE SUPPORT AND UPVOTE THE CURRENT KERNEL AND ORIGINAL","metadata":{}},{"cell_type":"markdown","source":"# Introduction:\n## What is diabetic retinopathy?\n#### Diabetic retinopathy is the most common form of diabetic eye disease. Diabetic retinopathy usually only affects people who have had diabetes (diagnosed or undiagnosed) for a significant number of years.\n#### Retinopathy can affect all diabetics and becomes particularly dangerous, increasing the risk of blindness, if it is left untreated.\n#### The risk of developing diabetic retinopathy is known to increase with age as well with less well controlled blood sugar and blood pressure level.\n#### According to the NHS, 1,280 new cases of blindness caused by diabetic retinopathy are reported each year in England alone, while a further 4,200 people in the country are thought to be at risk of retinopathy-related vision loss.\n#### All people with diabetes should have a dilated eye examination at least once every year to check for diabetic retinopathy.\n![](https://www.aoa.org/Images/public/Diabetic_Retinopathy.jpg)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-03T13:03:19.458394Z","iopub.execute_input":"2021-12-03T13:03:19.45901Z","iopub.status.idle":"2021-12-03T13:03:19.48596Z","shell.execute_reply.started":"2021-12-03T13:03:19.458902Z","shell.execute_reply":"2021-12-03T13:03:19.485293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate)\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:03:25.773233Z","iopub.execute_input":"2021-12-03T13:03:25.7735Z","iopub.status.idle":"2021-12-03T13:03:30.55674Z","shell.execute_reply.started":"2021-12-03T13:03:25.773471Z","shell.execute_reply":"2021-12-03T13:03:30.555983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image, ImageOps\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n#from keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.applications.densenet import DenseNet121,DenseNet169\nimport tensorflow.keras.backend as K\nfrom sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport imgaug as ia\n\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nSIZE = 300\nNUM_CLASSES = 5","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-12-03T13:03:30.558402Z","iopub.execute_input":"2021-12-03T13:03:30.558822Z","iopub.status.idle":"2021-12-03T13:03:32.410093Z","shell.execute_reply.started":"2021-12-03T13:03:30.558783Z","shell.execute_reply":"2021-12-03T13:03:32.40936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ndf_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:03:32.411335Z","iopub.execute_input":"2021-12-03T13:03:32.411588Z","iopub.status.idle":"2021-12-03T13:03:32.441542Z","shell.execute_reply.started":"2021-12-03T13:03:32.411555Z","shell.execute_reply":"2021-12-03T13:03:32.440937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualising some sample pictures of different classes.","metadata":{}},{"cell_type":"code","source":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:03:32.449389Z","iopub.execute_input":"2021-12-03T13:03:32.44958Z","iopub.status.idle":"2021-12-03T13:03:43.782236Z","shell.execute_reply.started":"2021-12-03T13:03:32.449557Z","shell.execute_reply":"2021-12-03T13:03:43.781552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df_train['id_code']\ny = df_train['diagnosis']\n\nx, y = shuffle(x, y, random_state=8)\ny.hist()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:03:43.783578Z","iopub.execute_input":"2021-12-03T13:03:43.783786Z","iopub.status.idle":"2021-12-03T13:03:44.027758Z","shell.execute_reply.started":"2021-12-03T13:03:43.783757Z","shell.execute_reply":"2021-12-03T13:03:44.027017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = to_categorical(y, num_classes=NUM_CLASSES)\ntrain_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n                                                      stratify=y, random_state=8)\nprint(train_x.shape)\nprint(train_y.shape)\nprint(valid_x.shape)\nprint(valid_y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:03:54.650371Z","iopub.execute_input":"2021-12-03T13:03:54.650629Z","iopub.status.idle":"2021-12-03T13:03:54.694844Z","shell.execute_reply.started":"2021-12-03T13:03:54.650597Z","shell.execute_reply":"2021-12-03T13:03:54.693776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sometimes = lambda aug: iaa.Sometimes(0.5, aug)\nseq = iaa.Sequential(\n        [\n            # apply the following augmenters to most images\n            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n            iaa.Flipud(0.2), # vertically flip 20% of all images\n            sometimes(iaa.Affine(\n                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n                rotate=(-10, 10), # rotate by -45 to +45 degrees\n                shear=(-5, 5), # shear by -16 to +16 degrees\n                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n                mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n            )),\n            # execute 0 to 5 of the following (less important) augmenters per image\n            # don't execute all of them, as that would often be way too strong\n            iaa.SomeOf((0, 5),\n                [\n                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n                    iaa.OneOf([\n                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n                    ]),\n                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n                    # search either for all edges or for directed edges,\n                    # blend the result with the original image using a blobby mask\n                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n                    ])),\n                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n                    iaa.OneOf([\n                        iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n                    ]),\n                    iaa.Invert(0.01, per_channel=True), # invert color channels\n                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n                    iaa.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n                    # either change the brightness of the whole image (sometimes\n                    # per channel) or change the brightness of subareas\n                    iaa.OneOf([\n                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n                        iaa.FrequencyNoiseAlpha(\n                            exponent=(-1, 0),\n                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n                            second=iaa.ContrastNormalization((0.9, 1.1))\n                        )\n                    ]),\n                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n                    sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n                ],\n                random_order=True\n            )\n        ],\n        random_order=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:03:57.682325Z","iopub.execute_input":"2021-12-03T13:03:57.682757Z","iopub.status.idle":"2021-12-03T13:03:57.745539Z","shell.execute_reply.started":"2021-12-03T13:03:57.682724Z","shell.execute_reply":"2021-12-03T13:03:57.744764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class My_Generator(Sequence):\n\n    def __init__(self, image_filenames, labels,\n                 batch_size, is_train=True,\n                 mix=False, augment=False):\n        self.image_filenames, self.labels = image_filenames, labels\n        self.batch_size = batch_size\n        self.is_train = is_train\n        self.is_augment = augment\n        if(self.is_train):\n            self.on_epoch_end()\n        self.is_mix = mix\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        if(self.is_train):\n            return self.train_generate(batch_x, batch_y)\n        return self.valid_generate(batch_x, batch_y)\n\n    def on_epoch_end(self):\n        if(self.is_train):\n            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n        else:\n            pass\n    \n    def mix_up(self, x, y):\n        lam = np.random.beta(0.2, 0.4)\n        ori_index = np.arange(int(len(x)))\n        index_array = np.arange(int(len(x)))\n        np.random.shuffle(index_array)        \n        \n        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n        \n        return mixed_x, mixed_y\n\n    def train_generate(self, batch_x, batch_y):\n        batch_images = []\n        for (sample, label) in zip(batch_x, batch_y):\n            img = cv2.imread('../input/aptos2019-blindness-detection/train_images/'+sample+'.png')\n            img = cv2.resize(img, (SIZE, SIZE))\n            if(self.is_augment):\n                img = seq.augment_image(img)\n            batch_images.append(img)\n        batch_images = np.array(batch_images, np.float32) / 255\n        batch_y = np.array(batch_y, np.float32)\n        if(self.is_mix):\n            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n        return batch_images, batch_y\n\n    def valid_generate(self, batch_x, batch_y):\n        batch_images = []\n        for (sample, label) in zip(batch_x, batch_y):\n            img = cv2.imread('../input/aptos2019-blindness-detection/train_images/'+sample+'.png')\n            img = cv2.resize(img, (SIZE, SIZE))\n            batch_images.append(img)\n        batch_images = np.array(batch_images, np.float32) / 255\n        batch_y = np.array(batch_y, np.float32)\n        return batch_images, batch_y","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:04:00.591465Z","iopub.execute_input":"2021-12-03T13:04:00.591728Z","iopub.status.idle":"2021-12-03T13:04:00.60961Z","shell.execute_reply.started":"2021-12-03T13:04:00.591698Z","shell.execute_reply":"2021-12-03T13:04:00.608762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = DenseNet121(include_top=False,\n                   weights=None,\n                   input_tensor=input_tensor)\n    base_model.load_weights(\"../input/densenet-keras/DenseNet-BC-121-32-no-top.h5\")\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n    model = Model(input_tensor, final_output) \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:04:02.751435Z","iopub.execute_input":"2021-12-03T13:04:02.752097Z","iopub.status.idle":"2021-12-03T13:04:02.758169Z","shell.execute_reply.started":"2021-12-03T13:04:02.752062Z","shell.execute_reply":"2021-12-03T13:04:02.757448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create callbacks list\nfrom tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n\nepochs = 30; batch_size = 32\ncheckpoint = ModelCheckpoint('../working/densenet_.h5', monitor='val_accuracy', verbose=1, \n                             save_best_only=True)\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n                                   verbose=1, epsilon=0.0001)\nearly = EarlyStopping(monitor=\"val_accuracy\", verbose=1,\n                      patience=9)\n\ncsv_logger = CSVLogger(filename='../working/training_log.csv',\n                       separator=',',\n                       append=True)\n\ntrain_generator = My_Generator(train_x, train_y, 128, is_train=True)\ntrain_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=False, augment=True)\nvalid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n\nmodel = create_model(\n    input_shape=(SIZE,SIZE,3), \n    n_out=NUM_CLASSES)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:04:04.838441Z","iopub.execute_input":"2021-12-03T13:04:04.839025Z","iopub.status.idle":"2021-12-03T13:04:10.81203Z","shell.execute_reply.started":"2021-12-03T13:04:04.838981Z","shell.execute_reply":"2021-12-03T13:04:10.810988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reference link: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow\ndef kappa_loss(y_true, y_pred, y_pow=2, eps=1e-12, N=5, bsize=32, name='kappa'):\n    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n        Args:\n            y_pred: 2D tensor or array, [batch_size, num_classes]\n            y_true: 2D tensor or array,[batch_size, num_classes]\n            y_pow: int,  e.g. y_pow=2\n            N: typically num_classes of the model\n            bsize: batch_size of the training or validation ops\n            eps: a float, prevents divide by zero\n            name: Optional scope/name for op_scope.\n        Returns:\n            A tensor with the kappa loss.\"\"\"\n\n    with tf.name_scope(name):\n        y_true = tf.to_float(y_true)\n        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n    \n        pred_ = y_pred ** y_pow\n        try:\n            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n        except Exception:\n            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n    \n        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n        hist_rater_b = tf.reduce_sum(y_true, 0)\n    \n        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n    \n        nom = tf.reduce_sum(weights * conf_mat)\n        denom = tf.reduce_sum(weights * tf.matmul(\n            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n                              tf.to_float(bsize))\n    \n        return nom*0.5 / (denom + eps) + categorical_crossentropy(y_true, y_pred)*0.5","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:04:10.885153Z","iopub.execute_input":"2021-12-03T13:04:10.885766Z","iopub.status.idle":"2021-12-03T13:04:10.899586Z","shell.execute_reply.started":"2021-12-03T13:04:10.885728Z","shell.execute_reply":"2021-12-03T13:04:10.898842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nclass QWKEvaluation(Callback):\n    def __init__(self, validation_data=(), batch_size=64, interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.batch_size = batch_size\n        self.valid_generator, self.y_val = validation_data\n        self.history = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict_generator(generator=self.valid_generator,\n                                                  steps=np.ceil(float(len(self.y_val)) / float(self.batch_size)),\n                                                  workers=1, use_multiprocessing=False,\n                                                  verbose=1)\n            def flatten(y):\n                return np.argmax(y, axis=1).reshape(-1)\n            \n            score = cohen_kappa_score(flatten(self.y_val),\n                                      flatten(y_pred),\n                                      labels=[0,1,2,3,4],\n                                      weights='quadratic')\n            print(\"\\n epoch: %d - QWK_score: %.6f \\n\" % (epoch+1, score))\n            self.history.append(score)\n            if score >= max(self.history):\n                print('saving checkpoint: ', score)\n                self.model.save('../working/densenet_bestqwk.h5')\n\nqwk = QWKEvaluation(validation_data=(valid_generator, valid_y),\n                    batch_size=batch_size, interval=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:04:19.754402Z","iopub.execute_input":"2021-12-03T13:04:19.754728Z","iopub.status.idle":"2021-12-03T13:04:19.770364Z","shell.execute_reply.started":"2021-12-03T13:04:19.75469Z","shell.execute_reply":"2021-12-03T13:04:19.769708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# warm up model\nfor layer in model.layers:\n    layer.trainable = False\ncallbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early, qwk]\nfor i in range(-3,0):\n    model.layers[i].trainable = True\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer=Adam(1e-3))\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n    epochs=2,\n    workers=WORKERS, use_multiprocessing=True,\n    verbose=1,\n    callbacks=callbacks_list)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:04:58.414962Z","iopub.execute_input":"2021-12-03T13:04:58.415637Z","iopub.status.idle":"2021-12-03T13:17:58.846927Z","shell.execute_reply.started":"2021-12-03T13:04:58.415599Z","shell.execute_reply":"2021-12-03T13:17:58.84603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train all layers\nfor layer in model.layers:\n    layer.trainable = True\ncallbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early, qwk]\nmodel.compile(loss='categorical_crossentropy',metrics=['accuracy'],\n            # loss=kappa_loss,\n            optimizer=Adam(lr=1e-4))\nmodel.fit_generator(\n    train_mixup,\n    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n    validation_data=valid_generator,\n    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n    epochs=epochs,\n    verbose=1,\n    workers=1, use_multiprocessing=False,\n    callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T13:18:58.516159Z","iopub.execute_input":"2021-12-03T13:18:58.51645Z","iopub.status.idle":"2021-12-03T17:24:51.127247Z","shell.execute_reply.started":"2021-12-03T13:18:58.516415Z","shell.execute_reply":"2021-12-03T17:24:51.126544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nmodel.load_weights('../working/densenet_bestqwk.h5')\npredicted = []","metadata":{"execution":{"iopub.status.busy":"2021-12-03T17:27:19.095559Z","iopub.execute_input":"2021-12-03T17:27:19.095856Z","iopub.status.idle":"2021-12-03T17:27:19.619309Z","shell.execute_reply.started":"2021-12-03T17:27:19.095822Z","shell.execute_reply":"2021-12-03T17:27:19.618446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reference:https://www.kaggle.com/CVxTz/cnn-starter-nasnet-mobile-0-9709-lb \nfor i, name in tqdm(enumerate(submit['id_code'])):\n    path = os.path.join('../input/aptos2019-blindness-detection/test_images/', name+'.png')\n    image = cv2.imread(path)\n    image = cv2.resize(image, (SIZE, SIZE))\n    X = np.array((image[np.newaxis])/255)\n    score_predict=((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n    label_predict = np.argmax(score_predict)\n    predicted.append(str(label_predict))","metadata":{"execution":{"iopub.status.busy":"2021-12-03T17:27:22.385573Z","iopub.execute_input":"2021-12-03T17:27:22.386041Z","iopub.status.idle":"2021-12-03T17:35:51.905348Z","shell.execute_reply.started":"2021-12-03T17:27:22.386001Z","shell.execute_reply":"2021-12-03T17:35:51.904596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit['diagnosis'] = predicted\nsubmit.to_csv('submission.csv', index=False)\nsubmit.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T17:39:03.17634Z","iopub.execute_input":"2021-12-03T17:39:03.177104Z","iopub.status.idle":"2021-12-03T17:39:03.202012Z","shell.execute_reply.started":"2021-12-03T17:39:03.177062Z","shell.execute_reply":"2021-12-03T17:39:03.201193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}