{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jigsaw Unintended Bias in Toxicity Classification, EDA + DL (Keras LSTM)\n\n## Detect toxicity across a diverse range of conversations\n\n![](https://storage.googleapis.com/kaggle-media/competitions/jigsaw/003-avatar.png)\n[image source](https://storage.googleapis.com/kaggle-media/competitions/jigsaw/003-avatar.png)\n\nIn this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.\n\n## *Kernel in progress, is continuously being updated and extended*"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n\nfrom sklearn import metrics\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import text, sequence\nfrom keras.models import load_model\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, SpatialDropout1D, Activation, Conv1D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Flatten, GlobalMaxPooling1D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\n\nimport gc\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"TEXT_COL = 'comment_text'\nEMB_PATH = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\ntrain_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', index_col='id')\ntest_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.target.plot.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since for evaluation, the test set examples with target >= 0.5 will be considered to be in the positive class (toxic). The same notion will be applied here; The target from the train set will be transformed as bescribed above. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.target = np.where(train_df.target> 0.5, 1, 0)\nprint(train_df.target.value_counts())\nsns.countplot(train_df.target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Rating Univariate analysis\nConverting the character feature 'rating' which takes 2 values; approved and rejected into 1 and 0 respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df['rating'].value_counts()\ntrain_df['rating'] = np.where(train_df['rating'] == \"approved\", 1, 0)\ntrain_df['rating'].value_counts()\nsns.countplot(train_df['rating'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['severe_toxicity', 'obscene',\n       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n       'other_sexual_orientation', 'physical_disability',\n       'psychiatric_or_mental_illness', 'transgender', 'white', 'rating', 'funny', 'wow',\n       'sad', 'likes', 'disagree', 'sexual_explicit',\n       'identity_annotator_count', 'toxicity_annotator_count']\n\n\ntoxicity_features = [\"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\", \"sexual_explicit\"]\n\nidentity_features = [\"male\", \"female\", \"transgender\", \"other_gender\", \"heterosexual\", \"homosexual_gay_or_lesbian\",\n                     \"bisexual\", \"other_sexual_orientation\", \"christian\", \"jewish\", \"muslim\", \"hindu\", \"buddhist\",\n                     \"atheist\", \"other_religion\", \"black\", \"white\", \"asian\", \"latino\", \"other_race_or_ethnicity\",\n                     \"physical_disability\", \"intellectual_or_learning_disability\", \"psychiatric_or_mental_illness\", \"other_disability\"]\n\nmetadata_features = [\"rating\", \"funny\", \"wow\", \"sad\", \"likes\", \"disagree\", \"toxicity_annotator_count\", \"identity_annotator_count\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(20, 150))\nfor i, col in enumerate(toxicity_features):\n    plt.subplot(40, 4, i + 1)\n    plt.hist(train_df[col]) \n    plt.title(col)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(20, 150))\nfor i, col in enumerate(identity_features):\n    plt.subplot(40, 4, i + 1)\n    plt.hist(train_df[col]) \n    plt.title(col)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(20, 150))\nfor i, col in enumerate(metadata_features):\n    plt.subplot(40, 4, i + 1)\n    plt.hist(train_df[col]) \n    plt.title(col)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(20, 150))\nfor i, col in enumerate(toxicity_features):\n    plt.subplot(40, 4, i + 1)\n    plt.hist(train_df[col]) \n    plt.hist(train_df[train_df[\"target\"] == 0][col], alpha=0.5, label='0', color='b')\n    plt.hist(train_df[train_df[\"target\"] == 1][col], alpha=0.5, label='1', color='r') \n    plt.title(col)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(20, 150))\nfor i, col in enumerate(identity_features):\n    plt.subplot(40, 4, i + 1)\n    plt.hist(train_df[col]) \n    plt.hist(train_df[train_df[\"target\"] == 0][col], alpha=0.5, label='0', color='b')\n    plt.hist(train_df[train_df[\"target\"] == 1][col], alpha=0.5, label='1', color='r') \n    plt.title(col)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Distributions columns')\nplt.figure(figsize=(20, 150))\nfor i, col in enumerate(metadata_features):\n    plt.subplot(40, 4, i + 1)\n    plt.hist(train_df[col]) \n    plt.hist(train_df[train_df[\"target\"] == 0][col], alpha=0.5, label='0', color='b')\n    plt.hist(train_df[train_df[\"target\"] == 1][col], alpha=0.5, label='1', color='r') \n    plt.title(col)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.close();\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_df[\"comment_text\"]\nlabel_data = train_df[\"target\"]\ntest_data = test_df[\"comment_text\"]\ntrain_data.shape, label_data.shape, test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = text.Tokenizer()\ntokenizer.fit_on_texts(list(train_data) + list(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = tokenizer.texts_to_sequences(train_df['comment_text'])\ntest_data = tokenizer.texts_to_sequences(test_df['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN = 200\ntrain_data = sequence.pad_sequences(train_data, maxlen=MAX_LEN)\ntest_data = sequence.pad_sequences(test_data, maxlen=MAX_LEN)\n\nxtrain, xvalid, ytrain, yvalid = train_test_split(train_data, label_data, stratify=train_df.target, random_state=42, test_size=0.2, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = len(tokenizer.word_index) + 1\nmax_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_path1 = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\"\n#embedding_path2 = \"../input/glove840b300dtxt/glove.840B.300d.txt\"\nembed_size = 300\n\ndef get_coefs(word,*arr):\n    return word, np.asarray(arr, dtype='float32')\n\ndef build_matrix(embedding_path, tokenizer):\n    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n\n    word_index = tokenizer.word_index\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n    for word, i in word_index.items():\n        if i >= max_features:\n            continue\n        embedding_vector = embedding_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    return embedding_matrix\n\nembedding_matrix = build_matrix(embedding_path1, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_data;\ndel train_df;\ndel test_df;\ndel tokenizer;\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    x = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(x, acc, 'b', label='Training acc')\n    plt.plot(x, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, 'b', label='Training loss')\n    plt.plot(x, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_HIDDEN = 256\nEMB_SIZE = 300\nLABEL_SIZE = 1\nMAX_FEATURES = max_features\nDROP_OUT_RATE = 0.2\nDENSE_ACTIVATION = \"sigmoid\"\nNUM_EPOCH = 5\nconv_size = 128\n\nBATCH_SIZE = 512\nLOSS_FUNC = \"binary_crossentropy\"\nOPTIMIZER_FUNC = \"adam\"\nMETRICS = [\"accuracy\"]\n\nfrom numpy.random import seed\nseed(42)\nfrom tensorflow import set_random_seed\nset_random_seed(42)\n\n\nmodel=Sequential()\nmodel.add(Embedding(max_features, EMB_SIZE, weights=[embedding_matrix], trainable=False))\n#model.add(keras.layers.Embedding(max_features, EMB_SIZE))\nmodel.add(SpatialDropout1D(DROP_OUT_RATE))\nmodel.add(LSTM(NUM_HIDDEN, return_sequences=True))\n#model.add(Dropout(rate=DROP_OUT_RATE))\nmodel.add(Conv1D(conv_size, 2, activation='relu', padding='same'))\nmodel.add(MaxPooling1D(5, padding='same'))\nmodel.add(Conv1D(conv_size, 3, activation='relu', padding='same'))\nmodel.add(GlobalMaxPooling1D())\n#model.add(Flatten())\nmodel.add(Dense(LABEL_SIZE, activation=DENSE_ACTIVATION))\n\ncheckpointer = ModelCheckpoint(monitor='val_acc', mode='max', filepath='model.hdf5', verbose=2, save_best_only=True)\nearlyStopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=0, mode='max')\n\nmodel.compile(loss=LOSS_FUNC, optimizer=OPTIMIZER_FUNC, metrics=METRICS)\n\nhistory_lstm = model.fit(\n    xtrain, \n    ytrain, \n    batch_size = BATCH_SIZE, \n    epochs = NUM_EPOCH, callbacks=[checkpointer, earlyStopping],\nvalidation_data=(xvalid, yvalid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history(history_lstm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ny_pred_lstm = model.predict_classes(xvalid, verbose=1, batch_size = BATCH_SIZE)\nprint(classification_report(yvalid, y_pred_lstm))\n\nprint()\nprint(\"accuracy_score\", accuracy_score(yvalid, y_pred_lstm))\n\nprint()\nprint(\"Weighted Averaged validation metrics\")\nprint(\"precision_score\", precision_score(yvalid, y_pred_lstm, average='weighted'))\nprint(\"recall_score\", recall_score(yvalid, y_pred_lstm, average='weighted'))\nprint(\"f1_score\", f1_score(yvalid, y_pred_lstm, average='weighted'))\n\nprint()\nfrom sklearn.metrics import confusion_matrix\nimport scikitplot as skplt\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_confusion_matrix(yvalid, y_pred_lstm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_in = '../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv'\nresult = model.predict(test_data, verbose=1, batch_size = BATCH_SIZE)\n\nsubmission = pd.read_csv(submission_in, index_col='id')\nsubmission['prediction'] = result\nsubmission.reset_index(drop=False, inplace=True)\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}