{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This tutorial is based on my previous one which was building a word embedding more a GRU layer.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['jigsaw-unintended-bias-in-toxicity-classification', 'glove6b100dtxt']\n","name":"stdout"}]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \nimport random\n# data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom nltk.tokenize import TweetTokenizer,sent_tokenize, word_tokenize \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nimport lightgbm as lgb\nfrom sklearn import metrics\nimport os\nimport torch\nimport warnings \n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D, add\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks,Sequential\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\nfrom keras.optimizers import Adam\n\n\nimport gensim \nfrom gensim.models import Word2Vec","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"**Process to prepare the data:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n#train=train[:250000]\ntest = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\nsub = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\nfor col in identity_columns + ['target']:\n    train[col] = np.where(train[col] >= 0.5, True, False)\n    ","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split train in train and validate\ntrain_df, valid_df = train_test_split(train, test_size=0.33, stratify=train['target'])\ntest_df=test\n\ntrain_df.loc[:,'size_comment']=train_df.comment_text.apply(lambda x:len(x))\nvalid_df.loc[:,'size_comment']=valid_df.comment_text.apply(lambda x:len(x))\ntest_df.loc[:,'size_comment']=test_df.comment_text.apply(lambda x:len(x))\n\n#train_df=train_df[:250000]\ntrain_df=train_df\ntrain_df.loc[:,'set_']=\"train\"\nvalid_df.loc[:,'set_']=\"valid\"\ntest_df.loc[:,'set_']=\"test\"\n\n\n#Set_indices=train_df.loc[:,'set_'][:250000]\nSet_indices=train_df.loc[:,'set_']\nSet_indices=Set_indices.append(valid_df.loc[:,'set_'])\nSet_indices=Set_indices.append(test_df.loc[:,'set_'])\n\n\n#y_train = train_df['target'][:250000]\ny_train = train_df['target']\ny_valid = valid_df['target']\n\n#Set_indices_labels=train_df.loc[:,'set_'][:250000]\nSet_indices_labels=train_df.loc[:,'set_']\nSet_indices_labels=Set_indices_labels.append(valid_df.loc[:,'set_'])","execution_count":5,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self.obj[key] = _infer_fill_value(value)\n/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self.obj[item] = s\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    from tensorflow import set_random_seed\n    set_random_seed(2)\n\nseed_everything()","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts=train_df['comment_text']\ntexts=texts.append(valid_df['comment_text'])\ntexts=texts.append(test_df['comment_text'])\n\n\nprint(texts.shape)\n\nlabels=train_df['target']\nlabels=labels.append(valid_df['target'])\n\nprint(labels.shape)","execution_count":7,"outputs":[{"output_type":"stream","text":"(347320,)\n(250000,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Tokenization:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\nmaxlen = 200\nmax_words = 50000\nembedding_size=100\nlr = 1e-3\nlr_d = 0\n\n\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\ndata = pad_sequences(sequences, maxlen=maxlen)\nlabels = np.asarray(labels)\nprint('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', labels.shape)\n","execution_count":9,"outputs":[{"output_type":"stream","text":"Found 159346 unique tokens.\nShape of data tensor: (347320, 200)\nShape of label tensor: (250000,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = data[Set_indices == \"train\"]\nx_val = data[Set_indices == \"valid\"]\nx_test = data[Set_indices == \"test\"]\n\n\ny_train = labels[Set_indices_labels == \"train\"]\ny_val = labels[Set_indices_labels == \"valid\"]\n\nprint('Shape of train tensor:', x_train.shape)\nprint('Shape of validate tensor:', x_val.shape)\nprint('Shape of test tensor:', x_val.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"Shape of train tensor: (167500, 200)\nShape of validate tensor: (82500, 200)\nShape of test tensor: (82500, 200)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Parsing the GloVe word-embeddings file**"},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_dir = '../input/glove6b100dtxt'\nembeddings_index = {}\nf = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n\n\n\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Found %s word vectors.' % len(embeddings_index))","execution_count":11,"outputs":[{"output_type":"stream","text":"Found 400000 word vectors.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Building the word embedding matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 100\nembedding_matrix = np.zeros((max_words, embedding_dim))\nfor word, i in word_index.items():\n    if i < max_words:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building the model:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.layers as L\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\nsequence_input = L.Input(shape=(maxlen,), dtype='int32')\nembedding_layer = L.Embedding(max_words,embedding_dim,\n                                weights=[embedding_matrix],\n                                input_length=maxlen,\n                                trainable=True)\nx = embedding_layer(sequence_input)\nx = L.GRU(embedding_dim)(x)\n#x = L.Dense(32, activation='relu')(x)\n#x = Model(inputs=sequence_input, outputs=x)\n\ny = L.Input(shape=(1,), dtype='float32')\n#y = L.Dense(1, activation='relu')(sequence_input_length)\n#y = Model(inputs=sequence_input_length, outputs=y)\n\ncombined = concatenate([x, y])\n\ncombined = L.Dense(32, activation='relu')(combined)\npreds = L.Dense(1, activation='sigmoid')(combined)\n\nmodel = Model(inputs=[sequence_input, y], outputs=preds)\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nckpt = ModelCheckpoint(f'gru.hdf5', save_best_only = True)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.005\nlr_d = 0\n\nhistory = model.fit([x_train, train_df.size_comment], y_train,\n                    epochs=100,\n                    batch_size=12000,\n                    validation_data=([x_val, valid_df.size_comment], y_val),\n                    callbacks = [es,ckpt])\n","execution_count":21,"outputs":[{"output_type":"stream","text":"Train on 167500 samples, validate on 82500 samples\nEpoch 1/100\n167500/167500 [==============================] - 17s 104us/step - loss: 1.0381 - acc: 0.8531 - val_loss: 0.9313 - val_acc: 0.8695\nEpoch 2/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.8325 - acc: 0.9129 - val_loss: 0.6865 - val_acc: 0.9119\nEpoch 3/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.5560 - acc: 0.9205 - val_loss: 0.4080 - val_acc: 0.9301\nEpoch 4/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.2873 - acc: 0.9365 - val_loss: 0.2006 - val_acc: 0.9260\nEpoch 5/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.1378 - acc: 0.9484 - val_loss: 0.1425 - val_acc: 0.9477\nEpoch 6/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.1130 - acc: 0.9544 - val_loss: 0.1405 - val_acc: 0.9462\nEpoch 7/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.0996 - acc: 0.9590 - val_loss: 0.1446 - val_acc: 0.9476\nEpoch 8/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.0874 - acc: 0.9641 - val_loss: 0.1528 - val_acc: 0.9433\nEpoch 9/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.0740 - acc: 0.9699 - val_loss: 0.1709 - val_acc: 0.9435\nEpoch 10/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.0616 - acc: 0.9757 - val_loss: 0.1919 - val_acc: 0.9408\nEpoch 11/100\n167500/167500 [==============================] - 16s 97us/step - loss: 0.0509 - acc: 0.9805 - val_loss: 0.2199 - val_acc: 0.9396\nEpoch 00011: early stopping\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Look at the loss and the gain in accuracy for each epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.clf()\nacc = history_dict['acc']\nval_acc = history_dict['val_acc']\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Run final model with the right number of iteration**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the model\n#loss, accuracy = model.evaluate(x_train, y_train, verbose=2)\n#print('Accuracy train: %f' % (accuracy*100))\n\n# evaluate the model\n#loss, accuracy = model.evaluate(x_val, y_val, verbose=2)\n#print('Accuracy validate: %f' % (accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test my word embedding on my local test with Jigsaw metric**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npred_val = model.predict([x_val, valid_df.size_comment], batch_size = 12000, verbose = 0)\n","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_NAME = 'my_model'\nTOXICITY_COLUMN = 'target'\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\nvalid_df[MODEL_NAME] = pred_val\n\nSUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]]\n    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[df[subgroup] & df[label]]\n    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label], examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n\nbias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\nprint(bias_metrics_df)\n\ndef calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]\n    predicted_labels = df[model_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n    \nlocal_valid=get_final_metric(bias_metrics_df, calculate_overall_auc(valid_df, MODEL_NAME))\nprint(local_valid)\nlocal_valid.tofile('local_valid.csv',sep=',',format='%10.5f')\n#accuracy.tofile('accuracyEmbedding.csv',sep=',',format='%10.5f')\n","execution_count":23,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n","name":"stderr"},{"output_type":"stream","text":"   bnsp_auc  bpsn_auc      ...       subgroup_auc  subgroup_size\n6  0.896103  0.797845      ...           0.759843            808\n4  0.826253  0.860566      ...           0.774633            189\n5  0.906925  0.805043      ...           0.780164            460\n7  0.907439  0.799656      ...           0.782614            983\n2  0.894485  0.823957      ...           0.813767            412\n0  0.876806  0.867824      ...           0.826562           1986\n1  0.878415  0.873107      ...           0.835660           2554\n3  0.875649  0.880913      ...           0.843544           1203\n8  0.917535  0.881673      ...           0.887654            297\n\n[9 rows x 5 columns]\n0.8594710044839958\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Apply the model on the test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npred = model.predict([x_test, test_df.size_comment], batch_size = 12000, verbose = 1)\n\n           \nsub = pd.DataFrame({\"id\": test['id'].values})\nsub[\"prediction\"] = pred\n\nsub.to_csv('submission.csv', index=False)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}