{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Problem Statement**\nThe content, tone, and format of job bulletins can influence the quality of the applicant pool. Overly-specific job requirements may discourage diversity. The Los Angeles Mayor’s Office wants to reimagine the city’s job bulletins by using text analysis to identify needed improvements.\n\nThe goal is to convert a folder full of plain-text job postings into a single structured CSV file and then to use this data to: (1) identify language that can negatively bias the pool of applicants; (2) improve the diversity and quality of the applicant pool; and/or (3) make it easier to determine which promotions are available to employees in each job class.\n\n\n**Introduction**\nAs a beginner looking at this problem, I could see that the first task was to get the data into a CSV. I did some google research on 'text to CSV', 'text parsing' etc and a lot of blogs recommended REGEX.I decided I will give it a try and for this data set, I found it to work decently; for the simple reason that most of the JOB Bulletins here are in a similar format.\n\nSo the catch here is that this technique will not work so well if we have Job bulletins from different organisations that are structurally very different. For that kind of a problem, we will need a better solution.\n\nHowever since I am a beginner, I thought \"Let me try cracking this using REGEX and later I will find a framework or a library that will solve my problem more efficiently\""},{"metadata":{},"cell_type":"markdown","source":"The below code initialises the environment.\n\nAt this point , I listed all the files in the directory basically to get familiar with the directory"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport csv\nimport re\n\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n# print(os.listdir(\"../input/cityofla/CityofLA/Job Bulletins\"))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step is to define the REGEXES to identify each section\n\nI started out with trying to get the TITLE, Class code and Open Date from all the job bulletins. This was my first time using regex, so I started out simple and eventually built the regex for each section. \n\nI used https://regex101.com/  to help build these. I could see that the regex would often break on certain files. I would immprove the regex by working against these files. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Defining dictionary of the REGEX for each category. Still pending to extract salaries for Department of Water and Power.\n\nrx_dict = {\n    'TITLE': re.compile(r'(?P<title>.*)(\\n+.*Class Code:)'),\n    'Class Code': re.compile(r'(Class Code:)(?P<classcode>.*)(\\n)'),\n    'Open Date': re.compile(r'(Open Date:)(?P<open_date>.*)(\\n)'),\n    'Annual Salary': re.compile(r'ANNUAL\\s*SALARY\\s*\\n*\\s*(?P<Lowerend>\\$\\d*,\\d*)(\\s*to\\s*(?P<Upperend>\\$\\d*,\\d*)|.*)'),\n    'Salary DWP': re.compile(r'ANNUAL\\s*SALARY(.|\\n)*?.*Department of Water and Power.*(?P<Lowerend>\\$\\d*,\\d*)(\\s*to\\s*(?P<Upperend>\\$\\d*,\\d*))'),\n    'DUTIES': re.compile(r'(DUTIES(?P<Duties>(.|\\n)*?))(SELECTION PROCESS|APPLICATION DEADLINE|WHERE TO APPLY|MINIMUM\\s*QUALIFICATIONS|QUALIFICATIONS|REQUIREMENTS|QUALIFICATION|REQUIREMENT|\\Z)'),\n    'REQUIREMENTS': re.compile(r'((REQUIREMENT|REQUIREMENT/MINIMUM QUALIFICATION|QUALIFICATION|QUALIFICATIONS)(?P<Requirement>(.|\\n)*?))(SELECTION PROCESS|APPLICATION DEADLINE|WHERE TO APPLY|\\Z)'),\n    'WHERE TO APPLY': re.compile(r'(WHERE TO APPLY(?P<WheretoApply>(.|\\n)*?))(SELECTION PROCESS|APPLICATION DEADLINE|\\Z)'),\n    'APPLICATION DEADLINE': re.compile(r'(APPLICATION DEADLINE(?P<ApplicationDeadline>(.|\\n)*?))(SELECTION PROCESS|\\Z)'),\n    'SELECTION PROCESS': re.compile(r'(SELECTION PROCESS(?P<SelectionProcess>(.|\\n)*?))(\\Z)'),\n    'ALL':re.compile(r'(DUTIES(?P<Duties>(.|\\n)*))((REQUIREMENTS|REQUIREMENTS\\\\MINIMUM QUALIFICATIONS|QUALIFICATIONS|REQUIREMENT|QUALIFICATION)(?P<Requirements>(.|\\n)*))(WHERE TO APPLY(?P<Wheretoapply>(.|\\n)*))(APPLICATION DEADLINE(?P<ApplicationDeadline>(.|\\n)*))(SELECTION PROCESS(?P<SelectionProcess>(.|\\n)*))')\n}\n                             \n                            \n\n       \n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is the code for fileparser. It accepts the file path and file name and parses the said file and returns  a list containing the fields picked up."},{"metadata":{"trusted":true},"cell_type":"code","source":"def _parse_file(filepath,filename):\n    data = []  # create an empty list to collect the data\n    # open the file and read through it line by line\n    Salary_lower_gen = \"\"\n    Salary_upper_gen = \"\"\n    Salary_lower_DWP = \"\"\n    Salary_upper_DWP = \"\"\n    Title = \"\"\n    Title_final = \"\"\n    Class_code = \"\"\n    Class_code_final = \"\"\n    Duties = \"\"\n    Duties1 = \"\"\n    Duties_final = \"\"\n    Requirements = \"\"\n    Requirements1 = \"\"\n    Requirement_final =\"\"\n    Where_to_apply = \"\"\n    Where_to_apply1 = \"\"\n    Where_to_apply_final = \"\"\n    Application_deadline = \"\"\n    Application_deadline1 = \"\"\n    Application_deadline_final = \"\"\n    Selection_process = \"\"\n    Selection_process1= \"\"\n    Selection_process_final = \"\"\n    \n    with open(filepath, 'r', encoding=\"latin-1\") as file_object:\n        line = file_object.read()\n        for key, rx in rx_dict.items():\n            match = rx.search(line)\n            if match:\n                #print(\"Enter\")\n                if key == 'TITLE':\n                    Title = \"\" if not match.group('title') else match.group('title').strip() \n                    #print(Title)\n           \n                if key == 'Class Code':\n                    Class_code = \"\" if not match.group('classcode') else match.group('classcode').strip() \n                    #print(Class_code)\n                \n            \n                if key == 'Open Date':\n                    Open_date = \"\" if not match.group('open_date') else match.group('open_date').strip()\n                    #print(Open_date)\n                    \n                if key == 'Annual Salary':\n                    Salary_lower_gen = \"\" if not match.group('Lowerend') else match.group('Lowerend').strip()\n                    Salary_upper_gen = \"\" if not match.group('Upperend') else match.group('Upperend').strip()\n                    #print(Salary_lower_gen, Salary_upper_gen)\n                if key == 'Salary DWP':\n                    Salary_lower_DWP = \"\" if not match.group('Lowerend') else match.group('Lowerend').strip()\n                    Salary_upper_DWP = \"\" if not match.group('Upperend') else match.group('Upperend').strip()\n                    \n                \n                #if key == 'DUTIES':\n                    #Duties = 'default' if not match.group('Duties') else match.group('Duties')\n                    #print(Salary_lower_gen, Salary_upper_gen)\n                if key == 'ALL':\n                    Duties = \"\" if not match.group('Duties') else match.group('Duties')\n                    Requirements = \"\" if not match.group('Requirements') else match.group('Requirements')\n                    Where_to_apply = \"\" if not match.group('Wheretoapply') else match.group('Wheretoapply')\n                    Application_deadline = \"\" if not match.group('ApplicationDeadline') else match.group('ApplicationDeadline')\n                    Selection_process = \"\" if not match.group('SelectionProcess') else match.group('SelectionProcess')\n                    #print(Salary_lower_gen, Salary_upper_gen)   \n                if key == 'DUTIES':\n                    Duties1 = \"\" if not match.group('Duties') else match.group('Duties')\n                if key == 'REQUIREMENTS':\n                    Requirements1 = \"\" if not match.group('Requirement') else match.group('Requirement')\n                if key == 'WHERE TO APPLY':\n                    Where_to_apply1 = \"\" if not match.group('WheretoApply') else match.group('WheretoApply')\n                if key == 'APPLICATION DEADLINE':\n                    Application_deadline1 = \"\" if not match.group('ApplicationDeadline') else match.group('ApplicationDeadline')\n                if key == 'SELECTION PROCESS':\n                    Selection_process1 = \"\" if not match.group('SelectionProcess') else match.group('SelectionProcess')\n           \n    # Extract each field using two different regexes and obtain the best possible result.\n    Duties_final = Duties1.strip() if not Duties else Duties.strip()                \n    Requirements_final = Requirements1.strip() if not Requirements else Requirements.strip()\n    Where_to_apply_final = Where_to_apply1.strip() if not Where_to_apply else Where_to_apply.strip()\n    Application_deadline_final = Application_deadline1.strip() if not Application_deadline else Application_deadline.strip()\n    Selection_process_final = Selection_process1.strip() if not Selection_process else Selection_process.strip()\n    Title_final = re.split('[0-9]',filename)[0].strip() if not Title else Title\n    #print(re.split('[0-9]',filename)[0].strip())\n    try:\n        Class_code_final = re.split('(\\s\\d\\d\\d\\d\\s)',filename)[1].strip() if not Class_code else Class_code\n    except: \n        Class_code_final =  Class_code\n    row = {\n                'FILENAME': filename,\n                'JOB_CLASS_TITLE': Title_final,\n                'JOB_CLASS_NO': Class_code_final,\n                'ENTRY_SALARY_GEN': Salary_lower_gen,\n                'HIGHEST_SALARY_GEN': Salary_upper_gen,\n                'ENTRY_SALARY_DWP': Salary_lower_DWP,\n                'HIGHEST_SALARY_DWP': Salary_upper_DWP,\n                'DUTIES': Duties_final,\n                'REQUIREMENTS': Requirements_final,\n                'WHERE_TO_APPLY': Where_to_apply_final,\n                'APPLICATION_DEADLINE': Application_deadline_final,\n                'SELECTION_PROCESS': Selection_process_final\n              }\n\n    data.append(row)\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The parser function is called for each file withing the Job Bulletins folder."},{"metadata":{"trusted":true},"cell_type":"code","source":"#for file in JD_Filename:\nfilepath = \"../input/cityofla/CityofLA/Job Bulletins/\" \ndf = pd.DataFrame(columns = ['FILENAME','JOB_CLASS_TITLE','JOB_CLASS_NO', 'ENTRY_SALARY_GEN' , 'HIGHEST_SALARY_GEN', 'ENTRY_SALARY_DWP','HIGHEST_SALARY_DWP','DUTIES','REQUIREMENTS',                'WHERE_TO_APPLY',\n                'APPLICATION_DEADLINE',\n                'SELECTION_PROCESS'])\n\n#Parsing through all the files and calling the parser function\nfor file in os.listdir(filepath):\n    #print(file)\n    data =_parse_file(filepath + file,file)\n    #print(data)\n    df = df.append(data, ignore_index = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submitting Output"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Writing output to CSV\noutput = df\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point, we have just managed to extract the raw data and put it into a structured format. We are still to extract some fields like whether a driving license is mandatory etc.\n\nNExt I am planning to do some data exploration to moving into extraction of finer details."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}