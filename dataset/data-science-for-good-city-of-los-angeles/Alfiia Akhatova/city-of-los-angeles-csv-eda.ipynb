{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>Data Science for Good: City of Los Angeles</center></h1> \n<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/89/Los_Angeles%2C_Winter_2016.jpg\" style=\"height:400px\">\n\n### Problem statement\n\nAbout 30 percent of Los Angeles's 50,000 city employees are eligible to retire in 2020. Let's help to the city to attract young workers to take their place!\n\n**Goal.** Convert a folder full of plain-text job postings into a structured CSV file and do the analysis of the content, tone, and format of job bulletins. \n\n**The objectives:** \n- identify language that can bias the pool of applicants\n- improve the diversity and quality of the applicant pool; and/or\n- increase the discoverability of promotional pathways"},{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport os\nimport string\nimport operator\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\n#from afinn import Afinn\nfrom datetime import datetime\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom sklearn.base import BaseEstimator, TransformerMixin\n \nimport gensim\nfrom gensim.models import word2vec\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import wordnet as wn\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import sentiwordnet as swn\nfrom nltk import sent_tokenize, word_tokenize, pos_tag\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot, init_notebook_mode\n# Using plotly + cufflinks in offline mode\nimport cufflinks\ncufflinks.go_offline(connected=True)\ninit_notebook_mode(connected=True)\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read the CSV files"},{"metadata":{"trusted":true},"cell_type":"code","source":"additional = '../input/data-science-for-good-city-of-los-angeles/cityofla/CityofLA/Additional data'\njob_titles=pd.read_csv(additional+'/job_titles.csv',names=[\"JOB_TITLE\"])\nsample_job=pd.read_csv(additional+'/sample job class export template.csv')\nkaggle_data=pd.read_csv(additional+'/kaggle_data_dictionary.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature extraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# UTILS\nbulletins = '../input/data-science-for-good-city-of-los-angeles/cityofla/CityofLA/Job Bulletins'\n# Exclude the bulletins with inappropriate filling\nvalid_bulletins = [i for i in os.listdir(bulletins) if i not in ('ANIMAL CARE TECHNICIAN SUPERVISOR 4313 122118.txt',\n                                               'WASTEWATER COLLECTION SUPERVISOR 4113 121616.txt',\n                                               'SENIOR EXAMINER OF QUESTIONED DOCUMENTS 3231 072216 REVISED 072716.txt',\n                                               'SENIOR UTILITY SERVICES SPECIALIST 3753 121815 (1).txt',\n                                               'CHIEF CLERK POLICE 1219 061215.txt',\n                                               'Vocational Worker  DEPARTMENT OF PUBLIC WORKS.txt')]\n# Requiremens - Full Text\ndef get_requirement(line):\n    i = 1\n    req = []\n    while True:\n        req.append(data_list[line + i])\n        i+=1\n        if any(x in data_list[line + i] for x in headers):\n            break\n    return list(filter(None, req))\n                   \n# Salary\n# https://www.kaggle.com/ranimdewaib/city-of-la-convert-text-files-to-csv-file\ndef get_salary(line):\n    global salary_gen\n    global salary_dwp \n    salary = []\n    \n    if \"flat\" in line.lower().strip() and \"Department of Water and Power\" not in line.strip(): #flat and not dwp(gen)\n        salary_gen = re.search(r\"\\$\\d{2,3}\\,\\d{3}\", line.lower()).group()\n        salary_dwp = \"\"\n    if \"flat\" not in line.lower().strip() and \"Department of Water and Power\" not in line.strip(): #not flat and not dwp(gen)\n        salary_gen = re.search(r\"\\$\\d{2,3}\\,\\d{3}\\sto\\s\\$\\d{2,3}\\,\\d{3}|\\$\\d{2,3}\\,\\d{3}[*]\\sto\\s\\$\\d{2,3}\\,\\d{3}|\\$\\d{2,3}\\,\\d{3}\", line.lower()).group().replace(\"to\",\"-\")\n        salary_dwp = \"\"\n    if \"flat\" in line.lower().strip() and \"Department of Water and Power\" in line.strip(): #flat and dwp\n        salary_dwp = re.search(r\"\\$\\d{2,3}\\,\\d{3}\", line.lower()).group()\n    if \"flat\" not in line.lower().strip() and \"Department of Water and Power\" in line.strip(): #not flat and dwp\n        salary_dwp = re.search(r\"\\$\\d{2,3}\\,\\d{3}\\sto\\s\\$\\d{2,3}\\,\\d{3}|\\$\\d{2,3}\\,\\d{3}\\sto\\s\\$\\d{2,3}\\,\\s\\d{3}\", line.lower()).group().replace(\"to\",\"-\")\n \n    salary.append(salary_gen)\n    salary.append(salary_dwp)\n\n    return salary\n                   \n# Examination Type\n# https://www.kaggle.com/danielbecker/l-a-jobs-data-exctraction-eda\ndef get_exam_type(text):\n\n    regex_dic = {'OPEN_INT_PROM':r'BOTH.*INTERDEPARTMENTAL.*PROMOTIONAL', \n                 'INT_DEPT_PROM':r'INTERDEPARTMENTAL.*PROMOTIONAL', \n                 'DEPT_PROM':r'DEPARTMENTAL.*PROMOTIONAL',\n                 'OPEN':r'OPEN.*COMPETITIVE.*BASIS'\n                }\n    result = np.nan\n    for key, value in regex_dic.items():\n        regex = value\n        regex_find = re.findall(regex, text, re.DOTALL|re.IGNORECASE)\n        if regex_find:\n            result = key\n            break\n    return result\n\n# Driver's license requirement (R and P) & licence type (A, B, C)\ndef get_drive(text):\n    global lic_req\n    global lic_type\n    \n    req_dic = {'is required':'R', 'may require':'P'}\n    \n    lic_req = np.nan\n    lic_type = np.nan\n    \n    drive_search = re.search(r'(is required|may require)', text, re.IGNORECASE)\n    if drive_search:\n        lic_req = drive_search.group(0)\n        lic_req = req_dic[lic_req]\n           \n    drive_lic_type_search = re.findall(r\"(Class \\w,\\s*\\w|Class \\w)\", text, re.IGNORECASE)\n    lic_type = ','.join(drive_lic_type_search).upper().replace(\"CLASS \", \"\")\n    \n    return lic_req, lic_type","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Extracting features from Full Bulletin Text\nJOB = []\nfor file_name in valid_bulletins:\n    with open(bulletins + '/' + file_name, encoding = \"ISO-8859-1\", errors = 'ignore') as f:\n        file = f.read().replace('\\t','')\n        data = file.replace('\\n','')\n        data_list = file.split('\\n')\n        headers = [head for head in data_list if head.isupper()]\n        class_title = headers[0].lower()  # JOB_CLASS_TITLE\n        exam_type = get_exam_type(data)\n        lic_req = np.nan\n        lic_type = np.nan\n        deadline = np.nan\n        for line in range(len(data_list)):\n            if \"Class Code:\" in data_list[line]:\n                class_code = data_list[line].split(\"Class Code:\")[1].strip()  # JOB_CLASS_NO\n            if \"Open Date:\" in data_list[line]:                              \n                open_date = data_list[line].split(\"Open Date:\")[1].split(\"(\")[0].strip() # OPEN_DATE  \n            if \"DUTIES\" in data_list[line]:\n                job_duties = data_list[line+2]  # JOB_DUTIES\n            if \"driver's license\" in data_list[line]:\n                function = get_drive(data_list[line])\n                try:\n                    lic_req = function[0]  # DRIVERS_LICENSE_REQ\n                    lic_type = function[1] # DRIV_LIC_TYPE\n                except TypeError:\n                    lic_req = np.nan\n                    lic_type = np.nan\n            if bool(re.search(r\"\\$\\d{2,3}\\,\\d{3}\", data_list[line])): \n                salary_gen = get_salary(data_list[line])[0] \n                salary_dwp = get_salary(data_list[line])[1]\n            if \"REQUIRE\" in data_list[line]:                                      \n                req = get_requirement(line) # REQUIREMENTS_Full_Text\n            if \"APPLICATION DEADLINE\" in data_list[line]:\n                deadline_search = re.search(r'([A-Z]{1,9})\\s(\\d{1,2},\\s\\d{4})',data_list[line + 2])        \n                if deadline_search:\n                    deadline = deadline_search.group()  # DEADLINE\n\n        JOB.append([file_name, class_title, class_code, open_date, \n                    exam_type, job_duties, salary_gen, salary_dwp, \n                    req, lic_req, lic_type, deadline])\n        \ndf = pd.DataFrame(JOB)\ndf.columns = [\"FILE_NAME\", \"JOB_CLASS_TITLE\", 'JOB_CLASS_NO', 'OPEN_DATE', \n              \"EXAM_TYPE\", \"JOB_DUTIES\", \"ENTRY_SALARY_GEN\", \"ENTRY_SALARY_DWP\", \n              \"REQ_TEXT\",\"DRIVERS_LICENSE_REQ\", \"DRIV_LIC_TYPE\", \"DEADLINE\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"REQ_TEXT\"][14]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the Requirement Full Text into rows: each requirement in one row\ndef splitDataFrameList(df,target_column):\n    ''' df = dataframe to split,\n    target_column = the column containing the values to split\n    returns: a dataframe with each entry for the target column separated, with each element moved into a new row. \n    The values in the other columns are duplicated across the newly divided rows.\n    '''\n    row_accumulator = []\n\n    def splitListToRows(row):\n        split_row = row[target_column]\n        for s in split_row:\n            new_row = row.to_dict()\n            new_row[target_column] = s\n            row_accumulator.append(new_row)\n\n    df.apply(splitListToRows, axis=1)\n    new_df = pd.DataFrame(row_accumulator)\n    return new_df[df.columns]\n\ndf_new = splitDataFrameList(df,'REQ_TEXT')\ndf_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utils for Feature Exctraction from Requirement Text\n# Requirement set and subset IDs \ndef req_set_subset_id(text):\n    reg_expr_set = r'^\\d(?=\\.)'\n    reg_expr_subset = r'^[a-z](?=\\.)'\n    set_search = re.finditer(reg_expr_set, text)\n    if set_search:\n        set_search_result = ''.join([(x.group(0)) for x in set_search])\n    else:\n        set_search_result = ''\n\n    subset_search = re.finditer(reg_expr_subset, text, re.MULTILINE|re.IGNORECASE)\n    if subset_search:\n        subset_search_result = ''.join([(x.group(0)) for x in subset_search])\n    else:\n        subset_search_result = ''\n        \n    return set_search_result, subset_search_result\n\n# Full Time or Part Time Job?\ndef get_full_time_part_time(text):\n    full_time_search = re.search(r'full\\s*-\\s*time', text, re.DOTALL|re.IGNORECASE)\n    part_time_search = re.search(r'part\\s*-\\s*time', text, re.DOTALL|re.IGNORECASE)\n    if full_time_search:\n        full_time_part_time = 'FULL_TIME'\n    elif part_time_search:\n        full_time_part_time = 'PART_TIME'\n    else:\n        full_time_part_time = np.nan\n    return full_time_part_time\n\n# Required Job Experience : Job Title\ndef get_job_title(text):\n    job_list = job_titles.values\n    job_list = job_titles['JOB_TITLE'].values\n    job_list = [x for x in job_list if str(x) != 'nan']\n    job_list = list(filter(lambda x: re.sub(\"[^a-zA-Z]\",\"\", x), job_list))\n    job_list = [x.lower() for x in job_list]\n    jobs = []\n    for job in job_list:\n        if job in text.lower():\n            jobs.append(job)\n    return '|'.join(jobs)\n\n# Required Job Experience Length\ndef get_experience_length(text):\n    num_dic = {'one':1, 'two':2, 'three':3, 'four':4, 'five':5,\n                'six':6, 'seven':7, 'eight':8, 'nine':9, 'ten':10}\n    result = np.nan\n    regex_search = re.search(r'(\\w{3,5}|\\d{1,2})\\s*(months?|years?)\\s(of\\sfull\\s*-\\s*time|of\\spart\\s*-\\s*time)', text, re.IGNORECASE)\n    if regex_search:\n        exp_len_raw = regex_search.group(1).lower()\n        if exp_len_raw.isnumeric():\n            exp_len = exp_len_raw\n        elif exp_len_raw in num_dic:\n            exp_len = num_dic[exp_len_raw]\n        else:\n            exp_len = ''\n      \n        units = regex_search.group(2).lower()\n        if 'year' in units and str(exp_len).isnumeric():\n            result = float(exp_len)\n        if 'month' in units and str(exp_len).isnumeric():\n            result = round(float(exp_len)/12.0, 2)\n    return result\n\n# Required Job Experience : Job Function\ndef get_job_func(text):\n    functions = ''\n    function_search = re.search(r'(experience in|worker in|the responsibility for|performing|performance of|working on)', text, re.IGNORECASE)\n    if function_search:\n        functions = text.split(function_search.group())[1].strip()\n    return functions\n    \n\n# Required Education Type \ndef get_school(text):    \n    \n    num_dic = {'one':1, 'two':2, 'three':3, 'four':4, 'five':5,\n                'six':6, 'seven':7, 'eight':8, 'nine':9, 'ten':10}\n    \n    num_dic_1 = {'one-year':1, 'two-year':2, 'three-year':3, 'four-year':4, 'five-year':5}\n    \n    edu_years = np.nan\n    school_type = np.nan\n    school_search = re.search(r'(\\w+|\\w{3,5}-year?)\\s*(college or university|college|university|high school|apprenticeship)', text, re.DOTALL|re.IGNORECASE)\n    school_len_search = re.search(r'(\\w{3,5}|\\d{1,2})(\\s*)(year?|month?|semester?)\\s*(college or university|college|university|high school|apprenticeship)', text, re.DOTALL|re.IGNORECASE)\n    \n    if school_search:\n        school_len_raw = school_search.group(1)\n        school_type = school_search.group(2).upper()\n        if school_type == 'COLLEGE' or school_type == 'UNIVERSITY':\n            school_type = 'COLLEGE OR UNIVERSITY'\n        if school_len_raw in num_dic_1:\n            school_len = num_dic_1[school_len_raw]\n        else:\n            school_len = ''\n        edu_years = school_len\n    \n    if school_len_search:\n        school_len_raw = school_len_search.group(1).lower()\n        units = school_len_search.group(3).lower()\n        \n        if school_len_raw.isnumeric():\n            school_len = school_len_raw\n        elif school_len_raw in num_dic:\n            school_len = num_dic[school_len_raw]\n        else:\n            school_len = ''\n\n        if 'year' in units and str(school_len).isnumeric():\n            edu_years = float(school_len)\n\n        if 'month' in units and str(school_len).isnumeric():\n            edu_years = round(float(school_len)/12.0, 2)\n\n        if 'semester' in units and str(school_len).isnumeric():\n            edu_years = round(float(school_len)/2.0, 2)\n        \n    return edu_years, school_type\n\n# Required Courses\ndef get_courses(text):\n    courses = ''\n    courses_search = re.search(r'(course in|courses in)\\s*(\\w+\\s*and\\s*\\w+|\\w+)', text, re.IGNORECASE)\n    if courses_search:\n        courses = courses_search.group(2).split(' and ')\n    return '|'.join(courses).upper()\n\n\n# Required Length of Courses\ndef get_courses_length(text):\n    result = ''\n    semester = ''\n    quarter = ''\n    semester_search = re.search(r'(\\d{1,2})\\s(semester?)', text, re.DOTALL|re.IGNORECASE)\n    quarter_search = re.search(r'(\\d{1,2})\\s(quarter?)', text, re.DOTALL|re.IGNORECASE)\n    courses_search = re.search(r'(course in|courses in)', text, re.IGNORECASE)\n    if semester_search and courses_search:\n        semester = semester_search.group(1)\n    if quarter_search and courses_search:\n        quarter = quarter_search.group(1)\n    if semester.isnumeric() and quarter.isnumeric():\n        result = str(quarter) + 'Q' + '/' + str(semester) + 'S'\n    return result\n\n# Education major\n'''\nUse the major list from https://github.com/fivethirtyeight/data/tree/master/college-majors\nand word2Vec representing words as vectors\nto calculate the cosine similarity between words and \nfind the words more similar to the education majors presented in the majors-list.csv\n\n'''\ndef word2vec(word):\n    from collections import Counter\n    from math import sqrt\n\n    # count the characters in word\n    cw = Counter(word)\n    # precomputes a set of the different characters\n    sw = set(cw)\n    # precomputes the \"length\" of the word vector\n    lw = sqrt(sum(c*c for c in cw.values()))\n\n    # return a tuple\n    return cw, sw, lw\n\ndef cosdis(v1, v2):\n    # which characters are common to the two words?\n    common = v1[1].intersection(v2[1])\n    # by definition of cosine distance we have\n    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]\n\nmajors_df = pd.read_csv('../input/majorslist/majors-list.csv')\nmajors_list = majors_df['Major'].values\nmajors_list = [x for x in majors_list if str(x) != 'nan']\nmajors_list = list(filter(lambda x: re.sub(\"[^a-zA-Z]\",\"\", x), majors_list))\nmajors_list = [x.lower() for x in majors_list]\n\ndef get_education_major(text):\n    \n    single_list = text.split()\n    double_list = list(map(' '.join, zip(single_list[:-1], single_list[1:])))\n    text_list = single_list + double_list\n\n    results = []\n    threshold = 0.94\n    for key in majors_list:\n        for word in text_list:\n            try:\n                res = cosdis(word2vec(word), word2vec(key))\n                if res > threshold:\n                    #print(\"Found a word with cosine distance > 94 - {} : {} with original word: {}\".format(res*100, word, key))\n                    if key not in results:\n                        results.append(key)\n            except IndexError:\n                pass\n    return '|'.join(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract features from Requirement Full Text\ndf_new['REQUIREMENT_SET_ID'], df_new['REQUIREMENT_SUBSET_ID'] = zip(*df_new['REQ_TEXT'].map(req_set_subset_id))\ndf_new['EDUCATION_YEARS'], df_new['SCHOOL_TYPE'] = zip(*df_new['REQ_TEXT'].map(get_school))\ndf_new['EDUCATION_MAJOR'] = df_new['REQ_TEXT'].map(get_education_major)\ndf_new['EXPERIENCE_LENGTH'] = df_new['REQ_TEXT'].map(get_experience_length)\ndf_new['FULL_TIME_PART_TIME'] = df_new['REQ_TEXT'].map(get_full_time_part_time)\ndf_new['EXP_JOB_CLASS_TITLE'] = df_new['REQ_TEXT'].map(get_job_title)\ndf_new['EXP_JOB_CLASS_FUNCTION'] = df_new['REQ_TEXT'].map(get_job_func)\ndf_new['COURSE_SUBJECT'] = df_new['REQ_TEXT'].map(get_courses)\ndf_new['COURSE_LENGTH'] = df_new['REQ_TEXT'].map(get_courses_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating CSV file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.to_csv('City of Los Angeles.csv', index=False)\n#df_new = pd.read_csv('City of Los Angeles.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Job posting for diverse candidates\n\nEven [one word in job description](https://www.fastcompany.com/3044094/how-changing-one-word-in-job-descriptions-can-lead-to-more-diverse-candid) can affect whether or not you are attracting a diverse talent pool. Here are a few suggestion from [experts to improve the job descriptions](https://business.linkedin.com/talent-solutions/blog/job-descriptions/2018/5-must-dos-for-writing-inclusive-job-descriptions):\n-  Avoid gender-coded words, like “rockstar,” “hackers” and “dominate”. [Studies show](https://business.linkedin.com/talent-solutions/blog/job-descriptions/2016/17-words-that-are-turning-women-away-from-your-jobs) that gender-coded words can significantly reduce the number of women applying to your open positions, even though this type of bias is usually unconscious.\n-  Limit your job requirements to “must-haves”. [Studies show](https://hbr.org/2014/08/why-women-dont-apply-for-jobs-unless-theyre-100-qualified) that while men are likely to apply to jobs for which they meet only 60% of the qualifications, women are much more likely to hesitate unless they meet 100% of the listed requirements.\n- Avoid using unnecessary corporate speak and jargon. That includes things like KPIs, procurement, SLAs, P&L, and so on. While candidates with plenty of experience in a similar role might know what you’re talking about, [studies show](https://business.linkedin.com/talent-solutions/blog/job-descriptions/2017/cut-the-jargon-and-3-other-tips-for-entry-level-job-description) jargon and corporate language in job postings is one of the biggest barriers keeping talented young people from applying to entry-level positions.\n- Emphasize your commitment to diversity and inclusion.While you can simply state at the bottom that you are “an equality opportunity employer,” a statement in your own words is more powerful.\n- Call out inclusive benefits like parental leave and childcare subsidies\n"},{"metadata":{},"cell_type":"markdown","source":"### Clean the bulletin text"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CleanText(BaseEstimator, TransformerMixin):\n    def remove_mentions(self, input_text):\n        return re.sub(r'@\\w+', '', input_text)\n    \n    def remove_urls(self, input_text):\n        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n    \n    def remove_punctuation(self, input_text):\n        # Make translation table\n        punct = string.punctuation\n        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n        return input_text.translate(trantab)\n\n    def remove_digits(self, input_text):\n        return re.sub('\\d+', '', input_text)\n    \n    def to_lower(self, input_text):\n        return input_text.lower()\n    \n    def remove_stopwords(self, input_text):\n        stopwords_list = stopwords.words('english')\n        # Some words which might indicate a certain sentiment are kept via a whitelist\n        whitelist = [\"n't\", \"not\", \"no\"]\n        words = input_text.split() \n        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n        return \" \".join(clean_words) \n    \n    def stemming(self, input_text):\n        porter = PorterStemmer()\n        words = input_text.split() \n        stemmed_words = [porter.stem(word) for word in words]\n        return \" \".join(stemmed_words)\n    \n    def fit(self, X, y=None, **fit_params):\n        return self\n    \n    def transform(self, X, **transform_params):\n        clean_X = self.remove_mentions(X)\n        clean_X = self.remove_urls(clean_X)\n        clean_X = self.remove_punctuation(clean_X)\n        clean_X = self.remove_digits(clean_X)\n        clean_X = self.to_lower(clean_X)\n        clean_X = self.remove_stopwords(clean_X)\n        clean_X = self.stemming(clean_X)\n        #clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords).apply(self.stemming)\n        return clean_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct = CleanText()\nclean_text = []\nfor file_name in valid_bulletins:\n    with open(bulletins + '/' + file_name, encoding = \"ISO-8859-1\", errors = 'ignore') as f:\n        file = f.read().replace('\\t',' ')\n        data = file.replace('\\n',' ')\n        data = ct.fit_transform(data)\n        clean_text.append(data)\n        \ndf_text = pd.DataFrame(clean_text)\ndf_text.columns = ['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now text of each bulletin is cleaned and stemmatized\nlist(df_text['text'].iloc[1:2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gender-coded words"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sourse of words http://gender-decoder.katmatfield.com/results/083aa142-2c95-4930-b2d6-afe5033e1482\n\nfeminine_coded_words = [\n    \"agree\",\n    \"affectionate\",\n    \"child\",\n    \"cheer\",\n    \"collab\",\n    \"commit\",\n    \"communal\",\n    \"compassion\",\n    \"connect\",\n    \"considerate\",\n    \"cooperat\",\n    \"co-operat\",\n    \"depend\",\n    \"emotiona\",\n    \"empath\",\n    \"feel\",\n    \"flatterable\",\n    \"gentle\",\n    \"honest\",\n    \"interpersonal\",\n    \"interdependen\",\n    \"interpersona\",\n    \"inter-personal\",\n    \"inter-dependen\",\n    \"inter-persona\",\n    \"kind\",\n    \"kinship\",\n    \"loyal\",\n    \"modesty\",\n    \"nag\",\n    \"nurtur\",\n    \"pleasant\",\n    \"polite\",\n    \"quiet\",\n    \"respon\",\n    \"sensitiv\",\n    \"submissive\",\n    \"support\",\n    \"sympath\",\n    \"tender\",\n    \"together\",\n    \"trust\",\n    \"understand\",\n    \"warm\",\n    \"whin\",\n    \"enthusias\",\n    \"inclusive\",\n    \"yield\",\n    \"share\",\n    \"sharin\"\n]\n\nmasculine_coded_words = [\n    \"active\",\n    \"adventurous\",\n    \"aggress\",\n    \"ambitio\",\n    \"analy\",\n    \"assert\",\n    \"athlet\",\n    \"autonom\",\n    \"battle\",\n    \"boast\",\n    \"challeng\",\n    \"champion\",\n    \"compet\",\n    \"confident\",\n    \"courag\",\n    \"decid\",\n    \"decision\",\n    \"decisive\",\n    \"defend\",\n    \"determin\",\n    \"domina\",\n    \"dominant\",\n    \"driven\",\n    \"fearless\",\n    \"fight\",\n    \"force\",\n    \"greedy\",\n    \"head-strong\",\n    \"headstrong\",\n    \"hierarch\",\n    \"hostil\",\n    \"impulsive\",\n    \"independen\",\n    \"individual\",\n    \"intellect\",\n    \"lead\",\n    \"logic\",\n    \"objective\",\n    \"opinion\",\n    \"outspoken\",\n    \"persist\",\n    \"principle\",\n    \"reckless\",\n    \"self-confiden\",\n    \"self-relian\",\n    \"self-sufficien\",\n    \"selfconfiden\",\n    \"selfrelian\",\n    \"selfsufficien\",\n    \"stubborn\",\n    \"superior\",\n    \"unreasonab\"\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class gender_coded_words():\n    \n    def __init__(self, text):\n        self.text = text\n        \n    def as_list(self):\n        return self.text.split()\n    \n    def count_coded_words(self, gender_word_list):\n        gender_biased_words = [word for word in self.as_list() \n                               for coded_word in gender_word_list \n                               if word.startswith(coded_word)]\n        return (\",\").join(gender_biased_words), len(gender_biased_words)\n    \n    def gender_bias_score(self):\n        masculine_words, masculine_words_count = self.count_coded_words(masculine_coded_words)\n        feminine_words, feminine_words_count = self.count_coded_words(feminine_coded_words)\n        coding_score = masculine_words_count - feminine_words_count\n        coding = ''\n        if coding_score == 0:\n            if feminine_words_count:\n                coding = \"neutral\"\n            else:\n                coding = ''\n        elif coding_score < -3:\n            coding = \"strongly feminine-coded\"\n        elif coding_score < 0:\n            coding = \"feminine-coded\"\n        elif coding_score > 3:\n            coding = \"strongly masculine-coded\"\n        else:\n            coding = \"masculine-coded\"\n        return coding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_text['gender_bias'] = list(map(lambda x: gender_coded_words(x).gender_bias_score(),df_text['text']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_text['gender_bias'].iplot(kind='hist', xTitle='Gender Tone',\n                  yTitle='Count', title='Gender coded words distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most of the bulletins contain strongly masculine-coded language.** Probably, greater masculine wording is dictated by the majority of male-dominated occupations than female-dominated occupations. However, according to [gendered wording studies](http://www.fortefoundation.org/site/DocServer/gendered_wording_JPSP.pdf?docID=16121) regardless of whether the occupations were traditionally more male or female dominated, participants found jobs most attractive when there was a match between their gender and the gendered wording used in the advertisement. \n\n**Suggestion #1: replacing the masculine wording with parallel feminine wording would increase women’s interest in those jobs.**"},{"metadata":{},"cell_type":"markdown","source":"# Job requirements Tone"},{"metadata":{"trusted":true},"cell_type":"code","source":"strict_requirements = ['must', 'requir', 'essenti', 'necess', 'need', 'expert', 'strong', 'profess']\nsoft_requirements = ['desir', 'familiar', 'capab', 'abl','inform', 'convers', 'practic', 'addit']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class requirement_tone():\n    \n    def __init__(self, text):\n        self.text = text\n        \n    def as_list(self):\n        return self.text.split()\n    \n    def count_words(self, req_word_list):\n        words = [word for word in self.as_list() \n                               for req_word in req_word_list \n                               if word.startswith(req_word)]\n        return (\",\").join(words), len(words)\n    \n    def req_tone_score(self):\n        strict_words, strict_words_count = self.count_words(strict_requirements)\n        soft_words, soft_words_count = self.count_words(soft_requirements)\n        strict_words_score = strict_words_count - soft_words_count\n        coding = ''\n        if strict_words_score == 0:\n            if strict_words_count:\n                coding = \"neutral\"\n            else:\n                coding = ''\n        elif strict_words_score < -3:\n            coding = \"very low demands\"\n        elif strict_words_score < 0:\n            coding = \"low demands\"\n        elif strict_words_score > 3:\n            coding = \"very high demands\"\n        else:\n            coding = \"high demands\"\n        return coding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_text['req_tone'] = list(map(lambda x: requirement_tone(x).req_tone_score(),df_text['text']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_text['req_tone'].iplot(kind='hist', xTitle='Requirement Tone',\n                  yTitle='Count', title='Requirements distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most of the bulletins contain very strict requirements.** This tone repels women, as well as people at the beginning of their career path, regardless of their gender. \n\n**Suggestion #2: Replacing certain desired skills by more soft language like:**\n- familiarity with...\n- bonus points for\n- working knowledge of...\n- comfortable with...\n- if you have any combination of these skills ...\n\n**Suggestion #3: Don't use the word “expert” or similar. Some candidates will consider themselves experts, but many qualified, talented candidates won’t identify with that descriptor, or might even be intimidated by it.**"},{"metadata":{},"cell_type":"markdown","source":"# Benefits"},{"metadata":{"trusted":true},"cell_type":"code","source":"def benefits(text):\n    benefit_list= ['work-lif', 'flexibl', 'childcar', \n                   'parent', 'healthcar', 'matern', 'benefit', 'opportun']\n    \n    words = [word for word in text.split() if word in benefit_list]\n    \n    return len(words)\n\ndf_text['benefits'] = df_text['text'].apply(benefits)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There is no information abouth benefits: health coverage, life insurance, parental leave**\n\nOnly formal phrase: *If you receive and accept an offer of employment to a regular position with the City of Los Angeles, your employee benefit coverage (including health and dental coverage as well as life insurance) will commence approximately six weeks after your original regular appointment. Not all positions in the City receive benefit coverage; you should inquire regarding the availability of employee benefits prior to accepting a position.*\n\n**There is no information abouth education and training opportunities**\n\n**There is no mention of work-life balance and flexible time**\n\n**Suggestion #4: Add information about benefits and opportunities for the candidates. If you don’t show candidates that you take care of your employees, they will find a company that does**"},{"metadata":{},"cell_type":"markdown","source":"# Job Description Length\n\nPeople spent an average of [49.7 seconds](https://blogs.wsj.com/atwork/2013/05/02/how-we-really-read-job-ads/) before dismissing a position as a poor fit, and 76.7 seconds with job ads that appeared to match their interests and skills. Applicants spent the most time reading the job description (25.9 seconds) and the company description (23 seconds). In addition, participants’ eyes tended to skim the job description rather than read it closely, and often skipped the bottom section of the description entirely."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DUTIES_len'] = df['JOB_DUTIES'].str.split().apply(len)\ndf['REQ_len'] = list(map(lambda x: len(''.join(x).split()),df['REQ_TEXT']))\ndf['FULL_TEXT_len'] = df_text['text'].str.split().apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['DUTIES_len','REQ_len','FULL_TEXT_len']].iplot(kind='box',\n                  yTitle='Number of words', title='Job Description Length')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Median lenghts of job duties (64 words) and requirements (55 words) generally fall under recomended job description length (if reading speed = 2...3 words/sec). But overall job description length is too long. Let's be honest no one will read them completely.\n\nLess is more. Job postings of less than 300 words received higher apply rates than longer job postings, according to this [analysis of 4.5 million job postings on LinkedIn](https://business.linkedin.com/talent-solutions/blog/job-descriptions/2018/new-job-post-stats).\n\n**Suggestion #5: Keep [the more useful parts of job description](https://business.linkedin.com/talent-solutions/blog/job-descriptions/2018/job-description-heatmap) : salary, qualifications, and day-to-day details of the job.**\n\n**Suggestion #6: Cut the text of job description:**\n- **Keep sentences short!** According to [The Public Relations Society of America](http://prsay.prsa.org/2009/01/14/how-to-make-your-copy-more-readable-make-sentences-shorter/) when the average sentence length is 8 word sentences, readers understood 100% of the story. At 14 words, the understanding rate drops to 90%. At 43 words per sentence it was below 10% understanding rate.\n- **Make short paragraphs**\n- **Get more simple alternatives for long phrases**"},{"metadata":{},"cell_type":"markdown","source":"# Unsupervized Sentiment Analysis"},{"metadata":{},"cell_type":"markdown","source":"### a) Sentiment Analysis with AFINN"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install afinn\nfrom afinn import Afinn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"afn = Afinn(emoticons=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AFINN is a list of words rated for valence with an integer between minus five (negative) and plus five (positive).\n# Simple examples:\nprint('Predicted Sentiment polarity:', afn.score('The movie was so bad'))\nprint('Predicted Sentiment polarity:', afn.score('The movie was so good'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DUTIES_afinn_score'] = list(map(lambda x: afn.score(x), df['JOB_DUTIES']))\ndf['REQ_afinn_score'] = list(map(lambda x: afn.score(''.join(x)),df['REQ_TEXT']))\ndf['FULL_TEXT_afinn_score'] = list(map(lambda x: afn.score(x), df_text['text']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['DUTIES_afinn_score', 'REQ_afinn_score','FULL_TEXT_afinn_score']].iplot(kind='box', \n                  yTitle='Sentiment polarity', title='Sentiment Scores')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{} % of job bulletines are classified as negative'.format(int(len(df[df['FULL_TEXT_afinn_score']<-1])*100/len(df))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### b) Sentiment Analysis with SentiWordNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('sentiwordnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simple example\ntext = list(swn.senti_synsets('awesome', 'a'))[0]\nprint('Positive Polarity Score:', text.pos_score())\nprint('Negative Polarity Score:', text.neg_score())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\n\ndef penn_to_wn(tag):\n    \"\"\"\n    Convert between the PennTreebank tags to simple Wordnet tags\n    \"\"\"\n    if tag.startswith('J'):\n        return wn.ADJ\n    elif tag.startswith('N'):\n        return wn.NOUN\n    elif tag.startswith('R'):\n        return wn.ADV\n    elif tag.startswith('V'):\n        return wn.VERB\n    return None\n \ndef swn_polarity(text):\n    \"\"\"\n    Return a sentiment polarity: negative, positive or neutral\n    \"\"\"\n \n    sentiment = 0.0\n    tokens_count = 0\n \n    raw_sentences = sent_tokenize(text)\n    for raw_sentence in raw_sentences:\n        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n \n        for word, tag in tagged_sentence:\n            wn_tag = penn_to_wn(tag)\n            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n                continue\n \n            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n            if not lemma:\n                continue\n \n            synsets = wn.synsets(lemma, pos=wn_tag)\n            if not synsets:\n                continue\n \n            # Take the first sense, the most common\n            synset = synsets[0]\n            swn_synset = swn.senti_synset(synset.name())\n \n            sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n            tokens_count += 1\n \n    # netral by default\n    if not tokens_count:\n        return 'neutral'\n \n    # sum greater than 0 => positive sentiment\n    if sentiment >= 0:\n        return 'positive'\n \n    # negative sentiment\n    else:\n        return 'negative'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DUTIES_swn'] = list(map(lambda x: swn_polarity(x), df['JOB_DUTIES']))\ndf['REQ_swn'] = list(map(lambda x: swn_polarity(''.join(x)),df['REQ_TEXT']))\ndf['FULL_TEXT_swn'] = list(map(lambda x: swn_polarity(x), df_text['text']))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.iplot(kind='hist', barmode = 'group', histnorm = 'percent', dimensions=(1000, 300), \n         columns = ['DUTIES_swn', 'REQ_swn','FULL_TEXT_swn'], \n         yTitle='%', title='Sentiment Scores')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{} % of job bulletines are classified as negative'.format(int(len(df[df['FULL_TEXT_swn']=='negative'])*100/len(df))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dictionary-based approaches show a high percentage of negative language bulletins. But these dictionaries were created based on customer feedback and may not be suitable for our task.**"},{"metadata":{},"cell_type":"markdown","source":"### c) Sentiment Analysis with VADER\n\nVADER or Valence Aware Dictionary and Sentiment Reasoner is a rule/lexicon-based, open-source sentiment analyzer pre-built library, protected under the MIT license. VADER’s sentiment analyzer class will return the polarity score in dictionary format which will help in evaluating the probability of a positive, negative or neutral sentiment. "},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('vader_lexicon')\nsid = SentimentIntensityAnalyzer()\ndef get_vader_score(sent):\n    # Polarity score returns dictionary\n    ss = sid.polarity_scores(sent)\n    ss.pop('compound', None)\n    # return 'pos' - positive, 'neg' - negative and 'neu' - neutral\n    return max(ss.items(), key=operator.itemgetter(1))[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DUTIES_sid'] = list(map(lambda x: get_vader_score(x), df['JOB_DUTIES']))\ndf['REQ_sid'] = list(map(lambda x: get_vader_score(''.join(x)),df['REQ_TEXT']))\ndf['FULL_TEXT_sid'] = list(map(lambda x: get_vader_score(x), df_text['text']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iplot(kind='hist', barmode = 'group', histnorm = 'percent', dimensions=(1000, 300), \n         columns = ['DUTIES_sid', 'REQ_sid','FULL_TEXT_sid'], \n         yTitle='%', title='Sentiment Scores')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VADER-based sentiment analyzer predict that almost all bulletins are neutral**"},{"metadata":{},"cell_type":"markdown","source":"# Recomendations"},{"metadata":{},"cell_type":"markdown","source":"### Remove Gender Bias\n- Avoid (or balance) your use of gender-charged words\n- Avoid the word “expert” or similar in requirements\n- Limit the number of requirements\n- Reconsider your major requirements\n- State your family-friendly benefits\n\n### Cut Word Count\n**- Reduce information repeated in each bulletins. For example:**\n\n*Applicants will be disqualified and not eligible for hire if their record within the last 36 months reflects three or more moving violations and/or at-fault accidents, or a conviction of a major moving violation (such as DUI)*\n\n*In addition to answering the regular City application supplemental questions, each applicant is required to complete the ... Qualifications Questionnaire at the time of filing. The ... Qualifications Questionnaire is located within the Supplemental Questions section of the City application. Applicants who fail to complete the Qualifications Questionnaire will not be considered further in this examination, and their application will not be processed.*\n\n*Candidates completing the examination process will be contacted by the Personnel Department to provide required proof of qualifying degree or coursework.*\n\n**Some of the NOTES are too obvious:**\n\n*Applicants are urged to apply early to ensure you have time to resolve any technical issues you may encounter.*\n\n*All application materials must be completed at the time of filing for you to be considered a candidate in this examination*\n\n**Too formal language, too long sentence, repeated in each bulletins, nobody read this:**\n\n*In accordance with Civil Service Rule 4.2, all applicants who apply may not be tested in this examination. To meet anticipated hiring needs, only a limited number of qualified applicants will be invited to participate in the exam in the following order: 1) Los Angeles City Promotional applicants who meet the minimum requirements. You must have received a regular appointment to a City position or be on a reserve list to apply for this examination as a promotional candidate; 2) Applicants currently employed by the City of Los Angeles on a part-time or exempt basis who meet the minimum requirements; 3) Remaining applicants who meet the minimum requirements in sufficient numbers to meet hiring needs in the order that applications were received. Applications submitted during the filing period will be kept on file for two years from February 3, 2017 in the event that additional applicants need to be tested to meet hiring needs.*\n\n**and again:**\n\n*1 . As a covered entity under the Fair Employment and Housing Act and Title II of the Americans with Disabilities Act, the City of Los Angeles does not discriminate on the basis of disability and upon request, will provide reasonable accommodations to ensure equal access to its programs, services, and activities. To request a disability accommodation, please complete the Disability Accommodation Form within 14 calendar days of the submittal of the City application. The Disability Accommodation Form can be obtained at\n2 . Applications are accepted subject to review to ensure that minimum qualifications are met. Candidates may be disqualified at any time if it is determined that they do not possess the minimum qualifications stated on this bulletin.\n3 . A final average score of 70% is required to be placed on the eligible list.\n4 . In conjunction with Civil Service Rules, applicants who are current eligible City employees or are on a reserve list will be considered Promotional candidates while all other applicants will be considered Open candidates.\n5 . The promotional list will ordinarily be used ahead of the open competitive list. However, if open competitive candidates receive a higher score, without military credits, than the highest available promotional candidate, after adding seniority credit at the rate of 0.25 of a point for each year of continuous classified City service, the Civil Service Commission, upon request of the appointing authority, may approve certification of such open competitive candidates ahead of the promotional candidates.\n6 . In accordance with Civil Service Rule, Sec. 4.24, review periods may be combined. Candidates in the examination process may file protests as provided in Sec. 4.20, 4.22, 4.23 as applicable and within the required timeframe; however, the Personnel Department may respond to and resolve protests prior to the establishment of the eligible list.*\n\n**- Improve the readability of Selection Process:**\n- Use shorter sentences. One idea for each sentence.\n- Summarize important points in subheadings to break up bulky paragraph of Selection Process\n\n**State the family-friendly benefits** instead of writing\n\n*If you receive and accept an offer of employment to a regular position with the City of Los Angeles, your employee benefit coverage (including health and dental coverage as well as life insurance) will commence approximately six weeks after your original regular appointment. Not all positions in the City receive benefit coverage; you should inquire regarding the availability of employee benefits prior to accepting a position.*\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}