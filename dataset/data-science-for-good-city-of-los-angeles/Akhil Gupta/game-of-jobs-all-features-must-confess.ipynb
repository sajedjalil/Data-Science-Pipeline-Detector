{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Employment is coming @ Los Angeles.\n![](https://www.oxy.edu/sites/default/files/styles/banner_image/public/page/banner-images/los-angeles_main_1440x800.jpg?itok=GiOVS9-4)\n\n## Problem Statement\n* Extract relevant information from the 683 raw full-text job postings into a structured CSV. (Initial columns for the same have been provided)\n* Use the structured data to identify the language, content and quality of each job posting.\n\n### Approach:\n- <b>The focus of the current kernel version is to extract as much information as possible. 5 new features have been created!</b>\n- I have preprocessed this using <i>simple Python manipulation</i>, i.e. <u>no RegEx</u>. :)"},{"metadata":{},"cell_type":"markdown","source":"#### Columns Added (As on 05/16/2019): \n<u>EDA and first-level analysis done for all, but last 4 features.</u>\n- 'FILE_NAME'\n- 'JOB_CLASS_TITLE'\n- 'JOB_CLASS_NO'\n- 'OPEN_DATE'\n- **REVISED_DATE** -> **TIME_TO_REVISION**\n- 'JOB_DUTIES'\n- 'DRIVERS_LICENSE_REQ'\n- 'EXAM_TYPE'\n- 'ENTRY_SALARY_GEN' -> **SALARY_GEN_AVG**\n- 'ENTRY_SALARY_DWP' -> **SALARY_DWP_AVG**\n- **SELECTION_CRITERIA**\n- **APPLICATION_DEADLINE**\n- **CLOSE_W/O_PRIOR_NOTICE**\n- **APPL_CIVIL_SERV_RULES**"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport glob\nimport warnings\nfrom collections import Counter\nimport seaborn as sns\nimport math\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nos.chdir('/kaggle/input/data-science-for-good-city-of-los-angeles/cityofla/CityofLA/')\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Getting the list of Job Postings\njob_bulletins = sorted(glob.glob('Job Bulletins/*.txt'))\n\n# Master dataframe with filename added\nmaster = pd.DataFrame(data=[job.split('/')[1] for job in job_bulletins], columns=['FILE_NAME'])\n\n# Traversing over job postings to create a list of list of individual elements within the job posting for easy extraction\njobs_list = []\nfor job in job_bulletins:\n    string_val = ''\n    flag = 1\n    for i in open(job, \"r\", encoding='latin1').readlines():\n        if len(i.strip()) <= 1:\n            continue\n        else:\n            j = i.strip()\n            if j.isupper() == True:\n                if flag == 1:\n                    string_val += \"***%s\"%(j)\n                    flag = 0\n                else:\n                    string_val += '\\n%s'%(j)\n            else:\n                flag = 1\n                string_val += '\\n%s'%(j)\n    jobs_list.append([i.strip() for i in string_val.split('***') if len(i)!=0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Common headings to get a sense of what the raw data content looks like!\nck = []\nfor j in jobs_list:\n    for i in j:\n        urr = []\n        for k in i.replace('\\n', ' ').split(' '):\n            if k.isupper()==True and len(k)>1:\n                urr.append(k)\n            else:\n                break\n        ck.append(' '.join(urr))\nsorted(dict(Counter(ck)).items(), key=lambda x:x[1], reverse=True)[:25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Job Title, Job Code, Open Date and Revised Date (if Applicable)\nNow, we start with the basic information for the structured CSV.\n- *Job title* - collation done with the provided file names. (Some preprocessing has been done in the following cell)\n- *Class code* - 4 digit and containing only digits.\n- *Open date* - datetime object.\n- **Revised date** - it was observed that some of the job postings get revised. Usually, this happens in order to extend the application deadline. This may provide a sense of the less responses obtained when the job was posted for the first time.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"job_info = []\n\nfor idx, job in enumerate(jobs_list):\n    val = job[0]\n    for old, new in {'  ': ' ', '\\n': ' ', '\\t': ' ', 'date': 'Date'}.items():\n        val = val.replace(old, new)\n    title = val.split('Class Code:')[0].strip()\n    try:\n        code = val[val.find('Class Code:') : val.find('Open Date')].split(':')[1].strip()\n        if len(code) != 4 or code.isdigit() == False:\n            print(code)\n        date = val.split('Open Date:')[1].strip()\n        date = date.split(' ')[0]\n    except:\n        code = ''\n        date = np.nan\n        print(\"No job info (class code and open date) found for ***%s***\"%(master.iloc[idx]['FILE_NAME']))\n    job_info.append((title, code, date))\n\nmaster['JOB_CLASS_TITLE'] = [i[0] for i in job_info]\nmaster['JOB_CLASS_NO'] = [i[1] for i in job_info]\nmaster['OPEN_DATE'] = pd.to_datetime([i[2] for i in job_info]) # Validation of the Date\n\ndel job_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rectifying title name values with the File-Name\n\ndef break_file_name(x):\n    title = []\n    code = []\n    for i in x.split(' '):\n        if len(i) == 4 and i.isdigit()==True:\n            code.append(i)\n            break\n        title.append(i)\n    return (' '.join(title).strip(), ' '.join(code).strip())\n\nmaster['TITLE_CHECKER'] = master.apply(lambda x: break_file_name(x['FILE_NAME'])[0], axis=1)\nmaster['CODE_CHECKER'] = master.apply(lambda x: break_file_name(x['FILE_NAME'])[1], axis=1)\n\nmaster['TITLE_MATCH'] = np.where(master['JOB_CLASS_TITLE'] == master['TITLE_CHECKER'], 1, 0)\nmaster['CODE_MATCH'] = np.where(master['JOB_CLASS_NO'] == master['CODE_CHECKER'], 1, 0)\n\n# Rectifying title\nfor index, row in master.iterrows():\n    y = row['JOB_CLASS_TITLE']\n    if row['TITLE_MATCH'] == 0:\n        if 'CAMPUS INTERVIEWS ONLY' in y:\n            master.set_value(index, 'JOB_CLASS_TITLE', y.split('CAMPUS INTERVIEWS ONLY')[1].strip())\n        elif '(' in y or ')' in y:\n            st = y[y.find('('): y.find(')') + 1]\n            if len(st)==0:\n                st = y[y.find('('):]\n            y = y.replace(st, '')\n            y = y.replace('  ', ' ')\n            master.set_value(index, 'JOB_CLASS_TITLE', y.strip())\n        elif '\\t' in y:\n            y = y.split('\\t')[0]\n            master.set_value(index, 'JOB_CLASS_TITLE', y.strip())\n        else:\n            continue\n            \nmaster.drop(columns=['CODE_CHECKER', 'CODE_MATCH'], inplace=True)\nmaster.drop(columns=['TITLE_CHECKER', 'TITLE_MATCH'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"revised_dates = []\n\nfor job in jobs_list:\n    flag = 0\n    for i in job:\n        j = i.upper()\n        if 'REVISED' in j:\n            g = []\n            g = [k.strip(':') for k in j[j.find('REVISED') : j.find('REVISED') + 100].split(' ')[1:] if len(k)>1][0].split('\\n')[0][:8] # Keep maximum eight characters MM-DD-YY\n            dates = g.split('-')\n            if len(dates) == 3:\n                revised_dates.append('%d-%d-%d'%(int(dates[0]), int(dates[1]), 2000 + int(dates[2])))\n                flag = 1\n                break\n    if flag == 0:\n        revised_dates.append(np.nan)\n\nmaster['REVISED_DATE'] = pd.to_datetime(revised_dates)\n\ndel revised_dates","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Analyzing the job titles which occur more than once."},{"metadata":{"trusted":true},"cell_type":"code","source":"jobs_more_than_once = master.groupby(['JOB_CLASS_NO'])['FILE_NAME'].nunique().reset_index()\njobs_more_than_once = jobs_more_than_once[jobs_more_than_once['FILE_NAME']>1]\n\n# Remove the job titles which have multiple occurences on the same open date\nmaster[master['JOB_CLASS_NO'].isin(jobs_more_than_once['JOB_CLASS_NO'])].sort_values(['JOB_CLASS_NO'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the record for Animal Care Techniciam Supervisor i.e. INDEX 27! ()\nmaster.drop(master.index[27], inplace=True)\nmaster.reset_index(drop=True, inplace=True)\ndel jobs_list[27]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Average time taken for revision of the job posting."},{"metadata":{"trusted":true},"cell_type":"code","source":"master['TIME_TO_REVISION'] = (master['REVISED_DATE'] - master['OPEN_DATE']).astype('timedelta64[D]')\nplt.figure(figsize=(10, 8))\nsns.distplot(master[(master['TIME_TO_REVISION'].isnull()==False)&(master['TIME_TO_REVISION']<=800)]['TIME_TO_REVISION'])\nplt.xticks(range(0, 800, 50))\nplt.xlabel(\"Days taken for the Job Posting Revision\")\nplt.ylabel(\"Proportion of Jobs\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be clearly seen that most of the job postings get revised within 30-50 days of the posting. There are very few records with more than 800 time to revision (excluded from this visual)."},{"metadata":{},"cell_type":"markdown","source":"#### Count of Job Postings by Quarter.\nJobs having their open date or revised date in [2014, 2018] have been included henceforth."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Open Date Trends\ndef quarter(x):\n    if math.isnan(x):\n        return None\n    else:\n        return '%d_Q%d'%(x/100, ((x%100 - 1)/3) + 1)\n\nmaster['OPEN_MONTH_YEAR'] = master.apply(lambda x: (x['OPEN_DATE'].month) + (x['OPEN_DATE'].year)*100, axis=1)\nmaster['REVISED_MONTH_YEAR'] = master.apply(lambda x: (x['REVISED_DATE'].month) + (x['REVISED_DATE'].year)*100, axis=1)\ndate_analysis = master[((master['OPEN_MONTH_YEAR']>=201400)&(master['OPEN_MONTH_YEAR']<201900)) | ((master['REVISED_MONTH_YEAR']>=201400)&(master['REVISED_MONTH_YEAR']<201900))]\ndate_analysis['OPEN_MONTH_YEAR'] = np.where((date_analysis['OPEN_MONTH_YEAR']<201400) | (date_analysis['OPEN_MONTH_YEAR']>201900), date_analysis['REVISED_MONTH_YEAR'], \n                                            date_analysis['OPEN_MONTH_YEAR'])\ndate_analysis['OPEN_QUARTER'] = date_analysis.apply(lambda x: quarter(x['OPEN_MONTH_YEAR']), axis=1)\ndate_removed = master.iloc[list(set(master.index) - set(date_analysis.index)),:]\nquarterly = date_analysis.groupby(['OPEN_QUARTER'])['FILE_NAME'].nunique().reset_index()\nquarterly.sort_values(['OPEN_QUARTER'], ascending=True, inplace=True)\nplt.figure(figsize=(15, 8))\nplt.plot(quarterly['FILE_NAME'], marker='s')\nplt.xlabel(\"Quarters\")\nplt.ylabel(\"# Jobs\")\ndisplay_quarters = [i[2:] for i in list(quarterly['OPEN_QUARTER'])]\nfor idx, i in enumerate(display_quarters):\n    if idx%4 == 0:\n        plt.axvline(x=idx, color='orange', linestyle='--')\nplt.xticks(range(0, len(quarterly)), display_quarters)\nplt.show()\n\nmaster.drop(columns=['OPEN_MONTH_YEAR', 'REVISED_MONTH_YEAR'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> - The trend for the number of jobs has been on an increasing trend.\n> - Only the jobs between 2014 and 2018 have been considered because the PDF files have been shared for these years. It makes sense to fixate on a reliable time frame before jumping to any insight generation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# These 7 records are being dropped because their open date is either before 2014, or in 2019.\ndate_removed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing these dates from the master analysis file as well (Too old or too new)\ndate_removed = list(date_removed.index.values)\nmaster.drop(index=date_removed, inplace=True)\nmaster.reset_index(drop=True, inplace=True)\n\njobs_list2 = []\nfor idx, i in enumerate(jobs_list):\n    if idx not in date_removed:\n        jobs_list2.append(i)\njobs_list = jobs_list2\ndel jobs_list2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Job Duties"},{"metadata":{"trusted":true},"cell_type":"code","source":"duties = []\n\nfor job in jobs_list:\n    duty = ''\n    for i in job:\n        for old, new in {'\\n': ' ', '\\t': ' '}.items():\n            i = i.replace(old, new)\n        for term in ['DUTIES AND RESPONSIBILITIES', 'DUTIES']: # NOT AVAILABLE FOR FIRE-RELATED JOBS\n            if term in i:\n                duty = i.split(term)[1].strip()\n                break\n    duties.append(duty)\n    \nmaster['JOB_DUTIES'] = duties\nmaster['JOB_DUTIES'] = np.where(master['JOB_DUTIES'] == '', np.nan, master['JOB_DUTIES'])\n\ndel duties","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Wordcloud for most frequent words (TF-IDF scores could also be used for a better deep-dive into this feature)\n\nfrom wordcloud import WordCloud\nimport string\n\nbow = []\nfor i in list(master['JOB_DUTIES'].unique()):\n    if type(i) == str:\n        words = i.lower().split(' ')\n        for w in words:\n            for s in list(string.punctuation) + [\"'s\"]:\n                if s in w:\n                    w = w.strip(s)\n            bow.append(w)\n    else:\n        pass\nbow = list(sorted(dict(Counter(bow)).items(), key=lambda x:x[1], reverse=True))\n\nst = pd.read_csv('/kaggle/input/stopwords/stopwords.csv')\nbow = dict([i for i in bow if i[0] in list(set([i[0] for i in bow]) - set(st['stopwords'].unique()))])\n\nwordcloud = WordCloud(min_font_size=10,max_font_size=60,background_color=\"white\",width=600,height=300).generate_from_frequencies(bow)\nplt.figure(figsize=(15, 9))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Driver's License"},{"metadata":{"trusted":true},"cell_type":"code","source":"driver_license_req = []\n\nfor job in jobs_list:\n    text = \"driver's license\"\n    y = ' '.join(job).lower().strip()\n    y = y.replace(\"drivers'\", \"driver's\")\n    vicinity = y[y.find(text) -100: y.find(text) + 100]\n    if text in vicinity:\n        if 'may require a valid' in y or 'some positions require a valid' in y or 'license may be required' in y:\n            driver_license_req.append('P')\n        elif 'license is required' in y or 'possession of a valid' in y or 'is required' in y or 'who apply with a valid':\n            driver_license_req.append('R')\n        else:\n            raise ValueError(\"Please check for the specified license keywords.\")\n    else:\n        driver_license_req.append('')\n        \nmaster['DRIVERS_LICENSE_REQ'] = driver_license_req\nmaster['DRIVERS_LICENSE_REQ'] = np.where(master['DRIVERS_LICENSE_REQ'] == '', np.nan, master['DRIVERS_LICENSE_REQ'])\n\ndel driver_license_req","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master['DRIVERS_LICENSE_REQ'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exam Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_exam_type(value): # Identifying the exam type from the text present in the job body\n    if 'INTERDEPARTMENTAL' and 'OPEN' in value:\n        return 'OPEN_INT_PROM'\n    elif 'INTER' in value:\n        return 'INT_DEPT_PROM'\n    elif 'DEPARTMENT' in value:\n        return 'DEPT_PROM'\n    elif 'OPEN' in value:\n        return 'OPEN'\n    else:\n        return ''\n    \nexam_type = []\n\nfor idx, job in enumerate(jobs_list):\n    flag = 0\n    for i in job:\n        for old, new in {'\\n': ' ', '\\t': ' ', 'EXAM ': 'EXAMINATION '}.items():\n            i = i.replace(old, new)\n        if 'THIS EXAMINATION' in i:\n            g = []\n            for j in i[i.find('THIS EXAMINATION'): i.find('THIS EXAMINATION') + 150].split(' '):\n                if j.isupper() == True:\n                    g.append(j)\n                else:\n                    break\n            exam_type.append(' '.join(g))\n            flag = 1\n            break\n    if flag == 0:\n        print('Exam Type not found for ***%s***'%(master.iloc[idx]['FILE_NAME']))\n        exam_type.append('')\n        \nmaster['EXAM_TYPE'] = exam_type\nmaster['EXAM_TYPE'] = master.apply(lambda x: parse_exam_type(x['EXAM_TYPE']), axis=1) ### 646 is screwed up! \n\ndel exam_type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart for the Exam Type\nplt.figure()\nplt.bar(master[\"EXAM_TYPE\"].value_counts().index, master['EXAM_TYPE'].value_counts().values, width=0.5)\nplt.xlabel(\"Exam Type\")\nplt.ylabel(\"# of Jobs\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"def salary_decompose(sal): # Identifying the first-mentioned salary components\n    if '$' not in sal:\n        return ''\n    else:\n        gen_sal = sal.split(' ')\n        x = []\n        initial_sal = 0\n        initial_idx = -1\n        for idx, s in enumerate(gen_sal):\n            if '$' in s and initial_sal == 0:\n                x.append(s)\n                initial_idx = idx\n                initial_sal = 1\n            if len(x) > 0 and '$' in s and 'to' in gen_sal[idx-1] and idx - 2 == initial_idx:\n                x.append('to')\n                x.append(s)\n                break\n        if 'to' not in ' '.join(x):\n            y = x[0].split('(')[0].strip(';').strip(',').strip('.')\n        else:\n            y = ' '.join(x).strip(';').strip(',').strip('.')\n        return y\n\nsalary = []\nsalary_wp = []\n\nfor job in jobs_list:\n    flag_salary = 0\n    flag_salary_wp = 0\n    for i in job:\n        for old, new in {'ANNUALSALARY': 'ANNUAL SALARY', '\\n': ' ', '$ ': '$'}.items():\n            i = i.replace(old, new)\n        if 'ANNUAL SALARY' in i and '$' in i:\n            x = i.split('Water')\n            salary.append(salary_decompose(x[0]))\n            flag_salary = 1\n            if len(x) > 1:\n                salary_wp.append(salary_decompose(x[1]))\n                flag_salary_wp = 1\n    if flag_salary == 0:\n        salary.append('')\n    if flag_salary_wp == 0:\n        salary_wp.append('')\n\nmaster['ENTRY_SALARY_GEN'] = salary\nmaster['ENTRY_SALARY_GEN'] = np.where(master['ENTRY_SALARY_GEN'] == '', np.nan, master['ENTRY_SALARY_GEN'])\nmaster['ENTRY_SALARY_DWP'] = salary_wp\nmaster['ENTRY_SALARY_DWP'] = np.where(master['ENTRY_SALARY_DWP'] == '', np.nan, master['ENTRY_SALARY_DWP'])\n\ndel salary, salary_wp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting the Average Salary for each job post\n\ndef salarized(x):\n    if type(x) == float:\n        return np.nan\n    else:\n        if 'to' in x.lower():\n            a1 = int(x.split(' ')[0].strip('$').strip('*').replace(',', '').split('.')[0])\n            a2 = int(x.split(' ')[-1].strip('$').strip('*').replace(',', '').split('.')[0])\n            return (a1+a2)/2\n        else:\n            return int(x.strip('$').strip('*').replace(',', '').split('.')[0])\n\nmaster['SALARY_GEN_AVG'] = master.apply(lambda x: salarized(x['ENTRY_SALARY_GEN']), axis=1)\nmaster['SALARY_DWP_AVG'] = master.apply(lambda x: salarized(x['ENTRY_SALARY_DWP']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nsns.distplot(master[master['SALARY_GEN_AVG'].isnull()==False]['SALARY_GEN_AVG'], bins=50)\nplt.xticks(range(0, 300001, 50000), list(range(0, 300001, 50000)))\nplt.xlabel('Average Entry Salary (General)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nsns.distplot(master[master['SALARY_DWP_AVG'].isnull()==False]['SALARY_DWP_AVG'], bins=50, label='DWP (All)')\nsns.distplot(master[(master['SALARY_DWP_AVG'].isnull()==False)&(master['SALARY_GEN_AVG'].isnull()==False)]['SALARY_GEN_AVG'], bins=50, label='DWP (with GEN)')\nplt.xticks(range(0, 300001, 50000), list(range(0, 300001, 50000)))\nplt.xlabel('Average Entry Salary (DWP)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = master[(master['SALARY_DWP_AVG'].isnull()==False)&(master['SALARY_GEN_AVG'].isnull()==False)]\nplt.figure(figsize=(10, 8))\nplt.scatter(temp['SALARY_GEN_AVG'], temp['SALARY_DWP_AVG'], color='orange')\nx = np.linspace(0, 200001)\nplt.plot(x, x, 'black', linestyle='--')\nplt.xticks(range(0, 200001, 50000), list(range(0, 200001, 50000)))\nplt.yticks(range(0, 200001, 50000), list(range(0, 200001, 50000)))\nplt.xlabel(\"Average Entry Salary (GEN)\")\nplt.ylabel(\"Average Entry Salary (DWP)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### This plot indicates that for the same job posting, <u>salary in Department of Warer & Power (DWP) is higher than the General Salary</u>."},{"metadata":{},"cell_type":"markdown","source":"## Creation of Additional Features (after data exploration)"},{"metadata":{},"cell_type":"markdown","source":"### Selection Criteria"},{"metadata":{"trusted":true},"cell_type":"code","source":"exam_weights = []\nfor job in jobs_list:\n    flag = 0\n    for i in job:\n        x = i.lower().replace('\\t', ' ')\n        if 'examination weight' in x:\n            j = x[x.find('examination weight'):].split(':')[1].split('\\n')\n            curr = []\n            for k in j:\n                if '. . .' in k:\n                    k = k.replace('.', '_')\n                    k = k.replace(' ', '_')\n                    k = k.split('__')\n                    m = []\n                    for l in k:\n                        l = l.replace('_', ' ').strip()\n                        if len(l)>0:\n                            m.append(l)\n                    curr.append(m)\n            exam_weights.append(curr)\n            flag = 1\n            break\n    if flag == 0:\n        exam_weights.append([])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validate Exam Weights and Rectify that\nexam_weights2 = []\n\ndef check_exam_weight(x):\n    if (x[0] == 'advisory' and x[1] == 'essay') or (x[0] == 'advisory essay'):\n        x = ['essay', 'advisory']\n    if x[1] in ['qualifying(pass/fail)', 'qualifying (pass/fail)', 'pass/fail']:\n        x = [x[0], 'qualifying']\n    if x[0] in ['demonstration of job knowledge and evaluation of general qualifications by technical interview']:\n        x = ['qualification by technical interview', x[1]]\n    if x[0] in ['assessment of training & experience', 'assessment of training and experience questionnaire']:\n        x = ['assessment of training and experience', x[1]]\n    if x[0] in ['essay test', 'writing exercise']:\n        x = ['essay', x[1]]\n    if x[0] in ['interview (including city application, essay, and personnel folder)', 'interview (including city application, advisory essay, and personnel folder)',\n               'technical interview', 'qualification by technical interview', 'interview (including city application, problem solving exercise, and personnel folder)',\n               'training and experience questionnaire/interview']:\n        x = ['interview', x[1]]\n    if x[0] in ['job simulation exercises']:\n        x = ['job simulation exercise', x[1]]\n    if x[0] in ['multiple choice test', 'multiple-choice written test', 'multiple-choice', 'written test - multiple-choice', 'qualifying multiple-choice test']:\n        x = ['multiple-choice test', x[1]]\n    if x[0] in ['oral presentation and defense', 'oral presentation exercise']:\n        x = ['oral presentation', x[1]]\n    if x[0] in ['physical abilities test (pat)', 'physical abilities']:\n        x = ['physical abilities test', x[1]]\n    if x[0] in ['pre-trip safety inspection test']:\n        x = ['pre-trip inspection test', x[1]]\n    if x[0] in ['training & experience questionnaire', 'training and experience questionnaire evaluation', \n                'training and experience questionnaire', 'assessment of training and experience', 'evaluation of training and experience questionnaire', \n                'training and experience (t&e) questionnaire', 'forensic print specialist training and experience questionnaire']:\n        x = ['training and experience evaluation', x[1]]\n    if x[0] in ['knowledge, skills, and abilities written test', 'written', 'personal characteristics written test']:\n        x = ['written test', x[1]]\n    return x\n\nfor idx, i in enumerate(exam_weights):\n    curr = []\n    for j in i:\n        k = j\n        if len(k)==3:\n            if 'advisory' in k[1] and 'interview' in k[1]:\n                k = [j[0]] + j[1].split(' ') + [j[2]]\n            else:\n                k = [' '.join(j[:2])] + [j[2]]\n        if len(k)==4:\n            curr.append(check_exam_weight(k[:2]))\n            curr.append(check_exam_weight(k[2:]))\n        elif len(k)==2:\n            curr.append(check_exam_weight(k))\n        else:\n            print(len(k), k)\n            raise ValueError(\"Unknown length of array encountered.\")\n    exam_weights2.append(curr)\n    \nexam_weights3 = []\nfor i in exam_weights2:\n    curr = []\n    for j in i:\n        curr.append(' | '.join(j))\n    exam_weights3.append(' || '.join(curr))\n    \nmaster['SELECTION_CRITERIA'] = exam_weights3\ndel exam_weights, exam_weights2, exam_weights3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Application Deadline"},{"metadata":{"trusted":true},"cell_type":"code","source":"months = ['JANUARY', 'FEBRUARY', 'MARCH', 'APRIL', 'MAY', 'JUNE', 'JULY', 'AUGUST', 'SEPTEMBER', 'OCTOBER', 'NOVEMBER', 'DECEMBER']\n\ndef check_date(date):\n    flag = 0\n    temp_date = date.split('_')\n    if temp_date[0] in months: # Months\n        flag+=1\n    if temp_date[1].isdigit() == True: # Dates\n        if int(temp_date[1]) >= 1 and int(temp_date[1]) <= 31:\n            flag+=1\n    if temp_date[2].isdigit() == True: # Years\n        if int(temp_date[2]) >= 1990 and int(temp_date[2]) <= 2025:\n            flag+=1\n    return int(flag/3)\n\napplication_deadlines = []\nprior_notice = []\n\nfor job in jobs_list:\n    flag = 0\n    for i in job:\n        if 'APPLICATION DEADLINE' in i:\n            x = i[i.find('APPLICATION DEADLINE'):].upper().split(' ')\n            dates_identified = []\n            dates_idx = []\n            for idx, j in enumerate(x):\n                if j in months:\n                    check_term = x[idx] + '_' + x[idx+1].split(',')[0] + '_' + x[idx+2][:4]\n                    if check_date(check_term) == 1:\n                        if len(dates_idx) > 0:\n                            if dates_idx[-1]<80 and idx>100:\n                                continue\n                            else:\n                                dates_identified.append(check_term)\n                                dates_idx.append(idx)\n                        else:\n                            if idx<100:\n                                dates_identified.append(check_term)\n                                dates_idx.append(idx)\n            if len(dates_identified) == 3:\n                    dates_identified = [dates_identified[0], dates_identified[1]]\n            if len(dates_identified) > 0:\n                flag = 1\n                if 'may close without prior notice' in i:\n                    prior_notice.append(1)\n                else:\n                    prior_notice.append(0)\n                if len(dates_identified) == 1:\n                    dates_identified = dates_identified[0].split('_')\n                    application_deadlines.append('%s %s, %s'%(dates_identified[0], dates_identified[1], dates_identified[2]))\n                else:\n                    dates_combos = []\n                    idx_marker = 0\n                    while 2*len(dates_combos) != len(dates_identified):\n                        st = dates_identified[idx_marker].split('_')\n                        en = dates_identified[idx_marker + 1].split('_')\n                        idx_marker += 2\n                        dates_combos.append(\"%s %s, %s to %s %s, %s\"%(st[0], st[1], st[2], en[0], en[1], en[2]))\n                    application_deadlines.append(\" | \".join(dates_combos))\n    if flag == 0:\n        if 'prior notice' in ' '.join(job):\n            prior_notice.append(1)\n        else:\n            prior_notice.append(0)\n        application_deadlines.append('')\n\nmaster['APPLICATION_DEADLINE'] = application_deadlines\nmaster['CLOSE_W/O_PRIOR_NOTICE'] = prior_notice\n\ndel application_deadlines, prior_notice","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Applicable Civil Service Rules"},{"metadata":{"trusted":true},"cell_type":"code","source":"applicable_civil_service_rules = []\n\nfor job in jobs_list:\n    curr = []\n    for i in job:\n        if 'Civil Service Rule' in i:\n            curr_text = i[i.find('Civil Service Rule'):i.find('Civil Service Rule')+100]\n            curr_text = [t.strip().strip(',').strip('.') for t in curr_text.split(' ')]\n            curr_text = [t for t in curr_text if len(t.split('.'))==2 and t.split('.')[0].isdigit()==True and t.split('.')[1].isdigit()==True]\n            if len(curr_text)>0:\n                curr.append(', '.join(curr_text))\n    if len(curr)>0:\n        applicable_civil_service_rules.append(' | '.join(set(curr)))\n    else:\n        applicable_civil_service_rules.append('')\n        \nmaster['APPL_CIVIL_SERV_RULES'] = applicable_civil_service_rules\n\ndel applicable_civil_service_rules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master.sample(5, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### That's it for now, guys!\n* Will try to extract more information and update soon. Keep watching this space.\n* Need to update EDA and Analysis on the columns starting Selection Criteria!\n* Please let me know in case you have any suggestions.\n\n#### Best of Data-Hacking. Thanks for visiting. :D\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://ksr-ugc.imgix.net/assets/011/453/774/67b0835e7a19844ecd1db4e6ee46021d_original.jpg?ixlib=rb-2.0.0&crop=faces&w=1552&h=873&fit=crop&v=1463682941&auto=format&frame=1&q=92&s=5f851358ec46b5f0489bbb3f017799b7)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}