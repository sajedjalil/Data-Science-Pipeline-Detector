{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Science for Good: City of Los Angeles\n## Background;\nWhen candidates are hunting for new jobs, the content, tone, and format of job bulletins can influence wether the candidates would apply or not. Therefore, improving the quality of the job description is essential for a better applicant pool.\n\nThe goal of this notebook is to demenstrate the process of conveting the plain text job description to a single structured CSV file. Afterwords, we would use this data to: \n1. Identify language that can negatively bias the pool of applicants; \n2. Improve the diversity and quality of the applicant pool; \n3. Make it easier to determine which promotions are available to employees in each job class.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Configuration and package installation\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\nimport re\nimport csv\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n!pip install textstat\nimport textstat\nimport nltk\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk import pos_tag\nfrom collections  import Counter\n!pip install find_job_titles\n!pip install graphviz\nfrom find_job_titles import FinderAcora\nfrom graphviz import Digraph\n!pip install vaderSentiment\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\n# Prevent warning message, making report more user-friendly\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Open files directory \nfiles=[dir for dir in os.walk('../input/cityofla/CityofLA')]\n\nbulletins=os.listdir(\"../input/cityofla/CityofLA/Job Bulletins/\")\nadditional=os.listdir(\"../input/cityofla/CityofLA/Additional data/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a list of job positions: each element of list is one job description\njob = []\n\nfor bullet in bulletins:\n    \n    f = open(\"../input/cityofla/CityofLA/Job Bulletins/\"+ bullet,encoding='latin-1')\n    position = f.read()\n    pos = position.replace('\\t','').replace('\\n','')\n    f.close()\n    \n    job.append(pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Write regular patterns of each feature\ndate = '(\\d\\d\\d\\d\\d\\d)'\ncode = '(\\d\\d\\d\\d)'\nsalary = '\\$(\\d+,\\d+)(\\s(to|and)\\s)(\\$\\d+,\\d+)'\nrequire1 = '(REQUIREMENTS?/\\s?MINIMUM QUALIFICATIONS?)(.*)(PROCESS NOTE)' \nrequire2 = '(REQUIREMENTS?)(.*)(NOTES?)'\neducate = 'College or University|College|University|High School|college or university|college|university|high school|special degree program|degree program|undergraduate|Undergraduate|Graduate|graduate|Bachelor’s Degree|Bachelor|Master|Master’s Degree|Doctoral or Professional Degree'\nexperience = 'paid experience|volunteer experience|unpaid experience|full-time experience|part-time experience|full time experience|part time experience|work experience|experiences|experience'\n\n# Check regular patterns function \ndef check_re(pat, S):\n    return bool(re.search(pat, S))\n\n# Extract Title to a list\nTitle = []\nfor i in bulletins:\n    Title.append(re.split(\"\\d{4}\", i)[0].lower())\n\nTitle = pd.Series(Title)\n\n# Extract OpenDate to a list\nOpenDate = []\nfor i in range(len(bulletins)):\n    if check_re(date,bulletins[i]) == True:\n        OpenDate.append(re.search(date,bulletins[i]).group())\n    else:\n        OpenDate.append('')\n        \nOpenDate = pd.Series(OpenDate)\n\n# Extract ClassNode to a list\nClassCode = []\nfor i in range(len(job)):\n    if check_re(code,job[i]) == True:\n        ClassCode.append(re.search(code,job[i]).group())\n    else:\n        ClassCode.append('')\n    \nClassCode = pd.Series(ClassCode)\n\n# Extract Salary to a list\nSalary = []\nfor i in range(len(job)):\n    if check_re(salary,job[i]) == True:\n        Salary.append(re.search(salary,job[i]).group())\n    else:\n        Salary.append('')\n\nSalary = pd.Series(Salary)\n\nSalaryStart = []\nSalaryEnd = []\nfor i in range(len(Salary)):\n    if Salary[i] != '':\n        SalaryStart.append(re.split('(to|and)',Salary[i])[0])\n        SalaryEnd.append(re.split('(to|and)',Salary[i])[2])\n    else:\n        SalaryStart.append('')\n        SalaryEnd.append('')\n\nSalaryStart = pd.Series(SalaryStart)\nSalaryEnd = pd.Series(SalaryEnd)\n\n# Check regular patterns function \ndef check_re(pat, S):\n    return bool(re.search(pat, S))\n\n# Extract Requirement to a list\nRequirement = []\nfor i in range(len(job)):\n    if check_re(require1,job[i]) == True:\n        Requirement.append(re.search(require1,job[i]).group(2))\n    elif check_re(require2,job[i]) == True:\n        try:\n            Requirement.append(re.search('(.*)NOTES?',re.findall(r'(REQUIREMENTS?)(.*)(NOTES?)',job[i])[0][1][:1200]).group(0))\n        except:\n            Requirement.append('NA')\n    else:\n        Requirement.append('')\n\n# Clean requirement:       \nfor r in range(len(Requirement)):\n    if 'NOTE' in Requirement[r]:\n        Requirement[r] = Requirement[r].split(\"NOTE\",1)[0]    \n        \nRequirement = pd.Series(Requirement)\n\n# Extract FileName to a list\nFileName = pd.Series(bulletins)\n\n# Extract Length to a list\nLength = []\nfor i in range(len(job)):\n    Length.append(len(job[i].split()))\n    \nLength = pd.Series(Length)\n\n# Extract Education Level to a list\nEducation = []\nfor i in range(len(Requirement)):\n    if check_re(educate,Requirement[i]) == True:\n        Education.append(re.search(educate,Requirement[i]).group(0))\n    else:\n        Education.append('no education required')\n\nfor i in range(len(Education)):\n    if check_re('College or University|College|University|college or university|college|university|undergraduate|Undergraduate|Bachelor’s Degree|Bachelor',Education[i]) == True:\n        Education[i] = 'college or university'\n    elif check_re('High School|high school',Education[i]) == True:\n        Education[i] = 'high school'\n    elif check_re('Graduate|graduate|Master|Master’s Degree|Doctoral or Professional Degree', Education[i]) == True:\n        Education[i] = 'graduate'\n    elif check_re('special degree program|degree program',Education[i]):\n        Education[i] = 'special degree program'\n    else:\n        Education[i] = Education[i]\n\n\nEducation = pd.Series(Education)\n\n# Extract Experience Level to a list\nExperience = []\nfor i in range(len(Requirement)):\n    if check_re(experience,Requirement[i]) == True:\n        Experience.append('require experience')\n    else:\n        Experience.append('no experience required')\n           \nExperience = pd.Series(Experience)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Duties to a list\nDuties = []\nduty = '(DUTIES)(\\s*)'\n\nfor bullet in bulletins:\n    f = open(\"../input/cityofla/CityofLA/Job Bulletins/\"+ bullet,encoding='latin-1')\n    jobList = f.readlines()\n    for i in range(len(jobList)):\n        jobList[i] = jobList[i].replace('\\n','')\n    \n    jobList = [elem for elem in jobList if elem != '']\n          \n    if sum(1 for i in range(len(jobList)) if check_re(duty,jobList[i]) == True) == 1:\n        for i in range(len(jobList)):\n            if check_re(duty,jobList[i]) == True:\n                Duties.append(jobList[i+1])\n    else:\n        Duties.append('') # some job description doesn't contains duties\n\nDuties = pd.Series(Duties)\n\n# EXtract Deadlines of applications\nEndDate = []\nfor i in job:\n    try:\n        EndDate.append(re.search(r'(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\\s(\\d{1,2},\\s\\d{4})',i).group())\n    except Exception as e:\n        EndDate.append(np.nan)\n        \nEndDate = pd.Series(EndDate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dataframe for further analysis\ndf = pd.concat([FileName, Title, OpenDate, ClassCode, Salary,SalaryStart, SalaryEnd, \n                Requirement, Experience, Education, Duties, Length,EndDate], axis=1)\ndf.columns = ['FileName','Title', 'OpenDate', 'ClassCode', 'Salary','SalaryStart', 'SalaryEnd', \n              'Requirement','Experience', 'Education', 'Duties','Length','EndDate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correct the column types: SalaryStart and SalaryEnd\ndf['SalaryStart'] = df['SalaryStart'].str.replace('$','')\ndf['SalaryStart'] = df['SalaryStart'].str.replace(',','')\ndf['SalaryStart'] = pd.to_numeric(df['SalaryStart'])\n\ndf['SalaryEnd'] = df['SalaryEnd'].str.replace('$','')\ndf['SalaryEnd'] = df['SalaryEnd'].str.replace(',','')\ndf['SalaryEnd'] = pd.to_numeric(df['SalaryEnd'])\n\n# Fill the missing values with mean\ndf['SalaryStart'] = df['SalaryStart'].fillna(df['SalaryStart'].mean())\ndf['SalaryEnd'] = df['SalaryEnd'].fillna(df['SalaryEnd'].mean())\n\n# Delete unnecessary column\ndel df['Salary']\n\n# Set class code as index\ndf = df.set_index('ClassCode')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign the null value a new value: '010100'\nfor i in range(len(df['OpenDate'])):\n    if df['OpenDate'][i] == '':\n        df['OpenDate'][i] = '010100'\n\n# Transform column type into datetime\ndf['OpenDate'] = df['OpenDate'].apply(lambda x : dt.datetime.strptime(x, '%m%d%y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"### How does the length of words distributed?\n#### Problem 1.1:\nFirst, we want to know the number of words in each job description. Length of job description could reflect the efficiency of job description in some degree. We use histogram to visualize the distribution of the number of words in job descriptions. The x-axis is the bins of number of words and the y-axis is the frequency."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describe the statistics of length of words\ndf['Length'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot histogram \nfig, ax = plt.subplots(figsize=(12, 8))\nax.hist(df['Length'], bins=10, color=\"#d1ae45\")\n\n# Set title label legend and xtickers\nplt.title('Words Count',size = 18,alpha=0.8)\nplt.xlabel('Number Of Words',size = 18,alpha=0.8)\nplt.ylabel('Frequency',size = 18,alpha=0.8)\n\n\n# Change background color inside the axes\nax.set_facecolor(\"#2E2E2E\")\n\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Findings:\nFrom the plot, it can be find that the distribution is a right-skewed distribution. Most of job posts contain less than 2000 but greater than 1000 words. Only a few of job descriptions contain more than 2000 words. Based on the research of Indeed.com, it shows that 'job descriptions between 700 and 2,000 characters get up to 30% more applications', which indicates that it would be better to write more concise job description than a tedious one. \n\n#### Recommendation:\nWe recommend that recruiters should pay attention to the length of job posting and make efforts to limit the length of job post within 1000 words. The job post is also a type of reflection of company culture and work attitude. Efficiency would attract more applicants. Recruiters should find a good balance between providing enough details so that the candidates could fully understand the requirements and duties while keeping the description concise. \n\n#### Reference:\nhttps://www.indeed.com/hire/how-to-write-a-job-description?matchtype=b&network=g&device=c&devicemodel=&creative=355143870850&keyword=%2Bjob%20%2Bdescriptions&placement=&param1=&param2=&random=3857810173098333339&aceid=&adposition=1t1&utm_source=google&utm_medium=cpc&utm_term=job+descriptions&utm_campaign=job+description+pages+general+0+%28bmm%29&utm_medium=cpc&utm_source=google_search&utm_campaign=2001311670&utm_term=kwd-17476351936&gclid=EAIaIQobChMIlPaS7u_64gIVT-DICh1eIAqJEAAYASAAEgL6XPD_BwE"},{"metadata":{},"cell_type":"markdown","source":"#### Problem 1.2:\nAlso, we want to know the length of job title, job requirements and job duties separately. We use three boxplots to visualize data. The x-axis is the number of counts."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the number of characters in Title and number of words in Requirements and Duties\ndf['TitleLen'] = df['Title'].apply(lambda x: len(x))\ndf['RequireLen'] = df['Requirement'].apply(lambda x: len(x.split(' ')))\ndf['DutiesLen'] = df['Duties'].apply(lambda x: len(x.split(' ')))\n\nfig = plt.figure(2,(12,8))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n# Subplot the length of job title\nfig.add_subplot(3,1,1)\nsns.boxplot(x=df['TitleLen'],color = 'lightcoral')\nplt.title('Job Title Length(in characters)')\nplt.xlabel('number of characters',size = 12,alpha=0.8)\n\n# Subplot the length of job requirements\nfig.add_subplot(3,1,2)\nsns.boxplot(x=df['RequireLen'],color = 'firebrick')\nplt.title('Job Requirement Length(in words)')\nplt.xlabel('number of words',size = 12,alpha=0.8)\n\n# Subplot the length of job duties\nfig.add_subplot(3,1,3)\nsns.boxplot(x=df['DutiesLen'],color = 'mistyrose')\nplt.title('Job Duty Length(in words)')\nplt.xlabel('number of words',size = 12,alpha=0.8)\n\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Findings:\nFrom the plots, it can be seen that most job titles are within 20 to 35 characters, most job requirements are less than 100 words, and most job duties are within 40 to 80 words. Most job posts have a reasonable number of words, which is good for applicants to read. It indicates that the core components of job posting (requirement and duty) are very concise for most job posts.\n\n#### Recommendation:\nOur recommendation is that it would be better to simplify the words about the description of hiring processes and additional information of the job position. If the content of additional information are much more than the core information of job description, it would divert applicats attention from the more important information. "},{"metadata":{},"cell_type":"markdown","source":"### What are the basic salary distributed of different kinds of common experience requirement?\n#### Problem 2:\nThen, we want to know the general distribution of starting salary. We use distribution plot to visualize data. The x-axis is the starting salary and the y-axis is the probability."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot starting salary distplot\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nsns.distplot(df['SalaryStart'], rug=True, rug_kws={\"color\": \"darkgreen\"},\n             kde_kws={\"color\": \"olive\", \"lw\": 3, \"label\": \"KDE\"},\n             hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n                       \"alpha\": 1, \"color\": \"darkgreen\"})\n\nplt.title('Starting Salary Distribution')\nplt.ylabel('Probability',size = 12,alpha=0.8)\nplt.xlabel('Starting Salary',size = 12,alpha=0.8)\n\n# Plot ending salary distplot\nplt.subplot(1,2,2)\nsns.distplot(df['SalaryEnd'], rug=True, rug_kws={\"color\": \"firebrick\"},\n             kde_kws={\"color\": \"orange\", \"lw\": 3, \"label\": \"KDE\"},\n             hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n                       \"alpha\": 1, \"color\": \"firebrick\"})\nplt.title('Ending Salary Distribution')\nplt.ylabel('Probability',size = 12,alpha=0.8)\nplt.xlabel('Ending Salary',size = 12,alpha=0.8)\n\nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Findings 2.1:\nFrom the plots, it can be seen that the starting salary and ending salary basically conform to normal distribution. Most starting salary falls between 50000 and 100000, while most ending salary falls between 75000 and 12500. In terms of ZipRecruiter.com, it says that 'A pay range will generally spread +/- 15-20% from the midpoint, but any range the employer feels is appropriate is acceptable, and ranges may be different for different grades.' Most of the job description conform to this rule. However, a few of job description has a huger range of salary. As shown in the following tables.\n\n#### Reference:\nhttps://www.ziprecruiter.com/blog/how-to-set-a-salary-and-create-pay-grades/"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the difference of salary start and salary end \ndf['SalaryDiff']=abs(df['SalaryEnd']-df['SalaryStart'])\n\n# Filter the top 10 job position with largest difference of salary\nranges=df[['Title','SalaryDiff']].sort_values(by='SalaryDiff',ascending=False)[:10]\nranges","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Findings 2.2:\nFrom the table, it can be seen that manager, director, principal, superintendent usually has the largest gap in starting salary and ending salary. It indicates that the salary of hign-rank position has more upside potential. There are more space for applicants to negotiate salary. \n\n\n#### Recommendation:\nOur recommendation is that recruiters should clearly label the lowest salary and the highest salary of one job position. In order to avoid any confusion, the salary range should be within 15% to 20% from the mean of salary. Also, recruiters could also establish some pay grades or highlight pay equity in job description. For example, entry-level may be paid 75-80% of the market rate and high-experienced employees would max out around 120-125% of the market rate."},{"metadata":{},"cell_type":"markdown","source":"### How does the education or experience be mentioned in job description?\n#### Problem 3: \nNext, we want to know whether there are education requirements in job description. We use a donut chart (pie chart) to visualize the eduaction data and use bar chart to visualize experience data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the occurance of education requirements \neducation = pd.DataFrame(df.groupby(by='Education').agg({'Title': 'count'}))\neducation.columns = ['count']\neducation = education[education['count'] > 10]\neducation.sort_values(by = 'count',ascending=False)\n\n\n# Create donut plot to visualize the occurance of education requirements \nfig, ax = plt.subplots(figsize=(14, 8), subplot_kw=dict(aspect=\"equal\"))\n\nwedges, texts = ax.pie(education['count'], wedgeprops=dict(width=0.5), startangle=-40,colors=['chocolate','salmon','gold'])\n\nbbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\nkw = dict(xycoords='data', textcoords='data', arrowprops=dict(arrowstyle=\"-\"),\n          bbox=bbox_props, zorder=0, va=\"center\")\n\n# Demonstrate the value of each category instead of percentage as the default value\nfor i, p in enumerate(wedges):\n    ang = (p.theta2 - p.theta1)/2. + p.theta1\n    y = np.sin(np.deg2rad(ang))\n    x = np.cos(np.deg2rad(ang))\n    horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n    connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n    kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n    ax.annotate(str(education.index[i])+' : '+str(education['count'][i]), xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n                 horizontalalignment=horizontalalignment, **kw)\n\nax.set_title(\"The number of education requirements\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Findings 3.1:\nFrom the plot, it can be seen more than half of the job description don't have a educational background bias and don't mention the required degree. about one third job posts require college or university degree. Based on the research of Harvard Business School, employers should stop requiring college degree for middle-skill jobs because it may cause \"degree inflation\". \n\n#### Recommendation 3.1:\nOur recommendation is that for high-level jobs, it would be better to explicit the minimum requirement of education degree. However, for low-level jobs or medium-level jobs, it is better not to include any requirements of education degree. We think that most of the recruiters did well in this point. It is because the emphasis of the education may cause degree inflation so that applicants may regard the company with bias. It's better to not let a college degree become a barrier to entering the workforce or seeking their careers. Instead, sometimes experience in related fields may be more important.\n\n#### Reference:\nhttps://hbswk.hbs.edu/item/why-employers-must-stop-requiring-college-degrees-for-middle-skill-jobs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the occurance of experience requirements \nexperience = pd.DataFrame(df.groupby(by='Experience').agg({'Title': 'count'}))\nexperience.columns = ['count']\nexperience.sort_values(by = 'count',ascending=False)\n\n# Plot the frequency of experience requirements\nplt.figure(figsize=(10, 6))\nsns.barplot(y=experience['count'],x=experience.index,palette=\"Set2\")\nplt.title('Experience requirement')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### Findings 3.2:\nFrom the plot, most of the job posts list experience as one of the requirement. There are more than 600 job descriptions mention experience in job requirements. We think this is good because relavant work experience would be very important to determine whether a candidates fit that job."},{"metadata":{},"cell_type":"markdown","source":"### How does the open date distributed? (in year/ month/ week/ season)\n#### Problem 4:\nThen, we want to explore how does the open date distribution in terms of year, quarter, month and week. We use four subplots to visualize data. The y-axis is the frequency of occurance."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subplot quarter \nplt.figure(figsize=(16,8))\nplt.subplot(2,2,1)\ndf['OpenQuarter']=[z.quarter for z in df['OpenDate']]\ncount=df['OpenQuarter'].value_counts(sort=False)\nsns.barplot(y=count.values,x=count.index,palette='Spectral')\nplt.title('Quarter')\n\n# Subplot year\nplt.subplot(2,2,2)\ndf['OpenYear']=[z.year for z in df['OpenDate']]\ncount=df['OpenYear'].value_counts(sort=False)\nsns.barplot(y=count.values,x=count.index,palette='Spectral')\nplt.title('Year')\n\n# Subplot month\nplt.subplot(2,2,3)\ndf['OpenMonth']=[z.month for z in df['OpenDate']]\ncount=df['OpenMonth'].value_counts(sort=False)\nsns.barplot(y=count.values,x=count.index,palette='Spectral')\nplt.title('Month')\n\n# Subplot weekday\nplt.subplot(2,2,4)\ndf['OpenDay']=[z.weekday() for z in df['OpenDate']]\ncount=df['OpenDay'].value_counts(sort=False)\nsns.barplot(y=count.values,x=count.index,palette='Spectral')\nplt.title('Weekday')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Findings:\nFrom the plots, it can be seen that jobs are posted evenly in each quarter. March, October and December have the most job posts. The number of job posting has increased dramatically since 2014. However, the most interesting finding is that most job postings are released on Friday. That could be one problem for recruiters because Friday may not be the best day to release a job post. Based on the research of LinkedIn.com, it shows that there are the most applicants browse job website on Monday and fewest applicants on Friday and weekends. \n\n#### Recommendation:\nOur recommendation is that recruiters could change the open day from Friday to Monday to increase the number of potential applicants. The more applicants, the more choices for one company. \n\n#### Reference:\nhttps://business.linkedin.com/talent-solutions/blog/trends-and-research/2016/the-best-times-to-post-a-job-on-linkedin"},{"metadata":{},"cell_type":"markdown","source":"### Readability Analysis\nWhen we went through a few job post examples, we find that it's hard to understand the context of the file quickly. This is a problem when it comes to attracting more diverse and qualified candidates. Therefore, we performed a readability analysis on the job posts.\n\nWe decided to use *textstat* which is a Python package to calculate statistics from text to determine readability, complexity and grade level of a particular corpus. In addition, we use *Readability Consensus based upon all the above tests* which is based upon all the above tests, returns the estimated school grade level required to understand the text."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the redability score of requirement for each job post\nreadability_score = []\nfor i in range(len(df)):\n    temp = df['Requirement'][i]\n    readability_score.append(textstat.text_standard(temp)[:2])\nreadability_score = pd.Series(readability_score).str.replace('[t]', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the readability_score\nreadability_score = pd.to_numeric(readability_score)\nreadability_score.hist(bins=40, figsize = (10,8));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We find that the readability score distribution is not as good as we expected, around half are higher than 10. Not many candidates have that high level of education. Therefore, we recommmend that city of LA could consider to use simpler words and sentences to propose the job description which is easier to read."},{"metadata":{},"cell_type":"markdown","source":"### Gender bias in job posting\nWhile the Civil Rights Act of 1964 prohibits employers from overtly soliciting a preferred gender in their job listings, research shows that the language of job descriptions often subtly adheres to gender stereotypes. And that deters members of the opposite gender from applying to those jobs.\n\nTherefore, here we would like to perform text analysis in requirement, duties and title of job posting to find out wether gender bias is a problem of City of LA."},{"metadata":{"trusted":true},"cell_type":"code","source":"req=' '.join(text for text in df['Requirement'])\nduties= ' '.join(d for d in df['Duties'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pronoun(data):\n    \n    '''function to tokenize data and perform pos_tagging.Returns tokens having \"PRP\" tag'''\n    \n    prn=[]\n    vrb=[]\n    token=word_tokenize(data)\n    pos=pos_tag(token)\n   \n    vrb=Counter([x[0] for x in pos if x[1]=='PRP'])\n    \n    return vrb\n    \n\n\nreq_prn=pronoun(req)\nduties_prn=pronoun(duties)\nprint('pronouns used in requirement section are')\nprint(req_prn.keys())\nprint('\\npronouns used in duties section are')\nprint(duties_prn.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the result, we do not detect any gender bias words in the retuirement and duties section of all job postings. Therefore, we do encourge City of LA to continue to perform well on keeping the word neutral, imporving the diversity and the applicants pool."},{"metadata":{},"cell_type":"markdown","source":"### Find out whether the job post is negtive or positive¶\nIf the job post is more negtive, it not good for the candidates to read."},{"metadata":{"trusted":true},"cell_type":"code","source":"analyzer = SentimentIntensityAnalyzer()\n\n# Write the function get_sentiment to get the sentiment information\ndef get_sentiment(column_name):\n    sentiment = []\n    for i in range(len(df)):\n        temp = list(analyzer.polarity_scores(df[column_name][i]).values())[3]\n        sentiment.append(temp)\n        \n    #print(sentiment)\n    return sentiment","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sentiment Analysis for Responsibility\n- score -1 ~ -0.25 means the text is negtive;\n- score -0.25 ~ 0.25 means the text is neutral;\n- score 0.25 ~ 1 means the text is positive."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the analysis for responsibility\nplt.hist(get_sentiment('Requirement'), bins=30)\nplt.title('Sentiment Distribution for Requeirment')\nplt.xlabel('Sentiment')\nplt.ylabel('count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sentiment Analysis for Duties"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the analysis for Duties\nplt.hist(get_sentiment('Duties'), bins=30)\nplt.title('Sentiment Distribution for Duties')\nplt.xlabel('Sentiment')\nplt.ylabel('count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sentiment Analysis for Title"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the analysis for Title\nplt.hist(get_sentiment('Title'), bins=30)\nplt.title('Sentiment Distribution for Title')\nplt.xlabel('Sentiment')\nplt.ylabel('count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result of sentiment analysis shows that the text in requirement, duties, and titles are very neutral. Therefore, city of LA could continue to use the neutral words when propose a job post"},{"metadata":{},"cell_type":"markdown","source":"### Promotion path\nSince there are too many position in the promotion path and it's not easy to visualize, we decided to use *animal* related position to show the promotion path"},{"metadata":{"trusted":true},"cell_type":"code","source":"dot = Digraph(comment='Promotions')\n\nfinder=FinderAcora()\nstrReq = \"Requirement\"\narrRelation=[]\narrFinal=[]\n\ndef get_promotion(row):\n    strLine = str(row [strReq]) #only check Requirement/minimum qualification section to get the promotion path\n    # usually the promotion sentences start with \"as a\" and finish with \"with\"\n    if strLine.find(\"as a\") > 0:\n        objItem = dict() \n        # only one previous position required\n        #if strLine.find(\"or\") < 0:\n        strTemp = strLine[strLine.find(\"as a\"):strLine.find(\"with\")-1]\n        strTemp = strTemp.replace(\"as an\", \"as a\").replace(\"as a \",\"\")\n        if strTemp != \"\":\n            for m in finder.findall(strTemp):\n                objItem['Job1'] = row[\"Title\"].lstrip().rstrip().upper()\n                objItem['Job2'] = m[2].lstrip().rstrip().upper()\n                arrRelation.append(objItem)\n    return row\n    \ndf = df.apply(get_promotion, axis=1)\n\npro = pd.DataFrame(arrRelation)\n#pro.head()\n#pro.to_csv('C:/Work/Promotion.csv')\npro = pro.drop_duplicates()\n#Job1 is higher role and Job1 is the role which could promote to Job1\nfor index, row in pro.iterrows():\n# as the image is too large, here just take police related jobs as an example\n    if row[\"Job2\"].startswith(\"ANIMAL\"):\n        dot.edge(row[\"Job2\"], row[\"Job1\"], label='Promote')\ndot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract data frame into csv file\ndf.to_csv('./jobs.csv', index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}