{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Overview\nThis notebook compares features extracted from the last hidden layer of 9 [pre-trained text models from Huggingface](https://huggingface.co/transformers/pretrained_models.html). Models are evaluated according to prediction accuracy in the [CommonLit Readability Prize competition](https://www.kaggle.com/c/commonlitreadabilityprize) training data. Model *roberta-large* appears to be the best model, followed by *camembert-base*.","metadata":{}},{"cell_type":"markdown","source":"## Selected models\nThe following models were picked from the [Huggingface pre-trained models page](https://huggingface.co/transformers/pretrained_models.html). Some were commented out because they produce an error of one type or another (e.g. notebook runs out of memory, or there's no tokenizer.)","metadata":{}},{"cell_type":"code","source":"MODEL_NAMES = [\n    'bert-large-cased',\n    'openai-gpt',\n    #'gpt2-large',\n    #'xlnet-large-cased',\n    #'xlm-mlm-en-2048',\n    'roberta-large',\n    'distilbert-base-cased',\n    #'ctrl',\n    'camembert-base',\n    'albert-large-v2',\n    #'t5-large',\n    'flaubert/flaubert_large_cased',\n    'facebook/bart-large-cnn',\n    'moussaKam/mbarthez',\n    #'DialoGPT-large',\n    #'facebook/m2m100_418M',\n    'allenai/longformer-large-4096',\n    #'lxmert-base-uncased',\n    #'funnel-transformer/small',\n    #'funnel-transformer/xlarge',\n    'microsoft/layoutlm-large-uncased',\n    'microsoft/deberta-xlarge-v2',\n    'squeezebert/squeezebert-mnli-headless',\n    'camembert/camembert-base-wikipedia-4gb',\n    'chkla/roberta-argument',\n]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:33:52.843365Z","iopub.execute_input":"2021-05-29T21:33:52.84379Z","iopub.status.idle":"2021-05-29T21:33:52.85047Z","shell.execute_reply.started":"2021-05-29T21:33:52.84374Z","shell.execute_reply":"2021-05-29T21:33:52.849182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following function is used to load a model and tokenizer.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel\n\nassert torch.cuda.is_available(), 'No CUDA!'\ndevice = torch.device('cuda')\n\ndef get_model_info(model_name: str):    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModel.from_pretrained(model_name).to(device)\n    return model, tokenizer,","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-05-29T21:33:52.852131Z","iopub.execute_input":"2021-05-29T21:33:52.852867Z","iopub.status.idle":"2021-05-29T21:33:52.865358Z","shell.execute_reply.started":"2021-05-29T21:33:52.852758Z","shell.execute_reply":"2021-05-29T21:33:52.864415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Last hidden layer\nPyTorch models may consist of sub-models or sequences of modules. The *get_last_hidden_layer*() function makes a best guess as to which layer is the one that feeds the output layer.","metadata":{}},{"cell_type":"code","source":"from torch.nn import Sequential\n\ndef get_last_two_layers_in_sequence(seq: Sequential):   \n    seq_size = len(seq)\n    if seq_size == 0:\n        return None, None,\n    elif seq_size == 1:\n        return None, seq[seq_size - 1],\n    else:\n        return seq[seq_size - 2], seq[seq_size - 1],\n\n    \ndef get_last_two_layers(model):\n    prev_layer = None\n    last_layer = None\n    module_dict = model._modules\n    for key in module_dict:\n        module = module_dict[key]\n        if isinstance(module, Sequential):\n            m_prev, m_last = get_last_two_layers_in_sequence(module)                        \n        else:\n            m_prev, m_last = get_last_two_layers(module)\n        if m_last is None:\n            m_last = module\n        prev_layer = m_prev if m_prev is not None else last_layer\n        last_layer = m_last\n    return prev_layer, last_layer,\n\n\ndef get_last_hidden_layer(model):\n    prev, _ = get_last_two_layers(model)\n    return prev","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:33:52.867518Z","iopub.execute_input":"2021-05-29T21:33:52.867936Z","iopub.status.idle":"2021-05-29T21:33:52.877497Z","shell.execute_reply.started":"2021-05-29T21:33:52.867896Z","shell.execute_reply":"2021-05-29T21:33:52.876583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature extraction\nWe'll now define a function that can extract features from an arbitrary model and layer, assuming the shape of the feature tensor is known.","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef get_features(model, tokenizer, layer, out_shape, text: str):\n    vector_buffer = torch.zeros(out_shape)\n    def _local_hook(_, _input, _output):\n        nonlocal vector_buffer\n        vector_buffer.copy_(_output.data)\n    tensors = tokenizer(text, return_tensors='pt')\n    fh = layer.register_forward_hook(_local_hook)\n    model(**tensors.to(device))\n    fh.remove()\n    return torch.flatten(vector_buffer)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:33:52.879108Z","iopub.execute_input":"2021-05-29T21:33:52.879471Z","iopub.status.idle":"2021-05-29T21:33:52.886696Z","shell.execute_reply.started":"2021-05-29T21:33:52.879434Z","shell.execute_reply":"2021-05-29T21:33:52.885651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of features\nTo find the shape of the feature tensor, we use a layer hook that captures the shape of the layer's output.","metadata":{}},{"cell_type":"code","source":"def get_features_shape_mn(model_name: str, test_text='hello', for_input=False):\n    model, tokenizer = get_model_info(model_name)\n    layer = get_last_hidden_layer(model)\n    return get_features_shape(model, tokenizer, layer, test_text=test_text, for_input=for_input)\n\n\ndef get_features_shape(model, tokenizer, layer, test_text='hello', for_input=False):\n    t_dims = None\n    def _local_hook(_, _input, _output):\n        nonlocal t_dims\n        t_dims = _input[0].size() if for_input else _output.size()\n        return _output \n    tensors = tokenizer(test_text, return_tensors='pt')\n    fh = layer.register_forward_hook(_local_hook)\n    model(**tensors.to(device))\n    fh.remove()\n    return t_dims","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:33:52.888201Z","iopub.execute_input":"2021-05-29T21:33:52.88859Z","iopub.status.idle":"2021-05-29T21:33:52.899512Z","shell.execute_reply.started":"2021-05-29T21:33:52.888553Z","shell.execute_reply":"2021-05-29T21:33:52.89857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following table captures the number of features produced by the last hidden layer of each model, \nassuming the input contains only one token. If two tokens produce a different tensor shape, then the\n*tokens_dependent* column will be *True*.","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:33:52.90085Z","iopub.execute_input":"2021-05-29T21:33:52.902617Z","iopub.status.idle":"2021-05-29T21:33:52.909615Z","shell.execute_reply.started":"2021-05-29T21:33:52.902586Z","shell.execute_reply":"2021-05-29T21:33:52.908708Z"}}},{"cell_type":"code","source":"import sys\nimport gc\nimport pandas as pd\n\ndef flattened_size(size):\n    p = 1\n    for i in range(len(size)):\n        p *= size[i]\n    return p\n\n\nfeature_counts = []\nfor model_name in MODEL_NAMES:\n    try:\n        model, tokenizer = get_model_info(model_name)\n        layer = get_last_hidden_layer(model)\n        shape1 = get_features_shape(model, tokenizer, layer, test_text='hello')\n        num_features = flattened_size(shape1)\n        shape2 = get_features_shape(model, tokenizer, layer, test_text='hello world')\n        tokens_dependent = flattened_size(shape2) != num_features\n        feature_counts.append((model_name, num_features, tokens_dependent))\n        del model\n        del tokenizer\n        gc.collect()\n    except:\n        print('Model failed: %s |' % model_name, sys.exc_info()[0])\nfeature_count_frame = pd.DataFrame(feature_counts, columns=['model_name', 'num_features', 'tokens_dependent'])\nfeature_count_frame","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:33:52.938313Z","iopub.execute_input":"2021-05-29T21:33:52.93859Z","iopub.status.idle":"2021-05-29T21:37:42.300659Z","shell.execute_reply.started":"2021-05-29T21:33:52.938563Z","shell.execute_reply":"2021-05-29T21:37:42.299714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformation\nThe *transform_dataset*() function takes competition data frame and produces a feature matrix in place of excerpts.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndef transform_dataset(data_frame: pd.DataFrame, model, tokenizer, layer, features_shape):\n    y = []\n    x = []\n    for index, row in data_frame.iterrows():\n        text = row['excerpt']\n        label = row['target']\n        features = get_features(model, tokenizer, layer, features_shape, text)\n        x.append(features.detach().numpy())\n        y.append(label)\n    return np.array(x), np.array(y),","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:37:42.302363Z","iopub.execute_input":"2021-05-29T21:37:42.302705Z","iopub.status.idle":"2021-05-29T21:37:42.309437Z","shell.execute_reply.started":"2021-05-29T21:37:42.302667Z","shell.execute_reply":"2021-05-29T21:37:42.308269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using k-NN to evaluate feature sets\nIf we were to use a linear regressor or a neural network to evaluate feature sets, we'd have to consider that larger feature sets are at a disadvantage, statistically. (The competition's training dataset isn't very large.) Plus regularization parameters depend on the number of features. Even with a random forest or a GBM, the number of trees would need to be adjusted according to the number of features. The k-NN algorithm does not have these issues.\n\nAdditionally, we can quickly do leave-one-out cross-validation with k-NN, and we're defining a custom function that does this, with the help of *sklearn*'s BallTree implementation:","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import BallTree\n\ndef leave_one_out_knn_predictions(x, y: np.ndarray, k: int):\n    ball_tree = BallTree(x, leaf_size=10)\n    idx_matrix = ball_tree.query(x, k=k+1, return_distance=False)\n    loo_idx_matrix = idx_matrix[:,1:]\n    return np.array([np.mean(y[idx_row]) for idx_row in loo_idx_matrix])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:37:42.311418Z","iopub.execute_input":"2021-05-29T21:37:42.311819Z","iopub.status.idle":"2021-05-29T21:37:42.322596Z","shell.execute_reply.started":"2021-05-29T21:37:42.311753Z","shell.execute_reply":"2021-05-29T21:37:42.321557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation\nNot we put everything together and run an evaluation routine. Models are skipped if the number of features depends on the number of tokens. Cross-validation RMSE of remaining model feature sets is shown in a bar chart below.","metadata":{}},{"cell_type":"code","source":"%%time\n\nfrom sklearn.metrics import mean_squared_error\n\n\ndef evaluate_models(model_names):\n    train_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\n    results_matrix = []\n    for index, row in feature_count_frame.iterrows():\n        model_name = row['model_name']\n        if row['tokens_dependent']:\n            print('Skipping %s' % model_name)\n            continue\n        print('Evaluating %s ...' % model_name)\n        model, tokenizer = get_model_info(model_name)\n        layer = get_last_hidden_layer(model)\n        shape = get_features_shape(model, tokenizer, layer)\n        x, y = transform_dataset(train_data, model, tokenizer, layer, shape)\n        pred_y = leave_one_out_knn_predictions(x, y, k=10)\n        rmse = mean_squared_error(pred_y, y, squared=False)\n        results_matrix.append([model_name, rmse])\n        del model\n        del tokenizer\n        del x\n        gc.collect()\n    return pd.DataFrame(results_matrix, columns=['model_name','rmse'])\n\n\nmodel_eval_frame = evaluate_models(MODEL_NAMES)\nmodel_eval_frame = model_eval_frame.sort_values('rmse')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T21:37:42.324096Z","iopub.execute_input":"2021-05-29T21:37:42.324532Z","iopub.status.idle":"2021-05-29T21:57:38.603766Z","shell.execute_reply.started":"2021-05-29T21:37:42.324491Z","shell.execute_reply":"2021-05-29T21:57:38.602704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport plotly.express as px\n\ndef plot_bar_chart(data, x_var: str, y_var: str, title='', x_label='', y_label=''):\n    fig = px.bar(data, x=x_var, y=y_var, title=title,\n                 labels={x_var: x_label, y_var: y_label})\n    fig.show()\n    \n\nplot_bar_chart(model_eval_frame, 'model_name', 'rmse',\n               title='Text model comparison',\n               x_label='Model name', y_label='k-NN RMSE')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-29T21:57:38.605415Z","iopub.execute_input":"2021-05-29T21:57:38.605809Z","iopub.status.idle":"2021-05-29T21:57:38.665459Z","shell.execute_reply.started":"2021-05-29T21:57:38.605767Z","shell.execute_reply":"2021-05-29T21:57:38.664427Z"},"trusted":true},"execution_count":null,"outputs":[]}]}