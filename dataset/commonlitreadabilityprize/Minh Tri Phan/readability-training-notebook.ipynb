{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DeBERTa version 1, sub-version 1","metadata":{"papermill":{"duration":0.018501,"end_time":"2021-06-30T08:44:42.295398","exception":false,"start_time":"2021-06-30T08:44:42.276897","status":"completed"},"tags":[],"id":"sharp-fever"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"d9CZi8FCswOp","executionInfo":{"status":"ok","timestamp":1627301711641,"user_tz":-60,"elapsed":36,"user":{"displayName":"Trí Phan Minh","photoUrl":"","userId":"02889094254595027772"}},"outputId":"2038a7ea-f996-4e56-eced-6986d4588ae1","execution":{"iopub.status.busy":"2021-08-02T15:38:21.074296Z","iopub.execute_input":"2021-08-02T15:38:21.074702Z","iopub.status.idle":"2021-08-02T15:38:21.755535Z","shell.execute_reply.started":"2021-08-02T15:38:21.074586Z","shell.execute_reply":"2021-08-02T15:38:21.75453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport random\n\nimport nltk\nimport string\nimport re\nimport math\n\nfrom sklearn.utils import shuffle\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\n# Autocast\nfrom torch.cuda.amp import autocast, GradScaler\n\n# Stochastic Weight Average\nfrom torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, AdamW\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":7.752921,"end_time":"2021-06-30T08:44:50.066277","exception":false,"start_time":"2021-06-30T08:44:42.313356","status":"completed"},"tags":[],"id":"opponent-cursor","execution":{"iopub.status.busy":"2021-08-02T15:38:21.757396Z","iopub.execute_input":"2021-08-02T15:38:21.757765Z","iopub.status.idle":"2021-08-02T15:38:30.566264Z","shell.execute_reply.started":"2021-08-02T15:38:21.757724Z","shell.execute_reply":"2021-08-02T15:38:30.565278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\ntransformers.__version__","metadata":{"papermill":{"duration":0.027356,"end_time":"2021-06-30T08:44:50.111582","exception":false,"start_time":"2021-06-30T08:44:50.084226","status":"completed"},"tags":[],"id":"portable-thomson","executionInfo":{"status":"ok","timestamp":1627301722666,"user_tz":-60,"elapsed":40,"user":{"displayName":"Trí Phan Minh","photoUrl":"","userId":"02889094254595027772"}},"outputId":"11bd833c-fd85-4d0e-c59b-bfb351304818","execution":{"iopub.status.busy":"2021-08-02T15:38:30.568302Z","iopub.execute_input":"2021-08-02T15:38:30.568782Z","iopub.status.idle":"2021-08-02T15:38:30.579544Z","shell.execute_reply.started":"2021-08-02T15:38:30.568736Z","shell.execute_reply":"2021-08-02T15:38:30.578244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Readability features by spaCy","metadata":{"papermill":{"duration":0.018672,"end_time":"2021-06-30T08:44:50.14877","exception":false,"start_time":"2021-06-30T08:44:50.130098","status":"completed"},"tags":[],"id":"legal-processing"}},{"cell_type":"code","source":"def seed_everything(seed = 0):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nseed = 1234\nseed_everything(seed)","metadata":{"papermill":{"duration":0.039563,"end_time":"2021-06-30T08:45:04.197133","exception":false,"start_time":"2021-06-30T08:45:04.15757","status":"completed"},"tags":[],"id":"royal-european","execution":{"iopub.status.busy":"2021-08-02T15:38:30.581945Z","iopub.execute_input":"2021-08-02T15:38:30.582363Z","iopub.status.idle":"2021-08-02T15:38:30.593416Z","shell.execute_reply.started":"2021-08-02T15:38:30.58232Z","shell.execute_reply":"2021-08-02T15:38:30.592694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data","metadata":{"papermill":{"duration":0.023565,"end_time":"2021-06-30T08:45:04.245372","exception":false,"start_time":"2021-06-30T08:45:04.221807","status":"completed"},"tags":[],"id":"assured-franchise"}},{"cell_type":"code","source":"base_dir = '../input/clrcross-validation-strategies'\ndata = pd.read_csv(f'{base_dir}/train_folds_shuffle.csv')\nbenchmark = data[data['standard_error'] == 0.]\ndata['compare_to_benchmark'] = np.sign(data['target'])\ndata.head()","metadata":{"papermill":{"duration":0.146311,"end_time":"2021-06-30T08:45:04.415459","exception":false,"start_time":"2021-06-30T08:45:04.269148","status":"completed"},"tags":[],"id":"figured-antibody","executionInfo":{"status":"ok","timestamp":1627301731932,"user_tz":-60,"elapsed":785,"user":{"displayName":"Trí Phan Minh","photoUrl":"","userId":"02889094254595027772"}},"outputId":"3e1d7bbb-fd0d-4d1d-b939-044daf06b7d2","execution":{"iopub.status.busy":"2021-08-02T15:38:30.594815Z","iopub.execute_input":"2021-08-02T15:38:30.595274Z","iopub.status.idle":"2021-08-02T15:38:30.736567Z","shell.execute_reply.started":"2021-08-02T15:38:30.595235Z","shell.execute_reply":"2021-08-02T15:38:30.735606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('*' * 50)\nsample_text_low = data.sort_values('target')['excerpt'].iloc[10]\nprint('Sample hard-to-read document: \\n', sample_text_low)\nprint('*' * 50)\nsample_text_high = data.sort_values('target')['excerpt'].iloc[-10]\nprint('Sample easy-to-read document: \\n', sample_text_high)","metadata":{"papermill":{"duration":0.037561,"end_time":"2021-06-30T08:45:04.477443","exception":false,"start_time":"2021-06-30T08:45:04.439882","status":"completed"},"tags":[],"id":"silent-midnight","executionInfo":{"status":"ok","timestamp":1627301731933,"user_tz":-60,"elapsed":15,"user":{"displayName":"Trí Phan Minh","photoUrl":"","userId":"02889094254595027772"}},"outputId":"750ee12c-2d3e-4094-df55-832a61138e05","execution":{"iopub.status.busy":"2021-08-02T15:38:30.738036Z","iopub.execute_input":"2021-08-02T15:38:30.738373Z","iopub.status.idle":"2021-08-02T15:38:30.753474Z","shell.execute_reply.started":"2021-08-02T15:38:30.738337Z","shell.execute_reply":"2021-08-02T15:38:30.752657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"papermill":{"duration":0.024407,"end_time":"2021-06-30T08:45:04.52632","exception":false,"start_time":"2021-06-30T08:45:04.501913","status":"completed"},"tags":[],"id":"spanish-humidity"}},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower().strip()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\ndef text_preprocessing(text):\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    combined_text = ' '.join(tokenized_text)\n    return combined_text\n\ndef readability_feat(text):\n    text = nlp(text)\n    \n    return np.array([text._.flesch_kincaid_grade_level,\n                     text._.flesch_kincaid_reading_ease,\n                     text._.dale_chall,\n                     text._.coleman_liau_index,\n                     text._.automated_readability_index,\n                     text._.forcast], dtype = np.float)\n\ndef sample_text(targets, num_output = 5):\n    mean, var = targets[0], targets[1]\n    if targets[1] != 0.:\n        sampled_target = torch.normal(mean, var, size = (num_output,))\n    else:\n        sampled_target = torch.tensor([0.] * num_output, dtype = torch.float)\n    return sampled_target\n\ndef convert_examples_to_features(text, tokenizer, max_len, is_test = False, return_tensor = False):\n    # Take from https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-fit\n    text = text.replace('\\n', '')\n    if return_tensor:\n        tok = tokenizer.encode_plus(\n            text, \n            max_length = max_len, \n            padding = 'max_length', \n            return_tensors = 'pt',\n            truncation = True,\n            return_attention_mask = True,\n            return_token_type_ids = True\n        )\n    else:\n        tok = tokenizer.encode_plus(\n            text, \n            max_length = max_len, \n            padding = 'max_length', \n            truncation = True,\n            return_attention_mask = True,\n            return_token_type_ids = True\n        )\n    return tok\n\ndef form_dataset(token, external_features = None, target = None, bins = None):\n    if target is not None:\n        if bins is not None:\n            if external_features is not None:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'external_features': torch.tensor(external_features, dtype = torch.float),\n                    'target': target,\n                    'bins': bins,\n                }\n            else:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'target': target,\n                    'bins': bins,\n                }\n        else:\n            if external_features is not None:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'external_features': torch.tensor(external_features, dtype = torch.float),\n                    'target': target,\n                }\n            else:\n                return {\n                    'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                    'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                    'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                    'target': target,\n                }\n    else:\n        if external_features is not None:\n            return {\n                'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n                'external_features': torch.tensor(external_features, dtype = torch.float),\n            }\n        else:\n            return {\n                'input_ids': torch.tensor(token['input_ids'], dtype = torch.long),\n                'token_type_ids': torch.tensor(token['token_type_ids'], dtype = torch.long),\n                'attention_mask': torch.tensor(token['attention_mask'], dtype = torch.long),\n            }","metadata":{"papermill":{"duration":0.05062,"end_time":"2021-06-30T08:45:04.601834","exception":false,"start_time":"2021-06-30T08:45:04.551214","status":"completed"},"tags":[],"id":"sexual-constitution","execution":{"iopub.status.busy":"2021-08-02T15:38:30.756503Z","iopub.execute_input":"2021-08-02T15:38:30.756799Z","iopub.status.idle":"2021-08-02T15:38:30.782643Z","shell.execute_reply.started":"2021-08-02T15:38:30.756771Z","shell.execute_reply":"2021-08-02T15:38:30.781739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.024453,"end_time":"2021-06-30T08:45:04.650782","exception":false,"start_time":"2021-06-30T08:45:04.626329","status":"completed"},"tags":[],"id":"graduate-taste"}},{"cell_type":"code","source":"class Readability_Dataset(Dataset):\n    def __init__(self, documents, tokenizer, sample = False, max_len = 300, num_output = 5, binning = True, mode = 'train'):\n        self.documents = documents\n        self.tokenizer = tokenizer\n        self.sample = sample\n        self.max_len = max_len\n        self.mode = mode\n        self.num_output = num_output\n        \n        if self.mode == 'train':\n            self.binning = binning\n        \n    def __len__(self):\n        return len(self.documents)\n    \n    def __getitem__(self, idx):\n        sample = self.documents.iloc[idx]\n        document = sample['excerpt']\n        \n        # Compute readability features\n        ext_features = None # readability_feat(document)\n        \n        # Tokenize\n        features = convert_examples_to_features(document, self.tokenizer, self.max_len)\n        \n        if self.mode == 'train':\n            target = torch.tensor([sample['target'], sample['standard_error']], dtype = torch.float)\n            if self.sample:\n                target = sample_text(target, num_output = self.num_output)\n                \n            if self.binning:\n                bins = torch.tensor(sample['bins'], dtype = torch.long)\n            else:\n                bins = None\n                \n        elif self.mode == 'valid':\n            target = torch.tensor(sample['target'])\n            bins = None\n        else:\n            target = None\n            bins = None\n            \n        return form_dataset(features, external_features = ext_features, target = target, bins = bins)","metadata":{"papermill":{"duration":0.038231,"end_time":"2021-06-30T08:45:04.713891","exception":false,"start_time":"2021-06-30T08:45:04.67566","status":"completed"},"tags":[],"id":"ecological-portland","execution":{"iopub.status.busy":"2021-08-02T15:38:30.786019Z","iopub.execute_input":"2021-08-02T15:38:30.786297Z","iopub.status.idle":"2021-08-02T15:38:30.799043Z","shell.execute_reply.started":"2021-08-02T15:38:30.786266Z","shell.execute_reply":"2021-08-02T15:38:30.798229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.024401,"end_time":"2021-06-30T08:45:04.762908","exception":false,"start_time":"2021-06-30T08:45:04.738507","status":"completed"},"tags":[],"id":"unavailable-spouse"}},{"cell_type":"code","source":"class Readability_Model(nn.Module):\n    def __init__(self, backbone, model_config, is_sampled = False, num_external_features = 6, num_output = 2, \n                 num_cat = 7, attention_dim = 1024, multisample_dropout = True, benchmark_token = None):\n        super(Readability_Model, self).__init__()\n        self.model_config = model_config\n        self.is_sampled = is_sampled\n        self.benchmark_token = benchmark_token\n        self.backbone = AutoModel.from_pretrained(backbone, config = self.model_config)\n        self.layer_norm = nn.LayerNorm(self.model_config.hidden_size * 2)    # Concat of mean and max pooling\n        self.output = nn.Linear(self.model_config.hidden_size * 2, num_output)   #  + num_external_features\n        self.output_cat = nn.Linear(self.model_config.hidden_size * 2, num_cat)\n        \n        # Attention pooler\n        self.word_weight = nn.Linear(self.model_config.hidden_size * 2, attention_dim)\n        self.context_weight = nn.Linear(attention_dim, 1)\n        \n        self.hidden_layer_weights = nn.Parameter(torch.zeros(self.model_config.num_hidden_layers).view(-1, 1, 1, 1))\n        \n        # Dropout layers\n        if multisample_dropout:\n            self.dropouts_output = nn.ModuleList([\n                nn.Dropout(0.5) for _ in range(5)\n            ])\n            self.dropouts_cat = nn.ModuleList([\n                nn.Dropout(0.5) for _ in range(5)\n            ])\n        else:\n            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n        \n        # Initialize weights\n        self._init_weights(self.layer_norm)\n        self._init_weights(self.output)\n        self._init_weights(self.word_weight)\n        self._init_weights(self.context_weight)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean = 0.0, std = self.model_config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean = 0.0, std = self.model_config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def forward(self, input_ids, token_type_ids, attention_mask, external_features = None):\n        output_backbone = self.backbone(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n        \n        # Extract output\n        hidden_states = output_backbone.hidden_states\n        \n        # Mean/max pooling (over hidden layers), concatenate with pooler\n        hidden_states = torch.stack(tuple(hidden_states[-i-1] for i in range(len(hidden_states) - 1)), dim = 0)\n        layer_weight = F.softmax(self.hidden_layer_weights, dim = 0)\n        out_mean = torch.sum(hidden_states * layer_weight, dim = 0)\n        out_max, _ = torch.max(hidden_states, dim = 0)\n        output_backbone = torch.cat((out_mean, out_max), dim = -1)\n        output_backbone = self.layer_norm(output_backbone)\n        \n        # Attention Pooling (over time)\n        u_i = torch.tanh(self.word_weight(output_backbone))\n        u_w = self.context_weight(u_i).squeeze(1)\n        val = u_w.max()\n        att = torch.exp(u_w - val)\n        att = att / torch.sum(att, dim = 1, keepdim = True)\n        \n        output = output_backbone * att\n        output = output.sum(dim = 1)\n        \n        # Multiple dropout\n        for i, dropout in enumerate(self.dropouts_output):\n            if i == 0:\n                logits = self.output(dropout(output))\n                cats = self.output_cat(self.dropouts_cat[i](output))\n            else:\n                logits += self.output(dropout(output))\n                cats += self.output_cat(self.dropouts_cat[i](output))\n        \n        logits /= len(self.dropouts_output)\n        cats /= len(self.dropouts_output)\n        \n        if self.benchmark_token is not None:\n            logits = logits[:-1] - logits[-1]\n\n            cats = cats[:-1]\n        \n        if self.is_sampled:\n            return logits, None, torch.argmax(F.softmax(cats, dim = -1), dim = -1)\n        else:\n            return logits[:,0], torch.exp(0.5 * logits[:,1]), torch.argmax(F.softmax(cats, dim = -1), dim = -1)","metadata":{"papermill":{"duration":0.049908,"end_time":"2021-06-30T08:45:04.896195","exception":false,"start_time":"2021-06-30T08:45:04.846287","status":"completed"},"tags":[],"id":"demonstrated-individual","execution":{"iopub.status.busy":"2021-08-02T15:38:30.802031Z","iopub.execute_input":"2021-08-02T15:38:30.802454Z","iopub.status.idle":"2021-08-02T15:38:30.827545Z","shell.execute_reply.started":"2021-08-02T15:38:30.802422Z","shell.execute_reply":"2021-08-02T15:38:30.826691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss functions and metrics","metadata":{"papermill":{"duration":0.02427,"end_time":"2021-06-30T08:45:04.945005","exception":false,"start_time":"2021-06-30T08:45:04.920735","status":"completed"},"tags":[],"id":"everyday-twenty"}},{"cell_type":"code","source":"class KLLoss(nn.Module):\n    def __init__(self):\n        super(KLLoss, self).__init__()\n        \n    def forward(self, pred_mean, pred_std, target_mean, target_std):\n        p = torch.distributions.Normal(pred_mean, pred_std)\n        q = torch.distributions.Normal(target_mean, target_std)\n        loss = torch.mean(torch.distributions.kl_divergence(p, q))\n        return loss\n    \nclass RMSELoss(nn.Module):\n    def __init__(self):\n        super(RMSELoss, self).__init__()\n        \n    def forward(self, pred_mean, target_mean):\n        return torch.mean((pred_mean - target_mean)**2)\n    \nclass RankingLoss(nn.Module):\n    def __init__(self):\n        super(RankingLoss, self).__init__()\n        \n    def forward(self, pred_mean, pred_benchmark_mean, target_mean, margin = 0.5):\n        return nn.MarginRankingLoss(margin = margin)(pred_mean, pred_benchmark_mean, torch.sign(target_mean))\n    \nclass QuadraticWeightedKappaLoss(nn.Module):\n    def __init__(self, num_cat = 7, device = 'cpu'):\n        super(QuadraticWeightedKappaLoss, self).__init__()\n        self.num_cat = num_cat\n        cats = torch.arange(num_cat).to(device)\n        self.weights = (cats.view(-1,1) - cats.view(1,-1)).pow(2) / (num_cat - 1)**2\n        \n    def _confusion_matrix(self, pred_cat, true_cat):\n        confusion_matrix = torch.zeros((self.num_cat, self.num_cat)).to(pred_cat.device)\n        for t, p in zip(true_cat.view(-1), pred_cat.view(-1)):\n            confusion_matrix[t.long(), p.long()] += 1\n        return confusion_matrix\n        \n    def forward(self, pred_cat, true_cat):\n        # Confusion matrix\n        O = self._confusion_matrix(pred_cat, true_cat)\n        \n        # Count elements in each category\n        true_hist = torch.bincount(true_cat, minlength = self.num_cat)\n        pred_hist = torch.bincount(pred_cat, minlength = self.num_cat)\n        \n        # Expected values\n        E = torch.outer(true_hist, pred_hist)\n        \n        # Normlization\n        O = O / torch.sum(O)\n        E = E / torch.sum(E)\n        \n        # Weighted Kappa\n        numerator = torch.sum(self.weights * O)\n        denominator = torch.sum(self.weights * E)\n        \n        return numerator / denominator\n    \nclass BradleyTerryLoss(nn.Module):\n    def __init__(self):\n        super(BradleyTerryLoss, self).__init__()\n        \n    def forward(self, pred_mean, true_mean):\n        batch_size = len(pred_mean)\n        true_comparison = true_mean.view(-1,1) - true_mean.view(1,-1)\n        pred_comparison = pred_mean.view(-1,1) - pred_mean.view(1,-1)\n        \n        return torch.log(1 + torch.tril(torch.exp(-true_comparison * pred_comparison))).sum() / (batch_size * (batch_size - 1) / 2)\n    \ndef loss_fn(pred_mean, pred_std, target_mean, target_std, pred_cat = None, target_cat = None, loss_type = 'rmse', num_bins = None):\n    assert loss_type in ['rmse', 'kl', 'rank', 'qwk', 'rmse_rank', 'kl_rank', 'rmse_qwk', 'kl_qwk', 'rank_qwk', \n                         'bradley-terry', 'rmse_bradley-terry', 'qwk_bradley-terry', 'rmse_qwk_bradley-terry']\n    if 'qwk' in loss_type:\n        assert (pred_cat is not None) and (target_cat is not None) and (num_bins is not None)\n    if 'rank' in loss_type:\n        assert pred_benchmark_mean is not None\n    \n    device = pred_mean.device\n    \n    if loss_type == 'rmse':\n        return RMSELoss()(pred_mean, target_mean)\n    elif loss_type == 'kl':\n        return KLLoss()(pred_mean, pred_std, target_mean, target_std)\n    elif loss_type == 'rank':\n        return RankingLoss()(pred_mean, target_mean, margin = 0.5)\n    elif loss_type == 'qwk':\n        return QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n    elif loss_type == 'rmse_rank':\n        return torch.sqrt(RMSELoss()(pred_mean, target_mean)) + RankingLoss()(pred_mean, pred_benchmark_mean, target_mean, margin = 0.5)\n    elif loss_type == 'kl_rank':\n        return KLLoss()(pred_mean, pred_std, target_mean, target_std) + RankingLoss()(pred_mean, pred_benchmark_mean, target_mean, margin = 0.5)\n    elif loss_type == 'rmse_qwk':\n        return torch.sqrt(RMSELoss()(pred_mean, target_mean)) + QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n    elif loss_type == 'kl_qwk':\n        return KLLoss()(pred_mean, pred_std, target_mean, target_std) + QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n    elif loss_type == 'bradley-terry':\n        return BradleyTerryLoss()(pred_mean, target_mean)\n    elif loss_type == 'rmse_bradley-terry':\n        return torch.sqrt(RMSELoss()(pred_mean, target_mean)) + BradleyTerryLoss()(pred_mean, target_mean)\n    elif loss_type == 'qwk_bradley-terry':\n        return BradleyTerryLoss()(pred_mean, target_mean) + \\\n               QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n    elif loss_type == 'rmse_qwk_bradley-terry':\n        return torch.sqrt(RMSELoss()(pred_mean, target_mean)) + BradleyTerryLoss()(pred_mean, target_mean) + \\\n               QuadraticWeightedKappaLoss(num_cat = num_bins, device = device)(pred_cat, target_cat)\n\ndef metric_fn(pred_mean, target_mean):\n    return np.sqrt(np.mean((pred_mean - target_mean)**2))","metadata":{"papermill":{"duration":0.05085,"end_time":"2021-06-30T08:45:05.020687","exception":false,"start_time":"2021-06-30T08:45:04.969837","status":"completed"},"tags":[],"id":"revised-saying","execution":{"iopub.status.busy":"2021-08-02T15:38:30.829094Z","iopub.execute_input":"2021-08-02T15:38:30.829425Z","iopub.status.idle":"2021-08-02T15:38:30.858498Z","shell.execute_reply.started":"2021-08-02T15:38:30.82939Z","shell.execute_reply":"2021-08-02T15:38:30.857523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and validation functions","metadata":{"papermill":{"duration":0.024292,"end_time":"2021-06-30T08:45:05.069284","exception":false,"start_time":"2021-06-30T08:45:05.044992","status":"completed"},"tags":[],"id":"attractive-climb"}},{"cell_type":"code","source":"def train(model, train_dataloader, valid_dataloader, optimizer, fold, epoch, cfg, benchmark_token = None, \n          scaler = None, scheduler = None, best_metric_val = np.inf, swa_model = None, swa_scheduler = None):\n    \n    loss = 0\n    num_sample = 0\n    \n    pred = []\n    true = []\n    \n    if cfg.use_tqdm:\n        tbar = tqdm(train_dataloader)\n    else:\n        tbar = train_dataloader\n    \n    for i, item in enumerate(tbar):\n        model.train()\n        input_ids = item['input_ids'].to(cfg.device)\n        token_type_ids = item['token_type_ids'].to(cfg.device)\n        attention_mask = item['attention_mask'].to(cfg.device)\n        external_features = None\n        targets = item['target'].to(cfg.device)\n        if cfg.binning:\n            bins = item['bins'].to(cfg.device)\n        else:\n            bins = None\n        \n        if benchmark_token is not None:\n            benchmark_input_ids, benchmark_token_type_ids, benchmark_attention_mask = benchmark_token\n            input_ids = torch.cat((input_ids, benchmark_input_ids), dim = 0)\n            token_type_ids = torch.cat((token_type_ids, benchmark_token_type_ids), dim = 0)\n            attention_mask = torch.cat((attention_mask, benchmark_attention_mask), dim = 0)\n\n        if cfg.is_sampled:\n            true_mean = targets\n            true_std = None\n        else:\n            true_mean = targets[:,0]\n            true_std = targets[:,1]\n        \n        batch_size = input_ids.shape[0]\n        \n        # Set zero gradient\n        optimizer.zero_grad()\n        \n        with autocast(enabled = True):\n            # Feed the input to the model\n            pred_mean, pred_std, pred_cat = model(input_ids, token_type_ids, attention_mask, external_features)\n\n            # Compute loss\n            loss_batch = loss_fn(pred_mean, pred_std, true_mean, true_std, pred_cat = pred_cat, target_cat = bins, loss_type = cfg.loss_type, num_bins = cfg.num_bins)\n        \n        if cfg.use_tqdm:\n            tbar.set_description(f'Loss: {round(loss_batch.item(), 3)}')\n        \n        if scaler is not None:\n            # Back-propagation\n            scaler.scale(loss_batch).backward()\n            \n            # Update gradient\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            # Back-propagation\n            loss_batch.backward()\n            \n            # Update gradient\n            optimizer.step()\n        \n        # Evaluation\n        if epoch < int(cfg.evaluate_every[0][0] * cfg.nepochs):\n            evaluate_every = cfg.evaluate_every[0][1]\n        elif epoch >= int(cfg.evaluate_every[0][0] * cfg.nepochs) and epoch < (cfg.evaluate_every[1][0] * cfg.nepochs):\n            evaluate_every = cfg.evaluate_every[1][1]\n        else:\n            evaluate_every = cfg.evaluate_every[2]\n            \n        if i % evaluate_every == 0 or i == len(tbar) - 1:\n            if swa_model is None:\n                loss_val, metric_val = valid(model, valid_dataloader, cfg, benchmark_token = benchmark_token)\n                if metric_val < best_metric_val:\n                    best_metric_val = metric_val\n                    model_dict = {\n                        'epoch': epoch,\n                        'model_state_dict': model.state_dict(),\n                        'best_metric': best_metric\n                    }\n                    torch.save(model_dict, os.path.join(cfg.output_dir, f'model_best_fold_{fold}_{cfg.model_name}.bin'))\n                    print(f'Best metric updated to: {best_metric_val} !!!')\n            else:\n                swa_model.update_parameters(model)\n                update_bn(train_dataloader, swa_model)\n                loss_val, metric_val = valid(swa_model, valid_dataloader, cfg, benchmark_token = benchmark_token)\n                if metric_val < best_metric_val:\n                    best_metric_val = metric_val\n                    model_dict = {\n                        'epoch': epoch,\n                        'model_state_dict': swa_model.state_dict(),\n                        'best_metric': best_metric\n                    }\n                    torch.save(model_dict, os.path.join(cfg.output_dir, f'model_best_fold_{fold}_{cfg.model_name}.bin'))\n                    print(f'Best metric updated to: {best_metric_val} !!!')\n                \n        # Verbosity\n        if i % cfg.verbose == 0:\n            print(f'Epoch: {epoch + 1}  -  Finished: {round(i / len(train_dataloader) * 100, 2)}%  -  Valid metric: {metric_val}  -  Best metric: {best_metric_val}')\n        \n        loss += loss_batch * batch_size\n        num_sample += batch_size\n        \n        # Extract output\n        pred.extend(pred_mean.cpu().detach().numpy())\n        true.extend(true_mean.cpu().detach().numpy())\n        \n        torch.cuda.empty_cache()\n        \n        if swa_model is not None:\n            swa_scheduler.step()\n        \n        if scheduler is not None:\n            if swa_model is None:\n                scheduler.step()        \n        \n    # Stack\n    pred = np.array(pred)\n    true = np.array(true)\n    \n    # Compute loss and metrics\n    loss = torch.sqrt(loss / num_sample)\n    metric = metric_fn(pred, true)\n    \n    return loss, metric, best_metric_val","metadata":{"papermill":{"duration":0.049898,"end_time":"2021-06-30T08:45:05.14561","exception":false,"start_time":"2021-06-30T08:45:05.095712","status":"completed"},"tags":[],"id":"dutch-margin","execution":{"iopub.status.busy":"2021-08-02T15:38:30.860126Z","iopub.execute_input":"2021-08-02T15:38:30.86052Z","iopub.status.idle":"2021-08-02T15:38:30.887196Z","shell.execute_reply.started":"2021-08-02T15:38:30.86048Z","shell.execute_reply":"2021-08-02T15:38:30.886379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid(model, valid_dataloader, cfg, benchmark_token = None):\n    model.eval()\n    \n    loss = 0\n    num_sample = 0\n    \n    pred = []\n    true = []\n    \n    if cfg.use_tqdm:\n        tbar = tqdm(valid_dataloader)\n    else:\n        tbar = valid_dataloader\n    \n    for item in tbar:\n        input_ids = item['input_ids'].to(cfg.device)\n        token_type_ids = item['token_type_ids'].to(cfg.device)\n        attention_mask = item['attention_mask'].to(cfg.device)\n        external_features = None\n        targets = item['target'].to(cfg.device)\n        true_mean = targets\n        true_std = None\n        \n        batch_size = input_ids.shape[0]\n\n        if benchmark_token is not None:\n            benchmark_input_ids, benchmark_token_type_ids, benchmark_attention_mask = benchmark_token\n            input_ids = torch.cat((input_ids, benchmark_input_ids), dim = 0)\n            token_type_ids = torch.cat((token_type_ids, benchmark_token_type_ids), dim = 0)\n            attention_mask = torch.cat((attention_mask, benchmark_attention_mask), dim = 0)\n        \n        # Feed the input to the model\n        with torch.no_grad():\n            with autocast(enabled = True):\n                pred_mean, pred_std, pred_cat = model(input_ids, token_type_ids, attention_mask, external_features)\n                \n                if cfg.is_sampled:\n                    pred_mean = torch.mean(pred_mean, dim = -1)\n                    \n                # Compute loss\n                loss_batch = loss_fn(pred_mean, pred_std, true_mean, true_std, loss_type = 'rmse')\n\n            if cfg.use_tqdm:\n                tbar.set_description(f'Loss: {round(loss_batch.item(), 3)}')\n            \n            loss += loss_batch * batch_size\n            num_sample += batch_size\n\n            # Extract output\n            pred.extend(pred_mean.cpu().detach().numpy())\n            true.extend(true_mean.cpu().detach().numpy())\n        \n    # Stack\n    pred = np.array(pred)\n    true = np.array(true)\n    \n    # Compute loss and metrics\n    loss = torch.sqrt(loss / num_sample)\n    metric = metric_fn(pred, true)\n    \n    return loss, metric","metadata":{"papermill":{"duration":0.036504,"end_time":"2021-06-30T08:45:05.206345","exception":false,"start_time":"2021-06-30T08:45:05.169841","status":"completed"},"tags":[],"id":"suspected-upgrade","execution":{"iopub.status.busy":"2021-08-02T15:38:30.888776Z","iopub.execute_input":"2021-08-02T15:38:30.88926Z","iopub.status.idle":"2021-08-02T15:38:30.903225Z","shell.execute_reply.started":"2021-08-02T15:38:30.889225Z","shell.execute_reply":"2021-08-02T15:38:30.902521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Differentiate learning rate https://www.kaggle.com/rhtsingh/on-stability-of-few-sample-transformer-fine-tuning","metadata":{"papermill":{"duration":0.024093,"end_time":"2021-06-30T08:45:05.254433","exception":false,"start_time":"2021-06-30T08:45:05.23034","status":"completed"},"tags":[],"id":"brutal-cliff"}},{"cell_type":"code","source":"def get_optimizer_params(model, model_type = 'backbone', learning_rate = 2e-5, weight_decay = 0.01, layerwise_learning_rate_decay = 0.95):\n    no_decay = ['bias', 'LayerNorm.weight']\n    # Initialize lr for task specific layer\n    optimizer_grouped_parameters = [\n        {\n            'params': [p for n, p in model.named_parameters() if 'backbone' not in n],\n            'weight_decay': 0.0,\n            'lr': 1e-3,\n        },\n    ]\n    # Initialize lrs for every layer\n    num_layers = model.model_config.num_hidden_layers\n    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n    layers.reverse()\n    lr = learning_rate\n    for i, layer in enumerate(layers):\n        lr *= layerwise_learning_rate_decay\n        optimizer_grouped_parameters += [\n            {\n                'params': [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n                'weight_decay': weight_decay,\n                'lr': lr,\n            },\n            {\n                'params': [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n                'weight_decay': 0.0,\n                'lr': lr,\n            },\n        ]\n    return optimizer_grouped_parameters","metadata":{"papermill":{"duration":0.034507,"end_time":"2021-06-30T08:45:05.313104","exception":false,"start_time":"2021-06-30T08:45:05.278597","status":"completed"},"tags":[],"id":"judicial-giant","execution":{"iopub.status.busy":"2021-08-02T15:38:30.90436Z","iopub.execute_input":"2021-08-02T15:38:30.904781Z","iopub.status.idle":"2021-08-02T15:38:30.915891Z","shell.execute_reply.started":"2021-08-02T15:38:30.904745Z","shell.execute_reply":"2021-08-02T15:38:30.914908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model configuration","metadata":{"papermill":{"duration":0.024152,"end_time":"2021-06-30T08:45:05.361235","exception":false,"start_time":"2021-06-30T08:45:05.337083","status":"completed"},"tags":[],"id":"coordinate-batch"}},{"cell_type":"code","source":"class config():\n    # For training\n    nepochs = 20\n    lr = 2e-5\n    weight_decay = 0.01\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    use_tqdm = False\n    verbose = 60\n    evaluate_every = ((0.3, 20), (0.6, 40), 80)\n    es = None\n    swa_start = 6\n    swa_lr = 2e-6\n    # For dataloader\n    is_sampled = False\n    if is_sampled:\n        loss_type = 'rmse'\n        num_output = 10\n    else:\n        loss_type = 'rmse_qwk_bradley-terry'\n        num_output = 2\n    if 'qwk' in loss_type:\n        num_bins = 29\n        binning = True\n    else:\n        num_bins = 1\n        binning = False\n    max_len = 250\n    batch_size = 4\n    num_workers = 4\n    # For model\n    output_dir = os.getcwd()\n    backbone = 'microsoft/deberta-large'\n    model_name = '_'.join('deberta-large'.split('-'))\n\ncfg = config()","metadata":{"papermill":{"duration":0.07976,"end_time":"2021-06-30T08:45:05.465105","exception":false,"start_time":"2021-06-30T08:45:05.385345","status":"completed"},"tags":[],"id":"activated-delay","execution":{"iopub.status.busy":"2021-08-02T15:38:30.917229Z","iopub.execute_input":"2021-08-02T15:38:30.917609Z","iopub.status.idle":"2021-08-02T15:38:30.970623Z","shell.execute_reply.started":"2021-08-02T15:38:30.917574Z","shell.execute_reply":"2021-08-02T15:38:30.969415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bin the target\nif 'qwk' in cfg.loss_type:\n    data['bins'] = pd.cut(data['target'], bins = cfg.num_bins, labels = False)","metadata":{"papermill":{"duration":0.034046,"end_time":"2021-06-30T08:45:05.524169","exception":false,"start_time":"2021-06-30T08:45:05.490123","status":"completed"},"tags":[],"id":"federal-raising","execution":{"iopub.status.busy":"2021-08-02T15:38:30.973067Z","iopub.execute_input":"2021-08-02T15:38:30.973396Z","iopub.status.idle":"2021-08-02T15:38:30.988151Z","shell.execute_reply.started":"2021-08-02T15:38:30.973367Z","shell.execute_reply":"2021-08-02T15:38:30.987173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main","metadata":{"papermill":{"duration":0.024128,"end_time":"2021-06-30T08:45:05.572331","exception":false,"start_time":"2021-06-30T08:45:05.548203","status":"completed"},"tags":[],"id":"african-solution"}},{"cell_type":"code","source":"for fold in range(5):\n    # Split\n    trn = data[data['kfold'] != fold]\n    val = data[data['kfold'] == fold]\n    \n    tokenizer = AutoTokenizer.from_pretrained(cfg.backbone)\n    model_dir = cfg.backbone\n    model_config = AutoConfig.from_pretrained(model_dir, output_hidden_states = True)\n    \n    # Tokenize the benchmark text\n    benchmark_token = convert_examples_to_features(benchmark['excerpt'].iloc[0], tokenizer, cfg.max_len, return_tensor = True)\n    benchmark_token = (benchmark_token['input_ids'].to(cfg.device), benchmark_token['token_type_ids'].to(cfg.device), benchmark_token['attention_mask'].to(cfg.device))\n    \n    # Dataset\n    train_dataset = Readability_Dataset(trn, tokenizer, sample = cfg.is_sampled, max_len = cfg.max_len, binning = cfg.binning, mode = 'train')\n    valid_dataset = Readability_Dataset(val, tokenizer, sample = False, max_len = cfg.max_len, binning = cfg.binning, mode = 'valid')\n    \n    # Dataloader\n    train_dataloader = DataLoader(train_dataset, batch_size = cfg.batch_size, num_workers = cfg.num_workers, shuffle = True)\n    valid_dataloader = DataLoader(valid_dataset, batch_size = cfg.batch_size, num_workers = cfg.num_workers, shuffle = False)\n    \n    # Model\n    model = Readability_Model(model_dir, model_config, num_output = cfg.num_output, num_cat = cfg.num_bins, \n                              benchmark_token = benchmark_token).to(cfg.device)\n    swa_model = AveragedModel(model)\n    \n    # Differentiated learning rate for separate layers\n    optimizer_grouped_parameters = get_optimizer_params(model, learning_rate = cfg.lr, weight_decay = cfg.weight_decay)\n    optimizer = AdamW(optimizer_grouped_parameters, lr = cfg.lr, weight_decay = cfg.weight_decay)\n    num_training_steps = cfg.nepochs * len(train_dataloader)\n    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = int(0.05 * num_training_steps), \n                                                num_training_steps = num_training_steps)\n    \n    swa_scheduler = SWALR(optimizer, anneal_strategy = 'linear', anneal_epochs = 1, swa_lr = cfg.swa_lr)\n    \n    scaler = GradScaler()\n    \n    es = 0\n    best_metric = np.inf\n    \n    print('*' * 50)\n    print(f'Fold: {fold}')\n    \n    for epoch in range(cfg.nepochs):\n        if epoch < cfg.swa_start:\n            _, _, best_metric = train(model, train_dataloader, valid_dataloader, optimizer, fold, epoch, cfg, benchmark_token = benchmark_token, \n                                      scaler = scaler, scheduler = scheduler, best_metric_val = best_metric)\n        else:\n            _, _, best_metric = train(model, train_dataloader, valid_dataloader, optimizer, fold, epoch, cfg, benchmark_token = benchmark_token, scaler = scaler, \n                                      best_metric_val = best_metric, swa_model = swa_model, swa_scheduler = swa_scheduler)\n\n        if epoch >= 7:\n            break\n            \n    update_bn(train_dataloader, swa_model)","metadata":{"papermill":{"duration":7670.391602,"end_time":"2021-06-30T10:52:55.988469","exception":false,"start_time":"2021-06-30T08:45:05.596867","status":"completed"},"tags":[],"id":"funky-march","executionInfo":{"status":"ok","timestamp":1627312695258,"user_tz":-60,"elapsed":10962020,"user":{"displayName":"Trí Phan Minh","photoUrl":"","userId":"02889094254595027772"}},"outputId":"e693a279-cc05-4483-e15e-e59907f8e715","execution":{"iopub.status.busy":"2021-08-02T15:38:30.98983Z","iopub.execute_input":"2021-08-02T15:38:30.990242Z"},"trusted":true},"execution_count":null,"outputs":[]}]}