{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/mi9U6o5.png\">","metadata":{}},{"cell_type":"markdown","source":"# Introduction üìù\nüéØ **Goal:** To build algorithms to rate the complexity of reading passages for grade 3-12 classroom use. \n\nüìñ **Data:** \n> **train.csv / test.csv** - the training and testing set\n> - ```id``` - unique ID for excerpt\n> - ```url_legal``` - URL of source \n> - ```license``` - license of source material \n> - ```excerpt``` - text to predict reading ease of\n> - ```target``` - reading ease\n> - ```standard_error``` - measure of spread of scores among multiple raters for each excerpt\n\nüìå **Note:** ```url_legal```, ```license``` and ```standard error``` are blank in the test set.\n\nüß™ **Evaluation metric:** Root Mean Squared Error (RMSE)\n> $$RMSE = \\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}{\\Big(\\frac{y_i - \\hat{y_i}}{\\sigma_i}\\Big)^2}}$$\n> where \n> * $y_i$ : original value\n> * $\\hat{y_i}$ : predicted value\n> * $n$ : number of rows in the test data","metadata":{}},{"cell_type":"markdown","source":"# Import libraries üìö","metadata":{}},{"cell_type":"code","source":"!pip install textstat\n!pip install rich\n\nimport os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport re\nimport nltk\nimport textstat\nimport time\nimport wandb\nimport rich\nimport spacy\n\nfrom pandas import DataFrame\nfrom matplotlib.lines import Line2D\nfrom rich.console import Console\nfrom rich import print\nfrom rich.theme import Theme\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag\nfrom collections import Counter\nfrom wordcloud import WordCloud,STOPWORDS\nfrom spacy import displacy\nfrom nltk.tokenize import sent_tokenize, word_tokenize \nfrom sklearn.feature_extraction.text import CountVectorizer as CV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error as mse\n\nnltk.download('stopwords')","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src=\"https://camo.githubusercontent.com/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\">\n\n> I will be integrating W&B for visualizations and logging artifacts!\n> \n> [CommonLit Project on W&B Dashboard](https://wandb.ai/ruchi798/commonlit?workspace=user-ruchi798) üèãÔ∏è‚Äç‚ôÄÔ∏è\n> \n> - To get the API key, an account is to be created on the [website](https://wandb.ai/site) first.\n> - Next, use secrets to use API Keys more securely ü§´","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"api_key\")\n\nos.environ[\"WANDB_SILENT\"] = \"true\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! wandb login $api_key","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n\ndef custom_palette(custom_colors):\n    customPalette = sns.set_palette(sns.color_palette(custom_colors))\n    sns.palplot(sns.color_palette(custom_colors),size=0.8)\n    plt.tick_params(axis='both', labelsize=0, length = 0)\n\npalette = [\"#7209B7\",\"#3F88C5\",\"#136F63\",\"#F72585\",\"#FFBA08\"]\npalette2 = sns.diverging_palette(120, 220, n=20)\ncustom_palette(palette)\n\ncustom_theme = Theme({\n    \"info\" : \"italic bold cyan\",\n    \"warning\": \"italic bold magenta\",\n    \"danger\": \"bold blue\"\n})\n\nconsole = Console(theme=custom_theme)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing valuesüîÆ","metadata":{}},{"cell_type":"markdown","source":"Here I have used a viz module called [missingno](https://pypi.org/project/missingno/) to visualize missing values in the training set.\n\nWe don't have any missing values in the columns of our interest, i.e., ```excerpt```, ```target``` and ```standard_error```!","metadata":{}},{"cell_type":"code","source":"msno.bar(train_df,color=palette[2], sort=\"ascending\", figsize=(10,5), fontsize=12)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing excerpt ‚úÇÔ∏è","metadata":{}},{"cell_type":"markdown","source":"It's important to preprocess the excerpt before we proceed further!","metadata":{}},{"cell_type":"code","source":"excerpt1 = train_df['excerpt'].min()\nconsole.print(\"Before preprocessing: \",style=\"info\")\nconsole.print(excerpt1,style='warning')\n\ne = re.sub(\"[^a-zA-Z]\", \" \", excerpt1)\ne = e.lower()\n        \ne = nltk.word_tokenize(e)\n        \ne = [word for word in e if not word in set(stopwords.words(\"english\"))]\n        \nlemma = nltk.WordNetLemmatizer()\ne = [lemma.lemmatize(word) for word in e]\ne=\" \".join(e)\nconsole.print(\"After preprocessing: \",style=\"info\")\nconsole.print(e,style='warning')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#====== Preprocessing function ======\ndef preprocess(data):\n    excerpt_processed=[]\n    for e in data['excerpt']:\n        \n        # find alphabets\n        e = re.sub(\"[^a-zA-Z]\", \" \", e)\n        \n        # convert to lower case\n        e = e.lower()\n        \n        # tokenize words\n        e = nltk.word_tokenize(e)\n        \n        # remove stopwords\n        e = [word for word in e if not word in set(stopwords.words(\"english\"))]\n        \n        # lemmatization\n        lemma = nltk.WordNetLemmatizer()\n        e = [lemma.lemmatize(word) for word in e]\n        e=\" \".join(e)\n        \n        excerpt_processed.append(e)\n        \n    return excerpt_processed ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logging the preprocessed dataset as an **artifact** üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"# train_df[\"excerpt_preprocessed\"] = preprocess(train_df)\n# test_df[\"excerpt_preprocessed\"] = preprocess(test_df)\n\n# #====== Saving to csv files and creating artifacts ======\n# train_df.to_csv(\"train_excerpt_preprocessed.csv\")\n\n# run = wandb.init(project='commonlit', name='excerpt_preprocessed')\n\n# artifact = wandb.Artifact('train_excerpt_preprocessed', type='dataset')\n\n# #====== Add a file to the artifact's contents ======\n# artifact.add_file(\"train_excerpt_preprocessed.csv\")\n\n# #====== Save the artifact version to W&B and mark it as the output of this run ====== \n# run.log_artifact(artifact)\n\n# run.finish()\n\n# #====== Saving to csv files and creating artifacts ======\n# test_df.to_csv(\"test_excerpt_preprocessed.csv\")\n\n# run = wandb.init(project='commonlit', name='excerpt_preprocessed')\n\n# artifact = wandb.Artifact('test_excerpt_preprocessed', type='dataset')\n\n# #====== Add a file to the artifact's contents ======\n# artifact.add_file(\"test_excerpt_preprocessed.csv\")\n\n# #====== Save the artifact version to W&B and mark it as the output of this run ====== \n# run.log_artifact(artifact)\n\n# run.finish()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the **saved artifact** üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"run = wandb.init(project='commonlit')\nartifact = run.use_artifact('ruchi798/commonlit/train_excerpt_preprocessed:v0', type='dataset')\nartifact_dir = artifact.download()\nrun.finish()\n\npath = os.path.join(artifact_dir,\"train_excerpt_preprocessed.csv\")\ntrain_df = pd.read_csv(path)\ntrain_df = train_df.drop(columns=[\"Unnamed: 0\"])\n\nrun = wandb.init(project='commonlit')\nartifact = run.use_artifact('ruchi798/commonlit/test_excerpt_preprocessed:v0', type='dataset')\nartifact_dir = artifact.download()\nrun.finish()\n\npath = os.path.join(artifact_dir,\"test_excerpt_preprocessed.csv\")\ntest_df = pd.read_csv(path)\ntest_df = test_df.drop(columns=[\"Unnamed: 0\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA üìä","metadata":{}},{"cell_type":"code","source":"#====== Function to plot wandb bar chart ======\ndef plot_wb_bar(df,col1,col2,name,title): \n    run = wandb.init(project='commonlit', job_type='image-visualization',name=name)\n    \n    dt = [[label, val] for (label, val) in zip(df[col1], df[col2])]\n    table = wandb.Table(data=dt, columns = [col1,col2])\n    wandb.log({name : wandb.plot.bar(table, col1,col2,title=title)})\n\n    run.finish()\n    \n#====== Function to plot wandb histogram ======\ndef plot_wb_hist(df,name,title):\n    run = wandb.init(project='commonlit', job_type='image-visualization',name=name)\n\n    dt = [[x] for x in df[name]]\n    table = wandb.Table(data=dt, columns=[name])\n    wandb.log({name : wandb.plot.histogram(table, name, title=title)})\n\n    run.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(20,10))\nsns.kdeplot(train_df['target'], color=palette[0], shade=True,ax=ax[0])\nsns.kdeplot(train_df['standard_error'], color=palette[1], shade=True,ax=ax[1])\nax[0].axvline(train_df['target'].mean(), color=palette[0],linestyle=':', linewidth=2)\nax[1].axvline(train_df['standard_error'].mean(), color=palette[1],linestyle=':', linewidth=2)\nax[0].set_title(\"Target Distribution\",font=\"Serif\")\nax[1].set_title(\"Standard Error Distribution\",font=\"Serif\")\nax[0].annotate('mean', xy=(-0.3* np.pi, 0.2), xytext=(1, 0.2), font='Serif',\n            arrowprops=dict(arrowstyle=\"->\",\n                            connectionstyle=\"angle3,angleA=0,angleB=-90\"));\nax[1].annotate('mean', xy=(0.49, 6), xytext=(0.57, 6), font='Serif',\n            arrowprops=dict(arrowstyle=\"->\",\n                            connectionstyle=\"angle3,angleA=0,angleB=-90\"));\nplt.show()\n\nsns.jointplot(x=train_df['target'], y=train_df['standard_error'], kind='hex',height=10,edgecolor=palette[4])\nplt.suptitle(\"Target vs Standard error \",font=\"Serif\")\nplt.subplots_adjust(top=0.95)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logging **custom histograms** for target and standard error distribution üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"plot_wb_hist(train_df,\"target\",\"Target Distribution\")\nplot_wb_hist(train_df,\"standard_error\",\"Standard Error Distribution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logging a **dictionary of custom objects** üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"run = wandb.init(project='commonlit', name='count')\n\n# maximum target\nm_t = train_df[\"target\"].max() \n\n# minimum target\nl_t = train_df[\"target\"].min() \n\n# maximum standard error\nm_se = train_df[\"standard_error\"].max()\n\n# minimum standard error\nl_se = train_df[\"standard_error\"].min() \n\nwandb.log({'Target (highest value)': m_t, \n           'Target (lowest value)': l_t,\n           'Standard error (highest value)': m_se, \n           'Standard error (lowest value)': l_se\n          })\n\nrun.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nsns.countplot(y=\"license\",data=train_df,palette=\"BrBG\",linewidth=3)\nplt.title(\"License Distribution\",font=\"Serif\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logging a **custom bar chart** for license distribution üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"license_data = pd.DataFrame(train_df.license.value_counts().reset_index().values,columns=[\"license\", \"counts\"])\nplot_wb_bar(license_data,'license', 'counts',\"license\",\"License Distribution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top_n_words(corpus, n=None):\n    vec = CV().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ndef get_top_n_bigram(corpus, n=None):\n    vec = CV(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\n\ndef get_top_n_trigram(corpus, n=None):\n    vec = CV(ngram_range=(3, 3)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_bt(x,w,p):\n    common_words = x(train_df['excerpt_preprocessed'], 20)\n    common_words_df = DataFrame (common_words,columns=['word','freq'])\n\n    plt.figure(figsize=(16,8))\n    sns.barplot(x='freq', y='word', data=common_words_df,facecolor=(0, 0, 0, 0),linewidth=3,edgecolor=sns.color_palette(p,20))\n    plt.title(\"Top 20 \"+ w,font='Serif')\n    plt.xlabel(\"Frequency\", fontsize=14)\n    plt.yticks(fontsize=13)\n    plt.xticks(rotation=45, fontsize=13)\n    plt.ylabel(\"\");\n    return common_words_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_words = get_top_n_words(train_df['excerpt_preprocessed'], 20)\ncommon_words_df1 = DataFrame(common_words,columns=['word','freq'])\nplt.figure(figsize=(16, 8))\nax = sns.barplot(x='freq', y='word', data=common_words_df1,facecolor=(0, 0, 0, 0),linewidth=3,edgecolor=sns.color_palette(\"ch:start=3, rot=.1\",20))\n\nplt.title(\"Top 20 unigrams\",font='Serif')\nplt.xlabel(\"Frequency\", fontsize=14)\nplt.yticks(fontsize=13)\nplt.xticks(rotation=45, fontsize=13)\nplt.ylabel(\"\");\n\ncommon_words_df2 = plot_bt(get_top_n_bigram,\"bigrams\",\"ch:rot=-.5\")\ncommon_words_df3 = plot_bt(get_top_n_trigram,\"trigrams\",\"ch:start=-1, rot=-.6\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logging **custom bar charts** for unigrams, bigrams and trigrams üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"plot_wb_bar(common_words_df1,'word','freq',\"unigrams\",\"Top 20 unigrams\")\nplot_wb_bar(common_words_df2,'word','freq',\"bigrams\",\"Top 20 bigrams\")\nplot_wb_bar(common_words_df3,'word','freq',\"trigrams\",\"Top 20 trigrams\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# color function for the wordcloud\ndef color_wc(word=None,font_size=None,position=None, orientation=None,font_path=None, random_state=None):\n    h = int(360.0 * 150.0 / 255.0)\n    s = int(100.0 * 255.0 / 255.0)\n    l = int(100.0 * float(random_state.randint(80, 120)) / 255.0)\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\nplt.subplots(figsize=(16,16))\nwc = WordCloud(stopwords=STOPWORDS,background_color=\"white\", contour_width=2, contour_color='blue',width=1500, height=750,color_func=color_wc,max_words=150, max_font_size=256,random_state=42)\nwc.generate(' '.join(train_df['excerpt_preprocessed']))\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_props = train_df.copy()\n\ndef avg_word_len(df):\n    df = df.str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x))\n    return df\n\ntext_len = train_df['excerpt'].str.len()\ntext_len_pre = train_df['excerpt_preprocessed'].str.len()\navg_text = avg_word_len(train_df['excerpt'])\navg_text_pre = avg_word_len(train_df['excerpt_preprocessed'])\nlexicon_count = []\nlexicon_count_pre = []\nsentence_count = []\nfor i in range(len(train_df)):\n    lc = textstat.lexicon_count(train_df['excerpt'][i])\n    lcp = textstat.lexicon_count(train_df['excerpt_preprocessed'][i])\n    sc = textstat.sentence_count(train_df['excerpt'][i])\n    lexicon_count.append(lc)\n    lexicon_count_pre.append(lcp)\n    sentence_count.append(sc)\n    \ntext_props['text_len'] = text_len\ntext_props['text_len_pre'] = text_len_pre\ntext_props['lexicon_count'] = lexicon_count\ntext_props['lexicon_count_pre'] = lexicon_count_pre\ntext_props['avg_text'] = avg_text\ntext_props['avg_text_pre'] = avg_text_pre\ntext_props['sentence_count'] = sentence_count\n\ndef plot_distribution(col1,col2,title1,title2):\n    fig, ax = plt.subplots(1,2,figsize=(20,10))\n    sns.kdeplot(data=text_props, x=col1,color=palette[3],label=\"Excerpt\",ax=ax[0])\n    sns.kdeplot(data=text_props, x=col2,color=palette[4],label=\"Excerpt preprocessed\",ax=ax[0])\n    ax[0].set_title(title1,font=\"Serif\")\n\n    sns.scatterplot(data=text_props,x=col1,y='target',color= palette[3],ax=ax[1],markers='.')\n    sns.scatterplot(data=text_props,x=col2,y='target',color= palette[4],ax=ax[1],markers='.')\n    ax[1].set_title(title2,font=\"Serif\")\n\n    plt.show()\n\ncustom_lines = [Line2D([0], [0], color=palette[3], lw=4),\n                Line2D([0], [0], color=palette[4], lw=4)]\n\nplt.figure(figsize=(20, 1))\nlegend = plt.legend(custom_lines, ['Excerpt', 'Excerpt preprocessed'],loc=\"center\")\nplt.setp(legend.texts, family='Serif')\nplt.axis('off')\nplt.show()\n\nplot_distribution(\"text_len\",\"text_len_pre\",\"Character count distribution\",\"Character count vs Target\")\nplot_distribution(\"lexicon_count\",\"lexicon_count_pre\",\"Word count distribution\",\"Word count vs Target\")\nplot_distribution(\"avg_text\",\"avg_text_pre\", \"Average word length distribution\",\"Average word length vs Target\")\n\nfig, ax = plt.subplots(1,2,figsize=(20,10))\nsns.kdeplot(data=text_props, x=sentence_count,color=palette[3],label=\"Excerpt\",ax=ax[0])\nax[0].set_title(\"Sentence count distribution\",font=\"Serif\")\nax[0].set_xlabel(\"sentence_count\")\nsns.scatterplot(data=text_props,x='sentence_count',y='target',color= palette[3],ax=ax[1],markers='.')\nax[1].set_title(\"Sentence count vs Target\",font=\"Serif\")\nplt.show()\n\nnum_cols = ['text_len','text_len_pre','lexicon_count','lexicon_count_pre','avg_text','avg_text_pre','sentence_count','target']\ncorr = text_props[num_cols].corr()\n\nfig = plt.figure(figsize=(12,12),dpi=80)\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, mask=mask, cmap='BuPu', robust=True, center=0,\n            square=True, linewidths=.5)\nplt.title('Correlation of text properties', fontsize=15,font=\"Serif\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå ```sentence_count``` and ```target``` are very highly correlated since extremely long sentences can be complex to read and understand.","metadata":{}},{"cell_type":"markdown","source":"Logging **custom histograms** for the distribution of character count, word count, average word length and sentence count üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"plot_wb_hist(text_props,\"text_len\",\"Character Count Distribution\")\nplot_wb_hist(text_props,\"lexicon_count\",\"Word Count Distribution\")\nplot_wb_hist(text_props,\"avg_text\",\"Average Word Length Distribution\")\nplot_wb_hist(text_props,\"sentence_count\",\"Sentence Count Distribution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part-of-Speech tagging üè∑Ô∏è","metadata":{}},{"cell_type":"code","source":"text_props['pos_tags'] = text_props['excerpt_preprocessed'].str.split().map(pos_tag)\n\ndef count_tags(pos_tags):\n    tag_count = {}\n    for word,tag in pos_tags:\n        if tag in tag_count:\n            tag_count[tag] += 1\n        else:\n            tag_count[tag] = 1\n    return tag_count\n\ntext_props['tag_counts'] = text_props['pos_tags'].map(count_tags)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_pos = set([tag for tags in text_props['tag_counts'] for tag in tags])\ntag_cols = list(set_pos)\n\nfor tag in tag_cols:\n    text_props[tag] = text_props['tag_counts'].map(lambda x: x.get(tag, 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"| Abbreviation    | Meaning                                              |\n|-----------------|------------------------------------------------------|\n| CC              | coordinating conjunction                             |\n| CD              | cardinal digit                                       |\n| DT              | determiner                                           |\n| EX              | existential there                                    |\n| FW              | foreign word                                         |\n| IN              | preposition/subordinating conjunction                |\n| JJ              | adjective (large)                                    |\n| JJR             | adjective, comparative (larger)                      |\n| JJS             | adjective, superlative (largest)                     |\n| LS              | list item marker                                     |\n| MD              | modal (could, will)                                  |\n| NN              | noun, singular                                       |\n| NNS             | noun plural                                          |\n| NNP             | proper noun, singular                                |\n| NNPS            | proper noun, plural                                  |\n| PDT             | predeterminer                                        |\n| POS             | possessive ending (parent\\ 's)                       |\n| PRP             | personal pronoun (hers, herself, him,himself)        |\n| PRP dollar-sign | possessive pronoun (her, his, mine, my, our )        |\n| RB              | adverb (occasionally, swiftly)                       |\n| RBR             | adverb, comparative (greater)                        |\n| RBS             | adverb, superlative (biggest)                        |\n| RP              | particle (about)                                     |\n| SYM             | symbol                                               |\n| TO              | infinite marker (to)                                 |\n| UH              | interjection (goodbye)                               |\n| VB              | verb (ask)                                           |\n| VBG             | verb gerund (judging)                                |\n| VBD             | verb past tense (pleaded)                            |\n| VBN             | verb past participle (reunified)                     |\n| VBP             | verb, present tense not 3rd person singular(wrap)    |\n| VBZ             | verb, present tense with 3rd person singular (bases) |\n| WDT             | wh-determiner (that, what)                           |\n| WP              | wh- pronoun (who)                                    |\n| WP dollar-sign  | possessive wh-pronoun                                |\n| WRB             | wh- adverb (how)                                     |\n\nüìå Higher the grade, more the complexity of grammar(?)\n\n[Penn Part of Speech Tags](https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html)","metadata":{}},{"cell_type":"code","source":"pos = text_props[tag_cols].sum().sort_values(ascending = False)\nplt.figure(figsize=(16,10))\nax = sns.barplot(x=pos.index, y=pos.values,palette=\"Wistia\")\nplt.xticks(rotation = 50)\nax.set_yscale('log')\nplt.title('POS tags frequency',fontsize=15,font=\"Serif\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logging a **custom bar chart** for POS distribution üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"pos_data = pd.DataFrame({'part_of_speech':pos.index, 'freq':pos.values})\nplot_wb_bar(pos_data,'part_of_speech', 'freq',\"POS\",\"POS tags frequency\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.scatterplot(data=text_props,x='NN',y='target',color= palette[3],markers='.',label=\"noun, singular\")\nsns.scatterplot(data=text_props,x='JJ',y='target',color= palette[4],markers='.',label=\"adjective\",)\nsns.scatterplot(data=text_props,x='VBD',y='target',color= palette[0],markers='.',label=\"verb past tense\")\nsns.scatterplot(data=text_props,x='RB',y='target',color= palette[1],markers='.',label=\"adverb\")\nplt.legend(title=\"POS tag\",bbox_to_anchor=(1.4, 1))\nplt.xlabel(\"POS tags count\")\nplt.title(\"POS vs Target\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"toughest_excerpt = text_props[text_props[\"target\"] == text_props[\"target\"].min()].excerpt.values[0]\nlowest_target = text_props[text_props[\"target\"] == text_props[\"target\"].min()].target.values[0]\nnlp = spacy.load(\"en_core_web_sm\")\nsentences = sent_tokenize(toughest_excerpt)\nword_count = lambda sentence: len(word_tokenize(sentence))\npos_text = max(sentences, key=word_count)  \n\nconsole.print(\"Target of the toughest excerpt: \",style=\"info\")\nconsole.print(lowest_target,style='warning')\n\nconsole.print(\"Longest sentence of the toughest excerpt: \",style=\"info\")","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(pos_text)\ndisplacy.render(doc, style=\"dep\")","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Readability tests üß™\n\n[textstat](https://pypi.org/project/textstat/) is a library used to calculate statistics from text.\nIt came in super handy for calculating scores of various readability tests!\n\n- ```flesch_re:``` [The Flesch Reading Ease formula](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch_reading_ease)\n- ```flesch_kg:``` [The Flesch-Kincaid Grade Level ](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch_reading_ease)\n- ```fog_scale:``` [The Fog Scale (Gunning FOG Formula)](https://en.wikipedia.org/wiki/Gunning_fog_index)\n- ```automated_r:``` [Automated Readability Index](https://en.wikipedia.org/wiki/Automated_readability_index)\n- ```coleman:``` [The Coleman-Liau Index](https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index)\n- ```linsear:``` [Linsear Write Formula](https://en.wikipedia.org/wiki/Linsear_Write)\n- ```text_standard:``` Readability Consensus based upon all the above tests","metadata":{}},{"cell_type":"code","source":"# flesch_re, flesch_kg, fog_scale, automated_r,coleman, linsear, text_standard  = ([] for i in range(7))\n# for i in range(len(text_props)):\n#     flr = textstat.flesch_reading_ease(train_df['excerpt'][i])\n#     flkg = textstat.flesch_kincaid_grade(train_df['excerpt'][i])\n#     fs = textstat.gunning_fog(train_df['excerpt'][i])\n#     ar = textstat.automated_readability_index(train_df['excerpt'][i])\n#     cole = textstat.coleman_liau_index(train_df['excerpt'][i])\n#     lins = textstat.linsear_write_formula(train_df['excerpt'][i])\n#     ts = textstat.text_standard(train_df['excerpt'][i])\n    \n#     flesch_re.append(flr)\n#     flesch_kg.append(flkg)\n#     fog_scale.append(fs)\n#     automated_r.append(ar)\n#     coleman.append(cole)\n#     linsear.append(lins)\n#     text_standard.append(ts)\n    \n# text_props['flesch_re'] = flesch_re\n# text_props['flesch_kg'] = flesch_kg\n# text_props['fog_scale'] = fog_scale\n# text_props['automated_r'] = automated_r\n# text_props['coleman'] = coleman\n# text_props['linsear'] = linsear\n# text_props['text_standard'] = text_standard","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logging the text properties dataset as an **artifact** üèãÔ∏è‚Äç‚ôÄÔ∏è\n\nThis helps me to save on time since I can directly use the saved artifact for my workflow ü•≥","metadata":{}},{"cell_type":"code","source":"# #====== Saving to csv files and creating artifacts ======\n# text_props.to_csv(\"text_props_readability.csv\")\n\n# run = wandb.init(project='commonlit', name='text_props_readability')\n\n# artifact = wandb.Artifact('text_props_readability', type='dataset')\n\n# #====== Add a file to the artifact's contents ======\n# artifact.add_file(\"text_props_readability.csv\")\n\n# #====== Save the artifact version to W&B and mark it as the output of this run ====== \n# run.log_artifact(artifact)\n\n# run.finish()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A snapshot of the newly created artifacts ‚¨áÔ∏è\n\n<img src=\"https://i.imgur.com/WFeQRt7.png\">","metadata":{}},{"cell_type":"markdown","source":"Since I have already logged the artifact, I can directly use it in this manner ‚¨áÔ∏è","metadata":{}},{"cell_type":"code","source":"run = wandb.init(project='commonlit')\nartifact = run.use_artifact('ruchi798/commonlit/text_props_readability:v0', type='dataset')\nartifact_dir = artifact.download()\nrun.finish()\n\npath = os.path.join(artifact_dir,\"text_props_readability.csv\")\ntext_props = pd.read_csv(path)\ntext_props = text_props.drop(columns=[\"Unnamed: 0\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"readability_cols = ['flesch_re','flesch_kg','fog_scale','automated_r','coleman','linsear','text_standard','target']\n\ncorr = text_props[readability_cols].corr()\nfig = plt.figure(figsize=(12,12),dpi=80)\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, mask=mask, cmap='PuBuGn', robust=True, center=0,\n            square=True, linewidths=.5,annot=True)\nplt.title('Correlation of readability tests', fontsize=15,font=\"Serif\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a strong correlation between our ```target``` variable and the ```Flesch Readability Ease``` test values.\n\nLet's explore the distribution of test values for ```Flesch Readability Ease```.\n\n| Score          | Notes                                                                  |\n|----------------|------------------------------------------------------------------------|\n| 90-100         | very easy to read, easily understood by an average 11-year-old student |\n| 80-90          | easy to read                                                           |\n| 70-80          | fairly easy to read                                                    |\n| 60-70          | easily understood by 13- to 15-year-old students                       |\n| 50-60          | fairly difficult to read                                               |\n| 30-50          | difficult to read, best understood by college graduates                |\n| 0-30           | very difficult to read, best understood by university graduates        |","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.kdeplot(text_props[\"flesch_re\"],color=palette[4],shade=True)\nplt.title(\"Distribution of Flesch Reading Ease test\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logging a **custom histogram** for the distribution of Flesch Reading Ease scores üèãÔ∏è‚Äç‚ôÄÔ∏è","metadata":{}},{"cell_type":"code","source":"plot_wb_hist(text_props,\"flesch_re\",\"Flesch Reading Ease Distribution\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"üìå More than **70%** of excerpts can be easily understood by **13-15 year olds**.","metadata":{}},{"cell_type":"code","source":"text_props.loc[text_props['flesch_re'] > 60]['flesch_re'].count() / len(text_props) *100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see which excerpts have the highest and lowest ```Target``` and ```Flesch Reading Ease Score``` ‚¨áÔ∏è","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\nmax_text = text_props[text_props[\"target\"] == text_props[\"target\"].max()]['excerpt']\nmin_text = text_props[text_props[\"target\"] == text_props[\"target\"].min()]['excerpt']\n\nmax_text_f = text_props[text_props[\"flesch_re\"] == text_props[\"flesch_re\"].max()]['excerpt']\nmin_text_f = text_props[text_props[\"flesch_re\"] == text_props[\"flesch_re\"].min()]['excerpt']\n\nconsole.print(\"Highest Target\", style=\"danger\")\nconsole.print(max_text, style=\"info\")\ntext_props[text_props[\"target\"] == text_props[\"target\"].max()][['flesch_re','target','text_standard']]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"console.print(\"Highest Flesch Reading Ease Score\", style=\"danger\")\nconsole.print(max_text_f, style=\"info\")\ntext_props[text_props[\"flesch_re\"] == text_props[\"flesch_re\"].max()][['flesch_re','target','text_standard']]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"console.print(\"Lowest Target\", style=\"danger\")\nconsole.print(min_text, style=\"warning\")\ntext_props[text_props[\"target\"] == text_props[\"target\"].min()][['flesch_re','target','text_standard']]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"console.print(\"Lowest Flesch Reading Ease Score\", style=\"danger\")\nconsole.print(min_text_f, style=\"warning\")\ntext_props[text_props[\"flesch_re\"] == text_props[\"flesch_re\"].min()][['flesch_re','target','text_standard']]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline model ‚öôÔ∏è","metadata":{}},{"cell_type":"code","source":"def training(model, X_train, y_train, X_test, y_test, model_name):\n    t1 = time.time()\n    \n    model = make_pipeline(\n        TfidfVectorizer(binary=True, ngram_range=(1,1)),\n        model,\n    )\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    MSE = mse(y_test, y_pred)\n    \n    t2 = time.time()\n    training_time = t2-t1 \n    \n    console.print(\"--- Model:\", model_name,\"---\",style='warning')\n    console.print(\"MSE: \",MSE,style='danger')\n    console.print(\"Training time:\",training_time,style='danger')\n\nridge = Ridge(fit_intercept = True, normalize = False)\nlr = LinearRegression()\nm = [ridge,lr]\nmn = [\"Ridge Regression\",\"Linear Regression\"]\n\nX = train_df[\"excerpt_preprocessed\"]\ny = train_df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nfor i in range(0,len(m)):\n    training(model=m[i], X_train=X_train, y_train=y_train, X_test=X_test,y_test=y_test, model_name=mn[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_all(model,X,y):\n    \n    model = make_pipeline(\n        TfidfVectorizer(binary=True, ngram_range=(1,1)),\n        model,\n    )\n    model.fit(X, y)\n    y_pred = model.predict(test_df[\"excerpt_preprocessed\"])\n    \n    return y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission file üìù","metadata":{}},{"cell_type":"code","source":"test_pred = training_all(lr,X,y)\npredictions = pd.DataFrame()\npredictions['id'] = test_df['id']\npredictions['target'] = test_pred\npredictions.to_csv(\"/kaggle/working/submission.csv\", index=False)\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's a snapshot of my [project](https://wandb.ai/ruchi798/commonlit?workspace=user-ruchi798) ‚¨áÔ∏è\n\n<img src=\"https://i.imgur.com/vmxri2T.png\">","metadata":{}},{"cell_type":"markdown","source":"Illustrations tools ‚ö°\n\n- [Canva](https://www.canva.com/) üñåÔ∏è\n\n<img src=\"https://i.imgur.com/pl3FhXV.png\">","metadata":{}}]}