{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 2- Learning ðŸ¤—  - Out-of-the-box RoBERTa [LB: 0.53]\n\nHi, and welcome! This is the second kernel of the series `Learning ðŸ¤—`, a personal project I'm currently working on. I am an experienced data scientist diving into the hugging face transformers library and this series or kernels is a \"working diary\", as I do it. The approach I'm taking is the following: \n1. Explore various out-of-the-box models, without digging into their technical details. \n2. After that, I'll start going over the best ranked public kernels, understand their ideas, and reproduce them by myself. \n\nYou are invited to follow me in this journey. In this short kernel  we fine-tune an out-of-the-box cased RoBERTa, with just the minimal set up required for it to run in this competition, obtaining a leaderboard score of `0.53`. \n\n\nThis is an ongoing project, so expect more notebooks to be added to the series soon. Actually, we are currently working on the following ones:\n\n\n1. [Learning ðŸ¤—  - Out-of-the-box BERT [LB: 0.577]](https://www.kaggle.com/julian3833/1-learning-out-of-the-box-bert-lb-0-577)\n2. [Learning ðŸ¤— - Out-of-the-box RoBERTa [LB: 0.53]](https://www.kaggle.com/julian3833/2-learning-out-of-the-box-roberta-lb-0-53) (this notebook)\n3. [Learning ðŸ¤— - Out-of-the-box Electra [LB: 0.58]](https://www.kaggle.com/julian3833/3-learning-out-of-the-box-electra-lb/) \n4. _Learning ðŸ¤— - Minimal fine tuning (WIP)_\n5. _Learning ðŸ¤— - Preprocessing (WIP)_\n6. _Learning ðŸ¤— - Reviewing public kernels (WIP)_\n7. _Learning ðŸ¤— - Intra-domain pre training RoBERTa (WIP)_\n\n\n\n## This notebook\n\nThe code below is just a copy of the code in [1- Learning ðŸ¤—  - Out-of-the-box BERT [LB: 0.577]](https://www.kaggle.com/julian3833/1-learning-out-of-the-box-bert-lb-0-577) with just 2 changes, which are the following ones. Refer to that notebook for a more detailed description of the process and a more verbose, commented code.","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = \"../input/huggingface-roberta-variants/roberta-base/roberta-base\"\nEPOCHS = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We had imported [Huggingface Roberta Variants](https://www.kaggle.com/sauravmaheshkar/huggingface-roberta-variants) instead of BERT this time.\nAnd we are using 1 epoch because this is what gave better results (compared against 3).\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n\ndef load_dfs():\n    train_csv = '../input/commonlitreadabilityprize/train.csv'\n    test_csv = '../input/commonlitreadabilityprize/test.csv'\n    df_train = pd.read_csv(train_csv)[[\"excerpt\", \"target\"]].rename(columns={\"target\": \"label\", \"excerpt\": \"text\"})\n    df_test = pd.read_csv(test_csv)[[\"id\", \"excerpt\"]].rename(columns={ \"excerpt\": \"text\"})\n    return df_train, df_test\n\ndef rmse(y_true, y_pred): return np.sqrt(((y_true - y_pred) ** 2).mean().item())\n    \ndef compute_metrics(pred_results):\n    y_pred = pred_results.predictions.squeeze()\n    y_true = pred_results.label_ids\n    return {\"rmse\": rmse(y_true, y_pred)}\n\ndef submit(trainer, ds_test):\n    sample_sub_csv = '../input/commonlitreadabilityprize/sample_submission.csv'\n    pred_csv = '/kaggle/working/submission.csv'\n    pred_results = trainer.predict(ds_test)\n    y_pred = pred_results.predictions.squeeze()\n    df_res = pd.read_csv(sample_sub_csv)\n    df_res['target'] = y_pred.tolist()\n    df_res.to_csv(pred_csv, index=False)\n\ndef tokenize(tokenizer, df_train, df_val, df_test):    \n    train_tokenized = tokenizer(df_train['text'].tolist(), padding=\"max_length\", truncation=True, max_length=512)\n    val_tokenized = tokenizer(df_val['text'].tolist(), padding=\"max_length\", truncation=True, max_length=512)\n    test_tokenized = tokenizer(df_test['text'].tolist(), padding=\"max_length\", truncation=True, max_length=512)\n    train_tokenized['label'] = df_train['label'].tolist()\n    val_tokenized['label'] = df_val['label'].tolist()\n    ds_train = [dict(zip(train_tokenized,t)) for t in zip(*train_tokenized.values())]\n    ds_val = [dict(zip(val_tokenized,t)) for t in zip(*val_tokenized.values())]\n    ds_test = [dict(zip(test_tokenized,t)) for t in zip(*test_tokenized.values())]\n    return ds_train, ds_val, ds_test\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1)\ndf_base, df_test = load_dfs()\ndf_train, df_val = train_test_split(df_base, test_size=0.066)\nds_train, ds_val, ds_test = tokenize(tokenizer, df_train, df_val, df_test)\nargs = TrainingArguments(\"/kaggle/working/model/\", num_train_epochs=EPOCHS, \n                         evaluation_strategy=\"steps\", eval_steps=100, report_to=\"none\")\ntrainer = Trainer(model=model, args=args, train_dataset=ds_train, eval_dataset=ds_val, \n                  compute_metrics=compute_metrics)\ntrainer.train()\nsubmit(trainer, ds_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ðŸ¤—ðŸ¤— Thanks for reading this notebook! Remember to upvote if you found it useful, and stay tuned for the next deliveries! ðŸ¤—ðŸ¤—","metadata":{}}]}