{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## CommonLit Readability - Baseline","metadata":{}},{"cell_type":"markdown","source":"In this competition, we're predicting the reading ease of excerpts from literature - readability score. Text readability is best defined as the ease with which a text can be read and understood in terms of the linguistic features found within a text. So the task is to build algorithms to rate the complexity of reading passages for grade 3-12 classroom use.\n\nThis post can be viewed as a continuation of my previous notebook here - https://www.kaggle.com/sharrpie/commonlit-readability-eda-fe-topic-modelling. I'd highly recommend you take a look at it to make the most out of this notebook.\nIn this post, we would primarily consolidate all the observations drawn from EDA and build up on it by developing a baseline for readability score prediction. So without further deviation, let's get started! And while doing so, we focus on writing clean and reusable code whose components you can plug in directly in other competitions. Code inspirations from the great @abhishekthakur! Entire structured code can be found at: https://github.com/SharvilN/Common-Readability-Prize","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install textacy --no-index --find-links=file:///kaggle/input/textacy/textacy > /dev/null\n!pip install ../input/spacy-3-1-0/dist/en_core_web_lg-3.1.0.tar > /dev/null","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport os\nimport spacy\nimport joblib\nimport textacy\nimport collections\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\n\nfrom enum import Enum, auto\nfrom typing import List, Optional\n\nfrom textacy import preprocessing\nfrom textacy import text_stats\nfrom textacy.text_stats import readability\n\nfrom sklearn import metrics\nfrom sklearn import ensemble\nfrom sklearn import linear_model\nfrom sklearn import pipeline\nfrom sklearn import decomposition\nfrom sklearn import preprocessing as skpreprocessing\nfrom sklearn import svm\nfrom sklearn import model_selection","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-18T19:53:34.969992Z","iopub.execute_input":"2021-07-18T19:53:34.970717Z","iopub.status.idle":"2021-07-18T19:53:46.747154Z","shell.execute_reply.started":"2021-07-18T19:53:34.970651Z","shell.execute_reply":"2021-07-18T19:53:46.745988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Preprocessor","metadata":{}},{"cell_type":"code","source":"class TextPreprocessor:\n\n    def __init__(self, pipelines: List, remove_chars: Optional[List] = None):\n        self.pipelines = list()\n        if \"unicode\" in pipelines: self.pipelines.append(preprocessing.normalize.unicode)\n        if \"whitespace\" in pipelines: self.pipelines.append(preprocessing.normalize.whitespace)\n        self.preprocessor = preprocessing.make_pipeline(*self.pipelines)\n\n        self.remove_chars = remove_chars\n\n    def run(self, text):\n        for pattern in self.remove_chars:\n            text = re.sub(pattern, ' ', text)\n        text = self.preprocessor(text)\n        return text","metadata":{"execution":{"iopub.status.busy":"2021-07-18T19:53:46.749227Z","iopub.execute_input":"2021-07-18T19:53:46.749811Z","iopub.status.idle":"2021-07-18T19:53:46.758237Z","shell.execute_reply.started":"2021-07-18T19:53:46.749745Z","shell.execute_reply":"2021-07-18T19:53:46.757155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Generator","metadata":{}},{"cell_type":"code","source":"class FeatureGenerator:\n\n    def __init__(self, df: pd.DataFrame, spacy_model=None, preprocess: bool=True) -> None:\n        self.raw = df\n        self.output = self.raw.copy(deep=True)\n        self.nlp = spacy_model\n        self.preprocess = preprocess\n\n    def extract_features(self):\n        if self.preprocess: self._preprocess()\n        self._extract_traditional_features()\n        self._extract_syntatic_features()\n        self._extract_pos_tag_features()\n        self._spacy_vectors()\n\n        return self.output\n\n    def _preprocess(self):\n        print('Preprocessing data...')\n        preprocessor = TextPreprocessor(pipelines=[\"unicode\", \"whitespace\"], \n                                       remove_chars = [\"\\n\"])\n        self.raw.loc[:, 'preprocessed_excerpt'] = self.raw['excerpt'].apply(preprocessor.run)\n        self.output.loc[:, 'preprocessed_excerpt'] = self.raw['preprocessed_excerpt']\n\n    def _extract_traditional_features(self):\n\n        def n_longest_sent(doc) -> int:\n            return max([len(sent) for sent in list(doc.sents)])\n\n        print('Extracting traditional features...')\n        for idx, row in self.raw.iterrows():\n            doc = textacy.make_spacy_doc(row['preprocessed_excerpt'], lang='en_core_web_lg')\n            ts = text_stats.TextStats(doc)\n            self.output.loc[idx, 'n_sents'] = ts.n_sents                \n            self.output.loc[idx, 'n_words'] = ts.n_words                \n            self.output.loc[idx, 'n_words_per_sent'] = ts.n_words / ts.n_sents             \n            self.output.loc[idx, 'n_unique_words'] = ts.n_unique_words\n            self.output.loc[idx, 'n_unique_words_per_sent'] = ts.n_unique_words / ts.n_sents\n            self.output.loc[idx, 'n_chars_per_word'] = ts.n_chars / ts.n_words\n            self.output.loc[idx, 'n_syllables'] = ts.n_syllables\n            self.output.loc[idx, 'n_syllables_per_word'] = ts.n_syllables / ts.n_words\n            self.output.loc[idx, 'n_syllables_per_sent'] = ts.n_syllables / ts.n_sents\n            self.output.loc[idx, 'n_monosyllable_words'] = ts.n_monosyllable_words\n            self.output.loc[idx, 'n_polysyllable_words'] = ts.n_polysyllable_words\n            self.output.loc[idx, 'n_long_words'] = ts.n_long_words\n            self.output.loc[idx, 'n_long_words_ratio'] = ts.n_long_words / ts.n_words\n            self.output.loc[idx, 'entropy'] = ts.entropy\n            self.output.loc[idx, 'n_longest_sent'] = n_longest_sent(doc)\n\n            self.output.loc[idx, 'automated_readability_index'] \\\n                = readability.automated_readability_index(ts.n_chars, ts.n_words, ts.n_sents)\n            self.output.loc[idx, 'coleman_liau_index'] \\\n                = readability.coleman_liau_index(ts.n_chars, ts.n_words, ts.n_sents)\n            self.output.loc[idx, 'flesch_kincaid_grade_level'] \\\n                = readability.flesch_kincaid_grade_level(ts.n_syllables, ts.n_words, ts.n_sents)\n            self.output.loc[idx, 'flesch_reading_ease'] \\\n                = readability.flesch_reading_ease(ts.n_syllables, ts.n_words, ts.n_sents)\n            self.output.loc[idx, 'lix'] \\\n                = readability.lix(ts.n_syllables, ts.n_long_words, ts.n_sents)\n            self.output.loc[idx, 'smog_index'] \\\n                = readability.smog_index(ts.n_polysyllable_words, ts.n_sents)\n            self.output.loc[idx, 'gunning_fog_index'] \\\n                = readability.gunning_fog_index(ts.n_words, ts.n_polysyllable_words, ts.n_sents)\n\n    def _extract_syntatic_features(self):\n        print('Extracting Syntactic features...')\n        def tree_height(root):\n            if not list(root.children):\n                return 1\n            else:\n                return 1 + max(tree_height(x) for x in root.children)\n\n        def get_average_height(paragraph):\n            doc = self.nlp(paragraph) if type(paragraph) == str else paragraph\n            roots = [sent.root for sent in doc.sents]\n            return np.mean([tree_height(root) for root in roots])\n\n        def count_subtrees(root):\n            if not list(root.children):\n                return 0\n            else:\n                return 1 + sum(count_subtrees(x) for x in root.children)\n\n        def get_mean_subtrees(paragraph):\n            doc = self.nlp(paragraph) if type(paragraph) == str else paragraph\n            roots = [sent.root for sent in doc.sents]\n            return np.mean([count_subtrees(root) for root in roots])\n\n        def get_averge_noun_chunks(paragraph):\n            doc = self.nlp(paragraph) if type(paragraph) == str else paragraph\n            return len(list(doc.noun_chunks))\n            \n        def get_noun_chunks_size(paragraph):\n            doc = self.nlp(paragraph) if type(paragraph) == str else paragraph\n            noun_chunks_size = [len(chunk) for chunk in doc.noun_chunks]\n            return np.mean(noun_chunks_size)\n        \n        self.output['avg_parse_tree_height'] = self.output.preprocessed_excerpt.apply(get_average_height)\n        self.output['mean_parse_subtrees'] = self.output.preprocessed_excerpt.apply(get_mean_subtrees)\n        self.output['noun_chunks'] = self.output.preprocessed_excerpt.apply(get_averge_noun_chunks)\n        self.output['noun_chunk_size'] = self.output.preprocessed_excerpt.apply(get_noun_chunks_size)\n        self.output['avg_noun_chunks'] = self.output['noun_chunks'] / self.output['n_sents']\n        self.output['mean_noun_chunk_size'] = self.output['noun_chunk_size'] / self.output['avg_noun_chunks']\n    \n    def _extract_pos_tag_features(self):\n        print('Extracting POS Tag features...')\n        def get_pos_freq_per_word(paragraph, tag):\n            doc = self.nlp(paragraph) if type(paragraph) == str else paragraph\n            pos_counter = collections.Counter(([token.pos_ for token in doc]))\n            pos_count_by_tag = pos_counter[tag]\n            total_pos_counts = sum(pos_counter.values())\n            return pos_count_by_tag / total_pos_counts\n\n        self.output['nouns_per_word'] = self.raw.preprocessed_excerpt.apply(lambda x: get_pos_freq_per_word(x, 'NOUN'))\n        self.output['proper_nouns_per_word'] = self.raw.preprocessed_excerpt.apply(lambda x: get_pos_freq_per_word(x, 'PROPN'))\n        self.output['pronouns_per_word'] = self.raw.preprocessed_excerpt.apply(lambda x: get_pos_freq_per_word(x, 'PRON'))\n        self.output['adj_per_word'] = self.raw.preprocessed_excerpt.apply(lambda x: get_pos_freq_per_word(x, 'ADJ'))\n        self.output['adv_per_word'] = self.raw.preprocessed_excerpt.apply(lambda x: get_pos_freq_per_word(x, 'ADV'))\n        self.output['verbs_per_word'] = self.raw.preprocessed_excerpt.apply(lambda x: get_pos_freq_per_word(x, 'VERB'))\n        self.output['cconj_per_word'] = self.raw.preprocessed_excerpt.apply(lambda x: get_pos_freq_per_word(x, 'CCONJ'))\n        self.output['sconj_per_word'] = self.raw.preprocessed_excerpt.apply(lambda x: get_pos_freq_per_word(x, 'SCONJ'))\n\n    def get_col_names(self, prefix: str, count: int):\n        return [f\"{prefix}_{i}\" for i in range(count)]\n\n    def _spacy_vectors(self):\n        print('Extracting Spacy vectors...')\n        with self.nlp.disable_pipes():\n            vectors = np.array([self.nlp(text).vector for text in self.output.preprocessed_excerpt])\n            cols = self.get_col_names('spacy', len(vectors[0]))\n            self.output[cols] = vectors","metadata":{"execution":{"iopub.status.busy":"2021-07-18T19:53:46.760325Z","iopub.execute_input":"2021-07-18T19:53:46.760653Z","iopub.status.idle":"2021-07-18T19:53:46.802761Z","shell.execute_reply.started":"2021-07-18T19:53:46.760624Z","shell.execute_reply":"2021-07-18T19:53:46.801617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\nfe = FeatureGenerator(df, spacy.load(\"en_core_web_lg\"))\ndf_features = fe.extract_features()\ndf_features.to_csv(\"./train_features.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T19:54:12.151078Z","iopub.execute_input":"2021-07-18T19:54:12.151473Z","iopub.status.idle":"2021-07-18T19:54:19.988318Z","shell.execute_reply.started":"2021-07-18T19:54:12.15144Z","shell.execute_reply":"2021-07-18T19:54:19.987418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross Validation Framework","metadata":{}},{"cell_type":"code","source":"class ProblemType(Enum):\n        BINARY = auto(),\n        MULTICLASS = auto(),\n        REGRESSION = auto(),\n        MULTI_COL_REGRESSION = auto(),\n        HOLDOUT = auto(),\n        MULTILABEL = auto()\n        \nclass CrossValidation:\n\n    def __init__(\n            self,\n            df,\n            target_cols,\n            shuffle,\n            problem_type,\n            holdout_pct=None,\n            n_folds=5,\n            multilabel_delimiter=',',\n            random_state=31\n        ):\n        self.df = df\n        self.target_cols = target_cols\n        self.n_targets = len(self.target_cols)\n        self.problem_type = problem_type\n        self.shuffle = shuffle\n        self.n_folds = n_folds\n        self.holdout_pct = holdout_pct\n        self.multilabel_delimiter = multilabel_delimiter\n        self.random_state = random_state\n\n        if self.shuffle is True:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n        self.df['kfold'] = -1\n\n    def split(self):\n        if self.problem_type in (ProblemType.BINARY, ProblemType.MULTICLASS):\n            if self.n_targets != 1:\n                raise Exception(f'Invalid number of targets {self.n_targets} for selected problem type: {self.problem_type}') \n            \n            target = self.target_cols[0]\n            kf = model_selection.StratifiedKFold(n_splits=self.n_folds)\n        \n            for fold, (train_idx, val_idx) in enumerate(kf.split(X=self.df, y=self.df[target].values)):\n                print(len(train_idx), len(val_idx))\n                self.df.loc[val_idx, 'kfold'] = fold\n\n        elif self.problem_type in (ProblemType.REGRESSION, ProblemType.MULTI_COL_REGRESSION):\n            if self.n_targets != 1 and self.problem_type == ProblemType.REGRESSION:\n                raise Exception(f'Invalid combination of number of targets {self.n_targets} and problem type {self.problem_type}')\n            if self.n_targets < 2 and self.problem_type == ProblemType.MULTI_COL_REGRESSION:\n                raise Exception(f'Invalid combination of number of targets {self.n_targets} and problem type {self.problem_type}')\n            \n            target = self.target_cols[0]\n\n            # calculate number of bins by Sturge's rule\n            # I take the floor of the value, you can also\n            # just round it\n            num_bins = int(np.floor(1 + np.log2(len(self.df))))\n            \n            # bin targets\n            self.df.loc[:, \"bins\"] = pd.cut(\n                self.df[\"target\"], bins=num_bins, labels=False\n            )\n            \n            # initiate the kfold class from model_selection module\n            kf = model_selection.StratifiedKFold(n_splits=self.n_folds)\n            \n            # fill the new kfold column\n            # note that, instead of targets, we use bins!\n            for fold, (train_idx, valid_idx) in enumerate(kf.split(X=self.df, y=self.df.bins.values)):\n                print(len(train_idx), len(valid_idx))\n                self.df.loc[valid_idx, 'kfold'] = fold\n            \n            # drop the bins column\n            self.df = self.df.drop(\"bins\", axis=1)\n\n        \n        elif self.problem_type == ProblemType.HOLDOUT:\n            holdout_pctg = self.holdout_pct\n            n_holdout_samples = int(len(self.df) * holdout_pctg / 100)\n            self.df.loc[:n_holdout_samples, 'kfold'] = 0\n            self.df.loc[n_holdout_samples: , 'kfold'] = 1\n            print(n_holdout_samples)\n\n        elif self.problem_type == ProblemType.MULTILABEL:\n            if self.n_targets != 1:\n                raise Exception(f'Invalid combination of number of targets {self.n_targets} and problem type {self.problem_type}')\n\n            targets = self.df[self.target_cols[0]].apply(lambda x: len(x.split(self.multilabel_delimiter)))\n            print(targets.value_counts())\n            kf = model_selection.StratifiedKFold(n_splits=self.n_folds)\n\n            for fold, (train_idx, valid_idx) in enumerate(kf.split(X=self.df, y=targets)):\n                print(len(train_idx), len(valid_idx))\n                self.df.loc[valid_idx, 'kfold'] = fold\n\n        else:\n            raise Exception(f'Invalid problem type found : {self.problem_type}')\n        return self.df","metadata":{"execution":{"iopub.status.busy":"2021-07-18T19:54:35.014019Z","iopub.execute_input":"2021-07-18T19:54:35.014411Z","iopub.status.idle":"2021-07-18T19:54:35.037627Z","shell.execute_reply.started":"2021-07-18T19:54:35.01438Z","shell.execute_reply":"2021-07-18T19:54:35.036651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Folds","metadata":{}},{"cell_type":"code","source":"def create_folds(data_path: str, output_path: str, target_cols: List[str], problem_type: ProblemType,  n_folds: Optional[int] = 5) -> None:\n\n    print(f'Target columns : {target_cols}')\n    print(f'Reading data from {data_path}')\n    df = pd.read_csv(data_path)\n    cv = CrossValidation(df,\n                        target_cols,\n                        n_folds=n_folds,\n                        shuffle=True,\n                        problem_type=problem_type)\n    \n    print(f'Generating folds...')\n    df_split = cv.split()\n    print(df_split.head())\n    print(df_split.tail())\n    print(df_split.groupby(by=['kfold'])['target'].median())\n\n    print(f'Saving train folds to {output_path}')\n    df_split.to_csv(output_path, index=False)\n\ncreate_folds(\"./train_features.csv\",\n             \"./trainfe_folds.csv\",\n             target_cols=[\"target\"],\n            problem_type=ProblemType.REGRESSION)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-18T19:54:36.407641Z","iopub.execute_input":"2021-07-18T19:54:36.408015Z","iopub.status.idle":"2021-07-18T19:54:36.984476Z","shell.execute_reply.started":"2021-07-18T19:54:36.407985Z","shell.execute_reply":"2021-07-18T19:54:36.982642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Dispatcher","metadata":{}},{"cell_type":"code","source":"MODELS = {\n    'RFR': ensemble.RandomForestRegressor(),\n    'ETR': ensemble.ExtraTreesRegressor(),\n    'RIDGE': linear_model.Ridge(alpha=0.5, solver='auto'),\n    'LASSO': linear_model.Lasso(normalize=True),\n    'OLS': linear_model.LinearRegression(normalize=True, fit_intercept=False),\n    'SVM': svm.SVR(),\n    'RIDGE_PIPE': pipeline.Pipeline([('poly', skpreprocessing.StandardScaler()),\n                 ('fit', linear_model.Ridge(alpha=1))]),\n    'LASSO_PIPE': pipeline.Pipeline([('poly', skpreprocessing.PolynomialFeatures()),\n                 ('fit', linear_model.Lasso())]),\n    'OLS_PIPE': pipeline.Pipeline([('poly', skpreprocessing.PolynomialFeatures()),\n                 ('fit', linear_model.LinearRegression())]),\n}\n\nPARAMS = {\n    'RIDGE_PIPE': {'fit__alpha':[550, 580, 600, 620, 650]},\n    'LASSO_PIPE': {'fit__alpha':[0.005, 0.02, 0.03, 0.05, 0.06]}\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"def rmse(targets, preds):\n    return np.sqrt(metrics.mean_squared_error(targets, preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(train_path, fold, store_model_at, model):\n    df = pd.read_csv(train_path)\n    train = df[df.kfold != fold]\n    val = df[df.kfold == fold]\n\n    ytrain = train.target.values\n    yval = val.target.values\n\n    cols_to_drop = ['id', 'url_legal', 'license', 'excerpt', 'standard_error', 'target', 'kfold',\n                   'preprocessed_excerpt']\n    xtrain = train.drop(cols_to_drop, axis=1)\n    xval = val.drop(cols_to_drop, axis=1)\n\n    regressor = MODELS[model]\n\n    regressor.fit(xtrain, ytrain)\n    preds = regressor.predict(xval)\n\n    rmse_loss = rmse(preds, yval)\n    print(f'Loss for fold={fold} : rmse={rmse_loss}')\n\n    joblib.dump(regressor, f'{store_model_at}/{model}_{fold}.pkl')\n    \n\ntrain(\"./trainfe_folds.csv\", 0, \".\", \"RIDGE\")\ntrain(\"./trainfe_folds.csv\", 1, \".\", \"RIDGE\")\ntrain(\"./trainfe_folds.csv\", 2, \".\", \"RIDGE\")\ntrain(\"./trainfe_folds.csv\", 3, \".\", \"RIDGE\")\ntrain(\"./trainfe_folds.csv\", 4, \".\", \"RIDGE\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\nfe_test = FeatureGenerator(test_df, spacy.load(\"en_core_web_lg\"))\ntest_features = fe_test.extract_features()\ntest_features.to_csv(\"./test_features.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(test_path: str, model_dir: str, model_prefix: str):\n    test_df = pd.read_csv(test_path)\n    cols_to_drop = ['id', 'url_legal', 'license', 'excerpt', 'preprocessed_excerpt']\n    test = test_df.drop(cols_to_drop, axis=1)\n\n    models = list()\n    for dirname, _, filenames in os.walk(model_dir):\n        for filename in filenames:\n            if model_prefix in filename:\n                models.append(joblib.load(os.path.join(dirname, filename)))\n\n    preds = [model.predict(test) for model in models]\n    preds = np.mean(preds, axis=0)\n    submission = pd.DataFrame({\"id\": test_df[\"id\"], \"target\": preds})\n    submission.to_csv(\"submission.csv\", index=False)\n\npredict(\"./test_features.csv\", \".\", \"RIDGE\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}