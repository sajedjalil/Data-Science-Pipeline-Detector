{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom transformers import TFAutoModelForSequenceClassification, AutoTokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def regular_encode(texts, tokenizer, max_len=256):\n    enc_di = tokenizer.batch_encode_plus(\n        texts,\n        return_attention_mask=True,\n        return_token_type_ids=False,\n        padding='max_length',\n        max_length=max_len,\n        truncation=True,\n    )\n\n    return {\n            \"input_ids\": np.array(enc_di[\"input_ids\"]),\n            \"attention_mask\": np.array(enc_di[\"attention_mask\"]),\n        }\n\ndef generate_predictions(model_path, max_len, file_name, x_column=\"excerpt\"):\n    model = TFAutoModelForSequenceClassification.from_pretrained(model_path, from_pt=True)\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n    df = pd.read_csv(file_name)\n    \n    dataset = regular_encode(df[x_column].tolist(), tokenizer=tokenizer, max_len=max_len)\n\n    input_ids = tf.keras.layers.Input((max_len,), dtype=tf.int32, name=\"input_ids\")\n    attention_mask = tf.keras.layers.Input((max_len,), dtype=tf.int32, name=\"attention_mask\")\n    output_layer = model(input_ids=input_ids, attention_mask=attention_mask)\n    reg_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output_layer)\n\n    final_output = reg_model.predict(dataset, verbose=1, batch_size=16)\n    final_output = sum(final_output.logits.tolist(), [])\n    \n    return np.array(final_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds1 = generate_predictions(\"../input/modelf1/\", max_len=256, file_name=\"../input/commonlitreadabilityprize/test.csv\")\npreds2 = generate_predictions(\"../input/modelf2/\", max_len=256, file_name=\"../input/commonlitreadabilityprize/test.csv\")\npreds3 = generate_predictions(\"../input/modelf3/\", max_len=256, file_name=\"../input/commonlitreadabilityprize/test.csv\")\npreds4 = generate_predictions(\"../input/modelf4/\", max_len=256, file_name=\"../input/commonlitreadabilityprize/test.csv\")\npreds5 = generate_predictions(\"../input/modelf5/\", max_len=256, file_name=\"../input/commonlitreadabilityprize/test.csv\")\npreds6 = generate_predictions(\"../input/a81657/\", max_len=256, file_name=\"../input/commonlitreadabilityprize/test.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_pos = [2.29301865e-08 ,9.18492143e-02 ,3.56011564e-01, 5.34926853e-09,\n 8.52853500e-02 ,4.66853844e-01]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = weights_pos\npreds = preds1*weights[0] + preds2*weights[1] + preds3*weights[2]+ preds4*weights[3] + preds5*weights[4]+ preds6*weights[5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = preds\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Original Notebook in Pytorch by @abhishek: Original Notebook: https://www.kaggle.com/abhishek/yum-yum-yum\n\nPublic Score: 0.488 ","metadata":{}}]}