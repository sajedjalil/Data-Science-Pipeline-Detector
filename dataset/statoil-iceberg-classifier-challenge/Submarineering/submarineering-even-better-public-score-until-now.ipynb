{"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","file_extension":".py"}},"cells":[{"metadata":{"_uuid":"2eb7adaeaf575bd8c68e24ce1ec940416aa9d3c9","_cell_guid":"71cd635b-4fb7-47a6-acfa-0eeec414216d"},"cell_type":"markdown","source":"<img src=\"https://lh3.googleusercontent.com/-tNe1vwwd_w4/VZ_m9E44C7I/AAAAAAAAABM/5yqhpSyYcCUzwHi-ti13MwovCb_AUD_zgCJkCGAYYCw/w256-h86-n-no/Submarineering.png\">"},{"metadata":{"_uuid":"dcb914ca72a621d46ad02e8e322ae4929c98d1fa","_cell_guid":"3eacba78-a0ec-4e1a-b230-8fdcc85936f0"},"cell_type":"markdown","source":"This is  **EVEN better the public score** kernel in the competition until now. \nI wanted strongly dedicate this kernel to that **scavenger colleagues** that spend the time tracking back the work of other members just to take chance and get any good idea only for his own benefit, but, however they don't share anything, just providing  bad comments for those who share with the best will and without breaking the rules.\n\nIf you do not feel alluded , **please VOTE me UP.**"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"518b490c58f98a59d25d8d5d8c39dca0673564e1","_cell_guid":"28a96b13-fb54-43af-aeb9-ccb40526ec1f"},"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd \nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"metadata":{"_uuid":"9db24b56f89561784a4118c9faf4aca6cfdaea3a","_cell_guid":"b4d21b76-54f0-42db-a60f-5cba96b239bd"},"cell_type":"markdown","source":"First thing first@\n# Credits to the following awesome authors and kernels\n\nAuthor: QuantScientist    \nFile: sub_200_ens_densenet.csv     \nLink: https://www.kaggle.com/solomonk/pytorch-cnn-densenet-ensemble-lb-0-1538     \n\n\nAuthor: wvadim     \nFile: sub_TF_keras.csv     \nLink: https://www.kaggle.com/wvadim/keras-tf-lb-0-18     \n\n\nAuthor: Ed Miller    \nFile: sub_fcn.csv    \nLink: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193     \n\n\nAuthor: Chia-Ta Tsai    \nFile: sub_blend009.csv    \nLink: https://www.kaggle.com/cttsai/ensembling-gbms-lb-203    \n\n\nAuthor: DeveshMaheshwari    \nFile: sub_keras_beginner.csv    \nLink: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d       \n\nAuthor: Submarineering    \n\nFiles: submission38.csv , submission43.csv\n\nLink : https://www.kaggle.com/submarineering/submission38-lb01448\n\n### Without their truly dedicated efforts, this notebook will not be possible.     "},{"metadata":{"_uuid":"aae1d396e2fad44a15fcb8e970c5affa8fb6ddc6","_cell_guid":"1840df41-7524-4305-93d9-423a2a6fe5bd"},"cell_type":"markdown","source":"# Data Load"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"da6c496f6bc0f2228a30da1cb31c50d2bbe33569","_cell_guid":"5cf037ae-98a4-44d5-92e6-090c3686e2df"},"cell_type":"code","source":"sub_path = \"../input/statoil-iceberg-submissions\"\nall_files = os.listdir(sub_path)\nall_files = all_files[1:3]\nall_files.append('submission38.csv')\nall_files.append('submission43.csv')\nall_files"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"1fa9dd2434873dc5bc918b102a3a69649d0f35c7","_cell_guid":"c978c838-8a87-45ef-a118-b6bd565bdb2e"},"cell_type":"code","source":"# Read and concatenate submissions\nout1 = pd.read_csv(\"../input/statoil-iceberg-submissions/sub_200_ens_densenet.csv\", index_col=0)\nout2 = pd.read_csv(\"../input/statoil-iceberg-submissions/sub_TF_keras.csv\", index_col=0)\nout3 = pd.read_csv(\"../input/submission38-lb01448/submission38.csv\", index_col=0)\nout4 = pd.read_csv(\"../input/submission38-lb01448/submission43.csv\", index_col=0)\nconcat_sub = pd.concat([out1, out2, out3, out4], axis=1)\ncols = list(map(lambda x: \"is_iceberg_\" + str(x), range(len(concat_sub.columns))))\nconcat_sub.columns = cols\nconcat_sub.reset_index(inplace=True)\nconcat_sub.head()\n"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"37b39229e34b71032d8d2371c6b731ed452b8eb2","_cell_guid":"a193cac9-e544-4749-8622-2c0a7d882193"},"cell_type":"code","source":"# check correlation\nconcat_sub.corr()"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"07cdbb447c11008557c1773e464d08f798d8b2b2","_cell_guid":"c7be9be8-b999-42d9-a0cc-6bf2a035b25b"},"cell_type":"code","source":"# get the data fields ready for stacking\nconcat_sub['is_iceberg_max'] = concat_sub.iloc[:, 1:6].max(axis=1)\nconcat_sub['is_iceberg_min'] = concat_sub.iloc[:, 1:6].min(axis=1)\nconcat_sub['is_iceberg_mean'] = concat_sub.iloc[:, 1:6].mean(axis=1)\nconcat_sub['is_iceberg_median'] = concat_sub.iloc[:, 1:6].median(axis=1)"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"d412b01db3dd513eef9158bfaaebe96617e79d5b","_cell_guid":"2b115d55-48f4-43c6-9b22-dbd8cd5a28a8"},"cell_type":"code","source":"# set up cutoff threshold for lower and upper bounds, easy to twist \ncutoff_lo = 0.8\ncutoff_hi = 0.2"},{"metadata":{"_uuid":"698574b4531ce5ec1c59d5afaf451392169af5e0","_cell_guid":"d0493bc1-1d92-4bc7-aa84-107fcb6d7324"},"cell_type":"markdown","source":"# Mean Stacking"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"a6642e2884dacc8c5095413e6a0945c6791ee1b5","_cell_guid":"f1169e63-b019-4a39-87b5-8fa1d0488f09"},"cell_type":"code","source":"#concat_sub['is_iceberg'] = concat_sub['is_iceberg_mean']\n#concat_sub[['id', 'is_iceberg']].to_csv('stack_mean.csv', index=False, float_format='%.6f')"},{"metadata":{"_uuid":"a24eecfd51f4f6665d751f3f1c126e46a44426bd","_cell_guid":"64a7aeea-ac14-4ae8-ac62-0c58b13c1f9e"},"cell_type":"markdown","source":"**LB 0.1698** , decent first try - still some gap comparing with our top-line model performance in stack."},{"metadata":{"_uuid":"d213635b179fc8d07a6985d257c8c3e0007e0f7a","_cell_guid":"103f2414-04a8-40bd-8ffc-4e77e510e023"},"cell_type":"markdown","source":"# Median Stacking"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"76fc5734615b45bf6234df1f450c9a24ca518834","_cell_guid":"9d5af2c0-1cc5-4adc-9153-d20d19c69bd6"},"cell_type":"code","source":"#concat_sub['is_iceberg'] = concat_sub['is_iceberg_median']\n#concat_sub[['id', 'is_iceberg']].to_csv('stack_median.csv', index=False, float_format='%.6f')"},{"metadata":{"_uuid":"a1a1754ba1c9ca956da71920dcc5bf2f0ee78172","_cell_guid":"3da1db01-1922-4d34-ae02-1d3acfa59fca"},"cell_type":"markdown","source":"**LB 0.1575**, very close with our top-line model performance, but we want to see some improvement at least."},{"metadata":{"_uuid":"caa0cb178c1f4921cb7c5b6552bfe4e0fb91475e","_cell_guid":"fba2a588-19a4-41fd-a495-af6a3a551777"},"cell_type":"markdown","source":"# PushOut + Median Stacking \n\nPushout strategy is a bit agressive given what it does..."},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"e6038b30485244cf144ede75fb3ecab55afa3f84","_cell_guid":"f8646a39-f2cc-483a-912b-46af12b5de64"},"cell_type":"code","source":"#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), 1, \n#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n#                                             0, concat_sub['is_iceberg_median']))\n#concat_sub[['id', 'is_iceberg']].to_csv('stack_pushout_median.csv', \n#                                        index=False, float_format='%.6f')"},{"metadata":{"_uuid":"ed7b3420cf44929c977970605c9c231714926e0e","_cell_guid":"f016ad2f-ddc9-4182-a288-32f4dcb466d3"},"cell_type":"markdown","source":"**LB 0.1940**, not very impressive results given the base models in the pipeline..."},{"metadata":{"_uuid":"9244a9d9ddce162fa7ddd7d32e271097b0b405df","_cell_guid":"26fa22e0-4f00-455b-8328-3e3cdf34adfb"},"cell_type":"markdown","source":"# MinMax + Mean Stacking\n\nMinMax seems more gentle and it outperforms the previous one given its peformance score."},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"4ffd0c65d59a03ee04d5452b853efac717f3f3f7","_cell_guid":"7634aaa4-2466-45b1-afbf-32dedb8691a4"},"cell_type":"code","source":"#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n#                                    concat_sub['is_iceberg_max'], \n#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n#                                             concat_sub['is_iceberg_min'], \n#                                             concat_sub['is_iceberg_mean']))\n#concat_sub[['id', 'is_iceberg']].to_csv('stack_minmax_mean.csv', \n#                                        index=False, float_format='%.6f')"},{"metadata":{"_uuid":"c4da0e0b2530daf4fdcb362980ad9fbfce5b3476","_cell_guid":"de9e7a52-2a3e-440a-9056-93ed4d9f87f9"},"cell_type":"markdown","source":"**LB 0.1622**, need to stack with Median to see the results."},{"metadata":{"_uuid":"95b5ccf95505b498dede6966f2a899c376d855dd","_cell_guid":"61831c59-a583-45d6-9bba-1102d1f80862"},"cell_type":"markdown","source":"# MinMax + Median Stacking "},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"d4b7e91489d86452dc6d13340109e07da40f9fa9","_cell_guid":"8aa75397-da75-4d93-916e-d88f464e13fe"},"cell_type":"code","source":"#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n#                                    concat_sub['is_iceberg_max'], \n#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n#                                             concat_sub['is_iceberg_min'], \n#                                             concat_sub['is_iceberg_median']))\n#concat_sub['is_iceberg'] = np.clip(concat_sub['is_iceberg'].values, 0.001, 0.999)\n#concat_sub[['id', 'is_iceberg']].to_csv('stack_minmax_median.csv', \n#                                       index=False, float_format='%.6f')"},{"metadata":{"_uuid":"1abbdcd40aca61b375ee4dd0e3e90b814cecceba","_cell_guid":"b9d1df47-6c0b-4bca-9357-ceaf61746171"},"cell_type":"markdown","source":"**LB 0.1488** - **Great!** This is an improvement to our top-line model performance (LB 0.1538). But can we do better?"},{"metadata":{"_uuid":"935499734e508b98e7d694606bd2851a4b3cbce5","_cell_guid":"307ebff0-d690-4dbf-8496-3fc8340bcc60"},"cell_type":"markdown","source":"# MinMax + BestBase Stacking"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"8e3f2ac12368eac5fc2b69e9e899873dd33adef8","_cell_guid":"59f60095-f1ff-4c26-8d51-e0111e80f3ba"},"cell_type":"code","source":"# load the model with best base performance\nsub_base = pd.read_csv('../input/submission38-lb01448/submission43.csv')"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"2ac62e85fbafd2a9095e71d576633a65694787d8","_cell_guid":"2758287f-0e47-4dc6-ab11-004ce8812f8f"},"cell_type":"code","source":"concat_sub['is_iceberg_base'] = sub_base['is_iceberg']\nconcat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:4] > cutoff_lo, axis=1), \n                                    concat_sub['is_iceberg_max'], \n                                    np.where(np.all(concat_sub.iloc[:,1:4] < cutoff_hi, axis=1),\n                                             concat_sub['is_iceberg_min'], \n                                             concat_sub['is_iceberg_base']))\nconcat_sub['is_iceberg'] = np.clip(concat_sub['is_iceberg'].values, 0.001, 0.999)\nconcat_sub[['id', 'is_iceberg']].to_csv('submission54.csv', \n                                        index=False, float_format='%.6f')"},{"metadata":{"_uuid":"3b1a6a2c393b1858847a895dbfc92f4bd71b719a","_cell_guid":"a6e915c2-719e-41be-8760-e05271058ac7"},"cell_type":"markdown","source":"\nRoboust model is always the key component, stacking only comes last with the promise to surprise, sometimes, in an unpleasant direction@. \n\nFor more efficient models I highly recommend my engineering features extraction kernels: \n\nhttps://www.kaggle.com/submarineering/submarineering-size-matters-0-75-lb\n\nhttps://www.kaggle.com/submarineering/submarineering-objects-isolation-0-75-lb\n\nhttps://www.kaggle.com/submarineering/submarineering-what-about-volume-lb-0-45\n\nGreeting, Subamrineering.\n\n\n"},{"metadata":{"_uuid":"b37f85c4d43ab41574a6503b536f21e634079ac7","_cell_guid":"2eec9111-e4d0-4aca-ad39-a2e8b3adaf11"},"cell_type":"markdown","source":"I hope these lines be useful for your. **Please vote up.**"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"8bda1361fdf30328ad1b89347255bd6ae7e5536e","_cell_guid":"67018cdf-68a3-4b1f-bdf8-e9ecb3d0b378"},"cell_type":"code","source":""}],"nbformat":4}