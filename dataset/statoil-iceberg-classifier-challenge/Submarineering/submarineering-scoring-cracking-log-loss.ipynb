{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python","version":"3.6.4","file_extension":".py","nbconvert_exporter":"python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_uuid":"2eb7adaeaf575bd8c68e24ce1ec940416aa9d3c9","_cell_guid":"71cd635b-4fb7-47a6-acfa-0eeec414216d"},"cell_type":"markdown","source":"<img src=\"https://lh3.googleusercontent.com/-tNe1vwwd_w4/VZ_m9E44C7I/AAAAAAAAABM/5yqhpSyYcCUzwHi-ti13MwovCb_AUD_zgCJkCGAYYCw/w256-h86-n-no/Submarineering.png\">"},{"metadata":{"_uuid":"dcb914ca72a621d46ad02e8e322ae4929c98d1fa","_cell_guid":"3eacba78-a0ec-4e1a-b230-8fdcc85936f0"},"cell_type":"markdown","source":"Dear Colleagues, as you know, for this competition and others, we are allowed to make only two submission per day.\n\nThat is a little frustrating, especially when you have a good idea and you have not the possibility of test it.\n\nI have spent a lot of time on understanding how log_loss behave over different models and kind of submissions.\n\nThe main purpose of this kernel is provide a workbench in order to make you able to test different submissions accuracy before  be submitted.\n\nI would like to take into consideration your experience and your input. Please comment if you have something to add.\n\nI highly recommed this related article: \n\nhttp://www.exegetic.biz/blog/2015/12/making-sense-logarithmic-loss/\n\nI hope this kernel be useful for you. Please, Vote up.  \n\n"},{"metadata":{"_uuid":"518b490c58f98a59d25d8d5d8c39dca0673564e1","_cell_guid":"28a96b13-fb54-43af-aeb9-ccb40526ec1f"},"execution_count":null,"outputs":[],"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd \nfrom sklearn.metrics import log_loss \n%pylab inline\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"metadata":{"_uuid":"9db24b56f89561784a4118c9faf4aca6cfdaea3a","_cell_guid":"b4d21b76-54f0-42db-a60f-5cba96b239bd"},"cell_type":"markdown","source":"First thing first@\n# Credits to the following awesome authors and kernels\n\nAuthor: QuantScientist    \nFile: sub_200_ens_densenet.csv     \nLink: https://www.kaggle.com/solomonk/pytorch-cnn-densenet-ensemble-lb-0-1538     \n\n\nAuthor: wvadim     \nFile: sub_TF_keras.csv     \nLink: https://www.kaggle.com/wvadim/keras-tf-lb-0-18     \n\n\nAuthor: Ed Miller    \nFile: sub_fcn.csv    \nLink: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193     \n\n\nAuthor: Chia-Ta Tsai    \nFile: sub_blend009.csv    \nLink: https://www.kaggle.com/cttsai/ensembling-gbms-lb-203    \n\n\nAuthor: DeveshMaheshwari    \nFile: sub_keras_beginner.csv    \nLink: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d       \n\nAuthor: Submarineering    \n\nFiles: submission38.csv , submission43.csv, submission54.csv\n\nLink : https://www.kaggle.com/submarineering/submission38-lb01448\n\n### Without their truly dedicated efforts, this notebook will not be possible.     "},{"metadata":{"_uuid":"aae1d396e2fad44a15fcb8e970c5affa8fb6ddc6","_cell_guid":"1840df41-7524-4305-93d9-423a2a6fe5bd"},"cell_type":"markdown","source":"# Data Load"},{"metadata":{"_uuid":"1fa9dd2434873dc5bc918b102a3a69649d0f35c7","collapsed":true,"_cell_guid":"c978c838-8a87-45ef-a118-b6bd565bdb2e"},"execution_count":null,"outputs":[],"cell_type":"code","source":"# Read different submissions.\nout1 = pd.read_csv(\"../input/statoil-iceberg-submissions/sub_200_ens_densenet.csv\", index_col=0)\nout2 = pd.read_csv(\"../input/statoil-iceberg-submissions/sub_TF_keras.csv\", index_col=0)\nout3 = pd.read_csv(\"../input/submission38-lb01448/submission38.csv\", index_col=0)\nout4 = pd.read_csv(\"../input/submission38-lb01448/submission43.csv\", index_col=0)\nout5 = pd.read_csv('../input/submarineering-even-better-public-score-until-now/submission54.csv',index_col=0)"},{"metadata":{"_uuid":"37b39229e34b71032d8d2371c6b731ed452b8eb2","collapsed":true,"_cell_guid":"a193cac9-e544-4749-8622-2c0a7d882193"},"cell_type":"markdown","source":"Now , very important to understand the concept. \nBecause 'out5' is the best scored available, I am going to use it to get the labels. Imagine that this labels are the true labels. \nOf course not,  but knowing the score obtain by the file we can estimate and error and play taking into considaration that error to score the others files. "},{"metadata":{"_uuid":"07cdbb447c11008557c1773e464d08f798d8b2b2","collapsed":true,"_cell_guid":"c7be9be8-b999-42d9-a0cc-6bf2a035b25b"},"execution_count":null,"outputs":[],"cell_type":"code","source":"#getting lables from our best scored file. \nlabels = (out5>0.5).astype(int)"},{"metadata":{"_uuid":"d412b01db3dd513eef9158bfaaebe96617e79d5b","_cell_guid":"2b115d55-48f4-43c6-9b22-dbd8cd5a28a8"},"execution_count":null,"outputs":[],"cell_type":"code","source":"# out5 score a log_loss of 0.1427 and could be considered also like an error Lerr= 0.1427\n# Error produce by itself.\nout5err = log_loss(labels, out5)\nLerr =  0.1427\nprint('out5 Error:', Lerr+out5err)"},{"metadata":{"_uuid":"2bdb85f34d9a3a418378040b0df1a34c41897fb2","_cell_guid":"c56709fa-1e82-469f-83d6-9f17d4f639fb"},"cell_type":"markdown","source":" Then, now can be estimate the ranking of all the files and test the accuary based on labels, and its error. \n I am going to do it for every file('score already known') available on the kernel. \n"},{"metadata":{"_uuid":"ae003b4fcefe8b2bf20539cdac528e7d04fee80d","collapsed":true,"_cell_guid":"a25a81a5-7145-4a96-a28a-c91d3eafc23b"},"execution_count":null,"outputs":[],"cell_type":"code","source":"files = ['out1', 'out2', 'out3', 'out4', 'out5']\nranking = []\nfor file in files:\n    ranking.append(log_loss(labels, eval(file)))\n"},{"metadata":{"_uuid":"e0e1b36dc15c439b9c2209085604842418176d8f","_cell_guid":"6736e663-f906-42ae-95e7-4c7ffbb225a9"},"execution_count":null,"outputs":[],"cell_type":"code","source":"results = pd.DataFrame(files, columns=['Files'])\nresults['Error'] = ranking\nresults['Lerr'] = Lerr\nresults['Total_Error'] = results['Error']+ results['Lerr']\nresults"},{"metadata":{"_uuid":"a6642e2884dacc8c5095413e6a0945c6791ee1b5","_cell_guid":"f1169e63-b019-4a39-87b5-8fa1d0488f09"},"execution_count":null,"outputs":[],"cell_type":"code","source":"results['Total_Error'].plot(kind='bar')"},{"metadata":{"_uuid":"a24eecfd51f4f6665d751f3f1c126e46a44426bd","_cell_guid":"64a7aeea-ac14-4ae8-ac62-0c58b13c1f9e"},"cell_type":"markdown","source":"Now you can get your own conclusion and compare between files before the submission. "},{"metadata":{"_uuid":"d213635b179fc8d07a6985d257c8c3e0007e0f7a","_cell_guid":"103f2414-04a8-40bd-8ffc-4e77e510e023"},"cell_type":"markdown","source":"LOG_LOSS curve: \n\n<img src='http://www.exegetic.biz/static/img/2015/12/log-loss-curve.png'>"},{"metadata":{"_uuid":"76fc5734615b45bf6234df1f450c9a24ca518834","collapsed":true,"_cell_guid":"9d5af2c0-1cc5-4adc-9153-d20d19c69bd6"},"cell_type":"markdown","source":"As can be read in the above recommeded article, Log_loss penalize very high when the classifier produce a false positive or viceversa. And the penalty is higher when more extreme is the probability predicted for the class. \nThe article, mention some smoothing method to avoid that extra penalty.\nLet me see, how act clipping over this matter. \nThe file with the worse relative score to our artificial labels, is out2. \nCan be improved the scored, just appling some clipping ?"},{"metadata":{"_uuid":"e5cd0f6b6d5a2103bf7a26951254a6decdd56b0b","_cell_guid":"a3c6c970-6241-4526-bc8d-cb17480858ec"},"execution_count":null,"outputs":[],"cell_type":"code","source":"# As before :\nout2err = log_loss(labels, out2) + Lerr\nout2err"},{"metadata":{"_uuid":"c5f0f7148fda421ef91afdb516a9dbe963f02fcf","_cell_guid":"db58cae1-fbe8-4eba-b8d3-0a419d7c40d4"},"execution_count":null,"outputs":[],"cell_type":"code","source":"# Apply some clipping : \nOUT2err = log_loss(labels, np.clip(out2, 0.0001, 0.99)) + Lerr\nOUT2err"},{"metadata":{"_uuid":"5e6d1c97b74fed4f1dedd5131b529850f150acd7","_cell_guid":"2851e8fa-2c68-4b0f-91c3-e3809b389b97"},"cell_type":"markdown","source":"And Of course, you can. Please, fell free to experiment and share if you discover something interesting. "},{"metadata":{"_uuid":"3b1a6a2c393b1858847a895dbfc92f4bd71b719a","_cell_guid":"a6e915c2-719e-41be-8760-e05271058ac7"},"cell_type":"markdown","source":"\nRoboust model is always the key component, stacking only comes last with the promise to surprise, sometimes, in an unpleasant direction@. \n\nFor more efficient models I highly recommend my engineering features extraction kernels: \n\nhttps://www.kaggle.com/submarineering/submarineering-size-matters-0-75-lb\n\nhttps://www.kaggle.com/submarineering/submarineering-objects-isolation-0-75-lb\n\nhttps://www.kaggle.com/submarineering/submarineering-what-about-volume-lb-0-45\n\nGreeting, Subamrineering.\n\n\n"},{"metadata":{"_uuid":"b37f85c4d43ab41574a6503b536f21e634079ac7","_cell_guid":"2eec9111-e4d0-4aca-ad39-a2e8b3adaf11"},"cell_type":"markdown","source":"I hope these lines be useful for your. **Please vote up.** and let your comments."}]}