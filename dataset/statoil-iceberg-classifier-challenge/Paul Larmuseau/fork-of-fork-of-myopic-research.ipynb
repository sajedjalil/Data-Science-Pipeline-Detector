{"cells":[{"source":"","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"b13c8256d6b43bde80ed575d942bda4099ad3392","_cell_guid":"cb03b7aa-cc9b-4106-b6bc-e797b99695c6"}},{"source":"#load with pandas, manipulate with numpy, plot with matplotlib\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport cv2\nfrom skimage import filters\nfrom skimage import data, exposure\nfrom sklearn.feature_extraction import image\nfrom sklearn.cluster import spectral_clustering\nfrom scipy import ndimage\n\n\nfrom sklearn.mixture import GMM\n\n\n#ML - we will classify using a naive xgb with stratified cross validation\nimport xgboost as xgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\n\n\n\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"e6b43e7b7d786bc565deb7c52acd78d2885d9837","_cell_guid":"08e02f57-9c97-487a-ab0d-b2afad161d53"}},{"source":"#filenames\ninputFolder = \"../input/\"\ntrainSet = 'train.json'\n#testSet = 'test.json'\nsubName = 'iceberg-svd-xgb-3fold.csv'\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"027ce3e753ae41fbe6600369f6dd38047e1fdd59","_cell_guid":"232aecf4-a711-415c-8b23-d277824788c3"}},{"source":"#load data\ntrainDF = pd.read_json(inputFolder+trainSet)\n#testDF = pd.read_json(inputFolder+testSet)","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"f52fbe147c7723767b3f03200c9746ba5abdaae5","_cell_guid":"2d055ac8-6c5d-4bd3-8f93-c981379fe57a"}},{"source":"trainDF.head(15)","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"_uuid":"f580f9b454f136aa5c10f950bec1358f32f11dfe","_cell_guid":"9b3ba319-00d2-4899-872a-33a65f1baca0"}},{"source":"#get numpy arrays for train/test data, prob there is a more pythonic approach\nband1 = trainDF['band_1'].values\nim1 = np.zeros((len(band1),len(band1[0])))\nfor j in range(len(band1)):\n    im1[j,:]=np.asarray(band1[j])\n    \nband2 = trainDF['band_2'].values\nim2 = np.zeros((len(band2),len(band2[0])))\nfor j in range(len(band2)):\n    im2[j,:]=np.asarray(band2[j])\n    \n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"7f08caa08f99b025488c086b4a610333e306d087","_cell_guid":"a2ff70e4-e630-419b-b6b3-9a8be46a7014"}},{"source":"basic view\n---","cell_type":"markdown","metadata":{"_uuid":"4e1004363a6628deb377f64d7610cb66337b0c3b","_cell_guid":"80d7b907-ea64-4f60-a102-aeec7ffa9e24"}},{"source":"\nfrom time import time\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.ticker import NullFormatter\nimport random\nfrom sklearn import manifold, datasets\n\n# Next line to silence pyflakes. This import is needed.\nAxes3D\nimage=im1[6,:]\nimage2=im2[6,:]\nimage=image-image.min()\nimage=image/image.max()*254+1\nimage2=image2-image2.min()\nimage2=image2/image2.max()*254+1\nn_points = 75*75\n\nX, color = datasets.samples_generator.make_s_curve(n_points, random_state=0)\nfor xi in range(0,75):\n    for yi in range(0,75):\n        X[xi+yi*75,0]=xi+random.random()/100\n        X[xi+yi*75,1]=yi+random.random()/100 #image[xi+yi*75]\n        X[xi+yi*75,2]=image[xi+yi*75]/2+image2[xi+yi*75]/2+random.random()/100\ncolor=image               \nn_neighbors = 15\nn_components = 2\n\nfig = plt.figure(figsize=(20, 10))\nplt.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n             % (1000, n_neighbors), fontsize=14)\n\n\nax = fig.add_subplot(251, projection='3d')\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\nax.view_init(4, -72)\n\nmethods = ['standard', 'hessian', 'modified', 'ltsa']\nlabels = ['LLE', 'Hessian LLE', 'Modified LLE', 'LTSA']\n\nfor i, method in enumerate(methods):\n    t0 = time()\n    Y = manifold.LocallyLinearEmbedding(n_neighbors, n_components,\n                                        eigen_solver='auto',\n                                        method=method).fit_transform(X)\n    t1 = time()\n    print(\"%s: %.2g sec\" % (methods[i], t1 - t0))\n\n    ax = fig.add_subplot(252 + i)\n    plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n    plt.title(\"%s (%.2g sec)\" % (labels[i], t1 - t0))\n    ax.xaxis.set_major_formatter(NullFormatter())\n    ax.yaxis.set_major_formatter(NullFormatter())\n    plt.axis('tight')\n\nt0 = time()\nY = manifold.Isomap(n_neighbors, n_components).fit_transform(X)\nt1 = time()\nprint(\"Isomap: %.2g sec\" % (t1 - t0))\nax = fig.add_subplot(257)\nplt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\nplt.title(\"Isomap (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis('tight')\n\n\nt0 = time()\nmds = manifold.MDS(n_components, max_iter=100, n_init=1)\nY = mds.fit_transform(X)\nt1 = time()\nprint(\"MDS: %.2g sec\" % (t1 - t0))\nax = fig.add_subplot(258)\nplt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\nplt.title(\"MDS (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis('tight')\n\n\nt0 = time()\nse = manifold.SpectralEmbedding(n_components=n_components,\n                                n_neighbors=n_neighbors)\nY = se.fit_transform(X)\nt1 = time()\nprint(\"SpectralEmbedding: %.2g sec\" % (t1 - t0))\nax = fig.add_subplot(259)\nplt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\nplt.title(\"SpectralEmbedding (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis('tight')\n\nt0 = time()\ntsne = manifold.TSNE(n_components=n_components, init='pca', random_state=0)\nY = tsne.fit_transform(X)\nt1 = time()\nprint(\"t-SNE: %.2g sec\" % (t1 - t0))\nax = fig.add_subplot(2, 5, 10)\nplt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\nplt.title(\"t-SNE (%.2g sec)\" % (t1 - t0))\nax.xaxis.set_major_formatter(NullFormatter())\nax.yaxis.set_major_formatter(NullFormatter())\nplt.axis('tight')\n\nplt.show()","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"scrolled":true}},{"source":"import time\nimport warnings\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn import cluster, datasets, mixture\nfrom sklearn.neighbors import kneighbors_graph\nfrom sklearn.preprocessing import StandardScaler\nfrom itertools import cycle, islice\nimagematrix=np.reshape(im1[6,:],(75,75))\nimagematrix=imagematrix-imagematrix.min()\nno_structure = imagematrix,None\nnp.random.seed(0)\n\n# ============\n# Generate datasets. We choose the size big enough to see the scalability\n# of the algorithms, but not too big to avoid too long running times\n# ============\n\n# ============\n# Set up cluster parameters\n# ============\nplt.figure(figsize=(9 * 2 + 3, 12.5))\nplt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n                    hspace=.01)\n\nplot_num = 1\n\ndefault_base = {'quantile': .3,\n                'eps': .3,\n                'damping': .9,\n                'preference': -200,\n                'n_neighbors': 10,\n                'n_clusters': 3}\n\ndatasets = [ (no_structure, {})]\n\nfor i_dataset, (dataset, algo_params) in enumerate(datasets):\n    # update parameters with dataset-specific values\n    params = default_base.copy()\n    params.update(algo_params)\n\n    X, y = dataset\n\n    # normalize dataset for easier parameter selection\n    X = StandardScaler().fit_transform(X)\n\n    # estimate bandwidth for mean shift\n    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n\n    # connectivity matrix for structured Ward\n    connectivity = kneighbors_graph(\n        X, n_neighbors=params['n_neighbors'], include_self=False)\n    # make connectivity symmetric\n    connectivity = 0.5 * (connectivity + connectivity.T)\n\n    # ============\n    # Create cluster objects\n    # ============\n    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n    ward = cluster.AgglomerativeClustering(\n        n_clusters=params['n_clusters'], linkage='ward',\n        connectivity=connectivity)\n    spectral = cluster.SpectralClustering(\n        n_clusters=params['n_clusters'], eigen_solver='arpack',\n        affinity=\"nearest_neighbors\")\n    dbscan = cluster.DBSCAN(eps=params['eps'])\n    affinity_propagation = cluster.AffinityPropagation(\n        damping=params['damping'], preference=params['preference'])\n    average_linkage = cluster.AgglomerativeClustering(\n        linkage=\"average\", affinity=\"cityblock\",\n        n_clusters=params['n_clusters'], connectivity=connectivity)\n    birch = cluster.Birch(n_clusters=params['n_clusters'])\n    gmm = mixture.GaussianMixture(\n        n_components=params['n_clusters'], covariance_type='full')\n\n    clustering_algorithms = (\n        ('MiniBatchKMeans', two_means),\n        ('AffinityPropagation', affinity_propagation),\n        ('MeanShift', ms),\n        ('SpectralClustering', spectral),\n        ('Ward', ward),\n        ('AgglomerativeClustering', average_linkage),\n        ('Birch', birch),\n        ('GaussianMixture', gmm)\n    )\n\n    for name, algorithm in clustering_algorithms:\n        t0 = time.time()\n\n        # catch warnings related to kneighbors_graph\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\n                \"ignore\",\n                message=\"the number of connected components of the \" +\n                \"connectivity matrix is [0-9]{1,2}\" +\n                \" > 1. Completing it to avoid stopping the tree early.\",\n                category=UserWarning)\n            warnings.filterwarnings(\n                \"ignore\",\n                message=\"Graph is not fully connected, spectral embedding\" +\n                \" may not work as expected.\",\n                category=UserWarning)\n            algorithm.fit(X)\n\n        t1 = time.time()\n        if hasattr(algorithm, 'labels_'):\n            y_pred = algorithm.labels_.astype(np.int)\n        else:\n            y_pred = algorithm.predict(X)\n\n        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n        if i_dataset == 0:\n            plt.title(name, size=18)\n\n        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n                                             '#f781bf', '#a65628', '#984ea3',\n                                             '#999999', '#e41a1c', '#dede00']),\n                                      int(max(y_pred) + 1))))\n        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n\n        plt.xlim(-2.5, 2.5)\n        plt.ylim(-2.5, 2.5)\n        plt.xticks(())\n        plt.yticks(())\n        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n                 transform=plt.gca().transAxes, size=15,\n                 horizontalalignment='right')\n        plot_num += 1\n\nplt.show()","cell_type":"code","execution_count":null,"outputs":[],"metadata":{}},{"source":"import time\n\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction import image\nfrom sklearn.cluster import spectral_clustering\n\nfor xi in range(0,15):\n    face=np.reshape(im1[xi,:],(75,75))\n    face= face-face.min()\n    face= face/face.max()*255\n    # Resize it to 10% of the original size to speed up the processing\n    face = sp.misc.imresize(face, 0.5) / 255.\n\n    # Convert the image into a graph with the value of the gradient on the\n    # edges.\n    graph = image.img_to_graph(face)\n\n    # Take a decreasing function of the gradient: an exponential\n    # The smaller beta is, the more independent the segmentation is of the\n    # actual image. For beta=1, the segmentation is close to a voronoi\n    beta = 2\n    eps = 1e-6\n    graph.data = np.exp(-beta * graph.data / graph.data.std()) + eps\n\n    # Apply spectral clustering (this step goes much faster if you have pyamg\n    # installed)\n    N_REGIONS = 2\n\n    for assign_labels in ('kmeans', 'discretize'):\n        t0 = time.time()\n        labels = spectral_clustering(graph, n_clusters=N_REGIONS,\n                                 assign_labels=assign_labels, random_state=1)\n        t1 = time.time()\n        labels = labels.reshape(face.shape)\n\n        plt.figure(figsize=(5, 5))\n        plt.imshow(face, cmap=plt.cm.gray)\n        for l in range(N_REGIONS):\n            plt.contour(labels == l, contours=1,\n                        colors=[plt.cm.spectral(l / float(N_REGIONS))])\n        plt.xticks(())\n        plt.yticks(())\n        title = 'Spectral clustering: %s, %.2fs' % (assign_labels, (t1 - t0))\n        print(title)\n        plt.title(title)\n    plt.show()","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"53d0866f7f7c37e403e38923dd364fffeb6002fa","_cell_guid":"f5f22393-aed1-442e-937e-031f1fdc9396"}},{"source":"","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"106820a81529defc2c11d2f02f0709efd2bd8785","_cell_guid":"c9652703-d59d-46c6-92e9-d8c19ac3c3c2"}},{"source":"from sklearn.metrics.pairwise import cosine_similarity\n\n\nfor xi in range(0,15):\n    image=np.reshape(im1[xi,:],(75,75))\n    Ui,si,Vi=np.linalg.svd(image)\n    imagecore=Ui[:,:3].dot(Vi[:,:3].T)\n    image=np.corrcoef(imagecore)\n    imainv=np.linalg.inv(image)    \n    imacos=cosine_similarity(Ui[:,:3],Vi[:,:3])\n\n    fig, ax = plt.subplots(1,2) \n    ax[0].imshow(imagecore, cmap='nipy_spectral',interpolation='nearest')\n    ax[1].imshow( imacos, cmap='nipy_spectral', interpolation='nearest')\n    ax[1].set_xlabel(trainDF.iloc[xi]['is_iceberg'])\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"59930dd75691f984099d9ec896581bba41e683ba","_cell_guid":"9811d193-c0b6-4bf7-b7ce-102af9dc5afb"}},{"source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,\n                                 denoise_wavelet, estimate_sigma)\nfrom skimage import data, img_as_float, color\nfrom skimage.util import random_noise\n\n\noriginal =np.reshape(im1[xi,:],(75,75))\noriginal = original-original.min()\noriginal = (original+original.T)/2\n#original = original * 255/original.max()\n#print(original)\nsigma = original.std()*4\nnoisy = random_noise(original, var=sigma**2)\n\nfig, ax = plt.subplots(nrows=2, ncols=4, figsize=(8, 5), sharex=True,\n                       sharey=True, subplot_kw={'adjustable': 'box-forced'})\n\nplt.gray()\n\n# Estimate the average noise standard deviation across color channels.\nsigma_est = estimate_sigma(noisy, multichannel=True, average_sigmas=True)\n# Due to clipping in random_noise, the estimate will be a bit smaller than the\n# specified sigma.\nprint(\"Estimated Gaussian noise standard deviation = {}\".format(sigma_est))\n\nax[0, 0].imshow(noisy)\nax[0, 0].axis('off')\nax[0, 0].set_title('Noisy')\nax[0, 1].imshow(denoise_tv_chambolle(noisy, weight=0.1, multichannel=False))\nax[0, 1].axis('off')\nax[0, 1].set_title('TV')\nax[0, 2].imshow(denoise_bilateral(noisy, sigma_color=0.05, sigma_spatial=15,\n                multichannel=False))\nax[0, 2].axis('off')\nax[0, 2].set_title('Bilateral')\nax[0, 3].imshow(denoise_wavelet(noisy, multichannel=False))\nax[0, 3].axis('off')\nax[0, 3].set_title('Wavelet denoising')\n\nax[1, 1].imshow(denoise_tv_chambolle(noisy, weight=0.2, multichannel=False))\nax[1, 1].axis('off')\nax[1, 1].set_title('(more) TV')\nax[1, 2].imshow(denoise_bilateral(noisy, sigma_color=0.1, sigma_spatial=15,\n                multichannel=False))\nax[1, 2].axis('off')\nax[1, 2].set_title('(more) Bilateral')\nax[1, 3].imshow(denoise_wavelet(noisy, multichannel=True, convert2ycbcr=False))\nax[1, 3].axis('off')\nax[1, 3].set_title('Wavelet denoising\\nin YCbCr colorspace')\nax[1, 0].imshow(original)\nax[1, 0].axis('off')\nax[1, 0].set_title('Original')\n\nfig.tight_layout()\n\nplt.show()","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"f51550fc566a93618311f7694994b73f0e46cc7b","_cell_guid":"dcb0ee9f-16c2-42db-b8d7-e5ae9e4ace56"}},{"source":"statistical\n---\n* above mean\n*  normalized ","cell_type":"markdown","metadata":{"_uuid":"eddf283d245376f7597ab6f1db736a09274e0634","_cell_guid":"e2ff92a2-8ddb-4f70-b52f-926d15fd80fb"}},{"source":"for xi in range(0,15):\n    image=np.reshape(im1[xi,:],(75,75))\n    fig, ax = plt.subplots(1,2) \n    ax[0].imshow(image*(image > image.mean()), cmap='nipy_spectral', interpolation='nearest')\n    ax[1].imshow( ( image -image.min() )/ (image.max()-image.min() )*image.var(), cmap='nipy_spectral', interpolation='nearest')\n    ax[1].set_xlabel(trainDF.iloc[xi]['is_iceberg'])\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"0cebdd8231772bc8bebcf8320bb0c72fe208ac0a","_cell_guid":"5ffa65f1-5533-4f53-b0d4-f821059127e2"}},{"source":"gaussian filter\n---\npure noise filter\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"ddeada0895d3fcf63e832753676c805d60172c7b","_cell_guid":"fd75405c-e4da-4f89-b2ca-2d20c6df7bf1"}},{"source":"for xi in range(0,15):\n    image=np.reshape(im1[xi,:],(75,75))\n    fig, ax = plt.subplots(1,2) \n    image_gf=ndimage.gaussian_filter(image, 3)\n    image_perf=image*(image*1.3 < image_gf)\n    ax[0].imshow(image_gf)\n    ax[1].imshow(image_perf)\n    ax[1].set_xlabel(trainDF.iloc[xi]['is_iceberg'])\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"21357c8adf7a8d87fc4529f2f856cf3e022baa96","_cell_guid":"a094c3c3-62df-47d1-a6b5-31199f4948ff"}},{"source":"gaussian laplace\n---","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"268ee70359147ce8c6a2e162f5c9d0d20669a964","_cell_guid":"ed4e05cf-4c71-46cb-890e-6cf2056ccfb6"}},{"source":"for xi in range(0,15):\n    image=np.reshape(im1[xi,:],(75,75))\n    image_gl=ndimage.filters.gaussian_laplace(image, image.std(), output=None, mode='reflect', cval=0.0)\n    fig, ax = plt.subplots(1,2) \n    ax[0].imshow(image_gl)\n    ax[1].imshow(image_gl, cmap='nipy_spectral', interpolation='nearest')\n    ax[1].set_xlabel(trainDF.iloc[xi]['is_iceberg'])\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"2e35ca6732e0cfe6750d62b8ecb43be467076d74","_cell_guid":"c97c58f0-b2c6-45ec-8361-26919e8aad85"}},{"source":"\n#hsobel_text = filters.sobel_h(image)\n#val = filters.threshold_otsu(image)\n\nfor xi in range(0,15):\n    image=np.reshape(im1[xi,:],(75,75))    \n    hist, bin_edges = np.histogram(image, bins=60)\n    #print(hist.shape, bin_edges.shape)\n    camera_equalized = exposure.equalize_hist(image)\n\n    threshold = np.mean(image)-image.std()\n    binary_img = image > threshold\n    fig, ax = plt.subplots(1,4) \n    ax[0].hist(img, bins=20)\n    ax[1].imshow(image*binary_img, cmap='nipy_spectral', interpolation='nearest')\n    ax[3].imshow(camera_equalized)\n\n\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"965cc1220c4946e27e8f36982a44f9c4112d4369","_cell_guid":"25fa4fcb-a1cf-40e1-ac65-bb84cd4669b3"}},{"source":"from math import sqrt\nfrom skimage import data\nfrom skimage.feature import blob_dog, blob_log, blob_doh\nfrom skimage.color import rgb2gray\n\nimport matplotlib.pyplot as plt\n\nfor xi in range(0,15):\n    image=np.reshape(im1[xi,:],(75,75))\n    image_gray = rgb2gray(image)\n    blobs_log = blob_log(image_gray, max_sigma=30, num_sigma=10, threshold=.1)\n    # Compute radii in the 3rd column.\n    blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n    blobs_dog = blob_dog(image_gray, max_sigma=30, threshold=.0001)\n    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n    blobs_doh = blob_doh(image_gray, max_sigma=30, threshold=.1)\n    blobs_list = [blobs_log, blobs_dog, blobs_doh]\n    colors = ['yellow', 'lime', 'red']\n    titles = ['Laplacian of Gaussian', 'Difference of Gaussian',\n          'Determinant of Hessian']\n    sequence = zip(blobs_list, colors, titles)\n\n    fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True,\n                         subplot_kw={'adjustable': 'box-forced'})\n    ax = axes.ravel()\n\n    for idx, (blobs, color, title) in enumerate(sequence):\n        ax[idx].set_title(title)\n        ax[idx].imshow(image, interpolation='nearest')\n        for blob in blobs:\n            y, x, r = blob\n            c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n            ax[idx].add_patch(c)\n        ax[idx].set_axis_off()\n\n    plt.tight_layout()\n    plt.show()","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"b55a3a12d9545e5a1eb6bbcfeab50e8f08d0eab1","_cell_guid":"bf0cabd8-1dff-47af-8078-1821fc956c23"}},{"source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import ndimage as ndi\n\nfrom skimage import feature\n\nfor xi in range(0,15):\n    # Generate noisy image of a square\n    im = np.reshape(im1[xi,:],(75,75))\n    im = ndimage.gaussian_filter(im, 3)\n\n    # Compute the Canny filter for two values of sigma\n    edges1 = feature.canny(im)\n    edges2 = feature.canny(im, sigma=5)\n\n    # display results\n    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n                                    sharex=True, sharey=True)\n\n    ax1.imshow(im, cmap=plt.cm.gray)\n    ax1.axis('off')\n    ax1.set_title('noisy image', fontsize=20)\n\n    ax2.imshow(edges1, cmap=plt.cm.seismic)\n    ax2.axis('off')\n    ax2.set_title('Canny filter, $\\sigma=1$', fontsize=20)\n\n    ax3.imshow(edges2, cmap=plt.cm.spectral)\n    ax3.axis('off')\n    #ax3.set_title('Canny filter, $\\sigma=3$', fontsize=20)\n    ax3.set_title(trainDF.iloc[xi]['is_iceberg'])        \n\n    fig.tight_layout()\n\n    plt.show()","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"aecddc95df97f53e88e18931cb6ec5a44f3f2e01","_cell_guid":"02b21dd5-9f6d-4587-ad9e-045bf8eac46c"}},{"source":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# loading image\n#img0 = cv2.imread('SanFrancisco.jpg',)\nimg0 = image = np.reshape(im1[9,:],(75,75))\nfrom skimage.exposure import equalize_hist\n\nequalized_image = equalize_hist(img0)\n\n\n# remove noise\nimg = cv2.GaussianBlur(equalized_image,(3,3),0)\n\n# convolute with proper kernels\nlaplacian = cv2.Laplacian(img,cv2.CV_64F)\nsobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)  # x\nsobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)  # y\n\nplt.subplot(2,2,1),plt.imshow(img,cmap = 'nipy_spectral')\nplt.title('Original'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'nipy_spectral')\nplt.title('Laplacian'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'nipy_spectral')\nplt.title('Sobel X'), plt.xticks([]), plt.yticks([])\nplt.subplot(2,2,4),plt.imshow(sobely,cmap = 'nipy_spectral')\nplt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n\nplt.show()\nfrom skimage.feature import corner_harris,corner_peaks\n\n# More pyplot!\ndef show_corners(corners,image,title=None):\n    \"\"\"Display a list of corners overlapping an image\"\"\"\n    fig = plt.figure()\n    plt.imshow(image,cmap = 'gray')\n    # Convert coordinates to x and y lists\n    y_corner,x_corner = zip(*corners)\n    plt.plot(x_corner,y_corner,'v') # Plot corners\n    if title:\n        plt.title(title)\n    plt.xlim(0,image.shape[1])\n    plt.ylim(image.shape[0],0) # Images use weird axes\n    fig.set_size_inches(np.array(fig.get_size_inches()) * 1.5)\n    plt.show()\n    print (\"Number of corners:\",len(corners) )\n\n# Make a checker board\ncheckers = np.zeros((100,100),dtype=np.bool)\nind = np.arange(100).reshape((10,10))[::2].flatten()\ncheckers[ind,:] = True\ncheckers[:,ind] = np.invert(checkers[:,ind])\ncheckers = np.where(checkers,1.,0.)\n\n# Run Harris\ncheckers_corners = corner_peaks(corner_harris(checkers),min_distance=2)\nshow_corners(checkers_corners,checkers)\ncorners = corner_peaks(corner_harris(image),min_distance=2)\nshow_corners(corners,image,\n             title=\"Harris Corner Algorithm\")","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"bb301af51f9a359f4cd63d604cf5bb0841707568","_cell_guid":"37751614-5c21-43ba-a755-d4efc9f58fcb"}},{"source":"U1,s1,V1  = np.linalg.svd(im1,full_matrices = 0)\n#U2,s2,V2  = np.linalg.svd(im2,full_matrices = 0)\nprint(U1[:,:100].shape,V1.shape)","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"fc7c8798fa82e8a614df8aec951baf8bdc490583","_cell_guid":"6631c80c-86a7-43d6-9c51-12d92e0c7d58"}},{"source":"from sklearn.metrics.pairwise import cosine_similarity\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"0044e9c1841f18f554ee33c3dbbfe74f2c5dde83","_cell_guid":"036ce5ab-57c4-4168-9863-dcc6a6e1b2ce"}},{"source":"Singular reformed images\n---\n\nless (noise) is more (iceberg)","cell_type":"markdown","metadata":{"_uuid":"f900b9378d8d5b1a07371f50952b8988b66e21a5","_cell_guid":"dee4a78c-053a-4d23-8970-a88ace2ff42c"}},{"source":"\n\nfor rank in range(3,50,3):\n    im1cs=cosine_similarity(U1[:,:rank],V1[:rank,:].T)\n    image=np.reshape(im1cs[13,:],(75,75))\n    fig, ax = plt.subplots(1,3) \n    ax[0].imshow(image)\n    ax[1].imshow(image, cmap='nipy_spectral', interpolation='nearest')\n    ax[2].imshow(image, cmap='gray', interpolation='nearest')\n\n","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"77d5dcf0ec7254a09d0a08bff52b6694075eedbe","_cell_guid":"b984d7af-f610-461a-8ddb-7a61218ae4f5"}},{"source":"print(np.reshape(im1[13,:],(75,75)))\nim1ce = exposure.equalize_hist(im1)\nU1,s1,V1  = np.linalg.svd(im1ce,full_matrices = 0)","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"8aa37e369e8ebb2243bdd564014a604bb7da9655","_cell_guid":"47f9a1a8-8a85-4691-b3ea-f0d2fd0f0348"}},{"source":"camera exposure equilizing\n---","cell_type":"markdown","metadata":{"_uuid":"1dd1af0611b9e5b650b07bcf0ca314c81602a6b9","_cell_guid":"d3de8827-d164-4cdc-8f0a-dfd17e70c15d"}},{"source":"for rank in range(3,50,3):\n    im1cs=cosine_similarity(U1[:,:rank],V1[:rank,:].T)\n    image=np.reshape(im1cs[13,:],(75,75))\n    fig, ax = plt.subplots(1,3) \n    ax[0].imshow(image)\n    ax[1].imshow(image, cmap='nipy_spectral', interpolation='nearest')\n    ax[2].imshow(image, cmap='gray', interpolation='nearest')","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"7e500a34a030f7702902d9b48d6bb13a438d665e","_cell_guid":"81714912-dd01-4500-810b-5ed82450949d"}},{"source":"from sklearn.preprocessing import normalize\ndef distanc(X,Y):\n    Z=X\n    for yi in range(0,len(X)):\n        Z[yi]=angle_between((X[yi],Y[yi],0),(1,0,0))\n    return Z #np.reshape(Z,(75,75))\n\ndef unit_vector(vector):\n    \"\"\" Returns the unit vector of the vector.  \"\"\"\n    return vector / np.linalg.norm(vector)\n\ndef angle_between(v1, v2):\n    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n\n            >>> angle_between((1, 0, 0), (0, 1, 0))\n            1.5707963267948966\n            >>> angle_between((1, 0, 0), (1, 0, 0))\n            0.0\n            >>> angle_between((1, 0, 0), (-1, 0, 0))\n            3.141592653589793\n    \"\"\"\n    v1_u = unit_vector(v1)\n    v2_u = unit_vector(v2)\n    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n\nima=im1\nfor xi in range(0,len(im1)):\n    xi1=np.reshape(im1[xi,:],(75,75))\n    xi2=np.reshape(im2[xi,:],(75,75))\n    ima[xi]=distanc(im1[xi,:],im2[xi,:])","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"394fb73718bb13e64a5643de468bb9971973d8ff","_cell_guid":"b5f4060a-b6fa-4538-8810-0c4e92e180a9"}},{"source":"U1,s1,V1  = np.linalg.svd(ima,full_matrices = 0)\n\nfor rank in range(3,50,3):\n    im1cs=cosine_similarity(U1[:,:rank],V1[:rank,:].T)\n    image=np.reshape(im1cs[13,:],(75,75))\n    fig, ax = plt.subplots(1,3) \n    ax[0].imshow(image)\n    ax[1].imshow(image, cmap='nipy_spectral', interpolation='nearest')\n    ax[2].imshow(image, cmap='gray', interpolation='nearest')","cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"884958a9dcccee18b64d2eb062de6e0a63cf323e","_cell_guid":"a36784ca-7365-4e01-b873-d463fbe74ec5"}}],"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","version":"3.6.3"}},"nbformat_minor":1,"nbformat":4}