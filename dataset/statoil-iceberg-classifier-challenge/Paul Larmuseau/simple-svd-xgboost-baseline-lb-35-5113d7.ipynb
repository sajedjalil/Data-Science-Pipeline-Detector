{"cells":[{"metadata":{"_cell_guid":"057b28f0-4682-4bce-a25f-9e07f478450f","_uuid":"5aed6729ec2b6aaf3d0cdec5da3a24cd5508a175"},"source":"We aim to use svd to dimensionally reduce the images to just a few features (20 per image in this particular case), which works nicely as it turns out most of variance in the image is just noise. LB should be aroun ~0.35, but I've played a bit with xgb parameters and the crossvalidation improved, this suggest that perhaps you can get lower LB if you submit this notebook. ","cell_type":"markdown"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"08e02f57-9c97-487a-ab0d-b2afad161d53","_uuid":"e6b43e7b7d786bc565deb7c52acd78d2885d9837","collapsed":true},"source":"#load with pandas, manipulate with numpy, plot with matplotlib\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n#ML - we will classify using a naive xgb with stratified cross validation\nimport xgboost as xgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\n\n\n\n","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"232aecf4-a711-415c-8b23-d277824788c3","_uuid":"027ce3e753ae41fbe6600369f6dd38047e1fdd59","collapsed":true},"source":"#filenames\ninputFolder = \"../input/\"\ntrainSet = 'train.json'\ntestSet = 'test.json'\nsubName = 'iceberg-svd-xgb-3fold.csv'\n","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"2d055ac8-6c5d-4bd3-8f93-c981379fe57a","_uuid":"f52fbe147c7723767b3f03200c9746ba5abdaae5","collapsed":true},"source":"#load data\ntrainDF = pd.read_json(inputFolder+trainSet)\ntestDF = pd.read_json(inputFolder+testSet)","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"a2ff70e4-e630-419b-b6b3-9a8be46a7014","_uuid":"7f08caa08f99b025488c086b4a610333e306d087","collapsed":true},"source":"#get numpy arrays for train/test data, prob there is a more pythonic approach\nband1 = trainDF['band_1'].values\nim1 = np.zeros((len(band1),len(band1[0])))\nfor j in range(len(band1)):\n    im1[j,:]=np.asarray(band1[j])\n    \nband2 = trainDF['band_2'].values\nim2 = np.zeros((len(band2),len(band2[0])))\nfor j in range(len(band2)):\n    im2[j,:]=np.asarray(band2[j])\n    \n#get numpy array for test data\nband1test = testDF['band_1'].values\nim1test = np.zeros((len(band1test),len(band1test[0])))\nfor j in range(len(band1test)):\n    im1test[j,:]=np.asarray(band1test[j])\n    \nband2test = testDF['band_2'].values\nim2test = np.zeros((len(band2test),len(band2test[0])))\nfor j in range(len(band2test)):\n    im2test[j,:]=np.asarray(band2test[j])","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"eec13fca-3462-46e8-8f1e-c462f1c90d99","_uuid":"78e22d6cc95e32ddbcbbf4d07dc7138b7b81e978","collapsed":true},"source":"import cv2\nfrom skimage import filters\nfrom skimage import data, exposure\n\nU1,s1,V1 = np.linalg.svd(np.vstack((im1,im1test)),full_matrices = 0)\nU2,s2,V2 = np.linalg.svd(np.vstack((im2,im2test)),full_matrices = 0)\n#svd of the two bands\nUh1,sh1,Vh1 = np.linalg.svd(exposure.equalize_hist(np.vstack((im1,im1test))),full_matrices = 0)\nUh2,sh2,Vh2 = np.linalg.svd(exposure.equalize_hist(np.vstack((im2,im2test))),full_matrices = 0)\nprint(Uh2.shape,Vh2.shape)","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"28f0bea0-ad1e-4dac-be86-f76096aeab2f","_uuid":"e8e87c37e83b9be919a0f98a8ccda59495466ee8","collapsed":true},"source":"#original \nnmodes=20\n\nim1p=np.dot(U1[:,:nmodes],V1[:nmodes,])\nim2p=np.dot(U2[:,:nmodes],V2[:nmodes,])\nim1ph=np.dot(Uh1[:,:nmodes],Vh1[:nmodes,])\nim2ph=np.dot(Uh2[:,:nmodes],Vh2[:nmodes,])\n","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"8907b35b-6d4a-4b52-9c64-7ef47f604809","_uuid":"8f769429220e7b3b4cb252da26dc75d308bf1404","collapsed":true},"source":"\nnmodes = 20\n\nX = np.hstack((U1[:len(trainDF),:nmodes],U2[:len(trainDF),:nmodes]))\nX = np.hstack((X,Uh1[:len(trainDF),:nmodes]))\nX = np.hstack((X,Uh2[:len(trainDF),:nmodes]))\nX_test = np.hstack((U1[len(trainDF):,:nmodes],U2[len(trainDF):,:nmodes]))\nX_test = np.hstack((X_test,Uh1[len(trainDF):,:nmodes]))\nX_test = np.hstack((X_test,Uh2[len(trainDF):,:nmodes]))\ny = trainDF['is_iceberg'].values","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"a1569666-7286-43af-b31e-842c9dbb8795","_uuid":"581325179817744f640cbad47b040c4dc282552a","collapsed":true},"source":"#is there a native xgb way of doing it?\ndef logloss_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    score = log_loss(labels, preds)\n    return 'logloss', score","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"db22c09b-3f05-4cab-b65c-98b96ef2a2c5","_uuid":"b1f4522cbe45692088e1fe1d817f1db387cddaee","collapsed":true},"source":"nfolds = 3;\nxgb_mdl=[None]*nfolds\n\n\nxgb_params = {\n        'objective': 'binary:logistic',\n        'n_estimators':1000,\n        'max_depth': 8,\n        'subsample': 0.9,\n        'colsample_bytree': 0.9 ,\n     #   'max_delta_step': 1,\n     #   'min_child_weight': 10,\n        'eta': 0.01,\n      #  'gamma': 0.5\n        }\n\n\nfolds = list(StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=2016).split(X, y))\n\nd_test = xgb.DMatrix(X_test)\n\npreds = np.zeros((X_test.shape[0],nfolds))\n\nfor j, (train_idx, valid_idx) in enumerate(folds):\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n    \n    X_valid = X[valid_idx]\n    y_valid = y[valid_idx]\n    \n    d_train =  xgb.DMatrix(X_train,label=y_train)\n    d_valid =  xgb.DMatrix(X_valid,label=y_valid)\n    \n    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n    \n    xgb_mdl[j]=xgb.train(\n            xgb_params, \n            d_train, \n            1600, watchlist, \n            early_stopping_rounds=70, \n            feval=logloss_xgb, \n            maximize=False, \n            verbose_eval=100)\n    preds[:,j] = xgb_mdl[j].predict(d_test)","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true},"source":"import matplotlib.pyplot as plt\ny = trainDF['is_iceberg'].values\npre = xgb_mdl[j].predict(xgb.DMatrix(X))\nplt.scatter(pre, y)\nplt.show()","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"1fe79978-e5fa-4e5d-9192-9b309ae12e45","_uuid":"ee960d6bb03549e9b7956715ebd3a670af600a8e","collapsed":true},"source":"y_pred = np.mean(preds,axis=1)\nsub = pd.DataFrame()\nsub['id'] = testDF['id']\nsub['is_iceberg'] = y_pred\nsub.to_csv(subName, index=False)\n","cell_type":"code"}],"nbformat":4,"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","file_extension":".py","version":"3.6.3","mimetype":"text/x-python"}}}