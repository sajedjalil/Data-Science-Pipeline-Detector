{"nbformat_minor":1,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","name":"python","nbconvert_exporter":"python","file_extension":".py","version":"3.6.4","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"cells":[{"source":"**This project is to build a machine learning model to automatically classify boat and iceberg in satallite images.**\n\n**Part I, Image processing/denoising, backscattering signal extraction, data scaling.**\n\n**Part II, deep learning (transfer learning with multiple inputs and data augmentation).**","cell_type":"markdown","metadata":{"_cell_guid":"98f63571-2dc1-4be5-b02a-222a610288d9","_uuid":"868b6abd09f93bc88546c2dcd888b777120baf91"}},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"3d9bd703-a6ee-47f5-8fb0-d3608c96d0c3","_uuid":"f6528733be9c63de5fedd610c81d2c03314b4206"},"source":"#Import libraries.\nimport numpy as np \nimport pandas as pd \nimport cv2\nfrom skimage import restoration, filters, img_as_ubyte\n\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\nfrom scipy.stats import mode\nfrom scipy.ndimage.filters import uniform_filter\nfrom scipy.ndimage.measurements import variance\n\nfrom keras import applications, regularizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Input, SeparableConv2D, Add, Average\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, concatenate\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam, SGD, Nadam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.xception import Xception\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg16 import VGG16\nfrom keras import backend as K\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"source":" **Part I: Image processing and signal extraction**","cell_type":"markdown","metadata":{"_cell_guid":"abfdbe28-69af-4e22-a09c-ba3d3643e272","_uuid":"c0c7738893ebf1b9807e307d03e01652e1debd66"}},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"95962dd3-e1d4-4fce-85cb-8cb1759f89a0","_uuid":"09c66bf6fc7b085ef6a0c97c2aab9b0203834914"},"source":"#Define a function to plot the radar signals as images.\ndef img_plot(img_arr, ax, title):\n    ax.imshow(img_arr)\n    ax.axis('off')\n    ax.grid('off')\n    if title == 1:\n        ax.set_title('Iceberg')\n    elif title == 0:\n        ax.set_title('Boat')"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"41f4fd06-705c-4890-9254-99152f3fada4","_uuid":"fa64a4e6f3ccfd6ce1fdbb94496867917f8d6316"},"source":"# Create the Lee filter function.\ndef lee_filter(img, size):\n    img_mean = uniform_filter(img, (size, size))\n    img_sqr_mean = uniform_filter(img**2, (size, size))\n    img_variance = img_sqr_mean - img_mean**2\n\n    overall_variance = variance(img)\n\n    img_weights = img_variance**2 / (img_variance**2 + overall_variance**2)\n    img_output = img_mean + img_weights * (img - img_mean)\n    return img_output"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"a273d56a-5809-4c98-bae2-ea080394a4c1","_uuid":"5b3089a5550d525ba347abfe679ffa3209c99ab2"},"source":"#Now, define a funciton to use the Lee filter, denoise_nl_means and bilateral functions sequentially to remove noise.\n#The filter parameters are defined in the function. \ndef noise_removal(signal, img_h=75, img_w=75):\n    #Convert the signal array to 2d array/image\n    #Apply three filters sequentially to remove noise\n    image = signal\n    if len(signal.shape) == 1:\n        image = signal.reshape(img_h, img_w)\n    lee = lee_filter(image, 5)\n    final_image = restoration.denoise_nl_means(lee, patch_size=5, patch_distance=10, h=2, \n                                               multichannel=False, fast_mode=True)\n    return(final_image)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"1ea4e55a-c414-4df0-9584-2c9a2661c598","_uuid":"55d70a468501282e694bb246706377cfb6c7edf0"},"source":"# Read the training dataset.\ndata_df = pd.read_json('../input/statoil-iceberg-classifier-challenge/train.json')"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"5494e966-a3c4-45a3-bceb-f6a915b56741","_uuid":"cd060d4a32dd3de00424dd31c36bf2bb2d55a107"},"source":"# Remove noise and save the images in new columns, ch1 and ch2. \n# Add another new column, ch3, which is the sum of band1 and band2 data.\n# This step is time consuming!!\ndata_df = pd.concat([data_df, pd.DataFrame(columns = ['band3'], dtype='object')])\nfor row in range(0,len(data_df)):\n    arr1 = np.array(data_df.loc[row,'band_1'])\n    arr2 = np.array(data_df.loc[row,'band_2'])\n    data_df.at[row,'band3'] = noise_removal(arr1 + arr2)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"6523ae58-6188-4396-abca-12be25835615","_uuid":"98d05a506e2142f3841216e8f04b8fb92c7976db"},"source":"#plot the raw data in 2-D images\nfig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\nfor d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n    raw1 = np.array(data_df.loc[d, 'band_1']).reshape(75,75)\n    title = data_df.loc[d, 'is_iceberg']\n    img_plot(raw1, ax, title)\n\nplt.tight_layout(pad=-1.2)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"fdb919fe-6ffa-46fd-aa4d-bdac47df637e","_uuid":"77b2da60b3c95f4a22ced0132c563ff3110cf8b8"},"source":"#plot the denoised \"band3\" images.\nfig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\nfor d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n    ch3 = data_df.loc[d, 'band3']\n    title = data_df.loc[d, 'is_iceberg']\n    img_plot(ch3, ax, title)\n\nplt.tight_layout(pad=-1.2)"},{"source":"Some images contain more than one object. It would be better to remove the contaminating objects which are mostly like near the edges of the images.","cell_type":"markdown","metadata":{"_cell_guid":"f68894e7-b0fc-4f60-9064-fd17e102ed94","_uuid":"402bd6dbe9eecb0aff27c866a2137a6f89a67673"}},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"2c494074-7162-4eac-8b17-2e2c84c324af","_uuid":"bf301c0824c5f3bb4ddd705cc136d05a33c51e7d"},"source":"#Define a function to get the centroid of a contour.\n#The centroid can be used to determined if a contour is too close to the edges of the image.\ndef get_center(contour):\n    M = cv2.moments(contour)\n    if M[\"m00\"] != 0:\n        cX, cY = int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]) \n    else:\n        cX, cY = 0, 0 \n    return(cX, cY)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"f006eb91-d8fc-41da-b137-5e831a08f54d","_uuid":"2c986ca1cfe3c4c2a89f7ba85ed2b53f94cbfc30"},"source":"#Define a function to list and remove all contours that are too close to the edges of the image.\n#If all contours are close to the edges (no central object), no contour will be removed.\ndef get_central_cnts(cnts_lst):\n    edge_lst = []\n    central_lst = []\n    for c in cnts_lst:\n        cX, cY = get_center(c)\n        if cX < 15 or cX > 60 or cY < 15 or cY > 60:\n            edge_lst.append(c)\n        else:\n            central_lst.append(c)\n    \n    #If there is no central object, do not remove any object near the edges.\n    if (len(edge_lst) == len(cnts_lst)) and (len(central_lst) == 0):\n        edge_lst = []\n        central_lst = cnts_lst\n    \n    return(central_lst, edge_lst)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"b94a405a-2b07-4f51-9761-13bbc65e65b9","_uuid":"19857eef64aeb4efa85161d38cd764feeae1cc62"},"source":"#Define a function to find contours and create masks.\ndef cnt_to_mask(binary_image):\n    #Find contours in the binary image.\n    _, cnts, _ = cv2.findContours(binary_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    if len(cnts) == 0:\n        print('No contour is found!')\n    \n    #Create a mask and draw the contours on the mask to record the background coordinates.\n    mask_bg = np.zeros((75,75), dtype='uint8')\n    for c in cnts:\n        cv2.drawContours(mask_bg, [c], -1, 1, -1)\n    \n    #Remove the contours that are too close to the edges.\n    cnts_clean, cnts_edge = get_central_cnts(cnts)\n    \n    #Create a mask and draw the cleaned contours on the mask to record the foreground coordinates.\n    mask_fg = np.zeros((75,75), dtype='uint8')\n    for c in cnts_clean:\n        cv2.drawContours(mask_fg, [c], -1, 1, -1)\n    \n    #Create a mask and draw the edge contours on the mask to record the edge coordinates.\n    mask_eg = np.zeros((75,75), dtype='uint8')\n    for c in cnts_edge:\n        cv2.drawContours(mask_eg, [c], -1, 1, -1)\n   \n    return(mask_bg, mask_fg, mask_eg) "},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"a7bca7cb-f1e2-40df-b809-9e19073d4e43","_uuid":"328604496aa56af533799e89b54e0f9b62a81219"},"source":"# Define a function to generate binary images and create masks.\ndef get_mask(input_img, cutoff = filters.threshold_triangle):\n    #Calculate the threshold and create the binary image.\n    thresh = cutoff(input_img, nbins=256)   \n    binary_img = input_img > thresh\n    \n    #Get the masks\n    mask_bg, mask_fg, mask_eg = cnt_to_mask(img_as_ubyte(binary_img)) \n      \n    #If any foreground contour touches the edge, the threshold probably didn't precisely cut out the object.\n    #Modify the threshold, and recreate the binary image and masks.\n    if sum(mask_fg[0,:]) > 1 or sum(mask_fg[74,:]) > 1 or sum(mask_fg[:,0]) > 1 or sum(mask_fg[74,:]) > 1:\n        fg_coord = np.where(mask_fg.flatten() == 1)\n        fg_mean = np.mean(np.take(input_img.flatten(), fg_coord[0]))\n        fg_max = np.max(np.take(input_img.flatten(), fg_coord[0]))\n        thresh_new = thresh + (fg_max - fg_mean) / 3\n        binary_img_new = input_img > thresh_new\n        mask_bg, mask_fg, mask_eg = cnt_to_mask(img_as_ubyte(binary_img_new)) \n    \n    return(mask_bg, mask_fg, mask_eg)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"14d9e61a-92cd-40bf-b553-e37804a0140b","_uuid":"253043c83e9fcb3e3a24ad5ea8e6df4d91d92a4d"},"source":"#Check if the masks can be properly created.\nfig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\nfor d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n    mask_bg, mask_fg, mask_eg = get_mask(np.array(data_df.loc[d, 'band3']))\n    final = cv2.bitwise_and(data_df.loc[d, 'band3'], data_df.loc[d, 'band3'], mask=mask_fg)\n    title = data_df.loc[d, 'is_iceberg']\n    img_plot(final, ax, title)\n\nplt.tight_layout(pad=-1.2)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"571cc247-0694-42a6-ad93-5a4a49808126","_uuid":"f60508c3975a8ff991686704affac589fc1e8881"},"source":"#Replace the objects on the edges with mean background signal. \n#Save the cleaned images in new columns, band1_cl and band2_cl.\ndata_df = pd.concat([data_df, pd.DataFrame(columns = ['band1_cl','band2_cl'], dtype='object')])\nfor r in range(0,len(data_df)):\n    mask_bg, _, mask_eg = get_mask(np.array(data_df.loc[r,'band3']))    \n    coord_bg = np.where(mask_bg.flatten() == 0)\n    bg1 = np.mean(np.take(np.array(data_df.at[r,'band_1']), coord_bg[0]))\n    bg2 = np.mean(np.take(np.array(data_df.at[r,'band_2']), coord_bg[0]))\n    if np.sum(mask_eg) > 0:\n        coord_eg = np.where(mask_eg.flatten() == 1)\n        \n        band1 = np.array(data_df.at[r,'band_1'])\n        np.put(band1, coord_eg, bg1)\n        data_df.at[r,'band1_cl'] = band1.reshape(75,75)\n        \n        band2 = np.array(data_df.at[r,'band_2'])\n        np.put(band2, coord_eg, bg2)\n        data_df.at[r,'band2_cl'] = band2.reshape(75,75)\n    \n    else:\n        data_df.at[r,'band1_cl'] = np.array(data_df.at[r,'band_1']).reshape(75,75)\n        data_df.at[r,'band2_cl'] = np.array(data_df.at[r,'band_2']).reshape(75,75)  "},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"34ce06dd-0ec7-4a1a-b065-38b739fe11ea","_uuid":"817e9f38fe024d96f3c5fbe376d5b40f1f9a1ab3"},"source":"#Check if the images are cleaned.\nfig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\nfor d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n    image = data_df.at[d,'band1_cl']\n    title = data_df.loc[d, 'is_iceberg']\n    img_plot(image, ax, title)\n\nplt.tight_layout(pad=-1.2)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"7ea5639b-3851-47db-8e65-018b1b659ea2","_uuid":"e505ccb8ecc22bcc28b82c884d83ca6176ce9281"},"source":"# Now do noise_removal again using the cleaned images, and save the new images in new columns ch1-ch3.\ndata_df = pd.concat([data_df, pd.DataFrame(columns = ['ch1','ch2','ch3'], dtype='object')])\nfor row in range(0,len(data_df)):\n    arr1 = data_df.loc[row,'band1_cl']\n    arr2 = data_df.loc[row,'band2_cl']\n    data_df.at[row,'ch1'] = noise_removal(arr1)\n    data_df.at[row,'ch2'] = noise_removal(arr2)\n    data_df.at[row,'ch3'] = noise_removal(arr1 + arr2)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"24fbf4bf-9a05-415f-823e-cb5b309570af","_uuid":"9b1e25368614b28b0a66ba5f600aa2639bd483fd"},"source":"#plot the denoised clean ch3 images.\nfig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\nfor d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n    ch3 = data_df.loc[d, 'ch3']\n    title = data_df.loc[d, 'is_iceberg']\n    img_plot(ch3, ax, title)\n\nplt.tight_layout(pad=-1.2)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"5273d368-6b49-48f2-bad1-6a35333db527","_uuid":"2ab6e45aa084f10abc53f2d9f2b17faa0281035c"},"source":"#Create new masks using the newly denoised images.\n#Extract background and object backscattering values.\n#Put the values in new columns, eng1 and eng2.\ndata_df = pd.concat([data_df, pd.DataFrame(columns = ['eng1','eng2'], dtype='float')])\nfor r in range(0,len(data_df)):\n    #Create masks\n    mask_bg, mask_fg, _ = get_mask(data_df.loc[r,'ch3'],cutoff = filters.threshold_otsu)\n\n    #Extract backscattering signals from objects.\n    coord_bg = np.where(mask_bg.flatten() == 0)\n    coord_fg = np.where(mask_fg.flatten() == 1)\n    bg1 = np.mean(np.take(np.array(data_df.at[r,'band1_cl']), coord_bg[0]))\n    bg2 = np.mean(np.take(np.array(data_df.at[r,'band2_cl']), coord_bg[0]))\n    sig1 = np.take(data_df.at[r,'band1_cl'], coord_fg[0])\n    sig2 = np.take(data_df.at[r,'band2_cl'], coord_fg[0])\n    data_df.at[r,'eng1'] = np.mean(sig1) - bg1\n    data_df.at[r,'eng2'] = np.mean(sig2) - bg2"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"cbe32bc7-6b49-43bf-b507-de41f1ccd9e4","_uuid":"f3fa71d565ec6c0cbafda45647b5886f00c90f56"},"source":"#Standardize the energy values.\ndata_df['eng1_std'] = (data_df['eng1'] - data_df['eng1'].mean()) / data_df['eng1'].std()\ndata_df['eng2_std'] = (data_df['eng2'] - data_df['eng2'].mean()) / data_df['eng2'].std()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"aee5d3ab-b42b-47ed-a241-bc1aaeb06678","_uuid":"023e076a3057ef4fa277a51dbc78ada1978de10c"},"source":"#Pair plot the energy values to see whether they can be used for classification.\ng = sns.PairGrid(data=data_df, \n                 hue='is_iceberg', #Variables in data for different colors.\n                 hue_order=None, \n                 palette='husl', \n                 hue_kws={\"marker\": [\"+\", \"x\"]}, \n                 vars=['eng1_std','eng2_std'], #list of columns to use, otherwise use all columns\n                 diag_sharey=True, \n                 size=3, #each facet\n                 aspect=1, \n                 despine=True, \n                 dropna=True)\n    \ng = g.map_diag(plt.hist, edgecolor=\"black\", linewidth=0.5)\ng = g.map_offdiag(plt.scatter, linewidth=0.5, s=50)  \ng = g.add_legend()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"5c1c4c62-60f7-4503-8e48-61db34ae41b8","_uuid":"9f57cf8b912193cb0d9dd8c5d7dfc72b4d9031ce"},"source":"#plot a heatmap to check the multicollinearity.\ncmap = sns.diverging_palette(150, 10, n=9, s=90, l=50, center='light', as_cmap=True)\nfig, ax = plt.subplots(figsize=(4,4))\nsns.heatmap(data_df[['eng1_std','eng2_std']].corr(), vmin=-1, vmax=1, cmap=cmap, annot=True, square=True, ax=ax, cbar_kws={'shrink':0.7})"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"8a03410e-4562-4df9-b239-617c4b485c91","_uuid":"2b5e5e7002eb604dab8ab68cb200a4345994d34d"},"source":"# Scale the images and put them in new columns.\n# In this case, I chose to scale them to [-1, 1].\ndata_df = pd.concat([data_df, pd.DataFrame(columns = ['scale_111','scale_112','scale_113',\n                                                      'scale_b1','scale_b2','scale_b3'], dtype='object')])\nfor row in range(0,len(data_df)):\n    arr1 = data_df.loc[row,'band1_cl']\n    arr2 = data_df.loc[row,'band2_cl']\n    arr3 = data_df.loc[row,'ch3']\n    arr_b1 = np.array(data_df.loc[row,'band_1']).reshape(75,75)\n    arr_b2 = np.array(data_df.loc[row,'band_2']).reshape(75,75)\n    arr_b3 = data_df.loc[row,'band3']\n    \n#     # Rescale the image data to 0 to 1.\n#     data_df.at[row,'n011'] = (arr1 - np.min(arr1))/(np.max(arr1)-np.min(arr1))\n#     data_df.at[row,'n012'] = (arr2 - np.min(arr2))/(np.max(arr2)-np.min(arr2))\n#     data_df.at[row,'n013'] = (arr3 - np.min(arr3))/(np.max(arr3)-np.min(arr3))\n#     data_df.at[row,'n014'] = (arr4 - np.min(arr4))/(np.max(arr4)-np.min(arr4))\n#     data_df.at[row,'n015'] = (arr5 - np.min(arr5))/(np.max(arr5)-np.min(arr5))\n    \n    # Rescale the image data to -1 to 1.\n    data_df.at[row,'scale_111'] = 2*(arr1 - np.min(arr1))/(np.max(arr1)-np.min(arr1))-1\n    data_df.at[row,'scale_112'] = 2*(arr2 - np.min(arr2))/(np.max(arr2)-np.min(arr2))-1\n    data_df.at[row,'scale_113'] = 2*(arr3 - np.min(arr3))/(np.max(arr3)-np.min(arr3))-1    \n    data_df.at[row,'scale_b1'] = 2*(arr_b1 - np.min(arr_b1))/(np.max(arr_b1)-np.min(arr_b1))-1\n    data_df.at[row,'scale_b2'] = 2*(arr_b2 - np.min(arr_b2))/(np.max(arr_b2)-np.min(arr_b2))-1  \n    data_df.at[row,'scale_b3'] = 2*(arr_b3 - np.min(arr_b3))/(np.max(arr_b3)-np.min(arr_b3))-1"},{"source":"**Part II: Model training**","cell_type":"markdown","metadata":{"_cell_guid":"0d541be0-ee55-4275-8464-004fca3f5ee9","_uuid":"fe3a5e6c092288e2fee87f08813ad7de6a250b94"}},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"c387ac2a-c0a3-4eb6-8265-b3e88910d40b","_uuid":"1f5979a86785a1d9981132653dde4f2006491bec"},"source":"# Prepare the arrays.\narr_111 = np.stack(data_df['scale_111'], axis=0)\narr_112 = np.stack(data_df['scale_112'], axis=0)\narr_113 = np.stack(data_df['scale_113'], axis=0)\narr_b1 = np.stack(data_df['scale_b1'], axis=0)\narr_b2 = np.stack(data_df['scale_b2'], axis=0)\narr_b3 = np.stack(data_df['scale_b3'], axis=0)\ndata_img = np.concatenate([arr_b1[:,:,:,np.newaxis], arr_b2[:,:,:,np.newaxis], arr_b3[:,:,:,np.newaxis]], axis=3)\nprint(data_img.shape)\ndata_y = np.array(data_df['is_iceberg'].astype(int))\nprint(data_y.shape)\ndata_feat = np.array(data_df[['eng1_std','eng2_std']].astype(float))\nprint(data_feat.shape)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"59d29292-bd72-4d6c-95ba-203f8efe96c0","_uuid":"dc6e83ce7404ce043f9c69399830c6ffc1f060a5"},"source":"# Data split into the training and test sets\nimg_train, img_test, feat_train, feat_test, y_train, y_test = train_test_split(data_img, \n                                                                               data_feat,\n                                                                               data_y, \n                                                                               random_state=4, \n                                                                               test_size=0.25)\nprint(img_train.shape, feat_train.shape, img_test.shape, feat_test.shape)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"1b0a6bda-21bc-49de-9f74-cdfb9e02849a","_uuid":"ee3b469d6c7a0d3de32bff6856641fb2506bbf8d"},"source":"input_shape = (75, 75, 3)"},{"source":"Transfer learning using VGG16, 2 inputs.","cell_type":"markdown","metadata":{"_cell_guid":"f8151636-f5a8-4ec8-a1e6-3f87c21a528f","_uuid":"d115618f12966373fbf094c35876ebd9c77876d6"}},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"6d370d51-c562-40c6-b90e-e4f3732eea6d","_uuid":"066c82dbcc14389f431d6a2658cfa4926b7e73cb"},"source":"# Define data augmentation parameters\ndatagen_train = ImageDataGenerator(rotation_range=40.,\n                                   shear_range=0.,\n                                   zoom_range=0.,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   vertical_flip=True,\n                                   horizontal_flip=True,\n                                   samplewise_center=False,\n                                   samplewise_std_normalization=False,\n                                   fill_mode='nearest')\n\ndatagen_test = ImageDataGenerator(rotation_range=20.,\n                                  vertical_flip=True,\n                                  horizontal_flip=True,\n                                  samplewise_center=False,\n                                  samplewise_std_normalization=False)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"0858231c-8070-44ad-97f4-f15587400092","_uuid":"aa669dbed4dc557c676247f8a06bea13531d8a9f"},"source":"#Define a function to make a customized data generator, combining image and non-image data.\ndef combo_gen(gen1, gen2):\n    while True:\n        set1 = gen1.next()\n        set2 = gen2.next()\n        yield [set2[0], set2[1]], set1[1]"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"fa8c8c81-8953-4fac-abb9-59b637aa526d","_uuid":"69436d4f9d7e762997900b44334927f5b67ad00d"},"source":"# Define the VGG16-derived transfer learing model.\ndef vgg16_model_2input():\n    base_model = VGG16(weights=None, input_shape=input_shape, include_top=False, classes=1)\n    base_model.load_weights('../input/vgg16wgts/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    # Fix the lower-level 7 layer (no training). \n    for layer in base_model.layers[0:7]:\n        layer.trainable = False     \n    for layer in base_model.layers[7:]:\n        layer.trainable = True   \n    x = base_model.get_layer('block5_pool').output\n    x = Flatten()(x)\n    # Add a second input.\n    eng_input = Input(shape=(2,), name=\"energy\")\n    combined = concatenate([x, eng_input])    \n    combined = Dense(512, activation='relu', name='fc1')(combined)\n    combined = Dropout(0.3)(combined)\n    combined = Dense(128, activation='relu', name='fc2')(combined)\n    combined = Dropout(0.3)(combined)\n    predictions = Dense(1, activation='sigmoid')(combined)    \n    combined_model = Model(inputs=[base_model.input, eng_input], outputs=predictions)\n    sgd = SGD(lr=0.001, decay=0.001/1000, momentum=0.9, nesterov=True)\n#     nadam = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n#     adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n#     The Adam and Nadam optimizers didn't work! \n    combined_model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    return(combined_model)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"44cbe1b6-a3e4-4ba3-94f8-cde130f676f4","_uuid":"65e6f86aa1d872d420253e422f538eb7e4b302f7"},"source":"# Create data generators for both image and non-image data.\nbatch_size = 8\ntrain_gen1 = datagen_train.flow(img_train, y_train, shuffle=False, seed=1, batch_size=batch_size)\ntrain_gen2 = datagen_train.flow(img_train, feat_train, shuffle=False, seed=1, batch_size=batch_size)\ntest_gen1 = datagen_test.flow(img_test, y_test, shuffle=False, seed=1, batch_size=batch_size)\ntest_gen2 = datagen_test.flow(img_test, feat_test, shuffle=False, seed=1, batch_size=batch_size)\n# Create customized data generators with 2 inputs.\ntrain_combo_gen = combo_gen(train_gen1, train_gen2)\ntest_combo_gen = combo_gen(test_gen1, test_gen2)\n# Set up callbacks parameters. These are commonly used.\nearlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\nmcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, epsilon=1e-4, mode='min')"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"22986a63-d3db-40d5-b524-eecb0b58149d","scrolled":false,"_uuid":"f142dd24e1854c407f0d83ebe00e85a3f86870fb"},"source":"model_vgg16_2input = vgg16_model_2input()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"59f1b9ff-428f-453c-bd43-42787fe46bb5","_uuid":"5bb73ee44328d3cf7d8e5b8dfc1e456d1f4da5c1"},"source":"model_vgg16_2input.fit_generator(train_combo_gen, \n                                 epochs=50,\n                                 steps_per_epoch=img_train.shape[0] // 8.0,\n                                 verbose=1,\n                                 callbacks=[earlyStopping, mcp_save, reduce_lr_loss],\n                                 validation_data=test_combo_gen,\n                                 validation_steps=img_test.shape[0] // 8.0\n                                 )"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"0a01aacb-8d8d-4338-88b6-5636fff9f49c","_uuid":"09a1b33beccc5278d1b25e552b7feb02e028a842"},"source":"model_vgg16_2input.load_weights('.mdl_wts.hdf5')\nprint('Training scores')\nprint(model_vgg16_2input.evaluate([img_train,feat_train], y_train))\nprint('Testing scores')\nprint(model_vgg16_2input.evaluate([img_test,feat_test], y_test))"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"34a0e31e-aed5-4809-9264-bf250d949b17","_uuid":"6e559603f27b1daa44d76b40e4b28b2eca0acda6"},"source":"del model_vgg16_2input\nK.clear_session()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"5331b07f-9003-484d-afb8-80dd7c6c523d","_uuid":"501c0fb4898967c0d0b831476726b46e9852e1b6"},"source":""}]}