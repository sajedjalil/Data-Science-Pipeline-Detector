{"cells":[{"source":"import numpy as np\nnp.random.seed(42)\nimport pandas as pd\n\nimport cv2\nfrom sklearn.model_selection import KFold\n\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","cell_type":"code","metadata":{"_uuid":"629df8d24e72716fd68f4979e5b399c627155b28","_cell_guid":"78048ae2-6848-4868-89f0-2cdb99a72856"},"outputs":[],"execution_count":22},{"source":"# Load data\ntrain = pd.read_json(\"../input/train.json\")\ntest = pd.read_json(\"../input/test.json\")","cell_type":"code","metadata":{"collapsed":true},"outputs":[],"execution_count":23},{"source":"# Train data\nx_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_1']])\nx_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_2']])\n\nX_train = np.concatenate([x_band1[:, :, :, np.newaxis],\n                          x_band2[:, :, :, np.newaxis],\n                          ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n\ntarget_train=train['is_iceberg']\n\ndel train","cell_type":"code","metadata":{"collapsed":true},"outputs":[],"execution_count":24},{"source":"# Test data\nx_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\nx_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n\nX_test = np.concatenate([x_band1[:, :, :, np.newaxis],\n                         x_band2[:, :, :, np.newaxis],\n                         ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n\nid_test = test['id'].values\n\ndel test; del x_band1; del x_band2","cell_type":"code","metadata":{},"outputs":[],"execution_count":25},{"source":"# Define CNN Model Architecture (Kaggle can't access the weights file)\nimg_height = 224\nimg_width = 224\nimg_channels = 3\nimg_dim = (img_height, img_width, img_channels)\n\ndef inceptionv3(img_dim=img_dim):\n    input_tensor = Input(shape=img_dim)\n    base_model = InceptionV3(include_top=False,\n                   weights='imagenet',\n                   input_shape=img_dim)\n    bn = BatchNormalization()(input_tensor)\n    x = base_model(bn)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    output = Dense(1, activation='sigmoid')(x)\n    model = Model(input_tensor, output)\n    \n    return model\n\nmodel = inceptionv3()\nmodel.summary()","cell_type":"code","metadata":{},"outputs":[],"execution_count":26},{"source":"# Train Model and predict\ndef train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n        \n    train_scores = []; valid_scores = []\n    preds_test = np.zeros(len(test), dtype = np.float)\n\n    i = 1\n\n    for train_index, test_index in kf.split(x):\n        x_train = x[train_index]; x_valid = x[test_index]\n        y_train = y[train_index]; y_valid = y[test_index]\n\n        def augment(src, choice):\n            if choice == 0:\n                # Rotate 90\n                src = np.rot90(src, 1)\n            if choice == 1:\n                # flip vertically\n                src = np.flipud(src)\n            if choice == 2:\n                # Rotate 180\n                src = np.rot90(src, 2)\n            if choice == 3:\n                # flip horizontally\n                src = np.fliplr(src)\n            if choice == 4:\n                # Rotate 90 counter-clockwise\n                src = np.rot90(src, 3)\n            if choice == 5:\n                # Rotate 180 and flip horizontally\n                src = np.rot90(src, 2)\n                src = np.fliplr(src)\n            return src\n\n        def train_generator():\n            while True:\n                for start in range(0, len(x_train), batch_size):\n                    x_batch = []\n                    end = min(start + batch_size, len(x_train))\n                    y_batch = y_train[start:end]\n                    for img in x_train[start:end]:\n                        new_img = cv2.resize(img, img_size)\n                        new_img = augment(new_img, np.random.randint(6))\n                        x_batch.append(new_img)\n                    x_batch = np.array(x_batch, np.float32) / 255.\n                    y_batch = np.array(y_batch, np.uint8)\n                    yield x_batch, y_batch\n\n        def valid_generator():\n            while True:\n                for start in range(0, len(x_valid), batch_size):\n                    x_batch = []\n                    end = min(start + batch_size, len(x_valid))\n                    y_batch = y_valid[start:end]\n                    for img in x_valid[start:end]:\n                        new_img = cv2.resize(img, img_size)\n                        x_batch.append(new_img)\n                    x_batch = np.array(x_batch, np.float32) / 255.\n                    y_batch = np.array(y_batch, np.uint8)\n                    yield x_batch, y_batch\n\n        def test_generator():\n            while True:\n                for start in range(0, len(test), n_fold):\n                    x_batch = []\n                    end = min(start + n_fold, len(test))\n                    for img in test[start:end]:\n                        new_img = cv2.resize(img, img_size)\n                        x_batch.append(new_img)\n                    x_batch = np.array(x_batch, np.float32) / 255.\n                    yield x_batch\n                    \n        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n                               verbose=1, min_lr=1e-7),\n             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n                             save_best_only=True, save_weights_only=True, mode='auto')]\n\n        train_steps = len(x_train) / batch_size\n        valid_steps = len(x_valid) / batch_size\n        test_steps = len(test) / n_fold\n        \n        model = model\n\n        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])\n\n        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n                            callbacks=callbacks, validation_data=valid_generator(), \n                            validation_steps=valid_steps)\n\n        model.load_weights(filepath='inception.fold_' + str(i) + '.hdf5')\n\n        \n        print('----------------------------------------')\n        print('Running train evaluation on fold {}'.format(i))\n        train_score = model.evaluate_generator(train_generator(), steps=train_steps)        \n        print('Running validation evaluation on fold {}'.format(i))\n        valid_score = model.evaluate_generator(valid_generator(), steps=valid_steps)\n        print('----------------------------------------')   \n        \n        print('Train loss: {:0.5f}\\n Train acc: {:0.5f} for fold {}'.format(train_score[0],\n                                                                            train_score[1], i))\n        print('Valid loss: {:0.5f}\\n Valid acc: {:0.5f} for fold {}'.format(valid_score[0],\n                                                                            valid_score[1], i))\n        print('----------------------------------------')\n\n        train_scores.append(train_score[1])\n        valid_scores.append(valid_score[1])\n        print('Avg Train Acc: {:0.5f}\\nAvg Valid Acc: {:0.5f} after {} folds'.format\n              (np.mean(train_scores), np.mean(valid_scores), i))\n        print('----------------------------------------')\n        \n        print('Running test predictions with fold {}'.format(i))        \n        preds_test_fold = model.predict_generator(generator=test_generator(),\n                                              steps=test_steps, verbose=1)[:, -1]\n\n        preds_test += preds_test_fold\n\n        print('\\n\\n')\n\n        i += 1\n\n        if i <= n_fold:\n            print('Now beginning training for fold {}\\n\\n'.format(i))\n        else:\n            print('Finished training!')\n\n    preds_test /= n_fold\n\n    return preds_test","cell_type":"code","metadata":{"collapsed":true},"outputs":[],"execution_count":27},{"source":"batch_size = 6\nepochs = 50\nn_fold = 3\nimg_size = (img_height, img_width)\nkf = KFold(n_splits=n_fold, shuffle=True)\n\nprediction = train_model(model, batch_size, epochs, img_size, X_train, \n                                target_train, X_test, n_fold, kf)\n\nsubmit = pd.DataFrame({'id': id_test, 'is_iceberg': prediction.reshape((prediction.shape[0]))})\nsubmit.to_csv('./submission.csv', index=False)","cell_type":"code","metadata":{},"outputs":[],"execution_count":28}],"metadata":{"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","mimetype":"text/x-python","file_extension":".py","version":"3.6.3","nbconvert_exporter":"python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1,"nbformat":4}