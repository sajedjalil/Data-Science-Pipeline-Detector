{"metadata":{"language_info":{"version":"3.6.3","pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","name":"python","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1,"cells":[{"outputs":[],"execution_count":null,"metadata":{"_uuid":"76a4489d06e8b686764dc0093d6220696efe1d14","_cell_guid":"6c6cabd2-f186-460c-b2ca-25bc54be7062"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom os.path import join as opj\nimport keras\n\n#from matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n#import pylab\n#plt.rcParams['figure.figsize'] = 10, 10\n#%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"path = \"../input\"\ntrain = pd.read_json(path+\"/train.json\")\ntarget_train=train['is_iceberg']\ntest = pd.read_json(path+\"/test.json\")\n\ntarget_train=train['is_iceberg']\ntest['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\ntrain['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\ntrain['inc_angle']=train['inc_angle'].fillna(method='pad')\nX_angle=train['inc_angle']\ntest['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\nX_test_angle=test['inc_angle']\n\n#Generate the training data\nX_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nX_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n#X_band_3=(X_band_1+X_band_2)/2\nX_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\nX_band_4=np.maximum(X_band_1,X_band_2)\nX_band_5=np.minimum(X_band_1,X_band_2)\n#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\nX_train = np.concatenate([\n                          \n                          X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n\n\n\nX_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nX_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n#X_band_test_3=(X_band_test_1+X_band_test_2)/2\nX_band_test_3=np.fabs(np.subtract(X_band_test_1,X_band_test_2))\nX_band_test_4=np.maximum(X_band_test_1,X_band_test_2)\nX_band_test_5=np.minimum(X_band_test_1,X_band_test_2)\n#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\nX_test = np.concatenate([\n                          X_band_test_3[:, :, :, np.newaxis], X_band_test_4[:, :, :, np.newaxis],X_band_test_5[:, :, :, np.newaxis]],axis=-1)\n"},{"metadata":{},"cell_type":"markdown","source":"# Loading libraries"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"\n#Import Keras.\n#from matplotlib import pyplot\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\nfrom keras.layers import *\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras import initializers\nfrom keras.optimizers import Adam\nfrom keras.optimizers import rmsprop\nfrom keras.layers.advanced_activations import LeakyReLU, PReLU\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n\nfrom keras.datasets import cifar10\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.xception import Xception\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.vgg19 import VGG19\nfrom keras.layers import Concatenate, Dense, LSTM, Input, concatenate\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\t\n\n#Data Aug for multi-input\nfrom keras.preprocessing.image import ImageDataGenerator\nbatch_size=32"},{"metadata":{},"cell_type":"markdown","source":"## Define Data augmentation"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"# Define the image transformations here\ngen = ImageDataGenerator(horizontal_flip = True,\n                         vertical_flip = True,\n                         width_shift_range = 0.,\n                         height_shift_range = 0.,\n                         channel_shift_range=0,\n                         zoom_range = 0.5,\n                         rotation_range = 10)\n\n# Here is the function that merges our two generators\n# We use the exact same generator with the same random seed for both the y and angle arrays\ndef gen_flow_for_two_inputs(X1, X2, y):\n    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n    while True:\n            X1i = genX1.next()\n            X2i = genX2.next()\n            #Assert arrays are equal - this was for peace of mind, but slows down training\n            #np.testing.assert_array_equal(X1i[0],X2i[0])\n            yield [X1i[0], X2i[1]], X1i[1]\n\n# Finally create generator\ndef get_callbacks(filepath, patience=2):\n   #es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n   es = EarlyStopping('val_loss', patience=20, mode=\"min\")\n   msave = ModelCheckpoint(filepath, save_best_only=True)\n   return [es, msave]\n"},{"metadata":{},"cell_type":"markdown","source":"## Define Model "},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"def getVggAngleModel():\n    input_2 = Input(shape=[1], name=\"angle\")\n    angle_layer = Dense(1, )(input_2)\n    base_model = VGG16(weights='imagenet', include_top=False, \n                 input_shape=X_train.shape[1:], classes=1)\n    x = base_model.get_layer('block5_pool').output\n    x = GlobalMaxPooling2D()(x)\n    base_model2 = keras.applications.mobilenet.MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train.shape[1:])\n\n    x2 = base_model2.output\n    x2 = GlobalAveragePooling2D()(x2)\n\n    merge_one = concatenate([x, x2, angle_layer])\n\n    merge_one = Dropout(0.6)(merge_one)\n    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n    \n    model = Model(input=[base_model.input, input_2], output=predictions)\n    \n    sgd = Adam(lr=1e-4) #SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(loss='binary_crossentropy',\n                  optimizer=sgd,\n                  metrics=['accuracy'])\n    return model\n"},{"metadata":{},"cell_type":"markdown","source":"## Define kfold CV"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"\n#Using K-fold Cross Validation with Data Augmentation.\ndef myAngleCV(X_train, X_angle, X_test):\n    K=5\n    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n    y_test_pred_log = 0\n    y_train_pred_log=0\n    y_valid_pred_log = 0.0*target_train\n    for j, (train_idx, test_idx) in enumerate(folds):\n        print('\\n===================FOLD=',j)\n        X_train_cv = X_train[train_idx]\n        y_train_cv = target_train[train_idx]\n        X_holdout = X_train[test_idx]\n        Y_holdout= target_train[test_idx]\n        \n        #Angle\n        X_angle_cv=X_angle[train_idx]\n        X_angle_hold=X_angle[test_idx]\n\n        #define file path and get callbacks\n        file_path = \"%s_aug_model_weights.hdf5\"%j\n        callbacks = get_callbacks(filepath=file_path, patience=10)\n        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n        galaxyModel= getVggAngleModel()\n        galaxyModel.fit_generator(\n                gen_flow,\n                steps_per_epoch=24,\n                epochs=100,\n                shuffle=True,\n                verbose=1,\n                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n                callbacks=callbacks)\n\n        #Getting the Best Model\n        galaxyModel.load_weights(filepath=file_path)\n        #Getting Training Score\n        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n        print('Train loss:', score[0])\n        print('Train accuracy:', score[1])\n        #Getting Test Score\n        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n        print('Test loss:', score[0])\n        print('Test accuracy:', score[1])\n\n        #Getting validation Score.\n        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n\n        #Getting Test Scores\n        temp_test=galaxyModel.predict([X_test, X_test_angle])\n        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n\n        #Getting Train Scores\n        temp_train=galaxyModel.predict([X_train, X_angle])\n        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n\n    y_test_pred_log=y_test_pred_log/K\n    y_train_pred_log=y_train_pred_log/K\n\n    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n    return y_test_pred_log\n"},{"metadata":{},"cell_type":"markdown","source":"## Run 5-fold cv\n(this code run 25 minutes locally on a GTX 1070)"},{"outputs":[],"execution_count":null,"metadata":{},"cell_type":"code","source":"preds=myAngleCV(X_train, X_angle, X_test)\n#Submission for each day.\nsubmission = pd.DataFrame()\nsubmission['id']=test['id']\nsubmission['is_iceberg']=preds\nsubmission.to_csv('sub.csv', index=False)"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"from IPython.display import FileLink\n#%cd $LESSON_HOME_DIR\nFileLink('sub.csv')"}],"nbformat":4}