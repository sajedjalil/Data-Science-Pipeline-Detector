{"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"name":"python","file_extension":".py","version":"3.6.3","mimetype":"text/x-python","pygments_lexer":"ipython3","nbconvert_exporter":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"cells":[{"metadata":{},"execution_count":null,"cell_type":"code","source":"import time\n\nimport pandas as pd\nimport numpy as np\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\n\nfrom sklearn.model_selection import train_test_split","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"def get_images(df):\n    '''Create 2-channel 'images'. Return normalised images.'''\n    \n    im1 = df.band_1.apply(np.array).apply(lambda x: x.reshape(75, 75)).tolist()\n    im2 = df.band_2.apply(np.array).apply(lambda x: x.reshape(75, 75)).tolist()\n    \n    im1 = np.array(im1)\n    im2 = np.array(im2)\n\n    images = np.stack([im1, im2], axis=3)\n    \n    # normalise images.\n    im_min = images.min(axis=(0, 1), keepdims=True)\n    im_max = images.max(axis=(0, 1), keepdims=True)\n    images = (images - im_min) / (im_max - im_min)\n    \n    return images","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"def create_model():\n    '''Create and return a keras model.'''\n    \n    model = Sequential()\n    \n    # input: 75x75 images with 2 channels \n    \n    # this applies 16 convolution filters of size 3x3 each.\n    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(75, 75, 2)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.5))\n\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    tensorboard = TensorBoard(log_dir='./logs/{}'.format(time.time()), batch_size=32)\n\n    return model, [tensorboard]","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"train = pd.read_json('../input/train.json')\nX = get_images(train)\ny = train.is_iceberg.values\n\ntrain = None\n\nX, Xt, y, yt = train_test_split(X, y, test_size=0.25)","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"model, callbacks = create_model()\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\nmodel.fit(X, y, validation_data=(Xt, yt), batch_size=32, epochs=5, callbacks=callbacks)","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"model.save('model.h5')","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"# create a submission\n\ntest = pd.read_json('../input/test.json')\nX = get_images(test)\n# make predictions\npredictions = model.predict_proba(X)\nsubmission = pd.DataFrame({'id': test['id'], 'is_iceberg': predictions[:, 0]})\nsubmission.to_csv('submission.csv', index=False)","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"","outputs":[]}],"nbformat":4}