{"cells":[{"outputs":[],"metadata":{"_cell_guid":"c8fce719-3599-43fc-bb00-22094f973975","_uuid":"ad2662b89d27ca32edade97f1167447d88f3f102"},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\npy.init_notebook_mode(connected = True)\nimport plotly.graph_objs as go\nimport seaborn as sns\nsns.set()","execution_count":1},{"source":"This notebook will show you how to use deep convolutional neural network with Noise-contrastive estimation.\n\nThe idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity.\n\nYou can read more about [NCE cost function here](http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf)","cell_type":"markdown","metadata":{}},{"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"df = pd.read_json('../input/train.json')\ndf.inc_angle = df.inc_angle.replace('na', 0)\ndf.inc_angle = df.inc_angle.astype(float).fillna(0.0)","execution_count":2},{"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1\"]])\nx_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2\"]])\nX_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n                          , x_band2[:, :, :, np.newaxis]\n                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\nX_angle_train = np.array(df.inc_angle)\ny_train = np.array(df[\"is_iceberg\"])","execution_count":3},{"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"# just take 200 dataset to do visualization\n# we assume this 200 able to generalize the whole dataset\n# if not enough, increase the number\nX_train = X_train[:500]\ny_train = y_train[:500].reshape((-1, 1))\nX_angle_train = X_angle_train[:500].reshape((-1, 1))\nlearning_rate = 0.001\nboundary = [-1, 1]\nbatch_size = 20\ndimension_size = 300\nepoch = 30","execution_count":4},{"outputs":[],"metadata":{},"cell_type":"code","source":"class Model:\n\n    def __init__(self, vocabulary_size):\n        self.X = tf.placeholder('float', [None, 75, 75, 3])\n        self.X_angle = tf.placeholder('float', (None, 1))\n        self.Y = tf.placeholder('float', [None, 1])\n\n        def conv_layer(x, conv, out_shape, name, stride = 1):\n            w = tf.Variable(tf.truncated_normal([conv, conv, int(x.shape[3]), out_shape]), name = name + '_w')\n            b = tf.Variable(tf.truncated_normal([out_shape], stddev = 0.01), name = name + '_b')\n            return tf.nn.conv2d(x, w, [1, stride, stride, 1], padding = 'SAME') + b\n\n        def pooling(x, k = 2, stride = 2):\n            return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, stride, stride, 1], padding = 'SAME')\n\n        with tf.name_scope(\"conv5-16\"):\n            conv1 = tf.nn.sigmoid(conv_layer(self.X, 5, 16, '16'))\n\n        with tf.name_scope(\"maxpool-1\"):\n            pooling1 = pooling(conv1)\n            \n        with tf.name_scope(\"conv5-32\"):\n            conv2 = tf.nn.sigmoid(conv_layer(pooling1, 5, 32, '32'))\n    \n        with tf.name_scope(\"maxpool-2\"):\n            pooling2 = pooling(conv2)\n\n        with tf.name_scope(\"conv5-64\"):\n            conv3 = tf.nn.sigmoid(conv_layer(pooling2, 5, 64, '64'))\n\n        with tf.name_scope(\"maxpool-3\"):\n            pooling3 = pooling(conv3)\n\n        with tf.name_scope(\"conv5-128\"):\n            conv4 = tf.nn.sigmoid(conv_layer(pooling3, 5, 128, '128'))\n\n        with tf.name_scope(\"maxpool-4\"):\n            pooling4 = pooling(conv4)\n            \n        with tf.name_scope(\"conv5-256\"):\n            conv5 = tf.nn.sigmoid(conv_layer(pooling4, 5, 256, '256'))\n\n        with tf.name_scope(\"maxpool-5\"):\n            pooling5 = pooling(conv5)\n\n        output_shape = int(pooling5.shape[1]) * int(pooling5.shape[2]) * int(pooling5.shape[3])\n        pooling5 = tf.reshape(pooling5, [-1, output_shape])\n        pooling5 = tf.concat([pooling5, self.X_angle], axis = 1)\n        embeddings = tf.Variable(tf.random_uniform([output_shape + 1, dimension_size], boundary[0], boundary[1]))\n        embeddings = tf.matmul(pooling5, embeddings)\n        nce_weights = tf.Variable(tf.truncated_normal([vocabulary_size, dimension_size], stddev = 1.0 / np.sqrt(dimension_size)))\n        nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n        self.loss = tf.reduce_mean(tf.nn.nce_loss(weights = nce_weights, biases = nce_biases, labels = self.Y,\n                                                  inputs = embeddings, num_sampled = batch_size, num_classes = vocabulary_size))\n\n        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.loss)\n        norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims = True))\n        self.normalized_embeddings = embeddings / norm","execution_count":5},{"outputs":[],"metadata":{},"cell_type":"code","source":"sess = tf.InteractiveSession()\nmodel = Model(X_train.shape[0])\nsess.run(tf.global_variables_initializer())\nfor i in range(epoch):\n    total_loss = 0\n    for k in range(0, (X_train.shape[0] // batch_size) * batch_size, batch_size):\n        loss, _ = sess.run([model.loss, model.optimizer], feed_dict = {model.X: X_train[k: k + batch_size, :, :, :], \n                                                                       model.X_angle: X_angle_train[k: k + batch_size, :],\n                                                                       model.Y: y_train[k: k + batch_size, :]})\n    total_loss += loss\n    print('epoch: ', i, 'avg loss: ', total_loss / (X_train.shape[0] // batch_size))","execution_count":6},{"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"vector_out = sess.run(model.normalized_embeddings, feed_dict = {model.X: X_train, model.X_angle: X_angle_train})","execution_count":7},{"outputs":[],"metadata":{},"cell_type":"code","source":"from sklearn.manifold import TSNE\nembed_2d = TSNE(n_components = 2).fit_transform(vector_out)\nembed_3d = TSNE(n_components = 3).fit_transform(vector_out)","execution_count":8},{"outputs":[],"metadata":{},"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nlabel = ['ship', 'ice']\ncolors = sns.color_palette(n_colors = len(label))\ny_train_reshape = y_train.reshape([-1])\nfor no, _ in enumerate(np.unique(y_train_reshape)):\n    plt.scatter(embed_2d[y_train_reshape == no, 0], embed_2d[y_train_reshape == no, 1], c = colors[no], label = label[no])\nplt.legend()\nplt.show()","execution_count":11},{"outputs":[],"metadata":{},"cell_type":"code","source":"data_graph = []\nfrom ast import literal_eval\n# i love these colors, dont judge me\ncolors = ['rgb(0,31,63)', 'rgb(255,133,27)']\nfor no, _ in enumerate(np.unique(y_train_reshape)):\n    graph = go.Scatter3d(\n    x = embed_3d[y_train_reshape == no, 0],\n    y = embed_3d[y_train_reshape == no, 1],\n    z = embed_3d[y_train_reshape == no, 2],\n    name = label[no],\n    mode = 'markers',\n    marker = dict(\n        size = 12,\n        line = dict(\n            color = '#%02x%02x%02x' % literal_eval(colors[no][3:]),\n            width = 0.5\n            ),\n        opacity = 0.5\n        )\n    )\n    data_graph.append(graph)\n    \nlayout = go.Layout(\n    scene = dict(\n        camera = dict(\n            eye = dict(\n            x = 0.7,\n            y = 0.7,\n            z = 0.7\n            )\n        )\n    ),\n    margin = dict(\n        l = 0,\n        r = 0,\n        b = 0,\n        t = 0\n    )\n)\nfig = go.Figure(data = data_graph, layout = layout)\npy.iplot(fig, filename = '3d-scatter')","execution_count":14},{"source":"Tada! It is beautiful! scattered neatly! I can say, this one is very hard to classify with perfect score","cell_type":"markdown","metadata":{}},{"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"","execution_count":null}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","version":"3.6.3","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python"}}}