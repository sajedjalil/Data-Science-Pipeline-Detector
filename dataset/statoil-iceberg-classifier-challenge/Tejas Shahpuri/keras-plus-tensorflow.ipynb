{"nbformat":4,"metadata":{"language_info":{"mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"cells":[{"source":"**Introduction**\nThis is actually my first public kernel, so i hope it will be useful for someone.\n\nBefore you read the notebook, it is immportant to know that this notebook is a compilation of already existing notebooks and ","metadata":{"_cell_guid":"19c5b317-002e-41a0-ab5f-c8719e0844a9","_uuid":"c49e418eac7d03e7ca798d07f59ccdcb4de759d4"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"9ff0feae-78ab-4148-9855-2bba378058f3","_uuid":"4e13a616a733fd882af0f5dce7b29014fc2568d3","collapsed":true},"source":"# Random initialization\nimport numpy as np\nnp.random.seed(98643)\nimport tensorflow as tf\ntf.set_random_seed(683)\n# Uncomment this to hide TF warnings about allocation\n#import os\n#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n# An image clearing dependencies\nfrom skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,\n                                 denoise_wavelet, estimate_sigma, denoise_tv_bregman, denoise_nl_means)\nfrom skimage.filters import gaussian\nfrom skimage.color import rgb2gray\n\n# Data reading and visualization\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Training part\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, GlobalAveragePooling2D, Lambda\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\n# Any results you write to the current directory are saved as output.","cell_type":"code"},{"source":"First of all, some data preprocessing is required.\n\nThe basic idea is that images, that provided in a dataset are very noisy and if we will get rid of granular noise, we will be able to predict better and construct noisy dataset by our own.\n\nIt is also interesting to train a denoising autoencoder on dataset in order to extract some global features that may be used further on model training.","metadata":{"_cell_guid":"c2f51a1a-07b9-4136-960f-ad3d58ffa5e8","_uuid":"23417302e3d1614ab7e065951476f4d4719ed840"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"d1fcdda8-0330-4cd7-830e-de0245242adc","_uuid":"1b6fc591056bf2bd10067bad260807f980a21474","collapsed":true},"source":"# Translate data to an image format\ndef color_composite(data):\n    rgb_arrays = []\n    for i, row in data.iterrows():\n        band_1 = np.array(row['band_1']).reshape(75, 75)\n        band_2 = np.array(row['band_2']).reshape(75, 75)\n        band_3 = band_1 / band_2\n\n        r = (band_1 + abs(band_1.min())) / np.max((band_1 + abs(band_1.min())))\n        g = (band_2 + abs(band_2.min())) / np.max((band_2 + abs(band_2.min())))\n        b = (band_3 + abs(band_3.min())) / np.max((band_3 + abs(band_3.min())))\n\n        rgb = np.dstack((r, g, b))\n        rgb_arrays.append(rgb)\n    return np.array(rgb_arrays)\n\ndef denoise(X, weight, multichannel):\n    return np.asarray([denoise_tv_chambolle(item, weight=weight, multichannel=multichannel) for item in X])\n\ndef smooth(X, sigma):\n    return np.asarray([gaussian(item, sigma=sigma) for item in X])\n\ndef grayscale(X):\n    return np.asarray([rgb2gray(item) for item in X])","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"64b46aeb-c4f8-4ae8-a523-511d821835d4","_uuid":"86d9241572a3c56a653f95a5a2b0c2ad7c0a1459","collapsed":true},"source":"train = pd.read_json(\"../input/train.json\")\ntrain.inc_angle = train.inc_angle.replace('na', 0)\ntrain.inc_angle = train.inc_angle.astype(float).fillna(0.0)\ntrain_all = True\n\n# These are train flags that required to train model more efficiently and \n# select proper model parameters\ntrain_b = True or train_all\ntrain_img = True or train_all\ntrain_total = True or train_all\npredict_submission = True and train_all\n\nclean_all = True\nclean_b = True or clean_all\nclean_img = True or clean_all\n\nload_all = False\nload_b = False or load_all\nload_img = False or load_all","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"0cbff33b-2d88-4dd3-a8da-c0f295ef87e2","_uuid":"fef3d7beed760212a77708cf2901b9b5a6b5bd34","collapsed":true},"source":"def create_dataset(frame, labeled, smooth_rgb=0.2, smooth_gray=0.5,\n                   weight_rgb=0.05, weight_gray=0.05):\n    band_1, band_2, images = frame['band_1'].values, frame['band_2'].values, color_composite(frame)\n    to_arr = lambda x: np.asarray([np.asarray(item) for item in x])\n    band_1 = to_arr(band_1)\n    band_2 = to_arr(band_2)\n    band_3 = (band_1 + band_2) / 2\n    gray_reshape = lambda x: np.asarray([item.reshape(75, 75) for item in x])\n    # Make a picture format from flat vector\n    band_1 = gray_reshape(band_1)\n    band_2 = gray_reshape(band_2)\n    band_3 = gray_reshape(band_3)\n    print('Denoising and reshaping')\n    if train_b and clean_b:\n        # Smooth and denoise data\n        band_1 = smooth(denoise(band_1, weight_gray, False), smooth_gray)\n        print('Gray 1 done')\n        band_2 = smooth(denoise(band_2, weight_gray, False), smooth_gray)\n        print('Gray 2 done')\n        band_3 = smooth(denoise(band_3, weight_gray, False), smooth_gray)\n        print('Gray 3 done')\n    if train_img and clean_img:\n        images = smooth(denoise(images, weight_rgb, True), smooth_rgb)\n    print('RGB done')\n    tf_reshape = lambda x: np.asarray([item.reshape(75, 75, 1) for item in x])\n    band_1 = tf_reshape(band_1)\n    band_2 = tf_reshape(band_2)\n    band_3 = tf_reshape(band_3)\n    #images = tf_reshape(images)\n    band = np.concatenate([band_1, band_2, band_3], axis=3)\n    X_angle = np.array(frame.inc_angle)\n    if labeled:\n        y = np.array(frame[\"is_iceberg\"])\n    else:\n        y = None\n    return y, X_angle, band, images","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"f241f481-e9c1-4d0d-a812-1299fb265b78","_uuid":"b2049e52259c4fe972d57fcfd812a1f07f230fab","collapsed":true},"source":"y_train, X_angles, X_b, X_images = create_dataset(train, True)","cell_type":"code"},{"source":"Plotting some random images to check how cleaning works","metadata":{"_cell_guid":"d6f276ea-3310-47b3-ae3b-64a989e946cc","_uuid":"1171fdd57902f437128ad68993b53bb4abc1e750"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"04733eaf-f5ec-470f-b2ad-1ff4d9cff16c","_uuid":"87138ec6a826b32958d52a3f1d10e78fe5744950","collapsed":true},"source":"fig = plt.figure(200, figsize=(15, 15))\nrandom_indicies = np.random.choice(range(len(X_images)), 9, False)\nsubset = X_images[random_indicies]\nfor i in range(9):\n    ax = fig.add_subplot(3, 3, i + 1)\n    ax.imshow(subset[i])\nplt.show()","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"4f2f8cd5-edf0-428f-87ab-49e3e903d15b","_uuid":"145b5b03f6bb12596fb39193311f7adc24f7d71a","collapsed":true},"source":"fig = plt.figure(202, figsize=(15, 15))\nband_1_x = train['band_1'].values\nsubset = np.asarray(band_1_x)[random_indicies]\nsubset = np.asarray([np.asarray(item).reshape(75, 75) for item in subset])\nfor i in range(9):\n    ax = fig.add_subplot(3, 3, i + 1)\n    ax.imshow(subset[i])\nplt.show()","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"4a3b4e1d-76f3-4997-b0ff-ec5cf851d94f","_uuid":"9fb9cd0f2101d4c6153bff7657bac0ebf6264f76","collapsed":true},"source":"fig = plt.figure(202, figsize=(15, 15))\nsubset = np.asarray(band_1_x)[random_indicies]\nsubset = denoise(np.asarray([np.asarray(item).reshape(75, 75) for item in subset]), 0.05, False)\nfor i in range(9):\n    ax = fig.add_subplot(3, 3, i + 1)\n    ax.imshow(subset[i])\nplt.show()","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"ea64172b-5723-4151-bf15-3f68e1955f85","_uuid":"194412e3605431fd760515aab788004ed5216112","collapsed":true},"source":"fig = plt.figure(202, figsize=(15, 15))\nsubset = np.asarray(band_1_x)[random_indicies]\nsubset = smooth(denoise(np.asarray(\n    [np.asarray(item).reshape(75, 75) for item in subset]), 0.05, False), 0.5)\nfor i in range(9):\n    ax = fig.add_subplot(3, 3, i + 1)\n    ax.imshow(subset[i])\nplt.show()","cell_type":"code"},{"source":"**A few words about model**\n\nThe model itself consists of 3 convolutional neural networks.\nTwo basic networks and one combined. The idea is to train two basic networks on different data representations and after that, using trained convolutional layers in combination to train common network.\n\nArchitecture for these networks is taken from notebook mentioned in the vere beginning.\n\nFor training i'm using 3 datasets, 1 that network sees only once and default keras val split for model selection.","metadata":{"_cell_guid":"b0e15210-f504-4c09-90a3-2c40e844b5b2","_uuid":"89f57998fdc5648a31bf0e79d4cf27b9b82e1098"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"f717c6d1-3663-4f1a-a6df-0a3b24f32a07","_uuid":"1f8cacdbedf830892f3c9a32fb294256c83278c4","collapsed":true},"source":"def get_model_notebook(angle, lr, decay, channels, relu_type='relu'):\n    # angle variable defines if we should use angle parameter or ignore it\n    input_1 = Input(shape=(75, 75, channels))\n    input_2 = Input(shape=[1])\n\n    fcnn = Conv2D(32, kernel_size=(3, 3), activation=relu_type)(input_1)\n    fcnn = MaxPooling2D((3, 3))(fcnn)\n    fcnn = Dropout(0.2)(fcnn)\n    fcnn = Conv2D(64, kernel_size=(3, 3), activation=relu_type)(fcnn)\n    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n    fcnn = Dropout(0.2)(fcnn)\n    fcnn = Conv2D(128, kernel_size=(3, 3), activation=relu_type)(fcnn)\n    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n    fcnn = Dropout(0.2)(fcnn)\n    fcnn = Conv2D(128, kernel_size=(3, 3), activation=relu_type)(fcnn)\n    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n    fcnn = Dropout(0.2)(fcnn)\n    fcnn = Flatten()(fcnn)\n    if angle:\n        local_input = [input_1, input_2]\n    else:\n        local_input = input_1\n    dense = Dropout(0.2)(fcnn)\n    dense = Dense(256, activation=relu_type)(dense)\n    partial_model = Model(input_1, fcnn)\n    dense = Dropout(0.2)(dense)\n    dense = Dense(128, activation=relu_type)(dense)\n    dense = Dropout(0.2)(dense)\n    dense = Dense(64, activation=relu_type)(dense)\n    dense = Dropout(0.2)(dense)\n    # For some reason i've decided not to normalize angle data\n    if angle:\n        dense = Concatenate()([dense, input_2])\n    else:\n        dense = dense\n    output = Dense(1, activation=\"sigmoid\")(dense)\n    model = Model(local_input, output)\n    optimizer = Adam(lr=lr, decay=decay)\n    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n    return model, partial_model\n","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"0ee9e3ac-ef51-46f0-9448-2c38a52f91c4","_uuid":"49a1ad046a2c70ba0196f37ec6d14289a37a3098","collapsed":true},"source":"def combined_model(m_b, m_img, lr, decay):\n    input_b = Input(shape=(75, 75, 3))\n    input_img = Input(shape=(75, 75, 3))\n    input_angular = Input(shape=[1])\n\n    # I've never tested non-trainable source models tho\n    #for layer in m_b.layers:\n    #    layer.trainable = False\n    #for layer in m_img.layers:\n    #    layer.trainable = False\n\n    m1 = m_b(input_b)\n    m2 = m_img(input_img)\n\n    # So, combine models and train perceptron based on that\n    # The iteresting idea is to use XGB for this task, but i actually hate this method\n    common = Concatenate()([m1, m2])\n    common = BatchNormalization()(common)\n    common = Dropout(0.3)(common)\n    common = Dense(2048, activation='relu')(common)\n    common = Dropout(0.3)(common)\n    common = Dense(1024, activation='relu')(common)\n    common = Dropout(0.3)(common)\n    common = Dense(512, activation='relu')(common)\n    common = Dropout(0.3)(common)\n    common = Concatenate()([common, BatchNormalization()(input_angular)])\n    output = Dense(1, activation=\"sigmoid\")(common)\n    model = Model([input_b, input_img, input_angular], output)\n   # optimizer = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=decay)\n    optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n    return model","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"3b06285d-d988-4ba9-8250-fe8f6e1f0378","_uuid":"653ef06b4f4d9dec9106046340c7249cbd2201e5","collapsed":true},"source":"def train_model(model, batch_size, epochs, checkpoint_name, X_train, y_train, verbose=2, val_data=None, val_split=0.15):\n    callbacks = [ModelCheckpoint(checkpoint_name, save_best_only=True, monitor='val_loss')]\n    try:\n        if val_data is None:\n            model.fit(X_train, y_train, epochs=epochs, validation_split=val_split,\n                      batch_size=batch_size, callbacks=callbacks, verbose=verbose, shuffle=True)\n        else:\n            x_val, y_val = val_data\n            model.fit(X_train, y_train, epochs=epochs, validation_data=[x_val, y_val],\n                      batch_size=batch_size, callbacks=callbacks, verbose=verbose, shuffle=True)\n    except KeyboardInterrupt:\n        if verbose > 0:\n            print('Interrupted')\n    if verbose > 0:\n        print('Loading model')\n    model.load_weights(filepath=checkpoint_name)\n    return model","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"6d7ceccc-7d33-4770-a421-b783e8543ae7","_uuid":"0ce5ff4f914fe83a2b3749d518daa6f2e066dbf7","collapsed":true},"source":"def get_angular_status(angle, x, x_a):\n    if angle:\n        result = [x, x_a]\n    else:\n        result = x\n    return result\n","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"14569e86-5c0b-4321-aba4-9728cfb08b7c","_uuid":"f96f5518de17746a228a7f200a1ec778c5ef5ff5","collapsed":true},"source":"#Train a particular model\ndef gen_model_weights(angle, lr, decay, channels, relu, batch_size, epochs, path_name, data, only_load=False, verbose=2):\n    X_train, X_angle_train, y_train, X_val, X_angles_val, y_val = data\n    X_train, X_angle_train, y_train = shuffle(X_train, X_angle_train, y_train, random_state=np.random.randint(1, 123))\n    model, partial_model = get_model_notebook(angle, lr, decay, channels, relu)\n    if only_load:\n        model.load_weights(path_name)\n        return model, partial_model\n    model = train_model(model, batch_size, epochs, path_name,\n                           get_angular_status(angle, X_train, X_angle_train), y_train, verbose=verbose)\n\n    if verbose > 0:\n        loss_val, acc_val = model.evaluate(get_angular_status(angle, X_val, X_angles_val), y_val,\n                               verbose=0, batch_size=batch_size)\n\n        loss_train, acc_train = model.evaluate(get_angular_status(angle, X_train, X_angle_train), y_train,\n                                       verbose=0, batch_size=batch_size)\n\n        print('Val/Train Loss:', str(loss_val) + '/' + str(loss_train), \\\n            'Val/Train Acc:', str(acc_val) + '/' + str(acc_train))\n    return model, partial_model","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"d0a6595b-85e0-4754-99fb-b50e02fbe35d","_uuid":"85650a871595e2e5bef756c99e0f85335912fa3d","collapsed":true},"source":"# Train all 3 models\ndef train_models(dataset, lr, batch_size, max_epoch, verbose=2, return_model=False):\n    X_angles, y_train, X_b, X_images = dataset\n    angle_b = True\n    angle_images = True\n    X_angles, X_angles_val,\\\n    y_train, y_val,\\\n    X_b, X_b_val,\\\n    X_images, X_images_val = train_test_split(X_angles, y_train, X_b, X_images, random_state=687, train_size=0.9)\n\n    if train_b:\n        if verbose > 0:\n            print('Training bandwidth network')\n        data_b1 = (X_b, X_angles, y_train, X_b_val, X_angles_val, y_val)\n        model_b, model_b_cut = gen_model_weights(angle_b, lr, 0, 3, 'relu', batch_size, max_epoch, 'model_b',\n                                             data_b1, only_load=load_b, verbose=verbose)\n\n    if train_img:\n        if verbose > 0:\n            print('Training image network')\n        data_images = (X_images, X_angles, y_train, X_b_val, X_angles_val, y_val)\n        model_images, model_images_cut = gen_model_weights(angle_images, lr, 0, 3, 'relu', batch_size, max_epoch, 'model_img',\n                                                       data_images, only_load=load_img, verbose=verbose)\n\n    if train_total:\n        common_model = combined_model(model_b_cut, model_images_cut, lr, 0)\n        common_x_train = [X_b, X_images, X_angles]\n        common_y_train = y_train\n        common_x_val = [X_b_val, X_images_val, X_angles_val]\n        common_y_val = y_val\n        if verbose > 0:\n            print('Training common network')\n        common_model = train_model(common_model, batch_size, max_epoch, 'common_check', common_x_train,\n                           common_y_train, verbose=verbose, val_split=0.2)\n\n        loss_val, acc_val = common_model.evaluate(common_x_val, common_y_val,\n                                           verbose=0, batch_size=batch_size)\n        loss_train, acc_train = common_model.evaluate(common_x_train, common_y_train,\n                                                  verbose=0, batch_size=batch_size)\n        if verbose > 0:\n            print('Loss:', loss_val, 'Acc:', acc_val)\n    if return_model:\n        return common_model\n    else:\n        return (loss_train, acc_train), (loss_val, acc_val)","cell_type":"code"},{"source":"Model parameters that are used in training assumes that you have enough computational power to process all the data.\n\n(Don't know if it is obvious or not) The important moment here is to save 3 sets, since if you are selecting model based on a validation set it affects final performance since it causes inderect observations of validation set and affect final evaluation score.","metadata":{"_cell_guid":"898ed975-40e4-405b-ace6-a9f48b1caf81","_uuid":"1f34a6875b19ce91b2a9706c956ff31773dfc87c"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"6a3c65dd-925c-47be-91bb-1180304daf07","_uuid":"2f9cdff24383457b318bf9a28232163f0f73a784","collapsed":true},"source":"# Best parameters i got are\n# epochs : 250\n# learning rate : 8e-5\n# batch size : 32\n# CARE: The image model is overfits with parameters used here\ncommon_model = train_models((X_angles, y_train, X_b, X_images), 5e-04, 32, 50, 1, return_model=True)","cell_type":"code"},{"source":"*The filtration step for RGB images may take a lot of time.*","metadata":{"_cell_guid":"6d0a910b-e01c-45bc-bb96-a00365f6236c","_uuid":"9762fc87115e1cce4fc3c7953443d3fd9c490b8f"},"cell_type":"markdown"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"ea13d6dc-a446-40cf-b159-27a387b79e1a","_uuid":"29e8fff0b5842f813ba289725c53ec43b9048032","collapsed":true},"source":"if predict_submission:\n    print('Reading test dataset')\n    test = pd.read_json(\"../input/test.json\")\n    test.inc_angle = test.inc_angle.replace('na', 0)\n    test.inc_angle = test.inc_angle.astype(float).fillna(0.0)\n    y_fin, X_angle_fin, X_fin_b, X_fin_img = create_dataset(test, False)\n    print('X shape:', X_fin_img.shape)\n    print('X angle shape:', X_angle_fin.shape)\n    print('Predicting')\n    prediction = common_model.predict([X_fin_b, X_fin_img, X_angle_fin], verbose=1, batch_size=32)\n    print('Submitting')\n    submission = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': prediction.reshape((prediction.shape[0]))})\n\n    submission.to_csv(\"./submission.csv\", index=False)\n    print('Done')","cell_type":"code"},{"source":"**TODO:**\n* Add features from https://www.kaggle.com/muonneutrino/exploration-transforming-images-in-python\n* Modify base model and train different models for pictures and bandwidth\n* Select denoising algorithm more meaningfully\n* Use XBG on output features of convolutional nets\n* Train denoising autoencoder on train and test data ot extract additional features and clean data\n* Data preprocessing parallelization","metadata":{"_cell_guid":"f7a67423-6de5-4af1-98b7-3c7ee58b294c","_uuid":"964e754449f42efd9594f6555aac4943887b942e"},"cell_type":"markdown"}],"nbformat_minor":1}