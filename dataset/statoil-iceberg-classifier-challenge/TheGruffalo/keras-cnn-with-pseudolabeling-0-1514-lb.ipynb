{"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"ce279432822b0fc2a3dc5a01dbcd115cb0ae0356","_cell_guid":"c224351a-5175-4421-82e6-4afc2f56c066"},"source":"This Kernal implements a Keras + Tensorflow CNN for the StatOil Iceberg competition. It has yielded results of 0.1995 on the leaderboard. With some tuning and image filtering plus more of an inclusion of the incident angle, a better result could be yielded I'm sure.\n\nThe input is a 75x75x3 set of images. The output is a binary 0/1 where 1 is noteed as an iceberg. \n\nThe set of images are band_1 (HH), band_2 (HV), and an combined band which would be (HH dot HV)/constant. However, since we are working with the images in dB, the 3rd band is modified to compenate for the log function yielding band_1 + band_2 -log(constant). The last term is neglected as when the images are scaled the 3rd term would be removed by the mathematics anyway.\n\nThis and other information can be found from: https://earth.esa.int/c/document_library/get_file?folderId=409229&name=DLFE-5566.pdf"},{"cell_type":"markdown","metadata":{"_uuid":"89afc499bdc0d54df2878813887e5c841de2724a","_cell_guid":"54385d02-b920-489f-a284-9c5a47f7db17"},"source":"## Imports"},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport cv2 # Used to manipulated the images \nnp.random.seed(1337) # The seed I used - pick your own or comment out for a random seed. A constant seed allows for better comparisons though\n\n# Import Keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, KFold\nfrom scipy.ndimage.filters import uniform_filter\nfrom scipy.ndimage.measurements import variance","metadata":{"_uuid":"0801b3ee5a4b9aa92115d07e8a6b45d3d90b920d","collapsed":true,"_cell_guid":"a3ec2abe-091b-4373-b4f4-6b6ce0eae741"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"5221ea258687d1eeb908b35e07adf5d0f602fdf9","_cell_guid":"4418a5a9-a5be-4796-a82a-2f5b6abe2fb8"},"source":"## Load Training Data"},{"cell_type":"code","source":"df_train = pd.read_json('../input/train.json') # this is a dataframe","metadata":{"_uuid":"dacc75fbec2b870839c7f164db3e556464e79933","collapsed":true,"_cell_guid":"152fef62-7399-4a3f-939a-23b972460e05"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"d04abab8263c2275627d917a0a961249bfc9cb20","_cell_guid":"2b8f3a77-cc5d-4562-b954-917186f53de4"},"source":"Need to reshape and feature scale the images:"},{"cell_type":"code","source":"def get_scaled_imgs(df):\n    imgs = []\n    \n    for i, row in df.iterrows():\n        #make 75x75 image\n        band_1 = np.array(row['band_1']).reshape(75, 75)\n        band_2 = np.array(row['band_2']).reshape(75, 75)\n        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n        \n        # use a lee filter to help with speckling\n        band_1 = lee_filter(band_1,4)\n        band_2 = lee_filter(band_2,4)\n        band_3 = lee_filter(band_3,4)\n        \n        # Rescale\n        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n\n        imgs.append(np.dstack((a, b, c)))\n\n    return np.array(imgs)","metadata":{"_uuid":"b80987bc2dea30f0617ee37e55879d71f7c733b6","collapsed":true,"_cell_guid":"d053c62c-0f2b-47ac-a7c2-3f0fa6c19027"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def lee_filter(img, size):\n    \n    img_mean = uniform_filter(img, (size, size))\n    img_sqr_mean = uniform_filter(img**2, (size, size))\n    img_variance = img_sqr_mean - img_mean**2\n\n    overall_variance = variance(img)\n\n    img_weights = img_variance**2 / (img_variance**2 + overall_variance**2)\n    img_output = img_mean + img_weights * (img - img_mean)\n\n    return img_output","metadata":{"_uuid":"82d4d9b669ed64d9268f5103fcddf8bba8164c2c","collapsed":true,"_cell_guid":"958628eb-ba93-428c-ae30-f1befb671e8d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Xtrain = get_scaled_imgs(df_train)","metadata":{"_uuid":"021884ba14db13799bfb861d2fd676d235f8f47c","collapsed":true,"_cell_guid":"8ce89919-19d1-4f6c-93e8-a06133c5f133"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"339d03794161f6321a26c7fc84f801379b80002d","_cell_guid":"8b7ea6b2-c22a-4250-88aa-9dde5308570b"},"source":"Get the response variable \"is_iceberg\""},{"cell_type":"code","source":"Ytrain = np.array(df_train['is_iceberg'])","metadata":{"_uuid":"5b75304abe871357500a437aa043a15937d825b9","collapsed":true,"_cell_guid":"422c200f-5ab9-4d10-96c8-9bdaa22254a1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"474e906d3fc24b8cdd1306f85e65d1654d1f8875","_cell_guid":"ad32b1c1-0959-4c31-b6c5-73e20d5b1ecf"},"source":"Some of the incident angle from the satellite are unknown and marked as \"na\". Replace these na with 0 and find the indices where the incident angle is >0 (this way you can use a truncated set or the full set of training data)."},{"cell_type":"code","source":"df_train.inc_angle = df_train.inc_angle.replace('na',0)\nidx_tr = np.where(df_train.inc_angle>0)","metadata":{"_uuid":"62927b398cbb56744a8b97e5a9b6bb67e73c8e33","collapsed":true,"_cell_guid":"9f655f27-0af0-490e-9a26-2edb9b4cf07d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"130c604e76400c61eddc3d63de6cff183e0438e9","_cell_guid":"04d881e5-9ae0-4b21-b47e-ae5773394161"},"source":"You can now use the option of training with only known incident angles or the whole set. I found slightly better results training with only the known incident angles so:"},{"cell_type":"code","source":"Ytrain = Ytrain[idx_tr[0]]\nXtrain = Xtrain[idx_tr[0],...]","metadata":{"_uuid":"f741670d5788e873ba03e365c35c8b55c9b7bf12","collapsed":true,"_cell_guid":"1ac8fd0c-3280-4f18-9e1f-babd67d9d646"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"70298628709d0f50853afed7b020e4f3ca718314","_cell_guid":"33b155b4-5a61-4820-b360-bab442404065"},"source":"Similarly, get the test data and separate it out:"},{"cell_type":"code","source":"df_test = pd.read_json('../input/test.json')\ndf_test.inc_angle = df_test.inc_angle.replace('na',0)\nXtest = (get_scaled_imgs(df_test))","metadata":{"_uuid":"2959170c6246e1ce5720564aa4cecf749fdaaa98","collapsed":true,"_cell_guid":"f50619ff-ff80-40a7-9c7d-1a6707718467"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"42c519584cba592c06a92185208b7d3bbef6e7fe","_cell_guid":"8325bbe8-6ac3-4a8f-a64c-b57b7b9ac314"},"source":"## Adding images for training"},{"cell_type":"markdown","metadata":{"_uuid":"850f3f199cb368d3cec2e835818df6c8f115f55a","_cell_guid":"1591ecda-0e38-411a-8fb8-5bfef5c7dbae"},"source":"Now, a big improvement I had was by adding more data to train on. I did this by simply including horizontally and vertically flipped data. Using OpenCV this is easily done."},{"cell_type":"code","source":"def get_augment(imgs):\n    \n    more_images = []\n    vert_flip_imgs = []\n    hori_flip_imgs = []\n      \n    for i in range(0,imgs.shape[0]):\n        a=imgs[i,:,:,0]\n        b=imgs[i,:,:,1]\n        c=imgs[i,:,:,2]\n        \n        av=cv2.flip(a,1)\n        ah=cv2.flip(a,0)\n        bv=cv2.flip(b,1)\n        bh=cv2.flip(b,0)\n        cv=cv2.flip(c,1)\n        ch=cv2.flip(c,0)\n        \n        vert_flip_imgs.append(np.dstack((av, bv, cv)))\n        hori_flip_imgs.append(np.dstack((ah, bh, ch)))\n      \n    v = np.array(vert_flip_imgs)\n    h = np.array(hori_flip_imgs)\n       \n    more_images = np.concatenate((imgs,v,h))\n    \n    return more_images\n","metadata":{"_uuid":"249411ae8bc7f222434f30a033c22c4d74f94e5a","collapsed":true,"_cell_guid":"543a9d88-332a-4839-a17d-aac89a493344"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"1f69c268324d4ac1490105943ca0b73d563d5ad9","_cell_guid":"e1eb83cb-512b-4602-9be2-728c2ac566d9"},"source":"## CNN Keras Model"},{"cell_type":"markdown","metadata":{"_uuid":"5c7a36e1f4c7b3411cb013f7599ea332cc313a76","_cell_guid":"31eed236-5d75-44ad-99e9-76bb42cb11b3"},"source":"Now the nitty gritty of the situation, the CNN model. This is a simplistic model that should give reasonable results. It is not tuned that well and there are plenty of options and changes you can try so as to improve it. At least you will get the idea:"},{"cell_type":"code","source":"def getModel():\n    #Build keras model\n    \n    model=Sequential()\n    \n    # CNN 1\n    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n    model.add(Dropout(0.2))\n\n    # CNN 2\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Dropout(0.2))\n\n    # CNN 3\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Dropout(0.2))\n\n    #CNN 4\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Dropout(0.2))\n\n    # You must flatten the data for the dense layers\n    model.add(Flatten())\n\n    #Dense 1\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.2))\n\n    #Dense 2\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.2))\n\n    # Output \n    model.add(Dense(1, activation=\"sigmoid\"))\n\n    optimizer = Adam(lr=0.001, decay=0.0)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    \n    return model","metadata":{"_uuid":"245aa8795aff036873e58a6a7ee53e42072fef60","collapsed":true,"_cell_guid":"15efe883-ee27-4133-97b1-54755b16d744"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"4339c23b060bcd103536125a125943ad01ba3d80","_cell_guid":"7069f1ee-6923-4fd3-abff-048411d44459"},"source":"## Stratified splitting"},{"cell_type":"markdown","metadata":{"_uuid":"2ea0d79a0eec6ade032e72224043c795c9286d66","_cell_guid":"ce830e78-c2d5-464b-98b1-4d95c110c738"},"source":"One issue with the previous kernel was that after augmenting the iamges, teh data was split. This almost certainly results in unfavourable training / vaildation sets. Therefore I have modified the code to do a stratified split on the data."},{"cell_type":"code","source":"sss = StratifiedShuffleSplit(n_splits=5,test_size=0.2)\n\nfor train_index, cv_index in sss.split(Xtrain, Ytrain):\n\n    X_train, X_cv = Xtrain[train_index], Xtrain[cv_index]\n    y_train, y_cv = Ytrain[train_index], Ytrain[cv_index]\n    Xtr_more = get_augment(X_train) \n    Xcv_more = get_augment(X_cv) \n    Ytr_more = np.concatenate((y_train,y_train,y_train))\n    Ycv_more = np.concatenate((y_cv,y_cv,y_cv))\n","metadata":{"_uuid":"c9a355526eb0f6dc0f5184dd71ffca84d4e90d92","collapsed":true,"_cell_guid":"1849105f-4999-4fe6-93bf-8744dee7121b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"086b7516a765aef3a74619d6c5f7991457014ef8","_cell_guid":"e2138004-682c-41d4-941e-2591adfe0bb3"},"source":"Now get the model and get ready to train"},{"cell_type":"code","source":"    model = getModel()\n    model.summary()\n\n    batch_size = 32\n    \n    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n    mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')","metadata":{"_uuid":"f9bcb0ca5026f10f5ef7d0a232e94e8e1a9f24cd","collapsed":true,"_cell_guid":"710fd0e1-6ae5-40b5-bc79-e1495020bea4"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"3dc7c180909eeef1b331365bce43631e9956aaad","_cell_guid":"abc46efd-2f00-4ce4-8aa7-61195559e44c"},"source":"Now train the model!"},{"cell_type":"code","source":"    model.fit(Xtr_more, Ytr_more, batch_size=batch_size, epochs=50, verbose=0, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)","metadata":{"_uuid":"bc5e49c662111c48039c9e7b93f35a45eefc406d","collapsed":true,"_cell_guid":"6a7ea293-d02c-4d8a-99bb-7c76eaf00824"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"a87bdaa52a1d28d00c317c3be93214f91592e2d4","_cell_guid":"43eaed4e-9074-45c4-9382-8936a38831fa"},"source":"Load the best weights, check scores, and predict values"},{"cell_type":"code","source":"    model.load_weights(filepath = '.mdl_wts.hdf5')\n\n    score = model.evaluate(Xcv_more, Ycv_more, verbose=2)\n    print('CV loss:', score[0])\n    print('CV accuracy:', score[1])\n\n    pt = model.predict(Xcv_more)\n    mse = (np.mean((pt-Ycv_more)**2))\n    print('CV MSE: ', mse)\n    \n    predA_test = model.predict(Xtest) # Here, we make the predictions for use in pseudo-labelling","metadata":{"_uuid":"76fa8a06ac9df4f280b58d717ca709e8d3014a39","collapsed":true,"_cell_guid":"94ab67df-cea5-47a0-ba1d-2c7994aaadc7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    idx_pred_1 = (np.where(predA_test[:,0]>0.95))\n    idx_pred_0 = (np.where(predA_test[:,0]<0.05))\n    \n    Xtrain_pl = np.concatenate((Xtrain,Xtest[idx_pred_1[0],...],Xtest[idx_pred_0[0],...]))\n    Ytrain_pl = np.concatenate((Ytrain,np.ones(idx_pred_1[0].shape[0]),np.zeros(idx_pred_0[0].shape[0])))\n    \n    pl_kf = KFold(n_splits=5, shuffle=True)\n\n    for train_pl_index, cv_pl_index in pl_kf.split(Xtrain_pl, Ytrain_pl):\n        Xtrain_pl, Xpl_cv = Xtrain_pl[train_pl_index], Xtrain_pl[cv_pl_index]\n        Ytrain_pl, Ypl_cv = Ytrain_pl[train_pl_index], Ytrain_pl[cv_pl_index]\n        break #you can remove this to add more folds - set to one for demo\n       \n    model = getModel()\n    \n    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n    mcp_save = ModelCheckpoint('.mdl_wtsPL.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1, epsilon=1e-4, mode='min')\n    history_pl = model.fit(Xtrain_pl, Ytrain_pl, batch_size=batch_size, epochs=30, verbose=0, callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_data=(Xpl_cv,Ypl_cv))\n    ","metadata":{"_uuid":"d0d520f95af61ab09926daf32df05a764dbcc3e1","collapsed":true,"_cell_guid":"c97659cd-2269-4720-8c23-45f6f8c23314"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"5fcd861ef3374914932789f8154bd5f2bdc21115","_cell_guid":"25e7fa72-f0dc-44a7-874a-38e585edcd7c"},"source":"## Results"},{"cell_type":"markdown","metadata":{"_uuid":"44e83e6a6c1a33ba41897b928f1d9da3a4f4167c","_cell_guid":"d5288e2f-8c64-4a1b-a993-7bd188cb5fc8"},"source":"Load the best weights and check various loss and accuracy data."},{"cell_type":"code","source":"    model.load_weights(filepath = '.mdl_wtsPL.hdf5')\n    \n    scorePLCV = model.evaluate(Xpl_cv, Ypl_cv, verbose=0)\n    print('Train PL CV score:', scorePLCV[0])\n    print('Train PL CV accuracy:', scorePLCV[1])\n    \n    score = model.evaluate(Xtrain_pl, Ytrain_pl, verbose=0)\n    print('Train PL score:', score[0])\n    print('Train PL accuracy:', score[1])\n    \n    \n    score = model.evaluate(X_cv, y_cv, verbose=0)\n    print('X_cv score:', score[0])\n    print('X_cv accuracy:', score[1])\n    \n    score = model.evaluate(Xtrain, Ytrain, verbose=0)\n    print('Train score:', score[0])\n    print('Train accuracy:', score[1])\n","metadata":{"_uuid":"ab7bf223eaf1925d0cc21fab025d0651f4fa795b","collapsed":true,"_cell_guid":"a73ada33-6ff9-48ff-8274-1f5f49c78776"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"72dc5af9ace215cb68b53c98a19aff2fed78ff4a","_cell_guid":"d44f1660-7e61-408e-bd1c-aa9ac96a636f"},"source":"Now, to make a submissionm train the model and output a csv file."},{"cell_type":"code","source":"    predA_test = model.predict(Xtest)\n    \n    submission = pd.DataFrame({'id': df_test[\"id\"], 'is_iceberg': predA_test.reshape((predA_test.shape[0]))})\n    print(submission.head(10))\n    \n    submission.to_csv(INPUT_PATH + '20180101_submission'+'.csv', index=False)","metadata":{"_uuid":"3cede4a6614ffe2c539728dbb0c66a13886d3f31","collapsed":true,"_cell_guid":"56b9ee2c-9e95-41e5-b2c1-f309df0fa9b2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"702ea8b5e06ad2134901b8f5c565c9b79545097a","_cell_guid":"9a2c615f-21ce-48fa-87e8-574dd2ea6a74"},"source":"The best submission with this I received was 0.1516 on the leaderboard with ensembling some results. Have a go and see how well you can do! If you make some improvements or if I've made errors, please let me know too ;-)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.4","pygments_lexer":"ipython3","name":"python"}},"nbformat_minor":1}