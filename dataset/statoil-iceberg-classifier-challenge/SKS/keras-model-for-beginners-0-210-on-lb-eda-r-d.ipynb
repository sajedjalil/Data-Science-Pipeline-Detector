{"metadata":{"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","name":"python","version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"cells":[{"outputs":[],"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"metadata":{"collapsed":true,"_uuid":"f57e59e8589cb94001d8673fb737a4e0d96852bd","_cell_guid":"dbf2ff22-712b-4fc2-8687-99caa9bf07d8"}},{"cell_type":"markdown","source":"This kernel is specifically is for Beginners who want's to experiment building CNN using Keras. By using this kernel, you can expect to get good score and also learn keras. \nKeras is simple frameworks where we can initialize the model and keep stacking the layers we want. It makes building deep neural networks very easy.","metadata":{"_uuid":"113b5b8f58952300f5a35a3999788e2d076beeab","_cell_guid":"2805f6da-0df3-41f1-977a-547dac26a11f"}},{"outputs":[],"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom os.path import join as opj\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport pylab\nplt.rcParams['figure.figsize'] = 10, 10\n%matplotlib inline","execution_count":null,"metadata":{"collapsed":true,"_uuid":"58c82d3b3c4b4305b388a6ac4eeca49d600f9105","_cell_guid":"ea3f4874-a9aa-42f1-9605-b1784a6f48ba"}},{"outputs":[],"cell_type":"code","source":"#Load the data.\ntrain = pd.read_json(\"../input/train.json\")","execution_count":null,"metadata":{"collapsed":true,"_uuid":"7a7f3af5ef279a9ed26c4d9ee764bd1fb4bdf10e","_cell_guid":"804d3969-9035-4ceb-bb65-1b8549d729ec"}},{"outputs":[],"cell_type":"code","source":"test = pd.read_json(\"../input/test.json\")","execution_count":null,"metadata":{"collapsed":true,"_uuid":"2c18cf164fbbc6d1c29e9c668cbfcd7a1ea10824","_cell_guid":"7b546aab-7b7d-4cde-91cc-e794fd4041bd"}},{"cell_type":"markdown","source":"#Intro about the Data.\n\nSentinet -1 sat is at about 680 Km above earth. Sending pulses of signals at a particular angle of incidence and then recoding it back. Basically those reflected signals are called backscatter. The data we have been given is backscatter coefficient which is the conventional form of backscatter coefficient given by:\n\n$σo (dB) = βo (dB) + 10log10 [ sin(ip) / sin (ic)] $\n\nwhere\n1. ip=is angle of incidence for a particular pixel\n2. 'ic ' is angle of incidence for center of the image\n3. K =constant.\n\nWe have been given $σo$ directly in the data. \n###Now coming to the features of $σo$\nBasically σo varies with the surface on which the signal is scattered from. For example, for a particular angle of incidence, it varies like:\n*             WATER...........           SETTLEMENTS........           AGRICULTURE...........          BARREN........\n\n1.**HH:**     -27.001   ................                     2.70252       .................                -12.7952        ................    -17.25790909\n\n2.**HV: **      -28.035      ................            -20.2665             ..................          -21.4471       .................     -20.019\n\nAs you can see, the HH component varies a lot but HV doesn't.\n**I don't have the data for scatter from ship, but being a metal object, it should vary differently as compared to ice object.**\n\n###WTF is HH HV?\n\nOk, so this Sentinal Settalite is equivalent to RISTSAT(an Indian remote sensing Sat) and they only Transmit pings in H polarization, **AND NOT IN V polarization**.  Those H-pings gets scattered, objects change their polarization and returns as a mix of H and V.\n**Since Sentinel has only H-transmitter, return signals are of the form of HH and HV only**. Don't ask why VV is not given(because Sentinel don't have V-ping transmitter).\n\nNow coming to features, for the purpose of this demo code, I am extracting all two bands and taking avg of them as 3rd channel to create a 3-channel RGB equivalent. \n","metadata":{"_uuid":"f5b6c2ba24e6bf5726f8551cdeeeaf931184c2bc","_cell_guid":"e178779f-0698-47cd-9be5-50f9c9590089"}},{"outputs":[],"cell_type":"code","source":"#Generate the training data\n#Create 3 bands having HH, HV and avg of both\nX_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nX_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\nX_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"5292632717f11cd01c135dfabfd3cda9318cc639","_cell_guid":"829bf7db-fab1-4a2d-9562-0a37c6390d2a"}},{"outputs":[],"cell_type":"code","source":"#Take a look at a iceberg\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\ndef plotmy3d(c, name):\n\n    data = [\n        go.Surface(\n            z=c\n        )\n    ]\n    layout = go.Layout(\n        title=name,\n        autosize=False,\n        width=700,\n        height=700,\n        margin=dict(\n            l=65,\n            r=50,\n            b=65,\n            t=90\n        )\n    )\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig)\nplotmy3d(X_band_1[12,:,:], 'iceberg')","execution_count":null,"metadata":{"collapsed":true,"_uuid":"01b69c50c6425d7d35b9bbefca7c06ea4bf1214b","_cell_guid":"a95eedd5-fc75-4834-a817-e3ad700923f5"}},{"cell_type":"markdown","source":"That's a cool looking iceberg we have. Remember, in radar data, the shape of the iceberg is going to be like a mountain as shown in here. Since this is not a actual image but scatter from radar, the shape is going to have peaks and distortions like these. The shape of the ship is going to be like a point, may be like a elongated point. From here the structural differences arise and we can exploit those differences using a CNN. It would be helpful if we can create composite images using the backscatter from radar.","metadata":{"_uuid":"1c65412c80ff504df19d55aa14093ebcd1028e6a","_cell_guid":"cd7ea3c1-f039-445e-b5da-adfb608930d7"}},{"outputs":[],"cell_type":"code","source":"plotmy3d(X_band_1[14,:,:], 'Ship')","execution_count":null,"metadata":{"collapsed":true,"scrolled":false,"_uuid":"ab163fd947f3f108eacb0d367bf62505b0b9df9b","_cell_guid":"f78d43c6-c83e-47e3-a279-4dc8d3481c6c"}},{"cell_type":"markdown","source":"That's a ship, looks like a elongated point. We don't have much resolution in images to visualize the shape of the ship. However CNN is here to help. There are few papers on ship iceberg classification like this:\nhttp://elib.dlr.de/99079/2/2016_BENTES_Frost_Velotto_Tings_EUSAR_FP.pdf\nHowever their data have much better resolution so I don't  feel that the CNN they used would be suitable here.","metadata":{"_uuid":"f907f993a1c63f4519872ecb381021c1a0dce2ca","_cell_guid":"1e2a6f33-992a-435e-be65-5ee614e6f7ba"}},{"cell_type":"markdown","source":"Get back to building a CNN using Keras. Much better frameworks then others. You will enjoy for sure.","metadata":{"_uuid":"906b685c8ab2b91b3b9e4baffb65ad1c1aa028c3","_cell_guid":"6c0c41e0-b95e-4129-a95e-06cd6808553d"}},{"outputs":[],"cell_type":"code","source":"#Import Keras.\nfrom matplotlib import pyplot\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras import initializers\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping","execution_count":null,"metadata":{"collapsed":true,"_uuid":"7a68a94f8c617209dfe56a58e291193e963d0f62","_cell_guid":"fb15bc53-becc-4e87-88ce-3bc99d45358d"}},{"outputs":[],"cell_type":"code","source":"#define our model\ndef getModel():\n    #Building the model\n    gmodel=Sequential()\n    #Conv Layer 1\n    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n    gmodel.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 2\n    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 3\n    gmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Conv Layer 4\n    gmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    gmodel.add(Dropout(0.2))\n\n    #Flatten the data for upcoming dense layers\n    gmodel.add(Flatten())\n\n    #Dense Layers\n    gmodel.add(Dense(512))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Dropout(0.2))\n\n    #Dense Layer 2\n    gmodel.add(Dense(256))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Dropout(0.2))\n\n    #Sigmoid Layer\n    gmodel.add(Dense(1))\n    gmodel.add(Activation('sigmoid'))\n\n    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n    gmodel.compile(loss='binary_crossentropy',\n                  optimizer=mypotim,\n                  metrics=['accuracy'])\n    gmodel.summary()\n    return gmodel\n\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\nfile_path = \".model_weights.hdf5\"\ncallbacks = get_callbacks(filepath=file_path, patience=5)\n","execution_count":null,"metadata":{"collapsed":true,"_uuid":"4602792c9d531903bd65c3b127a1e6be2c444b2d","_cell_guid":"d7a4c0cc-0e96-46ea-960c-89bb80e11b56"}},{"outputs":[],"cell_type":"code","source":"target_train=train['is_iceberg']\nX_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=1, train_size=0.75)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"a883659e53709da950d04a4e5349c66d77a9422f","_cell_guid":"1d690d4a-09ca-417c-8090-2aa417c514dd"}},{"outputs":[],"cell_type":"code","source":"#Without denoising, core features.\nimport os\ngmodel=getModel()\ngmodel.fit(X_train_cv, y_train_cv,\n          batch_size=24,\n          epochs=50,\n          verbose=1,\n          validation_data=(X_valid, y_valid),\n          callbacks=callbacks)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"4e6dab11165b7d9515eb32b698851b260f0d941f","_cell_guid":"d6bb750a-e882-4429-ad23-4392389f427f"}},{"cell_type":"markdown","source":"###Though the score may be different here,  it works good on LB, I got 0.210 score.","metadata":{"_uuid":"04da75db4d60b76ae357503ea1178808e1026b56","_cell_guid":"923850b1-707e-41e7-bdcb-b5d0633fb12f"}},{"outputs":[],"cell_type":"code","source":"gmodel.load_weights(filepath=file_path)\nscore = gmodel.evaluate(X_valid, y_valid, verbose=1)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"metadata":{"collapsed":true,"_uuid":"0fa65f37d198cd6301376f179d9de0ccc1d40db3","_cell_guid":"079f0a8d-d2a5-4154-b37f-b425333e4ada"}},{"outputs":[],"cell_type":"code","source":"\nX_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nX_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\nX_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n                          , X_band_test_2[:, :, :, np.newaxis]\n                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\npredicted_test=gmodel.predict_proba(X_test)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"27f021784da863a2ad960a96b9c7394f25521802","_cell_guid":"7cae1458-a566-4714-8b80-0b23fe88509c"}},{"outputs":[],"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['id']=test['id']\nsubmission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\nsubmission.to_csv('sub.csv', index=False)","execution_count":null,"metadata":{"collapsed":true,"_uuid":"b34412c33fe8250df3285867d9a13e4bd08e8c12","_cell_guid":"da3618f6-6e0a-475c-a390-7e17f5406c1a"}},{"cell_type":"markdown","source":"#### Conclusion\nTo increase the score, I have tried Speckle filtering, Indicence angle normalization and other preprocessing and they don't seems to work.  You may try and see but for me they are not giving any good results.\n\nYou can't be on top-10 using this kernel, so here is one beautiful peice of information. The test dataset contain 8000 images, We can exploit this. We can do pseudo labelling to increase the predictions. Here is the article related to that:\nhttps://towardsdatascience.com/simple-explanation-of-semi-supervised-learning-and-pseudo-labeling-c2218e8c769b\n\nUpvote if you liked this kernel.","metadata":{"collapsed":true,"_uuid":"741f9696d91da6af29266fb199a6c2fb80d26dfe","_cell_guid":"a5140949-c867-43fd-baba-49e57bec44cf"}},{"outputs":[],"cell_type":"code","source":"","execution_count":null,"metadata":{"collapsed":true,"_uuid":"962411dc0d6a00c1730bfd22767542210c36f751","_cell_guid":"637e3662-38ac-4fa6-8065-48c8105026a9"}}],"nbformat_minor":1}