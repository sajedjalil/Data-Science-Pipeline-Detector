{"nbformat_minor":1,"cells":[{"metadata":{"_kg_hide-output":false,"_uuid":"797e6828462473335764b3ccca82c625c7d545ab","_cell_guid":"292b7729-4d40-4068-a4e8-6871d7d18de1"},"outputs":[],"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras as k\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\ntrain = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')\ntrain.inc_angle = train.inc_angle.replace('na', 0)\ntrain = train[train.inc_angle>0]\ntest.inc_angle = test.inc_angle.replace('na', 0)\nprint('len of train set',len(train))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code"},{"metadata":{"collapsed":true,"_uuid":"a25d62dabf01cac8231a380b60f1778354ca8494","_cell_guid":"4b5622be-07bb-4e86-8586-e5511c913f8e"},"outputs":[],"execution_count":null,"source":"def band_to_images(df):\n    images = []\n    for x in df.index:\n        band_1 = np.array(df.loc[x].band_1).reshape(75, 75)\n        band_2 = np.array(df.loc[x].band_2).reshape(75, 75)\n        band_3 = (band_1+band_2)/2\n        #band_4 = band_1 / band_2\n        band_1_scale = (band_1-band_1.mean())/(band_1.max()-band_1.min())\n        band_2_scale = (band_2-band_2.mean())/(band_2.max()-band_2.min())\n        band_3_scale = (band_3-band_3.mean())/(band_3.max()-band_3.min())\n        #band_4_scale = (band_4-band_4.mean())/(band_4.max()-band_4.min())\n        images.append(np.dstack((band_1_scale, band_2_scale, band_3_scale)))\n    return np.array(images)\ndef data_augment(images):\n    lr_images = []\n    ud_images = []\n    for x in range(0, images.shape[0]):\n        band_1 = images[x, :, :, 0]\n        band_2 = images[x, :, :, 1]\n        band_3 = images[x, :, :, 2]\n        #band_4 = images[x, :, :, 3]\n        # lr augment\n        band_1_lr = np.fliplr(band_1)\n        band_2_lr = np.fliplr(band_2)\n        band_3_lr = np.fliplr(band_3)\n        #band_4_lr = np.fliplr(band_4)\n        lr_images.append(np.dstack((band_1_lr, band_2_lr, band_3_lr)))\n        #ud augment\n        band_1_ud = np.flipud(band_1)\n        band_2_ud = np.flipud(band_2)\n        band_3_ud = np.flipud(band_3)\n        #band_4_ud = np.flipud(band_4)\n        ud_images.append(np.dstack((band_1_ud, band_2_ud, band_3_ud)))\n    lr_images = np.array(lr_images)\n    ud_images = np.array(ud_images)\n    images = np.concatenate((images, ud_images, lr_images))\n    return images","cell_type":"code"},{"metadata":{"collapsed":true,"_uuid":"47366722eb88bc5945957bff12a43a52f7c7bb4d","_cell_guid":"7669f2f4-58ba-4764-a262-403d5f3c15a7"},"outputs":[],"execution_count":null,"source":"x_train = band_to_images(train)\nx_train = data_augment(x_train)\ny_train = train.is_iceberg\ny_train = np.concatenate((y_train, y_train, y_train))\nx_test = band_to_images(test)\nidno_test = test.id","cell_type":"code"},{"metadata":{"collapsed":true,"_uuid":"d4e866f67ab8508b0e6a18f7c595e0fa3c686a12","_cell_guid":"87601e43-8322-4400-a4cb-455ced95dac1"},"outputs":[],"execution_count":null,"source":"model = k.models.Sequential()\n# conv1\nmodel.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(75, 75, 3)))\nmodel.add(k.layers.convolutional.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\nmodel.add(k.layers.Dropout(0.2))\n#conv2\nmodel.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(k.layers.Dropout(0.2))\n#conv3\nmodel.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3), activation='relu' ))\nmodel.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(k.layers.Dropout(0.2))\n# conv4\nmodel.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(k.layers.Dropout(0.2))\n# fc1\nmodel.add(k.layers.Flatten())\nmodel.add(k.layers.Dense(512))\nmodel.add(k.layers.Activation('relu'))\nmodel.add(k.layers.Dropout(0.2))\n#fc2\nmodel.add(k.layers.Dense(256))\nmodel.add(k.layers.Activation('relu'))\nmodel.add(k.layers.Dropout(0.2))\n#output\nmodel.add(k.layers.Dense(1))\nmodel.add(k.layers.Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=k.optimizers.Nadam(0.001), metrics=['accuracy'])\n#model.summary()","cell_type":"code"},{"metadata":{"_kg_hide-output":true,"collapsed":true,"_uuid":"2d5db491fb3683b493bec9cd351af8a2509164b6","_cell_guid":"be22fb12-37db-4a69-a492-289a8d7c0f80"},"outputs":[],"execution_count":null,"source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\nmcp_save = ModelCheckpoint('md.hdf5', save_best_only=True, monitor='val_loss', mode='min')\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='min')\nhistory = model.fit(x_train, y_train, batch_size=32, epochs=20, verbose=1, validation_split=0.25, callbacks=[early_stopping, reduce_lr_loss, mcp_save])\n\nmodel.load_weights(filepath = 'md.hdf5')\nscore = model.evaluate(x_train, y_train, verbose=1)\nprint('Train score:', score[0])\nprint('Train accuracy:', score[1])\n\npred_test = model.predict(x_test)\nsubmission = pd.DataFrame({'id': idno_test, 'is_iceberg': pred_test.reshape((pred_test.shape[0]))})\nsubmission.to_csv('cnn_keras.csv', index=False)\n\n","cell_type":"code"},{"metadata":{"_uuid":"fcbd83ff148df6dd6a18c5d2be84b59adca0ab3c","_cell_guid":"65754e4b-5dbf-4b17-a928-520bc6861e77"},"source":"Thanks for fvzaur's kernals\n[www.kaggle.com/fvzaur/iceberg-ship-classification-with-cnn-on-keras](http://)","cell_type":"markdown"}],"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat":4}