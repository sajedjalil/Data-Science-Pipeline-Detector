{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"version":"3.6.4","name":"python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3"}},"nbformat":4,"cells":[{"metadata":{"_cell_guid":"24ca26f2-b020-4b89-b3c0-ab9afeba77d6","_uuid":"46931b816a5b0e07b7672b173b3866fe8f56eea2"},"source":"The data section mentions that some training examples are missing the **\"inc_angle\"** field. Let's come up with a good way to fill in the missing values!","cell_type":"markdown"},{"metadata":{"_cell_guid":"275daa6f-facd-4847-b147-af13cf655175","_uuid":"57b878989680b145caa05495b472dd79176c1f76"},"source":"First, let's see how many training examples we need to fix:","cell_type":"markdown"},{"metadata":{"_cell_guid":"f0de98af-5c08-4fc5-9140-00ab3c06d525","_uuid":"04094702f5facbf4e58d96cf75a6eb3161db9ee1"},"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/train.json\")\n\ntraining_examples = train.shape[0]\nmissing_angles = len(train[train['inc_angle'] == 'na'])\npercent_missing = (missing_angles/training_examples)*100\n\nprint(\"{0}/{1} ({2:.2f}%) of examples are missing inc_angle\".format(\n    missing_angles, training_examples, percent_missing))\n","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"464a1451-d39a-4f0a-8e07-5fc3afec328e","_uuid":"ca5bbecca60e6be0ca3aa9692136674407e928bf"},"source":"Not too many... but 8% is a sinificant portion of the training data. It's definetely more than we can fill in manually.","cell_type":"markdown"},{"metadata":{"_cell_guid":"7671f8bb-0739-41b5-a578-e66038bc9def","_uuid":"cdf67a775e5c5d2b06ea37de9d77ec270d543d5e"},"source":"Mean, Median and Mode\n===========\nOne quick and easy solution would be to fill in all the missing angles with the mean, median or mode of all known inc_angles. Let's try it: ","cell_type":"markdown"},{"metadata":{"_cell_guid":"230004ba-115f-41ba-8427-09de73677ca7","_uuid":"fabb52b31ef352675d8baa0b75d07dc1709789d5"},"source":"# Include the test data in our calculations: \ntest = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/test.json\")\ntrain_no_ib = train.drop(['is_iceberg'],axis=1)\nexamples = pd.concat([train_no_ib,test])\n\ninc_angles = examples[examples['inc_angle'] != 'na']['inc_angle']\n\nmean = inc_angles.mean()\nmedian = inc_angles.median()\nmode = inc_angles.astype(np.double).round(1).mode()[0] # round to the nearest tenth for mode\nprint(\"Mean: {0}\\nMedian: {1}\\nMode: {2}\".format(mean,median,mode))","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ebf184e-9db2-419c-845f-ef364ec52ddb","_uuid":"880a7843df300064e86f35ea5e1ba240c25563dc"},"source":"**Which one should we use?  **\n\nTo get a better sense of the quality of our fill in values, let's treat this like a learning problem. We can create train & validation sets and evaluate performance with *mean absolute error*:","cell_type":"markdown"},{"metadata":{"_cell_guid":"28c880f0-6511-4a38-a781-1bafef751285","_uuid":"165059e5179be64e7899fe585cf0853ee8ab934d"},"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\ninc_angles_train, inc_angles_valid = train_test_split(inc_angles, random_state=1, train_size=0.8, test_size=0.2)\n\nones = np.ones(inc_angles_valid.shape[0])\nmean_mae = mean_absolute_error(ones*inc_angles_train.mean(), inc_angles_valid)\nmedian_mae = mean_absolute_error(ones*inc_angles_train.median(), inc_angles_valid)\nmode_mae = mean_absolute_error(ones*inc_angles_train.astype(np.double).round(1).mode()[0], inc_angles_valid)\n\nprint(\"Mean Error: {0}\\nMedian Error: {1}\\nMode Error: {2}\".format(mean_mae,median_mae,mode_mae))","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2d26637d-92b1-4a5f-b74f-96c850ba3fa3","_uuid":"bb3e67c74caa1fe211b9ef62011baa5c58713f8b"},"source":"So on average, our examples' incidence angles are ~3.43 degrees away from the median and the mean. It looks like mode is a little worse.\n\nIf we wanted to stop here, we could fill in our missing inc_angles with the median (+ small random value) and write out a new training data file:","cell_type":"markdown"},{"metadata":{"_cell_guid":"83f4015a-82f7-4bfd-a305-a68f0825fa66","collapsed":true,"_uuid":"94b5ee79715844be073aa7e1dacd9c3782d2370b"},"source":"from random import uniform\n\ntrain_out = train.copy()\n\nmin_var = median_mae*-0.5\nmax_var = median_mae*0.5\n\ntrain_out['inc_angle'] = [(median + uniform(min_var,max_var)) if angle == 'na' \n                          else angle \n                          for angle in train_out['inc_angle']]\n\ntrain_out.to_json('train_median_fill.json')\n","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c7ae03b7-d2ba-4159-97f7-dc43ee505365","_uuid":"18a2fe9855f48e4a6db089b4a224a3bbb6ceb148"},"source":"*But we can do better!*","cell_type":"markdown"},{"metadata":{"_cell_guid":"f5384b24-e5d5-430c-b353-d32c2269a9a0","_uuid":"5436644b6e7b537e6c9dd1e1c9ed5fac678ecb30"},"source":"Predicting Incidence Angles\n===\nSince the incidence angle describes a relationship between our 2 radar bands we should be able to build a model that predicts the incidence angle given the two bands as inputs. Let's give it a try with Keras:","cell_type":"markdown"},{"metadata":{"_cell_guid":"89b6adf5-57ac-4f82-9520-dfd9917148b9","_uuid":"c991307f5ebd1fd1760fafc28aeeb702b47c214f"},"source":"from keras.models import Input,Model\nfrom keras.layers import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D, Reshape, Dense, Dropout, Flatten, Activation, BatchNormalization\nfrom keras.regularizers import l2\nfrom keras import initializers\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, Callback\n\ndef model(dropout=0.1, regularization=0.00005):\n\n    x_input = Input(shape=(75,75,2,1,)) \n\n    # Layer 1\n    x = Conv3D(96, kernel_size=(5, 5, 2),activation='relu',input_shape=(75, 75, 2,1), kernel_regularizer=l2(regularization))(x_input)\n    x = BatchNormalization()(x)\n    x = MaxPooling3D(pool_size=(2, 2, 1), strides=(2, 2, 1))(x)\n    x = Dropout(dropout)(x)\n\n    x = Reshape((35,35,96))(x)\n\n    # Layer 2\n    x = Conv2D(128, kernel_size=(3, 3), activation='relu' , kernel_regularizer=l2(regularization))(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    x = Dropout(dropout)(x)\n    \n    # Layer 3\n    x = Conv2D(256, kernel_size=(3, 3), activation='relu' , kernel_regularizer=l2(regularization))(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    x = Dropout(dropout+0.1)(x)\n    \n    # Layer 4\n    x = Conv2D(128, kernel_size=(3, 3), activation='relu' , kernel_regularizer=l2(regularization))(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    x = Dropout(dropout)(x)\n    \n    x = Flatten()(x)\n    \n    # Layer 5\n    x = Dense(768, kernel_regularizer=l2(regularization))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(dropout+0.1)(x)\n    \n    # Layer 6\n    x = Dense(384, kernel_regularizer=l2(regularization))(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(dropout+0.1)(x)\n    \n    # Linear Output Layer\n    y_ = Dense(1)(x)\n    \n    model = Model(inputs=x_input, outputs=y_)\n    adam_otim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n    model.compile(loss='mean_squared_error', optimizer=adam_otim, metrics=['mae'])\n    \n    model.summary()\n    return model","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0c27c19d-9dbc-45ba-a6c9-8930d5623dd3","_uuid":"e0e2b20a1329da9489b183fdb87ebc50c83ff43d"},"source":"This is the best of a few different model setups I tried. It's loosly based on DeveshMaheshwari's [kernal](https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d). There's probably room for improvement. Feel free to tweak the hyperparameters and let me know what works best for you.\n\nNotice we're using the same evaluation metric, mean absolute error ('mae'), that we used with our mean/median/mode fills above.","cell_type":"markdown"},{"metadata":{"_cell_guid":"c37794f2-9102-4848-9501-4fbee79e7e7c","collapsed":true,"_uuid":"bd91b01382d8c6fd7d13800804e234c29e33cb69"},"source":"def load_train_data():\n    train = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/train.json\")\n    test = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/test.json\")\n    \n    train = train.drop(['is_iceberg'],axis=1)\n    train = pd.concat([train,test])\n    train = train[train['inc_angle'] != 'na']\n    \n    band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n    band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n    bands = np.concatenate([band_1[:, :, :, np.newaxis], band_2[:, :, :, np.newaxis]], axis=-1)\n    bands = bands.reshape((-1, 75, 75, 2, 1))\n    \n    angles = train[\"inc_angle\"]\n    \n    return train_test_split(bands, angles, random_state=1, train_size=0.8, test_size=0.2)","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"da166b58-5e02-4f7d-b195-f597dde833b3","_uuid":"557ae209e4c5e5fab8a648bdfebad8d7234d631d"},"source":"It took my macbook a few hours to train the model. So to speed things up, I included my pretrained weights as an input to this kernal. If you want to tweak the model and train it yourself locally, I included code to do that too:","cell_type":"markdown"},{"metadata":{"_cell_guid":"1facae00-0482-4f3d-a02c-55010305c3e1","_uuid":"1606f153f887a8f3cfa29775af5dffcc4c75cdc0"},"source":"m = model()\nx_train, x_valid, y_train, y_valid = load_train_data()\nweights_file = '../input/pretrained-weights-for-inc-angle/inc_angle_weights_pretrained.hdf5'\n\nTRAIN_FROM_SCRATCH = False\n\nif TRAIN_FROM_SCRATCH:\n    checkpoint = ModelCheckpoint(weights_file, save_best_only=True)\n    model.fit(x_train, y_train, batch_size=32, epochs=25, verbose=1,\n              validation_data=(x_valid, y_valid),\n              callbacks=[checkpoint])\nelse:\n    m.load_weights(filepath=weights_file)","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9bc0e34e-33c8-4992-b3f4-cf099668288e","_uuid":"a572b4ed7eafb36ad6c716940463f216cb61de43"},"source":"Now that it's trained, let's see if our model does any better than the median at predicting inc_angles:","cell_type":"markdown"},{"metadata":{"_cell_guid":"93b9016f-64f9-4f3c-ac31-723bea1e0dd4","_uuid":"8b1cc3c51dee2694a508b2f2ea0f07bbe0992db2"},"source":"predicted_angles = m.predict(x_valid, verbose=1)\nmodel_mae = mean_absolute_error(predicted_angles, y_valid)\nprint('Model Error: {0}'.format(model_mae))","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"23e9cccd-39ca-448b-b32c-13d65f3f4bed","_uuid":"7343e829e4566ae5f638100e236595b1442283f9"},"source":"**Success!**\n\nOur model is ~16% better than the median at predicting incidence angles. It's not a huge improvement. And it probably wasn't worth all the effort considering it only helps ~8% of the training data... but nevertheless! It's still pretty cool that we can get a rough angle estimate given the two radar images. I suspect it wouldn't be too much effort to improve our accuracy even further.\n\nUsing our awesome new angle-prediction-model, let's create a new training data file without any missing inc_angles:","cell_type":"markdown"},{"metadata":{"_cell_guid":"c4da43c1-b3ac-403c-86f3-d004462d3b88","collapsed":true,"_uuid":"3e4689e237a6406726b7d09e74ca814731e2a77f"},"source":"def predict_inc_angle(ex, model):\n    band_1 = np.array([np.array(ex[\"band_1\"]).astype(np.float32).reshape(75, 75)])\n    band_2 = np.array([np.array(ex[\"band_2\"]).astype(np.float32).reshape(75, 75)])\n    bands = np.concatenate([band_1[:, :, :, np.newaxis], band_2[:, :, :, np.newaxis]], axis=-1)\n    bands = bands.reshape((1, 75, 75, 2, 1))\n    inc_angle = model.predict(bands)\n    return inc_angle.reshape(1)[0]\n    \ntrain_out_model = train.copy()\n\ntrain_out_model['inc_angle'] = [predict_inc_angle(ex,m) if ex['inc_angle'] == 'na' \n                          else ex['inc_angle'] \n                          for _,ex in train_out_model.iterrows()]\n\ntrain_out_model.to_json('train_model_fill.json')\n#print(train_out_model)","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33658aed-eeab-4962-b8ad-2329b99b1b07","_uuid":"17c11bc3ba9b31db153d3b73c2b7cbd4a8162b97"},"source":"As a bonus, if you take a look at the output (1574->1603 were all previously 'na') you'll notice there's a lot more variation in our predicted angles compared to the \"median + random value\" method seen earlier.  The variations from our *model*'s output should be more meaningful too. It's also nice to see that our model wasn't just learning the median. \n\nFeel free to use either of the results in your own models. Let me know if you have any questions or suggestions below. Upvote if this was helpful and thanks for reading!\n\n-Ryan","cell_type":"markdown"}],"nbformat_minor":1}