{"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","file_extension":".py","version":"3.6.3","codemirror_mode":{"name":"ipython","version":3}}},"cells":[{"source":"In this kernel I provide an Exploratory Data Analyis for the Iceberg classification challenge and some snippets showing how to generate new data to agument the initial dataset.","metadata":{},"cell_type":"markdown"},{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom subprocess import check_output\ntrain = pd.read_json('../input/train.json')\ntrain.head()","outputs":[],"metadata":{"_cell_guid":"44f807d7-b450-47ad-a817-a906fddb1c39","_uuid":"41907e53c1eed50cea38698890031a089f60e1bb","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Let's check if the two sets, icebergs and ships, are balanced","metadata":{"_cell_guid":"a9271730-be55-4401-8277-678eb7c10c30","_uuid":"5e17dae11ef88751752682117d9468ced7e2c0ee"},"cell_type":"markdown"},{"source":"f,ax = plt.subplots(1,1,figsize=(15,6))\nsns.barplot(x=['not an iceberg','iceberg'],y=train.groupby(['is_iceberg'],as_index=False).count()['id'])\nplt.show()","outputs":[],"metadata":{"_cell_guid":"aa806ade-23ef-4760-be46-69ddc4aad38f","_uuid":"84a9c985d90796428017f8157f3fa3aa6e72c464","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Here you can see the distribution of the angles at which detections took place. There where null values I turned to 0","metadata":{"_cell_guid":"7dfed6da-6fb5-49b9-8718-a0a3436ecf48","_uuid":"ec854eeaef93959f586be2b835f94f7d8b4cb6a2"},"cell_type":"markdown"},{"source":"f,ax = plt.subplots(1,1,figsize=(15,6))\nangles = [int(float(t)) if t!='na' else 0 for t in train['inc_angle']]\ntrain['intangle'] = angles\nsns.distplot(angles)\nplt.show()","outputs":[],"metadata":{"_cell_guid":"5660a2e8-de2f-43c7-865d-a68b31aa7276","_uuid":"7a575416102e1878d443d2cb1ce9412f6e0c0b5b","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from PIL import Image\n\ndef normalizeArrays(data,i):\n    arr1 = np.reshape(data['band_1'][i],(75,75))\n    arr1 = arr1+ abs(np.asarray(arr1).min())\n    arr1 = np.asarray(arr1/np.asarray(arr1).max())\n\n    arr2 = np.reshape(data['band_2'][i],(75,75))\n    arr2 = arr2+ abs(np.asarray(arr2).min())\n    arr2 = np.asarray(arr2/np.asarray(arr2).max())\n    \n    return arr1,arr2\n\nnorm =[normalizeArrays(train,i) for i in range(len(train))]\ntrain['norm1'] = [t[0] for t in norm]\ntrain['norm2'] = [t[1] for t in norm]","outputs":[],"metadata":{"_cell_guid":"c6f5e46c-42ce-49b8-a2ca-17910c821fa2","_uuid":"c65988b9b1c8b44ce8ee5132db86af1dd1da0ea5","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Let's have look at the normalized data","metadata":{"_cell_guid":"66ac33e1-6ca0-4cc5-91c9-e6ff2eb84486","_uuid":"c8802fa946afd733e475e1bff92f334e3a3b11c3"},"cell_type":"markdown"},{"source":"from PIL import ImageFilter\nf,axarr = plt.subplots(2,3,figsize=(20,10))\niarray = []\nfor i in range(6):\n    img = Image.fromarray(train['norm1'][i]*255)\n    img = img.convert('L')\n    img = img.filter(ImageFilter.SMOOTH_MORE)\n    iarray.append(img)    \naxarr[0][0].imshow(iarray[0])\naxarr[0][1].imshow(iarray[1])\naxarr[0][2].imshow(iarray[2])\naxarr[1][0].imshow(iarray[3])\naxarr[1][1].imshow(iarray[4])\naxarr[1][2].imshow(iarray[5])\nplt.show()","outputs":[],"metadata":{"_cell_guid":"a5c0fb8f-066c-4f8b-81fe-5dbbf71de1b3","_uuid":"ea756681b4fc717d79a5b7894cc62cc7e2cd7e16","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from PIL import ImageFilter\nf,axarr = plt.subplots(2,3,figsize=(20,10))\niarray = []\nfor i in range(6):\n    img = Image.fromarray(train['norm2'][i]*255)\n    img = img.convert('L')\n    img = img.filter(ImageFilter.SMOOTH_MORE)\n    iarray.append(img)    \naxarr[0][0].imshow(iarray[0])\naxarr[0][1].imshow(iarray[1])\naxarr[0][2].imshow(iarray[2])\naxarr[1][0].imshow(iarray[3])\naxarr[1][1].imshow(iarray[4])\naxarr[1][2].imshow(iarray[5])\nplt.show()","outputs":[],"metadata":{"_cell_guid":"7503ab24-518d-465e-9a51-665fcb93368a","_uuid":"dd990a6fbd54b52a08424b02899ffb3f31038685","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from this kernel  https://www.kaggle.com/muonneutrino/exploration-transforming-images-in-python the idea of using X derivaate. What an amazing 3D effect :)","metadata":{"_cell_guid":"07ebcfbf-c59b-40bc-b97a-45fb2e1fa1d6","_uuid":"ec339e2ae7fa98a66d72e1f28af187ad6615a762"},"cell_type":"markdown"},{"source":"from scipy import signal\nfig = plt.figure(1,figsize=(15,15))\nxder = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\nfor i in range(6):\n    ax = fig.add_subplot(3,3,i+1)\n    arr = signal.convolve2d(np.reshape(np.array(train['norm1'][i]),(75,75)),xder,mode='valid')\n    ax.imshow(arr)\nplt.show()\n","outputs":[],"metadata":{"_cell_guid":"34f3213a-f36a-45d2-b30d-260b2c5a0bd8","_uuid":"31365915b23d7bc62f20b681a7cb377344fd9fd5","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Now we are going to extract some basic features","metadata":{"_cell_guid":"4a5a4fab-806a-4fcf-9b60-1742c14fb4d8","_uuid":"b33b37d9b763b160eeb53dfbdd3cddcdc3245201"},"cell_type":"markdown"},{"source":"max1 = [pd.Series(train['band_1'][i]).max() for i in range(len(train))]\nmax2 = [pd.Series(train['band_2'][i]).max() for i in range(len(train))]\nmean1 = [pd.Series(train['band_1'][i]).mean() for i in range(len(train))]\nmean2 =[pd.Series(train['band_2'][i]).mean() for i in range(len(train))]\nmin1 = [pd.Series(train['band_1'][i]).min() for i in range(len(train))]\nmin2 = [pd.Series(train['band_2'][i]).min() for i in range(len(train))]\ntrain['min1'] = min1\ntrain['min2'] = min2\ntrain['max1'] = max1\ntrain['max2'] = max2\ntrain['mean1'] = mean1\ntrain['mean2'] = mean2","outputs":[],"metadata":{"_cell_guid":"a06e7a47-ea76-4e3a-b818-c98b98156edc","_uuid":"86cae7edfff66816f102caff20cfa43141c921f8","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from scipy.stats import kendalltau\n\njp = sns.jointplot(x=train['max1'], y=train['intangle'], kind=\"hex\")\njp.fig.set_size_inches(8,6)\njp.ax_joint.set_ylim(30,45)","outputs":[],"metadata":{"_cell_guid":"c15de8ae-7f19-4360-a150-9e7028af4211","_uuid":"3e817864354d526069e738d634891351f8666ab9","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"and see how the correlate with the target class (ships, iceberg)","metadata":{"_cell_guid":"ef931425-3cdb-492c-b0c4-26ecc8254038","_uuid":"eea72055b0462bc51e5276d6291d30254972ab86"},"cell_type":"markdown"},{"source":"import seaborn as sns\nf,axarr = plt.subplots(1,1,figsize=(15,6))\nsns.heatmap(train.corr())\nplt.show()","outputs":[],"metadata":{"_cell_guid":"855f6ee5-de5b-4e84-ae31-c6ea3fcc501c","_uuid":"b7110d1c7ee54a31d1f29dbc460183435c3e501d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"## Dataset Augmentation","metadata":{"_cell_guid":"694fc633-6777-4c68-8769-c25f8870c8ff","_uuid":"cd194500ec57d19f60e59251fa39d086deb9a1a2"},"cell_type":"markdown"},{"source":"From this Kernel https://www.kaggle.com/sinkie/keras-data-augmentation-with-multiple-inputs  the idea of using the Keras ImageDataGenerator to augment the input dataset","metadata":{"_cell_guid":"1d059c20-6389-4dc9-b5d0-2f1f732aab8a","_uuid":"b0f8ed4c1801f2d2b1c3f75e45dc4fb766b383ed"},"cell_type":"markdown"},{"source":"gin = np.asarray([np.asarray(p).reshape(75,75) for p in train['band_1']])\ngin = gin.reshape(1604,75,75,1)","outputs":[],"metadata":{"_cell_guid":"f14d70f2-9eee-4d3b-8d33-2570f76f1029","_uuid":"01e3835d334e1fafc3eca43d4d8d48445859b55d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(featurewise_center=False, featurewise_std_normalization=False,rotation_range=90)\ndatagen.fit(gin)","outputs":[],"metadata":{"_cell_guid":"2fb36907-acf7-4319-a084-bfd6fb850567","_uuid":"0ced944fdde4ef36ec806feb4e98f557924cd10d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"fig = plt.figure(1,figsize=(15,15))\nfor X_batch, y_batch in datagen.flow(gin, train['is_iceberg'], batch_size=9):\n    for i in range(0, 9):\n        ax = fig.add_subplot(3,3,i+1)\n        ax.imshow(X_batch[i].reshape(75, 75), cmap=plt.get_cmap('gray'))\n    plt.show()\n    break","outputs":[],"metadata":{"_cell_guid":"7c7097d3-a674-4bab-a845-187ec95e06d7","_uuid":"b4741e0202d58c17e890e22505656b13a9891fe7","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import svm\n\nclf = GradientBoostingClassifier(n_estimators = 50,random_state=0)\nfeatures = ['min1','min2','max1','max2','mean1','mean2']\nscores = cross_val_score(clf,train[features],train['is_iceberg'], cv=3)\nclf.fit(train[features],train['is_iceberg'])\nscores\n\n","outputs":[],"metadata":{"_cell_guid":"23c8d548-9ce2-4730-b650-64ccfdf1b7db","_uuid":"77a92bd10f0af2beed6cd5e3774488e8ebb7a68d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"## Prediction","metadata":{"_cell_guid":"b0edc35f-fe81-4848-9a39-958962d96e97","_uuid":"3615fff71c02c5bb7056a9de84f6fae5bde73e5f"},"cell_type":"markdown"},{"source":"test = pd.read_json('../input/test.json')","outputs":[],"metadata":{"_cell_guid":"c2304344-320d-45c4-935a-691fa7f966a6","_uuid":"a736ed03506e007e71690e22f66cdb1c42dd138f","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"max1 = [pd.Series(test['band_1'][i]).max() for i in range(len(test))]\nmax2 = [pd.Series(test['band_2'][i]).max() for i in range(len(test))]\nmean1 = [pd.Series(test['band_1'][i]).mean() for i in range(len(test))]\nmean2 =[pd.Series(test['band_2'][i]).mean() for i in range(len(test))]\nmin1 = [pd.Series(test['band_1'][i]).min() for i in range(len(test))]\nmin2 = [pd.Series(test['band_2'][i]).min() for i in range(len(test))]\ntest['min1'] = min1\ntest['min2'] = min2\ntest['max1'] = max1\ntest['max2'] = max2\ntest['mean1'] = mean1\ntest['mean2'] = mean2","outputs":[],"metadata":{"_cell_guid":"69306272-7a18-435e-a677-5bbeedaeb1cf","_uuid":"8ea406a92c2ec46cd9d224faab63493568681817","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"pred = clf.predict(test[features])\nout = pd.DataFrame({'id':test['id'],'is_iceberg':pred})\nout.to_csv('res.csv',header=True,index=False)","outputs":[],"metadata":{"_cell_guid":"f14e61bd-1459-4449-ba0e-4979fa150e24","_uuid":"b1a9b32890e5308b6b9760e34895995719e5160f","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"import numpy as np\nim1 = np.reshape(train['band_1'][0],(75,75))","outputs":[],"metadata":{"_cell_guid":"136c53e0-466a-4170-bef9-16345ea986d8","_uuid":"92fa85939dc076b251e7486a5d1c7dab495452e1","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from PIL import Image\nfrom matplotlib.pyplot import imshow\nfrom scipy.misc import toimage\nplt.imshow(np.reshape(train['band_1'][0],(75,75)))\nplt.show()\nplt.imshow(np.reshape(train['band_1'][1],(75,75)))\nplt.show()\nplt.imshow(np.reshape(train['band_1'][2],(75,75)))\nplt.show()","outputs":[],"metadata":{"_cell_guid":"cc94acad-c3b5-4afe-b9b0-51219628eaf3","_uuid":"62b78d7ac5110bce039f62a10c32ec91953c4326","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"work in progress","metadata":{"_cell_guid":"21273afd-67e7-4a54-ae89-393a538566e4","_uuid":"1563448324a5bd9e4e0f55033b924217d34394d5","collapsed":true},"cell_type":"markdown"}],"nbformat":4}