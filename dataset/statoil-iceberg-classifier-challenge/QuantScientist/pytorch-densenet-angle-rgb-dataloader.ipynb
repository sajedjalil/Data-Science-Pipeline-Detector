{"nbformat_minor":1,"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"source":"# Pytorch DenseNet + Angle + RGB DataLoader\n\n\n- The angle is used as a Third RGB channel\n-  An alternative is to use the angle as a second input to the CNN (will do this next) ","cell_type":"markdown","metadata":{"_uuid":"779ab5dd78fcdaaf0d1387ae5dc3f175524858d9","_cell_guid":"a6b7d6ae-f2f1-4ab3-bf7a-50948292cacd"}},{"source":"## Imports","cell_type":"markdown","metadata":{}},{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n%reset -f\n\nimport torch\nfrom torch.autograd import Variable\nimport numpy as np\nimport pandas\nimport numpy as np\nimport pandas as pd\nfrom sklearn import cross_validation\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom sklearn import cross_validation\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\nfrom sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\nimport logging\nimport numpy\nimport numpy as np\nfrom __future__ import print_function\nfrom __future__ import division\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nimport os\nimport torch\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport time\nfrom sklearn.preprocessing import PolynomialFeatures\nimport pandas as pd\nimport numpy as np\nimport scipy\n%matplotlib inline\nfrom pylab import rcParams\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom tqdm import tqdm_notebook\nimport seaborn as sns\n","cell_type":"code","metadata":{"_uuid":"c1cf1feee03e3784251c9ae345244d9ae5375af3","collapsed":true,"_cell_guid":"303a9986-71cd-41d0-b53a-0b26ac4007cb"},"execution_count":null,"outputs":[]},{"source":"# %%timeit\nuse_cuda = torch.cuda.is_available()\n# use_cuda = False\n\nprint(\"USE CUDA=\" + str (use_cuda))\nFloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\nLongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\nTensor = FloatTensor\n","cell_type":"code","metadata":{"_uuid":"4c275216209a4e834ea224cb1d25a3e32b1eea50","collapsed":true,"_cell_guid":"fcc60e51-f654-45b3-a621-6a2909e934a5"},"execution_count":null,"outputs":[]},{"source":"# fix seed\nseed=17*19\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif use_cuda:\n    torch.cuda.manual_seed(seed)","cell_type":"code","metadata":{"_uuid":"97f568d27bfdecaf98e9226fea4c95c465630e67","collapsed":true,"_cell_guid":"fa31a53f-e031-48b5-9a40-67fca0975794"},"execution_count":null,"outputs":[]},{"source":"","cell_type":"code","metadata":{"_uuid":"db4d4d6154afcb3a5d444b0f288f04b9b15e35c0","collapsed":true,"_cell_guid":"5861c386-86d2-4177-900e-7ed30aa76795"},"execution_count":null,"outputs":[]},{"source":" # PyTorch Custom Image DataLoader","cell_type":"markdown","metadata":{"_uuid":"32093bd16103f80a50ef37fe5251c93ac9308263","_cell_guid":"27e49cba-77a9-450e-bf7b-129cd41153a3"}},{"source":"import os\nimport sys\nimport random\nimport numpy as np\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch\nimport torch.utils.data as data\n\nIMG_EXTENSIONS = [\n    '.jpg',\n    'png'\n]\n\nto_tensor = transforms.Compose([transforms.ToTensor()])\n\ndef is_img_file(filename):\n    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n\n# def default_loader(path):\n# \treturn Image.open(path).convert('RGB')\n\ndef tensor_load_rgbimage(filename, size=None, scale=None, keep_asp=False):\n    img = Image.open(filename).convert('RGB')\n    if size is not None:\n        if keep_asp:\n            size2 = int(size * 1.0 / img.size[0] * img.size[1])\n            img = img.resize((size, size2), Image.ANTIALIAS)\n        else:\n            img = img.resize((size, size), Image.ANTIALIAS)\n\n    elif scale is not None:\n        img = img.resize((int(img.size[0] / scale), int(img.size[1] / scale)), Image.ANTIALIAS)\n    img = np.array(img).transpose(2, 0, 1)\n    img = torch.from_numpy(img).float()\n    return img\n\n\ndef default_loader_scale(input_path, size=20):\n    input_image = (Image.open(input_path)).convert('RGB')\n    if size is not None:\n        input_image = input_image.resize((size, size), Image.ANTIALIAS)\n\n    # input_image = np.array(input_image).transpose(2, 0, 1)\n    # input_image = torch.from_numpy(input_image).float()\n    return input_image\n\ndef default_loader(input_path):\n    # pil_to_tensor = transforms.ToTensor()\n    input_image = (Image.open(input_path)).convert('RGB')\n    # input_image = pil_to_tensor(input_image)\n    # img = np.array(img).transpose(2, 0, 1)\n    # img = torch.from_numpy(img).float()\n    return input_image\n\ndef find_classes(dir):\n    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    return classes, class_to_idx\n\ndef make_dataset(dir, class_to_idx):\n    tensors = []\n    if not os.path.exists(dir):\n        print(\"Seed dataset %s doesn't exist.\" % (dir))\n        sys.exit()\n    else:\n        dir = os.path.expanduser(dir)\n        for target in sorted(os.listdir(dir)):\n            d = os.path.join(dir, target)\n            if not os.path.isdir(d):\n                continue\n\n            for root, _, fnames in sorted(os.walk(d)):\n                for fname in sorted(fnames):\n                    if is_img_file(fname):\n                        path = os.path.join(root, fname)\n                        item = (path, class_to_idx[target])\n                        tensors.append(item)\n\n    return tensors\n\n\nclass SeedImageDataset(data.Dataset):\n    def __init__(self,root,phase,loader=default_loader_scale,transform=None):\n\n        classes, class_to_idx = find_classes(root)\n        print ('Classes: {}'.format(classes))\n        print ('# Classes: {}'.format(len(classes)))\n        print ('Class to idx: {}'.format(class_to_idx))\n\n        tensors = make_dataset(root, class_to_idx)\n        if len(tensors) == 0:\n            raise (RuntimeError(\n                \"Found 0 sound files in subfolders of: \" + root + \"Supported img file extensions are: \" + \",\".join(\n                    IMG_EXTENSIONS)))\n\n        self.tensors = tensors\n        self.root = root\n        self.phase = phase\n        self.classes = classes\n        self.class_to_idx = class_to_idx\n        self.transform = transform\n        self.loader = loader\n\n\n    def __getitem__(self, index):\n        # Get path of input image and ground truth\n        input, target = self.tensors[index]\n        # Acquire input image and ground truth\n        input_tensor = self.loader(input)\n        # print (type(input_tensor)) # <class 'PIL.Image.Image'>\n\n        if self.transform is not None:\n            input_tensor = self.transform(input_tensor)\n\n        if type(input_tensor) is not torch.FloatTensor:\n        # print (type(input_tensor)) # MUST BE <class 'torch.FloatTensor'>\n            input_tensor=to_tensor(input_tensor)\n\n        return input_tensor, target\n\n    def __len__(self):\n        return len(self.tensors)\n","cell_type":"code","metadata":{"_uuid":"48696e30f09b8817ea6f4f07ce5c1ac65e731b97","_cell_guid":"90d2d22e-51a9-4532-b4bb-1b2d212827e8"},"execution_count":null,"outputs":[]},{"source":"#your custom aug function for numpy image:\n#seems like all flip augmentations may decrease performance\n\n\nnormalize = transforms.Normalize(\n   mean=[0.485, 0.456, 0.406],\n   std=[0.229, 0.224, 0.225]\n)\npreprocess = transforms.Compose([\n#    transforms.Scale(256),\n#    transforms.CenterCrop(224),\n   transforms.ToTensor(),\n   normalize\n])\n\ntrain = pd.read_json('../input/train.json')\ntrain['inc_angle'] = pd.to_numeric(train['inc_angle'], errors='coerce')\ntrain['band_1'] = train['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\ntrain['band_2'] = train['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n        \nbatch_size = 32\n# train_ds = ImageDataset(train, include_target = True, u =0.5, X_transform = random_vertical_flip)\ntrain_ds = ImageDataset(train, include_target = True, X_transform = preprocess)\nUSE_CUDA = False #for kernel\nTHREADS = 1 #for kernel\ntrain_loader = data.DataLoader(train_ds, batch_size,\n                                    sampler = RandomSampler(train_ds),\n                                    num_workers = THREADS,\n                                    pin_memory= USE_CUDA )\n                                    \n#prseudo code for train\n# for i, dict_ in enumerate(train_loader):\n#     images  = dict_['img']\n#     target  = dict_['target'].type(torch.FloatTensor)\n    \n#     if USE_CUDA:\n#         images = images.cuda()\n#         target = target.cuda()\n    \n#     images = Variable(images)\n#     target = Variable(target)    \n    \n#     #for kernel:\n#     print(target)\n#     if i ==0 : break\n","cell_type":"code","metadata":{"_uuid":"983c3598967c04c6306897427dd99108750859a4","_cell_guid":"020bbd02-2ebe-49a7-bb9c-fe0e0c03c0b7"},"execution_count":null,"outputs":[]},{"source":"%matplotlib inline\nfrom torchvision.utils import make_grid\n    \ndef flaotTensorToImage(img, mean=0, std=1):\n    \"\"\"convert a tensor to an image\"\"\"\n    img = img.numpy()\n    img= img.reshape(75, 75, 3)    \n    img = (img*std+ mean)*255\n    img = img.astype(np.uint8)    \n#     print (img.shape)\n    return img    \n    \nimport matplotlib.pyplot as plt\n\nimagesToShow=4\n\nfor i, data in enumerate(train_loader, 0):\n    print('i=%d: '%(i))            \n    images  = data['img']\n    target  = data['target'].type(torch.FloatTensor)\n    num = len(images)\n    ax = plt.subplot(1, imagesToShow, i + 1)\n    plt.tight_layout()\n    ax.set_title('Sample #{}'.format(i))\n    ax.axis('off')\n    \n    for n in range(num):\n        image=images[n]\n        label=target[n]\n        plt.imshow (flaotTensorToImage(image))\n#         show(image)\n        \n    if i==imagesToShow-1:\n        break    \n","cell_type":"code","metadata":{"_uuid":"51392cdecd3f46bd43af13ac2c0fe2205ff4deb1","collapsed":true,"_cell_guid":"adb275ba-0c2a-42fa-8d9c-82706b4ddfdb"},"execution_count":null,"outputs":[]},{"source":"from torch.utils.data import TensorDataset, DataLoader\n\nclass FullTrainningDataset(torch.utils.data.Dataset):\n    def __init__(self, full_ds, offset, length):\n        self.full_ds = full_ds\n        self.offset = offset\n        self.length = length\n        assert len(full_ds)>=offset+length, Exception(\"Parent Dataset not long enough\")\n        super(FullTrainningDataset, self).__init__()\n        \n    def __len__(self):        \n        return self.length\n    \n    def __getitem__(self, i):\n        return self.full_ds[i+self.offset]\n    \nvalidationRatio=0.11    \n\ndef trainTestSplit(dataset, val_share=0.11):\n    val_offset = int(len(dataset)*(1-val_share))\n    print (\"Offest:\" + str(val_offset))\n    return FullTrainningDataset(dataset, 0, val_offset), FullTrainningDataset(dataset, \n                                                                              val_offset, len(dataset)-val_offset)\n\ntrain_ds, val_ds = trainTestSplit(train_loader)\nt_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=False,\n                                            num_workers=1)\nv_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=1)\n\nprint (t_loader)\nprint (v_loader)","cell_type":"code","metadata":{"_uuid":"64fdca54a5cf0723363021b4ed66a357e4452441","collapsed":true,"_cell_guid":"9637b0b0-1e44-4158-a7be-4ebc166d2671"},"execution_count":null,"outputs":[]},{"source":"## Define simple model","cell_type":"markdown","metadata":{"_uuid":"21eacbdcf5f04eecf86da49621b5aff4d3b92d8d","_cell_guid":"9655dd9c-c792-4d15-bb8b-94a800eb9c0e"}},{"source":"import sys\nimport math\n\nclass Bottleneck(nn.Module):\n    def __init__(self, nChannels, growthRate):\n        super(Bottleneck, self).__init__()\n        interChannels = 4*growthRate\n        self.bn1 = nn.BatchNorm2d(nChannels)\n        self.conv1 = nn.Conv2d(nChannels, interChannels, kernel_size=1,\n                               bias=False)\n        self.bn2 = nn.BatchNorm2d(interChannels)\n        self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3,\n                               padding=1, bias=False)\n\n    def forward(self, x):\n        out = self.conv1(F.relu(self.bn1(x)))\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = torch.cat((x, out), 1)\n        return out\n\nclass SingleLayer(nn.Module):\n    def __init__(self, nChannels, growthRate):\n        super(SingleLayer, self).__init__()\n        self.bn1 = nn.BatchNorm2d(nChannels)\n        self.conv1 = nn.Conv2d(nChannels, growthRate, kernel_size=3,\n                               padding=1, bias=False)\n\n    def forward(self, x):\n        out = self.conv1(F.relu(self.bn1(x)))\n        out = torch.cat((x, out), 1)\n        return out\n\nclass Transition(nn.Module):\n    def __init__(self, nChannels, nOutChannels):\n        super(Transition, self).__init__()\n        self.bn1 = nn.BatchNorm2d(nChannels)\n        self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1,\n                               bias=False)\n\n    def forward(self, x):\n        out = self.conv1(F.relu(self.bn1(x)))\n        out = F.avg_pool2d(out, 2)\n        return out\n\n\nclass DenseNet(nn.Module):\n    def __init__(self, growthRate, depth, reduction, nClasses, bottleneck):\n        super(DenseNet, self).__init__()\n\n        nDenseBlocks = (depth-4) // 3\n        if bottleneck:\n            nDenseBlocks //= 2\n\n        nChannels = 2*growthRate\n        self.conv1 = nn.Conv2d(3, nChannels, kernel_size=3, padding=1,\n                               bias=False)\n        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n        nChannels += nDenseBlocks*growthRate\n        nOutChannels = int(math.floor(nChannels*reduction))\n        self.trans1 = Transition(nChannels, nOutChannels)\n\n        nChannels = nOutChannels\n        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n        nChannels += nDenseBlocks*growthRate\n        nOutChannels = int(math.floor(nChannels*reduction))\n        self.trans2 = Transition(nChannels, nOutChannels)\n\n        nChannels = nOutChannels\n        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n        nChannels += nDenseBlocks*growthRate\n\n        self.bn1 = nn.BatchNorm2d(nChannels)\n        self.fc = nn.Linear(128, nClasses)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n        layers = []\n        for i in range(int(nDenseBlocks)):\n            if bottleneck:\n                layers.append(Bottleneck(nChannels, growthRate))\n            else:\n                layers.append(SingleLayer(nChannels, growthRate))\n            nChannels += growthRate\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.trans1(self.dense1(out))\n        out = self.trans2(self.dense2(out))\n        out = self.dense3(out)\n        # print(out.data.shape)\n        out = F.avg_pool2d(F.relu(self.bn1(out)), 8)\n        out = out.view(out.size(0), -1)\n        # print(out.data.shape)\n        out = F.sigmoid(self.fc(out))\n        return out\n\nmodel = DenseNet(growthRate=8, depth=20, reduction=0.5,\n                            bottleneck=True, nClasses=1)\n\nprint (model)\n\nprint('  + Number of params: {}'.format(sum([p.data.nelement() for p in model.parameters()])))","cell_type":"code","metadata":{"_uuid":"4112e0197ba91e6ab2d39c65d67ed112fdc78729","collapsed":true,"_cell_guid":"03178a5e-e8ef-4334-a97d-f1cf7c0fecf8"},"execution_count":null,"outputs":[]},{"source":"## Train","cell_type":"markdown","metadata":{"_uuid":"d14d6e56da8fc08a04dede4ad982fc95c332c79b","_cell_guid":"3e6db15e-bcab-421e-bab6-cd0e1d387736"}},{"source":"loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n\n# NN params\nLR = 0.0005\nMOMENTUM= 0.95\noptimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=5e-5) #  L2 regularization\nif use_cuda:    \n    model.cuda()\n    loss_func.cuda()\n\nprint(optimizer)\nprint(loss_func)\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\ncriterion = loss_func\nall_losses = []\nval_losses = []\nnum_epoches=10\n\nif __name__ == '__main__':\n\n    for epoch in range(num_epoches):\n        print('Epoch {}'.format(epoch + 1))\n        print('*' * 5 + ':')\n        running_loss = 0.0\n        running_acc = 0.0\n        \n        for i, data in enumerate(train_loader, 0):        \n            img  = data['img']\n            label  = data['target'].type(torch.FloatTensor)\n\n#         for i, data in enumerate(train_loader, 0):    \n#             img  = data['img']\n#             label  = data['target']#     \n            \n            img, label = Variable(img), Variable(label)  # RuntimeError: expected CPU tensor (got CUDA tensor)\n    \n            out = model(img).type(torch.FloatTensor).squeeze(1)\n            loss = criterion(out, label)\n            running_loss += loss.data[0] * label.size(0)\n    \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()               \n    \n        print('Finish {} epoch, Loss: {:.6f}'.format(epoch + 1, running_loss / (len(train_ds))))\n    \n#         model.eval()\n#         eval_loss = 0\n#         eval_acc = 0\n#         for data in v_loader:            \n#             img  = data['img']\n#             label  = data['target']\n            \n#             img = Variable(img, volatile=True)\n#             label = Variable(label, volatile=True)\n    \n#             out = model(img).type(torch.FloatTensor).squeeze(1)\n#             loss = criterion(out, label)\n#             eval_loss += loss.data[0] * label.size(0)\n    \n#         print('VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_ds))))\n#         val_losses.append(eval_loss / (len(val_ds)))\n#         print()\n    \n    torch.save(model.state_dict(), './cnn.pth')","cell_type":"code","metadata":{"_uuid":"dce6970dc7686d32f9b92e49880b578b98dd3647","collapsed":true,"_cell_guid":"85270692-7f04-4a94-92fb-57c0a3b27ba5"},"execution_count":null,"outputs":[]},{"source":"","cell_type":"code","metadata":{"_uuid":"abad58921a6aeb5ea0603056bb0021436b73d039","collapsed":true,"_cell_guid":"7025d0d8-206f-4cb0-af69-7b1a85ebd7f8"},"execution_count":null,"outputs":[]}],"nbformat":4}