{"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PyTorch GPU based CNN using BCELoss and torchvision import transforms\n\nThis is my fifth generation PyTorch script which includes many improvements over the previous versions. \nThe previous versions are here:\n\n- https://www.kaggle.com/solomonk/pytorch-gpu-cnn-bceloss-0-2198-lb\n\n- https://www.kaggle.com/solomonk/pytorch-gpu-based-cnn-bceloss-with-predictions\n \nImprovements include:\n1. Automatic calculation of the FC layer size\n2. A nice fit() methood which also does validation (but albeit is slower) \n3. Saving and loading the CNN model \n\nTodo:\n1. Add image transforms, see:  https://discuss.pytorch.org/t/applying-an-image-transform-data-augumentations-to-a-2d-floattensor-pil/9359 \n\nComments are welocmed, \n\n## Updates \n- Update 2/11/2017:\nAdded IcebergCustomDataSet and torchvision  transforms using https://www.kaggle.com/supersp1234/tools-for-pytorch-transform\n\n","metadata":{"_uuid":"22e14672b9865f93dd3fd68b60cfe1714e875090","_cell_guid":"531ab90a-d599-4696-888b-84c851179957"}},{"outputs":[],"metadata":{"_uuid":"bb1dda3b60c8fbfbed8ed30ffba79f39e3812b06","_cell_guid":"1c5adb34-239f-457a-9522-41c1b3fb9cdb"},"cell_type":"code","source":"% reset -f\nimport torch\nimport sys\nimport torch\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nfrom sklearn import cross_validation\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\nfrom sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n\nprint('__Python VERSION:', sys.version)\nprint('__pyTorch VERSION:', torch.__version__)\n\nimport numpy\nimport numpy as np\n\nuse_cuda = torch.cuda.is_available()\nFloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\nLongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\nTensor = FloatTensor\n\nimport pandas\nimport pandas as pd\n\nimport logging\nhandler=logging.basicConfig(level=logging.INFO)\nlgr = logging.getLogger(__name__)\n%matplotlib inline\n\n# !pip install psutil\nimport psutil\nimport os\ndef cpuStats():\n        print(sys.version)\n        print(psutil.cpu_percent())\n        print(psutil.virtual_memory())  # physical memory usage\n        pid = os.getpid()\n        py = psutil.Process(pid)\n        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n        print('memory GB:', memoryUse)\n\ncpuStats()","execution_count":1},{"cell_type":"markdown","source":"# Concatenate and Reshape\nHere we load the data and then combine the two bands and recombine them into a single image/tensor for training","metadata":{"_uuid":"d4d08af6a7165ce1b0eba40d3b784a82b2f283ac","_cell_guid":"f5c415ae-3ab7-4042-ad9c-f843124823cf"}},{"outputs":[],"metadata":{"_uuid":"196c3599b40df0f044c90371bb732ce7e5424abd","_cell_guid":"e7258c0a-2d47-4bdf-b1cf-ac7ab9b542ee"},"cell_type":"code","source":"# Data params\nTARGET_VAR= 'target'\nBASE_FOLDER = '../input/'\ndata = pd.read_json(BASE_FOLDER + '/train.json')\n\ndata['band_1'] = data['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\ndata['band_2'] = data['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\ndata['inc_angle'] = pd.to_numeric(data['inc_angle'], errors='coerce')\n\nprint (type(data))\n\n# Suffle\nimport random\nfrom datetime import datetime\nrandom.seed(datetime.now())\nfrom sklearn.utils import shuffle\n# data = shuffle(data) # otherwise same validation set each time!\n# data= data.reindex(np.random.permutation(data.index))\n\n# data= data.reindex(np.random.permutation(data.index))\n# data = shuffle(data) # otherwise same validation set each time!\n\nband_1 = np.concatenate([im for im in data['band_1']]).reshape(-1, 75, 75)\nband_2 = np.concatenate([im for im in data['band_2']]).reshape(-1, 75, 75)\nfull_img = np.stack([band_1, band_2], axis=1)\n\n\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.utils.data.sampler import RandomSampler\nimport cv2 \n\nbatch_size=64","execution_count":2},{"cell_type":"markdown","source":"# Custom PyTorch Dataset to enable applying image Transforms\n- Since we have a non regular image type, a custom Dataset has to be written (adapted from:https://www.kaggle.com/supersp1234/tools-for-pytorch-transform and https://www.kaggle.com/heyt0ny/pytorch-custom-dataload-with-augmentaion)\n- This is required for enrichment \n","metadata":{"_uuid":"ee42c63c3bd4d0968680ed0c2de108ba7d9266cf","_cell_guid":"886386d4-ef8e-40e8-9e46-e5a0f92fe151"}},{"outputs":[],"metadata":{"_uuid":"334fff5c5b44f8136cc6e195a59cc2b6078f4a9c","_cell_guid":"92eed319-abf5-4035-96ac-93c1f8c906a4"},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils,datasets, models\nimport random\nimport PIL\nfrom PIL import Image, ImageOps\nimport math\nimport torch.nn.functional as F\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nclass IcebergCustomDataSet(Dataset):\n    \"\"\"total dataset.\"\"\"\n\n    def __init__(self, data, labels,transform=None):\n        self.data= data\n        self.labels = labels\n        self.transform = transform        \n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        sample = {'image': self.data[idx,:,:,:], 'labels': np.asarray([self.labels[idx]])}\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample\n\nclass ToTensor(object):\n    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n    def __call__(self, sample):\n        image, labels = sample['image'], sample['labels']\n        # swap color axis because\n        # numpy image: H x W x C\n        # torch image: C X H X W\n        #image = image.transpose((2, 0, 1))\n        image = image.astype(float)/255\n        return {'image': torch.from_numpy(image.copy()).float(),\n                'labels': torch.from_numpy(labels).float()\n               }\nclass RandomHorizontalFlip(object):\n    \"\"\"Horizontally flip the given PIL.Image randomly with a probability of 0.5.\"\"\"\n\n    def __call__(self, sample):\n        \"\"\"\n        Args:\n            img (PIL.Image): Image to be flipped.\n\n        Returns:\n            PIL.Image: Randomly flipped image.\n        \"\"\"\n        image, labels = sample['image'], sample['labels']\n        \n        if random.random() < 0.5:\n            image=np.flip(image,1)\n        \n        return {'image': image, 'labels': labels}\n    \nclass RandomVerticallFlip(object):\n    \"\"\"Horizontally flip the given PIL.Image randomly with a probability of 0.5.\"\"\"\n\n    def __call__(self, sample):     \n        image, labels = sample['image'], sample['labels']\n        if random.random() < 0.5:\n            image=np.flip(image,0)\n        return {'image': image, 'labels': labels} \n\nclass RandomTranspose(object):\n    def __call__(self, sample):     \n        image, labels = sample['image'], sample['labels']\n        if random.random() < 0.7: \n            image=np.transpose(image,0)\n        return {'image': image, 'labels': labels} \n\nclass Normalize(object):   \n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):      \n        # TODO: make efficient\n        img=tensor['image'].float()\n        for t, m, s in zip(img, self.mean, self.std):\n            t.sub_(m).div_(s)\n        return {'image': img, 'labels': tensor['labels']}  \n\nfrom random import randrange    \nrandom.seed(datetime.now()) # re seed \n\nX_train,X_val,y_train,y_val=train_test_split(full_img,data['is_iceberg'].values,\n                                                   test_size=0.33, \n                                                   random_state=randrange(50000))\n\n\n# val_dataset = IcebergCustomDataSet(X_val, y_val, transform=transforms.Compose([\n#                                                               ToTensor(), \n#                                                               ])) \n# train_dataset = IcebergCustomDataSet(X_train, y_train, transform=transforms.Compose([\n#                                                               ToTensor(), \n#                                                               ])) \n\n\ntrain_ds = IcebergCustomDataSet(X_train, y_train, transform=transforms.Compose([\n                                                              RandomHorizontalFlip(), \n                                                              RandomVerticallFlip(),\n                                                              \n                                                              ToTensor(), \n                                                              ])) \n\nval_dataset = IcebergCustomDataSet(X_val, y_val, \n                                transform=transforms.Compose([\n                                                              RandomHorizontalFlip(), \n                                                              RandomVerticallFlip(), \n                                                               \n                                                              ToTensor(), \n                                                              ])) \n\ntrain_loader = DataLoader(dataset=train_ds, batch_size=batch_size,\n                          shuffle=True, num_workers=1)\nval_loader = DataLoader(dataset=val_dataset, batch_size=batch_size,\n                          shuffle=True, num_workers=1)\n\nprint (train_loader)\nprint (val_loader)    ","execution_count":3},{"cell_type":"markdown","source":"# Train/Validation split \n(Not currently in use old version that did not involve image transforms)","metadata":{"_uuid":"9d2e6d45a634d7d8ef386cced633790de459e08e","_cell_guid":"07dc65a6-e81b-4fff-b557-330b3b1233eb"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"6682a80e31ec1ddf0887920fec8b86e6b91b8d06","_cell_guid":"821d15f8-89c5-4a79-b6c2-cb87e2609673"},"cell_type":"code","source":"# # Data params\n# TARGET_VAR= 'target'\n# BASE_FOLDER = '../input/'\n\n\n# data = pd.read_json(BASE_FOLDER + '/train.json')\n\n# data['band_1'] = data['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\n# data['band_2'] = data['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n# data['inc_angle'] = pd.to_numeric(data['inc_angle'], errors='coerce')\n\n# # Suffle\n# import random\n# from datetime import datetime\n# random.seed(datetime.now())\n# # np.random.seed(datetime.now())\n# from sklearn.utils import shuffle\n# data = shuffle(data) # otherwise same validation set each time!\n# data= data.reindex(np.random.permutation(data.index))\n\n# band_1 = np.concatenate([im for im in data['band_1']]).reshape(-1, 75, 75)\n# band_2 = np.concatenate([im for im in data['band_2']]).reshape(-1, 75, 75)\n# full_img = np.stack([band_1, band_2], axis=1)\n\n# Convert the np arrays into the correct dimention and type\n# Note that BCEloss requires Float in X as well as in y\ndef XnumpyToTensor(x_data_np):\n    x_data_np = np.array(x_data_np, dtype=np.float32)        \n    print(x_data_np.shape)\n    print(type(x_data_np))\n\n    if use_cuda:\n        lgr.info (\"Using the GPU\")    \n        X_tensor = (torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n    else:\n        lgr.info (\"Using the CPU\")\n        X_tensor = (torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n        \n    print((X_tensor.shape)) # torch.Size([108405, 29])\n    return X_tensor\n\n\n# Convert the np arrays into the correct dimention and type\n# Note that BCEloss requires Float in X as well as in y\ndef YnumpyToTensor(y_data_np):    \n    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n    print(y_data_np.shape)\n    print(type(y_data_np))\n\n    if use_cuda:\n        lgr.info (\"Using the GPU\")            \n    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n        Y_tensor = (torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n    else:\n        lgr.info (\"Using the CPU\")        \n    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n        Y_tensor = (torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n\n    print(type(Y_tensor)) # should be 'torch.cuda.FloatTensor'\n    print(y_data_np.shape)\n    print(type(y_data_np))    \n    return Y_tensor\n\n\n# #  Custom data loader\n\n# In[17]:\n\n# class FullTrainningDataset(torch.utils.data.Dataset):\n#     def __init__(self, full_ds, offset, length):\n#         self.full_ds = full_ds\n#         self.offset = offset\n#         self.length = length\n#         assert len(full_ds)>=offset+length, Exception(\"Parent Dataset not long enough\")\n#         super(FullTrainningDataset, self).__init__()\n        \n#     def __len__(self):        \n#         return self.length\n    \n#     def __getitem__(self, i):\n#         return self.full_ds[i+self.offset]\n    \n# validationRatio=0.22    \n\n# def trainTestSplit(dataset, val_share=validationRatio):\n#     val_offset = int(len(dataset)*(1-val_share))\n#     print (\"Offest:\" + str(val_offset))\n#     return FullTrainningDataset(dataset, 0, val_offset), FullTrainningDataset(dataset, \n#                                                                               val_offset, len(dataset)-val_offset)\n# batch_size=32\n\n# from torch.utils.data import TensorDataset, DataLoader\n\n# # train_imgs = torch.from_numpy(full_img_tr).float()\n# train_imgs=XnumpyToTensor (full_img)\n# train_targets = YnumpyToTensor(data['is_iceberg'].values)\n# dset_train = TensorDataset(train_imgs, train_targets)\n\n\n# train_ds, val_ds = trainTestSplit(dset_train)\n\n# train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=False,\n#                                             num_workers=1)\n# val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=1)\n\n# print (train_loader)\n# print (val_loader)\n","execution_count":4},{"cell_type":"markdown","source":"# CNN","metadata":{"collapsed":true,"_uuid":"47ae7ccfed58965f8c7458a9d49aa164732faaca","_cell_guid":"c2709d15-9a71-4a2d-ab22-de030dbd6fba"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"1b6fd083b9a2633746c966e5b54669d91a48bab5","_cell_guid":"eb214f3c-33e1-4cfe-b8e6-dc785ee9350d"},"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# See https://github.com/kimhc6028/forward-thinking-pytorch/blob/master/forward_thinking.py for a great example    \n# loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n# dropout = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n# See https://github.com/kimhc6028/forward-thinking-pytorch/blob/master/forward_thinking.py\ndef cnnBlock(in_planes, out_planes,kernel_size=7, padding=2,pool_size=2):\n        conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,padding=padding)\n        bn   = torch.nn.BatchNorm2d(out_planes)\n        relu = torch.nn.LeakyReLU()        \n        pl   = torch.nn.MaxPool2d(pool_size,pool_size)\n        av   = torch.nn.AvgPool2d(pool_size,pool_size)\n#         dr   = torch.nn.Dropout(d_rate)\n        return nn.Sequential(conv, bn, relu,pl,av)\n                \ndropout = [0.65, 0.55, 0.30, 0.20, 0.10, 0.05]\n\nclass CNNClassifier(torch.nn.Module):        \n    def __init__(self, img_size, img_ch, kernel_size, pool_size, n_out, padding):\n        super(CNNClassifier, self).__init__()\n        self.img_size = img_size\n        self.img_ch = img_ch\n        self.kernel_size = kernel_size\n        self.pool_size = pool_size\n        self.padding = padding\n        \n        self.n_out = n_out\n        self.sig=torch.nn.Sigmoid()\n        self.all_losses = []\n        self.val_losses = []  \n        self.cnn_features = []\n        self.layers = []\n        self.build_model()        \n#         print (self)\n    # end constructor\n        \n    def build_model(self):           \n        self.conv1=cnnBlock(self.img_ch, 16, kernel_size=self.kernel_size,padding=self.padding)        \n        self.conv2=cnnBlock(16, 32, kernel_size=5,padding=self.padding)\n        self.conv3=cnnBlock(32, 64, kernel_size=3,padding=self.padding)\n        \n        self.cnn_features = [self.conv1, \n                             self.conv2,\n                             self.conv3,\n                            ]                \n        self.fc = nn.Sequential(\n            nn.Linear(64, self.n_out),\n        )\n        \n        self.criterion = torch.nn.BCELoss()          \n        LR = 0.0005        \n        self.optimizer = torch.optim.Adam(self.parameters(), lr=LR,weight_decay=5e-5) #  L2 regularization\n    # end method build_model\n\n    def forward(self, x):\n        for c in self.cnn_features:\n            x = (c(x))\n        x= self.shrink(x)\n        x= self.fc(x)\n        return self.sig(x)\n    # end method forward\n\n    def shrink(self, X):\n        return X.view(X.size(0), -1)\n    # end method flatten\n\n    def fit(self,loader, num_epochs, batch_size):               \n        self.train()\n        for epoch in range(num_epochs):\n            self.train()\n            print('Epoch {}'.format(epoch + 1))\n            print('*' * 5 + ':')\n            running_loss = 0.0\n            running_acc = 0.0            \n    \n            for i, dict_ in enumerate(loader):\n                images  = dict_['image']\n                target  = dict_['labels']\n#                 images, target=dict_\n#                 self.train()\n                inputs = torch.autograd.Variable(images)\n                labels = torch.autograd.Variable(target)                \n        \n                preds = self.forward(inputs)            # cnn output\n                loss = self.criterion(preds, labels)    # cross entropy loss\n                running_loss += loss.data[0] * labels.size(0)\n                self.optimizer.zero_grad()              # clear gradients for this training step\n                loss.backward()                         # backpropagation, compute gradients\n                self.optimizer.step()                   # apply gradients\n                preds = torch.max(preds, 1)[1].data.numpy().squeeze()\n                acc = (preds == target.numpy()).mean()\n                if (i+1) % 10 == 0:\n                    print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Acc: %.4f'\n                           %(epoch+1, num_epochs, i+1, \n                             int(len(train_ds)/batch_size), loss.data[0], acc)) \n                    \n            #save model\n            torch.save(self.state_dict(), './cnn.pth')\n            #Cross validation\n            self.LeavOneOutValidation(val_loader)            \n        torch.save(self.state_dict(), './cnn.pth')\n    # end method fit\n    \n    def LeavOneOutValidation(self, val_loader): \n        print ('Leave one out VALIDATION ...')\n        model = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n                            pool_size=pool_size, n_out=n_out, padding=padding)\n        # .. to load your previously training model:\n        model.load_state_dict(torch.load('./cnn.pth'))\n        val_losses = []\n        model.eval()\n        print (val_loader)\n        eval_loss = 0\n        eval_acc = 0\n        for data in val_loader:        \n            img  = data['image']\n            label  = data['labels']\n#             img, label=data\n            img = Variable(img, volatile=True)\n            label = Variable(label, volatile=True)\n\n            out = model(img)\n            loss = model.criterion(out, label)\n            eval_loss += loss.data[0] * label.size(0)\n\n        print('Leave one out VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_dataset))))\n        val_losses.append(eval_loss / (len(val_dataset)))\n        print()    \n        \n    def gen_batch(self, arr, batch_size):\n        for i in range(0, len(arr), batch_size):\n            yield arr[i : i + batch_size]\n    # end method gen_batch\n    \n   \n    # end class CNNClassifier","execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{"_uuid":"a86442e28d3d56f5784cbc150f4fdeceda59a390","_cell_guid":"275ec299-3a7c-4ca7-b0f4-3a6b80299c8f"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"596302a7b101347cc51f2751bf8ce471b0cb3801","_cell_guid":"d119aa1d-ff01-4c43-b940-82aa32207fe3"},"cell_type":"code","source":"img_size = (75,75)\nimg_ch = 2\nkernel_size = 7\npool_size = 2\npadding=2\nn_out = 1\nn_epoch = 35\n\nif __name__ == '__main__':\n    cnn = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n                        pool_size=pool_size, n_out=n_out, padding=padding)\n    cnn.fit(train_loader,n_epoch, batch_size)\n#     cnn.evaluate(val_loader, batch_size=8)","execution_count":null},{"cell_type":"markdown","source":"","metadata":{"_uuid":"c59a404fe0b1294f48a9cb79fbede5094a2c9b4a","_cell_guid":"7051bf53-14cf-4811-80e5-ede71360e5de"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"c89f9b77c79ea740bcc39bce704a604f387ac4ca","_cell_guid":"f091cb58-bd95-4d76-8b18-1cd2b471a0b6"},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\n\n# def kFoldValidation(folds): \n#     print ('K FOLD VALIDATION ...')\n#     cnn = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n#                         pool_size=pool_size, n_out=n_out, padding=padding)\n#     # .. to load your previously training model:\n#     model.load_state_dict(torch.load('./cnn.pth'))\n#     val_losses = []\n#     model.eval()\n    \n#     for e in range(folds):\n#         print ('Fold:' + str(e))        \n#         data = pd.read_json('../input/train.json')        \n#         data['band_1'] = data['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\n#         data['band_2'] = data['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n#         data['inc_angle'] = pd.to_numeric(data['inc_angle'], errors='coerce')\n#         band_1 = np.concatenate([im for im in data['band_1']]).reshape(-1, 75, 75)\n#         band_2 = np.concatenate([im for im in data['band_2']]).reshape(-1, 75, 75)\n#         full_img = np.stack([band_1, band_2], axis=1)\n                                \n#         X_train,X_val,y_train,y_val=train_test_split(full_img,data['is_iceberg'].values,\n#                                                    test_size=0.11, \n#                                                    random_state=randrange(3000))\n#         # Only need val set\n#         val_dataset_kfold = IcebergCustomDataSet(X_val, y_val, \n#                                 transform=transforms.Compose([RandomHorizontalFlip(), \n#                                                               RandomVerticallFlip(), \n#                                                               ToTensor(), \n#                                                               ])) \n#         val_loader_kfold = DataLoader(dataset=val_dataset, batch_size=batch_size,\n#                           shuffle=True, num_workers=1)\n        \n#         print (val_loader_kfold)\n\n#         eval_loss = 0\n#         eval_acc = 0\n#         for data in val_loader:\n#             img  = data['image']\n#             label  = data['labels']\n\n#             img = Variable(img, volatile=True)\n#             label = Variable(label, volatile=True)\n\n#             out = model(img)\n#             loss = model.criterion(out, label)\n#             eval_loss += loss.data[0] * label.size(0)\n\n#         print('VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_dataset_kfold))))\n#         val_losses.append(eval_loss / (len(val_dataset_kfold)))\n#         print()\n    \ndef LeavOneOutValidation(val_loader): \n    print ('Leave one out VALIDATION ...')\n    model = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n                        pool_size=pool_size, n_out=n_out, padding=padding)\n    # .. to load your previously training model:\n    model.load_state_dict(torch.load('./cnn.pth'))\n    val_losses = []\n    model.eval()        \n    print (val_loader)\n    eval_loss = 0\n    eval_acc = 0\n    for data in val_loader:        \n        img  = data['image']\n        label  = data['labels']\n        img = Variable(img, volatile=True)\n        label = Variable(label, volatile=True)\n        out = model(img)\n        loss = model.criterion(out, label)\n        eval_loss += loss.data[0] * label.size(0)\n    print('Leave one out VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_dataset))))\n    val_losses.append(eval_loss / (len(val_dataset)))\n    print()\n    print()        \n    \nLeavOneOutValidation(val_loader)    ","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"1b27b0abe97351669c847040687b6de44fd1fd52","_cell_guid":"0132970d-1c83-4785-bfea-73876af38b0b"},"cell_type":"code","source":"# kFoldValidation(10)","execution_count":null},{"cell_type":"markdown","source":"# Make Predictions\nHere we make predictions on the output and export the CSV so we can submit","metadata":{"_uuid":"a5f2ddcc3d70b5c41a870e5961fe907ee268d32b","_cell_guid":"e2ed31f1-3fa0-4b75-bcde-51ad11f70a00"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"7e33c89ae19e631fcea492d8b306d2cd47f22c92","_cell_guid":"f5bc1e63-60a8-42d8-93a1-8c752b0d6f6e"},"cell_type":"code","source":"# load the model\n# model=torch.load('./cnn.pth')\nmodel = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n                        pool_size=pool_size, n_out=n_out, padding=padding)\n# .. to load your previously training model:\nmodel.load_state_dict(torch.load('./cnn.pth'))\nprint (model)\n\ndf_test_set = pd.read_json('../input/test.json')\n\ndf_test_set['band_1'] = df_test_set['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\ndf_test_set['band_2'] = df_test_set['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\ndf_test_set['inc_angle'] = pd.to_numeric(df_test_set['inc_angle'], errors='coerce')\n\ndf_test_set.head(3)\n\n\nprint (df_test_set.shape)\ncolumns = ['id', 'is_iceberg']\ndf_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n# df_pred.id.astype(int)\n\nfor index, row in df_test_set.iterrows():\n    rwo_no_id=row.drop('id')    \n    band_1_test = (rwo_no_id['band_1']).reshape(-1, 75, 75)\n    band_2_test = (rwo_no_id['band_2']).reshape(-1, 75, 75)\n    full_img_test = np.stack([band_1_test, band_2_test], axis=1)\n\n    x_data_np = np.array(full_img_test, dtype=np.float32)        \n    if use_cuda:\n        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n    else:\n        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n                    \n#     X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n    predicted_val = (model(X_tensor_test).data).float() # probabilities     \n    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n    \n    df_pred = df_pred.append({'id':row['id'], 'is_iceberg':p_test},ignore_index=True)\n#     df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n\ndf_pred.head(5)","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"089b7e22bfb305a21f5ee2f9a0f47ee3ecd11c95","_cell_guid":"31b60d26-13ad-4004-8e22-5ee20d56defb"},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.plot(model.all_losses)\nplt.show()","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"cb940713b1d74f8175ef2bfd904305994db759e1","_cell_guid":"84882b4a-7f43-4b85-b184-5775bfea3146"},"cell_type":"code","source":"# df_pred.id=df_pred.id.astype(int)\n\ndef savePred(df_pred):\n#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n#     csv_path = 'pred_{}_{}.csv'.format(loss, (str(time.time())))\n    csv_path='sample_submission.csv'\n    df_pred.to_csv(csv_path, columns=('id', 'is_iceberg'), index=None)\n    print (csv_path)\n    \nsavePred (df_pred)","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"0eb588f141c6c88e4a5fb958bc6e4d431b7f56b9","_cell_guid":"bb0b012f-d5b0-4a59-b33b-273447f5f549"},"cell_type":"code","source":"","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"03052e5ab85c3fac83f5a31177243e9774efcd3f","_cell_guid":"00e5267c-9f38-4654-aa8a-517fcbec4e43"},"cell_type":"code","source":"","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"9b3892c0048b1887a5ed97ff907c85fcaa0c1bdc","_cell_guid":"54f8233e-6a0f-4a29-beee-2a29c76b7228"},"cell_type":"code","source":"","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"42940f8bb08d6b48e577141b0a5fedddc22bd78e","_cell_guid":"6f601c0b-7bce-4e63-b10b-0e500607cd6f"},"cell_type":"code","source":"","execution_count":null}],"nbformat_minor":1,"metadata":{"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","name":"python","version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}}}