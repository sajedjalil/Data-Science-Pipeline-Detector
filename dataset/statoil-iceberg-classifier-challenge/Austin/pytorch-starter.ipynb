{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom tqdm import tqdm_notebook\nimport seaborn as sns","metadata":{"_cell_guid":"303a9986-71cd-41d0-b53a-0b26ac4007cb","_uuid":"c1cf1feee03e3784251c9ae345244d9ae5375af3","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')\n","metadata":{"_cell_guid":"5861c386-86d2-4177-900e-7ed30aa76795","_uuid":"db4d4d6154afcb3a5d444b0f288f04b9b15e35c0","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['band_1'] = data['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\ndata['band_2'] = data['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\ntest['band_1'] = test['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\ntest['band_2'] = test['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n\ndata['inc_angle'] = pd.to_numeric(data['inc_angle'], errors='coerce')\ntest['inc_angle'] = pd.to_numeric(test['inc_angle'], errors='coerce')\n\ntrain = data.sample(frac=0.8)\nval = data[~data.isin(train)].dropna()","metadata":{"_cell_guid":"cc4ffad0-682b-4189-90ff-2ba3f7dd06d1","_uuid":"03a65e001dd2f489526d69d9050ced2c7f86b278","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"1a4b5e71cde91e11e265dec6976ff13588aaa1b0","_cell_guid":"af9554de-5a48-4e02-be69-73718450e0ec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## check NaNs, ignore inc_angle for now","metadata":{"_uuid":"93e00078db03e6c0f4559142a03de167d676e9f4","_cell_guid":"2f498192-6c0b-4d1b-a69b-f60079ba3e0c"}},{"cell_type":"code","source":"train.info()","metadata":{"_uuid":"71809564010f972105b7401db85318fc156e6542","_cell_guid":"4fddd47a-6fd3-4ddb-af25-05f60017c09f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Class Balance","metadata":{"_uuid":"dfaefa3dd3496dcef3d3756667eed09f24032d5c","_cell_guid":"357a59fe-4d8b-443d-9db3-b808b3a82936"}},{"cell_type":"code","source":"sns.countplot(train['is_iceberg']);","metadata":{"_uuid":"3990351fb1641563855b9941da4d2b8bdf9d8366","_cell_guid":"25a5ea24-8dff-4b7f-b5a2-cce48732c61e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(df, idx):\n    c = ( 'Not Hotdog', 'Hotdog')\n    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n    ax1.imshow(df['band_1'].iloc[idx])\n    ax2.imshow(df['band_2'].iloc[idx])\n    ax3.hist(df['band_1'].iloc[idx].ravel(), bins=256, fc='k', ec='k');\n    ax4.hist(df['band_2'].iloc[idx].ravel(), bins=256, fc='k', ec='k');\n    f.set_figheight(10)\n    f.set_figwidth(10)\n    plt.suptitle(c[df['is_iceberg'].iloc[idx]])\n    plt.show()","metadata":{"_cell_guid":"5e5c251e-c84f-4284-93f9-da758b967708","_uuid":"f021f9f1eedc6a8a75da2297add391cea31bee90","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_sample(train, 764)","metadata":{"_uuid":"423a89a2e8d88bb349e9e7d1b6b6860748619b11","_cell_guid":"4e6a6ab0-552e-4bbc-9030-c66d48991ade"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_sample(train, 2)","metadata":{"_uuid":"7149a3dfb49c56e5393dd90e93c401a32ec78109","_cell_guid":"1328f51c-452a-4da5-9404-5850aa17b011"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Concat Bands into (N, 2, 75, 75) images","metadata":{"_uuid":"64e3489d0f8f58fe011a3785e799c45df9a1fdf3","_cell_guid":"02ad0f9b-6223-48af-ad33-57b5e1b08cfc"}},{"cell_type":"code","source":"band_1_tr = np.concatenate([im for im in train['band_1']]).reshape(-1, 75, 75)\nband_2_tr = np.concatenate([im for im in train['band_2']]).reshape(-1, 75, 75)\nfull_img_tr = np.stack([band_1_tr, band_2_tr], axis=1)\n\nband_1_val = np.concatenate([im for im in val['band_1']]).reshape(-1, 75, 75)\nband_2_val = np.concatenate([im for im in val['band_2']]).reshape(-1, 75, 75)\nfull_img_val = np.stack([band_1_val, band_2_val], axis=1)\n\nband_1_test = np.concatenate([im for im in test['band_1']]).reshape(-1, 75, 75)\nband_2_test = np.concatenate([im for im in test['band_2']]).reshape(-1, 75, 75)\nfull_img_test = np.stack([band_1_test, band_2_test], axis=1)\n","metadata":{"_cell_guid":"81e1fb9f-61e7-4a64-baa9-d4348a945f7f","_uuid":"2c37a3d625bfa6dcaaa97c12d8070249b16a2377","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{"_uuid":"e99daa83567a13ab4e86e9451e03995c731e6c2b","_cell_guid":"f845a93e-faa5-40c6-af89-14e813a8ba34"}},{"cell_type":"code","source":"train_imgs = torch.from_numpy(full_img_tr).float()\ntrain_targets = torch.from_numpy(train['is_iceberg'].values).long()\ntrain_dataset = TensorDataset(train_imgs, train_targets)\n\nval_imgs = torch.from_numpy(full_img_val).float()\nval_targets = torch.from_numpy(val['is_iceberg'].values).long()\nval_dataset = TensorDataset(val_imgs, val_targets)\n\n\ntest_imgs  = torch.from_numpy(full_img_test).float()\n\n","metadata":{"_cell_guid":"8c2b51ec-1eeb-4519-bb56-49a3dc525386","_uuid":"dccb943235b8fd0cae479601e70f864526a8df86","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"_uuid":"12a5c2028b61fe93ce0e58981d6a66dba9fd9b8d","_cell_guid":"1b89d96e-cb0b-4497-b169-7c93f0aebb47"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define simple model","metadata":{"_uuid":"21eacbdcf5f04eecf86da49621b5aff4d3b92d8d","_cell_guid":"9655dd9c-c792-4d15-bb8b-94a800eb9c0e"}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.batch = nn.BatchNorm2d(2)\n        self.conv1 = nn.Conv2d(2, 32, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(64 * 18 * 18, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 2)\n\n    def forward(self, x):\n        x = self.batch(x)\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"_cell_guid":"03178a5e-e8ef-4334-a97d-f1cf7c0fecf8","_uuid":"4112e0197ba91e6ab2d39c65d67ed112fdc78729","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = Net()","metadata":{"_cell_guid":"9b03f56c-1e44-4083-9865-e4e1e08970b3","_uuid":"1957c1d7b492da1aa1aa67aa69fdfc46638e302e","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"_uuid":"d14d6e56da8fc08a04dede4ad982fc95c332c79b","_cell_guid":"3e6db15e-bcab-421e-bab6-cd0e1d387736"}},{"cell_type":"code","source":"epochs = 2\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(net.parameters())","metadata":{"_cell_guid":"85270692-7f04-4a94-92fb-57c0a3b27ba5","_uuid":"dce6970dc7686d32f9b92e49880b578b98dd3647","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utils \nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self, window_size=None):\n        self.length = 0\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n        self.window_size = window_size\n\n    def reset(self):\n        self.length = 0\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        if self.window_size and (self.count >= self.window_size):\n            self.reset()\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \ndef accuracy(y_true, y_pred):\n    y_true = y_true.float()\n    _, y_pred = torch.max(y_pred, dim=-1)\n    return (y_pred.float() == y_true).float().mean()\n    \ndef fit(train, val, epochs, batch_size):\n    print('train on {} images validate on {} images'.format(len(train), len(val)))\n    net.train()\n    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False)\n    for epoch in tqdm_notebook(range(epochs), total=epochs):\n        running_loss = AverageMeter()\n        running_accuracy = AverageMeter()\n        val_loss_meter = AverageMeter()\n        val_acc_meter = AverageMeter()\n        pbar = tqdm_notebook(train_loader, total=len(train_loader))\n        for data, target in pbar:\n            data, target = Variable(data), Variable(target)\n            output = net(data)\n            loss = criterion(output, target)\n            acc = accuracy(target.data, output.data)\n            running_loss.update(loss.data[0])\n            running_accuracy.update(acc)\n            pbar.set_description(\"[ loss: {:.4f} | acc: {:.4f} ] \".format(\n                running_loss.avg, running_accuracy.avg))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        print(\"[ loss: {:.4f} | acc: {:.4f} ] \".format(running_loss.avg, running_accuracy.avg))\n        for val_data, val_target in val_loader:\n            val_data, val_target = Variable(val_data), Variable(val_target)\n            output = net(val_data)\n            val_loss = criterion(output, val_target)\n            val_acc = accuracy(val_target.data, output.data)\n            val_loss_meter.update(val_loss.data[0])\n            val_acc_meter.update(val_acc)\n        pbar.set_description(\"[ loss: {:.4f} | acc: {:.4f} | vloss: {:.4f} | vacc: {:.4f} ] \".format(\n        running_loss.avg, running_accuracy.avg, val_loss_meter.avg, val_acc_meter.avg))\n        print(\"[ loss: {:.4f} | acc: {:.4f} | vloss: {:.4f} | vacc: {:.4f} ] \".format(\n        running_loss.avg, running_accuracy.avg, val_loss_meter.avg, val_acc_meter.avg))","metadata":{"_cell_guid":"78485c3a-7a3a-45cb-a274-ab5b18c75086","_uuid":"86c0dd0d72371012f63ac546cfe383426c699643","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit(train_dataset, val_dataset, 3, 32)","metadata":{"_uuid":"e3dfaaa671f7541e2a35cb6c0ef43886153e9deb","_cell_guid":"075b1bff-b336-4248-a5ae-7b2b75baaf31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit(train_dataset, val_dataset, 3, 32)","metadata":{"_uuid":"42f3a731631d9da4a9d765e222d21c9f63cc22fe","_cell_guid":"75ed79a5-5d79-4b62-9aa0-e7490e1004b7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Overfitting at 4 epochs","metadata":{"_uuid":"e706a40b65b9643482ea4213f760ec354cdeea31","_cell_guid":"877d62dd-b699-4ee5-a4c9-1cd278dcefe6"}},{"cell_type":"code","source":"","metadata":{"_cell_guid":"7025d0d8-206f-4cb0-af69-7b1a85ebd7f8","_uuid":"abad58921a6aeb5ea0603056bb0021436b73d039","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]}]}