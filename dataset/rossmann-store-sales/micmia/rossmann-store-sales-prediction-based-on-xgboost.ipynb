{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style='whitegrid', palette='muted')\n\ndata_train = pd.read_csv('../input/train.csv',\n                         dtype={\n                             'StateHoliday': 'category',\n                             'SchoolHoliday': 'category'},\n                         parse_dates=['Date'])\ndata_test = pd.read_csv('../input/test.csv',\n                        dtype={\n                            'StateHoliday': 'category',\n                            'SchoolHoliday': 'category'},\n                        parse_dates=['Date'])\ndata_store = pd.read_csv('../input/store.csv',\n                         dtype={\n                             'StoreType': 'category',\n                             'Assortment': 'category',\n                             'CompetitionOpenSinceMonth': float,\n                             'CompetitionOpenSinceYear': float,\n                             'Promo2': float,\n                             'Promo2SinceWeek': float,\n                             'Promo2SinceYear': float})\ndata_train = pd.merge(data_train, data_store, on='Store', how='left')\ndata_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of samples:', data_train.shape[0])\nprint('')\ndata_train.info()\nprint('')\nprint(data_train.iloc[:, 1:].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = data_train.isnull().sum()\nprint('Missing value counts:')\nprint(counts)\nplt.figure(figsize=(10, 3))\ng = sns.barplot(counts.index, counts.values)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(15, 8))\nsns.distplot(data_train['Sales'].dropna(), bins=20, ax=axes[0][0]);\nsns.distplot(data_train['CompetitionDistance'].dropna(), bins=20, ax=axes[0][1]);\nsns.boxplot(x=data_train['Sales'].dropna(), ax=axes[1][0])\nsns.boxplot(x=data_train['CompetitionDistance'].dropna(), ax=axes[1][1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\ndata_train_sales = data_train[['Date', 'Sales']]\ndata_train_sales_1 = data_train_sales.groupby(pd.Grouper(key='Date', freq='7D')).mean()\nax = sns.lineplot(x=data_train_sales_1.index, y=data_train_sales_1['Sales'])\nax.set_title('Average daily sales per 7 days from 2013-01 to 2015-07')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\ndata_train_customers = data_train[['Date', 'Customers']]\ndata_train_customers_1 = data_train_customers.groupby(pd.Grouper(key='Date', freq='7D')).mean()\nax = sns.lineplot(x=data_train_customers_1.index, y=data_train_customers_1['Customers'])\nax.set_title('Average daily customers per 7 days from 2013-01 to 2015-07')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.scatterplot(x=data_train_sales_1['Sales'], y=data_train_customers_1['Customers']).set_title('Sales and Customers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_open_sl_cstm = data_train[['Sales', 'Customers']]\ndata_train_open_sl_cstm.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 4))\ndata_train_wd = data_train.copy()\ndata_train_wd['Year'] = data_train_wd['Date'].dt.strftime('%Y')\ndata_train_wd = data_train_wd.groupby(['Year', 'DayOfWeek']).mean().reset_index()\nsns.barplot(x='DayOfWeek', y='Sales', hue='Year', palette='pastel', data=data_train_wd)\ndata_train_wd = data_train_wd.groupby(['DayOfWeek']).mean().reset_index()\nax = sns.lineplot(x=data_train_wd.index, y=data_train_wd['Sales'], color='#c64d4f')\nax.set_title('Average daily sales by day of week')\nax.legend_.set_title('Year')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 4))\ndata_train_m = data_train.copy()\ndata_train_m['Year'] = data_train_m['Date'].dt.strftime('%Y')\ndata_train_m['Month'] = data_train_m['Date'].dt.strftime('%m')\ndata_train_m = data_train_m.groupby(['Year', 'Month']).mean().reset_index()\nsns.barplot(x='Month', y='Sales', hue='Year', palette='pastel', data=data_train_m)\ndata_train_m = data_train_m.groupby(['Month']).mean().reset_index()\nax = sns.lineplot(x=data_train_m.index, y=data_train_m['Sales'], color='#c64d4f')\nax.set_title('Average daily sales by month')\nax.legend_.set_title('Year')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 4))\ndata_train_ = data_train.copy()\ndata_train_ = data_train_[['Sales', 'Date', 'Promo', 'Promo2']]\ndata_train_['Promo_Promo2'] = data_train_['Promo'] & data_train_['Promo2']\ndata_train_ = data_train_.groupby([pd.Grouper(key='Date', freq='30D'), 'Promo', 'Promo_Promo2']).mean().reset_index()\nax = sns.lineplot(x='Date', y='Sales', hue='Promo', style='Promo_Promo2', data=data_train_, markers=True, dashes=False)\nax.set_title('Average daily sales per 30 days by promo')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 3))\nax = sns.boxplot(x='StoreType', y='Sales', hue='Assortment', palette='pastel', data=data_train)\nax.set_title('Sales by StoreType and Assortment')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering and preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create utilities for preprocessing\ndef read_csv(files):\n    data_train = pd.read_csv(files[0],\n                             dtype={\n                                 'StateHoliday': 'category',\n                                 'SchoolHoliday': 'int'},\n                             parse_dates=['Date'])\n\n    data_test = pd.read_csv(files[1],\n                            dtype={\n                                'StateHoliday': 'category',\n                                'SchoolHoliday': 'int'},\n                            parse_dates=['Date'])\n\n    data_store = pd.read_csv(files[2],\n                             dtype={\n                                 'StoreType': 'category',\n                                 'Assortment': 'category',\n                                 'CompetitionOpenSinceMonth': float,\n                                 'CompetitionOpenSinceYear': float,\n                                 'Promo2': float,\n                                 'Promo2SinceWeek': float,\n                                 'Promo2SinceYear': float,\n                                 'PromoInterval': str})\n\n    return data_train, data_test, data_store\n\ndef combine(data, data_store):\n    return pd.merge(data, data_store, on='Store', how='left')\n\ndef preprocess(data_train, data_test):\n    data_train_ = data_train.copy()\n    data_test_ = data_test.copy()\n\n    data_train_ = data_train_[(data_train_['Sales'] > 0) & (data_train_['Open'] != 0)]\n    data_test_['Open'] = data_test_['Open'].fillna(1)\n\n    def process(data):\n        data['Year'] = data['Date'].dt.year\n        data['Month'] = data['Date'].dt.month\n        data['Day'] = data['Date'].dt.day\n        data['DayOfWeek'] = data['Date'].dt.dayofweek\n        data['DayOfYear'] = data['Date'].dt.dayofyear\n        data['WeekOfYear'] = data['Date'].dt.weekofyear\n        data['Quarter'] = (data['Date'].dt.month - 1) // 3 + 1\n\n        mappings = {'0': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4}\n        data['StoreType'].replace(mappings, inplace=True)\n        data['Assortment'].replace(mappings, inplace=True)\n        data['StateHoliday'].replace(mappings, inplace=True)\n\n        data['CompetitionDistance'] = data['CompetitionDistance'].fillna(data['CompetitionDistance'].median())\n\n        # Extend features\n        data['CompetitionOpen'] = 12 * (data['Year'] - data['CompetitionOpenSinceYear']) + (data['Month'] - data['CompetitionOpenSinceMonth']).apply(lambda x: x if x > 0 else 0)\n\n        data['Promo2Open'] = 12 * (data['Year'] - data['Promo2SinceYear']) + (data['WeekOfYear'] - data['Promo2SinceWeek']) / 4.0\n        data['Promo2Open'] = data['Promo2Open'].apply(lambda x: x if x > 0 else 0)\n\n        data['PromoInterval'] = data['PromoInterval'].fillna('')\n        data['InPromoMonth'] = data.apply(lambda x: 1 if (x['Date'].strftime('%b') if not x['Date'].strftime('%b') == 'Sep' else 'Sept') in x['PromoInterval'].split(',') else 0, axis=1)\n\n        data_meanlog_salesbystore = data_train_.groupby(['Store'])['Sales'].mean().reset_index(name='MeanLogSalesByStore')\n        data_meanlog_salesbystore['MeanLogSalesByStore'] = np.log1p(data_meanlog_salesbystore['MeanLogSalesByStore'])\n        data = data.merge(data_meanlog_salesbystore, on=['Store'], how='left', validate='m:1')\n\n        data_meanlog_salesbydow = data_train_.groupby(['DayOfWeek'])['Sales'].mean().reset_index(name='MeanLogSalesByDOW')\n        data_meanlog_salesbydow['MeanLogSalesByDOW'] = np.log1p(data_meanlog_salesbystore['MeanLogSalesByStore'])\n        data = data.merge(data_meanlog_salesbydow, on=['DayOfWeek'], how='left', validate='m:1')\n\n        data_meanlog_salesbymonth = data_train_.groupby(['Month'])['Sales'].mean().reset_index(name='MeanLogSalesByMonth')\n        data_meanlog_salesbymonth['MeanLogSalesByMonth'] = np.log1p(data_meanlog_salesbymonth['MeanLogSalesByMonth'])\n        data = data.merge(data_meanlog_salesbymonth, on=['Month'], how='left', validate='m:1')\n\n        return data\n\n    features = [\n        'Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'DayOfYear', 'WeekOfYear', 'Quarter', 'Open', 'Promo',\n        'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n        'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'CompetitionOpen',\n        'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'Promo2Open', 'InPromoMonth',\n        'MeanLogSalesByStore', 'MeanLogSalesByDOW', 'MeanLogSalesByMonth']\n\n    data_train_ = process(data_train_)\n    data_test_ = process(data_test_)\n\n    return (data_train_[features], np.log1p(data_train_['Sales'])), data_test_[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)  \npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)\n\ndata_train, data_test, data_store = read_csv(['../input/train.csv', '../input/test.csv', '../input/store.csv'])\ndata_train = combine(data_train, data_store)\ndata_test = combine(data_test, data_store)\n(X_train, y_train), X_test = preprocess(data_train, data_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementing model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation function\ndef rmspe(y_true, y_pred):\n    err = np.sqrt(np.mean((1 - y_pred / y_true) ** 2))\n    return err\n\n# Evaluation function adapted to XGBoost\ndef rmspe_xgb(y_pred, y_true):\n    y_true = y_true.get_label()\n    err = rmspe(y_true, y_pred)\n    return 'rmspe', err","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nclass Model:\n    def __init__(self, params=None, **kwargs):\n        self.params = params\n        self.kwargs = kwargs\n\n    def train(self, X, y):\n        X_train, X_test, y_train, y_test = X[41088:], X[:41088], y[41088:], y[:41088]\n        dtrain = xgb.DMatrix(X_train, label=y_train)\n        dvalid = xgb.DMatrix(X_test, label=y_test)\n        watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n        self.bst = xgb.train(self.params, dtrain, self.kwargs['num_boost_round'], evals=watchlist,\n                             feval=rmspe_xgb, early_stopping_rounds=self.kwargs['early_stopping_rounds'],\n                             verbose_eval=True)\n\n    def predict(self, X, weight=0.995):\n        y_pred = np.expm1(weight * self.bst.predict(xgb.DMatrix(X)))\n        return y_pred\n\n    def save_model(self, filename):\n        joblib.dump(self.bst, filename)\n\n    def load_model(self, filename):\n        self.bst = joblib.load(filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Train the model\nparams = {\n    'eta': 0.03,\n    'max_depth': 10,\n    'subsample': 0.8,\n    'colsample_bytree': 0.7,\n    'lambda': 0.2,\n    'silent': 1,\n    'seed': 12\n}\n\nm = Model(params, num_boost_round=5000, early_stopping_rounds=50)\nm.train(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correction(model, y_train):\n    y_true, y_pred = y_train[:41088], model.bst.predict(xgb.DMatrix(X_train[:41088]))\n    weights = np.arange(0.98, 1.02, 0.005)\n    errors = []\n    \n    for w in weights:\n        error = rmspe(np.expm1(y_true[:41088]), np.expm1(y_pred * w))\n        errors.append(error)\n\n    plt.plot(weights, errors)\n    plt.xlabel('weight')\n    plt.ylabel('RMSPE')\n    plt.title('RMSPE Curve')\n    \n    idx = errors.index(min(errors))\n    print('Best weight is {}, RMSPE is {:.4f}'.format(weights[idx], min(errors)))\n    \ncorrection(m, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nweight = 1.0\ny_pred = m.predict(X_test, weight=weight)\n\nresult = pd.DataFrame({'Id': data_test['Id'], 'Sales': y_pred})\nresult.to_csv('submission.csv', index=False)\nresult","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}