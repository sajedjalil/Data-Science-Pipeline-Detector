{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Import stuff"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import warnings\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\n#plt.style.use('fivethirtyeight')\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib\nimport datetime\nfrom IPython.display import clear_output\nimport time\nimport seaborn as sns\nsns.set_style('darkgrid')\ncolor = sns.color_palette()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read the csv data "},{"metadata":{"trusted":false},"cell_type":"code","source":"train = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert date column to datetime type"},{"metadata":{"trusted":false},"cell_type":"code","source":"train['Date'] = pd.to_datetime(train['Date'])\ntest['Date'] = pd.to_datetime(test['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"display(train.head())\ndisplay(test.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sort test & train data by store then date"},{"metadata":{"trusted":false},"cell_type":"code","source":"test = test.sort_values(by=['Store','Date'])\ntrain = train.sort_values(by=['Store','Date'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"train['Date'].unique().max(), train['Date'].unique().min() \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test['Date'].unique().max(), test['Date'].unique().min() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test[test['Store'] == 1].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get store list from needed for test data"},{"metadata":{"trusted":false},"cell_type":"code","source":"store_list = test['Store'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyzing data"},{"metadata":{},"cell_type":"markdown","source":"Stasionary test and acf, pacf graph"},{"metadata":{"trusted":false},"cell_type":"code","source":"store = 21\n\ndate_from = '2013-06-02'\ndate_to = ''\nrsmpl_opt = '3d'\nspqd_period = 24\nprogram_starts = time.time()\niters = 0\n\nsales = train[train['Store'] == store]\nsales = sales.set_index('Date')\nsales = sales[date_from:]\n\nsales_exog = sales[['Open','Promo','StateHoliday','SchoolHoliday']]\nsales_exog['Open'] = pd.to_numeric(sales_exog['Open'], errors='coerce').fillna(0)\nsales_exog['Promo'] = pd.to_numeric(sales_exog['Promo'], errors='coerce').fillna(0)\nsales_exog['StateHoliday'] = pd.to_numeric(sales_exog['StateHoliday'], errors='coerce').fillna(0)\nsales_exog['SchoolHoliday'] = pd.to_numeric(sales_exog['SchoolHoliday'], errors='coerce').fillna(0)\n\nsales_exog = sales_exog[date_from:]\n\nsales_exog = sales_exog.resample(rsmpl_opt).mean()\n#sales_exog = sales_exog\nsales_exog = sales_exog.fillna({'Open':0, 'Promo':0, 'StateHoliday':0, 'SchoolHoliday':0})\n#print(sales_exog)\n\n\n\nsales = sales['Sales'].resample(rsmpl_opt).mean()    \n\n\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(sales, lags=len(sales)/2-1, ax=ax1) # \nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(sales, lags=len(sales)/2-1, ax=ax2)# , lags=40\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(sales, lags=len(sales)/2-1, ax=ax1) # \nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(sales, lags=len(sales)/2-1, ax=ax2)# , lags=40","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\ndef test_stationarity(timeseries, window = 12, cutoff = 0.01):\n\n    #Determing rolling statistics\n    rolmean = timeseries.rolling(window).mean()\n    rolstd = timeseries.rolling(window).std()\n\n    #Plot rolling statistics:\n    fig = plt.figure(figsize=(12, 8))\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show()\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC', maxlag = 20 )\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    pvalue = dftest[1]\n    if pvalue < cutoff:\n        print('p-value = %.4f. The series is likely stationary.' % pvalue)\n    else:\n        print('p-value = %.4f. The series is likely non-stationary.' % pvalue)\n    \n    print(dfoutput)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"test_stationarity(sales)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"first_diff = sales - sales.shift(1)\nfirst_diff = first_diff.dropna(inplace = False)\ntest_stationarity(first_diff, window = 12)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(first_diff, lags=len(first_diff)-2,ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(first_diff, lags=len(first_diff)/2-1, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MAIN SARIMAX LOOP FOR ALL STORE LIST"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"hasil = pd.DataFrame()\n\n# Change the rsmpl_opt and also spqd_period for different smoothing of data \ndate_from = '2013-06-02'\ndate_to = ''\nrsmpl_opt = 'M'\nspqd_period = 12\nprogram_starts = time.time()\niters = 0\n\nfor store in store_list:\n    \n   \n    sales = train[train['Store'] == store]\n    sales = sales.set_index('Date')\n    sales = sales[date_from:]\n    \n    sales_exog = sales[['Open','Promo','StateHoliday','SchoolHoliday']]\n    sales_exog['Open'] = pd.to_numeric(sales_exog['Open'], errors='coerce').fillna(0)\n    sales_exog['Promo'] = pd.to_numeric(sales_exog['Promo'], errors='coerce').fillna(0)\n    sales_exog['StateHoliday'] = pd.to_numeric(sales_exog['StateHoliday'], errors='coerce').fillna(0)\n    sales_exog['SchoolHoliday'] = pd.to_numeric(sales_exog['SchoolHoliday'], errors='coerce').fillna(0)\n    \n    sales_exog = sales_exog[date_from:]\n    \n    sales_exog = sales_exog.resample(rsmpl_opt).mean()\n    #sales_exog = sales_exog\n    sales_exog = sales_exog.fillna({'Open':0, 'Promo':0, 'StateHoliday':0, 'SchoolHoliday':0})\n    #print(sales_exog)\n    \n    \n    \n    sales = sales['Sales'].resample(rsmpl_opt).mean()    \n    #y = pd.DataFrame(sales['Sales'])\n    \n    \n    \n    #params\n    p = d = q = range(0, 2)\n    pdq = list(itertools.product(p, [1], q))\n    seasonal_pdq = [(x[0], 1, x[2], spqd_period) for x in pdq]\n    #seasonal_pdq = [(0, 1, 1, spqd_period)]\n    # IMPORTANTTTTT\n    \n    #p = q = range(0, 6) \n    #pdq = list(itertools.product([0], [1], q)) \n    #sp = sq = range(1,8)#range(0,1) <- ARIMAX \n    #seasonal_pdq = list(itertools.product(sp, [0,1], sq,[1]))#rlist(itertools.product(sp, [0], sq,[0]))<- ARIMAX\n    \n    \n    #p = d = q = range(0, 6)\n    #pdq = list(itertools.product(p, [1], q))\n    #seasonal_pdq = [(x[0], x[1], x[2], spqd_period) for x in pdq]\n    #seasonal_pdq = [(0, 1, 1, spqd_period)]\n    \n    \n    \n    #search for the best params\n    aic = 9999999999999999999\n    for param in pdq:\n        for param_seasonal in seasonal_pdq:\n            try:\n                mod2 = sm.tsa.statespace.SARIMAX(sales,\n                                                exog=sales_exog,\n                                                order=param,\n                                                seasonal_order=param_seasonal,\n                                                enforce_stationarity=False,\n                                                enforce_invertibility=False,\n                                                error_action='ignore',\n                                                suppress_warnings=True)\n                results = mod.fit()\n\n                if ((results.aic < 50) && ) :\n                    aic = results.aic\n                    st = f'ARIMA{param}x{param_seasonal}12 - AIC:{results.aic}'\n                    pl = param  #param with lowest aic\n                    pls = param_seasonal #param_seasonal with lowest aic\n                    mod = mod2\n                    return\n            except:\n                continue\n            \n\n    #print('=========LOWEST AIC===========')\n    \n    #print(f'ARIMA{pl}x{pls}12 - AIC:{results.aic}')\n    #print([pl[0], pl[1], pl[2]])\n    #print([pls[0], pls[1], pls[2]])\n\n    #mod = sm.tsa.statespace.SARIMAX(sales,\n    #                                exog=sales_exog,\n    #                                order=(pl[0], pl[1], pl[2]),\n     #                               seasonal_order=(pls[0], pls[1], pls[2], spqd_period), # IMPORTANTTTTT\n    #                                enforce_stationarity=False,\n    #                                enforce_invertibility=False,\n    #                              error_action='ignore',\n     #                               suppress_warnings=True)\n    results = mod.fit()\n    #print(results.summary().tables[1])\n    #print(results.summary().tables[1])\n\n    \n    #get the prediction for this store\n    test_sales = test[test['Store'] == store]\n    test_sales = test_sales.set_index('Date')\n    test_sales_exog = test_sales[['Open','Promo','StateHoliday','SchoolHoliday']]\n    \n    test_sales_exog['Open'] = pd.to_numeric(test_sales_exog['Open'], errors='coerce').fillna(0)\n    test_sales_exog['Promo'] = pd.to_numeric(test_sales_exog['Promo'], errors='coerce').fillna(0)\n    test_sales_exog['StateHoliday'] = pd.to_numeric(test_sales_exog['StateHoliday'], errors='coerce').fillna(0)\n    test_sales_exog['SchoolHoliday'] = pd.to_numeric(test_sales_exog['SchoolHoliday'], errors='coerce').fillna(0)\n\n    test_sales_exog = test_sales_exog.resample(rsmpl_opt).mean()\n    test_sales_exog = test_sales_exog.fillna({'Open':0, 'Promo':0, 'StateHoliday':0, 'SchoolHoliday':0})\n    #print(test_sales_exog)\n    \n    \n    pred_uc = results.get_forecast(steps=len(test_sales_exog),exog=test_sales_exog)\n    pred_ci = pred_uc.conf_int()\n    pred_ci = pd.DataFrame(pred_ci[['lower Sales','upper Sales']].mean(axis=1))\n    pred_ci['Store'] = store\n    pred_ci = pred_ci.sort_index()\n    #pred_ci.sort_values(by=['Index'])\n    hasil = hasil.append(pred_ci)\n    \n    \n    \n    \n    \n    #print(f'{sales_exog.index}')\n    #print(f'{y.index} ')\n    clear_output()\n    print(st)\n    iters = iters + 1\n    print(f'done: {iters}/{len(store_list)}')\n    now = time.time()\n    print(\"It has been {0} seconds since the loop started\".format(now - program_starts))\n\nprint('done')\n\n\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"hasil2 = hasil","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking model"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"date = str(sales_exog.last('10M').first('1d').index.item())\n#pred = results.get_prediction(start=pd.to_datetime(date), exog=sales_exog[sales_exog.index >= pd.to_datetime(date)] , dynamic=False)\npred = results.get_prediction(start=pd.to_datetime(date), exog=sales_exog[sales_exog.index >= date] , dynamic=False)\npred_cix = pred.conf_int()\nax = sales[date_from:].plot(label='observed')\npred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\n\nax.fill_between(pred_cix.index,\n                pred_cix.iloc[:, 0],\n                pred_cix.iloc[:, 1], color='k', alpha=.2)\nplt.legend()\nplt.show()\npred.dist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_forecasted = pred.predicted_mean\ny_truth = sales[date:]\nmse = ((y_forecasted - y_truth) ** 2).mean()\nprint(f'The Mean Squared Error is {round(mse, 2)}')\nprint(f'The Root Mean Squared Error of our forecasts is {round(np.sqrt(mse))}')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"pd.concat([pd.DataFrame(sales), sales_exog],axis=1, join='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"hasil","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":false},"cell_type":"code","source":"store_list[1:25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Matching result and id, also turning the smoothed data to daily data"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"wak = pd.DataFrame()\nm = max(store_list)\nfor store in store_list:\n    wak = wak.append(test[test['Store'] == store][['Id','Store','Date']])\n    clear_output()\n    print(f'{store}/{m}')\n    \n#wak\nwkwk = pd.DataFrame([], columns=['Id','Date','Sales'])\niters = 0;\nn = len(wak)\nfor index, row in wak.iterrows():\n    wkwk = wkwk.append({'Id': row['Id'],'Date': row['Date'], 'Sales': hasil[hasil['Store'] == row['Store']].iloc[hasil[hasil['Store']== row['Store']].index.get_loc(row['Date'], method='nearest')][0]},ignore_index=True)\n    iters = iters +1\n    clear_output()\n    print(f'matching = {iters}/{n}')\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking result and cleaning just before exporting the result into csv."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"wkwk2['Sales'][wkwk2['Sales'] > 10**3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"wkwk2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"wkwk2 = wkwk[['Id', 'Sales']].sort_values(['Id'])\nwkwk2\nlen(wkwk2['Sales'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(wkwk2['Sales'][np.isnan(wkwk2['Sales'])])\nlen(wkwk2['Sales'][wkwk2['Sales'] < 0])\nwkwk2['Sales'][np.isnan(wkwk2['Sales'])] = wkwk2['Sales'].notnull().mean()\nwkwk2['Sales'][wkwk2['Sales'] < 0] = wkwk2['Sales'].notnull().mean()\nwkwk2['Sales'][wkwk2['Sales'] > 10**4] = wkwk2['Sales'].notnull().mean()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"wkwk2[np.isnan(wkwk2['Sales'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"wkwk2['Sales'][wkwk2['Sales'] < 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OUTPUT to csv"},{"metadata":{"trusted":false},"cell_type":"code","source":"wkwk2.to_csv('weekly3.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}