{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is inspired from https://www.kaggle.com/iafoss/256x256-images. You can use this data if some one need to work with 512x512 images."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport os\nfrom tqdm.notebook import tqdm\nimport zipfile\nimport tifffile as tiff","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_csv = '../input/hubmap-kidney-segmentation/train.csv'\ntest_csv = '../input/hubmap-kidney-segmentation/train.csv'\ntrain_folder = '../input/hubmap-kidney-segmentation/train'\ntest_folder = '../input/hubmap-kidney-segmentation/test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Basic EDA\n\nLet look at images we have and let us see their size."},{"metadata":{"trusted":true},"cell_type":"code","source":"images = [file for file in os.listdir(train_folder) if str(file).split('.')[1] == 'tiff']\nfor image_name in images:\n    img = tiff.imread(os.path.join(train_folder,image_name))\n    print(image_name,img.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that some images have channels first and some other last. Also we need to squeeze some images as we go further."},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_df = pd.read_csv(train_csv)\n# seting id as index as ot will be useful while iterating\n# mask_df = mask_df.set_index('id')\nmask_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n \ndef rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fixed size = 1024\ntile_size = 512\nfactor = 2\ntrain_zip,mask_zip = 'train.zip', 'masks.zip'\n\nwith zipfile.ZipFile(train_zip, 'w') as img_out,zipfile.ZipFile(mask_zip, 'w') as mask_out:\n    for i in range(mask_df.shape[0]):\n        row = mask_df.loc[i]\n        index, encoding = row[0],row[1]\n        #read image and generate the mask\n        img = tiff.imread(os.path.join(train_folder,index+'.tiff'))\n        if len(img.shape) == 5:\n            img = np.transpose(img.squeeze(), (1,2,0))\n        mask = rle2mask(encoding, (img.shape[1],img.shape[0]))\n    \n        ## padding images so that split can be correct\n        shape = img.shape\n        pad0 = (tile_size*factor - shape[0]%(tile_size*factor))%(tile_size*factor) \n        pad1 = (tile_size*factor - shape[1]%(tile_size*factor))%(tile_size*factor)\n                           \n        img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=0)\n        mask = np.pad(mask,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2]],constant_values=0)\n    \n        #split image and mask into tiles using the reshape+transpose trick\n        img = cv2.resize(img,(img.shape[0]//factor,img.shape[1]//factor),interpolation = cv2.INTER_AREA)\n        img = img.reshape(img.shape[0]//tile_size,tile_size,img.shape[1]//tile_size,tile_size,3)\n        img = img.transpose(0,2,1,3,4).reshape(-1,tile_size,tile_size,3)\n\n        mask = cv2.resize(mask,(mask.shape[0]//factor,mask.shape[1]//factor),interpolation = cv2.INTER_NEAREST)\n        mask = mask.reshape(mask.shape[0]//tile_size,tile_size,mask.shape[1]//tile_size,tile_size)\n        mask = mask.transpose(0,2,1,3).reshape(-1,tile_size,tile_size)\n\n        #write data\n        for i,(im,m) in enumerate(zip(img,mask)):\n            if im.sum() == 0: continue\n            im = cv2.imencode('.png',cv2.cvtColor(im, cv2.COLOR_RGB2BGR))[1]\n            img_out.writestr(f'{index}_{i}.png', im)\n            m = cv2.imencode('.png',m)[1]\n            mask_out.writestr(f'{index}_{i}.png', m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/working","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}