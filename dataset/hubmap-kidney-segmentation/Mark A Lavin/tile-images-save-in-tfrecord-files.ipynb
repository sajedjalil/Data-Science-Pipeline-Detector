{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Lavin versions\n* Tile Images, Save in TFRecord v. 14:  Try skipping blank (glom-less) tiles for new 15-image train DataSet\n* Tile Images, Save in TFRecord v. 11:  Get mask data from \"train.csv\", not from \"<imageid>.json\" files\n*  v.21, include \"pixel_overlap\" in output TFRecords\n* v.1, after cloning v29 for regular (non-Normalized) images"},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls -al /kaggle/input/hubmap-kidney-segmentation/*","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Pre-Disclaimer:*** \nThis notebook was adapted from the excellent one by Marcos Novaes https://www.kaggle.com/marcosnovaes/hubmap-read-data-and-build-tfrecords; changes:\n* introduction of overlapping tiles.\n* write all tiles for a single original image into a single TFrecord file.\n* The notebook contains exploratory material that can be disabled by setting the variable EDA (Exploratory Data Analysis) to False.\n* If P['DO_NORMALIZE'] is True, normalize each image by subtracting its 3-channel mean and (sort of) dividing by its 3-channel stddev.\n* If P['SKIP_BLANK_TILES'] is True, don't output tiles for which there are NO glom markers in the hopes of saving space and training time"},{"metadata":{"trusted":true},"cell_type":"code","source":"EDA = False\n\n# Run parameters (after Wojtek's convention)\n\nP = {}\nP[ 'DO_NORMALIZE'] = False   # Don't ormalize input images to standard statistics\nP[ 'TILE_SIZE' ] = 512   # Nominal Image diameter in pixels, NOT including overlap\nP[ 'TILE_OVERLAP' ] = 64  # Overlap between adjacent tiles in pixels\nP[ 'SKIP_BLANK_TILES' ] = True  # Ignore tiles with no glom markers\n\nprint( \"Tile Images, Save in TFRecord Files\" )\nprint( \"parameters:\" )\nfor p in P:\n    print( f\"{p}: {P[p]}\" )\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Objective:\n\nThe objective of this notebook is to provide an example of how to transform the HubMAP Hacking the Kidney competition dataset into a form that can readily used to train models leveraging accelerators. The images in this competition have very high resolution, averaging 30,000 x 30,000 pixels, and this presents a difficult challenge in memory management. It is just not possible to read them all in memory in the Kaggle environment, and it is also not possible to build a model using the whole image as input. This notebooks provides some tips for reading the competitions images and masks, and proposes a strategy to deal with the large sizes. \nThe strategy adopted in this Notebook is to tile the images into overlapping tiles, and then transforming the tiles into TFRecords such that we can later use them as input to train models using GPU or TPU accelerators. \n\nThis Notebook takes a long time to run because it processes all the competition files and the resulting, compressed dataset is 18.1G, almost exceeding the Kaggle VM limit. I was able to process all files and then uploaded the results to a Kaggle daset that I have made public:\n--> [Link to the TFRecord Dataset Produced by this Notebook.](https://www.kaggle.com/marcosnovaes/hubmap-tfrecord-512)\n\nI have also developed a Notebook that explains how to use the TFRecord Dataset: [https://www.kaggle.com/marcosnovaes/hubmap-looking-at-tfrecords/](https://www.kaggle.com/marcosnovaes/hubmap-looking-at-tfrecords/)\n\nIf you want to use the dataset without change you don't need to run the Notebook -- but do read through it because it provides a lot of insight on how the read the images, masks and convert them to TFRecords. I will be using this dataset on my subsequent notebooks. You can also easily costumize this Notebook if you want to produce tiles of different sizes (P['TILE_SIZE']) or if you want to include more metadata for each tile. "},{"metadata":{},"cell_type":"markdown","source":"# Reading the Images\nSome of the images are in TIFF format, some are in BigTIFF. I used the tiffile library and it seems to read the images with no problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install tifffile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Libs used in this Notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport cv2\nimport json\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport rasterio\nfrom rasterio.windows import Window\n\n#from imread import imread, imsave\n\nimport shutil\nimport psutil\n\nimport tensorflow as tf\n\nimport glob\nimport tifffile\nimport gc\nimport sys","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the input data. Find and read the competition train.csv file."},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l /kaggle/input/hubmap-kidney-segmentation/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basepath = '/kaggle/input/hubmap-kidney-segmentation/'\ntrain_df = pd.read_csv(basepath + \"train.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The id corresponds to the images provided. For each image, you are provided a .tiff image file and the Run Length Encoding Mask. \n\nBut notice that the masks are also provided as a .json file with polygon definitions. I used this option instead in this Notebook. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l /kaggle/input/hubmap-kidney-segmentation/train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l /kaggle/input/hubmap-kidney-segmentation/test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next cell reads all tiffs and prints their shapes. It turns out that some TIFF images are channel first (number \"3\" first) and others channel last (number \"3\" last). When reading them, we must check if the \"3\" is first and swap the axis as needed. This loop will take a long time as each image is read just so we can tell its shape. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# verify that we can read all images\ndef verify_read(file_list):\n    for file_name in file_list:\n        baseimage = tifffile.imread(file_name)\n        #baseimage = tif.series[0].asarray()\n        print('img id = {}, shape = {}, dtype = {}'.format(file_name,baseimage.shape, baseimage.dtype ) )\n        baseimage = None\n        gc.collect()\n\nif EDA:\n    print( \"before verify_read:\", psutil.virtual_memory(), file = sys.stderr )\n    file_list = glob.glob('/kaggle/input/hubmap-kidney-segmentation/train/*.tiff')\n    verify_read(file_list)\n    print( \"after verify_read:\", psutil.virtual_memory(), file = sys.stderr )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading and Showing a sample image and mask\nThe next cells show the code that can read the first image in the csv file. \n\nIMPORTANT: Note that in the case of a \"channel first\" TIFF (number \"3\" first) we need to swap the axis of the numpy array as noted below. You CANNOT use \"reshape\" instead, that will scramble the channels."},{"metadata":{"trusted":true},"cell_type":"code","source":"#select an image to investigate\nworking_image_index = 0\nworking_image_id = train_df['id'][working_image_index]\nworking_image_id\nworking_image_path = '/kaggle/input/hubmap-kidney-segmentation/train/'+working_image_id+'.tiff'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is the code that takes care of the difference in shapes. \nIMPORTANT: Notice that you need to use the numpy.swapaxes function to change the shape, using \"reshape\" will scramble the channels."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nif EDA:\n    baseimage = tifffile.imread(working_image_path)\n    print ('original image shape',baseimage.shape)\n    print ('original image dtype', baseimage.dtype )\n    print ('original image min/max', ( np.amin( baseimage ), np.amax( baseimage ) ) )\n    baseimage = np.squeeze(baseimage)\n    if( baseimage.shape[0] == 3):\n        baseimage = baseimage.swapaxes(0,1)\n        baseimage = baseimage.swapaxes(1,2)\n        print ('swaped shape',baseimage.shape)\n\n    plt.figure()\n\n    plt.imshow(baseimage)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The masks are provided in the csv files in RLE format, but we are also provided json files that describe the mask as polygons. I will be using the json files:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read json mask\nworking_image_json_mask = '/kaggle/input/hubmap-kidney-segmentation/train/'+working_image_id+'.json'\nif EDA:\n    read_file = open(working_image_json_mask, \"r\") \n    mask_data = json.load(read_file)\n    print( mask_data[0] )\n    mask_data = None\n    gc.collect()\n    print( psutil.virtual_memory(), file = sys.stderr )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following function converts the polygons into a numpy boolean mask with the same shape as the image."},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_mask(mask_file, mask_shape):\n    read_file = open(mask_file, \"r\") \n    mask_data = json.load(read_file)\n    polys = []\n    for index in range(mask_data.__len__()):\n        geom = np.array(mask_data[index]['geometry']['coordinates'])\n        polys.append(geom)\n\n    mask = np.zeros(mask_shape, dtype = np.uint8 )\n    cv2.fillPoly(mask, polys, 1)\n    mask = mask.astype(bool)\n    return mask\n\ndef read_mask_from_RLE( image_id, mask_shape ):\n    '''\n    Gets Run-Length Encoded representation of glom mask image corresponding to train image \"image_id\"\n    and converts to binary image, returned.\n    '''\n    RLE = train_df[ train_df[ 'id' ] == image_id ][ 'encoding' ].values[ 0 ]\n    mask = rle2mask( RLE, mask_shape )\n    return mask\n   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Run length encoding (RLE) Functions\nBased on https://www.kaggle.com/friedchips/fully-correct-hubmap-rle-encoding-and-decoding:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_RLE( mask, column_pixel_offset = 0 ):\n    '''\n    Given a predicted binary image tile column \"mask\" and a starting offset in\n    column-major ordered pixels, calculate and return the string RLE, which will be\n    concatenated with RLEs from other columns, to construct RLE for the entire image:\n    '''\n    mask = mask.T.reshape(-1) # make 1D, column-first\n    mask = np.pad(mask, 1) # make sure that the 1d mask starts and ends with a 0\n    starts = np.nonzero((~mask[:-1]) & mask[1:])[0] # start points\n    ends = np.nonzero(mask[:-1] & (~mask[1:]))[0] # end points\n    rle = np.empty(2 * starts.size, dtype=int) # interlacing...\n    rle[0::2] = starts  + column_pixel_offset # ...starts...\n    rle[1::2] = ends - starts # ...and lengths\n    rle = ' '.join([ str(elem) for elem in rle ]) # turn into space-separated string\n    return rle\n\ndef rle2mask(rle, mask_shape):\n    ''' takes a space-delimited RLE string in column-first order\n    and turns it into a 2d boolean numpy array of shape mask_shape '''\n    \n    mask = np.zeros(np.prod(mask_shape), dtype=bool) # 1d mask array\n    rle = np.array(rle.split()).astype(int) # rle values to ints\n    starts = rle[::2]\n    lengths = rle[1::2]\n    for s, l in zip(starts, lengths):\n        mask[s:s+l] = True\n    return mask.reshape(np.flip(mask_shape)).T # flip because of column-first order\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    mask_shape = (baseimage.shape[0], baseimage.shape[1])\n    mask = read_mask(working_image_json_mask, mask_shape)\n    plt.imshow(mask)\n    gc.collect()\n    print( psutil.virtual_memory(), file = sys.stderr )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    baseimage.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    mask.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    mask.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, now we know how to read each image and mask, and that their types are uint8 and bool respectively. But they have very large dimensions, we would not be able to train a ML model at these dimensions. So, in the next section I takes the approach of tiling up the image and working with tiles."},{"metadata":{},"cell_type":"markdown","source":"# Tiling the Large Images into tiles with overlap\nTiles are square arrays of pixels with two regions:   An inner region consisting of a P['TILE_SIZE'] pixel diameter square surrounded by an outer annular region with a radius\nof P['TILE_OVERLAP'] pixels.  Tiles are arranged so that inner regions abut to cover the entire image, with outer regions overlapping adjacent tiles.\n\nNOTE: The image numpy arrays have dimensions [height, width, channels]. This Notebook will tile the image using offsets for the height index and width index. So:\n- a Tile with coordinate [0,0] represents the first tile on the top left corner.  \n- a Tile with coordinate [1,0] represents a tile with height offset = 1*Tile Size, in this case it starts at numpy coordinates [P['TILE_SIZE'],0], which means it is the tile below [0,0]\n- a Tile with coordinate [0,1] represents a tile with wodth offset = 1*Tile Size, in this case it starts at numpy coordinates [0,P['TILE_SIZE']], which means it is the tile to the right of [0,0]\n\nHere are some useful functions that use the numpy slicing capability to select specific tiles of the image. "},{"metadata":{"trusted":true},"cell_type":"code","source":"class OverlappingTiledImage:\n    '''\n    A class whose objects can be used to extract overlapping tiles from a larger image,\n    whose primary method get_tile extends nominal tile size by specified overlap, \n    reflecting through the boundaries of the larger image if the tile + overlap would\n    extend past the boundary.  We use the convention that \"row\" and \"col\" (lower case)\n    refer to location of pixels in one tile, while \"ROW\" and \"COL\" (upper case) refer\n    to the location of the tile in the tableau of tiles covering the image.\n    '''\n    # Primary data members, specified by constructor arguments:\n    # self.image:   The large \"base\" image from which tiles are extracted\n    # self.tile_pixel_rows:  The number of rows of pixels in a tile\n    # self.tile_pixel_cols:  The number of columns of pixels in a tile\n    # self.tile_pixel_overlap: The overlap, in pixels, between adjacent tiles, in all directions\n    # self.image_pixel_row_start:  The pixel row number of the upper left corner of the (ROW=0, COL=0) tile\n    # self.image_pixel_col_start:  The pixel column number \" \" \"\n    # self.image_pixel_row_stop: The pixel row number past the lower right corner of the (ROW=tile_ROWS-1,COL=tile_COLS-1) tile\n    # self.image_pixel_col_stop: The pixel column number \" \" \"\n    # Derived data members:\n    # self.tile_ROWS:  The number of ROWS of tiles in the tableau of overlapping tiles\n    # self.tile_COLS:  The number of COLUMNS of tiles in the tableau of overlapping tiles\n    \n    # \"public\" methods:\n    def __init__ ( self, image, pixel_rows, pixel_cols, pixel_overlap, \n                   image_pixel_row_start = 0, image_pixel_col_start = 0,\n                   image_pixel_row_stop = None, image_pixel_col_stop = None ):\n        # Process defaults for last two args:\n        if image_pixel_row_stop is None:\n            image_pixel_row_stop = image.shape[ 0 ]\n        if image_pixel_col_stop is None:\n            image_pixel_col_stop = image.shape[ 1 ]\n        # Sanity checks\n        assert pixel_rows > 0\n        assert pixel_cols > 0\n        assert pixel_overlap >= 0\n        assert image_pixel_row_start >= 0\n        assert image_pixel_row_stop <= image.shape[ 0 ]\n        assert image_pixel_row_start < image_pixel_row_stop\n        assert image_pixel_col_start >= 0\n        assert image_pixel_col_stop <= image.shape[ 1 ]\n        assert image_pixel_col_start < image_pixel_row_stop\n        # Copy primary data members\n        self.image = image\n        self.tile_pixel_rows = pixel_rows\n        self.tile_pixel_cols = pixel_cols\n        self.tile_pixel_overlap = pixel_overlap\n        self.image_pixel_row_start = image_pixel_row_start\n        self.image_pixel_col_start = image_pixel_col_start\n        self.image_pixel_row_stop = image_pixel_row_stop\n        self.image_pixel_col_stop = image_pixel_col_stop\n        # Derive data members\n        self.tile_ROWS = ( image_pixel_row_stop - image_pixel_row_start ) // pixel_rows\n        self.tile_COLS = ( image_pixel_col_stop - image_pixel_col_start ) // pixel_cols\n        '''\n        print( \"image_pixel_row_stop\", image_pixel_row_stop, \"image_pixel_row_start\", image_pixel_row_start, file = sys.stderr )\n        print( \"image_pixel_col_stop\", image_pixel_col_stop, \"image_pixel_col_start\", image_pixel_col_start, file = sys.stderr )\n        print( \"pixel_rows\", pixel_rows, \"pixel_cols\", pixel_cols, file = sys.stderr )\n        '''\n        \n    def SHAPE( self ):\n        '''\n        Returns:  Shape of overlapping image in tiles\n        '''\n        return ( self.tile_ROWS, self.tile_COLS )\n    \n    def tile_shape( self ):\n        '''\n        Returns:  Shape + overlap of individual tile, in pixels\n        '''\n        return ( self.tile_pixel_rows, self.tile_pixel_cols, self.tile_pixel_overlap )\n    \n    def image_shape( self ):\n        '''\n        Returns:  shape of underlying image, ignoring image_pixel_row_start, etc.\n        '''\n        return self.image.shape\n    \n    def get_tile( self, tile_ROW, tile_COL ):\n        assert ( tile_ROW >= 0 ) & ( tile_ROW < self.tile_ROWS )\n        assert ( tile_COL >= 0 ) & ( tile_COL < self.tile_COLS )\n        pixel_row_start = self.image_pixel_row_start + tile_ROW * self.tile_pixel_rows - self.tile_pixel_overlap\n        pixel_col_start = self.image_pixel_col_start + tile_COL * self.tile_pixel_cols - self.tile_pixel_overlap\n        pixel_row_stop_no = min( self.image_pixel_row_start + ( 1 + tile_ROW ) * self.tile_pixel_rows, self.image_pixel_row_stop )\n        pixel_col_stop_no = min( self.image_pixel_col_start + ( 1 + tile_COL ) * self.tile_pixel_cols, self.image_pixel_col_stop )\n        pixel_row_stop = pixel_row_stop_no + self.tile_pixel_overlap\n        pixel_col_stop = pixel_col_stop_no + self.tile_pixel_overlap\n        '''\n        print( \"  pixel_row_stop_no\", pixel_row_stop_no, file = sys.stderr )\n        print( \"  pixel_col_stop_no\", pixel_col_stop_no, file = sys.stderr )\n        print( \"  pixel_row_start\", pixel_row_start, \"pixel_col_start\", pixel_col_start, file = sys.stderr )\n        print( \"  pixel_row_stop\", pixel_row_stop, \"pixel_col_stop\", pixel_col_stop, file = sys.stderr )\n        '''\n        \n        tile = self.image[ max( pixel_row_start, self.image_pixel_row_start ) : min( pixel_row_stop, self.image_pixel_row_stop ),\n                           max( pixel_col_start, self.image_pixel_col_start ) : min( pixel_col_stop, self.image_pixel_col_stop ) ]\n        if ( pixel_row_start < self.image_pixel_row_start ):\n            tile = self.extend_top( tile, pixel_row_start )\n            # print( \"  extend_top\", file = sys.stderr )\n        if ( pixel_row_stop > self.image_pixel_row_stop ):\n            tile = self.extend_bottom( tile, pixel_row_stop )\n            # print( \"  extend_bottom\", file = sys.stderr )\n        if ( pixel_col_start < self.image_pixel_col_start ):\n            tile = self.extend_left( tile, pixel_col_start )\n            # print( \"  extend_left\", file = sys.stderr )\n        if ( pixel_col_stop > self.image_pixel_col_stop ):\n            tile = self.extend_right( tile, pixel_col_stop )\n            # print( \"  extend_right\",file = sys.stderr )\n        return tile\n    \n    def remove_overlap( self, tile ):\n        '''\n        Returns: \"tile\" with overlap removed\n        '''\n        return tile[ self.tile_pixel_overlap : - self.tile_pixel_overlap, self.tile_pixel_overlap : - self.tile_pixel_overlap ]\n    \n    # \"private\" methods:\n    \n    def copyMakeBorder( self, tile, border_top, border_bot, border_left, border_right, treatment = cv2.BORDER_REFLECT ):\n        if tile.dtype == np.bool:\n            return cv2.copyMakeBorder( tile.astype( np.int8 ), border_top, border_bot, border_left, border_right, treatment ).astype( np.bool )\n        else:\n            return cv2.copyMakeBorder( tile, border_top, border_bot, border_left, border_right, treatment )\n        \n    \n    def extend_top( self, tile, pixel_row_start ):\n        return self.copyMakeBorder( tile, self.image_pixel_row_start - pixel_row_start, 0, 0, 0 )\n            \n    def extend_bottom( self, tile, pixel_row_stop ):\n        return self.copyMakeBorder( tile, 0, pixel_row_stop - self.image_pixel_row_stop, 0, 0 )\n    \n    def extend_left( self, tile, pixel_col_start ):\n        return self.copyMakeBorder( tile, 0, 0, self.image_pixel_col_start - pixel_col_start, 0 )\n\n    def extend_right( self, tile, pixel_col_stop ):\n        return self.copyMakeBorder( tile, 0, 0, 0, pixel_col_stop - self.image_pixel_col_stop )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#explore a few tiles\ndef show_tile_and_mask(baseimage_oti, mask_oti, tile_col_pos, tile_row_pos):\n    tile_image = baseimage_oti.get_tile( tile_col_pos, tile_row_pos )\n    tile_mask = mask_oti.get_tile( tile_col_pos, tile_row_pos )\n    fig, ax = plt.subplots(1,2,figsize=(20,3))\n    ax[0].imshow(tile_image)\n    ax[1].imshow(tile_mask)\n'''    \ndef get_tile(baseimage, tile_size, tile_col_pos, tile_row_pos):\n    start_col = tile_col_pos*tile_size\n    end_col = start_col + tile_size\n    start_row = tile_row_pos * tile_size\n    end_row = start_row + tile_size\n    tile_image = baseimage[start_col:end_col, start_row:end_row,:]\n    return tile_image\n\ndef get_tile_mask(baseimage, tile_size, tile_col_pos, tile_row_pos):\n    start_col = tile_col_pos*tile_size\n    end_col = start_col + tile_size\n    start_row = tile_row_pos * tile_size\n    end_row = start_row + tile_size\n    tile_image = baseimage[start_col:end_col, start_row:end_row]\n    return tile_image\n\n'''  \ndef show_tile_dist(tile):\n    fig, ax = plt.subplots(1,2,figsize=(20,3))\n    #ax[0].set_title(\"Tile ID = {} Xpos = {} Ypos = {}\".format(img_mtd['tile_id'], img_mtd['tile_col_pos'],img_mtd['tile_row_pos']))\n    ax[0].imshow(tile)\n    ax[1].set_title(\"Pixelarray distribution\");\n    sns.distplot(tile.flatten(), ax=ax[1]);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be noticed in the sample image displayed, there is a black border and then a lot of white surrounding the tissue. If we select [0,0] we expect to see a black tile. If we move a little to the right and down, we are then in the white zone. So let's try the values [0,0] and [5,5] and we should be a black and a white tile respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    tile_size = P[ 'TILE_SIZE' ]\n    overlap = P[ 'TILE_OVERLAP' ]\n    baseimage_oti = OverlappingTiledImage( baseimage, tile_size, tile_size, overlap )\n    mask_oti = OverlappingTiledImage( mask, tile_size, tile_size, overlap )\n    tile = baseimage_oti.get_tile( 0, 0)\n    print( \"tile.shape\", tile.shape, file = sys.stderr )\n    show_tile_dist(tile)\n    print( \"baseimage_oti.SHAPE()\", baseimage_oti.SHAPE(), file = sys.stderr )\n    gc.collect()\n    print( psutil.virtual_memory(), file = sys.stderr )\n    mask_tile = mask_oti.get_tile( 0, 0 )\n    print( \"mask_tile.dtype\", mask_tile.dtype, file = sys.stderr )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Black as predicted. As we explore the tiles, I also calculate the tile histogram. If we observe the histogram we will notice that it will provide a useful way to filter black and white tiles later. The numpy.histogram function divides the color spectrum in 10 bins and shows how many pixels call within each bin. We can notice that black and white fall into the higher end of the spectrum. Black tiles have 0 pixels in the lower end, while \"white\" (actually \"dirty gray\") has only about 20 pixels in that region. We then see that tiles with some actual tissue have a more even distribution. Let's call this metric \"lowpass energy\". It turns out that if we later select lowpass energy > 100 we are garanteed to have actual tissue in the slide, and we can discard anything with < 100. "},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    img_hist = np.histogram(tile)\n    print('histogram = {}'.format(img_hist[0]))\n    print('histogram_lowpass = {}'.format(np.sum(img_hist[0][0:4])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And here is the white one ([5,5]"},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    tile = baseimage_oti.get_tile( 5, 5)\n    show_tile_dist(tile)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    img_hist = np.histogram(tile)\n    print('histogram = {}'.format(img_hist[0]))\n    print('histogram_lowpass = {}'.format(np.sum(img_hist[0][0:4])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    tile = baseimage_oti.get_tile( 8, 20 )\n    print( \"tile.shape\", tile.shape, file = sys.stderr )\n    show_tile_dist(tile)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now let's try to find a glomerulus. If we look back at the polygon dump above, it shows that the first glom starts at pixel [10503, 4384]. If we divide both indexes by 512, we expect to find a glom in tile [8,20]"},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    img_hist = np.histogram(tile)\n    print('histogram = {}'.format(img_hist[0]))\n    print('histogram_lowpass = {}'.format(np.sum(img_hist[0][0:4])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    show_tile_and_mask(baseimage_oti, mask_oti, 8, 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bingo!!! We found our first glom. Let's now derive a metric for masks, so that in the future we can easily find tiles with gloms. This metric will be used when we want to filter the training dataset to make sure it includes a certain number of tiles with gloms. Simply counting the number of \"TRUE\" pixels in the mask is a great metric that indicate the tile contains a glom."},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    tile_mask = mask_oti.get_tile( 8, 20)\n    mask_density = np.count_nonzero(tile_mask)\n    print( \"mask_density\", mask_density, \"/\", tile_mask.shape[0] * tile_mask.shape[1] )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's move down the image by incrementing the height offset to [9,20], which should be the tile below [8,20]"},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    show_tile_and_mask(baseimage_oti, mask_oti, 9, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    tile_mask = mask_oti.get_tile( 9, 20)\n    mask_density = np.count_nonzero(tile_mask)\n    mask_density","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, the glom ends in that tile, and there are fewer TRUE pixels. Going further down we find a cortex tile with no gloms."},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    show_tile_and_mask(baseimage_oti, mask_oti, 10, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if EDA:\n    tile_mask = mask_oti.get_tile( 10, 20)\n    mask_density = np.count_nonzero(tile_mask)\n\n    print( \"\\nAt end of visualizations, before gc, memory is {}\", psutil.virtual_memory(), file = sys.stderr, flush = True )\n    baseimage = None\n    mask = None\n    baseimage_oti = None\n    mask_oti = None\n    gc.collect()\n    print( \"\\nAt end of visualizations, memory is {}\", psutil.virtual_memory(), file = sys.stderr, flush = True )\n\n    mask_density","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Functions for normalizing images (Optional)\nIn effect, performs linear transform independently for each of the three color channels of the input images so that resulting images have standardized mean (128/255) and standard deviation (42/255)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_images_stats( tiff_image_dirnames ):\n    image_stats = {}\n    for tiff_image_dirname in tiff_image_dirnames:\n        for tiff_image_filename in glob.glob( tiff_image_dirname + \"*.tiff\" ):\n            stats = calculate_image_stats( tiff_image_filename )\n            image_id = pathlib.Path( tiff_image_filename ).stem\n            print( \"for\", image_id, \"stats are\", stats )\n            image_stats[ image_id ] = stats\n    return image_stats\n        \ndef calculate_image_stats( tiff_image_filename ):\n    '''\n    Samples \"tiff_image_filename\" in a square of WINDOW_RADIUS (half-width)\n    Returns:\n        ( mean, std ), each a 3-array for three channels\n    '''\n    WINDOW_RADIUS = 1024  # ### SHOULD BE IN \"P[...]\" ###\n    with rasterio.open( tiff_image_filename ) as tiff_image_dataset:\n        image_rows, image_cols = tiff_image_dataset.shape\n        window = Window.from_slices ( ( image_rows // 2 - WINDOW_RADIUS,\n                                        image_rows // 2 + WINDOW_RADIUS ),\n                                      ( image_cols // 2 - WINDOW_RADIUS,\n                                        image_cols // 2 + WINDOW_RADIUS ) )\n        window_image = tiff_image_dataset.read( [1, 2, 3 ], window = window )\n        window_image = np.moveaxis( window_image, 0, -1 ) # Channel -> last\n        return calculate_window_stats( window_image )\n    \ndef calculate_window_stats( window_image ):    \n    mean = np.mean( window_image, axis = ( 0, 1 ) ).astype( int )\n    std = np.std( window_image, axis = ( 0, 1 ) ).astype( int )\n    stats = ( mean, std )\n    return stats\n    \ndef normalize_image( image, stats ):\n    '''\n    Normalizes the R x C x 3 \"image\" by subtracting the image mean and\n    dividing by the image stdev, return result\n    '''\n    mean, std = stats\n    assert image.shape[ 2 ] == 3\n    assert mean.shape[ 0 ] == 3\n    assert std.shape[ 0 ] == 3\n    # For each channel \"c\", we will subtract from image[:,:,c] the value\n    # of mean[c], then divide by std[c], clip the result to +/- 3, which\n    # will capture 97% of the cases, and then rescale to 0-255, so we\n    # return a \"uint8\" result consistent with what's read using rasterio.\n    image = image.astype( np.float )\n    image -= mean.astype( np.float )\n    EPSILON = 1E-6\n    image /= ( std.astype( np.float ) + EPSILON)\n    image = np.clip( image, - ( 3.0 - EPSILON ), ( 3.0 - EPSILON ) )\n    image *= 255.0 / 6.0\n    image += 128.0\n    image = np.clip( image, 0, 255 ).astype( np.uint8 )\n    return image\n\n'''\nTEST:\ncalculate_images_stats( ( \"/kaggle/input/hubmap-kidney-segmentation/test/\",\n                          \"/kaggle/input/hubmap-kidney-segmentation/train/\" ) )\n''' ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transforming the Tiles into a TFRecord Dataset\nWe are now ready to read all the images (one at a time or we will run out of memory!) and then writing each tile to a TFRecord file. Kaggle has a limit of 50 upper level directories, so we will create one dir for each image. We will also build a pandas dataframe that has the metadata for each tile, including the lowpass energy and mask density metrics that we derived above. \n\nUsing the TFRecord format for storing data should be easy, but unfortunately it requires data serialization which complicates it a little bit. This is done using [protocol buffers](https://developers.google.com/protocol-buffers/) and that is a bit of a learning curve. But in ML you only need to understand the [TFExample](https://www.tensorflow.org/api_docs/python/tf/train/Example) format. In this Notebook I provide a little template code for dealing with TFExamples that can be quickly customized for any type of data. This template is explained in detail in [this tutorial](https://www.tensorflow.org/tutorials/load_data/tfrecord); but you don't need to read all this, in this Notebook I provide an example specific for image data that you can quickly customize.\n\nFor serialization using TFExample, we have to make any data fit into either one of 3 types:\n* bytes_feature\n* float_feature\n* int_64_feature\n\nIn this Notebook and image and mask are passed as bytes_features and the other metadata as int_64. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilities serialize data into a TFRecord\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float / double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_example(image_index, image_tile, mask_tile, pixel_overlap, tile_id, tile_col_pos, tile_row_pos):\n    image_tile_shape = image_tile.shape\n    \n    img_bytes = image_tile.tostring()\n\n    mask_bytes = np.zeros((0,0)).tostring() if mask_tile is None else mask_tile.tostring()\n    \n    feature = {\n        'img_index': _int64_feature(image_index),\n        'height': _int64_feature(image_tile_shape[0]),  # NOTE this and \"width\" >includes< 2 * pixel_overlap\n        'width': _int64_feature(image_tile_shape[1]),\n        'pixel_overlap': _int64_feature(pixel_overlap),\n        'num_channels': _int64_feature(image_tile_shape[2]),\n        'image': _bytes_feature(img_bytes),\n        'mask' : _bytes_feature(mask_bytes),\n        'tile_id':  _int64_feature(tile_id),\n        'tile_col_pos': _int64_feature(tile_col_pos),\n        'tile_row_pos': _int64_feature(tile_row_pos),\n    }\n\n    return tf.train.Example(features=tf.train.Features(feature=feature))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This function writes a tile to storage, notice the GZIP compression -- this makes possible for all the tiles to be stored locally without exceeding the HD allowance of the Kaggle machine."},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_tfrecord( image_index, image_tile, mask_tile, pixel_overlap, tile_id, tile_col_pos, tile_row_pos, tf_writer):\n    tf_example = image_example(image_index, image_tile, mask_tile, pixel_overlap, tile_id, tile_col_pos, tile_row_pos)\n    tf_writer.write(tf_example.SerializeToString())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is the function that takes an image, slices into tiles, calculates tile metadata and commits to storage. It also builds a pandas dataframe with the metadata for all tiles. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_tfrecord_tiles( image_index, image_id, \n                          image_oti, mask_oti, output_dir,\n                          image_stats = None ):\n    '''\n    Write all the tiles for \"image_oti\" and \"mask_oti\" (if non-None) to \"output_path\".tfrec\n    Args:\n        image_index    0-origin index of original image/mask\n        image_id       8-digit hexadecimal identifier of image/mask\n        image_oti      Overlapping tile generator for original image\n        mask_oti       Overlapping tile generator for mask, may be None if not training\n        output_dir     For storing the single .tfrec file that all tiles are written to\n    Returns:\n    Dataframe describing all tiles for this image / mask \n    '''\n    print( \"write_tfrecord_tiles, output_dir\", output_dir, \"image_id\", image_id, file = sys.stderr )\n    # Check\" that \"image_oti\" and \"mask_oti\" match:\n    if mask_oti is not None:\n        assert image_oti.SHAPE() == mask_oti.SHAPE()\n        assert image_oti.tile_shape() == mask_oti.tile_shape()\n    \n    tile_rows, tile_cols = image_oti.SHAPE()\n    tile_pixel_rows, tile_pixel_cols, tile_pixel_overlap = image_oti.tile_shape()\n    tileID = 0\n    \n    print( \"write_tfrecord_tiles for image\", image_id, tile_rows, \"x\", tile_cols, \"tiles\", flush = True )\n\n    # create a pandas dataframe to store metadata for each tile\n    tile_df = pd.DataFrame(columns = ['img_index', 'img_id','tile_id', 'tile_rel_path',\n                                      'tile_col_num', 'tile_row_num', \n                                      'tile_pixel_rows', 'tile_pixel_cols', 'tile_pixel_overlap', \n                                      'lowband_density', 'mask_density'])\n\n    output_path = output_dir + image_id + \".tfrec\"\n    print( \"image_id\", image_id, \"output_path\", output_path, file = sys.stderr, flush = True )\n    \n    opts = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n    with tf.io.TFRecordWriter(output_path, opts) as tf_writer:\n\n        for col_number in range(tile_cols):\n\n            print('tile col_number {} '.format(col_number),end='', flush = True )\n    \n            for row_number in range(tile_rows):\n                \n                relative_path = image_id+'/col{}_row{}.tfrec'.format(col_number,row_number)\n    \n                # First, look at the glom mask for this tile.  If it's \n                # empty and P['SKIP_BLANK_TILES'] is true, skip it:\n                if mask_oti is None:\n                    tile_mask = None\n                else:\n                    tile_mask = mask_oti.get_tile( row_number, col_number )\n                    if P['SKIP_BLANK_TILES'] & ( np.sum( tile_mask ) == 0 ):\n                        continue;\n\n                # Write this image, mask tile:\n                image_tile = image_oti.get_tile( row_number, col_number )\n                # If selected, normalize all three color channels of the tile:\n                if image_stats is not None:\n                    image_tile = normalize_image( image_tile, image_stats)\n\n                num_records = write_tfrecord( image_index, image_tile, tile_mask, tile_pixel_overlap, \n                                               tileID, col_number, row_number, tf_writer )\n                \n                # populate the metadata for this tile\n                img_hist = np.histogram(image_tile)\n                lowband_density = np.sum(img_hist[0][0:4])\n                mask_density = 0 if tile_mask is None else  np.count_nonzero(tile_mask)\n                tile_df = tile_df.append({'img_index':image_index, 'img_id':image_id, 'tile_id': tileID, \n                                          'tile_rel_path':relative_path, \n                                          'tile_col_num':col_number, 'tile_row_num':row_number,\n                                          'tile_pixel_rows':tile_pixel_rows, \n                                          'tile_pixel_cols':tile_pixel_cols, \n                                          'tile_pixel_overlap':tile_pixel_overlap,\n                                          'lowband_density':lowband_density, 'mask_density':mask_density},\n                                         ignore_index=True)\n                tileID += 1\n                \n    # Follow Wojtek Rosa's convention to include number of tiles in tfrec filename\n    os.rename( output_path, output_path.replace( image_id, image_id + \"-\" + str( tileID ) ) )\n                \n    return tile_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This inline code will read each image and mask in the train set, swap axes when needed, loading the image and mask into numpy arrays and then invoking the above function for each image/mask pair. This will take a long time..."},{"metadata":{"trusted":true},"cell_type":"code","source":"def tile_and_build_tfr( input_dir, output_dir, do_mask = True, do_normalize = False,\n                        tile_size = P['TILE_SIZE'], tile_overlap = P['TILE_OVERLAP'] ):\n    '''\n    For all original images/masks in \"input_dir\" ,\n    break the images/masks into overlapping tiles and place in TFRecord files in \"output_dir\", one file per original image/mask.  This aligns with input conventions\n    assumed by Wojtek Rosa's code that we will borrow from.\n\n    Args:\n        input_dir    (e.g., '/kaggle/input/hubmap-kidney-segmentation/train/')\n        output_dir   (e.g., \"/kaggle/working/train/\")\n        do_mask      Iff True, tile mask images as well\n        tile_size    Tiles are ( tile_size x tile_size ) PLUS border of tile_overlap on all four sides\n        tile_overlap\n    Returns:\n        None\n    '''\n    print( \"tile_and_build_tfr, input_dir\", input_dir, \"output_dir\", output_dir, file = sys.stderr, flush = True )\n    image_file_list = glob.glob( input_dir + '[0-9a-f]*.tiff')\n                              \n    if os.path.exists(output_dir):\n        shutil.rmtree(output_dir)\n    os.mkdir(output_dir)\n\n    for image_index, image_file_name in enumerate( image_file_list ):\n        \n        # ### mask_file_name = image_file_name.replace( \"tiff\", \"json\" )\n        image_id = os.path.split( image_file_name )[1].split(\".\")[0]\n        print( \"image_id\", image_id )\n        \n        baseimage = tifffile.imread( image_file_name )\n        print ('original image {  }, shape, ID = {}',baseimage.shape, image_id, flush = True )\n        baseimage = np.squeeze(baseimage)\n        if( baseimage.shape[0] == 3):\n            baseimage = baseimage.swapaxes(0,1)\n            baseimage = baseimage.swapaxes(1,2)\n            print ('swapped shape',baseimage.shape)\n            \n        if do_normalize:\n            image_stats = calculate_image_stats( image_file_name )\n            print( \"for image_index\", image_index, \"image_stats: \", image_stats )\n        else:\n            image_stats = None\n            \n        # read json mask\n        if do_mask:\n            mask_shape = (baseimage.shape[0], baseimage.shape[1])\n            # ### mask = read_mask( mask_file_name, mask_shape)\n            mask = read_mask_from_RLE( image_id, mask_shape)\n        else:\n            mask = None\n        \n        # Set up overlap tiling for image and mask:\n        image_oti = OverlappingTiledImage( baseimage, tile_size, tile_size, tile_overlap )\n        mask_oti = None if mask is None else OverlappingTiledImage( mask, tile_size, tile_size, tile_overlap )\n        \n        print('writing {} x {} tiles for image {}'.format(image_oti.SHAPE()[ 0 ], image_oti.SHAPE()[ 1 ], image_id ) )\n        if mask_oti is not None:\n            print('writing {} x {} tiles for mask {}'.format(mask_oti.SHAPE()[ 0 ], mask_oti.SHAPE()[ 1 ], image_id ) )\n        tile_df = write_tfrecord_tiles( image_index, image_id, \n                                        image_oti, mask_oti, output_dir,\n                                        image_stats )\n        \n        #write the dataframe\n        print('writing tile metadata for image {}'.format(image_id))\n        df_path = output_dir+image_id+'_tiles.csv'\n        tile_df.to_csv(df_path)\n        \n        del baseimage\n        del mask\n        del image_oti\n        del mask_oti\n        gc.collect()\n        print( f\"\\nAt end of writing tiles for {image_id}, memory is {psutil.virtual_memory()}\", file = sys.stderr )\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Write tiles for all train images and verify they were written to file."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tile and save train image\ninput_dir = \"/kaggle/input/hubmap-kidney-segmentation/train/\"\n# ### output_dir = '/kaggle/working/train/'\n!mkdir /kaggle/tmp\noutput_dir = '/kaggle/tmp/train/'\ntile_and_build_tfr( input_dir, output_dir, do_mask = True, do_normalize = P['DO_NORMALIZE'] )\n!ls -l /kaggle/tmp/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l /kaggle/tmp/train/*.tfrec\n!wc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! kaggle datasets list --mine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls -al ~","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\ndef kaggle_authenticate( username, key ):\n    kaggle_data = {\"username\":username,\"key\":key}\n    os.environ['KAGGLE_USERNAME']=kaggle_data[\"username\"]\n    os.environ['KAGGLE_KEY']=kaggle_data[\"key\"]\n    !kaggle\n\nusername = \"markalavin\"\nkey = \"e13d4e98754a1b2c8913909429477e99\"  # Get this by [Create New Key] under <user>/Accounts\n# ### kaggle_authenticate( username, key )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!kaggle datasets create -h","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!kaggle datasets init -p /kaggle/tmp/train/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ndef create_dataset_metadata( title, slug, licenses, path ):\n    '''\n    Write a metadata file for uploading a data set; the file goes into\n    the folder \"path\" as dataset-metadata.json.  \"title\" is the print\n    name of the DataSet.  \"slug\" is an version of \"title\" with -'s\n    replacing blanks.  \"licenses\" is a list of license names\n    '''\n    metadata = { \"title\":title,\"id\":slug,\"licenses\":licenses }\n    with open( path + \"dataset-metadata.json\", \"w\") as file:\n        file.write( json.dumps( metadata ) )\n    !ls /kaggle/tmp/train\n    !cat /kaggle/tmp/train/dataset-metadata.json\n    !kaggle datasets create -p /kaggle/tmp/train -t\n\ntitle = \"new 512x512x64 no normalize no augment\"\nslug = \"markalavin/new-512x512x64-no-normalize-no-augment\"\nlicenses = [ { \"name\":\"CC0-1.0\"}]\npath = \"/kaggle/tmp/train/\"\n# ### create_dataset_metadata( title, slug, licenses, path )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}