{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TIF to TFRecords in multiple resolutions\nIn this notebook we will transform the huge train images into TFRecords format.\nWhen creating TFRecords of a dataset it is most efficient for the processing pipeline to have TFRecords of a certain size, generally >10MBytes, to benefit from I/O prefetching.  \n\n**Updated with the latest dataset!**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport glob\nfrom PIL import Image\nimport hashlib\nfrom io import BytesIO\nfrom skimage import io\nimport contextlib2\nimport json\nimport cv2\nimport os, shutil  \nfrom functools import partial\n%matplotlib inline  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References\nThis notebook uses/modifies some code snippets from these notebooks:\n* [Global Wheat to TFRecords](https://www.kaggle.com/mistag/global-wheat-to-tfrecords) (own work)\n* [HuBMap: Read data and build TFRecords](https://www.kaggle.com/marcosnovaes/hubmap-read-data-and-build-tfrecords)   \n\nIn addition some sample code from Keras documentation.","metadata":{}},{"cell_type":"markdown","source":"# TFRecords creation using patches\nThe super-resolution cell scan images need to be split into patches (or tiles if you like).   \n\nHere we go for 1024x1024 as the primary tile (patch) size. Adjust the IMG_SIZE variable further below to suit needs. We also create downscaled versions of 512x512 and 256x256.   ","metadata":{}},{"cell_type":"code","source":"# A few helper functions for reading in image and masks (from json)\n\ndef read_tif_file(fname):\n    img = io.imread(fname)\n    img = np.squeeze(img)\n    if img.shape[0] == 3: # swap axes as required\n        img = img.swapaxes(0,1)\n        img = img.swapaxes(1,2)\n    return img\n\ndef read_mask_file(fname, mshape):\n    with open(fname) as f:\n        mdata = json.load(f)\n        polys = []\n        for index in range(mdata.__len__()):\n            if mdata[index]['properties']['classification']['name'] == 'glomerulus':\n                geom = np.array(mdata[index]['geometry']['coordinates'])\n                if geom.shape[0] == 1:\n                    polys.append(geom[0].astype('int32'))\n        mask = np.zeros(mshape, dtype=np.int8)\n        cv2.fillPoly(mask, polys, 1)\n        mask = mask.astype(bool, copy=False)\n    return mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function below creates a TFRecord from a single patch. The image is stored as JPEG, while the mask is stored as PNG (lossless). We also put in some extra metadata.","metadata":{}},{"cell_type":"code","source":"# patches are stored as jpeg, masks as PNG\ndef create_tf_example(patch, m_patch, fid, x, y, size):\n    filename = fid+'.tiff'\n    height = size # Image height\n    width = size # Image width\n    buf= BytesIO()\n    im = Image.fromarray(np.uint8(patch))\n    im.save(buf, format= 'JPEG') # encode to jpeg in memory\n    encoded_image_data= buf.getvalue()\n    image_format = b'jpeg'\n    source_id = fid+'-'+str(x)+'-'+str(y) # must be unique\n    # A hash of the image is used in some frameworks\n    key = hashlib.sha256(encoded_image_data).hexdigest()\n    # Mask encoding\n    buf= BytesIO()\n    mim = Image.fromarray(np.uint8(m_patch))\n    mim.save(buf, format= 'PNG') # encode to png in memory\n    encoded_mask_data= buf.getvalue()\n    mask_format = b'png'\n    \n    tf_record = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[source_id.encode()])),\n        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n        'image/key/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode()])),\n        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n        'image/patch-x': tf.train.Feature(int64_list=tf.train.Int64List(value=[x])),\n        'image/patch-y': tf.train.Feature(int64_list=tf.train.Int64List(value=[y])),\n        'mask/patch-x': tf.train.Feature(int64_list=tf.train.Int64List(value=[x])),\n        'mask/patch-y': tf.train.Feature(int64_list=tf.train.Int64List(value=[y])),\n        'mask/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_mask_data])),\n        'mask/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[mask_format])),\n    }))\n    \n    return tf_record","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create TFRecord per image\nWe create a separate TFRecord file for each image. Well, actually two: One for tiles containing glomeruli (\"Tissue\") and one for the rest (\"Bkgnd\").","metadata":{}},{"cell_type":"code","source":"PATH = '/kaggle/input/hubmap-kidney-segmentation/train/'\nfilelist = glob.glob(PATH+'*.tiff')\nfilelist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fnames = []\nfor f in filelist:\n    fnames.append(f.split('train/')[-1].split('.')[0])\nfnames","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\nPATH = '/kaggle/input/hubmap-kidney-segmentation/train/'\nIMG_SIZE = 1024 # adjust according to desired tile size\nOVERLAP = IMG_SIZE//2 # overlap between each tile\nSTEP = IMG_SIZE-OVERLAP\nSCALES = 2 # number of times to downscale each patch (generate SCALES+1 sets of images)\nSCALE_FACTOR = 2 # scale factor to use for each set, adjust according to needs\nBKGND_1_OF_X = 15 # add every n'th background image to the TFRecord\n\nimg_sizes = np.zeros(SCALES+1, dtype=int)\nimg_sizes[0] = IMG_SIZE\nfor i in range(SCALES):\n    img_sizes[i+1] = int(img_sizes[i]/SCALE_FACTOR)\n\nfilelist = glob.glob(PATH+'*.tiff')\nFCNT = len(filelist)\n\ndef open_sharded_tfrecords(exit_stack, names, size):\n    tf_record_output_filenames = [\n        '{}-{}.tfrecord'.format(names[idx], size)\n        for idx in range(len(names))\n        ]\n    tfrecords = [\n        exit_stack.enter_context(tf.io.TFRecordWriter(file_name))\n        for file_name in tf_record_output_filenames\n    ]\n    return tfrecords\n\ngcnt = np.zeros(len(filelist), dtype=int)\n\n# A context2.ExitStack is used to automatically close all the TFRecords created \nwith contextlib2.ExitStack() as tf_record_close_stack:\n    # create list of TFRecords\n    output_tfrecords1 = []\n    for scnt in range(SCALES+1):\n        output_tfrecords1.append(open_sharded_tfrecords(tf_record_close_stack, fnames, img_sizes[scnt]))\n    # process images w/overlapped tiles\n    output_shard_index = 0\n    for file in filelist:\n        print(file)\n        fid = file.replace('\\\\','.').replace('/','.').split('.')[-2]        \n        img, mask = np.zeros(10), np.zeros(10) \n        img = read_tif_file(file)\n        dims = np.array(img.shape[:2])\n        mask = read_mask_file(file.split('.')[0]+'.json', dims)\n        bcnt = 0\n        for x in range((img.shape[0]-OVERLAP)//STEP):\n            for y in range((img.shape[1]-OVERLAP)//STEP):\n                # Extract patch\n                patch = img[x*STEP:x*STEP+IMG_SIZE, y*STEP:y*STEP+IMG_SIZE]\n                m_patch = mask[x*STEP:x*STEP+IMG_SIZE, y*STEP:y*STEP+IMG_SIZE]*255\n                # separate tissue from bakground by checking for non-zero pixels in mask\n                IsTissue = False\n                if np.max(m_patch) == 255:\n                    IsTissue = True;\n                tf_record = create_tf_example(patch, m_patch, fid, x, y, size=img_sizes[0])\n                if IsTissue:\n                    output_tfrecords1[0][output_shard_index].write(tf_record.SerializeToString())\n                    gcnt[output_shard_index] += 1\n                else:\n                    if bcnt == BKGND_1_OF_X:\n                        output_tfrecords1[0][output_shard_index].write(tf_record.SerializeToString())\n                        gcnt[output_shard_index] += 1\n                # create downscaled images\n                for s in range(SCALES): \n                    spatch = cv2.resize(patch, dsize=(img_sizes[s+1], img_sizes[s+1]), interpolation = cv2.INTER_AREA)\n                    sm_patch = cv2.resize(m_patch.astype(int), dsize=(img_sizes[s+1], img_sizes[s+1]), interpolation = cv2.INTER_NEAREST)\n                    tf_record = create_tf_example(spatch, sm_patch, fid, x, y, size=img_sizes[s+1])\n                    if IsTissue:\n                        output_tfrecords1[s+1][output_shard_index].write(tf_record.SerializeToString())\n                    else:\n                        if bcnt == BKGND_1_OF_X:\n                            output_tfrecords1[s+1][output_shard_index].write(tf_record.SerializeToString())\n                if bcnt == BKGND_1_OF_X:\n                    bcnt = 0\n                else:\n                    bcnt = bcnt + 1\n        output_shard_index += 1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a .json file with a few useful parameters we might need during training/inference:","metadata":{}},{"cell_type":"code","source":"dparams = {\n    \"IMG_SIZE\": IMG_SIZE,\n    \"SCALE_FACTOR\": SCALE_FACTOR}\nwith open(\"dparams.json\", \"w\") as json_file:\n    json_file.write(json.dumps(dparams, indent = 4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Export a table with number of images per TFRecord.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nrecsizes = []\nnum_shards = len(filelist)\nfor i in range(num_shards):\n    for j in range(len(img_sizes)):\n        recsizes.append(['{}-{}.tfrecord'.format(fnames[i], img_sizes[j]), gcnt[i]])\ndf = pd.DataFrame(recsizes, columns=['File', 'ImgCount'])\ndf.to_pickle('./record_stats.pkl')\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the output files\nThe final check is to load and plot a couple of TFRecords and verify that everything loads OK.","metadata":{}},{"cell_type":"code","source":"def plot_imgs(dataset):\n    fig = plt.figure(figsize=(18,18))\n    idx=1\n    for raw_record in dataset.take(36):\n        axes = fig.add_subplot(6, 6, idx)\n        example = tf.train.Example()\n        example.ParseFromString(raw_record.numpy())\n        img_encoded=example.features.feature['image/encoded'].bytes_list.value[0]\n        img = Image.open(BytesIO(img_encoded))\n        mask_encoded=example.features.feature['mask/encoded'].bytes_list.value[0]\n        mask = Image.open(BytesIO(mask_encoded))\n        plt.setp(axes, xticks=[], yticks=[])\n        plt.imshow(img)\n        plt.imshow(mask, alpha=0.25)\n        idx=idx+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fname='./095bf7a1f-256.tfrecord'\ndataset = tf.data.TFRecordDataset(fname)\ndataset = dataset.shuffle(2048, reshuffle_each_iteration=True)\nplot_imgs(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}