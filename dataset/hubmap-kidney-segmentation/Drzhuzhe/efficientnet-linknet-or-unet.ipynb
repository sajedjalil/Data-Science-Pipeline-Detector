{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Preproccess and tranning\n\n1. preproccess https://www.kaggle.com/drzhuzhe/hubmap-tf-with-tpu-efficientunet-256-tfrecord\n2. my trainning notebook https://www.kaggle.com/drzhuzhe/hubmap-efficientnet-and-linknet-train\n3. my predict visualization https://www.kaggle.com/drzhuzhe/ananlysis-predict\n\n\n## Reffernce notebook\n\n* 1. Tensorflow HuBMAP - Hacking the Kidney competition starter kit:\n* https://www.kaggle.com/wrrosa/hubmap-tf-with-tpu-efficientunet-512x512-tfrecs (how to create training and inference tfrecords) https://www.kaggle.com/wrrosa/hubmap-tf-with-tpu-efficientunet-512x512-train (training pipeline)\n* 2. best public LB notebook https://www.kaggle.com/vgarshin/kidney-unet-model-keras-inference\n* https://github.com/vgarshin/kaggle_kidney/blob/master/kidney_train.ipynb\n* This infer note book is as same as wrrosa's work too\n\n* 3. TODO https://www.kaggle.com/matjes/hubmap-efficient-sampling-deepflash2-train\n\n## Approach \n\n1. https://www.kaggle.com/c/hubmap-kidney-segmentation/discussion/200955\n2. https://www.kaggle.com/c/hubmap-kidney-segmentation/discussion/200626\n\n\n\n\n# Versions\n* V1 - V2 use effientnetb4 + unet baseline form wrrosa’s idea (LB .907)\n* V3 try  efficientb0 + linknet from vgarshin‘s idea (LB .915)\n* v4 ~intend to try deepflash's approach~ but just try efficientnetb0 + unet\n* v5 - v22 fix preprocess bug use 256 pics\n* v22-v40 tuning params  (LB .920)\n* v40-v43 add TTA for tfrecord (LB .921)\n* v44 add extenal data ","metadata":{}},{"cell_type":"markdown","source":"# Parameters\nRead parameteres from notebook output, actually only **DIM** is used:","metadata":{}},{"cell_type":"code","source":"# 改成用我自己的\n#mod_path = '/kaggle/input/hubmap-efficientnet-and-linknet-train/'\nmod_path = '/kaggle/input/hubmap-efficientnet-and-linknet-train/'\nimport yaml\nimport pprint\nwith open(mod_path+'params.yaml') as file:\n    P = yaml.load(file, Loader=yaml.FullLoader)\n    pprint.pprint(P)\n    \nTHRESHOLD = 0.3 # preds > THRESHOLD\nWINDOW = 1024\n\nMIN_OVERLAP =  1 / 16\nNEW_SIZE = P['DIM']\nREDUCE = int(WINDOW / NEW_SIZE)\nEXPAND = 4\n\nSUBMISSION_MODE = 'PUBLIC_TFREC' # PUBLIC_TFREC or FULL\n# 'PUBLIC_TFREC' = use created tfrecords for public test set with MIN_OVERLAP = 300 tiling 1024-512, ignore other (private test) data\n# 'FULL' do not use tfrecords, just full submission \n\nCHECKSUM = True # compute mask sum for each image\nselected_models = [0, 1, 2, 3, 4]\n#selected_models = [0]\nTTAS = [0, 1, 2, 3]\n#TTAS = [0]\nVOTERS = 0.5\ndef flip(img, axis=0):\n    if axis == 1:\n        return img[::-1, :, ]\n    elif axis == 2:\n        return img[:, ::-1, ]\n    elif axis == 3:\n        return img[::-1, ::-1, ]\n    else:\n        return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"code","source":"import json\n\nwith open(mod_path + 'metrics.json') as json_file:\n    M = json.load(json_file)\nprint('Model run datetime: '+M['datetime'])\nprint('OOF val_dice_coe: ' + str(M['oof_dice_coe']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Packages","metadata":{}},{"cell_type":"code","source":"! pip install ../input/kerasapplications/keras-team-keras-applications-3b180cb -f ./ --no-index -q\n! pip install ../input/efficientnet/efficientnet-1.1.0/ -f ./ --no-index -q\nimport numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport gc\n\nimport rasterio\nfrom rasterio.windows import Window\n\nimport pathlib\nfrom tqdm.notebook import tqdm\nimport cv2\n\nimport tensorflow as tf\nimport efficientnet as efn\nimport efficientnet.tfkeras\n#import tensorflow.keras.backend as K","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#glob.glob(mod_path+'*.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#a = np.array([[[1,2,3],[4,5,6],[7,8,9]],[[1,2,3],[4,5,6],[7,8,9]]])\n\"\"\"\na = np.array(\n    [[[[1],[2],[3]],\n     [[4],[5],[6]],\n     [[7],[8],[9]]],\n    [[[1],[2],[3]],\n     [[4],[5],[6]],\n     [[7],[8],[9]]]])\n\"\"\"\n#a[0][::-1, :, ]\n#print(flip(a[1], axis=2))\n#print(K.reverse(a[0],axes=2))\n#r = []\n#for x in a:\n#    x[...] = flip(x, axis=2)\n#print(np.array(r))\n#print(a)\n#a = flip(a, axis=3)\n#print(a)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"def rle_encode_less_memory(img):\n    pixels = img.T.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef make_grid(shape, window=256, min_overlap=32):\n    \"\"\"\n        Return Array of size (N,4), where N - number of tiles,\n        2nd axis represente slices: x1,x2,y1,y2 \n    \"\"\"\n    x, y = shape\n    nx = x // (window - min_overlap) + 1\n    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n    x1[-1] = x - window\n    x2 = (x1 + window).clip(0, x)\n    ny = y // (window - min_overlap) + 1\n    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n    y1[-1] = y - window\n    y2 = (y1 + window).clip(0, y)\n    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n    \n    for i in range(nx):\n        for j in range(ny):\n            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n    return slices.reshape(nx*ny,4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\nfold_models = []\n# for fold_model_path in glob.glob(mod_path+'.h5'): \nfor selected_models_idx in selected_models:\n    fold_model_path = f'/kaggle/input/hubmap-efficientnet-and-linknet-train/model-fold-{selected_models_idx}.h5'\n    print(fold_model_path)\n    fold_models.append(tf.keras.models.load_model(fold_model_path,compile = False))\nprint(len(fold_models), fold_models)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tfrecords functions","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nimage_feature = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'x1': tf.io.FixedLenFeature([], tf.int64),\n    'y1': tf.io.FixedLenFeature([], tf.int64)\n}\ndef _parse_image(example_proto, tta_mode=0):\n    example = tf.io.parse_single_example(example_proto, image_feature)\n    image = tf.reshape( tf.io.decode_raw(example['image'],out_type=np.dtype('uint8')), (P['DIM'],P['DIM'], 3))\n    \n    # 左右\n    if tta_mode == 2:\n        image = tf.image.flip_left_right(image)\n    # 上下\n    if tta_mode == 1:\n        image = tf.image.flip_up_down(image)\n    # 反转\n    if tta_mode == 3:\n        image = tf.image.rot90(image, k=2)\n        \n    return image, example['x1'], example['y1']\n\ndef load_dataset(filenames, ordered=True, tta_mode=0):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(lambda ex: _parse_image(ex, tta_mode=tta_mode))\n    return dataset\n\ndef get_dataset(FILENAME, tta_mode=0):\n    dataset = load_dataset(FILENAME, tta_mode=tta_mode)\n    dataset  = dataset.batch(64)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"p = pathlib.Path('../input/hubmap-kidney-segmentation')\nsubm = {}\n\nfor i, filename in tqdm(enumerate(p.glob('test/*.tiff')), \n                        total = len(list(p.glob('test/*.tiff')))):\n    \n    print(f'{i+1} Predicting {filename.stem}')\n    \n    dataset = rasterio.open(filename.as_posix(), transform = identity)\n    \n    # predict on 4 * 4 * 256 image to save infer time\n    tile_size = int(NEW_SIZE * EXPAND)\n    tile_resized = int(tile_size * REDUCE)\n             \n    preds = np.zeros(dataset.shape, dtype=np.uint8)    \n    \n    if SUBMISSION_MODE == 'PUBLIC_TFREC' and MIN_OVERLAP == 300 and WINDOW == 1024 and NEW_SIZE == 256:\n        print('SUBMISSION_MODE: PUBLIC_TFREC')\n        fnames = glob.glob('/kaggle/input/hubmap-tf-with-tpu-efficientunet-256-tfrecord/test/'+filename.stem+'*.tfrec')\n        \n        if len(fnames)>0: # PUBLIC TEST SET\n            for FILENAME in fnames:\n                pred = None\n                \n                for tta_mode in TTAS:\n                    for fold_model in fold_models:\n                        tmp = fold_model.predict(get_dataset(FILENAME, tta_mode=tta_mode))/len(fold_models)  \n                        # 还原\n                        for x in tmp:\n                            x[...] = flip(x, axis=tta_mode)                    \n                        if pred is None:\n                            pred = tmp\n                        else:\n                            pred += tmp\n                        del tmp\n                        gc.collect()\n                    \n                pred = pred / len(TTAS)\n                \n                pred = tf.cast((tf.image.resize(pred, (WINDOW,WINDOW)) > THRESHOLD),tf.bool).numpy().squeeze()\n\n                idx = 0\n                for img, X1, Y1 in get_dataset(FILENAME):\n                    for fi in range(X1.shape[0]):\n                        x1 = X1[fi].numpy()\n                        y1 = Y1[fi].numpy()\n                        preds[x1:(x1+WINDOW),y1:(y1+WINDOW)] += pred[idx]\n                        idx += 1\n                        \n        else: # IGNORE PRIVATE TEST SET (CREATE TFRECORDS IN FUTURE)\n            pass\n    else:\n        print('SUBMISSION_MODE: FULL')\n        slices = make_grid(dataset.shape, window=tile_resized, min_overlap=int( tile_resized * MIN_OVERLAP ))\n                    \n        if dataset.count != 3:\n            print('Image file with subdatasets as channels')\n            layers = [rasterio.open(subd) for subd in dataset.subdatasets]\n            \n        for (x1,x2,y1,y2) in slices:\n            if dataset.count == 3:\n                image = dataset.read([1,2,3],\n                            window=Window.from_slices((x1,x2),(y1,y2)))\n                image = np.moveaxis(image, 0, -1)\n            else:\n                image = np.zeros((tile_resized, tile_resized, 3), dtype=np.uint8)\n                for fl in range(3):\n                    image[:,:,fl] = layers[fl].read(window=Window.from_slices((x1,x2),(y1,y2)))\n                    \n            image = cv2.resize(image, (tile_size, tile_size),interpolation = cv2.INTER_AREA)\n            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n            \n            #image = np.expand_dims(image, 0)\n\n            pred = np.zeros((tile_size, tile_size), dtype=np.float32)            \n            ### tta s \n            #\"\"\"                  \n            for tta_mode in TTAS:\n                img_aug = flip(image, axis=tta_mode)\n                img_aug = np.expand_dims(img_aug, 0)\n                \"\"\"\n                my model is training without pixel/255, \n                if you did, plase uncommit next line \n                or you will get all predicts very small value under THRESHOLD so get a empty submit\n                \"\"\" \n                #img_aug = img_aug.astype(np.float32) / 255\n                for fold_model in fold_models:\n                    pred_aug = np.squeeze(fold_model.predict(img_aug))\n                    pred += flip(pred_aug, axis=tta_mode)\n            pred /= (len(fold_models) * len(TTAS))           \n            # tta e\n\n            pred = cv2.resize(pred, (tile_resized, tile_resized))\n            preds[x1:x2,y1:y2] += (pred > THRESHOLD).astype(np.uint8)\n                    \n        del fold_model, image, pred, img_aug, pred_aug; gc.collect()\n\n    preds = (preds > VOTERS).astype(np.uint8)\n    \n    subm[i] = {'id':filename.stem, 'predicted': rle_encode_less_memory(preds)}\n    \n    if CHECKSUM:\n        print('Checksum: '+ str(np.sum(preds)))\n    \n    del preds\n    gc.collect();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making submission","metadata":{}},{"cell_type":"code","source":"# kaggle 的单人资源似乎是抢占式的\n\nsubmission = pd.DataFrame.from_dict(subm, orient='index')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}