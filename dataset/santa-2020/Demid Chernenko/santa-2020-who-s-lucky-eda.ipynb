{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center> Santa-2020 - who's lucky? (leaderboard analysis) </center></h1>"},{"metadata":{},"cell_type":"markdown","source":"<h2><center> <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/68/Xmasart_%2857%29.jpg\" alt=\"Christmas img\"></center></h2>"},{"metadata":{},"cell_type":"markdown","source":"It's quite obvious that luck plays an important role in this competition. This notebook shows that most medal-winning teams have small number of \"medal zone\" agents. That is, these are lucky outliers (repeated submissions didn't achieve the same score). However, this effect is much smaller than in [Rock, Paper, Scissors](https://www.kaggle.com/demche/rock-paper-scissors-leaderboard-eda) competition.\n\n[@dmitriyguller](https://www.kaggle.com/dmitriyguller) quite precisely formulated this issue: \n> The nature of the leaderboard also exaggerates luck, because it rewards the extreme deviation from expected performance, not the expected performance itself. An agent that scores 1100 99% of the time, but 1350 the other 1% of the time, is preferable to the agent who gets 1325 every single time."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport warnings\nfrom kaggle_environments import list_episodes\nfrom IPython.display import display, Markdown\npd.set_option(\"display.max_rows\", 200)\npd.options.display.float_format = '{:,.2f}'.format\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!wget \"https://www.kaggle.com/c/santa-2020/leaderboard.json?includeBeforeUser=true&includeAfterUser=false\" -O leaderboard.json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"with open(\"leaderboard.json\") as f:\n    jsn = json.load(f)\nleaderboard = pd.DataFrame(columns = [\"team_name\", \"team_id\", \"score\", \"n_agents\", \"team_rank\"])\nfor user in jsn[\"beforeUser\"]+jsn[\"afterUser\"]:\n    leaderboard = leaderboard.append({\"team_name\": user[\"teamName\"], \n                                      \"team_id\": user[\"teamId\"], \n                                      \"score\": user[\"score\"], \n                                      \"n_agents\": user[\"entries\"],\n                                     \"team_rank\": user[\"rank\"]}, \n                                     ignore_index=True)\nleaderboard[[\"score\", \"n_agents\", \"team_rank\"]] = leaderboard[[\"score\", \"n_agents\", \"team_rank\"]].apply(pd.to_numeric)\ngold_min_score = leaderboard.sort_values(\"score\", ascending=False)[\"score\"][10]\nsilver_min_score = leaderboard.sort_values(\"score\", ascending=False)[\"score\"][49]\nbronze_min_score = leaderboard.sort_values(\"score\", ascending=False)[\"score\"][99]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"episodes = pd.read_csv(\"../input/meta-kaggle/Episodes.csv\")\ngaps = sorted(set(range(episodes[episodes[\"CompetitionId\"] == 24539][\"Id\"].min(), episodes[\"Id\"].max() + 1)) - set(episodes[\"Id\"].values), reverse=True)\nepisodes = episodes.loc[episodes[\"CompetitionId\"] == 24539]\nepisodes[\"CreateTime\"] = pd.to_datetime(episodes[\"CreateTime\"], format=\"%m/%d/%Y %H:%M:%S\")\nepisodes = episodes[[\"Id\", \"CreateTime\"]]\n\nepisode_agents = pd.read_csv(\"../input/meta-kaggle/EpisodeAgents.csv\")\nepisode_agents = pd.merge(episode_agents, episodes, left_on=\"EpisodeId\", right_on=\"Id\")\nepisode_agents = episode_agents[[\"EpisodeId\", \"CreateTime\", \"SubmissionId\", \"UpdatedScore\"]]\nepisode_agents = episode_agents.drop_duplicates()\nepisode_agents[\"date\"] = episode_agents[\"CreateTime\"].dt.date\nagents_mapping = pd.DataFrame(columns = [\"team_id\", \"submission_id\", \"submission_dt\"])\n\nepisodes_to_consider = episode_agents[episode_agents[\"EpisodeId\"].isin(episodes[\"Id\"])].groupby([\"SubmissionId\"])[\"EpisodeId\"].max().to_list()\nfor i in range(0, len(episodes_to_consider), 1000):\n    batch = episodes_to_consider[i:i + 1000]\n    try:\n        resp = list_episodes(batch)  \n        for episode in resp[\"result\"][\"submissions\"]:\n            agents_mapping = agents_mapping.append({\"team_id\": episode[\"teamId\"],\n                                \"submission_id\":  episode[\"id\"] ,\n                                \"submission_dt\": datetime.datetime.strptime(episode[\"dateSubmitted\"][:19], \"%Y-%m-%dT%H:%M:%S\")\n                               }, ignore_index=True)\n        del episode, batch\n    except Exception as ex:\n        print(\"Error:\", ex)\n        continue\n\nfor i in range(0, len(gaps), 1000):\n    batch = gaps[i:i + 1000]\n    try:\n        resp = list_episodes(batch)      \n        if len(resp[\"result\"][\"episodes\"]) != 0:\n            for episode in resp[\"result\"][\"episodes\"]:\n                if episode[\"competitionId\"] == 24539:\n                    EpisodeId = episode[\"id\"]\n                    for agent in episode[\"agents\"]:\n                        submissionId = agent[\"submissionId\"]\n                        updatedScore = agent[\"updatedScore\"]\n                        CreateTime = datetime.strptime(episode[\"createTime\"][:19], \"%Y-%m-%dT%H:%M:%S\")\n                        episode_agents = episode_agents.append({\"EpisodeId\": EpisodeId,\n                                                    \"CreateTime\": CreateTime,\n                                                    \"SubmissionId\": submissionId,\n                                                    \"UpdatedScore\": updatedScore\n                                                    }, ignore_index=True)           \n            for episode in episodes[\"result\"][\"submissions\"]:\n                agents_mapping = agents_mapping.append({\"team_id\": episode[\"teamId\"],\n                                    \"submission_id\":  episode[\"id\"] ,\n                                    \"submission_dt\": datetime.datetime.strptime(episode[\"dateSubmitted\"][:19], \"%Y-%m-%dT%H:%M:%S\")\n                                   }, ignore_index=True)\n            del episode, batch\n    except Exception as ex:\n        print(\"Error:\", ex)\n        continue\n        \nagents_mapping = agents_mapping.drop_duplicates(subset=[\"submission_id\"])\nepisode_agents = episode_agents[episode_agents[\"SubmissionId\"].isin(agents_mapping[\"submission_id\"])]\nepisode_agents = episode_agents.drop_duplicates()\nagents = episode_agents.loc[episode_agents.groupby(\"SubmissionId\").CreateTime.idxmax()].dropna(subset=[\"UpdatedScore\"]).\\\n    loc[:, [\"SubmissionId\", \"UpdatedScore\"]].reset_index(drop=True)\nagents.columns = [\"submission_id\", \"score\"]\nagents = pd.merge(agents, agents_mapping, on=\"submission_id\", how=\"left\")\nagents = agents.drop_duplicates(subset=[\"submission_id\"])\nagents = pd.merge(agents, leaderboard.loc[:, [\"team_name\", \"team_id\"]], on=\"team_id\", how=\"left\")\nagents[\"medal\"] = [\"gold\" if x >= gold_min_score else \"silver\" if x >= silver_min_score else \"bronze\" if x >= bronze_min_score else \"no medal\" \\\n     for x in agents[\"score\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Score distribution"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nplt.hist(leaderboard[\"score\"], color=\"lightsteelblue\", bins=200)\nplt.axvline(x=gold_min_score, color=\"gold\")\nplt.axvline(x=silver_min_score, color=\"silver\")\nplt.axvline(x=bronze_min_score, color=\"peru\")\nplt.xlabel(\"Team score\")\nplt.ylabel(\"Number of teams\")\nplt.legend(title=\"Team score distribution (vertical lines are medal thresholds)\", loc=\"upper center\", title_fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nplt.hist(leaderboard[\"score\"][leaderboard[\"score\"] > 1000], color=\"thistle\", bins=120)\nplt.axvline(x=gold_min_score, color=\"gold\")\nplt.axvline(x=silver_min_score, color=\"silver\")\nplt.axvline(x=bronze_min_score, color=\"peru\")\nplt.xlabel(\"Team score\")\nplt.ylabel(\"Number of teams\")\nplt.legend(title=\"Team score distribution (teams with score > 1000, vertical lines are medal thresholds)\", loc=\"upper center\", title_fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"leaderboard[\"score\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stat_santa = episode_agents.groupby([\"date\"]).agg({\"UpdatedScore\": [np.max, np.min, np.mean, np.median]}, axis=\"columns\")\nstat_santa.columns = stat_santa.columns.droplevel(0)\nstat_santa.plot(figsize=(25,10), title=\"Score summary statistics for individual agents\", colormap=\"Spectral\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Number of submissions for medal-winning teams"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nplt.hist([leaderboard.sort_values(\"score\", ascending=False)[\"n_agents\"][:10],\n          leaderboard.sort_values(\"score\", ascending=False)[\"n_agents\"][11:51],\n          leaderboard.sort_values(\"score\", ascending=False)[\"n_agents\"][51:101]],\n         label=[\"gold-winning team\", \"silver-winning team\", \"bronze-winning team\"],\n         color= [\"gold\", \"silver\", \"peru\"], bins=50, stacked=True, alpha=0.7)\nplt.xlabel(\"Number of submissions\")\nplt.ylabel(\"Number of teams\")\nplt.legend(title=\"Total number of submissions for medal-winning teams\", loc=\"upper center\", title_fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Medal zone agents"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"agents_bronze = agents[agents[\"medal\"] == \"bronze\"].sort_values(by=[\"score\"], ascending=False).reset_index()[\"team_name\"].\\\nvalue_counts().reset_index().rename(columns={\"index\": \"team\", \"team_name\": \"bronze\"})\nagents_silver = agents[agents[\"medal\"] == \"silver\"].sort_values(by=[\"score\"], ascending=False).reset_index()[\"team_name\"].\\\nvalue_counts().reset_index().rename(columns={\"index\": \"team\", \"team_name\": \"silver\"})\nagents_gold = agents[agents[\"medal\"] == \"gold\"].sort_values(by=[\"score\"], ascending=False).reset_index()[\"team_name\"].\\\nvalue_counts().reset_index().rename(columns={\"index\": \"team\", \"team_name\": \"gold\"})\nmedal_zone_agents = pd.merge(pd.merge(agents_gold, agents_silver, on=\"team\", how=\"outer\"), agents_bronze, on=\"team\", how=\"outer\").fillna(0)\nmedal_zone_agents[\"bronze\"] = medal_zone_agents[\"bronze\"].astype(int)\nmedal_zone_agents[\"silver\"] = medal_zone_agents[\"silver\"].astype(int)\nmedal_zone_agents[\"gold\"] = medal_zone_agents[\"gold\"].astype(int)\nmedal_zone_agents.head(100).style.background_gradient(cmap=\"YlGn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Time of submission by medal zone\n\n[@pedram](https://www.kaggle.com/pedram) [suggested](https://www.kaggle.com/c/santa-2020/discussion/214271) that newly written agents can possibly get into the top. Right now there is no apparent relationship between submission time and score. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"agents[\"medal_color\"] = [\"peru\" if x == \"bronze\" else \"lightblue\" if x == \"no medal\" else x for x in agents[\"medal\"]]\nfor medal_type, group in agents.groupby(\"medal\"):\n    display(Markdown(\"Medal: \" + str(medal_type)))\n    plt.figure(figsize=(20, 10))\n    plt.scatter(group[\"submission_dt\"], group[\"score\"], c=group[\"medal_color\"])\n    plt.title(\"Medal: \" + str(medal_type))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Top-10 agents for medal-winning teams"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"top_teams_agents = agents[agents[\"team_id\"].isin(leaderboard.sort_values(by=[\"score\"], ascending=False).head(100)[\"team_id\"])].reset_index()\ntop_teams_agents = pd.merge(top_teams_agents, leaderboard[[\"team_id\", \"team_rank\"]], on=[\"team_id\"], how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top_teams_agents_best10 = top_teams_agents.sort_values(\"score\",ascending = False).groupby(\"team_id\").head(10).reset_index(drop=True)\ntop_teams_agents_best10 = top_teams_agents_best10.loc[:, [\"team_name\", \"score\"]]\ntop_teams_agents_best10[\"rank\"] = top_teams_agents_best10.groupby(\"team_name\")[\"score\"].rank(\"dense\", ascending=False).astype(int)\ntop_teams_agents_best10.pivot(index=\"team_name\", columns=\"rank\", values=\"score\").sort_values(1,ascending = False).style.background_gradient(cmap=\"YlOrBr\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Best agent vs top agents\n\nBest agent is clearly outlier if there is significant difference between its score and top agents' score."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"best1_agents = agents.sort_values(\"score\",ascending = False).groupby(\"team_name\").head(1).reset_index(drop=True).\\\n    groupby(\"team_name\").agg({\"score\": np.mean}).rename(columns={\"score\": \"best agent\"})\nbest10_agents = agents.sort_values(\"score\",ascending = False).groupby(\"team_name\").head(10).reset_index(drop=True).\\\n    groupby(\"team_name\").agg({\"score\": np.mean}).rename(columns={\"score\": \"top 10 agents\"})\nbest30_agents = agents.sort_values(\"score\",ascending = False).groupby(\"team_name\").head(30).reset_index(drop=True).\\\n    groupby(\"team_name\").agg({\"score\": np.mean}).rename(columns={\"score\": \"top 30 agents\"})\nbest_agents = pd.merge(pd.merge(pd.merge(best1_agents, best10_agents, on=[\"team_name\"]), best30_agents, on=[\"team_name\"]), \n                leaderboard.loc[:, [\"team_name\", \"n_agents\"]], on=[\"team_name\"])\nbest_agents[\"difference best - top 10\"] = best_agents.apply(lambda x: x[\"best agent\"] - x[\"top 10 agents\"], axis=1)\nbest_agents[\"difference best - top 30\"] = best_agents.apply(lambda x: x[\"best agent\"] - x[\"top 30 agents\"], axis=1)\nbest_agents[\"medal\"] = [\"gold\" if x >= gold_min_score else \"silver\" if x >= silver_min_score else \"peru\" if x >= bronze_min_score else \"lightblue\" \\\n     for x in best_agents[\"best agent\"]]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,15))\nplt.scatter(best_agents[\"best agent\"], best_agents[\"top 10 agents\"], c=best_agents[\"medal\"], alpha=0.7)\nplt.xlabel(\"Best agent score\")\nplt.ylabel(\"Top-10 agents score (mean)\")\nplt.legend(title=\"Top-10 agents score (mean) vs best agent score\", loc=\"lower center\", title_fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nplt.hist(best_agents[\"difference best - top 10\"][best_agents[\"difference best - top 10\"] != 0], color=\"lightcoral\", bins=200)\nplt.xlabel(\"Difference between best agent and top 10 agents\")\nplt.ylabel(\"Number of teams\")\nplt.legend(title=\"Difference between top-10 agents score (mean) and best agent score\", loc=\"upper center\", title_fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,15))\nplt.scatter(best_agents[\"best agent\"], best_agents[\"top 30 agents\"], c=best_agents[\"medal\"], alpha=0.7)\nplt.xlabel(\"Best agent score\")\nplt.ylabel(\"Top-30 agents score (mean)\")\nplt.legend(title=\"Top-30 agents score (mean) vs best agent score\", loc=\"lower center\", title_fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nplt.hist(best_agents[\"difference best - top 30\"][best_agents[\"difference best - top 30\"] != 0], color=\"orange\", bins=200)\nplt.xlabel(\"Difference between best agent and top 30 agents\")\nplt.ylabel(\"Number of teams\")\nplt.legend(title=\"Difference between top-30 agents score (mean) and best agent score\", loc=\"upper center\", title_fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Difference for medal-winning teams:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"best_agents[best_agents[\"team_name\"].isin(leaderboard.sort_values(\"score\", ascending=False)[\"team_name\"][0:99])].\\\n    loc[:, [\"team_name\", \"best agent\", \"top 10 agents\", \"top 30 agents\", \"difference best - top 10\", \n             \"difference best - top 30\", \"n_agents\"]].sort_values(\"best agent\", ascending=False).reset_index(drop=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}