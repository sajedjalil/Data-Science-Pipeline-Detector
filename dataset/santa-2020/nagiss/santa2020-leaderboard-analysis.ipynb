{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install kaggle-environments --upgrade","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from pprint import pprint\nimport os\nimport sys\nfrom time import time, sleep\nimport json\nfrom datetime import datetime\nimport warnings\nfrom operator import itemgetter\nfrom itertools import groupby, count\nfrom collections import defaultdict, Counter\n\nimport numpy as np\nimport numba\nimport pandas as pd\nimport matplotlib.dates as mdates\nimport matplotlib.pyplot as plt\nfrom kaggle_environments import (\n    evaluate, make, utils,\n    get_episode_replay, list_episodes, list_episodes_for_submission  # list_episodes_for_team is no longer available\n)\n\nSANTA2020_COMPETITION_ID = 24539\npd.options.display.max_rows = 1000\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!wget 'https://www.kaggle.com/c/santa-2020/leaderboard.json?includeBeforeUser=true&includeAfterUser=false' -O leaderboard.json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"with open(\"leaderboard.json\") as f:\n    jsn = json.load(f)\nleaderboard_data = jsn[\"beforeUser\"] + jsn[\"afterUser\"]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_episode_agents = pd.read_csv(\"../input/meta-kaggle/EpisodeAgents.csv\")\n\ndf_episodes = pd.read_csv(\"../input/meta-kaggle/Episodes.csv\")\ndf_episodes[\"CreateTime\"] = pd.to_datetime(df_episodes[\"CreateTime\"], format=\"%m/%d/%Y %H:%M:%S\")\ndf_episodes[\"EndTime\"] = pd.to_datetime(df_episodes[\"EndTime\"], format=\"%m/%d/%Y %H:%M:%S\")\n\ndf_teams = pd.read_csv(\"../input/meta-kaggle/Teams.csv\")\ndf_teams[\"ScoreFirstSubmittedDate\"] = pd.to_datetime(df_teams[\"ScoreFirstSubmittedDate\"], format=\"%m/%d/%Y\")\ndf_teams[\"LastSubmissionDate\"] = pd.to_datetime(df_teams[\"LastSubmissionDate\"], format=\"%m/%d/%Y\")\ndf_teams[\"MedalAwardDate\"] = pd.to_datetime(df_teams[\"MedalAwardDate\"], format=\"%m/%d/%Y\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"l = df_episodes[df_episodes[\"CompetitionId\"]==SANTA2020_COMPETITION_ID][\"Id\"].min()\nr = df_episodes[\"Id\"].max()\nmissing_ids = sorted(set(range(l, r+1)) - set(df_episodes[\"Id\"].values))\nassert len(missing_ids) <= 100000","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%%time\n\nepisodes = []\nepisode_agents = []\ndict_submissions = {}\ndict_teams = {}\n\ndef get_new_data(ids):\n    for _ in range(3):\n        try:\n            res = list_episodes(ids)\n            sleep(10)\n            break\n        except:\n            print(\"ERROR!\")\n            sleep(60)\n    else:\n        print(\"SKIPPED!\")\n        return False\n    print(f'len(res[\"result\"][\"episodes\"])={len(res[\"result\"][\"episodes\"])}')\n    if len(res[\"result\"][\"episodes\"]) == 0:\n        return False\n    for episode in res[\"result\"][\"episodes\"]:\n        episodes.append(episode)\n        for agent in episode[\"agents\"]:\n            agent[\"episodeId\"] = episode[\"id\"]\n            episode_agents.append(agent)\n    for submission in res[\"result\"][\"submissions\"]:\n        if submission[\"status\"] != \"error\":\n            dict_submissions[submission[\"id\"]] = submission\n    for team in res[\"result\"][\"teams\"]:\n        dict_teams[team[\"id\"]] = team\n    return True\n\nfor idx_missing_ids in range(0, len(missing_ids), 1000):\n    ids = missing_ids[idx_missing_ids:idx_missing_ids+1000]\n    print(f\"{ids[0]}-{ids[-1]}\")\n    get_new_data(ids)\n\nl = df_episodes[\"Id\"].max()+1\nfor id_ in range(l, l+500000, 1000):\n    ids = list(range(id_, id_+1000))\n    print(f\"{ids[0]}-{ids[-1]}\")\n    updated = get_new_data(ids)\n    if ids[0] > 17759033 and not updated:\n        print(\"finished!\")\n        break","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"len(episodes)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"gold_score = min(float(x[\"score\"]) for x in leaderboard_data if x[\"medal\"]==\"gold\")\nsilver_score = min(float(x[\"score\"]) for x in leaderboard_data if x[\"medal\"]==\"silver\")\nbronze_score = min(float(x[\"score\"]) for x in leaderboard_data if x[\"medal\"]==\"bronze\")\nmedal_thresholds = [gold_score, silver_score, bronze_score]\nmedal_colors = [\"#B88121\", \"#838280\", \"#8E5B3D\"]\nmedal_thresholds","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def episode_type_str_to_int(t):\n    if t == \"public\":\n        return 1\n    elif t == \"validation\":\n        return 4\n    else:\n        # ?\n        return -100\n\ndf_episodes_new = pd.DataFrame(episodes)\ndf_episodes_new.columns = [col[0].upper() + col[1:] for col in df_episodes_new.columns]\ndf_episodes_new[\"CreateTime\"] = df_episodes_new[\"CreateTime\"].map(lambda x: datetime.fromtimestamp(x[\"seconds\"]))\ndf_episodes_new[\"EndTime\"] = df_episodes_new[\"EndTime\"].map(lambda x: datetime.fromtimestamp(x[\"seconds\"]))\ndf_episodes_new[\"Type\"] = df_episodes_new[\"Type\"].map(episode_type_str_to_int)\ndf_episodes_new = df_episodes_new[df_episodes.columns]\n\ndf_episodes = pd.concat([df_episodes, df_episodes_new])\ndf_episodes.drop_duplicates(\"Id\", keep=\"last\", inplace=True)\ndf_episodes.sort_values(\"Id\", inplace=True)\ndf_episodes.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_episode_agents_new = pd.DataFrame(episode_agents)\ndf_episode_agents_new.columns = [col[0].upper() + col[1:] for col in df_episode_agents_new.columns]\ndf_episode_agents_new[\"State\"] = -1\ndf_episode_agents_new = df_episode_agents_new[df_episode_agents.columns]\n\ndf_episode_agents = pd.concat([df_episode_agents, df_episode_agents_new])\ndf_episode_agents.drop_duplicates(\"Id\", keep=\"last\", inplace=True)\ndf_episode_agents.sort_values(\"Id\", inplace=True)\ndf_episode_agents.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_teams_new = pd.DataFrame(dict_teams.values())\ndf_teams_new.columns = [col[0].upper() + col[1:] for col in df_teams_new.columns]\ndf_teams_new[\"LastSubmissionDate\"] = df_teams_new[\"LastSubmissionDate\"].map(lambda x: datetime.fromtimestamp(x[\"seconds\"]) if x is not None else np.nan)\ndf_teams_new = df_teams_new[list(set(df_teams_new.columns) & set(df_teams.columns))]\n\ndf_teams = pd.concat([df_teams, df_teams_new])\ndf_teams.drop_duplicates(\"Id\", keep=\"last\", inplace=True)\ndf_teams.sort_values(\"Id\", inplace=True)\ndf_teams.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_episode_agents = df_episode_agents[df_episode_agents[\"EpisodeId\"].map(dict(df_episodes[[\"Id\", \"CompetitionId\"]].values))==SANTA2020_COMPETITION_ID]\ndf_episode_agents.reset_index(inplace=True, drop=True)\ndf_episode_agents = df_episode_agents[df_episode_agents[\"EpisodeId\"].map(df_episode_agents[\"EpisodeId\"].value_counts())==2]\ndf_episode_agents.sort_values(\"EpisodeId\", inplace=True)\ndf_episode_agents.reset_index(inplace=True, drop=True)\ndf_episode_agents[\"TeamId\"] = df_episode_agents[\"SubmissionId\"].map(lambda x: dict_submissions[x][\"teamId\"] if x in dict_submissions else -1)\n\ndf_submissions = df_episode_agents.drop_duplicates(\"SubmissionId\", keep=\"last\")[[\"SubmissionId\", \"TeamId\", \"UpdatedScore\"]]\ndf_submissions.rename(columns={\"UpdatedScore\": \"Rating\"}, inplace=True)\ndf_submissions.reset_index(drop=True, inplace=True)\ndf_submissions = df_submissions[~df_submissions[\"Rating\"].isna()]\ndf_submissions.sort_values(\"SubmissionId\", inplace=True)\ndf_submissions.reset_index(drop=True, inplace=True)\ndf_submissions[\"SubmissionDate\"] = df_submissions[\"SubmissionId\"].map(lambda x: datetime.fromtimestamp(dict_submissions[x][\"dateSubmitted\"][\"seconds\"]) if x in dict_submissions else np.nan)\n\ndict_team_id_to_team_rank = defaultdict(lambda: 99999)\ndict_team_id_to_team_rank.update({team[\"teamId\"]: team[\"rank\"] for team in leaderboard_data})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Boxplot (last 30 agents for each team)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"last_n = 30\nmax_rank = 100\nmax_rating = (int(df_submissions[\"Rating\"].max()) // 100 + 1) * 100\nmin_rating = max_rating - 1000\n\nplt.figure(figsize=(20, 50))\nplt.vlines(medal_thresholds, 0, max_rank+1, medal_colors, linewidth=1.5, linestyles=(0, (3, 10)))\n\ndict_submission_id_to_rating = dict(df_submissions[[\"SubmissionId\", \"Rating\"]].values)\nlast_submission_ids_each_team = defaultdict(list)\nlast_submission_ids_each_team.update(dict(df_submissions.groupby(\"TeamId\")[\"SubmissionId\"].apply(lambda x: sorted(x)[-last_n:])))\nlast_submission_ratings_each_team = defaultdict(list)\nlast_submission_ratings_each_team.update({team_id: [dict_submission_id_to_rating[sub_id] for sub_id in sub_ids] for team_id, sub_ids in last_submission_ids_each_team.items()})\ntop_teams_last_submission_ratings = []\nfor team in leaderboard_data[:max_rank]:\n    rank, score, team_id, team_name, n_agents = team[\"rank\"], team[\"score\"], team[\"teamId\"], team[\"teamName\"], team[\"entries\"]\n    ratings = last_submission_ratings_each_team[team_id]\n    top_teams_last_submission_ratings.append(ratings)\n    \n    plt.scatter(ratings, np.random.randn(len(ratings))*0.15+rank)\n    plt.annotate(f\"{rank:3d}  {team_name}  {score}  {n_agents}\", xy=(min_rating, rank), fontsize=20)\nplt.boxplot(top_teams_last_submission_ratings, vert=False)\nplt.xlim(min_rating, max_rating)\nplt.ylim(max_rank+1, 0)\nplt.xticks(list(range(min_rating, max_rating+100, 100)))\nplt.tick_params(labeltop=True)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Win rate (last 30 agents for each team)"},{"metadata":{},"cell_type":"markdown","source":"## last 30 vs last 30"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"top_n = 25\nlast_n = 30\n\nlast_submission_ids_each_team = dict(df_submissions.groupby(\"TeamId\")[\"SubmissionId\"].apply(lambda x: sorted(x)[-last_n:]))\n\nwins = np.zeros((top_n, top_n))\nloses = np.zeros((top_n, top_n))\ndraws = np.zeros((top_n, top_n))\ntop_team_ids = set(team[\"teamId\"] for team in leaderboard_data[:top_n])\ntarget_submission_ids = {sub_id for team_id, sub_ids in last_submission_ids_each_team.items() for sub_id in sub_ids if team_id in top_team_ids}\nit = df_episode_agents.itertuples()\nfor agent1, agent2 in zip(it, it):\n    assert agent1.EpisodeId == agent2.EpisodeId\n    if agent1.SubmissionId in target_submission_ids and agent2.SubmissionId in target_submission_ids:\n        team1, team2 = dict_submissions[agent1.SubmissionId][\"teamId\"], dict_submissions[agent2.SubmissionId][\"teamId\"]\n        idx1, idx2 = dict_team_id_to_team_rank[team1] - 1, dict_team_id_to_team_rank[team2] - 1\n        if (np.isnan(agent1.Reward) and np.isnan(agent2.Reward)) or agent1.Reward == agent2.Reward:\n            draws[idx1, idx2] += 1.0\n            draws[idx2, idx1] += 1.0\n        elif np.isnan(agent2.Reward) or agent1.Reward > agent2.Reward:\n            wins[idx1, idx2] += 1.0\n            loses[idx2, idx1] += 1.0\n        else:\n            loses[idx1, idx2] += 1.0\n            wins[idx2, idx1] += 1.0\n\nplt.figure(figsize=(24, 18))\nplt.imshow((wins + draws*0.5) / (wins + loses + draws), cmap=\"RdBu_r\", vmin=0, vmax=1)\nfor y in range(top_n):\n    for x in range(top_n):\n        plt.annotate(f\"{int(wins[y,x])}/{int(loses[y,x])}/{int(draws[y,x])}\", xy=(x, y), ha=\"center\", va=\"center\")\nteam_names = [team[\"teamName\"] for team in leaderboard_data[:top_n]]\nplt.xticks(np.arange(top_n), team_names, rotation=90)\nplt.yticks(np.arange(top_n), team_names)\nplt.xlabel(\"last 30 agents\")\nplt.ylabel(\"last 30 agents\")\nplt.tick_params(labeltop=True, labelright=True)\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## last 30 vs all"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"top_n = 25\nlast_n = 30\n\nall_submission_ids_each_team = dict(df_submissions.groupby(\"TeamId\")[\"SubmissionId\"].apply(lambda x: sorted(x)))\nlast_submission_ids_each_team = {team_id: sub_ids[-last_n:] for team_id, sub_ids in all_submission_ids_each_team.items()}\n\nwins = np.zeros((top_n, top_n))\nloses = np.zeros((top_n, top_n))\ndraws = np.zeros((top_n, top_n))\ntop_team_ids = set(team[\"teamId\"] for team in leaderboard_data[:top_n])\ntarget_submission_ids_1 = {sub_id for team_id, sub_ids in last_submission_ids_each_team.items() for sub_id in sub_ids if team_id in top_team_ids}\ntarget_submission_ids_2 = {sub_id for team_id, sub_ids in all_submission_ids_each_team.items() for sub_id in sub_ids if team_id in top_team_ids}\nit = df_episode_agents.itertuples()\nfor agent1_, agent2_ in zip(it, it):\n    assert agent1_.EpisodeId == agent2_.EpisodeId\n    for agent1, agent2 in [[agent1_, agent2_], [agent2_, agent1_]]:\n        if agent1.SubmissionId in target_submission_ids_1 and agent2.SubmissionId in target_submission_ids_2:\n            team1, team2 = dict_submissions[agent1.SubmissionId][\"teamId\"], dict_submissions[agent2.SubmissionId][\"teamId\"]\n            idx1, idx2 = dict_team_id_to_team_rank[team1] - 1, dict_team_id_to_team_rank[team2] - 1\n            if (np.isnan(agent1.Reward) and np.isnan(agent2.Reward)) or agent1.Reward == agent2.Reward:\n                draws[idx1, idx2] += 1.0\n            elif np.isnan(agent2.Reward) or agent1.Reward > agent2.Reward:\n                wins[idx1, idx2] += 1.0\n            else:\n                loses[idx1, idx2] += 1.0\n\nplt.figure(figsize=(24, 18))\nplt.imshow((wins + draws*0.5) / (wins + loses + draws), cmap=\"RdBu_r\", vmin=0, vmax=1)\nfor y in range(top_n):\n    for x in range(top_n):\n        plt.annotate(f\"{int(wins[y,x])}/{int(loses[y,x])}/{int(draws[y,x])}\", xy=(x, y), ha=\"center\", va=\"center\")\nteam_names = [team[\"teamName\"] for team in leaderboard_data[:top_n]]\nplt.xticks(np.arange(top_n), team_names, rotation=90)\nplt.yticks(np.arange(top_n), team_names)\nplt.xlabel(\"all agents\")\nplt.ylabel(\"last 30 agents\")\nplt.tick_params(labeltop=True, labelright=True)\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## last 30 vs rating"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"top_n = 100\nlast_n = 30\nn_classes = 25\nbin_size = 25\nmax_rating = (int(df_submissions[\"Rating\"].max()) // bin_size + 1) * bin_size\n\nall_submission_ids_each_team = dict(df_submissions.groupby(\"TeamId\")[\"SubmissionId\"].apply(lambda x: sorted(x)))\nlast_submission_ids_each_team = {team_id: sub_ids[-last_n:] for team_id, sub_ids in all_submission_ids_each_team.items()}\n\ndef rating_to_class(rating):\n    res = (max_rating - int(rating)) // bin_size\n    if res >= n_classes:\n        return n_classes - 1\n    return res\n\nwins = np.zeros((top_n, n_classes))\nloses = np.zeros((top_n, n_classes))\ndraws = np.zeros((top_n, n_classes))\ntop_team_ids = set(team[\"teamId\"] for team in leaderboard_data[:top_n])\ntarget_submission_ids_1 = {sub_id for team_id, sub_ids in last_submission_ids_each_team.items() for sub_id in sub_ids if team_id in top_team_ids}\nit = df_episode_agents.itertuples()\nfor agent1_, agent2_ in zip(it, it):\n    assert agent1_.EpisodeId == agent2_.EpisodeId\n    for agent1, agent2 in [[agent1_, agent2_], [agent2_, agent1_]]:\n        if agent1.SubmissionId in target_submission_ids_1:\n            team1 = dict_submissions[agent1.SubmissionId][\"teamId\"]\n            idx1, idx2 = dict_team_id_to_team_rank[team1] - 1, rating_to_class(dict_submission_id_to_rating[agent2.SubmissionId])\n            if (np.isnan(agent1.Reward) and np.isnan(agent2.Reward)) or agent1.Reward == agent2.Reward:\n                draws[idx1, idx2] += 1.0\n            elif np.isnan(agent2.Reward) or agent1.Reward > agent2.Reward:\n                wins[idx1, idx2] += 1.0\n            else:\n                loses[idx1, idx2] += 1.0\n\nplt.figure(figsize=(24, 80))\nplt.imshow((wins + draws*0.5) / (wins + loses + draws), cmap=\"RdBu_r\", vmin=0.0, vmax=1.0)\nfor y in range(top_n):\n    for x in range(n_classes):\n        text = f\"{int(wins[y,x])}/{int(loses[y,x])}/{int(draws[y,x])}\"\n        if len(text) >= 9:\n            text = f\"{int(wins[y,x])}/{int(loses[y,x])}\\n/{int(draws[y,x])}\"\n        plt.annotate(text, xy=(x, y), ha=\"center\", va=\"center\", ma=\"right\")\nteam_names = [team[\"teamName\"] for team in leaderboard_data[:top_n]]\nplt.xticks(np.arange(-0.5, n_classes, 1.0), np.arange(max_rating, max_rating-bin_size*n_classes, -bin_size))\nplt.yticks(np.arange(top_n), team_names)\nplt.xlabel(\"current rating\")\nplt.ylabel(\"last 30 agents\")\nplt.tick_params(labeltop=True, labelright=True)\nplt.colorbar(aspect=60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rating vs Submission date"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 70))\ncmap = plt.get_cmap(\"tab10\")\ndict_team_id_to_team_name = defaultdict(lambda: np.nan)\ndict_team_id_to_team_name.update({team[\"teamId\"]: team[\"teamName\"] for team in leaderboard_data})\n\nxlim = datetime(2020, 12, 9), datetime(2021, 2, 3)\nmax_rating = (int(df_submissions[\"Rating\"].max()) // 100 + 1) * 100\nmin_rating = max_rating - 1000\n\nfor team_id, group in groupby(sorted(dict_submissions.values(), key=lambda x: dict_team_id_to_team_rank[x[\"teamId\"]]), key=itemgetter(\"teamId\")):\n    rank = dict_team_id_to_team_rank[team_id]\n    if not 1 <= rank <= 100:\n        continue\n    plt.subplot(20, 5, rank)\n    plt.hlines(medal_thresholds, *xlim, medal_colors, linewidth=1.2, linestyles=\"solid\")\n    group = list(group)\n    group = [sub for sub in group if sub[\"status\"] != \"error\"]\n    rates = [dict_submission_id_to_rating[sub[\"id\"]] for sub in group]\n    sub_datetimes = [datetime.fromtimestamp(sub[\"dateSubmitted\"][\"seconds\"]) for sub in group]\n    plt.scatter(sub_datetimes, rates, s=10, c=cmap((rank-1)%10))\n    plt.xlim(*xlim)\n    plt.ylim(min_rating, max_rating)\n    team_name = dict_team_id_to_team_name[team_id]\n    plt.title(f\"{rank}  {team_name}\")\n    plt.gca().xaxis.set_major_locator(mdates.DayLocator(bymonthday=(1, 16)))\n    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n    plt.grid()\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top agents"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = df_submissions[df_submissions[\"Rating\"] >= 1350]\ndf.sort_values(\"Rating\", ascending=False, inplace=True)\ndf.reset_index(drop=True, inplace=True)\ndf[\"TeamName\"] = df[\"TeamId\"].map(dict_team_id_to_team_name)\ndf[\"Rank\"] = np.arange(1, len(df)+1)\n\ntop_n = 100\nlast_n = 30\nn_classes = 8\nbin_size = 100\nmax_rating = (int(df_submissions[\"Rating\"].max()) // bin_size + 1) * bin_size\n\nall_submission_ids_each_team = dict(df_submissions.groupby(\"TeamId\")[\"SubmissionId\"].apply(lambda x: sorted(x)))\nlast_submission_ids_each_team = {team_id: sub_ids[-last_n:] for team_id, sub_ids in all_submission_ids_each_team.items()}\n\ndef rating_to_class(rating):\n    res = (max_rating - int(rating)) // bin_size\n    if res >= n_classes:\n        return n_classes - 1\n    return res\n\ndict_submission_id_to_agent_rank = dict(df[[\"SubmissionId\", \"Rank\"]].values)\nn_targets = len(dict_submission_id_to_agent_rank)\nwins = np.zeros((n_targets, n_classes), dtype=np.int64)\nloses = np.zeros((n_targets, n_classes), dtype=np.int64)\ndraws = np.zeros((n_targets, n_classes), dtype=np.int64)\nit = df_episode_agents.itertuples()\nfor agent1_, agent2_ in zip(it, it):\n    assert agent1_.EpisodeId == agent2_.EpisodeId\n    for agent1, agent2 in [[agent1_, agent2_], [agent2_, agent1_]]:\n        if agent1.SubmissionId in dict_submission_id_to_agent_rank:\n            idx1, idx2 = dict_submission_id_to_agent_rank[agent1.SubmissionId] - 1, rating_to_class(dict_submission_id_to_rating[agent2.SubmissionId])\n            if (np.isnan(agent1.Reward) and np.isnan(agent2.Reward)) or agent1.Reward == agent2.Reward:\n                draws[idx1, idx2] += 1.0\n            elif np.isnan(agent2.Reward) or agent1.Reward > agent2.Reward:\n                wins[idx1, idx2] += 1.0\n            else:\n                loses[idx1, idx2] += 1.0\n\nwin_lose_draw_columns = []\nfor idx_classes in range(n_classes):\n    l = max_rating - idx_classes * bin_size\n    r = l - bin_size if idx_classes != n_classes - 1 else \"\"\n    df[f\"vs_{l}-{r}_win\"] = wins[:, idx_classes]\n    df[f\"vs_{l}-{r}_lose\"] = loses[:, idx_classes]\n    df[f\"vs_{l}-{r}_draw\"] = draws[:, idx_classes]\n    col = f\"vs_{l}-{r}\"\n    win_lose_draw_columns.append(col)\n    df[col] = df[f\"vs_{l}-{r}_win\"].astype(str) + \"/\" + df[f\"vs_{l}-{r}_lose\"].astype(str) + \"/\" + df[f\"vs_{l}-{r}_draw\"].astype(str)\n\ndef win_rate_gradient(s, cmap=\"PuBu\", low=0, high=0, text_color_threshold=0.408):\n    # https://github.com/pandas-dev/pandas/blob/v1.2.1/pandas/io/formats/style.py\n    \n    if (\n        not isinstance(text_color_threshold, (float, int))\n        or not 0 <= text_color_threshold <= 1\n    ):\n        msg = \"`text_color_threshold` must be a value from 0 to 1.\"\n        raise ValueError(msg)\n\n    with pd.io.formats.style._mpl(pd.io.formats.style.Styler.background_gradient) as (plt, colors):\n        smin = 0.0\n        smax = 1.0\n        rng = smax - smin\n        norm = colors.Normalize(smin - (rng * low), smax + (rng * high))\n        def to_rate(win_lose_draw):\n            w, l, d = map(np.float64, win_lose_draw.split(\"/\"))\n            rate = (w + d * 0.5 + 1e-100) / (w + l + d + 2e-100)\n            return rate\n        rgbas = plt.cm.get_cmap(cmap)(norm(np.vectorize(to_rate)(s)))\n\n        def relative_luminance(rgba):\n            r, g, b = (\n                x / 12.92 if x <= 0.03928 else ((x + 0.055) / 1.055 ** 2.4)\n                for x in rgba[:3]\n            )\n            return 0.2126 * r + 0.7152 * g + 0.0722 * b\n\n        def css(rgba):\n            dark = relative_luminance(rgba) < text_color_threshold\n            text_color = \"#f1f1f1\" if dark else \"#000000\"\n            return f\"background-color: {colors.rgb2hex(rgba)};color: {text_color};\"\n\n        if s.ndim == 1:\n            return [css(rgba) for rgba in rgbas]\n        else:\n            return pd.DataFrame(\n                [[css(rgba) for rgba in row] for row in rgbas],\n                index=s.index,\n                columns=s.columns,\n            )\n\npd.options.display.max_colwidth = 50\npd.options.display.expand_frame_repr = False\ndf.set_index(\"Rank\").reindex(columns=[\"Rating\", \"TeamName\", \"SubmissionDate\", \"SubmissionId\"] + win_lose_draw_columns) \\\n.style.format({\"Rating\": lambda x: f\"{x:7.2f}\",\n               \"SubmissionId\": lambda x: f'<a href=\"https://www.kaggle.com/c/santa-2020/leaderboard?dialog=episodes-submission-{x}\">{x}</a>',\n               \"SubmissionDate\": lambda x: x.strftime(\"%Y-%m-%d\")}) \\\n.apply(win_rate_gradient, subset=win_lose_draw_columns, cmap=\"RdBu_r\")\n#.set_properties(subset=win_lose_draw_columns, width=\"50px\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = df_submissions.copy()\nstep = 50\nmax_rating = (int(df_submissions[\"Rating\"].max()) // step + 1) * step\nmin_rating = 1000\nbin_columns = []\nfor r in range(max_rating, min_rating, -step):\n    col = f\"{r}-{r-step}\"\n    df[col] = (r-step <= df[\"Rating\"]) & (df[\"Rating\"] < r)\n    bin_columns.append(col)\ndf = df.groupby(\"TeamId\")[bin_columns].sum()\ndf.reset_index(inplace=True)\ndf[\"TeamRank\"] = df[\"TeamId\"].map(dict_team_id_to_team_rank)\ndf[\"TeamName\"] = df[\"TeamId\"].map(dict_team_id_to_team_name)\ndf.sort_values(\"TeamRank\", inplace=True)\ndf.reset_index(drop=True, inplace=True)\ndf = df.reindex(columns=[\"TeamRank\", \"TeamId\", \"TeamName\", *bin_columns])\ndf = df[df[bin_columns].sum(1) >= 1]\ndf.set_index(\"TeamRank\", inplace=True)\ndf.style.background_gradient(cmap=\"OrRd\", axis=None, subset=bin_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Wooden spoon"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_submissions[\"TeamName\"] = df_submissions[\"TeamId\"].map(dict_team_id_to_team_name)\ndf_submissions.sort_values(\"Rating\", ascending=False).tail(10).reset_index(drop=True).reindex(columns=[\"Rating\", \"TeamName\", \"SubmissionId\"]).style.format({\"Rating\": lambda x: f\"{x:7.2f}\", \"SubmissionId\": lambda x: f'<a href=\"https://www.kaggle.com/c/santa-2020/leaderboard?dialog=episodes-submission-{x}\">{x}</a>'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LB progress"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = df_episodes[df_episodes[\"CompetitionId\"]==SANTA2020_COMPETITION_ID]\ndf.sort_values(\"EndTime\", inplace=True)\ndf.reset_index(drop=True, inplace=True)\nfor agent_index in range(2):\n    df_agents = df_episode_agents[df_episode_agents[\"Index\"]==agent_index]\n    df_agents.set_index(\"EpisodeId\", inplace=True)\n    df[f\"Agent{agent_index}SubmissionId\"] = df[\"Id\"].map(df_agents[\"SubmissionId\"])\n    df[f\"Agent{agent_index}UpdatedScore\"] = df[\"Id\"].map(df_agents[\"UpdatedScore\"])\ndf","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm\nfrom heapq import heappush, heappop\n\nteam_data = {\n    team_id: {\n        \"dict_submission_id_to_rating\": {},\n        \"heap_ratings\": [],\n        \"counter_to_remove_from_heap\": Counter(),\n        \"max_rating_trajectory\": [],\n    } for team_id in dict_teams\n}\nfor end_time, a0_sub_id, a0_score, a1_sub_id, a1_score in tqdm(zip(df[\"EndTime\"].dt.to_pydatetime(), df[\"Agent0SubmissionId\"].values, df[\"Agent0UpdatedScore\"].values, df[\"Agent1SubmissionId\"].values, df[\"Agent1UpdatedScore\"].values), total=len(df)):\n    for sub_id, score in [[a0_sub_id, a0_score], [a1_sub_id, a1_score]]:\n        if sub_id not in dict_submissions:\n            continue\n        team_id = dict_submissions[sub_id][\"teamId\"]\n        if team_id not in team_data:\n            continue\n        team_dat = team_data[team_id]\n        heap_ratings = team_dat[\"heap_ratings\"]\n        counter_to_remove_from_heap = team_dat[\"counter_to_remove_from_heap\"]\n        dict_submission_id_to_rating = team_dat[\"dict_submission_id_to_rating\"]\n        max_rating_trajectory = team_dat[\"max_rating_trajectory\"]\n        if sub_id not in dict_submission_id_to_rating:\n            dict_submission_id_to_rating[sub_id] = score\n            heappush(heap_ratings, -score)\n        else:\n            old_score = dict_submission_id_to_rating[sub_id]\n            counter_to_remove_from_heap[old_score] += 1\n            while len(heap_ratings) > 0 and -heap_ratings[0] in counter_to_remove_from_heap:\n                max_score = -heap_ratings[0]\n                if counter_to_remove_from_heap[max_score] == 1:\n                    del counter_to_remove_from_heap[max_score]\n                else:\n                    counter_to_remove_from_heap[max_score] -= 1\n                heappop(heap_ratings)\n            \n            dict_submission_id_to_rating[sub_id] = score\n            heappush(heap_ratings, -score)\n        max_score = -heap_ratings[0]\n        if len(max_rating_trajectory) == 0 or max_score != max_rating_trajectory[-1][0]:\n            max_rating_trajectory.append((max_score, end_time))\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# from bisect import insort\n# all_trajectories = []\n# for team_id, team_dat in team_data.items():\n#     for score, end_time in team_dat[\"max_rating_trajectory\"]:\n#         all_trajectories.append((team_id, score, end_time))\n# all_trajectories.sort(key=itemgetter(end_time))\n# top_teams = []\n# for team_id, score, end_time in all_trajectories:\n#     if top_teams.append(())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objects as go\nfig = go.Figure()\nfig.update_layout(autosize=False, width=1500, height=800)\nfor team_id, team_dat in team_data.items():\n    max_rating_trajectory = team_dat[\"max_rating_trajectory\"]\n    if len(max_rating_trajectory) == 0:\n        continue\n    xs = []\n    ys = []\n    for y, x in max_rating_trajectory:\n        ys.extend([y, y])\n        xs.extend([x, x])\n    del xs[0]\n    xs.append(datetime.now())\n    if max(ys) < 1350:\n        continue\n    team_name = dict_team_id_to_team_name[team_id]\n    fig.add_trace(go.Scatter(x=xs, y=ys, name=team_name))\niplot(fig)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}