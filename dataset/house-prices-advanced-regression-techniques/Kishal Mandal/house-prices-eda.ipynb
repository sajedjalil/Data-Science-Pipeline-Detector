{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n    horizontal-align: middle;\n}\nimg[alt=Real-Estate-Slideshow-Presentation]{\n    width:  800px;\n    height: 400px;\n    text-align: center;\n    vertical-align: middle;\n    horizontal-align: middle;\n}\nimg[alt=THANKS]{\n    width:  800px;\n    height: 400px;\n    text-align: center;\n    vertical-align: middle;\n    horizontal-align: middle;\n}\nh1,h2 {\n    text-align: center;\n    background-color: #A0988E;\n    padding: 20px;\n    margin: 0;\n    color: white;\n    font-family: ariel;\n    border-radius: 80px\n}\n\nh3 {\n    text-align: center;\n    border-style: solid;\n    border-width: 3px;\n    padding: 12px;\n    margin: 0;\n    color: black;\n    font-family: ariel;\n    border-radius: 80px;\n    border-color: #F0F0F0;\n}\n\nbody, p {\n    font-family: ariel;\n    font-size: 20px;\n    color: charcoal;\n}\ndiv {\n    font-size: 20px;\n    margin: 0;\n\n}\n\nh4 {\n    padding: 0px;\n    margin: 0;\n    font-family: ariel;\n    color: #A0988E;\n}\n</style>\n\"\"\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T15:07:01.199129Z","iopub.execute_input":"2021-12-14T15:07:01.199718Z","iopub.status.idle":"2021-12-14T15:07:01.206573Z","shell.execute_reply.started":"2021-12-14T15:07:01.199681Z","shell.execute_reply":"2021-12-14T15:07:01.205748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style='color:#fff'>House Prices EDA - The only EDA you will need.</span>\n\n<span style='color:#654321'>Data needs to be visualised. It's hard to judge the behaviour of the data just from the values. There are many ways to visualise the data and that fits according to the problem. Some of them are checking the distribution, checking for outliers, correlation between the variables, etc. \n\n<span style='color:#654321'>Here I have shown, some t-SNE plots also, just for the aesthetics üò¨. And followed by sole violin plots, distribution plots, correlation matrix. Filled up the missing data with the mean.\n\n<span style='color:#654321'>Note: I have not done any feature engineering here, neither did I encode the categorial varibles. This is just an EDA notebook which is visually soothing üôÇ </span>","metadata":{}},{"cell_type":"markdown","source":"![Real-Estate-Slideshow-Presentation](https://user-images.githubusercontent.com/74188336/146017303-899f35cf-40d2-456e-846e-9f14c5704303.jpeg)","metadata":{}},{"cell_type":"markdown","source":"## <span style='color:#fff'>About this notebook. </span>\n\n<span style='color:#654321'>In this notebook, I have show some exploratory data analysis of the variables (continous as well as categorical). No feature engineering has been done. \n\n<span style='color:#654321'>No one likes to read a loooooooong notebook. So kept it short with just EDA.\n\n<span style='color:#654321'>If this notebook gets some attention I will come up with some Gradient Boosting Methods and maybe some Neural Nets using PyTorch. \n\n<span style='color:#654321'>If you like this notebook and got to learn something an Upvote will be appreciated. And any feedback will be helpful üòÉ","metadata":{}},{"cell_type":"markdown","source":"## <span style='color:#fff'>Contents:</span>\n\n### <span style='color:#654321'>1. t-SNE plots (for the aesthetics) üò¨ </span>\n### <span style='color:#654321'>2. Histograms and stuff üìä</span>\n### <span style='color:#654321'>3. Correlation Matrix üåü</span>\n### <span style='color:#654321'>4. Some violin plots..... üéª</span>\n### <span style='color:#654321'>5. Distribution of the variables (Scaled down for comparison) üê¢</span>","metadata":{}},{"cell_type":"markdown","source":"#### <span style='color:#654321'>Separating the non-categorical variables\n\n<span style='color:#654321'>This dataset has categorical as well as non categorical variables. Let us separate the non-categorical variables for the t-SNE plots.\n\n<span style='color:#654321'>Separating is fairly easy. Any variable that is not of the `object` dtype is considered as non-categorical variable here","metadata":{}},{"cell_type":"code","source":"import cudf\nimport cuml\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom cuml.manifold import TSNE\nimport matplotlib.pyplot as plt\nsns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n\ntrain_data = cudf.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n\ndf = train_data.to_pandas()\n\nprint('-'*50)\nprint('NON-CATEGORICAL VARIABLES')\nprint('-'*50)\nnon_categorical_cols = []\ncolumns = df.columns\nfor col in columns:\n    if df[col].dtype != 'object':\n        non_categorical_cols.append(col)\nprint('\\n'.join(non_categorical_cols))\n\ndf_non_cat = df[non_categorical_cols]\ndf_cat = df[[x for x in columns if x not in non_categorical_cols]]\n\ntsnedf = cudf.from_pandas(df_non_cat)\ntsnedf = tsnedf.fillna(tsnedf.mean())\n# tsnedf = cudf.concat([tsnedf]*10)\ntsne    = TSNE(n_components=2, perplexity=6, learning_rate=2, random_state=101)\ntsne_2D = tsne.fit_transform(tsnedf);\nx1, y1 = tsne_2D.as_matrix().T","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T14:54:49.479849Z","iopub.execute_input":"2021-12-14T14:54:49.48033Z","iopub.status.idle":"2021-12-14T14:54:55.696597Z","shell.execute_reply.started":"2021-12-14T14:54:49.480291Z","shell.execute_reply":"2021-12-14T14:54:55.695846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style='color:#fff'>1. t-SNE plots (for the aesthetics) üò¨</span>","metadata":{}},{"cell_type":"markdown","source":"<span style='color:#654321'>t-distributed stochastic neighbor embedding (t-SNE) is a statistical method for visualizing high-dimensional data by giving each datapoint a location in a two or three-dimensional map.\n\n<span style='color:#654321'>Though for this I have not really used for data analysis. But rather for the aesthetics üéÉ","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 20))\nax.scatter(x1, y1, s=2, c=x1**2+y1**2, cmap=plt.cm.cool)\nfig.set_facecolor('#000') #ebf0ff\nplt.xticks([])\nplt.yticks([])\nplt.box(False)\nplt.savefig('foo.png')\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T15:18:19.158015Z","iopub.execute_input":"2021-12-14T15:18:19.160473Z","iopub.status.idle":"2021-12-14T15:18:19.509881Z","shell.execute_reply.started":"2021-12-14T15:18:19.160433Z","shell.execute_reply":"2021-12-14T15:18:19.509098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#654321'>Seems like a galaxy eh?","metadata":{}},{"cell_type":"code","source":"tsne    = TSNE(n_components=2, perplexity=14, learning_rate=5, random_state=101)\ntsne_2D = tsne.fit_transform(tsnedf);\nx2, y2 = tsne_2D.as_matrix().T\nfig, ax = plt.subplots(figsize=(20, 20))\nax.scatter(x2, y2, s=2, c=x2**2+y2**2, cmap=plt.cm.Pastel1)\nfig.set_facecolor('#252C2C') #ebf0ff\nplt.xticks([])\nplt.yticks([])\nplt.box(False)\nplt.savefig('foo1.png')\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T15:18:11.836043Z","iopub.execute_input":"2021-12-14T15:18:11.836319Z","iopub.status.idle":"2021-12-14T15:18:12.965477Z","shell.execute_reply.started":"2021-12-14T15:18:11.836286Z","shell.execute_reply":"2021-12-14T15:18:12.964567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#654321'>What do you think?","metadata":{}},{"cell_type":"code","source":"tsne    = TSNE(n_components=2, perplexity=30, learning_rate=5, random_state=101)\ntsne_2D = tsne.fit_transform(tsnedf);\nx3, y3 = tsne_2D.as_matrix().T\nfig, ax = plt.subplots(figsize=(20, 20))\nax.scatter(x3, y3, s=2, c=x3**2+y3**2, cmap=plt.cm.Reds)\nfig.set_facecolor('black') #ebf0ff\nplt.xticks([])\nplt.yticks([])\nplt.box(False)\nplt.savefig('foo2.png')\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T15:18:05.35762Z","iopub.execute_input":"2021-12-14T15:18:05.357908Z","iopub.status.idle":"2021-12-14T15:18:06.4533Z","shell.execute_reply.started":"2021-12-14T15:18:05.357878Z","shell.execute_reply":"2021-12-14T15:18:06.452644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#654321'> The shapes change as we change the perplexity ü§Ø","metadata":{}},{"cell_type":"code","source":"tsne    = TSNE(n_components=2, perplexity=50, learning_rate=10, random_state=101)\ntsne_2D = tsne.fit_transform(tsnedf);\nx4, y4 = tsne_2D.as_matrix().T\nfig, ax = plt.subplots(figsize=(20, 20))\nax.scatter(x4, y4, s=2, c=x4**2+y4**2, cmap=plt.cm.cool)\nfig.set_facecolor('#ebf0ff') #ebf0ff\nplt.xticks([])\nplt.yticks([])\nplt.box(False)\nplt.savefig('foo3.png')\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T14:54:58.574976Z","iopub.execute_input":"2021-12-14T14:54:58.575253Z","iopub.status.idle":"2021-12-14T14:54:58.751738Z","shell.execute_reply.started":"2021-12-14T14:54:58.575216Z","shell.execute_reply":"2021-12-14T14:54:58.750981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#654321'>Seems like an **M**, doesn't it?","metadata":{}},{"cell_type":"code","source":"tsne    = TSNE(n_components=2, perplexity=80, learning_rate=10, random_state=101)\ntsne_2D = tsne.fit_transform(tsnedf);\nx5, y5 = tsne_2D.as_matrix().T\nfig, ax = plt.subplots(figsize=(20, 20))\nax.scatter(x5, y5, s=2, c=y5, cmap=plt.cm.gist_rainbow)\nfig.set_facecolor('#000') #ebf0ff\nplt.xticks([])\nplt.yticks([])\nplt.box(False)\nplt.savefig('foo4.png')\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T14:54:59.527018Z","iopub.execute_input":"2021-12-14T14:54:59.527298Z","iopub.status.idle":"2021-12-14T14:54:59.702435Z","shell.execute_reply.started":"2021-12-14T14:54:59.527266Z","shell.execute_reply":"2021-12-14T14:54:59.701685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style='color:#654321'>A horse shoe üê¥","metadata":{}},{"cell_type":"markdown","source":"#### <span style='color:#654321'> The t-SNE plots are pretty amazing. Interesting to look at. These are more widely used to visualise high dimensional data, like this one. (Has 81 columns in total üò±)","metadata":{}},{"cell_type":"markdown","source":"## <span style='color:#fff'>2. Histograms and stuff üìä</span>","metadata":{}},{"cell_type":"markdown","source":"<span style='color:#654321'>For the visualisation of the data for each category, I have plotted these histograms. The y-axis is the count and the x-axis are the values of the variables. Histograms are really helpful when the data points are discrete.\n\n<span style='color:#654321'>But here I have plotted for all the variables","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(27, 3, figsize=(18, 160))\nidx = 1\nfor i in range(27):\n    for j in range(3):\n        if i==27 and j==3:\n            continue\n        try:\n        \n            sns.histplot(df[columns[idx]].value_counts().values, ax=axes[i, j]).set_title(columns[idx])\n            \n        except Exception as e:\n            pass\n        idx+=1\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T14:54:59.703955Z","iopub.execute_input":"2021-12-14T14:54:59.704249Z","iopub.status.idle":"2021-12-14T14:56:08.276812Z","shell.execute_reply.started":"2021-12-14T14:54:59.704202Z","shell.execute_reply":"2021-12-14T14:56:08.275976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style='color:#654321'>Some plots are blank. That means the data is sparse and does not show p in the y-axis. Maybe it has a wide range of distribution with very less repetitions.\n\n<span style='color:#654321'>Anyways histograms are good to visualise the categorical and discrete variables üòÉ","metadata":{}},{"cell_type":"markdown","source":"## <span style='color:#fff'>3. Correlation Matrix üåü</span>","metadata":{}},{"cell_type":"markdown","source":"<span style='color:#654321'>To see the interaction of the variables with other variables, and the effect of one variable on another, we use the **so-called** correlation matrix. Any values more than 0.8 or 0.9, those variables are considered to be highly correlated.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(df_non_cat.corr(), annot=True, linewidths=.5, ax=ax, cbar=False, cmap=plt.cm.copper_r)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T15:35:00.783507Z","iopub.execute_input":"2021-12-14T15:35:00.783864Z","iopub.status.idle":"2021-12-14T15:35:07.131556Z","shell.execute_reply.started":"2021-12-14T15:35:00.783822Z","shell.execute_reply":"2021-12-14T15:35:07.13085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style='color:#654321'>The darker the color, higher is the correlation :)","metadata":{}},{"cell_type":"markdown","source":"##  <span style='color:#fff'>4. Some violin plots..... üéª</span>","metadata":{}},{"cell_type":"markdown","source":"<span style='color:#654321'>Violin-plot. Hmmm.....\n    \n<span style='color:#654321'>The name is fancy huh? Ain't it mate?\n\n<span style='color:#654321'>Well, Violin plots are basically distribution plots for continuous as well as discrete variables. For discrete variables the plots show up as stepped plots. \n","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=27, cols=3)\nidx=1\ncolumns = df.columns\nfor i in range(27):\n    for j in range(3):\n        try:\n            fig.add_trace(go.Violin(y=df[columns[idx]], box_visible=False, line_color='black',\n                                    meanline_visible=True, fillcolor='pink', opacity=0.6, showlegend=False,\n                                    x0=columns[idx], name='Not Potable', hoverinfo='skip'), row=i+1, col=j+1)\n            fig.update_yaxes(showgrid=False, zeroline=False)\n            idx+=1\n        except Exception:\n            pass\n\nfig.update_traces(meanline_visible=False)\nfig.update_layout(height=6000, width=1200, \n                  title_text=\"Distribution of Features (Violin Plot)\", template='ggplot2')\n\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T14:56:15.642113Z","iopub.execute_input":"2021-12-14T14:56:15.642645Z","iopub.status.idle":"2021-12-14T14:56:21.032216Z","shell.execute_reply.started":"2021-12-14T14:56:15.642586Z","shell.execute_reply":"2021-12-14T14:56:21.030747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style='color:#654321'>We can also see the outliers here. Removing outliers are crucial to build a good model. Outliers throw the model in some different direction which indeed confuses the model. Removing them gives better and more stable results","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom plotly.colors import n_colors","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T14:56:21.033531Z","iopub.execute_input":"2021-12-14T14:56:21.034457Z","iopub.status.idle":"2021-12-14T14:56:21.044365Z","shell.execute_reply.started":"2021-12-14T14:56:21.034414Z","shell.execute_reply":"2021-12-14T14:56:21.043407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\ndf_scaled = sc.fit_transform(df_non_cat)\ndf_scaled = pd.DataFrame(df_scaled, columns = df_non_cat.columns)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T14:56:21.046201Z","iopub.execute_input":"2021-12-14T14:56:21.046479Z","iopub.status.idle":"2021-12-14T14:56:21.066295Z","shell.execute_reply.started":"2021-12-14T14:56:21.046445Z","shell.execute_reply":"2021-12-14T14:56:21.065459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style='color:#fff'>5. Distribution of the variables (Scaled down for comparison) üê¢</span>","metadata":{}},{"cell_type":"markdown","source":"<span style='color:#654321'>Now let's compare the distribution of the variables by scaling them down so that we can compare them on a single graph. Also scaling down is required for some models so that some high valued variable does not overwhelm the small valued variables.</span>\n    \n### <span style='color:#A0988E'>This is my <i style='color:white; background-color:#A0988E'>most liked</i> plot. </span>\n\n<span style='color:#654321'>This single plot has so much to tell. A single plot to see the distribution of all the data rather than going through all the violin plots. (Though violin plots have their own advantages like plottinh the outliers)","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\ncolumns = df_scaled.columns\ncolors = n_colors('rgb(5, 200, 200)', 'rgb(0, 0, 139)', df_scaled.shape[1], colortype='rgb')\nfor idx, color in enumerate(colors):\n    if idx==0:\n        continue\n    fig.add_trace(go.Violin(x=df_scaled[columns[idx]]+idx/2, line_color=color, name=columns[idx], showlegend=False, hoverinfo='skip'))\n\nfig.update_traces(orientation='h', side='positive', width=2.5, points=False)\nfig.update_layout(yaxis_showgrid=False, xaxis_zeroline=False, template='ggplot2', title_text='Distribution of features (non-categorical)', height=800)\nfig.update_xaxes(showticklabels=False, title='', showgrid=False, range=[-3,23])\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-14T15:12:47.418027Z","iopub.execute_input":"2021-12-14T15:12:47.418624Z","iopub.status.idle":"2021-12-14T15:12:47.534145Z","shell.execute_reply.started":"2021-12-14T15:12:47.418566Z","shell.execute_reply":"2021-12-14T15:12:47.533275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style='color:#654321'>Hmmmmm..... Interesting.\n    \n<span style='color:#654321'>We can see that many variables are highly skewed. Also variables like `YearBuilt` have stepped distributions. It means they are categorical variables. same for `YearSold`. We can decide onto which variables to take for some feature engineering. The `YearBuilt` and `YearSold` can be converted into `AgeOfTheHouse` and many more. \n    \n<span style='color:#654321'>It is really important to visualise the data and see which variables are more important than the others. And lesser the dimension, simpler is the model.\n    \n<span style='color:#654321'> If this notebook gets enough upvotes I will be building a baseline model with feature engineering done in it. ","metadata":{}},{"cell_type":"markdown","source":"## <span style='color:#fff'>THANKS</span>\n\n![THANKS](https://user-images.githubusercontent.com/74188336/146017864-2b153a82-bd71-4ce9-b0e4-1a42752e6f8a.jpeg)","metadata":{}}]}