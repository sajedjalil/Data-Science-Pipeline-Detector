{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![width = 500](https://ctp-media.imigino.com/image/1/process/nullxnull?source=https://d3cx3ub94vxukq.cloudfront.net/wp-content/uploads/sites/30/2018/06/The-Tembisan-Gauteng-property-market-showing-signs-of-early-recovery.jpeg)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-02T13:56:56.173362Z","iopub.execute_input":"2021-08-02T13:56:56.17384Z","iopub.status.idle":"2021-08-02T13:56:57.071474Z","shell.execute_reply.started":"2021-08-02T13:56:56.173746Z","shell.execute_reply":"2021-08-02T13:56:57.070638Z"}}},{"cell_type":"markdown","source":"# House Price Prediction using diffrent regression methods\n* EDA \n* Data preparation and Feature Engineering \n    * outliers\n    * missing data\n    * categorical data\n* Liniear regression\n* Polynomial regression\n* L1 regression \n* L2 regression\n* Elastic Net\n* Conclusion","metadata":{}},{"cell_type":"markdown","source":"# 游늵 Data Gathering and EDA","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:25.880365Z","iopub.execute_input":"2021-08-04T11:43:25.880751Z","iopub.status.idle":"2021-08-04T11:43:26.057891Z","shell.execute_reply.started":"2021-08-04T11:43:25.880721Z","shell.execute_reply":"2021-08-04T11:43:26.056489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\ndf_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:26.059714Z","iopub.execute_input":"2021-08-04T11:43:26.060047Z","iopub.status.idle":"2021-08-04T11:43:26.195653Z","shell.execute_reply.started":"2021-08-04T11:43:26.060018Z","shell.execute_reply":"2021-08-04T11:43:26.194381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:26.197768Z","iopub.execute_input":"2021-08-04T11:43:26.198173Z","iopub.status.idle":"2021-08-04T11:43:26.327802Z","shell.execute_reply.started":"2021-08-04T11:43:26.198139Z","shell.execute_reply":"2021-08-04T11:43:26.326132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:26.329597Z","iopub.execute_input":"2021-08-04T11:43:26.329941Z","iopub.status.idle":"2021-08-04T11:43:26.365339Z","shell.execute_reply.started":"2021-08-04T11:43:26.329911Z","shell.execute_reply":"2021-08-04T11:43:26.364091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.drop(\"Id\", axis = 1, inplace = True)\ndf_test.drop(\"Id\", axis = 1, inplace = True)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:26.366972Z","iopub.execute_input":"2021-08-04T11:43:26.367413Z","iopub.status.idle":"2021-08-04T11:43:26.409788Z","shell.execute_reply.started":"2021-08-04T11:43:26.367371Z","shell.execute_reply":"2021-08-04T11:43:26.408685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:26.411091Z","iopub.execute_input":"2021-08-04T11:43:26.411373Z","iopub.status.idle":"2021-08-04T11:43:26.418564Z","shell.execute_reply.started":"2021-08-04T11:43:26.411346Z","shell.execute_reply":"2021-08-04T11:43:26.417406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## what we're gonna do is first take a look at what we're predicting! That would be the SalePrice. So let's see what we got. :)","metadata":{}},{"cell_type":"code","source":"sns.histplot(df_train['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:26.420074Z","iopub.execute_input":"2021-08-04T11:43:26.420363Z","iopub.status.idle":"2021-08-04T11:43:26.819883Z","shell.execute_reply.started":"2021-08-04T11:43:26.420336Z","shell.execute_reply":"2021-08-04T11:43:26.819064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:26.822292Z","iopub.execute_input":"2021-08-04T11:43:26.822667Z","iopub.status.idle":"2021-08-04T11:43:27.030056Z","shell.execute_reply.started":"2021-08-04T11:43:26.822637Z","shell.execute_reply":"2021-08-04T11:43:27.028622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target variable is right skewed. To make it more like a normal distro with assign a log function to it because especially linear models like normal distributions.","metadata":{}},{"cell_type":"code","source":"df_train[\"SalePrice\"] = np.log1p(df_train[\"SalePrice\"])\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:27.032629Z","iopub.execute_input":"2021-08-04T11:43:27.032981Z","iopub.status.idle":"2021-08-04T11:43:27.24731Z","shell.execute_reply.started":"2021-08-04T11:43:27.032947Z","shell.execute_reply":"2021-08-04T11:43:27.246449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The skew seems now corrected and the data appears more normally distributed.","metadata":{}},{"cell_type":"code","source":"df_train_cor = df_train.corr()\ndf_train_cor[df_train_cor['PoolArea']>0.7]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:27.248717Z","iopub.execute_input":"2021-08-04T11:43:27.24937Z","iopub.status.idle":"2021-08-04T11:43:27.286872Z","shell.execute_reply.started":"2021-08-04T11:43:27.249322Z","shell.execute_reply":"2021-08-04T11:43:27.285869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_train.GarageYrBit.astype('float64')\nsns.scatterplot(data=df_train, x ='YearBuilt', y='GarageYrBlt')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:27.288041Z","iopub.execute_input":"2021-08-04T11:43:27.288499Z","iopub.status.idle":"2021-08-04T11:43:27.685703Z","shell.execute_reply.started":"2021-08-04T11:43:27.288459Z","shell.execute_reply":"2021-08-04T11:43:27.684974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Now let's take look at our categorical features.","metadata":{}},{"cell_type":"code","source":"var = 'OverallQual'\ndata = pd.concat([df_train['SalePrice'], df_train['OverallQual']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=df_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:27.686999Z","iopub.execute_input":"2021-08-04T11:43:27.687327Z","iopub.status.idle":"2021-08-04T11:43:28.064457Z","shell.execute_reply.started":"2021-08-04T11:43:27.687281Z","shell.execute_reply":"2021-08-04T11:43:28.063403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Up to now we just kept going after our gut to find the corrolations! we can take a look at all corrolations with df.corr. But I preffer to find them by a heatplot because it's graphical and instead of numbers we can find them by colors.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T07:16:03.951301Z","iopub.execute_input":"2021-07-24T07:16:03.951686Z","iopub.status.idle":"2021-07-24T07:16:03.958501Z","shell.execute_reply.started":"2021-07-24T07:16:03.951653Z","shell.execute_reply":"2021-07-24T07:16:03.956918Z"}}},{"cell_type":"code","source":"corrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(13, 9))\nsns.heatmap(corrmat, vmax=.9, square=True,cmap=\"YlGnBu\");","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:28.065849Z","iopub.execute_input":"2021-08-04T11:43:28.066146Z","iopub.status.idle":"2021-08-04T11:43:29.394261Z","shell.execute_reply.started":"2021-08-04T11:43:28.066117Z","shell.execute_reply":"2021-08-04T11:43:29.3932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Find the dark blues. They show us big corrolations. The relation that our intuition told us was true. Look at the SalePrice on axis X and OverallQual on the Y axis. Yep that's dark dark blue. Besides two other thing got my attention. First it's the relation between GrLiveArea and TotRmsAbvGrd. Second intersting relation is GarageYrBit and YearBuilt.","metadata":{}},{"cell_type":"markdown","source":"To be sure about our corrolations we'll use scatterplots. Because we have a lot of features we will choose noncategorical features that we think they may have some corrolations with one another.","metadata":{}},{"cell_type":"code","source":"cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nplt.figure(figsize=(6,4),dpi=150)\nsns.pairplot(df_train[cols], size = 2.5)\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:29.39553Z","iopub.execute_input":"2021-08-04T11:43:29.39593Z","iopub.status.idle":"2021-08-04T11:43:40.477209Z","shell.execute_reply.started":"2021-08-04T11:43:29.395894Z","shell.execute_reply":"2021-08-04T11:43:40.476361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have a linear regression between GrLiveArea and ToralBsmtSF and we can see a nice positive corrolation between SalesPrice and GrLiveArea. Also realtion between SalePrice and YearBuilt can make us think!(kinda exponential regression)","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering and Data Prepration\nWe have three issues to deal with:\n1. Outliers\n2. Missing Data\n3. Categorical Data \n","metadata":{"execution":{"iopub.status.busy":"2021-08-02T10:26:26.608693Z","iopub.execute_input":"2021-08-02T10:26:26.609094Z","iopub.status.idle":"2021-08-02T10:26:27.009216Z","shell.execute_reply.started":"2021-08-02T10:26:26.609055Z","shell.execute_reply":"2021-08-02T10:26:27.00833Z"}}},{"cell_type":"markdown","source":"# Outliers ","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x = 'OverallQual', y= 'SalePrice', data = df_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:40.478544Z","iopub.execute_input":"2021-08-04T11:43:40.478843Z","iopub.status.idle":"2021-08-04T11:43:40.700363Z","shell.execute_reply.started":"2021-08-04T11:43:40.4788Z","shell.execute_reply":"2021-08-04T11:43:40.699264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x = 'GrLivArea', y= 'SalePrice', data = df_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:40.70204Z","iopub.execute_input":"2021-08-04T11:43:40.702472Z","iopub.status.idle":"2021-08-04T11:43:40.927887Z","shell.execute_reply.started":"2021-08-04T11:43:40.702424Z","shell.execute_reply":"2021-08-04T11:43:40.926623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the first plot we can see that two points in the 10th bar that are being soled with low prices and we can say these two points are probably our outliers. In the second plot we see two points for GrLivArea that are highly off-priced. we can assume that these two points in the first and second plot are the same.","metadata":{}},{"cell_type":"code","source":"df_train[(df_train['SalePrice']<12.5) & (df_train['OverallQual'] > 8) & (df_train['GrLivArea']>4000)]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:40.929279Z","iopub.execute_input":"2021-08-04T11:43:40.929701Z","iopub.status.idle":"2021-08-04T11:43:40.962547Z","shell.execute_reply.started":"2021-08-04T11:43:40.929664Z","shell.execute_reply":"2021-08-04T11:43:40.961855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We found them. these are the two points that will really screw up our regression. Obviously we can not check all the features one by one in order to find outliers. The corrolations hepled us to find the most corrolative features wich are OverallQual and GrLivArea and by checking them we found two points that will really screw our prediction up.","metadata":{}},{"cell_type":"code","source":"dropouts = df_train[(df_train['SalePrice']<12.5) & (df_train['OverallQual'] > 8) & (df_train['GrLivArea']>4000)]\ndf_train = df_train.drop(df_train[(df_train['SalePrice']<12.5) & (df_train['OverallQual'] > 8) & (df_train['GrLivArea']>4000)].index)\nsns.scatterplot(x = 'GrLivArea', y= 'SalePrice', data = df_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:40.963448Z","iopub.execute_input":"2021-08-04T11:43:40.963695Z","iopub.status.idle":"2021-08-04T11:43:41.188453Z","shell.execute_reply.started":"2021-08-04T11:43:40.963671Z","shell.execute_reply":"2021-08-04T11:43:41.187371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'There are {df_train.isnull().sum().sum()} missing values')\ndf_train.isnull().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.189679Z","iopub.execute_input":"2021-08-04T11:43:41.190214Z","iopub.status.idle":"2021-08-04T11:43:41.219702Z","shell.execute_reply.started":"2021-08-04T11:43:41.190174Z","shell.execute_reply":"2021-08-04T11:43:41.218669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's concatinate the train and test data, because the data preparation such as data missing procedure must apply on both train and test data.","metadata":{}},{"cell_type":"code","source":"df = df_train\ny = df[\"SalePrice\"]\ndf.drop(['SalePrice'], axis=1, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.221283Z","iopub.execute_input":"2021-08-04T11:43:41.221923Z","iopub.status.idle":"2021-08-04T11:43:41.259104Z","shell.execute_reply.started":"2021-08-04T11:43:41.221874Z","shell.execute_reply":"2021-08-04T11:43:41.257999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing Data","metadata":{}},{"cell_type":"code","source":"df.isnull().sum().sort_values(ascending = False).head(20)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.260303Z","iopub.execute_input":"2021-08-04T11:43:41.260788Z","iopub.status.idle":"2021-08-04T11:43:41.277291Z","shell.execute_reply.started":"2021-08-04T11:43:41.260738Z","shell.execute_reply":"2021-08-04T11:43:41.276129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* PoolQC: data description says NA means \"No Pool\". Ok then it's reasonable to fill the NA by None beacause majority of houses have no pool.","metadata":{}},{"cell_type":"code","source":"df[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.281479Z","iopub.execute_input":"2021-08-04T11:43:41.28181Z","iopub.status.idle":"2021-08-04T11:43:41.287403Z","shell.execute_reply.started":"2021-08-04T11:43:41.281778Z","shell.execute_reply":"2021-08-04T11:43:41.286511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* MiscFeature : data description says NA means \"no misc feature\"","metadata":{}},{"cell_type":"code","source":"df[\"MiscFeature\"] = df[\"MiscFeature\"].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.289425Z","iopub.execute_input":"2021-08-04T11:43:41.289913Z","iopub.status.idle":"2021-08-04T11:43:41.303536Z","shell.execute_reply.started":"2021-08-04T11:43:41.289879Z","shell.execute_reply":"2021-08-04T11:43:41.302664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Alley : data description says NA means \"no alley access\"","metadata":{}},{"cell_type":"code","source":"df[\"Alley\"] = df[\"Alley\"].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.304674Z","iopub.execute_input":"2021-08-04T11:43:41.305205Z","iopub.status.idle":"2021-08-04T11:43:41.318373Z","shell.execute_reply.started":"2021-08-04T11:43:41.305117Z","shell.execute_reply":"2021-08-04T11:43:41.317533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Fence : data description says NA means \"no fence\"\n","metadata":{}},{"cell_type":"code","source":"df[\"Fence\"] = df[\"Fence\"].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.319412Z","iopub.execute_input":"2021-08-04T11:43:41.319826Z","iopub.status.idle":"2021-08-04T11:43:41.333151Z","shell.execute_reply.started":"2021-08-04T11:43:41.319786Z","shell.execute_reply":"2021-08-04T11:43:41.332116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* FireplaceQu : data description says NA means \"no fireplace\"","metadata":{}},{"cell_type":"code","source":"df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.334351Z","iopub.execute_input":"2021-08-04T11:43:41.334852Z","iopub.status.idle":"2021-08-04T11:43:41.347497Z","shell.execute_reply.started":"2021-08-04T11:43:41.334791Z","shell.execute_reply":"2021-08-04T11:43:41.346364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LotFrontage : I actually didn't know what to do with this column and since it has almost 500 missing data, we cann't drop them. So I got help from https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard notebook to find a way. Since the area of each street connected to the house property most likely have a similar area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood.","metadata":{}},{"cell_type":"code","source":"df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].apply(\n    lambda x: x.fillna(x.median()))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.348593Z","iopub.execute_input":"2021-08-04T11:43:41.348911Z","iopub.status.idle":"2021-08-04T11:43:41.372287Z","shell.execute_reply.started":"2021-08-04T11:43:41.348879Z","shell.execute_reply":"2021-08-04T11:43:41.371057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice that median is diffrent from mean it's actually the middle of the values in the list of numbers.","metadata":{}},{"cell_type":"markdown","source":"* GarageType, GarageFinish, GarageQual and GarageCond : Replacing missing data with None","metadata":{}},{"cell_type":"code","source":"df['GarageType'] = df['GarageType'].fillna('None')\ndf['GarageFinish'] = df['GarageFinish'].fillna('None')\ndf['GarageQual'] = df['GarageQual'].fillna('None')\ndf['GarageCond'] = df['GarageCond'].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.373527Z","iopub.execute_input":"2021-08-04T11:43:41.373834Z","iopub.status.idle":"2021-08-04T11:43:41.38342Z","shell.execute_reply.started":"2021-08-04T11:43:41.373791Z","shell.execute_reply":"2021-08-04T11:43:41.382352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* GarageYrBlt, GarageArea and GarageCars : Replacing missing data with 0 (Since No garage = no cars in such garage.)","metadata":{}},{"cell_type":"code","source":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    df[col] = df[col].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.384602Z","iopub.execute_input":"2021-08-04T11:43:41.384986Z","iopub.status.idle":"2021-08-04T11:43:41.397504Z","shell.execute_reply.started":"2021-08-04T11:43:41.384951Z","shell.execute_reply":"2021-08-04T11:43:41.396649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath and BsmtHalfBath : missing values are likely zero for having no basement","metadata":{}},{"cell_type":"code","source":"for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    df[col] = df[col].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.398518Z","iopub.execute_input":"2021-08-04T11:43:41.398969Z","iopub.status.idle":"2021-08-04T11:43:41.411445Z","shell.execute_reply.started":"2021-08-04T11:43:41.398929Z","shell.execute_reply":"2021-08-04T11:43:41.410384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1 and BsmtFinType2 : For all these categorical basement-related features, NaN means that there is no basement.","metadata":{}},{"cell_type":"code","source":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    df[col] = df[col].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.412456Z","iopub.execute_input":"2021-08-04T11:43:41.412893Z","iopub.status.idle":"2021-08-04T11:43:41.43088Z","shell.execute_reply.started":"2021-08-04T11:43:41.412848Z","shell.execute_reply":"2021-08-04T11:43:41.429855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* MasVnrArea and MasVnrType : NA most likely means no masonry veneer for these houses. We can fill 0 for the area and None for the type.","metadata":{}},{"cell_type":"code","source":"df[\"MasVnrType\"] = df[\"MasVnrType\"].fillna(\"None\")\ndf[\"MasVnrArea\"] = df[\"MasVnrArea\"].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.431914Z","iopub.execute_input":"2021-08-04T11:43:41.432316Z","iopub.status.idle":"2021-08-04T11:43:41.444266Z","shell.execute_reply.started":"2021-08-04T11:43:41.432288Z","shell.execute_reply":"2021-08-04T11:43:41.443471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For MSZoning we hava 4 missing data. We can either delete them or another approach is to fill missing with the most common data is this column. ","metadata":{}},{"cell_type":"code","source":"df['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.445247Z","iopub.execute_input":"2021-08-04T11:43:41.445633Z","iopub.status.idle":"2021-08-04T11:43:41.457901Z","shell.execute_reply.started":"2021-08-04T11:43:41.445605Z","shell.execute_reply":"2021-08-04T11:43:41.457115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Utilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.","metadata":{}},{"cell_type":"code","source":"df = df.drop(['Utilities'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.459102Z","iopub.execute_input":"2021-08-04T11:43:41.459551Z","iopub.status.idle":"2021-08-04T11:43:41.474195Z","shell.execute_reply.started":"2021-08-04T11:43:41.459519Z","shell.execute_reply":"2021-08-04T11:43:41.472981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Functional : data description says NA means typical","metadata":{}},{"cell_type":"code","source":"df[\"Functional\"] = df[\"Functional\"].fillna(\"Typ\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.47813Z","iopub.execute_input":"2021-08-04T11:43:41.478474Z","iopub.status.idle":"2021-08-04T11:43:41.488979Z","shell.execute_reply.started":"2021-08-04T11:43:41.478437Z","shell.execute_reply":"2021-08-04T11:43:41.487667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Electrical : we will repeat the same apprach we used for MSZoning. It has one NA value. Since this feature has mostly 'SBrkr', we can set that for the missing value.","metadata":{}},{"cell_type":"code","source":"df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.490603Z","iopub.execute_input":"2021-08-04T11:43:41.491093Z","iopub.status.idle":"2021-08-04T11:43:41.504339Z","shell.execute_reply.started":"2021-08-04T11:43:41.491045Z","shell.execute_reply":"2021-08-04T11:43:41.503232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* KitchenQual: Only one NA value, and same as Electrical, we set 'TA' (which is the most frequent) for the missing value in KitchenQual.","metadata":{}},{"cell_type":"code","source":"df['KitchenQual'] = df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.506278Z","iopub.execute_input":"2021-08-04T11:43:41.50662Z","iopub.status.idle":"2021-08-04T11:43:41.519059Z","shell.execute_reply.started":"2021-08-04T11:43:41.506588Z","shell.execute_reply":"2021-08-04T11:43:41.518059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Exterior1st and Exterior2nd : Again Both Exterior 1 & 2 have only one missing value. We will just substitute in the most common string","metadata":{}},{"cell_type":"code","source":"df['Exterior1st'] = df['Exterior1st'].fillna(df['Exterior1st'].mode()[0])\ndf['Exterior2nd'] = df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.520659Z","iopub.execute_input":"2021-08-04T11:43:41.521075Z","iopub.status.idle":"2021-08-04T11:43:41.538954Z","shell.execute_reply.started":"2021-08-04T11:43:41.52104Z","shell.execute_reply":"2021-08-04T11:43:41.537918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* SaleType : Fill in again with most frequent which is \"WD\"","metadata":{}},{"cell_type":"code","source":"df['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.540598Z","iopub.execute_input":"2021-08-04T11:43:41.541097Z","iopub.status.idle":"2021-08-04T11:43:41.551667Z","shell.execute_reply.started":"2021-08-04T11:43:41.541049Z","shell.execute_reply":"2021-08-04T11:43:41.550714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* MSSubClass : Na most likely means No building class. We can replace missing values with None","metadata":{}},{"cell_type":"code","source":"df['MSSubClass'] = df['MSSubClass'].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.552881Z","iopub.execute_input":"2021-08-04T11:43:41.553342Z","iopub.status.idle":"2021-08-04T11:43:41.564667Z","shell.execute_reply.started":"2021-08-04T11:43:41.55331Z","shell.execute_reply":"2021-08-04T11:43:41.563721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.566115Z","iopub.execute_input":"2021-08-04T11:43:41.56674Z","iopub.status.idle":"2021-08-04T11:43:41.587897Z","shell.execute_reply.started":"2021-08-04T11:43:41.566707Z","shell.execute_reply":"2021-08-04T11:43:41.586893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ok it seems we've got rid of the missing data succesfully. Let's move on to categorical data.","metadata":{}},{"cell_type":"markdown","source":"# Categorical Data","metadata":{}},{"cell_type":"code","source":"categorical_data = df.dtypes[(df.dtypes == \"object\")].index\ncategorical_data","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.589274Z","iopub.execute_input":"2021-08-04T11:43:41.589918Z","iopub.status.idle":"2021-08-04T11:43:41.602546Z","shell.execute_reply.started":"2021-08-04T11:43:41.589872Z","shell.execute_reply":"2021-08-04T11:43:41.601069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[categorical_data].head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.603937Z","iopub.execute_input":"2021-08-04T11:43:41.604249Z","iopub.status.idle":"2021-08-04T11:43:41.640197Z","shell.execute_reply.started":"2021-08-04T11:43:41.60422Z","shell.execute_reply":"2021-08-04T11:43:41.639386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numerical = df.select_dtypes(exclude='object')\ndf_categorical = df.select_dtypes(include='object')\ndff = pd.get_dummies(df_categorical, drop_first=True)\ndf= pd.concat([df_numerical, dff], axis=1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.64138Z","iopub.execute_input":"2021-08-04T11:43:41.641653Z","iopub.status.idle":"2021-08-04T11:43:41.721682Z","shell.execute_reply.started":"2021-08-04T11:43:41.641628Z","shell.execute_reply":"2021-08-04T11:43:41.720666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This part was kanda tricky and honestly I choose the easiest way to deal with the categorical data. Another way to deal with them was checking their corrolation with SalePrice and assigning a number to that feature target according to its corrolation. The more domain knowlege we use in this part the more precise data we will extract.**","metadata":{}},{"cell_type":"markdown","source":"Fnally It's time build out model and start predecting.","metadata":{}},{"cell_type":"markdown","source":"# 游늳 Training a Regression Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=101)\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.723038Z","iopub.execute_input":"2021-08-04T11:43:41.723374Z","iopub.status.idle":"2021-08-04T11:43:41.758544Z","shell.execute_reply.started":"2021-08-04T11:43:41.72334Z","shell.execute_reply":"2021-08-04T11:43:41.757267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 游릭 Linear Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\nlinearModel = LinearRegression()\nlinearModel.fit(X_train, y_train)\nlinearPred = linearModel.predict(X_test)\n\nMAE_linear = metrics.mean_absolute_error(y_test, linearPred)\nMSE_linear = metrics.mean_squared_error(y_test, linearPred)\nRMSE_linear = np.sqrt(MSE_linear)\n\nresults_df = pd.DataFrame(data=[[\"Linear Regression\", MAE_linear, MSE_linear, RMSE_linear]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE'])\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:41.760012Z","iopub.execute_input":"2021-08-04T11:43:41.760352Z","iopub.status.idle":"2021-08-04T11:43:42.051195Z","shell.execute_reply.started":"2021-08-04T11:43:41.760318Z","shell.execute_reply":"2021-08-04T11:43:42.049944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 游릭 Polynomial Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npolynomial_convertor = PolynomialFeatures(degree = 2, include_bias = False)\npolynomial_convertor.fit(df)\npoly_features = polynomial_convertor.transform(df)\npoly_features.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:42.053048Z","iopub.execute_input":"2021-08-04T11:43:42.053483Z","iopub.status.idle":"2021-08-04T11:43:42.385202Z","shell.execute_reply.started":"2021-08-04T11:43:42.053441Z","shell.execute_reply":"2021-08-04T11:43:42.384464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(poly_features, y, test_size=0.3, random_state=101)\npolyLinearModel = LinearRegression()\npolyLinearModel.fit(X_train_poly, y_train_poly)\npolyLinearPred = polyLinearModel.predict(X_test_poly)\n\nMAE_poly_linear = metrics.mean_absolute_error(y_test_poly, polyLinearPred)\nMSE_poly_linear = metrics.mean_squared_error(y_test_poly, polyLinearPred)\nRMSE_poly_linear = np.sqrt(MSE_poly_linear)\nresults_df = pd.DataFrame(data=[[\"Linear Regression\", MAE_linear, MSE_linear, RMSE_linear],\n                                [\"Polynomial Regression\", MAE_poly_linear, MSE_poly_linear, RMSE_poly_linear ]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE'])\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:42.386329Z","iopub.execute_input":"2021-08-04T11:43:42.386788Z","iopub.status.idle":"2021-08-04T11:43:45.417414Z","shell.execute_reply.started":"2021-08-04T11:43:42.386756Z","shell.execute_reply":"2021-08-04T11:43:45.416235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 游릭 Ridge Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge, RidgeCV\nridgeModel = Ridge(alpha = 10)\nridgeModel.fit(X_train, y_train)\nridgePred = ridgeModel.predict(X_test)\n\nMAE_ridge = metrics.mean_absolute_error(y_test, ridgePred)\nMSE_ridge = metrics.mean_squared_error(y_test, ridgePred)\nRMSE_ridge = np.sqrt(MSE_ridge)\n\nresults_df = pd.DataFrame(data=[[\"Linear Regression\", MAE_linear, MSE_linear, RMSE_linear],\n                                [\"Polynomial Regression\", MAE_poly_linear, MSE_poly_linear, RMSE_poly_linear],\n                                [\"Ridge Regression\", MAE_ridge, MSE_ridge, RMSE_ridge]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE'])\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:45.419155Z","iopub.execute_input":"2021-08-04T11:43:45.419874Z","iopub.status.idle":"2021-08-04T11:43:45.489642Z","shell.execute_reply.started":"2021-08-04T11:43:45.419804Z","shell.execute_reply":"2021-08-04T11:43:45.488366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ridgeCvModel = RidgeCV(alphas=(0.1,1.0,10.0,100.0))\nridgeCvModel.fit(X_train, y_train)\nridgeCvModel.alpha_","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:43:45.491568Z","iopub.execute_input":"2021-08-04T11:43:45.492048Z","iopub.status.idle":"2021-08-04T11:43:45.62524Z","shell.execute_reply.started":"2021-08-04T11:43:45.492001Z","shell.execute_reply":"2021-08-04T11:43:45.623625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 游릭 LASSO Regression (Least Absolute Shrinking and Selection Operator)","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LassoCV\nlassoCvModel = LassoCV(eps=0.1, n_alphas=10000,cv=5)\nlassoCvModel.fit(X_train,y_train)\nlassoCvModel.alpha_","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:44:09.236271Z","iopub.execute_input":"2021-08-04T11:44:09.236716Z","iopub.status.idle":"2021-08-04T11:44:31.47089Z","shell.execute_reply.started":"2021-08-04T11:44:09.236678Z","shell.execute_reply":"2021-08-04T11:44:31.469863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lassoPred = lassoCvModel.predict(X_test)\nMAE_lasso = metrics.mean_absolute_error(y_test, lassoPred)\nMSE_lasso = metrics.mean_squared_error(y_test, lassoPred)\nRMSE_lasso = np.sqrt(MSE_lasso)\n\nresults_df = pd.DataFrame(data=[[\"Linear Regression\", MAE_linear, MSE_linear, RMSE_linear],\n                                [\"Polynomial Regression\", MAE_poly_linear, MSE_poly_linear, RMSE_poly_linear],\n                                [\"Ridge Regression\", MAE_ridge, MSE_ridge, RMSE_ridge],\n                                [\"LASSO Regression\", MAE_lasso, MSE_lasso, RMSE_lasso]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE'])\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:46:52.375321Z","iopub.execute_input":"2021-08-04T11:46:52.375771Z","iopub.status.idle":"2021-08-04T11:46:52.411253Z","shell.execute_reply.started":"2021-08-04T11:46:52.375734Z","shell.execute_reply":"2021-08-04T11:46:52.409601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lassoCvModel.coef_","metadata":{"execution":{"iopub.status.busy":"2021-08-04T11:47:52.609608Z","iopub.execute_input":"2021-08-04T11:47:52.610089Z","iopub.status.idle":"2021-08-04T11:47:52.621971Z","shell.execute_reply.started":"2021-08-04T11:47:52.610044Z","shell.execute_reply":"2021-08-04T11:47:52.621151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you saw in the table LASSO Regression didn't do a good a job predecting the data and that's because lasso regression allow the coeficient to be zero. All coeficients are zero execpt two of them that means we only consider two of our feature to predict our label.\n* **Ok then why do we even use this model?!!!**\n    * In some cases the trade-off in resault may worth it to consider less feature. Considering only two feature would make out job too easy beacause as then we should only be worried about those two although we should consider the error rate it has given two us.    ","metadata":{}},{"cell_type":"markdown","source":"# 游릭 Elastic Net","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNetCV\nelasticModel = ElasticNetCV(l1_ratio=[.1,.5,.7,.7,.9,.95,.99,1],\n                           eps = 0.001, n_alphas=100,max_iter=1000000)\nelasticModel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:16:03.559429Z","iopub.execute_input":"2021-08-04T12:16:03.559903Z","iopub.status.idle":"2021-08-04T12:16:06.136924Z","shell.execute_reply.started":"2021-08-04T12:16:03.559862Z","shell.execute_reply":"2021-08-04T12:16:06.135639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elasticPred = elasticModel.predict(X_test)\nprint(elasticModel.l1_ratio_)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:19:02.338841Z","iopub.execute_input":"2021-08-04T12:19:02.339213Z","iopub.status.idle":"2021-08-04T12:19:02.363744Z","shell.execute_reply.started":"2021-08-04T12:19:02.339182Z","shell.execute_reply":"2021-08-04T12:19:02.362919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This means since l1_ratio is 1 and that's the alpha parameter in the formula, it only considered lasso.","metadata":{}},{"cell_type":"code","source":"MAE_elastic = metrics.mean_absolute_error(y_test, lassoPred)\nMSE_elastic = metrics.mean_squared_error(y_test, lassoPred)\nRMSE_elastic = np.sqrt(MSE_elastic)\nresults_df = pd.DataFrame(data=[[\"Linear Regression\", MAE_linear, MSE_linear, RMSE_linear],\n                                [\"Polynomial Regression\", MAE_poly_linear, MSE_poly_linear, RMSE_poly_linear],\n                                [\"Ridge Regression\", MAE_ridge, MSE_ridge, RMSE_ridge],\n                                [\"LASSO Regression\", MAE_lasso, MSE_lasso, RMSE_lasso],\n                                [\"Elastic Net\", MAE_elastic, MSE_elastic, RMSE_elastic]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE'])\nresults_df","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:20:16.733169Z","iopub.execute_input":"2021-08-04T12:20:16.73366Z","iopub.status.idle":"2021-08-04T12:20:16.756333Z","shell.execute_reply.started":"2021-08-04T12:20:16.733614Z","shell.execute_reply":"2021-08-04T12:20:16.755373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see the result for elastic and LASSO regression are exactly the same.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(10,7)\nregressors = [\"Linear\", \"Polynomial\", \"Ridge\", \"LASSO\", \"Elastic Net\"]\nrmses = [RMSE_linear, RMSE_poly_linear, RMSE_ridge, RMSE_lasso, RMSE_elastic]\nsns.barplot(x=regressors, y=rmses, ax= ax)\nplt.ylabel('RMSE')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:26:42.741859Z","iopub.execute_input":"2021-08-04T12:26:42.742233Z","iopub.status.idle":"2021-08-04T12:26:42.933306Z","shell.execute_reply.started":"2021-08-04T12:26:42.742201Z","shell.execute_reply":"2021-08-04T12:26:42.932151Z"},"trusted":true},"execution_count":null,"outputs":[]}]}