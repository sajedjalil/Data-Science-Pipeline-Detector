{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pprint\n\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, PredefinedSplit, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, FunctionTransformer\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\nfrom hpsklearn import HyperoptEstimator, svr, svr_linear, svr_rbf, svr_poly, svr_sigmoid, knn_regression, ada_boost_regression, gradient_boosting_regression, random_forest_regression, extra_trees_regression, sgd_regression, xgboost_regression","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 100)\npd.set_option(\"display.max_rows\", 400)\nrandom_state = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndf_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n\ndf_target = df_train[['SalePrice']]\ndf = df_train.append(df_test)\ndf.drop(columns=['Id'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Clean Datas**\n\nIn the first step we will focus on filling in the null values, I did not choose to do some kind of automatic filling (average, mode, median ...). Let's do it in 'baby step', first we will treat the attributes with the highest amount of nulls.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function to mount info about df current.\ndef mount_df_info(df):\n    df_info = df.dtypes.to_frame(name='type')\n    df_info['count_null'] = df.isnull().values.sum(axis=0)\n    df_info['nunique'] = df.nunique().values\n    df_info['count_zeros'] = (df == 0).values.sum(axis=0)\n    df_info['max_value'] = df.max()\n    df_info['min_value'] = df.min()\n    \n    return df_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_info = mount_df_info(df)\ndf_info.sort_values(by='count_null', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']\ndf[columns] = df[columns].fillna('nan')\ndf_info = mount_df_info(df)\ndf_info.sort_values(by='count_null', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df[df['GarageYrBlt'] == 2207].index, 'GarageYrBlt'] = 2010\ndf['GarageYrBlt'] = df['GarageYrBlt'].fillna(0).astype(int)\n\ncolumns = ['GarageCond', 'GarageFinish', 'GarageQual', 'GarageType']\ndf[columns] = df[columns].fillna('nan')\ndf_info = mount_df_info(df)\ndf_info.sort_values(by='count_null', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['BsmtCond', 'BsmtExposure', 'BsmtQual', 'BsmtFinType2', 'BsmtFinType1']\ndf[columns] = df[columns].fillna('nan')\ndf_info = mount_df_info(df)\ndf_info.sort_values(by='count_null', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n\ncolumns = ['Electrical', 'KitchenQual', 'MSZoning', 'Exterior1st', 'Exterior2nd', 'SaleType']\n\nfor _column in columns:\n    df[_column] = df[_column].fillna(df[_column].mode()[0])\n\ncolumns = ['MasVnrArea', 'BsmtHalfBath', 'BsmtFullBath', 'GarageArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageCars']\ndf[columns] = df[columns].fillna(0)\n\ncolumns = ['MasVnrType', 'Functional', 'Utilities']\ndf[columns] = df[columns].fillna('nan')\n\ndf_info = mount_df_info(df)\ndf_info.sort_values(by='nunique', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_disc = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n                'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle',\n                'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtExposure', 'BsmtFinType1',\n                'BsmtFinType2', 'Heating', 'CentralAir', 'Electrical', 'Functional', 'GarageType', 'GarageFinish',\n                'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n\ncolumns_disc_qual = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu',\n                        'GarageQual', 'GarageCond', 'PoolQC']\n\ncolumns_cont = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n               'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n               'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n               'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n\ncolumns_year = ['YearBuilt', 'GarageYrBlt', 'YearRemodAdd', 'YrSold', 'MoSold']\n\nprint('Columns disc', len(columns_disc))\nprint('Columns disc to cont', len(columns_disc_qual))\nprint('Columns cont', len(columns_cont))\nprint('Columns year', len(columns_year))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_disc = columns_disc + columns_disc_qual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df.iloc[df_train.shape[0]:]\ndf_train = df.iloc[:df_train.shape[0]]\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exploratory analysis**\n\nLet's study the training data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(len(columns_cont) // 3 + 1, 3, figsize=(18, 40))\ni = 0\ncorr_with_sales_price = df_train[columns_cont + ['SalePrice']].corr(method='spearman')['SalePrice'].sort_values(ascending=False)\n\nfor _column in corr_with_sales_price.index[1:]:\n    _ax = axs[i//3, i%3]\n    _ax.boxplot(df_train[_column], whis=3)\n    _ax.set_title(f'{_column} - {corr_with_sales_price[_column]}')\n    i+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(len(columns_disc) // 3 + 1, 3, figsize=(18, 60))\ni = 0\n\nfor _column in columns_disc:\n    _ax = axs[i//3, i%3]\n    _ax.hist(df_train[_column])\n    _ax.set_title(f'{_column}')\n    i+=1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr_disc = pd.DataFrame(columns=['feature', 'value', 'corr_with_sale_prices', 'count'])\n\nfor _feature in columns_disc:\n    df_temp = pd.get_dummies(df_train[_feature])\n\n    for _column in df_temp.columns:\n        _corr = stats.pointbiserialr(df_temp[_column], df_train['SalePrice'])\n        df_corr_disc = df_corr_disc.append({'feature': _feature, 'value': _column, 'corr_with_sale_prices': _corr[0], 'count': sum(df_temp[_column])}, ignore_index=True)\ndf_corr_disc.sort_values(by='corr_with_sale_prices')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fireplaces: Number of fireplaces\n\nFireplaceQu: Fireplace quality\n\n       Ex\tExcellent - Exceptional Masonry Fireplace\n       Gd\tGood - Masonry Fireplace in main level\n       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n       Fa\tFair - Prefabricated Fireplace in basement\n       Po\tPoor - Ben Franklin Stove\n       NA\tNo Fireplace","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['new_Fireplaces'] = df_train['Fireplaces'] * df_train['FireplaceQu'].map({'nan': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}).astype(int)\ndf['new_Fireplaces'] = df['Fireplaces'] * df['FireplaceQu'].map({'nan': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}).astype(int)\n\ndf_train[['new_Fireplaces', 'SalePrice']].corr(method='spearman')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"YearBuilt: Original construction date\n\nYearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\n\nGarageYrBlt: Year garage was built\n\nMoSold: Month Sold (MM)\n\nYrSold: Year Sold (YYYY)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = df_train[df_train['YearRemodAdd'] > df_train['YearBuilt']]\nplt.hist(df_temp['YearRemodAdd'] - df_temp['YearBuilt'], bins=30) #hist to see time remod after built (only build has remod) \nplt.show()\n\ndf_train['new_has_remod'] = df_train['YearRemodAdd'] > df_train['YearBuilt']\ndf_train['new_time_remod'] = df_train['YearRemodAdd'] - df_train['YearBuilt']\ndf['new_has_remod'] = df['YearRemodAdd'] > df['YearBuilt']\ndf['new_time_remod'] = df['YearRemodAdd'] - df['YearBuilt']\n\nprint(stats.pointbiserialr(df_train['new_has_remod'], df_train['SalePrice']))\ndf_train[['new_time_remod', 'SalePrice']].corr(method='spearman')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df_train['YrSold'] - df_train['YearBuilt'], bins=30)\nplt.show()\n\ndf_train['new_time_sold'] = df_train['YrSold'] - df_train['YearBuilt']\ndf['new_time_sold'] = df['YrSold'] - df['YearBuilt']\n\ndf_train[['new_time_sold', 'SalePrice']].corr(method='spearman')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['new_garage_after_build'] = df_train['GarageYrBlt'] > df_train['YearBuilt']\ndf['new_garage_after_build'] = df['GarageYrBlt'] > df['YearBuilt']\n\nprint(stats.pointbiserialr(df_train['new_garage_after_build'], df_train['SalePrice']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TotalBsmtSF: Total square feet of basement area\n\n1stFlrSF: First Floor square feet\n \n2ndFlrSF: Second floor square feet\n\nGarageArea: Size of garage in square feet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['new_totalSF'] = df_train['TotalBsmtSF'] + df_train['1stFlrSF'] + df_train['2ndFlrSF'] + df_train['GarageArea']\ndf['new_totalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF'] + df['GarageArea']\n\ndf_train[['new_totalSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GarageArea', 'SalePrice']].corr(method='spearman')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['BsmtFullBath'] = df_train['BsmtFullBath'].astype(int)\ndf['BsmtFullBath'] = df['BsmtFullBath'].astype(int)\n\ndf_train['BsmtHalfBath'] = df_train['BsmtHalfBath'].astype(int)\ndf['BsmtHalfBath'] = df['BsmtHalfBath'].astype(int)\n\ndf_train['new_others_room'] = df_train['TotRmsAbvGrd'] - df_train['BedroomAbvGr'] - df_train['KitchenAbvGr']\ndf['new_others_room'] = df['TotRmsAbvGrd'] - df['BedroomAbvGr'] - df['KitchenAbvGr']\n\ndf_train['new_all_room'] = df_train['TotRmsAbvGrd'] + df_train['BsmtFullBath'] + df_train['BsmtHalfBath'] + df_train['FullBath'] + df_train['HalfBath']\ndf['new_all_room'] = df['TotRmsAbvGrd'] + df['BsmtFullBath'] + df['BsmtHalfBath'] + df['FullBath'] + df['HalfBath']\n\ndf_train[['TotRmsAbvGrd', 'BedroomAbvGr', 'KitchenAbvGr', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'new_others_room', 'new_all_room', 'SalePrice']].corr(method='spearman')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_df_temp = pd.DataFrame()\n\nfor _columns in columns_disc_qual:\n    _df_temp[_columns] = df[_columns].map({'nan': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}).astype(int)\n    \ndf['new_overall'] = _df_temp[columns_disc_qual].sum(axis=1) / len(columns_disc_qual)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(kind='scatter', x='new_overall', y= 'OverallQual')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Choosing the columns that we will use as features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_disc = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n                'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle',\n                'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtExposure', 'BsmtFinType1',\n                'BsmtFinType2', 'Heating', 'CentralAir', 'Electrical', 'Functional', 'GarageType', 'GarageFinish',\n                'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition', 'MoSold',\n                \n                'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu',\n                'GarageQual', 'GarageCond', 'PoolQC',\n                \n                'new_has_remod', 'new_garage_after_build']\n\n\ncolumns_cont = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n               'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n               'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n               'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n                \n                'new_Fireplaces', 'new_time_remod', 'new_time_sold', 'new_totalSF', 'new_others_room', 'new_all_room', 'new_overall']\n\ncolumns_year = ['YearBuilt', 'GarageYrBlt', 'YearRemodAdd', 'YrSold']\n\nprint('Columns disc', len(columns_disc))\nprint('Columns cont', len(columns_cont))\nprint('Columns year', len(columns_year))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_cont = columns_cont + columns_year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oneHot = OneHotEncoder(handle_unknown='ignore')\ndf_onehot = oneHot.fit_transform(df[columns_disc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_disc = pd.DataFrame.sparse.from_spmatrix(df_onehot, columns=oneHot.get_feature_names(df[columns_disc].columns)).astype(bool).reset_index()\ndf_cont = df[columns_cont].reset_index()\ndf_processed = pd.concat([df_cont, df_disc], sort=False, axis=1).drop(columns=['index'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard = StandardScaler()\ndf_processed[columns_cont] = standard.fit_transform(df_processed[columns_cont])\n\ntransformer = FunctionTransformer(np.log1p)\ndf_target = transformer.transform(df_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_processed[columns_cont].hist(figsize=(18,30))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_processed.iloc[:df_train.shape[0]]\ndf_test = df_processed.iloc[df_train.shape[0]:]\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsqle(y, y_pred):\n    return np.sqrt(mean_squared_log_error(np.expm1(np.abs(y)), np.expm1(np.abs(y_pred))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, _X_test, _y_test):\n    _y_pred = model.predict(_X_test)\n    return rmsqle(_y_test, _y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_submission(_result):\n    df_to_submit = pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')\n    df_to_submit['SalePrice'] = np.expm1(_result)\n    df_to_submit.to_csv('/kaggle/working/to_submit.csv', index=False)\n    df_to_submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmsqle_score = make_scorer(rmsqle, greater_is_better=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_drop = ['MSSubClass_150', 'Utilities_nan', 'Functional_nan']\ndf_train.drop(columns=columns_to_drop, inplace=True)\ndf_test.drop(columns=columns_to_drop, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_train, df_target, test_size=0.25, random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XGBoost**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor, plot_importance\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"xgb = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213,\n                             random_state=7, nthread = -1)\n\nxgb.fit(X_train, y_train)\nprint(rmsqle(xgb.predict(X_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.Series(xgb.feature_importances_, index=list(df[columns_cont].columns) + list(set(oneHot.get_feature_names(df[columns_disc].columns))- set(columns_to_drop)))\nimportances.sort_values(ascending=False).head(20) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n\nlgbm.fit(X_train, y_train)\nprint(rmsqle(lgbm.predict(X_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.Series(lgbm.feature_importances_, index=list(df[columns_cont].columns) + list(set(oneHot.get_feature_names(df[columns_disc].columns))- set(columns_to_drop)))\nimportances.sort_values(ascending=False).head(20) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\n\ngradient.fit(X_train, y_train)\nprint(rmsqle(gradient.predict(X_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.Series(gradient.feature_importances_, index=list(df[columns_cont].columns) + list(set(oneHot.get_feature_names(df[columns_disc].columns))- set(columns_to_drop)))\nimportances.sort_values(ascending=False).head(20) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_xgb = xgb.predict(df_test)\npredict_lgbm = lgbm.predict(df_test)\npredict_gradient = gradient.predict(df_test)\n\npredict_final = (predict_lgbm * 0.30 + predict_xgb * 0.50 + predict_gradient * 0.20)\nwrite_submission(predict_final)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}