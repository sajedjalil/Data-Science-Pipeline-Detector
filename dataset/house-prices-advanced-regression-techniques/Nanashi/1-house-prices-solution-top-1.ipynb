{"cells":[{"metadata":{"_uuid":"72cb4fbdcf8a9b882a5dfaa1449a3520ae529639"},"cell_type":"markdown","source":"# House Prices: Advanced Regression Techniques\n### Predict sales prices and practice feature engineering, RFs, and gradient boosting\n![main](http://www.propertyreporter.co.uk/images/660x350/16402-shutterstock_538341163.jpg)\n\n<br>\n### Weekly update\n\n**Competition Description**\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\n**Executive Summary**\n\nI started this competition by just focusing on getting a good understanding of the dataset. The EDA is detailed and many visualizations are included. This version also includes modeling:\n\n- Lasso regression model (great perform)\n- XGBoost model\n- LGBM model\n- Dragon model\n\n"},{"metadata":{},"cell_type":"markdown","source":"<br>\n### Load packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom datetime import datetime\nfrom scipy.stats import skew  # for some statistics\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom mlxtend.regressor import StackingCVRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport sklearn.linear_model as linear_model\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nprint (\"Data is loaded!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74dbd74c5d18163b3e9c58a91c008e775415cd1f","_kg_hide-input":true},"cell_type":"code","source":"print (\"Train: \",train.shape[0],\"sales, and \",train.shape[1],\"features\")\nprint (\"Test: \",test.shape[0],\"sales, and \",test.shape[1],\"features\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5657e5c58c3f4cb8c0b9012d275fb15f44cee2ef"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f589f6bd8a1e1773b5ac8251ab15ebb4215d436"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"There are 1460 instances of training data and 1460 of test data. Total number of attributes equals 81, of which 36 is quantitative, 43 categorical + Id and SalePrice.\n\n**Quantitative:** 1stFlrSF, 2ndFlrSF, 3SsnPorch, BedroomAbvGr, BsmtFinSF1, BsmtFinSF2, BsmtFullBath, BsmtHalfBath, BsmtUnfSF, EnclosedPorch, Fireplaces, FullBath, GarageArea, GarageCars, GarageYrBlt, GrLivArea, HalfBath, KitchenAbvGr, LotArea, LotFrontage, LowQualFinSF, MSSubClass, MasVnrArea, MiscVal, MoSold, OpenPorchSF, OverallCond, OverallQual, PoolArea, ScreenPorch, TotRmsAbvGrd, TotalBsmtSF, WoodDeckSF, YearBuilt, YearRemodAdd, YrSold\n\n**Qualitative:** Alley, BldgType, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, BsmtQual, CentralAir, Condition1, Condition2, Electrical, ExterCond, ExterQual, Exterior1st, Exterior2nd, Fence, FireplaceQu, Foundation, Functional, GarageCond, GarageFinish, GarageQual, GarageType, Heating, HeatingQC, HouseStyle, KitchenQual, LandContour, LandSlope, LotConfig, LotShape, MSZoning, MasVnrType, MiscFeature, Neighborhood, PavedDrive, PoolQC, RoofMatl, RoofStyle, SaleCondition, SaleType, Street, Utilities,"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\nquantitative.remove('SalePrice')\nquantitative.remove('Id')\nqualitative = [f for f in train.columns if train.dtypes[f] == 'object']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"quantitative","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"qualitative","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nmissing = train.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"19 attributes have missing values, 5 over 50% of all data. Most of times NA means lack of subject described by attribute, like missing pool, fence, no garage and basement."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"y = train['SalePrice']\nplt.figure(1); plt.title('Johnson SU')\nsns.distplot(y, kde=False, fit=stats.johnsonsu)\nplt.figure(2); plt.title('Normal')\nsns.distplot(y, kde=False, fit=stats.norm)\nplt.figure(3); plt.title('Log Normal')\nsns.distplot(y, kde=False, fit=stats.lognorm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is apparent that SalePrice doesn't follow normal distribution, so before performing regression it has to be transformed. While log transformation does pretty good job, best fit is unbounded Johnson distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_normality = lambda x: stats.shapiro(x.fillna(0))[1] < 0.01\nnormal = pd.DataFrame(train[quantitative])\nnormal = normal.apply(test_normality)\nprint(not normal.any())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also none of quantitative variables has normal distribution so these should be transformed as well."},{"metadata":{},"cell_type":"markdown","source":"**Spearman correlation** is better to work with in this case because it picks up relationships between variables even when they are nonlinear. OverallQual is main criterion in establishing house price. Neighborhood has big influence, partially it has some intrisinc value in itself, but also houses in certain regions tend to share same characteristics (confunding) what causes similar valuations."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def encode(frame, feature):\n    ordering = pd.DataFrame()\n    ordering['val'] = frame[feature].unique()\n    ordering.index = ordering.val\n    ordering['spmean'] = frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']\n    ordering = ordering.sort_values('spmean')\n    ordering['ordering'] = range(1, ordering.shape[0]+1)\n    ordering = ordering['ordering'].to_dict()\n    \n    for cat, o in ordering.items():\n        frame.loc[frame[feature] == cat, feature+'_E'] = o\n    \nqual_encoded = []\nfor q in qualitative:  \n    encode(train, q)\n    qual_encoded.append(q+'_E')\nprint(qual_encoded)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def spearman(frame, features):\n    spr = pd.DataFrame()\n    spr['feature'] = features\n    spr['spearman'] = [frame[f].corr(frame['SalePrice'], 'spearman') for f in features]\n    spr = spr.sort_values('spearman')\n    plt.figure(figsize=(6, 0.25*len(features)))\n    sns.barplot(data=spr, y='feature', x='spearman', orient='h')\n    \nfeatures = quantitative + qual_encoded\n#spearman(train, features)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(1)\ncorr = train[quantitative+['SalePrice']].corr()\nsns.heatmap(corr)\nplt.figure(2)\ncorr = train[qual_encoded+['SalePrice']].corr()\nsns.heatmap(corr)\nplt.figure(3)\ncorr = pd.DataFrame(np.zeros([len(quantitative)+1, len(qual_encoded)+1]), index=quantitative+['SalePrice'], columns=qual_encoded+['SalePrice'])\nfor q1 in quantitative+['SalePrice']:\n    for q2 in qual_encoded+['SalePrice']:\n        corr.loc[q1, q2] = train[q1].corr(train[q2])\nsns.heatmap(corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simple clustering"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"features = quantitative + qual_encoded\nmodel = TSNE(n_components=2, random_state=0, perplexity=50)\nX = train[features].fillna(0.).values\ntsne = model.fit_transform(X)\n\nstd = StandardScaler()\ns = std.fit_transform(X)\npca = PCA(n_components=30)\npca.fit(s)\npc = pca.transform(s)\nkmeans = KMeans(n_clusters=5)\nkmeans.fit(pc)\n\nfr = pd.DataFrame({'tsne1': tsne[:,0], 'tsne2': tsne[:, 1], 'cluster': kmeans.labels_})\nsns.lmplot(data=fr, x='tsne1', y='tsne2', hue='cluster', fit_reg=False)\nprint(np.sum(pca.explained_variance_ratio_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models"},{"metadata":{"_uuid":"f80e5f49255bd7af3d0348af6e439f1ab27e5dae"},"cell_type":"markdown","source":"### Data processing"},{"metadata":{"trusted":true,"_uuid":"6809fd6f2b047998499fcc874f3153375e4ce2ff"},"cell_type":"code","source":"train.drop(['Id'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c14fb1e14dd78259b6d56fa4345b6cca969e6f80"},"cell_type":"code","source":"train = train[train.GrLivArea < 4500]\ntrain.reset_index(drop=True, inplace=True)\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\ny = train['SalePrice'].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19fce170074c59b1bd12652969a61faba9d2e9a4"},"cell_type":"markdown","source":"### Features"},{"metadata":{"trusted":true,"_uuid":"b8680fdd6ef9abb99796777d3272fa1ffe7776a0"},"cell_type":"code","source":"train_features = train.drop(['SalePrice'], axis=1)\ntest_features = test\nfeatures = pd.concat([train_features, test_features]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43674957e009d32de93adefbcaba716dd5645825"},"cell_type":"code","source":"features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cefcd65a3c4cdfb8a23e83b1100b0a04a5c4ba9a","_kg_hide-input":true},"cell_type":"code","source":"features['MSSubClass'] = features['MSSubClass'].apply(str)\nfeatures['YrSold'] = features['YrSold'].astype(str)\nfeatures['MoSold'] = features['MoSold'].astype(str)\nfeatures['Functional'] = features['Functional'].fillna('Typ') \nfeatures['Electrical'] = features['Electrical'].fillna(\"SBrkr\") \nfeatures['KitchenQual'] = features['KitchenQual'].fillna(\"TA\") \nfeatures[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\nfeatures['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0]) \nfeatures['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\nfeatures['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dee1a00a8d7f02b9750a3d53304428d68e7f712d","_kg_hide-input":true},"cell_type":"code","source":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    features[col] = features[col].fillna(0)\n\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    features[col] = features[col].fillna('None')\n\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    features[col] = features[col].fillna('None')\n\nfeatures['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddece569289fdbe674d93bfb5e7667ddb96f9ee4","_kg_hide-input":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57603f03d91470f0e129b0ed88ec70ba547f3663"},"cell_type":"code","source":"objects = []\nfor i in features.columns:\n    if features[i].dtype == object:\n        objects.append(i)\nfeatures.update(features[objects].fillna('None'))\n\nfeatures['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics = []\nfor i in features.columns:\n    if features[i].dtype in numeric_dtypes:\n        numerics.append(i)\nfeatures.update(features[numerics].fillna(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e115eab54fbf0fbc16d5f0ec1202d51d866002b2"},"cell_type":"code","source":"numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics2 = []\nfor i in features.columns:\n    if features[i].dtype in numeric_dtypes:\n        numerics2.append(i)\nskew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nfor i in skew_index:\n    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75773fdb4be11c0831d99aad8271d709f4b4ef7f"},"cell_type":"code","source":"features = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n\nfeatures['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\nfeatures['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n\nfeatures['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n                                 features['1stFlrSF'] + features['2ndFlrSF'])\n\nfeatures['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n\nfeatures['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n                              features['EnclosedPorch'] + features['ScreenPorch'] +\n                              features['WoodDeckSF'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a187e78c5decf896d62e8076eed6f5bb3ba8c702"},"cell_type":"code","source":"features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aae8e5f66e6da9204c8567f6bac5c0e92fc22ef4"},"cell_type":"code","source":"features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95eea818f1242ae1ec1b58bc1112fb19b17e4ad0"},"cell_type":"code","source":"final_features = pd.get_dummies(features).reset_index(drop=True)\nfinal_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d1a016b7d8628c3f7be1f1fd2d9964b2b724d40"},"cell_type":"code","source":"X = final_features.iloc[:len(y), :]\nX_sub = final_features.iloc[len(y):, :]\nX.shape, y.shape, X_sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a6cb7302e1aa4928b738f65c3d4c05bcf2e267a"},"cell_type":"code","source":"outliers = [30, 88, 462, 631, 1322]\nX = X.drop(X.index[outliers])\ny = y.drop(y.index[outliers])\n\noverfit = []\nfor i in X.columns:\n    counts = X[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros / len(X) * 100 > 99.94:\n        overfit.append(i)\n\noverfit = list(overfit)\nX = X.drop(overfit, axis=1)\nX_sub = X_sub.drop(overfit, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b4eb5df4ad4e4ef500087fd290aabeb92ad062e"},"cell_type":"code","source":"X.shape, y.shape, X_sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"221673e6ce1fe10acdb5111dc7952f5e1d910c9c"},"cell_type":"code","source":"kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef cv_rmse(model, X=X):\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n    return (rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cec1909ad2525acdb074f9ceefe1888a8e55dab"},"cell_type":"code","source":"alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"667e3e46ec214c90faa65f7707b269c68e630abb"},"cell_type":"code","source":"ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\nelasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \nsvr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c86cb1ea160210c8a08e7c1a899bcb246d686334"},"cell_type":"code","source":"gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)                             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63e11ef6d6af7e9b0552e87ca2f58660bef1b174"},"cell_type":"code","source":"lightgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=5000,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose=-1,\n                                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"914205a77a844dc220dcc438d23ec1122ecc83b3"},"cell_type":"code","source":"xgboost = XGBRegressor(learning_rate=0.01,n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,\n                                     objective='reg:linear', nthread=-1,\n                                     scale_pos_weight=1, seed=27,\n                                     reg_alpha=0.00006)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd688572d658afe67dcf71963e28eff20c16b721"},"cell_type":"code","source":"stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n                                meta_regressor=xgboost,\n                                use_features_in_secondary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81aae079934ae19a2bb621f3115609770ccb0e6a"},"cell_type":"code","source":"score = cv_rmse(ridge)\nscore = cv_rmse(lasso)\nprint(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(elasticnet)\nprint(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(svr)\nprint(\"SVR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(lightgbm)\nprint(\"lightgbm: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(gbr)\nprint(\"gbr: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(xgboost)\nprint(\"xgboost: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d39f40cf0a5ce35f211aa1479052c6fdc25b22f"},"cell_type":"code","source":"print('START Fit')\n\nprint('stack_gen')\nstack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n\nprint('elasticnet')\nelastic_model_full_data = elasticnet.fit(X, y)\n\nprint('Lasso')\nlasso_model_full_data = lasso.fit(X, y)\n\nprint('Ridge')\nridge_model_full_data = ridge.fit(X, y)\n\nprint('Svr')\nsvr_model_full_data = svr.fit(X, y)\n\nprint('GradientBoosting')\ngbr_model_full_data = gbr.fit(X, y)\n\nprint('xgboost')\nxgb_model_full_data = xgboost.fit(X, y)\n\nprint('lightgbm')\nlgb_model_full_data = lightgbm.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec2b00b49c8e397510c01bb0962ff22cb9776b5c"},"cell_type":"markdown","source":"# Blending Models"},{"metadata":{"trusted":true,"_uuid":"8d8102c22cf183b3965d3092f3152006ae237a62"},"cell_type":"code","source":"def blend_models_predict(X):\n    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n            (0.05 * lasso_model_full_data.predict(X)) + \\\n            (0.1 * ridge_model_full_data.predict(X)) + \\\n            (0.1 * svr_model_full_data.predict(X)) + \\\n            (0.1 * gbr_model_full_data.predict(X)) + \\\n            (0.15 * xgb_model_full_data.predict(X)) + \\\n            (0.1 * lgb_model_full_data.predict(X)) + \\\n            (0.3 * stack_gen_model.predict(np.array(X))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b972324b0039d12d9422112f9c6a65c84b820f0"},"cell_type":"code","source":"print('RMSLE score on train data:')\nprint(rmsle(y, blend_models_predict(X)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0fa2dfe20409dc1ee8b31139d6523c62b14d658"},"cell_type":"code","source":"print('Predict submission')\nsubmission = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\nsubmission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"478804e950bfb156e74f95c3635baea1cd3f1193"},"cell_type":"code","source":"print('Blend with Top Kernels submissions\\n')\nsub_1 = pd.read_csv('../input/top-10-0-10943-stacking-mice-and-brutal-force/House_Prices_submit.csv')\nsub_2 = pd.read_csv('../input/hybrid-svm-benchmark-approach-0-11180-lb-top-2/hybrid_solution.csv')\nsub_3 = pd.read_csv('../input/lasso-model-for-regression-problem/lasso_sol22_Median.csv')\nsubmission.iloc[:,1] = np.floor((0.25 * np.floor(np.expm1(blend_models_predict(X_sub)))) + \n                                (0.25 * sub_1.iloc[:,1]) + \n                                (0.25 * sub_2.iloc[:,1]) + \n                                (0.25 * sub_3.iloc[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f91b0dfa25e867d93d4e8fb383f8240d6fcd250"},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true,"_uuid":"1a3b3c0025fdf118a0bedca994650e8a38170370","_kg_hide-input":true},"cell_type":"code","source":"q1 = submission['SalePrice'].quantile(0.005)\nq2 = submission['SalePrice'].quantile(0.995)\nsubmission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\nsubmission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9a3a97f62fd8e553e8c44b07011f7711e016b32"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# New blending"},{"metadata":{},"cell_type":"markdown","source":"Based on: **https://www.kaggle.com/itslek/blend-stack-lr-gb-0-10649-house-prices-v57/data?scriptVersionId=11189608**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\nfrom scipy.stats import skew  # for some statistics\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom mlxtend.regressor import StackingCVRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Based on https://www.kaggle.com/hemingwei/top-2-from-laurenstc-on-house-price-prediction\n\ntrain = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nprint(\"Train set size:\", train.shape)\nprint(\"Test set size:\", test.shape)\nprint('START data processing', datetime.now(), )\n\ntrain_ID = train['Id']\ntest_ID = test['Id']\n# Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain.drop(['Id'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)\n\n# Deleting outliers\ntrain = train[train.GrLivArea < 4500]\ntrain.reset_index(drop=True, inplace=True)\n\n# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\ny = train.SalePrice.reset_index(drop=True)\ntrain_features = train.drop(['SalePrice'], axis=1)\ntest_features = test\n\nfeatures = pd.concat([train_features, test_features]).reset_index(drop=True)\nprint(features.shape)\n# Some of the non-numeric predictors are stored as numbers; we convert them into strings \nfeatures['MSSubClass'] = features['MSSubClass'].apply(str)\nfeatures['YrSold'] = features['YrSold'].astype(str)\nfeatures['MoSold'] = features['MoSold'].astype(str)\n\nfeatures['Functional'] = features['Functional'].fillna('Typ')\nfeatures['Electrical'] = features['Electrical'].fillna(\"SBrkr\")\nfeatures['KitchenQual'] = features['KitchenQual'].fillna(\"TA\")\nfeatures['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0])\nfeatures['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\nfeatures['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n\nfeatures[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    features[col] = features[col].fillna(0)\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    features[col] = features[col].fillna('None')\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    features[col] = features[col].fillna('None')\n\nfeatures['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n\nobjects = []\nfor i in features.columns:\n    if features[i].dtype == object:\n        objects.append(i)\n\nfeatures.update(features[objects].fillna('None'))\n\nfeatures['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\n# Filling in the rest of the NA's\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics = []\nfor i in features.columns:\n    if features[i].dtype in numeric_dtypes:\n        numerics.append(i)\nfeatures.update(features[numerics].fillna(0))\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics2 = []\nfor i in features.columns:\n    if features[i].dtype in numeric_dtypes:\n        numerics2.append(i)\n\nskew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nfor i in skew_index:\n    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))\n\nfeatures = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n\nfeatures['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\nfeatures['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n\nfeatures['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n                                 features['1stFlrSF'] + features['2ndFlrSF'])\n\nfeatures['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n\nfeatures['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n                              features['EnclosedPorch'] + features['ScreenPorch'] +\n                              features['WoodDeckSF'])\n\n# simplified features\nfeatures['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nfeatures['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n\nprint(features.shape)\nfinal_features = pd.get_dummies(features).reset_index(drop=True)\nprint(final_features.shape)\n\nX = final_features.iloc[:len(y), :]\nX_sub = final_features.iloc[len(X):, :]\n\nprint('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n\noutliers = [30, 88, 462, 631, 1322]\nX = X.drop(X.index[outliers])\ny = y.drop(y.index[outliers])\n\noverfit = []\nfor i in X.columns:\n    counts = X[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros / len(X) * 100 > 99.94:\n        overfit.append(i)\n\noverfit = list(overfit)\noverfit.append('MSZoning_C (all)')\n\nX = X.drop(overfit, axis=1).copy()\nX_sub = X_sub.drop(overfit, axis=1).copy()\n\nprint('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n\n# ################## ML ########################################\nprint('START ML', datetime.now(), )\n\nkfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n\n\n# rmsle\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\n\n# build our model scoring function\ndef cv_rmse(model, X=X):\n    rmse = np.sqrt(-cross_val_score(model, X, y,\n                                    scoring=\"neg_mean_squared_error\",\n                                    cv=kfolds))\n    return (rmse)\n\n\n# setup models    \nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n\nridge = make_pipeline(RobustScaler(),\n                      RidgeCV(alphas=alphas_alt, cv=kfolds))\n\nlasso = make_pipeline(RobustScaler(),\n                      LassoCV(max_iter=1e7, alphas=alphas2,\n                              random_state=42, cv=kfolds))\n\nelasticnet = make_pipeline(RobustScaler(),\n                           ElasticNetCV(max_iter=1e7, alphas=e_alphas,\n                                        cv=kfolds, l1_ratio=e_l1ratio))\n                                        \nsvr = make_pipeline(RobustScaler(),\n                      SVR(C= 20, epsilon= 0.008, gamma=0.0003,))\n\n\ngbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =42)\n                                   \n\nlightgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=5000,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose=-1,\n                                       #min_data_in_leaf=2,\n                                       #min_sum_hessian_in_leaf=11\n                                       )\n                                       \n\nxgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n                                     max_depth=3, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,\n                                     objective='reg:linear', nthread=-1,\n                                     scale_pos_weight=1, seed=27,\n                                     reg_alpha=0.00006)\n\n# stack\nstack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet,\n                                            gbr, xgboost, lightgbm),\n                                meta_regressor=xgboost,\n                                use_features_in_secondary=True)\n                                \n\nprint('TEST score on CV')\n\nscore = cv_rmse(ridge)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(lasso)\nprint(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(elasticnet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(svr)\nprint(\"SVR score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(lightgbm)\nprint(\"Lightgbm score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(gbr)\nprint(\"GradientBoosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\nscore = cv_rmse(xgboost)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n\n\nprint('START Fit')\nprint(datetime.now(), 'StackingCVRegressor')\nstack_gen_model = stack_gen.fit(np.array(X), np.array(y))\nprint(datetime.now(), 'elasticnet')\nelastic_model_full_data = elasticnet.fit(X, y)\nprint(datetime.now(), 'lasso')\nlasso_model_full_data = lasso.fit(X, y)\nprint(datetime.now(), 'ridge')\nridge_model_full_data = ridge.fit(X, y)\nprint(datetime.now(), 'svr')\nsvr_model_full_data = svr.fit(X, y)\nprint(datetime.now(), 'GradientBoosting')\ngbr_model_full_data = gbr.fit(X, y)\nprint(datetime.now(), 'xgboost')\nxgb_model_full_data = xgboost.fit(X, y)\nprint(datetime.now(), 'lightgbm')\nlgb_model_full_data = lightgbm.fit(X, y)\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def blend_models_predict(X):\n    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n            (0.1 * lasso_model_full_data.predict(X)) + \\\n            (0.1 * ridge_model_full_data.predict(X)) + \\\n            (0.1 * svr_model_full_data.predict(X)) + \\\n            (0.1 * gbr_model_full_data.predict(X)) + \\\n            (0.15 * xgb_model_full_data.predict(X)) + \\\n            (0.1 * lgb_model_full_data.predict(X)) + \\\n            (0.25 * stack_gen_model.predict(np.array(X))))\n            \nprint('RMSLE score on train data:')\nprint(rmsle(y, blend_models_predict(X)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Predict submission', datetime.now(),)\nsubmission = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")\nsubmission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))\n\n# this kernel gave a score 0.114\n# let's up it by mixing with the top kernels\n\nprint('Blend with Top Kernals submissions', datetime.now(),)\nsub_1 = pd.read_csv('../input/top-10-0-10943-stacking-mice-and-brutal-force/House_Prices_submit.csv')\nsub_2 = pd.read_csv('../input/hybrid-svm-benchmark-approach-0-11180-lb-top-2/hybrid_solution.csv')\nsub_3 = pd.read_csv('../input/lasso-model-for-regression-problem/lasso_sol22_Median.csv')\n\nsubmission.iloc[:,1] = np.floor((0.25 * np.floor(np.expm1(blend_models_predict(X_sub)))) + \n                                (0.25 * sub_1.iloc[:,1]) + \n                                (0.25 * sub_2.iloc[:,1]) + \n                                (0.25 * sub_3.iloc[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Brutal approach to deal with predictions close to outer range \nq1 = submission['SalePrice'].quantile(0.0045)\nq2 = submission['SalePrice'].quantile(0.99)\n\nsubmission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\nsubmission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\n\nsubmission.to_csv(\"new_submission.csv\", index=False)\nprint('Save submission', datetime.now(),)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/my-best-house-price/House_0.10649.csv')\nsubmission.to_csv('best_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}