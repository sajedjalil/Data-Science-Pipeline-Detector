{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"toc_section\"></a>\n## Contents of this notebook\n\n[**Raghav Rastogi**](https://www.kaggle.com/raghavrastogi75) \n\n\n* [Introduction](#1)\n* [Data Import](#2)\n* [Data Cleaning](#3)\n* [Data Preprocessing and feature engineering](#4)\n    - [Handling missing values and combining/reducing the features](#5)\n    - [Finding the most important features in the dataset](#6)\n* [Preparing the test and train dataset](#7)\n* [Finding best hyperparameters](#8)\n    - [Lasso](#9)\n    - [Ridge](#10)\n    - [Elastic Net](#11)\n    - [Gradient Boost Regression](#12)\n    - [LightGBM](#13)\n    - [XGBoost](#14)\n* [Creating all models](#15)\n* [Preprocessing of test set](#16)\n* [Creating Blended Model](#17)\n* [Prediction](#18)","metadata":{}},{"cell_type":"markdown","source":"# Introduction<span id=\"1\"></span>\n","metadata":{}},{"cell_type":"markdown","source":"## If you find this notebook helpful please **UPVOTE** and do share your thoughts on what other ways could this result be improved.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Starting with Data Inport<span id=\"2\"></span>","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Having a look at the columns","metadata":{}},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Having a look at the NULL values and type of data","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning<span id=\"3\"></span>","metadata":{}},{"cell_type":"markdown","source":"### Looking at outliers","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize = (10,10))\nplt.scatter(train['GrLivArea'],train['SalePrice'])\nplt.xlabel('Area')\nplt.ylabel('Price')\nplt.title(\"Area vs price\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see that the bottom 2 points could be removed entirely as they vary non-linearly as compared to other data points","metadata":{}},{"cell_type":"code","source":"train = train.loc[(train['GrLivArea'] < 4000) | (train['SalePrice'] > 300000)]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transforming the target variable to log values so that the error is equally impactful to the low and high prices.","metadata":{}},{"cell_type":"code","source":"train['SalePrice'] = np.log1p(train['SalePrice'])\ny = train.SalePrice\n# train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing and feature engineering<span id=\"4\"></span>","metadata":{}},{"cell_type":"markdown","source":"### Handling missing values and combining/reducing the features while still holding the information <span id=\"5\"></span>\n\n* Every explanation is below the code cell","metadata":{}},{"cell_type":"code","source":"# Handle missing values for features where median/mean or most common value doesn't make sense\n\n# Alley : data description says NA means \"no alley access\"\ntrain.loc[:, \"Alley\"] = train.loc[:, \"Alley\"].fillna(\"None\")\n# BedroomAbvGr : NA most likely means 0\ntrain.loc[:, \"BedroomAbvGr\"] = train.loc[:, \"BedroomAbvGr\"].fillna(0)\n# BsmtQual etc : data description says NA for basement features is \"no basement\"\ntrain.loc[:, \"BsmtQual\"] = train.loc[:, \"BsmtQual\"].fillna(\"No\")\ntrain.loc[:, \"BsmtCond\"] = train.loc[:, \"BsmtCond\"].fillna(\"No\")\ntrain.loc[:, \"BsmtExposure\"] = train.loc[:, \"BsmtExposure\"].fillna(\"No\")\ntrain.loc[:, \"BsmtFinType1\"] = train.loc[:, \"BsmtFinType1\"].fillna(\"No\")\ntrain.loc[:, \"BsmtFinType2\"] = train.loc[:, \"BsmtFinType2\"].fillna(\"No\")\ntrain.loc[:, \"BsmtFullBath\"] = train.loc[:, \"BsmtFullBath\"].fillna(0)\ntrain.loc[:, \"BsmtHalfBath\"] = train.loc[:, \"BsmtHalfBath\"].fillna(0)\ntrain.loc[:, \"BsmtUnfSF\"] = train.loc[:, \"BsmtUnfSF\"].fillna(0)\n# CentralAir : NA most likely means No\ntrain.loc[:, \"CentralAir\"] = train.loc[:, \"CentralAir\"].fillna(\"N\")\n# Condition : NA most likely means Normal\ntrain.loc[:, \"Condition1\"] = train.loc[:, \"Condition1\"].fillna(\"Norm\")\ntrain.loc[:, \"Condition2\"] = train.loc[:, \"Condition2\"].fillna(\"Norm\")\n# EnclosedPorch : NA most likely means no enclosed porch\ntrain.loc[:, \"EnclosedPorch\"] = train.loc[:, \"EnclosedPorch\"].fillna(0)\n# External stuff : NA most likely means average\ntrain.loc[:, \"ExterCond\"] = train.loc[:, \"ExterCond\"].fillna(\"TA\")\ntrain.loc[:, \"ExterQual\"] = train.loc[:, \"ExterQual\"].fillna(\"TA\")\n# Fence : data description says NA means \"no fence\"\ntrain.loc[:, \"Fence\"] = train.loc[:, \"Fence\"].fillna(\"No\")\n# FireplaceQu : data description says NA means \"no fireplace\"\ntrain.loc[:, \"FireplaceQu\"] = train.loc[:, \"FireplaceQu\"].fillna(\"No\")\ntrain.loc[:, \"Fireplaces\"] = train.loc[:, \"Fireplaces\"].fillna(0)\n# Functional : data description says NA means typical\ntrain.loc[:, \"Functional\"] = train.loc[:, \"Functional\"].fillna(\"Typ\")\n# GarageType etc : data description says NA for garage features is \"no garage\"\ntrain.loc[:, \"GarageType\"] = train.loc[:, \"GarageType\"].fillna(\"No\")\ntrain.loc[:, \"GarageFinish\"] = train.loc[:, \"GarageFinish\"].fillna(\"No\")\ntrain.loc[:, \"GarageQual\"] = train.loc[:, \"GarageQual\"].fillna(\"No\")\ntrain.loc[:, \"GarageCond\"] = train.loc[:, \"GarageCond\"].fillna(\"No\")\ntrain.loc[:, \"GarageArea\"] = train.loc[:, \"GarageArea\"].fillna(0)\ntrain.loc[:, \"GarageCars\"] = train.loc[:, \"GarageCars\"].fillna(0)\n# HalfBath : NA most likely means no half baths above grade\ntrain.loc[:, \"HalfBath\"] = train.loc[:, \"HalfBath\"].fillna(0)\n# HeatingQC : NA most likely means typical\ntrain.loc[:, \"HeatingQC\"] = train.loc[:, \"HeatingQC\"].fillna(\"TA\")\n# KitchenAbvGr : NA most likely means 0\ntrain.loc[:, \"KitchenAbvGr\"] = train.loc[:, \"KitchenAbvGr\"].fillna(0)\n# KitchenQual : NA most likely means typical\ntrain.loc[:, \"KitchenQual\"] = train.loc[:, \"KitchenQual\"].fillna(\"TA\")\n# LotFrontage : NA most likely means no lot frontage\ntrain.loc[:, \"LotFrontage\"] = train.loc[:, \"LotFrontage\"].fillna(0)\n# LotShape : NA most likely means regular\ntrain.loc[:, \"LotShape\"] = train.loc[:, \"LotShape\"].fillna(\"Reg\")\n# MasVnrType : NA most likely means no veneer\ntrain.loc[:, \"MasVnrType\"] = train.loc[:, \"MasVnrType\"].fillna(\"None\")\ntrain.loc[:, \"MasVnrArea\"] = train.loc[:, \"MasVnrArea\"].fillna(0)\n# MiscFeature : data description says NA means \"no misc feature\"\ntrain.loc[:, \"MiscFeature\"] = train.loc[:, \"MiscFeature\"].fillna(\"No\")\ntrain.loc[:, \"MiscVal\"] = train.loc[:, \"MiscVal\"].fillna(0)\n# OpenPorchSF : NA most likely means no open porch\ntrain.loc[:, \"OpenPorchSF\"] = train.loc[:, \"OpenPorchSF\"].fillna(0)\n# PavedDrive : NA most likely means not paved\ntrain.loc[:, \"PavedDrive\"] = train.loc[:, \"PavedDrive\"].fillna(\"N\")\n# PoolQC : data description says NA means \"no pool\"\ntrain.loc[:, \"PoolQC\"] = train.loc[:, \"PoolQC\"].fillna(\"No\")\ntrain.loc[:, \"PoolArea\"] = train.loc[:, \"PoolArea\"].fillna(0)\n# SaleCondition : NA most likely means normal sale\ntrain.loc[:, \"SaleCondition\"] = train.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n# ScreenPorch : NA most likely means no screen porch\ntrain.loc[:, \"ScreenPorch\"] = train.loc[:, \"ScreenPorch\"].fillna(0)\n# TotRmsAbvGrd : NA most likely means 0\ntrain.loc[:, \"TotRmsAbvGrd\"] = train.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n# Utilities : NA most likely means all public utilities\ntrain.loc[:, \"Utilities\"] = train.loc[:, \"Utilities\"].fillna(\"AllPub\")\n# WoodDeckSF : NA most likely means no wood deck\ntrain.loc[:, \"WoodDeckSF\"] = train.loc[:, \"WoodDeckSF\"].fillna(0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are trying to remove every Null value with the best possible alternative. I made the initial mistake of generalising everything initially and trying to \"Get Over\" this step. But I realise now how important this is to improve the results.","metadata":{}},{"cell_type":"code","source":"# Some numerical features are actually really categories\ntrain = train.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n                                       150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n                      })","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we are removing the numerical data from the orignal categories and representing them in categorical data.","metadata":{}},{"cell_type":"code","source":"# Encode some categorical features as ordered numbers when there is information in the order\ntrain = train.replace({\"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n                       \"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n                       \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n                                         \"ALQ\" : 5, \"GLQ\" : 6},\n                       \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n                                         \"ALQ\" : 5, \"GLQ\" : 6},\n                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n                       \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n                       \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n                       \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n                       \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}}\n                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are trying to extract more useful information by converting categorical data to numerical by the degree of its quality. This makes the data highlt usable by reducing the dimensions which would have been otherwise created by One Hot Encoding.","metadata":{}},{"cell_type":"code","source":"train[\"SimplOverallQual\"] = train.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, # bad\n                                                       4 : 2, 5 : 2, 6 : 2, # average\n                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                                      })\ntrain[\"SimplOverallCond\"] = train.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, # bad\n                                                       4 : 2, 5 : 2, 6 : 2, # average\n                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                                      })\ntrain[\"SimplPoolQC\"] = train.PoolQC.replace({1 : 1, 2 : 1, # average\n                                             3 : 2, 4 : 2 # good\n                                            })\ntrain[\"SimplGarageCond\"] = train.GarageCond.replace({1 : 1, # bad\n                                                     2 : 1, 3 : 1, # average\n                                                     4 : 2, 5 : 2 # good\n                                                    })\ntrain[\"SimplGarageQual\"] = train.GarageQual.replace({1 : 1, # bad\n                                                     2 : 1, 3 : 1, # average\n                                                     4 : 2, 5 : 2 # good\n                                                    })\ntrain[\"SimplFireplaceQu\"] = train.FireplaceQu.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\ntrain[\"SimplFireplaceQu\"] = train.FireplaceQu.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\ntrain[\"SimplFunctional\"] = train.Functional.replace({1 : 1, 2 : 1, # bad\n                                                     3 : 2, 4 : 2, # major\n                                                     5 : 3, 6 : 3, 7 : 3, # minor\n                                                     8 : 4 # typical\n                                                    })\ntrain[\"SimplKitchenQual\"] = train.KitchenQual.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\ntrain[\"SimplHeatingQC\"] = train.HeatingQC.replace({1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  })\ntrain[\"SimplBsmtFinType1\"] = train.BsmtFinType1.replace({1 : 1, # unfinished\n                                                         2 : 1, 3 : 1, # rec room\n                                                         4 : 2, 5 : 2, 6 : 2 # living quarters\n                                                        })\ntrain[\"SimplBsmtFinType2\"] = train.BsmtFinType2.replace({1 : 1, # unfinished\n                                                         2 : 1, 3 : 1, # rec room\n                                                         4 : 2, 5 : 2, 6 : 2 # living quarters\n                                                        })\ntrain[\"SimplBsmtCond\"] = train.BsmtCond.replace({1 : 1, # bad\n                                                 2 : 1, 3 : 1, # average\n                                                 4 : 2, 5 : 2 # good\n                                                })\ntrain[\"SimplBsmtQual\"] = train.BsmtQual.replace({1 : 1, # bad\n                                                 2 : 1, 3 : 1, # average\n                                                 4 : 2, 5 : 2 # good\n                                                })\ntrain[\"SimplExterCond\"] = train.ExterCond.replace({1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  })\ntrain[\"SimplExterQual\"] = train.ExterQual.replace({1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  })\n# 2* Combinations of existing features\n# Overall quality of the house\ntrain[\"OverallGrade\"] = train[\"OverallQual\"] * train[\"OverallCond\"]\n# Overall quality of the garage\ntrain[\"GarageGrade\"] = train[\"GarageQual\"] * train[\"GarageCond\"]\n# Overall quality of the exterior\ntrain[\"ExterGrade\"] = train[\"ExterQual\"] * train[\"ExterCond\"]\n# Overall kitchen score\ntrain[\"KitchenScore\"] = train[\"KitchenAbvGr\"] * train[\"KitchenQual\"]\n# Overall fireplace score\ntrain[\"FireplaceScore\"] = train[\"Fireplaces\"] * train[\"FireplaceQu\"]\n# Overall garage score\ntrain[\"GarageScore\"] = train[\"GarageArea\"] * train[\"GarageQual\"]\n# Overall pool score\ntrain[\"PoolScore\"] = train[\"PoolArea\"] * train[\"PoolQC\"]\n# Simplified overall quality of the house\ntrain[\"SimplOverallGrade\"] = train[\"SimplOverallQual\"] * train[\"SimplOverallCond\"]\n# Simplified overall quality of the exterior\ntrain[\"SimplExterGrade\"] = train[\"SimplExterQual\"] * train[\"SimplExterCond\"]\n# Simplified overall pool score\ntrain[\"SimplPoolScore\"] = train[\"PoolArea\"] * train[\"SimplPoolQC\"]\n# Simplified overall garage score\ntrain[\"SimplGarageScore\"] = train[\"GarageArea\"] * train[\"SimplGarageQual\"]\n# Simplified overall fireplace score\ntrain[\"SimplFireplaceScore\"] = train[\"Fireplaces\"] * train[\"SimplFireplaceQu\"]\n# Simplified overall kitchen score\ntrain[\"SimplKitchenScore\"] = train[\"KitchenAbvGr\"] * train[\"SimplKitchenQual\"]\n# Total number of bathrooms\ntrain[\"TotalBath\"] = train[\"BsmtFullBath\"] + (0.5 * train[\"BsmtHalfBath\"]) + \\\ntrain[\"FullBath\"] + (0.5 * train[\"HalfBath\"])\n# Total SF for house (incl. basement)\ntrain[\"AllSF\"] = train[\"GrLivArea\"] + train[\"TotalBsmtSF\"]\n# Total SF for 1st + 2nd floors\ntrain[\"AllFlrsSF\"] = train[\"1stFlrSF\"] + train[\"2ndFlrSF\"]\n# Total SF for porch\ntrain[\"AllPorchSF\"] = train[\"OpenPorchSF\"] + train[\"EnclosedPorch\"] + \\\ntrain[\"3SsnPorch\"] + train[\"ScreenPorch\"]\n# Has masonry veneer or not\ntrain[\"HasMasVnr\"] = train.MasVnrType.replace({\"BrkCmn\" : 1, \"BrkFace\" : 1, \"CBlock\" : 1, \n                                               \"Stone\" : 1, \"None\" : 0})\n# House completed before sale or not\ntrain[\"BoughtOffPlan\"] = train.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \n                                                      \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are two key steps performed here. First one being to reduce the number of categories by combinig the values to lesser number. This takes away some load on the model when we create the complete the data set after one hot encoding. The second one being to again combining the features itself that would contain the information of multiple columns in one omre concide format.","metadata":{}},{"cell_type":"markdown","source":"### Finding the most important features in the dataset <span id=\"6\"></span>","metadata":{}},{"cell_type":"code","source":"print(\"Find most important features relative to target\")\ncorr = train.corr()\ncorr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n#print(corr.SalePrice)\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n    print(corr.SalePrice)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can look at the most correlated attributes which will be an important factor while predicting the results.","metadata":{}},{"cell_type":"code","source":"# Create new features\n# 3* Polynomials on the top 10 existing features\ntrain[\"OverallQual-s2\"] = train[\"OverallQual\"] ** 2\ntrain[\"OverallQual-s3\"] = train[\"OverallQual\"] ** 3\ntrain[\"OverallQual-Sq\"] = np.sqrt(train[\"OverallQual\"])\ntrain[\"AllSF-2\"] = train[\"AllSF\"] ** 2\ntrain[\"AllSF-3\"] = train[\"AllSF\"] ** 3\ntrain[\"AllSF-Sq\"] = np.sqrt(train[\"AllSF\"])\ntrain[\"AllFlrsSF-2\"] = train[\"AllFlrsSF\"] ** 2\ntrain[\"AllFlrsSF-3\"] = train[\"AllFlrsSF\"] ** 3\ntrain[\"AllFlrsSF-Sq\"] = np.sqrt(train[\"AllFlrsSF\"])\ntrain[\"GrLivArea-2\"] = train[\"GrLivArea\"] ** 2\ntrain[\"GrLivArea-3\"] = train[\"GrLivArea\"] ** 3\ntrain[\"GrLivArea-Sq\"] = np.sqrt(train[\"GrLivArea\"])\ntrain[\"SimplOverallQual-s2\"] = train[\"SimplOverallQual\"] ** 2\ntrain[\"SimplOverallQual-s3\"] = train[\"SimplOverallQual\"] ** 3\ntrain[\"SimplOverallQual-Sq\"] = np.sqrt(train[\"SimplOverallQual\"])\ntrain[\"ExterQual-2\"] = train[\"ExterQual\"] ** 2\ntrain[\"ExterQual-3\"] = train[\"ExterQual\"] ** 3\ntrain[\"ExterQual-Sq\"] = np.sqrt(train[\"ExterQual\"])\ntrain[\"GarageCars-2\"] = train[\"GarageCars\"] ** 2\ntrain[\"GarageCars-3\"] = train[\"GarageCars\"] ** 3\ntrain[\"GarageCars-Sq\"] = np.sqrt(train[\"GarageCars\"])\ntrain[\"TotalBath-2\"] = train[\"TotalBath\"] ** 2\ntrain[\"TotalBath-3\"] = train[\"TotalBath\"] ** 3\ntrain[\"TotalBath-Sq\"] = np.sqrt(train[\"TotalBath\"])\ntrain[\"KitchenQual-2\"] = train[\"KitchenQual\"] ** 2\ntrain[\"KitchenQual-3\"] = train[\"KitchenQual\"] ** 3\ntrain[\"KitchenQual-Sq\"] = np.sqrt(train[\"KitchenQual\"])\ntrain[\"GarageScore-2\"] = train[\"GarageScore\"] ** 2\ntrain[\"GarageScore-3\"] = train[\"GarageScore\"] ** 3\ntrain[\"GarageScore-Sq\"] = np.sqrt(train[\"GarageScore\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aim here is to create multiple features from highly correlated features which might help enhance the prediction. This could be taken from simple example which shows that squaring of the features makes data linearly separable. We can extrapolate this result to even power of 3.","metadata":{}},{"cell_type":"code","source":"cat_features = train.select_dtypes(include = [\"object\"]).columns\nnum_features = train.select_dtypes(exclude = [\"object\"]).columns\nnum_features = num_features.drop('SalePrice')\ntrain_num = train[num_features]\ntrain_cat = train[cat_features]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now differentiate the categorical features and numerical features to perform the preprocessing accordingly.","metadata":{}},{"cell_type":"code","source":"print(\"before\",train_num.isnull().values.sum())\ntrain_num = train_num.fillna(train_num.median())\nprint(\"after\",train_num.isnull().values.sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Handling remaining missing values by replacing it with median of the values.","metadata":{}},{"cell_type":"code","source":"from scipy.stats import skew\n\nskewness = train_num.apply(lambda x: skew(x))\nskewness = skewness[abs(skewness) > 0.5]\nskewed_features = skewness.index\ntrain_num[skewed_features] = np.log1p(train_num[skewed_features])\n#print(skewed_features)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transforming all the skewed values to log values to lessen the impact of outliers","metadata":{}},{"cell_type":"code","source":"train_cat = pd.get_dummies(train_cat)\nprint(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Applying one hot encoding to the categorical variables","metadata":{}},{"cell_type":"markdown","source":"# Preparing the test and train dataset <span id=\"7\"></span>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Join categorical and numerical features\ntrain = pd.concat([train_num, train_cat], axis = 1)\n\n# Partition the dataset in train + validation sets\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size = 0.3, random_state = 42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Applying Standard Scaler to the numerical dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstdSc = StandardScaler()\nX_train.loc[:, num_features] = stdSc.fit_transform(X_train.loc[:, num_features])\nX_test.loc[:, num_features] = stdSc.transform(X_test.loc[:, num_features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finding best hyperparameters<span id=\"8\"></span>","metadata":{}},{"cell_type":"markdown","source":"## Our first goal is to create the models and find their best hyperparameters by running the model individually by gridsearch cross validation.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.model_selection import KFold, cross_val_score\n\nridge = Ridge()\n\nlasso = Lasso()\n\nelasticnet = ElasticNet()\n\ngbr = GradientBoostingRegressor()\n\nlightgbm = LGBMRegressor()\n\nxgboost = XGBRegressor()\n\nscvr = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n                           meta_regressor=xgboost,\n                           use_features_in_secondary=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finding best parameters for each model\n## I have marked them in comments as they take a lot of time to run and I have already found out the best parameters after running them multiple times\n\n### Lasso<span id=\"9\"></span>\n","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n# param_grid = [{'alpha': [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]}]\n# grid_search = GridSearchCV(lasso, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n# grid_search.fit(X_train,y_train)\n# print(grid_search.best_params_)\n# np.sqrt(-grid_search.score(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ridge<span id=\"10\"></span>","metadata":{}},{"cell_type":"code","source":"# param_grid = [{'alpha': [11.5,11.6,11.7,11.8,11.9,12,12.1,12.2,12.3]}]\n# grid_search = GridSearchCV(ridge, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n# grid_search.fit(X_train,y_train)\n# print(grid_search.best_params_)\n# np.sqrt(-grid_search.score(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Elasticnet<span id=\"11\"></span>","metadata":{}},{"cell_type":"code","source":"# param_grid = [{'alpha': [0.001,0.0001,0.005]}]\n# grid_search = GridSearchCV(elasticnet, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n# grid_search.fit(X_train,y_train)\n# print(grid_search.best_params_)\n# np.sqrt(-grid_search.score(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boost Regressor<span id=\"12\"></span>","metadata":{}},{"cell_type":"code","source":"# param_grid = [{'n_estimators' : [3000,100], 'learning_rate':[0.05,0.1,0.005], 'max_depth':[1,4,8], 'max_features':['sqrt',320,80],\n#               'min_samples_leaf':[15], 'min_samples_split':[10], 'loss':['huber']}]\n# grid_search = GridSearchCV(gbr, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n# grid_search.fit(X_train,y_train)\n# print(grid_search.best_params_)\n# np.sqrt(-grid_search.score(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LightGBM <span id=\"13\"></span>","metadata":{}},{"cell_type":"code","source":"# param_grid = [{'num_leaves':[4,40,100], 'learning_rate': [0.01,0.1,1], 'n_estimators':[5000,500]}]\n# grid_search = GridSearchCV(lightgbm, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n# grid_search.fit(X_train,y_train)\n# print(grid_search.best_params_)\n# np.sqrt(-grid_search.score(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost<span id=\"14\"></span>","metadata":{}},{"cell_type":"code","source":"# param_grid = [{'learning_rate' : [0.01 , 0.1,1] ,'n_estimators' : [1000,3500,5000], 'max_depth' : [3,5,10]}]\n# grid_search = GridSearchCV(xgboost, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n# grid_search.fit(X_train,y_train)\n# print(grid_search.best_params_)\n# np.sqrt(-grid_search.score(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating all the models with the best hyperparmeters <span id=\"15\"></span>","metadata":{}},{"cell_type":"code","source":"lasso = Lasso(alpha = 0.0005)\nridge = Ridge(alpha = 11.9)\nelasticnet = ElasticNet(alpha = 0.001)\ngbr = GradientBoostingRegressor(learning_rate = 0.1, loss = 'huber', max_depth = 1, max_features ='sqrt',\n                                min_samples_leaf = 15, min_samples_split = 10, n_estimators =3000)\nlightgbm = LGBMRegressor(learning_rate = 0.01, n_estimators = 5000, num_leaves = 4)\nxgboost = XGBRegressor(learning_rate = 0.01, max_depth = 3, n_estimators = 3500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scvr = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n                                meta_regressor=xgboost,\n                                use_features_in_secondary=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Note here that I have trained the model multiple times using X_train and y_train. But at the end to create the best model, I have fitted the algorithm with the complete training data.","metadata":{}},{"cell_type":"code","source":"train.loc[:, num_features] = stdSc.fit_transform(train.loc[:, num_features])\n\nrmse_list = []\nmodels = [lasso,ridge,elasticnet,gbr,lightgbm,xgboost]\nscvr.fit(np.array(train),np.array(y))\ny_pred = scvr.predict(np.array(X_test))\nrmse_list.append(mean_squared_error(y_test,y_pred,squared = False))\nfor i in models:\n    i.fit(train,y)\n    y_pred = i.predict(X_test)\n    rmse_list.append(mean_squared_error(y_test,y_pred,squared = False))\nprint(rmse_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get extremely low error here as the data already knows what to expect as we have trained the model with the complete dataset. However, I got decent enough results when I tested it with the X_train and X_test. I created the list of all models and fitted each one with the best parameters on the data.","metadata":{}},{"cell_type":"markdown","source":"# We now perform the entire preprocessing activity that we did for training set to the test set provided. <span id=\"16\"></span>","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handle missing values for features where median/mean or most common value doesn't make sense\n\n# Alley : data description says NA means \"no alley access\"\ntest.loc[:, \"Alley\"] = test.loc[:, \"Alley\"].fillna(\"None\")\n# BedroomAbvGr : NA most likely means 0\ntest.loc[:, \"BedroomAbvGr\"] = test.loc[:, \"BedroomAbvGr\"].fillna(0)\n# BsmtQual etc : data description says NA for basement features is \"no basement\"\ntest.loc[:, \"BsmtQual\"] = test.loc[:, \"BsmtQual\"].fillna(\"No\")\ntest.loc[:, \"BsmtCond\"] = test.loc[:, \"BsmtCond\"].fillna(\"No\")\ntest.loc[:, \"BsmtExposure\"] = test.loc[:, \"BsmtExposure\"].fillna(\"No\")\ntest.loc[:, \"BsmtFinType1\"] = test.loc[:, \"BsmtFinType1\"].fillna(\"No\")\ntest.loc[:, \"BsmtFinType2\"] = test.loc[:, \"BsmtFinType2\"].fillna(\"No\")\ntest.loc[:, \"BsmtFullBath\"] = test.loc[:, \"BsmtFullBath\"].fillna(0)\ntest.loc[:, \"BsmtHalfBath\"] = test.loc[:, \"BsmtHalfBath\"].fillna(0)\ntest.loc[:, \"BsmtUnfSF\"] = test.loc[:, \"BsmtUnfSF\"].fillna(0)\n# CentralAir : NA most likely means No\ntest.loc[:, \"CentralAir\"] = test.loc[:, \"CentralAir\"].fillna(\"N\")\n# Condition : NA most likely means Normal\ntest.loc[:, \"Condition1\"] = test.loc[:, \"Condition1\"].fillna(\"Norm\")\ntest.loc[:, \"Condition2\"] = test.loc[:, \"Condition2\"].fillna(\"Norm\")\n# EnclosedPorch : NA most likely means no enclosed porch\ntest.loc[:, \"EnclosedPorch\"] = test.loc[:, \"EnclosedPorch\"].fillna(0)\n# External stuff : NA most likely means average\ntest.loc[:, \"ExterCond\"] = test.loc[:, \"ExterCond\"].fillna(\"TA\")\ntest.loc[:, \"ExterQual\"] = test.loc[:, \"ExterQual\"].fillna(\"TA\")\n# Fence : data description says NA means \"no fence\"\ntest.loc[:, \"Fence\"] = test.loc[:, \"Fence\"].fillna(\"No\")\n# FireplaceQu : data description says NA means \"no fireplace\"\ntest.loc[:, \"FireplaceQu\"] = test.loc[:, \"FireplaceQu\"].fillna(\"No\")\ntest.loc[:, \"Fireplaces\"] = test.loc[:, \"Fireplaces\"].fillna(0)\n# Functional : data description says NA means typical\ntest.loc[:, \"Functional\"] = test.loc[:, \"Functional\"].fillna(\"Typ\")\n# GarageType etc : data description says NA for garage features is \"no garage\"\ntest.loc[:, \"GarageType\"] = test.loc[:, \"GarageType\"].fillna(\"No\")\ntest.loc[:, \"GarageFinish\"] = test.loc[:, \"GarageFinish\"].fillna(\"No\")\ntest.loc[:, \"GarageQual\"] = test.loc[:, \"GarageQual\"].fillna(\"No\")\ntest.loc[:, \"GarageCond\"] = test.loc[:, \"GarageCond\"].fillna(\"No\")\ntest.loc[:, \"GarageArea\"] = test.loc[:, \"GarageArea\"].fillna(0)\ntest.loc[:, \"GarageCars\"] = test.loc[:, \"GarageCars\"].fillna(0)\n# HalfBath : NA most likely means no half baths above grade\ntest.loc[:, \"HalfBath\"] = test.loc[:, \"HalfBath\"].fillna(0)\n# HeatingQC : NA most likely means typical\ntest.loc[:, \"HeatingQC\"] = test.loc[:, \"HeatingQC\"].fillna(\"TA\")\n# KitchenAbvGr : NA most likely means 0\ntest.loc[:, \"KitchenAbvGr\"] = test.loc[:, \"KitchenAbvGr\"].fillna(0)\n# KitchenQual : NA most likely means typical\ntest.loc[:, \"KitchenQual\"] = test.loc[:, \"KitchenQual\"].fillna(\"TA\")\n# LotFrontage : NA most likely means no lot frontage\ntest.loc[:, \"LotFrontage\"] = test.loc[:, \"LotFrontage\"].fillna(0)\n# LotShape : NA most likely means regular\ntest.loc[:, \"LotShape\"] = test.loc[:, \"LotShape\"].fillna(\"Reg\")\n# MasVnrType : NA most likely means no veneer\ntest.loc[:, \"MasVnrType\"] = test.loc[:, \"MasVnrType\"].fillna(\"None\")\ntest.loc[:, \"MasVnrArea\"] = test.loc[:, \"MasVnrArea\"].fillna(0)\n# MiscFeature : data description says NA means \"no misc feature\"\ntest.loc[:, \"MiscFeature\"] = test.loc[:, \"MiscFeature\"].fillna(\"No\")\ntest.loc[:, \"MiscVal\"] = test.loc[:, \"MiscVal\"].fillna(0)\n# OpenPorchSF : NA most likely means no open porch\ntest.loc[:, \"OpenPorchSF\"] = test.loc[:, \"OpenPorchSF\"].fillna(0)\n# PavedDrive : NA most likely means not paved\ntest.loc[:, \"PavedDrive\"] = test.loc[:, \"PavedDrive\"].fillna(\"N\")\n# PoolQC : data description says NA means \"no pool\"\ntest.loc[:, \"PoolQC\"] = test.loc[:, \"PoolQC\"].fillna(\"No\")\ntest.loc[:, \"PoolArea\"] = test.loc[:, \"PoolArea\"].fillna(0)\n# SaleCondition : NA most likely means normal sale\ntest.loc[:, \"SaleCondition\"] = test.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n# ScreenPorch : NA most likely means no screen porch\ntest.loc[:, \"ScreenPorch\"] = test.loc[:, \"ScreenPorch\"].fillna(0)\n# TotRmsAbvGrd : NA most likely means 0\ntest.loc[:, \"TotRmsAbvGrd\"] = test.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n# Utilities : NA most likely means all public utilities\ntest.loc[:, \"Utilities\"] = test.loc[:, \"Utilities\"].fillna(\"AllPub\")\n# WoodDeckSF : NA most likely means no wood deck\ntest.loc[:, \"WoodDeckSF\"] = test.loc[:, \"WoodDeckSF\"].fillna(0)\n","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some numerical features are actually really categories\ntest = test.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n                                       150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n                      })","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode some categorical features as ordered numbers when there is information in the order\ntest = test.replace({\"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n                       \"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n                       \"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n                                         \"ALQ\" : 5, \"GLQ\" : 6},\n                       \"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n                                         \"ALQ\" : 5, \"GLQ\" : 6},\n                       \"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n                       \"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n                       \"GarageCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"GarageQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n                       \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n                       \"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n                       \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}}\n                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"SimplOverallQual\"] = test.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, # bad\n                                                       4 : 2, 5 : 2, 6 : 2, # average\n                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                                      })\ntest[\"SimplOverallCond\"] = test.OverallCond.replace({1 : 1, 2 : 1, 3 : 1, # bad\n                                                       4 : 2, 5 : 2, 6 : 2, # average\n                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                                      })\ntest[\"SimplPoolQC\"] = test.PoolQC.replace({1 : 1, 2 : 1, # average\n                                             3 : 2, 4 : 2 # good\n                                            })\ntest[\"SimplGarageCond\"] = test.GarageCond.replace({1 : 1, # bad\n                                                     2 : 1, 3 : 1, # average\n                                                     4 : 2, 5 : 2 # good\n                                                    })\ntest[\"SimplGarageQual\"] = test.GarageQual.replace({1 : 1, # bad\n                                                     2 : 1, 3 : 1, # average\n                                                     4 : 2, 5 : 2 # good\n                                                    })\ntest[\"SimplFireplaceQu\"] = test.FireplaceQu.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\ntest[\"SimplFireplaceQu\"] = test.FireplaceQu.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\ntest[\"SimplFunctional\"] = test.Functional.replace({1 : 1, 2 : 1, # bad\n                                                     3 : 2, 4 : 2, # major\n                                                     5 : 3, 6 : 3, 7 : 3, # minor\n                                                     8 : 4 # typical\n                                                    })\ntest[\"SimplKitchenQual\"] = test.KitchenQual.replace({1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      })\ntest[\"SimplHeatingQC\"] = test.HeatingQC.replace({1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  })\ntest[\"SimplBsmtFinType1\"] = test.BsmtFinType1.replace({1 : 1, # unfinished\n                                                         2 : 1, 3 : 1, # rec room\n                                                         4 : 2, 5 : 2, 6 : 2 # living quarters\n                                                        })\ntest[\"SimplBsmtFinType2\"] = test.BsmtFinType2.replace({1 : 1, # unfinished\n                                                         2 : 1, 3 : 1, # rec room\n                                                         4 : 2, 5 : 2, 6 : 2 # living quarters\n                                                        })\ntest[\"SimplBsmtCond\"] = test.BsmtCond.replace({1 : 1, # bad\n                                                 2 : 1, 3 : 1, # average\n                                                 4 : 2, 5 : 2 # good\n                                                })\ntest[\"SimplBsmtQual\"] = test.BsmtQual.replace({1 : 1, # bad\n                                                 2 : 1, 3 : 1, # average\n                                                 4 : 2, 5 : 2 # good\n                                                })\ntest[\"SimplExterCond\"] = test.ExterCond.replace({1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  })\ntest[\"SimplExterQual\"] = test.ExterQual.replace({1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  })\n# 2* Combinations of existing features\n# Overall quality of the house\ntest[\"OverallGrade\"] = test[\"OverallQual\"] * test[\"OverallCond\"]\n# Overall quality of the garage\ntest[\"GarageGrade\"] = test[\"GarageQual\"] * test[\"GarageCond\"]\n# Overall quality of the exterior\ntest[\"ExterGrade\"] = test[\"ExterQual\"] * test[\"ExterCond\"]\n# Overall kitchen score\ntest[\"KitchenScore\"] = test[\"KitchenAbvGr\"] * test[\"KitchenQual\"]\n# Overall fireplace score\ntest[\"FireplaceScore\"] = test[\"Fireplaces\"] * test[\"FireplaceQu\"]\n# Overall garage score\ntest[\"GarageScore\"] = test[\"GarageArea\"] * test[\"GarageQual\"]\n# Overall pool score\ntest[\"PoolScore\"] = test[\"PoolArea\"] * test[\"PoolQC\"]\n# Simplified overall quality of the house\ntest[\"SimplOverallGrade\"] = test[\"SimplOverallQual\"] * test[\"SimplOverallCond\"]\n# Simplified overall quality of the exterior\ntest[\"SimplExterGrade\"] = test[\"SimplExterQual\"] * test[\"SimplExterCond\"]\n# Simplified overall pool score\ntest[\"SimplPoolScore\"] = test[\"PoolArea\"] * test[\"SimplPoolQC\"]\n# Simplified overall garage score\ntest[\"SimplGarageScore\"] = test[\"GarageArea\"] * test[\"SimplGarageQual\"]\n# Simplified overall fireplace score\ntest[\"SimplFireplaceScore\"] = test[\"Fireplaces\"] * test[\"SimplFireplaceQu\"]\n# Simplified overall kitchen score\ntest[\"SimplKitchenScore\"] = test[\"KitchenAbvGr\"] * test[\"SimplKitchenQual\"]\n# Total number of bathrooms\ntest[\"TotalBath\"] = test[\"BsmtFullBath\"] + (0.5 * test[\"BsmtHalfBath\"]) + \\\ntest[\"FullBath\"] + (0.5 * test[\"HalfBath\"])\n# Total SF for house (incl. basement)\ntest[\"AllSF\"] = test[\"GrLivArea\"] + test[\"TotalBsmtSF\"]\n# Total SF for 1st + 2nd floors\ntest[\"AllFlrsSF\"] = test[\"1stFlrSF\"] + test[\"2ndFlrSF\"]\n# Total SF for porch\ntest[\"AllPorchSF\"] = test[\"OpenPorchSF\"] + test[\"EnclosedPorch\"] + \\\ntest[\"3SsnPorch\"] + test[\"ScreenPorch\"]\n# Has masonry veneer or not\ntest[\"HasMasVnr\"] = test.MasVnrType.replace({\"BrkCmn\" : 1, \"BrkFace\" : 1, \"CBlock\" : 1, \n                                               \"Stone\" : 1, \"None\" : 0})\n# House completed before sale or not\ntest[\"BoughtOffPlan\"] = test.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \n                                                      \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create new features\n# 3* Polynomials on the top 10 existing features\ntest[\"OverallQual-s2\"] = test[\"OverallQual\"] ** 2\ntest[\"OverallQual-s3\"] = test[\"OverallQual\"] ** 3\ntest[\"OverallQual-Sq\"] = np.sqrt(test[\"OverallQual\"])\ntest[\"AllSF-2\"] = test[\"AllSF\"] ** 2\ntest[\"AllSF-3\"] = test[\"AllSF\"] ** 3\ntest[\"AllSF-Sq\"] = np.sqrt(test[\"AllSF\"])\ntest[\"AllFlrsSF-2\"] = test[\"AllFlrsSF\"] ** 2\ntest[\"AllFlrsSF-3\"] = test[\"AllFlrsSF\"] ** 3\ntest[\"AllFlrsSF-Sq\"] = np.sqrt(test[\"AllFlrsSF\"])\ntest[\"GrLivArea-2\"] = test[\"GrLivArea\"] ** 2\ntest[\"GrLivArea-3\"] = test[\"GrLivArea\"] ** 3\ntest[\"GrLivArea-Sq\"] = np.sqrt(test[\"GrLivArea\"])\ntest[\"SimplOverallQual-s2\"] = test[\"SimplOverallQual\"] ** 2\ntest[\"SimplOverallQual-s3\"] = test[\"SimplOverallQual\"] ** 3\ntest[\"SimplOverallQual-Sq\"] = np.sqrt(test[\"SimplOverallQual\"])\ntest[\"ExterQual-2\"] = test[\"ExterQual\"] ** 2\ntest[\"ExterQual-3\"] = test[\"ExterQual\"] ** 3\ntest[\"ExterQual-Sq\"] = np.sqrt(test[\"ExterQual\"])\ntest[\"GarageCars-2\"] = test[\"GarageCars\"] ** 2\ntest[\"GarageCars-3\"] = test[\"GarageCars\"] ** 3\ntest[\"GarageCars-Sq\"] = np.sqrt(test[\"GarageCars\"])\ntest[\"TotalBath-2\"] = test[\"TotalBath\"] ** 2\ntest[\"TotalBath-3\"] = test[\"TotalBath\"] ** 3\ntest[\"TotalBath-Sq\"] = np.sqrt(test[\"TotalBath\"])\ntest[\"KitchenQual-2\"] = test[\"KitchenQual\"] ** 2\ntest[\"KitchenQual-3\"] = test[\"KitchenQual\"] ** 3\ntest[\"KitchenQual-Sq\"] = np.sqrt(test[\"KitchenQual\"])\ntest[\"GarageScore-2\"] = test[\"GarageScore\"] ** 2\ntest[\"GarageScore-3\"] = test[\"GarageScore\"] ** 3\ntest[\"GarageScore-Sq\"] = np.sqrt(test[\"GarageScore\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features = test.select_dtypes(include = [\"object\"]).columns\nnum_features = test.select_dtypes(exclude = [\"object\"]).columns\ntest_num = test[num_features]\ntest_cat = test[cat_features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"before\",test_num.isnull().values.sum())\ntest_num = test_num.fillna(test_num.median())\nprint(\"after\",test_num.isnull().values.sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skewness = test_num.apply(lambda x: skew(x))\nskewness = skewness[abs(skewness) > 0.5]\nskewed_features = skewness.index\ntest_num[skewed_features] = np.log1p(test_num[skewed_features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_cat = pd.get_dummies(test_cat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.concat([test_num, test_cat], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstdSc = StandardScaler()\ntest.loc[:, num_features] = stdSc.fit_transform(test.loc[:, num_features])\nprint(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We are done with the preprocessing!","metadata":{}},{"cell_type":"markdown","source":"# We still some small steps remaining to create the test det similar to train set.\n### Starting with comparing the test set features with the train set features","metadata":{}},{"cell_type":"code","source":"data = [[0]*14]*1459\n\ndf = pd.DataFrame(data,columns = ['Condition2_RRAe', 'Condition2_RRAn', 'Condition2_RRNn', 'HouseStyle_2.5Fin',\n                             'RoofMatl_Membran', 'RoofMatl_Metal', 'RoofMatl_Roll', 'Exterior1st_ImStucc',\n                             'Exterior1st_Stone', 'Exterior2nd_Other', 'Heating_Floor', 'Heating_OthW',\n                             'Electrical_Mix', 'MiscFeature_TenC'])\n# print(df.shape)\n\ntest = pd.concat([test, df], axis = 1)\ntest = test.drop(columns = ['MSSubClass_SC150'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have added **0** to wherever required while creating extra features and adding to the test set. This is due to the fact that while doing OneHotEncoding there were some extra values in the train set but not in the test set. Thus create those features insert '0' in values and concat it to the test set.","metadata":{}},{"cell_type":"code","source":"t = []\nfor i in test.columns:\n    if i not in X_train.columns:\n        t.append(i)\nprint(t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = []\nfor i in X_train.columns:\n    if i not in test.columns:\n        t.append(i)\nprint(t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking for any extra columns in both the sets","metadata":{}},{"cell_type":"markdown","source":"# Creating a blended model<span id=\"17\"></span>","metadata":{}},{"cell_type":"markdown","source":"### We now create a function that would predict each value depending on the weights set by us. We can tune these weights however we want to get the least error possible.","metadata":{}},{"cell_type":"code","source":"def blend_models_predict1(X):\n    return ((0.1 * elasticnet.predict(X)) + \\\n            (0.1 * lasso.predict(X)) + \\\n            (0.1 * ridge.predict(X)) + \\\n            (0.2 * gbr.predict(X)) + \\\n            (0.2 * xgboost.predict(X)) + \\\n            (0.1 * lightgbm.predict(X)) + \\\n            (0.2 * scvr.predict(np.array(X))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[train.columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above step is crucial to make sure that the sequence of the features in test set is same as the features in the train set. This is used specially for stacking CV regressor.","metadata":{}},{"cell_type":"markdown","source":"# Prediction <span id=\"18\"></span>","metadata":{}},{"cell_type":"code","source":"\ny_pred_final = blend_models_predict1(test)\ny_pred_final\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(y_pred_final)\n\ny_pred_final = np.expm1(y_pred_final)\nprint(y_pred_final)\nId = list(range(1461,2920))\nfinal = pd.DataFrame({'Id': Id, 'SalePrice': y_pred_final})\nfinal.to_csv('submission.csv',index=False)\nprint(final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}