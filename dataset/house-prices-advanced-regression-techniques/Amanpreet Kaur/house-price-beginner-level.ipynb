{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\ntrain.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cat = train.select_dtypes(include = ['object'])\ntest_cat = test.select_dtypes(include = ['object'])\ntrain_cat.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_numeric = train.select_dtypes(include = ['float64', 'int64'])\ntest_numeric = test.select_dtypes(include = ['float64', 'int64'])\ntrain_numeric.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_cat_train = pd.DataFrame(train_cat.isna().sum().sort_values(ascending = False), columns=['missing_cat_total'])\nmissing_cat_test = pd.DataFrame(test_cat.isna().sum().sort_values(ascending = False), columns = ['missing_cat_total'])\nprint(missing_cat_train)\nprint( '-' * 40)\nprint(missing_cat_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_numeric_train = pd.DataFrame(train_numeric.isna().sum().sort_values(ascending = False), columns=['missing_num_total'])\nmissing_numeric_test = pd.DataFrame(test_numeric.isna().sum().sort_values(ascending = False), columns = ['missing_num_total'])\nprint(missing_numeric_train)\nprint('-' * 40)\nprint(missing_numeric_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's check and try to fill the missing values in categorical data columns. If the percentage of missing values is very large, we can drop the corresponding column.\n","metadata":{}},{"cell_type":"code","source":"missing_cat_percent = (missing_cat_train['missing_cat_total']/ 1460)*100\nprint(missing_cat_percent)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_num_percent = (missing_numeric_train['missing_num_total']/1460)*100\nprint(missing_num_percent)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### So let's drop the first four which are greater than 50 percent missing","metadata":{}},{"cell_type":"code","source":"train = train.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'], axis = 1)\ntrain.head()\n# do the same for test data\ntest = test.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### so now 4 columns are dropped. Let's fill the missing values now","metadata":{}},{"cell_type":"code","source":"missing_data = train[['GarageType', 'GarageCond', 'GarageQual', 'GarageFinish', 'BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtQual', 'BsmtCond', 'MasVnrType', 'Electrical', 'LotFrontage', 'GarageYrBlt', 'MasVnrArea']]\nmissing_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### If GarageType is missing that could mean there is no Garage, so let's fill those values and the missing values of all the other realetd columns eaqual to 'none'.\n#### let's fill basementfintype2, basementexposure, bsmntfintype1, bsmtqual, bsmtcond, masvnrtype, electrical with none.\n#### lets fill lotfrontage with mean value\n#### lets fill GarageYrBlt with mode\n#### lets fill MasVnrArea with mean","metadata":{}},{"cell_type":"code","source":"for col in ('GarageType', 'GarageCond', 'GarageQual', 'GarageFinish', 'BsmtFinType2', 'BsmtFinType1', 'BsmtExposure', 'BsmtQual', 'BsmtCond', 'MasVnrType', 'Electrical', 'MasVnrArea'):\n    train[col] = train[col].fillna('None')\ntrain['LotFrontage'] = train['LotFrontage'].fillna(train['LotFrontage'].mean())\ntrain['GarageYrBlt'] = train['GarageYrBlt'].fillna(train['GarageYrBlt'].mean())\n# do the same for test data\nfor col in ('GarageType', 'GarageCond', 'GarageQual', 'GarageFinish', 'BsmtFinType2', 'BsmtFinType1', 'BsmtExposure', 'BsmtQual', 'BsmtCond', 'MasVnrType', 'Electrical', 'MasVnrArea'):\n    test[col] = test[col].fillna('None')\ntest['LotFrontage'] = test['LotFrontage'].fillna(test['LotFrontage'].mean())\ntest['GarageYrBlt'] = test['GarageYrBlt'].fillna(test['GarageYrBlt'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.isna().sum().sort_values(ascending = False))\nprint('*' * 40)\nprint(test.isna().sum().sort_values(ascending = False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### we ahve dealt with all the missing values in the train data. Now lets check for the ones left in test data and fill them","metadata":{}},{"cell_type":"code","source":"test_missing_left = pd.DataFrame(test.isna().sum().sort_values(ascending = False), columns = ['test_missing'])\ntest_missing_left = test_missing_left[test_missing_left['test_missing']>0]\ntest_missing_left","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### lets fill all these values with 'None', since missing values are just one or two in each.","metadata":{}},{"cell_type":"code","source":"for col in ['MSZoning', 'BsmtHalfBath', 'BsmtFullBath', 'Functional', 'Utilities', 'Exterior1st', 'KitchenQual', 'GarageCars','GarageArea', 'BsmtFinSF1','TotalBsmtSF', 'BsmtFinSF2', 'BsmtUnfSF', 'SaleType', 'Exterior2nd']:\n    test[col] = test[col].fillna('None')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.isna().sum().sort_values(ascending=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### NOw lets check the correlation of all the numerical variables with SalePrice","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,1))\nsns.heatmap(train.drop('Id', axis=1).corr().sort_values(by = ['SalePrice'], ascending = False).head(1), cmap='coolwarm', annot=True, annot_kws={'size': 8}, fmt = '.2f')\n\nplt.title('Correlation of Numerical Features with the Target', weight = 'bold', fontsize = 18)\nplt.xticks(weight='bold')\nplt.yticks(weight='bold', color='dodgerblue', rotation=0)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,12))\nsns.set(font_scale=1.5)\nsns.heatmap(train.drop('Id', axis=1).corr(), mask=np.triu(np.ones_like(train.drop('Id', axis=1).corr(), dtype=np.bool)), fmt='.2f', cmap='coolwarm', annot=True, cbar_kws={\"shrink\": .8}, annot_kws={'size':8})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### So the highly correlated ones are- 'OverallQual', 'GrlivArea', 'TotalBsmtSF','1st floorSF', 'GarageCars' etc.\n#### Let's plot some of these with the target variable","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,10))\nsns.set_palette('pastel')\nplt.subplot(2,3,1)\nsns.regplot(x='GrLivArea', y='SalePrice', data=train)\nplt.subplot(2,3,2)\nsns.boxplot(x='OverallQual', y='SalePrice', data=train)\nplt.subplot(2,3,3)\nsns.regplot(x='TotalBsmtSF', y='SalePrice', data=train)\nplt.subplot(2,3,4)\nsns.regplot(x='1stFlrSF', y='SalePrice', data=train)\nplt.subplot(2,3,5)\nsns.boxplot(x='GarageCars', y='SalePrice', data=train)\nplt.subplot(2,3,6)\nsns.regplot(x='GarageArea', y='SalePrice', data=train)\nplt.subplots_adjust(wspace=0.5)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now lets check the relation of traget variable with categorical variables","metadata":{}},{"cell_type":"code","source":"traincat = train.select_dtypes(include = ['object'])\ntraincat.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,35))\nsns.set_palette('pastel')\nsns.set_style('darkgrid')\nplt.subplot(8,5,1)\nsns.violinplot(x='MSZoning', y='SalePrice', data=train)\nplt.subplot(8,5,2)\nsns.violinplot(x='Street', y='SalePrice', data=train)\nplt.subplot(8,5,3)\nsns.violinplot(x='LotShape', y='SalePrice', data=train)\nplt.subplot(8,5,4)\nsns.violinplot(x='LandContour', y='SalePrice', data=train)\nplt.subplot(8,5,5)\nsns.violinplot(x='Utilities', y='SalePrice', data=train)\nplt.subplot(8,5,6)\nsns.violinplot(x='LotConfig', y='SalePrice', data=train)\nplt.subplot(8,5,7)\nsns.violinplot(x='LandSlope', y='SalePrice', data=train)\nplt.subplot(8,5,8)\nsns.violinplot(x='Neighborhood', y='SalePrice', data=train)\nplt.subplot(8,5,9)\nsns.violinplot(x='Condition1', y='SalePrice', data=train)\nplt.subplot(8,5,10)\nsns.violinplot(x='Condition2', y='SalePrice', data=train)\nplt.subplot(8,5,11)\nsns.violinplot(x='BldgType', y='SalePrice', data=train)\nplt.subplot(8,5,12)\nsns.violinplot(x='HouseStyle', y='SalePrice', data=train)\nplt.subplot(8,5,13)\nsns.violinplot(x='RoofStyle', y='SalePrice', data=train)\nplt.subplot(8,5,14)\nsns.violinplot(x='RoofMatl', y='SalePrice', data=train)\nplt.subplot(8,5,15)\nsns.violinplot(x='Exterior1st', y='SalePrice', data=train)\nplt.subplot(8,5,16)\nsns.violinplot(x='Exterior2nd', y='SalePrice', data=train)\nplt.subplot(8,5,17)\nsns.violinplot(x='MasVnrType', y='SalePrice', data=train)\nplt.subplot(8,5,18)\nsns.violinplot(x='MasVnrArea', y='SalePrice', data=train)\nplt.subplot(8,5,19)\nsns.violinplot(x='ExterQual', y='SalePrice', data=train)\nplt.subplot(8,5,20)\nsns.violinplot(x='ExterCond', y='SalePrice', data=train)\nplt.subplot(8,5,21)\nsns.violinplot(x='Foundation', y='SalePrice', data=train)\nplt.subplot(8,5,22)\nsns.violinplot(x='BsmtQual', y='SalePrice', data=train)\nplt.subplot(8,5,23)\nsns.violinplot(x='BsmtCond', y='SalePrice', data=train)\nplt.subplot(8,5,24)\nsns.violinplot(x='BsmtExposure', y='SalePrice', data=train)\nplt.subplot(8,5,25)\nsns.violinplot(x='BsmtFinType1', y='SalePrice', data=train)\nplt.subplot(8,5,26)\nsns.violinplot(x='BsmtFinType2', y='SalePrice', data=train)\nplt.subplot(8,5,27)\nsns.violinplot(x='Heating', y='SalePrice', data=train)\nplt.subplot(8,5,28)\nsns.violinplot(x='HeatingQC', y='SalePrice', data=train)\nplt.subplot(8,5,29)\nsns.violinplot(x='CentralAir', y='SalePrice', data=train)\nplt.subplot(8,5,30)\nsns.violinplot(x='Electrical', y='SalePrice', data=train)\nplt.subplot(8,5,31)\nsns.violinplot(x='KitchenQual', y='SalePrice', data=train)\nplt.subplot(8,5,32)\nsns.violinplot(x='Functional', y='SalePrice', data=train)\nplt.subplot(8,5,33)\nsns.violinplot(x='GarageType', y='SalePrice', data=train)\nplt.subplot(8,5,34)\nsns.violinplot(x='GarageFinish', y='SalePrice', data=train)\nplt.subplot(8,5,35)\nsns.violinplot(x='GarageQual', y='SalePrice', data=train)\nplt.subplot(8,5,35)\nsns.violinplot(x='GarageCond', y='SalePrice', data=train)\nplt.subplot(8,5,36)\nsns.violinplot(x='PavedDrive', y='SalePrice', data=train)\nplt.subplot(8,5,37)\nsns.violinplot(x='SaleType', y='SalePrice', data=train)\nplt.subplot(8,5,38)\nsns.violinplot(x='SaleCondition', y='SalePrice', data=train)\nplt.subplots_adjust(wspace=0.5, hspace=0.8)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### More the variation in mean, stronger the corelation with the target variable.\n#### So, Mszoning, neighborhood, condition1, condition2, roofmatl, exterquality, basementqual, centralair, kitchenqual, saletype, MasVnrType are strongly corelated with SalePrice. \n\n\n  ","metadata":{}},{"cell_type":"markdown","source":"#### So let's keep the following features for modelling","metadata":{}},{"cell_type":"code","source":"features=['OverallQual', 'YearBuilt','YearRemodAdd','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea','MSZoning', 'Neighborhood','Condition1', 'Condition2', 'RoofMatl', 'ExterQual','BsmtQual', 'CentralAir', 'KitchenQual','SaleType','MasVnrType', 'SaleCondition','HouseStyle']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traintest=pd.concat([train, test], axis=0, sort=False)\ntraintest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traintest.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traintest.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test = pd.get_dummies(traintest[features])\ntrain_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=train_test[0:1460]\nX_test=train_test[1460:2919]\ny_train= train[['SalePrice']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train', X_train.shape)\nprint('Test', X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nfrom sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()\nX_train = my_imputer.fit_transform(X_train)\nX_test = my_imputer.fit_transform(X_test)\nlr.fit(X_train, y_train)\nprediction = lr.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(round(lr.score(X_train, y_train)*100,2))\n\n#mean_squared_error(y_test, prediction, squared=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(X_train, y_train)\ny_pred = forest_model.predict(X_test)\nprint(round(forest_model.score(X_train, y_train)*100,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=[]\nfor item in prediction:\n    for i in item:\n        pred.append(i)\n    \nprint(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code required to submit for competition\noutput = pd.DataFrame({'Id':pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')['Id'], 'SalePrice': pred})\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Lasso, Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.gridspec as gridspec\nimport missingno as msno\nimport scipy.stats as stats \nfrom scipy.special import boxcox1p\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Create an empty list\npipeline_models = []\n\n# Assign all models into the list\nseed = 42\nmodels = [Ridge(tol=10,random_state=seed),\n          Lasso(tol=1,random_state=seed),\n          RandomForestRegressor(random_state=seed),\n          ExtraTreesRegressor(random_state=seed),\n          GradientBoostingRegressor(),\n          DecisionTreeRegressor(),\n          KNeighborsRegressor()]\n\nmodel_names = [\"Ridge\",\"Lasso\",\"RFR\",\"ETR\",\"GBoost_Reg\",\"DT_Reg\",\"KNN_Reg\"]\n\n## Assign each model to a pipeline\nfor name, model in zip(model_names,models):\n    pipeline = (\"Scaled_\"+ name,\n                Pipeline([(\"Scaler\",StandardScaler()),\n                          (name,model)\n                         ]))\n    pipeline_models.append(pipeline)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Create a dataframe to store all the models' cross validation score\nevaluate = pd.DataFrame(columns=[\"model\",\"cv\",\"std\"])\n\n\n## Encoded dataset\nfor name,model in pipeline_models:\n    kfold = KFold(n_splits=7,shuffle=True,random_state=42)\n    cv = cross_val_score(model, X_train, y_train, cv=kfold, n_jobs=-1, scoring=\"r2\")\n    \n    row = evaluate.shape[0]\n    evaluate.loc[row,\"model\"] = name\n    evaluate.loc[row,\"cv\"] = round(cv.mean(),3)\n    evaluate.loc[row,\"std\"] = \"+/- {}\".format(round(cv.std(),4))\n    \n    evaluate = evaluate.sort_values(\"cv\",ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Visualization\nfig, ax = plt.subplots(1,1,sharey=False,figsize=(16,9))\n\n## Encoded dataset\nbar = sns.barplot(evaluate[\"model\"], evaluate[\"cv\"],ax=ax,palette = sns.cubehelix_palette(evaluate.shape[0]))\nfor rec in bar.patches:\n    height = rec.get_height()\n    ax.text(rec.get_x() + rec.get_width()/2, height*1.02,height,ha=\"center\")\nax.set_title(\"Cross Validate Score\")\nax.set_xticklabels(evaluate[\"model\"].to_list(),rotation =50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}