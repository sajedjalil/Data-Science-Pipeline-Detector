{"cells":[{"metadata":{"_uuid":"3e431211452bb55874302ce3b02154e329114830"},"cell_type":"markdown","source":"<h3>Introduction</h3><br>\n<b>Hello,</b><br>\nIn this kernel I will be showing you the fastest way to make your first submission to a Kaggle competition I will be using the data from the <b>'House prices: Advanced Regression Techniques'</b> competition.<br> \nFor this competition, we are predicting the sale price of property. The data is splited into two parts Training and testing sets both contains 1470 observations and 80 features.<br>\n<b style=\"color:red\">This approach with no feature engineering does ok on leaderboard </b>\n<br><br><br>\n\nI would like to recommend some kernels and courses that helped me begin my journey on Kaggle:\n<ul>\n  <li>Machine learning <a href=\"https://course.fast.ai/ml.html\">Fastai</a> it’s free and available on YouTube</li>\n  <li>For advance feature engineering and parameter tuning those 2 kernels are well detailed \n      <a href=\"https://www.kaggle.com/josh24990/simple-stacking-approach-top-12-score/notebook\">Simple stacking approach</a>,\n      <a href=\"https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\">Stacked Regressions</a>\n</li>\n</ul>  \n\n"},{"metadata":{"_uuid":"c82fd2ef6d1326fe92183bdbf82edf625a886e03"},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"47832ae9e4e4d005933a912340c9545a8dbd4957"},"cell_type":"markdown","source":"<h4><a href=\"https://github.com/fastai/fastai\">Fastai download Installation guide/documentation</a></h4>"},{"metadata":{"trusted":true,"_uuid":"475aab865d28a5f466f46d5e6a201f5977742e1c"},"cell_type":"code","source":" !pip install git+https://github.com/fastai/fastai@2e1ccb58121dc648751e2109fc0fbf6925aa8887 2>/dev/null 1>/dev/null\n# !apt update && apt install -y libsm6 libxext6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbbc68af351041b93dc3a14f4decea8ca6f7f53b"},"cell_type":"code","source":"from fastai.structured import rf_feat_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7723f7b623b21eb7ecc851b3d841a9370ea9496"},"cell_type":"code","source":"from fastai.structured import train_cats,proc_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b06f64ba8f565c6591082965d93cf81b9e1fa07"},"cell_type":"markdown","source":"#### Import ML models "},{"metadata":{"trusted":true,"_uuid":"803e22a524029db0271a761e93a3c78eb629b2ad"},"cell_type":"code","source":"#RandomForest\nimport math \nimport pandas as pd\nimport numpy as np \nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n#Xgboost\nimport xgboost as xgb\n#CatBoost \nfrom catboost import CatBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecc97faaa4308b7f4dad4f7878eeddde082c8226"},"cell_type":"markdown","source":"### Reading the data"},{"metadata":{"trusted":true,"_uuid":"4071e9991fa896241b0625d821fc0ed9efb47b34"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b27ce2011d7a0424e2d22bd49b8fbcaa77d6b4a3"},"cell_type":"markdown","source":"#### Saving the Id column for later use "},{"metadata":{"trusted":true,"_uuid":"1a9c3625444076365ed6831c1402fa6710807b4a"},"cell_type":"code","source":"Id = test['Id']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae335350c38a9fa5ff30cb065af6e8d28c428c92"},"cell_type":"markdown","source":"#### combinion the traning and testing dataset to maintain consistency between the sets"},{"metadata":{"trusted":true,"_uuid":"d991eb4c580046c44e34d4ed8cf4421496ae6aa1"},"cell_type":"code","source":"test_copy = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4cde063fe6ea766771d19754b97741deabee58f"},"cell_type":"code","source":"test_copy[\"SalePrice\"] = np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df734be41f1cb639dc71ac4818be33603843c42d"},"cell_type":"code","source":"train_set_data = [train,test_copy]\ntrain_set_data = pd.concat(train_set_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bec6aa1c75348497c43d6a88e4c67ca5210b43d3"},"cell_type":"code","source":"len(train_set_data) == len(train)+len(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de522a4d842328695c3f1dd0f739f74a0844c786"},"cell_type":"markdown","source":"#### train_cats is a function in the fastai library that  convert strings to pandas categories"},{"metadata":{"trusted":true,"_uuid":"b40a6888e6b853f8d7ca8cbe7843ddbef37aa4fa"},"cell_type":"code","source":"train_cats(train_set_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e08cdaa389ec837d1bfb981ab3a68c93fec0cbce"},"cell_type":"markdown","source":"#### proc_df will replace categories with their numeric codes, handle missing continuous values, and split the dependent variable into a separate variable for the max_n_cat is to create dummy variables for the categorical column with less or equal to 10 categories "},{"metadata":{"trusted":true,"_uuid":"ab0e217acff9d334a0000d5d874b2259751fe0d5"},"cell_type":"code","source":"df, y, nas = proc_df(train_set_data, 'SalePrice',max_n_cat=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47a934e4584b80f96d84430237e6686711e4c161"},"cell_type":"markdown","source":"####  resplite the training and test set"},{"metadata":{"trusted":true,"_uuid":"d20cf38dffc20bab17691dc75b3f713943f497d0"},"cell_type":"code","source":"test_df = df[1460:2919]\ndf = df[0:1460]\ny=y[0:1460]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b6d39974c268691860cacc59d4062b0d4146a1e"},"cell_type":"markdown","source":"#### Train a quick randomForest Resressor to check the feature importance "},{"metadata":{"trusted":true,"_uuid":"33c1baaa26d984bec9c20bb4fb1b9e97bd36d28e"},"cell_type":"code","source":"m = RandomForestRegressor(n_jobs=-1,verbose=0)\nm.fit(df, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5d84a9f9029a4e9d035ffc74638793757b4bd3f"},"cell_type":"markdown","source":"#### rf_feat_importance that uses the feature_importances_ attribute from the RandomForestRegressor to return a dataframe with the columns and their importance in descending order."},{"metadata":{"trusted":true,"_uuid":"5e699784f98c76f2746e6d8482582e7f3d5b45b3"},"cell_type":"code","source":"fi = rf_feat_importance(m, df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9cded86278ad1112393c996e64246458499f33f"},"cell_type":"code","source":"len(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05d2f19be4558e15f36915dfee28aab555289e4c"},"cell_type":"code","source":"def plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee1163efd0db3fcdbda2b2b9ffa53fd095a093ba"},"cell_type":"markdown","source":"#### creating a plot of the most relevant features "},{"metadata":{"trusted":true,"_uuid":"085c747cc7188e53687f5ee167ea8a4786d0f765"},"cell_type":"code","source":"plot_fi(fi[fi.imp>0.005])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d86365f946360707776bef58493beaf8d5456932"},"cell_type":"markdown","source":"#### keep only the column that have a acceptable information gain "},{"metadata":{"trusted":true,"_uuid":"69d802514d7a0ab3a98e60c7804c1687e4a2967c"},"cell_type":"code","source":"df = df[fi[fi.imp>0.0005].cols]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"327e63288851521dd46a1ccfe2202ba0d967faae"},"cell_type":"markdown","source":"#### Splite the data to training set and a validation set "},{"metadata":{"trusted":true,"_uuid":"31e08ea592b48c014398ecc996136868ec2e5eee"},"cell_type":"code","source":"def split_vals(a,n): return a[:n].copy(), a[n:].copy()\n\nn_valid = 400  \nn_trn = len(df)-n_valid\nX_train, X_valid = split_vals(df, n_trn)\ny_train, y_valid = split_vals(y, n_trn)\n\nX_train.shape, y_train.shape, X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8973d43c30394860927d9ac42d6f8a30cfa15890"},"cell_type":"markdown","source":"#### creating a function that evaluate the algorithmes performance <a href=\"https://en.wikipedia.org/wiki/Out-of-bag_error\">Learn more about OOB score</a> "},{"metadata":{"trusted":true,"_uuid":"7838ea442e62617db3480312a93fb891afce6642"},"cell_type":"code","source":"def rmse(x,y): return math.sqrt(((np.log(x)-np.log(y))**2).mean())\n\ndef print_score(m):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71e0c14502cd0baf6b25f3d1c580d84681d398a4"},"cell_type":"markdown","source":"### <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">RandomForest</a>"},{"metadata":{"_uuid":"70a45bc0fe25807f9af054543ed75d59e935b0da"},"cell_type":"markdown","source":"#### optimizing hyperparameters of a random forest with the grid search "},{"metadata":{"trusted":true,"_uuid":"8aa31357a0d9171f9a27c1c6cd6790674746064e"},"cell_type":"code","source":"rf_param_grid = {\n                 'max_depth' : [4, 6, 8,12],\n                 'n_estimators': [5,10,20,60,100],\n                 'max_features': ['sqrt', 'auto', 'log2'],\n                 'min_samples_split': [2, 3, 10,20],\n                 'min_samples_leaf': [1, 3, 10,18,25],\n                 'bootstrap': [True, False],\n                 }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e518a8f578aaca2403515d801a8a5f1ba651474"},"cell_type":"code","source":"m = RandomForestRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2399312a120d8a5b9ad8e72453c1bb0185ad4d6"},"cell_type":"code","source":"m_r = RandomizedSearchCV(param_distributions=rf_param_grid, \n                                    estimator = m,  \n                                    verbose = 0, n_iter = 50, cv = 4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22d63da326921eb082a18e75d9a137ed36020ecd"},"cell_type":"markdown","source":"#### fitting the model to the training set "},{"metadata":{"trusted":true,"_uuid":"f0ea4f16261aca6220057497a14845a478e1e300"},"cell_type":"code","source":"m_r.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8835c750a4efc1153be7186a72f46f65fa551305"},"cell_type":"code","source":"print_score(m_r)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0314e9b36c21b81ad8cabdf92d5e8bf86b35aca"},"cell_type":"markdown","source":"### <a href=\"https://xgboost.readthedocs.io/en/latest/\">Xgboost</a>"},{"metadata":{"trusted":true,"_uuid":"5b24bca0f3d4f9eb37f4bf5b861f69ab1fcff51f"},"cell_type":"code","source":"xgb_classifier = xgb.XGBRegressor()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a7d6b4d8e487e5b2611be73a7d810bda2797280"},"cell_type":"markdown","source":"#### optimizing hyperparameters of a random forest with the grid search "},{"metadata":{"trusted":true,"_uuid":"2492f4e85fb3161c8c81eafe09dcfd697b21a46b"},"cell_type":"code","source":"gbm_param_grid = {\n    'n_estimators': range(1,100),\n    'max_depth': range(1, 15),\n    'learning_rate': [.1,.13, .16, .19,.3,.6],\n    'colsample_bytree': [.6, .7, .8, .9, 1]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77b10a240c3222cf7036850ccc2d079ba8b69025"},"cell_type":"code","source":"xgb_random = RandomizedSearchCV(param_distributions=gbm_param_grid, \n                                    estimator = xgb_classifier, \n                                    verbose = 0, n_iter = 50, cv = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dce8aeadd9d47f4b2fc9747d639fb8e8fa196d84"},"cell_type":"code","source":"xgb_random.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05e9043854fb8e6a57dbe5e3cde92dd6189daed9"},"cell_type":"code","source":"print_score(xgb_random)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d02d9697adf5124b5f03235e89708c33f8117434"},"cell_type":"markdown","source":"### <a href=\"https://tech.yandex.com/catboost/doc/dg/concepts/python-installation-docpage/\">CatBoost</a>"},{"metadata":{"_uuid":"2706d1fa7d5a64b527c2db2bcc12a4dc145672e2"},"cell_type":"markdown","source":"##### The below parameters come from <a href=\"https://www.kaggle.com/josh24990/simple-stacking-approach-top-12-score/notebook\">this kernel </a>, we can optimizing hyperparameter but it will take a long time a lot of processing power (<a href=\"https://tech.yandex.com/catboost/doc/dg/concepts/parameter-tuning-docpage/\">catBoost parameter tuning</a>)"},{"metadata":{"trusted":true,"_uuid":"34a89412376a258c65dee216ac6e8e83c12cb8c9"},"cell_type":"code","source":"m_c = CatBoostRegressor(iterations=2000,learning_rate=0.1,depth=3,loss_function='RMSE',l2_leaf_reg=4,border_count=15,verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d243270bd0ab2df161ea21332dc0528710cd280f"},"cell_type":"code","source":"m_c.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6abc0072a53c1b79542dc29deabe9773f1f18b90"},"cell_type":"code","source":"print_score(m_c)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f34be652ae6c4a16bf1b588948f8926655090986"},"cell_type":"markdown","source":"#### get only the column used on the training set to predict on the test set "},{"metadata":{"trusted":true,"_uuid":"3b6d1712a88082da868a03ad64e0ce588826000b"},"cell_type":"code","source":"test_df = test_df[list(X_train.columns)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91f8360ef17ee6231eceeb0a1b67113020e81d94"},"cell_type":"markdown","source":"### combining the 3 models to predict on the test set  "},{"metadata":{"trusted":true,"_uuid":"eebe550c1dc0f44c639bf8b16c19e37c2fbcfac7"},"cell_type":"code","source":"y_pred = (m_c.predict(test_df) + m_r.predict(test_df)+xgb_random.predict(test_df))/3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"883deae93294ec7ba693ba76ce50eb1b82cbd15c"},"cell_type":"markdown","source":"#### concatenate the saved Id with the predicted values to create a csv file for submussion "},{"metadata":{"trusted":true,"_uuid":"802b11fb24cb7a1733867039376b5c4405440ef8"},"cell_type":"code","source":"submission = pd.DataFrame({\"Id\": Id,\"SalePrice\": y_pred})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bb22c6c25ac20b4a4801e8a46ae4df62b21702b"},"cell_type":"markdown","source":"![](submission.PNG)"},{"metadata":{"_uuid":"85aacbfc722c98c14ffba73450f69a0e68ca2909"},"cell_type":"markdown","source":"### For further parameter engineering they is a great python library \"<a href=\"https://github.com/pandas-profiling/pandas-profiling\">Pandas profiling</a>\" that Generates profile reports from a pandas DataFrame."},{"metadata":{"_uuid":"86824a3f2fbe737b2da5f4dc9d072bd3be565090"},"cell_type":"markdown","source":"### Thank you for reading ( ͡ᵔ ͜ʖ ͡ᵔ )"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}