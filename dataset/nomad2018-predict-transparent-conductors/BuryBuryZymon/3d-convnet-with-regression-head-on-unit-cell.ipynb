{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"nbconvert_exporter":"python","version":"3.6.4","pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_cell_guid":"57294e1e-0eb4-48c2-9167-e3ce991ed6bf","_uuid":"cae8b7ec0ba0986d4d156803e73fb7219cbd3e39"},"cell_type":"markdown","source":"# 3D ConvNet with Regression head on Unit Cell"},{"metadata":{},"cell_type":"markdown","source":"## Preamble \nIn this script, I will try to solve this problem using using 3D ConvNet on unit cell. The challenge is to predict the bandgap and formation energy for given alloys. For this we are given a csv file containing properties of alloys like space group, fraction of Al, Ga, In and few other information. in general DFT is used to calculate the HOMO LOMO energy and their difference is know as bandgap for that particular alloy. As its mentioned in the compitition, DFT calculations are expensive and takes huge amount of computational power. even solving a schrodinger's equation for 5 electron system is very tough, and here we are solving the equation for unit cells containing 60-80 atoms. I believe that structure of atoms in unit cell contains information which can be used to solve this problem. So I will start with making a 4D array presentin g unit cell and use 3D convolutional neural network with regresion head to solve this problem. As of now, its just an experiment so I will keep the size of CNN very small containing only 2 conv layers and 1 fc layer followed by regression head. We will be doing data prep followed by defining and training 3D convnet.\n- **Data prep for making unit cell** - we will color code the atoms based on their position in unit cell\n- **Defining and visualizing 3D ConvNet** - create a CNN for this task\n- **Training the CNN** - we will train the CNN for 10 epochs \n\n*PS* - This is an experiment I did for learning tensorflow and 3D convnet, these codes use global variables and has huge scope for improvement to perform well on leaderboard. I expect Kagglers to develop it further and let me know if they found this useful.\n\nSpecial thanks to my friend **Indra Kiran** for fixing some part of the code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"# For reading .xyz extention files \ndef get_xyz_data(filename):\n    \"\"\"source - https://www.kaggle.com/tonyyy/how-to-get-atomic-coordinates\n    Thanks Tony Y. for this function\"\"\"\n    pos_data = []\n    lat_data = []\n    with open(filename) as f:\n        for line in f.readlines():\n            x = line.split()\n            if x[0] == 'atom':\n                pos_data.append([np.array(x[1:4], dtype=np.float),x[4]])\n            elif x[0] == 'lattice_vector':\n                lat_data.append(np.array(x[1:4], dtype=np.float))\n    return pos_data, np.array(lat_data)"},{"metadata":{},"cell_type":"markdown","source":"## Function to create 3D images with different colors for Al, Ga, In, O"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"def image_dimension(train_xyz, print_ = 0):\n    \"\"\"function to return the values min-max for each dimension\"\"\"\n    x_cordinates = list()\n    y_cordinates = []\n    z_cordinates = []\n    for i in range(train_xyz.__len__()):\n        x_cordinates.append(train_xyz[i][0][0]) \n        y_cordinates.append(train_xyz[i][0][1])\n        z_cordinates.append(train_xyz[i][0][2])\n    min_x = min(x_cordinates) \n    max_x = max(x_cordinates)\n    min_y = min(y_cordinates)\n    max_y = max(y_cordinates)\n    min_z = min(z_cordinates)\n    max_z = max(z_cordinates)\n    if print_ == 1:\n        print(\"min_max of X is {} - {}\".format(min_x, max_x))\n        print(\"min_max of Y is {} - {}\".format(min_y, max_y))\n        print(\"min_max of Z is {} - {}\".format(min_z, max_z))\n    return(min_x, max_x, min_y, max_y, min_z, max_z)\n\ndef new_cordinates(point , train_xyz, pixel =20):\n    \"\"\"function to give nw cordinates for unit cell 3d image\"\"\"\n    min_x, max_x, min_y, max_y, min_z, max_z = image_dimension(train_xyz)\n    old_x = point[0][0]\n    old_y = point[0][1]\n    old_z = point[0][2]\n    new_x = 0 + pixel*abs((old_x-min_x)/(max_x - min_x))\n    new_y = 0 + pixel*abs((old_y-min_y)/(max_y - min_y))\n    new_z = 0 + pixel*abs((old_z-min_z)/(max_z - min_z))\n    return(int(new_x), int(new_y), int(new_z))\n\ndef image_generator(train_xyz, pixel = 20):\n    \"\"\"function to create a 3d image for convnet regression\"\"\"\n    rgb = np.zeros((pixel+1, pixel+1, pixel+1, 3), dtype=np.uint8)\n    rgb[..., 0] = 0.0\n    rgb[..., 1] = 0.0\n    rgb[..., 2] = 0.0\n    # Ininitally we have initiated a unit cell with all zeros = > No atoms \n    # Now, we will gradually fill atoms, and color code them for 3DConvNet\n    for j in range(train_xyz.__len__()):\n        #print(j)\n        point = train_xyz[j]\n        #print(point)\n        new_x, new_y, new_z = new_cordinates(point, train_xyz, pixel)\n        #if j ==45:\n        #print(new_x, new_y, new_z)\n        #print(train_xyz[j][1])\n        if train_xyz[j][1]=='Al':\n            #print(j)\n            # Al is red colored\n            rgb[new_x,new_y,new_z,0] = 255.0\n            #print(rgb[new_x][new_y][new_z])\n            rgb[new_x][new_y][new_z][1] = 0.0\n            rgb[new_x][new_y][new_z][2] = 0.0\n        elif train_xyz[j][1] == 'Ga':\n            #print(j)\n            #Ga is green\n            rgb[new_x][new_y][new_z][0] = 0.0\n            rgb[new_x][new_y][new_z][1] = 255.0\n            rgb[new_x][new_y][new_z][2] = 0.0\n        elif train_xyz[j][1] == 'In':\n            #print(j)\n            #Ga is green\n            rgb[new_x][new_y][new_z][0] = 0.0\n            rgb[new_x][new_y][new_z][1] = 0.0\n            rgb[new_x][new_y][new_z][2] = 255.0\n        else:\n            #print(j)\n            #print(new_x, new_y, new_z)\n            rgb[new_x][new_y][new_z][0] = 255.0\n            rgb[new_x][new_y][new_z][1] = 255.0\n            rgb[new_x][new_y][new_z][2] = 255.0\n    #print(rgb)\n    return(rgb)\n\n# function check\n#img = image_generator(train_xyz, pixel = 20)          \n"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"ids = list(range(1, 2401))\nimg_array = []\nfor id_ in ids:\n    fn = \"../input/train/{}/geometry.xyz\".format(id_)\n    train_xyz, train_lat = get_xyz_data(fn)\n    #print(id_)\n    img_temp = image_generator(train_xyz, pixel = 20)\n    #print(img_temp.shape)\n    img_array.append(img_temp)\nimg_ar = np.array(img_array)\nimg_ar.shape"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"np.save('position_unitcell_21.npy', img_ar)"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"# Visualizing unit cell Layers \nfig = plt.figure(1,figsize=(15,15))\nfor i in range(21):\n    ax = fig.add_subplot(7,3,i+1)\n    arr = img_ar[0][:][i]\n    ax.imshow(arr,cmap='inferno')\n    \n#plt.show()\n#plt.imshow(img[:][0])\nplt.show()"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\n# bandgap numpy array for 3D convnet\nbandgap = np.array(train_df.bandgap_energy_ev.values)\nbandgap.shape\nbandgap[0]\nnp.save('bandgap.npy', bandgap)\n\n\n# bandgap = np.array(train_df.bandgap_energy_ev.values)\nef = np.array(train_df.formation_energy_ev_natom.values)\nef.shape\nef[0]\nnp.save('ef.npy', ef)"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"# Start TensorFlow InteractiveSession\nimport tensorflow as tf\nimport numpy as np\nIMG_SIZE_PX = 21\nSLICE_COUNT = 21\nn_input = 1\nn_classes = 1\nbatch_size = 30\nX = tf.placeholder(tf.float32, [None, 21, 21, 21, 3], name='images')\nY = tf.placeholder(tf.float32, [None, 1], name='labels')\nkeep_rate = 0.6"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"def conv3d(x, W):\n    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='VALID')\n\ndef maxpool3d(x):\n    #size of window movement of window as you slide about\n    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='VALID')\n"},{"metadata":{},"cell_type":"markdown","source":"# Constructing and training 3D ConvNet with regression-head"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"def convolutional_neural_network(x):\n    #                # 5 x 5 x 5 patches, 1 channel, 32 features to compute.\n    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,3,32])),\n               #       5 x 5 x 5 patches, 32 channels, 64 features to compute.\n               'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\n               #                                  64 features\n               'W_fc':tf.Variable(tf.random_normal([3*3*3*64,1024])),\n               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n\n    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n               'b_conv2':tf.Variable(tf.random_normal([64])),\n               'b_fc':tf.Variable(tf.random_normal([1024])),\n               'out':tf.Variable(tf.random_normal([n_classes]))}\n\n    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n    conv1 = maxpool3d(conv1)\n\n\n    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n    conv2 = maxpool3d(conv2)\n\n    fc = tf.reshape(conv2,[-1, 3*3*3*64]) #3*3*3*64\n    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n    fc = tf.nn.dropout(fc, keep_rate)\n\n    output = tf.matmul(fc, weights['out'])+biases['out']\n\n    return output"},{"metadata":{},"cell_type":"markdown","source":"# Plotting the 3D CNN as computational graph "},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"import numpy as np\nfrom IPython.display import clear_output, Image, display, HTML\n\ndef strip_consts(graph_def, max_const_size=32):\n    \"\"\"Strip large constant values from graph_def.\"\"\"\n    strip_def = tf.GraphDef()\n    for n0 in graph_def.node:\n        n = strip_def.node.add() \n        n.MergeFrom(n0)\n        if n.op == 'Const':\n            tensor = n.attr['value'].tensor\n            size = len(tensor.tensor_content)\n            if size > max_const_size:\n                tensor.tensor_content = \"<stripped %d bytes>\"%size\n    return strip_def\n\ndef show_graph(graph_def, max_const_size=32):\n    \"\"\"Visualize TensorFlow graph.\"\"\"\n    if hasattr(graph_def, 'as_graph_def'):\n        graph_def = graph_def.as_graph_def()\n    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n    code = \"\"\"\n        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n        <script>\n          function load() {{\n            document.getElementById(\"{id}\").pbtxt = {data};\n          }}\n        </script>\n        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n        <div style=\"height:600px\">\n          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n        </div>\n    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n\n    iframe = \"\"\"\n        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n    \"\"\".format(code.replace('\"', '&quot;'))\n    display(HTML(iframe))"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"g = tf.Graph()\n\nwith g.as_default():\n    x = tf.placeholder(tf.float32, name=\"X\")\n    n_classes =1\n    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,3,32])),\n               #       5 x 5 x 5 patches, 32 channels, 64 features to compute.\n               'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\n               #                                  64 features\n               'W_fc':tf.Variable(tf.random_normal([3*3*3*64,1024])),\n               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n\n    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n               'b_conv2':tf.Variable(tf.random_normal([64])),\n               'b_fc':tf.Variable(tf.random_normal([1024])),\n               'out':tf.Variable(tf.random_normal([n_classes]))}\n\n    #                            image X      image Y        image Z\n    #x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 3])\n    with tf.name_scope(\"Layer1\"):\n        conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n        conv1 = maxpool3d(conv1)\n\n    with tf.name_scope(\"Layer2\"):\n        conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n        conv2 = maxpool3d(conv2)\n    with tf.name_scope(\"Layer3\"):\n        fc = tf.reshape(conv2,[-1, 3*3*3*64]) #3*3*3*64\n        fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n        fc = tf.nn.dropout(fc, keep_rate)\n    with tf.name_scope(\"Layer4\"):\n        output = tf.matmul(fc, weights['out'])+biases['out']\n    \n    \n    \ntf.summary.FileWriter(\"logs\", g).close()\n\nshow_graph(g)"},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"full_data = np.load('./position_unitcell_21.npy')\nfull_y = np.load('./bandgap.npy')\nprint(full_data.shape, full_y.shape)\nfull_y = full_y*10000 # normalizing y for easy convergence \nfull_y[1:5]"},{"metadata":{},"cell_type":"markdown","source":"# Train-val split for validation "},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"train_data = full_data[:-240]\ntrain_y = full_y[:-240].reshape(2160,1)\nprint(train_data.shape, train_y.shape)\nvalidation_data = full_data[-240:]\nvalidation_y = full_y[-240:].reshape(240,1)\nprint(validation_data.shape, validation_y.shape)"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"def test_neural_network(x):\n    prediction = convolutional_neural_network(X)\n    cost = tf.reduce_mean(tf.square(Y-prediction))\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        saver = tf.train.Saver(max_to_keep=3)\n        ckpt = tf.train.latest_checkpoint('.')\n        if ckpt:\n            saver.restore(sess, ckpt)\n            print('Model restored')\n        X_test = test_data\n        Y_test = test_y\n        preds, loss = sess.run([prediction,cost], feed_dict={X: X_test, Y: Y_test})\n        print(preds, loss)\n        np.save(\"Predictions.npy\", preds)\n    \n\ndef train_neural_network(x):\n    prediction = convolutional_neural_network(x)\n    cost = tf.reduce_mean(tf.square(Y-prediction))\n    global_step = tf.Variable(0, trainable=False)\n    starter_learning_rate = 1e-4\n    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n                                           20*72, 0.10, staircase=True)\n    optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-4)\n    train_op = optimizer.minimize(cost, global_step=global_step)\n    hm_epochs = 3\n    with tf.Session() as sess:\n        saver = tf.train.Saver(max_to_keep=3)\n        sess.run(tf.global_variables_initializer())\n        \n        successful_runs = 0\n        total_runs = 0\n    \n        for epoch in range(hm_epochs):\n            epoch_loss = 0.0\n            num_batches = len(train_data)//batch_size\n            print(\"Number of batches {}\".format(num_batches))\n            print(\"Learning_rate {}\".format(learning_rate.eval()))\n            indices = np.arange(len(train_data))\n            np.random.permutation(indices)\n            for batch in range(num_batches):\n                batch_indices = indices[batch*batch_size:(batch+1)*batch_size]\n                X_batch = train_data[batch_indices]\n                Y_batch = train_y[batch_indices]\n                _, p, c = sess.run([train_op, prediction, cost], feed_dict={X: X_batch, Y: Y_batch})\n                epoch_loss += c\n            epoch_loss /= num_batches\n            print(\"Epoch: %d \\t Loss: %f\" % (epoch+1, epoch_loss))\n            print(\"-\"*52)\n            \n            if (epoch+1)%10 == 0:\n                X_val = validation_data\n                Y_val = validation_y\n                val_pred, val_loss = sess.run([prediction,cost], feed_dict={X: X_val, Y: Y_val})\n                print('Validation loss : %f' % val_loss)\n            \n            saver.save(sess, './model.ckpt', global_step=epoch)\n            "},{"metadata":{},"outputs":[],"execution_count":null,"cell_type":"code","source":"train_neural_network(X)"},{"metadata":{},"cell_type":"markdown","source":"## Thats it. Develop further and let me know how it works... \n** Kudos to all the awesome kagglers** \\m/"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":""}]}