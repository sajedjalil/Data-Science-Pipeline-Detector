{"cells":[{"metadata":{"_cell_guid":"256bf8b7-92ed-445f-b137-9db81e6b7244","_uuid":"94e1c572c69dfe1912c3bec2945b3f240c0621b3"},"cell_type":"markdown","source":"\n\n# Pytorch SimpleNet + DataLoader,Kaggle Plant Seedlings Classification LB 0.945\n- Custom PyTorch image data loader\n- You must run this on a GPU\n- Work in progress|\n\n# Todo:\n- Inference (**done**)\n- Submission (**done**)\n\nhttps://github.com/QuantScientist/Deep-Learning-Boot-Camp/tree/master/Kaggle-PyTorch\n\nShlomo Kashani. \n"},{"metadata":{"_cell_guid":"42dcf0c0-28f0-4386-9ee3-367f3606aa30","_uuid":"33595673f3f93faf28ed0ac10f0a7c0e59a9c0ad","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport time\nfrom shutil import copyfile\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom os import listdir, makedirs, getcwd, remove\nfrom PIL import Image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as func\nimport torchvision\nfrom torchvision import transforms, datasets, models\nimport random \n\nuse_cuda = torch.cuda.is_available()\n\nmanualSeed = None\ndef fixSeed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if use_cuda:\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\n\nif manualSeed is None:\n        manualSeed = 999\nfixSeed(manualSeed)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"579bc4ea-49c2-4413-a4bf-57472a155db4","_uuid":"ab87c9fc87053c27d96e4765be8a942e91bf79bd"},"cell_type":"markdown","source":"### Define Custom Dataset"},{"metadata":{"_cell_guid":"796ac7f9-d66a-4856-acba-b1be8f4960b6","_uuid":"e32251e2e44d9bf3b14af6153643b36110cb17ef","trusted":true},"cell_type":"code","source":"class SeedlingDataset(Dataset):\n    def __init__(self, labels, root_dir, subset=False, transform=None):\n        self.labels = labels\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        img_name = self.labels.iloc[idx, 0] # file name\n        fullname = join(self.root_dir, img_name)\n        image = Image.open(fullname).convert('RGB')\n        labels = self.labels.iloc[idx, 2] # category_id\n#         print (labels)\n        if self.transform:\n            image = self.transform(image)\n        return image, labels\n    \n\nimport os\ndata_dir = '../input/train/'\n# cache_dir = expanduser(join('~', '.torch'))\n\ndef find_classes(fullDir):\n    classes = [d for d in os.listdir(fullDir) if os.path.isdir(os.path.join(fullDir, d))]\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    num_to_class = dict(zip(range(len(classes)), classes))\n    \n    train = []\n    for index, label in enumerate(classes):\n        path = fullDir + label + '/'\n        for file in listdir(path):\n            train.append(['{}/{}'.format(label, file), label, index])\n    \n    df = pd.DataFrame(train, columns=['file', 'category', 'category_id',]) \n\n    return classes, class_to_idx, num_to_class, df\n\nclasses, class_to_idx, num_to_class, df =find_classes (data_dir )\n\n\n# class_to_idx\n# num_to_class\ndf.head(5)    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a11e110c-6a69-4260-9a6a-eea6ca54e0af","_uuid":"bafad8e4158a53697b0599470478212180c07d6d","trusted":true},"cell_type":"code","source":"len(classes)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"39a38e9b-7d05-4bc9-96d2-746731aed528","_uuid":"e2439ccb5fd97c0f9b8acab3cd977978c95db2f9","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\n\nfrom torchvision.transforms import *\n\nfrom PIL import Image, ImageDraw\nimport numpy as np\nimport torch\n\nimport torchvision\nimport random\nfrom PIL import Image, ImageOps\nimport numpy as np\nimport numbers\nimport math\nimport torch\nimport torch\nimport random\nimport PIL.ImageEnhance as ie\nimport PIL.Image as im\n\n# adapted from https://github.com/kuangliu/pytorch-retinanet/blob/master/transform.py\n# https://github.com/mratsim/Amazon-Forest-Computer-Vision/blob/master/src/p_data_augmentation.py\n\nnormalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\ndef draw(img, boxes):\n    draw = ImageDraw.Draw(img)\n    for box in boxes:\n        draw.rectangle(list(box), outline='red')\n    img.show()\n\n\nclass Stack(object):\n\n    def __init__(self, roll=False):\n        self.roll = roll\n\n    def __call__(self, img_group):\n        if img_group[0].mode == 'L':\n            return np.concatenate([np.expand_dims(x, 2) for x in img_group], axis=2)\n        elif img_group[0].mode == 'RGB':\n            if self.roll:\n                return np.concatenate([np.array(x)[:, :, ::-1] for x in img_group], axis=2)\n            else:\n                return np.concatenate(img_group, axis=2)\n\n\nclass ToTorchFormatTensor(object):\n    \"\"\" Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range [0, 255]\n    to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \"\"\"\n    def __init__(self, div=True):\n        self.div = div\n\n    def __call__(self, pic):\n        if isinstance(pic, np.ndarray):\n            # handle numpy array\n            img = torch.from_numpy(pic).permute(2, 0, 1).contiguous()\n        else:\n            # handle PIL Image\n            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n            img = img.view(pic.size[1], pic.size[0], len(pic.mode))\n            # put it from HWC to CHW format\n            # yikes, this transpose takes 80% of the loading time/CPU\n            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n        return img.float().div(255) if self.div else img.float()\n\n\nclass IdentityTransform(object):\n\n    def __call__(self, data):\n        return data\n\nclass RandomErasing(object):\n    def __init__(self, EPSILON = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n        self.EPSILON = EPSILON\n        self.mean = mean\n        self.sl = sl\n        self.sh = sh\n        self.r1 = r1\n       \n    def __call__(self, img):\n\n        if random.uniform(0, 1) > self.EPSILON:\n            return img\n\n        for attempt in range(100):\n            area = img.size()[1] * img.size()[2]\n       \n            target_area = random.uniform(self.sl, self.sh) * area\n            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n\n            h = int(round(math.sqrt(target_area * aspect_ratio)))\n            w = int(round(math.sqrt(target_area / aspect_ratio)))\n\n            if w <= img.size()[2] and h <= img.size()[1]:\n                x1 = random.randint(0, img.size()[1] - h)\n                y1 = random.randint(0, img.size()[2] - w)\n                if img.size()[0] == 3:\n                    #img[0, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n                    #img[1, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n                    #img[2, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n                    #img[:, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(3, h, w))\n                else:\n                    img[0, x1:x1+h, y1:y1+w] = self.mean[1]\n                    # img[0, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(1, h, w))\n                return img\n\n        return img\n\ndef random_crop(img, boxes):\n    '''Crop the given PIL image to a random size and aspect ratio.\n    A crop of random size of (0.08 to 1.0) of the original size and a random\n    aspect ratio of 3/4 to 4/3 of the original aspect ratio is made.\n    Args:\n      img: (PIL.Image) image to be cropped.\n      boxes: (tensor) object boxes, sized [#ojb,4].\n    Returns:\n      img: (PIL.Image) randomly cropped image.\n      boxes: (tensor) randomly cropped boxes.\n    '''\n    success = False\n    for attempt in range(10):\n        area = img.size[0] * img.size[1]\n        target_area = random.uniform(0.56, 1.0) * area\n        aspect_ratio = random.uniform(3. / 4, 4. / 3)\n\n        w = int(round(math.sqrt(target_area * aspect_ratio)))\n        h = int(round(math.sqrt(target_area / aspect_ratio)))\n\n        if random.random() < 0.5:\n            w, h = h, w\n\n        if w <= img.size[0] and h <= img.size[1]:\n            x = random.randint(0, img.size[0] - w)\n            y = random.randint(0, img.size[1] - h)\n            success = True\n            break\n\n    # Fallback\n    if not success:\n        w = h = min(img.size[0], img.size[1])\n        x = (img.size[0] - w) // 2\n        y = (img.size[1] - h) // 2\n\n    img = img.crop((x, y, x+w, y+h))\n    boxes -= torch.Tensor([x,y,x,y])\n    boxes[:,0::2].clamp_(min=0, max=w-1)\n    boxes[:,1::2].clamp_(min=0, max=h-1)\n    return img, boxes\n\n\nclass Lighting(object):\n    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n\n    def __init__(self, alphastd, eigval, eigvec):\n        self.alphastd = alphastd\n        self.eigval = eigval\n        self.eigvec = eigvec\n\n    def __call__(self, img):\n        if self.alphastd == 0:\n            return img\n\n        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n        rgb = self.eigvec.type_as(img).clone() \\\n            .mul(alpha.view(1, 3).expand(3, 3)) \\\n            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n            .sum(1).squeeze()\n\n        return img.add(rgb.view(3, 1, 1).expand_as(img))\n\n\nclass Grayscale(object):\n    def __call__(self, img):\n        gs = img.clone()\n        gs[0].mul_(0.299).add_(0.587, gs[1]).add_(0.114, gs[2])\n        gs[1].copy_(gs[0])\n        gs[2].copy_(gs[0])\n        return gs\n\n\nclass Saturation(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = Grayscale()(img)\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass Brightness(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = img.new().resize_as_(img).zero_()\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass Contrast(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = Grayscale()(img)\n        gs.fill_(gs.mean())\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass RandomOrder(object):\n    \"\"\" Composes several transforms together in random order.\n    \"\"\"\n\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img):\n        if self.transforms is None:\n            return img\n        order = torch.randperm(len(self.transforms))\n        for i in order:\n            img = self.transforms[i](img)\n        return img\n\n\nclass ColorJitter(RandomOrder):\n    def __init__(self, brightness=0.4, contrast=0.4, saturation=0.4):\n        self.transforms = []\n        if brightness != 0:\n            self.transforms.append(Brightness(brightness))\n        if contrast != 0:\n            self.transforms.append(Contrast(contrast))\n        if saturation != 0:\n            self.transforms.append(Saturation(saturation))\n\n\nclass RandomFlip(object):\n    \"\"\"Randomly flips the given PIL.Image with a probability of 0.25 horizontal,\n                                                                0.25 vertical,\n                                                                0.5 as is\n    \"\"\"\n\n    def __call__(self, img):\n        dispatcher = {\n            0: img,\n            1: img,\n            2: img.transpose(im.FLIP_LEFT_RIGHT),\n            3: img.transpose(im.FLIP_TOP_BOTTOM)\n        }\n\n        return dispatcher[random.randint(0, 3)]  # randint is inclusive\n\n\nclass RandomRotate(object):\n    \"\"\"Randomly rotate the given PIL.Image with a probability of 1/6 90°,\n                                                                 1/6 180°,\n                                                                 1/6 270°,\n                                                                 1/2 as is\n    \"\"\"\n\n    def __call__(self, img):\n        dispatcher = {\n            0: img,\n            1: img,\n            2: img,\n            3: img.transpose(im.ROTATE_90),\n            4: img.transpose(im.ROTATE_180),\n            5: img.transpose(im.ROTATE_270)\n        }\n\n        return dispatcher[random.randint(0, 5)]  # randint is inclusive\n\n\nclass PILColorBalance(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Color(img).enhance(alpha)\n\n\nclass PILContrast(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Contrast(img).enhance(alpha)\n\n\nclass PILBrightness(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Brightness(img).enhance(alpha)\n\n\nclass PILSharpness(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Sharpness(img).enhance(alpha)\n\n\n# Check ImageEnhancer effect: https://www.youtube.com/watch?v=_7iDTpTop04\n# Not documented but all enhancements can go beyond 1.0 to 2\n# Image must be RGB\n# Use Pillow-SIMD because Pillow is too slow\nclass PowerPIL(RandomOrder):\n    def __init__(self, rotate=True,\n                 flip=True,\n                 colorbalance=0.4,\n                 contrast=0.4,\n                 brightness=0.4,\n                 sharpness=0.4):\n        self.transforms = []\n        if rotate:\n            self.transforms.append(RandomRotate())\n        if flip:\n            self.transforms.append(RandomFlip())\n        if brightness != 0:\n            self.transforms.append(PILBrightness(brightness))\n        if contrast != 0:\n            self.transforms.append(PILContrast(contrast))\n        if colorbalance != 0:\n            self.transforms.append(PILColorBalance(colorbalance))\n        if sharpness != 0:\n            self.transforms.append(PILSharpness(sharpness))\n\ndef default_loader(input_path):\n    input_image = (Image.open(input_path)).convert('RGB')\n    return input_image\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc8a9969-280a-4ec8-850b-25aed1ee38d6","_uuid":"0163fcd2a2ea5a4e93bc87f47a96f404bcad6a83"},"cell_type":"markdown","source":"### Setup transforms, datasets, and dataloaders"},{"metadata":{"_cell_guid":"f94cb9fa-e76a-46d5-a363-8856b45c59e1","_uuid":"fe82da4f8b1501203d12027200d1f8d2209f0057","trusted":true},"cell_type":"code","source":"image_size = 224\n\nnormalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n\ntrain_trans = transforms.Compose([\n    transforms.RandomSizedCrop(image_size),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nvalid_trans = transforms.Compose([\n    transforms.Scale(256),\n    transforms.CenterCrop(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n\ntrain_trans = transforms.Compose([\n    transforms.RandomSizedCrop(image_size),\n    PowerPIL(),\n    transforms.ToTensor(),\n    normalize_img,\n])\n\n## Normalization only for validation and test\nvalid_trans = transforms.Compose([\n    transforms.Scale(256),\n    transforms.CenterCrop(image_size),\n    transforms.ToTensor(),\n    normalize_img\n])\n\n\nbatch_size = 64\ntrain_data = df.sample(frac=0.90)\nvalid_data = df[~df['file'].isin(train_data['file'])]\n\ntrain_set = SeedlingDataset(train_data, data_dir, transform = train_trans)\nvalid_set = SeedlingDataset(valid_data, data_dir, transform = valid_trans)\n        \n\nt_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\nv_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n# test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n\ndataset_sizes = {\n    'train': len(t_loader.dataset), \n    'valid': len(v_loader.dataset)\n}\n\nprint (dataset_sizes)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d966c8a9-d189-4b76-8def-6180f9498154","_uuid":"fde155bdd9ce81e2598146c263cedfa65eaba806"},"cell_type":"markdown","source":"### Define the model"},{"metadata":{"_cell_guid":"f2eb7b14-c63b-4fdf-8370-baabd48a9943","_uuid":"29184efaeb75c7105b9f144550b68814c577534a","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport math \n\n\n\n# class SimpleNet(nn.Module):\n#     def __init__(self):\n#         super(SimpleNet, self).__init__()\n#         self.conv1 = nn.Conv2d(3, 32, 3, stride=1)\n#         self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n\n#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n#         self.conv4 = nn.Conv2d(64, 64, kernel_size=3)\n#         self.dense1 = nn.Linear(179776, out_features=512)\n#         self.dense1_bn = nn.BatchNorm1d(512)\n#         self.dense2 = nn.Linear(512, len(classes))\n\n#     def forward(self, x):\n#         x = F.relu(self.conv1(x))\n#         x = F.relu(F.dropout(F.max_pool2d(self.conv2(x), 2), 0.25))\n#         x = F.relu(self.conv3(x))\n#         x = F.relu(F.dropout(F.max_pool2d(self.conv4(x), 2), 0.25))        \n#         x = x.view(x.size(0), -1)\n# #         print (x.data.shape)\n#         x = F.relu(self.dense1_bn(self.dense1(x)))        \n#         x = x.view(x.size(0), -1)\n# #         print (x.data.shape)\n#         x = self.dense2(x)\n        \n#         return x\n    \n\n# model = SimpleNet()\n# model = DenseNet(growthRate=4, depth=10, reduction=0.5,bottleneck=True, nClasses=len(classes))\n# model = models.resnet152(pretrained=True)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom collections import OrderedDict\nfrom torch.nn import init\nimport numpy as np\n\n\n\ndropout = torch.nn.Dropout(p=0.30)\nrelu=torch.nn.LeakyReLU()\npool = nn.MaxPool2d(2, 2)\n\nclass ConvRes(nn.Module):\n    def __init__(self,insize, outsize):\n        super(ConvRes, self).__init__()\n        drate = .3\n        self.math = nn.Sequential(\n                 nn.BatchNorm2d(insize),\n                 nn.Dropout(drate),\n                 torch.nn.Conv2d(insize, outsize, kernel_size=2,padding=2),\n                 nn.PReLU(),\n                )\n        \n    def forward(self, x):\n        return self.math(x) \n\nclass ConvCNN(nn.Module):\n    def __init__(self,insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n        super(ConvCNN, self).__init__()\n        self.avg=avg\n        self.math = torch.nn.Sequential(\n            torch.nn.Conv2d(insize, outsize, kernel_size=kernel_size,padding=padding),\n            torch.nn.BatchNorm2d(outsize),\n            torch.nn.LeakyReLU(),\n            torch.nn.MaxPool2d(pool,pool),\n        )\n        self.avgpool=torch.nn.AvgPool2d(pool,pool)\n        \n    def forward(self, x):\n        x=self.math(x)\n        if self.avg is True:\n            x=self.avgpool(x)\n        return x   \n        \nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()        \n        \n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        \n        self.cnn1 = ConvCNN (3,64,  kernel_size=7, pool=4, avg=False)\n        self.cnn2 = ConvCNN (64,64, kernel_size=5, pool=2, avg=True)\n        self.cnn3 = ConvCNN (64,256, kernel_size=5, pool=2, avg=True)\n        \n        self.res1 = ConvRes (256,64)\n        \n        self.features = nn.Sequential( \n            self.cnn1,dropout,          \n            self.cnn2,\n            self.cnn3,\n            self.res1,\n        )        \n        \n        self.classifier = torch.nn.Sequential(\n            nn.Linear(2304, len(classes)),             \n        )\n#         self.sig=nn.Sigmoid()        \n            \n    def forward(self, x):\n        x = self.features(x) \n        x = x.view(x.size(0), -1)        \n#         print (x.data.shape)\n        x = self.classifier(x)                \n#         x = self.sig(x)\n        return x        \n\nmodel = Net()\n    \nif use_cuda:\n    model = model.cuda()\n# for param in model.parameters():\n#     param.requires_grad = False    \n# num_ftrs = model.fc.in_features\n# model.fc = torch.nn.Linear(num_ftrs, len(classes))\n# criterion = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.0005)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr= 0.00005 * 2 * 2)\n\nif use_cuda:\n    model = model.cuda()\nprint (model)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0cd8c571-5d93-42b6-9ef0-9c16b6d43ef7","_uuid":"1257d2cc10e64019a8ca94c814d4e179a45e04cd"},"cell_type":"markdown","source":"### Training\nmostly if not entirely from pytorch transfer learning tutorial"},{"metadata":{"_cell_guid":"f2cd5d63-c765-476a-9258-0152d8a06360","_uuid":"d5ecfa57978ed8afd52e1551f6f5688ce9e16a5c","trusted":true},"cell_type":"code","source":"from tqdm import tqdm \nfrom sklearn import metrics\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n\ndef train(train_loader, model, epoch, optimizer):\n    model.train()\n    \n    for batch_idx, (data, target) in ((enumerate(train_loader))):\n        correct = 0\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        pred = output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data).cpu().sum()\n        accuracy = 100. * correct / len(data)\n        optimizer.step()\n        if batch_idx %200 == 0:\n            print('TRAIN: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.3f}%)'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0],\n                correct, len(data),\n                accuracy))            \n\n\ndef test(test_loader, model, epoch):\n#     model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in (test_loader):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += criterion(output, target).data[0]\n        pred = output.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data).cpu().sum()\n\n    test_loss = test_loss\n    test_loss /= len(test_loader) # loss function already averages over batch size\n    accuracy = 100. * correct / len(test_loader.dataset)\n    print('\\nVAL: Average loss: {:.6f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        accuracy))\n    \n    return test_loss, accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d33413f79aa2d2b02482789f79a460a3052f90e9"},"cell_type":"code","source":"! ls -la '../input/'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7b939262-bef9-4384-9e65-1c6f19b0e7af","_uuid":"c89aec6e431baa5ad878aa07c30faef161dea697"},"cell_type":"markdown","source":"### Train the model\nusing one epoch due to time constraints"},{"metadata":{"_cell_guid":"c75d0756-757e-4cdb-b3e3-43d0ae2110eb","_uuid":"56b469e006382a0c93c7ce30b7976783257762b9","trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/' + 'sample_submission.csv')\nsample_submission.columns = ['file', 'species']\n# sample_submission['category_id'] = 0\nsample_submission.head(3)\n\n\n# test_trans = transforms.Compose([transforms.Scale(image_size), transforms.ToTensor()])\ntest_trans = valid_trans\n\ntest_data_dir = '../input/test/'\n\ndef testImageLoader(image_name):\n    \"\"\"load image, returns cuda tensor\"\"\"\n#     image = Image.open(image_name)\n    image = Image.open(image_name).convert('RGB')\n    image = test_trans(image)\n#     image = Variable(image, requires_grad=True)\n    image = image.unsqueeze(0)  \n    if use_cuda:\n#         print (\"cuda\")\n        image.cuda()         \n    return image  \n\ndef testModel(test_dir, local_model):    \n    if use_cuda:\n        local_model.cuda()\n    \n    local_model.eval()\n    \n    columns = ['file', 'species']\n    df_pred = pd.DataFrame(data=np.zeros((0, len(columns))), columns=columns)\n#     df_pred.species.astype(int)\n    for index, row in (sample_submission.iterrows()):\n#         for file in os.listdir(test_dir):            \n        currImage=os.path.join(test_dir, row['file'])\n        if os.path.isfile(currImage):\n            X_tensor_test=testImageLoader (currImage)            \n#             print (type(X_tensor_test))\n            if use_cuda:\n                X_tensor_test = Variable(X_tensor_test.cuda()) \n            else:\n                X_tensor_test = Variable(X_tensor_test)        \n            \n            # get the index of the max log-probability\n            predicted_val = (local_model(X_tensor_test)).data.max(1)[1] # get the index of the max log-probability\n#             predicted_val = predicted_val.data.max(1, keepdim=True)[1]\n            p_test = (predicted_val.cpu().numpy().item())\n            df_pred = df_pred.append({'file': row['file'], 'species': num_to_class[int(p_test)]}, ignore_index=True)             \n    \n    return df_pred\n\nif __name__ == '__main__':    \n    for epoch in tqdm(range(0, 120)):        \n        train(t_loader, model, epoch, optimizer)\n        test_loss, accuracy= test(v_loader, model, epoch)\n        if float(accuracy) > float(90.0): \n            print (\"EARLY STOP\")\n            df_pred=testModel(test_data_dir,model)\n            df_pred.to_csv(str(type(model).__name__) + '_' + str(accuracy) + '_' + str(epoch) + \"_sub.csv\", columns=('file', 'species'), index=None)        \n#             torch.save(model.state_dict(),  str(type(model).__name__) + '_' + str(accuracy) + '_cnn.pth')\n    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ae6b08e0-b03b-4dec-8e10-3df59ee06049","_uuid":"e9b60494613d5395e08916da9bf2a5211e4ea874","trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), str(type(model).__name__) + '_' + str(accuracy) + '_.pth')\n# model = SimpleNet()\n# .. to load your previously training model:\n# model.load_state_dict(torch.load('simplenet_cnn.pth'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"457dee33-2e0e-42b8-99e3-efa07aea09d6","collapsed":true,"_uuid":"7e95165c2c98f9dbf5554061cc3e5fb46ff8fead"},"cell_type":"markdown","source":"### LB score 0.91939"},{"metadata":{"_cell_guid":"6e871692-70e1-43bd-8baa-d82de6ee689c","collapsed":true,"_uuid":"302eb15b5bdc2040b852eba9263fbad00af1a0fb","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}