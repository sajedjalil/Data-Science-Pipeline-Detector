{"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.4","nbconvert_exporter":"python","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python"}},"cells":[{"outputs":[],"source":"import os\nfrom PIL import Image\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nimport scipy.misc\nfrom skimage import transform\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n#convertering list of training data paths to df\ntrain_dir = '../input/train/'\ntrain_list = os.listdir(train_dir)\nrecords = []\nfor category in train_list:\n    img_list = os.listdir(train_dir + category)\n    for img in img_list:\n        records.append((img,category))\n        \ndf_train = pd.DataFrame.from_records(records,columns=['image','category'])\n\nprint(df_train.head())\n\n\n\n#looking at the test data\ntest_dir = '../input/test/'\ntest_list = os.listdir(test_dir)\nprint('Train Data', len(df_train.index))\nprint('Test Data',type(test_list),len(test_list))\nprint('categories',os.listdir(train_dir))\nprint('# of categories', len(os.listdir(train_dir)))","execution_count":null,"cell_type":"code","metadata":{"_uuid":"a43d555e4c3b411b203b7dba0d3885f76b5a0671","_cell_guid":"ff811823-dec0-4611-8932-548ffa457a20"}},{"source":"Let's see what our images look like.","metadata":{"_uuid":"3d28d002e29b2cc27ab6ca231c2ed596f26dda0c","_cell_guid":"09a868d4-5df3-486b-8655-1d900b3c4a34"},"cell_type":"markdown"},{"outputs":[],"source":"for i in list(df_train['image'])[0:1]:\n    img = Image.open(train_dir + df_train['category'][0] + '/' + i)\n    img.load()\n    data = np.asarray(img, dtype=\"float32\" )\n    plt.imshow(data)\n    plt.show()","execution_count":null,"cell_type":"code","metadata":{"_uuid":"803cb1778fa1ab0f91a16c6f25b565792fa49513","_cell_guid":"24cd4122-313b-4f6f-88ad-6c26f2f56b0b"}},{"source":"First, we will normalize our images and remove any images that possibly aren't square. Then we will create our X and y datasets.","metadata":{"_uuid":"0fd6033d8c97723794d7e93c26af5bfe764eda33","_cell_guid":"43bd567f-d5b1-496e-b701-b6bb2fa4a769"},"cell_type":"markdown"},{"outputs":[],"source":"dim_image = []\nfor i in (train_dir + df_train['category'] + '/' + df_train['image']):\n    img = Image.open(i)\n    data = img.size\n    dim_image.append(data[0])\nprint('smallest image dimension', min(dim_image))\n\ni_height = min(dim_image)\ni_width = min(dim_image)\n\nX = []\ncount = 0\nbad_images = []\n#df_train = df_train.drop(df_train.index[bad_images])\nfor i in (train_dir + df_train['category'] + '/' + df_train['image']):\n    img = Image.open(i)\n    img.load()\n    img = np.asarray(img, dtype='float32')\n    img = img/255\n    data = transform.resize(img,(49,49))\n    if data.size != 7203:\n        bad_images.append(count)\n#     plt.imshow(data)\n#     plt.show()\n#     X.append(data)\n    count += 1\nprint('bad images',bad_images)\n\ndf_train = df_train.drop(df_train.index[bad_images])\nfor i in (train_dir + df_train['category'] + '/' + df_train['image']):\n    img = Image.open(i)\n    img.load()\n    img = np.asarray(img, dtype='float32')\n    img = img/255\n    data = transform.resize(img,(49,49))\n    X.append(data)\n\nX = np.array(X)\n\ny = np.array(df_train['category'].astype('category').cat.codes)\n\nprint('Done creating X and y.')\nprint('X Shape',X.shape)","execution_count":null,"cell_type":"code","metadata":{"_uuid":"51564291a5bbce32efa8ef4c4b14cb18885dc526","_cell_guid":"1df6b4f6-7f54-4be2-b66d-a0854a161372"}},{"source":"**Convolutional Neural Network**","metadata":{},"cell_type":"markdown"},{"outputs":[],"source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nim_shape = (49,49,3)\nbatch_size = 10\n\ncnn  = Sequential([\n    Conv2D(32, kernel_size=(3,3), activation='linear', input_shape=im_shape, padding='same'),\n    LeakyReLU(alpha=0.1),\n    MaxPooling2D((2,2), padding='same'),\n    Conv2D(64, kernel_size=(3,3), activation='linear', padding='same'),\n    LeakyReLU(alpha=0.1),\n    MaxPooling2D((2,2), padding='same'),\n    Conv2D(128, kernel_size=(3,3), activation='linear', padding='same'),\n    LeakyReLU(alpha=0.1),\n    MaxPooling2D((2,2), padding='same'),\n    Flatten(),\n    Dense(50,activation='relu'),\n    Dense(12, activation='softmax')\n])\n\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n\ncnn. fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, validation_data=(X_test,y_test))","execution_count":null,"cell_type":"code","metadata":{}},{"source":"","metadata":{},"cell_type":"markdown"}]}