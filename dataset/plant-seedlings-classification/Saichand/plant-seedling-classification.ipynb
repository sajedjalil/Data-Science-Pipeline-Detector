{"cells":[{"metadata":{"id":"QpH0zvdTHUV9","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plot\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import tensorflow libraries**"},{"metadata":{"id":"pxfvGsH4bIzH","colab_type":"code","outputId":"2d8b2f59-f958-449a-ab14-734bfc6b11bc","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"id":"QdXsXtTkbM5k","colab_type":"code","outputId":"d7821814-d827-42f8-c240-1eae6a2a815e","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"../input/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The below function fetches all the images of training set from the directory.**"},{"metadata":{"id":"MHc4zpczBZNA","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_images(directory):\n    Images = []\n    Labels = []\n    for dir_name in os.listdir(directory): \n        for image_file in os.listdir(directory+dir_name):\n            image = cv2.imread(directory+dir_name+r'/'+image_file)\n            if image is not None:\n                image = cv2.resize(image,(300,300),)\n                Images.append(image)\n                Labels.append(dir_name)\n    return Images, Labels","execution_count":null,"outputs":[]},{"metadata":{"id":"7FWuFWqxBeYY","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"Images, Labels = get_images('../input/train/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Encoding the text labels to numericals, since machine learning models only understand data in numbers.**"},{"metadata":{"id":"xu0ihZnTHY5S","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"labels = []\nmapping = { 'Sugar beet': 0, 'Fat Hen': 1, 'Scentless Mayweed' : 2, 'Charlock' : 3,\n           'Small-flowered Cranesbill': 4, 'Maize': 5, 'Shepherds Purse' :6, 'Common wheat': 7,\n           'Common Chickweed': 8, 'Cleavers': 9, 'Loose Silky-bent' : 10, 'Black-grass': 11 }\nfor label in Labels:\n    labels.append(mapping[label])\ndel Labels","execution_count":null,"outputs":[]},{"metadata":{"id":"MGm0yoZK_h-p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"05be089f-fd3e-4ed5-88d9-963b20dad870","trusted":true},"cell_type":"code","source":"Images[0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reshaping the images to 4 dimensional tensors. (Model requires the input data to be in 4 dimensional format [no. of images, height, width, channels])**"},{"metadata":{"id":"S5BkEVq0CXCJ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"Images = np.reshape(Images,(-1,300,300,3))\nLabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"TvDIL2DfD8Lv","colab_type":"code","outputId":"cd2dde8f-b614-49fb-b6f9-117d196874b3","colab":{"base_uri":"https://localhost:8080/","height":50},"trusted":true},"cell_type":"code","source":"print(\"Shape of training data: \", Images.shape)\nprint(\"Shape of labels data: \", Labels.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting the data into Training and Validation to check the accuracy of the model on unseen data. **"},{"metadata":{"id":"4hrCXjapPFB1","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(Images, Labels, test_size=.2, random_state=42, stratify = Labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The below function performs one hot encoding on the labels.**"},{"metadata":{"id":"j53KKooFZuCu","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train,num_classes=12)\ny_val = np_utils.to_categorical(y_val,num_classes=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ImageDataGenerator helps in image augmentation by performing various operations on the existing images.**"},{"metadata":{"id":"jYjs8GDIMzJf","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                  )\n\nvalidation_datagen = ImageDataGenerator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del Images\ndel Labels","execution_count":null,"outputs":[]},{"metadata":{"id":"dt98WrdSNkaw","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\nvalidation_generator = validation_datagen.flow(x_val, y_val, batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here, I am using VGG16 Pretrained Network**"},{"metadata":{"id":"cOIyxa4ezEOk","colab_type":"code","outputId":"9750363f-e81e-42d8-97a0-1744be220231","colab":{"base_uri":"https://localhost:8080/","height":121},"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nvgg = VGG16(include_top=\n            False, weights='imagenet', input_shape = (300,300,3))","execution_count":null,"outputs":[]},{"metadata":{"id":"2WXE5t84w1nH","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import tensorflow.keras.optimizers as Optimizer\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAvgPool2D, GlobalMaxPooling2D, Concatenate\nfrom tensorflow.keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"id":"xoxZQQdlzETk","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"vgg.trainable=False\nfor layer in vgg.layers:\n    layer.trainable = False\n\nfc1 = Concatenate(axis=-1)([GlobalAvgPool2D()(vgg.output), GlobalMaxPooling2D()(vgg.output)])\nfc1 = Dense(400, activation='relu')(fc1)\nfc1_dropout = Dropout(0.3)(fc1)\nfc2 = Dense(200, activation='relu')(fc1_dropout)\nfc2_dropout = Dropout(0.3)(fc2)\nfc2 = Dense(75, activation='relu')(fc1_dropout)\noutput = Dense(12, activation='softmax')(fc2_dropout)\nmodel = Model(vgg.input, output)\n\nmodel.compile(optimizer=Optimizer.Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**During training, you can save the model's best weights using ModelCheckpoint. The one with the minimum validation loss is saved.**"},{"metadata":{"id":"9R_KViGUV-CQ","colab_type":"code","outputId":"3ca75b77-daa4-4171-fafc-bfb626460232","colab":{"base_uri":"https://localhost:8080/","height":6938},"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\ncheckpoint = ModelCheckpoint('saved_model.hdf5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\ntrained = model.fit_generator(train_generator,steps_per_epoch = 25, epochs=200, validation_data = validation_generator,\n                              validation_steps=10, \n                              verbose=1, callbacks = callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting the graph of model's accuracy and loss.**"},{"metadata":{"id":"X02kvmYeLb1T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":574},"outputId":"9898bdaf-1b9d-49a7-f12a-33179d260244","trusted":true},"cell_type":"code","source":"plot.plot(trained.history['acc'])\nplot.plot(trained.history['val_acc'])\nplot.title('Model accuracy')\nplot.ylabel('Accuracy')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()\n\nplot.plot(trained.history['loss'])\nplot.plot(trained.history['val_loss'])\nplot.title('Model loss')\nplot.ylabel('Loss')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"_yA0Cgu2Wx-s","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_test_images(directory):\n    Images = []\n    Image_names = []\n    for image_file in os.listdir(directory):\n        Image_names.append(image_file)\n        image = cv2.imread(directory+r'/'+image_file)\n        if image is not None:\n            image = cv2.resize(image,(300,300),)\n            Images.append(image)\n    return Images, Image_names","execution_count":null,"outputs":[]},{"metadata":{"id":"RFK7jETxNcKL","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"test_images, image_names = get_test_images('../input/test/')\ntest_images = np.array(test_images)\nprint(test_images.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here, To load the saved weights we need to define the same model architecture again. Also, make sure you do not compile the model this time.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg = VGG16(include_top=\n            False, weights='imagenet', input_shape = (300,300,3))\n\nvgg.trainable=False\nfor layer in vgg.layers:\n    layer.trainable = False\n\nfc1 = Concatenate(axis=-1)([GlobalAvgPool2D()(vgg.output), GlobalMaxPooling2D()(vgg.output)])\nfc1 = Dense(400, activation='relu')(fc1)\nfc1_dropout = Dropout(0.3)(fc1)\nfc2 = Dense(200, activation='relu')(fc1_dropout)\nfc2_dropout = Dropout(0.3)(fc2)\nfc2 = Dense(75, activation='relu')(fc1_dropout)\noutput = Dense(12, activation='softmax')(fc2_dropout)\nmodel = Model(vgg.input, output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('saved_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If you ever want to save the entire model, you can save using tensorflow.keras.models.save_model()**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorflow.keras.models.save_model(\n    model,\n    'tf_model.hdf5',\n    overwrite=True,\n    include_optimizer=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Then you can load the entire model using from tensorflow.keras.models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model('tf_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here, the model predicts the new images using function model.predict()**"},{"metadata":{"id":"vUzsKdL7QrtI","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_images)\npredictions = np.argmax(predictions, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelled_predictions = []\nmapping = {0: 'Sugar beet',1:'Fat Hen' ,2: 'Scentless Mayweed',3:  'Charlock', \n        4:'Small-flowered Cranesbill', 5:'Maize' ,\n        6: 'Shepherds Purse' ,7:'Common wheat' ,8:'Common Chickweed' ,\n        9:'Cleavers' ,10:'Loose Silky-bent'  ,11: 'Black-grass'}\nfor pred in predictions:\n    labelled_predictions.append(mapping[pred])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preparing the predictions for submission**"},{"metadata":{"id":"zQ_hh0ZuPB2_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":806},"outputId":"b2c5edbf-4d6e-43f7-e977-ce3a631694b2","trusted":true},"cell_type":"code","source":"d = []\ni=0\nfor pred in labelled_predictions:\n    d.append({'file': image_names[i], 'species': pred})\n    i=i+1\noutput = pd.DataFrame(d)\noutput.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Plant Seedling Classification","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}