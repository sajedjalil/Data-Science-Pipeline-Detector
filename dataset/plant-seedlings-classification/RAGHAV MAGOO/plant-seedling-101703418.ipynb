{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color:teal\">Plant </span><span style=\"color:green\">*Seedlings*</span><span style=\"color:teal\"> Classification</span>\n***\n\n"},{"metadata":{},"cell_type":"markdown","source":"#### Initialization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nimport itertools\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Activation, Flatten, Dropout, concatenate, Input, Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam, Adadelta\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.utils.np_utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/plant-seedlings-classification/train'\ntest_dir = '../input/plant-seedlings-classification/test'\nsample_submission = pd.read_csv('../input/plant-seedlings-classification/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Different Species"},{"metadata":{"trusted":true},"cell_type":"code","source":"SPECIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen',\n              'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse',\n              'Small-flowered Cranesbill', 'Sugar beet']\n\nfor species in SPECIES:\n    print('{} {} images'.format(species, len(os.listdir(os.path.join(train_dir, species)))))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Training Data Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = []\n\nfor species_num, species in enumerate(SPECIES):\n    for file in os.listdir(os.path.join(train_dir, species)):\n        train.append(['train/{}/{}'.format(species, file), species_num, species])\n        \ntrain = pd.DataFrame(train, columns=['file', 'species_num', 'species'])\n\nprint('Training Data: ',train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Image Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_mask_for_plant(image):\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    sensitivity = 35\n    lower_hsv = np.array([60 - sensitivity, 100, 50])\n    upper_hsv = np.array([60 + sensitivity, 255, 255])\n\n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\ndef segment_plant(image):\n    mask = create_mask_for_plant(image)\n    output = cv2.bitwise_and(image, image, mask = mask)\n    return output\n\ndef sharpen_image(image):\n    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n    return image_sharp\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Loading Traing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nx_train = []\n\nfor species in SPECIES:\n    lis =  os.listdir(os.path.join(train_dir, species))\n    new = []\n    \n    for l in lis:\n        new.append(os.path.join(train_dir, species) + '/' + l)\n        \n    for l in new:\n        img = cv2.imread(l)\n        img = cv2.resize(img,dsize=(256,256))\n        img_stack = segment_plant(img)\n        img_stack = sharpen_image(img_stack)\n        img_stack = cv2.cvtColor( img_stack, cv2.COLOR_RGB2GRAY )\n        img_stack = np.reshape(img_stack,(256,256,1))\n        x_train.append(np.concatenate((np.array(img),np.array(img_stack)),axis=2))\n        \n\nx_train = np.array(x_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### One-hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train['species_num']\nlabels = to_categorical(labels, num_classes = len(SPECIES))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CV-Partition"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x_train, labels, test_size = 0.1, random_state=10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Input Shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = x_train[1].shape\nprint('Input Shape is :', input_shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:teal\">Architecture</span>\n---"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def fire_incept(x, fire=16, intercept=64):\n    x = Conv2D(fire, (5,5), strides=(2,2))(x)\n    x = LeakyReLU(alpha=0.15)(x)\n    \n    left = Conv2D(intercept, (3,3), padding='same')(x)\n    left = LeakyReLU(alpha=0.15)(left)\n    \n    right = Conv2D(intercept, (5,5), padding='same')(x)\n    right = LeakyReLU(alpha=0.15)(right)\n    \n    x = concatenate([left, right], axis=3)\n    return x\n\ndef fire_squeeze(x, fire=16, intercept=64):\n    x = Conv2D(fire, (1,1))(x)\n    x = LeakyReLU(alpha=0.15)(x)\n    \n    left = Conv2D(intercept, (1,1))(x)\n    left = LeakyReLU(alpha=0.15)(left)\n    \n    right = Conv2D(intercept, (3,3), padding='same')(x)\n    right = LeakyReLU(alpha=0.15)(right)\n    \n    x = concatenate([left, right], axis=3)\n    return x\n\nimage_input=Input(shape=input_shape)\n\nx = fire_incept((image_input), fire=16, intercept=16)\n\nx = fire_incept(x, fire=32, intercept=32)\nx = fire_squeeze(x, fire=32, intercept=32)\n\nx = fire_incept(x, fire=64, intercept=64)\nx = fire_squeeze(x, fire=64, intercept=64)\n\nx = fire_incept(x, fire=64, intercept=64)\nx = fire_squeeze(x, fire=64, intercept=64)\n\nx = Conv2D(64, (3,3))(x)\nx = LeakyReLU(alpha=0.1)(x)\n\nx = Flatten()(x)\n\nx = Dense(512)(x)\nx = LeakyReLU(alpha=0.1)(x)\nx = Dropout(0.1)(x)\n\nout = Dense(len(SPECIES), activation='softmax')(x)\n\nmodel_new = Model(image_input, out)\nmodel_new.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Compile the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_new.compile(optimizer = Adam(lr=.00025) , loss = 'categorical_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Set a learning rate annealer"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \n                                            factor=0.5, min_lr=0.00001)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Augumentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=40, zoom_range = 0.2, width_shift_range=0.2, height_shift_range=0.2,\n                             horizontal_flip=True, vertical_flip=True)\ndatagen.fit(x_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load the Saved Weights *(pre-trained) *"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_new.load_weights('../input/pretrained-weight/model_weights.h5f')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span style=\"color:teal\">Fit the model</span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nepochs = 40\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"history = model_new.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size), epochs = epochs,\n                                  validation_data = (x_val,y_val), verbose = 1, \n                                  steps_per_epoch=x_train.shape[0] // batch_size, \n                                  callbacks=[learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Save Model Weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_new.save_weights('./model_weights_2.h5f', overwrite=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <span style=\"color:teal\">Predictions</span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntest = []\nfor file in os.listdir(os.path.join(test_dir)):\n    test.append(test_dir + '/' + file)\n\nfor i in range(len(test)):\n    img = cv2.imread(test[i])\n    img = cv2.resize(img,dsize=(256,256))\n    img_stack = segment_plant(img)\n    img_stack = sharpen_image(img_stack)\n    img_stack = cv2.cvtColor( img_stack, cv2.COLOR_RGB2GRAY )\n    img_stack = np.reshape(img_stack,(256,256,1))\n    x_test.append(np.concatenate((np.array(img),np.array(img_stack)),axis=2))\n\nx_test = np.array(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Prediction on Test Set"},{"metadata":{"trusted":false},"cell_type":"code","source":"Pred_labels = np.argmax(model_new.predict(x_test),axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Submit Test results (Deep Neural Network with _New Model_)"},{"metadata":{"trusted":false},"cell_type":"code","source":"Pred_labels = pd.DataFrame(Pred_labels,index =None,columns=['species_num'])\n\ntest_id = []\nfor file in os.listdir(test_dir):\n    test_id.append(['{}'.format(file)])\n\ntest_id = pd.DataFrame(test_id, columns=['file'])\n\ntest_df = pd.DataFrame()\ntest_df['species_num'] = Pred_labels['species_num']\ntest_df['file'] = test_id['file']\ntest_df['species'] = [SPECIES[i] for i in Pred_labels['species_num']]\n\nsubmission = pd.merge(left=sample_submission, right=test_df[['file', 'species']], on=\"file\", how=\"right\")\nsubmission.drop(['species_x'], axis = 1, inplace = True)\nsubmission.columns = ['file','species'] \n\nsubmission.to_csv('./submission.csv', index=False)\nprint(submission.head())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Bhartendu [matrixB](www.linkedin.com/in/bhartendu-thakur-56bb6285/), Machine Learning & Computing \n***\n##### Credits to:\n> [beluga](https://www.kaggle.com/gaborfodor/seedlings-pretrained-keras-models)\n***\n> [GÃ¡bor Vecsei](https://www.kaggle.com/gaborvecsei/plant-seedlings-fun-with-computer-vision)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}