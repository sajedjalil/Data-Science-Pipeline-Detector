{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.3","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python"}},"cells":[{"cell_type":"markdown","metadata":{"_uuid":"c5c8e70fc7c9cd5667759bb5224fbe3b1aabd692","_cell_guid":"55fd0f2e-cdca-47d3-972a-3b75d153a7ff"},"source":"**Training your own CNN model**\nThe steps involved are:-\n1.\n2.\n3.\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"30eb0745f0ddcdc29928590b73a0728dd73746b2","_cell_guid":"b976d500-1e50-44e0-97ee-bb08367520fd"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nimport os\nimport cv2\nimport skimage\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom PIL import Image, ImageOps\nfrom scipy.misc import imresize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n\nBase_Data_Folder = \"../input\"\nTrain_Data_Folder = os.path.join(Base_Data_Folder, \"train\")","outputs":[]},{"cell_type":"markdown","metadata":{"_kg_hide-input":false,"_uuid":"4246bb380e5fd0aa6109a967cd412cc6d683290e","_cell_guid":"d8746905-dc5b-4997-ac86-bff54dd876ba"},"source":"Read in the images and convert it from RGB to BGR (because OpenCV uses BGR)"},{"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_uuid":"840884072cc2330613e27c0d613cea422a59ca92","_cell_guid":"845f965d-b568-4e86-a7aa-89a3e37e9ef4"},"source":"images = glob('../input/train/*/*.png')\nimages_per_class = {}\nfor class_folder_name in os.listdir(Train_Data_Folder):\n    class_folder_path = os.path.join(Train_Data_Folder, class_folder_name)\n    class_label = class_folder_name\n    images_per_class[class_label] = []\n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n        images_per_class[class_label].append(image_bgr)","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"40d9543a4e428c11bd6a22681582178579cbd2e0","_cell_guid":"ac9426c8-7257-40f3-a4f5-af82886020f6"},"source":"**Number of images per class**"},{"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_uuid":"f0c185735938ec3f145f3a60edafc08ae89f41a5","_cell_guid":"5e65d7a9-8b25-4c7d-b293-3f519c5757e6"},"source":"for key,value in images_per_class.items():\n    print(\"{0} -> {1}\".format(key, len(value)))","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"cc4a7071f8a3061ba988ff4dc7b1d2125a09b309","_cell_guid":"97325388-8930-4bd2-b6d0-cabe7daf60f5"},"source":"*Preprocessing for the Images*"},{"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_uuid":"ec295c62b9bcfd0ea0862ab66e0eeec747bfa1db","_cell_guid":"dacbf115-26e8-41bc-8728-5c0d4c830177"},"source":"# Test image to see the changes\ntest_1 = images_per_class[\"Black-grass\"][97]\ntest_2 = images_per_class[\"Common wheat\"][97]\ntest_3 = images_per_class[\"Loose Silky-bent\"][97]\n\ntest_1hsv = cv2.cvtColor(test_1, cv2.COLOR_BGR2HSV)\ntest_2hsv = cv2.cvtColor(test_2, cv2.COLOR_BGR2HSV)\ntest_3hsv = cv2.cvtColor(test_3, cv2.COLOR_BGR2HSV)\n\nsensitivity = 35\nlower_hsv = np.array([60 - sensitivity, 100, 50])\nupper_hsv = np.array([60 + sensitivity, 255, 255])\n\nmask1 = cv2.inRange(test_1hsv, lower_hsv, upper_hsv)\nmask2 = cv2.inRange(test_2hsv, lower_hsv, upper_hsv)\nmask3 = cv2.inRange(test_3hsv, lower_hsv, upper_hsv)\n\nkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\nmask1 = cv2.morphologyEx(mask1, cv2.MORPH_CLOSE, kernel)\nmask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernel)\nmask3 = cv2.morphologyEx(mask3, cv2.MORPH_CLOSE, kernel)\n\noutput1 = cv2.bitwise_and(test_1, test_1, mask = mask1)\noutput2 = cv2.bitwise_and(test_2, test_2, mask = mask2)\noutput3 = cv2.bitwise_and(test_3, test_3, mask = mask3)\n\noutput_blurred1 = cv2.GaussianBlur(output1, (0, 0), 3)\noutput_blurred2 = cv2.GaussianBlur(output2, (0, 0), 3)\noutput_blurred3 = cv2.GaussianBlur(output3, (0, 0), 3)\n\noutput_sharp1 = cv2.addWeighted(output1, 1.5, output_blurred1, -0.5, 0)\noutput_sharp2 = cv2.addWeighted(output2, 1.5, output_blurred2, -0.5, 0)\noutput_sharp3 = cv2.addWeighted(output3, 1.5, output_blurred3, -0.5, 0)\n\nfig, axs = plt.subplots(1, 4, figsize=(20, 20))\naxs[0].imshow(test_1)\naxs[1].imshow(mask1)\naxs[2].imshow(output1)\naxs[3].imshow(output_sharp1)\n\nfig, axs = plt.subplots(1, 4, figsize=(20, 20))\naxs[0].imshow(test_2)\naxs[1].imshow(mask2)\naxs[2].imshow(output2)\naxs[3].imshow(output_sharp2)\n\nfig, axs = plt.subplots(1, 4, figsize=(20, 20))\naxs[0].imshow(test_3)\naxs[1].imshow(mask3)\naxs[2].imshow(output3)\naxs[3].imshow(output_sharp3)","outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"_uuid":"bdeab42f8c09c69370608d2b5eacde0f86279369","_cell_guid":"4f9bbd86-a0d3-497e-a14f-6e1f9e031a07"},"source":"Change all the images To Green and Black and save them"},{"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_uuid":"de4a024f2f1ec9e78c502c6b153d405b7c49fb10","_cell_guid":"6c72cfc1-ef46-4c5c-99af-7c02a3b8f89f"},"source":"sensitivity = 35\nlower_hsv = np.array([60 - sensitivity, 100, 50])\nupper_hsv = np.array([60 + sensitivity, 255, 255])\nkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n\nimages_per_class_processed = {}\nfor class_folder_name in os.listdir(Train_Data_Folder):\n    class_folder_path = os.path.join(Train_Data_Folder, class_folder_name)\n    class_label = class_folder_name\n    images_per_class_processed[class_label] = []\n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n        image_resized = cv2.resize(image_bgr, (128, 128)) \n        image_hsv = cv2.cvtColor(image_resized, cv2.COLOR_BGR2HSV)\n        \n        mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n\n        output = cv2.bitwise_and(image_resized, image_resized, mask = mask)\n\n        output_blurred = cv2.GaussianBlur(output, (0, 0), 3)\n        output_sharp = cv2.addWeighted(output, 1.5, output_blurred, -0.5, 0)\n        \n        images_per_class_processed[class_label].append(output_sharp)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_uuid":"98c89909aa2903d29f7c9b08aed9609cac4c32fa","_cell_guid":"3eb26d17-a4dd-4418-a3d4-b2fc12c8d3bb"},"source":"sensitivity = 35\nlower_hsv = np.array([60 - sensitivity, 100, 50])\nupper_hsv = np.array([60 + sensitivity, 255, 255])\nkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n\nimagez = glob('../input/train/*/*.png')\nlabels = []\nimages_processed = []\nfor image in imagez:\n    if image[-3:] != 'png':\n        continue\n    labels.append(image.split('/')[-2])\n    new_img = Image.open(image)\n    images_processed.append(ImageOps.fit(new_img, (128, 128), Image.ANTIALIAS).convert('RGB'))","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_uuid":"1f705b230d03a90c353739b84e62191e578545af","_cell_guid":"e8377036-4662-4053-927a-f774d2d43274"},"source":"sensitivity = 35\nlower_hsv = np.array([60 - sensitivity, 100, 50])\nupper_hsv = np.array([60 + sensitivity, 255, 255])\nkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1,1))\n\nimage = np.array(images_processed[213])\nimage_x = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\nimage_hsv = cv2.cvtColor(image_x, cv2.COLOR_BGR2HSV)\nmask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\nmask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\noutput = cv2.bitwise_and(image, image, mask = mask)\noutput_blurred = cv2.GaussianBlur(output, (0, 0), 3)\noutput_sharp = cv2.addWeighted(output, 1.5, output_blurred, -0.5, 0)\nImage.fromarray(output_sharp)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_uuid":"30b8f7de297bda3e3d934b6a8e42cee6ca96cdc9","_cell_guid":"4dc67498-fd72-4aa1-b443-d6e4546e2ac6"},"source":"","outputs":[]}],"nbformat":4,"nbformat_minor":1}