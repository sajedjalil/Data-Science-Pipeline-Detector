{"cells":[{"metadata":{"_cell_guid":"616f7c5b-fd90-42e3-b744-d699e42ce55b","_uuid":"eed6bbd44f0d258fa2dbf0a96e7472fe77dfd9e9"},"cell_type":"markdown","source":"# Transfer learning with pretrained Keras models\n\nAlthough Kernel resources were increased recently we still can not train useful CNNs without GPU. Fortunately prediction is much faster (<1s/image) making it possible to run meaningful experiments with Kaggle Kernels."},{"metadata":{"_cell_guid":"e2dd0914-a862-4aa5-9741-433e87c63a45","_uuid":"0ea36321c46ab52fa904673fe22a221b5d27c858","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 16\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom tqdm import tqdm","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"deb8f726-2aa2-4a55-bda7-a5f663fb7b97","collapsed":true,"_uuid":"6c1ceceae3119ef773b0611b5ab7f6613498f408","trusted":true},"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"ee262cec-0fad-42f7-a92a-8e99c0f5e16d","collapsed":true,"_uuid":"315ff18239ff7eb4ed11528e4e2ca8619b13703d","trusted":true},"cell_type":"code","source":"start = dt.datetime.now()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"463cad4a-17ac-4aa0-85a7-b731f06c6557","_uuid":"9dad24f2b7f2cf932e36b2a5bd259ad7350961f3"},"cell_type":"markdown","source":"# Use Keras Pretrained Models dataset\nKernels can't use network connection to download pretrained keras model weights.\nThis dataset helps you to apply your favorite pretrained model in the Kaggle Kernel environment. \nYou can find more details [here](https://www.kaggle.com/gaborfodor/keras-pretrained-models).\n\nWe have to copy the pretrained models to the cache directory (~/.keras/models) where keras is looking for them."},{"metadata":{"_cell_guid":"73599529-b6a0-4a42-8122-6a503617a70a","_uuid":"254f7813a878c36be78b279a371c8079845aa239","trusted":true},"cell_type":"code","source":"!ls ../input/keras-pretrained-models/","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"b492684d-afcb-4a21-8604-50fb6905bd08","collapsed":true,"_uuid":"4934928bfc41b0123fe6bd254cbf05588ae2c582","trusted":true},"cell_type":"code","source":"cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"9f282c9d-51ed-4bee-8546-9516d1a74215","collapsed":true,"_uuid":"81a1be7942ff36b8ccbcdcdf00c68d6c7b49a495","trusted":true},"cell_type":"code","source":"!cp ../input/keras-pretrained-models/xception* ~/.keras/models/","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"f393ca60-35f3-439b-8025-501628fd3d3e","_uuid":"09d010bfbcc1589536e73d8567d2c0ed86cc2130","trusted":true},"cell_type":"code","source":"!ls ~/.keras/models","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"2d06e357-93db-42b1-895b-9a32c535ab5c","_uuid":"b8120325c4c1da5f8fb388cae2cee87cb99f7a78"},"cell_type":"markdown","source":"# Check the plant seedlings"},{"metadata":{"_cell_guid":"9652c662-852c-4fe0-921a-565a0c3b389f","_uuid":"d48e3acaf4555a53dba57dc33c379c8400399430","trusted":true},"cell_type":"code","source":"!ls ../input/plant-seedlings-classification","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"14620782-c426-42b7-a567-233f194b7b7a","collapsed":true,"_uuid":"c6c779c33c038bef8a3db965439a12657983d466","trusted":true},"cell_type":"code","source":"CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\nNUM_CATEGORIES = len(CATEGORIES)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"04d813fb-4351-4b87-9eba-1a443ddb61d6","collapsed":true,"_uuid":"b688c3a5cbcbb6ed57169f845a9b80dd85c3949d","trusted":true},"cell_type":"code","source":"SAMPLE_PER_CATEGORY = 200\nSEED = 1987\ndata_dir = '../input/plant-seedlings-classification/'\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')\nsample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"d83a1778-76c4-44fe-a494-f971fee3de95","_uuid":"616267c1245a074c8ad0e66d3480e648b837c375","trusted":true},"cell_type":"code","source":"sample_submission.head(2)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"1f7481dc-8326-47f2-9cb4-33b6ca28ea42","_uuid":"6a5300af60fd507b77a7d39d81562734e1a6e91b","trusted":true},"cell_type":"code","source":"for category in CATEGORIES:\n    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"60bbddff-12f2-4690-acf0-72da1a6503a5","_uuid":"fa85ae6d0f64c29d568ca697e6299eaa3b4eb556","trusted":true},"cell_type":"code","source":"train = []\nfor category_id, category in enumerate(CATEGORIES):\n    for file in os.listdir(os.path.join(train_dir, category)):\n        train.append(['train/{}/{}'.format(category, file), category_id, category])\ntrain = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\ntrain.head(2)\ntrain.shape","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"58913b37-0e65-463d-9c48-01ed6a00b638","_uuid":"949b925d64c4f50e25dc7f84a1d870e5735bc08e"},"cell_type":"markdown","source":"# Training sample"},{"metadata":{"_cell_guid":"507b4a32-38b6-4dff-8714-430a1ce23342","_uuid":"be192e8d9ea6d53b2d3a78bf6bdab25f662993b0","trusted":true},"cell_type":"code","source":"train = pd.concat([train[train['category'] == c][:SAMPLE_PER_CATEGORY] for c in CATEGORIES])\ntrain = train.sample(frac=1)\ntrain.index = np.arange(len(train))\ntrain.head(2)\ntrain.shape","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"8fe2c6b8-1414-4a98-ba09-adbde64121ee","_uuid":"d88f1fbcdd4ddb777435ce1f27996f4fb69d089a","trusted":true},"cell_type":"code","source":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test/{}'.format(file), file])\ntest = pd.DataFrame(test, columns=['filepath', 'file'])\ntest.head(2)\ntest.shape","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"2662f1a2-1930-49bd-85cd-e36a59b3dd9b","collapsed":true,"_uuid":"a17ad0110424e8545fa73c1f3988ccc1ec9598f9","trusted":true},"cell_type":"code","source":"def read_img(filepath, size):\n    img = image.load_img(os.path.join(data_dir, filepath), target_size=size)\n    img = image.img_to_array(img)\n    return img","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"e13db656-a9be-4ed2-b24b-bd504344c6ab","_uuid":"b21a709045cfd96227a2f1c7e258741347bc39d7"},"cell_type":"markdown","source":"# Example images"},{"metadata":{"_cell_guid":"f444d98e-b6b2-4e81-a1cd-6a0b9cf1d5c4","_uuid":"d41dd29a0c62d1cca4ee82ac234e95cfb32cc6ab","trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(NUM_CATEGORIES, NUM_CATEGORIES))\ngrid = ImageGrid(fig, 111, nrows_ncols=(NUM_CATEGORIES, NUM_CATEGORIES), axes_pad=0.05)\ni = 0\nfor category_id, category in enumerate(CATEGORIES):\n    for filepath in train[train['category'] == category]['file'].values[:NUM_CATEGORIES]:\n        ax = grid[i]\n        img = read_img(filepath, (224, 224))\n        ax.imshow(img / 255.)\n        ax.axis('off')\n        if i % NUM_CATEGORIES == NUM_CATEGORIES - 1:\n            ax.text(250, 112, filepath.split('/')[1], verticalalignment='center')\n        i += 1\nplt.show();","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"8ea7a715-c3ca-4f4d-999b-9659eaa5a1e3","_uuid":"1c93527fe50e1b91e9d9d2be905500d96bf7f76b"},"cell_type":"markdown","source":"# Validation split"},{"metadata":{"_cell_guid":"ced5450c-7ce8-4405-b34d-bf37eb38e0b3","_uuid":"7f2c46099d0f7555e923d3ca4e7b112d68dd51cf","trusted":true},"cell_type":"code","source":"np.random.seed(seed=SEED)\nrnd = np.random.random(len(train))\ntrain_idx = rnd < 0.8\nvalid_idx = rnd >= 0.8\nytr = train.loc[train_idx, 'category_id'].values\nyv = train.loc[valid_idx, 'category_id'].values\nlen(ytr), len(yv)","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"140b509f-94ad-4f64-96d0-f76ef299ef1a","_uuid":"fc2e809d03bfc8195b1d02f2b765515effa01bbb"},"cell_type":"markdown","source":"## Extract Xception bottleneck features"},{"metadata":{"_cell_guid":"7152595a-bc0e-4c1e-9945-b63ecbd695dd","_uuid":"f3f59af75a0ad4f667064f50e0356cf2b1447f19","trusted":true},"cell_type":"code","source":"INPUT_SIZE = 299\nPOOLING = 'avg'\nx_train = np.zeros((len(train), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, file in tqdm(enumerate(train['file'])):\n    img = read_img(file, (INPUT_SIZE, INPUT_SIZE))\n    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_train[i] = x\nprint('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"910da5f0-74ce-4ca1-b817-0bd576c8876c","_uuid":"6d5f2aea4581170e2498e8127f35e44c7e3550d8","trusted":true},"cell_type":"code","source":"Xtr = x_train[train_idx]\nXv = x_train[valid_idx]\nprint((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\nxception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\ntrain_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\nvalid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\nprint('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\nprint('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"ed155341-c762-4257-b22c-50cb26d1e0dc","_uuid":"26e3a6e3383fcfc85b2cf02ae35709d69a21d1ae"},"cell_type":"markdown","source":"## LogReg on Xception bottleneck features"},{"metadata":{"_cell_guid":"1b619668-b540-407a-b478-42eb55526c32","_uuid":"105b5bb8a0c7f085ba640684c61b963b09e57d3b","trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlogreg.fit(train_x_bf, ytr)\nvalid_probs = logreg.predict_proba(valid_x_bf)\nvalid_preds = logreg.predict(valid_x_bf)","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"6a8e4c54-f4a3-406c-9bdb-79b8d68f9778","_uuid":"2672c5978efb2e56921c44ad38986fde2d6c0661","trusted":true},"cell_type":"code","source":"print('Validation Xception Accuracy {}'.format(accuracy_score(yv, valid_preds)))","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"520f241f-4ac2-4ffd-9200-ebb7067c6c19","_uuid":"1907b6d61dea447b6292247b526e65430a9272c7"},"cell_type":"markdown","source":"## Confusion matrix"},{"metadata":{"_cell_guid":"bee3a60d-47cc-4c99-bac1-ae995d36a44f","collapsed":true,"_uuid":"296af537c2f84893baf57e2838cc58a06fe514de","trusted":true},"cell_type":"code","source":"cnf_matrix = confusion_matrix(yv, valid_preds)","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"4a502dbf-0451-4a2c-bd6a-36942d2c9b40","_uuid":"26d7c4fcfd7a5b3402cd2619ff4f6375a708e5fb","trusted":true},"cell_type":"code","source":"abbreviation = ['BG', 'Ch', 'Cl', 'CC', 'CW', 'FH', 'LSB', 'M', 'SM', 'SP', 'SFC', 'SB']\npd.DataFrame({'class': CATEGORIES, 'abbreviation': abbreviation})","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"abb70092-d085-4ee4-bee9-f36345d252a1","_uuid":"01c7ed4b0384db2ed9f5f904112a63c4210386e8","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1)\nax = sns.heatmap(cnf_matrix, ax=ax, cmap=plt.cm.Greens, annot=True)\nax.set_xticklabels(abbreviation)\nax.set_yticklabels(abbreviation)\nplt.title('Confusion Matrix')\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nfig.savefig('Confusion matrix.png', dpi=300)\nplt.show();","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"78241212-ebfe-453f-abd3-98c8b8362b91","_uuid":"bd6591ab1070226352dba8eea2619b13a625d023"},"cell_type":"markdown","source":"## Create submission"},{"metadata":{"_cell_guid":"d94b2d0d-3a48-4502-a74c-c919236bbd94","_uuid":"3286a8262ed80b2cd7fcecea4138b2c15de08197","trusted":true},"cell_type":"code","source":"x_test = np.zeros((len(test), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, filepath in tqdm(enumerate(test['filepath'])):\n    img = read_img(filepath, (INPUT_SIZE, INPUT_SIZE))\n    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_test[i] = x\nprint('test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"6218510d-9efe-4935-a9f3-468b71127298","_uuid":"67305f8cda58943a437b9e029351692f44ac339c","trusted":true},"cell_type":"code","source":"test_x_bf = xception_bottleneck.predict(x_test, batch_size=32, verbose=1)\nprint('Xception test bottleneck features shape: {} size: {:,}'.format(test_x_bf.shape, test_x_bf.size))\ntest_preds = logreg.predict(test_x_bf)","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"0bffccab-cb6b-4e85-9d9f-746d22843509","collapsed":true,"_uuid":"ac7c62255748e3ca80c5424da9de54dcf12da463","trusted":true},"cell_type":"code","source":"test['category_id'] = test_preds\ntest['species'] = [CATEGORIES[c] for c in test_preds]\ntest[['file', 'species']].to_csv('submission.csv', index=False)","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"debc53f3-9454-4b48-9961-e5663db49167","_uuid":"65220cc1537f74448fba07284f0a8befa8cddb5e","trusted":true},"cell_type":"code","source":"end = dt.datetime.now()\nprint('Total time {} s.'.format((end - start).seconds))\nprint('We almost used the one hour time limit.')","execution_count":29,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}