{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0,"cells":[{"metadata":{"_cell_guid":"493f31f4-1c27-e8d7-2dd2-9d2452192b69","_active":true,"collapsed":false},"source":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport dicom\nimport os\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\n\nfrom skimage import measure, morphology\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\n# Some constants \nINPUT_FOLDER = '../input/sample_images/'\npatients = os.listdir(INPUT_FOLDER)\npatients.sort()\npatients = [k for k in patients if '.DS_Store' not in k]\n\n# Function to get the slice thinkness\ndef load_scan(path):\n    dicoms=os.listdir(path)\n    dicoms = [k for k in dicoms if '.DS_Store' not in k]\n    slices = [dicom.read_file(path + '/' + s) for s in dicoms]\n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        \n    return slices\n\n# Convert to Hounsfield Units (HU)\ndef get_pixels_hu(slices):\n    image = np.stack([s.pixel_array for s in slices])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)\n\n\nfirst_patient = load_scan(INPUT_FOLDER + patients[0])\nfirst_patient_pixels = get_pixels_hu(first_patient)\nplt.hist(first_patient_pixels.flatten(), bins=80, color='c')\nplt.xlabel(\"Hounsfield Units (HU)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Show some slice in the middle\nplt.imshow(first_patient_pixels[80], cmap=plt.cm.gray)\nplt.show()\n\n\n# \npath=INPUT_FOLDER + patients[0]\ndicoms=os.listdir(path)\ndicoms = [k for k in dicoms if '.DS_Store' not in k]\nslices = [dicom.read_file(path + '/' + s) for s in dicoms]\nslices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\nimage = np.stack([s.pixel_array for s in slices])\nplt.imshow(image[80], cmap=plt.cm.gray)\nplt.show()\n\n#A scan may have a pixel spacing of [2.5, 0.5, 0.5], which means that the distance between slices is 2.5 millimeters. For a different scan this may be [1.5, 0.725, 0.725], this can be problematic for automatic analysis (e.g. using ConvNets)!\n#A common method of dealing with this is resampling the full dataset to a certain isotropic resolution. If we choose to resample everything to 1mm1mm1mm pixels we can use 3D convnets without worrying about learning zoom/slice thickness invariance.\n#Whilst this may seem like a very simple step, it has quite some edge cases due to rounding. Also, it takes quite a while.\ndef resample(image, scan, new_spacing=[1,1,1]):\n    # Determine current pixel spacing\n    spacing = np.array([scan[0].SliceThickness] + scan[0].PixelSpacing, dtype=np.float32)\n    print ('original spacing:',spacing)\n\n    resize_factor = spacing / new_spacing\n    print ('resize_factor:',resize_factor)\n\n    print ('image shape',image.shape)\n    \n    new_real_shape = image.shape * resize_factor\n    print ('new real shape:',new_real_shape)\n    new_shape = np.round(new_real_shape)\n    print ('rounded shape:',new_shape)\n    real_resize_factor = new_shape / image.shape\n    print ('real size factor',real_resize_factor)\n    new_spacing = spacing / real_resize_factor\n    print ('new spacing',new_spacing)\n    \n    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n    \n    return image, new_spacing\n\n\ndef plot_3d(image, threshold=-300):\n    \n    # Position the scan upright, \n    # so the head of the patient would be at the top facing the camera\n    p = image.transpose(2,1,0)\n    \n    verts, faces = measure.marching_cubes(p, threshold)\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n    mesh = Poly3DCollection(verts[faces], alpha=0.70)\n    face_color = [0.45, 0.45, 0.75]\n    mesh.set_facecolor(face_color)\n    ax.add_collection3d(mesh)\n\n    ax.set_xlim(0, p.shape[0])\n    ax.set_ylim(0, p.shape[1])\n    ax.set_zlim(0, p.shape[2])\n\n    plt.show()\n\npix_resampled, spacing = resample(first_patient_pixels, first_patient, [1,1,1])\nprint(\"Shape before resampling\\t\", first_patient_pixels.shape)\nprint(\"Shape after resampling\\t\", pix_resampled.shape)\n\ndef largest_label_volume(im, bg=-1):\n    vals, counts = np.unique(im, return_counts=True)\n\n    counts = counts[vals != bg]\n    vals = vals[vals != bg]\n\n    if len(counts) > 0:\n        return vals[np.argmax(counts)]\n    else:\n        return None\n    \ndef segment_lung_mask(image, fill_lung_structures=True):\n    \n    # not actually binary, but 1 and 2. \n    # 0 is treated as background, which we do not want\n    binary_image = np.array(image > -320, dtype=np.int8)+1\n    labels = measure.label(binary_image)\n    \n    # Pick the pixel in the very corner to determine which label is air.\n    #   Improvement: Pick multiple background labels from around the patient\n    #   More resistant to \"trays\" on which the patient lays cutting the air \n    #   around the person in half\n    background_label = labels[0,0,0]\n    \n    #Fill the air around the person\n    binary_image[background_label == labels] = 2\n    \n    \n    # Method of filling the lung structures (that is superior to something like \n    # morphological closing)\n    if fill_lung_structures:\n        # For every slice we determine the largest solid structure\n        for i, axial_slice in enumerate(binary_image):\n            axial_slice = axial_slice - 1\n            labeling = measure.label(axial_slice)\n            l_max = largest_label_volume(labeling, bg=0)\n            \n            if l_max is not None: #This slice contains some lung\n                binary_image[i][labeling != l_max] = 1\n\n    \n    binary_image -= 1 #Make the image actual binary\n    binary_image = 1-binary_image # Invert it, lungs are now 1\n    \n    # Remove other air pockets insided body\n    labels = measure.label(binary_image, background=0)\n    l_max = largest_label_volume(labels, bg=0)\n    if l_max is not None: # There are air pockets\n        binary_image[labels != l_max] = 0\n \n    return binary_image\n\n#plot_3d(pix_resampled, 400)\n\nsegmented_lungs = segment_lung_mask(pix_resampled, False)\nsegmented_lungs_fill = segment_lung_mask(pix_resampled, True)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"cc31164d-af9f-bb6f-0092-caa08a822ce1","_active":false,"collapsed":false},"source":"plot_3d(segmented_lungs, 0)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"7fb5dc9d-ac17-aec8-cdc6-6deabf5b85ca","_active":false,"collapsed":false},"source":"np.unique(segmented_lungs[30],return_counts=True)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"4102b8bf-205e-cc29-3ac6-279de5a84b93","_active":false,"collapsed":false},"source":"plot_3d(segmented_lungs_fill, 0)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"682bc2e7-7e4c-e982-d896-981f1d3254e6","_active":false,"collapsed":false},"source":"plot_3d(segmented_lungs_fill - segmented_lungs, 0)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"46de7d08-d886-d731-943d-f37f0ae83194","_active":false,"collapsed":false},"source":"binary_image -= 1","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"21c78463-9056-184a-fd71-1eeb687284ae","_active":false,"collapsed":false},"source":"image=pix_resampled\nd=pd.DataFrame((np.array(image > -320, dtype=np.int8)+1).flatten())\n#np.array(image > -320, dtype=np.int8)+1\n","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"5195d454-54ce-1622-8d64-d71a341a3ff2","_active":false,"collapsed":false},"source":"d.columns=['val']\nmy_tab = pd.crosstab(index=d['val'],  # Make a crosstab\n                             columns='count')\nmy_tab","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"c5433162-8c93-002b-5fa9-bda7c5a848df","_active":false,"collapsed":false},"source":"binary_image = np.array(image > -320, dtype=np.int8)+1\nd=pd.DataFrame(binary_image[0].flatten())\nd.columns=['val']\nmy_tab = pd.crosstab(index=d['val'],  # Make a crosstab\n                             columns='count')\nmy_tab\n#type(d)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"97fb9d3d-8fc1-bdfe-b15c-7f3d55e98b1a","_active":false,"collapsed":false},"source":"labels = measure.label(binary_image)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"81fb54ab-a852-2209-079a-ed06a20ac5bf","_active":false,"collapsed":false},"source":" background_label = labels[0,0,0]","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"4ab556b4-5ab7-bca4-6158-669c26323706","_active":false,"collapsed":false},"source":"binary_image[background_label == labels] = 2\nnp.unique(binary_image[0],return_counts=True)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"c0bcb169-a2f9-ddaf-2463-41723b4c258a","_active":false,"collapsed":false},"source":"axial_slice=binary_image[0]-1\nlabeling = measure.label(axial_slice)\nnp.unique(labeling,return_counts=True)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"6df932cb-6178-d0e5-8752-5bc8c8ad3740","_active":false,"collapsed":false},"source":"\naxial_slice=binary_image[0]-1\nlabeling = measure.label(axial_slice)\nim=labeling\nvals, counts = np.unique(im, return_counts=True)\nvals,counts\n#vals = vals[vals != bg]\nvals != bg","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"414c5a43-1b57-77b1-dff5-56f255e16cd3","_active":false,"collapsed":false},"source":null,"execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"f1f3b746-8d3a-f539-2b44-2c65a7b78867","_active":false,"collapsed":false},"source":"for i, axial_slice in enumerate(binary_image):\n    print(i)\n    print(axial_slice.shape)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"1b940a73-3f53-0a97-ea8e-92864ffb5210","_active":false,"collapsed":false},"source":null,"execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"}]}