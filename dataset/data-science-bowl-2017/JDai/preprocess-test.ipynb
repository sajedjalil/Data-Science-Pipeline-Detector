{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"7ad4fd64-571c-f3fa-36ee-edb2f8c0e416"},"source":"Ref to\n[DeepMan](https://www.kaggle.com/deepman)'s excellent notebook \nhttps://www.kaggle.com/deepman/data-science-bowl-2017/3d-convolutional-neural-network-w-o-programming for the preprocession. Thx, DeepMan!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"901f6501-7b3c-ee01-18ac-664e7e9341f7"},"outputs":[],"source":"import os\nos.listdir('../input/sample_images/')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c746d32-e1b8-8f81-4eac-0fac7129649c"},"outputs":[],"source":"import dicom"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f28a95c-ee57-50d5-3c04-47f93fe00f39"},"outputs":[],"source":"# use DeepMan's script here\ndef load_scan_as_HU_nparray(path):\n    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n    \n    image = np.stack([s.pixel_array for s in slices])\n    \n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)   "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b1ca6f5-a9cf-b655-cdec-48930270d772"},"outputs":[],"source":"sample_scan_path = '../input/sample_images/0a0c32c9e08cc2ea76a71649de56be6d'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83926373-b8a1-4cdb-07fb-10337a6d9c9b"},"outputs":[],"source":"import numpy as np\nsample_scan = load_scan_as_HU_nparray(sample_scan_path)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"545ce049-7f48-206d-df9e-d489b6d294aa"},"outputs":[],"source":"import matplotlib.pyplot as plt\nplt.imshow(sample_scan[49])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f420545-010d-5b44-c0ba-10a59a836149"},"outputs":[],"source":"# A little dissection of DeepMan's \"seperate_lungs_and_pad\" function\nimage = sample_scan[55]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c45c3ef0-e99b-1924-507f-92a4abc85841"},"outputs":[],"source":"plt.imshow(image)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e05970ab-ac37-2be1-1d6c-9e1b3bc4a9a8"},"outputs":[],"source":"marker_internal = image < -400"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"586619ac-07d8-443c-4628-ea1703a3e07c"},"outputs":[],"source":"marker_internal"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26e53a8d-e7e0-fde1-6e44-f65c60f01baf"},"outputs":[],"source":"plt.imshow(marker_internal)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31a6e547-edae-b3de-77f6-f9fbb1522573"},"outputs":[],"source":"from skimage import segmentation\nmarker_internal = segmentation.clear_border(marker_internal)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40ef4e04-b353-eccf-57d9-75a6c685d7f7"},"outputs":[],"source":"plt.imshow(marker_internal)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"243155f1-21dd-60ba-5616-503cd59ac8d9"},"outputs":[],"source":"from skimage import measure\nmarker_internal_labels = measure.label(marker_internal)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd869f48-b6ee-9540-12df-878b5c7ea479"},"outputs":[],"source":"marker_internal_labels"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a98cad18-997d-473c-7fda-f4ce69a9eb83"},"outputs":[],"source":"plt.imshow(marker_internal_labels)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4de41be7-2e72-d328-8e48-7e79f5d41589"},"outputs":[],"source":"regions = measure.regionprops(marker_internal_labels)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b831e1c-3c0b-b8c0-3155-ae174a099e0c"},"outputs":[],"source":"dir(regions[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8ae3991-85d5-7207-aff6-26d0abf0689e"},"outputs":[],"source":"regions[0].area"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a994e737-39f1-df41-3f82-670fd7c03f32"},"outputs":[],"source":"regions[0].coords[:20,:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aaeccd7f-f1ad-3d47-b350-2d9166206fc9"},"outputs":[],"source":"areas = [r.area for r in regions]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22974c47-0c52-d826-40e8-a7673f29762d"},"outputs":[],"source":"areas"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"28901d8c-9ce2-9e2e-1cf9-bae31f7bc080"},"outputs":[],"source":"areas.sort()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"21d9ff52-e3ac-2bd4-5792-72edee1db200"},"outputs":[],"source":"areas"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c7f54b6-6b2f-582f-ddf8-5ab647b6cb49"},"outputs":[],"source":"areas[-2]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54153c99-2934-4f91-8e98-47e1fc6eed85"},"outputs":[],"source":"marker_internal_labels.max()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a95b46f0-52b7-f0ae-e013-b66dd274864b"},"outputs":[],"source":"marker_internal_labels.min()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aef5b32a-6aaf-666d-53d6-87e1a3bd2c50"},"outputs":[],"source":"marker_internal_labels_tst = np.copy(marker_internal_labels)\nfor coordinates in regions[0].coords:\n    marker_internal_labels_tst[coordinates[0], coordinates[1]] = 0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e043438-8e98-42e6-2ab0-72b7482d25d0"},"outputs":[],"source":"plt.hist(marker_internal_labels.flatten())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68e21580-493d-436f-f6b7-634cbfc5025c"},"outputs":[],"source":"plt.hist(marker_internal_labels_tst.flatten())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae1b0919-34b7-c571-6d2c-64de277fb63b"},"outputs":[],"source":"plt.imshow(marker_internal_labels_tst)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a179229-5dde-280b-b3ed-aab990860d42"},"outputs":[],"source":"marker_internal_labels_tst2 = np.copy(marker_internal_labels)\nfor region in regions:\n    if region.area < areas[-2]:\n        for coordinates in region.coords:                \n            marker_internal_labels_tst2[coordinates[0], coordinates[1]] = 0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37bd5c91-54b7-bbc2-966f-4d4eff0b92e1"},"outputs":[],"source":"plt.imshow(marker_internal_labels_tst2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe86ac2c-f92e-8536-9864-b3a7cf72460c"},"outputs":[],"source":"marker_internal = marker_internal_labels_tst2 > 0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ace18b1-53ec-b756-3fda-cfabdca595be"},"outputs":[],"source":"plt.imshow(marker_internal)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5e0e4c3-c7ec-3329-1d68-1e3793676f89"},"outputs":[],"source":"# Test the whole segmentation function\ndef seperate_lungs_and_pad(scan):\n    \n    # make total 256 slices fill in -1100 as exterme value \n    segmented_scan = np.full ((256, 512, 512), THRESHOLD_LOW)\n    \n    for i, image in enumerate (scan):\n        \n        # Ignore all slices later than 255 if required.\n        if (i == 256):\n            break\n        \n        # Creation of the internal Marker\n        marker_internal = image < -400\n        marker_internal = segmentation.clear_border(marker_internal)\n        marker_internal_labels = measure.label(marker_internal)\n        areas = [r.area for r in measure.regionprops(marker_internal_labels)]\n        areas.sort()\n        if len(areas) > 2:\n            for region in measure.regionprops(marker_internal_labels):\n                if region.area < areas[-2]:\n                    for coordinates in region.coords:                \n                           marker_internal_labels[coordinates[0], coordinates[1]] = 0\n        marker_internal = marker_internal_labels > 0\n        #Creation of the external Marker\n        external_a = ndimage.binary_dilation(marker_internal, iterations=10)\n        external_b = ndimage.binary_dilation(marker_internal, iterations=55)\n        marker_external = external_b ^ external_a\n        #Creation of the Watershed Marker matrix\n        marker_watershed = np.zeros((512, 512), dtype=np.int)\n        marker_watershed += marker_internal * 255\n        marker_watershed += marker_external * 128\n\n        #Creation of the Sobel-Gradient\n        sobel_filtered_dx = ndimage.sobel(image, 1)\n        sobel_filtered_dy = ndimage.sobel(image, 0)\n        sobel_gradient = np.hypot(sobel_filtered_dx, sobel_filtered_dy)\n        sobel_gradient *= 255.0 / np.max(sobel_gradient)\n\n        #Watershed algorithm\n        watershed = morphology.watershed(sobel_gradient, marker_watershed)\n\n        #Reducing the image created by the Watershed algorithm to its outline\n        outline = ndimage.morphological_gradient(watershed, size=(3,3))\n        outline = outline.astype(bool)\n\n        #Performing Black-Tophat Morphology for reinclusion\n        #Creation of the disk-kernel and increasing its size a bit\n        blackhat_struct = [[0, 0, 1, 1, 1, 0, 0],\n                           [0, 1, 1, 1, 1, 1, 0],\n                           [1, 1, 1, 1, 1, 1, 1],\n                           [1, 1, 1, 1, 1, 1, 1],\n                           [1, 1, 1, 1, 1, 1, 1],\n                           [0, 1, 1, 1, 1, 1, 0],\n                           [0, 0, 1, 1, 1, 0, 0]]\n        blackhat_struct = ndimage.iterate_structure(blackhat_struct, 8)\n        #Perform the Black-Hat\n        outline += ndimage.black_tophat(outline, structure=blackhat_struct)\n\n        #Use the internal marker and the Outline that was just created to generate the lungfilter\n        lungfilter = np.bitwise_or(marker_internal, outline)\n        #Close holes in the lungfilter\n        #fill_holes is not used here, since in some slices the heart would be reincluded by accident\n        lungfilter = ndimage.morphology.binary_closing(lungfilter, structure=np.ones((5,5)), iterations=3)\n\n        #Apply the lungfilter (note the filtered areas being assigned 30 HU)\n        segmented_scan[i] = np.where(lungfilter == 1, image, 30*np.ones((512, 512)))\n        \n    return segmented_scan"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31f5d56d-d67e-8804-930d-6fedc8b60d87"},"outputs":[],"source":"THRESHOLD_LOW = -1100\nimport scipy.ndimage as ndimage\nfrom skimage import morphology\n#processed_scan = seperate_lungs_and_pad (sample_scan)\n\n# Kernel dead on this step\n# \"The kernel was stopped, for exceeding the limits on idle time (20 minutes), storage (512 Mb) or memory (8Gb). You can use the restart button in the toolbar to try again...\"\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fdff6885-b614-1cbb-0eee-d41d08fe9123"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}