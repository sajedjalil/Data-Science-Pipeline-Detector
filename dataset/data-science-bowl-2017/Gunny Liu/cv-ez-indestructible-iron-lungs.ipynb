{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"758145f0-9a92-a150-40bb-adf54096ee0c"},"source":"Hello World, we love preprocessing and hate lung cancer."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"224e45ae-7c02-1154-e67e-e47639e1d4d9"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"a07f5103-d036-968f-40d7-57649bbb4864"},"source":"# Preprocessing Agenda:\n\n* Averaging every 10 pixels\n* Decimating\n* Chunking for the CNN?\n* Flattening\n\n## Original Work: \n\n* **Loading the DICOM files**, and adding missing metadata  \n* **Converting the pixel values to *Hounsfield Units (HU)***, and what tissue these unit values correspond to"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d12eab6-3340-fa57-84a1-91fe13886996"},"outputs":[],"source":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport dicom\nimport os\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\n\nfrom skimage import measure, morphology\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\n# gun dev note: one patient per folder\nINPUT_FOLDER = '../input/sample_images/'\npatients = os.listdir(INPUT_FOLDER)\npatients.sort()"},{"cell_type":"markdown","metadata":{"_cell_guid":"56147dd5-3127-8844-644d-0b1565c9dac3"},"source":"# I/O: Scans to PyDicom Datasets"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f50e5b1-c1e8-14a8-591b-eb466e5adc0d"},"outputs":[],"source":"# Load the scans in given folder path\ndef load_scan(path):\n    # gun dev note: every folder contains multiple slices, which is \"a single scan\"\n    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n        \n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n    \n    # gdn: for capturing hidden slice thickness field; assuming that the slice thickness is uniform across all slices\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        \n    return slices"},{"cell_type":"markdown","metadata":{"_cell_guid":"79a91d86-1009-ac6d-14d4-a1c117f3dd64"},"source":"# Houndsfield Units\n* HU: std measure of radiodensity\n* From Wikipedia:\n\n![HU examples][1]\n\n# Convert to proper HU units: \n* the pixel_array of each slice is encoded in unscaled HU\n* pixels that fall outside of these bounds get the fixed value -2000\n* multiplying with the rescale slope \n* adding the intercept\n\n  [1]: http://i.imgur.com/4rlyReh.png"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e60f402c-0cd9-f0d2-0c3d-3e7af98f9845"},"outputs":[],"source":"def get_pixels_hu(slices):\n    image = np.stack([s.pixel_array for s in slices])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        # each slice in slices has lots of \"hidden\" attributes\n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9a64cb22-2b5d-425c-7ced-0e977ca04fa7"},"source":"# Visualization of HU Distribution"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0012bd3-50f6-278b-de58-a2a39361f1bb"},"outputs":[],"source":"# gdn: viz on patient num 0\nfirst_patient = load_scan(INPUT_FOLDER + patients[0])\n\n# gdn: display entire Dataset. use dir(\"search_term\") function call to find fields that match \n    # a pydicom Dataset instance is essentially a dict mapping\n    # large set of hidden fields contained in each Dataset\nprint(len(first_patient))\n# gdn: don't print the repr unless you wanna see it real time; too many fields\nprint(first_patient)\n\nfirst_patient_pixels = get_pixels_hu(first_patient)\n# gdn: viz of HU distribution in 0th patient scan\n    # what if... we run algorithms on this data?\nplt.hist(first_patient_pixels.flatten(), bins=80, color='c')\nplt.xlabel(\"Hounsfield Units (HU)\")\nplt.ylabel(\"Frequency\")\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"2f199017-59b7-d9a0-bfdc-c2dc7d295c1e"},"source":"# Visualization of Random Sample"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e07a9313-6bc5-5233-228f-cf336e4ef91f"},"outputs":[],"source":"# 134 slices, 512 x 512 pixels per slice\nprint(first_patient_pixels.shape)\nnum_slices, num_rows, num_cols = first_patient_pixels.shape\n\n# Higher HU = whiter; Lower HU = darker\n# gdn: quick try at taking HU mean across all 134 slices of image\nplt.imshow(first_patient_pixels.mean(axis=0), cmap=plt.cm.gray)\nplt.show()\n# gdn: visualize a random slice \nidx = np.random.randint(0, num_slices)\nplt.imshow(first_patient_pixels[idx], cmap=plt.cm.gray)\nplt.show()\n\n# gdn: how can we quantify the viz though? how dark/light versus what HU value??"},{"cell_type":"markdown","metadata":{"_cell_guid":"894982a5-844c-ebb2-a48c-62a057cf5ec9"},"source":"# Averaging per 10 Slices\n* intuitively, averaging across all e.g. 134 slices is not effective\n* try averaging on 10 slices instead"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3eda0d6a-19e5-7004-da4c-37f533f1d6c7"},"outputs":[],"source":"'''\ninput: a scan processed by get_pixels_hu; ndarray representation\noutput: same scan, same representation, averaged per 10-slices\n'''\ndef averaging_10_slices(scan):\n    # gdn: split into chunks of 10 slices each\n        # outputs a list\n    num_slices, num_rows, num_cols = scan.shape\n    num_chunks = num_slices / 10 + 1\n    split_scan = np.array_split(scan, num_chunks, axis=0)\n    \n    # gdh: take mean across axis 0 on each batch\n    split_scan_out = []\n    for each in split_scan:\n        split_scan_out.append(each.mean(axis=0))\n    \n    return np.stack(split_scan_out, axis=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0195ee8e-ac45-ba01-da26-c91ca3b5b33f"},"outputs":[],"source":"first_patient_pixels_avg10 = averaging_10_slices(first_patient_pixels)\nnum_slices, num_rows, num_cols = first_patient_pixels_avg10.shape\n\n# gdn: viz all post-averaged slice\nfor _ in range(num_slices):\n    plt.imshow(first_patient_pixels_avg10[_], cmap=plt.cm.gray)\n    plt.show()\n    \n# gdn: compare this quantitatively with the raw stuff?"},{"cell_type":"markdown","metadata":{"_cell_guid":"ae70ecba-82a6-099b-ac6a-c2f69c055929"},"source":"# Resampling\nA scan may have a pixel spacing of `[2.5, 0.5, 0.5]`, which means that the distance between slices is `2.5` millimeters. For a different scan this may be `[1.5, 0.725, 0.725]`, this can be problematic for automatic analysis (e.g. using ConvNets)! \n\nA common method of dealing with this is resampling the full dataset to a certain isotropic resolution. If we choose to resample everything to 1mm*1mm*1mm pixels we can use 3D convnets without worrying about learning zoom/slice thickness invariance. \n\nWhilst this may seem like a very simple step, it has quite some edge cases due to rounding. Also, it takes quite a while.\n\nBelow code worked well for us (and deals with the edge cases):"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}