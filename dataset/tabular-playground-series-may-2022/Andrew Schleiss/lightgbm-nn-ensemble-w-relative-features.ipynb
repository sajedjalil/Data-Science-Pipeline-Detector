{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Summary \n\nThis notebook is a continuation of the baseline[ model and EDA](https://www.kaggle.com/code/slythe/tps-may-super-eda-base-model). ","metadata":{"papermill":{"duration":0.033929,"end_time":"2022-05-14T06:50:38.865254","exception":false,"start_time":"2022-05-14T06:50:38.831325","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸ“© Import Libraries ðŸ“© ","metadata":{"papermill":{"duration":0.032817,"end_time":"2022-05-14T06:50:38.929531","exception":false,"start_time":"2022-05-14T06:50:38.896714","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Data and visualization\nimport pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\nfrom collections import Counter\n\n# hyperparameter tuning \nimport optuna \n\nimport gc\n\n#modelling\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.calibration import calibration_curve, CalibratedClassifierCV\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Input, InputLayer, Add, Concatenate\nfrom tensorflow.keras.utils import plot_model\n\nimport datetime\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":7.50022,"end_time":"2022-05-14T06:50:46.462519","exception":false,"start_time":"2022-05-14T06:50:38.962299","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parameters \nsns.set_theme()\n\nCALIBRATION = True\nEPOCHS =3000\nNN_EPOCHS = 200\n\nDROP_COLS = False\n\nFULL_RUN = False\n\nFEATS_2 = True","metadata":{"papermill":{"duration":0.04043,"end_time":"2022-05-14T06:50:46.537244","exception":false,"start_time":"2022-05-14T06:50:46.496814","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ’¾ Load Data ðŸ’¾\n\nI have run [Feature Engine](https://feature-engine.readthedocs.io/en/1.3.x/) to create relative features of the float columns. \\\nThis was run outside of Kaggle (on AWS instances due to memory constraints) \\\nA notebook detailing the process can be found [here](https://www.kaggle.com/code/slythe/feature-engine-selecting-creating-features?scriptVersionId=95047781) \n\nI then ran Powershap on these features to reduce the number, Powershap process can be found [here](https://www.kaggle.com/code/slythe/powershap-feature-selection-recursive)","metadata":{"papermill":{"duration":0.031725,"end_time":"2022-05-14T06:50:46.600854","exception":false,"start_time":"2022-05-14T06:50:46.569129","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_original = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\",index_col = 0)\ntest_original = pd.read_csv(\"../input/tabular-playground-series-may-2022/test.csv\",index_col = 0)\n\ntrain_features = pd.read_pickle(\"../input/tps-may-22-relative-feature-engine-powershap/Relative_feats_powershap_train.pickle\")\ntest_features = pd.read_pickle(\"../input/tps-may-22-relative-feature-engine-powershap/Relative_feats_powershap_test.pickle\")\nsub = pd.read_csv(\"../input/tabular-playground-series-may-2022/sample_submission.csv\",index_col = 0)","metadata":{"papermill":{"duration":38.791551,"end_time":"2022-05-14T06:51:25.424413","exception":false,"start_time":"2022-05-14T06:50:46.632862","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int_cols = train_original.dtypes[(train_original.dtypes ==\"int64\") & (train_original.dtypes.index != \"target\") ].index\nfloat_cols = train_original.dtypes[train_original.dtypes ==\"float64\" ].index","metadata":{"papermill":{"duration":0.039691,"end_time":"2022-05-14T06:51:25.497233","exception":false,"start_time":"2022-05-14T06:51:25.457542","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_cols = [col for col in train_features.columns if col not in train_original]\nprint(add_cols)","metadata":{"papermill":{"duration":0.038575,"end_time":"2022-05-14T06:51:25.56853","exception":false,"start_time":"2022-05-14T06:51:25.529955","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features[add_cols]","metadata":{"papermill":{"duration":0.364341,"end_time":"2022-05-14T06:51:25.967643","exception":false,"start_time":"2022-05-14T06:51:25.603302","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add newly created features \ntrain_original[add_cols]= train_features[add_cols]\ntest_original[add_cols]= test_features[add_cols]\ntrain_original","metadata":{"papermill":{"duration":2.769078,"end_time":"2022-05-14T06:51:28.787446","exception":false,"start_time":"2022-05-14T06:51:26.018368","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_features\ndel test_features","metadata":{"papermill":{"duration":0.185928,"end_time":"2022-05-14T06:51:29.026723","exception":false,"start_time":"2022-05-14T06:51:28.840795","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸŒŸ Feature Engineering ðŸŒŸ","metadata":{"papermill":{"duration":0.033839,"end_time":"2022-05-14T06:51:29.095175","exception":false,"start_time":"2022-05-14T06:51:29.061336","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"* Unicode (ord) code taken from [cabaxiom](https://www.kaggle.com/code/cabaxiom/tps-may-22-eda-lgbm-model#Feature-Engineering)\n\nAdditional feats taken from wti200 and [ambrosm](https://www.kaggle.com/code/ambrosm/tpsmay22-advanced-keras) ","metadata":{"papermill":{"duration":0.034911,"end_time":"2022-05-14T06:51:29.164705","exception":false,"start_time":"2022-05-14T06:51:29.129794","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for df in [train_original, test_original]:\n    # Extract the 10 letters of f_27 into individual features\n    for i in range(10):\n        df[f'ch{i}'] = df.f_27.str.get(i).apply(ord) - ord('A')\n        \n    # unique_characters feature is from https://www.kaggle.com/code/cabaxiom/tps-may-22-eda-lgbm-model\n    df[\"unique_characters\"] = df.f_27.apply(lambda s: len(set(s)))\n    \n    # Feature interactions: create three ternary features\n    # Every ternary feature can have the values -1, 0 and +1\n    df['i_02_21'] = (df.f_21 + df.f_02 > 5.2).astype(int) - (df.f_21 + df.f_02 < -5.3).astype(int)\n    df['i_05_22'] = (df.f_22 + df.f_05 > 5.1).astype(int) - (df.f_22 + df.f_05 < -5.4).astype(int)\n    i_00_01_26 = df.f_00 + df.f_01 + df.f_26\n    df['i_00_01_26'] = (i_00_01_26 > 5.0).astype(int) - (i_00_01_26 < -5.0).astype(int)","metadata":{"papermill":{"duration":17.569207,"end_time":"2022-05-14T06:51:46.768107","exception":false,"start_time":"2022-05-14T06:51:29.1989","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neural_feats = [col for col in train_original.columns if col not in add_cols and col not in [\"target\", 'f_27', 'unique_text_str']]\nprint(neural_feats)","metadata":{"papermill":{"duration":0.046877,"end_time":"2022-05-14T06:51:46.851939","exception":false,"start_time":"2022-05-14T06:51:46.805062","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_letters = ['A', 'B', 'D', 'E', 'P', 'C', 'S', 'G', 'F', 'Q', 'H', 'N', 'K', 'R', 'M', 'T', 'O', 'J', 'I', 'L']\n\ndef feature_engineering(df):\n    \n    # taken from wti200 https://www.kaggle.com/code/wti200/analysing-interactions-with-shap and CABAXIOM https://www.kaggle.com/code/cabaxiom/tps-may-22-eda-lgbm-model#Feature-Engineering\n    df['i_02_21'] = (df.f_21 + df.f_02 > 5.2).astype(int) - (df.f_21 + df.f_02 < -5.3).astype(int)\n    df['i_05_22'] = (df.f_22 + df.f_05 > 5.1).astype(int) - (df.f_22 + df.f_05 < -5.4).astype(int)\n    i_00_01_26 = df.f_00 + df.f_01 + df.f_26\n    df['i_00_01_26'] = (i_00_01_26 > 5.0).astype(int) - (i_00_01_26 < -5.0).astype(int)\n    \n    #Unicoding\n    for i in range(10):\n        df[\"f_27_\"+str(i)] = df[\"f_27\"].str[i].apply(lambda x: ord(x) - ord(\"A\"))\n    \n    # Get Unique letters\n    df[\"unique_text_str\"] = df[\"f_27\"].apply(lambda x :  ''.join([str(n) for n in list(set(x))]) )\n    df[\"unique_text_str\"] = df[\"unique_text_str\"].astype(\"category\")\n\n    \n    return df\n\ntrain = feature_engineering(train_original)\ntest = feature_engineering(test_original)","metadata":{"papermill":{"duration":32.694113,"end_time":"2022-05-14T06:52:19.582076","exception":false,"start_time":"2022-05-14T06:51:46.887963","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"F_27_CAT_FEATS = [f'p_{i}' for i in range(10)]\n\ndef feature_engineering2(df):\n    categories = [chr(c) for c in range(65, 85)]\n\n    for i in range(0, 10):\n        df[f'p_{i}'] = list(df['f_27'].map(lambda x: x[i]))\n        df[f'p_{i}'] = pd.Categorical(df[f'p_{i}'], categories=categories)\n    \n    return df\n\nif FEATS_2:\n    print(\"adding feats\")\n    feature_engineering2(train)\n    feature_engineering2(test)","metadata":{"papermill":{"duration":8.164224,"end_time":"2022-05-14T06:52:27.78295","exception":false,"start_time":"2022-05-14T06:52:19.618726","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mathematical Features \n* We will do this with certain columns i.e. the float columns (but certain groupings)","metadata":{"papermill":{"duration":0.036509,"end_time":"2022-05-14T06:52:27.856472","exception":false,"start_time":"2022-05-14T06:52:27.819963","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_original[float_cols].describe()","metadata":{"papermill":{"duration":1.152758,"end_time":"2022-05-14T06:52:29.045991","exception":false,"start_time":"2022-05-14T06:52:27.893233","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Group Float columns \n* We can see from the above that certain columns have similar std/ min/ max, we will group them\n* f_00 to f_06 => Group1\n* f_19 to f_26 => Group2\n* f28 looks to be seperate from both groups","metadata":{"papermill":{"duration":0.057752,"end_time":"2022-05-14T06:52:29.16201","exception":false,"start_time":"2022-05-14T06:52:29.104258","status":"completed"},"tags":[]}},{"cell_type":"code","source":"group1_float =['f_00','f_01','f_02','f_03','f_04','f_05','f_06']\ngroup2_float = ['f_19','f_20','f_21','f_22','f_23','f_24','f_25','f_26']\n\ndef mathematical_feats(df,cols, suffix):\n    df[f\"sum_{suffix}\"] = df[cols].sum(axis = 1)\n    df[f\"mean_{suffix}\"] = df[cols].mean(axis = 1)\n    df[f\"std_{suffix}\"] = df[cols].std(axis = 1)\n#     df[f\"min_{suffix}\"] = df[cols].min(axis = 1)\n#     df[f\"max_{suffix}\"] = df[cols].max(axis = 1)\n    df[f\"median_{suffix}\"] = df[cols].median(axis = 1)\n    df[f\"mad_{suffix}\"] = df[cols].mad(axis = 1)\n    df[f\"max-min_{suffix}\"] = df[cols].max(axis = 1) - df[cols].min(axis = 1)\n    \n    df[f\"q01_{suffix}\"] = df[cols].quantile(q= 0.01, axis =1)\n    df[f\"q1_{suffix}\"] = df[cols].quantile(q= 0.1, axis =1)\n    df[f\"q25_{suffix}\"] = df[cols].quantile(q= 0.25, axis =1) \n    df[f\"q50_{suffix}\"] = df[cols].quantile(q= 0.5, axis =1) \n    df[f\"q75_{suffix}\"] = df[cols].quantile(q= 0.75, axis =1) \n    df[f\"q95_{suffix}\"] = df[cols].quantile(q= 0.95, axis =1) \n    df[f\"q99_{suffix}\"] = df[cols].quantile(q= 0.99, axis =1)\n    df[f\"kurt_{suffix}\"] = df[cols].kurt(axis =1) \n    df[f\"skew_{suffix}\"] = df[cols].skew( axis =1)\n    \n    return df\n\nmathematical_feats(train, float_cols, \"group2_float\")\nmathematical_feats(test, float_cols, \"group2_float\")\n# mathematical_feats(train, float_cols, \"group1_float\")\n# mathematical_feats(test, float_cols, \"group1_float\")","metadata":{"papermill":{"duration":22.367879,"end_time":"2022-05-14T06:52:51.587362","exception":false,"start_time":"2022-05-14T06:52:29.219483","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop unimportant features \nFrom previous runs ","metadata":{"papermill":{"duration":0.057227,"end_time":"2022-05-14T06:52:51.702956","exception":false,"start_time":"2022-05-14T06:52:51.645729","status":"completed"},"tags":[]}},{"cell_type":"code","source":"feats = ['f_02_mul_f_03', 'f_19_add_f_22', 'f_21_add_f_22', 'f_19_add_f_23',\n       'f_20_add_f_23', 'f_05_add_f_22', 'f_19_add_f_26', 'f_21_add_f_23',\n       'f_19_add_f_24', 'f_20_add_f_24', 'f_23_add_f_24', 'f_19_add_f_25',\n       'f_20_add_f_25', 'f_26_add_f_26', 'f_25_add_f_26', 'f_23_add_f_26',\n       'f_22_add_f_26', 'f_20_add_f_21', 'f_01_add_f_26', 'f_00_add_f_26',\n       'f_03_mul_f_05', 'f_19_mul_f_23', 'f_05_truediv_f_28', 'f_00_mul_f_26',\n       'f_24_add_f_25', 'f_06_mul_f_28', 'f_05_mul_f_28', 'f_04_mul_f_28',\n       'f_03_mul_f_28', 'f_02_mul_f_28', 'f_01_mul_f_28', 'f_00_mul_f_28',\n       'f_01_mul_f_26', 'f_22_mul_f_25', 'f_03_truediv_f_28', 'f_19_mul_f_25',\n       'f_22_mul_f_24', 'f_19_mul_f_24', 'f_20_mul_f_22', 'f_19_mul_f_22',\n       'f_00_add_f_01', 'f_19_add_f_20', 'f_02_add_f_21', 'f_02_truediv_f_28',\n       'f_21_add_f_25']\n\ndef drop_feats(df, feats):\n    df.drop(feats ,axis = 1 ,inplace = True )\n    return df \n\nif DROP_COLS:\n    print(\"dropping columns\")\n    drop_feats(train, feats)\n    drop_feats(test, feats)","metadata":{"papermill":{"duration":0.066919,"end_time":"2022-05-14T06:52:51.827564","exception":false,"start_time":"2022-05-14T06:52:51.760645","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downcasting","metadata":{"papermill":{"duration":0.057925,"end_time":"2022-05-14T06:52:51.943907","exception":false,"start_time":"2022-05-14T06:52:51.885982","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df\n\nreduce_mem_usage(train)\nreduce_mem_usage(test)","metadata":{"papermill":{"duration":53.373512,"end_time":"2022-05-14T06:53:45.3781","exception":false,"start_time":"2022-05-14T06:52:52.004588","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print([col for col in train.columns])","metadata":{"papermill":{"duration":0.046142,"end_time":"2022-05-14T06:53:45.46433","exception":false,"start_time":"2022-05-14T06:53:45.418188","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸš€ Base Model ðŸš€","metadata":{"papermill":{"duration":0.039711,"end_time":"2022-05-14T06:53:45.544297","exception":false,"start_time":"2022-05-14T06:53:45.504586","status":"completed"},"tags":[]}},{"cell_type":"code","source":"categorical_features = [\"unique_text_str\"\n                        #, \"f29_f30\"\n                        #,\"min_letter\"\n                        #,\"max_letter\"\n                        #,\"f_29\",\"f_30\"\n                       ]\n\n\nif FEATS_2:\n    categorical_features.extend(F_27_CAT_FEATS)\n    \nif DROP_COLS:\n    for col in drop_feats:\n        categorical.remove(col) ","metadata":{"papermill":{"duration":0.046519,"end_time":"2022-05-14T06:53:45.630614","exception":false,"start_time":"2022-05-14T06:53:45.584095","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop the text column as we already have features created earlier\nX = train.drop([\"target\",\"f_27\"],axis =1)\ny= train[\"target\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 42)\n","metadata":{"papermill":{"duration":1.8552,"end_time":"2022-05-14T06:53:47.526035","exception":false,"start_time":"2022-05-14T06:53:45.670835","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Base model","metadata":{"papermill":{"duration":0.04022,"end_time":"2022-05-14T06:53:47.607763","exception":false,"start_time":"2022-05-14T06:53:47.567543","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def run_lgb_model(X_train, y_train, X_test, y_test, test):\n    model = lgb.LGBMClassifier(\n    objective= 'binary',\n    metric= \"auc\",\n    num_iterations = EPOCHS,\n    num_threads= -1,\n    learning_rate= 0.18319492258552644,\n    boosting= 'gbdt',\n#     lambda_l1= 0.00028648667113792726,\n#     lambda_l2= 0.00026863027834978876,\n    num_leaves= 229,\n    max_depth= 0,\n    min_child_samples=80,\n    device = 'cpu',\n    max_bins=511, \n    random_state=42 \n    )\n    model.fit(X_train,y_train, eval_set=[(X_test,y_test)], callbacks = [lgb.early_stopping(30)],eval_metric=\"auc\" , \n              categorical_feature = categorical_features\n             )\n\n\n    val_preds = model.predict_proba(X_test)[:, 1]\n    y_preds = model.predict_proba(X_train)[:, 1]\n    \n    test_preds = model.predict_proba(test.drop(\"f_27\",axis =1))[:, 1]\n\n    score = model.best_score_[\"valid_0\"][\"auc\"]\n    print(\"LGB Intrinsic AUC:\", roc_auc_score(y_train, y_preds))\n    print(\"LGB Val AUC:\", score)\n        \n    return model,val_preds, test_preds, score\n\nlgb_model,val_preds, test_preds, lgb_score = run_lgb_model(X_train, y_train, X_test, y_test, test)","metadata":{"papermill":{"duration":2873.257548,"end_time":"2022-05-14T07:41:40.905595","exception":false,"start_time":"2022-05-14T06:53:47.648047","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test","metadata":{"papermill":{"duration":0.065949,"end_time":"2022-05-14T07:41:41.036187","exception":true,"start_time":"2022-05-14T07:41:40.970238","status":"failed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running now \nShould be the best (trying to get 0.9967554527789698) = ","metadata":{}},{"cell_type":"markdown","source":"## Calibration \nTaken from last months kernel [TPS April ](https://www.kaggle.com/code/slythe/calibrated-xgboost-human-activity-recognition)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"prob_true, prob_pred = calibration_curve(y_test, val_preds, n_bins=10)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calibrator = CalibratedClassifierCV(lgb_model, method = \"isotonic\", cv='prefit')\ncalibrator.fit(X_test, y_test)\ncal_preds = calibrator.predict_proba(X_test)[:, 1]\n\nprint(\"Validation AUC:\", lgb_model.best_score_[\"valid_0\"][\"auc\"])\nprint(\"Calibrated AUC:\" , roc_auc_score(y_test, cal_preds ))","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,10))\nplt.plot(prob_pred,prob_true, marker='o', linewidth=1, label='xgb model probabilities')\n\n# reference line\nline = mlines.Line2D([0, 1], [0, 1], color='black')\ntransform = ax.transAxes\nline.set_transform(transform)\nax.add_line(line)\n#plt.axvline(x=0.2, color = \"r\")\nfig.suptitle('Calibration plot')\nax.set_xlabel('Predicted probability (mean)')\nax.set_ylabel('Fraction of positives (%True  in each bin)')\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_model():\n\n    activation = 'swish'\n    inputs = Input(shape=(len(neural_feats)))\n    x = Dense(128, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(inputs)\n    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    x = Dense(32, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    x = Dense(16, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    x = Dense(8, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    x = Dense(1, \n              activation='sigmoid',\n             )(x)\n    model = Model(inputs, x)\n    return model\n\nplot_model(my_model(), show_layer_names=False, show_shapes=True)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef run_nn_model(X_train, y_train, X_test, y_test, test,features):\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train[features])\n    X_test = scaler.transform(X_test[features])\n    test_s = scaler.transform(test[features])\n    validation_data = (X_train, y_train)\n\n    # Define the learning rate schedule and EarlyStopping\n    lr_start=0.01\n\n    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, \n                           patience=4, verbose=0)\n    es = EarlyStopping(monitor=\"val_loss\",\n                       patience=12, \n                       verbose=1,\n                       mode=\"min\", \n                       restore_best_weights=True)\n    callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n\n\n    # Construct and compile the model\n    model = my_model()\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_start),\n                  metrics='AUC',\n                  loss=tf.keras.losses.BinaryCrossentropy())\n\n    # Train the model\n    history = model.fit(X_train, y_train, \n                        validation_data=validation_data, \n                        epochs=NN_EPOCHS,\n                        verbose=0,\n                        batch_size=2048,\n                        shuffle=True,\n                        callbacks=callbacks)\n    \n    # Inference for validation\n    y_va_pred = model.predict(X_test, batch_size=len(X_test), verbose=0)\n    test_preds = model.predict(test_s, batch_size=len(test_s), verbose=0)[:,-1]\n    \n    #eval\n    score = roc_auc_score(y_test, y_va_pred)\n    print(f\"NN Val AUC: {score:.5f}\")\n       \n    return model, test_preds, score\n\nnn_model, test_preds ,nn_score= run_nn_model(X_train, y_train, X_test, y_test, test,neural_feats)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âŽ Cross validation âŽ","metadata":{"execution":{"iopub.execute_input":"2022-05-04T13:15:44.717395Z","iopub.status.busy":"2022-05-04T13:15:44.716577Z","iopub.status.idle":"2022-05-04T13:15:44.721768Z","shell.execute_reply":"2022-05-04T13:15:44.720717Z","shell.execute_reply.started":"2022-05-04T13:15:44.717335Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"gc.collect()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not FULL_RUN:\n    cv = KFold(n_splits = 5, shuffle = True,random_state=42)\n    #cv = StratifiedKFold(n_splits = 5, shuffle = True,random_state=42)\n\n    preds = []\n    auc_cv = []\n    \n    for fold, (idx_train, idx_val) in enumerate(cv.split(X,y)):\n        print(\"\\n\")\n        print(\"#\"*10, f\"Fold: {fold}\",\"#\"*10)\n        X_train , X_test = X.iloc[idx_train] , X.iloc[idx_val]\n        y_train , y_test = y[idx_train] , y[idx_val]\n\n        lgb_model,lgb_val_preds , lgb_test_preds, lgb_score = run_lgb_model(X_train, y_train, X_test, y_test, test)        \n\n        if CALIBRATION:\n            calibrator = CalibratedClassifierCV(lgb_model, method = \"isotonic\", cv='prefit')\n            calibrator.fit(X_test, y_test)\n            auc = roc_auc_score(y_test, calibrator.predict_proba(X_test)[:, 1])\n            print(\"\\n Calibration AUC:\" , auc)\n            preds.append(calibrator.predict_proba(test.drop(\"f_27\",axis =1))[:, 1])\n        else:\n            preds.append(lgb_test_preds)\n            auc_cv.append(lgb_score)\n            \n        nn_model, nn_test_preds ,nn_score= run_nn_model(X_train, y_train, X_test, y_test, test,neural_feats)\n        preds.append(nn_test_preds)\n        auc_cv.append(nn_score)\n        \n        del lgb_model\n        del nn_model\n        del nn_test_preds\n        del lgb_test_preds\n        del lgb_val_preds\n        del lgb_score\n        del nn_score\n\n    print(\"FINAL AUC: \", np.mean(auc_cv))","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸŒ¾ Full Run: Seed ðŸŒ¾\n\nfrom  [CABAXIOM](https://www.kaggle.com/code/cabaxiom/tps-may-22-eda-lgbm-model/notebook#Model)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"def pred_test():\n    pred_full = []\n    for seed in range(5):\n        \n        print(f\"\\n### Running seed {seed} ###\")\n        \n        model = build_model()\n        \n        model.fit(X,y)\n        \n        #calibration\n        print(\" Calibrating\")\n        calibrator = CalibratedClassifierCV(model, method = \"isotonic\", cv='prefit')\n        calibrator.fit(X, y)\n        cal_preds = calibrator.predict_proba(test.drop(\"f_27\",axis =1))\n        \n        #preds = model.predict_proba(test.drop(\"f_27\"),axis =1)[:,1]\n        pred_full.append(cal_preds[:,1])\n    return pred_full\n\nif FULL_RUN:\n    pred_full = pred_test()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“¡ Submission ðŸ“¡","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"# Full Submission vs CV\n\nif FULL_RUN:\n    sub[\"target\"] = np.array(pred_full).mean(axis =0)\n    sub.to_csv(\"sub_full.csv\")\n    sub\nelse:\n    #CV submission \n    sub[\"target\"] = np.array(preds).mean(axis =0)\n    sub.to_csv(\"submission_csv.csv\")\n    sub","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20,8))\nsns.histplot(sub[\"target\"])\n#sns.histplot(sub_full[\"target\"],color = \"red\" , alpha = 0.5,label = \"Full prediiction\")\nplt.show()","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]}]}