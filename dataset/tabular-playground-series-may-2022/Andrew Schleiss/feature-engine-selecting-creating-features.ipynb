{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ‚ö°Ô∏èSummary ‚ö°Ô∏è\n\nIn this notebook we we will look at creating features for none timeseries data \\\nFor this we will use:\n1. Manual intuition from [exploring our data](https://www.kaggle.com/code/slythe/tps-may-super-eda-base-model)\n1. [Feature Engine](https://feature-engine.readthedocs.io/en/1.3.x/) -> a python library used for feature engineering and creation \n\n**Note** \\\nI have commented out some Feature engineering codes due to memory issues or the duration of the process (12hour cap for Kaggle) \\\nFeel free to run each section as required with the required functions ","metadata":{}},{"cell_type":"code","source":"!pip install feature-engine","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-06T15:17:24.159365Z","iopub.execute_input":"2022-05-06T15:17:24.160746Z","iopub.status.idle":"2022-05-06T15:17:36.509376Z","shell.execute_reply.started":"2022-05-06T15:17:24.160572Z","shell.execute_reply":"2022-05-06T15:17:36.50745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from feature_engine.selection import RecursiveFeatureElimination\nfrom feature_engine.creation import RelativeFeatures, MathFeatures","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:17:36.513455Z","iopub.execute_input":"2022-05-06T15:17:36.513865Z","iopub.status.idle":"2022-05-06T15:17:37.907608Z","shell.execute_reply.started":"2022-05-06T15:17:36.513808Z","shell.execute_reply":"2022-05-06T15:17:37.906493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data manipulation and  viz\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport pandas as pd \nimport numpy as np \nfrom collections import Counter\n\nimport gc\n\n# Feature importance with modelling\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T15:17:37.908776Z","iopub.execute_input":"2022-05-06T15:17:37.909032Z","iopub.status.idle":"2022-05-06T15:17:39.163475Z","shell.execute_reply.started":"2022-05-06T15:17:37.908978Z","shell.execute_reply":"2022-05-06T15:17:39.162431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parameters \n\nEPOCHS = 5000","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:17:39.166125Z","iopub.execute_input":"2022-05-06T15:17:39.166392Z","iopub.status.idle":"2022-05-06T15:17:39.171874Z","shell.execute_reply.started":"2022-05-06T15:17:39.166361Z","shell.execute_reply":"2022-05-06T15:17:39.170757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üíæ Load Data üíæ\nData taken from TPS May 2022 competition ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\",index_col = 0)\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2022/test.csv\",index_col = 0)\nsub = pd.read_csv(\"../input/tabular-playground-series-may-2022/sample_submission.csv\",index_col = 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:17:39.174213Z","iopub.execute_input":"2022-05-06T15:17:39.17479Z","iopub.status.idle":"2022-05-06T15:17:55.601386Z","shell.execute_reply.started":"2022-05-06T15:17:39.174739Z","shell.execute_reply":"2022-05-06T15:17:55.600178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:17:55.602789Z","iopub.execute_input":"2022-05-06T15:17:55.60309Z","iopub.status.idle":"2022-05-06T15:17:55.638476Z","shell.execute_reply.started":"2022-05-06T15:17:55.603047Z","shell.execute_reply":"2022-05-06T15:17:55.6378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üåü Manual Feature Engineering üåü\n\nWe have a variety of feature types which we have already investigated in a seperate [EDA notebook ](https://www.kaggle.com/code/slythe/tps-may-super-eda-base-model) \\\nWe will apply some text feature engineering and other techniques depending on the dataset","metadata":{}},{"cell_type":"code","source":"int_cols = train.dtypes[(train.dtypes ==\"int64\") & (train.dtypes.index != \"target\") ].index\nfloat_cols = train.dtypes[train.dtypes ==\"float64\" ].index","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:17:55.639488Z","iopub.execute_input":"2022-05-06T15:17:55.640466Z","iopub.status.idle":"2022-05-06T15:17:55.64683Z","shell.execute_reply.started":"2022-05-06T15:17:55.640419Z","shell.execute_reply":"2022-05-06T15:17:55.646199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_letters = ['A', 'B', 'D', 'E', 'P', 'C', 'S', 'G', 'F', 'Q', 'H', 'N', 'K', 'R', 'M', 'T', 'O', 'J', 'I', 'L']\n\ndef feature_engineering(df):\n    #letter count \n    for letter in all_letters:\n        df[letter] = df[\"f_27\"].str.count(letter)\n    \n    #Unicoding\n    for i in range(10):\n        df[\"f_27_\"+str(i)] = df[\"f_27\"].str[i].apply(lambda x: ord(x) - ord(\"A\"))\n    \n    # Get Unique letters\n    df[\"unique_text\"] = df[\"f_27\"].apply(lambda x :  ''.join([str(n) for n in list(set(x))]) )\n    df[\"unique_text\"] = df[\"unique_text\"].astype(\"category\")\n    \n    #Merge categorical columns \n    df[\"f29_f30\"] = df[[\"f_29\",\"f_30\"]].apply(lambda x: str( x[\"f_29\"] ) + str(x[\"f_30\"]), axis =1) \n    df[\"f29_f30\"] = df[\"f29_f30\"].astype(\"category\")\n    \n    # get max and min letter (use 'Counter' to get count of letters and then get max/min from this dictionary )\n    df[\"max_letter\"] = df[\"f_27\"].apply(lambda x : Counter(x)).apply(lambda x : max(x, key=x.get))\n    df[\"max_letter\"] = df[\"max_letter\"].astype(\"category\")\n    df[\"min_letter\"] = df[\"f_27\"].apply(lambda x : Counter(x)).apply(lambda x : min(x, key=x.get))\n    df[\"min_letter\"] = df[\"min_letter\"].astype(\"category\")\n    \n    return df\n\ntrain = feature_engineering(train)\ntest = feature_engineering(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:17:55.647972Z","iopub.execute_input":"2022-05-06T15:17:55.648728Z","iopub.status.idle":"2022-05-06T15:19:44.450149Z","shell.execute_reply.started":"2022-05-06T15:17:55.648694Z","shell.execute_reply":"2022-05-06T15:19:44.449377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üöâ Feature Creation üöâ","metadata":{}},{"cell_type":"markdown","source":"## 1. üöÄ Relative Features w/ Feature Engine üöÄ\n**As per the Feature Engine website:** \\\nRelativeFeatures() applies basic mathematical operations between a group of variables and one or more reference features. It adds the resulting features to the dataframe.\n\nIn other words, RelativeFeatures() adds, subtracts, multiplies, performs the division, true division, floor division, module or exponentiation of a group of features to / by a group of reference variables. The features resulting from these functions are added to the dataframe.\n\n**Note**: \\\nWe can only do this with the float columns and only one or two functions (due to time constraints)","metadata":{}},{"cell_type":"code","source":"functions = [\n    'add'\n    #, 'mul','sub', 'div' , 'truediv', 'floordiv', 'mod', 'pow'\n]\nFE = RelativeFeatures(variables  = list(float_cols), reference=list(float_cols)  ,func = functions, drop_original=False)\ntrain= FE.fit_transform(X = train)\ntest= FE.fit_transform(X = test)\n\ntrain.to_csv(\"Relative_feats_train.csv\")\ntest.to_csv(\"Relative_feats_test.csv\")\nprint([col for col in train.columns])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:19:44.45141Z","iopub.execute_input":"2022-05-06T15:19:44.452603Z","iopub.status.idle":"2022-05-06T15:35:40.428786Z","shell.execute_reply.started":"2022-05-06T15:19:44.452493Z","shell.execute_reply":"2022-05-06T15:35:40.427819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. üöÄ Mathematical Features (Manual) üöÄ\n\n**Note**: \n* We will do this with certain columns i.e. the float columns (but certain groupings)","metadata":{}},{"cell_type":"code","source":"train[float_cols].describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:35:40.433263Z","iopub.execute_input":"2022-05-06T15:35:40.433905Z","iopub.status.idle":"2022-05-06T15:35:45.125793Z","shell.execute_reply.started":"2022-05-06T15:35:40.433858Z","shell.execute_reply":"2022-05-06T15:35:45.124737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Group Float columns \n* We can see from the above that certain columns have similar std/ min/ max, we will group them\n* f_00 to f_06 => Group1\n* f_19 to f_26 => Group2\n* f28 looks to be seperate from both groups","metadata":{}},{"cell_type":"code","source":"group1_float =['f_00','f_01','f_02','f_03','f_04','f_05','f_06','f_19']\ngroup2_float = ['f_19','f_20','f_21','f_22','f_23','f_24','f_25','f_26']\n\ndef mathematical_feats(df,cols, suffix):\n    df[f\"sum_{suffix}\"] = df[cols].sum(axis = 1)\n    df[f\"mean_{suffix}\"] = df[cols].mean(axis = 1)\n    df[f\"std_{suffix}\"] = df[cols].std(axis = 1)\n    df[f\"min_{suffix}\"] = df[cols].min(axis = 1)\n    df[f\"max_{suffix}\"] = df[cols].max(axis = 1)\n    df[f\"median_{suffix}\"] = df[cols].median(axis = 1)\n    df[f\"mad_{suffix}\"] = df[cols].mad(axis = 1)\n\n    #potentially change periods OR changes axis OR fillna with actuals\n    #df[f\"diff_{suffix}\"] = df[cols].diff(periods=1, axis = 1)\n    \n    df[f\"max-min_{suffix}\"] = df[cols].max(axis = 1) - df[cols].min(axis = 1)\n    df[f\"q01_{suffix}\"] = df[cols].quantile(q= 0.1, axis =1)\n    df[f\"q25_{suffix}\"] = df[cols].quantile(q= 0.25, axis =1) \n    df[f\"q50_{suffix}\"] = df[cols].quantile(q= 0.5, axis =1) \n    df[f\"q75_{suffix}\"] = df[cols].quantile(q= 0.75, axis =1) \n    df[f\"q95_{suffix}\"] = df[cols].quantile(q= 0.95, axis =1) \n    df[f\"q99_{suffix}\"] = df[cols].quantile(q= 0.99, axis =1)\n    df[f\"kurt_{suffix}\"] = df[cols].kurt(axis =1) \n    df[f\"skew_{suffix}\"] = df[cols].skew( axis =1)\n    \n    return df\n\nmathematical_feats(train, group1_float, \"group1_float\")\nmathematical_feats(test, group1_float, \"group1_float\")","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:35:45.127219Z","iopub.execute_input":"2022-05-06T15:35:45.127461Z","iopub.status.idle":"2022-05-06T15:36:33.88845Z","shell.execute_reply.started":"2022-05-06T15:35:45.127433Z","shell.execute_reply":"2022-05-06T15:36:33.887531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üëª Feature Selection w/ LightGBM üëª\n\nThere are multiple ways to do feature selection, my favourite being the automated [Powershap](https://github.com/predict-idlab/powershap) library \\\nYou can see Powershap in action in this [notebook](https://www.kaggle.com/code/slythe/powershap-feature-selection-recursive) (however you may come across memory issues depending on the size of your dataset\n\nAs this dataset is quite large for Kaggle I will do my own single run of LightGBM and check the feature importances \\\nI also have only used one dataset(Mathemematical feats) --> change this as needed","metadata":{}},{"cell_type":"code","source":"# drop the text column and target\nX = train.drop(['target','f_27'],axis =1)\ny= train[\"target\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:36:33.890206Z","iopub.execute_input":"2022-05-06T15:36:33.890747Z","iopub.status.idle":"2022-05-06T15:36:40.209006Z","shell.execute_reply.started":"2022-05-06T15:36:33.890688Z","shell.execute_reply":"2022-05-06T15:36:40.208036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lgb.LGBMClassifier(n_jobs = -1, n_estimators = EPOCHS)\nmodel.fit(X_train,y_train, eval_set=[(X_test,y_test)], callbacks = [lgb.early_stopping(30)],eval_metric=\"auc\" , \n         )\nval_preds = model.predict_proba(X_test)\ny_preds = model.predict_proba(X_train)\n\nprint(\"Intrinsic AUC:\", roc_auc_score(y_train, y_preds[:,1]))\nprint(\"Validation AUC:\", roc_auc_score(y_test, val_preds[:, 1] ))\n\ndel val_preds\ndel y_preds\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:36:40.210629Z","iopub.execute_input":"2022-05-06T15:36:40.211241Z","iopub.status.idle":"2022-05-06T15:52:54.957769Z","shell.execute_reply.started":"2022-05-06T15:36:40.211181Z","shell.execute_reply":"2022-05-06T15:52:54.956216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_importance = pd.DataFrame(data = model.feature_importances_, index= train.drop([\"target\",\"f_27\"],axis =1).columns).sort_values(ascending = False, by= [0] )\n\nplt.figure(figsize= (25,10))\nsns.barplot(y= feat_importance[0], x= feat_importance.index)\nplt.xticks(rotation = 90) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:52:54.960822Z","iopub.execute_input":"2022-05-06T15:52:54.961225Z","iopub.status.idle":"2022-05-06T15:53:01.04334Z","shell.execute_reply.started":"2022-05-06T15:52:54.961178Z","shell.execute_reply":"2022-05-06T15:53:01.042157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features with zero importance\nprint([col for col in feat_importance[feat_importance[0] ==0].index])\n\ndel feat_importance\ndel train","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:53:01.0451Z","iopub.execute_input":"2022-05-06T15:53:01.046331Z","iopub.status.idle":"2022-05-06T15:53:01.055113Z","shell.execute_reply.started":"2022-05-06T15:53:01.046271Z","shell.execute_reply":"2022-05-06T15:53:01.054108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìù Submission üìù","metadata":{}},{"cell_type":"code","source":"test_preds = model.predict_proba(test.drop(\"f_27\",axis =1))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:53:01.60588Z","iopub.execute_input":"2022-05-06T15:53:01.60642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[\"target\"] = test_preds[:,1]\nsub.to_csv(\"submission.csv\")\n\nsub.plot(kind= \"hist\",figsize= (25,8))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}