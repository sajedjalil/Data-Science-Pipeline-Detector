{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\nenv = riiideducation.make_env()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport riiideducation\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport seaborn as sns\nimport os\npath=\"/kaggle/input/riiid-test-answer-prediction/\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndtype = {\n    'timestamp':'int64',\n    'content_type_id':'bool',\n    'content_id':'int16',\n    'answered_correctly':'int8',\n    'prior_question_elapsed_time':'float32',\n    'prior_question_had_explanation':'int8'\n}\ncols = [\n    'timestamp',\n    'content_type_id',\n    'content_id',\n    'answered_correctly',\n    'prior_question_elapsed_time',\n    'prior_question_had_explanation'\n]\ndf_lect = pd.read_csv(path+'lectures.csv', sep=',')\ndf_q = pd.read_csv(path+'questions.csv', sep=',')\ndf_sub = pd.read_csv(path+'example_sample_submission.csv', sep=',')\ndf_test = pd.read_csv(path+'example_test.csv', sep=',')\ndf_train = pd.read_csv(path+'train.csv',sep=',',usecols=cols,dtype=dtype)\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_q['tags'] = df_q['tags'].astype(str)\n\ntags = [x.split() for x in df_q['tags'].values]\ntags = [item for elem in tags for item in elem]\ntags = set(tags)\ntags_df = pd.DataFrame()\ntags = list(tags)\ncorrect = df_train[df_train.answered_correctly != -1].groupby([\"content_id\", 'answered_correctly'], as_index=False).size()\ncorrect = correct.pivot(index= \"content_id\", columns='answered_correctly', values='size')\ncorrect.columns = ['Wrong', 'Right']\ncorrect = correct.fillna(0)\ncorrect[['Wrong', 'Right']] = correct[['Wrong', 'Right']].astype(int)\ndf_q = df_q.merge(correct, left_on = \"question_id\", right_on = \"content_id\", how = \"left\")\nfor i in range(len(tags)):\n    df = df_q[df_q.tags.str.contains(tags[i])].agg({'Wrong': ['sum'], 'Right': ['sum']})\n    df['tag'] = tags[i]\n    df = df.set_index('tag')\n    tags_df = tags_df.append(df)\n\ntags_df['Percent_correct'] = tags_df.Right/(tags_df.Right + tags_df.Wrong)\ntags_df = tags_df.sort_values(by = \"Percent_correct\")\n\ntags_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_train = df_train[df_train.content_type_id==False]\ndf_train[df_train.content_type_id==False]\ndel df_train['content_type_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# counter=0\n# for x,i in enumerate(A):\n#     if len(i[1])>=1000:\n#         A[x] = (A[x][0],A[x][1][:1200])\n#     counter += len(A[x][1])\n        \n        \n# sz = len(A)\n# print(counter, sz)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff = 1/tags_df.Percent_correct\ndiff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndel df_q['question_id']\ndel df_q['part']\ndf_q['dif'] = df_q['Wrong']/(df_q['Right']+df_q['Wrong'])\ndf_q\ndf_q.groupby('bundle_id')['dif'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_lect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_q['correct_answer']\ndel df_q['tags']\ndel df_q['Wrong']\ndel df_q['Right']\ndf_train = df_train.merge(df_q,how = 'inner',left_on='content_id',right_on='bundle_id')\ndel df_train['content_id']\nanswers = df_train['answered_correctly']\ndel df_train['answered_correctly']\ndel df_train['bundle_id']\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train\ndf_train['timestamp'] = df_train['timestamp'].astype('float32')\ndf_train['prior_question_had_explanation'] = df_train['prior_question_had_explanation'].astype('float32')\nanswers = answers.to_numpy(dtype='bool')  \nanswers = np.array([answers, ~answers],dtype='int8').transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"model.fit(df_train, answers, epochs=1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\ndf_train = df_train.values\nmin_max_scaler = preprocessing.MinMaxScaler()\ndf_train = min_max_scaler.fit_transform(df_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.Sequential()\nact = 'relu'\nmodel.add(keras.layers.Dense(25, input_dim=4, activation=act))\n\nmodel.add(keras.layers.Dense(20, activation=act))\nmodel.add(keras.layers.Dense(17, activation=act))\nmodel.add(keras.layers.Dense(15, activation=act))\n\nmodel.add(keras.layers.Dense(2, activation='softmax'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['AUC'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(df_train, answers, epochs=5, batch_size=10000,verbose=1,validation_split=0.3)\ndel df_train\ndel answers\nmodel.save('model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Predict(df_test, df_q, model):\n    df_test = df_test.merge(df_q,how = 'inner',left_on='content_id',right_on='bundle_id')\n    row_id = df_test.row_id\n    df_test = df_test[['timestamp','prior_question_elapsed_time','prior_question_had_explanation','dif']]\n    df_test['timestamp'] = df_test['timestamp'].astype('float32')\n    df_test['prior_question_had_explanation'] = df_test['prior_question_had_explanation'].astype('float32')\n    df_test = df_test.values\n    min_max_scaler = preprocessing.MinMaxScaler()\n    df_test = min_max_scaler.fit_transform(df_test)\n    pred = model.predict(df_test)\n    return pred.reshape((2,len(pred)))[0]\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df[test_df['content_type_id']==0]\n    test_df['answered_correctly'] = Predict(test_df,df_q,model)\n    test_df = test_df[['row_id', 'answered_correctly']]\n    env.predict(test_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = df_test[df_test['content_type_id']==0]\ntest_df['answered_correctly'] = Predict(test_df,df_q,model)\ntest_df = test_df[['row_id', 'answered_correctly']]\nprint(test_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}