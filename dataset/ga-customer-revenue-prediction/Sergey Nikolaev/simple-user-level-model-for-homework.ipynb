{"cells":[{"metadata":{"trusted":true,"_uuid":"3de9f4d4185d1aebad64478ac1372671cfdf584f"},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5790d39033f40b1dd9921e689f2617a24908439"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GroupKFold\nimport time\nimport gc\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ngc.enable()\nwarnings.simplefilter('ignore')\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46052ba7b54014bbf286d1982ea0638462b48623"},"cell_type":"markdown","source":"## Load data"},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T11:39:56.910137Z","start_time":"2018-10-14T11:39:35.028392Z"},"trusted":true,"_uuid":"a3d88ad703e27bc26db5b2d117245b02dec05b9d"},"cell_type":"code","source":"# https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields\ntrain_df = pd.read_csv('../input/data-flattened/train-flattened/train-flattened.csv', dtype={'fullVisitorId': 'str'})\ntest_df = pd.read_csv('../input/data-flattened/test-flattened/test-flattened.csv', dtype={'fullVisitorId': 'str'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52639458546acf3bf739509c98ec1a77192ae1bb"},"cell_type":"markdown","source":"## Drop constant columns"},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T11:40:00.992256Z","start_time":"2018-10-14T11:39:56.932083Z"},"trusted":true,"_uuid":"a5964794549af6e39ee569ebd3733c6655aefe3e"},"cell_type":"code","source":"const_cols = [c for c in train_df.columns if train_df[c].nunique(dropna=False) == 1]\ntrain_df.drop(columns=const_cols + ['trafficSource.campaignCode'], inplace=True)\ntest_df.drop(columns=const_cols, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40696d0d95a924371516ab3b3c5b5edbd4e26107"},"cell_type":"markdown","source":"## Preprocess some features"},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T11:40:17.139433Z","start_time":"2018-10-14T11:40:00.994216Z"},"trusted":true,"_uuid":"09be7b0f348bfc7616e27fde5fe507dd28730fdc"},"cell_type":"code","source":"# https://www.kaggle.com/prashantkikani/teach-lightgbm-to-sum-predictions-fe\ndef browser_mapping(x):\n    browsers = ['chrome', 'safari', 'firefox', 'internet explorer', 'edge', 'opera', 'coc coc', 'maxthon', 'iron']\n    mobile_browsers = ['android', 'samsung', 'mini', 'iphone', 'in-app', 'playstation', 'mozilla', 'chrome',\n                       'blackberry', 'nokia', 'browser', 'amazon', 'lunascape', 'netscape', 'konqueror', 'puffin']\n    if x in browsers:\n        return x\n    elif '(not set)' in x:\n        return x\n    elif sum([(k in x) for k in mobile_browsers]):\n        return 'mobile browser'\n    else:\n        return 'others'\n\ndef adcontents_mapping(x):\n    if 'google' in x:\n        return 'google'\n    elif ('placement' in x) or ('placememnt' in x):\n        return 'placement'\n    elif ('(not set)' in x) or ('nan' in x):\n        return x\n    elif 'ad' in x:\n        return 'ad'\n    else:\n        return 'others'\n\ndef source_mapping(x):\n    sources = ['google', 'youtube', '(not set)', 'nan', 'yahoo', 'facebook', 'reddit', 'bing', 'quora', 'outlook', 'linkedin',\n               'pinterest', 'ask', 'siliconvalley', 'lunametrics', 'amazon', 'mysearch', 'qiita', 'messenger', 'twitter',\n               't.co', 'vk.com', 'search', 'edu', 'mail', 'ad', 'golang', 'direct', 'dealspotr', 'sashihara', 'phandroid',\n               'baidu', 'mdn', 'duckduckgo', 'seroundtable', 'metrics', 'sogou', 'businessinsider', 'github', 'gophergala',\n               'yandex', 'msn', 'dfa', 'feedly', 'arstechnica', 'squishable', 'flipboard', 't-online.de', 'sm.cn', 'wow', \n               'partners']\n    for s in sources:\n        if s in x:\n            return s\n    return 'others'\n\ndef custom(df):\n    print('custom..')\n    df['source.country'] = df['trafficSource.source'] + '_' + df['geoNetwork.country']\n    df['campaign.medium'] = df['trafficSource.campaign'] + '_' + df['trafficSource.medium']\n    df['browser.category'] = df['device.browser'] + '_' + df['device.deviceCategory']\n    df['browser.os'] = df['device.browser'] + '_' + df['device.operatingSystem']\n\n    df['device_deviceCategory_channelGrouping'] = df['device.deviceCategory'] + \"_\" + df['channelGrouping']\n    df['channelGrouping_browser'] = df['device.browser'] + \"_\" + df['channelGrouping']\n    df['channelGrouping_OS'] = df['device.operatingSystem'] + \"_\" + df['channelGrouping']\n    \n    df['content.source'] = df['trafficSource.adContent'] + \"_\" + df['source.country']\n    df['medium.source'] = df['trafficSource.medium'] + \"_\" + df['source.country']\n    \n    for i in ['geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country','geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region','geoNetwork.subContinent']:\n        for j in ['device.browser','device.deviceCategory', 'device.operatingSystem', 'trafficSource.source']:\n            df[i + \"_\" + j] = df[i] + \"_\" + df[j]\n    \n    return df\n\nfor df in [train_df, test_df]:\n    df['device.browser'] = df['device.browser'].map(lambda x: browser_mapping(str(x).lower()))\n    df['trafficSource.adContent'] = df['trafficSource.adContent'].map(lambda x: adcontents_mapping(str(x).lower()))\n    df['trafficSource.source'] = df['trafficSource.source'].map(lambda x: source_mapping(str(x).lower()))\n\ntrain_df = custom(train_df)\ntest_df = custom(test_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1d0275859d97ef907a69538450330373de91069"},"cell_type":"markdown","source":"## Add several features"},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T11:40:53.808526Z","start_time":"2018-10-14T11:40:29.56618Z"},"trusted":true,"_uuid":"927f307f32e8327e403d281e3f21682c833476c9"},"cell_type":"code","source":"for df in [train_df, test_df]:\n    df['visitStartTime'] = pd.to_datetime(df['visitStartTime'], unit='s')\n    df['sess_date_dow'] = df['visitStartTime'].dt.dayofweek\n    df['sess_date_hours'] = df['visitStartTime'].dt.hour\n    \n    df['totals.hits/views'] = df['totals.hits'] / (df['totals.pageviews'] + 1)\n\n    df.sort_values(['fullVisitorId', 'visitStartTime'], ascending=True, inplace=True)\n    df['next_session_1'] = (\n        df['visitStartTime'] - df[['fullVisitorId', 'visitStartTime']].groupby('fullVisitorId')['visitStartTime'].shift(1)\n    ).astype(np.int64) // 1e9 // 60 // 60\n    df['next_session_2'] = (\n        df['visitStartTime'] - df[['fullVisitorId', 'visitStartTime']].groupby('fullVisitorId')['visitStartTime'].shift(-1)\n    ).astype(np.int64) // 1e9 // 60 // 60","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bf1f09f1141c201c9bb5d2e2cdec299006721fe"},"cell_type":"markdown","source":"## Encode categorical features and convert the numerical variables to float"},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T11:46:34.148652Z","start_time":"2018-10-14T11:46:34.14463Z"},"trusted":true,"_uuid":"5696af22ab4c7497aaeb9f7f4100f748d84b3e25"},"cell_type":"code","source":"num_cols = ['visitNumber', 'totals.hits', 'totals.pageviews', 'totals.hits/views', 'next_session_1', 'next_session_2']\nexcluded_cols = ['date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', 'visitId', 'visitStartTime']\ncat_cols = [col for col in train_df.columns \n            if (col not in excluded_cols) and (col not in num_cols)]\nall_cols = cat_cols + num_cols\n\nfor col in cat_cols:\n    train_df[col], indexer = pd.factorize(train_df[col].astype(str))\n    test_df[col] = indexer.get_indexer(test_df[col].astype(str))\n    \nfor col in num_cols:\n    train_df[col] = train_df[col].astype(float)\n    test_df[col] = test_df[col].astype(float)\n\ntrain_df[\"totals.transactionRevenue\"].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d7d07dbf8a6396a7d78a31bfa25423abd326b9f"},"cell_type":"markdown","source":"## KFold split function"},{"metadata":{"trusted":true,"_uuid":"0dd2acf404652610c2ddc0c395570ef16cd5df2c"},"cell_type":"code","source":"# https://www.kaggle.com/mukesh62/lgb-fe-groupkfold-cv-xgb\ndef get_folds(df=None, n_splits=5, seed=42):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['fullVisitorId'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    np.random.seed(seed)\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['fullVisitorId'].isin(unique_vis[trn_vis])],\n                ids[df['fullVisitorId'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"314e69c2a9ef18b73f41cf7a3d33ececa65a14ef"},"cell_type":"markdown","source":"## Train session-level model"},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T13:14:08.030593Z","start_time":"2018-10-14T13:14:08.018627Z"},"trusted":true,"_uuid":"248520b0a5a9d17ff255cd1d17c39885283d2fb3"},"cell_type":"code","source":"params = {'learning_rate': 0.01, \n         'objective': 'regression', \n         'metric': 'rmse', \n         'num_leaves': 49, \n         'verbose': 1, \n         'bagging_fraction': 0.94, \n         'feature_fraction': 0.67, \n         'random_state': 42, \n         'max_depth': 14, \n         'random_seed': 42,\n         'bagging_frequency': 5, \n         'lambda_l2': 0.2, \n         'lambda_l1': 0.55, \n         'min_child_samples': 130\n        }","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T13:27:04.978844Z","start_time":"2018-10-14T13:20:54.424647Z"},"scrolled":true,"trusted":true,"_uuid":"2ffcfd03cc68c1f14da62b69fdfc929777f21eeb"},"cell_type":"code","source":"train_y = train_df[\"totals.transactionRevenue\"]\nfolds = get_folds(train_df, n_splits=5)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(train_df.shape[0])\nsub_preds = np.zeros(test_df.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = train_df[all_cols].iloc[trn_], train_y.iloc[trn_]\n    val_x, val_y = train_df[all_cols].iloc[val_], train_y.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(**params, n_estimators=2000)\n    reg.fit(trn_x, np.log1p(trn_y), eval_set=[(val_x, np.log1p(val_y))], early_stopping_rounds=100, \n            verbose=100, eval_metric='rmse')\n    \n    imp_df = pd.DataFrame()\n    imp_df['feature'] = all_cols\n    imp_df['gain_reg'] = reg.booster_.feature_importance(importance_type='gain')\n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    # LightGBM\n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    lgb_preds = reg.predict(test_df[all_cols], num_iteration=reg.best_iteration_)\n    lgb_preds[lgb_preds < 0] = 0\n    \n    sub_preds += np.expm1(lgb_preds) / len(folds)\n    \nprint(\"LGBM session-level error: \", mean_squared_error(np.log1p(train_y.values), oof_reg_preds) ** .5)\n\noof_pred_df = pd.DataFrame({\"fullVisitorId\": train_df[\"fullVisitorId\"].values})\noof_pred_df[\"transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].values\noof_pred_df[\"PredictedRevenue\"] = np.expm1(oof_reg_preds)\noof_pred_df = oof_pred_df.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\noof_err = np.sqrt(mean_squared_error(np.log1p(oof_pred_df[\"transactionRevenue\"].values), \n                                     np.log1p(oof_pred_df[\"PredictedRevenue\"].values)))\nprint(\"LGBM user-level error: \", oof_err)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T13:36:09.053299Z","start_time":"2018-10-14T13:36:06.476743Z"},"trusted":true,"_uuid":"5d9dc7f05b389b3616fe9cb5fadcf933e14e9766"},"cell_type":"code","source":"importances['gain_log'] = np.log1p(importances['gain_reg'])\nmean_gain = importances[['gain_reg', 'feature']].groupby('feature').mean()\nimportances['mean_gain'] = importances['feature'].map(mean_gain['gain_reg'])\n\nplt.figure(figsize=(8, 15))\nsns.barplot(x='gain_log', y='feature', data=importances.sort_values('mean_gain', ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fd705057162f3f05316111e65f9fe057b5671c7"},"cell_type":"markdown","source":"## Create user-level features"},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T13:36:40.09284Z","start_time":"2018-10-14T13:36:40.06688Z"},"trusted":true,"_uuid":"98f73c7e0899f206934c153eb447e9e6fa5d6162"},"cell_type":"code","source":"train_df['predictions'] = np.expm1(oof_reg_preds)\ntest_df['predictions'] = sub_preds","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T13:40:59.529376Z","start_time":"2018-10-14T13:40:59.520358Z"},"trusted":true,"_uuid":"a4a71955209a6b58eebdd7ab6f87c4d3f1b19234"},"cell_type":"code","source":"# Mode functions in scipy and pandas are too slow\ndef find_mode(x):\n    mode, mode_cnt = 0, 0\n    d = dict()\n    for val in x.values:\n        current_cnt = d.get(val, 0) + 1\n        d[val] = current_cnt\n        if current_cnt > mode_cnt:\n            mode = val\n            mode_cnt = current_cnt\n    return mode\n\n# use top_N predictions as features for user-level model\ndef parse_predictions(df):\n    top_N = 20\n    res = dict()\n    res['pred_first'] = df.predictions.values[0]\n    res['pred_last'] = df.predictions.values[-1]\n    for i, pred in enumerate(df.predictions.sort_values(ascending=False).head(top_N)):\n        res['pred_' + str(i)] = pred\n    return res","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T13:48:45.777797Z","start_time":"2018-10-14T13:42:48.130499Z"},"trusted":true,"_uuid":"52bda72491617dac3c9b14ff2dd51f6b98a90785"},"cell_type":"code","source":"%%time\n# Aggregate data at User level\n# mean for numerical features and mode for categorical\ntrn_data = train_df[all_cols + ['fullVisitorId']].groupby('fullVisitorId')\\\n    .agg({c: np.mean if c in num_cols else find_mode for c in all_cols})\ntrn_pred_list = train_df[['fullVisitorId', 'predictions']].groupby('fullVisitorId').apply(parse_predictions)\ntrn_all_predictions = pd.DataFrame(list(trn_pred_list.values), index=trn_data.index)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T14:26:39.327292Z","start_time":"2018-10-14T14:26:39.322306Z"},"trusted":true,"_uuid":"a3fe5266a17ded8fc7f188d18b291793e1183270"},"cell_type":"code","source":"trn_all_predictions.columns","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T14:27:32.407616Z","start_time":"2018-10-14T14:27:24.054158Z"},"trusted":true,"_uuid":"d98f24d31e6da0c238fd8e86c5e1491e168ac42b"},"cell_type":"code","source":"# Create a DataFrame with VisitorId as index\nsession_pred_cols = trn_all_predictions.columns[:-2]\ntrn_all_predictions['t_log_mean'] = np.log1p(trn_all_predictions[session_pred_cols].mean(axis=1))\ntrn_all_predictions['t_log_median'] = np.log1p(trn_all_predictions[session_pred_cols].median(axis=1))\ntrn_all_predictions['t_sum_log'] = np.log1p(trn_all_predictions[session_pred_cols]).sum(axis=1)\ntrn_all_predictions['t_sum_act'] = np.log1p(trn_all_predictions[session_pred_cols].fillna(0).sum(axis=1))\ntrn_all_predictions['t_nb_sess'] = trn_all_predictions[session_pred_cols].isnull().sum(axis=1)\nfull_data = pd.concat([trn_data, trn_all_predictions], axis=1)\ndel trn_data, trn_all_predictions\ngc.collect()\nfull_data.shape","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T14:38:24.752738Z","start_time":"2018-10-14T14:33:15.259587Z"},"trusted":true,"_uuid":"6ee80ecadd4ecbc9a7da53e7efc5857e523303df"},"cell_type":"code","source":"%%time\nsub_data = test_df[all_cols + ['fullVisitorId']].groupby('fullVisitorId')\\\n    .agg({c: np.mean if c in num_cols else find_mode for c in all_cols})\nsub_pred_list = test_df[['fullVisitorId', 'predictions']].groupby('fullVisitorId').apply(parse_predictions)\nsub_all_predictions = pd.DataFrame(list(sub_pred_list.values), index=sub_data.index)\nfor f in session_pred_cols:\n    if f not in sub_all_predictions.columns:\n        sub_all_predictions[f] = np.nan\nsub_all_predictions['t_log_mean'] = np.log1p(sub_all_predictions[session_pred_cols].mean(axis=1))\nsub_all_predictions['t_log_median'] = np.log1p(sub_all_predictions[session_pred_cols].median(axis=1))\nsub_all_predictions['t_sum_log'] = np.log1p(sub_all_predictions[session_pred_cols]).sum(axis=1)\nsub_all_predictions['t_sum_act'] = np.log1p(sub_all_predictions[session_pred_cols].fillna(0).sum(axis=1))\nsub_all_predictions['t_nb_sess'] = sub_all_predictions[session_pred_cols].isnull().sum(axis=1)\n\nsub_full_data = pd.concat([sub_data, sub_all_predictions], axis=1)\ndel sub_data, sub_all_predictions\ngc.collect()\nsub_full_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"434f17224a8b2f8bef79aa81bed6ab07c57020e3"},"cell_type":"markdown","source":"## Train user-level model"},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T14:42:59.816953Z","start_time":"2018-10-14T14:42:58.607188Z"},"trusted":true,"_uuid":"fb1efa6d72cd54c2c21bf1b36388f569c9f3cb4c"},"cell_type":"code","source":"target = train_df[['fullVisitorId', 'totals.transactionRevenue']].groupby('fullVisitorId').sum()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T15:23:07.486752Z","start_time":"2018-10-14T15:23:07.477776Z"},"trusted":true,"_uuid":"fb025e34bcc2676d02cfe1f317b3517d7848b248"},"cell_type":"code","source":"params = {'learning_rate': 0.01, \n         'objective': 'regression', \n         'metric': 'rmse', \n         'num_leaves': 31, \n         'verbose': 1, \n         'bagging_fraction': 0.93, \n         'feature_fraction': 0.57, \n         'random_state': 42, \n         'max_depth': 14, \n         'random_seed': 42,\n         'bagging_frequency': 5, \n         'lambda_l2': 0.62, \n         'lambda_l1': 0.07, \n         'min_child_samples': 179\n        }","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T15:27:03.509414Z","start_time":"2018-10-14T15:23:59.158922Z"},"trusted":true,"_uuid":"3243bf24904d3c447430b0086161bbe874f9f4a8"},"cell_type":"code","source":"folds = get_folds(df=full_data[['totals.pageviews']].reset_index(), n_splits=5)\n\noof_reg_preds = np.zeros(full_data.shape[0])\nsub_preds = np.zeros(sub_full_data.shape[0])\nvis_importances = pd.DataFrame()\n\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = full_data.iloc[trn_], target['totals.transactionRevenue'].iloc[trn_]\n    val_x, val_y = full_data.iloc[val_], target['totals.transactionRevenue'].iloc[val_]\n    \n    reg = lgb.LGBMRegressor(**params,n_estimators=2000)\n    reg.fit(trn_x, np.log1p(trn_y), eval_set=[(val_x, np.log1p(val_y))], early_stopping_rounds=100, \n            verbose=100, eval_metric='rmse')\n    \n    imp_df = pd.DataFrame()\n    imp_df['feature'] = trn_x.columns\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    vis_importances = pd.concat([vis_importances, imp_df], axis=0, sort=False)\n    \n    # LightGBM\n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    lgb_preds = reg.predict(sub_full_data[full_data.columns], num_iteration=reg.best_iteration_)\n    lgb_preds[lgb_preds < 0] = 0\n    \n    sub_preds += np.expm1(lgb_preds) / len(folds)\n    \nprint(\"LGBM Result: \", mean_squared_error(np.log1p(target['totals.transactionRevenue']), oof_reg_preds) ** .5)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T15:27:34.930139Z","start_time":"2018-10-14T15:27:32.806833Z"},"trusted":true,"_uuid":"755fd6d2fb52edf9fb6af31e365b915b2ad09eb5"},"cell_type":"code","source":"vis_importances['gain_log'] = np.log1p(vis_importances['gain'])\nmean_gain = vis_importances[['gain', 'feature']].groupby('feature').mean()\nvis_importances['mean_gain'] = vis_importances['feature'].map(mean_gain['gain'])\n\nplt.figure(figsize=(8, 25))\nsns.barplot(x='gain_log', y='feature', data=vis_importances.sort_values('mean_gain', ascending=False).iloc[:300])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-14T15:28:46.805668Z","start_time":"2018-10-14T15:28:44.374175Z"},"trusted":true,"_uuid":"80e3b409c69a83d76ceca3e7a756b86908ee3f35"},"cell_type":"code","source":"sub_full_data['PredictedLogRevenue'] = np.log1p(sub_preds)\nsub_full_data[['PredictedLogRevenue']].to_csv('submission.csv', index=True)","execution_count":null,"outputs":[]}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}