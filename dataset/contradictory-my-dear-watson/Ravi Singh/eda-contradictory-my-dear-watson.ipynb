{"cells":[{"metadata":{},"cell_type":"markdown","source":"> \"…when you have eliminated the impossible, whatever remains, however improbable, must be the truth\"\n\n> -Sir Arthur Conan Doyle","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/e7/b8/df/e7b8dfcca0a5383d99142f28b3a6f51d.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **The Challenge:**\nIf you have two sentences, there are three ways they could be related: one could entail the other, one could contradict the other, or they could be unrelated. Natural Language Inferencing (NLI) is a popular NLP problem that involves determining how pairs of sentences (consisting of a premise and a hypothesis) are related.\n\nYour task is to create an NLI model that assigns labels of 0, 1, or 2 (corresponding to entailment, neutral, and contradiction) to pairs of premises and hypotheses. To make things more interesting, the train and test set include text in fifteen different languages! You can find more details on the dataset by reviewing the Data page.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I have always felt like EDA notebooks on kaggle have lost its main motive and that is to explain the Data. It is more about fancy graph then the meaning behind it. I hope I fulfill it.\n\n\nLet us walk through the directory.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install  -q wordcloud","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nprint('Inside Input we have:')\nfor i, (dirname, _, filenames) in enumerate(os.walk('/kaggle/input/contradictory-my-dear-watson')):\n    print('\\t '* i, '{}) {} folder. It has:-'.format(i+1, dirname.split('/')[-1]))\n    for idx,filename in enumerate(filenames):\n        print('\\t '* (i+1),f'{idx+1}. {filename}' )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let us load our CSV files and do some","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/contradictory-my-dear-watson/train.csv')\ntest_df = pd.read_csv('../input/contradictory-my-dear-watson/test.csv')\ntrain_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Note to ourself: ***It looks like Multi-Lingual, Multi-Class Problem.***","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" ### First let us analyze label or target\n They are classifying pairs of sentences (consisting of a premise and a hypothesis) into three categories - \n \n **1. entailment means logical sequence**\n \n **2. contradiction means illogical sequence**  \n \n **3. neutral means niether logical or illogical sequence**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### EXAMPLE\nAs explained in Getting Started.\n> He came, he opened the door and I remember looking back and seeing the expression on his face, and I could tell that he was disappointed.\n\n###### Hypothesis 1:\n\n> Just by the look on his face when he came through the door I just knew that he was let down.\n\nWe know that this is true based on the information in the premise. So, this pair is related by **entailment**.\n\n###### Hypothesis 2:\n\n> He was trying not to make us feel guilty but we knew we had caused him trouble.\n\nThis very well might be true, but we can’t conclude this based on the information in the premise. So, this relationship is **neutral**.\n\n###### Hypothesis 3:\n\n> He was so excited and bursting with joy that he practically knocked the door off it's frame.\n\nWe know this isn’t true, because it is the complete opposite of what the premise says. So, this pair is related by **contradiction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(train_df.label);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Note to ourself: In terms of Labels, it is a **Multi Class Balanced** Dataset Problem.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Now let us move forward and analyze language variable \n\nLet see different language we are dealing with:-","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Different types of language are', train_df['language'].unique(), '\\nTotal number of Languages are:-',len((train_df['language'].unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have \nArabic, Bulgarian, Chinese, German, Greek, English, Spanish, French, Hindi, Russian, Swahili, Thai, Turkish, Urdu, and Vietnamese.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nimport matplotlib.pyplot as plt\n\nname, count = np.unique(train_df['language'], return_counts = True)\nfig = px.pie( values= count, names=name, title='Languages Available to us.')\nfig.update_traces(hoverinfo='value+label+percent', textposition='inside', textfont_size=15,textinfo = 'value + label',\n                  marker=dict( line=dict(color='#000100', width=2)))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name, count = np.unique(train_df[train_df['language'] != 'English'].language, return_counts = True)\n\nfig = px.bar(x=name, y=count)\nfig.update_traces(texttemplate='%{y:.2s}',  textposition='outside')\nfig.update_layout(uniformtext_minsize=15, uniformtext_mode='hide', xaxis_tickangle=-80)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (25,18))\nfor i,n in enumerate(train_df.language.unique()):\n    ax1 = plt.subplot(5,3,i+1)\n    sns.countplot(train_df[train_df.language == n].label, ax =ax1)\n    ax1.set_title(n)\n    ax1.set_xlabel('')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Note to ourself: It is fairly a balanced Dataset if we seperate English and other Languages.\n\n### Now let us move forward and analyze Text portion.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import wordcloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = train_df[train_df.language == 'English'].premise.to_string()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\nstopwords.update([\"many\", \"alway\", \"you\", \"many\", \"well\", 'time, mean', 'much'])\nwordcloud = WordCloud(stopwords=stopwords,max_font_size=50, max_words=800, background_color=\"white\").generate(text)\n\n# Display the generated image:\nplt.figure(figsize = (15,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Min and Max of len of strings in Premise and hypothesis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('max length of sentence in premise', max(train_df.premise.apply(lambda x:len(x.split(' ')))))\nprint('min length of sentence in premise',min(train_df.premise.apply(lambda x:len(x.split(' ')))))\nprint('max length of sentence in hypothesis',max(train_df.hypothesis.apply(lambda x:len(x.split(' ')))))\nprint('min length of sentence in hypothesis',min(train_df.hypothesis.apply(lambda x:len(x.split(' ')))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Things we have learned about about dataset are:\n* Multi Class\n* Multi Lingual\n* Balanced Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}