{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello!\n\nThis is inference notebook from this [train notebook](https://www.kaggle.com/alturutin/watson-xml-r-nli-train).\n\nAlso, I interpeted results and showed why the accuracy in this competition is so high.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip > /dev/null\n!pip install --upgrade transformers > /dev/null\n!pip install nlp > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3a20929-8e1d-48d2-869c-cc57f8c63cc9","_cell_guid":"20666a1f-e31b-4134-94f8-fea9a50998d3","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport plotly.express as px\n\n# NN\nfrom tensorflow.keras.layers import Dense, Input, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nimport nlp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def init_strategy():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Init TPU strategy\")\n    except ValueError:\n        strategy = tf.distribute.get_strategy() # for CPU and single GPU\n        print(\"Init CPU/GPU strategy\")\n    return strategy\n\ndef build_model(model_name, maxlen, head=\"avg_pooling\"):\n    input_ids = Input(shape=(maxlen,), dtype=tf.int32, name=\"input_ids\")\n    encoder = TFAutoModel.from_pretrained(model_name)\n    encoder_output = encoder(input_ids)[0]\n    \n    # convert transformer encoding to vector\n    if head == \"cls\":\n        features = encoder_output[:, 0, :] # using first token as encoder feature map\n    elif head == \"avg_pooling\":\n        features = GlobalAveragePooling1D()(encoder_output)\n    elif head == \"max_pooling\":\n        features = GlobalMaxPooling1D()(encoder_output)\n    else:\n        raise NotImplementedError\n    \n    # 3class softmax\n    out = Dense(3, activation='softmax')(features)\n    \n    # define model\n    model = Model(inputs=input_ids, outputs=out)\n    model.compile(\n        Adam(lr=1e-5), \n        loss='sparse_categorical_crossentropy', \n        metrics=['accuracy']\n    )\n    return model\n\ndef tokenize_dataframe(df, tokenizer, max_length):\n    # tokenize\n    text = df[['premise', 'hypothesis']].values.tolist()\n    encoded = tokenizer.batch_encode_plus(text, padding=True, max_length=max_length, truncation=True)\n    # features\n    x = encoded['input_ids']\n    # labels\n    y = None\n    if 'label' in df.columns:\n        y = df.label.values\n    return x, y\n\ndef build_dataset(x, y, mode, batch_size):\n    if mode == \"train\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices((x, y))\n            .repeat()\n            .shuffle(2048)\n            .batch(batch_size)\n            .prefetch(auto)\n        )\n    elif mode == \"valid\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices((x, y))\n            .batch(batch_size)\n            .cache()\n            .prefetch(auto)\n        )\n    elif mode == \"test\":\n        dataset = (\n            tf.data.Dataset\n            .from_tensor_slices(x)\n            .batch(batch_size)\n        )\n    else:\n        raise NotImplementedError\n    return dataset\n\ndef load_mnli(use_validation=True):\n    result = []\n    dataset = nlp.load_dataset(path='glue', name='mnli')\n    keys = ['train', 'validation_matched','validation_mismatched'] if use_validation else ['train']\n    for k in keys:\n        for record in dataset[k]:\n            c1, c2, c3 = record['premise'], record['hypothesis'], record['label']\n            if c1 and c2 and c3 in {0,1,2}:\n                result.append((c1,c2,c3,'en'))\n    result = pd.DataFrame(result, columns=['premise','hypothesis','label','lang_abv'])\n    return result\n\ndef load_xnli():\n    result = []\n    dataset = nlp.load_dataset(path='xnli')\n    for k in dataset.keys():\n        for record in dataset[k]:\n            hp, pr, lb = record['hypothesis'], record['premise'], record['label']\n            if hp and pr and lb in {0,1,2}:\n                for lang, translation in zip(hp['language'], hp['translation']):\n                    pr_lang = pr.get(lang, None)\n                    if pr_lang is None:\n                        continue\n                    result.append((pr_lang, translation, lb,lang))\n    result = pd.DataFrame(result, columns=['premise','hypothesis','label','lang_abv'])\n    return result\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL = 'jplu/tf-xlm-roberta-large'\nMAXLEN = 120\nstrategy = init_strategy()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nauto = tf.data.experimental.AUTOTUNE\n\ndef preprocess(df):\n    return tokenize_dataframe(df, tokenizer, MAXLEN)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e60d19f-aeae-417a-a10a-50cc1d5ee685","_cell_guid":"f3ad567b-a156-4ffc-a6f8-1f5e6e989a4e","trusted":true,"collapsed":true},"cell_type":"code","source":"# load data\ntrain = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\ntest = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/test.csv')\nsubmission = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/sample_submission.csv')\n\n# preprocess\nx, y = preprocess(train)\nx_test, _ = preprocess(test)\ntest_dataset = build_dataset(x_test, None, \"test\", BATCH_SIZE)\n\n# load external datasets for interpretation purpose\nmnli = load_mnli()\nxnli = load_xnli()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's build toy search engine: it's looking for a full match of query and knowledge base.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\npunct = '[' + ''.join([c for c in string.punctuation if c != \"'\"]) + ']'\n\ndef preprocess_query(q):\n    q = q.lower()\n    q = re.sub(punct, ' ', q)\n    q = re.sub('[ ]{2,}', ' ', q)\n    return q\n\ndef search_in_base(q, kb):\n    q = preprocess_query(q)\n    return int(q in kb)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"premises = pd.concat([train[['premise', 'lang_abv']], test[['premise', 'lang_abv']]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knowledge_base = set(mnli['premise'].apply(preprocess_query))\npremises['mnli'] = premises['premise'].apply(lambda q: search_in_base(q, knowledge_base))\nprint(f\"fraction of train set english premises occurence in MNLI = {premises.loc[premises.lang_abv=='en', 'mnli'].mean() * 100}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knowledge_base = set(xnli['premise'].apply(preprocess_query))\npremises['xnli'] = premises['premise'].apply(lambda q: search_in_base(q, knowledge_base))\nprint(f\"fraction of train set non-english premises occurence in XNLI = {premises.loc[premises.lang_abv!='en', 'xnli'].mean() * 100}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As we can see, external datasets completely include train and test data, and it's obvious overfitting :)","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# save results \nstrategy = init_strategy()\nwith strategy.scope():\n    model = build_model(MODEL, MAXLEN)\n    model.load_weights(\"../input/watson-xlmr-models/XLMR_mnlixnli_ep6.h5\")\n    \ndataset = build_dataset(x, y, \"valid\", BATCH_SIZE)\npr = np.argmax(model.predict(dataset), axis=1)\nprint(f\"accuracy {accuracy_score(y, pr):.4f}\")\n\ntest_preds = model.predict(test_dataset, verbose=0)\nsubmission['prediction'] = test_preds.argmax(axis=1)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}