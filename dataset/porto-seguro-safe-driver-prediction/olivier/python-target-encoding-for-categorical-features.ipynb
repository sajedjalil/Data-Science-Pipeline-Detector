{"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","name":"python","version":"3.6.1","file_extension":".py","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":1,"cells":[{"execution_count":null,"metadata":{"_cell_guid":"44908ad8-22b6-4207-bb6b-3aff37da8eb7","_uuid":"7979fd6cf2728a50bdc8f07ac6ef735d5f15b148"},"outputs":[],"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"metadata":{"_cell_guid":"09bfb72b-604b-4b3e-bf37-f94a992b7561","_uuid":"4323e8bd79448c64d374670e72c26adcbab01714"},"cell_type":"markdown","source":"### Target encoding with smoothing\nmin_samples_leaf define a threshold where prior and target mean (for a given category value) have the same weight. Below the threshold prior becomes more important and above mean becomes more important.\n\nHow weight behaves against value counts is controlled by smoothing parameter"},{"execution_count":null,"metadata":{"_cell_guid":"228b3cb2-b8bd-4484-af9a-46b64c2417e3","collapsed":true,"_uuid":"e1265cc5526a35811e2dfce90dfdebd5c386f015"},"outputs":[],"cell_type":"code","source":"def add_noise(series, noise_level):\n    return series * (1 + noise_level * np.random.randn(len(series)))\n\ndef target_encode(trn_series=None, \n                  tst_series=None, \n                  target=None, \n                  min_samples_leaf=1, \n                  smoothing=1,\n                  noise_level=0):\n    \"\"\"\n    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n    trn_series : training categorical feature as a pd.Series\n    tst_series : test categorical feature as a pd.Series\n    target : target data as a pd.Series\n    min_samples_leaf (int) : minimum samples to take category average into account\n    smoothing (int) : smoothing effect to balance categorical average vs prior  \n    \"\"\" \n    assert len(trn_series) == len(target)\n    assert trn_series.name == tst_series.name\n    temp = pd.concat([trn_series, target], axis=1)\n    # Compute target mean \n    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n    # Compute smoothing\n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n    # Apply average function to all target data\n    prior = target.mean()\n    # The bigger the count the less full_avg is taken into account\n    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n    # Apply averages to trn and tst series\n    ft_trn_series = pd.merge(\n        trn_series.to_frame(trn_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=trn_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_trn_series.index = trn_series.index \n    ft_tst_series = pd.merge(\n        tst_series.to_frame(tst_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=tst_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_tst_series.index = tst_series.index\n    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"},{"metadata":{"_cell_guid":"562c9068-b02f-4c64-be36-128754df107e","_uuid":"184ac78fd83e42102ccfde0307b31bbd92d0a595"},"cell_type":"markdown","source":"### Testing with ps_car_11_cat"},{"execution_count":null,"metadata":{"_cell_guid":"02726dea-c371-488e-84d3-8d54998e59c4","_uuid":"cf4f62d29a00eb971821592a7b4b77ac203facd8"},"outputs":[],"cell_type":"code","source":"# reading data\ntrn_df = pd.read_csv(\"../input/train.csv\", index_col=0)\nsub_df = pd.read_csv(\"../input/test.csv\", index_col=0)\n\n# Target encode ps_car_11_cat\ntrn, sub = target_encode(trn_df[\"ps_car_11_cat\"], \n                         sub_df[\"ps_car_11_cat\"], \n                         target=trn_df.target, \n                         min_samples_leaf=100,\n                         smoothing=10,\n                         noise_level=0.01)\ntrn.head(10)"},{"metadata":{"_cell_guid":"909b0a7a-2fde-42d4-826d-26ee307e25ea","_uuid":"c01f4d1c40913fd539eb99fa8415a840ac5931ef"},"cell_type":"markdown","source":"### Scatter plot of category values vs target encoding\nWe see that the category values are not ordered\n"},{"execution_count":null,"metadata":{"_kg_hide-input":false,"_cell_guid":"3ab7dddb-ce8e-4ba1-a9ba-c7dbcf61ac98","_uuid":"f1892c3e00c89207c75e3ca4adb036ef0e852ded"},"outputs":[],"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.scatter(trn_df[\"ps_car_11_cat\"], trn)\nplt.xlabel(\"ps_car_11_cat category values\")\nplt.ylabel(\"Noisy target encoding\")"},{"metadata":{"_cell_guid":"d687755e-92fd-4131-8e75-dbb65a9f21e3","_uuid":"f2ef7ce0e9991f52745a11f7532782c975ae9577"},"cell_type":"markdown","source":"### Check AUC metric improvement after noisy encoding over 5 folds"},{"execution_count":null,"metadata":{"_kg_hide-input":true,"_cell_guid":"dccd829f-a816-4475-9c32-a6f140fb1b95","_kg_hide-output":false,"_uuid":"08e2048bb660113bad3d67f764165beaa64188e9"},"outputs":[],"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\nf_cats = [f for f in trn_df.columns if \"_cat\" in f]\nprint(\"%20s   %20s | %20s\" % (\"\", \"Raw Categories\", \"Encoded Categories\"))\nfor f in f_cats:\n    print(\"%-20s : \" % f, end=\"\")\n    e_scores = []\n    f_scores = []\n    for trn_idx, val_idx in folds.split(trn_df.values, trn_df.target.values):\n        trn_f, trn_tgt = trn_df[f].iloc[trn_idx], trn_df.target.iloc[trn_idx]\n        val_f, val_tgt = trn_df[f].iloc[trn_idx], trn_df.target.iloc[trn_idx]\n        trn_tf, val_tf = target_encode(trn_series=trn_f, \n                                       tst_series=val_f, \n                                       target=trn_tgt, \n                                       min_samples_leaf=100, \n                                       smoothing=20,\n                                       noise_level=0.01)\n        f_scores.append(max(roc_auc_score(val_tgt, val_f), 1 - roc_auc_score(val_tgt, val_f)))\n        e_scores.append(roc_auc_score(val_tgt, val_tf))\n    print(\" %.6f + %.6f | %6f + %.6f\" \n          % (np.mean(f_scores), np.std(f_scores), np.mean(e_scores), np.std(e_scores)))"},{"execution_count":null,"metadata":{"_cell_guid":"2d07e4fa-456f-4c5b-a100-0dd28e0a4691","collapsed":true,"_uuid":"3e343c4458ebc4b2d29d846ba9974944b1c4fe79"},"outputs":[],"cell_type":"code","source":""}]}