{"nbformat":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","file_extension":".py","name":"python","mimetype":"text/x-python","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":1,"cells":[{"metadata":{"_cell_guid":"9d6e916b-81a7-46b5-b98c-ea1a6b810a28","_uuid":"2e3d4db614725c4e307f589b06481eefbf60206a"},"cell_type":"markdown","source":"## Introduction\nThe goal is this notebook is to see if best rounds computed during 5-CV optimization for boosting algos can be generalized to predicting test target using the full training dataset. \n\nThe notebook runs 20 2-fold experiments where each fold is used to predict the other by means of a 5-fold CV. "},{"metadata":{"_cell_guid":"957448df-db28-4a6b-9d40-a7bc5ec2d511","_uuid":"a9cbea12674fbca41bab19475e4a9e63b425df08"},"execution_count":null,"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\ntrn = pd.read_csv(\"../input/train.csv\", index_col=0)\ntarget = trn.target\ndel trn[\"target\"]","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"45be5f90-a3c6-491a-8aa9-5b8b7344b95a","collapsed":true,"_uuid":"91beda41609869bede15f4be2f5bd262d887c5f7"},"execution_count":null,"source":"from lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\n\ndef compute_optimal_round(x, y, x_v, y_v):\n    clf = LGBMClassifier(n_estimators=200, \n                         num_leaves=10,\n                         learning_rate=.2, n_jobs=2)\n    clf.fit(x, y, \n            eval_set=[(x_v, y_v)], \n            early_stopping_rounds=25,\n            eval_metric=\"auc\",\n            verbose=0)\n    best_score = roc_auc_score(y_v, clf.predict_proba(x_v, num_iteration=clf.best_iteration_)[:, 1])\n    return clf.best_iteration_, best_score\n\ndef compute_score(x, y, x_v, y_v, rounds):\n    clf = LGBMClassifier(n_estimators=int(np.max(rounds)), \n                         num_leaves=10,\n                         learning_rate=.2, n_jobs=2)\n    clf.fit(x, y, \n            eval_set=[(x_v, y_v)], \n            early_stopping_rounds=None,\n            eval_metric=\"auc\",\n            verbose=0)\n    #print(clf.evals_result_)\n    lgb_evals = clf.evals_result_[\"valid_0\"][\"auc\"]\n    return [lgb_evals[int(round) - 1] for round in rounds]","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"fb1daabe-28c6-4f34-994f-603ec743f64e","_uuid":"a552f8c6c1118a975c1cc45335f9b653e964a02a"},"cell_type":"markdown","source":"## Check generalization\nHere we \n1. split the dataset in 2 equal parts at each iteration. \n2. We run an LGBM on the first part with early stopping using the 2nd part to get the optimal round\n3. We then run a 5 fold CV with early stopping on the 1st part and keep all folds best round\n4. We compare mean, max and min to the optimum\n5. Do the same flipping part 1 and 2 roles\n6. Use a new seed"},{"metadata":{"_cell_guid":"0e88fdf6-885e-4f32-9309-bf85c0124892","_kg_hide-output":false,"_kg_hide-input":true,"_uuid":"49c55c17eca43bc78177512517ffe1c573aafd33"},"execution_count":null,"source":"from sklearn.model_selection import StratifiedKFold\nimport time\nnb_seed = 20\nvalues = np.zeros((2 * nb_seed, 4))\nscores = np.zeros((2 * nb_seed, 4))\ni = 0\nstart = time.time()\nfor seed in range(nb_seed):\n    fold_lev1 = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n    for trn_l1_idx, val_l1_idx in fold_lev1.split(target, target):\n        # Split level1 data\n        trn_l1_x, trn_l1_y = trn.iloc[trn_l1_idx], target.iloc[trn_l1_idx]\n        val_l1_x, val_l1_y = trn.iloc[val_l1_idx], target.iloc[val_l1_idx]\n        # Compute Optimal l1 round\n        opt_l1_rnd, opt_score = compute_optimal_round(trn_l1_x, trn_l1_y, val_l1_x, val_l1_y)\n        # print(\"opt_l1_rnd : \", opt_l1_rnd)\n        # Split level2 data\n        opt_l2_rnd = []\n        fold_lev2 = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n        for trn_l2_idx, val_l2_idx in fold_lev2.split(trn_l1_y, trn_l1_y):\n            trn_l2_x, trn_l2_y = trn_l1_x.iloc[trn_l2_idx], trn_l1_y.iloc[trn_l2_idx]\n            val_l2_x, val_l2_y = trn_l1_x.iloc[val_l2_idx], trn_l1_y.iloc[val_l2_idx]\n            # Compute optimal round for current fold\n            opt_fold_round, _ = compute_optimal_round(trn_l2_x, trn_l2_y, val_l2_x, val_l2_y)\n            opt_l2_rnd.append(opt_fold_round)\n        # Print rounds\n        values[i, :] = [opt_l1_rnd, np.mean(opt_l2_rnd), np.min(opt_l2_rnd), np.max(opt_l2_rnd)]\n        elapsed = (time.time() - start) / 60\n        score_mean, score_min, score_max = compute_score(\n            trn_l1_x, trn_l1_y, val_l1_x, val_l1_y, \n            rounds = [np.mean(opt_l2_rnd),  \n                      np.min(opt_l2_rnd), \n                      np.max(opt_l2_rnd)])\n        scores[i, :] = [opt_score, score_mean, score_min, score_max]\n        \n        print(\"Opt round %5d / Mean round %5d / Min round %5d / Max round %5d [in %5.1f min]\"\n              % (values[i, 0], values[i, 1], values[i, 2], values[i, 3], elapsed))\n        print(\"Opt score %.3f / Mean score %.3f / Min score %.3f / Max score %.3f [in %5.1f min]\"\n              % (scores[i, 0], scores[i, 1], scores[i, 2], scores[i, 3], elapsed))\n        \n        i += 1","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"9cacc18a-ed13-45e0-a6ef-a6d9431f1eac","_kg_hide-input":true,"_uuid":"454ff283a4f01274c8111808802e9a41509431ea"},"execution_count":null,"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.figure(figsize=(10,10))\nsns.distplot(100 * (values[:, 1] - values[:, 0]) / values[:, 0], label=\"Mean CV rounds - Optimum round\")\nsns.distplot(100 * (values[:, 2] - values[:, 0]) / values[:, 0], label=\"Min CV rounds - Optimum round\")\nsns.distplot(100 * (values[:, 3] - values[:, 0]) / values[:, 0], label=\"Max CV rounds - Optimum round\")\nplt.legend(loc=\"upper right\")\nplt.title(\"Error in Optimum round estimation using 5-CV best rounds (in %)\")\n","cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On average the mean of fold rounds gives a good estimate but variance is a big issue here.\n\nBut What about scores ?"},{"metadata":{},"execution_count":null,"source":"plt.figure(figsize=(10,10))\nsns.distplot(100 * (scores[:, 1] - scores[:, 0]) / scores[:, 0], label=\"Mean CV rounds - Optimum round\")\nsns.distplot(100 * (scores[:, 2] - scores[:, 0]) / scores[:, 0], label=\"Min CV rounds - Optimum round\")\nsns.distplot(100 * (scores[:, 3] - scores[:, 0]) / scores[:, 0], label=\"Max CV rounds - Optimum round\")\nplt.legend(loc=\"upper right\")\nplt.title(\"Error in Optimum score estimation using 5-CV best rounds (in %)\")","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"4049d737-680b-4095-bf4c-75b41c0648d9","_uuid":"0762ecbb99f6cd95ab4584085b064c425f7c3b2b"},"cell_type":"markdown","source":"In terms of score, mean of round has a far better shape than min or max."},{"metadata":{"_cell_guid":"27028123-994e-4f89-9d86-512e8e652b62","collapsed":true,"_uuid":"f52efb20a03e519ccb7d14cae2304bd24b4ce363"},"execution_count":null,"source":"","cell_type":"code","outputs":[]}]}