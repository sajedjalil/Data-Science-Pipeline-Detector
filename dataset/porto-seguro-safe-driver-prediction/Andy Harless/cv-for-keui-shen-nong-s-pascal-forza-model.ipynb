{"nbformat_minor":1,"nbformat":4,"cells":[{"source":"MAX_ROUNDS = 5000\nOPTIMIZE_ROUNDS = True","outputs":[],"metadata":{"_cell_guid":"99393d57-64b8-4e66-a126-037fa9b347fe","collapsed":true,"_uuid":"be941765ddc97c673bcb21665a55a64510f419df"},"execution_count":null,"cell_type":"code"},{"source":"Based on Keui Shen Nong's [script](https://www.kaggle.com/kueipo/base-on-froza-pascal-single-xgb-lb-0-284).  *The main point of this kernel is to generate out-of-fold data for stacking/validation/etc..*  It also generates a submission file, which I guess might be interesting, mostly in a negative way.  This uses 4-fold CV as compared to the 25% holdout validation in the original.  In principle 4-fold CV is more robust, so if the LB score from this is not as good, that probably means the original is overfit.  But maybe not, because the process of averaging across folds may not be trustworthy.  (You could also try other methods of averaging:  log-odds or rank average or whatever.  Maybe I will in a future version.  If they all produce worse LB results than the original, that would be a pretty strong indication that it's overfit.  But who is going to make all those submissions....?)  Setting a fixed number of rounds (<code>OPTIMIZE_ROUNDS=False</code> if you can find a good choice for <code>MAX_ROUNDS</code>) will probably generate more reliable out-of-fold predictions.  Alternatively, one could add noise to the validation data to compensate for overfitting.  (I might do that in a later version, too.)","metadata":{"_cell_guid":"12b97784-1dee-48c4-b831-56c696c88f78","_uuid":"ef25ae18c01b92601c3222ad9d23a86957e95782"},"cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom multiprocessing import *\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport xgboost as xgb\nfrom numba import jit","outputs":[],"metadata":{"_cell_guid":"b7258128-55f9-4543-8611-5e0a6661837b","collapsed":true,"_uuid":"72171ee53e170096d37a18eef84682fa348ae5c4"},"execution_count":null,"cell_type":"code"},{"source":"### Gini\n\ndef ginic(actual, pred):\n    actual = np.asarray(actual) \n    n = len(actual)\n    a_s = actual[np.argsort(pred)]\n    a_c = a_s.cumsum()\n    giniSum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n    return giniSum / n\n \ndef gini_normalized(a, p):\n    if p.ndim == 2:\n        p = p[:,1] \n    return ginic(a, p) / ginic(a, a)\n    \n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score\n\n# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n@jit\ndef eval_gini(y_true, y_prob):\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    ntrue = 0\n    gini = 0\n    delta = 0\n    n = len(y_true)\n    for i in range(n-1, -1, -1):\n        y_i = y_true[i]\n        ntrue += y_i\n        gini += y_i * delta\n        delta += 1 - y_i\n    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n    return gini","outputs":[],"metadata":{"_cell_guid":"22381008-e684-428d-a97f-da90eaa44111","collapsed":true,"_uuid":"b24fae4ad6b332041cc889e33b39e46328dfe7cc"},"execution_count":null,"cell_type":"code"},{"source":"def transform_df(df):\n    df = pd.DataFrame(df)\n    dcol = [c for c in df.columns if c not in ['id','target']]\n    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n    for c in dcol:\n        if '_bin' not in c: #standard arithmetic\n            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n\n    for c in one_hot:\n        if len(one_hot[c])>2 and len(one_hot[c]) < 7:\n            for val in one_hot[c]:\n                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n    return df\n\ndef multi_transform(df):\n    print('Init Shape: ', df.shape)\n    p = Pool(cpu_count())\n    df = p.map(transform_df, np.array_split(df, cpu_count()))\n    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n    p.close(); p.join()\n    print('After Shape: ', df.shape)\n    return df","outputs":[],"metadata":{"_cell_guid":"7f8f84f9-aa46-43d6-8d78-619ef9a7dcce","collapsed":true,"_uuid":"affb627af275ad7aa0c5c85dd826ee140370eb3e"},"execution_count":null,"cell_type":"code"},{"source":"#### Load Data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","outputs":[],"metadata":{"_cell_guid":"52b50086-b405-4598-b11c-97887cdcce8e","collapsed":true,"_uuid":"07a5a5782894611e9006ae1b399b0b8fb8a0f06b"},"execution_count":null,"cell_type":"code"},{"source":"### \ny = train['target'].values\ntestid= test['id'].values\ntrainid = train['id'].values\n\n\ntrain.drop(['id','target'],axis=1,inplace=True)\ntest.drop(['id'],axis=1,inplace=True)\n\n### Drop calc\nunwanted = train.columns[train.columns.str.startswith('ps_calc_')]\ntrain = train.drop(unwanted, axis=1)  \ntest = test.drop(unwanted, axis=1)","outputs":[],"metadata":{"_cell_guid":"1b36eb15-ee01-43a3-8766-27650f98158d","collapsed":true,"_uuid":"6255e3c12616b0279cef5c1bdec97751bb72d8b8"},"execution_count":null,"cell_type":"code"},{"source":"### Great Recovery from Pascal's materpiece\n\ndef recon(reg):\n    integer = int(np.round((40*reg)**2)) \n    for a in range(32):\n        if (integer - a) % 31 == 0:\n            A = a\n    M = (integer - A)//31\n    return A, M\ntrain['ps_reg_A'] = train['ps_reg_03'].apply(lambda x: recon(x)[0])\ntrain['ps_reg_M'] = train['ps_reg_03'].apply(lambda x: recon(x)[1])\ntrain['ps_reg_A'].replace(19,-1, inplace=True)\ntrain['ps_reg_M'].replace(51,-1, inplace=True)\ntest['ps_reg_A'] = test['ps_reg_03'].apply(lambda x: recon(x)[0])\ntest['ps_reg_M'] = test['ps_reg_03'].apply(lambda x: recon(x)[1])\ntest['ps_reg_A'].replace(19,-1, inplace=True)\ntest['ps_reg_M'].replace(51,-1, inplace=True)","outputs":[],"metadata":{"_cell_guid":"2123222b-efb8-4bda-af06-45a44bb46022","collapsed":true,"_uuid":"9b5cb463284af71689f14c682b0385cb7a684a30"},"execution_count":null,"cell_type":"code"},{"source":"# Set up folds\nK = 4\nkf = KFold(n_splits = K, random_state = 1, shuffle = True)\ny_valid_pred = pd.DataFrame(0*y)\ny_test_pred = 0\nX = pd.DataFrame(train)\nydf = pd.DataFrame(y)","outputs":[],"metadata":{"_cell_guid":"7c6e4823-4e8c-4408-b961-576d469e9241","collapsed":true,"_uuid":"6aa7ada2193c2e4b8a63eebda925cee5023b45b0"},"execution_count":null,"cell_type":"code"},{"source":"# Set up classifier\nparams = {\n    'eta': 0.025, \n    'max_depth': 4, \n    'subsample': 0.9, \n    'colsample_bytree': 0.7, \n    'colsample_bylevel':0.7,\n    'min_child_weight':100,\n    'alpha':4,\n    'objective': 'binary:logistic', \n    'eval_metric': 'auc', \n    'seed': 99, \n    'silent': True\n}","outputs":[],"metadata":{"_cell_guid":"5d8108f3-e9e8-45d6-93b5-740eb7b4b10b","collapsed":true,"_uuid":"581c3f15f294378a0e2ac3305e9e3d375f664b21"},"execution_count":null,"cell_type":"code"},{"source":"# Run CV\n\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n    \n    # Create data for this fold\n    y_train, y_valid = ydf.iloc[train_index].copy(), ydf.iloc[test_index].copy()\n    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n    X_test = test.copy()\n    print( \"\\nFold \", i)\n\n    # Transform data for this fold\n    one_hot = {c: list(X_train[c].unique()) for c in X_train.columns}\n    X_train = X_train.replace(-1, np.NaN)  # Get rid of -1 while computing summary stats\n    d_median = X_train.median(axis=0)\n    d_mean = X_train.mean(axis=0)\n    X_train = X_train.fillna(-1)  # Restore -1 for missing values\n\n    X_train = multi_transform(X_train)\n    X_valid = multi_transform(X_valid)\n    X_test = multi_transform(X_test)\n\n    # Run model for this fold\n    if OPTIMIZE_ROUNDS:\n        watchlist = [(xgb.DMatrix(X_train, y_train), 'train'), \n                     (xgb.DMatrix(X_valid, y_valid), 'valid')]\n        model = xgb.train( params, xgb.DMatrix(X_train, y_train), MAX_ROUNDS,  \n                           watchlist, feval=gini_xgb, maximize=True, \n                           verbose_eval=100, early_stopping_rounds=70)\n        pred = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(xgb.DMatrix(X_test), ntree_limit=model.best_ntree_limit)\n    else:\n        model = xgb.train( params, xgb.DMatrix(X_train, y_train), MAX_ROUNDS,  \n                           feval=gini_xgb, maximize=True, verbose_eval=100)\n        pred = model.predict( xgb.DMatrix(X_valid) )\n        test_pred = model.predict( xgb.DMatrix(X_test) )\n\n    # Save validation predictions for this fold\n    print( \"  Gini = \", eval_gini(y_valid, pred) )\n    y_valid_pred.iloc[test_index] = pred.reshape( y_valid_pred.iloc[test_index].shape )\n    \n    # Accumulate test set predictions\n    y_test_pred += test_pred\n    \ny_test_pred /= K  # Average test set predictions\n\nprint( \"\\nGini for full training set:\" )\neval_gini(y, y_valid_pred[0].values)","outputs":[],"metadata":{"scrolled":false,"_cell_guid":"c4e48347-920f-4ba7-8b37-cfbaab4c3c00","collapsed":true,"_uuid":"2b9ed96c98b705d3e4bf2a3d60323dfab4332674"},"execution_count":null,"cell_type":"code"},{"source":"# Save validation predictions for stacking/ensembling\nval = pd.DataFrame()\nval['id'] = trainid\nval['target'] = y_valid_pred[0].values\nval.to_csv('forza_pascal_oof.csv', float_format='%.6f', index=False)","outputs":[],"metadata":{"_cell_guid":"0e3dfd76-c566-4b8d-a460-b56e964d0772","collapsed":true,"_uuid":"e61bf4e22c1c29c8358caeecb6e67d6658f2005d"},"execution_count":null,"cell_type":"code"},{"source":"# Create submission file\nsub = pd.DataFrame()\nsub['id'] = testid\nsub['target'] = y_test_pred\nsub.to_csv('forza_pascal_test.csv', float_format='%.6f', index=False)","outputs":[],"metadata":{"_cell_guid":"f4cbef2c-e52b-4afb-b8ef-904ee9b5f9d5","collapsed":true,"_uuid":"380fc8053d00cd8bb2796bfd2b59d10cbc4ce7e1"},"execution_count":null,"cell_type":"code"}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3"}}}