{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.3","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"cells":[{"metadata":{"_cell_guid":"ac228e73-0ffa-4dee-97bd-6249e361bde3","_uuid":"17f6bcd35060823c600f9f9a27f8134a47003845"},"source":"Motivation: auc/gini with keras","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"2cb538a0-e640-4362-a736-cb26f64dbae1","_uuid":"da301e76f462e3594e18add4aee3b5449b80a9b6"},"outputs":[],"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"},{"execution_count":null,"metadata":{"_cell_guid":"8fb03ab7-4c63-4668-9c4e-be07b8b91fd6","_uuid":"c0cde987ee904bffe6d8e601b99c396c92fb73d6"},"outputs":[],"cell_type":"code","source":"print('Reading files')\ntrain  =pd.read_csv(\"../input/train.csv\")\ntest   =pd.read_csv(\"../input/test.csv\")\ncol_x= train.columns.drop(['target'])\ncol  = train.columns.drop(['id','target'])\nprint('OK')"},{"metadata":{"_cell_guid":"fa54554a-4b3d-489e-b593-6df810587ccd","_uuid":"5e41fb3d1157e0df879613ccd2ba3148237ebcbe"},"source":"Blablah keras toys you want to use","cell_type":"markdown"},{"execution_count":null,"metadata":{"_cell_guid":"0b82e77f-cbef-41a3-9a74-05fb54c7cfb7","_uuid":"7eb208ddeec475acb30cd27b8774236eb69dd1f4"},"outputs":[],"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimport keras.models "},{"metadata":{"_cell_guid":"4188a5de-c98b-4940-92a4-08e69c6c2d34","_uuid":"7145ac7f914a5d891dcb8f21b802cf5c57e46ede"},"source":"Kaggle discussion/kernels metrics","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"54947964-db5f-468e-a0fd-81316b4b99c9","_uuid":"aac1908563fd37d5be03a4911e89df189c773c6d"},"outputs":[],"cell_type":"code","source":"import tensorflow as tf\nimport keras.backend as K\n\ndef gini(actual, pred, cmpcol = 0, sortcol = 1):\n    assert( len(actual) == len(pred) )\n    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n    totalLosses = all[:,0].sum()\n    giniSum = all[:,0].cumsum().sum() / totalLosses\n    \n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\n \ndef gini_normalized(a, p):\n    return gini(a, p) / gini(a, a)\n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score\n\n# FROM https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41108\ndef jacek_auc(y_true, y_pred):\n   score, up_opt = tf.metrics.auc(y_true, y_pred)\n   #score, up_opt = tf.contrib.metrics.streaming_auc(y_pred, y_true)    \n   K.get_session().run(tf.local_variables_initializer())\n   with tf.control_dependencies([up_opt]):\n       score = tf.identity(score)\n   return score\n\n# FROM https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41015\n# AUC for a binary classifier\ndef discussion41015_auc(y_true, y_pred):\n    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n    binSizes = -(pfas[1:]-pfas[:-1])\n    s = ptas*binSizes\n    return K.sum(s, axis=0)\n\n#---------------------\n# PFA, prob false alert for binary classifier\ndef binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # N = total number of negative labels\n    N = K.sum(1 - y_true)\n    # FP = total number of false alerts, alerts from the negative class labels\n    FP = K.sum(y_pred - y_pred * y_true)\n    return FP/N\n\n#----------------\n# P_TA prob true alerts for binary classifier\ndef binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # P = total number of positive labels\n    P = K.sum(y_true)\n    # TP = total number of correct alerts, alerts from the positive class labels\n    TP = K.sum(y_pred * y_true)\n    return TP/P"},{"metadata":{"_cell_guid":"baa50a2f-3306-43c5-936c-1d021e12587b","_uuid":"88154d25124b0b82c936139a5550e44dc6a0a074"},"source":"Any model, just an example:","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"94410713-e1c6-4de6-a012-e8e4ccf1f358","_uuid":"63f5c1587a1265e66912d41d32ed07f4758b1254"},"outputs":[],"cell_type":"code","source":"def model_relu1():\n    model = Sequential()\n    model.add(Dense(1024, input_dim=57, activation='relu', name='in'))\n    model.add(Dense(   1, activation='sigmoid', name='out'))\n    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[jacek_auc,discussion41015_auc])\n    return model\n"},{"metadata":{"_cell_guid":"e8131ec9-865b-4c1a-afdb-8a7c18155f40","_uuid":"43290a586cc0dffe8a82952eebc5baad35b86f40"},"source":"# Option 1 - magic , create an callback and handle everything","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"8cb8e3ef-6445-4266-89f0-2ddcb9d2ea99","_uuid":"45ae4b3b93e90780d0959938a072e233c139202b"},"outputs":[],"cell_type":"code","source":"#go here, it's easier to understand callbacks reading keras source code:\n#   https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L838\n#   https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L1040\n\nfrom sklearn.metrics import roc_auc_score\nclass GiniWithEarlyStopping(keras.callbacks.Callback):\n    def __init__(self, min_delta=0, patience=0, verbose=0, predict_batch_size=1024):\n        #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n        \n        # FROM EARLY STOP\n        super(GiniWithEarlyStopping, self).__init__()\n        self.patience = patience\n        self.verbose = verbose\n        self.min_delta = min_delta\n        self.wait = 0\n        self.stopped_epoch = 0\n        self.monitor_op = np.greater\n        self.predict_batch_size=predict_batch_size\n    \n    def on_batch_begin(self, batch, logs={}):\n        if(self.verbose > 1):\n            if(batch!=0):\n                print(\"\")\n            print(\"Hi! on_batch_begin() , batch=\",batch,\",logs:\",logs)\n            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n    \n    def on_batch_end(self, batch, logs={}):\n        if(self.verbose > 1):\n            print(\"Hi! on_batch_end() , batch=\",batch,\",logs:\",logs)\n            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n    \n    def on_train_begin(self, logs={}):\n        if(self.verbose > 1):\n            print(\"Hi! on_train_begin() ,logs:\",logs)\n            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n\n        # FROM EARLY STOP\n        # Allow instances to be re-used\n        self.wait = 0\n        self.stopped_epoch = 0\n        self.best = -np.Inf\n    \n    def on_train_end(self, logs={}):\n        if(self.verbose > 1):\n            print(\"Hi! on_train_end() ,logs:\",logs)\n            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n\n        # FROM EARLY STOP\n        if self.stopped_epoch > 0 and self.verbose > 0:\n            print('Epoch ',self.stopped_epoch,': GiniEarlyStopping')\n    \n    def on_epoch_begin(self, epoch, logs={}):\n        if(self.verbose > 1):\n            print(\"Hi! on_epoch_begin() , epoch=\",epoch,\",logs:\",logs)\n            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n\n    def on_epoch_end(self, epoch, logs={}):\n        if(self.validation_data):\n            y_hat_val=self.model.predict(self.validation_data[0],batch_size=self.predict_batch_size)\n            \n        if(self.verbose > 1):\n            print(\"Hi! on_epoch_end() , epoch=\",epoch,\",logs:\",logs)\n            #print(\"self vars: \",vars(self))  #uncomment and discover some things =)\n        \n        #i didn't found train data to check gini on train set (@TODO HERE)\n        # from source code of Keras: https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L1127\n        # for cbk in callbacks:\n        #     cbk.validation_data = val_ins\n        # Probably we will need to change keras... \n        # \n        \n            print(\"    GINI Callback:\")\n            if(self.validation_data):\n                print('        validation_data.inputs       : ',np.shape(self.validation_data[0]))\n                print('        validation_data.targets      : ',np.shape(self.validation_data[1]))\n                print(\"        roc_auc_score(y_real,y_hat)  : \",roc_auc_score(self.validation_data[1], y_hat_val ))\n                print(\"        gini_normalized(y_real,y_hat): \",gini_normalized(self.validation_data[1], y_hat_val))\n                print(\"        roc_auc_scores*2-1           : \",roc_auc_score(self.validation_data[1], y_hat_val)*2-1)\n        \n            print('    Logs (others metrics):',logs)\n        # FROM EARLY STOP\n        if(self.validation_data):\n            if (self.verbose == 1):\n                print(\"\\n GINI Callback:\",gini_normalized(self.validation_data[1], y_hat_val))\n            current = gini_normalized(self.validation_data[1], y_hat_val)\n            \n            # we can include an \"gambiarra\" (very usefull brazilian portuguese word)\n            # to logs (scores) and use others callbacks too....\n            # logs['gini_val']=current\n            \n            if self.monitor_op(current - self.min_delta, self.best):\n                self.best = current\n                self.wait = 0\n            else:\n                self.wait += 1\n                if self.wait >= self.patience:\n                    self.stopped_epoch = epoch\n                    self.model.stop_training = True\n"},{"execution_count":null,"metadata":{"_cell_guid":"e851e72e-9531-4574-abab-83fcceda67f5","_uuid":"7eb7e7fa25e9e8ca36da9878c9030df574830f33","scrolled":false},"outputs":[],"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n\n# reduce train size, just to this kernel example\nt=train[0:1000]\n# batch_size=500 ~= 2 batchs\nestimator = KerasClassifier(build_fn=model_relu1, nb_epoch=3, batch_size=500, verbose=1)\n\n\n\ncb = [\n    # verbose =2 make many prints (nice to learn keras callback)\n    GiniWithEarlyStopping(patience=1, verbose=2) \n]\n\nestimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n\n\n"},{"metadata":{"collapsed":true,"_cell_guid":"2beedcc0-c093-4a4c-8ba9-e00148ab5857","_uuid":"a06a5922d2b239def68e5cb3dfe3f4613a808a81"},"source":"I don't know why the last line \" < keras.callbacks.History at 0x..... > \" anyone please check it and comment to fix","cell_type":"markdown"},{"execution_count":null,"metadata":{"_cell_guid":"fa405dab-ef65-4528-a722-5dfbfa320d8d","_uuid":"21d50cd93e1c8a66bda0dff4f323ad7924a1bd81"},"outputs":[],"cell_type":"code","source":"cb = [\n    # verbose =1 print gini per epoch\n    GiniWithEarlyStopping(patience=1, verbose=1) \n]\n\nestimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n\n"},{"metadata":{"_cell_guid":"f32ff083-d86d-496e-a2f8-1cf104de4ae8","_uuid":"9b6ba6e17bd863a9637d435ac53d930274c591ab"},"source":"I don't know why the last line \" < keras.callbacks.History at 0x..... > \" anyone please check it and comment to fix","cell_type":"markdown"},{"execution_count":null,"metadata":{"_cell_guid":"d28cca82-a771-4325-8d3f-bd4fcc9cbc77","_uuid":"3cb9173ecf43c6a4a48491d99a97b1ac4e949d36"},"outputs":[],"cell_type":"code","source":"cb = [\n    # verbose =0 don't print\n    GiniWithEarlyStopping(patience=1, verbose=0) \n]\n\nestimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n\n"},{"metadata":{"collapsed":true,"_cell_guid":"0ea5f1d3-eb85-4325-853b-f131d434c0ac","_uuid":"adde2a46b4a9f00b272dfd7abb092b39384885de"},"source":"# Option 2 - magic, Include metric in logs dictionary\n\nexample with Roc","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"484b7bcd-a9e9-4db0-88e5-194805ec3056","_uuid":"33426449d0f23ca963d5ca2edd9cf65991257e65"},"outputs":[],"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nclass RocAucMetricCallback(keras.callbacks.Callback):\n    def __init__(self, predict_batch_size=1024, include_on_batch=False):\n        super(RocAucMetricCallback, self).__init__()\n        self.predict_batch_size=predict_batch_size\n        self.include_on_batch=include_on_batch\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_batch_end(self, batch, logs={}):\n        if(self.include_on_batch):\n            logs['roc_auc_val']=float('-inf')\n            if(self.validation_data):\n                logs['roc_auc_val']=roc_auc_score(self.validation_data[1], \n                                                  self.model.predict(self.validation_data[0],\n                                                                     batch_size=self.predict_batch_size))\n\n    def on_train_begin(self, logs={}):\n        if not ('roc_auc_val' in self.params['metrics']):\n            self.params['metrics'].append('roc_auc_val')\n\n    def on_train_end(self, logs={}):\n        pass\n\n    def on_epoch_begin(self, epoch, logs={}):\n        pass\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['roc_auc_val']=float('-inf')\n        if(self.validation_data):\n            logs['roc_auc_val']=roc_auc_score(self.validation_data[1], \n                                              self.model.predict(self.validation_data[0],\n                                                                 batch_size=self.predict_batch_size))\n\n"},{"execution_count":null,"metadata":{"_cell_guid":"78a70077-f712-4307-a82c-cc21c4a3b971","_uuid":"8cef5db284ac94619eec45b96b8d92d57420bb4d"},"outputs":[],"cell_type":"code","source":"from keras.callbacks import EarlyStopping\n# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n\n# reduce train size, just to this kernel example\nt=train[0:1000]\n# batch_size=500 ~= 2 batchs\nestimator = KerasClassifier(build_fn=model_relu1, nb_epoch=3, batch_size=500, verbose=1)\n\ncb = [\n    RocAucMetricCallback(), # include it before EarlyStopping!\n    EarlyStopping(monitor='roc_auc_val',patience=1, verbose=2) \n]\n\nestimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n\n\n"},{"metadata":{"_cell_guid":"f5b6e9d0-aa07-4e76-aa69-6c1290b70c58","_uuid":"9e8e2f60afdcf429419b29bd2d4781ddd4d51346"},"source":"\"Epoch 00002: early stopping\" - Nice =D\n","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"4bfda9f3-304a-4714-9d1a-9221174351d1","_uuid":"8a6c4524d709cdba04b493ba9d62e25bfcff3de1"},"outputs":[],"cell_type":"code","source":"cb = [\n    EarlyStopping(monitor='roc_auc_val',patience=1, verbose=2), \n    RocAucMetricCallback(), # include it before EarlyStopping! i told you...\n]\nestimator.fit(t[col].values,t['target'],epochs=100,validation_split=.2,callbacks=cb)\n"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"e798580a-6f2c-41d1-9845-5ca73972f4a3","_uuid":"8cf4c2e069954e280660958ff47a5db300dc7a49"},"outputs":[],"cell_type":"code","source":""}],"nbformat_minor":1,"nbformat":4}