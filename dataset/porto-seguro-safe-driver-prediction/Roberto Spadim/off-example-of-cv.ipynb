{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","version":"3.6.1"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_uuid":"6f5dcc7969de4094da628be88b7f6f96ca140ab2","_cell_guid":"a8d2dbe0-b71b-476b-9924-70f4ce7da59c"},"source":" example to Daniel Moller - https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/40881\n ideas and comments are wellcode","cell_type":"markdown"},{"metadata":{"_uuid":"0fa6422e7dcc650e00503e8ed25d10e7769cff5b","_cell_guid":"589124d3-0d37-43c4-936c-cdb084f832db"},"outputs":[],"execution_count":null,"cell_type":"code","source":"import numpy as np  # numeric library\nimport pandas as pd # read file, and use dataframes (like database tables, but in python)\n# read train file (train have features (X vectors) and target (Y vectors)), you use it to fit models\ntrain  =pd.read_csv(\"../input/train.csv\")\nprint(train.columns)   # show columns at train pandas.DataFrame\nprint(np.shape(train)) # show DataFrame shape (~= rows, features)\n\n#this variable will contain an 'array' of all feature columns, i will use it to train model\ncol = train.columns.drop(['id','target'])\n"},{"metadata":{"collapsed":true,"_uuid":"792d572b4a6bb9728ff604ed056382ff27f17197","_cell_guid":"77c72854-8e89-439d-90c0-cfe73ac594d6"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#in this competition we use GINI metric as 'evaluation function'\n# there're 2 metrics, error functions - used to fit models (normally they are differentiable)\n#                and evaluation functions - used to select / check what's the useful metric information\n\n# i will show an XGBoost model classifier, it's an gradient boosted , it will use logloss to train, in this case\n# it will use logloss as error function, and evaluation function is just to check if model is doing a good work\n# XGBoost have others methods to crossvalidate it, \n# but i will show an 'generic' estimator CV scoring idea using scikit learn lib\n\n\n\n\n\n\n#let's implement the evaluation function:\nfrom sklearn.metrics import make_scorer #function to create a scorer from an metric function\ndef gini(actual, pred, cmpcol = 0, sortcol = 1):\n    assert( len(actual) == len(pred) )\n    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n    totalLosses = all[:,0].sum()\n    giniSum = all[:,0].cumsum().sum() / totalLosses\n    \n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\ndef gini_normalized(a, p):\n    return gini(a, p) / gini(a, a)\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score\n# i will create an SCORER to use with SCIKIT LEARN library\ngini_scorer = make_scorer(gini_normalized, greater_is_better = True)"},{"metadata":{"_uuid":"00180ef769ce7a9c7a43f05cd71ae934cad6b643","_cell_guid":"7d91134f-e5d0-4939-9a2f-a8082e08167d"},"outputs":[],"execution_count":null,"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import validation_curve,StratifiedShuffleSplit\n#let's create a model (xgb_model variable) using some 'default' parameters\nxgb_model = XGBClassifier(\n    n_jobs=-1,\n    objective='binary:logistic',\n    learning_rate=1,\n    max_depth=2,\n    silent=False,\n    subsample=1,\n    colsample_bytree=1,\n    n_estimators=100,\n    random_state=1\n)\n\n#i will naive reduce dataset size cause validation_curve is a bit cpu intensive (that's not ok, just an example)\n# you should check if you can do it, and how, with your model+dataset or not\nsome_sample_data_to_test=train.sample(n=10000)\n\n# let's do some fitting, using different parameters and plot what's the crossvalidation score:\nparam_range=[2,4,6]\ntrain_scores, test_scores = validation_curve( #http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n    xgb_model,       #model that we will fit many many times (crossvalidate) with different parameters\n    some_sample_data_to_test[col],      #features\n    some_sample_data_to_test['target'], #target variable \n    param_name=\"max_depth\",       #parameter that we will change\n    param_range=param_range,      #values that we will change\n    cv=StratifiedShuffleSplit(5,random_state=1,test_size=.1),  # CV SPLIT STRATEGY, here we select how to cut data and validation_curve function will execute crossvalidation scoring\n    scoring=gini_scorer,#\"neg_log_loss\",    #score function\n    n_jobs=-1)\n\n# get scorer values\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std  = np.std(train_scores, axis=1)\ntest_scores_mean  = np.mean(test_scores, axis=1)\ntest_scores_std   = np.std(test_scores, axis=1)\n\n#plot some chart\nimport matplotlib.pyplot as plt\nplt.title(\"Validation Curve\")\nplt.xlabel(\"Param\")\nplt.ylabel(\"Score\")\nlw = 2\nplt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=lw)\nplt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2,color=\"darkorange\", lw=lw)\nplt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",color=\"navy\", lw=lw)\nplt.fill_between(param_range, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.2,color=\"navy\", lw=lw)\nplt.legend(loc=\"best\")\nplt.show()\n\n#more explanation about bias-variance: https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\n#http://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py\n#T. Hastie, R. Tibshirani and J. Friedman, “Elements of Statistical Learning”, Springer, 2009.\n\n#check that training score is high (in-sample data) - the model overfit in sample\n#check that test score is lower (out-of-sample data) - the model don't generalize to the out-of-sample \n#                                                      data (bad estimator ~ wrong hyperparameters or wrong model, or poor dataset ~ poor features or intratable problem)\n#\n#the crossvalidation idea is test model with diferent train-test data (folds / cuts), \n#and have a 'good' crossvalidation score (good bias/variance), good crossvalidation ~= good generalization ~= good models"},{"metadata":{"_uuid":"352cd4fbe85b598a0abfc4ddb571591463bf8409","_cell_guid":"417fc011-c399-4be1-8989-41f039544d5c"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# you can use cross_val_score too, it just train-test and return scores, no validation curve\n\nfrom sklearn.model_selection import cross_val_score #http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score\n\n\nxgb_model = XGBClassifier(\n    n_jobs=-1,\n    objective='binary:logistic',\n    learning_rate=1,\n    max_depth=2,\n    silent=False,\n    subsample=1,\n    colsample_bytree=1,\n    n_estimators=100,\n    random_state=1\n)\n\nsome_sample_data_to_test=train.sample(n=10000)\n\nprint(\n    'score for each kfold, using cross_val_score function:',\n    cross_val_score(xgb_model, \n                          X=some_sample_data_to_test[col], \n                          y=some_sample_data_to_test['target'],\n                          scoring=gini_scorer,\n                          cv=StratifiedShuffleSplit(5,random_state=1,test_size=.1)\n     ) ) "},{"metadata":{"_uuid":"699410187f99dbd70ac265daae49a02d92ff0d8b","_cell_guid":"0d057931-7dff-4e44-9362-dfdaee3d1ccb"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# what StratifiedShuffleSplit do?\ncv=StratifiedShuffleSplit(5,random_state=1,test_size=.1)\n\n#some_sample_data_to_test=train.sample(n=10000).copy()   #copy dataset \n#some_sample_data_to_test.reset_index(drop=True,inplace=True) #reset index\n\nX=some_sample_data_to_test[col]\ny=some_sample_data_to_test['target']\nprint('splits using CV functions->',cv.get_n_splits(X,y))\n\n#it create an generator object that return (X,y) slices to train-test\ni=0\nfor train_index, test_index in cv.split(X,y):\n    if(False): #change to true to check index selected at each fold\n        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index] #cut data - X\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index] #cut data - Y\n    \n    #fit your model\n    xgb_model.fit(X_train,y_train)\n    #score it (that's what cross_val_score do)\n    print('cv split',i,' score=',gini_normalized(y_test,xgb_model.predict_proba(X_test)[:,1]))\n    i+=1\n    \n#if your model have a good bias/variance tradeoff in crossvalidation, you can fit you model \n# with all data:\n\nxgb_model.fit(some_sample_data_to_test[col],some_sample_data_to_test['target'])\n\n#and predict any other new data\npredict  =pd.read_csv(\"../input/test.csv\") #reading test data\n\nxgb_model.predict_proba(predict[col])[:,1]  #[:,1] select only positive (true) probabilities"},{"metadata":{"_uuid":"746591283b810f0725404fd0cdfca27561e99454","_cell_guid":"9df21392-f3e7-481c-8f21-b79baef0529a"},"source":"good luck!","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"e0d852d72d44e0139a98470fe24949259979d5eb","_cell_guid":"a9a1f5e0-b275-46f7-ab51-a2c6248853a1"},"outputs":[],"execution_count":null,"cell_type":"code","source":""}]}