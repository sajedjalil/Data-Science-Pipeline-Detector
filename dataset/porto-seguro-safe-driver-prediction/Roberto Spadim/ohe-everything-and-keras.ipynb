{"nbformat_minor":1,"nbformat":4,"cells":[{"source":"from other kernel....\n\nhttps://www.kaggle.com/rspadim/humm-float-integer-why-not-categorical","metadata":{"_uuid":"d0865ebd80675f1e6a3db00ca6854fc921bd8a4c","_cell_guid":"5cb825d3-dbf6-432d-aed4-7a59cfab2812"},"cell_type":"markdown"},{"outputs":[],"source":"#reading data :)\nimport numpy as np\nimport pandas as pd\ntrain=pd.read_csv('../input/train.csv')\ntest =pd.read_csv('../input/test.csv')\ntest['target']=-1 # just to match columns\nboth=test.copy()\nboth=both.append(train.copy())\ndel test  #bye!\ndel train #bye!\ncols=both.columns.drop(['id','target']).tolist()\nprint('columns: ',both.columns.tolist())\nprint('target values: ',both['target'].unique())","execution_count":null,"metadata":{"_uuid":"2f6546284c9f654d181e28128415998a616e2296","_cell_guid":"6cb9e2b2-1ed7-494d-8165-99a808a7ec00"},"cell_type":"code"},{"outputs":[],"source":"noncat=[]\ncats=[]\ncats_prefix={}\nfor i in cols:\n    unique_train=both[both['target']!=-1][i].unique()\n    unique_both =both[i].unique()\n    equal=(sorted(unique_train) == sorted(unique_both))\n    length_train=len(unique_train)\n    length_both=len(unique_both)\n    print('Column: ',i,'\\t unique values at train/both=',\n          length_train,' / ',length_both,\n          '\\t <- categorical?!' if equal else ''\n         )\n    if(not equal):\n        noncat.append(i)\n    if(equal and length_both>2):\n        cats.append(i)\n        cats_prefix[i]=\"OHE_\"+i\nprint(\"these variables should be categorical, or not?! =) \",cats)","execution_count":null,"metadata":{"_uuid":"2168b92678d03fb65396c217cb5e6aed5d8f80b2","_cell_guid":"bd6f6eac-17f0-4ace-b292-efbd4635f401"},"cell_type":"code"},{"outputs":[],"source":"#i will OHE to you :)\nboth=pd.get_dummies(both,prefix=cats_prefix,columns=cats)\nboth[both['target']!=-1].to_csv('train.cat.ohe.csv.gzip',index=False,compression='gzip')\nboth[both['target']==-1].to_csv('test.cat.ohe.csv.gzip' ,index=False,compression='gzip')\n\nprint('features:',len(both.columns.drop(['target','id']).tolist()))","execution_count":null,"metadata":{"_uuid":"cf3b9569476462f53ec9c4a8860c870a2c5e56c7","_cell_guid":"bdf60734-8987-4718-92e4-df2a36effc3a"},"cell_type":"code"},{"outputs":[],"source":"del both\nimport gc\ngc.collect()","execution_count":null,"metadata":{"_uuid":"1bb84964d81ad8510c24c40494bdb9015ccf91de","_cell_guid":"2c9e16c8-ec89-4443-8064-26a31d9673f9"},"cell_type":"code"},{"source":"--------------\nkeras\n\nfrom: https://www.kaggle.com/tilii7/keras-averaging-runs-gini-early-stopping","metadata":{"_uuid":"075d90ccdf253a5bc3bfeb4c8f6f37d98443c53b","collapsed":true,"_cell_guid":"03a13f48-aae2-4800-90a5-e416af4df851"},"cell_type":"markdown"},{"outputs":[],"source":"from datetime import datetime\nfrom sklearn.metrics import log_loss, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import load_model\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Dropout, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback\nfrom keras.wrappers.scikit_learn import KerasClassifier","execution_count":null,"metadata":{},"cell_type":"code"},{"outputs":[],"source":"class roc_auc_callback(Callback):\n    def __init__(self,training_data,validation_data):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict_proba(self.x, verbose=0)\n        roc = roc_auc_score(self.y, y_pred)\n        logs['roc_auc'] = roc_auc_score(self.y, y_pred)\n        logs['norm_gini'] = ( roc_auc_score(self.y, y_pred) * 2 ) - 1\n\n        y_pred_val = self.model.predict_proba(self.x_val, verbose=0)\n        roc_val = roc_auc_score(self.y_val, y_pred_val)\n        logs['roc_auc_val'] = roc_auc_score(self.y_val, y_pred_val)\n        logs['norm_gini_val'] = ( roc_auc_score(self.y_val, y_pred_val) * 2 ) - 1\n\n        print('\\rroc_auc: %s - roc_auc_val: %s - norm_gini: %s - norm_gini_val: %s' % (str(round(roc,5)),str(round(roc_val,5)),str(round((roc*2-1),5)),str(round((roc_val*2-1),5))), end=10*' '+'\\n')\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"outputs":[],"source":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod(\n            (datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' %\n              (thour, tmin, round(tsec, 2)))\n\ndef scale_data(X, scaler=None):\n    if not scaler:\n        scaler = MinMaxScaler(feature_range=(-1, 1))\n        scaler.fit(X)\n    X = scaler.transform(X)\n    return X, scaler","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"outputs":[],"source":"# train and test data path\nDATA_TRAIN_PATH = 'train.cat.ohe.csv.gzip'\nDATA_TEST_PATH = 'test.cat.ohe.csv.gzip'\n\ndef load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n    train_loader = pd.read_csv(path_train, compression='gzip', \n                               dtype={'target': np.int8, 'id': np.int32})\n    train = train_loader.drop(['target', 'id'], axis=1)\n    train_labels = train_loader['target'].values\n    train_ids = train_loader['id'].values\n    print('\\n Shape of raw train data:', train.shape)\n\n    test_loader = pd.read_csv(path_test, compression='gzip', dtype={'id': np.int32})\n    \n    test = test_loader.drop(['id','target'], axis=1)\n    test_ids = test_loader['id'].values\n    print(' Shape of raw test data:', test.shape)\n\n    return train, train_labels, test, train_ids, test_ids","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"outputs":[],"source":"folds = 4\nruns = 2\n\ncv_LL = 0\ncv_AUC = 0\ncv_gini = 0\nfpred = []\navpred = []\navreal = []\navids = []","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"outputs":[],"source":"# Load data set and target values\ntrain, target, test, tr_ids, te_ids = load_data()\nn_train = train.shape[0]\ntrain_test = pd.concat((train, test)).reset_index(drop=True)\ntrain_test_scaled, scaler = scale_data(train_test)\ntrain = train_test_scaled[:n_train, :]\ntest = train_test_scaled[n_train:, :]\nprint('\\n Shape of processed train data:', train.shape)\nprint(' Shape of processed test data:', test.shape)","execution_count":null,"metadata":{},"cell_type":"code"},{"outputs":[],"source":"patience = 10\nbatchsize = 128","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"outputs":[],"source":"# Let's split the data into folds. I always use the same random number for reproducibility, \n# and suggest that you do the same (you certainly don't have to use 1001).\n\nskf = StratifiedKFold(n_splits=folds, random_state=1001)\nstarttime = timer(None)\nfor i, (train_index, test_index) in enumerate(skf.split(train, target)):\n    start_time = timer(None)\n    X_train, X_val = train[train_index], train[test_index]\n    y_train, y_val = target[train_index], target[test_index]\n    train_ids, val_ids = tr_ids[train_index], tr_ids[test_index]\n    \n# This is where we define and compile the model. These parameters are not optimal, as they were chosen \n# to get a notebook to complete in 60 minutes. Other than leaving BatchNormalization and last sigmoid \n# activation alone, virtually everything else can be optimized: number of neurons, types of initializers, \n# activation functions, dropout values. The same goes for the optimizer at the end.\n\n#########\n# Never move this model definition to the beginning of the file or anywhere else outside of this loop. \n# The model needs to be initialized anew every time you run a different fold. If not, it will continue \n# the training from a previous model, and that is not what you want.\n#########\n\n    # This definition must be within the for loop or else it will continue training previous model\n    def baseline_model():\n        model = Sequential()\n        model.add(\n            Dense(\n                200,\n                input_dim=X_train.shape[1],\n                kernel_initializer='glorot_normal',\n                ))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(Dense(100, kernel_initializer='glorot_normal'))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.25))\n        model.add(Dense(50, kernel_initializer='glorot_normal'))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.15))\n        model.add(Dense(25, kernel_initializer='glorot_normal'))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.1))\n        model.add(Dense(1, activation='sigmoid'))\n\n        # Compile model\n        model.compile(optimizer='adam', metrics = ['accuracy'], loss='binary_crossentropy')\n\n        return model\n\n# This is where we repeat the runs for each fold. If you choose runs=1 above, it will run a \n# regular N-fold procedure.\n\n#########\n# It is important to leave the call to random seed here, so each run starts with a different seed.\n#########\n\n    for run in range(runs):\n        print('\\n Fold %d - Run %d\\n' % ((i + 1), (run + 1)))\n        np.random.seed()\n\n# Lots to unpack here.\n\n# The first callback prints out roc_auc and gini values at the end of each epoch. It must be listed \n# before the EarlyStopping callback, which monitors gini values saved in the previous callback. Make \n# sure to set the mode to \"max\" because the default value (\"auto\") will not handle gini properly \n# (it will act as if the model is not improving even when roc/gini go up).\n\n# CSVLogger creates a record of all iterations. Not really needed but it doesn't hurt to have it.\n\n# ModelCheckpoint saves a model each time gini improves. Its mode also must be set to \"max\" for reasons \n# explained above.\n\n        callbacks = [\n            roc_auc_callback(training_data=(X_train, y_train),validation_data=(X_val, y_val)),  # call this before EarlyStopping\n            EarlyStopping(monitor='norm_gini_val', patience=patience, mode='max', verbose=1),\n            CSVLogger('keras-5fold-run-01-v1-epochs.log', separator=',', append=False),\n            ModelCheckpoint(\n                    'keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check',\n                    monitor='norm_gini_val', mode='max', # mode must be set to max or Keras will be confused\n                    save_best_only=True,\n                    verbose=1)\n        ]\n\n# The classifier is defined here. Epochs should be be set to a very large number (not 3 like below) which \n# will never be reached anyway because of early stopping. I usually put 5000 there. Because why not.\n\n        nnet = KerasClassifier(\n            build_fn=baseline_model,\n# Epoch needs to be set to a very large number ; early stopping will prevent it from reaching\n#            epochs=5000,\n            epochs=3,\n            batch_size=batchsize,\n            validation_data=(X_val, y_val),\n            verbose=2,\n            shuffle=True,\n            callbacks=callbacks)\n\n        fit = nnet.fit(X_train, y_train)\n        \n# We want the best saved model - not the last one where the training stopped. So we delete the old \n# model instance and load the model from the last saved checkpoint. Next we predict values both for \n# validation and test data, and create a summary of parameters for each run.\n\n        del nnet\n        nnet = load_model('keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check')\n        scores_val_run = nnet.predict_proba(X_val, verbose=0)\n        LL_run = log_loss(y_val, scores_val_run)\n        print('\\n Fold %d Run %d Log-loss: %.5f' % ((i + 1), (run + 1), LL_run))\n        AUC_run = roc_auc_score(y_val, scores_val_run)\n        print(' Fold %d Run %d AUC: %.5f' % ((i + 1), (run + 1), AUC_run))\n        print(' Fold %d Run %d normalized gini: %.5f' % ((i + 1), (run + 1), AUC_run*2-1))\n        y_pred_run = nnet.predict_proba(test, verbose=0)\n        if run > 0:\n            scores_val = scores_val + scores_val_run\n            y_pred = y_pred + y_pred_run\n        else:\n            scores_val = scores_val_run\n            y_pred = y_pred_run\n            \n# We average all runs from the same fold and provide a parameter summary for each fold. Unless something \n# is wrong, the numbers printed here should be better than any of the individual runs.\n\n    scores_val = scores_val / runs\n    y_pred = y_pred / runs\n    LL = log_loss(y_val, scores_val)\n    print('\\n Fold %d Log-loss: %.5f' % ((i + 1), LL))\n    AUC = roc_auc_score(y_val, scores_val)\n    print(' Fold %d AUC: %.5f' % ((i + 1), AUC))\n    print(' Fold %d normalized gini: %.5f' % ((i + 1), AUC*2-1))\n    timer(start_time)\n    \n# We add up predictions on the test data for each fold. Create out-of-fold predictions for validation data.\n\n    if i > 0:\n        fpred = pred + y_pred\n        avreal = np.concatenate((avreal, y_val), axis=0)\n        avpred = np.concatenate((avpred, scores_val), axis=0)\n        avids = np.concatenate((avids, val_ids), axis=0)\n    else:\n        fpred = y_pred\n        avreal = y_val\n        avpred = scores_val\n        avids = val_ids\n    pred = fpred\n    cv_LL = cv_LL + LL\n    cv_AUC = cv_AUC + AUC\n    cv_gini = cv_gini + (AUC*2-1)","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"outputs":[],"source":"LL_oof = log_loss(avreal, avpred)\nprint('\\n Average Log-loss: %.5f' % (cv_LL/folds))\nprint(' Out-of-fold Log-loss: %.5f' % LL_oof)\nAUC_oof = roc_auc_score(avreal, avpred)\nprint('\\n Average AUC: %.5f' % (cv_AUC/folds))\nprint(' Out-of-fold AUC: %.5f' % AUC_oof)\nprint('\\n Average normalized gini: %.5f' % (cv_gini/folds))\nprint(' Out-of-fold normalized gini: %.5f' % (AUC_oof*2-1))\nscore = str(round((AUC_oof*2-1), 5))\ntimer(starttime)\nmpred = pred / folds","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"outputs":[],"source":"print('#\\n Writing results')\nnow = datetime.now()\noof_result = pd.DataFrame(avreal, columns=['target'])\noof_result['prediction'] = avpred\noof_result['id'] = avids\noof_result.sort_values('id', ascending=True, inplace=True)\noof_result = oof_result.set_index('id')\nsub_file = 'train_5fold-keras-run-01-v1-oof_' + str(score) + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\nprint('\\n Writing out-of-fold file:  %s' % sub_file)\noof_result.to_csv(sub_file, index=True, index_label='id')","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"outputs":[],"source":"result = pd.DataFrame(mpred, columns=['target'])\nresult['id'] = te_ids\nresult = result.set_index('id')\nprint('\\n First 10 lines of your 5-fold average prediction:\\n')\nprint(result.head(10))\nsub_file = 'submission_5fold-average-keras-run-01-v1_' + str(score) + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\nprint('\\n Writing submission:  %s' % sub_file)\nresult.to_csv(sub_file, index=True, index_label='id')","execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"nbconvert_exporter":"python","file_extension":".py","name":"python","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","version":"3.6.3"}}}