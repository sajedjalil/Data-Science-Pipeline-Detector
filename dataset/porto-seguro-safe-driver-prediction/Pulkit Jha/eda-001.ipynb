{"cells":[{"metadata":{"_cell_guid":"d20d05fd-8125-46a9-8337-1937aadbf7e4","_uuid":"4f2b29a02ebca1cfd6f269abd09e54387fa404f9","scrolled":true},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code","outputs":[],"execution_count":1},{"metadata":{"_cell_guid":"31d02cc6-c4a0-46cd-b23c-35fc32dfeaff","_uuid":"1737926de45d37cc589252971c99cd4f7bf660c1","collapsed":true},"source":"train = pd.read_csv('../input/train.csv')\nvalid  = pd.read_csv('../input/test.csv')","cell_type":"code","outputs":[],"execution_count":2},{"metadata":{"_cell_guid":"4657c2f8-7079-4673-9abb-b95b526569fc","_uuid":"ee3bc8a2f2cf6d398084b1cc17ddf1ca2ad1e442"},"source":"print(\"Shape of Train Data : \", train.shape)\nprint(\"Shape of Validation Data : \",  valid.shape)","cell_type":"code","outputs":[],"execution_count":3},{"metadata":{"_cell_guid":"35cb6808-986d-41ba-88d2-f9f40d5320c9","_uuid":"b19e5d86b24e8c4547572c1991b624d9a1f3649e"},"source":"print(\"Data Type in the Training Data : \")\nprint(train.dtypes)\nprint(valid.dtypes)","cell_type":"code","outputs":[],"execution_count":4},{"metadata":{"_cell_guid":"458b16e5-31ab-4717-9124-8f9c586d1a9b","_uuid":"01183d04be55a4cad3fa3d2aa6d610054f9c62a3","scrolled":true},"source":"print('Summary Statistics:')\nfor col in train.columns:\n    print('Distinct Values, min and, max of : ',col, train[col].nunique(), min(train[col]), max(train[col]))","cell_type":"code","outputs":[],"execution_count":5},{"metadata":{"_cell_guid":"8abb4c3e-60b2-4293-bde8-6b03054778c7","_uuid":"ca65d08993f3d380b51868f4d3d94c1b884e9d58"},"source":"print('Distribution of Events : ')\ndfOut = train['target'].value_counts().reset_index()\ndfOut.columns = ['target', 'event']\ndfOut['eventRate'] = dfOut['event']/sum(dfOut['event'])\nprint(dfOut)","cell_type":"code","outputs":[],"execution_count":6},{"metadata":{"_cell_guid":"bb932d5d-5018-43e6-9019-b83de4cec5af","_uuid":"820787db6ed202232b9366e8de18ef2f629aed11","scrolled":true},"source":"print(' --- Risk Table (Different Approach) --- ')\nfor col in train.columns:\n    if(col not in ['id','target','ps_reg_03','ps_car_12','ps_car_13','ps_car_14','ps_car_15']):\n        print(\"Feature : \", col)\n        dfOut = train.groupby(col)['target'].agg({'sum' : 'sum', 'count' : 'count'}).reset_index()\n        dfOut['eventOdd'] = dfOut['sum']/dfOut['count'] * 100\n        dfOut[col + '_eventRate']= dfOut['sum']/sum(dfOut['sum']) * 100\n        dfOut.sort_values(col + '_eventRate', ascending = False, inplace = True)\n        dfOut.drop(['sum','count','eventOdd'], axis = 1, inplace = True)\n        train = pd.merge(train, dfOut, on = col, how = 'inner')\n        train.drop(col, axis = 1, inplace = True)\n\npd.set_option('display.max_columns',None)       \nprint(train.head())\n","cell_type":"code","outputs":[],"execution_count":7},{"metadata":{"_cell_guid":"9c80c93f-72c8-4a7c-91a1-b875cf14cbc7","_uuid":"29ef07ba3952c0e79a59e9441f7716a7042f277e"},"source":"print('--- XGBoost ---')\nimport random\nfrom xgboost import XGBRegressor\n\ntrain['randomNumber'] = [random.uniform(0,1) for x in range(train.shape[0])]\n\ndfTrain = train.query('randomNumber<=.7')\ndfTest  = train.query('randomNumber>.7')\n\nprint('--- Distribuion of Event in Train and Test Datasets')\nprint('--- Train ---\\n', dfTrain['target'].value_counts())\nprint('--- Test ---\\n', dfTest['target'].value_counts())\n\ncolsToKeep = [x for x in train.columns if x not in ('id','target','randomNumber')]\nxTrain = dfTrain[colsToKeep].apply(lambda x: x).values\nyTrain = dfTrain['target'].values\nxTest  = dfTest[colsToKeep].apply(lambda x: x).values\nyTest  = dfTest['target'].values\n\nreg = XGBRegressor()\nreg.fit(xTrain, yTrain)\nyPred = reg.predict(xTest)\n\nfrom sklearn.metrics import log_loss, accuracy_score\nprint('Log Loss:\\n', log_loss(yTest, yPred))\n","cell_type":"code","outputs":[],"execution_count":8},{"metadata":{"_cell_guid":"743cedbd-8cd1-4f57-8e67-d25f3f25dabe","_uuid":"c5bc00e0d174d37b9d3715dcd99819442b4f4332"},"source":"print('--- Model Validation ---')\nxValid = valid.drop(['id'], axis = 1).values\n\nyOut = reg.predict(xValid)\n\noutDf = pd.DataFrame()\noutDf['id'] = valid['id']\noutDf['target'] = yOut\n\noutDf.to_csv('100_test.csv', index = False)","cell_type":"code","outputs":[],"execution_count":9},{"metadata":{"_cell_guid":"d9e358ea-6d7e-47bb-a60f-211e9c4049a1","_uuid":"78e2e31e7d6ee99e2fd408b67b14374b16d515bf","collapsed":true},"source":"","cell_type":"code","outputs":[],"execution_count":null}],"nbformat_minor":1,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python","file_extension":".py","name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4}