{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.1","nbconvert_exporter":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}}},"cells":[{"metadata":{"_cell_guid":"5a600795-43d4-4227-9bd2-f25a13d05a99","_uuid":"82f409f98d84e5aaa130dadacee759271477382d"},"source":"# Stratified KFold + Gradient Boosting Classification with XGBoost in Python\n### **Hyungsuk Kang, Sungkyunkwan University**\n#### 2017/07/23\n\n* **1. Introduction**\n* **2. Data preparation**\n    * 2.1 Load data\n    * 2.2 Check for missing values\n    * 2.3 Split features and targets from the data\n    * 2.4 Exploratory Visualization\n* **3. Training/Predicting Pipeline**\n    * 3.1  Define Gini metric\n    * 3.2 Drop Unnecessary Features\n    * 3.3 Stratified KFold\n    * 3.4 XGBoost\n* **4. Prediction and submission**\n    * 4.1 Predict and Submit results\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"5dc3e5c3-8d2d-4dfb-a252-cc33acb9d441","_uuid":"fc64877d5b5e85b5a82b7128a18723827e74afed"},"source":"# **1. Introduction**\n\nThis is a guide for Porto Seguroâ€™s Safe Driver Prediction dataset provided by Porto Seguro. Stratified KFold is used due to inbalance of the output variable. XGBoost is used because it is like the winning ticket for classification problem with formatted data. You can check its success on this link. ([XGBoost winning solutions](https://github.com/dmlc/xgboost/tree/master/demo#machine-learning-challenge-winning-solutions)) First, I will prepare the data (driver's information and whether the driver initiated auto insurance or not) then I will focus on prediction.\n\nFor more information on XGBoost, click this link.\n\n# [XGBoost](https://xgboost.readthedocs.io/en/latest/)\n","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"9dfa8b80-9a5d-4c92-ac17-18d678ac35b8","_uuid":"85cf8f32aa5179d80968b007537a08bdb781b28f"},"source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"5548f2d2-24cd-4244-8942-6a12ef644ce2","_uuid":"27c4a750327eea06ffc23584a3f50d2a987fce97"},"source":"# **2. Data Preparation**\n\n## **2.1 Load Data**","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"e2ad9237-bc88-42c6-b196-c38f01c695de","_uuid":"0882d3357aaaa908c395c52105bb7dcee7e2ddc0"},"source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"34003744-6c95-4c6c-aa28-b8cbafb9763a","_uuid":"69d820a6de3abaaaef9f9a52214b56b4f0b8b562"},"source":"## 2.2 Check for missing values(NaN)","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"8ed1fa51-df99-4f1a-a527-5a4972fd3fb8","_uuid":"438b925aa63456a43a92770c006e32a3e05d1afa"},"source":"train.isnull().values.any()","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"8b9b6de2-547e-43c4-a951-b46821bcf5ba","_uuid":"6b1e94988313676e547bbe91bca345d8e0494282"},"source":"## 2.3 Split features and targets from the data","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"03c4bc1f-f027-4236-b071-f48f40f73eb4","_uuid":"e8b870948bebb05ace4a93fd60bbb3d11ed0400f"},"source":"features = train.drop(['id','target'], axis=1).values\ntargets = train.target.values","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"3cee8906-5695-45c6-ac1e-ca664566b974","_uuid":"5e60b147bad75616f3a1fa8ef672109c155ad903"},"source":"## 2.3 Exploratory Visualization\n\n### Distribution of targets","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"9722b9dc-3a2b-4ab2-8393-728cc7713dc2","_uuid":"76a60dcde2c706ca25c3656c2f1e9bbf3e3f71e3"},"source":"ax = sns.countplot(x = targets ,palette=\"Set2\")\nsns.set(font_scale=1.5)\nax.set_xlabel(' ')\nax.set_ylabel(' ')\nfig = plt.gcf()\nfig.set_size_inches(10,5)\nax.set_ylim(top=700000)\nfor p in ax.patches:\n    ax.annotate('{:.2f}%'.format(100*p.get_height()/len(targets)), (p.get_x()+ 0.3, p.get_height()+10000))\n\nplt.title('Distribution of 595212 Targets')\nplt.xlabel('Initiation of Auto Insurance Claim Next Year')\nplt.ylabel('Frequency [%]')\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"e6e1534a-ca91-4bed-9f1d-5ec96c93be4a","_uuid":"cf662e4f087070515b1182714f6e7ff2cccc75c8"},"source":"### The plot shows that:\n- the target is imbalanced\n- high bias is expected to 0\n- class weight has to be balanced on training","cell_type":"markdown"},{"metadata":{"_cell_guid":"58399fd6-e51d-4c2f-8704-4360a72353b4","_uuid":"18201c4e652f627cf4dd511453d4ce5f28c1c40c"},"source":"### Correlation matrix","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"a6909cab-0a23-40ee-9232-135b492069b8","_uuid":"8499f27a16e180fea1f0da645faff27b068d688f"},"source":"sns.set(style=\"white\")\n\n\n# Compute the correlation matrix\ncorr = train.corr()\n\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"818c5984-d96b-409a-85b2-9c73e044ba33","_uuid":"ecd57eaf9bf43cdd39e15cac19d0f18632a5ee81"},"source":"### It can be seen that:\n - ps\\_calc\\_\\*  features are not related to target at all.\n - Removing them would prevent the curse of dimensionality.\n    \n    ","cell_type":"markdown"},{"metadata":{"_cell_guid":"85ddc994-8079-4ab2-bd7c-8e6d8bb2ee8d","_uuid":"589f6dce6891bc90768234de74378ac8991b5401"},"source":"# 3. Training/Predicting Pipeline","cell_type":"markdown"},{"metadata":{"_cell_guid":"3d69d105-834c-4617-a4a9-0f4fd1b7084f","_uuid":"f85faae208f051e6e9ea4997342a010f7c549dc2"},"source":"## 3.1 Define Gini Metric","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"6ec93bd8-13e4-456f-ba01-22aafa6762f6","_uuid":"2c1426791afedb9ffcd855e7cd022f13bd68e7b7"},"source":"# Define the gini metric - from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\ndef gini(actual, pred, cmpcol = 0, sortcol = 1):\n    assert( len(actual) == len(pred) )\n    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n    totalLosses = all[:,0].sum()\n    giniSum = all[:,0].cumsum().sum() / totalLosses\n    \n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\n \ndef gini_normalized(a, p):\n    return gini(a, p) / gini(a, a)\n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"8883d5bd-ca9c-4bcf-8aa4-42616779a18a","_uuid":"9104fc2d318e0327a94690b8074bfa6bbe5a46f9"},"source":"## 3.2 Drop Unnecessary Columns","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"39263bbf-d629-4f45-8837-3a667766c4c9","_uuid":"47659ac91791d5fdeadee74e0ab9114eb72a8c68"},"source":"unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"f490e9d2-721e-494c-a347-4562dc6e8945","_uuid":"01bdfa62d650b42c285e7923e6aa8f61299e2741"},"source":"train = train.drop(unwanted, axis=1)  \ntest = test.drop(unwanted, axis=1)  ","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"0b375f34-c95e-4608-83a7-62bca8a32909","_uuid":"558a2d9dd948b9adff47642db24e565f6643960c"},"source":"## 3.3 Stratified KFold\n\nStratified KFold is used to keep the distribution of each label consistent for each training batch.","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"22aaab23-4619-4ba3-80d0-570ac3202bd5","_uuid":"98f27176654074475122a1b3db38af22b27a4e6d"},"source":"kfold = 5\nskf = StratifiedKFold(n_splits=kfold, random_state=42)","cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b26126e2-07b2-471a-9085-90ee0540835c","_uuid":"aeb605939f52a99c84651774230055ed9bde3648"},"source":"## 3.4. XGBoost","cell_type":"markdown"},{"metadata":{"_cell_guid":"3727c428-54c1-4b78-8b8e-a70771ee3e8e","_uuid":"dcc634ead12543bbb6210bf832d33c5fdadb01c6"},"source":"### Set parameters","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"b2260320-aeec-45c2-a6b0-2460b56f3103","_uuid":"eee28d25a4b4b7a5a4936c77797744cd21b4feba"},"source":"params = {\n        '''\n        Good luck with parameter tuning\n        '''\n        }","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"76899112-fc99-4f6f-9c79-b2177946c711","_uuid":"fbf74bdcf41280d2144e906ebfdc4bf544a9eada"},"source":"# 4.  Prediction and submission","cell_type":"markdown"},{"metadata":{"_cell_guid":"f9d5b2fe-ff33-4f19-aa03-c56ed691cb81","_uuid":"e3a947464778d8a4ef3dfbcf41ef5e731bcefcd9"},"source":"## 4.1. Predict and Submit results","cell_type":"markdown"},{"metadata":{"_cell_guid":"1bf957f5-5d71-48c4-a667-5bed7eae17f8","_uuid":"104e8c5da3aeee8e404284cdb31e6cbb401a560f"},"source":"### Define X and y","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"e36cad63-66df-4209-9ff0-20a488159e06","_uuid":"1a842f3b72c03fbf0e49e78258def00c13bcff2c"},"source":"X = train.drop(['id', 'target'], axis=1).values\ny = train.target.values\ntest_id = test.id.values\ntest = test.drop('id', axis=1)","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"99d02884-ee04-4cec-93c3-bc2bcd265f17","_uuid":"39075f331377b0ed98c68a4fa4a2247bc74353ae"},"source":"### Create a submission file","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"a1e5d0c6-bd69-4dd3-bf77-a9e71897d854","_uuid":"6fd4e0417fc825ca0aa7a8d3c0f240e814d3585c"},"source":"sub = pd.DataFrame()\nsub['id'] = test_id\nsub['target'] = np.zeros_like(test_id)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"scrolled":false,"collapsed":true,"_cell_guid":"111c004f-df7c-4b8e-8d20-7c1fb4e9af59","_uuid":"cc2dd2cb0ca4acabe81a1e2313e21bfac8671dae"},"source":"for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n    print('[Fold %d/%d]' % (i + 1, kfold))\n    X_train, X_valid = X[train_index], X[test_index]\n    y_train, y_valid = y[train_index], y[test_index]\n    # Convert our data into XGBoost format\n    d_train = xgb.DMatrix(X_train, y_train)\n    d_valid = xgb.DMatrix(X_valid, y_valid)\n    d_test = xgb.DMatrix(test.values)\n    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\n    # Train the model! We pass in a max of 2,000 rounds (with early stopping after 100)\n    # and the custom metric (maximize=True tells xgb that higher metric is better)\n    mdl = xgb.train(params, d_train, 1600, watchlist, early_stopping_rounds=70, feval=gini_xgb, maximize=True, verbose_eval=100)\n\n    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n    # Predict on our test data\n    p_test = mdl.predict(d_test)\n    sub['target'] += p_test/kfold","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"bdc1a0b6-30d3-4eea-85c1-2be38a0c84ad","_uuid":"6a702330943a9b96732b978bfd18693a3f88e3c5"},"source":"### Put submission to csv file","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"8df72cf4-9e4e-4135-88ac-1cf19d4d69c8","_uuid":"c9a622eae062317ac1eee0be3029d42929d1b25c"},"source":"sub.to_csv('StratifiedKFold.csv', index=False)","cell_type":"code","outputs":[]}],"nbformat_minor":1,"nbformat":4}