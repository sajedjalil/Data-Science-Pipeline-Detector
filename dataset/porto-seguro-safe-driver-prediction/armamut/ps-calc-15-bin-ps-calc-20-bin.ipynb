{"cells":[{"source":"Almost everybody seems to drop features `'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin'` in their kernels. \n\nAt first, it seems logical to do this, as xgb.booster feature importances are low. But let's look, if we can find any structure in them.","cell_type":"markdown","metadata":{"_cell_guid":"d2ab1560-2785-4128-b716-94ec51c03f74","_uuid":"50f60f96a6db5ad2b522d56aa8493f3fc338b20b"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_uuid":"c4a0a25c316fc7e69be4eec4e4cccaf9e407c1e6","_kg_hide-output":false,"_cell_guid":"8fb8b329-0083-49e6-a467-2125db783195","_kg_hide-input":false},"source":"# Load standard libraries\n\nimport numpy as np\nRANDOM_SEED = 1337\nnp.random.seed(RANDOM_SEED)\nimport pandas as pd\npd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', 70)\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\npy.init_notebook_mode()\n\n%time df_train = pd.read_csv('../input/train.csv', na_values=-1)\n\nprint('Loaded data and libraries.')"},{"source":"I first assumed that these features are some kind of encoded (one-hot, binary, etc.). As I looked through the data, I see they are not one-hot, because there are more than one 1's in the same row.\n\nLet's assume, they are binary encoded integers from a categorical value from 0 to 63 (as there are 6 columns, 2**6 = 64). Let's count some stats on these categories.","cell_type":"markdown","metadata":{"_cell_guid":"543baeff-3861-4f82-aff1-8c293502f052","_uuid":"6aaa4c22ce8cea6e8dd526fa0edd1f059a04e614"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"b5e4ba37-0d2e-4a06-ade7-24dcaf73aecb","_uuid":"b3fb340cb60635104bc5b0047880bb1449da3ddd"},"source":"cols = ['ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin',\n        'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin']\n\ngroupped = df_train.groupby(cols)['target'].agg(['sum', 'count', 'mean']).reset_index()\ngroupped"},{"source":"If we plot count and sum columns, we can clearly see a pattern here.","cell_type":"markdown","metadata":{"_cell_guid":"549957e8-6c5f-423e-b888-b89915654264","_uuid":"40c8ef04ac378d4c4903c155bd318948b37a13a2"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"20355df3-1a35-4dbc-a470-7d31f252877f","_uuid":"da0074a52293ec1ea045c7f4d57ae46c0c7bf9d6"},"source":"py.iplot([go.Scatter(y=groupped['count'])])\npy.iplot([go.Scatter(y=groupped['sum'])])\npy.iplot([go.Scatter(y=groupped['mean'])])"},{"source":"If we look at first two chart, there are jumps on multiples of 2 and 8. And, first half of the chart is on average greater than second half. The jumps seem to be related to our binary features.\n\nWe'll now sort these graphs as if they were smooth and try to find a pattern in permutation of binary representaton. First, calculate a category number from these bin features.","cell_type":"markdown","metadata":{"_cell_guid":"a0b1765a-e713-415a-bcfd-ee4a67b64219","_uuid":"d905fc69367faf3334c1d786907b499ae6f020b5"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"d97a5ac0-8b7d-472e-acf0-452cb7416af9","_uuid":"d3c09d99a31a66aa0dd523e1ac8b5a2d00550807"},"source":"groupped['ps_calc_15_to_20']  = groupped['ps_calc_15_bin']*32 + groupped['ps_calc_16_bin']*16\ngroupped['ps_calc_15_to_20'] += groupped['ps_calc_17_bin']*8  + groupped['ps_calc_18_bin']*4\ngroupped['ps_calc_15_to_20'] += groupped['ps_calc_19_bin']*2  + groupped['ps_calc_20_bin']*1\ngroupped['ps_calc_15_to_20'].astype(np.uint8, inplace=True)\ngroupped"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"2c5fec69-6427-4197-a6b5-173a3a207a55","_uuid":"f578637cf85c447c5f55dad03a4cc08d9a6f0473"},"source":"groupped = groupped.sort_values(by='count', ascending=False).reset_index()\ngroupped = groupped.drop('index', axis=1)\ngroupped"},{"source":"Now we draw them on a chord chart. The symmetry in the graph is clearly visible.","cell_type":"markdown","metadata":{"_cell_guid":"edf84cf7-80f8-41a2-bef0-89950f039424","_uuid":"6cb7d6296f0bde0b8a1d914685cdfb5eeafa3fbb"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"ec75c22f-d94e-42aa-87b2-2e61715b63c4","_uuid":"476c99484ac232de930fcb9eaae0821024dadc80"},"source":"# Draw Chord Graph\ndots = groupped['ps_calc_15_to_20'].copy()\nn = 64.0\n# Dots start at 12 o'clock, and rotates clockwise.\nx = np.sin((dots+0.5)/n*2*np.pi)\ny = np.cos((dots+0.5)/n*2*np.pi)\nedges = list(zip(x,y))\ndata = [go.Scattergl(\n    x=x,\n    y=y,\n    text=['Dot %d'%c for c in dots],\n    mode='lines+markers',\n    marker={\n        'color':'rgb(30,30,30)',\n        'size':5\n    },\n    line={\n        'color':'rgba(46, 147, 219, 0.5)',\n        'width':5\n    },\n    hoverinfo='text'\n)]\nlayout = go.Layout(autosize=False, width=500, height=500, showlegend=False)\npy.iplot(go.Figure(data=data, layout=layout))"},{"source":"Now let's stop here. I spent almost a day trying to figure out what this permutation might be. I've looked at cyclic groups, huffman codes, balanced gray codes, searched at OEIS etc. Then my brain stopped and I gave up! :)\n\nIt is what it is. Let's forget about the generation process and use it.\n\nI noticed that the sum of the first and last indices after this sort operation is 63. This as a consequence of this symmetry situation. They may have first scrambled the 64 bin's indexes, then generated binary encoded features from that index. Whatever... Let's go on.","cell_type":"markdown","metadata":{"_cell_guid":"a5c34887-ba81-4343-9f78-78d08eddb104","_uuid":"0a4650a0fbe8d878b437c69abbc118916a7abf54"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"847ae85c-b414-4639-9c1a-e97bc9ccf125","_uuid":"381a84cf7fe87bd9b30abe6f22a25f4a95986cc6"},"source":"dots = pd.DataFrame(dots)\ndots['ps_calc_15_to_20_reversed'] = dots['ps_calc_15_to_20'].iloc[::-1].values\ndots['sum_of_them'] = dots['ps_calc_15_to_20'] + dots['ps_calc_15_to_20_reversed']\ndots"},{"source":"We see that there are some rows which sum is not equal to 63. As I said, they may have generated these by a rule (which I don't know yet) and we can fix our ordering according to this rule.","cell_type":"markdown","metadata":{"_cell_guid":"8dcf6388-090b-4238-811c-a78fc7a497f1","_uuid":"2525d675e03952ef6690a12cf9da5963846c47cc"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"bf1e6f0f-3f8c-4b41-adfd-8c98f9b7d2a4","_uuid":"294a894f869367db1955b3404870cb251c881079"},"source":"dots[dots['sum_of_them']!=63]"},{"source":"If we switch rows 4-5 and 12-13, we'll have a nice pattern structure again.","cell_type":"markdown","metadata":{"_cell_guid":"f3b17d0b-2ed8-4415-aeb0-22a064209f79","_uuid":"6c967c2c3f7f8ca4f1842e889042d43ede5974f5"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"e5edc84f-135c-429b-b19a-63127019d450","_uuid":"ccb1ff27f73c0a4c7c258b2ce813b49790d40fc1"},"source":"new_index = list(range(4)) + [5,4] + list(range(6,12)) + [13,12] + list(range(14,64))\n#new_index += [51,50] + list(range(52,58)) + [59,58] + list(range(60,64))\nprint(len(new_index))\nnp.array(new_index) # used np.array to display the list nicer."},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"1db384c5-2310-4cb4-85fb-33e348cdff40","_uuid":"4a590b07b2b02e77e094679c213813624bf14545"},"source":"dots2 = dots.copy()\ndots2 = dots2.reindex(index=new_index).reset_index(drop=True)\ndots2['ps_calc_15_to_20_reversed'] = dots2['ps_calc_15_to_20'].iloc[::-1].values\ndots2['sum_of_them'] = dots2['ps_calc_15_to_20'] + dots2['ps_calc_15_to_20_reversed']\n\ndots2"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"a0821918-8e5c-4365-bc90-d9308c19fb94","_uuid":"0bb66309c3a4bae5b1a5f9019e803fdfb4bf3cc9"},"source":"dots2[dots2['sum_of_them']!=63]"},{"source":"Now we think we have a nice permutation of 0..63. Let's switch row 4-5 and 12-13 in first table and see if our graphs changed somehow.","cell_type":"markdown","metadata":{"_cell_guid":"235a63b9-9292-406c-904e-16e05ab4bc0a","_uuid":"acfc2f0a1ea4fe1f506c99bac64ab5c138f0d49e"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"a9b90757-4fea-4fa4-a3c4-d1f256f7ed1b","_uuid":"fd24e1c5c35160fa9d8ed3d09bdd37b409d0f57a"},"source":"groupped = groupped.reindex(index=new_index).reset_index(drop=True)\ngroupped"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"40028f6d-3f5f-4aae-ab23-4636a1a775d8","_uuid":"71d6a374d937dc3b0730bd44882053d261ed8117"},"source":"py.iplot([go.Scatter(y=groupped['count'])])\npy.iplot([go.Scatter(y=groupped['sum'])])\npy.iplot([go.Scatter(y=groupped['mean'])])"},{"source":"That looks better and a little bit meaningfull now.\n\nIn summary, if you want to use this feature in your model, use:","cell_type":"markdown","metadata":{"_cell_guid":"5183a9dc-d3f3-4e75-9bdc-24a6b607e02a","_uuid":"41e2a519a15f9dd2870fccb59a53293b5709a9f5"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"036598b8-78f8-4b70-ba73-7a0e0865941d","collapsed":true,"_uuid":"a0624fccbff35e9bdc988c24599352889c82e898"},"source":"# Columns -> binary decoded.\n\ntmp  = df_train['ps_calc_15_bin'] * 32 + df_train['ps_calc_16_bin'] * 16 + df_train['ps_calc_17_bin'] * 8\ntmp += df_train['ps_calc_18_bin'] * 4 + df_train['ps_calc_19_bin'] * 2 + df_train['ps_calc_20_bin'] * 1\n\ntmp2 = [5, 22, 9, 32, 13, 38, 20, 47, 2, 19, 8, 30, 10, 35, 17, 45, 1,\n        15, 4, 24, 7, 29, 14, 40, 0, 12, 3, 21, 6, 26, 11, 36, 27, 52,\n        37, 57, 42, 60, 51, 63, 23, 49, 34, 56, 39, 59, 48, 62, 18, 46,\n        28, 53, 33, 55, 44, 61, 16, 43, 25, 50, 31, 54, 41, 58]\ntmp2 = pd.Series(tmp2)\n\ndf_train['ps_calc_15_16_17_18_19_20'] = tmp.map(tmp2)\n\n# You may now drop the others peacefully.\n#df_train.drop(['ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin',\n#               'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin'], axis=1, inplace=True)"},{"source":"Or use this, if you want to overfit a little bit :)","cell_type":"markdown","metadata":{"_cell_guid":"15dfb9a5-9924-4c0f-9909-720234c1f920","_uuid":"b500134be19670f87c9bfcf074bbd0c2b3db978f"}},{"source":"Please, feel free to comment below. Especially, if you have any idea about the permutation method they have used, it would be appreciated.\n\nAnd, please comment how much improvement did it make in your model.\n\nThank you!","cell_type":"markdown","metadata":{"_cell_guid":"f0afdd0e-c531-4497-9da0-1104c12f40cd","_uuid":"59f2749ef1997b5b560dd5bfce52570383272308"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"4365a24f-449d-487d-8e5b-7d4a5ef393d2","collapsed":true,"_uuid":"a0f157820a14691c1e4b14885f2205ac56afb64f"},"source":""}],"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.3","name":"python"}},"nbformat_minor":1}