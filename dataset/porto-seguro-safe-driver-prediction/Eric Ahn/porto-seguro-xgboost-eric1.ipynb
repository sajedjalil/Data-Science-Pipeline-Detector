{"cells":[{"metadata":{"_uuid":"663762d0acd501a442290010ddc25eaea219ff13","_cell_guid":"ecf01439-91f9-40c2-90ca-cfc9fef897f9"},"cell_type":"markdown","source":"Based on [olivier's script](https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283)"},{"metadata":{"_uuid":"dbd332f83c89108c4e641218f5c4e7b9cd325b80","collapsed":true,"_cell_guid":"45ba73d4-6c4c-40bb-9390-7dfc956c555d","trusted":false},"cell_type":"code","source":"MAX_ROUNDS = 400\nOPTIMIZE_ROUNDS = False\nLEARNING_RATE = 0.07\nEARLY_STOPPING_ROUNDS = 50  \n# Note: I set EARLY_STOPPING_ROUNDS high so that (when OPTIMIZE_ROUNDS is set)\n#       I will get lots of information to make my own judgment.  You should probably\n#       reduce EARLY_STOPPING_ROUNDS if you want to do actual early stopping.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b277fe426336d65ac71f0e6ac96c7ee16d02074c","_cell_guid":"7e199c98-16b0-45e7-a6d1-bdd9325c2631"},"cell_type":"markdown","source":"I recommend initially setting <code>MAX_ROUNDS</code> fairly high and using <code>OPTIMIZE_ROUNDS</code> to get an idea of the appropriate number of rounds (which, in my judgment, should be close to the maximum value of  <code>best_ntree_limit</code> among all folds, maybe even a bit higher if your model is adequately regularized...or alternatively, you could set <code>verbose=True</code> and look at the details to try to find a number of rounds that works well for all folds).  Then I would turn off <code>OPTIMIZE_ROUNDS</code> and set <code>MAX_ROUNDS</code> to the appropraite number of total rounds.  \n\nThe problem with \"early stopping\" by choosing the best round for each fold is that it overfits to the validation data.    It's therefore liable not to produce the optimal model for predicting test data, and if it's used to produce validation data for stacking/ensembling with other models, it would cause this one to have too much weight in the ensemble.  Another possibility (and the default for XGBoost, it seems) is to use the round where the early stop actually happens (with the lag that verifies lack of improvement) rather than the best round.  That solves the overfitting problem (provided the lag is long enough), but so far it doesn't seem to have helped.  (I got a worse validation score with 20-round early stopping per fold than with a constant number of rounds for all folds, so the early stopping actually seemed to underfit.)\n"},{"metadata":{"_uuid":"72171ee53e170096d37a18eef84682fa348ae5c4","collapsed":true,"_cell_guid":"b7258128-55f9-4543-8611-5e0a6661837b","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom numba import jit\nimport time\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"154b078a7e86c0a5a328118a61d28e2581bb3b0a","collapsed":true,"_cell_guid":"3d16f16e-12cc-4b41-b7bd-fa05ce44770c","trusted":false},"cell_type":"code","source":"# Compute gini\n\n# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n@jit\ndef eval_gini(y_true, y_prob):\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    ntrue = 0\n    gini = 0\n    delta = 0\n    n = len(y_true)\n    for i in range(n-1, -1, -1):\n        y_i = y_true[i]\n        ntrue += y_i\n        gini += y_i * delta\n        delta += 1 - y_i\n    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n    return gini","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67a8ca9dead7110c776d7f75bb8963b3429617cb","collapsed":true,"_cell_guid":"99b88ea4-a9af-45aa-9df0-86412d7264cf","trusted":false},"cell_type":"code","source":"# Funcitons from olivier's kernel\n# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = -eval_gini(labels, preds)\n    return [('gini', gini_score)]\n\n\ndef add_noise(series, noise_level):\n    return series * (1 + noise_level * np.random.randn(len(series)))\n\n\ndef target_encode(trn_series=None,    # Revised to encode validation series\n                  val_series=None,\n                  tst_series=None,\n                  target=None,\n                  min_samples_leaf=1,\n                  smoothing=1,\n                  noise_level=0):\n    \"\"\"\n    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n    trn_series : training categorical feature as a pd.Series\n    tst_series : test categorical feature as a pd.Series\n    target : target data as a pd.Series\n    min_samples_leaf (int) : minimum samples to take category average into account\n    smoothing (int) : smoothing effect to balance categorical average vs prior\n    \"\"\"\n    assert len(trn_series) == len(target)\n    assert trn_series.name == tst_series.name\n    temp = pd.concat([trn_series, target], axis=1)\n    # Compute target mean\n    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n    # Compute smoothing\n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n    # Apply average function to all target data\n    prior = target.mean()\n    # The bigger the count the less full_avg is taken into account\n    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n    # Apply averages to trn and tst series\n    ft_trn_series = pd.merge(\n        trn_series.to_frame(trn_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=trn_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_trn_series.index = trn_series.index\n    ft_val_series = pd.merge(\n        val_series.to_frame(val_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=val_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_val_series.index = val_series.index\n    ft_tst_series = pd.merge(\n        tst_series.to_frame(tst_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=tst_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_tst_series.index = tst_series.index\n    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07a5a5782894611e9006ae1b399b0b8fb8a0f06b","collapsed":true,"_cell_guid":"52b50086-b405-4598-b11c-97887cdcce8e","trusted":false},"cell_type":"code","source":"# Read data\ntrain_df = pd.read_csv('../input/train.csv', na_values=\"-1\") # .iloc[0:200,:]\ntest_df = pd.read_csv('../input/test.csv', na_values=\"-1\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ac19052e2f2c14d79962af5e5a8ee3d54a28695","collapsed":true,"_cell_guid":"b9e041d2-18fb-4a8a-8bb4-577e8993189b","trusted":false},"cell_type":"code","source":"# from olivier\ntrain_features = [\n    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n]\n# add combinations\ncombs = [\n    ('ps_reg_01', 'ps_car_02_cat'),  \n    ('ps_reg_01', 'ps_car_04_cat'),\n]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da09aaf7c0c77a131c7d9d53feae512c8f9730c1","collapsed":true,"_cell_guid":"d9a217fa-50f4-43a7-805b-d1c796a7ebf7","trusted":false},"cell_type":"code","source":"# Process data\nid_test = test_df['id'].values\nid_train = train_df['id'].values\ny = train_df['target']\n\nstart = time.time()\nfor n_c, (f1, f2) in enumerate(combs):\n    name1 = f1 + \"_plus_\" + f2\n    print('current feature %60s %4d in %5.1f'\n          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n    print('\\r' * 75, end='')\n    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n    # Label Encode\n    lbl = LabelEncoder()\n    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n    train_df[name1] = lbl.transform(list(train_df[name1].values))\n    test_df[name1] = lbl.transform(list(test_df[name1].values))\n\n    train_features.append(name1)\n    \nX = train_df[train_features]\ntest_df = test_df[train_features]\n\nf_cats = [f for f in X.columns if \"_cat\" in f]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6255e3c12616b0279cef5c1bdec97751bb72d8b8","collapsed":true,"_cell_guid":"1b36eb15-ee01-43a3-8766-27650f98158d","trusted":false},"cell_type":"code","source":"y_valid_pred = 0*y\ny_test_pred = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6aa7ada2193c2e4b8a63eebda925cee5023b45b0","collapsed":true,"_cell_guid":"7c6e4823-4e8c-4408-b961-576d469e9241","trusted":false},"cell_type":"code","source":"# Set up folds\nK = 5\nkf = KFold(n_splits = K, random_state = 1, shuffle = True)\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"581c3f15f294378a0e2ac3305e9e3d375f664b21","collapsed":true,"_cell_guid":"5d8108f3-e9e8-45d6-93b5-740eb7b4b10b","trusted":false},"cell_type":"code","source":"# Set up classifier\nmodel = XGBClassifier(    \n                        n_estimators=MAX_ROUNDS,\n                        max_depth=4,\n                        objective=\"binary:logistic\",\n                        learning_rate=LEARNING_RATE, \n                        subsample=.8,\n                        min_child_weight=6,\n                        colsample_bytree=.8,\n                        scale_pos_weight=1.6,\n                        gamma=10,\n                        reg_alpha=8,\n                        reg_lambda=1.3,\n                     )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b9ed96c98b705d3e4bf2a3d60323dfab4332674","scrolled":true,"collapsed":true,"_cell_guid":"c4e48347-920f-4ba7-8b37-cfbaab4c3c00","trusted":false},"cell_type":"code","source":"# Run CV\n\nfor i, (train_index, test_index) in enumerate(kf.split(train_df)):\n    \n    # Create data for this fold\n    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n    X_test = test_df.copy()\n    print( \"\\nFold \", i)\n    \n    # Enocode data\n    for f in f_cats:\n        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n                                                        trn_series=X_train[f],\n                                                        val_series=X_valid[f],\n                                                        tst_series=X_test[f],\n                                                        target=y_train,\n                                                        min_samples_leaf=200,\n                                                        smoothing=10,\n                                                        noise_level=0\n                                                        )\n    # Run model for this fold\n    if OPTIMIZE_ROUNDS:\n        eval_set=[(X_valid,y_valid)]\n        fit_model = model.fit( X_train, y_train, \n                               eval_set=eval_set,\n                               eval_metric=gini_xgb,\n                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                               verbose=False\n                             )\n        print( \"  Best N trees = \", model.best_ntree_limit )\n        print( \"  Best gini = \", model.best_score )\n    else:\n        fit_model = model.fit( X_train, y_train )\n        \n    # Generate validation predictions for this fold\n    pred = fit_model.predict_proba(X_valid)[:,1]\n    print( \"  Gini = \", eval_gini(y_valid, pred) )\n    y_valid_pred.iloc[test_index] = pred\n    \n    # Accumulate test set predictions\n    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n    \n    del X_test, X_train, X_valid, y_train\n    \ny_test_pred /= K  # Average test set predictions\n\nprint( \"\\nGini for full training set:\" )\neval_gini(y, y_valid_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e61bf4e22c1c29c8358caeecb6e67d6658f2005d","collapsed":true,"_cell_guid":"0e3dfd76-c566-4b8d-a460-b56e964d0772","trusted":false},"cell_type":"code","source":"# Save validation predictions for stacking/ensembling\nval = pd.DataFrame()\nval['id'] = id_train\nval['target'] = y_valid_pred.values\nval.to_csv('xgb_valid.csv', float_format='%.6f', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"380fc8053d00cd8bb2796bfd2b59d10cbc4ce7e1","collapsed":true,"_cell_guid":"f4cbef2c-e52b-4afb-b8ef-904ee9b5f9d5","trusted":false},"cell_type":"code","source":"# Create submission file\nsub = pd.DataFrame()\nsub['id'] = id_test\nsub['target'] = y_test_pred\nsub.to_csv('xgb_submit.csv', float_format='%.6f', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5401495c2c34ef736c761573c70d7e3b4efa3a5b","_cell_guid":"77516718-78a9-4043-8b4b-0b04276e4345"},"cell_type":"markdown","source":"Notes:<br>\nversion 16. Baseline best CV=.2832, LB=.282<br>\nversion 15. Ntree optimization for baseline<br>\nversion 21. Verbose version of baseline optimization<br>\nversion 22. Baseline + per-fold early stopping after 20 rounds<br>\nversion 23. Back to baseline.<br>\nversion 24. Some parameter tuning.<br>\nversion 25. Re-published to make it visible.<br>\nversion 26. A little more tuning.<br>\nversion 27: More tuning, get rid of upsampling (using  **<code>scale_pos_weight</code>** instead),<br>\n                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n                    Set <code>OPTIMIZE_ROUNDS</code> and <code>verbose</code> temporarily<br>\nversion 28: <code>MAX_ROUNDS=300</code> as a compromise<br>\nversion 29: Substantively identical. (Turn off now-irrelevant <code>verbose</code>.)<br>\nversion 30: Still substantively identical. Some visual cleanup.<br>\nversion 35. More tuning. CV went up but LB sorts lower (still .283)<br>\nversion 36. Identical (except turn off irrelevant <code>verbose</code>). Republished to make it visible.<br>\nversions 37-42. More tuning (gamma=10, alpha=8). LB .284 (\\*end zone dance\\*).<br>\nversion 43. More tuning (min_child_weight=6).  LB score has considerably improved according to sort, but still .284"},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.6.3","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}