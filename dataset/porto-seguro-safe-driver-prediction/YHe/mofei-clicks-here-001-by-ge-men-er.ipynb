{"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"adae1c914e550e06b2625e30f869d89d7fd56658","_cell_guid":"8c9c7b2e-aaa7-486d-9856-87b10c268d03"},"source":"**Ge men er:**\n\nI was trying to open these file by excel, that's silly and never work out LOL\n\nAll right, here is the problem. We need to predict** if a driver will file an insurance claim next year**. The train data file has 59 columns, 595212 rows; the test data file has 58 columns, and 892816 rows; and the sample_submission file has 2 columns and 892816 rows.\n\nThe only different column between train and test is 'target' column. The 2 columns in submission are id and target. These id in train and test has no overlap. \n \n Ge Men er, **please** continue reading and feel free to **add comments**."},{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for drawing plot graph\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code","execution_count":null,"metadata":{"trusted":true,"_uuid":"4b6293fdc6cac2070cc27f482865fd317abb9695","_cell_guid":"515c7d9e-8bdf-48aa-b14e-27b4bfd4f31a"},"outputs":[]},{"source":"#input the train set and test set\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":true,"_uuid":"46db1793d0c0b457b15586d0875ca26277db1e67","_cell_guid":"16bbf0c2-663e-44f4-91f2-2d1d1f026ad3"},"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"53647e50e8bdb8ab6f877285926d3c9b6db1fdc1","_cell_guid":"e31e730e-b33d-43fb-86cf-1bb75d070958"},"source":"**Q1: What's the meaning of target?**\n\n\n**MF Answer: ** I guess they want us to predict the probability of whether or not a claim was filed for the driver, so it should be in the range of [0,1]. \n\nBecause I'm not sure if the target value could be 0.3, 0.8 or even 0.5. I made the plot gragh. The above graph shows the target value in train data file are either 1 or 0. Uh-Oh:(\n\nBut, in the sample_submission file, they have all the target value as 0.0364. Do you think it's a hint for us, the value could be any REAL value between [0,1]? \nOr we just rougly tend to think every driver's skill is as bad as YANG LAO SHI's. Thus, when target value less or equal than 0.5, we would give a piecewise to make it equals to 0 and elsewhere equals to 1.\n\nI also find a smiliar discussion on https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/40222\n, please search rkoptelov or Daniel Moller.\n\n>>**HY Answer:** You can write anything here, such as agree:) Seriously, we can see the precentage of 0 and 1 are very different, probably 9:1. Do you think 0 means having a claim or not? Or it doesn't matter??? But how could that work?!\n\n**Q2: What's the meaning of the other columns?**\n\nWe observed the column name is a combination of three or four parts, the fourth part(if has) could be cat or bin.\n\nI find this answer from the** data description**. \n\n2.1  In the train and test data, features that belong to similar groupings are tagged as such in the feature names (e.g., ind, reg, car, calc). \n\n2.2 In addition, feature names include the postfix** bin to indicate binary features and cat to indicate categorical features**.\n\n2.3  **Features without these designations are either continuous or ordinal**. Values of **-1** indicate that the feature was **missing** from the observation. \n\n>>Do you think we can do more in this part to understand features better, such as same first two parts, compute coefficient or we will compute each two anyhow. "},{"cell_type":"markdown","metadata":{"_uuid":"2d32a11b5934aa0261374379e785ad07435602b2","_cell_guid":"a91fd6f6-bb0e-4eab-a4b6-e5b19881a163"},"source":"**Ge men er:**\n\nSeriously,I agree with most of your points : ).Here is mine:\n\nFor train set, it is proper that the target values 0 or 1. The 0 means a driver will not initiate an auto insurance claim in the next year, And 1 means the opposite situation. For test set, we should give the probability that a driver will initiate an auto insurance claim in the next year.  We will order the user by probability and only the order counts. \n\nThe models based on GBDT can predict the probability that the sample is classified to 1. \n\nIf we use the xgboost or lightgbm, the coefficients between features can not influence our result. The missing data is fine for our model.\n\nWe don't know what the featrues represent. I think the only thing we can do is just dummies the category features, But I am worry about this rude method. We can do it by this method , check the result and think other method later.\n\nThe step of this question:\n\n1) dummies the category features\n\n2) check the features without the designations ,   continuous  or  category\n\n3) put them into model Violently\n\nFinally, try our best to fingure out the meanings of features.\n\nTo humor Mofei"},{"source":"#for every category feature,check the number of different value and make sure the number is less than 10(10 is my\n#own advice,we can change this value later).\ntrain_col = list(train_df.columns)\nfor col in train_col:\n    if col[-3:] == 'cat':\n        values = train_df[col]\n        if len(set(values)) > 10:\n            print(col,len(set(values)))\n# view the result, 'ps_car_11_cat' can't get dummies directly","cell_type":"code","execution_count":null,"metadata":{"trusted":true,"_uuid":"a27de866a2335d5cbfaac92490d99ab2bed40a4a","_cell_guid":"f9aaa88e-f277-422d-b36f-81109624dcff"},"outputs":[]},{"source":"#check every features  category or continuous\nConVar = []\nfor col in train_col:\n    values = train_df[col]\n    if len(set(values)) > 30:\n        ConVar.append(col)","cell_type":"code","execution_count":null,"metadata":{"trusted":true,"_uuid":"6b969cafc932c17ed83d229243057cb5e62a3299","_cell_guid":"5fa71e2f-a2e5-40fa-acf0-8106420c3794"},"outputs":[]},{"source":"for col in ConVar:\n    print(col,len(set(train_df[col])))","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d370803e-57d3-4fcd-9421-166b018a2a56","trusted":true,"_uuid":"53bb29976c0680fe537e1b6c728e19f64d1c165c","scrolled":true},"outputs":[]},{"source":"missvar = []\ndis = len(train_df)\nfor col in train_col:\n    values = train_df[col]\n    miss = [-1 for x in values if x == -1]\n    if len(miss)/dis > 0.5:\n        print(len(miss))\n        missvar.append(col)","cell_type":"code","execution_count":null,"metadata":{"trusted":true,"_uuid":"4481a3217ebf14406eff6d48203219e32854e525","_cell_guid":"924b3e22-463e-4fa5-b63a-7c769e18e7bf"},"outputs":[]},{"source":"values = train_df[missvar[0]]\nvalues_ide = list(set(values))\nprint(values_ide)\nprint(missvar,len(set(values)),len(values))","cell_type":"code","execution_count":null,"metadata":{"trusted":true,"_uuid":"619356ed39b6fc3484be0e7b9ececbb609835dcc","_cell_guid":"69014c4a-4de0-410c-b9c4-cfe7ffbe47f0"},"outputs":[]},{"source":"","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":true,"_uuid":"ff438ba6dac073c3c67a351d839e9272fdf4682f","_cell_guid":"c09fda39-b179-4ac1-be18-318fcb3410c9"},"outputs":[]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.6.3","pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","name":"python"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1}