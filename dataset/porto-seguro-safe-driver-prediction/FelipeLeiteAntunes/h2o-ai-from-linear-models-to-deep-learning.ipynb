{"nbformat":4,"metadata":{"varInspector":{"cols":{"lenName":16,"lenVar":40,"lenType":16},"window_display":false,"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"kernels_config":{"r":{"library":"var_list.r","delete_cmd_prefix":"rm(","varRefreshCmd":"cat(var_dic_list()) ","delete_cmd_postfix":") "},"python":{"library":"var_list.py","delete_cmd_prefix":"del ","varRefreshCmd":"print(var_dic_list())","delete_cmd_postfix":""}}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","version":"3.6.3","name":"python"},"celltoolbar":"Initialization Cell","toc":{"toc_section_display":"block","skip_h1_title":false,"toc_window_display":false,"toc_cell":false,"number_sections":true,"nav_menu":{},"sideBar":true,"toc_position":{}}},"nbformat_minor":1,"cells":[{"source":"# Porto Seguroâ€™s Safe Driver Prediction: H2O.ai\n","metadata":{"_uuid":"54efe415e28ed200214c38db2664cebffadd8962","_cell_guid":"3530b75f-fc03-412e-854b-2f15a85a9ee1"},"cell_type":"markdown"},{"source":"In this competition, you will predict the probability that an auto insurance policy holder files a claim.\nIn the train and test data, features that belong to similar groupings are tagged as such in the feature names (e.g., ind, reg, car, calc). In addition, feature names include the postfix bin to indicate binary features and cat to indicate categorical features. Features without these designations are either continuous or ordinal. Values of -1 indicate that the feature was missing from the observation. The target columns signifies whether or not a claim was filed for that policy holder.","metadata":{"_uuid":"4a410faa3a309adda6bff0828e3d298afb549690","_cell_guid":"eb1b537b-380f-4c3e-ad42-1858e6ebbdf0"},"cell_type":"markdown"},{"source":"## Initializing H2O","metadata":{"_uuid":"34f9ab22b9bfae2aa95cfa6a4cda0a8d5874d76b","_cell_guid":"431f997c-7674-4212-879d-2a7841cb11c2"},"cell_type":"markdown"},{"source":"# Load the H2O library and start up the H2O cluter locally on your machine\nimport h2o\nh2o.init(ip=\"localhost\", port=54323)","outputs":[],"metadata":{"_uuid":"80909cc8055787fba5e511606dbfd72c52b022b6","scrolled":false,"ExecuteTime":{"start_time":"2017-10-07T19:18:48.365726Z","end_time":"2017-10-07T19:18:48.446441Z"},"_cell_guid":"2a17f285-7efe-4999-812b-763be1e25020","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"### Importing Libs","metadata":{"_uuid":"0effd87be866639f8ba9a86efdbf40b6ac5ac82e","_cell_guid":"f6c576c2-4c09-4eda-9765-c27c91dc02f0"},"cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np","outputs":[],"metadata":{"_uuid":"1fbce677a56ddfd27e9250eafa0a4f88224e051f","init_cell":true,"ExecuteTime":{"start_time":"2017-10-07T19:18:48.450954Z","end_time":"2017-10-07T19:18:48.456468Z"},"_cell_guid":"1517057c-015f-4a51-ad03-9c67db5a5414","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"### Loading datasets\ntrain.csv contains the training data, where each row corresponds to a policy holder, and the target columns signifies that a claim was filed. test.csv contains the test data. sample_submission.csv is submission file showing the correct format.\n\"Ind\" is related to individual or driver, \"reg\" is related to region, \"car\" is related to car itself and \"calc\" is an calculated feature.","metadata":{"_uuid":"bbc48ec3680cf01d68942df2e2969e6f5e0e7e8d","_cell_guid":"ee410e3e-e3b4-4aba-a9fc-f3551ebe4444"},"cell_type":"markdown"},{"source":"# Setting working directory\n\npath = '../input/'","outputs":[],"metadata":{"_uuid":"8e62d31067bebe08ddcc1dc9d1193493e0236d34","init_cell":true,"ExecuteTime":{"start_time":"2017-10-07T19:18:48.460479Z","end_time":"2017-10-07T19:18:48.528158Z"},"_cell_guid":"36e2c62d-1881-4556-96bd-40d5d94319aa","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#load files\ntrain_data = h2o.import_file(path + 'train.csv')\ntest_data = h2o.import_file(path + 'test.csv')","outputs":[],"metadata":{"_uuid":"cbd83a3ac5e576ee8bea7e1224f37ef4a7d020ab","init_cell":true,"ExecuteTime":{"start_time":"2017-10-07T20:23:37.709324Z","end_time":"2017-10-07T20:24:17.875114Z"},"_cell_guid":"178e26ba-0d0b-450b-98a8-1da3946bd443","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":" test_id = h2o.import_file(path + 'test.csv')['id']","outputs":[],"metadata":{"_uuid":"5e3221852518635adeaba38fbb89e06e83e35680","_cell_guid":"ecf91e35-0320-423f-8581-4b3468673e01","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":" train_data[\"target\"] = train_data[\"target\"].asfactor()","outputs":[],"metadata":{"_uuid":"c77aee6f216e1a6b19b046fa42fcdf4769c1e041","ExecuteTime":{"start_time":"2017-10-07T19:18:54.716646Z","end_time":"2017-10-07T19:18:54.722161Z"},"_cell_guid":"ffd34150-75b5-4082-af73-9c91e5ed99f4","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"train, valid, test = train_data.split_frame(ratios=[0.7, 0.15], seed=42)  ","outputs":[],"metadata":{"_uuid":"e5673e3979d3e0b328a916df9d903997ae77baac","ExecuteTime":{"start_time":"2017-10-07T19:18:54.726174Z","end_time":"2017-10-07T19:18:55.133257Z"},"_cell_guid":"d4a7814d-7011-4f22-be34-2b0572b7475b","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"y = 'target'\nx = list(train_data.columns)","outputs":[],"metadata":{"_uuid":"8c846e3cb0540a406be61e0e5fe51211b446fc05","ExecuteTime":{"start_time":"2017-10-07T19:18:55.136264Z","end_time":"2017-10-07T19:18:55.148797Z"},"_cell_guid":"975d4511-a3b4-4b06-a7f9-04bb9218e938","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"x.remove(y)  #remove the response","outputs":[],"metadata":{"_uuid":"293f1bcfb34e6def3357c82dca34ac79363e0f85","ExecuteTime":{"start_time":"2017-10-07T19:18:55.152307Z","end_time":"2017-10-07T19:18:55.169444Z"},"_cell_guid":"861c3bfa-aca1-4b15-b9ba-a5981ca9b871","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"print(x)","outputs":[],"metadata":{"_uuid":"21a388444b051efc168caaad39b197d555981d30","ExecuteTime":{"start_time":"2017-10-07T19:18:55.17286Z","end_time":"2017-10-07T19:18:55.202941Z"},"_cell_guid":"37b7ad16-d622-4d15-bc87-a4f2ee095c08","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"## H2O Machine Learning\nNow that we have prepared the data, we can train some models. We will start by training a single model from each of the H2O supervised algos:\n- Generalized Linear Model (GLM)\n- Random Forest (RF)\n- Gradient Boosting Machine (RF)\n- Deep Learning (DL)","metadata":{"_uuid":"fa341f50e8ed907d165c76b8fa790468f0a21fae","_cell_guid":"720f80dd-8341-4249-a95f-9b18e4d2a126"},"cell_type":"markdown"},{"source":"### Generalized Linear Model\nLet's start with a basic binomial Generalized Linear Model (GLM). By default, H2O's GLM uses a regularized, elastic net model.","metadata":{"_uuid":"79c068a5f4cfef55ac74e41de8359465d7140f44","_cell_guid":"a660422a-6c1d-40dc-94d1-053d97a58b68"},"cell_type":"markdown"},{"source":"# Import H2O GLM:\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator","outputs":[],"metadata":{"_uuid":"265a2018f7f43d265dc7199c2714d2bfa3e96508","ExecuteTime":{"start_time":"2017-10-07T19:18:55.20595Z","end_time":"2017-10-07T19:18:55.220988Z"},"_cell_guid":"d99bd6ea-ee57-421e-89ea-f778c6c5af67","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train a default GLM\nWe first create an object of class, \"H2OGeneralizedLinearEstimator\". ","metadata":{"_uuid":"05db74de3f993b9c15e62058652764925e7b0774","_cell_guid":"4f017336-7f45-46c5-88d0-74c6fb9b7637"},"cell_type":"markdown"},{"source":"glm_fit1 = H2OGeneralizedLinearEstimator(family='binomial', model_id='glm_fit1')","outputs":[],"metadata":{"_uuid":"af6c6d39ca75c4347e0eb2196d56ca936fd5642c","ExecuteTime":{"start_time":"2017-10-07T21:06:16.346871Z","end_time":"2017-10-07T21:06:16.386978Z"},"_cell_guid":"f1f47bc4-0f36-4116-a285-f67f5bc86184","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Now that glm_fit1 object is initialized, we can train the model:","metadata":{"_uuid":"93996253e4e9015c09a22220831ad815dfb20d4f","_cell_guid":"01f0dd5f-dddf-4edd-856c-236acb50c2a2"},"cell_type":"markdown"},{"source":"glm_fit1.train(x=x, y=y, training_frame=train)","outputs":[],"metadata":{"_uuid":"17f64e65eecfcfc6814bc9d100408c764c470144","ExecuteTime":{"start_time":"2017-10-07T19:18:55.248061Z","end_time":"2017-10-07T19:18:59.259283Z"},"_cell_guid":"ea172030-e2da-455f-a24d-173f2c984f6d","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#### Train a GLM with lambda search\nNext we will do some automatic tuning by passing in a validation frame and setting lambda_search = True. Since we are training a GLM with regularization, we should try to find the right amount of regularization (to avoid overfitting). The model parameter, lambda, controls the amount of regularization in a GLM model and we can find the optimal value for lambda automatically by setting lambda_search = True and passing in a validation frame (which is used to evaluate model performance using a particular value of lambda).","metadata":{"_uuid":"86cd9327b402072db6435fe105654f59ad535041","_cell_guid":"b7b93dbd-75f3-4470-98c2-6f931e3a2448"},"cell_type":"markdown"},{"source":"glm_fit2 = H2OGeneralizedLinearEstimator(family='binomial', model_id='glm_fit2', lambda_search=True,balance_classes = True)\nglm_fit2.train(x=x, y=y, training_frame=train, validation_frame=valid)","outputs":[],"metadata":{"_uuid":"e73749439dc1898a2d77be59426ff7e8865bd924","ExecuteTime":{"start_time":"2017-10-07T19:18:59.261788Z","end_time":"2017-10-07T19:19:10.16786Z"},"_cell_guid":"fae97fd3-7eb8-438c-b887-8b7135838781","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"#### Evaluate model performance\nLet's compare the performance of the two GLMs that were just trained.","metadata":{"_uuid":"b704d1205627fbd165dd67f96de0f210d193a6bf","_cell_guid":"90684e48-95c0-4ed1-a39a-e4619bd2509b"},"cell_type":"markdown"},{"source":"glm_perf1 = glm_fit1.model_performance(test)\nglm_perf2 = glm_fit2.model_performance(test)","outputs":[],"metadata":{"_uuid":"6f3dfd6515bdbd6e9337491aae4f950fbb4b620d","ExecuteTime":{"start_time":"2017-10-07T19:19:10.170368Z","end_time":"2017-10-07T19:19:10.571943Z"},"_cell_guid":"1e79c577-a590-4096-89b7-8cea1944111c","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# Retreive test set AUC\nprint (glm_perf1.gini())\nprint (glm_perf2.gini())","outputs":[],"metadata":{"_uuid":"7429e91b88df9a7c9dec2f8eaa6066f37fe36ef3","ExecuteTime":{"start_time":"2017-10-07T19:19:10.571943Z","end_time":"2017-10-07T19:19:10.587584Z"},"_cell_guid":"0dac600c-486e-44af-8499-5cc0595db901","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# Compare test AUC to the training AUC and validation AUC\nprint (glm_fit2.gini(train=True))\nprint (glm_fit2.gini(valid=True))","outputs":[],"metadata":{"_uuid":"f3ad2c94f148caa9e0c8f51bcc4e99382b4ba2bc","ExecuteTime":{"start_time":"2017-10-07T20:50:01.950373Z","end_time":"2017-10-07T20:50:01.966415Z"},"_cell_guid":"137c73c9-da6e-46ea-810c-b599d12b089a","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"### Random Forest\nH2O's Random Forest (RF) is implements a distributed version of the standard Random Forest algorithm and variable importance measures.","metadata":{"_uuid":"07387a70f239e5d71662313293096b4bad231b3b","_cell_guid":"f764d97d-ac49-459d-9453-ca61cd544215"},"cell_type":"markdown"},{"source":"# Import H2O RF:\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator","outputs":[],"metadata":{"_uuid":"4468f483839c59c85ef206a04dd518baec2fb526","ExecuteTime":{"start_time":"2017-10-07T20:50:47.846011Z","end_time":"2017-10-07T20:50:47.892634Z"},"_cell_guid":"2964ed4c-eae8-468a-9841-47ee889307f3","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train and a default RF\nFirst we will train a basic Random Forest model with default parameters. Random Forest will infer the response distribution from the response encoding. A seed is required for reproducibility.\n:","metadata":{"_uuid":"4a4563b7715e16c3ef71bcf706fc5545ec53ff51","_cell_guid":"7d4d5a4c-2f3b-4c70-b138-0f65ec909305"},"cell_type":"markdown"},{"source":"# Initialize the RF estimator:\n\nrf_fit1 = H2ORandomForestEstimator(model_id='rf_fit1',   seed=1)","outputs":[],"metadata":{"_uuid":"bff6334f2d82c874f16c0253f1d1881171d1f011","ExecuteTime":{"start_time":"2017-10-07T20:51:14.882483Z","end_time":"2017-10-07T20:51:14.894013Z"},"_cell_guid":"a803fd83-b400-4546-876c-375047c5c9f1","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Now that rf_fit1 object is initialized, we can train the model:","metadata":{"_uuid":"7c381c75895484365d1dbadbd3fb63727d9809f9","_cell_guid":"fc346747-c0d5-4468-b5bf-3afb0875f76c"},"cell_type":"markdown"},{"source":"rf_fit1.train(x=x, y=y, training_frame=train,validation_frame=valid)","outputs":[],"metadata":{"_uuid":"e637ec1cd67402e29ad9c7f63a4875d3792f64f3","ExecuteTime":{"start_time":"2017-10-07T20:51:36.033299Z","end_time":"2017-10-07T20:52:48.757029Z"},"_cell_guid":"27335e9a-c2df-4124-b88a-8e1f30d0699b","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train an RF with more trees\nNext we will increase the number of trees used in the forest by setting ntrees = 100. The default number of trees in an H2O Random Forest is 50, so this RF will be twice as big as the default. Usually increasing the number of trees in an RF will increase performance as well. Unlike Gradient Boosting Machines (GBMs), Random Forests are fairly resistant (although not free from) overfitting by increasing the number of trees. See the GBM example below for additional guidance on preventing overfitting using H2O's early stopping functionality.","metadata":{"_uuid":"9e26c6cb1376a972a4d5cc37510b3b77491f8593","_cell_guid":"de6d4c6c-7293-4041-81d2-1da0032dee8b"},"cell_type":"markdown"},{"source":"rf_fit2 = H2ORandomForestEstimator(model_id='rf_fit2', ntrees=100,   seed=1)\nrf_fit2.train(x=x, y=y, training_frame=train,validation_frame=valid)","outputs":[],"metadata":{"_uuid":"d12c185f59e342620620af9928fa6e799ad7638e","ExecuteTime":{"start_time":"2017-10-07T20:53:12.222622Z","end_time":"2017-10-07T20:55:34.509053Z"},"_cell_guid":"3648db7e-482a-4320-901e-cdc6f14bc952","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Compare model performance\nLet's compare the performance of the two RFs that were just trained.","metadata":{"_uuid":"9a5cdb0f585d0f5111c97816739e70a253a4d972","_cell_guid":"2e87fc58-d342-43d0-801f-f23b98bdc7ec"},"cell_type":"markdown"},{"source":"rf_perf1 = rf_fit1.model_performance(test)\nrf_perf2 = rf_fit2.model_performance(test)","outputs":[],"metadata":{"_uuid":"3b315bbebd2c16ef37d17703448de0a7e064415e","ExecuteTime":{"start_time":"2017-10-07T20:56:00.92851Z","end_time":"2017-10-07T20:56:19.650414Z"},"_cell_guid":"a69fb8fa-b7b2-4912-800c-0b64bfd9c286","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# Retreive test set AUC\nprint(rf_perf1.gini())\nprint(rf_perf2.gini())","outputs":[],"metadata":{"_uuid":"74e0b9da2f79db87fbdff6ae79add50b39d93cd5","ExecuteTime":{"start_time":"2017-10-07T20:56:44.866316Z","end_time":"2017-10-07T20:56:44.904922Z"},"_cell_guid":"3f79b351-67a7-4986-a7aa-3b15574abd4a","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Cross-validate performance\nRather than using held-out test set to evaluate model performance, a user may wish to estimate model performance using cross-validation. Using the RF algorithm (with default model parameters) as an example, we demonstrate how to perform k-fold cross-validation using H2O. No custom code or loops are required, you simply specify the number of desired folds in the nfolds argument.\nSince we are not going to use a test set here, we can use the original (full) dataset, which we called data rather than the subsampled  train dataset. Note that this will take approximately k (nfolds) times longer than training a single RF model, since it will train k models in the cross-validation process (trained on n(k-1)/k rows), in addition to the final model trained on the full training_frame dataset with n rows.","metadata":{"_uuid":"f73a0dd2350e51479dee58c87defee059aabaa6e","_cell_guid":"335a2eee-2dd0-4973-9825-98c30d21b459"},"cell_type":"markdown"},{"source":"rf_fit3 = H2ORandomForestEstimator(model_id='rf_fit3', seed=1, nfolds=5)\nrf_fit3.train(x=x, y=y, training_frame=train)","outputs":[],"metadata":{"_uuid":"bd4d91749a7a9c4d816d233ccf297a60bb704032","ExecuteTime":{"start_time":"2017-10-07T20:57:07.443048Z","end_time":"2017-10-07T21:03:38.759129Z"},"_cell_guid":"f85cea95-c281-4c39-81a9-ffa9b61b3674","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"To evaluate the cross-validated AUC, do the following:","metadata":{"_uuid":"27d87313c052fb67d66f42bd1fba4d4f47a72d9b","_cell_guid":"4e4bb38e-e04e-4303-afb6-a943e81caa20"},"cell_type":"markdown"},{"source":"print( rf_fit3.gini(xval=True))","outputs":[],"metadata":{"_uuid":"197b1de12b083e946ba41b5d58df8bbf3628f98f","ExecuteTime":{"start_time":"2017-10-07T21:04:04.023906Z","end_time":"2017-10-07T21:04:04.03594Z"},"_cell_guid":"0d681a91-02b0-4b41-b1b7-7f80303016be","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Note that the cross-validated AUC is slighly higher than the test set performance we estimated for rf_fit1, and this is likely due to the fact that we trained on more data (n rows) than we did while using train as the training set (0.75*n rows) in rf_fit1.\n3. Gradient Boosting Machine\nH2O's Gradient Boosting Machine (GBM) offers a Stochastic GBM, which can increase performance quite a bit compared to the original GBM implementation.","metadata":{"_uuid":"4351314ecf76e9f34be89201b040def3ea4fb5c2","_cell_guid":"f7938bac-830f-4d34-b0cd-3d752a856fda"},"cell_type":"markdown"},{"source":"# Import H2O GBM:\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator","outputs":[],"metadata":{"_uuid":"4492140fbbb602ed149febb8970f9cd93449c88e","ExecuteTime":{"start_time":"2017-10-07T20:08:36.172026Z","end_time":"2017-10-07T20:08:36.179046Z"},"_cell_guid":"efb2146a-8902-4690-9b05-4bb733085313","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train a default GBM\nFirst we will train a basic GBM model with default parameters. GBM will infer the response distribution from the response encoding if not specified explicitly through the distribution argument. A seed is required for reproducibility.","metadata":{"_uuid":"ad1724151ca8735ee6f7a63d01fbc7b3a995ac53","_cell_guid":"21492cd6-26ff-4921-b3f5-489c0fef2319"},"cell_type":"markdown"},{"source":"# Initialize and train the GBM estimator:\n\ngbm_fit1 = H2OGradientBoostingEstimator(model_id='gbm_fit1',   seed=1)\ngbm_fit1.train(x=x, y=y, training_frame=train, validation_frame=valid)","outputs":[],"metadata":{"_uuid":"39c57b6625f28fdc3179ef820e809e135ca79eff","ExecuteTime":{"start_time":"2017-10-07T20:53:34.613Z","end_time":"2017-10-07T21:04:27.208439Z"},"_cell_guid":"9b8a3074-5e08-4004-b73a-1feff57996b6","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train a GBM with more trees\nNext we will increase the number of trees used in the GBM by setting ntrees=500. The default number of trees in an H2O GBM is 50, so this GBM will trained using ten times the default. Increasing the number of trees in a GBM is one way to increase performance of the model, however, you have to be careful not to overfit your model to the training data by using too many trees. To automatically find the optimal number of trees, you must use H2O's early stopping functionality. This example will not do that, however, the following example will.","metadata":{"_uuid":"4f97d0a9ea44849aacc5352b89afa4017f59d9bb","_cell_guid":"0de32ddf-0b19-4cce-b621-00e686f0ab27"},"cell_type":"markdown"},{"source":"gbm_fit2 = H2OGradientBoostingEstimator(model_id='gbm_fit2', ntrees=500,   seed=1)\ngbm_fit2.train(x=x, y=y, training_frame=train,validation_frame=valid)","outputs":[],"metadata":{"_uuid":"61796f1a342d0467fd0c1c63dad34c5dd2b56020","ExecuteTime":{"start_time":"2017-10-07T20:53:27.967Z","end_time":"2017-10-07T21:04:27.200451Z"},"_cell_guid":"e4eec583-1745-4652-8eee-f3870b77427e","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train a GBM with early stopping\nWe will again set ntrees = 500, however, this time we will use early stopping in order to prevent overfitting (from too many trees). All of H2O's algorithms have early stopping available, however, with the exception of Deep Learning, it is not enabled by default.\nThere are several parameters that should be used to control early stopping. The three that are generic to all the algorithms are: stopping_rounds, stopping_metric and stopping_tolerance. The stopping metric is the metric by which you'd like to measure performance, and so we will choose AUC here. The score_tree_interval is a parameter specific to Random Forest and GBM. Setting score_tree_interval=5 will score the model after every five trees. The parameters we have set below specify that the model will stop training after there have been three scoring intervals where the AUC has not increased more than 0.0005. Since we have specified a validation frame, the stopping tolerance will be computed on validation AUC rather than training AUC.","metadata":{"_uuid":"0ce7f1edf38ae2adef5822a97200ed9211239a74","_cell_guid":"0acb6e0a-8f52-4698-85c8-b01cf5d143a2"},"cell_type":"markdown"},{"source":"# Now let's use early stopping to find optimal ntrees\n\ngbm_fit3 = H2OGradientBoostingEstimator(model_id='gbm_fit3', \n                                        ntrees=1000, \n                                        score_tree_interval=5,     #used for early stopping\n                                        stopping_rounds=3,         #used for early stopping\n                                        stopping_metric='AUC',     #used for early stopping\n                                        stopping_tolerance=0.0005, #used for early stopping\n                                        seed=1)\n# The use of a validation_frame is recommended with using early stopping\ngbm_fit3.train(x=x, y=y, training_frame=train, validation_frame=valid)","outputs":[],"metadata":{"_uuid":"4d393dda3b0385cc77cd2845ace4fe56a618b8f7","ExecuteTime":{"start_time":"2017-10-07T21:07:42.668872Z","end_time":"2017-10-07T21:10:51.936659Z"},"_cell_guid":"e6e13099-1613-4276-8c09-7584ad05071f","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# Let's try XGBOOSTING\nfrom h2o.estimators import H2OXGBoostEstimator\nparam = {\n      \"model_id\": 'gbm_fit4'\n    , \"ntrees\" : 100\n    , \"max_depth\" : 10\n    , \"learn_rate\" : 0.02\n    , \"sample_rate\" : 0.7\n    , \"col_sample_rate_per_tree\" : 0.9\n    , \"min_rows\" : 5\n    , \"seed\": 4241\n    , \"score_tree_interval\": 100\n}\ngbm_fit4 = H2OXGBoostEstimator(**param)\ngbm_fit4.train(x=x, y=y, training_frame=train, validation_frame=valid)","outputs":[],"metadata":{"_uuid":"4d393dda3b0385cc77cd2845ace4fe56a618b8f7","ExecuteTime":{"start_time":"2017-10-07T21:07:42.668872Z","end_time":"2017-10-07T21:10:51.936659Z"},"_cell_guid":"e6e13099-1613-4276-8c09-7584ad05071f","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Compare model performance\nLet's compare the performance of the three GBMs that were just trained.","metadata":{"_uuid":"64f4aa25c8f922b1782ae17cbb9da91ad3e82bea","_cell_guid":"8e960e03-d89b-4b24-8e2d-dba312d14363"},"cell_type":"markdown"},{"source":"gbm_perf1 = gbm_fit1.model_performance(test)\ngbm_perf2 = gbm_fit2.model_performance(test)\ngbm_perf3 = gbm_fit3.model_performance(test)\ngbm_perf4 = gbm_fit4.model_performance(test)","outputs":[],"metadata":{"_uuid":"a8ccaaa5af51d54e369f78d3b696289a136bc06d","ExecuteTime":{"start_time":"2017-10-07T21:11:10.559222Z","end_time":"2017-10-07T21:11:19.181166Z"},"_cell_guid":"63adfb17-f8f9-4a7c-8d6f-485e57bc0268","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# Retreive test set AUC\nprint (gbm_perf1.gini())\nprint (gbm_perf2.gini())\nprint (gbm_perf3.gini())\nprint (gbm_perf4.gini())","outputs":[],"metadata":{"_uuid":"796de0b31a6044c52f73c7a55f4412d58f073992","ExecuteTime":{"start_time":"2017-10-07T21:11:37.216678Z","end_time":"2017-10-07T21:11:37.243751Z"},"_cell_guid":"1b240891-d245-490a-aba1-52c72ccb47e3","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"### Deep Learning\nH2O's Deep Learning algorithm is a multilayer feed-forward artificial neural network. It can also be used to train an autoencoder, however, in the example below we will train a standard supervised prediction model.","metadata":{"_uuid":"977cdd13aced49388474d897a6e997984ee84f6f","_cell_guid":"7742304d-6e9a-42ce-ab82-6c59f51e3d05"},"cell_type":"markdown"},{"source":"# Import H2O DL:\nfrom h2o.estimators.deeplearning import H2ODeepLearningEstimator","outputs":[],"metadata":{"_uuid":"8724eee1f991d556412cca46726119d3f7eec6e5","ExecuteTime":{"start_time":"2017-10-07T20:26:07.13223Z","end_time":"2017-10-07T20:26:07.137769Z"},"_cell_guid":"5ed24742-8e0c-4c41-a7e9-6038baff3e95","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train a default DL\nFirst we will train a basic DL model with default parameters. DL will infer the response distribution from the response encoding if not specified explicitly through the distribution argument. H2O's DL will not be reproducbible if run on more than a single core, so in this example, the performance metrics below may vary slightly from what you see on your machine.\nIn H2O's DL, early stopping is enabled by default, so below, it will use the training set and default stopping parameters to perform early stopping.","metadata":{"_uuid":"7c1795efd6a11a2efee1da9dd5bfce3e8abcbf7e","_cell_guid":"48fa078e-6150-46a9-9261-d81719022c41"},"cell_type":"markdown"},{"source":"# Initialize and train the DL estimator:\n\ndl_fit1 = H2ODeepLearningEstimator(model_id='dl_fit1',   seed=1,  balance_classes = True)\ndl_fit1.train(x=x, y=y, training_frame=train,validation_frame=valid)","outputs":[],"metadata":{"_uuid":"5d33a70bfaa22a725d216be5b6b02f6a842b15fd","ExecuteTime":{"start_time":"2017-10-07T20:26:21.988746Z","end_time":"2017-10-07T20:28:29.294178Z"},"_cell_guid":"1509d0b9-c059-4434-8261-77ff2ef1e99e","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train a DL with new architecture and more epochs\nNext we will increase the number of epochs used in the GBM by setting epochs=20 (the default is 10). Increasing the number of epochs in a deep neural net may increase performance of the model, however, you have to be careful not to overfit your model. To automatically find the optimal number of epochs, you must use H2O's early stopping functionality. Unlike the rest of the H2O algorithms, H2O's DL will use early by default, so we will first turn it off in the next example by setting stopping_rounds=0, for comparison.","metadata":{"_uuid":"cd0e220cfaa46ff4e1f7b78f3feb5f5e65743c85","_cell_guid":"918423d2-2d91-4f38-ad86-08c44be4ce9f"},"cell_type":"markdown"},{"source":"dl_fit2 = H2ODeepLearningEstimator(model_id='dl_fit2', \n                                   epochs=50, \n                                   hidden=[10,10], \n                                   stopping_rounds=0,  #disable early stopping\n                                   seed=1,\n                                   balance_classes = True)\ndl_fit2.train(x=x, y=y, training_frame=train,validation_frame=valid)","outputs":[],"metadata":{"_uuid":"32cb78949f18d39b42c026e6dde3334a118e8648","ExecuteTime":{"start_time":"2017-10-07T20:31:04.766258Z","end_time":"2017-10-07T20:32:21.313178Z"},"_cell_guid":"9040e2b4-51a9-47ca-8304-7c1cbe13d05f","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Train a DL with early stopping\nThis example will use the same model parameters as dl_fit2, however, we will turn on early stopping and specify the stopping criterion. We will also pass a validation set, as is recommended for early stopping.","metadata":{"_uuid":"3978db971fd8d76911e90a8e9086d6adbc92c662","ExecuteTime":{"start_time":"2017-10-07T03:45:10.516Z","end_time":"2017-10-07T03:51:45.245666Z"},"_cell_guid":"dfe4e11c-afa2-484c-81c3-7e061ce80bfa"},"cell_type":"markdown"},{"source":"dl_fit3 = H2ODeepLearningEstimator(model_id='dl_fit3', \n                                   epochs=500, \n                                   hidden=[10,10],\n                                   score_interval=1,          #used for early stopping\n                                   stopping_rounds=50,         #used for early stopping\n                                   stopping_metric='AUC',     #used for early stopping\n                                   stopping_tolerance=0.0005, #used for early stopping\n                                   seed=1,  \n                                   balance_classes = True)\ndl_fit3.train(x=x, y=y, training_frame=train, validation_frame=valid)","outputs":[],"metadata":{"_uuid":"d62e959c328c2575b741abcf4df659fb8946268f","ExecuteTime":{"start_time":"2017-10-07T20:38:57.182592Z","end_time":"2017-10-07T20:42:30.968703Z"},"_cell_guid":"9134867e-5e3b-45f9-a8f0-f34f41c808cf","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Compare model performance\nAgain, we will compare the model performance of the three models using a test set and AUC.","metadata":{"_uuid":"a461a7fdd6d68e2ace96445402c61c89542a8aac","ExecuteTime":{"start_time":"2017-10-07T03:45:27.364Z","end_time":"2017-10-07T03:51:45.260203Z"},"_cell_guid":"41322c0c-fc16-4c6e-8100-b42dce2924dc"},"cell_type":"markdown"},{"source":"dl_perf1 = dl_fit1.model_performance(test)\ndl_perf2 = dl_fit2.model_performance(test)\ndl_perf3 = dl_fit3.model_performance(test)","outputs":[],"metadata":{"_uuid":"93959aa4ec079ab26b1a586d3f3b11a4718ea736","ExecuteTime":{"start_time":"2017-10-07T20:42:42.776885Z","end_time":"2017-10-07T20:42:45.055597Z"},"_cell_guid":"cf7e06e7-6927-4500-8348-8844e0313825","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"# Retreive test set AUC\nprint (dl_perf1.gini())\nprint (dl_perf2.gini())\nprint( dl_perf3.gini())","outputs":[],"metadata":{"_uuid":"e785bb44dada76872fa7611dcfc1d6402e51b87a","ExecuteTime":{"start_time":"2017-10-07T20:42:57.634805Z","end_time":"2017-10-07T20:42:57.647841Z"},"_cell_guid":"e61800c0-a22d-435c-9af7-c9fae108c060","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"test_pred = gbm_fit4.predict(test_data)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"sub = pd.DataFrame()\nsub['id'] = h2o.as_list(test_id)\nsub['target'] = h2o.as_list(test_pred['p1'])\nsub.to_csv('xgb_h2o.csv', index=False)","outputs":[],"metadata":{"_uuid":"d012574d790b724e7b25e8395a942a9617d81496","_cell_guid":"034a5e65-bc46-4d0e-bb40-b7578b780868","collapsed":true},"execution_count":null,"cell_type":"code"}]}