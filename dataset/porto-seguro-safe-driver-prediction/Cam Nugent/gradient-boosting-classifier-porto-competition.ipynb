{"nbformat":4,"cells":[{"metadata":{"_uuid":"e84dbb814842c2d629d989d021499c767a5a7a03","_cell_guid":"bce5f8ee-5add-4f30-946a-64672337b77b"},"source":"## Initial Gradient boosting model to predict probabilities of an insurance claim\n\nThis kernel contains my initial sanity check of the data, a preliminary grid search of hyperparamaters and my initial submission from a gradient boost classification model.\n\nFirst, we import the needed libraries:","cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV","metadata":{"_uuid":"4a5615f8ffaa9081510c837ba6b1723df3f854c0","_cell_guid":"270d3590-5fb5-44e7-9503-1f808954082b","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"613424a87b9eb5da9ef2cd84128d8dab7cc80b23","_cell_guid":"5d1982c0-b644-459c-a930-079719d72c99"},"source":"Next, the data is read in using pandas's read_csv() function","cell_type":"markdown"},{"source":"test_dat = pd.read_csv('../input/test.csv')\ntrain_dat = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')\n","metadata":{"_uuid":"eec3def462ff61bfbc8359a91555fbde68bbbaa0","_cell_guid":"4b7a62d7-0c96-423a-a126-785571ef4f09","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"a00ff903aa86ee996a4d8f8f81c9aae3c837437e","_cell_guid":"5a5a2181-f8b4-41f5-8e5b-97214b5766c0"},"source":"An initial check of the data is made to identify any missing values.","cell_type":"markdown"},{"source":"train_dat.info()","metadata":{"_uuid":"e322fcfe294886c0b8a4b0cf65fd71a4af6981c8","_cell_guid":"181c359a-dc4b-4cf4-8dc2-4ef604475aba","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"97bc653449f21d5d8beb8e09ec7f6d87cdcd1faf","_cell_guid":"e518655e-5e22-4b94-a72f-a5e601564817"},"source":"There appears to be no missing values across the dataset, so we can proceed without the need to impute. Most of the columns appear to be binary, with a few continious floating point predictors as well.","cell_type":"markdown"},{"source":"train_dat.describe()\n","metadata":{"_uuid":"0cda736cb90ac19187f0b49839f53c8fe8684efd","_cell_guid":"9105fd5c-3468-475d-903a-af9a209d0fbe","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"5abef0456aec00466477bfa8a5201b5c79962a99","_cell_guid":"03b0fc54-1ffc-4226-8278-7073266f43d6"},"source":"We split the training data into a y response variable, and the predictors, while dropping the ID column.","cell_type":"markdown"},{"source":"\ntrain_y = train_dat['target']\ntrain_x = train_dat.drop(['target', 'id'], axis = 1)\n","metadata":{"_uuid":"89aaaa6c4be947080767611276f1eaf754c8c169","_cell_guid":"5979e1b4-6fd3-4f4f-943e-5704629b67ae","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"4be75a4f582aeeb9cbae2a931182723aa1463448","_cell_guid":"e048fe6e-a61e-443e-be8f-4b56fb50958c"},"source":"A grid search is performed to select the optimal hypterparamaters for the gradient boosting classifier.  You can change this section to your own set of values an likely improve the best estimator! Commented out to avoid the time cap.","cell_type":"markdown"},{"source":"\"\"\"\ngb_params = {\n    'n_estimators' : [100,200,300],\n    'learning_rate' : [.1,.2,.3],\n    'max_depth' : [3,5,7]\n}\n\ngb_class = GradientBoostingClassifier()\n\ngb_grid = GridSearchCV(gb_class, gb_params, cv = 5, n_jobs=-1)\ngb_grid.fit(train_x, train_y)\n\ngb_grid.best_estimator_\n\"\"\"","metadata":{"_uuid":"13d3512b7c38dc2daf971221d92e04f6667f2b42","_cell_guid":"bbd7da36-f941-4957-af54-5de401d184a2","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"932b6b710942e44a627118574d6bf94339d7aa3d","_cell_guid":"39ae1299-da90-4228-b01c-6eeff1ba82f9"},"source":"An initial run produced the following optimal model paramaters, which I here use to train a new model using the complete training set.\n\nFirst, model is initiated:","cell_type":"markdown"},{"source":"gb_opt = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n                            learning_rate=0.1, loss='deviance', max_depth=3,\n                            max_features=None, max_leaf_nodes=None, min_impurity_split=None,\n                            min_samples_leaf=1, min_samples_split=2,\n                            min_weight_fraction_leaf=0.0, n_estimators=100,\n                            presort='auto', random_state=None, subsample=1.0, verbose=0,\n                            warm_start=False)\n    \n","metadata":{"_uuid":"c5bd72552fcd4097484868c4a2ea98006e28d631","_cell_guid":"37d4cbb1-24cf-4e3f-8747-869453f59c5e","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"b3fffbe34660d9f9e18e5fedb24480a5ee163517","_cell_guid":"8275eb1e-0202-415d-b392-cc1693344676"},"source":"Then it is fed the training data","cell_type":"markdown"},{"source":"gb_opt.fit(train_x, train_y)\n","metadata":{"_uuid":"5378f969911e5cb2f3e1bdad6184a5726864f9c7","_cell_guid":"009997e6-d353-4197-abd7-28bc1889d598","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"0e92776e93215f720c96982f37d6c56cc03aadaa","_cell_guid":"70aaca57-20ff-4bb0-85f8-d16e5e84eeb2"},"source":"Since we are predicting probabilities of belonging to a given class, we use predict_proba() as opposed to predict(), which would give us the predicted classes instead of the probabilities.","cell_type":"markdown"},{"source":"test_y_gb = gb_opt.predict_proba(test_x)\n","metadata":{"_uuid":"4550a8bdd57c8450f47bbee3dd5113ffd94aa00a","_cell_guid":"582bc550-7311-4cb3-9cfa-5e16cca90343","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"f97f7e654e2f994d2d7295179aff47d0c53477da","_cell_guid":"3ef64764-10b5-4684-ab4d-79e0eccd06e4"},"source":"Below the predictions are placed into the sample submission dataframe, and the inverse of the predictions is taken. predict_proba() give the probability of the given instance being a '0' but we want the probability of an instance being a '1' (an insurance claim filed). Therefore, we take the inverse.","cell_type":"markdown"},{"source":"\ngb_out = submission\ngb_out['target'] = test_y_gb\n\ngb_out['target'] = 1-gb_out['target']","metadata":{"_uuid":"fea4b1031030257ae65b3f36c67e459479446733","_cell_guid":"c38c6d02-87db-44f0-aeb4-f2a3e5595591","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"1a7a63d628a70ab5d58b15c248a22b42ce31d3b6","_cell_guid":"f533c9d1-b10c-4098-a1d9-8eafd5f7f247"},"source":"Then we write the data to a csv, dropping the index and rounding the probabilities to 4 decimals (this was the number of decimals in the sample submission).","cell_type":"markdown"},{"source":"gb_out.to_csv('gb_predictions1.csv', index=False, float_format='%.4f')\n","metadata":{"_uuid":"fee9ef6b2e343009f19755955cb10a8b9d23d7b4","_cell_guid":"06bc6628-1fb3-4880-aedb-8a1cee88ac17","collapsed":true},"execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_uuid":"f928f8af519adb3b49c77a6ccfdaff2a9a92c393","_cell_guid":"dbf48063-3f8e-4c37-ba35-52bf94132f23"},"source":"And thats it! If you play around with the hyperparameters then there are likely some large performance boosts to be found (accidental pun... but I'm leaving it). ","cell_type":"markdown"}],"metadata":{"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","mimetype":"text/x-python","name":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":1}