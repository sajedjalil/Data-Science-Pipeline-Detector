{"nbformat_minor":1,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"dbf065a7-85c4-4148-969b-27e290be9e91","_uuid":"831c0b75d810668e82928598b61246d681e28728"},"source":"# A deep neural network for insurance classification written in tensorflow\n\n## Original goal, and a what I learned\n\nI had originally set out to write this post with the intent of gaining practice in the design of neural networks using tensorflow, but along the way I learned a valuable lesson about class imbalance which I will share here in additon to the model I have designed. This process has shown me that you can design a really nifty model, but if it is given data it cannot effectively learn from, your predictions will be just as garbage as your inputs.\n\nExecutable script versions of the different nn variants are avaliable at: https://github.com/CNuge/kaggle_code/tree/master/insurance_classification\n\n## What this post covers\n1. Designing the neural network\n2. My first training attempt (a.k.a. how to do it wrong)\n3. Why the training was not working\n4. Solution A: Downsampling the 0s\n5. Solution B: Upsampling the 1s\n6. Discussion of the results from the two methods of addressing class imbalance\n\nSo If all you want is the best form of the working model, then you can look at just parts 1. and 5. If you're interested in learning from my mistakes in dealing with class imbalance then read on!\n\n### Housekeeping: imports\n"},{"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n","cell_type":"code","metadata":{"_cell_guid":"8d827254-f0ef-4f24-afed-f470b6562d53","collapsed":true,"_uuid":"515e6a3b9f7f504165aa5e06f4751cd76f2606c9"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"a0f677ac-6f4b-49c8-ab5e-458aa1188244","_uuid":"7f5481883c6904d86047acb5390e4d6c0d3b5f13"},"source":"## 1. Designing the network\n\nThe first three functions below are not part of the network. The two gini functions are used to assess the normalized gini index score for the model, and I will be calling them once per training epoch so that we can check in on the model's accuracy.\n\n### 1.a gini assessment function"},{"outputs":[],"source":"def gini(actual, pred, cmpcol = 0, sortcol = 1):\n\tassert( len(actual) == len(pred) )\n\tall = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n\tall = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n\ttotalLosses = all[:,0].sum()\n\tginiSum = all[:,0].cumsum().sum() / totalLosses\n\n\tginiSum -= (len(actual) + 1) / 2.\n\treturn giniSum / len(actual)\n \ndef gini_normalized(a, p):\n\treturn gini(a, p) / gini(a, a)","cell_type":"code","metadata":{"_cell_guid":"5dfe8b2d-ba4c-46c9-bf10-a1e716286f33","collapsed":true,"_uuid":"878662f2d082bc7b94ca94f63b178d561b562ce2"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"634ff09f-fd14-41fd-887c-a5ae8238ccf8","_uuid":"468b84f15d9289e131d79bbd854d245ff42a3c35"},"source":"### 1.b reset function for the tensorflow graph\nSince we will be running multiple models in this notebook, we need to reset the tensorflow graph between runs so that the various parts aren't erroneously linked together. "},{"outputs":[],"source":"\n#for stability\ndef reset_graph(seed=42):\n    tf.reset_default_graph()\n    tf.set_random_seed(seed)\n    np.random.seed(seed)\n\n\nreset_graph()","cell_type":"code","metadata":{"_cell_guid":"7b28d513-d0c0-4a1c-a4a6-f8e303999517","collapsed":true,"_uuid":"ce2c60d10c32d7fc94f1af0cf42ff90cad97e68a"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"eb44edc1-6795-40d6-8d5d-eb750fdd2cdc","_uuid":"f45154d46b0625cdde93bb6efc40ecb778b3b925"},"source":"### 1.c Load the data, split categoricals, clean the data and standardize scale\n\nTo keep things chronological, this is how I first went about importing the data. Note that I do not even look at the number of 0s and the number of 1s in the training data! This mistake would come to bite me in the butt and cause the training to fail.\nWhat happens here is that the data is loaded, the y is split off from the training dataframe and then the train and test are merged and one-hot encoded (categoricals) and scaled (numericals) as a unit. "},{"outputs":[],"source":"# Load the data\n\ntest_dat = pd.read_csv('../input/test.csv')\ntrain_dat = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')\n\ntrain_y = train_dat['target'].as_matrix()\ntrain_x = train_dat.drop(['target', 'id'], axis = 1)\ntest_dat = test_dat.drop(['id'], axis = 1)","cell_type":"code","metadata":{"_cell_guid":"504efce2-581d-4eff-a188-a83fdbaaa852","collapsed":true,"_uuid":"8c3fcdb6e045bbc9ee844e6d8e9d52582ddf32db"},"execution_count":null},{"outputs":[],"source":"#clean the data\n\nmerged_dat = pd.concat([train_x, test_dat],axis=0)\n\ncat_features = [col for col in merged_dat.columns if col.endswith('cat')]\nfor column in cat_features:\n\ttemp=pd.get_dummies(pd.Series(merged_dat[column]))\n\tmerged_dat=pd.concat([merged_dat,temp],axis=1)\n\tmerged_dat=merged_dat.drop([column],axis=1)\n\nnumeric_features = [col for col in merged_dat.columns if '_calc_' in  str(col)]\nnumeric_features = [col for col in numeric_features if '_bin' not in str(col)]\n\nscaler = StandardScaler()\nscaled_numerics = scaler.fit_transform(merged_dat[numeric_features])\nscaled_num_df = pd.DataFrame(scaled_numerics, columns =numeric_features )\n\n\nmerged_dat = merged_dat.drop(numeric_features, axis=1)\n\n\nmerged_dat = np.concatenate((merged_dat.values,scaled_num_df), axis = 1)\n\n\ntrain_x = merged_dat[:train_x.shape[0]]\ntest_dat = merged_dat[train_x.shape[0]:]\n\n\ntrain_x = train_x.astype(np.float32)\ntest_dat = test_dat.astype(np.float32)","cell_type":"code","metadata":{"_cell_guid":"c69d3c42-3cca-446d-8c99-dd3c0fa44380","collapsed":true,"_uuid":"328c6e1be21d2dc041fe714eeba47819eac0c45d"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"4267c34d-0e26-4eab-a90b-a43d896d5f78","_uuid":"ce4b1d35580fe8b552ce53ad4f513f1c12918641"},"source":"### 1.d Designing the deep neural network\n\nTo make the network I've used the tf.layers API which lets you define the makeup in a given layer of the neural network very easily. Here, the input for any layer is always the variable name given to the previous layer. The second thing passed in is the number of neurons, followed by some hyperparamater arguments (discussed below).\n\nNotes on the components I've used:\n- This neural network is designed using 4 fully connected hidden layers, a batch normalization layer and an output layer with a sigmoid activation function (so that useful probability predictions are generated). \n- The batch normalization applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1 (effectively centering the outputs of the previous layer). \n- Throughout the network the rectified linear unit (ReLU) activation function(https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) is used, along with an He Kernel initializer (https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf). \n"},{"outputs":[],"source":"num_inputs = train_x.shape[1]\nlearning_rate = 0.1\nnum_classes = 2\nn_hidden1 = 100\nn_hidden2 = 400\nn_hidden3 = 200\nn_hidden4 = 100\ndropout = 0.3\n","cell_type":"code","metadata":{"_cell_guid":"700e18ae-e93f-453e-b31a-828e5a266ad7","collapsed":true,"_uuid":"9c3e93c4d40fd4fddb616f1dd9bf6b833daf8f3e"},"execution_count":null},{"outputs":[],"source":"X = tf.placeholder(tf.float32, shape=(None, num_inputs), name=\"X\")\ny = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n\n\nwith tf.variable_scope('ClassNet'):\n\n\the_init = tf.contrib.layers.variance_scaling_initializer()\n\n\ttraining = tf.placeholder_with_default(False, shape=(), name='training')\n\n\thidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n\t\t\t\t\t\t\t  kernel_initializer=he_init, name=\"hidden1\")\n\n\tbn1 = tf.layers.batch_normalization(hidden1, training = training, momentum = 0.9)\n\n\thidden2 = tf.layers.dense(bn1, n_hidden2, activation=tf.nn.relu,\n\t\t\t\t\t\t\t  kernel_initializer=he_init, name=\"hidden2\")\n\n\thidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu,\n\t\t\t\t\t\t\t  kernel_initializer=he_init, name=\"hidden3\")\n\n\thidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n\t\t\t\t\t\t\t  kernel_initializer=he_init, name=\"hidden4\")\n\n\tfc1 = tf.layers.dropout(hidden4, rate=dropout)\n\n\tlogits = tf.layers.dense(fc1, num_classes, activation=tf.nn.sigmoid)\n\t","cell_type":"code","metadata":{"_cell_guid":"240951f0-29d4-40cc-ac82-c9bfb83d8565","collapsed":true,"_uuid":"140646fe3c5480e161e5d7c8d5c51b1db2ae667d"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"27f0548b-4046-4f12-babe-008b6c5ee346","_uuid":"96d47563494e5e54d28d08f03686ec864d5031f7"},"source":"With the neural network graph defined, the next this we need to do is define the methods used to calculate loss, to train the model, and to evaluate the model. These are all shown below. With all of the scopes defined we can initialize the network and supporting tf functions."},{"outputs":[],"source":"with tf.name_scope(\"loss\"):\n\txentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n\tloss = tf.reduce_mean(xentropy, name=\"loss\")\n","cell_type":"code","metadata":{"_cell_guid":"073bd515-7009-4e79-9c23-d8961fd29f08","collapsed":true,"_uuid":"88b878621d4c9b58904488d351d60edbcdc60f4b"},"execution_count":null},{"outputs":[],"source":"with tf.name_scope(\"train\"):\n\toptimizer = tf.train.GradientDescentOptimizer(learning_rate)\n\ttraining_op = optimizer.minimize(loss)\n","cell_type":"code","metadata":{"_cell_guid":"f7868418-db26-451c-b165-a89f1d7948b1","collapsed":true,"_uuid":"d6c0a919590f6afcef5e13de00b9d4329ff5786d"},"execution_count":null},{"outputs":[],"source":"with tf.name_scope(\"eval\"):\n\tcorrect = tf.nn.in_top_k(logits, y, 1)\n\taccuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n","cell_type":"code","metadata":{"_cell_guid":"c01ee2c0-be4d-452b-ae84-e52b19406f8e","collapsed":true,"_uuid":"adeae18f7c1703fb3f662dadfec0baf4c930f5e8"},"execution_count":null},{"outputs":[],"source":"init = tf.global_variables_initializer()\n#saver = tf.train.Saver()\n\n","cell_type":"code","metadata":{"_cell_guid":"511cea00-17ad-4881-bde7-641463ed130b","collapsed":true,"_uuid":"da1a8df239e20b25b3867a779cbfdfe2563328ca"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"eec06073-cdcb-49dd-b8a7-de22700dd5ef","_uuid":"00ba25f0f72198e7e46bf903b86fb61278aa22de"},"source":"# 2. The first attempt at training the network\n\n\nI've defined n_epochs = 20 for brevity's sake, as on further iterations the flatline in the GINI NORM score persists.\nAs you can see I here just pass all the training data into the model and leave it to run, note the scores and how they are changing from epoch to epoch, we aren't getting significant improvements to the final score!\n\n### Train the model"},{"outputs":[],"source":"n_epochs = 20\n\nwith tf.Session() as sess:\n\tinit.run()\n\tfor epoch in range(n_epochs):\n\t\tsess.run(training_op, feed_dict={X: X_train, y: y_train})\t\n\t\tacc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n\t\tacc_test = accuracy.eval(feed_dict={X: X_val,\n\t\t\t\t\t\t\t\t\t\t\ty: y_val})\n\n\t\t###below is the new GINI test.\n\t\tprob_test = logits.eval(feed_dict={X: X_val,\n\t\t\t\t\t\t\t\ty: y_val})\n\t\t#switched from outputs to logits\n\t\tgini_n = gini_normalized(y_val, prob_test[:,1])\n\n\t\tprint(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test, \n\t\t\t\"\\nGINI NORM:\", gini_n)\n\t\n\tsave_path = saver.save(sess, \"./cams_model_final.ckpt\")\n\n","cell_type":"code","metadata":{"_cell_guid":"255f75b8-221d-4fa4-a522-72e746741452","collapsed":true,"_uuid":"b74cb6b8eb12e8e0daea2c3bc402c9e123785b1e"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"a35ad073-2b4e-4bd3-bcdc-9b4d24813938","_uuid":"631067c5f8828699fdf5c9408a2c78997cb73543"},"source":"# 3. Why is this not working ?!?\n\n\nWithout even evaluating on the test data we can see that this is not working! The GINI NORM scores flounder around 0.03 and considering that the leader board has scores in the 0.289 range recorded this tells us that it is way way off base! So why is the accuracy improving but the gini score flatlined? Well I asked this same question (https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/43282) and was politely informed in the discussion section that the issue is that I have completely forgotten to consider the distribution of the two classes in the data! Which is a bonehead move on my part.  96%+ of the training data is 0s.... so by just predicting a 0 each time I would be correct 96% of the time. This is no good because we cannot get an informative probability, and the order of the data relative to one another (which is what matters in the gini score) is all jumbled. For this reason accuracy isn't what we should be focusing on, this is more of a ranking task than a classification one. \n\nRodrigo Bicalho provided the a comment with a suggestion that I focused on as the best way to resolve the issue: 'There is a couple things you can try: i) Oversampling or Undersampling your sample If you do this, in your training set you might get 50%/50% split between Y=1 and Y=0. That way, your model will be less driven to predict all zeros.'\n\n\nSo by giving a higher proportion of 1s relative to the number of 0s, then the model can begin to learn the features that are informative in distinguishing 'claim' from 'no claim'. We need to balance the class distribution in the dataset and can do this through either of the two methods. Undersampling is dropping instances from the class in the higher proportion in order to restore an even ratio. Oversampling is the opposite, where we duplicate the observations of the class in the lower proportion in order to bring the two classes into an even ratio.\n\nBut which one is better, over or under sampling? There is an obvious speed advantage to undersampling as the size of the training set is decreased significantly. But this comes at a cost of throwing out lots of really useful data, so maybe it is better to increase the number of 1s and work with an expanded training set with a 50:50 ratio of 1s and 0s. I decided to try both and compare the results!"},{"cell_type":"markdown","metadata":{"_cell_guid":"51a9d75e-d5c8-4ab9-b6f3-a37f0625a073","_uuid":"0e5282cd62bc5ecbec679ef991157f82d7e2267e"},"source":"# 4. Solution A: Downsampling the 0s\n\nThis method scores: ~0.246 with epoch change below.\n\nIn order to balance the 0s and 1s through downsampling, I split the 0s and 1s into separate dataframes, then I take a random sample of the 0s dataframe that is equal to the size of the the 1s dataframe. This provides a 50:50 split of the 0s and 1s to pass in to the neural network. After training, the model scores ~0.246 on the public leaderboard which is much higher then the dud of a GINI score that we were getting from the unaltered training dataset."},{"outputs":[],"source":"test_dat = pd.read_csv('../input/test.csv')\ntrain_dat = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')\n\ntrain_dat_1s = train_dat[train_dat['target'] == 1]\n\ntrain_dat_0s = train_dat[train_dat['target'] == 0]\nkeep_0s = train_dat_0s.sample(frac=train_dat_1s.shape[0]/train_dat_0s.shape[0])\n\n\ntrain_dat = pd.concat([keep_0s,train_dat_1s],axis=0)\n\n\n","cell_type":"code","metadata":{"_cell_guid":"aee035f3-9874-4fa0-abc3-a48b059c1fca","collapsed":true,"_uuid":"417405ce6c270c34cd6bf47c8851896293c12f27"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"d81b0ed3-b558-475c-b6f4-fd302f527269","_uuid":"bad91f27e510a5cc8846f3468bac1baa11d8008a"},"source":"### Cleaning steps - unchanged"},{"outputs":[],"source":"\ntrain_y = train_dat['target'].as_matrix()\ntrain_x = train_dat.drop(['target', 'id'], axis = 1)\ntest_dat = test_dat.drop(['id'], axis = 1)\n\nmerged_dat = pd.concat([train_x, test_dat],axis=0)\n\ncat_features = [col for col in merged_dat.columns if col.endswith('cat')]\nfor column in cat_features:\n\ttemp=pd.get_dummies(pd.Series(merged_dat[column]))\n\tmerged_dat=pd.concat([merged_dat,temp],axis=1)\n\tmerged_dat=merged_dat.drop([column],axis=1)\n\nnumeric_features = [col for col in merged_dat.columns if '_calc_' in  str(col)]\nnumeric_features = [col for col in numeric_features if '_bin' not in str(col)]\n\nscaler = StandardScaler()\nscaled_numerics = scaler.fit_transform(merged_dat[numeric_features])\nscaled_num_df = pd.DataFrame(scaled_numerics, columns =numeric_features )\n\n\nmerged_dat = merged_dat.drop(numeric_features, axis=1)\n\n\nmerged_dat = np.concatenate((merged_dat.values,scaled_num_df), axis = 1)\n\n\ntrain_x = merged_dat[:train_x.shape[0]]\ntest_dat = merged_dat[train_x.shape[0]:]\n\n\ntrain_x = train_x.astype(np.float32)\ntest_dat = test_dat.astype(np.float32)\n","cell_type":"code","metadata":{"_cell_guid":"7878a704-3983-4cc0-afce-9825f795b7ab","collapsed":true,"_uuid":"61404c2e53a1c6babb46df696b95c5919878ac89"},"execution_count":null},{"outputs":[],"source":"reset_graph()\n","cell_type":"code","metadata":{"_cell_guid":"09010550-93c9-42d0-885f-050598291cd2","collapsed":true,"_uuid":"9d0500cbfc0fa52a1635e0bdbcc7ea965d95ab6a"},"execution_count":null},{"outputs":[],"source":"n_epochs = 1500\n\nwith tf.Session() as sess:\n\tinit.run()\n\tfor epoch in range(n_epochs):\n\t\tsess.run(training_op, feed_dict={X: X_train, y: y_train})\t\n\t\tacc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n\t\tacc_test = accuracy.eval(feed_dict={X: X_val,\n\t\t\t\t\t\t\t\t\t\t\ty: y_val})\n\n\t\t###below is the new GINI test.\n\t\tprob_test = logits.eval(feed_dict={X: X_val,\n\t\t\t\t\t\t\t\ty: y_val})\n\t\t#switched from outputs to logits\n\t\tgini_n = gini_normalized(y_val, prob_test[:,1])\n\n\t\tprint(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test, \n\t\t\t\"\\nGINI NORM:\", gini_n)\n\t\n#\tsave_path = saver.save(sess, \"./cams_model_final.ckpt\")\n","cell_type":"code","metadata":{"_cell_guid":"5349478d-4211-4841-81b8-8077491e7bc3","collapsed":true,"_uuid":"be1d1ca69fa0fa11c02076a6a16cde73faec63cc"},"execution_count":null},{"outputs":[],"source":"#make external predictions on the test_dat\nwith tf.Session() as sess:\n#    saver.restore(sess, \"./cams_model_final.ckpt\") # or better, use save_path\n    Z = logits.eval(feed_dict={X: test_dat}) #switched from outputs to logits\n    y_pred = Z[:,1]\n","cell_type":"code","metadata":{"_cell_guid":"b9bca28c-f043-4bd3-884f-9d239c2c6f82","collapsed":true,"_uuid":"bd744a938ce06cb6181c54e7760e655dc0ae66f4"},"execution_count":null},{"outputs":[],"source":"\n\ndnn_output = submission\ndnn_output['target'] = y_pred\n\ndnn_output.to_csv('tf_dnn_downsample.csv', index=False, float_format='%.10f')\n\n","cell_type":"code","metadata":{"_cell_guid":"ad8c310a-41fa-4dca-b1de-5a9f42619203","collapsed":true,"_uuid":"87a760b3aaff6935ea90f5bef73c0ad804672d40"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"bc360bae-a459-4598-96cb-633ef6b9c472","_uuid":"320416494a140952b339747ac8948a92a1fcaed2"},"source":"# 5. Solution B: Upsampling the 1s\n\nThis method scores: ~0.248 with epoch change below.\n\nHere we do the inverse of the downsampling, instead of subsetting the 0s, we instead up the number of 1s. Below I use a list comprehension to duplicate (and then merge) a set of 26 copies of the 1s dataframe. This brings the instances of 0s and 1s up to a 50:50 ratio for the training of the neural network"},{"outputs":[],"source":"test_dat = pd.read_csv('../input/test.csv')\ntrain_dat = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')\n\n\ntrain_dat_0s = train_dat[train_dat['target'] == 0]\n\n\ntrain_dat_1s = train_dat[train_dat['target'] == 1]\nrep_1 =[train_dat_1s for x in range(train_dat_0s.shape[0]//train_dat_1s.shape[0] )]\nkeep_1s = pd.concat(rep_1, axis=0)\n\ntrain_dat = pd.concat([keep_1s,train_dat_0s],axis=0)","cell_type":"code","metadata":{"_cell_guid":"8dd58495-a05b-4fea-b847-d798f85e9692","collapsed":true,"_uuid":"ba692e1d89a9370b3d6c3c98162954c2dad8ae15"},"execution_count":null},{"outputs":[],"source":"\ntrain_y = train_dat['target'].as_matrix()\ntrain_x = train_dat.drop(['target', 'id'], axis = 1)\ntest_dat = test_dat.drop(['id'], axis = 1)\n\nmerged_dat = pd.concat([train_x, test_dat],axis=0)\n\ncat_features = [col for col in merged_dat.columns if col.endswith('cat')]\nfor column in cat_features:\n\ttemp=pd.get_dummies(pd.Series(merged_dat[column]))\n\tmerged_dat=pd.concat([merged_dat,temp],axis=1)\n\tmerged_dat=merged_dat.drop([column],axis=1)\n\nnumeric_features = [col for col in merged_dat.columns if '_calc_' in  str(col)]\nnumeric_features = [col for col in numeric_features if '_bin' not in str(col)]\n\nscaler = StandardScaler()\nscaled_numerics = scaler.fit_transform(merged_dat[numeric_features])\nscaled_num_df = pd.DataFrame(scaled_numerics, columns =numeric_features )\n\n\nmerged_dat = merged_dat.drop(numeric_features, axis=1)\n\n\nmerged_dat = np.concatenate((merged_dat.values,scaled_num_df), axis = 1)\n\n\ntrain_x = merged_dat[:train_x.shape[0]]\ntest_dat = merged_dat[train_x.shape[0]:]\n\n\ntrain_x = train_x.astype(np.float32)\ntest_dat = test_dat.astype(np.float32)","cell_type":"code","metadata":{"_cell_guid":"87350d8c-a391-4054-b881-879b5ec266f8","collapsed":true,"_uuid":"e7c3c90a08d573b9db0d083782f1ecbd110fc111"},"execution_count":null},{"outputs":[],"source":"reset_graph()","cell_type":"code","metadata":{"_cell_guid":"1756c478-96d8-4ba1-a9ad-45007e64f720","collapsed":true,"_uuid":"70948cffb6ab74b3478ada44ff2be6d39d25aa74"},"execution_count":null},{"outputs":[],"source":"n_epochs = 1500\n\nwith tf.Session() as sess:\n\tinit.run()\n\tfor epoch in range(n_epochs):\n\t\tsess.run(training_op, feed_dict={X: X_train, y: y_train})\t\n\t\tacc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n\t\tacc_test = accuracy.eval(feed_dict={X: X_val,\n\t\t\t\t\t\t\t\t\t\t\ty: y_val})\n\n\t\t###below is the new GINI test.\n\t\tprob_test = logits.eval(feed_dict={X: X_val,\n\t\t\t\t\t\t\t\ty: y_val})\n\t\t#switched from outputs to logits\n\t\tgini_n = gini_normalized(y_val, prob_test[:,1])\n\n\t\tprint(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test, \n\t\t\t\"\\nGINI NORM:\", gini_n)\n\t\n#\tsave_path = saver.save(sess, \"./cams_model_final.ckpt\")\n","cell_type":"code","metadata":{"_cell_guid":"a038d102-d947-4af3-9c91-c05f61261855","collapsed":true,"_uuid":"8ef86685f344969915ee2bf57a0e9d09f57a2123"},"execution_count":null},{"outputs":[],"source":"#make external predictions on the test_dat\nwith tf.Session() as sess:\n#    saver.restore(sess, \"./cams_model_final.ckpt\") # or better, use save_path\n    Z = logits.eval(feed_dict={X: test_dat}) #switched from outputs to logits\n    y_pred = Z[:,1]\n","cell_type":"code","metadata":{"_cell_guid":"60682c48-1ae3-4ba0-84a4-f4c27ba87a2d","collapsed":true,"_uuid":"91339b533775f8a9f8e9c4e8422d7db010e1763f"},"execution_count":null},{"outputs":[],"source":"dnn_output = submission\ndnn_output['target'] = y_pred\n\ndnn_output.to_csv('tf_dnn_predictions_upsample.csv', index=False, float_format='%.10f')","cell_type":"code","metadata":{"_cell_guid":"e3f4ddb1-053b-4a86-a570-2994b7f016c1","collapsed":true,"_uuid":"3d0593a136cecf980ffd36a75776291aa53d0991"},"execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"4d006a35-4e3d-42fe-90bc-c28799c69a76","_uuid":"30b2666e81d3e03123732e0d07007220e8abae73"},"source":"## Conclusion\n\nSo before any hyperparamater tuning, by simply creating balanced training data from a very imbalanced training set we are able to produce a model that is fairly effective at predicting the relative likelihoods of people filing insurance claims. This has taught me the importance of assessing the data I am using, and thinking of instances beyond the obvious things such as missing data and the need to one hot encode categoricals. \n\nThe difference here between a model that is completely useless and one that is a good predictor is very small, just 3 lines of pandas dataframe manipulation in the preprocessing, but it proved to make all the difference. Over sampling and undersampling proved to be roughly equivalent, with a slightly higher LB score observed for the oversampled data. I have learned my lesson and will always check the class distribution in future classification problems that I undertake!\n\n"}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.3","pygments_lexer":"ipython3"}},"nbformat":4}