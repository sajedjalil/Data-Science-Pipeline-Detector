{"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.1","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","name":"python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1,"cells":[{"metadata":{},"source":"# Introduction\nThis kernel is ref from my kernel. [EDA+StratifiedShuffleSplit+xgboost for starter](https://www.kaggle.com/youhanlee/eda-stratifiedshufflesplit-xgboost-for-starter)\n\nI'll update this kernel soon!","cell_type":"markdown"},{"metadata":{"_cell_guid":"214470b0-a2a7-439e-bdd8-b39f5d6cf1a6","_uuid":"c0be39b81eace54a3dd2cb84dfbd4ee84d268c0e","collapsed":true},"outputs":[],"execution_count":null,"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\n\nimport seaborn as sns # visualization\nimport missingno as msno\n\nfrom sklearn.model_selection import train_test_split\n# from sklearn.cluster import MiniBatchKMeans\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nimport xgboost as xgb # Gradient Boosting\nfrom xgboost import XGBClassifier\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n# Any results you write to the current directory are saved as output","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"np.random.seed(1989)\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nprint(\"Train shape : \", train.shape)\nprint(\"Test shape : \", test.shape )","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"train.head()","cell_type":"code"},{"metadata":{"scrolled":true},"outputs":[],"execution_count":null,"source":"train.info()","cell_type":"code"},{"metadata":{"scrolled":true},"outputs":[],"execution_count":null,"source":"test.info()","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print(\"Train has these types: {}\".format(train.dtypes.unique()))\nprint(\"Test has these types: {}\".format(test.dtypes.unique()))","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"targets = train['target'].values\n# sns.set(style=\"darkgrid\")\nax = sns.countplot(x = targets)\nfor p in ax.patches:\n    ax.annotate('{:.2f}%'.format(100*p.get_height()/len(targets)), (p.get_x()+ 0.3, p.get_height()+10000))\nplt.title('Distribution of Target', fontsize=20)\nplt.xlabel('Claim', fontsize=20)\nplt.ylabel('Frequency [%]', fontsize=20)\nax.set_ylim(top=700000)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print('Id is unique.') if train.id.nunique() == train.shape[0] else print('Oh no')\nprint('Train and test sets are distinct.') if len(np.intersect1d(train.id.values, test.id.values)) == 0 else print('Oh no')\nprint('We do not need to worry about missing values.') if train.count().min() == train.shape[0] else print('Oh no')","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"train_nan = train\ntrain_nan = train_nan.replace(-1, np.NaN)\n\nmsno.matrix(df=train_nan.iloc[:, :], figsize=(20, 14), color=(0.8, 0.5, 0.2))   ","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"test_nan = test\ntest_nan = test_nan.replace(-1, np.NaN)\n\nmsno.matrix(df=test_nan.iloc[:, :], figsize=(20, 14), color=(0.8, 0.5, 0.2))   ","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"# Extract columns with null data\ntrain_nan = train_nan.loc[:, train_nan.isnull().any()]\ntrain_nan_columns = train_nan.columns\n\ntest_nan = test_nan.loc[:, test_nan.isnull().any()]\ntest_nan_columns = test_nan.columns","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print('Columns \\t Number of NaN')\nfor column in train_nan.columns:\n    print('{}:\\t {}'.format(column,len(train_nan[column][np.isnan(train_nan[column])])))","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print('Columns \\t Number of NaN')\nfor column in test_nan.columns:\n    print('{}:\\t {}'.format(column,len(test_nan[column][np.isnan(test_nan[column])])))","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"feature_list = list(train.columns)\ndef groupFeatures(features):\n    features_bin = []\n    features_cat = []\n    features_etc = []\n    for feature in features:\n        if 'bin' in feature and 'calc' not in feature:\n            features_bin.append(feature)\n        elif 'cat' in feature:\n            features_cat.append(feature)\n        elif 'id' in feature or 'target' in feature:\n            continue\n        else:\n            features_etc.append(feature)\n    return features_bin, features_cat, features_etc\n\nfeature_list_bin, feature_list_cat, feature_list_etc = groupFeatures(feature_list)\nprint(\"# of binary feature : \", len(feature_list_bin))\nprint(\"# of categorical feature : \", len(feature_list_cat))\nprint(\"# of other feature : \", len(feature_list_etc))","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"colormap = \"jet\"\nplt.figure(figsize=(16, 12))\nplt.title('Pearson correlation of continuous features', y=1.05, size=15)\ndata = train.drop(['id'], axis=1)\nsns.heatmap(data.corr(),linewidths=0.1,vmax=1.0, vmin=-1.0, square=True, cmap=colormap, linecolor='white')","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"feature_list_calc = []\nfeature_list_without_calc = []\nfor feature in train.columns:\n    if 'calc' in feature or 'target' in feature:\n        feature_list_calc.append(feature)\n    else:\n        feature_list_without_calc.append(feature)\n        \ntrain_without_calc = train.drop(feature_list_calc, axis=1).drop(['id'], axis=1)\ntrain_with_calc = train.drop(feature_list_without_calc, axis=1)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"colormap = \"jet\"\nplt.figure(figsize=(20, 20))\nplt.title('Pearson correlation of continuous features', y=1.05, size=15)\nsns.heatmap(train_with_calc.corr(),linewidths=0.1,\n            vmax=1.0, vmin=-1.0, square=True, cmap=colormap, linecolor='white')","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"colormap = \"jet\"\nplt.figure(figsize=(20, 20))\nplt.title('Pearson correlation of continuous features', y=1.05, size=15)\nsns.heatmap(train_without_calc.corr(),linewidths=0.1,\n            vmax=1.0, vmin=-1.0, square=True, cmap=colormap, linecolor='white')","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"def TrainTestHistogram(train, test, feature):\n    fig, axes = plt.subplots(len(feature), 2, figsize=(10, 40))\n    fig.tight_layout()\n\n    left  = 0  # the left side of the subplots of the figure\n    right = 0.9    # the right side of the subplots of the figure\n    bottom = 0.1   # the bottom of the subplots of the figure\n    top = 0.9      # the top of the subplots of the figure\n    wspace = 0.3   # the amount of width reserved for blank space between subplots\n    hspace = 0.7   # the amount of height reserved for white space between subplot\n\n    plt.subplots_adjust(left=left, bottom=bottom, right=right, \n                        top=top, wspace=wspace, hspace=hspace)\n    count = 0\n    for i, ax in enumerate(axes.ravel()):\n        if i % 2 == 0:\n            title = 'Train: ' + feature[count]\n            ax.hist(train[feature[count]], bins=30, normed=False)\n            ax.set_title(title)\n#             ax.text(0, 1.2, train[feature[count]].head(), horizontalalignment='left',\n#                     verticalalignment='top', style='italic',\n#                 bbox={'facecolor':'red', 'alpha':0.2, 'pad':10}, transform=ax.transAxes)\n        else:\n            title = 'Test: ' + feature[count]\n            ax.hist(test[feature[count]], bins=30, normed=False)\n            ax.set_title(title)\n#             ax.text(0, 1.2, test[feature[count]].head(), horizontalalignment='left',\n#                     verticalalignment='top', style='italic',\n#                 bbox={'facecolor':'red', 'alpha':0.2, 'pad':10}, transform=ax.transAxes)\n            count = count + 1","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"TrainTestHistogram(train, test, feature_list_bin)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"TrainTestHistogram(train, test, feature_list_cat)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"TrainTestHistogram(train, test, feature_list_etc)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"left  = 0  # the left side of the subplots of the figure\nright = 0.9    # the right side of the subplots of the figure\nbottom = 0.1   # the bottom of the subplots of the figure\ntop = 0.9      # the top of the subplots of the figure\nwspace = 0.3   # the amount of width reserved for blank space between subplots\nhspace = 0.7   # the amount of height reserved for white space between subplot\n\nfig, axes = plt.subplots(13, 2, figsize=(10, 40))\nplt.subplots_adjust(left=left, bottom=bottom, right=right, \n                    top=top, wspace=wspace, hspace=hspace)\n\nfor i, ax in enumerate(axes.ravel()):\n    title = 'Train: ' + feature_list_etc[i]\n    ax.hist(train[feature_list_etc[i]], bins=20, normed=True)\n    ax.set_title(title)\n    ax.text(0, 1.2, train[feature_list_etc[i]].head(), horizontalalignment='left',\n            verticalalignment='top', style='italic',\n       bbox={'facecolor':'red', 'alpha':0.2, 'pad':10}, transform=ax.transAxes)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"# For ordinal group\nordianal_features = ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01',\n                    'ps_reg_02', 'ps_car_11', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03',\n                    'ps_calc_04', 'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08',\n                    'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13',\n                    'ps_calc_14']\n\ncontinuous_features = ['ps_reg_03', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15']","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"ordinal_feature_with_calc = [feature for feature in ordianal_features if 'calc' in feature]\nordinal_feature_without_calc = [feature for feature in ordianal_features if 'calc' not in feature]","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"sns.set(font_scale=1.5)\nfor i in range(len(feature_list_cat)):\n    feature_number = i\n    temp_data = train.loc[train[feature_list_cat[feature_number]] != -1]\n    g = sns.factorplot(x=feature_list_cat[feature_number], y=\"target\", data=temp_data, kind=\"bar\",\n                   size=6, palette = \"muted\")\n    g = g.set_ylabels(\"Claim probability\")","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"sns.set(font_scale=1.5)\nfor i in range(len(feature_list_bin)):\n    feature_number = i\n    temp_data = train.loc[train[feature_list_bin[feature_number]] != -1]\n    g = sns.factorplot(x=feature_list_bin[feature_number], y=\"target\", data=temp_data, kind=\"bar\",\n                   size=6, palette = \"muted\")\n    g = g.set_ylabels(\"Claim probability\")","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"sns.set(font_scale=1.5)\nfor i in range(len(ordinal_feature_with_calc)):\n    feature_number = i\n    temp_data = train.loc[train[ordinal_feature_with_calc[feature_number]] != -1]\n    g = sns.factorplot(x=ordinal_feature_with_calc[feature_number], y=\"target\", data=temp_data, kind=\"bar\",\n                   size=6, palette = \"muted\")\n    g = g.set_ylabels(\"Claim probability\")","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"sns.set(font_scale=1.5)\nfor i in range(len(ordinal_feature_without_calc)):\n    feature_number = i\n    temp_data = train.loc[train[ordinal_feature_without_calc[feature_number]] != -1]\n    g = sns.factorplot(x=ordinal_feature_without_calc[feature_number], y=\"target\", data=temp_data, kind=\"bar\",\n                   size=6, palette = \"muted\")\n    g = g.set_ylabels(\"Claim probability\")","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"for feature in continuous_features:\n    g = sns.FacetGrid(train, col='target')\n    g = g.map(sns.distplot, feature)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"def make_overlap_histogram(df, feature, target):\n    fig, ax = plt.subplots(figsize=(6, 6))\n    g = sns.kdeplot(df[feature][(df[target] == 0) & (df[feature] != -1)], color=\"Red\", shade = True)\n    g = sns.kdeplot(df[feature][(df[target] == 1) & (df[feature] != -1)], ax=g, color=\"Blue\", shade= True)\n    g.set_xlabel(feature)\n    g.set_ylabel(\"Frequency\")\n    g = g.legend([\"Not claim\",\"Claim\"])","cell_type":"code"},{"metadata":{"scrolled":false},"outputs":[],"execution_count":null,"source":"for feature in continuous_features:\n    make_overlap_histogram(train, feature, 'target')","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"def show_skew(df, feature):\n    fig, ax = plt.subplots(figsize=(8, 8))\n    g = sns.distplot(train[feature][train[feature] != -1], color=\"m\", label=\"Skewness : %.2f\"%(train[feature].skew()))\n    g = g.legend(loc=\"best\")","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"dataset = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\ndataset = dataset.replace(-1, np.NaN)\ndataset.tail()","cell_type":"code"},{"metadata":{"scrolled":false},"outputs":[],"execution_count":null,"source":"for feature in continuous_features:\n    show_skew(dataset, feature)","cell_type":"code"},{"metadata":{"scrolled":false},"outputs":[],"execution_count":null,"source":"for feature in continuous_features:\n    fig, ax = plt.subplots(figsize=(6, 6))\n    temp = dataset[feature].map(lambda i: np.log(i) if i > 0 else 0)\n    g = sns.distplot(temp[temp != -1], color=\"m\", label=\"Skewness : %.2f\"%(temp.skew()))\n    g = g.legend(loc=\"best\")","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"feature_list_not_using = ['ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_08', 'ps_calc_09']\nfeature_list_log_function = ['ps_car_13']","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"dataset = dataset.drop(feature_list_not_using, axis=1)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"dataset['ps_car_13'] = dataset['ps_car_13'].map(lambda i: np.log(i) + 1 if i > 0 else 0)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"for feature in (set(train_nan_columns).union(set(test_nan_columns))):\n    if 'cat' in feature or 'bin' in feature:\n        # For categorical and binary features with postfix, substitue null values with the most frequent value to avoid float number.\n        dataset[feature].fillna(dataset[feature].value_counts().idxmax(), inplace=True)\n    elif feature in continuous_features:\n        dataset[feature].fillna(dataset[feature].median(), inplace=True)\n    elif feature in ordianal_features:\n        # For ordinal features which was assumed, substitue null values with the most frequent value to avoid float number.\n        dataset[feature].fillna(dataset[feature].value_counts().idxmax(), inplace=True)\n    else:\n        print(feature)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"msno.matrix(df=dataset.iloc[:, :], figsize=(20, 14), color=(0.8, 0.5, 0.2))  ","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"for feature in feature_list_cat:\n    print(\"{}: \\t{}\".format(feature, dataset[feature].value_counts().shape[0]))","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"def oneHotEncode_dataframe(df, features):\n    for feature in features:\n        if df[feature].value_counts().shape[0] < 8:\n            temp_onehot_encoded = pd.get_dummies(df[feature])\n            column_names = [\"{}_{}\".format(feature, x) for x in temp_onehot_encoded.columns]\n            temp_onehot_encoded.columns = column_names\n            df = df.drop(feature, axis=1)\n            df = pd.concat([df, temp_onehot_encoded], axis=1)\n        else:\n            continue\n    return df","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"dataset = oneHotEncode_dataframe(dataset, feature_list_cat)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"x_train = dataset.loc[:train.shape[0]-1, :]\nx_test = dataset.loc[train.shape[0]:, :]","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"x_train.tail()","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"x_test.head()","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"# Define the gini metric - from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\ndef gini(actual, pred, cmpcol = 0, sortcol = 1):\n    assert( len(actual) == len(pred) )\n    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n    totalLosses = all[:,0].sum()\n    giniSum = all[:,0].cumsum().sum() / totalLosses\n    \n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\n \ndef gini_normalized(a, p):\n    return gini(a, p) / gini(a, a)\n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score","cell_type":"code"},{"metadata":{},"source":"I will add ensemble method on this part. \nComing soon :).","cell_type":"markdown"}]}