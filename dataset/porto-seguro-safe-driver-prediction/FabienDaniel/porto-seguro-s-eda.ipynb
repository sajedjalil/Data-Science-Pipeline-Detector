{"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","version":"3.6.3","name":"python"}},"nbformat_minor":1,"cells":[{"source":"# Porto Seguro's EDA\n_F. Daniel (September 2017)_\n___\n\nThe aim of this notebook is to provide a quick overview of the content of the dataset. In particular, this dataset contains a reasonnable number of features but none of them is directly related to a well defined quantity (as for example the age of the insurance older, the number of years since he obtained its driving licence, ...). Hence, the analysis will be performed in a _blind_ manner and without any kind of _a priori_ concerning the content of the variables. However, a first step is to understand the behaviour of the categorical (which are all tagged with an integer numbering) and numerical variables.","metadata":{"_uuid":"1bf0ca80e51acec06329381b3d686b850f04c24b","_cell_guid":"befc22e3-a736-46b4-adeb-14c11b04f01b"},"cell_type":"markdown"},{"source":"I first load the packages:","metadata":{"_uuid":"429ffc3d6a6b1f578cce36b40e733cd2cbe24094","_cell_guid":"7d3af1c5-6349-497b-810d-213ac3940cb2"},"cell_type":"markdown"},{"source":"import numpy as np \nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.options.display.max_columns = 100\nplt.rcParams[\"patch.force_edgecolor\"] = True\nplt.style.use('fivethirtyeight')\nmpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n%matplotlib inline\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"d57b099227a23b80fd39e9b6a67429d2487ad254","_cell_guid":"4048b23a-0284-4feb-8325-692ac2dc51a2","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"and the import the dataframes:","metadata":{"_uuid":"1283a4e3fca543badacda118615aeec2bd09de9f","_cell_guid":"fd7cbefd-782e-479b-869c-a61c75020e36"},"cell_type":"markdown"},{"source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')","outputs":[],"metadata":{"_kg_hide-input":false,"_uuid":"b064e77076d3a6f29e36f3db1f9368fe606ab898","_cell_guid":"88e21add-9b10-455b-b8eb-dbf60fd5f915","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Before continuing, I put aside the **id** and **target** variables:","metadata":{"_uuid":"daf0c7bb3d3c3f00a4cd9b40961141594e3335d2","_cell_guid":"da42033a-f471-46c9-bd2e-680a77380c8a"},"cell_type":"markdown"},{"source":"df_targets = df_train[['id', 'target']]\ndf_train.drop(['id', 'target'], axis = 1, inplace = True)","outputs":[],"metadata":{"_uuid":"897adf0ea72c3613a06ea4ab93990e109a693e26","_cell_guid":"9dc80b01-139e-48fa-b0e5-80f04b5bfca3","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"## 1. Variables and null values","metadata":{"_uuid":"21652dc06d6981f871aafc5361d34a3fa2d3d36b","_cell_guid":"9775fdad-4ba8-4088-a4bd-5425bef5dbb0"},"cell_type":"markdown"},{"source":"First, I have a look at the variables in the dataframe and to the number of missing values. The setting of the dataset is such that undefined values are set to `-1`. I switch to the standard nomenclature and convert the `-1` values to `np.nan` (skipping this step would not allow to use `pandas` facilities such like the  `isnull()`method that allows to quickly access undefined quantities). I define the `get_info()`function  that outputs the data types of each variable, the number of null values and their percentage with rexpect to the total number of entries:","metadata":{"_uuid":"fa2bb4aca8e873dd022ef186ae82ed6a9bebd81d","_cell_guid":"eeeb21b9-6d4f-4a12-bf97-b6ebe3fa2de3"},"cell_type":"markdown"},{"source":"def get_info(df):\n    \"\"\"\n    Gives some infos on columns types and number of null values\n    \"\"\"\n    print('dataframe dimensions:', df.shape)\n    tab_info=pd.DataFrame(df.dtypes).T.rename(index={0:'column type'})\n    df.replace({-1:np.nan}, inplace = True) # TAG NULL VALUES\n    tab_info=tab_info.append(pd.DataFrame(df.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n    tab_info=tab_info.append(pd.DataFrame(df.isnull().sum()/df.shape[0]*100)\n                             .T.rename(index={0:'null values (%)'}))\n    return tab_info","outputs":[],"metadata":{"_kg_hide-input":false,"_uuid":"328be9a88e8dca3301b89366d9654613bc7018a3","_cell_guid":"88b32b2c-c516-4d6f-832d-41150861a66c","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"I then look at the training set:","metadata":{"_uuid":"d755fb0d97a74ea3cca78e8cc53acc66a8da69be","_cell_guid":"5df83d7e-ae5f-4e6a-8868-83680338b544"},"cell_type":"markdown"},{"source":"tab_info = get_info(df_train)\ntab_info","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"afbbd4bd93e42c68cacd39d27c7c97d2266f9ef1","scrolled":false,"_cell_guid":"c8cdc2e3-f3fd-49a3-bc5f-6ec36a977319","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"and at the test set:","metadata":{"_uuid":"017536dca4b4352fc8420f92c91d4fe6d9a231c7","_cell_guid":"42e897b1-d784-4233-a14e-89753694f8ba"},"cell_type":"markdown"},{"source":"get_info(df_test)","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"0eb7852477ce82d15bd15cdcdfcdfe94b1baf477","_cell_guid":"eabc189d-eff7-4a5c-8155-ab666e55d9fd","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Now, we can have a look at the percentage of missing values in each variable:","metadata":{"_uuid":"ad518f59beb2c11676a3a8c0c590e5ab5a09a7de","_cell_guid":"cdb94fa6-9646-4e80-bac5-08fe1777dcae"},"cell_type":"markdown"},{"source":"tab_info = tab_info.T.reset_index()\ntab_info = tab_info.sort_values('null values (%)').reset_index(drop = True)\n#_____________________________________\ny_axis  = tab_info['null values (%)'] \nx_label = tab_info['index']\nx_axis  = tab_info.index\n\nfig = plt.figure(figsize=(11, 4))\nplt.xticks(rotation=80, fontsize = 14)\nplt.yticks(fontsize = 13)\nplt.bar(x_axis, y_axis)\nplt.xticks(x_axis, x_label, fontsize = 12)\nplt.title('Missing values (%)', fontsize = 18);","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"c5e3c63bd7aa2b9fad83157b77a78c76453f1c44","_cell_guid":"8264f47c-fef8-4a55-8fb6-6b0d49e24497","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"The **target** variable, which is to be predicted, indicate wether a claim was filled or not. \n\nApart from this variable, the dataframe contains 58 variables:\n- **id**: the identifiant of the user\n- 57 columns named **ps\\_tag1\\_NUM(\\_tag2)** with:\n    * tag1 $\\in$ \\{ind, reg, car, calc \\}\n    * NUM $\\in$ [1:20]\n    * tag2 $\\in$ \\{bin, cat \\} indicate respectively binary and categorical features. This tag is optional.\n  \nThe tables given above shows that there are a few undefined values, in particular for the following variables:\n- **ps_reg_03**: 18% \n- **ps_car_03_cat**: 69%\n- **ps_car_05_cat**: 45%\n- **ps_car_14**: 7%","metadata":{"_uuid":"6197e6cca3dd032b1ae5b5455f32296213d29495","_cell_guid":"134d4799-2345-4822-937e-2caa9143d8e1"},"cell_type":"markdown"},{"source":"____\n## 2. Categorical values","metadata":{"_kg_hide-input":false,"_uuid":"9748ae48609bdc15468ddc30762b96e23627ffa5","_cell_guid":"ec7436c6-85e1-4281-9d61-fd2008860dc0"},"cell_type":"markdown"},{"source":"There a few categorical variables indexed with the **tag** postfix:","metadata":{"_uuid":"46ba2d2218c79840a4a80f98e12ea7ce7ceec72d","_cell_guid":"d271f872-ee5d-4ccc-aee7-4eb9d46fd8b4"},"cell_type":"markdown"},{"source":"nb = sum([\"cat\" in s for s in df_train.columns])\nprint('categorical variables: {} '.format(nb))","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"ac0caf85ae70d2738ea7623c84b4361cedd31b19","scrolled":true,"_cell_guid":"15a97adf-60ad-4291-aa33-d837ca990cf1","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"These variables contain integers. Below, I represent the number of categories in each of these variables:","metadata":{"_kg_hide-input":false,"_uuid":"accaa970ea3c11afe52bcfe562a86c26d40b959c","_cell_guid":"97bcf098-1ab8-4d3e-b1c9-c38b82eff3ae"},"cell_type":"markdown"},{"source":"ind = 0\nfor col in df_train.columns:\n    if \"cat\" not in col: continue\n    ind += 1\n    fig = plt.figure(1, figsize=(11,30))\n    ax1 = fig.add_subplot(nb,1,ind)    \n    x_axis = list(df_train[col].value_counts().index)\n    y_axis = list(df_train[col].value_counts())\n    x_label = list(map(int,x_axis))\n    if len(x_label) > 50:\n        x_label = [s if s%2 == 0 else '' for i,s in enumerate(x_label)]\n    plt.xticks(x_axis, x_label)\n    ax1.bar(x_axis, y_axis, align = 'center', label = col)\n    plt.legend(prop={'size': 14})\n    if ind == nb: break","outputs":[],"metadata":{"_kg_hide-input":false,"_uuid":"7f9110d88bdbc9cf3a9f46da0ebbc6fba4878439","_cell_guid":"5fa052df-dfae-4cc4-a95a-7c334eee0dba","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"## 3. Numerical variables","metadata":{"_uuid":"4b8d7f6b2bfeff1bf3c27841290d2a149f6d04d8","_cell_guid":"dd218f18-b0b7-4a01-8903-2407c0a08de9","collapsed":true},"cell_type":"markdown"},{"source":"nb  = sum([(\"cat\" not in s) and ('bin' not in s) for s in df_train.columns])\nprint('numerical variables: {} '.format(nb))","outputs":[],"metadata":{"_uuid":"eb3ace203e808cccaf03d804c03c608e3f87a735","scrolled":true,"_cell_guid":"35d8f4ad-1c2e-40c6-bb6d-8d02b353cde8","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"### 3.1 Distributions","metadata":{"_uuid":"66e9d1a031504d35d0454f713a7016f5a796ca10","_cell_guid":"d87a5913-7c2c-4813-bde9-c4e4830d97b3"},"cell_type":"markdown"},{"source":"#### 3.1.1 Variables with the **calc** tag\n\nBy looking at the numerical variables, we can distinguish a few different kinds of distributions. First, if we consider the variables indexed with the **calc** tag, we see that we have either uniform distributions:","metadata":{"_uuid":"871dd6b3fe2b334390c2880e780cd6f02e27dbf0","_cell_guid":"30faacd3-d7bf-4d8f-a0bd-3d260bf51c1c"},"cell_type":"markdown"},{"source":"# uniform distributions:\nlist_cols_uniform = ['ps_calc_01', 'ps_calc_02', 'ps_calc_03']\n#____________________________\nind = 0\nfor col in list_cols_uniform:\n    ind += 1\n    fig = plt.figure(1, figsize=(11,3))\n    ax1 = fig.add_subplot(1, 3, ind)    \n    sns.distplot(df_train[col].dropna(), kde=False  )        \n    if ind == nb: break\nplt.suptitle('Uniform distributions');","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"b521d48a316aee4bba1e2fa3b4ec3f7e52a9dfe8","_cell_guid":"5f6bfc39-dc83-4634-b082-1f3fecfeddb1","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"or distributions that have a more shallow shape.","metadata":{"_uuid":"2d53f4f3131c69542c35f6de6ee90d307b40cd72","_cell_guid":"4736fc96-b5df-4f26-a75a-e47529f9aa2b"},"cell_type":"markdown"},{"source":"# shallow distributions: \nlist_cols_shallow = ['ps_car_13', 'ps_reg_03', 'ps_calc_10', 'ps_calc_14', 'ps_calc_11',\n                     'ps_ind_03', 'ps_calc_13', 'ps_calc_06', 'ps_calc_07', 'ps_calc_07',\n                     'ps_calc_09', 'ps_calc_12', 'ps_calc_04', 'ps_calc_05', 'ps_car_11']\n#____________________________\nind = 0\nfor col in list_cols_shallow:\n    ind += 1\n    fig = plt.figure(1, figsize=(10,15))\n    ax1 = fig.add_subplot(5, 3, ind)    \n    sns.distplot(df_train[col].dropna(), kde=False  )        \n    if ind == nb: break\nfig.suptitle('Shallow distributions')\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"9a4c3cae0ca76a6e7dc702e1f352387cd31905c3","scrolled":true,"_cell_guid":"e2789f47-efc8-4f08-852a-aed829a87bc9","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"Given the regularity of the distributions found for these variables (and assuming that the **calc** tag carry some meaning), we may assume that the above variables come from some statistical model.\n\n#### 3.1.2 Empirical distributions\n\nThe other numerical variables in the dataframe do not show such smooth shapes and are probably obtained through a census:","metadata":{"_uuid":"a7dcefd6381813a9a1245e5a53ccb291902b16b9","_cell_guid":"766c73bf-97f5-4dfa-990a-85a2d1e226f9"},"cell_type":"markdown"},{"source":"list_cols_other   = ['ps_ind_01', 'ps_ind_15', 'ps_reg_01', 'ps_reg_02', 'ps_car_12',\n                     'ps_car_14', 'ps_car_15', 'ps_ind_14', 'ps_car_12']\n#____________________________\nind = 0\nfor col in list_cols_other:\n    ind += 1\n    fig = plt.figure(1, figsize=(10,10))\n    ax1 = fig.add_subplot(3, 3, ind)    \n    sns.distplot(df_train[col].dropna(), kde=False  )        \n    if ind == nb: break\nfig.suptitle('Empirical distributions')\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])\n","outputs":[],"metadata":{"_kg_hide-input":true,"_uuid":"26029b0c3736cf93de0b770bfb7da82522149c31","_cell_guid":"46f29539-ccdb-4610-a046-18c4097fb40c","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"### 3.2 Correlation coefficients","metadata":{"_uuid":"b241a4c51ae0ae4e358b014fc54f6bfa6191daa4","_cell_guid":"37e4c6d4-fa3c-494a-9ab1-846ace257c7c"},"cell_type":"markdown"},{"source":"For some reason, the coeffs I calculate seem differents than the one given in other notebooks. I have to dig this.","metadata":{"_uuid":"ba72d1b4504765d1a4d4e1f4780045dfdb429f95","_cell_guid":"c07602da-aa49-4ae2-be72-a9557f5bedf4"},"cell_type":"markdown"},{"source":"list_cols = []\nfor col in df_train.columns:\n    if 'bin' not in col and 'cat' not in col:\n        list_cols.append(col)\n\n        \ndf_corr = df_train.copy(deep=True)\ndf_corr['target'] = df_targets['target']\ncorrmat = df_corr[list_cols + ['target']].corr()","outputs":[],"metadata":{"_uuid":"bd371f2ccf5899d84042b9bb11f8eba381f15074","_cell_guid":"3c12753b-0d2c-406e-8c23-ad755fc586ff","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"df_corr[list_cols + ['target']].dropna(how='any').corr()[:5]","outputs":[],"metadata":{"_uuid":"7d10a1866809b9145de35cd442da8bf593082eb4","_cell_guid":"51ddb95b-c41b-468c-ba0c-a95e68a22627","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"corrmat[:5]","outputs":[],"metadata":{"_uuid":"2b66dd91085f9b4c08ec88a312d764776f69eff3","_cell_guid":"604dfe1b-6d61-4119-9c1c-4dda04c3e35a","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"f, ax = plt.subplots(figsize=(12, 9))\nk = 15 # number of variables for heatmap\ncols = corrmat.nlargest(k, 'ps_reg_01')['ps_reg_01'].index\n#cm = np.corrcoef(df_corr[cols].dropna(how='any').values.T)\ncm = np.corrcoef(df_corr[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True,\n                 fmt='.2f', annot_kws={'size': 10}, linewidth = 0.1, cmap = 'coolwarm',\n                 yticklabels=cols.values, xticklabels=cols.values)\nf.text(0.5, 0.93, \"Correlation coefficients\", ha='center', fontsize = 18)\nplt.show()","outputs":[],"metadata":{"_uuid":"3453916aa36b829d3d7192ee21c3076ebbf32256","_cell_guid":"a8228cc4-0842-495e-93c9-7e05a0d7153f","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"","outputs":[],"metadata":{"_uuid":"2d1870fa5db169a0c0fb30f4ca415721cbaf847a","_cell_guid":"95a63f5e-3094-40ec-a88d-052a86d44c78","collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"","outputs":[],"metadata":{"_uuid":"b4fa9e2835c86b7c46e5dd53bf37894c4645ae23","_cell_guid":"09e20a7e-3a49-451d-8a64-4dbe46861ada","collapsed":true},"execution_count":null,"cell_type":"code"}]}