{"cells":[{"metadata":{},"cell_type":"markdown","source":"This work was influenced by some kernels. Help me to improve this kernel and to understand some graphs as i am new to this."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"raw_train=pd.read_csv('/kaggle/input/forest-cover-type-prediction/train.csv')\n#Drop column ID\nraw_train = raw_train.iloc[:,1:]\nraw_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(set(raw_train.dtypes.tolist()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ll the features are in the form of Numeric only."},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No attribute is missing as count is 15120 for all attributes. Hence, all rows can be used"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Wilderness_Area and Soil_Type are one hot encoded. Hence, they could be converted back for some analysis\n \n Attributes Soil_Type7 and Soil_Type15 can be removed as they are constant\n \n Scales are not the same for all. Hence, rescaling and standardization may be necessary for some algos\n \n Horizontal_Distance_To_Hydrology, Vertical_Distance_To_Hydrology,Horizontal_Distance_To_Roadways,Horizontal_Distance_To_Fire_Points can have multiplier as their max value is much greater than the 75%. \t\t\n \n "},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train[raw_train.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no dupplicate records"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9, 8))\nsns.distplot(raw_train['Cover_Type'], color='g', hist_kws={'alpha': 0.4});","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train.hist(figsize=(20, 30), bins=50, xlabelsize=8, ylabelsize=8); # ; avoid having the matplotlib verbose informations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distribution(col):\n    #plt.figure(figsize=(6,4))\n    ax = sns.countplot(raw_train[col])\n    height = sum([p.get_height() for p in ax.patches])\n    for p in ax.patches:\n            ax.annotate(f'{100*p.get_height()/height:.2f} %', (p.get_x()+0.3, p.get_height()+5000),animated=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_distribution(\"Cover_Type\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that all classes have an equal presence. No class re-balancing is necessary"},{"metadata":{},"cell_type":"markdown","source":"# Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsize = 10\ncorr = raw_train.iloc[:,:size].corr()\n\n#num_cols = raw_train.select_dtypes(exclude=['object']).columns  # Without this also, it will generate the same result by selecting only numeric columns\n#corr = raw_train[num_cols].corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**A correlation matrix of the 10 numerical variables is created and plotted in Figure 4\n\nThere are six pairwise correlations that have a value higher than absolute 0.5\n\n    HS.noon, HS.3pm (0.61)\n    HD.9am, HS.3pm (-0.78)\n    HD.Hyrdro, VD.Hyrdo (0.65)\n    Slope, HS.noon (-0.61)\n    Aspect, HS.9am (-0.59)\n    Aspect, HS.3pm (0.64)\n    Elevation, HD.Road (0.58)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = raw_train.drop('Cover_Type', axis=1).corr() # We already examined SalePrice correlations\nplt.figure(figsize=(20, 15))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can conclude that, by essence, some of those features may be combined between each other in order to reduce the number of features like HS.noon, HS.3pm (0.61)\n,HD.9am, HS.3pm (-0.78)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndf_num_corr = raw_train.corr()\ndf_num_corr\n#golden_features_list = df_num_corr[abs(df_num_corr) > 0.2].sort_values(ascending=False)\n#print(\"There is {} strongly correlated values with Covet_Type:\\n{}\".format(len(golden_features_list), golden_features_list))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scatter Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(raw_train.iloc[:,:size])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The scatter plot reveals some interesting pairwise relationships.\n\n    The hillshade at noon and 3pm creates an elipsoid.\n\n    As the horizontal distance to a hydro increases, the variance in vertical distance increases.\n\n    As slope increase a proportion othe data’s hillshade at noon decreases (probably due to the aspect.)\n\n    H3.3pm has a sigmoid relationship with Aspect\n\n    F. Similarily Aspect and HS.9am have a more difined sigmoid relationship.\n    \n    Can also use bokeh.chart module to draw scatter plot one two features which are correlated\n    \n    # Import the necessary modules\nfrom bokeh.charts import Scatter, output_file, show\n\n     #Construct the scatter plot\np = Scatter(iris, x='Petal_length', y='Petal_width', color=\"Class\", title=\"Petal Length vs Petal Width\",\n            xlabel=\"Sepal Length\", ylabel=\"Sepal Width\")\n\n     #Output the file \noutput_file('scatter.html')\n\n     #Show the scatter plot\nshow(p)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0, len(raw_train.columns), 5):\n    sns.pairplot(data=raw_train,\n                x_vars=raw_train.columns[i:i+5],\n                y_vars=['Cover_Type'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elevation seems to be an important feature as there are variations wrt the Cover_Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train.columns[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bin_cols = [f'Wilderness_Area{i+1}' for i in range(4)]\nprint(bin_cols)\n\nfig, ax = plt.subplots(1,6, figsize=(30,10))\n\nfor i, col in enumerate(bin_cols):\n     ax0 = plt.subplot(1,4,i+1)\n     \n     #data[col].value_counts().plot.bar(color='pink')\n     sns.countplot(f'{col}', data= raw_train)\n     #print(ax0.patches)\n     height = sum([p.get_height() for p in ax0.patches])\n     for p in ax0.patches:\n         #get_x : Return the left coord of the rectangle\n         ax0.text(p.get_x()+p.get_width()/2., p.get_height(), f'{100*p.get_height()/height:.2f} %', ha='center') \n     plt.xlabel(f'{col}')\nplt.suptitle('Distribution over binary feature of train data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wilderness_Area2 is very less"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot wrt Cover_Type for binary features\nfig, ax = plt.subplots(1,4, figsize=(30, 8))\nfor i in range(4): \n    sns.countplot(f'Wilderness_Area{i+1}', hue='Cover_Type', data=raw_train, ax=ax[i])\n    ax[i].set_ylim([0, 3000])\n    ax[i].set_title(f'Wilderness_Area{i+1}', fontsize=15)\nfig.suptitle(\"Binary Feature Distribution Wildnerness (Train Data)\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Box plot of numeric data"},{"metadata":{"trusted":true},"cell_type":"code","source":"featuresToPlot=[\"Elevation\",\"Aspect\",\"Slope\",\"Horizontal_Distance_To_Hydrology\",\"Vertical_Distance_To_Hydrology\",\n                \"Horizontal_Distance_To_Roadways\",\"Horizontal_Distance_To_Fire_Points\",\"Hillshade_9am\",\n                \"Hillshade_Noon\",\"Hillshade_3pm\"]\n\nfig, ax = plt.subplots(3,4 ,figsize=(30,10))\nfor i, col in enumerate(featuresToPlot):\n    #print(i,col)\n    plt.subplot(2,5,i+1)\n    raw_train.boxplot( column =[col])\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the outliers values using IQR"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Need to work on Outliers\nQ1=raw_train.quantile(0.25)\nQ3=raw_train.quantile(0.75)\nIQR=Q3-Q1\n#print(IQR)\nQ1['Elevation']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the outlier value for Vertical_Distance_To_Hydrology\nprint(len(raw_train[(raw_train['Vertical_Distance_To_Hydrology']<(Q1['Vertical_Distance_To_Hydrology']-1.5*IQR['Vertical_Distance_To_Hydrology']))]))\nprint(len(raw_train[(raw_train['Vertical_Distance_To_Hydrology']>(Q3['Vertical_Distance_To_Hydrology']+1.5*IQR['Vertical_Distance_To_Hydrology']))]))\n\n\n\n#df = df[~((df < (Q1–1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are total {7+579} outlier for Vartical_Distance_To_Hydrology. We can chack for all the records."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = raw_train[~((raw_train<(Q1-1.5 * IQR)) |(raw_train>(Q3+1.5*IQR))).all(axis=1)]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print((raw_train<(Q1-1.5 * IQR)) | (raw_train>(Q3+1.5*IQR)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are outliers in most of teh columns. We need work on this to remove the outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,5 ,figsize=(30,10))\nfor i, col in enumerate(featuresToPlot):\n    #print(i,col)\n    #plt.subplot(2,5,i+1)\n    raw_train.boxplot(by='Cover_Type', column =[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorical Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge 4 category Wilderness Type into One column and check for the distribution\nnewLabels =[\"Rawah\",\"Neota\",\"ComanchePeak\",\"CachePoudre\"]\noldCols =[\"Wilderness_Area1\",\"Wilderness_Area2\",\"Wilderness_Area3\",\"Wilderness_Area4\"]\ndf_one_hot=raw_train[oldCols]\ndf_one_hot.head()\ndf_one_hot.idxmax(axis=1)\nraw_train['Wild']=df_one_hot.idxmax(axis=1)\ndi = {\"Wilderness_Area1\":\"Rawah\",\"Wilderness_Area2\":\"Neota\",\"Wilderness_Area3\":\"ComanchePeak\",\"Wilderness_Area4\":\"CachePoudre\"}\nraw_train['Wild']=raw_train['Wild'].map(di)  \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(raw_train['Wild'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(f'Wild', hue='Cover_Type', data=raw_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection\n"},{"metadata":{},"cell_type":"markdown","source":"## Removing features with low variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\nsel_variance_threshold = VarianceThreshold() \nX_train_remove_variance = sel_variance_threshold.fit_transform(raw_train)\nprint(X_train_remove_variance.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Variance is 0 for soil type  7 and 15 so they got removed usng this method. Actual data has 55 column and here we have 53 columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = raw_train.drop('Cover_Type',axis=1)\ny = raw_train['Cover_Type']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}