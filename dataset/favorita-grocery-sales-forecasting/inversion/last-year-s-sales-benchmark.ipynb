{"cells":[{"execution_count":null,"outputs":[],"metadata":{"_uuid":"0a607fbe5e16b05d37524b4f49fe41ec3a331b3c","_cell_guid":"54da3700-040d-4bd9-b7b3-9c57c31da5cc"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"7071bf40190e6fd013707d84bf2c356c7d483060","_cell_guid":"9866d996-87b1-4864-ae2a-812acd62c8da"},"source":"dtypes = {'store_nbr': np.dtype('int64'),\n          'item_nbr': np.dtype('int64'),\n          'unit_sales': np.dtype('float64'),\n          'onpromotion': np.dtype('O')}\n\ntrain = pd.read_csv('../input/train.csv', index_col='id', parse_dates=['date'], dtype=dtypes)\ntest = pd.read_csv('../input/test.csv', index_col='id', parse_dates=['date'], dtype=dtypes)\nsubmission = pd.read_csv('../input/sample_submission.csv', index_col='id')","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"ab834557471fe2d9c209a4ccbb8a2d5d92c19ea7","_cell_guid":"208b2ba3-1d10-49b3-bd9c-e17f16183555"},"source":"train.head()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"4c4da1bd2e4bd0152008acbc83da7f4141c71204","_cell_guid":"f7c32abf-a168-40ce-a434-c44f589d90fa"},"source":"test.head()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"b8e3e15b82f672f910fd97fb74efcc12fe88f10e","_cell_guid":"d0afbadf-d1ba-4950-9ba8-66658ea003e2"},"source":"submission.head()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"049c14af9e8c64a7a72243eb0190a996d673e52d","_cell_guid":"cf20825a-927d-4fe4-b471-9b4df4d09d8c"},"source":"# We only need the corresponding dates found in Test\ndate_mask = (train['date'] >= '2016-08-16') & (train['date'] <= '2016-08-31')\n\nlast_year_sales = train.loc[date_mask].copy()\nlast_year_sales.drop('onpromotion', axis=1, inplace=True)\n\n# Make a look-up dictionary with keys: date, store_nbr, item_nbr\nlast_year_sales = last_year_sales.set_index(['date', 'store_nbr', 'item_nbr'])\nlast_year_sales = last_year_sales.to_dict()['unit_sales']\n\nbenchmark = submission.copy()\n\n# Use the look-up dictionary, using the .get method so we can default in a value of 0\nbenchmark['unit_sales'] = \\\n    test.apply(lambda x: last_year_sales.get((x['date'] - pd.Timedelta(365, unit='d'), \n                                              x['store_nbr'],\n                                              x['item_nbr']), 0), axis=1)\n\n# Unless you enjoy seeing red errors after your submission uploads\nbenchmark[benchmark['unit_sales'] < 0] = 0\n    \n# Repeat after me . . . \"I will always compress my submission file for this contest\"\nbenchmark.to_csv('last_year_sales.csv.gz', float_format='%.4g', compression='gzip')","cell_type":"code"}],"nbformat_minor":1,"metadata":{"language_info":{"mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4}