{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n\n# --- setup ---\npd.set_option('max_columns', 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     filenames.sort()\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\n%%time\nimport requests\n\nfor filename in ['time_series_covid19_confirmed_global.csv',\n                 'time_series_covid19_deaths_global.csv',\n                 'time_series_covid19_recovered_global.csv',\n                 'time_series_covid19_confirmed_US.csv',\n                 'time_series_covid19_deaths_US.csv']:\n    print(f'Downloading {filename}')\n    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{filename}'\n    myfile = requests.get(url)\n    open(filename, 'wb').write(myfile.content)\n    \n    from datetime import datetime\n\ndef _convert_date_str(df):\n    try:\n        df.columns = list(df.columns[:4]) + [datetime.strptime(d, \"%m/%d/%y\").date().strftime(\"%Y-%m-%d\") for d in df.columns[4:]]\n    except:\n        print('_convert_date_str failed with %y, try %Y')\n        df.columns = list(df.columns[:4]) + [datetime.strptime(d, \"%m/%d/%Y\").date().strftime(\"%Y-%m-%d\") for d in df.columns[4:]]\n\n\nconfirmed_global_df = pd.read_csv('time_series_covid19_confirmed_global.csv')\n_convert_date_str(confirmed_global_df)\n\ndeaths_global_df = pd.read_csv('time_series_covid19_deaths_global.csv')\n_convert_date_str(deaths_global_df)\n\nrecovered_global_df = pd.read_csv('time_series_covid19_recovered_global.csv')\n_convert_date_str(recovered_global_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Filter out problematic data points (The West Bank and Gaza had a negative value, cruise ships were associated with Canada, etc.)\nremoved_states = \"Recovered|Grand Princess|Diamond Princess\"\nremoved_countries = \"US|The West Bank and Gaza\"\n\nconfirmed_global_df.rename(columns={\"Province/State\": \"Province_State\", \"Country/Region\": \"Country_Region\"}, inplace=True)\ndeaths_global_df.rename(columns={\"Province/State\": \"Province_State\", \"Country/Region\": \"Country_Region\"}, inplace=True)\nrecovered_global_df.rename(columns={\"Province/State\": \"Province_State\", \"Country/Region\": \"Country_Region\"}, inplace=True)\n\nconfirmed_global_df = confirmed_global_df[~confirmed_global_df[\"Province_State\"].replace(np.nan, \"nan\").str.match(removed_states)]\ndeaths_global_df    = deaths_global_df[~deaths_global_df[\"Province_State\"].replace(np.nan, \"nan\").str.match(removed_states)]\nrecovered_global_df = recovered_global_df[~recovered_global_df[\"Province_State\"].replace(np.nan, \"nan\").str.match(removed_states)]\n\nconfirmed_global_df = confirmed_global_df[~confirmed_global_df[\"Country_Region\"].replace(np.nan, \"nan\").str.match(removed_countries)]\ndeaths_global_df    = deaths_global_df[~deaths_global_df[\"Country_Region\"].replace(np.nan, \"nan\").str.match(removed_countries)]\nrecovered_global_df = recovered_global_df[~recovered_global_df[\"Country_Region\"].replace(np.nan, \"nan\").str.match(removed_countries)]\n\nconfirmed_global_melt_df = confirmed_global_df.melt(\n    id_vars=['Country_Region', 'Province_State', 'Lat', 'Long'], value_vars=confirmed_global_df.columns[4:], var_name='Date', value_name='ConfirmedCases')\ndeaths_global_melt_df = deaths_global_df.melt(\n    id_vars=['Country_Region', 'Province_State', 'Lat', 'Long'], value_vars=confirmed_global_df.columns[4:], var_name='Date', value_name='Deaths')\nrecovered_global_melt_df = deaths_global_df.melt(\n    id_vars=['Country_Region', 'Province_State', 'Lat', 'Long'], value_vars=confirmed_global_df.columns[4:], var_name='Date', value_name='Recovered')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create Trainning data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = confirmed_global_melt_df.merge(deaths_global_melt_df, on=['Country_Region', 'Province_State', 'Lat', 'Long', 'Date'])\ntrain = train.merge(recovered_global_melt_df, on=['Country_Region', 'Province_State', 'Lat', 'Long', 'Date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training data for US**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nconfirmed_us_df = pd.read_csv('time_series_covid19_confirmed_US.csv')\ndeaths_us_df = pd.read_csv('time_series_covid19_deaths_US.csv')\n\nconfirmed_us_df.drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Combined_Key'], inplace=True, axis=1)\ndeaths_us_df.drop(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Combined_Key', 'Population'], inplace=True, axis=1)\n\nconfirmed_us_df.rename({'Long_': 'Long'}, axis=1, inplace=True)\ndeaths_us_df.rename({'Long_': 'Long'}, axis=1, inplace=True)\n\n_convert_date_str(confirmed_us_df)\n_convert_date_str(deaths_us_df)\n\n# clean\nconfirmed_us_df = confirmed_us_df[~confirmed_us_df.Province_State.str.match(\"Diamond Princess|Grand Princess|Recovered|Northern Mariana Islands|American Samoa\")]\ndeaths_us_df = deaths_us_df[~deaths_us_df.Province_State.str.match(\"Diamond Princess|Grand Princess|Recovered|Northern Mariana Islands|American Samoa\")]\n\n# --- Aggregate by province state ---\n#confirmed_us_df.groupby(['Country_Region', 'Province_State'])\nconfirmed_us_df = confirmed_us_df.groupby(['Country_Region', 'Province_State']).sum().reset_index()\ndeaths_us_df = deaths_us_df.groupby(['Country_Region', 'Province_State']).sum().reset_index()\n\n# remove lat, long.\nconfirmed_us_df.drop(['Lat', 'Long'], inplace=True, axis=1)\ndeaths_us_df.drop(['Lat', 'Long'], inplace=True, axis=1)\n\nconfirmed_us_melt_df = confirmed_us_df.melt(\n    id_vars=['Country_Region', 'Province_State'], value_vars=confirmed_us_df.columns[2:], var_name='Date', value_name='ConfirmedCases')\ndeaths_us_melt_df = deaths_us_df.melt(\n    id_vars=['Country_Region', 'Province_State'], value_vars=deaths_us_df.columns[2:], var_name='Date', value_name='Deaths')\n\ntrain_us = confirmed_us_melt_df.merge(deaths_us_melt_df, on=['Country_Region', 'Province_State', 'Date'])\n\ntrain = pd.concat([train, train_us], axis=0, sort=False)\n\ntrain_us.rename({'Country_Region': 'country', 'Province_State': 'province', 'Date': 'date', 'ConfirmedCases': 'confirmed', 'Deaths': 'fatalities'}, axis=1, inplace=True)\ntrain_us['country_province'] = train_us['country'].fillna('') + '/' + train_us['province'].fillna('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Trainning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndatadir = Path('/kaggle/input/covid19-global-forecasting-week-4')\n\n# Read in the data CSV files\n#train = pd.read_csv(datadir/'train.csv')\n#test = pd.read_csv(datadir/'test.csv')\n#submission = pd.read_csv(datadir/'submission.csv')\ntrain.rename({'Country_Region': 'country', 'Province_State': 'province', 'Id': 'id', 'Date': 'date', 'ConfirmedCases': 'confirmed', 'Deaths': 'fatalities', 'Recovered': 'recovered'}, axis=1, inplace=True)\ntrain['country_province'] = train['country'].fillna('') + '/' + train['province'].fillna('')\n\n# test.rename({'Country_Region': 'country', 'Province_State': 'province', 'Id': 'id', 'Date': 'date', 'ConfirmedCases': 'confirmed', 'Fatalities': 'fatalities'}, axis=1, inplace=True)\n# test['country_province'] = test['country'].fillna('') + '/' + test['province'].fillna('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Worldwide trend**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ww_df = train.groupby('date')[['confirmed', 'fatalities']].sum().reset_index()\nww_df['new_case'] = ww_df['confirmed'] - ww_df['confirmed'].shift(1)\nww_df.tail()\n\nww_melt_df = pd.melt(ww_df, id_vars=['date'], value_vars=['confirmed', 'fatalities', 'new_case'])\nww_melt_df\n\nfig = px.line(ww_melt_df, x=\"date\", y=\"value\", color='variable', \n              title=\"Worldwide Confirmed/Death Cases Over Time\")\nfig.show()\n\nfig = px.line(ww_melt_df, x=\"date\", y=\"value\", color='variable',\n              title=\"Worldwide Confirmed/Death Cases Over Time (Log scale)\",\n             log_y=True)\nfig.show()\n\nww_df['mortality'] = ww_df['fatalities'] / ww_df['confirmed']\n\nfig = px.line(ww_df, x=\"date\", y=\"mortality\", \n              title=\"Worldwide Mortality Rate Over Time\")\nfig.show()\n\ncountry_df = train.groupby(['date', 'country'])[['confirmed', 'fatalities']].sum().reset_index()\ncountry_df.tail()\n\ncountries = country_df['country'].unique()\nprint(f'{len(countries)} countries are in dataset:\\n{countries}')\n\n\ntarget_date = country_df['date'].max()\n\nprint('Date: ', target_date)\nfor i in [1, 10, 100, 1000, 10000]:\n    n_countries = len(country_df.query('(date == @target_date) & confirmed > @i'))\n    print(f'{n_countries} countries have more than {i} confirmed cases')\n    \nax = sns.distplot(np.log10(country_df.query('date == \"2020-03-27\"')['confirmed'] + 1))\nax.set_xlim([0, 6])\nax.set_xticks(np.arange(7))\n_ = ax.set_xticklabels(['0', '10', '100', '1k', '10k', '100k'])\n\ntop_country_df = country_df.query('(date == @target_date) & (confirmed > 1000)').sort_values('confirmed', ascending=False)\ntop_country_melt_df = pd.melt(top_country_df, id_vars='country', value_vars=['confirmed', 'fatalities'])\n\nfig = px.bar(top_country_melt_df.iloc[::-1],\n             x='value', y='country', color='variable', barmode='group',\n             title=f'Confirmed Cases/Deaths on {target_date}', text='value', height=1500, orientation='h')\nfig.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*US's spread speed is the fastest, US's fatality cases become top1 on Apr 10th.*"},{"metadata":{},"cell_type":"markdown","source":"**Take a look at fatalities top 30 countries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"top30_countries = top_country_df.sort_values('fatalities', ascending=False).iloc[:30]['country'].unique()\ntop30_countries_df = country_df[country_df['country'].isin(top30_countries)]\nfig = px.line(top30_countries_df,\n              x='date', y='fatalities', color='country',\n              title=f'Fatalities for top 30 country as of {target_date}')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Monthly rate by country**"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_country_df = country_df.query('(date == @target_date) & (confirmed > 100)')\ntop_country_df['mortality_rate'] = top_country_df['fatalities'] / top_country_df['confirmed']\ntop_country_df = top_country_df.sort_values('mortality_rate', ascending=False)\nfig = px.bar(top_country_df[:30].iloc[::-1],\n             x='mortality_rate', y='country',\n             title=f'Mortality rate HIGH: top 30 countries on {target_date}', text='mortality_rate', height=800, orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Countries with low mortality**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(top_country_df[-30:],\n             x='mortality_rate', y='country',\n             title=f'Mortality rate LOW: top 30 countries on {target_date}', text='mortality_rate', height=800, orientation='h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of confirmed cases on map**"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_country_df = country_df.query('date == @target_date')\nall_country_df['confirmed_log1p'] = np.log10(all_country_df['confirmed'] + 1)\nall_country_df['fatalities_log1p'] = np.log10(all_country_df['fatalities'] + 1)\nall_country_df['mortality_rate'] = all_country_df['fatalities'] / all_country_df['confirmed']\n\nfig = px.choropleth(all_country_df, locations=\"country\", \n                    locationmode='country names', color=\"confirmed_log1p\", \n                    hover_name=\"country\", hover_data=[\"confirmed\", 'fatalities', 'mortality_rate'],\n                    range_color=[all_country_df['confirmed_log1p'].min(), all_country_df['confirmed_log1p'].max()], \n                    color_continuous_scale=\"peach\", \n                    title='Countries with Confirmed Cases')\n\n# I'd like to update colorbar to show raw values, but this does not work somehow...\n# Please let me know if you know how to do this!!\ntrace1 = list(fig.select_traces())[0]\ntrace1.colorbar = go.choropleth.ColorBar(\n    tickvals=[0, 1, 2, 3, 4, 5],\n    ticktext=['1', '10', '100', '1000','10000', '10000'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**mortality rate is especially high in Europe region**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = px.choropleth(all_country_df, locations=\"country\", \n                    locationmode='country names', color=\"mortality_rate\", \n                    hover_name=\"country\", range_color=[0, 0.12], \n                    color_continuous_scale=\"peach\", \n                    title='Countries with mortality rate')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Daily NEW confirmed cases trend**"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_df['prev_confirmed'] = country_df.groupby('country')['confirmed'].shift(1)\ncountry_df['new_case'] = country_df['confirmed'] - country_df['prev_confirmed']\ncountry_df['new_case'].fillna(0, inplace=True)\ntop30_country_df = country_df[country_df['country'].isin(top30_countries)]\n\nfig = px.line(top30_country_df,\n              x='date', y='new_case', color='country',\n              title=f'DAILY NEW Confirmed cases world wide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**US**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for country in countries:\n    province = train.query('country == @country')['province'].unique()\n    if len(province) > 1:       \n        print(f'Country {country} has {len(province)} provinces: {province}')\nusa_state_code_df = pd.read_csv('/kaggle/input/usstatecode/usa_states2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_us['mortality_rate'] = train_us['fatalities'] / train_us['confirmed']\n\n# Convert province column to its 2-char code name,\nstate_name_to_code = dict(zip(usa_state_code_df['state_name'], usa_state_code_df['state_code']))\ntrain_us['province_code'] = train_us['province'].map(state_name_to_code)\n\n# Only show latest days.\ntrain_us_latest = train_us.query('date == @target_date')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**New York, and its neighbor New Jersey dominates its spread **"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.choropleth(train_us_latest, locations='province_code', locationmode=\"USA-states\",\n                    color='confirmed', scope=\"usa\", hover_data=['province', 'fatalities', 'mortality_rate'],\n                    title=f'Confirmed cases in US on {target_date}')\nfig.show()\ntrain_us_latest.sort_values('confirmed', ascending=False)\nfig = px.choropleth(train_us_latest, locations='province_code', locationmode=\"USA-states\",\n                    color='mortality_rate', scope=\"usa\", hover_data=['province', 'fatalities', 'mortality_rate'],\n                    title=f'Mortality rate in US on {target_date}')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Europe**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ref: https://www.kaggle.com/abhinand05/covid-19-digging-a-bit-deeper\neurope_country_list =list([\n    'Austria','Belgium','Bulgaria','Croatia','Cyprus','Czechia','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Ireland',\n    'Italy', 'Latvia','Luxembourg','Lithuania','Malta','Norway','Netherlands','Poland','Portugal','Romania','Slovakia','Slovenia',\n    'Spain', 'Sweden', 'United Kingdom', 'Iceland', 'Russia', 'Switzerland', 'Serbia', 'Ukraine', 'Belarus',\n    'Albania', 'Bosnia and Herzegovina', 'Kosovo', 'Moldova', 'Montenegro', 'North Macedonia'])\n\ncountry_df['date'] = pd.to_datetime(country_df['date'])\ntrain_europe = country_df[country_df['country'].isin(europe_country_list)]\n#train_europe['date_str'] = pd.to_datetime(train_europe['date'])\ntrain_europe_latest = train_europe.query('date == @target_date')\n\nfig = px.choropleth(train_europe_latest, locations=\"country\", \n                    locationmode='country names', color=\"confirmed\", \n                    hover_name=\"country\", range_color=[1, train_europe_latest['confirmed'].max()], \n                    color_continuous_scale='portland', \n                    title=f'European Countries with Confirmed Cases as of {target_date}', scope='europe', height=800)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Asia**"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_latest = country_df.query('date == @target_date')\n\nfig = px.choropleth(country_latest, locations=\"country\", \n                    locationmode='country names', color=\"confirmed\", \n                    hover_name=\"country\", range_color=[1, 50000], \n                    color_continuous_scale='portland', \n                    title=f'Asian Countries with Confirmed Cases as of {target_date}', scope='asia', height=800)\nfig.show()\n\ntop_asian_country_df = country_df[country_df['country'].isin(['China', 'Indonesia', 'Iran', 'Japan', 'Korea, South', 'Malaysia', 'Philippines'])]\n\nfig = px.line(top_asian_country_df,\n              x='date', y='new_case', color='country',\n              title=f'DAILY NEW Confirmed cases world wide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Curve fitting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(t, M, beta, alpha, offset=0):\n    alpha += offset\n    return M / (1 + np.exp(-beta * (t - alpha)))\n\ndef error(x, y, params):\n    M, beta, alpha = params\n    y_pred = sigmoid(x, M, beta, alpha)\n\n    # apply weight, latest number is more important than past.\n    weight = np.arange(len(y_pred)) ** 2\n    loss_mse = np.mean((y_pred - y) ** 2 * weight)\n    return loss_mse\n\ndef gen_random_color(min_value=0, max_value=256) -> str:\n    \"\"\"Generate random color for plotly\"\"\"\n    r, g, b = np.random.randint(min_value, max_value, 3)\n    return f'rgb({r},{g},{b})'\n\n\ndef fit_sigmoid(exclude_days=0):\n    target_country_df_list = []\n    pred_df_list = []\n    for target_country in top30_countries:\n        print('target_country', target_country)\n        # --- Train ---\n        target_country_df = country_df.query('country == @target_country')\n\n        #train_start_date = target_country_df['date'].min()\n        train_start_date = target_country_df.query('confirmed > 1000')['date'].min()\n        train_end_date = pd.to_datetime(target_date) - pd.Timedelta(f'{exclude_days} days')\n        target_date_df = target_country_df.query('(date >= @train_start_date) & (date <= @train_end_date)')\n        if len(target_date_df) <= 7:\n            print('WARNING: the data is not enough, use 7 more days...')\n            train_start_date -= pd.Timedelta('7 days')\n            target_date_df = target_country_df.query('(date >= @train_start_date) & (date <= @train_end_date)')\n\n        confirmed = target_date_df['confirmed'].values\n        x = np.arange(len(confirmed))\n\n        lossfun = lambda params: error(x, confirmed, params)\n        res = sp.optimize.minimize(lossfun, x0=[np.max(confirmed) * 5, 0.04, 2 * len(confirmed) / 3.], method='nelder-mead')\n        M, beta, alpha = res.x\n        # sigmoid_models[key] = (M, beta, alpha)\n        # np.clip(sigmoid(list(range(len(data), len(data) + steps)), M, beta, alpha), 0, None).astype(int)\n\n        # --- Pred ---\n        pred_start_date = target_country_df['date'].min()\n        pred_end_date = pd.to_datetime('2020-07-01')\n        days = int((pred_end_date - pred_start_date) / pd.Timedelta('1 days'))\n        # print('pred start', pred_start_date, 'end', pred_end_date, 'days', days)\n\n        x = np.arange(days)\n        offset = (train_start_date - pred_start_date) / pd.Timedelta('1 days')\n        print('train_start_date', train_start_date, 'offset', offset, 'params', M, beta, alpha)\n        y_pred = sigmoid(x, M, beta, alpha, offset=offset)\n        # target_country_df['confirmed_pred'] = y_pred\n\n        all_dates = [pred_start_date + np.timedelta64(x, 'D') for x in range(days)]\n        pred_df = pd.DataFrame({\n            'date': all_dates,\n            'country': target_country,\n            'confirmed_pred': y_pred,\n        })\n\n        target_country_df_list.append(target_country_df)\n        pred_df_list.append(pred_df)\n    return target_country_df_list, pred_df_list\n\ndef plot_sigmoid_fitting(target_country_df_list, pred_df_list, title=''):\n    n_countries = len(top30_countries)\n\n    # --- Plot ---\n    fig = go.Figure()\n\n    for i in range(n_countries):\n        target_country = top30_countries[i]\n        target_country_df = target_country_df_list[i]\n        pred_df = pred_df_list[i]\n        color = gen_random_color(min_value=20)\n        # Prediction\n        fig.add_trace(go.Scatter(\n            x=pred_df['date'], y=pred_df['confirmed_pred'],\n            name=f'{target_country}_pred',\n            line=dict(color=color, dash='dash')\n        ))\n\n        # Ground truth\n        fig.add_trace(go.Scatter(\n            x=target_country_df['date'], y=target_country_df['confirmed'],\n            mode='markers', name=f'{target_country}_actual',\n            line=dict(color=color),\n        ))\n    fig.update_layout(\n        title=title, xaxis_title='Date', yaxis_title='Confirmed cases')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_country_df_list, pred_df_list = fit_sigmoid(exclude_days=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sigmoid_fitting(target_country_df_list, pred_df_list, title='Sigmoid fitting with all latest data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_country_df_list, pred_df_list = fit_sigmoid(exclude_days=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sigmoid_fitting(target_country_df_list, pred_df_list, title='Sigmoid fitting without last 7days data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction using ensemble learning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ntrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/train.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/test.csv')\ndf1 = train.Population.groupby(train['Country_Region']).max().sort_values(ascending= False)\ndf10 = pd.DataFrame()\ndf20 = pd.DataFrame()\ndf10['population'] = df1.iloc[0:10]\ndf10['country']= df10.index\ndf20['population'] = df1.iloc[11:20]\ndf20['country'] = df20.index\n\ntrain1= train[train['Target']=='ConfirmedCases']\ndata1 = pd.DataFrame()\ndata1['values'] =train1.TargetValue.groupby(train1['Country_Region']).sum().sort_values(ascending= False)\ndata1['country'] = data1.index\ndata1.index = np.arange(0,len(data1))\ndata10 = data1.iloc[0:10,:]\ndata20 = data1.iloc[11:20,:]\n\ntrain1= train[train['Target']!='ConfirmedCases']\ndata1 = pd.DataFrame()\ndata1['values'] =train1.TargetValue.groupby(train1['Country_Region']).sum().sort_values(ascending= False)\ndata1['country'] = data1.index\ndata1.index = np.arange(0,len(data1))\ndata10 = data1.iloc[0:10,:]\ndata20 = data1.iloc[11:20,:]\n\nindia = train[train['Country_Region']=='India']\nindia.drop(['County','Province_State'],axis =1,inplace =True)\nindia.index = np.arange(0,len(india)) #rechanging the index\nind = india[india['Target']=='ConfirmedCases']\nind.index = np.arange(0,len(ind))\n\nlist1 = []\nfor i in range(2,7):\n    date = '2020'+'-0'+str(i)+'-01'\n    list1.append(ind[ind['Date']<date]['TargetValue'].sum())\n\n\nlist2 =[]\nfor i in range(len(list1)):\n    if i ==0:\n        list2.append(list1[i])\n    else:\n        list2.append(list1[i]-list1[i-1])\n\nlabels =['Jan','Feb','Mar','Apr','May']\ndf = india['TargetValue'].groupby(train['Target']).sum()\nlabels =[df.index[0],df.index[1]]\nsizes = [df[0],df[1]]\nexplode = (0, 0.2)  \n\n\nwor = train[train['Target']=='ConfirmedCases']\nindependent_columns = ['Country_Region','Weight','Target','Date']\ndependent_column = ['TargetValue']\nX= train[independent_columns]\ny = train[dependent_column]\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX['Target']=le.fit_transform(X['Target'])\n\ntrain1= train[train['Target']=='ConfirmedCases']\ndata1 = pd.DataFrame()\ndata1['values'] =train1.TargetValue.groupby(train1['Country_Region']).sum().sort_values(ascending= False)\ndata1['country'] = data1.index\n\nk = len(data1['country'])\ndict1 = {}\nfor i in data1['country']:\n    dict1[i] = k\n    k =k-1\n\nlist1=[]\nX['encoded_country']=0\nfor i in X['Country_Region']:\n    list1.append(dict1[i])\nX['encoded_country'] = list1\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Date and month**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X['date_dup'] = pd.to_datetime(X['Date'])\n\nX['month'] = 0\nlist1=[]\nfor i in X['date_dup']:\n    list1.append(i.month)\nX['month'] = list1\n\nX['date'] = 0\nlist1=[]\nfor i in X['date_dup']:\n    list1.append(i.day)\nX['date'] = list1\nX.drop(['Country_Region','Date','date_dup'],axis =1,inplace =True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split as tts\nmax_range =10\n\nfrom sklearn.ensemble import RandomForestRegressor as regr\nfrom sklearn.metrics import r2_score\n\nX_train,X_test,y_train,y_test = tts(X,y,test_size =0.3,random_state =7)\nmodel = regr()\nmodel.fit(X_train,y_train)\n\nprint(r2_score(y_test,model.predict(X_test)))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Testing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test[independent_columns]\nlist1=[]\ntest['encoded_country']=0\nfor i in test['Country_Region']:\n    list1.append(dict1[i])\ntest['encoded_country'] = list1\n\ntest['date_dup'] = pd.to_datetime(test['Date'])\n\ntest['month'] = 0\nlist1=[]\nfor i in test['date_dup']:\n    list1.append(i.month)\ntest['month'] = list1\n\ntest['date'] = 0\nlist1=[]\nfor i in test['date_dup']:\n    list1.append(i.day)\ntest['date'] = list1\n\ntest.drop(['Country_Region','Date','date_dup'],axis =1,inplace =True)\n\nle1 =LabelEncoder()\ntest['Target'] = le1.fit_transform(test['Target'])\n\npred = model.predict(test)\nt =pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/test.csv')\nss = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-5/submission.csv')\noutput = pd.DataFrame({'Id': t.ForecastId  , 'TargetValue': pred})\na=output.groupby(['Id'])['TargetValue'].quantile(q=0.05).reset_index()\nb=output.groupby(['Id'])['TargetValue'].quantile(q=0.5).reset_index()\nc=output.groupby(['Id'])['TargetValue'].quantile(q=0.95).reset_index()\n\n\na.columns=['Id','q0.05']\nb.columns=['Id','q0.5']\nc.columns=['Id','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05']\na['q0.5']=a['q0.5']\na['q0.95']=a['q0.95']\n\nsub=pd.melt(a, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}