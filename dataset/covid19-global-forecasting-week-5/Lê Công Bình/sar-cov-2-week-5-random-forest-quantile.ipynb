{"cells":[{"metadata":{},"cell_type":"markdown","source":"Other approach:\n- https://www.kaggle.com/binhlc/sar-cov-2-week-5-gradientboosting-vs-light-gbm"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/covid19-global-forecasting-week-5/test.csv\")\ndf_train = pd.read_csv(\"../input/covid19-global-forecasting-week-5/train.csv\")\ndf_sub = pd.read_csv(\"../input/covid19-global-forecasting-week-5/submission.csv\")\n\nvalid_date = df_test.Date.min()\ndf_train = df_train[df_train.Date < valid_date]\ndf = pd.concat([df_train, df_test])\ndf.Date = pd.to_datetime(df.Date)\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom datetime import datetime\n\ndf[\"geography\"] = df.Country_Region + \"_\" + df.Province_State + \"_\" + df.County\ndf.loc[df.County.isna(), \"geography\"] = df[df.County.isna()].Country_Region + \"_\" + df[df.County.isna()].Province_State\ndf.loc[df.Province_State.isna(), \"geography\"] = df[df.Province_State.isna()].Country_Region\n\nle = LabelEncoder()\ndf.Country_Region = le.fit_transform(df.Country_Region.astype(str))\ndf.Province_State = le.fit_transform(df.Province_State.astype(str))\ndf.County = le.fit_transform(df.County.astype(str))\ndf.Target = le.fit_transform(df.Target.astype(str))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lags = [1, 2, 3, 4, 5, 6, 7, 8, 9]\nlag_cols = [f\"lag_{lag}\" for lag in lags]\nwins = [3,7]\nlag_wins = [1,2,3]\n\nwin_cols = []\nfor win in wins:\n    for lag_win in lag_wins:\n        win_col = f\"rmean_{lag_win}_{win}\"  \n        win_cols = win_cols + [win_col]\n\ndef createfeature(df):   \n    df.sort_values([\"geography\", \"Date\", \"Target\"], inplace = True)\n    for lag, lag_col in zip(lags, lag_cols):\n        df[lag_col] = df.groupby([\"geography\", \"Target\"])[\"TargetValue\"].shift(lag)\n\n    for win in wins:\n        for lag_win in lag_wins:\n            win_col = f\"rmean_{lag_win}_{win}\"          \n            df[win_col] = df[[f\"lag_{lag}\" for lag in range(lag_win, lag_win+win)]].mean(axis = 1)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = createfeature(df)\nfeatures = [\"Country_Region\", \"Province_State\", \"County\", \"Population\",\"Target\"] + lag_cols + win_cols   \n\ncategorical_features = [\"Country_Region\", \"Province_State\", \"County\", \"Target\"]\n\ndf_train = df[~(df.TargetValue.isna()) & ~ (df.lag_9.isna())]\nX_train = df_train[df_train.Date < datetime(2020, 4, 20)][features]\ny_train = df_train[df_train.Date < datetime(2020, 4, 20)].TargetValue.values\nX_test = df_train[df_train.Date >= datetime(2020, 4, 20)][features]\ny_test = df_train[df_train.Date >= datetime(2020, 4, 20)].TargetValue.values\n\nprint(f\"Train shape: {(X_train.shape, y_train.shape)}\")\nprint(f\"Test shape: {(X_test.shape, y_test.shape)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"QUANTILE = [0.05, 0.5, 0.95]\n\ndef Weighted_Pinball_Loss(q, X_test, y_test, y_pred):\n    df_weight = X_test[['Population','Target']].copy()\n    df_weight['Weight'] = df_weight['Population']\n    #Facilities\n    df_weight.loc[df_weight.Target == 1, 'Weight'] = 10 *  df_weight.loc[df_weight.Target == 1, 'Weight']\n    #W = X_test.apply(lambda x: x.Population if x.Target == 0 else 10 * x.Population, axis=1).values\n    W = df_weight['Weight'].values\n    W = np.log(W+1) ** -1\n    e = y_test - y_pred\n    L = np.maximum(q * e, (q - 1) * e)\n    score = np.average(L, weights = W)\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nLEARNING_RATE = 0.01\nN_ESTIMATORS = 100\n\nmodel_rf_save = {}\nscore_rf_save = {}\n\nmodel = RandomForestRegressor(n_estimators=N_ESTIMATORS,n_jobs=-1)\nmodel = model.fit(X_train,y_train)\n\nrf_preds = []\nfor estimator in model.estimators_:\n    rf_preds.append(estimator.predict(X_test))\nrf_preds = np.array(rf_preds).transpose()\n\nfor alpha in QUANTILE:\n    y_pred = np.percentile(rf_preds, alpha * 100, axis=1)\n    score = Weighted_Pinball_Loss(alpha,X_test,y_test,y_pred)\n    score_rf_save.update({alpha: score})\n    print(f'{alpha}: Weighted Pinball Loss {score}')\nprint(f'Average Pinball Loss: {np.mean(list(score_rf_save.values()))}')    \n\nmodel = RandomForestRegressor(n_estimators=N_ESTIMATORS,n_jobs=-1)\nmodel = model.fit(df_train[features], df_train.TargetValue.values)\nmodel_rf_save = model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_save = model_rf_save\n\n# Predict by day\ndf_sub = pd.DataFrame()\nfor pred_date in df_test.Date.unique():\n    print(f'Predict day {pred_date}')\n    X_pred = df[df.Date == pred_date][features]\n\n    rf_preds = []\n    for estimator in model_save.estimators_:\n        rf_preds.append(estimator.predict(X_pred))\n    rf_preds = np.array(rf_preds).transpose()\n\n    for alpha in QUANTILE:\n        y_pred = np.percentile(rf_preds, alpha * 100, axis=1)\n        df_sub = df_sub.append(pd.DataFrame({\n            'ForecastId': (df_test[df_test.Date == pred_date]['ForecastId']).values,\n            'Quantile': alpha,\n            'ForecastId_Quantile': (df_test[df_test.Date == pred_date]['ForecastId'].astype(str) + '_' + str(alpha)).values, \n            'TargetValue': y_pred }),ignore_index=True)\n    y_pred = model_save.predict(X_pred)\n    df.loc[df.Date == pred_date, 'TargetValue'] = y_pred\n    df = createfeature(df)           \n        \n    # Create submission\ndf_sub = df_sub.sort_values(['ForecastId','Quantile']).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub[['ForecastId_Quantile','TargetValue']].to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import NumeralTickFormatter\nfrom bokeh.palettes import Spectral11\noutput_notebook()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotCountry(country):\n    df_country = pd.merge(left=df_test[df_test['Country_Region'] == country], right=df_sub, left_on='ForecastId', right_on='ForecastId')\n    df_country = df_country.groupby(['Date','Target','Quantile']).sum().reset_index()\n    df_country.Date = pd.to_datetime(df_country.Date)\n    mypalette=Spectral11[0:3]\n    p = figure(title=country + \" Confirmed Cases Forecast\", x_axis_label='Date', x_axis_type='datetime', y_axis_label='Confirmed Cases')\n    i = 0\n    for alpha in QUANTILE:\n        df_quantile = df_country[(df_country['Target'] == 'ConfirmedCases') & (df_country['Quantile'] == alpha)]   \n        p.line(df_quantile['Date'], df_quantile['TargetValue'], legend_label=f\"Confirmed Cases - Quantile {alpha}\", line_width=2, line_color=mypalette[i])\n        i += 1\n    p.legend.location = \"top_left\"\n    p.yaxis.formatter=NumeralTickFormatter(format=\"‘0.0a\")    \n    show(p)\n\n    mypalette=Spectral11[0:3]\n    p = figure(title=country + \" Fatalities Forecast\", x_axis_label='Date', x_axis_type='datetime', y_axis_label='Fatalities')\n    i = 0\n    for alpha in QUANTILE:\n        df_quantile = df_country[(df_country['Target'] == 'Fatalities') & (df_country['Quantile'] == alpha)]   \n        p.line(df_quantile['Date'], df_quantile['TargetValue'], legend_label=f\"Fatalities - Quantile {alpha}\", line_width=2, line_color=mypalette[i])\n        i += 1\n    p.legend.location = \"top_left\"\n    p.yaxis.formatter=NumeralTickFormatter(format=\"‘0.0a\")    \n    show(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotCountry('US')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotCountry('Vietnam')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}