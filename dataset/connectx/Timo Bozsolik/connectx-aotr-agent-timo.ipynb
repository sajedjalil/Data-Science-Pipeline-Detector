{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install kaggle-environments","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install 'kaggle-environments>=0.1.6'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create ConnectX Environment","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils\n\nenv = make(\"connectx\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LOG = True\n\n# This agent random chooses a non-empty column.\ndef random_agent(observation, configuration):\n    from random import choice\n    return choice([c for c in range(configuration.columns) if observation.board[c] == 0])\n\ndef constant_agent(observation, configuration):\n    return 4\n\n\n# This agent random chooses a non-empty column.\ndef first_free_agent(observation, configuration):\n    import numpy as np\n    def column_is_full(column, board, configuration):\n        return board[0][column] != 0\n        \n    #board[row, column] simplifies data access\n    board = np.reshape(observation.board, (configuration.rows, configuration.columns))\n    \n    first_not_full = 0\n    for col in range(configuration.columns):   \n        full = column_is_full(col, board, configuration)\n        # print(\"Column\", col, \"is full\", full)\n        if not full:\n            first_not_full = col\n            break\n    \n    # print(board)\n    return first_not_full\n                \n\ndef timo_agent(observation, configuration):\n    from random import choice\n    import numpy as np\n    \n    # 0. Helper functions\n    def is_win(board, column, columns, rows, inarow, mark, has_played=True):\n        row = (\n            min([r for r in range(rows) if board[column + (r * columns)] == mark])\n            if has_played\n            else max([r for r in range(rows) if board[column + (r * columns)] == 0])\n        )\n        def count(offset_row, offset_column):\n            for i in range(1, inarow + 1):\n                r = row + offset_row * i\n                c = column + offset_column * i\n                if (\n                    r < 0\n                    or r >= rows\n                    or c < 0\n                    or c >= columns\n                    or board[c + (r * columns)] != mark\n                ):\n                    return i - 1\n            return inarow\n\n        return (\n            count(1, 0) >= inarow  # vertical.\n            or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n            or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n            or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n        )\n    \n    def column_is_full(column, board):\n        return board[0][column] != 0\n    \n    # setup\n    playable_columns = [c for c in range(configuration.columns) if observation.board[c] == 0]\n    board = np.reshape(observation.board, (configuration.rows, configuration.columns))\n    me = observation.mark\n    other_player = 1 if observation.mark == 2 else 2\n    \n    #print(\"--> Playable\", playable_columns)\n\n    # 1. If you can win with any move, just make that move\n    for col in playable_columns:\n        if (is_win(observation.board, col, configuration.columns, configuration.rows, configuration.inarow - 1, me, False)):\n            #print(\"==> (1) Play\", col)\n            return col\n        \n    # 2. If other player would win with that move, the play that one\n    for col in playable_columns:\n        if (is_win(observation.board, col, configuration.columns, configuration.rows, configuration.inarow - 1, other_player, False)):\n            #print(\"==> (2) Play\", col)\n            return col\n        \n    # 3. Calculate a score for each column and return best score\n    scores = []\n    for col in playable_columns:\n        score = 0\n        \n        for get_inarow in range(configuration.inarow - 1):\n            if (is_win(observation.board, col, configuration.columns, configuration.rows, get_inarow, observation.mark, False)):\n                #print(\"--> (2) Col\", col, \"get_inarow\", get_inarow, \"yay\")\n                score += (get_inarow + 1)\n            #print(\"--> (2) Col\", col, \"get_inarow\", get_inarow, \"noo\")\n        \n        scores.append([col, score])\n        #print(\"--> (3) Col\", col, \"score\", score)\n    \n    col = 0\n    max_score = 0\n    for score in scores:\n        if score[1] > max_score:\n            max_score = score[1]\n            col = score[0]\n    \n    #print(\"==> (3) Play\", col)\n    return col\n        \n    # X. Otherwise return a random one\n    #col = choice(playable_columns)\n    #print(\"==> (X) Play\", col)\n    #return col\n\n    \n\n\n# Play one step\n#trainer = env.train([None, \"random\"])\ntrainer = env.train([None, \"negamax\"])\nobservation = trainer.reset()\n\nprint(observation) \n\nenv.render()\n\nwhile not env.done:\n    action = timo_agent(observation, env.configuration)\n    print(\"Timo plays\", action)\n    observation, reward, done, info = trainer.step(action)\n    env.render()\n    \nprint(\"Timo got\", reward);\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test your Agent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\nenv.run([timo_agent, \"random\"])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agents = {\n    \"Timo\": timo_agent,\n    \"Constant\": constant_agent,\n    \"Negamax\": \"negamax\",\n    \"Random\": \"random\"\n}\n    \nprint(agents)\n\nnum_episodes = 2\npoints = {}\nfor name in agents:\n    points[name] = 0\nprint(points)\n\nfor name_1 in agents:\n    for name_2 in agents:\n        if (name_1 == name_2):\n            continue\n        env.reset()\n        result = evaluate(\"connectx\", [agents[name_1], agents[name_2]], num_episodes=num_episodes)\n        \n        #for r in result:\n        #    print(r)\n        name_1_points = sum([r[0] for r in result if r[0] is not None])\n        name_2_points = sum([r[1] for r in result if r[1] is not None])\n        \n        print(\"Playing\", num_episodes, \":\", name_1, \"=\", name_1_points, \"points /\", name_2, \"=\", name_2_points, \"points\")\n        points[name_1] += name_1_points\n        points[name_2] += name_2_points\n\nprint(points)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write Submission File\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(timo_agent, \"submission.py\")\n\n# write other test file\nwith open(\"testfile.txt\", \"a\" if os.path.exists(\"testfile.txt\") else \"w\") as f:\n        f.write(\"Teeest\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validate Submission\nPlay your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n\nWhy validate? This roughly verifies that your submission is fully encapsulated and can be run remotely.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: Stdout replacement is a temporary workaround.\nimport sys\nout = sys.stdout\nsubmission = utils.read_file(\"/kaggle/working/submission.py\")\nagent = utils.get_last_callable(submission)\nsys.stdout = out\n\nenv = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}