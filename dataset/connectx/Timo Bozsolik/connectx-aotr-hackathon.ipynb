{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install kaggle-environments"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install 'kaggle-environments>=0.1.6'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create ConnectX Environment"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils\n\nenv = make(\"connectx\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def timo_agent(observation, configuration):\n    from random import choice\n    import numpy as np\n    \n    # 0. Helper functions\n    def is_win(board, column, columns, rows, inarow, mark, has_played=True):\n        row = (\n            min([r for r in range(rows) if board[column + (r * columns)] == mark])\n            if has_played\n            else max([r for r in range(rows) if board[column + (r * columns)] == 0])\n        )\n        def count(offset_row, offset_column):\n            for i in range(1, inarow + 1):\n                r = row + offset_row * i\n                c = column + offset_column * i\n                if (\n                    r < 0\n                    or r >= rows\n                    or c < 0\n                    or c >= columns\n                    or board[c + (r * columns)] != mark\n                ):\n                    return i - 1\n            return inarow\n\n        return (\n            count(1, 0) >= inarow  # vertical.\n            or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n            or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n            or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n        )\n    \n    def column_is_full(column, board):\n        return board[0][column] != 0\n    \n    # setup\n    playable_columns = [c for c in range(configuration.columns) if observation.board[c] == 0]\n    board = np.reshape(observation.board, (configuration.rows, configuration.columns))\n    me = observation.mark\n    other_player = 1 if observation.mark == 2 else 2\n    \n    #print(\"--> Playable\", playable_columns)\n\n    # 1. If you can win with any move, just make that move\n    for col in playable_columns:\n        if (is_win(observation.board, col, configuration.columns, configuration.rows, configuration.inarow - 1, me, False)):\n            #print(\"==> (1) Play\", col)\n            return col\n        \n    # 2. If other player would win with that move, the play that one\n    for col in playable_columns:\n        if (is_win(observation.board, col, configuration.columns, configuration.rows, configuration.inarow - 1, other_player, False)):\n            #print(\"==> (2) Play\", col)\n            return col\n        \n    # 3. Calculate a score for each column and return best score\n    scores = []\n    for col in playable_columns:\n        score = 0\n        \n        for get_inarow in range(configuration.inarow - 1):\n            if (is_win(observation.board, col, configuration.columns, configuration.rows, get_inarow, observation.mark, False)):\n                #print(\"--> (2) Col\", col, \"get_inarow\", get_inarow, \"yay\")\n                score += (get_inarow + 1)\n            #print(\"--> (2) Col\", col, \"get_inarow\", get_inarow, \"noo\")\n        \n        scores.append([col, score])\n        #print(\"--> (3) Col\", col, \"score\", score)\n    \n    col = 0\n    max_score = 0\n    for score in scores:\n        if score[1] > max_score:\n            max_score = score[1]\n            col = score[0]\n    \n    #print(\"==> (3) Play\", col)\n    return col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dev_agent(observation, configuration):\n    from random import choice\n    def score_action(observation, configuration, action):\n        new_board = look_next(observation, configuration, action)\n        score = 0\n        if observation.mark == 1:\n            enemy = 2\n        else:\n            enemy = 1\n        #count row with most-in a row\n        max_row_score = 0\n        running_score = 0\n        for r in range(configuration.rows):\n            for c in range(configuration.columns):\n                if new_board[r][c] == observation.mark:\n                    running_score += 1\n                    if running_score > score:\n                        max_row_score = running_score\n                if new_board[r][c] == enemy:\n                    running_score = 0\n                if running_score > max_row_score:\n                    max_row_score = running_score\n                else:\n                    running_score = 0\n            running_score = 0\n        max_column_score = 0\n        for c in range(configuration.columns):\n            for r in range(configuration.rows):\n                if new_board[r][c] == observation.mark:\n                    running_score += 1\n                if new_board[r][c] == enemy:\n                    running_score = 0\n                if running_score > max_column_score:\n                    max_column_score = running_score\n                else:\n                    running_score = 0\n            running_score = 0\n        return max(max_column_score, max_row_score)\n    def look_next(observation, configuration, col):\n        board = np.reshape(observation.board, (configuration.rows, configuration.columns))\n        new = board.copy()\n        for r in range(configuration.rows-1, -1, -1):\n            if new[r][col] == 0:\n                new[r][col] = observation.mark\n                break\n        return new\n    playable_columns = [c for c in range(configuration.columns) if observation.board[c] == 0]\n    scores_dict = {}\n    high_score = 0\n    best_move = 0\n    for c in playable_columns:\n        temp_score = score_action(observation, configuration, c)\n        if temp_score > high_score:\n            high_score = temp_score\n            best_move = c\n    return best_move\n    #return choice([c for c in range(configuration.columns) if observation.board[c] == 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ilya_agent(observation, configuration):\n    import numpy as np\n    mark = observation.mark # who am I? 0 or 1\n    columns = configuration.columns\n    rows = configuration.rows\n    inarow = configuration.inarow\n    board = observation.board\n    brd = np.array(board).reshape(rows, columns)\n    if np.max(brd[rows - 1]) == 0:\n        return columns // 2\n    tmp = np.sum(brd, axis=0)\n    action = int(np.argmax(tmp))\n    if np.max(brd[0]) > 0:\n        # top filled\n        action = int(np.argmin(tmp))\n    return action","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mark_agent(observation, configuration):\n    from random import choice\n    return choice([c for c in range(configuration.columns) if observation.board[c] == 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def victor_agent(observation, configuration):\n    from random import choice\n    import numpy as np\n    from functools import reduce\n    #print(observation.board)\n    board = np.reshape(observation.board, (configuration.rows, configuration.columns))\n    top_player = reduce(lambda x, y: [y[c] if x[c] == 0 else x[c] for c in range(configuration.columns)], board)\n    #print(top_player)\n    for i in range(len(top_player)):\n        if top_player[i] == observation.mark and observation.board[i] == 0:\n            return i\n    if sum(map(lambda x: x == 0, board[-1])) == 0:\n        return choice([c for c in range(configuration.columns) if board[-1] == 0])\n    else:\n        return choice([c for c in range(configuration.columns) if observation.board[c] == 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def peijen_agent(observation, configuration):\n    import numpy as np\n    def can_I_win(column, board):\n        for r in range(configuration.rows):\n            if board[r][column] != 0 and board[r][column] != observation.mark:\n                if r >= 4:\n                    return True\n                else:\n                    return False\n            else:\n                # can't really win but block the other player\n                if r > 4 and board[r][column] != observation.mark:\n                    return True\n        return True\n    # setup\n    playable_columns = [c for c in range(configuration.columns) if observation.board[c] == 0]\n    board = np.reshape(observation.board, (configuration.rows, configuration.columns))\n    for x in range(configuration.columns):\n        column = (4 + x) % configuration.columns\n        if column in playable_columns and can_I_win(column, board):\n            return column\n    # cannot win? play 4 anyway\n    return 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jacky_agent(observation, configuration):\n    return 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agents = {\n    \"Timo\": timo_agent,\n    \"Dev\": dev_agent,\n    \"Ilya\": ilya_agent,\n    \"Mark\": mark_agent,\n    \"Victor\": victor_agent,\n    \"Peijen\": peijen_agent,\n    \"Jacky\": jacky_agent,\n    \"Random\": \"random\",\n#    \"Negamax\": \"negamax\"\n}\n    \nprint(agents)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_episodes = 10\npoints = {}\nfor name in agents:\n    points[name] = 0\nprint(points)\n\nfor name_1 in agents:\n    for name_2 in agents:\n        if (name_1 == name_2):\n            continue\n        env.reset()\n        result = evaluate(\"connectx\", [agents[name_1], agents[name_2]], num_episodes=num_episodes)\n        \n        #for r in result:\n        #    print(r)\n        name_1_points = sum([r[0] for r in result if r[0] is not None])\n        name_2_points = sum([r[1] for r in result if r[1] is not None])\n        \n        print(\"Playing\", num_episodes, \":\", name_1, \"=\", name_1_points, \"points /\", name_2, \"=\", name_2_points, \"points\")\n        points[name_1] += name_1_points\n        points[name_2] += name_2_points\n\nprint(points)       ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}