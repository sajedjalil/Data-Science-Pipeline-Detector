{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Some heuristic reward/penalty system is developed\n* One step ahaed calculation strategy is implemented (sim_play).\n* Deeper calculation is implemented (play_deep), but previous one (sim_play) got better reulsts.\n* Developed agent (sim_play) has 99.9% winning rate against random.\n\nforked from https://www.kaggle.com/domcastro/connectx-rule-based-easy-solution-or-negamax\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.4 cannot be found (uncomment if needed). \n# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n\n# ConnectX environment was defined in v0.1.4\n!pip install 'kaggle-environments>=0.1.4'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make\nfrom kaggle_environments.envs.connectx import connectx as ctx\n\nenv = make(\"connectx\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create an Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"def agent(observation, configuration):\n    import numpy as np\n    \n    # reward parameters\n    rw_win = 10   # reward for win\n    rw_loss = -15 # penalty for loose\n    rw_3=2        # reward for making 3 in a row\n    rw_3enemy=-3  # penalty for making 3 in a row (enemy)\n    rw_2=0        # for 2 in a row\n    rw_2enemy=0   # for 2 in a row\n    rws_init=[0,  0.3,  0.5,  0.7,  0.4,  0.2,  0] # initial rewards (prefer center slightly)\n    \n    # me:me_or_enemy=1, enemy:me_or_enemy=2\n    def check_vertical_chance(me_or_enemy,board=[], n=4):\n        if len(board)==0:\n            board=observation.board\n        chances=[]\n        for i in range(0, 7):\n            for j in range(6-n+1,6):\n                for k in range(n-1): # check if vertical row for te palyer and empty last cell\n                    if board[i+7*(j-k)] != me_or_enemy: # if all same player\n                        break\n                    if k==n-2 and board[i+7*(j-k-1)] == 0: # last cell empty\n                        chances.append(i)\n        return chances\n            \n    # me:me_or_enemy=1, enemy:me_or_enemy=2\n    def check_horizontal_chance(me_or_enemy,board=[], n=4):\n        if len(board)==0:\n            board=observation.board\n        chances=[]\n        for i in range(6):\n            for j in range(0, 7-n+1): \n                sums=sum([board[i*7 + j+s] == me_or_enemy for s in range(n)])\n                if sums == n-1:\n                    for k in [i*7 + j+s for s in range(n)]:\n                        if board[k] == 0:\n                            chance_cell_num = k\n                            # bottom line\n                            if chance_cell_num in range(35, 42):\n                                chances.append(chance_cell_num - 35)\n                            # others\n                            elif board[chance_cell_num+7] != 0:\n                                chances.append(chance_cell_num % 7)\n        return chances            \n    \n    # me:me_or_enemy=1, enemy:me_or_enemy=2\n    def check_slanting_chance(me_or_enemy, lag, cell_list,board=[], n=4):\n        if len(board)==0:\n            board=observation.board\n        chances=[]\n        for i in cell_list:\n            sums=sum([board[i+lag*s] == me_or_enemy for s in range(n)])\n            if sums == n-1:\n                for j in [i+lag*s for s in range(n)]:\n                    if board[j] == 0:\n                        chance_cell_num = j\n                        # bottom line\n                        if chance_cell_num in range(35, 42):\n                            chances.append(chance_cell_num - 35)\n                        # others\n                        elif board[chance_cell_num+7] != 0:\n                            chances.append(chance_cell_num % 7)\n        return chances\n    \n    def check_horizontal_first_enemy_chance():\n        # enemy's chance\n        if observation.board[38] == enemy_num:\n            if sum([observation.board[39] == enemy_num, observation.board[40] == enemy_num]) == 1 \\\n            and observation.board[37] == 0:\n                for i in range(39, 41):\n                    if observation.board[i] == 0:\n                        return i - 35\n            if sum([observation.board[36] == enemy_num, observation.board[37] == enemy_num]) == 1 \\\n            and observation.board[39] == 0:\n                for i in range(36, 38):\n                    if observation.board[i] == 0:\n                        return i - 35\n        return -99 # no chance\n\n    def check_first_or_second():\n        count = 0\n        for i in observation.board:\n            if i != 0:\n                count += 1\n        # first\n        if count % 2 != 1:\n            my_num = 1\n            enemy_num = 2\n        # second\n        else:\n            my_num = 2\n            enemy_num = 1\n        return my_num, enemy_num\n        \n    def check_my_chances():\n        # check my virtical chance\n        result = check_vertical_chance(my_num)\n        if len(result)>0:\n            return result[0]\n        # check my horizontal chance\n        result = check_horizontal_chance(my_num)\n        if len(result)>0:\n            return result[0]\n        # check my slanting chance 1 (up-right to down-left)\n        result = check_slanting_chance(my_num, 6, [3,4,5,6,10,11,12,13,17,18,19,20])\n        if len(result)>0:\n            return result[0]\n        # check my slanting chance 2 (up-left to down-right)\n        result = check_slanting_chance(my_num, 8, [0,1,2,3,7,8,9,10,14,15,16,17])\n        if len(result)>0:\n            return result[0]\n        # no chance\n        return -99\n    \n    def check_enemy_chances():\n        # check horizontal first chance\n        result = check_horizontal_first_enemy_chance()\n        if result != -99:\n            return result\n        # check enemy's vertical chance\n        result = check_vertical_chance(enemy_num)\n        if len(result)>0:\n            return result[0]\n        # check enemy's horizontal chance\n        result = check_horizontal_chance(enemy_num)\n        if len(result)>0:\n            return result[0]\n        # check enemy's slanting chance 1 (up-right to down-left)\n        result = check_slanting_chance(enemy_num, 6, [3,4,5,6,10,11,12,13,17,18,19,20])\n        if len(result)>0:\n            return result[0]\n        # check enemy's slanting chance 2 (up-left to down-right)\n        result = check_slanting_chance(enemy_num, 8, [0,1,2,3,7,8,9,10,14,15,16,17])\n        if len(result)>0:\n            return result[0]\n        # no chance\n        return -99\n\n    # check first or second\n    my_num, enemy_num = check_first_or_second()\n\n    # defines the placed cell for playing pos. ex: playing 0 could place cell 14\n    def RealPos(pos,board):\n        real_pos=None\n        for d in reversed(range(6)):\n            if board[pos+7*d]==0:\n                real_pos=pos+7*d\n                break\n        return real_pos\n    \n    # simulate play one step and get possible rewards\n    def sim_play(player=my_num, opponent=enemy_num, board=[]):\n        # check real position when playing\n        # check max lengths as reward (non-blocked lengths)\n        # choose max reward     \n        rws=rws_init.copy() # # use priority - 3 > 2 > 4 > 1 > 5 > 0 > 6\n        if len(board)==0:\n            board=observation.board.copy()\n        for i in range(7):\n            col_empty=[j for j in range(6) if board[i+7*j]==0]\n            if len(col_empty)==0:\n                rws[i]=-9999\n            else:\n                pos=max(col_empty)\n                board2=board.copy()\n                board2[i+pos*7]=player\n\n                # makin 4 in a row chanes\n                v=check_vertical_chance(player,board2)\n                h=check_horizontal_chance(player,board2)\n                s1=check_slanting_chance(player, 6, [3,4,5,6,10,11,12,13,17,18,19,20],board2)\n                s2=check_slanting_chance(player, 8, [0,1,2,3,7,8,9,10,14,15,16,17],board2)\n                chances = v + h + s1 + s2\n                rws[i]+=len(chances)**2 * rw_win\n                # making 3 in a row chances\n                v=check_vertical_chance(player,board2,n=3)\n                h=check_horizontal_chance(player,board2,n=3)\n                s1=check_slanting_chance(player, 6, [2,3,4,5,9,10,11,12,16,17,18,19,23,24,25,26],board2,n=3)\n                s2=check_slanting_chance(player, 8, [1,2,3,4,8,9,10,11,15,16,17,18,22,23,24,25],board2,n=3)\n                chances = v + h + s1 + s2\n                rws[i]+=len(chances)**2 * rw_3\n                # making 2 in a row chances\n                rws[i]+=len(chances) * rw_win\n                v=check_vertical_chance(player,board2,n=2)\n                h=check_horizontal_chance(player,board2,n=2)\n                s1=check_slanting_chance(player, 6, [1,2,3,4, 8,9,10,11, 15,16,17,18, 22,23,24,25],board2,n=2)\n                s2=check_slanting_chance(player, 8, [2,3,4,5, 9,10,11,12, 16,17,18,19, 23,24,25,26],board2,n=2)\n                chances = v + h + s1 + s2\n                rws[i]+=len(chances) * rw_2\n\n                # making 4 in a row chanes for opponent\n                v=check_vertical_chance(opponent,board2)\n                h=check_horizontal_chance(opponent,board2)\n                s1=check_slanting_chance(opponent, 6, [3,4,5,6,10,11,12,13,17,18,19,20],board2)\n                s2=check_slanting_chance(opponent, 8, [0,1,2,3,7,8,9,10,14,15,16,17],board2)\n                chances = v + h + s1 + s2\n                rws[i]+=len(chances)**2 * rw_loss\n                # making 3 in a row chanes for opponent\n                v=check_vertical_chance(opponent,board2,n=3)\n                h=check_horizontal_chance(opponent,board2,n=3)\n                s1=check_slanting_chance(opponent, 6, [2,3,4,5,9,10,11,12,16,17,18,19,23,24,25,26],board2,n=3)\n                s2=check_slanting_chance(opponent, 8, [1,2,3,4,8,9,10,11,15,16,17,18,22,23,24,25],board2,n=3)\n                chances = v + h + s1 + s2\n                rws[i]+=len(chances)**2 * rw_3enemy\n                # making 2 in a row chanes for opponent\n                v=check_vertical_chance(opponent,board2,n=2)\n                h=check_horizontal_chance(opponent,board2,n=2)\n                s1=check_slanting_chance(opponent, 6, [1,2,3,4, 8,9,10,11, 15,16,17,18, 22,23,24,25],board2,n=2)\n                s2=check_slanting_chance(opponent, 8, [2,3,4,5, 9,10,11,12, 16,17,18,19, 23,24,25,26],board2,n=2)\n                chances = v + h + s1 + s2\n                rws[i]+=len(chances) * rw_2enemy\n\n        return rws\n    \n    def play_deep(alpha=0.6):\n        rws=sim_play()\n        #rws=np.array(rws)\n        #moves=rws.argsort()[-4:][::-1]\n        board=observation.board.copy()\n        for move in range(7): # check all 7 moves\n            board2=board.copy()\n            real_pos=RealPos(move,board2)\n            if real_pos==None: # move is not posibble\n                continue\n            board2[real_pos]=my_num\n            rws_enemy=sim_play(player=enemy_num, opponent=my_num, board=board2)\n            rws_enemy_=np.array(rws_enemy)\n            moves2=[t for t in range(7)] # check all 7 moves\n            if rws_enemy!=rws_init:\n                rws[move] -= alpha * sum(sorted(rws_enemy)[-3:])/3 # - alpha * average of best 3 move\n                moves2=rws_enemy_.argsort()[-3:][::-1] # best 3 enemy move\n            for move2 in moves2:\n                board3=board2.copy()\n                real_pos=RealPos(move2,board3)\n                if real_pos==None:\n                    continue                \n                board3[real_pos]=enemy_num\n                rws_me=sim_play(player=my_num, opponent=enemy_num, board=board3)\n                rws[move] += alpha*alpha * sum(sorted(rws_me)[-3:])/3 # + alpha^2 * average of best 3 move\n        best_rws=-9999\n        best_move=0\n        for move in range(7):\n            if rws[move]>best_rws:\n                best_move=move\n        return int(best_move)\n    \n    # play for the next step not further ahead\n    def play_greedy():\n        rws=sim_play()\n        move=int(np.argmax(rws))\n        return move\n\n    # if immediate no immediate reward, calculate deeper\n    def play_partial():\n        rws=sim_play()\n        if rws!=rws_init:\n            move=int(np.argmax(rws))\n            return move\n        else:\n            move = play_deep()\n            return move\n        move=int(np.argmax(rws))\n        return move\n    \n    #################################################\n    ####################  PLAY  #####################\n    #################################################\n    \n    # check immediate wins and play if occurs\n    result = check_my_chances()\n    if result != -99:\n        return result\n    \n    # check possible immediate lost and prevent\n    result = check_enemy_chances()\n    if result != -99:\n        return result\n    \n    # decision for no immediate win or loss\n    move=play_greedy()\n    return move\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\n# Play as the first agent against default \"random\" agent.\n#env.run([my_agent, \"random\"])\nenv.run([agent, \"negamax\"])\nenv.render(mode=\"ipython\", width=300, height=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([\"random\", agent])\n# env.run([agent, \"negamax\"])\nenv.render(mode=\"ipython\", width=300, height=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\n# my agent VS my agent\nenv.run([agent, agent])\n# env.run([agent, \"negamax\"])\nenv.render(mode=\"ipython\", width=300, height=300)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Debug/Train your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"while not env.done:\n    my_action = agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_reward(rewards):\n    win=sum(r[0] for r in rewards if r[0] not in [None,0.5])\n    loss=sum(r[1] for r in rewards if r[1] not in [None,0.5])\n    eq=len(rewards)-win-loss\n    rew= (win+eq/2) / (win+loss+eq)\n    rew=int(rew*1000+0.5)/1000.0\n    return rew, win, loss, eq\n\nprint(\"My Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [agent, agent], num_episodes=1)))\n\n\"\"\"\n----------------- 0 -----------------\nRandom vs Agent: (0.003, 3, 997, 0)\nAgent vs Random: (0.999, 998, 1, 1)\n \n----------------- 1 -----------------\nRandom vs Agent: (0.004, 3, 996, 1)\nAgent vs Random: (1.0, 1000, 0, 0)\n \n----------------- 2 -----------------\nRandom vs Agent: (0.001, 1, 999, 0)\nAgent vs Random: (0.998, 998, 2, 0)\n\"\"\"\n# Run multiple episodes to estimate it's performance.\n# remove for commit to save time, increase repeat and runs for real performance test\nrepeat=3\nruns=10\nfor i in range(repeat):\n    print(\"-----------------\",i,\"-----------------\")\n    print(\"Random vs Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", agent], num_episodes=runs)))\n    print(\"Agent vs Random:\", mean_reward(evaluate(\"connectx\", [agent, \"random\"], num_episodes=runs)))\n    print(\" \")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write Submission File\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(agent, \"submission.py\")\nprint(\"Done\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}