{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook we will implement a simple \"1-step-lookahead\" agent. The agent takes a winning move if one is avaiable. If not then it tries blocking opponent's winning move if they are about to win. Otherwise it takes a random move. \n\nWe will also look into simplifying the submission process, by automatically adding code of specified functions after main function definition."},{"metadata":{},"cell_type":"markdown","source":"# Install kaggle-environments"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.4 cannot be found (uncomment if needed). \n# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n\n# ConnectX environment was defined in v0.1.4\n!pip install 'kaggle-environments>=0.1.4'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create ConnectX Environment"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make\n\nenv = make(\"connectx\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).\n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy (more may be added later). "},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_winning_board(board, configuration):\n    \"\"\"\n    Check if a given board has 4 connected\n    \"\"\"\n    move_deltas = [(1, 0), # horizontal\n                   (0, 1), # vertical\n                   (1, 1), # diagonal top-right\n                   (-1, 1) # diagonal bottom-left\n                  ]\n    \n    rows, columns = configuration.rows, configuration.columns\n    for r in range(rows):\n        for c in range(columns):\n            # ignore empty cells\n            if board[r][c] == 0:\n                continue\n                \n            for dr, dc in move_deltas:\n                # check we don't leave the board\n                if not (0 < r + dr*3 < rows and 0 < c + dc*3 < columns):\n                    continue\n                # finally check for 4 in a row\n                if board[r][c] == board[r+dr][c+dc] == board[r+dr*2][c+dc*2] == board[r+dr*3][c+dc*3]:\n                    return True\n        \n    return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_move(board, column, marker, configuration):\n    \"\"\"\n    Returns a new board with a chip dropped at provided column\n    \"\"\"\n    import copy\n    \n    board = copy.deepcopy(board) # avoid modifying the original board\n    row = 0\n    max_row = configuration.rows\n    \n    # find lowest unfilled\n    while row < max_row and board[row][column] == 0:\n        row += 1\n    \n    board[row - 1][column] = marker\n    \n    return board","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This agent random chooses a non-empty column.\ndef my_agent(observation, configuration):\n    from random import choice\n    import numpy\n    \n    rows, columns = configuration.rows, configuration.columns\n    allowable_moves = [c for c in range(columns) if observation.board[c] == 0]\n    \n    # transform into 2D board\n    board = numpy.array(observation.board)\n    board.resize(rows, columns)\n    \n    for move in allowable_moves:\n        for marker in [\"1\", \"0\"]: # first try our moves then opponent's\n            new_board = make_move(board, move, marker, configuration)\n            if is_winning_board(new_board, configuration):\n                return move\n        \n    return choice(allowable_moves)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([my_agent, \"random\"])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Debug/Train your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nwhile not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    # env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) / sum(r[0] + r[1] for r in rewards)\n\n# Run multiple episodes to estimate it's performance.\nprint(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\nprint(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write Submission File"},{"metadata":{},"cell_type":"markdown","source":"Here I modify the script to insert additional specified functions into the beginning of the main agent function"},{"metadata":{"trusted":true},"cell_type":"code","source":"import inspect\nimport os\n\n# can get function reference through 'globals()[func_name]'\nimport_functions = [\n    is_winning_board,\n    make_move\n]\n\ndef write_agent_to_file(function, file, import_functions=[]):\n    # get source and transform into list of lines\n    function_source = inspect.getsource(my_agent)\n    function_source = function_source.split(\"\\n\")\n\n    for func in import_functions:\n        import_source = inspect.getsource(func)\n        # add tab after every new line\n        import_source = import_source.split(\"\\n\")\n        import_source = [\"    \" + line for line in import_source]\n        # insert new function after function definition\n        function_source.insert(1, \"\\n\".join(import_source))\n    \n    function_source = \"\\n\".join(function_source)\n    \n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(function_source)\n        print(function_source) # print written code\n\nwrite_agent_to_file(my_agent, \"submission.py\", import_functions=import_functions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}