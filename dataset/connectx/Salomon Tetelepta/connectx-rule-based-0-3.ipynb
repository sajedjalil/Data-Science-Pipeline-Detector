{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install kaggle-environments"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n\n# ConnectX environment was defined in v0.1.6\n!pip install 'kaggle-environments>=0.1.6'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_agent(observation, configuration):\n    import numpy as np\n    import re\n    from scipy.linalg import hankel, toeplitz\n    \n    def get_opponent(player):\n        assert player in [1, 2], \"valid player values: {1, 2}\"\n\n        # transform to range {0, 1}\n        player -= 1\n\n        # get opponent by adding 1 mod 2\n        opponent = (player + 1) % 2\n\n        # transform back to range {1, 2}\n        opponent += 1\n\n        return opponent\n\n\n    def array2string(arr):\n        arr = np.array(arr)\n        return \"\".join(list(arr.astype(int).astype(str)))\n\n    \n    def rows_to_board_indices(matches):\n        '''\n        return the board coordinates for a list of tuples containing list_indices and match_indices:\n\n        - matches (list): [(list_index, match_index), (list_index, match_index) .. ]\n        '''\n\n        output = []\n        for list_index, match_index in matches:\n            output.append((list_index, match_index))\n        return output\n\n\n    def cols_to_board_indices(matches):\n        '''\n        return the board coordinates for a list of tuples containing list_indices and match_indices:\n\n        - matches (list): [(list_index, match_index), (list_index, match_index) .. ]\n        '''\n\n        output = []\n        for list_index, match_index in matches:\n            output.append((match_index, list_index))\n        return output\n\n\n    def diag_to_board_indices(board, matches, direction):\n        '''\n        return board indices for diagonal hits.\n\n        - board (ndarray): numpy 2D array representing board state\n        - matches (list): [(list_index, match_index), (list_index, match_index) .. ]\n        - direction (str):\n            - 'bltr': bottom-left top-right diagonals\n            - 'tlbr': top-left bottom-right diagonals\n        ''' \n        assert direction in [\"bltr\", 'tlbr']\n\n        # get dimensions\n        nrows, ncols = board.shape\n\n        # initialize first column and last row to set up diagonal matrix\n        first_col = np.arange(nrows)\n        last_row = np.arange(nrows-1, nrows + ncols-1)\n\n        if direction == \"bltr\":\n            # use toeplitz matrix for the bottom-left to top-right diagonal\n            diagonal_matrix = toeplitz(first_col[::-1], last_row)\n        else:\n            # use hankel matrix for the top-left to bottom-right diagonals\n            diagonal_matrix = hankel(first_col, last_row)\n\n        output = []\n        for list_index, match_index in matches:\n            diagonal_board_indices = np.where(diagonal_matrix == list_index)\n            r = diagonal_board_indices[0][match_index]\n            c = diagonal_board_indices[1][match_index]\n            output.append((r, c))\n        return output\n    \n\n    def find_pattern(list_of_lists, pattern):\n        '''\n        Find pattern (str) in a list of arrays.\n\n        Returns list of lists with start indices of each match.\n\n        Examples:\n            >>> matches = find_pattern([[1, 0, 0, 1, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 1], [1, 0, 1, 1, 0, 1, 1]], \"11\")\n            >>> for match in matches:\n            >>>    print(match)\n            [3]\n            []\n            [0, 2]\n            [2, 5]\n        '''\n\n        all_matches = []\n        for i, arr in enumerate(list_of_lists):\n            string = array2string(arr)\n            all_matches.append([(m.start()) for m in re.finditer(pattern, string)])\n        return all_matches\n\n\n    def find_zeros_pattern(list_of_lists, pattern):\n        '''\n        Find pattern (str) in a list of arrays that are actionable. This function assumes that the pattern contains zeros (\"0\")\n        This function finds the pattern in the list of lists, and checks if the zeros that are part of the match are actionable, which means\n        that there exists a valid action, to fill the corresponding cell.\n\n        Returns list of lists with start indices of each match.\n\n        Examples:\n            >>> matches = find_actionable_pattern([[1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 1, 0, 1, 0]], \"1010\")\n            >>> print(matches)\n            [(0, 1), (0, 5), (2, 4), (0, 3), (0, 7), (2, 6)]\n\n        In each tuple the first value is the list index, the second value is the index of a zero-value in that list.\n        '''\n\n        # find all matches\n        matches = find_pattern(list_of_lists, pattern)\n\n        # get indices of the zeros in the pattern\n        zeros_in_pattern = [z.start() for z in re.finditer(\"0\", pattern)]\n\n        results = []\n        for zero in zeros_in_pattern:\n            for i, match in enumerate(matches):\n                if len(match) > 0:\n                    for entry in list(np.array(match) + zero):\n                        results.append((i, entry))\n        return results\n\n\n    def is_actionable(board, r, c):\n        '''\n        return true if the (r, c) cell can be reached by making an action (a=c)\n        '''\n        if (board[r, c] == 0) and (0 not in board[r+1:, c]):\n            return True\n        return False\n\n\n    def filter_actionable(board, coords):\n        actionable_coords = []\n        for r, c in coords:\n            if is_actionable(board, r, c):\n                actionable_coords.append((r, c))\n        return actionable_coords\n\n\n    def get_board_lines(board):\n        nrows = board.shape[0]\n        ncols = board.shape[1]        \n    \n        rows = [board[i, :] for i in np.arange(nrows)]\n        cols = [board[:, j] for j in np.arange(ncols)]\n\n        # offset ranges to get all diagonals for both bottom-left-top-right (bltr) and top-left-bottom-right (tlbr)\n        offset_bltr = {\n            'start': -(nrows-1), \n            'stop': ncols\n        } \n        offset_tlbr = {\n            'start': -(ncols-1), \n            'stop': nrows\n        }\n        \n        diag1 = [np.diagonal(board, offset=offset) for offset in np.arange(**offset_bltr)]\n        diag2 = [np.diagonal(np.rot90(board), offset=offset) for offset in np.arange(**offset_tlbr)]    \n    \n        return {'rows': rows, 'cols': cols, 'diag1': diag1, 'diag2': diag2}\n\n    \n    def find_actionable_patterns(board, pattern):\n        \n        # get rows, columns and diagonal lines\n        all_lists = get_board_lines(board)\n\n        results = []\n        actionable_results = []    \n\n        for list_type, list_of_lists in all_lists.items():\n            zero_indices = find_zeros_pattern(list_of_lists, pattern)\n            if list_type == 'rows':\n                board_coords = rows_to_board_indices(zero_indices)\n            if list_type == 'cols':\n                board_coords = cols_to_board_indices(zero_indices)\n            if list_type == 'diag1':\n                board_coords = diag_to_board_indices(board, zero_indices, direction=\"bltr\")\n            if list_type == 'diag2':\n                board_coords = diag_to_board_indices(board, zero_indices, direction=\"tlbr\")\n            results.extend(board_coords)\n            actionable_results.extend(filter_actionable(board, board_coords))\n        return results, actionable_results\n    \n    ##############\n    ### look ahead\n    \n    def get_row_of_first_piece(column):\n        # get row of first piece\n        pieces_in_column = np.nonzero(column)\n        if np.size(pieces_in_column) > 0:\n            return np.min(pieces_in_column)\n        else:\n            return len(column)\n\n\n    def get_next_state(board, player, action):\n        assert action in np.arange(board.shape[1]), f\"invalid action {action}. Valid range: {0}-{board.shape[1]-1}\"\n\n        # copy board, to preserve original state\n        board = board.copy()\n\n        # column where action is taken \n        column = board[:, action]\n\n        # get row for first piece in the column (top-down)\n        row_first_piece = get_row_of_first_piece(board[:, action])\n\n        # test for full columns\n        assert row_first_piece >= 0, f\"invalid action {action}, column is full, row_first_piece: {row_first_piece}\"\n\n        # add piece for player to cell above\n        board[row_first_piece-1, action] = player\n\n        return board\n\n    \n    def cartesian_product(num_actions, num_levels):\n        '''\n        Return tree with all possible actions and counter actions.\n\n        Example:\n\n        >>> cartesian_product(num_actions=3, num_levels=2)\n        >>> array([[0, 0],\n           [0, 1],\n           [0, 2],\n           [1, 0],\n           [1, 1],\n           [1, 2],\n           [2, 0],\n           [2, 1],\n           [2, 2]])\n        '''\n        arrays = np.repeat([np.arange(num_actions)], num_levels, axis=0)\n\n        num_arrays = len(arrays)\n        dtype = np.result_type(*arrays)\n        arr = np.empty([len(a) for a in arrays] + [num_arrays], dtype=dtype)\n        for i, a in enumerate(np.ix_(*arrays)):\n            arr[...,i] = a\n        return arr.reshape(-1, num_arrays)\n    \n    \n    def game_finished(board, inarow=4):\n        all_lines = get_board_lines(board)\n\n        # look for winning pattern accross all lines\n        for line_type, line in all_lines.items():\n            for player in ['1', '2']:\n                found = find_pattern(line, inarow * player)\n                if len(np.nonzero(found)[0]):\n                    return True, int(player)\n        return False, None\n\n    \n    class Observation():\n        board = None\n        mark = 1\n\n\n    class Configuration():\n        columns = 7\n        rows = 6\n        inarow = 4\n\n\n    def get_losing_moves(board, player):\n        nrows, ncols = board.shape\n        num_actions = ncols\n        num_levels = 2\n        opponent = get_opponent(player)\n        sim_observation = Observation()\n        sim_observation.board = board\n        sim_observation.mark = player\n\n        sim_configuration = Configuration()\n\n        # get cartesian product, and reshape it group it by player action\n        action_tree = cartesian_product(num_actions, num_levels)\n\n        losing_moves = []\n\n        for trajectory in action_tree:\n            # reset observation to current state and make sure player is next to move\n            sim_observation.board = list(np.ravel(board))\n            sim_observation.mark = player\n\n            for action in trajectory:\n                if sim_observation.board[action] != 0:\n                    # invalid action\n                    continue\n\n                # simulate a move\n                next_state = get_next_state(np.array(sim_observation.board).reshape(nrows, ncols), sim_observation.mark, action)\n\n                # update board\n                sim_observation.board = list(np.ravel(next_state))\n\n                # switch mark to opponent\n                sim_observation.mark = get_opponent(sim_observation.mark)\n\n                done, won = game_finished(next_state, inarow=4)\n \n                if done == True and won == opponent:\n                    losing_moves.append(trajectory[0])\n                    break\n        return losing_moves\n    \n    ##################\n    ### end look ahead\n    \n    \n    def return_action():\n        # shape board\n        nrows = configuration['rows']\n        ncols = configuration['columns'] \n        \n        board = np.array(observation['board']).reshape((nrows, ncols))\n        player = int(observation['mark'])\n        opponent = get_opponent(player)\n        \n        # define patterns to search for\n        patterns = [\n            # winning / losing moves\n            {'string': '1110', 'weight': 1},\n            {'string': '1101', 'weight': 1},\n            {'string': '1011', 'weight': 1},             \n            {'string': '0111', 'weight': 1},\n            \n            {'string': '110', 'weight': 0.4},\n            {'string': '101', 'weight': 0.4},\n            {'string': '011', 'weight': 0.4},            \n        ]\n        \n        progressing_moves = []\n        preventing_moves = []\n        \n        for pattern in patterns:            \n            # find the patterns accross columns, rows, diagonals\n            results_player, actionable_player_moves = find_actionable_patterns(board, pattern['string'].replace('1', str(player)))\n            results_player, actionable_opponent_moves = find_actionable_patterns(board, pattern['string'].replace('1', str(opponent)))\n            \n            for move in actionable_player_moves:\n                progressing_moves.append({'action': move[1], 'weight': pattern['weight'], 'is_player': 1, 'string': pattern['string']})\n            \n            for move in actionable_opponent_moves:\n                preventing_moves.append({'action': move[1], 'weight': pattern['weight'], 'is_player': 0, 'string': pattern['string']})\n           \n        all_moves = progressing_moves + preventing_moves\n        \n        losing_moves = get_losing_moves(board, player=player)\n        \n        sorted_moves = sorted(all_moves, key=lambda k: (k['weight'], k['is_player']), reverse=True)\n        # print(\"1. sorted_moves:\", sorted_moves)\n        sorted_moves = [move for move in sorted_moves if not move['action'] in losing_moves]\n        # print(\"2. sorted_moves:\", sorted_moves)\n        \n        # print(\"losing_moves:\", losing_moves, \"player\",player)\n        \n        if len(sorted_moves) > 0:\n            action = int(sorted_moves[0]['action'])\n            # print(\"sorted move:\", action)\n        else:\n            if np.sum(board) == 0:\n                # return start move\n                return 3\n            else:\n                ######################################################\n                # choose random action\n                from random import choice\n                moves = [c for c in range(configuration.columns) if observation.board[c] == 0 and c not in losing_moves]\n                if len(moves) > 0:\n                    action = choice(moves)\n                else:\n                    # all lost..\n                    action = choice([c for c in range(configuration.columns) if observation.board[c] == 0])\n        \n        # print(\"action:\", action)\n        return action\n    return return_action()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils\n\ne = make(\"connectx\", debug=True)\ne.reset()\n\n# Play as first position againt my_agent (self play)\nt = e.train([my_agent, None])\n\no = t.reset()\n\nprint(\"start state\")\ne.render()\n\nwhile not e.done:\n    a = my_agent(o, e.configuration)\n    #print(\"action\", a)\n    o, r, d, i = t.step(a)\n\nprint(\"end state, reward\")    \ne.render()\n\nprint(\"* Conclusion: player 1 wants to extend its own 2-cell line on (5, 2), (5,3)) helping player 2 to make a winning move.\")\nprint(\"* Solution would be to do a 1-step look ahead, and check if an action leads to winning moves for the opponent.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from kaggle_environments import evaluate, make, utils\n\n# env = make(\"connectx\", debug=True)\n# env.reset()\n\n# # Play as first position againt my_agent (self play)\n# trainer = env.train([None, my_agent])\n\n# observation = trainer.reset()\n# #observation.board = list(board.ravel().astype(int))\n\n# print(\"start state\")\n# env.render()\n\n# while not env.done:\n#     my_action = my_agent(observation, env.configuration)\n#     print(\"action\", my_action)\n#     observation, reward, done, info = trainer.step(my_action)\n\n# print(\"end state, reward\")    \n# env.render()\n\n# print(\"* Conclusion: player 1 wants to extend its own 2-cell line on (5, 2), (5,3)) helping player 2 to make a winning move.\")\n# print(\"* Solution would be to do a 1-step look ahead, and check if an action leads to winning moves for the opponent.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils\n\nenv = make(\"connectx\", debug=True)\nenv.reset()\n# Play as the first agent against default \"random\" agent.\n#env.run([my_agent, \"random\"])\nenv.run([my_agent, \"negamax\"])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_reward(rewards):\n    #print(rewards)\n    return sum(r[0] for r in rewards) / sum(r[0] + r[1] for r in rewards)\n\n# # Run multiple episodes to estimate it's performance.\nprint(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, my_agent], num_episodes=20)))\n# print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))\n# # print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent_rule02, \"negamax\"], num_episodes=10)))\n# # print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent_rule02, \"negamax\"], num_episodes=10)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(my_agent, \"submission.py\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."},{"metadata":{},"cell_type":"markdown","source":"### Validate submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: Stdout replacement is a temporary workaround.\nimport sys\nout = sys.stdout\nsubmission = utils.read_file(\"/kaggle/working/submission.py\")\nagent = utils.get_last_callable(submission)\nsys.stdout = out\n\nenv = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}