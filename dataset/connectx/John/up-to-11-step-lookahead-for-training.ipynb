{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Summary\n\nI used this N-step lookahead agent to train my models. It has some advantages in comparison with the built-in negamax agent. It is written in Cython, which makes it faster than the negamax agent for a number of steps lookahead smaller than 10 and it is easy to change the strength of the opponent, by reducing or increasing the search depth. \nI'm not sure if you can submit a Cython agent to the competition though.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Install kaggle-environments","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n\n# ConnectX environment was defined in v0.1.6\n!pip install 'kaggle-environments>=0.1.6'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create ConnectX Environment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils\n\nenv = make(\"connectx\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import the Cython Jupyter extension","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext Cython","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cython Agent\n\nThe agent uses a minimax algorithm with alpha beta pruning -> [*Wikipedia*](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning). To make calculating the scores faster, I changed all values = 2 from the board to -1. This allows to sum the four values in a row. For example [1,1,1,0], [1,1,0,1], [1,0,1,1], [0,1,1,1] all have sum = 3. If the remaining spot is already taken by the opponent, the sum is = 2 and it doesn't count for the score. The basic structure is similar to the N-Step-Lookahead agent by Alexis Cook -> [*N-Step-Lookahead*](https://www.kaggle.com/alexisbcook/n-step-lookahead)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%cython\ncimport cython\nfrom libc.stdlib cimport malloc\nfrom libc.stdlib cimport rand, RAND_MAX\n\n# Checks for 3 and 4 in a row\ncdef int get_score(int[42] grid, int mark, int[42] prev_grid, int depth):\n\n    cdef int t, row, col, summe\n    cdef int num_threes = 0\n    cdef int num_threes_opp = 0\n     \n    # horizontal\n    for row in range(6):\n        col = 0\n        while col < 4:\n            summe = 0\n            for t in range(4):\n                summe += grid[row * 7 + col + t]\n    \n            if summe < 3 and summe >= 0:\n                col += 3 - summe\n                continue\n                \n            if summe > -3 and summe < 0:\n                col += 3 + summe\n                continue\n                \n            col += 1    \n            summe *= mark\n            if summe == 3:\n                num_threes += 1\n                continue\n            if summe == -3:\n                num_threes_opp += 1\n    \n    # vertical\n    for col in range(7):\n        for row in range(3):\n            summe = 0\n            for t in range(4):\n                summe += grid[(row+t) * 7 + col]\n            \n            if summe == 0:\n                break\n                \n            summe *= mark\n            if summe == 3:\n                num_threes += 1\n                continue\n            if summe == -3:\n                num_threes_opp += 1\n\n    # positive diagonal\n    for row in range(3):\n        col = 0\n        while col < 4:\n            summe = 0\n            for t in range(4):\n                summe += grid[(row+t) * 7 + col + t]\n    \n            if summe < 3 and summe >= 0:\n                col += 3 - summe\n                continue\n                \n            if summe > -3 and summe < 0:\n                col += 3 + summe\n                continue\n                \n            col += 1   \n            summe *= mark\n            if summe == 3:\n                num_threes += 1\n                continue\n            if summe == -3:\n                num_threes_opp += 1\n\n    # negative diagonal\n    for row in range(3,6):\n        col = 0\n        while col < 4:\n            summe = 0\n            for t in range(4):\n                summe += grid[(row-t) * 7 + col + t]\n    \n            if summe < 3 and summe >= 0:\n                col += 3 - summe\n                continue\n                \n            if summe > -3 and summe < 0:\n                col += 3 + summe\n                continue\n                \n            col += 1   \n            summe *= mark\n            if summe == 3:\n                num_threes += 1\n                continue\n            if summe == -3:\n                num_threes_opp += 1\n                  \n    return num_threes - 2 * num_threes_opp # Alternatively weigh opponents higher or lower\n\n\n# Checks if it is a terminal position, if true it returns the score\ncdef int is_terminal_node(int[42] board, int column, int mark, int row, int player_mark, int depth):\n    \n    cdef int i = 0\n    cdef int j = 0\n    cdef int col = 0\n    \n    # To check if board is full\n    for col in range(7):\n        if board[col] == 0:\n            break\n        col += 1\n    \n    # vertical\n    if row < 3:\n        for i in range(1, 4):\n            if board[column + (row+i) * 7] != mark:\n                break\n            i += 1\n    if i == 4:\n        if player_mark == mark:\n            return 1000 + depth # depth added, so that it chooses the faster option to win\n        else:\n            return -1000 - depth\n    \n    # horizontal\n    for i in range(1, 4):\n        if (column + i) >= 7 or board[column + i + (row) * 7] != mark:\n            break\n        i += 1\n    for j in range(1, 4):\n        if (column - j) < 0 or board[column - j + (row) * 7] != mark:\n            break\n        j += 1\n    if (i + j) >= 5:\n        if player_mark == mark:\n            return 1000 + depth\n        else:\n            return -1000 - depth\n    \n    # top left diagonal\n    for i in range(1, 4):\n        if (column + i) >= 7 or (row + i) >= 6 or board[column + i + (row + i) * 7] != mark:\n            break\n        i += 1\n    for j in range(1, 4):\n        if (column - j) < 0 or(row - j) < 0 or board[column - j + (row - j) * 7] != mark:\n            break\n        j += 1\n    if (i + j) >= 5:\n        if player_mark == mark:\n            return 1000 + depth\n        else:\n            return -1000 - depth\n    \n    # top right diagonal\n    for i in range(1, 4):\n        if (column + i) >= 7 or (row - i) < 0 or board[column + i + (row - i) * 7] != mark:\n            break\n        i += 1\n    for j in range(1, 4):\n        if (column - j) < 0 or(row + j) >= 6 or board[column - j + (row + j) * 7] != mark:\n            break\n        j += 1\n    if (i + j) >= 5:\n        if player_mark == mark:\n            return 1000 + depth\n        else:\n            return -1000 - depth\n    \n    if col == 7:\n        return 1 # draw\n    return 0 # nobody has won so far\n\n\n# Initial move is scored with minimax\ncdef int score_move(int[42] grid, int col, int mark, int nsteps):\n\n    cdef int[42] next_grid = grid\n    cdef int row, row2, column\n    cdef int[42] child\n    \n    for row in range(5, -1, -1):\n        if next_grid[7 * row + col] == 0:\n            next_grid[7 * row + col] = mark # drop mark\n            break\n    \n    if nsteps > 2: # check if there is an obvious move\n        is_terminal = is_terminal_node(next_grid, col, mark, row, mark, nsteps-1)\n        if is_terminal != 0:\n            return is_terminal\n\n        for column in range(7):\n            if next_grid[column] != 0:\n                continue\n            child = next_grid\n            for row2 in range(5, -1, -1):\n                if child[7 * row2 + column] == 0:\n                    child[7 * row2 + column] = mark*(-1)\n                    break\n\n            is_terminal = is_terminal_node(child, column, mark*(-1), row2, mark, nsteps-2)\n            if is_terminal != 0:\n                return is_terminal + (col == column) #added in case the opponent makes a mistake\n        \n    cdef int alpha = - 10000000\n    cdef int beta = 10000000\n    return minimax(next_grid, nsteps-1, 0, mark, grid, alpha, beta, col, row)\n\n\n# Minimax agent with alpha-beta pruning\ncdef int minimax(int[42] node, int depth, int maximizingPlayer, int mark, int[42] grid, int alpha, int beta, int column, int newrow):\n    \n    cdef int is_terminal \n    if maximizingPlayer:\n        is_terminal = is_terminal_node(node, column, mark*(-1), newrow, mark, depth)\n        if is_terminal != 0:\n            return is_terminal\n    if maximizingPlayer == 0:\n        is_terminal = is_terminal_node(node, column, mark, newrow, mark, depth)\n        if is_terminal != 0:\n            return is_terminal\n\n    cdef int value, col, row\n    cdef int[42] child\n    \n    if depth == 0:\n        return get_score(node, mark, grid, depth)\n\n    if maximizingPlayer:\n        value = -1000000\n        for col in range(7):\n            if node[col] != 0:\n                continue\n            child = node\n            for row in range(5, -1, -1):\n                if child[7 * row + col] == 0:\n                    child[7 * row + col] = mark \n                    break\n            value = max(value, minimax(child, depth-1, 0, mark, grid, alpha, beta, col, row))\n            alpha = max(alpha, value)\n            if alpha >= beta:\n                break\n        return value\n    else:\n        value = 1000000\n        for col in range(7):\n            if node[col] != 0:\n                continue\n            child = node\n            for row in range(5, -1, -1):\n                if child[7 * row + col] == 0:\n                    child[7 * row + col] = mark*(-1)\n                    break\n            value = min(value, minimax(child, depth-1, 1, mark, grid, alpha, beta, col, row))\n            beta = min(beta, value)\n            if beta <= alpha:\n                break\n        return value\n    \n\n# define the agent   \n@cython.cdivision(True)\ncpdef int agen(list grid, int mark, int N_STEPS):\n    \n    if mark == 2:\n        mark = -1\n        \n    cdef int num_max = 1\n    cdef int col, sc, i\n    cdef int maxsc = -1000001\n    cdef int[7] score = [-10000, -10000, -10000, -10000, -10000, -10000, -10000]\n\n    cdef int *c_grid\n    \n    c_grid = <int *>malloc(42*cython.sizeof(int))\n    for i in range(42):\n        if grid[i] == 2:\n            c_grid[i] = -1\n            continue\n        c_grid[i] = grid[i]\n    \n    for col in range(7):\n        if c_grid[col] == 0:\n            sc = score_move(c_grid, col, mark, N_STEPS)\n            if sc == maxsc:\n                num_max += 1\n                \n            if sc > maxsc:\n                maxsc = sc\n                num_max = 1\n                \n            score[col] = sc\n            \n    cdef int choice = int(rand()/(RAND_MAX/num_max))\n    cdef int indx = 0\n    \n    #print(score, mark)\n\n    for i in range(7):\n        if score[i] == maxsc:\n            if choice == indx:\n                return i  \n            indx += 1\n     \n    return 0 # shouldn't be necessary   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance\n\nNow lets see how well the agents perform. I decided to test a 2,3,5,7,9 and 11 step lookahead agent against the negamax agent.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def agentc2(obs, conf):\n    return agen(obs.board, obs.mark, 2)\n\ndef agentc3(obs, conf):\n    return agen(obs.board, obs.mark, 3)\n\ndef agentc5(obs, conf):\n    return agen(obs.board, obs.mark, 5)\n\ndef agentc7(obs, conf):\n    return agen(obs.board, obs.mark, 7)\n\ndef agentc9(obs, conf):\n    return agen(obs.board, obs.mark, 9)\n\ndef agentc11(obs, conf):\n    return agen(obs.board, obs.mark, 11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.run([\"negamax\", agentc2])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.run([\"negamax\", agentc3])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.run([\"negamax\", agentc5])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.run([\"negamax\", agentc7])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.run([\"negamax\", agentc9])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.run([\"negamax\", agentc11])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.run([agentc11, agentc11])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Speed\n\nAs opponent I chose the random agent and the runtime can be compared to the negamax agent. The time is averaged over 10 games. I noticed, that often the agentc2, agentc3 and agentc5 are not that different in speed. My guess is that this is because the games have more moves on average for lower search depths.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"l = [\"random\", \"negamax\", agentc2, agentc3, agentc5, agentc7, agentc9, agentc11]\nnames = [\"random agent\", \"negamax agent\", \"agentc2\", \"agentc3\", \"agentc5\", \"agentc7\", \"agentc9\", \"agentc11\"]\nfor c, agent in enumerate(l):\n    start = time.time()\n    evaluate(\"connectx\", [\"random\", agent], num_episodes=10)\n    end = time.time()\n    print(\"Random Agent vs.\", names[c], end-start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Play the Agent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"env.play([agentc11, None], width=750, height=620)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you noticed a mistake or if you have any suggestions for improving the agent, I would gladly try to correct it!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}