{"cells":[{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"_cell_guid":"45aaf873-4fd6-4411-8218-77fa16c785a8","_uuid":"00cb987589cece4b5aab4280adb579b739951edb"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"_cell_guid":"244e387a-4e25-4ad8-9048-705e97557edd","collapsed":true,"_uuid":"7be5af55f8997f716c1f9ed349a5f5233f9b569c"},"source":"ar = pd.read_csv('../input/air_reserve.csv')\nasi = pd.read_csv('../input/air_store_info.csv')\navd = pd.read_csv('../input/air_visit_data.csv')\ndi = pd.read_csv('../input/date_info.csv')\nhr = pd.read_csv('../input/hpg_reserve.csv')\nhsi = pd.read_csv('../input/hpg_store_info.csv')\nsid = pd.read_csv('../input/store_id_relation.csv')"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"_cell_guid":"1b826f99-fa66-420e-8b51-98d8bf9cf764","collapsed":true,"_uuid":"2a218d10cfca5f920a94c02731889d01808a21e6"},"source":"#air_8093d0b565e9dbdf hpg_874415e6e7ccfe13"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"_cell_guid":"08f09c13-9634-478d-b0a4-64a291611096","collapsed":true,"_uuid":"0d06e327d7df264fdbd4a8f77bc9aa453b6b2886"},"source":"store = avd[avd['air_store_id'] == 'air_8093d0b565e9dbdf']\nstore = store.merge(di, left_on='visit_date', right_on='calendar_date')\nstore.drop(['calendar_date', 'day_of_week', 'air_store_id'], axis=1, inplace=True)\nstore.set_index('visit_date', inplace=True)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"store.head()"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"_cell_guid":"b6413ac4-97ec-4d33-a4a7-8ac6eefc7def","collapsed":true,"_uuid":"65d23dbd3fa2f2f066ebc2838c3e421f8e7e70de"},"source":"def rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    to_sum = [(math.log(pred + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(to_sum) * (1.0/len(y))) ** 0.5"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"import math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)\n# fix random seed for reproducibility\nnp.random.seed(7)\n# load the dataset\ndataset = store['visitors'].values\ndataset = dataset.astype('int32')\n# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset.reshape(-1, 1))\n# split into train and test sets\ntrain_size = int(len(dataset) * 0.8)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n# reshape into X=t and Y=t+1\nlook_back = 7\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n# reshape input to be [samples, time steps, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(100, input_shape=(1, look_back)))\nmodel.add(Dense(7))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=15, batch_size=1, verbose=2)\n# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))\n# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"ratios = [x/y for x,y in zip(testPredict, testY)]"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"plt.plot(ratios[0])\nplt.show()"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"ones = [x for x in ratios[0] if (x>0.6) & (x<1.3)]\nlen(ones)/len(ratios[0])"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":"rmsle(testY.T, testPredict)"},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{},"source":""},{"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":""}],"nbformat":4,"metadata":{"language_info":{"name":"python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","version":"3.6.3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1}