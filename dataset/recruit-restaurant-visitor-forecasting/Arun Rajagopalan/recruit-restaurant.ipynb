{"cells":[{"cell_type":"code","execution_count":null,"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12\n\n%matplotlib inline\n\nnp.random.seed(42)\n\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.utils import check_array\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import sparse\n\n# Definition of the CategoricalEncoder class, copied from PR #9151.\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.utils import check_array\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import sparse\n\nclass CategoricalEncoder(BaseEstimator, TransformerMixin):\n    \"\"\"Encode categorical features as a numeric array.\n    The input to this transformer should be a matrix of integers or strings,\n    denoting the values taken on by categorical (discrete) features.\n    The features can be encoded using a one-hot aka one-of-K scheme\n    (``encoding='onehot'``, the default) or converted to ordinal integers\n    (``encoding='ordinal'``).\n    This encoding is needed for feeding categorical data to many scikit-learn\n    estimators, notably linear models and SVMs with the standard kernels.\n    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n    Parameters\n    ----------\n    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n        The type of encoding to use (default is 'onehot'):\n        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n          (or also called 'dummy' encoding). This creates a binary column for\n          each category and returns a sparse matrix.\n        - 'onehot-dense': the same as 'onehot' but returns a dense array\n          instead of a sparse matrix.\n        - 'ordinal': encode the features as ordinal integers. This results in\n          a single column of integers (0 to n_categories - 1) per feature.\n    categories : 'auto' or a list of lists/arrays of values.\n        Categories (unique values) per feature:\n        - 'auto' : Determine categories automatically from the training data.\n        - list : ``categories[i]`` holds the categories expected in the ith\n          column. The passed categories are sorted before encoding the data\n          (used categories can be found in the ``categories_`` attribute).\n    dtype : number type, default np.float64\n        Desired dtype of output.\n    handle_unknown : 'error' (default) or 'ignore'\n        Whether to raise an error or ignore if a unknown categorical feature is\n        present during transform (default is to raise). When this is parameter\n        is set to 'ignore' and an unknown category is encountered during\n        transform, the resulting one-hot encoded columns for this feature\n        will be all zeros.\n        Ignoring unknown categories is not supported for\n        ``encoding='ordinal'``.\n    Attributes\n    ----------\n    categories_ : list of arrays\n        The categories of each feature determined during fitting. When\n        categories were specified manually, this holds the sorted categories\n        (in order corresponding with output of `transform`).\n    Examples\n    --------\n    Given a dataset with three features and two samples, we let the encoder\n    find the maximum value per feature and transform the data to a binary\n    one-hot encoding.\n    >>> from sklearn.preprocessing import CategoricalEncoder\n    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n    ... # doctest: +ELLIPSIS\n    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n              encoding='onehot', handle_unknown='ignore')\n    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n    See also\n    --------\n    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n      integer ordinal features. The ``OneHotEncoder assumes`` that input\n      features take on values in the range ``[0, max(feature)]`` instead of\n      using the unique values.\n    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n      dictionary items (also handles string-valued features).\n    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n      encoding of dictionary items or strings.\n    \"\"\"\n\n    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n                 handle_unknown='error'):\n        self.encoding = encoding\n        self.categories = categories\n        self.dtype = dtype\n        self.handle_unknown = handle_unknown\n\n    def fit(self, X, y=None):\n        \"\"\"Fit the CategoricalEncoder to X.\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_feature]\n            The data to determine the categories of each feature.\n        Returns\n        -------\n        self\n        \"\"\"\n\n        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n                        \"or 'ordinal', got %s\")\n            raise ValueError(template % self.handle_unknown)\n\n        if self.handle_unknown not in ['error', 'ignore']:\n            template = (\"handle_unknown should be either 'error' or \"\n                        \"'ignore', got %s\")\n            raise ValueError(template % self.handle_unknown)\n\n        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n                             \" encoding='ordinal'\")\n\n        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n        n_samples, n_features = X.shape\n\n        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n\n        for i in range(n_features):\n            le = self._label_encoders_[i]\n            Xi = X[:, i]\n            if self.categories == 'auto':\n                le.fit(Xi)\n            else:\n                valid_mask = np.in1d(Xi, self.categories[i])\n                if not np.all(valid_mask):\n                    if self.handle_unknown == 'error':\n                        diff = np.unique(Xi[~valid_mask])\n                        msg = (\"Found unknown categories {0} in column {1}\"\n                               \" during fit\".format(diff, i))\n                        raise ValueError(msg)\n                le.classes_ = np.array(np.sort(self.categories[i]))\n\n        self.categories_ = [le.classes_ for le in self._label_encoders_]\n\n        return self\n\n    def transform(self, X):\n        \"\"\"Transform X using one-hot encoding.\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_features]\n            The data to encode.\n        Returns\n        -------\n        X_out : sparse matrix or a 2-d array\n            Transformed input.\n        \"\"\"\n        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n        n_samples, n_features = X.shape\n        X_int = np.zeros_like(X, dtype=np.int)\n        X_mask = np.ones_like(X, dtype=np.bool)\n\n        for i in range(n_features):\n            valid_mask = np.in1d(X[:, i], self.categories_[i])\n\n            if not np.all(valid_mask):\n                if self.handle_unknown == 'error':\n                    diff = np.unique(X[~valid_mask, i])\n                    msg = (\"Found unknown categories {0} in column {1}\"\n                           \" during transform\".format(diff, i))\n                    raise ValueError(msg)\n                else:\n                    # Set the problematic rows to an acceptable value and\n                    # continue `The rows are marked `X_mask` and will be\n                    # removed later.\n                    X_mask[:, i] = valid_mask\n                    X[:, i][~valid_mask] = self.categories_[i][0]\n            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n\n        if self.encoding == 'ordinal':\n            return X_int.astype(self.dtype, copy=False)\n\n        mask = X_mask.ravel()\n        n_values = [cats.shape[0] for cats in self.categories_]\n        n_values = np.array([0] + n_values)\n        indices = np.cumsum(n_values)\n\n        column_indices = (X_int + indices[:-1]).ravel()[mask]\n        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n                                n_features)[mask]\n        data = np.ones(n_samples * n_features)[mask]\n\n        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n                                shape=(n_samples, indices[-1]),\n                                dtype=self.dtype).tocsr()\n        if self.encoding == 'onehot-dense':\n            return out.toarray()\n        else:\n            return out","metadata":{"collapsed":true,"_cell_guid":"b83a9d3f-c669-49ac-8e8a-fac4119ca81c","_uuid":"c2e3698abcaa17ba5112793cb951629afb853e43"}},{"cell_type":"markdown","source":"# Load the data","metadata":{"_cell_guid":"ec4adc5e-22ad-43f3-b31e-308d02453a65","_uuid":"e955b059ad65af46c05b73d0e5c271cbd95eeb43"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data = {\n    'air_reserve': pd.read_csv('../input/air_reserve.csv'),\n    'air_store_info': pd.read_csv('../input/air_store_info.csv'),\n    'air_visit_data': pd.read_csv('../input/air_visit_data.csv'),\n    'date_info': pd.read_csv('../input/date_info.csv'),\n    'hpg_reserve': pd.read_csv('../input/hpg_reserve.csv'),\n    'hpg_store_info': pd.read_csv('../input/hpg_store_info.csv'),\n    'store_id_relation': pd.read_csv('../input/store_id_relation.csv'),\n    'sample_submission': pd.read_csv('../input/sample_submission.csv'),\n}","metadata":{"collapsed":true,"_cell_guid":"f6fd42bc-6649-44dd-a05c-e8b420dcac2e","_uuid":"38287f2c6f8beb0e11158e1f1be59bbbc7174f16"}},{"cell_type":"markdown","source":"# Data Exploration","metadata":{"_cell_guid":"6f578b13-c31e-431c-88a6-536070794f10","_uuid":"8ac71e246bee1b139565875e6985babac7481b0c"}},{"cell_type":"markdown","source":"**Air Reserve**","metadata":{"_cell_guid":"d9456f49-7a86-4f17-b25f-808b164184e0","_uuid":"3dfb4aa472e88df95e558d4e8cc277882efa3ade"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_reserve'].info()","metadata":{"_cell_guid":"270d9f60-302c-49c1-91d7-5bf743bc25b6","_uuid":"c9a316e9b862557f3b84e5f0565b20fb3dbe9461"}},{"cell_type":"markdown","source":"**Columns**\n- air_store_id - the restaurant's id in the air system\n- visit_datetime - the time of the reservation\n- reserve_datetime - the time the reservation was made\n- reserve_visitors - the number of visitors for that reservation","metadata":{"_cell_guid":"c5dd2795-f667-4785-aafc-074e64679926","_uuid":"8ca0ea056a656767f5a2d3ebb0631d67cf2a361b"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_reserve']['visit_datetime'] = pd.to_datetime(data['air_reserve']['visit_datetime']) #Converting date object\ndata['air_reserve']['reserve_datetime'] = pd.to_datetime(data['air_reserve']['reserve_datetime']) #Converting date object\ndata['air_reserve']['air_store_id'].nunique() #Unique stores in air reserve data","metadata":{"_cell_guid":"de565c10-6265-40b6-8f57-7eb6b84942bd","_uuid":"d950867b2eb2f5be32c71805d16b21c10777a167"}},{"cell_type":"markdown","source":"** Air Store Info**","metadata":{"_cell_guid":"8ae1dcda-45c6-4a5c-bdcc-0fcad86b01b9","_uuid":"eba2054c3ac40f76f4367b856156bf386939d1b2"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_store_info'].info()","metadata":{"_cell_guid":"0132297c-ef6a-4e70-be13-afc9cd13f867","_uuid":"d1e3d261883fe9f135b4f8368cf71d1a37b8da9d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_store_info']['air_store_id'].nunique()","metadata":{"_cell_guid":"409a31de-ba35-4637-82e1-9d0803271282","_uuid":"39161e26eb176a4f2312a5689f0c60a9909c7e2e"}},{"cell_type":"markdown","source":"** Air Visit Data **","metadata":{"_cell_guid":"70b1c526-cafe-4dfb-8781-ec658486f722","_uuid":"85536069eb500d3cfdfe7258f781a16b951aa1b0"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_visit_data'].info()","metadata":{"_cell_guid":"dbdeb21b-b633-4e9f-af6a-e44e02227009","_uuid":"b8cfaf6d7d457618306c2c96dbfe5adc545ad4f9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_visit_data']['air_store_id'].nunique()","metadata":{"_cell_guid":"fd71ff41-07c9-4103-bd91-71e51a292c98","_uuid":"3f567b8ee6bb7bc9d44866c10881ff4e76f31a4c"}},{"cell_type":"markdown","source":"** Date Info **","metadata":{"_cell_guid":"e0d8dced-882c-4d18-9992-4bac2d6e5b3a","_uuid":"859f2b1c317ba3525abe33913ef2ba0a735a14a0"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['date_info'].info()","metadata":{"_cell_guid":"0843a251-8279-46ca-9d82-e7731b1bb61f","_uuid":"451811be8caf466e6bc3b42b81f5679f629a7c9c"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['date_info']['calendar_date'] = pd.to_datetime(data['date_info']['calendar_date'])\n#data['date_info'].describe()\n#data['date_info']['calendar_date'].max()","metadata":{"collapsed":true,"_cell_guid":"15a98768-8e1a-426b-987c-663941eaba49","_uuid":"6a1a95272aa582fb423dd1a1a444b88fc56d98e0"}},{"cell_type":"markdown","source":"** HPG Reserve **","metadata":{"_cell_guid":"12c3f3a3-284f-4e49-aead-c74fd6894981","_uuid":"08b676c9cf966fbf117a1dc8921717a0a42b3736"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['hpg_reserve'].info()","metadata":{"_cell_guid":"d3db08c0-a6b3-40ac-97fd-f9745533cf72","_uuid":"bfbf00f59ff50850033d2f553e0db5814ac81a77"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['hpg_reserve']['visit_datetime'] = pd.to_datetime(data['hpg_reserve']['visit_datetime']) #Converting date object\ndata['hpg_reserve']['reserve_datetime'] = pd.to_datetime(data['hpg_reserve']['reserve_datetime']) #Converting date object\ndata['hpg_reserve']['hpg_store_id'].nunique() #Unique stores in hpg reserve data","metadata":{"_cell_guid":"19d26de7-86e1-484c-a940-34061dfc634f","_uuid":"6627097e27d4dacfd76000201b21fb2ea83058d9"}},{"cell_type":"markdown","source":"** HPG store info **","metadata":{"_cell_guid":"c40cfb31-5e51-4e62-b7ff-1d5d35a08aba","_uuid":"6dc80605eece5d2a3d1d1776bc5d3ee3a4b9ce90"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['hpg_store_info'].info()","metadata":{"_cell_guid":"f8d4b93f-56d9-4a81-b1c0-5c5048042717","_uuid":"d83fe582fdfc31a35f29d383ff5c8b059be672f3"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['hpg_store_info']['hpg_store_id'].nunique() #Unique stores in hpg store info","metadata":{"_cell_guid":"e787d2c9-3f0b-48e8-8d16-404ae6c317e6","_uuid":"eee215594826b8342897b8d4385ded99505c1e88"}},{"cell_type":"markdown","source":"There are some missing store info between reserve and hpg info data","metadata":{"_cell_guid":"1bab5872-cd59-4430-8c07-a0a53335ef61","_uuid":"6dca9aae6461b63d60a10363690c83d9aa2aa397"}},{"cell_type":"markdown","source":"** Store Relation **","metadata":{"_cell_guid":"b81c2236-0e91-4bd0-ad73-2f4d7a75606d","_uuid":"8f31a0d9d3facf31213fd58837a274385fa844e2"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['store_id_relation'].info()","metadata":{"_cell_guid":"c33e0f12-1734-4987-a3e4-9f9cfe12fb81","_uuid":"3c2ce7e3b13040eb5042024044b7da87049bf2ac"}},{"cell_type":"markdown","source":"** Submission **","metadata":{"_cell_guid":"f0c6e026-5394-46b5-9ce2-59666054f305","_uuid":"7323c1de7da3e2bd1d69ecd2242937c80dab46a5"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['sample_submission'].info()","metadata":{"_cell_guid":"5d4efd67-315d-4df3-bf92-1992c9e81d21","_uuid":"676310dd6930852f4df7c11459f8b86839502b64"}},{"cell_type":"markdown","source":"Splitting the sample submission data to air store id and date","metadata":{"_cell_guid":"e9302b91-9748-4a63-ae17-cfc5c1dd88d5","_uuid":"b7072f9143359369d325be861404bca44809ca24"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['submission_prep'] = data['sample_submission'].copy()\ndata['submission_prep']['visit_date'] = data['submission_prep']['id'].map(lambda x: str(x).split('_')[2])\ndata['submission_prep']['visit_date'] = pd.to_datetime(data['submission_prep']['visit_date'])\ndata['submission_prep']['air_store_id'] = data['submission_prep']['id'].map(lambda x: '_'.join(str(x).split('_')[:2]))","metadata":{"collapsed":true,"_cell_guid":"5db59060-a9a5-4c6b-853f-705f7cf45243","_uuid":"01c82a2f44170bd98cd39f440b9f979e896d0062"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['submission_prep']['air_store_id'].nunique()","metadata":{"_cell_guid":"0f981817-8b89-4d13-8008-e2bc7fd06c6f","_uuid":"8b6f2e1e6252f4246d1050da25dd40e9caade3d4"}},{"cell_type":"markdown","source":"# Data Preparation","metadata":{"_cell_guid":"d7304d5b-b76d-41be-a396-13df2e1e18ac","_uuid":"3f60161cb07306e09d297016cefff0380c1c6669"}},{"cell_type":"markdown","source":"Combining the data in both hpg reserve and air reserve","metadata":{"collapsed":true,"_cell_guid":"b423405e-1e4b-45f6-b614-7b30f8cb4bdb","_uuid":"2564d556531acc97da10a0dc1ef9000d21727dac"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_hpg_store_info'] = pd.merge(data['store_id_relation'], data['hpg_store_info'], how=\"inner\")","metadata":{"collapsed":true,"_cell_guid":"052841ed-fd4d-4bfb-97ca-855e140a9614","_uuid":"302eb3390fc5a45dde1764f95320141e9db072ba"}},{"cell_type":"markdown","source":"Creating the HPG Reserve table based on store location id","metadata":{"_cell_guid":"89ab2f24-2e23-4f03-9dd6-51e62f861261","_uuid":"9837ef750fc1cad7682e97b7135c9c335a75f1f1"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['hpg_air_reserve'] =pd.merge(data['store_id_relation'], data['hpg_reserve'], how=\"inner\")","metadata":{"collapsed":true,"_cell_guid":"02766772-d91c-4b07-96c6-17b2f71916fa","_uuid":"e32590d77058e45d0e853caa23c43983a5d113ff"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_reserve_prep'] = data['air_reserve'].copy()\ndata['air_reserve_prep']['visit_date'] = data['air_reserve_prep']['visit_datetime'].dt.date\ndata['air_reserve_prep']['reserve_date'] = data['air_reserve_prep']['reserve_datetime'].dt.date\ndata['air_reserve_prep'].drop(['visit_datetime', 'reserve_datetime'], axis=1, inplace=True)","metadata":{"collapsed":true,"_cell_guid":"e35cae8f-647c-44c3-bf81-19db13335b91","_uuid":"120d5f2a0c6c30b4a089cf2c89f84240518a3cee"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_reserve_prep'] = data['air_reserve_prep'].groupby(['air_store_id', 'visit_date', 'reserve_date']).sum()\ndata['air_reserve_prep'] = data['air_reserve_prep'].reset_index()","metadata":{"collapsed":true,"_cell_guid":"5e0dd721-a593-4707-b0e6-500fbf35126e","_uuid":"518ddc06c4490ac525625e763eee80ffef57af68"}},{"cell_type":"markdown","source":"HPG Reserve Data Cleaning","metadata":{"_cell_guid":"b9943880-06f1-4eeb-bcd0-e127dda1c9fa","_uuid":"e63bf0995173f06dbf40c12d8c5d14244d6cddf8"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['hpg_air_reserve_prep'] = data['hpg_air_reserve'].copy()\ndata['hpg_air_reserve_prep']['visit_date'] = data['hpg_air_reserve_prep']['visit_datetime'].dt.date\ndata['hpg_air_reserve_prep']['reserve_date'] = data['hpg_air_reserve_prep']['reserve_datetime'].dt.date\ndata['hpg_air_reserve_prep'].drop(['visit_datetime', 'reserve_datetime', 'hpg_store_id'], axis=1, inplace=True)\ndata['hpg_air_reserve_prep'] = data['hpg_air_reserve_prep'].groupby(['air_store_id', 'visit_date', 'reserve_date']).sum()\ndata['hpg_air_reserve_prep'] = data['hpg_air_reserve_prep'].reset_index()","metadata":{"collapsed":true,"_cell_guid":"d87cc10c-03b3-4ac8-aada-85eb4df745e7","_uuid":"9481833dfdaee40b3eb12e1d77a90b8a39c5cd04"}},{"cell_type":"markdown","source":"Air Reserve Data Cleaning and merging the hpg reserve data","metadata":{"_cell_guid":"92646139-668d-43b9-8bb6-79ea00fdf613","_uuid":"c575fd8eda4a42a020f77cce044ef5a0ba0f5a04"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_reserve_final'] = pd.concat([data['air_reserve_prep'], data['hpg_air_reserve_prep']], axis=0) \ndata['air_reserve_final'] = data['air_reserve_final'].groupby(['air_store_id', 'visit_date', 'reserve_date']).sum()\ndata['air_reserve_final'] = data['air_reserve_final'].reset_index()","metadata":{"collapsed":true,"_cell_guid":"4d733785-a2c4-4c11-bdaf-0ac0943bae84","_uuid":"98fe03e4f5a2136c7260e053749f71bfb8e943e6"}},{"cell_type":"markdown","source":"Creating final visit data for model preparation","metadata":{"_cell_guid":"f518fd64-c2d9-4ae0-a649-aab891186676","_uuid":"a97c0eaa56df229a22896b28edea8392e90d442b"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_reserve_final']['visit_date'] = pd.to_datetime(data['air_reserve_final']['visit_date'])\ndata['air_reserve_final']['day_n_of_week'] = data['air_reserve_final']['visit_date'].dt.dayofweek\ndata['air_reserve_final']['day'] = data['air_reserve_final']['visit_date'].dt.day\ndata['air_visit_data']['visit_date'] = pd.to_datetime(data['air_visit_data']['visit_date'])","metadata":{"collapsed":true,"_cell_guid":"410144eb-7f01-4a89-b797-9ba7dbfed85f","_uuid":"0d8bb50bb6acd80de90a10c204c8916552853813"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['visit_reserve_final'] = data['air_reserve_final'].drop('reserve_date', axis=1)\ndata['visit_reserve_final'] = data['visit_reserve_final'].groupby(['air_store_id', 'visit_date']).sum()\ndata['visit_reserve_final'] = data['visit_reserve_final'].reset_index()\ndata['visit_final'] = pd.merge(data['visit_reserve_final'], data['air_visit_data'], how=\"right\")\ndata['visit_final'].shape","metadata":{"_cell_guid":"8f594847-9feb-4b6e-9eaf-6fd9274eff21","_uuid":"c22f1658968c8a2f4db3cde164875add41aa6fa7"}},{"cell_type":"markdown","source":"Merging store info data to visit data set","metadata":{"_cell_guid":"5b59fcee-0789-4e74-ad48-083cebabaaf3","_uuid":"81b2ad11e7cad082da509a37854e72d6e4557f10"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['air_store_info']['air_genre_name'] = data['air_store_info']['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\ndata['air_store_info']['air_area_name'] = data['air_store_info']['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))","metadata":{"collapsed":true,"_cell_guid":"19a2e633-f84a-434b-9a0f-ef541324d1ad","_uuid":"1dc1df5e3909a57a08c650187d82b780d6da660b"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['final_data'] = pd.merge(data['air_store_info'], data['visit_final'])\ndata['final_data'] = pd.merge(data['final_data'], data['date_info'], how = \"left\", \n                              right_on ='calendar_date', left_on='visit_date') #Merge with date information\n\n#Id Change\nair_store_id_reshaped = data['final_data']['air_store_id'].values.reshape(-1, 1)\ncat_encoder = CategoricalEncoder(encoding=\"ordinal\")\ndata['final_data']['store_id'] = cat_encoder.fit_transform(air_store_id_reshaped)\n\n#Area name split\ndata['final_data']['region_0'] = data['final_data']['air_area_name'].map(lambda x: str(x).split(' ')[0])\ndata['final_data']['region_1'] = data['final_data']['air_area_name'].map(lambda x: str(x).split(' ')[1])\ndata['final_data']['region_2'] = data['final_data']['air_area_name'].map(lambda x: str(x).split(' ')[2])\ndata['final_data']['region_3'] = data['final_data']['air_area_name'].map(lambda x: str(x).split(' ')[3])\n\n#Genre name split\ndata['final_data']['genre_0'] = data['final_data']['air_genre_name'].map(lambda x: str(x).split(' ')[0])\ndata['final_data']['genre_1'] = data['final_data']['air_genre_name'].map(lambda x: str(x).split(' ')[1] \n                                                                         if len(str(x).split(' ')) > 1 else \"\")\n\n#data['final_data'].shape\ndata['final_data']['lat_long'] = data['final_data']['longitude'] + data['final_data']['latitude']\n\n#Adding more fields for visit date, day, month and week\n\ndata['final_data']['month'] = data['final_data']['visit_date'].dt.month\ndata['final_data']['week'] = data['final_data']['visit_date'].dt.week\ndata['final_data']['day_n_of_week'] =  data['final_data']['visit_date'].dt.dayofweek + 1\ndata['final_data']['year'] =  data['final_data']['visit_date'].dt.year\ndata['final_data']['day'] =  data['final_data']['visit_date'].dt.day \n\n#mean reserve\ndata['mean_reserve'] = data['visit_reserve_final'].groupby(['air_store_id'])[['reserve_visitors']].mean().reset_index()\ndata['mean_reserve'].columns = ['air_store_id', 'mean_reserve_visitors']\ndata['final_data'] = pd.merge(data['final_data'] , data['mean_reserve'], how = \"left\", right_on=\"air_store_id\", left_on=\"air_store_id\")\n\ndata['mean_week_reserve'] = data['visit_reserve_final'].groupby(['air_store_id', 'day_n_of_week']).agg({'reserve_visitors' : [np.min,np.mean,np.median,np.max]}).reset_index()\ndata['mean_week_reserve'].columns = ['air_store_id', 'day_n_of_week', 'min_wk_res_visitors', 'mean_wk_res_visitors', 'median_wk_res_visitors',\n                                      'max_wk_res_visitors']\ndata['final_data'] = pd.merge(data['final_data'] , data['mean_week_reserve'], how = \"left\")\n\ndata['mean_day_reserve'] = data['visit_reserve_final'].groupby(['air_store_id', 'day']).agg({'reserve_visitors' : [np.min,np.mean,np.median,np.max]}).reset_index()\ndata['mean_day_reserve'].columns = ['air_store_id', 'day', 'min_day_res_visitors', 'mean_day_res_visitors', 'median_day_res_visitors',\n                                      'max_day_res_visitors']\ndata['final_data'] = pd.merge(data['final_data'] , data['mean_day_reserve'], how = \"left\")\n\n#mean_visitors\ndata['mean_visitors'] = data['final_data'].groupby(['air_store_id'])[['visitors']].mean().reset_index()\ndata['mean_visitors'].columns = ['air_store_id', 'mean_visitors']\ndata['final_data'] = pd.merge(data['final_data'] , data['mean_visitors'], how = \"left\", right_on=\"air_store_id\", left_on=\"air_store_id\")\n\ndata['mean_week_visitors'] = data['final_data'].groupby(['air_store_id', 'day_n_of_week']).agg({'visitors' : [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\ndata['mean_week_visitors'].columns = ['air_store_id', 'day_n_of_week', 'min_wk_visitors', 'mean_wk_visitors', 'median_wk_visitors',\n                                      'max_wk_visitors','count_wk_observations']\ndata['final_data'] = pd.merge(data['final_data'] , data['mean_week_visitors'], how = \"left\")\n\ndata['mean_day_visitors'] = data['final_data'].groupby(['air_store_id', 'day']).agg({'visitors' : [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\ndata['mean_day_visitors'].columns = ['air_store_id', 'day', 'min_day_visitors', 'mean_day_visitors', 'median_day_visitors',\n                                      'max_day_visitors','count_day_observations']\ndata['final_data'] = pd.merge(data['final_data'] , data['mean_day_visitors'], how = \"left\")\n\n#Adding 0 on missing values\ndata['final_data'] = data['final_data'].fillna(0)","metadata":{"collapsed":true,"_cell_guid":"f0a13976-2f1c-4ba9-9c7b-b161e1e2aeb0","_uuid":"6d7d17001f760868b0a7c2fd4bb8b35b9812fed4"}},{"cell_type":"markdown","source":"Preparing the test dataset","metadata":{"_cell_guid":"e3fb3f31-6ec8-47bd-a448-6892c83e9700","_uuid":"4c615c65e1705ed4fec00c52ca78f2fd346f8efc"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['test_data'] = pd.merge(data['visit_reserve_final'], data['submission_prep'], how=\"right\")\ndata['test_data'] = pd.merge(data['test_data'], data['air_store_info'])\ndata['test_data'] = pd.merge(data['test_data'], data['date_info'], how = \"left\", \n                              right_on ='calendar_date', left_on='visit_date') #Merge with date information\n#data['test_data'].shape\n\n#Id Change\nair_store_id_reshaped = data['test_data']['air_store_id'].values.reshape(-1, 1)\ncat_encoder = CategoricalEncoder(encoding=\"ordinal\")\ndata['test_data']['store_id'] = cat_encoder.fit_transform(air_store_id_reshaped)\n\n#Area name split\ndata['test_data']['region_0'] = data['test_data']['air_area_name'].map(lambda x: str(x).split(' ')[0])\ndata['test_data']['region_1'] = data['test_data']['air_area_name'].map(lambda x: str(x).split(' ')[1])\ndata['test_data']['region_2'] = data['test_data']['air_area_name'].map(lambda x: str(x).split(' ')[2])\ndata['test_data']['region_3'] = data['test_data']['air_area_name'].map(lambda x: str(x).split(' ')[3])\n\n\n#Genre name split\ndata['test_data']['genre_0'] = data['test_data']['air_genre_name'].map(lambda x: str(x).split(' ')[0])\ndata['test_data']['genre_1'] = data['test_data']['air_genre_name'].map(lambda x: str(x).split(' ')[1] \n                                                                         if len(str(x).split(' ')) > 1 else \"\")\n\ndata['test_data']['lat_long'] = data['test_data']['longitude'] + data['test_data']['latitude']\n\n\n#Adding more fields for visit date, day, month and week\n\ndata['test_data']['month'] = data['test_data']['visit_date'].dt.month\ndata['test_data']['week'] = data['test_data']['visit_date'].dt.week\ndata['test_data']['day_n_of_week'] =  data['test_data']['visit_date'].dt.dayofweek + 1\ndata['test_data']['year'] =  data['test_data']['visit_date'].dt.year\ndata['test_data']['day'] =  data['test_data']['visit_date'].dt.day \n\n#mean reserve\n\ndata['test_data'] = pd.merge(data['test_data'] , data['mean_reserve'], how = \"left\"\n                             , right_on=\"air_store_id\", left_on=\"air_store_id\")\ndata['test_data'] = pd.merge(data['test_data'] , data['mean_week_reserve'], how = \"left\")\ndata['test_data'] = pd.merge(data['test_data'] , data['mean_day_reserve'], how = \"left\")\n\n#mean_visitors\ndata['test_data'] = pd.merge(data['test_data'] , data['mean_visitors'], how = \"left\"\n                             , right_on=\"air_store_id\", left_on=\"air_store_id\")\ndata['test_data'] = pd.merge(data['test_data'] , data['mean_week_visitors'], how = \"left\")\ndata['test_data'] = pd.merge(data['test_data'] , data['mean_day_visitors'], how = \"left\")\n\n#Adding 0 on missing values\ndata['test_data'] = data['test_data'].fillna(0)\ndata['test_data'] = data['test_data'].sort_values(by=['id'])","metadata":{"collapsed":true,"_cell_guid":"0a8d5bc7-5483-4d92-8e8c-1f8025d4a839","_uuid":"fe33114385edf748096efc5b0905cd6af170d174"}},{"cell_type":"markdown","source":"# Data Exploration","metadata":{"_cell_guid":"b9fac961-2578-4849-b378-9a3adc432b33","_uuid":"a933e4e634969cd6d6f6592fd04322d0265835f7"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#Visitors based on week days\n#fig, ax = plt.subplots(figsize=(10,10))\nsns.barplot(x=\"day_n_of_week\", y=\"visitors\", data=data['final_data'])","metadata":{"_cell_guid":"35884ba9-f054-48f4-8a24-abbaa12f7c48","_uuid":"17540ffa3bbd0cad11fb2d5427b9ab3705ce3b4f"}},{"cell_type":"markdown","source":"There are more visitors on Saturday followed by Sunday and Friday and Other days average is less.","metadata":{"_cell_guid":"55c010a8-e6c1-4160-8cdc-d5c4f88b7f48","_uuid":"f794541adb241181eff3e1c6e8a50897c16e0515"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#Visitors each day\nf, ax = plt.subplots(1, 1, figsize=(15, 8))\nplt1 = data['final_data'].groupby(['visit_date'], as_index=False).agg({'visitors': np.sum})\nplt2 = data['final_data'].groupby(['visit_date'], as_index=False).agg({'reserve_visitors': np.sum})\nplt1 = plt1.set_index('visit_date')\nplt2 = plt2.set_index('visit_date')\nplt1.plot(color='c', kind='area', ax=ax)\nplt2.plot(color='r', kind='line', ax=ax)\nplt.ylabel(\"Sum of Visitors\")\nplt.title(\"Visitor and Reservations\")","metadata":{"_cell_guid":"23f94e67-1ae8-4ade-9145-0647af0d4762","_uuid":"8afcf500cdd273ef8c5e6f4ea1a2db750588fbbc"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#Visitors by Genre\n\nplt.style.use('seaborn')\ncolor = sns.color_palette()\n\nf,ax=plt.subplots(1,1, figsize=(10,8))\ngenre=data['final_data'].groupby(['air_genre_name'],as_index=False)['visitors'].sum()\ngenre.sort_values(by='visitors', ascending=True, inplace=True)\ngenre['air_genre'] =[i for i,x in enumerate(genre['air_genre_name'])] \ngenre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\nmy_range = genre['air_genre']\nplt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[‘solid’ | ‘dashed’ | ‘dashdot’ | ‘dotted’]\nplt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n\n# Add titles and axis names\nplt.yticks(my_range, genre['air_genre_name'],fontsize=15)\nplt.title(\"Total visitors by Air Genre\", loc='center')\nplt.xlabel('Score')\nplt.ylabel('Features')","metadata":{"_cell_guid":"45a86cb9-532f-44e3-a2f6-358415bca594","_uuid":"a3f061ee48eb731b13bda1da52e72a894bd81825"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#Visitors by Region\n\nplt.style.use('seaborn')\ncolor = sns.color_palette()\n\nf,ax=plt.subplots(1,1, figsize=(10,8))\ngenre=data['final_data'].groupby(['region_0'],as_index=False)['visitors'].sum()\ngenre.sort_values(by='visitors', ascending=True, inplace=True)\ngenre['region'] =[i for i,x in enumerate(genre['region_0'])] \ngenre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\nmy_range = genre['region']\nplt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[‘solid’ | ‘dashed’ | ‘dashdot’ | ‘dotted’]\nplt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n\n# Add titles and axis names\nplt.yticks(my_range, genre['region_0'],fontsize=15)\nplt.title(\"Region 0\", loc='center')\nplt.xlabel('Score')\nplt.ylabel('Features')","metadata":{"_cell_guid":"7fbeddd9-658a-44e6-acee-b68148c9f37e","_uuid":"656b33ad9495f541429a7b71b8d942a8e1d7d29d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#Visitors by Region\n\nplt.style.use('seaborn')\ncolor = sns.color_palette()\n\nf,ax=plt.subplots(1,1, figsize=(10,8))\ngenre=data['final_data'].groupby(['region_1'],as_index=False)['visitors'].sum()\ngenre.sort_values(by='visitors', ascending=True, inplace=True)\ngenre['region'] =[i for i,x in enumerate(genre['region_1'])] \ngenre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\nmy_range = genre['region']\nplt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[‘solid’ | ‘dashed’ | ‘dashdot’ | ‘dotted’]\nplt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n\n# Add titles and axis names\nplt.yticks(my_range, genre['region_1'],fontsize=15)\nplt.title(\"Region 1\", loc='center')\nplt.xlabel('Score')\nplt.ylabel('Features')","metadata":{"_cell_guid":"b73a79b4-2433-4fe5-b403-57267fa92aa3","_uuid":"4a6f0dad9276103f11af733259b530b1473a22c7"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#Visitors by Region\n\nplt.style.use('seaborn')\ncolor = sns.color_palette()\n\nf,ax=plt.subplots(1,1, figsize=(15,15))\ngenre=data['final_data'].groupby(['region_2'],as_index=False)['visitors'].sum()\ngenre.sort_values(by='visitors', ascending=True, inplace=True)\ngenre['region'] =[i for i,x in enumerate(genre['region_2'])] \ngenre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\nmy_range = genre['region']\nplt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[‘solid’ | ‘dashed’ | ‘dashdot’ | ‘dotted’]\nplt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n\n# Add titles and axis names\nplt.yticks(my_range, genre['region_2'],fontsize=15)\nplt.title(\"Region 2\", loc='center')\nplt.xlabel('Score')\nplt.ylabel('Features')","metadata":{"_cell_guid":"4bc408f6-0d68-4b46-af0a-10d9697020f0","_uuid":"dda367b5d53065ea2f274bd694e242a72c67eb17"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"plt1=data['final_data']['visitors'].value_counts().reset_index().sort_index()\nfig, ax = plt.subplots(figsize=(15, 6), nrows=1, ncols=2, sharex=False, sharey=False)\nax[0].bar(plt1['index'] ,plt1['visitors'],color='limegreen')\nax[1]= sns.boxplot(y='visitors',x='day_n_of_week', data=data['final_data'],hue='holiday_flg',palette=\"Set2\")\nax[1].set_title('Number of daily visitors by day of the week')\nax[0].bar(plt1['index'] ,plt1['visitors'],color='limegreen')\nax[0].set_title('Frequency')\nax[0].set_xlim(0,100)\nax[1].set_ylim(0,80)\nax[1].legend(loc=1)","metadata":{"_cell_guid":"a035641d-e9e5-4193-8d27-ec1117e91065","_uuid":"544e2ddc84ae6998283bc37b775570a585256191"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# column index\nlatitude_ix, longitude_ix = 3, 4\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X, y=None):\n        lat_plus_long = X[:, latitude_ix] + X[:, longitude_ix]\n        return np.c_[X, lat_plus_long]\n    \nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n# Create a class to select numerical or categorical columns \n# since Scikit-Learn doesn't handle DataFrames yet\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values","metadata":{"collapsed":true,"_cell_guid":"be2c1067-e8df-4ece-bfbe-60b94788291e","_uuid":"b114177f666ae6829dcd880980e6b0d88586dbc2"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['train_data'] = data['final_data'].drop('visitors', axis=1)\ny_train = np.log1p(data['final_data']['visitors'].copy())\n\n#num_attribs = list(data['train_data'].select_dtypes(include=[np.number]))\nnum_attribs =  [#'latitude',\n                 #'longitude',\n                 'store_id',\n                 'reserve_visitors',\n                 'day_n_of_week',\n                 #'day',\n                 'holiday_flg',\n                 #'lat_long',\n                 'month',\n                 #'week',\n                 'year',\n                 #'mean_reserve_visitors',\n                 'min_wk_res_visitors',\n                 'mean_wk_res_visitors',\n                 'median_wk_res_visitors',\n                 'max_wk_res_visitors',\n                 #'min_day_res_visitors',\n                 #'mean_day_res_visitors',\n                 #'median_day_res_visitors',\n                 #'max_day_res_visitors',\n                 #'mean_visitors',\n                 'min_wk_visitors',\n                 'mean_wk_visitors',\n                 'median_wk_visitors',\n                 'max_wk_visitors',\n                 'count_wk_observations',\n                # 'min_day_visitors',\n                # 'mean_day_visitors',\n                # 'median_day_visitors',\n                # 'max_day_visitors',\n                # 'count_day_observations'\n                ]\n#[\"air_store_id\",\nord_cat_attribs =  [\"air_store_id\"]\n                   #\"genre_0\",\n                   #\"genre_1\",\n                   #\"region_0\",\n                   #\"region_1\",\n                   #\"region_2\",\n                   #\"region_3\"]\n\nonehot_cat_attribs =  [\"genre_0\",\n                   \"genre_1\",\n                   \"region_0\",\n                   \"region_1\",\n                   \"region_2\",\n                   \"region_3\"]\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, Imputer\n\nord_cat_pipeline = Pipeline([\n        ('selector', DataFrameSelector(ord_cat_attribs)),\n        ('ord_encoder', CategoricalEncoder(encoding=\"ordinal\")),\n        ('std_scaler', StandardScaler()),\n    ])\n\nonehot_cat_pipeline = Pipeline([\n        ('selector', DataFrameSelector(onehot_cat_attribs)),\n        ('onehot_encoder', CategoricalEncoder(encoding=\"onehot-dense\")),\n        #('std_scaler', StandardScaler()),\n    ])\nnum_pipeline = Pipeline([\n        ('selector', DataFrameSelector(num_attribs)),\n        ('imputer', Imputer(strategy=\"mean\")),\n        #('attribs_adder', CombinedAttributesAdder()),\n        ('std_scaler', StandardScaler()),\n    ])","metadata":{"collapsed":true,"_cell_guid":"f885a790-0ba7-4e7b-bdb7-094078a8e689","_uuid":"46102c02bd994f67b18ee589e1a8b34289d2bb28"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.pipeline import FeatureUnion\n\nfull_pipeline = FeatureUnion(transformer_list=[\n        #(\"ord_cat_pipeline\", ord_cat_pipeline),\n        (\"onehot_cat_pipeline\", onehot_cat_pipeline),\n        (\"num_pipeline\", num_pipeline),\n    ])\n\nX_train = full_pipeline.fit_transform(data[\"train_data\"])\n\nfrom sklearn.pipeline import FeatureUnion\n\nfull_pipeline = FeatureUnion(transformer_list=[\n        #(\"ord_cat_pipeline\", ord_cat_pipeline),\n        (\"onehot_cat_pipeline\", onehot_cat_pipeline),\n        (\"num_pipeline\", num_pipeline),\n    ])\n\nX_test = full_pipeline.fit_transform(data[\"test_data\"])","metadata":{"collapsed":true,"_cell_guid":"cb65834d-927e-4d24-a82d-eeb49dd5f4ca","_uuid":"47c6999c95c09251d7bcfff76af3bac747925bbe"}},{"cell_type":"markdown","source":"# Select and Train a model","metadata":{"_cell_guid":"e05d4c6b-1366-4119-ad27-7f2c89a24a0a","_uuid":"9dd6b919449144260e91fca83c9412a287bc0e68"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)","metadata":{"_cell_guid":"0b981f6b-4888-4640-8a4f-0de441825b13","_uuid":"e2c6bd8e5a0d9aed6007a1a28035fa332f86cb64"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.metrics import mean_squared_error\n\nrecruit_predictions = lin_reg.predict(X_train)\nlin_mse = mean_squared_error(y_train, recruit_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","metadata":{"_cell_guid":"d63644f5-20a5-46f5-98f2-146e6cbc502e","_uuid":"bea38ab8a8b637053e7ebe621dd9661916c74d62"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"Y_test_pred = np.expm1(lin_reg.predict(X_test))\ntest_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \"visitors\": Y_test_pred})\n#test_submission.head()\ntest_submission.to_csv(\"test_submission.csv\", index=False)","metadata":{"collapsed":true,"_cell_guid":"063b88f0-6960-4cd0-83dc-3bb5d528ebfe","_uuid":"e70a83a69b323a5b76a81dc8fc35a9448d8fda0b"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"test_submission.head()","metadata":{"_cell_guid":"b59222c2-0fa0-4534-a345-c34b04a9ffca","_uuid":"69c0475162bd78c0286e80dcdba036ec1f460490"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nregressors = [\n    LinearRegression(),\n    RandomForestRegressor(random_state=42),\n    GradientBoostingRegressor(learning_rate=0.2, random_state=42),\n    KNeighborsRegressor(n_neighbors=4, n_jobs=-1),\n    #SGDRegressor(penalty=None, eta0=0.1),\n    DecisionTreeRegressor(max_depth= 10, random_state=42)\n]\n\nlog_cols = ['Regressor', 'rmse']\nlog = pd.DataFrame(columns=log_cols)\n\nrmse_dict = {}\n\nfor reg in regressors:\n    name = reg.__class__.__name__\n    reg.fit(X_train, y_train)\n    predictions = reg.predict(X_train)\n    mse = mean_squared_error(y_train, predictions)\n    rmse = np.sqrt(mse)\n    print(rmse)\n    if name in rmse_dict:\n        rmse_dict[name] += rmse\n    else:\n         rmse_dict[name] = rmse\n\nfor reg in rmse_dict:\n    log_entry = pd.DataFrame([[reg, rmse_dict[reg]]], columns=log_cols)\n    log = log.append(log_entry)\n    \nplt.xlabel('Root Mean Square Error')\nplt.title('RMSE')\n\n#sns.set_color_codes(\"muted\")\nsns.barplot(x='rmse', y='Regressor', data=log, color=\"lightgreen\")","metadata":{"_cell_guid":"fc8ee3fb-015a-4aa5-ada8-2c1e0017d693","_uuid":"5030fcfe106da7f167a2a171c2a0774d78ff9f8c"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","metadata":{"collapsed":true,"_cell_guid":"813066e1-26a4-4fcf-897d-04a9f69ee0cc","_uuid":"967b98a712f45607ab5276e6191a3c7eac562eee"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.model_selection import cross_val_score\n\nlin_scores = cross_val_score(lin_reg, X_train, y_train,\n                             scoring=\"neg_mean_squared_error\", cv=5)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","metadata":{"_cell_guid":"46e6f9ce-7c48-4d41-ba51-7ed11745abe5","_uuid":"0987c922623804bf467449fe2915e42d22e2eafa"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(random_state=42)\nforest_reg.fit(X_train, y_train)\n\nforest_predictions = forest_reg.predict(X_train)\nforest_mse = mean_squared_error(y_train, forest_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","metadata":{"_cell_guid":"763add3b-e2ab-46b0-8eae-d8346e055b33","_uuid":"fdc365985bf0dbd9f44c6121d4a005baf25f238b"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"Y_forest_test_pred = np.expm1(forest_reg.predict(X_test))\ntest_forest_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n                                       \"visitors\": Y_forest_test_pred})\n#test_submission.head()\ntest_forest_submission.to_csv(\"test_forest_submission.csv\", index=False)","metadata":{"collapsed":true,"_cell_guid":"8d9d2e1f-39e4-439a-8bc4-eeb356a4f1f8","_uuid":"96bbdf2db01bf0fd00e77cad01be6aeee8b76a5d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"test_forest_submission.head()","metadata":{"_cell_guid":"4c93b649-76fa-4eff-8629-8ba5a4fb5ba6","_uuid":"d3e90f9365d266c037478531e23713db7790f86c"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"#from sklearn.model_selection import cross_val_score\n\n'''forest_scores = cross_val_score(forest_reg, X_train, y_train,\n                             scoring=\"neg_mean_squared_error\", cv=5)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)'''","metadata":{"_cell_guid":"a8279df4-a268-4ad2-b705-b2fb1352f884","_uuid":"8c8de7c3225c57c7f054a912140d5a9e965f5397"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbr_reg = GradientBoostingRegressor(learning_rate=0.2, random_state=42)\ngbr_reg.fit(X_train, y_train)\n\ngbr_predictions = gbr_reg.predict(X_train)\ngbr_mse = mean_squared_error(y_train, gbr_predictions)\ngbr_rmse = np.sqrt(gbr_mse)\ngbr_rmse","metadata":{"_cell_guid":"fc15a2d9-02b1-41dc-9376-f8136757b276","_uuid":"07e37a26b82e041929b5867c7629beae0e701681"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"Y_gbr_test_pred = np.expm1(gbr_reg.predict(X_test))#.clip(lower=0.)\ntest_gbr_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n                                       \"visitors\": Y_gbr_test_pred})\n#test_submission.head()\ntest_gbr_submission.to_csv(\"test_gbr_submission.csv\", index=False)","metadata":{"collapsed":true,"_cell_guid":"bc764c96-a202-4c32-8447-49c9536105c1","_uuid":"57d289a1769d9b475d56021ae112c8eaa29ad526"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"'''from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom scipy.stats import randint\n\nparam_distribs = {\n        'n_estimators': randint(low=20, high=200),\n        'max_features': randint(low=10, high=23),\n        'max_depth': randint(low=5, high=20),\n        'learning_rate': [0.1, 0.2, 0.3, 0.4]\n    }\n\ngbr_reg = GradientBoostingRegressor(random_state=42, subsample=0.8)\ngbr_search = RandomizedSearchCV(gbr_reg, param_distributions=param_distribs,\n                                n_iter=5, cv=5, scoring='neg_mean_squared_error', random_state=42, verbose=10, n_jobs=-1)\ngbr_search.fit(X_train, y_train)'''","metadata":{"_cell_guid":"be588e07-f4fe-4b2d-b49f-e72812f9301d","_uuid":"7814529cf09c60ed09e6bcda32c21391f9cdfce3"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"'''gbr_search.best_score_\ngbr_rmse = np.sqrt(-gbr_search.best_score_)\ngbr_rmse'''","metadata":{"_cell_guid":"d35d1309-039f-4691-a110-bb0b2a70ae07","_uuid":"5eb89ddfd29fe9b216b3a0f3e8453d7d89ec3348"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"'''gbr_best_model = gbr_search.best_estimator_\n\nY_gbr_test_pred = np.expm1(gbr_best_model.predict(X_test))\ntest_gbr_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n                                       \"visitors\": Y_gbr_test_pred})\n#test_submission.head()\ntest_gbr_submission.to_csv(\"test_gbr_submission.csv\", index=False)'''","metadata":{"_cell_guid":"790d08c7-64f3-44e0-ab06-f7313baa7c64","_uuid":"38f88c7f3dc0d56ad97f0be154fcdb056b46e8e5"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"'''gbr_scores = cross_val_score(gbr_reg, X_train, y_train,\n                             scoring=\"neg_mean_squared_error\", cv=5)\ngbr_rmse_scores = np.sqrt(-gbr_scores)\ndisplay_scores(gbr_rmse_scores)'''","metadata":{"_cell_guid":"3b44c36a-da9a-41de-afe8-aa356bd82367","_uuid":"e4f1acc9e0b6e8b4e215c44cbe234c903ed83917"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.linear_model import ElasticNet\n\nelastic_net = ElasticNet(alpha=0.01, l1_ratio=0.01, random_state=42)\nelastic_net.fit(X_train, y_train)\nelastic_net_predictions = elastic_net.predict(X_train)\nelastic_net_mse = mean_squared_error(y_train, elastic_net_predictions)\nelastic_net_rmse = np.sqrt(elastic_net_mse)\nelastic_net_rmse","metadata":{"_cell_guid":"b67b86c1-bffa-49f8-91df-beebc0e0c744","_uuid":"250f89a8fd0c49a27f1728d2b790fc4250eb6040"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"'''eln_scores = cross_val_score(elastic_net, X_train, y_train,\n                             scoring=\"neg_mean_squared_error\", cv=5)\neln_rmse_scores = np.sqrt(-eln_scores)\ndisplay_scores(eln_rmse_scores)'''","metadata":{"_cell_guid":"d7c6fcd1-4834-4743-be09-8dd52a61f3ed","_uuid":"f83e3b0fbca4b4b0af79fb1ff0133e1c888fcbe3"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"Y_eln_test_pred = np.expm1(elastic_net.predict(X_test))\ntest_eln_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n                                       \"visitors\": Y_eln_test_pred})\n#test_submission.head()\ntest_eln_submission.to_csv(\"test_eln_submission.csv\", index=False)","metadata":{"collapsed":true,"_cell_guid":"2f6b3e65-3e88-4b15-b943-50c564d9f25e","_uuid":"f55c5f5b856863f967ad905b30b193a67bc1077f"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"knn_reg = KNeighborsRegressor(n_neighbors=4, n_jobs=-1)\nknn_reg.fit(X_train, y_train)\n\nknn_predictions = knn_reg.predict(X_train)\nknn_mse = mean_squared_error(y_train, knn_predictions)\nknn_rmse = np.sqrt(knn_mse)\nknn_rmse","metadata":{"_cell_guid":"13a510a3-2fd1-411e-94a7-5e5834d6ae69","_uuid":"b6cd8f3dce4aed4f2792703b6412530e496820c9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"knn_reg = KNeighborsRegressor(n_neighbors=4, n_jobs=-1)\nknn_reg.fit(X_train, y_train)\n\n'''knn_scores = cross_val_score(knn_reg, X_train, y_train,\n                             scoring=\"neg_mean_squared_error\", cv=5)\nknn_rmse_scores = np.sqrt(-knn_scores)\ndisplay_scores(knn_rmse_scores)'''","metadata":{"_cell_guid":"a9e9e58b-ce68-4edf-9ce2-83c8474b0650","_uuid":"375e1a73720bbf21547a1bf805ebe22adbbb86af"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"Y_knn_test_pred = np.expm1(knn_reg.predict(X_test))\ntest_knn_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n                                       \"visitors\": Y_knn_test_pred})\n#test_submission.head                                             \ntest_knn_submission.to_csv(\"test_knn_submission.csv\", index=False)","metadata":{"collapsed":true,"_cell_guid":"4c28ea8f-f85e-490e-abd9-deb9eb251387","_uuid":"0430e3dd1430782afec9d93e0a0313b1901055d4"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom scipy.stats import randint\n\n\nparam_distribs = {\n        'max_depth': randint(low=4, high=100),\n        'max_features': randint(low=1, high=23)\n    }\n\ndec_reg = DecisionTreeRegressor(criterion='mse', min_samples_split=4,random_state=42, presort=False)\ndec_search = RandomizedSearchCV(dec_reg, param_distributions=param_distribs,\n                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42, verbose=3)\ndec_search.fit(X_train, y_train)","metadata":{"_cell_guid":"ab5eb6e7-3e95-4fac-b64a-143e85ba3b31","_uuid":"355ed710e8e7a7db94e38809f6d03e1d13133345"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"dec_search.best_score_\nrmse = np.sqrt(-dec_search.best_score_)\nrmse","metadata":{"_cell_guid":"6f78e787-3897-4b63-8dde-ce7583d087da","_uuid":"fb065a10c9e1175f85e63f5223ca38d9cc2fee6c"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"dec_search.best_params_","metadata":{"_cell_guid":"c050c8ef-c28c-4c1a-b87d-d8568e2734ea","_uuid":"866212b1f543f5217b1a00885a3ce30036824cab"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"dec_best_model = dec_search.best_estimator_\n\nY_dec_test_pred = np.expm1(dec_best_model.predict(X_test))\ntest_dec_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n                                       \"visitors\": Y_dec_test_pred})\n#test_submission.head()\ntest_dec_submission.to_csv(\"test_dec_submission.csv\", index=False)","metadata":{"collapsed":true,"_cell_guid":"77858056-a791-4233-8c21-8fd27c4a4c19","_uuid":"c151be74014c6d7b8806fc2d2b3d7f03e85b4025"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"avg_visit = data['final_data'].groupby(['air_store_id', 'day_n_of_week'])[['visitors']].mean().reset_index()\ndummy = data['submission_prep'].copy()\ndummy.drop('visitors', axis=1, inplace=True)\ndummy['day_n_of_week'] = dummy['visit_date'].dt.dayofweek + 1\navg_visitors = pd.merge(dummy, avg_visit, how=\"left\")\navg_visitors = avg_visitors[['id', 'visitors']]\navg_visitors = avg_visitors.fillna(1)","metadata":{"_cell_guid":"d99c18df-53a1-4556-8bba-665500826e96","_uuid":"37b04ba8b9000b20160043580214975530d94097"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"data['test_data']['visitors'] = (dec_best_model.predict(X_test) + np.array(np.log1p(avg_visitors['visitors']))) / 2\ndata['test_data']['visitors'] = np.expm1(data['test_data']['visitors']).clip(lower=0)\nrecruit_predictions = data['test_data'][['id', 'visitors']]\nrecruit_predictions.to_csv(\"recruit_predictions.csv\", index=False)","metadata":{"collapsed":true,"_cell_guid":"54585741-86eb-49ec-bc03-cb96d23edf78","_uuid":"b71f1b5f04a771b3347424af777c04ef8c8ae098"}}],"nbformat":4,"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","version":"3.6.3","name":"python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":1}