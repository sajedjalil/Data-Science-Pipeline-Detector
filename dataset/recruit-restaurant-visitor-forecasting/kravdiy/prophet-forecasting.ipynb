{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"file_extension":".py","name":"python","nbconvert_exporter":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3"}},"cells":[{"metadata":{"_cell_guid":"c737d116-bfc8-4172-a7a8-b2d3a81bb067","collapsed":true,"_uuid":"de47fedafc1cc9a334aca06e94097587ee64419e"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom fbprophet import Prophet\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"56bb1270-8415-4299-a435-9ab80e94e8e4","_uuid":"09ad60d1224f37af9547a9775a6a752d0bce6251"},"source":"Generally let us divide process to the 4 main parts. \n1. Data preparation.\n2. Data exploration.\n3. Model selection & fitting.\n4. Model evaluation.","cell_type":"markdown"},{"metadata":{"_cell_guid":"feac6433-cd81-4057-b361-d40e845e4a53","_uuid":"b2f0ae13356fcb72dafd7901d645639dbc6db88e"},"source":"Data preparation. \n","cell_type":"markdown"},{"metadata":{"_cell_guid":"172439b3-1d6e-4862-8f01-c3c618d233d4","collapsed":true,"_uuid":"3ba20183f6b7cf9f36bcbdee630412c8d5d36f52"},"source":"data = {\n    'tra': pd.read_csv('../input/air_visit_data.csv'),\n    'as': pd.read_csv('../input/air_store_info.csv'),\n    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n    'ar': pd.read_csv('../input/air_reserve.csv'),\n    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n    'id': pd.read_csv('../input/store_id_relation.csv'),\n    'tes': pd.read_csv('../input/sample_submission.csv'),\n    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n    }\n\ndata['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n\nfor df in ['ar','hr']:\n    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date    \n    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n    data[df] = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date'})\n    data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n    \ndata['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\ndata['tra']['year'] = data['tra']['visit_date'].dt.year\ndata['tra']['month'] = data['tra']['visit_date'].dt.month\ndata['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n\ndata['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\ndata['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\ndata['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\ndata['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\ndata['tes']['year'] = data['tes']['visit_date'].dt.year\ndata['tes']['month'] = data['tes']['visit_date'].dt.month\ndata['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n\nunique_stores = data['tes']['air_store_id'].unique()\nstores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n\ntmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \ntmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\ntmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\ntmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n\nstores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) \nlbl = LabelEncoder()\nstores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\nstores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n\ndata['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\ndata['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\ndata['hol']['visit_date'] = data['hol']['visit_date'].dt.date\ntrain = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \ntest = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n\ntrain = pd.merge(data['tra'], stores, how='left', on=['air_store_id','dow']) \ntest = pd.merge(data['tes'], stores, how='left', on=['air_store_id','dow'])\n\nfor df in ['ar','hr']:\n    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n    \ntrain = train.fillna(-1)\ntest = test.fillna(-1)\n\ncol = [c for c in train if c not in ['id', 'air_store_id', 'visit_date', 'visitors']]\ntrain = train.fillna(-1)\ntest = test.fillna(-1)\n\ntrain.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"5e4cb7ba-a750-4ef3-b64b-76b0376ecf15","_uuid":"f22de53eb0f2abad6d37eb5f7c7cf21a731ea7bc"},"source":"Data exploration","cell_type":"markdown"},{"metadata":{"_cell_guid":"70328a72-5f0b-4ae4-b64c-12a2e485eb24","collapsed":true,"_uuid":"b3ebdb19f3e96329cf6d7d427a879d7806aa0908"},"source":"train.describe()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"fa5ada58-d2a0-4106-8874-d40a8ed7a59d","_uuid":"a3532f0e5181cffcef8660962c909c69d274df4c"},"source":"I can reccomend library to save a lot of time for statistical exploration of the data.","cell_type":"markdown"},{"metadata":{"_cell_guid":"f181ddb7-62f4-4312-a60a-03d41aad3160","collapsed":true,"_uuid":"f070e8aa5f868de854a39c1e56be824e96dbea3d"},"source":"import pandas_profiling","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"e0eddd5d-60d4-4373-a34f-71eb817bb1b7","collapsed":true,"_uuid":"132f814c71408d0e2884ca34e4dc8bf131e8b789"},"source":"pandas_profiling.ProfileReport(train)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"545ee50d-a7f7-44c0-a27c-3c7e09d066a8","_uuid":"b7fc100d495a881ab1995545768d813b6a18248b"},"source":"Stationarity test.","cell_type":"markdown"},{"metadata":{"_cell_guid":"d962cfb0-0872-4767-9014-874020320829","collapsed":true,"_uuid":"4fbd02f0bc5f22b4089bceb477b02d02d779043a"},"source":"% time date = train.groupby('visit_date').nunique()\ndate['visitors'] = train.groupby('visit_date').visitors.agg('sum')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"21ed0bd3-b9ae-4ec1-85b8-6d55f10582ab","collapsed":true,"_uuid":"ad2e24c7342da6f57e78e6e7417cb2507e597067"},"source":"def test_stationarity(ts):\n    \n    #Determing rolling statistics\n    rolmean = ts.rolling(window=2, center=False).mean()\n    rolstd = ts.rolling(window=2, center=False).std()\n\n    #Plot rolling statistics:\n    orig = plt.plot(ts, color='blue', label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label='Rolling Std')\n    plt.legend(loc='best')\n    fig_size[0] = 20\n    fig_size[1] = 10\n    plt.rcParams[\"figure.figsize\"] = fig_size\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(ts, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n    for key, value in dftest[4].items():\n        dfoutput['Critical Value (%s)' % key] = value\n    print(dfoutput)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"b96c83e0-d245-4913-bb91-97a8efa031ce","collapsed":true,"_uuid":"7424bf34149dceab9d0a520511131ff777da9032"},"source":"fig_size = plt.rcParams[\"figure.figsize\"]\nfig_size\nfig_size[0] = 12\nfig_size[1] = 9\nplt.rcParams[\"figure.figsize\"] = fig_size","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"25a93678-427e-4b4a-af61-45c20154ecc9","collapsed":true,"_uuid":"175c679647500bc8b3eea76cafaf57d47fa98dba"},"source":"date.index","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"8817085a-13c2-4ec7-ab3b-24b8363c3c4a","collapsed":true,"_uuid":"7850e0ff59a8023e0f4dae4d4d28ef445baf4ad9"},"source":"ts = date['visitors']\nts.head(20)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"e2db1704-9ab1-4c55-ae6b-cc0334722c6c","collapsed":true,"_uuid":"72ecec031ae9e83a33c973d9d3dc604f505ad394"},"source":"X = ts.values\nts.dropna(inplace=True)\ntest_stationarity(ts)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"0ac75347-f942-4c84-bc41-b50d73979142","collapsed":true,"_uuid":"f2a80cee40d17e16286ad1df5670c985492cad71"},"source":"ts_log = np.log(ts)\nplt.plot(ts_log)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"15443782-8816-4df5-af63-5466da903dfb","collapsed":true,"_uuid":"ff4dd7297d2c59e99a2c4d5d42f088fd69d01df6"},"source":"test_stationarity(ts_log)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"7ba6b995-f88c-4550-b787-a6ba5fea9ad1","_uuid":"bb088ba616e72523d21616987714c9dbf3d4a738"},"source":"Prophet forecasting","cell_type":"markdown"},{"metadata":{"_cell_guid":"71f1ce4e-89e5-4cd3-bdfa-741469317c15","collapsed":true,"_uuid":"77f9b0db9c5cd9966515678bcaa7134a0da9a806"},"source":"import logging\nlogging.getLogger('fbprophet.forecaster').propagate = False\n\ndf_sub = pd.read_csv('../input/sample_submission.csv')\ndf_sub['store_id'] = df_sub['id'].apply(lambda x:x[:-11])\n\ndf_sub = df_sub.set_index('id')\n\nnumber_of_stores = df_sub['store_id'].nunique()\ndate_range = pd.date_range(start=pd.to_datetime('2016-07-01'),\n                           end=pd.to_datetime('2017-04-22'))\nforecast_days = (pd.to_datetime('2017-05-31')-pd.to_datetime('2017-04-22')).days\n\nfor cnt, store_id in enumerate(df_sub['store_id'].unique()):\n    print('Predicting %d of %d.'%(cnt, number_of_stores), end='\\r')\n    data = train[train['air_store_id'] == store_id]\n    data = data[['visit_date', 'visitors']].set_index('visit_date')\n    # Ensure we have full range of dates.\n    data = data.reindex(date_range).fillna(0).reset_index()\n    data.columns = ['ds', 'y']\n    \n    m = Prophet()\n    #m = Prophet(yearly_seasonality=True, mcmc_samples=300)\n    #m.add_seasonality(name='weekly', period=7, fourier_order=3)\n    m.fit(data)\n    future = m.make_future_dataframe(forecast_days)\n    forecast = m.predict(future)\n    forecast = forecast[['ds', 'yhat']]\n    forecast.columns = ['id', 'visitors']\n    forecast['id'] = forecast['id'].apply(lambda x:'%s_%s'%(store_id, x.strftime('%Y-%m-%d')))\n    forecast = forecast.set_index('id')\n    df_sub.update(forecast)\nprint('\\n\\nDone.')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"20a2bbe5-6aaf-4e64-8ad7-0b0eb25bb2c4","collapsed":true,"_uuid":"c2edcadb0fb82e0a537849c2fef4a7a84b3a595c"},"source":"df_sub","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"177c44cd-0b2b-4a9d-9657-9fde3569de18","collapsed":true,"_uuid":"3a9141b4ba18d50d8c226062b6814d7656bdb13e"},"source":"df_sub = df_sub.reset_index()[['id','visitors']]\ndf_sub['visitors'] = df_sub['visitors'].clip(lower=0)\ndf_sub.to_csv('submission_1.csv', index=False)\ndf_sub.head(10)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"98b29ed5-1367-439d-8a00-e5b76b8ead4d","_uuid":"e8a406ac42c751da68052d81d9d2518603656fc6"},"source":"Let us check overall trends on the markets.","cell_type":"markdown"},{"metadata":{"_cell_guid":"2239798f-8e36-42c5-af1e-cf6eb08d3a53","collapsed":true,"_uuid":"b339af4c75b425e9d9d90f543726c88419af8865"},"source":"date_amount = pd.DataFrame(date, columns=['visit_date', 'visitors'])\ndate_amount.index","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"39e91c7f-0ebc-44ce-bf5a-d05e340cf31b","collapsed":true,"_uuid":"27c39d2356bb2168b0cf2c2bbe29f2036f5c743e"},"source":"def to_prophet(df_ts):\n    df = pd.DataFrame(df_ts, columns=['visit_date', 'visitors'])\n    df.drop(['visit_date'], axis=1, inplace=True)\n    df.reset_index(inplace=True)\n    df.rename(columns={\"visit_date\": \"ds\", \"visitors\": \"y\"}, inplace=True)\n    return df","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"bd59c405-db78-42d1-8e13-d417324ded54","collapsed":true,"_uuid":"1241dbdadcf392bfc1a2decaf2f3e1f9b95af6aa"},"source":"date = to_prophet(date)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"207e6c93-6310-45dc-97e8-4e90511650f2","collapsed":true,"_uuid":"8d82a144d0f33fbedc3a229775c7dc3ebd9453b0"},"source":"m = Prophet(daily_seasonality=True, mcmc_samples=150)\nm.fit(date)\nfuture = m.make_future_dataframe(periods=40)\nfuture.head()\nforecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"54d9d654-8b6c-4aae-a446-3d0344b7962d","collapsed":true,"_uuid":"810fbbca3fce532c6fcbc423f14b6a9f55b85820"},"source":"m.plot(forecast);","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"a24ecea4-09be-44f2-a56e-61b2677b58ea","collapsed":true,"_uuid":"9d6f9baf51193a1865dae8cf775b195a3de3a381"},"source":"m.plot_components(forecast);","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"6a4ac9a2-f2bf-4ab7-b3ba-cf81eb2b2a51","collapsed":true,"_uuid":"7cc5e18e62d997d60de6a5e465bc72555046ffac"},"source":"from fbprophet.diagnostics import cross_validation\ndf_cv = cross_validation(m, horizon = '30 days')\ndf_cv.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"854b840a-5518-4fa7-87e9-7f1b92bb2cb0","collapsed":true,"_uuid":"d79d157bee28334126b96cf2a2aec4664ac5a956"},"source":"from sklearn.metrics import mean_squared_error","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"3970e76c-ddc5-4b25-b0c9-be349951432c","collapsed":true,"_uuid":"a6394ecc3dadfbcd94780f2f2e182bd52aa05ab7"},"source":"def RMSLE(y, pred):\n    return mean_squared_error(y, pred)**0.5","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"c8dfa89f-08a0-455e-a832-6b94fe1d611e","collapsed":true,"_uuid":"4dfb29592385958f219e79e38fbd39c9d8a8d4e3"},"source":"RMSLE(df_cv['y'], df_cv['yhat'])","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"bf7d7a58-4c5a-45c0-8103-25a05fcc1b7f","collapsed":true,"_uuid":"aa27686e03d9882ef2f282cfdb1acfa7cb7c7b1f"},"source":"forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(39)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"5798489c-1f24-4dc2-b0ed-bb3d18213376","_uuid":"f21e5b885dd3ec83c0359663317a0b757b68ba34"},"source":"GBM regression model","cell_type":"markdown"},{"metadata":{"_cell_guid":"2c1ca9d3-d8c4-4b32-88e2-8a917cf02554","collapsed":true,"_uuid":"ea91d0bcdf5f8bb84f6a0f4b57c435c448e1fdb0"},"source":"from sklearn import *\nX = train[col]\ny = pd.DataFrame()\ny['visitors'] = np.log1p(train['visitors'].values)\n\ny_test_pred = 0\n\nK = 4\nkf = model_selection.KFold(n_splits = K, random_state = 1, shuffle = True)\nnp.random.seed(1)\n\nparams = {'n_estimators': 100, \n        'max_depth': 8,\n        'min_samples_split': 200, \n        'min_samples_leaf': 50,\n        'learning_rate': 0.005,\n        'max_features':  9,\n        'subsample': 0.9,\n        'loss': 'ls'}\n\nmodel = ensemble.GradientBoostingRegressor(**params)\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n\n    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n    X_test = test[col]\n    print(\"\\nFold \", i)\n\n    fit_model = model.fit(X_train, y_train)\n    pred = model.predict(X_valid)\n    print('RMSE GBM Regressor, fold ', i, ': ', RMSLE(y_valid, pred))\n    print('Prediction length on validation set, GBM Regressor, fold ', i, ': ', len(pred))\n\n    pred = model.predict(X_test)\n    print('Prediction length on test set, GBM Regressor, fold ', i, ': ', len(pred))\n    y_test_pred += pred\n\n    del X_test, X_train, X_valid, y_train\n\n% time y_test_pred /= K  \n","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"5885c0a0-f167-4ea2-910a-b1710a5e5bac","collapsed":true,"_uuid":"20df7ac0f34370f21524c37d18d5e077970bef61"},"source":"df_sub1 = pd.DataFrame()\ndf_sub1['id'] = test['id']\ndf_sub1['visitors'] = np.expm1(y_test_pred) \ndf_sub1.to_csv('submission_2.csv', float_format='%.6f', index=False)\ndf_sub1.head(10)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"cf63c212-58cf-49c4-ad7b-3a9525766391","collapsed":true,"_uuid":"eba88618c90f5594cf0e19355bed67a7c9b05351"},"source":"x1 = df_sub1['visitors']\nx2 = df_sub['visitors']\ncompr = x1 - x2\ncompr","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"3bf11ab0-7564-4d8c-b3ed-f6efdcfe477c","_uuid":"08f4e350d00e78c8af182baf919ca33e678b271c"},"source":"Autocorrelation Function and seasonal decomposition","cell_type":"markdown"},{"metadata":{"_cell_guid":"649b2550-ae9f-402f-b907-ab3d5475081c","collapsed":true,"_uuid":"0dd0feede36472cbc9c9cd99408f93a9309efd65"},"source":"from statsmodels.tsa.stattools import acf, pacf\n\nlag_acf = acf(ts, nlags=20)\nlag_pacf = pacf(ts, nlags=20, method='ols')\n\nplt.subplot(121) \nplt.plot(lag_acf)\nplt.axhline(y=0, linestyle='--', color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts)), linestyle='--', color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts)), linestyle='--', color='gray')\nplt.title('Autocorrelation Function')\n\n#Plot PACF:\nplt.subplot(122)\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--', color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts)), linestyle='--', color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts)), linestyle='--', color='gray')\nplt.title('Partial Autocorrelation Function')\nplt.tight_layout()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"c112d4e2-ab65-4e1b-be12-02fd15a139c8","collapsed":true,"_uuid":"41b0e2ca876508e499406a7d71271f0a026d188f"},"source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\ndecomposition = seasonal_decompose(np.asarray(ts), freq=7)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\ndecomposition.plot()\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]}],"nbformat":4,"nbformat_minor":1}