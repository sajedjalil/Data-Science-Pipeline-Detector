{"cells":[{"source":"# Recruit Restaurant Visitor Forecasting\n\n**Note** - This is my first time series experiment and I will be using LSTM. Let me know improvement areas in comments and upvote if you find it useful.\n\n# Preamble \nIn this competition we are given data from Hot Pepper Gourmet ( which is similar website to Yelp) and AirREGI ( a reservation control and cash register system) and we hare supposed to predict visitors forecasting. e are supposed to use the reservations, visits, and other information from these sites to forecast future restaurant visitor totals on a given date. The training data covers the dates from 2016 until April 2017. The test set covers the last week of April and May of 2017. The test set is split based on time (the public fold coming first, the private fold following the public) and covers a chosen subset of the air restaurants. Let's dive in the data and see what we are given with and lets see what can be done.. \n","metadata":{"_uuid":"fc0ddc665e3035f63c213b37c8848de0942254ad","_cell_guid":"8e2ac554-9cb3-41d7-bbe7-b645711a3452"},"cell_type":"markdown"},{"outputs":[],"source":"import pandas as pd  #pandas for using dataframe and reading csv \nimport numpy as np   #numpy for vector operations and basic maths \nimport urllib        #for url stuff\nimport re            #for processing regular expressions\nimport datetime      #for datetime operations\nimport calendar      #for calendar for datetime operations\nimport time          #to get the system time\nimport scipy         #for other dependancies\nfrom sklearn.cluster import KMeans # for doing K-means clustering\nfrom haversine import haversine # for calculating haversine distance\nimport math          #for basic maths operations\nimport seaborn as sns #for making plots\nimport matplotlib.pyplot as plt # for plotting\nimport os                # for os commands\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nimport xgboost as xgb\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import ensemble, metrics, model_selection, naive_bayes","metadata":{"collapsed":true,"_uuid":"ee5bb07031edeec0a4145e673daff192d29a8465","_cell_guid":"075a9374-8b68-4511-9edb-a561bbf02023"},"execution_count":null,"cell_type":"code"},{"outputs":[],"source":"air_reserve = pd.read_csv(\"../input/air_reserve.csv\")\nair_store = pd.read_csv(\"../input/air_store_info.csv\")\nair = air_reserve.merge(air_store, on = 'air_store_id', how = 'left')\nair_visit = pd.read_csv(\"../input/air_visit_data.csv\")\nair = air.merge(air_visit, on = 'air_store_id', how = 'left')\ndate_info = pd.read_csv(\"../input/date_info.csv\")\nair = air.merge(date_info, left_on='visit_date', right_on = 'calendar_date', how = 'left')\n# air.head()","metadata":{"collapsed":true,"_uuid":"9c0dbc986a352e3aae951f2f3f3ece79a172def9","_cell_guid":"3d175e9b-cc29-4928-a5c2-229e384dfe15"},"execution_count":null,"cell_type":"code"},{"outputs":[],"source":"hpg_reserve = pd.read_csv(\"../input/hpg_reserve.csv\")\nstore_id_rel = pd.read_csv(\"../input/store_id_relation.csv\")\nhpg_store_info = pd.read_csv(\"../input/hpg_store_info.csv\")\nhpg = hpg_reserve.merge(hpg_store_info, on = 'hpg_store_id', how = 'left')\nhpg = hpg.merge(store_id_rel, on = 'hpg_store_id', how = 'left')\n#train = hpg.merge(air, on = 'air_store_id', how = 'left')\n#train.head()\nhpg.head()","metadata":{"_uuid":"d601cbe39e6ef4bf2c1e93d5ba10664c0a0351be","_cell_guid":"826359a4-80d8-47b3-952e-653f52d91c4c"},"execution_count":null,"cell_type":"code"},{"source":"## Data preparation\nAs of now I am using only air file to predict the outputs, in next versions I will include the hpg file as well. By looking at the data in air file we are given information that we have to prepared to be fed to LSTM. We have to predict visitors for given id and date. ","metadata":{"_uuid":"4e7f073266ce493e63f72c928ed0d7beabfef3ba","_cell_guid":"88ed39de-4b54-44ad-8a70-6c4fa1d55e35"},"cell_type":"markdown"},{"outputs":[],"source":"air.head()\n","metadata":{"_uuid":"b7742192402b44b677df998392c61646d418b035","_cell_guid":"da93cc2e-4631-48bc-a4e7-5a7f11870c69"},"execution_count":null,"cell_type":"code"},{"source":"# Visualization of restaurants \nShowing restaurants of most famous genres...","metadata":{"_uuid":"5a7ac63da318338379ba2c58514bddb12632d466","_cell_guid":"6912a5a6-9e25-404b-b836-392df6fa61b1"},"cell_type":"markdown"},{"outputs":[],"source":"genre_summary = pd.DataFrame(air.groupby('air_genre_name')['air_genre_name'].count())\ngenre_summary.reset_index(drop = True)\ngenre_summary = genre_summary.sort_values('air_genre_name', ascending = False)","metadata":{"_uuid":"7ee7bad5f0f2fbb631432660f972402f02e8a9d2","_cell_guid":"a79ebc89-df10-4e2b-afab-748d3d518c2d"},"execution_count":null,"cell_type":"code"},{"outputs":[],"source":"import folium\ndef show_fmaps(train_data, path=1):\n    \"\"\"function to generate map and add the pick up and drop coordinates\n    1. Path = 1 : Join pickup (blue) and drop(red) using a straight line\n    \"\"\"\n    full_data = train_data\n    summary_full_data = pd.DataFrame(full_data.groupby('air_genre_name')['air_store_id'].count())\n    summary_full_data.reset_index(inplace = True)\n    summary_full_data = summary_full_data.loc[summary_full_data['air_store_id']>70000]\n    map_1 = folium.Map(location=[35.767937, 139.982155], zoom_start=10,tiles='OpenStreetMap') # manually added centre\n    new_df = train_data.loc[train_data['air_genre_name'].isin(summary_full_data.air_genre_name.tolist())].sample(50)\n    new_df.reset_index(inplace = True, drop = True)\n    for i in range(new_df.shape[0]):\n        pick_long = new_df.loc[new_df.index ==i]['longitude'].values[0]\n        pick_lat = new_df.loc[new_df.index ==i]['latitude'].values[0]\n        #dest_long = new_df.loc[new_df.index ==i]['dropoff_longitude'].values[0]\n        #dest_lat = new_df.loc[new_df.index ==i]['dropoff_latitude'].values[0]\n        folium.Marker([pick_lat, pick_long]).add_to(map_1)\n        #folium.Marker([dest_lat, dest_long]).add_to(map_1)\n    return map_1","metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"outputs":[],"source":"osm = show_fmaps(air, path=1)\nosm","metadata":{},"execution_count":null,"cell_type":"code"},{"source":"**To Be continued... **","metadata":{},"cell_type":"markdown"},{"outputs":[],"source":"","metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","version":"3.6.3","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1}