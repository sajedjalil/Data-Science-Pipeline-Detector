{"cells":[{"metadata":{"_uuid":"01124bd73b917dbf759058c2659626a42cfb471f"},"cell_type":"markdown","source":"# Feature Engineering based on`Suprise MeÂ´\nBecause most of the Suprise Me kernels are very straight forward I created a more structured version of the feature engineering process with more comments. Maybe it can be a help for someone else too. At the end I added a small dictionary which describes all attributes that are created over the time."},{"metadata":{"trusted":false,"_uuid":"987dba98a216eeb85b4458c08bc9d6f7dcf5afbe"},"cell_type":"code","source":"import glob\nimport re\nimport numpy as np\nimport pandas as pd\n\n# Remove the restriction for the max dataframe width\npd.options.display.max_columns = 250\npd.options.display.max_rows = 250\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom datetime import datetime\nfrom IPython.display import display","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b811a59006cf144e4faaabda512e2ec600e2627"},"cell_type":"markdown","source":"# Load the datasets with pandas"},{"metadata":{"trusted":false,"_uuid":"aeaf55a47e9cf589ec429eb573bf71077352b165"},"cell_type":"code","source":"data = {\n    'gt_visits': pd.read_csv('../input/air_visit_data.csv'),\n    'air_store_info': pd.read_csv('../input/air_store_info.csv'),\n    #'hs': pd.read_csv('../input/hpg_store_info.csv'),\n    'air_reserve_history': pd.read_csv('../input/air_reserve.csv'),\n    'hpg_reserve_history': pd.read_csv('../input/hpg_reserve.csv'),\n    \n    'hpg_to_air_id': pd.read_csv('../input/store_id_relation.csv'),\n    'subm_visits': pd.read_csv('../input/sample_submission.csv'),\n    'holidays': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3836b60ed5a4c219c2b99851bf1bac59fd653a04"},"cell_type":"markdown","source":"## Merge the reservation histories of both plattforms"},{"metadata":{"trusted":false,"_uuid":"1d0e327903a1ec204042d439a167d635ac8d5c10"},"cell_type":"code","source":"###############################################################################################\n# Get the air-reserve id  of the hpg restaurants\n###############################################################################################\ndata['hpg_reserve_history'] = pd.merge(\n    data['hpg_reserve_history'], data['hpg_to_air_id'], \n    how='inner', on=['hpg_store_id']\n)\n\n###############################################################################################\n# Drop the HPG id\n###############################################################################################\ndata['hpg_reserve_history'] = data['hpg_reserve_history'].drop('hpg_store_id', axis=1)\n\ndisplay(data['hpg_reserve_history'].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e463c6104e88d1e89a15d28ecc92ec3bca2c9df6"},"cell_type":"code","source":"###############################################################################################\n# Append the HPG reservations to the air-reserve history\n###############################################################################################\nprint(\"Shape before: \", data['air_reserve_history'].shape)\n\nreservation_history = data['air_reserve_history'].append(data['hpg_reserve_history'], sort=\"True\")\nreservation_history = data['air_reserve_history'].sort_values(by=['air_store_id', 'reserve_datetime'])\nreservation_history = data['air_reserve_history'].reset_index()\nreservation_history = reservation_history.drop('index', axis=1)\n\ndisplay(reservation_history.head())\nprint(\"Shape after: \", reservation_history.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1b1b40912979cfe095c26cdd3e2c7585ebeb8614"},"cell_type":"code","source":"###############################################################################################\n# Log transform the the ammount of reserved visitors for this day\n###############################################################################################\nreservation_history['reserve_visitors'] = np.log1p(reservation_history['reserve_visitors'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e5a799fff27abdb26f8c03303e35f4d985fd4f6c"},"cell_type":"code","source":"###############################################################################################\n# Convert dates into datetime objects / get the day of the week / \n# cut off hours, minutes and seconds\n###############################################################################################\nreservation_history['visit_datetime'] = pd.to_datetime(reservation_history['visit_datetime'])\nreservation_history['visit_dow'] = reservation_history['visit_datetime'].dt.dayofweek\nreservation_history['visit_datetime'] = reservation_history['visit_datetime'].dt.date\nreservation_history['reserve_datetime'] = pd.to_datetime(reservation_history['reserve_datetime'])\nreservation_history['reserve_datetime'] = reservation_history['reserve_datetime'].dt.date\n\n###############################################################################################\n# Calculate the time difference between reservation and visit\n###############################################################################################\nreservation_history['reserve_datetime_diff'] = reservation_history.apply(\n    lambda r: (r['visit_datetime'] - r['reserve_datetime']).days,\n    axis=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"150585496d478e57d76a1e4a603b6e83e71d6bb6"},"cell_type":"code","source":"reservation_history[reservation_history.air_store_id == 'air_00a91d42b08b08d9']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5111f45994e0782fcd91970451de955b6e545b31"},"cell_type":"code","source":"###############################################################################################\n# Group the reservations in to subgroubs:\n# \n# EARLY RESERVATIONS\n# sum_res_diff_er ==> SUM reservation_diff on this day\n# sum_vis_er ==> SUM reservated visitors this day\n# avg_res_diff_er ==> AVG reservation_diff on this day\n# avg_vis_er ==> AVG reservated visitors this day\n#\n# LATE RESERVATIONS\n# sum_res_diff_lr ==> SUM reservation_diff on this day\n# sum_vis_lr ==> SUM reservated visitors this day\n# avg_res_diff_lr ==> AVG reservation_diff on this day\n# avg_vis_lr ==> AVG reservated visitors this day\n###############################################################################################\nreservation_history['early_reservation'] = reservation_history['reserve_datetime_diff'] > 2\nreservation_history['late_reservation'] = reservation_history['reserve_datetime_diff'] <= 2\n\n# SUM early reservations\ntmp1 = reservation_history[reservation_history['early_reservation']].groupby(\n    ['air_store_id','visit_datetime'], as_index=False\n)[['reserve_datetime_diff', 'reserve_visitors']]\ntmp1 = tmp1.sum()\ntmp1 = tmp1.rename(columns={\n    'visit_datetime':'visit_date',\n    'reserve_datetime_diff': 'sum_res_diff_er',\n    'reserve_visitors':'sum_vis_er'\n})\n\n# AVG early reservations\ntmp2 = reservation_history[reservation_history['early_reservation']].groupby(\n    ['air_store_id','visit_datetime'], as_index=False\n)[['reserve_datetime_diff', 'reserve_visitors']]\ntmp2 = tmp2.mean()\ntmp2 = tmp2.rename(columns={\n    'visit_datetime':'visit_date',\n    'reserve_datetime_diff': 'avg_res_diff_er',\n    'reserve_visitors':'avg_vis_er'\n})\n\n# SUM late reservations\ntmp3 = reservation_history[reservation_history['late_reservation']].groupby(\n    ['air_store_id','visit_datetime'], as_index=False\n)[['reserve_datetime_diff', 'reserve_visitors']]\ntmp3 = tmp3.sum()\ntmp3 = tmp3.rename(columns={\n    'visit_datetime':'visit_date', \n    'reserve_datetime_diff': 'sum_res_diff_lr', \n    'reserve_visitors':'sum_vis_lr'\n})\n\n# AVG late reservations\ntmp4 = reservation_history[reservation_history['late_reservation']].groupby(\n    ['air_store_id','visit_datetime'], as_index=False\n)[['reserve_datetime_diff', 'reserve_visitors']]\ntmp4 = tmp4.mean()\ntmp4 = tmp4.rename(columns={\n    'visit_datetime':'visit_date', \n    'reserve_datetime_diff': 'avg_res_diff_lr',\n    'reserve_visitors':'avg_vis_lr'\n})\n\nreservation_history = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\nreservation_history = pd.merge(reservation_history, tmp3, how='outer', on=['air_store_id','visit_date'])\nreservation_history = pd.merge(reservation_history, tmp4, how='outer', on=['air_store_id','visit_date'])\n\nreservation_history.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3a0801afc8a89a186983736ed340ead578da1927"},"cell_type":"code","source":"###############################################################################################\n# Get all unique stores from the submission file\n# Because the submission file contains the restaurant id and visit date in one attribute, \n# this information has to be splitted up\n###############################################################################################\n\ndata['subm_visits']['visit_date'] = data['subm_visits']['id'].map(lambda x: str(x).split('_')[2])\ndata['subm_visits']['air_store_id'] = data['subm_visits']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n\n# Extract unique store ids and create an empty dataframe for the store meta information\nunique_stores = data['subm_visits']['air_store_id'].unique()\nstores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n\nstores.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81ed436026c9aeaa764ecd1710a8e18dd0c3cef9"},"cell_type":"markdown","source":"## Resample timeseries of the ground truth datasets to fill missing days"},{"metadata":{"trusted":false,"_uuid":"b21982add6261c7e0188dccbf4d519cbc129b358"},"cell_type":"code","source":"###############################################################################################\n# Fill the gaps in the training dataset for each restaurant\n# So every row step is exactly one day\n###############################################################################################\ndata['gt_visits']['visit_date'] = pd.to_datetime(data['gt_visits']['visit_date'])\ndata['gt_visits'] = data['gt_visits'].groupby('air_store_id').resample('D', on='visit_date').sum().fillna(0)\ndata['gt_visits'] = data['gt_visits'].reset_index()\ndata['gt_visits'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0e55a3265786f55b226cd536ae174e9aca52fb2c"},"cell_type":"code","source":"###############################################################################################\n# Also check if the submission data has the same stepsize for each restaurant\n# One row step == one day\n###############################################################################################\norg_shape = data['subm_visits'].shape\ndata['subm_visits']['visit_date'] = pd.to_datetime(data['subm_visits']['visit_date'])\ntmp = data['subm_visits'].groupby('air_store_id').resample('D', on='visit_date').sum().fillna(0)\ntmp = tmp.reset_index()\nresampled_shape = tmp.shape\n\nif org_shape[0] == resampled_shape[0]:\n    print('Submission has a stepsize of one day per row and restaurant')\n    del org_shape, tmp, resampled_shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0de8a47b209b0774804a0a5afc57141e3d89eb27"},"cell_type":"markdown","source":"## Prepare the training and submission data (transform date information into week, month, year + DOW)"},{"metadata":{"trusted":false,"_uuid":"dfd32c00b5efe1666d3629430cb299f9aa66c378"},"cell_type":"code","source":"###############################################################################################\n# Transform to datetime objects and split the dates up\n###############################################################################################\ndata['gt_visits']['visit_date'] = pd.to_datetime(data['gt_visits']['visit_date'])\ndata['gt_visits']['dow'] = data['gt_visits']['visit_date'].dt.dayofweek\ndata['gt_visits']['year'] = data['gt_visits']['visit_date'].dt.year\ndata['gt_visits']['month'] = data['gt_visits']['visit_date'].dt.month\ndata['gt_visits']['week'] = data['gt_visits']['visit_date'].dt.week\ndata['gt_visits']['visit_date'] = data['gt_visits']['visit_date'].dt.date\n\n# Also store the visit date as an integer value\ndata['gt_visits']['visit_date_int'] = data['gt_visits']['visit_date'].apply(\n    lambda x: x.strftime('%Y%m%d')\n).astype(int)\n\n# Also log-transform the ground truth visitor values\ndata['gt_visits']['visitors'] = np.log1p(data['gt_visits']['visitors'].values.astype(np.int))\n\ndata['gt_visits'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c298a6fd8c224335ead7b6a5632b4fd2e13193e2"},"cell_type":"code","source":"###############################################################################################\n# Transform to datetime objects and split the dates up\n###############################################################################################\ndata['subm_visits']['visit_date'] = pd.to_datetime(data['subm_visits']['visit_date'])\ndata['subm_visits']['dow'] = data['subm_visits']['visit_date'].dt.dayofweek\ndata['subm_visits']['year'] = data['subm_visits']['visit_date'].dt.year\ndata['subm_visits']['month'] = data['subm_visits']['visit_date'].dt.month\ndata['subm_visits']['week'] = data['subm_visits']['visit_date'].dt.week\ndata['subm_visits']['visit_date'] = data['subm_visits']['visit_date'].dt.date\n\n# Also store the visit date as an integer value\ndata['subm_visits']['visit_date_int'] = data['subm_visits']['visit_date'].apply(\n    lambda x: x.strftime('%Y%m%d')\n).astype(int)\n\ndata['subm_visits'].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31238da29c0a9d47b8af1c70f928d12aa5e296b7"},"cell_type":"markdown","source":"## Generate some more meta information about each restaurant"},{"metadata":{"trusted":false,"_uuid":"4418baf8b30397a8884360c4c78e4ea5dbb5bfde"},"cell_type":"code","source":"###############################################################################################\n# Calculate the min, max, avg, median and overall reservations for each day of a week\n###############################################################################################\n# Min visits\ntmp = data['gt_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors']\ntmp = tmp.min()\ntmp = tmp.rename(columns={'visitors':'min_visitors'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n\n# Mean visits\ntmp = data['gt_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors']\ntmp = tmp.mean()\ntmp = tmp.rename(columns={'visitors':'mean_visitors'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n\n# Median visits\ntmp = data['gt_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors']\ntmp = tmp.median()\ntmp = tmp.rename(columns={'visitors':'median_visitors'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n\n# Max visits\ntmp = data['gt_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors']\ntmp = tmp.max()\ntmp = tmp.rename(columns={'visitors':'max_visitors'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n\n# Overall visits on this week day\ntmp = data['gt_visits'].groupby(['air_store_id','dow'], as_index=False)['visitors']\ntmp = tmp.count()\ntmp = tmp.rename(columns={'visitors':'count_observations'})\nstores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n\n###############################################################################################\n# Merge this information with the remaining restaurant meta information\n###############################################################################################\nstores = pd.merge(stores, data['air_store_info'], how='left', on=['air_store_id'])\n\n###############################################################################################\n# Show one example\n###############################################################################################\nstores.loc[stores['air_store_id'] == 'air_00a91d42b08b08d9']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00c4b69089c0e5cbd369da8009e82e708e185cef"},"cell_type":"markdown","source":"## Prepare the Area and Genre names of each store"},{"metadata":{"trusted":false,"_uuid":"a82b5b1bc6620723620b019e690a7b67a066a4b3"},"cell_type":"code","source":"###############################################################################################\n# Remove some char from the Genre name and area name\n###############################################################################################\nstores['air_genre_name'] = stores['air_genre_name'].map(\n    lambda x: str(str(x).replace('/',' '))\n)\nstores['air_area_name'] = stores['air_area_name'].map(\n    lambda x: str(str(x).replace('-',' '))\n)\n\n###############################################################################################\n# Label-Encoding the cleanded names\n###############################################################################################\nle = LabelEncoder()\nstores['air_genre_name'] = le.fit_transform(stores['air_genre_name'])\nstores['air_area_name'] = le.fit_transform(stores['air_area_name'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88c26fecc7f2f10b4dd461180b62afb87c97cf77"},"cell_type":"markdown","source":"## Create sme features based on longitude and latitude"},{"metadata":{"trusted":false,"_uuid":"b3f0a1e8b7bfec74859943814c5616fd75286dbc"},"cell_type":"code","source":"stores['lon_plus_lat'] = stores['longitude'] + stores['latitude']\nstores['var_max_lat'] = stores['latitude'].max() - stores['latitude']\nstores['var_max_lon'] = stores['longitude'].max() - stores['longitude']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bb409e28b1729ec936fc2f13e0cfa366ccce5a5"},"cell_type":"markdown","source":"## Add the store_id as an seperate feature for the prediction"},{"metadata":{"trusted":false,"_uuid":"c4791c74ff442d7810613bd10ec96432ed6718fa"},"cell_type":"code","source":"le = LabelEncoder()\nstores['air_store_id_feat'] = le.fit_transform(stores['air_store_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b61ff383ae2f72f596672d671702d35462b9be22"},"cell_type":"code","source":"display(stores.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0ccde81b15c72dfc5afc02c2fcfc41db79c0338"},"cell_type":"markdown","source":"## Add information about the holidays"},{"metadata":{"trusted":false,"_uuid":"cce3f0577eaed2286a15d69346be944e57ed1920"},"cell_type":"code","source":"###############################################################################################\n# Prepare the datetime object and simplify it in a da and day of week\n###############################################################################################\ndata['holidays']['visit_date'] = pd.to_datetime(data['holidays']['visit_date'])\n\n# Attention: This day of week does not match the encoding of the 'dow' field\ndata['holidays']['day_of_week'] = le.fit_transform(data['holidays']['day_of_week'])\ndata['holidays']['dow_holidays'] = data['holidays']['visit_date'].dt.dayofweek\n\ndata['holidays']['visit_date'] = data['holidays']['visit_date'].dt.date\n\ndisplay(data['holidays'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bba2a199c7089339104e8968fd5a96e8b2561ed7"},"cell_type":"code","source":"###############################################################################################\n# Add holiday information to the training data\n###############################################################################################\ntrain = pd.merge(data['gt_visits'], data['holidays'], how='left', on=['visit_date'])\ndisplay(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d30dbfdb3e6050d7cbb10f907bb06dadd024d0bf"},"cell_type":"code","source":"###############################################################################################\n# Add holiday information to the submission data\n###############################################################################################\ntest = pd.merge(data['subm_visits'], data['holidays'], how='left', on=['visit_date'])\ndisplay(test.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a9a9ac4f9b16334afc1027c1e91aa6d5dfe4b33"},"cell_type":"markdown","source":"## Merge reservation history with fixed restaurant meta information"},{"metadata":{"trusted":false,"_uuid":"9be79c086d2000e98189d7612b9893830514e161"},"cell_type":"code","source":"##############################################################################################\n# Merge the training data with the prepared meta information\n##############################################################################################\ntrain = pd.merge(train, stores, how='inner', on=['air_store_id','dow'])\ntrain = pd.merge(train, reservation_history, how='left', on=['air_store_id','visit_date'])\n\n# Create the same ID that is used in the submission file\ntrain['id'] = train.apply(\n    lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), \n    axis=1\n)\n\n###############################################################################################\n# Merge the submission dataset with the prepared meta information\n###############################################################################################\ntest = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\ntest = pd.merge(test, reservation_history, how='left', on=['air_store_id','visit_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2fc26c400b29db0ef5fa0c242e8cbbd95f94872f"},"cell_type":"code","source":"###############################################################################################\n# Sort the train and test dataframes again\n###############################################################################################\ntrain = train.sort_values(by=['air_store_id', 'visit_date'])\ntest = test.sort_values(by=['air_store_id', 'visit_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5ba2d70b5f22656cdb6ad567839bd6774cb28210"},"cell_type":"code","source":"###############################################################################################\n# Fill NaN with an -1 value\n###############################################################################################\ntrain = train.fillna(-1)\ntest = test.fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e04a16ae3c81fc9ef7f0b2c7981feefef77528f3"},"cell_type":"code","source":"display(train.head())\ndisplay(train.shape)\ndisplay(test.head())\ndisplay(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"316a1753c99ba09bdc2808d04d1deaccd9da6bbf"},"cell_type":"markdown","source":"## Sort the columns"},{"metadata":{"trusted":false,"_uuid":"0fe238e1a31e360097180f0a55601c5375df3d11"},"cell_type":"code","source":"FEATURES = {\n    'air_store_id_feat' : 'LabelEncoded store ID as an input feature. It allows the network to seperate between the stores',\n    'dow' : 'Day of the week e.g. Monday, Tuesday, Wednesday,...',\n    'year' : 'Year of the visit',\n    'month' : 'Month of the visit',\n    'week' : 'Week of the visit',\n    'visit_date_int' : 'Complete visit date as a integer value',\n    'holiday_flg' : 'Is the current day in the holidays',\n    'min_visitors' : 'Minimum visitors of the current week day',\n    'mean_visitors' : 'Mean visitors of the current week day',\n    'median_visitors' : 'Median visitors of the current week day',\n    'max_visitors' : 'Maximum visitors of the current week day',\n    'count_observations' : 'Total number of reservations for this week day',\n    'air_genre_name' : 'Label encoded name of the cusine genre',\n    'air_area_name' : 'Label encoded name of the area the restaurant is located in',\n    'latitude' : 'Latitude of the restaurant location',\n    'longitude' : 'Longitude of the restaurant location',\n    'lon_plus_lat' : 'Linear combination of longitude and latitude',\n    'var_max_lat' : 'Max(Latitude) - Latitude of the current restaurant',\n    'var_max_lon' : 'Max(Longitude) - Longitude of the current restaurant',\n    'sum_res_diff_er' : 'Summed up differences between the reservation date and the visit date [Diff > 2 days]',\n    'sum_vis_er' : 'Summed up reservated visitors for this day [Diff > 2 days]',\n    'avg_res_diff_er' : 'AVG of differences between the reservation date and the visit date [Diff > 2 days]',\n    'avg_vis_er' : 'AVG reservated visitors for this day [Diff > 2 days]',\n    'sum_res_diff_lr' : 'Summed up differences between the reservation date and the visit date [Diff <= 2 days]',\n    'sum_vis_lr' : 'Summed up reservated visitors for this day [Diff <= 2 days]',\n    'avg_res_diff_lr' : 'AVG of differences between the reservation date and the visit date [Diff > 2 days]',\n    'avg_vis_lr' : 'AVG reservated visitors for this day [Diff <= 2 days]' \n}\n\nEXCLUDED_FEATURES = {\n    'id' : 'Air reservation id of the restaurant',\n    'visit_date' : 'Use the numeric value instead!',\n    'air_store_id' : 'Air reservation id of the restaurant',\n    'day_of_week' : 'Day of the week encoded in the date_info.csv file',\n    'dow_holidays' : 'Day of the week encoded in the date_info.csv file'\n}\n\nGROUND_TRUTH_FEATURES = {\n    'visitors' : 'Ground truth information. The number os visitors is transformed with np.log1p()'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"25865b0d3ca99c660c2229e9a021182632782429"},"cell_type":"code","source":"FEATURE_COLS = list(FEATURES.keys())\nEXCLUDED_COLS = list(EXCLUDED_FEATURES.keys())\nGROUND_TRUTH_COLS = list(GROUND_TRUTH_FEATURES.keys())\n\nprint('Number of cols: ', len(FEATURE_COLS) + len(EXCLUDED_COLS) + len(GROUND_TRUTH_COLS))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}