{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport torch \nfrom PIL import Image \nimport cv2\nimport albumentations as A\nfrom matplotlib import patches, pyplot as plt \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Let's Look at our Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = \"../input/nfl-impact-detection/\"\nim_path = \"../input/nfl-impact-detection/images/\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_label = pd.read_csv(\"../input/nfl-impact-detection/train_labels.csv\")\nimage_label = pd.read_csv(DATA_DIR+\"image_labels.csv\")\ntrain_player_tracking = pd.read_csv(DATA_DIR+\"train_player_tracking.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_label.head(2)\nlen(image_label[\"image\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_player_tracking.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(image_label[\"label\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_label[\"label\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef draw_bb(ax, img, im_df):\n    \n    img_data= im_df[im_df[\"image\"]==img]\n    #print(img_data.shape)\n    for i in range(img_data.shape[0]):\n        data = img_data.iloc[i]\n        bb = patches.Rectangle(\n            (data[\"left\"], \n            data[\"top\"]),\n            data[\"width\"], \n            data[\"height\"],\n            linewidth =2, \n            edgecolor = \"red\"\n        )\n        ax.add_patch(bb)\n            \n    return \n    \ndef plot_img_with_bb():  \n    \n   \n    #image_label = pd.read_csv(DATA_DIR+\"image_labels.csv\")\n    img_list = os.listdir(im_path)\n    \n    fig, ax = plt.subplots(3,3, figsize=(16,14))\n    for i in range(3):\n        for j in range (3):\n            \n            #plt.subplot(3,3,i+1)\n            rand_idx = np.random.randint(len(img_list))\n            img =Image.open(im_path+img_list[rand_idx])\n            #print(img)\n            ax[i][j].imshow(img)\n            \n            draw_bb(ax[i][j], img_list[rand_idx], image_label)\n\n            ax[i][j].set_xticklabels([])\n            ax[i][j].set_yticklabels([])\n        fig.show()\n    fig.subplots_adjust(wspace=0, hspace=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#img_list = image_label[\"image\"].unique()\nplot_img_with_bb()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Faster RCNN "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass NFLDataset(object):\n    def __init__(self, df, image_dir):\n    \n        self.image_ids = df['image'].unique()\n        self.df = df\n        self.image_dir = image_dir\n        #self.transforms = transforms\n        self.labels_dict = {\n            'Helmet':1, \n            'Helmet-Blurred':2, \n            'Helmet-Difficult':3, \n            'Helmet-Sideline':4,\n            'Helmet-Partial':5\n        }\n\n    def __getitem__(self, idx:int):\n        # load images ad masks\n        image_id = self.image_ids[idx]\n        image = np.array(Image.open(f'{self.image_dir}/{image_id}'))/225.0\n        image = np.moveaxis(image, 2, 0)\n        records = self.df[self.df[\"image\"]==self.image_ids[idx]]\n        boxes = []\n        labels = []\n        for i in range(records.shape[0]):\n            img_data = records.iloc[i]\n            x_min = img_data.left\n            x_max = img_data.left + img_data.width\n            y_min = img_data.top\n            y_max = img_data.top + img_data.height\n            boxes.append([x_min, y_min, x_max, y_max])\n            label = self.labels_dict[img_data.label]\n            labels.append(label)\n\n        # convert everything into a torch.Tensor\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        # there are 5 classes \n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        image  = torch.as_tensor(image , dtype = torch.float32)\n        image_id = torch.tensor([idx])\n        \n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        \n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        \n        '''if self.transforms:\n            sample = {\n                'image': image,\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n'''\n        return image, target, image_id\n\n    def __len__(self):\n        return self.image_ids.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#albumentation \ndef get_train_transform():\n    return A.Compose([\n        A.Flip(0.5),\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\ndef get_valid_transform():\n    return A.Compose([\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\n# load a model pre-trained pre-trained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\n# replace the classifier with a new one, that has\n# num_classes which is user-defined\nnum_classes = 6  \n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.imshow(Image.open(os.path.join(im_path, image_label[\"image\"][0])).convert(\"RGB\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\n\ntrain_dataset = NFLDataset(image_label, im_path)\nvalid_dataset = NFLDataset(image_label, im_path)\n# split the dataset in train and test set\n#indices = torch.randperm(len(dataset)).tolist()\nindices = torch.randperm(len(train_dataset)).tolist()\ntrain_cnt = int(0.9*len(indices))\n\ntrain_dataset = torch.utils.data.Subset(train_dataset,indices[:train_cnt])\nvalid_dataset = torch.utils.data.Subset(valid_dataset,indices[train_cnt:])\n\n\n\ntrain_data_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=8,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n\nvalid_data_loader =  torch.utils.data.DataLoader(\n    valid_dataset,\n    batch_size=8,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(len(indices), len(train_dataset), len(valid_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, targets, image_ids = next(iter(train_data_loader))\nimages = list(image.to(device) for image in images)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\nsample = images[0].permute(1,2,0).cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nax.set_axis_off()\nax.imshow(sample)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define and Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\nlr_scheduler = None\n\nnum_epochs = 2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#torch.cuda.empty_cache()\nloss = []\niterations = []\nfor epoch in range(num_epochs):\n    \n\n    for i, batch in enumerate(train_data_loader):\n        if torch.cuda.is_available():\n            images, targets, image_ids = batch\n            images = list(image.to(device) for image in images)\n            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n            model.train()\n            loss_dict = model(images, targets)\n\n            losses = sum(loss for loss in loss_dict.values())\n            loss_value = losses.item()\n\n            optimizer.zero_grad()\n            losses.backward()\n            optimizer.step()\n            \n            if i % 1000 == 0:\n                print(f\"Iteration #{i} loss: {loss_value}\")\n            \n            loss.append(loss_value)\n            iterations.append(i)\n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n        \n    plt.plot(iterations, loss)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), \"frcnnresnet50.pth\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"images, targets, image_ids = next(iter(valid_data_loader))\nimages = list(img.to(device) for img in images)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]\nboxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\nsample = images[0].permute(1,2,0).cpu().numpy()\nmodel.eval()\ncpu_device = torch.device(\"cpu\")\n\noutputs = model(images)\noutputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nax.set_axis_off()\nax.imshow(sample)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}