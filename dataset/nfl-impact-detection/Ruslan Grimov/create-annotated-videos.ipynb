{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport subprocess\nimport tempfile\nimport shutil\n\nimport pandas as pd\n\nfrom tqdm.auto import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Code for video annotation from @samhuddleston https://www.kaggle.com/samhuddleston/nfl-1st-and-future-getting-started kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"def annotate_video(\n        video_path: str,\n        video_labels: pd.DataFrame,\n        output_path: str,\n        convert: bool = False) -> str:\n    '''\n    Create a function to annotate the video at the provided path using labels\n    from the provided dataframe, return the path of the video\n    '''\n\n    VIDEO_CODEC = \"MP4V\"\n    HELMET_COLOR = (0, 0, 0)    # Black\n    IMPACT_COLOR = (0, 0, 255)  # Red\n    video_name = os.path.basename(video_path)\n\n    vidcap = cv2.VideoCapture(video_path)\n    fps = vidcap.get(cv2.CAP_PROP_FPS)\n    width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        tmp_output_path = os.path.join(tmp_dir, video_name)\n        output_video = cv2.VideoWriter(tmp_output_path,\n                                       cv2.VideoWriter_fourcc(*VIDEO_CODEC),\n                                       fps, (width, height))\n        frame = 0\n        while True:\n            it_worked, img = vidcap.read()\n            if not it_worked:\n                break\n\n            # We need to add 1 to the frame count to match the label frame index\n            # that starts at 1\n            frame += 1\n\n            # Let's add a frame index to the video so we can track where we are\n            img_name = f\"{video_name}_frame{frame}\"\n            cv2.putText(img, img_name, (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n                        HELMET_COLOR, thickness=2)\n\n            # Now, add the boxes\n            boxes = video_labels.query(\"video == @video_name and frame == @frame\")\n            for box in boxes.itertuples(index=False):\n                # Filter for definitive head impacts and turn labels red\n                if box.impact == 1 and box.confidence > 1 and box.visibility > 0:\n                    color, thickness = IMPACT_COLOR, 2\n                else:\n                    color, thickness = HELMET_COLOR, 1\n                # Add a box around the helmet\n                cv2.rectangle(img, (box.left, box.top),\n                            (box.left + box.width, box.top + box.height),\n                            color, thickness=thickness)\n                cv2.putText(img, box.label, (box.left, max(0, box.top - 5)),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, thickness=1)\n            output_video.write(img)\n        output_video.release()\n\n        if os.path.exists(output_path):\n            os.remove(output_path)\n        # Not all browsers support the codec, we will re-load the file at\n        # tmp_output_path and convert to a codec that is more broadly\n        # readable using ffmpeg\n        if convert:\n            subprocess.run([\"ffmpeg\", \"-i\", tmp_output_path,\n                            \"-crf\", \"18\", \"-preset\", \"veryfast\",\n                            \"-vcodec\", \"libx264\", output_path])\n        else:\n            shutil.copy(tmp_output_path, output_path)\n\n    return output_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define input and output paths\ndata_path = '/kaggle/input/nfl-impact-detection'\ndest_video_path = './output/annotated_videos/'\n\nvideo_path = os.path.join(data_path, 'train')\nvideo_files = os.listdir(video_path)\nvideo_labels = pd.read_csv(os.path.join(data_path, 'train_labels.csv'))\n\nos.makedirs(dest_video_path, exist_ok=True)\n\nfor video_file in tqdm(video_files):\n    annotate_video(os.path.join(video_path, video_file), video_labels,\n                   os.path.join(dest_video_path, video_file),\n                   True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}