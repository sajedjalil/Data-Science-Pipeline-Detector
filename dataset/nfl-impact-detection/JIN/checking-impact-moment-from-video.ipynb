{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n**Main Topic**\n\nThis notebook is for **Visualizing Impacting Moment** with blind and config speed from `train` *.mp4.\n\nYou can analysis **Impact Moment** from the video.\n\nMain source code is from References, I just a little bit customize the module.\n\n**References**\n\n**Sam Huddleston** : [NFL 1st and Future Getting Started](https://www.kaggle.com/samhuddleston/nfl-1st-and-future-getting-started)"},{"metadata":{},"cell_type":"markdown","source":"# Set up environment"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import imageio\nfrom PIL import Image\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport subprocess\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n%matplotlib inline\nplt.rcParams['figure.dpi'] = 150\n\nimport seaborn as sns\n\nfrom IPython.display import Video, display\n\n#block those warnings from pandas about setting values on a slice\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import video_labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in the video labels file\nvideo_labels = pd.read_csv('../input/nfl-impact-detection/train_labels.csv')\nvideo_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the video we'll process\nvideo_name = video_labels['video'][0]\nvideo_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Show original video","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the path and then display the video using \nvideo_path = f\"../input/nfl-impact-detection/train/{video_name}\"\ndisplay(Video(data=video_path, embed=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define annotate_video\n\nI just added blind & speed parameters from Original NB [NFL 1st and Future Getting Started](https://www.kaggle.com/samhuddleston/nfl-1st-and-future-getting-started)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function to annotate the video at the provided path using labels from the provided dataframe, return the path of the video\ndef annotate_video(video_path: str, video_labels: pd.DataFrame, blind=False, speed=1) -> str:\n    VIDEO_CODEC = \"MP4V\"\n    HELMET_COLOR = (255, 255, 255)    # Black\n    IMPACT_COLOR = (0, 0, 255)  # Red\n    video_name = os.path.basename(video_path)\n    \n    vidcap = cv2.VideoCapture(video_path)\n    width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    output_path = \"labeled_\" + video_name\n    tmp_output_path = \"tmp_\" + output_path\n    fps = 60 * speed\n    output_video = cv2.VideoWriter(tmp_output_path, cv2.VideoWriter_fourcc(*VIDEO_CODEC), fps, (width, height))\n    frame = 0\n    while True:\n        it_worked, img = vidcap.read()\n        if not it_worked:\n            break\n        if blind:\n            img = img * 0\n        \n        # We need to add 1 to the frame count to match the label frame index that starts at 1\n        frame += 1\n        \n        # Let's add a frame index to the video so we can track where we are\n        img_name = f\"{video_name}_frame{frame}\"\n        cv2.putText(img, img_name, (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, HELMET_COLOR, thickness=2)\n    \n        # Now, add the boxes\n        boxes = video_labels.query(\"video == @video_name and frame == @frame\")\n        for box in boxes.itertuples(index=False):\n            if box.impact == 1 and box.confidence > 1 and box.visibility > 0:    # Filter for definitive head impacts and turn labels red\n                color, thickness = IMPACT_COLOR, 2\n            else:\n                color, thickness = HELMET_COLOR, 1\n            # Add a box around the helmet\n            cv2.rectangle(img, (box.left, box.top), (box.left + box.width, box.top + box.height), color, thickness=thickness)\n            cv2.putText(img, box.label, (box.left, max(0, box.top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, thickness=1)\n        output_video.write(img)\n    output_video.release()\n    \n    # Not all browsers support the codec, we will re-load the file at tmp_output_path and convert to a codec that is more broadly readable using ffmpeg\n    if os.path.exists(output_path):\n        os.remove(output_path)\n    subprocess.run([\"ffmpeg\", \"-i\", tmp_output_path, \"-crf\", \"18\", \"-preset\", \"veryfast\", \"-vcodec\", \"libx264\", output_path])\n    os.remove(tmp_output_path)\n    \n    return output_path","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set Speed = 0.5 "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label the video and display it - this will take a bit\nlabeled_video = annotate_video(f\"../input/nfl-impact-detection/train/{video_name}\", video_labels, speed=0.5)\ndisplay(Video(data=labeled_video, embed=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set Blind Video, Speed = 0.3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label the video and display it - this will take a bit\nlabeled_video = annotate_video(f\"../input/nfl-impact-detection/train/{video_name}\", video_labels, blind=True, speed=0.3)\ndisplay(Video(data=labeled_video, embed=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}