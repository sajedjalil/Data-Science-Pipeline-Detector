{"cells":[{"metadata":{"id":"Eo9ulW5s6iz5","trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nfrom sklearn import preprocessing\nimport numpy as np\nfrom scipy import integrate, optimize\nimport math\n\npredictions_total = []\nactual_total = []\nval_loss_dict = {}\n\nval_info_dict = {}\npredictions_dict = {}\nactuals_dict = {}\ncolors_dict = {}\nloss_dict = {}\ntrain_start = 0\ntrain_end = 0\nval_start = 0\nval_end = 0\ntest_start = 0\ntest_end = 0\nmodes = [\"Confirmed Cases\", \"Fatalities\"]\nmethod = \"SIR\"\ndynamic_start_day = False","execution_count":null,"outputs":[]},{"metadata":{"id":"bL4IrSy_-xqw","trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\", parse_dates=[\"Date\"])\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\")\nsubmission = pd.read_csv(\"../input/covid19-global-forecasting-week-3/submission.csv\")\nall_data = train.copy()\n# Create date columns\nall_data['Date'] = pd.to_datetime(all_data['Date'])\nle = preprocessing.LabelEncoder()\nall_data['Day_num'] = le.fit_transform(all_data.Date)\nall_data['Day'] = all_data['Date'].dt.day\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year","execution_count":null,"outputs":[]},{"metadata":{"id":"MEX_1h2CYUyZ","outputId":"7bef57b8-18b5-42a3-8518-069f9849dc4b","trusted":true},"cell_type":"code","source":"# Load countries data file\nworld_population = pd.read_csv(\"../input/population-by-country-2020/population_by_country_2020.csv\")\n\n# Select desired columns and rename some of them\nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Land Area (Km²)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Replace United States by US\nworld_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'\n\n# Remove the % character from Urban Pop values\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\nprint(\"Cleaned country details dataset\")\n\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='Country_Region', right_on='Country (or dependency)', how='left')\nall_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\n\n\nprint(\"Encoded dataset\")\n# Label encode countries and provinces. Save dictionary for exploration purposes\nall_data.drop('Country (or dependency)', inplace=True, axis=1)\nall_data['Country_Region'] = le.fit_transform(all_data['Country_Region'])\n\nnumber_c = all_data['Country_Region']\ncountries = le.inverse_transform(all_data['Country_Region'])\ncountry_dict = dict(zip(countries, number_c)) \nall_data['Province_State'].fillna(\"None\", inplace=True)\nall_data['Province_State'] = le.fit_transform(all_data['Province_State'])\nnumber_p = all_data['Province_State']\nprovince = le.inverse_transform(all_data['Province_State'])\nprovince_dict = dict(zip(province, number_p)) ","execution_count":null,"outputs":[]},{"metadata":{"id":"bGq-gMq5oqUV","trusted":true},"cell_type":"code","source":"class SIR:\n    def __init__(self, beta=0, gamma=0, fix_gamma=False):\n        self.beta = beta\n        self.gamma = gamma\n        self.infected_t0 = 0\n        self.fitted_on = np.array([])\n        self.fix_gamma = fix_gamma\n        self.fitted = False\n        \n    def ode(self, y, x, beta, gamma):\n        '''Defines the ODE that governs the SIRs behaviour'''\n        dSdt = -beta * y[0] * y[1]\n        dRdt = gamma * y[1]\n        dIdt = -(dSdt + dRdt)\n        return dSdt, dIdt, dRdt\n    \n    def solve_ode(self, x, beta, gamma):\n        '''Solves the resulting ODE to get predictions for each time step'''\n        return np.cumsum(integrate.odeint(self.ode, (1-self.infected_t0, self.infected_t0, 0.0), x, args=(beta, gamma))[:,1])\n    \n    def solve_ode_fixed(self, x, beta):\n        '''Solves the resulting ODE to get predictions for each time step'''\n        return np.cumsum(integrate.odeint(self.ode, (1-self.infected_t0, self.infected_t0, 0.0), x, args=(beta, self.gamma))[:,1])\n    \n    def describe(self):\n        assert self.fitted, \"You need to fit the model before describing it!\"\n        print(\"Beta: \", self.beta)\n        print(\"Gamma: \", self.gamma)\n        print(\"Infected at t=0: \", self.infected_t0)\n        \n        plt.plot(range(1,len(self.fitted_on)+1), self.fitted_on, \"x\", label='Actual')\n        plt.plot(range(1,len(self.fitted_on)+1), self.predict(len(self.fitted_on)), label='Prediction')\n        plt.title(\"Fit of SIR model to global infected cases\")\n        plt.ylabel(\"Population infected\")\n        plt.xlabel(\"Days\")\n        plt.legend()\n        plt.show()\n    \n    def fit(self, y):\n        '''Fits the parameters to the data, assuming the first data point is the start of the outbreak'''\n        if len(y) == 1: y = np.array([0, y[0]]) # SIR needs at least 2 datapoints to fit\n        self.infected_t0 = y[0]\n        x = np.array(range(1,len(y)+1), dtype=float)\n        self.fitted_on = y\n        if(self.fix_gamma):\n            popt, _ = optimize.curve_fit(self.solve_ode_fixed, x, y)\n            self.beta = popt[0]\n        else:\n            popt, _ = optimize.curve_fit(self.solve_ode, x, y, maxfev=1000)\n            self.beta = popt[0]\n            self.gamma = popt[1]\n        self.fitted = True\n        \n    def predict(self ,length):\n        '''Returns the predicted cumulated cases at each time step, assuming outbreak starts at t=0'''\n        #assert self.fitted, \"You need to fit the model before predicting!\"\n        return self.solve_ode(range(1, length+1), self.beta, self.gamma)","execution_count":null,"outputs":[]},{"metadata":{"id":"DbvCXYEbsV_l","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef visualize(val_loss_dict, val_info_dict, start=10, end=150):\n  fig = plt.figure(figsize=(10,2))\n  ax = fig.add_axes([0,0,1,1])\n\n  loss_sorted = sorted(val_loss_dict.items(), key=lambda x: x[1], reverse=True)\n  print(loss_sorted[10:20])\n  losses = [x[1] for x in loss_sorted[start:end]]\n  countries = [x[0] for x in loss_sorted[start:end]]\n  colors = [val_info_dict[x][\"Color\"] for x in countries]\n  ax.bar(countries, losses, color=colors)","execution_count":null,"outputs":[]},{"metadata":{"id":"_r7cJkVjnlsn","trusted":true},"cell_type":"code","source":"unknown_countries = []\nhardcoded_countries = {\n    \"Korea, South\": 51269000,\n    \"Diamond Princess\": 3711,\n    \"Taiwan*\": 23800000,\n    \"Saint Vincent and the Grenadines\": 109897,\n    \"Congo (Brazzaville)\":5261000,\n    \"Congo (Kinshasa)\":81340000,\n    \"Cote d'Ivoire\":24300000,\n    \"Czechia\": 10650000,\n    \"Saint Kitts and Nevis\": 55345,\n    \"Burma\": 53370000,\n    \"Kosovo\": 1831000,\n    \"MS Zaandam\": 1432, # cruise ship\n    \"West Bank and Gaza\": 4685,\n}\nstate_populations= pd.read_csv(\"../input/covid19-forecasting-metadata/region_metadata.csv\")\ndef get_population(country_name, province_name=None):\n  if province_name:\n    pop = state_populations[state_populations['Province_State']==province_name]['population']\n    if len(pop)==0:\n      print(f\"Warning: We have no province population data at the moment. Instead of data for {province_name}, using data for {country_name}\")\n    else:\n      return pop.iloc[0]\n  \n  if country_name in hardcoded_countries:\n    return hardcoded_countries[country_name]\n  \n\n  \n  pop = all_data[all_data[\"Country_Region\"] == country_dict[country_name]].iloc[0][\"Population (2020)\"]\n  if not pop:\n    print(f\"population of {country_name} unknown\")\n    pop = 100\n    unknown_countries.append(country_name)\n  return pop","execution_count":null,"outputs":[]},{"metadata":{"id":"QELZtpCdQp8P","outputId":"09e65ef5-ade6-4800-da95-105f01a41fd3","trusted":true},"cell_type":"code","source":"country_name = 'China'\nall_data[all_data[\"Country_Region\"] == country_dict[country_name]].iloc[0][\"Population (2020)\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"tsjtS2dcCh6j","outputId":"fdde0367-1edd-4244-937e-c09f24723c5e","trusted":true},"cell_type":"code","source":"country_name = 'Hubei'\nall_data[all_data[\"Province_State\"] == province_dict[country_name]].iloc[0][\"Population (2020)\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"gzpYg0IBtp3h","trusted":true},"cell_type":"code","source":"def visualize_country(country_name, val_info_dict=val_info_dict):\n  info = val_info_dict[country_name]\n  cases_actual = info[\"Cases Actual\"]\n  cases_predicted = info[\"Cases Predicted\"]\n  cases_split = info[\"Case Split\"]\n  fat_actual = info[\"Fatalities Actual\"]\n  fat_predicted = info[\"Fatalities Predicted\"]\n  fat_split = info[\"Fatality Split\"]\n  \n  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30,15))\n\n  ax1.plot(cases_actual, 'o')\n  ax1.plot(cases_predicted)\n  ax1.axvline(x=cases_split, color='gray', linestyle='--')\n  ax1.set_title(\"Fit of SIR model to global infected cases\")\n    \n  ax2.plot(fat_actual, 'o')\n  ax2.plot(fat_predicted)\n  ax2.axvline(x=fat_split, color='gray', linestyle='--')\n  ax2.set_title(\"Fit of SIR model to global fatalities\")\n  \n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"B3d-fcFy5bK2","trusted":true},"cell_type":"code","source":"def get_country_data(country_name, province_name=None):\n  if province_name:\n    confirmed_total_date_country = train[(train['Country_Region']==country_name) & (train['Province_State']==province_name)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n    fatalities_total_date_country = train[(train['Country_Region']==country_name) & (train['Province_State']==province_name)].groupby(['Date']).agg({'Fatalities':['sum']})\n    total_date_country = confirmed_total_date_country.join(fatalities_total_date_country)\n\n    cases = total_date_country.ConfirmedCases['sum'].values\n    cases_normalized = total_date_country.ConfirmedCases['sum'].values / get_population(country_name, province_name)\n    fatalities_normalized = total_date_country.Fatalities['sum'].values / get_population(country_name, province_name)\n\n    cases_final = cases_normalized[np.argmax(cases>0):]\n    fatalities_final = fatalities_normalized[np.argmax(fatalities_normalized>0):]\n\n    cases_length = len(cases_final)\n    fat_length = len(fatalities_final)\n    cases_split = math.floor(cases_length * 1.0)\n    fat_split = math.floor(fat_length * 1.0)\n  else:\n    confirmed_total_date_country = train[train['Country_Region']==country_name].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n    fatalities_total_date_country = train[train['Country_Region']==country_name].groupby(['Date']).agg({'Fatalities':['sum']})\n    total_date_country = confirmed_total_date_country.join(fatalities_total_date_country)\n\n    cases = total_date_country.ConfirmedCases['sum'].values\n    cases_normalized = cases / get_population(country_name, province_name)\n    fatalities_normalized = total_date_country.Fatalities['sum'].values / get_population(country_name, province_name)\n\n    cases_final = cases_normalized[np.argmax(cases>0):]\n    fatalities_final = fatalities_normalized[np.argmax(fatalities_normalized>0):]\n\n    cases_length = len(cases_final)\n    fat_length = len(fatalities_final)\n    cases_split = math.floor(cases_length * 1.0)\n    fat_split = math.floor(fat_length * 1.0)\n    \n  return cases_final, fatalities_final, cases_split, fat_split, cases_length, fat_length","execution_count":null,"outputs":[]},{"metadata":{"id":"6IvVbeCU7YUz","trusted":true},"cell_type":"code","source":"def train_val_country(country_name):\n    cases, fatalities, case_split, fat_split, case_length, fat_length = get_country_data(country_name)\n    cases_train = cases[0:case_split]\n    cases_test = cases[case_split:]\n    fat_train = fatalities[0:fat_split]\n    fat_test = fatalities[fat_split:]\n    \n    case_model = SIR()\n    case_model.fit(cases_train)\n    fat_model = SIR()\n    fat_model.fit(fat_train)\n    \n    cases_pred_all = case_model.predict(len(cases_train) + len(cases_test))\n    cases_pred_val = cases_pred_all[case_split:]\n    fat_pred_all = fat_model.predict(len(fat_train) + len(fat_test))\n    fat_pred_val = fat_pred_all[fat_split:]\n    \n    if(sum(cases_test) > sum(cases_pred_val)):\n      color = \"red\"\n    else:\n      color = \"blue\"\n    \n    #val_loss = np.sqrt(mean_squared_log_error(cases_test, cases_pred_val))\n    val_loss = 1\n    #print(f\"Val Loss for {country_name}: {val_loss}\")\n    #print(f\"Sum actual: {sum(y)} Sum predicted: {sum(pred)}\")\n    val_loss_dict[country_name] = val_loss\n    results_dict =  {\n        \"Country\": country_name,\n        \"Province\": float('nan'),\n        \"Case Model\": case_model,\n        \"Fatality Model\": fat_model,\n        \"Color\": color,\n        \"Cases Predicted\": cases_pred_all,\n        \"Cases Actual\": cases,\n        \"Fatalities Predicted\": fat_pred_all,\n        \"Fatalities Actual\": fatalities,\n        \"Loss\": val_loss,\n        \"Case Split\": case_split,\n        \"Fatality Split\": fat_split,\n        \"Case length\": case_length,\n        \"Fatality length\": fat_length\n    }\n    return results_dict\n\ndef train_val_province(country_name, province_name):\n    cases, fatalities, case_split, fat_split, case_length, fat_length = get_country_data(country_name, province_name)\n    cases_train = cases[0:case_split]\n    cases_test = cases[case_split:]\n    fat_train = fatalities[0:fat_split]\n    fat_test = fatalities[fat_split:]\n    \n    case_model = SIR()\n    case_model.fit(cases_train)\n    fat_model = SIR()\n    fat_model.fit(fat_train)\n      \n    cases_pred_all = case_model.predict(len(cases_train) + len(cases_test))\n    cases_pred_val = cases_pred_all[case_split:]\n    fat_pred_all = fat_model.predict(len(fat_train) + len(fat_test))\n    fat_pred_val = fat_pred_all[fat_split:]\n    \n    if(sum(cases_test) > sum(cases_pred_val)):\n      color = \"red\"\n    else:\n      color = \"blue\"\n    \n    #val_loss = np.sqrt(mean_squared_log_error(cases_test, cases_pred_val))\n    val_loss = 1\n    #print(f\"Val Loss for {country_name}: {val_loss}\")\n    #print(f\"Sum actual: {sum(y)} Sum predicted: {sum(pred)}\")\n    val_loss_dict[country_name] = val_loss\n    results_dict = {\n        \"Country\": country_name,\n        \"Province\": province_name,\n        \"Case Model\": case_model,\n        \"Fatality Model\": fat_model,\n        \"Color\": color,\n        \"Cases Predicted\": cases_pred_all,\n        \"Cases Actual\": cases,\n        \"Fatalities Predicted\": fat_pred_all,\n        \"Fatalities Actual\": fatalities,\n        \"Loss\": val_loss,\n        \"Case Split\": case_split,\n        \"Fatality Split\": fat_split,\n        \"Case length\": case_length,\n        \"Fatality length\": fat_length\n    }\n    return results_dict","execution_count":null,"outputs":[]},{"metadata":{"id":"LZynM7cQ8fUN","trusted":true},"cell_type":"code","source":"country_and_provinces = {}\nonly_provinces = {}\nonly_country = []\nfor country in test['Country_Region'].unique():\n  provinces = test[test['Country_Region']==country]['Province_State'].unique()\n  \n  if len(provinces)>1:\n    contains_nan = False\n    for province in provinces:\n      if type(province) == float:\n        contains_nan = True\n    if contains_nan:\n      country_and_provinces[country] = provinces\n    else:\n      only_provinces[country] = provinces\n  else:\n    only_country.append(country)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"eoEqisvajzsY","outputId":"0ed82a6b-94a5-4928-8eb5-3948dddc611e","trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\nfor country in tqdm(train['Country_Region'].unique()):\n  #if(country==\"Guinea-Bissau\" or country==\"Mali\" or country==\"Saint Kitts and Nevis\" or country==\"Australia\" or country==\"Canada\"): continue\n  \n  #If we only need to predict for the provinces, not for the whole country\n  if country in only_provinces:\n    for province in only_provinces[country]:\n      #if(province in [\"Alaska\", \"Hawaii\", \"West Virginia\"]): continue\n      #if country != \"China\":\n        val_info_dict[province] = train_val_province(country, province)\n      \n  #If we need to predict for the provinces and for the whole country\n  elif country in country_and_provinces:\n    for province in country_and_provinces[country]:\n      #if(province in [\"St Martin\"]): continue\n      #For the 'nan' province value: Make predictions for the whole country\n      if type(province) == float:\n        val_info_dict[country] = train_val_country(country)\n      else:\n        val_info_dict[province] = train_val_province(country, province)\n\n  #If we don't have any provinces for this country\n  elif country in only_country:\n    try:\n      val_info_dict[country] = train_val_country(country)\n    except:\n      print(country)","execution_count":null,"outputs":[]},{"metadata":{"id":"FgSEco90VBdM","outputId":"4f78feff-3f74-416e-9b3e-979b31ae8640","trusted":true},"cell_type":"code","source":"# submission date range: 19Mar20-30Apr20\npd_daterange_submission = pd.date_range(\"26Mar20\", \"7May20\") #TODO get from test dataset: min/max of Date\nlength_submission = len(pd_daterange_submission)\n\ndef make_submission(val_info_dict=val_info_dict):\n  # generate submission frames for all items in val_info_dict\n  frames = []\n  for attr, item in val_info_dict.items():\n    country = item[\"Country\"]\n    province = item[\"Province\"]\n    case_length = item[\"Case length\"]\n    fat_length = item[\"Fatality length\"]\n    case_model = item[\"Case Model\"]\n    fat_model = item[\"Fatality Model\"]\n\n    if(type(province)==float):\n        pop = get_population(country)\n    else:\n        pop = get_population(country, province)\n        \n    case_preds = pop * case_model.predict(case_length + length_submission)[case_length:]\n    fat_preds = pop * fat_model.predict(fat_length + length_submission)[fat_length:]\n\n    frames.append(pd.DataFrame({\n        \"Country_Region\": country,\n        \"Province_State\": province,\n        \"Date\": pd_daterange_submission,\n        \"ConfirmedCases\": case_preds,\n        \"Fatalities\": fat_preds\n        })\n    )\n  \n  # concat sub frames and prepare for mergeing with test to get ForecastId\n  submission_data = pd.concat(frames)\n  submission = test.copy()\n\n  index = [\"id\", \"Date\"]\n  submission[\"id\"] = submission[\"Country_Region\"].astype(str) + \"_\" + submission[\"Province_State\"].astype(str)\n  submission = submission[[\"id\", \"Date\", \"ForecastId\"]].set_index(index)\n\n  submission_data[\"id\"] = submission_data[\"Country_Region\"].astype(str) + \"_\" + submission_data[\"Province_State\"].astype(str)\n  submission_data = submission_data[[\"id\", \"Date\", \"ConfirmedCases\", \"Fatalities\"]].set_index(index)\n\n  # merge w/ ForecastId and extract submission columns\n  submission = submission.join(submission_data)\n  submission = submission[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]]\n\n  # fillna (China)\n  submission = submission.fillna(1)\n    \n  # write to csv\n  submission.to_csv(\"submission.csv\", index=False)\n\n  print(\"submission saved to csv.\")\n  \nmake_submission()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Temporal SIR-Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SIRT:\n    def __init__(self, gamma=0, a=0, b=0, c=0, d=0, fix_gamma=False):\n        self.gamma = gamma\n        self.a = a\n        self.b = b\n        self.c = c\n        self.d = d\n        self.infected_t0 = 0\n        self.fitted_on = np.array([])\n        self.fix_gamma = fix_gamma\n        self.fitted = False\n        \n    def ode(self, y, timestep, c, d, gamma):\n        '''Defines the ODE that governs the SIRs behaviour'''\n        beta = c * timestep + d\n        \n        dSdt = -beta * y[0] * y[1]\n        dRdt = gamma * y[1]\n        dIdt = -(dSdt + dRdt)\n        return dSdt, dIdt, dRdt\n    \n    def solve_ode(self, x, c, d, gamma):\n        '''Solves the resulting ODE to get predictions for each time step'''\n        return np.cumsum(integrate.odeint(self.ode, (1-self.infected_t0, self.infected_t0, 0.0), x, args=(c, d, gamma))[:,1])\n    \n    def solve_ode_fixed(self, x, beta):\n        '''Solves the resulting ODE to get predictions for each time step'''\n        return np.cumsum(integrate.odeint(self.ode, (1-self.infected_t0, self.infected_t0, 0.0), x, args=(beta, self.gamma))[:,1])\n    \n    def describe(self):\n        assert self.fitted, \"You need to fit the model before describing it!\"\n        print(\"c: \", self.c)\n        print(\"d: \", self.d)\n        print(\"Gamma: \", self.gamma)\n        print(\"Infected at t=0: \", self.infected_t0)\n        \n        plt.plot(range(1,len(self.fitted_on)+1), self.fitted_on, \"x\", label='Actual')\n        plt.plot(range(1,len(self.fitted_on)+1), self.predict(len(self.fitted_on)), label='Prediction')\n        plt.title(\"Fit of SIR model to global infected cases\")\n        plt.ylabel(\"Population infected\")\n        plt.xlabel(\"Days\")\n        plt.legend()\n        plt.show()\n    \n    def fit(self, y):\n        '''Fits the parameters to the data, assuming the first data point is the start of the outbreak'''\n        self.infected_t0 = y[0]\n        x = np.array(range(1,len(y)+1), dtype=float)\n        self.fitted_on = y\n        if(self.fix_gamma):\n            popt, _ = optimize.curve_fit(self.solve_ode_fixed, x, y)\n            self.beta = popt[0]\n        else:\n            popt, _ = optimize.curve_fit(self.solve_ode, x, y)\n            self.c = popt[0]\n            self.d = popt[1]\n            self.gamma = popt[2]\n        self.fitted = True\n        \n    def predict(self ,length):\n        '''Returns the predicted cumulated cases at each time step, assuming outbreak starts at t=0'''\n        #assert self.fitted, \"You need to fit the model before predicting!\"\n        return self.solve_ode(range(1, length+1), self.c, self.d, self.gamma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measures = pd.read_csv(\"../input/covid19-containment-and-mitigation-measures/COVID 19 Containment measures data.csv\")\nmeasures[\"Keywords\"].fillna(value=\"-\", inplace=True)\nmeasures[\"Country\"] = measures[\"Country\"].str.replace('South Korea', 'Korea, South', regex=True)\nmeasures[\"Country\"] = measures[\"Country\"].str.replace('US:Georgia', 'US', regex=True)\nmeasures[\"Country\"] = measures[\"Country\"].str.replace('US: Illinois', 'US', regex=True)\nmeasures[\"Country\"] = measures[\"Country\"].str.replace('US:Maryland', 'US', regex=True)\n\nmeasures = measures[measures[\"Country\"] != \"Vatican City\"]\nmeasures = measures[measures[\"Country\"] != \"Hong Kong\"]\n\ndef get_measures(measure_name):\n    \n    took_measure = measures[measures[\"Keywords\"].str.contains(\"distancing\")]\n    output = pd.DataFrame(data=0,\n                          columns=train['Country_Region'].unique(),\n                          index=pd.date_range(\"02.01.2020\", \"03.01.2020\"))\n    \n    print(took_measure)\n    \n    for index, row in took_measure.iterrows():\n        output[row[\"Country\"]][pd.to_datetime(row[\"Date Start\"]):] = 1\n    return output\n                               \nget_measures(\"distancing\")[\"Italy\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SIRT()\nc, _, case_split, _, case_length, _ = get_country_data(\"Spain\")\nmodel.fit(c[:case_split])\nmodel.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling SIR Parameters\nPredicting SIR parameters from Country/Province Metadata"},{"metadata":{"trusted":true},"cell_type":"code","source":"# WIP\nfor attr, item in val_info_dict.items():\n    country = item[\"Country\"]\n    province = item[\"Province\"]\n    case_length = item[\"Case length\"]\n    fat_length = item[\"Fatality length\"]\n    case_model = item[\"Case Model\"]\n    fat_model = item[\"Fatality Model\"]","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"LeoCorona","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}