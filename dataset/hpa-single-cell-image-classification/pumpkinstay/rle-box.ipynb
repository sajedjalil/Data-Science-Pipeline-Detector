{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"print('test test test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try and get keras plot to work\n!pip install -q pydot\n!pip install -q pydotplus\n!apt-get install -q graphviz\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nimport tensorflow_addons as tfa;\nimport scipy;\nfrom collections import Counter\nfrom datetime import datetime\nimport multiprocessing\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport math\nimport tqdm\nimport time\nimport gzip\nimport io\nimport os\nimport gc\nimport re\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nfrom tqdm.notebook import tqdm\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib; \nimport plotly\nimport PIL\nimport cv2\nimport ast\ntry:\n    import hpacellseg.cellsegmentator as cellsegmentator\n    from hpacellseg.utils import label_cell,label_nuclei\n    import pytorch_zoo\nexcept:\n    !pip install -q \"/kaggle/input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\"\n    !pip install -q \"/kaggle/input/hpapytorchzoozip/pytorch_zoo-master\"\n    import hpacellseg.cellsegmentator as cellsegmentator\n    from hpacellseg.utils import label_cell,label_nuclei\n    import pytorch_zoo\n\nprint(\"\\n\\nIMPORTS COMPLETE\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 要复制到他们那里的","metadata":{}},{"cell_type":"code","source":"# some functions used in segmentation visualization\n\ndef get_blended_image(images): \n    # get rgby images for sample\n\n    # blend rgby images into single array\n    blended_array = np.stack(images[:-1], 2)\n\n    # Create PIL Image\n    blended_image = Image.fromarray( np.uint8(blended_array) )\n    return blended_image\n\n\ndef image_to_arrays(path):  \n    # list of image filters. png -> np.arrays\n    image_arrays = list()\n    for image in path:\n        array = np.asarray(Image.open(image))\n        image_arrays.append(array)\n    image_arrays = np.array(image_arrays)\n    return image_arrays\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/hpa-single-cell-image-classification\"\ntrain = pd.read_csv(os.path.join(DATA_DIR,'train.csv'))\ncolours = ['_red.png', '_blue.png', '_yellow.png', '_green.png']\nTRAIN = '../input/hpa-single-cell-image-classification/train'\npaths = [[os.path.join(TRAIN, train.iloc[idx,0])+ colour for colour in colours] for idx in range(len(train))]\n\ntitles = ['microtubules', 'nuclei', 'endoplasmic reticulum', 'protein of interest']\nfig, axs = plt.subplots(2, 4, figsize =(16,8))\nfor entry in range(2):\n    for channel in range(4):\n        img = plt.imread(paths[entry][channel])\n        axs[entry, channel].imshow(img)\n        axs[entry, channel].set_xticks([])\n        axs[entry, channel].set_yticks([])\n        if entry == 0:\n            axs[0, channel].set_title(titles[channel])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUC_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth'\nCELL_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth'\nsegmentator = cellsegmentator.CellSegmentator(\n    NUC_MODEL,\n    CELL_MODEL,\n    scale_factor=0.25,\n    device=\"cuda\",\n    padding=False,\n    multi_channel_model=True,\n)\nimage_path = paths[10]   # shape:(21806, 4). 4 channels, rgby\narrays = image_to_arrays(image_path)  # shape: (4, 2048, 2048)\nnuclei = arrays[1]\ncell = arrays[:-1]\nprint('image shape:',arrays.shape)\nprint('nuclei shape:',nuclei.shape)\nprint('cell shape:',cell.shape)\n\n\n# Nuclei segmentation\nnuc_segmentations = segmentator.pred_nuclei([nuclei])\n\nf, ax = plt.subplots(1, 2, figsize=(8,8))\nax[0].imshow(arrays[1])\nax[0].set_title('Original Nucleis', size=10)\nax[0].set_xticks([])\nax[0].set_yticks([])\nax[1].imshow(nuc_segmentations[0])\nax[1].set_title('Segmented Nucleis', size=10)\nplt.axis('off')\nplt.show()\n\n# Cell segmentation\ninter_step = [[i] for i in image_path[:-1]]\ncell_segmentations = segmentator.pred_cells(inter_step)\n\nf, ax = plt.subplots(1, 2, figsize=(8,8))\nax[0].imshow(get_blended_image(arrays))\nax[0].set_title('Original Cells')\nax[0].set_xticks([])\nax[0].set_yticks([])\nax[1].imshow(cell_segmentations[0])\nax[1].set_title('Segmented Cells')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nuclei mask\nnuclei_mask = label_nuclei(nuc_segmentations[0])\n# Cell masks\ncell_nuclei_mask, cell_mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n# Plotting\nf, ax = plt.subplots(1, 3, figsize=(12,12))\nax[0].imshow(nuclei_mask)\nax[0].set_title('Nuclei Mask')\nax[0].set_xticks([])\nax[0].set_yticks([])\nax[1].imshow(cell_nuclei_mask)\nax[1].set_title('Cell Nuclei Mask')\nax[1].set_xticks([])\nax[1].set_yticks([])\nax[2].imshow(cell_mask)\nax[2].set_title('Cell Mask')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# segment cells\n\n# Unique vector of cell_mask numbers\nnumbers = set(np.ravel(cell_mask))\nnumbers.remove(0)\n\nplt.figure()\nplt.title(\"Complete Cell Mask\")\nplt.imshow(cell_mask)\nplt.axis('off')\n\n\n# show several segments for visulazation\n\nfig = plt.figure(figsize=(16,16))\nindex = 1\nfor number in numbers:\n    number = number*4\n    isolated_cell = np.where(cell_mask==number, cell_mask, 0)\n    ax = fig.add_subplot(1, 5, index)\n    ax.set_title(\"Segment\"+str(number))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    plt.imshow(isolated_cell)\n    index += 1\n    if index == 6:\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## training dataset generalization","metadata":{}},{"cell_type":"code","source":"# ROOT_DIR = \"/kaggle/input\"\nDATA_DIR = \"/kaggle/input/hpa-single-cell-image-classification\"\n# COMP_DIR = os.path.join(ROOT_DIR, \"hpa-single-cell-image-classification\")\n# PKL_DIR = os.path.join(ROOT_DIR, \"hpa-rule-based-single-cell-filtering\")\n# # paths of the training tiles \n# RED_TILE_DIR = os.path.join(ROOT_DIR, \"human-protein-atlas-red-cell-tile-dataset\")\n# GREEN_TILE_DIR = os.path.join(ROOT_DIR, \"human-protein-atlas-green-cell-tile-dataset\")\n# BLUE_TILE_DIR = os.path.join(ROOT_DIR, \"human-protein-atlas-blue-cell-tile-dataset\")\n# YELLOW_TILE_DIR = os.path.join(ROOT_DIR, \"human-protein-atlas-yellow-cell-tile-dataset\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the paths to the training and testing tfrecord and image folders respectively\nTRAIN_IMG_DIR = os.path.join(DATA_DIR, \"train\")\nTRAIN_TFREC_DIR = os.path.join(DATA_DIR, \"train_tfrecords\")\nTEST_IMG_DIR = os.path.join(DATA_DIR, \"test\")\nTEST_TFREC_DIR = os.path.join(DATA_DIR, \"test_tfrecords\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LBL_NAMES = [\"Nucleoplasm\", \"Nuclear Membrane\", \"Nucleoli\", \"Nucleoli Fibrillar Center\", \"Nuclear Speckles\", \"Nuclear Bodies\", \"Endoplasmic Reticulum\", \"Golgi Apparatus\", \"Intermediate Filaments\", \"Actin Filaments\", \"Microtubules\", \"Mitotic Spindle\", \"Centrosome\", \"Plasma Membrane\", \"Mitochondria\", \"Aggresome\", \"Cytosol\", \"Vesicles\", \"Negative\"]\n# INT_2_STR = {x:LBL_NAMES[x] for x in np.arange(19)}\n# INT_2_STR_LOWER = {k:v.lower().replace(\" \", \"_\") for k,v in INT_2_STR.items()}\n# STR_2_INT_LOWER = {v:k for k,v in INT_2_STR_LOWER.items()}\n# STR_2_INT = {v:k for k,v in INT_2_STR.items()}\n# FIG_FONT = dict(family=\"Helvetica, Arial\", size=14, color=\"#7f7f7f\")\n# LABEL_COLORS = [px.colors.label_rgb(px.colors.convert_to_RGB_255(x)) for x in sns.color_palette(\"Spectral\", len(LBL_NAMES))]\n# LABEL_COL_MAP = {str(i):x for i,x in enumerate(LABEL_COLORS)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TILE_DIRS = [RED_TILE_DIR, GREEN_TILE_DIR, BLUE_TILE_DIR, YELLOW_TILE_DIR]\n# # Define the paths to the training files for the tile dataset as a map from class index to list of paths\n# RED_FILE_MAP, GREEN_FILE_MAP, BLUE_FILE_MAP, YELLOW_FILE_MAP = get_color_path_maps(TILE_DIRS, None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## helper function里的 有的话不用加\n\ndef load_image(img_id, img_dir):\n    \"\"\" Load An Image Using ID and Directory Path - Composes 4 Individual Images \"\"\"\n    rgby = [\n        np.asarray(Image.open(os.path.join(img_dir, img_id+f\"_{c}.png\")), np.uint8) \\\n        for c in [\"red\", \"green\", \"blue\", \"yellow\"]\n    ]\n    return np.stack(rgby, axis=-1)\n\n\ndef plot_rgb(arr, figsize=(12,12)):\n    \"\"\" Plot 3 Channel Microscopy Image \"\"\"\n    plt.figure(figsize=figsize)\n    plt.title(f\"RGB Composite Image\", fontweight=\"bold\")\n    plt.imshow(arr)\n    plt.axis(False)\n    plt.show()\n    \n    \ndef get_color_path_map(color_dir):\n    c_p_map = {}\n    for c in tqdm(os.listdir(color_dir), total=len(os.listdir(color_dir))):\n        if c.endswith(\"256\"):\n            cls = c.split(\"_\", 1)[1].rsplit(\"_\",1)[0]\n            c_dir = os.path.join(color_dir, c, \"data\", \"train_tiles\", cls)\n            c_p_map[STR_2_INT_LOWER[cls]] = sorted([\n                os.path.join(c_dir, f_name) \\\n                for f_name in  os.listdir(c_dir) \\\n                if f_name.endswith(\".png\")\n            ])\n    return c_p_map\n\n\ndef plot_ex(arr, figsize=(20,6), title=None, plot_merged=True, rgb_only=False):\n    \"\"\" Plot 4 Channels Side by Side \"\"\"\n    if plot_merged and not rgb_only:\n        n_images=5 \n    elif plot_merged and rgb_only:\n        n_images=4\n    elif not plot_merged and rgb_only:\n        n_images=4\n    else:\n        n_images=3\n    plt.figure(figsize=figsize)\n    if type(title) == str:\n        plt.suptitle(title, fontsize=20, fontweight=\"bold\")\n\n    for i, c in enumerate([\"Red Channel – Microtubles\", \"Green Channel – Protein of Interest\", \"Blue - Nucleus\", \"Yellow – Endoplasmic Reticulum\"]):\n        if not rgb_only:\n            ch_arr = np.zeros_like(arr[..., :-1])        \n        else:\n            ch_arr = np.zeros_like(arr)\n        if c in [\"Red Channel – Microtubles\", \"Green Channel – Protein of Interest\", \"Blue - Nucleus\"]:\n            ch_arr[..., i] = arr[..., i]\n        else:\n            if rgb_only:\n                continue\n            ch_arr[..., 0] = arr[..., i]\n            ch_arr[..., 1] = arr[..., i]\n        plt.subplot(1,n_images,i+1)\n        plt.title(f\"{c.title()}\", fontweight=\"bold\")\n        plt.imshow(ch_arr)\n        plt.axis(False)\n        \n    if plot_merged:\n        plt.subplot(1,n_images,n_images)\n        \n        if rgb_only:\n            plt.title(f\"Merged RGB\", fontweight=\"bold\")\n            plt.imshow(arr)\n        else:\n            plt.title(f\"Merged RGBY into RGB\", fontweight=\"bold\")\n            plt.imshow(convert_rgby_to_rgb(arr))\n        plt.axis(False)\n        \n    plt.tight_layout(rect=[0, 0.2, 1, 0.97])\n    plt.show()\n    \n    \n# def flatten_list_of_lists(l_o_l, to_string=False):\n#     if not to_string:\n#         return [item for sublist in l_o_l for item in sublist]\n#     else:\n#         return [str(item) for sublist in l_o_l for item in sublist]\n\n    \n    \ndef grab_contours(cnts):\n    # if the length the contours tuple returned by cv2.findContours\n    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n    # v4-official\n    if len(cnts) == 2:\n        cnts = cnts[0]\n\n    # if the length of the contours tuple is '3' then we are using\n    # either OpenCV v3, v4-pre, or v4-alpha\n    elif len(cnts) == 3:\n        cnts = cnts[1]\n\n    # otherwise OpenCV has changed their cv2.findContours return\n    # signature yet again and I have no idea WTH is going on\n    else:\n        raise Exception((\"Contours tuple must have length 2 or 3, \"\n            \"otherwise OpenCV changed their cv2.findContours return \"\n            \"signature yet again. Refer to OpenCV's documentation \"\n            \"in that case\"))\n\n    # return the actual contours array\n    return cnts\n\n    \ndef convert_rgby_to_rgb(arr):\n    \"\"\" Convert a 4 channel (RGBY) image to a 3 channel RGB image.\n    \n    Advice From Competition Host/User: lnhtrang\n\n    For annotation (by experts) and for the model, I guess we agree that individual \n    channels with full range px values are better. \n    In annotation, we toggled the channels. \n    For visualization purpose only, you can try blending the channels. \n    For example, \n        - red = red + yellow\n        - green = green + yellow/2\n        - blue=blue.\n        \n    Args:\n        arr (numpy array): The RGBY, 4 channel numpy array for a given image\n    \n    Returns:\n        RGB Image\n    \"\"\"\n    \n    rgb_arr = np.zeros_like(arr[..., :-1])\n    rgb_arr[..., 0] = arr[..., 0]\n    rgb_arr[..., 1] = arr[..., 1]+arr[..., 3]/2\n    rgb_arr[..., 2] = arr[..., 2]\n    \n    return rgb_arr\n\n# def tif_gzip_to_png(tif_path):\n#     \"\"\"Function to convert .tif.gz to .png and put it in the same folder\n    \n#     Eg. for working in local work station\n    \n#     Args:\n#         tif_path (str): Path to the tif zip file to be converted to png\n        \n#     Returns:\n#         None; Zip will be unzipped to same directory as .tif zip exists    \n#     \"\"\"\n    \n#     png_path = pathlib.Path(tif_path.replace('.tif.gz','.png'))\n#     tf = gzip.open(tif_path).read()\n#     img = imageio.imread(tf, 'tiff')\n#     imageio.imwrite(png_path, img)\n    \n    \n# def download_and_convert_tifgzip_to_png(url, target_path):    \n#     \"\"\"Function to convert .tif.gz to .png and put it in the same folder\n    \n#     Args:\n#         url (str): Path to the url containing the tifgzip file\n#         target_path (str): Path to directory to unzip to\n        \n#     Returns:\n#         None; Images are downloaded and unzipped    \n#     \"\"\"\n    \n#     r = requests.get(url)\n#     f = io.BytesIO(r.content)\n#     tf = gzip.open(f).read()\n#     img = imageio.imread(tf, 'tiff')\n#     imageio.imwrite(target_path, img)\n\n    \n# def get_new_data():\n#     public_hpa_df = pd.read_csv('../input/publichpa/kaggle_2021.tsv',sep='\\t',header=None)\n#     public_hpa_df.columns = ['Image', 'Label']\n#     colors = ['blue', 'red', 'green', 'yellow']\n#     save_dir = os.path.join(os.getcwd(),'publichpa')\n#     if not os.path.exists(save_dir):\n#         os.makedirs(save_dir)\n\n#     for i, row in public_hpa_df.iterrows():\n#         try:\n#             img = row.Image\n#             for color in colors:\n#                 img_url = f'{img}_{color}.tif.gz'\n#                 save_path = os.path.join(save_dir,  f'{os.path.basename(img)}_{color}.png')\n#                 download_and_convert_tifgzip_to_png(img_url, save_path)\n#                 print(f'Downloaded {img_url} as {save_path}')    \n#         except:\n#             print(f'failed to download: {img}')\n#     return save_dir\n\n# def seg_demo_plot(mt, er, nu):\n#     fig, ax = plt.subplots(3,3, figsize=(20,18))\n#     for i in range(3):\n#         microtubule = plt.imread(mt[i])    \n#         endoplasmicrec = plt.imread(er[i])    \n#         nuclei = plt.imread(nu[i])\n#         mask = plt.imread(mt[i].replace('red','predictedmask'))\n#         img = np.dstack((microtubule, endoplasmicrec, nuclei))\n#         ax[0][i].imshow(img)\n#         ax[1][i].imshow(mask)\n#         ax[2][i].imshow(img)\n#         ax[2][i].imshow(mask, alpha=0.5)\n\n#         ax[0][i].axis('off')\n#         ax[1][i].axis('off')\n#         ax[2][i].axis('off')\n#     plt.tight_layout()\n#     plt.show()\n    \n    \n# def multihot_melt(row):\n#     \"\"\" Melt current column into 19 binary-1-hot columns \"\"\"\n#     return [1 if L in row[\"target_list\"] else 0 for L in LBL_NAMES]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation","metadata":{}},{"cell_type":"code","source":"def encode_binary_mask(mask, mask_val=1):\n    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n    mask = np.where(mask==mask_val, 1, 0)\n    \n    # check input mask --\n    if mask.dtype != np.bool:\n        raise ValueError(f\"encode_binary_mask expects a binary mask, received dtype == {mask.dtype}\")\n\n    mask = np.squeeze(mask)\n    if len(mask.shape) != 2:\n        raise ValueError(f\"encode_binary_mask expects a 2d mask, received shape == {mask.shape}\")\n\n    # convert input mask to expected COCO API input --\n    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n    mask_to_encode = mask_to_encode.astype(np.uint8)\n    mask_to_encode = np.asfortranarray(mask_to_encode)\n\n    # RLE encode mask --\n    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n    # compress and base64 encoding --\n    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n    base64_str = base64.b64encode(binary_str)\n    return base64_str\n\n\ndef rle_encoding(img, mask_val=1):\n    \"\"\"\n    Turns our masks into RLE encoding to easily store them\n    and feed them into models later on\n    https://en.wikipedia.org/wiki/Run-length_encoding\n    \n    Args:\n        img (np.array): Segmentation array\n        mask_val (int): Which value to use to create the RLE\n        \n    Returns:\n        RLE string\n    \n    \"\"\"\n    dots = np.where(img.T.flatten() == mask_val)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n        \n    return ' '.join([str(x) for x in run_lengths])\n\n\ndef rle_to_mask(rle_string, height, width):\n    \"\"\" Convert RLE sttring into a binary mask \n    \n    Args:\n        rle_string (rle_string): Run length encoding containing \n            segmentation mask information\n        height (int): Height of the original image the map comes from\n        width (int): Width of the original image the map comes from\n    \n    Returns:\n        Numpy array of the binary segmentation mask for a given cell\n    \"\"\"\n    rows,cols = height,width\n    rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n    rle_pairs = np.array(rle_numbers).reshape(-1,2)\n    img = np.zeros(rows*cols,dtype=np.uint8)\n    for index,length in rle_pairs:\n        index -= 1\n        img[index:index+length] = 255\n    img = img.reshape(cols,rows)\n    img = img.T\n    return img\n\n\ndef create_segmentation_maps(list_of_image_lists, batch_size=4):\n    \"\"\" Function to generate segmentation maps using CellSegmentator tool \n    \n    Args:\n        list_of_image_lists (list of lists):\n            - [[micro-tubules(red)], [endoplasmic-reticulum(yellow)], [nucleus(blue)]]\n        batch_size (int): Batch size to use in generating the segmentation masks\n        \n    Returns:\n        List of lists containing RLEs for all the cells in all images\n    \"\"\"\n    \n    all_mask_rles = {}\n    t1 = time.time()\n    NUC_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth'\n    CELL_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth'\n    segmentator = cellsegmentator.CellSegmentator(NUC_MODEL,CELL_MODEL)\n    print(f\"CELL SEGMENTOR CLASS   {time.time()-t1:.2f}\")\n    print()\n    \n    for i in tqdm(range(0, len(list_of_image_lists[0]), batch_size), total=len(list_of_image_lists[0])//batch_size):\n        \n        # Get batch of images\n        sub_images = [img_channel_list[i:i+batch_size] for img_channel_list in list_of_image_lists]\n        # Do segmentation\n        \n        t1 = time.time()\n        cell_segmentations = segmentator.pred_cells(sub_images)\n        nuc_segmentations = segmentator.pred_nuclei(sub_images[2])\n        print(f\"MODEL PREDICT BATCH {i//batch_size+1}    {time.time()-t1:.2f}\")\n\n        # post-processing\n        for j, path in enumerate(sub_images[0]):\n            t1 = time.time()\n            img_id = path.replace(\"_red.png\", \"\").rsplit(\"/\", 1)[1]\n            nuc_mask, cell_mask = label_cell(nuc_segmentations[j], cell_segmentations[j])\n            new_name = os.path.basename(path).replace('red','mask')\n            all_mask_rles[img_id] = [rle_encoding(cell_mask, mask_val=k) for k in range(1, np.max(cell_mask)+1)]\n            print(f\"LABEL CELL BATCH {i+1}-{j+1}    {time.time()-t1:.2f}\", )\n        print()\n    return all_mask_rles\n    \n\ndef get_img_list(img_dir, return_ids=False, sub_n=1):\n    \"\"\" Get image list in the format expected by the CellSegmentator tool \"\"\"\n    if sub_n is None:\n        sub_n=len(glob(img_dir + '/' + f'*_red.png'))\n    if return_ids:\n        images = [sorted(glob(img_dir + '/' + f'*_{c}.png'))[:sub_n] for c in [\"red\", \"yellow\", \"blue\"]]\n        return [x.replace(\"_red.png\", \"\").rsplit(\"/\", 1)[1] for x in images[0]], images\n    else:\n        return [sorted(glob(img_dir + '/' + f'*_{c}.png'))[:sub_n] for c in [\"red\", \"yellow\", \"blue\"]]\n    \n    \n    \ndef get_contour_bbox(rle, width, height):\n    \"\"\" Get bbox of contour as `xmin ymin xmax ymax`\n    \n    Args:\n        rle (rle_string): Run length encoding containing \n            segmentation mask information\n        height (int): Height of the original image the map comes from\n        width (int): Width of the original image the map comes from\n    \n    Returns:\n        Numpy array for a cell bounding box coordinates\n    \"\"\"\n    \n    cnts = grab_contours(\n        cv2.findContours(\n            rle_to_mask(rle, height, width).copy(), \n            cv2.RETR_EXTERNAL, \n            cv2.CHAIN_APPROX_SIMPLE\n        ))\n    x,y,w,h = cv2.boundingRect(cnts[0])\n    return x,y,x+w,y+h\n\n\ndef pad_to_square(a):\n    \"\"\" Pad an array `a` evenly until it is a square \"\"\"\n    if a.shape[1]>a.shape[0]: # pad height\n        n_to_add = a.shape[1]-a.shape[0]\n        top_pad = n_to_add//2\n        bottom_pad = n_to_add-top_pad\n        a = np.pad(a, [(top_pad, bottom_pad), (0, 0), (0, 0)], mode='constant')\n\n    elif a.shape[0]>a.shape[1]: # pad width\n        n_to_add = a.shape[0]-a.shape[1]\n        left_pad = n_to_add//2\n        right_pad = n_to_add-left_pad\n        a = np.pad(a, [(0, 0), (left_pad, right_pad), (0, 0)], mode='constant')\n    else:\n        pass\n    return a\n\n\ndef cut_out_cells(rgby, rles, resize_to=(224,224), square_off=True):\n    \"\"\" Cut out the cells as padded square images \n    \n    Args:\n        rgby (np.array): 4 Channel image to be cut into tiles\n        rles (list of RLE strings): List of run length encoding containing \n            segmentation mask information\n        resize_to (tuple of ints, optional): The square dimension to resize the image to\n        square_off (bool, optional): Whether to pad the image to a square or not\n        \n    Returns:\n        list of square arrays representing squared off cell images\n    \"\"\"\n    w,h = rgby.shape[:2]\n    contour_bboxes = [get_contour_bbox(rle, w, h) for rle in rles]\n    arrs = [rgby[bbox[1]:bbox[3], bbox[0]:bbox[2], :] for bbox in contour_bboxes]\n    if square_off:\n        arrs = [pad_to_square(arr) for arr in arrs]\n        \n    if resize_to is not None:\n        arrs = [cv2.resize(pad_to_square(arr), resize_to, interpolation=cv2.INTER_CUBIC) for arr in arrs]\n    \n    return arrs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 新函数 记得加进 helper functions\ndef plot_rgby(arr, figsize=(20,6), title=None, plot_merged=False):\n    \"\"\" Plot 4 Channels Side by Side \"\"\"\n    if plot_merged:\n        n_images=5 \n    else:\n        n_images=4\n    plt.figure(figsize=figsize)\n    if type(title) == str:\n        plt.suptitle(title)\n\n    for i, c in enumerate([\"Microtubles\", \"Protein of Interest\", \"Nucleus\", \"Endoplasmic Reticulum\"]):\n        ch_arr = np.zeros_like(arr[..., :-1])        \n        if c in [\"Microtubles\", \"Protein of Interest\", \"Nucleus\"]:\n            ch_arr[..., i] = arr[..., i]\n        else:\n            ch_arr[..., 0] = arr[..., i]\n            ch_arr[..., 1] = arr[..., i]\n        plt.subplot(1,n_images,i+1)\n        plt.title(f\"{c.title()}\")\n        plt.imshow(ch_arr)\n        plt.axis(False)\n        \n    if plot_merged:\n        plt.subplot(1,n_images,n_images)\n        plt.title(f\"Merged RGBY into RGB\", fontweight=\"bold\")\n        plt.imshow(convert_rgby_to_rgb(arr))\n        plt.axis(False)\n        \n    plt.tight_layout(rect=[0, 0.2, 1, 0.97])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## raw data --> segment -> box -> rle\n\n\ntesting_ids, testing_images = get_img_list(TRAIN_IMG_DIR, return_ids=True, sub_n=2)\ntesting_masks = create_segmentation_maps(testing_images, 2)\n\ntesting_id_1 = testing_ids[1]\ntesting_img_1 = load_image(testing_id_1, TRAIN_IMG_DIR)\ntesting_mask_1 = testing_masks[testing_id_1]\ncell_boxes = cut_out_cells(testing_img_1, testing_mask_1)\n\nprint(\"\\n ———— Original Image———— \\n\")\nplot_ex(testing_img_1)\n\nprint(\"\\n ———— The first 5 segmented cells from one images ———— \\n\")\n    \nfor b in cell_boxes:\n    plot_rgby(b, title=\" \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for b in cell_boxes:\n    plot_rgby(b, title=\"MY METHOD\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## for test 的路径","metadata":{}},{"cell_type":"code","source":"output_DIR = \"/kaggle/working/train_SegmentedCells\"\n\nif not os.path.isdir(output_DIR):\n    os.makedirs(output_DIR,exist_ok=True)\n\nred_DIR = os.path.join(output_DIR, \"red\")\nblue_DIR = os.path.join(output_DIR, \"blue\")\nyellow_DIR = os.path.join(output_DIR, \"yellow\")\ngreen_DIR = os.path.join(output_DIR, \"green\")\n\nDIRs = [red_DIR, blue_DIR,yellow_DIR,green_DIR]\nfor DIR in DIRs:\n    if not os.path.isdir(DIR):\n        os.makedirs(DIR,exist_ok=True)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nred = Image.fromarray(cell_boxes[0])\nred.save(\"/kaggle/working/1\",\"png\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\noutput_DIR = \"/kaggle/working/train_SegmentedCells\"\n\nred_DIR = os.path.join(output_DIR, \"red\")\nblue_DIR = os.path.join(output_DIR, \"blue\")\nyellow_DIR = os.path.join(output_DIR, \"yellow\")\ngreen_DIR = os.path.join(output_DIR, \"green\")\n\nDIRs = [red_DIR, blue_DIR,yellow_DIR,green_DIR]\nfor DIR in DIRs:\n    if not os.path.exists(DIR):\n        os.makedirs(DIR)\n        \nfor b in cell_boxes:\n    plot_rgby(b, title=\"MY METHOD\")\n\ntesting_ids, testing_images = get_img_list(TRAIN_IMG_DIR, return_ids=True, sub_n=2)\ntesting_masks = create_segmentation_maps(testing_images, 2)\n\ntesting_id_1 = testing_ids[1]\ntesting_img_1 = load_image(testing_id_1, TRAIN_IMG_DIR)\ntesting_mask_1 = testing_masks[testing_id_1]\ncell_boxes = cut_out_cells(testing_img_1, testing_mask_1，resize_to=(224,224))\n\n# 复制get_img_list过来 方便看它怎么运行的\ndef get_img_list(img_dir, return_ids=False, sub_n=1):\n    \"\"\" Get image list in the format expected by the CellSegmentator tool \"\"\"\n    if sub_n is None:\n        sub_n=len(glob(img_dir + '/' + f'*_red.png'))\n    if return_ids:\n        images = [sorted(glob(img_dir + '/' + f'*_{c}.png'))[:sub_n] for c in [\"red\", \"yellow\", \"blue\"]]\n        return [x.replace(\"_red.png\", \"\").rsplit(\"/\", 1)[1] for x in images[0]], images\n    else:\n        return [sorted(glob(img_dir + '/' + f'*_{c}.png'))[:sub_n] for c in [\"red\", \"yellow\", \"blue\"]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 没什么用 用来看数据结构的\nprint(np.array(testing_ids).shape)\nprint(np.array(testing_images).shape)\nprint(TRAIN_IMG_DIR)\nsub_n=len(glob(TRAIN_IMG_DIR + '/' + f'*_red.png'))\nprint(sub_n)  # 21806 red pictures\nprint('id: ', testing_id_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_IDs, train_images_ryb = get_img_list(TRAIN_IMG_DIR, return_ids=True, sub_n=2)\ntrain_masks = create_segmentation_maps(train_images_ryb, 2)\ntrain_img_rgby = load_image(train_IDs, TRAIN_IMG_DIR)\n\ncell_boxes = cut_out_cells(train_img_rgby, train_masks，resize_to=(224,224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}