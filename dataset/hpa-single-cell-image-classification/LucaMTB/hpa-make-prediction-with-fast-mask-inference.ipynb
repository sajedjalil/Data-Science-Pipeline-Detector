{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math, re, os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\nimport glob\nprint(\"Tensorflow version \" + tf.__version__)\nimport cv2\nfrom cv2 import cvtColor\n#from PIL import Image\nimport numpy.ma as ma\nimport time\nfrom skimage.transform import resize\n\n\nimport tensorflow_addons as tfa\n\n\n\n# Initialization\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Acknowledgment\n\n\nThis notebook was inspiried by \n\nhttps://www.kaggle.com/h053473666/0-354-efnb7-classification-weights-0-4-0-6\n\nhttps://www.kaggle.com/thedrcat/fastai-quick-submission-template\n\nhttps://www.kaggle.com/linshokaku/faster-hpa-cell-segmentation\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.7\nsession = InteractiveSession(config=config)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IM_SIZE = 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"specified_class_names = \"\"\"0. Nucleoplasm\n1. Nuclear membrane\n2. Nucleoli\n3. Nucleoli fibrillar center\n4. Nuclear speckles\n5. Nuclear bodies\n6. Endoplasmic reticulum\n7. Golgi apparatus\n8. Intermediate filaments\n9. Actin filaments \n10. Microtubules\n11. Mitotic spindle\n12. Centrosome\n13. Plasma membrane\n14. Mitochondria\n15. Aggresome\n16. Cytosol\n17. Vesicles and punctate cytosolic patterns\n18. Negative\"\"\"\n\nclass_names = [class_name.split('. ')[1] for class_name in specified_class_names.split('\\n')]\nclass_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(class_names) +1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imlist = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nif len(df_imlist) == 559:\n    debug = True\n    df_imlist = df_imlist[:3]\nelse:\n    debug = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def blend2_image(image):\n    \n    directory = '../input/hpa-single-cell-image-classification/test/'\n    \n    \n    \n    blue_image = cv2.imread(directory+image + '_blue' + '.png', cv2.IMREAD_GRAYSCALE )#.resize((size,size))\n    red_image = cv2.imread(directory+image + '_red' + '.png', cv2.IMREAD_GRAYSCALE )#.resize((size,size))\n\n    #green_image = Image.open(directory+image + '_green' + '.png' )#.resize((size,size))\n    \n    green_image = cv2.imread(directory+image + '_green' + '.png', cv2.IMREAD_GRAYSCALE)\n\n\n    \n    ## Convert red \n    \n    bild_array_red = np.asarray(red_image)\n    bild_array_red = np.require(bild_array_red, dtype='f4', requirements=['O', 'W'])\n    bild_array_red.flags['WRITEABLE'] = True\n    bild_array_red /= 255\n\n    \n    ## Convert blue\n    \n    bild_array_blue = np.asarray(blue_image)\n    \n    bild_array_blue = np.require(bild_array_blue, dtype='f4', requirements=['O', 'W'])\n    bild_array_blue.flags['WRITEABLE'] = True\n    \n    bild_array_blue /= 255\n\n      \n    bild_array_green = np.asarray(green_image)\n    \n    bild_array_green = np.require(bild_array_green, dtype='f4', requirements=['O', 'W'])\n    bild_array_green.flags['WRITEABLE'] = True\n    \n    bild_array_green /= 255\n\n\n    blend = np.stack((bild_array_red, bild_array_green, bild_array_blue), axis=-1)\n    #blend = np.stack((bild_array_blue, bild_array_green, bild_array_red), axis=-1) # lie picture\n\n    \n    return blend","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#directory = '../input/hpa-single-cell-image-classification/test/'\n\n#blue_image = Image.open(directory+'6220622a-b7e6-47c7-bdfa-2dfe650771b2' + '_green' + '.png' )\n\n\n\n#blue_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(30,30),constrained_layout = True)\n\nplt.imshow(blend2_image('d48f8a42-d427-45d4-a0fd-ce119ba654a7'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cropped_resized_cell(img):\n    #bmask = msk.astype(int)[...,None]\n    #masked_img = img * bmask\n    true_points = np.argwhere(img)\n    top_left = true_points.min(axis=0)\n    bottom_right = true_points.max(axis=0)\n    cropped_arr = img[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1]\n    cropped_arr = cv2.resize(cropped_arr,(IM_SIZE,IM_SIZE))\n    return cropped_arr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bild = blend2_image('d48f8a42-d427-45d4-a0fd-ce119ba654a7')\n\nbild = get_cropped_resized_cell(bild)\n\nplt.imshow(bild)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def macro_f1(y, y_hat, thresh=0.5):\n    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n    \n    Args:\n        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n        thresh: probability value above which we predict positive\n        \n    Returns:\n        macro_f1 (scalar Tensor): value of macro F1 for the batch\n    \"\"\"\n    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    macro_f1 = tf.reduce_mean(f1)\n    return macro_f1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cell level Models","metadata":{}},{"cell_type":"code","source":"models = []\n\n\n\nmodel = keras.models.load_model('../input/multieffe0-rs10-6e/HPA_model_effect0_RS10_6mcepoch.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout, \"macro_f1\" : macro_f1})\nmodel1 = keras.models.load_model('../input/multieff0-rs11/HPA_model_effect0_RS11_6mcepoch.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout, \"macro_f1\" : macro_f1})\nmodel2 = keras.models.load_model('../input/multidense/HPA_model_effect0_RS11_6mcepoch.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout, \"macro_f1\" : macro_f1})\nmodel3 = keras.models.load_model('../input/pubdensenet/HPA_model_dense121_RS14_15mcepoch.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout, \"macro_f1\" : macro_f1})\n#model4 = keras.models.load_model('../input/modeleffect/HPA_model_eff3_RS35.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})\n#model5 = keras.models.load_model('../input/dense121-rs65/HPA_model_dens121_RS65.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})\n#model6 = keras.models.load_model('../input/pubdens121-rs4-6epoch/HPA_model_den121_RS4_6epoch.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})\n#model7 = keras.models.load_model('../input/pubeffe3rs2/HPA_model_eff3_RS2_pubda.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})\n#model8 = keras.models.load_model('../input/pubdensrs0/HPA_model_dens121_RS0_5epoch.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})\n#model9 = keras.models.load_model('../input/pub-effec-rs8-8epoch/HPA_model_effect_RS8_8epoch.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})\n#model10 = keras.models.load_model('../input/pubeff0rs95ep/HPA_model_effect0_RS9_5epoch.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout})\n\n\nmodels.append(model)\nmodels.append(model1)\nmodels.append(model2)\nmodels.append(model3)\n#models.append(model4)\n#models.append(model5)\n#models.append(model6)\n#models.append(model7)\n#models.append(model8)\n#models.append(model9)\n#models.append(model10)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#enumerate(model.predict(img)[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#liste = sum([model.predict(img)[0] for model in models]) / len(models)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#liste","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/pycocotools/pycocotools-2.0.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import base64\nimport numpy as np\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport zlib\n\n\ndef encode_binary_mask(mask: np.ndarray) -> t.Text:\n    \n    \n    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n    \n  # check input mask --\n    if mask.dtype != np.bool:\n        raise ValueError(\n        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n        mask.dtype)\n\n    mask = np.squeeze(mask)\n    if len(mask.shape) != 2:\n        raise ValueError(\n        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n        mask.shape)\n\n  # convert input mask to expected COCO API input --\n    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n    mask_to_encode = mask_to_encode.astype(np.uint8)\n    mask_to_encode = np.asfortranarray(mask_to_encode)\n\n  # RLE encode mask --\n    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n  # compress and base64 encoding --\n    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n    base64_str = base64.b64encode(binary_str)\n    return base64_str","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\n#!pip install \"../input/hpacellsegmentatorraman/HPA-Cell-Segmentation/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/hpapytorchzoozip/pytorch_zoo-master/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install ../input/pycocotools/pycocotools-2.0.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#    plt.imshow(test_mask)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell,label_nuclei","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Faster Cell mask","metadata":{}},{"cell_type":"code","source":"import os.path\nimport urllib\nimport zipfile\n\nimport numpy as np\nimport scipy.ndimage as ndi\nfrom skimage import filters, measure, segmentation\nfrom skimage.morphology import (binary_erosion, closing, disk,\n                                remove_small_holes, remove_small_objects)\n\nHIGH_THRESHOLD = 0.4\nLOW_THRESHOLD = HIGH_THRESHOLD - 0.25\n\n\ndef download_with_url(url_string, file_path, unzip=False):\n    \"\"\"Download file with a link.\"\"\"\n    with urllib.request.urlopen(url_string) as response, open(\n        file_path, \"wb\"\n    ) as out_file:\n        data = response.read()  # a `bytes` object\n        out_file.write(data)\n\n    if unzip:\n        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n            zip_ref.extractall(os.path.dirname(file_path))\n\n\ndef __fill_holes(image):\n    \"\"\"Fill_holes for labelled image, with a unique number.\"\"\"\n    boundaries = segmentation.find_boundaries(image)\n    image = np.multiply(image, np.invert(boundaries))\n    image = ndi.binary_fill_holes(image > 0)\n    image = ndi.label(image)[0]\n    return image\n\n\n\n\n\ndef label_cell2(nuclei_pred, cell_pred):\n    \"\"\"Label the cells and the nuclei.\n    Keyword arguments:\n    nuclei_pred -- a 3D numpy array of a prediction from a nuclei image.\n    cell_pred -- a 3D numpy array of a prediction from a cell image.\n    Returns:\n    A tuple containing:\n    nuclei-label -- A nuclei mask data array.\n    cell-label  -- A cell mask data array.\n    0's in the data arrays indicate background while a continous\n    strech of a specific number indicates the area for a specific\n    cell.\n    The same value in cell mask and nuclei mask refers to the identical cell.\n    NOTE: The nuclei labeling from this function will be sligthly\n    different from the values in :func:`label_nuclei` as this version\n    will use information from the cell-predictions to make better\n    estimates.\n    \"\"\"\n    def __wsh(\n        mask_img,\n        threshold,\n        border_img,\n        seeds,\n        threshold_adjustment=0.35,\n        small_object_size_cutoff=10,\n    ):\n        img_copy = np.copy(mask_img)\n        m = seeds * border_img  # * dt\n        img_copy[m <= threshold + threshold_adjustment] = 0\n        img_copy[m > threshold + threshold_adjustment] = 1\n        img_copy = img_copy.astype(np.bool)\n        img_copy = remove_small_objects(img_copy, small_object_size_cutoff).astype(\n            np.uint8\n        )\n\n        mask_img[mask_img <= threshold] = 0\n        mask_img[mask_img > threshold] = 1\n        mask_img = mask_img.astype(np.bool)\n        mask_img = remove_small_holes(mask_img, 63)\n        mask_img = remove_small_objects(mask_img, 1).astype(np.uint8)\n        markers = ndi.label(img_copy, output=np.uint32)[0]\n        labeled_array = segmentation.watershed(\n            mask_img, markers, mask=mask_img, watershed_line=True\n        )\n        return labeled_array\n\n    nuclei_label = __wsh(\n        nuclei_pred[..., 2] / 255.0,\n        0.4,\n        1 - (nuclei_pred[..., 1] + cell_pred[..., 1]) / 255.0 > 0.05,\n        nuclei_pred[..., 2] / 255,\n        threshold_adjustment=-0.25,\n        small_object_size_cutoff=32,\n    )\n\n    # for hpa_image, to remove the small pseduo nuclei\n    nuclei_label = remove_small_objects(nuclei_label, 157)\n    nuclei_label = measure.label(nuclei_label)\n    # this is to remove the cell borders' signal from cell mask.\n    # could use np.logical_and with some revision, to replace this func.\n    # Tuned for segmentation hpa images\n    threshold_value = max(0.22, filters.threshold_otsu(cell_pred[..., 2] / 255) * 0.5)\n    # exclude the green area first\n    cell_region = np.multiply(\n        cell_pred[..., 2] / 255 > threshold_value,\n        np.invert(np.asarray(cell_pred[..., 1] / 255 > 0.05, dtype=np.int8)),\n    )\n    sk = np.asarray(cell_region, dtype=np.int8)\n    distance = np.clip(cell_pred[..., 2], 255 * threshold_value, cell_pred[..., 2])\n    cell_label = segmentation.watershed(-distance, nuclei_label, mask=sk)\n    cell_label = remove_small_objects(cell_label, 344).astype(np.uint8)\n    selem = disk(2)\n    cell_label = closing(cell_label, selem)\n    cell_label = __fill_holes(cell_label)\n    # this part is to use green channel, and extend cell label to green channel\n    # benefit is to exclude cells clear on border but without nucleus\n    sk = np.asarray(\n        np.add(\n            np.asarray(cell_label > 0, dtype=np.int8),\n            np.asarray(cell_pred[..., 1] / 255 > 0.05, dtype=np.int8),\n        )\n        > 0,\n        dtype=np.int8,\n    )\n    cell_label = segmentation.watershed(-distance, cell_label, mask=sk)\n    cell_label = __fill_holes(cell_label)\n    cell_label = np.asarray(cell_label > 0, dtype=np.uint8)\n    cell_label = measure.label(cell_label)\n    cell_label = remove_small_objects(cell_label, 344) # was 344\n    cell_label = measure.label(cell_label)\n    cell_label = np.asarray(cell_label, dtype=np.uint16)\n    #nuclei_label = np.multiply(cell_label > 0, nuclei_label) > 0\n    #nuclei_label = measure.label(nuclei_label)\n    #nuclei_label = remove_small_objects(nuclei_label, 157)\n    #nuclei_label = np.multiply(cell_label, nuclei_label > 0)\n\n    return cell_label#nuclei_label, cell_label\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predicton(mask,image,j,models,econding):\n    \n    mask = (mask == j).astype(int)[...,None]\n    mask = np.float32(mask)\n    mask=cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n    #image = blend2_image(imageID)\n    result = mask * image\n    result = get_cropped_resized_cell(result)\n    img =  tf.reshape(result, (-1, IM_SIZE, IM_SIZE, 3))\n    liste = sum([model.predict(img) for model in models]) / len(models)\n    #print(liste)\n        \n    return [\"%s\" % i  + ' ' +  p.astype('str') + ' ' + econding  for i,p in enumerate(liste[0])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nNUC_MODEL = \"../input/hpacellsegmodel/nuclei-model.pth\"\nCELL_MODEL = \"../input/hpacellsegmodel/cell-model.pth\"\n\n\n#NUC_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth\"\n#CELL_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth\"\n\nsegmentator = cellsegmentator.CellSegmentator(\n            NUC_MODEL,\n            CELL_MODEL,\n            scale_factor=0.25,\n            device=\"cuda\",\n            padding=True,\n            multi_channel_model=True,\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_mask(cell_mask,i):\n    \n    cell_mask = (cell_mask == i)#.astype(int)[...,None]\n    \n    #return '7'+' 1.0 ' + encode_binary_mask(ma.make_mask(cell_mask)).decode(\"utf-8\")+ ' '\n    #return ' ' + encode_binary_mask(ma.make_mask(cell_mask)).decode(\"utf-8\")+ ' '\n    return encode_binary_mask(cell_mask).decode(\"utf-8\") + ' '\n    \n\n    \n    \ndef pred_str2(imageID,size):\n    \n    \n\n    directory = '../input/hpa-single-cell-image-classification/test/'\n\n\n\n#im_string = '5f1af6b4-bb99-11e8-b2b9-ac1f6b6435d0'\n\n\n  \n\n    images = [\n            [directory+ imageID + '_red.png'],\n            [directory+ imageID + '_yellow.png'],\n            [directory+ imageID + '_blue.png' ]\n        ]\n\n    #blue_batch = cv2.imread(directory+ imageID + '_blue.png', cv2.IMREAD_GRAYSCALE )\n    #blue_batch = np.asarray(blue_batch)\n    \n    #red_batch = cv2.imread(directory+ imageID + '_blue.png', cv2.IMREAD_GRAYSCALE )\n    #red_batch = np.asarray(red_batch)\n        # For nuclei\n        \n    if os.path.isfile('../input/hpa-write-mask/' + imageID + '.npz'):\n        \n        cell_mask = np.load('../input/hpa-write-mask/' + imageID + '.npz')['label']\n    else:\n        nuc_segmentations = segmentator.pred_nuclei(images[2])\n    #nuc_segmentations = segmentator.pred_nuclei(blue_batch)\n\n        # For full cells\n        cell_segmentations = segmentator.pred_cells(images)\n    #cell_segmentations = cellsegmentor.pred_cells(rgb_batch, precombined=True)\n\n\n        cell_mask = label_cell2(cv2.resize(nuc_segmentations[0],(512,512)), cv2.resize(cell_segmentations[0],(512,512)))\n        #cell_mask = resize(cell_mask,(size,size),preserve_range=True)\n        #cell_mask = label_cell3(nuc_segmentations[0], cell_segmentations[0])\n        cell_mask = cv2.resize(cell_mask,(size,size),interpolation=cv2.INTER_NEAREST)\n        \n    \n    \n    \n    #s = [encode_mask(cell_mask,i)  for i in range(1,np.amax(cell_mask)+1)]\n    \n    blend_image = blend2_image(imageID)\n    \n    #s = [encode_mask(cell_mask,i).join([\"%s\" % p[0]  + ' ' +  np.round(p[1],3).astype('str')  for p in enumerate(get_predicton(cell_mask,blend_image,i,model))]) for i in range(1,np.amax(cell_mask)+1)]\n    \n    s = []\n    \n    for i in range(1,np.amax(cell_mask)+1):\n        \n        #mask2 = np.copy(cell_mask)\n        #mask2[mask2 > i] = 0\n        #mask2[mask2 < i] = 0\n        #mask2 = resize(mask2,(size,size))\n        #mask2[mask2 > 0] = 1\n        \n        \n        encoding = encode_mask(cell_mask,i)\n        \n        #liste =  [\"%s\" % p[0]  + ' ' +  p[1].astype('str') + ' ' + encoding \n        #          for p in enumerate(get_predicton(cell_mask,blend_image,i,model))]\n        \n        #output = [i + ' ' + string for i in liste]\n        #output = ''.join(liste)\n        output = ''.join(get_predicton(cell_mask,blend_image,i,models,encoding))\n        s.append(output)\n    #    s.append(''.join(output))\n    \n    #for i in range(1,np.amax(cell_mask)+1):\n   \n    \n    #    test_mask = cell_mask\n    #    test_mask = (test_mask == i).astype(int)[...,None]\n    #    s.append('0'+' 1.0 ' + encode_binary_mask(ma.make_mask(test_mask)).decode(\"utf-8\")+ ' ')\n    return ''.join(s)[:-1]\n\ndef getmask(imageID,size):\n    \n    \n\n    directory = '../input/hpa-single-cell-image-classification/test/'\n\n\n\n#im_string = '5f1af6b4-bb99-11e8-b2b9-ac1f6b6435d0'\n\n\n  \n\n    images = [\n            [directory+ imageID + '_red.png'],\n            [directory+ imageID + '_yellow.png'],\n            [directory+ imageID + '_blue.png' ]\n        ]\n\n    #blue_batch = cv2.imread(directory+ imageID + '_blue.png', cv2.IMREAD_GRAYSCALE )\n    #blue_batch = np.asarray(blue_batch)\n    \n    #red_batch = cv2.imread(directory+ imageID + '_blue.png', cv2.IMREAD_GRAYSCALE )\n    #red_batch = np.asarray(red_batch)\n        # For nuclei\n        \n    if os.path.isfile('../input/hpa-write-mask/' + imageID + '.npz'):\n        \n        cell_mask = np.load('../input/hpa-write-mask/' + imageID + '.npz')['label']\n    else:\n        nuc_segmentations = segmentator.pred_nuclei(images[2])\n    #nuc_segmentations = segmentator.pred_nuclei(blue_batch)\n\n        # For full cells\n        cell_segmentations = segmentator.pred_cells(images)\n    #cell_segmentations = cellsegmentor.pred_cells(rgb_batch, precombined=True)\n\n\n        cell_mask = label_cell2(cv2.resize(nuc_segmentations[0],(512,512)), cv2.resize(cell_segmentations[0],(512,512)))\n        #cell_mask = cell_mask * 10000\n        #cell_mask = cv2.resize(cell_mask,(size,size))\n        #cell_mask = cell_mask / 10000\n        #cell_mask = cell_mask.astype(int)\n        \n        #kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,8))\n        #cell_mask = cv2.morphologyEx(cell_mask, cv2.MORPH_CLOSE, kernel)\n        #cell_mask = remove_small_objects(cell_mask, 1000)\n        #cell_mask = label_cell3(nuc_segmentations[0], cell_segmentations[0])\n        \n    return cell_mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imlist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for i, row in df_imlist.iterrows():\n#    print(np.amax(getmask(row['ID'],row['ImageWidth'])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\ndf_imlist['PredictionString'] =  df_imlist.apply(\n    lambda row: pred_str2(row['ID'],row['ImageWidth']),\n    axis=1\n)\n\n\n\n\nend = time.time()\n\nprint((end - start)/3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imlist['PredictionString'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image level Models","metadata":{}},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n\nif debug:\n    sub_df = sub_df[:3]\nelse:\n    sub_df = sub_df\n\ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n    return strategy\n\n\ndef build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.image.resize(img, target_size)\n\n        return img\n\n    def decode_with_labels(path, label):\n        return decode(path), label\n\n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        return img\n\n    def augment_with_labels(img, label):\n        return augment(img), label\n\n    return augment_with_labels if with_labels else augment\n\n\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n\n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n\n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n\n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n\n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO)\n\n    return dset\n\nCOMPETITION_NAME = \"hpa-single-cell-image-classification\"\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\n\nIMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\n\nload_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n#sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n#sub_df = ss_df.copy()\n\nsub_df = sub_df.drop(sub_df.columns[1:],axis=1)\n\nfor i in range(19):\n    sub_df[f'{i}'] = pd.Series(np.zeros(sub_df.shape[0]))\n\n\ntest_paths = load_dir + \"/test/\" + sub_df['ID'] + '_green.png'\n# Get the multi-labels\nlabel_cols = sub_df.columns[1:]\n\ntest_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[8], IMSIZE[8]))\ndtest = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=True, cache=False,\n    decode_fn=test_decoder\n)\n\nwith strategy.scope():\n    models_full = []\n\n    model_full = tf.keras.models.load_model(\n        '../input/fullimageeff5/HPA_model_effect5_RS10_full.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout,\"macro_f1\" : macro_f1}\n        )\n\n    model_full1 = tf.keras.models.load_model(\n        '../input/fullimageeffe5rs11/HPA_model_effect5_RS11_full.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout,\"macro_f1\" : macro_f1}\n        )\n    \n    model_full2 = tf.keras.models.load_model(\n        '../input/fulldensrs12/HPA_model_effect7_RS12_full.h5',custom_objects={\"FixedDropout\": keras.layers.Dropout,\"macro_f1\" : macro_f1}\n        )\n\n \n    \n    \n    models_full.append(model_full)\n    models_full.append(model_full1)\n    models_full.append(model_full2)\n    #models_full.append(model_full3)\n\n#model.summary()\nsub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models_full]) / len(models_full)\n\nsub_df.head()\n\nss_df = pd.merge(sub_df, df_imlist, on = 'ID', how = 'left')\n\nfor i in range(ss_df.shape[0]):\n    if ss_df.loc[i,'PredictionString'] == '0 1 eNoLCAgIMAEABJkBdQ==':\n        continue\n    a = ss_df.loc[i,'PredictionString']\n    b = a.split()\n    for j in range(int(len(a.split())/3)):\n        for k in range(19):\n            if int(b[0 + 3 * j]) == k:\n\n                c = b[0 + 3 * j + 1]               \n                b[0 + 3 * j + 1] = str(ss_df.loc[i,f'{k}'] * 0.4 + float(c) * 0.6)# * 0.9 + float(c) * 0.1\n\n    ss_df.loc[i,'PredictionString'] = ' '.join(b)\n\nss_df = ss_df[['ID','ImageWidth','ImageHeight','PredictionString']]\nss_df.to_csv('submission.csv',index = False)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imlist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPETITION_NAME = \"hpa-single-cell-image-classification\"\nload_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\nsub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n    #sub_df = ss_df.copy()\n\nsub_df = sub_df.drop(sub_df.columns[1:],axis=1)\nsub_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}