{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### this notebook is part of the documentation on my HPA approach  \n    -> main notebook: https://www.kaggle.com/philipjamessullivan/0-hpa-approach-summary\n\n# 1: make masks, get bboxes, make dataframe\n## GOAL:\nextract the bounding boxes of the individual cells contained in each image  \n\n## RESULTS:\n**dataset name:** \"hpa-data\" (linked to this notebook)  \n---> contains two files;  \n\n**file1 type:** dictionary (pickled)  \n**file1 name:** \"bboxesone.pkl\"  \n**file 1 contents:** all image ids mapped to all bbox coordinates contained  \n\n**file2 type:** dataframe (pickled)   \n**file2 name:** \"hpa-data.pkl  \n**file2 contents:** all image ids mapped to all labels and all bbox coordinates with one row per bbox and one column per value","metadata":{}},{"cell_type":"code","source":"#constants\nIMG_FOLDER_PATH=\"../input/hpa-single-cell-image-classification/train/\"\nCSV_FILE_PATH=\"../input/hpa-single-cell-image-classification/train.csv\"\nMASK_FOLDER_PATH=\"./masks\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load HPA dataset\nimport pandas as pd\nCSV_FILE_PATH=\"../input/hpa-single-cell-image-classification/train.csv\"\nid_labels_array=pd.read_csv(CSV_FILE_PATH)\nid_array=(id_labels_array[\"ID\"]).tolist()\nlabels_dict=id_labels_array.set_index('ID').T.to_dict('list')\nlabels_dict = {num: labels[0] for num, labels in labels_dict.items()}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n#function for cell segmentation\n!pip install https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip\nimport hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell, label_nuclei\nfrom PIL import Image\nimport numpy as np\nNUC_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth\"\nCELL_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth\"\nsegmentator = cellsegmentator.CellSegmentator(\n    NUC_MODEL,\n    CELL_MODEL,\n    scale_factor=0.25,\n    device=\"cpu\", # why not gpu? does not lead to major increase, as the bottleneck is the file loading!\n    padding=False,\n    multi_channel_model=True,\n)\n\n#function to get mask only using supplied img_id\ndef get_mask(img_id):\n    ch_r=Image.open(IMG_FOLDER_PATH+img_id+\"_red.png\")\n    ch_y=Image.open(IMG_FOLDER_PATH+img_id+\"_yellow.png\")\n    ch_b=Image.open(IMG_FOLDER_PATH+img_id+\"_blue.png\")\n    nuc_segmentations = segmentator.pred_nuclei([np.asarray( ch_b )])\n    cell_segmentations = segmentator.pred_cells([\n            [np.asarray( ch_r )],\n            [np.asarray( ch_y )],\n            [np.asarray( ch_b )]\n        ])\n    nuclei_mask, mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n    mask = np.uint8(mask)\n    return mask\n\n#function for bbox creation\ndef get_bboxes(mask):\n    mask_flattened=np.ravel(mask)\n    cell_ids=set(mask_flattened)\n    cell_ids.remove(0)\n    bboxes=list()\n    for cell_id in cell_ids:\n        a = np.where(mask == cell_id)\n        ymin, ymax, xmin, xmax = np.min(a[0]), np.max(a[0]), np.min(a[1]), np.max(a[1])\n        bboxes.append([ymin,ymax,xmin,xmax])\n    return bboxes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this step takes more than the maximum of 9h allowed for a kaggle notebook:\n##SOLUTION1: divide dataset into about 20 pieces and run kaggle notebooks in parallel, one for each part\n##SOLUTION2: download data and compute on local machine\n##  --> PROBLEM WITH SOLUTION 2: kaggle upload of large datasets is very buggy\n\nimport pickle\nfrom tqdm import tqdm\n\nbboxes_dict={}\nfor img_id in tqdm(id_array[:10]):    ###LIMITED TO 10 ONLY FOR DEMONSTRATION\n    mask=get_mask(img_id)\n    bboxes=get_bboxes(mask)\n    bboxes_dict[img_id]=bboxes\n    \nwith open('bboxes_dict.pkl', 'wb') as handle:\n    pickle.dump(bboxes_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(columns=['ID','cell','Label','ymin','ymax','xmin','xmax'])\nfor img_id in bboxes_dict.keys():\n    for i,bbox in enumerate(bboxes_dict[img_id]):\n        df = df.append({'ID': img_id,\n                        'cell':i+1,\n                        'Label': labels_dict[img_id],\n                        'ymin': bbox[0],\n                        'ymax': bbox[1],\n                        'xmin': bbox[2],\n                        'xmax': bbox[3]}, ignore_index=True)\nwith open('hpa_data_df.pkl', 'wb') as handle:\n    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show results\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show results\nbboxes_dict","metadata":{},"execution_count":null,"outputs":[]}]}