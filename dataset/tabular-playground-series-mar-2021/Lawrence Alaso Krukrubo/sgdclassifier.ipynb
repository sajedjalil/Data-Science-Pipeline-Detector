{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport pickle\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[SGD-LINK](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n\n[optuna-searchcv](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.OptunaSearchCV.html#optuna.integration.OptunaSearchCV)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set up dask\n\n!pip install --upgrade --quiet pip\n!pip install --quiet dask-ml\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from dask.distributed import Client\nimport dask.dataframe as dd\nimport joblib\n\nclient = Client(n_workers=4)\nclient","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_interim_df(folder):\n    \n    folder+='/'\n    \n    print('WARNING: Loading Datasets...')\n    \n    names = os.listdir(folder)\n    datas = []\n    \n    for name in names:\n        filename=folder+name\n        data = pickle.load(open(filename, 'rb'))\n        datas.append(data)\n\n    return datas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder='../input/mar-tab-final/'\n\n_, X_val, X_train, y_val = load_interim_df(folder)\n\nprint(f'x_train shape is {X_train.shape}')\nprint(f'x_val shape is {X_val.shape}')\nprint(f'y_val shape is {y_val.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder='../input/test-pkl'\ntest = load_interim_df(folder)[0]\nprint(f'test shape is {test.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder='../input/y-train-mar'\ny_train = load_interim_df(folder)[0]\nprint(f'y_train shape is {y_train.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try: # detect TPUs\n    tpu = None\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept Exception as e: # detect GPUs\n    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, f1_score, log_loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy\n\nimport kerastuner as kt\nimport optuna\nfrom sklearn import linear_model\nfrom sklearn import model_selection\nprint('Imported!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optimizing SGDC with Optuna"},{"metadata":{},"cell_type":"markdown","source":"### Define The objective function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial, xt=X_train, yt=y_train, xv=X_val, yv=y_val):\n    \n    base_params = {\n    'max_iter':2000,\n    'verbose':50,\n    'n_jobs':-1,\n    'random_state':123,\n    'early_stopping': True,\n    'class_weight': 'balanced',\n    'average': True\n    }\n\n    # Define Base Params\n    ###############################################################################################################\n    \n    base_params['loss'] = trial.suggest_categorical(\"loss\", [\"hinge\", 'log', 'modified_huber'])\n    base_params[\"alpha\"] = trial.suggest_float(\"alpha\", 0.0001, 0.01)\n    base_params['learning_rate'] = trial.suggest_categorical(\"learning_rate\", [\"invscaling\", \"constant\", \"optimal\", \"adaptive\"])\n\n    # Define Param for learning-rate\n    ###############################################################################################################\n    \n    if base_params['learning_rate'] != 'optimal':\n        base_params['eta0'] = trial.suggest_float('eta0', 1e-4, 1e-2)\n        if base_params['learning_rate'] == 'invscaling':\n            base_params['power_t'] = trial.suggest_float('power_t', 0.2, 0.8)\n        \n    # Define Param for loss and penalty\n    ###############################################################################################################\n    \n    if base_params['loss'] == 'hinge':\n        base_params['penalty'] = 'l2'\n    else:\n        base_params['penalty'] = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"]) \n        if base_params['penalty'] == 'elasticnet':\n            base_params['l1_ratio'] = trial.suggest_float('l1_ratio', 0.1, 0.6)\n    \n    print()\n    print(base_params)\n    print()\n    \n    with strategy.scope():\n        clf = SGDClassifier(**base_params)\n        with joblib.parallel_backend('dask'):\n            clf.fit(xt, yt)\n            \n    # Make Prediction and Obtain Metric\n    ###############################################################################################################\n    \n    preds = clf.predict(xv)\n    preds = np.rint(preds).astype('int32')\n    \n    f1 = f1_score(yv, preds)\n    \n    return f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    with joblib.parallel_backend('dask'):\n        st=time.time()\n        study = optuna.create_study(direction='maximize')\n        study.optimize(objective, n_trials=1500, show_progress_bar=True)\n        print(\"Number of finished trials: \", len(study.trials))\n        print(\"Best trial:\")\n        trial = study.best_trial\n\n        print(\"  Value: {}\".format(trial.value))\n        print(\"  Params: \")\n        for key, value in trial.params.items():\n            print(\"    {}: {}\".format(key, value))\n        print(f'Process ran for {time.time()-st} secs!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract The best Params"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = trial.params\nbest_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's see the top 10 runs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe from the study.\ndf = study.trials_dataframe()\ndf.sort_values(by='value', ascending=False, inplace=True)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deciding the most ideal Estimators to fit the Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params['early_stopping'] = True\nbest_params['max_iter'] = 20000\nbest_params['verbose'] = int(best_params['max_iter']*0.01)\nbest_params['random_state'] = 123\nbest_params['n_jobs'] = -1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a new model\n\nsgd = SGDClassifier(**best_params)\nsgd.get_params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train on the train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    with joblib.parallel_backend('dask'):\n        st=time.time()\n        sgd.fit(X_train, y_train)\n        print(f'Took {time.time()-st} secs!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract the best iter"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_iter = sgd.n_iter_\nbest_iter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set the best iter and re-instantiate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params['max_iter'] = best_iter\nbest_params['early_stopping'] = False\nbest_params['verbose'] = True\n\n# Reinstantiate the model\nsgd = SGDClassifier(**best_params)\nsgd.get_params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use Kfold cross validation with best params on the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the Kfold strategy\n\nfolds = KFold(n_splits=10, shuffle=True, random_state=231)\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define a class of average folds to train a model with initial best-params"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageFoldsSGDC(object):\n    \n    def __init__(self, folds):\n        self.folds = folds\n        self.models = []\n        \n    def fit(self, X_train, y_train, model=sgd):\n        # create out-of-folds prediction template\n        \n        try:\n            assert isinstance(y_train, pd.Series)\n        except AssertionError:\n            y_train = pd.Series(y_train)\n            \n        oof_preds = np.zeros_like(y_train).reshape(-1,1)\n        \n        self.X_train = X_train\n        self.y_train = y_train\n        \n        for train_idx, val_idx in tqdm(folds.split(X_train)):\n            train_x, val_x = self.X_train.iloc[train_idx], self.X_train.iloc[val_idx]\n            train_y, val_y = self.y_train.iloc[train_idx], self.y_train.iloc[val_idx]\n            \n            model.fit(train_x,\n                      train_y.values.ravel())\n            \n            self.models.append(model)\n            \n            oof_pred = model.predict(val_x).reshape(-1, 1)\n            oof_pred = np.rint(oof_pred).astype('int32')\n            (unique, counts) = np.unique(oof_pred, return_counts=True)\n            print('unique is', unique)\n            \n            oof_preds[val_idx] = oof_pred\n            \n        self.oof_preds = oof_preds\n        \n        \n    def predict(self, X_test):\n        preds = []\n        for model in tqdm(self.models):\n            pred = model.predict(X_test)\n            preds.append(pred)\n        preds = np.mean(preds, axis=0)\n        preds = np.rint(preds).astype('int64')\n        \n        if preds.ndim >= 2:\n            preds = preds.flatten()\n        \n        return preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extend best params with base params\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from itertools import chain\n\n# best_params = dict(chain.from_iterable(d.items() for d in (best_params, base_params)))\n# best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    with joblib.parallel_backend('dask'):\n        st=time.time()\n        model = AverageFoldsSGDC(folds)\n        model.fit(X_train, y_train)\n        print(f'Took {time.time()-st} secs!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let' see the count of zeros and ones"},{"metadata":{"trusted":true},"cell_type":"code","source":"(unique, counts) = np.unique(model.oof_preds, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\nfrequencies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### F1-score"},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_val, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_val, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Disribution Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"def distribution_plot(true, pred, true_name, pred_name, Title):\n    plt.figure(figsize=(5,4), dpi=100)\n    ax1 = sns.distplot(true, hist=False, color='r', label= true_name)\n    ax2 = sns.distplot(pred, hist=False, color='b', label= pred_name, ax=ax1)\n    \n    plt.title(Title)\n    plt.xlabel('Features')\n    plt.ylabel('Target')\n    \n    plt.show()\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true = y_val\npred = pred\ntrue_name = 'Target'\npred_name = 'y_hat'\nTitle = 'Target Vs Predictions Plot: SGDClassifier'\n\ndistribution_plot(true, pred, true_name, pred_name, Title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make a Prediction on Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"if True:\n    prediction = model.predict(test)\n    print('Done!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### See spread of prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"(unique, counts) = np.unique(prediction, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\nfrequencies","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define a Submissions method"},{"metadata":{"trusted":true},"cell_type":"code","source":"if True:\n    def submissions(prediction=prediction):\n        sample['target'] = prediction\n        sample.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Call the submissions method and save the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"if True:\n    submissions()\n    display(pd.read_csv('submission.csv').head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save the Parameter-Search DataFrame for more analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --quiet gs-wrap\nimport gswrap\nimport datetime as dt\nclient = gswrap.Client('vibrant-reach-282320')\nprint('gswrap ready for use!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_to_gcp(df, folder_name, file_name):\n    try:\n        assert file_name.endswith('.csv')\n    except:\n        file_name+='.csv'\n    \n    t = str(dt.datetime.now()).replace(' ', '_').split('.')[0]\n    df.to_csv(file_name, index=False)\n    \n    with strategy.scope():\n        st=time.time()\n        print('Copying files...')\n        client.cp(src=f\"./{file_name}\",\n                  dst=f\"gs://kaggle1980/Kaggle/GridSearch/{folder_name}/{file_name.split('.')[0]}_{t}.csv\",\n                  multithreaded=True)\n        ed=time.time()\n        memory = df.memory_usage().sum()\n        print(f'1 file of size {memory} bytes copied in {ed-st} seconds!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    save_to_gcp(df, 'sgdc', 'sgd_grid')\nexcept Exception as e:\n    print(e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save The model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\n# save the model to disk\ntry:\n    filename = 'sgd_model.sav'\n    pickle.dump(model.models[0], open(filename, 'wb'))\nexcept Exception as e:\n    print(e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save the Best Params"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's create a byte-stream placeholder object named 'xgb_params.pickle'\npickle_holder = open('sgd_params.pickle','wb')\n\n# Now let's dump the 'xgb_params' data into 'xgb_params.pickle'\npickle.dump(best_params, pickle_holder)\n\n# Finally, let's close the connection\npickle_holder.close()\nprint('Done!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}