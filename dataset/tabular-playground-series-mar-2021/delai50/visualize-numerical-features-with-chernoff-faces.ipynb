{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### The other day I was listening to [Linear Digressions podcast](http://lineardigressions.com/) and they were talking about a tool to visualize numerical features called Chernoff faces ([episode](http://lineardigressions.com/episodes/2016/2/29/chernoff-faces-and-minard-maps)). I wanted to give it a try in this dataset just for fun.\n\n### What are Chernoff faces?\n#### Chernoff faces, invented by Herman Chernoff in 1973, display multivariate data in the shape of a human face. The individual parts, such as eyes, ears, mouth and nose represent values of the variables by their shape, size, placement and orientation. The idea behind using faces is that humans easily recognize faces and notice small changes without difficulty. Chernoff faces handle each variable differently. Because the features of the faces vary in perceived importance, the way in which variables are mapped to the features should be carefully chosen (e.g. eye size and eyebrow-slant have been found to carry significant weight) ([paper]( http://www.research.ibm.com/people/c/cjmorris/publications/Chernoff_990402.pdf)). Following is an example for the famous iris dataset ([source](https://archive.ics.uci.edu/ml/datasets/iris)) where features (sepal length, sepal width, petal length, petal width) are presented as Chernoff faces and the colour marks each of the species (i.e. the target: setosa, versicolor, virginica) ([source](https://github.com/antononcube/MathematicaForPrediction/blob/master/MarkdownDocuments/Making-Chernoff-faces-for-data-visualization.md)):\n\n![Chernoff faces](https://camo.githubusercontent.com/ced6cd0923a923aade542c33f9ccc86614049e30ab7c0c1085ee7823752ce858/687474703a2f2f692e696d6775722e636f6d2f7550425a4a75666c2e676966)\n\n#### It can be seen that different species have different characteristic facial features that let their indentification visually very easily.\n#### Let's take a look now at how the Chernoff faces look like for the numerical features of this competition and whether the resultant faces can help to discriminate the target classes in some way."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport os\n\nPATH = \"/kaggle/input/tabular-playground-series-mar-2021/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to draw Chernoff faces (source: https://gist.github.com/dribnet/e26f52f423f0656c1bb8fc6f4e741cc2#file-mpl_cfaces-py)\n\ndef cface(ax, x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18):\n    # x1 = height  of upper face\n    # x2 = overlap of lower face\n    # x3 = half of vertical size of face\n    # x4 = width of upper face\n    # x5 = width of lower face\n    # x6 = length of nose\n    # x7 = vertical position of mouth\n    # x8 = curvature of mouth\n    # x9 = width of mouth\n    # x10 = vertical position of eyes\n    # x11 = separation of eyes\n    # x12 = slant of eyes\n    # x13 = eccentricity of eyes\n    # x14 = size of eyes\n    # x15 = position of pupils\n    # x16 = vertical position of eyebrows\n    # x17 = slant of eyebrows\n    # x18 = size of eyebrows\n    \n    # transform some values so that input between 0,1 yields variety of output\n    x3 = 1.9*(x3-.5)\n    x4 = (x4+.25)\n    x5 = (x5+.2)\n    x6 = .3*(x6+.01)\n    x8 = 5*(x8+.001)\n    x11 /= 5\n    x12 = 2*(x12-.5)\n    x13 += .05\n    x14 += .1\n    x15 = .5*(x15-.5)\n    x16 = .25*x16\n    x17 = .5*(x17-.5)\n    x18 = .5*(x18+.1)\n\n    # top of face, in box with l=-x4, r=x4, t=x1, b=x3\n    e = matplotlib.patches.Ellipse( (0,(x1+x3)/2), 2*x4, (x1-x3), fc='white', edgecolor='black', linewidth=2)\n    # e.set_clip_box(ax.bbox)\n    # e.set_facecolor([0,0,0])\n    ax.add_artist(e)\n\n    # bottom of face, in box with l=-x5, r=x5, b=-x1, t=x2+x3\n    e = matplotlib.patches.Ellipse( (0,(-x1+x2+x3)/2), 2*x5, (x1+x2+x3), fc='white', edgecolor='black', linewidth=2)\n    ax.add_artist(e)\n\n    # cover overlaps\n    e = matplotlib.patches.Ellipse( (0,(x1+x3)/2), 2*x4, (x1-x3), fc='white', edgecolor='black', ec='none')\n    ax.add_artist(e)\n    e = matplotlib.patches.Ellipse( (0,(-x1+x2+x3)/2), 2*x5, (x1+x2+x3), fc='white', edgecolor='black', ec='none')\n    ax.add_artist(e)\n    \n    # draw nose\n    ax.plot([0,0], [-x6/2, x6/2], 'k')\n    \n    # draw mouth\n    p = matplotlib.patches.Arc( (0,-x7+.5/x8), 1/x8, 1/x8, theta1=270-180/np.pi*np.arctan(x8*x9), theta2=270+180/np.pi*np.arctan(x8*x9))\n    ax.add_artist(p)\n    \n    # draw eyes\n    p = matplotlib.patches.Ellipse( (-x11-x14/2,x10), x14, x13*x14, angle=-180/np.pi*x12, facecolor='white', edgecolor='black')\n    ax.add_artist(p)\n    \n    p = matplotlib.patches.Ellipse( (x11+x14/2,x10), x14, x13*x14, angle=180/np.pi*x12, facecolor='white', edgecolor='black')\n    ax.add_artist(p)\n\n    # draw pupils\n    p = matplotlib.patches.Ellipse( (-x11-x14/2-x15*x14/2, x10), .05, .05, facecolor='black')\n    ax.add_artist(p)\n    p = matplotlib.patches.Ellipse( (x11+x14/2-x15*x14/2, x10), .05, .05, facecolor='black')\n    ax.add_artist(p)\n    \n    # draw eyebrows\n    ax.plot([-x11-x14/2-x14*x18/2,-x11-x14/2+x14*x18/2],[x10+x13*x14*(x16+x17),x10+x13*x14*(x16-x17)],'k')\n    ax.plot([x11+x14/2+x14*x18/2,x11+x14/2-x14*x18/2],[x10+x13*x14*(x16+x17),x10+x13*x14*(x16-x17)],'k')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the training data\ndf_train = pd.read_csv(os.path.join(PATH, \"train.csv\"))\nnum_feats = [c for c in df_train.columns if c.startswith(\"cont\")]\ndf_train_num = df_train[num_feats].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The function used to generate the faces must ingest 17 features to plot them as facial features. Here we have only 11 numerical features and, since I didn't want to change the function code, I used constant values for the rest. I chose what I thought are the most distinctive facial features to represent the numerical features of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"cf = np.ones((df_train.shape[0], 17)) * 0.5\n# Fill the columns with the desired facial features with our dataset\ncf[:,[0,1,2,3,5,8,9,10,11,12,15]] = df_train_num\n\n# Split the matrix according to the target value\ncf_ones = cf[df_train[\"target\"]==1, :]\ncf_zeros = cf[df_train[\"target\"]==0, :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's plot some faces at random for each of the classes (background color salmon:0, backgorund color turquoise:1):"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5,10, figsize=(20,10))\n\nfor i in range(5):\n    for j in range(10):\n        if j < 5:\n            cface(ax[i,j], .9, *cf_zeros[np.random.randint(cf_zeros.shape[0]),:])\n            ax[i,j].set_facecolor('xkcd:salmon')\n        else:\n            cface(ax[i,j], .9, *cf_ones[np.random.randint(cf_ones.shape[0]),:])\n            ax[i,j].set_facecolor('xkcd:turquoise')\n        ax[i,j].axis([-1.2, 1.2, -1.2, 1.2])\n        ax[i,j].set_xticks([])\n        ax[i,j].set_yticks([])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### I leave it to you to find the characteristic facial features (if any) of each class!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}