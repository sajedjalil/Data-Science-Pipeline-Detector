{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Binary Classification problem based on real life data\n* We have to predict probabilities and the metric is ROC-AUC\n* This is a sample notebook which gives beginner approach to the data and hyperparameter tuning using Optuna\n\n\nI'm a beginner in this field too, Please give suggestions to improove the score!!\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport optuna\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum().values.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum().values.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No null values!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor i in range(19):\n    le.fit(list(train['cat'+str(i)])+list(test['cat'+str(i)]))\n    train['cat'+str(i)] = le.transform(train['cat'+str(i)])\n    test['cat'+str(i)] = le.transform(test['cat'+str(i)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.iloc[:,1:-1].values\ny = train.iloc[:,-1].values\nX_test = test.iloc[:,1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.15,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lg = LGBMClassifier()\nlg.fit(X_train,y_train)\ny_pred_l = lg.predict_proba(X_dev)[:,1]\nroc_auc_score(y_dev,y_pred_l)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning using Optuna"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fun(trial,data=X,target=y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param = {\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_uniform('subsample', 0,1),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0, 0.1 ),\n        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-5 , 1),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 1, 100),\n        'cat_l2': trial.suggest_int('cat_l2',1,20),\n        'metric': 'auc', \n        'random_state': 13,\n        'n_estimators': 10000,\n        \n    }\n    model = LGBMClassifier(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=200,verbose=False)\n    \n    preds = model.predict_proba(test_x)[:,1]\n    \n    auc = roc_auc_score(test_y, preds)\n    \n    return auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(fun, n_trials=30)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_optimization_histor: shows the scores from all trials as well as the best score so far at each point.\noptuna.visualization.plot_optimization_history(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_parallel_coordinate: interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_slice: shows the evolution of the search. You can see where in the hyperparameter space your search\n# went and which parts of the space were explored more.\noptuna.visualization.plot_slice(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Best Parameters found by Optuna"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = study.best_params\nbest_params['n_estimators'] = 10000\nbest_params['cat_feature'] = [i for i in range(19)]\nbest_params['random_state'] = 13\nbest_params['metric'] = 'auc'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = [col for col in train.columns if col not in ['id','target'] ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.zeros(X_test.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 13 , shuffle = True)\nauc =[]\nn=0\n\nfor tr_idx, test_idx in kf.split(train[columns], train['target']):\n    \n    X_tr, X_val = train[columns].iloc[tr_idx], train[columns].iloc[test_idx]\n    y_tr, y_val = train['target'].iloc[tr_idx], train['target'].iloc[test_idx]\n    \n    model = LGBMClassifier(**best_params)\n    \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=False)\n    \n    preds+=model.predict_proba(X_test)[:,1]/kf.n_splits\n    auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:,1]))\n    print(n+1,auc[n])\n    n+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id':test['id'],'target':preds})\nsubmission.to_csv('submit.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Please upvote the notebook if it helped in any way! \n\n## Have a nice day :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}