{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is PyTorch Tabular?\n\n![PyTorch Tabular](https://deepandshallowml.files.wordpress.com/2021/01/pytorch_tabular_logo.png)\n\nPyTorch Tabular is a framework/ wrapper library which aims to make Deep Learning with Tabular data easy and accessible to real-world cases and research alike. The core principles behind the design of the library are:\n\n- Low Resistance Usability\n- Easy Customization\n- Scalable and Easier to Deploy\n\nInstead of starting from scratch, the framework has been built on the shoulders of giants like **PyTorch**(obviously), and **PyTorch Lightning**.\n\nIt also comes with state-of-the-art deep learning models that can be easily trained using pandas dataframes.\n\nThe high-level config driven API makes it very quick to use and iterate. You can just use a **pandas dataframe** and all of the heavy lifting for normalizing, standardizing, encoding categorical features, and preparing the dataloader is handled by the library.\n\nThe `BaseModel` class provides an easy to extend abstract class for implementing custom models and still leverage the rest of the machinery packaged with the library.\nState-of-the-art networks like **Neural Oblivious Decision Ensembles(NODE)** for Deep Learning on Tabular Data, and **TabNet**: Attentive Interpretable Tabular Learning are implemented. See examples from the [documentation](https://pytorch-tabular.readthedocs.io/en/latest/) for how to use them.\n\nBy using PyTorch Lightning for the training, PyTorch Tabular inherits the flexibility and scalability that Pytorch Lightning provides\n\n- GitHub: [https://github.com/manujosephv/pytorch_tabular](https://github.com/manujosephv/pytorch_tabular)\n- Documentation: [https://pytorch-tabular.readthedocs.io/en/latest/](https://pytorch-tabular.readthedocs.io/en/latest/)\n- Accompanying Blog: [PyTorch Tabular â€“ A Framework for Deep Learning for Tabular Data](https://deep-and-shallow.com/2021/01/27/pytorch-tabular-a-framework-for-deep-learning-for-tabular-data/)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# install PyTorch Tabular first\n!pip install pytorch_tabular\n# This is for a custom optimizer. PyTorch Tabular is flexible enough to use custom optimizers\n!pip install torch_optimizer\n!pip install pandas==1.1.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# NODE and ML tools\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom pytorch_tabular import TabularModel\nfrom pytorch_tabular.models import CategoryEmbeddingModelConfig, NodeConfig, TabNetModelConfig\nfrom pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\nfrom pytorch_tabular.categorical_encoders import CategoricalEmbeddingTransformer\nfrom torch_optimizer import QHAdam\nimport category_encoders as ce\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load training data\ndf_train = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\ndisplay(df_train.head())\n# load test data\ndf_test = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')\ndisplay(df_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining the configs for the data, training, model, and optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_configs(train):\n    epochs = 25\n    batch_size = 1024\n    steps_per_epoch = int((len(train)//batch_size)*0.9)\n    data_config = DataConfig(\n        target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n        continuous_cols=['cont0', 'cont1', 'cont2', 'cont3', 'cont4',\n       'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10'],\n        categorical_cols=['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7',\n       'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15',\n       'cat16', 'cat17', 'cat18'],\n        continuous_feature_transform=\"quantile_normal\"\n    )\n    trainer_config = TrainerConfig(\n        auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n        batch_size=batch_size,\n        max_epochs=epochs,\n#         gpus=1, #index of the GPU to use. 0, means CPU\n    )\n    optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n    model_config = CategoryEmbeddingModelConfig(\n        task=\"classification\",\n        layers=\"500-200\",  # Number of nodes in each layer\n        activation=\"ReLU\", # Activation between each layers\n        learning_rate = 1e-3,\n        batch_norm_continuous_input=True,\n        use_batch_norm =True,\n        dropout=0.1,\n        embedding_dropout=0.05,\n        initialization=\"kaiming\",\n        metrics=[\"auroc\"],\n        metrics_params = [{}]\n    )\n    return data_config, trainer_config, optimizer_config, model_config","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_config, trainer_config, optimizer_config, model_config = get_configs(df_train)\ntabular_model = TabularModel(\n    data_config=data_config,\n    model_config=model_config,\n    optimizer_config=optimizer_config,\n    trainer_config=trainer_config\n)\n# fit model\ntabular_model.fit(train=df_train, optimizer=QHAdam, \n              optimizer_params={\"nus\": (0.7, 1.0), \"betas\": (0.95, 0.998)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = tabular_model.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare submission\ndf_sub = pd.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')\ndf_sub.target = pred_df['1_probability'].values\ndf_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}