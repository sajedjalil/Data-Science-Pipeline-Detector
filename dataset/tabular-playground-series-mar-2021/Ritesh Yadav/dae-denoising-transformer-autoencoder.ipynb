{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Denoising Autoencoder"},{"metadata":{},"cell_type":"markdown","source":"**This is Notebook Implementation of DAE,I have just open the py files and Added them in the form of notebook from this https://github.com/ryancheunggit/Denoise-Transformer-AutoEncoder for ease,I have tried to train it but got some \"Ran out of memory Error\" If anyone wants to run this you can do it in your Local env if you have high end configration.**\n\n**My suggestion is use the above github repo if you donot want to use Notebook, best is repo if you have high config cpu**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/tabular-playground-series-mar-2021/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom torch.utils.data import Dataset\n\npath = \"../input/tabular-playground-series-mar-2021\"\n\ndef get_data():\n    train_data = pd.read_csv(path+'/train.csv')\n    test_data = pd.read_csv(path+'/test.csv')\n\n#     X_nums = np.vstack([\n#         train_data.iloc[:, 11:-1].to_numpy(),\n#         test_data.iloc[:, 11:].to_numpy()\n#     ])\n#     X_nums = (X_nums - X_nums.mean(0)) / X_nums.std(0)\n\n#     X_cat = np.vstack([\n#         train_data.iloc[:, 1:11].to_numpy(),\n#         test_data.iloc[:, 1:11].to_numpy()\n#     ])\n#     encoder = OneHotEncoder(sparse=False)\n#     X_cat = encoder.fit_transform(X_cat)\n\n    X_nums = np.vstack([\n\ttrain_data.iloc[:, 21:-1].values,\n\ttest_data.iloc[:, 21:].values\n    ])\n    \n    \n    X_cat = np.vstack([\n\ttrain_data.iloc[:, 1:21].values,\n\ttest_data.iloc[:, 1:21].values\n    ])\n    \n    encoder = OneHotEncoder(sparse=False)\n    X_cat = encoder.fit_transform(X_cat)\n\n\n    X = np.hstack([X_cat, X_nums])\n    y = train_data['target'].to_numpy().reshape(-1, 1)\n    return X, y, X_cat.shape[1], X_nums.shape[1]\n\n\nclass SingleDataset(Dataset):\n    def __init__(self, x, is_sparse=False):\n        self.x = x.astype('float32')\n        self.is_sparse = is_sparse\n\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, index):\n        x = self.x[index]\n        if self.is_sparse: x = x.toarray().squeeze()\n        return x    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\n\n\nbce_logits = torch.nn.functional.binary_cross_entropy_with_logits\nmse = torch.nn.functional.mse_loss\n\n\nclass TransformerEncoder(torch.nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout, feedforward_dim):\n        super().__init__()\n        self.attn = torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n        self.linear_1 = torch.nn.Linear(embed_dim, feedforward_dim)\n        self.linear_2 = torch.nn.Linear(feedforward_dim, embed_dim)\n        self.layernorm_1 = torch.nn.LayerNorm(embed_dim)\n        self.layernorm_2 = torch.nn.LayerNorm(embed_dim)\n    \n    def forward(self, x_in):\n        attn_out, _ = self.attn(x_in, x_in, x_in)\n        x = self.layernorm_1(x_in + attn_out)\n        ff_out = self.linear_2(torch.nn.functional.relu(self.linear_1(x)))\n        x = self.layernorm_2(x + ff_out)\n        return x\n\n\nclass TransformerAutoEncoder(torch.nn.Module):\n    def __init__(\n            self, \n            num_inputs, \n            n_cats, \n            n_nums, \n            hidden_size=1024, \n            num_subspaces=8,\n            embed_dim=128, \n            num_heads=8, \n            dropout=0, \n            feedforward_dim=512, \n            emphasis=.75, \n            task_weights=[10, 14],\n            mask_loss_weight=2,\n        ):\n        super().__init__()\n        assert hidden_size == embed_dim * num_subspaces\n        self.n_cats = n_cats\n        self.n_nums = n_nums\n        self.num_subspaces = num_subspaces\n        self.num_heads = num_heads\n        self.embed_dim = embed_dim\n        self.emphasis = emphasis\n        self.task_weights = np.array(task_weights) / sum(task_weights)\n        self.mask_loss_weight = mask_loss_weight\n\n        self.excite = torch.nn.Linear(in_features=num_inputs, out_features=hidden_size)\n        self.encoder_1 = TransformerEncoder(embed_dim, num_heads, dropout, feedforward_dim)\n        self.encoder_2 = TransformerEncoder(embed_dim, num_heads, dropout, feedforward_dim)\n        self.encoder_3 = TransformerEncoder(embed_dim, num_heads, dropout, feedforward_dim)\n        \n        self.mask_predictor = torch.nn.Linear(in_features=hidden_size, out_features=num_inputs)\n        self.reconstructor = torch.nn.Linear(in_features=hidden_size + num_inputs, out_features=num_inputs)\n\n    def divide(self, x):\n        batch_size = x.shape[0]\n        x = x.reshape((batch_size, self.num_subspaces, self.embed_dim)).permute((1, 0, 2))\n        return x\n\n    def combine(self, x):\n        batch_size = x.shape[1]\n        x = x.permute((1, 0, 2)).reshape((batch_size, -1))\n        return x\n\n    def forward(self, x):\n        x = torch.nn.functional.relu(self.excite(x))\n        \n        x = self.divide(x)\n        x1 = self.encoder_1(x)\n        x2 = self.encoder_2(x1)\n        x3 = self.encoder_3(x2)\n        x = self.combine(x3)\n        \n        predicted_mask = self.mask_predictor(x)\n        reconstruction = self.reconstructor(torch.cat([x, predicted_mask], dim=1))\n        return (x1, x2, x3), (reconstruction, predicted_mask)\n\n    def split(self, t):\n        return torch.split(t, [self.n_cats, self.n_nums], dim=1)\n\n    def feature(self, x):\n        attn_outs, _ = self.forward(x)\n        return torch.cat([self.combine(x) for x in attn_outs], dim=1)\n\n    def loss(self, x, y, mask, reduction='mean'):\n        _, (reconstruction, predicted_mask) = self.forward(x)\n        x_cats, x_nums = self.split(reconstruction)\n        y_cats, y_nums = self.split(y)\n        w_cats, w_nums = self.split(mask * self.emphasis + (1 - mask) * (1 - self.emphasis))\n\n        cat_loss = self.task_weights[0] * torch.mul(w_cats, bce_logits(x_cats, y_cats, reduction='none'))\n        num_loss = self.task_weights[1] * torch.mul(w_nums, mse(x_nums, y_nums, reduction='none'))\n\n        reconstruction_loss = torch.cat([cat_loss, num_loss], dim=1) if reduction == 'none' else cat_loss.mean() + num_loss.mean()\n        mask_loss = self.mask_loss_weight * bce_logits(predicted_mask, mask, reduction=reduction)\n\n        return reconstruction_loss + mask_loss if reduction == 'mean' else [reconstruction_loss, mask_loss]\n\n\nclass SwapNoiseMasker(object):\n    def __init__(self, probas):\n        self.probas = torch.from_numpy(np.array(probas))\n\n    def apply(self, X):\n        should_swap = torch.bernoulli(self.probas.to(X.device) * torch.ones((X.shape)).to(X.device))\n        corrupted_X = torch.where(should_swap == 1, X[torch.randperm(X.shape[0])], X)\n        mask = (corrupted_X != X).float()\n        return corrupted_X, mask\n\n\ndef test_tf_encoder():\n    m = TransformerEncoder(4, 2, .1, 16)\n    x = torch.rand((32, 8))\n    x = x.reshape((32, 2, 4)).permute((1, 0, 2))\n    o = m(x)\n    assert o.shape == torch.Size([2, 32, 4])\n\n\ndef test_dae_model():\n    m = TransformerAutoEncoder(5, 2, 3, 16, 4, 4, 2, .1, 4, .75)\n    x = torch.cat([torch.randint(0, 2, (5, 2)), torch.rand((5, 3))], dim=1)\n    f = m.feature(x)\n    assert f.shape == torch.Size([5, 16 * 3])\n    loss = m.loss(x, x, (x > .2).float())\n\n\ndef test_swap_noise():\n    probas = [.2, .5, .8]\n    m = SwapNoiseMasker(probas)\n    diffs = []\n    for i in range(1000):\n        x = torch.rand((32, 3))\n        noisy_x, _ = m.apply(x)\n        diffs.append((x != noisy_x).float().mean(0).unsqueeze(0)) \n\n    print('specified : ', probas, ' - actual : ', torch.cat(diffs, 0).mean(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n    test_tf_encoder()\n    test_dae_model()\n    test_swap_noise()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\nfrom datetime import datetime\n#from util import AverageMeter\n#from model import SwapNoiseMasker, TransformerAutoEncoder\n#from data import get_data, SingleDataset\nfrom torch.utils.data import DataLoader\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\n\n# Hyper-params\nmodel_params = dict(\n    hidden_size=1024,\n    num_subspaces=8,\n    embed_dim=128,\n    num_heads=8,\n    dropout=0,\n    feedforward_dim=512,\n    emphasis=.75,\n    mask_loss_weight=2\n)\nbatch_size = 38\ninit_lr = 3e-4\nlr_decay = .998\nmax_epochs = 20\n\nrepeats = [  2,  2,  2,  4,  4,  4,  8,  8,  7, 15,  14]\nprobas =  [.95, .4, .7, .9, .9, .9, .9, .9, .9, .9, .25]\nswap_probas = sum([[p] * r for p, r in zip(probas, repeats)], [])\n\n#  get data\nX, Y, n_cats, n_nums = get_data()\n\ntrain_dl = DataLoader(\n    dataset=SingleDataset(X),\n    batch_size=batch_size,\n    shuffle=True,\n    pin_memory=True,\n    drop_last=True\n)\n\n# setup model\nmodel = TransformerAutoEncoder(\n    num_inputs=X.shape[1],\n    n_cats=n_cats,\n    n_nums=n_nums,\n    **model_params\n).cuda()\nmodel_checkpoint = 'model_checkpoint.pth'\n\nprint(model)\n\nnoise_maker = SwapNoiseMasker(swap_probas)\noptimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay)\n\n# train model\nfor epoch in range(max_epochs):\n    t0 = datetime.now()\n    model.train()\n    meter = AverageMeter()\n    for i, x in enumerate(train_dl):\n        x = x.cuda()\n        x_corrputed, mask = noise_maker.apply(x)\n        optimizer.zero_grad()\n        loss = model.loss(x_corrputed, x, mask)\n        loss.backward()\n        optimizer.step()\n\n        meter.update(loss.detach().cpu().numpy())\n\n    delta = (datetime.now() - t0).seconds\n    scheduler.step()\n    print('\\r epoch {:5d} - loss {:.6f} - {:4.6f} sec per epoch'.format(epoch, meter.avg, delta), end='')\n\ntorch.save({\n        \"optimizer\": optimizer.state_dict(),\n        \"scheduler\": scheduler.state_dict(),\n        \"model\": model.state_dict()\n    }, model_checkpoint\n)\nmodel_state = torch.load(model_checkpoint)\nmodel.load_state_dict(model_state['model'])\n\n# extract features\ndl = DataLoader(dataset=SingleDataset(X), batch_size=1024, shuffle=False, pin_memory=True, drop_last=False)\nfeatures = []\nmodel.eval()\nwith torch.no_grad():\n    for x in dl:\n        features.append(model.feature(x.cuda()).detach().cpu().numpy())\nfeatures = np.vstack(features)\n\n# downstream supervised regressor\nalpha = 1250 # 1000\nX = features[:300_000, :]\nscores = []\nfor train_idx, valid_idx in KFold().split(X, Y):\n    scores.append(mean_squared_error(Y[valid_idx], Ridge(alpha=1250).fit(X[train_idx], Y[train_idx]).predict(X[valid_idx]), squared=False))\nprint(np.mean(scores))\n\nnp.save('dae_features.npy', features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}