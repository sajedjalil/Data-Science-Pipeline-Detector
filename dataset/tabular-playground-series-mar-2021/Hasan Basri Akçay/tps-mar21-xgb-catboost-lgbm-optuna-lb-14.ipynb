{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nHey, thanks for viewing my Kernel!\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! ðŸ˜Š","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport warnings\n\n\nwarnings.simplefilter(\"ignore\")\n\nX = pd.read_csv('/kaggle/input/prepared-data/x_train.csv')\nX_test = pd.read_csv('/kaggle/input/prepared-data/x_test.csv')\ny = pd.read_csv('/kaggle/input/prepared-data/y_train.csv')\n\nprint('X shape: ', X.shape)\nprint('X_test shape: ', X_test.shape)\nprint('y shape: ', y.shape)\nprint(X.head())\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:08:10.346195Z","iopub.execute_input":"2022-01-03T12:08:10.346768Z","iopub.status.idle":"2022-01-03T12:08:15.688074Z","shell.execute_reply.started":"2022-01-03T12:08:10.346656Z","shell.execute_reply":"2022-01-03T12:08:15.687257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Creating and Evaluating","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ndef scorer(y, y_pred):\n    return roc_auc_score(y, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:08:15.689841Z","iopub.execute_input":"2022-01-03T12:08:15.690104Z","iopub.status.idle":"2022-01-03T12:08:18.219798Z","shell.execute_reply.started":"2022-01-03T12:08:15.69007Z","shell.execute_reply":"2022-01-03T12:08:18.219067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBClassifier\nxgbc_model = XGBClassifier(min_child_weight=0.1, reg_lambda=100, booster='gbtree', objective='binary:logitraw', random_state=42)\nxgbc_score = cross_val_score(xgbc_model, train_X, train_y, scoring='roc_auc', cv=5)\nprint('xgbc_score: ', xgbc_score.mean())\n\n# LGBMClassifier\nligthgbmc_model = LGBMClassifier(boosting_type='gbdt', objective='binary', random_state=42)\nligthgbmc_score = cross_val_score(ligthgbmc_model, train_X, train_y, scoring='roc_auc', cv=5)\nprint('ligthgbmc_score: ', ligthgbmc_score.mean())\n\n# CatBoostClassifier\ncbc_model = CatBoostClassifier(loss_function='Logloss', random_state=42, verbose=False)\ncbc_score = cross_val_score(cbc_model, train_X, train_y, scoring='roc_auc', cv=5)\nprint('cbc_score: ', cbc_score.mean())","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:08:18.221014Z","iopub.execute_input":"2022-01-03T12:08:18.221265Z","iopub.status.idle":"2022-01-03T12:19:58.573594Z","shell.execute_reply.started":"2022-01-03T12:08:18.22123Z","shell.execute_reply":"2022-01-03T12:19:58.572901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB Optuna","metadata":{}},{"cell_type":"code","source":"def objective(trial, data=X, target=y):\n    X_train, X_val, y_train, y_val = train_test_split(data, target, test_size=0.2, random_state=42)\n\n    params = {\n        'max_depth': trial.suggest_int('max_depth', 3, 32),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.005, 0.02, 0.05, 0.08, 0.1]),\n        'n_estimators': trial.suggest_int('n_estimators', 2000, 8000),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n        'gamma': trial.suggest_float('gamma', 0.0001, 1.0, log = True),\n        'alpha': trial.suggest_float('alpha', 0.0001, 10.0, log = True),\n        'lambda': trial.suggest_float('lambda', 0.0001, 10.0, log = True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.8),\n        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n        'tree_method': 'gpu_hist',\n        'booster': 'gbtree',\n        'random_state': 42,\n        'use_label_encoder': False,\n        'eval_metric': 'auc'\n\n    }\n    \n    model = XGBClassifier(**params)  \n    model.fit(X_train, y_train, eval_set = [(X_val,y_val)], early_stopping_rounds = 333, verbose = False)\n    y_pred = model.predict_proba(X_val)[:,1]\n    roc_auc = roc_auc_score(y_val, y_pred)\n\n    return roc_auc","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:19:58.575541Z","iopub.execute_input":"2022-01-03T12:19:58.575858Z","iopub.status.idle":"2022-01-03T12:19:58.585437Z","shell.execute_reply.started":"2022-01-03T12:19:58.57582Z","shell.execute_reply":"2022-01-03T12:19:58.584774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#study = optuna.create_study(direction='maximize')\n#study.optimize(objective, n_trials=50)\n#print('Number of finished trials: ', len(study.trials))\n#print('Best trial: ', study.best_trial.params)\n#print('Best value: ', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:19:58.586604Z","iopub.execute_input":"2022-01-03T12:19:58.587005Z","iopub.status.idle":"2022-01-03T12:19:58.614867Z","shell.execute_reply.started":"2022-01-03T12:19:58.58697Z","shell.execute_reply":"2022-01-03T12:19:58.614059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of finished trials: 1 Best trial: {'max_depth': 4, 'learning_rate': 0.1, 'n_estimators': 2616, 'min_child_weight': 36, 'gamma': 0.0001231342905079067, 'alpha': 5.138826788428377, 'lambda': 0.006952601632723477, 'colsample_bytree': 0.3019243613187322, 'subsample': 0.7474126793277557} Best value: 0.8941200673933261\n\nNumber of finished trials: 50 Best trial: {'max_depth': 6, 'learning_rate': 0.02, 'n_estimators': 2941, 'min_child_weight': 10, 'gamma': 0.027689264382343946, 'alpha': 2.239319562015662, 'lambda': 0.005116156806904708, 'colsample_bytree': 0.2018103901998171, 'subsample': 0.7452030806282816} Best value: 0.8951492161710065","metadata":{}},{"cell_type":"markdown","source":"# CatBoost Optuna","metadata":{}},{"cell_type":"code","source":"def objective(trial, data=X, target=y):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    params = {\n        'max_depth': trial.suggest_int('max_depth', 3, 64),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.005, 0.02, 0.05, 0.08, 0.1]),\n        'n_estimators': trial.suggest_int('n_estimators', 2000, 8000),\n        'max_bin': trial.suggest_int('max_bin', 200, 400),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.0001, 1.0, log = True),\n        'subsample': trial.suggest_float('subsample', 0.1, 0.8),\n        'random_seed': 42,\n        'task_type': 'GPU',\n        'loss_function': 'Logloss',\n        'eval_metric': 'AUC',\n        'bootstrap_type': 'Poisson'\n    }\n    \n    model = CatBoostClassifier(**params)  \n    model.fit(X_train, y_train, eval_set = [(X_val,y_val)], early_stopping_rounds = 222, verbose = False)\n    y_pred = model.predict_proba(X_val)[:,1]\n    roc_auc = roc_auc_score(y_val, y_pred)\n\n    return roc_auc","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:19:58.616769Z","iopub.execute_input":"2022-01-03T12:19:58.617462Z","iopub.status.idle":"2022-01-03T12:19:58.627163Z","shell.execute_reply.started":"2022-01-03T12:19:58.617427Z","shell.execute_reply":"2022-01-03T12:19:58.626483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#study = optuna.create_study(direction = 'maximize')\n#study.optimize(objective, n_trials = 50)\n#print('Number of finished trials:', len(study.trials))\n#print('Best trial:', study.best_trial.params)\n#print('Best value:', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:19:58.62842Z","iopub.execute_input":"2022-01-03T12:19:58.628789Z","iopub.status.idle":"2022-01-03T12:19:58.640759Z","shell.execute_reply.started":"2022-01-03T12:19:58.628752Z","shell.execute_reply":"2022-01-03T12:19:58.640131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of finished trials: 50 Best trial: {'max_depth': 4, 'learning_rate': 0.1, 'n_estimators': 2877, 'max_bin': 200, 'min_data_in_leaf': 10, 'l2_leaf_reg': 0.09385107162927438, 'subsample': 0.7990428819543426} Best value: 0.8925910141177894","metadata":{}},{"cell_type":"markdown","source":"# LGBM Optuna","metadata":{}},{"cell_type":"code","source":"def objective(trial,data=X,target=y):   \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n    params = {\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 11, 333),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 5, 64),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.05, 0.005, 0.1]),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.5),\n        'n_estimators': trial.suggest_int('n_estimators', 2000, 8000),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 10, 100),\n        'cat_l2': trial.suggest_int('cat_l2', 1, 20),\n        'min_data_per_group': trial.suggest_int('min_data_per_group', 50, 200),\n        'cat_feature' : [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, \n                         32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, \n                         53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67],\n        'n_jobs' : -1, \n        'random_state': 42,\n        'boosting_type': 'gbdt',\n        'metric': 'AUC',\n        'device': 'gpu'\n    }\n    model = LGBMClassifier(**params)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],eval_metric='auc', early_stopping_rounds=300, verbose=False)\n    \n    preds = model.predict_proba(test_x)[:,1]\n    \n    auc = roc_auc_score(test_y, preds)\n    \n    return auc","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:19:58.641752Z","iopub.execute_input":"2022-01-03T12:19:58.642008Z","iopub.status.idle":"2022-01-03T12:19:58.657467Z","shell.execute_reply.started":"2022-01-03T12:19:58.641982Z","shell.execute_reply":"2022-01-03T12:19:58.656623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\nprint('Number of finished trials: ', len(study.trials))\nprint('Best trial: ', study.best_trial.params)\nprint('Best value: ', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:19:58.660953Z","iopub.execute_input":"2022-01-03T12:19:58.661655Z","iopub.status.idle":"2022-01-03T12:20:43.767657Z","shell.execute_reply.started":"2022-01-03T12:19:58.661619Z","shell.execute_reply":"2022-01-03T12:20:43.766892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trial 32 finished with value: 0.8960118885713237 and parameters: {'reg_alpha': 5.028382776465415, 'reg_lambda': 7.969115943661513, 'num_leaves': 196, 'min_child_samples': 39, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.22772406492167746, 'n_estimators': 7028, 'cat_smooth': 38, 'cat_l2': 20, 'min_data_per_group': 199}. Best is trial 32 with value: 0.8960118885713237.\n\nNumber of finished trials: 50 Best trial: {'reg_alpha': 5.028382776465415, 'reg_lambda': 7.969115943661513, 'num_leaves': 196, 'min_child_samples': 39, 'max_depth': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.22772406492167746, 'n_estimators': 7028, 'cat_smooth': 38, 'cat_l2': 20, 'min_data_per_group': 199}. Best is trial 32 with value: 0.8960118885713237.","metadata":{}},{"cell_type":"code","source":"# Historic\nplot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:20:43.77023Z","iopub.execute_input":"2022-01-03T12:20:43.770483Z","iopub.status.idle":"2022-01-03T12:20:43.92782Z","shell.execute_reply.started":"2022-01-03T12:20:43.770449Z","shell.execute_reply":"2022-01-03T12:20:43.92718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importance\noptuna.visualization.plot_param_importances(study)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:20:43.929153Z","iopub.execute_input":"2022-01-03T12:20:43.929413Z","iopub.status.idle":"2022-01-03T12:20:44.135093Z","shell.execute_reply.started":"2022-01-03T12:20:43.929379Z","shell.execute_reply":"2022-01-03T12:20:44.134048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_params =  {'reg_alpha': 5.028382776465415, \n               'reg_lambda': 7.969115943661513, \n               'num_leaves': 196, \n               'min_child_samples': 39, \n               'max_depth': 20, \n               'learning_rate': 0.01, \n               'colsample_bytree': 0.22772406492167746, \n               'n_estimators': 7028, \n               'cat_smooth': 38, \n               'cat_l2': 20, \n               'min_data_per_group': 199,\n               'cat_feature' : [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, \n                                 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, \n                                 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67],\n               'n_jobs' : -1, \n               'random_state': 42,\n               'boosting_type': 'gbdt',\n               'metric': 'AUC',\n               'device': 'gpu'\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:30:01.740497Z","iopub.execute_input":"2022-01-03T12:30:01.740754Z","iopub.status.idle":"2022-01-03T12:30:01.748531Z","shell.execute_reply.started":"2022-01-03T12:30:01.740726Z","shell.execute_reply":"2022-01-03T12:30:01.747888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_params = study.best_trial.params\nlgb_params['device'] = \"gpu\"\nlgb_params['random_state'] = 42\nlgb_params['cat_feature'] = [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, \n                             32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, \n                             53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]\nlgb_params['n_jobs'] = -1 \nlgb_params['boosting_type'] =  'gbdt'\nlgb_params['metric'] =  'AUC'","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:30:05.630832Z","iopub.execute_input":"2022-01-03T12:30:05.631505Z","iopub.status.idle":"2022-01-03T12:30:05.64085Z","shell.execute_reply.started":"2022-01-03T12:30:05.631467Z","shell.execute_reply":"2022-01-03T12:30:05.640118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NFOLDS = 20\nfolds = StratifiedKFold(n_splits=NFOLDS, random_state=42, shuffle=True)\npredictions = np.zeros(len(X_test))\nfor fold, (train_index, test_index) in enumerate(folds.split(X, y)):\n    print(\"--> Fold {}\".format(fold + 1))\n    \n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    \n    lgb_model = LGBMClassifier(**lgb_params).fit(X_train, y_train, \n                                                  eval_set=[(X_valid, y_valid)], \n                                                  eval_metric='auc', \n                                                  early_stopping_rounds=300, verbose=0)\n    \n    y_preds = lgb_model.predict_proba(X_valid)[:,1]\n    predictions += lgb_model.predict_proba(X_test)[:,1] / folds.n_splits \n    \n    print(\": LGB - ROC AUC Score = {}\".format(roc_auc_score(y_valid, y_preds, average=\"micro\")))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:31:02.290364Z","iopub.execute_input":"2022-01-03T12:31:02.291007Z","iopub.status.idle":"2022-01-03T12:31:54.72226Z","shell.execute_reply.started":"2022-01-03T12:31:02.290967Z","shell.execute_reply":"2022-01-03T12:31:54.720465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')\nsub['target'] = predictions\nregr_table = sub.to_csv(\"Sub_lgb_v2.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T12:20:44.142038Z","iopub.status.idle":"2022-01-03T12:20:44.142432Z","shell.execute_reply.started":"2022-01-03T12:20:44.142217Z","shell.execute_reply":"2022-01-03T12:20:44.142238Z"},"trusted":true},"execution_count":null,"outputs":[]}]}