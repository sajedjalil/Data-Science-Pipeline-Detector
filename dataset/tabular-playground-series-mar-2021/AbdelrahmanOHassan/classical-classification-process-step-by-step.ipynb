{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hey Kagglers!! Today I am going to walk you through a binary classification problem in simple and clear steps","metadata":{}},{"cell_type":"code","source":"from IPython import display\ndisplay.Image(\"../input/classification-cover/classification_cover.png\", width=1400,height=600,)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-19T12:29:09.700995Z","iopub.execute_input":"2022-03-19T12:29:09.701526Z","iopub.status.idle":"2022-03-19T12:29:09.712628Z","shell.execute_reply.started":"2022-03-19T12:29:09.701491Z","shell.execute_reply":"2022-03-19T12:29:09.711887Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**First lets get our tools ready**","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import accuracy_score, confusion_matrix , precision_recall_fscore_support\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-19T12:29:11.302978Z","iopub.execute_input":"2022-03-19T12:29:11.303697Z","iopub.status.idle":"2022-03-19T12:29:11.342905Z","shell.execute_reply.started":"2022-03-19T12:29:11.30366Z","shell.execute_reply":"2022-03-19T12:29:11.342201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\ntest_data = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:11.703562Z","iopub.execute_input":"2022-03-19T12:29:11.70447Z","iopub.status.idle":"2022-03-19T12:29:14.723258Z","shell.execute_reply.started":"2022-03-19T12:29:11.704425Z","shell.execute_reply":"2022-03-19T12:29:14.722303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test_data.copy()  #lets just keep a safe version","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:14.725397Z","iopub.execute_input":"2022-03-19T12:29:14.725733Z","iopub.status.idle":"2022-03-19T12:29:14.763146Z","shell.execute_reply.started":"2022-03-19T12:29:14.725687Z","shell.execute_reply":"2022-03-19T12:29:14.76221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:14.764366Z","iopub.execute_input":"2022-03-19T12:29:14.764603Z","iopub.status.idle":"2022-03-19T12:29:14.974759Z","shell.execute_reply.started":"2022-03-19T12:29:14.764575Z","shell.execute_reply":"2022-03-19T12:29:14.974106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:14.976404Z","iopub.execute_input":"2022-03-19T12:29:14.977149Z","iopub.status.idle":"2022-03-19T12:29:15.095432Z","shell.execute_reply.started":"2022-03-19T12:29:14.977107Z","shell.execute_reply":"2022-03-19T12:29:15.094658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data = pd.concat([train_data , test_data]) \nall_data    #not recommended :)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:15.09662Z","iopub.execute_input":"2022-03-19T12:29:15.096988Z","iopub.status.idle":"2022-03-19T12:29:15.604101Z","shell.execute_reply.started":"2022-03-19T12:29:15.096958Z","shell.execute_reply":"2022-03-19T12:29:15.603128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I created this dataframe \"all_data\" inorder to easily make the operations on the features (Xs) {ex:Drop, replace, rename} at once for the test and train data sets, But we must be cautious about data leakage!**","metadata":{}},{"cell_type":"markdown","source":"> **train_data = all_data.iloc[0:300000, :]**             \n> **test_data = all_data.iloc[300000 : , :].drop(['target'],axis=1)**","metadata":{}},{"cell_type":"markdown","source":"# **Data Preparation**","metadata":{}},{"cell_type":"markdown","source":"### **Data preparation is a very very important phase of any ML project, we can basically divide this phase into two parts : EDA & preprocessing**","metadata":{}},{"cell_type":"markdown","source":">#  Exploratory Data Analysis - EDA","metadata":{}},{"cell_type":"markdown","source":">**At this level our approach is analyzing the data set to summerize it's main characteristics and see if we have any alarming flags**","metadata":{}},{"cell_type":"code","source":"display.Image(\"../input/explore/explore.jpeg\",width=650, height=500) ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:15.605764Z","iopub.execute_input":"2022-03-19T12:29:15.606018Z","iopub.status.idle":"2022-03-19T12:29:15.613906Z","shell.execute_reply.started":"2022-03-19T12:29:15.605972Z","shell.execute_reply":"2022-03-19T12:29:15.612769Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:15.615125Z","iopub.execute_input":"2022-03-19T12:29:15.615721Z","iopub.status.idle":"2022-03-19T12:29:15.62285Z","shell.execute_reply.started":"2022-03-19T12:29:15.615684Z","shell.execute_reply":"2022-03-19T12:29:15.622279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:16.083875Z","iopub.execute_input":"2022-03-19T12:29:16.084297Z","iopub.status.idle":"2022-03-19T12:29:16.107512Z","shell.execute_reply.started":"2022-03-19T12:29:16.084267Z","shell.execute_reply":"2022-03-19T12:29:16.106803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# id column is useless for now !\nall_data.drop('id',axis=1,inplace=True)\ntrain_data.drop('id',axis=1,inplace=True)\ntest_data.drop('id',axis=1,inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:16.24353Z","iopub.execute_input":"2022-03-19T12:29:16.2441Z","iopub.status.idle":"2022-03-19T12:29:16.502553Z","shell.execute_reply.started":"2022-03-19T12:29:16.244048Z","shell.execute_reply":"2022-03-19T12:29:16.501748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:16.504335Z","iopub.execute_input":"2022-03-19T12:29:16.504864Z","iopub.status.idle":"2022-03-19T12:29:17.135146Z","shell.execute_reply.started":"2022-03-19T12:29:16.504819Z","shell.execute_reply":"2022-03-19T12:29:17.134153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:17.137053Z","iopub.execute_input":"2022-03-19T12:29:17.137442Z","iopub.status.idle":"2022-03-19T12:29:17.756152Z","shell.execute_reply.started":"2022-03-19T12:29:17.137398Z","shell.execute_reply":"2022-03-19T12:29:17.755075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are 300k data point and no missing values !**","metadata":{}},{"cell_type":"markdown","source":"Lets the see the unique categories in each of the categorical columns ","metadata":{}},{"cell_type":"code","source":"for i in range (18):\n    print(\"category{}\".format(i) , train_data[\"cat{}\".format(i)].unique() ,\"\\n\") ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:17.850169Z","iopub.execute_input":"2022-03-19T12:29:17.85044Z","iopub.status.idle":"2022-03-19T12:29:18.236502Z","shell.execute_reply.started":"2022-03-19T12:29:17.850412Z","shell.execute_reply":"2022-03-19T12:29:18.235579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nWe can see that some categorical columns (like cat10,cat5) have so many categories, this wiil cause a huge increase in the number of columns if we decided to use One Hot Encoding ! ","metadata":{}},{"cell_type":"code","source":"len(train_data[\"cat10\"].unique())","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:20.780943Z","iopub.execute_input":"2022-03-19T12:29:20.781243Z","iopub.status.idle":"2022-03-19T12:29:20.81083Z","shell.execute_reply.started":"2022-03-19T12:29:20.781212Z","shell.execute_reply":"2022-03-19T12:29:20.809941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: I tried to drop \"Cat10\" since it had so many features and the distribution was so bad (one feature had most of the frequency) but the accuracy of the model actually decrease a bit so I undropped it","metadata":{}},{"cell_type":"markdown","source":"Lets do a quick summary statistic for numerical data","metadata":{}},{"cell_type":"code","source":"train_data.describe()   #only for train data !","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:30.626046Z","iopub.execute_input":"2022-03-19T12:29:30.626363Z","iopub.status.idle":"2022-03-19T12:29:30.814839Z","shell.execute_reply.started":"2022-03-19T12:29:30.626325Z","shell.execute_reply":"2022-03-19T12:29:30.813985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:30.932847Z","iopub.execute_input":"2022-03-19T12:29:30.93346Z","iopub.status.idle":"2022-03-19T12:29:30.943088Z","shell.execute_reply.started":"2022-03-19T12:29:30.93342Z","shell.execute_reply":"2022-03-19T12:29:30.942258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the target label, This is a binary classification problem  .... Also we can see that there is a class inbalance between the positive and negative classes ! , we might what to handel that by something like class_weights","metadata":{}},{"cell_type":"markdown","source":"let's plot a bargraph fot the target variable","metadata":{}},{"cell_type":"code","source":"train_data[\"target\"].value_counts().plot(kind='bar',color='red') ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:35.071908Z","iopub.execute_input":"2022-03-19T12:29:35.07219Z","iopub.status.idle":"2022-03-19T12:29:35.265915Z","shell.execute_reply.started":"2022-03-19T12:29:35.072162Z","shell.execute_reply":"2022-03-19T12:29:35.265274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can always use a heat map to find explore the correlation between features**","metadata":{}},{"cell_type":"code","source":"corr_matrix = train_data.corr()   # will only work for continuous numerical data (pearson's correlation)\nplt.figure(figsize = (10,10))\nsns.heatmap(corr_matrix,xticklabels=corr_matrix.columns.values,yticklabels=corr_matrix.columns.values,annot = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:36.693838Z","iopub.execute_input":"2022-03-19T12:29:36.694127Z","iopub.status.idle":"2022-03-19T12:29:37.861774Z","shell.execute_reply.started":"2022-03-19T12:29:36.694094Z","shell.execute_reply":"2022-03-19T12:29:37.860784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_with_target=corr_matrix['target']  #absolute value to see feature importance regardless of sign\ncorrelation_with_target.abs().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:37.863257Z","iopub.execute_input":"2022-03-19T12:29:37.863497Z","iopub.status.idle":"2022-03-19T12:29:37.873099Z","shell.execute_reply.started":"2022-03-19T12:29:37.863468Z","shell.execute_reply":"2022-03-19T12:29:37.872123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's Seperate categorical and numerical columns**","metadata":{}},{"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']  #numeric data types\nnum_columns = [col for col in all_data.columns if (all_data[col].dtype in numerics) and (col != \"target\") ]\nnum_columns","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:39.372595Z","iopub.execute_input":"2022-03-19T12:29:39.372853Z","iopub.status.idle":"2022-03-19T12:29:39.382813Z","shell.execute_reply.started":"2022-03-19T12:29:39.372826Z","shell.execute_reply":"2022-03-19T12:29:39.381824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_columns = [col for col in all_data.columns if (all_data[col].dtype not in numerics)]\ncat_columns","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:40.310712Z","iopub.execute_input":"2022-03-19T12:29:40.310984Z","iopub.status.idle":"2022-03-19T12:29:40.319389Z","shell.execute_reply.started":"2022-03-19T12:29:40.310957Z","shell.execute_reply":"2022-03-19T12:29:40.318532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Frequency distribution for numeric columns***","metadata":{}},{"cell_type":"code","source":"for i in range (train_data[num_columns].shape[1]):\n    plt.figure()\n    plt.hist(train_data[num_columns].iloc[:,i])\n    plt.xlabel(train_data[num_columns].columns[i])\n    plt.ylabel('frequency')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:46.417395Z","iopub.execute_input":"2022-03-19T12:29:46.417923Z","iopub.status.idle":"2022-03-19T12:29:49.307945Z","shell.execute_reply.started":"2022-03-19T12:29:46.417889Z","shell.execute_reply":"2022-03-19T12:29:49.306928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Frequency distribution for categorical columns***","metadata":{}},{"cell_type":"code","source":"for i in range (train_data[cat_columns].shape[1]):\n    plt.figure()\n    plt.hist(train_data[cat_columns].iloc[:,i])\n    plt.xlabel(train_data[cat_columns].columns[i])\n    plt.ylabel('frequency')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:29:49.309783Z","iopub.execute_input":"2022-03-19T12:29:49.310148Z","iopub.status.idle":"2022-03-19T12:30:02.343393Z","shell.execute_reply.started":"2022-03-19T12:29:49.310113Z","shell.execute_reply":"2022-03-19T12:30:02.342543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Check out this fancy visualization !****","metadata":{}},{"cell_type":"code","source":"#thanks to @ANDRESHG\n\nnum_rows, num_cols = len(num_columns),2\nf, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 15))\nf.suptitle('Distribution of Features', fontsize=16)\n\nfor index, column in enumerate(num_columns):\n    i,j = (index // num_cols, index % num_cols)\n    sns.kdeplot(train_data.loc[train_data['target'] == 0, column], color=\"r\", shade=True, ax=axes[index,0])\n    sns.kdeplot(train_data.loc[train_data['target'] == 1, column], color=\"g\", shade=True, ax=axes[index,0])\n    sns.histplot(data=train_data,x=column,hue='target', kde=False, palette='Paired_r', bins=10, ax=axes[index,1],multiple='stack')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:30:02.34484Z","iopub.execute_input":"2022-03-19T12:30:02.345094Z","iopub.status.idle":"2022-03-19T12:30:20.062445Z","shell.execute_reply.started":"2022-03-19T12:30:02.345062Z","shell.execute_reply":"2022-03-19T12:30:20.06147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"display.Image(\"../input/cleaning/datapreproc.png\",width=500, height=500)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-19T12:30:33.070474Z","iopub.execute_input":"2022-03-19T12:30:33.070912Z","iopub.status.idle":"2022-03-19T12:30:33.083393Z","shell.execute_reply.started":"2022-03-19T12:30:33.070883Z","shell.execute_reply":"2022-03-19T12:30:33.082464Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*luckily, the data doesn't need any cleaning*","metadata":{}},{"cell_type":"markdown","source":"### **Let's check for multicollinearity between independent variables**","metadata":{}},{"cell_type":"markdown","source":"*Actually we already saw the correlation between the independent variables in the heat map before ;)*","metadata":{}},{"cell_type":"code","source":"corr_matrix[corr_matrix>0.8][corr_matrix !=1].fillna(\"OK\")","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:30:36.065287Z","iopub.execute_input":"2022-03-19T12:30:36.065578Z","iopub.status.idle":"2022-03-19T12:30:36.09269Z","shell.execute_reply.started":"2022-03-19T12:30:36.065546Z","shell.execute_reply":"2022-03-19T12:30:36.091646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**cont1 is highley correlated to cont2 and cont0 is highley correlated cont10 .... is that a big deal ?**                     \n>**Acually for some algorithms, yes it is; You see, some algorithms like logestic regression (which we will use in a moment) assumes the absence of multicollinearity           \nSo multicollinearity missleads the model into inflating the affect of those correlated features (note: checkout VIF \"quantifies the severity of multicollinearity\")            \nFair to say that some other models like tree-based models are not affected by this multicollinearity**","metadata":{}},{"cell_type":"markdown","source":"**Lets fix this using some basic feature engineering!**","metadata":{}},{"cell_type":"code","source":"all_data['cont1_2'] = all_data['cont1'] * all_data['cont2']\nall_data['cont0_10'] = all_data['cont0'] * all_data['cont10']    \nall_data.drop('cont1',axis=1,inplace=True)\nall_data.drop('cont2',axis=1,inplace=True)\nall_data.drop('cont0',axis=1,inplace=True)\nall_data.drop('cont10',axis=1,inplace=True)\nnum_columns = [col for col in all_data.columns if (all_data[col].dtype in numerics) and (col != \"target\") ]\ncat_columns = [col for col in all_data.columns if (all_data[col].dtype not in numerics)]","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:30:38.392666Z","iopub.execute_input":"2022-03-19T12:30:38.393097Z","iopub.status.idle":"2022-03-19T12:30:38.946745Z","shell.execute_reply.started":"2022-03-19T12:30:38.393057Z","shell.execute_reply":"2022-03-19T12:30:38.945669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = train_data.shape[0]\ntrain_data = all_data.iloc[0:t, :]","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:30:41.263847Z","iopub.execute_input":"2022-03-19T12:30:41.264237Z","iopub.status.idle":"2022-03-19T12:30:41.269132Z","shell.execute_reply.started":"2022-03-19T12:30:41.264203Z","shell.execute_reply":"2022-03-19T12:30:41.26798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We could also get a principal component that finds an axis that explains most of the variance, and then we will used this new component with dropping one of the old features**","metadata":{}},{"cell_type":"markdown","source":"That process will look like this :","metadata":{}},{"cell_type":"markdown","source":"***====Just for demonstration====***","metadata":{}},{"cell_type":"code","source":"# pca = PCA( n_components =1)\n# cont1_2 = pca.fit_transform(all_data[['cont1','cont2']])\n# print(pca.explained_variance_ratio_)\n##From the explained variance ratio we can basically have an intuition about the percentage of lost information after transformation","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:31:57.639196Z","iopub.execute_input":"2022-03-19T12:31:57.63995Z","iopub.status.idle":"2022-03-19T12:31:57.643157Z","shell.execute_reply.started":"2022-03-19T12:31:57.639915Z","shell.execute_reply":"2022-03-19T12:31:57.642498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_data[\"cont1_2\"] = cont1_2\n# all_data.drop('cont1',axis=1,inplace=True)\n# all_data.drop('cont2',axis=1,inplace=True)\n\n# we have already delt with the correlated features","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:31:57.780386Z","iopub.execute_input":"2022-03-19T12:31:57.78118Z","iopub.status.idle":"2022-03-19T12:31:57.784434Z","shell.execute_reply.started":"2022-03-19T12:31:57.781132Z","shell.execute_reply":"2022-03-19T12:31:57.783807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pca1 = PCA( n_components =1)\n# cont0_10 = pca1.fit_transform(all_data[['cont0','cont10']])\n# print(pca1.explained_variance_ratio_) ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:31:58.938612Z","iopub.execute_input":"2022-03-19T12:31:58.938911Z","iopub.status.idle":"2022-03-19T12:31:58.942971Z","shell.execute_reply.started":"2022-03-19T12:31:58.938879Z","shell.execute_reply":"2022-03-19T12:31:58.942045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_data[\"cont0_10\"] = cont0_10\n# all_data.drop('cont10',axis=1,inplace=True)\n# all_data.drop('cont0',axis=1,inplace=True)\n# all_data.drop('cat10',axis=1,inplace=True)\n\n# we have already delt with the correlated features","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:31:59.049476Z","iopub.execute_input":"2022-03-19T12:31:59.049952Z","iopub.status.idle":"2022-03-19T12:31:59.053939Z","shell.execute_reply.started":"2022-03-19T12:31:59.049897Z","shell.execute_reply":"2022-03-19T12:31:59.053215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**===================**","metadata":{}},{"cell_type":"markdown","source":"**Let's check the correlation between features now after we delt with the correlated features !**","metadata":{}},{"cell_type":"code","source":"corr_matrix_after = train_data.corr() \ncorr_matrix_after[corr_matrix>0.8][corr_matrix !=1].fillna(\"OK\")","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:32:01.838396Z","iopub.execute_input":"2022-03-19T12:32:01.839455Z","iopub.status.idle":"2022-03-19T12:32:01.973404Z","shell.execute_reply.started":"2022-03-19T12:32:01.839408Z","shell.execute_reply":"2022-03-19T12:32:01.972038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**That's Looking Better !!**","metadata":{}},{"cell_type":"code","source":"train_data_x = all_data.iloc[0:t, :].drop(['target'],axis=1)\ntest_data = all_data.iloc[t : , :].drop(['target'],axis=1)     ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:32:05.741373Z","iopub.execute_input":"2022-03-19T12:32:05.741652Z","iopub.status.idle":"2022-03-19T12:32:05.845616Z","shell.execute_reply.started":"2022-03-19T12:32:05.741623Z","shell.execute_reply":"2022-03-19T12:32:05.844708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_x.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:32:07.754046Z","iopub.execute_input":"2022-03-19T12:32:07.754356Z","iopub.status.idle":"2022-03-19T12:32:07.784152Z","shell.execute_reply.started":"2022-03-19T12:32:07.754324Z","shell.execute_reply":"2022-03-19T12:32:07.783329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        #('std_scaler', StandardScaler()),\n    ])\n#in this problem ... there is no missing data, so we dont need an imputer, this is what a typical pipeline will look like tho\n#we will comment the scaler since tree-base models(which we will be using alot of) doesn't require standarization","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:32:10.138365Z","iopub.execute_input":"2022-03-19T12:32:10.139137Z","iopub.status.idle":"2022-03-19T12:32:10.144266Z","shell.execute_reply.started":"2022-03-19T12:32:10.139101Z","shell.execute_reply":"2022-03-19T12:32:10.143365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('encoder', OneHotEncoder(handle_unknown ='ignore')),\n    ])\n#Lets start with one hot encoding","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:33:04.232652Z","iopub.execute_input":"2022-03-19T12:33:04.23294Z","iopub.status.idle":"2022-03-19T12:33:04.238299Z","shell.execute_reply.started":"2022-03-19T12:33:04.23291Z","shell.execute_reply":"2022-03-19T12:33:04.237357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_attribs = num_columns\ncat_attribs = cat_columns\n\nfull_pipeline = ColumnTransformer([\n        (\"numerical\", num_pipeline, num_attribs),      \n        (\"categorical\", cat_pipeline, cat_attribs)],\n        \n    )","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:33:06.695073Z","iopub.execute_input":"2022-03-19T12:33:06.695637Z","iopub.status.idle":"2022-03-19T12:33:06.700654Z","shell.execute_reply.started":"2022-03-19T12:33:06.695601Z","shell.execute_reply":"2022-03-19T12:33:06.699556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_x_prep = full_pipeline.fit_transform(train_data_x)   #fit_transform for training data","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:33:09.096897Z","iopub.execute_input":"2022-03-19T12:33:09.097209Z","iopub.status.idle":"2022-03-19T12:33:13.238943Z","shell.execute_reply.started":"2022-03-19T12:33:09.09718Z","shell.execute_reply":"2022-03-19T12:33:13.237913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_prep = full_pipeline.transform(test_data)   #transform only for training data !","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:33:21.393128Z","iopub.execute_input":"2022-03-19T12:33:21.394906Z","iopub.status.idle":"2022-03-19T12:33:23.126843Z","shell.execute_reply.started":"2022-03-19T12:33:21.394847Z","shell.execute_reply":"2022-03-19T12:33:23.125603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_x_prep.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:33:23.128509Z","iopub.execute_input":"2022-03-19T12:33:23.128866Z","iopub.status.idle":"2022-03-19T12:33:23.135433Z","shell.execute_reply.started":"2022-03-19T12:33:23.128831Z","shell.execute_reply":"2022-03-19T12:33:23.134301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_prep.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:33:23.655351Z","iopub.execute_input":"2022-03-19T12:33:23.65565Z","iopub.status.idle":"2022-03-19T12:33:23.662233Z","shell.execute_reply.started":"2022-03-19T12:33:23.655606Z","shell.execute_reply":"2022-03-19T12:33:23.661402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.target","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:33:23.850643Z","iopub.execute_input":"2022-03-19T12:33:23.850952Z","iopub.status.idle":"2022-03-19T12:33:23.860117Z","shell.execute_reply.started":"2022-03-19T12:33:23.850919Z","shell.execute_reply":"2022-03-19T12:33:23.859282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data is ready","metadata":{}},{"cell_type":"markdown","source":"**Now, Lets get started with the model itself !**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:34:08.779462Z","iopub.execute_input":"2022-03-19T12:34:08.779771Z","iopub.status.idle":"2022-03-19T12:34:08.785112Z","shell.execute_reply.started":"2022-03-19T12:34:08.779738Z","shell.execute_reply":"2022-03-19T12:34:08.784136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n \nclasses = np.unique(train_data.target)\nweights = compute_class_weight(class_weight='balanced', classes=classes, y=train_data.target)\nclass_weights1 = dict(zip(classes, weights))\n#This is to be used in Catboost, in LGBM for example we can just type class_weight ='balanced' ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:34:10.894402Z","iopub.execute_input":"2022-03-19T12:34:10.8947Z","iopub.status.idle":"2022-03-19T12:34:10.983269Z","shell.execute_reply.started":"2022-03-19T12:34:10.894671Z","shell.execute_reply":"2022-03-19T12:34:10.982267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The idea behined StratifiedKFold is just to ensure that the dirtribution of classes(the ratios) in each fold is the same as in the entire data set**                          \n**So basically if the ratio of class A to B is 0.4 in the data-set,StratifiedKFold will ensure the ratio between them to be 0.4 in each of the folds**","metadata":{}},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"code","source":"display.Image(\"../input/baseline/baseline.png\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-19T12:34:21.024196Z","iopub.execute_input":"2022-03-19T12:34:21.024515Z","iopub.status.idle":"2022-03-19T12:34:21.031251Z","shell.execute_reply.started":"2022-03-19T12:34:21.024482Z","shell.execute_reply":"2022-03-19T12:34:21.030506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We just want to create a initial point of refrence to be sure that the problem is solvable and that we are making progress in the next steps**","metadata":{}},{"cell_type":"markdown","source":"  ","metadata":{}},{"cell_type":"markdown","source":"## Logestic Regression","metadata":{}},{"cell_type":"markdown","source":"Lets start by creating a simple Logestic Regression model ","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression(max_iter=700,class_weight='balanced',n_jobs=-1)\ncv = cross_val_score(lr ,train_data_x_prep,train_data.target,cv=skf,scoring='roc_auc')\ncv, cv.mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Good start out of the box, lets see if we can do any better !","metadata":{}},{"cell_type":"markdown","source":"# Upscaling: Develop a model that overfits !","metadata":{}},{"cell_type":"code","source":"display.Image(\"../input/overfit/overfit.png\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T22:38:23.165671Z","iopub.execute_input":"2022-03-18T22:38:23.166785Z","iopub.status.idle":"2022-03-18T22:38:23.182942Z","shell.execute_reply.started":"2022-03-18T22:38:23.166722Z","shell.execute_reply":"2022-03-18T22:38:23.182076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt.fit(train_data_x_prep,train_data.target)\ndt.predict(train_data_x_prep) \ndt.score(train_data_x_prep,train_data.target)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"100% score !! thats great ! ...right?  actually NO, the DT classifier of sklearn by defalut has \"max_depth=None\" which means that it will gladly continue to make splits and more leafs until it totally overfits the data !  want a prove?   Lets test the model using the validation error (Train the model on parts of the data and the test on another part that it didn't see before)","metadata":{}},{"cell_type":"code","source":"dt = DecisionTreeClassifier()\ncv = cross_val_score(dt ,train_data_x_prep,train_data.target,cv=skf)\ncv, cv.mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This huge dump in performance is due to the model overfitting the folds it gets for training each time and performes poorly on the hidden fold ","metadata":{}},{"cell_type":"markdown","source":"**We can do better !**","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# Developing models that performs better than the baseline","metadata":{}},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"markdown","source":"Random Forest is basicly a bootstraping aggregation of diffrent DTs, essentially we get a bunch of DTs that are trained on diffrent splits(with resampling) of the data and even diffrent sets of features. This form of ensembling really helps in generalizing the model (regularization) ... Lets see that in action and see how RF will out perform a single DT in the validation errors ","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators= 300,n_jobs=-1 ,class_weight = 'balanced')\ncv = cross_val_score(rf ,train_data_x_prep,train_data.target,cv=skf,scoring='roc_auc')\ncv, cv.mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T07:32:54.531529Z","iopub.status.idle":"2022-03-18T07:32:54.5322Z","shell.execute_reply.started":"2022-03-18T07:32:54.531959Z","shell.execute_reply":"2022-03-18T07:32:54.531984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Way better !","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"code","source":"display.Image(\"../input/lightgbm/lightgbm.png\",width=300,height=300)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:16:48.565215Z","iopub.execute_input":"2022-03-19T12:16:48.565626Z","iopub.status.idle":"2022-03-19T12:16:48.578899Z","shell.execute_reply.started":"2022-03-19T12:16:48.565593Z","shell.execute_reply":"2022-03-19T12:16:48.577997Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets try Microsoft's LightGBM and see how it compares","metadata":{}},{"cell_type":"code","source":"lbg = LGBMClassifier(n_estimators= 110,num_leaves = 300)\ncv = cross_val_score(lbg ,train_data_x_prep,train_data.target,cv=skf,scoring='roc_auc')\ncv, cv.mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T18:12:41.99356Z","iopub.execute_input":"2022-03-18T18:12:41.993861Z","iopub.status.idle":"2022-03-18T18:12:41.997734Z","shell.execute_reply.started":"2022-03-18T18:12:41.993829Z","shell.execute_reply":"2022-03-18T18:12:41.997066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's good, Lets see if we can do any better with hyperparameter tuning using a grid search !","metadata":{}},{"cell_type":"code","source":"def clf_performance(classifier, model_name):\n    print(model_name)\n    print('Best Score: ',classifier.best_score_)\n    print('Best Parameters: ' , classifier.best_params_)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:26:55.953395Z","iopub.execute_input":"2022-03-18T21:26:55.954318Z","iopub.status.idle":"2022-03-18T21:26:55.958704Z","shell.execute_reply.started":"2022-03-18T21:26:55.954273Z","shell.execute_reply":"2022-03-18T21:26:55.958049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_estimators = [90,100,110,120]\nnum_leaves = [250,300, 350]\nparam_grid = {'n_estimators': n_estimators,'num_leaves' :num_leaves }","metadata":{"execution":{"iopub.status.busy":"2022-03-18T21:26:57.04989Z","iopub.execute_input":"2022-03-18T21:26:57.050302Z","iopub.status.idle":"2022-03-18T21:26:57.054516Z","shell.execute_reply.started":"2022-03-18T21:26:57.050272Z","shell.execute_reply":"2022-03-18T21:26:57.053917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The grid search will try all the possible compinations and come back with the best performer !","metadata":{}},{"cell_type":"code","source":"lbg = LGBMClassifier(class_weight = 'balanced')\nclf_lbg = GridSearchCV(lbg, param_grid = param_grid,  verbose = 0,scoring ='roc_auc', n_jobs = -1,cv=None)\nbest_clf_lbg = clf_lbg.fit(train_data_x_prep,train_data.target) \nclf_performance(best_clf_lbg,'LGBM')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T18:12:45.752598Z","iopub.execute_input":"2022-03-18T18:12:45.753356Z","iopub.status.idle":"2022-03-18T18:12:45.757269Z","shell.execute_reply.started":"2022-03-18T18:12:45.753315Z","shell.execute_reply":"2022-03-18T18:12:45.756247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So the best combination of the parameters within this search is n_estimators= 90 & num_leaves = 250","metadata":{}},{"cell_type":"code","source":"# lbg = LGBMClassifier(n_estimators= 90,num_leaves = 250,n_jobs=-1 ,class_weight = 'balanced' )\ncv = cross_val_score(best_clf_lbg ,train_data_x_prep,train_data.target,cv=skf,scoring='roc_auc')\ncv, cv.mean() ","metadata":{"execution":{"iopub.status.busy":"2022-03-18T18:12:45.928535Z","iopub.execute_input":"2022-03-18T18:12:45.929527Z","iopub.status.idle":"2022-03-18T18:12:45.933305Z","shell.execute_reply.started":"2022-03-18T18:12:45.929485Z","shell.execute_reply":"2022-03-18T18:12:45.932367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's good from LGBM , lets try another competitor !","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"display.Image(\"../input/catboost/catboost.png\",width=300,height=300)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:16:53.351829Z","iopub.execute_input":"2022-03-19T12:16:53.352141Z","iopub.status.idle":"2022-03-19T12:16:53.363203Z","shell.execute_reply.started":"2022-03-19T12:16:53.352101Z","shell.execute_reply":"2022-03-19T12:16:53.362345Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat = CatBoostClassifier(verbose=False,class_weights = class_weights1,iterations = 10000)\ncv = cross_val_score(cat,train_data_x_prep,train_data.target,cv=skf,scoring='roc_auc')\ncv, cv.mean()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T18:12:56.481668Z","iopub.execute_input":"2022-03-18T18:12:56.481971Z","iopub.status.idle":"2022-03-18T18:37:04.611482Z","shell.execute_reply.started":"2022-03-18T18:12:56.481938Z","shell.execute_reply":"2022-03-18T18:37:04.610733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow, just by increasing the number of iterations, we get amazing results !  Looks like we have a winner !!","metadata":{}},{"cell_type":"markdown","source":"**note: in a case like this I would use something like a voting classifier, but since the required output of this problem is probability rather than actual results ... lets stop here and go evaluate our output**","metadata":{}},{"cell_type":"code","source":"cat.fit(train_data_x_prep,train_data.target)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T01:01:42.831482Z","iopub.execute_input":"2022-03-19T01:01:42.832281Z","iopub.status.idle":"2022-03-19T01:08:58.674326Z","shell.execute_reply.started":"2022-03-19T01:01:42.832229Z","shell.execute_reply":"2022-03-19T01:08:58.67333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prob_pred = cat.predict_proba(test_data_prep)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:20:13.719693Z","iopub.execute_input":"2022-03-18T16:20:13.720907Z","iopub.status.idle":"2022-03-18T16:20:15.099972Z","shell.execute_reply.started":"2022-03-18T16:20:13.720848Z","shell.execute_reply":"2022-03-18T16:20:15.098775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prob_pred=prob_pred[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:20:16.54281Z","iopub.execute_input":"2022-03-18T16:20:16.543122Z","iopub.status.idle":"2022-03-18T16:20:16.548926Z","shell.execute_reply.started":"2022-03-18T16:20:16.543091Z","shell.execute_reply":"2022-03-18T16:20:16.547963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#In this specific dataset, the output is required in the form of probabilities\noutput = pd.DataFrame({'id':test.id, 'target': prob_pred})\noutput.to_csv('Osama_new.csv', index=False)\noutput","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lastly, letâ€™s check our model's detailed performance (TP,FP,TN,FN)  from which we can interpret many important metrics as accuracy, recall and precision","metadata":{}},{"cell_type":"code","source":"cm = confusion_matrix(train_data.target,cat.predict(train_data_x_prep)) \nsns.set(font_scale = 1)\n# Transform to df for easier plotting\ncm_df = pd.DataFrame(cm)\n\nplt.figure(figsize=(6,4.5))\nsns.heatmap(cm_df, annot=True, fmt='g')\n# plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(y_df_train, lr.predict(train)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T01:10:13.473406Z","iopub.execute_input":"2022-03-19T01:10:13.473775Z","iopub.status.idle":"2022-03-19T01:10:16.093049Z","shell.execute_reply.started":"2022-03-19T01:10:13.473742Z","shell.execute_reply":"2022-03-19T01:10:16.092169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets see how we did !**","metadata":{}},{"cell_type":"code","source":"display.Image(\"../input/score/score.jpg\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-19T12:17:19.672252Z","iopub.execute_input":"2022-03-19T12:17:19.67254Z","iopub.status.idle":"2022-03-19T12:17:19.679868Z","shell.execute_reply.started":"2022-03-19T12:17:19.67251Z","shell.execute_reply":"2022-03-19T12:17:19.679179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not bad !","metadata":{}},{"cell_type":"markdown","source":"**I really hope you have enjoyed this notebook, feel free to leave any comments**","metadata":{}},{"cell_type":"code","source":"display.Image(\"../input/thanks/thanks.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:17:03.20319Z","iopub.execute_input":"2022-03-19T12:17:03.203495Z","iopub.status.idle":"2022-03-19T12:17:03.215239Z","shell.execute_reply.started":"2022-03-19T12:17:03.203464Z","shell.execute_reply":"2022-03-19T12:17:03.214321Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}