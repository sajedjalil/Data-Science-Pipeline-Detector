{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data and Library Imports üìö\n\nLet's start this interesting competition by first importing data and libraries!"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"! pip install -q rich dabl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nfrom scipy import stats\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom rich import print as _pprint\nfrom rich.progress import track\nfrom colorama import Fore, Style\n\nimport dabl\n\nimport plotly.express as px\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom IPython.display import HTML\nimport tensorflow as tf\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\n\nf = open(\"../input/notebookassets/blue.css\").read()\nHTML(f\"<style>{f}</style>\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def cprint(string):\n    _pprint(f\"[black]{string}[/black]\")\n    \ndef cout(string: str, color=Fore.RED):\n    \"\"\"\n    Saves some work\n    \"\"\"\n    print(color+string+Style.RESET_ALL)\n\ndef stats(scol, col):\n    cout(f\"Average Value in the Column: {scol} is: {np.mean(col):.4f}\", Fore.RED)\n    cout(f\"Median Value in the Column: {scol} is: {np.median(col):.4f}\", Fore.BLUE)\n    cout(f\"Maxmimum Value in the Column: {scol} is: {np.max(col):.4f}\", Fore.GREEN)\n    cout(f\"Minimum Value in the Column: {scol} is: {np.min(col):.4f}\", Fore.YELLOW)\n    cout(f\"50th Quantile of the Column: {scol} is: {np.quantile(col, 0.5):.4f}\", Fore.CYAN)\n    cout(f\"75th Quantile of the Column: {scol} is: {np.quantile(col, 0.75):.4f}\", Fore.MAGENTA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file = pd.read_csv(\"../input/tabular-playground-series-mar-2021/train.csv\")\ntest_file = pd.read_csv(\"../input/tabular-playground-series-mar-2021/test.csv\")\n\ntrain_file.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Peeking the Data üëÅ\n\nLet's start by taking a peek at the data and getting some basic insights from it!\n<!-- <div class=\"alert alert-block alert-info\"></div> -->"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## A brief look at Target Column"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\nThis Competition (unlike it's predecessors) wants us to classify the data points into either of 2 categories (0 or 1).\nAs you can probably see from below, the dataset is not very balanced when looking from the Target Column's perspective.\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"names = train_file['target'].value_counts().index.tolist()\nvalues = train_file['target'].value_counts().tolist()\n\nplt.figure(figsize=(9, 9))\nplt.pie(x=values, labels=names, autopct=\"%1.2f%%\", colors=[\"cyan\", \"blue\"], explode=[0, 0.05])\nplt.title(\"Target Value Pie-Chart\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a list of Categorical as well as continuous column names\ncatCols = [f\"cat{i}\" for i in range(0, 19)]\nconCols = [f\"cont{i}\" for i in range(0, 11)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show Unique categories in feature columns\ncprint(\"[bold magenta] Categorical Features in the dataset [/bold magenta]\")\nfor col in catCols:\n    print(f\"Number of features in {col}: \", end='')\n    cout(f\"{train_file[col].nunique()}\", color=Fore.MAGENTA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# # Show some quick stats of Continuous Features\n# cprint(\"[bold green] Continuous Features and their Basic Statistics [/bold green]\")\n# for col in conCols:\n#     print(f\"\\n{'-'*20} Column: {col} {'-'*20}\\n\")\n#     stats(col, train_file[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Advanced Exploratory Data Analysis üìä\n\nLet's now start with detailed Exploratory Data Analysis and take a look at different combinations of features, one by one!"},{"metadata":{},"cell_type":"markdown","source":"## Continuous Features\n\nLet's begin by seeing this month's data's continuous features and how they are distributed."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(15, 15))\nfig.suptitle('Distribution of Continuous Features (cont0-cont10)', fontsize=16)\n\nfor idx, col in enumerate(train_file[conCols]):\n    i,j = (idx // 4, idx % 4)\n    sns.kdeplot(train_file[col], color=\"blue\", shade=True, label=\"%1.1f\"%(train_file[col].skew()), ax=ax[i,j])\n\nfig.delaxes(ax[2, 3])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now see how Continuous features behave based on what target variable they represent."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(15, 15))\nfig.suptitle('Distribution of Continuous Features with Targets (cont0-cont10)', fontsize=16)\n\nfor idx, col in enumerate(train_file[conCols]):\n    i,j = (idx // 4, idx % 4)\n    current_plot_1 = train_file.loc[train_file['target'].astype(int) == 1][col]\n    current_plot_0 = train_file.loc[train_file['target'].astype(int) == 0][col]\n    f1 = sns.kdeplot(current_plot_0, color=\"blue\", shade=True, ax=ax[i,j], label=\"Target-0\")\n    f2 = sns.kdeplot(current_plot_1, color=\"purple\", shade=True, ax=ax[i,j], label=\"Target-1\")\n    f1 = f1.legend(loc=\"best\")\n    f2 = f2.legend(loc=\"best\")\n    \nfig.delaxes(ax[2, 3])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Features\n\nLet's now take a look at the Categorical features in this Dataset and the distribution of their various categories."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\nfig.suptitle('Distribution of Categorical Features (cat0-cat18)', fontsize=16)\n\ncatCols_s = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat6', 'cat9', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18']\nfor idx, col in enumerate(train_file[catCols_s]):\n    i, j = (idx // 4, idx % 4)\n    sns.histplot(x=col, data=train_file, ax=ax[i, j], color='green')\n\nfig.delaxes(ax[3, 3])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just like the Continuous Features, let's see how the selected categorical features change with Targets. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\nfig.suptitle('Distribution of Categorical Features with respect to Targets(cat0-cat18)', fontsize=16)\n\ncatCols_s = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat6', 'cat9', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18']\nfor idx, col in enumerate(train_file[catCols_s]):\n    i, j = (idx // 4, idx % 4)\n    f1 = sns.histplot(x=col, data=train_file[train_file['target'].astype(int)==0], ax=ax[i, j], color='green', label='Target-0')\n    f2 = sns.histplot(x=col, data=train_file[train_file['target'].astype(int)==1], ax=ax[i, j], color='yellow', label='Target-1')\n    f1 = f1.legend(loc=\"best\")\n    f2 = f2.legend(loc=\"best\")\n\nfig.delaxes(ax[3, 3])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\nI have not plotted the following Categorical Columns in the Above Plot:\n    \n<code>cat5</code>,\n<code>cat7</code>,\n<code>cat8</code>,\n<code>cat10</code>.\n\nThe Reason behind this was that since there were so many categories, it wouldn't fit into subplots.\nWe shall plot them separately down below.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"## A closer look at some Categorical features.\n\nLet's now take a look at the aforementioned 4 categorical features that are too clumsy to fit in a subplots."},{"metadata":{},"cell_type":"markdown","source":"### Feature: cat5\n\nSince the feature `cat5` has *over 80* different categories, I will be plotting only the top-10 most occuring ones."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ixs = train_file['cat5'].value_counts().index.tolist()[:10]\ncat5_fl = train_file[train_file['cat5'].isin(ixs)]['cat5']\n\nplt.figure(figsize=(8, 7))\nax = sns.histplot(cat5_fl, color='orange')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Top-10 Categories of feature: cat5\")\n\ntotal = len(train_file['cat5'])\nfor p in ax.patches:\n        percentage = '{:.2f}%'.format(100 * p.get_height()/total)\n        x = p.get_x() + p.get_width() / 5\n        y = p.get_y() + p.get_height() + 0.02\n        ax.annotate(percentage, (x, y))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see above, the categories `BI`, `AB` and `BU` dominate the count for this feature."},{"metadata":{},"cell_type":"markdown","source":"### Feature: cat7\n\nSame as cat5, I am only showing the top-10 most occuring values here."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ixs = train_file['cat7'].value_counts().index.tolist()[:10]\ncat7_fl = train_file[train_file['cat7'].isin(ixs)]['cat7'].reset_index(drop=True)\n\nplt.figure(figsize=(8, 7))\nax = sns.histplot(cat7_fl, color='orange')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Top-10 Categories of feature: cat7\")\n\ntotal = len(train_file['cat7'])\nfor p in ax.patches:\n        percentage = '{:.2f}%'.format(100 * p.get_height()/total)\n        x = p.get_x() + p.get_width() / 7\n        y = p.get_y() + p.get_height() + 0.02\n        ax.annotate(percentage, (x, y))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature: cat8\n\nSame as cat5 and cat7, I am only showing the top-10 most occuring values here."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ixs = train_file['cat8'].value_counts().index.tolist()[:10]\ncat8_fl = train_file[train_file['cat8'].isin(ixs)]['cat8'].reset_index(drop=True)\n\nplt.figure(figsize=(8, 7))\nax = sns.histplot(cat8_fl, color='orange')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Top-10 Categories of feature: cat8\")\n\ntotal = len(train_file['cat8'])\nfor p in ax.patches:\n        percentage = '{:.2f}%'.format(100 * p.get_height()/total)\n        x = p.get_x() + p.get_width() / 7\n        y = p.get_y() + p.get_height() + 0.02\n        ax.annotate(percentage, (x, y))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature: cat10\n\nSame as cat5, cat7 and cat8, I am only showing the top-10 most occuring values here."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ixs = train_file['cat10'].value_counts().index.tolist()[:10]\ncat10_fl = train_file[train_file['cat10'].isin(ixs)]['cat10'].reset_index(drop=True)\n\nplt.figure(figsize=(8, 7))\nax = sns.histplot(cat10_fl, color='orange')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.title(\"Top-10 Categories of feature: cat10\")\n\ntotal = len(train_file['cat10'])\nfor p in ax.patches:\n        percentage = '{:.2f}%'.format(100 * p.get_height()/total)\n        x = p.get_x() + p.get_width() / 7\n        y = p.get_y() + p.get_height() + 0.02\n        ax.annotate(percentage, (x, y))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation Between Continuous features and Target\n\nLet us now plot the correlation between continuous features and the target and see how things change."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"corr = train_file[conCols+[\"target\"]].corr()\n\nfig = px.imshow(corr, title=\"Correlation Heatmap Between Continuous Features and Target\", color_continuous_scale=px.colors.sequential.Hot_r)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DABL Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"dabl.plot(train_file, target_col='target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multi Input Embeddings Model - Tensorflow üåÜ\n\nLet's start modelling by using one of the model types that I experimented in last TPS Competition (Feburary).\n\nFor Categorical features, I am using Entity Embeddings for every feature then concatenating them and then passing them to a few final layers where they are combined with the features learned from the Dense network built for continuous data."},{"metadata":{},"cell_type":"markdown","source":"First get the TPU for faster training."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we encode categorical columns in both training and testing sets to make them ready for modelling."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode the categorical features\ndef encodeCategoricalColumns(train, test):\n    for col in track(catCols, description=\"[red]Encoding...[/red]\"):\n        le = LabelEncoder()\n        fit_data = pd.concat([train[col], test[col]])\n        le.fit(fit_data)\n        train[col] = le.transform(train[col])\n        test[col] = le.transform(test[col])\nencodeCategoricalColumns(train_file, test_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle the data and then split features and targets\ntrain_csv = train_file.sample(frac=1).reset_index(drop=True)\ndata = train_csv.drop(['id', 'target'], axis=1)\ntarget = train_csv[['target']]\ntarget_train = tf.keras.utils.to_categorical(target)\n\nprint(f\"Data Shape: {data.shape}, Target shape: {target_train.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to get the number of input & output dimensions for the embeddings \ndef get_emb_dims(categorical_column):\n    in_dim = categorical_column.nunique()\n    out_dim = int(np.sqrt(in_dim))\n    return in_dim, out_dim\n\n# for c in catCols:\n#     ind, oud = get_emb_dims(data[c])\n#     print(f\"{c}: in-{ind}, out-{oud}\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def build_categorical_model(cat_data=data[catCols]):\n    # Cat-0\n    cat0_inp = tf.keras.Input(shape=(1,))\n    cat0_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat0')(cat0_inp)\n    cat0_out = tf.keras.layers.Reshape(target_shape=(1,))(cat0_out)\n    \n    # Cat-1\n    cat1_inp = tf.keras.Input(shape=(1,))\n    cat1_out = tf.keras.layers.Embedding(input_dim=15, output_dim=3, name='cat1')(cat1_inp)\n    cat1_out = tf.keras.layers.Reshape(target_shape=(3,))(cat1_out)\n    \n    # Cat-2\n    cat2_inp = tf.keras.Input(shape=(1,))\n    cat2_out = tf.keras.layers.Embedding(input_dim=19, output_dim=4, name='cat2')(cat2_inp)\n    cat2_out = tf.keras.layers.Reshape(target_shape=(4,))(cat2_out)\n    \n    # Cat-3\n    cat3_inp = tf.keras.Input(shape=(1,))\n    cat3_out = tf.keras.layers.Embedding(input_dim=13, output_dim=3, name='cat3')(cat3_inp)\n    cat3_out = tf.keras.layers.Reshape(target_shape=(3,))(cat3_out)\n    \n    # Cat-4\n    cat4_inp = tf.keras.Input(shape=(1,))\n    cat4_out = tf.keras.layers.Embedding(input_dim=20, output_dim=4, name='cat4')(cat4_inp)\n    cat4_out = tf.keras.layers.Reshape(target_shape=(4,))(cat4_out)\n    \n    # Cat-5\n    cat5_inp = tf.keras.Input(shape=(1,))\n    cat5_out = tf.keras.layers.Embedding(input_dim=84, output_dim=9, name='cat5')(cat5_inp)\n    cat5_out = tf.keras.layers.Reshape(target_shape=(9,))(cat5_out)\n    \n    # Cat-6\n    cat6_inp = tf.keras.Input(shape=(1,))\n    cat6_out = tf.keras.layers.Embedding(input_dim=16, output_dim=4, name='cat6')(cat6_inp)\n    cat6_out = tf.keras.layers.Reshape(target_shape=(4,))(cat6_out)\n    \n    # Cat-7\n    cat7_inp = tf.keras.Input(shape=(1,))\n    cat7_out = tf.keras.layers.Embedding(input_dim=51, output_dim=7, name='cat7')(cat7_inp)\n    cat7_out = tf.keras.layers.Reshape(target_shape=(7,))(cat7_out)\n    \n    # Cat-8\n    cat8_inp = tf.keras.Input(shape=(1,))\n    cat8_out = tf.keras.layers.Embedding(input_dim=61, output_dim=7, name='cat8')(cat8_inp)\n    cat8_out = tf.keras.layers.Reshape(target_shape=(7,))(cat8_out)\n    \n    # Cat-9\n    cat9_inp = tf.keras.Input(shape=(1,))\n    cat9_out = tf.keras.layers.Embedding(input_dim=19, output_dim=4, name='cat9')(cat9_inp)\n    cat9_out = tf.keras.layers.Reshape(target_shape=(4,))(cat9_out)\n    \n    # Cat-10\n    cat10_inp = tf.keras.Input(shape=(1,))\n    cat10_out = tf.keras.layers.Embedding(input_dim=299, output_dim=17, name='cat10')(cat10_inp)\n    cat10_out = tf.keras.layers.Reshape(target_shape=(17,))(cat10_out)\n    \n    # Cat-11\n    cat11_inp = tf.keras.Input(shape=(1,))\n    cat11_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat11')(cat11_inp)\n    cat11_out = tf.keras.layers.Reshape(target_shape=(1,))(cat11_out)\n    \n    # Cat-12\n    cat12_inp = tf.keras.Input(shape=(1,))\n    cat12_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat12')(cat12_inp)\n    cat12_out = tf.keras.layers.Reshape(target_shape=(1,))(cat12_out)\n    \n    # Cat-13\n    cat13_inp = tf.keras.Input(shape=(1,))\n    cat13_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat13')(cat13_inp)\n    cat13_out = tf.keras.layers.Reshape(target_shape=(1,))(cat13_out)\n    \n    # Cat-14\n    cat14_inp = tf.keras.Input(shape=(1,))\n    cat14_out = tf.keras.layers.Embedding(input_dim=2, output_dim=1, name='cat14')(cat14_inp)\n    cat14_out = tf.keras.layers.Reshape(target_shape=(1,))(cat14_out)\n    \n    # Cat-15\n    cat15_inp = tf.keras.Input(shape=(1,))\n    cat15_out = tf.keras.layers.Embedding(input_dim=4, output_dim=2, name='cat15')(cat15_inp)\n    cat15_out = tf.keras.layers.Reshape(target_shape=(2,))(cat15_out)\n    \n    # Cat-16\n    cat16_inp = tf.keras.Input(shape=(1,))\n    cat16_out = tf.keras.layers.Embedding(input_dim=4, output_dim=2, name='cat16')(cat16_inp)\n    cat16_out = tf.keras.layers.Reshape(target_shape=(2,))(cat16_out)\n    \n    # Cat-17\n    cat17_inp = tf.keras.Input(shape=(1,))\n    cat17_out = tf.keras.layers.Embedding(input_dim=4, output_dim=2, name='cat17')(cat17_inp)\n    cat17_out = tf.keras.layers.Reshape(target_shape=(2,))(cat17_out)\n    \n    # Cat-18\n    cat18_inp = tf.keras.Input(shape=(1,))\n    cat18_out = tf.keras.layers.Embedding(input_dim=4, output_dim=2, name='cat18')(cat18_inp)\n    cat18_out = tf.keras.layers.Reshape(target_shape=(2,))(cat18_out)\n    \n    # Concatenate all entity embedding layers.\n    input_layers = [cat0_inp, cat1_inp, cat2_inp, cat3_inp, cat4_inp, cat5_inp, cat6_inp, cat7_inp, cat8_inp, cat9_inp, cat10_inp, cat11_inp, cat12_inp, cat13_inp, cat14_inp, cat15_inp, cat16_inp, cat17_inp, cat18_inp]\n    output_layers = [cat0_out, cat1_out, cat2_out, cat3_out, cat4_out, cat5_out, cat6_out, cat7_out, cat8_out, cat9_out, cat10_out, cat11_out, cat12_out, cat13_out, cat14_out, cat15_out, cat16_out, cat17_out, cat18_out]\n    \n    concat = tf.keras.layers.Concatenate(name=\"combine-embd\")(output_layers)\n    \n    # Add Dense, Dropout and Batchnorm\n    bn = tf.keras.layers.BatchNormalization(name=\"embd-bn\")(concat)\n    dropout_1 = tf.keras.layers.Dropout(0.3, name=\"embd-drop1\")(bn)\n    fc1 = tf.keras.layers.Dense(1024, activation='relu', name=\"embd-fc1\")(dropout_1)\n    dropout_2 = tf.keras.layers.Dropout(0.5, name=\"embd-drop2\")(fc1)\n    fc2 = tf.keras.layers.Dense(512, activation='relu', name=\"embd-fc2\")(dropout_2)\n    dropout_3 = tf.keras.layers.Dropout(0.5, name=\"embd-drop3\")(fc2)\n    cat_output = tf.keras.layers.Dense(64, activation='relu', name=\"embd-out\")(dropout_3)\n    \n    # Return the Last Layer output\n    return input_layers, cat_output\n\ndef build_continuous_model(con_data=data[conCols]):\n    # Model for Continuous Data\n    con_inputs = tf.keras.Input(shape=(con_data.shape[1]))\n    \n    fc1 = tf.keras.layers.Dense(512, activation='relu', name=\"cont_fc1\")(con_inputs)\n    drp1 = tf.keras.layers.Dropout(0.5, name=\"cont_drop1\")(fc1)\n    fc2 = tf.keras.layers.Dense(256, activation='relu', name=\"cont_fc2\")(drp1)\n    drp2 = tf.keras.layers.Dropout(0.3, name=\"cont_drop2\")(fc2)\n    fc3 = tf.keras.layers.Dense(128, activation='relu', name=\"cont_fc3\")(drp2)\n    drp3 = tf.keras.layers.Dropout(0.3, name=\"cont_drop3\")(fc3)\n    con_output = tf.keras.layers.Dense(64, activation='relu', name=\"cont_out\")(drp3)\n    \n    return con_inputs, con_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    cat_inputs, cat_outputs = build_categorical_model(data[catCols])\n    con_inputs, con_outputs = build_continuous_model(data[conCols])\n    \n    # Concatenate the outputs\n    all_layers_out = [cat_outputs, con_outputs]\n    concat_outputs = tf.keras.layers.Concatenate()(all_layers_out)\n    fc1 = tf.keras.layers.Dense(256, activation='relu', name=\"all_fc1\")(concat_outputs)\n    drp1 = tf.keras.layers.Dropout(0.3, name=\"all_drop1\")(fc1)\n    fc2 = tf.keras.layers.Dense(128, activation='relu', name=\"all_fc2\")(drp1)\n    drp2 = tf.keras.layers.Dropout(0.3, name=\"all_drop2\")(fc2)\n    fc3 = tf.keras.layers.Dense(64, activation='relu', name=\"all_fc3\")(drp2)\n    drp3 = tf.keras.layers.Dropout(0.5, name=\"all_drop3\")(fc3)\n    fc4 = tf.keras.layers.Dense(16, activation='relu', name=\"all_fc4\")(drp3)\n    output = tf.keras.layers.Dense(2, activation='softmax', name=\"all_out\")(fc4)\n    \n    all_inputs = cat_inputs + [con_inputs]\n    return tf.keras.Model(inputs=all_inputs, outputs=output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the above defined functions to build this huge model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize a temporary model so that we can see the model architecture plot.\ntemp_model = build_model()\ntf.keras.utils.plot_model(temp_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's train this model and see how it performs!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Init KFolds training\nkfold = KFold(5, shuffle=False)\n\nfor fold_, (train_idx, valid_idx) in enumerate(kfold.split(data, target)):\n    print(f\"{'='*20} FOLD: {fold_+1} {'='*20}\")\n    # Get this fold's training and validation splits\n    trainX, trainY = data.iloc[train_idx], target_train[train_idx]\n    validX, validY = data.iloc[valid_idx], target_train[valid_idx]\n    \n    training_data = ([trainX[f\"cat{i}\"] for i in range(0, 19)] + [trainX[conCols]], trainY)\n    validation_data = ([validX[f\"cat{i}\"] for i in range(0, 19)] + [validX[conCols]], validY)\n\n    # Initalize this fold's model\n    with strategy.scope():\n        model = build_model()\n        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    # Init early stopping so that we don't train the model more than we have to\n    early_stopper = tf.keras.callbacks.EarlyStopping(\n        monitor='val_acc',\n        patience=2,\n        mode='max',\n        restore_best_weights=True\n    )\n    \n    # Also have a model checkpoint\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=f\"fold_{fold_}_model.h5\",\n        monitor='val_acc',\n        mode='max',\n        save_best_only=True\n    )\n    \n    # Fit this fold's model\n    model.fit(\n        training_data[0],\n        training_data[1],\n        epochs=5,\n        validation_data=validation_data,\n        callbacks=[early_stopper, checkpoint]\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\nKeep in mind that I am training this model for only 2 epochs per fold (reason being it's high time consumption).\nI encourage you to fork the notebook (if you do, leaving an upvote would be nice üòÅ) and then increasing the number of folds and playing around with other numbers to see how the results change!\n</div>"},{"metadata":{},"cell_type":"markdown","source":"# Inference üåå\n\nNow let's do quick inference based on the model(s) trained above."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the testing data in the right shape for inference\ntest_ids = test_file['id']\ntest = test_file.drop(['id'], axis=1)\ntest_data = [test[f\"cat{i}\"] for i in range(0, 19)] + [test[conCols]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do the inference\npreds = model.predict(test_data)\npreds = preds.argmax(1)\nprint(preds)  # Printing some predictions for sanity check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the inference into a submission file\nsubmission_file = pd.DataFrame()\nsubmission_file['id'] = test_ids.tolist()\nsubmission_file['target'] = preds\nsubmission_file.to_csv(\"submission.csv\", index=None)\nsubmission_file.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n    Thanks for taking your time to look at my work!\n    <br><br>\n    <bold>If you like this notebook, you can consider giving an upvote! It will help me make more useful content!</bold>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cprint(\"[bold green]UNDER WORK! MORE CELLS ARE BEING ADDED DAILY![/bold green]\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}