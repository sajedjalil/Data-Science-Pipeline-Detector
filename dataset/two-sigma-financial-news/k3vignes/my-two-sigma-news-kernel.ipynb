{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"```\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n\n(market_train_df, news_train_df) = env.get_training_data()\ntrain_my_model(market_train_df, news_train_df)\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in env.get_prediction_days():\n  predictions_df = make_my_predictions(market_obs_df, news_obs_df, predictions_template_df)\n  env.predict(predictions_df)\n  \nenv.write_submission_file()\n```\nNote that `train_my_model` and `make_my_predictions` are functions you need to write for the above example to work."},{"metadata":{"trusted":true,"_uuid":"a36cef49908eb1eedf1e8fdc294dc077b0948fc3","scrolled":true},"cell_type":"code","source":"def warn(*args, **kwargs):\n    pass\n\nimport warnings\nwarnings.warn = warn\nfrom kaggle.competitions import twosigmanews\nimport json\nimport re\nimport time\nimport datetime\nimport multiprocessing\nfrom datetime import date, timedelta\nfrom dateutil.relativedelta import relativedelta\nfrom sklearn.linear_model import LogisticRegression\nimport pandas as pd\nimport numpy as np\n\nmaster_s_time = time.time()\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04f8c796e20105515ad3854dbf8644063deca4c2"},"cell_type":"code","source":"MY_LOG = open('my_log.txt', 'w+')\nMY_LOG.write('start_time: {0}'.format(datetime.datetime.now()))\nmarket_train_df, news_train_df = env.get_training_data()\nfeatures = ['day', 'totalNumArticles','numAssetArticles',\n            'portionOfAssetArticles','relevance','negSentiment',\n            'neutralSentiment', 'posSentiment', 'noveltyCount24H',\n            'volumeCount24H']\ninput_features = list(set(features + ['open', 'close', 'returnsOpenPrevMktres1']) - {'day'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc71937a9d33ded9a98e88b56c26b07f8f7a628d"},"cell_type":"code","source":"MY_MAX_TIME = pd.Timestamp('2007-06-01 22:00:00+0000', tz='UTC')\nmarket_train_df = market_train_df.loc[market_train_df['time'] < MY_MAX_TIME].copy()\nnews_train_df = news_train_df.loc[news_train_df['time'] < MY_MAX_TIME].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9f3c515e335b3f5704aea20080858a521f090b1"},"cell_type":"code","source":"def output(s): \n    print(s)\n    MY_LOG.write(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b47354c66f0ca108e093953e7dde9843ddf0ba7"},"cell_type":"code","source":"def get_next_trading_date(df, current_date, date_col='time'):\n    return df.loc[df[date_col] > current_date, date_col].min()\n\ndef get_prev_trading_date(df, current_date, date_col='time'):\n    return df.loc[df[date_col] < current_date, date_col].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4825ac494dc51d3f2a03c191551f2b8bcddbec8"},"cell_type":"code","source":"def add_day_feature_to_market_data(market_df, asset_codes): \n    market_df['day'] = np.NaN\n    market_df.sort_values('time')\n    for i, asset_code in enumerate(asset_codes):\n        market_df.loc[market_df['assetCode'] == asset_code, 'day'] = list(range(1, len(market_df.loc[market_df['assetCode'] == asset_code]) + 1))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66011669bf5749e4305fb9ec8e882f678a33f1df"},"cell_type":"code","source":"def add_curr_day_news_features(market_df, news_df, asset_name, ind):\n    market_df.loc[ind, 'totalNumArticles'] = len(news_df)\n    news_df = news_df.loc[news_df['assetName'] == asset_name].copy()\n    market_df.loc[ind, 'numAssetArticles'] = len(news_df)\n    if market_df.loc[ind, 'numAssetArticles'] == 0: \n        market_df.loc[ind, ['portionOfAssetArticles',\n                            'relevance',\n                            'negSentiment',\n                            'neutralSentiment', \n                            'posSentiment', \n                            'noveltyCount24H', \n                            'volumeCount24H']] = 0\n    else: \n        market_df.loc[ind, 'portionOfAssetArticles'] = market_df.loc[ind, 'numAssetArticles'] / market_df.loc[ind, 'totalNumArticles']\n        market_df.loc[ind, 'relevance'] = news_df['relevance'].sum() / market_df.loc[ind,'numAssetArticles']\n        market_df.loc[ind, 'negSentiment'] = news_df['sentimentNegative'].sum() / market_df.loc[ind,'numAssetArticles']\n        market_df.loc[ind, 'neutralSentiment'] = news_df['sentimentNeutral'].sum() / market_df.loc[ind,'numAssetArticles']\n        market_df.loc[ind, 'posSentiment'] = news_df['sentimentPositive'].sum() / market_df.loc[ind, 'numAssetArticles']\n        market_df.loc[ind, 'noveltyCount24H'] = news_df['noveltyCount24H'].sum() / market_df.loc[ind,'numAssetArticles']\n        market_df.loc[ind, 'volumeCount24H'] = news_df['volumeCounts24H'].sum() / market_df.loc[ind,'numAssetArticles']\n                  \ndef add_news_features(market_df, news_df, asset_codes): \n    s_time = time.time()\n    name = multiprocessing.current_process().name\n    for i, asset_code in enumerate(asset_codes): \n        if i % 100 == 0: \n            e_time = timedelta(seconds=(time.time() - s_time))\n            name = multiprocessing.current_process().name\n            print('On assetCode: {0}/{1} | Thread {2}'.format(i,len(asset_codes), name))\n        tmp_market_df = market_df.loc[market_df['assetCode'] == asset_code].copy()\n        tmp_market_df.sort_values(by=['day'], inplace=True)\n        prev_date = news_df['time'].min()\n        curr_date = None\n        counter = 0\n        for ind, row in tmp_market_df.iterrows():\n            if row['day'] == 1: \n                prev_date = row['time']\n                continue\n            else: \n                curr_date = row['time']\n                tmp_news_df = news_df.loc[(news_df['time'] > prev_date) &\n                                          (news_df['time'] < curr_date)].copy()\n                # Assigns values to market_df by ref\n                add_curr_day_news_features(market_df, tmp_news_df, row['assetName'], ind)\n                prev_date = curr_date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cb64678aec368406b0651dd2541e3fdb09a039b"},"cell_type":"code","source":"def worker(from_date, to_date, min_date, l): \n    multiprocessing.current_process().name += ' |' + str(from_date) + ' - ' + str(to_date) \n    name = multiprocessing.current_process().name\n    print('indexing...')\n    s_time = time.time()\n    tmp_market_df = market_train_df.loc[(market_train_df['time'] >= from_date) &\n                                        (market_train_df['time'] < to_date)].copy()\n    if from_date > min_date:\n        from_date = get_prev_trading_date(market_train_df, from_date)\n    tmp_news_df = news_train_df.loc[(news_train_df['time'] >= from_date) &\n                                    (news_train_df['time'] < to_date)].copy()\n    asset_codes = tmp_market_df['assetCode'].unique().tolist()\n    asset_names = tmp_news_df['assetName'].unique().tolist()\n    e_time = time.time() - s_time\n    print('Took: {0} | thread {1}'.format(str(timedelta(seconds=e_time)), name))\n    print('add_news_feature_to_market_data...')\n    s_time = time.time()\n    add_news_features(tmp_market_df, tmp_news_df, asset_codes)\n    e_time = time.time() - s_time\n    print('Took: {0} | thread {1}'.format(str(timedelta(seconds=e_time)), name))\n    l.append(tmp_market_df)\n    print('appended to list')\n\ndef callback(tmp_market_df): \n    print('callback fn...')\n    name = multiprocessing.current_process().name\n    s_time = time.time()\n    inds = tmp_market_df.index\n    market_train_df.loc[inds, features] = tmp_market_df.loc[inds, features]\n    e_time = time.time() - s_time\n    print('Took: {0} | thread {1}'.format(str(timedelta(seconds=e_time)), name))\n    \ndef add_features_cols(): \n    for feature in features: \n        market_train_df[feature] = np.NaN\n    news_train_df['day'] = np.NaN\n\ndef add_features_to_training_data(): \n    MONTHS_RANGE = 1\n    NUM_PROCESSES = 4\n    with multiprocessing.Manager() as manager:\n        min_date = market_train_df['time'].min()\n        prev_date = min_date\n        curr_date = prev_date + relativedelta(months=MONTHS_RANGE)\n        max_date = market_train_df['time'].max()\n        p = multiprocessing.Pool(processes=NUM_PROCESSES)\n        l = manager.list()\n        process_counter = 1\n        while prev_date < max_date: \n            p.apply_async(worker, args=(prev_date, curr_date, min_date, l))\n            prev_date = curr_date\n            curr_date += relativedelta(months=MONTHS_RANGE)\n            process_counter += 1\n        p.close()\n        p.join()\n        \n        for tmp_market_df in l: \n            callback(tmp_market_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f1aeabb7dc5ec698fb1467f0f5335dd942d8e6a"},"cell_type":"markdown","source":"\n* `day` column is used when calculating 10-day prev market return"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e36b74268ad6addefe11467faea2d15d54188793"},"cell_type":"code","source":"def add_large_return_features(market_train_df,\n                              num_std=1, target='returnsOpenNextMktres10'):\n    market_train_df['large_pos_target'] = 0\n    market_train_df['large_neg_target'] = 0\n    mean = market_train_df[target].mean()\n    std = market_train_df[target].std()\n    market_train_df.loc[market_train_df[target] > mean + std * num_std, 'large_pos_target'] = 1\n    market_train_df.loc[market_train_df[target] < mean - std * num_std, 'large_neg_target'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e0d76985a98b116ddebae4b5a0c1b6f27a81a15"},"cell_type":"code","source":"def add_pos_neg_return_features(market_train_df, target='returnsOpenNextMktres10'):\n    market_train_df['pos_target'] = 0\n    market_train_df['neg_target'] = 0\n    market_train_df.loc[market_train_df[target] > 0, 'pos_target'] = 1\n    market_train_df.loc[market_train_df[target] < 0, 'neg_target'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a196aee25a4bc17fa6fcae3de82f7f2c19f3c72"},"cell_type":"code","source":"def train_models(enhanced_market_df, asset_codes):\n    models = dict.fromkeys(asset_codes)\n    for i, asset_code in enumerate(asset_codes):\n        if i % 100 == 0: \n            print(\"Training assetCode: {0}/{1}\".format(i, len(asset_codes)))\n        X = market_train_df.loc[market_train_df['assetCode'] == asset_code, input_features]\n        y_pos = market_train_df.loc[market_train_df['assetCode'] == asset_code, 'pos_target']\n        y_neg = market_train_df.loc[market_train_df['assetCode'] == asset_code, 'neg_target']\n        if len(y_pos.unique()) < 2: \n            print('{0} has less than 2 y_pos classes '.format(asset_code))\n            continue\n        if len(y_neg.unique()) < 2: \n            print('{0} has less than 2 y_neg classe'.format(asset_code))\n            continue\n        pos_return_classifier = LogisticRegression(random_state=0, solver='lbfgs',\n                                                   multi_class='multinomial', n_jobs=-1).fit(X, y_pos)\n        neg_return_classifier = LogisticRegression(random_state=0, solver='lbfgs',\n                                                   multi_class='multinomial', n_jobs=-1).fit(X, y_neg)\n        models[asset_code] = {\n            'pos_return_classifier': pos_return_classifier,\n            'neg_return_classifier': neg_return_classifier\n        }\n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa0fea33f3e6be5f06d4d5670e6b0159156f3684"},"cell_type":"code","source":"def fill_market_df(market_df, asset_codes):\n    for asset_code in asset_codes: \n        market_train_df.loc[market_train_df['assetCode'] == asset_code,\n                            'returnsOpenPrevMktres1'] = market_train_df.loc[market_train_df['assetCode'] == asset_code,\n                                                                            'returnsOpenPrevMktres1'].interpolate(method='linear')\n    market_train_df.dropna(subset=input_features, inplace=True)\n    return market_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0296194feef5bafc936cd615c2b8bbdab40da7ce"},"cell_type":"code","source":"def fill_and_train_worker(asset_codes, l):\n    market_df = market_train_df.loc[market_train_df['assetCode'].isin(asset_codes)].copy()\n    filled_market_df = fill_market_df(market_df, asset_codes)\n    models = train_models(filled_market_df, asset_codes)\n    l.append(models)\n    \ndef fill_and_train_models(market_train_df, asset_codes): \n    div_asset_code = round(len(asset_codes) / 4)\n    NUM_PROCESSES = 4\n    models = {}\n    with multiprocessing.Manager() as manager: \n        p = multiprocessing.Pool(processes=NUM_PROCESSES)\n        l = manager.list()\n        for i in range(NUM_PROCESSES):\n            if i == (NUM_PROCESSES - 1): \n                portion_asset_codes = asset_codes[(i * div_asset_code):]\n            else: \n                portion_asset_codes = asset_codes[(i * div_asset_code): ((i+1) * div_asset_code)]\n            p.apply_async(fill_and_train_worker, args=(portion_asset_codes, l))\n        p.close()\n        p.join()\n        models = {**l[0], **l[1], **l[2], **l[3]}\n        \n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1ea64826197da9989f5d85148431af45a9ae9d4","scrolled":true},"cell_type":"code","source":"def train_my_model(market_train_df, news_train_df):\n    asset_codes = market_train_df['assetCode'].unique().tolist()\n    asset_names = market_train_df['assetName'].unique().tolist()\n    add_features_cols()\n    \n    output('add_day_feature_to_market_data... |  start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    add_day_feature_to_market_data(market_train_df, asset_codes)\n    e_time = time.time() - s_time\n    output('Took: {0} to add_day_feature_to_market_data'.format(str(timedelta(seconds=e_time))))\n    \n    output('add_features_to_market_data... | start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    add_features_to_training_data()\n    e_time = time.time() - s_time\n    output('Finished adding features to training data. Took: {0}'.format(str(timedelta(seconds=e_time))))\n    output('End time: {0}'.format(datetime.datetime.now()))\n    output('add_large_return_features... |  start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    add_large_return_features(market_train_df, num_std=1)\n    e_time = time.time() - s_time\n    output('Took: {0} to add large return features'.format(str(timedelta(seconds=e_time))))\n    output('add_pos_neg_return_features... |  start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    add_pos_neg_return_features(market_train_df)\n    e_time = time.time() - s_time\n    output('Took: {0} to add pos_neg_return features'.format(str(timedelta(seconds=e_time))))\n    output('fill_market_df & Train... |  start_time: {0}'.format(datetime.datetime.now()))\n    s_time = time.time()\n    models = fill_and_train_models(market_train_df, asset_codes)\n    #filled_market_df = fill_market_df(market_train_df, asset_codes) # parralelize\n    #e_time = time.time() - s_time\n    #print('Took: {0}'.format(str(timedelta(seconds=e_time))))\n    #print('Train Models...')\n    #s_time = time.time()\n    #models = train_models(filled_market_df, asset_codes) # parralelize\n    e_time = time.time() - s_time\n    output('Took: {0} to train models'.format(str(timedelta(seconds=e_time))))\n    output('done! train_my_model()')\n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ed96f806b4df2cf7419f683d576949e89c48c03","scrolled":true},"cell_type":"code","source":"models = train_my_model(market_train_df, news_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee56385411b83c05472c6c0aafed110ae9e56feb"},"cell_type":"code","source":"class tmp_classifier():\n    def predict_proba(X): \n        return [[0, 0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08762f9570e46fdeef7a8bda6e873abd19ed5ef7"},"cell_type":"code","source":"for asset_code, classifiers in models.items(): \n    if classifiers is None: \n        models[asset_code] = {\n            'pos_return_classifier': tmp_classifier, \n            'neg_return_classifier': tmp_classifier\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6f4ea02be4f387b095b610cc9c09a16df82af23"},"cell_type":"code","source":"def make_my_predictions(market_obs_df, news_obs_df, predictions_template_df): \n    global market_train_df\n    output('On date {0} |  current_time: {1}'.format(market_obs_df['time'].iloc[0], datetime.datetime.now()))\n    output('{0} | {1} | {2}'.format(len(predictions_template_df), len(market_obs_df), len(news_obs_df)))\n    for feature in features: \n        market_obs_df[feature] = np.NaN\n    for ind, row in market_obs_df.iterrows():\n        #market_obs_df.loc[ind, 'day'] = market_train_df.loc[market_train_df['assetCode'] == row['assetCode'],\n        #                                                    'day'].max() + 1\n        add_curr_day_news_features(market_obs_df, news_obs_df, row['assetName'], ind)\n        market_obs_df.loc[ind, 'returnsOpenPrevMktres1'] = market_obs_df.loc[ind, 'returnsOpenPrevMktres1'] if not np.isnan(market_obs_df.loc[ind, 'returnsOpenPrevMktres1']) else 0\n        X = market_obs_df.loc[[ind], input_features]\n        pred_ind = predictions_template_df.loc[predictions_template_df['assetCode'] == row['assetCode']].index\n        if row['assetCode'] in models: \n            predictions_template_df.loc[pred_ind, 'confidenceValue'] = models[row['assetCode']]['pos_return_classifier'].predict_proba(X)[0][0]\n        else: \n            predictions_template_df.loc[pred_ind, 'confidenceValue'] = 0\n    return predictions_template_df\n    # when I'm ready to add Moving avgs    \n    # market_obs_missing_cols = ['neg_target', 'large_neg_target', 'larget_pos_target', 'pos_target',\n    #                           'returnsOpenNextMktres10', 'universe']\n    # for missing_col in market_obs_missing_cols: \n    #     market_obs_df[missing_col] = np.NaN\n    # market_train_df = pd.concat([market_train_df, market_obs_df])\n    \n    # change to ffill with prev day data\n    # market_obs_df['returnsOpenPrevMktres1'] = market_obs_df['returnsOpenPrevMktres1'].fillna(0)\n    # for ind, row in predictions_template_df.iterrows(): \n    #    X = market_obs_df.loc[market_obs_df['assetCode'] == row['assetCode'], input_features]\n    #    if row['assetCode'] in models: \n    #        predictions_template_df.loc[ind, 'confidenceValue'] = models[row['assetCode']]['pos_return_classifier'].predict_proba(X)[0][0]\n    #    else: \n    #        predictions_template_df.loc[ind, 'confidenceValue'] = 0\n    # return predictions_template_df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a7e0f8a91102685cda77fcb9fdf5492b843187d"},"cell_type":"code","source":"days = env.get_prediction_days()\n#market_obs_df, news_obs_df, predictions_template_df = next(days)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"372bb501ac65ef09ae765f39a4a24a25716cbff7","scrolled":true},"cell_type":"code","source":"#predictions_df = make_my_predictions(market_obs_df, news_obs_df, predictions_template_df)\n#predictions_df\n#env.predict(predictions_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29d81dc578a948fe846ea3c789fde92ad22f8edd"},"cell_type":"code","source":"for (market_obs_df, news_obs_df, predictions_template_df) in days:\n    predictions_df = make_my_predictions(market_obs_df, news_obs_df, predictions_template_df)\n    env.predict(predictions_df)\n    \nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bde735979a6903afcf6ba7dd742dfea13b89368a"},"cell_type":"code","source":"e_time = time.time() - master_s_time\nprint('Total time: {0}'.format(e_time))\nMY_LOG.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e4a3c018b5254a64cc36f6940f15893f108e7b7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}