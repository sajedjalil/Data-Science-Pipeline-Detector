{"cells":[{"metadata":{"_uuid":"f4e7057e10b8d2ca2ed50a34d056df8f3d07f63d"},"cell_type":"markdown","source":"**A. Exploratory Data Analysis EDA**"},{"metadata":{"_uuid":"3ab514f9c0e54dc6a253fb8b180130289b09167f"},"cell_type":"markdown","source":"**Pour Bien Comprendre nos Datasets (NEWS & MARKET) , et découvrire la structure des données , on va utiliser l'approche EDA.**"},{"metadata":{"_uuid":"a28654c70638b0ab4605de8c89642ea2c0365ca5"},"cell_type":"markdown","source":"***1.Importer les Librairies et acquérir les données:***"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom itertools import chain\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"def04f87d7318bd15fd6952bdc2c94914bb2db08","trusted":true},"cell_type":"code","source":"(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e8af5e0b7e031960006651383bc3346852e5446"},"cell_type":"markdown","source":"On a deux datasets , on va traiter chacune à part"},{"metadata":{"_uuid":"ca2a1707a92fe249595e25b3fe301d1aa494b649"},"cell_type":"markdown","source":"***2.EDA pour Market Data:***"},{"metadata":{"_uuid":"3142a74aabe1c4745f431eceef8f352e8f5f9e5d","trusted":true},"cell_type":"code","source":"market_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94c333473e69ec84d06a2d786c3c0a57537b1a88","trusted":true},"cell_type":"code","source":"market_train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2f8bcb5e4ac9a5b928c9a4e45df025f7e4efa47","trusted":true},"cell_type":"code","source":"market_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdb0d5364d606705f4473f67fa3ce3cd4d5b9201"},"cell_type":"markdown","source":"Alors on constate que Market dataset contient 4072956 lignes et 16 colonnes. mais quelles sont ces colonnes?"},{"metadata":{"_uuid":"bdf666ce4e27da076b41a5fff24ac7555c3c9ca3","trusted":true},"cell_type":"code","source":"market_train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ad6907c32494db1905296b3944253cec65f39c0"},"cell_type":"markdown","source":"Maintenant , on a une idée sur les noms des colonnes , il reste qu'afficher le type de chaque colonne"},{"metadata":{"_uuid":"62d4625a0ca90221cb9dd28fc89583cabba3b4a1","trusted":true},"cell_type":"code","source":"market_train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"befb059e2590f22a56d7449ead8af0b882d21e3b"},"cell_type":"markdown","source":"Et voila , on trouve qu'il ya trois colonnes qui sont pas des float , c'est: time , AssetCode, et AssetName.\nMaintenant on peut extraire quelques statistiques pour ces données:"},{"metadata":{"_uuid":"800ccb8cab2d4e81f16bed4b3e0105d365710901","trusted":true},"cell_type":"code","source":"market_train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1aa71ad98be63112cdb263282138ed091689cee4"},"cell_type":"markdown","source":"D'abord , on a une idée générale sur nos données , il reste à decouvrire s'il ya des valeurs nulles dans le dataset ou pas:"},{"metadata":{"_uuid":"87c8e4a0d2ae225017401565cdd1f67b37fbadb2","scrolled":true,"trusted":true},"cell_type":"code","source":"market_train_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89714de600f89bc465e863577a973ad75d260c70"},"cell_type":"markdown","source":"On a 4 colonnes contenant les valeurs nulles, on va decouvrire le pourcentage de ces valeurs dans notre dataset et puis les visualiser:"},{"metadata":{"trusted":true,"_uuid":"6582e3c06c7ba0596453663994662aa6ccce62f5"},"cell_type":"code","source":"market_train_df.isnull().sum()*100/market_train_df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5dcfffc58c0318d3c16f5944636b5aeb68507c06"},"cell_type":"code","source":"import matplotlib.pyplot as plt\npercent = (market_train_df.isnull().sum()*100/market_train_df.shape[0]).sort_values(ascending=False)\npercent.plot(kind=\"bar\", figsize = (20,10), fontsize = 20)\nplt.xlabel(\"Columns\", fontsize = 20)\nplt.ylabel(\"Value Percent(%)\", fontsize = 20)\nplt.title(\"Total Missing Value by market_obs_df\", fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d363b7c7187b5e0cde87c084e7659f3734e848cd"},"cell_type":"markdown","source":"\nLes colonnes returnsClosePrevMktres1 , returnsOpenPrevMktres1,returnsClosePrevMktres10,returnsOpenPrevMktres1 ont des valeurs nulles , ces colonnes refèrent au Residual returns qui se calcule par la formule suivante:**mktres=raw−β*rmarket** .\nDans notre cas on peut pas calculer le β ,donc on va remplacer ces valeurs nulles par la médiane ou bien la moyenne , ça depends des outiliers qu'on va les visualiser tout de suite:\n"},{"metadata":{"trusted":true,"_uuid":"ac1a73ea8839b8c8282f9d844a5c98d970da7fdf"},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nmarket_train_df['returnsClosePrevMktres1'].plot(kind='box')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1e6030f933b86ff77f1d1cf6e3290f8fb644b3e"},"cell_type":"markdown","source":"Ici On a un nombre faible des outliers , donc on va savoir la distribution par rapport à la médiane et la moyenne:"},{"metadata":{"_uuid":"e90dbe54b5bbd15632dd54f0ca1e13a4bd29a80b"},"cell_type":"markdown","source":"![](http://)Par rapport à la moyenne:"},{"metadata":{"trusted":true,"_uuid":"a20290059d196b0e32428724efe61f579d4a59f3"},"cell_type":"code","source":"( market_train_df['returnsClosePrevMktres1']<market_train_df['returnsClosePrevMktres1'].mean()).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56631f0948d359f535f0214fad23c5b55581ff3a"},"cell_type":"markdown","source":"Par rapport à la médiane:"},{"metadata":{"trusted":true,"_uuid":"149a45bfa72ae168ad9afb5c9df839c1407185a1"},"cell_type":"code","source":"( market_train_df['returnsClosePrevMktres1']<market_train_df['returnsClosePrevMktres1'].median()).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8636606fb682b2b02ec90c1c5b212904e3ff58a"},"cell_type":"markdown","source":"* Donc on va remplacer par la moyenne:"},{"metadata":{"trusted":true,"_uuid":"6b6f09ffea2ded7a0bff4622648cf3cbe5562390"},"cell_type":"code","source":"market_train_df['returnsClosePrevMktres1'].fillna(market_train_df['returnsClosePrevMktres1'].mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a06979bd0cc231024fe63fe609952e73f7d0992e"},"cell_type":"code","source":"market_train_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82b81f2684371094831adf137a3714ce554033e8"},"cell_type":"markdown","source":"Passant maintenant au autres colonnes contenant les valeurs nulles:"},{"metadata":{"trusted":true,"_uuid":"02d9111d7b02025ec33c4290b36d847f71862013"},"cell_type":"code","source":"market_train_df['returnsOpenPrevMktres1'].plot.box()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5a6e02ecac5a618fb008474803d119973f4a678"},"cell_type":"code","source":"market_train_df['returnsClosePrevMktres10'].plot.box()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cb3eef9c56e2240fc3ac6ab4a986333fb3f3e07"},"cell_type":"code","source":"market_train_df['returnsOpenPrevMktres10'].plot.box()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5dbca0f0e9305dec677cbf811af9c2f92d2ae3f"},"cell_type":"markdown","source":"On a plusieurs ouliers , donc on va remplacer les valeurs nulles par la médiane:"},{"metadata":{"trusted":true,"_uuid":"3e893a500ec7c4f1ba0b0c8d612d6648cca47387"},"cell_type":"code","source":"market_train_df['returnsOpenPrevMktres1'].fillna(market_train_df['returnsOpenPrevMktres1'].median(),inplace=True)\nmarket_train_df['returnsClosePrevMktres10'].fillna(market_train_df['returnsClosePrevMktres10'].median(),inplace=True)\nmarket_train_df['returnsOpenPrevMktres10'].fillna(market_train_df['returnsOpenPrevMktres10'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c629a8753b3cb44acc1673cb5f55c5c322dbf41"},"cell_type":"code","source":"market_train_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9fea9275482669a0e2d0c9981e5075e2c471768"},"cell_type":"markdown","source":"Maintenant on a traité les valeurs nulles de Market Data , passant à l'exploration du News Data."},{"metadata":{"trusted":true,"_uuid":"bedd059642c26f123b902e4dbe2effebe97e3ebc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"78790b94ec91d8a866fa0050c75d48a652a596f4"},"cell_type":"markdown","source":"***3.EDA News Data***"},{"metadata":{"_uuid":"63e37b24b8b21eebdc159d19868060e7590fe740","scrolled":true,"trusted":true},"cell_type":"code","source":"news_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec521120e41f45a6f22ad9773aee12c7ade75ffd","trusted":true},"cell_type":"code","source":"news_train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75561b022f8c99123df00d7245e2d01383fa3115","trusted":true},"cell_type":"code","source":"news_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c22ca275105a7788b36660756171741641bff3d"},"cell_type":"markdown","source":"News dataset contient 9328750 ligne et 35 colonne."},{"metadata":{"_uuid":"03cf7155ecc6ec89b4b62e92d4442ad6db44d38a","trusted":true},"cell_type":"code","source":"news_train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3729ad6665ca4419093b06d2ded199ca6f925609","trusted":true},"cell_type":"code","source":"news_train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7dea82271702c575502c4e38b32564e54be0ff5","trusted":true},"cell_type":"code","source":"news_train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86c37cb1f0871bed6e36245d57c465b67a92f515"},"cell_type":"code","source":"news_train_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44019d7004f317efe97b635f4513598969ded8af"},"cell_type":"markdown","source":"alors on a pas de valeurs manquantes dans news dataset."},{"metadata":{"_uuid":"4467cf1ad512c59ff6f9efec47c09c68ebfa297e"},"cell_type":"markdown","source":"Maintenant on va retourner vers Market dataset et visualiser les prix des quelques  assetcodes "},{"metadata":{"_uuid":"49459160121772a63b1c9f66778764ff8c6ccf6c","trusted":true},"cell_type":"code","source":"import plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\ndata = []\nfor asset in np.random.choice(market_train_df['assetCode'].unique(), 10):\n    asset_df = market_train_df[(market_train_df['assetCode'] == asset)]\n\n    data.append(go.Scatter(\n        x = asset_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = asset_df['close'].values,\n        name = asset\n    ))\nlayout = go.Layout(dict(title = \"Closing prices of 10 random assets\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ad70d66170ce8030ed1c9d1f69038785fa15d72"},"cell_type":"markdown","source":"Normalement on a les données de 2007 jusqu'a maintenant , Or dans 2008 il y avait une crise mondiale s'appellle  la crise bancaire et financière de l'automne 2008 , donc on va jeter un coup d'eil sur les données de Market dans cette période:********"},{"metadata":{"trusted":true,"_uuid":"d0d3b764c8093a0fd2bb64f787131234b81da841"},"cell_type":"code","source":"market_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\nmarket_train_df.sort_values('price_diff')[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63224afc31819090a994e492a0acb0ed79f7f65c"},"cell_type":"markdown","source":"Donc, le prix des actions \"Towers Watson & Co\" et Bank of New York Mellon Corp  était presque 10k ... ce qui est anormale .\nMaintenant, on pense qu'il est temps de jeter une vieille partie du dataset. Laissons seulement les données depuis l'année 2009 , pour se  débarrasser des données de la plus grande crise."},{"metadata":{"trusted":true,"_uuid":"72c4d20ae9f70b63e19cdd23a6f55dd2369e5342"},"cell_type":"code","source":"news_train_df = news_train_df.loc[news_train_df['time'] >= '2009-01-01 22:00:00+0000']\nmarket_train_df = market_train_df.loc[market_train_df['time'] >= '2009-01-01 22:00:00+0000']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25a1b138f4e47d328661e19be69e4b44ebce9f1e"},"cell_type":"markdown","source":"**B.Features Engineering**"},{"metadata":{"_uuid":"8921ed822994daa8dc5b87e592b98404cf72f04f"},"cell_type":"markdown","source":"Dans l'approche Features Engineering , on essaye de garder les caractéristiques les plus pertinents et les plus utils dans notre étude , pour cela on va dans un premier moment , on va faire une étude de corrélation pour les données séparés , puis on va faire une jointure des deux tables (Market et News) et appliquer des modèles afin de savoir l'importance des Caractéristiques ."},{"metadata":{"_uuid":"f74bd81d9e90b2e94f503f4c1859d6b6cbd980ae"},"cell_type":"markdown","source":"***1.Market Dataset***"},{"metadata":{"_uuid":"5f68ae8515871700d4eebc8602561d6db5385c37"},"cell_type":"markdown","source":"On va savoir la corrélation entre les données du Market premièrement et puis la corrélation entre les caractéristiques et la cible"},{"metadata":{"trusted":true,"_uuid":"8f055cc1c122e0aa343b034ec5b33914b011cf9c"},"cell_type":"code","source":"corr=market_train_df.corr()\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,len(corr.columns),1)\nax.set_xticks(ticks)\nplt.xticks(rotation=90)\nax.set_yticks(ticks)\nax.set_xticklabels(corr.columns)\nax.set_yticklabels(corr.columns)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79fc30a4a8e98a743b54f3313d02d1cf3cbc8113"},"cell_type":"markdown","source":"Alors on constate qu'il ya des caractéristiques qui ont une forte corrélation entre eux et il ya ceux qui ont une faible corrélation entre eux , mais l'essentiel pour nous est de savoir la corrélation entre la cible et les autres caractéristiques"},{"metadata":{"trusted":true,"_uuid":"4203c0f77dedf04f4d2abc3c0e111efe3643f2da"},"cell_type":"code","source":"corr_with_mkt = market_train_df.corr()[\"returnsOpenNextMktres10\"].sort_values(ascending=False)\nplt.figure(figsize=(14,7))\ncorr_with_mkt.drop(\"returnsOpenNextMktres10\").plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0bb98696baf5e0544f66ffc747badb9cedd015a"},"cell_type":"markdown","source":"***2.News Dataset***"},{"metadata":{"trusted":true,"_uuid":"645517b09d7c74f5c1fb377cc52255d7ac48e41d"},"cell_type":"code","source":"corr2=news_train_df.corr()\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(corr2,cmap='coolwarm', vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,len(corr2.columns),1)\nax.set_xticks(ticks)\nplt.xticks(rotation=90)\nax.set_yticks(ticks)\nax.set_xticklabels(corr2.columns)\nax.set_yticklabels(corr2.columns)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"836a4853f217235f9efd48753ac3d3946e3a04c7"},"cell_type":"markdown","source":"Maintenant on veux savoir la corrélation entre les caractéristiques du news data et le sentiments class:"},{"metadata":{"trusted":true,"_uuid":"0ea3cd43e2598c7b70d2fd1ab77ff24e068d49bd"},"cell_type":"code","source":"corr_with_mkt = news_train_df.corr()[\"sentimentClass\"].sort_values(ascending=False)\nplt.figure(figsize=(14,7))\ncorr_with_mkt.drop(\"sentimentClass\").plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5a152941e9370dbd7f14cc9950e3349d636303c"},"cell_type":"markdown","source":"Maintenant , on va faire une jointure de données , et savoir l'importance de chaque caractéristique pour le returnsOpenNextMktres10 ."},{"metadata":{"_uuid":"3a51247cd86559b0d5fc2a16879140d9540df2f0"},"cell_type":"markdown","source":"Avant de faire la jointure , on va prendre que 1_500_000 ligne du market data et 3_500_000 du News data."},{"metadata":{"trusted":true,"_uuid":"31b4d4e59596dfedc8c7f26bfbc19322cd0fdec5"},"cell_type":"code","source":"market = market_train_df.head(1_500_000)\nnews = news_train_df.head(3_500_000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"397d4460af7803f1ba4951b5f4867c4f64de324f"},"cell_type":"code","source":"news_cols_agg = {\n    'urgency': ['min', 'count'],\n    'takeSequence': ['max'],\n    'bodySize': ['min', 'max', 'mean'],\n    'wordCount': ['min', 'max', 'mean'],\n    'sentenceCount':['min', 'max', 'mean'],\n    'companyCount': ['min', 'max', 'mean'],\n    'relevance': ['min', 'max', 'mean'],\n    'sentimentClass': ['min', 'max', 'mean'],\n    'sentimentNegative': ['min', 'max', 'mean'],\n    'sentimentNeutral': ['min', 'max', 'mean'],\n    'sentimentPositive': ['min', 'max', 'mean'],\n    'sentimentWordCount': ['min', 'max', 'mean'],\n    'noveltyCount12H': ['min', 'max', 'mean'],\n    'noveltyCount24H': ['min', 'max', 'mean'],\n    'noveltyCount3D': ['min', 'max', 'mean'],\n    'noveltyCount5D': ['min', 'max', 'mean'],\n    'noveltyCount7D':['min', 'max', 'mean'],\n    'volumeCounts12H': ['min', 'max', 'mean'],\n    'volumeCounts24H': ['min', 'max', 'mean'],\n    'volumeCounts3D': ['min', 'max', 'mean'],\n    'volumeCounts5D': ['min', 'max', 'mean'],\n    'volumeCounts7D': ['min', 'max', 'mean']\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd8565abad71a661228daa7e94531abe956f73c1"},"cell_type":"markdown","source":"La fonction pour faire la jointure"},{"metadata":{"trusted":true,"_uuid":"f491fdda58ecbc26cc6460721b2fa35e435a68a4"},"cell_type":"code","source":"def merge_data(news_train_df,market_train_df):\n    #rendre les assetCodes dans une liste\n    news_train_df['assetCodes'] = news_train_df['assetCodes'].str.findall(f\"'([\\w\\./]+)'\")\n    news_train_df.time= news_train_df.time.dt.date\n    market_train_df.time= market_train_df.time.dt.date\n    #faire sortir élément par élément de la liste\n    assetCodes_expanded = list(chain(*news_train_df['assetCodes']))\n    #création d'un array ayant les indexes répétés de chaque ligne dupliquée\n    assetCodes_index = news_train_df.index.repeat( news_train_df['assetCodes'].apply(len) )\n    #Création d'un dataframe contenant les assetCodes et leurs indexes\n    df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n    # Creation d'un news dataframe où les lignes sont répétées\n    news_cols = ['time', 'assetCodes'] + sorted(news_cols_agg.keys())\n    #je dois ajouter get dummies pour provider à ce niveau là\n    news_train_df_expanded = pd.merge(df_assetCodes, news_train_df[news_cols], left_on='level_0',\n                                  right_index=True, suffixes=(['','_old']))\n     # Free memory\n    del news_train_df, df_assetCodes\n    news_train_df_aggregated = news_train_df_expanded.groupby(['time', 'assetCode']).agg(news_cols_agg)\n     # Free memory\n    del news_train_df_expanded\n    # Convert to float32 to save memory\n    news_train_df_aggregated = news_train_df_aggregated.apply(np.float32)\n    # Flat columns\n    news_train_df_aggregated.columns = ['_'.join(col).strip() for col in news_train_df_aggregated.columns.values]\n    # Join with train\n    market_train_df = market_train_df.join(news_train_df_aggregated, on=['time', 'assetCode'])\n    # Free memory\n    del news_train_df_aggregated\n    return market_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"190906ac78dbb9c3762812cd0d45f01505774bf4"},"cell_type":"code","source":"data_m=merge_data(news,market)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79143b6b6f5a7d67ae4480e0616d8fc4486a3a55"},"cell_type":"markdown","source":"On va se debarasser des valeurs nulles :"},{"metadata":{"trusted":true,"_uuid":"3d7921238a9230cad6d6e5965203457459c60c6e"},"cell_type":"code","source":"data_m=data_m.dropna()\ndata_m.shape ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b878d7ae0a10b9d07c6a3cf321fcde0af604c144"},"cell_type":"markdown","source":"et voila on a obtenu 414779 lignes de données. Maintenant il reste à decouvrire la corrélation entre la cible et les autres colonnes"},{"metadata":{"trusted":true,"_uuid":"5a1e277a2514773c83ea9ce7b1a1076ed78fe43a"},"cell_type":"code","source":"corr_with_mkt1 = data_m.corr()[\"returnsOpenNextMktres10\"].sort_values(ascending=False)\nplt.figure(figsize=(14,7))\ncorr_with_mkt1.drop(\"returnsOpenNextMktres10\").plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7a2e93956e6ea5c75677ddc9afe1d10d595557e"},"cell_type":"markdown","source":"Il ya des caractéristiques qui ont une forte corrélation avec la cible et il ya ceux qui ont une faible corrélation , maintenat on va appliquer quelques modèles pour savoir l'importance de ces caractéristiques , mais avant ça il faut préparer ces données"},{"metadata":{"trusted":true,"_uuid":"21bbbea4e8309724f3ca4e66907f5c6df4d162dc"},"cell_type":"code","source":"Y=data_m.returnsOpenNextMktres10.values \ndata_f=data_m.drop(['returnsOpenNextMktres10'],axis=1)\ndata_final=data_f.drop(['assetName'],axis=1) #On a deja l'assetCode ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9cba49138acd384268b2a7449bc451936f2a1fb"},"cell_type":"code","source":"print(data_final.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dce484553f09e75a4df3f999b236433d5d68ac9f"},"cell_type":"markdown","source":"Alors il faut avoir le meme type (float64) pour tous les données"},{"metadata":{"trusted":true,"_uuid":"af94e85c3e3e77576ebab7d89c91978e9ebd5931"},"cell_type":"code","source":"from sklearn import preprocessing\ndel data_final['time']\nle = preprocessing.LabelEncoder()\nle.fit(data_final['assetCode'])\ndata_final['assetCode']=le.fit_transform(data_final['assetCode'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a3dbece008a58846fd4690be201e8fbd92ae88e"},"cell_type":"code","source":"data_final=data_final.astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33ebf06aa01c500da3c8cf187fa9f81799d0ca6c"},"cell_type":"code","source":"print(data_final.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cdc5983234a2d7a303f61441c852eff9392723e8"},"cell_type":"markdown","source":"Maintenant les données sont prets , il reste à appliquer les modèles "},{"metadata":{"trusted":true,"_uuid":"c95abe1df79070aae57a9720dce7e18673a23b53"},"cell_type":"code","source":"X=data_final.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ebbb5b05138d0abb86ecc15298a3f95c7c44623"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler,Imputer\n# définir un dictionnaire pour stocker nos rankings \nranks = {}\n# créer une fonction qui stocke le classement des caractéristiques \ndef ranking(ranks, names, order=1):\n    minmax = MinMaxScaler()\n    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n    ranks = map(lambda x: round(x,2), ranks)\n    return dict(zip(names, ranks))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2026a7b2e4b588d6dc87d829534fe597555628d6"},"cell_type":"markdown","source":"Parmis les algorithmes qu'on va appliquer , on trouve LinearRegression, Ridge, Lasso et LogisticRegression, puis on va extraire l'importance de chaque caractéristique pour chaque algorithme et faire la moyenne par la suite :"},{"metadata":{"trusted":true,"_uuid":"7236e6363bb120be03450587e8173d715c603d8f"},"cell_type":"code","source":"from sklearn.feature_selection import RFE, f_regression\nfrom sklearn.preprocessing import StandardScaler\nX_scaled=StandardScaler().fit_transform(X)\nfrom sklearn.linear_model import (LinearRegression, Ridge, Lasso,LogisticRegression)\ncolnames=data_final.columns\nlr = LinearRegression(normalize=True)\nlr.fit(X_scaled,Y)\nranks[\"LinReg\"] = ranking(np.abs(lr.coef_), colnames)\n\n#  Ridge \nridge = Ridge(alpha = 7)\nridge.fit(X_scaled,Y)\nranks['Ridge'] = ranking(np.abs(ridge.coef_), colnames)\n\n#  Lasso\nlasso = Lasso(alpha=.05)\nlasso.fit(X_scaled, Y)\nranks[\"Lasso\"] = ranking(np.abs(lasso.coef_), colnames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cecb28dceee8de1f3a0045691f3a36af30781b45"},"cell_type":"code","source":"r = {}\nfor name in colnames:\n    r[name] = round(np.mean([ranks[method][name] \n                             for method in ranks.keys()]), 2)\n \nmethods = sorted(ranks.keys())\nranks[\"Mean\"] = r\nmethods.append(\"Mean\")\n \nprint(\"\\t%s\" % \"\\t\".join(methods))\nfor name in colnames:\n    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n                         [ranks[method][name] for method in methods]))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f2c5a37296387ea05e15d4d1f0c89e840fe69c4"},"cell_type":"code","source":"# mettre la moyenne dans un dataframe Pandas\nmeanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])\n\n# Trier le  dataframe\nmeanplot = meanplot.sort_values('Mean Ranking', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"752eb4ad4110e3b4d4ad22048fdf5cc9f3047f72"},"cell_type":"code","source":"import seaborn as sns\nsns.factorplot(x=\"Mean Ranking\", y=\"Feature\", data = meanplot, kind=\"bar\", \n               size=20, aspect=1.9, palette='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63d5b6375608f3506e0b4709f4e395d413ad2d2f"},"cell_type":"markdown","source":"Maintenant on va prendre que les caractéristiques qui ont une importance pour notre cible"},{"metadata":{"trusted":true,"_uuid":"665213cffdb64efe71f2ef361cf995c2a938148b"},"cell_type":"code","source":"features=list(meanplot[meanplot['Mean Ranking']!=0].Feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5e210f070f67dd3f06bc5712052d6d5b5103796"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}