{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/24800/logos/header.png?t=2020-12-17-19-26-15\">\n<center>\n    <h1 style=\"color:red;font-weight:900;font-size:2.5em\">VinBigData Chest X-ray Abnormalities Detection</h1>\n    <h3>Automatically localize and classify thoracic abnormalities from chest radiographs</h3>\n</center>\n<br>\n<br>\n<hr>\n<h2 style=\"color:blue;font-weight:600\"> About Competition </h2>\n<p>\n    Radiologists diagnose and treat medical conditions using imaging techniques like CT and PET scans, MRIs, and, of course, X-rays. Yet, as it happens when working with such a wide variety of medical tools, radiologists face many daily challenges, perhaps the most difficult being the chest radiograph. The interpretation of chest X-rays can lead to medical misdiagnosis, even for the best practicing doctor. Computer-aided detection and diagnosis systems (CADe/CADx) would help reduce the pressure on doctors at metropolitan hospitals and improve diagnostic quality in rural areas.\n</p>\n<p>\n    In this competition we are to predict the thoracic abnormalities in given X-Ray images and also locate those abnormalities. The data provided include:\n    <ul>\n    <li>Train and Test X-Ray images in folders <b style=\"font-weight:700\">Train</b> and <b style=\"font-weight:700\">Test</b>\n    <li> sample submission file in sample_submission.csv\n    <li> train dataframe in train.csv\n    </ul>\n</p>\n<hr>\n<br>\n<a id=\"home\"></a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\" style=\"background: rgb(49,114,163);\nbackground: radial-gradient(circle, rgba(49,114,163,1) 0%, rgba(26,136,181,1) 15%, rgba(1,159,200,1) 52%, rgba(0,212,255,1) 60%, rgba(0,182,224,1) 64%, rgba(0,145,186,1) 69%, rgba(1,66,104,1) 82%, rgba(2,33,70,1) 95%, rgba(24,23,50,1) 100%);\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\"style=\"background: rgb(49,114,163);\nbackground: radial-gradient(circle, rgba(49,114,163,1) 0%, rgba(26,136,181,1) 15%, rgba(1,159,200,1) 52%, rgba(0,212,255,1) 60%, rgba(0,182,224,1) 64%, rgba(0,145,186,1) 69%, rgba(1,66,104,1) 82%, rgba(2,33,70,1) 95%, rgba(24,23,50,1) 100%);\">Table of Contents</h3>\n    <center>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#first\" role=\"tab\" aria-controls=\"profile\">First Look at the Data<span class=\"badge badge-primary badge-pill\">1</span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#second\" role=\"tab\" aria-controls=\"profile\">EDA<span class=\"badge badge-primary badge-pill\">2</span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#third\" role=\"tab\" aria-controls=\"profile\">An insight of the Data<span class=\"badge badge-primary badge-pill\">2</span></a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#fourth\" role=\"tab\" aria-controls=\"messages\">Data Preparation<span class=\"badge badge-primary badge-pill\">3</span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#fifth\" role=\"tab\" aria-controls=\"messages\">Model Building and training<span class=\"badge badge-primary badge-pill\">4</span></a>\n    </center>\n</div>\n<hr>\n<h1 style=\"color:red\">Note:</h1>\n<h5 style=\"color:red\">The utilities_x_ray module used here is a script that I have written(can be found <a href=\"https://www.kaggle.com/bibhash123/utilities-x-ray\">here</a>). It contains some functions for visualization of the X-Ray images. The dicom image reading pipeline is taken from <a href=\"https://www.kaggle.com/raddar/popular-x-ray-image-normalization-techniques\"> this Notebook</a> by <a href=\"https://www.kaggle.com/raddar\">@raddar</a></h5>\n<h5 style=\"color:red\">The numpy files dataset used in this notebook can be found <a href=\"https://www.kaggle.com/bibhash123/xraynumpy\">Here</a></h5>"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:blue\">Updates:</h2>\n<ul>\n    <li>Improved data loading speed by using numpy files dataset</li>\n    <li>Implemented Kfold cross validation</li>\n    <li>Wrote a training and prediction loop</li>\n</ul>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport random\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport seaborn as sns\nimport pandas as pd\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom utilities_x_ray import read_xray,showXray\nfrom tqdm import tqdm\nimport pydicom\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seedAll(seed=355):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    random.seed(seed)\nseedAll()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"display:inline\"> <a id=\"first\"> First Look at the data</a></h1>&emsp;&emsp;&emsp;&emsp;&emsp;<a href=\"#home\" style=\"color:blue\"><img src=\"https://toppng.com/uploads/preview/light-blue-up-arrow-11550117759k4je61afsa.png\" style=\"display:inline;width:2em;height:2em\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## 1. DataFrames"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\nss = pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<ul>\n<li><code>image_id</code> - unique image identifier</li>\n<li><code>class_name</code>&nbsp;- the name of the class of detected object (or \"No finding\")</li>\n<li><code>class_id</code>&nbsp;- the ID of the class of detected object</li>\n<li><code>rad_id</code>&nbsp;- the ID of the radiologist that made the observation</li>\n<li><code>x_min</code>&nbsp;- minimum X coordinate of the object's bounding box</li>\n<li><code>y_min</code>&nbsp;- minimum Y coordinate of the object's bounding box</li>\n<li><code>x_max</code>&nbsp;- maximum X coordinate of the object's bounding box</li>\n<li><code>y_max</code>&nbsp;- maximum Y coordinate of the object's bounding box</li>\n</ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The submission file must contain the image id and the prediction string in the format \"a b (c,d,e,f)\"<br>where\n<ul>\n    <li>a = predicted class ; 14 for no abnormality</li>\n    <li>b= confidence</li>\n    <li>(c,d,e,f) = (x_min,y_min,x_max,y_max)</li>\n</ul>"},{"metadata":{},"cell_type":"markdown","source":"## 2. Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,10))\nplt.imshow(read_xray('../input/vinbigdata-chest-xray-abnormalities-detection/train/0108949daa13dc94634a7d650a05c0bb.dicom'),cmap=plt.cm.bone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showXray('../input/vinbigdata-chest-xray-abnormalities-detection/train/0108949daa13dc94634a7d650a05c0bb.dicom',train,with_boxes=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"display:inline\"><a id=\"second\">EDA</a></h1>&emsp;&emsp;&emsp;&emsp;&emsp;<a href=\"#home\" style=\"color:blue\"><img src=\"https://toppng.com/uploads/preview/light-blue-up-arrow-11550117759k4je61afsa.png\" style=\"display:inline;width:2em;height:2em\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Number of rows in train dataframe: {}\".format(train.shape[0]))\nprint(\"Number of Unique images in train set: {}\".format(train.image_id.nunique()))\nprint(\"Number of Classes: {}\\n\".format(train.class_name.nunique()))\nprint(\"Class Names: {}\".format(list(train.class_name.unique())))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Null Values:\")\ntrain.isna().sum().to_frame().rename(columns={0:'Null Value count'}).style.background_gradient('viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of null values are same as the number of samples that do not have any abnormality"},{"metadata":{},"cell_type":"markdown","source":"### The Distribution of Classes\nWe can see there is a huge class imbalance. The number of negative examples are very high and a few abnormalities have very few examples "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\nsns.countplot(train[\"class_id\"]);\nplt.title(\"Class Distributions\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of Radiologists"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\nsns.countplot(train[\"rad_id\"]);\nplt.title(\"rad_id Distributions\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"display:inline\"><a id=\"third\"> An Intuition of the Data</a></h1>&emsp;&emsp;&emsp;&emsp;&emsp;<a href=\"#home\" style=\"color:blue\"><img src=\"https://toppng.com/uploads/preview/light-blue-up-arrow-11550117759k4je61afsa.png\" style=\"display:inline;width:2em;height:2em\"></a><br><br>\n<h5>Before proceeding further let us try and get an intuition of the data and what exactly we need to do.</h5>\n<h5> In this competition we have been given 15000 images for training. Parallelly we have a dataframe containing the ground truths for various abnormalities. Every sample in the datframe contains:</h5>\n  <ul>\n      <li>the image id</li><li>the id of the radiologist who annoted it</li><li>the name of the corresponding class</li><li>the class id</li><li>the bounding box coordinates</li>\n  </ul>\n<b style=\"font-weight:700\">Important points to be noted here are:</b>\n<ul>\n    <li>Each image may have multiple corresponding abnormalities. Therefore this is a multilabel prediction</li>\n    <li>Bounding boxes for each image have been annoted by multiple radiologists. Therefore for every sample we have multiple ground truths. A naive way to deal with this is to take mean of bounding box coordinates by every radiologists for a particular abnormality</li>\n    <li>There is a significant class imbalance which is likely to affect the performance of models a lot.</li>\n</ul>\n<h4 style=\"font-weight:700\">Information about dicom can be found: <a href=\"https://en.wikipedia.org/wiki/DICOM\" style=\"font-size:1em\">Here</a></h4>\n<h4 style=\"font-weight:700\">Procedure to extract DICOM metadata can be found in: <a href=\"https://www.kaggle.com/mrutyunjaybiswal/vbd-chest-x-ray-abnormalities-detection-eda\" style=\"font-size:1em\">this notebook</a></h4>"},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"display:inline\"><a id=\"fourth\">Data Preparation</a></h1>&emsp;&emsp;&emsp;&emsp;&emsp;<a href=\"#home\" style=\"color:blue\"><img src=\"https://toppng.com/uploads/preview/light-blue-up-arrow-11550117759k4je61afsa.png\" style=\"display:inline;width:2em;height:2em\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = sorted(train.class_name.unique())\ndel class_names[class_names.index('No finding')]\nclass_names = class_names+['No finding']\nclasses = dict(zip(list(range(15)),class_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareDataFrame(train_df= train):\n    train_df = train_df.fillna(0)\n    cols = ['image_id','label']+list(range(4*len(class_names[:-1])))\n    return_df = pd.DataFrame(columns=cols)\n    \n    for image in tqdm(train_df.image_id.unique()):\n        df = train_df.query(\"image_id==@image\")\n        label = np.zeros(15)\n        for cls in df.class_id.unique():\n            label[int(cls)]=1\n        bboxes_df = df.groupby('class_id')[['x_min','y_min','x_max','y_max']].mean().round()\n        \n        bboxes_list = [0 for i in range(60)]\n        for ind in list(bboxes_df.index):\n            bboxes_list[4*ind:4*ind+4] = list(bboxes_df.loc[ind,:].values)\n        return_df.loc[len(return_df),:] = [image]+[label]+bboxes_list[:-4]\n    return return_df\ntrain_df = prepareDataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generateFolds(n_splits = None):\n    kf = KFold(n_splits= n_splits)\n    for id,(tr_,val_) in enumerate(kf.split(train_df[\"image_id\"],train_df[\"label\"])):\n        train_df.loc[val_,'kfold'] = int(id)\n    train_df[\"kfold\"].astype(int)\n\ngenerateFolds(n_splits=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataLoader:\n    def __init__(self,path = None,train_df=train_df,val_df=None):\n        self.path = path\n        self.df = train_df\n        self.val_df = val_df\n        self.train_list = [f'{img}.npy' for img in train_df[\"image_id\"].unique()]\n        np.random.shuffle(self.train_list)\n        self.test_list = [f'{img}.npy' for img in val_df[\"image_id\"].unique()]\n        np.random.shuffle(self.test_list)\n    \n    def read_image(self):\n        for img in self.train_list:\n            im_name = img.split('.npy')[0]\n            image = np.load(self.path+img)\n            temp = self.df[self.df.image_id==im_name]\n            c_label,bb = temp.iloc[0,1],temp.iloc[0,2:].values.astype('float')\n            yield image,c_label,bb\n    \n    \n    def batch_generator(self,items,batch_size):\n        a=[]\n        i=0\n        for item in items:\n            a.append(item)\n            i+=1\n\n            if i%batch_size==0:\n                yield a\n                a=[]\n        if len(a) is not 0:\n            yield a\n            \n    def flow(self,batch_size):\n        \"\"\"\n        flow from given directory in batches\n        ==========================================\n        batch_size: size of the batch\n        \"\"\"\n        while True:\n            for bat in self.batch_generator(self.read_image(),batch_size):\n                batch_images = []\n                batch_c_labels = []\n                batch_bb = []\n                for im,im_c_label,im_bb in bat:\n                    batch_images.append(im)\n                    batch_c_labels.append(im_c_label)\n                    batch_bb.append(im_bb)\n                batch_images = np.stack(batch_images,axis=0)\n                batch_labels =  (np.stack(batch_c_labels,axis=0),np.stack(batch_bb,axis=0))\n                yield batch_images,batch_labels\n    \n    def getVal(self):\n        images = []\n        c_labels = []\n        bb_labels = []\n        for img in self.test_list:\n            im_name = img.split('.npy')[0]\n            image = np.load(self.path+img)\n            temp = self.val_df[self.val_df.image_id==im_name]\n            c_label,bb = temp.iloc[0,1],temp.iloc[0,2:].values.astype('float')\n            images.append(image)\n            c_labels.append(c_label)\n            bb_labels.append(bb)\n        return np.stack(images,axis=0),(np.stack(c_labels,axis=0),np.stack(bb_labels,axis=0))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"display:inline\"><a id=\"fifth\">Model Building and Training</a></h1>&emsp;&emsp;&emsp;&emsp;&emsp;<a href=\"#home\" style=\"color:blue\"><img src=\"https://toppng.com/uploads/preview/light-blue-up-arrow-11550117759k4je61afsa.png\" style=\"display:inline;width:2em;height:2em\"></a>"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"def build():\n    in1 = L.Input(shape=(256,256,1))\n    \n    out1 = L.Conv2D(32,(3,3),activation=\"relu\")(in1)\n    out1 = L.Conv2D(32,(3,3),activation=\"relu\")(out1)\n    out1 = L.MaxPooling2D((2,2))(out1)\n    \n    out1 = L.Conv2D(64,(3,3),activation=\"relu\")(out1)\n    out1 = L.Conv2D(64,(3,3),activation=\"relu\")(out1)\n    out1 = L.MaxPooling2D((2,2))(out1)\n    \n    out1 = L.Conv2D(128,(3,3),activation=\"relu\")(out1)\n    out1 = L.Conv2D(128,(3,3),activation=\"relu\")(out1)\n    out1 = L.MaxPooling2D((2,2))(out1)\n    out1 = L.Flatten()(out1)\n    \n    out2 = L.Dense(50,activation=\"relu\",kernel_initializer=\"lecun_normal\")(out1)\n    out2 = L.Dense(30,activation=\"relu\",kernel_initializer=\"lecun_normal\")(out2)\n    out2 = L.Dense(15,activation=\"sigmoid\",kernel_initializer=\"lecun_normal\",name='class_out')(out2)\n    \n    out3 = L.Dense(50,activation=\"relu\",kernel_initializer=\"lecun_normal\")(out1)\n    out3 = L.Dense(30,activation=\"relu\",kernel_initializer=\"lecun_normal\")(out3)\n    out3 = L.Dense(56,activation=\"relu\",kernel_initializer=\"lecun_normal\",name=\"bb_out\")(out3)\n    \n    model = tf.keras.Model(inputs=in1,outputs=[out2,out3])\n    model.compile(loss={'class_out':'categorical_crossentropy','bb_out':'mse'},optimizer=\"adam\")\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"model = build()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Training Loop</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getTest(path=None):\n    images = []\n    for img in tqdm(os.listdir(path)):\n        im_name = img.split('.npy')[0]\n        image = np.load(path+img)\n        images.append(image)\n    return np.stack(images,axis=0)\n\nX_test = getTest('../input/xraynumpy/images/test/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_label = np.zeros((len(X_test),15))\nbb_label = np.zeros((len(X_test),56))\n\nfor fold in range(5):\n    print(f'\\nFold: {fold}\\n')\n    \n    X_train = train_df[train_df.kfold!=fold].drop('kfold',axis=1)\n    X_val = train_df[train_df.kfold==fold].drop('kfold',axis=1)\n    \n    dl = DataLoader('../input/xraynumpy/images/train/',X_train,X_val)\n    train_set = dl.flow(batch_size=32)\n    X_eval,Y_eval = dl.getVal()\n    \n    chckpt = tf.keras.callbacks.ModelCheckpoint(f'./model_f{fold}.hdf5',monitor='val_loss',mode='min',save_best_only=True)\n    \n    K.clear_session()\n    model = build()\n    \n    model.fit(train_set,\n             epochs=10,\n              steps_per_epoch=int(15000/32),\n              validation_data = (X_eval,Y_eval),\n              callbacks = [chckpt]\n             )\n    \n    c,b = model.predict(X_test)\n    class_label+=c\n    bb_label+=b\nclass_label = class_label/5\nbb_label = bb_label/5\nnp.save('./class_label.npy',class_label)\nnp.save('./bb_label.npy',bb_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Work in Progress....\n<h2 style=\"color:blue\">To Do:</h2>\n<ul>\n    <li><h2 style=\"color:blue\">1.Implement submission pipeline</h2></li>\n    <li><h2 style=\"color:blue\">2.Implement an evaluation metric corresponding to competition evaluation criteria</h2></li>\n    <li><h2 style=\"color:blue\">3.Choose better loss functions</h2></li>\n</ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}