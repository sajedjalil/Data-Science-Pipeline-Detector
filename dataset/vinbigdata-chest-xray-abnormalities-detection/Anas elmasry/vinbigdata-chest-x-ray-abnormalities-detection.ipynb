{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport pydicom\nfrom tqdm import tqdm\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\"\ndf = pd.read_csv(path)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#path_1 = \"../input/vinbigdata-chest-xray-abnormalities-detection/train/47ed17dcb2cbeec15182ed335a8b5a9e.dicom\"\n#dicom = pydicom.read_file(path_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    \"\"\" Convert dicom file to numpy array \n    \n    Args:\n        path (str): Path to the dicom file to be converted\n        voi_lut (bool): Whether or not VOI LUT is available\n        fix_monochrome (bool): Whether or not to apply monochrome fix\n        \n    Returns:\n        Numpy array of the respective dicom file \n        \n    \"\"\"\n    dicom = pydicom.read_file(path)      # Use the pydicom library to read the dicom file\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":#MONOCHROME1\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.float32)#uint8\n        \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train/'\next = '.dicom'\n\ndata = read_xray(root + df.image_id[64] + ext)\nplt.imshow(data, 'gray');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df\nk = np.random.randint(0,len(data))  #selecting random integer for plotting XRAY\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_id = data.image_id[k]\nimg_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_name = data.class_name[k]\nclass_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_id+ext","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_path = os.path.join(root, img_id+ext)\n#dicom_pixel = read_xray(img_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_xray(data, root=root, ext=ext):\n    fig, axs = plt.subplots(3,3, figsize=(16,18))\n    \n    for i in range(9):\n        k = np.random.randint(0,len(data))  #selecting random integer for plotting XRAY\n        img_id = data.image_id[k]\n        class_name = data.class_name[k]\n        \n        img_path = os.path.join(root, img_id+ext)\n        dicom_pixel = read_xray(img_path)\n        \n        axs[i//3,i%3].imshow(dicom_pixel, cmap='gray')\n        axs[i//3,i%3].title.set_text(class_name)\n    plt.show()\n\n#show_xray(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0 - Aortic enlargement\n1 - Atelectasis\n2 - Calcification\n3 - Cardiomegaly\n4 - Consolidation\n5 - ILD\n6 - Infiltration\n7 - Lung Opacity\n8 - Nodule/Mass\n9 - Other lesion\n10 - Pleural effusion\n11 - Pleural thickening\n12 - Pneumothorax\n13 - Pulmonary fibrosis\n14 - No finding"},{"metadata":{"trusted":true},"cell_type":"code","source":"#used label encoder\ncode = {'Aortic enlargement':0 ,'Atelectasis':1,'Calcification':2,'Cardiomegaly':3,'Consolidation':4,\n        'ILD':5,'Infiltration':6,'Lung Opacity':7,'Nodule/Mass':8,\n        'Other lesion':9,'Pleural effusion':10,'Pleural thickening':11,'Pneumothorax':12,'Pulmonary fibrosis':13,'No finding':14}\n\ndef getcode(n) : \n    for x , y in code.items() : \n        if n == y : \n            return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nroot = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train/'\nimg_path = glob.glob('/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train/*.*')\nlen(img_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dicom_pixel = read_xray(img_path[5620])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(dicom_pixel, 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_path[500]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_batch = np.random.choice(df.index, size=16)\nimages_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.index\nprint(data[15010])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\"\ndf_1 = pd.read_csv(path)\nroot = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train/'\next = '.dicom'\ndata = df_1\nX_train = []\ny_train = []\ni=0\ns=128\nfor file in tqdm(data.index): \n    img_id = data.image_id[file]#take image ID\n    #class_name = data.class_name[file]\n    idx = data.class_id[file]#take image class ID (0 1 .....14)\n    \n    img_path = os.path.join(root, img_id+ext)\n    dicom_pixel = read_xray(img_path)\n    \n    image_array = cv2.resize(dicom_pixel , (s,s), interpolation = cv2.INTER_AREA)\n    \n    X_train.append(list(image_array))\n    y_train.append(idx)#code[class_name]\n    if (file == 1):\n        break\n'''    else:\n        i=i+1'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the shape of low resolution image (LR) for resize\npath = \"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\"\ndf_1 = pd.read_csv(path)\ndata = df_1\nroot = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train/'\next = '.dicom'\nimage_shape = (224, 224)\nimg_path = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train/*.*'\ndef sample_images(batch_size, image_shape):\n    \n    # create the list of all images, which are inside of data_dir catalogue\n    #all_images = glob.glob(data_dir)\n    \n    # select a random batch with images\n    images_batch = np.random.choice(15000, size=batch_size)#total_images\n\n    X_train = []\n    y_train = []\n\n    for img in images_batch:\n        # take the numpy ndarray from the current image\n        img_id = data.image_id[img]\n        idx = data.class_id[img]#take image class ID (0 1 .....14)\n        img_path = os.path.join(root, img_id+ext)\n        dicom_pixel = read_xray(img_path)\n        image_array = cv2.resize(dicom_pixel , image_shape, interpolation = cv2.INTER_AREA)\n        X_train.append(list(image_array))\n        y_train.append(idx)#code[class_name]\n        \n    X_train=np.array(X_train)\n    X_train = X_train.reshape(-1,224,224,1)\n    y_train=to_categorical(y_train)\n    # convert lists into numpy ndarrays\n    return X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(images_batch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 8\n(X_train,y_train)= sample_images(batch_size, image_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPool2D,BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import SGD,Adam,RMSprop,Adagrad\nfrom keras.regularizers import l1\nimport numpy as np\nnp.random.seed(512)\n\ns = 224\nmodel = Sequential()\n#model.add(BatchNormalization(input_shape=(s,s,1)))\nmodel.add(Conv2D(16, kernel_size=(3,3), padding='same', activation='relu',input_shape=(s,s,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#,activity_regularizer=l1(0.000001)\n\nmodel.add(Conv2D(32, kernel_size=(3,3),padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3),padding='same', activation='relu'))#\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128, kernel_size=(3,3),padding='same', activation='relu')) \nmodel.add(Conv2D(64, kernel_size=(3,3),padding='same', activation='relu'))\n\nmodel.add(Conv2D(256, kernel_size=(3,3),padding='same', activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3,3),padding='same', activation='relu'))#64,101\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.08))\n\nmodel.add(Flatten())\nmodel.add(Dense(2024, activation='relu'))\nmodel.add(Dropout(0.13))\n\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.13))\n\nmodel.add(Dense(4096, activation='relu'))\n#model.add(Dropout(0.11))\nmodel.add(Dense(2024, activation='relu'))#1024\n#model.add(Dropout(0.11))\nmodel.add(Dense(15, activation='softmax'))\n\n\n\n#=========================================================================================\n\nmodel.summary()\n\nopt = Adam(learning_rate=0.00001)\n# Compile the model\nmodel.compile(loss=tensorflow.keras.losses.categorical_crossentropy, optimizer=opt, metrics=[\"categorical_accuracy\"]) #categorical_accuracy\n# plot model architecture\nplot_model(model, show_shapes=True, to_file='Covid-19_Model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#del model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n#ModelCheckpoint means save best weights\nmodel_chkpt = ModelCheckpoint('best_mod.h5', save_best_only=True, monitor='accuracy')\nlearning_rate_reduction1 = ReduceLROnPlateau(monitor='val_loss', \n                                             patience=2, verbose=1, factor=0.5,mode=\"min\", min_lr=0.0000001)\nlearning_rate_reduction2 = ReduceLROnPlateau(monitor='loss', \n                                             patience=2, verbose=1, factor=0.5,mode=\"min\", min_lr=0.000001)\n\nearly_stopping = EarlyStopping(monitor='val_categorical_accuracy', restore_best_weights=False, patience=20)#val_loss,val_categorical_accuracy\ncallbacks1=[early_stopping,learning_rate_reduction2,learning_rate_reduction1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#del history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#(X_train,y_train)= sample_images(batch_size, image_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FAST_RUN=True\n#if FAST_RUN else 6\nbatch_size1=128\nbatch_size2=8\nbatch_size3=64\nepochs1=32\nfor epoch in range(epochs1):\n    print(epoch)\n    (X_train,y_train)= sample_images(batch_size1, image_shape)\n    (X_test,y_test)= sample_images(batch_size3, image_shape)\n    history = model.fit(X_train, y_train ,epochs=2,validation_data=(X_test, y_test),\n                        batch_size=batch_size2, shuffle=True, callbacks=callbacks1)#, verbose=1\n    print(\"========================================================================================\")\n    \n#validation_data=(X_test, y_test),validation_split=0.20,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(12, 3))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}