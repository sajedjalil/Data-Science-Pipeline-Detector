{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Summary\nThe purpose of this kernel is that summarizing the result of several model output.  It seems that QDA and GMM had higher CV score than other models. Ensembling models got slightly better score but not boosting... so we need more explor something like make_classification method..\n\n## Single Models\n- [1. QDA with VarianceThreshold and StandardScaler](#1)\n   - CV: 0.96476\n- [2. QDA with PCA](#2)\n   - CV: 0.96457\n- [3. GaussianMixture with VarianceThreshold](#3)\n   - CV: 0.96748\n- [4. Logistic Regression with VarianceThreshold, PolynomialFeatures and StandardScaler](#4)\n   - CV: 0.95049\n- [5. LabelSpreading with VarianceThreshold](#5)\n   - CV: 0.93674\n- [6. kNN with VarianceThreshold and StandardScaler](#6)\n   - CV: 0.91593\n- [7. NN with PolynomialFeatures and StandardScaler](#7)\n   - CV: 0.94289\n\n## Single Model with Pseued Label\n- [P1. GSearch QDA with Pseued Label by GaussianMixture](#p1)\n   - CV: 0.96861\n\n## Blending\n- [AVG Blending](#b1)\n   - CV: 0.968017\n\n## Stacking\n- [Logistic Regression](#s1)\n    - CV: 0.969105"},{"metadata":{},"cell_type":"markdown","source":"## Preparation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import FeatureAgglomeration\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.covariance import GraphicalLasso\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.semi_supervised import LabelSpreading\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import Pipeline\nimport warnings\nimport multiprocessing\nfrom scipy.optimize import minimize  \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def load_data(data):\n    return pd.read_csv(data)\n    \nwith multiprocessing.Pool() as pool:\n    train, test, sub = pool.map(load_data, ['../input/train.csv', '../input/test.csv', '../input/sample_submission.csv'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Single Models"},{"metadata":{},"cell_type":"markdown","source":"<div id=\"1\">\n</div>\n## 1. QDA with VarianceThreshold and StandardScaler and get best paramater by GSearch\n- [VarianceThreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html): Removes all low-variance features (under threshold)\n- [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html): Standardize features by removing the mean and scaling to unit variance\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_qda1 = np.zeros(len(train))\npreds_qda1 = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = np.arange(0.1, 0.5, 0.1) # [0.1 0.2, 0.3, 0.4, 0.5]\nparameters = [{'reg_param': params}]\nreg_params = np.zeros(512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    test2.reset_index(drop=True, inplace=True)\n    \n    steps = [\n        ('vt', VarianceThreshold(threshold=2)),\n        ('sscaler', StandardScaler()),\n        #('rscaler', RobustScaler()),\n        #('mmscaler', MinMaxScaler())\n    ]\n    \n    pipe = Pipeline(steps=steps)\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n    \n    skf = StratifiedKFold(n_splits=11, random_state=42)\n    for train_index, test_index in skf.split(train2, train2['target']):\n\n        qda = QuadraticDiscriminantAnalysis()\n        clf = GridSearchCV(qda, parameters, cv=4)\n        clf.fit(train3[train_index,:], train2.loc[train_index]['target'])\n        reg_params[i] = clf.best_params_['reg_param']\n        oof_qda1[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds_qda1[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('QDA with VarianceThreshold and StandardScaler CV Score =',round(roc_auc_score(train['target'], oof_qda1), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_qda1\nsub['target'].to_csv('submission_qda1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_qda1\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"2\">\n</div>\n## 2. QDA with PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_qda2 = np.zeros(len(train))\npreds_qda2 = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict = dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor s in range(512):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==s]\n    test2 = test[test['wheezy-copper-turtle-magic']==s]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    \n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n        \n    dict[s] = train3.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    test2.reset_index(drop=True, inplace=True)  \n    \n    steps = [\n        #('pca', PCA(n_components=dict[i], random_state=42))\n        ('scaler', StandardScaler()), \n        ('fa', FeatureAgglomeration(n_clusters=dict[i]))\n    ]\n    \n    pipe = Pipeline(steps=steps)\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n\n    skf = StratifiedKFold(n_splits=11, random_state=42)\n    for train_index, test_index in skf.split(train2, train2['target']):\n\n        clf = QuadraticDiscriminantAnalysis(0.5)\n        clf.fit(train3[train_index,:], train2.loc[train_index]['target'])\n        oof_qda2[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds_qda2[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('QDA with PCA CV Score =',round(roc_auc_score(train['target'], oof_qda2), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_qda2\nsub.to_csv('submission_qda2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_qda2\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"3\">\n</div>\n## 3. GaussianMixture with VarianceThreshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_gmm = np.zeros(len(train))\npreds_gmm = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mean_cov(x, y):\n    \n    model = GraphicalLasso()\n    ones = (y==1).astype(bool)\n    x2 = x[ones]\n    model.fit(x2)\n    p1 = model.precision_\n    m1 = model.location_\n    \n    onesb = (y==0).astype(bool)\n    x2b = x[onesb]\n    model.fit(x2b)\n    p2 = model.precision_\n    m2 = model.location_\n    \n    ms = np.stack([m1,m2])\n    ps = np.stack([p1,p2])\n    \n    return ms, ps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    test2.reset_index(drop=True, inplace=True)\n    \n    steps = [\n        ('vt', VarianceThreshold(threshold=1.5))\n    ]\n    \n    pipe = Pipeline(steps=steps)\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n    \n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        ms, ps = get_mean_cov(train3[train_index,:], train2.loc[train_index]['target'].values)\n        \n        clf = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001, reg_covar=0.001, max_iter=100, n_init=1, means_init=ms, precisions_init=ps)\n        clf.fit(np.concatenate([train3,test3],axis = 0))\n        oof_gmm[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,0]\n        preds_gmm[idx2] += clf.predict_proba(test3)[:,0] / skf.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('GaussianMixture with VarianceThreshold CV Score =',round(roc_auc_score(train['target'], oof_gmm), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_gmm\nsub.to_csv('submission_gmm.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_gmm\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"4\">\n</div>\n## 4. Logistic Regression with VarianceThreshold, PolynomialFeatures and StandardScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_lr = np.zeros(len(train))\npreds_lr = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    test2.reset_index(drop=True, inplace=True)\n    \n    steps = [\n        ('vt', VarianceThreshold(threshold=1.5)),\n        ('poly', PolynomialFeatures(degree=2)),\n        ('sc', StandardScaler())\n    ]\n    \n    pipe = Pipeline(steps=steps)\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n    \n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n                \n        clf = LogisticRegression(solver='saga', penalty='l2', C=0.01, tol=0.001, n_jobs=-1)\n        clf.fit(train3[train_index,:], train2.loc[train_index]['target'])\n        oof_lr[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds_lr[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Logistic Regression with VarianceThreshold CV Score =',round(roc_auc_score(train['target'], oof_lr), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_lr\nsub.to_csv('submission_lr.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_lr\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"5\">\n</div>\n## 5. LabelSpreading with VarianceThreshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_ls = np.zeros(len(train))\npreds_ls = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    test2.reset_index(drop=True, inplace=True)\n    \n    steps = [\n        ('vt', VarianceThreshold(threshold=1.5))\n    ]\n    \n    pipe = Pipeline(steps=steps)\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n    \n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        clf = LabelSpreading(gamma=0.01, kernel='rbf', max_iter=10)\n        clf.fit(train3[train_index,:], train2.loc[train_index]['target'])\n        oof_ls[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds_ls[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LabelSpreading with VarianceThreshold CV Score =',round(roc_auc_score(train['target'], oof_ls), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_ls\nsub.to_csv('submission_ls.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_ls\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"6\">\n</div>\n## 6. kNN with VarianceThreshold and StandardScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_knn = np.zeros(len(train))\npreds_knn = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    test.reset_index(drop=True, inplace=True)\n    \n    steps = [\n        ('vt', VarianceThreshold(threshold=2)),\n        ('scaler', StandardScaler())\n    ]\n    \n    pipe = Pipeline(steps=steps)\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n    \n    skf = StratifiedKFold(n_splits=11, random_state=42)\n    for train_index, test_index in skf.split(train2, train2['target']):\n\n        clf = KNeighborsClassifier(n_neighbors=17, p=2.9, n_jobs=-1)\n        clf.fit(train3[train_index,:], train2.loc[train_index]['target'])\n        oof_knn[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds_knn[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('kNN with VarianceThreshold and StandardScaler CV Score =',round(roc_auc_score(train['target'], oof_knn), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_knn\nsub.to_csv('submission_knn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_knn\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"7\">\n</div>\n## 7. NN with PolynomialFeatures and StandardScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_nn = np.zeros(len(train))\npreds_nn = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    test2.reset_index(drop=True, inplace=True)\n    \n    steps = [\n        ('vt', VarianceThreshold(threshold=1.5)),\n        ('poly', PolynomialFeatures(degree=2)),\n        ('sc', StandardScaler())\n        # log scale\n    ]\n    \n    pipe = Pipeline(steps=steps)\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = pipe.fit_transform(data[cols])\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n    \n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n                \n        clf = MLPClassifier(random_state=3, activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250, ))\n        clf.fit(train3[train_index,:], train2.loc[train_index]['target'])\n        oof_nn[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds_nn[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('NN with PolynomialFeatures and StandardScaler CV Score =',round(roc_auc_score(train['target'], oof_nn), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_nn\nsub.to_csv('submission_nn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_nn\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div id=\"p1\">\n</div>\n## P1. GSearch QDA with Pseued Label by GaussianMixture"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_qda3 = np.zeros(len(train))\npreds_qda3 = preds_gmm.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in range(10):\n    \n    test['target'] = preds_qda3\n    test.loc[test['target'] > 0.955, 'target'] = 1\n    test.loc[test['target'] < 0.045, 'target'] = 0\n    usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n    new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n    \n    print(usefull_test.shape[0], \"Test Record added for iteration : \", i + 1)\n    \n    new_train.loc[oof_qda3 > 0.995, 'target'] = 1\n    new_train.loc[oof_qda3 < 0.005, 'target'] = 0\n    \n    oof_qda3 = np.zeros(len(train))\n    preds_qda = np.zeros(len(test))\n    \n    for i in tqdm_notebook(range(512)):\n\n        train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n        test2 = test[test['wheezy-copper-turtle-magic']==i]\n        idx1 = train[train['wheezy-copper-turtle-magic']==i].index\n        idx2 = test2.index\n        train2.reset_index(drop=True, inplace=True)\n        test2.reset_index(drop=True, inplace=True)\n        \n        steps = [\n            ('vt', VarianceThreshold(threshold=1.5)),\n            ('scaler', StandardScaler())\n        ]\n        \n        pipe = Pipeline(steps=steps)\n        train3 = pipe.fit_transform(train2[cols])\n        test3 = pipe.fit_transform(test2[cols])\n        \n        skf = StratifiedKFold(n_splits=11, random_state=42)\n        for train_index, test_index in skf.split(train2, train2['target']):\n            oof_test_index = [t for t in test_index if t < len(idx1)]\n            \n            clf = QuadraticDiscriminantAnalysis(reg_params[i])\n            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n            if len(oof_test_index) > 0:\n                oof_qda3[idx1[oof_test_index]] = clf.predict_proba(train3[oof_test_index,:])[:,1]\n            preds_qda3[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n    \n    print('QDA with Pseued Label by GaussianMixture CV Score =',round(roc_auc_score(train['target'], oof_qda3), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_qda3\nsub.to_csv('submission_gda3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_qda3\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"p2\">\n</div>\n## P2. GSearch QDA with Pseued Label by QDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_qda4 = oof_qda1.copy()\npreds_qda4 = preds_qda1.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in range(10):\n    \n    test['target'] = preds_qda4\n    test.loc[test['target'] > 0.955, 'target'] = 1\n    test.loc[test['target'] < 0.045, 'target'] = 0\n    usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n    new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n    \n    print(usefull_test.shape[0], \"Test Record added for iteration : \", i + 1)\n    \n    new_train.loc[oof_qda4 > 0.995, 'target'] = 1\n    new_train.loc[oof_qda4 < 0.005, 'target'] = 0\n    \n    oof_qda4= np.zeros(len(train))\n    preds_qd4 = np.zeros(len(test))\n    \n    for i in tqdm_notebook(range(512)):\n\n        train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n        test2 = test[test['wheezy-copper-turtle-magic']==i]\n        idx1 = train[train['wheezy-copper-turtle-magic']==i].index\n        idx2 = test2.index\n        train2.reset_index(drop=True, inplace=True)\n        test2.reset_index(drop=True, inplace=True)\n        \n        steps = [\n            ('vt', VarianceThreshold(threshold=1.5)),\n            ('scaler', StandardScaler())\n        ]\n        \n        pipe = Pipeline(steps=steps)\n        train3 = pipe.fit_transform(train2[cols])\n        test3 = pipe.fit_transform(test2[cols])\n        \n        skf = StratifiedKFold(n_splits=11, random_state=42)\n        for train_index, test_index in skf.split(train2, train2['target']):\n            oof_test_index = [t for t in test_index if t < len(idx1)]\n            \n            clf = QuadraticDiscriminantAnalysis(reg_params[i])\n            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n            if len(oof_test_index) > 0:\n                oof_qda4[idx1[oof_test_index]] = clf.predict_proba(train3[oof_test_index,:])[:,1]\n            preds_qda4[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n    \n    print('GSearch QDA with Pseued Label by QDA CV Score =',round(roc_auc_score(train['target'], oof_qda3), 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_qda4\nsub.to_csv('submission_gda3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_qda4\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensembling"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('All Model CV Score Summary')\nprint('---------------------------------')\nprint('1. QDA with VarianceThreshold and StandardScaler', roc_auc_score(train['target'], oof_qda1))\nprint('2. QDA with PCA', roc_auc_score(train['target'], oof_qda2))\nprint('3. GaussianMixture with VarianceThreshold', roc_auc_score(train['target'], oof_gmm))\nprint('4. Logistic Regression with PolynomialFeatures and StandardScaler', roc_auc_score(train['target'], oof_lr))\nprint('5. LabelSpreading with VarianceThreshold', roc_auc_score(train['target'], oof_ls))\nprint('6. kNN with VarianceThreshold and StandardScaler', roc_auc_score(train['target'], oof_knn))\nprint('P1. QDA with Pseued Label by GaussianMixture', roc_auc_score(train['target'], oof_qda3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_list = [preds_qda1, preds_qda2, preds_gmm, preds_lr, preds_ls, preds_knn, preds_nn, preds_qda3]\noof_list = [oof_qda1, oof_qda2, oof_gmm, oof_lr, oof_ls, oof_knn, oof_nn, oof_qda3]\nprint('The number of model is {}'.format(len(preds_list)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"b1\">\n</div>\n## AVG Blending"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_avg = sum(oof_list) / len(oof_list)\npreds_avg = sum(preds_list) / len(preds_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{} model blend CV score ='.format(len(preds_list)),round(roc_auc_score(train['target'], oof_avg),6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_avg\nsub.to_csv('submission_blend_avg.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_avg\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stacking Model Blending"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_blend = np.zeros(len(train))\npreds_knn = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_blend = 0.5*(oof_qda3 + oof_qda4)\npreds_blend = 0.5*(preds_qda3 + preds_qda4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Stacking model blend CV score =',round(roc_auc_score(train['target'], oof_blend),6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_blend\nsub.to_csv('submission_blend.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = preds_blend\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stacking"},{"metadata":{},"cell_type":"markdown","source":"<div id=\"s1\">\n</div>    \n## Logistic Regression Stacking"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_qda1 = oof_qda1.reshape(-1, 1)\noof_qda2 = oof_qda2.reshape(-1, 1)\noof_gmm = oof_gmm.reshape(-1, 1)\noof_lr = oof_lr.reshape(-1, 1)\noof_ls = oof_ls.reshape(-1, 1)\noof_knn = oof_knn.reshape(-1, 1)\noof_nn = oof_nn.reshape(-1, 1)\noof_qda3 = oof_qda3.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_qda1 = preds_qda1.reshape(-1, 1)\npreds_qda2 = preds_qda2.reshape(-1, 1)\npreds_gmm = preds_gmm.reshape(-1, 1)\npreds_lr = preds_lr.reshape(-1, 1)\npreds_ls = preds_ls.reshape(-1, 1)\npreds_knn = preds_knn.reshape(-1, 1)\npreds_nn = preds_nn.reshape(-1, 1)\npreds_qda3 = preds_qda3.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_stck = np.concatenate([oof_qda1, oof_qda2, oof_gmm, oof_lr, oof_ls, oof_knn, oof_nn, oof_qda3], axis=1)\ntest_stack = np.concatenate([preds_qda1, preds_qda2, preds_gmm, preds_lr, preds_ls, preds_knn, preds_nn, preds_qda3], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_stack = np.zeros(len(train)) \npred_stack = np.zeros(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for train_index, test_index in skf.split(train_stck, train['target']):\n    clf = LogisticRegression(solver='saga', penalty='l2', C=0.01, tol=0.001)\n    clf.fit(train_stck[train_index], train['target'][train_index])\n    oof_stack[test_index] = clf.predict_proba(train_stck[test_index,:])[:,1]\n    pred_stack += clf.predict_proba(test_stack)[:,1] / skf.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{} model stack CV score ='.format(len(preds_list)),round(roc_auc_score(train['target'], oof_stack),6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = pred_stack\nsub.to_csv('submission_stack.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target'] = pred_stack\nsub['target'].hist(bins=100, alpha=0.6)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}