{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src = \"https://storage.googleapis.com/kaggle-forum-message-attachments/543450/13399/Untitled.jpg\" width = \"400\"></img>"},{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"# <a id='0'>Content</a>\n\n- <a href='#1'>1. Read the data</a>\n- <a href='#2'>2. Data Understanding</a>\n- <a href='#3'>3. Data Exploration</a>\n - <a href='#7'>3.1 Distribution of Y variable</a>\n - <a href='#8'>3.2 Distribution of X variables</a>\n - <a href='#9'>3.3 Correlation</a>\n- <a href='#4'>4. Magic Feature</a>\n- <a href='#5'>5. Model (LR)</a>\n - <a href='#10'>5.1 Model w/o Magic feature</a>\n - <a href='#11'>5.2 Model with Magic feature</a>\n- <a href='#6'>6. Model (QDA)</a>"},{"metadata":{},"cell_type":"markdown","source":"## <a id='1'>1. Read the data</a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import necessary libraries\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input path\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/instant-gratification/train.csv')\ntest  = pd.read_csv('/kaggle/input/instant-gratification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='2'>2. Data Understanding</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='3'>3. Data Exploration</a>"},{"metadata":{},"cell_type":"markdown","source":"### <a id='7'>3.1 Distribution of Y variable</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train.target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion: \nTarget variable seems to be equally distributed"},{"metadata":{},"cell_type":"markdown","source":"### <a id='8'>3.2 Distribution of X variables</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_distplot(df, features):\n    i = 0\n    plt.figure()\n    fig, ax = plt.subplots(4,4,figsize=(14,14))\n\n    for feature in features:\n        i += 1\n        plt.subplot(4,4,i)\n        sns.distplot(df[feature])\n        plt.xlabel(feature, fontsize=9)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [col for col in train.columns if col not in [\"id\", \"target\"]]\n\n# distribution plot for first 16 variables\nplot_feature_distplot(train, cols[0:16])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion: \nAll 'X' variables seems to be normally distributed."},{"metadata":{},"cell_type":"markdown","source":"### <a id='9'>3.3 Correlation</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[16,9])\nsns.heatmap(train[cols].corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion: \nFrom heatmap, it seems to be there is no relation between 'X' variables."},{"metadata":{},"cell_type":"markdown","source":"## <a id='4'>4. Magic Feature</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes[train.dtypes == np.int64]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There are two 'int' type columns in train dataset\n1. wheezy-copper-turtle-magic\n2. target"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['wheezy-copper-turtle-magic'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Column 'wheezy-copper-turtle-magic' can be treated as numeric or category."},{"metadata":{},"cell_type":"markdown","source":"### Here, we are gong to build the model by considering both options\n1. Treat the column 'wheezy-copper-turtle-magic' as numeric\n2. Treat the column 'wheezy-copper-turtle-magic' as category"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['wheezy-copper-turtle-magic'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train set')\nprint('Minimum value of wheezy-copper-turtle-magic:',train['wheezy-copper-turtle-magic'].min())\nprint('Maximum value of wheezy-copper-turtle-magic:',train['wheezy-copper-turtle-magic'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='5'>5. Model (LR)</a>"},{"metadata":{},"cell_type":"markdown","source":"### <a id='10'>5.1 Model w/o Magic Feature</a>"},{"metadata":{},"cell_type":"markdown","source":"### Here, we consider the column 'wheezy-copper-turtle-magic' as numeric and build the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [c for c in train.columns if c not in ['id', 'target']]\noof = np.zeros(len(train))\n\n# Stratified K-fold\nskf = StratifiedKFold(n_splits=5)\n \nfor train_idx, val_idx in skf.split(train[cols], train['target']):\n    \n    # LR model\n    clf = LogisticRegression()\n    clf.fit(train.loc[train_idx][cols], train.loc[train_idx]['target'])\n    oof[val_idx] = clf.predict_proba(train.loc[val_idx][cols])[:,1]\n\nauc = roc_auc_score(train['target'],oof)\nprint('LR CV score w/o Magic feature =',round(auc,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='11'>5.2 Model with Magic Feature</a>"},{"metadata":{},"cell_type":"markdown","source":"### Here, we consider the column 'wheezy-copper-turtle-magic' as category and build 512 models for each value"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"cols = [c for c in train.columns if c not in ['id', 'target']]\n\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\n\n# Build 512 models\nfor i in range(512):\n    \n    # train the data for each value of 'wheezy-copper-turtle-magic'\n    train1 = train[train['wheezy-copper-turtle-magic']==i]     \n    \n    idx1 = train1.index\n    train1.reset_index(drop = True, inplace = True)\n    \n    # Stratified K-fold\n    skf = StratifiedKFold(n_splits = 5)     \n    \n    for train_idx, val_idx in skf.split(train1[cols], train1['target']):\n        \n        # LR model \n        clf = LogisticRegression(solver = 'liblinear', penalty = 'l1', C = 0.05)\n        clf.fit(train1.loc[train_idx][cols], train1.loc[train_idx]['target'])\n        oof[idx1[val_idx]] = clf.predict_proba(train1.loc[val_idx][cols])[:,1]\n    \nauc = roc_auc_score(train['target'],oof)       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LR CV score with Magic feature =',round(auc,4)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion: \nWe can see huge difference in the CV score with Magic feature\n1. LR, CV score without Magic feature: 0.53\n2. LR, CV score with Magic feature:    0.79"},{"metadata":{},"cell_type":"markdown","source":"## <a id='6'>6. Model (QDA)</a>"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"cols = [c for c in train.columns if c not in ['id', 'target']]\n\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\n\n# Build 512 models\nfor i in range(512):\n    \n    # train the data for each value of 'wheezy-copper-turtle-magic'\n    train1 = train[train['wheezy-copper-turtle-magic']==i]     \n    \n    idx1 = train1.index\n    train1.reset_index(drop = True, inplace = True)\n    \n    # Dropping low-variance features (fit and transform)\n    sel = VarianceThreshold(threshold = 1.5).fit(train1[cols])\n    train2 = sel.transform(train1[cols])\n    \n    # Stratified K-fold\n    skf = StratifiedKFold(n_splits = 5)     \n    \n    for train_idx, val_idx in skf.split(train2, train1['target']):\n        \n        # QDA model \n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train2[train_idx,:], train1.loc[train_idx]['target'])\n        oof[idx1[val_idx]] = clf.predict_proba(train2[val_idx,:])[:,1]\n    \nauc = roc_auc_score(train['target'],oof)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('QDA, CV score =',round(auc,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Summary\n\nQDA outperforms LR and other models as well.\n\nThe dataset most likely was produced by sklearn.datasets make_classification. This method generates clusters of gaussians with non-diagonal covariance matrix and assigns them classes. QDA works exactly with this structure of data, it learns normal distributions with n-dimentional covariance matrix.\n\nQDA works by finding the multivariate Gaussian distribution of target=1 and finding the multivariate Gaussian distribution of target=0. A multivariate Gaussian distribution is an hyper-ellipsoid in p dimensional space where p is the number of variables.\n\nFor more information, please refer:\nhttps://www.kaggle.com/c/instant-gratification/discussion/93843"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}