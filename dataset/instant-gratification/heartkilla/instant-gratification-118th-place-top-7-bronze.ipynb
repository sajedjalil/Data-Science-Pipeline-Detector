{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Instant Gratification Solution (118th place, top 7%, bronze medal)"},{"metadata":{},"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-media/competitions/general/Kerneler-white-desc2_transparent.png)"},{"metadata":{},"cell_type":"markdown","source":"## 1. Dependencies and utility functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependencies\nimport subprocess\nimport re\nimport sys\nimport os\nimport glob\nimport warnings\nimport ctypes\nimport time\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.decomposition import PCA\nfrom sklearn.covariance import GraphicalLasso\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.pipeline import Pipeline\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimization code to make BLAS single-threaded\n\n_MKL_ = 'mkl'\n_OPENBLAS_ = 'openblas'\n\n\nclass BLAS:\n    def __init__(self, cdll, kind):\n        if kind not in (_MKL_, _OPENBLAS_):\n            raise ValueError(f'kind must be {MKL} or {OPENBLAS}, got {kind} instead.')\n        \n        self.kind = kind\n        self.cdll = cdll\n        \n        if kind == _MKL_:\n            self.get_n_threads = cdll.MKL_Get_Max_Threads\n            self.set_n_threads = cdll.MKL_Set_Num_Threads\n        else:\n            self.get_n_threads = cdll.openblas_get_num_threads\n            self.set_n_threads = cdll.openblas_set_num_threads\n            \n\ndef get_blas(numpy_module):\n    LDD = 'ldd'\n    LDD_PATTERN = r'^\\t(?P<lib>.*{}.*) => (?P<path>.*) \\(0x.*$'\n\n    NUMPY_PATH = os.path.join(numpy_module.__path__[0], 'core')\n    MULTIARRAY_PATH = glob.glob(os.path.join(NUMPY_PATH, '_multiarray_umath.*so'))[0]\n    ldd_result = subprocess.run(\n        args=[LDD, MULTIARRAY_PATH], \n        check=True,\n        stdout=subprocess.PIPE, \n        universal_newlines=True\n    )\n\n    output = ldd_result.stdout\n\n    if _MKL_ in output:\n        kind = _MKL_\n    elif _OPENBLAS_ in output:\n        kind = _OPENBLAS_\n    else:\n        return\n\n    pattern = LDD_PATTERN.format(kind)\n    match = re.search(pattern, output, flags=re.MULTILINE)\n\n    if match:\n        lib = ctypes.CDLL(match.groupdict()['path'])\n        return BLAS(lib, kind)\n    \n\nclass single_threaded:\n    def __init__(self, numpy_module=None):\n        if numpy_module is not None:\n            self.blas = get_blas(numpy_module)\n        else:\n            import numpy\n            self.blas = get_blas(numpy)\n\n    def __enter__(self):\n        if self.blas is not None:\n            self.old_n_threads = self.blas.get_n_threads()\n            self.blas.set_n_threads(1)\n        else:\n            warnings.warn(\n                'No MKL/OpenBLAS found, assuming NumPy is single-threaded.'\n            )\n\n    def __exit__(self, *args):\n        if self.blas is not None:\n            self.blas.set_n_threads(self.old_n_threads)\n            if self.blas.get_n_threads() != self.old_n_threads:\n                message = (\n                    f'Failed to reset {self.blas.kind} '\n                    f'to {self.old_n_threads} threads (previous value).'\n                )\n                raise RuntimeError(message)\n    \n    def __call__(self, func):\n        def _func(*args, **kwargs):\n            self.__enter__()\n            func_result = func(*args, **kwargs)\n            self.__exit__()\n            return func_result\n        return _func","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Models"},{"metadata":{},"cell_type":"markdown","source":"### 2.1. QDA with PL from GL+GMM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function that estimates mean and covariance using Graphical Lasso model\ndef get_mean_cov(x,y):\n    model = GraphicalLasso(alpha=0.05)\n    ones = (y==1).astype(bool)\n    x2 = x[ones]\n    model.fit(x2)\n    p1 = model.precision_\n    m1 = model.location_\n    \n    onesb = (y==0).astype(bool)\n    x2b = x[onesb]\n    model.fit(x2b)\n    p2 = model.precision_\n    m2 = model.location_\n    \n    ms = np.stack([m1, m2])\n    ps = np.stack([p1, p2])\n    return ms, ps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train GMM model\n\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\nwith single_threaded(np):\n    for i in tqdm(range(512)):\n        train2 = train[train['wheezy-copper-turtle-magic']==i]\n        test2 = test[test['wheezy-copper-turtle-magic']==i]\n        idx1 = train2.index; idx2 = test2.index\n        train2.reset_index(drop=True,inplace=True)\n\n        sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n        train3 = sel.transform(train2[cols])\n        test3 = sel.transform(test2[cols])\n\n        skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n        for train_index, test_index in skf.split(train3, train2['target']):\n\n            ms, ps = get_mean_cov(train3[train_index, :],train2.loc[train_index]['target'].values)\n\n            gm = GaussianMixture(n_components=2, init_params='kmeans', covariance_type='full',\n                                 tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,\n                                 means_init=ms, precisions_init=ps, random_state=1)\n            gm.fit(np.concatenate([train3, test3], axis = 0))\n            oof[idx1[test_index]] = gm.predict_proba(train3[test_index, :])[:, 0]\n            preds[idx2] += gm.predict_proba(test3)[:, 0] / skf.n_splits\n\nauc = roc_auc_score(train['target'], oof)\nprint('GMM CV: ',round(auc, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collect numbers of useful features using Variance Threshold\n# to use them in PCA as n_components\n\ncat_dict = dict()\n\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\n\nfor i in range(512):\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n        \n    cat_dict[i] = train3.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train QDA model with PL from GMM\n\ntest['target'] = preds\noof1 = np.zeros(len(train))\npreds1 = np.zeros(len(test))\n\nwith single_threaded(np):\n    for k in tqdm(range(512)):\n        train2 = train[train['wheezy-copper-turtle-magic']==k] \n        train2p = train2.copy(); idx1 = train2.index \n        test2 = test[test['wheezy-copper-turtle-magic']==k]\n        \n        # Using pseudolabels with confidence <= 0.15 or >= 0.85\n        test2p = test2[(test2['target']<=0.15) | (test2['target']>=0.85)].copy()\n        test2p.loc[test2p['target']>=0.5, 'target'] = 1\n        test2p.loc[test2p['target']<0.5, 'target'] = 0 \n        train2p = pd.concat([train2p, test2p], axis=0)\n        train2p.reset_index(drop=True, inplace=True)\n\n        sel = VarianceThreshold(threshold=1.5)\n        sel.fit(train2p[cols])\n        train3p = sel.transform(train2p[cols])\n        train3 = sel.transform(train2[cols])\n        test3 = sel.transform(test2[cols])\n\n        skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n        for train_index, test_index in skf.split(train3p, train2p['target']):\n            test_index3 = test_index[test_index < len(train3)]\n            clf = QuadraticDiscriminantAnalysis(reg_param=0.4)\n            clf.fit(train3p[train_index, :],train2p.loc[train_index]['target'])\n            oof1[idx1[test_index3]] += clf.predict_proba(train3[test_index3, :])[:, 1]\n\n            preds1[test2.index] += clf.predict_proba(test3)[:, 1] / skf.n_splits\n        \nauc = roc_auc_score(train['target'], oof1)\nprint('Model 1 CV: ', round(auc, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. PCA+QDA with PL from GL+GMM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train PCA+QDA using previously computed predictions from GMM \n# and PCA n_components\ntest['target'] = preds\noof2 = np.zeros(len(train))\npreds2 = np.zeros(len(test))\n\nwith single_threaded(np):\n    for k in tqdm(range(512)):\n        train2 = train[train['wheezy-copper-turtle-magic']==k] \n        train2p = train2.copy(); idx1 = train2.index \n        test2 = test[test['wheezy-copper-turtle-magic']==k]\n\n        # Using pseudolabels with confidence <= 0.2 or >= 0.8\n        test2p = test2[(test2['target']<=0.2) | (test2['target']>=0.8)].copy()\n        test2p.loc[test2p['target']>=0.5, 'target'] = 1\n        test2p.loc[test2p['target']<0.5, 'target'] = 0 \n        train2p = pd.concat([train2p, test2p], axis=0)\n        train2p.reset_index(drop=True, inplace=True)\n\n        pca = PCA(n_components=cat_dict[k], random_state=1234)\n        pca.fit(train2p[cols])\n        train3p = pca.transform(train2p[cols])\n        train3 = pca.transform(train2[cols])\n        test3 = pca.transform(test2[cols])\n\n        skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n        for train_index, test_index in skf.split(train3p, train2p['target']):\n            test_index3 = test_index[test_index<len(train3)]\n            clf = QuadraticDiscriminantAnalysis(reg_param=0.4)\n            clf.fit(train3p[train_index, :],train2p.loc[train_index]['target'])\n            oof2[idx1[test_index3]] += clf.predict_proba(train3[test_index3, :])[:, 1]\n            preds2[test2.index] += clf.predict_proba(test3)[:, 1] / skf.n_splits\n\nauc = roc_auc_score(train['target'], oof2)\nprint('Model 2 CV: ', round(auc, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 2.3. Bagging QDA with PL from Model 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train QDA with bagging and PL from Model 1\n\ntest['target'] = preds1 \noof3 = np.zeros(len(train))\npreds3 = np.zeros(len(test))\n\nwith single_threaded(np):\n    for k in tqdm(range(512)):\n        train2 = train[train['wheezy-copper-turtle-magic']==k] \n        train2p = train2.copy(); idx1 = train2.index \n        test2 = test[test['wheezy-copper-turtle-magic']==k]\n\n        # Using all test data as pseudolabels\n        test2p = test2.copy()\n        test2p.loc[test2p['target']>=0.5, 'target'] = 1\n        test2p.loc[test2p['target']<0.5, 'target'] = 0 \n        train2p = pd.concat([train2p, test2p], axis=0)\n        train2p.reset_index(drop=True, inplace=True)\n\n        sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n        train3p = sel.transform(train2p[cols])\n        train3 = sel.transform(train2[cols])\n        test3 = sel.transform(test2[cols])\n\n        skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n        for train_index, test_index in skf.split(train3p, train2p['target']):\n            test_index3 = test_index[test_index<len(train3)]\n            clf = QuadraticDiscriminantAnalysis(reg_param=0.3)\n            clf = BaggingClassifier(clf, n_estimators=200, random_state=333)\n            clf.fit(train3p[train_index, :],train2p.loc[train_index]['target'])\n            oof3[idx1[test_index3]] += clf.predict_proba(train3[test_index3, :])[:, 1]\n            preds3[test2.index] += clf.predict_proba(test3)[:, 1] / skf.n_splits\n        \nauc = roc_auc_score(train['target'], oof3)\nprint('Model 3 CV: ', round(auc, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4. QDA with iterative PL"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train QDA with Grid Search on reg_param and iterative PL for 4 loops\n\noof4 = np.zeros(len(train))\npreds4 = np.zeros(len(test))\nparams = [{'reg_param': [0.1, 0.2, 0.3, 0.4, 0.5]}]\nreg_params = np.zeros(512)\n\nwith single_threaded(np):\n    for i in tqdm(range(512)):\n        train2 = train[train['wheezy-copper-turtle-magic']==i]\n        test2 = test[test['wheezy-copper-turtle-magic']==i]\n        idx1 = train2.index; idx2 = test2.index\n        train2.reset_index(drop=True, inplace=True)\n\n        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n        pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n        data2 = pipe.fit_transform(data[cols])\n        train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n\n        skf = StratifiedKFold(n_splits=11, random_state=42)\n        for train_index, test_index in skf.split(train2, train2['target']):\n            qda = QuadraticDiscriminantAnalysis()\n            clf = GridSearchCV(qda, params, cv=4)\n            clf.fit(train3[train_index, :],train2.loc[train_index]['target'])\n            reg_params[i] = clf.best_params_['reg_param']\n            oof4[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n            preds4[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n\n    for itr in range(4):\n        test['target'] = preds4\n        # Using pseudolabels with confidence < 0.045 or > 0.955\n        test.loc[test['target'] > 0.955, 'target'] = 1\n        test.loc[test['target'] < 0.045, 'target'] = 0\n        usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n        new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n        # Assign 0 or 1 to highly confident predictions\n        new_train.loc[oof > 0.995, 'target'] = 1\n        new_train.loc[oof < 0.005, 'target'] = 0\n        oof4 = np.zeros(len(train))\n        preds4 = np.zeros(len(test))\n        for i in tqdm(range(512)):\n            train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n            test2 = test[test['wheezy-copper-turtle-magic']==i]\n            idx1 = train[train['wheezy-copper-turtle-magic']==i].index\n            idx2 = test2.index\n            train2.reset_index(drop=True,inplace=True)\n\n            data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n            pipe = Pipeline([('vt', VarianceThreshold(threshold=2)), ('scaler', StandardScaler())])\n            data2 = pipe.fit_transform(data[cols])\n            train3 = data2[:train2.shape[0]]\n            test3 = data2[train2.shape[0]:]\n\n            skf = StratifiedKFold(n_splits=11, random_state=42)\n            for train_index, test_index in skf.split(train2, train2['target']):\n                oof_test_index = [t for t in test_index if t < len(idx1)]\n                clf = QuadraticDiscriminantAnalysis(reg_params[i])\n                clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n                if len(oof_test_index) > 0:\n                    oof4[idx1[oof_test_index]] = clf.predict_proba(train3[oof_test_index,:])[:,1]\n                preds4[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n\nauc = roc_auc_score(train['target'], oof4)\nprint('Model 4 CV: ', round(auc, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Final submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A weighted average of all the models\noof = 0.65*(0.25*oof1 + 0.15*oof2 + 0.6*oof3) + 0.35*oof4\npreds = 0.65*(0.25*preds1 + 0.15*preds2 + 0.6*preds3) + 0.35*preds4\nauc = roc_auc_score(train['target'], oof)\nprint('Final submission CV: ', round(auc, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}