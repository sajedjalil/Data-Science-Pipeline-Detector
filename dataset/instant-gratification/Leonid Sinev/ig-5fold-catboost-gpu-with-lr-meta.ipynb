{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Instant Gratification\nA synchronous Kernels-only competition"},{"metadata":{},"cell_type":"markdown","source":"## Loading libraries and preparing functions"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os, sys\nimport time\nimport gc\nfrom numba import jit\ntry:\n    import cPickle as pickle\nexcept:\n    import pickle\n\n# from tqdm import tqdm\nfrom tqdm import trange\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n# from sklearn.metrics import roc_auc_score\n\nfrom sklearn import svm\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\nfrom sklearn import metrics\nfrom collections import Counter\n\nfrom IPython.display import HTML\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('max_colwidth', 500)\npd.set_option('max_columns', 500)\npd.options.display.precision = 15\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Inspired by\n# https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65\n# https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n\ndef convert_col_to_proper_int(df_col):\n    col_type = df_col.values.dtype\n    if ((str(col_type)[:3] == 'int') | (str(col_type)[:4] == 'uint')):\n        c_min = df_col.values.min()\n        c_max = df_col.values.max()\n        if c_min < 0:\n            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n            # https://stackoverflow.com/a/42631281 through values is faster (test with timeit)\n                df_col = pd.Series(df_col.values.astype(np.int8), name=df_col.name)\n            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n                df_col = pd.Series(df_col.values.astype(np.int16), name=df_col.name)\n            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n               df_col = pd.Series(df_col.values.astype(np.int32), name=df_col.name)\n            elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n                df_col = pd.Series(df_col.values.astype(np.int64), name=df_col.name)\n        else:\n            if c_max <= np.iinfo(np.uint8).max:\n                df_col = pd.Series(df_col.values.astype(np.uint8), name=df_col.name)\n            elif c_max <= np.iinfo(np.uint16).max:\n                df_col = pd.Series(df_col.values.astype(np.uint16), name=df_col.name)\n            elif c_max <= np.iinfo(np.uint32).max:\n                df_col = pd.Series(df_col.values.astype(np.uint32), name=df_col.name)\n            elif c_max <= np.iinfo(np.uint64).max:\n                df_col = pd.Series(df_col.values.astype(np.uint64), name=df_col.name)\n            \n    return df_col\n\ndef convert_col_to_proper_float(df_col):\n    col_type = df_col.values.dtype\n    if str(col_type)[:5] == 'float':\n        unique_count = len(np.unique(df_col))\n        # https://stackoverflow.com/a/42631281 through values is faster (test with timeit)\n        df_col_temp = pd.Series(df_col.values.astype(np.float32), name=df_col.name)\n        if len(np.unique(df_col_temp)) == unique_count:\n            df_col = df_col_temp\n            c_min = df_col.values.min()\n            c_max = df_col.values.max()\n            if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n                df_col_temp = pd.Series(df_col.values.astype(np.float16), name=df_col.name)\n                if len(np.unique(df_col_temp)) == unique_count:\n                    df_col = df_col_temp\n            \n    return df_col\n\ndef gentle_reduce_mem_usage(data, verbose = True, process_objects = False, cat_level = None):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    if cat_level is not None:\n        cat_level = np.round(abs(cat_level) % 1, 15)\n    start_mem = data.memory_usage().sum() / 1024**2\n    if verbose:\n        print('Memory usage of dataframe: {:.2f} MB'.format(start_mem))\n\n    start_time = time.time()\n\n    for col in tqdm(data.columns, desc='columns'):\n#         if verbose:\n#             print(col, type(data[col]), data[col].shape, 'started at', time.ctime())\n        col_type = data[col].values.dtype\n\n        if (process_objects & (col_type == object)):\n            try:\n                data[col] = pd.to_numeric(data[col], downcast='float')\n            except ValueError:\n                try:\n                    data[col] = pd.to_numeric(data[col].str.replace(',', '.'), downcast='float')\n                except ValueError:\n                    data[col] = pd.to_datetime(data[col], infer_datetime_format=True, errors='ignore')\n            col_type = data[col].values.dtype\n\n        if (process_objects & (col_type == object) & (cat_level is not None)):\n            if len(np.unique(data[col].values)) <= cat_level*len(data[col].values):\n                data[col] = data[col].astype('category')\n                col_type = data[col].values.dtype\n\n        if ((col_type != object) & (col_type != '<M8[ns]') & (col_type != '<m8[ns]')\\\n                & (col_type.name != 'bool') & (col_type.name != 'category') & (col_type.name != 'complex64')\\\n                & (col_type.name != 'complex128')):#\n            c_min = data[col].values.min()\n            c_max = data[col].values.max()\n            if ((str(col_type)[:3] == 'int') | (str(col_type)[:4] == 'uint')):\n                data[col] = convert_col_to_proper_int(data[col])\n            else:\n                if np.isfinite(data[col].values).all():\n                    if c_min < 0:\n                        if abs(data[col].values - data[col].values.astype(np.int64)).sum() < 0.01:\n                            data[col] = convert_col_to_proper_int(pd.Series(data[col].values.astype(np.int64),\n                                                                            name=data[col].name))\n                        else:\n                            data[col] = convert_col_to_proper_float(data[col])\n                    else:\n                        if abs(data[col].values - data[col].values.astype(np.uint64)).sum() < 0.01:\n                            data[col] = convert_col_to_proper_int(pd.Series(data[col].values.astype(np.uint64),\n                                                                            name=data[col].name))\n                        else:\n                            data[col] = convert_col_to_proper_float(data[col])\n                else:\n                    data[col] = convert_col_to_proper_float(data[col])\n\n    end_time = time.time()\n    end_mem = data.memory_usage().sum() / 1024**2\n    if verbose:\n        print('Memory usage after optimization: {:.2f} MB'.format(end_mem))\n        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n        print('Done in {} seconds.'.format(end_time - start_time))\n\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"RANDOM_STATE = 2042\nnp.random.seed(RANDOM_STATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"NUM_THREADS = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_path = '../input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_name = 'model'\nmodel_num = 0\npostfix = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data overview"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"%%time\ntrain = pd.read_csv(f'{input_path}train.csv', dtype = {'target': np.uint8})\ntest = pd.read_csv(f'{input_path}test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ok_cols = [col for col in train.columns if col not in ['id', 'target', 'wheezy-copper-turtle-magic']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from https://www.kaggle.com/cdeotte/logistic-regression-0-800\n# INITIALIZE VARIABLES\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in trange(512, desc='wheezy-copper-turtle-magic value'):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    test2.reset_index(drop=True,inplace=True)\n    \n    skf = StratifiedKFold(n_splits=25, random_state=42)\n    for train_index, val_index in skf.split(train2.iloc[:,1:-1], train2['target']):\n        # LOGISTIC REGRESSION MODEL\n        clf = LogisticRegression(solver='liblinear',penalty='l1',C=0.05)\n        clf.fit(train2.loc[train_index][ok_cols],train2.loc[train_index]['target'])\n        oof[idx1[val_index]] += clf.predict_proba(train2.loc[val_index][ok_cols])[:,1]\n        preds[idx2] += clf.predict_proba(test2[ok_cols])[:,1]\n        \n# PRINT CV AUC\nauc = metrics.roc_auc_score(train['target'],oof.astype(np.float32))\nprint('LR with interactions scores CV =',round(auc,5))\n\ntrain['meta_lr'] = oof.astype(np.float32)\ntest['meta_lr'] = preds.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_len = len(train)\ndata = pd.concat([train.drop(columns=['target']), test], ignore_index = True).reset_index(drop=True)\ny = train['target']\ndel train, test, auc\ngc.collect()\ngentle_reduce_mem_usage(data)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ncol_part_names = [col.split('-') for col in ok_cols]\ncol_part_names = [i for j in col_part_names for i in j]\nsome_cols = [i[0] for i in Counter(col_part_names).most_common() if i[1] > 4]\n\n#frequencies\ndata['wheezy-copper-turtle-magic_count'] = data.groupby(['wheezy-copper-turtle-magic'])['id'].transform('count')\n\nfor col in tqdm(ok_cols, desc='processed columns'):\n    data[f'{col}_w_mean'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform('mean').fillna(0).values.astype(np.float32)\n    data[f'{col}_w_std'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform('std').fillna(0).values.astype(np.float32)\n    data[f'{col}_w_max'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform('max').fillna(0).values.astype(np.float32)\n    data[f'{col}_w_min'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform('min').fillna(0).values.astype(np.float32)\n    data[f'{col}_w_quantile_10'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform(lambda x: np.percentile(x.unique(), 10)).fillna(0).values.astype(np.float32)\n#     data[f'{col}_w_quantile_25'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform(lambda x: np.percentile(x.unique(), 25)).fillna(0).values.astype(np.float32)\n#     data[f'{col}_w_median'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform(lambda x: np.percentile(x.unique(), 50)).fillna(0).values.astype(np.float32)\n#     data[f'{col}_w_quantile_75'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform(lambda x: np.percentile(x.unique(), 75)).fillna(0).values.astype(np.float32)\n    data[f'{col}_w_quantile_90'] = data.groupby(['wheezy-copper-turtle-magic'])[col].transform(lambda x: np.percentile(x.unique(), 90)).fillna(0).values.astype(np.float32)\n\nfor c in tqdm(some_cols, desc='some_cols columns'):\n    more_such_cols = [col for col in ok_cols if c in col]\n    data[f'{c}_mean'] = data[more_such_cols].mean(1)\n    data[f'{c}_min'] = data[more_such_cols].min(1)\n    data[f'{c}_max'] = data[more_such_cols].max(1)\n    data[f'{c}_std'] = data[more_such_cols].std(1)\n\nscaler = StandardScaler()\nprint('Scaling with StandardScaler\\n')\ndata[ok_cols] = scaler.fit_transform(data[ok_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gentle_reduce_mem_usage(data)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Catboost model"},{"metadata":{"trusted":false},"cell_type":"code","source":"# data['wheezy-copper-turtle-magic'] = data['wheezy-copper-turtle-magic'].astype(object) #making cat_feature for catboost\nX = data[:train_len].drop(['id'], axis=1)\nX_test = data[train_len:].drop(['id'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"n_fold = 5\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=RANDOM_STATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training function:"},{"metadata":{"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"@jit\ndef fast_auc(y_true, y_prob):\n    \"\"\"\n    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    nfalse = 0\n    auc = 0\n    n = len(y_true)\n    for i in range(n):\n        y_i = y_true[i]\n        nfalse += (1 - y_i)\n        auc += y_i * nfalse\n    auc /= (nfalse * (n - nfalse))\n    return auc\n\n\ndef eval_auc(y_true, y_pred):\n    \"\"\"\n    Fast auc eval function for lgb.\n    \"\"\"\n    return 'auc', fast_auc(y_true, y_pred), True\n\n\ndef train_model_classification(X, X_test, y, params, folds, model_type='cat', eval_metric='auc', columns=None,\n                               plot_feature_importance=False, model=None, cat_plot = None,\n                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n    \"\"\"\n    A function to train a variety of classification models.\n    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n    \n    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n    :params: y - target\n    :params: folds - folds to split data\n    :params: model_type - type of model to use\n    :params: eval_metric - metric to use\n    :params: columns - columns to use. If None - use all columns\n    :params: plot_feature_importance - whether to plot feature importance of LGB\n    :params: model - sklearn model, works only for \"sklearn\" model type\n    \n    \"\"\"\n    columns = X.columns if columns == None else columns\n    X_test = X_test[columns]\n    \n    # to set up scoring parameters\n    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n                        'catboost_metric_name': 'AUC',#AUC:hints=skip_train~false\n                        'sklearn_scoring_function': metrics.roc_auc_score},\n                    'mcc': {'lgb_metric_name': eval_auc,\n                        'catboost_metric_name': 'MCC',\n                        'sklearn_scoring_function': metrics.roc_auc_score},\n                    }\n    loss_dict ={'auc': {'lgb_metric_name': eval_auc,\n                        'catboost_metric_name': 'Logloss',\n                        'sklearn_scoring_function': metrics.roc_auc_score},\n                'mcc': {\n                    'lgb_metric_name': eval_auc,\n                    'catboost_metric_name': 'Logloss',\n                    'sklearn_scoring_function': metrics.roc_auc_score},\n                }\n    \n    result_dict = {}\n    \n    # out-of-fold predictions on train data\n    oof = np.zeros((len(X), len(set(y.values))))\n    \n    # averaged predictions on train data\n    prediction = np.zeros((len(X_test), oof.shape[1]))\n    \n    # list of scores on folds\n    scores = []\n    feature_importance = pd.DataFrame()\n    \n    # split and train on folds\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n        if type(X) == np.ndarray:\n            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n            y_train, y_valid = y[train_index], y[valid_index]\n        else:\n            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n            \n        if model_type == 'lgb':\n            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = NUM_THREADS)\n            model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                      eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n            \n            y_pred_valid = model.predict_proba(X_valid)\n            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)\n            \n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, n_jobs = NUM_THREADS,\n                              early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n        \n        if model_type == 'sklearn':\n            model = model\n            model.fit(X_train, y_train)\n            \n            y_pred_valid = model.predict(X_valid).reshape(-1,)\n            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n            print('')\n            \n            y_pred = model.predict_proba(X_test)\n        \n        if model_type == 'cat':\n            model = CatBoostClassifier(iterations=n_estimators, thread_count=NUM_THREADS,\n                                       early_stopping_rounds = early_stopping_rounds,\n                                       eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n                                       loss_function=loss_dict[eval_metric]['catboost_metric_name'])\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid),\n                      plot = cat_plot,\n                      use_best_model=True, verbose=verbose)\n\n            y_pred_valid = model.predict_proba(X_valid)\n            y_pred = model.predict_proba(X_test)\n        \n#         print(oof[valid_index].shape)\n#         print(y_pred_valid.shape)\n        oof[valid_index] = y_pred_valid\n        scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid[:, 1]))\n\n        prediction += y_pred    \n        \n        if model_type == 'lgb' and plot_feature_importance:\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = columns\n            fold_importance[\"importance\"] = model.feature_importances_\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction /= folds.n_splits\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f} (CV score: {0:.3f}Â±{2:.3f}).'.format(np.mean(scores), np.std(scores),\n                                                                                     3*np.std(scores)))\n    \n    result_dict['oof'] = oof\n    result_dict['prediction'] = prediction\n    result_dict['scores'] = scores\n    \n    if model_type == 'lgb':\n        if plot_feature_importance:\n            feature_importance[\"importance\"] /= folds.n_splits\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n            \n            result_dict['feature_importance'] = feature_importance\n        \n    return result_dict\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"params = {'metric_period': 200, #auc calculation is slow, so evaluate less\n#           'cat_features': [X.columns.get_loc('wheezy-copper-turtle-magic')],\n          'random_seed': RANDOM_STATE,\n          'depth': 8,\n          'bagging_temperature': 0.825,\n          'random_strength': 0.125,\n#           'l2_leaf_reg': 6.0,\n          'task_type': 'GPU',\n#           'learning_rate': 0.10,\n          'od_type': 'Iter',\n          'custom_metric': 'MCC',\n         }\nresult_dict_cat = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='cat',\n                                             cat_plot = False,\n                                             eval_metric='auc', plot_feature_importance=True, verbose=200, n_estimators=30000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"result_dict_cat['prediction'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"result_dict_cat['oof'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(f'{input_path}sample_submission.csv')\nsub['target'] = result_dict_cat['prediction'][:, 1]\nsub.to_csv(\"submission.csv\", index=False)\n# sub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}