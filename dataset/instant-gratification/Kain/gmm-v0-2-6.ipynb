{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\nfrom sklearn.covariance import EmpiricalCovariance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn import linear_model\nimport sympy \nimport numpy as np\nfrom sklearn.covariance import OAS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import DBSCAN\n\n# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        x_train, y_train = train3[train_index,:], train2.loc[train_index]['target'].values\n        \n        x_train_0 = x_train[y_train==0]\n        x_train_1 = x_train[y_train==1]\n        \n#         brc = BayesianGaussianMixture(n_components=3, covariance_type='full', weight_concentration_prior=1e-2, \n#                                       weight_concentration_prior_type='dirichlet_process', mean_precision_prior=1e-2, covariance_prior=1e0 * np.eye(2),\n#                                       init_params=\"random\", max_iter=100, random_state=666)#Birch(branching_factor=50, n_clusters=3, threshold=0.4, compute_labels=True)\n        brc = Birch(branching_factor=50, n_clusters=3, threshold=0.6, compute_labels=True)\n        labels_0 = brc.fit_predict(x_train_0)\n        labels_1 = brc.fit_predict(x_train_1) \n        \n        zero_mean = []\n        zero_cov = []\n        for l in np.unique(labels_0):\n            model = OAS()\n            model.fit(x_train_0[labels_0==l])\n            p = model.precision_\n            m = model.location_\n            \n            zero_mean.append(m)\n            zero_cov.append(p)\n            \n        one_mean = []\n        one_cov = []\n        for l in np.unique(labels_1):\n            model = OAS()\n            model.fit(x_train_1[labels_1==l])\n            p = model.precision_\n            m = model.location_\n            \n            one_mean.append(m)\n            one_cov.append(p)\n       \n            \n            \n        \n#         print(np.array(zero_mean).mean(axis=0))\n        \n        ms = np.stack(zero_mean + one_mean)\n        ps = np.stack(zero_cov +  one_cov)\n        \n      \n        gm = GaussianMixture(n_components=6, init_params='kmeans', \n                             covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,\n                             means_init=ms, precisions_init=ps, random_state=666)\n        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n        oof[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:, 0:3].mean(axis=1)\n        preds[idx2] += gm.predict_proba(test3)[:, 0:3].mean(axis=1) / skf.n_splits\n    print('AUC ', i, roc_auc_score(1- train2['target'], oof[idx1]))    \n\n        \n# PRINT CV AUC\nauc = roc_auc_score(1 - train['target'],oof)\nprint('QDA scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_0 = oof\npreds_0 = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import DBSCAN\n\n# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        x_train, y_train = train3[train_index,:], train2.loc[train_index]['target'].values\n        \n        x_train_0 = x_train[y_train==0]\n        x_train_1 = x_train[y_train==1]\n        \n#         brc = BayesianGaussianMixture(n_components=3, covariance_type='full', weight_concentration_prior=1e-2, \n#                                       weight_concentration_prior_type='dirichlet_process', mean_precision_prior=1e-2, covariance_prior=1e0 * np.eye(2),\n#                                       init_params=\"random\", max_iter=100, random_state=666)#Birch(branching_factor=50, n_clusters=3, threshold=0.4, compute_labels=True)\n        brc = Birch(branching_factor=50, n_clusters=4, threshold=0.6, compute_labels=True)\n        labels_0 = brc.fit_predict(x_train_0)\n        labels_1 = brc.fit_predict(x_train_1) \n        \n        zero_mean = []\n        zero_cov = []\n        for l in np.unique(labels_0):\n            model = OAS()\n            model.fit(x_train_0[labels_0==l])\n            p = model.precision_\n            m = model.location_\n            \n            zero_mean.append(m)\n            zero_cov.append(p)\n            \n        one_mean = []\n        one_cov = []\n        for l in np.unique(labels_1):\n            model = OAS()\n            model.fit(x_train_1[labels_1==l])\n            p = model.precision_\n            m = model.location_\n            \n            one_mean.append(m)\n            one_cov.append(p)\n       \n            \n            \n        \n#         print(np.array(zero_mean).mean(axis=0))\n        \n        ms = np.stack(zero_mean + one_mean)\n        ps = np.stack(zero_cov +  one_cov)\n        \n      \n        gm = GaussianMixture(n_components=8, init_params='kmeans', \n                             covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,\n                             means_init=ms, precisions_init=ps, random_state=666)\n        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n        oof[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:, 0:4].mean(axis=1)\n        preds[idx2] += gm.predict_proba(test3)[:, 0:4].mean(axis=1) / skf.n_splits\n    print('AUC ', i, roc_auc_score(1- train2['target'], oof[idx1]))    \n\n        \n# PRINT CV AUC\nauc = roc_auc_score(1 - train['target'],oof)\nprint('QDA scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_1 = oof\npreds_1 = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import DBSCAN\n\n# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n        x_train, y_train = train3[train_index,:], train2.loc[train_index]['target'].values\n        \n        x_train_0 = x_train[y_train==0]\n        x_train_1 = x_train[y_train==1]\n        \n#         brc = BayesianGaussianMixture(n_components=3, covariance_type='full', weight_concentration_prior=1e-2, \n#                                       weight_concentration_prior_type='dirichlet_process', mean_precision_prior=1e-2, covariance_prior=1e0 * np.eye(2),\n#                                       init_params=\"random\", max_iter=100, random_state=666)#Birch(branching_factor=50, n_clusters=3, threshold=0.4, compute_labels=True)\n        brc = Birch(branching_factor=50, n_clusters=2, threshold=0.6, compute_labels=True)\n        labels_0 = brc.fit_predict(x_train_0)\n        labels_1 = brc.fit_predict(x_train_1) \n        \n        zero_mean = []\n        zero_cov = []\n        for l in np.unique(labels_0):\n            model = OAS()\n            model.fit(x_train_0[labels_0==l])\n            p = model.precision_\n            m = model.location_\n            \n            zero_mean.append(m)\n            zero_cov.append(p)\n            \n        one_mean = []\n        one_cov = []\n        for l in np.unique(labels_1):\n            model = OAS()\n            model.fit(x_train_1[labels_1==l])\n            p = model.precision_\n            m = model.location_\n            \n            one_mean.append(m)\n            one_cov.append(p)\n       \n            \n            \n        \n#         print(np.array(zero_mean).mean(axis=0))\n        \n        ms = np.stack(zero_mean + one_mean)\n        ps = np.stack(zero_cov +  one_cov)\n        \n      \n        gm = GaussianMixture(n_components=4, init_params='kmeans', \n                             covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,\n                             means_init=ms, precisions_init=ps, random_state=666)\n        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n        oof[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:, 0:2].mean(axis=1)\n        preds[idx2] += gm.predict_proba(test3)[:, 0:2].mean(axis=1) / skf.n_splits\n    print('AUC ', i, roc_auc_score(1- train2['target'], oof[idx1]))    \n\n        \n# PRINT CV AUC\nauc = roc_auc_score(1 - train['target'],oof)\nprint('QDA scores CV =',round(auc,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_2 = oof\npreds_2 = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['y_0'] = oof_0\ntest['y_0'] = preds_0\n\ntrain['y_1'] = oof_1\ntest['y_1'] = preds_1\n\ntrain['y_2'] = oof_2\ntest['y_2'] = preds_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_features = ['y_0', 'y_1', 'y_2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for m in sorted(train['wheezy-copper-turtle-magic'].unique()):\n        idx_tr = (train['wheezy-copper-turtle-magic']==m)\n        idx_te = (test['wheezy-copper-turtle-magic']==m)\n        oofs = []\n        preds = []\n        kf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n        oof_preds = np.zeros((len(train[idx_tr][oof_features]), 1))\n        test_preds = np.zeros((len(test[idx_te][oof_features]), 1))\n        for idx, (train_index, valid_index) in enumerate(kf.split(train[idx_tr][oof_features], train[idx_tr]['target'])):\n                y_train, y_valid = train[idx_tr]['target'].iloc[train_index], train[idx_tr]['target'].iloc[valid_index]\n                x_train, x_valid = train[idx_tr][oof_features].iloc[train_index,:], train[idx_tr][oof_features].iloc[valid_index,:]\n\n                model = linear_model.Ridge(alpha=3)\n                model.fit(x_train, y_train)   \n                oof_preds[valid_index, :] = model.predict(x_valid).reshape((-1, 1))\n                test_preds += model.predict(test[idx_te][oof_features]).reshape((-1, 1)) / 11  \n        print('OOF AUC ', m, ' ', roc_auc_score(train[idx_tr]['target'], oof_preds))\n        oofs.append((idx_tr, oof_preds))\n        preds.append((idx_te, test_preds))\n        for ids, target in oofs:\n            train.loc[ids,'target_final'] = target\n        for ids, target in preds:\n            test.loc[ids,'target_final'] = target\n            \nprint('OOF AUC ', roc_auc_score(train['target'], train['target_final']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['target_final'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(np.concatenate([preds_0.reshape(-1, 1), preds_1.reshape(-1, 1), preds_2.reshape(-1, 1), 1 - test['target_final'].values.reshape(-1, 1)], axis=1)).rank().corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = pd.DataFrame(np.concatenate([preds_0.reshape(-1, 1), preds_1.reshape(-1, 1), preds_2.reshape(-1, 1), 1 - test['target_final'].values.reshape(-1, 1)], axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat = test_preds.rank(axis=0, method='min').mul(test_preds.shape[1] * [1 / test_preds.shape[1]]).sum(1) / test_preds.shape[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = 1 - test['target_final'].values\nsub.to_csv('submission.csv',index=False)\n\nimport matplotlib.pyplot as plt\nplt.hist(1 - test['target_final'].values ,bins=100)\nplt.title('Final Test.csv predictions')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}