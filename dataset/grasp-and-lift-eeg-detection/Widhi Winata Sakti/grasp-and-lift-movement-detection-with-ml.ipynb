{"cells":[{"metadata":{},"cell_type":"markdown","source":"Extract Zip File"},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile(\"../input/grasp-and-lift-eeg-detection/test.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"../input/grasp-and-lift-eeg-detection/train.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\ntrain_set_labels = pd.read_csv(\"train/subj1_series1_events.csv\")\ntrain_set_signals = pd.read_csv(\"train/subj1_series1_data.csv\")\ntrain_set_signals.head()\naxis = plt.gca()\ndownSampleToShow = 500\ntrain_set_signals[::downSampleToShow].plot(x=\"id\", y=\"Fp1\", ax=axis)\ntrain_set_signals[::downSampleToShow].plot(x=\"id\", y=\"PO10\", ax=axis, figsize=(15,5))\ntrain_set_labels[::downSampleToShow].plot(figsize=(15,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eeg_channels = train_set_signals.columns.drop('id')\nlabels = train_set_labels.columns.drop('id')\ntrain_set_complete = pd.concat([train_set_signals,train_set_labels], axis=1)\ntrain_set_complete.insert(0, \"order\", range(0, len(train_set_complete)))\ntrain_set_complete.head()\ndef highlight(indices,ax,color):\n    i=0\n    while i<len(indices):\n        ax.axvspan(indices[i]-0.5, indices[i]+0.5, facecolor=color, edgecolor='none', alpha=.35)\n        i+=1\nsecondsToShow = 8\nchannelsToShow = 3\nlabelsToShow = 6\n\nsample_set = train_set_complete[train_set_complete[\"order\"] < secondsToShow*500].drop(\"id\", axis=1).set_index(\"order\") #sample rate is 500hz \ncolors=[\"red\",\"purple\",\"black\",\"green\", \"yellow\", \"blue\"]\naxes = sample_set.plot(y=eeg_channels[:channelsToShow],subplots=True, figsize=(15,10))\nfor i in range(0, len(labels)):\n    print(labels[i], \"=\", colors[i])\n    \nfor axis in axes:    \n    colorindex = 0\n    for label in labels[:labelsToShow]:\n        highlight(sample_set[sample_set[label]==1].index, axis, colors[colorindex])        \n        colorindex = colorindex + 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nsub1_events_file = 'train/subj1_series1_events.csv'\nsub1_data_file = 'train/subj1_series1_data.csv'\n\nsub1_events = pd.read_csv(sub1_events_file)\nsub1_data = pd.read_csv(sub1_data_file)\n\nsub1 = pd.concat([sub1_events, sub1_data], axis = 1)\nsub1[\"time\"] = range(0, len(sub1))\n\nsample_sub1 = sub1[sub1[\"time\"] < 5000]\n\nevent = \"HandStart\"\nevent1 = \"FirstDigitTouch\"\nEventColors = [\"lightgrey\", \"green\",\"blue\"]\n\nplot_columns = [\"O1\", \"O2\", \"C3\", \"C4\"]\n\nfig, axes = plt.subplots(nrows=len(plot_columns), ncols=1)\nfig.suptitle(event)\nfor (i, y) in enumerate(plot_columns):\n    # Plot all the columns\n    sample_sub1.plot(kind=\"scatter\", x=\"time\", y=y, edgecolors='none', ax=axes[i], figsize=(10,8), c=sample_sub1[event].apply(EventColors.__getitem__))\n   \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DENOİSİNG BUTTERWORTH**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom glob import glob\nimport scipy\nfrom scipy.signal import butter, lfilter, convolve, boxcar\nfrom scipy.signal import freqz\nfrom scipy.fftpack import fft, ifft\nimport os\n\nfrom sklearn.preprocessing import StandardScaler\n\n\n\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\n\ndef butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n    y = lfilter(b, a, data)\n    return y\n#############function to read data###########\n\ndef prepare_data_train(fname):\n    \"\"\" read and prepare training data \"\"\"\n    # Read data\n    data = pd.read_csv(fname)\n    # events file\n    events_fname = fname.replace('_data','_events')\n    # read event file\n    labels= pd.read_csv(events_fname)\n    clean=data.drop(['id' ], axis=1)#remove id\n    labels=labels.drop(['id' ], axis=1)#remove id\n    return  clean,labels\n\ndef prepare_data_test(fname):\n    \"\"\" read and prepare test data \"\"\"\n    # Read data\n    data = pd.read_csv(fname)\n    return data\nfrom sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\ndef data_preprocess_train(X):\n    X_prep=scaler.fit_transform(X)\n    #do here your preprocessing\n    return X_prep\ndef data_preprocess_test(X):\n    X_prep=scaler.transform(X)\n    #do here your preprocessing\n    return X_prep\nsubjects = range(1,4)\nfrom glob import glob\nimport pandas as pd\nids_tot = []\npred_tot = []\nX_train_butter = []\nfrom sklearn.model_selection import train_test_split\nimport numpy as  np\n\n###loop on subjects and 8 series for train data + 2 series for test data\ny_raw= []\nraw = []\ny_rawt= []\nrawt = []\nfor subject in subjects:\n    \n    ################ READ DATA ################################################\n    fnames =  sorted(glob('train/subj%d_series*_data.csv' % (subject)))[:6]\n\n\n#    fnames =  glob('../input/train/subj1_series1_events.csv')\n#    fnames =  glob('../input/train/subj1_series1_data.csv')\n    for fname in fnames:\n      data,labels=prepare_data_train(fname)\n      raw.append(data)\n      y_raw.append(labels)\n\n    for fname in fnames:\n      with open(fname) as myfile:\n        head = [next(myfile) for x in range(10)]\n        \n        ################ READ TEST DATA ################################################\n    tnames =  sorted(glob('train/subj%d_series*_data.csv' % (subject)))\n\n\n#    fnames =  glob('../input/train/subj1_series1_events.csv')\n#    fnames =  glob('../input/train/subj1_series1_data.csv')\n    for fname in tnames:\n      datat,labelst=prepare_data_train(fname)\n      rawt.append(datat)\n      y_rawt.append(labelst)\n\n    for fname in tnames:\n      with open(fname) as myfile:\n        head = [next(myfile) for x in range(10)]\n      \n        \nX = pd.concat(raw)\ny = pd.concat(y_raw)\n    #transform in numpy array\n    #transform train data in numpy array\nX_train =np.asarray(X.astype(float))\nytrain = np.asarray(y.astype(float))\n\n\n\nfrom sklearn.preprocessing import StandardScaler,Normalizer\nscaler= StandardScaler()\ndef data_preprocess_train(X):\n    X_prep=scaler.fit_transform(X)\n    #do here your preprocessing\n    return X_prep\nfs = 500.0\nlowcut = 7.0\nhighcut = 30.0\n\nx_train_butter = []\nfor i in range(0,32):\n    x_train_butter.append( butter_bandpass_filter(X_train[:,i], lowcut, highcut, fs, order=6))\nx_train_butter=np.array(x_train_butter).T\nxtrain=data_preprocess_train(x_train_butter)\nsplitrate=xtrain.shape[0]//5\nxval=xtrain[:splitrate]\nyval=ytrain[:splitrate]\nxtrain=xtrain[splitrate:]\nytrain=ytrain[splitrate:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8,5))\nax.plot(X_train[:10000,1], label='signal', color=\"b\", alpha=0.5,)\nax.plot(x_train_butter[:10000,1], label='reconstructed signal',color=\"k\")\nax.legend(loc='upper left')\nax.set_title('Denoising with Butterworth')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DWT denoising**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\nimport pywt\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom glob import glob\nimport scipy\nfrom scipy.signal import butter, lfilter, convolve, boxcar\nfrom scipy.signal import freqz\nfrom scipy.fftpack import fft, ifft\nimport os\n\nfrom sklearn.preprocessing import StandardScaler\n\ndef wavelet_denoising(x, wavelet='db2', level=3):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * madev(coeff[-level])\n    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n    return pywt.waverec(coeff, wavelet, mode='per')\ndef madev(d, axis=None):\n    \"\"\" Mean absolute deviation of a signal \"\"\"\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n#############function to read data###########\n\ndef prepare_data_train(fname):\n    \"\"\" read and prepare training data \"\"\"\n    # Read data\n    data = pd.read_csv(fname)\n    # events file\n    events_fname = fname.replace('_data','_events')\n    # read event file\n    labels= pd.read_csv(events_fname)\n    clean=data.drop(['id' ], axis=1)#remove id\n    labels=labels.drop(['id' ], axis=1)#remove id\n    return  clean,labels\n\ndef prepare_data_test(fname):\n    \"\"\" read and prepare test data \"\"\"\n    # Read data\n    data = pd.read_csv(fname)\n    return data\n\ndef data_preprocess_train(X):\n    X_prep=scaler.fit_transform(X)\n    #do here your preprocessing\n    return X_prep\ndef data_preprocess_test(X):\n    X_prep=scaler.transform(X)\n    #do here your preprocessing\n    return X_prep\nsubjects = range(1,6)\nfrom glob import glob\nimport pandas as pd\nids_tot = []\npred_tot = []\nX_train_butter = []\nfrom sklearn.model_selection import train_test_split\nimport numpy as  np\n\n###loop on subjects and 8 series for train data + 2 series for test data\ny_raw= []\nraw = []\ny_rawt= []\nrawt = []\nfor subject in subjects:\n    \n    ################ READ DATA ################################################\n    fnames =  sorted(glob('train/subj%d_series*_data.csv' % (subject)))#[:6]\n\n\n#    fnames =  glob('../input/train/subj1_series1_events.csv')\n#    fnames =  glob('../input/train/subj1_series1_data.csv')\n    for fname in fnames:\n      data,labels=prepare_data_train(fname)\n      raw.append(data)\n      y_raw.append(labels)\n\n    for fname in fnames:\n      with open(fname) as myfile:\n        head = [next(myfile) for x in range(10)]\n        \n\n      \n        \nX = pd.concat(raw)\ny = pd.concat(y_raw)\n    #transform in numpy array\n    #transform train data in numpy array\nX_train =np.asarray(X.astype(float))\ny_train = np.asarray(y.astype(float))\n\n\n\nfrom sklearn.preprocessing import StandardScaler,Normalizer,MinMaxScaler\nscaler= StandardScaler()\ndef data_preprocess_train(X):\n    X_prep=scaler.fit_transform(X)\n    #do here your preprocessing\n    return X_prep\n\nx_train_butter=wavelet_denoising(X_train)\nx_train=data_preprocess_train(x_train_butter)\nsplitrate=-x_train.shape[0]//5*2\nxval=x_train[splitrate:splitrate//2]\nyval=y_train[splitrate:splitrate//2]\nxtest=x_train[splitrate//2:]\nytest=y_train[splitrate//2:]\nxtrain=x_train[:splitrate]\nytrain=y_train[:splitrate]\n\n\"\"\"\n#for  ml algoritm\nx_train_butter=wavelet_denoising(X_train)\nx_train=data_preprocess_train(x_train_butter)\nsplitrate=x_train.shape[0]//5\nxval=x_train[:splitrate]\nyval=y_train[:splitrate]\nxtrain=x_train[splitrate:]\nytrain=y_train[splitrate:]\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pywt\nimport pandas as pd\nimport numpy as np\ndef wavelet_denoising(x, wavelet='db2', level=3):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * madev(coeff[-level])\n    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n    return pywt.waverec(coeff, wavelet, mode='per')\ndef madev(d, axis=None):\n    \"\"\" Mean absolute deviation of a signal \"\"\"\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\nsignal=pd.read_csv('train/subj1_series1_data.csv')\nsignal = signal.drop(\"id\", axis=1)\nfiltered = wavelet_denoising(signal, wavelet='db2', level=3)\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(8,5))\nax.plot(signal.iloc[:10000,1], label='signal', color=\"b\", alpha=0.5,)\nax.plot(filtered[:10000,1], label='reconstructed signal',color=\"k\")\nax.legend(loc='upper left')\nax.set_title('Denoising with DWT')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## OneVsRestClassifier and SGDClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import make_pipeline\n\n# Binary Relevance\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Performance metric\nfrom sklearn.metrics import f1_score\nlr = SGDClassifier()\n#clf = OneVsRestClassifier(LinearSVC(random_state=0))\nclf =OneVsRestClassifier(lr)\nimport time\nstart=time.time()\nclf.fit(xtrain,ytrain)\n\nprint('training time taken: ',round(time.time()-start,0),'seconds')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\ny_score = clf.decision_function(xval)\n#y_score = clf.predict(xval)\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(6):\n    fpr[i], tpr[i], _ = roc_curve(yval[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot of a ROC curve for a specific class\nfor i in range(6):\n    plt.figure()\n    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Accuracy // Hamming Loss  // label_ranking_average_precision_score ***"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import hamming_loss\nfrom sklearn.metrics import label_ranking_average_precision_score\npredictions = clf.predict(xval)\n# accuracy\nprint(\"roc_auc:\",sum(roc_auc.values())/6)\nprint(\"Accuracy = \",accuracy_score(yval,predictions))\nprint(\"Hamming Loss = \",hamming_loss(yval,predictions))\nprint(\"label_ranking_average_precision_score\",label_ranking_average_precision_score(yval,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\ncm=multilabel_confusion_matrix(yval, predictions)\nprint(cm)\nimport matplotlib.pyplot as plt\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfig, ax = plot_confusion_matrix(conf_mat=cm[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  ClassifierChain and GaussianNB"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skmultilearn.problem_transform import ClassifierChain\nimport time\nfrom sklearn.naive_bayes import GaussianNB\n\n# initialize classifier chains multi-label classifier\n# with a gaussian naive bayes base classifier\ncls = ClassifierChain(GaussianNB())\n\n# train\nstart=time.time()\ncls.fit(xtrain,ytrain)\n\nprint('training time taken: ',round(time.time()-start,0),'seconds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\ny_score = cls.predict(xval)\nycls=y_score.toarray()\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(6):\n    fpr[i], tpr[i], _ = roc_curve(yval[:, i], ycls[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot of a ROC curve for a specific class\n\nfor i in range(6):\n    plt.figure()\n    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Accuracy // Hamming Loss  // label_ranking_average_precision_score ***"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import hamming_loss\nfrom sklearn.metrics import label_ranking_average_precision_score\n\npredictionc = cls.predict(xval)\nprint(\"roc_auc:\",sum(roc_auc.values())/6)\nprint(\"Accuracy = \",accuracy_score(yval,predictionc))\nprint(\"Hamming Loss = \",hamming_loss(yval,predictionc))\nprint(\"label_ranking_average_precision_score\",label_ranking_average_precision_score(yval,predictionc.toarray()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\ncm=multilabel_confusion_matrix(yval, predictionc)\nprint(cm)\nimport matplotlib.pyplot as plt\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfig, ax = plot_confusion_matrix(conf_mat=cm[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LabelPowerset and GaussianNB"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom skmultilearn.problem_transform import LabelPowerset\nfrom sklearn.naive_bayes import GaussianNB\n\n# initialize Label Powerset multi-label classifier\n# with a gaussian naive bayes base classifier\nclassifier = LabelPowerset(GaussianNB())\n\n# train\nstart=time.time()\nclassifier.fit(xtrain,ytrain)\n\nprint('training time taken: ',round(time.time()-start,0),'seconds')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\ny_score = classifier.predict(xval)\nycls=y_score.toarray()\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(6):\n    fpr[i], tpr[i], _ = roc_curve(yval[:, i], ycls[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot of a ROC curve for a specific class\nfor i in range(6):\n    plt.figure()\n    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import hamming_loss\nfrom sklearn.metrics import label_ranking_average_precision_score\n\nprediction = classifier.predict(xval)\n\nprint(\"roc_auc:\",sum(roc_auc.values())/6)\nprint(\"Accuracy = \",accuracy_score(yval,prediction))\nprint(\"Hamming Loss = \",hamming_loss(yval,prediction))\nprint(\"label_ranking_average_precision_score\",label_ranking_average_precision_score(yval,prediction.toarray()))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\ncm=multilabel_confusion_matrix(yval, prediction)\nprint(cm)\nimport matplotlib.pyplot as plt\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfig, ax = plot_confusion_matrix(conf_mat=cm[1])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}