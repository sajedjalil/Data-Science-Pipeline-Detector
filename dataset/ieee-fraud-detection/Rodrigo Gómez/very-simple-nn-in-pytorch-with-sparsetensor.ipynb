{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IEEE-CIS Fraud Detection"},{"metadata":{},"cell_type":"markdown","source":"In this notebook we show a very simple example of PyTorch on sparse data in the competition IEEE-CIS Fraud Detection."},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.sparse import load_npz\nimport gc\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.metrics import average_precision_score, roc_auc_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select cuda device and set a seed."},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.set_device(0)\ntorch.cuda.manual_seed_all(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data\nWe load the data on npz compressed format (~20 MB train and test sets). For now, data is omitted.\n\nBrief data description:\n\n- dummies on categorical data.\n- split in 512 bins continuous data and dummies.\n\nFinally, we have about 13k columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_folder = '/kaggle/input/sparse-data-v3/'\nX_train = load_npz(data_folder+'/train.npz')\nX_test = load_npz(data_folder+'/test.npz')\ny_train = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv', usecols=['isFraud', 'TransactionDT']).sort_values('TransactionDT')['isFraud']\nprint(X_train.shape, X_test.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A function to transform data from csr_matrix format to PyTorch sparse tensor."},{"metadata":{"trusted":false},"cell_type":"code","source":"def from_csr_to_tensor(X, y):\n    x_batch = X.tocoo()\n    x_batch = torch.sparse_coo_tensor(indices = torch.cuda.LongTensor([x_batch.row.tolist(), x_batch.col.tolist()]),\n                            values = torch.cuda.FloatTensor(x_batch.data), size=[X.shape[0], X_train.shape[1]])\n    y_batch = torch.from_numpy(y.values)\n    x_batch = x_batch.type(torch.cuda.FloatTensor)\n    y_batch = y_batch.type(torch.cuda.FloatTensor)\n    \n    return x_batch, y_batch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split data in 80% train, 20% test, sorted by TransactionDT"},{"metadata":{"trusted":false},"cell_type":"code","source":"rows = X_train.shape[0]\nrows_split = int(rows*0.8)\nprint(rows, rows_split)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_valid = X_train[rows_split:]\ny_valid = y_train[rows_split:]\nX_fit = X_train[:rows_split]\ny_fit = y_train[:rows_split]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transform valid data to sparse tensor. Fit data will be transformed into each mini-batch."},{"metadata":{"trusted":false},"cell_type":"code","source":"x_batch_valid, y_batch_valid = from_csr_to_tensor(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neuronal Network"},{"metadata":{"trusted":false},"cell_type":"code","source":"class MyClassifier(nn.Module):\n    def __init__(self):\n        super(MyClassifier,self).__init__()\n        self.fc1 = nn.Linear(X_train.shape[1], 1024)\n        self.relu1 = nn.ReLU()\n        self.dout1 = nn.Dropout(0.25)\n        self.fc2 = nn.Linear(1024, 2048)\n        self.relu2 = nn.ReLU()\n        self.dout2 = nn.Dropout(0.25)\n        self.fc3 = nn.Linear(2048, 512)\n        self.relu3 = nn.ReLU()\n        self.dout3 = nn.Dropout(0.2)\n        self.fc4 = nn.Linear(512, 64)\n        self.prelu = nn.PReLU(1)\n        self.out = nn.Linear(64, 1)\n        self.out_act = nn.Sigmoid()\n        \n    def forward(self, input_):\n        a1 = self.fc1(input_)\n        h1 = self.relu1(a1)\n        dout1 = self.dout1(h1)\n        a2 = self.fc2(dout1)\n        h2 = self.relu2(a2)\n        dout2 = self.dout2(h2)\n        a3 = self.fc3(dout2)\n        h3 = self.relu3(a3)\n        dout3 = self.dout3(h3)\n        a4 = self.fc4(dout3)\n        h4 = self.prelu(a4)\n        a5 = self.out(h4)\n        y = self.out_act(a5)\n        return y\n              \n    def predict(self, x):\n        #Apply softmax to output. \n        pred = F.softmax(self.forward(x))\n        return torch.tensor(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Initialize the model        \nmodel = MyClassifier()\nmodel.cuda()\n#Define loss criterion\ncriterion = nn.BCELoss()\n#Define the optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.004)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train\n\nTrain the NN with Time Series 80/20 split to determine which is the optimal epoch."},{"metadata":{"trusted":false},"cell_type":"code","source":"#Number of epochs\nepochs = 50\n#Batch size\nbatch_size = 16368\n#Losses\nlosses = []\n#Early-Stopping\nbest_epoch = 0\nlast_score = 0\nes_rounds = 2\n#Range\nRango = range(0, X_fit.shape[0], batch_size)\nlen_Rango = len(list(Rango))\n\nfor i in range(1, epochs+1):\n    print('Training epoch {}'.format(i))\n    loss_epoch = 0\n    loss_valid = 0\n    loss_aps = 0\n    loss_auc = 0\n    loss_auc_valid = 0\n    loss_aps_valid = 0\n    model.train()\n    for j in Rango:\n        x_batch, y_batch = from_csr_to_tensor(X_fit[j:j+batch_size], y_fit[j:j+batch_size])\n        #Clear the previous gradients\n        optimizer.zero_grad()\n        #Precit the output for Given input\n        y_pred = model(x_batch)\n        #Compute Cross entropy loss\n        loss = criterion(y_pred, y_batch)\n        del x_batch\n        del y_batch\n        torch.cuda.empty_cache()\n        gc.collect()\n        #Compute gradients\n        loss.backward()\n        #Adjust weights\n        optimizer.step()\n        \n    #Validate data with model.eval()    \n    model.eval()\n    y_pred_valid = model(x_batch_valid)\n    loss_val = criterion(y_pred_valid, y_batch_valid)\n    loss_valid += loss_val.item()\n    loss_auc_valid += roc_auc_score(y_batch_valid.data.cpu().numpy(), y_pred_valid.data.cpu().numpy())\n    loss_aps_valid += average_precision_score(y_batch_valid.data.cpu().numpy(), y_pred_valid.data.cpu().numpy())\n        \n    losses.append([loss_epoch, loss_valid, loss_auc, loss_auc_valid, loss_aps, loss_aps_valid])\n    print(f'trains loss: {loss_epoch}, trains AUC: {loss_auc}, trains APS: {loss_aps}')\n    print(f'tests loss: {loss_valid}, tests AUC: {loss_auc_valid}, tests APS: {loss_aps_valid}')\n        \n    if last_score <= loss_auc_valid:\n        last_score = loss_auc_valid\n        best_epoch = i\n        es_rounds = 2\n    else:\n        if es_rounds > 0:\n            es_rounds -=1\n        else:\n            print('EARLY-STOPPING !')\n            print('Best epoch found: nÂº {}'.format(best_epoch))\n            print('Exiting. . .')\n            break\n\n\nplt.figure(figsize=(16,12))\nplt.subplot(3, 1, 1)\nplt.title('Score per epoch')\nplt.ylabel('Binary Cross-entropy')\n# plt.plot(list(range(len(losses))), [x[0] for x in losses], label=['Trains BCE loss'])\nplt.plot(list(range(len(losses))), [x[1] for x in losses], label=['Valids BCE loss'])\nplt.legend()\nplt.subplot(3, 1, 2)\nplt.ylabel('ROC-AUC Score')\n# plt.plot(list(range(len(losses))), [x[2] for x in losses], label=['Trains ROC_AUC'])\nplt.plot(list(range(len(losses))), [x[3] for x in losses], label=['Valids ROC_AUC'])\nplt.legend()\nplt.subplot(3, 1, 3)\nplt.xlabel('Epoch')\nplt.ylabel('PR-AUC Score')\n# plt.plot(list(range(len(losses))), [x[4] for x in losses], label=['Trains PR_AUC'])\nplt.plot(list(range(len(losses))), [x[5] for x in losses], label=['Valids PR_AUC'])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Re-fitting with all train data and the best number of epochs."},{"metadata":{"trusted":false},"cell_type":"code","source":"model = MyClassifier()\nmodel.cuda()\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.004)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.train()\nfor i in range(1, best_epoch+1):\n    print('Training epoch {}'.format(i))\n    loss_epoch = 0\n    loss_aps = 0\n    loss_auc = 0\n    for j in Rango:\n        x_batch, y_batch = from_csr_to_tensor(X_train[j:j+batch_size], y_train[j:j+batch_size])\n        #Clear the previous gradients\n        optimizer.zero_grad()\n        #Precit the output for Given input\n        y_pred = model(x_batch)\n        #Compute Cross entropy loss\n        loss = criterion(y_pred, y_batch)\n        #Compute gradients\n        loss.backward()\n        #Adjust weights\n        optimizer.step()\n        \n    del x_batch\n    del y_batch\n    torch.cuda.empty_cache()\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del x_batch_valid\ndel y_batch_valid\ndel X_fit\ndel y_fit\ndel X_valid\ndel y_valid\ntorch.cuda.empty_cache()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test\n\nTest set predictions in batches to avoid CUDA Memory Errors."},{"metadata":{"trusted":false},"cell_type":"code","source":"batch_size = 16368\ny_dummy = pd.Series(np.array([1,1]))\nRango = range(0, X_test.shape[0], batch_size)\nlen_Rango = len(list(Rango))\n\nmodel.eval()\n\nfinal_preds = np.array([])\n\nfor j in Rango:\n    x_batch_valid, _ = from_csr_to_tensor(X_test[j:j+batch_size], y_dummy)\n    y_pred_valid = model(x_batch_valid)\n    y_pred_valid = y_pred_valid.data.cpu().numpy()\n    \n    final_preds = np.concatenate((final_preds, y_pred_valid), axis=None)\n\n    del x_batch_valid\n    del y_pred_valid\n    torch.cuda.empty_cache()\n    gc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save final submission"},{"metadata":{"trusted":false},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')\nsubmission['isFraud'] = final_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', sep=',', header=True, index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}