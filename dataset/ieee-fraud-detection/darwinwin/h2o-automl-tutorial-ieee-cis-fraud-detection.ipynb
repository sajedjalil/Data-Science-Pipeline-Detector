{"cells":[{"metadata":{},"cell_type":"markdown","source":"# H2O AutoML tutorial on IEEE-CIS Fruad detection compitition"},{"metadata":{},"cell_type":"markdown","source":"<img src='https://image.slidesharecdn.com/joeamsautoml-171107063815/95/using-h2o-automl-for-kaggle-competitions-10-638.jpg'></img>"},{"metadata":{},"cell_type":"markdown","source":"### The objective of this kernel is to detect fraudulant transactions taking place on a ecommerce site using H2O AutoML\n\n### This kernel helps provide a fair understanding of the H2O's AutoML and it's syntactic nitty gritties. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Standard imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#to show the large number of features in this dataset\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the H2O library and Starting a local H2O cluster (on your machine)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\n# Number of threads, nthreads = -1, means use all cores on your machine\n# max_mem_size is the maximum memory (in GB) to allocate to H2O\nh2o.init(nthreads = -1, max_mem_size = 16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Prep"},{"metadata":{},"cell_type":"markdown","source":"We shall first import the data in a pandas dataframe, carry out a memory reduction operation on the dataset (pandas dataframe) and then load it in a H2OFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Based on this great kernel https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65\ndef reduce_mem_usage(df):\n    start_mem_usg = df.memory_usage().sum() / 1024**2 \n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in df.columns:\n        if df[col].dtype != object:  # Exclude strings      \n            # make variables for Int, max and min\n            IsInt = False\n            mx = df[col].max()\n            mn = df[col].min()            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(df[col]).all(): \n                NAlist.append(col)\n                df[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = df[col].fillna(0).astype(np.int64)\n            result = (df[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True            \n            # Make Integer/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < 65535:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        df[col] = df[col].astype(np.uint32)\n                    else:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)    \n            # Make float datatypes 32 bit\n            else:\n                df[col] = df[col].astype(np.float32)\n\n    return df, NAlist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import Dataset\ntrain_identity= pd.read_csv(\"../input/train_identity.csv\", index_col='TransactionID')\ntrain_transaction= pd.read_csv(\"../input/train_transaction.csv\", index_col='TransactionID')\ntest_identity= pd.read_csv(\"../input/test_identity.csv\", index_col='TransactionID')\ntest_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creat our train & test dataset\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Delete the imports to free up memory\ndel train_identity,train_transaction,test_identity, test_transaction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Memory reduction for train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, NAlist = reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The size of train dataset reduced by almost 65% after the operation (for the sake of simplicity, size reduction logs have not been printed)"},{"metadata":{},"cell_type":"markdown","source":"### Memory reduction for Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test, NAlist = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The size of train dataset reduced by almost 76% after the operation (for the sake of simplicity, size reduction logs have not been printed)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting the pandas dataframe (memory reduced) to H2OFrame"},{"metadata":{},"cell_type":"markdown","source":"Also, encoding the response variable to factor is important bacause otherwise H2O will asssume it as numeric and will train a regression model instead of a classifiaction model."},{"metadata":{"trusted":true},"cell_type":"code","source":"hf_train = h2o.H2OFrame(train)\nhf_test = h2o.H2OFrame(test)\n#encode the binary repsonse as a factor\nhf_train['isFraud'] = hf_train['isFraud'].asfactor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Partition data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Partition data into 70%, 15%, 15% chunks\n# Setting a seed will guarantee reproducibility\n\nsplits = hf_train.split_frame(ratios=[0.7, 0.15], seed=1)  \n\ntrain_x = splits[0]\nvalid = splits[1]\ntest_x = splits[2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that split_frame() uses approximate splitting not exact splitting (for efficiency), so these are not exactly 70%, 15% and 15% of the total rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_x.nrow)\nprint(valid.nrow)\nprint(test_x.nrow)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting the target and predictor variables\n\nIn H2O, we use y to designate the response variable and x to designate the list of predictor columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"y = 'isFraud'\nx = list(hf_train.columns)\nx.remove(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a stacked Emsemble Model"},{"metadata":{},"cell_type":"markdown","source":"# 1. Generate a 2-model stacked ensemble (GBM + RF)**\n\n### Train and cross-validate a GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of CV folds (to generate level-one data for stacking)\nnfolds = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_gbm = H2OGradientBoostingEstimator(distribution=\"bernoulli\",\n                                      ntrees=10,\n                                      max_depth=3,\n                                      min_rows=2,\n                                      learn_rate=0.2,\n                                      nfolds=nfolds,\n                                      fold_assignment=\"Modulo\",\n                                      keep_cross_validation_predictions=True,\n                                      seed=1)\nmy_gbm.train(x=x, y=y, training_frame=train_x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train and cross-validate a RF"},{"metadata":{},"cell_type":"markdown","source":"The default number of trees in an H2O Random Forest is 50, here, we have taken ntrees=100 so this RF will be twice as big as the default. Usually increasing the number of trees in an RF will increase performance as well. "},{"metadata":{"trusted":true},"cell_type":"code","source":"my_rf = H2ORandomForestEstimator(ntrees=100,\n                                 nfolds=nfolds,\n                                 fold_assignment=\"Modulo\",\n                                 keep_cross_validation_predictions=True,\n                                 seed=1)\nmy_rf.train(x=x, y=y, training_frame=train_x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train a stacked ensemble using the GBM and RF above"},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_binomial\",\n                                       base_models=[my_gbm, my_rf])\nensemble.train(x=x, y=y, training_frame=train_x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Eval ensemble performance on the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"stack_test = ensemble.model_performance(test_x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compare to base learner performance on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"perf_gbm_test = my_gbm.model_performance(test_x)\nperf_rf_test = my_rf.model_performance(test_x)\nbaselearner_best_auc_test = max(perf_gbm_test.auc(), perf_rf_test.auc())\nstack_auc_test = stack_test.auc()\nprint(\"Best Base-learner Test AUC:  {0}\".format(baselearner_best_auc_test))\nprint(\"Ensemble Test AUC:  {0}\".format(stack_auc_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate predictions on test set \npred = ensemble.predict(hf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/sample_submission.csv')\nsample_submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['isFraud'] = pred['p1'].as_data_frame().values\nsample_submission.to_csv('h2o_automl_submission_3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This kernel acts as a baseline for H2o AutoML stacked ensembles'. One can further build high performance models by adding/removing base learners, hyperparameter tuning etc.\n\n**Please upvote the kernel if you found it helpful.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}