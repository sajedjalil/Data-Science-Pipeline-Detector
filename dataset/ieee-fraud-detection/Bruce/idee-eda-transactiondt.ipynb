{"cells":[{"metadata":{},"cell_type":"markdown","source":"## This notebook's purpose is to provide an EDA on the TransactionDT"},{"metadata":{},"cell_type":"markdown","source":"This kernel has been inspired by https://www.kaggle.com/artkulak/ieee-fraud-simple-baseline-0-9383-lb"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport random\n\n#plotly packages\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tools\n\n#Modelling\nimport os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_transaction = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n\ntrain_identity = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\n\nsample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(train.shape)\nprint(test.shape)\n\ny_train = train['isFraud'].copy()\ndel train_transaction, train_identity, test_transaction, test_identity\n\n# Drop target, fill in NaNs\nX_train = train.drop('isFraud', axis=1)\nX_test = test.copy()\n\ndel train, test\n\n# Label Encoding\nfor f in X_train.columns:\n    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n        X_train[f] = lbl.transform(list(X_train[f].values))\n        X_test[f] = lbl.transform(list(X_test[f].values))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# From kernel https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n# WARNING! THIS CAN DAMAGE THE DATA \ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\nX_train = reduce_mem_usage(X_train)\nX_test = reduce_mem_usage(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values(df):\n    percent_missing = df.isnull().sum() * 100 / len(df)\n    missing_value_df = pd.DataFrame({'column_name': df.columns,\n                                     'percent_missing': percent_missing})\n    return missing_value_df\n\ndata = [go.Bar(\n            x=missing_values(X_train).column_name,\n            y=missing_values(X_train).percent_missing\n    )]\nlayout = go.Layout(\n    autosize=False,\n    width=1000,\n    height=500,\ntitle = 'Missing Values by Column')\nfig = go.Figure(data=data, layout=layout)\npy.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TransactionDT Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['data'] = 'X_train'\nX_test['data'] = 'X_test'\n\nX_train_test = pd.concat([X_train, X_test], axis = 1)\nprint(X_train_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [\n    go.Scatter(\n        x=X_train.TransactionDT, # assign x as the dataframe column 'x'\n        y=X_train.TransactionAmt,\n        name='X_train'\n    )\n#     ,\n#     go.Scatter(\n#         x=X_test.TransactionDT, # assign x as the dataframe column 'x'\n#         y=X_test.TransactionAmt,\n#         name='X_test'\n#     )\n]\nfig = data\npy.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pick_color():\n    colors = [\"blue\",\"black\",\"brown\",\"red\",\"yellow\",\"green\",\"orange\",\"beige\",\"turquoise\",\"pink\"]\n    random.shuffle(colors)\n    return colors[0]\n\ndef Hist_plot(data,i):\n    trace0 = go.Histogram(\n        x= data.iloc[:,i],\n        name = str(data.columns[i]),\n        nbinsx = 100,\n        marker= dict(\n            color=pick_color(),\n            line = dict(\n                color = 'black',\n                width = 0.5\n              ),\n        ),\n        opacity = 0.70,\n  )\n    fig_list = [trace0]\n    title = str(data.columns[i])\n    return fig_list, title\n    \ndef Plot_grid(data, ii, ncols=2):\n    plot_list = list()\n    title_list = list()\n    \n    #Saving all the plots in a list\n    for i in range(ii):\n        p = Hist_plot(data,i)\n        plot_list.append(p[0])\n        title_list.append(p[1])\n    \n    #Creating the grid\n    nrows = max(1,ii//ncols)\n    i = 0\n    fig = tools.make_subplots(rows=nrows, cols=ncols, subplot_titles = title_list)\n    for rows in range(1,nrows+1):\n        for cols in range(1,ncols+1):\n            fig.append_trace(plot_list[i][0], rows, cols)\n            i += 1\n    fig['layout'].update(height=400*nrows, width=1000)\n    return py.offline.iplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Plot_grid(X_train, 6,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}