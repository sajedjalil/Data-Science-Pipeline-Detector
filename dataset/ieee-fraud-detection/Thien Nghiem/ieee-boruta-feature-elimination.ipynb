{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# About Boruta Feature Elimination\n\nThe Boruta algorithm is a wrapper built around the random forest classification algorithm. The algorithm tries to evaluate the features to rank their importance with respect to the target variable. Boruta compares the feature importance (Z-score) with the feature importance produced by a shuffled copy of the original dataset (called shadow features). Each time the feature has a higher Z-score than the maximum Z-score of its shadow features than the best of the shadow features, Robuta record a \"hits\" for that feature.\n\nIf a feature don't record a hit in certain amount of iteration, we put it in the reject bin.\n\nHigh-level description can be found here: https://www.datacamp.com/community/tutorials/feature-selection-R-boruta\n\nOriginal paper: https://www.jstatsoft.org/article/view/v036i11/v36i11.pdf\n\nPython Implementation Kernel:https://www.kaggle.com/tilii7/boruta-feature-elimination/notebook\n\n\n**Note**: Depend on your data size, Boruta will takes while to complete. Mine took ~5 hours.\n\nI can only run with almost half the dataset due to Kaggle 16GB ram limitation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity = pd.read_csv(\"../input/ieee-fraud-detection/train_identity.csv\", index_col='TransactionID')\ntrain_transaction = pd.read_csv(\"../input/ieee-fraud-detection/train_transaction.csv\", index_col='TransactionID')\n\ntrain_identity = reduce_mem_usage(train_identity)\ntrain_transaction = reduce_mem_usage(train_transaction)\n\ntrain_full = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n\ntrain_full = train_full.sample(frac = 0.4, random_state = 42)\n\ndel train_identity, train_transaction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection\n\nIn the baseline model, we learned that the information poor features such as TransactionDT was among the most important features. We will try Boruta, a method of eliminating these features by only capture the important, interesting features that have high degree of influence on the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom boruta import BorutaPy\n\ntrain_full = train_full.fillna(-999)\n\n# Label Encoding\nfor f in train_full.columns:\n    if train_full[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train_full[f].values)) \n        train_full[f] = lbl.transform(list(train_full[f].values))\n\nX = train_full.drop('isFraud', axis = 1).values\ny = train_full['isFraud'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run Boruta \nrfc = RandomForestClassifier(n_estimators='auto', n_jobs=4, max_depth=6)\nboruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, max_iter = 70)\nboruta_selector.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of selected features\nprint ('\\n Number of selected features:')\nprint (boruta_selector.n_features_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity = pd.read_csv(\"../input/ieee-fraud-detection/train_identity.csv\", index_col='TransactionID')\ntrain_transaction = pd.read_csv(\"../input/ieee-fraud-detection/train_transaction.csv\", index_col='TransactionID')\n\ntrain_full = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n\nfeature_df = pd.DataFrame(train_full.drop(['isFraud'], axis=1).columns.tolist(), columns=['features'])\nfeature_df['rank']=boruta_selector.ranking_\nfeature_df = feature_df.sort_values('rank', ascending=True).reset_index(drop=True)\nprint ('\\n Top %d features:' % boruta_selector.n_features_)\nprint (feature_df.head(boruta_selector.n_features_))\nfeature_df.to_csv('feature-ranking.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check selected features\nselected_features = train_full.drop('isFraud', axis = 1).columns[boruta_selector.support_]\nrejected_features = train_full.drop('isFraud', axis = 1).columns[boruta_selector.support_ == False]\n\nprint('List of selected features: \\n', selected_features)\nprint('\\nList of rejected features: \\n', rejected_features)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}