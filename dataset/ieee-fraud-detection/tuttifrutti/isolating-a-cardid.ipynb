{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Isolate a cardID\nUnique card identifier was often called \"magic feature\", it indeed gives a great boost to the models if identified, but reconstructing it is quite straightforward.\n\nThis is the first of a two parts kernel series, in the second one we are going to identify a user."},{"metadata":{},"cell_type":"markdown","source":"### Let's begin\n<img src=\"https://images.tailorstore.com/YToyOntzOjU6IndpZHRoIjtzOjQ6IjEwMDAiO3M6NjoiaGVpZ2h0IjtzOjA6IiI7fQ%3D%3D/images/cms/TS-Sleeves-4.jpg\" alt=\"remontetesmanchesfrangin\" width=\"500\">"},{"metadata":{},"cell_type":"markdown","source":"Have a look at this kernel, which is a starting point to the present one:\nhttps://www.kaggle.com/tuttifrutti/creating-features-from-d-columns-guessing-userid\n\nBasicaly, it says that D1 is the number of days elapsed since the first transaction of a card. So that in order to identify a unique card, we could aggregate card1 to card6 (which we assume is stable by card), and D1 minus day."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ntrain_transaction = pd.read_csv('../input/ieee-fraud-detection/train_transaction.csv')        \ntrain_identity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')\ntrain_transaction = train_transaction.merge(train_identity, how='left', left_on='TransactionID',right_on='TransactionID')\ndel train_identity","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import itertools\nimport math\nimport networkx as nx\n\n#function to create keys based on multiple columns\ndef create_key(df, cols, name_new_col):\n    '''\n    df: pandas dataframe\n    cols: list of columns composing the key\n    name_new_col: name given to the new column\n    '''\n    df.loc[:,name_new_col] = ''\n    for col in cols:\n        df.loc[:,name_new_col] = df.loc[:,name_new_col] + df.loc[:,col].astype(str)\n    return df  \n\ndef truncate(f, n):\n    return math.floor(f * 10 ** n) / 10 ** n  \n\ndef merge(list1, list2): \n    merged_list = [[p1, p2] for idx1, p1 in enumerate(list1)  \n    for idx2, p2 in enumerate(list2) if idx1 == idx2] \n    return merged_list   \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the cell below, I create the cardID resulting of the starting point notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['day'] = train_transaction['TransactionDT']/(3600*24)\ntrain_transaction['D1minusday'] = (train_transaction['D1']-train_transaction['day']).replace(np.nan, -9999).map(int)\ncolsID = ['card1','card2','card3','card4','card5','card6','D1minusday','ProductCD']\ntrain_transaction = create_key(train_transaction, colsID, 'cardID_D1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['cardID_D1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, here we go. We obviously do not identify unique cards with this combination. We assume that a unique card cannot process 1414 transactions in a period of 6 months, neither 480. **We need to find something more robust.**\n\nIn the identity data, we have some informations about the device used, the browser, its version ect... \nWe can assume that a sequence of fraudulent transactions in a short timeframe, from the same card group we have created, made from the same Device has great chances to come from the same user right? <br>\nLet's have a look then at this kind of sequences and try to derive information from other variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_transaction[(train_transaction.isFraud==1) & (train_transaction.ProductCD==\"C\")])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['V307'] = train_transaction['V307'].fillna(0)\ntrain_transaction['V307plus'] = train_transaction['V307']+train_transaction['TransactionAmt']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As there are not that many, let's export all the frauds from product C in excel and see what we can find. Excel is so underrated, and I find it to be much easier to explore data with this tool, when the circumstances permit it (it is the case most of the time).\n\nSo after looking at the cluster in short time frame of devices, same amounts, or other variables that might indicate a unique user, we find that V307 represents the cumsum of the transactions of the same card groups.\n\nSo we could join the V307 to reconstruct the card.\n\nI've created a column, V307plus, which is the transaction Amt plus V307 of the same line. The result is the value expected for V307 on the next transaction of the same card. <br>\nHere I have colored the groups respecting the sequence for a same card group created previously (try to match V307plus, with the next V307, and you'll find the sequences)\n\n\n<img src=\"https://i.ibb.co/NKCHH7M/Capture-d-cran-de-2019-09-27-21-44-34.png\" alt=\"V307V307plus\">\n\nBy the way, it seems that the first card was used on multiple device, this could be great feature.\n\nBack to our notebook. Let's create the V307plus feature and try to recreate the sequences of cards."},{"metadata":{},"cell_type":"markdown","source":"Basically we have to find the V307 that matches V307plus. Like the V307 value of ID 3030465 with V307plus of 3026025"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.loc[(train_transaction.TransactionID==3030465),'V307'].values[0] == train_transaction.loc[(train_transaction.TransactionID==3026025),'V307plus'].values[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ho wait! it does not match. \n\nThe reason is that TransactionAmt suffered from some rounding or truncating.\n\nLet's create some variants of V307 and TransactionAmt and see if we can reconstruct the cards (the parameters of the roundings and truncatings in the following cell were found after some trial and errors)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction['V307rtrunc'] = train_transaction['V307'].apply(lambda x: truncate(x,3))\ntrain_transaction['V307round'] = train_transaction['V307'].apply(lambda x: round(x,3))\ntrain_transaction['V307plusround'] = train_transaction['V307plus'].apply(lambda x: round(x,4))\ntrain_transaction['V307plusroundtrunc'] = train_transaction['V307plusround'].apply(lambda x: truncate(x,3))\ntrain_transaction['V307plusround'] = train_transaction['V307plus'].apply(lambda x: round(x,3))\ntrain_transaction['V307trunc2'] = train_transaction['V307'].apply(lambda x: truncate(x,2))\ntrain_transaction['V307plustrunc2'] = train_transaction['V307plus'].apply(lambda x: truncate(x,2))\ntrain_transaction['TransactionAmttrunq'] = train_transaction['TransactionAmt'].apply(lambda x: round(x,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And try to find the couples of TransactionID that have matching V307 and V307plus based on a transformation of V307 and V307plus (truncated for the first one, and round then truncated for the second)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#the card group of interest for this example\ncard_group = train_transaction[train_transaction.cardID_D1=='16136204.0185.0visa138.0debit108C']\n\nlist1 = card_group['V307plusroundtrunc'].tolist()\nlist2 = card_group['V307rtrunc'].tolist()\nkv = []\nres = [[list(filter(lambda z: list1[z]==x, range(len(list1)))),list(filter(lambda z: list2[z]==x, range(len(list2))))] for x in list1 if x in list2] #find the pairs\nres= [list(map(kv.append,map(list,(itertools.product(*sublist))))) for sublist in res] #drop duplicates from list of list\nres = list(map(list, set(map(lambda i: tuple(i), kv)))) #create list of couple indexes\nlist1 = card_group.iloc[[i[0] for i in res]]['TransactionID'].tolist()\nlist2 = card_group.iloc[[i[1] for i in res]]['TransactionID'].tolist()\nliste_existstrun = merge(list1, list2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"liste_existstrun","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get the following couples of TransactionID that match based on these transformations of V307 and V307plus. Let's group them"},{"metadata":{"trusted":true},"cell_type":"code","source":"L = liste_existstrun\nG = nx.Graph()\n\nG.add_nodes_from(sum(L, []))\nq = [[(s[i],s[i+1]) for i in range(len(s)-1)] for s in L]\nfor i in q:\n    G.add_edges_from(i)\ngroup_list = [list(i) for i in nx.connected_components(G)]\ngroup_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that we were successful, in drawing 6 groups with these transformations of V307 features.\nBut we had 5 groups in this card group (based on D1 minus day and card1-6).\n\nAfter many iterations, trial and errors, i ended-up with the following function, grouping based on:\n- matching V307plus rounded (4 decimals) then truncated (3dec), and V307 rounded (3dec)\n- V307plus rounded and V307 rounded (3dec)\n- V307plus and V307 truncated  (2dec)\n- V307 rounded and TransactionAmt truncated (sometimes a Transaction is not counted in V307, and repeat a previous Amount value)\n\nYou can see that here you have to make your assumptions, and that the result will depend strongly on them."},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_groups(aa):\n    group_list = []\n    \n    #get the couples by existstrun\n    list1 = aa['V307plusroundtrunc'].tolist()\n    list2 = aa['V307rtrunc'].tolist()\n    kv = []\n    res = [[list(filter(lambda z: list1[z]==x, range(len(list1)))),list(filter(lambda z: list2[z]==x, range(len(list2))))] for x in list1 if x in list2] #find the pairs\n    res= [list(map(kv.append,map(list,(itertools.product(*sublist))))) for sublist in res] #drop duplicates from list of list\n    res = list(map(list, set(map(lambda i: tuple(i), kv)))) #create list of couple indexes\n    list1 = aa.iloc[[i[0] for i in res]]['TransactionID'].tolist()\n    list2 = aa.iloc[[i[1] for i in res]]['TransactionID'].tolist()\n    liste_existstrun = merge(list1, list2)\n\n\n    #get the couples by existsroundtrunc\n    list1 = aa['V307plusroundtrunc'].tolist()\n    list2 = aa['V307round'].tolist()\n    kv = []\n    res = [[list(filter(lambda z: list1[z]==x, range(len(list1)))),list(filter(lambda z: list2[z]==x, range(len(list2))))] for x in list1 if x in list2] #find the pairs\n    res= [list(map(kv.append,map(list,(itertools.product(*sublist))))) for sublist in res] #drop duplicates from list of list\n    res = list(map(list, set(map(lambda i: tuple(i), kv)))) #create list of couple indexes\n    list1 = aa.iloc[[i[0] for i in res]]['TransactionID'].tolist()\n    list2 = aa.iloc[[i[1] for i in res]]['TransactionID'].tolist()\n    liste_existsroundtrunc = merge(list1, list2)\n\n    #get the couples by existsroundtrunc\n    list1 = aa['V307plusround'].tolist()\n    list2 = aa['V307round'].tolist()\n    kv = []\n    res = [[list(filter(lambda z: list1[z]==x, range(len(list1)))),list(filter(lambda z: list2[z]==x, range(len(list2))))] for x in list1 if x in list2] #find the pairs\n    res= [list(map(kv.append,map(list,(itertools.product(*sublist))))) for sublist in res] #drop duplicates from list of list\n    res = list(map(list, set(map(lambda i: tuple(i), kv)))) #create list of couple indexes\n    list1 = aa.iloc[[i[0] for i in res]]['TransactionID'].tolist()\n    list2 = aa.iloc[[i[1] for i in res]]['TransactionID'].tolist()\n    liste_existsroundround = merge(list1, list2)\n\n\n    #get the couples by existsroundtrunc\n    list1 = aa['V307trunc2'].tolist()\n    list2 = aa['V307plustrunc2'].tolist()\n    kv = []\n    res = [[list(filter(lambda z: list1[z]==x, range(len(list1)))),list(filter(lambda z: list2[z]==x, range(len(list2))))] for x in list1 if x in list2] #find the pairs\n    res= [list(map(kv.append,map(list,(itertools.product(*sublist))))) for sublist in res] #drop duplicates from list of list\n    res = list(map(list, set(map(lambda i: tuple(i), kv)))) #create list of couple indexes\n    list1 = aa.iloc[[i[0] for i in res]]['TransactionID'].tolist()\n    list2 = aa.iloc[[i[1] for i in res]]['TransactionID'].tolist()\n    liste_existstrunc2 = merge(list1, list2)\n\n\n    #get the couples by existsamount\n    list1 = aa['TransactionAmttrunq'].tolist()\n    list2 = aa['V307round'].tolist()\n    kv = []\n    res = [[list(filter(lambda z: list1[z]==x, range(len(list1)))),list(filter(lambda z: list2[z]==x, range(len(list2))))] for x in list1 if x in list2] #find the pairs\n    res= [list(map(kv.append,map(list,(itertools.product(*sublist))))) for sublist in res] #drop duplicates from list of list\n    res = list(map(list, set(map(lambda i: tuple(i), kv)))) #create list of couple indexes\n    list1 = aa.iloc[[i[0] for i in res]]['TransactionID'].tolist()\n    list2 = aa.iloc[[i[1] for i in res]]['TransactionID'].tolist()\n    liste_existsamount = merge(list1, list2)\n\n    #get by exact same amount\n    a=[]\n    liste_sameamount = aa.groupby('TransactionAmt')['TransactionID'].apply(list).tolist()\n    res = [list(map(a.append, map(list,zip(i, i[1:] + i[:1])))) for i in liste_sameamount]\n\n    group_list.extend(liste_existstrun)\n    group_list.extend(liste_existsroundtrunc)\n    group_list.extend(liste_existsamount)\n    group_list.extend(liste_existsroundround)\n    group_list.extend(liste_existstrunc2)\n\n    group_list.extend(a)\n\n    L = group_list\n    G = nx.Graph()\n    G.add_nodes_from(sum(L, []))\n    q = [[(s[i],s[i+1]) for i in range(len(s)-1)] for s in L]\n    for i in q:\n        G.add_edges_from(i)\n    group_list = [list(i) for i in nx.connected_components(G)]\n    return group_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groups_found = find_groups(card_group)\ngroups_found","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And here we go, we found the 5 groups that we identified in our Excel!\n\n<img src=\"https://i.ibb.co/NKCHH7M/Capture-d-cran-de-2019-09-27-21-44-34.png\" alt=\"V307V307plus\">"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}