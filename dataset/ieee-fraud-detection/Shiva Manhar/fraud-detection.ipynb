{"cells":[{"metadata":{},"cell_type":"markdown","source":"I seen <code>train_transaction.csv</code> file that lots of missing value. when lots of missing value in the dataset definitely that effect in over result.\nI am only taking a 20% dataset data and I know when taking sample size small that result is overfitted. \n\n\n<ul>\n    <li> Data Exploration </li>\n    <li> Data visualization </li>\n    <li> Create feature </li>\n    <li> Make pipline </li>\n    <li> Predict result </li>\n    <li> Submit result </li>\n    <li> Conclusion </li>\n</ul>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\nfrom catboost import CatBoostRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import  RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nlbl = LabelEncoder()\nimport os\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\n%matplotlib inline\nprint(os.listdir(\"../input\"))\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load train data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"path = \"../input/\"\ntrain_identity = pd.read_csv(path+'train_identity.csv')\ntrain_transaction = pd.read_csv(path+'train_transaction.csv')\ntest_identity = pd.read_csv(path+'test_identity.csv')\ntest_transaction = pd.read_csv(path+'test_transaction.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It will be comment before final submission\ntrain_transaction = train_transaction.sample(frac=0.05, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_identity.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transaction.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train transaction are cols {} and rows {}\".format(train_transaction.shape[0], train_transaction.shape[1]))\nprint(\"Train identity are cols {} and rows {}\".format(train_identity.shape[0], train_identity.shape[1]))\nprint(\"Train transaction are cols {} and rows {}\".format(test_transaction.shape[0], test_transaction.shape[1]))\nprint(\"Train identity are cols {} and rows {}\".format(test_identity.shape[0], test_identity.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"I got to join this both the datashet then prepare features after that apply this feature in many models. The column name TransactionID is the same in both tables."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.merge(train_transaction, train_identity, how='left', left_on=['TransactionID'], right_on=['TransactionID'], right_index=False)\ntest_df = pd.merge(test_transaction, test_identity, how='left', left_on=['TransactionID'], right_on=['TransactionID'], right_index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After join dataset check numbers of rows and columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train dataframe are cols {} and rows {}\".format(train_df.shape[0], train_df.shape[1]))\nprint(\"test dataframe are cols {} and rows {}\".format(test_df.shape[0], test_df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Total required 506691 cols in final submition."},{"metadata":{},"cell_type":"markdown","source":"Explore datashet."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[[\"ProductCD\", \"isFraud\"]].groupby(['ProductCD'], as_index=False).mean().sort_values(by='isFraud', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(test_df['card6'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[[\"card6\", \"isFraud\"]].groupby(['card6'], as_index=False).mean().sort_values(by='isFraud', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(test_df['card4'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[[\"card4\", \"isFraud\"]].groupby(['card4'], as_index=False).mean().sort_values(by='isFraud', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_df['ProductCD'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_fraud = train_df.loc[(train_df['isFraud'] == 1),].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fraud_percentage = (total_fraud*100)/train_df.shape[0]\nprint(\"Total fraud percenate \",format(fraud_percentage,'.2f'),\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total transaction amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(train_df['TransactionAmt'].sum(), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Max transaction amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(train_df['TransactionAmt'].max(),2 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Max fraud amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[(train_df['isFraud'] == 1),'TransactionAmt'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Min fraud amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[(train_df['isFraud'] == 1),'TransactionAmt'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total fraud amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"format(train_df.loc[(train_df['isFraud'] == 1),'TransactionAmt'].sum(), '.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percentage of fraud amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"format((train_df.loc[(train_df['isFraud'] == 1),'TransactionAmt'].sum()*100)/train_df['TransactionAmt'].sum(), '.2f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['TransactionAmt'].apply(np.log).plot(kind='hist', bins=50) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for columns in train_df.columns:\n#    print(columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df['card1'].min())\nprint(train_df['card2'].min())\nprint(train_df['card3'].min())\nprint(train_df['card5'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df['card1'].max())\nprint(train_df['card2'].max())\nprint(train_df['card3'].max())\nprint(train_df['card5'].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['card_avg'] = round((train_df['card1']+train_df['card2']+train_df['card3']+train_df['card5'])/4, 2)\ntest_df['card_avg'] = round((test_df['card1']+test_df['card2']+test_df['card3']+test_df['card5'])/4, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(train_df['card_avg']).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"card_avg = round(train_df['card_avg'].mean(), 2)\ntrain_df['card_avg']= train_df['card_avg'].fillna(card_avg)\ntest_df['card_avg']= test_df['card_avg'].fillna(card_avg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.isnull(train_df).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_col = ['TransactionAmt','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','D1','V95','V96','V97','V98','V99','V100','V101','V102','V103','V104','V105','V106','V107','V108','V109','V110','V111','V112','V113','V114','V115','V116','V117','V118','V119','V120','V121','V122','V123','V124','V125','V126','V127','V128','V129','V130','V131','V132','V133','V134','V135','V136','V137','V279','V280','V281','V282','V283','V284','V285','V286','V287','V288','V289','V290','V291','V292','V293','V294','V295','V296','V297','V298','V299','V300','V301','V302','V303','V304','V305','V306','V307','V308','V309','V310','V311','V312','V313','V314','V315','V316','V317','V318','V319','V320','V321','card_avg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(selected_col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select only nan columns in selected columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[selected_col].columns[pd.isnull(train_df[selected_col]).sum() != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n#random.choice([3, 4, 99, 29, 49])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#random.choice(train_df['V106'][~train_df['V106'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df['V106'] = train_df['V106'].fillna(random.choice(train_df['V106'][~train_df['V106'].isnull()]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_cols = []\nna_cols = ['D1', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103',\n       'V104', 'V105', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113',\n       'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122',\n       'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131',\n       'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V281', 'V282', 'V283',\n       'V288', 'V289', 'V296', 'V300', 'V301', 'V313', 'V314', 'V315']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fill the missing colums values by the random value."},{"metadata":{"trusted":true},"cell_type":"code","source":"col =''\nfor col in na_cols:\n    train_df[col] = train_df[col].fillna(random.choice(train_df[col][~train_df[col].isnull()]))\n    test_df[col] = test_df[col].fillna(random.choice(test_df[col][~test_df[col].isnull()]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find object in selected columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[selected_col].columns[pd.isnull(test_df[selected_col]).sum() != 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fill the missing colums values by the random value."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_na_cols = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n       'C12', 'C13', 'C14', 'V279', 'V280', 'V284', 'V285', 'V286', 'V287',\n       'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V297', 'V298', 'V299',\n       'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310',\n       'V311', 'V312', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321']\n\ncol =''\nfor col in test_na_cols:\n    test_df[col] = test_df[col].fillna(random.choice(test_df[col][~test_df[col].isnull()]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[:,train_df.dtypes =='object'].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['ProductCD']= lbl.fit_transform(train_df['ProductCD']) \ntest_df['ProductCD']= lbl.fit_transform(test_df['ProductCD']) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\nfrom catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using catboost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"catboost = CatBoostClassifier(iterations=1000)\ncatboost.fit(train_df[selected_col],\n          train_df['isFraud'],\n          verbose = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catboost.score(train_df[selected_col],train_df['isFraud'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#catboost.predict(test_df[selected_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(train_df[selected_col]).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['V106'] = train_df['V106'].fillna(random.choice(train_df['V106'][~train_df['V106'].isnull()]))\ntest_df['V106'] = test_df['V106'].fillna(random.choice(test_df['V106'][~test_df['V106'].isnull()]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = []\nmodel_score = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kneighbors = KNeighborsClassifier()\nkneighbors.fit(train_df[selected_col],train_df['isFraud'])\nkneighbors_score = round(kneighbors.score(train_df[selected_col],train_df['isFraud'])*100, 2)\nmodel_name.append('KNeighborsClassifier')\nmodel_score.append(kneighbors_score)\nkneighbors_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linsvc = LinearSVC()\nlinsvc.fit(train_df[selected_col],train_df['isFraud'])\nlinsvc_score = round(linsvc.score(train_df[selected_col],train_df['isFraud'])*100, 2)\nmodel_name.append('LinearSVC')\nmodel_score.append(linsvc_score)\nlinsvc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"randomforest = RandomForestClassifier(n_estimators=8, max_depth=10, min_samples_split=0.8, random_state=58)\nrandomforest.fit(train_df[selected_col],train_df['isFraud'])\nrandomforest_score = round(randomforest.score(train_df[selected_col],train_df['isFraud'])*100, 2)\nmodel_name.append('RandomForestClassifier')\nmodel_score.append(randomforest_score)\nrandomforest_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x_train, x_test, y_train, y_test = train_test_split(train_df[selected_col], train_df['isFraud'], test_size=0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient = GradientBoostingClassifier()\ngradient.fit(train_df[selected_col],train_df['isFraud'])\ngradient_score = round(gradient.score(train_df[selected_col],train_df['isFraud'])*100, 2)\nmodel_name.append('GradientBoostingClassifier')\nmodel_score.append(gradient_score)\ngradient_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_score = pd.DataFrame({'model_name':model_name, 'model_score':model_score})\nall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.isnull(test_df[selected_col]).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_fraud_detection = kneighbors.predict(test_df[selected_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'TransactionID':test_transaction['TransactionID'], 'isFraud':predicted_fraud_detection})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n<p>Our target value is binary so itâ€™s a binary classification problem. Regression will not work here.</p>\n**I am still working in this kernel** <br/>\nAny suggestions to improve our score are most welcome. Upvote would be appreciated - That will keep me motivated :) "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}