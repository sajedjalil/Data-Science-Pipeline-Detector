{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setup\n\n+ 이 대회는 거래 사기를 찾아내는 것이 목적이라고 해도 크게 무관하지만,\n+ 정확히 표현하면 사기를 일으킨 '고객'을 찾아내는 문제입니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n!pip install chart_studio\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport plotly.figure_factory as ff\n\n# Using plotly + cufflinks in offline mode\ninit_notebook_mode(connected=True)\n\n# Preprocessing, modelling and evaluating\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold, KFold,RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 요약용\ndef resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    # null이 몇개나 있는가\n    summary['Missing'] = df.isnull().sum().values    \n    # unique한 값의 갯수\n    summary['Uniques'] = df.nunique().values\n    # 1 ~ 3 번째 값 나열\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary\n\n# 메모리 절약용\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# Outlier 요약\ndef CalcOutliers(df_num): \n\n    # calculating mean and std of the array\n    data_mean, data_std = np.mean(df_num), np.std(df_num)\n\n    # seting the cut line to both higher and lower values\n    # You can change this value\n    cut = data_std * 3\n\n    #Calculating the higher and lower cut values\n    lower, upper = data_mean - cut, data_mean + cut\n\n    # creating an array of lower, higher and total outlier values \n    outliers_lower = [x for x in df_num if x < lower]\n    outliers_higher = [x for x in df_num if x > upper]\n    outliers_total = [x for x in df_num if x < lower or x > upper]\n\n    # array without outlier values\n    outliers_removed = [x for x in df_num if x > lower and x < upper]\n    \n    print('mean and std: %d %d' % (data_mean, data_std))\n    print('Identified lowest outliers: %d' % len(outliers_lower)) # printing total number of values in lower cut of outliers\n    print('Identified upper outliers: %d' % len(outliers_higher)) # printing total number of values in higher cut of outliers\n    print('Total outlier observations: %d' % len(outliers_total)) # printing total number of values outliers of both sides\n    print('Non-outlier observations: %d' % len(outliers_removed)) # printing total number of non outlier values\n    print(\"Total percentual of Outliers: \", round((len(outliers_total) / len(outliers_removed) )*100, 4)) # Percentual of outliers in points\n    \n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터를 불러옵니다.\ndf_id = pd.read_csv(\"../input/train_identity.csv\")\ndf_trans = pd.read_csv(\"../input/train_transaction.csv\")\n\ndf_trans = reduce_mem_usage(df_trans)\ndf_id = reduce_mem_usage(df_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_id.shape, df_trans.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resumetable(df_trans)[:25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\n\n# Fraud별 총 거래 금액 및 횟수를 그려봅니다.\ndf_trans['TransactionAmt'] = df_trans['TransactionAmt'].astype(float)\ntotal = len(df_trans)\ntotal_amt = df_trans.groupby(['isFraud'])['TransactionAmt'].sum().sum()\n\n# 총 거래 횟수\nplt.subplot(121)\ng = sns.countplot(x='isFraud', data=df_trans)\ng.set_title(\"Fraud Transactions Distribution \\n# 0: No Fraud | 1: Fraud #\", fontsize = 16)\ng.set_xlabel(\"Is fraud?\", fontsize=18)\ng.set_ylabel('Count', fontsize=18)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize = 14) \nperc_amt = (df_trans.groupby(['isFraud'])['TransactionAmt'].sum())\nperc_amt = perc_amt.reset_index()\n\n# 총 거래 금액\nplt.subplot(122)\ng1 = sns.barplot(x='isFraud', y='TransactionAmt',  dodge=True, data=perc_amt)\ng1.set_title(\"% Total Amount in Transaction Amt \\n# 0: No Fraud | 1: Fraud #\", fontsize = 16)\ng1.set_xlabel(\"Is fraud?\", fontsize=18)\ng1.set_ylabel('Total Transaction Amount Scalar', fontsize=18)\nfor p in g1.patches:\n    height = p.get_height()\n    g1.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total_amt * 100),\n            ha=\"center\", fontsize = 14) \n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# .975 이후는 이상치임을 알 수 있습니다.\ndf_trans['TransactionAmt'] = df_trans['TransactionAmt'].astype(float)\nprint(\"Transaction Amounts Quantiles:\")\nprint(df_trans['TransactionAmt'].quantile([.01, .025, .1, .25, .5, .75, .9, .975, .99]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,12))\nplt.suptitle('Transaction Values Distribution', fontsize=22)\n\n# TransactionAmt 이상치 제거 후의 분포\nplt.subplot(221)\ng = sns.distplot(df_trans[df_trans['TransactionAmt'] <= 1000]['TransactionAmt'])\ng.set_title(\"Transaction Amount Distribuition <= 1000\", fontsize=18)\ng.set_xlabel(\"\")\ng.set_ylabel(\"Probability\", fontsize=15)\n\n# 로그화 후 분포 확인\nplt.subplot(222)\ng1 = sns.distplot(np.log(df_trans['TransactionAmt']))\ng1.set_title(\"Transaction Amount (Log) Distribuition\", fontsize=18)\ng1.set_xlabel(\"\")\ng1.set_ylabel(\"Probability\", fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,12))\n\n# isFraud가 0인 것과 1인 것을 scatter plot으로 나타낸 것\nplt.subplot(111)\ng = plt.scatter(range(df_trans[df_trans['isFraud'] == 0].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 0]['TransactionAmt'].values), \n                 label='NoFraud', alpha=.2)\ng = plt.scatter(range(df_trans[df_trans['isFraud'] == 1].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 1]['TransactionAmt'].values), \n                 label='Fraud', alpha=.2)\ng = plt.title(\"ECDF \\nFRAUD and NO FRAUD Transaction Amount Distribution\", fontsize=18)\ng = plt.xlabel(\"Index\")\ng = plt.ylabel(\"Amount Distribution\", fontsize=15)\ng = plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# isFraud를 0과 1로 각각 plot그린 것\nplt.figure(figsize=(16,12))\nplt.subplot(221)\ng = plt.scatter(range(df_trans[df_trans['isFraud'] == 1].shape[0]), \n                 np.sort(df_trans[df_trans['isFraud'] == 1]['TransactionAmt'].values), \n                label='isFraud', alpha=.4)\nplt.title(\"FRAUD\", fontsize=18)\nplt.xlabel(\"Index\")\nplt.ylabel(\"Amount Distribution\", fontsize=12)\n\nplt.subplot(222)\ng1 = plt.scatter(range(df_trans[df_trans['isFraud'] == 0].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 0]['TransactionAmt'].values), \n                 label='NoFraud', alpha=.2)\ng1= plt.title(\"NO FRAUD\", fontsize=18)\ng1 = plt.xlabel(\"Index\")\ng1 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n\nplt.suptitle('Individual Distribution', fontsize=22)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.concat([df_trans[df_trans['isFraud'] == 1]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index(), \n                 df_trans[df_trans['isFraud'] == 0]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index()],\n                axis=1, keys=['Fraud', \"No Fraud\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이상치 확인\nCalcOutliers(df_trans['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"대략 0부터 800(~1000) 사이 값을 사용하면 더욱 신뢰할 수 있는 분포를 얻을 수 있을 것으로 보입니다.\n\n또, 1.74%, 10,000개 이상치가 있음을 확인할 수 있었습니다."},{"metadata":{},"cell_type":"markdown","source":"## Product Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = pd.crosstab(df_trans['ProductCD'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\ntmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 교차테이블, 빈도표\ntmp = pd.crosstab(df_trans['ProductCD'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('ProductCD Distributions', fontsize=22)\n\n# ProductCD에 있는 값들의 갯수\nplt.subplot(221)\ng = sns.countplot(x='ProductCD', data=df_trans)\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\ng.set_title(\"ProductCD Distribution\", fontsize=19)\ng.set_xlabel(\"ProductCD Name\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\ng.set_ylim(0,500000)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize=14) \n\n# ProductCD, countplot의 hue는 해당 데이터에 카테고리가 있는 경우 색상으로 분류해줌\n# pointplot으로 fraud ratio check\nplt.subplot(222)\ng1 = sns.countplot(x='ProductCD', hue='isFraud', data=df_trans)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='ProductCD', y='Fraud', data=tmp, color='black', order=['W', 'H',\"C\", \"S\", \"R\"], legend=False)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Product CD by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"ProductCD Name\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='ProductCD', y='TransactionAmt', hue='isFraud', \n              data=df_trans[df_trans['TransactionAmt'] <= 2000] )\ng3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"ProductCD Name\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"W, C, R에서 거래가 가장 빈번하게 일어남\n\n특히, W, H, R은 Non-Fraud 거래에 비해 Fraud 거래값이 더 높은 것을 Transaction Value로 확인해볼 수 있음"},{"metadata":{},"cell_type":"markdown","source":"## Card Features\n+ Card1: ID\n+ Card2: bank-branch\n+ Card3: Country\n+ Card4: company of card\n+ Card5: third part software company ex) xxpay etc.\n+ Card6: Credit or debit"},{"metadata":{},"cell_type":"markdown","source":"+ card feature는 모두 categorical 형태입니다\n+ card가 가지고 있는 각 특징값들을 알아봅니다.\n+ card feature는 총 6개이며, 4개는 numerical 형태입니다. quantile과 distribution을 알아봅니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Knowning the Card Features\nresumetable(df_trans[['card1', 'card2', 'card3','card4', 'card5', 'card6']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Card1을 제외한 Card2 ~ Card6은 Missing Value를 가지고 있습니다.\n\n나중에 따로 처리해주어야 합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Card Features Quantiles: \")\nprint(df_trans[['card1', 'card2', 'card3', 'card5']].quantile([0.01, .025, .1, .25, .5, .75, .975, .99]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Card1, Card2는 값의 범위가 매우 큰 것을 확인할 수 있었습니다.\n\n아마 log화 시키면 좋은 결과를 얻을 수 있을 것 같아보입니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# card3, card5에서 횟수가 200, 300보다 작은 경우는 others로 변경해줌.\ndf_trans.loc[df_trans.card3.isin(df_trans.card3.value_counts()[df_trans.card3.value_counts() < 200].index), 'card3'] = \"Others\"\ndf_trans.loc[df_trans.card5.isin(df_trans.card5.value_counts()[df_trans.card5.value_counts() < 300].index), 'card5'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing Card 1, Card 2 and Card 3 Distributions"},{"metadata":{},"cell_type":"markdown","source":"+ Card1, Card2는 numerical이므로 분포를 그려서 확인하고,\n+ Card3, Card5는 Fraud ratio(%)를 확인해봅니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# card3에 대한 교차테이블\ntmp = pd.crosstab(df_trans['card3'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n# card5에 대한 교차테이블\ntmp2 = pd.crosstab(df_trans['card5'], df_trans['isFraud'], normalize='index') * 100\ntmp2 = tmp2.reset_index()\ntmp2.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,22))\n\n# distplot 2개로 card1 비교\nplt.subplot(411)\ng = sns.distplot(df_trans[df_trans['isFraud'] == 1]['card1'], label='Fraud')\ng = sns.distplot(df_trans[df_trans['isFraud'] == 0]['card1'], label='NoFraud')\ng.legend()\ng.set_title(\"Card 1 Values Distribution by Target\", fontsize=20)\ng.set_xlabel(\"Card 1 Values\", fontsize=18)\ng.set_ylabel(\"Probability\", fontsize=18)\n\n# distplot 2개로 card2 비교\nplt.subplot(412)\ng1 = sns.distplot(df_trans[df_trans['isFraud'] == 1]['card2'].dropna(), label='Fraud')\ng1 = sns.distplot(df_trans[df_trans['isFraud'] == 0]['card2'].dropna(), label='NoFraud')\ng1.legend()\ng1.set_title(\"Card 2 Values Distribution by Target\", fontsize=20)\ng1.set_xlabel(\"Card 2 Values\", fontsize=18)\ng1.set_ylabel(\"Probability\", fontsize=18)\n\n# card3\nplt.subplot(413)\ng2 = sns.countplot(x='card3', data=df_trans, order=list(tmp.card3.values))\ng22 = g2.twinx()\ngg2 = sns.pointplot(x='card3', y='Fraud', data=tmp, \n                    color='black', order=list(tmp.card3.values))\ngg2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng2.set_title(\"Card 3 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng2.set_xlabel(\"Card 3 Values\", fontsize=18)\ng2.set_ylabel(\"Count\", fontsize=18)\nfor p in g2.patches:\n    height = p.get_height()\n    g2.text(p.get_x()+p.get_width()/2.,\n            height + 25,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\") \n\n# card5\nplt.subplot(414)\ng3 = sns.countplot(x='card5', data=df_trans, order=list(tmp2.card5.values))\ng3t = g3.twinx()\ng3t = sns.pointplot(x='card5', y='Fraud', data=tmp2, \n                    color='black', order=list(tmp2.card5.values))\ng3t.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng3.set_title(\"Card 5 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng3.set_xticklabels(g3.get_xticklabels(),rotation=90)\ng3.set_xlabel(\"Card 5 Values\", fontsize=18)\ng3.set_ylabel(\"Count\", fontsize=18)\nfor p in g3.patches:\n    height = p.get_height()\n    g3.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=11) \n    \nplt.subplots_adjust(hspace = 0.6, top = 0.85)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = pd.crosstab(df_trans['card4'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('Card 4 Distributions', fontsize=22)\n\n# card4의 categorical\nplt.subplot(221)\ng = sns.countplot(x='card4', data=df_trans)\ng.set_title(\"Card4 Distribution\", fontsize=19)\ng.set_ylim(0,420000)\ng.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=14) \n\nplt.subplot(222)\ng1 = sns.countplot(x='card4', hue='isFraud', data=df_trans)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='card4', y='Fraud', data=tmp, \n                   color='black', legend=False, \n                   order=['discover', 'mastercard', 'visa', 'american express'])\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Card4 by Target (isFraud)\", fontsize=19)\ng1.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='card4', y='TransactionAmt', hue='isFraud', \n              data=df_trans[df_trans['TransactionAmt'] <= 2000] )\ng3.set_title(\"Card 4 Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"97%가 MasterCard, Visa에서 이루어집니다.\n\nFraud ratio는 discover에서 ~8%로 가장 높은 수치를 보이는 반면 Mastercard ~3.5%, American Express 2.87%를 보입니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = pd.crosstab(df_trans['card6'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('Card 6 Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='card6', data=df_trans, order=list(tmp.card6.values))\ng.set_title(\"Card6 Distribution\", fontsize=19)\ng.set_ylim(0,480000)\ng.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=14) \n\nplt.subplot(222)\ng1 = sns.countplot(x='card6', hue='isFraud', data=df_trans, order=list(tmp.card6.values))\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='card6', y='Fraud', data=tmp, order=list(tmp.card6.values),\n                   color='black', legend=False, )\ngt.set_ylim(0,20)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Card6 by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='card6', y='TransactionAmt', hue='isFraud', order=list(tmp.card6.values),\n              data=df_trans[df_trans['TransactionAmt'] <= 2000] )\ng3.set_title(\"Card 6 Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모든 데이터가 Credit, Debit에 해당함을 볼 수 있고, 특히 Debit Transaction이 Credit 보다 훨씬 많은 빈도수를 보여줌을 알 수 있습니다.\n\nTransaction Amount 분포는 큰 차이를 보여주지 못합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    df_trans[col] = df_trans[col].fillna(\"Miss\")\n    \ndef ploting_dist_ratio(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(20,5))\n    plt.suptitle(f'{col} Distributions ', fontsize=22)\n\n    plt.subplot(121)\n    g = sns.countplot(x=col, data=df, order=list(tmp[col].values))\n    g.set_title(f\"{col} Distribution\\nCound and %Fraud by each category\", fontsize=18)\n    g.set_ylim(0,400000)\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,20)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    for p in gt.patches:\n        height = p.get_height()\n        gt.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\",fontsize=14) \n        \n    perc_amt = (df_trans.groupby(['isFraud',col])['TransactionAmt'].sum() / total_amt * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.subplot(122)\n    g1 = sns.boxplot(x=col, y='TransactionAmt', hue='isFraud', \n                     data=df[df['TransactionAmt'] <= lim], order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,5)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g1.set_title(f\"{col} by Transactions dist\", fontsize=18)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Amount(U$)\", fontsize=16)\n        \n    plt.subplots_adjust(hspace=.4, wspace = 0.35, top = 0.80)\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    ploting_dist_ratio(df_trans, col, lim=2500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위 그래프로 각 M Features를 확인해볼 수 있습니다."},{"metadata":{},"cell_type":"markdown","source":"## Addr1 and Addr2"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Card Features Quantiles: \")\nprint(df_trans[['addr1', 'addr2']].quantile([0.01, .025, .1, .25, .5, .75, .90,.975, .99]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans.loc[df_trans.addr1.isin(df_trans.addr1.value_counts()[df_trans.addr1.value_counts() <= 5000 ].index), 'addr1'] = \"Others\"\ndf_trans.loc[df_trans.addr2.isin(df_trans.addr2.value_counts()[df_trans.addr2.value_counts() <= 50 ].index), 'addr2'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Addr1 Distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ploting_cnt_amt(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    \n    plt.figure(figsize=(16,14))    \n    plt.suptitle(f'{col} Distributions ', fontsize=24)\n    \n    plt.subplot(211)\n    g = sns.countplot( x=col,  data=df, order=list(tmp[col].values))\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,tmp['Fraud'].max()*1.1)\n    gt.set_ylabel(\"%Fraud Transactions\", fontsize=16)\n    g.set_title(f\"Most Frequent {col} values and % Fraud Transactions\", fontsize=20)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    sizes = []\n    for p in g.patches:\n        height = p.get_height()\n        sizes.append(height)\n        g.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\",fontsize=12) \n        \n    g.set_ylim(0,max(sizes)*1.15)\n    \n    #########################################################################\n    perc_amt = (df.groupby(['isFraud',col])['TransactionAmt'].sum() \\\n                / df.groupby([col])['TransactionAmt'].sum() * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    amt = df.groupby([col])['TransactionAmt'].sum().reset_index()\n    perc_amt = perc_amt.fillna(0)\n    plt.subplot(212)\n    g1 = sns.barplot(x=col, y='TransactionAmt', \n                       data=amt, \n                       order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, \n                        order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,perc_amt['Fraud'].max()*1.1)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    g1.set_title(f\"{col} by Transactions Total + %of total and %Fraud Transactions\", fontsize=20)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Total Amount(U$)\", fontsize=16)\n    g1.set_xticklabels(g.get_xticklabels(),rotation=45)    \n    \n    for p in g1.patches:\n        height = p.get_height()\n        g1.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total_amt*100),\n                ha=\"center\",fontsize=12) \n        \n    plt.subplots_adjust(hspace=.4, top = 0.9)\n    plt.show()\n    \nploting_cnt_amt(df_trans, 'addr1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Addr2 Distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_trans, 'addr2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Addr2는 거의 같은 값을 가집니다.\n\n흥미로운점은 65 value가 60% 정도의 Fraud를 가지고 있다는 것과,\n87 value가 88% 거래 횟수와 96% 거래량을 보여준다는 점입니다."},{"metadata":{},"cell_type":"markdown","source":"## P emaildomain Distributions"},{"metadata":{},"cell_type":"markdown","source":"+ 비슷한 email 형식은 grouping을 해주고,\n+ 횟수가 500 이하인 것은 전부 Other로 변환합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans.loc[df_trans['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n\ndf_trans.loc[df_trans['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\ndf_trans.loc[df_trans['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\ndf_trans.loc[df_trans.P_emaildomain.isin(df_trans.P_emaildomain\\\n                                         .value_counts()[df_trans.P_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'P_emaildomain'] = \"Others\"\ndf_trans.P_emaildomain.fillna(\"NoInf\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_trans, 'P_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R-Email Domain plot distribution  \n\n+ 비슷한 email 형식은 grouping을 해주고,\n+ 횟수가 300 이하인 것은 전부 Other로 변환합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans.loc[df_trans['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n\ndf_trans.loc[df_trans['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\ndf_trans.loc[df_trans['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                             'outlook.es', 'live.com', 'live.fr',\n                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\ndf_trans.loc[df_trans.R_emaildomain.isin(df_trans.R_emaildomain\\\n                                         .value_counts()[df_trans.R_emaildomain.value_counts() <= 300 ]\\\n                                         .index), 'R_emaildomain'] = \"Others\"\ndf_trans.R_emaildomain.fillna(\"NoInf\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_trans, 'R_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"email domain feature는 매우 유사한 분포를 보여줍니다.\n\n흥미로운 점은 Google, icloud frauds가 높은 값을 보여준다는 것입니다."},{"metadata":{},"cell_type":"markdown","source":"## C1-C14 features\n+ C1 ~ C14 feature 분포 확인\n+ C1 ~ C14는 지불결제 관련 정보, 자세한 정보는 보안"},{"metadata":{"trusted":true},"cell_type":"code","source":"resumetable(df_trans[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n                      'C9', 'C10', 'C11', 'C12', 'C13', 'C14']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n                      'C9', 'C10', 'C11', 'C12', 'C13', 'C14']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans.loc[df_trans.C1.isin(df_trans.C1\\\n                              .value_counts()[df_trans.C1.value_counts() <= 400 ]\\\n                              .index), 'C1'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C1 Distribution Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_trans, 'C1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans.loc[df_trans.C2.isin(df_trans.C2\\\n                              .value_counts()[df_trans.C2.value_counts() <= 350 ]\\\n                              .index), 'C2'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_trans, 'C2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.0, 2.0, 3.0의 총량이 비슷한 값(패턴)을 보여주고 있습니다."},{"metadata":{},"cell_type":"markdown","source":"## TimeDelta Feature\n+ 어떤 시간에 사기가 가장 빈번하게 나타나는지 확인해봅니다."},{"metadata":{},"cell_type":"markdown","source":"## Converting to Total Days, Weekdays and Hours\n\n+ TimeDelta Feature 처리 참고 링크: # https://www.kaggle.com/c/ieee-fraud-detection/discussion/100400#latest-579480\n+ first date를 2017-12-01로 사용해서, datetime feature로 변환하여 사용합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\nSTART_DATE = '2017-12-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\ndf_trans[\"Date\"] = df_trans['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n\n# 주중, 시간, 일을 순서대로 구합니다.\ndf_trans['_Weekdays'] = df_trans['Date'].dt.dayofweek\ndf_trans['_Hours'] = df_trans['Date'].dt.hour\ndf_trans['_Days'] = df_trans['Date'].dt.day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"First Date is {df_trans['Date'].dt.date.min()} and the last date is {df_trans['Date'].dt.date.max()} \\\n      \\nTotal Difference in days are {(df_trans['Date'].max() - df_trans['Date'].min()).days} Days\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top Days with highest Total Transaction Amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_trans, '_Days')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ploting WeekDays Distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_trans, '_Weekdays')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ploting Hours Distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_trans, '_Hours')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transactions and Total Amount by each day"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 링크 코드 참고\n# Calling the function to transform the date column in datetime pandas object\n\n#seting some static color options\ncolor_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n\n\ndates_temp = df_trans.groupby(df_trans.Date.dt.date)['TransactionAmt'].count().reset_index()\n# renaming the columns to apropriate names\n\n# creating the first trace with the necessary parameters\ntrace = go.Scatter(x=dates_temp['Date'], y=dates_temp.TransactionAmt,\n                    opacity = 0.8, line = dict(color = color_op[7]), name= 'Total Transactions')\n\n# Below we will get the total amount sold\ndates_temp_sum = df_trans.groupby(df_trans.Date.dt.date)['TransactionAmt'].sum().reset_index()\n\n# using the new dates_temp_sum we will create the second trace\ntrace1 = go.Scatter(x=dates_temp_sum.Date, line = dict(color = color_op[1]), name=\"Total Amount\",\n                        y=dates_temp_sum['TransactionAmt'], opacity = 0.8, yaxis='y2')\n\n# creating the layout the will allow us to give an title and \n# give us some interesting options to handle with the outputs of graphs\nlayout = dict(\n    title= \"Total Transactions and Fraud Informations by Date\",\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1, label='1m', step='month', stepmode='backward'),\n                dict(count=3, label='3m', step='month', stepmode='backward'),\n                dict(count=6, label='6m', step='month', stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(visible = True),\n        type='date' ),\n    yaxis=dict(title='Total Transactions'),\n    yaxis2=dict(overlaying='y',\n                anchor='x', side='right',\n                zeroline=False, showgrid=False,\n                title='Total Transaction Amount')\n)\n\n# creating figure with the both traces and layout\nfig = dict(data= [trace, trace1,], layout=layout)\n\n# rendering the graphs\niplot(fig) #it's an equivalent to plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FRAUD TRANSACTIONS BY DATE\n+ Date를 기준으로 사기 거래만 나타내봅니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calling the function to transform the date column in datetime pandas object\n\n#seting some static color options\ncolor_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n\ntmp_amt = df_trans.groupby([df_trans.Date.dt.date, 'isFraud'])['TransactionAmt'].sum().reset_index()\ntmp_trans = df_trans.groupby([df_trans.Date.dt.date, 'isFraud'])['TransactionAmt'].count().reset_index()\n\ntmp_trans_fraud = tmp_trans[tmp_trans['isFraud'] == 1]\ntmp_amt_fraud = tmp_amt[tmp_amt['isFraud'] == 1]\n\ndates_temp = df_trans.groupby(df_trans.Date.dt.date)['TransactionAmt'].count().reset_index()\n# renaming the columns to apropriate names\n\n# creating the first trace with the necessary parameters\ntrace = go.Scatter(x=tmp_trans_fraud['Date'], y=tmp_trans_fraud.TransactionAmt,\n                    opacity = 0.8, line = dict(color = color_op[1]), name= 'Fraud Transactions')\n\n# using the new dates_temp_sum we will create the second trace\ntrace1 = go.Scatter(x=tmp_amt_fraud.Date, line = dict(color = color_op[7]), name=\"Fraud Amount\",\n                    y=tmp_amt_fraud['TransactionAmt'], opacity = 0.8, yaxis='y2')\n\n#creating the layout the will allow us to give an title and \n# give us some interesting options to handle with the outputs of graphs\nlayout = dict(\n    title= \"FRAUD TRANSACTIONS - Total Transactions and Fraud Informations by Date\",\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1, label='1m', step='month', stepmode='backward'),\n                dict(count=3, label='3m', step='month', stepmode='backward'),\n                dict(count=6, label='6m', step='month', stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(visible = True),\n        type='date' ),\n    yaxis=dict(title='Total Transactions'),\n    yaxis2=dict(overlaying='y',\n                anchor='x', side='right',\n                zeroline=False, showgrid=False,\n                title='Total Transaction Amount')\n)\n\n# creating figure with the both traces and layout\nfig = dict(data= [trace, trace1], layout=layout)\n\n#rendering the graphs\niplot(fig) #it's an equivalent to plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features [id_12 to id_38]\n+ identity dataset은 categorical 형태를 띄고 있습니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_id[['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18',\n       'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25',\n       'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32',\n       'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']].describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cat_feat_ploting(df, col):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(14,10))\n    plt.suptitle(f'{col} Distributions', fontsize=22)\n\n    plt.subplot(221)\n    g = sns.countplot(x=col, data=df, order=tmp[col].values)\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\n    g.set_title(f\"{col} Distribution\", fontsize=19)\n    g.set_xlabel(f\"{col} Name\", fontsize=17)\n    g.set_ylabel(\"Count\", fontsize=17)\n    # g.set_ylim(0,500000)\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\", fontsize=14) \n\n    plt.subplot(222)\n    g1 = sns.countplot(x=col, hue='isFraud', data=df, order=tmp[col].values)\n    plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n    gt = g1.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, color='black', order=tmp[col].values, legend=False)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\n    g1.set_title(f\"{col} by Target(isFraud)\", fontsize=19)\n    g1.set_xlabel(f\"{col} Name\", fontsize=17)\n    g1.set_ylabel(\"Count\", fontsize=17)\n\n    plt.subplot(212)\n    g3 = sns.boxenplot(x=col, y='TransactionAmt', hue='isFraud', \n                       data=df[df['TransactionAmt'] <= 2000], order=tmp[col].values )\n    g3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\n    g3.set_xlabel(\"ProductCD Name\", fontsize=17)\n    g3.set_ylabel(\"Transaction Values\", fontsize=17)\n\n    plt.subplots_adjust(hspace = 0.4, top = 0.85)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ploting columns with few unique values"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29']:\n    df_train[col] = df_train[col].fillna('NaN')\n    cat_feat_ploting(df_train, col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Id 30"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[df_train['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\ndf_train.loc[df_train['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\ndf_train.loc[df_train['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\ndf_train.loc[df_train['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\ndf_train['id_30'].fillna(\"NAN\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_train, 'id_30')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Id 31"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[df_train['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\ndf_train.loc[df_train['id_31'].str.contains('firefox', na=False), 'id_31'] = 'Firefox'\ndf_train.loc[df_train['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\ndf_train.loc[df_train['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\ndf_train.loc[df_train['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\ndf_train.loc[df_train['id_31'].str.contains('samsung', na=False), 'id_31'] = 'Samsung'\ndf_train.loc[df_train['id_31'].str.contains('opera', na=False), 'id_31'] = 'Opera'\ndf_train['id_31'].fillna(\"NAN\", inplace=True)\ndf_train.loc[df_train.id_31.isin(df_train.id_31.value_counts()[df_train.id_31.value_counts() < 200].index), 'id_31'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting_cnt_amt(df_train, 'id_31')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling\n+ 아래 링크 참조\n+ https://www.kaggle.com/artkulak/ieee-fraud-simple-baseline-0-9383-lb - (@artkulak - Art) \n+ https://www.kaggle.com/artgor/eda-and-models - (@artgor - Andrew Lukyanenko)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 학습, 테스트, 제출에 필요한 csv를 불러옵니다.\ndf_trans = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ndf_test_trans = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n\ndf_id = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ndf_test_id = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\n\nsample_submission = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n\ndf_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True)\ndf_test = df_test_trans.merge(df_test_id, how='left', left_index=True, right_index=True)\n\nprint(df_train.shape)\nprint(df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_column_names = list(df_test.columns)\ntest_column_names = [x.replace('-', '_') for x in test_column_names]\n\ndf_test.columns = test_column_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime \n\nSTART_DATE = '2017-12-01' \nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\") \ndf_train[\"Date\"] = df_train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x))) \ndf_test[\"Date\"] = df_test['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n\ndf_train['_Weekdays'] = df_train['Date'].dt.dayofweek \ndf_train['_Hours'] = df_train['Date'].dt.hour \ndf_train['_Days'] = df_train['Date'].dt.day\n\ndf_test['_Weekdays'] = df_test['Date'].dt.dayofweek \ndf_test['_Hours'] = df_test['Date'].dt.hour \ndf_test['_Days'] = df_test['Date'].dt.day\n\ndf_train.drop(\"Date\", axis=1, inplace=True) \ndf_test.drop(\"Date\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['TransactionAmt_to_mean_card1'] = df_train['TransactionAmt'] / df_train.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_train['TransactionAmt_to_mean_card4'] = df_train['TransactionAmt'] / df_train.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_train['TransactionAmt_to_std_card1'] = df_train['TransactionAmt'] / df_train.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_train['TransactionAmt_to_std_card4'] = df_train['TransactionAmt'] / df_train.groupby(['card4'])['TransactionAmt'].transform('std')\n\ndf_test['TransactionAmt_to_mean_card1'] = df_test['TransactionAmt'] / df_test.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_mean_card4'] = df_test['TransactionAmt'] / df_test.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_std_card1'] = df_test['TransactionAmt'] / df_test.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_test['TransactionAmt_to_std_card4'] = df_test['TransactionAmt'] / df_test.groupby(['card4'])['TransactionAmt'].transform('std')\n\ndf_train['id_02_to_mean_card1'] = df_train['id_02'] / df_train.groupby(['card1'])['id_02'].transform('mean')\ndf_train['id_02_to_mean_card4'] = df_train['id_02'] / df_train.groupby(['card4'])['id_02'].transform('mean')\ndf_train['id_02_to_std_card1'] = df_train['id_02'] / df_train.groupby(['card1'])['id_02'].transform('std')\ndf_train['id_02_to_std_card4'] = df_train['id_02'] / df_train.groupby(['card4'])['id_02'].transform('std')\n\ndf_test['id_02_to_mean_card1'] = df_test['id_02'] / df_test.groupby(['card1'])['id_02'].transform('mean')\ndf_test['id_02_to_mean_card4'] = df_test['id_02'] / df_test.groupby(['card4'])['id_02'].transform('mean')\ndf_test['id_02_to_std_card1'] = df_test['id_02'] / df_test.groupby(['card1'])['id_02'].transform('std')\ndf_test['id_02_to_std_card4'] = df_test['id_02'] / df_test.groupby(['card4'])['id_02'].transform('std')\n\ndf_train['D15_to_mean_card1'] = df_train['D15'] / df_train.groupby(['card1'])['D15'].transform('mean')\ndf_train['D15_to_mean_card4'] = df_train['D15'] / df_train.groupby(['card4'])['D15'].transform('mean')\ndf_train['D15_to_std_card1'] = df_train['D15'] / df_train.groupby(['card1'])['D15'].transform('std')\ndf_train['D15_to_std_card4'] = df_train['D15'] / df_train.groupby(['card4'])['D15'].transform('std')\n\ndf_test['D15_to_mean_card1'] = df_test['D15'] / df_test.groupby(['card1'])['D15'].transform('mean')\ndf_test['D15_to_mean_card4'] = df_test['D15'] / df_test.groupby(['card4'])['D15'].transform('mean')\ndf_test['D15_to_std_card1'] = df_test['D15'] / df_test.groupby(['card1'])['D15'].transform('std')\ndf_test['D15_to_std_card4'] = df_test['D15'] / df_test.groupby(['card4'])['D15'].transform('std')\n\ndf_train['D15_to_mean_addr1'] = df_train['D15'] / df_train.groupby(['addr1'])['D15'].transform('mean')\ndf_train['D15_to_mean_card4'] = df_train['D15'] / df_train.groupby(['card4'])['D15'].transform('mean')\ndf_train['D15_to_std_addr1'] = df_train['D15'] / df_train.groupby(['addr1'])['D15'].transform('std')\ndf_train['D15_to_std_card4'] = df_train['D15'] / df_train.groupby(['card4'])['D15'].transform('std')\n\ndf_test['D15_to_mean_addr1'] = df_test['D15'] / df_test.groupby(['addr1'])['D15'].transform('mean')\ndf_test['D15_to_mean_card4'] = df_test['D15'] / df_test.groupby(['card4'])['D15'].transform('mean')\ndf_test['D15_to_std_addr1'] = df_test['D15'] / df_test.groupby(['addr1'])['D15'].transform('std')\ndf_test['D15_to_std_card4'] = df_test['D15'] / df_test.groupby(['card4'])['D15'].transform('std')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_value_cols = [col for col in df_train.columns if df_train[col].nunique() <= 1]\none_value_cols_test = [col for col in df_test.columns if df_test[col].nunique() <= 1]\none_value_cols == one_value_cols_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"many_null_cols = [col for col in df_train.columns if df_train[col].isnull().sum() / df_train.shape[0] > 0.9]\nmany_null_cols_test = [col for col in df_test.columns if df_test[col].isnull().sum() / df_test.shape[0] > 0.9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_top_value_cols = [col for col in df_train.columns if df_train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\nbig_top_value_cols_test = [col for col in df_test.columns if df_test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_drop = list(set(many_null_cols + many_null_cols_test +\n                        big_top_value_cols +\n                        big_top_value_cols_test +\n                        one_value_cols + one_value_cols_test))\nlen(cols_to_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_drop.remove('isFraud')\n\ndf_train = df_train.drop(cols_to_drop, axis=1)\ndf_test = df_test.drop(cols_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Enconding categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    if col in df_train.columns:\n        le = preprocessing.LabelEncoder() # label화\n        le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n        df_test[col] = le.transform(list(df_test[col].astype(str).values)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing high correlated features"},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.98\n    \n# Absolute value correlation matrix\ncorr_matrix = df_train[df_train['isFraud'].notnull()].corr().abs()\n\n# Getting the upper triangle of correlations\n# np.triu는 matrix의 윗사각형을 반환하는 것. k는 index위치를 의미\n# 메모리를 아끼기 위하여 corr_matrix의 윗 사각형만 사용\n# k=1 인 이유는 isFraud는 제외\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))\ndf_train = df_train.drop(columns = to_drop)\ndf_test = df_test.drop(columns = to_drop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seting X and y"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'], axis=1)\ny_train = df_train.sort_values('TransactionDT')['isFraud']\n\ndel df_train\n\nX_test = df_test.sort_values('TransactionDT').drop(['TransactionDT'], axis=1)\ndf_test = df_test[[\"TransactionDT\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reducing the memory before run the algorithmn"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = reduce_mem_usage(X_train)\nX_test = reduce_mem_usage(X_test)\n\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyper Opt - Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Hyperopt modules\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import TimeSeriesSplit\n\ndef objective(params):\n\n    print(\"############## New Run ################\")\n    print(\"PARAMETERS: \")\n    print(f\"params  = {params}\")\n    \n    params = {\n        'max_depth': int(params['max_depth']),\n        'gamma': \"{:.3f}\".format(params['gamma']),\n        'reg_alpha': \"{:.3f}\".format(params['reg_alpha']),\n        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n        'gamma': \"{:.3f}\".format(params['gamma']),\n        'num_leaves': '{:.3f}'.format(params['num_leaves']),\n        'min_child_samples': '{:.3f}'.format(params['min_child_samples']),\n        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n        'bagging_fraction': '{:.3f}'.format(params['bagging_fraction'])\n    }\n    \n    EPOCHS = 10\n    tss = TimeSeriesSplit(n_splits=EPOCHS)\n    score_mean = 0\n    \n    print(\"CV SCORE: \")\n    \n    for tr_idx, val_idx in tss.split(X_train, y_train):\n        clf = xgb.XGBClassifier(\n            n_estimators=200, random_state=4,\n            tree_method='gpu_hist', verbosity=2,\n            **params\n        )\n\n        X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n        y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n        \n        clf.fit(X_tr, y_tr)\n        \n        y_pred_train = clf.predict_proba(X_vl)[:,1]\n        score = roc_auc_score(y_vl, y_pred_train)\n        score_mean += score\n        \n        print(f'ROC AUC {score}')\n        \n    del X_tr, X_vl, y_tr, y_vl, clf, y_pred_train    \n    gc.collect()\n    \n    print(f'Mean ROC_AUC: {score_mean / EPOCHS} \\n')\n    return -(score_mean / EPOCHS)\n\nspace = {\n    'max_depth': hp.quniform('max_depth', 5, 24, 1),\n    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.9),\n    'reg_lambda': hp.uniform('reg_lambda', 0.1, 1.0),\n    'learning_rate': hp.uniform('learning_rate', 0.05, 0.2),\n    'colsample_bytree'ㅔㅔ: hp.uniform('colsample_bytree', 0.3, 1.0),\n    'gamma': hp.uniform('gamma', 0.0, 0.8),\n    'num_leaves': hp.choice('num_leaves', list(range(20, 300, 20))),       \n    'min_child_samples': hp.choice('min_child_samples', list(range(10, 80, 3))),\n    'feature_fraction': hp.choice('feature_fraction', [.5, .6, .7, .8, .9]),\n    'bagging_fraction': hp.choice('bagging_fraction', [.5, .6, .7, .8, .9])\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error가 난다면 GPU가 활성화되어 있는지 확인하세요.\n# Set algoritm parameters\nbest = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=15)\n\n# Print best parameters\n# best_params = space_eval(space, best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"BEST PARAMS: \", best)\n\nbest['max_depth'] = int(best['max_depth'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBClassifier(\n    n_estimators=600,\n    **best,\n    tree_method='gpu_hist'\n)\n\nclf.fit(X_train, y_train)\n\ny_preds = clf.predict_proba(X_test)[:,1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_important = clf.get_booster().get_score(importance_type=\"weight\")\nkeys = list(feature_important.keys())\nvalues = list(feature_important.values())\n\ndata = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n\n# Top 10 featur_importances\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['isFraud'] = y_preds\nsample_submission.to_csv('XGB_hypopt_model.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}