{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Reference\n\n* https://www.kaggle.com/suoires1/fraud-detection-eda-and-modeling"},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"working_directory_path = \"/kaggle/input/ieee-fraud-detection/\"\nout_dir = \"/kaggle/working/\"\nos.chdir(working_directory_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# Timing decorator\nfrom functools import wraps\nfrom time import time\n\ndef timing(f):\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        start = time()\n        result = f(*args, **kwargs)\n        end = time()\n        print('Elapsed time: {:.2f} Sec'.format(end-start))\n        return result\n    return wrapper","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DATA Load / Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Read CSV and return df\n@timing\ndef data_load():\n    train_identity = pd.read_csv(\"train_identity.csv\")\n    train_transaction = pd.read_csv(\"train_transaction.csv\")\n\n    test_identity = pd.read_csv(\"test_identity.csv\")\n    test_transaction = pd.read_csv(\"test_transaction.csv\")\n\n    train_df = pd.merge(train_identity, train_transaction, on = 'TransactionID', how='right')\n    test_df = pd.merge(test_identity, test_transaction, on = 'TransactionID', how='right')\n    \n    print(\"INFO - Data load and merge complete\")\n    print(\"INFO - Train - \", train_df.shape)\n    print(\"INFO - Submission - \", test_df.shape)\n    \n    return train_df, test_df\n\n@timing\ndef data_info(df):\n    columns = df.columns\n    \n# Create Metadata object for df\n@timing\ndef data_df_metadata(df):\n    \n    total_rows = len(df.index)\n    na_count = df.isna().sum().to_list()\n    na_pct =  list(map(lambda x: round(x / total_rows * 100) , na_count))\n    unique_count = list(map(lambda x: len(df[x].unique()) , df.columns))\n    memory = round((df.memory_usage(index=False, deep=False)/1024**2),2).to_list()\n    \n    print(len(df.columns.to_list()), len(df.dtypes.to_list()), len(df.isna().sum().to_list()), len(na_pct), len(unique_count), len(memory))\n    \n    metadata_dict = {'column': df.columns.to_list(), \n                     'dtype': df.dtypes.to_list(),\n                     'na_count': na_count, \n                     'na_pct': na_pct,\n                     'unique_count': unique_count,\n                     'memory': memory}\n    return pd.DataFrame(metadata_dict)\n\n# Save data as pickle\ndef data_save_pkl(train_df, submission_df):\n    train_df.to_pickle(out_dir + \"train_df.pkl\")\n    print(\"INFO - train_df saved as pkl\")\n    submission_df.to_pickle(out_dir + \"submission_df.pkl\")\n    print(\"INFO - submission_df saved as pkl\")\n\n# Print Categorical info\ndef data_print_categorical(df):\n    for col in df.columns:\n        if (df[col].dtype == 'object'):\n            print(\"---------- ---------- ----------\")\n            print(df[col].describe())\n            print(\"----------\")\n            print(df[col].value_counts(dropna=False))\n            \n            \n# Load equal no.of target class data\n@timing\ndef data_load_equal_target_count(train_df):\n    positive_train_df = train_df[train_df.isFraud == 1]\n    negative_train_df = train_df[train_df.isFraud == 0].sample(n=positive_train_df.shape[0], random_state=10)\n    \n    combine_df = positive_train_df.append(negative_train_df).sample(frac=1, random_state=10)\n    print(positive_train_df.shape, negative_train_df.shape, combine_df.shape)\n    \n    return combine_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_train_df, input_test_df = data_load()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = data_load_equal_target_count(input_train_df)\ntest_df = input_test_df\n# del input_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_train_df = input_train_df.sample(frac=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # sample_train_df.columns.to_list()\n\n# cols_show = ['TransactionDT',\n#  'TransactionAmt',\n#  'ProductCD',\n#  'card1',\n#  'card2',\n#  'card3',\n#  'card4',\n#  'card5',\n#  'card6',\n#  'addr1',\n#  'addr2',\n#  'dist1',\n#  'dist2',\n#  'P_emaildomain',\n#  'R_emaildomain']\n\n# sample_train_df[cols_show]\n\n# sample_train_df['D5'].unique()\n# # sample_train_df['id_03'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df = reduce_mem_usage(train_df)\n# test_df = reduce_mem_usage(test_df)\n\n# data_save_pkl(train_df, submission_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# msno.bar(train_df, figsize=(60, 10))\n# msno.matrix(train_df, figsize=(40, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop columns which have > 10% NAN\nmetadata_df = data_df_metadata(train_df)\ncolumns_to_drop = metadata_df[metadata_df['na_pct']>53].column.to_list()\ntrain_df = train_df.drop(columns_to_drop, axis=1)\n# columns_to_drop.remove('isFraud')\ntest_df = test_df.drop(columns_to_drop, axis=1)\n\nmetadata_df = data_df_metadata(train_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_df.info()\nsubmission_df = test_df['TransactionID']\nsubmission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data_print_categorical(train_df)\ntrain_df = train_df.drop('TransactionID', axis=1)\ntest_df = test_df.drop('TransactionID', axis=1)\n\ntrain_df = train_df.drop('P_emaildomain', axis=1)\ntest_df = test_df.drop('P_emaildomain', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_print_categorical(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df = reduce_mem_usage(train_df)\n# test_df = reduce_mem_usage(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.fillna(-999, inplace=True)\ntest_df.fillna(-999, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \n\nmetadata_df = data_df_metadata(train_df)\ncol_list = metadata_df[metadata_df['dtype'] == 'object'].column.to_list()\nprint(col_list)\n\nencoders = {}\n\n@timing\ndef setup_encoders(df, col_list):\n    encoders = {}\n    for col in col_list:\n        print('processing: ', col)\n        LE = LabelEncoder() \n        encoders[col] = LE.fit(list(df[col].astype(str).values))\n    return encoders\n\n@timing\ndef encode_data(df, col_list, encoders):\n    for col in col_list:\n        print('processing: ', col)\n        LE = encoders[col]\n        df[col] = LE.transform(list(df[col].astype(str).values)) \n    return df\n\nencoders = setup_encoders(train_df, col_list)\n\ntrain_df = encode_data(train_df, col_list, encoders)\ntest_df = encode_data(test_df, col_list, encoders)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df\nfrom sklearn.model_selection import train_test_split\nX_train, X_test = train_test_split(train_df, test_size = 0.4, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = X_train['isFraud']\nX_train = X_train.drop(['isFraud'], axis=1)\n\nY_test = X_test['isFraud']\nX_test = X_test.drop(['isFraud'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import RobustScaler\n\n# scaler = RobustScaler()\n\n# def data_scalar(train_df, test_df, sub_df):\n#     scaled_train_df = scaler.fit_transform(train_df)\n#     scaled_test_df = scaler.fit_transform(test_df)\n#     scaled_sub_df = scaler.fit_transform(sub_df)\n    \n#     return pd.DataFrame(scaled_train_df), pd.DataFrame(scaled_test_df), pd.DataFrame(scaled_train_df), \n\n# X_train, X_test, test_df = data_scalar(X_train, X_test, test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# from sklearn import decomposition\n\n# def run_pca(df):\n#     pca = decomposition.PCA(n_components=20)\n#     pca.fit(df)\n#     print(pca.explained_variance_ratio_)\n#     return pca.transform(df)\n# X_pca = run_pca(X_train)\n# X_sub_pca = run_pca(submission_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import metrics\nimport lightgbm as lgb\n\n@timing\ndef get_model_MNB(X, target, alpha=1):\n    model = MultinomialNB(alpha=alpha).fit(X, target)\n    return model\n\n@timing\ndef get_model_BNB(X, target, alpha=1):\n    model = BernoulliNB(alpha=alpha).fit(X, target)\n    return model\n\n@timing\ndef get_model_GNB(X, target, alpha=1):\n    model = GaussianNB().fit(X, target)\n    return model\n\n@timing\ndef get_model_RF(X, target):\n    model = RandomForestClassifier()\n    return model.fit(X, target)\n\n@timing\ndef get_model_XGB_simple(X, target):\n    model = xgb.XGBClassifier()\n    return model.fit(X, target)\n\n@timing\ndef get_model_XGB_custom(X, target):\n    model = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n    return model.fit(X, target)\n\n@timing\ndef get_model_lgb(lgb_train, lgb_val):\n    parameters = {\n        'application': 'binary',\n        'objective': 'binary',\n        'metric': 'auc',\n        'is_unbalance': 'true',\n        'boosting': 'gbdt',\n        'num_leaves': 31,\n        'feature_fraction': 0.5,\n        'bagging_fraction': 0.5,\n        'bagging_freq': 20,\n        'learning_rate': 0.05,\n        'verbose': 2\n    }\n    model = lgb.train(parameters,\n                       lgb_train,\n                       valid_sets=lgb_val,\n                       num_boost_round=2000,\n                       early_stopping_rounds=100)\n    return model\n\n@timing\ndef get_model_SGD(X, target):\n    model = SGDClassifier(loss='log', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)\n    return model.fit(X, target)\n\n@timing\ndef run_exp(model, X_test, Y_test):\n    prediction = model.predict_proba(X_test)\n    score = prediction[:, 1].round(1)\n    plt.hist(score)\n#     print(metrics.classification_report(Y_test, score))\n    print(\"ROC_AUC: \", metrics.roc_auc_score(Y_test, score))\n    return model, prediction\n\n@timing\ndef run_exp_lgb(model, X_test, Y_test):\n    prediction = model.predict(X_test, num_iteration=model.best_iteration)\n    print(prediction)\n    plt.hist(prediction)\n    return model, prediction\n\n@timing\ndef run_all_exp():\n    model_BernoulliNB  = get_model_BNB(X_train, Y_train, 1)\n    print(\"BernoulliNB\", run_exp(model_BernoulliNB, X_test, Y_test))\n    print(\"---------- ----------\")\n    model_RF  = get_model_RF(X_train, Y_train)\n    print(\"RF\", run_exp(model_RF, X_test, Y_test))\n    print(\"---------- ----------\")\n    model_SGD  = get_model_SGD(X_train, Y_train)\n    print(\"SGD\", run_exp(model_SGD, X_test, Y_test))\n    print(\"---------- ----------\")\n#     model_RF  = get_model_RF(X_train, Y_train)\n#     print(\"RF\", run_exp(model_RF, X_test, Y_test))\n#     print(\"---------- ----------\")\n#     model_RF  = get_model_RF(X_train, Y_train)\n#     print(\"RF\", run_exp(model_RF, X_test, Y_test))\n#     print(\"---------- ----------\")\n\n@timing\ndef save_submission(model, X_test, X_sub, name, isLGB = False):\n    prediction = []\n    if (isLGB):\n        prediction = model.predict(X_test)\n        score = prediction.round(1)\n    else:\n        prediction = model.predict_proba(X_test)\n        score = prediction[:, 1].round(1)\n    print(score)\n    print(len(score))\n    plt.hist(score)\n    submission_dict = {'TransactionID': X_sub, 'isFraud': score}\n    out_df = pd.DataFrame(submission_dict) \n\n    # saving the dataframe \n    os.chdir(out_dir)\n    out_df.to_csv(name, index=False)\n    return score\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_BernoulliNB  = get_model_BNB(X_train, Y_train, 1)\n_, pred = run_exp(model_BernoulliNB, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RF  = get_model_RF(X_train, Y_train)\n_, pred = run_exp(model_RF, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get_model_XGB_simple\n# model_XGB_simple  = get_model_XGB_simple(X_train, Y_train)\n# _, pred = run_exp(model_XGB_simple, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_XGB_custom  = get_model_XGB_custom(X_train, Y_train)\n_, pred = run_exp(model_XGB_custom, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, Y_train)\nlgb_eval = lgb.Dataset(X_test, Y_test)\n\nmodel_lgb = get_model_lgb(lgb_train, lgb_eval)\n_, pred = run_exp_lgb(model_lgb, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_SGD  = get_model_SGD(X_train, Y_train)\n# _, pred = run_exp(model_SGD, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# run_all_exp()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = save_submission(model_XGB_custom, test_df, submission_df, '24_XGB_2204_submsission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = save_submission(model_lgb, test_df, submission_df, '24_LGB_2204_submsission.csv', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import autosklearn.classification\n# import sklearn.model_selection\n# import sklearn.metrics\n\n# automl = autosklearn.classification.AutoSklearnClassifier()\n# automl.fit(X_train, Y_train)\n# Y_hat = automl.predict(X_test)\n# print(\"Accuracy score\", sklearn.metrics.accuracy_score(Y_test, Y_hat))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}