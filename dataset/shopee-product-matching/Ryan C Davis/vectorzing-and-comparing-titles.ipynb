{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd, gc\nimport matplotlib.pyplot as plt\nimport time\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetB2, ResNet50V2\nprint('RAPIDS',cuml.__version__)\nprint('TF',tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 1GB OF GPU RAM\n# SO THAT WE HAVE 15GB RAM FOR RAPIDS\nLIMIT = 1\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')\n# train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generator","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=''): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) // self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0\n        return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Embeddings","metadata":{}},{"cell_type":"code","source":"# BASE = '../input/shopee-product-matching/train_images/'\n\n# WGT = '../input/efficientnetb0-notoph5/efficientnetb0_notop.h5'\n# model = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n# #model = ResNet50V2(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n\n# embeds = []\n# CHUNK = 1024*4\n\n# print('Computing image embeddings...')\n# CTS = len(train)//CHUNK\n# if len(train)%CHUNK!=0: CTS += 1\n# for i,j in enumerate( range( CTS ) ):\n    \n#     a = j*CHUNK\n#     b = (j+1)*CHUNK\n#     b = min(b,len(train))\n#     print('chunk',a,'to',b)\n    \n#     test_gen = DataGenerator(train.iloc[a:b], batch_size=32, path=BASE)\n#     image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)\n#     embeds.append(image_embeddings)\n    \n# del model\n# _ = gc.collect()\n# image_embeddings = np.concatenate(embeds)\n# del embeds\n# print('image embeddings shape',image_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Nearest Neighbors","metadata":{}},{"cell_type":"code","source":"# model = NearestNeighbors(n_neighbors = 50, metric = 'cosine')\n# model.fit(image_embeddings)\n\n# n_distances = []\n# n_indices = []\n# CHUNK = 1024*4\n\n# print('Computing image nearest neighbors...')\n# CTS = len(train)//CHUNK\n# if len(train)%CHUNK!=0: CTS += 1\n# for i in range( CTS ):\n    \n#     # calculates chunk\n#     a = i*CHUNK\n#     b = (i+1)*CHUNK\n#     b = min(b,len(train))\n#     print('chunk',a,'to',b)\n    \n#     distances, indices_kNN = model.kneighbors(image_embeddings[a:b,])\n#     n_distances.append(distances)\n#     n_indices.append(indices_kNN)\n    \n#     del distances, indices_kNN\n    \n# _ = gc.collect() # garbage collector\n# n_distances = np.concatenate(n_distances) # convert sequence of arrays to ndarray\n# n_indices = np.concatenate(n_indices)\n# print('distances shape', np.shape(n_distances))\n# print('indices shape', np.shape(n_indices))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for ind in range(50):\n#     plt.hist(n_distances[ind, :], color = \"skyblue\")\n    \n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like 0.15 is a good cutoff for neighbor distances.","metadata":{}},{"cell_type":"markdown","source":"# Text Normalization","metadata":{}},{"cell_type":"code","source":"# lowercase = [title.lower() for title in train.title]\n# tokenized = [word_tokenize(title) for title in lowercase]\n\n# stopwords_punctuation = stopwords.words('english')\n# punctuation = [ '!', '\"', '#', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/',  '\\\\', ':', ';', '<', '=', '>',\n#            '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '\\t','\\n',\"'\",\",\",'~' , '—']\n# stopwords_punctuation.extend(punctuation)\n\n# titles_no_stopwords = []\n# for title in tokenized:\n#     title_no_sw = [word for word in title if not word in stopwords_punctuation]\n#     title_string = ' '.join(title_no_sw)\n#     titles_no_stopwords.append(title_string)\n    \n# train['title_no_sw'] = titles_no_stopwords\n# train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Predictions","metadata":{}},{"cell_type":"code","source":"# start_time = time.time()\n\n# ids = []\n# item_group = [] # tracks which group an item is in\n# groups = {} # tracks which items are in each group\n# for ind in train.index:\n    \n#     indices_phash = train.loc[(train['image_phash'] == train['image_phash'][ind])].index \n#     indices_title = train.loc[(train['title_no_sw'] == train['title_no_sw'][ind])].index \n#     indices_image = n_indices[ind, np.where(n_distances[ind] < 0.15)[0]]\n#     indices = set(indices_phash).union(set(indices_title)).union(set(indices_image))\n    \n#     # check if an item this matches already has a group\n#     match_ids = list(train.loc[indices]['posting_id'])\n#     if set(match_ids).intersection(ids):\n#         existing_group = item_group[ids.index(list(set(match_ids).intersection(ids))[0])]\n#         item_group.append(existing_group)\n#         groups[existing_group] = set(groups[existing_group]).union(match_ids)\n#     else:\n#         item_group.append(len(groups))\n#         groups[len(groups)] = match_ids\n        \n#     ids.append(train['posting_id'][ind])\n    \n# matches = [' '.join(list(groups[ind])) for ind in item_group]\n\n# print(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Score","metadata":{}},{"cell_type":"code","source":"# # add column with ground truth\n# tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n# train['target'] = train.label_group.map(tmp)\n\n# train['oof'] = [list(groups[ind]) for ind in item_group]\n# train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def getMetric(col):\n#     def f1score(row):\n#         n = len( np.intersect1d(row.target,row[col]) )\n#         return 2*n / (len(row.target)+len(row[col]))\n#     return f1score\n\n# train['f1'] = train.apply(getMetric('oof'),axis=1)\n# print('CV score =',train.f1.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using EfficientNetB1 resulted in a train score of 0.6521957366521641, and EfficientNetB2 resulted in 0.6546894934201912. ResNet50V2 gave 0.5910695245925622. Using EfficientNetB0 again with the NearestNeighbors metric set to cosine gave a training score of 0.6788261580490697.","metadata":{}},{"cell_type":"markdown","source":"# Applying to test set","metadata":{}},{"cell_type":"code","source":"BASE = '../input/shopee-product-matching/test_images/'\n\nWGT = '../input/effnetb0/efficientnetb0_notop.h5'\nmodel = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n\nembeds = []\nCHUNK = 1024*4\n\nprint('Computing image embeddings...')\nCTS = len(test)//CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor i,j in enumerate( range( CTS ) ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    test_gen = DataGenerator(test.iloc[a:b], batch_size=32, path=BASE)\n    image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)\n    embeds.append(image_embeddings)\n    \ndel model\n_ = gc.collect()\nimage_embeddings = np.concatenate(embeds)\ndel embeds\nprint('image embeddings shape',image_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neighbors = 3\nif test.shape[0] > 3:\n    neighbors = 50\nmodel = NearestNeighbors(n_neighbors = neighbors, metric = 'cosine')\nmodel.fit(image_embeddings)\n\nn_distances = []\nn_indices = []\nCHUNK = 1024*4\n\nprint('Computing image nearest neighbors...')\nCTS = len(test)//CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor i in range( CTS ):\n    \n    # calculates chunk\n    a = i*CHUNK\n    b = (i+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    # find 50 neighbors for everything in this chunk\n    distances, indices_kNN = model.kneighbors(image_embeddings[a:b,])\n    n_distances.append(distances)\n    n_indices.append(indices_kNN)\n    \n    del distances, indices_kNN\n    \n_ = gc.collect() # garbage collector\nn_distances = np.concatenate(n_distances) # convert sequence of arrays to ndarray\nn_indices = np.concatenate(n_indices)\nprint('distances shape', np.shape(n_distances))\nprint('indices shape', np.shape(n_indices))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lowercase = [title.lower() for title in test.title]\ntokenized = [word_tokenize(title) for title in lowercase]\n\nstopwords_punctuation = stopwords.words('english')\npunctuation = [ '!', '\"', '#', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/',  '\\\\', ':', ';', '<', '=', '>',\n           '?', '@', '[', ']', '^', '_', '`', '{', '|', '}', '\\t','\\n',\"'\",\",\",'~' , '—']\nstopwords_punctuation.extend(punctuation)\n\ntitles_no_stopwords = []\nfor title in tokenized:\n    title_no_sw = [word for word in title if not word in stopwords_punctuation]\n    title_string = ' '.join(title_no_sw)\n    titles_no_stopwords.append(title_string)\n    \ntest['title_no_sw'] = titles_no_stopwords\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport matplotlib.pyplot as pl\nstart_time = time.time()\ntfidf  = TfidfVectorizer()\ncorpus = tfidf.fit_transform(test['title_no_sw'])\nprint(corpus.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\nids = []\nitem_group = [] # tracks which group an item is in\ngroups = {} # tracks which items are in each group\nfor ind in test.index:\n    indices_phash = test.loc[(test['image_phash'] == test['image_phash'][ind])].index \n    indices_title = test.loc[(test['title_no_sw'] == test['title_no_sw'][ind])].index \n    indices_image = n_indices[ind, np.where(n_distances[ind] < 0.15)[0]]\n    alike_titles = []\n    for j in test.index:\n        if ind != j and cosine_similarity(corpus[ind], corpus[j]) > .75:\n            alike_titles.append(j)\n    indices = set(indices_phash).union(set(indices_title)).union(set(indices_image)).union(alike_titles)\n    \n    # check if an item this matches already has a group\n    match_ids = list(test.loc[indices]['posting_id'])\n    if set(match_ids).intersection(ids):\n        existing_group = item_group[ids.index(list(set(match_ids).intersection(ids))[0])]\n        item_group.append(existing_group)\n        groups[existing_group] = set(groups[existing_group]).union(match_ids)\n    else:\n        item_group.append(len(groups))\n        groups[len(groups)] = match_ids\n        \n    ids.append(test['posting_id'][ind])\n    \nmatches = [' '.join(list(groups[ind])) for ind in item_group]\n\nprint(time.time() - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now we have the ones that are the same but going to add similar ones as well\nprint(len(ids))\nprint(len(matches))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'posting_id': ids, 'matches': matches})\nsubmission.to_csv('submission.csv', index = False)\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}