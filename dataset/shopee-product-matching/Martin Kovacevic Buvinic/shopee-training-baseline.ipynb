{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install efficientnet\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom scipy import spatial\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nEPOCHS = 5\nBATCH_SIZE = 32\nIMAGE_SIZE = [384, 384]\n# Seed\nSEED = 42\n# Learning rate\nLR = 0.001\n# Verbosity\nVERBOSE = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to get our f1 score\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\n# Function to read and preprocess our data\ndef preprocess():\n    # Read train and test csv\n    train = pd.read_csv('../input/shopee-product-matching/train.csv')\n    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n    # Drop duplicates images to avoid leakage (dont know if this is correct)\n    train.drop_duplicates(subset = ['image'], inplace = True)\n    train.reset_index(drop = True, inplace = True)\n    label_mapper = dict(zip(train['label_group'].unique(), np.arange(len(train['label_group'].unique()))))\n    label_mapper_inv = dict(zip(np.arange(len(train['label_group'].unique())), train['label_group'].unique()))\n    train['label_group'] = train['label_group'].map(label_mapper)\n    # Number of classes\n    N_CLASSES = train['label_group'].nunique()\n    # Get ground truth labels format\n    tmp = train.groupby(['label_group'])['posting_id'].unique().to_dict()\n    train['matches'] = train['label_group'].map(tmp)\n    train['matches'] = train['matches'].apply(lambda x: ' '.join(x))\n    ground_truth = train[['posting_id', 'matches']]\n    # Calculate naive score using self-post\n    ground_truth['f1'] = f1_score(ground_truth['matches'], ground_truth['posting_id'])\n    score = ground_truth['f1'].mean()\n    print(f'Using the same posting id as prediction our f1 score is {score}')\n    return train, test, label_mapper, label_mapper_inv, N_CLASSES, ground_truth\n\n# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# Function to read our image and return image, label_group\ndef read_image(image, label_group):\n    image = tf.io.read_file(image)\n    image = decode_image(image)\n    return image, label_group\n\n# Function to get our training dataset\ndef get_training_dataset(image, label_group):\n    dataset = tf.data.Dataset.from_tensor_slices((image, label_group))\n    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# Function to get our validation dataset\ndef get_validation_dataset(image, label_group):\n    dataset = tf.data.Dataset.from_tensor_slices((image, label_group))\n    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n    \n# Function to split our data into train and validation\ndef train_and_eval_split(image, label_group):\n    trn_image, val_image, trn_labels, val_labels = train_test_split(image, label_group, random_state = SEED, shuffle = True)\n    return trn_image, val_image, trn_labels, val_labels\n\n# Function to create our EfficientNetB0 model\ndef get_model():\n        \n    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3))\n    x = efn.EfficientNetB0(include_top = False, weights = 'imagenet')(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n    output = tf.keras.layers.Dense(N_CLASSES, activation = 'softmax')(x)\n\n    model = tf.keras.models.Model(inputs = [inp], outputs = [output])\n\n    opt = tf.keras.optimizers.Adam(learning_rate = LR)\n\n    model.compile(\n        optimizer = opt,\n        loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n    )\n\n    return model\n\n# Function for a custom learning rate scheduler with warmup and decay\ndef get_lr_callback():\n    lr_start   = 0.000001\n    lr_max     = 0.000005 * BATCH_SIZE\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max    \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n    return lr_callback\n\n# Function to train and evaluate our model\ndef train_and_evaluate(image, label_group):\n    print('\\n')\n    print('-'*50)\n    # Seed everything\n    seed_everything(SEED)\n    STEPS_PER_EPOCH = len(image) // BATCH_SIZE\n    K.clear_session()\n    model = get_model()\n    image = '../input/shopee-product-matching/train_images/' + image\n    trn_image, val_image, trn_labels, val_labels = train_and_eval_split(image, label_group)\n    train_dataset = get_training_dataset(trn_image, trn_labels)\n    val_dataset = get_validation_dataset(val_image, val_labels)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'EfficientNetB0_{IMAGE_SIZE[0]}_{SEED}.h5', \n                                                    monitor = 'val_loss', \n                                                    verbose = VERBOSE, \n                                                    save_best_only = True,\n                                                    save_weights_only = True, \n                                                    mode = 'min')\n    history = model.fit(train_dataset,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        epochs = EPOCHS,\n                        callbacks = [checkpoint, get_lr_callback()], \n                        validation_data = val_dataset,\n                        verbose = VERBOSE)\n    \n    \n    print('\\n')\n    print('-'*50)\n    print('Training Complete...')\n    \n    return model, val_image\n\ndef get_cv_score(image, label_group, model, val_image):\n    \n    model.load_weights(f'EfficientNetB0_{IMAGE_SIZE[0]}_{SEED}.h5')\n    model = tf.keras.models.Model(inputs = model.input, outputs = model.layers[-2].output)\n    \n    # Respect order\n    image = '../input/shopee-product-matching/train_images/' + image\n    dataset_images = get_validation_dataset(image, label_group)\n    dataset_images = dataset_images.map(lambda image, label_group: image)\n    # Predict the entire dataset\n    embeddings = model.predict(dataset_images)\n    \n    # Find the best threshold (lazy optimization)\n    predictions_08 = []\n    predictions_09 = []\n    predictions_10 = []\n    predictions_11 = []\n    predictions_12 = []\n    predictions_13 = []\n    predictions_14 = []\n    predictions_15 = []\n    predictions_16 = []\n    # Iterate over each validation image and use cosine distance to find similar images\n    for val_index in tqdm(val_image.index):\n        distances = spatial.distance.cdist(\n            embeddings[np.newaxis, val_index, :], embeddings, 'cosine')[0]\n        # Only get small distances\n        TOP_08 = len(distances[distances <= 0.08])\n        TOP_09 = len(distances[distances <= 0.09])\n        TOP_10 = len(distances[distances <= 0.10])\n        TOP_11 = len(distances[distances <= 0.11])\n        TOP_12 = len(distances[distances <= 0.12])\n        TOP_13 = len(distances[distances <= 0.13])\n        TOP_14 = len(distances[distances <= 0.14])\n        TOP_15 = len(distances[distances <= 0.15])\n        TOP_16 = len(distances[distances <= 0.16])\n        top_k_08 = list(np.argsort(distances)[:TOP_08])\n        top_k_09 = list(np.argsort(distances)[:TOP_09])\n        top_k_10 = list(np.argsort(distances)[:TOP_10])\n        top_k_11 = list(np.argsort(distances)[:TOP_11])\n        top_k_12 = list(np.argsort(distances)[:TOP_12])\n        top_k_13 = list(np.argsort(distances)[:TOP_13])\n        top_k_14 = list(np.argsort(distances)[:TOP_14])\n        top_k_15 = list(np.argsort(distances)[:TOP_15])\n        top_k_16 = list(np.argsort(distances)[:TOP_16])\n        predictions_08.append(' '.join(train['posting_id'].iloc[top_k_08].values))\n        predictions_09.append(' '.join(train['posting_id'].iloc[top_k_09].values))\n        predictions_10.append(' '.join(train['posting_id'].iloc[top_k_10].values))\n        predictions_11.append(' '.join(train['posting_id'].iloc[top_k_11].values))\n        predictions_12.append(' '.join(train['posting_id'].iloc[top_k_12].values))\n        predictions_13.append(' '.join(train['posting_id'].iloc[top_k_13].values))\n        predictions_14.append(' '.join(train['posting_id'].iloc[top_k_14].values))\n        predictions_15.append(' '.join(train['posting_id'].iloc[top_k_15].values))\n        predictions_16.append(' '.join(train['posting_id'].iloc[top_k_16].values))\n\n    val_predictions = ground_truth.loc[val_image.index]\n    val_predictions['predictions_08'] = predictions_08\n    val_predictions['predictions_09'] = predictions_09\n    val_predictions['predictions_10'] = predictions_10\n    val_predictions['predictions_11'] = predictions_11\n    val_predictions['predictions_12'] = predictions_12\n    val_predictions['predictions_13'] = predictions_13\n    val_predictions['predictions_14'] = predictions_14\n    val_predictions['predictions_15'] = predictions_15\n    val_predictions['predictions_16'] = predictions_16\n    val_predictions['f1_08'] = f1_score(val_predictions['matches'], val_predictions['predictions_08'])\n    val_predictions['f1_09'] = f1_score(val_predictions['matches'], val_predictions['predictions_09'])\n    val_predictions['f1_10'] = f1_score(val_predictions['matches'], val_predictions['predictions_10'])\n    val_predictions['f1_11'] = f1_score(val_predictions['matches'], val_predictions['predictions_11'])\n    val_predictions['f1_12'] = f1_score(val_predictions['matches'], val_predictions['predictions_12'])\n    val_predictions['f1_13'] = f1_score(val_predictions['matches'], val_predictions['predictions_13'])\n    val_predictions['f1_14'] = f1_score(val_predictions['matches'], val_predictions['predictions_14'])\n    val_predictions['f1_15'] = f1_score(val_predictions['matches'], val_predictions['predictions_15'])\n    val_predictions['f1_16'] = f1_score(val_predictions['matches'], val_predictions['predictions_16'])\n    print('Our f1 score with threshold 0.08 for the validation set is {}'.format(val_predictions['f1_08'].mean()))\n    print('Our f1 score with threshold 0.09 for the validation set is {}'.format(val_predictions['f1_09'].mean()))\n    print('Our f1 score with threshold 0.10 for the validation set is {}'.format(val_predictions['f1_10'].mean()))\n    print('Our f1 score with threshold 0.11 for the validation set is {}'.format(val_predictions['f1_11'].mean()))\n    print('Our f1 score with threshold 0.12 for the validation set is {}'.format(val_predictions['f1_12'].mean()))\n    print('Our f1 score with threshold 0.13 for the validation set is {}'.format(val_predictions['f1_13'].mean()))\n    print('Our f1 score with threshold 0.14 for the validation set is {}'.format(val_predictions['f1_14'].mean()))\n    print('Our f1 score with threshold 0.15 for the validation set is {}'.format(val_predictions['f1_15'].mean()))\n    print('Our f1 score with threshold 0.16 for the validation set is {}'.format(val_predictions['f1_16'].mean()))\n    return val_predictions\n\ntrain, test, label_mapper, label_mapper_inv, N_CLASSES, ground_truth = preprocess()\nmodel, val_image = train_and_evaluate(train['image'], train['label_group'])\nval_predictions = get_cv_score(train['image'], train['label_group'], model, val_image)\nval_predictions.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}