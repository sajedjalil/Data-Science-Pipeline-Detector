{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!apt install ../input/pyturbojpeg/libturbojpeg_1.4.2-0ubuntu3.4_amd64.deb\n!pip install ../input/pyturbojpeg/PyTurboJPEG-1.4.1","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:47:04.925288Z","iopub.execute_input":"2021-05-28T10:47:04.925995Z","iopub.status.idle":"2021-05-28T10:47:20.820887Z","shell.execute_reply.started":"2021-05-28T10:47:04.925884Z","shell.execute_reply":"2021-05-28T10:47:20.819218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport torchvision.utils\n\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision.models import *\nfrom torchvision.datasets import ImageFolder\nfrom torch.autograd import Variable\nimport torchvision.models as models\n\nimport torchvision.datasets as datasets\nimport torch.optim as optim\nfrom torch.utils.data.dataset import Dataset\n\nfrom pathlib import Path\nimport sys\n\nfrom glob import glob\nfrom PIL import Image\n\nimport itertools\nimport random\n\nfrom tqdm.notebook import tqdm_notebook\n\nfrom turbojpeg import TurboJPEG\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport matplotlib.pyplot as plt\n\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-28T10:48:11.081784Z","iopub.execute_input":"2021-05-28T10:48:11.082168Z","iopub.status.idle":"2021-05-28T10:48:11.092454Z","shell.execute_reply.started":"2021-05-28T10:48:11.082133Z","shell.execute_reply":"2021-05-28T10:48:11.09163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42)\n\nBATCH_SIZE = 32\nNUMBER_EPOCHS = 5\nIMG_SIZE = 200","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:48:19.935939Z","iopub.execute_input":"2021-05-28T10:48:19.936539Z","iopub.status.idle":"2021-05-28T10:48:19.940256Z","shell.execute_reply.started":"2021-05-28T10:48:19.936505Z","shell.execute_reply":"2021-05-28T10:48:19.939513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.figure(figsize=(150, 150))\n    plt.show()    \n\ndef show_plot(iteration,loss):\n    plt.plot(iteration,loss)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:48:28.546776Z","iopub.execute_input":"2021-05-28T10:48:28.547357Z","iopub.status.idle":"2021-05-28T10:48:28.5523Z","shell.execute_reply.started":"2021-05-28T10:48:28.547322Z","shell.execute_reply":"2021-05-28T10:48:28.551575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_images = glob(\"../input/shopee-product-matching/train_images/*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:48:30.812517Z","iopub.execute_input":"2021-05-28T10:48:30.813273Z","iopub.status.idle":"2021-05-28T10:48:31.705987Z","shell.execute_reply.started":"2021-05-28T10:48:30.813232Z","shell.execute_reply":"2021-05-28T10:48:31.704528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/shopee-product-matching/train.csv\").sample(frac=1.0, random_state=666).reset_index(drop=True)\n\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:48:38.370861Z","iopub.execute_input":"2021-05-28T10:48:38.371547Z","iopub.status.idle":"2021-05-28T10:48:38.652773Z","shell.execute_reply.started":"2021-05-28T10:48:38.371468Z","shell.execute_reply":"2021-05-28T10:48:38.651565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = train.loc[:, ['posting_id', 'label_group']] \\\n    .merge(train.groupby('label_group', as_index=False).agg({'posting_id': list}), on='label_group', how='left') \\\n    .rename(columns={'posting_id_x': 'posting_id', 'posting_id_y': 'matches'}).drop(columns=['label_group']).explode('matches')\\\n    .reset_index(drop=True)\n\ncorrect['check'] = 1\ncorrect","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:50:45.772692Z","iopub.execute_input":"2021-05-28T10:50:45.773131Z","iopub.status.idle":"2021-05-28T10:50:46.409867Z","shell.execute_reply.started":"2021-05-28T10:50:45.773097Z","shell.execute_reply":"2021-05-28T10:50:46.408331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_groups = random.sample(list(train['label_group'].unique()), 1014)\n\nsplits = {\n    'train': train.loc[~train['label_group'].isin(val_groups), :],\n    'valid': train.loc[train['label_group'].isin(val_groups), :]\n}\n\ngroups = dict()\npairs = dict()\n\nfor split in list(splits.keys()):\n    groups[split] = splits[split].groupby('label_group', as_index=False).agg({'posting_id': list})\n    \n    combs = []\n\n    for i in groups[split]['posting_id']:\n        combs.extend(list(itertools.combinations(i, 2)))\n    \n    pairs[split] = pd.DataFrame({\n        'item_1': [i[0] for i in combs],\n        'item_2': [i[1] for i in combs]\n    }).sample(frac=1.0).drop_duplicates() \\\n        .merge(train.rename(columns={'posting_id': 'item_1'}).loc[:, ['item_1', 'image']], on='item_1', how='left') \\\n        .merge(train.rename(columns={'posting_id': 'item_2'}).loc[:, ['item_2', 'image']], on='item_2', how='left')\n\npairs","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:53:31.485957Z","iopub.execute_input":"2021-05-28T10:53:31.486387Z","iopub.status.idle":"2021-05-28T10:53:32.221144Z","shell.execute_reply.started":"2021-05-28T10:53:31.486352Z","shell.execute_reply":"2021-05-28T10:53:32.219857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tra = list(zip(pairs['train'].image_x.values, pairs['train'].image_y.values))\nval = list(zip(pairs['valid'].image_x.values, pairs['valid'].image_y.values))\n\nprint(\"Total train pairs:\", len(train))    \nprint(\"Total val pairs:\", len(val))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:54:13.607478Z","iopub.execute_input":"2021-05-28T10:54:13.607851Z","iopub.status.idle":"2021-05-28T10:54:13.641188Z","shell.execute_reply.started":"2021-05-28T10:54:13.60782Z","shell.execute_reply":"2021-05-28T10:54:13.639841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jpeg_reader = TurboJPEG() \n\nimg = random.choice(glob(\"../input/shopee-product-matching/train_images/*.jpg\"))\n\nwith open(img, \"rb\") as f:\n    img0 = jpeg_reader.decode(f.read(), 0) \n    \ntransform = A.Compose([\n    A.SmallestMaxSize(max_size=200, p=1.0),\n    A.RandomCrop(width=200, height=200, p=1.0)\n])\n    \nplt.imshow(transform(image=img0)['image'])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:54:17.208514Z","iopub.execute_input":"2021-05-28T10:54:17.208865Z","iopub.status.idle":"2021-05-28T10:54:17.597202Z","shell.execute_reply.started":"2021-05-28T10:54:17.208834Z","shell.execute_reply":"2021-05-28T10:54:17.595684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class trainingDataset(Dataset):\n    \n    def __init__(self,relationships, transform=None): \n        self.relationships = relationships\n        self.transform = transform\n        self.jpeg_reader = TurboJPEG() \n        \n    def __getitem__(self, index):\n        img0_info = self.relationships[index]\n        img0_path = glob(\"../input/shopee-product-matching/train_images/\" + img0_info[0])\n        img0_path = random.choice(img0_path)\n        \n        should_get_same_class = random.choice([0,1]) \n\n        if should_get_same_class==1:\n            img1_path = glob(\"../input/shopee-product-matching/train_images/\" + img0_info[1])\n            img1_path = random.choice(img1_path)\n        else:\n            img1_path = glob(\"../input/shopee-product-matching/train_images/*.jpg\")\n            img1_path = random.choice(img1_path)\n        \n        with open(img0_path, \"rb\") as f:\n            img0 = self.jpeg_reader.decode(f.read(), 1) \n            \n        with open(img1_path, \"rb\") as f:\n            img1 = self.jpeg_reader.decode(f.read(), 1) \n        \n        if self.transform is not None:\n            img0 = self.transform(image=img0)['image']\n            img1 = self.transform(image=img1)['image']\n        \n        return img0, img1, should_get_same_class \n    \n    def __len__(self):\n        return len(self.relationships)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:54:28.335394Z","iopub.execute_input":"2021-05-28T10:54:28.335873Z","iopub.status.idle":"2021-05-28T10:54:28.347679Z","shell.execute_reply.started":"2021-05-28T10:54:28.335833Z","shell.execute_reply":"2021-05-28T10:54:28.346264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val[0]","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:54:31.765633Z","iopub.execute_input":"2021-05-28T10:54:31.766082Z","iopub.status.idle":"2021-05-28T10:54:31.772774Z","shell.execute_reply.started":"2021-05-28T10:54:31.766045Z","shell.execute_reply":"2021-05-28T10:54:31.771809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([\n    A.SmallestMaxSize(max_size=200, p=1.0),\n    A.RandomCrop(width=200, height=200, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n    A.Rotate(p=0.25),\n    A.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n    ),\n    ToTensorV2()\n])\n\n\ntransform_val = A.Compose([\n    A.SmallestMaxSize(max_size=200, p=1.0),\n    A.RandomCrop(width=200, height=200, p=1.0),\n    A.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225],\n    ),\n    ToTensorV2()\n])\n\ntrainset = trainingDataset(relationships=tra[:10000],\n                           transform=transform)\n\ntrainloader = DataLoader(trainset,\n                        shuffle=True,\n                        num_workers=8,\n                        batch_size=BATCH_SIZE)\n\nvalset = trainingDataset(relationships=val[:1000],\n                         transform=transform_val)\n\nvalloader = DataLoader(valset,\n                        shuffle=True,\n                        num_workers=8,\n                        batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:58:55.487887Z","iopub.execute_input":"2021-05-28T10:58:55.488553Z","iopub.status.idle":"2021-05-28T10:58:55.541263Z","shell.execute_reply.started":"2021-05-28T10:58:55.488512Z","shell.execute_reply":"2021-05-28T10:58:55.54003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vis_dataloader = DataLoader(trainset,\n                        shuffle=True,\n                        num_workers=8,\n                        batch_size=8)\ndataiter = iter(vis_dataloader)\n\n\nexample_batch = next(dataiter)\nconcatenated = torch.cat((example_batch[0],example_batch[1]),0)\n\nimshow(torchvision.utils.make_grid(concatenated))\n\nprint(example_batch[2])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:58:57.026716Z","iopub.execute_input":"2021-05-28T10:58:57.027157Z","iopub.status.idle":"2021-05-28T10:59:06.462167Z","shell.execute_reply.started":"2021-05-28T10:58:57.02712Z","shell.execute_reply":"2021-05-28T10:59:06.461105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        self.cnn1 = models.resnet50(pretrained=True)\n        self.fc1 = nn.Linear(2*1000, 500)\n        self.fc2 = nn.Linear(500, 500)\n        self.fc3 = nn.Linear(500, 2)\n\n\n    def forward(self, input1, input2):\n        output1 = self.cnn1(input1)\n        output1 = output1.view(output1.size()[0], -1)\n        output2 = self.cnn1(input2)\n        output2 = output2.view(output2.size()[0], -1)\n        \n        output = torch.cat((output1, output2),1)\n        output = F.relu(self.fc1(output))\n        output = F.relu(self.fc2(output))\n        output = self.fc3(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:59:13.603401Z","iopub.execute_input":"2021-05-28T10:59:13.603905Z","iopub.status.idle":"2021-05-28T10:59:13.614965Z","shell.execute_reply.started":"2021-05-28T10:59:13.603864Z","shell.execute_reply":"2021-05-28T10:59:13.613039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nnet = SiameseNetwork().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n\ncounter = []\nloss_history = [] \niteration_number= 0\nbest = 0\n\nfor epoch in range(0,NUMBER_EPOCHS):\n    print(\"Epochï¼š\", epoch, \" start.\")\n    for i, data in enumerate(tqdm_notebook(trainloader),0):\n        img0, img1, labels = data\n        img0, img1, labels = img0.to(device), img1.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = net(img0, img1)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        if i %10 == 0:\n            iteration_number +=10\n            counter.append(iteration_number)\n            loss_history.append(loss.item())\n    \n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for data in tqdm_notebook(valloader):\n            img0, img1, labels = data\n            img0, img1, labels = img0.to(device), img1.to(device) , labels.to(device)\n            outputs = net(img0,img1)\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n    \n    if (100 * correct_val / total_val) > best:\n        torch.save(net, \"best_siamese.pth\")\n        best = 100 * correct_val / total_val\n    print((100 * correct_val / total_val))\n    show_plot(counter,loss_history)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T10:59:13.989223Z","iopub.execute_input":"2021-05-28T10:59:13.989664Z","iopub.status.idle":"2021-05-28T11:12:55.775836Z","shell.execute_reply.started":"2021-05-28T10:59:13.989624Z","shell.execute_reply":"2021-05-28T11:12:55.773783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img0.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:16:03.559226Z","iopub.execute_input":"2021-05-28T11:16:03.559672Z","iopub.status.idle":"2021-05-28T11:16:03.566313Z","shell.execute_reply.started":"2021-05-28T11:16:03.559613Z","shell.execute_reply":"2021-05-28T11:16:03.565596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_similarity(img0,img1):\n    \n    with open(img0, \"rb\") as f:\n        img0 = jpeg_reader.decode(f.read(), 1) \n            \n    with open(img1, \"rb\") as f:\n        img1 = jpeg_reader.decode(f.read(), 1) \n        \n    f, axarr = plt.subplots(1,2)\n    axarr[0].imshow(img0)\n    axarr[1].imshow(img1)\n        \n    img0 = transform_val(image=img0)['image'].view(1,3,200,200)\n    img1 = transform_val(image=img1)['image'].view(1,3,200,200)\n    \n    return torch.softmax(net(img0,img1), 1)[0][1].item()\n\nimage_similarity(\"../input/shopee-product-matching/test_images/0006c8e5462ae52167402bac1c2e916e.jpg\", \n                 \"../input/shopee-product-matching/test_images/0007585c4d0f932859339129f709bfdc.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:53:46.607059Z","iopub.execute_input":"2021-05-28T11:53:46.60799Z","iopub.status.idle":"2021-05-28T11:53:47.63196Z","shell.execute_reply.started":"2021-05-28T11:53:46.60794Z","shell.execute_reply":"2021-05-28T11:53:47.631073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}