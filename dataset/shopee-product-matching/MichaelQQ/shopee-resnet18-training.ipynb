{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"data_path1 = '../input/shopee-product-matching/'\ndata_path2 = '../input/shopeemorepicscsv/'\ndata_path3 = '../input/shopeepiclabeldic'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import psutil\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nimport gc\nimport pickle\n\n# import cudf, cuml, cupy\n# from cuml.feature_extraction.text import TfidfVectorizer\n# from cuml.neighbors import NearestNeighbors\n\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPUTE_CV = True\n\ntest = pd.read_csv(data_path1 + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n\n# COMPUTE_CV = False\n\nif COMPUTE_CV:\n    train = pd.read_csv(data_path1 + 'train.csv')\n    train['image'] = data_path1 + 'train_images/' + train['image']\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    # train_gf = cudf.read_csv(DATA_PATH + 'train.csv')\nelse:\n    train = pd.read_csv(data_path1 + 'test.csv')\n    train['image'] = data_path1 + 'test_images/' + train['image']\n    # train_gf = cudf.read_csv(DATA_PATH + 'test.csv')\n    \nprint('train shape is', train.shape )\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train2 = pd.read_csv(data_path2+'trainMorePics_in kaggle.csv')\ntrain2.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train1 = train[['image', 'label_group']]\ntrain1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([train1, train2])\ntrain.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(data_path3+'/label_di.pkl', 'rb') as f:\n    label_di = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['label'] = train.label_group.map(label_di)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.value_counts('label_group')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nclass ShopeeImageDataset(Dataset):\n    def __init__(self, img_path, label, transform):\n        self.img_path = img_path\n        self.label = label\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index]).convert('RGB')\n        img = self.transform(img)\n        label = self.label[index]\n        return img, label\n    \n    def __len__(self):\n        return len(self.img_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagedataset = ShopeeImageDataset(\n    train['image'].values, train['label'].values,\n    transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(20),\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]))\n    \nimageloader = torch.utils.data.DataLoader(\n    imagedataset,\n    batch_size=40, shuffle=False, num_workers=2\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, label in imageloader:\n    print(x.shape, label.shape)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build ResNet","metadata":{}},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n        super(Block, self).__init__()\n        self.num_layers = num_layers\n        if self.num_layers > 34:\n            self.expansion = 4\n        else:\n            self.expansion = 1\n        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        if self.num_layers > 34:\n            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        else:\n            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n\n    def forward(self, x):\n        identity = x\n        if self.num_layers > 34:\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x\n\n\nclass ResNet(nn.Module):\n    def __init__(self, num_layers, block, image_channels, num_classes):\n        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n                                                     f'to be 18, 34, 50, 101, or 152 '\n        super(ResNet, self).__init__()\n        if num_layers < 50:\n            self.expansion = 1\n        else:\n            self.expansion = 4\n        if num_layers == 18:\n            layers = [2, 2, 2, 2]\n        elif num_layers == 34 or num_layers == 50:\n            layers = [3, 4, 6, 3]\n        elif num_layers == 101:\n            layers = [3, 4, 23, 3]\n        else:\n            layers = [3, 8, 36, 3]\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # ResNetLayers\n        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * self.expansion, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc(x)\n        return x\n\n    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n        layers = []\n\n        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n        self.in_channels = intermediate_channels * self.expansion # 256\n        for i in range(num_residual_blocks - 1):\n            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n        return nn.Sequential(*layers)\n\n\ndef ResNet18(img_channels=3, num_classes=1000):\n    return ResNet(18, Block, img_channels, num_classes)\n\n\ndef ResNet34(img_channels=3, num_classes=1000):\n    return ResNet(34, Block, img_channels, num_classes)\n\n\ndef ResNet50(img_channels=3, num_classes=1000):\n    return ResNet(50, Block, img_channels, num_classes)\n\n\ndef ResNet101(img_channels=3, num_classes=1000):\n    return ResNet(101, Block, img_channels, num_classes)\n\n\ndef ResNet152(img_channels=3, num_classes=1000):\n    return ResNet(152, Block, img_channels, num_classes)\n\n\ndef test():\n    net = ResNet18(img_channels=3, num_classes=1000)\n    y = net(torch.randn(4, 3, 224, 224)).to(\"cuda\")\n    print(y.size())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpointpath = '../input/shopeecheckpoint02/checkpoint05.pth'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda')\nnum_classes = len(train.label_group.unique()) # 11014\n# model = ResNet18(img_channels=3, num_classes=num_classes).to(device)\nmodel = torch.load(checkpointpath).to(device)\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_li = []\nacc_li = []\nfor epoch in range(1):\n    for idx, (x, label) in enumerate(imageloader):\n        x, label = x.to(device), label.to(device)\n        logits = model(x) \n        loss = criterion(logits, label) \n        loss_li.append(loss.item())\n        # backprop\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    model.eval()\n    with torch.no_grad():\n        tot_corr = 0\n        tot_num = 0\n        \n        for x, label in imageloader:\n            x, label = x.to(device), label.to(device)\n            logits = model(x)\n            pred = logits.argmax(dim=1)\n            \n            tot_corr += torch.eq(pred, label).float().sum().item() # using item() to convert tensor to number\n            tot_num += x.size(0)\n            acc = tot_corr / tot_num\n            acc_li.append(acc)\n    \n    print('epoch: {}, loss: {}, acc: {}'.format(epoch, loss, acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('loss.pkl', 'wb') as f:\n    pickle.dump(loss_li, f)\nwith open('acc.pkl', 'wb') as f:\n    pickle.dump(acc_li, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, './checkpoint06.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}