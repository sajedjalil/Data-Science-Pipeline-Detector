{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install dependencies","metadata":{}},{"cell_type":"code","source":"%%bash\npip install ../input/shopee-libs/imagesize-1.2.0-py2.py3-none-any.whl \\\n../input/shopee-libs/PyStemmer-2.0.1/dist/PyStemmer-2.0.1.tar\npip install ../input/faiss-163/faiss_gpu-1.6.3-cp37-cp37m-manylinux2010_x86_64.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys\nsys.path.append('../input/shopee-libs')\nimport ast\nimport os\nimport time\nimport cv2\nimport PIL.Image\nimport random\nimport joblib\nimport pickle\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\nimport gc\n\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\n\n\nimport cudf\nfrom cuml.feature_extraction.text import TfidfVectorizer\nimport cupy as cp\nfrom igraph import Graph\nimport numba\n\n\nimport faiss\nimport langid\nimport Levenshtein\nfrom tqdm import tqdm\n\n\nfrom warnings import filterwarnings\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nmap_used_time = defaultdict(float)\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    tt = time.time() - t0\n    map_used_time[title] += tt\n    print(\"  {} - done in {:.5f}s\".format(title, tt))\n\n\nfilterwarnings(\"ignore\")\n\nK = 60\n\n# Due to memory limit, model training cannot be done in kaggle kernel. Please use a local machine with the input dataset.\nDEBUG = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load CSV","metadata":{}},{"cell_type":"code","source":"import imagesize\nimport Stemmer\nstemmer = Stemmer.Stemmer('indonesian')\n\ndata_dir = '../input/shopee-product-matching/train_images/'\n\ndf_test = pd.read_csv('../input/shopee-feats/train_with_fold.csv')\ndf_test['file_path'] = df_test.image.apply(lambda x: os.path.join(data_dir, f'{x}'))\n\nlabel_groups = np.sort(df_test['label_group'].unique())\nmap_label2id = {g: i for i, g in enumerate(label_groups)}\ndf_test['label'] = df_test['label_group'].map(map_label2id)\ndf_test['target'] = df_test['label_group'].map(df_test.groupby('label_group').apply(lambda x: x.index.values.tolist()))\n\ntitles = df_test['title'].str.lower().values\n\nwith timer('get lang'):\n    df_test['lang'] = [langid.classify(t)[0] for t in tqdm(titles)]\n    list_lang = df_test['lang'].values\nwith timer('lemmatize'):\n    titles = np.array([t.encode('ascii').decode('unicode-escape').encode('ascii', 'replace').decode('ascii').replace('?', ' ') for t in titles])\n    titles = [' '.join(stemmer.stemWords(t.split())) if list_lang[i] in {'id', 'ms'} else t for i, t in enumerate(tqdm(titles))]\n    df_test['title'] = titles\n\nwith timer('get image size'):\n    ## Getting image size and file size. Please see lyakaap's code\n    st_sizes, img_hs, img_ws = joblib.load('../input/shopee-cache/lyk_img_meta_data.pkl')\n    df_test['width'] = img_ws[:df_test.shape[0]]\n    df_test['hight'] = img_hs[:df_test.shape[0]]\n    df_test['st_size'] = st_sizes[:df_test.shape[0]]\n    df_test['wxh/st_size'] = df_test['width'] * df_test['hight'] / df_test['st_size']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Similarity: Text TFIDF","metadata":{}},{"cell_type":"code","source":"\n\n\nmodel = TfidfVectorizer(stop_words=None,#stop_words,#np.load('stop_words.npy').tolist(),\n                        binary=True,\n                        # norm='l1',\n                        # analyzer='char_wb',\n                        #ngram_range=(2, 5),\n                        #tokenizer=tokenizer.tokenize,\n                        #token_pattern='(?u)\\\\b\\\\w+\\\\b',\n                        # max_features=50000,\n                        # max_df=100,\n                        #vocabulary=['aaa', 'bbb'],\n                        min_df=2,\n                        dtype=np.float32)\n\nwith timer('tfidf fit'):\n    langs = df_test.lang.values\n    titles = df_test.title.values\n\n    text_embeddings = model.fit_transform(cudf.Series(titles)) #cp.sparse.csr_matrix(model.fit_transform(cudf.Series(titles)))\n    print('text embeddings shape', text_embeddings.shape)\n\n\nwith timer('tfidf pred'):\n    CHUNK = 1024*4\n    print('Finding similar titles...')\n    text_D = np.zeros((df_test.shape[0], K), dtype=np.float32)\n    text_I = np.zeros((df_test.shape[0], K), dtype=np.int32)\n\n    CTS = text_embeddings.shape[0]//CHUNK\n    if text_embeddings.shape[0] % CHUNK != 0:\n        CTS += 1\n    cnt = 0\n    for j in range(CTS):\n\n        a = j*CHUNK\n        b = (j+1)*CHUNK\n        b = min(b, text_embeddings.shape[0])\n        print('chunk', a, 'to', b, text_embeddings.shape[0])\n\n        # COSINE SIMILARITY DISTANCE\n        cts = (text_embeddings * text_embeddings[a:b].T).T.toarray()\n        indices = cp.argsort(cts, axis=1)\n\n        for k in range(b-a):\n            idx = indices[k][::-1]\n            text_I[cnt] = idx[:K].get()\n            text_D[cnt] = cts[k, idx[:K]].get()\n            cnt += 1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Similarity: Multi modal (NFNet-F0 and Indonesian BERT (concatenated at final feature layers))","metadata":{}},{"cell_type":"code","source":"list_preds1 = np.load('../input/shopee-feats/v79_mm_feats_2fold.npy').astype(np.float32)\n\nmut_D = []\nmut_I = []\n\nfor fold_id in tqdm(range(2)):\n    preds = list_preds1[fold_id]\n    preds /= np.linalg.norm(preds, axis=1).reshape((-1, 1))\n\n    index = faiss.IndexFlatIP(preds.shape[1])   # build the index\n\n    res = faiss.StandardGpuResources()\n    index = faiss.index_cpu_to_gpu(res, 0, index)\n\n    index.add(preds)                  # add vectors to the index\n    D, I = index.search(preds, K)\n\n    mut_D.append(D)\n    mut_I.append(I)\nfold_mut_I = np.stack(mut_I)\nfold_mut_D = np.stack(mut_D)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Similarity: Bert (Indonesian-BERT, Multilingual-BERT, and Paraphrase-XLM embeddings)","metadata":{}},{"cell_type":"code","source":"list_preds_txt = [np.load('../input/shopee-feats/v75_bert_feats_2fold.npy').astype(np.float32),\n                np.load('../input/shopee-feats/v102_bert_feats_2fold.npy').astype(np.float32),\n                np.load('../input/shopee-feats/v103_bert_feats_2fold.npy').astype(np.float32),\n                #np.load('../input/shopee-feats/v106_bert_feats_2fold.npy').astype(np.float32),\n                #np.stack([np.load('../input/shopee-feats/clip_text_feats.npy').astype(np.float32)] * 2),\n                #np.stack([np.load('../input/shopee-feats/use_multilingual_feats.npy').astype(np.float32)] * 2),\n]\n\nbrt_D = []\nbrt_I = []\n\nfor fold_id in tqdm(range(2)):\n    #import pdb;pdb.set_trace()\n    #preds = list_preds1[fold_id]\n    preds = np.hstack([p[fold_id] for p in list_preds_txt])\n\n    preds /= np.linalg.norm(preds, axis=1).reshape((-1, 1))\n\n    index = faiss.IndexFlatIP(preds.shape[1])   # build the index\n\n    res = faiss.StandardGpuResources()\n    index = faiss.index_cpu_to_gpu(res, 0, index)\n\n    index.add(preds)                  # add vectors to the index\n    D, I = index.search(preds, K)\n\n    brt_D.append(D)\n    brt_I.append(I)\nfold_brt_I = np.stack(brt_I)\nfold_brt_D = np.stack(brt_D)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Similarity: Image (NFNet-F0 and ViT )","metadata":{}},{"cell_type":"code","source":"list_preds1 = np.load('../input/shopee-feats/v34_image_feats_2fold.npy').astype(np.float32)\nlist_preds2 = np.load('../input/shopee-feats/v45_image_feats_2fold.npy').astype(np.float32)\n#list_preds3 = np.load('list_pred_0420_resnet50d_lykfold.npy').astype(np.float32)\n\nimg_D = []\nimg_I = []\nfor fold_id in tqdm(range(2)):\n    preds = np.concatenate([list_preds1[fold_id], list_preds2[fold_id]], axis=1)\n    preds /= np.linalg.norm(preds, axis=1).reshape((-1, 1))\n\n    index = faiss.IndexFlatIP(preds.shape[1])   # build the index\n\n    res = faiss.StandardGpuResources()\n    index = faiss.index_cpu_to_gpu(res, 0, index)\n\n    index.add(preds)                  # add vectors to the index\n    D, I = index.search(preds, K)\n\n    img_D.append(D)\n    img_I.append(I)\n\nfold_img_I = np.stack(img_I)\nfold_img_D = np.stack(img_D)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Similarity: Image+BERT","metadata":{}},{"cell_type":"code","source":"list_preds_txt = [np.load('../input/shopee-feats/v75_bert_feats_2fold.npy').astype(np.float32),\n                np.load('../input/shopee-feats/v102_bert_feats_2fold.npy').astype(np.float32),\n                np.load('../input/shopee-feats/v103_bert_feats_2fold.npy').astype(np.float32),\n\n]\nlist_preds_img = [\n    np.load('../input/shopee-feats/v34_image_feats_2fold.npy').astype(np.float32),\n    np.load('../input/shopee-feats/v45_image_feats_2fold.npy').astype(np.float32),\n]\n\n\nbth_D = []\nbth_I = []\n\nfor fold_id in tqdm(range(2)):\n    preds1 = np.hstack([p[fold_id] for p in list_preds_txt])\n    preds1 /= np.linalg.norm(preds1, axis=1).reshape((-1, 1))\n\n    preds2 = np.hstack([p[fold_id] for p in list_preds_img])\n    preds2 /= np.linalg.norm(preds2, axis=1).reshape((-1, 1))\n\n    preds = np.concatenate([preds1, preds2], axis=1)\n    preds /= np.linalg.norm(preds, axis=1).reshape((-1, 1))\n\n    index = faiss.IndexFlatIP(preds.shape[1])   # build the index\n\n    res = faiss.StandardGpuResources()\n    index = faiss.index_cpu_to_gpu(res, 0, index)\n\n    index.add(preds)                  # add vectors to the index\n    D, I = index.search(preds, K)\n\n    bth_D.append(D)\n    bth_I.append(I)\nfold_bth_I = np.stack(bth_I)\nfold_bth_D = np.stack(bth_D)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Features","metadata":{}},{"cell_type":"code","source":"df_feat_all = pd.DataFrame()\n\nTARGETS = df_test['label_group'].values\n\nwidth_hight = df_test[['width', 'hight']].values\nst_size = df_test['st_size'].values\nwh_st_size = df_test['wxh/st_size'].values\n\ntitles = df_test['title'].values\nlangs = df_test['lang'].values\n\nnumset = set('0123456789')\n\ntxt_cnt_all = np.vstack([(text_D[:, :K] > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\ntxt_avg_all = text_D[:, :K].mean(axis=1)\ntxt_std_all = text_D[:, :K].std(axis=1)\n\ntxt_avg_5_all = text_D[:, :5].mean(axis=1)\ntxt_avg_10_all = text_D[:, :10].mean(axis=1)\ntxt_avg_15_all = text_D[:, :15].mean(axis=1)\ntxt_avg_30_all = text_D[:, :30].mean(axis=1)\n\nTARGETS = df_test['label_group'].values\n\nneighbors_txt = np.take(TARGETS, text_I)\n\nfor fold_id in range(2):\n    D, I = fold_img_D[fold_id], fold_img_I[fold_id]\n    img_cnt_all = np.vstack([(D[:, :K] > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n    img_avg_all = D[:, :K].mean(axis=1)\n    img_std_all = D[:, :K].std(axis=1)\n\n    neighbors = np.take(TARGETS, I)\n    ###\n    bert_I, bert_D = fold_brt_I[fold_id], fold_brt_D[fold_id]\n    brt_cnt_all = np.vstack([(bert_D[:, :K] > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n    brt_avg_all = bert_D[:, :K].mean(axis=1)\n    brt_std_all = bert_D[:, :K].std(axis=1)\n\n    neighbors_brt = np.take(TARGETS, bert_I)\n    ###\n    mut_I, mut_D = fold_mut_I[fold_id], fold_mut_D[fold_id]\n    mut_cnt_all = np.vstack([(mut_D[:, :K] > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n    mut_avg_all = mut_D[:, :K].mean(axis=1)\n    mut_std_all = mut_D[:, :K].std(axis=1)\n\n    neighbors_mut = np.take(TARGETS, mut_I)\n    ###\n\n    bth_I, bth_D = fold_bth_I[fold_id], fold_bth_D[fold_id]\n    bth_cnt_all = np.vstack([(bth_D[:, :K] > t).sum(axis=1) for t in [0.9, 0.8, 0.7, 0.6, 0.5]]).T\n    bth_avg_all = bth_D[:, :K].mean(axis=1)\n    bth_std_all = bth_D[:, :K].std(axis=1)\n\n    neighbors_bth = np.take(TARGETS, bth_I)\n    ###\n    \n    indices = df_test[df_test['fold'] == fold_id].index.values\n    if DEBUG:\n        indices = indices[:1000]\n        \n    list_feat = []\n    for i in tqdm(indices):  # tqdm(df_test.index.values):#range(TARGETS.shape[0]):\n        img_d = D[i]\n        img_i = I[i]\n\n        img_cnt = img_cnt_all[i]  # (img_d > 0.9).sum()\n        img_avg = img_avg_all[i]  # img_d.mean()\n        img_std = img_std_all[i]  # img_d.std()\n\n        img_width, img_hight = width_hight[i]\n        ###\n        brt_d = bert_D[i]\n        brt_i = bert_I[i]\n\n        brt_cnt = brt_cnt_all[i]  # (brt_d > 0.9).sum()\n        brt_avg = brt_avg_all[i]  # brt_d.mean()\n        brt_std = brt_std_all[i]  # brt_d.std()\n\n        brt_set = set(titles[i])\n        ###\n        mut_d = mut_D[i]\n        mut_i = mut_I[i]\n\n        mut_cnt = mut_cnt_all[i]  # (mut_d > 0.9).sum()\n        mut_avg = mut_avg_all[i]  # mut_d.mean()\n        mut_std = mut_std_all[i]  # mut_d.std()\n\n        mut_set = set(titles[i])\n\n        ###\n        bth_d = bth_D[i]\n        bth_i = bth_I[i]\n\n        bth_cnt = bth_cnt_all[i]  # (bth_d > 0.9).sum()\n        bth_avg = bth_avg_all[i]  # bth_d.mean()\n        bth_std = bth_std_all[i]  # bth_d.std()\n\n        bth_set = set(titles[i])\n        ###\n        txt_d = text_D[i]\n        txt_i = text_I[i]\n\n        txt_cnt = txt_cnt_all[i]  # (txt_d > 0.9).sum()\n        txt_avg = txt_avg_all[i]  # txt_d.mean()\n        txt_std = txt_std_all[i]  # txt_d.std()\n\n        txt_set = set(titles[i])\n\n        map_feat = {}\n        row = neighbors[i]\n        for j in range(min(K, len(img_i))):\n            _w, _h = width_hight[img_i[j]]\n            _img_cnt = img_cnt_all[img_i[j]]  # (img_d > 0.9).sum()\n            _img_avg = img_avg_all[img_i[j]]  # img_d.mean()\n            _img_std = img_std_all[img_i[j]]  # img_d.std()\n\n\n            diff_width = abs(img_width - _w)\n            diff_hight = abs(img_hight - _h)\n            d = {'idx': i, 'idx2': img_i[j],\n                 'fold': fold_id,\n                 'label': row[j] == TARGETS[i],\n                 'img_sim': img_d[j],\n                 'img_avg': img_avg,\n                 'img_std': img_std,\n                 'img_avg2': _img_avg,\n                 'img_std2': _img_std,\n\n                 'diff_width': diff_width,\n                 'diff_hight': diff_hight,\n                 'img_width': img_width,\n                 'img_hight': img_hight,\n                 'img_width2': _w,\n                 'img_hight2': _h,\n\n                 'st_size': st_size[i],\n                 'st_size2': st_size[img_i[j]],\n                 'wh_st_size': wh_st_size[i],\n                 'wh_st_size2': wh_st_size[img_i[j]]\n                 }\n            d.update({f'img_cnt_{ii}': img_cnt[ii] for ii in range(img_cnt.shape[0])})\n            d.update({f'img_cnt2_{ii}': _img_cnt[ii] for ii in range(_img_cnt.shape[0])})\n            map_feat[img_i[j]] = d\n\n        row = neighbors_brt[i]\n        for j in range(min(K, len(brt_i))):\n            _brt_set = set(titles[brt_i[j]])\n            _brt_cnt = brt_cnt_all[brt_i[j]]  # (brt_d > 0.9).sum()\n            _brt_avg = brt_avg_all[brt_i[j]]  # brt_d.mean()\n            _brt_std = brt_std_all[brt_i[j]]  # brt_d.std()\n\n            diff_brt_set = set(titles[brt_i[j]]) & brt_set\n            diff_brt_set = len(numset & diff_brt_set) / (len(diff_brt_set) + 1)\n            xor_brt_set = set(titles[brt_i[j]]) ^ brt_set\n            xor_brt_set = len(numset & xor_brt_set) / (len(xor_brt_set) + 1)\n            jac_brt = len(brt_set & _brt_set) / (len(brt_set | _brt_set) + 1)\n            lev_dist = Levenshtein.distance(titles[i], titles[brt_i[j]])\n            d = {'idx': i, 'idx2': brt_i[j],\n                 'fold': fold_id,\n                 'label': row[j] == TARGETS[i],\n                 'brt_sim': brt_d[j],\n                 'brt_avg': brt_avg,\n                 'brt_std': brt_std,\n                 'brt_avg2': _brt_avg,\n                 'brt_std2': _brt_std,\n\n                 'jac_txt': jac_brt,\n                 'diff_txt_set': diff_brt_set,\n                 'xor_txt_set': xor_brt_set,\n                 'lev_dist': lev_dist,\n                 'len_txt': len(titles[i]),\n                 'len_txt2': len(titles[brt_i[j]]),\n                 'lang_en': int(langs[i] == 'en'),\n                 'lang_en2': int(langs[brt_i[j]] == 'en'),\n                 }\n            d.update({f'brt_cnt_{ii}': brt_cnt[ii] for ii in range(brt_cnt.shape[0])})\n            d.update({f'brt_cnt2_{ii}': _brt_cnt[ii] for ii in range(_brt_cnt.shape[0])})\n            if brt_i[j] in map_feat:\n                map_feat[brt_i[j]].update(d)\n            else:\n                map_feat[brt_i[j]] = d\n\n        row = neighbors_mut[i]\n        for j in range(min(K, len(mut_i))):\n            _mut_set = set(titles[mut_i[j]])\n            _mut_cnt = mut_cnt_all[mut_i[j]]  # (mut_d > 0.9).sum()\n            _mut_avg = mut_avg_all[mut_i[j]]  # mut_d.mean()\n            _mut_std = mut_std_all[mut_i[j]]  # mut_d.std()\n\n            _w, _h = width_hight[mut_i[j]]\n            diff_width = abs(img_width - _w)\n            diff_hight = abs(img_hight - _h)\n\n            diff_mut_set = set(titles[mut_i[j]]) & mut_set\n            diff_mut_set = len(numset & diff_mut_set) / (len(diff_mut_set) + 1)\n            xor_mut_set = set(titles[mut_i[j]]) ^ mut_set\n            xor_mut_set = len(numset & xor_mut_set) / (len(xor_mut_set) + 1)\n            jac_mut = len(mut_set & _mut_set) / (len(mut_set | _mut_set) + 1)\n            lev_dist = Levenshtein.distance(titles[i], titles[mut_i[j]])\n            d = {'idx': i, 'idx2': mut_i[j],\n                 'fold': fold_id,\n                 'label': row[j] == TARGETS[i],\n                 'mut_sim': mut_d[j],\n                 'mut_avg': mut_avg,\n                 'mut_std': mut_std,\n                 'mut_avg2': _mut_avg,\n                 'mut_std2': _mut_std,\n\n                 'jac_txt': jac_mut,\n                 'diff_txt_set': diff_mut_set,\n                 'xor_txt_set': xor_mut_set,\n                 'lev_dist': lev_dist,\n                 'len_txt': len(titles[i]),\n                 'len_txt2': len(titles[mut_i[j]]),\n                 'lang_en': int(langs[i] == 'en'),\n                 'lang_en2': int(langs[mut_i[j]] == 'en'),\n\n                 'diff_width': diff_width,\n                 'diff_hight': diff_hight,\n                 'img_width': img_width,\n                 'img_hight': img_hight,\n                 'img_width2': _w,\n                 'img_hight2': _h,\n                 'st_size': st_size[i],\n                 'st_size2': st_size[mut_i[j]],\n                 'wh_st_size': wh_st_size[i],\n                 'wh_st_size2': wh_st_size[mut_i[j]]\n                 }\n            d.update({f'mut_cnt_{ii}': mut_cnt[ii] for ii in range(mut_cnt.shape[0])})\n            d.update({f'mut_cnt2_{ii}': _mut_cnt[ii] for ii in range(_mut_cnt.shape[0])})\n            if mut_i[j] in map_feat:\n                map_feat[mut_i[j]].update(d)\n            else:\n                map_feat[mut_i[j]] = d\n\n        row = neighbors_bth[i]\n        for j in range(min(K, len(bth_i))):\n            _bth_set = set(titles[bth_i[j]])\n            _bth_cnt = bth_cnt_all[bth_i[j]]  # (bth_d > 0.9).sum()\n            _bth_avg = bth_avg_all[bth_i[j]]  # bth_d.mean()\n            _bth_std = bth_std_all[bth_i[j]]  # bth_d.std()\n\n            _w, _h = width_hight[bth_i[j]]\n            diff_width = abs(img_width - _w)\n            diff_hight = abs(img_hight - _h)\n\n            diff_bth_set = set(titles[bth_i[j]]) & bth_set\n            diff_bth_set = len(numset & diff_bth_set) / (len(diff_bth_set) + 1)\n            xor_bth_set = set(titles[bth_i[j]]) ^ bth_set\n            xor_bth_set = len(numset & xor_bth_set) / (len(xor_bth_set) + 1)\n            jac_bth = len(bth_set & _bth_set) / (len(bth_set | _bth_set) + 1)\n            lev_dist = Levenshtein.distance(titles[i], titles[bth_i[j]])\n            d = {'idx': i, 'idx2': bth_i[j],\n                'fold': fold_id,\n                'label': row[j] == TARGETS[i],\n                'bth_sim': bth_d[j],\n                'bth_avg': bth_avg,\n                'bth_std': bth_std,\n                'bth_avg2': _bth_avg,\n                'bth_std2': _bth_std,\n\n                'jac_txt': jac_bth,\n                'diff_txt_set': diff_bth_set,\n                'xor_txt_set': xor_bth_set,\n                'lev_dist': lev_dist,\n                'len_txt': len(titles[i]),\n                'len_txt2': len(titles[bth_i[j]]),\n                'lang_en': int(langs[i] == 'en'),\n                'lang_en2': int(langs[bth_i[j]] == 'en'),\n\n\n                 'diff_width': diff_width,\n                 'diff_hight': diff_hight,\n                 'img_width': img_width,\n                 'img_hight': img_hight,\n                 'img_width2': _w,\n                 'img_hight2': _h,\n                 'st_size': st_size[i],\n                 'st_size2': st_size[bth_i[j]],\n                 'wh_st_size': wh_st_size[i],\n                 'wh_st_size2': wh_st_size[bth_i[j]]\n                }\n            d.update({f'bth_cnt_{ii}': bth_cnt[ii] for ii in range(bth_cnt.shape[0])})\n            d.update({f'bth_cnt2_{ii}': _bth_cnt[ii] for ii in range(_bth_cnt.shape[0])})\n            if bth_i[j] in map_feat:\n                map_feat[bth_i[j]].update(d)\n            else:\n                map_feat[bth_i[j]] = d\n\n        row = neighbors_txt[i]\n        for j in range(min(K, len(txt_i))):\n            _txt_set = set(titles[txt_i[j]])\n            _txt_cnt = txt_cnt_all[txt_i[j]]  # (txt_d > 0.9).sum()\n            _txt_avg = txt_avg_all[txt_i[j]]  # txt_d.mean()\n            _txt_std = txt_std_all[txt_i[j]]  # txt_d.std()\n            diff_txt_set = set(titles[txt_i[j]]) & txt_set\n            diff_txt_set = len(numset & diff_txt_set) / (len(diff_txt_set) + 1)\n            xor_txt_set = set(titles[txt_i[j]]) ^ txt_set\n            xor_txt_set = len(numset & xor_txt_set) / (len(xor_txt_set) + 1)\n            jac_txt = len(txt_set & _txt_set) / (len(txt_set | _txt_set) + 1)\n            lev_dist = Levenshtein.distance(titles[i], titles[txt_i[j]])\n            d = {'idx': i, 'idx2': txt_i[j],\n                 'fold': fold_id,\n                 'label': row[j] == TARGETS[i],\n                 'txt_sim': txt_d[j],\n                 'txt_avg': txt_avg,\n                 'txt_std': txt_std,\n                 'txt_avg2': _txt_avg,\n                 'txt_std2': _txt_std,\n                 'jac_txt': jac_txt,\n                 'diff_txt_set': diff_txt_set,\n                 'xor_txt_set': xor_txt_set,\n                 'lev_dist': lev_dist,\n                 'len_txt': len(titles[i]),\n                 'len_txt2': len(titles[txt_i[j]]),\n                 'lang_en': int(langs[i] == 'en'),\n                 'lang_en2': int(langs[txt_i[j]] == 'en'),\n                 }\n            d.update({f'txt_cnt_{ii}': txt_cnt[ii] for ii in range(txt_cnt.shape[0])})\n            d.update({f'txt_cnt2_{ii}': _txt_cnt[ii] for ii in range(_txt_cnt.shape[0])})\n            if txt_i[j] in map_feat:\n                map_feat[txt_i[j]].update(d)\n            else:\n                map_feat[txt_i[j]] = d\n\n        #df_feat = pd.DataFrame(map_feat.values()).fillna(0)\n        #import pdb;pdb.set_trace()\n        list_feat += list(map_feat.values())\n    df_feat = pd.DataFrame(list_feat).fillna(0)\n    df_feat['fold_id'] = fold_id\n    df_feat_all = df_feat_all.append(df_feat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graph Features","metadata":{}},{"cell_type":"code","source":"for sim in tqdm(['img', 'bth', 'mut', 'brt', 'txt'], desc='graph'):\n    weights = df_feat_all[f'{sim}_sim'].values\n    list_idx = df_feat_all['idx'].values\n    list_idx2 = df_feat_all['idx2'].values\n    idx = weights > 0\n    g = Graph()\n    g.add_vertices(len(df_test))\n    g.add_edges(list(zip(list_idx[idx], list_idx2[idx])), {'weight': weights[idx]})\n    with timer('pagerank'):\n        map_pr = np.array(g.pagerank(damping=0.85, weights='weight', niter=100, eps=1e-06, directed=False))\n    with timer('pagerank reg'):\n        data1 = map_pr[list_idx]\n        data2 = map_pr[list_idx2]\n\n        data1[weights <= 0] = 0\n        data2[weights <= 0] = 0\n        df_feat_all[f'{sim}_pagerank'] = data1\n        df_feat_all[f'{sim}_pagerank2'] = data2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample weighting according to label group size","metadata":{}},{"cell_type":"code","source":"df_feat_all['weight'] = df_feat_all['idx'].map(df_test['label_group'].map(df_test['label_group'].value_counts()))\ndf_feat_all['weight'] = df_feat_all['weight'] ** 0.44636585418558483  #** (trial.suggest_uniform('weight_factor', 0, 2)) #(trial.suggest_uniform('weight_factor', 0, 2)) # 0.6431355997563519 # \ndf_feat_all['group'] = df_feat_all['idx'].map(df_test['label_group'].map(df_test['label_group'].value_counts()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train LGB model","metadata":{}},{"cell_type":"markdown","source":"### F1 Optimization for stopping criteria\n\nhttps://www.kaggle.com/c/instacart-market-basket-analysis/discussion/37221","metadata":{}},{"cell_type":"code","source":"%load_ext Cython","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%cython\n\nfrom cython.parallel cimport parallel, prange\nfrom libc.stdlib cimport abort, malloc, free\ncimport cython\nimport numpy as np\ncimport numpy as np\nfrom sklearn.metrics import f1_score\n\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\ndef f1_opt(np.ndarray[double, ndim=1] preds):\n    cdef int i, j, k, k1\n    cdef double f1, score\n    cdef long n = preds.shape[0]\n\n\n    cdef np.ndarray[double, ndim = 2] DP_C = np.zeros((n + 2, n + 1), dtype=np.float)\n\n    DP_C[0, 0] = 1.0\n    for j in range(1, n):\n        DP_C[0, j] = (1.0 - preds[j - 1]) * DP_C[0, j - 1]\n    for i in range(1, n + 1):\n        DP_C[i, i] = DP_C[i - 1, i - 1] * preds[i - 1]\n        for j in range(i + 1, n + 1):\n            DP_C[i, j] = preds[j - 1] * DP_C[i - 1, j - 1] + (1.0 - preds[j - 1]) * DP_C[i, j - 1]\n\n    cdef np.ndarray[double, ndim = 1] DP_S = np.zeros((2 * n + 1,))\n\n    for i in range(1, 2 * n + 1):\n        DP_S[i] = 1. / (1. * i)\n\n    score = -1\n    cdef np.ndarray[double, ndim= 1] expectations = np.zeros(n + 1)\n\n    for k in range(n + 1)[::-1]:\n        f1 = 0\n        for k1 in range(n + 1):\n            f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]\n        for i in range(1, 2 * k - 1):\n            DP_S[i] = (1 - preds[k - 1]) * DP_S[i] + preds[k - 1] * DP_S[i + 1]\n\n        expectations[k] = f1\n\n    return expectations\n\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\ndef f1_score(np.ndarray[long, ndim=1] label, np.ndarray[double, ndim=1] preds):\n    cdef int i, j, k, k1\n    cdef double f1, score, f1None, pNone\n    cdef long n = preds.shape[0]\n\n    pNone = 0.\n\n    cdef np.ndarray[long, ndim= 1] idx = np.argsort(preds)[::-1]\n    label = label[idx]\n    preds = preds[idx]\n\n    cdef np.ndarray[double, ndim = 2] DP_C = np.zeros((n + 2, n + 1), dtype=np.float)\n\n    DP_C[0, 0] = 1.0\n    for j in range(1, n):\n        DP_C[0, j] = (1.0 - preds[j - 1]) * DP_C[0, j - 1]\n    for i in range(1, n + 1):\n        DP_C[i, i] = DP_C[i - 1, i - 1] * preds[i - 1]\n        for j in range(i + 1, n + 1):\n            DP_C[i, j] = preds[j - 1] * DP_C[i - 1, j - 1] + (1.0 - preds[j - 1]) * DP_C[i, j - 1]\n\n    cdef np.ndarray[double, ndim = 1] DP_S = np.zeros((2 * n + 1,))\n    cdef np.ndarray[double, ndim = 1] DP_SNone = np.zeros((2 * n + 1,))\n    for i in range(1, 2 * n + 1):\n        DP_S[i] = 1. / (1. * i)\n        DP_SNone[i] = 1. / (1. * i + 1)\n\n    score = -1\n    cdef np.ndarray[double, ndim= 1] expectations = np.zeros(n + 1)\n    cdef np.ndarray[double, ndim= 1] expectationsNone = np.zeros(n + 1)\n\n    for k in range(n + 1)[::-1]:\n        f1 = 0\n        f1None = 0\n        for k1 in range(n + 1):\n            f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]\n            f1None += 2 * k1 * DP_C[k1][k] * DP_SNone[k + k1]\n        for i in range(1, 2 * k - 1):\n            DP_S[i] = (1 - preds[k - 1]) * DP_S[i] + preds[k - 1] * DP_S[i + 1]\n            DP_SNone[i] = (1 - preds[k - 1]) * DP_SNone[i] + preds[k - 1] * DP_SNone[i + 1]\n        expectations[k] = f1\n        expectationsNone[k] = f1None + 2 * pNone / (2 + k)\n\n    if expectations.max() > expectationsNone.max():\n        i = np.argsort(expectations)[n] - 1\n        tp = label[:i + 1].sum()\n        if tp > 0:\n            precision = tp / (i + 1)\n            recall = tp / label.sum()\n            f1 = (2 * precision * recall) / (precision + recall)\n        else:\n            f1 = 0\n    else:\n        i = np.argsort(expectationsNone)[n] - 1\n        tp = label[:i + 1].sum() if label.sum() != 0 else 1\n        if tp > 0:\n            precision = tp / (i + 2)\n            recall = tp / max(label.sum(), 1)\n            f1 = (2 * precision * recall) / (precision + recall)\n        else:\n            f1 = 0\n\n    return f1\n\n\nfrom multiprocessing import Pool\n\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\ndef f1_group(np.ndarray[long, ndim=1] label, np.ndarray[double, ndim=1] preds, np.ndarray[long, ndim=1] group):\n    cdef int i, start, end, j, s\n    cdef double score = 0.\n    cdef long m = group.shape[0]\n    cdef long n = preds.shape[0]\n    start = 0\n\n    p = Pool()\n    list_p = []\n    for i in range(m):\n        end = start + group[i]\n        list_p.append(p.apply_async(f1_score, (label[start:end], preds[start:end],)))\n        start = end\n    scores = [a.get() for a in list_p]\n    p.close()\n    p.join()\n    return np.mean(scores)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"param = {'objective': 'binary',\n             'verbosity': -1,\n             'boosting_type': 'gbdt',\n             'bagging_freq': 1,\n             'num_iterations': 10000 if not DEBUG else 101,\n             'early_stopping_round': 201,\n             'n_jobs': 32,\n             'seed': 114,\n             'metric':  'auc',  # trial.suggest_categorical('metric', ['auc', 'binary_logloss', ]), #'auc',\n             'learning_rate': 0.01,\n             'lambda_l1': 4.8179519901479875,\n             'lambda_l2': 7.805340795613767,\n             'num_leaves': 43,\n             'feature_fraction': 0.48605812738261606, \n              'min_child_samples': 14, \n               'bagging_fraction': 0.7692769160924116}\n\ndef f1_metric(pred, dmat):\n    itr, sc = np.load('/tmp/eval.npy')\n    if itr < (2500 if not DEBUG else 100):\n        sc = itr * 1.0e-5\n    elif itr % 50 == 0:\n        res = f1_group(dmat.get_label().astype(np.int), pred, dmat.get_group())\n        sc = np.mean(res)\n    np.save('/tmp/eval', [itr + 1, sc])\n    return 'f1', sc, True\n\nlist_clf = []\n\nfor fold_id in tqdm(range(2)):\n    df_feat = df_feat_all[df_feat_all['fold_id'] != fold_id].sort_values(['idx', 'idx2']).reset_index(drop=True)\n    trn_x = df_feat.drop(['label', 'fold_id', 'fold', 'label', 'idx', 'idx2',  'weight',\n                          'group'], axis=1).fillna(0).astype(np.float32)  # .values\n    trn_y = df_feat['label'].values\n    trn_w = 1. / df_feat['weight'].values\n    trn_g = df_feat.groupby('idx').apply(lambda row: row.index.shape[0]).values\n\n    df_feat = df_feat_all[df_feat_all['fold_id'] == fold_id].sort_values(['idx', 'idx2']).reset_index(drop=True)\n    val_x = df_feat.drop(['label', 'fold_id', 'fold', 'label', 'idx', 'idx2',  'weight',\n                          'group'], axis=1).fillna(0).astype(np.float32)  # .values\n    val_y = df_feat['label'].values\n    val_w = 1. / df_feat['weight'].values\n    val_g = df_feat.groupby('idx').apply(lambda row: row.index.shape[0]).values\n\n    dtrain = lgb.Dataset(trn_x, label=trn_y, weight=trn_w, group=trn_g)\n    eval_data = lgb.Dataset(val_x, label=val_y, weight=val_w, group=val_g)\n\n    param['metric'] = \"None\"\n    np.save('/tmp/eval', [0, 0])\n    best = lgb.train(param,\n                          dtrain,\n                          valid_sets=eval_data,\n                          early_stopping_rounds=201,\n                          feval=f1_metric,\n                          verbose_eval=50\n                          )\n    list_clf.append(best)\n\n\nwith open('list_clf_tune_balanced.pkl', 'wb') as f:\n    pickle.dump(list_clf, f, -1)\n    \nx = df_feat_all.drop(['label', 'fold_id', 'fold', 'label', 'idx', 'idx2',\n                      'weight', 'group'], axis=1).fillna(0).astype(np.float32)\ny = df_feat_all['label'].values\nw = 1. / df_feat_all['weight'].values\ndtrain = lgb.Dataset(x, label=y, weight=w)\nbest_param = dict(param)\nbest_param['num_iterations'] = int(np.mean([c.best_iteration for c in list_clf]) * 1.1)\nbest_param.pop('early_stopping_round')\nbest = lgb.train(best_param,\n                      dtrain,\n                      )\nwith open('all_data_clf.pkl', 'wb') as f:\n    pickle.dump(best, f, -1)\n    \n\nbest.save_model('all_data_clf_norm.lgb')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict ","metadata":{}},{"cell_type":"code","source":"list_pred_idx = [[] for _ in range(df_test.shape[0])]\nlist_pred_val = [[] for _ in range(df_test.shape[0])]\n\nfor fold_id in range(2):\n    #indices = df_test[df_test['fold'] == fold_id].index.values\n    df = df_feat_all[df_feat_all['fold'] == fold_id].reset_index(drop=True)\n    clf = list_clf[fold_id]\n    col = clf.feature_name()\n    feat = df[col]\n    prob = clf.predict(feat[col])\n\n    for i, (j, j2) in enumerate(df[['idx', 'idx2']].values):\n        list_pred_idx[j].append(j2)\n        list_pred_val[j].append(prob[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"map_result = {}\n\n\n@numba.jit\ndef calc_f1(sc, total_cnt):\n    #sc = targets[i] == row\n    tp = sc.sum()\n    fp = len(sc) - tp\n    fn = total_cnt - tp\n    f1 = (tp) / (tp + 0.5 * (fp + fn))\n    return f1\n\n\ntargets = df_test.label.values\nmap_cnt = Counter(targets)\nmap_id2label = dict(tuple(x) for x in df_test[['posting_id', 'label']].values)\n\ntk0 = tqdm(np.arange(0.3, 0.5, 0.02))\nfor avg_threshold in tk0:\n    list_pred_id = [[] for _ in range(df_test.shape[0])]\n\n    for i in range(df_test.shape[0]):\n        pred_id = []\n\n        idx = np.array(list_pred_idx[i])\n        prob = np.array(list_pred_val[i])\n\n        pred_id += idx[prob > avg_threshold].tolist()\n        list_pred_id[i] = pred_id\n\n    posting_ids = df_test['posting_id'].values\n\n    list_res = []\n    for i in (range(df_test.shape[0])):\n        row = posting_ids[list_pred_id[i]]\n        list_res.append(dict(posting_id=posting_ids[i],\n                             matches=row)\n                        )\n\n    for fold_id in range(2):\n        indices = df_test[df_test['fold'] == fold_id].index.values\n\n        list_sc = []\n        for i in indices:  # range(df_test.shape[0]):\n            row = [map_id2label[j] for j in list_res[i]['matches']]\n            sc = targets[i] == row\n            f1 = calc_f1(sc, map_cnt[targets[i]])\n            list_sc.append(f1)\n\n        map_result[avg_threshold, fold_id] = np.mean(list_sc)\n    df_res = pd.pivot_table(pd.Series(map_result).to_frame(name='score').reset_index(),\n                            index='level_0', columns='level_1', values='score')\n    tmp = df_res.mean(axis=1).to_frame()\n\nprint(df_res.index.values[df_res.values.argmax(axis=0)])\ntmp['rank'] = tmp[0].rank(ascending=False)\nprint(tmp[tmp['rank'] < 6])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best threshold is', float(tmp.loc[tmp['rank'] == 1, 0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}