{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training using simCLR in Tensorflow - Training Script only.\n\nJust a simple implementation of simCLR in Tensorflow. \n\nThis code does work although it may give you an OOM error in Kaggle Kernels.\n\nShould run it in a VM.\n\nFor more information on simCLR, visit [here](https://github.com/google-research/simclr).","metadata":{}},{"cell_type":"markdown","source":"Huge credits to ragnar's Tensorflow script: https://www.kaggle.com/ragnar123/unsupervised-baseline-arcface\n\nAll other credits go to the above mentioned Github Repository. I just stiched things together.","metadata":{}},{"cell_type":"code","source":"! pip install tensorflow_addons\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB4, EfficientNetB5, EfficientNetB7\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, train_test_split\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom tqdm.notebook import tqdm\nfrom kaggle_datasets import KaggleDatasets\n\nimport sys\nsys.path.append('../input/simclr-tf-utils-scripts')\n\n\nimport helpers\nfrom losses import _dot_simililarity_dim1 as sim_func_dim1, _dot_simililarity_dim2 as sim_func_dim2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_PATH = KaggleDatasets().get_gcs_path('shopeetfrecords512stratifiedolder')\n\n# Configuration\nEPOCHS = 25\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [512, 512]\n# Seed\nSEED = 42\n# Learning rate\nLR = 0.0001\n# Verbosity\nVERBOSE = 2\n# Number of classes\nN_CLASSES = 11011\n# Number of folds\nFOLDS = 5\n\n# Training filenames directory\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get our f1 score\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\n# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \ndef arcface_format(posting_id, image, label_group, matches):\n    return posting_id, {'inp1': image, 'inp2': label_group}, label_group, matches\n\n# Data augmentation function\ndef data_augment(posting_id, image, label_group, matches):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.70, 1.30)\n    image = tf.image.random_contrast(image, 0.80, 1.20)\n    image = tf.image.random_brightness(image, 0.10)\n    return posting_id, image, label_group, matches\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# This function parse our images and also get the target variable\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"posting_id\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label_group\": tf.io.FixedLenFeature([], tf.int64),\n        \"matches\": tf.io.FixedLenFeature([], tf.string)\n    }\n\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    posting_id = example['posting_id']\n    image = decode_image(example['image'])\n#     label_group = tf.one_hot(tf.cast(example['label_group'], tf.int32), depth = N_CLASSES)\n    label_group = tf.cast(example['label_group'], tf.int32)\n    matches = example['matches']\n    return posting_id, image, label_group, matches\n\n# This function loads TF Records and parse them into tensors\ndef load_dataset(filenames, ordered = False):\n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO)\n    return dataset\n\n# This function is to get our training tensors\ndef get_training_dataset(filenames, ordered = False):\n    dataset = load_dataset(filenames, ordered = ordered)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# This function is to get our validation tensors\ndef get_validation_dataset(filenames, ordered = True):\n    dataset = load_dataset(filenames, ordered = ordered)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) \n    return dataset\n\n# Function to count how many photos we have in\ndef count_data_items(filenames):\n    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nprint(f'Dataset: {NUM_TRAINING_IMAGES} training images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Augmentation utilities (differs from the original implementation)\n# Referred from: https://arxiv.org/pdf/2002.05709.pdf (Appendxi A \n# corresponding GitHub: https://github.com/google-research/simclr/)\n\nclass CustomAugment(object):\n    def __call__(self, sample):        \n        # Random flips\n        sample = self._random_apply(tf.image.flip_left_right, sample, p=0.5)\n        \n        # Randomly apply transformation (color distortions) with probability p.\n        sample = self._random_apply(self._color_jitter, sample, p=0.8)\n        sample = self._random_apply(self._color_drop, sample, p=0.2)\n\n        return sample\n\n    def _color_jitter(self, x, s=1):\n        # one can also shuffle the order of following augmentations\n        # each time they are applied.\n        x = tf.image.random_brightness(x, max_delta=0.8*s)\n        x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n        x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n        x = tf.image.random_hue(x, max_delta=0.2*s)\n        x = tf.clip_by_value(x, 0, 1)\n        return x\n    \n    def _color_drop(self, x):\n        x = tf.image.rgb_to_grayscale(x)\n        x = tf.tile(x, [1, 1, 1, 3])\n        return x\n    \n    def _random_apply(self, func, x, p):\n        return tf.cond(\n          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n                  tf.cast(p, tf.float32)),\n          lambda: func(x),\n          lambda: x)\n\n# Build the augmentation pipeline\ndata_augmentation = tf.keras.models.Sequential([tf.keras.layers.Lambda(CustomAugment())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Architecture utils\ndef get_resnet_simclr(hidden_1, hidden_2, hidden_3):\n    base_model = tf.keras.applications.ResNet50(include_top=False, weights=None, input_shape=(512, 512, 3))\n    base_model.trainable = True\n    inputs = tf.keras.layers.Input((512, 512, 3))\n    h = base_model(inputs, training=True)\n    h = tf.keras.layers.GlobalAveragePooling2D()(h)\n\n    projection_1 = tf.keras.layers.Dense(hidden_1)(h)\n    projection_1 = tf.keras.layers.Activation(\"relu\")(projection_1)\n    projection_2 = tf.keras.layers.Dense(hidden_2)(projection_1)\n    projection_2 = tf.keras.layers.Activation(\"relu\")(projection_2)\n    projection_3 = tf.keras.layers.Dense(hidden_3)(projection_2)\n\n    resnet_simclr = tf.keras.Model(inputs, projection_3)\n\n    return resnet_simclr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative_mask = helpers.get_negative_mask(BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(xis, xjs, model, optimizer, criterion, temperature):\n    with tf.GradientTape() as tape:\n        zis = model(xis)\n        zjs = model(xjs)\n\n        # normalize projection feature vectors\n        zis = tf.math.l2_normalize(zis, axis=1)\n        zjs = tf.math.l2_normalize(zjs, axis=1)\n\n        l_pos = sim_func_dim1(zis, zjs)\n        l_pos = tf.reshape(l_pos, (BATCH_SIZE, 1))\n        l_pos /= temperature\n\n        negatives = tf.concat([zjs, zis], axis=0)\n\n        loss = 0\n\n        for positives in [zis, zjs]:\n            l_neg = sim_func_dim2(positives, negatives)\n\n            labels = tf.zeros(BATCH_SIZE, dtype=tf.int32)\n\n            l_neg = tf.boolean_mask(l_neg, negative_mask)\n            l_neg = tf.reshape(l_neg, (BATCH_SIZE, -1))\n            l_neg /= temperature\n\n            logits = tf.concat([l_pos, l_neg], axis=1) \n            loss += criterion(y_pred=logits, y_true=labels)\n\n        loss = loss / (2 * BATCH_SIZE)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_simclr(model, dataset, optimizer, criterion,\n                 temperature=0.1, epochs=100):\n    step_wise_loss = []\n    epoch_wise_loss = []\n\n    for epoch in tqdm(range(epochs)):\n        for image_batch in dataset:\n            a = data_augmentation(image_batch)\n            b = data_augmentation(image_batch)\n\n            loss = train_step(a, b, model, optimizer, criterion, temperature)\n            step_wise_loss.append(loss)\n\n        epoch_wise_loss.append(np.mean(step_wise_loss))\n        wandb.log({\"nt_xentloss\": np.mean(step_wise_loss)})\n        \n        if epoch % 10 == 0:\n            print(\"epoch: {} loss: {:.3f}\".format(epoch + 1, np.mean(step_wise_loss)))\n\n    return epoch_wise_loss, model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the dataset\ntrain, valid = train_test_split(TRAINING_FILENAMES, shuffle = True, random_state = SEED)\ntrain_dataset = get_training_dataset(train, ordered = False)\ntrain_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\nval_dataset = get_validation_dataset(valid, ordered = True)\nval_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\nSTEPS_PER_EPOCH = count_data_items(train) // BATCH_SIZE\nK.clear_session()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n                                                          reduction=tf.keras.losses.Reduction.SUM)\ndecay_steps = 1000\nlr_decayed_fn = tf.keras.experimental.CosineDecay(\n    initial_learning_rate=0.1, decay_steps=decay_steps)\noptimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n\nresnet_simclr_2 = get_resnet_simclr(256, 128, 50)\n\nepoch_wise_loss, resnet_simclr  = train_simclr(resnet_simclr_2, train_dataset, optimizer, criterion,\n                 temperature=0.1, epochs=10)\n\nwith plt.xkcd():\n    plt.plot(epoch_wise_loss)\n    plt.title(\"tau = 0.1, h1 = 256, h2 = 128, h3 = 50\")\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}