{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nLIMIT = 1\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 1024 * LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n    print('then RAPIDS can use %iGB GPU RAM'%(16 - LIMIT))\n  except RuntimeError as e:\n    print(e)\nelse:\n    print(\"GPU is not running\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEBUG = False\nif DEBUG:\n    df = df.sample(n = 2000).reset_index(drop = True)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\ngroups = df[\"label_group\"].values\ngkf = GroupKFold(n_splits = 5)\nfor train_idx, valid_idx in gkf.split(df, groups, groups):\n    train = df.iloc[train_idx, :].copy()\n    valid = df.iloc[valid_idx, :].copy()\nprint(train.shape, valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Images"},{"metadata":{},"cell_type":"markdown","source":"# 3. Autoencoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use(\"seaborn-white\")\nimport tensorflow as tf\n\ndef train_preprocess(path, _):\n    path = \"../input/shopee-product-matching/train_images\" + \"/\" + path\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    image = tf.image.resize(image, [256, 256])\n    image = tf.cast(image, tf.float32) / 255.0\n    return image, image\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((train[\"image\"].values, train[\"label_group\"].values))\nvalid_ds = tf.data.Dataset.from_tensor_slices((valid[\"image\"].values, valid[\"label_group\"].values))\ntrain_ds = train_ds.map(train_preprocess)\nvalid_ds = valid_ds.map(train_preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image, _ = next(iter(train_ds))\nplt.imshow(image)\nplt.show()\nprint(image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image, _ = next(iter(valid_ds))\nplt.imshow(image)\nplt.show()\nprint(image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = train_ds.batch(64).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\nvalid_ds = valid_ds.batch(64 * 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\n\ndef autoencoder(input_shape):\n    inputs = L.Input(shape = input_shape)\n    encoded = L.Conv2D(filters = 16, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(inputs)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    encoded = L.Conv2D(filters = 32, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    encoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    \"\"\"\n    encoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    encoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    encoded = L.Conv2D(filters = 128, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    encoded = L.BatchNormalization()(encoded)\n    encoded = L.MaxPooling2D(pool_size = (2, 2), padding = \"same\")(encoded)\n    \"\"\"\n\n#    features = encoded\n    \n    \"\"\"\n    decoded = L.Conv2D(filters = 128, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(decoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(decoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    \"\"\"\n    decoded = L.Conv2D(filters = 64, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(encoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 32, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(decoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 16, kernel_size = (3, 3), padding = \"same\", activation = \"relu\")(decoded)\n    decoded = L.UpSampling2D(size = (2, 2))(decoded)\n    decoded = L.Conv2D(filters = 3, kernel_size = (3, 3), padding = \"same\", activation = \"sigmoid\")(decoded)\n    \n    encoder = M.Model(inputs = inputs, outputs = encoded)\n    autoencoder = M.Model(inputs = inputs, outputs = decoded)\n    autoencoder.compile(optimizer = \"Adam\", loss = \"binary_crossentropy\")\n    return autoencoder, encoder\n\ntf.keras.backend.clear_session()\nautoencoder, encoder = autoencoder((256, 256, 3))\nautoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING = False\n\nif TRAINING:\n    history = autoencoder.fit(\n        train_ds, validation_data = valid_ds, epochs = 1,\n        callbacks = [\n            tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 3, mode = \"min\"),\n            tf.keras.callbacks.ModelCheckpoint(filepath = \"autoencoder.h5\", monitor = \"val_loss\", mode = \"min\", save_best_only = True, save_weights_only = True)\n        ]\n    )\nelse:\n    autoencoder.load_weights(\"../input/shoppee-autoencoder0324/autoencoder.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = next(iter(valid_ds))[0][0]\nplt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(autoencoder.predict(next(iter(valid_ds))[0])[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm, trange\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    import cuml\n    from cuml.neighbors import NearestNeighbors\nelse:\n    from sklearn.neighbors import NearestNeighbors\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"tmp = valid.groupby(\"label_group\")[\"posting_id\"].agg(\"unique\").to_dict()\nvalid[\"target\"] = valid[\"label_group\"].map(tmp)\nvalid[\"oof\"] = valid.apply(lambda x: np.unique(x[\"image_preds\"]), axis = 1)\nvalid.head()"},{"metadata":{"trusted":true},"cell_type":"raw","source":"def metric(col):\n    def f1score(row):\n        n = len(np.intersect1d(row[\"target\"], row[col]))\n        return 2*n / (len(row[\"target\"]) + len(row[col]))\n    return f1score\n\nscore = valid.apply(metric(\"oof\"), axis = 1).mean()\nprint(f\"CV Score = {score}\")"},{"metadata":{},"cell_type":"markdown","source":"# INFERENCE"},{"metadata":{"trusted":true},"cell_type":"code","source":"CV = True\n\ntest = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\nif test.shape[0] > 3:\n    CV = False\n\nif CV:\n    test = valid.copy()\n    DIR = \"../input/shopee-product-matching/train_images\"\nelse:\n    DIR = \"../input/shopee-product-matching/test_images\"\nprint(test.shape, DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CHUNK = 1024\nCHUNK_SIZE = test.shape[0] // CHUNK\nif test.shape[0] % CHUNK != 0:\n    CHUNK_SIZE += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_preprocess(path):\n    path = DIR + \"/\" + path\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    image = tf.image.resize(image, [256, 256])\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\ntest[\"image_preds\"] = \"\"\nKNN = 50\nknn = NearestNeighbors(n_neighbors = KNN)\n\nfor chunk in range(CHUNK_SIZE):\n    a = chunk * CHUNK\n    b = min((chunk + 1) * CHUNK, test.shape[0])\n    \n    test_ds = tf.data.Dataset.from_tensor_slices((test.iloc[a : b][\"image\"].values))\n    test_ds = test_ds.map(test_preprocess)\n    test_ds = test_ds.batch(64 * 2)\n\n    test_encoded = []\n    for image in tqdm(test_ds):\n        batch_size = image.shape[0]\n        encoded = encoder.predict(image)\n        test_encoded.append(encoded.reshape(batch_size, -1))\n    test_encoded = np.concatenate(test_encoded, axis = 0)\n    \n    knn.fit(test_encoded)\n    distances, indices = knn.kneighbors(test_encoded)\n    del test_encoded; gc.collect()\n\n    preds = []\n    for i in range(b - a):\n        idx = np.where(distances[i] < 5.0)[0]\n        ids = indices[i, idx]\n        preds.append(test.iloc[a: b].iloc[ids][\"posting_id\"].values)\n\n    del distances, indices; gc.collect()\n    test.iloc[a : b,][\"image_preds\"] = preds\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"matches\"] = test.apply(lambda x: \" \".join(np.unique(x[\"image_preds\"])) , axis = 1)\nsubmit = test[[\"posting_id\", \"matches\"]].copy()\nsubmit.to_csv(\"submission.csv\", index = False)\nsubmit","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}