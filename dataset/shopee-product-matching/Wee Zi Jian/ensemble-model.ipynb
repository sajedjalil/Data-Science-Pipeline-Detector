{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Rapids\nimport sys\n!cp ../input/rapids/rapids.0.18.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install BERT\n!pip install ../input/bertfortf2/bert/py-params-0.10.2/py-params-0.10.2\n!pip install ../input/bertfortf2/bert/params-flow-0.8.2/params-flow-0.8.2\n!pip install ../input/bertfortf2/bert/bert-for-tf2-0.14.9/bert-for-tf2-0.14.9","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport os\nimport gc\nimport nltk\nimport cuml, cupy\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport bert\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nfrom tensorflow import keras\nfrom PIL import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 8GB OF GPU RAM\n# SO THAT WE HAVE 8GB RAM FOR RAPIDS\nLIMIT = 8\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configure if we are computing CV on train data or making submission on test data\nCOMPUTE_CV = True\n\n# If test size is > 3, configure for submission\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\n\nif len(test) > 3:\n    COMPUTE_CV = False\n    del test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\nif COMPUTE_CV:\n    # If we are computing CV, use train dataset\n    df = pd.read_csv('../input/shopee-product-matching/train.csv')\n    \n    # Create dictionary of label groups (key) and posting IDs (values)\n    label_dict = df.groupby('label_group')['posting_id'].unique().to_dict()\n\n    # Create column of matching products\n    df['matches'] = df['label_group'].map(label_dict)\n    \nelse:\n    df = pd.read_csv('../input/shopee-product-matching/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create directory path to images\nif COMPUTE_CV:\n    image_dir = '../input/shopee-product-matching/train_images'\nelse:\n    image_dir = '../input/shopee-product-matching/test_images'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Embeddings","metadata":{}},{"cell_type":"code","source":"# Import re-trained EfficientNetB4\nmodel = keras.models.load_model('../input/efficientnetb4model8/model_8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set image size for EfficientNetB4 input\nim_size = 380\n\n# Set batch size\nbatch = 8\n\n# As the dataset is large, we will run the modelling in chunks\nchunk_size = 5000\nchunks = np.arange(np.ceil(len(df) / chunk_size))\n\n# Set image paths of all images\nimage_paths = image_dir + '/' + df['image']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create function to pre-process images\ndef process_image(image_file_path):\n    # Read and decode image from file path\n    image = tf.io.read_file(image_file_path)\n    image = tf.image.decode_jpeg(image, channels = 3)\n\n    # Resize image\n    image = tf.image.resize(image, (im_size,im_size))\n\n    # Scale image vector\n    image = tf.cast(image, tf.float32) / 255.0\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create tensorflow dataset from image paths\ndef get_data(image_paths):\n    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n\n    # Process dataset with the image processing function created above. Set parallel calls to autotune\n    dataset = dataset.map(process_image, num_parallel_calls = tf.data.AUTOTUNE)\n\n    # Set batch size\n    dataset = dataset.batch(batch_size = batch)\n\n    # Set prefetch to autotune\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate image embeddings from EfficientNetB4 model in chunks\n# Initialize embeddings list\nembeddings = []\n\n# Iterate through chunks\nfor i in chunks:\n    # Start and end index\n    start = int(i * chunk_size)\n    end = int((i + 1) * chunk_size)\n\n    # Get image dataset\n    image_dataset = get_data(image_paths[start:end])\n\n    # Generate embeddings\n    chunk_embeddings = model.predict(image_dataset)\n\n    # Append to embeddings list\n    embeddings.append(chunk_embeddings)\n\n    # Print status\n    print(f'Chunk {i} completed')\n\nimage_embeddings = np.concatenate(embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete unused variables\ndel model\ndel image paths\ndel embeddings\ndel image_dataset\ndel chunk_embeddings\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_embeddings.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF Embeddings","metadata":{}},{"cell_type":"code","source":"# Create stop words\nstop_words = nltk.corpus.stopwords.words('english') + \\\n             nltk.corpus.stopwords.words('indonesian') + \\\n             [# Sales words:\n                'free', 'gift', 'give', 'get', 'ready', 'stock', 'stocks', 'stok',\n                'ori', 'original', 'official', 'new', 'latest',\n                'import', 'low', 'price', 'cheap', 'vip', 'discount', 'warranty',\n                'promo', 'promotion', 'buy', 'buyer', 'shop', 'shopper', 'shopping',\n                'bigsale', 'sale', 'sell', 'seller', 'resell', 'reseller',\n                'all', 'any', 'full', 'include', 'includes', 'inclusive', 'tax',\n    \n                # Units\n                'pieces', 'piece', 'pcs', 'pc', 'box', 'boxes', 'pack', 'packs', 'packet', 'packets', 'paket', 'package',\n                'set', 'sets', 'size', 'roll', 'rolls', 'sachet', 'sachets'\n                \n                # Dimensions\n                'ml', 'l', 'litre', 'liter', 'g', 'gr', 'gram', 'kg', 'kilo', 'kilogram',\n                'mm', 'cm', 'm', 'meter', 'metre', 'yard', 'inch', 'x',\n    \n                # Miscellaneous alphabets\n                'c', 'xe', 'f', 'b', 'v', 'xa',\n                \n                # Location words:\n                'shopee', 'indonesia', 'indonesian', 'indo', 'id', 'jakarta', 'local', 'lokal',\n    \n                # English descriptors:\n                'fashion', 'colour', 'color', 'design',\n                'plus', 'pro', 'mini', 'premium', 'pro', 'super', 'extra', 'big', 'small',\n                \n                # Indonesian descriptors:\n                'bpom', 'muat', 'cod', 'murah', 'isi', 'warna', 'pajak', 'garansi', 'beli', 'gratis',\n                'terbaru', 'harga', 'resmi',\n]\n\nstop_words = list(set(stop_words))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create function for generating tokens from titles\ndef process_tokens(title, stop_words, tokenizer):\n    words = tokenizer.tokenize(title.lower())\n    return ' '.join([word for word in words if word not in stop_words])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = nltk.tokenize.RegexpTokenizer('[a-zA-Z0-9]+')\ntitle_tokens = df['title'].map(lambda x: process_tokens(x, stop_words, tokenizer)).to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tvec = TfidfVectorizer()\ntfidf_embeddings = tvec.fit_transform(title_tokens)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_embeddings.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LaBSE Embeddings","metadata":{}},{"cell_type":"code","source":"def get_model(model_url, max_seq_length):\n    labse_layer = hub.KerasLayer(model_url, trainable=True)\n\n    # Define input.\n    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                             name=\"input_word_ids\")\n    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                         name=\"input_mask\")\n    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                          name=\"segment_ids\")\n\n    # LaBSE layer.\n    pooled_output,  _ = labse_layer([input_word_ids, input_mask, segment_ids])\n\n    # The embedding is l2 normalized.\n    pooled_output = tf.keras.layers.Lambda(\n          lambda x: tf.nn.l2_normalize(x, axis=1))(pooled_output)\n\n    # Define model.\n    return tf.keras.Model(\n            inputs=[input_word_ids, input_mask, segment_ids],\n            outputs=pooled_output), labse_layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 64","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labse_model, labse_layer = get_model(model_url=\"../input/labse-1\", max_seq_length=max_seq_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_file = labse_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = labse_layer.resolved_object.do_lower_case.numpy()\ntokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n\ndef create_input(input_strings, tokenizer, max_seq_length):\n    \n    input_ids_all, input_mask_all, segment_ids_all = [], [], []\n    for input_string in input_strings:\n        \n        # Tokenize input.\n        input_tokens = [\"[CLS]\"] + tokenizer.tokenize(input_string) + [\"[SEP]\"]\n        input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n        sequence_length = min(len(input_ids), max_seq_length)\n\n        # Padding or truncation.\n        if len(input_ids) >= max_seq_length:\n            input_ids = input_ids[:max_seq_length]\n        else:\n            input_ids = input_ids + [0] * (max_seq_length - len(input_ids))\n\n        input_mask = [1] * sequence_length + [0] * (max_seq_length - sequence_length)\n\n        input_ids_all.append(input_ids)\n        input_mask_all.append(input_mask)\n        segment_ids_all.append([0] * max_seq_length)\n\n    return np.array(input_ids_all), np.array(input_mask_all), np.array(segment_ids_all)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode(input_text):\n    input_ids, input_mask, segment_ids = create_input(input_text, tokenizer, max_seq_length)\n    return labse_model([input_ids, input_mask, segment_ids])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As the dataset is large, we will run the embedding in chunks\nchunk_size = 2000\nchunks = np.arange(np.ceil(len(df) / chunk_size))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate text embeddings from LaBSE model in chunks for tokens set 2\n# Initialize embeddings list\nembeddings = []\n\n# Iterate through chunks\nfor i in chunks:\n    # Start and end index\n    start = int(i * chunk_size)\n    end = int((i + 1) * chunk_size)\n\n    # Get tokens\n    tokens = title_tokens[start:end]\n\n    # Generate embeddings\n    text_embeddings = encode(tokens)\n\n    # Append to embeddings list\n    embeddings.append(text_embeddings)\n\n    # Print status\n    print(f'Chunk {i} completed')\n\ntext_labse_embeddings = np.concatenate(embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete unused variables\ndel labse_model\ndel labse_layer\ndel embeddings\ndel tokens\ndel title_tokens\ndel text_embeddings\ndel tokenizer\ndel vocab_file\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_labse_embeddings.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Predictions","metadata":{}},{"cell_type":"code","source":"combined_embeddings = np.concatenate((image_embeddings,text_labse_embeddings), axis=1)\nss = StandardScaler(with_mean=False)\ncombined_embeddings_scaled = ss.fit_transform(combined_embeddings)\ndel combined_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_model = NearestNeighbors(n_neighbors=51, metric = 'cosine')\nimage_model.fit(image_embeddings)\nimage_distances, image_indices = image_model.kneighbors(image_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_model = NearestNeighbors(n_neighbors=51, metric = 'cosine')\ntfidf_model.fit(tfidf_embeddings)\ntfidf_distances, tfidf_indices = tfidf_model.kneighbors(tfidf_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_model = NearestNeighbors(n_neighbors=51, metric = 'cosine')\ncombined_model.fit(combined_embeddings_scaled)\ncombined_distances, combined_indices = combined_model.kneighbors(combined_embeddings_scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del image_model, tfidf_model, combined_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create function to predict based on ratio of distances\ndef predict(df, image_distances, image_indices, tfidf_distances, tfidf_indices,\n            combined_distances, combined_indices, image_ratio, tfidf_ratio, combined_ratio):\n    \n    preds = []\n\n    for i in range(df.shape[0]):\n        \n        # Set thresholds based on ratios of average distances\n        image_threshold = image_ratio * np.mean(image_distances[i])\n        image_idx = image_indices[i][np.where(image_distances[i] <= image_threshold)]\n        image_ids = df['posting_id'].iloc[image_idx].values\n        \n        tfidf_threshold = tfidf_ratio * np.mean(tfidf_distances[i])\n        tfidf_idx = tfidf_indices[i][np.where(tfidf_distances[i] <= tfidf_threshold)]\n        tfidf_ids = df['posting_id'].iloc[tfidf_idx].values\n        \n        combined_threshold = combined_ratio * np.mean(combined_distances[i])\n        combined_idx = combined_indices[i][np.where(combined_distances[i] <= combined_threshold)]\n        combined_ids = df['posting_id'].iloc[combined_idx].values      \n        \n        preds.append(np.union1d(combined_ids, np.union1d(image_ids, tfidf_ids)))\n\n    return preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ratio = 0.5\ntfidf_ratio = 0.5\ncombined_ratio = 0.7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = predict(df, image_distances, image_indices, tfidf_distances, tfidf_indices,\n                combined_distances, combined_indices, image_ratio, tfidf_ratio, combined_ratio)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Score / Submit","metadata":{}},{"cell_type":"code","source":"# Create function to score predictions based on actual matches\ndef scores(matches, preds):\n    result = []\n    for i in range(len(matches)):\n        n = len(np.intersect1d(matches[i], preds[i]))\n        score = 2*n / (len(matches[i]) + len(preds[i]))\n        result.append(score)\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    matches = list(df['matches'].to_numpy())\n    print(f'Average combined score on train data: {np.mean(scores(matches, preds))}')\n    print('')\n    print('Saving dummy submission file')\n    dummy = pd.read_csv('../input/shopee-product-matching/test.csv')\n    dummy['matches'] = dummy['posting_id']\n    dummy[['posting_id','matches']].to_csv('submission.csv',index=False)\n    \nelse:\n    df['matches'] = preds\n    df['matches'] = df['matches'].map(lambda x: ' '.join(x))\n    df[['posting_id','matches']].to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Notebook references\n\n- https://www.kaggle.com/cdeotte/part-2-rapids-tfidfvectorizer-cv-0-700","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}