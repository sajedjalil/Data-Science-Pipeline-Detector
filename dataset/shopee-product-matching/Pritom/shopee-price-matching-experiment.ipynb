{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip download efficientnet ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/modules/Keras_Applications-1.0.8-py3-none-any.whl\n!pip install ../input/modules/efficientnet-1.1.1-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport math\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom scipy import spatial\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nEPOCHS = 12\nBATCH_SIZE = 8\nIMAGE_SIZE = [384, 384]\n# Seed\nSEED = 42\n# Learning rate\nLR = 0.001\n# Verbosity\nVERBOSE = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to read and preprocess our data\ndef preprocess():\n    # Read train and test csv\n    train = pd.read_csv('../input/shopee-product-matching/train.csv')\n    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n   \n    \n    # Drop duplicates images to avoid leakage (dont know if this is correct)\n    train.drop_duplicates(subset = ['image'], inplace = True)\n    train.reset_index(drop = True, inplace = True)\n    label_mapper = dict(zip(train['label_group'].unique(), np.arange(len(train['label_group'].unique()))))\n    label_mapper_inv = dict(zip(np.arange(len(train['label_group'].unique())), train['label_group'].unique()))\n    train['label_group'] = train['label_group'].map(label_mapper)\n    # Number of classes\n    N_CLASSES = train['label_group'].nunique()\n    return test, N_CLASSES\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# Function to read our test image and return image\ndef read_image_test(image):\n    image = tf.io.read_file(image)\n    image = decode_image(image)\n    return image\n\ndef get_test_dataset(image):\n    dataset = tf.data.Dataset.from_tensor_slices(image)\n    dataset = dataset.map(read_image_test, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# Function to create our EfficientNetB0 model\ndef get_model():\n        \n    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3))\n    x = efn.EfficientNetB3(include_top = False, weights = None)(inp) #EfficientNetB0-> EfficientNetB3\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n    output = tf.keras.layers.Dense(N_CLASSES, activation = 'softmax')(x)\n\n    model = tf.keras.models.Model(inputs = [inp], outputs = [output])\n\n    opt = tf.keras.optimizers.Adam(learning_rate = LR)\n\n    model.compile(\n        optimizer = opt,\n        loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n    )\n\n    return model\n\ndef inference(test):\n    print('\\n')\n    print('-'*50)\n    model = get_model()\n    model.load_weights('../input/weight2/EfficientNetB3_128_42.h5') #loading the trained model\n    model = tf.keras.models.Model(inputs = model.input, outputs = model.layers[-2].output)\n    test_image = '../input/shopee-product-matching/test_images/' + test['image']\n    test_dataset = get_test_dataset(test_image)\n    # Predict the test images and get embeddings\n    embeddings = model.predict(test_dataset)\n\n    # Iterate over each test image and use cosine distance to find similar images\n    predictions = []\n    for test_index in tqdm(range(embeddings.shape[0])):\n        distances = spatial.distance.cdist(\n            embeddings[np.newaxis, test_index, :], embeddings, 'cosine')[0]\n        # Only get small distances\n        TOP = len(distances[distances <= .11])\n        top_k = list(np.argsort(distances)[:TOP])\n        predictions.append(' '.join(test['posting_id'].iloc[top_k].values))\n        \n    submission = pd.DataFrame({'posting_id' :test['posting_id'], 'matches': predictions})\n    return submission\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test, N_CLASSES = preprocess()\nsubmission = inference(test)\n# Save predictions\nsubmission.to_csv('/kaggle/working/submission.csv', index = False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Important Comment\n- in version 14 Top distance <=0.05\n- in version 14.1 Top distance <=0.11 like previous accepted versions\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}