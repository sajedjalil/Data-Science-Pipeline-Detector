{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RAPIDS cuML TfidfVectorizer and KNN to find similar Text and Images\nIn this notebook we use RAPIDS cuML's TfidfVectorizer and cuML's KNN to find items with similar titles and items with similar images. First we use RAPIDS cuML TfidfVectorizer to extract text embeddings of each item's title and then compare the embeddings using RAPIDS cuML KNN. Next we extract image embeddings of each item with EffNetB0 and compare them using RAPIDS cuML KNN.","metadata":{}},{"cell_type":"markdown","source":"# Load Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd, gc\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nprint('RAPIDS',cuml.__version__)\nprint('TF',tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 1GB OF GPU RAM\n# SO THAT WE HAVE 15GB RAM FOR RAPIDS\nLIMIT = 1\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Train Data\nFirst we load the train data and create a target column of ground truths to help us compute CV score. Note how the variable COMPUTE_CV will change to False when we submit this notebook but it is True now because you are reading a commit notebook.","metadata":{}},{"cell_type":"code","source":"COMPUTE_CV = True\n\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n    \ntrain = pd.read_csv('../input/shopee-product-matching/train.csv')\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\nprint('train shape is', train.shape )\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display Random Items from Train Data","metadata":{}},{"cell_type":"code","source":"BASE = '../input/shopee-product-matching/train_images/'\n\ndef displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):\n    for k in range(ROWS):\n        plt.figure(figsize=(20,5))\n        for j in range(COLS):\n            if random: row = np.random.randint(0,len(train))\n            else: row = COLS*k + j\n            name = train.iloc[row,1]\n            title = train.iloc[row,3]\n            title_with_return = \"\"\n            for i,ch in enumerate(title):\n                title_with_return += ch\n                if (i!=0)&(i%20==0): title_with_return += '\\n'\n            img = cv2.imread(path+name)\n            plt.subplot(1,COLS,j+1)\n            plt.title(title_with_return)\n            plt.axis('off')\n            plt.imshow(img)\n        plt.show()\n        \ndisplayDF(train,random=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display Duplicated Items from Train Data\nUsing the column label_group which is the ground truth, we can display examples of duplicated items.","metadata":{}},{"cell_type":"code","source":"groups = train.label_group.value_counts()\nplt.figure(figsize=(20,5))\nplt.plot(np.arange(len(groups)),groups.values)\nplt.ylabel('Duplicate Count',size=14)\nplt.xlabel('Index of Unique Item',size=14)\nplt.title('Duplicate Count vs. Unique Item Count',size=16)\nplt.show()\n\nplt.figure(figsize=(20,5))\nplt.bar(groups.index.values[:50].astype('str'),groups.values[:50])\nplt.xticks(rotation = 45)\nplt.ylabel('Duplicate Count',size=14)\nplt.xlabel('Label Group',size=14)\nplt.title('Top 50 Duplicated Items',size=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(5):\n    print('#'*40)\n    print('### TOP %i DUPLICATED ITEM:'%(k+1),groups.index[k])\n    print('#'*40)\n    top = train.loc[train.label_group==groups.index[k]]\n    displayDF(top, random=False, ROWS=2, COLS=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute Baseline CV Score\nA baseline is to predict all items with the same image_phash as being duplicate. Let's calcuate the CV score for this submission.","metadata":{}},{"cell_type":"code","source":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof'] = train.image_phash.map(tmp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['f1'] = train.apply(getMetric('oof'),axis=1)\nprint('CV score for baseline =',train.f1.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute RAPIDS Model CV and Infer Submission\nWe will now use image embeddings, text embeddings, and phash to create a better model with better CV. We will also infer submission csv.\n\nNote how the variable COMPUTE_CV is only True when we commit this notebook. Right now you are reading a commit notebook, so we see test replaced with train and computed CV score. When we submit this notebook, the variable COMPUTE_CV will be False and the submit notebook will not compute CV. Instead it will load the real test dataset with 70,000 rows and find duplicates in the real test dataset.","metadata":{}},{"cell_type":"code","source":"if COMPUTE_CV:\n    test = pd.read_csv('../input/shopee-product-matching/train.csv')\n    test_gf = cudf.DataFrame(test)\n    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\nelse:\n    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n    test_gf = cudf.read_csv('../input/shopee-product-matching/test.csv')\n    print('Test shape is', test_gf.shape )\ntest_gf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use Image Embeddings\nTo prevent memory errors, we will compute image embeddings in chunks. And we will find similar images with RAPIDS cuML KNN in chunks.","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, img_size=256, batch_size=32, path=''): \n        self.df = df\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.path = path\n        self.indexes = np.arange( len(self.df) )\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = len(self.df) // self.batch_size\n        ct += int(( (len(self.df)) % self.batch_size)!=0)\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X = self.__data_generation(indexes)\n        return X\n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')\n        df = self.df.iloc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            img = cv2.imread(self.path+row.image)\n            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0\n        return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE = '../input/shopee-product-matching/test_images/'\nif COMPUTE_CV: BASE = '../input/shopee-product-matching/train_images/'\n\n# model = EfficientNetB0(weights='imagenet',include_top=False, pooling='avg', input_shape=None)\nWGT = '../input/effnetb0/efficientnetb0_notop.h5'\nmodel = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)\n\nembeds = []\nCHUNK = 1024*4\n\nprint('Computing image embeddings...')\nCTS = len(test)//CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor i,j in enumerate( range( CTS ) ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    test_gen = DataGenerator(test.iloc[a:b], batch_size=32, path=BASE)\n    image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)\n    embeds.append(image_embeddings)\n\n    #if i>=1: break\n    \ndel model\n_ = gc.collect()\nimage_embeddings = np.concatenate(embeds)\nprint('image embeddings shape',image_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN = 50\nif len(test)==3: KNN = 2\neffnet_model = NearestNeighbors(n_neighbors=KNN)\neffnet_model.fit(image_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings)//CHUNK\nif len(image_embeddings)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(image_embeddings))\n    print('chunk',a,'to',b)\n    distances, indices = effnet_model.kneighbors(image_embeddings[a:b,])\n    \n    for k in range(b-a):\n        IDX = np.where(distances[k,]<6.0)[0]\n        IDS = indices[k,IDX]\n        o = test.iloc[IDS].posting_id.values\n        preds.append(o)\n        \ndel effnet_model, distances, indices, image_embeddings, embeds\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['preds2'] = preds\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use Text Embeddings\nTo prevent memory errors, we will find similar titles in chunks. To faciliate this, we will use cosine similarity between text embeddings instead of KNN.","metadata":{}},{"cell_type":"code","source":"print('Computing text embeddings...')\ntext_model = TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\ntext_embeddings = text_model.fit_transform(test_gf.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(test)//CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        IDX = cupy.where(cts[k,]>0.7)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        \ndel text_model, text_embeddings\n_ = gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['preds'] = preds\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use Phash Feature\nWe will predict all items with the same phash as duplicates","metadata":{}},{"cell_type":"code","source":"tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['preds3'] = test.image_phash.map(tmp)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute CV Score\nThis simple model scores a high CV of 0.700+!","metadata":{}},{"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.preds,row.preds2, row.preds3])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds,row.preds2, row.preds3])\n    return np.unique(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if COMPUTE_CV:\n    tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n    test['target'] = test.label_group.map(tmp)\n    test['oof'] = test.apply(combine_for_cv,axis=1)\n    test['f1'] = test.apply(getMetric('oof'),axis=1)\n    print('CV Score =', test.f1.mean() )\n\ntest['matches'] = test.apply(combine_for_sub,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Write Submission CSV\nIn this notebook, the submission file below looks funny containing train information. But when we submit this notebook, the size of test.csv dataframe will be longer than 3 rows and the variable COMPUTE_CV will subsequently set to False. Then our submission notebook will compute the correct matches using the real test dataset and our submission csv for LB will be ok.","metadata":{}},{"cell_type":"code","source":"test[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}