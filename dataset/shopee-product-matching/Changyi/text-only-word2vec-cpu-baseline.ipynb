{"cells":[{"metadata":{},"cell_type":"markdown","source":"Credits :\n- [[PART 2] - RAPIDS TfidfVectorizer - [CV 0.700]](https://www.kaggle.com/cdeotte/part-2-rapids-tfidfvectorizer-cv-0-700)\n- [ðŸ›’ Shopee: EDA ðŸ“Š preprocessing âš™ï¸ pl](https://www.kaggle.com/prokaggler/shopee-eda-preprocessing-pytorch-bert/comments#-Data-Preprocessing-)\n- [EDA And Text Embedding](https://www.kaggle.com/marwanelghitany/eda-and-text-embedding/comments)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nfrom gensim.corpora import Dictionary\nfrom gensim.models import Word2Vec, WordEmbeddingSimilarityIndex\nfrom gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/shopee-product-matching/train.csv')\ntest  = pd.read_csv('../input/shopee-product-matching/test.csv')\n\nlen_test = len(test)\nlen_pred = len_test if len_test > 3 else len(train)\nCOMPUTE_CV = False if len_test > 3 else True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndef tokenize(text):\n    return text.split(' ')\n\ndef preprocess_text(sentence):\n    sentence = str(sentence)\n    sentence = sentence.lower()\n    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n    sentence = sentence.split()\n    sentence = [word for word in sentence if word not in stopwords.words('english')]\n    wl = WordNetLemmatizer()\n    sentence = [wl.lemmatize(word) for word in sentence]\n    sentence = ' '.join(sentence)\n    return sentence\n\ntrain['title_clean'] = train['title'].progress_apply(preprocess_text)\ntest['title_clean']  = test['title'].progress_apply(preprocess_text)\n\ndf = pd.concat([test, train]).reset_index(drop=True) if len_test > 3 else train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Word2Vec"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# bag of words\ntitles_tokens = [title.split() for title in df['title_clean']]\n\n# word dictionary\ndictionary = Dictionary(titles_tokens)\n# dictionary.filter_extremes(no_below=2, no_above=50)\n\n# Bag of words\nbow_corpus = [dictionary.doc2bow(token) for token in titles_tokens]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel = Word2Vec(titles_tokens, size=50, window=5, min_count=1, workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# word similarity index\ntermsim_index = WordEmbeddingSimilarityIndex(model.wv)\n\n# similarity matrix\nsimilarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary)\n\n# soft cosine similarity\ndocsim_index = SoftCosineSimilarity(bow_corpus, similarity_matrix, num_best=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getFilteredQuery(query, dict):\n    query = query.split()\n    return([wrd for wrd in query if dict.doc2idx([wrd])[0] >= 0])\n\ndef getIndex(sim, boundry, threshold):\n    inds = [s[0] for s in sim if s[1] > threshold]\n    if boundry > 3:\n        inds = [i for i in inds if i < boundry]\n    return inds\n\ndef getSimilarDoc(sentences, dict, docsim_index, boundry, threshold = 0.7):\n    queries = [dict.doc2bow(getFilteredQuery(sent, dict)) for sent in sentences]\n    sims = docsim_index[queries]\n    return [getIndex(sim, boundry, threshold) for sim in sims]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nCHUNK = 1024 * 4\n\nprint('Finding similar titles...')\nCTS = len_pred // CHUNK\nif len_pred % CHUNK != 0: CTS += 1\nfor j in range(CTS):\n    \n    a, b = j * CHUNK, min((j+1) * CHUNK, len_pred)\n    print('chunk',a,'to',b)\n    \n    # get similar sentences\n    index = getSimilarDoc(df['title_clean'][a:b], dictionary, docsim_index, len_test, 0.98)\n    \n    for k in range(b-a):\n        o = df.iloc[index[k]].posting_id.values\n        preds.append(o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if len(df) > len_pred:\n    df = df[:len_pred]\ndf['preds'] = preds\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.preds])\n    return ' '.join(np.unique(x))\n\ndf['matches'] = df.apply(combine_for_sub,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}