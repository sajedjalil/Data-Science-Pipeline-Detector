{"cells":[{"metadata":{},"cell_type":"markdown","source":"thanks to https://www.kaggle.com/cdeotte/part-2-rapids-tfidfvectorizer-cv-0-700"},{"metadata":{},"cell_type":"markdown","source":"# Load Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nsys.path = [\n    '../input/geffnet-20200820'  \n] + sys.path\n\nimport numpy as np, pandas as pd, gc\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nimport albumentations\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport geffnet\nfrom transformers import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Train Data\nFirst we load the train data and create a target column of ground truths to help us compute CV score. Note how the variable `COMPUTE_CV` will change to `False` when we **submit** this notebook but it is `True` now because you are reading a **commit** notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"COMPUTE_CV = True\n\ntest = pd.read_csv('../input/shopee-product-matching/test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/shopee-product-matching/train.csv')\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\nprint('train shape is', train.shape )\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compute Baseline CV Score\nA baseline is to predict all items with the same `image_phash` as being duplicate. Let's calcuate the CV score for this submission."},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof'] = train.image_phash.map(tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['f1'] = train.apply(getMetric('oof'),axis=1)\nprint('CV score for baseline =',train.f1.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compute RAPIDS Model CV and Infer Submission\nWe will now use image embeddings, text embeddings, and phash to create a better model with better CV. We will also infer submission csv.\n\nNote how the variable `COMPUTE_CV` is only `True` when we **commit** this notebook. Right now you are reading a **commit** notebook, so we see test replaced with train and computed CV score. When we **submit** this notebook, the variable `COMPUTE_CV` will be `False` and the **submit** notebook will **not** compute CV. Instead it will load the real test dataset with 70,000 rows and find duplicates in the real test dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    test = pd.read_csv('../input/shopee-folds/train_fold.csv')\n#     test = test[test.fold==0]\n    test_gf = cudf.DataFrame(test)\n    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\nelse:\n    test = pd.read_csv('../input/shopee-product-matching/test.csv')\n    test_gf = cudf.read_csv('../input/shopee-product-matching/test.csv')\n    print('Test shape is', test_gf.shape )\ntest_gf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use Image Embeddings\nTo prevent memory errors, we will compute image embeddings in chunks. And we will find similar images with RAPIDS cuML KNN in chunks."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\n\ndef get_transforms(img_size=256):\n    return  albumentations.Compose([\n                albumentations.Resize(img_size, img_size),\n                albumentations.Normalize()\n            ])\n\n\nclass LandmarkDataset(Dataset):\n    def __init__(self, csv, split, mode, transforms=get_transforms(img_size=256), tokenizer=None):\n\n        self.csv = csv.reset_index()\n        self.split = split\n        self.mode = mode\n        self.transform = transforms\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        text = row.title\n        \n        image = cv2.imread(row.filepath)\n        image = image[:, :, ::-1]\n        \n        res0 = self.transform(image=image)\n        image0 = res0['image'].astype(np.float32)\n        image = image0.transpose(2, 0, 1)        \n\n        text = self.tokenizer(text, padding='max_length', truncation=True, max_length=16, return_tensors=\"pt\")\n        input_ids = text['input_ids'][0]\n        attention_mask = text['attention_mask'][0]\n\n        if self.mode == 'test':\n            return torch.tensor(image), input_ids, attention_mask\n        else:\n            return torch.tensor(image), input_ids, attention_mask, torch.tensor(row.label_group)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('../input/bert-base-uncased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not COMPUTE_CV: \n    df_sub = pd.read_csv('../input/shopee-product-matching/test.csv')\n\n    df_test = df_sub.copy()\n    df_test['filepath'] = df_test['image'].apply(lambda x: os.path.join('../input/shopee-product-matching/', 'test_images', x))\n\n    dataset_test = LandmarkDataset(df_test, 'test', 'test', transforms=get_transforms(img_size=256), tokenizer=tokenizer)\n    test_loader = DataLoader(dataset_test, batch_size=16, num_workers=4)\n\n    print(len(dataset_test),dataset_test[0])\nelse:\n    df_sub = test\n\n    df_test = df_sub.copy()\n    df_test['filepath'] = df_test['image'].apply(lambda x: os.path.join('../input/shopee-product-matching/', 'train_images', x))\n\n    dataset_test = LandmarkDataset(df_test, 'test', 'test', transforms=get_transforms(img_size=256), tokenizer=tokenizer)\n    test_loader = DataLoader(dataset_test, batch_size=16, num_workers=4)\n\n    print(len(dataset_test),dataset_test[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ArcMarginProduct_subcenter(nn.Module):\n    def __init__(self, in_features, out_features, k=3):\n        super().__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n        self.reset_parameters()\n        self.k = k\n        self.out_features = out_features\n        \n    def reset_parameters(self):\n        stdv = 1. / math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n        \n    def forward(self, features):\n        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n        cosine, _ = torch.max(cosine_all, dim=2)\n        return cosine \n    \nsigmoid = torch.nn.Sigmoid()\n\nclass Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\nclass Swish_module(nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)\n\n    \n \n    \nclass enet_arcface_FINAL(nn.Module):\n\n    def __init__(self, enet_type, out_dim):\n        super(enet_arcface_FINAL, self).__init__()\n        self.bert = AutoModel.from_pretrained('../input/bert-base-uncased')\n        self.enet = geffnet.create_model(enet_type.replace('-', '_'), pretrained=None)\n        self.feat = nn.Linear(self.enet.classifier.in_features+self.bert.config.hidden_size, 512)\n        self.swish = Swish_module()\n        self.dropout = nn.Dropout(0.5)\n        self.metric_classify = ArcMarginProduct_subcenter(512, out_dim)\n        self.enet.classifier = nn.Identity()\n \n    def forward(self, x,input_ids, attention_mask):\n        x = self.enet(x)\n        text = self.bert(input_ids=input_ids, attention_mask=attention_mask)[1]\n        x = torch.cat([x, text], 1)\n        x = self.swish(self.feat(x))\n        return F.normalize(x), self.metric_classify(x)\n    \ndef load_model(model, model_file):\n    state_dict = torch.load(model_file)\n    if \"model_state_dict\" in state_dict.keys():\n        state_dict = state_dict[\"model_state_dict\"]\n    state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n#     del state_dict['metric_classify.weight']\n    model.load_state_dict(state_dict, strict=True)\n    print(f\"loaded {model_file}\")\n    model.eval()    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nfrom tqdm import tqdm\n\nWGT = '../input/shopee-b0-bert/b0ns_256_bert_20ep_fold0_epoch27.pth'\n\nmodel = enet_arcface_FINAL('tf_efficientnet_b0_ns', out_dim=11014).cuda()\nmodel = load_model(model, WGT)\n\n\nembeds = []\n\nwith torch.no_grad():\n    for img, input_ids, attention_mask in tqdm(test_loader): \n        img, input_ids, attention_mask = img.cuda(), input_ids.cuda(), attention_mask.cuda()\n        feat, _ = model(img, input_ids, attention_mask)\n        image_embeddings = feat.detach().cpu().numpy()\n        embeds.append(image_embeddings)\n\n    \ndel model\n_ = gc.collect()\nimage_embeddings = np.concatenate(embeds)\nprint('image embeddings shape',image_embeddings.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_embeddings = cupy.array(image_embeddings)\npreds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings)//CHUNK\nif len(image_embeddings)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(image_embeddings))\n    print('chunk',a,'to',b)\n   \n    cts = cupy.matmul(image_embeddings, image_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n#         print(sorted(cts[k,], reverse=True))\n        IDX = cupy.where(cts[k,]>0.5)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['preds2'] = preds\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use Text Embeddings\nTo prevent memory errors, we will find similar titles in chunks. To faciliate this, we will use cosine similarity between text embeddings instead of KNN."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Computing text embeddings...')\nmodel = TfidfVectorizer(stop_words=None, \n                        binary=True, \n                        max_features=25000)\ntext_embeddings = model.fit_transform(test_gf.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(test)//CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    #COSINE SIMILARITY DISTANCE\n    cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        IDX = cupy.where(cts[k,]>0.75)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['preds'] = preds\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use Phash Feature\nWe will predict all items with the same phash as duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['preds3'] = test.image_phash.map(tmp)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compute CV Score\nThis simple model scores a high CV of 0.700+!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.preds, row.preds2, row.preds3])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds, row.preds2, row.preds3])\n    return np.unique(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if COMPUTE_CV:\n    tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n    test['target'] = test.label_group.map(tmp)\n    test['oof'] = test.apply(combine_for_cv,axis=1)\n    test['f1'] = test.apply(getMetric('oof'),axis=1)\n    print('CV Score =', test.f1.mean() )\n\ntest['matches'] = test.apply(combine_for_sub,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CV for image :\", round(test.apply(getMetric('preds2'),axis=1).mean(), 3))\nprint(\"CV for text  :\", round(test.apply(getMetric('preds'),axis=1).mean(), 3))\nprint(\"CV for phash :\", round(test.apply(getMetric('preds3'),axis=1).mean(), 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Write Submission CSV\nIn this notebook, the submission file below looks funny containing train information. But when we submit this notebook, the size of `test.csv` dataframe will be longer than 3 rows and the variable `COMPUTE_CV` will subsequently set to `False`. Then our submission notebook will compute the correct matches using the real test dataset and our submission csv for LB will be ok."},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}