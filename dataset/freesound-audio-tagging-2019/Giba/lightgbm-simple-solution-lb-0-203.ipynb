{"cells":[{"metadata":{},"cell_type":"markdown","source":">v0.1 This code implements a simple feature extraction and train using Lightgbm.\n\nFeature extraction is very simple and can be improved."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport librosa\nimport matplotlib.pyplot as plt\nimport gc\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom sklearn.metrics import label_ranking_average_precision_score\nfrom sklearn.metrics import roc_auc_score\n\nfrom joblib import Parallel, delayed\nimport lightgbm as lgb\nfrom scipy import stats\n\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_and_label(rows_labels):\n    \n    row_labels_list = []\n    for row in rows_labels:\n        row_labels = row.split(',')\n        labels_array = np.zeros((80))\n        \n        for label in row_labels:\n            index = label_mapping[label]\n            labels_array[index] = 1\n        \n        row_labels_list.append(labels_array)\n    \n    return row_labels_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_curated = pd.read_csv('../input/train_curated.csv')\ntrain_noisy = pd.read_csv('../input/train_noisy.csv')\ntrain_noisy = train_noisy[['fname','labels']]\ntest = pd.read_csv('../input/sample_submission.csv')\nprint(train_curated.shape, train_noisy.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_columns = list( test.columns[1:] )\nlabel_mapping = dict((label, index) for index, label in enumerate(label_columns))\nlabel_mapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_curated_labels = split_and_label(train_curated['labels'])\ntrain_noisy_labels   = split_and_label(train_noisy  ['labels'])\nlen(train_curated_labels), len(train_noisy_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in label_columns:\n    train_curated[f] = 0.0\n    train_noisy[f] = 0.0\n\ntrain_curated[label_columns] = train_curated_labels\ntrain_noisy[label_columns]   = train_noisy_labels\n\ntrain_curated['num_labels'] = train_curated[label_columns].sum(axis=1)\ntrain_noisy['num_labels']   = train_noisy[label_columns].sum(axis=1)\n\ntrain_curated['path'] = '../input/train_curated/'+train_curated['fname']\ntrain_noisy  ['path'] = '../input/train_noisy/'+train_noisy['fname']\n\ntrain_curated.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([train_curated, train_noisy],axis=0)\n\ndel train_curated, train_noisy\ngc.collect()\n\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_features( pathname ):\n\n    var, sr = librosa.load( pathname, sr=44100)\n    # trim silence\n    if 0 < len(var): # workaround: 0 length causes error\n        var, _ = librosa.effects.trim(var)\n    xc = pd.Series(var)\n    \n    X = []\n    X.append( xc.mean() )\n    X.append( xc.median() )\n    X.append( xc.std() )\n    X.append( xc.max() )\n    X.append( xc.min() )\n    X.append( xc.skew() )\n    X.append( xc.mad() )\n    X.append( xc.kurtosis() )\n    \n    X.append( np.mean(np.diff(xc)) )\n    X.append( np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0]) )\n    X.append( np.abs(xc).max() )\n    X.append( np.abs(xc).min() )\n    \n    X.append( xc[:4410].std() )\n    X.append( xc[-4410:].std() )\n    X.append( xc[:44100].std() )\n    X.append( xc[-44100:].std() )\n    \n    X.append( xc[:4410].mean() )\n    X.append( xc[-4410:].mean() )\n    X.append( xc[:44100].mean() )\n    X.append( xc[-44100:].mean() )\n    \n    X.append( xc[:4410].min() )\n    X.append( xc[-4410:].min() )\n    X.append( xc[:44100].min() )\n    X.append( xc[-44100:].min() )\n    \n    X.append( xc[:4410].max() )\n    X.append( xc[-4410:].max() )\n    X.append( xc[:44100].max() )\n    X.append( xc[-44100:].max() )\n    \n    X.append( xc[:4410].skew() )\n    X.append( xc[-4410:].skew() )\n    X.append( xc[:44100].skew() )\n    X.append( xc[-44100:].skew() )\n    \n    X.append( xc.max() / np.abs(xc.min()) )\n    X.append( xc.max() - np.abs(xc.min()) )\n    X.append( xc.sum() )\n    \n    X.append( np.mean(np.nonzero((np.diff(xc[:4410]) / xc[:4410][:-1]))[0]) )\n    X.append( np.mean(np.nonzero((np.diff(xc[-4410:]) / xc[-4410:][:-1]))[0]) )\n    X.append( np.mean(np.nonzero((np.diff(xc[:44100]) / xc[:44100][:-1]))[0]) )\n    X.append( np.mean(np.nonzero((np.diff(xc[-44100:]) / xc[-44100:][:-1]))[0]) )\n    \n    X.append( np.quantile(xc, 0.95) )\n    X.append( np.quantile(xc, 0.99) )\n    X.append( np.quantile(xc, 0.10) )\n    X.append( np.quantile(xc, 0.05) )\n    \n    X.append( np.abs(xc).mean() )\n    X.append( np.abs(xc).std() )\n             \n    return np.array( X )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = Parallel(n_jobs= 4)(delayed(create_features)(fn) for fn in tqdm(train['path'].values) )\nX = np.array( X )\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtest = Parallel(n_jobs= 4)(delayed(create_features)( '../input/test/'+fn) for fn in tqdm(test['fname'].values) )\nXtest = np.array( Xtest )\nXtest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nn_fold = 5\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=69)\n\nparams = {'num_leaves': 15,\n         'min_data_in_leaf': 200, \n         'objective':'binary',\n         \"metric\": 'auc',\n         'max_depth': -1,\n         'learning_rate': 0.05,\n         \"boosting\": \"gbdt\",\n         \"bagging_fraction\": 0.85,\n         \"bagging_freq\": 1,\n         \"feature_fraction\": 0.20,\n         \"bagging_seed\": 42,\n         \"verbosity\": -1,\n         \"nthread\": -1,\n         \"random_state\": 69}\n\nPREDTRAIN = np.zeros( (X.shape[0],80) )\nPREDTEST  = np.zeros( (Xtest.shape[0],80) )\nfor f in range(len(label_columns)):\n    y = train[ label_columns[f] ].values\n    oof      = np.zeros( X.shape[0] )\n    oof_test = np.zeros( Xtest.shape[0] )\n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X,y)):\n        model = lgb.LGBMClassifier(**params, n_estimators = 20000)\n        model.fit(X[trn_idx,:], \n                  y[trn_idx], \n                  eval_set=[(X[val_idx,:], y[val_idx])], \n                  eval_metric='auc',\n                  verbose=0, \n                  early_stopping_rounds=25)\n        oof[val_idx] = model.predict_proba(X[val_idx,:], num_iteration=model.best_iteration_)[:,1]\n        oof_test += model.predict_proba(Xtest          , num_iteration=model.best_iteration_)[:,1]/5.0\n\n    PREDTRAIN[:,f] = oof    \n    PREDTEST [:,f] = oof_test\n    \n    print( f, str(roc_auc_score( y, oof ))[:6], label_columns[f] )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ndef calculate_overall_lwlrap_sklearn(truth, scores):\n    \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n    # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n    sample_weight = np.sum(truth > 0, axis=1)\n    nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n    overall_lwlrap = label_ranking_average_precision_score(\n        truth[nonzero_weight_sample_indices, :] > 0, \n        scores[nonzero_weight_sample_indices, :], \n        sample_weight=sample_weight[nonzero_weight_sample_indices])\n    return overall_lwlrap\n\nprint( 'lwlrap cv:', calculate_overall_lwlrap_sklearn( train[label_columns].values, PREDTRAIN ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[label_columns] = PREDTEST\ntest.to_csv('submission.csv', index=False)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}