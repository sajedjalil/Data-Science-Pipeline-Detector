{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries and Data import","metadata":{}},{"cell_type":"code","source":"import datatable as dt  # pip install datatable","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:03:54.424931Z","iopub.execute_input":"2021-09-09T07:03:54.425331Z","iopub.status.idle":"2021-09-09T07:03:54.575237Z","shell.execute_reply.started":"2021-09-09T07:03:54.425245Z","shell.execute_reply":"2021-09-09T07:03:54.57429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\n\nfrom matplotlib.lines import Line2D\n\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\n\n\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import precision_recall_curve\n\nimport optuna\n\n# Pandas setting to display more dataset rows and columns\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=UserWarning)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T08:34:09.998119Z","iopub.execute_input":"2021-09-09T08:34:09.99848Z","iopub.status.idle":"2021-09-09T08:34:10.01237Z","shell.execute_reply.started":"2021-09-09T08:34:09.99845Z","shell.execute_reply":"2021-09-09T08:34:10.01138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the data\ntrain = dt.fread(\"../input/tabular-playground-series-sep-2021/train.csv\").to_pandas().set_index(\"id\")\ntest = dt.fread(\"../input/tabular-playground-series-sep-2021/test.csv\").to_pandas().set_index(\"id\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:06:26.021051Z","iopub.execute_input":"2021-09-09T07:06:26.021416Z","iopub.status.idle":"2021-09-09T07:06:40.995818Z","shell.execute_reply.started":"2021-09-09T07:06:26.021386Z","shell.execute_reply":"2021-09-09T07:06:40.994987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Memory reducing \ntaken from: https://www.kaggle.com/bextuychiev/how-to-work-w-million-row-datasets-like-a-pro\n","metadata":{}},{"cell_type":"code","source":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() / 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) / start_mem\n            )\n        )\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:06:40.99728Z","iopub.execute_input":"2021-09-09T07:06:40.997587Z","iopub.status.idle":"2021-09-09T07:06:41.0119Z","shell.execute_reply.started":"2021-09-09T07:06:40.997552Z","shell.execute_reply":"2021-09-09T07:06:41.011106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_memory_usage(train, verbose=True)\ntest = reduce_memory_usage(test, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:06:41.013588Z","iopub.execute_input":"2021-09-09T07:06:41.014098Z","iopub.status.idle":"2021-09-09T07:07:05.595901Z","shell.execute_reply.started":"2021-09-09T07:06:41.014062Z","shell.execute_reply":"2021-09-09T07:07:05.595092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NA values in train and test","metadata":{"execution":{"iopub.status.busy":"2021-09-01T12:43:35.04385Z","iopub.execute_input":"2021-09-01T12:43:35.044253Z","iopub.status.idle":"2021-09-01T12:43:35.048912Z","shell.execute_reply.started":"2021-09-01T12:43:35.044217Z","shell.execute_reply":"2021-09-01T12:43:35.047441Z"}}},{"cell_type":"code","source":"print(\"(train, test) na --> \",(train.isna().sum().sum(), test.isna().sum().sum()))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:08:03.387938Z","iopub.execute_input":"2021-09-09T07:08:03.388309Z","iopub.status.idle":"2021-09-09T07:08:04.065694Z","shell.execute_reply.started":"2021-09-09T07:08:03.388275Z","shell.execute_reply":"2021-09-09T07:08:04.064609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_na_train_df = train.drop(columns=\"claim\").isna().sum(axis = 1)\nprint(is_na_train_df.shape)\n\nis_na_test_df = test.isna().sum(axis = 1)\nprint(is_na_test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:08:20.154906Z","iopub.execute_input":"2021-09-09T07:08:20.155256Z","iopub.status.idle":"2021-09-09T07:08:21.226542Z","shell.execute_reply.started":"2021-09-09T07:08:20.155219Z","shell.execute_reply":"2021-09-09T07:08:21.225611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation: Feature enG + Siple Imputer + NA to median","metadata":{}},{"cell_type":"code","source":"train[\"isNA\"] =is_na_train_df\nprint(train.shape)\n\ntest[\"isNA\"] = is_na_test_df\nprint(test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:08:24.370696Z","iopub.execute_input":"2021-09-09T07:08:24.37112Z","iopub.status.idle":"2021-09-09T07:08:24.468843Z","shell.execute_reply.started":"2021-09-09T07:08:24.371075Z","shell.execute_reply":"2021-09-09T07:08:24.467787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_Mm_scaler = MinMaxScaler()\nX = pd.DataFrame(x_Mm_scaler.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\ny = train.claim\nX_test = pd.DataFrame(x_Mm_scaler.transform(test), columns=test.columns)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:08:31.727544Z","iopub.execute_input":"2021-09-09T07:08:31.72787Z","iopub.status.idle":"2021-09-09T07:08:35.325538Z","shell.execute_reply.started":"2021-09-09T07:08:31.727839Z","shell.execute_reply":"2021-09-09T07:08:35.324501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer_zeros = SimpleImputer(strategy=\"median\")\nX = pd.DataFrame(imputer_zeros.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(imputer_zeros.transform(test), columns=test.columns)\nX = pd.DataFrame(x_Mm_scaler.fit_transform(X),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(x_Mm_scaler.transform(X_test), columns=test.columns)\nprint(\"(train, test) na --> \",(X.isna().sum().sum(), X_test.isna().sum().sum()))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:15:16.970767Z","iopub.execute_input":"2021-09-09T07:15:16.971088Z","iopub.status.idle":"2021-09-09T07:15:45.259662Z","shell.execute_reply.started":"2021-09-09T07:15:16.971057Z","shell.execute_reply":"2021-09-09T07:15:45.258767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model_optuna_xgb(trial, X_train, X_valid, y_train, y_valid):\n    \"\"\"\n    A function to train a model using different hyperparamerters combinations provided by Optuna. \n    Loss of validation data predictions is returned to estimate hyperparameters effectiveness.\n    \"\"\"\n    preds = 0\n       \n    #A set of hyperparameters to optimize by optuna\n    xgb_params = {\n                 \"n_estimators\": trial.suggest_categorical('n_estimators', [10000]),\n                 \"learning_rate\": trial.suggest_float('learning_rate', 0.01, 0.8),\n                 \"subsample\": trial.suggest_float('subsample', 0.5, 0.95),\n                 \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.5, 0.95),\n                 \"max_depth\": trial.suggest_int(\"max_depth\", 5, 16),\n                 \"booster\": trial.suggest_categorical('booster', [\"gbtree\"]),\n                 \"tree_method\": trial.suggest_categorical('tree_method', [\"gpu_hist\"]),\n                 \"reg_lambda\": trial.suggest_float('reg_lambda', 2, 100),\n                 \"reg_alpha\": trial.suggest_float('reg_alpha', 1, 50),\n                 \"random_state\": trial.suggest_categorical('random_state', [42]),\n                 \"n_jobs\": trial.suggest_categorical('n_jobs', [4]),\n                    }\n\n    # Model loading and training\n    model = XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"rmse\",\n              early_stopping_rounds=100,\n              verbose=False)\n    \n    print(f\"Number of boosting rounds: {model.best_iteration}\")\n    oof = model.predict(X_valid)\n    oof[oof<0] = 0\n    \n    return np.sqrt(mean_squared_error(y_valid, oof))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:19:44.563911Z","iopub.execute_input":"2021-09-09T07:19:44.564236Z","iopub.status.idle":"2021-09-09T07:19:44.573812Z","shell.execute_reply.started":"2021-09-09T07:19:44.564188Z","shell.execute_reply":"2021-09-09T07:19:44.572712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {'n_estimators': 10000, \n              'learning_rate': 0.08625196792060146, \n              'subsample': 0.5959773829663169, \n              'colsample_bytree': 0.7603045913120982, \n              'max_depth': 7, 'booster': 'gbtree', \n              'tree_method': 'gpu_hist', \n              'reg_lambda': 74.60593770387143, \n              'reg_alpha': 33.38858560681472, \n              'random_state': 42, \n              'n_jobs': 4}\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T07:19:49.34688Z","iopub.execute_input":"2021-09-09T07:19:49.347243Z","iopub.status.idle":"2021-09-09T07:19:49.354222Z","shell.execute_reply.started":"2021-09-09T07:19:49.347177Z","shell.execute_reply":"2021-09-09T07:19:49.35335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsplits = 10\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_rmse = 0\ntotal_mean_roc_auc_score = 0\n\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X,y)):\n    \n    X_train, X_valid = X.loc[train_indicies], X.loc[valid_indicies]\n    y_train, y_valid = y.loc[train_indicies], y.loc[valid_indicies]\n    print(fold, f\"X_train = {X_train.shape} - y_train: {y_train.shape}\")\n    print(fold, f\"X_valid = {X_valid.shape} - y_valid: {y_valid.shape}\")\n    model = XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"auc\",\n              early_stopping_rounds=100,\n              verbose=False)\n    print(\"fitted\")\n    preds += model.predict(X_test) / splits\n    print(preds.shape)\n    print(\"preds ok\")\n    model_fi += model.feature_importances_\n    print(\"model_fi ok\")\n    oof_preds[valid_indicies] = model.predict(X_valid)\n    print(oof_preds)\n    oof_preds[oof_preds < 0] = 0\n#     fold_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(np.array(y_valid).reshape(-1,1)), y_scaler.inverse_transform(np.array(oof_preds[valid_idx]).reshape(-1,1))))\n    fold_roc_auc_score = roc_auc_score(y_valid, oof_preds[valid_indicies])\n    # fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_indicies]))\n    print(f\"Fold {fold} ROC AUC Score: {fold_roc_auc_score}\")\n#         print(f\"Trees: {model.tree_count_}\")\n    # total_mean_rmse += fold_rmse / splits\n    total_mean_roc_auc_score += fold_roc_auc_score / splits\nprint(f\"\\nOverall ROC AUC Score: {total_mean_roc_auc_score}\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:34:39.76677Z","iopub.execute_input":"2021-09-09T08:34:39.767097Z","iopub.status.idle":"2021-09-09T08:39:29.959321Z","shell.execute_reply.started":"2021-09-09T08:34:39.767062Z","shell.execute_reply":"2021-09-09T08:39:29.958488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb public Score untuned and fast parameters: 0.76817\npredictions = pd.DataFrame()\npredictions[\"id\"] = test.index\npredictions[\"claim\"] = preds\n\npredictions.to_csv('submission.csv', index=False, header=predictions.columns)\npredictions.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:50:59.008738Z","iopub.execute_input":"2021-09-09T08:50:59.009073Z","iopub.status.idle":"2021-09-09T08:51:00.321835Z","shell.execute_reply.started":"2021-09-09T08:50:59.009041Z","shell.execute_reply":"2021-09-09T08:51:00.320854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for plotting Confusion Matrix\n\ndef plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i in range (cm.shape[0]):\n        for j in range (cm.shape[1]):\n            plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:51:05.902326Z","iopub.execute_input":"2021-09-09T08:51:05.902674Z","iopub.status.idle":"2021-09-09T08:51:05.910871Z","shell.execute_reply.started":"2021-09-09T08:51:05.902645Z","shell.execute_reply":"2021-09-09T08:51:05.909646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feeding parameters in the CM Function\nthreshold = 0.5\ny_true=y\ny_pred=oof_preds > threshold\ncm = confusion_matrix(y_true=y_true, y_pred = y_pred)\n# len(oof_preds)\n#Labels for the CM\n\ncm_plot_labels = ['Negative','Positive']\nprint(\"\\n         Confusion Matrix\")\nprint(\"***********************************\")\nprint(\"* True Negative  | False Negative *\")\nprint(\"*---------------------------------*\")\nprint(\"* False Negative | True Positive  *\")\nprint(\"***********************************\\n\")\n#Plotting the CM\n\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:56:35.917092Z","iopub.execute_input":"2021-09-09T08:56:35.917466Z","iopub.status.idle":"2021-09-09T08:56:36.913723Z","shell.execute_reply.started":"2021-09-09T08:56:35.917434Z","shell.execute_reply":"2021-09-09T08:56:36.912718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\nprint(\"Precision: TP/(TP+FP)\")\nprint(precision_score(y_true=y_true, y_pred = y_pred))\nprint(\"Recall: TP/(TP+FN)\")\nprint(recall_score(y_true=y_true, y_pred = y_pred))\nprint(\"f1_score = 2/((1/precision)+(1/recall))\")\nprint(f1_score(y_true=y_true, y_pred = y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T08:56:55.601741Z","iopub.execute_input":"2021-09-09T08:56:55.602066Z","iopub.status.idle":"2021-09-09T08:56:56.888406Z","shell.execute_reply.started":"2021-09-09T08:56:55.602036Z","shell.execute_reply":"2021-09-09T08:56:56.887461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Precision Recall versus the decision threshold","metadata":{}},{"cell_type":"code","source":"y_pred=oof_preds\ny_true = y\n\nprecisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.rcParams['font.size'] = 12\n    plt.title('Precision Recall vs threshold')\n    plt.xlabel('Threshold')\n    plt.legend(loc=\"lower left\")\n    \n    plt.grid(True)\n\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:28:33.423095Z","iopub.execute_input":"2021-09-09T09:28:33.423447Z","iopub.status.idle":"2021-09-09T09:28:33.937399Z","shell.execute_reply.started":"2021-09-09T09:28:33.423416Z","shell.execute_reply":"2021-09-09T09:28:33.936432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_precision_vs_recall(precisions, recalls):\n    plt.plot(recalls[:-1], precisions[:-1], \"b-\", label=\"Precision\")\n    \n    plt.rcParams['font.size'] = 12\n    plt.title('Precision vs recall')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    # plt.legend(loc=\"lower left\")\n    \n    plt.grid(True)\n\nplot_precision_vs_recall(precisions, recalls)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:33:06.819157Z","iopub.execute_input":"2021-09-09T09:33:06.819502Z","iopub.status.idle":"2021-09-09T09:33:07.036965Z","shell.execute_reply.started":"2021-09-09T09:33:06.819471Z","shell.execute_reply":"2021-09-09T09:33:07.036022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROC curve","metadata":{}},{"cell_type":"code","source":"y_true=y\ny_pred=oof_preds\nfpr, tpr, thresholds = roc_curve(y_true, y_pred)\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr, \"r-\", label=label)\n    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.rcParams['font.size'] = 12\n    plt.title('XGBR ROC curve for TPS 09')\n    plt.xlabel('False Positive Rate (1 - Specificity)')\n    plt.ylabel('True Positive Rate (Sensitivity)')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n\nplot_roc_curve(fpr, tpr, label=\"XGB\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T09:46:18.591618Z","iopub.execute_input":"2021-09-09T09:46:18.592049Z","iopub.status.idle":"2021-09-09T09:46:18.657967Z","shell.execute_reply.started":"2021-09-09T09:46:18.591965Z","shell.execute_reply":"2021-09-09T09:46:18.656552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}