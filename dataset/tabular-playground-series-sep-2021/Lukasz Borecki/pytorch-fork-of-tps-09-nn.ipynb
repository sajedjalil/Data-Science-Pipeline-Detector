{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Because i am actually learning PyTorch and i want to be dual framework developer i made my tensorflow model translated into PyTorch. It is my first PyTorch model so there may be an errors :)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nfrom scipy import stats\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-22T16:37:39.732237Z","iopub.execute_input":"2021-09-22T16:37:39.732724Z","iopub.status.idle":"2021-09-22T16:37:40.429497Z","shell.execute_reply.started":"2021-09-22T16:37:39.732636Z","shell.execute_reply":"2021-09-22T16:37:40.428533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler,  QuantileTransformer,  KBinsDiscretizer, PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, IterativeImputer\nimport torch\nimport torchmetrics\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom datetime import datetime\nfrom torchmetrics import AUROC\nfrom scipy.stats import zscore\n","metadata":{"execution":{"iopub.status.busy":"2021-09-22T16:37:40.430954Z","iopub.execute_input":"2021-09-22T16:37:40.431297Z","iopub.status.idle":"2021-09-22T16:37:42.149675Z","shell.execute_reply.started":"2021-09-22T16:37:40.431258Z","shell.execute_reply":"2021-09-22T16:37:42.148736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/train.csv')\nX_test =  pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/test.csv')\ntrain.pop('id')\n\ny = train['claim']\ntrain.pop('claim')\nX_test.pop('id')\nX=train\nX['sum_na'] = X.isna().sum(axis=1)\nX_test['sum_na'] = X_test.isna().sum(axis=1)\nprint(X.shape)\n\ndel train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-22T16:37:42.153258Z","iopub.execute_input":"2021-09-22T16:37:42.153556Z","iopub.status.idle":"2021-09-22T16:38:21.925422Z","shell.execute_reply.started":"2021-09-22T16:37:42.153531Z","shell.execute_reply":"2021-09-22T16:38:21.924601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp = SimpleImputer(missing_values=np.nan, strategy='median')\nX = imp.fit_transform(X)\nX_test = imp.transform(X_test)\n\nX, X_off, y, y_off  = train_test_split(X,y,test_size=0.05,random_state=2021,stratify=y)\n# z_scores = zscore(X)\n\n# print(X.shape)\n# abs_z_scores = np.abs(z_scores)\n# filtered_entries = (abs_z_scores < 3.5).all(axis=1)\n# y = y[filtered_entries]\n# X = X[filtered_entries]\ny = np.float32(y)\ny_off = np.float32(y_off)\nprint(X.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T16:38:21.926999Z","iopub.execute_input":"2021-09-22T16:38:21.927342Z","iopub.status.idle":"2021-09-22T16:38:50.689321Z","shell.execute_reply.started":"2021-09-22T16:38:21.927308Z","shell.execute_reply":"2021-09-22T16:38:50.688282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClassModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n    \n        self.emb = nn.Embedding(106,18)\n        self.fc = nn.Linear(119*18,20)#2380 for 20\n        self.dropout = nn.Dropout(0.2)\n        self.dropout2 = nn.Dropout(0.5)\n        self.fc1 = nn.Linear(119,20)\n        self.fc2 = nn.Linear(30,30)\n        self.fc3 = nn.Linear(128*14,20)\n        self.out = nn.Linear(60,1)\n        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=1)\n        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=1)\n        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1)\n        self.pool1 = nn.MaxPool1d(kernel_size=2,stride=2)\n        self.pool2 = nn.MaxPool1d(kernel_size=2,stride=2)\n        self.pool3 = nn.MaxPool1d(kernel_size=2,stride=2)\n        torch.nn.init.xavier_normal_(self.out.weight)\n        torch.nn.init.xavier_normal_(self.emb.weight)\n        torch.nn.init.xavier_normal_(self.fc.weight)\n        torch.nn.init.xavier_normal_(self.fc1.weight)\n        torch.nn.init.xavier_normal_(self.fc2.weight)\n        torch.nn.init.xavier_normal_(self.fc3.weight)\n        torch.nn.init.xavier_normal_(self.conv1.weight)\n        torch.nn.init.xavier_normal_(self.conv2.weight)\n        torch.nn.init.xavier_normal_(self.conv3.weight)\n    def forward(self, x_bin, x, x_conv):\n\n        x_conv = F.relu(self.conv1(x_conv))\n        x_conv = self.pool1(x_conv)\n        x_conv = F.relu(self.conv2(x_conv))\n        x_conv = self.pool2(x_conv)\n        x_conv = F.relu(self.conv3(x_conv))\n        x_conv = self.pool3(x_conv)\n\n        x_conv = x_conv.view(-1,14*128)\n        x_conv = F.silu(self.fc3(x_conv))\n        x_bin = self.emb(x_bin)\n        #x_bin = self.dropout(x_bin)\n        x_bin = x_bin.view(-1,119*18)\n        x_bin = F.silu(self.fc(x_bin))\n\n\n        x = F.silu(self.fc1(x))\n        #x = torch.add(torch.add(x_bin,x),x_conv)\n        x = torch.cat((x,x_bin,x_conv),1)\n        x = self.dropout2(x)\n        #x = F.silu(self.fc2(x))\n        #x = self.dropout2(x)\n        x = torch.sigmoid(self.out(x))\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2021-09-22T16:38:50.69073Z","iopub.execute_input":"2021-09-22T16:38:50.691092Z","iopub.status.idle":"2021-09-22T16:38:50.706333Z","shell.execute_reply.started":"2021-09-22T16:38:50.691056Z","shell.execute_reply":"2021-09-22T16:38:50.705514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 8 - Fold Section","metadata":{}},{"cell_type":"code","source":"\ndef batch_gd(X, X_test, y, X_off,y_off,epochs):\n\n\n    qt = QuantileTransformer(n_quantiles=106, output_distribution='normal')\n    X = qt.fit_transform(X)\n    X_test = qt.transform(X_test)\n    X_off = qt.transform(X_off)\n    bin_cat = KBinsDiscretizer(n_bins=106, encode='ordinal',strategy='uniform')\n    X_bin = bin_cat.fit_transform(X)\n    X_bin_off = bin_cat.transform(X_off)\n    X_conv = X_bin.reshape(-1,1,119)/106\n    X_conv_off = X_bin_off.reshape(-1,1,119)/106\n    X_test_bin = bin_cat.transform(X_test)\n    X_test_conv = X_test_bin.reshape(-1,1,119)/106\n\n    gc.collect()\n    kfold = StratifiedKFold(n_splits = 8, random_state=202109, shuffle=True)\n    y_pred = torch.zeros(493474,1)\n    metric = AUROC()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n       # device = 'cpu'\n    print('Using {} device'.format(device))   \n    y_pred = y_pred.to(device)\n    X_test = torch.from_numpy(X_test.astype(np.float32))\n    X_test_bin = torch.from_numpy(X_test_bin.astype(np.float32))\n    X_test_conv = torch.from_numpy(X_test_conv.astype(np.float32))\n    test_dataset=torch.utils.data.TensorDataset(X_test_bin.long(),X_test,X_test_conv)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n    \n    X_off = torch.from_numpy(X_off.astype(np.float32))\n    X_bin_off = torch.from_numpy(X_bin_off.astype(np.float32))\n    X_conv_off = torch.from_numpy(X_conv_off.astype(np.float32))\n    y_off = torch.from_numpy(y_off.astype(np.float32).reshape(-1, 1))\n    off_dataset=torch.utils.data.TensorDataset(X_bin_off.long(),X_off,X_conv_off, y_off)\n    off_loader = torch.utils.data.DataLoader(off_dataset, batch_size=512, shuffle=False)\n    for idx in kfold.split(X=X, y=y):\n        best_metric = 0\n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X[train_idx]\n        xtrain_bin = X_bin[train_idx]\n        xtrain_conv = X_conv[train_idx]\n        ytrain = y[train_idx]\n        xval = X[val_idx]\n        xval_bin = X_bin[val_idx]\n        xval_conv = X_conv[val_idx]\n        yval = y[val_idx]\n        \n        ytrain = np.array(ytrain)\n        yval = np.array(yval)\n        \n        xtrain = torch.from_numpy(xtrain.astype(np.float32))\n        xval = torch.from_numpy(xval.astype(np.float32))\n        ytrain = torch.from_numpy(ytrain.astype(np.float32).reshape(-1, 1))\n        yval = torch.from_numpy(yval.astype(np.float32).reshape(-1, 1))\n\n        xtrain_bin = torch.from_numpy(xtrain_bin.astype(np.float32))\n        xval_bin = torch.from_numpy(xval_bin.astype(np.float32))\n        xtrain_conv = torch.from_numpy(xtrain_conv.astype(np.float32))\n        xval_conv = torch.from_numpy(xval_conv.astype(np.float32))\n        \n        train_dataset=torch.utils.data.TensorDataset(xtrain_bin.long(),xtrain,xtrain_conv,ytrain)\n        val_dataset=torch.utils.data.TensorDataset(xval_bin.long(),xval,xval_conv,yval)\n\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True)\n        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=512, shuffle=False)\n        \n        model = ClassModel()\n#         model.apply(weights_init)\n        criterion = nn.BCELoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.00023, eps=1e-08)\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n        model.to(device)\n        gc.collect()\n        for epoch in range(epochs):\n            model.train()\n            t0 = datetime.now()\n            train_loss = []\n            for inputs_bin, inputs, inputs_conv, targets in train_loader:\n                inputs_bin, inputs, inputs_conv, targets = inputs_bin.to(device), inputs.to(device), inputs_conv.to(device), targets.to(device)\n\n                optimizer.zero_grad()\n                outputs = model(inputs_bin,inputs,inputs_conv)\n                loss = criterion(outputs, targets)\n                loss.backward()\n                optimizer.step()\n                train_loss.append(loss.item())\n            train_loss = np.mean(train_loss) \n\n            model.eval()\n            with torch.no_grad():\n                val_loss = []\n                for inputs_bin, inputs, inputs_conv, targets in val_loader:\n                    inputs_bin, inputs, inputs_conv, targets = inputs_bin.to(device), inputs.to(device), inputs_conv.to(device), targets.to(device)\n                    outputs = model(inputs_bin,inputs, inputs_conv)\n                    loss = criterion(outputs, targets)\n                    val_loss.append(loss.item())\n                    auroc = metric(outputs,targets.int())\n\n                val_loss = np.mean(val_loss)\n                auroc = metric.compute()\n                metric.reset()\n                for inputs_bin, inputs, inputs_conv, targets in off_loader:\n                    inputs_bin, inputs, inputs_conv, targets = inputs_bin.to(device), inputs.to(device), inputs_conv.to(device), targets.to(device)\n                    outputs = model(inputs_bin,inputs, inputs_conv)\n                    auroc_off = metric(outputs,targets.int())\n                auroc_off = metric.compute()\n                metric.reset()\n                if auroc_off > best_metric:\n                    best_metric = auroc_off\n                    torch.save(model.state_dict(), '/kaggle/working/ckpt_pytorch')\n        #         auc_roc = metric(outputs,targets.int()).compute()\n                dt = datetime.now() - t0\n                print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n              Val Loss: {val_loss:.4f} ,Best AUC {best_metric:.5f} , Off AUC {auroc_off:.4f} ,   Val AUC: {auroc:.4f} Duration: {dt}')\n                auroc = metric.reset()\n                auroc_off = metric.reset()\n        with torch.no_grad():\n            del model\n            del inputs_bin\n            del inputs\n            del targets\n            del xtrain\n            del xtrain_bin\n            del xval_bin\n            del xval\n            del ytrain\n            del yval\n            del train_dataset\n            del val_dataset\n            del train_loader\n            del val_loader\n            gc.collect()\n            with torch.cuda.device('cuda:0'):\n                torch.cuda.empty_cache()\n            model = ClassModel()\n            model.load_state_dict(torch.load('/kaggle/working/ckpt_pytorch'))\n            model.to(device)\n            preds = []\n            model.eval()\n            for inputs_bin, inputs, inputs_conv in test_loader:\n                inputs_bin, inputs, inputs_conv = inputs_bin.to(device), inputs.to(device), inputs_conv.to(device)\n                preds.append(model(inputs_bin, inputs, inputs_conv)/kfold.n_splits)\n            y_pred += torch.cat(preds,0)\n\n    return y_pred.cpu().numpy()\n\n\n\n\n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-22T16:38:50.707572Z","iopub.execute_input":"2021-09-22T16:38:50.708061Z","iopub.status.idle":"2021-09-22T16:38:50.740086Z","shell.execute_reply.started":"2021-09-22T16:38:50.708023Z","shell.execute_reply":"2021-09-22T16:38:50.73917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=batch_gd(X, X_test, y, X_off,y_off, epochs=12)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T16:38:50.741182Z","iopub.execute_input":"2021-09-22T16:38:50.741551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:49:08.142406Z","iopub.execute_input":"2021-09-21T15:49:08.142736Z","iopub.status.idle":"2021-09-21T15:49:08.151787Z","shell.execute_reply.started":"2021-09-21T15:49:08.142705Z","shell.execute_reply":"2021-09-21T15:49:08.150091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv')\nsub.iloc[:,1]=y_pred\nsub=sub.set_index('id')\nsub.to_csv('baseline_pytorch_cv.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:49:12.696365Z","iopub.execute_input":"2021-09-21T15:49:12.69672Z","iopub.status.idle":"2021-09-21T15:49:14.956255Z","shell.execute_reply.started":"2021-09-21T15:49:12.696689Z","shell.execute_reply":"2021-09-21T15:49:14.955175Z"},"trusted":true},"execution_count":null,"outputs":[]}]}