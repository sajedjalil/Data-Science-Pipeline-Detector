{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import roc_auc_score\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback\nfrom lightgbm import LGBMClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-02T10:43:35.515461Z","iopub.execute_input":"2021-10-02T10:43:35.516017Z","iopub.status.idle":"2021-10-02T10:43:38.436022Z","shell.execute_reply.started":"2021-10-02T10:43:35.515934Z","shell.execute_reply":"2021-10-02T10:43:38.435043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-sep-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-sep-2021/test.csv')\nsample_solution = pd.read_csv('../input/tabular-playground-series-sep-2021/sample_solution.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:43:38.437711Z","iopub.execute_input":"2021-10-02T10:43:38.438114Z","iopub.status.idle":"2021-10-02T10:44:23.130658Z","shell.execute_reply.started":"2021-10-02T10:43:38.438054Z","shell.execute_reply":"2021-10-02T10:44:23.129672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"features = [c for c in df_test.columns if 'f' in c]\n\ndf_train['kfold'] = -1\n\ndf_train['missing'] = df_train.isnull().sum(axis=1)\ndf_test['missing']  = df_test.isnull().sum(axis=1)\n\nfeatures.append('missing')\n\ny_train = df_train.claim\nX_train = df_train.drop('claim', axis=1)\n\ndf_train[features] = df_train[features].fillna(df_train[features].median())\ndf_test[features] = df_test[features].fillna(df_test[features].median())\n\nscaler = preprocessing.RobustScaler()\ndf_train[features] = scaler.fit_transform(df_train[features])\ndf_test[features] = scaler.transform(df_test[features])","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:44:23.132513Z","iopub.execute_input":"2021-10-02T10:44:23.132918Z","iopub.status.idle":"2021-10-02T10:45:24.691021Z","shell.execute_reply.started":"2021-10-02T10:44:23.132876Z","shell.execute_reply":"2021-10-02T10:45:24.689165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating folds","metadata":{}},{"cell_type":"code","source":"skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (i_train, i_valid) in enumerate (skf.split(X_train, y_train)):\n    df_train.loc[i_valid, 'kfold'] = fold","metadata":{"execution":{"iopub.status.busy":"2021-10-02T10:45:24.69484Z","iopub.execute_input":"2021-10-02T10:45:24.695413Z","iopub.status.idle":"2021-10-02T10:45:24.994566Z","shell.execute_reply.started":"2021-10-02T10:45:24.695352Z","shell.execute_reply":"2021-10-02T10:45:24.993574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter tuning with Optuna","metadata":{}},{"cell_type":"code","source":"# seed = 0\n\n# def objective(trial):\n#     fold = 0\n#     params = {\n#         'num_leaves': trial.suggest_int('num_leaves', 21, 30),\n#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1000, 20000),\n#         'max_depth': trial.suggest_int('max_depth', 0, 0),\n#         'max_bin': trial.suggest_int('max_bin', 200, 400),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.01),\n#         'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.00001, 5),\n#         'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.00001, 1),\n#         'min_gain_to_split': trial.suggest_float('min_gain_to_split', 1, 3),\n#         'feature_fraction': trial.suggest_float('feature_fraction', 0.05, 0.75),\n#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.78, 0.9),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 1)        \n#     }\n\n#     X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n#     X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n        \n#     y_train = X_train.claim\n#     y_valid = X_valid.claim\n    \n#     X_train = X_train[features]\n#     X_valid = X_valid[features]\n    \n#     model = LGBMClassifier(\n#             objective='binary',\n#             tree_learner='serial',\n#             seed=seed,\n#             n_estimators=50000,\n#             **params)\n    \n#     model.fit(X_train,\n#               y_train,\n#               early_stopping_rounds=500,\n#               eval_set=[(X_valid, y_valid)],\n#               eval_metric='auc',\n#               callbacks=[LightGBMPruningCallback(trial, 'auc')],\n#               verbose=1000)\n    \n#     valid_pred = model.predict_proba(X_valid)[:,1]\n        \n#     auc = roc_auc_score(y_valid, valid_pred)\n#     return auc\n\n# for i in range(3):\n#     study = optuna.create_study(direction=\"maximize\")\n#     study.optimize(objective, n_trials=40)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"%%time\n\nm = 7\ns = 26\n\ntest_preds = []\nvalid_preds = {}\nscores = []\n    \nfor fold in range(5):\n    X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n    X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n    X_test = df_test[features].copy()\n\n    valid_ids = X_valid.id.values.tolist()\n\n    y_train = X_train.claim\n    y_valid = X_valid.claim\n\n    X_train = X_train[features]\n    X_valid = X_valid[features]\n\n    params = {'num_leaves': 15,\n              'min_data_in_leaf': 2200,\n              'max_depth': 4,\n              'max_bin': 220,\n              'learning_rate': 0.010799862652877246,\n              'lambda_l1': 1.8358777923407985,\n              'lambda_l2': 0.0003751344396869442,\n              'min_gain_to_split': 2.850800313709466,\n              'feature_fraction': 0.44543603862631437,\n              'bagging_fraction': 0.7701524274455008,\n              'bagging_freq': 1}\n\n    model = LGBMClassifier(\n        objective='binary',\n        importance_type='split', #default=split. try gain\n        boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n        tree_learner='serial',\n        num_threads=-1,\n        random_state=s,\n        n_estimators=50000,\n        **params)\n\n    model.fit(X_train,\n              y_train,\n              early_stopping_rounds=500,\n              eval_set=[(X_valid, y_valid)],\n              eval_metric='auc',\n              verbose=1000)\n\n    valid_pred = model.predict_proba(X_valid)[:,1]\n    test_pred = model.predict_proba(X_test)[:,1]\n\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    test_preds.append(test_pred)\n    \n    score = roc_auc_score(y_valid, valid_pred)    \n    scores.append(score)\n    \nprint(f'Mean auc {np.mean(scores)}, std {np.std(scores)}')\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\nvalid_preds.columns = ['id', f'm{m}s{s}_pred']\nvalid_preds.to_csv(f'm{m}s{s}_valid_pred.csv', index=False)\n\nsample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\nsample_solution.columns = ['id', f'm{m}s{s}_pred']\nsample_solution.to_csv(f'm{m}s{s}_test_pred.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-02T11:18:22.425831Z","iopub.execute_input":"2021-10-02T11:18:22.426222Z","iopub.status.idle":"2021-10-02T11:19:26.870771Z","shell.execute_reply.started":"2021-10-02T11:18:22.426192Z","shell.execute_reply":"2021-10-02T11:19:26.869634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n\n# m = 7\n# s = 35\n\n# test_preds = []\n# valid_preds = {}\n# scores = []\n    \n# for fold in range(5):\n#     X_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n#     X_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n#     X_test = df_test[features].copy()\n\n#     valid_ids = X_valid.id.values.tolist()\n\n#     y_train = X_train.claim\n#     y_valid = X_valid.claim\n\n#     X_train = X_train[features]\n#     X_valid = X_valid[features]\n\n#     params = {'num_leaves': 15,\n#               'min_data_in_leaf': 2200,\n#               'max_depth': 4,\n#               'max_bin': 220,\n#               'learning_rate': 0.010799862652877246,\n#               'lambda_l1': 1.8358777923407985,\n#               'lambda_l2': 0.0003751344396869442,\n#               'min_gain_to_split': 2.850800313709466,\n#               'feature_fraction': 0.44543603862631437,\n#               'bagging_fraction': 0.7701524274455008,\n#               'bagging_freq': 1}\n\n#     model = LGBMClassifier(\n#         objective='binary',\n#         importance_type='split', #default=split. try gain\n#         boosting_type='gbdt', #default=gbdt. try dart, goss, rf\n#         tree_learner='serial',\n#         num_threads=-1,\n#         random_state=s,\n#         n_estimators=50000,\n#         **params)\n\n#     model.fit(X_train,\n#               y_train,\n#               early_stopping_rounds=500,\n#               eval_set=[(X_valid, y_valid)],\n#               eval_metric='auc',\n#               verbose=1000)\n\n#     valid_pred = model.predict_proba(X_valid)[:,1]\n#     test_pred = model.predict_proba(X_test)[:,1]\n\n#     valid_preds.update(dict(zip(valid_ids, valid_pred)))\n#     test_preds.append(test_pred)\n    \n#     score = roc_auc_score(y_valid, valid_pred)    \n#     scores.append(score)\n    \n# print(f'Mean auc{np.mean(scores)}, std {np.std(scores)}')\n\n# valid_preds = pd.DataFrame.from_dict(valid_preds, orient='index').reset_index()\n# valid_preds.columns = ['id', f'm{m}s{s}_pred']\n# valid_preds.to_csv(f'm{m}s{s}_valid_pred.csv', index=False)\n\n# sample_solution.claim = np.mean(np.column_stack(test_preds), axis=1)\n# sample_solution.columns = ['id', f'm{m}s{s}_pred']\n# sample_solution.to_csv(f'm{m}s{s}_test_pred.csv', index=False)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}