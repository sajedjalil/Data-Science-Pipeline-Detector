{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-04T13:19:38.419702Z","iopub.execute_input":"2021-09-04T13:19:38.420175Z","iopub.status.idle":"2021-09-04T13:19:38.435091Z","shell.execute_reply.started":"2021-09-04T13:19:38.420072Z","shell.execute_reply":"2021-09-04T13:19:38.433984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom skopt import BayesSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom warnings import filterwarnings\n\nfilterwarnings(\"ignore\", category=DeprecationWarning) \nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:19:38.628562Z","iopub.execute_input":"2021-09-04T13:19:38.628916Z","iopub.status.idle":"2021-09-04T13:19:41.085716Z","shell.execute_reply.started":"2021-09-04T13:19:38.62888Z","shell.execute_reply":"2021-09-04T13:19:41.084733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-sep-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:19:41.08736Z","iopub.execute_input":"2021-09-04T13:19:41.087775Z","iopub.status.idle":"2021-09-04T13:20:25.678681Z","shell.execute_reply.started":"2021-09-04T13:19:41.087732Z","shell.execute_reply":"2021-09-04T13:20:25.677731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = train.drop(['id','claim'],axis=1)\ny_train = np.array(train.claim)\nx_cols = x_train.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:20:25.680773Z","iopub.execute_input":"2021-09-04T13:20:25.68108Z","iopub.status.idle":"2021-09-04T13:20:26.05367Z","shell.execute_reply.started":"2021-09-04T13:20:25.681052Z","shell.execute_reply":"2021-09-04T13:20:26.052713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# as all are numerical columns so filling missing values with mean\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer = imputer.fit(x_train)\nx_train = imputer.transform(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:20:26.055171Z","iopub.execute_input":"2021-09-04T13:20:26.055446Z","iopub.status.idle":"2021-09-04T13:20:28.657724Z","shell.execute_reply.started":"2021-09-04T13:20:26.055418Z","shell.execute_reply":"2021-09-04T13:20:28.656735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = pd.DataFrame(data = x_train, columns=x_cols)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:20:28.659172Z","iopub.execute_input":"2021-09-04T13:20:28.6596Z","iopub.status.idle":"2021-09-04T13:20:28.664668Z","shell.execute_reply.started":"2021-09-04T13:20:28.659546Z","shell.execute_reply":"2021-09-04T13:20:28.66374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_train = pd.DataFrame(data = x_train, columns=x_cols)\nx_train","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:20:28.665824Z","iopub.execute_input":"2021-09-04T13:20:28.666216Z","iopub.status.idle":"2021-09-04T13:20:31.323245Z","shell.execute_reply.started":"2021-09-04T13:20:28.666186Z","shell.execute_reply":"2021-09-04T13:20:31.322351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0, stratify = y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:20:31.324543Z","iopub.execute_input":"2021-09-04T13:20:31.324825Z","iopub.status.idle":"2021-09-04T13:20:33.126529Z","shell.execute_reply.started":"2021-09-04T13:20:31.324798Z","shell.execute_reply":"2021-09-04T13:20:33.125442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bayesian Optimization","metadata":{}},{"cell_type":"code","source":"#tuning hyperparameters\nfrom bayes_opt import BayesianOptimization\nfrom skopt  import BayesSearchCV \nimport warnings\n#graph, plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#building models\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nimport time\nimport sys\n\n#metrics \nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport shap\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:20:33.128426Z","iopub.execute_input":"2021-09-04T13:20:33.128738Z","iopub.status.idle":"2021-09-04T13:20:40.69015Z","shell.execute_reply.started":"2021-09-04T13:20:33.128705Z","shell.execute_reply":"2021-09-04T13:20:40.688975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6,n_estimators=20000, output_process=False):\n    # prepare data\n    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n    # parameters\n    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf,min_sum_hessian_in_leaf,subsample):\n        params = {'application':'binary', 'metric':'auc'}\n        params['learning_rate'] = max(min(learning_rate, 1), 0)\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        params['max_bin'] = int(round(max_depth))\n        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n        params['subsample'] = max(min(subsample, 1), 0)\n                \n        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n        return max(cv_result['auc-mean'])\n     \n    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.001, 0.2),\n                                            'num_leaves': (20, 50),\n                                            'feature_fraction': (0.1, 1),\n                                            'bagging_fraction': (0.5, 1),\n                                            'max_depth': (5, 30),\n                                            'max_bin':(20,90),\n                                            'min_data_in_leaf': (20, 80),\n                                            'min_sum_hessian_in_leaf':(0,100),\n                                           'subsample': (0.01, 1.0)}, random_state=200)\n\n    \n    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n    \n    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n    \n    model_auc=[]\n    for model in range(len( lgbBO.res)):\n        model_auc.append(lgbBO.res[model]['target'])\n    \n    # return best parameters\n    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n\nopt_params = bayes_parameter_opt_lgb(X_train, Y_train, init_round=5, opt_round=10, n_folds=5, random_seed=6,n_estimators=10000)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-04T07:08:23.841377Z","iopub.execute_input":"2021-09-04T07:08:23.841861Z","iopub.status.idle":"2021-09-04T07:23:40.435999Z","shell.execute_reply.started":"2021-09-04T07:08:23.84182Z","shell.execute_reply":"2021-09-04T07:23:40.434669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will extract the best features","metadata":{}},{"cell_type":"code","source":"opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\nopt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\nopt_params[1]['min_data_in_leaf'] = int(round(opt_params[1]['min_data_in_leaf']))\nopt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\nopt_params[1]['objective']='binary'\nopt_params[1]['metric']='auc'\nopt_params[1]['is_unbalance']=True\nopt_params[1]['boost_from_average']=False\nopt_params=opt_params[1]\nopt_params","metadata":{"execution":{"iopub.status.busy":"2021-09-04T07:28:13.941527Z","iopub.execute_input":"2021-09-04T07:28:13.942044Z","iopub.status.idle":"2021-09-04T07:28:13.955214Z","shell.execute_reply.started":"2021-09-04T07:28:13.942005Z","shell.execute_reply":"2021-09-04T07:28:13.953885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ny_train = train.claim\nfeatures= [c for c in x_train.columns ]\nfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=31416)\noof = np.zeros(len(train))\npredictions = np.zeros(len(test))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=y_train.iloc[trn_idx])\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=y_train.iloc[val_idx])\n\n    num_round = 15000\n    clf = lgb.train(opt_params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 250)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(y_train, oof)))","metadata":{"execution":{"iopub.status.busy":"2021-09-04T07:30:22.958088Z","iopub.execute_input":"2021-09-04T07:30:22.958619Z","iopub.status.idle":"2021-09-04T07:43:02.987859Z","shell.execute_reply.started":"2021-09-04T07:30:22.958569Z","shell.execute_reply":"2021-09-04T07:43:02.985503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Importance","metadata":{}},{"cell_type":"code","source":"cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n        .groupby(\"Feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:20].index)\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\nplt.figure(figsize=(20,28))\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('Features importance (averaged/folds)')\nplt.tight_layout()\nplt.savefig('Feature_Importance.png')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T07:43:06.721637Z","iopub.execute_input":"2021-09-04T07:43:06.722083Z","iopub.status.idle":"2021-09-04T07:43:08.152313Z","shell.execute_reply.started":"2021-09-04T07:43:06.722044Z","shell.execute_reply":"2021-09-04T07:43:08.151534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the model","metadata":{}},{"cell_type":"code","source":"# explainer = shap.TreeExplainer(clf)\n# shap_values = explainer.shap_values(X_train)\n\n# shap.summary_plot(shap_values, X_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T07:43:13.121938Z","iopub.execute_input":"2021-09-04T07:43:13.122544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tree visualization\ngraph = lgb.create_tree_digraph(clf, tree_index=3, name='Tree3' )\ngraph.graph_attr.update(size=\"500,500\")\ngraph","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_id = test.id\nx_test = test.drop(['id'],axis=1)\n# filling the NaN with mean\nx_test = imputer.transform(x_test)\nx_test = pd.DataFrame(data = x_test, columns=x_cols)\nx_test = scaler.transform(x_test)\nx_test = pd.DataFrame(data = x_test, columns=x_cols)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:31:18.364899Z","iopub.execute_input":"2021-09-04T13:31:18.365495Z","iopub.status.idle":"2021-09-04T13:31:19.547875Z","shell.execute_reply.started":"2021-09-04T13:31:18.365447Z","shell.execute_reply":"2021-09-04T13:31:19.546936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submission(model,filename):\n    pred = model.predict(x_test, num_iteration=model.best_iteration)\n    pred = pd.DataFrame(pred,columns=['claim'])\n    sub = pd.concat([test_id,pred],axis=1)\n    sub.set_index('id',inplace=True)\n    sub.to_csv(f\"Submission_file_{filename}.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:31:22.865122Z","iopub.execute_input":"2021-09-04T13:31:22.865616Z","iopub.status.idle":"2021-09-04T13:31:22.871782Z","shell.execute_reply.started":"2021-09-04T13:31:22.865576Z","shell.execute_reply":"2021-09-04T13:31:22.870993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating submission file\nsubmission(clf,\"Tuned_lgbm\")\npred = pd.DataFrame(predictions,columns=['claim'])\nsub = pd.concat([test_id,pred],axis=1)\nsub.set_index('id',inplace=True)\nsub.to_csv(\"Submission_file_Model_raw.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-04T13:31:24.245164Z","iopub.execute_input":"2021-09-04T13:31:24.245646Z","iopub.status.idle":"2021-09-04T13:31:37.449955Z","shell.execute_reply.started":"2021-09-04T13:31:24.245611Z","shell.execute_reply":"2021-09-04T13:31:37.448949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I hope you guys enjoyed my kernel and do not forget to upvote if you think that it's helpful!**","metadata":{}}]}