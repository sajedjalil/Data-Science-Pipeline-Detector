{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**ì‹¤ìŠµ ëª©í‘œ**\n\nğŸ’¡ ë”¥ëŸ¬ë‹ ëª¨ë¸ (MLP, CNN, VGG19)ì„ ì´ìš©í•œ ê°œ vs.ê³ ì–‘ì´ ì´ë¯¸ì§€ ë¶„ë¥˜\n\nğŸ’¡ ëª¨ë¸ì´ ì´ë¯¸ì§€ì˜ ì–´ë–¤ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì˜€ëŠ”ì§€ ì‹œê°í™” ","metadata":{}},{"cell_type":"markdown","source":"**í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë° ì¶”ê°€ëœ ë°ì´í„° path í™•ì¸**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**zipíŒŒì¼ ì••ì¶• í•´ì œ**","metadata":{}},{"cell_type":"code","source":"from zipfile import ZipFile\n\nbase_path = '/kaggle/input/dogs-vs-cats/'\nunzip_path = '/kaggle/working/' # í˜„ì¬ ë””ë ‰í† ë¦¬\n\n# ë°˜ë³µë¬¸ ì´ìš©\nfor folder in os.listdir(path = base_path):\n    if folder.split(\".\")[1] == 'zip':\n        with ZipFile(base_path + folder, 'r') as zipfile:\n            zipfile.extractall(unzip_path)\n            print(f'{folder} ì••ì¶•í•´ì œ ì™„ë£Œ!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ë°ì´í„°ë¶„ì„ ë° ì „ì²˜ë¦¬","metadata":{}},{"cell_type":"markdown","source":"ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ì»´í“¨í„°ê°€ í•™ìŠµ í•  ìˆ˜ ìˆë„ë¡ ì „ì²˜ë¦¬ í•´ì¤€ë‹¤. ","metadata":{}},{"cell_type":"code","source":"train_dir = os.path.join(unzip_path, 'train')\ntest_dir = os.path.join(unzip_path, 'test1')\n\n# íŒŒì¼ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\ntrain_img_names = os.listdir(train_dir)\ntest_img_names = os.listdir(test_dir)\n\nprint('total training images : ', len(train_img_names))\nprint('total test images : ', len(test_img_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_names[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ì´ë¯¸ì§€ ì´ë¦„ê³¼ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ê°–ëŠ” dataframe ìƒì„±**","metadata":{}},{"cell_type":"code","source":"categories = list()\n\n# ë°˜ë³µë¬¸ ì´ìš©\nfor image in train_img_names:\n    category = image.split('.')[0]\n    if category == 'dog':\n        categories.append('dog')\n    else:\n        categories.append('cat')\n        \ndf = pd.DataFrame({'Image':train_img_names, 'Category':categories})[:2000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ğŸ“ŒTry it!!**","metadata":{}},{"cell_type":"code","source":"# ë§Œë“¤ì–´ì§„ ë°ì´í„°í”„ë ˆì„ dfë¥¼ ì¶œë ¥í•´ë³´ì.\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ë°ì´í„° ì‹œê°í™”**","metadata":{}},{"cell_type":"code","source":"# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = plt.figure(figsize=(5, 5))\nax = f.add_subplot()\nsns.countplot(data=df, x='Category', ax=ax)\n\nfor patch in ax.patches:\n    label_x = patch.get_x() + patch.get_width()/2\n    label_y = patch.get_y() + patch.get_height()/2\n    text_msg = str(int(patch.get_height())) \n    ax.text(label_x, label_y, text_msg, horizontalalignment='center', verticalalignment='center')\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"random í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ í™•ì¸í•˜ê¸°","metadata":{}},{"cell_type":"code","source":"import random\n\nsample = random.choice(train_img_names)\nsample_path = '/kaggle/working/train/' + sample\nplt.imshow(plt.imread(sample_path))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ğŸ“Œ Try it!!**\n\nì‹¤í–‰í• ë•Œë§ˆë‹¤ ì •ë§ë¡œ randomí•˜ê²Œ ì´ë¯¸ì§€ê°€ ì¶œë ¥ë˜ëŠ”ì§€ í™•ì¸í•´ë³´ì.","metadata":{}},{"cell_type":"code","source":"# í•œë²ˆì— ì—¬ëŸ¬ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥\npath = '/kaggle/working/train/'\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    img_path = path + df.Image[i]\n    \n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(plt.imread(img_path))\n    plt.xlabel(df.Category[i])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### í›ˆë ¨ë°ì´í„°, í…ŒìŠ¤íŠ¸ë°ì´í„° ë‚˜ëˆ„ê¸°","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df, test_size=0.25, stratify=df['Category'])\n# dataframeì˜ ê¸°ì¡´ ì¸ë±ìŠ¤ ì œê±°\ntrain = train.reset_index(drop=True)\n# test = test.reset_index(drop=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ğŸ **Try it !!!**\n\ntrain, test ë°ì´í„°ë¥¼ ê°ê° reset_index(drop=True) ì²˜ë¦¬ë¥¼ í–ˆì„ ë•Œì™€\n\ní•˜ì§€ ì•Šì•˜ì„ ë•Œ ë°ì´í„°í”„ë ˆì„ ì¸ë±ìŠ¤ ì°¨ì´ë¥¼ í™•ì¸í•˜ì—¬ ë³´ì„¸ìš”.","metadata":{}},{"cell_type":"markdown","source":"**í›ˆë ¨ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ë°ì´í„° ê°¯ìˆ˜ ì‹œê°í™”**","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(13,5))\nsns.countplot(data=train, x='Category', palette='magma', ax=ax[0])\nsns.countplot(data=test, x='Category', palette='magma', ax=ax[1])\n\nfor patch in ax[0].patches:\n    label_x = patch.get_x() + patch.get_width()/2\n    label_y = patch.get_y() + patch.get_height()/2\n    text_msg = str(int(patch.get_height())) \n    ax[0].text(label_x, label_y, text_msg, horizontalalignment='center', verticalalignment='center')\n\nfor patch in ax[1].patches:\n    label_x = patch.get_x() + patch.get_width()/2\n    label_y = patch.get_y() + patch.get_height()/2\n    text_msg = str(int(patch.get_height())) \n    ax[1].text(label_x, label_y, text_msg, horizontalalignment='center', verticalalignment='center')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kerasì˜ ImageDataGenerator ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì§„í–‰\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nheight, width, channel = (150, 150, 3)\n\ntrain_datagen = ImageDataGenerator(rescale=1. / 255.)\n\ntrain_generator = train_datagen.flow_from_dataframe(train,\n                                                   directory = './train',\n                                                   x_col='Image',\n                                                   y_col='Category',\n                                                   batch_size=32,\n                                                   class_mode='categorical',\n                                                   color_mode= 'rgb',\n                                                   target_size=(height, width))\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255.)\ntest_generator = test_datagen.flow_from_dataframe(test,\n                                                   directory = './train',\n                                                   x_col='Image',\n                                                   y_col='Category',\n                                                   batch_size=32,\n                                                   class_mode='categorical',\n                                                   color_mode= 'rgb',\n                                                   target_size=(height, width))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ëª¨ë¸ í›ˆë ¨","metadata":{}},{"cell_type":"code","source":"# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import\nimport tensorflow\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, InputLayer, Resizing\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization\nfrom tensorflow.keras.layers import MaxPool2D, GlobalMaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import SGD","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MLP","metadata":{}},{"cell_type":"code","source":"# MLP ëª¨ë¸ ì •ì˜\nmlp_model = Sequential()\n\nmlp_model.add(InputLayer((height, width, channel)))\nmlp_model.add(Resizing(48, 48, interpolation='bilinear'))\nmlp_model.add(Flatten()) \nmlp_model.add(Dense(2048, activation='relu'))\nmlp_model.add(Dense(1024, activation='relu'))\nmlp_model.add(Dense(512, activation='relu'))\nmlp_model.add(Dense(128, activation='relu'))\nmlp_model.add(Dense(2, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ëª¨ë¸ í™•ì¸\nmlp_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ëª¨ë¸ ì»´íŒŒì¼\nmlp_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n\n# ëª¨ë¸ í›ˆë ¨\nmlp_history = mlp_model.fit(train_generator,\n                           validation_data=test_generator,\n                           epochs=20\n                           )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ì •í™•ë„ì™€ ì†ì‹¤ê°’ í™•ì¸\n\nmlp_acc = mlp_history.history['accuracy']\nmlp_val_acc = mlp_history.history['val_accuracy']\nmlp_loss = mlp_history.history['loss']\nmlp_val_loss = mlp_history.history['val_loss']\n\nmlp_epochs = range(len(mlp_acc))\n\nplt.plot(mlp_epochs, mlp_acc, 'r', label='Training accuracy')\nplt.plot(mlp_epochs, mlp_val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(mlp_epochs, mlp_loss, 'r', label='Training Loss')\nplt.plot(mlp_epochs, mlp_val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### âœ… ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ ì‹œê°í™”","metadata":{}},{"cell_type":"code","source":"class_names = ['cat','dogs']\ndef plot_image(i, predictions_array, true_label, img):\n    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.imshow(img)\n\n    predicted_label = np.argmax(predictions_array)\n    true_label = np.argmax(true_label)\n    if predicted_label == true_label:\n        color = 'blue'\n    else:\n        color = 'red'\n\n    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n    predictions_array, true_label = predictions_array[i], true_label[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    thisplot = plt.bar(range(2), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1])\n    predicted_label = np.argmax(predictions_array)\n    true_label = np.argmax(true_label)\n\n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('blue')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = test_generator.next()\npredictions = mlp_model.predict(x)\n\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(4*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, predictions, y, x)\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions, y)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CNN","metadata":{}},{"cell_type":"code","source":"# CNN ëª¨ë¸ ì •ì˜\n\ncnn_model = Sequential()\n\ncnn_model.add(Conv2D(filters=32, kernel_size=3,activation=\"relu\", input_shape=(height, width, channel)))\ncnn_model.add(MaxPool2D(pool_size=2, strides=2))\ncnn_model.add(Conv2D(filters=64, kernel_size=3,activation=\"relu\"))\ncnn_model.add(MaxPool2D(pool_size=2, strides=2))\ncnn_model.add(Conv2D(filters=128, kernel_size=3, activation=\"relu\"))\ncnn_model.add(MaxPool2D(pool_size=2, strides=2))\ncnn_model.add(Flatten())\ncnn_model.add(Dense(units=512, activation=\"relu\"))\ncnn_model.add(Dropout(0.15))\ncnn_model.add(Dense(units=2, activation=\"softmax\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ëª¨ë¸ í™•ì¸\ncnn_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ëª¨ë¸ ì»´íŒŒì¼\ncnn_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# ëª¨ë¸ í›ˆë ¨\ncnn_history = cnn_model.fit(train_generator,\n                            validation_data=test_generator,\n                            epochs=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ëª¨ë¸ ì €ì¥\ncnn_model.save('cnn_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ì •í™•ë„ì™€ ì†ì‹¤ê°’ í™•ì¸\n\ncnn_acc = cnn_history.history['accuracy']\ncnn_val_acc = cnn_history.history['val_accuracy']\ncnn_loss = cnn_history.history['loss']\ncnn_val_loss = cnn_history.history['val_loss']\n\ncnn_epochs = range(len(cnn_acc))\n\nplt.plot(cnn_epochs, cnn_acc, 'r', label='Training accuracy')\nplt.plot(cnn_epochs, cnn_val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(cnn_epochs, cnn_loss, 'r', label='Training Loss')\nplt.plot(cnn_epochs, cnn_val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### âœ… CNN ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ ì‹œê°í™”","metadata":{}},{"cell_type":"code","source":"predictions = cnn_model.predict(x)\n\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(4*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, predictions, y, x)\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions, y)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VGG19","metadata":{}},{"cell_type":"code","source":"# VGG ëª¨ë¸ ì •ì˜\nimg_input = Input(shape = (height,width,channel))\n\n# Block 1\nx = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\nx = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\nx = MaxPool2D((2, 2), strides=(2, 2), name='block1_pool')(x)\nx = BatchNormalization()(x)\n\n# Block 2\nx = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\nx = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\nx = MaxPool2D((2, 2), strides=(2, 2), name='block2_pool')(x)\nx = BatchNormalization()(x)\n\n# Block 3\nx = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\nx = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\nx = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\nx = MaxPool2D((2, 2), strides=(2, 2), name='block3_pool')(x)\nx = BatchNormalization()(x)\n\n# Block 4\nx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\nx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\nx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\nx = MaxPool2D((2, 2), strides=(2, 2), name='block4_pool')(x)\nx = BatchNormalization()(x)\n\n# Block 5\nx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\nx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\nx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\nx = MaxPool2D((2, 2), strides=(2, 2), name='block5_pool')(x)\nx = BatchNormalization()(x)\n\nx = Flatten(name='flatten')(x)\nx = Dense(4096, activation='relu', name='fc1')(x)\nx = Dense(4096, activation='relu', name='fc2')(x)\nx = Dense(2, activation='softmax', name='predictions')(x)\n\nvgg_model = Model(img_input, x, name='vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ëª¨ë¸ í™•ì¸\nvgg_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ëª¨ë¸ ì»´íŒŒì¼\nvgg_model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n# ëª¨ë¸ í•™ìŠµ\nvgg_history = vgg_model.fit(train_generator,\n                            validation_data=test_generator,\n                            epochs=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ì •í™•ë„ ë° ì†ì‹¤ê°’ í™•ì¸\n\nvgg_acc = vgg_history.history['accuracy']\nvgg_val_acc = vgg_history.history['val_accuracy']\nvgg_loss = vgg_history.history['loss']\nvgg_val_loss = vgg_history.history['val_loss']\n\nvgg_epochs = range(len(vgg_acc))\n\nplt.plot(vgg_epochs, vgg_acc, 'r', label='Training accuracy')\nplt.plot(vgg_epochs, vgg_val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(vgg_epochs, vgg_loss, 'r', label='Training Loss')\nplt.plot(vgg_epochs, vgg_val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### âœ… VGG ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ ì‹œê°í™”","metadata":{}},{"cell_type":"code","source":"x, y = test_generator.next()\npredictions = vgg_model.predict(x)\n\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(4*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, predictions, y, x)\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions, y)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ëª¨ë¸ì´ ì–´ë– í•œ íŠ¹ì§•ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ í•œ ê±¸ê¹Œ!?\n\nğŸ‘€ì‹œê°í™” í•´ë³´ì! ","metadata":{}},{"cell_type":"code","source":"# ì €ì¥í•œ cnn ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\nfrom tensorflow.keras.models import load_model\nsaved_model = load_model('cnn_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ğŸTry it!!**\n\në¶ˆëŸ¬ì˜¨ ëª¨ë¸ ì •ë³´ë¥¼ í‘œì‹œí•´ë³´ì.","metadata":{}},{"cell_type":"code","source":"# ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ ì •ë³´ í™•ì¸\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**í›ˆë ¨ì— í¬í•¨ë˜ì§€ ì•Šì€ ì´ë¯¸ì§€ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°**","metadata":{}},{"cell_type":"code","source":"# ë¦¬ìŠ¤íŠ¸ í˜•íƒœì´ê¸° ë•Œë¬¸ì— head()ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ [:5]ë¡œ í™•ì¸\ntest_img_names[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from  tensorflow.keras.preprocessing import image\n\nimg_path = './test1/8961.jpg'\n# ëª¨ë¸ì´ í›ˆë ¨ë  ë•Œ ì…ë ¥ì— ì ìš©í•œ ì „ì²˜ë¦¬ ë°©ì‹ì„ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•´ì¤˜ì•¼í•©ë‹ˆë‹¤. (colorì •ë³´, ì´ë¯¸ì§€ í¬ê¸° ë“±)\n\nimg = image.load_img(img_path, target_size=(150, 150), color_mode='rgb')\nimg_tensor = image.img_to_array(img)\nimg_tensor = np.expand_dims(img_tensor, axis=0)\nimg_tensor /= 255.\n\n# ì´ë¯¸ì§€ í¬ê¸° (1, 150, 150, 3)\nprint(img_tensor.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ë¶ˆëŸ¬ì˜¨ ì´ë¯¸ì§€ í™•ì¸\nplt.imshow(img_tensor[0])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ëª¨ë¸ì´ ì‚¬ì§„ì„ë³´ê³  ê° ì¸µë³„ë¡œ ì–´ë–¤ íŠ¹ì§•ì„ ì¶”ì¶œí–ˆëŠ”ì§€ ì‚´í´ë³´ì.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import models\n\n\n# ìƒìœ„ 8ê°œ ì¸µì˜ ì¶œë ¥ì„ ì¶”ì¶œí•©\nlayer_outputs = [layer.output for layer in saved_model.layers[:8]]\n# ì…ë ¥ì— ëŒ€í•´ 8ê°œ ì¸µì˜ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ëª¨ë¸ì„ ìƒì„±\nactivation_model = models.Model(inputs=saved_model.input, outputs=layer_outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ì¸µì˜ í™œì„±í™”ë§ˆë‹¤ í•˜ë‚˜ì”© 8ê°œì˜ ë„˜íŒŒì´ ë°°ì—´ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:\nactivations = activation_model.predict(img_tensor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_layer_activation = activations[0]\nprint(first_layer_activation.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.matshow(first_layer_activation[0, :, :, 31], cmap='viridis')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\në‹¤ë¥¸ ì±„ë„ë„ ê·¸ë ¤ë³´ì.","metadata":{}},{"cell_type":"code","source":"plt.matshow(first_layer_activation[0, :, :, 9], cmap='viridis')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ì±„ë„ ìˆ˜ë¥¼ ë°”ê¾¸ì–´ ê°€ë©° í™•ì¸í•´ë³´ì\n\nê°•ì•„ì§€ ì–¼êµ´ ë¬´ëŠ¬ ì¤‘ ìƒ‰ì´ êµ¬ë¶„ë˜ëŠ” ì„ ì´ ëšœë ·íˆ ê´€ì°°ëœë‹¤.\n\nì´ì œ ë„¤íŠ¸ì›Œí¬ì˜ ëª¨ë“  í™œì„±í™”ì¸µì„ ì‹œê°í™” í•´ë´…ì‹œë‹¤.\n\n**íŠ¹ì„±ë§µ ê·¸ë¦¬ê¸°**","metadata":{}},{"cell_type":"code","source":"# ì¸µì˜ ì´ë¦„ì„ ê·¸ë˜í”„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©\nlayer_names = []\nfor layer in saved_model.layers[:8]:\n    layer_names.append(layer.name)\n\nimages_per_row = 16\n\n# íŠ¹ì„± ë§µ ê·¸ë¦¬ê¸°\nfor layer_name, layer_activation in zip(layer_names, activations):\n    # íŠ¹ì„± ë§µì— ìˆëŠ” íŠ¹ì„±ì˜ ìˆ˜\n    n_features = layer_activation.shape[-1]\n\n    # íŠ¹ì„± ë§µì˜ í¬ê¸° : (1, size, size, n_features)\n    size = layer_activation.shape[1]\n\n    # í™œì„±í™” ì±„ë„ì„ ìœ„í•œ ê·¸ë¦¬ë“œ í¬ê¸°\n    n_cols = n_features // images_per_row\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n\n    # ê° í™œì„±í™”ë¥¼ í•˜ë‚˜ì˜ í° ê·¸ë¦¬ë“œì— ì±„ì›ë‹ˆë‹¤\n    for col in range(n_cols):\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            # ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ê¸° ì¢‹ê²Œ íŠ¹ì„±ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤\n            channel_image -= channel_image.mean()\n            channel_image /= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size,\n                         row * size : (row + 1) * size] = channel_image\n\n    # ê·¸ë¦¬ë“œ ì¶œë ¥\n    scale = 1. / size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}