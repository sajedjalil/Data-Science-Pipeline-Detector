{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import ComplementNB\nfrom xgboost.sklearn import XGBClassifier\nfrom wordcloud import WordCloud\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/train_users_2.csv')\ntest = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/test_users.csv')\ntrain.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for different columns between train/test datasets\nprint(np.setdiff1d(train.columns, test.columns, assume_unique=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate both train & test datasets for further cleaning\nall_data = pd.concat([train.drop('country_destination', axis=1), test])\nall_data.dtypes\n\n# Change countries names' to numerical labels\nle = LabelEncoder()\ntrain_labels = le.fit_transform(train.country_destination)\ntarget_labels = pd.Series(train_labels, name='target')\nlist(le.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check numerical values\nall_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age contains weird entries that needs cleaning... I find ages greater than 110 to be rather wrong. Also, the minimum age to use/register/book on Airbnb is 18 years... So I will assume that entries below 18 is wrong??"},{"metadata":{},"cell_type":"markdown","source":"# Problem: Imbalanced Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.country_destination.value_counts().plot(kind='bar', color=plt.cm.tab20c(np.arange(len(train.country_destination.unique()))))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Problem: Way too many missing values\n* date_first_booking: Non present in the testing data, dropping it alltogether.\n* gender, age: could possibily be good features, need to draw some visualizations first to decide.\n* first_affiliate_tracked, language, first_device_type: very few missing values, will fill with mode\n* first_browser: this is a little bit tricky, but could analyze other features (device type, signup app, etc) and see if we can make an educated guess."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Clean the data\nall_data.replace(to_replace='-unknown-', value=np.nan, inplace=True)\n#all_data.replace(to_replace='Other/Unknown', value=np.nan, inplace=True)\nall_data.loc[all_data.age > 110, 'age'] = np.nan\nall_data.loc[all_data.age < 18, 'age'] = np.nan\nprint('Number of rows: {}'.format(len(train)))\nprint('\\nMissing Values as a percentage in training dataset')\nprint(all_data.iloc[:len(train)].isnull().sum().where(lambda x : x>0).dropna()/len(train))\nprint('\\nMissing Values as a percentage in testing dataset')\nprint(all_data.iloc[len(train):].isnull().sum().where(lambda x : x>0).dropna()/len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill language & first_affiliate_tracked with mode\n# drop date_first_booking\nall_data.language.fillna(all_data.language.mode()[0], inplace=True)\nall_data.first_affiliate_tracked.fillna(all_data.first_affiliate_tracked.mode()[0], inplace=True)\nall_data.drop('date_first_booking', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert dates to datetime format\nall_data.date_account_created = pd.to_datetime(all_data.date_account_created)\nall_data.timestamp_first_active = pd.to_datetime(all_data.timestamp_first_active, format='%Y%m%d%H%M%S')\nall_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy a new DF with fewer browser options\nplt.figure(figsize=(15,5))\nplt.subplot(121)\ntop_browsers = all_data.groupby('first_browser').id.count().nlargest(8).index\ndf = all_data.dropna(subset=['first_browser']).copy() # Drop Nulls to do the analysis\ndf.first_browser = df.first_browser.apply(lambda browser: 'Other' if browser not in top_browsers else browser)\nsns.countplot(x='first_browser', data=df, hue='signup_app' ,order=df.first_browser.value_counts().index)\nplt.xticks(rotation=30)\nplt.subplot(122)\nsns.countplot(x='first_browser',  data=df, hue='first_device_type' ,order=df.first_browser.value_counts().index)\nplt.xticks(rotation=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What can we conclude from this drawings:\n1. Mobile Safari is mostly used with Moweb, iOS signup apps and iPhone or iPads\n2. Chrome is mostly used over Web on Windows Desktops\n3. Safari is mostly used over Web on Mac Desktops..\n4. Chrome Mobile is mostly used with Android Phone"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mobile_Safari = all_data[all_data.first_device_type == 'iPad'].first_browser.value_counts().nlargest(1).index[0]\nall_data.loc[(all_data.first_device_type.isin(['iPad', 'iPhone']) | all_data.signup_app.isin(['Moweb', 'iOS'])) & \n             (all_data.first_browser.isnull()), 'first_browser'] = 'Mobile Safari'\nall_data.loc[(all_data.first_device_type == 'Windows Desktops') & (all_data.signup_app == 'Web') & \n             (all_data.first_browser.isnull()), 'first_browser'] = 'Chrome'\nall_data.loc[(all_data.first_device_type == 'Mac Desktops') & (all_data.signup_app == 'Web') & \n             (all_data.first_browser.isnull()), 'first_browser'] = 'Safari'\nall_data.loc[(all_data.first_device_type == 'Android Phone') & (all_data.first_browser.isnull()), 'first_browser'] = 'Chrome Mobile'\nall_data.first_browser.fillna(all_data.first_browser.mode()[0], inplace=True) # If any left, fill with mode.. (3% were left)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(all_data.isnull().sum().where(lambda x : x>0).dropna()/len(all_data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And we are left with only age/gender which have way too many nulls, I will just label them with -1.."},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creation Date Analysis\n1. How much popularity did Airbnb gain over the year?\n2. Which months are the most popular?\n1. Which year did most of Airbnb user base came from?"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,15))\nplt.subplot(221)\ngrouped_df = all_data.groupby([all_data.date_account_created.dt.year, all_data.date_account_created.dt.month]).count().id\ngrouped_df.plot(kind='line', xticks=range(1, len(grouped_df), 6), rot=45, color='g')\nplt.xlabel('Creation Date (Y, M)')\nplt.yticks([])\nplt.title('Development of user base over years')\n\nax = fig.add_subplot(222)\nall_data.groupby([all_data.timestamp_first_active.dt.year, \n                  all_data.timestamp_first_active.dt.month]).count().id.unstack().plot(\n                    kind='line', ax=ax, \n                    xticks=range(all_data.timestamp_first_active.dt.year.min(), \n                                 all_data.timestamp_first_active.dt.year.max()+1),\n                                 colormap='Paired')\nplt.title('Monthly new users development over years (first activity)')\nax.legend(title='Month')\n\nplt.subplot(223)\nall_data.groupby([all_data.date_account_created.dt.month]).count().id.plot(kind='bar', color='g')\nplt.title('New accounts by Month\\nJul, Aug & Sep are on top')\nplt.xlabel('Creation Month')\n\nplt.subplot(224)\nall_data.groupby([all_data.date_account_created.dt.year]).count().id.plot(kind='pie', shadow=True, autopct='%.1f%%', pctdistance=0.85)\nplt.title('Creation year as percentage of the total user base')\nplt.ylabel('User Base')\n\nplt.subplots_adjust(hspace=0.35)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Language Analysis: "},{"metadata":{"trusted":true},"cell_type":"code","source":"top_lang = all_data.language.value_counts(normalize=True).nlargest(1)\nprint('{} language is the most common used one, with percentage = {}% from the total users.'.format(top_lang.index[0].upper(), round(top_lang.values[0]*100, 2)))\nplt.figure(figsize=(8,6))\nplt.title('English is the most common language used')\nplt.xlabel('Language')\nplt.ylabel('Percentage of users')\nall_data.language.value_counts(normalize=True).plot(kind='bar', color='orange', rot=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sign Up Analysis: "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,15))\nplt.subplot(221)\nax = sns.countplot(x='signup_method', data=all_data, hue='first_device_type' ,order=all_data.signup_method.value_counts().index)\nax.legend(loc=1)\nplt.title('Signup method counts with different devices')\nplt.ylabel('')\nplt.subplot(222)\nsns.countplot(x=all_data.signup_flow)\nplt.ylabel('')\nplt.title('Signup flow counts')\n\nplt.subplot(223)\nsns.countplot(x=all_data.signup_app, order=all_data.signup_app.value_counts().index)\nplt.title('Signup application')\nplt.subplot(224)\ntop_x = 7\nsizes = np.append(all_data.first_browser.value_counts().iloc[:top_x].values, all_data.first_browser.value_counts().iloc[top_x+1:].values.sum())\nlabels = np.append(all_data.first_browser.value_counts().iloc[:top_x].index, 'Other')\nplt.pie(sizes, labels=labels, autopct='%.1f%%',\n        shadow=False, pctdistance=0.85, labeldistance=1.05, startangle=10, explode=[0.15 if (i == 0 or i == len(sizes)-1) else 0 for i in range(len(sizes))])\nplt.title('First browser used')\nplt.subplots_adjust(hspace=0.35)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Affiliate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.subplot(121)\ntop_x = 6\nsizes = np.append(all_data.affiliate_provider.value_counts().iloc[:top_x].values, all_data.affiliate_provider.value_counts().iloc[top_x+1:].values.sum())\nlabels = np.append(all_data.affiliate_provider.value_counts().iloc[:top_x].index, 'Other')\nplt.bar(x=range(top_x+1), height=sizes, tick_label=labels)\nplt.xticks(rotation=45)\nplt.title('Affiliate Providers')\nplt.subplot(122)\ngrouped_df = all_data.groupby('affiliate_channel').count().id.nlargest(len(all_data.affiliate_channel.unique()))\nexplode_thr = 4\nplt.pie(grouped_df, labels=grouped_df.index, autopct='%.1f%%', shadow=True, pctdistance=0.88, labeldistance=1.05, startangle=30, \n        explode = [0 if i < explode_thr else (i/len(grouped_df))-(explode_thr/len(grouped_df)) for i in range(len(grouped_df))])\nplt.title('Affiliate Channels')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sessions Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load user sessions and find the mean of each action along with most common actions..\nsessions = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/sessions.csv')\nsessions_grouped = sessions.groupby(['user_id', 'action']).secs_elapsed.mean()\ncrafted_features = pd.Series(sessions_grouped.index.get_level_values(1)).value_counts().nlargest().index\ncrafted_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unfortunately we only have sessions data for about half the users only... crafting a feature with this is unlikely\nprint('You have session data for {} of users'.format(round(len(sessions.user_id.unique())/len(all_data), 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sessions_df = sessions_grouped.unstack()[crafted_features]\nprint(sessions_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(11,8))\nsessions[sessions.action.isin(crafted_features)].groupby('action').secs_elapsed.mean().plot(kind='bar', rot=0)\nplt.ylabel('Average Elapsed Time In Seconds')\nplt.title('Most common 5 actions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = all_data.join(sessions_grouped.unstack()[crafted_features], how='outer', on='id')\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Attempts to find a feature to classify the unknown genders.... the header_userpic is the best one I could find, still not good enough\nplt.figure(figsize=(10,5))\nplt.subplot(121)\nsns.barplot(x='gender', y='header_userpic', data=all_data)\nplt.subplot(122)\nsns.kdeplot(data=all_data[all_data.gender == 'MALE'].age.rename('MALE'))\nsns.kdeplot(data=all_data[all_data.gender == 'FEMALE'].age.rename('FEMALE'))\nplt.xlabel('Age')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Age Gender Buckets Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"age_gender_countries = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/age_gender_bkts.csv')\nplt.figure(figsize=(15,12))\nplt.subplot(221)\nsorted_df = age_gender_countries.groupby([\"country_destination\"]).population_in_thousands.sum().reset_index().sort_values('population_in_thousands', ascending=False)\nsns.barplot(x=\"country_destination\", y=\"population_in_thousands\", hue=\"gender\", order=sorted_df.country_destination, data=age_gender_countries, ci=None)\nplt.title('Countries Visited By Gender')\nplt.xlabel('Country')\nplt.ylabel('Population in Thousands')\nplt.subplot(222)\nage_gender_countries.groupby([\"age_bucket\"]).population_in_thousands.sum().loc[age_gender_countries.age_bucket.iloc[:21].values[::-1]].plot(kind='bar', rot=45, color=plt.cm.tab20c(np.arange(len(age_gender_countries.age_bucket.unique()))))\nplt.title('Age Buckets vs Number Of Users Who Made At Least a Booking in 2015')\nplt.xlabel('Age Bucket')\nplt.subplot(212)\nplt.title('Age Buckets per Country vs Count')\nbuckets_count = len(age_gender_countries.age_bucket.unique())\nax = sns.barplot(x='country_destination', y=\"population_in_thousands\", \n                 hue='age_bucket', hue_order=age_gender_countries.age_bucket.iloc[:buckets_count].values[::-1], \n                 data=age_gender_countries, ci=None, palette=sns.color_palette(\"tab20c\", buckets_count))\nax.legend(title='Age Bucket', bbox_to_anchor=(1, 0.5), loc=6)\nplt.xlabel('Country of Destination')\nplt.ylabel('Population in Thousands')\nplt.subplots_adjust(hspace=0.35)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Countries Area and Language Levenshtein Distance"},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/countries.csv')\ncountries.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A comparison of countries area..\nwordcloud = WordCloud(background_color='white').generate_from_frequencies(dict(zip(countries.country_destination.values, countries.destination_km2.values)))\nfig, ax = plt.subplots(1,1,figsize=(10,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# An engineered feature to see if people prefer to travel to countries close to them with minor language levenshtein distance\nplt.figure(figsize=(10,5))\ncountries_lang_distance = train.merge(countries, on='country_destination', how='outer')[['language_levenshtein_distance',\n                                                                                         'distance_km']]\ncountries_lang_distance=(countries_lang_distance-countries_lang_distance.min())/(countries_lang_distance.max()-countries_lang_distance.min()) #Normalize..\ncountries_lang_distance.dropna(how='all').mean(axis=1).plot(kind='hist')\nplt.title('No relation could be seen')\nplt.xlabel('Mean of Language Levenshtein Distance and Real Distance of Destination')\nplt.ylabel('Number of travellers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding of Categorial Features:\nchoosen_ohe_features = ['gender', 'language', 'affiliate_provider', 'first_affiliate_tracked', 'affiliate_channel',\n                    'signup_app', 'first_device_type','first_browser']\n\nohe_df = pd.get_dummies(all_data[choosen_ohe_features])\n\nnumerical_features = [all_data.timestamp_first_active.dt.year.rename('first_active_year'), \n                      all_data.timestamp_first_active.dt.month.rename('first_active_month'), \n                      all_data.date_account_created.dt.year.rename('account_creation_year'), \n                      all_data.date_account_created.dt.month.rename('account_creation_month'), \n                      all_data.age]\n\n\nnum_df = pd.concat(numerical_features, axis=1)\n\n# changing month to cyclical feature\nnum_df['firth_active_month_sin'] = np.sin((num_df.first_active_month-1)*(2.*np.pi/12))\nnum_df['firth_active_month_cos'] = np.cos((num_df.first_active_month-1)*(2.*np.pi/12))\nnum_df['account_creation_month_sin'] = np.sin((num_df.account_creation_month-1)*(2.*np.pi/12))\nnum_df['account_creation_month_cos'] = np.cos((num_df.account_creation_month-1)*(2.*np.pi/12))\nnum_df.drop(['first_active_month', 'account_creation_month'], axis=1, inplace=True)\n\nnum_df=(num_df-num_df.min())/(num_df.max()-num_df.min()) #Normalize..\nnum_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([num_df, ohe_df], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resplitting into train/test and calculating accuracy for random guess\nnew_train = df.iloc[:len(train)]\nnew_test = df.iloc[len(new_train):]\nprint('If you randomly guess using the same distribution, you should have an accuracy around {}%'.format(round(target_labels.value_counts(normalize=True).nlargest(1).values[0]*100, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\n\nnclasses = len(np.unique(target_labels))\nnfeatures = np.size(new_train, axis=1)\n\ntarget_labels_keras = to_categorical(target_labels)\n\n# keras model\nmodel = Sequential()\nmodel.add(Dense(nfeatures, activation='elu', kernel_initializer='he_normal', input_shape=(nfeatures,)))\nmodel.add(Dense(150, activation='elu', kernel_initializer='he_normal'))\nmodel.add(Dense(100, activation='elu', kernel_initializer='he_normal'))\nmodel.add(Dense(50, activation='elu', kernel_initializer='he_normal'))\nmodel.add(Dense(20, activation='elu', kernel_initializer='he_normal'))\nmodel.add(Dense(15, activation='elu', kernel_initializer='he_normal'))\nmodel.add(Dense(nclasses, activation='softmax', kernel_initializer='he_normal'))\n\n# compile model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n#fit model\nmodel.fit(new_train, target_labels_keras, validation_split=0.15, epochs=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(new_test)\ny_pred = np.flip(np.argsort(y_pred), axis=1)[:, :5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([test.id.repeat(5).reset_index(drop=True), pd.Series(y_pred.ravel()).rename('country')], axis=1)\nsubmission['country'] = le.inverse_transform(submission.country)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = ComplementNB()\n# model = MultinomialNB()\n# model = XGBClassifier(n_estimators=25, max_depth=7, learning_rate=0.2, \n#                       objective='multi:softprob', seed=555, subsample=0.5, colsample_bytree=0.5)  \n#model = RandomForestClassifier(n_estimators=25, random_state=555, max_depth=7, random_seed=555)\n# model.fit(new_train, target_labels)\n# y_pred = model.predict(new_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}