{"cells":[{"metadata":{},"cell_type":"markdown","source":"It's is a fork of Alex Shonenkov kernel with TTA added.\n\nTTA means test time augmentation, which can improve the accuracy while testing.\n\n[Alex Shonenkov kernel Link here](https://www.kaggle.com/shonenkov/train-inference-gpu-baseline/)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import packages\n!pip install -q efficientnet_pytorch > /dev/null\nfrom glob import glob\nfrom sklearn.model_selection import GroupKFold\nimport cv2\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nimport sklearn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Different transforms","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Original\ndef get_test_transforms1():\n    return A.Compose([\n        A.Resize(height=512, width=512, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.0)\n\n# HorizontalFlip\ndef get_test_transforms2():\n    return A.Compose([\n        A.HorizontalFlip(p=1),\n        A.Resize(height=512, width=512, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.0)\n\n# VerticalFlip\ndef get_test_transforms3():\n    return A.Compose([\n        A.VerticalFlip(p=1),\n        A.Resize(height=512, width=512, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.0)\n\n# HorizontalFlip & VerticalFlip\ndef get_test_transforms4():\n    return A.Compose([\n        A.HorizontalFlip(p=1),\n        A.VerticalFlip(p=1),\n        A.Resize(height=512, width=512, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use model","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"DATA_ROOT_PATH = '../input/alaska2-image-steganalysis'\n\nfrom efficientnet_pytorch import EfficientNet\n\n\ndef get_net():\n    net = EfficientNet.from_pretrained('efficientnet-b2')\n    net._fc = nn.Linear(in_features=1408, out_features=4, bias=True)\n    return net\n\n\nnet = get_net().cuda()\n\ncheckpoint = torch.load('../input/model33/best-checkpoint-033epoch.bin')\nnet.load_state_dict(checkpoint['model_state_dict'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get result","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetSubmissionRetriever(Dataset):\n\n    def __init__(self, image_names, transforms1, transforms2, transforms3, transforms4):\n        super().__init__()\n        self.image_names = image_names\n        self.transforms1 = transforms1\n        self.transforms2 = transforms2\n        self.transforms3 = transforms3\n        self.transforms4 = transforms4\n\n    def __getitem__(self, index: int):\n        image_name = self.image_names[index]\n\n        image1 = cv2.imread(f'{DATA_ROOT_PATH}/Test/{image_name}', cv2.IMREAD_COLOR)\n        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image1 /= 255.0\n\n        sample = {'image': image1}\n        sample1 = self.transforms1(**sample)\n        image1 = sample1['image']\n\n        sample2 = self.transforms2(**sample)\n        image2 = sample2['image']\n\n        sample3 = self.transforms3(**sample)\n        image3 = sample3['image']\n\n        sample4 = self.transforms4(**sample)\n        image4 = sample4['image']\n        return image_name, image1, image2, image3, image4\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]\n\n\ndataset = DatasetSubmissionRetriever(\n    image_names=np.array([path.split('/')[-1] for path in glob('../input/alaska2-image-steganalysis/Test/*.jpg')]),\n    transforms1=get_test_transforms1(),\n    transforms2=get_test_transforms2(),\n    transforms3=get_test_transforms3(),\n    transforms4=get_test_transforms4(),\n)\n\ndata_loader = DataLoader(\n    dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n)\n\nresult = {'Id': [], 'Label': []}\nfor step, (image_names, images1, images2, images3, images4) in enumerate(data_loader):\n    print(step, end='\\r')\n\n    y_pred1 = net(images1.cuda())\n    y_pred1 = 1 - nn.functional.softmax(y_pred1, dim=1).data.cpu().numpy()[:, 0]\n\n    y_pred2 = net(images2.cuda())\n    y_pred2 = 1 - nn.functional.softmax(y_pred2, dim=1).data.cpu().numpy()[:, 0]\n\n    y_pred3 = net(images3.cuda())\n    y_pred3 = 1 - nn.functional.softmax(y_pred3, dim=1).data.cpu().numpy()[:, 0]\n\n    y_pred4 = net(images4.cuda())\n    y_pred4 = 1 - nn.functional.softmax(y_pred4, dim=1).data.cpu().numpy()[:, 0]\n\n    result['Id'].extend(image_names)\n    # The weights can change by yourself\n    result['Label'].extend((y_pred1 * 3 + y_pred2 + y_pred3 + y_pred4) / 6)\n\nsubmission = pd.DataFrame(result)\nsubmission.to_csv('submission.csv', index=False)\nprint(submission.head())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}