{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport re\nimport sys, gc, os\nfrom IPython.display import display\n\n\n#import shap\n#shap.initjs()\n#import featuretools as ft\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import LinearSVR\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.preprocessing import MinMaxScaler, Normalizer, MaxAbsScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import (StandardScaler, MinMaxScaler, PowerTransformer, QuantileTransformer ,LabelEncoder,\n                                   OneHotEncoder,OrdinalEncoder)\n\nimport lightgbm as lgb\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\n\nimport optuna","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/tabular-playground-series-feb-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-feb-2021/test.csv')\ndf_sub = pd.read_csv('../input/tabular-playground-series-feb-2021/sample_submission.csv')\n\nSEED = 1991","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df_train['target']\ndf_train.drop(['id', 'target'], axis=1, inplace=True)\ndf_test.drop('id', axis=1, inplace=True)\n\nto_drop = target[target <= 4].index\ntarget.drop(to_drop, inplace=True)\ndf_train.drop(to_drop, inplace=True)\n\nplt.figure(figsize=(10,5))\nsns.histplot(target, color='slategray', stat='frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CAT = df_train.columns.tolist()[:10]\nNUM = df_train.columns.tolist()[10:]\ncols = df_train.columns.tolist()\n\nct = ColumnTransformer([('onehot',OrdinalEncoder(), CAT),\n                        #('quantile',QuantileTransformer(random_state=SEED, n_quantiles=1500),NUM)\n                        ('minmax', MinMaxScaler(), NUM)])\n\ntrain_data = ct.fit_transform(df_train)\ntest_data = ct.transform(df_test)\n\ntrain_data = pd.DataFrame(train_data, columns = cols)\ntest_data = pd.DataFrame(test_data, columns = cols)\n\ntrain_data[CAT] = train_data[CAT] / 10\ntest_data[CAT] = test_data[CAT] / 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def basic_fe(df):\n    \n    # Manually multiply and drop specific columns\n    \n    #df['cont_003'] = df['cont0'] * df['cont8']\n\n    df['cont001'] = df['cont8'] * df['cont0']\n    df['cont002'] = df['cont9'] * df['cont0']\n    df['cont003'] = df['cont9'] * df['cont5']\n    df['cont004'] = df['cont8'] * df['cont5']\n    #df['cont005'] = df['cont2'] * df['cont4']\n    #df['cont006'] = df['cont1'] * df['cont3']\n    #df['cont007'] = df['cont13'] * df['cont1']\n    \n    #df['cat001'] = df['cat2'] * df['cat1']\n    #df['cat002'] = df['cat3'] * df['cat4']\n    \n    #df.drop('cont5', axis=1, inplace=True)\n    #df.drop('cont9', axis=1, inplace=True)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = basic_fe(train_data)\ntest_data = basic_fe(test_data)\n\nprint(train_data.shape, test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Optuna"},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial,data=train_data,target=target):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2, random_state=SEED)\n    \n    params = {\n        'metric': 'rmse', \n        'random_state': SEED,\n        'n_estimators': 20000,\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.35,0.4,0.45,0.5,0.6,0.7,0.75,0.8,0.85]),\n        'subsample': trial.suggest_categorical('subsample', [0.3,0.35,0.4,0.5,0.6,0.65,0.7,0.75,0.8,0.85]),\n        'learning_rate': trial.suggest_categorical('learning_rate', \n                                                   [0.001,0.002,0.003,0.004,0.005,0.006,0.008,0.01,0.015,0.02,0.03]),\n        'max_depth': trial.suggest_categorical('max_depth', [-1,10,20]),\n        'num_leaves' : trial.suggest_int('num_leaves', 1, 300),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n    }\n    \n    model = lgb.LGBMRegressor(**params)  \n    \n    model.fit(train_x, train_y, eval_set=[(test_x,test_y)], early_stopping_rounds=300, verbose=False)\n    \n    preds = model.predict(test_x)\n    \n    rmse = mean_squared_error(test_y, preds, squared=False)\n    \n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=70)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.visualization.plot_param_importances(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = study.best_params   \nparams['random_state'] = SEED\nparams['n_estimators'] = 20000 \nparams['metric'] = 'rmse'\n\nparams['cat_smooth'] = params.pop('min_data_per_groups')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_FOLDS = 7\n\nkf = KFold(n_splits = N_FOLDS)\noof = np.zeros(len(target))\n\npreds_folds_lgb = np.zeros(len(test_data))\n\n\nfor train_ind, test_ind in tqdm(kf.split(train_data)):\n    X_train = train_data.iloc[train_ind]\n    X_val = train_data.iloc[test_ind]\n    y_train = target.iloc[train_ind]\n    y_val = target.iloc[test_ind]\n\n    model = lgb.LGBMRegressor(**params)\n    \n    model.fit(X_train, y_train, eval_set = ((X_val, y_val)), early_stopping_rounds = 300, verbose = 1000)\n    p = model.predict(X_val)\n    oof[test_ind] = p\n\n    preds_folds_lgb += model.predict(test_data)/N_FOLDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'rmse on training data: {np.round(mean_squared_error(target, oof, squared=False),5)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub['target'] = preds_folds_lgb\ndf_sub.to_csv('submission_lgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_params_kfold = {\n     'reg_alpha': 5.2,\n     'reg_lambda': 1.2,\n     'min_data_in_leaf': 10,\n     'colsample_bytree': 0.35,\n     'subsample': 0.75,\n     'learning_rate': 0.001,\n     'max_depth': -10,\n     'num_leaves': 120,\n     'min_child_samples': 285,\n     #'random_state':SEED,\n     'verbose':-1,\n     'n_estimators': 50000,\n     'metric': 'rmse',\n     'cat_smooth': 23\n}","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}