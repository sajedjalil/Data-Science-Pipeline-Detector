{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n# (Tabular Playground Series - Feb 2021 Competition.)\n## by (Peter Gamal Girgis)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os       \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import LinearRegression,Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# open train Dataframe CSV file\npath = '/kaggle/input/tabular-playground-series-feb-2021/'\nX = pd.read_csv(path + '/train.csv', index_col='id')\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# open test Dataframe CSV file\nX_test_full = pd.read_csv(path + '/test.csv', index_col='id')\nX_test_full.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# open submission Dataframe CSV file\nsubmission = pd.read_csv(path + '/sample_submission.csv', index_col='id')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove rows with missing target, separate target from predictors\nX = X.dropna(axis=0, subset=['target'])\ny = X.target\nX = X.drop(['target'], axis=1)\n\n# We will drop columns with missing values if founded (not in this DF)\ncols_with_missing = [col for col in X.columns if X[col].isnull().any()]\nX = X.drop(cols_with_missing, axis=1)\nX_test = X_test_full.drop(cols_with_missing, axis=1)\n\n# Break off Validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_full","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select categorical columns with relatively low cordinality\ncategorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and X_train_full[cname].dtype =='object']\n\n# Select numeric columns\nnumerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64','float64']]\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[('inputer', SimpleImputer(strategy='most_frequent')),\n                                         ('onehot', OneHotEncoder(handle_unknown='ignore'))\n                                         ])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),\n                                              ('cat', categorical_transformer, categorical_cols)\n                                              ])\n\n# Define model\nmodel = RandomForestRegressor(n_estimators=200, random_state=0)\n# We can improve the model\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n\n# Fit the model\nmy_pipeline.fit(X_train, y_train)\n\n# Get Predictions\npredictions = my_pipeline.predict(X_valid)\n\n# Calculate MAE\nmae = mean_absolute_error(y_valid, predictions)\nprint('Mean Absolute Error: ', mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing of test data, fit model\npreds_test = my_pipeline.predict(X_test) # Your code here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot: Worest model\nplt.scatter(y_valid, predictions)\nplt.title('Pipeline model',weight = 'bold', size = 15)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save New DataFrame in CSV format at new created folder\noutput = pd.DataFrame({'id': X_test.index, 'target':preds_test })\noutput.to_csv('Pipelinet_Submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}