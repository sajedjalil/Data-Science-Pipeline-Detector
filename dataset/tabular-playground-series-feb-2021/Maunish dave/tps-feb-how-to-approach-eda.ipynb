{"cells":[{"metadata":{},"cell_type":"markdown","source":"## TPS(feb): How to EDA. \n\nEDA (exploratory data analysis) is very important and most ignored part of Data Science.<br/>\nEDA allows us to understand our data better and helps us in data preprocessing.<br/>\n\nwhen we are solving a real world problem with the help of data only making models is not enough we need to comunicate our findings as well.\n\nIn this notebook I will explain how to get started with EDA and what things to look for in a data.\n\nThis notebook uses matplotlib, seaborn and plotly for making graphs and plots.\n\nThat said let's get started."},{"metadata":{},"cell_type":"markdown","source":"## Importing LibrariesðŸ“—\n\nHere I am importing basic libraries which is required for data loading, manupilating and  plotting."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport time\nimport tqdm\nimport random\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\nimport plotly.express as px \nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.model_selection import train_test_split\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What problem are we trying to solve ?\n\nKaggle provides us with predetermined problem that we need to solve but that is not always true in real world we need to define the problem before solving it.\n\nSo first step is to ask what problem are we trying to solve,answer is not always as simple as regression, classification ,time-series.\nfor example it could be someting like how can we increase sales of certain product, how to advertise so that it reaches interested customer, how to recommend better movies and shows, how to secure people from spam emails etc.\n\nWell here we are doing no such thing. Here we need to create a regression model which effeciently determines relationship between independent and target variables."},{"metadata":{},"cell_type":"markdown","source":"## Loading Data ðŸ’½\n\nHere we are provided with 3 files one train.csv which contains all the training data it consists of 10 categorical and 14 continous features and a target column other is test.csv on which we have to make prediction 3rd file submission.csv shows format of submission file.\n\nLet's load this files and see shape of each file."},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = '../input/tabular-playground-series-feb-2021'\ntrain_data = pd.read_csv(f'{folder_path}/train.csv')\ntest_data = pd.read_csv(f'{folder_path}/test.csv')\nsample = pd.read_csv(f'{folder_path}/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"{0}Number of rows in train data: {1}{2}\\n{0}Number of columns in train data: {1}{3}\".format(y_,r_,train_data.shape[0],train_data.shape[1]))\nprint(\"{0}Number of rows in test data: {1}{2}\\n{0}Number of columns in test data: {1}{3}\".format(m_,r_,test_data.shape[0],test_data.shape[1]))\nprint(\"{0}Number of rows in sample : {1}{2}\\n{0}Number of columns in sample : {1}{3}\".format(c_,r_,sample.shape[0],sample.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking at the Data\n\nNext step obviously is to look at the data and see what columns do we have.\n\nwe can see data is not very wide only 26 columns which is good narrow data is easy to analyse."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None) # for displaying all the columns of dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So data is very clear first is id which basically is like a unique number for each row. \n\nWe can see there are 10 categorical variables cat0 to cat9 ,14 continous variables cont0 to cont13.There is no mention whether categorical columns are nominal or ordinal."},{"metadata":{},"cell_type":"markdown","source":"## Always check for missing values.\n\nIn kaggle competitions data is usually very clean and requires very less preprocessing but that is not always true in real world. In real world data is very messy and inconsistent and has many missing values so we should always look for missing values in each column before any further analysis. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As I said in Kaggle competitions data is very clean so there is are no missing values in any column, but if there were missing values we need to preprocess them. There are three basic methods for dealing with missing values.\n\nIf there are too many missing values in a column it is better to remove that column.If there are some missing values in a column we should fill them using various filling techniques.If there are too few missing values maybe we can remove those rows with missing values.\n\nSometimes missing values in a column can act as a additional data we can create a seprate column indicating missing value in particular column and use it as a feature."},{"metadata":{},"cell_type":"markdown","source":"## Let's begin plotting.\n\nRaw data do not provide much information so we make graphs to bring insight from it.\n\nGraphs and plots are good way to communicate our findings to other.\n\nThere are some basics we need to know about plotting.\nThere are two basic simple types of plotting Univariate graphs and multivariate graphs. In Univariate graphing we try to detect patterns and anamolies in single variable and in multivariate we try to find relationship between different variables."},{"metadata":{},"cell_type":"markdown","source":"## Distribution of continous columns\n\nDistribution of continous column shows what values are more and less likely to occure. It also reveals if there are certain values which are far away from other values\n\nGo to method for looking at distribution of continous column is distplot in seaborn another method is boxplot.\n\nMean, min, max, std are some stats which reveals more about data. So we will write a function that will do all this thing in one go."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = [f'cat{i}' for i in range(10)]\ncont_features = [f'cont{i}' for i in range(14)]\nall_features = cat_features + cont_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\ndef distribution1(feature,color1,color2,df=train_data):\n    plt.figure(figsize=(15,7))\n    \n    plt.subplot(121)\n    dist = sns.distplot(df[feature],color=color1)\n    a = dist.patches\n    xy = [(a[i].get_x() + a[i].get_width() / 2,a[i].get_height()) \\\n          for i in range(1,len(a)-1) if (a[i].get_height() > a[i-1].get_height() and a[i].get_height() > a[i+1].get_height())]\n    \n    for i,j in xy:\n        dist.annotate(\n            s=f\"{i:.3f}\",\n            xy=(i,j), \n            xycoords='data',\n            ha='center', \n            va='center', \n            fontsize=11, \n            color='black',\n            xytext=(0,7), \n            textcoords='offset points',\n        )\n    \n    qnt = df[feature].quantile([.25, .5, .75]).reset_index(level=0).to_numpy()\n    plt.subplot(122)\n    box = sns.boxplot(df[feature],color=color2)\n    for i,j in qnt:\n        box.annotate(str(j)[:4],xy= (j-.05,-0.01),horizontalalignment='center')\n        \n    print(\"{}Max value of {} is: {} {:.2f} \\n{}Min value of {} is: {} {:.2f}\\n{}Mean of {} is: {}{:.2f}\\n{}Standard Deviation of {} is:{}{:.2f}\"\\\n      .format(y_,feature,r_,df[feature].max(),g_,feature,r_,df[feature].min(),b_,feature,r_,df[feature].mean(),m_,feature,r_,df[feature].std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution1('cont0','blue','yellow');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there is no resemblance to normal distribution here so data might require some transformation before feeding it to model.\ndata is almost in the range of 0 to 1 almost and box plot reveals that most of data is in range of 0.4 to 0.6.\n\nlet's look at another feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution1('cont1','magenta','red');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"well cont1 is bit strange as there are gaps in the disbtibution you can see there are pillars in data it looks as if data is partially continous partially categorical."},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution1('cont2','yellow','pink');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cont2 also does not look anything like normal distribution and there is some anamoly in range of 0.9 to 1. Maybe we should have closer look in that area."},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution1('cont2','green','yellow',df=train_data[train_data['cont2']>=0.9]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"well this part of cont2 looks like a normal distribution and there are outliers in the distribution on right side."},{"metadata":{},"cell_type":"markdown","source":"Plotting and analysing all the continous features is time taking so lets see all the distribution at same time."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\ncolors = ['#8ECAE6','#219EBC','#023047',\n          '#023047','#023047','#0E402D',\n          '#023047','#023047','#F77F00',\n          '#D62828','#4285F4','#EA4335',\n          '#FBBC05','#34A853']\n\nfor i,feature in enumerate(cont_features):\n    plt.subplot(2,7,i+1)\n    sns.distplot(train_data[feature],color=colors[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well None of the distribution are normal distribution and there are peaks in all the distribution and one other thing is that all the peaks have a sharp what i meana is slope around them are very steep"},{"metadata":{},"cell_type":"markdown","source":"Categorical columns EDA.\n\nCategorical columns add valuable information in data.\n\nsuposse that we have a store which sells various products. so categorical data could be something like male or female which can be used to find out which sex is more likely to buy certain product. If we have data from many stores than store can be a categorical data which can be used to regulate product requirements of that store. These were examples of nominal categorical data. Ordinal catgorical data could be movie rating between 1 to 10. \n\nOther thing to look for in a categorical variable is balance in count of each category. which we will see in this notebook.\n\nFirst graph that i usually make for categorical data is countplot.\n\nI will write a function which will show countplot and also annotate it."},{"metadata":{"trusted":true},"cell_type":"code","source":"def countplot1(feature,df=train_data):\n    cnt = sns.countplot(df[feature])\n    for g in cnt.patches:\n        cnt.annotate(f\"{g.get_height()}\",(g.get_x()+g.get_width()/3,g.get_height()+50))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(dpi=100)\ncountplot1('cat0');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that there is huge imbalance in category A and B. such variable do not provide enough information when we feed it into model unless distribution of target for cat A and B are very different which we will see later.\n\nLet's see countplot of all the category at the same time"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfor i, feature in enumerate(cat_features):\n    plt.subplot(2,5,i+1)\n    countplot1(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cat1 is very well balanced. cat0, cat2, cat4, cat6, cat7, have one category which is dominating others. In cat3,cat5,cat8 and cat9 two categories are dominating."},{"metadata":{},"cell_type":"markdown","source":"Now we will look at interactions between cont-cont, cat-cat and cont-cat features.\n\nThis is the part where we can find some patterns which can help us in making business decisions. we can answers questions like what is the effect of increase in price on sale of product. on which day do people buy certain product. What are chances of catching certain disease in certain month.\n\n\nWhen you are looking at continous data first thing that you should do is plot a correlation matrix. Correlation matrix gives us how much effect a variable is having on other variable this. So we could focus on relationship between strongly correlated features.\n\nI like using plotly for correlation matrix you can use seaborn as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_data[cont_features+['target']].corr()\nfig = px.imshow(corr)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we look at variables from cont5 to cont12 we see some strong positive correlation.\nand value cont12 and cont2 has strongest negative correlation of -0.3.\ncont12 and cont5 shows highest correlation value of 0.63 so let's analyse those.\n\nTo look at relationship between continous variable we can use scatterplot but there is a more powerful tool in seaborn which plots regression plot which is called lmplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\nsns.lmplot(x='cont12',y='cont5',line_kws={\"color\":\"green\"},data=train_data)\nsns.lmplot(x='cont12',y='cont2',line_kws={\"color\":\"green\"},data=train_data);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"well it looks like there is no pattern to be found here which was expected as correlation value of 0.63 and -0.3 is not big enough.\n\nSo there is nothing much to find in relationship between continous variable but if you want to see relationship between all the continous variable we can use PairGrid in sns and plot scatter and kde on it.\n\nWe will use only 1000 sample for PariGrid as it takes lot of time."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_grid(data,color1,color2,color3):\n    f = sns.PairGrid(data)\n    plt.figure(figsize=(10,10))\n    f.map_upper(plt.scatter,color = color1)\n    f.map_lower(sns.kdeplot,color = color2)\n    f.map_diag(sns.kdeplot, lw=3, legend=False,color = color3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_grid(train_data.sample(n=1000),'#EA4335','#FBBC05','#34A853');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot helps us to see all the variables against each other so we can plot this at the begining and futher analyse those variable which looks interesting\n\nAt first glance I do not see any variable that stands out."},{"metadata":{},"cell_type":"markdown","source":"So now let us move on to finding relationship between continous and categorical variable.\nFirst thing I do while comparing continous variable with categorical is see that can categorical variable seprate distribution of target."},{"metadata":{"trusted":true},"cell_type":"code","source":"def distribution2(cat_feature,cont_feature,df=train_data):\n    sns.histplot(train_data,x=cont_feature,hue=cat_feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\ndistribution2('cat1','target');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One might say that most of the distribution is overlapping but I would say that there is a good difference. At the time of modeling model will give huge importance to this feature.\n\nLet us see this plot for all the cat features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i, feature in enumerate(cat_features):\n    plt.subplot(5,2,i+1)\n    distribution2(feature,'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like cat1, cat3, cat5 are good at seprating target data.\n\nWe can use same plots for finding relationship between any other continous variable and cat variable but we can also use boxplot for this purpose let us see how to do that.\n\nWe will look at relationship between cont0 and cat9"},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxploting1(feature,category,df=train_data):\n    sns.boxplot(x=feature, y=category, data=df,whis=[0, 100], width=.6, palette=\"vlag\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nboxploting1('cont1','cat9')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us see how  cat1 seprates other continous variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfor i,feature in enumerate(cont_features):\n    plt.subplot(2,7,i+1)\n    boxploting1(feature,'cat1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also use more than one category to make different types of countplots.\n\nThis type of graphs can be used to answer questions like which products sells more on each day of week.\nOr for example if we have a data of patients with disease X and Y we can plot how many patient had disease Y which has and does not have diesase X.\n\nLet's make a function for making this plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"def countplot2(cat1,cat2,df=train_data):\n    cnt = sns.countplot(data =df,x=cat1,hue=cat2)\n    for g in cnt.patches:\n        cnt.annotate(f\"{g.get_height()}\",(g.get_x()+g.get_width()/3,g.get_height()+50))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\ncountplot2('cat1','cat9')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see if the cat1 is A then we have more chance of having L(green) than in B.\nLet's plot one more such plot between cat3 and cat5"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\ncountplot2('cat3','cat5');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also use more than two categorical variable to make countplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(data=train_data,x='cat3', hue='cat5', col='cat1',kind='count',height=7, aspect=.7);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How to use Dimensnality Reduction in EDA ?\n\nDimensionality Reduction is exactly like it sounds, it reduces dimension basic idea of Dimensionality Reduction is finding few dimensions which represents whole data. Most used Dimensionality reduction technique is PCA (principle component analysis).Dimensionality reduction can be used to reduce dimensions so we can plot them. We cannot plot 14 dimension but we can plot 2 or 3 dimension.\n\nSo I am going to write a function which will show pairplot between all the components of pca and I will use color to add target in the plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"def pca_plot1(features,n_components,target,nrows=10**4):\n    pca = PCA(n_components=n_components)\n    train_d = train_data.sample(n=nrows).fillna(train_data.mean())\n    train_g_pca = pca.fit_transform(train_d[features])\n\n    total_var = pca.explained_variance_ratio_.sum()*100\n    labels = {str(i): f\"PC {i+1}\" for i in range(n_components)}\n\n    fig = px.scatter_matrix(\n        train_g_pca,\n        dimensions=range(n_components),\n        labels=labels,\n        title=f\"Total explained variance ratio{total_var:.2f}%\",\n        color=train_d[target].values\n    )\n\n    fig.update_traces(diagonal_visible=True,opacity=0.5)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_plot1(cont_features,4,'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well there is nothing much we stand out clearly but sometime you might find something that is usefull\n\nWe can also use 3 components and plot a 3d graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pca_plot_3d(features,target,nrows=10**4):\n    pca = PCA(n_components=3)\n    train_d = train_data.sample(n=nrows).fillna(train_data.mean())\n    train_g_pca = pca.fit_transform(train_d[features])\n\n    total_var = pca.explained_variance_ratio_.sum()*100\n\n    fig = px.scatter_3d(\n        train_g_pca,x=0,y=1,z=2,\n        title=f\"Total explained variance ratio{total_var:.2f}%\",\n        color=train_d[target].values,\n        labels={'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n    )\n\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_plot_3d(cont_features,'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ðŸš§ work in Progress ðŸš§\n\nI will keep on editing and adding stuff in this notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}