{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Jigsaw pre-processing\nThe process of converting data to something a computer can understand is referred to as pre-processing. One of the major forms of pre-processing is to filter out useless data.","metadata":{}},{"cell_type":"markdown","source":"- by visualizing the data  https://www.kaggle.com/andrej0marinchenko/jigsaw-data-vizualization-for-beginnersv\n- analyzed the result https://www.kaggle.com/c/jigsaw-toxic-severity-rating/discussion/294164\n- concluded that it was necessary to pre-process the text before toxicity analysis","metadata":{}},{"cell_type":"code","source":"import pandas as pd  # data analysis library\nimport numpy as np  # comprehensive mathematical functions, random number generators, linear algebra routines, Fourier transforms, and more\n\n#nlp\nimport string  # working with string constants\nimport re  # regular expressions\nimport nltk  # Natural Language Toolkit\n# NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, \n# along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, \n# and an active discussion forum.\nfrom nltk.corpus import stopwords  # In natural language processing, useless words (data), are referred to as stop words. \n\n\n# import matplotlib.pyplot as plt  # provides an implicit way of plotting\n# import seaborn as sns  # for visualization\n# from tqdm import tqdm  # progressbar decorator for iterators\n# import os  # for operating system\n\n# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator  # word cloud building library\n\n# import warnings  # error processing\n# warnings.filterwarnings(\"ignore\")\n\n# from collections import defaultdict  # if the key is not found in the method, then a new entry is created instead of KeyError. The type of this new entry is specified by the defaultdict argument.\n\n# from itertools import cycle  # contains some inbuilt functions for generating sequences using iterators\n# plt.style.use('ggplot')\n# color_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\n# color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n\n\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', None)\npd.set_option('max_rows', None)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:19:34.173169Z","iopub.execute_input":"2021-12-13T13:19:34.173727Z","iopub.status.idle":"2021-12-13T13:19:34.834994Z","shell.execute_reply.started":"2021-12-13T13:19:34.173597Z","shell.execute_reply":"2021-12-13T13:19:34.833883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at the data names and size\n!ls -Flash --color ../input/jigsaw-toxic-severity-rating/","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:19:37.044089Z","iopub.execute_input":"2021-12-13T13:19:37.044706Z","iopub.status.idle":"2021-12-13T13:19:37.818416Z","shell.execute_reply.started":"2021-12-13T13:19:37.044667Z","shell.execute_reply":"2021-12-13T13:19:37.817647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\nprint(f'Validation Data csv is of shape: {val.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:19:39.895381Z","iopub.execute_input":"2021-12-13T13:19:39.896255Z","iopub.status.idle":"2021-12-13T13:19:40.163635Z","shell.execute_reply.started":"2021-12-13T13:19:39.896211Z","shell.execute_reply":"2021-12-13T13:19:40.162744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:21:46.151047Z","iopub.execute_input":"2021-12-13T13:21:46.151346Z","iopub.status.idle":"2021-12-13T13:21:46.163821Z","shell.execute_reply.started":"2021-12-13T13:21:46.151317Z","shell.execute_reply":"2021-12-13T13:21:46.162804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clean Text\n\n-  \\ d - matches any one digit and replaces the expression [0-9];\n-  \\ D - excludes all digits and replaces [^ 0-9];\n-  \\ w - replaces any number, letter, or underscore;\n-  \\ W - any character except Latin, numbers or underscore;\n-  \\ s - matches any whitespace character;\n-  \\ S - describes any non-whitespace character.\n\n-  \".\"    аny single character except newline \\ n.\n-  \"?\"    0 or 1 occurrence of the pattern to the left\n-  \"+\"    1 or more occurrences of the pattern on the left\n-  \"*\"    0 or more occurrences of the pattern on the left\n-  \"\\w\"   Any number or letter (\\ W - everything except letter or number)\n-  \"\\d\"   Any digit [0-9] (\\ D - everything except a digit)\n-  \"\\s\"   Any whitespace character (\\ S is any non-whitespace character)\n-  \"\\b\"   Word boundary\n-  \"[..]\" One of the characters in brackets ([^ ..] - any character except those in brackets)\n-  \"\\\"    Escaping special characters (\\. Stands for period or \\ + for plus sign)\n-  \"^ and $\"      Beginning and end of line respectively\n-  \"{n, m}\"       n to m occurrences ({, m} - 0 to m)\n-  \"a | b\"        Matches a or b\n-  \"()\"           Groups the expression and returns the found text\n-  \"\\t, \\n, \\r\"    Tab, newline, and carriage return characters respectively","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n# stop = stopwords.words('english')\n\n\ndef clean_text(text):\n    text = text.lower()  # convert to lower case\n    \n    # remove unnecessary characters and words\n    text = text.replace('\\n', ' ')\n    text = text.replace('(\\xa0)', ' ')\n    text = text.replace('(&lt)', '')\n    text = text.replace('(&gt)', '')\n    text = text.replace(\"\\\\\", \"\")\n    \n    # process links to sites\n    text = text.replace('https?://\\S+|www\\.\\S+', ' social medium ')   # with or without(http),://, one or more non-white space character, OR www, .,one or more non-white space character\n    text = text.replace(\"http://\", \"\")\n    text = text.replace(\"www.\", \"\")\n    text = text.replace(\"https://\", \"\")\n    text = text.replace(\"wikipedia.org\", \"\")\n    \n    # Replace symbols\n    text = text.replace(\"$\", \"s\") \n    text = text.replace(\"@\", \"a\")    \n    text = text.replace(\"!\", \" ! \")\n    text = text.replace(\"?\", \" ? \")    \n    \n\n    # Replace character combinations\n    text = re.sub(r'<[^<]+?>', '', text)\n    text = re.sub(r'\\s+', ' ', text)\n    text = re.sub(r'<[^<]+?>', '', text) \n\n#     text = re.sub(\"[0-9]\", '', text)  # remove all numbers\n# a lot of uncensored words are written using numbers, simply deleting which we will lose important information\n# '4r5e':'arse', 'ar5e':'arse', '5h1t':'shit', '5hit': 'shit', 'a55':'ass', b!tch, 'c0ck' d1ck f_u_c_k, l3i+ch, l3itch, ma5terb8 #OFC - Of fuckin course\n    # text = re.sub('\\d', ' ', text)  # remove all numbers\n    # text = re.sub(\"\\D\", '', text)  # delete everything except the number\n    text = text.replace(\"0\", \"o\")\n    text = text.replace(\"1\", \"i\") \n    text = text.replace(\"2\", \"l\") \n    text = text.replace(\"3\", \"e\")\n    text = text.replace(\"4\", \"a\") \n    text = text.replace(\"5\", \"s\") \n    text = text.replace(\"6\", \"g\")\n    text = text.replace(\"7\", \"t\") \n#     text = text.replace(\"8\", \"ate\")\n    text = text.replace(\"9\", \"g\")\n  \n    text = text.replace(\"+\", \"t\") \n    text = text.replace(\"!\", \"i\") \n    text = text.replace(\"|\", \"i\")   \n    \n    text = text.replace(\"f ck\", \" fuck \")   \n    text = text.replace(\"i88\", \" it is ok \")  \n    text = text.replace(\"i8\", \" ok \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n    text = text.replace(\"f ck\", \" fuck \")  \n\n    text = text.replace(\"#ofc\", \" of fuckin course \")\n    text = text.replace(\"fggt\", \" faggot \")\n    text = text.replace(\"your\", \" your \")\n    text = text.replace(\"self\", \" self \")\n    text = text.replace(\"cuntbag\", \" cunt bag \")\n    text = text.replace(\"fartchina\", \" fart china \")    \n    text = text.replace(\"youi\", \" you i \")\n    text = text.replace(\"cunti\", \" cunt i \")\n    text = text.replace(\"sucki\", \" suck i \")\n    text = text.replace(\"pagedelete\", \" page delete \")\n    text = text.replace(\"cuntsi\", \" cuntsi \")\n    text = text.replace(\"i'm\", \" i am \")\n    text = text.replace(\"offuck\", \" of fuck \")\n    text = text.replace(\"centraliststupid\", \" central ist stupid \")\n    text = text.replace(\"hitleri\", \" hitler i \")\n    text = text.replace(\"i've\", \" i have \")\n    text = text.replace(\"i'll\", \" sick \")\n    text = text.replace(\"fuck\", \" fuck \")\n    text = text.replace(\"f u c k\", \" fuck \")\n    text = text.replace(\"shit\", \" shit \")\n    text = text.replace(\"bunksteve\", \" bunk steve \")\n    text = text.replace('wikipedia', ' social medium ')\n    text = text.replace(\"faggot\", \" faggot \")\n    text = text.replace(\"delanoy\", \" delanoy \")\n    text = text.replace(\"jewish\", \" jewish \")\n    text = text.replace(\"sexsex\", \" sex \")\n    text = text.replace(\"allii\", \" all ii \")\n    text = text.replace(\"i'd\", \" i had \")\n    text = text.replace(\"'s\", \" is \")\n    text = text.replace(\"youbollocks\", \" you bollocks \")\n    text = text.replace(\"dick\", \" dick \")\n    text = text.replace(\"cuntsi\", \" cuntsi \")\n    text = text.replace(\"mothjer\", \" mother \")\n    text = text.replace(\"cuntfranks\", \" cunt \")\n    text = text.replace(\"ullmann\", \" jewish \")\n    text = text.replace(\"mr.\", \" mister \")\n    text = text.replace(\"aidsaids\", \" aids \")\n    text = text.replace(\"njgw\", \" nigger \")\n    text = text.replace(\"wiki\", \" social medium \")\n    text = text.replace(\"administrator\", \" admin \")\n    text = text.replace(\"gamaliel\", \" jewish \")\n    text = text.replace(\"rvv\", \" vanadalism \")\n    text = text.replace(\"admins\", \" admin \")\n    text = text.replace(\"pensnsnniensnsn\", \" penis \")\n    text = text.replace(\"pneis\", \" penis \")\n    text = text.replace(\"pennnis\", \" penis \")\n    text = text.replace(\"pov.\", \" point of view \")\n    text = text.replace(\"vandalising\", \" vandalism \")\n    text = text.replace(\"cock\", \" dick \")\n    text = text.replace(\"asshole\", \" asshole \")\n    text = text.replace(\"youi\", \" you \")\n    text = text.replace(\"afd\", \" all fucking day \")\n    text = text.replace(\"sockpuppets\", \" sockpuppetry \")\n    text = text.replace(\"iiprick\", \" iprick \")\n    text = text.replace(\"penisi\", \" penis \")\n    text = text.replace(\"warrior\", \" warrior \")\n    text = text.replace(\"loil\", \" laughing out insanely loud \")\n    text = text.replace(\"vandalise\", \" vanadalism \")\n    text = text.replace(\"helli\", \" helli \")\n    text = text.replace(\"lunchablesi\", \" lunchablesi \")\n    text = text.replace(\"special\", \" special \")\n    text = text.replace(\"ilol\", \" i lol \")\n   \n    \n    \n    \n    text = re.sub(r'\\b[uU]\\b', 'you', text)\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n    \n\n    # text = re.sub('\\W', ' ', text)  # will remove any character except Latin, numbers or underscore;\n    # text = re.sub('\\w', ' ', text) # this entry will remove all letters - it will help you see how many punctuation marks and other symbols are used\n    text = re.sub('\\s+', ' ', text)  # will remove more than one whitespace character\n    # text = re.sub('\\S+', ' ', text)  # will remove everything except the whitespace character.\n    \n    text = re.sub(r'\\b([^\\W\\d_]+)(\\s+\\1)+\\b', r'\\1', re.sub(r'\\W+', ' ', text).strip(), flags=re.I)  # remove repeating words coming immediately one after another\n    # text = re.sub(r'([a-z])\\2+', r'\\1', text)  # remove all repeating characters going one by (more than two letters)\n\n#     text = re.sub(r'(.)\\1+', r'\\1', text)  # remove all repeated characters one by one (more than two characters)\n#     text = re.sub(r'(\\w)\\1(\\1+)',r'\\1',text)\n#     text = re.sub(r\"(\\w)\\1{2,}\", r\"(\\w)\\1{2}\", text) \n    text = re.sub(r'(.)\\1+', r'\\1\\1', text) # 2 or more characters are replaced by 2 characters\n    \n    text = re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', text, flags = re.I)\n    \n    # Regular expression        r '((\\ b \\ w + \\ b. {1,2} \\ w + \\ b) +). + \\ 1'\n    # finds each occurrence of multiple sequences of alphanumeric characters separated by one or two [any characters] \n    # (to cover the case where words are separated not only by a space, but possibly a period or comma and a space), \n    # and then repeats after doing some [any character ] of indeterminate length. Then\n    \n    # re.sub(r '((\\ b \\ w + \\ b. {1,2} \\ w + \\ b) +). + \\ 1', r '\\ 1', s, flags = re.I)\n    # replaces such occurrences with the first multiple set of alphanumeric characters, separated by one or two [any character], \n    # be sure to ignore case (since a repeated phrase can sometimes appear at the beginning of a sentence).\n\n    \n    text = re.sub(\"[:|♣|'|§|♠|*|/|?|=|%|&|-|#|•|~|^|>|<|►|_]\", '', text)\n    text = text.strip(' ')  # will remove spaces at the beginning and end of the line\n\n    \n#     print(stopwords.words('english'))  # view all stop words\n    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')  # formula\n    text = pattern.sub('', text)  # dell oll stop words\n        \n    \n    return text\n\n    \n#     in process","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:20:03.093424Z","iopub.execute_input":"2021-12-13T13:20:03.093736Z","iopub.status.idle":"2021-12-13T13:20:03.13589Z","shell.execute_reply.started":"2021-12-13T13:20:03.093701Z","shell.execute_reply":"2021-12-13T13:20:03.134867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val['less_toxic'] = val['less_toxic'].apply(clean_text)\nval['more_toxic'] = val['more_toxic'].apply(clean_text)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# val[0:10]\nval[10:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import modules Lemmatizer\nfrom nltk.stem import WordNetLemmatizer\n \nlemmatizer = WordNetLemmatizer()\n \n# print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n# print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n \n# # a denotes adjective in \"pos\"\n# print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n\n\n# lemmatizer = nltk.stem.WordNetLemmatizer()  # Lemmatize using WordNet’s built-in morphy function. Returns the input word unchanged if it cannot be found in WordNet.\n# Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context\n# to the words. So it links words with similar meanings to one word. \n#Text preprocessing includes both Stemming as well as Lemmatization. Many times people find these two terms confusing. Some treat these two as the same. Actually, lemmatization is preferred over\n# Stemming because lemmatization does morphological analysis of the words.\n\n\ndef lemmatize_text(text):\n    return lemmatizer.lemmatize(text)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val['less_toxic'] = val['less_toxic'].apply(lemmatize_text)\nval['more_toxic'] = val['more_toxic'].apply(lemmatize_text)\nval.head(10)\n\n# output list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# import these modules\nfrom nltk.stem import PorterStemmer  \n# Stemming is the process of producing morphological variants of a root / base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. \n# A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”.\n\n  \nps = PorterStemmer()\n     \n    \ndef stemmerize_text(text):   \n    return ps.stem(text)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val['less_toxic'] = val['less_toxic'].apply(stemmerize_text)\nval['more_toxic'] = val['more_toxic'].apply(stemmerize_text)\nval.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### step2","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()  # convert to lower case\n    \n    # remove unnecessary characters and words\n    text = text.replace(' wo wo', ' woo woo ')\n    text = text.replace('numbskul', ' numbskull ')\n    \n    \n       \n    \n    return text\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}