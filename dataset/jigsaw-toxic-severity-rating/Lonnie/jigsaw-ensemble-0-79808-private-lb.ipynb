{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Thanks @andrej0marinchenko for his [work](https://www.kaggle.com/andrej0marinchenko/jigsaw-ensemble-0-86)\n(please appreciate and upvote the original author)","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.base import TransformerMixin, BaseEstimator\nimport re \nimport scipy\nfrom scipy import sparse\nimport gc \nfrom IPython.display import display, HTML\nfrom pprint import pprint\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:22:18.234203Z","iopub.execute_input":"2021-12-24T14:22:18.234948Z","iopub.status.idle":"2021-12-24T14:22:19.180512Z","shell.execute_reply.started":"2021-12-24T14:22:18.23491Z","shell.execute_reply":"2021-12-24T14:22:19.179629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configurations","metadata":{}},{"cell_type":"code","source":"# 0.2 ?\n# 0.3 ?\n# 0.35 0.89 0.893\n# 0.4 0.889 0.892\nalpha_value = 0.35\n\n# 10 0.885\n# 8 0.887\n# 7 0.893\n# 6 0.890\n# 5 0.885\nn_folds = 7\n# 0 0.887\n# 0.03 0.890\n# 0.04 0.890\n# 0.05 0.892\n# 0.06 0.892\n# 0.07 0.893\n# 0.08 0.893\n# 0.09 0.891\n# 0.10 0.887 ?\n# 0.15 0.883 ?\n# 0.2 0.879 ?\nbert_ratio = 0.08","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"def clean_validation_data(data):\n    less_string = []\n    larger_string = []\n    less_list = []\n    conat_string = []\n    for i in range(len(data)):\n        less_toxic = data.iloc[i][\"less_toxic\"]\n        more_toxic = data.iloc[i][\"more_toxic\"]\n        less = less_toxic < more_toxic\n        if less:\n            less_string.append(less_toxic)\n            larger_string.append(more_toxic)\n        else:\n            less_string.append(more_toxic)\n            larger_string.append(less_toxic)\n        less_list.append(1 if less else 0)\n        conat_string.append(less_string[-1] + \"_\" + larger_string[-1])\n    df = pd.DataFrame({\"left\": less_string, \"right\": larger_string, \"concat\": conat_string, \"less\": less_list})\n    concat_score = dict()\n    concat_count = dict()\n    for i in range(len(df)):\n        concat = df.iloc[i][\"concat\"]\n        if concat in concat_score:\n            concat_score[concat] += df.iloc[i][\"less\"]\n            concat_count[concat] += 1\n        else:\n            concat_score[concat] = df.iloc[i][\"less\"]\n            concat_count[concat] = 1\n    concat_average_score = np.array(list(concat_score.values()), dtype=\"float\") / np.array(list(concat_count.values()), dtype=\"float\")\n    concat_score_df = pd.DataFrame({\"concat\": concat_score.keys(), \"average_score\": concat_average_score})\n    concat_score_dict = dict()\n    for i in range(len(concat_score_df)):\n        concat = concat_score_df.iloc[i][\"concat\"]\n        average_score = concat_score_df.iloc[i][\"average_score\"]\n        concat_score_dict[concat] = average_score\n    is_valids = []\n    for i in range(len(df)):\n        if df.iloc[i][\"less\"] == 1:\n            is_valid = concat_score_dict[df.iloc[i][\"concat\"]] > 0.5\n        else:\n            is_valid = df.iloc[i][\"is_valid\"] = concat_score_dict[df.iloc[i][\"concat\"]] < 0.5\n        is_valids.append(is_valid)\n    df[\"is_valid\"] = is_valids\n    df = df[df.is_valid == True]\n    less_toxics = []\n    more_toxics = []\n    concat_set = set()\n    for i in range(len(df)):\n        less = df.iloc[i][\"less\"]\n        left = df.iloc[i][\"left\"]\n        right = df.iloc[i][\"right\"]\n        concat = df.iloc[i][\"concat\"]\n        if concat in concat_set:\n            continue\n        concat_set.add(concat)\n        if less:\n            less_toxics.append(left)\n            more_toxics.append(right)\n        else:\n            less_toxics.append(right)\n            more_toxics.append(left)\n    clean_df = pd.DataFrame({\"less_toxic\": less_toxics, \"more_toxic\": more_toxics})\n    return clean_df","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:23:04.158596Z","iopub.execute_input":"2021-12-24T14:23:04.158884Z","iopub.status.idle":"2021-12-24T14:23:04.176271Z","shell.execute_reply.started":"2021-12-24T14:23:04.158851Z","shell.execute_reply":"2021-12-24T14:23:04.175529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training data \n\n## Convert the label to SUM of all toxic labels (This might help with maintaining toxicity order of comments)","metadata":{}},{"cell_type":"code","source":"\ndf = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\nprint(df.shape)\n\nfor col in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n    print(f'****** {col} *******')\n    display(df.loc[df[col]==1,['comment_text',col]].sample(10))","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:22:23.026734Z","iopub.execute_input":"2021-12-24T14:22:23.027001Z","iopub.status.idle":"2021-12-24T14:22:25.048937Z","shell.execute_reply.started":"2021-12-24T14:22:23.02697Z","shell.execute_reply":"2021-12-24T14:22:25.048138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Give more weight to severe toxic \n# 2 9 6 0.892\n# 2 10 6 0.893\ndf['insult'] = df.insult * 1.5\ndf['obscene'] = df.obscene * 1.5\ndf['severe_toxic'] = df.severe_toxic * 2\ndf['threat'] = df.threat * 10\ndf['identity_hate'] = df.identity_hate * 6\ndf['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\ndf['y'] = df['y']/df['y'].max()\n\ndf = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:22:30.975827Z","iopub.execute_input":"2021-12-24T14:22:30.976078Z","iopub.status.idle":"2021-12-24T14:22:31.018055Z","shell.execute_reply.started":"2021-12-24T14:22:30.976051Z","shell.execute_reply":"2021-12-24T14:22:31.017417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['y'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:22:33.415213Z","iopub.execute_input":"2021-12-24T14:22:33.415813Z","iopub.status.idle":"2021-12-24T14:22:33.429309Z","shell.execute_reply.started":"2021-12-24T14:22:33.415772Z","shell.execute_reply":"2021-12-24T14:22:33.428558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create 3 versions of the data","metadata":{}},{"cell_type":"code","source":"frac_1 = 0.3\nfrac_1_factor = 1.2\n\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = pd.concat([df[df.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n                        df[df.y==0].sample(n=int(len(df[df.y>0])*frac_1*frac_1_factor) , \n                                            random_state = 10*(fld+1))], axis=0).sample(frac=1, random_state = 10*(fld+1))\n\n    tmp_df.to_csv(f'/kaggle/working/df_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:22:37.917451Z","iopub.execute_input":"2021-12-24T14:22:37.917906Z","iopub.status.idle":"2021-12-24T14:22:39.230034Z","shell.execute_reply.started":"2021-12-24T14:22:37.917867Z","shell.execute_reply":"2021-12-24T14:22:39.229306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create 3 versions of __clean__ data","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    return [lemmatizer.lemmatize(w) for w in text]\n\ndef clean(data, col):\n    \n    data[col] = data[col].str.replace(r\"what's\", \"what is \")    \n    data[col] = data[col].str.replace(r\"\\'ve\", \" have \")\n    data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n    data[col] = data[col].str.replace(r\"n't\", \" not \")\n    data[col] = data[col].str.replace(r\"i'm\", \"i am \")\n    data[col] = data[col].str.replace(r\"\\'re\", \" are \")\n    data[col] = data[col].str.replace(r\"\\'d\", \" would \")\n    data[col] = data[col].str.replace(r\"\\'ll\", \" will \")\n    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \")\n    data[col] = data[col].str.replace(r\"\\'s\", \" \")\n\n    # Clean some punctutations\n    data[col] = data[col].str.replace('\\n', ' \\n ')\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    data[col] = data[col].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:23:13.434787Z","iopub.execute_input":"2021-12-24T14:23:13.435368Z","iopub.status.idle":"2021-12-24T14:23:13.447955Z","shell.execute_reply.started":"2021-12-24T14:23:13.435333Z","shell.execute_reply":"2021-12-24T14:23:13.447327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test clean function\ntest_clean_df = pd.DataFrame({\"text\":\n                              [\"heyy\\n\\nkkdsfj\",\n                               \"hi   how/are/you ???\",\n                               \"hey?????\",\n                               \"noooo!!!!!!!!!   comeone !! \",\n                              \"cooooooooool     brooooooooooo  coool brooo\",\n                              \"naaaahhhhhhh\"]})\ndisplay(test_clean_df)\nclean(test_clean_df,'text')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:23:17.968768Z","iopub.execute_input":"2021-12-24T14:23:17.969028Z","iopub.status.idle":"2021-12-24T14:23:17.996385Z","shell.execute_reply.started":"2021-12-24T14:23:17.968999Z","shell.execute_reply":"2021-12-24T14:23:17.995676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = clean(df,'text')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:23:27.065379Z","iopub.execute_input":"2021-12-24T14:23:27.065649Z","iopub.status.idle":"2021-12-24T14:24:33.76401Z","shell.execute_reply.started":"2021-12-24T14:23:27.065619Z","shell.execute_reply":"2021-12-24T14:24:33.763268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.y==0]","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:24:33.765773Z","iopub.execute_input":"2021-12-24T14:24:33.767661Z","iopub.status.idle":"2021-12-24T14:24:33.792841Z","shell.execute_reply.started":"2021-12-24T14:24:33.767629Z","shell.execute_reply":"2021-12-24T14:24:33.792122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfrac_1 = 0.3\nfrac_1_factor = 1.2\n\nfor fld in range(n_folds):\n    tmp_df = pd.concat([df[df.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n                        df[df.y==0].sample(n=int(len(df[df.y>0])*frac_1*frac_1_factor) , \n                                            random_state = 10*(fld+1))], axis=0).sample(frac=1, random_state = 10*(fld+1))\n\n    tmp_df.to_csv(f'/kaggle/working/df_clean_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:24:33.79428Z","iopub.execute_input":"2021-12-24T14:24:33.794747Z","iopub.status.idle":"2021-12-24T14:24:34.912473Z","shell.execute_reply.started":"2021-12-24T14:24:33.794704Z","shell.execute_reply":"2021-12-24T14:24:34.911626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df,tmp_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:24:34.914337Z","iopub.execute_input":"2021-12-24T14:24:34.914688Z","iopub.status.idle":"2021-12-24T14:24:35.037629Z","shell.execute_reply.started":"2021-12-24T14:24:34.914646Z","shell.execute_reply":"2021-12-24T14:24:35.035724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ruddit data","metadata":{}},{"cell_type":"code","source":"df_ = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\nprint(df_.shape)\n\ndf_ = df_[['txt', 'offensiveness_score']].rename(columns={'txt': 'text',\n                                                                'offensiveness_score':'y'})\n\ndf_['y'] = (df_['y'] - df_.y.min()) / (df_.y.max() - df_.y.min()) \ndf_.y.hist()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:24:51.345304Z","iopub.execute_input":"2021-12-24T14:24:51.345854Z","iopub.status.idle":"2021-12-24T14:24:51.704985Z","shell.execute_reply.started":"2021-12-24T14:24:51.345821Z","shell.execute_reply":"2021-12-24T14:24:51.704212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create 3 versions of data","metadata":{}},{"cell_type":"code","source":"%%time\n\nfrac_1 = 0.7\n\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = df_.sample(frac=frac_1, random_state = 10*(fld+1))\n    tmp_df.to_csv(f'/kaggle/working/df2_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:24:54.297753Z","iopub.execute_input":"2021-12-24T14:24:54.298029Z","iopub.status.idle":"2021-12-24T14:24:54.669631Z","shell.execute_reply.started":"2021-12-24T14:24:54.298001Z","shell.execute_reply":"2021-12-24T14:24:54.667801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del tmp_df, df_; \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:24:58.058051Z","iopub.execute_input":"2021-12-24T14:24:58.05834Z","iopub.status.idle":"2021-12-24T14:24:58.181468Z","shell.execute_reply.started":"2021-12-24T14:24:58.058309Z","shell.execute_reply":"2021-12-24T14:24:58.180589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Validation and Test data  \n","metadata":{}},{"cell_type":"code","source":"# Validation data \n\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf_val = clean_validation_data(df_val)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:25:00.865091Z","iopub.execute_input":"2021-12-24T14:25:00.865367Z","iopub.status.idle":"2021-12-24T14:25:39.614635Z","shell.execute_reply.started":"2021-12-24T14:25:00.865337Z","shell.execute_reply":"2021-12-24T14:25:39.613908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:25:39.617667Z","iopub.execute_input":"2021-12-24T14:25:39.61801Z","iopub.status.idle":"2021-12-24T14:25:39.623716Z","shell.execute_reply.started":"2021-12-24T14:25:39.617969Z","shell.execute_reply":"2021-12-24T14:25:39.622876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data\n\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:30:53.005017Z","iopub.execute_input":"2021-12-24T14:30:53.005296Z","iopub.status.idle":"2021-12-24T14:30:53.060108Z","shell.execute_reply.started":"2021-12-24T14:30:53.00526Z","shell.execute_reply":"2021-12-24T14:30:53.059381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Sklearn Pipeline with \n## TFIDF - Take 'char_wb' as analyzer to capture subwords well\n## Ridge - Ridge is a simple regression algorithm that will reduce overfitting ","metadata":{}},{"cell_type":"markdown","source":"### Does % of uppercase characters have effect on toxicity\n","metadata":{}},{"cell_type":"markdown","source":"## Train pipeline\n\n- Load folds data\n- train pipeline\n- Predict on validation data\n- Predict on test data","metadata":{}},{"cell_type":"markdown","source":"### Toxic data","metadata":{}},{"cell_type":"code","source":"%%time\n\nval_preds_arr1 = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2 = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arr = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([\n        (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3, 5))),\n    ])\n    pipeline = Pipeline(\n        [\n            (\"features\", features),\n            (\"clf\", Ridge(alpha=alpha_value)),\n        ]\n    )\n    print(\"\\nTrain:\")\n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_,2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    print(\"\\npredict validation data \")\n    val_preds_arr1[:,fld] = pipeline.predict(df_val['less_toxic'])\n    val_preds_arr2[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n    print(\"\\npredict test data \")\n    test_preds_arr[:,fld] = pipeline.predict(df_sub['text'])","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:31:00.093844Z","iopub.execute_input":"2021-12-24T14:31:00.094104Z","iopub.status.idle":"2021-12-24T14:34:44.442966Z","shell.execute_reply.started":"2021-12-24T14:31:00.094075Z","shell.execute_reply":"2021-12-24T14:34:44.442225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Toxic __clean__ data","metadata":{}},{"cell_type":"code","source":"%%time\n\nval_preds_arr1c = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2c = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arrc = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df_clean_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([\n        (\"vect3\", TfidfVectorizer(min_df= 3, max_df = 0.5, analyzer = 'char_wb', ngram_range = (3,5))),\n\n    ])\n    pipeline = Pipeline(\n        [\n            (\"features\", features),\n            (\"clf\", Ridge(alpha=alpha_value)),\n        ]\n    )\n    print(\"\\nTrain:\")\n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_, 2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    print(\"\\npredict validation data \")\n    val_preds_arr1c[:,fld] = pipeline.predict(df_val['less_toxic'])\n    val_preds_arr2c[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n    print(\"\\npredict test data \")\n    test_preds_arrc[:,fld] = pipeline.predict(df_sub['text'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:23:47.498683Z","iopub.execute_input":"2021-12-09T07:23:47.501592Z","iopub.status.idle":"2021-12-09T07:32:28.077006Z","shell.execute_reply.started":"2021-12-09T07:23:47.501548Z","shell.execute_reply":"2021-12-09T07:32:28.076263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ruddit data pipeline","metadata":{}},{"cell_type":"code","source":"%%time\n\nval_preds_arr1_ = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2_ = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arr_ = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df2_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([\n        (\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))),\n\n    ])\n    pipeline = Pipeline(\n        [\n            (\"features\", features),\n            (\"clf\", Ridge(alpha=alpha_value)),\n        ]\n    )\n    print(\"\\nTrain:\")\n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_,2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    print(\"\\npredict validation data \")\n    val_preds_arr1_[:,fld] = pipeline.predict(df_val['less_toxic'])\n    val_preds_arr2_[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n    print(\"\\npredict test data \")\n    test_preds_arr_[:,fld] = pipeline.predict(df_sub['text'])","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:32:28.07847Z","iopub.execute_input":"2021-12-09T07:32:28.078877Z","iopub.status.idle":"2021-12-09T07:38:16.941765Z","shell.execute_reply.started":"2021-12-09T07:32:28.07884Z","shell.execute_reply":"2021-12-09T07:38:16.941018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df, pipeline, feature_wts\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:16.943056Z","iopub.execute_input":"2021-12-09T07:38:16.943292Z","iopub.status.idle":"2021-12-09T07:38:17.064878Z","shell.execute_reply.started":"2021-12-09T07:38:16.943259Z","shell.execute_reply":"2021-12-09T07:38:17.064235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\" Toxic CLEAN data \")\np5 = val_preds_arr1c.mean(axis=1)\np6 = val_preds_arr2c.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p5 < p6).mean() * 100,2)}')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.066149Z","iopub.execute_input":"2021-12-09T07:38:17.066546Z","iopub.status.idle":"2021-12-09T07:38:17.074404Z","shell.execute_reply.started":"2021-12-09T07:38:17.06651Z","shell.execute_reply":"2021-12-09T07:38:17.073645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\" Toxic CLEAN data new \")\np5 = val_preds_arr1c.mean(axis=1)\np6 = val_preds_arr2c.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p5 < p6).mean() * 100,2)}')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.075842Z","iopub.execute_input":"2021-12-09T07:38:17.076135Z","iopub.status.idle":"2021-12-09T07:38:17.084074Z","shell.execute_reply.started":"2021-12-09T07:38:17.076101Z","shell.execute_reply":"2021-12-09T07:38:17.083347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate the pipeline ","metadata":{}},{"cell_type":"code","source":"print(\" Toxic data \")\np1 = val_preds_arr1.mean(axis=1)\np2 = val_preds_arr2.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}')\n\nprint(\" Ruddit data \")\np3 = val_preds_arr1_.mean(axis=1)\np4 = val_preds_arr2_.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p3 < p4).mean() * 100,2)}')\n\nprint(\" Toxic CLEAN data \")\np5 = val_preds_arr1c.mean(axis=1)\np6 = val_preds_arr2c.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p5 < p6).mean() * 100,2)}')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.085763Z","iopub.execute_input":"2021-12-09T07:38:17.086168Z","iopub.status.idle":"2021-12-09T07:38:17.10083Z","shell.execute_reply.started":"2021-12-09T07:38:17.086134Z","shell.execute_reply":"2021-12-09T07:38:17.100036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nprint(\"Find right weight\")\n\nwts_acc = []\nfor i in range(60, 70, 1):\n    for j in range(0, 20, 1):\n        w1 = i / 100\n        w2 = (100 - i - j)/100\n        w3 = (1 - w1 - w2)\n        p1_wt = w1*p1 + w2*p3 + w3*p5\n        p2_wt = w1*p2 + w2*p4 + w3*p6\n        wts_acc.append((w1 , w2, w3, np.round((p1_wt < p2_wt).mean() * 100, 3)))\nsorted(wts_acc, key=lambda x:x[3], reverse=True)[:5]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.101952Z","iopub.execute_input":"2021-12-09T07:38:17.102685Z","iopub.status.idle":"2021-12-09T07:38:17.305243Z","shell.execute_reply.started":"2021-12-09T07:38:17.10265Z","shell.execute_reply":"2021-12-09T07:38:17.30448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w1,w2,w3,_ = sorted(wts_acc, key=lambda x:x[2], reverse=True)[0]\n#print(best_wts)\np1_wt = w1*p1 + w2*p3 + w3*p5\np2_wt = w1*p2 + w2*p4 + w3*p6","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.30898Z","iopub.execute_input":"2021-12-09T07:38:17.30916Z","iopub.status.idle":"2021-12-09T07:38:17.314218Z","shell.execute_reply.started":"2021-12-09T07:38:17.309138Z","shell.execute_reply":"2021-12-09T07:38:17.313475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyze bad predictions \n### Incorrect predictions with similar scores\n### Incorrect predictions with different scores","metadata":{}},{"cell_type":"code","source":"df_val['p1'] = p1_wt\ndf_val['p2'] = p2_wt\ndf_val['diff'] = np.abs(p2_wt - p1_wt)\ndf_val['correct'] = (p1_wt < p2_wt).astype('int')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.315651Z","iopub.execute_input":"2021-12-09T07:38:17.316162Z","iopub.status.idle":"2021-12-09T07:38:17.324849Z","shell.execute_reply.started":"2021-12-09T07:38:17.316099Z","shell.execute_reply":"2021-12-09T07:38:17.324142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Incorrect predictions with similar scores\nincorrect_similar = df_val[df_val.correct == 0].sort_values('diff', ascending=True)\nincorrect_similar.to_csv(\"incorrect_similar.csv\", index=False)\nincorrect_similar.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.326076Z","iopub.execute_input":"2021-12-09T07:38:17.326777Z","iopub.status.idle":"2021-12-09T07:38:17.353002Z","shell.execute_reply.started":"2021-12-09T07:38:17.326741Z","shell.execute_reply":"2021-12-09T07:38:17.352284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Some of these just look incorrectly tagged \n","metadata":{}},{"cell_type":"code","source":"### Incorrect predictions with dis-similar scores\nincorrect_diff = df_val[df_val.correct == 0].sort_values('diff', ascending=False)\nincorrect_diff.to_csv(\"incorrect_diff.csv\", index=False)\nincorrect_diff.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.354294Z","iopub.execute_input":"2021-12-09T07:38:17.354641Z","iopub.status.idle":"2021-12-09T07:38:17.376887Z","shell.execute_reply.started":"2021-12-09T07:38:17.354592Z","shell.execute_reply":"2021-12-09T07:38:17.3763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict on test data ","metadata":{}},{"cell_type":"code","source":"# Predict using pipeline\n\ndf_sub['score'] = w1*test_preds_arr.mean(axis=1) + w2*test_preds_arr_.mean(axis=1) + w3*test_preds_arrc.mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.377988Z","iopub.execute_input":"2021-12-09T07:38:17.378348Z","iopub.status.idle":"2021-12-09T07:38:17.384633Z","shell.execute_reply.started":"2021-12-09T07:38:17.378315Z","shell.execute_reply":"2021-12-09T07:38:17.38395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correct the rank ordering","metadata":{}},{"cell_type":"code","source":"# Cases with duplicates scores\n\ndf_sub['score'].count() - df_sub['score'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.392528Z","iopub.execute_input":"2021-12-09T07:38:17.392843Z","iopub.status.idle":"2021-12-09T07:38:17.402163Z","shell.execute_reply.started":"2021-12-09T07:38:17.39281Z","shell.execute_reply":"2021-12-09T07:38:17.401324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"same_score = df_sub['score'].value_counts().reset_index()[:10]\nsame_score","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.403679Z","iopub.execute_input":"2021-12-09T07:38:17.403927Z","iopub.status.idle":"2021-12-09T07:38:17.416946Z","shell.execute_reply.started":"2021-12-09T07:38:17.403895Z","shell.execute_reply":"2021-12-09T07:38:17.416144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub[df_sub['score'].isin(same_score['index'].tolist())]","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:38:17.418152Z","iopub.execute_input":"2021-12-09T07:38:17.41849Z","iopub.status.idle":"2021-12-09T07:38:17.434983Z","shell.execute_reply.started":"2021-12-09T07:38:17.418453Z","shell.execute_reply":"2021-12-09T07:38:17.434334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bert Ensemble","metadata":{}},{"cell_type":"code","source":"%%time\n\nimport os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel\n\n# Utils\nfrom tqdm import tqdm\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/roberta-base',\n    test_batch_size = 128,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n\nMODEL_PATHS = [\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-0.bin',\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-1.bin',\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-2.bin',\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-3.bin',\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-4.bin'\n]\n\ndef set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \n    \nclass JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }    \n\n    \nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.0)\n        self.fc = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs\n    \n@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS\n\n\ndef inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds\n\n\nset_seed(CONFIG['seed'])\ndf = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ndf.head()\ntest_dataset = JigsawDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)\npreds1 = inference(MODEL_PATHS, test_loader, CONFIG['device'])\npreds = (preds1-preds1.min())/(preds1.max()-preds1.min())","metadata":{"execution":{"iopub.status.busy":"2021-12-24T14:26:17.359738Z","iopub.execute_input":"2021-12-24T14:26:17.36Z","iopub.status.idle":"2021-12-24T14:29:47.525256Z","shell.execute_reply.started":"2021-12-24T14:26:17.35997Z","shell.execute_reply":"2021-12-24T14:29:47.523794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub['score'] = df_sub['score']*(1 - bert_ratio)+preds*bert_ratio","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:41:51.202634Z","iopub.execute_input":"2021-12-09T07:41:51.203162Z","iopub.status.idle":"2021-12-09T07:41:51.214133Z","shell.execute_reply.started":"2021-12-09T07:41:51.203124Z","shell.execute_reply":"2021-12-09T07:41:51.213311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T07:41:51.215897Z","iopub.execute_input":"2021-12-09T07:41:51.216092Z","iopub.status.idle":"2021-12-09T07:41:51.250519Z","shell.execute_reply.started":"2021-12-09T07:41:51.216071Z","shell.execute_reply":"2021-12-09T07:41:51.249869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"UPVOTE TO CONTRIBUTE ðŸ‘","metadata":{}}]}