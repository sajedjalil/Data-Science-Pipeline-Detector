{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### What are you trying to do in this notebook?\nThis notebook is to visualise the text data to see and identify some patterns in the text data which might help us in differentiating between less_toxic and more_toxic comments. This notebook attempts to perform EDA on the Jiggsaw Toxic Severity Rating dataset. The focus in this competition is on ranking the severity of comment toxicity from innocuous to outrageous.\n\n#### Why are you trying it?\nIn this competition you will be ranking comments in order of severity of toxicity. You are given a list of comments, and each comment should be scored according to their relative toxicity. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity. In order to avoid leaks, the same text needs to be put into same Folds. For a single document this is easy, but for a pair of documents to both be in same folds is a bit tricky. This simple notebook tracks pairs of text recursively to group them and try to create a leak-free Fold split.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:37.940322Z","iopub.execute_input":"2021-12-09T17:00:37.940877Z","iopub.status.idle":"2021-12-09T17:00:37.946555Z","shell.execute_reply.started":"2021-12-09T17:00:37.940841Z","shell.execute_reply":"2021-12-09T17:00:37.945658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nimport pandas as pd\nimport numpy as np\nimport os\nimport re\nimport random\nimport gc\nimport glob\npd.set_option('display.max_columns', None)\nnp.seterr(divide='ignore', invalid='ignore')\ngc.enable()\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import OneCycleLR\n# NLP\nfrom transformers import AutoTokenizer, AutoModel\n\n# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:37.988183Z","iopub.execute_input":"2021-12-09T17:00:37.98863Z","iopub.status.idle":"2021-12-09T17:00:38.005192Z","shell.execute_reply.started":"2021-12-09T17:00:37.988596Z","shell.execute_reply":"2021-12-09T17:00:38.004332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/jigsaw-toxic-severity-rating'\nmodels_dir = '../input/jrstc-models'\ntest_file_path = os.path.join(data_dir, 'comments_to_score.csv')\nprint(f'Train file: {test_file_path}')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.006483Z","iopub.execute_input":"2021-12-09T17:00:38.009416Z","iopub.status.idle":"2021-12-09T17:00:38.015337Z","shell.execute_reply.started":"2021-12-09T17:00:38.009376Z","shell.execute_reply":"2021-12-09T17:00:38.014553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(test_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.018039Z","iopub.execute_input":"2021-12-09T17:00:38.018565Z","iopub.status.idle":"2021-12-09T17:00:38.050342Z","shell.execute_reply.started":"2021-12-09T17:00:38.018526Z","shell.execute_reply":"2021-12-09T17:00:38.049238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.051383Z","iopub.status.idle":"2021-12-09T17:00:38.051937Z","shell.execute_reply.started":"2021-12-09T17:00:38.051704Z","shell.execute_reply":"2021-12-09T17:00:38.051728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\ntest_df['text'] = test_df['text'].progress_apply(text_cleaning)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.053034Z","iopub.status.idle":"2021-12-09T17:00:38.053609Z","shell.execute_reply.started":"2021-12-09T17:00:38.053375Z","shell.execute_reply":"2021-12-09T17:00:38.053399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.054818Z","iopub.status.idle":"2021-12-09T17:00:38.055399Z","shell.execute_reply.started":"2021-12-09T17:00:38.055145Z","shell.execute_reply":"2021-12-09T17:00:38.055171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'device': device,\n    'debug': False,\n    'checkpoint': '../input/roberta-base',\n    'output_logits': 768,\n    'max_len': 256,\n    'batch_size': 32,\n    'dropout': 0.2,\n    'num_workers': 2\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.056467Z","iopub.status.idle":"2021-12-09T17:00:38.057009Z","shell.execute_reply.started":"2021-12-09T17:00:38.056777Z","shell.execute_reply":"2021-12-09T17:00:38.056803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if params['debug']:\n    train_df = train_df.sample(frac=0.01)\n    print('Reduced training Data Size for Debugging purposes')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.065009Z","iopub.execute_input":"2021-12-09T17:00:38.0658Z","iopub.status.idle":"2021-12-09T17:00:38.085226Z","shell.execute_reply.started":"2021-12-09T17:00:38.065764Z","shell.execute_reply":"2021-12-09T17:00:38.084115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTDataset:\n    def __init__(self, text, max_len=params['max_len'], checkpoint=params['checkpoint']):\n        self.text = text\n        self.max_len = max_len\n        self.checkpoint = checkpoint\n        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n        self.num_examples = len(self.text)\n\n    def __len__(self):\n        return self.num_examples\n\n    def __getitem__(self, idx):\n        text = str(self.text[idx])\n\n        tokenized_text = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_attention_mask=True,\n            return_token_type_ids=True,\n        )\n\n        ids = tokenized_text['input_ids']\n        mask = tokenized_text['attention_mask']\n        token_type_ids = tokenized_text['token_type_ids']\n\n        return {'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)}","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.086857Z","iopub.status.idle":"2021-12-09T17:00:38.087345Z","shell.execute_reply.started":"2021-12-09T17:00:38.087143Z","shell.execute_reply":"2021-12-09T17:00:38.087163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ToxicityModel(nn.Module):\n    def __init__(self, checkpoint=params['checkpoint'], params=params):\n        super(ToxicityModel, self).__init__()\n        self.checkpoint = checkpoint\n        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n        self.layer_norm = nn.LayerNorm(params['output_logits'])\n        self.dropout = nn.Dropout(params['dropout'])\n        self.dense = nn.Sequential(\n            nn.Linear(params['output_logits'], 256),\n            nn.LeakyReLU(negative_slope=0.01),\n            nn.Dropout(params['dropout']),\n            nn.Linear(256, 1)\n        )\n\n    def forward(self, input_ids, token_type_ids, attention_mask):\n        _, pooled_output = self.bert(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n        pooled_output = self.layer_norm(pooled_output)\n        pooled_output = self.dropout(pooled_output)\n        preds = self.dense(pooled_output)\n        return preds","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.088852Z","iopub.status.idle":"2021-12-09T17:00:38.089509Z","shell.execute_reply.started":"2021-12-09T17:00:38.089239Z","shell.execute_reply":"2021-12-09T17:00:38.089262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nn = None\nfor model_name in glob.glob(models_dir + '/*.pth'):\n    model = ToxicityModel()\n    model.load_state_dict(torch.load(model_name))\n    model = model.to(params['device'])\n    model.eval()\n\n    test_dataset = BERTDataset(\n        text = test_df['text'].values\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=params['batch_size'],\n        shuffle=False, num_workers=params['num_workers'],\n        pin_memory=True\n    )\n\n    temp_preds = None\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=f'Predicting. '):\n            ids= batch['ids'].to(device)\n            mask = batch['mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            predictions = model(ids, token_type_ids, mask).to('cpu').numpy()\n            \n            if temp_preds is None:\n                temp_preds = predictions\n            else:\n                temp_preds = np.vstack((temp_preds, predictions))\n\n    if predictions_nn is None:\n        predictions_nn = temp_preds\n    else:\n        predictions_nn += temp_preds\n        \npredictions_nn = (len(glob.glob(models_dir + '/*.pth')))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.106931Z","iopub.execute_input":"2021-12-09T17:00:38.107202Z","iopub.status.idle":"2021-12-09T17:00:38.116521Z","shell.execute_reply.started":"2021-12-09T17:00:38.107175Z","shell.execute_reply":"2021-12-09T17:00:38.115668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame()\nsub_df['comment_id'] = test_df['comment_id']\nsub_df['score'] = predictions_nn\nsub_df['score'] = sub_df['score'].rank(method='first')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.119954Z","iopub.execute_input":"2021-12-09T17:00:38.120406Z","iopub.status.idle":"2021-12-09T17:00:38.14337Z","shell.execute_reply.started":"2021-12-09T17:00:38.120379Z","shell.execute_reply":"2021-12-09T17:00:38.142319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.14431Z","iopub.status.idle":"2021-12-09T17:00:38.145257Z","shell.execute_reply.started":"2021-12-09T17:00:38.145027Z","shell.execute_reply":"2021-12-09T17:00:38.14505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.146217Z","iopub.status.idle":"2021-12-09T17:00:38.146987Z","shell.execute_reply.started":"2021-12-09T17:00:38.146751Z","shell.execute_reply":"2021-12-09T17:00:38.146776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('My heart is beating like Thunder')\nprint('By Elvis Presley')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T17:00:38.148121Z","iopub.status.idle":"2021-12-09T17:00:38.148877Z","shell.execute_reply.started":"2021-12-09T17:00:38.148641Z","shell.execute_reply":"2021-12-09T17:00:38.148665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Did it work?\nThere is no training data for this competition. You can refer to previous Jigsaw competitions for data that might be useful to train models. But note that the task of previous competitions has been to predict the probability that a comment was toxic, rather than the degree or severity of a comment's toxicity.\n\n#### What did you not understand about this process?\nWell, everything provides in the competition data page. I've no problem while working on it. If you guys don't understand the thing that I'll do in this notebook then please comment on this notebook.\n\n#### What else do you think you can try as part of this approach?\nWhile we don't include training data, we do provide a set of paired toxicity rankings that can be used to validate models.","metadata":{}}]}