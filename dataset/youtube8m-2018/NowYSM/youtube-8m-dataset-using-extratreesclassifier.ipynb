{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5da12a7341c95f5d841bd782568c6576d05ff00e"},"cell_type":"code","source":"#!curl storage.googleapis.com/data.yt8m.org/download_fix.py | partition=2/video/train mirror=us python\n#!curl storage.googleapis.com/data.yt8m.org/download_fix.py | partition=2/video/validate mirror=us python\n#!curl storage.googleapis.com/data.yt8m.org/download_fix.py | partition=2/video/test mirror=us python ","execution_count":50,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from multiprocessing import Pool, cpu_count\nfrom IPython.display import YouTubeVideo #YouTubeVideo('-0OWhcdBt0k', 7)\nfrom sklearn import ensemble, metrics, preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport glob\n\nsub = pd.read_csv('../input/sample_submission.csv')\nlbl = {k:{'label':v, 'count':0} for k,v in pd.read_csv('../input/label_names_2018.csv').values}\ntrain_videos = glob.glob('../input/video/train*')\ntest_videos = glob.glob('../input/video/test*')\nval_videos = glob.glob('../input/video/val*')\nframes = glob.glob('../input/frame/*')\nprint(len(train_videos), len(test_videos), len(val_videos),len(frames))","execution_count":51,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"models = []\ntrain = []\nloops_ = 0\nfor tf_vids in train_videos:\n    #f = tf_vids.split('/')[-1].split('.')[0]\n    if loops_ % 10 == 0:\n        print(loops_)\n    for tf_zip in tf.python_io.tf_record_iterator(tf_vids):\n        video = tf.train.Example.FromString(tf_zip)\n        vid_id = video.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\n        mean_rgb = video.features.feature['mean_rgb'].float_list.value\n        mean_audio = video.features.feature['mean_audio'].float_list.value\n        l = ','.join(map(str, video.features.feature['labels'].int64_list.value))\n        train.append([vid_id, l]+ list(mean_rgb) + list(mean_audio))\n    if loops_ > 2:\n        break\n    loops_ += 1\n\ncol = ['VideoId','label'] + ['mean_rgb'+str(i) for i in range(1024)] + ['mean_audio'+str(i) for i in range(128)]\ntrain = pd.DataFrame(train, columns=col)\ncol = [c for c in col if c not in ['VideoId','label']]\ny = train['label'].str.get_dummies(sep=',')\nmodel =  RandomForestClassifier(min_samples_split = 40, max_leaf_nodes = 15, n_estimators = 40, max_depth = 5,min_samples_leaf = 3)\nsc = preprocessing.StandardScaler()\nmodel.fit(sc.fit_transform(train[col]), y)\nmodels.append([model, y.columns])","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f3748c8376f5892fb08c949ce1ed822314ec7754"},"cell_type":"code","source":"val = []\nfor tf_vids in val_videos:\n    for tf_zip in tf.python_io.tf_record_iterator(tf_vids):\n        video = tf.train.Example.FromString(tf_zip)\n        vid_id = video.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\n        mean_rgb = video.features.feature['mean_rgb'].float_list.value\n        mean_audio = video.features.feature['mean_audio'].float_list.value\n        l = ','.join(map(str, video.features.feature['labels'].int64_list.value))\n        val.append([vid_id, l]+ list(mean_rgb) + list(mean_audio))\n\n    col = ['VideoId','label'] + ['mean_rgb'+str(i) for i in range(1024)] + ['mean_audio'+str(i) for i in range(128)]\n    val = pd.DataFrame(val, columns=col)\n    col = [c for c in col if c not in ['VideoId','label']]\n    y = val['label'].str.get_dummies(sep=',')\n    for c in models[0][1]:\n        if c not in y.columns:\n            y[c] = 0\n    ycol = [c for c in y.columns if c in models[0][1]]\n    y = y[ycol]\n    #print(len(y), len(results))\n    results = models[0][0].predict_proba(sc.transform(val[col]))\n    results = np.array(results).T[1]\n    results = pd.DataFrame(results, columns=models[0][1]) \n    print(metrics.average_precision_score(y, results, average='micro'))\n    break","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f00466311f6ec6bb7755f4883d89d07fb884f08","collapsed":true},"cell_type":"code","source":"def multi_tf_zip(tf_zip):\n    video = tf.train.Example.FromString(tf_zip)\n    vid_id = video.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\n    mean_rgb = video.features.feature['mean_rgb'].float_list.value\n    mean_audio = video.features.feature['mean_audio'].float_list.value\n    r = [vid_id]+ list(mean_rgb) + list(mean_audio)\n    return r\n\ntests = []\nloops_ = 0\nfor tf_vids in test_videos:\n    if loops_ % 100 == 0:\n        print (loops_)\n    test = []\n    p = Pool(cpu_count())\n    for tf_zip in tf.python_io.tf_record_iterator(tf_vids):\n        test.append(tf_zip)\n    test = p.map(multi_tf_zip, test)\n    p.close(); p.join()\n    \n    col = ['VideoId'] + ['mean_rgb'+str(i) for i in range(1024)] + ['mean_audio'+str(i) for i in range(128)]\n    test = pd.DataFrame(test, columns=col)\n    col = [c for c in col if c not in ['VideoId']]\n    results = models[0][0].predict_proba(sc.transform(test[col]))\n    results = np.array(results).T[1]\n    results = pd.DataFrame(results, columns=models[0][1])\n    results_ = []\n    for i in range(len(results)):\n        r = results.iloc[[i]].T.reset_index().sort_values(by=[i], ascending=False)\n        r = r[r[i]>0.0][:20]\n        results_.append(' '.join([' '.join(map(str, [k, round(v,3)])) for k, v in r.values]))\n    test['LabelConfidencePairs'] = results_\n    tests.append(test[['VideoId', 'LabelConfidencePairs']])\n    loops_ += 1\n\n#pd.concat(tests).to_csv('submission.csv', index=False)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce1fc88b1542988e464234e7817b3d816b9aa035","collapsed":true},"cell_type":"code","source":"#!kaggle competitions submit -c youtube8m-2018 -f submission.csv -m \"z01\"","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9eebc2fd3e002e350c3dcc74f2f4e70257215b79"},"cell_type":"code","source":"#Temporary\nfor tf_vids in train_videos:\n    for tf_zip in tf.python_io.tf_record_iterator(tf_vids):\n        video = tf.train.Example.FromString(tf_zip)\n        for k in list(video.features.feature['labels'].int64_list.value):\n            if k in lbl:\n                lbl[k]['count']+=1\ndf = pd.DataFrame.from_dict(lbl, orient='index').sort_values(['count'], ascending=[False])\ndf['id'] = df.index\ndf['count'] = df['count'] / sum(df['count'].values)\nsub.LabelConfidencePairs = ' '.join([str(int(x))+' '+str(round(y,2)) for x,y in df[['id','count']].values[:20]])\nsub.to_csv('submission.csv', index=False)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7c8592ba289e65493c3f67b3ec17fe44f5909b9a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}