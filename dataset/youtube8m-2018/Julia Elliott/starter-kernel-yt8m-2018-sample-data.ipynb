{"cells":[{"metadata":{"_cell_guid":"15a5f5c8-3fdc-4693-919a-2fc9de2ecee2","_uuid":"22217d65c9bfadd0e948a49b74a7ec75cba4437f"},"cell_type":"markdown","source":"# This notebook explores the data (TFRecord format) using a subsample of the YouTube-8M video & frame-level data. To work with the entire dataset, please refer to the Starter code on the [YouTube-8M github repo](https://github.com/google/youtube-8m)."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/frame\"))\nprint(os.listdir(\"../input/video\"))","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"f22c36cf-f788-4edc-9a88-32c116fa4cb8","_uuid":"d1656e711254f02e2479e2f95704e3dd42949607","trusted":true,"collapsed":true},"cell_type":"code","source":"#Loading libraries & datasets\nimport tensorflow as tf\nimport numpy as np\nfrom IPython.display import YouTubeVideo\n\nvideo_lvl_record = \"../input/video/train00.tfrecord\"\nframe_lvl_record = \"../input/frame/train00.tfrecord\"","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"d80e50b4-692b-480d-a3fd-d59cf226de19","_uuid":"8bd33285e392f106994effc1a46644d073dcc5fc"},"cell_type":"markdown","source":"# Let's start with the video-level data"},{"metadata":{"_cell_guid":"7b19d838-f9db-4e22-8420-16b0d93f16fe","_uuid":"16a62102bef4da3c6f5de8176267f7a5b0e74776","collapsed":true,"trusted":true},"cell_type":"code","source":"vid_ids = []\nlabels = []\nmean_rgb = []\nmean_audio = []\n\nfor example in tf.python_io.tf_record_iterator(video_lvl_record):\n    tf_example = tf.train.Example.FromString(example)\n\n    vid_ids.append(tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n    labels.append(tf_example.features.feature['labels'].int64_list.value)\n    mean_rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)\n    mean_audio.append(tf_example.features.feature['mean_audio'].float_list.value)","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"02c8c33e-c5d9-4fe4-ac14-20a3d689f877","_uuid":"d7e308317de941794b45c45d98945d07f669a8f9","trusted":true},"cell_type":"code","source":"print('Number of videos in this tfrecord: ',len(mean_rgb))\nprint('Picking a youtube video id:',vid_ids[13])\nprint('First 20 features of a youtube video (',vid_ids[13],'):')\nprint(mean_rgb[13][:20])","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"10154919-12f9-42e7-b1ea-a1b9c5c61247","_uuid":"50ddbae66c152eb53fc8c163e82619438af57084"},"cell_type":"markdown","source":"As described on the [YouTube8M download page](https://research.google.com/youtube8m/video_id_conversion.html), for privacy reasons, the video `id` has been randomly generated and does not directly correspond to the actual YouTube video id. To convert the `id` into the actua YouTube video id, we follow link: [http://data.yt8m.org/2/j/i/1r/1r00.js](http://data.yt8m.org/2/j/i/1r/1r00.js)"},{"metadata":{"_cell_guid":"17d9feba-98e3-4106-8e7a-9da233c34de5","_uuid":"862f198e022731fcc3a91e03c1bed5497fee35ec","trusted":true},"cell_type":"code","source":"#With that video id, we can play the video\nYouTubeVideo('-QM5ooctj0w')","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"4ebf04fd-0507-461b-92c8-a63527736203","_uuid":"1cb1866f0259916ea4a819fdc616baff3841fd77"},"cell_type":"markdown","source":"# Now, let's read the frame-level data"},{"metadata":{"_cell_guid":"75e41de0-a768-485e-8246-92f40ec06aed","_uuid":"379dc32f4543f99cb1b373e28398aface44031c2","collapsed":true,"trusted":true},"cell_type":"code","source":"# due to execution time, we're only going to read the first video\n\nfeat_rgb = []\nfeat_audio = []\n\nfor example in tf.python_io.tf_record_iterator(frame_lvl_record):        \n    tf_seq_example = tf.train.SequenceExample.FromString(example)\n    n_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n    sess = tf.InteractiveSession()\n    rgb_frame = []\n    audio_frame = []\n    # iterate through frames\n    for i in range(n_frames):\n        rgb_frame.append(tf.cast(tf.decode_raw(\n                tf_seq_example.feature_lists.feature_list['rgb'].feature[i].bytes_list.value[0],tf.uint8)\n                       ,tf.float32).eval())\n        audio_frame.append(tf.cast(tf.decode_raw(\n                tf_seq_example.feature_lists.feature_list['audio'].feature[i].bytes_list.value[0],tf.uint8)\n                       ,tf.float32).eval())\n        \n        \n    sess.close()\n    feat_rgb.append(rgb_frame)\n    feat_audio.append(audio_frame)\n    break","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"c09c3c2f-749f-4ebf-a159-d2efcc9fe1ac","_uuid":"a0922db2db6058deca67cba38204f705010be568","trusted":true},"cell_type":"code","source":"print('The first video has %d frames' %len(feat_rgb[0]))","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"f8c087f0-1a4d-49d0-b0ed-d8747d85d17a","_uuid":"612a50a77785f90d916899917c1a961035884450"},"cell_type":"markdown","source":"# Now let's explore the labels\n\nFirst, we'll find the most commonly used labels..."},{"metadata":{"_cell_guid":"02872613-bef2-4a77-a924-55a0f7b31adb","_uuid":"0abc6b55f0e4a268dc92918b8715c1bc4484b40c","collapsed":true,"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n%matplotlib inline\nfrom sklearn.manifold import TSNE\nimport numpy as np","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"08cf2a57-6eec-444a-b280-e86a5e026cdf","_uuid":"1367abe58fd3c94d63312773cabdce5af606d794","trusted":true},"cell_type":"code","source":"labels_2018 = pd.read_csv('../input/label_names_2018.csv')\nprint(\"we have {} unique labels in the dataset\".format(len(labels_2018['label_name'].unique())))","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"d159438b-ddcf-4d78-87cb-3e479404f261","_uuid":"44daa93d3c7acb4fed93ef7b11eac2d4718a5f5b","trusted":true},"cell_type":"code","source":"n=10\nfrom collections import Counter\nlabel_mapping = pd.read_csv('../input/label_names_2018.csv',header=0,index_col=0,squeeze=True).T.to_dict()\n\ntop_n = Counter([item for sublist in labels for item in sublist]).most_common(n)\ntop_n_labels = [int(i[0]) for i in top_n]\ntop_n_label_names = [label_mapping[x] for x in top_n_labels]\ntop_n_label_names","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"d1687471-951c-4028-a680-386cf22494b1","_uuid":"2d43fd67abda2e0ae7b2058218ca8e2fb57962ca"},"cell_type":"markdown","source":"And plot the relationships between each of these top labels..."},{"metadata":{"_cell_guid":"0a271ee2-3efc-4aee-b364-b0ece9157b0f","_uuid":"2d5bc349aef74f1a7158b65498662c10010edddf","trusted":true},"cell_type":"code","source":"import networkx as nx\nfrom itertools import combinations\n\nG=nx.Graph()\n\nG.clear()\nfor list_of_nodes in labels:\n    filtered_nodes = set(list_of_nodes).intersection(set(top_n_labels))  \n    for node1,node2 in list(combinations(filtered_nodes,2)): \n        node1_name = label_mapping[node1]\n        node2_name = label_mapping[node2]\n        G.add_node(node1_name)\n        G.add_node(node2_name)\n        G.add_edge(node1_name, node2_name)\n\nnx.draw_networkx(G,font_size=\"10\")","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"66ba94f4-5330-4e29-b42a-52aaa3fcc188","_uuid":"ae6ff68ffbc6e79d7da4e8162927eeb25115ad54"},"cell_type":"markdown","source":"And a t-SNE plot on the data..."},{"metadata":{"_cell_guid":"2639ecc0-0de8-44c4-88b6-864407e62400","_uuid":"02d9bcaeaa5ad450ce68d43ef620cf59b4f39f60","trusted":true},"cell_type":"code","source":"colors = plt.cm.rainbow(np.linspace(0, 1, n))\nmean_rgb_top_n = []\nlabels_for_tsne = []\n# filtering mean_rgb so it only contains top n labels\nfor idx, list_of_nodes in enumerate(labels):\n    for node in list_of_nodes:\n        if node in top_n_labels:\n            mean_rgb_top_n.append(mean_rgb[idx])\n            labels_for_tsne.append(node)\n\n\nX_embedded = TSNE(n_components=2, random_state=0).fit_transform(mean_rgb_top_n) \n\n\nfig = plt.figure()\nax = fig.add_subplot(111)\n\nhandles = []\nfor indx, color in enumerate(colors):\n    this_label = top_n_labels[indx]\n    X_embedded_filtered = X_embedded[np.array([x==this_label for x in labels_for_tsne])]\n    handles.append(ax.scatter(X_embedded_filtered[:, 0], X_embedded_filtered[:, 1], c=color, marker=\"o\",edgecolor='none'))\n\nax.legend(handles, top_n_labels)\n\nplt.show()","execution_count":16,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}