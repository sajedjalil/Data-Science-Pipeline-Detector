{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Warrning \n1. This notebook only include public testset for faster testif you submit it you will get 0 score\n2. Change wandb API KEY in training notebook to yours\n3. colab free GPU is about 3x faster than kaggle","metadata":{}},{"cell_type":"markdown","source":"# Approach and Refferences\n\n> efficientnetb3a with aux loss for study + efficientnetb5 for 2class + yolov5m for image \n\n## Refferences\n\n1. henhttps://www.kaggle.com/c/siim-covid19-detection/discussion/246586gk's aux loss https://www.kaggle.com/c/siim-covid19-detection/discussion/240233\n2. alien's 2 class tricks https://www.kaggle.com/c/siim-covid19-detection/discussion/246586\n3. darian's duplicate analysis https://www.kaggle.com/c/siim-covid19-detection/discussion/240878\n\n## Training notebook\n\n1. drop duplicate and create mask https://www.kaggle.com/drzhuzhe/siiim-covid-stratified-k-fold-and-create-mask\n\n2. training study level https://www.kaggle.com/drzhuzhe/covid19-classify efficientnetb3a 1e-3 10 ep + 1e-4 5ep CV map*0.66 score (3.76 + 3.92 + 3.85 + 3.7 + 3.6)/5 avg 3.766\n\n3. training yolo https://www.kaggle.com/drzhuzhe/covid19-det?scriptVersionId=67605495 efficientnetb5 only 10 epoch  CV map score (0.4947 + 0.5103 + 0.4848 +0.4692 +0.5198)/5 avg 0.49575 \n\n4. 2 class https://www.kaggle.com/drzhuzhe/siim-covid19-efnb7-train-fold0-5-2class  yolov5m 15 epoch (0.869 + 0.860 + 0.882 + 0.878 + 0.876)/5 avg 0.872\n\n## Experiments\n\n1. study level with 6 class is doable single fold LB 0.586 + \n2. efficientnetV2-m got low result https://www.kaggle.com/c/siim-covid19-detection/discussion/248442 according to this disscus efficientnetV2 may need larger batchsize\n3. aux CNN head attach to block 4 get mediocre result\n","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\n\nimport cv2\nimport sys\nimport math\n\nfrom timeit import default_timer as timer\nfrom datetime import datetime\nfrom numba import cuda","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:51.233652Z","iopub.execute_input":"2021-07-25T13:22:51.234221Z","iopub.status.idle":"2021-07-25T13:22:53.535007Z","shell.execute_reply.started":"2021-07-25T13:22:51.23412Z","shell.execute_reply":"2021-07-25T13:22:53.533991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:53.536764Z","iopub.execute_input":"2021-07-25T13:22:53.537349Z","iopub.status.idle":"2021-07-25T13:22:53.54506Z","shell.execute_reply.started":"2021-07-25T13:22:53.537296Z","shell.execute_reply":"2021-07-25T13:22:53.541738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_det_model_path = \"/kaggle/input/collect-submit-model/det/\"\n_classify_model_path = \"/kaggle/input/covidmodels/Archive/classify-ep12/\"\n\n_test_files_path = \"/kaggle/input/covid19512/test/\"\n_data_dir = \"/kaggle/input/covid19512/\"\n\nmeta_df = pd.read_csv(_data_dir + \"meta.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:53.548333Z","iopub.execute_input":"2021-07-25T13:22:53.548811Z","iopub.status.idle":"2021-07-25T13:22:53.586785Z","shell.execute_reply.started":"2021-07-25T13:22:53.548766Z","shell.execute_reply":"2021-07-25T13:22:53.585762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 512","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:53.588705Z","iopub.execute_input":"2021-07-25T13:22:53.589188Z","iopub.status.idle":"2021-07-25T13:22:53.594629Z","shell.execute_reply.started":"2021-07-25T13:22:53.58915Z","shell.execute_reply":"2021-07-25T13:22:53.593194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clssification","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.nn.parallel.data_parallel import data_parallel\n\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import *\n\nimport collections\nfrom collections import defaultdict\n\nimport timm\nfrom timm.models.efficientnet import *\n\nimport torch.cuda.amp as amp","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:53.59632Z","iopub.execute_input":"2021-07-25T13:22:53.597032Z","iopub.status.idle":"2021-07-25T13:22:57.45234Z","shell.execute_reply.started":"2021-07-25T13:22:53.596975Z","shell.execute_reply":"2021-07-25T13:22:57.450992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = _data_dir\nimage_size = IMG_SIZE\n\nstudy_name_to_predict_string = {\n    'Negative for Pneumonia'  :'negative',\n    'Typical Appearance'      :'typical',\n    'Indeterminate Appearance':'indeterminate',\n    'Atypical Appearance'     :'atypical',\n}\n\nstudy_name_to_label = {\n    'Negative for Pneumonia'  :0,\n    'Typical Appearance'      :1,\n    'Indeterminate Appearance':2,\n    'Atypical Appearance'     :3,\n}\nstudy_label_to_name = { v:k for k,v in study_name_to_label.items()}\nnum_study_label = len(study_name_to_label)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:57.454617Z","iopub.execute_input":"2021-07-25T13:22:57.455185Z","iopub.status.idle":"2021-07-25T13:22:57.465351Z","shell.execute_reply.started":"2021-07-25T13:22:57.455142Z","shell.execute_reply":"2021-07-25T13:22:57.462884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_fold(mode='train-0'):\n    if 'test' in mode:\n        df_meta  = pd.read_csv(data_dir+'meta.csv')\n        df_valid = df_meta[df_meta['split']=='test'].copy()\n\n        for l in study_name_to_label.keys():\n            df_valid.loc[:,l]=0\n        df_valid = df_valid.reset_index(drop=True)\n        return df_valid","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:57.467715Z","iopub.execute_input":"2021-07-25T13:22:57.468335Z","iopub.status.idle":"2021-07-25T13:22:57.478751Z","shell.execute_reply.started":"2021-07-25T13:22:57.468292Z","shell.execute_reply":"2021-07-25T13:22:57.477482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiimDataset(Dataset):\n    def __init__(self, df, augment=None):\n        super().__init__()\n        self.df = df\n        self.augment = augment\n        self.length = len(df)\n\n    def __str__(self):\n        string  = ''\n        string += '\\tlen = %d\\n'%len(self)\n        string += '\\tdf  = %s\\n'%str(self.df.shape)\n\n        string += '\\tlabel distribution\\n'\n        for i in range(num_study_label):\n            n = self.df[study_label_to_name[i]].sum()\n            string += '\\t\\t %d %26s: %5d (%0.4f)\\n'%(i, study_label_to_name[i], n, n/len(self.df) )\n        return string\n\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, index):\n        d = self.df.iloc[index]\n\n        image_file = data_dir + '/test/%s.png' % (d.image_id)\n        image = cv2.imread(image_file,cv2.IMREAD_GRAYSCALE)\n        onehot = d[study_name_to_label.keys()].values\n\n        mask = np.zeros_like(image)\n\n\n        r = {\n            'index' : index,\n            'd' : d,\n            'image' : image,\n            'mask' : mask,\n            'onehot' : onehot,\n        }\n        if self.augment is not None: r = self.augment(r)\n        return r\n\ndef null_collate(batch):\n    collate = defaultdict(list)\n\n    for r in batch:\n        for k, v in r.items():\n            collate[k].append(v)\n\n    # ---\n    batch_size = len(batch)\n    onehot = np.ascontiguousarray(np.stack(collate['onehot'])).astype(np.float32)\n    collate['onehot'] = torch.from_numpy(onehot)\n\n    image = np.stack(collate['image'])\n    image = image.reshape(batch_size, 1, image_size,image_size).repeat(3,1)\n    image = np.ascontiguousarray(image)\n    image = image.astype(np.float32) / 255\n    collate['image'] = torch.from_numpy(image)\n\n\n    mask = np.stack(collate['mask'])\n    mask = mask.reshape(batch_size, 1, image_size,image_size)\n    mask = np.ascontiguousarray(mask)\n    mask = mask.astype(np.float32) / 255\n    collate['mask'] = torch.from_numpy(mask)\n\n    return collate","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:57.483387Z","iopub.execute_input":"2021-07-25T13:22:57.483924Z","iopub.status.idle":"2021-07-25T13:22:57.501007Z","shell.execute_reply.started":"2021-07-25T13:22:57.483893Z","shell.execute_reply":"2021-07-25T13:22:57.49964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        e = efficientnet_b3a(pretrained=False, drop_rate=0.3, drop_path_rate=0.2)\n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1,\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.b8 = nn.Sequential(\n            e.conv_head, #384, 1536\n            e.bn2,\n            e.act2,\n        )\n\n        self.logit = nn.Linear(1536,num_study_label)\n        self.mask = nn.Sequential(\n            nn.Conv2d(136, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n        )\n\n\n    # @torch.cuda.amp.autocast()\n    def forward(self, image):\n        batch_size = len(image)\n        x = 2*image-1     # ; print('input ',   x.shape)\n\n        x = self.b0(x) #; print (x.shape)  # torch.Size([2, 40, 256, 256])\n        x = self.b1(x) #; print (x.shape)  # torch.Size([2, 24, 256, 256])\n        x = self.b2(x) #; print (x.shape)  # torch.Size([2, 32, 128, 128])\n        x = self.b3(x) #; print (x.shape)  # torch.Size([2, 48, 64, 64])\n        x = self.b4(x) #; print (x.shape)  # torch.Size([2, 96, 32, 32])\n        x = self.b5(x) #; print (x.shape)  # torch.Size([2, 136, 32, 32])\n        #------------\n        mask = self.mask(x)\n        #-------------\n        x = self.b6(x) #; print (x.shape)  # torch.Size([2, 232, 16, 16])\n        x = self.b7(x) #; print (x.shape)  # torch.Size([2, 384, 16, 16])\n        x = self.b8(x) #; print (x.shape)  # torch.Size([2, 1536, 16, 16])\n        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        #x = F.dropout(x, 0.5, training=self.training)\n        logit = self.logit(x)\n        return logit, mask","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:57.504133Z","iopub.execute_input":"2021-07-25T13:22:57.504771Z","iopub.status.idle":"2021-07-25T13:22:57.521452Z","shell.execute_reply.started":"2021-07-25T13:22:57.504726Z","shell.execute_reply":"2021-07-25T13:22:57.520338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def probability_to_df_study(df_valid, probability):\n    df_study = pd.DataFrame()\n    df_image = df_valid.copy()\n    df_study.loc[:,'id'] = df_valid.study + '_study'\n    for i in range(num_study_label):\n        df_study.loc[:,study_name_to_predict_string[study_label_to_name[i]]]=probability[:,i]\n        df_image.loc[:,study_name_to_predict_string[study_label_to_name[i]]]=probability[:,i]\n    \n    \n    df_study = df_study.groupby('id', as_index=False).mean()\n    df_study.loc[:, 'PredictionString'] = \\\n           'negative '      + df_study.negative.apply(lambda x: '%0.6f'%x)      + ' 0 0 1 1' \\\n        + ' typical '       + df_study.typical.apply(lambda x: '%0.6f'%x)       + ' 0 0 1 1' \\\n        + ' indeterminate ' + df_study.indeterminate.apply(lambda x: '%0.6f'%x) + ' 0 0 1 1' \\\n        + ' atypical '      + df_study.atypical.apply(lambda x: '%0.6f'%x)      + ' 0 0 1 1'\n\n    df_study = df_study[['id','PredictionString']]\n    return df_study, df_image","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:38:05.933124Z","iopub.execute_input":"2021-07-25T13:38:05.933542Z","iopub.status.idle":"2021-07-25T13:38:05.944849Z","shell.execute_reply.started":"2021-07-25T13:38:05.933498Z","shell.execute_reply":"2021-07-25T13:38:05.943356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_predict(net, valid_loader, tta=['flip','scale']): #flip\n\n    valid_probability = []\n    valid_num = 0\n\n    start_timer = timer()\n    for t, batch in enumerate(valid_loader):\n        batch_size = len(batch['index'])\n        image  = batch['image'].cuda()\n        onehot = batch['onehot']\n        label  = onehot.argmax(-1)\n\n        #<todo> TTA\n        net.eval()\n        with torch.no_grad():\n            probability = []\n            logit, mask = net(image)\n            probability.append(F.softmax(logit,-1))\n\n            if 'flip' in tta:\n                logit, mask = net(torch.flip(image,dims=(3,)))\n                probability.append(F.softmax(logit,-1))\n\n            if 'scale' in tta:\n                # size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None):\n                logit, mask = net(F.interpolate(image, scale_factor=1.33, mode='bilinear', align_corners=False))\n                probability.append(F.softmax(logit,-1))\n\n            #--------------\n            probability = torch.stack(probability,0).mean(0)\n\n        valid_num += batch_size\n        valid_probability.append(probability.data.cpu().numpy())\n        print('\\r %8d / %d  %s' % (valid_num, len(valid_loader.dataset), time_to_str(timer() - start_timer, 'sec')),\n              end='', flush=True)\n\n    assert(valid_num == len(valid_loader.dataset))\n    print('')\n\n    probability = np.concatenate(valid_probability)\n    return probability","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:57.539727Z","iopub.execute_input":"2021-07-25T13:22:57.540128Z","iopub.status.idle":"2021-07-25T13:22:57.555612Z","shell.execute_reply.started":"2021-07-25T13:22:57.540084Z","shell.execute_reply":"2021-07-25T13:22:57.55415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Logger(object):\n    def __init__(self):\n        self.terminal = sys.stdout  #stdout\n        self.file = None\n\n    def open(self, file, mode=None):\n        if mode is None: mode ='w'\n        self.file = open(file, mode)\n\n    def write(self, message, is_terminal=1, is_file=1 ):\n        if '\\r' in message: is_file=0\n\n        if is_terminal == 1:\n            self.terminal.write(message)\n            self.terminal.flush()\n            #time.sleep(1)\n\n        if is_file == 1:\n            self.file.write(message)\n            self.file.flush()\n\n    def flush(self):\n        # this flush method is needed for python 3 compatibility.\n        # this handles the flush command by doing nothing.\n        # you might want to specify some extra behavior here.\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:57.557732Z","iopub.execute_input":"2021-07-25T13:22:57.558652Z","iopub.status.idle":"2021-07-25T13:22:57.570053Z","shell.execute_reply.started":"2021-07-25T13:22:57.558605Z","shell.execute_reply":"2021-07-25T13:22:57.568782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def time_to_str(t, mode='min'):\n    if mode=='min':\n        t  = int(t)/60\n        hr = t//60\n        min = t%60\n        return '%2d hr %02d min'%(hr,min)\n\n    elif mode=='sec':\n        t   = int(t)\n        min = t//60\n        sec = t%60\n        return '%2d min %02d sec'%(min,sec)\n\n    else:\n        raise NotImplementedError","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:57.572323Z","iopub.execute_input":"2021-07-25T13:22:57.573076Z","iopub.status.idle":"2021-07-25T13:22:57.586117Z","shell.execute_reply.started":"2021-07-25T13:22:57.57299Z","shell.execute_reply":"2021-07-25T13:22:57.584743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_submit():\n    for fold in [0 ,1 ,2, 3, 4]:\n        out_dir = './study_predict/'\n        initial_checkpoint = \\\n            _classify_model_path + 'f' + str(fold) + '.pth'\n        ## setup  ----------------------------------------\n        #mode = 'local'\n        mode = 'remote'\n\n        submit_dir = out_dir + '%s-fold%d'%(mode, fold)\n        os.makedirs(submit_dir, exist_ok=True)\n\n        log = Logger()\n        log.open(out_dir + 'log.submit.txt', mode='a')\n        log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n        #log.write('\\t%s\\n' % COMMON_STRING)\n        log.write('\\n')\n\n        #\n        ## dataset ------------------------------------\n        \n        df_valid = make_fold('test')\n\n        valid_dataset = SiimDataset(df_valid)\n        valid_loader  = DataLoader(\n            valid_dataset,\n            sampler = SequentialSampler(valid_dataset),\n            batch_size  = 32,#128, #\n            drop_last   = False,\n            num_workers = 8,\n            pin_memory  = True,\n            collate_fn  = null_collate,\n        )\n        log.write('mode : %s\\n'%(mode))\n        log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n\n        ## net ----------------------------------------\n        if 1:\n            net = Net().cuda()\n            net.load_state_dict(torch.load(initial_checkpoint)['state_dict'], strict=True)\n\n            #---\n            start_timer = timer()\n            probability = do_predict(net, valid_loader)\n            log.write('time %s \\n' % time_to_str(timer() - start_timer, 'min'))\n            log.write('probability %s \\n' % str(probability.shape))\n\n            np.save(submit_dir + '/probability.npy',probability)\n            df_valid.to_csv(submit_dir + '/df_valid.csv', index=False)\n\n        else:\n            probability = np.load(submit_dir + '/probability.npy')\n\n        #----\n        df_study, df_image = probability_to_df_study(df_valid, probability)\n        \n        #df_image = probability_to_df_image(df_valid, None, None)\n        #df_submit = pd.concat([df_study,df_image])\n        df_submit = pd.concat([df_study])\n        df_submit.to_csv(submit_dir + '/submit.csv', index=False)\n\n        log.write('submit_dir : %s\\n' % (submit_dir))\n        log.write('initial_checkpoint : %s\\n' % (initial_checkpoint))\n        log.write('df_submit : %s\\n' % str(df_submit.shape))\n        log.write('%s\\n' % str(df_submit))\n        log.write('\\n')\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:22:57.58793Z","iopub.execute_input":"2021-07-25T13:22:57.588522Z","iopub.status.idle":"2021-07-25T13:22:57.605798Z","shell.execute_reply.started":"2021-07-25T13:22:57.588482Z","shell.execute_reply":"2021-07-25T13:22:57.604541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDENTIFIER   = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\nrun_submit()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-25T13:22:57.607514Z","iopub.execute_input":"2021-07-25T13:22:57.608018Z","iopub.status.idle":"2021-07-25T13:26:57.008033Z","shell.execute_reply.started":"2021-07-25T13:22:57.607975Z","shell.execute_reply":"2021-07-25T13:26:57.006804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_valid = make_fold('test')\n#df_valid","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:57.010347Z","iopub.execute_input":"2021-07-25T13:26:57.010841Z","iopub.status.idle":"2021-07-25T13:26:57.017099Z","shell.execute_reply.started":"2021-07-25T13:26:57.010791Z","shell.execute_reply":"2021-07-25T13:26:57.015119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_remote_ensemble():\n    out_dir = './study_predict/'\n    log = Logger()\n    log.open(out_dir + 'log.submit.txt', mode='a')\n    log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n    #log.write('\\t%s\\n' % COMMON_STRING)\n    log.write('\\n')\n\n\n    submit_dir=[\n        out_dir+'remote-fold0',\n        out_dir+'remote-fold1',\n        out_dir+'remote-fold2',\n        out_dir+'remote-fold3',\n        out_dir+'remote-fold4',\n    ]\n\n    probability=0\n    for d in submit_dir:\n        p = np.load(d + '/probability.npy')\n        probability += p**0.5\n    probability = probability/len(submit_dir)\n\n\n    #----\n    df_valid = pd.read_csv(submit_dir[1] + '/df_valid.csv')\n\n    df_study, df_image  = probability_to_df_study(df_valid, probability)\n    #df_image  = probability_to_df_image(df_valid, None, None)\n    #df_submit = pd.concat([df_study, df_image])\n    df_submit = pd.concat([df_study])\n    \n    #df_submit.to_csv(out_dir + '/effb3-full-512-mask-submit-ensemble1.csv', index=False)\n\n    log.write('submit_dir : %s\\n' % (submit_dir))\n    log.write('df_submit : %s\\n' % str(df_submit.shape))\n    log.write('%s\\n' % str(df_submit))\n    log.write('\\n')\n    \n    return df_submit, df_image","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:38:17.930035Z","iopub.execute_input":"2021-07-25T13:38:17.930424Z","iopub.status.idle":"2021-07-25T13:38:17.939214Z","shell.execute_reply.started":"2021-07-25T13:38:17.930377Z","shell.execute_reply":"2021-07-25T13:38:17.938021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IDENTIFIER   = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\npredict_study, df_image = run_remote_ensemble()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:38:21.493543Z","iopub.execute_input":"2021-07-25T13:38:21.493911Z","iopub.status.idle":"2021-07-25T13:38:21.550096Z","shell.execute_reply.started":"2021-07-25T13:38:21.493878Z","shell.execute_reply":"2021-07-25T13:38:21.548589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda.select_device(0)\ncuda.close()\ncuda.select_device(0)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:57.093331Z","iopub.execute_input":"2021-07-25T13:26:57.093853Z","iopub.status.idle":"2021-07-25T13:26:58.384374Z","shell.execute_reply.started":"2021-07-25T13:26:57.093808Z","shell.execute_reply":"2021-07-25T13:26:58.379362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict 2class","metadata":{}},{"cell_type":"code","source":"#!pip install /kaggle/input/kerasapplications -q","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:58.386474Z","iopub.execute_input":"2021-07-25T13:26:58.38725Z","iopub.status.idle":"2021-07-25T13:26:58.392353Z","shell.execute_reply.started":"2021-07-25T13:26:58.387201Z","shell.execute_reply":"2021-07-25T13:26:58.390886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:58.394261Z","iopub.execute_input":"2021-07-25T13:26:58.394931Z","iopub.status.idle":"2021-07-25T13:26:58.411103Z","shell.execute_reply.started":"2021-07-25T13:26:58.394888Z","shell.execute_reply":"2021-07-25T13:26:58.408293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import efficientnet.tfkeras as efn","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:58.413743Z","iopub.execute_input":"2021-07-25T13:26:58.414595Z","iopub.status.idle":"2021-07-25T13:26:58.423002Z","shell.execute_reply.started":"2021-07-25T13:26:58.414549Z","shell.execute_reply":"2021-07-25T13:26:58.421853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nimport tensorflow as tf\n\ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n    return strategy\n\n\ndef build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.image.resize(img, target_size)\n\n        return img\n\n    def decode_with_labels(path, label):\n        return decode(path), label\n\n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        return img\n\n    def augment_with_labels(img, label):\n        return augment(img), label\n\n    return augment_with_labels if with_labels else augment\n\n\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n\n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n\n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n\n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n\n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO)\n\n    return dset\n\n#COMPETITION_NAME = \"siim-cov19-test-img512-study-600\"\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\n\nIMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:58.43323Z","iopub.execute_input":"2021-07-25T13:26:58.434023Z","iopub.status.idle":"2021-07-25T13:26:58.451215Z","shell.execute_reply.started":"2021-07-25T13:26:58.433976Z","shell.execute_reply":"2021-07-25T13:26:58.449732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:58.453425Z","iopub.execute_input":"2021-07-25T13:26:58.461195Z","iopub.status.idle":"2021-07-25T13:26:58.483366Z","shell.execute_reply.started":"2021-07-25T13:26:58.461146Z","shell.execute_reply":"2021-07-25T13:26:58.481538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2class = meta_df.loc[meta_df.split == \"test\"].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:58.489069Z","iopub.execute_input":"2021-07-25T13:26:58.492149Z","iopub.status.idle":"2021-07-25T13:26:58.506816Z","shell.execute_reply.started":"2021-07-25T13:26:58.492062Z","shell.execute_reply":"2021-07-25T13:26:58.505395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_paths = f'/kaggle/input/covid19512/test/' + df_2class['image_id'] +'.png'","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:26:58.51383Z","iopub.execute_input":"2021-07-25T13:26:58.51711Z","iopub.status.idle":"2021-07-25T13:26:58.531498Z","shell.execute_reply.started":"2021-07-25T13:26:58.517003Z","shell.execute_reply":"2021-07-25T13:26:58.529816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2class['none'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#label_cols = df_2class.columns[5]\n#label_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 注意！！！！！！ 这个模型训练时 没有 drop duplicate\n\"\"\"\ntest_decoder = build_decoder(with_labels=False, target_size=(IMG_SIZE, IMG_SIZE), ext='png')\ndtest = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\nwith strategy.scope():\n    \n    models = []\n    \n    models0 = tf.keras.models.load_model(\n        '../input/siim-covid19-efnb7-train-fold0-5-2class/model0.h5'\n    )\n    models1 = tf.keras.models.load_model(\n        '../input/siim-covid19-efnb7-train-fold0-5-2class/model1.h5'\n    )\n    models2 = tf.keras.models.load_model(\n        '../input/siim-covid19-efnb7-train-fold0-5-2class/model2.h5'\n    )\n    models3 = tf.keras.models.load_model(\n        '../input/siim-covid19-efnb7-train-fold0-5-2class/model3.h5'\n    )\n    models4 = tf.keras.models.load_model(\n        '../input/siim-covid19-efnb7-train-fold0-5-2class/model4.h5'\n    )\n    \n    models.append(models0)\n    models.append(models1)\n    models.append(models2)\n    models.append(models3)\n    models.append(models4)\n\n       \ndf_2class[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)\ndf_2class = df_2class.reset_index(drop=True)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2class['none'] = df_image['negative'].values\ndf_2class.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:39:54.198367Z","iopub.execute_input":"2021-07-25T13:39:54.19876Z","iopub.status.idle":"2021-07-25T13:39:54.215608Z","shell.execute_reply.started":"2021-07-25T13:39:54.198729Z","shell.execute_reply":"2021-07-25T13:39:54.214091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cuda.select_device(0)\n#cuda.close()\n#cuda.select_device(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detect","metadata":{}},{"cell_type":"code","source":"shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\nos.chdir('/kaggle/working/yolov5')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:40:04.710189Z","iopub.execute_input":"2021-07-25T13:40:04.710607Z","iopub.status.idle":"2021-07-25T13:40:05.456995Z","shell.execute_reply.started":"2021-07-25T13:40:04.710574Z","shell.execute_reply":"2021-07-25T13:40:05.45573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = _det_model_path + \"yolom-f0.pt\" + \" \" + _det_model_path + \"yolom-f1.pt\" + \" \" + _det_model_path + \"yolom-f2.pt\" + \" \" + _det_model_path + \"yolom-f3.pt\" + \" \" + _det_model_path + \"yolom-f4.pt\"","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:40:06.74289Z","iopub.execute_input":"2021-07-25T13:40:06.743299Z","iopub.status.idle":"2021-07-25T13:40:06.752762Z","shell.execute_reply.started":"2021-07-25T13:40:06.743267Z","shell.execute_reply":"2021-07-25T13:40:06.751293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py --weights {MODEL_PATH} \\\n                  --source {_test_files_path} \\\n                  --img {IMG_SIZE} \\\n                  --conf 0.001 \\\n                  --iou-thres 0.5 \\\n                  --save-txt \\\n                  --save-conf\n","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:40:13.863116Z","iopub.execute_input":"2021-07-25T13:40:13.863482Z","iopub.status.idle":"2021-07-25T13:45:32.887716Z","shell.execute_reply.started":"2021-07-25T13:40:13.86345Z","shell.execute_reply":"2021-07-25T13:45:32.886448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n\n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n    return bboxes\n\n\nimage_ids = []\nPredictionStrings = []\n\n#for file_path in tqdm(glob('runs/detect/exp/labels/*.txt')):\nfor dir_path, _, filenames in os.walk(_test_files_path):\n        print(len(filenames))\nfor file in filenames:\n    file_path = 'runs/detect/exp/labels/' + file.replace(\".png\", '.txt')\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w, h = meta_df.loc[meta_df.image_id == image_id,['dim1', 'dim0']].values[0]\n    if not os.path.exists(file_path):\n        bboxes = \"none 1 0 0 1 1\"\n    else:\n        f = open(file_path, 'r')\n        data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n        data = data[:, [0, 5, 1, 2, 3, 4]]\n        bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n        for idx in range(len(bboxes)):\n            bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n        bboxes = ' '.join(bboxes)\n    image_id += \"_image\"\n    image_ids.append(image_id)\n    PredictionStrings.append(bboxes)\n\npredict_image = pd.DataFrame({'id':image_ids,\n                        'PredictionString':PredictionStrings})","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:45:32.890383Z","iopub.execute_input":"2021-07-25T13:45:32.890804Z","iopub.status.idle":"2021-07-25T13:45:37.163252Z","shell.execute_reply.started":"2021-07-25T13:45:32.890745Z","shell.execute_reply":"2021-07-25T13:45:37.162229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"for i in range(predict_image.shape[0]):\n    if predict_image.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n        continue\n    sub_df_split = predict_image.loc[i,'PredictionString'].split()\n    sub_df_list = []\n    for j in range(int(len(sub_df_split) / 6)):\n        sub_df_list.append('opacity')\n        sub_df_list.append(sub_df_split[6 * j + 1])\n        sub_df_list.append(sub_df_split[6 * j + 2])\n        sub_df_list.append(sub_df_split[6 * j + 3])\n        sub_df_list.append(sub_df_split[6 * j + 4])\n        sub_df_list.append(sub_df_split[6 * j + 5])\n    predict_image.loc[i,'PredictionString'] = ' '.join(sub_df_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:45:37.165685Z","iopub.execute_input":"2021-07-25T13:45:37.166149Z","iopub.status.idle":"2021-07-25T13:45:37.733466Z","shell.execute_reply.started":"2021-07-25T13:45:37.166077Z","shell.execute_reply":"2021-07-25T13:45:37.732123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(predict_image.shape[0]):\n    if predict_image.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n        _none = str(df_2class.loc[df_2class.image_id + \"_image\" == predict_image.iloc[i].id]['none'].item())\n        predict_image.loc[i,'PredictionString'] = predict_image.loc[i,'PredictionString'] + ' none ' + _none + ' 0 0 1 1'#","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:45:37.735315Z","iopub.execute_input":"2021-07-25T13:45:37.73573Z","iopub.status.idle":"2021-07-25T13:45:40.068903Z","shell.execute_reply.started":"2021-07-25T13:45:37.735689Z","shell.execute_reply":"2021-07-25T13:45:40.067712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, row in predict_study.iterrows():\n    submit_df.loc[submit_df.id == row.id, \"PredictionString\"] = row.PredictionString\n    \nfor index, row in predict_image.iterrows():\n    submit_df.loc[submit_df.id == row.id, \"PredictionString\"] = row.PredictionString","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:45:40.070586Z","iopub.execute_input":"2021-07-25T13:45:40.071056Z","iopub.status.idle":"2021-07-25T13:45:42.974898Z","shell.execute_reply.started":"2021-07-25T13:45:40.07101Z","shell.execute_reply":"2021-07-25T13:45:42.973871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df.to_csv('/kaggle/working/submission.csv',index = False)  ","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:46:01.721629Z","iopub.execute_input":"2021-07-25T13:46:01.72201Z","iopub.status.idle":"2021-07-25T13:46:01.798393Z","shell.execute_reply.started":"2021-07-25T13:46:01.721977Z","shell.execute_reply":"2021-07-25T13:46:01.797306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nsample = submit_df.iloc[-1]\nprint(sample.id, sample.PredictionString)\n\n_study = meta_df.loc[meta_df.image_id + \"_image\" == sample.id].study.item()\nprint(_study)\n_study_item = submit_df.loc[submit_df.id == _study + \"_study\"]\n_study_item\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:45:43.008805Z","iopub.status.idle":"2021-07-25T13:45:43.009341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.rmtree('/kaggle/working/yolov5')\nshutil.rmtree('/kaggle/working/study_predict')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}