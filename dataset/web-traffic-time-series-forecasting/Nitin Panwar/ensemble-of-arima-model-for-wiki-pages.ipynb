{"cells":[{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"1328926e-4cda-45cb-95d3-ebe1658df8c2","_uuid":"1b100b7e5361d81b846d8ef32eb7fca73e4c699e"},"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re # to separate pages based on language (regular expression)\nimport matplotlib.pyplot as plt # to visualize data\nfrom pandas.tools.plotting import autocorrelation_plot # to visualize and configure the parameters of ARIMA model\nfrom statsmodels.tsa.arima_model import ARIMA # to make an ARIMA model that fits the data"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"b874b339-ccb9-4204-b00e-fd457d8e7f87","_uuid":"23c16cdccec1a822a5572e7941c52a37477849fc"},"source":"train_df = pd.read_csv('../input/train_1.csv').fillna(0)\ntrain_df.head()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"8c76bb20-1525-4f67-8838-fbe84cd63988","_uuid":"3151f66b33ce9ffd356bccbf7c48f77c64d65c95"},"source":"train_df.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f80d5f97-0e7c-487a-b4dc-535404a572f2","_uuid":"c3a9f0a88b6f9202cfa6e84079beb08091d43907"},"source":"### Simple code to get the language of any given page"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"73123a60-bf2a-4aa2-a826-a5384df34627","collapsed":true,"_uuid":"932101ffc8467879fbb00be730bc4dc13bd110b3"},"source":"def find_language(url):\n    res = re.search('[a-z][a-z].wikipedia.org',url)\n    if res:\n        return res[0][0:2]\n    return 'na'\n\ntrain_df['lang'] = train_df.Page.map(find_language)"},{"cell_type":"markdown","metadata":{"_cell_guid":"93a78312-479e-43e6-b5e8-cfc562e04c55","_uuid":"4e5baf613e8b435507a36d96a11c7e038de5e3f2"},"source":"### Here we separate all the pages based on their language and average them up to find views per page per language"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"e78bfee2-98b3-4fd2-8d70-be26928f01e2","collapsed":true,"_uuid":"2049fb6b9a5a82d6f22186e0f4a76ef84238ac31"},"source":"lang_sets = {}\nlang_sets['en'] = train_df[train_df.lang=='en'].iloc[:,0:-1]\nlang_sets['ja'] = train_df[train_df.lang=='ja'].iloc[:,0:-1]\nlang_sets['de'] = train_df[train_df.lang=='de'].iloc[:,0:-1]\nlang_sets['na'] = train_df[train_df.lang=='na'].iloc[:,0:-1]\nlang_sets['fr'] = train_df[train_df.lang=='fr'].iloc[:,0:-1]\nlang_sets['zh'] = train_df[train_df.lang=='zh'].iloc[:,0:-1]\nlang_sets['ru'] = train_df[train_df.lang=='ru'].iloc[:,0:-1]\nlang_sets['es'] = train_df[train_df.lang=='es'].iloc[:,0:-1]\n\nsums = {}\nfor key in lang_sets:\n    sums[key] = lang_sets[key].iloc[:,1:].sum(axis=0) / lang_sets[key].shape[0]"},{"cell_type":"markdown","metadata":{"_cell_guid":"189f03e0-27c8-40b5-b85b-1755346ff276","_uuid":"72f310df144bb407f9a2707593d279733f419351"},"source":"### Plots of average number of views for all different languages per day "},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"dda148fb-ab53-4935-a962-b10441e04dee","scrolled":true,"_uuid":"9872d9366c5a581a3d37500eeb81267850987de7"},"source":"days = [r for r in range(sums['en'].shape[0])]\n\nfig = plt.figure(1,figsize=[10,10])\nplt.ylabel('Views per Page')\nplt.xlabel('Day')\nplt.title('Pages in Different Languages')\nlabels={'en':'English','ja':'Japanese','de':'German',\n        'na':'Media','fr':'French','zh':'Chinese',\n        'ru':'Russian','es':'Spanish'\n       }\n\nfor key in sums:\n    plt.plot(days,sums[key],label = labels[key] )\n    \nplt.legend()\nplt.show()\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b63e83a-55c3-4ee7-8c33-e87ba30ddc94","_uuid":"80535b2fca75d2c25412b789af824dd0119f5486"},"source":"### Now we can plot Autocorrelation and Partial Autocorrelation graphs for all these languages, to estimate the hyperparameters used in training the ARIMA model."},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"553f30cd-2d9f-4d41-ab0b-74fd49e755e2","_uuid":"4964b1bf73a89aa929d3b82b25511be686c030c2"},"source":"from statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import acf\n\nfor key in sums:\n    fig = plt.figure(1,figsize=[10,5])\n    ax1 = fig.add_subplot(121)\n    ax2 = fig.add_subplot(122)\n    data = np.array(sums[key])\n    autocorr = acf(data)\n    pac = pacf(data)\n\n    x = [x for x in range(len(pac))]\n    ax1.plot(x[1:],autocorr[1:])\n\n    ax2.plot(x[1:],pac[1:])\n    ax1.set_xlabel('Lag')\n    ax1.set_ylabel('Autocorrelation')\n\n    ax2.set_xlabel('Lag')\n    ax2.set_ylabel('Partial Autocorrelation')\n    print(key)\n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f9982671-4b9f-460a-a945-e11b0db92d13","_uuid":"8a19984748d482717c1d2b3d4dc3195c58d3d5fd"},"source":"### Looking at all these graphs we conclude\n 1. We won't be needing any differencing for en, ru, fr, na (d=0). For the others we need to subtract them once from their predecessor (d=1).\n 2. For ja, de, zh, es there is a trend of peaks after 7 days. Thus a lag of 7 might be used and for the rest a lag of 4 should work okay."},{"cell_type":"markdown","metadata":{"_cell_guid":"663b32a7-e0ec-44d3-92d2-5d9eb48a536a","_uuid":"c19181bd2a7d4ad0c5808a89a0170b43cbb69f9f"},"source":"## Now we will be training ARIMA models for different languages"},{"cell_type":"markdown","metadata":{"_cell_guid":"3c212765-862c-4b11-9df1-e7f1ea55fc07","_uuid":"840ad13d6803387b2f2618871885eb017a43d7da"},"source":"We tune in the parameters discussed above and train our ARIMA models as follows:"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"40529eb1-79af-4eb5-8c49-d4527d1c7a6a","_uuid":"ecc8041bcb019ecda1fd7c176664fe000fe4bb12"},"source":"params = {'en': [4,1,0], 'ja': [7,1,1], 'de': [7,1,1], 'na': [4,1,0], 'fr': [4,1,0], 'zh': [7,1,1], 'ru': [4,1,0], 'es': [7,1,1]}\n\nfor key in sums:\n    data = np.array(sums[key][0:300])\n    data1 = np.array(sums[key])\n    result = None\n    arima = ARIMA(data,params[key])\n    result = arima.fit(disp=False)\n    #print(result.params)\n    pred = result.predict(301,608,typ='levels')\n    x = [i for i in range(644)]\n    i=0\n    \n    print(key)\n    plt.plot(x[2:len(data1)],data1[2:] ,label='Data')\n    plt.plot(x[len(data)+1:len(data)+310],pred,label='ARIMA Model')\n    \n    plt.xlabel('Days')\n    plt.ylabel('Views')\n    plt.legend()\n    plt.show()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"158e4b78-c852-45ad-b0f2-1ab3388610e8","_uuid":"1b971a2fcacb0bf3b724010256bac5aae1f4d4bf"},"source":"params = {'en': [4,1,0], 'ja': [7,1,1], 'de': [7,1,1], 'na': [4,1,0], 'fr': [4,1,0], 'zh': [7,1,1], 'ru': [4,1,0], 'es': [7,1,1]}\n\nfor key in sums:\n    data = np.array(sums[key])\n    result = None\n    arima = ARIMA(data,params[key])\n    result = arima.fit(disp=False)\n    print(key)\n    print(sums[key])\n    pred = result.predict(550,608,typ='levels')\n    print(pd.Series(pred))\n    \n    #sums[key].append(pred,ignore_index=True)\n    break;\n    "},{"cell_type":"markdown","metadata":{"_cell_guid":"5664c5e6-5905-49a3-8ff6-b53e15719cb4","collapsed":true,"_uuid":"57944f6ece133c079ace6b5056419cdf0a88a7f1"},"source":"### Now let's use this ARIMA model and submit the output ?"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"24dbd2e0-fe66-496c-b551-86cfbc3e5323","_uuid":"891746a8792a25b6a14254fe0074c051f3d08ab1"},"source":"train_df.head()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"899bf21b-f155-4cba-b5db-3a825b70f334","_uuid":"d051db6dcb9531e07d489432ee433b79a6de162e"},"source":"train_df = train_df.drop('Page',axis = 1)\ntrain_df.shape"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"687c4c41-0023-465f-b895-48765673c6df","_uuid":"2e6cbdaf51a192f7dd0523dbec04d3297a57c02e"},"source":"print(sums['en'])"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"ed76d361-8362-4aaa-abf8-1de17594e9a4","collapsed":true,"_uuid":"cc04998912631b6b518ccc051830d8c42cd9a9de"},"source":"#Packages for pre processing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n # Importing the Keras libraries and packages for LSTM\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"71cbc03a-06e7-4bcf-a369-03ccb8672068","scrolled":true,"collapsed":true,"_uuid":"4a65bd5adf056ca55768340e014966d36a13cda8"},"source":" for key in sums:\n    row = [0]*sums[key].shape[0]\n    for i in range(sums[key].shape[0]):\n        row[i] = sums[key][i]\n\n\n    #Using Data From Random Row for Training and Testing\n\n    X = row[0:549]\n    y = row[1:550]\n\n    # Splitting the dataset into the Training set and Test set\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n\n    # Feature Scaling\n    sc = MinMaxScaler()\n    X_train = np.reshape(X_train,(-1,1))\n    y_train = np.reshape(y_train,(-1,1))\n    X_train = sc.fit_transform(X_train)\n    y_train = sc.fit_transform(y_train)\n\n\n    #Training LSTM\n\n    #Reshaping Array\n    X_train = np.reshape(X_train, (384,1,1))\n\n    # Initialising the RNN\n    regressor = Sequential()\n\n    # Adding the input layerand the LSTM layer\n    regressor.add(LSTM(units = 8, activation = 'relu', input_shape = (None, 1)))\n\n\n    # Adding the output layer\n    regressor.add(Dense(units = 1))\n\n    # Compiling the RNN\n    regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n\n    # Fitting the RNN to the Training set\n    regressor.fit(X_train, y_train, batch_size = 10, epochs = 100, verbose = 0)\n\n    # Getting the predicted Web View\n    inputs = X\n    inputs = np.reshape(inputs,(-1,1))\n    inputs = sc.transform(inputs)\n    inputs = np.reshape(inputs, (549,1,1))\n    y_pred = regressor.predict(inputs)\n    y_pred = sc.inverse_transform(y_pred)\n\n    print(key)\n    #Visualising Result\n    plt.figure\n    plt.plot(y, color = 'red', label = 'Real Web View')\n    plt.plot(y_pred, color = 'blue', label = 'Predicted Web View')\n    plt.title('Web View Forecasting')\n    plt.xlabel('Number of Days from Start')\n    plt.ylabel('Web View')\n    plt.legend()\n    plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a48475c0-6d98-42e8-8e92-d294b6307f0d","_uuid":"b0672f3adb1af10e22561b4e6a113169d582308f"},"source":"### Now we will combine the 2 models and make an ensemble out of it in the next step"}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"mimetype":"text/x-python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.1","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python"}}}