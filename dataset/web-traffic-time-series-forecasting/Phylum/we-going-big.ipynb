{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_cell_guid":"45fc169e-afb5-49af-9624-f41c6a460af4","_uuid":"959fc063d1cc3d0817ef7edec46995eb1a8d926a","_kg_hide-output":false,"scrolled":true},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#train = pd.read_csv('../input/train_1.csv').fillna('0')\ntrain = pd.read_csv(\"../input/train_1.csv\")\ntrain.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"0a01469d-1439-498d-a6e2-1c432c65e823","_uuid":"db3331f17199e93decfd1bc85f91a8ccef8b6f7b"},"source":"# split away the page data from the time series data\ntrain_pages = pd.DataFrame({ 'Page': train[\"Page\"]})\ntrain_pages.head()\n        ","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"ec321f62-53eb-4884-bb00-f1c7ef3263ed","_uuid":"c6e8bf0b83fb62682c175aab356417ea7e7d82c2","scrolled":true},"source":"# from https://www.kaggle.com/muonneutrino/wikipedia-traffic-data-exploration\n# create properties for the important data points\nimport re\ndef getLang(page):\n    sear = re.search('[a-z][a-z].wikipedia.org',page)\n    if sear:\n        return sear[0][0:2]\n    return 'null'\n\ntrain_pages['language'] = train_pages.Page.map(getLang)\n\ndef getExtra(page):\n    i = page.find(\".org_\")\n    if i > 0:\n        return page[i+len(\".org_\"):]\n    return \"NA\"\n\ntrain_pages['namemeta'] = train_pages.Page.map(getExtra)\n\ndef getAccess(page):\n    spl = page.split(\"_\")\n    if len(spl) >= 1:\n        return spl[0]\n    return 'null'\ntrain_pages['access'] = train_pages.namemeta.map(getAccess)\n\ndef getClient(page):\n    spl = page.split(\"_\")\n    if len(spl) >= 2:\n        return spl[1]\n    return 'null'\ntrain_pages['client'] = train_pages.namemeta.map(getClient)\ntrain_pages.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"86e330ae-0716-479b-a371-267107d0dbc7","_uuid":"a9617d2b9699b11e5f02a6d01101043ff26d6493"},"source":"#train[\"mean\"] = train.drop(\"Page\", axis=1).mean(axis=0)\n\ntrain['mean'] = train.drop(\"Page\", axis=1).astype(float).mean(axis=1, skipna=True)\ntrain.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"168acf78-5f96-4886-9eb7-5a0bc4b3b982","_uuid":"aca188f170b67af3f25e402d5fe571850448ec4b"},"source":"for i in train.iterrows():\n    print(i[1][1:])\n    print(max(i[1]))\n    raise Exception\ntrain.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"8965eae7-c350-4b29-9ae6-c6bd1c241cac","collapsed":true,"_uuid":"71b438606e2d8decd6e885035a514d6f1fb0db37","scrolled":true},"source":"# rename our time series data briefly - they are sequential over 500 days it seems?\nr = list(range(0,550))\n\nfrom datetime import datetime\ndateRoot = datetime.strptime(\"2015-07-01\", \"%Y-%m-%d\")\ndef getDateDiff(dateString):\n    dateDiff = datetime.strptime(dateString, \"%Y-%m-%d\")\n    return (dateDiff - dateRoot).days()\n\ntimef_train = train.drop(\"Page\", axis=1).drop(\"mean\", axis=1)\ntimef_train.columns = r\ntimef_train.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"783ca925-755a-426c-bfff-4338190e3da0","collapsed":true,"_uuid":"f9ce639714abdfd658cdc4c7d4260c567d78b342"},"source":"import scipy.optimize\nimport matplotlib.pyplot as plt\nfrom math import exp\n\ndef gaussian(x, amp, cen, wid):\n    return amp * np.exp(-(x-cen)**2 / wid)\n\n\n#xdata = #timef_train.columns.astype(float);\nxdata = list(range(0,550))\nfor row in timef_train.iterrows():\n    ydata = row[1]\n    popt, pcov = scipy.optimize.curve_fit(gaussian, xdata, ydata)\n    fig = plt.figure()\n    ax = fig.add_subplot(2,1,1)\n    ax.plot(xdata, ydata, 'b-', label='data')\n    ax.plot(xdata, gaussian(xdata, *popt), 'g--', label='fit-test')\n    ax.set_yscale('log')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    ax.legend()\n    plt.show()\n    raise Exception\n","execution_count":null,"cell_type":"code","outputs":[]}]}