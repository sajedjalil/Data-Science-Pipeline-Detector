{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python","version":"3.6.1","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3}}},"cells":[{"metadata":{"trusted":true,"_uuid":"cff98cd4cfcff6ae891a23ae1018f2c3f95936a3","_cell_guid":"5dc09cd8-3788-4389-927f-caf4b0158ce2"},"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nfrom fbprophet import Prophet\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c3ce9995f24962a889f13bb89415c580878f357","_cell_guid":"21f58d52-edb1-4a86-9e22-163770e4c7e1"},"execution_count":null,"cell_type":"code","source":"train_1 = pd.read_csv('../input/train_1.csv')\ntrain_1.head()","outputs":[]},{"metadata":{"trusted":true,"_uuid":"bff83c132c57d7e64b6cb70014dbad364952f6c8","_cell_guid":"d798023f-8ee8-4536-8f1d-daca51e8b0cf"},"execution_count":null,"cell_type":"code","source":"train_1.fillna(0, inplace=True)\npage=pd.DataFrame(train_1[train_1.columns[0]])\ntrain_1=train_1.drop(train_1.columns[0], axis=1)\ntrain_1.columns=range(len(train_1.columns))\ntrain_1=train_1.transpose()  \ntrain_1.columns=[page[page.columns[0]]]    \ntrain_1=train_1.convert_objects(convert_numeric=True)\ntrain_1.head()","outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4ec03b9a9417a95a9139a6807a934a2ad5850c8","collapsed":true,"_cell_guid":"7c5bba59-1b04-474e-836a-6a2f45988cd9"},"execution_count":null,"cell_type":"code","source":"df=pd.DataFrame(train_1[train_1.columns[0]])\ndf.insert(loc=1, column='visits', value=train_1[train_1.columns[1]])  #number columns \ny=df[-60:] \ny=y.visits.values\ndf=df[:-60]\n\ncount=0\nfor i in df.visits:\n    if i == 0:\n        count=count+1\n        \ndf=df[count:]\ndf.visits.replace(to_replace=0,value=df.visits.mean(),inplace=True)\ndf['visits'] = np.log(df['visits'])\ndf.columns = [\"ds\", \"y\"]","outputs":[]},{"metadata":{"trusted":true,"_uuid":"21928dc85e7ad5ad54f271c74822103dd8a9dcf6","collapsed":true,"_cell_guid":"4d99a662-dab1-4e69-bd4f-372689eaee2d"},"execution_count":null,"cell_type":"code","source":"articles = pd.DataFrame({\n  'holiday': 'publish',\n  'ds': pd.to_datetime(['2014-09-27', '2014-10-05', '2014-10-14', '2014-10-26', '2014-11-9',\n                        '2014-11-18', '2014-11-30', '2014-12-17', '2014-12-29', '2015-01-06',\n                        '2015-01-20', '2015-02-02', '2015-02-16', '2015-03-23', '2015-04-08',\n                        '2015-05-04', '2015-05-17', '2015-06-09', '2015-07-02', '2015-07-13',\n                        '2015-08-17', '2015-09-14', '2015-10-26', '2015-12-07', '2015-12-30',\n                        '2016-01-26', '2016-04-06', '2016-05-16', '2016-06-15', '2016-08-23',\n                        '2016-08-29', '2016-09-06', '2016-11-21', '2016-12-19', '2016-12-31',\n                        '2017-01-01', '2017-01-17', '2017-02-06', '2017-02-21']),\n  'lower_window': 0,\n  'upper_window': 3,\n})","outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c5c317e3e4a0f9676ed6806374385d2a83ccada","collapsed":true},"execution_count":null,"cell_type":"code","source":"m = Prophet(holidays=articles,changepoint_prior_scale=0.01,weekly_seasonality=True,yearly_seasonality=True).fit(df)\nfuture = m.make_future_dataframe(periods=60)\nforecast = m.predict(future)\n\nforecast[\"Sessions\"] = np.exp(forecast.yhat).round()\nforecast[\"Sessions_lower\"] = np.exp(forecast.yhat_lower).round()\nforecast[\"Sessions_upper\"] = np.exp(forecast.yhat_upper).round()\nforecast[(forecast.ds > \"3-5-2017\") &(forecast.ds < \"4-1-2017\")][[\"ds\", \"yhat\", \"Sessions_lower\",\"Sessions\", \"Sessions_upper\"]]\n\nforecast[\"Projected_Sessions\"] = np.exp(forecast.yhat).round()\nforecast[\"Projected_Sessions_lower\"] = np.exp(forecast.yhat_lower).round()\nforecast[\"Projected_Sessions_upper\"] = np.exp(forecast.yhat_upper).round()","outputs":[]},{"metadata":{"trusted":true,"_uuid":"23b3cf6363dac63b52bc21dcb435f91d83a39c9b","collapsed":true},"execution_count":null,"cell_type":"code","source":"final_proj = forecast[(forecast.ds > \"2016-11-01\") &(forecast.ds < \"2017-03-02\")][[\"ds\", \"Projected_Sessions_lower\",\"Projected_Sessions\", \"Projected_Sessions_upper\"]]\nm.plot(forecast);\n\ndef getsmape(pred,target):\n    smape=0\n    for i in range(len(pred)):\n        smape=smape+(abs(target[i]-pred[i])/((abs(target[i])+abs(pred[i]))/2))\n    smape=smape*100/len(pred)\n    return smape\n\nx=final_proj.Projected_Sessions\nx=x.values\nx=x*0.8  #0.8 it's well\nsmape=getsmape(x,y)\nprint (smape)","outputs":[]}],"nbformat_minor":1,"nbformat":4}