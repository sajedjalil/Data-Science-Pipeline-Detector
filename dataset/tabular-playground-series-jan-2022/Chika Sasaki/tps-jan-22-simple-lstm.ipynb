{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **TPS Jan 22 simple LSTM**\n\nI create this notebook for the purpose of learning LSTM.\n\nReferring to the following great notebooks.Thanks for sharing the information.\n\nhttps://www.kaggle.com/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru\n\nhttps://www.kaggle.com/samuelcortinhas/tps-jan-22-eda-modelling/notebook","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom itertools import combinations\nimport statistics\nimport time\nfrom datetime import datetime\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\nfrom tensorflow.keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\ntest_data = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=train_data.num_sold\nX=train_data.drop('num_sold', axis=1)\n\nX.date=pd.to_datetime(X.date)\ntest_data.date=pd.to_datetime(test_data.date)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unofficial_hol(hol_path, df):\n    countries = {'Finland': 1, 'Norway': 2, 'Sweden': 3}\n    stores = {'KaggleMart': 1, 'KaggleRama': 2}\n    products = {'Kaggle Mug': 1,'Kaggle Hat': 2, 'Kaggle Sticker': 3}\n    \n    # load holiday info.\n    holiday = pd.read_csv(hol_path)\n    \n    fin_holiday = holiday.loc[holiday.country == 'Finland']\n    swe_holiday = holiday.loc[holiday.country == 'Sweden']\n    nor_holiday = holiday.loc[holiday.country == 'Norway']\n    df['fin holiday'] = df.date.isin(fin_holiday.date).astype(int)\n    df['swe holiday'] = df.date.isin(swe_holiday.date).astype(int)\n    df['nor holiday'] = df.date.isin(nor_holiday.date).astype(int)\n    df['holiday'] = np.zeros(df.shape[0]).astype(int)\n    df.loc[df.country == 'Finland', 'holiday'] = df.loc[df.country == 'Finland', 'fin holiday']\n    df.loc[df.country == 'Sweden', 'holiday'] = df.loc[df.country == 'Sweden', 'swe holiday']\n    df.loc[df.country == 'Norway', 'holiday'] = df.loc[df.country == 'Norway', 'nor holiday']\n    df.drop(['fin holiday', 'swe holiday', 'nor holiday'], axis=1, inplace=True)\n    \n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def date_feat_eng(df):\n    df['day_of_week']=df['date'].dt.dayofweek       # 0 to 6\n    df['day_of_month']=df['date'].dt.day            # 1 to 31\n    df['weekend']=(df['day_of_week']//5 == 1)       # 0 or 1\n    df['weekend']=df['weekend'].astype('int')       # int64\n    df['week']=df['date'].dt.isocalendar().week     # 1 to 53\n    df['week'][df['week']>52]=52                    # 1 to 52\n    df['week']=df['week'].astype('int')             # int64\n    df['month']=df['date'].dt.month                 # 1 to 12\n    df['quarter']=df['date'].dt.quarter             # 1 to 4\n    df['year']=df['date'].dt.year                   # 2015 to 2019\n    df.drop('date',axis=1, inplace=True)            # drop date\n    return df\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hol_path = '../input/public-and-unofficial-holidays-nor-fin-swe-201519/holidays.csv'\n\nX = unofficial_hol(hol_path, X)\ntest_data = unofficial_hol(hol_path, test_data)\n\nX= date_feat_eng(X)\ntest_data=date_feat_eng(test_data)\n\n# Encoding\nX=pd.get_dummies(X, columns=['store', 'country', 'product'])\ntest_data=pd.get_dummies(test_data, columns=['store', 'country', 'product'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = np.array(X), np.array(y)\n\n# Reshaping X_train for efficient modelling\nX_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I also tried the GRU architecture, but did not get good results.","metadata":{}},{"cell_type":"code","source":"# The LSTM architecture\n\nregressor = Sequential()\n# First LSTM layer with Dropout regularisation\nregressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\nregressor.add(Dropout(0.2))\n# Second LSTM layer\nregressor.add(LSTM(units=50, return_sequences=True))\nregressor.add(Dropout(0.2))\n# Third LSTM layer\nregressor.add(LSTM(units=50, return_sequences=True))\nregressor.add(Dropout(0.2))\n# Fourth LSTM layer\nregressor.add(LSTM(units=50))\nregressor.add(Dropout(0.2))\n# The output layer\nregressor.add(Dense(units=1))\n\n# Compiling the RNN\nregressor.compile(optimizer='rmsprop',loss='mean_squared_error')\n# Fitting to the training set\nregressor.fit(X_train,y_train,epochs=50,batch_size=32)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.array(test_data)\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\npredicted_value = regressor.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = X_test[:,0]\noutput = np.concatenate([rows, predicted_value],axis=1)\n\noutput = pd.DataFrame({'row_id': test_data.row_id,\n                       'num_sold': np.squeeze(predicted_value)})\n\noutput.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}