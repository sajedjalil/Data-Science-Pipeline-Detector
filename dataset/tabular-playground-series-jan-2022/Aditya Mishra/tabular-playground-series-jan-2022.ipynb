{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* I had used pycaret to know which model suits best for our prepared data set, however did not include this in the the notebook as this would significantly increase processing time.\n* Will be posting new results after I tune the hyper parameters.\n* have used GDP datset and passed it as inputs to the model, additionally have calculated holidays.","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\n\nimport dateutil.easter as easter\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pathlib import Path\nfrom learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_periodogram, seasonal_plot\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom statsmodels.tsa.deterministic import DeterministicProcess","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:14:33.856116Z","iopub.execute_input":"2022-01-19T07:14:33.856525Z","iopub.status.idle":"2022-01-19T07:14:35.647328Z","shell.execute_reply.started":"2022-01-19T07:14:33.856434Z","shell.execute_reply":"2022-01-19T07:14:35.645897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will be importing GDP data as well to generate more insights from the data, we will use GDP datasets of ","metadata":{}},{"cell_type":"code","source":"original_train_df = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\noriginal_test_df = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')\ngdp_df = pd.read_csv('../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\n\ngdp_df.set_index('year', inplace=True)\n\n# The dates are read as strings and must be converted\nfor df in [original_train_df, original_test_df]:\n    df['date'] = pd.to_datetime(df.date)\noriginal_train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:14:35.649207Z","iopub.execute_input":"2022-01-19T07:14:35.649497Z","iopub.status.idle":"2022-01-19T07:14:35.769814Z","shell.execute_reply.started":"2022-01-19T07:14:35.649466Z","shell.execute_reply":"2022-01-19T07:14:35.768773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# keeping a function ready to compute SMAPE\ndef smape_loss(y_true, y_pred):\n    \"\"\"SMAPE Loss\"\"\"\n    return np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:14:35.771546Z","iopub.execute_input":"2022-01-19T07:14:35.771865Z","iopub.status.idle":"2022-01-19T07:14:35.777714Z","shell.execute_reply.started":"2022-01-19T07:14:35.771827Z","shell.execute_reply":"2022-01-19T07:14:35.776515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering\ndef engineer(df):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    \n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp_df.loc[row.date.year, country]\n        \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis=1)),\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    # The three products have different seasonal patterns\n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 3):\n        new_df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Mug']\n        new_df[f'hat_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Hat']\n        new_df[f'hat_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Hat']\n\n    return new_df\n\ntrain_df = engineer(original_train_df)\ntrain_df['date'] = original_train_df.date\ntrain_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\ntest_df = engineer(original_test_df)\n\nfeatures = test_df.columns\n\nfor df in [train_df, test_df]:\n    df[features] = df[features].astype(np.float32)\nprint(list(features))","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:14:35.779884Z","iopub.execute_input":"2022-01-19T07:14:35.780139Z","iopub.status.idle":"2022-01-19T07:14:37.081411Z","shell.execute_reply.started":"2022-01-19T07:14:35.780108Z","shell.execute_reply":"2022-01-19T07:14:37.080439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering for holidays\ndef engineer_more(df):\n    \"\"\"Return a new dataframe with more engineered features\"\"\"\n    new_df = engineer(df)\n\n    # End of year\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in range(1, 14)}),\n                        pd.DataFrame({f\"jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in range(1, 15)})],\n                       axis=1)\n    \n    # May\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n                                      for d in list(range(1, 10))}), #  + list(range(17, 25))\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in list(range(19, 26))})],\n                       axis=1)\n    \n    # June and July\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 14))}),\n                        #pd.DataFrame({f\"june{d}\":\n                        #              (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Norway')\n                        #              for d in list(range(22, 31))}),\n                        #pd.DataFrame({f\"july{d}\":\n                        #              (df.date.dt.month == 7) & (df.date.dt.day == d) & (df.country == 'Norway')\n                        #              for d in list(range(1, 3))})],\n                       ],\n                       axis=1)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 6))})],\n                       axis=1)\n    \n    # First Sunday of November\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})],\n                       axis=1)\n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 14))})],\n                       axis=1)\n\n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(50, 59))})],\n                       axis=1)\n    \n    return new_df.astype(np.float32)\n\ntrain_df = engineer_more(original_train_df)\ntrain_df['date'] = original_train_df.date\ntrain_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\ntest_df = engineer_more(original_test_df)\n\nfeatures = list(test_df.columns)\nprint(list(features))","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:14:37.082876Z","iopub.execute_input":"2022-01-19T07:14:37.083177Z","iopub.status.idle":"2022-01-19T07:14:39.583417Z","shell.execute_reply.started":"2022-01-19T07:14:37.083143Z","shell.execute_reply":"2022-01-19T07:14:39.582585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:14:39.584676Z","iopub.execute_input":"2022-01-19T07:14:39.585554Z","iopub.status.idle":"2022-01-19T07:14:39.59081Z","shell.execute_reply.started":"2022-01-19T07:14:39.585508Z","shell.execute_reply":"2022-01-19T07:14:39.589642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop('date', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:14:39.592122Z","iopub.execute_input":"2022-01-19T07:14:39.592685Z","iopub.status.idle":"2022-01-19T07:14:39.624605Z","shell.execute_reply.started":"2022-01-19T07:14:39.592631Z","shell.execute_reply":"2022-01-19T07:14:39.62362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_df.drop('num_sold',axis=1),train_df['num_sold'], test_size=0.2)\nct = CatBoostRegressor(verbose=False, eval_metric='SMAPE')\nct.fit(X_train, y_train, eval_set=(X_val,y_val))\nct","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:15:12.198218Z","iopub.execute_input":"2022-01-19T07:15:12.198975Z","iopub.status.idle":"2022-01-19T07:15:16.765153Z","shell.execute_reply.started":"2022-01-19T07:15:12.198933Z","shell.execute_reply":"2022-01-19T07:15:16.764284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = ct.predict(test_df)\npred = [int(i) for i in pred] \n# new_test_df = pd.read_csv(\"../input/tabular-playground-series-jan-2022/test.csv\")\n# new_test_df['num_sold'] = pred\n# new_test_df = new_test_df[['row_id','num_sold']]\n# new_test_df.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:15:20.845507Z","iopub.execute_input":"2022-01-19T07:15:20.845782Z","iopub.status.idle":"2022-01-19T07:15:20.883047Z","shell.execute_reply.started":"2022-01-19T07:15:20.845754Z","shell.execute_reply":"2022-01-19T07:15:20.882294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This notebook will be updated further.","metadata":{}},{"cell_type":"markdown","source":"### Let us try creating different models for different stores","metadata":{}},{"cell_type":"code","source":"original_train_df[\"store\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:22:43.769981Z","iopub.execute_input":"2022-01-19T07:22:43.770326Z","iopub.status.idle":"2022-01-19T07:22:43.779084Z","shell.execute_reply.started":"2022-01-19T07:22:43.77029Z","shell.execute_reply":"2022-01-19T07:22:43.778416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mart = original_train_df[original_train_df[\"store\"]=='KaggleMart']\ntrain_rama = original_train_df[original_train_df[\"store\"]=='KaggleRama']\ntest_mart = original_test_df[original_test_df[\"store\"]=='KaggleMart']\ntest_rama = original_test_df[original_test_df[\"store\"]=='KaggleRama']","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:47:52.812645Z","iopub.execute_input":"2022-01-19T07:47:52.81292Z","iopub.status.idle":"2022-01-19T07:47:52.831418Z","shell.execute_reply.started":"2022-01-19T07:47:52.812891Z","shell.execute_reply":"2022-01-19T07:47:52.830396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:38:14.833118Z","iopub.execute_input":"2022-01-19T07:38:14.833383Z","iopub.status.idle":"2022-01-19T07:38:14.844444Z","shell.execute_reply.started":"2022-01-19T07:38:14.833355Z","shell.execute_reply":"2022-01-19T07:38:14.843649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mart","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:54:50.944346Z","iopub.execute_input":"2022-01-19T07:54:50.944646Z","iopub.status.idle":"2022-01-19T07:54:50.962333Z","shell.execute_reply.started":"2022-01-19T07:54:50.944608Z","shell.execute_reply":"2022-01-19T07:54:50.961529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mart data prep\ntrain_df_mart = engineer_more(train_mart)\ntrain_df_mart['date'] = train_mart.date\ntrain_df_mart['num_sold'] = train_mart.num_sold.astype(np.float32)\ntest_df_mart = engineer_more(test_mart)\n\nfeatures_mart = list(test_df_mart.columns)\n\n#rama data prep\ntrain_df_rama = engineer_more(train_rama)\ntrain_df_rama['date'] = train_rama.date\ntrain_df_rama['num_sold'] = train_rama.num_sold.astype(np.float32)\ntest_df_rama = engineer_more(test_rama)\n\nfeatures_rama = list(test_df_rama.columns)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T07:48:08.300063Z","iopub.execute_input":"2022-01-19T07:48:08.301362Z","iopub.status.idle":"2022-01-19T07:48:10.972327Z","shell.execute_reply.started":"2022-01-19T07:48:08.301315Z","shell.execute_reply":"2022-01-19T07:48:10.971373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mart model and predictions\nX_train_mart, X_val_mart, y_train_mart, y_val_mart = train_test_split(train_df_mart.drop('num_sold',axis=1),train_df_mart['num_sold'], test_size=0.1)\nct_mart = CatBoostRegressor(verbose=False, eval_metric='SMAPE')\nct_mart.fit(X_train_mart, y_train_mart, eval_set=(X_val_mart,y_val_mart))\n\npred_mart = ct.predict(test_df_mart)\npred_mart = [int(i) for i in pred_mart] \ntest_mart['num_sold'] = pred_mart\ntest_mart = test_mart[['row_id','num_sold']]\n\n# rama model and predictions\nX_train_rama, X_val_rama, y_train_rama, y_val_rama = train_test_split(train_df_rama.drop('num_sold',axis=1),train_df_rama['num_sold'], test_size=0.1)\nct_rama = CatBoostRegressor(verbose=False, eval_metric='SMAPE')\nct_rama.fit(X_train_rama, y_train_rama, eval_set=(X_val_rama,y_val_rama))\n\npred_rama = ct.predict(test_df_rama)\npred_rama = [int(i) for i in pred_rama] \ntest_rama['num_sold'] = pred_rama\ntest_rama = test_rama[['row_id','num_sold']]\n\n#submission\nsubmission = pd.concat([test_mart,test_rama])\nsubmission.sort_index(inplace=True)\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:01:44.845121Z","iopub.execute_input":"2022-01-19T08:01:44.845397Z","iopub.status.idle":"2022-01-19T08:01:52.506376Z","shell.execute_reply.started":"2022-01-19T08:01:44.84537Z","shell.execute_reply":"2022-01-19T08:01:52.505543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-01-19T08:01:52.507869Z","iopub.execute_input":"2022-01-19T08:01:52.508158Z","iopub.status.idle":"2022-01-19T08:01:52.519841Z","shell.execute_reply.started":"2022-01-19T08:01:52.508117Z","shell.execute_reply":"2022-01-19T08:01:52.518886Z"},"trusted":true},"execution_count":null,"outputs":[]}]}