{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Advanced linear model for the January TPS with customer confidence index\n\nThis notebook contains some major changes compared to my earlier [linear model](https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model):\n- Feature engineering\n  - more external data: monthly consumer confidence index\n  - different selection of Fourier series; no Fourier series for stickers\n  - Small changes in length of holidays\n  - Different Easter effect for Norway than for other countries\n- Cross-validation shows results for Q1 and the other three quarters separately.\n- Regularization has been tuned with three MinMaxScalers\n- KaggleRama factor has been taken out of the regression (direct computation is more accurate)\n\n\nALDPARIS : I've added a simplification by observing that some date coefficients have the same values ; search the following word ALDPARIS in this notebook for a slight improvment.\nThis an AmbrosM notebook, the original : https://www.kaggle.com/ambrosm/tpsjan22-10-advanced-linear-model-with-cci","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport itertools\nimport gc\nimport math\nimport matplotlib.pyplot as plt\nimport dateutil.easter as easter\nfrom matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\nfrom datetime import datetime, date, timedelta\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nimport scipy.stats","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-01T18:58:35.627436Z","iopub.execute_input":"2022-02-01T18:58:35.627765Z","iopub.status.idle":"2022-02-01T18:58:36.705669Z","shell.execute_reply.started":"2022-02-01T18:58:35.627678Z","shell.execute_reply":"2022-02-01T18:58:36.704577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NO_STORE = True\n\noriginal_train_df = pd.read_csv('../input/tabular-playground-series-jan-2022/train.csv')\noriginal_test_df = pd.read_csv('../input/tabular-playground-series-jan-2022/test.csv')\n\ngdp_df = pd.read_csv('../input/gdp-20152019-finland-norway-and-sweden/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\ngdp_df.set_index('year', inplace=True)\n\ncci_df = pd.read_csv('../input/oecd-consumer-confidence-index/DP_LIVE_21012022073653464.csv')\ncci_df.set_index(['LOCATION', 'TIME'], inplace=True)\n\n# The dates are read as strings and must be converted\nfor df in [original_train_df, original_test_df]:\n    df['date'] = pd.to_datetime(df.date)\noriginal_train_df.head(6)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:58:36.707528Z","iopub.execute_input":"2022-02-01T18:58:36.707823Z","iopub.status.idle":"2022-02-01T18:58:36.877496Z","shell.execute_reply.started":"2022-02-01T18:58:36.707783Z","shell.execute_reply":"2022-02-01T18:58:36.876633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before starting, we calculate the ratio between KaggleRama and KaggleMart sales. This ratio is always the same and does not depend on any other features. A direct calculation is more accurate than linear regression:","metadata":{}},{"cell_type":"code","source":"kaggle_rama_log_diff = \\\n    np.log(original_train_df[original_train_df.store == \"KaggleRama\"].num_sold.values).mean() - \\\n    np.log(original_train_df[original_train_df.store == \"KaggleMart\"].num_sold.values).mean()\nprint(f\"KaggleRama always sells {np.exp(kaggle_rama_log_diff):.5f} more than KaggleMart.\")","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:58:40.699732Z","iopub.execute_input":"2022-02-01T18:58:40.700024Z","iopub.status.idle":"2022-02-01T18:58:40.715655Z","shell.execute_reply.started":"2022-02-01T18:58:40.699996Z","shell.execute_reply":"2022-02-01T18:58:40.714589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def smape_loss(y_true, y_pred):\n    \"\"\"SMAPE Loss\"\"\"\n    return np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:58:41.510444Z","iopub.execute_input":"2022-02-01T18:58:41.511265Z","iopub.status.idle":"2022-02-01T18:58:41.516355Z","shell.execute_reply.started":"2022-02-01T18:58:41.511217Z","shell.execute_reply":"2022-02-01T18:58:41.515428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering\n","metadata":{}},{"cell_type":"code","source":"# Feature engineering\ndef engineer(df):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    \n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp_df.loc[row.date.year, country]\n        \n    def get_cci(row):\n        country = row.country\n        time = f\"{row.date.year}-{row.date.month:02d}\"\n        # There is no monthly CCI data for Norway.\n        # We use the Finland data instead.\n        if country == 'Norway': country = 'Finland'\n        return cci_df.loc[country[:3].upper(), time].Value\n        \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis=1)),\n                           'cci': df.apply(get_cci, axis=1),\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    # The three products have different seasonal patterns\n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 3):\n        sink = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        cosk = np.cos(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = sink * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = cosk * new_df['Kaggle Mug']\n        new_df[f'hat_sin{k}'] = sink * new_df['Kaggle Hat']\n        new_df[f'hat_cos{k}'] = cosk * new_df['Kaggle Hat']\n\n    new_df.drop(columns=['mug_sin1'], inplace=True)\n    new_df.drop(columns=['mug_sin2'], inplace=True)\n\n    # Special days\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(25, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in range(1, 15)}),\n                        pd.DataFrame({f\"n-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in range(1, 15)})\n                       ],\n                       axis=1)\n    \n    # May and June\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n                                      for d in list(range(1, 10))}),\n#                         pd.DataFrame({f\"f-may{d}\":\n#                                       (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Finland') # end of the war\n#                                       for d in [9]}),\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                     for d in list(range(18, 26)) + [27]}),\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 15))}),\n                       ],\n                       axis=1)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 5))})],\n                       axis=1)\n    \n    # First Sunday of November\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})],\n                       axis=1)\n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 15))})],\n                       axis=1)\n\n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(51, 58))}),\n                        pd.DataFrame({f\"n_easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\")) & (df.country == 'Norway')\n                                      for d in list(range(-3, 8)) + list(range(50, 61))})],\n                       axis=1)\n    \n    return new_df.astype(np.float32)\n\ntrain_df = engineer(original_train_df)\ntrain_df['date'] = original_train_df.date\ntrain_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\ntest_df = engineer(original_test_df)\n\nfeatures = list(test_df.columns)\nif NO_STORE: features.remove('KaggleRama')\nprint(list(features))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:58:42.577824Z","iopub.execute_input":"2022-02-01T18:58:42.578466Z","iopub.status.idle":"2022-02-01T18:58:52.701704Z","shell.execute_reply.started":"2022-02-01T18:58:42.57841Z","shell.execute_reply":"2022-02-01T18:58:52.700739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation\n\nWe train on a GroupKFold with the years as groups. For the validation, we separate the SMAPE for the first quarter from the rest of the year. As the private leaderboard is computed on the predictions for April through December, SMAPE for these nine months is more important than SMAPE for the first quarter.\n\nThe data is scaled using three separate MinMaxScalers. Ridge regression will penalize high weights on the customer confidence index more than on other features.","metadata":{}},{"cell_type":"code","source":"def predict(features, preproc, model, X):\n    y = (np.exp(model.predict(preproc.transform(X[features])))).reshape(-1, 1)\n    if NO_STORE: y[X.KaggleRama.values > 0] = y[X.KaggleRama.values > 0] * np.exp(kaggle_rama_log_diff)\n    return y\n\n\ndef fit_model(X_tr, X_va=None, score_list=[], mse_list=[], run=0, fold=0, oof=None, outliers=False, correction=1.0):\n    \"\"\"Scale the data, fit a model, plot the training history and validate the model\"\"\"\n    start_time = datetime.now()\n\n    # Preprocess the data\n    X_tr_f = X_tr[features]\n    preproc = make_pipeline(ColumnTransformer([('general', MinMaxScaler(), ['gdp', 'wd4', 'wd56', 'Finland', 'Norway',\n                                                                            'Kaggle Mug', 'Kaggle Hat',\n                                                                            'mug_cos1', 'hat_sin1', 'hat_cos1', 'mug_cos2',\n                                                                            'hat_sin2', 'hat_cos2']),\n                                               ('cci', MinMaxScaler((0, 0.06)), ['cci']),\n                                              ],\n                                              remainder=MinMaxScaler((0, 2.8))),\n                            StandardScaler(with_std=False))\n    #preproc = make_pipeline(MinMaxScaler(), StandardScaler(with_std=False))\n    #preproc = StandardScaler()\n    X_tr_f = preproc.fit_transform(X_tr_f)\n    y_tr = X_tr.num_sold.values.reshape(-1, 1).copy()\n    if NO_STORE: y_tr[X_tr.KaggleRama != 0] = y_tr[X_tr.KaggleRama != 0] / np.exp(kaggle_rama_log_diff)\n\n    # Train the model\n    model = Ridge(alpha=0.2, tol=0.00001, max_iter=10000)\n    model.fit(X_tr_f, np.log(y_tr).ravel())\n\n    if X_va is not None:\n        # Preprocess the validation data\n        y_va = X_va.num_sold.values.reshape(-1, 1)\n\n        # Inference for validation\n        y_va_pred = predict(features, preproc, model, X_va)\n        oof.update(pd.Series(y_va_pred.ravel(), index=X_va.index))\n        \n        # Evaluation: Execution time and SMAPE\n        smape_before_correction = np.mean(smape_loss(y_va, y_va_pred))\n        y_va_pred *= correction\n        smape = np.mean(smape_loss(y_va, y_va_pred))\n        mse = mean_squared_error(np.log(y_va), np.log(y_va_pred))\n        print(f\"Fold {run}.{fold} | {str(datetime.now() - start_time)[-12:-7]}\"\n              f\" | SMAPE: {smape:.5f}   (before correction: {smape_before_correction:.5f})\"\n              f\" | MSE: {mse:.5f}\")\n        score_list.append(smape)\n        mse_list.append(mse)\n        \n    return preproc, model\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:58:52.703453Z","iopub.execute_input":"2022-02-01T18:58:52.703685Z","iopub.status.idle":"2022-02-01T18:58:52.716282Z","shell.execute_reply.started":"2022-02-01T18:58:52.703656Z","shell.execute_reply":"2022-02-01T18:58:52.715574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RUNS = 1 # should be 1\n\ndef validate(train_df, correction_factor=1.0):\n    # Make the results reproducible\n    np.random.seed(202100)\n    \n    df_reg_coef = pd.DataFrame()\n\n    total_start_time = datetime.now()\n    oof = pd.Series(0.0, index=train_df.index)\n    score_list, mse_list = [], []\n    for run in range(RUNS):\n        kf = GroupKFold(n_splits=4)\n        for fold, (train_idx, val_idx) in enumerate(kf.split(train_df, groups=train_df.date.dt.year)):\n            X_tr = train_df.iloc[train_idx]\n            X_va = train_df.iloc[val_idx]\n            print(f\"Fold {run}.{fold} validating on {train_df.iloc[val_idx].iloc[0].date.year}\")\n            preproc, model = fit_model(X_tr, X_va, score_list, mse_list, run=run, fold=fold, oof=oof, correction=correction_factor)\n\n            # ALDPARIS BEGIN\n            df_reg_coef = pd.concat([df_reg_coef, pd.DataFrame({f\"coef_yearval_{fold}\":model.coef_}, index=features)], axis=1)\n            # ALDPARIS END\n    \n    print(f\"Average SMAPE: {sum(score_list) / len(score_list):.5f} | MSE: {sum(mse_list) / len(mse_list):.7f}   \"\n          f\"| Y: {smape_loss(train_df.num_sold, oof).mean():.5f}   \"\n          f\"| Q1: {smape_loss(train_df.num_sold, oof)[train_df.date.dt.month <= 3].mean():.5f}   \"\n          f\"| Q234: {smape_loss(train_df.num_sold, oof)[train_df.date.dt.month > 3].mean():.5f}\")\n    with open('oof.pickle', 'wb') as handle: pickle.dump(oof, handle)\n        \n    # ALDPARIS BEGIN\n    return df_reg_coef\n    # ALDPARIS END\n        \ncoef = validate(train_df)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:07:16.658138Z","iopub.execute_input":"2022-02-01T19:07:16.658416Z","iopub.status.idle":"2022-02-01T19:07:17.418858Z","shell.execute_reply.started":"2022-02-01T19:07:16.658386Z","shell.execute_reply":"2022-02-01T19:07:17.417931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ALDPARIS : Let's see linear model coefficients by date\nRidge and regressions loves parsimony, Can't we simplify the feature engineering ?\nSame coefficient values can be find for several dates, let's gather those dates.","metadata":{}},{"cell_type":"code","source":"# ALDPARIS ADDED\n\n# Coefficients for all folds \ndef plot_feature_weights_numbered(prefix, df = coef):\n    \n    fig, ax = plt.subplots(nrows=len(prefix), ncols=4, figsize=(25, 5*len(prefix)), sharey=True)\n    plt.subplots_adjust(hspace = 0.4, wspace = 0.2)\n    \n    for r, p in enumerate(prefix):\n        \n        prefix_features = [f for f in list(df.index) if f.startswith(p)]\n        for c, y in enumerate(range(4)):\n            df.loc[df.index.isin(prefix_features), f\"coef_yearval_{y}\"].plot.bar(y=f\"coef_yearval_{y}\", ax=ax[r, c])\n            ax[r, c].set_title(p)\n        \nplot_feature_weights_numbered([\"s-jan\", \"f-jan\", 'easter', \"may\", \"wed_june\", \"june\", \"sun_nov\", \"dec\", \"n-dec\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:08:28.140487Z","iopub.execute_input":"2022-02-01T19:08:28.140777Z","iopub.status.idle":"2022-02-01T19:08:36.55875Z","shell.execute_reply.started":"2022-02-01T19:08:28.140742Z","shell.execute_reply":"2022-02-01T19:08:36.557898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature engineering\ndef engineer_NEW(df):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    \n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp_df.loc[row.date.year, country]\n        \n    def get_cci(row):\n        country = row.country\n        time = f\"{row.date.year}-{row.date.month:02d}\"\n        # There is no monthly CCI data for Norway.\n        # We use the Finland data instead.\n        if country == 'Norway': country = 'Finland'\n        return cci_df.loc[country[:3].upper(), time].Value\n        \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis=1)),\n                           'cci': df.apply(get_cci, axis=1),\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    # The three products have different seasonal patterns\n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 3):\n        sink = np.sin(dayofyear / 365 * 2 * math.pi * k)\n        cosk = np.cos(dayofyear / 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = sink * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = cosk * new_df['Kaggle Mug']\n        new_df[f'hat_sin{k}'] = sink * new_df['Kaggle Hat']\n        new_df[f'hat_cos{k}'] = cosk * new_df['Kaggle Hat']\n\n    new_df.drop(columns=['mug_sin1'], inplace=True)\n    new_df.drop(columns=['mug_sin2'], inplace=True)\n\n    # Special days\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(25, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in range(1, 15)}),\n                        pd.DataFrame({f\"n-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in range(1, 15)})\n                       ],\n                       axis=1)\n    \n    # May and June\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n                                      for d in list(range(1, 10))}),\n#                         pd.DataFrame({f\"f-may{d}\":\n#                                       (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Finland') # end of the war\n#                                       for d in [9]}),\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                     for d in list(range(18, 26)) + [27]}),\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 15))}),\n                       ],\n                       axis=1)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 5))})],\n                       axis=1)\n    \n    # First Sunday of November\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})],\n                       axis=1)\n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 15))})],\n                       axis=1)\n\n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(51, 58))}),\n                        pd.DataFrame({f\"n_easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\")) & (df.country == 'Norway')\n                                      for d in list(range(-3, 8)) + list(range(50, 61))})],\n                       axis=1)\n    \n    # ALDPARIS BEGIN\n    new_df[\"wed_june-1_1\"] = (new_df[\"wed_june-1\"]) | (new_df[\"wed_june1\"])\n    new_df[\"wed_june-2_2\"] = (new_df[\"wed_june-2\"]) | (new_df[\"wed_june2\"])\n    new_df[\"wed_june-3_3\"] = (new_df[\"wed_june-3\"]) | (new_df[\"wed_june3\"])\n    new_df[\"wed_june-4_4\"] = (new_df[\"wed_june-4\"]) | (new_df[\"wed_june4\"])\n    \n    new_df = new_df.drop([\"wed_june-1\", \"wed_june1\", \"wed_june-2\", \"wed_june2\", \"wed_june-3\", \"wed_june3\", \"wed_june-4\"\n                , \"wed_june4\"], axis=1)\n    # Instead of 8 coefficients for June, ridge will now estimate only 4 coefficients for June.\n    # ...\n    # ALDPARIS END\n    \n    return new_df.astype(np.float32)\n\ntrain_df = engineer_NEW(original_train_df)\ntrain_df['date'] = original_train_df.date\ntrain_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\ntest_df = engineer_NEW(original_test_df)\n\nfeatures = list(test_df.columns)\nif NO_STORE: features.remove('KaggleRama')\nprint(list(features))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:21:16.896666Z","iopub.execute_input":"2022-02-01T19:21:16.896982Z","iopub.status.idle":"2022-02-01T19:21:27.349366Z","shell.execute_reply.started":"2022-02-01T19:21:16.89695Z","shell.execute_reply":"2022-02-01T19:21:27.348751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coef = validate(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:21:44.842982Z","iopub.execute_input":"2022-02-01T19:21:44.843632Z","iopub.status.idle":"2022-02-01T19:21:45.590212Z","shell.execute_reply.started":"2022-02-01T19:21:44.843597Z","shell.execute_reply":"2022-02-01T19:21:45.587686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great, CV score is better...\n\n# Inference and submission","metadata":{}},{"cell_type":"code","source":"# Fit the model on the complete training data\npreproc, model = fit_model(train_df, None)\n\n# Inference for test\ntest_pred_list = []\ntest_pred_list.append(predict(features, preproc, model, test_df) * 1.003) # magic scaling factor\n\n# Prepare the submission file\nsub = original_test_df[['row_id']].copy()\nsub['num_sold'] = sum(test_pred_list) / len(test_pred_list)\n\n# Plot the distribution of the test predictions\nplt.figure(figsize=(16,3))\nplt.hist(train_df['num_sold'], bins=np.linspace(0, 3000, 201),\n         density=True, label='Training')\nplt.hist(sub['num_sold'], bins=np.linspace(0, 3000, 201),\n         density=True, rwidth=0.5, label='Test predictions')\nplt.xlabel('num_sold')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\n# Create a rounded submission file\nsub_rounded = sub.copy()\nsub_rounded['num_sold'] = sub_rounded['num_sold'].round()\nsub_rounded.to_csv('submission_linear_model_rounded.csv', index=False)\nsub_rounded","metadata":{"execution":{"iopub.status.busy":"2022-02-01T19:22:16.618344Z","iopub.execute_input":"2022-02-01T19:22:16.618654Z","iopub.status.idle":"2022-02-01T19:22:17.831702Z","shell.execute_reply.started":"2022-02-01T19:22:16.61862Z","shell.execute_reply":"2022-02-01T19:22:17.830729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}