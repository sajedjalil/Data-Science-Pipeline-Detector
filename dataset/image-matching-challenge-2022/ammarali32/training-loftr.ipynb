{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n!pip install ../input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\n!pip install ../input/loftrutils/einops-0.4.1-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:00.285704Z","iopub.execute_input":"2022-04-17T18:07:00.286036Z","iopub.status.idle":"2022-04-17T18:07:28.934789Z","shell.execute_reply.started":"2022-04-17T18:07:00.285951Z","shell.execute_reply":"2022-04-17T18:07:28.933672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/loftrutils/LoFTR-master/LoFTR-master/')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:28.939692Z","iopub.execute_input":"2022-04-17T18:07:28.939985Z","iopub.status.idle":"2022-04-17T18:07:28.947595Z","shell.execute_reply.started":"2022-04-17T18:07:28.939937Z","shell.execute_reply":"2022-04-17T18:07:28.946436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install loguru","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:28.950949Z","iopub.execute_input":"2022-04-17T18:07:28.952224Z","iopub.status.idle":"2022-04-17T18:07:38.34163Z","shell.execute_reply.started":"2022-04-17T18:07:28.952184Z","shell.execute_reply":"2022-04-17T18:07:38.340805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nimport pprint\nfrom loguru import logger\nfrom pathlib import Path\nimport cv2\nimport torch\nimport numpy as np\nimport pytorch_lightning as pl\nfrom matplotlib import pyplot as plt\nimport gc\nfrom src.loftr import LoFTR\nfrom src.loftr.utils.supervision import compute_supervision_coarse, compute_supervision_fine\nfrom src.losses.loftr_loss import LoFTRLoss\nfrom src.optimizers import build_optimizer, build_scheduler\nfrom src.utils.metrics import (\n    compute_symmetrical_epipolar_errors,\n    compute_pose_errors,\n    aggregate_metrics\n)\nfrom src.utils.plotting import make_matching_figures\nfrom src.utils.comm import gather, all_gather\nfrom src.utils.misc import lower_config, flattenList\nfrom src.utils.profiler import PassThroughProfiler\n\n\nclass PL_LoFTR(pl.LightningModule):\n    def __init__(self, config, pretrained_ckpt=None, profiler=None, dump_dir=None):\n        \"\"\"\n        TODO:\n            - use the new version of PL logging API.\n        \"\"\"\n        super().__init__()\n        # Misc\n        self.config = config  # full config\n        _config = lower_config(self.config)\n        self.loftr_cfg = lower_config(_config['loftr'])\n        self.profiler = profiler or PassThroughProfiler()\n        self.n_vals_plot = 1 #max(config.TRAINER.N_VAL_PAIRS_TO_PLOT // config.TRAINER.WORLD_SIZE, 1)\n\n        # Matcher: LoFTR\n        self.matcher = LoFTR(config=_config['loftr'])\n        self.loss = LoFTRLoss(_config)\n\n        # Pretrained weights\n        if pretrained_ckpt:\n            state_dict = torch.load(pretrained_ckpt, map_location='cuda')['state_dict']\n            self.matcher.load_state_dict(state_dict, strict=True)\n            logger.info(f\"Load \\'{pretrained_ckpt}\\' as pretrained checkpoint\")\n        \n        # Testing\n        self.dump_dir = dump_dir\n        \n    def configure_optimizers(self):\n        # FIXME: The scheduler did not work properly when `--resume_from_checkpoint`\n        optimizer = build_optimizer(self, self.config)\n        scheduler = build_scheduler(self.config, optimizer)\n        return [optimizer], [scheduler]\n    \n    def optimizer_step(\n            self, epoch, batch_idx, optimizer, optimizer_idx,\n            optimizer_closure, on_tpu, using_native_amp, using_lbfgs):\n        # learning rate warm up\n        warmup_step = self.config.TRAINER.WARMUP_STEP\n        if self.trainer.global_step < warmup_step:\n            if self.config.TRAINER.WARMUP_TYPE == 'linear':\n                base_lr = self.config.TRAINER.WARMUP_RATIO * self.config.TRAINER.TRUE_LR\n                lr = base_lr + \\\n                    (self.trainer.global_step / self.config.TRAINER.WARMUP_STEP) * \\\n                    abs(self.config.TRAINER.TRUE_LR - base_lr)\n                for pg in optimizer.param_groups:\n                    pg['lr'] = lr\n            elif self.config.TRAINER.WARMUP_TYPE == 'constant':\n                pass\n            else:\n                raise ValueError(f'Unknown lr warm-up strategy: {self.config.TRAINER.WARMUP_TYPE}')\n\n        # update params\n        optimizer.step(closure=optimizer_closure)\n        optimizer.zero_grad()\n    \n    def _trainval_inference(self, batch):\n        with self.profiler.profile(\"Compute coarse supervision\"):\n            compute_supervision_coarse(batch, self.config)\n        \n        with self.profiler.profile(\"LoFTR\"):\n            self.matcher(batch)\n        \n        with self.profiler.profile(\"Compute fine supervision\"):\n            compute_supervision_fine(batch, self.config)\n            \n        with self.profiler.profile(\"Compute losses\"):\n            self.loss(batch)\n    \n    def _compute_metrics(self, batch):\n        with self.profiler.profile(\"Copmute metrics\"):\n            compute_symmetrical_epipolar_errors(batch)  # compute epi_errs for each match\n            compute_pose_errors(batch, self.config)  # compute R_errs, t_errs, pose_errs for each pair\n\n            rel_pair_names = list(zip(*batch['pair_names']))\n            bs = batch['image0'].size(0)\n            metrics = {\n                # to filter duplicate pairs caused by DistributedSampler\n                'identifiers': ['#'.join(rel_pair_names[b]) for b in range(bs)],\n                'epi_errs': [batch['epi_errs'][batch['m_bids'] == b].cpu().numpy() for b in range(bs)],\n                'R_errs': batch['R_errs'],\n                't_errs': batch['t_errs'],\n                'inliers': batch['inliers']}\n            ret_dict = {'metrics': metrics}\n        return ret_dict, rel_pair_names\n    \n    def training_step(self, batch, batch_idx):\n        self._trainval_inference(batch)\n        \n        # logging\n        if self.trainer.global_rank == 0 and self.global_step % self.trainer.log_every_n_steps == 0:\n            # scalars\n            for k, v in batch['loss_scalars'].items():\n                self.logger.experiment.add_scalar(f'train/{k}', v, self.global_step)\n\n            # net-params\n            if self.config.LOFTR.MATCH_COARSE.MATCH_TYPE == 'sinkhorn':\n                self.logger.experiment.add_scalar(\n                    f'skh_bin_score', self.matcher.coarse_matching.bin_score.clone().detach().cpu().data, self.global_step)\n\n            # figures\n            if self.config.TRAINER.ENABLE_PLOTTING:\n                compute_symmetrical_epipolar_errors(batch)  # compute epi_errs for each match\n                figures = make_matching_figures(batch, self.config, self.config.TRAINER.PLOT_MODE)\n                for k, v in figures.items():\n                    self.logger.experiment.add_figure(f'train_match/{k}', v, self.global_step)\n        gc.collect()\n        torch.cuda.empty_cache()\n        return {'loss': batch['loss']}\n\n    def training_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        if self.trainer.global_rank == 0:\n            self.logger.experiment.add_scalar(\n                'train/avg_loss_on_epoch', avg_loss,\n                global_step=self.current_epoch)\n        gc.collect()\n        torch.cuda.empty_cache()\n    \n    def validation_step(self, batch, batch_idx):\n        self._trainval_inference(batch)\n        \n        ret_dict, _ = self._compute_metrics(batch)\n        \n        val_plot_interval = max(self.trainer.num_val_batches[0] // self.n_vals_plot, 1)\n        figures = {self.config.TRAINER.PLOT_MODE: []}\n        if batch_idx % val_plot_interval == 0:\n            figures = make_matching_figures(batch, self.config, mode=self.config.TRAINER.PLOT_MODE)\n        gc.collect()\n        torch.cuda.empty_cache()\n        return {\n            **ret_dict,\n            'loss_scalars': batch['loss_scalars'],\n            'figures': figures,\n        }\n        \n    def validation_epoch_end(self, outputs):\n        # handle multiple validation sets\n        multi_outputs = [outputs] if not isinstance(outputs[0], (list, tuple)) else outputs\n        multi_val_metrics = defaultdict(list)\n        \n        for valset_idx, outputs in enumerate(multi_outputs):\n            # since pl performs sanity_check at the very begining of the training\n            cur_epoch = self.trainer.current_epoch\n            if not self.trainer.resume_from_checkpoint :\n                cur_epoch = -1\n\n            # 1. loss_scalars: dict of list, on cpu\n            _loss_scalars = [o['loss_scalars'] for o in outputs]\n            loss_scalars = {k: flattenList(all_gather([_ls[k] for _ls in _loss_scalars])) for k in _loss_scalars[0]}\n\n            # 2. val metrics: dict of list, numpy\n            _metrics = [o['metrics'] for o in outputs]\n            metrics = {k: flattenList(all_gather(flattenList([_me[k] for _me in _metrics]))) for k in _metrics[0]}\n            # NOTE: all ranks need to `aggregate_merics`, but only log at rank-0 \n            val_metrics_4tb = aggregate_metrics(metrics, self.config.TRAINER.EPI_ERR_THR)\n            for thr in [5, 10, 20]:\n                multi_val_metrics[f'auc@{thr}'].append(val_metrics_4tb[f'auc@{thr}'])\n            \n            # 3. figures\n            _figures = [o['figures'] for o in outputs]\n            figures = {k: flattenList(gather(flattenList([_me[k] for _me in _figures]))) for k in _figures[0]}\n\n            # tensorboard records only on rank 0\n            if self.trainer.global_rank == 0:\n                for k, v in loss_scalars.items():\n                    mean_v = torch.stack(v).mean()\n                    self.logger.experiment.add_scalar(f'val_{valset_idx}/avg_{k}', mean_v, global_step=cur_epoch)\n\n                for k, v in val_metrics_4tb.items():\n                    self.logger.experiment.add_scalar(f\"metrics_{valset_idx}/{k}\", v, global_step=cur_epoch)\n                \n            gc.collect()\n            torch.cuda.empty_cache()   \n            plt.close('all')\n\n        for thr in [5, 10, 20]:\n            # log on all ranks for ModelCheckpoint callback to work properly\n            self.log(f'auc@{thr}', torch.tensor(np.mean(multi_val_metrics[f'auc@{thr}'])))  # ckpt monitors on this\n\n    def test_step(self, batch, batch_idx):\n        with self.profiler.profile(\"LoFTR\"):\n            self.matcher(batch)\n\n        ret_dict, rel_pair_names = self._compute_metrics(batch)\n\n        with self.profiler.profile(\"dump_results\"):\n            if self.dump_dir is not None:\n                # dump results for further analysis\n                keys_to_save = {'mkpts0_f', 'mkpts1_f', 'mconf', 'epi_errs'}\n                pair_names = list(zip(*batch['pair_names']))\n                bs = batch['image0'].shape[0]\n                dumps = []\n                for b_id in range(bs):\n                    item = {}\n                    mask = batch['m_bids'] == b_id\n                    item['pair_names'] = pair_names[b_id]\n                    item['identifier'] = '#'.join(rel_pair_names[b_id])\n                    for key in keys_to_save:\n                        item[key] = batch[key][mask].cpu().numpy()\n                    for key in ['R_errs', 't_errs', 'inliers']:\n                        item[key] = batch[key][b_id]\n                    dumps.append(item)\n                ret_dict['dumps'] = dumps\n\n        return ret_dict\n\n    def test_epoch_end(self, outputs):\n        # metrics: dict of list, numpy\n        _metrics = [o['metrics'] for o in outputs]\n        metrics = {k: flattenList(gather(flattenList([_me[k] for _me in _metrics]))) for k in _metrics[0]}\n\n        # [{key: [{...}, *#bs]}, *#batch]\n        if self.dump_dir is not None:\n            Path(self.dump_dir).mkdir(parents=True, exist_ok=True)\n            _dumps = flattenList([o['dumps'] for o in outputs])  # [{...}, #bs*#batch]\n            dumps = flattenList(gather(_dumps))  # [{...}, #proc*#bs*#batch]\n            logger.info(f'Prediction and evaluation results will be saved to: {self.dump_dir}')\n\n        if self.trainer.global_rank == 0:\n            print(self.profiler.summary())\n            val_metrics_4tb = aggregate_metrics(metrics, self.config.TRAINER.EPI_ERR_THR)\n            logger.info('\\n' + pprint.pformat(val_metrics_4tb))\n            if self.dump_dir is not None:\n                np.save(Path(self.dump_dir) / 'LoFTR_pred_eval', dumps)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:38.344867Z","iopub.execute_input":"2022-04-17T18:07:38.345095Z","iopub.status.idle":"2022-04-17T18:07:47.108642Z","shell.execute_reply.started":"2022-04-17T18:07:38.345067Z","shell.execute_reply":"2022-04-17T18:07:47.107711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \ndef read_megadepth_depth(path, pad_to=None):\n    depth = cv2.imread(path, 0)\n    if pad_to is not None:\n        depth, _ = pad_bottom_right(depth, pad_to, ret_mask=False)\n    depth = torch.from_numpy(depth).float()  # (h, w)\n    gc.collect()\n    return depth","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:47.110124Z","iopub.execute_input":"2022-04-17T18:07:47.111507Z","iopub.status.idle":"2022-04-17T18:07:47.118406Z","shell.execute_reply.started":"2022-04-17T18:07:47.111465Z","shell.execute_reply":"2022-04-17T18:07:47.117617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os.path as osp\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom loguru import logger\n\nfrom src.utils.dataset import read_megadepth_gray, pad_bottom_right\n\n\nclass MegaDepthDataset(Dataset):\n    def __init__(self,\n                 data,\n                 npz_path,\n                 mode='train',\n                 min_overlap_score=0.4,\n                 img_resize=None,\n                 df=None,\n                 img_padding=False,\n                 depth_padding=False,\n                 augment_fn=None,\n                 **kwargs):\n        \"\"\"\n        Manage one scene(npz_path) of MegaDepth dataset.\n        \n        Args:\n            root_dir (str): megadepth root directory that has `phoenix`.\n            npz_path (str): {scene_id}.npz path. This contains image pair information of a scene.\n            mode (str): options are ['train', 'val', 'test']\n            min_overlap_score (float): how much a pair should have in common. In range of [0, 1]. Set to 0 when testing.\n            img_resize (int, optional): the longer edge of resized images. None for no resize. 640 is recommended.\n                                        This is useful during training with batches and testing with memory intensive algorithms.\n            df (int, optional): image size division factor. NOTE: this will change the final image size after img_resize.\n            img_padding (bool): If set to 'True', zero-pad the image to squared size. This is useful during training.\n            depth_padding (bool): If set to 'True', zero-pad depthmap to (2000, 2000). This is useful during training.\n            augment_fn (callable, optional): augments images with pre-defined visual effects.\n        \"\"\"\n        super().__init__()\n    # self.root_dir = root_dir\n        self.mode = mode\n\n        # prepare scene_info and pair_info\n        if mode == 'test' and min_overlap_score != 0:\n            logger.warning(\"You are using `min_overlap_score`!=0 in test mode. Set to 0.\")\n            min_overlap_score = 0\n\n        # parameters for image resizing, padding and depthmap padding\n        if mode == 'train':\n            assert img_resize is not None and img_padding and depth_padding\n        self.img_resize = img_resize\n        self.df = df\n        self.img_padding = img_padding\n        self.depth_max_size = 2000 if depth_padding else None  # the upperbound of depthmaps size in megadepth.\n\n        # for training LoFTR\n        self.augment_fn = augment_fn if mode == 'train' else None\n        self.coarse_scale = getattr(kwargs, 'coarse_scale', 0.125)\n        self.path1 = data[\"path1\"].values\n        self.path2 = data[\"path2\"].values\n        self.camerainst1 = data[\"camerainst1\"].values\n        self.camerainst2 = data[\"camerainst2\"].values\n        self.rot1 = data[\"rot1\"].values\n        self.rot2 = data[\"rot2\"].values\n        self.trans1 = data[\"trans1\"].values\n        self.trans2 = data[\"trans2\"].values\n        gc.collect()\n        \n    def __len__(self):\n        return len(self.path1)\n\n    def __getitem__(self, idx):\n        # read grayscale image and mask. (1, h, w) and (h, w)\n        img_name0 = self.path1[idx]\n        img_name1 = self.path2[idx]\n        \n        # TODO: Support augmentation & handle seeds for each worker correctly.\n        image0, mask0, scale0 = read_megadepth_gray(\n            img_name0, self.img_resize, self.df, self.img_padding, None)\n            # np.random.choice([self.augment_fn, None], p=[0.5, 0.5]))\n        image1, mask1, scale1 = read_megadepth_gray(\n            img_name1, self.img_resize, self.df, self.img_padding, None)\n            # np.random.choice([self.augment_fn, None], p=[0.5, 0.5]))\n        depth_path0 = \"../input/generate-depth-masks/depth_maps/\" + img_name0.split(\"/\")[-3] + '/' + img_name0.split(\"/\")[-1]\n        depth_path1 = \"../input/generate-depth-masks/depth_maps/\" + img_name1.split(\"/\")[-3] + '/' + img_name1.split(\"/\")[-1]\n        \n        # read depth. shape: (h, w)\n        if self.mode in ['train', 'val']:\n            depth0 = read_megadepth_depth(\n                depth_path0, pad_to=self.depth_max_size)\n            depth1 = read_megadepth_depth(\n                depth_path1, pad_to=self.depth_max_size)\n        else:\n            depth0 = depth1 = torch.tensor([])\n\n        # read intrinsics of original size\n        K_0 = torch.tensor(np.asarray([float(x) for x in self.camerainst1[idx].split(\" \")]), dtype=torch.float).reshape(3, 3)\n        K_1 = torch.tensor(np.asarray([float(x) for x in self.camerainst2[idx].split(\" \")]), dtype=torch.float).reshape(3, 3)\n\n        # read and compute relative poses\n        R0 = self.rot1[idx].replace('{','').replace('}','').replace(\"'\", \"\")        \n        R0 = np.asarray([float(x) for x in R0.split(\" \")]).reshape(3, 3)\n        Tv0 = self.trans1[idx].replace('{','').replace('}','').replace(\"'\", \"\")\n        Tv0 = np.asarray([[float(x) for x in Tv0.split(\" \")]])\n        T0 = np.concatenate((R0, Tv0.T), axis=1)\n        T0 = np.concatenate((T0, np.asarray([[0, 0, 0, 1]])), axis=0)\n        del R0\n        del Tv0\n        R1 = self.rot2[idx].replace('{','').replace('}','').replace(\"'\", \"\")\n        R1 = np.asarray([float(x) for x in R1.split(\" \")]).reshape(3, 3)\n        Tv1 = self.trans2[idx].replace('{','').replace('}','').replace(\"'\", \"\")\n        Tv1 = np.asarray([[float(x) for x in Tv1.split(\" \")]])\n        T1 = np.concatenate((R1, Tv1.T), axis=1)\n        T1 = np.concatenate((T1, np.asarray([[0, 0, 0, 1]])), axis=0)\n        del R1\n        del Tv1\n        T_0to1 = torch.tensor(np.matmul(T1, np.linalg.inv(T0)), dtype=torch.float)[:4, :4]  # (4, 4)\n        T_1to0 = T_0to1.inverse()\n\n        data = {\n            'image0': image0,  # (1, h, w)\n            'depth0': depth0,  # (h, w)\n            'image1': image1,\n            'depth1': depth1,\n            'T_0to1': T_0to1,  # (4, 4)\n            'T_1to0': T_1to0,\n            'K0': K_0,  # (3, 3)\n            'K1': K_1,\n            'scale0': scale0,  # [scale_w, scale_h]\n            'scale1': scale1,\n            'dataset_name': 'MegaDepth',\n            'scene_id': idx,\n            'pair_id': idx,\n            'pair_names': (img_name0, img_name1),\n        }\n\n        # for LoFTR training\n        if mask0 is not None:  # img_padding is True\n            if self.coarse_scale:\n                [ts_mask_0, ts_mask_1] = F.interpolate(torch.stack([mask0, mask1], dim=0)[None].float(),\n                                                       scale_factor=self.coarse_scale,\n                                                       mode='nearest',\n                                                       recompute_scale_factor=False)[0].bool()\n            data.update({'mask0': ts_mask_0, 'mask1': ts_mask_1})\n        del image0\n        del image1\n        del depth0\n        del depth1\n        gc.collect()\n        torch.cuda.empty_cache()\n        return data","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:47.120151Z","iopub.execute_input":"2022-04-17T18:07:47.120937Z","iopub.status.idle":"2022-04-17T18:07:47.162885Z","shell.execute_reply.started":"2022-04-17T18:07:47.120898Z","shell.execute_reply":"2022-04-17T18:07:47.162108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport math\nfrom collections import abc\nfrom loguru import logger\nfrom torch.utils.data.dataset import Dataset\nfrom tqdm import tqdm\nfrom os import path as osp\nfrom pathlib import Path\nfrom joblib import Parallel, delayed\n\nimport pytorch_lightning as pl\nfrom torch import distributed as dist\nfrom torch.utils.data import (\n    Dataset,\n    DataLoader,\n    ConcatDataset,\n    DistributedSampler,\n    RandomSampler,\n    dataloader\n)\n\nfrom src.utils.augment import build_augmentor\nfrom src.utils.dataloader import get_local_split\nfrom src.utils.misc import tqdm_joblib\nfrom src.utils import comm\n\n\nfrom src.datasets.sampler import RandomConcatSampler\n\n\nclass MultiSceneDataModule(pl.LightningDataModule):\n    \"\"\" \n    For distributed training, each training process is assgined\n    only a part of the training scenes to reduce memory overhead.\n    \"\"\"\n    def __init__(self, args, config ,data):\n        super().__init__()\n\n        # 1. data config\n        # Train and Val should from the same data source\n        self.trainval_data_source = config.DATASET.TRAINVAL_DATA_SOURCE\n        self.test_data_source = config.DATASET.TEST_DATA_SOURCE\n        # training and validating\n        self.train_data = data\n        self.train_pose_root = config.DATASET.TRAIN_POSE_ROOT  # (optional)\n        self.train_npz_root = config.DATASET.TRAIN_NPZ_ROOT\n        self.train_list_path = config.DATASET.TRAIN_LIST_PATH\n        self.train_intrinsic_path = config.DATASET.TRAIN_INTRINSIC_PATH\n        self.val_data = data\n        self.val_pose_root = config.DATASET.VAL_POSE_ROOT  # (optional)\n        self.val_npz_root = config.DATASET.VAL_NPZ_ROOT\n        self.val_list_path = config.DATASET.VAL_LIST_PATH\n        self.val_intrinsic_path = config.DATASET.VAL_INTRINSIC_PATH\n        # testing\n        self.test_data = data\n        self.test_pose_root = config.DATASET.TEST_POSE_ROOT  # (optional)\n        self.test_npz_root = config.DATASET.TEST_NPZ_ROOT\n        self.test_list_path = config.DATASET.TEST_LIST_PATH\n        self.test_intrinsic_path = config.DATASET.TEST_INTRINSIC_PATH\n\n        # 2. dataset config\n        # general options\n        self.min_overlap_score_test = config.DATASET.MIN_OVERLAP_SCORE_TEST  # 0.4, omit data with overlap_score < min_overlap_score\n        self.min_overlap_score_train = config.DATASET.MIN_OVERLAP_SCORE_TRAIN\n        self.augment_fn = build_augmentor(config.DATASET.AUGMENTATION_TYPE)  # None, options: [None, 'dark', 'mobile']\n\n        # MegaDepth options\n        self.mgdpt_img_resize = config.DATASET.MGDPT_IMG_RESIZE  # 840\n        self.mgdpt_img_pad = config.DATASET.MGDPT_IMG_PAD   # True\n        self.mgdpt_depth_pad = config.DATASET.MGDPT_DEPTH_PAD   # True\n        self.mgdpt_df = config.DATASET.MGDPT_DF  # 8\n        self.coarse_scale = 1 / config.LOFTR.RESOLUTION[0]  # 0.125. for training loftr.\n\n        # 3.loader parameters\n        self.train_loader_params = {\n            'batch_size': args.batch_size,\n            'num_workers': args.num_workers,\n            'pin_memory': getattr(args, 'pin_memory', True)\n        }\n        self.val_loader_params = {\n            'batch_size': 1,\n            'shuffle': False,\n            'num_workers': args.num_workers,\n            'pin_memory': getattr(args, 'pin_memory', True)\n        }\n        self.test_loader_params = {\n            'batch_size': 1,\n            'shuffle': False,\n            'num_workers': args.num_workers,\n            'pin_memory': True\n        }\n        \n        # 4. sampler\n        self.data_sampler = config.TRAINER.DATA_SAMPLER\n        self.n_samples_per_subset = config.TRAINER.N_SAMPLES_PER_SUBSET\n        self.subset_replacement = config.TRAINER.SB_SUBSET_SAMPLE_REPLACEMENT\n        self.shuffle = config.TRAINER.SB_SUBSET_SHUFFLE\n        self.repeat = config.TRAINER.SB_REPEAT\n        \n        # (optional) RandomSampler for debugging\n\n        # misc configurations\n        self.parallel_load_data = getattr(args, 'parallel_load_data', False)\n        self.seed = config.TRAINER.SEED  # 66\n\n    def setup(self, stage=None):\n        \"\"\"\n        Setup train / val / test dataset. This method will be called by PL automatically.\n        Args:\n            stage (str): 'fit' in training phase, and 'test' in testing phase.\n        \"\"\"\n\n        assert stage in ['fit', 'test'], \"stage must be either fit or test\"\n\n\n        if stage == 'fit':\n            self.train_dataset = self._setup_dataset(\n                self.train_data,\n                self.train_npz_root,\n                self.train_list_path,\n                self.train_intrinsic_path,\n                mode='train',\n                min_overlap_score=self.min_overlap_score_train,\n                pose_dir=self.train_pose_root)\n            # setup multiple (optional) validation subsets\n            \n            self.val_dataset = self._setup_dataset(\n                self.val_data,\n                self.val_npz_root,\n                self.val_list_path,\n                self.val_intrinsic_path,\n                mode='val',\n                min_overlap_score=self.min_overlap_score_test,\n                pose_dir=self.val_pose_root)\n            \n        else:  # stage == 'test\n            self.test_dataset = self._setup_dataset(\n                self.test_data,\n                self.test_npz_root,\n                self.test_list_path,\n                self.test_intrinsic_path,\n                mode='test',\n                min_overlap_score=self.min_overlap_score_test,\n                pose_dir=self.test_pose_root)\n            \n\n    def _setup_dataset(self,\n                       data,\n                       split_npz_root,\n                       scene_list_path,\n                       intri_path,\n                       mode='train',\n                       min_overlap_score=0.,\n                       pose_dir=None):\n        \"\"\" Setup train / val / test set\"\"\"\n        local_npz_names = \"\"\n        dataset_builder = self._build_concat_dataset\n        return dataset_builder(data, local_npz_names, split_npz_root, intri_path,\n                                mode=mode, min_overlap_score=min_overlap_score, pose_dir=pose_dir)\n\n    def _build_concat_dataset(\n        self,\n        data,\n        npz_names,\n        npz_dir,\n        intrinsic_path,\n        mode,\n        min_overlap_score=0.,\n        pose_dir=None\n    ):\n        datasets = []\n        augment_fn = self.augment_fn if mode == 'train' else None\n        data_source = self.trainval_data_source if mode in ['train', 'val'] else self.test_data_source\n        npz_path = \"\"\n        \n        datasets.append(\n            MegaDepthDataset(data,\n                             npz_path,\n                             mode=mode,\n                             min_overlap_score=min_overlap_score,\n                             img_resize=self.mgdpt_img_resize,\n                             df=self.mgdpt_df,\n                             img_padding=self.mgdpt_img_pad,\n                             depth_padding=self.mgdpt_depth_pad,\n                             augment_fn=augment_fn,\n                             coarse_scale=self.coarse_scale))\n        return ConcatDataset(datasets)\n    \n\n    def train_dataloader(self):\n        \"\"\" Build training dataloader for ScanNet / MegaDepth. \"\"\"\n#         assert self.data_sampler in ['scene_balance']\n#         #logger.info(f'[rank:{self.rank}/{self.world_size}]: Train Sampler and DataLoader re-init (should not re-init between epochs!).')\n#         if self.data_sampler == 'scene_balance':\n#             sampler = RandomConcatSampler(self.train_dataset,\n#                                           self.n_samples_per_subset,\n#                                           self.subset_replacement,\n#                                           self.shuffle, self.repeat, self.seed)\n#         else:\n#             sampler = None\n        dataloader = DataLoader(self.train_dataset, batch_size=1, \n                              shuffle=False, \n                              num_workers=0, pin_memory=True, drop_last=True)\n        return dataloader\n    \n    def val_dataloader(self):\n        \"\"\" Build validation dataloader for ScanNet / MegaDepth. \"\"\"\n        #logger.info(f'[rank:{self.rank}/{self.world_size}]: Val Sampler and DataLoader re-init.')\n        dataloader = DataLoader(self.val_dataset, batch_size=1, \n                              shuffle=False, \n                              num_workers=0, pin_memory=True, drop_last=True)\n        return dataloader\n\n    def test_dataloader(self, *args, **kwargs):\n        #logger.info(f'[rank:{self.rank}/{self.world_size}]: Test Sampler and DataLoader re-init.')\n        sampler = DistributedSampler(self.test_dataset, shuffle=False)\n        return DataLoader(self.test_dataset, sampler=sampler, **self.test_loader_params)\n\n\ndef _build_dataset(dataset: Dataset, *args, **kwargs):\n    return dataset(*args, **kwargs)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:47.164502Z","iopub.execute_input":"2022-04-17T18:07:47.164761Z","iopub.status.idle":"2022-04-17T18:07:48.814359Z","shell.execute_reply.started":"2022-04-17T18:07:47.164728Z","shell.execute_reply":"2022-04-17T18:07:48.813564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport argparse\nimport pprint\nfrom distutils.util import strtobool\nfrom pathlib import Path\nfrom loguru import logger as loguru_logger\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities import rank_zero_only\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\nfrom pytorch_lightning.plugins import DDPPlugin\n\nfrom src.config.default import get_cfg_defaults\nfrom src.utils.misc import get_rank_zero_only_logger, setup_gpus\nfrom src.utils.profiler import build_profiler\nimport pandas as pd\nloguru_logger = get_rank_zero_only_logger(loguru_logger)\n\ndef parse_args():\n    # init a costum parser which will be added into pl.Trainer parser\n    # check documentation: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags\n    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\n        'data_cfg_path', type=str, help='data config path')\n    parser.add_argument(\n        'main_cfg_path', type=str, help='main config path')\n    parser.add_argument(\n        '--exp_name', type=str, default='default_exp_name')\n    parser.add_argument(\n        '--batch_size', type=int, default=4, help='batch_size per gpu')\n    parser.add_argument(\n        '--num_workers', type=int, default=4)\n    parser.add_argument(\n        '--pin_memory', type=lambda x: bool(strtobool(x)),\n        nargs='?', default=True, help='whether loading data to pinned memory or not')\n    parser.add_argument(\n        '--ckpt_path', type=str, default=\"../input/kornia-loftr/outdoor_ds.ckpt\",\n        help='pretrained checkpoint path, helpful for using a pre-trained coarse-only LoFTR')\n    parser.add_argument(\n        '--disable_ckpt', action='store_true',\n        help='disable checkpoint saving (useful for debugging).')\n    parser.add_argument(\n        '--profiler_name', type=str, default=None,\n        help='options: [inference, pytorch], or leave it unset')\n    parser.add_argument(\n        '--parallel_load_data', action='store_true',\n        help='load datasets in with multiple processes.')\n\n    parser = pl.Trainer.add_argparse_args(parser)\n    return parser.parse_args('../input/loftrutils/LoFTR-master/LoFTR-master/configs/data/megadepth_trainval_640.py ../input/loftrutils/LoFTR-master/LoFTR-master/configs/loftr/outdoor/loftr_ds_dense.py --exp_name test --gpus 0 --num_nodes 0 --accelerator gpu --batch_size 1 --check_val_every_n_epoch 1 --log_every_n_steps 1 --flush_logs_every_n_steps 1 --limit_val_batches 1 --num_sanity_val_steps 10 --benchmark True --max_epochs 4'.split())\n\n\ndef train():\n    # parse arguments\n    args = parse_args()\n    rank_zero_only(pprint.pprint)(vars(args))\n\n    # init default-cfg and merge it with the main- and data-cfg\n    config = get_cfg_defaults()\n    config.merge_from_file(args.main_cfg_path)\n    config.merge_from_file(args.data_cfg_path)\n    pl.seed_everything(config.TRAINER.SEED)  # reproducibility\n    # TODO: Use different seeds for each dataloader workers\n    # This is needed for data augmentation\n    \n    # scale lr and warmup-step automatically\n    args.gpus = _n_gpus = setup_gpus(args.gpus)\n    config.TRAINER.WORLD_SIZE = _n_gpus * args.num_nodes\n    config.TRAINER.TRUE_BATCH_SIZE = config.TRAINER.WORLD_SIZE * args.batch_size\n    _scaling = 1#config.TRAINER.TRUE_BATCH_SIZE / config.TRAINER.CANONICAL_BS\n    config.TRAINER.SCALING = _scaling\n    config.TRAINER.TRUE_LR = 0.00001 * _scaling\n    config.TRAINER.WARMUP_STEP = math.floor(config.TRAINER.WARMUP_STEP / _scaling)\n    \n    # lightning module\n    profiler = build_profiler(args.profiler_name)\n    model = PL_LoFTR(config, pretrained_ckpt=args.ckpt_path, profiler=profiler)\n    loguru_logger.info(f\"LoFTR LightningModule initialized!\")\n    \n    # lightning data\n    data = pd.read_csv(\"../input/imc-data-reorder/train.csv\")\n    data_module = MultiSceneDataModule(args, config, data[:100])\n    gc.collect()\n    loguru_logger.info(f\"LoFTR DataModule initialized!\")\n    \n    # TensorBoard Logger\n    logger = TensorBoardLogger(save_dir='logs/tb_logs', name=args.exp_name, default_hp_metric=False)\n    ckpt_dir = Path(logger.log_dir) / 'checkpoints'\n    \n    # Callbacks\n    # TODO: update ModelCheckpoint to monitor multiple metrics\n    ckpt_callback = ModelCheckpoint(monitor='auc@10', verbose=True, save_top_k=5, mode='max',\n                                    save_last=True,\n                                    dirpath=str(ckpt_dir),\n                                    filename='{epoch}-{auc@5:.3f}-{auc@10:.3f}-{auc@20:.3f}')\n    lr_monitor = LearningRateMonitor(logging_interval='step')\n    callbacks = [lr_monitor]\n    if not args.disable_ckpt:\n        callbacks.append(ckpt_callback)\n    \n    # Lightning Trainer\n    trainer = pl.Trainer.from_argparse_args(\n        args,\n#         plugins=DDPPlugin(find_unused_parameters=False,\n#                           num_nodes=args.num_nodes,\n#                           sync_batchnorm=config.TRAINER.WORLD_SIZE > 0),\n        gradient_clip_val=config.TRAINER.GRADIENT_CLIPPING,\n        callbacks=callbacks,\n        logger=logger,\n        #sync_batchnorm=config.TRAINER.WORLD_SIZE > 0,\n        replace_sampler_ddp=False,  # use custom sampler\n          # avoid repeated samples!\n        weights_summary='full',\n        profiler=profiler)\n    loguru_logger.info(f\"Trainer initialized!\")\n    loguru_logger.info(f\"Start training!\")\n    trainer.fit(model, datamodule=data_module)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:48.815847Z","iopub.execute_input":"2022-04-17T18:07:48.816121Z","iopub.status.idle":"2022-04-17T18:07:48.849851Z","shell.execute_reply.started":"2022-04-17T18:07:48.816083Z","shell.execute_reply":"2022-04-17T18:07:48.849185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T18:07:48.85116Z","iopub.execute_input":"2022-04-17T18:07:48.851428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd checkpoints/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}