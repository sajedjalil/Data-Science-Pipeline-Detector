{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Welcome Back Kagglers \n\ncredit : https://www.kaggle.com/code/ammarali32/imc-2022-kornia-loftr-from-0-533-to-0-721","metadata":{}},{"cell_type":"markdown","source":"\n<center>\n    <h2 style=\"color: #022047\"> If you found it useful please upvote  </h2>\n</center>\n\n![](https://storage.googleapis.com/kaggle-media/competitions/google-image-matching/trevi-canvas-licensed-nonoderivs.jpg)","metadata":{}},{"cell_type":"markdown","source":"# ***Install Libs***","metadata":{}},{"cell_type":"code","source":"dry_run = False\n!pip install ../input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n!pip install ../input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:43:50.83348Z","iopub.execute_input":"2022-05-31T09:43:50.833778Z","iopub.status.idle":"2022-05-31T09:44:47.342906Z","shell.execute_reply.started":"2022-05-31T09:43:50.8337Z","shell.execute_reply":"2022-05-31T09:44:47.342057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Import dependencies***","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport csv\nfrom glob import glob\nimport torch\nimport matplotlib.pyplot as plt\nimport kornia\nfrom kornia_moons.feature import *\nimport kornia as K\nimport kornia.feature as KF\nimport gc\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:44:47.344765Z","iopub.execute_input":"2022-05-31T09:44:47.345033Z","iopub.status.idle":"2022-05-31T09:44:49.561952Z","shell.execute_reply.started":"2022-05-31T09:44:47.344999Z","shell.execute_reply":"2022-05-31T09:44:49.561251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Model***","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda')\nmatcher = KF.LoFTR(pretrained=None)\nmatcher.load_state_dict(torch.load(\"../input/kornia-loftr/loftr_outdoor.ckpt\")['state_dict'])\nmatcher = matcher.to(device).eval().half()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:44:49.563161Z","iopub.execute_input":"2022-05-31T09:44:49.56411Z","iopub.status.idle":"2022-05-31T09:44:53.701215Z","shell.execute_reply.started":"2022-05-31T09:44:49.56407Z","shell.execute_reply":"2022-05-31T09:44:53.700471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Utils*","metadata":{}},{"cell_type":"code","source":"src = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]\n\n\ndef FlattenMatrix(M, num_digits=8):\n    '''Convenience function to write CSV files.'''\n    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n\n\ndef load_torch_image(fname):\n    img = cv2.imread(fname)\n#     img = img[:img.shape[1]] # memory check\n    orig_h, orig_w = img.shape[:2]\n    scale = 1200 / max(img.shape[0], img.shape[1]) \n    w = int(img.shape[1] * scale)\n    h = int(img.shape[0] * scale)\n    img = cv2.resize(img, (w, h))\n    img = K.image_to_tensor(img, False).float() /255.\n    img = K.color.bgr_to_rgb(img)\n    return img, (orig_w, orig_h), (w, h)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:44:53.703263Z","iopub.execute_input":"2022-05-31T09:44:53.703515Z","iopub.status.idle":"2022-05-31T09:44:53.715864Z","shell.execute_reply.started":"2022-05-31T09:44:53.703481Z","shell.execute_reply":"2022-05-31T09:44:53.715151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***Inference***","metadata":{}},{"cell_type":"code","source":"!nproc","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:44:53.717319Z","iopub.execute_input":"2022-05-31T09:44:53.717563Z","iopub.status.idle":"2022-05-31T09:44:54.401865Z","shell.execute_reply.started":"2022-05-31T09:44:53.717528Z","shell.execute_reply":"2022-05-31T09:44:54.401044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from multiprocessing import Pool\n\nalpha = 15.0\nangle: torch.tensor = torch.ones(1) * alpha\nscale: torch.tensor = torch.ones(1, 2)\n\ndef preprocess(row):\n    sample_id, batch_id, image_1_id, image_2_id = row\n    image_1, orig_sz1, sz1 = load_torch_image(f'{src}/test_images/{batch_id}/{image_1_id}.png')\n    center: torch.tensor = torch.ones(1, 2)\n    center[..., 0] = sz1[0] / 2  # x\n    center[..., 1] = sz1[1] / 2  # y\n    M: torch.tensor = K.geometry.get_rotation_matrix2d(center, angle, scale) # 1x2x3\n    Minv: torch.tensor = K.geometry.get_rotation_matrix2d(center, -angle, scale)\n    image_1_rot = K.geometry.warp_affine(image_1, M.to(image_1.device), dsize=(sz1[1], sz1[0]))\n    image_1_irot = K.geometry.warp_affine(image_1, Minv.to(image_1.device), dsize=(sz1[1], sz1[0]))\n    image_1_flip = K.geometry.transform.hflip(image_1)\n\n    image_2, orig_sz2, sz2 = load_torch_image(f'{src}/test_images/{batch_id}/{image_2_id}.png')\n    image_2_rot = K.geometry.warp_affine(image_2, M.to(image_2.device), dsize=(sz2[1], sz2[0]))\n    image_2_irot = K.geometry.warp_affine(image_2, Minv.to(image_2.device), dsize=(sz2[1], sz2[0]))\n    image_2_flip = K.geometry.transform.hflip(image_2)\n    \n    return {\n        'sample_id': sample_id,\n        'image_1_info': (orig_sz1, sz1),\n        'image_2_info': (orig_sz2, sz2),\n        'images_1': K.color.rgb_to_grayscale(torch.cat((image_1, image_1_rot, image_1_irot, image_1_flip))),\n        'images_2': K.color.rgb_to_grayscale(torch.cat((image_2, image_2_rot, image_2_irot, image_2_flip))),\n        'image_1': image_1,\n        'image_2': image_2,\n        'affine_mats': (M, Minv),\n        'st': time.perf_counter()\n    }\n\ndef _matching(model, feat_c0, feat_c1, feat_f0, feat_f1, data):\n    feat_c0, feat_c1 = model.loftr_coarse(feat_c0, feat_c1, None, None)\n    \n    # 3. match coarse-level\n    model.coarse_matching(feat_c0, feat_c1, data, mask_c0=None, mask_c1=None)\n\n    # 4. fine-level refinement\n    feat_f0_unfold, feat_f1_unfold = model.fine_preprocess(feat_f0, feat_f1, feat_c0, feat_c1, data)\n    if feat_f0_unfold.size(0) != 0:  # at least one coarse level predicted\n        feat_f0_unfold, feat_f1_unfold = model.loftr_fine(feat_f0_unfold, feat_f1_unfold)\n\n    # 5. match fine-level\n    model.fine_matching(feat_f0_unfold, feat_f1_unfold, data)\n\ndef deep(data):\n    with torch.no_grad():\n        M, Minv = data['affine_mats']\n        orig_sz1, sz1 = data['image_1_info']\n        orig_sz2, sz2 = data['image_2_info']\n        c0s, f0s = matcher.backbone(data['images_1'].to(device).half())\n        c1s, f1s = matcher.backbone(data['images_2'].to(device).half())\n        meta = {\n            'bs': 1,\n            'hw0_i': [sz1[1], sz1[0]],\n            'hw1_i': [sz2[1], sz2[0]],\n            'hw0_c': c0s.shape[2:], 'hw1_c': c1s.shape[2:],\n            'hw0_f': f0s.shape[2:], 'hw1_f': f1s.shape[2:],\n        }\n\n        mkpts0, mkpts1, batch_indexes = [], [], []\n        queries = [(0, 0), (1, 0), (2, 0), (3, 3), (0, 1), (0, 2)]\n        for bi, (i, j) in enumerate(queries):\n            feat_c0 = c0s[i:i+1]\n            feat_c1 = c1s[j:j+1]\n            feat_f0 = f0s[i:i+1]\n            feat_f1 = f1s[j:j+1]\n            \n            feat_c0 = matcher.pos_encoding(feat_c0).permute(0, 2, 3, 1)\n            n, h, w, c = feat_c0.shape\n            feat_c0 = feat_c0.reshape(n, -1, c)\n\n            feat_c1 = matcher.pos_encoding(feat_c1).permute(0, 2, 3, 1)\n            n1, h1, w1, c1 = feat_c1.shape\n            feat_c1 = feat_c1.reshape(n1, -1, c1)\n            _matching(matcher, feat_c0, feat_c1, feat_f0, feat_f1, meta)\n            \n            mkpts0.append(meta['mkpts0_f'].float().cpu().numpy())\n            mkpts1.append(meta['mkpts1_f'].float().cpu().numpy())\n            batch_indexes.append(np.full(len(meta['mkpts0_f']), bi, dtype=np.int32))\n    mkpts0 = np.concatenate(mkpts0)\n    mkpts1 = np.concatenate(mkpts1)\n    batch_indexes = np.concatenate(batch_indexes)\n\n    mask = (batch_indexes == 1)\n    mkpts0[mask] = np.concatenate([mkpts0[mask], np.ones((np.sum(mask), 1))], axis=1) @ Minv[0].cpu().numpy().T\n    mask = (batch_indexes == 2)\n    mkpts0[mask] = np.concatenate([mkpts0[mask], np.ones((np.sum(mask), 1))], axis=1) @ M[0].cpu().numpy().T\n    mask = (batch_indexes == 3)\n    mkpts0[mask, 0] = sz1[0] - mkpts0[mask, 0]\n    mkpts1[mask, 0] = sz2[0] - mkpts1[mask, 0]\n    mask = (batch_indexes == 4)\n    mkpts1[mask] = np.concatenate([mkpts1[mask], np.ones((np.sum(mask), 1))], axis=1) @ Minv[0].cpu().numpy().T\n    mask = (batch_indexes == 5)\n    mkpts1[mask] = np.concatenate([mkpts1[mask], np.ones((np.sum(mask), 1))], axis=1) @ M[0].cpu().numpy().T\n\n\n    mkpts0_orig = mkpts0 / sz1 * orig_sz1\n    mkpts1_orig = mkpts1 / sz2 * orig_sz2\n\n    data['mkpts0'] = mkpts0\n    data['mkpts1'] = mkpts1\n    data['mkpts0_orig'] = mkpts0_orig\n    data['mkpts1_orig'] = mkpts1_orig\n    return data\n\ndef ransac(data):\n    if len(data['mkpts0']) > 7:\n        F, inliers = cv2.findFundamentalMat(\n            data['mkpts0_orig'], data['mkpts1_orig'],\n            cv2.USAC_MAGSAC, 0.150, 0.9999, 250000)\n        inliers = inliers > 0\n        assert F.shape == (3, 3), 'Malformed F?'\n        data['F'] = F\n        data['inliers'] = inliers\n    else:\n        data['F'] = np.zeros((3, 3))\n        data['inliers'] = []\n    return data\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:44:54.405378Z","iopub.execute_input":"2022-05-31T09:44:54.405609Z","iopub.status.idle":"2022-05-31T09:44:54.440945Z","shell.execute_reply.started":"2022-05-31T09:44:54.405582Z","shell.execute_reply":"2022-05-31T09:44:54.439957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"F_dict = {}\n\nimport time\n\nprocessed_samples = map(preprocess, test_samples)\nmatched_samples = map(deep, processed_samples)\n\nwith Pool(2) as pool:\n    for i, data in enumerate(pool.imap(ransac, matched_samples, chunksize=4)):\n        F_dict[data['sample_id']] = data['F']\n        inliers = data['inliers']\n        nd = time.perf_counter()\n        if (i < 3) and len(inliers) > 0:\n            mkpts0 = data['mkpts0']\n            mkpts1 = data['mkpts1']\n            image_1 = data['image_1']\n            image_2 = data['image_2']\n\n            print(f\"Running time: {nd-data['st']:.3f}s\")\n            draw_LAF_matches(\n            KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0).view(1,-1, 2),\n                                        torch.ones(mkpts0.shape[0]).view(1,-1, 1, 1),\n                                        torch.ones(mkpts0.shape[0]).view(1,-1, 1)),\n\n            KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n                                        torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n                                        torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n            torch.arange(mkpts0.shape[0]).view(-1,1).repeat(1,2),\n            K.tensor_to_image(image_1),\n            K.tensor_to_image(image_2),\n            inliers,\n            draw_dict={'inlier_color': (0.2, 1, 0.2),\n                       'tentative_color': None, \n                       'feature_color': (0.2, 0.5, 1), 'vertical': False})\n\nwith open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in F_dict.items():\n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:44:54.442446Z","iopub.execute_input":"2022-05-31T09:44:54.443219Z","iopub.status.idle":"2022-05-31T09:46:24.361239Z","shell.execute_reply.started":"2022-05-31T09:44:54.443176Z","shell.execute_reply":"2022-05-31T09:46:24.360374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center>\n    <h2 style=\"color: #022047\"> Thanks for reading ðŸ¤—  </h2>\n</center>","metadata":{}}]}