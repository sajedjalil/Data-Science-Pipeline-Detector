{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this competition the competition hosts made us aware of an interresting alternative to all the keypoint detectors/descriptors. A line segment detector and descriptor named SOLD². The Github site is available at [url](https://github.com/cvg/SOLD2) \n\nAs the authors of the SOLD² model state on their github: 'SOLD² is a deep line segment detector and descriptor that can be trained without hand-labelled line segments and that can robustly match lines even in the presence of occlusion.'\n\nThis Inference Notebook contains an implementation of the SOLD² setup focussed on this Kaggle Competition. While the score of the notebook isn't LB breaking (could be a matter of further tuning...I will give it some more attempts) it is for sure one of the more interresting models that could be applied in various other situations.\n\nNote that we use in this notebook the start/end points of a line as the keypoints to further use the MAGSAC and finding of Fundamental Matrix implementation as is.\n\nLet me know if you like the notebook an give it an upvote if you do ;-)","metadata":{}},{"cell_type":"code","source":"# Import Modules\nimport numpy as np \nimport pandas as pd\nimport csv\nimport cv2\nimport gc\nimport torch\nimport sys\n\n# SOLD2\nsys.path.append('../input/sold2linematching')\nfrom sold2.model.line_matcher import LineMatcher\nfrom sold2.misc.visualize_util import plot_images, plot_lines, plot_line_matches, plot_color_line_matches, plot_keypoints","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T14:15:27.208744Z","iopub.execute_input":"2022-05-07T14:15:27.209436Z","iopub.status.idle":"2022-05-07T14:15:31.835836Z","shell.execute_reply.started":"2022-05-07T14:15:27.209308Z","shell.execute_reply":"2022-05-07T14:15:31.834893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Torch - Device\nif not torch.cuda.is_available():\n    print('You may want to enable the GPU switch?')    \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:31.837861Z","iopub.execute_input":"2022-05-07T14:15:31.838165Z","iopub.status.idle":"2022-05-07T14:15:31.910467Z","shell.execute_reply.started":"2022-05-07T14:15:31.838124Z","shell.execute_reply":"2022-05-07T14:15:31.90958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Data","metadata":{}},{"cell_type":"code","source":"src = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:31.9123Z","iopub.execute_input":"2022-05-07T14:15:31.913081Z","iopub.status.idle":"2022-05-07T14:15:31.93043Z","shell.execute_reply.started":"2022-05-07T14:15:31.913032Z","shell.execute_reply":"2022-05-07T14:15:31.929381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup SOLD2","metadata":{}},{"cell_type":"code","source":"ckpt_path = '../input/sold2linematching/pretrained/sold2_wireframe.tar'\nmode = 'dynamic'  # 'dynamic' or 'static'\n\n# Initialize the line matcher\nconfig = {\n    'model_cfg': {\n        'model_name': \"lcnn_simple\",\n        'model_architecture': \"simple\",\n        # Backbone related config\n        'backbone': \"lcnn\",\n        'backbone_cfg': {\n            'input_channel': 1, # Use RGB images or grayscale images.\n            'depth': 4,\n            'num_stacks': 2,\n            'num_blocks': 1,\n            'num_classes': 5\n        },\n        # Junction decoder related config\n        'junction_decoder': \"superpoint_decoder\",\n        'junc_decoder_cfg': {},\n        # Heatmap decoder related config\n        'heatmap_decoder': \"pixel_shuffle\",\n        'heatmap_decoder_cfg': {},\n        # Descriptor decoder related config\n        'descriptor_decoder': \"superpoint_descriptor\",\n        'descriptor_decoder_cfg': {},\n        # Shared configurations\n        'grid_size': 8,\n        'keep_border_valid': True,\n        # Threshold of junction detection\n        'detection_thresh': 0.0153846, # 1/65\n        'max_num_junctions': 500, # Original 300\n        # Threshold of heatmap detection\n        'prob_thresh': 0.5,\n        # Weighting related parameters\n        'weighting_policy': mode,\n        # [Heatmap loss]\n        'w_heatmap': 0.,\n        'w_heatmap_class': 1,\n        'heatmap_loss_func': \"cross_entropy\",\n        'heatmap_loss_cfg': {\n            'policy': mode\n        },\n        # [Heatmap consistency loss]\n        # [Junction loss]\n        'w_junc': 0.,\n        'junction_loss_func': \"superpoint\",\n        'junction_loss_cfg': {\n            'policy': mode\n        },\n        # [Descriptor loss]\n        'w_desc': 0.,\n        'descriptor_loss_func': \"regular_sampling\",\n        'descriptor_loss_cfg': {\n            'dist_threshold': 8,\n            'grid_size': 4,\n            'margin': 1,\n            'policy': mode\n        },\n    },\n    'line_detector_cfg': {\n        'detect_thresh': 0.20,  # Original: 0.25 ... depending on your images, you might need to tune this parameter\n        'num_samples': 512,     # Original: 64\n        'sampling_method': \"local_max\",\n        'inlier_thresh': 0.75,  # Original: 0.9 .. in paper 0.75 is mentioned.\n        \"use_candidate_suppression\": True,\n        \"nms_dist_tolerance\": 2.,  # Original 3.\n        \"use_heatmap_refinement\": True,\n        \"heatmap_refine_cfg\": {\n            \"mode\": \"local\",\n            \"ratio\": 0.2,\n            \"valid_thresh\": 1e-3,\n            \"num_blocks\": 20,\n            \"overlap_ratio\": 0.5\n        }\n    },\n    'multiscale': True,\n    'line_matcher_cfg': {\n        'cross_check': True,\n        'num_samples': 10,\n        'min_dist_pts': 2,\n        'top_k_candidates': 5,\n        'grid_size': 4\n    }\n}\n\n# Create SOLD2 Matcher\nsold2_matcher = LineMatcher(config[\"model_cfg\"], ckpt_path, device, config[\"line_detector_cfg\"], config[\"line_matcher_cfg\"], config[\"multiscale\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:31.934865Z","iopub.execute_input":"2022-05-07T14:15:31.935594Z","iopub.status.idle":"2022-05-07T14:15:37.769487Z","shell.execute_reply.started":"2022-05-07T14:15:31.935555Z","shell.execute_reply":"2022-05-07T14:15:37.768358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Functions","metadata":{}},{"cell_type":"code","source":"def FlattenMatrix(M, num_digits = 8):\n    '''Convenience function to write CSV files.'''    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n\ndef get_fundamental_matrix(kpts1, kpts2):    \n    if len(kpts1) > 7:\n        F, inliers = cv2.findFundamentalMat(kpts1, \n                                            kpts2, \n                                            cv2.USAC_MAGSAC, \n                                            ransacReprojThreshold = 0.20, \n                                            confidence = 0.99999, \n                                            maxIters = 100000)\n        return F, inliers\n    else:\n        return np.zeros((3, 3)), None\n    \n\ndef load_image(image_path):\n    img = cv2.imread(image_path, 0)\n    \n    # Scale Factor...recommended to scale images to between 400 - 800\n    scale_factor = 800 / max(img.shape[0], img.shape[1]) \n    w = int(img.shape[1] * scale_factor)\n    h = int(img.shape[0] * scale_factor)\n    \n    # Resize\n    img = cv2.resize(img, (w, h), interpolation = cv2.INTER_AREA)\n    img = (img / 255.).astype(float)\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:37.771826Z","iopub.execute_input":"2022-05-07T14:15:37.772071Z","iopub.status.idle":"2022-05-07T14:15:37.793548Z","shell.execute_reply.started":"2022-05-07T14:15:37.772042Z","shell.execute_reply":"2022-05-07T14:15:37.792373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the SOLD2 model we eventually have a set of matched lines. When using Ransac (or one of its variants..) in the process to calculate a fundamental matrix we can't use the lines. So what we instead do is use the start and endpoints of a line as unique keypoints.","metadata":{}},{"cell_type":"code","source":"def get_keypoints(batch_id, img_id1, img_id2, plot = False):\n    image_fpath_1 = f'{src}/test_images/{batch_id}/{img_id1}.png'\n    image_fpath_2 = f'{src}/test_images/{batch_id}/{img_id2}.png'\n    \n    # Process Image 1\n    img1 = load_image(image_fpath_1)\n    torch_img1 = torch.tensor(img1, dtype=torch.float)[None, None]\n    \n    # Process Image 2\n    img2 = load_image(image_fpath_2)\n    torch_img2 = torch.tensor(img2, dtype=torch.float)[None, None]\n\n    # Match the lines\n    outputs = sold2_matcher([torch_img1, torch_img2])\n    line_seg1 = outputs[\"line_segments\"][0]\n    line_seg2 = outputs[\"line_segments\"][1]\n    matches = outputs[\"matches\"]\n\n    # Get Valid Matches\n    valid_matches = matches != -1\n    match_indices = matches[valid_matches]\n    matched_lines1 = line_seg1[valid_matches][:, :, ::-1]\n    matched_lines2 = line_seg2[match_indices][:, :, ::-1]\n    \n    # Plot the matches\n    if plot:\n        plot_images([img1, img2], ['Image1 - detected lines', 'Image2 - detected lines'])\n        plot_lines([line_seg1[:, :, ::-1], line_seg2[:, :, ::-1]], ps=3, lw=2)\n        plot_images([img1, img2], ['Image1 - matched lines', 'Image2 - matched lines'])\n        plot_color_line_matches([matched_lines1, matched_lines2], lw=2)\n\n    # Get start and end point of matched lines as regular keypoints\n    mkpts1 = matched_lines1.reshape(matched_lines1.shape[0] * 2, 2)\n    mkpts2 = matched_lines2.reshape(matched_lines2.shape[0] * 2, 2)\n    \n    return mkpts1, mkpts2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"f_matrix_dict = {}\nfor i, row in enumerate(test_samples):\n    sample_id, batch_id, img_id1, img_id2 = row\n\n    # Get SOLD2 Keypoints\n    plot = False\n    if i < 3: plot = True\n    mkpts1, mkpts2 = get_keypoints(batch_id, img_id1, img_id2, plot)\n    \n    # Get Fundamental matrix\n    f_matrix_dict[sample_id], _ = get_fundamental_matrix(mkpts1, mkpts2)\n    \n    # Mem Cleanup\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:37.796147Z","iopub.execute_input":"2022-05-07T14:15:37.796479Z","iopub.status.idle":"2022-05-07T14:15:52.621898Z","shell.execute_reply.started":"2022-05-07T14:15:37.796431Z","shell.execute_reply":"2022-05-07T14:15:52.62096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission","metadata":{}},{"cell_type":"code","source":"# Write Submission File   \nwith open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in f_matrix_dict.items():\n                \n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:52.623507Z","iopub.execute_input":"2022-05-07T14:15:52.624373Z","iopub.status.idle":"2022-05-07T14:15:52.631164Z","shell.execute_reply.started":"2022-05-07T14:15:52.624331Z","shell.execute_reply":"2022-05-07T14:15:52.629987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:52.632823Z","iopub.execute_input":"2022-05-07T14:15:52.634007Z","iopub.status.idle":"2022-05-07T14:15:52.662781Z","shell.execute_reply.started":"2022-05-07T14:15:52.633959Z","shell.execute_reply":"2022-05-07T14:15:52.661867Z"},"trusted":true},"execution_count":null,"outputs":[]}]}