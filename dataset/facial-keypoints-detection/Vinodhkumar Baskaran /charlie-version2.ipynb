{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ***Reading the input file*** ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\"\"\"\nImporting the necessary package\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split \nfrom IPython.display import clear_output\nfrom time import sleep\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/facial-keypoints-detection/\n\nprint(\"\\nExtracting .zip dataset files to working directory ...\")\n!unzip -u ../input/facial-keypoints-detection/test.zip\n!unzip -u ../input/facial-keypoints-detection/training.zip\n\nprint(\"\\nCurrent working directory:\")\n!pwd\nprint(\"\\nContents of working directory:\")\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain_csv = 'training.csv'\ntest_csv = 'test.csv'\nidlookup_file = '../input/facial-keypoints-detection/IdLookupTable.csv'\ntrain = pd.read_csv(train_csv)\ntest = pd.read_csv(test_csv)\nidlookup_data = pd.read_csv(idlookup_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EDA**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of images in train : {}\".format(len(train)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **IDentifying null**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna(method = 'ffill',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)/255.\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop('Image',axis = 1)\n    keypoint_features = []\n    for idx, sample_keypoints in keypoint_data.iterrows():\n        keypoint_features.append(sample_keypoints)\n    keypoint_features = np.array(keypoint_features, dtype = 'float')\n    return keypoint_features\n\ndef plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_image_index = 10\n\nclean_train_images = load_images(train)\nprint(\"Shape of clean_train_images: {}\".format(np.shape(clean_train_images)))\nclean_train_keypoints = load_keypoints(train)\nprint(\"Shape of clean_train_keypoints: {}\".format(np.shape(clean_train_keypoints)))\ntest_images = load_images(test)\nprint(\"Shape of test_images: {}\".format(np.shape(test_images)))\n\ntrain_images = clean_train_images\ntrain_keypoints = clean_train_keypoints\nfig, axis = plt.subplots()\nplot_sample(clean_train_images[sample_image_index], clean_train_keypoints[sample_image_index], axis, \"Sample image & keypoints\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model Building**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras as keras\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input,LeakyReLU, Conv2D,Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D,MaxPool2D\nfrom tensorflow.keras import optimizers\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom keras import applications\nfrom keras.layers import concatenate\nimport time\nfrom skimage.transform import resize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #VGG-16 with batch norm and dropout rate = 0.2\n# model = Sequential()\n# model.add(Conv2D(input_shape=(96,96,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n# model.add(Dropout(0.4))\n# model.add(BatchNormalization())\n# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n# model.add(BatchNormalization())\n# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n# model.add(GlobalAveragePooling2D())\n# model.add(BatchNormalization())\n\n# # Input dimensions: (None, 3, 3, 512)\n# model.add(Flatten())\n# model.add(Dense(512,activation='relu'))\n# model.add(Dropout(0.1))\n# model.add(Dense(30))\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n\n# model.add(Conv2D(32, (3,3), padding='same', use_bias=True, input_shape=(96,96,1),activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# # model.add(Dropout(0.1))\n\n# model.add(Conv2D(64, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(64, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(64, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n\n# model.add(Conv2D(96, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(96, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(96, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# # model.add(Dropout(0.1))\n\n# model.add(Conv2D(128, (3,3),padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(128, (3,3),padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(128, (3,3),padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n\n# model.add(Conv2D(256, (3,3),padding='same',use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(256, (3,3),padding='same',use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(256, (3,3),padding='same',use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# # model.add(Dropout(0.1))\n\n# model.add(Conv2D(512, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(512, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Conv2D(512, (3,3), padding='same', use_bias=True,activation=\"relu\"))\n# model.add(BatchNormalization())\n\n\n# model.add(Flatten())\n# model.add(Dense(512,activation='relu'))\n# model.add(Dropout(0.1))\n# model.add(Dense(30))\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BEST MODEL AS NOW \n###########################################\n# model = Sequential()\n\n# model.add(Conv2D(32, (3,3), padding='same', use_bias=True, input_shape=(96,96,1)))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(32, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(32, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# # model.add(Dropout(0.1))\n\n# model.add(Conv2D(64, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(64, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(64, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(MaxPool2D(pool_size=(2, 2)))\n\n# model.add(Conv2D(96, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(96, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(96, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# # model.add(Dropout(0.1))\n\n# model.add(Conv2D(128, (3,3),padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(128, (3,3),padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(MaxPool2D(pool_size=(2, 2)))\n\n# model.add(Conv2D(256, (3,3),padding='same',use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(256, (3,3),padding='same',use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(MaxPool2D(pool_size=(2, 2)))\n# # model.add(Dropout(0.1))\n\n# model.add(Conv2D(512, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n# model.add(Conv2D(512, (3,3), padding='same', use_bias=True))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(BatchNormalization(momentum=0.8))\n\n\n\n# model.add(Flatten())\n# model.add(Dense(512))\n# model.add(LeakyReLU(alpha=0.2))\n# model.add(Dropout(0.1))\n# model.add(Dense(30))\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (5,5), padding='same', use_bias=True, input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(32, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(32, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# model.add(Dropout(0.1))\n\nmodel.add(Conv2D(64, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(64, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(64, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(96, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(96, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(96, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# model.add(Dropout(0.1))\n\nmodel.add(Conv2D(128, (5,5),padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(128, (5,5),padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (5,5),padding='same',use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(256, (5,5),padding='same',use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# model.add(Dropout(0.1))\n\nmodel.add(Conv2D(512, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\nmodel.add(Conv2D(512, (5,5), padding='same', use_bias=True))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(BatchNormalization(momentum=0.8))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (trainX, testX, trainY, testY) = train_test_split(train_images, train_keypoints,\n# \ttest_size=0.2, random_state=42)\n# trainX.shape, testX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #pyimage source\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# aug = ImageDataGenerator(\n# \t\trotation_range=20,\n# \t\tzoom_range=0.15,\n# \t\twidth_shift_range=0.2,\n# \t\theight_shift_range=0.2,\n# \t\tshear_range=0.15,\n# \t\thorizontal_flip=True,\n# \t\tfill_mode=\"nearest\")\n\n# aug.fit(train_images)\n\n# X_batch, y_batch = aug.flow(train_images, train_keypoints, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\n\n# model = load_model('best_modelV3_1.hdf5') # Uncomment it and start the training from where you left\n\n# Define necessary callbacks\ncheckpointer = ModelCheckpoint(filepath = 'best_modelV8.hdf5', monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n# adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n\n# Compile the model\nmodel.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=['mae', 'acc'])\n\n# Train the model\nhistory = model.fit(train_images, train_keypoints, epochs=500, batch_size=256, validation_split=0.1, callbacks=[checkpointer])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #originally\n\n# from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n# from keras.optimizers import Adam\n\n# # model = load_model('best_modelV3_1.hdf5') # Uncomment it and start the training from where you left\n\n# # Define necessary callbacks\n# checkpointer = ModelCheckpoint(filepath = 'best_modelV7.hdf5', monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n# # adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n\n# # Compile the model\n# model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=['mae', 'acc'])\n\n# # Train the model\n# history = model.fit(train_images, train_keypoints, epochs=50, batch_size=256, validation_split=0.1, callbacks=[checkpointer])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    plt.plot(history.history['mae'])\n    plt.plot(history.history['val_mae'])\n    plt.title('Mean Absolute Error vs Epoch')\n    plt.ylabel('Mean Absolute Error')\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'], loc='upper right')\n    plt.show()\n    # summarize history for accuracy\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Accuracy vs Epoch')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Loss vs Epoch')\n    plt.ylabel('Loss')\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\nexcept:\n    print(\"One of the metrics used for plotting graphs is missing! See 'model.compile()'s `metrics` argument.\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\n# import h5py\nmodel.save('best_modelV5x5_V1.hdf5')  # creates a HDF5 file 'best_modelV3.hdf5'\n# del model  # deletes the existing model\n\n# # returns a compiled model\n# # identical to the previous one\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom keras.models import load_model \nmodel = load_model('best_modelV5x5_V1.hdf5')\ntest_preds = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,16))\nfor i in range(10):\n    axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n    plot_sample(test_images[i], test_preds[i], axis, \"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = list(idlookup_data['FeatureName'])\nimage_ids = list(idlookup_data['ImageId']-1)\nrow_ids = list(idlookup_data['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('charlin_version_5X5.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Augmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#pyimage source\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\naug = ImageDataGenerator(\n\t\trotation_range=20,\n\t\tzoom_range=0.15,\n\t\twidth_shift_range=0.2,\n\t\theight_shift_range=0.2,\n\t\tshear_range=0.15,\n\t\thorizontal_flip=True,\n\t\tfill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX[:,:,:,0].shape\ntrainX=np.array([trainX[:,:,:,0],trainX[:,:,:,0],trainX[:,:,:,0]])\ntrainX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX[:,:,:,0].shape\ntestX=np.array([testX[:,:,:,0],testX[:,:,:,0],testX[:,:,:,0]])\ntestX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX=np.swapaxes(trainX,0,1)\ntrainX=np.swapaxes(trainX,1,2)\ntrainX=np.swapaxes(trainX,2,3)\ntrainX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testX=np.swapaxes(testX,0,1)\ntestX=np.swapaxes(testX,1,2)\ntestX=np.swapaxes(testX,2,3)\ntestX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Resnet Version\n# from keras.layers import Input\n# img_input = Input(shape=(96,96,1))\n# img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])   \n\n\n# base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (96,96,3))\n# base_model.trainable = False\n# base_model.summary()\n\n# model=Sequential()\n# model.add(Dense(512,activation='relu',input_shape=(2048,)))\n# model.add(Dense(256,activation='relu'))\n# model.add(Dropout(0.1))\n# model.add(Dense(128,activation='relu'))\n# model.add(Dropout(0.1))\n# model.add(Dense(48,activation='relu'))\n# model.add(Dropout(0.1))\n# model.add(Dense(30))\n# model.summary()\n# model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=['mae', 'acc'])\n\n# final_model = Sequential([base_model, model])\n# final_model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=['mae', 'acc'])\n# final_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# precomputed_train = base_model.predict(trainX, batch_size=256, verbose=1)\n# precomputed_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model.fit(\n#                     x=aug.flow(precomputed_train, trainY,batch_size=256, \n#                                validation_data=[precomputed_val, testY],\n#                     steps_per_epoch=len(trainX) // 256,\n#                     epochs=10, callbacks=[checkpointer]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# precomputed_val = base_model.predict(testX,batch_size=256, verbose=1)\n# precomputed_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n# from keras.optimizers import Adam\n\n# # model = load_model('best_modelV4.hdf5') # Uncomment it and start the training from where you left\n\n# # Define necessary callbacks\n# checkpointer = ModelCheckpoint(filepath = 'best_modelV5.hdf5', monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n# # adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n\n# # Compile the model\n# model.compile(optimizer=\"adam\", loss='mean_squared_error', metrics=['mae', 'acc'])\n# # Train the model\n# history = model.fit(precomputed_train, trainY, epochs=10, batch_size=256, validation_data=(precomputed_val, testY),callbacks=[checkpointer])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model.fit(\n#                     x=aug.flow(precomputed_train, trainY,batch_size=256, \n#                                validation_data=[precomputed_val, testY],\n#                     steps_per_epoch=len(trainX) // 256,\n#                     epochs=10, callbacks=[checkpointer]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try:\n#     plt.plot(history.history['mae'])\n#     plt.plot(history.history['val_mae'])\n#     plt.title('Mean Absolute Error vs Epoch')\n#     plt.ylabel('Mean Absolute Error')\n#     plt.xlabel('Epochs')\n#     plt.legend(['train', 'validation'], loc='upper right')\n#     plt.show()\n#     # summarize history for accuracy\n#     plt.plot(history.history['acc'])\n#     plt.plot(history.history['val_acc'])\n#     plt.title('Accuracy vs Epoch')\n#     plt.ylabel('Accuracy')\n#     plt.xlabel('Epochs')\n#     plt.legend(['train', 'validation'], loc='upper left')\n#     plt.show()\n#     # summarize history for loss\n#     plt.plot(history.history['loss'])\n#     plt.plot(history.history['val_loss'])\n#     plt.title('Loss vs Epoch')\n#     plt.ylabel('Loss')\n#     plt.xlabel('Epochs')\n#     plt.legend(['train', 'validation'], loc='upper left')\n#     plt.show()\n# except:\n#     print(\"One of the metrics used for plotting graphs is missing! See 'model.compile()'s `metrics` argument.\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.models import load_model\n# # import h5py\n# model.save('best_modelV5.hdf5')  # creates a HDF5 file 'best_modelV3.hdf5'\n# # del model  # deletes the existing model\n\n# # # returns a compiled model\n# # # identical to the previous one\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# from keras.models import load_model \n# model = load_model('best_modelV5.hdf5')\n# test_preds = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = plt.figure(figsize=(20,16))\n# for i in range(10):\n#     axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n#     plot_sample(test_images[i], test_preds[i], axis, \"\")\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature_names = list(idlookup_data['FeatureName'])\n# image_ids = list(idlookup_data['ImageId']-1)\n# row_ids = list(idlookup_data['RowId'])\n\n# feature_list = []\n# for feature in feature_names:\n#     feature_list.append(feature_names.index(feature))\n    \n# predictions = []\n# for x,y in zip(image_ids, feature_list):\n#     predictions.append(test_preds[x][y])\n    \n# row_ids = pd.Series(row_ids, name = 'RowId')\n# locations = pd.Series(predictions, name = 'Location')\n# locations = locations.clip(0.0,96.0)\n# submission_result = pd.concat([row_ids,locations],axis = 1)\n# submission_result.to_csv('charlin_version2_6.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}