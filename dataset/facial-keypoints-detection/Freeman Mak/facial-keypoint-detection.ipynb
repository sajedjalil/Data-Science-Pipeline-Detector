{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Multi-Stage Heatmap Regression\n\nHello everyone! In this notebook I will be sharing with you guys what I learned in keypoint detection using neural networks. I am currently doing some research into the human pose estimation problem and thought it would be fun to use what I learned on this simple dataset.\n\nThe challenge presented with this dataset is to figure out the Cartesian (x,y) coordinates of keypoints in facial images. Some of these keypoints include: left_eye_center, right_eye_center, etc... The simplest approach with deep learning is to try and directly map image input to Cartesian coordinates output. This idea was first introduced by Toshev et al. in his scientific paper about the DeepPose network. However, people have speculated that the direct mapping from image to Cartesian coordinates is really complex and hence any model with sufficient accuracy will also be likely to overfit and not generalize well to new data.\n\nIntroduce heatmap regression, in which the problem gets slightly changed. Instead of predicting Cartesian coordinates, we will be building a deep net to predict a different heatmap for every keypoint we want to find. A heatmap is simply just a picture that shows the likelyhood of a specific keypoint residing at that pixel. Please follow along this notebook to learn more!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imports\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.losses import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 1: Loading in the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Read in data\ndf = pd.read_csv('/kaggle/input/facial-keypoints-detection/training/training.csv')\ndf.fillna(method = 'ffill',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"#Transform the data into images and plot one to see\n\nimgs = []\nfor i in range(0,7049):\n    img = df['Image'][i].split(' ')\n    img = ['0' if x == '' else x for x in img]\n    imgs.append(img)\n\n\nimage_list = np.array(imgs,dtype = 'float')\nX_train = image_list.reshape(-1,96,96,1)\nplt.imshow(X_train[0].reshape(96,96),cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Get the keypoint labels\ntraining = df.drop('Image',axis = 1)\n\ny_train = []\nfor i in range(0,7049):\n    y = training.iloc[i,:]\n\n    y_train.append(y)\ny_train = np.array(y_train,dtype = 'float')\n\n#Plot labels ontop of image\nimg = X_train[0].copy()\nfor i in range(0, len(y_train[0])-1, 2):\n    x = int(y_train[0][i])\n    y = int(y_train[0][i+1])\n    plt.scatter(x,y)\nplt.imshow(img.reshape(96,96),cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Creating the Heatmaps\n\nOkay, so like I said before, we are going to be predicting heatmaps with our model. So how do we actually get our labelled heatmap data? Turns out it is actually quite easy, we simply pass our Cartesian coordinates through a 2D gaussian kernel."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to create heatmaps by convoluting a 2D gaussian kernel over a (x,y) keypoint.\ndef gaussian(xL, yL, H, W, sigma=5):\n\n    channel = [math.exp(-((c - xL) ** 2 + (r - yL) ** 2) / (2 * sigma ** 2)) for r in range(H) for c in range(W)]\n    channel = np.array(channel, dtype=np.float32)\n    channel = np.reshape(channel, newshape=(H, W))\n\n    return channel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generate heatmaps for one sample image\nheatmaps = []\n\nfor i in range(0, 30, 2):\n    x = int(y_train[0][i])\n    y = int(y_train[0][i + 1])\n    heatmap = gaussian(x, y, 96, 96)\n    heatmaps.append(heatmap)\n    \nheatmaps = np.array(heatmaps)\n\nplt.figure(figsize=(15,15))\n\nplt.subplot(1,4,1)\nplt.imshow(heatmaps[0])\nplt.title(\"Single Heatmap\")\n\nplt.subplot(1,4,2)\nplt.imshow(heatmaps.sum(axis=0))\nplt.title(\"All Heatmaps added Together\")\n\nplt.subplot(1,4,3)\nplt.imshow(np.squeeze(X_train[0], axis=2), cmap='gray')\nplt.title(\"Input Image\")\n\nplt.subplot(1,4,4)\nfor i in range(0, len(y_train[0])-1, 2):\n    x = int(y_train[0][i])\n    y = int(y_train[0][i+1])\n    plt.scatter(x,y)\nplt.imshow(X_train[0].reshape(96,96), cmap='gray')\nplt.title(\"Image with Keypoints\")\nplt.show()\n\nheatmaps.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So according to our dataset, each input image has 15 keypoints associated with it. Therefore each image is also going to have 15 heatmaps, one heatmap for each facial keypoint. As you can see from the pictures above, the areas of the heatmap that are more yellow represent pixels that are more likely for a keypoint location to be."},{"metadata":{},"cell_type":"markdown","source":"# Step 3: Keras Custom Generator\n\nHere we are going to create a custom keras generator to yield batches of our heatmap data on-the-fly during training. Alternatively, we could create all the heatmaps before hand and then just pass them into a machine learning model, but the heatmaps take up a lot of memory and we don't really care about keeping these heatmaps after training is finished.\n\nGenerators are a very important concept to learn for other machine learning problems, when your dataset is too big to fit into memory. I am going to teach you guys how to build your own custom generator that fits into your Keras framework."},{"metadata":{},"cell_type":"markdown","source":"Most of the information I will be sharing with you guys came from this link <a href=\"https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\">here</a>. Please take a look at their explanation as it is wayyyy better than mine :p"},{"metadata":{},"cell_type":"markdown","source":"Alright, so first of all we are going to be creating a new Python class that inherits from **keras.utilities.Sequence**, which gives us nice functionality like multiprocessing.\n\nTo make a generator that inherits the **keras.utilities.Sequence** class we need to create the following methods:\n- ```__init__()```: this is your basic initialization method.\n- ```on_epoch_end()```: this method is triggered every time your generator runs through one epoch of your data. Typically you would want to shuffle your dataset using this method.\n- ```__data_generation()```: this is the method that actually does the data processing. In here you will create your batch of data.\n- ```__len__()```: this method is used to tell the generator how many batches of data would be needed to complete one full epoch, it returns a number between 0 and the total number of batches. This number is passed into your other methods, typically called index.\n- ```__get_item__()```: this method is the one that actually returns your batch of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    \n    def __init__(self, imgs, kps, batch_size=32, shuffle=True):\n        self.imgs = imgs\n        self.kps = kps\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        return len(self.imgs) // self.batch_size\n\n    def __getitem__(self, index):\n        #Get index of images to generate\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        \n        # Generate data\n        X, y = self.__data_generation(indexes)\n\n        return X, y\n\n    def on_epoch_end(self):\n        #Shuffle the data after the generator has run through all samples\n        self.indexes = np.arange(len(self.imgs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n            \n    def gaussian(self, xL, yL, H, W, sigma=5):\n        ##Function that creates the heatmaps##\n        channel = [math.exp(-((c - xL) ** 2 + (r - yL) ** 2) / (2 * sigma ** 2)) for r in range(H) for c in range(W)]\n        channel = np.array(channel, dtype=np.float32)\n        channel = np.reshape(channel, newshape=(H, W))\n\n        return channel\n\n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples'\n        X_batch = [self.imgs[i] for i in indexes]\n        X_batch = np.array(X_batch)\n        \n        y_batch = []\n        \n        kps = [self.kps[i] for i in indexes]\n        \n        for i in range(0,len(kps)):\n            heatmaps = []\n            for j in range(0, 15):\n                x = int(kps[i][j*2])\n                y = int(kps[i][j*2+1])\n                heatmap = self.gaussian(x, y, 96, 96)\n                heatmaps.append(heatmap)\n            y_batch.append(heatmaps)\n                \n        y_batch = np.array(y_batch)\n        y_batch = np.swapaxes(y_batch,1,3)\n        y_batch = np.swapaxes(y_batch,1,2)\n        return X_batch, [y_batch, y_batch]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testing to see if our DataGenerator is working\nX_batch, [y_batch, _] = next(DataGenerator(X_train, y_train).__iter__())\nprint(X_batch.shape)\nprint(y_batch.shape)\n\n#Plot a single image overlayed with its heatmaps\nplt.imshow(X_batch[0].reshape(96,96), cmap='gray', alpha=0.5)\nplt.imshow(y_batch[0].sum(axis=2), alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you made it this far, you might have noticed that my DataGenerator actually yields two sets of y_batch. This was done on purpose because we are going to be using a two-stage heatmap regression approach, with intermediate training. I got this idea from the <a href=\"https://arxiv.org/pdf/1602.00134.pdf\">Convolutional Pose Machines paper</a>. This concept is similar to traditional boosting algorithms in which the main idea is to learn from the mistakes of the first output. Basically, every stage is going to predict a heatmap and the next stage will use the previous stage's heatmap prediction along with the input image to create a new, more accurate prediction.\n\nOne thing we need to clarify is **intermediate training**. The more stages you make the model, the more layers it is going to have, hence your model might run into the Vanishing Gradient Problem. To combat this, we will be using intermediate training in which the total loss of the model is the summation of each individual stage's loss.\n\nHere is a high level picture of how the multi-stage model works:\n![](https://i.imgur.com/xbtp8tC.png)"},{"metadata":{},"cell_type":"markdown","source":"# Step 4: Creating the Model\n\nIn this step we are actually going to make our model. It is a traditional fully convolutional network which I added two stages and trained using intermediate training."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Helper function for building model\ndef conv_block(x, nconvs, n_filters, block_name, wd=None):\n    for i in range(nconvs):\n        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n                   kernel_regularizer=wd, name=block_name + \"_conv\" + str(i + 1))(x)\n    x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', name=block_name + \"_pool\")(x)\n    return x\n  \n#Represents one stage of the model\ndef stages(x, stage_num, num_keypoints = 15):\n  \n    #Block 1\n    x = conv_block(x, nconvs=2, n_filters=64, block_name=\"block1_stage{}\".format(stage_num))\n  \n    #Block 2\n    x = conv_block(x, nconvs=2, n_filters=128, block_name=\"block2_stage{}\".format(stage_num))\n  \n    #Block 3\n    pool3 = conv_block(x, nconvs=3, n_filters=256, block_name=\"block3_stage{}\".format(stage_num))\n  \n    #Block 4\n    pool4 = conv_block(pool3, nconvs=3, n_filters=512, block_name=\"block4_stage{}\".format(stage_num))\n  \n    #Block 5\n    x = conv_block(pool4, nconvs=3, n_filters=512, block_name=\"block5_stage{}\".format(stage_num))\n  \n    #Convolution 6\n    x = Conv2D(4096, kernel_size=(1, 1), strides=1, padding=\"same\", activation=\"relu\", name=\"conv6_stage{}\".format(stage_num))(x)\n  \n    #Convolution 7\n    x = Conv2D(15, kernel_size=(1, 1), strides=1, padding=\"same\", activation=\"relu\", name=\"conv7_stage{}\".format(stage_num))(x)\n\n    #upsampling\n    preds_pool3 = Conv2D(15, kernel_size=(1, 1), strides=1, padding=\"same\", name=\"preds_pool3_stage{}\".format(stage_num))(pool3)\n    preds_pool4 = Conv2D(15, kernel_size=(1, 1), strides=1, padding=\"same\", name=\"preds_pool4_stage{}\".format(stage_num))(pool4)\n    up_pool4 = Conv2DTranspose(filters=15, kernel_size=2, strides=2, activation='relu', name=\"ConvT_pool4_stage{}\".format(stage_num))(preds_pool4)\n    up_conv7 = Conv2DTranspose(filters=15, kernel_size=4, strides=4, activation='relu', name=\"ConvT_conv7_stage{}\".format(stage_num))(x)\n  \n    fusion = Add()([preds_pool3, up_pool4, up_conv7])\n  \n    heatmaps = Conv2DTranspose(filters=15, kernel_size=8, strides=8, activation='relu', name=\"convT_fusion_stage{}\".format(stage_num))(fusion)\n    heatmaps = Conv2D(num_keypoints, kernel_size=(1, 1), strides=1, padding=\"same\", activation=\"linear\", name=\"output_stage{}\".format(stage_num))(heatmaps)\n    return heatmaps\n  \n#Create a single stage FCN\ndef build_model(input_shape):\n    outputs = []\n  \n    img = Input(shape=input_shape, name=\"Input_stage\")\n  \n    ### Stage 1 ###\n    heatmaps1 = stages(img, 1)\n    outputs.append(heatmaps1)\n  \n    ### Stage 2 ###\n    x = Concatenate()([img, heatmaps1])\n    heatmaps2 = stages(x, 2)\n    outputs.append(heatmaps2)\n  \n    model = Model(inputs=img, outputs=outputs, name=\"FCN_Final\")\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the model using mean squared losss\ndef get_loss_func():\n    def mse(x, y):\n        return mean_squared_error(x,y)\n  \n    keys = ['output_stage1', 'output_stage2']\n    losses = dict.fromkeys(keys, mse)\n    return losses\n\nmodel = build_model((96,96,1))\nlosses = get_loss_func()\nmodel.compile(loss = losses, optimizer = 'adam')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 5: Training the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#First, lets split the data into training and validation\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=2019)\n\n#Create your two generators for train and validation\ngen_train = DataGenerator(X_train, y_train)\ngen_val = DataGenerator(X_val, y_val)\n\n#Train the model\nmodel.fit_generator(generator = gen_train,\n                    epochs = 10,\n                    validation_data = gen_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_batch, [y_batch, _] = next(gen_val.__iter__())\n\nindex = np.random.randint(0,32)\n\npredictions = model.predict(X_batch)\n\nplt.figure(figsize=(15,15))\nplt.subplot(1,4,1)\nplt.imshow(y_batch[index].sum(axis=2))\nplt.title(\"Ground Truth Heatmap\")\n\nplt.subplot(1,4,2)\nplt.imshow(predictions[0][index].sum(axis=2))\nplt.title(\"Stage 1 Prediction\")\n\nplt.subplot(1,4,3)\nplt.imshow(predictions[1][index].sum(axis=2))\nplt.title(\"Stage 2 Prediction\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So as you can see our second stage looks a lot better than our first stage!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}