{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the libraries\nimport pandas as pd\nimport numpy as np\n\n#visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import machine learning models\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/data-science-london-scikit-learn/train.csv',header=None)\ntest=pd.read_csv('../input/data-science-london-scikit-learn/test.csv',header=None)\ntrainLabel=pd.read_csv('../input/data-science-london-scikit-learn/trainLabels.csv',header=None,names=['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train shape:', train.shape)\nprint('test shape:', test.shape)\nprint('trainLabel shape:', trainLabel.shape)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y=train,np.ravel(trainLabel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val=train_test_split(X,y,random_state=100,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']\nweights=['uniform','distance']\nneig=range(1,20)\ntrain_accuracy=[]\nval_accuracy=[]\nbest_score=0.0\nbest_knn=None\n\nfor k in neig:\n    KNN=KNeighborsClassifier(n_neighbors=k,algorithm='auto',weights='uniform')\n    KNN.fit(X_train,y_train)\n    y_pred=KNN.predict(X_val)\n    train_score=KNN.score(X_train,y_train)\n    val_score=accuracy_score(y_val,y_pred)\n    # we can append accuracy in lists\n    train_accuracy.append(train_score)\n    val_accuracy.append(val_score)\n    \n    #we can save best accurcy in best_score\n    if val_score > best_score :\n        best_score=val_score\n        best_knn=KNN\n\n#we can plot the graph to show number of neighbors with accuracy\nplt.figure(figsize=(10,10))\nplt.plot(neig,train_accuracy,c='blue',label='train accuracy')\nplt.plot(neig,val_accuracy,c='red',label='val accuracy')\nplt.legend()\nplt.title('number of neighbors with accuracy')\nplt.xlabel('n _neighbors')\nplt.ylabel('Accuracy')\n\nprint('train score : ',best_knn.score(X_train,y_train))\nprint('val score : ',best_score)\nprint(best_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RandomForesClassifiertModel=RandomForestClassifier(random_state=100)\nestimator=[20,50,70,100]\nmax_depth=[20,30,40,60]\nsplit=[5,10,15]\nparam=dict(n_estimators=estimator,max_depth=max_depth,min_samples_split=split)\nRandomForestCV=GridSearchCV(estimator=RandomForesClassifiertModel,param_grid=param,cv=6,n_jobs=-1)\nRandomForestCV.fit(X_train,y_train)\ny_pred=RandomForestCV.predict(X_val)\nprint(RandomForestCV.best_params_)\nprint('score train : ',RandomForestCV.score(X_train,y_train))\nprint('score test  : ',accuracy_score(y_pred,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel = ['linear','poly','rbf','sigmoid','precomputed']\nSVCModel=SVC(kernel='rbf',max_iter=1000,C=0.1)\nSVCModel.fit(X_train,y_train)\ny_pred=SVCModel.predict(X_val)\nprint('score train : ',SVCModel.score(X_train,y_train))\nprint('score test  : ',accuracy_score(y_val,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" we can applay GAUSSIAN MIXTURE MODEL "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('X shape :',X.shape)\nprint('\\n')\n\n# USING THE GAUSSIAN MIXTURE MODEL \n\n#The Bayesian information criterion (BIC) can be used to select the number of components in a Gaussian Mixture in an efficient way. \n#In theory, it recovers the true number of components only in the asymptotic regime\n# aic and bic The lower the better.\n\nlowest_bic = np.infty\nbic = []\n\n#The GaussianMixture comes with different options to constrain the covariance of the difference classes estimated: \n# spherical, diagonal, tied or full covariance.\n\ncv_types = ['spherical', 'tied', 'diag', 'full']\nfor cv_type in cv_types:\n    for n_components in range(1,7):\n        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n        gmm.fit(X)\n        bic.append(gmm.aic(X))\n        if bic[-1] < lowest_bic:\n            lowest_bic=bic[-1]\n            best_gmm=gmm\n                    \nbest_gmm.fit(X)\ngmm_train = best_gmm.predict_proba(X_train)\ngmm_val = best_gmm.predict_proba(X_val)\ngmm_test=best_gmm.predict_proba(test)\nbest_gmm\nprint(gmm.aic(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"gmm_test\",gmm_val.shape)\nprint(\"gmm_train\",gmm_train.shape)\nprint(\"X_train\",X_train.shape)\nprint(\"x_val\",X_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# now we can apply Support Vector Classifier Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel = ['linear','poly','rbf','sigmoid','precomputed']\nSVCModel=SVC(kernel='rbf',max_iter=1000,C=0.1)\nSVCModel.fit(gmm_train,y_train)\ny_pred=SVCModel.predict(gmm_val)\nprint('score train : ',SVCModel.score(gmm_train,y_train))\nprint('score test  : ',accuracy_score(y_pred,y_val))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# let's go to apply KNeighborsClassifier Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']\nweights=['uniform','distance']\nneig=range(1,20)\ntrain_accuracy=[]\nval_accuracy=[]\nbest_score=0.0\nbest_knn=None\n\nfor k in neig:\n    KNN=KNeighborsClassifier(n_neighbors=k,algorithm='auto',weights='uniform')\n    KNN.fit(gmm_train,y_train)\n    y_pred=KNN.predict(gmm_val)\n    train_score=KNN.score(gmm_train,y_train)\n    val_score=accuracy_score(y_val,y_pred)\n    # we can append accuracy in lists\n    train_accuracy.append(train_score)\n    val_accuracy.append(val_score)\n    \n    #we can save best accurcy in best_score\n    if val_score > best_score :\n        best_score=val_score\n        best_knn=KNN\n\n#we can plot the graph to show number of neighbors with accuracy\nplt.figure(figsize=(10,10))\nplt.plot(neig,train_accuracy,c='blue',label='train accuracy')\nplt.plot(neig,val_accuracy,c='red',label='val accuracy')\nplt.legend()\nplt.title('number of neighbors with accuracy')\nplt.xlabel('n _neighbors')\nplt.ylabel('Accuracy')\n\nprint('train score : ',best_knn.score(gmm_train,y_train))\nprint('val score : ',accuracy_score(y_pred,y_val))\n\n\nprint(best_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we can apply Random Forest Classifier Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"RandomForesClassifiertModel=RandomForestClassifier(random_state=100)\nestimator=[20,50,70,100]\nmax_depth=[20,30,40,60]\nsplit=[5,10,15]\nparam=dict(n_estimators=estimator,max_depth=max_depth,min_samples_split=split)\nRandomForestCV=GridSearchCV(estimator=RandomForesClassifiertModel,param_grid=param,cv=6,n_jobs=-1)\nRandomForestCV.fit(gmm_train,y_train)\ny_pred=RandomForestCV.predict(gmm_val)\nprint(RandomForestCV.best_params_)\nprint('score train : ',RandomForestCV.score(gmm_train,y_train))\nprint('score test  : ',accuracy_score(y_pred,y_val))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}