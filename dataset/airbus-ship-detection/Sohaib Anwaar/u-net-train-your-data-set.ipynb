{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom __future__ import print_function\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom PIL import Image\nimport tensorflow as tf\nimport os\nimport sys\nimport random\nimport numpy as np\n  \nimport numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\nfrom keras import backend as keras  \n\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy as np \nimport os\nimport glob\nimport skimage.io as io\nimport skimage.transform as trans\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.transform import resize\nfrom skimage.io import imread, imshow\n\n\n# Any results you write to the current directory are saved as output.\nimport os\nos.listdir(\"/kaggle/input/airbus-ship-detection/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing\n\n**Experimentation with nan or without nan**\n\nFirst Lets try to ignore Nan values and see what are the results. than we will include nan values and than see the results\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n\nbase_path=\"/kaggle/input/airbus-ship-detection/\"\nimages_path=\"/kaggle/input/airbus-ship-detection/train_v2/\"\ndf=pd.read_csv(base_path+\"train_ship_segmentations_v2.csv\")\n\n\n\nprint(\"Total Images\", len(df))\nprint(\"Images without masks\",df.EncodedPixels.isnull().sum())\nprint(\"Images with mask\" , len(df)-df.EncodedPixels.isnull().sum())\n# x_train=X\ndf=df.dropna()\nprint(\"Total Images after droping nans\", len(df))\n\n# Adding full path of images to pandas dataFrame\ndf.ImageId=df.ImageId.apply(lambda x:images_path+x )\n\ndf.head()\n# y_train=Y\n\nprint(\"splitting_dataframe into test train\")\n\n\ntrain_set = df.sample(frac=0.99, random_state=0)\ntest_set = df.drop(train_set.index)\n\n\nprint(\"Training DataFrame length \", len(train_set))\nprint(\"Testing DataFrame length \",len(test_set) )\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def adjustData(img,mask):\n    \n    if(np.max(img) > 1):\n        img = img / 255\n        mask = mask /255\n        mask[mask > 0.5] = 1\n        mask[mask <= 0.5] = 0\n        \n    return (img,mask)\n\n\n\ndef trainGenerator(df,num_class = 2,target_size = (768,768),batch_size=2):\n    IMG_HEIGHT, IMG_WIDTH=target_size\n    img_list=[]\n    mask_list=[]\n    while(1):\n        #     for n, id_ in tqdm(enumerate(image_ids), total=len(image_ids)):\n        for i in range (len(df)):  \n            img = imread(df['ImageId'].iloc[i], as_gray=True)\n\n\n            img = img / 255\n            img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n\n            mask=masks_as_image(df.query('ImageId==\"'+df['ImageId'].iloc[i]+'\"')['EncodedPixels'])\n\n\n            img,mask = adjustData(img,mask)\n\n\n            img_list.append(img.reshape(768,768,1))\n            mask_list.append(mask.reshape(768,768,1))\n\n\n            if i%batch_size==0 and i >=batch_size:\n                yield (np.asarray(img_list),np.asarray(mask_list))\n                del img_list,mask_list\n                img_list=[]\n                mask_list=[]\n    \n\n\n\n\n\ndef testGenerator(df,target_size = (768,768),flag_multi_class = False,as_gray = True):\n    IMG_HEIGHT, IMG_WIDTH=target_size\n    for i in range (len(df)): \n        img = imread(df['ImageId'].iloc[i], as_gray=True)\n        img = img / 255\n        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n        img = np.reshape(img,(1,)+img.shape)\n        yield img\n\n\n\n\ndef labelVisualize(num_class,color_dict,img):\n    img = img[:,:,0] if len(img.shape) == 3 else img\n    img_out = np.zeros(img.shape + (3,))\n    for i in range(num_class):\n        img_out[img == i,:] = color_dict[i]\n    return img_out / 255\n\n\n\ndef saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n    for i,item in enumerate(npyfile):\n        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n        \n        \ndef multi_rle_encode(img):\n    labels = label(img[:, :, 0])\n    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape) # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list, all_masks=None):\n    # Take the individual ship masks and create a single mask array for all ships\n    if all_masks is None:\n        all_masks = np.zeros((768, 768), dtype = np.int16)\n    #if isinstance(in_mask_list, list):\n    \n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            \n            all_masks += rle_decode(mask)\n        \n    return all_masks.T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass_colors = [(random.randint(0, 255), random.randint(\n    0, 255), random.randint(0, 255)) for _ in range(5000)]\ndef _get_colored_segmentation_image(img, seg, colors, n_classes):\n    \"\"\" Return a colored segmented image \"\"\"\n    seg_img = np.zeros_like(seg)\n\n\n    for c in range(n_classes):\n        seg_img[:, :, 0] += ((seg[:, :, 0] == c) *\n                            (colors[c][0])).astype('uint8')\n\n\n    return img , seg_img\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom skimage.measure import find_contours\nfrom matplotlib.patches import Polygon\nimport cv2\n\nbatch_size=6\ntrain_gen=iter(trainGenerator(train_set,num_class = 2,target_size = (768,768),batch_size=batch_size))\ncolor =1# random_colors(2)\nfor i in range(batch_size):\n    X,Y=next(train_gen)\n\n        \n    img , seg_img = _get_colored_segmentation_image(X[i],Y[i], class_colors, n_classes=1)\n    fig, ax = plt.subplots(1,2)\n    \n    ax[0].imshow(img.reshape(768,768))\n    ax[1].imshow(seg_img.reshape(768,768))\n    \n    plt.show()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smooth = 1.\n\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unet(pretrained_weights = None,input_size = (768,768,1)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\n    model = Model(input = inputs, output = conv10)\n\n    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics=[dice_coef])\n    \n    #model.summary()\n\n    if(pretrained_weights):\n    \tmodel.load_weights(pretrained_weights)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch=10\nbatch_size=6\n\n \n\n\ntest=trainGenerator(test_set,batch_size)\ntrain=trainGenerator(train_set,batch_size)\nmodel = unet(\"/kaggle/input/unet-weights-airbus/unet_membrane.hdf5\")\nmodel_checkpoint = ModelCheckpoint('unet_membrane_{epoch:02d}_{val_dice_coef:.2f}.hdf5', monitor='val_dice_coef',verbose=1, save_best_only=False, mode='max')\nES=EarlyStopping(monitor='val_dice_coef', min_delta=0, patience=10, verbose=1, mode='max', baseline=None, restore_best_weights=False)\nH=model.fit_generator(train,steps_per_epoch=100,\n\tvalidation_data=test,\n\tvalidation_steps=100,\n\tepochs=epoch,callbacks=[model_checkpoint,ES])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = epoch\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"dice_coef\"], label=\"train_dice_coef\")\nplt.plot(np.arange(0, N), H.history[\"val_dice_coef\"], label=\"val_dice_coef\")\nplt.title(\"Training Loss and Accuracy on Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visuzlization of Images and masks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = unet(\"/kaggle/input/unet-weights-airbus/unet_membrane.hdf5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimg_list=[]\nbatch_size=4\n\nX,Y=next(train_gen,batch_size)\n\n\n\n\n\npredict = model.predict(X, verbose=1)\n \n\nfor i in range(batch_size): \n    imshow(np.squeeze(predict[i]))\n\n    plt.show()\n\n    imshow(X[i].reshape(768,768))\n    plt.show()\n    imshow(Y[i].reshape(768,768))\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X=Image.fromarray(X[0])\n# print(X.shape)\n    \n\n\npredict = model.predict(X, verbose=1)\n \npredict = (predict > 0.5).astype(np.uint8)\n \nimshow(np.squeeze(predict[5]*255))\n\nplt.show()\n \nimshow(X[1].reshape(768,768))\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nEncoded_points=[]\nimgs=[]\npath=\"/kaggle/input/airbus-ship-detection/test_v2/\"\ncount=0\nfor i in os.listdir(path):\n    if count==5:\n        break\n    img = cv2.imread(path+i,0)\n    img = resize(img, (768,768), mode='constant', preserve_range=True)\n    x=np.array(img)\n    x=np.expand_dims(np.expand_dims(x, axis=0),axis=3)\n    print(x.shape)\n    predict = model.predict(x)\n    predict = (predict > 0.5).astype(np.uint8)\n    Encoded_points.append(np.squeeze(predict[0]))\n    imgs.append(i)\n    count=count+1\n    \ndf=pd.DataFrame()\ndf[\"ImageId\"]=imgs\ndf[\"EncodedPixels\"]=Encoded_points\n\n                        \ndf.to_csv(\"results.csv\")\ndf.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}