{"cells":[{"metadata":{"_uuid":"dcf5bc54c11a087f99243942448980cb77109b63"},"cell_type":"markdown","source":"# Manual Model Manipulation Trick\n# credits to Chris (https://www.kaggle.com/cdeotte/private-leaderboard-0-703), please upvote his kernel\nIn this kernel, we load my final submission file, view it's malware infection rate over time, and modify it manually to match what train.csv's malware rate looks like over time. The original submission file scores Public LB 0.700 and Private LB 0.646. After correction, the updated file scores Public LB 0.704 and Private LB 0.763.  \n  \nChris used this trick during the competition to increase Public LB score. But it wasn't until after the competition's end that Chris learned how to increase Private LB score."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# IMPORT LIBRARIES\nimport pandas as pd, numpy as np, os, gc\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom datetime import timedelta\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5021206270bb2db3b14248001eefed0944acf24"},"cell_type":"markdown","source":"# Load files and time stamps\nLoad submission and attach time stamps."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dtypes = {}\ndtypes['MachineIdentifier'] = 'str'\ndtypes['AvSigVersion'] = 'category'\ndtypes['HasDetections'] = 'int8'\n\n# LOAD TRAIN DATA\ndf_train = pd.read_csv('../input/microsoft-malware-prediction/train.csv', usecols=list(dtypes.keys()), dtype=dtypes)\nprint ('Loaded',len(df_train),'rows of train.CSV!')\n\n# LOAD TEST DATA\ndf_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv', usecols=list(dtypes.keys())[0:-1], dtype=dtypes)\nprint ('Loaded',len(df_test),'rows of test.CSV!')\n\n# LOAD PREDICTIONS FROM PUBLIC KERNEL\n# https://www.kaggle.com/hung96ad/new-blend\ndf_test2 = pd.read_csv('../input/malware-detection-stacking-2-0/submission_kfold.csv')\nprint ('Loaded',len(df_test),'rows of submission_kfold.csv!')\n\n# ADD TIMESTAMPS\ndatedictAS = np.load('../input/malware-timestamps/AvSigVersionTimestamps.npy')[()]\ndf_test['Date'] = df_test['AvSigVersion'].map(datedictAS)\ndf_train['Date'] = df_train['AvSigVersion'].map(datedictAS)\ndf_test2 = pd.merge(df_test2, df_test, on='MachineIdentifier', how='left')\ndf_test2['AvSigVersion2'] = df_test2['AvSigVersion'].map(lambda x: np.int(x.split('.')[1]) )","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"04d37580fa7bf43b8736036b11b53817554c35ee"},"cell_type":"code","source":"import calendar, math\n\ndef staticPlot(data, col, target='HasDetections', bars=10, show=1.0, sortby='frequency'\n               , verbose=1, top=5, title='',asc=False, dropna=False, minn=0.0):\n    # calcuate density and detection rate\n    cv = data[col].value_counts(dropna=dropna)\n    cvd = cv.to_dict()\n    nm = cv.index.values; lnn = len(nm); lnn2 = lnn\n    th = show * len(data)\n    th2 = minn * len(data)\n    sum = 0; lnn2 = 0\n    for x in nm[0:bars]:\n        lnn2 += 1\n        try: sum += cvd[x]\n        except: sum += cv[x]\n        if sum>th:\n            break\n        try:\n            if cvd[x]<th2: break\n        except:\n            if cv[x]<th2: break\n    if lnn2<bars: bars = lnn2\n    pct = round(100.0*sum/len(data),2)\n    lnn = min(lnn,lnn2)\n    ratio = [0.0]*lnn; lnn3 = lnn\n    if sortby =='frequency': lnn3 = min(lnn3,bars)\n    elif sortby=='category': lnn3 = 0\n    for i in range(lnn3):\n        if target not in data:\n            ratio[i] = np.nan\n        elif nan_check(nm[i]):\n            ratio[i] = data[target][data[col].isna()].mean()\n        else:\n            ratio[i] = data[target][data[col]==nm[i]].mean()\n    try: all = pd.DataFrame( {'category':nm[0:lnn],'frequency':[cvd[x] for x in nm[0:lnn]],'rate':ratio} )\n    except: all = pd.DataFrame( {'category':nm[0:lnn],'frequency':[cv[x] for x in nm[0:lnn]],'rate':ratio} )\n    if sortby=='rate': \n        all = all.sort_values(sortby, ascending=asc)\n    elif sortby=='category':\n        try: \n            all['temp'] = all['category'].astype('float')\n            all = all.sort_values('temp', ascending=asc)\n        except:\n            all = all.sort_values('category', ascending=asc)\n    if bars<lnn: all = all[0:bars]\n    if verbose==1 and target in data:\n        print('TRAIN.CSV variable',col,'has',len(nm),'categories')\n        print('The',min(bars,lnn),'bars displayed here contain',pct,'% of data.')\n        mlnn = data[col].isna().sum()\n        print(\"The data has %.1f %% NA. The plot is sorted by \" % (100.0*mlnn/len(data)) + sortby )\n    \n    # plot density and detection rate\n    fig = plt.figure(1,figsize=(15,3))\n    ax1 = fig.add_subplot(1,1,1)\n    clrs = ['red', 'green', 'blue', 'yellow', 'magenta']\n    barss = ax1.bar([str(x) for x in all['category']],[x/float(len(data)) for x in all['frequency']],color=clrs)\n    for i in range(len(all)-top):\n        barss[top+i].set_color('cyan')\n    if target in data:\n        ax2 = ax1.twinx()\n        if sortby!='category': infected = all['rate'][0:lnn]\n        else:\n            infected=[]\n            for x in all['category']:\n                if nan_check(x): infected.append( data[ data[col].isna() ][target].mean() )\n                elif cvd[x]!=0: infected.append( data[ data[col]==x ][target].mean() )\n                else: infected.append(-1)\n        ax2.plot([str(x) for x in all['category']],infected[0:lnn],'k:o')\n        #ax2.set_ylim(a,b)\n        ax2.spines['left'].set_color('red')\n        ax2.set_ylabel('Detection Rate', color='k')\n    ax1.spines['left'].set_color('red')\n    ax1.yaxis.label.set_color('red')\n    ax1.tick_params(axis='y', colors='red')\n    ax1.set_ylabel('Category Proportion', color='r')\n    if title!='': plt.title(title)\n    plt.show()\n    if verbose==1 and target not in data:\n        print('TEST.CSV variable',col,'has',len(nm),'categories')\n        print('The',min(bars,lnn),'bars displayed here contain',pct,'% of the data.')\n        mlnn = data[col].isna().sum()\n        print(\"The data has %.1f %% NA. The plot is sorted by \" % (100.0*mlnn/len(data)) + sortby )\n\ndef dynamicPlot(data,col, target='HasDetections', start=datetime(2018,4,1), end=datetime(2018,12,1)\n                ,inc_hr=0,inc_dy=7,inc_mn=0,show=0.99,top=5,top2=4,title='',legend=1,z=0,dots=False):\n    # check for timestamps\n    if 'Date' not in data:\n        print('Error dynamicPlot: DataFrame needs column Date of datetimes')\n        return\n    \n    # remove detection line if category density is too small\n    cv = data[(data['Date']>start) & (data['Date']<end)][col].value_counts(dropna=False)\n    cvd = cv.to_dict()\n    nm = cv.index.values\n    th = show * len(data)\n    sum = 0; lnn2 = 0\n    for x in nm:\n        lnn2 += 1\n        sum += cvd[x]\n        if sum>th:\n            break\n    top = min(top,len(nm))\n    top2 = min(top2,len(nm),lnn2,top)\n\n    # calculate rate within each time interval\n    diff = (end-start).days*24*3600 + (end-start).seconds\n    size = diff//(3600*((inc_mn * 28 + inc_dy) * 24 + inc_hr)) + 5\n    data_counts = np.zeros([size,2*top+1],dtype=float)\n    idx=0; idx2 = {}\n    for i in range(top):\n        idx2[nm[i]] = i+1\n    low = start\n    high = add_time(start,inc_mn,inc_dy,inc_hr)\n    data_times = [low+(high-low)/2]\n    while low<end:\n        slice = data[ (data['Date']<high) & (data['Date']>=low) ]\n        #data_counts[idx,0] = len(slice)\n        data_counts[idx,0] = 5000*len(slice['AvSigVersion'].unique())\n        for key in idx2:\n            if nan_check(key): slice2 = slice[slice[col].isna()]\n            else: slice2 = slice[slice[col]==key]\n            data_counts[idx,idx2[key]] = len(slice2)\n            if target in data:\n                data_counts[idx,top+idx2[key]] = slice2['HasDetections'].mean()\n        low = high\n        high = add_time(high,inc_mn,inc_dy,inc_hr)\n        data_times.append(low+(high-low)/2)\n        idx += 1\n\n    # plot lines\n    fig = plt.figure(1,figsize=(15,3))\n    cl = ['r','g','b','y','m']\n    ax3 = fig.add_subplot(1,1,1)\n    lines = []; labels = []\n    if z==1: ax3.plot(data_times,data_counts[0:idx+1,0],'k')\n    for i in range(top):\n        tmp, = ax3.plot(data_times,data_counts[0:idx+1,i+1],cl[i%5])\n        if dots: ax3.plot(data_times,data_counts[0:idx+1,i+1],cl[i%5]+'o')\n        lines.append(tmp)\n        labels.append(str(nm[i]))\n    ax3.spines['left'].set_color('red')\n    ax3.yaxis.label.set_color('red')\n    ax3.tick_params(axis='y', colors='red')\n    if col!='ones': ax3.set_ylabel('Category Density', color='r')\n    else: ax3.set_ylabel('Data Density', color='r')\n    #ax3.set_yticklabels([])\n    if target in data:\n        ax4 = ax3.twinx()\n        for i in range(top2):\n            ax4.plot(data_times,data_counts[0:idx+1,i+1+top],cl[i%5]+\":\")\n            if dots: ax4.plot(data_times,data_counts[0:idx+1,i+1+top],cl[i%5]+\"o\")\n        ax4.spines['left'].set_color('red')\n        ax4.set_ylabel('Detection Rate', color='k')\n    if title!='': plt.title(title)\n    if legend==1: plt.legend(lines,labels,loc=2)\n    plt.show()\n        \n# INCREMENT A DATETIME\ndef add_time(sdate,months=0,days=0,hours=0):\n    month = sdate.month -1 + months\n    year = sdate.year + month // 12\n    month = month % 12 + 1\n    day = sdate.day + days\n    if day>calendar.monthrange(year,month)[1]:\n        day -= calendar.monthrange(year,month)[1]\n        month += 1\n        if month>12:\n            month = 1\n            year += 1\n    hour = sdate.hour + hours\n    if hour>23:\n        hour = 0\n        day += 1\n        if day>calendar.monthrange(year,month)[1]:\n            day -= calendar.monthrange(year,month)[1]\n            month += 1\n            if month>12:\n                month = 1\n                year += 1\n    return datetime(year,month,day,hour,sdate.minute)\n\n# CHECK FOR NAN\ndef nan_check(x):\n    if isinstance(x,float):\n        if math.isnan(x):\n            return True\n    return False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49f3c9a8b8944667b3450f7b2acdcfdca14474a9"},"cell_type":"markdown","source":"# First, view train's malware probabilities\nWe notice that computers with AvSigVersion dates outside the window of sampling have lower malware probabilities. In the plot below, the dotted line uses the right y-axis and solid line uses left y-axis."},{"metadata":{"trusted":true,"_uuid":"c27662545a3fbc01f5b305a386b79e56387e4348"},"cell_type":"code","source":"df_train['ones'] = 1\ndynamicPlot(df_train,'ones',title='Training data. (Dotted line uses right y-axis. Solid uses left.)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"896e6bf4f2b9f921d0c4dbe96c3e277e92ee2fc8"},"cell_type":"markdown","source":"# Second, view original submission's malware probabilities\nWe notice that the probabilities before and after the sampling window should be lower. So we will correct them."},{"metadata":{"trusted":true,"_uuid":"ee0c84ab8ea78de4cd2de298ce7090263d104426"},"cell_type":"code","source":"df_test2['ones'] = 1\ndynamicPlot(df_test2,'ones',title='Original submission')\ndynamicPlot(df_test2,'AvSigVersion2',start=datetime(2018,9,1),end=datetime(2018,11,29),inc_dy=1,top2=4, dots=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0bc649f9b50f5c63e9bfeef64145543bea1f9c9"},"cell_type":"markdown","source":"# Third, adjust probabilities before and after sampling window\nWe will lower probabilities before September 26, 2018 and after November 21, 2018."},{"metadata":{"trusted":true,"_uuid":"bf02cc18425cc9556f93f07192c90ee35d0a56a3"},"cell_type":"code","source":"df_test2.loc[ (df_test2['AvSigVersion2']==275)|(df_test2['AvSigVersion2']==273),'HasDetections'] *= 0.8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df29b073ab5c258b1149746a72c2eadb0ffa2a94"},"cell_type":"code","source":"dynamicPlot(df_test2,'ones',title='Adjustment 1')\ndynamicPlot(df_test2,'AvSigVersion2',start=datetime(2018,9,1),end=datetime(2018,11,29),inc_dy=1,top2=4, dots=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12e59f1943ee4a0de8e167cbe0f2b76fb484a91f"},"cell_type":"code","source":"df_test2.loc[ df_test2['Date']>datetime(2018,11,21,0,0) ,'HasDetections'] *= 0.4\ndf_test2.loc[ df_test2['Date']>datetime(2018,11,24,0,0) ,'HasDetections'] *= 0.4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86b3688ddf083ca30675ec674c53dea7d0c3186e"},"cell_type":"code","source":"dynamicPlot(df_test2,'ones',title='Adjustment 2')\ndynamicPlot(df_test2,'AvSigVersion2',start=datetime(2018,9,1),end=datetime(2018,11,29),inc_dy=1,top2=4,\n            dots=True, title='adjustment 2')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52835cc4f3117bf5f88791c264ff6a062295214b"},"cell_type":"markdown","source":"# Submit updated submission file\nThe original submission file had Public/Private LB 0.700/0.646. The new updated file has Public/Private LB 0.704/0.763."},{"metadata":{"trusted":true,"_uuid":"a8e35bcdd9acd5997593c8f5240182d78038dd80"},"cell_type":"code","source":"df_test2[['MachineIdentifier','HasDetections']].to_csv('PrivateLeaderboard.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bb293c619ac9233e9f97b6d4f1ff4287a702347"},"cell_type":"markdown","source":"![image](https://i.imgur.com/yIUhNVp.png)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}