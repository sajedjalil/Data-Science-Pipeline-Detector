{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## UPDATES \n* v5\n    * Increased depth of the NN\n    * fitted the model with entire train data after K-Fold\n    * printed out a classification report\n    * created a confusion matrix","metadata":{}},{"cell_type":"code","source":"# Imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport optuna","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-16T14:54:41.010584Z","iopub.execute_input":"2022-02-16T14:54:41.011025Z","iopub.status.idle":"2022-02-16T14:54:41.016658Z","shell.execute_reply.started":"2022-02-16T14:54:41.010992Z","shell.execute_reply":"2022-02-16T14:54:41.015846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading in data\n\ntrain = pd.read_csv('../input/tabular-playground-series-feb-2022/train.csv', index_col='row_id')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:41.01814Z","iopub.execute_input":"2022-02-16T14:54:41.018497Z","iopub.status.idle":"2022-02-16T14:54:55.626112Z","shell.execute_reply.started":"2022-02-16T14:54:41.018462Z","shell.execute_reply":"2022-02-16T14:54:55.625332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list of features and target\n\nfeatures = [col for col in train.columns if col not in ['target']]\ntarget = 'target'","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:55.627235Z","iopub.execute_input":"2022-02-16T14:54:55.627995Z","iopub.status.idle":"2022-02-16T14:54:55.632465Z","shell.execute_reply.started":"2022-02-16T14:54:55.627959Z","shell.execute_reply":"2022-02-16T14:54:55.631377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target Values","metadata":{}},{"cell_type":"code","source":"train[target].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:55.633742Z","iopub.execute_input":"2022-02-16T14:54:55.63394Z","iopub.status.idle":"2022-02-16T14:54:55.945195Z","shell.execute_reply.started":"2022-02-16T14:54:55.633915Z","shell.execute_reply":"2022-02-16T14:54:55.944473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSIGHTS\nThere is a similar split between the categories. In other words there is a class balance between each bacteria.","metadata":{}},{"cell_type":"code","source":"# Encoding the classes of target into numerical values\n\nle = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:55.947525Z","iopub.execute_input":"2022-02-16T14:54:55.947786Z","iopub.status.idle":"2022-02-16T14:54:56.011491Z","shell.execute_reply.started":"2022-02-16T14:54:55.947755Z","shell.execute_reply":"2022-02-16T14:54:56.010517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Create a list of features and target\n\nfeatures = [col for col in train.columns if col not in ['target']]\ntarget = 'target'","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:56.012708Z","iopub.execute_input":"2022-02-16T14:54:56.012925Z","iopub.status.idle":"2022-02-16T14:54:56.028493Z","shell.execute_reply.started":"2022-02-16T14:54:56.012898Z","shell.execute_reply":"2022-02-16T14:54:56.027274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling the data\n\nsc = StandardScaler()\ntrain[features] = sc.fit_transform(train[features])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:56.029911Z","iopub.execute_input":"2022-02-16T14:54:56.030696Z","iopub.status.idle":"2022-02-16T14:54:57.590248Z","shell.execute_reply.started":"2022-02-16T14:54:56.030642Z","shell.execute_reply":"2022-02-16T14:54:57.589604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into train valid\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    train[features],\n    train['target'],\n    test_size=0.3,\n    stratify=train['target'],\n    random_state=0\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:57.591617Z","iopub.execute_input":"2022-02-16T14:54:57.592397Z","iopub.status.idle":"2022-02-16T14:54:58.273295Z","shell.execute_reply.started":"2022-02-16T14:54:57.592353Z","shell.execute_reply":"2022-02-16T14:54:58.272617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"markdown","source":"### Baseline Model","metadata":{}},{"cell_type":"code","source":"# Parameters for model\n\ndims = train[features].shape[1]\nclasses = train['target'].nunique()\nepochs = 15","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:58.274478Z","iopub.execute_input":"2022-02-16T14:54:58.274762Z","iopub.status.idle":"2022-02-16T14:54:58.417611Z","shell.execute_reply.started":"2022-02-16T14:54:58.274729Z","shell.execute_reply":"2022-02-16T14:54:58.416652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function that trains a Neural Network model\n\ndef nn_model(X_train, y_train, X_valid, y_valid):\n\n    # Clearing the tensorflow backend\n    K.clear_session()\n    \n    # Creating the model\n    inputs = tf.keras.Input(shape=(None, dims))\n    layer = tf.keras.layers.Dense(\n        32,\n        activation='relu',\n        kernel_initializer=tf.keras.initializers.HeNormal(seed=0),\n    )(inputs)\n    \n    layer = tf.keras.layers.Dense(\n        32,\n        activation='relu',\n        kernel_initializer=tf.keras.initializers.HeNormal(seed=0),\n    )(layer)\n\n    layer = tf.keras.layers.Dense(\n        32,\n        activation='relu',\n        kernel_initializer=tf.keras.initializers.HeNormal(seed=0),\n    )(layer)\n\n    outputs = tf.keras.layers.Dense(\n        classes,\n        activation='softmax',\n    )(layer)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Compiling the model\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        metrics=['accuracy'],\n    )\n    \n    # Fitting the model\n    history = model.fit(\n        X_train,\n        y_train,\n        validation_data=(X_valid, y_valid),\n        epochs=epochs,\n        verbose=0,\n    )\n    \n    return history, model","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:58.419272Z","iopub.execute_input":"2022-02-16T14:54:58.419828Z","iopub.status.idle":"2022-02-16T14:54:58.43178Z","shell.execute_reply.started":"2022-02-16T14:54:58.419775Z","shell.execute_reply":"2022-02-16T14:54:58.430639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def f1_score(y_true, y_pred):\n\n#     # Count positive samples.\n#     c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n#     c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n#     c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n\n#     # If there are no true samples, fix the F1 score at 0.\n#     if c3 == 0:\n#         return 0\n\n#     # How many selected items are relevant?\n#     precision = c1 / c2\n\n#     # How many relevant items are selected?\n#     recall = c1 / c3\n\n#     # Calculate f1_score\n#     f1_score = 2 * (precision * recall) / (precision + recall)\n#     return f1_score ","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:58.433683Z","iopub.execute_input":"2022-02-16T14:54:58.434288Z","iopub.status.idle":"2022-02-16T14:54:58.443531Z","shell.execute_reply.started":"2022-02-16T14:54:58.434233Z","shell.execute_reply":"2022-02-16T14:54:58.442841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function plotting the accuracy and loss of \n\ndef plot_results(history):\n    plt.figure(figsize=(10,5))\n    x_ticks = np.arange(len(history.history['accuracy']))+1\n    plt.subplot(1,2,1)\n    plt.plot(x_ticks, history.history['accuracy'], label='accuracy')\n    plt.plot(x_ticks, history.history['val_accuracy'], label='val_accuracy')\n    plt.xticks(x_ticks)\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.grid(True)\n    plt.title('Accuracy Over Epochs')\n    plt.legend();\n\n    plt.subplot(1,2,2)\n    plt.plot(x_ticks, history.history['loss'], label='loss')\n    plt.plot(x_ticks, history.history['val_loss'], label='val_loss')\n    plt.xticks(x_ticks)\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    plt.title('Loss Over Epochs')\n    plt.legend();\n\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:58.444502Z","iopub.execute_input":"2022-02-16T14:54:58.445052Z","iopub.status.idle":"2022-02-16T14:54:58.457492Z","shell.execute_reply.started":"2022-02-16T14:54:58.44501Z","shell.execute_reply":"2022-02-16T14:54:58.456811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K-Fold Cross Validation","metadata":{}},{"cell_type":"code","source":"X = train[features]\ny = train['target']\n\nk = 5\nkf = KFold(n_splits=k, shuffle=True, random_state=0)\n\nfold_num = 1\naccuracy_per_fold = []\nloss_per_fold = []\n\nfor train_index, valid_index in kf.split(X):\n    \n    ## Splitting the data into train and test\n    X_train, X_valid, = X.iloc[train_index,:], X.iloc[valid_index,:]\n    y_train, y_valid = y[train_index], y[valid_index]\n    \n    ## Create and train NN model\n    history, model = nn_model(X_train, y_train, X_valid, y_valid)\n    \n    ## Plotting accuracy and loss\n    plot_results(history)\n    \n    ## Get and save the accuracy and loss\n    scores = model.evaluate(X_valid, y_valid)\n    accuracy_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    print(f'Score for fold {fold_num}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n    \n    # Increase fold number\n    fold_num += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:54:58.45871Z","iopub.execute_input":"2022-02-16T14:54:58.459057Z","iopub.status.idle":"2022-02-16T15:09:03.353812Z","shell.execute_reply.started":"2022-02-16T14:54:58.459021Z","shell.execute_reply":"2022-02-16T15:09:03.352861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"KFold Results: \")\nprint(f\"------------------\")\nprint(f\"Accuracy mean: {np.mean(accuracy_per_fold):.3f} +/- {np.std(accuracy_per_fold):.3f}\")\nprint(f\"Loss mean: {np.mean(loss_per_fold):.3f} +/- {np.std(loss_per_fold):.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:09:03.356542Z","iopub.execute_input":"2022-02-16T15:09:03.35686Z","iopub.status.idle":"2022-02-16T15:09:03.364003Z","shell.execute_reply.started":"2022-02-16T15:09:03.356825Z","shell.execute_reply":"2022-02-16T15:09:03.363062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSIGHTS\n* Based on the standard deviation the model has low variance\n    * the accuracy and loss of the training and validation sets are somewhat consistent\n* Base on the mean, the bias is low\n    * the mean accuracy is 95% which makes the error low but maybe we can get the error lower","metadata":{}},{"cell_type":"code","source":"# Creating the model\n\ntf.keras.backend.clear_session()\n\ninputs = tf.keras.Input(shape=(None, dims))\nlayer = tf.keras.layers.Dense(\n    32,\n    activation='relu',\n    kernel_initializer=tf.keras.initializers.HeNormal(seed=0),\n)(inputs)\n\nlayer = tf.keras.layers.Dense(\n    32,\n    activation='relu',\n    kernel_initializer=tf.keras.initializers.HeNormal(seed=0),\n)(layer)\n\nlayer = tf.keras.layers.Dense(\n    32,\n    activation='relu',\n    kernel_initializer=tf.keras.initializers.HeNormal(seed=0),\n)(layer)\n\noutputs = tf.keras.layers.Dense(\n    classes,\n    activation='softmax',\n)(layer)\n\nfull_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:09:03.365296Z","iopub.execute_input":"2022-02-16T15:09:03.36552Z","iopub.status.idle":"2022-02-16T15:09:03.466557Z","shell.execute_reply.started":"2022-02-16T15:09:03.365491Z","shell.execute_reply":"2022-02-16T15:09:03.465723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy'],\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:09:03.467717Z","iopub.execute_input":"2022-02-16T15:09:03.467976Z","iopub.status.idle":"2022-02-16T15:09:03.480396Z","shell.execute_reply.started":"2022-02-16T15:09:03.46791Z","shell.execute_reply":"2022-02-16T15:09:03.479517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n\nhistory = full_model.fit(\n    X,\n    y,\n    epochs=15\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:09:03.482014Z","iopub.execute_input":"2022-02-16T15:09:03.482705Z","iopub.status.idle":"2022-02-16T15:12:19.991372Z","shell.execute_reply.started":"2022-02-16T15:09:03.48266Z","shell.execute_reply":"2022-02-16T15:12:19.990484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Error Analysis","metadata":{}},{"cell_type":"code","source":"y_preds = full_model.predict(X_valid)\ny_preds_final = np.argmax(y_preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:12:19.992708Z","iopub.execute_input":"2022-02-16T15:12:19.992981Z","iopub.status.idle":"2022-02-16T15:12:21.419735Z","shell.execute_reply.started":"2022-02-16T15:12:19.992932Z","shell.execute_reply":"2022-02-16T15:12:21.418417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_mat = confusion_matrix(y_preds_final, y_valid)\nprint(cf_mat)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:12:21.421504Z","iopub.execute_input":"2022-02-16T15:12:21.421939Z","iopub.status.idle":"2022-02-16T15:12:21.476142Z","shell.execute_reply.started":"2022-02-16T15:12:21.421884Z","shell.execute_reply":"2022-02-16T15:12:21.475262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_valid, y_preds_final))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:12:21.477885Z","iopub.execute_input":"2022-02-16T15:12:21.478216Z","iopub.status.idle":"2022-02-16T15:12:21.572291Z","shell.execute_reply.started":"2022-02-16T15:12:21.478173Z","shell.execute_reply":"2022-02-16T15:12:21.571354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning with Optuna","metadata":{}},{"cell_type":"code","source":"# def create_model(trial):\n#     # We optimize the numbers of layers, their units and weight decay parameter.\n#     n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n#     weight_decay = trial.suggest_float(\"weight_decay\", 1e-10, 1e-3, log=True)\n#     model = tf.keras.Sequential()\n#     model.add(tf.keras.layers.Flatten())\n#     for i in range(n_layers):\n#         num_hidden = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True)\n#         model.add(\n#             tf.keras.layers.Dense(\n#                 num_hidden,\n#                 activation=\"relu\",\n#                 kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n#             )\n#         )\n#     model.add(\n#         tf.keras.layers.Dense(classes, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n#     )\n#     return model","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:51:40.47664Z","iopub.status.idle":"2022-02-16T14:51:40.476938Z","shell.execute_reply.started":"2022-02-16T14:51:40.476781Z","shell.execute_reply":"2022-02-16T14:51:40.476797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def create_optimizer(trial):\n#     # We optimize the choice of optimizers as well as their parameters.\n#     kwargs = {}\n#     optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n#     optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n#     if optimizer_selected == \"RMSprop\":\n#         kwargs[\"learning_rate\"] = trial.suggest_float(\n#             \"rmsprop_learning_rate\", 1e-5, 1e-1, log=True\n#         )\n#         kwargs[\"decay\"] = trial.suggest_float(\"rmsprop_decay\", 0.85, 0.99)\n#         kwargs[\"momentum\"] = trial.suggest_float(\"rmsprop_momentum\", 1e-5, 1e-1, log=True)\n#     elif optimizer_selected == \"Adam\":\n#         kwargs[\"learning_rate\"] = trial.suggest_float(\"adam_learning_rate\", 1e-5, 1e-1, log=True)\n#     elif optimizer_selected == \"SGD\":\n#         kwargs[\"learning_rate\"] = trial.suggest_float(\n#             \"sgd_opt_learning_rate\", 1e-5, 1e-1, log=True\n#         )\n#         kwargs[\"momentum\"] = trial.suggest_float(\"sgd_opt_momentum\", 1e-5, 1e-1, log=True)\n\n#     optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n#     return optimizer","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:51:40.47789Z","iopub.status.idle":"2022-02-16T14:51:40.478205Z","shell.execute_reply.started":"2022-02-16T14:51:40.478053Z","shell.execute_reply":"2022-02-16T14:51:40.478069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def learn(model, optimizer, dataset, mode=\"eval\"):\n    \n#     (X_train, y_train), (X_valid, y_valid)\n    \n#     model.compile(\n#         loss=\"sparse_categorical_crossentropy\", \n#         optimizer=optimizer, \n#         metrics=[\"accuracy\"]\n#     )\n    \n#     model.fit(\n#         X_train,\n#         y_train,\n#         validation_data=(X_valid, y_valid),\n#         shuffle=True,\n# #         batch_size=BATCHSIZE,\n#         epochs=EPOCHS,\n#         verbose=False,\n#     )\n\n#     # Evaluate the model accuracy on the validation set.\n#     score = model.evaluate(X_valid, y_valid, verbose=0)\n#     return score","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:51:40.479122Z","iopub.status.idle":"2022-02-16T14:51:40.47941Z","shell.execute_reply.started":"2022-02-16T14:51:40.479256Z","shell.execute_reply":"2022-02-16T14:51:40.479272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def objective(trial):\n#     # Get MNIST data.\n#     train_ds, valid_ds = (X_train, y_train), (X_valid, y_valid)\n\n#     # Build model and optimizer.\n#     model = create_model(trial)\n#     optimizer = create_optimizer(trial)\n\n#     # Training and validating cycle.\n#     with tf.device(\"/cpu:0\"):\n#         for _ in range(EPOCHS):\n#             learn(model, optimizer, train_ds, \"train\")\n\n#         accuracy = learn(model, optimizer, valid_ds, \"eval\")\n\n#     # Return last validation accuracy.\n#     return accuracy.result()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:51:40.480303Z","iopub.status.idle":"2022-02-16T14:51:40.480622Z","shell.execute_reply.started":"2022-02-16T14:51:40.480439Z","shell.execute_reply":"2022-02-16T14:51:40.480455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# study = optuna.create_study(direction=\"maximize\")\n# study.optimize(objective, n_trials=1)\n\n# print(\"Number of finished trials: \", len(study.trials))\n\n# print(\"Best trial:\")\n# trial = study.best_trial\n\n# print(\"  Value: \", trial.value)\n\n# print(\"  Params: \")\n# for key, value in trial.params.items():\n#     print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T14:08:49.529517Z","iopub.status.idle":"2022-02-16T14:08:49.530339Z","shell.execute_reply.started":"2022-02-16T14:08:49.530121Z","shell.execute_reply":"2022-02-16T14:08:49.530148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/tabular-playground-series-feb-2022/test.csv')\ntest.drop(['row_id'], inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:14:50.29115Z","iopub.execute_input":"2022-02-16T15:14:50.292034Z","iopub.status.idle":"2022-02-16T15:15:02.122688Z","shell.execute_reply.started":"2022-02-16T15:14:50.291978Z","shell.execute_reply":"2022-02-16T15:15:02.121787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling the test data","metadata":{}},{"cell_type":"code","source":"test_features = test.columns\ntest_features","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:15:02.124416Z","iopub.execute_input":"2022-02-16T15:15:02.12476Z","iopub.status.idle":"2022-02-16T15:15:02.130801Z","shell.execute_reply.started":"2022-02-16T15:15:02.124715Z","shell.execute_reply":"2022-02-16T15:15:02.130021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[test_features] = sc.transform(test[test_features])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:15:02.131792Z","iopub.execute_input":"2022-02-16T15:15:02.132006Z","iopub.status.idle":"2022-02-16T15:15:02.480241Z","shell.execute_reply.started":"2022-02-16T15:15:02.131979Z","shell.execute_reply":"2022-02-16T15:15:02.479619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting on the Test Data","metadata":{}},{"cell_type":"code","source":"preds = full_model.predict(test)\ntemp = [row.argmax() for row in preds]\nfinal = le.inverse_transform(temp)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:15:02.482001Z","iopub.execute_input":"2022-02-16T15:15:02.482426Z","iopub.status.idle":"2022-02-16T15:15:08.104435Z","shell.execute_reply.started":"2022-02-16T15:15:02.482394Z","shell.execute_reply":"2022-02-16T15:15:08.103764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the Submission File","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')\nsubmission['target'] = final\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:15:08.106319Z","iopub.execute_input":"2022-02-16T15:15:08.106953Z","iopub.status.idle":"2022-02-16T15:15:08.395388Z","shell.execute_reply.started":"2022-02-16T15:15:08.106906Z","shell.execute_reply":"2022-02-16T15:15:08.394654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:15:08.397148Z","iopub.execute_input":"2022-02-16T15:15:08.397769Z","iopub.status.idle":"2022-02-16T15:15:08.40872Z","shell.execute_reply.started":"2022-02-16T15:15:08.397722Z","shell.execute_reply":"2022-02-16T15:15:08.407632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}