{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular Playground Series Feb. 2022\n* Introduction of Competition\n* Loading Libaries\n* Exploratory Data Analysis(EDA)\n* Model Training and Inference\n\n# 1.Introduction Of Competition\nWe have a competition on genetic data this month, 10 bacteria will be classified according to the results of genomic analysis in this competition. \nIn this technique, 10-mer snippets of DNA are sampled and analyzed to give the histogram of base count\n## 1.1. ðŸ¦  Bacteria species (classes)\n* [Streptococcus pyogenes](https://en.wikipedia.org/wiki/Streptococcus_pyogenes)\n* [Salmonella enterica](https://ru.wikipedia.org/wiki/Salmonella_enterica)\n* [Escherichia coli](https://en.wikipedia.org/wiki/Enterococcus_hirae)\n* [Campylobacter jejuni](https://en.wikipedia.org/wiki/Campylobacter_jejuni)\n* [Streptococcus pneumoniae](https://en.wikipedia.org/wiki/Streptococcus_pneumoniae)\n* [Staphylococcus aureus](https://en.wikipedia.org/wiki/Staphylococcus_aureus)\n* [Escherichia fergusonii](https://en.wikipedia.org/wiki/Escherichia_fergusonii)\n* [Bacteroides fragilis](https://en.wikipedia.org/wiki/Bacteroides_fragilis)\n* [Klebsiella pneumoniae](https://en.wikipedia.org/wiki/Klebsiella_pneumoniae)\n\nTODO: The next version of my notebook will be investigating case bacteria. \n\n# 2. ðŸ“š Import Libraries & Reduce Memory","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.stats import mode\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport warnings\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nwarnings.simplefilter('ignore')\nKAGGLE_DIR = r'../input/tabular-playground-series-feb-2022/'\nLOCAL_DIR = r''\nKAGGLE = True\nRS = 69420","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:45:07.800663Z","iopub.execute_input":"2022-02-06T14:45:07.801272Z","iopub.status.idle":"2022-02-06T14:45:10.62712Z","shell.execute_reply.started":"2022-02-06T14:45:07.801153Z","shell.execute_reply":"2022-02-06T14:45:10.626289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1. Reduce the memory Usage","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:45:10.628811Z","iopub.execute_input":"2022-02-06T14:45:10.629023Z","iopub.status.idle":"2022-02-06T14:45:10.644221Z","shell.execute_reply.started":"2022-02-06T14:45:10.628998Z","shell.execute_reply":"2022-02-06T14:45:10.643597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif KAGGLE:\n    print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\n    df = pd.read_csv(KAGGLE_DIR+'train.csv', index_col=0).pipe(reduce_mem_usage)\n    print(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\n    test = pd.read_csv(KAGGLE_DIR+'test.csv', index_col=0).pipe(reduce_mem_usage)\n    sub = pd.read_csv(KAGGLE_DIR+'sample_submission.csv').pipe(reduce_mem_usage)\nelse:\n    print(f\"{'*'*10} Loading Training Data... {'*'*10}\")\n    df = pd.read_csv(LOCAL_DIR+'train.csv', index_col=0).pipe(reduce_mem_usage)\n    print(f\"{'*'*10} Loading Testing Data... {'*'*10}\")\n    test = pd.read_csv(LOCAL_DIR+'test.csv', index_col=0).pipe(reduce_mem_usage)\n    sub = pd.read_csv(LOCAL_DIR+'sample_submission.csv').pipe(reduce_mem_usage)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:45:10.645512Z","iopub.execute_input":"2022-02-06T14:45:10.645975Z","iopub.status.idle":"2022-02-06T14:46:21.775193Z","shell.execute_reply.started":"2022-02-06T14:45:10.645936Z","shell.execute_reply":"2022-02-06T14:46:21.774191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del df \n#gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.777262Z","iopub.execute_input":"2022-02-06T14:46:21.777535Z","iopub.status.idle":"2022-02-06T14:46:21.780973Z","shell.execute_reply.started":"2022-02-06T14:46:21.777504Z","shell.execute_reply":"2022-02-06T14:46:21.78017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. ðŸ” Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.785756Z","iopub.execute_input":"2022-02-06T14:46:21.786427Z","iopub.status.idle":"2022-02-06T14:46:21.835277Z","shell.execute_reply.started":"2022-02-06T14:46:21.78638Z","shell.execute_reply":"2022-02-06T14:46:21.834685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.836332Z","iopub.execute_input":"2022-02-06T14:46:21.836789Z","iopub.status.idle":"2022-02-06T14:46:21.862286Z","shell.execute_reply.started":"2022-02-06T14:46:21.836736Z","shell.execute_reply":"2022-02-06T14:46:21.861679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train set - dimensions:\\t', df.shape)\nprint('Test set - dimensions:\\t', test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.863591Z","iopub.execute_input":"2022-02-06T14:46:21.864077Z","iopub.status.idle":"2022-02-06T14:46:21.869447Z","shell.execute_reply.started":"2022-02-06T14:46:21.864045Z","shell.execute_reply":"2022-02-06T14:46:21.868345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Missing value of Train set:{df.isnull().sum().sum()} and Missing value of Test set: {test.isnull().sum().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:21.870856Z","iopub.execute_input":"2022-02-06T14:46:21.871418Z","iopub.status.idle":"2022-02-06T14:46:22.376346Z","shell.execute_reply.started":"2022-02-06T14:46:21.871374Z","shell.execute_reply":"2022-02-06T14:46:22.375447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_dist = df[\"target\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:22.378762Z","iopub.execute_input":"2022-02-06T14:46:22.379014Z","iopub.status.idle":"2022-02-06T14:46:22.385952Z","shell.execute_reply.started":"2022-02-06T14:46:22.378983Z","shell.execute_reply":"2022-02-06T14:46:22.384671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(df,values=target_dist,names=target_dist.index,\n             color_discrete_sequence=px.colors.sequential.RdBu,\n            hole=0.1)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:22.38775Z","iopub.execute_input":"2022-02-06T14:46:22.388261Z","iopub.status.idle":"2022-02-06T14:46:23.398073Z","shell.execute_reply.started":"2022-02-06T14:46:22.388107Z","shell.execute_reply":"2022-02-06T14:46:23.397142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub25 = df.nunique()[df.nunique() < 25][:-1]\nsub25","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:23.399581Z","iopub.execute_input":"2022-02-06T14:46:23.400093Z","iopub.status.idle":"2022-02-06T14:46:25.351539Z","shell.execute_reply.started":"2022-02-06T14:46:23.40006Z","shell.execute_reply":"2022-02-06T14:46:25.350597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_feat = sub25.index.tolist()\nall_feat = df.columns.difference(cat_feat)[:-1] # -1 cuz last index is target we dont need it.\ndf.columns.difference(cat_feat)[-1]","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:25.352874Z","iopub.execute_input":"2022-02-06T14:46:25.353174Z","iopub.status.idle":"2022-02-06T14:46:25.36172Z","shell.execute_reply.started":"2022-02-06T14:46:25.353134Z","shell.execute_reply":"2022-02-06T14:46:25.360684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(df,names = [\"Continous Features\",\"Categorical Features\"],\n             values = [len(cat_feat),len(all_feat)],\n             hole = 0.4,\n            color_discrete_sequence=px.colors.sequential.RdBu)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:25.363048Z","iopub.execute_input":"2022-02-06T14:46:25.363839Z","iopub.status.idle":"2022-02-06T14:46:25.419262Z","shell.execute_reply.started":"2022-02-06T14:46:25.363798Z","shell.execute_reply":"2022-02-06T14:46:25.418388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.Preprocessing & Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfeature = df.columns[df.columns != \"target\"]\nle = LabelEncoder()\nX = df[feature]\ny = pd.DataFrame(le.fit_transform(df[\"target\"]), columns=[\"target\"])\nprint(f\"X shape:{X.shape} & y Shape:{y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:25.420274Z","iopub.execute_input":"2022-02-06T14:46:25.420477Z","iopub.status.idle":"2022-02-06T14:46:25.754113Z","shell.execute_reply.started":"2022-02-06T14:46:25.420451Z","shell.execute_reply":"2022-02-06T14:46:25.753108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.Modeling & Feature Ä°mportance\nWe are using model as ExtraTreesClassifier for these case, so what is ExtraTreesClassifier and what is difference with RandomForest?\n\n![](https://miro.medium.com/max/640/0*4VpGqWJUJnmD2mm0.jpg))\n\nExtraTreesClassifier is an ensemble learning method fundamentally based on decision trees. ExtraTreesClassifier, like RandomForest, randomizes certain decisions and subsets of data to minimize over-learning from the data and overfitting.\nLetâ€™s look at some ensemble methods ordered from high to low variance, ending in ExtraTreesClassifier.\n## 5.1. Trees:\n### 5.1.1. Decision Tree (High Variance)\nA single decision tree is usually overfits the data it is learning from because it learn from only one pathway of decisions. Predictions from a single decision tree usually donâ€™t make accurate predictions on new data.\n### 5.1.2.Random Forest (Medium Variance)\nRandom forest models reduce the risk of overfitting by introducing randomness by:\nbuilding multiple trees (n_estimators)\ndrawing observations with replacement (i.e., a bootstrapped sample)\nsplitting nodes on the best split among a random subset of the features selected at every node\n![](https://1.bp.blogspot.com/-Ax59WK4DE8w/YK6o9bt_9jI/AAAAAAAAEQA/9KbBf9cdL6kOFkJnU39aUn4m8ydThPenwCLcBGAsYHQ/s0/Random%2BForest%2B03.gif)\n### 5.1.3.Extra Trees (Low Variance)\nExtra Trees is like Random Forest, in that it builds multiple trees and splits nodes using random subsets of features, but with two key differences: it does not bootstrap observations (meaning it samples without replacement), and nodes are split on random splits, not best splits. So, in summary, ExtraTrees:\nbuilds multiple trees with bootstrap = False by default, which means it samples without replacement\nnodes are split based on random splits among a random subset of the features selected at every node\nIn Extra Trees, randomness doesnâ€™t come from bootstrapping of data, but rather comes from the random splits of all observations.\nExtraTrees is named for (Extremely Randomized Trees).\n![](https://www.researchgate.net/publication/346995264/figure/fig1/AS:969705405812741@1608207193473/The-structure-of-ExtraTree.png)\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\nimport time\n\nn_splits= 10\nfolds = StratifiedKFold(n_splits=n_splits,shuffle=True)\n\ny_pred = []\nscore = []\nfor fold,(train_id,test_id) in enumerate(folds.split(X,y)):\n    print(f\"{fold}. Fold\")\n    start_time = time.time()\n    #splitting the data per fold\n    X_train,y_train = X.iloc[train_id],y.iloc[train_id]\n    X_valid,y_valid = X.iloc[test_id],y.iloc[test_id]\n    \n    #create a model\n    etc = ExtraTreesClassifier(n_estimators=1000) # grid search or optuna will be coming soon!\n    #Train for per fold\n    etc.fit(X_train,y_train)\n    \n    #evaluation of per fold\n    val_pred = etc.predict(X_valid)\n    valid_score_acc = accuracy_score(y_valid,val_pred)\n    score.append(valid_score_acc)\n    run_time = time.time() - start_time\n    print(f\"fold acc: {valid_score_acc} run time :{run_time} The overall average of the trainings done so far: {np.mean(score)}\")  \n    # Now train our whole data for submission and ensemble it\n    y_pred.append(etc.predict(test))\nprint(f\"Mean acc score:{np.mean(score)}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:46:25.755861Z","iopub.execute_input":"2022-02-06T14:46:25.756172Z","iopub.status.idle":"2022-02-06T17:02:02.897149Z","shell.execute_reply.started":"2022-02-06T14:46:25.756129Z","shell.execute_reply":"2022-02-06T17:02:02.895964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2. Feature Ä°mportance","metadata":{}},{"cell_type":"code","source":"df_feature_imp = pd.DataFrame({\n    'feature': X.columns, \n    'importance': etc.feature_importances_\n})\n\nfeature_imp_25 = df_feature_imp.sort_values(\n    by='importance', ascending=False\n).iloc[:25].reset_index(drop=True)\n\nfig = go.Figure(\n    go.Bar(\n        x=feature_imp_25.importance,\n        y=feature_imp_25.feature,\n        orientation='h',\n        marker=dict(color=feature_imp_25.importance)\n    )\n)\n\nfig.update_layout(\n    width=1000, height=1000,\n    yaxis=dict(autorange='reversed')\n)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T17:02:02.899537Z","iopub.execute_input":"2022-02-06T17:02:02.899873Z","iopub.status.idle":"2022-02-06T17:02:03.410924Z","shell.execute_reply.started":"2022-02-06T17:02:02.899837Z","shell.execute_reply":"2022-02-06T17:02:03.410107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"y_pred = mode(y_pred).mode[0]\ny_pred = le.inverse_transform(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T17:02:03.412385Z","iopub.execute_input":"2022-02-06T17:02:03.413202Z","iopub.status.idle":"2022-02-06T17:02:06.710429Z","shell.execute_reply.started":"2022-02-06T17:02:03.413157Z","shell.execute_reply":"2022-02-06T17:02:06.709481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/tabular-playground-series-feb-2022/sample_submission.csv\")\nsubmission[\"target\"] = y_pred\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-02-06T17:45:16.163179Z","iopub.execute_input":"2022-02-06T17:45:16.16357Z","iopub.status.idle":"2022-02-06T17:45:16.255909Z","shell.execute_reply.started":"2022-02-06T17:45:16.163462Z","shell.execute_reply":"2022-02-06T17:45:16.253762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T17:02:06.785405Z","iopub.execute_input":"2022-02-06T17:02:06.785659Z","iopub.status.idle":"2022-02-06T17:02:07.048731Z","shell.execute_reply.started":"2022-02-06T17:02:06.785627Z","shell.execute_reply":"2022-02-06T17:02:07.047904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  6.References \n[Trees-namanbhandari.medium](https://medium.com/@namanbhandari/extratreesclassifier-8e7fc0502c7)\n\n[Quantdare](https://quantdare.com/what-is-the-difference-between-extra-trees-and-random-forest/)","metadata":{}},{"cell_type":"markdown","source":"### I hope you get a great time when you looking my notebook, have a good day.\n### Don't forget to mention my shortcomings and give an upvote! ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}