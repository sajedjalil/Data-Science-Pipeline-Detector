{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Welcome and have fun learning multiclass classification\n\n#### Metric: **Accuracy**. **[Softvoting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)** and weighted average is the objective to score towards target class.\n\nObjective of this notebook used to be a ~simple~ and robust multiclass classifier for future use.\n\n<blockquote style=\"margin-right:auto; margin-left:auto; padding: 1em; margin:24px;\">\n    <strong>Fork This Notebook!</strong><br>\nCreate your own editable copy of this notebook by clicking on the <strong>Copy and Edit</strong> button in the top right corner.\n</blockquote>","metadata":{}},{"cell_type":"code","source":"if '__initialized__' not in locals():\n    !pip install scikit-learn -U\n    # Intel® Extension for Scikit-learn installation:\n    !pip install scikit-learn-intelex\n    from sklearnex import patch_sklearn\n    patch_sklearn()\n\n# Installation Initialized\n__initialized__ = True","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-23T00:32:13.821089Z","iopub.execute_input":"2022-02-23T00:32:13.821608Z","iopub.status.idle":"2022-02-23T00:33:03.764651Z","shell.execute_reply.started":"2022-02-23T00:32:13.821516Z","shell.execute_reply":"2022-02-23T00:33:03.763804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\nfrom scipy import stats\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\nimport seaborn as sns\n\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler, TomekLinks\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, RobustScaler, PowerTransformer, OneHotEncoder\nle = LabelEncoder()\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.metrics import accuracy_score, log_loss, confusion_matrix, roc_curve, precision_recall_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.decomposition import PCA\n\nfrom datetime import datetime\nfrom packaging import version\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport gc\nimport os\nimport math\nimport random\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:03.766381Z","iopub.execute_input":"2022-02-23T00:33:03.766655Z","iopub.status.idle":"2022-02-23T00:33:03.971131Z","shell.execute_reply.started":"2022-02-23T00:33:03.766621Z","shell.execute_reply":"2022-02-23T00:33:03.970361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning\nFine tune the system using the hyperparameters and configs below:\n* **PRODUCTION** - True: For submission run. False: Fast trial run\n* FOLD - 5, 10, 15, 20.\n* SAMPLE - Set it to True for full sample run. Max sample per class.\n* N_ESTIMATORS - Model hyperparameter","metadata":{}},{"cell_type":"code","source":"# -----------------------------------------------------------------\n# Some parameters to config \nPRODUCTION = True # True: For submission run. False: Fast trial run\n\n# Hyperparameters\nFOLDS = 10 if PRODUCTION else 5   # Only 5 or 10.\nTREES = 20\nN_ESTIMATORS = 1300 if PRODUCTION else 7 # Overfitting vs underfitting https://www.kaggle.com/c/tabular-playground-series-feb-2022/discussion/305463\n\nSAMPLE_WEIGHT = True\nAVERAGE_WEIGHTED_FOLD = False\nDIST_BOUND = True      # Bound distribution by class accuracy\nDIST_THRESHOLD = 0.297 # Distribution bound threshold\n\nRANDOM_STATE = 1655\nVERBOSE = 0\n\nBLEND = True","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-23T00:33:03.972406Z","iopub.execute_input":"2022-02-23T00:33:03.972693Z","iopub.status.idle":"2022-02-23T00:33:03.978261Z","shell.execute_reply.started":"2022-02-23T00:33:03.972661Z","shell.execute_reply":"2022-02-23T00:33:03.977714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If the dataset is too huge for trial. Sampling it for speed run!\nSAMPLE = 20139 if PRODUCTION else 12522   # Max Sample size per category. For quick test: y counts [12522, 20139, 20063, 19947, 19958, 19937, 19847, 20030, 19929, 20074, 20076]  # 200000 total rows\nVALIDATION_SPLIT = 0.25 # Only used to min dataset for quick test\n\n# Admin\nID = \"row_id\"            # Id id x X index\nINPUT = \"../input/tabular-playground-series-feb-2022\"\nTPU = False           # True: use TPU.\nGPU = False           # True: use GPU.\nBEST_OR_FOLD = False # True: use Best model, False: use KFOLD softvote\nFEATURE_ENGINEERING = True\nPSEUDO_LABEL = False\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:03.9799Z","iopub.execute_input":"2022-02-23T00:33:03.980455Z","iopub.status.idle":"2022-02-23T00:33:03.993714Z","shell.execute_reply.started":"2022-02-23T00:33:03.980416Z","shell.execute_reply":"2022-02-23T00:33:03.99287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(RANDOM_STATE)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:03.99484Z","iopub.execute_input":"2022-02-23T00:33:03.995206Z","iopub.status.idle":"2022-02-23T00:33:04.004497Z","shell.execute_reply.started":"2022-02-23T00:33:03.995176Z","shell.execute_reply":"2022-02-23T00:33:04.003729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_cm(cm):\n    metrics = {\n        'accuracy': cm / cm.sum(),\n        'recall' : cm / cm.sum(axis = 1 ),\n        'precision': cm / cm.sum(axis = 0)\n    }\n    \n    fig, ax = plt.subplots(1,3, tight_layout = True, figsize = (20,6))\n    ax = ax.flatten()\n#     mask = (np.eye(cm.shape[0]) == 0) * 1\n    for idx, (name, matrix) in enumerate(metrics.items()):\n        ax[idx].set_title(name)\n        sns.heatmap(\n            data = matrix,\n            cmap = sns.dark_palette(\"#69d\", reverse=True, as_cmap=True),\n            cbar = False,\n#             mask=mask,\n            lw = 0.25,\n            annot = True,\n            fmt = '.2f',\n            ax = ax[idx]\n        )\n#         for tick in ax[idx].get_xticklabels():\n#                 tick.set_rotation(60)\n                \n    sns.despine()\n    \ndef plot_cm_error(cm):\n    mask = (np.eye(cm.shape[0]) != 0) * 1\n    fig, ax = plt.subplots(tight_layout=True, figsize=(15,8))\n    sns.heatmap(\n                data = pd.DataFrame(data=cm, index=le.classes_, columns = le.classes_),\n#                 cmap=sns.dark_palette(\"#69d\", reverse=True, as_cmap=True),\n                cbar = False,\n                lw = 0.25,\n                mask = mask,\n                annot = True,\n                fmt = '.0f',\n                ax = ax\n            )\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    sns.despine()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:04.005632Z","iopub.execute_input":"2022-02-23T00:33:04.005952Z","iopub.status.idle":"2022-02-23T00:33:04.017954Z","shell.execute_reply.started":"2022-02-23T00:33:04.005925Z","shell.execute_reply":"2022-02-23T00:33:04.017173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reduce Memory usage","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:04.019238Z","iopub.execute_input":"2022-02-23T00:33:04.019818Z","iopub.status.idle":"2022-02-23T00:33:04.035037Z","shell.execute_reply.started":"2022-02-23T00:33:04.01977Z","shell.execute_reply":"2022-02-23T00:33:04.03421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\n\ndef load_data():\n    # Read data\n    data_dir = Path(INPUT)\n    try:\n        # Read the parquet data.\n        df_train = pd.read_parquet('../input/tpsfeb22-soft-voting-baseline/train.parquet').pipe(reduce_mem_usage)\n        df_test = pd.read_parquet('../input/tpsfeb22-soft-voting-baseline/test.parquet').pipe(reduce_mem_usage)\n    except FileNotFoundError:\n        df_train = pd.read_csv(data_dir / \"train.csv\", index_col=ID).pipe(reduce_mem_usage)\n        df_test = pd.read_csv(data_dir / \"test.csv\", index_col=ID).pipe(reduce_mem_usage)\n\n    # Save the csv file to parquet.\n    # I learned parquet from this notebook: https://www.kaggle.com/wti200/one-vs-rest-approach\n    df_train.to_parquet('train.parquet')\n    df_test.to_parquet('test.parquet')\n    column_y = df_train.columns.difference(\n        df_test.columns)[0]  # column_y target_col label_col\n    return df_train, df_test, column_y","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:04.036495Z","iopub.execute_input":"2022-02-23T00:33:04.037018Z","iopub.status.idle":"2022-02-23T00:33:04.049973Z","shell.execute_reply.started":"2022-02-23T00:33:04.036977Z","shell.execute_reply":"2022-02-23T00:33:04.049055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing ##\n\nBefore we can do any feature engineering, we need to *preprocess* the data to get it in a form suitable for analysis. We'll need to:\n- **Load** the data from CSV files\n- **Clean** the data to fix any errors or inconsistencies\n- **Encode** the statistical data type (numeric, categorical)\n- **Impute** any missing values\n\nWe'll wrap all these steps up in a function, which will make easy for you to get a fresh dataframe whenever you need. After reading the CSV file, we'll apply three preprocessing steps, `clean`, `encode`, and `impute`, and then create the data splits: one (`df_train`) for training the model, and one (`df_test`) for making the predictions that you'll submit to the competition for scoring on the leaderboard.","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_data, test_data, TARGET_FEATURE_NAME = load_data()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:33:04.051184Z","iopub.execute_input":"2022-02-23T00:33:04.051443Z","iopub.status.idle":"2022-02-23T00:33:10.846014Z","shell.execute_reply.started":"2022-02-23T00:33:04.051414Z","shell.execute_reply":"2022-02-23T00:33:10.845329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check NA\nmissing_val = train_data.isnull().sum()\nprint(missing_val[missing_val > 0])","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:33:10.84864Z","iopub.execute_input":"2022-02-23T00:33:10.84909Z","iopub.status.idle":"2022-02-23T00:33:10.992861Z","shell.execute_reply.started":"2022-02-23T00:33:10.849044Z","shell.execute_reply":"2022-02-23T00:33:10.99158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Duplicate rows check\nhttps://www.kaggle.com/sfktrkl/tps-feb-2022/notebook","metadata":{}},{"cell_type":"code","source":"# Save original target distribution\ntarget_distribution = train_data[TARGET_FEATURE_NAME].value_counts().sort_index() / len(train_data) * 100\n\nduplicates_train = train_data.duplicated().sum()\nprint('Duplicates in train data: {0}'.format(duplicates_train))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:10.99469Z","iopub.execute_input":"2022-02-23T00:33:10.99534Z","iopub.status.idle":"2022-02-23T00:33:15.042388Z","shell.execute_reply.started":"2022-02-23T00:33:10.995287Z","shell.execute_reply":"2022-02-23T00:33:15.0401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dropping duplicated rows\nhttps://www.kaggle.com/c/tabular-playground-series-feb-2022/discussion/305364\n\nTo compensate for dropping the duplicates, column sample_weight is added to the dataframe.","metadata":{}},{"cell_type":"code","source":"# train_df = train_data.groupby(list(train_data.columns.values)).size().reset_index(name='sample_weight').copy()\nvc = train_data.value_counts()\ndedup_train = pd.DataFrame([list(tup) for tup in vc.index.values], columns=train_data.columns)\ndedup_train['sample_weight'] = vc.values\ntrain_df = dedup_train\ntrain_df.drop_duplicates(keep='first', inplace=True)\nduplicates_train = train_df.duplicated().sum()\n\nprint('Train data shape:', train_df.shape)\nprint('Duplicates in train data: {0}'.format(duplicates_train))\ntrain_df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:15.046122Z","iopub.execute_input":"2022-02-23T00:33:15.048232Z","iopub.status.idle":"2022-02-23T00:33:49.567832Z","shell.execute_reply.started":"2022-02-23T00:33:15.048063Z","shell.execute_reply":"2022-02-23T00:33:49.566887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What if you do the opposite and inverse sample weight\n# train_df['sample_weight'] = 1. / train_df['sample_weight']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:49.569531Z","iopub.execute_input":"2022-02-23T00:33:49.570433Z","iopub.status.idle":"2022-02-23T00:33:49.574213Z","shell.execute_reply.started":"2022-02-23T00:33:49.570381Z","shell.execute_reply":"2022-02-23T00:33:49.573418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample Weight bias\n- 2 * Escherichia_coli sample weight\n- 2 * Escherichia_fergusonii sample weight","metadata":{}},{"cell_type":"code","source":"# train_df[\"sample_weight\"] = np.where(train_df[TARGET_FEATURE_NAME]=='Escherichia_coli', train_df[\"sample_weight\"]*1.03, train_df[\"sample_weight\"])\n# train_df[\"sample_weight\"] = np.where(train_df[TARGET_FEATURE_NAME]=='Escherichia_fergusonii', train_df[\"sample_weight\"]*1.05, train_df[\"sample_weight\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:33:49.575223Z","iopub.execute_input":"2022-02-23T00:33:49.575496Z","iopub.status.idle":"2022-02-23T00:33:49.586822Z","shell.execute_reply.started":"2022-02-23T00:33:49.575467Z","shell.execute_reply":"2022-02-23T00:33:49.585979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## WIP\n\nGuess may not have the time to do spectrogram experiments","metadata":{}},{"cell_type":"code","source":"df_fergu = train_df.iloc[np.where(train_df[TARGET_FEATURE_NAME]=='Escherichia_fergusonii')]\ndf_coli = train_df.iloc[np.where(train_df[TARGET_FEATURE_NAME]=='Escherichia_coli')]\ndf_jejuni = train_df.iloc[np.where(train_df[TARGET_FEATURE_NAME]=='Campylobacter_jejuni')]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:49.587977Z","iopub.execute_input":"2022-02-23T00:33:49.588623Z","iopub.status.idle":"2022-02-23T00:33:49.716522Z","shell.execute_reply.started":"2022-02-23T00:33:49.588585Z","shell.execute_reply":"2022-02-23T00:33:49.715571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Escherichia_fergusonii","metadata":{}},{"cell_type":"code","source":"for i in range(0,10):\n    df_fergu.iloc[i][:-2].plot(kind='line',figsize=(20,6))\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:49.717769Z","iopub.execute_input":"2022-02-23T00:33:49.718008Z","iopub.status.idle":"2022-02-23T00:33:50.195173Z","shell.execute_reply.started":"2022-02-23T00:33:49.717977Z","shell.execute_reply":"2022-02-23T00:33:50.194402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Escherichia_coli","metadata":{}},{"cell_type":"code","source":"for i in range(0,10):\n    df_coli.iloc[i][:-2].plot(kind='line',figsize=(20,6))\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:50.196643Z","iopub.execute_input":"2022-02-23T00:33:50.197058Z","iopub.status.idle":"2022-02-23T00:33:50.592804Z","shell.execute_reply.started":"2022-02-23T00:33:50.197024Z","shell.execute_reply":"2022-02-23T00:33:50.59187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Campylobacter_jejuni","metadata":{}},{"cell_type":"code","source":"for i in range(0,10):\n    df_jejuni.iloc[i][:-2].plot(kind='line',figsize=(20,6))\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:50.594152Z","iopub.execute_input":"2022-02-23T00:33:50.594392Z","iopub.status.idle":"2022-02-23T00:33:50.990119Z","shell.execute_reply.started":"2022-02-23T00:33:50.594363Z","shell.execute_reply":"2022-02-23T00:33:50.989183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import librosa","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:50.9917Z","iopub.execute_input":"2022-02-23T00:33:50.991968Z","iopub.status.idle":"2022-02-23T00:33:50.996116Z","shell.execute_reply.started":"2022-02-23T00:33:50.991937Z","shell.execute_reply":"2022-02-23T00:33:50.995402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Spectrogram","metadata":{}},{"cell_type":"markdown","source":"### Escherichia_coli","metadata":{}},{"cell_type":"code","source":"from scipy import signal\nfrom scipy.fft import fftshift\n\ntime = np.arange(286)\n# f, t, Sxx = signal.spectrogram()\nfig, (ax1, ax2) = plt.subplots(nrows=2)\nax1.plot(time, df_coli.iloc[0][:-2])\nPxx, freqs, bins, im = ax2.specgram(df_jejuni.iloc[0][:-2])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:50.997265Z","iopub.execute_input":"2022-02-23T00:33:50.997736Z","iopub.status.idle":"2022-02-23T00:33:51.413494Z","shell.execute_reply.started":"2022-02-23T00:33:50.997695Z","shell.execute_reply":"2022-02-23T00:33:51.412592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows=2)\nax1.plot(time, df_coli.iloc[1][:-2])\nPxx, freqs, bins, im = ax2.specgram(df_jejuni.iloc[1][:-2])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:51.414799Z","iopub.execute_input":"2022-02-23T00:33:51.41504Z","iopub.status.idle":"2022-02-23T00:33:51.755025Z","shell.execute_reply.started":"2022-02-23T00:33:51.41501Z","shell.execute_reply":"2022-02-23T00:33:51.753962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows=2)\nax1.plot(time, df_coli.iloc[3][:-2])\nPxx, freqs, bins, im = ax2.specgram(df_jejuni.iloc[2][:-2])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:51.756749Z","iopub.execute_input":"2022-02-23T00:33:51.757069Z","iopub.status.idle":"2022-02-23T00:33:52.108558Z","shell.execute_reply.started":"2022-02-23T00:33:51.757025Z","shell.execute_reply":"2022-02-23T00:33:52.107535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Escherichia_fergusonii","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows=2)\nax1.plot(time, df_fergu.iloc[0][:-2])\nPxx, freqs, bins, im = ax2.specgram(df_jejuni.iloc[2][:-2])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:52.110304Z","iopub.execute_input":"2022-02-23T00:33:52.110624Z","iopub.status.idle":"2022-02-23T00:33:52.444141Z","shell.execute_reply.started":"2022-02-23T00:33:52.110581Z","shell.execute_reply":"2022-02-23T00:33:52.443255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows=2)\nax1.plot(time, df_fergu.iloc[1][:-2])\nPxx, freqs, bins, im = ax2.specgram(df_jejuni.iloc[2][:-2])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:52.445594Z","iopub.execute_input":"2022-02-23T00:33:52.446101Z","iopub.status.idle":"2022-02-23T00:33:52.766504Z","shell.execute_reply.started":"2022-02-23T00:33:52.446067Z","shell.execute_reply":"2022-02-23T00:33:52.765926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## X y Training dataset and Testing dataset","metadata":{}},{"cell_type":"code","source":"X = train_df.drop(columns=[TARGET_FEATURE_NAME, 'sample_weight'])\ny = train_df[[TARGET_FEATURE_NAME]]\nsample_weight = train_df['sample_weight']\n\nX_submission = test_data.loc[:,X.columns]\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:33:52.767668Z","iopub.execute_input":"2022-02-23T00:33:52.768536Z","iopub.status.idle":"2022-02-23T00:33:53.091851Z","shell.execute_reply.started":"2022-02-23T00:33:52.768473Z","shell.execute_reply":"2022-02-23T00:33:53.091102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Undersampling\nFor experiment measurements","metadata":{}},{"cell_type":"code","source":"def sampling_size_params(labels, sampling_max_size = SAMPLE):\n    ''' Return sampling parameters {labels: sample_size}'''\n    sampling_key, sampling_count = np.unique(labels, return_counts=True)\n    sampling_count[sampling_count > sampling_max_size] = sampling_max_size\n    zip_iterator = zip(sampling_key, sampling_count)\n    return dict(zip_iterator)\n\n# not minority\nsampling_params = sampling_size_params(y, SAMPLE)\n# sampling_params['Escherichia_coli'] = sampling_params['Escherichia_coli'] + 1\nundersample = RandomUnderSampler(\n    sampling_strategy=sampling_params, random_state=RANDOM_STATE)\n\nX, y = undersample.fit_resample(X, y)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:53.093176Z","iopub.execute_input":"2022-02-23T00:33:53.093944Z","iopub.status.idle":"2022-02-23T00:33:55.12257Z","shell.execute_reply.started":"2022-02-23T00:33:53.093892Z","shell.execute_reply":"2022-02-23T00:33:55.121602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare for multiclass classification\ny_cat = le.fit_transform(y[TARGET_FEATURE_NAME]) # y to categorical","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:55.123918Z","iopub.execute_input":"2022-02-23T00:33:55.124164Z","iopub.status.idle":"2022-02-23T00:33:55.167393Z","shell.execute_reply.started":"2022-02-23T00:33:55.124134Z","shell.execute_reply":"2022-02-23T00:33:55.166525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CSV_HEADER = list(train_data.columns[:])\n\nTARGET_FEATURE_LABELS = np.unique(y_cat)\n\nNUMERIC_FEATURE_NAMES = list(X.columns[:])\n\nCATEGORICAL_FEATURES_WITH_VOCABULARY = {}\n\nCATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n\nFEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n\nCOLUMN_DEFAULTS = [\n    [0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else [\"NA\"]\n    for feature_name in CSV_HEADER\n]\n\nNUM_CLASSES = len(TARGET_FEATURE_LABELS)\n\nINPUT_SHAPE = X.shape[-1]\nOUTPUT_SHAPE = le.classes_.shape[-1]\nprint(f'No. of features: {INPUT_SHAPE}')\nprint(f'Output shape: {OUTPUT_SHAPE}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:55.174116Z","iopub.execute_input":"2022-02-23T00:33:55.174406Z","iopub.status.idle":"2022-02-23T00:33:55.187971Z","shell.execute_reply.started":"2022-02-23T00:33:55.174376Z","shell.execute_reply":"2022-02-23T00:33:55.187084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del duplicates_train\ndel vc\ndel dedup_train\n# del train_data\ndel train_df\ndel df_coli\ndel df_fergu\ndel df_jejuni\n\ngc.collect()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:55.189087Z","iopub.execute_input":"2022-02-23T00:33:55.189834Z","iopub.status.idle":"2022-02-23T00:33:56.743291Z","shell.execute_reply.started":"2022-02-23T00:33:55.189788Z","shell.execute_reply":"2022-02-23T00:33:56.74243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model and Create Submissions #\n\nOnce you're satisfied with everything, it's time to create your final predictions! This cell will:\n- use the best trained model to make predictions from the test set\n- save the predictions to a CSV file\n\n$Softmax: \\sigma(z_i) = \\frac{e^{z_{i}}}{\\sum_{j=1}^K e^{z_{j}}} \\ \\ \\ for\\ i=1,2,\\dots,K$\n\nK - number of classes\n\n$z_i$ - is a vector containing the scores of each class for the instance z.\n\n$\\sigma(z_i)$ - is the estimated probability that the instance z belongs to class K, given the scores of each class for that instance.\n\n$Relu(z) = max(0, z)$\n\nBinary Cross Entropy: $-{(y\\log(p) + (1 - y)\\log(1 - p))}$\n\nFor multiclass classification, we calculate a separate loss for each class label per observation and sum the result.\n\n$-\\sum_{c=1}^My_{o,c}\\log(p_{o,c})$\n\n\n    M - number of classes\n\n    log - the natural log\n\n    y - binary indicator (0 or 1) if class label c is the correct classification for observation o\n\n    p - predicted probability observation o is of class c\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import make_column_selector, ColumnTransformer, TransformedTargetRegressor\n\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier, StackingClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:56.744416Z","iopub.execute_input":"2022-02-23T00:33:56.744611Z","iopub.status.idle":"2022-02-23T00:33:57.912553Z","shell.execute_reply.started":"2022-02-23T00:33:56.744588Z","shell.execute_reply":"2022-02-23T00:33:57.911696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Models","metadata":{}},{"cell_type":"code","source":"def build_estimator_stack(estimator_stack=[], seed=RANDOM_STATE):\n    models = []\n    \n    if GPU:\n        param_xgb = {\n                    'objective' : 'multi:softprob',\n                    'eval_metric' : 'mlogloss',\n                    'tree_method' : 'gpu_hist',\n                    'use_label_encoder': False,\n                    'n_estimators': N_ESTIMATORS,\n                    'random_state': seed\n                 }\n        param_cat = {\n                    'loss_function' : 'MultiClass', # MultiClassOneVsAll\n                    'eval_metric': 'MultiClass',\n                    'task_type' : 'GPU',            \n                    'n_estimators': N_ESTIMATORS,\n                    'random_state': seed,\n                    'verbose': VERBOSE\n                 }\n        param_lgb = {\n                    'objective' : 'multiclass',\n                    'n_estimators': N_ESTIMATORS,\n                    'device' : 'gpu',\n                    'random_state': seed\n                 }\n    else: #CPU\n        param_xgb = {\n                    'objective' : 'multi:softprob',\n                    'eval_metric' : 'mlogloss',\n                    'tree_method' : 'hist',\n                    'use_label_encoder': False,\n                    'n_estimators': N_ESTIMATORS,\n                    'random_state': seed\n                 }\n        param_cat = {\n                    'loss_function' : 'MultiClass',\n                    'eval_metric': 'MultiClass',\n                    'n_estimators': N_ESTIMATORS,\n                    'random_state': seed,\n                    'verbose': VERBOSE\n                 }\n        param_lgb = {\n                    'objective' : 'multiclass',\n                    'n_estimators': N_ESTIMATORS,\n                    'random_state': seed\n                 }\n        \n    if PRODUCTION:\n        models = [\n                    ExtraTreesClassifier(\n                        n_estimators=N_ESTIMATORS,\n                        random_state=seed,\n                        verbose=VERBOSE\n                    ),\n                    ExtraTreesClassifier(\n                        n_estimators=N_ESTIMATORS,\n                        random_state=seed+FOLDS,\n                        verbose=VERBOSE\n                    ),\n                   ]\n    else: # test run\n        for tree in range(0, TREES):\n            models.append(\n                ExtraTreesClassifier(\n                        n_estimators=N_ESTIMATORS,\n                        n_jobs=-1,\n                        random_state=seed+tree,\n                        verbose=VERBOSE\n                    ),\n            )\n\n#                     SVC(\n#                         gamma='scale',\n#                         class_weight='balanced',\n#                         probability=True,\n#                         random_state=seed+FOLDS+FOLDS,\n#                         verbose=VERBOSE\n#                     ),\n#                     XGBClassifier(**param_xgb),\n#                     lgb.LGBMClassifier(**param_lgb),\n#                     CatBoostClassifier(**param_cat),\n\n    for i, model in enumerate(models):\n        model_name = type(model).__name__\n#         print(f'****************** Stacking {model_name:>24}_{i} *************************')\n        estimator_stack.append((f'{model_name}_{i}', model))\n        \n    return estimator_stack","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:57.914226Z","iopub.execute_input":"2022-02-23T00:33:57.914737Z","iopub.status.idle":"2022-02-23T00:33:57.930216Z","shell.execute_reply.started":"2022-02-23T00:33:57.914687Z","shell.execute_reply":"2022-02-23T00:33:57.929084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacker pipeline with CV\nDecision tree does not require feature scaling.\n\n**sklearn.linear_model.LogisticRegressionCV**\n\nclass_weight: dict or ‘balanced’, default=None\n\n    Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.\n\n    The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).\n\n    Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.","metadata":{}},{"cell_type":"code","source":"def build_stacking_classifier(estimator_stack, seed=RANDOM_STATE):\n    \n    # X pipeline StandardScaler MinMaxScaler RobustScaler , class_weight='balanced', Cs= , n_jobs=1 , weights=[1.]*FOLDS , weights=weights\n#     stacking_classifier = make_pipeline(\n#         StackingClassifier(estimators=estimator_stack, final_estimator=LogisticRegressionCV(multi_class='multinomial', max_iter=10000, cv=FOLDS, random_state=seed), cv=FOLDS, n_jobs=1, verbose=VERBOSE)\n    voting_classifier = VotingClassifier(estimators=estimator_stack, voting='soft', verbose=VERBOSE)\n#     )\n    return voting_classifier","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:57.931352Z","iopub.execute_input":"2022-02-23T00:33:57.932181Z","iopub.status.idle":"2022-02-23T00:33:57.947312Z","shell.execute_reply.started":"2022-02-23T00:33:57.932124Z","shell.execute_reply":"2022-02-23T00:33:57.946442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"markdown","source":"Sample weight distribution","metadata":{}},{"cell_type":"code","source":"np.unique(sample_weight, return_counts=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:33:57.948487Z","iopub.execute_input":"2022-02-23T00:33:57.948732Z","iopub.status.idle":"2022-02-23T00:33:57.965196Z","shell.execute_reply.started":"2022-02-23T00:33:57.948702Z","shell.execute_reply":"2022-02-23T00:33:57.964591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross-validation\nWhile V-fold cross-validation does have inflated variance, its bias is fairly low when V is 10 or more.\n\n![Variance/bias differences in resampling schemes](data:image/png;base64,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)\n\nFour possible variance/bias cases are represented. We will that the model metric being measured here is better when the value is large and that the true value is represented by the green vertical line. The upper right right panel demonstrates a pessimistic bias since the values tend to be smaller than the true value while the panel below in the lower right shows a resampling scheme that has relatively low variance and the center of its distribution is on target with the true value. ","metadata":{}},{"cell_type":"markdown","source":"## Test prediction","metadata":{}},{"cell_type":"code","source":"%%time\nfrom tqdm import tqdm\n\nmax_valid = (len(y_cat) // FOLDS) # Max consistent validation shape for dot product\n# Reset\n# estimator_stack = []\nscores = []\npreds_test = []\npreds_valid_f = {}\npredictions = []\n\nkfolds = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_id, valid_id) in enumerate(tqdm(kfolds.split(X, y_cat), total=kfolds.get_n_splits(), desc=\"k-fold\" )):  \n    X_train = X.iloc[train_id]\n    y_train = y_cat[train_id]\n    X_valid = X.iloc[valid_id]\n    y_valid = y_cat[valid_id]\n    \n    # Build model\n    estimator_stack = []\n    estimator_stack = build_estimator_stack(estimator_stack, seed=RANDOM_STATE + fold*TREES)\n    eclf = build_stacking_classifier(estimator_stack=estimator_stack, seed=RANDOM_STATE + fold)\n#     eclf = ExtraTreesClassifier(\n#         n_estimators=N_ESTIMATORS,\n#         class_weight='balanced',\n#         random_state=RANDOM_STATE + fold*7,\n#         verbose=VERBOSE\n#     )\n    \n    if SAMPLE_WEIGHT:\n        sample_weight_train = sample_weight[train_id]\n        sample_weight_valid = sample_weight[valid_id]\n    else:\n        sample_weight_train = None\n        sample_weight_valid = None\n    # Train\n    eclf = eclf.fit(X=X_train, y=y_train, sample_weight=sample_weight_train)\n    \n    # Validation\n    preds_valid = eclf.predict_proba(X_valid)\n    score_valid = accuracy_score(y_valid, np.argmax(preds_valid, axis=1), sample_weight=sample_weight_valid)\n    \n    predictions.append([y_valid[:max_valid], preds_valid[:max_valid]])\n    index_valid = X_valid.index.tolist()\n    preds_valid_f.update(dict(zip(index_valid, le.inverse_transform(np.argmax(preds_valid, axis=1)))))\n    \n    print(\"Fold:\", fold + 1, \"Accuracy:\", score_valid, \"logloss:\", log_loss(y_valid, preds_valid, sample_weight=sample_weight_valid), \"valid size:\", len(y_valid))\n    scores.append(score_valid)\n    \n    # Test dataset prediction\n    preds_test.append(eclf.predict_proba(X_submission))\n    #     estimator_stack.append(eclf)\n    del eclf\n    gc.collect()\n\nplt.boxplot(scores, showmeans=True)\nplt.show()\nprint(\"Mean accuracy score:\", np.array(scores).mean())","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:33:57.966601Z","iopub.execute_input":"2022-02-23T00:33:57.9674Z","iopub.status.idle":"2022-02-23T00:36:59.362719Z","shell.execute_reply.started":"2022-02-23T00:33:57.967365Z","shell.execute_reply":"2022-02-23T00:36:59.361994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross Validation Score","metadata":{}},{"cell_type":"markdown","source":"But instead of just looking at the mean accuracy across the 10 cross-validation folds, let's plot all 10 scores for each model, along with a box plot highlighting the lower and upper quartiles, and \"whiskers\" showing the extent of the scores. Note that the `boxplot()` function detects outliers (called \"fliers\") and does not include them within the whiskers. Specifically, if the lower quartile is $Q_1$ and the upper quartile is $Q_3$, then the interquartile range $IQR = Q_3 - Q_1$ (this is the box's height), and any score lower than $Q_1 - 1.5 \\times IQR$ is a flier, and so is any score greater than $Q3 + 1.5 \\times IQR$.","metadata":{}},{"cell_type":"code","source":"# %%time\n# if PRODUCTION:\n#     X_train, X_test, y_train, y_test = train_test_split(X, y_cat, stratify=y_cat, test_size=0.0001, random_state=RANDOM_STATE)\n# else: # test run\n#     X_train, X_test, y_train, y_test = train_test_split(X, y_cat, stratify=y_cat, test_size=VALIDATION_SPLIT, random_state=RANDOM_STATE)\n# # Reset\n# estimator_stack = []\n\n# # Build model\n# estimator_stack = build_estimator_stack(estimator_stack)\n# eclf = build_stacking_classifier(estimator_stack=estimator_stack, seed=RANDOM_STATE)\n\n# if SAMPLE_WEIGHT:\n#     sample_weight_train = sample_weight[train_id]\n#     sample_weight_valid = sample_weight[valid_id]\n# else:\n#     sample_weight_train = None\n#     sample_weight_valid = None\n\n# # Train\n# eclf = eclf.fit(X_train, y_train)\n# preds_test=[]\n# # Predict test dataset\n# preds_test.append(eclf.predict_proba(X_submission.values))\n# # resets\n# preds_valid_f = {}\n# index_valid = X_test.index.tolist()\n# preds_valid = eclf.predict_proba(X_test)\n# preds_valid_f.update(dict(zip(index_valid, le.inverse_transform(np.argmax(preds_valid, axis=1)))))\n# accuracy_score(y_test, np.argmax(preds_valid, axis=1))\n\n# log_loss(y_test, preds_valid)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:36:59.364328Z","iopub.execute_input":"2022-02-23T00:36:59.364783Z","iopub.status.idle":"2022-02-23T00:36:59.36921Z","shell.execute_reply.started":"2022-02-23T00:36:59.364736Z","shell.execute_reply":"2022-02-23T00:36:59.368599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_loss_scores = []\naccuracy_scores = []\ndef log_loss_func(weights, verbose=VERBOSE):\n    ''' scipy minimize will pass the weights as a numpy array '''\n    final_prediction = 0\n    for weight, prediction in zip(weights, predictions):\n        final_prediction += weight*prediction[1]\n    \n    if verbose > 0:\n        print(f'log_loss: {log_loss(prediction[0], final_prediction)}')\n        \n    log_loss_score = log_loss(prediction[0], final_prediction)\n    log_loss_scores.append(log_loss_score)\n    return log_loss_score","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:36:59.37052Z","iopub.execute_input":"2022-02-23T00:36:59.370932Z","iopub.status.idle":"2022-02-23T00:36:59.386811Z","shell.execute_reply.started":"2022-02-23T00:36:59.370899Z","shell.execute_reply":"2022-02-23T00:36:59.385911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Average Weight Folds\n\nLets see if average weight folds across fold validation translate to test dataset as well.\nDid not work well. TBA","metadata":{}},{"cell_type":"code","source":"%time\n\nfrom scipy.optimize import minimize\n\n\n#the algorithms need a starting value, right not we chose 0.5 for all weights\n#its better to choose many random starting points and run minimize a few times\nstarting_values = [0.5]*len(predictions)\n#adding constraints  and a different solver as suggested by user 16universe\n#https://kaggle2.blob.core.windows.net/forum-message-attachments/75655/2393/otto%20model%20weights.pdf?sv=2012-02-12&se=2015-05-03T21%3A22%3A17Z&sr=b&sp=r&sig=rkeA7EJC%2BiQ%2FJ%2BcMpcA4lYQLFh6ubNqs2XAkGtFsAv0%3D\ncons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n#our weights are bound between 0 and 1\nbounds = [(1/(FOLDS+FOLDS*0.02),1.05/FOLDS)]*len(predictions)\n\nres = minimize(log_loss_func, starting_values, method='Powell', bounds=bounds, constraints=cons) #SLSQP\nprint('\\nEnsemble Score: {best_score}'.format(best_score=res['fun']))\nprint('Best Weights: {weights}'.format(weights=res['x']))\nplt.plot(log_loss_scores)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:36:59.388194Z","iopub.execute_input":"2022-02-23T00:36:59.388821Z","iopub.status.idle":"2022-02-23T00:37:02.164125Z","shell.execute_reply.started":"2022-02-23T00:36:59.388777Z","shell.execute_reply":"2022-02-23T00:37:02.163133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logistic Loss optimization plot","metadata":{}},{"cell_type":"code","source":"# Build model\n# eclf = build_stacking_classifier(estimator_stack=estimator_stack, weights=res['x'], seed=RANDOM_STATE)\n# preds_test=[]\n# Predict test dataset\n# preds_test.append(eclf.predict_proba(X_submission.values))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:02.165235Z","iopub.execute_input":"2022-02-23T00:37:02.165473Z","iopub.status.idle":"2022-02-23T00:37:02.169794Z","shell.execute_reply.started":"2022-02-23T00:37:02.165446Z","shell.execute_reply":"2022-02-23T00:37:02.169179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def log_loss_prediction(weights):\n    ''' scipy minimize will pass the weights as a numpy array '''\n    final_prediction = 0\n    for weight, prediction in zip(weights, preds_test):\n        final_prediction += weight*prediction\n    return final_prediction","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:02.171001Z","iopub.execute_input":"2022-02-23T00:37:02.171219Z","iopub.status.idle":"2022-02-23T00:37:02.180949Z","shell.execute_reply.started":"2022-02-23T00:37:02.171192Z","shell.execute_reply":"2022-02-23T00:37:02.180362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if AVERAGE_WEIGHTED_FOLD:\n    preds_final=[]\n    preds_final.append(log_loss_prediction(res['x']))\nelse:\n    preds_final=preds_test","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:37:02.182115Z","iopub.execute_input":"2022-02-23T00:37:02.182542Z","iopub.status.idle":"2022-02-23T00:37:02.193434Z","shell.execute_reply.started":"2022-02-23T00:37:02.182493Z","shell.execute_reply":"2022-02-23T00:37:02.192635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_y_hat = []\nfor key, value in sorted(preds_valid_f.items()):\n    oof_y_hat.append(value)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:02.194762Z","iopub.execute_input":"2022-02-23T00:37:02.195186Z","iopub.status.idle":"2022-02-23T00:37:02.265323Z","shell.execute_reply.started":"2022-02-23T00:37:02.195136Z","shell.execute_reply":"2022-02-23T00:37:02.2639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion matrix\n\n$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$\n\n$Precision = \\frac{TP}{TP+FP}$\n\n$Recall = \\frac{TP}{TP+FN}$\n\n$F1 = \\frac{2*Precision*Recall}{Precision+Recall} = \\frac{2*TP}{2*TP+FP+FN}$\n\nMost of the confusion between Escherichia_coli and Escherichia_fergusonii due to GCD >= 1000 collision. Lets see how postprocessing helps to seperate these two classes.","metadata":{}},{"cell_type":"code","source":"# create confusion matrix, calculate accuracy,recall & precision\ncm = pd.DataFrame(data = confusion_matrix(le.inverse_transform(y_cat), oof_y_hat, labels = le.classes_), index = le.classes_, columns = le.classes_)\nplot_cm(cm)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:02.266706Z","iopub.execute_input":"2022-02-23T00:37:02.267181Z","iopub.status.idle":"2022-02-23T00:37:06.333174Z","shell.execute_reply.started":"2022-02-23T00:37:02.267142Z","shell.execute_reply":"2022-02-23T00:37:06.332285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_cm_error(confusion_matrix(le.inverse_transform(y_cat), oof_y_hat, labels = le.classes_))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:06.334698Z","iopub.execute_input":"2022-02-23T00:37:06.335166Z","iopub.status.idle":"2022-02-23T00:37:07.840211Z","shell.execute_reply.started":"2022-02-23T00:37:06.335115Z","shell.execute_reply":"2022-02-23T00:37:07.839307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Postprocessing\nMean of Folds predictions","metadata":{}},{"cell_type":"code","source":"y_prob = sum(preds_final) / len(preds_final)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:37:07.841933Z","iopub.execute_input":"2022-02-23T00:37:07.842244Z","iopub.status.idle":"2022-02-23T00:37:07.858474Z","shell.execute_reply.started":"2022-02-23T00:37:07.842206Z","shell.execute_reply":"2022-02-23T00:37:07.857471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Weighted Average using distribution\nhttps://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n\nThere are differences in error bias between train dataset and test dataset. This is due to data compression and data loss.\n\nHypothesis:\n- The target distribution of train dataset and test dataset remain the same.","metadata":{}},{"cell_type":"markdown","source":"## Distribution Before:","metadata":{}},{"cell_type":"code","source":"pd.Series(le.inverse_transform(np.argmax(y_prob, axis=1)), index=X_submission.index).value_counts().sort_index() / len(X_submission) * 100","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:07.860109Z","iopub.execute_input":"2022-02-23T00:37:07.860451Z","iopub.status.idle":"2022-02-23T00:37:07.892107Z","shell.execute_reply.started":"2022-02-23T00:37:07.860409Z","shell.execute_reply":"2022-02-23T00:37:07.891229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution Target\n\n- If hypothesis is correct, overfitting to public LB should give better results. \n- Silly me, I should target distribution of private distribution 10%. public LB is just some random distribution.\n\nBacteroides_fragilis         9.974\nCampylobacter_jejuni        10.210\nEnterococcus_hirae           9.909\nEscherichia_coli             9.773\nEscherichia_fergusonii       9.909\nKlebsiella_pneumoniae        9.727\nSalmonella_enterica         10.345\nStaphylococcus_aureus       10.089\nStreptococcus_pneumoniae    10.150\nStreptococcus_pyogenes       9.914","metadata":{}},{"cell_type":"code","source":"target_distribution[0] = 10.\ntarget_distribution[1] = 10.\ntarget_distribution[2] = 10.\ntarget_distribution[3] = 10.\ntarget_distribution[4] = 10.\ntarget_distribution[5] = 10.\ntarget_distribution[6] = 10.\ntarget_distribution[7] = 10.\ntarget_distribution[8] = 10.\ntarget_distribution[9] = 10.","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:07.893772Z","iopub.execute_input":"2022-02-23T00:37:07.894258Z","iopub.status.idle":"2022-02-23T00:37:07.901429Z","shell.execute_reply.started":"2022-02-23T00:37:07.894203Z","shell.execute_reply":"2022-02-23T00:37:07.900815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_distribution","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:07.90257Z","iopub.execute_input":"2022-02-23T00:37:07.90358Z","iopub.status.idle":"2022-02-23T00:37:07.917322Z","shell.execute_reply.started":"2022-02-23T00:37:07.903542Z","shell.execute_reply":"2022-02-23T00:37:07.916479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial Diff","metadata":{}},{"cell_type":"code","source":"# Credit from https://www.kaggle.com/sfktrkl/tps-feb-2022\ndef get_diff(tune):\n    y_pred_tuned = np.argmax(y_prob + tune, axis=1)\n    return target_distribution - pd.Series(le.inverse_transform(y_pred_tuned)).value_counts().sort_index() / len(X_submission) * 100","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:07.918414Z","iopub.execute_input":"2022-02-23T00:37:07.919166Z","iopub.status.idle":"2022-02-23T00:37:07.926187Z","shell.execute_reply.started":"2022-02-23T00:37:07.919131Z","shell.execute_reply":"2022-02-23T00:37:07.925502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tune = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\ndiff = get_diff(tune)\nprint(diff)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:07.929435Z","iopub.execute_input":"2022-02-23T00:37:07.92968Z","iopub.status.idle":"2022-02-23T00:37:07.963621Z","shell.execute_reply.started":"2022-02-23T00:37:07.92965Z","shell.execute_reply":"2022-02-23T00:37:07.962718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution tuning\n\nBound distribution by class accuracy.","metadata":{}},{"cell_type":"markdown","source":"## Distribution After:","metadata":{}},{"cell_type":"code","source":"%%time\n\ndef dist_diff_loss_func(weights):\n    \"\"\"Loss function to be minimized (square/sqrt.abs.get_diff.sum)\"\"\"\n    loss = np.square(abs(get_diff(weights)).sum())\n    return loss\n\nx0 = [0] * len(le.classes_) # Initial weights\nif DIST_BOUND:\n    # Bounded by classes accuracy.\n    cm = confusion_matrix(le.inverse_transform(y_cat), oof_y_hat, labels = le.classes_)\n    acc = cm / cm.sum(axis = 0 )\n    bounds = tuple((-(1-a[i])*DIST_THRESHOLD, (1-a[i])*DIST_THRESHOLD) for i, a in enumerate(acc))\nelse:\n    bounds = None\nres = minimize(dist_diff_loss_func, x0, method='Powell', bounds=bounds, options={'disp':True})\nprint(f'\\nBest weights: {res.x}')\nprint(f'\\nDiff sum(): {abs(get_diff(res.x)).sum()}')\n\ny_proba_tuned = y_prob.copy()\ny_proba_tuned[:] += res.x\ny_pred_tuned = np.argmax(y_proba_tuned, axis=1)\ny_pred_tuned = le.inverse_transform(y_pred_tuned)\n\nprint(f'\\nDistribution After:')\npd.Series(y_pred_tuned, index=X_submission.index).value_counts().sort_index() / len(X_submission) * 100","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:07.964939Z","iopub.execute_input":"2022-02-23T00:37:07.965173Z","iopub.status.idle":"2022-02-23T00:37:17.758491Z","shell.execute_reply.started":"2022-02-23T00:37:07.965144Z","shell.execute_reply":"2022-02-23T00:37:17.75757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(INPUT + '/sample_submission.csv')\nsub[TARGET_FEATURE_NAME] = y_pred_tuned","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:37:17.760211Z","iopub.execute_input":"2022-02-23T00:37:17.760678Z","iopub.status.idle":"2022-02-23T00:37:17.847596Z","shell.execute_reply.started":"2022-02-23T00:37:17.760632Z","shell.execute_reply":"2022-02-23T00:37:17.846551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the distribution of the test predictions vs training set","metadata":{}},{"cell_type":"code","source":"# Plot the distribution of the test predictions vs training set\nplt.figure(figsize=(20,6))\nplt.hist(y[TARGET_FEATURE_NAME], bins = np.linspace(0, 10, 11), density = True, label = 'Training labels')\nplt.hist(sub[TARGET_FEATURE_NAME], bins = np.linspace(0, 10, 11), density = True, rwidth = 0.7, label = 'Test predictions')\n\nplt.xlabel(TARGET_FEATURE_NAME)\nplt.ylabel('Frequency')\nplt.gca().yaxis.set_major_formatter(PercentFormatter())\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:17.849415Z","iopub.execute_input":"2022-02-23T00:37:17.849716Z","iopub.status.idle":"2022-02-23T00:37:18.274674Z","shell.execute_reply.started":"2022-02-23T00:37:17.849672Z","shell.execute_reply":"2022-02-23T00:37:18.27373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_x_labels(ax):\n    for rect in ax.patches:\n        height = rect.get_height()\n        ax.annotate(f'{int(height)}', xy=(rect.get_x()+rect.get_width()/2, height), \n                    xytext=(0, 5), textcoords='offset points', ha='center', va='bottom') \n\n# Plot the distribution of the test predictions\nfig, ax = plt.subplots(2,1,figsize = (20,10))\nsns.countplot(x = sub[TARGET_FEATURE_NAME], ax = ax[0], orient = \"h\").set_title(\"Prediction\")\nplot_x_labels(ax[0])\n# Plot the distribution of the training set\nsns.countplot(x = y[TARGET_FEATURE_NAME], ax = ax[1], orient = \"h\").set_title(\"Training labels\")\nplot_x_labels(ax[1])\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:18.276074Z","iopub.execute_input":"2022-02-23T00:37:18.276336Z","iopub.status.idle":"2022-02-23T00:37:19.409796Z","shell.execute_reply.started":"2022-02-23T00:37:18.276301Z","shell.execute_reply":"2022-02-23T00:37:19.408976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From GOAT\n\nhttps://www.kaggle.com/ambrosm/tpsfeb22-03-clustering-improves-the-predictions/notebook","metadata":{}},{"cell_type":"code","source":"from math import factorial\n\nelements = [e for e in X.columns if e != ID and e != TARGET_FEATURE_NAME]\n\ndef bias(w, x, y, z):\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ndef bias_of(s):\n    w = int(s[1:s.index('T')])\n    x = int(s[s.index('T')+1:s.index('G')])\n    y = int(s[s.index('G')+1:s.index('C')])\n    z = int(s[s.index('C')+1:])\n    return factorial(10) / (factorial(w) * factorial(x) * factorial(y) * factorial(z) * 4**10)\n\ntrain_i = pd.DataFrame({col: ((train_data[col] + bias_of(col)) * 1000000).round().astype(int) for col in elements})\ntest_i = pd.DataFrame({col: ((X_submission[col] + bias_of(col)) * 1000000).round().astype(int) for col in elements})\n\ndef gcd_of_all(df_i):\n    gcd = df_i[elements[0]]\n    for col in elements[1:]:\n        gcd = np.gcd(gcd, df_i[col])\n    return gcd\n\ntrain_data['gcd'] = gcd_of_all(train_i)\nX_submission['gcd'] = gcd_of_all(test_i)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:19.410886Z","iopub.execute_input":"2022-02-23T00:37:19.411095Z","iopub.status.idle":"2022-02-23T00:37:22.139563Z","shell.execute_reply.started":"2022-02-23T00:37:19.411069Z","shell.execute_reply":"2022-02-23T00:37:22.138697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA, TruncatedSVD\n\ndef pca_gcd10_full(df, target, title):\n    \"\"\"Plot a 2d projection of all points of df with gcd = 10, colored by target\"\"\"\n    subset = df[df.gcd == 10]\n    pred_subset = le.transform(target)[df.gcd == 10]\n    # Compute the PCA\n    pca3 = TruncatedSVD(n_components=10, random_state=1)\n    pca3.fit(subset[elements])\n\n    # Transform the data so that the components can be analyzed\n    Xt_tr3 = pca3.transform(subset[elements])\n\n    # Plot a scattergram, projected to two PCA components\n    d0, d1 = 1, 2\n    plt.scatter(Xt_tr3[:,d0], Xt_tr3[:,d1], c=pred_subset, cmap='tab10', s=1)\n    plt.title(title)\n    \nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_full(train_data, train_data[TARGET_FEATURE_NAME], 'Training, gcd=10')\nplt.subplot(1, 2, 2)\npca_gcd10_full(X_submission, sub[TARGET_FEATURE_NAME], 'Current submission, gcd=10')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:22.141019Z","iopub.execute_input":"2022-02-23T00:37:22.141235Z","iopub.status.idle":"2022-02-23T00:37:24.780613Z","shell.execute_reply.started":"2022-02-23T00:37:22.141209Z","shell.execute_reply":"2022-02-23T00:37:24.779546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pca_gcd10_selection(df, target, title, clustering, innermost, label1=3, label2=4, seed=RANDOM_STATE):\n    \"\"\"Plot a 2d projection of certain points of df, colored by target\n    or by a clustering, and add the new clustering labels to df.\n    \n    We select the two innermost clusters with gcd = 10 of bacteria 3 and 4\"\"\"\n    # Get the subset\n    subset = df[df.gcd == 10].copy()\n    subset['radius'] = np.sqrt(np.square(subset[elements]).sum(axis=1))\n    subset['pred'] = le.transform(target)[df.gcd == 10]\n    mean_radius = subset.radius.groupby(subset.pred).mean()\n    mean_radius.name = 'mean_radius'\n    subset = subset.merge(mean_radius, left_on='pred', right_index=True).sort_index()\n#     print(mean_radius)\n    if innermost:\n        selection = ((subset.radius < subset.mean_radius * 0.388) &\n                     subset.pred.isin([label1, label2]))\n    else:\n        selection = ((subset.radius >= subset.mean_radius * 0.388) &\n                     (subset.radius < subset.mean_radius * 0.64) & \n                     subset.pred.isin([label1, label2]))\n    subset = subset[selection]\n#     print(subset.groupby(subset.pred).count())\n\n    if clustering:\n        # Cluster the data into two clusters\n        km = KMeans(n_clusters=2, random_state=1)\n        #km = AgglomerativeClustering(n_clusters=2)\n        km.fit(subset[elements])\n        # For every cluster, predict the most frequent label for all cluster members\n        new_pred = subset.pred.groupby(km.labels_).transform(lambda s: [mode(s)[0][0]] * len(s))\n        print(f\"Relabeled {(new_pred != subset.pred).sum()} samples\")\n\n    # Compute the PCA\n    pca3 = TruncatedSVD(n_components=10, random_state=seed)\n    pca3.fit(subset[elements])\n\n    # Transform the data so that the components can be analyzed\n    Xt_tr3 = pca3.transform(subset[elements])\n\n    # Plot a scattergram, projected to two PCA components\n    d0, d1 = 2, 1\n    plt.scatter(Xt_tr3[:,d0], Xt_tr3[:,d1],\n                cmap=ListedColormap(plt.get_cmap('tab10').colors[3:5]),\n                c=(new_pred if clustering else subset.pred),\n                s=25)\n    plt.title(title)\n    if clustering:\n        selected = pd.Series(False, index=df.index)\n        selected.loc[df.gcd == 10] = selection\n        df.loc[selected, 'new_pred'] = new_pred","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:24.782387Z","iopub.execute_input":"2022-02-23T00:37:24.782681Z","iopub.status.idle":"2022-02-23T00:37:24.799537Z","shell.execute_reply.started":"2022-02-23T00:37:24.782644Z","shell.execute_reply":"2022-02-23T00:37:24.798504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pca_gcd1000_selection(df, target, title, clustering, innermost, label1=3, label2=4):\n    \"\"\"Plot a 2d projection of certain points of df, colored by target\n    or by a clustering, and add the new clustering labels to df.\n    \n    We select the two innermost clusters with gcd = 10 of bacteria 3 and 4\"\"\"\n    # Get the subset\n    subset = df[df.gcd == 1000].copy()\n    subset['radius'] = np.sqrt(np.square(subset[elements]).sum(axis=1))\n    subset['pred'] = le.transform(target)[df.gcd == 1000]\n    mean_radius = subset.radius.groupby(subset.pred).mean()\n    mean_radius.name = 'mean_radius'\n    subset = subset.merge(mean_radius, left_on='pred', right_index=True).sort_index()\n    print(mean_radius)\n    if innermost:\n        selection = ((subset.radius < subset.mean_radius * 0.933) &\n                     subset.pred.isin([label1, label2]))\n    else:\n        selection = ((subset.radius >= subset.mean_radius * 0.173) &\n                     (subset.radius < subset.mean_radius * 0.87) & \n                     subset.pred.isin([label1, label2]))\n    subset = subset[selection]\n    print(subset)\n\n    if clustering:\n        # Cluster the data into two clusters\n#         km = KMeans(n_clusters=2, random_state=1)\n        km = AgglomerativeClustering(n_clusters=2)\n        km.fit(subset[elements])\n        # For every cluster, predict the most frequent label for all cluster members\n        new_pred = subset.pred.groupby(km.labels_).transform(lambda s: [mode(s)[0][0]] * len(s))\n        print(f\"Relabeled {(new_pred != subset.pred).sum()} samples\")\n\n    # Compute the PCA\n    pca3 = TruncatedSVD(n_components=10, random_state=1)\n    pca3.fit(subset[elements])\n\n    # Transform the data so that the components can be analyzed\n    Xt_tr3 = pca3.transform(subset[elements])\n\n    # Plot a scattergram, projected to two PCA components\n    d0, d1 = 2, 1\n    plt.scatter(Xt_tr3[:,d0], Xt_tr3[:,d1],\n                cmap=ListedColormap(plt.get_cmap('tab10').colors[3:5]),\n                c=(new_pred if clustering else subset.pred),\n                s=25)\n    plt.title(title)\n    if clustering:\n        selected = pd.Series(False, index=df.index)\n        selected.loc[df.gcd == 1000] = selection\n        df.loc[selected, 'new_pred'] = new_pred","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:24.80157Z","iopub.execute_input":"2022-02-23T00:37:24.802068Z","iopub.status.idle":"2022-02-23T00:37:24.819677Z","shell.execute_reply.started":"2022-02-23T00:37:24.802015Z","shell.execute_reply":"2022-02-23T00:37:24.818737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GCD-10 Innermost","metadata":{}},{"cell_type":"code","source":"from matplotlib.colors import ListedColormap\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\nfrom scipy.stats import mode\n\nlabel1=3\nlabel2=4\n\nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(train_data, train_data[TARGET_FEATURE_NAME], \n                    'Training, gcd=10: True labels',\n                    clustering=False, innermost=True, label1=label1,label2=label2)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(train_data, train_data[TARGET_FEATURE_NAME],\n                    'Training, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=True, label1=label1,label2=label2)\nplt.show()\n\nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(X_submission, sub[TARGET_FEATURE_NAME], \n                    'Test, gcd=10: Labels of submission',\n                    clustering=False, innermost=True, label1=label1,label2=label2)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(X_submission, sub[TARGET_FEATURE_NAME], \n                    'Test, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=True, label1=label1,label2=label2)\nplt.show()\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:24.820941Z","iopub.execute_input":"2022-02-23T00:37:24.821214Z","iopub.status.idle":"2022-02-23T00:37:27.250659Z","shell.execute_reply.started":"2022-02-23T00:37:24.821178Z","shell.execute_reply":"2022-02-23T00:37:27.250059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# subset = train_data[train_data.gcd == 10].copy()\n# subset['radius'] = np.sqrt(np.square(subset[elements]).sum(axis=1))\n# subset['pred'] = le.transform(train_data[TARGET_FEATURE_NAME])[train_data.gcd == 10]\n# mean_radius = subset.radius.groupby(subset.pred).mean()\n# mean_radius.name = 'mean_radius'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:27.25187Z","iopub.execute_input":"2022-02-23T00:37:27.252645Z","iopub.status.idle":"2022-02-23T00:37:27.257122Z","shell.execute_reply.started":"2022-02-23T00:37:27.252607Z","shell.execute_reply":"2022-02-23T00:37:27.256094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GCD-1000 Icant!","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\nlabel1=3\nlabel2=4\npca_gcd1000_selection(train_data, train_data[TARGET_FEATURE_NAME], \n                    'Training, gcd=1000: True labels',\n                    clustering=False, innermost=False, label1=label1,label2=label2)\nplt.subplot(1, 2, 2)\npca_gcd1000_selection(train_data, train_data[TARGET_FEATURE_NAME],\n                    'Training, gcd=1000: Labeled by clustering',\n                    clustering=False, innermost=False, label1=label1,label2=label2)\nplt.show()\n\nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd1000_selection(X_submission, sub[TARGET_FEATURE_NAME], \n                    'Test, gcd=1000: Labels of submission',\n                    clustering=False, innermost=False, label1=label1,label2=label2)\nplt.subplot(1, 2, 2)\npca_gcd1000_selection(X_submission, sub[TARGET_FEATURE_NAME], \n                    'Test, gcd=1000: Labeled by clustering',\n                    clustering=False, innermost=False, label1=label1,label2=label2)\nplt.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:27.258974Z","iopub.execute_input":"2022-02-23T00:37:27.259464Z","iopub.status.idle":"2022-02-23T00:37:29.023137Z","shell.execute_reply.started":"2022-02-23T00:37:27.25943Z","shell.execute_reply":"2022-02-23T00:37:29.022196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GCD-10 Second-to-innermost","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\n\nlabel1=3\nlabel2=4\npca_gcd10_selection(train_data, train_data[TARGET_FEATURE_NAME],\n                    'Training, gcd=10: True labels', \n                    clustering=False, innermost=False, label1=label1,label2=label2)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(train_data, train_data[TARGET_FEATURE_NAME], \n                    'Training, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=False, label1=label1,label2=label2)\nplt.show()\n\nplt.figure(figsize=(12,6))\nplt.subplot(1, 2, 1)\npca_gcd10_selection(X_submission, sub[TARGET_FEATURE_NAME],\n                    'Test, gcd=10: Labels of submission',\n                    clustering=False, innermost=False, label1=label1,label2=label2)\nplt.subplot(1, 2, 2)\npca_gcd10_selection(X_submission, sub[TARGET_FEATURE_NAME],\n                    'Test, gcd=10: Labeled by clustering',\n                    clustering=True, innermost=False, label1=label1,label2=label2)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:29.024758Z","iopub.execute_input":"2022-02-23T00:37:29.025454Z","iopub.status.idle":"2022-02-23T00:37:31.396648Z","shell.execute_reply.started":"2022-02-23T00:37:29.025402Z","shell.execute_reply":"2022-02-23T00:37:31.395985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = sub.set_index(ID, drop=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:31.397833Z","iopub.execute_input":"2022-02-23T00:37:31.398155Z","iopub.status.idle":"2022-02-23T00:37:31.403187Z","shell.execute_reply.started":"2022-02-23T00:37:31.398127Z","shell.execute_reply":"2022-02-23T00:37:31.402662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final submission","metadata":{}},{"cell_type":"code","source":"sub['new_pred'] = sub[TARGET_FEATURE_NAME]\nsub.loc[~X_submission.new_pred.isna(), 'new_pred'] = le.inverse_transform(X_submission.new_pred.dropna().astype(int))\n\nprint(f\"Relabeled predictions: {(sub.new_pred != sub[TARGET_FEATURE_NAME]).sum()}\")\nsubmission = sub[[ID, 'new_pred']].rename(columns={'new_pred': TARGET_FEATURE_NAME})\nif not BLEND:\n    submission.to_csv(f'submission.csv', index=False)\nsubmission.to_csv(f'tree{RANDOM_STATE}_{int(DIST_THRESHOLD*1000)}.csv', index=False)\n\ndisplay(submission.head(10))\ndisplay(submission.tail(10))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:46:11.318819Z","iopub.execute_input":"2022-02-23T00:46:11.319861Z","iopub.status.idle":"2022-02-23T00:46:11.642306Z","shell.execute_reply.started":"2022-02-23T00:46:11.319796Z","shell.execute_reply":"2022-02-23T00:46:11.641379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the distribution of the test predictions\nfig, ax = plt.subplots(2,1,figsize = (20,10))\nsns.countplot(x = sub[TARGET_FEATURE_NAME], ax = ax[0], orient = \"h\").set_title(\"Prediction\")\nplot_x_labels(ax[0])\n# Plot the distribution of the training set\nsns.countplot(x = y[TARGET_FEATURE_NAME], ax = ax[1], orient = \"h\").set_title(\"Training labels\")\nplot_x_labels(ax[1])\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:31.723832Z","iopub.execute_input":"2022-02-23T00:37:31.724558Z","iopub.status.idle":"2022-02-23T00:37:32.832383Z","shell.execute_reply.started":"2022-02-23T00:37:31.724506Z","shell.execute_reply":"2022-02-23T00:37:32.831442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tree ensemble\n\nEnsemble of Extra Tree with different seeds. It is said that ExtraTree(n_estimators=1000) is equivalent to 1000*ExtraTree(n_estimators=1).","metadata":{}},{"cell_type":"code","source":"def read_blenders(blenders, tree_filenames):\n    try:\n        results_df = [pd.read_csv(blender) for blender in blenders]\n        for tree_filename, result_df in zip(tree_filenames, results_df):\n            result_df.to_csv(f\"{tree_filename}\", index=False)\n        return results_df\n    except FileNotFoundError:\n        return [pd.read_csv(\"../input/tpsfeb22-soft-voting-baseline/tree42.csv\")]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:32.833693Z","iopub.execute_input":"2022-02-23T00:37:32.833936Z","iopub.status.idle":"2022-02-23T00:37:32.839812Z","shell.execute_reply.started":"2022-02-23T00:37:32.833905Z","shell.execute_reply":"2022-02-23T00:37:32.839202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\nseed_regex = re.compile(r'\\d+')\n\nblenders = []\nseeds = []\ntree_filenames = []\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        if (dirname != INPUT) & ('.csv' in filename):\n            if 'tree' in filename:\n                try:\n                    tree_filenames.append(filename)\n                    seeds.append(int(seed_regex.search(filename).group(0)))\n                    blenders.append(os.path.join(dirname, filename))\n                except Exception:\n                    pass","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:32.841461Z","iopub.execute_input":"2022-02-23T00:37:32.842244Z","iopub.status.idle":"2022-02-23T00:37:32.886046Z","shell.execute_reply.started":"2022-02-23T00:37:32.842207Z","shell.execute_reply":"2022-02-23T00:37:32.885339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = read_blenders(blenders, tree_filenames)\npredictions.append(submission)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:32.887338Z","iopub.execute_input":"2022-02-23T00:37:32.88797Z","iopub.status.idle":"2022-02-23T00:37:44.480696Z","shell.execute_reply.started":"2022-02-23T00:37:32.887926Z","shell.execute_reply":"2022-02-23T00:37:44.479596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame()\nfor i, ds in enumerate(predictions):\n    results[f'p{i+1}'] = le.transform(ds[TARGET_FEATURE_NAME])\n\nprint(results.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:44.481989Z","iopub.execute_input":"2022-02-23T00:37:44.482221Z","iopub.status.idle":"2022-02-23T00:37:45.529785Z","shell.execute_reply.started":"2022-02-23T00:37:44.482186Z","shell.execute_reply":"2022-02-23T00:37:45.528827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nresults[\"ensemble\"] = mode(np.array(results), axis=1)[0]\nresults.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:37:45.531676Z","iopub.execute_input":"2022-02-23T00:37:45.532263Z","iopub.status.idle":"2022-02-23T00:37:48.993139Z","shell.execute_reply.started":"2022-02-23T00:37:45.532216Z","shell.execute_reply":"2022-02-23T00:37:48.992524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[TARGET_FEATURE_NAME] = le.inverse_transform(results[\"ensemble\"])\nif BLEND:\n    sub.drop(columns=['new_pred']).to_csv(\"submission.csv\", index=False)\nsub.drop(columns=['new_pred']).to_csv(\"submission_blend.csv\", index=False)\nsub.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T00:37:48.994215Z","iopub.execute_input":"2022-02-23T00:37:48.994692Z","iopub.status.idle":"2022-02-23T00:37:49.527138Z","shell.execute_reply.started":"2022-02-23T00:37:48.994657Z","shell.execute_reply":"2022-02-23T00:37:49.526243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nunique(a, axis):\n    return (np.diff(np.sort(a,axis=axis),axis=axis)!=0).sum(axis=axis)+1\nresults[\"different\"] = nunique(results.iloc[:,:len(predictions)].values,1) - 1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:49.530218Z","iopub.execute_input":"2022-02-23T00:37:49.530884Z","iopub.status.idle":"2022-02-23T00:37:49.595044Z","shell.execute_reply.started":"2022-02-23T00:37:49.530848Z","shell.execute_reply":"2022-02-23T00:37:49.5944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize = (10,4))\nsns.countplot(x = results[\"different\"], ax = ax, orient = \"h\").set_title(\"Prediction difference\")\nplot_x_labels(ax)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T00:37:49.596193Z","iopub.execute_input":"2022-02-23T00:37:49.596464Z","iopub.status.idle":"2022-02-23T00:37:49.86524Z","shell.execute_reply.started":"2022-02-23T00:37:49.596433Z","shell.execute_reply":"2022-02-23T00:37:49.864653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To submit these predictions to the competition, follow these steps:\n\n1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.\n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the blue **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\n# Next Steps #\n\nIf you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n\nBe sure to check out [other users' notebooks](https://www.kaggle.com/c/tabular-playground-series-feb-2022/code) in this competition. You'll find lots of great ideas for new features and as well as other ways to discover more things about the dataset or make better predictions. There's also the [discussion forum](https://www.kaggle.com/c/tabular-playground-series-feb-2022/discussion), where you can share ideas with other Kagglers.\n\nHave fun Kaggling!","metadata":{}}]}