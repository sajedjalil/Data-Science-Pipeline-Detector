{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\n# Bacteria and Viruses\n\n[<img style=\"float:right; width:150px;height:300px;\" src=\"https://media4.giphy.com/media/l0O9xXtMtjz050twY/giphy.gif?cid=ecf05e47a7muzlffbso29382q1q4qocad2cvet8lb7urll6m&rid=giphy.gif&ct=g\">](http:google.com.au/)\nBacteria are single-celled, microscopic organisms. Most have a cell membrane and all lack membrane-bound organelles, including a nucleus. The bacterial genetic material is a single, circular molecule of DNA not arranged into a chromosome. Bacteria can have several shapes (e.g., rod shaped; filamentous; spiral shaped). Many bacteria cause disease by producing toxins. Bacterial infections that cause human illness can be prevented by vaccines or can be cured by antibiotics.\n\n# Challenge Description\n\nFor this challenge, you will be predicting bacteria species based on repeated lossy measurements of DNA snippets. Snippets of length 10 are analyzed using Raman spectroscopy that calculates the histogram of bases in the snippet. In other words, the DNA segment $ATATGGCCTT$ becomes translated to $A_2T_4G_2C_2$.\n\nEach row of data contains a spectrum of histograms generated by repeated measurements of a sample, each row containing the output of all 286 histogram possibilities (e.g. $A_0T_0G_0C_{10}$ to $A_{10}T_0G_0C_0$), which then has a bias spectrum (of totally random $ATGC$) subtracted from the results.","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# !pip -q install pandas --upgrade\n\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom statistics import mean\nfrom sklearn import datasets\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.gridspec as gridspec\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nimport matplotlib.pyplot as plt\n\nimport torch\n\n# setting device on GPU if available, else CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()\n\n#Additional Info when using cuda\nif device.type == 'cuda':\n    print(torch.cuda.get_device_name(0))\n    print('Memory Usage:')\n    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-27T18:29:46.035056Z","iopub.execute_input":"2022-02-27T18:29:46.035549Z","iopub.status.idle":"2022-02-27T18:29:48.454205Z","shell.execute_reply.started":"2022-02-27T18:29:46.035434Z","shell.execute_reply":"2022-02-27T18:29:48.453511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/tabular-playground-series-feb-2022/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/tabular-playground-series-feb-2022/test.csv\")\n\nrow_id = test_data[\"row_id\"]\n\ndel test_data[\"row_id\"]\ndel train_data[\"row_id\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-27T18:29:48.455548Z","iopub.execute_input":"2022-02-27T18:29:48.456195Z","iopub.status.idle":"2022-02-27T18:30:25.865975Z","shell.execute_reply.started":"2022-02-27T18:29:48.456159Z","shell.execute_reply":"2022-02-27T18:30:25.865045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Nb samples in train: {train_data.shape[0]}\\nNb columns in train: {train_data.shape[1]}\\nNb samples in test: {test_data.shape[0]}\\nNb columns in test: {test_data.shape[1]}\\n\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-27T18:30:25.867296Z","iopub.execute_input":"2022-02-27T18:30:25.867544Z","iopub.status.idle":"2022-02-27T18:30:25.872913Z","shell.execute_reply.started":"2022-02-27T18:30:25.867513Z","shell.execute_reply":"2022-02-27T18:30:25.87208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df\n\nprint(\"Train data\")\ntrain_data = reduce_mem_usage(train_data)\nprint(\"\\nTest data\")\ntest_data = reduce_mem_usage(test_data)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-27T18:30:25.874814Z","iopub.execute_input":"2022-02-27T18:30:25.875148Z","iopub.status.idle":"2022-02-27T18:30:58.108187Z","shell.execute_reply.started":"2022-02-27T18:30:25.875114Z","shell.execute_reply":"2022-02-27T18:30:58.106975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove Duplicated Rows since they can introduce bias, a.k.a. overfitting in our model.","metadata":{}},{"cell_type":"code","source":"print(f\"Total number of duplicated rows: {train_data.duplicated().sum()} out of {train_data.shape[0]} ({train_data.duplicated().sum()/train_data.shape[0]*100:.2f}%)\")\ntrain_data = train_data.drop_duplicates()\nprint(f\"Total number of rows after removal: {train_data.shape[0]}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-27T18:30:58.109611Z","iopub.execute_input":"2022-02-27T18:30:58.10998Z","iopub.status.idle":"2022-02-27T18:31:04.481973Z","shell.execute_reply.started":"2022-02-27T18:30:58.109941Z","shell.execute_reply":"2022-02-27T18:31:04.480979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"train_data.groupby('target').describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T18:31:04.483237Z","iopub.execute_input":"2022-02-27T18:31:04.483487Z","iopub.status.idle":"2022-02-27T18:31:10.748863Z","shell.execute_reply.started":"2022-02-27T18:31:04.483456Z","shell.execute_reply":"2022-02-27T18:31:10.747965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bacteria = train_data.target.value_counts(normalize=True).reset_index().rename(columns={'index': 'Name'})\n\ngs = gridspec.GridSpec(1, 2,width_ratios=[2.5, 2.5]) \nfig = plt.figure(figsize=(25,300))\n\n# Set the coordinates limits\nupperLimit = 100\nlowerLimit = 30\n\n# Compute max and min in the dataset\nmax = bacteria['target'].max()\n\n# Let's compute heights: they are a conversion of each item value in those new coordinates\n# In our example, 0 in the dataset will be converted to the lowerLimit (10)\n# The maximum will be converted to the upperLimit (100)\nslope = (max - lowerLimit) / max\nheights = slope * bacteria.target + lowerLimit +1000\n\n# Compute the width of each bar. In total we have 2*Pi = 360°\nwidth = 2*np.pi / len(bacteria.index)\n\n# Compute the angle each bar is centered on:\nindexes = list(range(1, len(bacteria.index)+1))\nangles = [element * width for element in indexes]\n\nCOLORMAP = [\"#5F4690\", \"#1D6996\", \"#38A6A5\", \"#0F8554\", \"#73AF48\", \"#EDAD08\", \"#E17C05\", \"#CC503E\", \"#94346E\", \"#666666\"]\n\n# initialize the figure\nplt.figure(figsize=(30,7))\nax = plt.subplot(gs[0,0], polar=True)\nplt.axis('off')\n\n\n# Draw bars\nbars = ax.bar(\n    x=angles, \n    height=heights, \n    width=width, \n    bottom=lowerLimit,\n    linewidth=2, \n    edgecolor=\"white\",\n    color=COLORMAP,\n)\n\n# little space between the bar and the label\nlabelPadding = 4\n\n\n\n# Add labels\nfor bar, angle, height, label,value in zip(bars,angles, heights, bacteria[\"Name\"], bacteria[\"target\"]):\n\n    # Labels are rotated. Rotation must be specified in degrees :(\n    rotation = np.rad2deg(angle)\n\n    # Flip some labels upside down\n    alignment = \"\"\n    if angle >= np.pi/2 and angle < 3*np.pi/2:\n        alignment = \"right\"\n        rotation = rotation + 180\n    else: \n        alignment = \"left\"\n\n    # Finally add the labels\n    ax.text(\n        x=angle, \n        y=lowerLimit + bar.get_height() + labelPadding, \n        s=label + \"  \" +str(round(value*100,1)) + \"%\", \n        ha=alignment, \n        va='center', \n        rotation=rotation, \n        rotation_mode=\"anchor\") \n    \n\nax1 = plt.subplot(gs[0,1])\n\n\nax1.axis('off')\nax1.axis('tight')\n\n\nax1.table(cellText=bacteria.values, colLabels=bacteria.columns, loc='center')\n\nfig.tight_layout()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-27T18:31:10.750311Z","iopub.execute_input":"2022-02-27T18:31:10.751041Z","iopub.status.idle":"2022-02-27T18:31:12.067466Z","shell.execute_reply.started":"2022-02-27T18:31:10.750989Z","shell.execute_reply":"2022-02-27T18:31:12.066827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check Distribution of variables","metadata":{}},{"cell_type":"code","source":"from numpy.random import seed\nfrom numpy.random import randn\nfrom statsmodels.graphics.gofplots import qqplot\nfrom matplotlib import pyplot\n# seed the random number generator\nseed(1)\n# generate univariate observations\ndata = np.array(train_data.iloc[:, 20])\n# q-q plot\nqqplot(data, line='s')\npyplot.show()\n\n# Everything indicates that we should go for non parametric models","metadata":{"execution":{"iopub.status.busy":"2022-02-27T18:31:12.068516Z","iopub.execute_input":"2022-02-27T18:31:12.068952Z","iopub.status.idle":"2022-02-27T18:31:12.608956Z","shell.execute_reply.started":"2022-02-27T18:31:12.068919Z","shell.execute_reply":"2022-02-27T18:31:12.608092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PCA \n\nThe PCA algorithm is going to standardize the input data frame, calculate the covariance matrix of the features.\n\nDon’t choose the number of components manually. Instead of that, use the option that allows you to set the variance of the input that is supposed to be explained by the generated components.","metadata":{}},{"cell_type":"code","source":"X = train_data.iloc[: , :-1].values\ny = train_data.iloc[: ,-1: ] # Target variable\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n\nmodel = make_pipeline(StandardScaler(),PCA(n_components=0.99), ExtraTreesClassifier(class_weight='balanced', n_estimators=1111, random_state=21)).fit(X_train,  y_train.values.ravel())","metadata":{"execution":{"iopub.status.busy":"2022-02-27T18:31:12.610446Z","iopub.execute_input":"2022-02-27T18:31:12.610919Z","iopub.status.idle":"2022-02-27T18:33:45.509119Z","shell.execute_reply.started":"2022-02-27T18:31:12.610876Z","shell.execute_reply":"2022-02-27T18:33:45.506854Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\n\n\n\nprint(\"Accuracy: \", accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-27T18:33:45.510396Z","iopub.status.idle":"2022-02-27T18:33:45.510935Z","shell.execute_reply.started":"2022-02-27T18:33:45.510642Z","shell.execute_reply":"2022-02-27T18:33:45.510671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_data)\n\n\n\nsubmission = pd.DataFrame({\"row_id\": row_id, 'target':preds}, index=test_data.index).to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T14:40:21.171344Z","iopub.execute_input":"2022-02-25T14:40:21.171835Z","iopub.status.idle":"2022-02-25T14:41:05.75855Z","shell.execute_reply.started":"2022-02-25T14:40:21.171792Z","shell.execute_reply":"2022-02-25T14:41:05.757641Z"},"trusted":true},"execution_count":null,"outputs":[]}]}