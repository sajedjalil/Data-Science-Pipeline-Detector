{"cells":[{"metadata":{"id":"iVGW39rDhljL"},"cell_type":"markdown","source":"# Creates TFRecords for the Pneumothorax Dataset\n\n\n### Creates TFRecords for the files from the [SIIM-ACR Pneumothorax-Segmentation Dataset](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation). \n\n### TFRecords Examples contain:\n\n- **All examples**:\n    - X-ray Images extracted from the DICOM files\n    - Image IDs\n    - Patient metadata from the DICOM files (age and sex)\n    - Image metadata (width and height)\n\n\n- **Train examples also include:**\n    - Labels, implied from the dataframe\n    - Transformed Run Lenght Encodings (RLEs)\n\n\n### About the Transformed Run Lenght Encodings (RLEs) \nRLEs stored in the TFRecs have been transformed from the original RLEs in the provided dataframe. **NOTE**: the `rle2mask()` function provided by the competition hosts will not work with this type of RLE encoding.\n\nThe RLEs stored in the TFRecs are pairs of values that contain a start position and a run length\n\n- e.g. `1 3` means starting at pixel 1 and running a total of 3 pixels \n- RLE pairs are space delimited\n- The pixels are numbered from top to bottom, then left to right: $1$ is pixel $(1,1)$, $2$ is pixel $(2,1)$, etc\n- The function `rle2mask()` provided below decodes the rle into a mask. `build_mask()` creates an image-like array for the mask\n\n\n\n### The TFRec Features are:\n```\nfeatures = {\n    'image': tf.io.FixedLenFeature([], tf.string), \n    'img_id': tf.io.FixedLenFeature([], tf.string), \n    'sex': tf.io.FixedLenFeature([], tf.string),\n    'age': tf.io.FixedLenFeature([], tf.int64),\n    'height': tf.io.FixedLenFeature([], tf.int64),\n    'width': tf.io.FixedLenFeature([], tf.int64),\n    }\n\nif labeled:\n    features['label'] = tf.io.FixedLenFeature([], tf.int64)\n    features['rle'] = tf.io.FixedLenFeature([], tf.string)\n```\nLook at `read_tfrecord()` for an example of how to extract example features. \n\n"},{"metadata":{"id":"lCF3mQ5LiWiY"},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"id":"43O1FabDNTnh","outputId":"1e4b7ff9-8c61-4c4c-902a-798ce0eaae7a","trusted":true},"cell_type":"code","source":"import os, contextlib2, pydicom\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\n\nimport tensorflow as tf\nprint('Tensorflow version ', tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE ","execution_count":null,"outputs":[]},{"metadata":{"id":"hvKE9BUJkLzf"},"cell_type":"markdown","source":"## Data Processing"},{"metadata":{},"cell_type":"markdown","source":"### Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"file_paths_train = tf.io.gfile.glob('../input/siim-train-test/dicom-images-train/*/*/*.dcm')\nfile_ids_train = [x.split('/')[-1].split('.dcm')[0] for x in file_paths_train]\n\ndf = pd.read_csv('../input/siim-acr-pneumothorax-segmentation/stage_2_train.csv')\nids_train = df['ImageId'].unique()\nlen(ids_train), len(file_ids_train) # note discreapancy in number of ids_train in the files vs. dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check unmatched train files, ImageIds"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_no_file = [f for f in ids_train if f not in file_ids_train]\nfile_no_df = [f for f in file_ids_train if f not in ids_train]\nlen(df_no_file), len(file_no_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"tstVEhrzCMfr"},"cell_type":"markdown","source":"Highlights from data description and exploration (train data):\n\n1. All ids_train in the dataframe have a corresponding dicom file, but not the way around.\n\n2. Non-contiguous mask pixels, even if corresponding to the same image, are specified in different rows. Thus, an image might have more than 1 row of EncodedPixels but all those rows correspond to the same mask. \n\n3. Images without pneumothorax disease have a mask value of -1.\n\n4. DICOM images have 1 channel and are 2D, i.e. (H, W) arrays.\n\nMainly because of 2, and so the encodings will go into the TFRecs as a fixed lenght feature, I will change the encoding to Start-Lenght RLE (as oppposed to the *relative* form RLE originally provided in the dataframe). "},{"metadata":{"id":"PhuxL2yECRKh","outputId":"ecd30d69-2cb1-4fee-baa7-982a9e776007","trusted":true},"cell_type":"code","source":"df = df.assign(Label = np.where(df['EncodedPixels'] == '-1', 0, 1))\ndf0 = df[df.Label == 0]\ndf1 = df[df.Label == 1]\n\nids_0 = df0['ImageId'].unique()\nids_1 = df1['ImageId'].unique()\n\nprint('Number of images with no Pneumothorax to be recorded: {}'.format(len(ids_0)))\nprint('Number of images with Pneumothorax to be recorded:    {}'.format(len(ids_1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"file_paths_test = tf.io.gfile.glob('../input/siim-train-test/dicom-images-test/*/*/*.dcm')\nfile_ids_test = [x.split('/')[-1].split('.dcm')[0] for x in file_paths_test]\n\nlen(file_ids_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a single dictionary mapping IDs and DICOM file paths"},{"metadata":{"trusted":true},"cell_type":"code","source":"file_ids = file_ids_train + file_ids_test\nfile_paths = file_paths_train + file_paths_test\npaths_dict = dict(zip(file_ids, file_paths))\nassert len(paths_dict.keys()) == len(file_ids_train) + len(file_ids_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"S1SVtpwUf2AC"},"cell_type":"markdown","source":"## Transform RLEs"},{"metadata":{"trusted":true},"cell_type":"code","source":"dicom_data = pydicom.dcmread(paths_dict[ids_1[0]])\nimage = dicom_data.pixel_array\nheight, width = image.shape\nprint(height, width)\n\nIMAGE_SIZE = (height, width)\nN_CHANNELS = 1\nN_CLASSES = 1","execution_count":null,"outputs":[]},{"metadata":{"id":"xAhy0sHlCRPO","cellView":"form","trusted":true},"cell_type":"code","source":"# RLE to Mask and Mask to RLE \n\ndef rle2mask_relative(rle, width, height): \n    # converts the \"relative\" rle provided to mask\n    mask= np.zeros(width*height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 1\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)\n\ndef integrate_masks(image_id):\n    # puts together non-contiguous mask pixels onto 1 single mask\n    temp_df = df1['EncodedPixels'][df1['ImageId'] == image_id]\n    mask = np.zeros([width, height])\n    for rle in temp_df:\n        mask = np.maximum(mask, rle2mask_relative(rle, width, height))\n    return mask.T\n\ndef mask2rle(mask_array):\n    '''\n    mask_array: a numpy or tensorflow 2D array: 1 - mask, 0 - background\n    Returns: run length as string\n    '''\n    pixels = tf.transpose(mask_array)\n    pixels = tf.reshape(pixels, [-1])\n    pixels = tf.cast(pixels, dtype=tf.int64) \n    pixels = tf.concat(([0], pixels, [0]), axis = 0) \n    changes = (pixels[1:] != pixels[:-1])\n    runs = tf.where(changes) + 1 \n    runs = tf.squeeze(runs)\n    lens = runs[1::2] - runs[::2]\n\n    zeros = tf.math.multiply(lens, 0)\n    ones = tf.math.add(zeros, 1)\n    inter = tf.stack((ones, zeros), axis = 1)\n    inter = tf.reshape(inter, [-1])\n\n    starts = tf.math.multiply(runs, inter)\n    lens = tf.stack((zeros, lens), axis = 1)\n    lens = tf.reshape(lens, [-1])\n\n    rles = tf.math.add(starts, lens)\n    rles = tf.strings.as_string(rles)\n    rles = tf.strings.reduce_join(rles, separator=' ')\n    return rles\n\ndef rle2mask(rle, input_shape): \n    size = tf.math.reduce_prod(input_shape) \n\n    s = tf.strings.split(rle)\n    s = tf.strings.to_number(s, tf.int32)\n\n    starts = s[0::2] - 1\n    lens = s[1::2]\n\n    total_ones = tf.reduce_sum(lens)\n    ones = tf.ones([total_ones], tf.int32)\n\n    r = tf.range(total_ones)\n    lens_cum = tf.math.cumsum(lens)\n    s = tf.searchsorted(lens_cum, r, 'right')\n    idx = r + tf.gather(starts - tf.pad(lens_cum[:-1], [(1, 0)]), s)\n\n    mask_flat = tf.scatter_nd(tf.expand_dims(idx, 1), ones, [size])\n    mask = tf.reshape(mask_flat, (input_shape[1], input_shape[0]))\n    return tf.transpose(mask)\n\ndef build_mask(rle, input_shape = (height, width)):\n    mask = rle2mask(rle, input_shape)\n    mask = tf.expand_dims(mask, axis=2)\n    mask = tf.reshape(mask, (*input_shape, 1))\n    return mask\n","execution_count":null,"outputs":[]},{"metadata":{"id":"A1pRu2YhPEVt","cellView":"form","trusted":true},"cell_type":"code","source":"# Plot Utils (DICOM files)\n\naxes_color = '#999999'\nmpl.rcParams.update({'text.color' : \"#999999\", 'axes.labelcolor' : axes_color,\n                     'font.size': 10, 'xtick.color':axes_color,'ytick.color':axes_color,\n                     'axes.spines.top': False, 'axes.spines.right': False,\n                     'axes.edgecolor': axes_color, 'axes.linewidth':1.0, 'figure.figsize':[8, 4]})\n\ndef plot_array(array):\n    fig = plt.figure(figsize=(5,5))\n    try: plt.imshow(array, alpha = 0.4, cmap = plt.cm.bone)\n    except: plt.imshow(tf.keras.preprocessing.image.array_to_img(array),\n                       alpha = 0.4, cmap = plt.cm.bone)\n    plt.axis('off')\n    plt.show()\n    return None\n\ndef plot_xray_and_mask_from_id(image_id):\n    print('Image ID:', image_id)\n    dcm_file_path = paths_dict[image_id]\n    dicom_data = pydicom.dcmread(dcm_file_path)\n    \n    plt.figure(figsize=(16,8))\n    plt.subplot(1,3,1)\n    plt.imshow(dicom_data.pixel_array, cmap=plt.cm.bone)\n    plt.title('X-Ray')\n    plt.axis('off')\n\n    mask = integrate_masks(image_id)\n    plt.subplot(1,3,2)\n    plt.imshow(mask, alpha = 0.4, cmap = 'bone')\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1,3,3)\n    plt.imshow(dicom_data.pixel_array, cmap=plt.cm.bone)\n    plt.imshow(mask, alpha = 0.4, cmap = plt.cm.bone)\n    plt.title('X-Ray + Mask')\n    plt.axis('off')\n    plt.show()\n    return None\n\nidx = -1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### X-rays + Mask Examples (from DICOM files)"},{"metadata":{"id":"zuCm08XeCRYk","cellView":"form","outputId":"de80e4d8-69a4-4ec7-e02c-88b76a07adb2","trusted":true},"cell_type":"code","source":"idx += 1\nplot_xray_and_mask_from_id(ids_1[idx])","execution_count":null,"outputs":[]},{"metadata":{"id":"lVCzgA46VbSb"},"cell_type":"markdown","source":"To transform the RLE\n\n1. Build the mask array with the given encodings using the given decoding function:\n\n    `mask = integrate_masks(ids_1[3])`\n\n2. Convert the array to the new RLE encoding:\n\n    `rle = mask2rle(mask)`\n"},{"metadata":{},"cell_type":"markdown","source":"To verify, compare masks from original and transformed RLEs"},{"metadata":{"cellView":"form","id":"eBBqfgPFtuIF","outputId":"2edbd9c1-a4f6-408d-8eab-bade396f8eeb","trusted":true},"cell_type":"code","source":"idx += 1\nmask_from_orig = integrate_masks(ids_1[idx])\nnew_rle = mask2rle(mask_from_orig)\nmask_from_new = rle2mask(new_rle, (width, height))\n\nplt.figure(figsize=(10, 5))\nplt.subplot(1,2,1)\nplt.imshow(mask_from_orig, alpha = 0.5, cmap = 'bone')\nplt.title('Mask from Original RLE')\nplt.axis('off')\n\nplt.subplot(1,2,2)\nplt.imshow(mask_from_new, alpha = 0.5, cmap = 'bone')\nplt.title('Mask from Transformed RLE')\nplt.axis('off')\n\nprint('Equal?', np.sum(mask_from_orig == mask_from_orig) == width*height)","execution_count":null,"outputs":[]},{"metadata":{"id":"CwcpOUKgIYhI"},"cell_type":"markdown","source":"### Create a dictionary for the tranformed RLEs for images with pneumothorax.\n\n- Train images with no pneumothorax will all be assigned `1 0` as RLE during TFRec creation. This is for ease of mask processing during the training pipeline.\n\n- Test images will not include RLE.\n\n- Train images with IDs not listed in the dataframe will be excluded from the TFRecs."},{"metadata":{"id":"JZ5ZwQmxRNKK","trusted":true},"cell_type":"code","source":"rle_dict = {}\nfor id in ids_1:\n    mask_array = integrate_masks(id)\n    rle_dict[id] = mask2rle(mask_array).numpy()","execution_count":null,"outputs":[]},{"metadata":{"id":"QqJs8RpNcdM_"},"cell_type":"markdown","source":"## Metadata from DICOM files\n\nCreate dictionaries for sex, age, and image sizes from the DICOM files to verify data consistency and completeness before adding to the TFRecords. This is done for train ids in the dataframe and test ids from test files."},{"metadata":{"id":"-Q4OAlAbYIhS","outputId":"d65baa8e-be4e-44a8-957e-cf6529dedb5c","trusted":true},"cell_type":"code","source":"sexes, ages, sizes = {}, {}, {}\nfor image_id in list(ids_train) + file_ids_test:\n    dcm_file_path = paths_dict[image_id]\n    dicom_data = pydicom.dcmread(dcm_file_path)\n    ages[image_id] = int(dicom_data.PatientAge)\n    sexes[image_id] = dicom_data.PatientSex\n    sizes[image_id] = dicom_data.pixel_array.shape\n\nincomplete = []\nfor image_id in ids_train:\n    if isinstance(ages[image_id], int) and sexes[image_id] in ['M', 'F'] and sizes[image_id] == (1024, 1024):\n        pass\n    else: incomplete.append[image_id]\n\nprint('Number of incomplete or inconsistent DICOM files: ', len(incomplete))","execution_count":null,"outputs":[]},{"metadata":{"id":"-JPax0kglc5u"},"cell_type":"markdown","source":"## Create TFRecords"},{"metadata":{"id":"9QO1L4LZeoMP","trusted":true},"cell_type":"code","source":"def _bytestring_feature(list_of_bytestrings):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n\ndef _int_feature(list_of_ints): # int64\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n\ndef image_bits_from_id(image_id):\n    image = pydicom.dcmread(paths_dict[image_id]).pixel_array\n    image = np.expand_dims(image, axis=2) # necessary since orig array is 2D, need 3D\n    image = tf.constant(image)\n    image_bits = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n    image_bits = image_bits.numpy()\n    return image_bits\n\ndef create_tfrec_example(image_id, diagnosis = 0):\n    '''\n    Creates a TFRecord example\n    args: image_id: (str) the image id\n          diagnosis: (int or None) one of 0, 1, or None. 1 for disease, \n              0 for no disease. None if unknown (i.e. test record)\n    returns: tfrec example\n    '''\n    image = image_bits_from_id(image_id) \n    age = ages[image_id]\n    sex = sexes[image_id]\n\n    feature = {\n        'image': _bytestring_feature([image]),\n        'img_id': _bytestring_feature([image_id.encode()]),\n        'sex': _bytestring_feature([sex.encode()]),\n        'age': _int_feature([age]), \n        'width': _int_feature([1024]), \n        'height': _int_feature([1024])\n        }\n    \n    if diagnosis != None:\n        if diagnosis: rle_bits = rle_dict[image_id] \n        else: rle_bits = '1 0'.encode()\n        feature['label'] = _int_feature([diagnosis]),\n        feature['rle'] = _bytestring_feature([rle_bits]),\n\n    tfrec_example = tf.train.Example(features=tf.train.Features(feature=feature))\n    return tfrec_example\n\n# create_tfrec_example(ids_1[133], 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"9wB4Y04mn37U"},"cell_type":"markdown","source":"Create 20 TFRecs for each class for 5% granularity and for $K \\in \\{4, 5, 10\\}$ $K$-fold partitioning. \n\nSeparate train TFRecs by label (disease, no-disease) for more flexible oversampling during training. Undersampling can be done using `dataset.filter()` in the dataset pipeline. \n\nDistribute the test files within 5 TFRecs."},{"metadata":{"id":"73Rv0i7A6Zg5","trusted":true},"cell_type":"code","source":" # the number of TFREcs for each label class.\ndef get_tfrec_fnames(id_list, description, NUM_TFRECS):\n    shard_object_count = [int(len(id_list)/NUM_TFRECS)] * NUM_TFRECS\n\n    for i in range(len(id_list)%NUM_TFRECS):  \n        shard_object_count[i] = shard_object_count[i] + 1\n    \n    tf_record_output_filenames = ['penumothorax-1024x1024-{}-{:02d}-{}.tfrec'.format(\n        description, idx+1, shard_object_count[idx]) for idx in range(NUM_TFRECS)]\n    return tf_record_output_filenames","execution_count":null,"outputs":[]},{"metadata":{"id":"17CyeQov6ZjC","trusted":true},"cell_type":"code","source":"disease_tfrec_names = get_tfrec_fnames(ids_1, 'train-disease', NUM_TFRECS = 20)\nno_disease_tfrec_names = get_tfrec_fnames(ids_0, 'train-no-disease', NUM_TFRECS = 20)\ntest_tfrec_names = get_tfrec_fnames(file_ids_test, 'test', NUM_TFRECS = 5)\n\ndisease_dict = {'ids': ids_1, 'tfrec_names': disease_tfrec_names, 'diagnosis': 1, 'NUM_TFRECS':20}\nno_disease_dict = {'ids': ids_0, 'tfrec_names': no_disease_tfrec_names, 'diagnosis': 0, 'NUM_TFRECS':20}\ntest_dict = {'ids': file_ids_test, 'tfrec_names': test_tfrec_names, 'diagnosis': None, 'NUM_TFRECS':5}","execution_count":null,"outputs":[]},{"metadata":{"id":"kUdPwA4kEHO-","trusted":true},"cell_type":"code","source":"def open_sharded_tfrecs(exit_stack, tfrec_names):\n    return [exit_stack.enter_context(tf.io.TFRecordWriter(fname)) for fname in tfrec_names]\n\nfor d in [disease_dict, no_disease_dict, test_dict]:\n    id_list = d['ids']\n    tfrec_names = d['tfrec_names']\n    diagnosis = d['diagnosis']\n    NUM_TFRECS = d['NUM_TFRECS']\n\n    with contextlib2.ExitStack() as tf_record_close_stack:\n        output_tfrecords = open_sharded_tfrecs(tf_record_close_stack, tfrec_names)    \n\n        for i, image_id in enumerate(id_list): \n            tf_record=create_tfrec_example(image_id, diagnosis)\n            output_tfrecords[i%NUM_TFRECS].write(tf_record.SerializeToString())","execution_count":null,"outputs":[]},{"metadata":{"id":"C5KyNleQlgzO"},"cell_type":"markdown","source":"## Verify TFRecords"},{"metadata":{"id":"TgG5TrsNwXNU","cellView":"form","trusted":true},"cell_type":"code","source":"# Parse TFRecs\ndef read_tfrecord(example, labeled = True):\n    features = {\n        'image': tf.io.FixedLenFeature([], tf.string), \n        'img_id': tf.io.FixedLenFeature([], tf.string), \n        'sex': tf.io.FixedLenFeature([], tf.string),\n        'age': tf.io.FixedLenFeature([], tf.int64),\n        'height': tf.io.FixedLenFeature([], tf.int64),\n        'width': tf.io.FixedLenFeature([], tf.int64),\n        }\n    \n    if labeled:\n        features['label'] = tf.io.FixedLenFeature([], tf.int64)\n        features['rle'] = tf.io.FixedLenFeature([], tf.string)\n\n    example = tf.io.parse_single_example(example, features)\n\n    image = example['image']\n    image = tf.image.decode_jpeg(image, channels=N_CHANNELS)\n    image = tf.cast(image, tf.float32) / 255.0  \n    image = tf.reshape(image, [*IMAGE_SIZE, N_CHANNELS]) \n    img_id = example['img_id']\n    \n    if not labeled: return image, img_id\n    else:\n        rle = example['rle']\n        mask = build_mask(rle)\n        mask = tf.cast(mask, tf.float32)\n        mask = tf.reshape(mask, [*IMAGE_SIZE, N_CLASSES]) \n        return image, mask\n\ndef get_dataset(filenames, labeled = True):\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    dataset = dataset.map(lambda x: read_tfrecord(x, labeled), num_parallel_calls=AUTO)\n    return dataset\n\ndef parse_examples(dataset, n=20):\n    dataset_examples = []\n    for i, (image, item2) in enumerate(dataset.take(n)):\n        dataset_examples.append((image, item2))\n    return dataset_examples","execution_count":null,"outputs":[]},{"metadata":{"id":"fRFx5RQyXPkn","trusted":true},"cell_type":"code","source":"# Plot Utils (for TFRecords)\ndef plot_xray_mask(img_mask_tuple):\n    xray = tf.keras.preprocessing.image.array_to_img(img_mask_tuple[0])\n    mask = tf.keras.preprocessing.image.array_to_img(img_mask_tuple[1])\n\n    plt.figure(figsize=(16,8))\n    plt.subplot(1,3,1)\n    plt.imshow(xray, cmap=plt.cm.bone)\n    plt.title('X-Ray')\n    plt.axis('off')\n\n    plt.subplot(1,3,2)\n    plt.imshow(mask, alpha = 0.4, cmap = 'bone')\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1,3,3)\n    plt.imshow(xray, cmap=plt.cm.bone)\n    plt.imshow(mask, alpha = 0.4, cmap = plt.cm.bone)\n    plt.title('X-Ray + Mask')\n    plt.axis('off')\n    plt.show()\n    return None","execution_count":null,"outputs":[]},{"metadata":{"id":"141RZMPo5HjT"},"cell_type":"markdown","source":"**Visualize X-Rays with Disease**"},{"metadata":{"id":"kuzHRvkJbCEO","trusted":true},"cell_type":"code","source":"ds = get_dataset(disease_tfrec_names[18:])\ndisease_examples = parse_examples(ds)","execution_count":null,"outputs":[]},{"metadata":{"id":"DeQIkrFha0yc","outputId":"fe53ea79-fa2f-438d-a7d9-70426bcdac43","trusted":true},"cell_type":"code","source":"idx += 1\nplot_xray_mask(disease_examples[idx])","execution_count":null,"outputs":[]},{"metadata":{"id":"qxrCxs5b5PfK"},"cell_type":"markdown","source":"**Visualize X-Rays with No Disease**"},{"metadata":{"id":"2BehpFTt49NX","trusted":true},"cell_type":"code","source":"ds = get_dataset(no_disease_tfrec_names[15:])\nno_disease_examples = parse_examples(ds)  ","execution_count":null,"outputs":[]},{"metadata":{"id":"wp288ln1XPnm","outputId":"64d1429f-52d5-4a02-ea20-5d0b08a9dd24","trusted":true},"cell_type":"code","source":"idx += 1\nplot_xray_mask(no_disease_examples[idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize X-Rays from test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = get_dataset(test_tfrec_names[2:], labeled = False)\ntest_examples = parse_examples(ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx += 1\ntest_example = test_examples[idx]\nxray = tf.keras.preprocessing.image.array_to_img(test_example[0])\nplt.figure(figsize=(5, 5))\nplt.imshow(xray, cmap=plt.cm.bone)\nplt.title('Test ID: {}'.format(test_example[1].numpy().decode()))\nplt.axis('off'); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir ./tfrecords\n!mv ./*.tfrec tfrecords\n!ls ./tfrecords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r ./tfrecords\n!ls","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}