{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <h1 style=\"text-align:center\">Extensive EDA On SIIM Pneumothorax Dataset</h1>\n\n\n* [1. introduction](#section1)\n* [2. Data science in Pneumothorax identification](#section2)\n    * [2.1 What is Pneumothorax?](#section2)\n    * [2.2 Why Datascience in Pneumothorax detection?](#section2)\n* [3. About Dataset](#section3)\n    * [3.1. Understanding DICCOM](#section3.1)\n* [4. Analyzing metadata](#section4)\n    * [4.1 Healthy vs non healthy Patients(Pneumothorax)](#section4)\n    * [4.2 Analysis On Sex](#section4.2)\n    * [4.3 Analysis On View position](#section4.3)\n    * [4.4 Analysis On Age](#section4.4)\n* [5. Analyzing images and masks](#section5)\n    * [5.1 Understanding images](#section5)\n    * [5.2 RLE encoding](#section5.2)\n    * [5.3 Visualizing images and masks](#section5.3)\n* [6. Conclusion and future steps](#section6)¶\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://image.shutterstock.com/image-vector/human-anatomy-pneumothorax-diagram-illustration-600w-1849652587.jpg\" height=\"200px\" width=\"1000px\">\n\n\n\n\n<a class=\"anchor\" id=\"section1\"></a>\n### 1. Introduction\n\nThe impact of Artificial intellihence in the field of medicine is inevitable. One of its common application of AI in medicine includes diagnosis of medical condition by analyzing\nhe Digital Imaging of X-rays, CT-Scans, etc. Here we have to detect Pneumothorax from Chest X-rays. Before geting in to analysis, let us get familirize with the domain.\n\n<a class=\"anchor\" id=\"section2\"></a>\n### 2. Data science in Pneumothorax identification\n\n**What is Pneumothorax?**\n\nA pneumothorax (noo-moe-THOR-aks) is a collapsed lung. A pneumothorax occurs when air leaks into the space between your lung and chest wall. This air pushes on the outside of your lung and makes it collapse. Pneumothorax can be a complete lung collapse or a collapse of only a portion of the lung. It is basically a combination of two words Pneumo(air) and Thorax(chest). Pneumothorax is also known as lung collapse. Pneumothorax is caused by an abnormal collection of air between the parietal and visceral pleura i. e. pleural space between the lungs and chest wall. \n\nPneumothorax is a relatively common respiratory disease that can occur in a wide range of patients and in various clinical settings.\nDoctors will use chest Xrays to identify Pneumothorax. Based on that doctor can suggest suitable treatment.\n\n<img src=\"https://www.svhlunghealth.com.au/Images/UserUploadedImages/3457/Pneumothorax%20still.jpg\" width=\"300px\">\n\n**Why Datascience in Pneumothorax detection?**\n\nIf we are able to segment/detect regions of Pneumothorax from chest X-rays it will be useful for the doctor or we can say that it will saves a lot of time for the doctor to diagnosis.\nUsing a dataset with x-ray images and their diagnosis with the exact place of the air in pleura, a model could be trained to recognize Pneumothorax. Additional information about the patients could also be useful when analyzing an x-ray image.Suppose we are able to find the target region, doctors can focus on that region and identify Pneumothorax easily.\n\n\n<a class=\"anchor\" id=\"section3\"></a>\n### 3. About Dataset\n\nWe have 2 folders one containing train data and other test data:\n\n* dicom-images-train\n* dicom-images-test\n\nInside each folder we have DICOM (Digital Imaging and Communications in Medicine) formatted files, for some reason every single image is embedded in two more folders. Also we have a csv file which provides mask encodings for each image. \n","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport pydicom,os,cv2\nfrom glob import glob\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\nimport warnings\nwarnings.simplefilter(\"ignore\")\n%matplotlib inline\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:01:59.954655Z","iopub.execute_input":"2021-05-27T14:01:59.955041Z","iopub.status.idle":"2021-05-27T14:02:01.232573Z","shell.execute_reply.started":"2021-05-27T14:01:59.955006Z","shell.execute_reply":"2021-05-27T14:02:01.231817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show some images\nfrom glob import glob\ntrain_fns = sorted(glob('../input/siim-train-test/dicom-images-train/*/*/*.dcm'))\ntest_fns = sorted(glob('../input/siim-train-test/dicom-images-test/*/*/*.dcm'))\n\nprint(f'Number of train dicom files in folder:{len(train_fns)}')\nprint(f'Number of test dicom files in folder:{len(test_fns)}')\n\ndf = pd.read_csv('../input/siim-train-test/train-rle.csv')\nprint(df.shape)\n\nprint(f'Total no of unique images in csv file: {df[\"ImageId\"].nunique()}')\nprint(f'Images with duplicate Encoded pixels, ie multiple annotations:{df[df.duplicated(subset=[\"ImageId\"])].shape[0]}')\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:02:01.233718Z","iopub.execute_input":"2021-05-27T14:02:01.2341Z","iopub.status.idle":"2021-05-27T14:04:35.633372Z","shell.execute_reply.started":"2021-05-27T14:02:01.234073Z","shell.execute_reply":"2021-05-27T14:04:35.632652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The csv with the labels: -1 means no Pneumothorax, othervise there is an encoding for the place of Pneumothorax.\n* We have images with multiple annotation. There are about 12047 unique images in our csv file.","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"section3.1\"></a>\n**Understanding DICCOM**","metadata":{}},{"cell_type":"code","source":"# code from https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data\ndef show_info(dataset):\n    print(\"Filename......:\", file_path)\n    print(\"Storage type.....:\", dataset.SOPClassUID)\n    print()\n\n    pat_name = dataset.PatientName\n    display_name = pat_name.family_name + \", \" + pat_name.given_name\n    print(\"Patient's name......:\", display_name)\n    print(\"Patient id..........:\", dataset.PatientID)\n    print(\"Patient's Age.......:\", dataset.PatientAge)\n    print(\"Patient's Sex.......:\", dataset.PatientSex)\n    print(\"Modality............:\", dataset.Modality)\n    print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n    print(\"View Position.......:\", dataset.ViewPosition)\n    \n    if 'PixelData' in dataset:\n        rows = int(dataset.Rows)\n        cols = int(dataset.Columns)\n        print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n            rows=rows, cols=cols, size=len(dataset.PixelData)))\n        if 'PixelSpacing' in dataset:\n            print(\"Pixel spacing....:\", dataset.PixelSpacing)\n\ndef plot_pixels(dataset, figsize=(8,8)):\n    plt.figure(figsize=figsize)\n    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:04:35.635141Z","iopub.execute_input":"2021-05-27T14:04:35.635658Z","iopub.status.idle":"2021-05-27T14:04:35.644449Z","shell.execute_reply.started":"2021-05-27T14:04:35.635623Z","shell.execute_reply":"2021-05-27T14:04:35.643325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = train_fns[0]\ndata = pydicom.dcmread(file_path)\nshow_info(data)\nplot_pixels(data)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:04:35.646121Z","iopub.execute_input":"2021-05-27T14:04:35.646746Z","iopub.status.idle":"2021-05-27T14:04:36.082489Z","shell.execute_reply.started":"2021-05-27T14:04:35.646711Z","shell.execute_reply":"2021-05-27T14:04:36.081713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us create a common dataframe including all information.","metadata":{}},{"cell_type":"code","source":"# code idea from https://www.kaggle.com/retyidoro/eda-of-pneumothorax-dataset\nmissing = 0\nmultiple = 0\npatients_data = []\nfor k,paths in enumerate(train_fns):\n    patient = {}\n    img_id = paths.split('/')[-1]\n    data = pydicom.dcmread(paths)\n    try:\n        tmp = df[df['ImageId'] == '.'.join(img_id.split('.')[:-1])]\n        \n        if tmp.shape[0] > 1: \n            multiple += 1\n        rle = tmp[' EncodedPixels'].values\n        if rle[0] == '-1':\n            pixels = rle[0]\n        else:    \n            pixels = [i for i in rle]\n        \n        patient[\"UID\"] = data.SOPInstanceUID\n        patient['EncodedPixels'] = pixels\n        patient[\"Age\"] = data.PatientAge\n        patient[\"Sex\"] = data.PatientSex\n        patient[\"Modality\"] = data.Modality\n        patient[\"BodyPart\"] = data.BodyPartExamined\n        patient[\"ViewPosition\"] = data.ViewPosition\n        patient[\"filepath\"] = paths\n        patients_data.append(patient)\n    except:\n        missing += 1\n\nprint(f'We have {missing} dicom in folder which is not present in csv')\nprint(f'There are {multiple} images with more than 1 annotation')\ndf_patients = pd.DataFrame(patients_data, columns=[\"UID\", \"EncodedPixels\", \"Age\", \n                            \"Sex\", \"Modality\", \"BodyPart\", \"ViewPosition\", \"filepath\"])\n\ndf_patients['Pneumothorax'] = df_patients['EncodedPixels'].apply(lambda x:0 if x == '-1' else 1)\ndf_patients['Pneumothorax'] = df_patients['Pneumothorax'].astype('int')\nprint(\"images with labels: \", df_patients.shape[0])\ndf_patients.head()    ","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:34.294893Z","iopub.execute_input":"2021-05-27T14:06:34.295243Z","iopub.status.idle":"2021-05-27T14:08:09.719844Z","shell.execute_reply.started":"2021-05-27T14:06:34.295215Z","shell.execute_reply":"2021-05-27T14:08:09.718819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"section4\"></a>\n### 4. Analyzing metadata\n\n### 4.1 Healthy vs non healthy Patients(Pneumothorax)","metadata":{}},{"cell_type":"code","source":"df_patients['Pneumothorax'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.277639Z","iopub.status.idle":"2021-05-27T14:06:29.278046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = df_patients['Pneumothorax'].value_counts()\ndf_patients['Pneumothorax'] = df_patients['Pneumothorax'].astype('int')\nfig, ax = plt.subplots(figsize=[10,6])\nax.pie(tmp,labels =['healthy','unhealthy'],autopct=\"%.1f%%\");\nplt.title(\"Pneumothorax present vs absent\", fontsize=14);","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.279071Z","iopub.status.idle":"2021-05-27T14:06:29.279472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that only 22.2% of the people have Pneumothorax rest of the people are healthy.\n\n<a class=\"anchor\" id=\"section4.2\"></a>\n### 4.2 Sex","metadata":{}},{"cell_type":"code","source":"def plot_dual(col):\n    \"\"\"\n    plot pie chart and bar graph\n    \"\"\"\n    tmp = df_patients[['Pneumothorax',col]]\n    tmp = tmp.groupby(by=col).mean().reset_index()\n    fig, axes = plt.subplots(1,2,figsize=(15,8))\n    \n    tmp2 = df_patients[col].value_counts()\n    axes[0].pie(tmp2,labels = tmp2.index ,\n            autopct=\"%.2f%%\",pctdistance=0.5);\n    axes[0].set_title(\"Total count\")\n    sns.barplot(x=tmp[col],y=tmp['Pneumothorax'],ax=axes[1])\n    axes[1].set_title(f\"Pneumothorax among different {col}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.280394Z","iopub.status.idle":"2021-05-27T14:06:29.280807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_dual('Sex')","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.281655Z","iopub.status.idle":"2021-05-27T14:06:29.28205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We can see that among 55% of whole data belongs to males and rest females\n* Among females about 25% of people have Pneumothorax and rest dont have Pneumothorax\n* Among maes close to 27% of people have Pneumothorax and rest dont have Pneumothorax\n\n<a class=\"anchor\" id=\"section4.3\"></a>\n### 4.3 View Position\n\nThe view position can be AP or PA.The abbreviations PA and AP stand for posteroanterior and anteroposterior, respectively. These describe the pathway of the x-rays through the patient to the detector (or, in the old days, film).\n\n* In a PA projection, the front of the patient’s chest is against the detector and the x-rays pass through the back (posterior)of the patient, through the front (anterior) of the chest and then strike the detector.\n\n* In a patient who cannot stand, the detector can be placed behind the patient’s back (while they’re lying or sitting up in a gurney or hospital bed, for example) In this scenario, the x-rays pass from the front of the patient’s chest (anterior) through the back (posterior), then strike the detector, yielding an AP view. \n\n* Usually PA projection is preferred for several reasons. For example, the portions of the chest closest to the detector are the sharpest and least magnified on the image. \n\n\nIt will be nice if we are able to see the mask of patients with pneumothorax and distinguish between AP and PA. But before that we have to generate the mask with rle encoding.","metadata":{}},{"cell_type":"code","source":"plot_dual('ViewPosition')","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.282896Z","iopub.status.idle":"2021-05-27T14:06:29.283285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We can see that among 60.38% of whole data belongs to 'PA' position and rest 'AP' position\n* Among AP 21% of people have Pneumothorax and rest dont have Pneumothorax\n* Among PA close to 28% of people have Pneumothorax and rest dont have Pneumothorax","metadata":{}},{"cell_type":"markdown","source":"\n<a class=\"anchor\" id=\"section4.4\"></a>\n### 4.4 Age","metadata":{}},{"cell_type":"code","source":"df_patients['Age'] = df_patients['Age'].astype('int') \nfig, axes = plt.subplots(nrows=1, ncols=1,figsize=(8,4))\nsns.boxplot(df_patients['Age'])\naxes.title.set_text(f'Age')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.284051Z","iopub.status.idle":"2021-05-27T14:06:29.284463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_patients[df_patients['Age'] > 100]","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.285682Z","iopub.status.idle":"2021-05-27T14:06:29.286097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nWe have few outliers. Might be mistake from dataentry. We have ages above 120, logically which is not correct. We will remove those values","metadata":{}},{"cell_type":"code","source":"df_patients = df_patients.drop(df_patients[df_patients['Age'] > 100].index)\nprint(df_patients.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.28707Z","iopub.status.idle":"2021-05-27T14:06:29.287509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let us see how Age is distributed among healthy and non healthy perosons**","metadata":{}},{"cell_type":"code","source":"non_healthy = df_patients[df_patients['Pneumothorax'] == 1] \nhealthy = df_patients[df_patients['Pneumothorax'] == 0]\n\ndf_patients['Age'] = df_patients['Age'].astype('int') \nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,8))\nsns.distplot(df_patients['Age'],ax=axes[0])\naxes[0].title.set_text('Distribution of Age')\nsns.distplot(healthy['Age'],ax=axes[1])\nsns.distplot(non_healthy['Age'],ax=axes[1],color='#B71C1C')\naxes[1].title.set_text('Distribution of Age(healthy vs unhealthy)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.288424Z","iopub.status.idle":"2021-05-27T14:06:29.288843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We will get more overview of we were able to see at what age Pneumothorax is more severe among males and females**\n","metadata":{}},{"cell_type":"code","source":"\ntmp_male = df_patients[df_patients['Sex'] == 'M'] \ntmp_female = df_patients[df_patients['Sex'] == 'F'] \n\nnon_healthy_M = tmp_male[tmp_male['Pneumothorax'] == 1] \nhealthy_M = tmp_male[tmp_male['Pneumothorax'] == 0]\nnon_healthy_F = tmp_female[tmp_female['Pneumothorax'] == 1] \nhealthy_F = tmp_female[tmp_female['Pneumothorax'] == 0]\n\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,8))\nsns.distplot(healthy_M['Age'],ax=axes[0])\nsns.distplot(non_healthy_M['Age'],ax=axes[0],color='#B71C1C')\naxes[0].set_title('Male Patient vs Age')\nsns.distplot(healthy_F['Age'],ax=axes[1])\nsns.distplot(non_healthy_F['Age'],ax=axes[1],color='#B71C1C')\naxes[1].set_title('Female Patient vs Age')\nplt.suptitle(f'Distribution of Age base on Sex')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T14:06:29.289741Z","iopub.status.idle":"2021-05-27T14:06:29.290151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Among males with 16-25 years of age chances of pneumothorax is high. However this is based on a small amount of data.\n\n<a class=\"anchor\" id=\"section5\"></a>\n### 5 Analyzing images and masks\n\n### 5.1 Understanding Images\nLet us see wheather train and test images are close by analyzing their mean.","metadata":{}},{"cell_type":"code","source":"# check the train images\nmeans = []\nfor fn in tqdm(train_fns):\n    img = pydicom.read_file(fn).pixel_array\n    means.append(img.mean())\nprint(\"Train mean: \", np.mean(means))\n\n# check the test images\nmeans = []\nfor fn in tqdm(test_fns):\n    img = pydicom.read_file(fn).pixel_array\n    means.append(img.mean())\nprint(\"Test mean: \", np.mean(means))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:44:16.114894Z","iopub.execute_input":"2021-05-27T12:44:16.115203Z","iopub.status.idle":"2021-05-27T12:47:48.197756Z","shell.execute_reply.started":"2021-05-27T12:44:16.115173Z","shell.execute_reply":"2021-05-27T12:47:48.196415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that both have close mean. So train and test can exhibit a close behaviour.\n\n<a class=\"anchor\" id=\"section5.2\"></a>\n### 5.2 RLE Encoding\n\nRun-length encoding (RLE) is a form of lossless data compression in which runs of data are stored as a single data value and count, rather than as the original run.\nLets understand how to generate masks, if EncodedPixels(RLE) are given instead of mask images with an example.\n\nLet us take an example, for image with UID '1.2.276.0.7230010.3.1.4.8323329.10005.1517875220.958951' RLE is as follows: \n\n['209126 1 1019 6 1015 10 1012 13 1010 14 1008 16 1007 16 1006 18 1004 20 1003 20 1002 22 1001 22 1001 23 999 24 999 24 999 25 997 26 997 27 996 27 996 27 996 28 995 28 995 28............1005 18 1010 12']\n\nThis means that when we flatten a 1024x1024 image to 1024 * 1024 =1048576, starting from 209126 pixels we have the next 1 pixel as a mask (a region with Pneumothorax). Now we are at 209127,  Now move 1019 pixels front. ie, from 209127 to 210145. Next starting from 210145 pixels, we have the next 6 pixels as a mask. I hope you get it now\n\nYou can read more about RLE [here.](http://https://medium.com/analytics-vidhya/generating-masks-from-encoded-pixels-semantic-segmentation-18635e834ad0)\n\n\n","metadata":{}},{"cell_type":"code","source":"# Here out RLE encoding is little bit different\ndef rle2mask(rles, width, height):\n    \"\"\"\n    \n    rle encoding if images\n    input: rles(list of rle), width and height of image\n    returns: mask of shape (width,height)\n    \"\"\"\n    \n    mask= np.zeros(width* height)\n    for rle in rles:\n        array = np.asarray([int(x) for x in rle.split()])\n        starts = array[0::2]\n        lengths = array[1::2]\n\n        current_position = 0\n        for index, start in enumerate(starts):\n            current_position += start\n            mask[current_position:current_position+lengths[index]] = 255\n            current_position += lengths[index]\n\n    return mask.reshape(width, height).T","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:47:48.199118Z","iopub.execute_input":"2021-05-27T12:47:48.199432Z","iopub.status.idle":"2021-05-27T12:47:48.206939Z","shell.execute_reply.started":"2021-05-27T12:47:48.199402Z","shell.execute_reply":"2021-05-27T12:47:48.20561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"section5.3\"></a>\n### 5.3 Visualizing Images and Masks","metadata":{}},{"cell_type":"markdown","source":"Some random images and masks if present","metadata":{}},{"cell_type":"code","source":"for file in train_fns[13:16]:\n    data = pydicom.dcmread(file)\n    image = data.pixel_array\n    id_ = '.'.join(file.split('/')[-1].split('.')[:-1])\n    rle = df[df['ImageId'] == str(id_)][' EncodedPixels'].values\n    if rle[0] == '-1':\n        fig,axes = plt.subplots(1,2,figsize=(10,5))\n        axes[0].imshow(image,cmap='bone')\n        axes[1].imshow(image,cmap='bone')\n        plt.suptitle(f'Image id: {id_}')\n        plt.show()\n    else:\n        fig,axes = plt.subplots(1,2,figsize=(10,5))\n        axes[0].imshow(image,cmap='bone')\n        mask = rle2mask(rle,image.shape[0],image.shape[1])\n        axes[1].imshow(image,cmap='bone')\n        axes[1].imshow(mask,alpha=0.3,cmap='Reds')\n        axes[1].set_title('Image Annoted')\n        plt.suptitle(f'Image id: {id_}')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:47:48.208147Z","iopub.execute_input":"2021-05-27T12:47:48.208452Z","iopub.status.idle":"2021-05-27T12:47:50.230697Z","shell.execute_reply.started":"2021-05-27T12:47:48.208423Z","shell.execute_reply":"2021-05-27T12:47:50.229513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us visualize better","metadata":{}},{"cell_type":"code","source":"def bounding_box(img):\n    # return max and min of a mask to draw bounding box\n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    \n    return rmin, cmin, rmax, cmax #ymin,xmin,ymax,cmax\n\n\ndef plot_imgs(n,df):\n    for i in range(n):\n        idx = np.random.randint(0,df.shape[0])\n        tmp = df.iloc[idx]\n        # path of file\n        path = tmp['filepath']\n        encoding = tmp['EncodedPixels']\n        image = pydicom.dcmread(path).pixel_array\n        fig, axes = plt.subplots(1,4, figsize=(20,15))\n        axes[0].imshow(image, cmap='bone')\n        axes[0].set_title('Image')\n        mask = rle2mask(encoding,image.shape[0],image.shape[1])\n        axes[1].imshow(mask,cmap='gray')\n        axes[1].set_title('Mask')\n        axes[2].imshow(image,cmap='bone')\n        axes[2].imshow(mask,alpha=0.3,cmap='Reds')\n        axes[2].set_title('Image + mask')\n        rmin, cmin, rmax, cmax = bounding_box(mask)\n        image_rgb = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n        cv2.rectangle(image_rgb, (cmin,rmin),(cmax,rmax), (255,255,0), 5)\n        axes[3].imshow(image_rgb)\n        axes[3].imshow(mask,alpha=0.3,cmap='Reds')\n        axes[3].set_title('Image Box Annoted')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:47:50.232491Z","iopub.execute_input":"2021-05-27T12:47:50.232944Z","iopub.status.idle":"2021-05-27T12:47:50.247808Z","shell.execute_reply.started":"2021-05-27T12:47:50.232896Z","shell.execute_reply":"2021-05-27T12:47:50.24673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = df_patients[df_patients['Pneumothorax'] == 1].reset_index(drop=True)\nplot_imgs(15,tmp)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:47:50.248986Z","iopub.execute_input":"2021-05-27T12:47:50.249293Z","iopub.status.idle":"2021-05-27T12:48:09.60977Z","shell.execute_reply.started":"2021-05-27T12:47:50.249263Z","shell.execute_reply":"2021-05-27T12:48:09.608796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saving file\ndf_patients.to_csv('processed.csv',index=False)\n\ndff = pd.read_csv('processed.csv')\ndff.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:48:09.61103Z","iopub.execute_input":"2021-05-27T12:48:09.611339Z","iopub.status.idle":"2021-05-27T12:48:10.060794Z","shell.execute_reply.started":"2021-05-27T12:48:09.61131Z","shell.execute_reply":"2021-05-27T12:48:10.059714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"section6\"></a>\n### 6. Conclusion and future steps\n\nWe have did an extensive analysis of the data and we got a clear picture on how to procees further. We can consider this as a segmentation problem. Initially We can think of two approaches:\n\n1. Image segmentation: This is straight forward approach where we will do a segmentation of affected regions of all images.\n\n2. Image classification + segmentation: In this approach we will have 2 models. One to classify weather the image has pneumothorax and second to segment it.\n\n","metadata":{}}]}