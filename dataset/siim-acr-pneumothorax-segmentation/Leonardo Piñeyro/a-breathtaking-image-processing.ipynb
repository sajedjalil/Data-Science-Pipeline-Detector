{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Pneumothorax...**\n![meme_lol](https://i.kym-cdn.com/photos/images/newsfeed/001/502/282/0b1.jpg)\n... *literally*.\n\nNow, memes aside, here I present some work on experimenting with \ndata and some ideas for images processing.\n\n# Understading data and some ideas\n\n* Images are **X-rays** of the lungs (both)\n* A **mask** over the image indicacte if the lung is compromised, and exactly where.\n* On most of the images, the **backbone** of the person is visible. This could help to **align the images**.\n  * Need to be careful aligning masks as well\n  * Need to store transformation for each image to perform an inverse transformation if necessary\n* Probably it would be easier for a model to **understand lungs using a single orientation** (instead of left and right)\n  * After the image is aligned with the backbone, the lungs can be separated into left and right lungs\n  * Then, the right lung image can be **mirrored horizontally**, and get a new \"left\" lung image!\n  * This is likely to make DA easier in the future"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport os\nimport sys\nimport glob\n\nimport cv2\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pydicom\nimport skimage\n\nfrom PIL import Image\nfrom PIL import ImageFilter\n\nfrom sklearn.svm import SVC\n\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n\nfrom mask_functions import rle2mask\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nprint(os.listdir(\"../input/siim-acr-pneumothorax-segmentation-data/pneumothorax\"))\n\nsample_files = glob.glob(\"../input/siim-acr-pneumothorax-segmentation/sample images/*.dcm\")\ndf_sample_files = pd.read_csv(\n    \"../input/siim-acr-pneumothorax-segmentation/sample images/train-rle-sample.csv\",\n    header=None,\n    names=['filename', 'target']\n)\ndf_sample_files = df_sample_files.set_index('filename')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"dpi = 220\nmatplotlib.rcParams['figure.dpi'] = dpi","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_sample_files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"samples = [\n    pydicom.dcmread(sample_file)\n    for sample_file in sample_files\n]\nprint(f\"Loaded {len(samples)} samples\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## X-ray sample image\n\nHere it is the first example"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.imshow(samples[0].pixel_array, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Process the images and try to segment the lungs\n\nWith the lungs segmented, it will make easier to align the images vertically. Here I remove any black padding from the images, then also perform a simple image equalization."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def get_biggest_blob(mask, max_blobs=1, max_val=255, inverted=False):\n    \"\"\"Get the biggest connected component from a mask\n\n    Parameters\n    ----------\n    mask : numpy image\n        A numpy image containing a mask\n    max_val : int or float\n        Maximum value to use in the new mask\n    inverted : bool\n        Returns the biggest negative mask\n\n    Returns\n    -------\n    A new mask containing only the biggest blob\n    \"\"\"\n    if inverted:\n        mask = np.logical_not(mask).astype(np.uint8)\n\n    nb_components, output, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=4)\n    sizes = stats[:, -1]\n\n    labels = [\n        (i, sizes[i])\n        for i in range(1, nb_components)\n    ]\n    labels.sort(key=lambda l: l[1], reverse=True)\n    \n    mask = np.zeros(output.shape)\n    mask_labels = np.zeros(output.shape)\n    for i in range(min(len(labels), max_blobs)):\n        mask[output == labels[i][0]] = max_val\n        mask_labels[output == labels[i][0]] = i + 1\n\n    if inverted:\n        mask = np.logical_not(mask).astype(np.uint8)\n\n    return mask, mask_labels\n\n\ndef get_basename(path):\n    return os.path.basename(path).rsplit('.', 1)[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_index = 0\n\nsample = samples[sample_index].pixel_array\nh, w = sample.shape\n\n# Remove black padding on some images and equalize\nsample_pre = Image.fromarray(sample)\nsample_pre = sample_pre.crop(sample_pre.getbbox())\nsample_pre = sample_pre.resize((h, w))\nsample_pre = np.asarray(sample_pre)\nsample_pre = cv2.equalizeHist(sample_pre)\n\n# Get mask for this sample\ntarget = df_sample_files.loc[get_basename(sample_files[sample_index])].target\n\nif target != '-1':\n    sample_mask = rle2mask(target, h, w).T\n\n    # Plot original sample and processed one\n    f, (ax1, ax2) = plt.subplots(1, 2)\n\n    ax1.imshow(sample, cmap='gray')\n    ax1.imshow(sample_mask, alpha=0.3, cmap='binary')\n    ax2.imshow(sample_pre, cmap='gray')\n    ax2.imshow(sample_mask, alpha=0.3, cmap='binary')\nelse:\n    print('Nothing to see in this sample')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trying to separate lungs\n\nUsing thresholding and flood-filling to detect the best candidates for the lungs segmentation masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply some minimum filter to remove noises\nsample_aux = Image.fromarray(sample_pre)\nsample_aux = sample_aux.filter(ImageFilter.MinFilter(3))\nsample_aux = np.asarray(sample_aux)\n\nimg = cv2.bitwise_not(sample_aux)\n\n# Binary thresholding\nth, im_th = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV);\n \n# Copy the thresholded image.\nim_floodfill = im_th.copy()\n \n# Mask used to flood filling.\n# Notice the size needs to be 2 pixels than the image.\nh, w = im_th.shape[:2]\nmask = np.zeros((h+2, w+2), np.uint8)\n \n# Floodfill from point (0, 0)\ncv2.floodFill(im_floodfill, mask, (0,0), 255);\n \n# Invert floodfilled image\nim_floodfill_inv = cv2.bitwise_not(im_floodfill)\n\n# erode and dilate to remove mini kernels of pixels\nkernel = np.ones((3, 3))\nim_floodfill_inv = cv2.erode(im_floodfill_inv, kernel, iterations=3)\nim_floodfill_inv = cv2.dilate(im_floodfill_inv, kernel, iterations=3)\n\n# Get the two biggest blobs\nim_out, mask_labels = get_biggest_blob(im_floodfill_inv, max_blobs=2)\n\nf, axes = plt.subplots(1, 5)\n\naxes[0].imshow(img, cmap='gray')\naxes[0].imshow(sample_mask, cmap='binary', alpha=0.3)\n\naxes[1].imshow(im_th)\naxes[2].imshow(im_floodfill)\naxes[3].imshow(im_floodfill_inv)\naxes[4].imshow(im_out)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a SVM model to get the best line between the lungs\n\nThe idea here is that each lung was labeled by the `get_biggest_blob` function. The SVM model will fit a decision border line between both lungs."},{"metadata":{"trusted":true},"cell_type":"code","source":"label_1_points = np.flip(np.argwhere(mask_labels == 1), 1)\nlabel_2_points = np.flip(np.argwhere(mask_labels == 2), 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.vstack((label_1_points, label_2_points))\ny = np.hstack((\n    np.ones(len(label_1_points)) * 0,\n    np.ones(len(label_2_points)) * 1,\n))\n\ndata = np.column_stack((X, y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select some random samples of pixels\ntrain = data[np.random.choice(data.shape[0], 15000, replace=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train[:, :2]\ny_train = train[:, 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC(kernel='linear')\n\nsvm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def plot_svc_decision_function(model, ax=None, plot_support=True):\n    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n    if ax is None:\n        ax = plt.gca()\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n    \n    # create grid to evaluate model\n    x = np.linspace(xlim[0], xlim[1], 30)\n    y = np.linspace(ylim[0], ylim[1], 30)\n    Y, X = np.meshgrid(y, x)\n    xy = np.vstack([X.ravel(), Y.ravel()]).T\n    P = model.decision_function(xy).reshape(X.shape)\n    \n    # plot decision boundary and margins\n    ax.contour(X, Y, P, colors='k',\n               levels=[-1, 0, 1], alpha=0.5,\n               linestyles=['--', '-', '--'])\n    \n    # plot support vectors\n    if plot_support:\n        ax.scatter(model.support_vectors_[:, 0],\n                   model.support_vectors_[:, 1],\n                   s=300, linewidth=1, c='r', alpha=0.3);\n        \n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n    ax.invert_yaxis()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X0, X1 = X_train[:, 0], X_train[:, 1]\n\nplt.scatter(X0[:300], X1[:300], c=y_train[:300])\nplot_svc_decision_function(svm, plot_support=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get the angle of the SVM decision line and rotate the image accordingly\n\nWith the SVM coeficients ready, we can calculate the angle of the line SVM defined. To align the image, we rotate the original image to the opposite angle so as to cancel the image ratation."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import math\n\ndef get_degree_from_points(x1, y1, x2, y2):\n    Y1 = max(y1, y2)\n    Y2 = min(y1, y2)\n    \n    return math.degrees(math.acos((Y1 - Y2) / math.sqrt( (x1 - x2) ** 2 + (Y1 - Y2) ** 2)))\n\ndef get_coefs_from_points(x1, y1, x2, y2):\n    degree = get_degree_from_points(x1, y1, x2, y2)\n\n    if np.isclose(degree, 0.0):  # Straight vertical lined\n        m = np.nan\n        c = np.nan\n    else:\n        m, c = np.polyfit(\n            np.array([x1, x2], dtype=np.float64),\n            np.array([y1, y2], dtype=np.float64), 1)\n\n    return m, c\n\n\ndef get_line_from_coefs(m, c, img, x=np.nan):\n    height, width = img.shape\n\n    y1 = 0\n    y2 = height\n\n    if not np.isnan(m) and not np.isnan(c):\n        x1 = max(0, min(width, int((y1 - c) / m)))\n        x2 = max(0, min(width, int((y2 - c) / m)))\n    else:\n        x1 = x\n        x2 = x\n\n    return (x1, y1, x2, y2)\n\ndef rotate_2d(points, center, angle=0):\n    \"\"\"Rotates a list of points with respect to a center point\n\n    Parameters\n    ----------\n\n    points : numpy array\n    center : numpy array containing one point\n    angle : float\n        Angle in degrees\"\"\"\n    angle = np.deg2rad(angle)\n\n    return center + np.dot(\n        points - center,\n        np.array([[np.cos(angle), np.sin(angle)], [-np.sin(angle), np.cos(angle)]])\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Support vectors:', svm.support_vectors_)\n\n# Find SVM decision line\n# TODO: make this easier\na = -svm.coef_[0][0] / svm.coef_[0][1]\nb = svm.intercept_[0] / svm.coef_[0][1]\n\ndef decision(x):\n    return a * x - b\n\nx1, x2 = 0, 100\ny1, y2 = decision(x1), decision(x2)\n\nprint(x1, x2, y1, y2)\n\nangle = get_degree_from_points(x1, y1, x2, y2)\nprint('Angle:', angle)\n\nm, c = get_coefs_from_points(x1, y1, x2, y2)\nx1, y1, x2, y2 = get_line_from_coefs(m, c, sample, x1)\n\npoints = np.array([[x1, y1], [x2, y2]])\npoints_ = rotate_2d(points, np.array([int(h / 2), int(w / 2)]), angle=angle)\nx1_, y1_ = points_[0]\nx2_, y2_ = points_[1]\n\nm, c = get_coefs_from_points(x1_, y1_, x2_, y2_)\nx1_, y1_, x2_, y2_ = get_line_from_coefs(m, c, sample, x1_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2)\n\naxes[0].imshow(sample_pre, cmap='gray')\naxes[0].plot([x1, x2], [y1, y2], 'r-')\naxes[1].imshow(Image.fromarray(sample_pre).rotate(-angle), cmap='gray')\naxes[1].plot([x1_, x2_], [y1_, y2_], 'r-')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# WIP\n\nThis work is still in progress. You're free to collaborate or fork if you find it somewhat helpful :)\n\nI haven't successfully been able to correctly detect the lungs on all samples, so probably some further processing will be necessary.\n\nMy plan is to improve the dataset, which I think it's key for getting better results on this kind of competitions. After that, I'll implement some Unet model to train to predict the mask. I'm pretty sure that making the model to learn just one kind of lung orientation will help to improve the results later."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}