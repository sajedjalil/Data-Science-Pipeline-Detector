{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nIn the last Kernel [(Finding Pneumo: EDA and UNet Starter Code)](https://www.kaggle.com/ekhtiar/finding-pneumo-eda-and-unet-starter-code), we did explored the data and trained an UNet model that wasn't performing. In this Kernel, we create a ResNet model, which manages to identify some cases of Pneumothorax.\n\n**In this Kernel we will not take advantage of any leakage because leakage isn't going to save an Pneumothorax patient.** My goal is identify approach and model that hopefully generalizes well to this and other datasets. For this purpose, I will document the journey of training our ResUNet in the summary section of this Kernel."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic imports for the entire Kernel\nimport numpy as np\nimport pandas as pd\n# imports for loading data\nimport pydicom\nfrom glob import glob\nfrom tqdm import tqdm\n# import mask function\nimport sys\nsys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\nfrom mask_functions import rle2mask, mask2rle\n# plotting function\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load rles\nrles_df = pd.read_csv('../input/siim-train-test/siim/train-rle.csv')\n# the second column has a space at the start, so manually giving column name\nrles_df.columns = ['ImageId', 'EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dicom_to_dict(dicom_data, file_path, rles_df, encoded_pixels=True):\n    \"\"\"Parse DICOM dataset and returns a dictonary with relevant fields.\n\n    Args:\n        dicom_data (dicom): chest x-ray data in dicom format.\n        file_path (str): file path of the dicom data.\n        rles_df (pandas.core.frame.DataFrame): Pandas dataframe of the RLE.\n        encoded_pixels (bool): if True we will search for annotation.\n        \n    Returns:\n        dict: contains metadata of relevant fields.\n    \"\"\"\n    \n    data = {}\n    \n    # Parse fields with meaningful information\n    data['patient_name'] = dicom_data.PatientName\n    data['patient_id'] = dicom_data.PatientID\n    data['patient_age'] = int(dicom_data.PatientAge)\n    data['patient_sex'] = dicom_data.PatientSex\n    data['pixel_spacing'] = dicom_data.PixelSpacing\n    data['file_path'] = file_path\n    data['id'] = dicom_data.SOPInstanceUID\n    \n    # look for annotation if enabled (train set)\n    if encoded_pixels:\n        encoded_pixels_list = rles_df[rles_df['ImageId']==dicom_data.SOPInstanceUID]['EncodedPixels'].values\n       \n        pneumothorax = False\n        for encoded_pixels in encoded_pixels_list:\n            if encoded_pixels != ' -1':\n                pneumothorax = True\n        \n        # get meaningful information (for train set)\n        data['encoded_pixels_list'] = encoded_pixels_list\n        data['has_pneumothorax'] = pneumothorax\n        data['encoded_pixels_count'] = len(encoded_pixels_list)\n        \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a list of all the files\ntrain_fns = sorted(glob('../input/siim-train-test/siim/dicom-images-train/*/*/*.dcm'))\n# parse train DICOM dataset\ntrain_metadata_df = pd.DataFrame()\ntrain_metadata_list = []\nfor file_path in tqdm(train_fns):\n    dicom_data = pydicom.dcmread(file_path)\n    train_metadata = dicom_to_dict(dicom_data, file_path, rles_df)\n    train_metadata_list.append(train_metadata)\ntrain_metadata_df = pd.DataFrame(train_metadata_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a list of all the files\ntest_fns = sorted(glob('../input/siim-train-test/siim/dicom-images-test/*/*/*.dcm'))\n# parse test DICOM dataset\ntest_metadata_df = pd.DataFrame()\ntest_metadata_list = []\nfor file_path in tqdm(test_fns):\n    dicom_data = pydicom.dcmread(file_path)\n    test_metadata = dicom_to_dict(dicom_data, file_path, rles_df, encoded_pixels=False)\n    test_metadata_list.append(test_metadata)\ntest_metadata_df = pd.DataFrame(test_metadata_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lung Segmentation\nIn my last EDA, and in the discussion section of this competiton, [Dr. Konya](https://www.kaggle.com/sandorkonya) made some awesome contributions. Something very important and obvious he mentioned is since pneumothorax would only appear on the lungs as far as the use cases for this competition is concerend, we should try to leverage pre-existing models for doing lung segmentation in this competition.\n\nI found some amazing works on Github, one of which is from the imlab-uiip for lung segmentation. They have also uploaded a pre-trained model on the Github repo. In this section, we use this pre-trained model to create masks for the data in this competition. We also conver the mask with RLE function provided by this competition to make it easy for us to use in future cases.\n\nI ran the model once, and the accuracy of the lung segmentation wasn't perfect. However, this model is still probably good enough to automatically crop the unwanted part of our image. In the discussion [Lung segmentation Dataset of the training images by a radiologist](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/100864) [Dr. Konya](https://www.kaggle.com/sandorkonya) points to an annotation he did for the competition to crop out only the important part for us. Using this model we will try to automate this and get the bounding box for our segmentation. In this way, we may be able to remove a lot of noise from our data and get better accuracy of our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nfrom skimage import morphology, io, color, exposure, img_as_float, transform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dir = '../input/lung-segmentation-for-siimacr-pneumothorax/trained_model.hdf5'\nlung_seg_model = tf.keras.models.load_model(model_dir, custom_objects=None, compile=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lung_seg_tensor(file_path, batch_size, seg_size, n_channels):\n    \n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((batch_size, seg_size, seg_size, n_channels))\n\n        # Process Image\n        pixel_array = pydicom.read_file(file_path).pixel_array\n        image_resized = cv2.resize(pixel_array, (seg_size, seg_size))\n        image_resized = exposure.equalize_hist(image_resized)\n        image_resized = np.array(image_resized, dtype=np.float64)\n        image_resized -= image_resized.mean()\n        image_resized /= image_resized.std()\n        # Store Image\n        X[0,] = np.expand_dims(image_resized, axis=2)\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_small_regions(img, size):\n    \"\"\"Morphologically removes small (less than size) connected regions of 0s or 1s.\"\"\"\n    img = morphology.remove_small_objects(img, size)\n    img = morphology.remove_small_holes(img, size)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bounding_box(img):\n    # return max and min of a mask \n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n    return rmin, rmax, cmin, cmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lung_seg_rle(metadata_df, seg_size):\n\n    processed_images = []\n\n    for id, row in metadata_df.iterrows():\n        # get image in the 4d tensor\n        img = get_lung_seg_tensor(row['file_path'],1,seg_size,1)\n        # get segmented mask\n        seg_mask = lung_seg_model.predict(img).reshape((seg_size,seg_size))\n        # only take above .5\n        seg_mask = seg_mask > 0.5\n        # remove small region\n        seg_mask = remove_small_regions(seg_mask, 0.02 * np.prod(seg_size))\n        processed_img = {}\n        processed_img['id'] = row['id']\n        processed_img['lung_mask'] = mask2rle(seg_mask*255, seg_size, seg_size)\n        processed_img['rmin'], processed_img['rmax'], processed_img['cmin'], processed_img['cmax'] = bounding_box(seg_mask)\n        processed_images.append(processed_img)\n    \n    return pd.DataFrame(processed_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seg_size = 256","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have created the [Lung Segmentation For SIIM-ACR Pneumothorax\n](https://www.kaggle.com/ekhtiar/lung-segmentation-for-siimacr-pneumothorax) dataset of the pre-trained model and also the lung segmentation mask pre-processed to make everyone's life easier."},{"metadata":{"trusted":true},"cell_type":"code","source":"#try:\n#    train_lung_mask_df = pd.read_csv('../input/lung-segmentation-for-siimacr-pneumothorax/train_lung_mask.csv')\n#except FileNotFoundError:\ntrain_lung_mask_df = get_lung_seg_rle(train_metadata_df, seg_size)\ntrain_lung_mask_df.to_csv('./train_lung_mask.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#try:\n#    test_lung_mask_df = pd.read_csv('../input/lung-segmentation-for-siimacr-pneumothorax/test_lung_mask.csv')\n#except FileNotFoundError:\ntest_lung_mask_df = get_lung_seg_rle(test_metadata_df, seg_size)\ntest_lung_mask_df.to_csv('./test_lung_mask.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### proof of concept\nlets check out our segmentation and visually inspect if it is working"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_lung_seg(file_path, mask_encoded_list, lung_mask, rmin, rmax, cmin, cmax):\n    \n    pixel_array = pydicom.dcmread(file_path).pixel_array\n    \n    # use the masking function to decode RLE\n    mask_decoded_list = [rle2mask(mask_encoded, 1024, 1024).T for mask_encoded in mask_encoded_list]\n    lung_mask_decoded = cv2.resize(rle2mask(lung_mask, 256, 256), (1024,1024))\n    rmin, rmax, cmin, cmax =  rmin * 4, rmax * 4, cmin * 4, cmax * 4 \n    \n    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(20,10))\n    \n    \n    ax[0].imshow(pixel_array, cmap=plt.cm.bone)\n    ax[0].imshow(lung_mask_decoded, alpha=0.3, cmap=\"Blues\")\n    ax[0].set_title('Xray with Lung Mask')\n    \n    ax[1].imshow(pixel_array[rmin:rmax+1,cmin:cmax+1], cmap=plt.cm.bone)\n    ax[1].set_title('Cropped Xray')\n   \n    ax[2].imshow(lung_mask_decoded, cmap='Blues')\n    for mask_decoded in mask_decoded_list:\n        ax[2].imshow(mask_decoded, alpha=0.3, cmap=\"Reds\")\n    ax[2].set_title('Lung Mask with Pneumothorax')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lm_metadata_df = pd.concat([train_metadata_df, train_lung_mask_df.drop('id',axis=1)], axis=1)\ntest_lm_metadata_df = pd.concat([test_metadata_df, test_lung_mask_df.drop('id',axis=1)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, r in train_lm_metadata_df[train_lm_metadata_df['has_pneumothorax']==True][:10].iterrows():\n    file_path = r['file_path']\n    encoded_pixels_list = r['encoded_pixels_list']\n    lung_mask = r['lung_mask']\n    rmin = r['rmin'] \n    rmax = r['rmax']\n    cmin = r['cmin']\n    cmax = r['cmax']\n    \n    plot_lung_seg(file_path, encoded_pixels_list, lung_mask, rmin, rmax, cmin, cmax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see our model gets it right more often than not. Although our lung segmentation is far from perfect, the crop version of the image looks promising! In the next kernel, I will try to make a comparision and see how close we got to the hand made annotation of 1K images from Dr. Konya."},{"metadata":{},"cell_type":"markdown","source":"## ResUNet\n\nIn this section we will use ResUNet instead of UNet to predict pneumothorax. The original paper that proposes this CNN architecture is [ResUNet-a: a deep learning framework for semantic segmentation of remotely sensed data](https://arxiv.org/abs/1904.00592). If you read the paper you will get more details about the network. However for reference, I am attaching the architecture of the model below: \n\n![ResUNet Architecture](https://raw.githubusercontent.com/nikhilroxtomar/Deep-Residual-Unet/master/images/arch.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining configuration parameters\nimg_size = 512 # image resize size\nbatch_size = 8\n# batch size for training unet\nk_size = 3 # kernel size 3x3\nval_size = .20 # split of training set between train and validation set\nno_pneumo_drop = 0 # dropping some data to balance the class a little bit better","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imports for building the network\nfrom tensorflow import reduce_sum\nfrom tensorflow.keras.backend import pow\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom sklearn.model_selection import train_test_split\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Generator\n\nTo push the data to our model, we will create a custom data generator. A generator lets us load data progressively, instead of loading it all into memory at once. A custom generator allows us to also fit in more customization during the time of loading the data. As the model is being procssed in the GPU, we can use a custom generator to pre-process images via a generator. At this time, we can also take advantage multiple processors to parallelize our pre-processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, file_path_list, labels, batch_size=32, \n                 img_size=256, channels=1, shuffle=True):\n        self.file_path_list = file_path_list\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.channels = channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.file_path_list)) / self.batch_size)\n    \n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        file_path_list_temp = [self.file_path_list[k] for k in indexes]\n        # generate data\n        X, y = self.__data_generation(file_path_list_temp)\n        # return data \n        return X, y\n    \n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.file_path_list))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, file_path_list_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n        y = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n        \n        for idx, file_path in enumerate(file_path_list_temp):\n            \n            id = file_path.split('/')[-1][:-4]\n            rle = self.labels.get(id)\n            image = pydicom.read_file(file_path).pixel_array\n            image_resized = cv2.resize(image, (self.img_size, self.img_size))\n            image_resized = np.array(image_resized, dtype=np.float64)\n            \n            X[idx,] = np.expand_dims(image_resized, axis=2)\n            \n            # if there is no mask create empty mask\n            # notice we are starting of with 1024 because we need to use the rle2mask function\n            if rle is None:\n                mask = np.zeros((1024, 1024))\n            else:\n                if len(rle) == 1:\n                    mask = rle2mask(rle[0], 1024, 1024).T\n                else: \n                    mask = np.zeros((1024, 1024))\n                    for r in rle:\n                        mask =  mask + rle2mask(r, 1024, 1024).T\n                        \n            mask_resized = cv2.resize(mask, (self.img_size, self.img_size))\n            y[idx,] = np.expand_dims(mask_resized, axis=2)\n            \n        # normalize \n        X = X / 255\n        y = (y > 0).astype(int)\n            \n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"masks = {}\nfor index, row in train_metadata_df[train_metadata_df['has_pneumothorax']==1].iterrows():\n    masks[row['id']] = list(row['encoded_pixels_list'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_data = train_metadata_df[train_metadata_df['encoded_pixels_count']==0].index\nnew_train_metadata_df = train_metadata_df.drop(bad_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_data = new_train_metadata_df[new_train_metadata_df['has_pneumothorax'] == False].sample(no_pneumo_drop).index\nnew_train_metadata_df = new_train_metadata_df.drop(drop_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the training data into train and validation set (stratified)\nX_train, X_val, y_train, y_val = train_test_split(new_train_metadata_df.index, new_train_metadata_df['has_pneumothorax'].values, test_size=val_size, random_state=42)\nX_train, X_val = new_train_metadata_df.loc[X_train]['file_path'].values, new_train_metadata_df.loc[X_val]['file_path'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'img_size': img_size,\n          'batch_size': batch_size,\n          'channels': 1,\n          'shuffle': True}\n\n# Generators\ntraining_generator = DataGenerator(X_train, masks, **params)\nvalidation_generator = DataGenerator(X_val, masks, **params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can verify that our generator class is working and is passing the right data visually in the following way."},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = training_generator.__getitem__(0)\nprint(x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nax = fig.add_subplot(1, 2, 1)\nax.imshow(x[6].reshape(img_size, img_size), cmap=plt.cm.bone)\nax = fig.add_subplot(1, 2, 2)\nax.imshow(np.reshape(y[6], (img_size, img_size)), cmap=\"gray\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ResUNet TensorFlow Keras Implementation\n\nLets build the ResUNet model in this section. Actually, I found a nice implementation of ResUNet on [Github](https://github.com/nikhilroxtomar/Deep-Residual-Unet), which I am using for this section of the Kernel."},{"metadata":{"trusted":true},"cell_type":"code","source":"def bn_act(x, act=True):\n    'batch normalization layer with an optinal activation layer'\n    x = tf.keras.layers.BatchNormalization()(x)\n    if act == True:\n        x = tf.keras.layers.Activation('relu')(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_block(x, filters, kernel_size=3, padding='same', strides=1):\n    'convolutional layer which always uses the batch normalization layer'\n    conv = bn_act(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n    return conv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stem(x, filters, kernel_size=3, padding='same', strides=1):\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n    conv = conv_block(conv, filters, kernel_size, padding, strides)\n    shortcut = Conv2D(filters, kernel_size=1, padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    output = Add()([conv, shortcut])\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def residual_block(x, filters, kernel_size=3, padding='same', strides=1):\n    res = conv_block(x, filters, k_size, padding, strides)\n    res = conv_block(res, filters, k_size, padding, 1)\n    shortcut = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    output = Add()([shortcut, res])\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def upsample_concat_block(x, xskip):\n    u = UpSampling2D((2,2))(x)\n    c = Concatenate()([u, xskip])\n    return c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ResUNet(img_size):\n    f = [16, 32, 64, 128, 256, 512, 1024, 2048] * 32\n    inputs = Input((img_size, img_size, 1))\n    \n    ## Encoder\n    e0 = inputs\n    e1 = stem(e0, f[0])\n    e2 = residual_block(e1, f[1], strides=2)\n    e3 = residual_block(e2, f[2], strides=2)\n    e4 = residual_block(e3, f[3], strides=2)\n    e5 = residual_block(e4, f[4], strides=2)\n    e6 = residual_block(e5, f[5], strides=2)\n    e7 = residual_block(e6, f[6], strides=2)\n    \n    ## Bridge\n    b0 = conv_block(e7, f[6], strides=1)\n    b1 = conv_block(b0, f[6], strides=1)\n    \n    ## Decoder\n    u1 = upsample_concat_block(b1, e6)\n    d1 = residual_block(u1, f[6])\n    \n    u2 = upsample_concat_block(d1, e5)\n    d2 = residual_block(u2, f[3])\n    \n    u3 = upsample_concat_block(d2, e4)\n    d3 = residual_block(u3, f[2])\n    \n    u4 = upsample_concat_block(d3, e3)\n    d4 = residual_block(u4, f[1])\n    \n    u5 = upsample_concat_block(d4, e2)\n    d5 = residual_block(u5, f[1])\n    \n    u6 = upsample_concat_block(d5, e1)\n    d6 = residual_block(u6, f[1])\n    \n    outputs = tf.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d6)\n    model = tf.keras.models.Model(inputs, outputs)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dsc(y_true, y_pred):\n    smooth = 1.\n    y_true_f = Flatten()(y_true)\n    y_pred_f = Flatten()(y_pred)\n    intersection = reduce_sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dsc(y_true, y_pred)\n    return loss\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ResUNet(img_size)\nadam = tf.keras.optimizers.Adam(lr = 0.01, epsilon = 0.1)\nmodel.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dsc])\n#model.summary() # print out the architecture of our network","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load a pre trained model here if you wish\n# model.load_weights('../input/resunet-e200-s256/ResUNet.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# running more epoch to see if we can get better results\nhistory = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('./ResUNet.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Plotting Model Training History\n\nIn this section we will use the simple non-flashy matplotlib to plot out the performance of our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.figure(figsize=(20,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['dsc'])\nplt.plot(history.history['val_dsc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n\n# summarize history for loss\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking out our model\n\nWe can visually inspect how our model is doing for our model in the following way."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_train(img, mask, pred):\n    \n    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(15,5))\n    \n    ax[0].imshow(img, cmap=plt.cm.bone)\n    ax[0].set_title('Chest X-Ray')\n    \n    ax[1].imshow(mask, cmap=plt.cm.bone)\n    ax[1].set_title('Mask')\n    \n    ax[2].imshow(pred, cmap=plt.cm.bone)\n    ax[2].set_title('Pred Mask')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets loop over the predictions and print some good-ish results\ncount = 0\nfor i in range(0,50):\n    if count <= 50:\n        x, y = validation_generator.__getitem__(i)\n        predictions = model.predict(x)\n        for idx, val in enumerate(x):\n            #if y[idx].sum() > 0 and count <= 15: \n                img = np.reshape(x[idx]* 255, (img_size, img_size))\n                mask = np.reshape(y[idx]* 255, (img_size, img_size))\n                pred = np.reshape(predictions[idx], (img_size, img_size))\n                pred = pred > 0.5\n                pred = pred * 255\n                plot_train(img, mask, pred)\n                count += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making Predictions\n\nIn this section, we predict using our model and create a submission without taking advantage of the leak."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_tensor(file_path, batch_size, img_size, channels):\n    \n        X = np.empty((batch_size, img_size, img_size, channels))\n\n        # Store sample\n        pixel_array = pydicom.read_file(file_path).pixel_array\n        image_resized = cv2.resize(pixel_array, (img_size, img_size))\n        image_resized = np.array(image_resized, dtype=np.float64)\n        image_resized -= image_resized.mean()\n        image_resized /= image_resized.std()\n        X[0,] = np.expand_dims(image_resized, axis=2)\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this competition we are very likely to make a lot of tiny small predictions. If the region is very small generally it is a good policy to take them out. The function below will help us do this."},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import morphology\n\ndef remove_small_regions(img, size):\n    \"\"\"Morphologically removes small (less than size) connected regions of 0s or 1s.\"\"\"\n    img = morphology.remove_small_objects(img, size)\n    img = morphology.remove_small_holes(img, size)\n    return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets use the model we have just built up to make prediction and identify pneumothorax."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = []\n\nfor i, row in test_metadata_df.iterrows():\n\n    test_img = get_test_tensor(test_metadata_df['file_path'][i],1,img_size,1)\n    \n    pred_mask = model.predict(test_img).reshape((img_size,img_size))\n    prediction = {}\n    prediction['ImageId'] = str(test_metadata_df['id'][i])\n    pred_mask = cv2.resize(pred_mask.astype('float32'), (1024, 1024))\n    pred_mask = (pred_mask > .5).astype(int)\n    pred_mask = remove_small_regions(pred_mask, 0.02 * np.prod(1024))\n    \n    if pred_mask.sum() < 1:\n        prediction['EncodedPixels']=  -1\n    else:\n        prediction['EncodedPixels'] = mask2rle(pred_mask.T * 255, 1024, 1024)\n        \n    submission.append(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame(submission)\nsubmission_df = submission_df[['ImageId','EncodedPixels']]\n# check out some predictions and see if it looks good\nsubmission_df[ submission_df['EncodedPixels'] != -1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}