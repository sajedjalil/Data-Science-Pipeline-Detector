{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font color=indigo size=20> Dive into DICOM Datasets </font>\n\n<font color=indigo><b> Work on progress... </b></font>  \n<font color=indigo><b> Last updated: Jun.28.2019 </b></font>\n  \n---\n\nThis kernel is based on [Jesper's awesome kernel](https://www.kaggle.com/jesperdramsch/intro-chest-xray-dicom-viz-u-nets-full-data).   \nAnd I used the external data made by [seesee](https://www.kaggle.com/seesee).  \n  \nHere I will do some EDA on train_rle and DICOM datasets.  \n\n---\n\n#### Helpful Passed Competitions:  \n* [Latest Instance Segmentation Task (Airbus Ship Detection Challenge)](https://www.kaggle.com/c/airbus-ship-detection)  \n    * Solutions  \n    [4th](https://towardsdatascience.com/image-segmentation-kaggle-experience-9a41cb8924f0) : \n    U-Net, [watershed](https://en.wikipedia.org/wiki/Watershed_%28image_processing%29)  \n    [6th](https://www.kaggle.com/c/airbus-ship-detection/discussion/71782#latest-558831) :\n    empty / non-empty binary classifier, ResNetBased U-Net, ResNetBased MaskRCNN  \n    [8th](https://www.kaggle.com/c/airbus-ship-detection/discussion/71601#latest-422002) :\n    empty / non-empty binary classifier, U-Net, MaskRCNN  \n    [9th](https://www.kaggle.com/c/airbus-ship-detection/discussion/71595#latest-457550) :\n    empty / non-empty binary classifier, Densenet169Based U-Net  \n    [10th](https://www.kaggle.com/c/airbus-ship-detection/discussion/71607#latest-423229) :\n    MaskRCNN without ensemble  \n\n\n* [Detection Task on Chest X-Ray Images (RSNA)](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge)\n    * [External Data Thread](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/64345#latest-409834)\n    * Solutions  \n    [1st](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/70421#latest-496413), \n    [2nd](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/70427#latest-497399), \n    [3rd](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/70632#latest-440310), \n    [4th](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/71070#latest-525861), \n    [5th](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/79381#latest-465479), \n    [6th](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/70650#latest-417951), \n    [7th](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/79265#latest-464970), \n    [8th](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/79115#latest-464026), \n    [10th](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/discussion/71022#latest-419873)  \n\n\n![](https://engineering.stanford.edu/sites/default/files/styles/full_width_banner_tall/public/xray.jpg?itok=kj2FlhrR)\n\n---"},{"metadata":{},"cell_type":"markdown","source":"# Load Packages\n\n- We will use an excellent package **pydicom** which can treat DICOM datasets\n- Also not forget to append a path to include **mask_functions.py**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport psutil\nimport glob\n\n# https://pydicom.github.io/pydicom/stable/auto_examples/input_output/plot_read_dicom.html\nimport pydicom\n\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../input/siim-acr-pneumothorax-segmentation/\"))\n\nfrom matplotlib import cm\nfrom matplotlib import pyplot as plt\n\nimport tensorflow as tf\n\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\nimport sys\nsys.path.append('../input/siim-acr-pneumothorax-segmentation/')\n\nfrom mask_functions import rle2mask\nfrom multiprocessing.pool import Pool, ThreadPool\nfrom joblib import Parallel, delayed\n\nplt.style.use('ggplot')\npd.set_option(\"display.max_colwidth\", 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Run Length Encoded Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_rle = pd.read_csv('../input/siim-train-test/siim/train-rle.csv')\nprint(tr_rle.shape)\ntr_rle.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As pointed out in discussion threads, some ImageIds have multiple rows in `train_rle.csv`. In that case, the patients seem to have multiple lung collapse.  \nIn test dataset, we must also predict multiple parts.  \n\n> https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/97054#560819  \n> Multiple instances of the same ImageId in any of the annotations files indicates the existence of multiple objects on the same image. Your submission should predict using multiple lines, a line representing each Pneumothorax object."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{} unique ImageId'.format(tr_rle.ImageId.nunique()))\ntmp = tr_rle.groupby('ImageId').agg({'ImageId':['count']}).reset_index()\ntmp.columns = ['ImageId', 'count']\nid_multi = tmp.loc[tmp['count'] > 1, 'ImageId']\ntr_rle[tr_rle['ImageId'].isin(id_multi)].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- In the case of segmenting small positive pixels, using stride 2 convolution can be sometimes crucial(making scores worse), using stride 1 convolution in the first layer of encoder would be better.\n- So computing **Perimeters** and **Surfaces** would be interesting.  \nLet's check those on examples with masks."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper function\ndef calc_per_sur(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 255\n        current_position += lengths[index]\n\n    return mask.sum(), lengths.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = tr_rle.loc[tr_rle['ImageId'].isin(id_multi), ' EncodedPixels'].apply(\n    lambda x: calc_per_sur(x, 1024, 1024))\ntr_rle['Perimeter'] = np.nan\ntr_rle['Surface'] = np.nan\ntr_rle['Surface_Ratio(%)'] = np.nan\ntr_rle.loc[tr_rle['ImageId'].isin(id_multi), 'Perimeter'] = tmp.apply(lambda x: x[0])\ntr_rle.loc[tr_rle['ImageId'].isin(id_multi), 'Surface'] = tmp.apply(lambda x: x[1])\ntr_rle.loc[tr_rle['ImageId'].isin(id_multi), 'Surface_Ratio(%)'] = tmp.apply(lambda x: x[1] * 100 / 1024**2)\ntr_rle.loc[:, 'Perimeter':'Surface_Ratio(%)'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_rle[tr_rle['ImageId'].isin(id_multi)].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The Surfaces of masks is about 1 ~ 8 % of 1024 x 1024 pixcel images\n* If we resize images, be careful of the number of stride"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 5))\ntr_rle['Surface_Ratio(%)'].hist(ax=ax, bins=50, color='deeppink', rwidth=0.9)\nax.set_xlabel('Surface Ratio (%)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# sample_submission.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/siim-acr-pneumothorax-segmentation/sample_submission.csv')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{} unique ImageId / {} rows'.format(sub.ImageId.nunique(), len(sub)))\ntmp = sub.groupby('ImageId').agg({'ImageId':['count']}).reset_index()\ntmp.columns = ['ImageId', 'count']\nid_multi = tmp.loc[tmp['count'] > 1, 'ImageId']\nprint('{} ImageIds have multiple rows.'.format(len(id_multi)))\nsub[sub['ImageId'].isin(id_multi)].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DICOM Data\n\nDicom is a format that has metadata, as well as Pixeldata attached to it. Below I extract some basic info with an image. You will know about the gender and age of the patient, as well as info how the image is sampled and generated. Quite useful to programatically read. Here's the [Wikipedia](https://en.wikipedia.org/wiki/DICOM) article for it.  \n  \nIn this section, we will use helper functions from the following kernel.  \nhttps://www.kaggle.com/schlerp/getting-to-know-dicom-and-the-data/data"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"def show_dcm_info(fp, dataset):\n    print(\"Filename.........:\", fp.split('/')[-1])\n    print(\"Storage type.....:\", dataset.SOPClassUID)\n    pat_name = dataset.PatientName\n    display_name = pat_name.family_name + \", \" + pat_name.given_name\n    print(\"Patient's name......:\", display_name)\n    print(\"Patient id..........:\", dataset.PatientID)\n    print(\"Patient's Age.......:\", dataset.PatientAge)\n    print(\"Patient's Sex.......:\", dataset.PatientSex)\n    print(\"Modality............:\", dataset.Modality)\n    print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n    print(\"View Position.......:\", dataset.ViewPosition)\n    \n    if 'PixelData' in dataset:\n        rows = int(dataset.Rows)\n        cols = int(dataset.Columns)\n        print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n            rows=rows, cols=cols, size=len(dataset.PixelData)))\n        if 'PixelSpacing' in dataset:\n            print(\"Pixel spacing....:\", dataset.PixelSpacing)\n\ndef plot_pixel_array(dataset, figsize=(10,10)):\n    plt.figure(figsize=figsize)\n    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    plt.grid(False)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fp in glob.glob('../input/siim-train-test/siim/dicom-images-train/*/*/*.dcm'):\n    dataset = pydicom.dcmread(fp)\n    show_dcm_info(fp, dataset)\n    plot_pixel_array(dataset)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DICOM datasets have more information in addition to above.  \nLet's explore all attributes of a DICOM object and check whether other meaningful information exists or not.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"dicom_attr = ['AccessionNumber', \n              'BitsAllocated', \n              'BitsStored', \n              'BodyPartExamined', \n              'Columns', \n              'ConversionType', \n              'HighBit',\n              'InstanceNumber',\n              'LossyImageCompression',\n              'LossyImageCompressionMethod',\n              'Modality',\n              'PatientAge',\n              'PatientBirthDate',\n              'PatientID',\n              'PatientName',\n              'PatientOrientation',\n              'PatientSex',\n              'PhotometricInterpretation',\n#               'PixelData',\n              'PixelRepresentation',\n              'PixelSpacing',\n              'ReferringPhysicianName',\n              'Rows',\n              'SOPClassUID',\n              'SOPInstanceUID',\n              'SamplesPerPixel',\n              'SeriesDescription',\n              'SeriesInstanceUID',\n              'SeriesNumber',\n              'SpecificCharacterSet',\n              'StudyDate',\n              'StudyID',\n              'StudyInstanceUID',\n              'StudyTime',\n              'ViewPosition']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_features(fp):\n    ret = []\n    ret.append(fp.split('/')[-1][:-4])\n    dataset = pydicom.dcmread(fp)\n    for da in dicom_attr:\n        ret.append(dataset.__getattr__(da))\n    return np.array(ret).T\n\ndicom_df = Parallel(n_jobs=psutil.cpu_count(), verbose=1)(\n    (delayed(create_features)(fp) for fp in glob.glob('../input/siim-train-test/siim/dicom-images-train/*/*/*.dcm'))\n)\ndicom_df = pd.DataFrame(np.array(dicom_df), columns=['ImageId'] + dicom_attr)\ndicom_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the number of unique values in each column."},{"metadata":{"trusted":true},"cell_type":"code","source":"dicom_df['PixelSpacing'] = dicom_df['PixelSpacing'].apply(lambda x: x[0])\ndicom_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There looks only 5 features to be useful.  \n( Column `ReferringPhysicianName` is empty )"},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_col = ['ImageId',\n              'PatientAge', \n              'PatientSex', \n#               'ReferringPhysicianName',\n              'ViewPosition', \n              'PixelSpacing']\ntr_rle = tr_rle.merge(dicom_df.loc[:, useful_col], how='left', on='ImageId')\ntr_rle.loc[:, 'IsDisease'] = (tr_rle.loc[:, ' EncodedPixels'] != ' -1')\ntr_rle.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore the Relationships between the Onset of Pneumothorax and Features.\n## PatientAge"},{"metadata":{},"cell_type":"markdown","source":"- There is an example which has **413** age. I guess he will be a wizard."},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = tr_rle.groupby('PatientAge').agg({\n    'IsDisease':['count', 'sum']\n}).reset_index()\ntmp.columns = ['PatientAge', 'count', 'sum']\ntmp['PatientAge'] = tmp['PatientAge'].astype('int')\ntmp.sort_values(by='PatientAge', inplace=True)\ntmp['Ratio'] = tmp['sum'] / tmp['count']\n\nfig, ax = plt.subplots(figsize=(7.5, 15))\nax.barh(range(len(tmp)), tmp['Ratio'], \n        color='deeppink', align='center', height=0.5)\nax.set_yticks(range(len(tmp)))\nax.set_yticklabels(tmp['PatientAge'].astype('str') + ' / (' + tmp['count'].astype('str') + ')', \n                   fontsize=7, color='dimgray')\nax.set_xlabel('Incidence Ratio', color='dimgray')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PatinetSex\n\n- The annual age-adjusted incidence rate (AAIR) of PSP is thought to be three to six times as high in males as in females.  \n  [wikipedia Pneumothorax](https://en.wikipedia.org/wiki/Pneumothorax)\n- If the mechanisms of onset of Pneumothorax is different in each sex, building each model would be interesting.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = tr_rle.groupby('PatientSex').agg({\n    'IsDisease':['count', 'sum']\n}).reset_index()\ntmp.columns = ['PatientSex', 'count', 'sum']\ntmp['Ratio'] = tmp['sum'] / tmp['count']\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(range(len(tmp)), tmp['Ratio'], \n        color='deeppink', align='center', width=0.5)\nax.set_xticks(range(len(tmp)))\nax.set_xticklabels(tmp['PatientSex'].astype('str') + ' / (' + tmp['count'].astype('str') + ')', \n                   fontsize=10, color='dimgray')\nax.set_ylabel('Incidence Ratio', color='dimgray')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ViewPosition\n\n- I can't understand the difference of AP and PA in incidence ratio is meaningful or not.  \n[What is the difference between an AP and a PA view of an X-ray?](https://www.quora.com/What-is-the-difference-between-an-AP-and-a-PA-view-of-an-X-ray)"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = tr_rle.groupby('ViewPosition').agg({\n    'IsDisease':['count', 'sum']\n}).reset_index()\ntmp.columns = ['ViewPosition', 'count', 'sum']\ntmp['Ratio'] = tmp['sum'] / tmp['count']\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.bar(range(len(tmp)), tmp['Ratio'], \n        color='deeppink', align='center', width=0.5)\nax.set_xticks(range(len(tmp)))\nax.set_xticklabels(tmp['ViewPosition'].astype('str') + ' / (' + tmp['count'].astype('str') + ')', \n                   fontsize=10, color='dimgray')\nax.set_ylabel('Incidence Ratio', color='dimgray')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PixelSpacing\n\n- There are 11 kinds of PixelSpacing."},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_rle['PixelSpacing'] = tr_rle['PixelSpacing'].round(6)\ntmp = tr_rle.groupby('PixelSpacing').agg({\n    'IsDisease':['count', 'sum']\n}).reset_index()\ntmp.columns = ['PixelSpacing', 'count', 'sum']\ntmp['Ratio'] = tmp['sum'] / tmp['count']\n\nfig, ax = plt.subplots(figsize=(20, 5))\nax.bar(range(len(tmp)), tmp['Ratio'], \n        color='deeppink', align='center', width=0.5)\nax.set_xticks(range(len(tmp)))\nax.set_xticklabels(tmp['PixelSpacing'].astype('str') + ' / (' + tmp['count'].astype('str') + ')', \n                   fontsize=13, color='dimgray')\nax.set_ylabel('Incidence Ratio', color='dimgray')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How do the masks look like?\n\nFirst let's look at all the sample images. We can see different modes of collection. It becomes very evident, that we have to be careful about the top right marker on the image. The different L may mess with our data. Could it be usable leakage as it points to the hospital it was taken at? Yes, yes it could, but I'm *sure* Kaggle took care of this.\n\nThen we'll look at 3 images and the masks that come with it. Personally, I can't really make out how to find the in the images. Play around with it, in some of the other images, it is definitely more visible."},{"metadata":{},"cell_type":"markdown","source":"## X-Ray Images without Mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_img = 5 * 3\nfig, ax = plt.subplots(nrows=num_img // 5, ncols=5, sharey=True, figsize=(20, num_img // 5 * 4))\naxes = ax.ravel()\nfor q, fp in enumerate(glob.glob('../input/siim-train-test/siim/dicom-images-train/*/*/*.dcm')[:num_img]):\n    dataset = pydicom.dcmread(fp)\n    axes[q].imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    axes[q].grid(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## X-Ray Images with Masks\n\n- Can you identify the diseases? I could not..."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_img = 5 * 3\nfig, ax = plt.subplots(nrows=num_img // 5, ncols=5, sharey=True, figsize=(20, num_img // 5 * 4))\naxes = ax.ravel()\nfor q, fp in enumerate(glob.glob('../input/siim-train-test/siim/dicom-images-train/*/*/*.dcm')[:num_img]):\n    dataset = pydicom.dcmread(fp)\n    axes[q].imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    axes[q].grid(False)\n    flag = (tr_rle.loc[:, 'ImageId'] == fp.split('/')[-1][:-4])\n    if tr_rle.loc[flag, ' EncodedPixels'].values[0] != ' -1':\n        mask = rle2mask(tr_rle.loc[flag, ' EncodedPixels'].values[0], 1024, 1024).T\n        axes[q].set_title('Pneumothorax', fontsize=10)\n        mask[mask == 0] = np.nan\n        axes[q].imshow(mask, alpha = 0.2, vmin = 0, vmax = 1)\n    else:\n        axes[q].set_title('No Diseases', fontsize=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Zoom In"},{"metadata":{"trusted":true},"cell_type":"code","source":"samp_id = tr_rle.loc[tr_rle.IsDisease == True, \"ImageId\"].sample(1).values[0]\nfig, ax = plt.subplots(1, 2, figsize=(20, 10))\naxes = ax.ravel()\nfp = glob.glob('../input/siim-train-test/siim/dicom-images-train/*/*/{}.dcm'.format(samp_id))[0]\ndataset = pydicom.dcmread(fp)\naxes[0].imshow(dataset.pixel_array, cmap=plt.cm.bone)\naxes[0].grid(False)\naxes[1].imshow(dataset.pixel_array, cmap=plt.cm.bone)\naxes[1].grid(False)\nmask = rle2mask(tr_rle.loc[tr_rle.ImageId == samp_id, ' EncodedPixels'].values[0], 1024, 1024).T\nmask[mask == 0] = np.nan\naxes[1].imshow(mask, alpha = 0.3, vmin = 0, vmax = 1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be honestly, I could NOT identify Pneumothorax from this X-Ray images. I hope our segmentation models can detect these.  \nNext I will try [this](https://github.com/JosephPB/XNet)."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# EOF"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}