{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8c0a35716c8cc97b11227ec6677f491aa307de3"},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport glob\nimport scipy\nimport cv2\n\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfc901dd07e761741d6f505e468d534b02964bb0"},"cell_type":"code","source":"\nimport random","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"a072507a4b551ae47a0a998dd9290d0c5fc650b1"},"cell_type":"markdown","source":"**Exploration**\n"},{"metadata":{"trusted":true,"_uuid":"e00ae99faa263f5ab696f56d379fd4e6fe999389"},"cell_type":"code","source":"\ntrain_data = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"396ccaaa12bddec9f19f8d82d5113a0c36a8532b"},"cell_type":"code","source":"\ntrain_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11bb60dee5e37d08d8893070b71d017e57517298"},"cell_type":"code","source":"\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e8365660954efe5c325cfbd9f46623c20921569"},"cell_type":"code","source":"\ntrain_data.has_cactus.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"516f2aad4774dff5de80504089d4bd9e940e08e6"},"cell_type":"code","source":"\ntrain_data.has_cactus.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0961d59ffd56bffd8e4e092ea42fe0c743a7b405"},"cell_type":"code","source":"\ntrain_data.has_cactus.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8ac9eba107afe5c2d99b7b2da52ef2d57449da7"},"cell_type":"code","source":"\ntrain_data.has_cactus.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b71d697d0f8911bc5aa51a10494319ed7544560"},"cell_type":"markdown","source":"**Model**"},{"metadata":{"trusted":true,"_uuid":"f9ff1b40ee8496610a4cb47eeb5da6a02a422b7e"},"cell_type":"code","source":"\ndef image_generator2(batch_size = 16, all_data=True, shuffle=True, train=True, indexes=None):\n    while True:\n        if indexes is None:\n            if train:\n                if all_data:\n                    indexes = np.arange(train_data.shape[0])\n                else:\n                    indexes = np.arange(train_data[:15000].shape[0])\n                if shuffle:\n                    np.random.shuffle(indexes)\n            else:\n                indexes = np.arange(train_data[15000:].shape[0])\n            \n        N = int(len(indexes) / batch_size)\n       \n\n        # Read in each input, perform preprocessing and get labels\n        for i in range(N):\n            current_indexes = indexes[i*batch_size: (i+1)*batch_size]\n            batch_input = []\n            batch_output = [] \n            for index in current_indexes:\n                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n                batch_input += [img]\n                batch_input += [img[::-1, :, :]]\n                batch_input += [img[:, ::-1, :]]\n                batch_input += [np.rot90(img)]\n                \n                temp_img = np.zeros_like(img)\n                temp_img[:28, :, :] = img[4:, :, :]\n                batch_input += [temp_img]\n                \n                temp_img = np.zeros_like(img)\n                temp_img[:, :28, :] = img[:, 4:, :]\n                batch_input += [temp_img]\n                \n                temp_img = np.zeros_like(img)\n                temp_img[4:, :, :] = img[:28, :, :]\n                batch_input += [temp_img]\n                \n                temp_img = np.zeros_like(img)\n                temp_img[:, 4:, :] = img[:, :28, :]\n                batch_input += [temp_img]\n                \n                batch_input += [cv2.resize(img[2:30, 2:30, :], (32, 32))]\n                \n                batch_input += [scipy.ndimage.interpolation.rotate(img, 10, reshape=False)]\n                \n                batch_input += [scipy.ndimage.interpolation.rotate(img, 5, reshape=False)]\n                \n                \n                for _ in range(11):\n                    batch_output += [train_data.has_cactus[index]]\n                \n            batch_input = np.array( batch_input )\n            batch_output = np.array( batch_output )\n        \n            yield( batch_input, batch_output.reshape(-1, 1) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_examples = train_data[train_data.has_cactus==1]\nnegative_examples = train_data[train_data.has_cactus==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment_img(img):\n    batch_input = []\n    batch_input += [img]\n    batch_input += [img[::-1, :, :]]\n    batch_input += [img[:, ::-1, :]]\n    batch_input += [np.rot90(img)]\n                \n    temp_img = np.zeros_like(img)\n    temp_img[:28, :, :] = img[4:, :, :]\n    batch_input += [temp_img]\n                \n    temp_img = np.zeros_like(img)\n    temp_img[:, :28, :] = img[:, 4:, :]\n    batch_input += [temp_img]\n                \n    temp_img = np.zeros_like(img)\n    temp_img[4:, :, :] = img[:28, :, :]\n    batch_input += [temp_img]\n                \n    temp_img = np.zeros_like(img)\n    temp_img[:, 4:, :] = img[:, :28, :]\n    batch_input += [temp_img]\n                \n    batch_input += [cv2.resize(img[2:30, 2:30, :], (32, 32))]\n                \n    batch_input += [scipy.ndimage.interpolation.rotate(img, 10, reshape=False)]\n                \n    batch_input += [scipy.ndimage.interpolation.rotate(img, 5, reshape=False)]\n    \n    return batch_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3c9f90999806f09488b0c86dba480784dd024eb"},"cell_type":"code","source":"\ndef image_generator(batch_size = 8, all_data=True, shuffle=True, train=True, indexes=None):\n    while True:\n        if indexes is None:\n            if train:\n                indexes = positive_examples.index.tolist()\n                neg_indexes = negative_examples.index.tolist()\n                if shuffle:\n                    np.random.shuffle(indexes)\n                    np.random.shuffle(neg_indexes)\n            \n        N = int(len(indexes) / (batch_size/2))\n        neg_N = int(len(neg_indexes) / (batch_size/2))\n       \n        j = 0\n\n        # Read in each input, perform preprocessing and get labels\n        for i in range(N):\n            current_indexes = indexes[i*(batch_size//2): (i+1)*(batch_size//2)]\n            current_neg_indexes = neg_indexes[j*(batch_size//2): (j+1)*(batch_size//2)]\n            j = (j + 1) % neg_N\n            batch_input = []\n            batch_output = [] \n            for ind in range(len(current_indexes)):\n                index = current_indexes[ind]\n                neg_index = current_neg_indexes[ind]\n                \n                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n                batch_input.extend(augment_img(img))\n                for _ in range(11):\n                    batch_output += [train_data.has_cactus[index]]\n                \n                neg_img = mpimg.imread('../input/train/train/' + train_data.id[neg_index])\n                batch_input.extend(augment_img(neg_img))\n                for _ in range(11):\n                    batch_output += [train_data.has_cactus[neg_index]]\n                \n#                 factor = 0.05\n#                 new_img = factor*neg_img + (1-factor)*img\n#                 batch_input.append(new_img)\n#                 batch_output += [factor*train_data.has_cactus[neg_index]+(1-factor)*train_data.has_cactus[index]]\n                \n#                 factor = 0.95\n#                 new_img = factor*neg_img + (1-factor)*img\n#                 batch_input.append(new_img)\n#                 batch_output += [factor*train_data.has_cactus[neg_index]+(1-factor)*train_data.has_cactus[index]]\n            \n                \n                \n            batch_input = np.array( batch_input )\n            batch_output = np.array( batch_output )\n        \n            yield( batch_input, batch_output.reshape(-1, 1) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4337c52c9073b3386d503202392af4a6f7fb4dc8"},"cell_type":"code","source":"model = keras.models.Sequential()\nmodel.add(keras.layers.Conv2D(64, (5, 5), input_shape=(32, 32, 3)))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.LeakyReLU(alpha=0.3))\n\nmodel.add(keras.layers.Conv2D(64, (5, 5)))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.LeakyReLU(alpha=0.3))\n\nmodel.add(keras.layers.Conv2D(128, (5, 5)))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.LeakyReLU(alpha=0.3))\n\nmodel.add(keras.layers.Conv2D(128, (5, 5)))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.LeakyReLU(alpha=0.3))\n\nmodel.add(keras.layers.Conv2D(256, (3, 3)))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.LeakyReLU(alpha=0.3))\n\nmodel.add(keras.layers.Conv2D(256, (3, 3)))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.LeakyReLU(alpha=0.3))\n\nmodel.add(keras.layers.Conv2D(512, (3, 3)))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.LeakyReLU(alpha=0.3))\n\nmodel.add(keras.layers.Flatten())\n\n\nmodel.add(keras.layers.Dense(100))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.LeakyReLU(alpha=0.3))\n\nmodel.add(keras.layers.Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94139886cb2ac2e3d09ca4a439a02a5a7c60017c"},"cell_type":"code","source":"\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b49b1fbb16775b030237fe721d9ed550242cb56e"},"cell_type":"code","source":"\nopt = keras.optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ce20c2953167cd775249eb4bcd1f074d1e97ca1"},"cell_type":"code","source":"def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n    '''\n    Wrapper function to create a LearningRateScheduler with step decay schedule.\n    '''\n    def schedule(epoch):\n        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n    \n    return keras.callbacks.LearningRateScheduler(schedule)\n\nlr_sched = step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=2)\nearly_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n\nmodel.fit_generator(image_generator(), steps_per_epoch= train_data.shape[0] / 8, epochs=30, callbacks=[lr_sched, early_stop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n#     '''\n#     Wrapper function to create a LearningRateScheduler with step decay schedule.\n#     '''\n#     def schedule(epoch):\n#         return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n    \n#     return keras.callbacks.LearningRateScheduler(schedule)\n\n# lr_sched = step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=2)\n\n# model.fit_generator(image_generator(), steps_per_epoch= train_data.shape[0] / 8, epochs=20, callbacks=[lr_sched])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(image_generator2(), steps=train_data.shape[0]//16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.evaluate_generator(image_generator(), steps=train_data.shape[0]//8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7db07bc211668a4f280a8a127911dc41ad2d5ac"},"cell_type":"code","source":"\n# keras.backend.eval(model.optimizer.lr.assign(0.00001))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c10eb0a90953f8afd803e65b8106d806278eb81f"},"cell_type":"code","source":"\n# model.fit_generator(image_generator(), steps_per_epoch= train_data.shape[0] / 16, epochs=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96dfee3f7779bf3ab414e1641fc6f232bee977f9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2a3fec0fad75eba5b16335a8caf4716c63639a9"},"cell_type":"code","source":"\nindexes = np.arange(train_data.shape[0])\nN = int(len(indexes) / 64)   \nbatch_size = 64\n\nwrong_ind = []\nfor i in range(N):\n            current_indexes = indexes[i*64: (i+1)*64]\n            batch_input = []\n            batch_output = [] \n            for index in current_indexes:\n                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n                batch_input += [img]\n                batch_output.append(train_data.has_cactus[index])\n            \n            batch_input = np.array( batch_input )\n#             batch_output = np.array( batch_output )\n\n            model_pred = model.predict_classes(batch_input)\n            for j in range(len(batch_output)):\n                if model_pred[j] != batch_output[j]:\n                    wrong_ind.append(i*batch_size+j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02cbcd07663980d89c0229052040e7a6efc3cea9"},"cell_type":"code","source":"\nlen(wrong_ind)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99aba14ddb0268f0b8ff0b1af520a2eb5694a59e"},"cell_type":"code","source":"\nindexes = np.arange(train_data.shape[0])\nN = int(len(indexes) / 64)   \nbatch_size = 64\n\nwrong_ind = []\nfor i in range(N):\n            current_indexes = indexes[i*64: (i+1)*64]\n            batch_input = []\n            batch_output = [] \n            for index in current_indexes:\n                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n                batch_input += [img[::-1, :, :]]\n                batch_output.append(train_data.has_cactus[index])\n            \n            batch_input = np.array( batch_input )\n\n            model_pred = model.predict_classes(batch_input)\n            for j in range(len(batch_output)):\n                if model_pred[j] != batch_output[j]:\n                    wrong_ind.append(i*batch_size+j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f60db58eb1452f2a1efa579cf3553d3ed97b760"},"cell_type":"code","source":"\nlen(wrong_ind)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f3df1560928f63f709862bd2cf157626c91419f"},"cell_type":"code","source":"\nindexes = np.arange(train_data.shape[0])\nN = int(len(indexes) / 64)   \nbatch_size = 64\n\nwrong_ind = []\nfor i in range(N):\n            current_indexes = indexes[i*64: (i+1)*64]\n            batch_input = []\n            batch_output = [] \n            for index in current_indexes:\n                img = mpimg.imread('../input/train/train/' + train_data.id[index])\n                batch_input += [img[:, ::-1, :]]\n                batch_output.append(train_data.has_cactus[index])\n            \n            batch_input = np.array( batch_input )\n\n            model_pred = model.predict_classes(batch_input)\n            for j in range(len(batch_output)):\n                if model_pred[j] != batch_output[j]:\n                    wrong_ind.append(i*batch_size+j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2080af1860ec56cb4995fc9a994a5466d963980b"},"cell_type":"code","source":"\nlen(wrong_ind)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8721278a9113d1f31ffbe6bfb2c7e9f50efdd3cc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19f369e7b978dbbe62cf90798a58fea1f9618421"},"cell_type":"code","source":"\n!ls ../input/test/test/* | wc -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0647c120d566e8e610c47a6b0c7ce302453607e2"},"cell_type":"code","source":"\ntest_files = os.listdir('../input/test/test/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ec494e58bd9cae89de579c0f139f19758dede6b"},"cell_type":"code","source":"\nlen(test_files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5da812ece13b25665dc1c608e5b6aacdcf1611f9"},"cell_type":"code","source":"\nbatch = 40\nall_out = []\nfor i in range(int(4000/batch)):\n    images = []\n    for j in range(batch):\n        img = mpimg.imread('../input/test/test/'+test_files[i*batch + j])\n        images += [img]\n    out = model.predict(np.array(images))\n    all_out += [out]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"410fff04d4f646e25bef760bc2a72b45e2c51642"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"230944dcd785fa2c6e3cefeda0798bab12361397"},"cell_type":"code","source":"\nall_out = np.array(all_out).reshape((-1, 1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"998937f04a36ee9f575b10b82e7e5783db9ab91a"},"cell_type":"code","source":"\nall_out.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b43a6dbc8ddba1234edaf899192273da3936f544"},"cell_type":"code","source":"\nsub_file = pd.DataFrame(data = {'id': test_files, 'has_cactus': all_out.reshape(-1).tolist()})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6122bc9076f7ac65545921713f77b8358a250e15"},"cell_type":"code","source":"\nsub_file.to_csv('sample_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}