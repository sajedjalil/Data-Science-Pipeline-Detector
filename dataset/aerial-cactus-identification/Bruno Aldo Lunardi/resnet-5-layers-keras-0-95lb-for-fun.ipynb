{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Learning how to implement a resnet 5 layers from scratch...\n\n\nI've used this kernel for preparing the images, thanks filipmg!! \n[https://www.kaggle.com/filipmg/cactus-identification-densenet](http://)"},{"metadata":{},"cell_type":"markdown","source":"* A residual neural network (ResNet) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or short-cuts to jump over some layers. Typical ResNet models are implemented with double- or triple- layer skips that contain nonlinearities (ReLu) and batch normalization in between. An additional weight matrix may be used to learn the skip weights; these models are known as HighwayNets. Models with several parallel skips are referred to as DenseNets. In the context of residual neural networks, a non-residual network may be described as a plain network."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Python ≥3.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn ≥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\nfrom sklearn.model_selection import train_test_split\n\n# Common imports\nimport numpy as np\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils, to_categorical\nfrom keras.callbacks import Callback,EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\n\nimport scipy.misc\n\nfrom matplotlib.pyplot import imshow\nimport keras.backend as K\n\n\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)\n\n%matplotlib inline \n#plotting directly without requering the plot()\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\") #ignoring most of warnings, cleaning up the notebook for better visualization\n\npd.set_option('display.max_columns', 500) #fixing the number of rows and columns to be displayed\npd.set_option('display.max_rows', 500)\n\nprint(os.listdir(\"../input\")) #showing all the files in the ../input directory\n\n# Any results you write to the current directory are saved as output. Kaggle message :D","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading and creating varibles to store relevant directory paths**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"input_path = '../input/'\ntrain_path = input_path + 'train/train/'\ntest_path = input_path + 'test/test/'\n\ntrain_dir=\"../input/train/train\"\ntest_dir=\"../input/test/test\"\ntrain=pd.read_csv('../input/train.csv')\n\nsub_df=pd.read_csv('../input/sample_submission.csv')\n\ntrain_id = train['id']\nlabels = train['has_cactus']\ntest_id = sub_df['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Before reading the images, splitting the training dataset, creating a validation set using 20% of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train_id, labels, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#credits to filipmg\n## function to read image and create lists of images according to the ids provided\ndef get_images(ids, filepath):\n    arr = []\n    for img_id in ids:\n        img = plt.imread(filepath + img_id)\n        arr.append(img)\n    \n    arr = np.array(arr).astype('float32')\n    arr = arr / 255\n    return arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = get_images(ids=x_train, filepath=train_path)\nx_val = get_images(ids=x_val, filepath=train_path)\ntest = get_images(ids=test_id, filepath=test_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The skip-connections help to address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function. There are two main types of ResNets blocks: The identity block and the convolutional block. Very deep Residual Networks are built by stacking these blocks together\n\n#### the function below is gonna build the identity blocks, and the next function is gonna implement the convolutional blocks"},{"metadata":{"trusted":true},"cell_type":"code","source":"#identity_block\n\ndef identity_block(X, f, filters, stage, block):\n    \"\"\"\n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convolutional_block\n\ndef convolutional_block(X, f, filters, stage, block, s = 2):\n    \"\"\"\n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    s -- Integer, specifying the stride to be used\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b', padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH ####\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Finally, the function below is gonna help us create the model that is gonna be used"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ResNet50(input_shape = (32, 32, 3), classes = 1):\n    \"\"\"\n    Implementation of the popular ResNet50 the following architecture:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n\n    # Stage 3\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [64, 64, 256], stage=3, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=3, block='c')\n    X = identity_block(X, 3, [64, 64, 256], stage=3, block='d')\n\n    # Stage 4 \n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n\n    # Stage 5 \n    X = convolutional_block(X, f = 3, filters = [256,256, 1024], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [256,256, 1024], stage=5, block='b')\n    X = identity_block(X, 3, [256,256, 1024], stage=5, block='c')\n\n    # AVGPOOL\n    X = AveragePooling2D(pool_size=(2,2), name='avg_pool')(X)\n    \n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(classes, activation='sigmoid', name='fc' + str(classes))(X)\n    \n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Creating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ResNet50(input_shape = (32,32,3), classes = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Creating callback for the model routine with early stopping, reduce learning rate and a model checkpoint."},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [EarlyStopping(monitor='val_loss', patience=25),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=2, mode='max')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Finally, fiting the model\na image data generator is gonna be used to rotate and flip the image, thus making the model more robust"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_aug = ImageDataGenerator(rotation_range=20, vertical_flip=True, horizontal_flip=True)\nimg_aug.fit(x_train)\n\nbatch_size = 64\nepochs = 30\nsteps = x_train.shape[0] // batch_size\n\nhistory = model.fit_generator(img_aug.flow(x_train, y_train, batch_size=batch_size), \n                    steps_per_epoch=steps, epochs=epochs,  validation_steps= 50,\n                    validation_data=(x_val, y_val), callbacks=callbacks, \n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Plotting the the accuracy and loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.subplots(figsize=(12,10))\nplt.plot(history.history['loss'], color='b', label=\"Training loss\")\nplt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nplt.legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.subplots(figsize=(12,10))\nplt.plot(history.history['acc'], color='b', label=\"Training accuracy\")\nplt.plot(history.history['val_acc'], color='r', label=\"Validation accuracy\")\nplt.legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"best_model.h5\")\n\nsubmission = model.predict(test,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_binary = [0 if value<0.50 else 1 for value in submission] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df['has_cactus'] = sub_binary\nsub_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}