{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This notebook write with [tf.data.datset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) pipeline and [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) high-level API\nand base on [CS230 Stanford Tensorflow Tutorial](https://cs230.stanford.edu/blog/tensorflow/)**\n\n*codes will be completed by the time*\n\n**some parts of code inspired from [This](https://www.kaggle.com/gabrielmv/aerial-cactus-identification-keras) notebook**\n\nI hope to be useful"},{"metadata":{},"cell_type":"markdown","source":"# Import Necessary library"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport os\n\nimport sklearn.utils\nfrom tqdm import tqdm, tqdm_notebook\nimport pandas as pd\nimport cv2 as cv\n\nfrom tqdm import tqdm\n\nimport tensorflow as tf\n#tf.enable_eager_execution()\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, LeakyReLU, DepthwiseConv2D, Flatten\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n\nimport json\nimport logging\n\nimport numpy as np\nimport matplotlib.pyplot as plt ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# All Path"},{"metadata":{},"cell_type":"markdown","source":"define path to dataset and csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = r'../input'\ndataset_dir = os.path.join(data_dir, r'train/train')\ncsv_dir = os.path.join(data_dir , 'train.csv')\nprint(os.getcwd())\nprint(dataset_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# use for reproductibility"},{"metadata":{},"cell_type":"markdown","source":"The most important things for compare hypreParameter is reproductibility in code\nso fixed all seed at first"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I set all seed as 1372\n\nfrom numpy.random import seed\nseed(1372)\nfrom tensorflow import set_random_seed\nset_random_seed(1372)\n\n#df = sklearn.utils.shuffle(df,random_state=1372)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define functions"},{"metadata":{},"cell_type":"markdown","source":"read ,resize and save image (due to dataset image cut to 32x32 pixel no need to that )"},{"metadata":{"trusted":true},"cell_type":"code","source":"def resize_and_save(filename, input_dir, output_dir, size=32):\n    \"\"\"Resize the image contained in `filename` and save it to the `output_dir`\"\"\"\n    image = Image.open(os.path.join(input_dir, filename))\n    # No resize Need for this dataset\n    # Use bilinear interpolation instead of the default \"nearest neighbor\" method\n    # image = image.resize((size, size), Image.BILINEAR)\n    image.save(os.path.join(output_dir, filename)) # linux => / windows => \\\\","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Base on CS230 course,It's better to save all hyperParameter to one file\nafter each change can compare between result and select best of them\n"},{"metadata":{},"cell_type":"markdown","source":"parameter can be saved or read as **param.json** file"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Params():\n    \"\"\"Class that loads hyperparameters from a json file.\n\n    Example:\n    ```\n    params = Params(json_path)\n    print(params.learning_rate)\n    params.learning_rate = 0.5  # change the value of learning_rate in params\n    ```\n    \"\"\"\n\n    def __init__(self, json_path):\n        self.update(json_path)\n\n    def save(self, json_path):\n        \"\"\"Saves parameters to json file\"\"\"\n        with open(json_path, 'w') as f:\n            json.dump(self.__dict__, f, indent=4)\n\n    def update(self, json_path):\n        \"\"\"Loads parameters from json file\"\"\"\n        with open(json_path) as f:\n            params = json.load(f)\n            self.__dict__.update(params)\n\n    @property\n    def dict(self):\n        \"\"\"Gives dict-like access to Params instance by `params.dict['learning_rate']`\"\"\"\n        return self.__dict__\n\n\ndef set_logger(log_path):\n    \"\"\"Sets the logger to log info in terminal and file `log_path`.\n\n    In general, it is useful to have a logger so that every output to the terminal is saved\n    in a permanent file. Here we save it to `model_dir/train.log`.\n\n    Example:\n    ```\n    logging.info(\"Starting training...\")\n    ```\n\n    Args:\n        log_path: (string) where to log\n    \"\"\"\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n\n    if not logger.handlers:\n        # Logging to a file\n        file_handler = logging.FileHandler(log_path)\n        file_handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n        logger.addHandler(file_handler)\n\n        # Logging to console\n        stream_handler = logging.StreamHandler()\n        stream_handler.setFormatter(logging.Formatter('%(message)s'))\n        logger.addHandler(stream_handler)\n\n\ndef save_dict_to_json(d, json_path):\n    \"\"\"Saves dict of floats in json file\n\n    Args:\n        d: (dict) of float-castable values (np.float, int, float, etc.)\n        json_path: (string) path to json file\n    \"\"\"\n    with open(json_path, 'w') as f:\n        # We need to convert the values to float for json (it doesn't accept np.array, np.float, )\n        d = {k: float(v) for k, v in d.items()}\n        json.dump(d, f, indent=4)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Pipeline"},{"metadata":{},"cell_type":"markdown","source":"The Dataset API allows you to build an asynchronous, highly optimized data pipeline to prevent your GPU from data starvation. It loads data from the disk (images or text), applies optimized transformations, creates batches and sends it to the GPU. Former data pipelines made the GPU wait for the CPU to load the data, leading to performance issues."},{"metadata":{},"cell_type":"markdown","source":"**for more info see [This](https://cs230.stanford.edu/blog/datapipeline/)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the filenames in each directory (train and test)\ndf = pd.read_csv(csv_dir)\ndf['id'] = dataset_dir + '/' + df['id'].astype(str)\nfilenames = df['id']\nlabels = df['has_cactus'].astype(np.float32)\n\n\n# Make sure to always shuffle with a fixed seed so that the split is reproducible\ndf = sklearn.utils.shuffle(df,random_state=1372)\ndf = df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"show a sample of label and filename array\noperation like shuffel on filename array is faster than image array"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('sample filename ',filenames[0])\nprint('sample label (1 = exsit) , (0 = dosent exist any cactus) ',labels[0],type(labels[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create tf.data.dataset"},{"metadata":{},"cell_type":"markdown","source":"**see [this](http://cs230.stanford.edu/blog/datapipeline/#building-an-image-data-pipeline) for more info**"},{"metadata":{},"cell_type":"markdown","source":"we can map function on all image of dataset by one line\nSO this can help us a lot like in agumentaion or preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _parse_function(filename, label, size):\n    \"\"\"Obtain the image from the filename (for both training and validation).\n\n    The following operations are applied:\n        - Decode the image from jpeg format\n        - Convert to float and to range [0, 1]\n    \"\"\"\n    image_string = tf.read_file(filename)\n\n    # Don't use tf.image.decode_image, or the output shape will be undefined\n    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n\n    # This will convert to float values in [0, 1]\n    image = tf.image.convert_image_dtype(image_decoded, tf.float32)\n\n    resized_image = tf.image.resize_images(image, [size, size])\n\n    return resized_image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_preprocess(image, label, use_random_flip):\n    \"\"\"Image preprocessing for training.\n\n    Apply the following operations:\n        - Horizontally flip the image with probability 1/2\n        - Apply random brightness and saturation\n    \"\"\"\n    if use_random_flip:\n        image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, max_delta=25.0 / 255.0)\n    image = tf.image.random_saturation(image, lower=0.6, upper=1.4)\n\n    # Make sure the image is still in [0, 1]\n    image = tf.clip_by_value(image, 0.0, 1.0)\n\n    return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def input_fn(is_training, filenames, labels, params):\n    \"\"\"Input function for the dataset.\n\n        Args:\n        is_training: (bool) whether to use the train or test pipeline.\n                     At training, we shuffle the data and have multiple epochs\n        filenames: (list) filenames of the images, as [\"data_dir/{label}_IMG_{id}.jpg\"...]\n        labels: (list) corresponding list of labels\n        params: (Params) contains hyperparameters of the model (ex: `params.num_epochs`)\n    \"\"\"\n    num_samples = len(filenames)\n    assert len(filenames) == len(labels), \"Filenames and labels should have same length\"\n\n    # Create a Dataset serving batches of images and labels\n    # We don't repeat for multiple epochs because we always train and evaluate for one epoch\n    parse_fn = lambda f, l: _parse_function(f, l, params.image_size)\n    train_fn = lambda f, l: train_preprocess(f, l, params.use_random_flip)\n\n    if is_training:\n        dataset = (tf.data.Dataset.from_tensor_slices((tf.constant(filenames), tf.constant(labels)))\n            .shuffle(num_samples)  # whole dataset into the buffer ensures good shuffling\n            .map(parse_fn, num_parallel_calls=params.num_parallel_calls)\n            .map(train_fn, num_parallel_calls=params.num_parallel_calls)\n            .batch(params.batch_size)\n            .repeat()\n            .prefetch(32)  # make sure you always have one batch ready to serve\n        )\n    else:\n        dataset = (tf.data.Dataset.from_tensor_slices((tf.constant(filenames), tf.constant(labels)))\n            .map(parse_fn)\n            .batch(params.batch_size)\n            .repeat()\n            .prefetch(32)  # make sure you always have one batch ready to serve\n        )\n        \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create params.json\nNotice:i can't upload it, so i write it as a text file.\nbut in practice you should put it in another folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"params.json\", \"w\") as text_file:\n    text_file.write(\"{\\n\"+\n    \"\\\"learning_rate\\\": 1.5e-3,\"+\n    \"\\\"batch_size\\\": 64,\"+\n    \"\\\"num_epochs\\\": 50,\"+\n    \"\\\"image_size\\\": 32,\"+\n    \"\\\"use_random_flip\\\": false,\"+\n    \"\\\"num_labels\\\": 2,\"+\n    \"\\\"num_parallel_calls\\\": 8,\"+\n    \"\\\"save_summary_steps\\\": 1\"+\n    \"\\n}\")\n    \nparamPath = r'./'\njson_path = os.path.join(paramPath , 'params.json')\nassert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"read parameter and split data into train and validation(%15)"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = Params(json_path)\nsplit = int(len(filenames)*0.15)\ntrain_dataset = input_fn(True, filenames[:split], labels[:split], params)\nvalid_dataset = input_fn(False , filenames[split:], labels[split:], params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot some sample to ensure we create  correct dataset"},{"metadata":{},"cell_type":"markdown","source":"The one_shot_iterator method creates an iterator that will be able to iterate once over the dataset. In other words, once we reach the end of the dataset, it will stop yielding elements and raise an Exception.\n\nNow, next_element is a graphâ€™s node that will contain the next element of iterator over the Dataset at each execution (adopted from CS230)"},{"metadata":{"trusted":true},"cell_type":"code","source":"iterator = train_dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\nwith tf.Session() as sess:\n    one_batch = sess.run(next_element)\n    print(one_batch[0].shape,' = 64 batch-size & 32x32x3 image')\n    for i in range(3):\n        plt.figure()\n        sample = one_batch[0]\n        label = one_batch[1]\n        print(label[i])\n        plt.imshow(sample[i])\n        plt.grid(False)       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Model"},{"metadata":{},"cell_type":"markdown","source":"Use tf.keras (I think its faster & better than Kera library)"},{"metadata":{},"cell_type":"markdown","source":"as rule of thumb if you go deeper in ConvNet layer, filters number increase (better to be a power of 2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n        \nmodel.add(Conv2D(3, kernel_size = 3, activation = 'relu', input_shape = (32, 32, 3)))\n\nmodel.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\nmodel.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 32, kernel_size = 1, activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 2, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 128, kernel_size = 1, activation = 'relu'))\nmodel.add(Conv2D(filters = 256, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 256, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 2, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 1024, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 1024, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n#model.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(128, activation = 'elu'))\n\nmodel.add(Dense(1, activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most popular optimizer ADAM <3"},{"metadata":{},"cell_type":"markdown","source":"**base on my [search](https://stats.stackexchange.com/questions/186091/what-loss-function-should-i-use-for-binary-detection-in-face-non-face-detection) and experience log_loss work better than other loss function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Adam = tf.keras.optimizers.Adam(lr=params.learning_rate , amsgrad=True)\nmodel.compile(optimizer = Adam, loss = tf.losses.log_loss, metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defin callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = 'weights-aerial-cactus.h5'\n\ncallbacks = [\n        ModelCheckpoint(file_path, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max'),\n        ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, mode = 'min', min_lr = 0.00001),\n        EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 15, verbose = 1, restore_best_weights = True)\n        ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"if you pass dataset to model.fit() function, you must define **steps_per_epoch** and **validation_steps**"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_dataset, validation_data=valid_dataset,\n          epochs=50,verbose=True,\n          steps_per_epoch=int((len(filenames) - split)/params.batch_size),\n          validation_steps=int(split/params.batch_size),\n           callbacks = callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"load best weight"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(file_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot loss and acc"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_training_curves(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc) + 1)\n    \n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Losses')\n    plt.legend()\n    plt.figure()\n    \n    plt.plot(epochs, acc, 'r', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.title('Accuracies')\n    plt.legend()\n    plt.figure()\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training_curves(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"read image from test file and predict result.\nat the end save as csv file to submit"},{"metadata":{},"cell_type":"markdown","source":"**you must put your probability of cactus existence into csv file\nso if you replace prob. with  0 and 1 (I mean P less than 0.5 set to zero and upper that set to 1) then ...?\nare you get higher score?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/sample_submission.csv')\nX_test = []\nimages_test = test_df['id'].values\n\nfor img_id in tqdm_notebook(images_test):\n    X_test.append(cv.imread('../input/test/test/' + img_id))\n    \nX_test = np.asarray(X_test)\nX_test = X_test.astype('float32')\nX_test /= 255\n\ny_test_pred = model.predict_proba(X_test)\n\ntest_df['has_cactus'] = y_test_pred\ntest_df.to_csv('aerial-cactus-submission_1.csv', index = False)\n\nfor i in range(len(y_test_pred)):\n    if y_test_pred[i][0] >= 0.5:\n        y_test_pred[i][0] = 1.0\n    else:\n        y_test_pred[i][0] = 0.0\n        \ntest_df['has_cactus'] = y_test_pred\ntest_df.to_csv('aerial-cactus-submission_2.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The END**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"}},"nbformat":4,"nbformat_minor":1}