{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n \nfrom tqdm import tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\n%matplotlib inline\nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid', color_codes=True)\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\nimport random\nimport uuid\nimport shutil\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(42)\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Investigate Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"PATH = \"../input\"\nIMAGE_SIZE = (32, 32)\n\ntrain_dir=f'{PATH}/train/train'\ntest_dir=f'{PATH}/test/test'\n\ntrain_img = os.listdir(train_dir)\ntest_img = os.listdir(test_dir)\n\ntrain_df =pd.read_csv(f'{PATH}/train.csv')\ntest_df = pd.read_csv(f'{PATH}/sample_submission.csv')\n\n# Create new images for the imbalanced data\ntrain_new_dir = 'train'\n\n# Make sure the folder is empty\nif os.path.exists(train_new_dir):\n    shutil.rmtree(train_new_dir)\nelse:\n    os.makedirs(train_new_dir)\n\nprint(f\"The number of rows in train and test set are {len(train_df)} and {len(test_df)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_df['has_cactus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 8))\nfor idx, img in enumerate(np.random.choice(train_img, 20)):\n    ax = fig.add_subplot(4, 20//4, idx+1, xticks=[], yticks=[])\n    im = cv2.imread(f'{train_dir}/{img}')\n    plt.imshow(im)\n    lab = train_df.loc[train_df['id'] == img, 'has_cactus'].values[0]\n    ax.set_title(f'has_cactus: {lab}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add images"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = []\nif len(os.listdir(train_new_dir))==0:\n    for idx, row in train_df[train_df['has_cactus']==0].iterrows():\n        # get image\n        img = cv2.imread(f'{train_dir}/{row[\"id\"]}')\n        # flip image\n        for i in range(2):\n            f = cv2.flip(img, i)\n            img_id = uuid.uuid4().hex + '.jpg'\n            cv2.imwrite(f'{train_new_dir}/{img_id}', f)\n            train_new.append({'id': img_id, 'has_cactus': 0}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'{len(os.listdir(train_new_dir))} new images generated')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# copy the read-only files to new dir\n!cp ../input/train/train/*.jpg train/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"The number of rows in train and test set are {len(os.listdir(train_new_dir))} and {len(test_df)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if len(train_df) == len(os.listdir(train_dir)):\n    train_df=train_df.append(train_new, ignore_index=True)\n    sns.countplot(train_df['has_cactus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting data into train and validation\ntrain, valid = train_test_split(train_df, stratify=train_df.has_cactus, test_size=0.33, random_state=2019)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 8\n\ntrain_gen=ImageDataGenerator(\n    rescale=1./255, \n    rotation_range=10,  \n    zoom_range = 0.1, \n    width_shift_range=0.1,  \n    height_shift_range=0.1,  \n    fill_mode='nearest'\n)  \n\ntrain_generator=train_gen.flow_from_dataframe(\n    x_col='id',                                  \n    y_col='has_cactus',\n    dataframe=train, \n    directory=train_new_dir, \n    class_mode='other',\n    color_mode='rgb',\n    batch_size=BATCH_SIZE,\n    target_size=IMAGE_SIZE,\n    shuffle=True,\n    seed=2019\n)\n\nvalid_generator=train_gen.flow_from_dataframe(\n    x_col='id',                                  \n    y_col='has_cactus',\n    dataframe=valid, \n    directory=train_new_dir, \n    class_mode='other',\n    color_mode='rgb',\n    batch_size=BATCH_SIZE,\n    target_size=IMAGE_SIZE,\n    shuffle=True,\n    seed=2019\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_rate=0.2\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(32,32,3)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,kernel_size=3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(drop_rate))\n\nmodel.add(Conv2D(64,kernel_size=3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,kernel_size=3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(drop_rate))\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(BatchNormalization())\nmodel.add(Dropout(drop_rate))\n\nmodel.add(Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer=Adam(), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = 'best_weights.h5'\n\ncallbacks = [\n    ModelCheckpoint(file_path, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max'),\n    ReduceLROnPlateau(monitor = 'val_loss', factor = 0.8, patience = 4, verbose = 1, mode = 'min', min_lr = 1e-8),\n    EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 32, verbose = 1, restore_best_weights = True)\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fit Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=128\nhistory=model.fit_generator(train_generator,\n                            steps_per_epoch=train_generator.n//train_generator.batch_size,\n                            epochs=epochs,\n                            verbose = 1,\n                            shuffle=True,\n                            validation_data=valid_generator,\n                            validation_steps=valid_generator.n//valid_generator.batch_size,\n                            callbacks = callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Virtualize Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make sure not output too many files\nif os.path.exists(train_new_dir):\n    shutil.rmtree(train_new_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(file_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen=ImageDataGenerator(\n    rescale=1./255, \n)  \n\ntest_generator=test_gen.flow_from_dataframe(\n    x_col='id',                                  \n    y_col='has_cactus',\n    dataframe=test_df, \n    directory=test_dir, \n    class_mode='other',\n    color_mode='rgb',\n    batch_size=1,\n    target_size=IMAGE_SIZE,\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()\npred = model.predict_generator(test_generator, verbose=1, steps=test_generator.n)\n\npred[pred>0.99]=1\npred[pred<0.01]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['has_cactus'] = pred\ntest_df.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}