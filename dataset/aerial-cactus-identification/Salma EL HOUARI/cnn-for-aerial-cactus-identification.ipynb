{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport PIL\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Lambda, Flatten, BatchNormalization, Convolution2D , MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing.image import load_img, img_to_array","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Among all the content we got from the input folder we choose to keep only the train and test folders . \n#The other files will be used later on\nfichier=os.listdir(\"../input\")\nfichier.remove('train.csv')\nfichier.remove('sample_submission.csv')\nfichier  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The folders train  and test countain images refered to by their 'id' followed by the type of the file (jpg).\nimgtype = '/*.jpg'\ntrain = sorted([x for x in os.listdir(\"../input\" + '/'+ 'train' + '/train'  ) if x.endswith(imgtype[2:])])\ntest = sorted([x for x in os.listdir(\"../input\" + '/'+ 'test' + '/test') if x.endswith(imgtype[2:])])\ntrain","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#We open the CSV file which countains two columns: 'id'and 'has cactus'\ncsv_train = pd.read_csv(\"../input/\" + 'train.csv')\nsns.countplot('has_cactus', data=csv_train)\nplt.title('Classes', fontsize=15)\nplt.show()\ncsv_train.has_cactus=csv_train.has_cactus.astype(str) #This variable is turned to string to match the data format \n                                                      #required by the augmentation function we'll use\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model 1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#The function ImageDataGenerator allows here to multiply the data by the value provided.\n#Batch Size corresponds to the number of samples that will be passed through our network at one time. \ndatagen=ImageDataGenerator(rescale=1./255)\nbatch_size=140 #so that the number of iterations will be 100 since the training sample countains 14000 images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#--------The Data Augmentation\n#The initial train sample is split between Training sample and validation sample following the rule of 80%/20%\n#The function flow_from_dataframe will provide a new sample with images randomly changed following the parameters fixed\n\ntrain_generator=datagen.flow_from_dataframe(dataframe=csv_train[:14001],directory=\"../input\" + '/'+ 'train' + '/train',x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                            target_size=(150,150))\nvalidation_generator=datagen.flow_from_dataframe(dataframe=csv_train[14000:],directory=\"../input\" + '/'+ 'train' + '/train',x_col='id',\n                                                y_col='has_cactus',class_mode='binary',batch_size=50,\n                                                target_size=(150,150))\ny_train=csv_train[:14001]\ny_val=csv_train[14000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_train_samples = 14001\nnb_validation_samples = 3500","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#--------Convolutionnal Neural Network model\n#The model we chose consists in three steps each time: convolution, pooling, and dropout.\n#1-Convolution2D function consists in applying a Convolutional kernel, of size 3x3. \n#2-MaxPooling uses a kernel 2x2 to downsize the information countained in the image and keep only the pixel with max value\n#3-Dropout\nmodel = Sequential() #Creation of an empty neural network\nmodel.add(Convolution2D(32, (3, 3), input_shape = (150, 150, 3), activation = 'relu')) #followed by an activation layer\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.1))\n\nmodel.add(Convolution2D(64, (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.1))\n\nmodel.add(Convolution2D(128, (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.1))\n\n#Flatten 3d feature maps to 1D\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n#compile the model\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n#generate a summary of the model\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Stops the fit generator when the value of the accuaracy stagnates\ncallbacks = [EarlyStopping(monitor='val_loss', patience=4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#--------Learning for the training set\nhistory = model.fit_generator(\n    train_generator, \n    steps_per_epoch=nb_train_samples // batch_size,\n    epochs=20,\n    callbacks=callbacks,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_samples // batch_size,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot training history\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.plot(history.history['val_acc'], label='acc_test')\nplt.plot(history.history['acc'], label='acc_train')\nplt.legend()\nplt.show()\n#the accuaracy of the model is 98%.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict_classes(validation_generator)\nconfusion_mtx = confusion_matrix(validation_generator.classes, Y_pred) \nplot_confusion_matrix(confusion_mtx, classes = range(2))\n\n#Its seems that the CNN built recognizes well when an image contains a Cactus, \n#but the  big number of real '1's is because they represented a biggest share of the training set.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ModÃ¨le 2**\n\nThis model has less layers than the first one and provides unsatisfaisant results. \nWe hence keep the first model."},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen1=ImageDataGenerator(rotation_range=30, width_shift_range=0.2, \n                             height_shift_range=0.2, zoom_range=0.2, \n                             horizontal_flip=True, vertical_flip=True, \n                             validation_split=0.1,rescale=1./255)\nbatch_size=140","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator1=datagen1.flow_from_dataframe(dataframe=csv_train[:14001],directory=\"../input\" + '/'+ 'train' + '/train',x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                            target_size=(150,150))\n\n\nvalidation_generator1=datagen.flow_from_dataframe(dataframe=csv_train[14000:],directory=\"../input\" + '/'+ 'train' + '/train',x_col='id',\n                                                y_col='has_cactus',class_mode='binary',batch_size=50,\n                                                target_size=(150,150))\n\ny_train=csv_train[:14001]\ny_val=csv_train[14000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = Sequential()\nmodel1.add(Convolution2D(32, (3, 3), input_shape = (150, 150, 3), activation = 'relu'))\nmodel1.add(MaxPooling2D(pool_size = (2, 2)))\nmodel1.add(Dropout(rate = 0.1))\nmodel1.add(Convolution2D(64, (3, 3), activation = 'relu'))\nmodel1.add(MaxPooling2D(pool_size = (2, 2)))\nmodel1.add(Dropout(rate = 0.1))\n#flatten 3d feature maps to 1D\nmodel1.add(Flatten())\nmodel1.add(Dense(64, activation = 'relu'))\nmodel1.add(Dense(1, activation = 'sigmoid'))\n\n#compile the model\nmodel1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nmodel1.summary()\n\ncallbacks = [EarlyStopping(monitor='val_loss', patience=4)]\n\nhistory1 = model1.fit_generator(\n    train_generator1, \n    steps_per_epoch=nb_train_samples // batch_size,\n    epochs=20,\n    callbacks=callbacks,\n    validation_data=validation_generator1,\n    validation_steps=nb_validation_samples // batch_size,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred1 = model1.predict_classes(train_generator)\nconfusion_mtx = confusion_matrix(train_generator.classes, Y_pred1) \nplot_confusion_matrix(confusion_mtx, classes = range(2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Images of the test folder are loaded into X_tst and resized so they can  match the format for which we did the training\nX_tst = []\nTest_imgs = []\nfor img_id in os.listdir(\"../input\" + '/'+ 'test' + '/test'):\n    img = cv2.imread(\"../input\" + '/'+ 'test' +'/' +'test' +'/' + img_id)\n    img2 = cv2.resize(img, (150,150))\n    X_tst.append(img2)     \n    \n    Test_imgs.append(img_id)\nX_tst = np.asarray(X_tst)\nX_tst = X_tst.astype('float32')\nX_tst /= 255\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We apply the final weights on the test sample... \ntest_predictions = model.predict_classes(X_tst)\ntest_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#... and save the result in csv file where the first column is the 'id' and the second is the prediction\nsub_df = pd.DataFrame(test_predictions, columns=['has_cactus'])\nsub_df['has_cactus'] = sub_df['has_cactus'].apply(lambda x: 1 if x > 0.75 else 0)\nsub_df['id'] = ''\ncols = sub_df.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nsub_df=sub_df[cols]\nfor i, img in enumerate(Test_imgs):\n    sub_df.set_value(i,'id',img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}