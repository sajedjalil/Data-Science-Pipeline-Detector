{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nfrom tqdm import tqdm, tqdm_notebook\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nseed = 4529\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set train and test directories"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = os.path.join(\"..\", \"input\") # set base directory\ntrain_df = pd.read_csv(os.path.join(base_dir, \"train.csv\"))\ntrain_dir = os.path.join(base_dir, \"train/train\")\ntest_dir = os.path.join(base_dir, \"test/test\")\n\n# print(os.listdir(train_dir))\nprint(train_df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tensorboard visualizations\n\nHelps visualizing the training loss and accuracy after each epoch. "},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard.notebook\n%tensorboard --logdir logs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get training images and labels\n\nThis process provides little scope for data augmentation. I commented this out to use Image Generators, which is mor esuited for augmentation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_images = []\n# train_labels = []\n# images = train_df['id'].values\n\n# for image_id in tqdm_notebook(images):\n#     image = np.array(cv2.imread(train_dir + \"/\" + image_id))\n#     train_images.append(image)\n    \n#     label = train_df[train_df['id'] == image_id]['has_cactus'].values[0]\n#     train_labels.append(label)\n    \n# train_images = np.asarray(train_images)\n# train_images = train_images / 255.0\n# train_labels = np.asarray(train_labels)\n\n# print(\"Number of Training images: \" + str(len(train_images)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Image Generators for preprocessing input images"},{"metadata":{},"cell_type":"markdown","source":"Image Generators have been used to augment the existing data. Training set is split in a 90:10 into train and validation set. Generators are created for each split. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['has_cactus'] = train_df['has_cactus'].astype(str)\n\nbatch_size = 64\ntrain_size = 15750\nvalidation_size = 1750\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    vertical_flip=False,\n    brightness_range=(1, 1.3),\n    shear_range=0.05,\n    validation_split=0.1)\n\ndata_args = {\n    \"dataframe\": train_df,\n    \"directory\": train_dir,\n    \"x_col\": 'id',\n    \"y_col\": 'has_cactus',\n    \"shuffle\": True,\n    \"target_size\": (32, 32),\n    \"batch_size\": batch_size,\n    \"class_mode\": 'binary'\n}\n\ntrain_generator = datagen.flow_from_dataframe(**data_args, subset='training')\nvalidation_generator = datagen.flow_from_dataframe(**data_args, subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build the model"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"model = Sequential([\n    Conv2D(64, (3,3), padding='same', activation=\"relu\", input_shape=(32, 32, 3)),\n    BatchNormalization(),\n    Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    Conv2D(128, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(128, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(128, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    Conv2D(256, (3,3), padding='same', activation=\"relu\"),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    Dropout(0.4),\n    GlobalAveragePooling2D(),\n    Dense(units=256, activation='relu'),\n    Dropout(0.5),\n    Dense(units=256, activation='relu'),\n    Dropout(0.5),\n    Dense(units=1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=Adam(lr=0.001), \n                 loss='binary_crossentropy',\n                 metrics=['acc'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set callbacks for training"},{"metadata":{},"cell_type":"markdown","source":"These are some standard callbacks which keras provides. \n1. EarlyStopping: Stops the training process if the monitored parameter stops improving with 'patience' number of epochs.\n2. ReduceLROnPlateau: Reduces learning rate by a factor if monitored parameter stops improving with 'patience' number of epochs. This helps fit the training data better.\n3. TensorBoard: Helps in visualization.\n4. ModelCheckpoint: Stores the best weights after each epoch in the path provided.\n\nFor further details, refer [this link.](https://keras.io/callbacks)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ckpt_path = 'aerial_cactus_detection.hdf5'\n\nearlystop = EarlyStopping(monitor='val_acc', patience=10, verbose=1, restore_best_weights=True)\nreducelr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3, verbose=1, min_lr=1.e-6)\nmodelckpt_cb = ModelCheckpoint(ckpt_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ntb = TensorBoard()\n\ncallbacks = [earlystop, reducelr, modelckpt_cb, tb]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator,\n              validation_data=validation_generator,\n              steps_per_epoch=train_size//batch_size,\n              validation_steps=validation_size//batch_size,\n              epochs=100, verbose=1, \n              shuffle=True,\n              callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train vs Validation Visualization\n\nThese plots can help realize cases of overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training plots\nepochs = [i for i in range(1, len(history.history['loss'])+1)]\n\nplt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\nplt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\nplt.legend(loc='best')\nplt.title('loss')\nplt.xlabel('epoch')\nplt.show()\n\nplt.plot(epochs, history.history['acc'], color='blue', label=\"training_accuracy\")\nplt.plot(epochs, history.history['val_acc'], color='red',label=\"validation_accuracy\")\nplt.legend(loc='best')\nplt.title('accuracy')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get Test Set images"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(base_dir, \"sample_submission.csv\"))\nprint(test_df.head())\ntest_images = []\nimages = test_df['id'].values\n\nfor image_id in images:\n    test_images.append(cv2.imread(os.path.join(test_dir, image_id)))\n    \ntest_images = np.asarray(test_images)\ntest_images = test_images / 255.0\nprint(\"Number of Test set images: \" + str(len(test_images)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make predictions on test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test_images)\ntest_df['has_cactus'] = pred\ntest_df.to_csv('aerial-cactus-submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}