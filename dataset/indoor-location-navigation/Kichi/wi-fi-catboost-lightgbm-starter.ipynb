{"cells":[{"metadata":{},"cell_type":"markdown","source":"Thanks @BIZEN"},{"metadata":{"_uuid":"b0b638d5-90e9-48ee-b527-0a2480a3d01b","_cell_guid":"1cb6635f-c3c1-457a-822e-e3c258dbf3fd","trusted":true},"cell_type":"code","source":"from catboost import CatBoost\nfrom catboost import Pool,CatBoostClassifier,CatBoostRegressor\nimport lightgbm as lgb\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nfrom pathlib import Path\nimport glob\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import KFold\n\nimport psutil\nimport random\nimport os\nimport time\nimport sys\nimport math\nfrom contextlib import contextmanager\n\n\n# ------------------------------------------------------------------------------\n# Fixed values\n# ------------------------------------------------------------------------------\nN_SPLITS = 9\nSEED = 1\n\n# ------------------------------------------------------------------------------\n# File path definition\n# ------------------------------------------------------------------------------\nLOG_PATH = Path(\"./log/\")\nLOG_PATH.mkdir(parents=True, exist_ok=True)\n\n\n# ------------------------------------------------------------------------------\n# Utilities\n# ------------------------------------------------------------------------------\n@contextmanager\ndef timer(name: str):\n    t0 = time.time()\n    p = psutil.Process(os.getpid())\n    m0 = p.memory_info()[0] / 2. ** 30\n    try:\n        yield\n    finally:\n        m1 = p.memory_info()[0] / 2. ** 30\n        delta = m1 - m0\n        sign = '+' if delta >= 0 else '-'\n        delta = math.fabs(delta)\n        print(f\"[{m1:.1f}GB({sign}{delta:.1f}GB): {time.time() - t0:.3f}sec] {name}\", file=sys.stderr)\n\n\ndef set_seed(seed=SEED):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n\n    \ndef comp_metric(xhat, yhat, fhat, x, y, f):\n    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n    return intermediate.sum()/xhat.shape[0]\n\n\ndef score_log(df: pd.DataFrame, num_files: int, nam_file: str, data_shape: tuple, n_fold: int, seed: int, mpe: float):\n    score_dict = {'n_files': num_files, 'file_name': nam_file, 'shape': data_shape, 'fold': n_fold, 'seed': seed, 'score': mpe}\n    # noinspection PyTypeChecker\n    df = pd.concat([df, pd.DataFrame.from_dict([score_dict])])\n    df.to_csv(LOG_PATH / f\"log_score.csv\", index=False)\n    return df\n\n\n\ndef trainX(data,target):\n    X, y = data, target\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                        test_size=0.3,\n                                                        shuffle=True,\n                                                        random_state=SEED)\n\n    train_pool = Pool(X_train, label=y_train)\n    test_pool = Pool(X_test, label=y_test)\n\n    params = {\n        'loss_function': 'RMSE',\n        'depth': 4,\n        'num_boost_round': 5000,\n        'early_stopping_rounds': 10,\n        'random_seed': SEED,\n        'verbose': 0\n    }\n\n    model = CatBoost(params)\n    model.fit(train_pool, eval_set=[test_pool])\n\n    y_pred = model.predict(test_pool)\n\n    mse = mean_squared_error(y_test, y_pred)\n    print('RMSE:', math.sqrt(mse))\n    return model\n\n\ndef trainY(data,target):\n    X, y = data, target\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                        test_size=0.3,\n                                                        shuffle=True,\n                                                        random_state=SEED)\n\n    train_pool = Pool(X_train, label=y_train)\n    test_pool = Pool(X_test, label=y_test)\n\n    params = {\n        'loss_function': 'RMSE',\n        'depth': 4,\n        'num_boost_round': 5000,\n        'early_stopping_rounds': 10,\n        'random_seed': SEED,\n        'verbose': 0\n    }\n\n    model = CatBoost(params)\n    model.fit(train_pool, eval_set=[test_pool])\n\n    y_pred = model.predict(test_pool)\n\n    mse = mean_squared_error(y_test, y_pred)\n    print('RMSE:', math.sqrt(mse))\n    return model\n\n\n\nlgb_f_params = {'objective': 'multiclass',\n                'boosting_type': 'gbdt',\n                'n_estimators': 5000,\n                'learning_rate': 0.04,\n                'num_leaves': 90,\n                'colsample_bytree': 0.4,\n                'subsample': 0.6,\n                'subsample_freq': 2,\n                'bagging_seed': SEED,\n                'reg_alpha': 10,\n                'reg_lambda': 2,\n                'random_state': SEED,\n                'n_jobs': -1\n                }\n\n\n\n\n# ------------------------------------------------------------------------------\n# Set seed\n# ------------------------------------------------------------------------------\nset_seed(SEED)\n\n# ------------------------------------------------------------------------------\n# Read data\n# ------------------------------------------------------------------------------\nfeature_dir = \"../input/indoor-navigation-and-location-wifi-features\"\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nsubm = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv', index_col=0)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------------------------------------------------------------------------------\n# Training and inference\n# ------------------------------------------------------------------------------\nscore_df = pd.DataFrame()\noof = list()\npredictions = list()\nfor n_files, file in enumerate(tqdm(train_files)):\n    data = pd.read_csv(file, index_col=0)\n    test_data = pd.read_csv(test_files[n_files], index_col=0)\n\n    oof_x, oof_y, oof_f = np.zeros(data.shape[0]), np.zeros(data.shape[0]), np.zeros(data.shape[0])\n    preds_x, preds_y = 0, 0\n    preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n\n    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n    for fold, (trn_idx, val_idx) in enumerate(kf.split(data.iloc[:, :-4])):\n        X_train = data.iloc[trn_idx, :-4]\n        y_trainx = data.iloc[trn_idx, -4]\n        y_trainy = data.iloc[trn_idx, -3]\n        y_trainf = data.iloc[trn_idx, -2]\n\n        X_valid = data.iloc[val_idx, :-4]\n        y_validx = data.iloc[val_idx, -4]\n        y_validy = data.iloc[val_idx, -3]\n        y_validf = data.iloc[val_idx, -2]\n        \n        \n        modelLF = lgb.LGBMClassifier(**lgb_f_params)\n        with timer(\"fit F\"):\n            modelLF.fit(X_train, y_trainf,\n                       eval_set=[(X_valid, y_validf)],\n                       eval_metric='multi_logloss',\n                       verbose=False,\n                       early_stopping_rounds=20\n                       )\n            \n        oof_f[val_idx] = modelLF.predict(X_valid).astype(int)\n        \n        \n        with timer(\"fit X\"):\n            modelX = trainX(X_train,y_trainx)\n        \n        oof_x[val_idx] = modelX.predict(X_valid)\n\n        with timer(\"fit Y\"):\n            modelY = trainY(X_train,y_trainy)\n        \n        oof_y[val_idx] = modelY.predict(X_valid)\n\n        \n\n        preds_x += modelX.predict(test_data.iloc[:, :-1]) / N_SPLITS\n        preds_y += modelY.predict(test_data.iloc[:, :-1]) / N_SPLITS\n        preds_f_arr[:, fold] = modelLF.predict(test_data.iloc[:, :-1]).astype(int)\n\n        score = comp_metric(oof_x[val_idx], oof_y[val_idx], oof_f[val_idx],\n                            y_validx.to_numpy(), y_validy.to_numpy(), y_validf.to_numpy())\n        print(f\"fold {fold}: mean position error {score}\")\n        score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, fold, SEED, score)\n        \n        break\n    \n    print(\"*+\"*40)\n    print(f\"file #{n_files}, shape={data.shape}, name={os.path.basename(file)}\")\n    score = comp_metric(oof_x, oof_y, oof_f,\n                        data.iloc[:, -4].to_numpy(), data.iloc[:, -3].to_numpy(), data.iloc[:, -2].to_numpy())\n    oof.append(score)\n    print(f\"mean position error {score}\")\n    print(\"*+\"*40)\n    score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, 999, SEED, score)\n\n    preds_f_mode = stats.mode(preds_f_arr, axis=1)\n    preds_f = preds_f_mode[0].astype(int).reshape(-1)\n    test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n    test_preds.columns = subm.columns\n    test_preds.index = test_data[\"site_path_timestamp\"]\n    test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n    predictions.append(test_preds)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \n# ------------------------------------------------------------------------------\n# Submit the result\n# ------------------------------------------------------------------------------\nall_preds = pd.concat(predictions)\nall_preds = all_preds.reindex(subm.index)\nall_preds.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}