{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Concept\nThe notebook simply uses **neural network algorithms (MLP)** to estimate indoor locations. It doesn't have high performance, but it was quite an interesting attempt. I've reinvented the wheel.\n\nWe used [**Wi-Fi signal feature dataset**](https://www.kaggle.com/hiro5299834/indoor-navigation-and-location-wifi-features) shared by [**BIZEN**](https://www.kaggle.com/hiro5299834). We appreciate his sharing!! <br/>\nPlease adjust the parameters according to GPU performance. Then you can get better results.\n\n### Network settings\nNetwork Architecture: input size - input size/2 - input size/20 - 1<br/>\nActivation Function : Sigmoid & Relu| Linear Regression <br/>\nOptimizers : Adam | MSE <br/>\nBatch size : 32 <br/>\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"#%% Import Libraries\n\nimport os\nimport glob\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tensorflow import keras\n\n#%% Test & Train File path defintion\n\ntrain_dir = sorted(glob.glob('../input/indoor-navigation-and-location-wifi-features/*_train.csv'))\ntest_dir = sorted(glob.glob('../input/indoor-navigation-and-location-wifi-features/*_test.csv'))\n\nfinal_ver = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv')\n\nsubmission = []\nk =[[0,0,0]]\n\n#%% TRAIN\nfor step in range(24):\n    output = []\n    \n    # load data\n    train_data = pd.read_csv(train_dir[step],index_col=0)\n    train_data = train_data.drop(['path'],axis=1)\n    \n    # test\n    test_data = pd.read_csv(test_dir[step],index_col=0)\n    test_data = test_data.iloc[:,:-1]\n    \n    # Normalization [0 ~ 1]\n    maxn = train_data.max()\n    minn = train_data.min()\n    \n    train_data = (train_data - minn) / (maxn - minn)\n    \n    maxt = test_data.max()\n    mint = test_data.min()\n    \n    test_data = (test_data - mint) / (maxt - mint)\n    test_data[test_data.isna()] = 0.0\n    \n    # Shuffle\n    train_data = train_data.sample(frac=1).reset_index(drop=True)\n    num = int(train_data.shape[0] * 0.90)\n    \n   \n    # Input dataset\n    train_in = train_data.iloc[:num]\n    valid_in = train_data.iloc[num:]\n    \n    train_ins = train_in.iloc[:,:-3]\n    valid_ins = valid_in.iloc[:,:-3]\n    \n    \n    results = []\n    predictions = []\n    print('STEP {}: {} Training Stage Start'.format(step,os.path.basename(train_dir[step])))\n    \n    for stage in range(3):\n        st = ['X','Y','F']\n        train_ous = train_in.iloc[:,stage-3]\n        valid_ous = valid_in.iloc[:,stage-3]\n    \n        # Network modeling\n        im_size = train_ins.shape[1]\n        w1 = int(im_size/2)\n        w2 = int(im_size/20)\n    \n        model = keras.Sequential([\n            keras.layers.Flatten(input_shape=(im_size, 1)),\n            keras.layers.Dense(w1, activation='sigmoid'),\n            keras.layers.Dense(w2, activation='sigmoid'),\n            keras.layers.Dense(1, activation='sigmoid') \n        ])\n    \n        model.compile(optimizer= tf.keras.optimizers.Adam(\n                        learning_rate=0.0005, beta_1=0.9, \n                        beta_2=0.999, epsilon=1e-07, \n                        amsgrad=False,name='Adam'),\n                        loss='mse',metrics=[ 'mse'])\n    \n        print('STEP {}-{}: ({}) Training {} Stage...'.format(step,stage,im_size,st[stage]))\n    \n        callback = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience = 10)\n        history = model.fit(train_ins, train_ous ,batch_size=32,\n                            validation_data=(valid_ins, valid_ous),\n                            epochs = 100,callbacks=[callback],\n                            verbose = 0)\n    \n        \n        prediction = model.predict(valid_ins)\n        prediction = prediction * (maxn[stage-3] - minn[stage-3]) + minn[stage-3]\n        target = valid_ous * (maxn[stage-3] - minn[stage-3]) + minn[stage-3]\n        \n        \n        if stage < 2:\n            mse = np.mean(np.sqrt(np.power(prediction.T - np.array(target),2)))\n            results.append(np.power(prediction.T - np.array(target),2))\n            print('{} Position MSE: {}'.format(st[stage],mse))\n        else:\n            prediction = np.round(prediction)\n            mse = np.mean(15 * (np.abs(prediction.T - np.array(target))))\n            print('{} Position MSE: {}'.format(st[stage],mse))\n            \n            mpe = np.mean(np.sqrt(results[0] + results[1]) + mse)\n            print('Evaluation Results MPE : {}\\n'.format(mpe))\n        \n        prediction = model.predict(test_data)  \n        prediction = prediction * (maxn[stage-3] - minn[stage-3]) + minn[stage-3]\n        if stage == 2: prediction = np.round(prediction)\n        predictions.append(prediction)\n    \n    submission.append(predictions)\n    \nfor i in submission:\n    k = np.vstack((np.array(k),np.hstack((i[2],i[0],i[1]))))\n    \nfinal_ver.loc[:,'floor':] = k[1:]\nfinal_ver.to_csv('./submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}