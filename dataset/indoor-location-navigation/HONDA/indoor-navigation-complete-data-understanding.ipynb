{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/oiG2jZl.png\">\n<center><h1>ğŸ§­Indoor Location and NavigationğŸ§­</h1></center>\n\n# 1. Introduction\n> ğŸ“Œ**Goal**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚»ãƒ³ã‚µãƒ¼ã«ã‚ˆã‚‹ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ğŸ“±ã®å®¤å†…ä½ç½®ã®äºˆæ¸¬ğŸ¯.\n\n> ã¾ãŸã€ä»Šå›ã®ã‚³ãƒ³ãƒšã§åˆ©ç”¨ã§ãã‚‹**GitHub Repository**ã‚’ä½¿ã£ã¦ã€ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°ã‚’**ãƒãƒ¼ãƒˆã«ã‚³ãƒ”ãƒ¼ãƒšãƒ¼ã‚¹ãƒˆã›ãšã«**å‘¼ã³å‡ºã™æ–¹æ³•ã‚‚å­¦ã³ã¾ã™ã€‚\n\n### LibrariesğŸ“š"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CPU libraries\nimport os\nimport json\nimport glob # ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã™ã‚‹ã™ã¹ã¦ã®ãƒ‘ã‚¹åã‚’è¦‹ã¤ã‘ã‚‹\nimport cv2  # OpenCV(ç”»åƒã®èª­ã¿æ›¸ããƒ»ãƒªã‚µã‚¤ã‚ºãƒ»åè»¢ãªã©ã®åŠ å·¥)\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns # ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–(ä¸­ã§matplotlibã‚’ä½¿ã£ã¦ã‚‹)\nimport matplotlib     # ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\n\nfrom PIL import Image, ImageOps # ç”»åƒå‡¦ç†(å‚è€ƒï¼šhttps://note.nkmk.me/python-pillow-basic/)\nfrom skimage import io          # ç”»åƒå‡¦ç†(å‚è€ƒï¼šhttps://qiita.com/supersaiakujin/items/fc54116df9ca6958a68d)\nfrom skimage.color import rgba2rgb, rgb2xyz\nfrom tqdm import tqdm           # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼\nfrom dataclasses import dataclass  # __init__() ã®ã‚ˆã†ãªç‰¹æ®Šãªã‚¯ãƒ©ã‚¹ã‚’ç”Ÿæˆ\nfrom math import floor, ceil\n\nmycolors = [\"#797D62\", \"#9B9B7A\", \"#D9AE94\", \"#FFCB69\", \"#D08C60\", \"#997B66\"]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def show_values_on_bars(axs, h_v=\"v\", space=0.4):\n    '''seabornã®æ£’ã‚°ãƒ©ãƒ•ã®æœ€å¾Œã«å€¤ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚\n    axs: ãƒ—ãƒ­ãƒƒãƒˆã®è»¸\n    h_v: ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆãŒå‚ç›´ï¼æ°´å¹³ã‹ã©ã†ã‹'''\n    \n    def _show_on_single_plot(ax):\n        if h_v == \"v\":  # å‚ç›´ã®å ´åˆ\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() / 2\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_height())\n                ax.text(_x, _y, format(value, ','), ha=\"center\") \n        elif h_v == \"h\": # æ°´å¹³ã®å ´åˆ\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_width())\n                ax.text(_x, _y, format(value, ','), ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### W&Bã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n* ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ä½œæˆ https://wandb.ai (it's free)\n* menu -> Add-ons -> Secrets -> Add a new Secret -> label=wandb-key value=wandb API key\n* Install `wandb`\n* ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã€Œãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ãƒ»ã‚­ãƒ¼ã€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ ( ç§ã®å ´åˆã¯æ©Ÿå¯†ãªã®ã§ã€ç§˜å¯†ã«ã—ã¦ãŠãã¾ã™ã€‚ :) )"},{"metadata":{"trusted":true},"cell_type":"code","source":"import wandb\nos.environ[\"WANDB_SILENT\"] = \"true\"\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\npersonal_key_for_api = user_secrets.get_secret(\"wandb-key\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wandbã«ãƒ­ã‚°ã‚¤ãƒ³\n! wandb login $personal_key_for_api","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–\n### project - overajjãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åå‰ï¼ˆGitHubã®ãƒªãƒã‚¸ãƒˆãƒªã®åå‰ã¨åŒã˜)\n### name/experiment - runã®åå‰ï¼ˆ1ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§è¤‡æ•°ã®runã‚’ä½¿ç”¨)\nrun = wandb.init(project=\"indoor-location-kaggle\", name=\"data-understanding\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We're all set!\n\n# 2. Data Understanding\n\n* `train` - *site*ã¨*floor*ã§æ§‹æˆã•ã‚ŒãŸå­¦ç¿’ç”¨ãƒ‘ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã€‚å„ãƒ‘ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€1ã¤ã®ãƒ•ãƒ­ã‚¢ã®1ã¤ã®ãƒ‘ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹ã€‚\n* `test` - ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‘ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã§ã€*site*ã¨*floor*ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚å„ãƒ‘ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€1ã¤ã®ãƒ•ãƒ­ã‚¢ã®1ã¤ã®ãƒ‘ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ãŒã€**waypoint (x, y)ãƒ‡ãƒ¼ã‚¿**ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n* `metadata` - ãƒ•ãƒ­ã‚¢ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆã‚µã‚¤ãƒˆã¨ãƒ•ãƒ­ã‚¢ã”ã¨ã«æ•´ç†ã•ã‚Œã¦ãŠã‚Šã€ãƒ•ãƒ­ã‚¢ã”ã¨ã«ä»¥ä¸‹ã‚’å«ã‚€:\n    * `floor_image.png`\n    * `floor_info.json`\n    * `geojson_map.json`\n    \n<img src=\"https://i.imgur.com/EE98923.png\" width=500>\n\n> ğŸ“Œ**Goal**: ã“ã®ã‚³ãƒ³ãƒšã®èª²é¡Œã¯ã€ä¸ãˆã‚‰ã‚ŒãŸsite-pathãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦ã€`sample_submission.csv`ãƒ•ã‚¡ã‚¤ãƒ«ã§ä¸ãˆã‚‰ã‚ŒãŸ**timestamp**ã§ã€**predict the floor**ã¨**waypoint locations**ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ã™ã€‚\n\n> â—**Note on data quality**â—: å­¦ç¿’ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­ã«ã¯ã€æœ€å¾Œã®æ”¹è¡Œæ–‡å­—ãŒãªã„è¡ŒãŒã‚ã‚Šã€æ¬¡ã®è¡Œã«é€²ã‚“ã§ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å•é¡Œã‚’ã©ã®ã‚ˆã†ã«å‡¦ç†ã™ã‚‹ã‹ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¬¡ç¬¬ã§ã™ã€‚ã“ã®å•é¡Œã¯ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’ç¢ºèª\ntrain_paths = glob.glob('../input/indoor-location-navigation/train/*/*/*')\ntest_paths = glob.glob('../input/indoor-location-navigation/test/*')\nsites = glob.glob('../input/indoor-location-navigation/metadata/*')\n\nprint(\"No. Files in Train: {:,}\".format(len(train_paths)), \"\\n\" +\n      \"No. Files in Test: {:,}\".format(len(test_paths)), \"\\n\" +\n      \"Total Sites (metadata): {:,}\".format(len(sites)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# å®Ÿé¨“çš„ã«W&Bã®\"data-understanding\"ã«ãƒ­ã‚°ã‚’æ®‹ã™ã€‚W&Bã®ã‚µã‚¤ãƒˆå‚ç…§\n# å‚è€ƒï¼šhttps://wandb.ai/honda/indoor-location-kaggle/runs/36e88gwf?workspace=user-honda\nwandb.log({'No. Files in Train': len(train_paths), \n           'No. Files in Test:' : len(test_paths),\n           'Total Sites (metadata)' : len(sites)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n\n> â—**Note**: æç¤ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯`.txt`å½¢å¼ã§ã€å¤šãã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ãŸã£ãŸ1ã¤ã®`.txt`ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã¤ã¾ã‚Š1ã¤ã®ãƒ‘ã‚¹ï¼‰ã«ã€126kè¡Œä»¥ä¸Šã®æƒ…å ±ãŒã‚ã‚Šã¾ã—ãŸã€‚1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«æƒ…å ±ã¯ç•°ãªã‚‹ã®ã§ã€ã™ã¹ã¦ã‚’æ§‹é€ åŒ–ã—ã‚ˆã†ã¨ã™ã‚‹ã¨é¢å€’ãªã“ã¨ã«ãªã‚Šã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã®ãã„ã¦ã¿ã‚‹\nbase = '../input/indoor-location-navigation'\npath = f'{base}/train/5cd56b5ae2acfd2d33b58549/5F/5d06134c4a19c000086c4324.txt'\n\nwith open(path) as p:\n    lines = p.readlines()\n\nprint(\"No. Lines in 1 example: {:,}\". format(len(lines)), \"\\n\" +\n      \"Example (5 lines): \", lines[0:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Kaggleã§ã®GitHub repoã®ä½¿ã„æ–¹?ğŸ”—\n\n> ğŸ“Œ**Goal**: ã“ã®ã‚³ãƒ³ãƒšã«ã¯ã€[GitHub repo](https://github.com/location-competition/indoor-location-competition-20)ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚io_f`ãƒ•ã‚¡ã‚¤ãƒ«ã®`read_data_file`é–¢æ•°ã‚’ä½¿ã£ã¦æƒ…å ±ã‚’èª­ã¿è¾¼ã‚ã°ã„ã„ã®ã§ã™ï¼ˆã“ã¡ã‚‰å´ã§ã®è¿½åŠ ã®è‹¦åŠ´ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‹ã‚³ãƒ”ãƒ¼ãƒšãƒ¼ã‚¹ãƒˆã§ã‚³ãƒ¼ãƒ‰ãŒä¹±é›‘ã«ãªã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã›ã‚“ :)ï¼‰\n\n#### *ğŸ™ğŸ»ã“ã®ç´ æ™´ã‚‰ã—ã„ãƒˆãƒªãƒƒã‚¯ã‚’æ•™ãˆã¦ãã‚ŒãŸ[Laura](https://www.kaggle.com/allunia)ã«æ„Ÿè¬ã—ã¾ã™ã€‚ğŸ™ğŸ»*\n\n**Steps**:\n* ğŸ¦¶ğŸ» - ã“ã®ãƒªãƒ³ã‚¯ã‹ã‚‰repoã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹(https://github.com/location-competition/indoor-location-competition-20)\n* ğŸ¦¶ğŸ» - ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’Kaggleç’°å¢ƒã«ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚ (`!cp -r path/* ./`)\n* ğŸ¦¶ğŸ» - importã—ã¦å¥½ããªã‚ˆã†ã«ä½¿ã†"},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r ../input/indoor-locationnavigation-2021/indoor-location-competition-20-master/indoor-location-competition-20-master/* ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\nfrom io_f import read_data_file\n\n# 1ã¤ã®ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ•ã‚¡ã‚¤ãƒ«ã§èª­ã‚€\nsample_file = read_data_file(path)\n\n# å„å¤‰æ•°ã®æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™:\nprint(\"~~~ Example ~~~\")\n# acce:TYPE_ACCELEROMETER:åŠ é€Ÿåº¦è¨ˆ\n# acacce_uncalice: TYPE_ACCELEROMETER_UNCALIBRATED:åŠ é€Ÿåº¦è¨ˆ(è£œæ­£å‰ï¼Ÿ)\n# ahrs:TYPE_ROTATION_VECTORï¼šå›è»¢ãƒ™ã‚¯ãƒˆãƒ«\n# gyro:TYPE_GYROSCOPEï¼šã‚¸ãƒ£ã‚¤ãƒ­ã‚¹ã‚³ãƒ¼ãƒ—(ç‰©ä½“ã®è§’åº¦ï¼ˆå§¿å‹¢ï¼‰ã‚„è§’é€Ÿåº¦ã‚ã‚‹ã„ã¯è§’åŠ é€Ÿåº¦ã‚’æ¤œå‡ºã™ã‚‹è¨ˆæ¸¬å™¨ãªã„ã—è£…ç½®)\n# ibeacn:TYPE_BEACONï¼šãƒ“ãƒ¼ã‚³ãƒ³(Bluetooth low energyã®ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆé€šä¿¡ã‚’åˆ©ç”¨ã—ãŸiOSã®è¿‘æ¥é€šçŸ¥æ©Ÿèƒ½)\n# magn:TYPE_MAGNETIC_FIELDï¼šç£åŠ›è¨ˆ\n# magn_uncali:TYPE_MAGNETIC_FIELD_UNCALIBRATEDï¼šç£åŠ›è¨ˆï¼ˆè£œæ­£å‰ï¼Ÿï¼‰\n# waypoint:TYPE_WAYPOINTï¼šæ­©ã„ãŸå ´æ‰€\n# wifi:TYPE_WIFIï¼š wifi\nprint(\"acce: {}\".format(sample_file.acce.shape), \"\\n\" +\n      \"acacce_uncalice: {}\".format(sample_file.acce_uncali.shape), \"\\n\" +\n      \"ahrs: {}\".format(sample_file.ahrs.shape), \"\\n\" +\n      \"gyro: {}\".format(sample_file.gyro.shape), \"\\n\" +\n      \"gyro_uncali: {}\".format(sample_file.gyro_uncali.shape), \"\\n\" +\n      \"ibeacon: {}\".format(sample_file.ibeacon.shape), \"\\n\" +\n      \"magn: {}\".format(sample_file.magn.shape), \"\\n\" +\n      \"magn_uncali: {}\".format(sample_file.magn_uncali.shape), \"\\n\" +\n      \"waypoint: {}\".format(sample_file.waypoint.shape), \"\\n\" +\n      \"wifi: {}\".format(sample_file.wifi.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ã‚ˆã—ã€ä»Šã‹ã‚‰æ¥½ã—ã‚‚ã†ï¼\n\n## SitesğŸ¢\n\n> **site**ã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ãŠã‚Šã€ãƒ‡ãƒ¼ã‚¿ãŒæŠ½å‡ºã•ã‚ŒãŸ**å»ºç‰©**ã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_site_png(site):\n    '''ã“ã®æ©Ÿèƒ½ã¯ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹.pngç”»åƒã‚’å¯è¦–åŒ–ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚\n    sites: 1ã¤ã®ã‚µã‚¤ãƒˆï¼ˆã¾ãŸã¯å»ºç‰©ï¼‰ã«å¯¾å¿œã™ã‚‹ã‚³ãƒ¼ãƒ‰'''\n    \n    base = '../input/indoor-location-navigation'\n    site_path = f\"{base}/metadata/{site}/*/floor_image.png\"\n    floor_paths = glob.glob(site_path)\n    n = len(floor_paths)\n\n    # ã‚«ã‚¹ã‚¿ãƒ ã®è¡Œã¨åˆ—ã®æ•°ã‚’ä½œæˆ 1è¡Œã«ã¤ã3ã¤ã¾ã§è¡¨ç¤ºã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚\n    ncols = [ceil(n / 3) if n > 4 else 4][0]\n    nrows = [ceil(n / ncols) if n > 4 else 1][0]\n\n    plt.figure(figsize=(16, 10))\n    plt.suptitle(f\"Site no. '{site}'\", fontsize=18)\n\n    # å„éšã®ãƒ—ãƒ­ãƒƒãƒˆã‚¤ãƒ¡ãƒ¼ã‚¸\n    for k, floor in enumerate(floor_paths):\n        plt.subplot(nrows, ncols, k+1)\n\n        image = Image.open(floor)\n        image = ImageOps.expand(image, border=15, fill=mycolors[5])\n\n        plt.imshow(image)\n        plt.axis(\"off\")\n        title = floor.split(\"/\")[5]\n        plt.title(title, fontsize=15)\n        \n        # W&Bã®\"data-understanding\"ã« å®Ÿé¨“çš„ã«ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹\n        wandb.log({\"Site Floors Example\": plt})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1ã¤ã®ä¾‹ã‚’è¦‹ã¦ã¿ã‚ˆã†\n# site = '5cd56b64e2acfd2d33b59246'\nshow_site_png(site='5cd56b64e2acfd2d33b592b3')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ã„ãã¤ã®ãƒ•ãƒ­ã‚¢ãŒã‚ã‚‹? ğŸ›©\n\n> â—**Note**: ã“ã®å¤‰æ•°ã¯ã€äºˆæ¸¬ãŒå¿…è¦ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®1ã¤ã§ã‚ã‚‹ãŸã‚ã€éå¸¸ã«é‡è¦ã§ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_floors = glob.glob(\"../input/indoor-location-navigation/metadata/*/*\")\nfloor_no = []\n\n# ãƒ•ãƒ­ã‚¢ç•ªå·ã®ã¿ã‚’æŠ½å‡º\nfor floor in all_floors:\n    no = floor.split(\"/\")[5]\n    floor_no.append(no)\n    \nfloor_no = pd.DataFrame(floor_no, columns=[\"No\"])\nfloor_no = floor_no[\"No\"].value_counts().reset_index()\nfloor_no = floor_no.sort_values(\"No\", ascending=False)\n\n# ~~~~\n# ãƒ•ãƒ­ã‚¢ã”ã¨ã«æ•°ã‚’è¡¨ç¤º\n# ~~~~\nplt.figure(figsize=(16, 12))\nax = sns.barplot(data=floor_no, x=\"No\", y=\"index\", palette=\"Greens_r\",\n                 saturation=0.4)\nshow_values_on_bars(ax, h_v=\"h\", space=0.4)\nax.set_title(\"Frequency of Floors\", size = 26, color = mycolors[0], weight='bold')\nax.set_xlabel(\"\")\nax.set_ylabel(\"Floor No.\", size = 18, color = mycolors[0], weight='bold')\nplt.xticks([])\nplt.yticks(fontsize=11)\nsns.despine(left=True, bottom=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# W&Bã®\"data-understanding\"ã«å®Ÿé¨“çš„ã«ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ã€‚\n### ç¾åœ¨ã€seabornã®ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆãƒ­ã‚°ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n### ã‚«ã‚¹ã‚¿ãƒ æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¾ã™ã€‚\ndata = [[index, no] for (index, no) in zip(floor_no[\"index\"], floor_no[\"No\"])]\ntable = wandb.Table(data=data, columns=[\"index\", \"no\"])\nwandb.log({\"Frequency of Floors\" : wandb.plot.bar(table, \"index\", \"no\", title=\"Frequency of Floors\")})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> W&Bã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã¯ã“ã®ã‚ˆã†ã«è¡¨ç¤ºã•ã‚Œã¾ã™:\n<img src=\"https://i.imgur.com/IpxLc7t.png\" width=700>\n\n## Waypoint\n\n> â—**Note**: ã“ã®å¤‰æ•°ã¯éå¸¸ã«é‡è¦ã§ã€æˆ‘ã€…ãŒäºˆæ¸¬ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã‚‚ã†ä¸€ã¤ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã§ã™ã€‚\n\n> ğŸ“Œ**Waypoint**: ä¸‹ã®å›³ã¯ã€1äººã®äººé–“ãŒ1ã¤ã®ã‚µã‚¤ãƒˆã®5éšã‚’é€šéã™ã‚‹éš›ã®*çµŒè·¯*ã€ã¤ã¾ã‚Šè»Œè·¡ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã‹ãªã‚Šæ­©ã„ã¦å¾€å¾©ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã“ã®è»Œè·¡ã®**é–‹å§‹ç‚¹**ã¨**çµ‚äº†ç‚¹**ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"# GitHub functions\nfrom visualize_f import visualize_trajectory, visualize_heatmap\n\npath = f'{base}/train/5cd56b5ae2acfd2d33b58549/5F/5d06134c4a19c000086c4324.txt'\n\n# ã‚µãƒ³ãƒ—ãƒ«ã®èª­ã¿è¾¼ã¿\nexample = read_data_file(path)\n\n# ~~~~~~~~~\n\n# ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨x,yåº§æ¨™ã®å€¤ã‚’è¿”ã™\ntrajectory = example.waypoint\n# ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®å‰Šé™¤ï¼ˆå¿…è¦ãªã®ã¯åº§æ¨™ã®ã¿)\ntrajectory = trajectory[:, 1:3]\n\n# ä¾‹é¡Œã«æ²¿ã£ãŸfloor_planã‚’ç”¨æ„ã™ã‚‹\n# ../input/indoor-location-navigation/metadata/5a0546857ecc773753327266/B1/xxxxx.xxx ã¨ã„ã†ã‚ˆã†ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ\nsite = path.split(\"/\")[4]\nfloorNo = path.split(\"/\")[5]\nfloor_plan_filename = f'{base}/metadata/{site}/{floorNo}/floor_image.png'\n\n# width_meter & height_meterã‚’æº–å‚™ã™ã‚‹\n### (taken from the .json file)\njson_plan_filename = f'{base}/metadata/{site}/{floorNo}/floor_info.json'\nwith open(json_plan_filename) as json_file:\n    json_data = json.load(json_file)\n    \n# {\"map_info\": {\"height\": 204.53342955266643, \"width\": 270.34143433711995}} ã“ã‚“ãªãƒ‡ãƒ¼ã‚¿\nwidth_meter = json_data[\"map_info\"][\"width\"]\nheight_meter = json_data[\"map_info\"][\"height\"]\n\n# Title\ntitle = \"Example of Waypoint\"\n\n# ~~~~~~~~~\n\n# Finally, let's plot\nvisualize_trajectory(trajectory = trajectory,\n                     floor_plan_filename = floor_plan_filename,\n                     width_meter = width_meter,\n                     height_meter = height_meter,\n                     title = title,\n                     g_size=755,\n                     point_color='#76C1A0',\n                     start_color='#007B51',\n                     end_color='#9B0000')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ç£åŠ›ã®å¼·ã• ğŸ§²\n\n> ğŸ“Œ**Magnetic Strength**: å»ºç‰©å†…ã®ã©ã®åœ°ç‚¹ã‚‚ã€**å›ºæœ‰ã®ç£åŠ›**ã‚’å—ã‘ã¦ã„ã¾ã™ã€‚åºŠã‚„å£ã€ã‚ã‚‹ã„ã¯éƒ¨å±‹ã®å‘¨å›²ã«ã‚ã‚‹ç‰©ä½“ã¯ã€3æ¬¡å…ƒç©ºé–“ã¨**ç£æ°—ã®å¤§ãã•**ã®4æ¬¡å…ƒåœ°å›³ã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã®ç©ºé–“å†…ã®ä»»æ„ã®ç‚¹ã«ãŠã‘ã‚‹ç£æ°—ã®å¤§ãã•ã¯ã€ãã®ç‚¹ã«ãŠã‘ã‚‹xã€yã€zã®ç£æ°—ãƒ™ã‚¯ãƒˆãƒ«ã‚’èª­ã¿å–ã‚‹ã“ã¨ã§æ¸¬å®šã§ãã‚‹ã€‚\n\n> â—**Note**: æºå¸¯é›»è©±ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç§»å‹•ã™ã‚‹ã¨ï¼ˆæºå¸¯é›»è©±ãŒå›è»¢ã™ã‚‹ã¨ï¼‰ã€ç£ç•Œã®å¤‰å‹•ã‚’æ¤œå‡ºã—ã¾ã™ã€‚ä¸‹ã®ä¾‹ã§ã¯ã€waypointã®æœ€åˆã®æ–¹ã§ã¯ç£å ´ãŒå¼·ãã€åºŠã®å·¦å´ã§ã¯ç£å ´ãŒå¼±ããªã£ã¦ã„ã¾ã™ã€‚\n\n#### ğŸ“mu tesla (1Ã—104 G) - ç£æ°—èª˜å°ã®æ´¾ç”Ÿå˜ä½ğŸ“"},{"metadata":{"trusted":true},"cell_type":"code","source":"# GitHub functions\nfrom main import calibrate_magnetic_wifi_ibeacon_to_position\nfrom main import extract_magnetic_strength\n\n# ç£åŠ›ã®å€¤ã‚’å–å¾—ã™ã‚‹ã€‚\nmwi_datas = calibrate_magnetic_wifi_ibeacon_to_position([path])\nmagnetic_strength = extract_magnetic_strength(mwi_datas)\n\nheat_positions = np.array(list(magnetic_strength.keys()))\nheat_values = np.array(list(magnetic_strength.values()))\n\n# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®å¯è¦–åŒ–\nvisualize_heatmap(heat_positions, \n                  heat_values, \n                  floor_plan_filename,\n                  width_meter, \n                  height_meter, \n                  colorbar_title='mu tesla', \n                  title='Magnetic Strength',\n                  g_size=755,\n                  colorscale='temps')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## WiFi ğŸ“¶\n\n> ğŸ“Œ**WiFi Access Points**: æ•·åœ°å†…ã®ãƒ•ãƒ­ã‚¢ã«ã¯ã€WiFiã‚¢ã‚¯ã‚»ã‚¹ãƒã‚¤ãƒ³ãƒˆãŒéå¸¸ã«å¤šãå­˜åœ¨ã—ã¾ã™ã€‚ãã®ãŸã‚ã€ã‚¨ãƒªã‚¢ã«ã‚ˆã£ã¦ä¿¡å·ã‚„ãã®å¼·ã•ãŒå¤§ããç•°ãªã‚Šã¾ã™ã€‚\n> â—**Note**: ä¸‹ã®ä¾‹ã§ã¯ã€ãƒ«ãƒ¼ãƒˆä¸Šã«ã“ã®ã‚ˆã†ãªã‚¢ã‚¯ã‚»ã‚¹ãƒã‚¤ãƒ³ãƒˆãŒãŸãã•ã‚“ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"# GitHub Libraries\nfrom main import extract_wifi_rssi, extract_wifi_count\n\n# Get WiFi data\nwifi_rssi = extract_wifi_rssi(mwi_datas)\nprint(f'This floor has {len(wifi_rssi.keys())} wifi aps (access points).')\n\nwifi_counts = extract_wifi_count(mwi_datas)\nheat_positions = np.array(list(wifi_counts.keys()))\nheat_values = np.array(list(wifi_counts.values()))\n# ç„¡ç·šLANãŒæ¤œå‡ºã•ã‚Œãªã„ä½ç½®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹\nmask = heat_values != 0\nheat_positions = heat_positions[mask]\nheat_values = heat_values[mask]\n\n# The heatmap\nvisualize_heatmap(heat_positions, \n                  heat_values, \n                  floor_plan_filename, \n                  width_meter, \n                  height_meter, \n                  colorbar_title='count', \n                  title=f'WiFi Count',\n                  g_size=755,\n                  colorscale='temps')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IBeacon (Bluetooth) ğŸ”µğŸ¦·\n\n> ğŸ“Œ**IBeacon**: ãƒ“ãƒ¼ã‚³ãƒ³ã¯ã€ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨é€£å‹•ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ“ãƒ¼ã‚³ãƒ³ã‹ã‚‰ä¸€å®šã®è·é›¢ã«è¿‘ã¥ã„ãŸã¨ãã«ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ã‚’è¡Œã†ãªã©ã€ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ç‰¹å®šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’èµ·ã“ã—ã¾ã™ã€‚\n\n> â—**Note**: ä¸‹ã®ä¾‹ã®çµŒè·¯ã«ã¯å¤šãã®ãƒ“ãƒ¼ã‚³ãƒ³ãŒè¨­ç½®ã•ã‚Œã¦ã„ã¾ã™ãŒã€iBeaconãŒå…¨ãè¨­ç½®ã•ã‚Œã¦ã„ãªã„éƒ¨åˆ†ã‚‚å¤šãã‚ã‚Šã¾ã™ã€‚ã“ã®éƒ¨åˆ†ã®ç²¾åº¦ã¯ä½ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n#### ğŸ“dBm (decibel milliwatts) - çµ¶å¯¾çš„ãªãƒ‘ãƒ¯ãƒ¼ã®æŒ‡æ¨™ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã€æ•°å€¤ãŒ0ã«è¿‘ã„ã»ã©ã€ä¿¡å·å¼·åº¦ãŒå„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’æ„å‘³ã™ã‚‹ğŸ“"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The GitHub function\nfrom main import extract_ibeacon_rssi\n\n# Getting the iBeacon data\nibeacon_rssi = extract_ibeacon_rssi(mwi_datas)\nprint(f'This floor has {len(ibeacon_rssi.keys())} ibeacons.')\nibeacon_ummids = list(ibeacon_rssi.keys())\ntarget_ibeacon = ibeacon_ummids[0]\nheat_positions = np.array(list(ibeacon_rssi[target_ibeacon].keys()))\nheat_values = np.array(list(ibeacon_rssi[target_ibeacon].values()))[:, 0]\n\n# The heatmap\nvisualize_heatmap(heat_positions, \n                  heat_values, \n                  floor_plan_filename, \n                  width_meter, \n                  height_meter, \n                  colorbar_title='dBm', \n                  title='iBeacon RSSE',\n                  g_size=755,\n                  colorscale='temps')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ~ END of EXPERIMENT ~\nwandb.finish()\n# ~~~~~~~~~~~~~~~~~~~~~","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Understanding the Competition Metric\n\n> ğŸ“Œ**Note**: å¤šãã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€åŒã˜ `comp_metric` é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ *Evaluation metric* ã‚’è¨ˆç®—ã—ã¦ã„ã¾ã™ãŒï¼ˆä»¥ä¸‹ã®ã‚ˆã†ã«ï¼‰ã€ã“ã®å¤‰æ•°ã¨ãã®æ„å‘³ã‚’ç†è§£ã™ã‚‹ã®ã«å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã—ãŸã€‚ãã®ãŸã‚ã€ï¼ˆç§ã®ã‚ˆã†ã«ï¼‰ã‚³ãƒ³ãƒšã®èª¬æ˜æ›¸ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹æƒ…å ±ã‚’æ—©ã€…ã«èª­ã¿é£›ã°ã—ã¦ã—ã¾ã£ãŸäººã®ãŸã‚ã«ã€å°‘ã—ã ã‘æƒ…å ±ã‚’å…±æœ‰ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚\n\n`def comp_metric(xhat, yhat, fhat, x, y, f):\n    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n    return intermediate.sum()/xhat.shape[0]`\n    \n### èª¬æ˜\n\nä¸Šè¨˜ã®å¼ã¯ã€ä»¥ä¸‹ã®æ•°å­¦é–¢æ•°ã®Pythonç‰ˆã«éãã¾ã›ã‚“ï¼ˆç«¶æŠ€ä¼šã§æä¾›ã•ã‚ŒãŸã‚‚ã®ã§ã™ï¼‰:\n<img src=\"https://i.imgur.com/1Z0s7Cc.png\" width=500>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import sqrt, power\nfrom numpy import abs as absolute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_position_error(x_pred, y_pred, f_pred, x_true, y_true, f_true, p=15):\n    '''Mean Position Errorã‚’è©•ä¾¡ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°ã€‚\n    x: waypointã®ä½ç½®ã®xåº§æ¨™; dtype list()\n    y: waypointã®ä½ç½®ã®yåº§æ¨™; dtype list()\n    f: æ­£ç¢ºãªéšæ•°ã¾ãŸã¯å»ºç‰©; dtype list()\n    p: ãƒ•ãƒ­ã‚¢ãƒšãƒŠãƒ«ãƒ†ã‚£'''\n    \n    N = len(x_true)\n    #1\n    formula = sqrt( power(x_pred - x_true, 2) + power(y_pred - y_true, 2) )\n    #2\n    formula = formula + p * absolute(f_pred - f_true)\n    #3\n    formula = formula.sum() / N\n    \n    return formula","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RAPIDS function\n- RAPIDSï¼šãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®ãŸã‚ã®æ§˜ã€…ãªå‡¦ç†ã‚’ä¸€è²«ã—ã¦GPUã§è¡Œã†ãŸã‚ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚\n- å‚è€ƒï¼šhttps://qiita.com/shin_ishiguro/items/8f39aac45acc8363a42e"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install cupy-cuda102\n!pip install cupy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install cupy --no-cache-dir -vvvv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from cupy import sqrt as sqrt_g\nfrom cupy import power as power_g\nfrom cupy import abs as abs_g","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_position_error_gpu(x_pred, y_pred, f_pred, x_true, y_true, f_true, p=15):\n    '''Same, but Faster ;)\n    ã“ã“ã§RAPIDSã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€å¾Œã«XGBoostãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚'''\n    \n    N = len(x_true)\n    formula = sqrt_g( power_g(x_pred - x_true, 2) + power_g(y_pred - y_true, 2) )\n    formula = formula + p * abs_g(f_pred - f_true)\n    formula = formula.sum() / N\n    return formula","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Baseline Model\n\n> ğŸ“Œ**Note**: å‰å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯[Devin Anzelmo](https://www.kaggle.com/devinanzelmo)ã«ã‚ˆã‚‹[this dataset](https://www.kaggle.com/devinanzelmo/indoor-navigation-and-location-wifi-features)ã‹ã‚‰ã®ã‚‚ã®ã§ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_submission(predictions, sample_subm, name=\"base.csv\"):\n    '''äºˆæ¸¬å€¤ã®ãƒªã‚¹ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼ã§å—ã‘å–ã‚Šã¾ã™ã€‚'''\n    final_submission = pd.concat(predictions).reset_index(drop=True)\n    final_submission.index = sample_subm.index\n    final_submission.to_csv(name)\n    print(\"Submission ready.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I. Light GBM\n- æ±ºå®šæœ¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ã„ãŸå‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ï¼ˆGradient Boostingï¼‰ã®æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯\n- å‚è€ƒï¼šhttps://www.codexa.net/lightgbm-beginner/"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Libraries\nimport lightgbm as lgb\n\n# ~~~~\n# Data\n# ~~~~\nbase_dir = \"../input/indoor-navigation-and-location-wifi-features/wifi_features\"\ntrain_dir = \"/train/*_train.csv\"\ntest_dir = \"/test/*_test.csv\"\n\n\n# Paths for train & test files\ntrain_paths = sorted(glob.glob(base_dir + train_dir))\ntest_paths = sorted(glob.glob(base_dir + test_dir))\nsample_subm = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv',\n                          index_col=0)\n\nprint(\"Len Train Files: {}\".format(len(train_paths)), \"\\n\" +\n      \"Len Test Files: {}\".format(len(test_paths)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# æ–°ã—ã„å®Ÿé¨“ã®åˆæœŸåŒ– (LGBM)\nrun = wandb.init(project=\"indoor-location-kaggle\", name=\"lgbm_train\")\n\nwandb.log({'Len Train Files' : len(train_paths),\n           'Len Test Files' : len(test_paths)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Schema of the \"Training loop\":\n<img src=\"https://i.imgur.com/UQmdRcz.png\" width=750>\n\n#### Code Below"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"def train_lgbm(train_perc=0.75, version=1):\n    '''\n    Training loop\n    '''\n\n    f = open(f\"lgbm_logs_{version}.txt\", \"w+\")\n    lgbm_predictions = []\n    \n    k = 1\n    for train_path, test_path in zip(train_paths, test_paths):\n\n\n        # --- Read in data ---\n        # index_col=æŒ‡å®šã—ãŸåˆ—ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦åˆ©ç”¨\n        # frac=æŠ½å‡ºã™ã‚‹è¡Œãƒ»åˆ—ã®å‰²åˆã‚’æŒ‡å®šã§ãã‚‹ã€‚1ã ã¨100%ã€‚\n        train_df = pd.read_csv(train_path, index_col=0)\n        train_df = train_df.sample(frac=1, random_state=10)\n\n        # æœ€å¾Œã®åˆ—ã‚’æ¶ˆã™ (which is \"site_path_timestamp\")\n        test_df = pd.read_csv(test_path, index_col=0).iloc[:, :-1]\n\n        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ã‚¢ã‚¦ãƒˆ\n        ### 3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã™ã¹ã¦ã«åŒã˜æƒ…å ±ã‚’é¸æŠã™ã‚‹ã‚ˆã†ã«æ³¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n        ### 1 for x, 1 for y and 1 for floor\n\n        train_size = int(len(train_df) * train_perc)\n\n\n        # --- Data Validation ---\n        # Train features + targets(75ï¼…ã‚’ç·´ç¿’ç”¨)\n        X_train = train_df.iloc[:train_size, :-4]\n        y_train_x = train_df.iloc[:train_size, -4]\n        y_train_y = train_df.iloc[:train_size, -3]\n        y_train_f = train_df.iloc[:train_size, -2]\n\n        # Valid features + targetsï¼ˆï¼’ï¼•ï¼…ã‚’ãƒ†ã‚¹ãƒˆç”¨ï¼‰\n        X_valid = train_df.iloc[train_size:, :-4]\n        y_valid_x = train_df.iloc[train_size:, -4]\n        y_valid_y = train_df.iloc[train_size:, -3]\n        y_valid_f = train_df.iloc[train_size:, -2]\n\n\n        # --- Model Training ---\n        # n_estimators=ãƒ„ãƒªãƒ¼ï¼ˆæœ¨ï¼‰ã®æ•°ã€num_leaves=æœ€å¤§ãƒ„ãƒªãƒ¼ãƒªãƒ¼ãƒ•æ•°\n        lgbm_x = lgb.LGBMRegressor(n_estimators=150, num_leaves=127)\n        lgbm_x.fit(X_train, y_train_x)\n\n        lgbm_y = lgb.LGBMRegressor(n_estimators=150, num_leaves=127)\n        lgbm_y.fit(X_train, y_train_y)\n\n        lgbm_f = lgb.LGBMClassifier(n_estimators=150, num_leaves=127)\n        lgbm_f.fit(X_train, y_train_f)\n\n\n        # --- ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ äºˆæ¸¬ ---\n        preds_x = lgbm_x.predict(X_valid)\n        preds_y = lgbm_y.predict(X_valid)\n        preds_f = lgbm_f.predict(X_valid).astype(int)\n        \n        mpe = mean_position_error(preds_x, preds_y, preds_f,\n                                  y_valid_x, y_valid_y, y_valid_f)\n        print(\"{} | MPE: {}\".format(k, mpe))\n        # Save logs\n        with open(f\"lgbm_logs_{version}.txt\", 'a+') as f:\n            print(\"{} | MPE: {}\".format(k, mpe), file=f)\n        k+=1\n        \n        # Log MPE of this experiment\n        wandb.log({'MPE' : mpe}, step=k)\n\n\n        # --- ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆã®äºˆæ¸¬ ---\n        test_preds_x = lgbm_x.predict(test_df)\n        test_preds_y = lgbm_y.predict(test_df)\n        test_preds_f = lgbm_f.predict(test_df).astype(int)\n\n        all_test_preds = pd.DataFrame({'floor' : test_preds_f,\n                                       'x' : test_preds_x, \n                                       'y' : test_preds_y})\n        lgbm_predictions.append(all_test_preds)\n    \n    \n    return lgbm_predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®è¡Œã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ãã ã•ã„ã€‚\nlgbm_predictions = train_lgbm(train_perc = 0.75, version=1)\n\n# Logs from my training:\nprint(open('../input/indoor-locationnavigation-2021/lgbm_logs_1.txt', \"r\").read())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> â—**Attention**: *5ç•ªç›®*ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã¯ã€å¤§ããªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆå¹³å‡4å€‹ã‹ã‚‰18å€‹ã«å¢—ãˆã¾ã—ãŸï¼‰ã€‚ã“ã®ã‚±ãƒ¼ã‚¹ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€è€ƒæ…®ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚10ç•ªç›®ã€13ç•ªç›®ã€21ç•ªç›®ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚‚åŒæ§˜ã«å¤§ããªMPEã‚’æŒã£ã¦ã„ã¾ã™ã€‚\n\n### Submission LGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®è¡Œã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ãã ã•ã„ã€‚\nmake_submission(lgbm_predictions, sample_subm, name=\"lgbm_base.csv\")\n\n# My submission:\nlgbm_predictions = pd.read_csv(\"../input/indoor-locationnavigation-2021/lgbm_base.csv\")\nlgbm_predictions.to_csv(\"lgbm_base.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ~ END of EXPERIMENT ~\nwandb.finish()\n# ~~~~~~~~~~~~~~~~~~~~~","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## II. XGBoost - Faster with RAPIDS\n\n> ğŸ“Œ**Note**: ä»Šå›ã¯ã€GPUä¸Šã®**RAPIDS**ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨XGBoostã‚’çµ„ã¿åˆã‚ã›ãŸã‚‚ã®ã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ä¸€ã¤ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¾¤ã«ã¤ã„ã¦ã®è©³ç´°ã¯[ã“ã¡ã‚‰](https://rapids.ai/)ã‚’ã”è¦§ãã ã•ã„ã€‚"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Libraries\nimport cudf\nimport cupy\nimport cuml\nimport xgboost\n\n# Adjust floor function\n### Multiclass XGBoostã¯ã€[0, n]ã®é–“ã®ãƒ©ãƒ™ãƒ«ã—ã‹å–ã‚‰ãªã„ã®ã§\n### ã—ã‹ã—ã€ãƒã‚¤ãƒŠã‚¹ã®ãƒ•ãƒ­ã‚¢å€¤ã‚’æŒã£ã¦ã„ã¾ã™\ndef adjust_floor(df, col_name):\n    '''Adjusts the floor to be >= 0.\n    Also returns the number fo classes (also used to complete classification).'''\n    num_classes = df[col_name].nunique()\n    smallest = df[col_name].unique().min()\n    df[col_name] = df[col_name] - smallest\n    \n    return df[col_name], num_classes, smallest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize new experiment (XGB)\nrun = wandb.init(project=\"indoor-location-kaggle\", name=\"xgb_train\")\n\nwandb.log({'Len Train Files' : len(train_paths),\n           'Len Test Files' : len(test_paths)})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def train_xgb(train_perc=0.75, version=1):\n    '''\n    Training loop\n    '''\n\n    f = open(f\"xgb_logs_{version}.txt\", \"w+\")\n    xgb_predictions = []\n    \n    k = 1\n    for train_path, test_path in zip(train_paths, test_paths):\n\n\n        # --- Read in data ---\n        train_df = cudf.read_csv(train_path, index_col=0)\n        train_df = train_df.sample(frac=1, random_state=10)\n        train_df[\"f\"], num_classes, smallest = adjust_floor(train_df, 'f')\n\n        # Erase last column (which is \"site_path_timestamp\")\n        test_df = cudf.read_csv(test_path, index_col=0).iloc[:, :-1]\n\n        # Sample out training and validation data\n        ### we need to be careful to choose same information for ALL 3 models\n        ### 1 for x, 1 for y and 1 for floor\n\n        train_size = int(len(train_df) * train_perc)\n\n\n        # --- Data Validation ---\n        # Train features + targets\n        X_train = train_df.iloc[:train_size, :-4]\n        y_train_x = train_df.iloc[:train_size, -4]\n        y_train_y = train_df.iloc[:train_size, -3]\n        y_train_f = train_df.iloc[:train_size, -2]\n\n        # Valid features + targets\n        X_valid = train_df.iloc[train_size:, :-4]\n        y_valid_x = cupy.asanyarray(train_df.iloc[train_size:, -4])\n        y_valid_y = cupy.asanyarray(train_df.iloc[train_size:, -3])\n        y_valid_f = cupy.asanyarray(train_df.iloc[train_size:, -2])\n        \n        \n        # --- Parameters ---\n        # max_depth=æ±ºå®šæœ¨ã®æ·±ã•ã®æœ€å¤§å€¤  max_leaves=è‘‰ã®æœ€å¤§å€¤ã€€tree_method=æœ¨æ§‹é€ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ   grow_policy=ãƒ„ãƒªãƒ¼ã«æ–°ã—ã„ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ ã™ã‚‹æ–¹æ³•\n        regr_params = {'max_depth' : 4, 'max_leaves' : 2**4, \n                       'tree_method' : 'gpu_hist', 'objective' : 'reg:squarederror',\n                       'grow_policy' : 'lossguide', 'colsample_bynode': 0.8}\n        classif_params = {'max_depth' : 4, 'max_leaves' : 2**4,\n                          'tree_method' : 'gpu_hist', 'objective' : 'multi:softmax',\n                          'num_class' : num_classes, 'grow_policy' : 'lossguide',\n                          'colsample_bynode': 0.8, 'verbosity' : 0}\n\n\n        # --- Model Training ---\n        trainMatrix_x = xgboost.DMatrix(data=X_train, label=y_train_x)\n        xgboost_x = xgboost.train(params=regr_params, dtrain=trainMatrix_x)\n\n        trainMatrix_y = xgboost.DMatrix(data=X_train, label=y_train_y)\n        xgboost_y = xgboost.train(params=regr_params, dtrain=trainMatrix_y)\n\n        trainMatrix_f = xgboost.DMatrix(data=X_train, label=y_train_f)\n        xgboost_f = xgboost.train(params=classif_params, dtrain=trainMatrix_f)\n\n\n        # --- Model Validation Predictions ---\n        preds_x = cupy.asanyarray(xgboost_x.predict(xgboost.DMatrix(X_valid)))\n        preds_y = cupy.asanyarray(xgboost_y.predict(xgboost.DMatrix(X_valid)))\n        preds_f = cupy.asanyarray(xgboost_f.predict(xgboost.DMatrix(X_valid)).astype(int))\n\n        mpe = mean_position_error_gpu(preds_x, preds_y, preds_f,\n                                      y_valid_x, y_valid_y, y_valid_f)\n        print(\"{} | MPE: {}\".format(k, mpe))\n        # Save logs\n        with open(f\"xgb_logs_{version}.txt\", 'a+') as f:\n            print(\"{} | MPE: {}\".format(k, mpe), file=f)\n        k+=1\n        # Log MPE of this experiment\n        wandb.log({'MPE' : mpe}, step=k)\n\n\n        # --- Model Test Predictions ---\n        test_preds_x = xgboost_x.predict(xgboost.DMatrix(test_df))\n        test_preds_y = xgboost_y.predict(xgboost.DMatrix(test_df))\n        test_preds_f = xgboost_f.predict(xgboost.DMatrix(test_df)).astype(int) + smallest\n\n        all_test_preds = pd.DataFrame({'floor' : test_preds_f,\n                                       'x' : test_preds_x, \n                                       'y' : test_preds_y})\n        xgb_predictions.append(all_test_preds)\n    \n    \n    return xgb_predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®è¡Œã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ãã ã•ã„ã€‚\n# xgb_predictions = train_xgb(train_perc=0.75, version=1)\n\n# Logs from my training:\nprint(open('../input/indoor-locationnavigation-2021/xgb_logs_1.txt', \"r\").read())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ä¸‹ã®è¡Œã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ã€è‡ªåˆ†ã§æŠ•ç¨¿ã—ã¦ãã ã•ã„ã€‚\n# make_submission(xgb_predictions, sample_subm, name=\"xgb_base.csv\")\n\n# My submission:\nxgb_predictions = pd.read_csv(\"../input/indoor-locationnavigation-2021/xgb_base.csv\")\nxgb_predictions.to_csv(\"xgb_base.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ~ END of EXPERIMENT ~\nwandb.finish()\n# ~~~~~~~~~~~~~~~~~~~~~","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Save W&B Submissions and Logs\n\n> We can save the predictions and logs to W&B."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submissions\n### we can save the predictions in W&B\nrun = wandb.init(project='indoor-location-kaggle', name='submissions')\nartifact = wandb.Artifact(name='submissions', \n                          type='dataset')\n\nartifact.add_file(\"../input/indoor-locationnavigation-2021/lgbm_base.csv\")\nartifact.add_file(\"../input/indoor-locationnavigation-2021/xgb_base.csv\")\n\nwandb.log_artifact(artifact)\nwandb.finish()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logs\n### we can save the predictions in W&B\nrun = wandb.init(project='indoor-location-kaggle', name='training_logs')\nartifact = wandb.Artifact(name='training_logs', \n                          type='dataset')\n\nartifact.add_file(\"../input/indoor-locationnavigation-2021/lgbm_logs_1.txt\")\nartifact.add_file(\"../input/indoor-locationnavigation-2021/xgb_logs_1.txt\")\n\nwandb.log_artifact(artifact)\nwandb.finish()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Read in data\nlgb_preds = pd.read_csv(\"../input/indoor-locationnavigation-2021/lgbm_base.csv\")\nxgb_preds = pd.read_csv(\"../input/indoor-locationnavigation-2021/xgb_base.csv\")\n\nsample_submission = pd.read_csv(\"../input/indoor-location-navigation/sample_submission.csv\")\n\n# Sample Submission\nsample_submission[\"x\"] = lgb_preds[\"x\"] * 0.9 + xgb_preds[\"x\"] * 0.1\nsample_submission[\"y\"] = lgb_preds[\"y\"] * 0.9 + xgb_preds[\"y\"] * 0.1\n\nsample_submission.to_csv(\"blend1.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/cUQXtS7.png\">\n\n# Specs on how I prepped & trained âŒ¨ï¸ğŸ¨\n### (on my local machine)\n* Z8 G4 Workstation ğŸ–¥\n* 2 CPUs & 96GB Memory ğŸ’¾\n* NVIDIA Quadro RTX 8000 ğŸ®\n* RAPIDS version 0.17 ğŸƒğŸ¾â€â™€ï¸"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}