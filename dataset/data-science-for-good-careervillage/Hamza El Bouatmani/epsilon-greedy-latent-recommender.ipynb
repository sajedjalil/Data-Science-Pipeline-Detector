{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>Epsilon-Greedy Latent Recommender</center></h1>\n\n<center><a href=\"https://www.kaggle.com/hamzael1\">Hamza El Bouatmani</a> on 14th April, 2019 </center>\n"},{"metadata":{},"cell_type":"markdown","source":"*Last Update 23th April*: *Code Refactoring, Evaluation Section & more Documentation added*\n\n____"},{"metadata":{},"cell_type":"markdown","source":"# Introduction:\n<a href=\"https://www.careervillage.org/\" target=\"_blank\">CareerVillage.org</a> <span style=\"color: purple;\">is a cloud-based solution for career advice</span>. It provides a platform where students with career-related questions meet professionals from the industry who help them by answering their questions.\n\nThe goal of <a href=\"https://www.kaggle.com/c/data-science-for-good-careervillage/overview\" target=\"_blank\">this competition</a>, is to develop a method to recommend relevant questions to the professionals who are most likely to answer them.\n\nIn this notebook, I propose a solution that addresses the problem in an efficient manner using a probabilistic approach (Epsilon-Greedy) combined with an *state-of-the-art technique (LSA)*. **This combination aims to balance between Exploration & Exploitation, targeting both the new and already-engaged professionals.**\n\nThe biggest strength that was noticed, is that **this solution behaves particularly well when encountering professionals with diverse interests. For example, when a professional follows a set of tags, and answers questions unrelated to those tags, the system still keeps recommending questions from both ends, adapts continuously to the interests of the professional along time and behaves in a resilient manner.**\n\nControlled randomness is inherent to the proposed approach, this has two advantages:\n* recommendations stay diverse.\n* unanswered new questions have a high chance to get answered because they get propritized. The model doesn't *over-focus* on the answered questions of the professionals.\n\nFurther, a basic framework for evaluating the system was proposed along with the most important metrics to measure. This helps fine-tune the model parameters locally before moving to production and gives and idea about the performance of the system.\n\nThis notebook is structured as follows:\n* First, we ask the question \"[Why do we need a Recommender?](#why)\" and answer it with some focused analytics.\n* Next, [techniques and concepts](#concepts) used in the proposed recommender are explained.\n* Then, we move to the actual [implementation of the proposed recommender system and explain its inner-workings](#implementation) after performing the necessary [proprocessings](#preproc).\n* We discuss the difficulty of evaluating Recommender Systems and [propose a very basic framework to evaluate the proposed system](#eval), along with the metrics that must be took into account.\n* Finally, some [advice and future suggestions for improving the system](#future) are listed, along with links to useful ressources.\n"},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"# Why do we need a Recommender ? Let's ask the Data ! <a class=\"anchor\" id=\"why\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/hamzael1/an-extensive-eda-for-careervillage\" target=\"_blank\">In a previous notebook</a> I made an overall Exploratory Data Analysis on the provided data. Here, I will be brief and focus on the most important statistics and metrics related to the recommendation problem.\n\n*Note: some code snippets that are trivial are collapsed for better readability, feel free to expand them if you want to check the code*"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Imports\n\nimport numpy as np  # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('max_colwidth', 200)\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nimport re\nimport string\nimport math\nimport random\nfrom random import choice, choices\nimport time\n\nimport gc\n\n\nfrom IPython.display import display\n\nimport warnings  \nwarnings.filterwarnings('ignore')\n\n# Professionals Import\n\nprofessionals = pd.read_csv('../input/professionals.csv', index_col='professionals_id')\nprofessionals = professionals.rename(columns={'professionals_location': 'location', 'professionals_industry': 'industry', 'professionals_headline': 'headline', 'professionals_date_joined': 'date_joined'})\nprofessionals['headline'] = professionals['headline'].fillna('')\nprofessionals['industry'] = professionals['industry'].fillna('')\n\n# Students Import\n\nstudents = pd.read_csv('../input/students.csv', index_col='students_id')\nstudents = students.rename(columns={'students_location': 'location', 'students_date_joined': 'date_joined'})\n\n# Questions Import\nquestions = pd.read_csv('../input/questions.csv', index_col='questions_id', parse_dates=['questions_date_added'], infer_datetime_format=True)\nquestions = questions.rename(columns={'questions_author_id': 'author_id', 'questions_date_added': 'date_added', 'questions_title': 'title', 'questions_body': 'body', 'questions_processed':'processed'})\n\n# Answers Import\nanswers = pd.read_csv('../input/answers.csv', index_col='answers_id', parse_dates=['answers_date_added'], infer_datetime_format=True)\nanswers = answers.rename(columns={'answers_author_id':'author_id', 'answers_question_id': 'question_id', 'answers_date_added': 'date_added', 'answers_body': 'body'})\n\n# Tags Import\ntags = pd.read_csv('../input/tags.csv',)\ntags = tags.set_index('tags_tag_id')\ntags = tags.rename(columns={'tags_tag_name': 'name'})\n\n# Comments Import\ncomments = pd.read_csv('../input/comments.csv', index_col='comments_id')\ncomments = comments.rename(columns={'comments_author_id': 'author_id', 'comments_parent_content_id': 'parent_content_id', 'comments_date_added': 'date_added', 'comments_body': 'body' })\n\n\n# School Memberships\nschool_memberships = pd.read_csv('../input/school_memberships.csv')\nschool_memberships = school_memberships.rename(columns={'school_memberships_school_id': 'school_id', 'school_memberships_user_id': 'user_id'})\n\n# Groups Memberships\ngroup_memberships = pd.read_csv('../input/group_memberships.csv')\ngroup_memberships = group_memberships.rename(columns={'group_memberships_group_id': 'group_id', 'group_memberships_user_id': 'user_id'})\n\n# Emails\nemails = pd.read_csv('../input/emails.csv')\nemails = emails.set_index('emails_id')\nemails = emails.rename(columns={'emails_recipient_id':'recipient_id', 'emails_date_sent': 'date_sent', 'emails_frequency_level': 'frequency_level'})\n\n#####################################################\nprint('Important numbers:')\nprint('\\nThere are:')\nprint(f'- {len(students)} Students.', end=\"\\t\")\nprint(f'- {len(professionals)} Professionals.')\nprint(f'- {len(questions)} Questions.', end=\"\\t\")\nprint(f'- {len(answers)} Answers.')\nprint(f'- {len(tags)} Tags.', end=\"\\t\\t\")\nprint(f'- {len(comments)} Comments.')\nprint(f'- {school_memberships[\"school_id\"].nunique()} Schools.', end=\"\\t\\t\")\nprint(f'- {len(pd.read_csv(\"../input/groups.csv\"))} Groups.')\nprint(f'- {len(emails)} Emails were sent.')\n#####################################################\n\n# Questions-related stats\ntag_questions = pd.read_csv('../input/tag_questions.csv',)\ntag_questions = tag_questions.rename(columns={'tag_questions_tag_id': 'tag_id', 'tag_questions_question_id': 'question_id'})\ncount_question_tags = tag_questions.groupby('question_id').count().rename(columns={'tag_id': 'count_tags'}).sort_values('count_tags', ascending=False)\nprint('\\nInteresting statistics: ')\nprint(f'- {(answers[\"question_id\"].nunique()/len(questions))*100:.2f} % of the questions have at least 1 answer.')\nprint(f'\\n- {(len(count_question_tags)/len(questions))*100:.2f}% of questions are tagged by at least {count_question_tags[\"count_tags\"].tail(1).values[0]} tag.')\nprint(f'- Mean of tags per question: {count_question_tags[\"count_tags\"].mean():.2f} tags per question.')\n\ntag_users = pd.read_csv('../input/tag_users.csv',)\ntag_users = tag_users.rename(columns={'tag_users_tag_id': 'tag_id', 'tag_users_user_id': 'user_id'})\nusers_who_follow_tags = list(tag_users['user_id'].unique())\nnbr_pros_tags = len(professionals[professionals.index.isin(users_who_follow_tags)])\nnbr_students_tags = len(students[students.index.isin(users_who_follow_tags)])\nprint(f'\\n- {(nbr_pros_tags / len(professionals))*100:.2f} % of the professionals follow at least 1 Tag ({nbr_pros_tags}).')\nprint(f'- {(nbr_students_tags / len(students))*100:.2f} % of the students follow at least 1 Tag ({nbr_students_tags}).')\n\nquestion_scores = pd.read_csv('../input/question_scores.csv')\nnbr_questions_with_hearts = question_scores[question_scores['score'] > 0]['id'].nunique()\nprint(f'\\n- {(nbr_questions_with_hearts/len(questions))*100:.2f} % of questions were upvoted ({nbr_questions_with_hearts}).')\n\nanswer_scores = pd.read_csv('../input/answer_scores.csv')\nnbr_answers_with_hearts = answer_scores[answer_scores['score'] > 0]['id'].nunique()\nprint(f'- {(nbr_answers_with_hearts/len(questions))*100:.2f} % of answers were upvoted ({nbr_answers_with_hearts}).')\n\n\n# School/Group Related Stats\n\ndef is_student(user_id):\n    if user_id in students.index.values:\n        return 1\n    elif user_id in professionals.index.values:\n        return 0\n    else:\n        raise ValueError('User ID not student & not professional')\n\nschool_memberships['is_student'] = school_memberships['user_id'].apply(is_student)\nschool_memberships['is_student'] = school_memberships['is_student'].astype(int)\ncount_students_professionals = school_memberships.groupby('is_student').count()[['school_id']].rename(columns={'school_id':'count'})\nprint(f'\\n- Only {count_students_professionals.loc[1].values[0]/len(students):.2f} % of the students are members of schools ({count_students_professionals.loc[1].values[0]}).')\nprint(f'- Only {count_students_professionals.loc[0].values[0]/len(professionals):.2f} % of the professionals are members of schools ({count_students_professionals.loc[0].values[0]}).')\n\ngroup_memberships['is_student'] = group_memberships['user_id'].apply(is_student)\ngroup_memberships['is_student'] = group_memberships['is_student'].astype(int)\ncount_students_professionals = group_memberships.groupby('is_student').count()[['group_id']].rename(columns={'group_id':'count'})\nprint(f'\\n- Only {count_students_professionals.loc[1].values[0]/len(students):.2f} % of the students are members of groups ({count_students_professionals.loc[1].values[0]}).')\nprint(f'- Only {count_students_professionals.loc[0].values[0]/len(professionals):.2f} % of the professionals are members of groups ({count_students_professionals.loc[0].values[0]}).')\n\n\nprint('')","execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":"<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>","text/vnd.plotly.v1+html":"<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"},"metadata":{}},{"output_type":"stream","text":"Important numbers:\n\nThere are:\n- 30971 Students.\t- 28152 Professionals.\n- 23931 Questions.\t- 51123 Answers.\n- 16269 Tags.\t\t- 14966 Comments.\n- 2706 Schools.\t\t- 49 Groups.\n- 1850101 Emails were sent.\n\nInteresting statistics: \n- 96.57 % of the questions have at least 1 answer.\n\n- 97.31% of questions are tagged by at least 1 tag.\n- Mean of tags per question: 3.29 tags per question.\n\n- 90.91 % of the professionals follow at least 1 Tag (25594).\n- 14.88 % of the students follow at least 1 Tag (4608).\n\n- 96.93 % of questions were upvoted (23196).\n- 57.82 % of answers were upvoted (13837).\n\n- Only 0.04 % of the students are members of schools (1355).\n- Only 0.15 % of the professionals are members of schools (4283).\n\n- Only 0.01 % of the students are members of groups (311).\n- Only 0.03 % of the professionals are members of groups (727).\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 1- Need to increase the number of active professionals:\nThe following two graphs examine the degree activity of professionals in terms of number of posted answers.\n\n* The first Pie Chart shows that most of the professionals still haven't posted their first answer.\n* The second Bar Graph compares the number of active (posted at least one answer) and inactive (didn't post any answer) professionals each year.\n\nA good recommendation system can surely help professionals find relevant questions to answer and increase their activity on the platform."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Professionals with zero answers\nnbr_pros_without_answers = len(professionals) - answers['author_id'].nunique()\n#print(f'\\n- {(nbr_pros_without_answers/len(professionals))*100:.2f} % of the professionals have Zero answers ({nbr_pros_without_answers}).')\nfig = {\n    'data': [{\n        'type': 'pie',\n        'labels': ['Zero answers', '> 0 answers'],\n        'values': [nbr_pros_without_answers , len(professionals) - nbr_pros_without_answers],\n        'textinfo': 'label+percent',\n        'showlegend': False,\n        'marker': {'colors': [ '#00FF66', '#D9BCDB',], 'line': {'width': 3, 'color': 'white'}},\n    }],\n    'layout': {\n        'title': 'Professionals with Zero Answers'\n    }\n}\niplot(fig)\n","execution_count":2,"outputs":[{"output_type":"display_data","data":{"application/vnd.plotly.v1+json":{"data":[{"labels":["Zero answers","> 0 answers"],"marker":{"colors":["#00FF66","#D9BCDB"],"line":{"color":"white","width":3}},"showlegend":false,"textinfo":"label+percent","values":[17983,10169],"type":"pie","uid":"4f6764f9-e8fd-483d-8de2-09d4135ce21f"}],"layout":{"title":{"text":"Professionals with Zero Answers"}},"config":{"showLink":false,"linkText":"Export to plot.ly","plotlyServerURL":"https://plot.ly"}},"text/html":"<div id=\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\")) {\n    Plotly.newPlot(\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\", [{\"labels\": [\"Zero answers\", \"> 0 answers\"], \"marker\": {\"colors\": [\"#00FF66\", \"#D9BCDB\"], \"line\": {\"color\": \"white\", \"width\": 3}}, \"showlegend\": false, \"textinfo\": \"label+percent\", \"values\": [17983, 10169], \"type\": \"pie\", \"uid\": \"fe284092-453a-4f43-98c4-6b95e24d8807\"}], {\"title\": {\"text\": \"Professionals with Zero Answers\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\")) {window._Plotly.Plots.resize(document.getElementById(\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\"));};})</script>","text/vnd.plotly.v1+html":"<div id=\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\")) {\n    Plotly.newPlot(\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\", [{\"labels\": [\"Zero answers\", \"> 0 answers\"], \"marker\": {\"colors\": [\"#00FF66\", \"#D9BCDB\"], \"line\": {\"color\": \"white\", \"width\": 3}}, \"showlegend\": false, \"textinfo\": \"label+percent\", \"values\": [17983, 10169], \"type\": \"pie\", \"uid\": \"fe284092-453a-4f43-98c4-6b95e24d8807\"}], {\"title\": {\"text\": \"Professionals with Zero Answers\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\")) {window._Plotly.Plots.resize(document.getElementById(\"c9ff2101-f305-424f-8be4-d34f66f2bf8e\"));};})</script>"},"metadata":{}}]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Answers Import\nyears = questions['date_added'].dt.year.unique()\nyears = sorted(years)\nprofessionals['date_joined'] = pd.to_datetime(professionals['date_joined'])\nactivity_per_year = {}\n\nfor y in years:\n#y = 2013\n    limit_date = pd.to_datetime(f'{y}-12-31') - np.timedelta64(200, 'D')\n    year_answers = answers[answers['date_added'].dt.year == y]\n    professionals_up_to_year = professionals[professionals['date_joined'].dt.year <= y]\n    \n    nbr_active_pros = year_answers['author_id'].nunique()\n    nbr_inactive_pros = len(professionals_up_to_year) - nbr_active_pros\n    activity_per_year[y] = (nbr_active_pros, nbr_inactive_pros)\n\n\nfig = {\n    'data': [\n        {\n        'type': 'bar',\n        'name': 'Number of Active Professionals',\n        'x': years,\n        'y': [e[0] for e in list(activity_per_year.values())],\n        'marker': {'color': '#db2d43'}\n        },\n        {\n        'type': 'bar',\n        'name': 'Number of Inactive Professionals',\n        'x': years,\n        'y': [e[1] for e in list(activity_per_year.values())],\n        'marker': {'color': '#906FA8'}\n        }\n    ],\n    'layout': {\n        'title': 'Number of Active vs Non-Active Professionals each year',\n        'xaxis': {'title': 'Years'},\n        'yaxis': {'title': 'Number of Professionals',},\n        'barmode': 'stack',\n        'legend': {'orientation': 'h'},\n    }\n}\niplot(fig)\n","execution_count":3,"outputs":[{"output_type":"display_data","data":{"application/vnd.plotly.v1+json":{"data":[{"marker":{"color":"#db2d43"},"name":"Number of Active Professionals","x":[2011,2012,2013,2014,2015,2016,2017,2018,2019],"y":[23,147,180,581,797,2679,3130,4094,413],"type":"bar","uid":"3e264d39-4c20-45a0-8e96-9f40e1f50bb6"},{"marker":{"color":"#906FA8"},"name":"Number of Inactive Professionals","x":[2011,2012,2013,2014,2015,2016,2017,2018,2019],"y":[34,132,528,1114,2438,6174,12045,22653,27739],"type":"bar","uid":"31cc49cc-6ffb-4632-bb1b-69cac2a3124a"}],"layout":{"barmode":"stack","legend":{"orientation":"h"},"title":{"text":"Number of Active vs Non-Active Professionals each year"},"xaxis":{"title":{"text":"Years"}},"yaxis":{"title":{"text":"Number of Professionals"}}},"config":{"showLink":false,"linkText":"Export to plot.ly","plotlyServerURL":"https://plot.ly"}},"text/html":"<div id=\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\")) {\n    Plotly.newPlot(\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\", [{\"marker\": {\"color\": \"#db2d43\"}, \"name\": \"Number of Active Professionals\", \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [23, 147, 180, 581, 797, 2679, 3130, 4094, 413], \"type\": \"bar\", \"uid\": \"577fbe98-c5ae-489d-9168-43883a111265\"}, {\"marker\": {\"color\": \"#906FA8\"}, \"name\": \"Number of Inactive Professionals\", \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [34, 132, 528, 1114, 2438, 6174, 12045, 22653, 27739], \"type\": \"bar\", \"uid\": \"f700d0b3-047a-4f46-a3d1-80940fa5c833\"}], {\"barmode\": \"stack\", \"legend\": {\"orientation\": \"h\"}, \"title\": {\"text\": \"Number of Active vs Non-Active Professionals each year\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Number of Professionals\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\")) {window._Plotly.Plots.resize(document.getElementById(\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\"));};})</script>","text/vnd.plotly.v1+html":"<div id=\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\")) {\n    Plotly.newPlot(\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\", [{\"marker\": {\"color\": \"#db2d43\"}, \"name\": \"Number of Active Professionals\", \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [23, 147, 180, 581, 797, 2679, 3130, 4094, 413], \"type\": \"bar\", \"uid\": \"577fbe98-c5ae-489d-9168-43883a111265\"}, {\"marker\": {\"color\": \"#906FA8\"}, \"name\": \"Number of Inactive Professionals\", \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [34, 132, 528, 1114, 2438, 6174, 12045, 22653, 27739], \"type\": \"bar\", \"uid\": \"f700d0b3-047a-4f46-a3d1-80940fa5c833\"}], {\"barmode\": \"stack\", \"legend\": {\"orientation\": \"h\"}, \"title\": {\"text\": \"Number of Active vs Non-Active Professionals each year\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Number of Professionals\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\")) {window._Plotly.Plots.resize(document.getElementById(\"af1f9ddf-6f80-42ab-89c1-2de2c906b6a0\"));};})</script>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 2- Mean Time-To-First-Answer. Can we do better ?\nThe following graph shows the evolution of the means of Time-to-First-Answer for questions of each year. A good recommendation system must minimize this metric.\n\n**Mean Time-to-First-Answer**: $\\frac{1}{nbr \\thinspace questions}\\sum_{q}^{questions}{nbr \\thinspace days \\thinspace between \\thinspace question \\thinspace q \\thinspace was \\thinspace posted \\thinspace and \\thinspace its \\thinspace first \\thinspace answer}$"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"answers = answers.rename(columns={'date_added': 'answers_date_added'})\nquestions = questions.rename(columns={'date_added': 'questions_date_added'})\nfirst_answers = answers[['question_id', 'answers_date_added']].groupby('question_id').min()\nanswers_questions = first_answers.join(questions[['questions_date_added']])\nanswers_questions['diff_days'] = (answers_questions['answers_date_added'] - answers_questions['questions_date_added'])/np.timedelta64(1,'D')\nvals = [answers_questions[answers_questions['questions_date_added'].dt.year == y]['diff_days'].mean() for y in years]\nLINE_COLOR = '#9250B0'\nfig = {\n    'data': [{\n        'type': 'scatter',\n        'x': years,\n        'y': vals,\n        'line': {'color': LINE_COLOR}\n    }],\n    'layout': {\n        'title': 'Evolution of Time to First Response in days',\n        'xaxis': {'title': 'Years'},\n        'yaxis': {'title': 'Time to First Response'}\n    }\n}\niplot(fig)\nanswers = answers.rename(columns={'answers_date_added': 'date_added'})\nquestions = questions.rename(columns={'questions_date_added': 'date_added'})","execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.plotly.v1+json":{"data":[{"line":{"color":"#9250B0"},"x":[2011,2012,2013,2014,2015,2016,2017,2018,2019],"y":[59.66146910919538,28.359825883354613,48.90281375324367,30.963589215767403,29.07802632036025,109.43998411169221,37.36001710311319,39.9203517742886,4.390634279654104],"type":"scatter","uid":"f416a69a-bd37-42cf-9a6b-32ebd223c937"}],"layout":{"title":{"text":"Evolution of Time to First Response in days"},"xaxis":{"title":{"text":"Years"}},"yaxis":{"title":{"text":"Time to First Response"}}},"config":{"showLink":false,"linkText":"Export to plot.ly","plotlyServerURL":"https://plot.ly"}},"text/html":"<div id=\"c077e25a-2c20-4452-89b2-0aa019feec16\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"c077e25a-2c20-4452-89b2-0aa019feec16\")) {\n    Plotly.newPlot(\"c077e25a-2c20-4452-89b2-0aa019feec16\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [59.66146910919538, 28.359825883354613, 48.90281375324367, 30.963589215767403, 29.07802632036025, 109.43998411169221, 37.36001710311319, 39.9203517742886, 4.390634279654104], \"type\": \"scatter\", \"uid\": \"ad65ee87-2821-4812-9fb9-65c1eb149d18\"}], {\"title\": {\"text\": \"Evolution of Time to First Response in days\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Time to First Response\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"c077e25a-2c20-4452-89b2-0aa019feec16\")) {window._Plotly.Plots.resize(document.getElementById(\"c077e25a-2c20-4452-89b2-0aa019feec16\"));};})</script>","text/vnd.plotly.v1+html":"<div id=\"c077e25a-2c20-4452-89b2-0aa019feec16\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"c077e25a-2c20-4452-89b2-0aa019feec16\")) {\n    Plotly.newPlot(\"c077e25a-2c20-4452-89b2-0aa019feec16\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [59.66146910919538, 28.359825883354613, 48.90281375324367, 30.963589215767403, 29.07802632036025, 109.43998411169221, 37.36001710311319, 39.9203517742886, 4.390634279654104], \"type\": \"scatter\", \"uid\": \"ad65ee87-2821-4812-9fb9-65c1eb149d18\"}], {\"title\": {\"text\": \"Evolution of Time to First Response in days\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Time to First Response\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"c077e25a-2c20-4452-89b2-0aa019feec16\")) {window._Plotly.Plots.resize(document.getElementById(\"c077e25a-2c20-4452-89b2-0aa019feec16\"));};})</script>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 3- Number of accurate recommendations:\nNext, we examine how many accurate recommendations are sent each year. How many of them were answered by the recipients of the emails. Again, this number must be maximized by our recommender system."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Number of accurate recommendations\nemails['date_sent'] = pd.to_datetime(emails['date_sent'], infer_datetime_format=True)\nmatches = pd.read_csv('../input/matches.csv')\nmatches = matches.join(emails[['recipient_id', 'date_sent']], on='matches_email_id')\n\nmatches = matches.rename(columns={'matches_question_id': 'question_id', 'matches_email_id': 'email_id'})\nall_recommendations_per_year = []\naccurate_recommendations_per_year = []\nmatches['author_id'] = matches['recipient_id']\nfor y in years:\n    year_answers = answers[answers['date_added'].dt.year == y]\n    year_recommendations = matches[matches['date_sent'].dt.year == y]\n    all_recommendations_per_year.append(len(year_recommendations))\n    m = year_answers.reset_index().merge(year_recommendations, on=['question_id', 'author_id']).set_index('answers_id')\n    nbr_accurate_recommendations = len(m)\n    accurate_recommendations_per_year.append(nbr_accurate_recommendations)\n    #print(f'- {(nbr_accurate_recommendations/len(matches))*100:.2f} % of recommended questions in emails were accurate (lead to professional answering the recommended question) ({nbr_accurate_recommendations})')\n\n#print(accurate_recommendations_per_year)\nLINE_COLOR = '#9250B0'\nfig = {\n    'data': [{\n        'type': 'scatter',\n        'x': years,\n        'y': accurate_recommendations_per_year,\n        'line': {'color': LINE_COLOR}\n    }],\n    'layout': {\n        'title': 'Evolution of Number of Accurate recommendations',\n        'xaxis': {'title': 'Years'},\n        'yaxis': {'title': 'Time to First Response'}\n    }\n}\niplot(fig)\n","execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.plotly.v1+json":{"data":[{"line":{"color":"#9250B0"},"x":[2011,2012,2013,2014,2015,2016,2017,2018,2019],"y":[0,0,5,548,581,5309,5024,5672,264],"type":"scatter","uid":"f02f8496-0479-4f33-8b10-d4bf04ba6867"}],"layout":{"title":{"text":"Evolution of Number of Accurate recommendations"},"xaxis":{"title":{"text":"Years"}},"yaxis":{"title":{"text":"Time to First Response"}}},"config":{"showLink":false,"linkText":"Export to plot.ly","plotlyServerURL":"https://plot.ly"}},"text/html":"<div id=\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\")) {\n    Plotly.newPlot(\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [0, 0, 5, 548, 581, 5309, 5024, 5672, 264], \"type\": \"scatter\", \"uid\": \"a7a8f248-d3c7-4136-8c14-85cff3fd0a34\"}], {\"title\": {\"text\": \"Evolution of Number of Accurate recommendations\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Time to First Response\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\")) {window._Plotly.Plots.resize(document.getElementById(\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\"));};})</script>","text/vnd.plotly.v1+html":"<div id=\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\")) {\n    Plotly.newPlot(\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [0, 0, 5, 548, 581, 5309, 5024, 5672, 264], \"type\": \"scatter\", \"uid\": \"a7a8f248-d3c7-4136-8c14-85cff3fd0a34\"}], {\"title\": {\"text\": \"Evolution of Number of Accurate recommendations\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Time to First Response\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\")) {window._Plotly.Plots.resize(document.getElementById(\"cf84077c-d4a0-4d1d-b9bf-e2f10946beb1\"));};})</script>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 4- Proportion of accurate recommendations:\n\nThe following graph plots the the Ratio of number of accurate recommendations over all recommendations made. We can see that even though an increase of number of accurate recommendations occured in 2016 (previous graph), it was due to a significant increase in recommendations made. Ideally, a good recommender should maximize the number of accurate recommendations and minimize the number of incorrect ones in order to avoid churning."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"proportions_of_accurate_recommendations = np.array(accurate_recommendations_per_year)/np.array(all_recommendations_per_year)\nproportions_of_accurate_recommendations = [0 if np.isnan(e) else e for e in proportions_of_accurate_recommendations]\n#print(proportions_of_accurate_recommendations)\nfig = {\n    'data': [{\n        'type': 'scatter',\n        'x': years,\n        'y': proportions_of_accurate_recommendations,\n        'line': {'color': LINE_COLOR}\n    },\n    ],\n    'layout': {\n        'title': 'Percentage of Accurate recommendations',\n        'xaxis': {'title': 'Years'},\n        'yaxis': {'title': 'Proportion of Accurate Recommendations', 'tickformat': ',.0%'}\n    }\n}\niplot(fig)","execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.plotly.v1+json":{"data":[{"line":{"color":"#9250B0"},"x":[2011,2012,2013,2014,2015,2016,2017,2018,2019],"y":[0,0,0.040983606557377046,0.01966060345136871,0.009731830287599873,0.005554218758173354,0.004713967097935857,0.0027169305199626374,0.0022127231581594168],"type":"scatter","uid":"cd183457-9343-4561-ab41-de472bd7da63"}],"layout":{"title":{"text":"Percentage of Accurate recommendations"},"xaxis":{"title":{"text":"Years"}},"yaxis":{"tickformat":",.0%","title":{"text":"Proportion of Accurate Recommendations"}}},"config":{"showLink":false,"linkText":"Export to plot.ly","plotlyServerURL":"https://plot.ly"}},"text/html":"<div id=\"f8442d07-0aa0-45f3-a93b-75b5a05af755\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"f8442d07-0aa0-45f3-a93b-75b5a05af755\")) {\n    Plotly.newPlot(\"f8442d07-0aa0-45f3-a93b-75b5a05af755\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [0, 0, 0.040983606557377046, 0.01966060345136871, 0.009731830287599873, 0.005554218758173354, 0.004713967097935857, 0.0027169305199626374, 0.0022127231581594168], \"type\": \"scatter\", \"uid\": \"6f4c6080-8e89-4f0d-8347-764d7b60785b\"}], {\"title\": {\"text\": \"Percentage of Accurate recommendations\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"tickformat\": \",.0%\", \"title\": {\"text\": \"Proportion of Accurate Recommendations\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"f8442d07-0aa0-45f3-a93b-75b5a05af755\")) {window._Plotly.Plots.resize(document.getElementById(\"f8442d07-0aa0-45f3-a93b-75b5a05af755\"));};})</script>","text/vnd.plotly.v1+html":"<div id=\"f8442d07-0aa0-45f3-a93b-75b5a05af755\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\nif (document.getElementById(\"f8442d07-0aa0-45f3-a93b-75b5a05af755\")) {\n    Plotly.newPlot(\"f8442d07-0aa0-45f3-a93b-75b5a05af755\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [0, 0, 0.040983606557377046, 0.01966060345136871, 0.009731830287599873, 0.005554218758173354, 0.004713967097935857, 0.0027169305199626374, 0.0022127231581594168], \"type\": \"scatter\", \"uid\": \"6f4c6080-8e89-4f0d-8347-764d7b60785b\"}], {\"title\": {\"text\": \"Percentage of Accurate recommendations\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"tickformat\": \",.0%\", \"title\": {\"text\": \"Proportion of Accurate Recommendations\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n}\n});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"f8442d07-0aa0-45f3-a93b-75b5a05af755\")) {window._Plotly.Plots.resize(document.getElementById(\"f8442d07-0aa0-45f3-a93b-75b5a05af755\"));};})</script>"},"metadata":{}}]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Garbadge collect stuff we won't be using for building the recommender.\n\ndel m\ndel emails\ndel matches\ndel students\ndel school_memberships\ndel group_memberships\ndel count_question_tags\ndel users_who_follow_tags\ndel nbr_pros_tags\ndel nbr_students_tags\ndel nbr_pros_without_answers\ndel nbr_questions_with_hearts\ndel count_students_professionals\ngc.collect()\nprint('')","execution_count":7,"outputs":[{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Takeaways:\n* Tags are heavily used by students in questions.\n* Most professionals follow tags to find questions related to their expertise.\n* **Most of the professionals (~63%) haven't answered any question yet.**\n* **Only a tiny proportion of recommended questions (~0.41%) in emails were accurate enough to probably lead the recipient to answer.**\n* For the moment, we can not rely on school/group memberships, because only a tiny portion of the users have used them."},{"metadata":{},"cell_type":"markdown","source":"## 5- Problem with the current System"},{"metadata":{},"cell_type":"markdown","source":"In the current system, emails containing recommended questions are sent to professionals on a daily basis by default. \n\nThe possible frequencies that a professional can choose from are:\n* Immediate\n* Daily\n* Weekly\n* Turn off all notifications.\n\nThe 'daily' option is problematic. It is extremely difficult to to maintain a good quality of recommendations when the frequency is as high as 'Daily'. **We thus end up with a huge number of emails being sent daily with poor-quality recommendations. This can cause the professional to start ignoring emails and ultimately not returning to the site.**\n\nIn addition, having poor-quality recommendations increases the chance that the professional will choose to turn off all notifications, which is not desirable.\n\n<span style=\"color: blue; font-weight: bold;\">Quick Solution proposal: </span> Maintain good-quality recommendations by removing the 'Daily' option, and only keeping the 'Immediate' & 'Weekly' options.\n\nAnother *future* solution would be to leave it up to the system to decide when to email each professional depending on the interaction of the professional with the site.\n"},{"metadata":{},"cell_type":"markdown","source":"# Basic concepts and techniques used in the Recommender System <a class=\"anchor\" id=\"concepts\"></a>\nThe recommender system works in two \"modes\":\n* **Professional-to-Questions**: Recommend top K questions to a particular professional (needed for the professionals who choose a fixed frequency like 'Weekly' option )\n* **Question-to-Professionals**: Recommend top K professionals most likely to answer a particular question. (needed for the professional who choose the 'Immediate' option)\n"},{"metadata":{},"cell_type":"markdown","source":"## The Exploration-Exploitation Dilemma in Recommendations:\n\n![slots](https://i.imgur.com/pFO04zu.jpg?3)\n\n"},{"metadata":{},"cell_type":"markdown","source":"A recommender system's job is not that simple. If a recommender system keeps suggesting the same items to the same users, then in some cases, questions about fairness might be raised, in other cases, users might get bored getting the same type of content. In the case of Question-Answering platforms like CareerVillage, potential interests (other than the ones already expressed by the professional through tags) might be ignored and users might stop coming to the platform.\n\nA recommendation system must not only recommend relevant questions to the professionals, **Occasionally, it should also introduce them to potentially new types of questions that might interest them**. It has to deal with the cold-start problem, where very little information about he professional is known.\n\nIn the ML litterature, finding the right tradeoff between these two components is called the **Exploration-Exploitation problem**."},{"metadata":{},"cell_type":"markdown","source":"## The Epsilon-Greedy Algorithm ( in a nutshell )\n\nTo tackle the Exploration-Exploitation problem, a popular algorithm called **'Epsilon-Greedy'** is used.\n\n> It works by setting an Epsilon threshold, which represents the probability of 'Exploitation' .\n> \n> A random number N between 0.0 and 1.0 is generated,\n> \n> if N < Epsilon\n> \n>     Exploit by searching similar questions based on the past\n> \n> else\n> \n>     Explore new questions\n\n**The Epsilon-Greedy Algorithm is simple, easy to implement and does not need heavy computation, making it a great solution for the problem at hand. **\n\n*( More details on the inner-workings in a later section )*\n\n*Note: normaly Epsilon is used for exploration, in this implementation I used it for exploitation, but the idea is the same*"},{"metadata":{},"cell_type":"markdown","source":"## LSA: Latent Semantic Analysis (in a nutshell)\n\nLatent Semantic Analysis is a **simple**, yet **powerful** technique in Natural Language Processing. It captures the latent (hidden) topics of a corpus of text and represents each document by a vector of k dimensions, each pointing to one latent topic.\n\nTo do this, LSA relies on a robust mathematical technique called SVD (Singular-Value Decomposition), which factorizes a real matrix to a product of 3 matrices. ([More on LSA and SVD](#links))\n\n\n<span style=\"color: red; font-weight: bold;\">Takeaway:</span> **Each question will be represented by a vector of length k. comparing the questions will be as easy as performing a cosine similarity between the vectors.**"},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing is paramount ! <a class=\"anchor\" id=\"preproc\"></a>\n\n\n<div style=\"border: solid 1px blue; padding: 5px;\"><h4><center><span style=\"color: red;\">If we let Garbage In, we get Garbage Out ! (GIGO)</span><center></h4></div>\n\n<br/>\nThe most important data type in this project is Text (questions, tags ...). Unfortunately, if left unpreprocessed, it becomes extremely hard to extract useful information from it.\n\nThis section's goal, is to prepare the data by simplifying it and removing any noise that migh get in the way between us and the True Information that we want to extract.\n\nThis simple preprocessing can be easily done online in production, doesn't require a lot of computation.\n"},{"metadata":{},"cell_type":"markdown","source":"## 1- Tags:\nFor some reason, there are many tags which are not used in any question (and they are also not followed by any user)."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Drop tags that are not used in any question and not followed by any user (it will clean a lot of useless stuff)\nuseless_tags = tags[~tags.index.isin(tag_questions['tag_id'].unique())]\nuseless_tags = tags[ (tags.index.isin(useless_tags.index.values)) & (~tags.index.isin(tag_users['tag_id'].values)) ]\ntags = tags.drop(useless_tags.index)\n\nprint(f'- {len(useless_tags)} useless tags were found and dropped.')","execution_count":8,"outputs":[{"output_type":"stream","text":"- 1865 useless tags were found and dropped.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Next, we make the following transformations to the tags:\n* make all tags lowercase.\n* create a new 'processed' column to hold the processed version of each tag\n* remove any special characters from the text.\n* correct some short words (yrs -> years)\n* lemmatize the tags ( eg. 'wolves' -> 'wolf' )\n* remove tags without any meaning that are just numbers, just preprositions, pronouns, stop-words ... ('where', 'and', 'the', '10', ...etc)\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Preprocessing Tags\n\nnbr_tags = len(tags)\n\nstop_words = set(stopwords.words('english'))\n# some common words / mistakes to filter out too\nstop_words.update(['want', 'go', 'like', 'aa', 'aaa', 'aaaaaaaaa', \n                   'good', 'best', 'would', 'get', 'as', 'th', 'k',\n                   'become', 'know', 'us'])\nspecial_characters = f'[{string.punctuation}]'\nlm = WordNetLemmatizer()\n\n\ntags['name'] = tags['name'].str.lower()\ntags.fillna('', inplace=True)\ntags['processed'] = tags['name'].str.replace(special_characters, '')\ntags['processed'] = tags['processed'].str.replace('^\\d+$', '') # tags that are just numbers :-/\ntags['processed'] = tags['processed'].apply(lambda x: lm.lemmatize(x)) # avoid having plurals like 'career' and 'careers'\ntags['processed'] = tags['processed'].str.replace('^\\w$', '') # single letter tags :-/\ntags['processed'] = tags['processed'].str.replace(r'(\\d+)(yrs?)', r'\\1year') #\ntags['processed'] = tags['processed'].apply(lambda x: x if x not in stop_words else '')\n\n# Drop tags which are prepositions, pronouns, determiners, wh-adverbs (where, ...)\ntags_to_drop = []\nfor i, t in tags['processed'].iteritems():\n    if len(t) > 0 and nltk.pos_tag([t])[0][1] in ['IN', 'PRP', 'WP$', 'PRP$', 'WP', 'DT', 'WRB']:\n        tags_to_drop.append(i)\ntag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\ntags = tags.drop(tags_to_drop)\n\n# Drop tags which are just numbers\ntags_to_drop = tags[tags['name'].str.contains('^\\d+$')].index\ntag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\ntags = tags.drop(tags_to_drop)\n\n# Drop tags which are just stop words ( after, the , with , ...)\ntags_to_drop = tags[tags['name'].isin(stop_words)].index\ntag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\ntags = tags.drop(tags_to_drop)\n\nprint(f'{nbr_tags - len(tags)} Tags were filtered out.')\ntags.sample(2)","execution_count":9,"outputs":[{"output_type":"stream","text":"63 Tags were filtered out.\n","name":"stdout"},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"                        name      processed\ntags_tag_id                                \n18788           young-adults    youngadults\n19371        unreal-engine-3  unrealengine3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>processed</th>\n    </tr>\n    <tr>\n      <th>tags_tag_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18788</th>\n      <td>young-adults</td>\n      <td>youngadults</td>\n    </tr>\n    <tr>\n      <th>19371</th>\n      <td>unreal-engine-3</td>\n      <td>unrealengine3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**<span style=\"color: red\">Result</span>**: We are now able to see that the following tags are the same: \"information-technology\", \"#informationtechnology\", \"#information-technology\", \"information-technology-\".\n\nA future task might be to explore how to add to this list the word \"IT\" (using word2vec), but the preprocessing is always necessary."},{"metadata":{},"cell_type":"markdown","source":"## 2- Questions\n* We create a new column 'processed' containing both 'title' & 'body' text, and do the same transformations we did to tags ( remove special characters, lemmatize words and remove stop words ).\n* Create a new column 'count_answers'."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Questions Cleaning\n\nquestions['processed'] = questions['title'] + ' ' + questions['body']\nquestions['processed'] = questions['processed'].str.lower()\nquestions['processed'] = questions['processed'].str.replace('<.*?>', '') # remove html tags\nquestions['processed'] = questions['processed'].str.replace('[-_]', '') # remove separators\nquestions['processed'] = questions['processed'].str.replace(special_characters, ' ') # remove special characters\n\nquestions['processed'] = questions['processed'].str.replace('\\d+\\s?yrs?', ' years') # single letter tags :-/\n\ndef lem_question(q):\n    return \" \".join([lm.lemmatize(w) for w in q.split() if w not in stop_words])\nquestions['processed'] = questions['processed'].apply(lem_question)\n\nquestions['processed'] = questions['processed'].str.replace(r'(\\d+)($|\\s+)', r'\\2') # remove numbers which are not part of words\nquestions['processed'] = questions['processed'].str.replace(r'(\\d+)([th]|k)', r'\\2') # remove numbers from before th and k\n\n\n# Function to preprocess new questions\n# TODO: update function to do like above\ndef preprocess_question(q):\n    q = q.lower()\n    q = re.sub(\"<.*?>\", \"\", q)\n    q = re.sub(\"[-_]\", \"\", q)\n    q = re.sub(\"\\d+\", \"\", q)\n    q = q.translate(q.maketrans('', '', string.punctuation))\n    q = \" \".join([lm.lemmatize(t) for t in q.split()])\n    return q\n\ncnt_answers = answers.groupby('question_id').count()[['body']].rename(columns={'body': 'count_answers'})\nquestions = questions.join(cnt_answers)\nquestions['count_answers'] = questions['count_answers'].fillna(0)\nquestions['count_answers'] = questions['count_answers'].astype(int)\n\nprint('Questions preprocessed.')\nquestions.sample(1)[['title', 'body', 'processed', 'count_answers']]","execution_count":10,"outputs":[{"output_type":"stream","text":"Questions preprocessed.\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"                                                                        title      ...      count_answers\nquestions_id                                                                       ...                   \na3dc74d420df4040bbc3d9cce1587e7b  is it impossible to eat healthy in college?      ...                  2\n\n[1 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>body</th>\n      <th>processed</th>\n      <th>count_answers</th>\n    </tr>\n    <tr>\n      <th>questions_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a3dc74d420df4040bbc3d9cce1587e7b</th>\n      <td>is it impossible to eat healthy in college?</td>\n      <td>many people talk about how broke they are and how they live off of ramen noodles #students</td>\n      <td>impossible eat healthy college many people talk broke live ramen noodle student</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 3- Professionals\n* **Count Answers:** Create a new column 'count_answers' for professionals\n* **Cleaning the headlines**\n* **Follow Tags ?**: This is just a handy column I added to differentiate after between Pros who do and don't when evaluating the recommender\n* **Last Answer Date**: We will rely also on this new column to know if the professional is active or not."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\n# Count Answers\nprint('Counting Answers ...')\npro_answers_count = answers.groupby('author_id').count()[['question_id']].rename(columns={'question_id': 'count_answers'})\nprofessionals = professionals.join(pro_answers_count)\nprofessionals['count_answers'] = professionals['count_answers'].fillna(0)\nprofessionals['count_answers'] = professionals['count_answers'].astype(int)\n\n\n# Cleaning the headlines\nprint('Cleaning Headlines ...')\nprofessionals['headline'] = professionals['headline'].fillna('')\nprofessionals['headline'] = professionals['headline'].str.lower()\nprofessionals['headline'] = professionals['headline'].str.replace('--|hello|hello!|hellofresh', '')\n\n# Check if follow tags or not\nprint('Creating \"follow_tags\" column ...')\nprofessionals['follow_tags'] = False\nfollowers = list(tag_users['user_id'].unique())\nprofessionals.loc[professionals.index.isin(followers), 'follow_tags'] = True\n\n# Create Last Answer Date Column\nprint('Creating \"last_answer_date\" column ... ')\nprofessionals = professionals.join(answers[['author_id', 'date_added']].groupby('author_id').max().rename(columns={'date_added': 'last_answer_date'}))\n\n\nprint('Professionals preprocessed')\nprofessionals.sample(3)\n","execution_count":11,"outputs":[{"output_type":"stream","text":"Counting Answers ...\nCleaning Headlines ...\nCreating \"follow_tags\" column ...\nCreating \"last_answer_date\" column ... \nProfessionals preprocessed\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"                                                     location         ...            last_answer_date\nprofessionals_id                                                      ...                            \n8141cb9e650444319aa34997de3c21c5                          NaN         ...         2018-05-18 16:12:45\n7d5663e2f3e5418f8350f8097c2c72b2          Parkville, Maryland         ...         2019-01-30 03:35:09\nb6d1e25589704b44bd058f707fb1fa18  Bengaluru, Karnataka, India         ...         2016-07-20 09:13:21\n\n[3 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>industry</th>\n      <th>headline</th>\n      <th>date_joined</th>\n      <th>count_answers</th>\n      <th>follow_tags</th>\n      <th>last_answer_date</th>\n    </tr>\n    <tr>\n      <th>professionals_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8141cb9e650444319aa34997de3c21c5</th>\n      <td>NaN</td>\n      <td>Telecommunications</td>\n      <td>human resources coordinator</td>\n      <td>2018-02-22 15:16:00</td>\n      <td>2</td>\n      <td>True</td>\n      <td>2018-05-18 16:12:45</td>\n    </tr>\n    <tr>\n      <th>7d5663e2f3e5418f8350f8097c2c72b2</th>\n      <td>Parkville, Maryland</td>\n      <td>Staffing and Recruiting</td>\n      <td>student at the community college of baltimore county</td>\n      <td>2019-01-27 01:30:29</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2019-01-30 03:35:09</td>\n    </tr>\n    <tr>\n      <th>b6d1e25589704b44bd058f707fb1fa18</th>\n      <td>Bengaluru, Karnataka, India</td>\n      <td>Information Technology and Services</td>\n      <td>sales support advisor  at dell</td>\n      <td>2016-06-29 12:00:22</td>\n      <td>3</td>\n      <td>True</td>\n      <td>2016-07-20 09:13:21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Start Modeling !\n\nNow that we have pre-processed our data, we are ready for the modeling part.\n\nThe modeling steps are as follows:\n\n* **Apply TF-IDF on the hole question corpus.**\n* **Apply SVD to reduce the dimensionality of the vectors.**\n* **Construct a Questions Similarity Matrix using The Cosine Similarity function.**\n\nAfter some experimentation, I chose the number of topics ( new dimensionality of question vectors ) to be 1100 ( values between 900~1100 are ok ).\n"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"start = time.time()\n\ntfidf_vectorizer = TfidfVectorizer(stop_words=stop_words,)\n\nNUM_TOPICS = 1100\ndef build_model(qs , nbr_topics=NUM_TOPICS):\n    print('Building the Model ...')\n    # TF-IDF Transformation\n\n    qs_tfidf = tfidf_vectorizer.fit_transform(qs['processed'])\n    terms = tfidf_vectorizer.get_feature_names()\n    print(' (1/3) TF-IDF matrix shape: ', qs_tfidf.shape)\n\n    # Dimensionality Reduction with SVD\n    model = TruncatedSVD(n_components=nbr_topics)\n    transformer_model = model.fit(qs_tfidf)\n    qs_transformed = transformer_model.transform(qs_tfidf)\n    print(' (2/3) Shape after Dimensionality Reduction:', qs_transformed.shape)\n\n    # Construct Similarity Matrix\n    sim_mat = cosine_similarity(qs_transformed, qs_transformed)\n    print(' (3/3) Similarity Matrix Shape', sim_mat.shape, '\\n')\n    return transformer_model, qs_transformed, sim_mat\n\ntransformer_model, Qs_transformed, Qs_sim_matrix = build_model(questions)\n\nend = time.time()\n\nprint(f'{(end-start)/60:.2f} minutes')","execution_count":12,"outputs":[{"output_type":"stream","text":"Building the Model ...\n (1/3) TF-IDF matrix shape:  (23931, 18761)\n (2/3) Shape after Dimensionality Reduction: (23931, 1100)\n (3/3) Similarity Matrix Shape (23931, 23931) \n\n1.08 minutes\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color: blue;\">Notes on production:</span>\n* *Here, we use the totality of the question corpus when constructing the Similarity Matrix, in practice though, the similarity matrix will only be constructed with relatively recent questions ( last 1 or 2 years ), since old questions will not be of any use. Its construction only takes ~ 40 seconds for a ~ 24k x 24k matrix (pretty quick).*\n* *When in production, the Similarity Matrix & Questions Transformed Matrix must be updated on regular basis, depending on the traffic.*"},{"metadata":{},"cell_type":"markdown","source":"# Building the Recommendations Engine <a class=\"anchor\" id=\"implementation\"></a>\n\nIn this section, we will build the recommendations engine from scratch using only the techniques previously talked about. Each sub-section will deal with a specific sub-problem.\n\nThere are two main data structures we will work with:\n* **The Transformed Questions Matrix**: a Matrix where each row represents a single question encoded in a K dimensional vector\n* **The Similarity Matrix**: a NxN Matrix (where N is the number of questions) rating the similarity between all pair of questions on a scale of 0 ~ 1.\n\nNote that the recommender prioritizes **quality over quantity**. So, when asked for N recommendations, it will return the best k recommendations, where $k \\leq N$. The reason for this, is that the cost of bad recommendations can be high. We don't want users to get bad recommendations and ignore our future emails."},{"metadata":{},"cell_type":"markdown","source":"## 1- Professional-to-Questions Mode:\nIn this mode, three types of professionals can be distinguished:\n* **Hot**: The professional has posted at least one answer. But if no answer is posted for a defined period ( in code I set the variable min_date_for_answers=400 days ) then professional will be treated as Cold.\n* **Cold**: The professional has never posted an answer, but follows some tags.\n* **Freezing**: The professional never posted an answer and doesn't follow any tags.\n\nWhen recommending K questions, each iteration can be either **Exploitation** or **Exploration**\n\n**How to deal with the 'Freezing' professional ?**\n\nThe 'Freezing' professional has most probably registered recently, and doesn't follow any tags. We don't know much about him, the recommendations are more like 'suggestions' with the goal of taking him to the higher categories. \n\nWe can suggest:\n* **Exploit:** session-based recommendations which recommend questions similar to questions already visited / upvoted or commented by the professional\n* **Explore:** popular questions on the platform and newly created ones.\n\n( session-based recommendations are only feasible in production, so in this implementation we stick with exploration for this type of users )\n\n**How to deal with the 'Cold' professional ?**\n\nUnlike the 'Freezing' professional, the 'Cold' one follows one more tags. This important hint must be fully exploited as followed:\n* **Exploit:** find relatively recent questions from the tags followed.\n* **Explore:** find tags similar to the followed tags and do the same. This is possible because of the simple *pre-processing of tags*.\n\n**How to deal with the 'Hot' professional ?**\n\nThis type of professional has already expressed interest in one or more questions.\n* **Exploit:** suggest a similar question to one of the previously answered questions. To choose the answered question that will be the basis, we score all the questions and choose one question randomly based on the scores, which act as a probability distribution.\n* **Explore:** suggest most recent & similar questions from the tags followed as follows:\n    * Select the n most recent questions from each followed tag.\n    * from all those questions, select one the question which is most similar to one of the answered ones.\n\n<span style=\"color: red\">The Exploration/Exploitation approach has the advantage of not letting many questions unanswered by recommending often, and not over-focusing on the answered ones.</span>\n\n### Calculating the Exploit Threshold and Scoring Questions (for the 'Hot' professional):\n\nUnlike the the two other types of professionals, the optimal Exploit Threshold for the 'Hot' professional is dynamic and changes from a professional to another. Some professionals have only answered one question, while others have answered many. Some professionals have answers which date to a relatively long time, while others have just recently answered a few. **Taking these parameters into consideration affects positively the quality of the recommendations**.\n\n* We want our recommender to prioritize questions similar to questions recently answered by the professional\n* We also don't want to completely ignore older questions.\n\n### Question-Scoring Formula:\nThe following formula scores the questions answered by the Hot professional while capturing the first note above:\n\n$$ score(x) = \\frac{log (\\frac{x}{\\epsilon})}{log (\\frac{1}{\\epsilon})} $$\nwhere:\n- x is the number of days elapsed between the date question was answered and today\n- $\\epsilon$ is the maximum number of days after which we no longer consider the question to be relevant ( now it is set to 370 but can be changed with the variable \"eps\", see code below )\n\nThe formula gives a score between 0~1 where 1 means that the question is very relevant and should be used as a reference.\n\nBelow is the values-table of the formula (credits to [this online grapher](https://www.desmos.com/calculator)). The formula \"rewards\" questions that are recent ( x is small ). And as x gets smaller, the score drops drown in a logarithmic fashion until it interesects with the x axis exactly at the value $\\epsilon$.\n\n![question_scoring_formula_table](https://i.imgur.com/HiHiQfA.png)\n\n### Exploit-Threshold Formula:\n\nAfter the (answered) questions get scored, the Exploit Threshold is calculated as follows:\n\n$$ threshold = log (\\sqrt{x} + 1) \\cdot \\alpha +  \\epsilon $$\nwhere:\n- x is the number of recently answered questions ( considering here only number of answers which have scores > 0 ).\n- $\\alpha$ controls the exploitation intensity (1.35 in the implementation). Acceptable values range between 1.0 for low exploitation and 1.7 for high exploitation.\n- $\\epsilon$ is an **optional** small value term (0.1 on the implementation) added if all answered questions are old ( meaning, that if x = 0, we still give a very small probability to $\\epsilon$ for exploitation, see the implementation below ).\n\nBelow is values-table of the formula. The formula give a \"bigger\" exploit-threshold as more questions answered increase. It increases in a logarithmic fashion. ( there is a 1.35 in the left of the function in the value table but I couldn't get it to be visible)\n\n![threshold_formula_table](https://i.imgur.com/SqXgM5T.png)\n\nBelow is the implementation of the two formulas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_score_question_answered(days_elapsed_after_answer):\n    eps = 370\n    score = np.log10(days_elapsed_after_answer*(1/eps)) / (np.log10(1/eps))\n    score = 0.001 if score < 0 else score # questions that got a score lower than 0 are still given a very low score\n    return score\n\ndef calculate_exploit_threshold(answered_question_scores, nbr_recommendations, alpha=1.35):\n    nbr_questions_answered = len([s for s in answered_question_scores if s > 0])\n    eps = 0.1 if nbr_questions_answered == 0 else 0\n    return np.log10(np.sqrt(nbr_questions_answered) + 1) * alpha + eps\n","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The next snippet of code builds the recommendation engine using two main functions:**\n* **get_similar_questions**: returns similar questions to the one given using the similarity matrix ( the parameter \"similarity_threshold\" controls what similar means, I set it by default to be 0.4 as I found that value to work well for most cases ) .\n* **recommend_questions_to_professional**: given a professional ID, returns top K recommended questions.\n\nThe debug variable below, if set to True,  makes exploration / exploitation decisions visible."},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"debug = False","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set current date as the last day of the data\ndef set_today(d_str):\n    d = pd.to_datetime(d_str)\n    \n    min_for_questions = d - np.timedelta64(600, 'D') # used for the Freezing professional to select the latest questions and for the cold to select the latest questions in followed and suggested tags\n    min_for_answers = d - np.timedelta64(400, 'D')   # used for hot professional to select his last answers. if no answers in this period, Hot professional will be treated as Cold\n    return d, min_for_questions, min_for_answers\n\ntoday, min_date_for_questions, min_date_for_answers = set_today('2019-01-31')","execution_count":15,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"*( Feel free to check the code below collapsed )*"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\ndef choose_random_answered_question(question_score_dic):\n    random_key = choices(list(question_score_dic.keys()), list(question_score_dic.values()))[0]\n    return (random_key, question_score_dic[random_key])\n\n\ndef choose_random_followed_tag(pro_id):\n    followed_tags = tag_users[tag_users['user_id'] == pro_id]\n    return followed_tags.sample(1)['tag_id'].values[0]\n\ndef get_similar_questions(qid, nbr_questions=10, except_questions_ids=[], prioritize=False, similarity_threshold=0.4):\n    recommendations = pd.DataFrame([])\n\n    #print(len(except_questions_ids))\n    #print()\n    q_dists_row = list(Qs_sim_matrix[questions.index.get_loc(qid)])\n    for eq_id in except_questions_ids:\n        #print('removing ', eq_id)\n        #print(len(q_dists_row), questions.index.get_loc(eq_id))\n        q_dists_row[questions.index.get_loc(eq_id)] = -1\n    q_dists_row = pd.Series(q_dists_row).sort_values(ascending=False)[:100]\n    q_dists_row = q_dists_row[1:]\n\n    if not prioritize:\n        q_dists_row = q_dists_row[:nbr_questions]\n        for i, d in q_dists_row.iteritems():\n            qid = questions.index.values[i]\n            recommendations = recommendations.append(questions.loc[qid])\n    else:\n        qid_to_score = {}\n        for i, d in q_dists_row.iteritems():\n            qid = questions.index.values[i]\n            if d > similarity_threshold:\n                #print(qid)\n                q_added = questions.loc[qid, 'date_added']\n                days_elapsed = (today - q_added) / np.timedelta64(1, 'D')\n                qid_to_score[qid] = d * days_elapsed\n        qid_scores = sorted(qid_to_score.items(), key=lambda x: x[1])[:nbr_questions]\n        for qid, score in qid_scores:\n            print(q_dists_row[questions.index.get_loc(qid)], qid_to_score[qid]) if debug else None\n            recommendations = recommendations.append(questions.loc[qid])\n    return recommendations\n\n\n\ndef recommend_questions_to_professional(pro_id, nbr_recommendations=10, silent=False, alpha=1.35):\n    print('Professional ID:', pro_id ) if not silent else None\n\n    # tags followed\n    tags_followed = tag_users[tag_users['user_id'] == pro_id]['tag_id']\n    tags_followed = tags[tags.index.isin(tags_followed)]\n    print('Followed Tags: ', tags_followed['name'].values)  if not silent else None\n\n    # Number of answered questions\n    cnt_pro_answers = professionals.loc[pro_id, 'count_answers']\n    if cnt_pro_answers > 0:\n        pros_answers = answers[(answers['author_id'] == pro_id) & (answers['date_added'] < min_date_for_answers)]\n        cnt_pro_answers = len(pros_answers)\n\n    # Type of Start\n    cold_start = (cnt_pro_answers == 0)\n    freezing_start = (cold_start and len(tags_followed) == 0 )\n\n    n = 3 # Nbr of questions per tag\n    recommendations = pd.DataFrame([])\n\n\n    # Freezing Start\n    if freezing_start:\n        print('Freezing ...')  if not silent else None\n        recommendations = recommendations.append(questions[questions['date_added'] > min_date_for_questions].sample(10))\n\n    # Cold Start\n    elif cold_start:\n        print('Cold', cnt_pro_answers)  if not silent else None\n\n        qids_from_followed_tags  = tag_questions[tag_questions['tag_id'].isin(tags_followed.index.values)]['question_id'].values\n        qids_from_followed_tags  = list(questions[(questions.index.isin(qids_from_followed_tags))   & (questions['date_added'] > min_date_for_questions)].sort_values('date_added', ascending=False).index.values)\n\n        tags_suggested = tags[tags['processed'].isin(tags_followed['processed'].values)]\n        tags_suggested = tags_suggested[~tags_suggested.index.isin(tags_followed.index.values)]\n        print('Suggested Tags: ', tags_suggested['name'].values)  if not silent else None\n        suggested_tags_available = len(tags_suggested) > 0\n        # If there are suggested tags, we do explore on them while exploiting on the followed tags\n        if suggested_tags_available:\n            qids_from_suggested_tags = tag_questions[tag_questions['tag_id'].isin(tags_suggested.index.values)]['question_id'].values\n            qids_from_suggested_tags = list(questions[(questions.index.isin(qids_from_followed_tags))  & (questions['date_added'] > min_date_for_questions)].sort_values('date_added', ascending=False).index.values)\n            exploit_threshold = .6\n        # If no suggested tags are available, we just exploit on the followed tags\n        else:\n            exploit_threshold = 1\n\n\n        print('Exploit Threshold: ', exploit_threshold) if debug else None\n        for i in range(1, nbr_recommendations+1):\n            if np.random.rand() < exploit_threshold and len(qids_from_followed_tags) > 0:\n                # Exploit followed tags\n                print(f'{i}- Exploit followed tags') if debug else None\n                random_index = choice(qids_from_followed_tags)\n                q = questions.loc[random_index]\n                recommendations = recommendations.append(q)\n                qids_from_followed_tags.remove(random_index)\n            elif suggested_tags_available and len(qids_from_suggested_tags) > 0:\n                # Suggest from suggested tags\n                print(f'{i}- Explore suggested tags') if debug else None\n                random_index = choice(qids_from_suggested_tags)\n                q = questions.loc[random_index]\n                recommendations = recommendations.append(q)\n                qids_from_suggested_tags.remove(random_index)\n            else:\n                # no more questions from the pool\n                pass\n\n    # Hot Start\n    else:\n        \n        questions_answered_ids = list(pros_answers['question_id'].unique())\n        questions_answered = questions[questions.index.isin(questions_answered_ids)].sort_values('date_added', ascending=False)\n        questions_answered_locs = []\n        for qid in questions_answered_ids:\n            questions_answered_locs.append(questions.index.get_loc(qid))\n\n        print('Hot, Answered Questions: ', cnt_pro_answers)  if not silent else None\n        #print(questions_answered_locs)\n        display(questions_answered[['date_added', 'title', 'body', 'count_answers']])  if not silent else None\n        \n        # calculate answered questions scores\n        q_scores = {}\n        for i, q in questions_answered.iterrows():\n            answer_post_date = pros_answers[pros_answers['question_id'] == i]['date_added'].values[0]\n            days_elapsed_after_answer = (today - answer_post_date)/np.timedelta64(1, 'D')\n            q_scores[i] = calculate_score_question_answered(days_elapsed_after_answer)\n        print('Question-Scores: ', q_scores) if debug else None\n\n        # calculate exploit_threshold\n        exploit_threshold = calculate_exploit_threshold(list(q_scores.values()), nbr_recommendations, alpha=alpha)\n        print('Exploit Threshold:', exploit_threshold) if debug else None\n        except_qs = []\n        except_qs += questions_answered_ids\n        for i in range(nbr_recommendations):\n\n            if np.random.rand() < exploit_threshold:\n                # Exploit\n                random_q_score = choose_random_answered_question(q_scores)\n                print('\\nExploit Question', random_q_score) if debug else None\n                recommendations = recommendations.append(get_similar_questions(random_q_score[0], nbr_questions=1, except_questions_ids=except_qs, prioritize=True))\n            else:\n                # Explore\n                \n                # Get Latest n questions from all followed tags\n                n = 5\n                latest_questions = pd.DataFrame([])\n                for tid in tags_followed.index.values:\n                    qids = tag_questions[tag_questions['tag_id'] == tid]['question_id'].values\n                    tag_qs = questions[questions.index.isin(qids)]\n                    tag_qs = tag_qs[~tag_qs.index.isin(except_qs)]\n                    if len(tag_qs) > 0:\n                        tag_qs = tag_qs.sort_values('date_added', ascending=False)\n                        latest_questions = latest_questions.append(tag_qs.head(n))\n                #display(latest_questions)\n                \n                # Select the most similar one to the ones answered using the similarity matrix\n                best_question_id = 0\n                best_distance = float('-inf')\n                for qid, r in latest_questions.iterrows():\n                    qloc = questions.index.get_loc(qid)\n                    for aqloc in questions_answered_locs:\n                        d = Qs_sim_matrix[qloc, aqloc]\n                        if best_question_id == 0 or d > best_distance:\n                            best_question_id = qid\n                            best_distance = d\n\n                print('\\nExplore Tags', best_question_id, best_distance) if debug else None\n                if best_question_id != 0:\n                    recommendations = recommendations.append(questions.loc[best_question_id])\n            except_qs = list(recommendations.index.values)\n            except_qs += questions_answered_ids\n\n    return recommendations","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing the recommender Part 1: standard random cases\n\nHere I'll let the recommender run on two randomly chosen professionals ( cold & Hot ).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Hot Professional\nrandom_hot_pro_id = professionals[(professionals['count_answers'] > 2) & (professionals['count_answers'] < 5)].sample(1).index.values[0]\n\n# Random Cold Professional ( check if he follows some tag )\nrandom_cold_pro_id = professionals[(professionals['count_answers'] == 0) & (professionals['follow_tags'] == True)].sample(1).index.values[0]\n\n\n#for random_pro_id in [random_hot_pro_id, random_cold_pro_id]:\nfor random_pro_id in [random_hot_pro_id, random_cold_pro_id]:\n    recs = recommend_questions_to_professional(random_pro_id, nbr_recommendations=10)\n    print('Recommendations: ')\n    display(recs[['date_added', 'title', 'body', 'count_answers']]) if len(recs) > 0 else None","execution_count":17,"outputs":[{"output_type":"stream","text":"Professional ID: 8aef158c449549f0bc4627cabedbe2e4\nFollowed Tags:  ['medicine' 'healthcare' 'higher-education' 'pharmacy' 'pharmacist'\n 'health,-wellness-and-fitness' 'lifesciences' 'pharmacy-school']\nCold 0\nSuggested Tags:  ['pharmacists' 'life-sciences' 'health-care' '#healthcare'\n 'health-wellness-and-fitness' 'highereducation' '#highereducation'\n '#medicine' '#pharmacist' '#pharmacy' 'pharmacy-' '#pharmacyschool']\nRecommendations: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                                          date_added      ...      count_answers\n0ebf80a07386418ba64a151d1541cfd4 2018-01-17 00:41:05      ...                1.0\n8d255acf4e5f426dbf058f9135b0607e 2018-06-30 22:01:07      ...                2.0\n29b043dd61f14ec6861aebf10eac88f5 2019-01-10 18:35:23      ...                1.0\n70f79946ec2f44e19b3c98dca8548cb4 2018-08-23 10:58:04      ...                0.0\ndb702a186d7041a5becd23ea7672dd29 2018-12-12 15:52:37      ...                1.0\nd459c19a5cfa4798b49df817e1142cb2 2018-06-20 18:45:49      ...                1.0\nd2e7869caf494b5e9722e5ec35bff99b 2018-01-20 02:00:57      ...                2.0\nbfd1a8c05104425c8b18626f1b0bae68 2018-03-31 00:33:36      ...                3.0\nc6c16f532ab54984a4c231188acd89fe 2018-10-26 23:44:23      ...                1.0\nee191ebc06bb4106b75a63c5e6113398 2018-03-13 16:18:51      ...                0.0\n\n[10 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_added</th>\n      <th>title</th>\n      <th>body</th>\n      <th>count_answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0ebf80a07386418ba64a151d1541cfd4</th>\n      <td>2018-01-17 00:41:05</td>\n      <td>What are the most important qualities to have to be a successful flight nurse?</td>\n      <td>I have found a strong passion for flight nursing and what to know if I would be a good fit for the career before the 3-5 years of training and classes. #flight-nurse #nursing #healthcare #hospital...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8d255acf4e5f426dbf058f9135b0607e</th>\n      <td>2018-06-30 22:01:07</td>\n      <td>What classes should I take to become a maternity nurse?</td>\n      <td>Are there specific minors that are needed or do you just get a BSN and apply for that job? #high-school-jobs  #collegecourses #nursing #nurse #medicine #college</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>29b043dd61f14ec6861aebf10eac88f5</th>\n      <td>2019-01-10 18:35:23</td>\n      <td>what are some good medical programs I can do while im still in high school?</td>\n      <td>#medical #medicine #medical-school #healthcare</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70f79946ec2f44e19b3c98dca8548cb4</th>\n      <td>2018-08-23 10:58:04</td>\n      <td>Is becoming any type of surgeon worth it in the end?</td>\n      <td>When I ask if it's worth it I mean is it worth it financially, mentally, etc. I've always been interested in the medical field but at the beginning of my junior year, my interest really sparked up...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>db702a186d7041a5becd23ea7672dd29</th>\n      <td>2018-12-12 15:52:37</td>\n      <td>Diagnostic mdical sonographer</td>\n      <td>How long does it take to become a Diagnostic medical Sonographer ? #healthcare #medical-school</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>d459c19a5cfa4798b49df817e1142cb2</th>\n      <td>2018-06-20 18:45:49</td>\n      <td>Best health science colleges?</td>\n      <td>I'm a CareerVillage staff member and I'm posting this because we know that many young people are looking for the answer to this question. This is among the most popular questions searched by youth...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>d2e7869caf494b5e9722e5ec35bff99b</th>\n      <td>2018-01-20 02:00:57</td>\n      <td>What is it like to teach English at the high school and college level?</td>\n      <td>My goal is to become an English teacher. I was planning on pursuing high school but someone suggested college. Since I haven't been to college yet I don't know what teachers are like there. Hearin...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>bfd1a8c05104425c8b18626f1b0bae68</th>\n      <td>2018-03-31 00:33:36</td>\n      <td>How am I going to pay off my college debt?</td>\n      <td>My parents are separated, and my mother is barely able to keep my family afloat. Many nights I've had to go to bed hungry because my mother simply couldn't afford to buy food. I work a part-time j...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>c6c16f532ab54984a4c231188acd89fe</th>\n      <td>2018-10-26 23:44:23</td>\n      <td>I do not have a lot of CNA experience, will I continue to get more exposure as a Nursing student and on the job as a Nurse?</td>\n      <td>#healthcare #nursing #nurse</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>ee191ebc06bb4106b75a63c5e6113398</th>\n      <td>2018-03-13 16:18:51</td>\n      <td>Can you really go to medical school for free in Cuba?</td>\n      <td>Read somewhere that you can. #medicine  #medical-school #med-school #cuba #tuition</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"Professional ID: e35e5f47db3941bf98870fa6bce2a814\nFollowed Tags:  ['telecommunications' '#business' '#career' '#college-major' '#management']\nCold 0\nSuggested Tags:  ['business' 'career' 'college-major' 'management' 'careers' 'business-'\n 'career-' '#careers' 'collegemajor' '#collegemajor' '#college_major'\n 'college-major-' '@management' 'management-' 'telecommunication'\n '#telecommunications']\nRecommendations: \n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                                          date_added      ...      count_answers\n5e98af14ee5d450ab9432017f1f5886d 2017-07-10 22:26:17      ...               11.0\n427b06841162456eae5fded841378ae5 2017-07-10 07:00:39      ...                4.0\n5e98af14ee5d450ab9432017f1f5886d 2017-07-10 22:26:17      ...               11.0\n0a1d9fec5b1f4f2dbda111a73f4f7cc8 2018-05-08 13:05:11      ...                5.0\n427b06841162456eae5fded841378ae5 2017-07-10 07:00:39      ...                4.0\n0a1d9fec5b1f4f2dbda111a73f4f7cc8 2018-05-08 13:05:11      ...                5.0\n\n[6 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_added</th>\n      <th>title</th>\n      <th>body</th>\n      <th>count_answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5e98af14ee5d450ab9432017f1f5886d</th>\n      <td>2017-07-10 22:26:17</td>\n      <td>If you were your own manager for one day, what would you change?</td>\n      <td>If you were in charge of the department you work in for one day, what would you do differently? Would it be something with the actual work you do, or the place you work in? \\r\\nThanks for your tim...</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>427b06841162456eae5fded841378ae5</th>\n      <td>2017-07-10 07:00:39</td>\n      <td>can someone with a Bs in renewable energy engineering or communications and informations engineering do a master in propulsion and become a propulsion engineer ?</td>\n      <td>hi , I'm going to college soon so i have to choose what major i'm going to study... I'm passionate about rockets and spacecrafts so i want to study aerospace engineering but the problem is that in...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>5e98af14ee5d450ab9432017f1f5886d</th>\n      <td>2017-07-10 22:26:17</td>\n      <td>If you were your own manager for one day, what would you change?</td>\n      <td>If you were in charge of the department you work in for one day, what would you do differently? Would it be something with the actual work you do, or the place you work in? \\r\\nThanks for your tim...</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>0a1d9fec5b1f4f2dbda111a73f4f7cc8</th>\n      <td>2018-05-08 13:05:11</td>\n      <td>Interniship Telecommute</td>\n      <td>Is it possible and how likely is it to get an IT paid internship working from #home in the network administration background if an individual has help desk experience? #internship #telecommunicati...</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>427b06841162456eae5fded841378ae5</th>\n      <td>2017-07-10 07:00:39</td>\n      <td>can someone with a Bs in renewable energy engineering or communications and informations engineering do a master in propulsion and become a propulsion engineer ?</td>\n      <td>hi , I'm going to college soon so i have to choose what major i'm going to study... I'm passionate about rockets and spacecrafts so i want to study aerospace engineering but the problem is that in...</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>0a1d9fec5b1f4f2dbda111a73f4f7cc8</th>\n      <td>2018-05-08 13:05:11</td>\n      <td>Interniship Telecommute</td>\n      <td>Is it possible and how likely is it to get an IT paid internship working from #home in the network administration background if an individual has help desk experience? #internship #telecommunicati...</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"* **Testing the recommender Part 2: Difficult Case **\n\nThis is the case of a professional who follows 'cooking' and 'computer-games', but has answered a question about 'journalism' and 'scholarships'. We can see that the system balances nicely between the topics."},{"metadata":{"trusted":true},"cell_type":"code","source":"random_hot_pro_id = 'fbd6566ddf36402abeb031c088096ae4'\nrecs = recommend_questions_to_professional(random_hot_pro_id, nbr_recommendations=10)\nprint('Recommendations:')\ndisplay(recs[['date_added', 'title', 'body', 'count_answers']])","execution_count":18,"outputs":[{"output_type":"stream","text":"Professional ID: fbd6566ddf36402abeb031c088096ae4\nFollowed Tags:  ['cooking' 'computer-games']\nHot, Answered Questions:  3\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                                          date_added      ...      count_answers\nquestions_id                                              ...                   \n83ee084ef5d546f5b16b66cf2b4acf6c 2015-09-17 17:46:08      ...                  4\nf6c5ae0b4f56488c9f7351b8b6c63f51 2015-08-19 20:45:27      ...                  3\n18f8485afa0e4f559197beb9ee0ca195 2015-08-18 12:59:25      ...                  8\n\n[3 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_added</th>\n      <th>title</th>\n      <th>body</th>\n      <th>count_answers</th>\n    </tr>\n    <tr>\n      <th>questions_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>83ee084ef5d546f5b16b66cf2b4acf6c</th>\n      <td>2015-09-17 17:46:08</td>\n      <td>Is being a newscaster hard?</td>\n      <td>I am thinking about becoming a newscaster for my career in life. #journalism #news #newscaster</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>f6c5ae0b4f56488c9f7351b8b6c63f51</th>\n      <td>2015-08-19 20:45:27</td>\n      <td>How do you get a full-ride scholarship to a university?</td>\n      <td>I'm a junior in highschool and I want to know how getting a scholarship works? #money</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>18f8485afa0e4f559197beb9ee0ca195</th>\n      <td>2015-08-18 12:59:25</td>\n      <td>How do i discover my passion?</td>\n      <td>I usually hear many people complaining of the kind of work they do, even saying they are only working just for a living and given an option, they will not even think twice, they will grab the new ...</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"Recommendations:\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"                                          date_added      ...      count_answers\n59184dc0d4b24f1fa92c3f07bce183a5 2019-01-26 00:56:16      ...                1.0\nbcfac02347ac472fa1356619eb4cba58 2018-01-22 17:09:05      ...                3.0\n2de48f91c8b34a95b250d99cf3f8d840 2018-10-17 23:57:46      ...                1.0\ne56dc76e23e64c00a64098fcbd52cd46 2018-10-14 04:09:48      ...                1.0\nc58d81a238df4c4f8429c183a78d0ff8 2018-10-24 00:38:37      ...                1.0\n6cea3ac361e2428283bf4ecee282dbcc 2018-10-22 01:39:30      ...                1.0\nc6e74071740d4cd69659082c0a9bf38a 2018-09-29 20:50:48      ...                1.0\n2664b927b60f4f839bf8cc6d60f989ca 2018-01-16 17:16:31      ...                1.0\n\n[8 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_added</th>\n      <th>title</th>\n      <th>body</th>\n      <th>count_answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59184dc0d4b24f1fa92c3f07bce183a5</th>\n      <td>2019-01-26 00:56:16</td>\n      <td>What is it like to really be a chef in a professional kitchen or even a bakery owner . What do you do daily ? Do you really enjoy what it is that your doing ? Have you ever had any regrets about c...</td>\n      <td>#chef #career #baker #advice #cooking</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>bcfac02347ac472fa1356619eb4cba58</th>\n      <td>2018-01-22 17:09:05</td>\n      <td>I want a career related to a video games. What do I major in?</td>\n      <td>I'm a junior in high school. I'm in my schools tech academy and i'm very unsure of my what I want to major in.I love video games and would want a job related to them. What are skills I need for vi...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2de48f91c8b34a95b250d99cf3f8d840</th>\n      <td>2018-10-17 23:57:46</td>\n      <td>What's the best scholarship website?</td>\n      <td>I am a mother going back to school and looking for the best scholarships #scholarship</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>e56dc76e23e64c00a64098fcbd52cd46</th>\n      <td>2018-10-14 04:09:48</td>\n      <td>How to find scholarships that are great?</td>\n      <td>Im searching for many scholarships its consuming most of my time. #scholarship</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>c58d81a238df4c4f8429c183a78d0ff8</th>\n      <td>2018-10-24 00:38:37</td>\n      <td>How can I be eligible for a scholarship?</td>\n      <td>#college #scholarship #money #financial-aid #help</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6cea3ac361e2428283bf4ecee282dbcc</th>\n      <td>2018-10-22 01:39:30</td>\n      <td>I am interested in journalism, are there a lot of opportunities for this major?</td>\n      <td>#journalism #college-major #college #professional #photojournalism</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>c6e74071740d4cd69659082c0a9bf38a</th>\n      <td>2018-09-29 20:50:48</td>\n      <td>What are the best things to include in a scholarship essay to give you a better chance at recieving the scholarship?</td>\n      <td>#scholarship #financial-aid #money #college</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2664b927b60f4f839bf8cc6d60f989ca</th>\n      <td>2018-01-16 17:16:31</td>\n      <td>What is the salary of a concept artist?</td>\n      <td>If working for a big(gish) game development company, how much money can you make as a concept artist or game designer? #computer-games #video-games</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 2- Question-to-Professionals mode:\n\nGiven a question, recommend the top K professionals to answer. This mode is used for the 'Immediate' professionals.\n\nThe overall approach taken is straightforward: recommend professionals who answered similar questions to the one given. \n\nThe 'Hot' professionals have the biggest probability to answer and are recommended, since a **key requirement of the recommender is to get a good quality answer as soon as possible.**\n\n\n### Is a professional active ?\nIt is important to know the answer to this question. Maybe the professional has answered numerous questions similar to the query but is no longer active on the platform ! So out of N candidates, we will select our k recommended ones based on their activity.\n\n\nHere, we select the top k candidates using two metrics:\n* How active they are: we determine this by using the 'last_answer_date' column, if the professional has answered a question in the last n days he gets priority (n = 60 by default in implementation) .\n* If the number candidates is still smaller than the required k, we add candidates based on the number of similar questions they answered even if they weren't active in the last n days. ( of course they have all answered similar questions, but in the first step, we prioritized the active ones, in the second step, which is optional, we fill in the missing places with professionals who answered most similar questions ). \n\nYou can check the small piece of code below: "},{"metadata":{"trusted":true},"cell_type":"code","source":"def recommend_professionals_for_question(qid, nbr_recommendations=10, inactivity_period=60):\n    #print(len(questions), len(answers))\n    similar_questions = get_similar_questions(qid, nbr_questions=10, except_questions_ids=[], prioritize=False)\n    #display(similar_questions)\n    answer_author_ids = answers[answers['question_id'].isin(similar_questions.index.values)]['author_id'].values\n    answer_author_ids = pd.Series(answer_author_ids).value_counts()\n    \n    # Step 1: Check how active the the candidates are\n    min_last_answer_date = today - np.timedelta64(inactivity_period, 'D')\n    candidates = professionals[(professionals.index.isin(answer_author_ids.index.values)) & (professionals['last_answer_date'] > min_last_answer_date)].sort_values('last_answer_date', ascending=False)\n    answer_author_ids = answer_author_ids.drop(candidates.index)\n    \n    # Step 2: if number of candidates is still smaller than nbr_recommendations, fill in with other authors based on how many similar questions they answered.\n    if len(candidates) < nbr_recommendations:\n        others = answer_author_ids.head(nbr_recommendations-len(candidates)).index.values\n        candidates = candidates.append(professionals[professionals.index.isin(others)])\n    return candidates[:nbr_recommendations]","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing the recommender"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_question_index = choice(questions.index.values)\n\nprint('Random Question: ', random_question_index,  questions.loc[random_question_index]['date_added'])\nprint(questions.loc[random_question_index]['title'])\nprint(questions.loc[random_question_index]['body'])\nrecommend_professionals_for_question(random_question_index, nbr_recommendations=8)[['location', 'industry', 'headline', 'count_answers', 'last_answer_date']]\n","execution_count":20,"outputs":[{"output_type":"stream","text":"Random Question:  44995e27fcf546da8eedf5fac6cf8f16 2018-01-26 18:27:55\nis it better to specialize your degree or remain general?\nwhat are the advantages and disadvantages, not sure on weather i should stick with one career to further advance in it , or remain general for change and more job opportunities?#indecisive #degree \n","name":"stdout"},{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"                                                            location         ...            last_answer_date\nprofessionals_id                                                             ...                            \n5fb15f468af546bbbf7861b0025b947d                  Nipomo, California         ...         2019-01-20 03:02:57\n58fa5e95fe9e480a9349bbb1d7faaddb  Redford Charter Township, Michigan         ...         2019-01-13 01:21:47\nb93aea656ec44f44a4fb6757d3a3345b                    Atlanta, Georgia         ...         2016-08-16 23:31:25\ncead073a47f548daa00cf477fc6687c8                           Singapore         ...         2016-05-03 01:40:20\n20569e00becc48fc82be8f9db9bd9035         Bengaluru, Karnataka, India         ...         2017-01-31 21:15:41\n704f599b85354ca4a79ca3847f585ec8                 Seattle, Washington         ...         2017-08-18 01:06:23\nd3fface68dba484292fd2357f1e6d5fc                Greater Chicago Area         ...         2018-05-02 21:29:16\na6d33c38902546849c36ea7e9e9f0870                       United States         ...         2018-06-10 15:04:14\n\n[8 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>industry</th>\n      <th>headline</th>\n      <th>count_answers</th>\n      <th>last_answer_date</th>\n    </tr>\n    <tr>\n      <th>professionals_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5fb15f468af546bbbf7861b0025b947d</th>\n      <td>Nipomo, California</td>\n      <td>Hospital and Health Care</td>\n      <td>principal at gravell insights, llc</td>\n      <td>78</td>\n      <td>2019-01-20 03:02:57</td>\n    </tr>\n    <tr>\n      <th>58fa5e95fe9e480a9349bbb1d7faaddb</th>\n      <td>Redford Charter Township, Michigan</td>\n      <td>Automotive</td>\n      <td>mechanical engineer i automotive</td>\n      <td>1112</td>\n      <td>2019-01-13 01:21:47</td>\n    </tr>\n    <tr>\n      <th>b93aea656ec44f44a4fb6757d3a3345b</th>\n      <td>Atlanta, Georgia</td>\n      <td>Marketing and Advertising</td>\n      <td>client development executive at odyssey logistics &amp; technology corporation</td>\n      <td>1</td>\n      <td>2016-08-16 23:31:25</td>\n    </tr>\n    <tr>\n      <th>cead073a47f548daa00cf477fc6687c8</th>\n      <td>Singapore</td>\n      <td>Information Technology and Services</td>\n      <td>president asia pacific &amp; japan region at symantec corporation</td>\n      <td>2</td>\n      <td>2016-05-03 01:40:20</td>\n    </tr>\n    <tr>\n      <th>20569e00becc48fc82be8f9db9bd9035</th>\n      <td>Bengaluru, Karnataka, India</td>\n      <td></td>\n      <td>dell international services india pvt. ltd.</td>\n      <td>33</td>\n      <td>2017-01-31 21:15:41</td>\n    </tr>\n    <tr>\n      <th>704f599b85354ca4a79ca3847f585ec8</th>\n      <td>Seattle, Washington</td>\n      <td></td>\n      <td>program manager</td>\n      <td>144</td>\n      <td>2017-08-18 01:06:23</td>\n    </tr>\n    <tr>\n      <th>d3fface68dba484292fd2357f1e6d5fc</th>\n      <td>Greater Chicago Area</td>\n      <td>Financial Services</td>\n      <td>management consulting associate at pwc</td>\n      <td>7</td>\n      <td>2018-05-02 21:29:16</td>\n    </tr>\n    <tr>\n      <th>a6d33c38902546849c36ea7e9e9f0870</th>\n      <td>United States</td>\n      <td>Career Counseling</td>\n      <td></td>\n      <td>259</td>\n      <td>2018-06-10 15:04:14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Helper functions in production:"},{"metadata":{},"cell_type":"markdown","source":"### Get Tag Suggestions for a new question:\nIt is very important to control tags, and use existing ones when possible. The following function suggests tags for a new question:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Analyze processed question and extracts implicit tags ( eg. 'computer science' => 'computerscience')\ndef get_tag_suggestions(q_p):\n    #q_p = preprocess_question(q)\n    #print(q_p)\n    q_tokens = nltk.word_tokenize(q_p)\n    q_tokens_cpy = q_tokens.copy()\n    \n    qp_tagged = nltk.pos_tag(q_tokens)\n    important = []\n    for t,pos in qp_tagged:\n        if t not in stop_words and pos == 'NN' and len(tags[tags['processed'] == t]) > 0 :\n            i = q_tokens.index(t)\n            #print(len(q_p), t, i)\n            poses_before_after = []\n            if i > 0:\n                poses_before_after.append(nltk.pos_tag([q_tokens[i-1]])[0])\n            if i < (len(q_tokens)-1):\n                poses_before_after.append(nltk.pos_tag([q_tokens[i+1]])[0])\n            for i, bf in enumerate(poses_before_after):\n                #print(t, bf)\n                if bf[1] in ['NN', 'NNS', 'JJ', 'JJR', 'VBG']:\n                    s = f'{t}{bf[0]}' if i == 1 else f'{bf[0]}{t}'\n                    important.append(s)\n            q_tokens.remove(t)\n    important = set(important)\n    for i in set(important):\n        if i not in tags['processed'].values or i in q_tokens_cpy:\n            important.remove(i)\n    #print(len(important),important)\n    \n    return tags[tags['processed'].isin(important)]","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Example: \n\nThe following example illustrates how many tags this question is related to."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_question = 'I am a student in computer science and I want to be a data scientist but I dont know how to study machine learning and artificial intelligence. Can anyone give some advice ?' \np_q = preprocess_question(new_question)\nsuggestions = get_tag_suggestions(p_q)\nprint('Question: ', new_question)\nprint('\\nTag Suggestions: ')\nsuggestions[['name']]","execution_count":22,"outputs":[{"output_type":"stream","text":"Question:  I am a student in computer science and I want to be a data scientist but I dont know how to study machine learning and artificial intelligence. Can anyone give some advice ?\n\nTag Suggestions: \n","name":"stdout"},{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"                                 name\ntags_tag_id                          \n461                  computer-science\n1846          artificial-intelligence\n29420                 computerscience\n18791                machine-learning\n29702                computer_science\n34595          artificialintelligence\n37542        #artificial-intelligence\n32065                #computerscience\n31605               #computer-science\n31759               computer-science-\n35849                #machinelearning\n31195               machine-learning-","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n    </tr>\n    <tr>\n      <th>tags_tag_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>461</th>\n      <td>computer-science</td>\n    </tr>\n    <tr>\n      <th>1846</th>\n      <td>artificial-intelligence</td>\n    </tr>\n    <tr>\n      <th>29420</th>\n      <td>computerscience</td>\n    </tr>\n    <tr>\n      <th>18791</th>\n      <td>machine-learning</td>\n    </tr>\n    <tr>\n      <th>29702</th>\n      <td>computer_science</td>\n    </tr>\n    <tr>\n      <th>34595</th>\n      <td>artificialintelligence</td>\n    </tr>\n    <tr>\n      <th>37542</th>\n      <td>#artificial-intelligence</td>\n    </tr>\n    <tr>\n      <th>32065</th>\n      <td>#computerscience</td>\n    </tr>\n    <tr>\n      <th>31605</th>\n      <td>#computer-science</td>\n    </tr>\n    <tr>\n      <th>31759</th>\n      <td>computer-science-</td>\n    </tr>\n    <tr>\n      <th>35849</th>\n      <td>#machinelearning</td>\n    </tr>\n    <tr>\n      <th>31195</th>\n      <td>machine-learning-</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Function to add a new question to DB:\n\nWhen a new question enters a DB, it should be converted and added to our model.\n* The following function transforms the new question to a vector and adds it to the matrix\n* adds an entry ( one row and one column ) to the similarity matrix"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Generate a random index for adding a question to DB\ndef gen_test_index():\n    length = np.random.randint(10,15)\n    letters_digits = string.ascii_lowercase + string.digits\n    return ''.join(random.sample(letters_digits, length))\n\n\ndef add_question_to_db(title, body):\n    global questions\n    global Qs_transformed\n    global Qs_sim_matrix\n    \n    q = title + ' ' + body\n    q_p = preprocess_question(q)\n    \n    tag_suggestions = get_tag_suggestions(q_p)\n    q_p = q_p + ' ' + ' '.join(tag_suggestions)\n    \n    print(q_p)  if debug else None\n    \n    author_id = 1 # special if for test ( doesn't exist in DB )\n    index = gen_test_index()\n    questions = questions.append(pd.Series({'author_id': author_id,'date_added': pd.to_datetime('now'), \n                                                  'title': title,\n                                                  'body': body, \n                                                  'processed': q_p, \n                                                  'count_answers': 0}, name=index))\n    print('Qs Transformed before', qs_transformed.shape) if debug else None\n    q_transformed = transformer_model.transform(tfidf_vectorizer.transform([q_p]))\n    Qs_transformed = np.append(Qs_transformed, [Qs_transformed[0]], axis=0)\n    print('Qs Transformed after', Qs_transformed.shape)  if debug else None\n    \n    sim_mat_shape = Qs_sim_matrix.shape\n    print('Similarity Matrix shape before', sim_mat_shape)  if debug else None\n    new_sims = cosine_similarity(Qs_transformed[-1].reshape(1,-1),Qs_transformed)[0]\n    print('new_sims', new_sims.shape)  if debug else None\n    Qs_sim_matrix = np.hstack((Qs_sim_matrix, np.zeros((sim_mat_shape[0], 1))))\n    Qs_sim_matrix = np.vstack((Qs_sim_matrix, np.zeros((sim_mat_shape[0]+1))))\n    Qs_sim_matrix[-1] = new_sims\n    Qs_sim_matrix[:, -1] = new_sims\n    print('Similarity Matrix shape before', sim_mat_shape)  if debug else None\n    print('Question Added to DB.')  if debug else None\n    return index\n","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the Recommender System using a Time Machine ! <a class=\"anchor\" id=\"eval\"></a>\n\nRecommender Systems are trickier to evaluate than - for example - a machine learning classifier. The reason is that the current recommender system influences the data that we have at hand ( that we are using for training and testing ).\n\nHowever, we can still get a idea about the performance of the model we're testing if we choose the good metrics and methodology for our project.\n\n\nWe can distinguish between two types of evaluation: **Offline & Online Evaluation**.\n\n*The Offline Evaluation* is used before deploying the model, to check its accuracy on the existing data. However, this method is **NOT** enough.\nUsually, only it's only after the model is deployed, and A/B tests are that we can draw conclusions about the actual performance of our system. This second step is referred to as *Online Evaluation*\n\n<span style=\"color: purple\">Another important thing about having a fixed offline evaluation framework, even though it's not accurate, is that we can use it as basis evaluate multiple recommender systems, or to fine-tune parameters related to our model, and observe how the results change ( before pushing the changes to prod ) .</span>\n\n\n\n\n## Methodology\n\nFor offline evaluation, I chose to use a real-world **Split Validation** method. It works as follows:\n\n* First, I extract a small amount of data ( the most recent ) for example the last 6 months (let's say October 2018 ~ November 2018), this will be the **Test Set**\n* The model is built using only the other part of the data ( the oldest ), this is the **Traning Set** .\n* Edit all data so that we can simulate exactly how the system was at that particular point in time : questions, answers and professionals that were added after the date ( July 2018 ) are removed.\n\nNow that the system looks exactly as  it was (let's say at October 2018), the tests occur weekly:\n- Each week, new questions, answers and professionals are added. \n- **Hide all answers that occured that week from the recommender.**\n- The recommender system makes predictions about:\n    * **the professionals who answered the questions: Given that a question \"Q\" was answered this week, use Question-to-Professionals mode and see if the recommendations generated for this question contain the professionals who actually answered the question. ( do that for all questions answered this week and each week of the test period )**\n    * **the questions that were answered by the professionals: Given that a professional \"P\" answered some question(s), use Professional-to-Questions mode and see if the recommendations generated for that professional contain the questions that the professional actually answered. ( do that for all professionals who posted answers this week and each week of the test period )**\n- The goal is to make as many accurate recommendations as possible. Meaning, send recommendations to professionals who actually answered the questions that week, or recommend the answered questions to the right professionals.\n- Note here, that the recommender can perform much better in production, because when evaluating it here, we don't account for potential answers coming as a result of the recommender itself.\n- The test system makes the following assumption: **if the model made accurate offline recommendations about the answered questions, it would do so for the unanswered ones in production.**\n\n\nThe following code snippet builds our *\"Time Machine\"* :"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Backup\nquestions_full = questions.copy()\nanswers_full = answers.copy()\nprofessionals_full = professionals.copy()\ntag_users_full = tag_users.copy()\ntag_questions_full = tag_questions.copy()\n\ndef run_time_machine(today_str):\n    global today\n    global min_date_for_questions\n    global min_date_for_answers\n    global professionals\n    global questions\n    global answers\n    global tag_users\n    global tag_questions\n    global tfidf_vectorizer\n    global transformer_model\n    global Qs_transformed\n    global Qs_sim_matrix\n\n    \n    first_date = pd.to_datetime('2012-01-01') \n\n    today, min_date_for_questions, min_date_for_answers = set_today(today_str)\n    print('Running Time Machine ....', 'Going to', today.strftime('%B %d %Y'), '................\\n')\n\n    professionals = professionals_full[professionals_full['date_joined'] < today].copy()\n    assert (professionals['date_joined'].max() < today), \"Professionals have date_joined > today !\"\n    questions = questions_full[(questions_full['date_added'] > first_date) & (questions_full['date_added'] < today)].copy()\n    answers = answers_full[(answers_full['date_added'] > first_date) & (answers_full['date_added'] < today) & (answers_full['question_id'].isin(questions.index.values))].copy()\n\n    #test_questions = questions_full[(questions_full['date_added'] > today) & (questions_full['count_answers'] > 0)].copy()\n    #test_answers   = answers_full[(answers_full['question_id'].isin(test_questions.index.values)) & (answers_full['author_id'].isin(professionals.index.values))].copy()\n    #print(len(test_questions), 'Test questions (with at least one answer)')\n    #print(len(test_answers), 'Answers were posted for the test questions (from professionals who joined before that date)')\n\n    cnt_answers = answers.groupby('question_id').count()[['body']].rename(columns={'body': 'count_answers'})\n    questions = questions.drop('count_answers', axis=1)\n    questions = questions.join(cnt_answers)\n    questions['count_answers'] = questions['count_answers'].fillna(0)\n    questions['count_answers'] = questions['count_answers'].astype(int)\n\n\n    cnt_answers = answers.groupby('author_id').count()[['question_id']].rename(columns={'question_id': 'count_answers'})\n    professionals = professionals.drop('count_answers', axis=1)\n    professionals = professionals.join(cnt_answers)\n    professionals['count_answers'] = professionals['count_answers'].fillna(0)\n    professionals['count_answers'] = professionals['count_answers'].astype(int)\n\n    # Create Last Answer Date Column\n    professionals = professionals.drop('last_answer_date', axis=1)\n    professionals = professionals.join(answers[['author_id', 'date_added']].groupby('author_id').max().rename(columns={'date_added': 'last_answer_date'}))\n\n\n    tag_users = tag_users_full[tag_users_full['user_id'].isin(professionals.index.values)].copy()\n    tag_questions = tag_questions_full[tag_questions_full['question_id'].isin(questions.index.values)].copy()\n\n    transformer_model, Qs_transformed, Qs_sim_matrix = build_model(questions)\n    gc.collect()\n    print('##################################\\n')","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Running this *\"Time Machine\"* is slow. This is because to simulate the exact state of the system at a particular date (each week) I rebuild the model each time ( I tried adding just what changed, but it was not better ). I chose a relatively short period for the test ( 2018-08-01 ~ 2018-08-22 ).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Start Date and End Date of the Simulation\n\ntest_start_date = pd.to_datetime('2018-08-01')\ntest_end_date = pd.to_datetime('2018-08-22')\nnbr_weeks = math.floor((test_end_date - test_start_date)/ np.timedelta64(1, 'W'))\n","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameters of the model:\n\nWe can fine-tune the following parameters:\n* **Number of recommendations to generate each time**: 5 for Professional -> Questions Mode and 10 for Question -> Professionals Mode\n* **Number of days without answers to consider a professional not active ( for selection of professionals to answer a question )**: 60 days\n* **Exploitation Intensity ($\\alpha$)**: 1.35"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Number of recommendations to generate for each professional. ( for the other mode, Question->Professional, it's nbr_recs*2)\nnbr_recs_pro_to_qs = 5\nnbr_recs_q_to_pros = nbr_recs_pro_to_qs * 2\n\n# Exploitation Intensity ( 1.0 ~ 1.7 )\nalpha_arg=1.35\n\n# Number of days to consider professional as inactive\ninactivity_period_arg=60","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"## %%time\n\nprint('Start First Simulation', test_start_date.strftime('%B %d, %Y'), '--->', test_end_date.strftime('%B %d, %Y'), '(', nbr_weeks, ' weeks )', '\\n')\nstart = time.time()\n#run_time_machine(test_start_date.strftime('%Y-%m-%d'))\n\n\nquestion_to_pros_recs = {}\npro_to_questions_recs = {}\n\nnbr_accurate_q_to_pros = 0\nnbr_accurate_pro_to_qs = 0\nnbr_all_q_to_pros = 0\nnbr_all_pro_to_qs = 0\n\n\ncorrect_question_ids = set([])\nall_question_ids = set([])\n\ntoday = test_start_date\nfor i in range(1, nbr_weeks+1):\n    print('\\n----------- ', 'Week', i, ' -----------')\n    d_old = today\n    run_time_machine((today + np.timedelta64(1, 'W')).strftime('%Y-%m-%d'))\n\n    week_questions= questions[(questions['date_added'] > d_old) & (questions['date_added'] < today)]\n    week_answers = answers[(answers['date_added'] > d_old) & (answers['date_added'] < today) & (answers['author_id'].isin(professionals.index.values))].copy()\n    \n    if len(week_answers) == 0:\n        continue\n    \n    target_questions = week_questions[week_questions.index.isin(week_answers)]\n    qs_answered_this_week = list(week_answers['question_id'].unique())\n    authors_this_week = week_answers['author_id'].unique()\n    all_question_ids.update(qs_answered_this_week)\n\n    print( d_old, ' ~ ', today, ' - Number of answers: ', len(week_answers), ' - Number answered questions: ', len(qs_answered_this_week), ' - Number authors: ', len(authors_this_week))\n    \n    # Hide answers from the system !!!\n    answers = answers.drop(week_answers.index)\n    for auth_id in authors_this_week:\n        professionals.at[auth_id, 'count_answers'] = len(answers[answers['author_id'] == auth_id])\n\n    # some tests to check if everything is ok\n    assert (len(answers[(answers['date_added'] < today) & (answers['date_added'] > d_old) & (answers['author_id'].isin(professionals.index.values)) ]) == 0), \"The answers of this week were not all removed\"\n    random_auth_id = authors_this_week[0]\n    assert (professionals.loc[random_auth_id, 'count_answers'] == len(answers[answers['author_id'] == random_auth_id])), \"Problem with count of answers for professional\"\n\n    print('Making Predictions for the week\\'s answered questions ...')\n    # Predict pros for questions that were answered ( Question->Pros )\n    for qid in qs_answered_this_week:\n        question_to_pros_recs[qid] = recommend_professionals_for_question(qid, nbr_recommendations=nbr_recs_q_to_pros, inactivity_period=inactivity_period_arg)\n        recommended_pro_ids = set(question_to_pros_recs[qid].index.values)\n        nbr_all_q_to_pros += len(recommended_pro_ids)\n        target_pro_ids = set(week_answers[week_answers['question_id'] == qid]['author_id'].unique())\n        union_len = len(target_pro_ids.union(recommended_pro_ids))\n        sum_len = len(recommended_pro_ids) + len(target_pro_ids)\n        if union_len < sum_len:\n            nbr_accurate_q_to_pros += (sum_len - union_len)\n            correct_question_ids.update([qid])\n            \n    # Predict questions for pros who answered ( Pro->Questions )\n    for auth_id in authors_this_week:\n        pro_to_questions_recs[auth_id] = recommend_questions_to_professional(auth_id, nbr_recommendations=nbr_recs_pro_to_qs, silent=True, alpha=alpha_arg)\n        recommended_question_ids = set(pro_to_questions_recs[auth_id].index.values)\n        nbr_all_pro_to_qs += len(recommended_question_ids)\n        target_question_ids = set(week_answers[week_answers['author_id'] == auth_id]['question_id'].unique())\n        union_len = len(target_question_ids.union(recommended_question_ids))\n        sum_len = len(recommended_question_ids) + len(target_question_ids)\n        if union_len < sum_len:\n            nbr_accurate_pro_to_qs += (sum_len - union_len)\n            correct_question_ids.update([e for e in recommended_question_ids if e in target_question_ids])\n    \n    #print('Number of Accurate Recommendations (Question -> Pros): ', nbr_accurate_q_to_pros)\n    #print('Number of Accurate Recommendations (Pro -> Questions): ', nbr_accurate_pro_to_qs)\n\nend = time.time()\nprint(f'\\n-------- End of Simulation ({(end-start)/60:.2f} minutes) --------')","execution_count":27,"outputs":[{"output_type":"stream","text":"Start First Simulation August 01, 2018 ---> August 22, 2018 ( 3  weeks ) \n\n\n-----------  Week 1  -----------\nRunning Time Machine .... Going to August 08 2018 ................\n\nBuilding the Model ...\n (1/3) TF-IDF matrix shape:  (21304, 17795)\n (2/3) Shape after Dimensionality Reduction: (21304, 1100)\n (3/3) Similarity Matrix Shape (21304, 21304) \n\n##################################\n\n2018-08-01 00:00:00  ~  2018-08-08 00:00:00  - Number of answers:  276  - Number answered questions:  248  - Number authors:  123\nMaking Predictions for the week's answered questions ...\n\n-----------  Week 2  -----------\nRunning Time Machine .... Going to August 15 2018 ................\n\nBuilding the Model ...\n (1/3) TF-IDF matrix shape:  (21572, 17894)\n (2/3) Shape after Dimensionality Reduction: (21572, 1100)\n (3/3) Similarity Matrix Shape (21572, 21572) \n\n##################################\n\n2018-08-08 00:00:00  ~  2018-08-15 00:00:00  - Number of answers:  477  - Number answered questions:  384  - Number authors:  193\nMaking Predictions for the week's answered questions ...\n\n-----------  Week 3  -----------\nRunning Time Machine .... Going to August 22 2018 ................\n\nBuilding the Model ...\n (1/3) TF-IDF matrix shape:  (21952, 18054)\n (2/3) Shape after Dimensionality Reduction: (21952, 1100)\n (3/3) Similarity Matrix Shape (21952, 21952) \n\n##################################\n\n2018-08-15 00:00:00  ~  2018-08-22 00:00:00  - Number of answers:  758  - Number answered questions:  577  - Number authors:  258\nMaking Predictions for the week's answered questions ...\n\n-------- End of Simulation (4.98 minutes) --------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Metrics & Results of the Evaluation\n\n\nTwo principal metrics are used:\n* **Proportion of answered questions got right**: meaning, out of all the questions that were answered, how many of them did we get right when making recommendations\n* **Proportion of accurate recommendations**: out of all recommendations made, how many did we get right\n\nNow, the proposed recommender system is compared to the legacy-one. Let's check the same metrics for recommendations made by the previous legacy-system in the same test period.\n\n*<span style=\"color: red;\">REMINDER:</span>* **This evaluation is actually not fair !** Because as mentioned before, the legacy recommender is actually influencing the answers we have at hand. **But ouf of curiosity**, we want to check how many accurate recommendations the proposed system is able to make, even without being deployed ! This must be taken into consideration when looking at the following numbers.\n\nFurthermore, many answers are just the product of users visiting the site \"organically\", and not the product of any recommendations.\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Results of the Test:')\nprint(f\"- Percentage of Answered Questions that got accurate recommendations: {len(correct_question_ids)/len(all_question_ids)*100:.2f}%\", f'( {len(correct_question_ids)} out of {len(all_question_ids)} questions  )' )\nprint('\\n- Percentage of accurate recommendations ( out of all sent ones ):')\nprint(f'\\t- Question-to-Professionals Mode:  {(nbr_accurate_q_to_pros/nbr_all_q_to_pros)*100:.2f}% ',  f'( {nbr_accurate_q_to_pros} out of {nbr_all_q_to_pros} recommendations were accurate )')\nprint(f'\\t- Professional-to-Questions Mode: {(nbr_accurate_pro_to_qs/nbr_all_pro_to_qs)*100:.2f}% ', f'( {nbr_accurate_pro_to_qs} out of {nbr_all_pro_to_qs} recommendations were accurate )')\n","execution_count":28,"outputs":[{"output_type":"stream","text":"Results of the Test:\n- Percentage of Answered Questions that got accurate recommendations: 18.58% ( 212 out of 1141 questions  )\n\n- Percentage of accurate recommendations ( out of all sent ones ):\n\t- Question-to-Professionals Mode:  1.72%  ( 198 out of 11532 recommendations were accurate )\n\t- Professional-to-Questions Mode: 1.17%  ( 30 out of 2555 recommendations were accurate )\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## The only True Evaluation\n\nThe only True Evaluation is done **online** with **good A/B Tests**, and with **measuring the right metrics**. I list here some metrics that should be considered:\n* **Number of active professionals**: we decide that a professional is active at time t if he answered a question in the last n days ( n = 100 in implementation )\n* **Mean Time-to-First-Answer**: $\\frac{1}{nbr \\thinspace questions}\\sum_{q}^{questions}{nbr \\thinspace days \\thinspace between \\thinspace question \\thinspace q \\thinspace was \\thinspace posted \\thinspace and \\thinspace its \\thinspace first \\thinspace answer}$\n* **Number of accurate recommendations**\n* **Percentage of accurate recommendations**: Ratio $\\frac{Number \\thinspace of \\thinspace accurate \\thinspace recommendations}{Number \\thinspace of \\thinspace all \\thinspace recommendations}$. The higher the ratio, the better. It will also help avoid churning.\n\nRunning A/B Tests on the parameters of the model will help to find the best combination of values that maximizes the metrics."},{"metadata":{},"cell_type":"markdown","source":"# Summary and Future Explorations <a class=\"anchor\" id=\"future\"></a>\n\nThe proposed system's strengths are **its effectiveness, ease of implementation and ease of maintainance in production.**\nIt uses controlled randomness to encourage new users while keeping engaged professionals in the platform.\n\nThe proposed system is designed to be very **resilient** when it comes to difficult cases like professionals with **various interests**. In addition to recommending questions based on semantic similarity, the proposed system also recommends relevant questions from tags, and from **tags which are textually similar to the followed ones** (eg. 'computer-science' and 'computerscience', 'information-technology' and 'informationtechnology' ) .\n\nFurther, a basic framework for evaluating the system was proposed along with the most important metrics to measure.\n\nSome recommendations for future improvements:\n\n* **Meta-data based Recommendations:** \n\nIt is possible to use valuable information obtained when users open a browsing session ( viewed and visited questions, ... ).\n\n* **Controlling Tags:**\n\nIt is important to preprocess tags and prevent the students from using tags which already exist. A powerful model possibly based on Word2Vec, could be used to model the relationships and similarities between tags. For example, capturing the similarity between 'information-technology' and 'IT' would hugely boost the performance of the recommender.\n\n* **Controlling Typos**:\n\nUsing a spell-checking engine like [Hunspell](https://pypi.org/project/hunspell/) would increase the quality of the data and help the engine make better recommendations\n\n* **Using the answers and comments in the model**:\n\nIn this model, only the text of the questions was used when encoding the questions. Another model should be explored, where we also make use of the answers and comments of each question to encode the questions.\n\n* **Making use of upvotes**:\n\nUnfortunately, The data provided about upvotes (questions & answers) wasn't specific as to who upvoted what. If this data was available, it could be used to better understand the interests of both professionals and students, and thus making better predictions.\n\n* **Using other Exploration Techniques**:\n\nI decided to go with the $\\epsilon$ Greedy Algorithm for its simpleness and ease of use. Other algorithms can be further explored like \"Optismism in face of uncertainty\" and \"Probability Matching\" ([See Links for more](#links))\n\n* **Making use of serious Reinforcement Learning**\n\nFinally, after exploring the previous suggestions, a very insteresting project would be to to make use of RL techniques, where the recommender uses the feedback of its actions (recommendations) to update and improve its future behaviour (recommendations). [See Links for more](#links)"},{"metadata":{},"cell_type":"markdown","source":"<h4>I hope that this Kernel was useful, and see you in the <a href=\"https://www.kaggle.com/hamzael1/kernels\" target=\"_blank\">next one</a> !</h4>\n\n*PS: upvotes & feedback are welcome !*\n"},{"metadata":{},"cell_type":"markdown","source":"# Links to useful Ressources: <a class=\"anchor\" id=\"links\"></a>\n<h4>About Recommender systems</h4>\n* [A whole Coursera Specialization about Recommender Systems](https://www.coursera.org/specializations/recommender-systems)\n* [Recommender Systems in Practice](https://towardsdatascience.com/recommender-systems-in-practice-cef9033bb23a)\n* [An amazing Playlist of Stanford University Videos about Mining Datasets](https://www.youtube.com/watch?v=1JRrCEgiyHM&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV&index=42&t=0s)\n\n<h4>About Epsilon Greedy and Exploration/Exploitation</h4>\n* [The Multi-armed Bandit Problem](https://en.wikipedia.org/wiki/Multi-armed_bandit)\n* [A nice article About Epsilon-Greedy Algorithm](https://imaddabbura.github.io/post/epsilon_greedy_algorithm/)\n* [Some great slides about how to solve the Exploration/Exploitation dilemma](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/XX.pdf)\n\n<h4>About Latent Semantic Analysis and SVD</h4>\n* [A nice short video about LSA](https://www.youtube.com/watch?v=OvzJiur55vo)\n* [A great explanation of SVD by Professor Jure Leskovec](https://www.youtube.com/watch?v=P5mlg91as1c&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV&index=47)\n\n<h4>About Reinforcement Learning in Recommender Systems</h4>\n* [Reinforcement Learning for Recommender Systems: A Case Study on Youtube](https://www.youtube.com/watch?v=HEqQ2_1XRTs)\n* [Contextualized Bandits for Recommendation Systems](https://towardsdatascience.com/bandits-for-recommender-system-optimization-1d702662346e)\n* [Netflix using using Contextualized Bandits for personalizing the selection of artwork](https://medium.com/netflix-techblog/artwork-personalization-c589f074ad76)\n* [A Multi-Armed Bandit Framework for Recommendations at Netflix](https://www.youtube.com/watch?v=kY-BCNHd_dM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}