{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Data Science Solution(KOR Ver)\n- This is written in Korean with reference to this link\n    - link : https://www.kaggle.com/startupsci/titanic-data-science-solutions/notebook\n\n**제가 NoteBook을 작성하게 된 계기는 처음 Kaggle에 접하시거나, DataScience가 무엇인지 한번 쯤 간단하게 접해보고 싶은 사람을 위해 작성하였습니다. 또한 Kaggle에 한글로 번역된 자료가 많이 없기에 작성한것도 있습니다. 처음 번역하여 NoteBook을 작성하였는데 오타 및 수정이 필요한 부분이 있을 수 있습니다. 발견하신 분들은 commit 남겨주시면 수정하도록 하겠습니다. 또한 좋게 봐주시는 분들이 있으면 추가적으로 매주 1회 정도 competition 한가지를 번역하여 정리해서 올릴려고 합니다. 이상 긴글 읽어주셔서 감사합니다.**\n","metadata":{}},{"cell_type":"markdown","source":"## 목차\n- 훈련, 테스트 데이터에 대한 습득(Acquire training and testing data)\n- 데이터 준비 및 다루기(Wrangle, prepare, cleanse the data)\n- 데이터 탐험, 패턴, 분석하기(Analyze, identify patterns, and explore the data.)\n- 모델 생성 및 문제 해결 및 예측(Model, predict and solve the problem.)\n- 문제 해결 단계와 최종 Solution, 시각화 (Visualize, report, and present the problem solving steps and final solution.)\n- 결과 제출(Supply or submit the results.)\n","metadata":{}},{"cell_type":"code","source":"# 데이터 분석 및 다루기(data analysis and wrangling)\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# 데이터 시각화(visualization)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# 머신러닝(machine learning)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:32:13.363546Z","iopub.execute_input":"2021-12-14T11:32:13.363933Z","iopub.status.idle":"2021-12-14T11:32:14.899757Z","shell.execute_reply.started":"2021-12-14T11:32:13.363832Z","shell.execute_reply":"2021-12-14T11:32:14.898818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset 가져오기\n- Pandas 패키지를 이용하여 dataset을 불러오겠습니다.\n    - Train, Test 데이터를 DataFrame 형태로 변환후, 데이터셋을 결합하여, 동시에 작업을 수행하겠습니다.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/titanic/train.csv')\ntest_df = pd.read_csv('../input/titanic/test.csv')\ncombine = [train_df , test_df]","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:32:14.901169Z","iopub.execute_input":"2021-12-14T11:32:14.901402Z","iopub.status.idle":"2021-12-14T11:32:14.937318Z","shell.execute_reply.started":"2021-12-14T11:32:14.901361Z","shell.execute_reply":"2021-12-14T11:32:14.93648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 어떠한 컬럼이 범주형 데이터인가?\n- 범주형 데이터 내에 명목,순서,비율,간격 기반의 범주형 데이터가 존재합니까?\n- 이러한 데이터들은 시각화에 도움을 주는 그래프를 선택하는 매우 도움이 됩니다.\n    - **Nominal : Survived, Sex, Embarked** \n    - **Ordinal : Pclass**   \n\n## 어떠한 컬럼이 수치형 데이터인가?\n- 수치형 데이터 내에 이산,연속,시계열에 기반인 데이터가 존재합니까?\n- 이러한 데이터들은 시각화에 도움을 주는 그래프를 선택하는 매우 도움이 됩니다.\n    - **Continous : Age, Fare** \n    - **Discete: SibSp, Parch**\n\n추가로 데이터의 특징에 대한 설명은 아래 Link를 참고하기 바랍니다.\n- link : https://blog.naver.com/qkrdnjsrl0628/222595486903","metadata":{}},{"cell_type":"code","source":"train_df.columns.values","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:50.534302Z","iopub.execute_input":"2021-12-14T11:33:50.535094Z","iopub.status.idle":"2021-12-14T11:33:50.543482Z","shell.execute_reply.started":"2021-12-14T11:33:50.535043Z","shell.execute_reply":"2021-12-14T11:33:50.542816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data에 대한 상세한 설명은 Titanic-data에 설명이 명시되어 있으니 확인해주시기 바랍니다.**","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:51.914084Z","iopub.execute_input":"2021-12-14T11:33:51.914343Z","iopub.status.idle":"2021-12-14T11:33:51.937085Z","shell.execute_reply.started":"2021-12-14T11:33:51.914315Z","shell.execute_reply":"2021-12-14T11:33:51.936513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 데이터 타입이 혼용된 컬럼은 어떤 것이 있습니까?\n- Ticket 데이터는 알파벳과 수치형데이터가 섞여 있으며, Cabin 데이터 또한 알파벳과 숫자 데이터가 섞여 있다.\n\n## 어떤 컬럼이 누락되어있거나 NULL 값을 가지고 있습니까?\n- 대규모 데이터에서는 다루기가 매우 어렵습니다. 하지만 몇가지 샘플을 확인하면 어떤 컬럼을 수정해야 하는지 바로 알 수 있다.\n\n- Name 데이터에는 대체 이름, 짧은 이름에 사용되는 따옴표를 포함하여 이름을 설명하는데 여러가지 방법이 있으므로, 오류나 오타가 포함되어 있을 수 있다.","metadata":{}},{"cell_type":"code","source":"train_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:54.567668Z","iopub.execute_input":"2021-12-14T11:33:54.568625Z","iopub.status.idle":"2021-12-14T11:33:54.584023Z","shell.execute_reply.started":"2021-12-14T11:33:54.568583Z","shell.execute_reply":"2021-12-14T11:33:54.583419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <strong>어떤 데이터가 누락 및 NUL을 포함하고 있습니까?</strong>\n- NULL값 및 누락 데이터는 수정될 필요가 있습니다.\n- 훈련 데이터 내에서는 Cabin > Age > Embarked 순으로 NULL 값 데이터가 존재합니다.\n- 테스트 데이터 내에는 Cabin > Age 순으로 NULl 값 데이터가 존재합니다.\n\n## <strong>데이터 타입의 개수가 어떻게 되나요?</strong>\n- 훈련 데이터에는 7개의 데이터들이 정수형 또는 실수형으로 이루어져 있으며, 테스트 데이터는 6개의 정수형 또는 실수형으로 이루어져 있다.\n- 5개의 데이터 타입은 object이다.","metadata":{}},{"cell_type":"code","source":"train_df.info()\nprint('_'*40)\ntest_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:56.633155Z","iopub.execute_input":"2021-12-14T11:33:56.634027Z","iopub.status.idle":"2021-12-14T11:33:56.66754Z","shell.execute_reply.started":"2021-12-14T11:33:56.633984Z","shell.execute_reply":"2021-12-14T11:33:56.666547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <strong>수치형 데이터의 분포가 어떻게 되나요?</strong>\n- <strong>수치형 데이터의 분포를 파악하는 것은 인사이트 를 얻는 것과 훈련데이터가 어떤 문제의 영역에 어떻게 직면하는 아는데 도움을 준다.<strong>\n    <br></br>\n    - 총 표본 데이터는 891개이다.\n    - 생존 데이터의 범주는 0, 1로 이루어져 있음을 알 수 있다.\n    - 생존을 나타내는 데이터가 38%임을 알 수 있다.\n    - 75% 이상이 부모 또는 자녀들과 여행을 가지 않았음을 알 수 있다.\n    - 승객의 30%정도는 형재 자매 및 배우자와 함께 타고 있음을 알 수 있다.\n    - 요금을 512달러까지 지불하는 승객들도 존재합니다.\n    - 65 - 80세 사이의 나이 많은 어르신분들이 대략 1%존재한다는 것을 알 수 있습니다.","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:57.223537Z","iopub.execute_input":"2021-12-14T11:33:57.223835Z","iopub.status.idle":"2021-12-14T11:33:57.260846Z","shell.execute_reply.started":"2021-12-14T11:33:57.2238Z","shell.execute_reply":"2021-12-14T11:33:57.260031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <strong>범주형 데이터는 어떻게 분포되어 있습니까?</strong>\n* 참고로 DataFrame.describe() 을 사용하면 수치형 데이터만을 알려주지만,&nbsp;\n  <strong>include = ['O'] 를 지정하면, 범주형 데이터를 알려준다.</strong>\n  \n  - Name 데이터는 유니크 데이터로 891개 존재한다.\n  - 성별의 65%는 남자임을 알 수 있다.\n  - Cabin 데이터 내에는 여러 데이터에 거쳐 중복항목이 존재한다. 몇몇 승객들은 선실을 공유하였습니다.\n  - Embarked 데이터에는 3가지 데이터가 존재한다. 대부분의 사람들이 S 라는 데이터를 가지고 있습니다.\n  \n  \n  ","metadata":{}},{"cell_type":"code","source":"train_df.describe(include = ['O'])\n# include 0으로 할 경우 문자열 데이터에 관한 통계를 알려준다.","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:57.793921Z","iopub.execute_input":"2021-12-14T11:33:57.79485Z","iopub.status.idle":"2021-12-14T11:33:57.818603Z","shell.execute_reply.started":"2021-12-14T11:33:57.794801Z","shell.execute_reply":"2021-12-14T11:33:57.81749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <strong>데이터 분석을 기반으로 한 가정</strong>\n- 데이터를 가지고 적절한 행동을 하기전 이러한 가정들을 검증할 것입니다.\n\n#### Correlating(상관 분석)\n- 나이와 생존간의 관계는 명확한 상관관계가 존재한다.\n- 생존 또는 또 다른 중요한 특징과 탑승지역과 관련지을 수도 있습니다.\n\n#### Correcting(정확성)\n- Ticket 데이터는 생존과 관계가 없을 뿐만 아니라, 22%의 데이터가 중복되므로 삭제하는 것이 좋습니다.\n- Cabin 데이터는 불완전하거나 많은 NULL값을 가지고 있기에 훈련 테스트 데이터에서 drop하는 것이 좋습니다.\n- PassengerID는 Survived와 관련이 없으므로, 삭제하는 것이 좋습니다.\n- Name 도 위와 동일합니다.\n\n#### Creating(제작)\n- Parch, Sibsp 기반으로 하여 가족의 총 수를 얻을 수 있습니다.\n- 새로운 특징을 추출하기 위해 Name 데이터를 다룰 수 있습니다.\n- Age 데이터를 가지고, 새로운 범주형 데이터를 만들수 있습니다.\n- Fare 또한 분석에 도움이 된다면 범주형으로 변경할 수 있습니다.\n\n\n#### Classifying(분류)\n- 문제의 설명을 기반으로 가정을 추가할 수 있습니다.\n- Wonme 는 생존할 가능성이 더 있습니다.\n- Age가 낮을수록 더욱 생존할 가능성이 존재합니다.\n- Pclass = 1 에 가까울수록 생존 할 가능성이 큽니다.","metadata":{}},{"cell_type":"markdown","source":"## <strong>Analyze by pivoting features</strong>\n\n- 몇몇 우리의 검증과 추정을 확증하기 위해, 특징을 pivot 함으로써 상관 관계를 신속하게 분석할 수 있습니다.\n- 이 단계는 공백의 데이터가 존재하지 않는 것에 한에서만 시행이 가능하다.\n- 데이터들을 pivoting 하는 것은 범주형 데이터나 이산형 데이터에 한해서만 시행하는 것이 좋다.\n\n    - Pclass : Pclass = 1 과 Survived 간의 상관관계가 있다는 것을 파악했으며, 모델의 특징에 포함하기로 한다.\n    - Sex : Female인 경우 생존률이 74% 이상임을 파악할 수 있습니다.\n    - SibSp and Parch : 값에 대하여 상관관계가 0이므로, 기능집합을 파생하는 것이 가장 좋다.\n    ","metadata":{}},{"cell_type":"code","source":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)\n# as_index 는 Pclass 를 그룹으로 한 것을 index화를 하는 것이냐, 안하는 것이냐를 지정하는 것이다.","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:58.262437Z","iopub.execute_input":"2021-12-14T11:33:58.263414Z","iopub.status.idle":"2021-12-14T11:33:58.281953Z","shell.execute_reply.started":"2021-12-14T11:33:58.263355Z","shell.execute_reply":"2021-12-14T11:33:58.281097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean().sort_values(by='Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:58.408173Z","iopub.execute_input":"2021-12-14T11:33:58.408607Z","iopub.status.idle":"2021-12-14T11:33:58.424047Z","shell.execute_reply.started":"2021-12-14T11:33:58.408566Z","shell.execute_reply":"2021-12-14T11:33:58.423194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:58.732126Z","iopub.execute_input":"2021-12-14T11:33:58.732427Z","iopub.status.idle":"2021-12-14T11:33:58.746917Z","shell.execute_reply.started":"2021-12-14T11:33:58.732391Z","shell.execute_reply":"2021-12-14T11:33:58.746019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['Parch', 'Survived']].groupby(['Parch'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:58.748741Z","iopub.execute_input":"2021-12-14T11:33:58.74933Z","iopub.status.idle":"2021-12-14T11:33:58.773068Z","shell.execute_reply.started":"2021-12-14T11:33:58.749284Z","shell.execute_reply":"2021-12-14T11:33:58.772457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <strong>데이터 시각화를 통한 분석</strong>\n- 분석한 데이터를 시각화 함으로써 우리의 몇몇 가정들을 검증해 나갈것입니다.\n## 수치형 데이터 관계성\n    - 수치형 데이터와 타겟데이터와의 관계를 이해해보려 하겠습니다.\n        - history chart 는 매우 유용하다. 연속적인 수치형 데이터의 유용한 패턴을 분석하는데 유용하다.\n        - histogram은 막대를 사용함으로써 데이터가 나타난 분포를 횟수를 그래프로 나타낸 것입니다.\n        - histogram 관련한 설명 링크 : https://sohyunwriter.tistory.com/142?category=892943\n        - histogram은 어릴수록 생존률이 높은지에 관하여 관련된 시각을 보여준다.\n        \n#### Observations\n- 4세 이하는 높은 생존률을 나타낸다.\n- 나이가 많을수록 생존률이 높다.\n- 15-25세 사이의 대부분은 생존하지 못하였다.\n- 대부분의 승객들은 15- 35세이다.\n\n#### Decisions\n- 이러한 간단한 분석은 차후 흐름에 대한 결정으로 우리의 가정을 확인한다.\n    - 모델에서 나이를 고려해야 함을 알 수 있다. (classifying 2)\n    - NULL 연령 기능을 처리해야 한다. (completing 1)\n    - 연령대별로 묶어야 함을 알 수 있다. (creating 3)\n      \n\n\n    ","metadata":{}},{"cell_type":"code","source":"# FaceGrid(참고) :  https://steadiness-193.tistory.com/201\ng = sns.FacetGrid(train_df, col = 'Survived')\ng.map(plt.hist, 'Age', bins = 20)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:58.948018Z","iopub.execute_input":"2021-12-14T11:33:58.948547Z","iopub.status.idle":"2021-12-14T11:33:59.501107Z","shell.execute_reply.started":"2021-12-14T11:33:58.948504Z","shell.execute_reply":"2021-12-14T11:33:59.500212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 수치형 데이터와 순서형 데이터 간의 상관관계\n- 단일 그래프를 사용함으로써 상관관계를 식별하기 위해 여러 기능을 결합할 수 있다.\n- 숫자 및 범주 기능으로써 사용할 수 있습니다.\n\n#### Observations\n- 대부분의 승객들은 Pclass = 3, 하지만 죽지는 않았다. (classifying 2)\n- Pclass = 2 or Pclass = 3 인 유아기의 아이들은 대부분 생존했다. (classifying 2)\n- Pclass = 1인 대부분의 승객들은 생존하였다. (classifying 3)\n- Pclass 는 승객의 연령에 따라 역할이 다름을 파악할 수 있다.\n\n#### Decisions\n- 모델을 학습할 때, Pclass를 고려할 수 있다.","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Pclass',hue = 'Survived')\ngrid.map(plt.hist, 'Age', alpha = .5, bins = 20)\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:33:59.502592Z","iopub.execute_input":"2021-12-14T11:33:59.50281Z","iopub.status.idle":"2021-12-14T11:34:00.537Z","shell.execute_reply.started":"2021-12-14T11:33:59.502784Z","shell.execute_reply":"2021-12-14T11:34:00.535993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass', size = 2.2, aspect = 1.6)\ngrid.map(plt.hist, 'Age', alpha =.5, bins = 20)\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:00.538499Z","iopub.execute_input":"2021-12-14T11:34:00.53888Z","iopub.status.idle":"2021-12-14T11:34:02.235945Z","shell.execute_reply.started":"2021-12-14T11:34:00.538835Z","shell.execute_reply":"2021-12-14T11:34:02.23508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 범주형 데이터 상관관계\n- Solution을 위해 범주형 데이터의 상관관계를 파악할 수 있다.\n\n## Observations.\n- 여성 승객은 남성보다는 높은 생존률을 지니고 있음을 알 수 있다.(classifying 1)\n- 남성이 더 높은 생존률을 보인 Embarked = C는 예외임을 알수 있고,Pclass와  Survived 관점에서 Pclass와 Embarked간의 상관관계가 있음을 알 수 있다. 단, Embarked 와 Survived는 직접적인 상관관계가 필수조건은 아님을 알 수 있다.\n- 남성의 경우 Pclass = 3 이 Pclass = 2 보다 생존률이 높음을 알 수 있다. (Completing 2)\n- Pclass = 3의 경우 특성이 매우 다양함을 알 수 있다. (Completing 1)\n\n## Decisions\n- 성별의 경우 모델을 학습시킬때 추가해야함을 알 수 있다.\n- 모델 학습을 완료한후 Embarked 특성을 추가한다.","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Embarked')\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette = 'deep')\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:02.237808Z","iopub.execute_input":"2021-12-14T11:34:02.23804Z","iopub.status.idle":"2021-12-14T11:34:03.644116Z","shell.execute_reply.started":"2021-12-14T11:34:02.23801Z","shell.execute_reply":"2021-12-14T11:34:03.643279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row = 'Embarked', size = 2.2, aspect = 1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette = 'deep')\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:03.645585Z","iopub.execute_input":"2021-12-14T11:34:03.645833Z","iopub.status.idle":"2021-12-14T11:34:04.927561Z","shell.execute_reply.started":"2021-12-14T11:34:03.645801Z","shell.execute_reply":"2021-12-14T11:34:04.926705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 범주형 데이터와 수치형 데이터의 상관관계\n- 범주형 데이터와 수치형 데이터의 상관관계를 파악해야 한다. 우리는 범주형 데이터인 Embarked, Sex, Survived와 수치형 데이터인 Fare를 비교할 수 있다.\n\n## Observations\n- 높은 요금을 지불한 사람들은 생존률이 높을 알 수 있다. (creating 4)\n- 승선항과 생존률간에 관계가 있음을 알 수 있다.\n\n## Decision\n- 요금을 범위별로 묶을 수 있다.\n","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row = 'Embarked', col = 'Survived', size = 2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha = .5, ci = None)\n# alpha 는 투명도(transparency)를 의미합니다.\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:04.928908Z","iopub.execute_input":"2021-12-14T11:34:04.92947Z","iopub.status.idle":"2021-12-14T11:34:05.948268Z","shell.execute_reply.started":"2021-12-14T11:34:04.929422Z","shell.execute_reply":"2021-12-14T11:34:05.947668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Embarked', hue = 'Survived',  palette={0: 'k', 1: 'w'})\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha = .5, ci = None)\n# alpha 는 투명도(transparency)를 의미합니다.\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:05.94918Z","iopub.execute_input":"2021-12-14T11:34:05.949756Z","iopub.status.idle":"2021-12-14T11:34:06.568223Z","shell.execute_reply.started":"2021-12-14T11:34:05.949722Z","shell.execute_reply":"2021-12-14T11:34:06.567301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 데이터 전처리(Preprocessing Data)\n- 본문에는 Wrangle Data라고 작성되어 있는데 데이터 전처리랑 비슷한 의미이다.\n- 참고 : https://bkshin.tistory.com/entry/DATA-23-Data-Wrangling\n\n- 데이터와 특정 솔루션과 관련하여 몇몇의 결정과 가정을 수집했다. 지금까지 값이나 기능을 변경할 필요가 없었다.지금부터는 문제를 해결하기 위해 데이터를 가공하면서 결정과 가정이 맞는지 파악해보겠습니다.\n\n## 데이터 삭제\n- 데이터를 삭제함으로써 더 적은 양의 데이터를 처리한다.\n- 우리의 추정과 결론을 기반으로 하여 우리는 Cabin 과 Ticket의 데이터 를 버릴 수 있다.\n- 일관성을 유지하기 위해서 훈련데이터와 테스트 데이터를 동시에 작업해줘야 한다.","metadata":{}},{"cell_type":"code","source":"print('Before', train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis = 1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis = 1)\ncombine = [train_df, test_df]\n\nprint('After', train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:06.569868Z","iopub.execute_input":"2021-12-14T11:34:06.570429Z","iopub.status.idle":"2021-12-14T11:34:06.581348Z","shell.execute_reply.started":"2021-12-14T11:34:06.570368Z","shell.execute_reply":"2021-12-14T11:34:06.580529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 존재하는 데이터로부터 새로운 데이터 추출하기\n- 만약 Name,Paseengerid 데이터를 삭제하기전에 Name 이름에서 성(Title)과 Survived간의 상관관계를   파악할 수 있도록 분석할 수 있습니다.\n- 정규표현식을 이용해서 추출할 수 있습니다.\n\n## Observation\n- 대부분의 성(Title)은 나이를 정확히 표현합니다. 예를들면 성(Title)이 Master인 사람은 평균적으로 5세 이하입니다\n- 성(Title)과 Age간의 생존관계는 서로 다릅니다.\n- 특정 성(Title)을 가진 사람은 사망했거나(Mme, Lady, Sir) 혹은 생존하였습니다.(Don, Rev, Jonkheer)\n\n## Decision\n- Model 훈련을 위해서 새로운 제목을 유지하기로 하였습니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand = False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:06.585047Z","iopub.execute_input":"2021-12-14T11:34:06.585259Z","iopub.status.idle":"2021-12-14T11:34:06.61898Z","shell.execute_reply.started":"2021-12-14T11:34:06.585233Z","shell.execute_reply":"2021-12-14T11:34:06.618398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"많은것을 더 일반적인 Title으로 변경하거나 Rare로 분류할 것입니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')    \n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index = False).mean()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:06.619855Z","iopub.execute_input":"2021-12-14T11:34:06.620746Z","iopub.status.idle":"2021-12-14T11:34:06.64596Z","shell.execute_reply.started":"2021-12-14T11:34:06.620707Z","shell.execute_reply":"2021-12-14T11:34:06.644983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"범주형(categorical) 데이터인 title을 순서형(ordinal) 데이터로 변환할 것입니다.","metadata":{}},{"cell_type":"code","source":"title_mapping = {\"Mr\":1 , \"Miss\":2, \"Mrs\":3, \"Master\":4, \"Rare\":5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:06.647685Z","iopub.execute_input":"2021-12-14T11:34:06.647999Z","iopub.status.idle":"2021-12-14T11:34:06.669075Z","shell.execute_reply.started":"2021-12-14T11:34:06.647959Z","shell.execute_reply":"2021-12-14T11:34:06.667848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['Name', 'PassengerId'], axis = 1)\ntest_df = test_df.drop(['Name'], axis = 1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape ","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:06.670305Z","iopub.execute_input":"2021-12-14T11:34:06.670983Z","iopub.status.idle":"2021-12-14T11:34:06.680539Z","shell.execute_reply.started":"2021-12-14T11:34:06.670945Z","shell.execute_reply":"2021-12-14T11:34:06.679686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 범주형 데이터 변환\n- 문자형, 수치형 데이터를 변환할 수 있습니다. 대부분의 모델에서는 요구되는 사항입니다.\n- 먼저 female, male 데이터를 변환하겠습니다. female = 1, male = 0","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female' : 1, 'male' : 0}).astype(int)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:06.681745Z","iopub.execute_input":"2021-12-14T11:34:06.68198Z","iopub.status.idle":"2021-12-14T11:34:06.701122Z","shell.execute_reply.started":"2021-12-14T11:34:06.681951Z","shell.execute_reply":"2021-12-14T11:34:06.700432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 수치형 연속형 데이터 다루기\n- 공백이 있거나 NULL값을 가진 데이터를 다루는 것부터 시작하겠습니다. 먼저 Age Feature부터 다루겠습니다.\n- 3가지 방식으로 연속형 데이터를 다룰 수 있습니다.\n    - 간단한 방식으로는 평균과 표준편차 사이에서 난수를 생성하는 방식이 있습니다.\n    - 공백이 있는 데이터를 더 정확하게 추측하는 방법으로 다른 정확한 데이터를 사용하는 방식이 존재합니다. 나이, 성별, Pclass 사이의 관계를 주목하겠습니다. Pclass 와 Gender를 결합하여 Age 에서 mean을 찾음으로써 추측을 할 수 있습니다.\n    - 첫번째 방식과 두번째 방식을 결합하는 것이 좋다. 따라서 Age를 중앙값으로 추측하는 대신 Pclass 및 Gender 조합 집합을 기반으로 평균 및 표준편차 사이의 난수를 사용할 것입니다.\n    \n    - random은 노이즈를 도입할 수 있습니다. 하지만 실행 결과가 모두 다를 수 있으므로. 2번째 방법을 이용하겠습니다.\n    ","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row = 'Pclass', col = 'Sex')\ngrid.map(plt.hist, 'Age')\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:06.702337Z","iopub.execute_input":"2021-12-14T11:34:06.702639Z","iopub.status.idle":"2021-12-14T11:34:08.373665Z","shell.execute_reply.started":"2021-12-14T11:34:06.702608Z","shell.execute_reply":"2021-12-14T11:34:08.372592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"guess_ages = np.zeros((2, 3))\nguess_ages","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.374925Z","iopub.execute_input":"2021-12-14T11:34:08.375169Z","iopub.status.idle":"2021-12-14T11:34:08.381835Z","shell.execute_reply.started":"2021-12-14T11:34:08.375138Z","shell.execute_reply":"2021-12-14T11:34:08.38089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"지금부터 Sex(0 or 1) 그리고 Pclass(1, 2, 3)을 조합하여 6번의 반복으로 Age 데이터를 추측할 것입니다.","metadata":{"execution":{"iopub.status.busy":"2021-12-13T14:25:10.042719Z","iopub.execute_input":"2021-12-13T14:25:10.043056Z","iopub.status.idle":"2021-12-13T14:25:10.048683Z","shell.execute_reply.started":"2021-12-13T14:25:10.043019Z","shell.execute_reply":"2021-12-13T14:25:10.04765Z"}}},{"cell_type":"code","source":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n            \n            age_guess = guess_df.median()\n            \n            guess_ages[i,j] = int((age_guess/0.5) + 0.5)*0.5\n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1), 'Age'] = guess_ages[i, j]\n    \n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.383034Z","iopub.execute_input":"2021-12-14T11:34:08.383448Z","iopub.status.idle":"2021-12-14T11:34:08.430416Z","shell.execute_reply.started":"2021-12-14T11:34:08.383413Z","shell.execute_reply":"2021-12-14T11:34:08.429454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age 데이터를 Survived와 관련하여 묶어서 확인해보겠습니다","metadata":{}},{"cell_type":"code","source":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index = False).mean().sort_values(by = 'AgeBand', ascending = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.431552Z","iopub.execute_input":"2021-12-14T11:34:08.431944Z","iopub.status.idle":"2021-12-14T11:34:08.463732Z","shell.execute_reply.started":"2021-12-14T11:34:08.431906Z","shell.execute_reply":"2021-12-14T11:34:08.463115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.465526Z","iopub.execute_input":"2021-12-14T11:34:08.465848Z","iopub.status.idle":"2021-12-14T11:34:08.493362Z","shell.execute_reply.started":"2021-12-14T11:34:08.465805Z","shell.execute_reply":"2021-12-14T11:34:08.492492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['AgeBand'], axis = 1)\ncombine = [train_df, test_df]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.495148Z","iopub.execute_input":"2021-12-14T11:34:08.495482Z","iopub.status.idle":"2021-12-14T11:34:08.510341Z","shell.execute_reply.started":"2021-12-14T11:34:08.495435Z","shell.execute_reply":"2021-12-14T11:34:08.509668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 존재하는 Feature를 결합하여 새로운 Feature 만들기\n- 우리는 Parch, SibSp를 결합하여 식구(가족 총 인원 수)에 대한 새로운 Feature를 생성할 수 있습니다.\n- 그렇게 함으로써 Parch, SibSp데이터를 제거가 가능해집니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.511304Z","iopub.execute_input":"2021-12-14T11:34:08.51214Z","iopub.status.idle":"2021-12-14T11:34:08.537355Z","shell.execute_reply.started":"2021-12-14T11:34:08.512093Z","shell.execute_reply":"2021-12-14T11:34:08.536538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index = False).mean()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.539024Z","iopub.execute_input":"2021-12-14T11:34:08.539349Z","iopub.status.idle":"2021-12-14T11:34:08.557953Z","shell.execute_reply.started":"2021-12-14T11:34:08.539306Z","shell.execute_reply":"2021-12-14T11:34:08.556927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis = 1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis = 1)\n\ncombine = [train_df, test_df]\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.559853Z","iopub.execute_input":"2021-12-14T11:34:08.560169Z","iopub.status.idle":"2021-12-14T11:34:08.579839Z","shell.execute_reply.started":"2021-12-14T11:34:08.560125Z","shell.execute_reply":"2021-12-14T11:34:08.57873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pclass 와 Age 에 관한 데이터를 결합함으로써 새로운 Feature를 생성 수 있습니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.581318Z","iopub.execute_input":"2021-12-14T11:34:08.581831Z","iopub.status.idle":"2021-12-14T11:34:08.601913Z","shell.execute_reply.started":"2021-12-14T11:34:08.581787Z","shell.execute_reply":"2021-12-14T11:34:08.601229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 범주형 데이터 다루기\n- Embarked Feature 는 S, Q, C 데이터를 가지고 있습니다. 훈련데이터에는 2개의 누락값이 존재합니다. 단순히 가장 흔히 나온 데이터로 채우겠습니다.","metadata":{}},{"cell_type":"code","source":"# mode는 최빈값을 출력합니다. 참고 : https://www.geeksforgeeks.org/python-pandas-dataframe-mode/\nfreq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.605478Z","iopub.execute_input":"2021-12-14T11:34:08.605738Z","iopub.status.idle":"2021-12-14T11:34:08.612517Z","shell.execute_reply.started":"2021-12-14T11:34:08.605705Z","shell.execute_reply":"2021-12-14T11:34:08.611833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n\ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.613621Z","iopub.execute_input":"2021-12-14T11:34:08.614265Z","iopub.status.idle":"2021-12-14T11:34:08.638686Z","shell.execute_reply.started":"2021-12-14T11:34:08.614224Z","shell.execute_reply":"2021-12-14T11:34:08.637918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.640575Z","iopub.execute_input":"2021-12-14T11:34:08.6413Z","iopub.status.idle":"2021-12-14T11:34:08.662186Z","shell.execute_reply.started":"2021-12-14T11:34:08.64125Z","shell.execute_reply":"2021-12-14T11:34:08.661497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 수치형 데이터 다루기\n- 최빈값을 이용함으로써 Fare요금에 대하여 누락된 값을 다룰 수 있습니다. \n- 소수 두번째 자릿수로 반올림하여 실행하겠습니다.","metadata":{}},{"cell_type":"code","source":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace = True)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.664002Z","iopub.execute_input":"2021-12-14T11:34:08.664529Z","iopub.status.idle":"2021-12-14T11:34:08.678873Z","shell.execute_reply.started":"2021-12-14T11:34:08.664484Z","shell.execute_reply":"2021-12-14T11:34:08.678071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 참고 : https://steadiness-193.tistory.com/67\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index = False).mean().sort_values(by = 'FareBand', ascending = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.680106Z","iopub.execute_input":"2021-12-14T11:34:08.680575Z","iopub.status.idle":"2021-12-14T11:34:08.707924Z","shell.execute_reply.started":"2021-12-14T11:34:08.680536Z","shell.execute_reply":"2021-12-14T11:34:08.706985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"FareBand를 기반으로 Fare feature 를 변경합니다.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n    dataset.loc[dataset['Fare']>31 , 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis = 1)\ncombine = [train_df, test_df]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.709095Z","iopub.execute_input":"2021-12-14T11:34:08.709779Z","iopub.status.idle":"2021-12-14T11:34:08.735936Z","shell.execute_reply.started":"2021-12-14T11:34:08.709727Z","shell.execute_reply":"2021-12-14T11:34:08.735074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 예측 및 문제 해결하기\n- 60개 이상의 모델에서 선택을 할 수 있습니다.\n- 문제의 종류를 파악해서 문제에 적합한 모델로 해결해야 합니다.\n\n## 모델\n- Logistic Regression\n- KNN or K-Nearst Neigbors\n- Support Vector Machines\n- Navie Bayes classifier\n- Decision Tree\n- Random Forest\n- Perceptron\n- Artifical neural network\n- RVM or Relevance Vector Machine","metadata":{}},{"cell_type":"code","source":"X_train = train_df.drop('Survived', axis = 1)\nY_train = train_df['Survived']\nX_test = test_df.drop('PassengerId', axis = 1).copy()\nX_train.shape , Y_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.737296Z","iopub.execute_input":"2021-12-14T11:34:08.737757Z","iopub.status.idle":"2021-12-14T11:34:08.74902Z","shell.execute_reply.started":"2021-12-14T11:34:08.737719Z","shell.execute_reply":"2021-12-14T11:34:08.748225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logistic Regresson는 초기 작업흐름을 파악하는 유용한 모델입니다.\n- Logistic Regresson의 특징에 관해서는 아래의 링크를 참고해주시기 바랍니다.<br></br>\n  https://ko.wikipedia.org/wiki/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80 ","metadata":{}},{"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, Y_train)\nY_pred = log_reg.predict(X_test)\nacc_log = round(log_reg.score(X_train, Y_train) * 100 , 2)\n\nprint(acc_log)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.750069Z","iopub.execute_input":"2021-12-14T11:34:08.751134Z","iopub.status.idle":"2021-12-14T11:34:08.777428Z","shell.execute_reply.started":"2021-12-14T11:34:08.751083Z","shell.execute_reply":"2021-12-14T11:34:08.77678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"저희의 추정과가정을 검증하게 위해 Logistic Regression을 사용하였습니다. 결정계수를 활용한 특정 계수를 확인 하였습니다. Positive Coefficients increase 로그 승산을 증가 시키며, Negative Coefficients 는 로그 승산을 감소시킵니다.\n- Sex Feature의 경우 매우 높은 양의 승산임을 알 수 있다. Survived = 1 이기 대부분이기 때문이다.\n- Pclass가 증가할수록 Survived 1일 확률이 매우 감소한다는 것을 알 수 있다.\n- Age*Class 는 Survived 와 음의 상관관계가 두번째로 높기에 modeling 하기에 매우 좋습니다.\n- Title 은 두번째로 양의 승산임을 알 수 있습니다.","metadata":{}},{"cell_type":"code","source":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df['Correlation'] = pd.Series(log_reg.coef_[0])\n\ncoeff_df.sort_values(by = 'Correlation', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.778462Z","iopub.execute_input":"2021-12-14T11:34:08.778858Z","iopub.status.idle":"2021-12-14T11:34:08.793138Z","shell.execute_reply.started":"2021-12-14T11:34:08.778825Z","shell.execute_reply":"2021-12-14T11:34:08.792237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"분류 및 회귀 분석에 사용되는 지도 학습 모델인 SVM을 사용하여 모델링 해보겠습니다.\n일련의 훈련 샘플이 주어지면 SVM은 한 범주가 다른 범주에 포함되는 모델을 구축하여 이진 선형 분류기를 생성합니다.\n- Logistic Regression 보다 confidence가 높습니다.","metadata":{}},{"cell_type":"code","source":"svc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100 , 2)\nacc_svc","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.794493Z","iopub.execute_input":"2021-12-14T11:34:08.795429Z","iopub.status.idle":"2021-12-14T11:34:08.838887Z","shell.execute_reply.started":"2021-12-14T11:34:08.795365Z","shell.execute_reply":"2021-12-14T11:34:08.838127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"KNN을 사용하여 분류와 회귀에 적용해 보겠습니다. KNN은 과반수의 투표로 구분 됩니다.\n- KNN은 Logistic Regression 보다 좋지만, SVM보다 cofidence score가 낮습니다.","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train)* 100 , 2)\nacc_knn","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.840101Z","iopub.execute_input":"2021-12-14T11:34:08.84035Z","iopub.status.idle":"2021-12-14T11:34:08.910302Z","shell.execute_reply.started":"2021-12-14T11:34:08.840321Z","shell.execute_reply":"2021-12-14T11:34:08.909511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Navie Bayes를 이용해보겠습니다.\n- 참고 : https://ko.wikipedia.org/wiki/%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98","metadata":{"execution":{"iopub.status.busy":"2021-12-13T15:35:23.438111Z","iopub.execute_input":"2021-12-13T15:35:23.438904Z","iopub.status.idle":"2021-12-13T15:35:23.446082Z","shell.execute_reply.started":"2021-12-13T15:35:23.438836Z","shell.execute_reply":"2021-12-13T15:35:23.444952Z"}}},{"cell_type":"code","source":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.911684Z","iopub.execute_input":"2021-12-14T11:34:08.911908Z","iopub.status.idle":"2021-12-14T11:34:08.927647Z","shell.execute_reply.started":"2021-12-14T11:34:08.91188Z","shell.execute_reply":"2021-12-14T11:34:08.926524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perceptron을 이용해보겠습니다.\n- 참고 : https://ko.wikipedia.org/wiki/%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0","metadata":{}},{"cell_type":"code","source":"perceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:08.92931Z","iopub.execute_input":"2021-12-14T11:34:08.930006Z","iopub.status.idle":"2021-12-14T11:34:08.948059Z","shell.execute_reply.started":"2021-12-14T11:34:08.929963Z","shell.execute_reply":"2021-12-14T11:34:08.947194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LinearSVC을 이용해보겠습니다.\n- 참고 : https://jfun.tistory.com/105","metadata":{}},{"cell_type":"code","source":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:09.215603Z","iopub.execute_input":"2021-12-14T11:34:09.215862Z","iopub.status.idle":"2021-12-14T11:34:09.269237Z","shell.execute_reply.started":"2021-12-14T11:34:09.215834Z","shell.execute_reply":"2021-12-14T11:34:09.26832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SGDClassifier을 이용해보겠습니다.\n- 참고 : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html","metadata":{}},{"cell_type":"code","source":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:09.739247Z","iopub.execute_input":"2021-12-14T11:34:09.739843Z","iopub.status.idle":"2021-12-14T11:34:09.756524Z","shell.execute_reply.started":"2021-12-14T11:34:09.739782Z","shell.execute_reply":"2021-12-14T11:34:09.755839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:09.757931Z","iopub.execute_input":"2021-12-14T11:34:09.758173Z","iopub.status.idle":"2021-12-14T11:34:09.772612Z","shell.execute_reply.started":"2021-12-14T11:34:09.758143Z","shell.execute_reply":"2021-12-14T11:34:09.771726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:09.84085Z","iopub.execute_input":"2021-12-14T11:34:09.841311Z","iopub.status.idle":"2021-12-14T11:34:10.122777Z","shell.execute_reply.started":"2021-12-14T11:34:09.841256Z","shell.execute_reply":"2021-12-14T11:34:10.12194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation\n- 모든 모델에 대한 rank를 매김으로 써 가장 적합한 모델을 선택해 보겠습니다.\n    - Decision Tree와 Random Forest는 모두 동일한 모델이지만, Overfitting 방지를 위해서 random_forest를 이용하겠습니다.","metadata":{}},{"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:10.791843Z","iopub.execute_input":"2021-12-14T11:34:10.792311Z","iopub.status.idle":"2021-12-14T11:34:10.807677Z","shell.execute_reply.started":"2021-12-14T11:34:10.792261Z","shell.execute_reply":"2021-12-14T11:34:10.806857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T11:34:11.34746Z","iopub.execute_input":"2021-12-14T11:34:11.3482Z","iopub.status.idle":"2021-12-14T11:34:11.356851Z","shell.execute_reply.started":"2021-12-14T11:34:11.348163Z","shell.execute_reply":"2021-12-14T11:34:11.356124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 이상 긴글 읽어주셔서 감사합니다.\n- 추가로 GridSearchCV로 하이퍼파라미터 최적화도 실행할 수 있지만 제가 이 Notebook을 번역한 목적은 DataScience입문하는 사람을 목적으로 하였기에 여기까지만 작성하였습니다.","metadata":{}}]}