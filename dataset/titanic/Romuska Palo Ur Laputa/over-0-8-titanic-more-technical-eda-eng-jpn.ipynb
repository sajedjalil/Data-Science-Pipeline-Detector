{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"font-family: 'Poppins', sans-serif; color: #ff7f50; font-size: 32px; text-align: center;\">Titanic view more detailed</h1>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px; font-weight: 500; text-align: center;\">I would like to touch on what I gained and how I see things through the \"titanic\".</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px; font-weight: 500; text-align: center;\">I've tried to make the graphs and other information easier to read by devised colors and percentage notation.  Please refer to this!</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px; font-weight: 500; text-align: center;\">I made a number of innovations in feature creation that other Notebooks have not done. In addition, we'll be digging deeper into the technologies that appears at the end than anywhere else!</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px; font-weight: 500; text-align: center;\">I will describe English and Japanese both in order to make it more accessible to a wider audience(for my own English studyğŸ˜ŠğŸ˜Š).</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px; font-weight: 500; text-align: center;\">Here are some of the many things I've learned. I will also update this notebook from time to time. If you find this notebook, please <b>DO UPVOTE</b> and <b>Comments!</b>!! It's my motivation!!</p>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section1\"></a>\n<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 29px; color: #ffa500\">Introduction</h3>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Titanic(RMS Titanic, Yoyal Mail Ship Titanic) was a British-flagged ocean liner built in the early 20th century. <br> She was the second of the Olympic-class passenger ships owned by the White Star Line, but on her maiden voyage, she struck an iceberg at midnight on April 14, 1912, and sank in the early hours of the following day, April 15. by wiki<br>\n    -----<br>\n    ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ï¼ˆè‹±èª: RMS Titanicã€ãƒ­ã‚¤ãƒ¤ãƒ«ãƒ¡ãƒ¼ãƒ«ã‚·ãƒƒãƒ—ãƒ»ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ï¼‰ã¯ã€20ä¸–ç´€åˆé ­ã«å»ºé€ ã•ã‚ŒãŸã‚¤ã‚®ãƒªã‚¹èˆ¹ç±ã®ã‚ªãƒ¼ã‚·ãƒ£ãƒ³ãƒ»ãƒ©ã‚¤ãƒŠãƒ¼ã€‚\nãƒ›ãƒ¯ã‚¤ãƒˆãƒ»ã‚¹ã‚¿ãƒ¼ãƒ»ãƒ©ã‚¤ãƒ³ç¤¾ãŒä¿æœ‰ã™ã‚‹ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯ç´šå®¢èˆ¹ã®2ç•ªèˆ¹ã§ã‚ã£ãŸãŒã€å‡¦å¥³èˆªæµ·ä¸­ã®1912å¹´4æœˆ14æ—¥æ·±å¤œã«æ°·å±±ã«è¡çªã—ã€ãã®éš›ã®æå‚·ã«ã‚ˆã‚‹æµ¸æ°´ãŒåŸå› ã¨ãªã£ã¦ç¿Œ15æ—¥æœªæ˜ã«æ²ˆæ²¡ã—ãŸã€‚ wikiã‚ˆã‚Š </p>","metadata":{}},{"cell_type":"markdown","source":"<h3 style = \"font-family: 'Poppins', sans-serif; font-size: 29px; color:#ffa500\">Loading Data</h3>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T11:02:29.654156Z","iopub.execute_input":"2021-10-25T11:02:29.654717Z","iopub.status.idle":"2021-10-25T11:02:29.66306Z","shell.execute_reply.started":"2021-10-25T11:02:29.654631Z","shell.execute_reply":"2021-10-25T11:02:29.662314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\nsubmission_data = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\ndata = pd.concat([train_data, test_data], ignore_index = True, sort = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:35:57.05575Z","iopub.execute_input":"2021-08-28T16:35:57.056199Z","iopub.status.idle":"2021-08-28T16:35:57.10524Z","shell.execute_reply.started":"2021-08-28T16:35:57.056168Z","shell.execute_reply":"2021-08-28T16:35:57.104321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 18px;\">â€»Since test_data is for predicting <b>Survived</b>, so <b>Survived</b> column does not exist.<br>-----<br>â€»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ã€<b>Survived</b>ã‚’äºˆæ¸¬ã™ã‚‹ã‚‚ã®ãªã®ã§ã€<b>Survived</b>ã‚«ãƒ©ãƒ ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section2\"></a>\n<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 29px; color: #ffa500\">brief description of each column</h3>\n\n<ol style = \"font-family: 'Poppins', sans-serif; font-size:16px;\">\n    <li>PassengerId -- passenger identifiation unique ID</li>\n    <li>Survived -- Survivor flag (0 = dead, 1 = survived)</li>\n    <li>Pclass -- ticket class:\n        <ul>\n            <li>1 = Upper Class</li>\n            <li>2 = Middle Class</li>\n            <li>3 = Lower Class</li>\n        </ul>\n    </li>\n    <li>Name -- as is</li>\n    <li>Sex -- as is</li>\n    <li>Age -- as is</li>\n    <li>SibSp -- number of siblings/spouses on Titanic</li>\n    <li>Parch -- number of parents/children on Titanic</li>\n    <li>Ticket -- ticket number</li>\n    <li>Fare -- price</li>\n    <li>Cabin -- Cabin number</li>\n    <li>Embarked -- port of departure\n        <ul>\n            <li>S = Southampton</li>\n            <li>C = Cherbourg</li>\n            <li>Q = Queenstown</li>\n        </ul>\n    </li>\n</ol>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section3\"></a>\n<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 29px; color: #ffa500\">deep description of each column</h3>\n\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">For a deeper look, use pandas_Pprofiling.<br>-----<br>ã‚ˆã‚Šæ·±ãè¦‹ã‚‹ãŸã‚ã«ã€pandas_profilingã‚’ä½¿ã„ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"import pandas_profiling as pp\npp.ProfileReport(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the easy way\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T11:29:35.297233Z","iopub.execute_input":"2021-08-25T11:29:35.29762Z","iopub.status.idle":"2021-08-25T11:29:35.31395Z","shell.execute_reply.started":"2021-08-25T11:29:35.297582Z","shell.execute_reply":"2021-08-25T11:29:35.313176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section2\"></a>\n> <span>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n   You can find more details above about <a href=\"#section2\">data status</a>.<br>-----\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\n    ä¸Šã«ã€<a href=\"#section2\">ãƒ‡ãƒ¼ã‚¿ã®çŠ¶æ…‹</a>ã®è©³ç´°ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚</p>\n    \n<ol style = \"font-family: 'Poppins', sans-serif; font-size:16px;\">\n    <strong>Categorial Features(è³ªçš„å¤‰æ•°):</strong>\n        <ul>\n            <li>Sex, Embarked</li>\n        </ul>\n    <strong>Ordinal Features(é †åºå¤‰æ•°):</strong>\n        <ul>\n            <li>Pclass</li>\n        </ul>\n    <strong>Continuous Features(é€£ç¶šå¤‰æ•°):</strong>\n        <ul>\n            <li>Age, Fare</li>\n        </ul>\n    <strong>Discrete Features(é›¢æ•£å¤‰æ•°):</strong>\n        <ul>\n            <li>SibSp, Parch</li>\n        </ul><br>\n    â€»â€»PassengerID is not used for this analysis because it is just an ID.<br>-----<br>\n    â€»â€»PassengerIDã¯ã€ãŸã ã®IDãªã®ã§åˆ†æã«ã¯ä½¿ã„ã¾ã›ã‚“ã€‚\n</ol>\n</span>","metadata":{}},{"cell_type":"markdown","source":"<h4><b>What is Categorial Feature? -- è³ªçš„å¤‰æ•°ã¨ã¯ä½•ãï¼Ÿ</b></h4>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">a categorical variables are those that cannot generally be measured in terms of number or quantity, such as gender, occupation, marital status, etc.<br>-----<br>\n    è³ªçš„å¤‰æ•°ã¨ã¯ã€æ€§åˆ¥ã€è·æ¥­ã€é…å¶è€…ã®æœ‰ç„¡ãªã©ã€ä¸€èˆ¬ã«æ•°ã‚„é‡ã§æ¸¬ã‚Œãªã„å¤‰æ•°ã‚’æŒ‡ã—ã¾ã™ã€‚ </p><br>\n<h4><b>What is Ordinal Feature? -- é †åºå¤‰æ•°ã¨ã¯ä½•ãï¼Ÿ</b></h4>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">an ordinal variables are variable whose value interval has no meaning.<br>-----<br>\n    é †åºå¤‰æ•°ã¯ã€å€¤ã®é–“éš”ã«æ„å‘³ãŒãªã„å¤‰æ•°ã‚’æŒ‡ã—ã¾ã™ã€‚ </p><br>\n<h4><b>What is Continuous Feature? -- é€£ç¶šå¤‰æ•°ã¨ã¯ä½•ãï¼Ÿ</b></h4>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">a continuous variable is a variable that takes a connected value and has an infinite number between the values.<br>-----<br>\n    é€£ç¶šå¤‰æ•°ã¨ã¯ã€ç¹‹ãŒã£ãŸå€¤ã‚’ã¨ã‚‹å¤‰æ•°ã§ã€å€¤ã¨å€¤ã®é–“ã«ç„¡é™ã«å–ã‚Šã†ã‚‹å€¤ãŒã‚ã‚‹å¤‰æ•°ã‚’æŒ‡ã—ã¾ã™ã€‚\n</p><br>\n<h4><b>What is Discrete Feature? -- é›¢æ•£å¤‰æ•°ã¨ã¯ä½•ãï¼Ÿ</b></h4>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">a discrete variable is a variable that has no values between its values.<br>-----<br>\n    é›¢æ•£å¤‰æ•°ã¨ã¯ã€å€¤ã®é–“ã«å€¤ãŒå­˜åœ¨ã—ãªã„å¤‰æ•°ã‚’æŒ‡ã—ã¾ã™ã€‚ </p><br>","metadata":{}},{"cell_type":"markdown","source":"<h3 style = \"font-family: 'Poppins', sans-serif; font-size: 29px; color:#ffa500\">Exploratory Data Analysis and Data Cleaning where needed</h3>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section4\"></a>","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T08:29:07.210548Z","iopub.execute_input":"2021-08-25T08:29:07.210903Z","iopub.status.idle":"2021-08-25T08:29:07.226479Z","shell.execute_reply.started":"2021-08-25T08:29:07.210873Z","shell.execute_reply":"2021-08-25T08:29:07.225515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 17px;\">ã€€From the above, <b>Age</b> and <b>Embarked</b> are missing.I will try to fix them.<br>-----<br>ã€€ä¸Šå›³ã‚ˆã‚Šã€<b>Age</b>ã¨<b>Embarked</b>ã«ã€æ¬ æãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚å¾Œã§ç›´ã—ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<h2>How many Survived?</h2>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport matplotlib.pylab as pylab\nimport matplotlib.cm as cm","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:15:09.885959Z","iopub.execute_input":"2021-08-29T05:15:09.886441Z","iopub.status.idle":"2021-08-29T05:15:10.002887Z","shell.execute_reply.started":"2021-08-29T05:15:09.886406Z","shell.execute_reply":"2021-08-29T05:15:10.00184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize = (18, 8))\ntrain_data['Survived'].value_counts().plot.pie(colors = ['#ff7f50', '#ff4500'], explode = [0, 0.1], autopct = '%1.1f%%', ax = ax[0],shadow = True)\nax[0].set_title('Survived %')\nax[0].set_ylabel('')\nsns.countplot('Survived', data = train_data, ax = ax[1], palette='Reds_r')\nax[1].set_title('Survived graph')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:07.321408Z","iopub.execute_input":"2021-08-28T16:36:07.32179Z","iopub.status.idle":"2021-08-28T16:36:07.635829Z","shell.execute_reply.started":"2021-08-28T16:36:07.321761Z","shell.execute_reply":"2021-08-28T16:36:07.635139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">It shows that more than half of the passengers died. In the data, only 38.4% of the 891 passengers survivedâ€¦ã€€To look deeper, we will explore the relationship with other features.<br>-----<br>\n    åŠåˆ†ä»¥ä¸Šã®ä¹—å®¢ãŒäº¡ããªã‚‰ã‚ŒãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ä¸Šã§ã¯ã€891äººã®å†…ã€38.4%ã—ã‹ç”Ÿå­˜ã§ãã¦ã„ã¾ã›ã‚“ã€‚ã‚‚ã£ã¨æ·±ãè¦‹ã‚‹ãŸã‚ã€ä»–ã®å¤‰æ•°ã¨ã®é–¢é€£ã‚’æ¢ã‚Šã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<h2><b>Sex</b> vs Survived</h2>","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 3, figsize = (18, 8))\ndata[['Sex', 'Survived']].groupby(['Sex']).mean().plot.bar(ax = ax[0])\nax[0].set_title('Sex vs Survived')\nsns.countplot('Sex', hue = 'Survived', data = data, ax = ax[1])\nax[1].set_title('Sex : Survived count')\ndata.groupby('Sex')['Survived'].value_counts(normalize = True).mul(100).rename('percent').reset_index().pipe((sns.barplot, 'data'), x = 'Sex', y = 'percent', hue = 'Survived', ax = ax[2])\nax[2].set_title('Sex : Survived percent')\n# h1, l1 = ax[1].get_legend_handles_labels()\n# h2, l2 = ax[2].get_legend_handles_labels()\n# ao = ax[1].legend(h1 + h2, l1 + l1, loc = 'lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:10.642168Z","iopub.execute_input":"2021-08-28T16:36:10.642761Z","iopub.status.idle":"2021-08-28T16:36:11.134113Z","shell.execute_reply.started":"2021-08-28T16:36:10.642724Z","shell.execute_reply":"2021-08-28T16:36:11.133008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">From the graph, we found that females survived more than males(even though the number of males was higherâ€¦). This fact is going to be very useful for our analysis!! <br>Make a note of this.<br>-----<br>\n    ã‚°ãƒ©ãƒ•ã‚ˆã‚Šã€ç”Ÿãæ®‹ã£ãŸå‰²åˆã¯ã€å¥³æ€§ã®æ–¹ãŒç”·æ€§ã‚ˆã‚Šã‚‚ç”Ÿãå»¶ã³ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸï¼ˆäººæ•°ã¯ç”·æ€§ã®æ–¹ãŒå¤šã„ã®ã«â€¦ï¼‰ã€‚ã“ã®äº‹å®Ÿã¯ã€åˆ†æã«ã¨ã¦ã‚‚ä½¿ãˆãã†ã§ã™ï¼ï¼<br>ãƒ¡ãƒ¢ãƒ¡ãƒ¢Ï†(ï½¡_ï½¡*) </p>","metadata":{}},{"cell_type":"markdown","source":"<h2><b>Pclass</b> vs Survived</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Please recall. <b>Pclass</b> is an ordinal variable. When making comparisons based on ordinal variables, I recommended <b>cross tabulation</b>.<br>-----<br>\n    æ€ã„å‡ºã—ã¦ãã ã•ã„ã€‚<b>Pclass</b>ã¯é †åºå¤‰æ•°ã§ã—ãŸã€‚é †åºå¤‰æ•°ã‚’åŸºã«æ¯”è¼ƒã™ã‚‹å ´åˆã€è‡ªåˆ†ã¯<b>ã‚¯ãƒ­ã‚¹é›†è¨ˆ</b>ã‚’ãŠã™ã™ã‚ã—ã¾ã™ã€‚ </p>","metadata":{}},{"cell_type":"code","source":"pd.crosstab(train_data.Pclass, train_data.Survived, margins = True).style.background_gradient(cmap = 'Oranges')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:15.908244Z","iopub.execute_input":"2021-08-28T16:36:15.908575Z","iopub.status.idle":"2021-08-28T16:36:15.992952Z","shell.execute_reply.started":"2021-08-28T16:36:15.908548Z","shell.execute_reply":"2021-08-28T16:36:15.99206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataf, ax = plt.subplots(2, 2, figsize = (18, 12))\ndata['Pclass'].value_counts().plot.bar(color = ['#ff4500', '#ff6347', '#ff7f50'], ax = ax[0, 0])\nax[0, 0].set_title('count per Pclass')\nax[0, 0].set_ylabel('count')\nsns.countplot('Pclass', hue = 'Survived', data = data, ax = ax[0, 1], palette = 'Reds_r', order = data['Pclass'].value_counts().index)\n\nplass_percent_df = data.groupby('Pclass')['Survived'].value_counts(normalize = True).mul(100).rename('percent').reset_index()\ng = sns.barplot('Pclass', 'percent', hue = 'Survived', data = plass_percent_df, ax = ax[1, 1], palette = 'Reds_r')\ng._axes.set_ylim(0, 100)\nfor p in g._axes.patches:\n    txt = str(p.get_height().round(2)) + '%'\n    txt_x = p.get_x()\n    txt_y = p.get_height()\n    g._axes.text(txt_x + 0.03, txt_y + 1, txt)\n\nax[0, 1].set_title('Pclass count div Survived')\ndata.groupby('Pclass')['Survived'].mean().plot.pie(colors = [cm.spring(float(co) / 3) for co in range(3)], autopct = '%1.1f%%', ax = ax[1, 0], shadow = True, explode=(0.03, 0.03, 0.03), textprops={'size': 'xx-large'})\nax[1, 0].set_title('Survived rate per Pclass')\n# ax[1, 0].set_ylabel('Percent')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:16.677493Z","iopub.execute_input":"2021-08-28T16:36:16.677875Z","iopub.status.idle":"2021-08-28T16:36:17.371676Z","shell.execute_reply.started":"2021-08-28T16:36:16.677843Z","shell.execute_reply":"2021-08-28T16:36:17.370805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">From the upper left figure, we can see that most of the passengers are Pclass3. The upper right figure also shows that most of the dead are in Pclass3.<br>But since most of the passengers were originally Pclass3, let's look at the percentages.The bottom left figure shows that about <b>half</b> of the survivors are Pclass1, more than <b>35%</b> are in Pclass2. Less than <b>20%</b> are in Pclass3.<br>The lower right figure shows the breakdown by Pclass. Pclass3 is still noteworthy, as more than <b>75%</b> of the passengers in Pclass3 dead.(As I recall, cabin of Pclass3 had a Pclass1 cabin directly above it, and the door was locked.)\n    <br>-----<br>\n    å·¦ä¸Šã®å›³ã‚ˆã‚Šã€ã»ã¨ã‚“ã©ã®ä¹—å®¢ãŒPclass3ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚å³ä¸Šã®å›³ã‚ˆã‚Šã€æ­»è€…ã®ã»ã¨ã‚“ã©ãŒPclass3ã§ã‚ã‚‹ã“ã¨ã‚‚ç¢ºèªã§ãã¾ã™ã€‚ã§ã™ãŒã€ã‚‚ã¨ã‚‚ã¨ä¹—å®¢ã®ã»ã¨ã‚“ã©ãŒPclass3ãªã®ã§ã€ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚å·¦ä¸‹ã®å›³ã‚ˆã‚Šã€ç”Ÿå­˜è€…ã®ç´„<b>åŠåˆ†</b>ãŒPclass1ã®äººã§ã€<b>35%</b>ãŒPclass2ã§ã™ã€‚Pclass3ã®äººã¯ã€<b>2å‰²</b>ã«ã‚‚é”ã—ã¦ã„ã¾ã›ã‚“ã€‚ã¾ãŸã€å³ä¸‹ã®å›³ã‚ˆã‚Šã€Pclassã”ã¨ã®å†…è¨³ãŒè¦—ã‘ã¾ã™ã€‚ã‚„ã¯ã‚Šã€æ³¨ç›®ã™ã¹ãã¯Pclass3ã§ã™ã€‚Pclass3ã§ã¯<b>75%</b>ä»¥ä¸Šã®äººãŒäº¡ããªã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ä½ãŒä¸Šã®äººã‹ã‚‰ãƒ¬ã‚¹ã‚­ãƒ¥ãƒ¼ã•ã‚ŒãŸã¨ã„ã†ã“ã¨ã§ã—ã‚‡ã†ã€‚ã€‚ï¼ˆç¢ºã‹ã€ä¸‰ç­‰èˆ¹å®¤ã®å ´æ‰€ã¯çœŸä¸Šã«ä¸€ç­‰èˆ¹å®¤ãŒã‚ã‚Šã€ãƒ‰ã‚¢ãŒãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ãŸã¯ãšã€‚ã€‚ï¼‰</p>","metadata":{}},{"cell_type":"code","source":"train_data.groupby('Pclass').count()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:26.210001Z","iopub.execute_input":"2021-08-28T16:36:26.210339Z","iopub.status.idle":"2021-08-28T16:36:26.229323Z","shell.execute_reply.started":"2021-08-28T16:36:26.210311Z","shell.execute_reply":"2021-08-28T16:36:26.228618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Sex and Pclass respectively, we got some interesting analysis! Let's look a little deeper. Now, let's combine both.\n    <br>-----<br>\n    Sexã¨Pclassãã‚Œãã‚Œã§ã€é¢ç™½ã„åˆ†æãŒã§ãã¾ã—ãŸï¼ã‚‚ã†å°‘ã—æ·±ãè¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ä»Šåº¦ã¯ã€ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›ã¦ã¿ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<h2><b>Pclass</b> - <b>Sex</b> vs Survived</h2>","metadata":{}},{"cell_type":"code","source":"pd.crosstab([data.Sex, data.Survived], data.Pclass, margins = True).style.background_gradient(cmap = 'Oranges')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:30.646908Z","iopub.execute_input":"2021-08-28T16:36:30.647398Z","iopub.status.idle":"2021-08-28T16:36:30.705674Z","shell.execute_reply.started":"2021-08-28T16:36:30.647367Z","shell.execute_reply":"2021-08-28T16:36:30.704934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">When you plot categorical features, <b>factorplot</b> is recommended. As shown in the figure below, it produces a very clear division.<br>-----<br>\n    è³ªçš„å¤‰æ•°ã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹éš›ã¯ã€<b>factorplot</b>ãŒãŠã™ã™ã‚ã§ã™ã€‚ä¸‹å›³ã®ã‚ˆã†ã«ã€ã¨ã¦ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„åˆ†å‰²ãŒæˆã•ã‚Œã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Pclass', 'Survived', hue = 'Sex', data = data, palette = 'Reds')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:32.828119Z","iopub.execute_input":"2021-08-28T16:36:32.828477Z","iopub.status.idle":"2021-08-28T16:36:33.381757Z","shell.execute_reply.started":"2021-08-28T16:36:32.828432Z","shell.execute_reply":"2021-08-28T16:36:33.380703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">As we knew from out previous analysis, the survival rate for female passengers with Pclass1 is very high. Conversely, the survival rate for males in Pclass1 is less than 40%.<br>The amazing thing is that the survival rate of Pclass3 women is higher than that of Pclass1 man. Half of them survived. <br>In this case, we can see that the rescue prioritized women regardless of their location. The situation must have been such that they had to bet on the patience of the men.<br>-----<br>\n    ã“ã‚Œã¾ã§ã®åˆ†æã§ã‚ã‹ã£ã¦ã„ãŸã“ã¨ã§ã™ãŒã€å¥³æ€§ã§ã‹ã¤Pclass1ã®ä¹—å®¢ã¯ã€ç”Ÿå­˜ç‡ãŒã™ã”ãé«˜ã„ã§ã™ã€‚é€†ã«ã€Pclass1ã§ã‚‚ã€ç”·æ€§ã®ç”Ÿå­˜ç‡ã¯4å‰²ã«ã‚‚æº€ãŸãªã„ã“ã¨ã‚‚åˆ†ã‹ã‚Šã¾ã™ã€‚<br>ã™ã”ã„ã®ã¯ã€Pclass3ã®å¥³æ€§ã¯ã€Pclass1ã®ç”·æ€§ã‚ˆã‚Šã‚‚ç”Ÿå­˜ç‡ãŒé«˜ã„ã“ã¨ã§ã™ã€‚åŠåˆ†ãŒç”Ÿãæ®‹ã£ã¦ã„ã¾ã™ã€‚<br>ã“ã‚Œã«é–¢ã—ã¦ã¯ã€å ´æ‰€é–¢ä¿‚ãªãå¥³æ€§ã‚’å„ªå…ˆã—ã¦ãƒ¬ã‚¹ã‚­ãƒ¥ãƒ¼ã—ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã­ã€‚ç”·æ€§ã®å¿è€ã«è³­ã‘ãªã„ã¨ã„ã‘ãªã„ã»ã©ã®çŠ¶æ³ã ã£ãŸã®ã§ã—ã‚‡ã†ã€‚ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<h2><b>Embarked</b> vs Survived</h2>","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Embarked', 'Survived', data = train_data, color = '#E2421F')\nfig = plt.gcf()\nfig.set_size_inches(5, 3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:39.992025Z","iopub.execute_input":"2021-08-28T16:36:39.992357Z","iopub.status.idle":"2021-08-28T16:36:40.353206Z","shell.execute_reply.started":"2021-08-28T16:36:39.99233Z","shell.execute_reply":"2021-08-28T16:36:40.352183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">We can see that the survival rate of S-port is remarkable low. Also, there is more than half of the survived passenger in C-port.<br>ã€€Let's take a closer look.\n    <br>-----<br>\n    Sãƒãƒ¼ãƒˆã®ç”Ÿå­˜ç‡ãŒé¡•è‘—ã«ä½ã„ã®ãŒåˆ†ã‹ã‚Šã¾ã™ã­ã€‚ã¾ãŸã€Cãƒãƒ¼ãƒˆã§ã¯åŠåˆ†ä»¥ä¸Šã®äººãŒç”Ÿãæ®‹ã£ã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(2, 2, figsize = (20,15))\nsns.countplot('Embarked', data = data, ax = ax[0,0], palette = 'Reds_r')\nax[0,0].set_title('count per Embarked')\nsns.countplot('Embarked', hue = 'Sex', data = data, ax = ax[0,1], palette = 'Oranges_r')\nax[0,1].set_title('count per Embarked div Sex')\nplass_percent_df = data.groupby('Embarked')['Survived'].value_counts(normalize = True).mul(100).rename('percent').reset_index()\ng = sns.barplot('Embarked', 'percent', hue = 'Survived', data = plass_percent_df, ax = ax[1, 0], palette = 'spring')\ng._axes.set_ylim(0, 100)\n\nfor p in g._axes.patches:\n    txt = str(p.get_height().round(2)) + '%'\n    txt_x = p.get_x()\n    txt_y = p.get_height()\n    g._axes.text(txt_x + 0.105, txt_y + 1, txt)\nsns.countplot('Embarked', hue = 'Pclass', data = data, ax = ax[1,1], palette = 'Reds')\nax[1,1].set_title('Embarked vs Pclass')\nplt.subplots_adjust(wspace = 0.2, hspace = 0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:45.231988Z","iopub.execute_input":"2021-08-28T16:36:45.232348Z","iopub.status.idle":"2021-08-28T16:36:45.83437Z","shell.execute_reply.started":"2021-08-28T16:36:45.232319Z","shell.execute_reply":"2021-08-28T16:36:45.833621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">We can see that most of the passengers had board from S-port. And, most of them are Pclass 3 people. Previous analysis showed that most of the dead were from Pclass 3, so it make sense that most of the dead were from S-port, where most of them departed.\n<br>From the lower left figure, we can see that there are more survivors among those who boarded from C-port. <br>This also seems to be influenced by the large number of Pclass 1 people from the lower right figure. \n    <br>-----<br>ã€€ã»ã¨ã‚“ã©ã®ä¹—å®¢ãŒã€Sãƒãƒ¼ãƒˆã‹ã‚‰ä¹—å®¢ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã­ã€‚ãã—ã¦ã€ãã®ã»ã¨ã‚“ã©ãŒPclasse3ã®æ–¹ãŸã¡ã§ã™ã€‚å‰ã®åˆ†æã§ã€æ­»è€…ã®ã»ã¨ã‚“ã©ãŒPclass3ã®äººã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã€ãã®äººãŸã¡ãŒå¤šãå‡ºç™ºã—ãŸSãƒãƒ¼ãƒˆã‹ã‚‰ã®æ­»è€…ãŒå¤šã„ã®ã¯ç´å¾—ãŒã„ãã¾ã™ã€‚<br>ã€€å·¦ä¸‹ã®å›³ã‹ã‚‰ã€Cã‹ã‚‰ä¹—èˆ¹ã—ãŸäººãŸã¡ã¯ã€ç”Ÿå­˜è€…ã®æ–¹ãŒå¤šã„ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã­ã€‚ã“ã‚Œã‚‚ã€å³ä¸‹ã®å›³ã‹ã‚‰ã€Pclass1ã®äººãŒå¤šã„ã“ã¨ãŒå½±éŸ¿ã—ã¦ãã†ã§ã™ã€‚<br>ã€€ãƒãƒ¼ãƒˆQã¯ã»ã¨ã‚“ã©ãŒPclass3ã®äººã§ã™ã€‚ã§ã™ãŒã€ãƒãƒ¼ãƒˆSã¨ã‚ã¾ã‚Šç”Ÿå­˜ç‡ãŒå¤‰ã‚ã£ã¦ã„ãªã„ã®ã¯é‹ãŒè‰¯ã‹ã£ãŸã®ã§ã—ã‚‡ã†ã‹ã€‚</p>","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Pclass', 'Survived', hue = 'Sex', col = 'Embarked', data = data, palette = 'Oranges')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:55.404963Z","iopub.execute_input":"2021-08-28T16:36:55.405338Z","iopub.status.idle":"2021-08-28T16:36:56.6632Z","shell.execute_reply.started":"2021-08-28T16:36:55.405303Z","shell.execute_reply":"2021-08-28T16:36:56.66228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Here are some interesting findings.<br>\n1. First of all, regardless of Embarked, the survival rate for Pclass1 and 2 women is almost 1.<br>\n2. The few Pclass 1 and 2 people in Embark-Q, only the women survived and none of the men did.  We also found out that most of the men in Embark-Q died regardless of Pclass...<br>I wonder if it changes so much between males and females.\n    <br>-----<br>ã€€é¢ç™½ã„ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã­ã€‚<br>\n    ã€€ï¼‘ï¼å…ˆãšã€Embarkedã«é–¢ä¿‚ãªãã€Pclass1ã¨2ã®å¥³æ€§ã¯ç”Ÿå­˜ç‡ãŒã»ã¼1ã§ã™ã€‚<br>\n    ã€€ï¼’ï¼ãƒãƒ¼ãƒˆQã«ã„ã‚‹ã€æ•°å°‘ãªã„Pclass1,2ã®äººãŸã¡ã¯ã€å¥³æ€§ã ã‘ç”Ÿãæ®‹ã‚Šã€ç”·æ€§ã¯èª°ã‚‚ç”Ÿå­˜ã§ããªã‹ã£ãŸã“ã¨ã‚‚åˆ†ã‹ã‚Šã¾ã—ãŸã€‚ç”·æ€§ã¯ã»ã¨ã‚“ã©ãŒæ­»ã‚“ã§ã—ã¾ã£ãŸã“ã¨ã‚‚åˆ¤æ˜ã—ã¾ã—ãŸã€‚<br>ã€€ã“ã“ã¾ã§ç”·æ€§ã¨å¥³æ€§ã§ã‹ã‚ã£ã¦ãã‚‹ã¨ã€å°‘ã—ç–‘å•ã‚’æŠ±ã„ã¦ã—ã¾ã†ã»ã©ã§ã™ã€‚ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">It gets too complicated, so it becomes a little difficult to see, let's dare to make it 'crosstab'.\n    <br>-----<br>ã€€ã“ã“ã¾ã§å…¥ã‚Šçµ„ã‚€ã¨ã€å°‘ã—è¦‹ã¥ã‚‰ããªã£ã¦ã—ã¾ã†ã®ã§ã€ã‚ãˆã¦crosstabã«ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"pd.crosstab([train_data.Embarked, train_data.Pclass], [train_data.Sex, train_data.Survived], margins = True).style.background_gradient(cmap = 'Oranges')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:36:59.477332Z","iopub.execute_input":"2021-08-28T16:36:59.477662Z","iopub.status.idle":"2021-08-28T16:36:59.561722Z","shell.execute_reply.started":"2021-08-28T16:36:59.477634Z","shell.execute_reply":"2021-08-28T16:36:59.560906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">This one is easier to understand. The Embarked-S is by far the darker color, and the numbers also show that the men were more unlucky.\n    <br>-----<br>ã€€ã“ã£ã¡ã®ã»ã†ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã§ã™ã­ã€‚åœ§å€’çš„ã«Embarked-SãŒè‰²ãŒæ¿ƒãã€ç”·æ€§ã®æ–¹ãŒä¸é‹ã ã£ãŸã“ã¨ã‚‚æ•°å­—ã§åˆ†ã‹ã‚Šã¾ã™ã€‚ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">By the way, Embrked has a missing value.ï¼ˆSee <a href = \"#section4\">here</a>ï¼‰.<br>\nLet's take a look.\n    <br>-----<br>ã€€ãã†ã„ãˆã°ã€Embarkedã«ã¯æ¬ æå€¤ãŒã‚ã‚Šã¾ã—ãŸã­ã€‚ï¼ˆ<a href = \"#section4\">ã“ã“</a>ã‚’å‚ç…§ï¼‰<br>ã€€è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"data[data['Embarked'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:37:02.142451Z","iopub.execute_input":"2021-08-28T16:37:02.142784Z","iopub.status.idle":"2021-08-28T16:37:02.160435Z","shell.execute_reply.started":"2021-08-28T16:37:02.142757Z","shell.execute_reply":"2021-08-28T16:37:02.159319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Both have a Pclass 1 and a Fare 80.0.ã€€So, under the condition of Pclass = 1, we compare the median of Fare for each Embarked.\n    <br>-----<br>ã€€å…±ã«ã€PclassãŒ1ã§ã€FareãŒ80.0ã§ã™ã€‚ãªã®ã§ã€PclassãŒ1ã§ã€Embarkedã”ã¨ã®Fareã®ä¸­å¤®å€¤ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"C = data[(data['Embarked'] == 'C') & (data['Pclass'] == 1)]['Fare'].median()\nS = data[(data['Embarked'] == 'S') & (data['Pclass'] == 1)]['Fare'].median()\nQ = data[(data['Embarked'] == 'Q') & (data['Pclass'] == 1)]['Fare'].median()\nprint(C, S, Q)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:37:04.148361Z","iopub.execute_input":"2021-08-28T16:37:04.148723Z","iopub.status.idle":"2021-08-28T16:37:04.162437Z","shell.execute_reply.started":"2021-08-28T16:37:04.148695Z","shell.execute_reply":"2021-08-28T16:37:04.16133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">Looking at this, C is the closest to 80.0.ã€€So it seems best to fill the missing of Embarked with C.\n    <br>-----<br>ã€€ã“ã‚Œã‚’ã¿ã‚‹ã¨ã€80.0ã«ä¸€ç•ªè¿‘ã„ã®ã¯Cã§ã™ã­ã€‚ãªã®ã§ã€Embarkedã®æ¬ æã¯ï¼£ã§åŸ‹ã‚ã‚‹ã®ãŒä¸€ç•ªã‚ˆã•ãã†ã§ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"data['Embarked'] = data['Embarked'].fillna('C')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:37:06.392469Z","iopub.execute_input":"2021-08-28T16:37:06.392797Z","iopub.status.idle":"2021-08-28T16:37:06.397172Z","shell.execute_reply.started":"2021-08-28T16:37:06.392769Z","shell.execute_reply":"2021-08-28T16:37:06.396464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Embarked'].isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:37:08.706944Z","iopub.execute_input":"2021-08-28T16:37:08.707336Z","iopub.status.idle":"2021-08-28T16:37:08.713762Z","shell.execute_reply.started":"2021-08-28T16:37:08.707301Z","shell.execute_reply":"2021-08-28T16:37:08.712821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2><b>Age</b> - <b>Pclass</b> - <b>Age</b> vs Survived</h2>","metadata":{}},{"cell_type":"code","source":"print('Age range: min =', train_data['Age'].min(), ', max =', train_data['Age'].max())","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:37:10.831282Z","iopub.execute_input":"2021-08-28T16:37:10.831633Z","iopub.status.idle":"2021-08-28T16:37:10.83812Z","shell.execute_reply.started":"2021-08-28T16:37:10.831603Z","shell.execute_reply":"2021-08-28T16:37:10.837089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = 'section12'></a>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">This time, we will use <b>violinplot</b>.ã€€This is a graph that allows you to see the density of the distribution of data, and is ideal for drawing numerical data like \"Age\".<br>-----<br>\nä»Šå›ã¯ã€<b>violinplot</b>ã‚’ä½¿ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã®å¯†åº¦ã‚’ç¢ºèªã§ãã‚‹ã‚°ãƒ©ãƒ•ã§ã€æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’æç”»ã™ã‚‹ã®ã«ã‚‚ã£ã¦ã“ã„ã§ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize = (18, 8))\nsns.violinplot('Pclass', 'Age', hue = 'Survived', data = data, split = True, ax = ax[0], palette = 'spring')\nax[0].set_title('Pclass - Age vs Survived')\nax[0].set_yticks(range(0, 100, 10))\nsns.violinplot('Sex', 'Age', hue = 'Survived', data = data, split = True, ax = ax[1], palette = 'spring')\nax[1].set_title('Sex - Age vs Survived')\nax[1].set_yticks(range(0, 100, 10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:41:30.544659Z","iopub.execute_input":"2021-08-28T16:41:30.545065Z","iopub.status.idle":"2021-08-28T16:41:30.991397Z","shell.execute_reply.started":"2021-08-28T16:41:30.545021Z","shell.execute_reply":"2021-08-28T16:41:30.990457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section5\"></a>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">What we can read from this graph is that:<br>\n<ul>\n <li>The survival rate of children under 10 years old is high regardless of their Pclass.\n <li>From the left figure, the survival rate of middle-age passengers in Pclass1 is high.(The right figure shows that women contribute this survival rate. â† This is what we found in the previous analysis.)\n <li>As Pclass get closer to 1, the age group goes up and the survival rate goes down.\n <li>Males have a higher survival rate for children. But women have a higher survival rate for the elderly.\n</ul><br>-----<br>\nã“ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ã®ã¯ã€<br>\n<ul>\n<li>10æ‰ä»¥ä¸‹ã®å­ä¾›ã®ç”Ÿå­˜ç‡ã¯ã€Pclassã«é–¢ä¿‚ãªãé«˜ã„ã€‚</li>\n<li>å·¦å›³ã‹ã‚‰ã€Pclass1ã«ã„ã‚‹ä¸­å¹´ã®ä¹—å®¢ã®ç”Ÿå­˜ç‡ãŒé«˜ã„ã€‚(å³å›³ã‚’è¦‹ã‚‹ã¨ã€å¥³æ€§ãŒç”Ÿå­˜ç‡ã«å¤§ããè²¢çŒ®ã—ã¦ã„ã‚‹ã€‚â†ã“ã‚Œã¯ã€å‰ã®åˆ†æã§ã‚‚ã‚ã‹ã£ãŸã“ã¨ã€‚)å¹´é½¢ãŒä¸­å¹´ã®äººã»ã©ã€ç”Ÿå­˜ç‡ãŒé«˜ã„ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚</li>\n<li>PclassãŒ1ã«ãªã‚‹ã«ã¤ã‚Œå¹´é½¢å±¤ã¯é«˜ããªã‚Šã€ç”Ÿå­˜ç‡ã¯ä½ããªã‚‹ã€‚</li>\n<li>ç”·æ€§ã®æ–¹ãŒã€å­ä¾›ã®ç”Ÿå­˜ç‡ãŒé«˜ã„ã€‚ã ãŒã€å¥³æ€§ã®æ–¹ãŒé«˜é½¢è€…ã®ç”Ÿå­˜ç‡ã¯é«˜ã„ã€‚</li>\n</ul>\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€Don't forget. ã€€Please take a look <a href=\"#section4\">here</a>.ã€€There were 263 missing values in this training data.ã€€Normally, we would use the mean or median of the data to deal with this. <br>\nã€€But is it really safe to use the mean or median when there are 263 missing values?ã€€In the avobe analysis, we know that <b>age</b> can be used as a major feature. ã€€We should processed with caution here.<br>ã€€\nSo, let's take a look at the <b>Name</b> column.ã€€There we find acronyms like 'Mr' and 'Mrs'!.ã€€Let's use them.<br>\nã€€To do so, let's first look at the age of each acronym.<br>-----<br>ã€€å¿˜ã‚Œã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚<a href=\"#section4\">ã“ã“</a>ã‚’è¦‹ã¦ãã ã•ã„ã€‚ä»Šå›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€<b>177</b>ã®æ¬ æå€¤ãŒã‚ã‚Šã¾ã—ãŸã€‚æ™®é€šã¯ã€ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã‚„ä¸­å¤®å€¤ã‚’å…¥ã‚Œã¦å¯¾å¿œã—ã¾ã™ã€‚<br>ã€€ã§ã™ãŒã€æœ¬å½“ã«177ã‚‚æ¬ æå€¤ãŒã‚ã‚‹ã®ã«ã€å¹³å‡å€¤ã‚„ä¸­å¤®å€¤ã‚’å…¥ã‚Œã¦ã—ã¾ã£ã¦å¤§ä¸ˆå¤«ãªã®ã§ã—ã‚‡ã†ã‹ã€‚ä¸Šã®åˆ†æã§ã€å¹´é½¢ã‚‚å¤§ããªç‰¹å¾´é‡ã¨ã—ã¦ä½¿ãˆã‚‹ã“ã¨ãŒåˆ†ã‹ã£ã¦ã„ã¾ã™ã€‚ã“ã“ã¯æ…é‡ã«äº‹ã‚’é€²ã‚ã‚‹ã¹ãã§ã™ã€‚<br>ã€€ãã“ã§ã€Nameã‚«ãƒ©ãƒ ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ãã“ã«ã¯ã€Mrã‚„Mrsã®ã‚ˆã†ãªé ­èªãŒã‚ã‚‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã‹ï¼ï¼ã“ã‚Œã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚<br>ã€€ãã®ãŸã‚ã«ã€ã¾ãšã¯é ­èªãã‚Œãã‚Œã®å¹´é½¢ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<h2>The battle to fill in missing values in <b>Age</b></h2>","metadata":{}},{"cell_type":"code","source":"data['Initial'] = 0\nfor _ in data:\n    data['Initial'] = data.Name.str.extract(r'([A-Za-z]+)\\.')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:41:36.343407Z","iopub.execute_input":"2021-08-28T16:41:36.34377Z","iopub.status.idle":"2021-08-28T16:41:36.422839Z","shell.execute_reply.started":"2021-08-28T16:41:36.343719Z","shell.execute_reply":"2021-08-28T16:41:36.421648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-08-25T11:10:15.221171Z","iopub.execute_input":"2021-08-25T11:10:15.221538Z","iopub.status.idle":"2021-08-25T11:10:15.252068Z","shell.execute_reply.started":"2021-08-25T11:10:15.221508Z","shell.execute_reply":"2021-08-25T11:10:15.251071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 3>It's done!ã€€Some acronyms exist for men and some for women, so let's look at them by gender.<br>-----<br>\nå‡ºæ¥ã¦ã„ã¾ã™ï¼é ­èªã«ã¯ã€ç”·æ€§ç”¨ã¨å¥³æ€§ç”¨ã®ã‚‚ã®ã‚‚å­˜åœ¨ã™ã‚‹ã®ã§ã€ç”·å¥³åˆ¥ã§è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n</font>","metadata":{}},{"cell_type":"code","source":"pd.crosstab(data.Initial, data.Sex).T.style.background_gradient(cmap = 'Reds')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:41:38.65874Z","iopub.execute_input":"2021-08-28T16:41:38.659105Z","iopub.status.idle":"2021-08-28T16:41:38.715758Z","shell.execute_reply.started":"2021-08-28T16:41:38.659075Z","shell.execute_reply":"2021-08-28T16:41:38.715093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 3>We can see that Mr. and Master are used by men, while Mrs. and Miss are used by women.ã€€However there are some initials that are misspelled or imply the same thing, so we will summarize them into five.<br>-----<br>Mrã‚„Masterã¯ç”·æ€§ã§ã€Mrsã‚„Missã¯å¥³æ€§ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã­ã€‚ã§ã™ãŒã€ã„ãã¤ã‹èª¤è¨˜ã•ã‚ŒãŸã‚¤ãƒ‹ã‚·ãƒ£ãƒ«ã ã£ãŸã‚Šã€åŒã˜ã‚‚ã®ã‚’å«æ„ã™ã‚‹ã‚‚ã®ã‚‚è¦‹å—ã‘ã‚‰ã‚Œã‚‹ã®ã§ã€ä»Šå›ã¯5ã¤ã«ã¾ã¨ã‚ã¾ã™ã€‚</font>","metadata":{}},{"cell_type":"code","source":"data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess', 'the Countess', 'Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],['Miss', 'Mrs', 'Mrs', 'Officer', 'Officer', 'Royalty', 'Royalty', 'Royalty', 'Master', 'Officer', 'Officer', 'Officer', 'Royalty', 'Royalty', 'Royalty'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:41:40.568614Z","iopub.execute_input":"2021-08-28T16:41:40.568975Z","iopub.status.idle":"2021-08-28T16:41:40.577845Z","shell.execute_reply.started":"2021-08-28T16:41:40.568944Z","shell.execute_reply":"2021-08-28T16:41:40.576952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = 'section11'></a>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€Let's look at this by honorific title.ã€€Mr. has the lowest survival rate by far.ã€€And the survival rate of Mrs. is the highest.ã€€There is that much difference, so we can use them as a feature.<br>-----<br>æ•¬ç§°åˆ¥ã«ã¿ã¦ã¿ã¾ã—ã‚‡ã†ã€‚Mrã®ç”Ÿå­˜ç‡ãŒãƒ€ãƒ³ãƒˆãƒ„ã§ä½ã„ã§ã™ã­ã€‚ã¾ãŸã€MrsãŒæœ€ã‚‚é«˜ã„ã“ã¨ã‚‚åˆ†ã‹ã‚Šã¾ã™ã€‚ã“ã“ã¾ã§å·®ãŒã‚ã‚‹ã¨ã€ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ãˆãã†ã§ã™ã€‚\n    </p>","metadata":{}},{"cell_type":"code","source":"sns.barplot('Initial', 'Survived', data = data, palette = 'spring')\ndata.groupby(['Initial'])['Age'].mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:41:42.128293Z","iopub.execute_input":"2021-08-28T16:41:42.128622Z","iopub.status.idle":"2021-08-28T16:41:42.468113Z","shell.execute_reply.started":"2021-08-28T16:41:42.128594Z","shell.execute_reply":"2021-08-28T16:41:42.467108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\" role=\"alert\">\n  A Common Approach\n</div>","metadata":{}},{"cell_type":"markdown","source":"<font size = 3>Let's start with the general method first.ã€€In each, we will look at the average.<br>-----<br>å…ˆãšã¯ä¸€èˆ¬çš„ãªæ‰‹æ³•ã‹ã‚‰ã§ã™ã€‚ãã‚Œãã‚Œã§ã€å¹³å‡ã‚’è¦‹ã¦ã„ãã¾ã™ã€‚</font>","metadata":{}},{"cell_type":"code","source":"data.groupby('Initial')['Age'].mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:42:04.679966Z","iopub.execute_input":"2021-08-28T16:42:04.680542Z","iopub.status.idle":"2021-08-28T16:42:04.689829Z","shell.execute_reply.started":"2021-08-28T16:42:04.680487Z","shell.execute_reply":"2021-08-28T16:42:04.688975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 3>It seems to be filled in the right values better than the mean and medianï¼(Let's hope it isn't a fake name..)<br>-----<br>å¹³å‡å€¤ã‚„ä¸­å¤®å€¤ã‚ˆã‚Šã€æ­£ã—ã„å€¤ã‚’åŸ‹ã‚ã‚‰ã‚Œãã†ã§ã™ï¼ï¼ï¼ˆå½åã§ãªã„ã“ã¨ã‚’ç¥ˆã‚Šã¾ã—ã‚‡ã†( Ë‡Ï‰Ë‡äºº )ï¼‰</font>","metadata":{}},{"cell_type":"code","source":"data.loc[(data.Age.isnull()) & (data.Initial == 'Master'), 'Age'] = 5\ndata.loc[(data.Age.isnull()) & (data.Initial == 'Miss'), 'Age'] = 22\ndata.loc[(data.Age.isnull()) & (data.Initial == 'Mr'), 'Age'] = 33\ndata.loc[(data.Age.isnull()) & (data.Initial == 'Mrs'), 'Age'] = 36\ndata.loc[(data.Age.isnull()) & (data.Initial == 'Other'), 'Age'] = 46","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:42:25.383979Z","iopub.execute_input":"2021-08-28T16:42:25.384526Z","iopub.status.idle":"2021-08-28T16:42:25.398412Z","shell.execute_reply.started":"2021-08-28T16:42:25.384497Z","shell.execute_reply":"2021-08-28T16:42:25.397406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Age.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:42:27.958276Z","iopub.execute_input":"2021-08-28T16:42:27.958615Z","iopub.status.idle":"2021-08-28T16:42:27.966211Z","shell.execute_reply.started":"2021-08-28T16:42:27.958587Z","shell.execute_reply":"2021-08-28T16:42:27.965139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize = (18, 8))\ndata[data['Survived'] == 0].Age.plot.hist(ax = ax[0], bins = 20, edgecolor = 'black', color = 'orange')\nax[0].set_title('Not Survived')\nax[0].set_xticks(range(0, 85, 5))\ndata[data['Survived'] == 1].Age.plot.hist(ax = ax[1], bins = 20, edgecolor = 'black', color = 'pink')\nax[1].set_title('Survived')\nax[1].set_xticks(range(0, 85, 5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:42:28.823926Z","iopub.execute_input":"2021-08-28T16:42:28.824304Z","iopub.status.idle":"2021-08-28T16:42:29.424507Z","shell.execute_reply.started":"2021-08-28T16:42:28.824272Z","shell.execute_reply":"2021-08-28T16:42:29.423477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 3>ã€€When we fill in the missing values, we can see that there are still many middle-age passengers and a high survival rate for children.<br>\nã€€Oh, and if we look at the diagram on the right, the oldest passenger is still alive!ã€€Let's check it out(ï¼›â—”à¸´Ğ´â—”à¸´)!<br>-----<br>æ¬ æå€¤ã‚’åŸ‹ã‚ã¦ã‚‚ã€ã‚„ã¯ã‚Šä¸­å¹´ã®ä¹—å®¢ãŒå¤šãã€å­ä¾›ã®ç”Ÿå­˜ç‡ãŒé«˜ã„ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã­ã€‚<br>ãŠã‚„ã€å³å›³ã‚’è¦‹ã¦ã¿ã‚‹ã¨ã€æœ€é«˜é½¢ã®ä¹—å®¢ãŒç”Ÿãã¦ã„ã‚‹ï¼ï¼Ÿç¢ºèªã—ã¦ã¿ã‚ˆã†(ï¼›â—”à¸´Ğ´â—”à¸´)ã€‚ã€‚</font>","metadata":{}},{"cell_type":"code","source":"data[data['Age'] == data['Age'].max()].Survived","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:42:39.878208Z","iopub.execute_input":"2021-08-28T16:42:39.878551Z","iopub.status.idle":"2021-08-28T16:42:39.887561Z","shell.execute_reply.started":"2021-08-28T16:42:39.878522Z","shell.execute_reply":"2021-08-28T16:42:39.886391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size = 3>She's alive!  What a relief( ï¼›âˆ€ï¼›)<br>-----<br>ã€€å¾¡å­˜å‘½ã â€•â€•â€•ï¼ï¼ï¼è‰¯ã‹ã£ãŸ( ï¼›âˆ€ï¼›)</font>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-success\" role=\"alert\">\n  A Little More Technical\n</div>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€Let me get straight to the point.ã€€When I used the Age variable supplemented by the average age by honorific title that we did above, the accuracy <b>dropped</b> for some reason.ã€€I guess that the age of each honorific title varies.ã€€(So simple tasks such as filling in missing values with the average value will be less accurate.)<br>-----<br>ã€€çµæœã‹ã‚‰è¨€ã„ã¾ã™ã€‚è‡ªåˆ†ã¯ã€ä¸Šã§ã‚„ã£ãŸæ•¬ç§°åˆ¥å¹³å‡å¹´é½¢ã§è£œå®Œã—ãŸAgeå¤‰æ•°ã‚’ä½¿ã†ã¨ã€ãªãœã‹ç²¾åº¦ãŒ<b>è½ã¡ã¾ã—ãŸ</b>ã€‚æ•¬ç§°ã‚’ä¸€ã¤ã¨ã£ã¦ã‚‚ã€å¹´é½¢ã¯ãƒãƒ©ãƒãƒ©ãªã®ã§ã—ã‚‡ã†ã€‚ï¼ˆé€†ã«è¨€ã†ã¨ã€Ageå¤‰æ•°ã‚’å¹³å‡å€¤ã§åŸ‹ã‚ã‚‹ãªã©ã®å˜ç´”ãªä½œæ¥­ã¯ã€ã‚ˆã‚Šç²¾åº¦ãŒè½ã¡ã‚‹ã¨æ€ã„ã¾ã™ã€‚ï¼‰</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€So I didn't adopt it as a feature, but when I checked it, I found that there is a concept of <b>estimating the missing value</b> of Age using complete data without missing values(sounds amazing).ã€€Let's give it a try!<br>-----<br>ã€€ãªã®ã§ç‰¹å¾´é‡ã«ã¯æ¡ç”¨ã—ãªã‹ã£ãŸã®ã§ã™ãŒã€èª¿ã¹ã¦ã¿ã‚‹ã¨ã€æ¬ æå€¤ãŒãªã„å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€Ageã®<b>æ¬ æå€¤ã‚’æ¨å®šã™ã‚‹</b>ã¨ã„ã†è€ƒãˆæ–¹ãŒã‚ã‚‹ãã†ã§ã™ï¼ˆã™ã”ãã†ï¼‰ã€‚ã‚„ã£ã¦ã¿ã¾ã—ã‚‡ã†ï¼<b></b>\n    </p>","metadata":{}},{"cell_type":"code","source":"#First, initialize the data\n#å…ˆãšã¯ãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\nsubmission_data = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\ndata = pd.concat([train_data, test_data], ignore_index = True, sort = False)\n\ndata['Embarked'] = data['Embarked'].fillna('C')\n\ndata['Initial'] = 0\nfor _ in data:\n    data['Initial'] = data.Name.str.extract(r'([A-Za-z]+)\\.')\n    \ndata['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess', 'the Countess', 'Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],['Miss', 'Mrs', 'Mrs', 'Officer', 'Officer', 'Royalty', 'Royalty', 'Royalty', 'Master', 'Officer', 'Officer', 'Officer', 'Royalty', 'Royalty', 'Royalty'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:07:47.406982Z","iopub.execute_input":"2021-08-29T05:07:47.407384Z","iopub.status.idle":"2021-08-29T05:07:47.549488Z","shell.execute_reply.started":"2021-08-29T05:07:47.40735Z","shell.execute_reply":"2021-08-29T05:07:47.548562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:43:17.791922Z","iopub.execute_input":"2021-08-28T16:43:17.792405Z","iopub.status.idle":"2021-08-28T16:43:17.822273Z","shell.execute_reply.started":"2021-08-28T16:43:17.792374Z","shell.execute_reply":"2021-08-28T16:43:17.82126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nage_df = data[['Age', 'Pclass', 'Sex', 'Parch', 'SibSp']]\n\n#one-hot encoding \nage_df = pd.get_dummies(age_df)\n\n#Since we are guessing the missing data in Age, we will use it as test data\nnot_null_age = age_df[age_df.Age.notnull()].values\nis_null_age = age_df[age_df.Age.isnull()].values\n#split train_data into explanation variable and target variable.\nX = not_null_age[:, 1:]\ny = not_null_age[:, 0]\n\n#create the inference model by RandomForest\nrfr = RandomForestRegressor(random_state = 0, n_estimators = 100, n_jobs = -1)\nrfr.fit(X, y)\n\n#using above model, we complement the Age feature in test data\npre_Ages = rfr.predict(is_null_age[:, 1:])\ndata.loc[(data.Age.isnull()), 'Age'] = pre_Ages","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:14:58.094326Z","iopub.execute_input":"2021-08-29T05:14:58.094853Z","iopub.status.idle":"2021-08-29T05:15:00.00872Z","shell.execute_reply.started":"2021-08-29T05:14:58.094801Z","shell.execute_reply":"2021-08-29T05:15:00.007362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Age.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:15:00.791136Z","iopub.execute_input":"2021-08-29T05:15:00.79161Z","iopub.status.idle":"2021-08-29T05:15:00.801826Z","shell.execute_reply.started":"2021-08-29T05:15:00.791558Z","shell.execute_reply":"2021-08-29T05:15:00.800836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facet = sns.FacetGrid(data[:len(train_data)], hue = 'Survived', aspect = 2, palette = 'Oranges')\nfacet.map(sns.kdeplot, 'Age', shade = True)\nfacet.set(xlim = (0, data.loc[:len(train_data), 'Age'].max()))\nfacet.add_legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:15:18.181087Z","iopub.execute_input":"2021-08-29T05:15:18.181553Z","iopub.status.idle":"2021-08-29T05:15:18.591598Z","shell.execute_reply.started":"2021-08-29T05:15:18.181519Z","shell.execute_reply":"2021-08-29T05:15:18.590698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Problem with <b>Age</b> feature in Machine Learning Modelsâ€¦</h2>","metadata":{}},{"cell_type":"markdown","source":"<font size = 3>ã€€As mentioned above, Age is a continuous variable.ã€€If we try to analyze a dataset with ages ranging from 0 to 80 like this time, we will end up with as many as 80 Age variable. This isn't computationally efficient, nor is it clean.<br>ã€€\nAs you can see, there is no problem with quantitive variables.ã€€For example, 'Sex' is fine because it is only either male or female.ã€€The problem is that it is a continuous variable that can take many values.<br>ã€€\nSo this time, we will prepare a new column called <b>Age_range</b> and apply it to each of the equally divided age groups.ã€€This time, we will use 5 divisions.ã€€The oldest was 80, so we will divide every 16 years.<br>-----<br>ã€€å…ˆã»ã©è§¦ã‚ŒãŸã‚ˆã†ã«ã€Ageã¯é€£ç¶šå¤‰æ•°ã§ã™ã€‚ä»Šå›ã®ã‚ˆã†ã«ã€0æ­³ã‹ã‚‰80æ­³ã¾ã§ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†æã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€å¤šãã¦80ã‚‚ã®Ageå¤‰æ•°ãŒå­˜åœ¨ã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€è¨ˆç®—é‡çš„ã«ã‚‚è‰¯ããªã„ã§ã™ã—ã€ç¾ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚<br>ã€€ãŠåˆ†ã‹ã‚Šã ã¨æ€ã„ã¾ã™ãŒã€è³ªçš„å¤‰æ•°ã§ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚Sexã ã¨ã€maleã‹femaleã®ã©ã¡ã‚‰ã‹ã§ã™ã‹ã‚‰ã€å¤§ä¸ˆå¤«ã§ã™ã€‚å•é¡Œãªã®ã¯ã€å¤šãã®å€¤ã‚’å–ã‚Šå¾—ã‚‹é€£ç¶šå¤‰æ•°ã§ã‚ã‚‹ã“ã¨ã§ã™ã€‚<br>ã€€ãªã®ã§ã€ä»Šå›ã¯<b>Age_range</b>ã¨ã„ã†æ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’ç”¨æ„ã—ã¦ã€ç­‰åˆ†ã•ã‚ŒãŸå¹´é½¢å±¤ã«ãã‚Œãã‚Œã®ä¹—å®¢ã‚’å½“ã¦ã¯ã‚ã¦ã„ãã¾ã™ã€‚ä»Šå›ã¯5åˆ†å‰²ã§ã„ãã¾ã™ã€‚æœ€é«˜é½¢ãŒ80ã§ã—ãŸã®ã§ã€16æ­³ã”ã¨ã®åˆ†å‰²ã§ã™ã€‚\n</font>","metadata":{}},{"cell_type":"code","source":"data['Age_range'] = 0\ndata.loc[(data['Age'] <= 16), 'Age_range'] = 0\ndata.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age_range'] = 1\ndata.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age_range'] = 2\ndata.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age_range'] = 3\ndata.loc[(data['Age'] > 64), 'Age_range'] = 4","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:18.846228Z","iopub.execute_input":"2021-08-29T05:16:18.846672Z","iopub.status.idle":"2021-08-29T05:16:18.862416Z","shell.execute_reply.started":"2021-08-29T05:16:18.846638Z","shell.execute_reply":"2021-08-29T05:16:18.861241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Age_range'].value_counts().to_frame().style.background_gradient(cmap='Oranges')","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:20.40967Z","iopub.execute_input":"2021-08-29T05:16:20.410078Z","iopub.status.idle":"2021-08-29T05:16:20.465502Z","shell.execute_reply.started":"2021-08-29T05:16:20.410043Z","shell.execute_reply":"2021-08-29T05:16:20.463974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = 'section10'></a>\n<font size = 3>ã€€Now, Let's check Age_range again, based on Pclass and Sex.<br>-----<br>ã€€ã“ã“ã§ã€ã‚‚ã†ä¸€åº¦Pclassã‚„Sexã‚’è¸ã¾ãˆã€Age_rangeã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n</font>","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Age_range', 'Survived', data = data, hue = 'Sex', col = 'Pclass', palette = 'Reds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:23.748429Z","iopub.execute_input":"2021-08-29T05:16:23.748863Z","iopub.status.idle":"2021-08-29T05:16:25.632241Z","shell.execute_reply.started":"2021-08-29T05:16:23.748829Z","shell.execute_reply":"2021-08-29T05:16:25.630679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500; text-align: left;\">ã€€As we expected, the overall survival rate for women and children is high, while Pclass 3 remains low.ã€€It is sad to see that the survival rate for men becomes lower as they move up in age group.<br>-----<br>ã€€ã‚„ã¯ã‚Šã€å…¨ä½“çš„ã«è¦‹ã¦ã‚‚å¥³æ€§ã‚„å­ä¾›ã®ç”Ÿå­˜ç‡ã¯é«˜ã„ã§ã™ã­ã€‚Pclass3ã¯ä¾ç„¶ã¨ä½ã„ã®ãŒè¦‹ã¦å–ã‚Œã¾ã™ã€‚ç”·æ€§ãŒå¹´é½¢å±¤ã‚’ä¸Šã’ã‚‹ã«ã¤ã‚Œã¦ç”Ÿå­˜ç‡ãŒä½ããªã‚‹ã®ã‹æ‚²ã—ã„ã§ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<h2>Children are not to be taken on board <b>alone</b></h2>","metadata":{}},{"cell_type":"code","source":"len(data[data['Age'] <= 10])","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:45:39.233955Z","iopub.execute_input":"2021-08-28T16:45:39.234454Z","iopub.status.idle":"2021-08-28T16:45:39.240529Z","shell.execute_reply.started":"2021-08-28T16:45:39.234422Z","shell.execute_reply":"2021-08-28T16:45:39.239788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€This shows that there are 89 children under the age of 10.ã€€It is impossible for a child  of this age to board the Titanic alone.ã€€They must have boarded with their parents. If I were a parent, I would definitely give priority to my child.ã€€I'm sure others do too.ã€€This may have a significantly impact on the survival rate. Let's take a deeper look.<br>ã€€If we look at the <a href = '#section2'>columns</a>, we can see <b>SibSp</b> and <b>Parch</b>.ã€€These represent the number of siblings, spouses, and parents.ã€€This seems to be useful.ã€€We will use this to create a new variable <b>Family_Size</b>.<br>-----<br>ã€€ã“ã‚Œã‚’ã¿ã‚‹ã¨ã€10æ­³ä»¥ä¸‹ã®å­ä¾›ã¯89äººã‚‚ã„ã¾ã™ã€‚ã“ã®å¹´é½¢ã§ã€ä¸€äººã§Titanicã«ä¹—è»Šã™ã‚‹ã®ã¯ã‚ã‚Šãˆã¾ã›ã‚“ã€‚è¦ªã¨ä¸€ç·’ã«ä¹—è»Šã—ãŸã¨æ€ã‚ã‚Œã¾ã™ã€‚ã‚‚ã—è‡ªåˆ†ãŒè¦ªãªã‚‰ã°ã€çµ¶å¯¾ã«å­ä¾›ã‚’å„ªå…ˆã—ã¦åŠ©ã‘ã¾ã™ã€‚ä»–ã®äººã‚‚ãã†ã ã¨æ€ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€ç”Ÿå­˜ç‡ã«å¤§ããªå½±éŸ¿ã‚’ã‚ãŸãˆã‚‹ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚ã‚‚ã†å°‘ã—æ·±ãè¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚<br>ã€€<a href = '#section2'>ã‚«ãƒ©ãƒ </a>ã‚’ã¿ã‚‹ã¨ã€<b>SibSp</b>ã¨<b>Parch</b>ã¨ã„ã†ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚å…„å¼Ÿã‚„é…å¶è€…ã€è¦ªã®æ•°ã‚’è¡¨ã—ã¾ã™ã€‚ã“ã‚Œã¯ä½¿ãˆãã†ã§ã™ã€‚ã“ã‚Œã‚’ã¤ã‹ã£ã¦ã€æ–°ã—ã„å¤‰æ•°<b>Family_Size</b>ã‚’ä½œã‚Šã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"data['Family_Size'] = 0\ndata['Family_Size'] = data['SibSp'] + data['Parch'] + 1#this 1 is the person himself.","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:30.2262Z","iopub.execute_input":"2021-08-29T05:16:30.226632Z","iopub.status.idle":"2021-08-29T05:16:30.235663Z","shell.execute_reply.started":"2021-08-29T05:16:30.22659Z","shell.execute_reply":"2021-08-29T05:16:30.23349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€On the other hand, if they are alone, what happens to their survival rate?ã€€To analyze this as well, we will create an <b>Alone</b> variable.<br>-----<br>ã€€é€†ã«ä¸€äººã ã¨ã€ç”Ÿå­˜ç‡ã¯ã©ã†ãªã‚‹ã‚“ã§ã—ã‚‡ã†ï¼Ÿï¼Ÿ<br>ã€€ã“ã‚Œã‚‚åˆ†æã™ã‚‹ãŸã‚ã«ã€<b>Alone</b>å¤‰æ•°ã‚’ä½œã£ã¦ã¿ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"data['Alone'] = 0\ndata.loc[data.Family_Size == 1, 'Alone'] = 1","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:32.446884Z","iopub.execute_input":"2021-08-29T05:16:32.447301Z","iopub.status.idle":"2021-08-29T05:16:32.45447Z","shell.execute_reply.started":"2021-08-29T05:16:32.447266Z","shell.execute_reply":"2021-08-29T05:16:32.453394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:45:54.369726Z","iopub.execute_input":"2021-08-28T16:45:54.370238Z","iopub.status.idle":"2021-08-28T16:45:54.402756Z","shell.execute_reply.started":"2021-08-28T16:45:54.370206Z","shell.execute_reply":"2021-08-28T16:45:54.402119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize = (18, 8))\nsns.barplot('Family_Size', 'Survived', data = data, ax = ax[0], palette = 'spring')\nax[0].set_title('Family_Size vs Survived')\nsns.barplot('Alone', 'Survived', data = data, palette = 'Oranges_r')\nax[1].set_title('Alone vs Survived')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:35.594757Z","iopub.execute_input":"2021-08-29T05:16:35.595147Z","iopub.status.idle":"2021-08-29T05:16:36.30325Z","shell.execute_reply.started":"2021-08-29T05:16:35.595112Z","shell.execute_reply":"2021-08-29T05:16:36.301634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€Family_Size, Alone =ï¼‘ represents one person. It turns out that the survival rate decreases when they are alone.<br>ã€€On the other hand, it turns out that the survival rate is higher in a general group such as a family of four.ã€€I guess it is the family bond. However when the number of family members exceeds four, the survival rate decreases as the number of family increases. <br>ã€€So, let's divide them into groups based on the survival rate according to the number of family members.<br>-----<br>ã€€Family_Size, Alone =ï¼‘ãŒä¸€äººã§ã™ã€‚ä¸€äººã ã¨ã€ç”Ÿå­˜ç‡ã¯ä¸‹ãŒã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸã€‚<br>ã€€é€†ã«ã€4äººå®¶æ—ãªã©ã®ä¸€èˆ¬çš„ãªã¾ã¨ã¾ã‚Šã§ã€ç”Ÿå­˜ç‡ãŒé«˜ããªã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸã€‚å®¶æ—ã®çµ†ã§ã—ã‚‡ã†ã‹ã€‚ã§ã™ãŒã€4ã‚’è¶…ãˆã‚‹ã¨ã€äººæ•°ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ç”Ÿå­˜ç‡ãŒä¸‹ãŒã£ã¦ã„ã¾ã™ã€‚ãªã®ã§ã€å®¶æ—äººæ•°ã«ã‚ˆã‚‹ç”Ÿå­˜ç‡ã§ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã¾ã—ã‚‡ã†ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"def Family_label(s):\n    if (s >= 2) & (s <= 4):\n        return 2\n    elif ((s >= 5) & (s <= 7)) | (s == 1):\n        return 1\n    elif (s > 7):\n        return 0\n    \ndata['Family_label'] = data['Family_Size'].apply(Family_label)\nsns.barplot('Family_label', 'Survived', data = data, palette = 'Oranges')","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:40.268492Z","iopub.execute_input":"2021-08-29T05:16:40.268865Z","iopub.status.idle":"2021-08-29T05:16:40.553356Z","shell.execute_reply.started":"2021-08-29T05:16:40.268835Z","shell.execute_reply":"2021-08-29T05:16:40.551542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€It is clearly devided.ã€€Let's take a look at 'Alone'.<br>-----<br>ã€€ç¶ºéº—ã«åˆ†ã‘ã‚‰ã‚Œã¦ã¾ã™ã­ã€‚<br>ã€€Aloneã‚‚è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Alone', 'Survived', data = data, hue = 'Sex', col = 'Pclass', palette = 'Reds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:44.376899Z","iopub.execute_input":"2021-08-29T05:16:44.377343Z","iopub.status.idle":"2021-08-29T05:16:45.555356Z","shell.execute_reply.started":"2021-08-29T05:16:44.3773Z","shell.execute_reply":"2021-08-29T05:16:45.55397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€We found out that regardless of Pclass or Sex, it is dangerous to be alone.ã€€To be honest, I had expected that it would be easier to escape when they are alone, but it turns out that just having someone who lead can make all the difference.<br>-----<br>ã€€Pclassã‚„Sexã«é–¢ä¿‚ãªãã€ä¸€äººã¯å±ãªã„ã¨ã„ã†ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸã€‚æ­£ç›´ã€è‡ªåˆ†ã¯ä¸€äººã®æ–¹ãŒé€ƒã’ã‚„ã™ã„ã¨äºˆæƒ³ã—ã¦ã„ãŸã®ã§ã™ãŒã€ã‚„ã¯ã‚Šå…ˆå°ã—ã¦ãã‚Œã‚‹äººãŒã„ã‚‹ã ã‘ã§ã€ã“ã“ã¾ã§çµæœãŒå¤‰ã‚ã£ã¦ãã‚‹ã®ã§ã™ã­ã€‚ã€‚\n</p>","metadata":{}},{"cell_type":"markdown","source":"<h3>By the way, what about <b>SibSp</b> and <b>Parch</b>?</h3>","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize = (18, 8))\nsns.barplot('SibSp', 'Survived', data = train_data, ax = ax[0], palette = 'Oranges_r')\nax[0].set_title('SibSp vs Survived')\nsns.barplot('Parch', 'Survived', data = train_data, ax = ax[1], palette = 'spring')\nax[1].set_title('Parch vs Survived')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:49.281861Z","iopub.execute_input":"2021-08-29T05:16:49.28227Z","iopub.status.idle":"2021-08-29T05:16:50.079096Z","shell.execute_reply.started":"2021-08-29T05:16:49.282211Z","shell.execute_reply":"2021-08-29T05:16:50.077805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€\nã€€After all, looking at the both SibSp and Parch, the survival rate for alone is low.ã€€Always should be with someone.<br>-----<br>\nã€€ã‚„ã¯ã‚Šã€<b>SibSp</b>ã¨<b>Parch</b>ä¸¡æ–¹ã‚’è¦‹ã¦ã‚‚ã€ã²ã¨ã‚Šã®ç”Ÿå­˜ç‡ã¯ä½ã„ã§ã™ã­ã€‚<br>ã€€å¸¸ã«ã ã‚Œã‹ã¨ä¸€ç·’ã«ã„ã¾ã—ã‚‡ã†ã€‚Â´-_ã‚-)Â´-_ã‚-)\n</p>","metadata":{}},{"cell_type":"markdown","source":"<h2>Let's dig a little deeper into <b>Name</b> feature.</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€Name contains other interesting information besides the honorific title.ã€€It's the last name.<br>ã€€The conventional feature like SibSp and Parch cannot reveal family relationship beyond the third degree.ã€€Therefore, we try to analyze them by using surnames.<br>-----<br>ã€€Nameã«ã¯ã€æ•¬ç§°ä»¥å¤–ã«ã‚‚é¢ç™½ã„æƒ…å ±ãŒå…¥ã£ã¦ã„ã¾ã™ã€‚è‹—å­—ã§ã™ã€‚<br>ã€€ä»Šã¾ã§ã®ç‰¹å¾´é‡SibSpã‚„Parchã§ã¯ã€3è¦ªç­‰ä»¥é™ã®å®¶æ—é–¢ä¿‚ãŒã‚ã‹ã‚Šã¾ã›ã‚“ã€‚ãã“ã§ã€è‹—å­—ã‚’ä½¿ã†ã“ã¨ã§åˆ†æã‚’è©¦ã¿ã¾ã™ã€‚\n    </p>","metadata":{}},{"cell_type":"code","source":"data['Surname'] = data['Name'].map(lambda name:name.split(',')[0].strip())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:54.677235Z","iopub.execute_input":"2021-08-29T05:16:54.677671Z","iopub.status.idle":"2021-08-29T05:16:54.687043Z","shell.execute_reply.started":"2021-08-29T05:16:54.677633Z","shell.execute_reply":"2021-08-29T05:16:54.685334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\nf, ax = plt.subplots(1, 1, figsize = (12, 8))\nd__ = {k: v for k, v in dict(data['Surname'].value_counts()).items() if v >= 2}\ny__ = d__.values()\nc__ = collections.Counter(y__)\nlabels_, values_ = zip(*c__.items())\nindexes = np.arange(len(labels_))\nplt.bar(indexes, values_, 1, color = ['#E2421F'])\nax.set_title('num of people who have the same ticket')\nplt.xticks(indexes, labels_)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:16:58.29184Z","iopub.execute_input":"2021-08-29T05:16:58.292292Z","iopub.status.idle":"2021-08-29T05:16:58.490713Z","shell.execute_reply.started":"2021-08-29T05:16:58.292254Z","shell.execute_reply":"2021-08-29T05:16:58.489479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€As we can see above, there are many people who have the same last name.ã€€As with the features we've seen so far, let's take a look at many of them.<br>-----<br>ã€€ä¸Šã®æ§˜ã«ã€åŒã˜è‹—å­—ã‚’æŒã£ã¦ã„ã‚‹äººãŒãŸãã•ã‚“ã„ã¾ã™ã€‚ä»Šã¾ã§ã®ç‰¹å¾´é‡ã®æ§˜ã«ã€è‰²ã€…ã¨è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n    </p>","metadata":{}},{"cell_type":"code","source":"#åŒã˜è‹—å­—ã®å‡ºç¾é »åº¦ã‚’ã‚«ã‚¦ãƒ³ãƒˆ\ndata['family_sur_num'] = data['Surname'].map(data['Surname'].value_counts())\ndata","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:01.907861Z","iopub.execute_input":"2021-08-29T05:17:01.908334Z","iopub.status.idle":"2021-08-29T05:17:01.962139Z","shell.execute_reply.started":"2021-08-29T05:17:01.908294Z","shell.execute_reply":"2021-08-29T05:17:01.960416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€Look at <a href = #section10>here</a>, we found the following.<br><ul>\n<li>There are tendencies that women or younger age have higher survival rate.\n<li>Men's survival rate tend to decrease as the age increases.</ul><br>\nã€€So we will do a group analysis of these two using their surnames.<br>-----<br>\n<a href = #section10>ã“ã“</a>ã‚’ã¿ã‚‹ã¨ã€\n<ul>\n<li>å¥³æ€§ã§ã¾ãŸã¯å¹´é½¢ãŒä½ã„ã¨ç”Ÿå­˜ç‡ãŒé«˜ã„å‚¾å‘ã«ã‚ã‚‹</li>\n<li>ç”·æ€§ã§å¹´é½¢ãŒé‡ãªã‚‹ã¨ç”Ÿå­˜ç‡ãŒä½ããªã‚‹å‚¾å‘ã«ã‚ã‚‹</li>\n    <br>ã“ã¨ãŒã‚ã‹ã£ã¦ã„ã¾ã—ãŸã‚ˆã­ã€‚ãã“ã§ã€ã“ã®äºŒã¤ã‚’è‹—å­—ã‚’ä½¿ã£ãŸã‚°ãƒ«ãƒ¼ãƒ—åˆ†æã‚’è¡Œã„ã¾ã™ã€‚\n</ul>    \n</p>","metadata":{}},{"cell_type":"code","source":"#data['family_sur_num'] >= 2 represents the duplications of surnames.\nFemale_Child_Group = data.loc[(data['family_sur_num'] >= 2) & ((data['Age'] <= 16) | (data['Sex'] == 'female'))]\nMale_Adult_group = data.loc[(data['family_sur_num'] >= 2) & (data['Age'] > 16) & (data['Sex'] == 'male')]\nFemale_Child_mean = Female_Child_Group.groupby('Surname')['Survived'].mean()\nMale_Adult_mean = Male_Adult_group.groupby('Surname')['Survived'].mean()\nprint(Female_Child_mean.value_counts())\nprint('-' * 28)\nprint(Male_Adult_mean.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:08.106083Z","iopub.execute_input":"2021-08-29T05:17:08.106518Z","iopub.status.idle":"2021-08-29T05:17:08.131854Z","shell.execute_reply.started":"2021-08-29T05:17:08.106483Z","shell.execute_reply":"2021-08-29T05:17:08.130122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€We found something interesting.ã€€As well as second-degree kinship represented by SibSp and Parch, there are new findings in relation about beyond third degree kinship represented by surname.<br>ã€€\nFirst, there are 113 groups that are 16 years old or younger or female with a 100% survival rate, while only 32 groups have a 0% survival rate.<br>ã€€\nã€€Also, there are 115 groups that are 16 years old or older and male with 0% survival rate, while 21 groups have a 100% survival rate.\n<br>\n<br>ã€€This means that there are certain surnames that have the opposite fate from the majority of groups.<br>-----<br>ã€€é¢ç™½ã„ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸã€‚SibSpã‚„Parchã§è¡¨ã•ã‚Œã‚‹2è¦ªç­‰ã¨åŒã˜ãã€Surnameã§è¡¨ã•ã‚Œã‚‹3è¦ªç­‰ä»¥é™ã®é–¢é€£ã§ã‚‚ã€æ–°ã—ã„ç™ºè¦‹ãŒå‡ºã¾ã—ãŸã€‚<br>ã€€å…ˆãšã€16æ‰ä»¥ä¸‹ã¾ãŸã¯å¥³æ€§ã®ã‚°ãƒ«ãƒ¼ãƒ—ã¯ã€113ã‚°ãƒ«ãƒ¼ãƒ—ã¨å¤šããŒç”Ÿå­˜ç‡100%ãªä¸€æ–¹ã§ã€32ã‚°ãƒ«ãƒ¼ãƒ—ã«é™ã£ã¦ã¯ç”Ÿå­˜ç‡0%ã§ã™ã€‚<br>ã€€ã¾ãŸã€16æ‰ã‚’è¶…ãˆã‹ã¤ç”·æ€§ã®ã‚°ãƒ«ãƒ¼ãƒ—ã¯ã€115ã‚°ãƒ«ãƒ¼ãƒ—ã¨å¤šããŒç”Ÿå­˜ç‡0%ãªä¸€æ–¹ã§ã€21ã‚°ãƒ«ãƒ¼ãƒ—ã«é™ã£ã¦ã¯ç”Ÿå­˜ç‡100%ã§ã™ã€‚<br>ã€€ã¤ã¾ã‚Šã€ã¨ã‚ã‚‹åå­—ã‚’æŒã¤ã¨ã€å¤§å¤šæ•°ã®ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã¯é€†ã®é‹å‘½ã‚’ãŸã©ã£ã¦ã—ã¾ã†è‹—å­—ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"Dead_List = set(Female_Child_mean[Female_Child_mean.apply(lambda x:x == 0)].index)\nSurvive_List = set(Male_Adult_mean[Male_Adult_mean.apply(lambda x:x == 1)].index)\nprint(Dead_List)\nprint(Survive_List)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:11.348995Z","iopub.execute_input":"2021-08-29T05:17:11.349359Z","iopub.status.idle":"2021-08-29T05:17:11.359502Z","shell.execute_reply.started":"2021-08-29T05:17:11.349326Z","shell.execute_reply":"2021-08-29T05:17:11.358401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 16px;\">\nã€€Above are the groups with surnames that had opposite fates.ã€€This means that when we make predictions with a test data, it will be more accurate if we always have passengers with the same surname guessed as <b>alive or dead</b>.ã€€So, we will rewrite the test data to make it so.<br>ã€€\nBring in the appropriate gender and age from <a href = '#section10'>here</a> and <a href = '#section12'>here</a>, and the appropriate honorific title from <a href = '#section11'>here</a>.<br>-----<br>ã€€ä¸ŠãŒã€ãã‚Œãã‚Œé€†ã®é‹å‘½ã‚’ãŸã©ã£ãŸè‹—å­—ã®ã‚°ãƒ«ãƒ¼ãƒ—ã§ã™ã€‚ã¨ã„ã†ã“ã¨ã¯ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã™ã‚‹ã¨ãã‚‚ã€åŒã˜è‹—å­—ã‚’æŒã¤ä¹—å®¢ã‚’ã€ã‹ãªã‚‰ãš<b>ç”Ÿå­˜ãƒ»æ­»äº¡</b>ã¨æ¨æ¸¬ã—ã¦ã‚‚ã‚‰ã£ãŸã»ã†ãŒã€ç²¾åº¦ãŒä¸ŠãŒã‚Šãã†ã§ã™ã€‚ãªã®ã§ã€ãã†ãªã‚‹ãŸã‚ã«ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ›¸ãæ›ãˆã‚’è¡Œã„ã¾ã™ã€‚<br>ã€€<a href = '#section10'>ã“ã“</a>ã¨<a href = '#section12'>ã“ã“</a>ã‚ˆã‚Šé©åˆ‡ãªæ€§åˆ¥ã¨å¹´é½¢ã‚’ã€<a href = '#section11'>ã“ã“</a>ã‚ˆã‚Šé©åˆ‡ãªæ•¬ç§°ã‚’æŒã£ã¦ãã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"#ãã‚Œãã‚Œã®ãƒªã‚¹ãƒˆã‚’åæ˜ ã•ã›ã¾ã™ã€‚\ndata.loc[(data['Survived'].isnull()) & (data['Surname'].apply(lambda x:x in Dead_List)), ['Sex', 'Age', 'Initial']] = ['male', 28.0, 'Mr']\ndata.loc[(data['Survived'].isnull()) & (data['Surname'].apply(lambda x:x in Survive_List)), ['Sex', 'Age', 'Initial']] = ['female', 5.0, 'Mrs']","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:15.347673Z","iopub.execute_input":"2021-08-29T05:17:15.348053Z","iopub.status.idle":"2021-08-29T05:17:15.364016Z","shell.execute_reply.started":"2021-08-29T05:17:15.348024Z","shell.execute_reply":"2021-08-29T05:17:15.362883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In comment, I had a question about above section. If you had trouble understanding the data rewriting above, please take a look at the Comment!<br>-----<br>\nCommentã®æ–¹ã«ã€è³ªå•ã‚’ã—ã¦ãã ã•ã£ãŸæ–¹ãŒã„ã¾ã—ãŸã€‚ã‚‚ã—ä¸Šã®ãƒ‡ãƒ¼ã‚¿æ›¸ãæ›ãˆãŒåˆ†ã‹ã‚Šã«ãã‹ã£ãŸå ´åˆã¯ã€Commentã®æ–¹ã‚’è¦‹ã¦ã¿ã¦ãã ã•ã„ï¼","metadata":{}},{"cell_type":"markdown","source":"<h2><b>Fare</b> is also continuous!</h2>","metadata":{}},{"cell_type":"code","source":"print('Fare range: min =', data['Fare'].min(), ', max =', data['Fare'].max())","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:46:50.91504Z","iopub.execute_input":"2021-08-28T16:46:50.915381Z","iopub.status.idle":"2021-08-28T16:46:50.921477Z","shell.execute_reply.started":"2021-08-28T16:46:50.915353Z","shell.execute_reply":"2021-08-28T16:46:50.920665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€What does zero mean?ã€€I think it's like a free trial. I wonder if there's a tradition like that for maiden voyages..<br>ã€€\nWhen it comes to money-related matters, Pclass is the place to be, so let's see what's related.<br>-----<br>ã€€0ã£ã¦ãªã‚“ã ã‚ã†ï¼Ÿï¼Ÿç„¡æ–™ã§ä½“é¨“ã¿ãŸã„ãªã“ã¨ãƒ‡ã‚¹ã‚«ãƒã€‚ã€‚å‡¦å¥³èˆªæµ·ã«ã¯ãã†ã„ã†ã—ããŸã‚ŠãŒã‚ã‚‹ã‚“ã§ã™ã‹ã­â€¦<br>ã€€ãŠé‡‘é–¢é€£ã¨ã„ãˆã°<b>Pclass</b>ã§ã™ã‹ã‚‰ã€é–¢é€£ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 3, figsize = (18, 8))\nsns.distplot(data[data['Pclass'] == 1].Fare, ax = ax[0])\nax[0].set_title('Fares in Pclass1')\nsns.distplot(data[data['Pclass'] == 2].Fare, ax = ax[1])\nax[1].set_title('Fares in Pclass2')\nsns.distplot(data[data['Pclass'] == 3].Fare, ax = ax[2])\nax[2].set_title('Fare in Pclass3')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:21.692967Z","iopub.execute_input":"2021-08-29T05:17:21.693328Z","iopub.status.idle":"2021-08-29T05:17:22.357281Z","shell.execute_reply.started":"2021-08-29T05:17:21.693289Z","shell.execute_reply":"2021-08-29T05:17:22.356136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€Pclass has a large distribution especially.ã€€It is concentrated in the 0~100 range, but some people have more than 500.<br>ã€€\nNow, Fare also had a missing value.<br>-----<br>ã€€Pclass1ã¯ç‰¹ã«ã€åˆ†å¸ƒãŒå¤§ãã„ã§ã™ã­ã€‚0~100ã®ã¨ã“ã‚ã«é›†ä¸­ã—ã¦ã¯ã„ã¾ã™ãŒã€500ã‚’è¶…ãˆã¦ã„ã‚‹äººã‚‚ã„ã¾ã™ã€‚<br>ã€€ã•ã¦ã€Fareã«ã‚‚æ¬ æå€¤ãŒã‚ã‚Šã¾ã—ãŸã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"data.loc[data['Fare'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:25.993671Z","iopub.execute_input":"2021-08-29T05:17:25.994369Z","iopub.status.idle":"2021-08-29T05:17:26.022414Z","shell.execute_reply.started":"2021-08-29T05:17:25.994328Z","shell.execute_reply":"2021-08-29T05:17:26.020995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€Since the missing value of Fare are male with Pclass3 and Embarked-S, so let's fill in the medians of Fare that match this condition.ï¼ˆIn this case, the number of missing values is small, so the process is simple.ï¼‰<br>-----<br>ã€€Fareã®æ¬ æå€¤ã¯ã€PclassãŒ3ã§ç”·æ€§ã€EmbarkedãŒSãªã®ã§ã€ãã‚Œã«ãƒãƒƒãƒã™ã‚‹Fareã®ãƒ¡ã‚¸ã‚¢ãƒ³ã‚’åŸ‹ã‚ã¾ã—ã‚‡ã†ã€‚(ä»Šå›ã¯æ¬ æã®æ•°ãŒå°‘ãªã„ã®ã§ã€å‡¦ç†ã¯ç°¡å˜ç›®ã«ã—ã¾ã—ãŸã€‚)\n</p>","metadata":{}},{"cell_type":"code","source":"fare = data.loc[(data['Embarked'] == 'S') & (data['Pclass'] == 3) & (data['Sex'] == 'male'), 'Fare'].median()\ndata['Fare'] = data['Fare'].fillna(fare)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:36.765093Z","iopub.execute_input":"2021-08-29T05:17:36.765535Z","iopub.status.idle":"2021-08-29T05:17:36.778508Z","shell.execute_reply.started":"2021-08-29T05:17:36.765496Z","shell.execute_reply":"2021-08-29T05:17:36.776455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€For the same reason as Age, Fare is also continuous variable.ã€€In the case of Age, we devided it by the value we decided because we can predict the approximate physical strength of a person.ã€€However, in the case of Fare, it must be difficult to divide without prior knowledge.<br>ã€€\nSo, we use <b>qcut</b> in pandas.ã€€This will do the binning process so that the number of elements in each bin is equal.ã€€In this case, let's split it into four parts.<br>ã€€It may sound persistent, but <b>deal with the missing values and then do the binning process.</b><br>-----<br>ã€€Ageã¨åŒã˜ç†ç”±ã§ã€Fareã‚‚é€£ç¶šå¤‰æ•°ã§ã™ã€‚Ageã®å ´åˆã€å€¤ã”ã¨ã§ãŠãŠã‚ˆãã®äººã®ä½“åŠ›ãªã©ãŒäºˆæƒ³ã§ãã‚‹ã®ã§ã€è‡ªåˆ†ã§æ±ºã‚ãŸå€¤ã§åˆ†å‰²ã—ã¾ã—ãŸã€‚ã§ã™ãŒã€Fareã®å ´åˆã€ãã‚Œã ã‘ã§ä½•ã‹ã‚’äºˆæ¸¬ã™ã‚‹ã®ã¯é›£ã—ã„ã¨æ€ã„ã¾ã™ã€‚ãã“ã§ã€pandasã«ã‚ã‚‹qcutã‚’ä½¿ã„ã¾ã™ã€‚<br>ã€€ã“ã‚Œã¯ã€å„ãƒ“ãƒ³ã«å«ã¾ã‚Œã‚‹è¦ç´ æ•°ãŒç­‰ã—ããªã‚‹ã‚ˆã†ã«ãƒ“ãƒ‹ãƒ³ã‚°å‡¦ç†ã‚’ã—ã¦ãã‚Œã¾ã™ã€‚ä»Šå›ã¯ã€4åˆ†å‰²ã«ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚<br>ã€€ã—ã¤ã“ã„ã‚ˆã†ã§ã™ãŒã€<b>æ¬ æå€¤ã‚’å‡¦ç†ã—ã¦ã‹ã‚‰ã€ãƒ“ãƒ‹ãƒ³ã‚°å‡¦ç†ã‚’è¡Œã„ã¾ã—ã‚‡ã†ã€‚</b>\n</p>","metadata":{}},{"cell_type":"code","source":"data['Fare'].isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:41.431083Z","iopub.execute_input":"2021-08-29T05:17:41.431488Z","iopub.status.idle":"2021-08-29T05:17:41.437721Z","shell.execute_reply.started":"2021-08-29T05:17:41.431452Z","shell.execute_reply":"2021-08-29T05:17:41.437022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Fare_range'] = pd.qcut(data['Fare'], 4)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:43.341939Z","iopub.execute_input":"2021-08-29T05:17:43.342479Z","iopub.status.idle":"2021-08-29T05:17:43.359139Z","shell.execute_reply.started":"2021-08-29T05:17:43.342447Z","shell.execute_reply":"2021-08-29T05:17:43.357894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot('Fare_range', data = data, palette='Reds_r')","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:44.032248Z","iopub.execute_input":"2021-08-29T05:17:44.032859Z","iopub.status.idle":"2021-08-29T05:17:44.190345Z","shell.execute_reply.started":"2021-08-29T05:17:44.03282Z","shell.execute_reply":"2021-08-29T05:17:44.189435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(['Fare_range'])['Survived'].mean().to_frame().style.background_gradient(cmap = 'Oranges')","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:46.283141Z","iopub.execute_input":"2021-08-29T05:17:46.283799Z","iopub.status.idle":"2021-08-29T05:17:46.308091Z","shell.execute_reply.started":"2021-08-29T05:17:46.283753Z","shell.execute_reply":"2021-08-29T05:17:46.306421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€From the above figure, we can see that as Fare_range increases, the survival rate does.  As with Pclass, we can see that the money has a lot to do with survival. This could also be used for analysis.<br>\nã€€Now that we have found a boundary that can be devided into the same number of elements by qcut, let's transform it in the same way as <b>Age_range</b>.<br>-----<br>ã€€ä¸Šå›³ã‚’è¦‹ã‚‹é™ã‚Šã€Fare_rangeãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ã€ç”Ÿå­˜ç‡ã‚‚é«˜ããªã£ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚Pclassã¨åŒã˜ã§ã€ãŠé‡‘ã¯ç”Ÿå­˜ã«å¤§ããé–¢ä¿‚ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‚åˆ†æã«ä½¿ãˆãã†ã§ã™ã€‚qcutã«ã‚ˆã£ã¦åŒã˜è¦ç´ æ•°ã«åˆ†ã‘ã‚‰ã‚Œã‚‹å¢ƒç•Œã‚’è¦‹ã¤ã‘ã‚ŒãŸã®ã§ã€Age_rangeã¨åŒã˜ã‚ˆã†ã«å¤‰æ›ã—ã¾ã—ã‚‡ã†ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"data['Fare_cat'] = 0\ndata.loc[data['Fare'] <= 7.896, 'Fare_cat'] = 0\ndata.loc[(data['Fare'] > 7.896) & (data['Fare'] <= 14.454), 'Fare_cat'] = 1\ndata.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31.275), 'Fare_cat'] = 2\ndata.loc[(data['Fare'] > 31.275) & (data['Fare'] <= 513), 'Fare_cat'] = 3","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:49.33653Z","iopub.execute_input":"2021-08-29T05:17:49.336969Z","iopub.status.idle":"2021-08-29T05:17:49.352603Z","shell.execute_reply.started":"2021-08-29T05:17:49.336931Z","shell.execute_reply":"2021-08-29T05:17:49.350882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.factorplot('Fare_cat', 'Survived', data = data, hue = 'Sex', palette = 'Reds')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:49.474442Z","iopub.execute_input":"2021-08-29T05:17:49.47497Z","iopub.status.idle":"2021-08-29T05:17:50.10403Z","shell.execute_reply.started":"2021-08-29T05:17:49.47493Z","shell.execute_reply":"2021-08-29T05:17:50.102449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€For both males and females, the survival rate is highest for those in the highest Fare class.  Interestingly, the survival rate is steadly increasing for males this time.<br>ã€€With the current processing, Fare can now be incorporated into the model in the same way as Age, so that's OK!!  I'm sure it will be a useful feature for us!<br>-----<br>ã€€ç”·æ€§ã‚‚å¥³æ€§ã‚‚ã€ä¸€ç•ªé«˜ã„Fareã‚¯ãƒ©ã‚¹ã®äººãŸã¡ã®ç”Ÿå­˜ç‡ãŒä¸€ç•ªé«˜ã„ã§ã™ã€‚é¢ç™½ã„ã“ã¨ã«ä»Šå›ã¯ã€ç”·æ€§ã®æ–¹ãŒé †èª¿ã«ç”Ÿå­˜ç‡ãŒä¸ŠãŒã£ã¦ã„ã¾ã™ã­ã€‚<br>\nã€€ä»Šã®å‡¦ç†ã§ã€Fareã‚‚Ageã¨åŒã˜ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã§ã€è§£æ±ºã§ã™ã€‚ãã£ã¨ã€å½¹ã«ç«‹ã¤ç‰¹å¾´ã¨ãªã£ã¦ãã‚Œã‚‹ã«é•ã„ã‚ã‚Šã¾ã›ã‚“ã€‚ \n</p>","metadata":{}},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:48:04.621061Z","iopub.execute_input":"2021-08-28T16:48:04.621401Z","iopub.status.idle":"2021-08-28T16:48:04.670589Z","shell.execute_reply.started":"2021-08-28T16:48:04.621372Z","shell.execute_reply":"2021-08-28T16:48:04.669945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€Now that we have most of the variables, let's take a look at the correlation between them.<br>-----<br>ã€€å¤§ä½“ã®å¤‰æ•°ãŒãã‚ã£ãŸã¨ã“ã‚ã§ã€ä¸€åº¦å¤‰æ•°é–“ã®ç›¸é–¢ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"sns.heatmap(data.corr(), annot = True, cmap = 'Oranges', linewidths = 0.2, annot_kws = {'size': 20})\nfig = plt.gcf()\nfig.set_size_inches(18, 15)\nplt.xticks(fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:17:56.414305Z","iopub.execute_input":"2021-08-29T05:17:56.414836Z","iopub.status.idle":"2021-08-29T05:17:57.832475Z","shell.execute_reply.started":"2021-08-29T05:17:56.414801Z","shell.execute_reply":"2021-08-29T05:17:57.830973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€From the above figure, we can see the correlation between each feature.<br>ã€€\nTo closer the value is to 1, the more positive correlation is, and the closer it is to -1, the more negative correlation is.<br>ã€€\nSince we create Family_size from SibSp and Parch, Fare_cat from Fare, etc., there is a strong correlation between them.<br>-----<br>ã€€ä¸Šå›³ã‚ˆã‚Šã€ãã‚Œãã‚Œã®ç‰¹å¾´é‡ã®ç›¸é–¢ãŒè¦‹ã‚Œã¾ã™ã€‚<br>ã€€1ã«è¿‘ã‘ã‚Œã°è¿‘ã„ã»ã©ã€æ­£ã®ç›¸é–¢ãŒã€-1ã«è¿‘ã‘ã‚Œã°è¿‘ã„ã»ã©è² ã®ç›¸é–¢ãŒã‚ã‚Šã¾ã™ã€‚<br>ã€€SibSpã‚„Parchã‹ã‚‰Family_Sizeã‚’ã€Fareã‹ã‚‰Fare_catç­‰ã‚’ä½œã£ã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚‰ã«ç›¸é–¢ãŒå¼·ãè¡¨ã‚Œã¦ã„ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-success\" role=\"alert\">\n  <h2>Are you sure you want to do this?â€¦</h2>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€(<b>Causion!</b>)\nã€€Below is the list of things that I thought might be useful when conducting the analysis.            It is not necessarily useful for improving accuracy, but please let me share them.<br>-----<br>ã€€(<b>æ³¨æ„ï¼ï¼</b>)<br>ã€€åˆ†æã‚’è¡Œã†ã«ã‚ãŸã‚Šã€ã“ã†ã„ã†è€ƒãˆæ–¹ã‚‚ã‚ã‚‹ã®ã§ã¯ï¼Ÿã¨æ€ã£ãŸã“ã¨ã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚å¿…ãšã—ã‚‚ç²¾åº¦å‘ä¸Šã«å½¹ã«ç«‹ã¤ã¨ã„ã†è¨³ã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€å…±æœ‰ã•ã›ã¦ãã ã•ã„ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<h2><b>Cabin</b></h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€Until now, Cabin was removed because of the large number of missing values, and Initial was only used for Age completion for integration to the model. Normally, this is where it ends.<br>ã€€But let's take a look at the Titanic image. <br>-----<br>ã€€ä»Šã¾ã§ã¯ã€Cabinã¯æ¬ æå€¤ãŒå¤šã‹ã£ãŸãŸã‚å‰Šé™¤ã—ã€Intialã¯Ageã®è£œå®Œã¨ãƒ¢ãƒ‡ãƒ«ã¸ã®çµ„ã¿è¾¼ã¿ã§ã—ã‹ä½¿ã‚ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚æ™®é€šã¯ã€ã“ã“ã§çµ‚ã‚ã‚Šã¾ã™ã€‚ã§ã™ãŒã€å°‘ã—Titanicã®ç”»åƒã‚’è¦‹ã¦ã¿ã¾ã™ã€‚\n<img src= \"https://qiita-image-store.s3.amazonaws.com/0/120341/7f4b870d-1335-5b9a-7f67-08d2ad7602e0.png\" alt =\"Titanic\" style=\"height: 750px; width:auto; align: center;\"></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€The image shows a cross-sectional view of the Titanic. The alphabet on the side is Cabin. According to the wiki, the lifeboats should have been on the deck, so the closer Cabin is to A, the higher the survival rate.<br>ã€€\nHowever, there are too many missing values, so we usually don't use it. But, in this c ase, we will use it because we want to have many features for <a href = \"#section9\">feature selection</a> later on.<br>-----<br>ã€€ç”»åƒã¯ã€Titanicå·ã®æ–­é¢å›³ã«ãªã‚Šã¾ã™ã€‚æ¨ªã«æŒ¯ã‚‰ã‚Œã¦ã„ã‚‹ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãŒã€Cabinã§ã™ã€‚Wikiã«ã‚ˆã‚‹ã¨ã€æ•‘å‘½ãƒœãƒ¼ãƒˆã¯ãƒ‡ãƒƒã‚­ã«ã‚ã£ãŸã¯ãšã§ã™ã‹ã‚‰ã€CabinãŒAã«è¿‘ã„ã»ã©ç”Ÿå­˜ç‡ãŒé«˜ã„ã¨æ€ã‚ã‚Œã¾ã™ã€‚<br>ã€€ãŸã ã€æ¬ æå€¤ãŒå¤šã™ãã‚‹ã®ã§æ™®é€šã¯ä½¿ã„ã¾ã›ã‚“ã€‚ã§ã™ãŒã€ä»Šå›ã¯å¾Œã«è¡Œã†<a href = \"#section9\">ç‰¹å¾´é‡é¸æŠ</a>ã®ãŸã‚ã«ã€ãªã‚‹ã¹ãç‰¹å¾´é‡ã‚’å¤šãã—ãŸã„ã®ã§ã€ä½¿ã†ã“ã¨ã«ã—ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"data['Cabin'] = data['Cabin'].fillna('Unknown')\ndata['Cabin_label'] = data['Cabin'].str.get(0)\nsns.barplot(x = 'Cabin_label', y = 'Survived', data = data, palette = 'spring')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:02.660115Z","iopub.execute_input":"2021-08-29T05:18:02.660492Z","iopub.status.idle":"2021-08-29T05:18:03.1428Z","shell.execute_reply.started":"2021-08-29T05:18:02.660453Z","shell.execute_reply":"2021-08-29T05:18:03.141597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2><b>Ticket</b></h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€Ticket is also too random to be used normally. But, there are passengers who have the same ticket number.<br>-----<br>ã€€Ticketã‚‚ã€ãƒ©ãƒ³ãƒ€ãƒ ã™ãã‚‹ã®ã§æ™®é€šã¯ä½¿ã„ã¾ã›ã‚“ã€‚ã§ã™ãŒã€åŒã˜ãƒã‚±ãƒƒãƒˆç•ªå·ã‚’æŒã£ã¦ã„ã‚‹ä¹—å®¢ã‚‚ã„ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"import collections, sys\nf, ax = plt.subplots(1, 1, figsize = (10, 8))\nd__ = {k: v for k, v in dict(data['Ticket'].value_counts()).items() if v >= 2}\ny__ = d__.values()\nc__ = collections.Counter(y__)\nlabels_, values_ = zip(*c__.items())\nindexes = np.arange(len(labels_))\nplt.bar(indexes, values_, 1, color = ['#E2421F'])\nax.set_title('num of people who have the same ticket')\nplt.xticks(indexes, labels_)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:06.773788Z","iopub.execute_input":"2021-08-29T05:18:06.774203Z","iopub.status.idle":"2021-08-29T05:18:06.969252Z","shell.execute_reply.started":"2021-08-29T05:18:06.774171Z","shell.execute_reply":"2021-08-29T05:18:06.968162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€If the number on the Ticket is the same, wouldn't they be in the same place? If so, it seems like they would naturally share the same way.<br>ã€€\nFor the same reason as Cabin, we want to add more variables, so we will create a variable that says how many people have the same ticket number.<br>-----<br>ã€€Ticketã®ãƒŠãƒ³ãƒãƒ¼ãŒåŒã˜ãªã‚‰ã€åŒã˜å ´æ‰€ã«å±…ãã†ã˜ã‚ƒãªã„ã§ã™ã‹ï¼Ÿãã†ã™ã‚‹ã¨ã€è‡ªç„¶ã¨åŒã˜é‹å‘½ã‚’ãŸã©ã‚‹æ°—ãŒã™ã‚‹ã®ã§ã™ã€‚<br>ã€€Cabinã¨åŒã˜ç†ç”±ã§ã€å¤‰æ•°ã‚’å¢—ã‚„ã—ãŸã„ã®ã§ã€TicketãƒŠãƒ³ãƒãƒ¼ãŒåŒã˜äººãŒä½•äººã„ã‚‹ã®ã‹ã¨ã„ã†å¤‰æ•°ã‚’ä½œã‚Šã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"Ticket_count = dict(data['Ticket'].value_counts())\ndata['TicketGroup'] = data['Ticket'].map(Ticket_count)\nsns.barplot('TicketGroup', 'Survived', data = data, palette = 'spring_r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:10.459911Z","iopub.execute_input":"2021-08-29T05:18:10.460423Z","iopub.status.idle":"2021-08-29T05:18:10.996703Z","shell.execute_reply.started":"2021-08-29T05:18:10.460391Z","shell.execute_reply":"2021-08-29T05:18:10.995955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€We can see that there is a high survival rate for people whose number of people with the same ticket number is distributed betweeen 2 and 4. Also, 11 people is zero, and the others are medium.<br>ã€€So we devide them into there groups.<br>-----<br>ã€€åŒã˜ãƒã‚±ãƒƒãƒˆç•ªå·ã‚’æŒã£ã¦ã„ã‚‹äººæ•°ãŒã€2~4ã®ç”Ÿå­˜ç‡ãŒé«˜ã„ã§ã™ã­ã€‚ã¾ãŸã€11äººã¯ã‚¼ãƒ­ã§ã€ä»–ãŒä¸­ãã‚‰ã„ã§ã™ã€‚ãªã®ã§3ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"data.loc[(data['TicketGroup'] >= 2) & (data['TicketGroup'] <= 4), 'Ticket_label'] = 2\ndata.loc[(data['TicketGroup'] >= 5) & (data['TicketGroup'] <= 8) | (data['TicketGroup'] == 1), 'Ticket_label'] = 1\ndata.loc[data['TicketGroup'] == 11, 'Ticket_label'] = 0\n\nsns.barplot('Ticket_label', 'Survived', data = data, palette = 'spring')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:13.684912Z","iopub.execute_input":"2021-08-29T05:18:13.685267Z","iopub.status.idle":"2021-08-29T05:18:13.943627Z","shell.execute_reply.started":"2021-08-29T05:18:13.685229Z","shell.execute_reply":"2021-08-29T05:18:13.942351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:48:39.478647Z","iopub.execute_input":"2021-08-28T16:48:39.479005Z","iopub.status.idle":"2021-08-28T16:48:39.531871Z","shell.execute_reply.started":"2021-08-28T16:48:39.478977Z","shell.execute_reply":"2021-08-28T16:48:39.5308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style = \"font-family: 'Poppins', sans-serif; color: #ff00ff\">Color Map</h3>\n\nOne of the comments asked me to explain more about <b>color map</b>! Here are the two main ones.<ul><li>Sequential Colormap<li>Qualitative Colormap</ul>","metadata":{}},{"cell_type":"markdown","source":"<h4><b>Sequential Colormap</b></h4>\nThis palette is appropriate for variables with <b>numbers or sorted values</b>.\nI will show the list of the color below.\n\n> `_r` means *'reverse'*.","metadata":{}},{"cell_type":"code","source":"def cmap_plot(cmap_list, ctype):\n    cmaps = cmap_list\n    \n    n = len(cmaps)\n    \n    fig = plt.figure(figsize = (8.25, n * .20))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequential_cmap = ('Greys', 'Reds', 'Oranges', \n         'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n         'Purples', 'YlGnBu', 'Blues', 'PuBu', 'GnBu', 'PuBuGn', 'BuGn',\n         'Greens', 'YlGn','bone', 'gray', 'pink', 'afmhot', 'hot', 'gist_heat', 'copper', \n         'Wistia', 'autumn_r', 'summer_r', 'spring_r', 'cool', 'winter_r')            \n\ncmap_plot(sequential_cmap, 'Sequential')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 29px; color: #ffa500\">Predictive modeling in more depth than anywhere else</h3>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€Now, here's where we get a little in-depth with the tech!<br>\nã€€If you read on, you should be able to submit a score over <b>0.8(top 1%!!)</b>, so stay with me!<br>-----<br>\nã€€ã“ã“ã‹ã‚‰ã€å°‘ã—è¸ã¿å…¥ã£ãŸæŠ€è¡“ã®ç´¹ä»‹ã«ãªã‚Šã¾ã™ï¼<br>\nã€€èª­ã‚“ã§ã„ãŸã ã‘ã‚Œã°ã€ã‚¹ã‚³ã‚¢ãŒ<b>0.8(ãƒˆãƒƒãƒ—1%)</b>ã‚’è¶…ãˆã‚‹ã‚µãƒ–ãƒŸãƒƒãƒˆãŒã§ãã‚‹ã¯ãšã§ã™ã®ã§ã€ãŠä»˜ãåˆã„ãã ã•ã„ï¼\n</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_selection import SelectKBest","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:46:38.50023Z","iopub.execute_input":"2021-08-29T05:46:38.501152Z","iopub.status.idle":"2021-08-29T05:46:38.508086Z","shell.execute_reply.started":"2021-08-29T05:46:38.501103Z","shell.execute_reply":"2021-08-29T05:46:38.506717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€First, let's prepare the data to be used.<br>-----<br>ã€€ã¾ãšã¯ã€ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ãˆã¾ã—ã‚‡ã†ã€‚\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€Putting all variables we have now into the model is not benefical, as it will only make more calculations and take up more time. It may learn something useless. <br>ã€€So, we remote variables that are not needed.<br>ã€€\nIn this case, it will be like the following.<br>-----<br>ã€€ä»Šã‚ã‚‹ã€ã™ã¹ã¦ã®å¤‰æ•°ã‚’ãƒ¢ãƒ‡ãƒ«ã«å…¥ã‚Œã¦ã‚‚ã€è¨ˆç®—ãŒå¤šããªã‚Šã€æ™‚é–“ã‚’å‰²ã„ã¦ã—ã¾ã†ã ã‘ã§ã€ãƒ¡ãƒªãƒƒãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç„¡é§„ãªã‚‚ã®ã‚’å­¦ç¿’ã—ã‹ã­ã¾ã›ã‚“ã€‚ãã“ã§ã€å¿…è¦ã®ãªã„å¤‰æ•°ã‚’å–ã‚Šé™¤ãã¾ã™ã€‚<br>ã€€ä»Šå›ã®å ´åˆã¯ã€ä»¥ä¸‹ã®æ§˜ã«ãªã‚Šã¾ã™ã€‚\n<ul>\n        <li><b><b>Name</b></b></li>Not needed, since we got an <b>Initial</b> that is more likely to describe the person.<br>-----<br>ãã®äººã‚’ã‚ˆã‚Šè¡¨ã™ã§ã‚ã‚ã†<b>Initial</b>ã‚’å–å¾—ã—ãŸã®ã§ã€å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b><b>Age</b></b></li>Not needed, since we got the <b>Age_range</b>.<br>-----<br><b>Age_range</b>ã‚’å–å¾—ã—ãŸã®ã§ã€å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b>Ticket</b></li>Not needed, since we got the <b>Ticket_label</b>.<br>-----<br><b>Ticket_label</b>ã‚’å–å¾—ã—ãŸã®ã§ã€å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b><b>Fare</b></b></li>Not needed, since we got the <b>Fare_cat</b>.<br>-----<br><b>Fare_cat</b>ã‚’å–å¾—ã—ãŸã®ã§ã€å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b><b>Cabin</b></b></li>Not needed, since we got the <b>Cabin_label</b>.<br>-----<br><b>Cabin_label</b>ã‚’å–å¾—ã—ãŸã®ã§ã€å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b><b>Fare_range</b></b></li>Not needed, since we got the <b>Fare_cat</b>.<br>-----<br><b>Fare_cat</b>ã®ãŸã‚ã®å¤‰æ•°ãªã®ã§ã€å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b><b>PassengerId</b></b></li>Just a meaningless identification value, so we don't need it.<br>-----<br>æ„å‘³ã®ãªã„ã€ãŸã ã®è­˜åˆ¥å€¤ã§ã™ã€‚å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b><b>Surname</b></b></li>A variable to see the relationship by honorific title. Not required.<br>-----<br>æ•¬ç§°åˆ¥ã®é–¢ä¿‚ã‚’è¦‹ã‚‹ãŸã‚ã®å¤‰æ•°ã§ã™ã€‚å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b><b>Family_Size</b></b></li>Not needed, since we got the <b>Family_label</b>.<br>-----<br><b>Family_label</b>ã®ãŸã‚ã®å¤‰æ•°ãªã®ã§ã€å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n        <li><b><b>family_sur_num</b></b></li>For rewriting the test data. Not necessary.<br>-----<br>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ›¸ãæ›ãˆã®ãŸã‚ã§ã—ãŸã€‚å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚<br>\n</ul>\n \n</p>","metadata":{}},{"cell_type":"code","source":"data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_range','PassengerId', 'Surname', 'Family_Size', 'family_sur_num'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:24.639674Z","iopub.execute_input":"2021-08-29T05:18:24.640179Z","iopub.status.idle":"2021-08-29T05:18:24.649446Z","shell.execute_reply.started":"2021-08-29T05:18:24.640134Z","shell.execute_reply":"2021-08-29T05:18:24.648467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:26.621403Z","iopub.execute_input":"2021-08-29T05:18:26.622267Z","iopub.status.idle":"2021-08-29T05:18:26.654422Z","shell.execute_reply.started":"2021-08-29T05:18:26.622185Z","shell.execute_reply":"2021-08-29T05:18:26.653148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€ã€€Since Machine Learning Model cannot understand Strings(In this case, categorical variable like Sex, Embarked and so on), so convert them into Numeric.<br>-----<br>ã€€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯æ–‡å­—åˆ—ï¼ˆã“ã“ã§ã¯Sex, Embarkedãªã©ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼å¤‰æ•°ï¼‰ã‚’ç†è§£ã§ããªã„ãŸã‚ã€æ•°å€¤ã«å¤‰æ›ã—ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"#Machine Learning Models cannot understand strings!\ndata_ = pd.get_dummies(data)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:30.733479Z","iopub.execute_input":"2021-08-29T05:18:30.734222Z","iopub.status.idle":"2021-08-29T05:18:30.750592Z","shell.execute_reply.started":"2021-08-29T05:18:30.734167Z","shell.execute_reply":"2021-08-29T05:18:30.748802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_.columns)\nprint(len(data_.columns))\nprint(data_.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:32.975404Z","iopub.execute_input":"2021-08-29T05:18:32.975831Z","iopub.status.idle":"2021-08-29T05:18:32.983552Z","shell.execute_reply.started":"2021-08-29T05:18:32.975792Z","shell.execute_reply":"2021-08-29T05:18:32.98191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = data_[data_['Survived'].notnull()]\ntest_data = data_[data_['Survived'].isnull()].drop('Survived', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:42.211232Z","iopub.execute_input":"2021-08-29T05:18:42.211588Z","iopub.status.idle":"2021-08-29T05:18:42.221224Z","shell.execute_reply.started":"2021-08-29T05:18:42.211556Z","shell.execute_reply":"2021-08-29T05:18:42.219993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:18:43.458394Z","iopub.execute_input":"2021-08-29T05:18:43.458998Z","iopub.status.idle":"2021-08-29T05:18:43.466045Z","shell.execute_reply.started":"2021-08-29T05:18:43.458955Z","shell.execute_reply":"2021-08-29T05:18:43.46447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"section9\"></a>\n<h2><b>Are you trying to manually narrow down the fetures?</b></h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€Manually selecting explanatory variables is where we can use our cultivated experience, but let's use the algorithms that out predecessors have created for us. In this article, I will introduce a few of them. <br>-----<br>ã€€æ‰‹å‹•ã§èª¬æ˜å¤‰æ•°ã‚’é¸æŠã™ã‚‹ã®ã¯ã€åŸ¹ã£ã¦ããŸçµŒé¨“ã‚’æ´»ã‹ã™å ´ã§ã¯ã‚ã‚Šã¾ã™ãŒã€ã“ã“ã¯å…ˆäººãŸã¡ãŒä½œã£ã¦ãã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚ä»Šå›ã¯ã€ãã®ä¸­ã§ã‚‚ã„ãã¤ã‹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#menu\" style=\"font-size:20pt; background-color:coral; color:white\"  class=\"list-group-item list-group-item-action\">Univariate statisticsï¼ˆå˜å¤‰é‡çµ±è¨ˆï¼‰</a>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Univariate statistics is a method that calculates the statistical relationship between individual features and target, and tries to select the features that are related with the highest degree of confidence.<br>ã€€\nThe key of this method is that it is <b>univariate</b>. In other words, features that are meaningful when combined with other features are discarded. This makes the calculation faster.<br>-----<br>ã€€å˜å¤‰é‡çµ±è¨ˆã¨ã¯ã€å€‹ã€…ã®ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®é–“ã«ã‚ã‚‹çµ±è¨ˆçš„é–¢ä¿‚ã‚’è¨ˆç®—ã—ã€æœ€ã‚‚é«˜ã„ç¢ºä¿¡åº¦ã§é–¢é€£ã—ã¦ã„ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠã—ã‚ˆã†ã¨ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚<br>ã€€ã“ã®æ‰‹æ³•ã®è‚ã¯ã€<b>å˜å¤‰é‡ã§ã‚ã‚‹ã“ã¨</b>ã§ã™ã€‚ã™ãªã‚ã¡ã€ä»–ã®ç‰¹å¾´é‡ã¨çµ„ã¿åˆã‚ã•ã£ã¦æ„å‘³ã‚’æŒã¤ã‚ˆã†ãªç‰¹å¾´é‡ã¯æ¨ã¦ã‚‰ã‚Œã¾ã™ã€‚ãã®åˆ†è¨ˆç®—ã¯é«˜é€Ÿã§ã™ã€‚\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€<h3 style = \"color:orange\">ï¼‘ï¼SelectKBest</h3>\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    Select top k features in the explanatory variables.<br>-----<br>ã€€èª¬æ˜å¤‰æ•°ã®å†…ã€ä¸Šä½kå€‹ã‚’é¸æŠã—ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"train__X = train_data.values[:, 1:]\ntrain__y = train_data.values[:, 0]\ntest__X = test_data.values","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:20:25.709404Z","iopub.execute_input":"2021-08-29T05:20:25.709792Z","iopub.status.idle":"2021-08-29T05:20:25.716699Z","shell.execute_reply.started":"2021-08-29T05:20:25.709761Z","shell.execute_reply":"2021-08-29T05:20:25.71546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_regression\n\nselector = SelectKBest(score_func = f_regression, k = 20)#obtain 20 features from the top. \nselector.fit(train__X, train__y)\nmask = selector.get_support()\nX_shape = selector.transform(train__X)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:54:21.719303Z","iopub.execute_input":"2021-08-28T16:54:21.719713Z","iopub.status.idle":"2021-08-28T16:54:21.737248Z","shell.execute_reply.started":"2021-08-28T16:54:21.719663Z","shell.execute_reply":"2021-08-28T16:54:21.736164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = data_.columns.drop('Survived')[mask]\na","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:54:57.251783Z","iopub.execute_input":"2021-08-28T16:54:57.252189Z","iopub.status.idle":"2021-08-28T16:54:57.259638Z","shell.execute_reply.started":"2021-08-28T16:54:57.252154Z","shell.execute_reply":"2021-08-28T16:54:57.258722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Above is the fetures selected by SelectKBest.<br>ã€€\nKeep this up, and we'll use the others!<br>-----<br>ã€€ä¸ŠãŒã€SelectKBestã§é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã«ãªã‚Šã¾ã™ã€‚<br>ã€€ã“ã®èª¿å­ã§ã€ä»–ã®ã‚‚ã®ã‚‚ä½¿ã£ã¦ã¿ã¾ã—ã‚‡ã†ï¼\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins'; sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€<h3 style = \"color:orange\">ï¼’ï¼SelectPercentile</h3>\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Here, it select the top k% explanatoly variables. <br>-----<br>ã€€ã“ã¡ã‚‰ã¯ã€èª¬æ˜å¤‰æ•°ã®å†…ã€ä¸Šä½k%ã‚’é¸æŠã—ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectPercentile, f_regression\n\nselector = SelectPercentile(score_func = f_regression, percentile = 70)\nselector.fit(train__X, train__y)\nmask = selector.get_support()\nprint(data_.columns.drop('Survived')[mask])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:55:02.660305Z","iopub.execute_input":"2021-08-28T16:55:02.660838Z","iopub.status.idle":"2021-08-28T16:55:02.673307Z","shell.execute_reply.started":"2021-08-28T16:55:02.660787Z","shell.execute_reply":"2021-08-28T16:55:02.672219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins'; sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€<h3 style = \"color:orange\">ï¼“ï¼GenericUnivariateSelect</h3>\n\nã€€It can be used in the following ways.<br>-----<br>ã€€ä»¥ä¸‹ã®ã‚ˆã†ãªä½¿ã„æ–¹ã‚’ã—ã¾ã™ã€‚\n   </p>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import GenericUnivariateSelect, f_regression\n\nselector = GenericUnivariateSelect(mode = 'fwe', score_func = f_regression, param = 70)\nselector.fit(train__X, train__y)\nmask = selector.get_support()\nprint(data_.columns.drop('Survived')[mask])","metadata":{"execution":{"iopub.status.busy":"2021-08-28T16:55:27.790303Z","iopub.execute_input":"2021-08-28T16:55:27.790665Z","iopub.status.idle":"2021-08-28T16:55:27.801673Z","shell.execute_reply.started":"2021-08-28T16:55:27.790638Z","shell.execute_reply":"2021-08-28T16:55:27.80071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Time for a detour...</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€We will take a short detour from here. What will be described is a description of other variables that can be set as arguments of GenericUnivariateSelect. \nIf you want to continue solving Titanic, please skip to here.<br>-----<br>ã€€ã“ã“ã‹ã‚‰å°‘ã—å¯„ã‚Šé“ã—ã¾ã™ã€‚è¨˜è¼‰ã™ã‚‹ã“ã¨ã¯ã€<b>GenericUnivariateSelect</b>ã®å¼•æ•°ã«è¨­å®šã§ãã‚‹ã»ã‹ã®å¤‰æ•°ã®èª¬æ˜ã§ã™ã€‚Titanicã‚’è§£ãä¸Šã§ã®è§£æ³•ã‚’ç¶šã‘ãŸã„æ–¹ã¯ã€<a href = \"#section8\">ã“ã“</a>ã¾ã§é£›ã‚“ã§ãã ã•ã„ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€In addition to the fwe we saw above, there are k_best, fpr and fdr in mode.<br>ã€€To understand this, remember <a href = \"https://towardsdatascience.com/visual-guide-to-the-confusion-matrix-bb63730c8eba\">confusion matrix</a>.<br>-----<br>\n    <br>ã€€modeã«ã¯ã€ä¸Šã§è¦‹ãŸfweä»¥å¤–ã«ã€<b>k_best</b>, <b>fpr</b>, <b>fdr</b>ãŒ<a href = https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html>å­˜åœ¨ã—ã¾ã™</a>ã€‚<br>ã€€ã“ã‚Œã‚’çŸ¥ã‚‹ã«ã¯ã€<a href = \"https://qiita.com/TsutomuNakamura/items/a1a6a02cb9bb0dcbb37f\">æ··åŒè¡Œåˆ—</a>ã‚’æ€ã„å‡ºã—ã¾ã—ã‚‡ã†ã€‚<br>\n    ã€€<img src = \"https://miro.medium.com/max/1050/1*85t6zbUiQA0fotnhDaJLaA.png\"  alt =\"Titanic\" style=\"height: 300px; width:auto; align: left;\"><img src= \"https://cz-cdn.shoeisha.jp/static/images/article/9995/9995_001.png\" alt =\"Titanic\" style=\"height: 150px; width:auto; align: left;\">\n    <br>\n</p>","metadata":{}},{"cell_type":"markdown","source":"<b>fpr</b> is a false positive, which is the percentage of negative data that is incorrectly predicted as positive. The feature values are determined by decreasing this fpr value.<br>-----<br><b>fpr</b> ã¯ã€å½é™½æ€§ã¨ã„ã‚ã‚Œã‚‹ã‚‚ã®ã§ã€é™°æ€§ãƒ‡ãƒ¼ã‚¿ã‚’é–“é•ã£ã¦é™½æ€§ã¨äºˆæ¸¬ã—ãŸå‰²åˆã§ã™ã€‚ã“ã‚Œã‚’å°ã•ãã—ã¦ã„ãå½¢ã§ç‰¹å¾´é‡ã‚’æ±ºå®šã—ã¦ã„ãã¾ã™ã€‚<br>\n<table class=\"bunsuu\" summary=\"ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚ˆã‚‹è¡¨ç¤ºä¾‹1\">\n   <tbody>\n      <tr>\n         <td rowspan = \"2\" class = \"kigou\"><b>FPR</b></td>\n         <td rowspan=\"2\" class=\"kigou\"><b>ï¼</b></td>\n          <td class=\"kasen\"><b>ã€€FP</b></td>\n      </tr>\n      <tr>\n         <td><b>TN + FP</b></td>\n      </tr>\n   </tbody>\n</table>\n<b>fdr</b> is a false discovery rate, which is the percentage of data predicted to be positive that are actually negative.<br>-----<br><b>fdr</b> ã¯ã€å½ç™ºè¦‹ç‡ã¨ã„ã‚ã‚Œã‚‹ã‚‚ã®ã§ã€é™½æ€§ã¨äºˆæ¸¬ã—ãŸãƒ‡ãƒ¼ã‚¿ã®å†…ã€æœ¬å½“ã¯é™°æ€§ãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚‹å‰²åˆã‚’æŒ‡ã—ã¾ã™ã€‚<br>\n<table class=\"bunsuu\" summary=\"ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚ˆã‚‹è¡¨ç¤ºä¾‹1\">\n   <tbody>\n      <tr>\n         <td rowspan = \"2\" class = \"kigou\"><b>FDR</b></td>\n         <td rowspan=\"2\" class=\"kigou\"><b>ï¼</b></td>\n          <td class=\"kasen\"><b>ã€€FP</b></td>\n      </tr>\n       <tr>\n         <td><b>TP + FP</b></td>\n      </tr>\n   </tbody>\n</table><br>ã€€<b>fwe</b> refers to family-wise error, which is the probability that at least one correct null hypothesis set among all hypothesis sets will be incorrectly rejected. (If anything, the R language should have a more detailed implementation of this. I'll skip it this time because it gets too mathematical.)<br>-----<br><b>fwe</b>ã¯ã€ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãƒ¯ã‚¤ã‚ºã‚¨ãƒ©ãƒ¼ã‚’æŒ‡ã—ã€ã™ã¹ã¦ã®ä»®èª¬é›†åˆã®ä¸­ã§å°‘ãªãã¨ã‚‚ä¸€ã¤ã®æ­£ã—ã„å¸°ç„¡ä»®èª¬é›†åˆãŒèª¤ã£ã¦æ£„å´ã•ã‚Œã¦ã—ã¾ã†ç¢ºç‡ã®äº‹ã‚’æŒ‡ã—ã¾ã™ã€‚<br>ï¼ˆã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨Rè¨€èªã®æ–¹ãŒè©³ã—ãå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã¯ãšã§ã™ã€‚æ•°å­¦ãƒãƒƒã‚¯ã«ãªã£ã¦ã—ã¾ã†ã®ã§ä»Šå›ã¯é£›ã°ã—ã¾ã™ã€‚ï¼‰<br>ã€€","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">Now, let's try to narrow down the features using these.<br>-----<br>ã§ã¯ã€ã“ã‚Œã‚‰ã‚’ä½¿ã£ã¦ç‰¹å¾´é‡ã‚’çµã£ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import GenericUnivariateSelect, f_regression\n\nselector = GenericUnivariateSelect(mode = 'fpr', score_func = f_regression, param = 70)\nselector.fit(train__X, train__y)\nmask = selector.get_support()\nprint(data_.columns.drop('Survived')[mask])","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:22:24.019796Z","iopub.execute_input":"2021-08-29T05:22:24.020219Z","iopub.status.idle":"2021-08-29T05:22:24.040795Z","shell.execute_reply.started":"2021-08-29T05:22:24.020185Z","shell.execute_reply":"2021-08-29T05:22:24.038973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selector = GenericUnivariateSelect(mode = 'fdr', score_func = f_regression, param = 70)\nselector.fit(train__X, train__y)\nmask = selector.get_support()\nprint(data_.columns.drop('Survived')[mask])","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:03:59.092274Z","iopub.execute_input":"2021-08-28T17:03:59.092622Z","iopub.status.idle":"2021-08-28T17:03:59.102923Z","shell.execute_reply.started":"2021-08-28T17:03:59.092593Z","shell.execute_reply":"2021-08-28T17:03:59.101544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selector = GenericUnivariateSelect(mode = 'fwe', score_func = f_regression, param = 70)\nselector.fit(train__X, train__y)\nmask = selector.get_support()\nprint(data_.columns.drop('Survived')[mask])","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:04:00.746537Z","iopub.execute_input":"2021-08-28T17:04:00.746909Z","iopub.status.idle":"2021-08-28T17:04:00.760657Z","shell.execute_reply.started":"2021-08-28T17:04:00.746864Z","shell.execute_reply":"2021-08-28T17:04:00.759323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€It is not that difference (haha).  By the way, the default is <b>percentile</b>.<br>\nã€€Now, let's move on to the next one.<br>-----<br>ã€€ãã“ã¾ã§å¤‰ã‚ã‚‰ãªã„ã§ã™ã­ï¼ˆç¬‘ï¼‰ã¾ã ã‚ã‚Šã¾ã™ï¼å› ã¿ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯<b>percentile</b>ã§ã™ã€‚<br>ã€€ã§ã¯ã€æ¬¡ã®ç´¹ä»‹ã§ã™ã€‚\n</p>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#menu\" style=\"font-size:20pt; background-color:coral; color:white\"  class=\"list-group-item list-group-item-action\">Model Base Feature Selection(ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡é¸æŠ)</a>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€Model-base feature selection is a method that determine the importance of individual features and keeps only the important ones using a supervised learning model.<br>\nã€€Unlike the case of univariate selection, this is considering all features at the same time, so capturing the interaction between variables. (This makes the calculation a little slower.)<br>-----<br>ã€€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡é¸æŠã¯ã€æ•™å¸«ã‚ã‚Šå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦å€‹ã€…ã®ç‰¹å¾´é‡ã®é‡è¦æ€§ã‚’åˆ¤æ–­ã—ã€é‡è¦ãªã‚‚ã®ã ã‘ã‚’æ®‹ã™æ‰‹æ³•ã§ã™ã€‚<br>å˜å¤‰é‡é¸æŠã®å ´åˆã¨ã¯é•ã„ã€ã™ã¹ã¦ã®ç‰¹å¾´é‡ã‚’åŒæ™‚ã«è€ƒæ…®ã™ã‚‹ã®ã§ã€å¤‰æ•°é–“ã®äº¤äº’ä½œç”¨ã‚’æ‰ãˆã‚‰ã‚Œã¾ã™ã€‚(ãã®åˆ†è¨ˆç®—ãŒå°‘ã—é…ããªã‚Šã¾ã™ã€‚)\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins'; sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€<h3 style = \"color:orange\">SelectFromModel</h3>\n</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n#estimator ã¨ã—ã¦ RandomForestRegressor ã‚’ä»•æ§˜ã€‚é‡è¦åº¦ãŒ medianä»¥ä¸Šã®ã‚‚ã®ã‚’é¸æŠã€‚\nselector = SelectFromModel(RandomForestRegressor(n_estimators = 100, random_state = 42), threshold = 'median')\nselector.fit(train__X, train__y)\nsm_mask = selector.get_support()\nprint(data_.columns.drop('Survived')[sm_mask])","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:22:19.917252Z","iopub.execute_input":"2021-08-29T05:22:19.9176Z","iopub.status.idle":"2021-08-29T05:22:20.216028Z","shell.execute_reply.started":"2021-08-29T05:22:19.917571Z","shell.execute_reply":"2021-08-29T05:22:20.215033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#menu\" style=\"font-size:20pt; background-color:coral; color:white\"  class=\"list-group-item list-group-item-action\">Iterative Feature Selection(åå¾©ç‰¹å¾´é‡é¸æŠ)</a>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€Unlike univariate statistics which uses no model, and model-base feature selection which uses only one model, this time we will create a series of model using different features. <br>\nã€€<b>RFE(recursive feature elimination)</b> creates model by starting with all features and then removes the least important feature in the model. This then creates the model again and removes the least important feature.<br>-----<br>ã€€ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã‚ãªã„å˜å¤‰é‡çµ±è¨ˆã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€ã¤ã ã‘ä½¿ã†ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡é¸æŠã¨ã¯é•ã„ã€ä»Šå›ã¯ã€ç•°ãªã‚‹ç‰¹å¾´é‡ã‚’ç”¨ã„ãŸä¸€é€£ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚<br>ã€€<b>RFE(recursive feature elimination)</b>:å†å¸°çš„ç‰¹å¾´é‡å‰Šæ¸›ã¯ã€ã™ã¹ã¦ã®ç‰¹å¾´é‡ã‹ã‚‰é–‹å§‹ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚Šã€ãã®ãƒ¢ãƒ‡ãƒ«ã§æœ€ã‚‚é‡è¦åº¦ãŒä½ã„ç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ã¾ã™ã€‚ãã—ã¦ã¾ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã¤ãã‚Šã€æœ€ã‚‚é‡è¦åº¦ãŒä½ã„ç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\nselector = RFE(RandomForestRegressor(n_estimators = 100, random_state = 42), n_features_to_select = 15)\nselector.fit(train__X, train__y)\nrfe_mask = selector.get_support()\nprint(data_.columns.drop('Survived')[rfe_mask])","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:20:55.888763Z","iopub.execute_input":"2021-08-29T05:20:55.88916Z","iopub.status.idle":"2021-08-29T05:21:00.037245Z","shell.execute_reply.started":"2021-08-29T05:20:55.889127Z","shell.execute_reply":"2021-08-29T05:21:00.035835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€The disadvantage is that it takes a considerable amount of time because it is learning random forest iteratively for n_features_to_select.<br>ã€€\nThis time, we will analyze with this 15 features selected by RFE.<br>-----<br>ã€€n_features_to_selectã®åˆ†ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‚’ç¹°ã‚Šè¿”ã—å­¦ç¿’ã—ã¦ã„ã‚‹ã®ã§ã€ç›¸å½“ãªæ™‚é–“ãŒã‹ã‹ã£ã¦ã—ã¾ã†ã®ãŒæ¬ ç‚¹ã€‚<br>ã€€ä»Šå›ã¯ã€ã“ã®RFEã«ã‚ˆã£ã¦é¸æŠã•ã‚ŒãŸã€é¸ã°ã‚Œã—15ã®ç‰¹å¾´é‡ã‚’ä½¿ã£ã¦åˆ†æã‚’ã—ã¦ã„ãã¾ã™ï¼\n</p>","metadata":{}},{"cell_type":"code","source":"print(len(train_data.columns))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:21:20.462258Z","iopub.execute_input":"2021-08-29T05:21:20.462695Z","iopub.status.idle":"2021-08-29T05:21:20.468986Z","shell.execute_reply.started":"2021-08-29T05:21:20.462654Z","shell.execute_reply":"2021-08-29T05:21:20.467773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"li = ['Survived']\nli.extend(data_.columns.drop('Survived')[rfe_mask].tolist())\ntrain_data_ = train_data[li]\nprint(len(train_data_.columns)) #'Survived' + 15 selected features","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:21:23.864953Z","iopub.execute_input":"2021-08-29T05:21:23.865371Z","iopub.status.idle":"2021-08-29T05:21:23.875376Z","shell.execute_reply.started":"2021-08-29T05:21:23.865338Z","shell.execute_reply":"2021-08-29T05:21:23.873909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_ = test_data[data_.columns.drop('Survived')[rfe_mask].tolist()]","metadata":{"execution":{"iopub.status.busy":"2021-08-29T08:04:26.207066Z","iopub.execute_input":"2021-08-29T08:04:26.207419Z","iopub.status.idle":"2021-08-29T08:04:26.213448Z","shell.execute_reply.started":"2021-08-29T08:04:26.207391Z","shell.execute_reply":"2021-08-29T08:04:26.212568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_","metadata":{"execution":{"iopub.status.busy":"2021-08-29T08:04:40.079653Z","iopub.execute_input":"2021-08-29T08:04:40.080175Z","iopub.status.idle":"2021-08-29T08:04:40.105004Z","shell.execute_reply.started":"2021-08-29T08:04:40.080143Z","shell.execute_reply":"2021-08-29T08:04:40.104079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:24:59.922424Z","iopub.execute_input":"2021-08-28T18:24:59.922774Z","iopub.status.idle":"2021-08-28T18:24:59.946108Z","shell.execute_reply.started":"2021-08-28T18:24:59.922737Z","shell.execute_reply":"2021-08-28T18:24:59.945429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(train_data_, test_size = 0.3, random_state = 0, stratify = train_data['Survived'])#don't forget 'stratify'\ntrain_X = train[train.columns[1:]]\ntrain_Y = train[train.columns[:1]]\ntest_X = test[test.columns[1:]]\ntest_Y = test[test.columns[:1]]\nX = train_data_[train_data_.columns[1:]]\nY = train_data_['Survived']\nX_combined = pd.concat((train_X, test_X))\ny_combined = pd.concat((train_Y, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:21:29.053803Z","iopub.execute_input":"2021-08-29T05:21:29.054181Z","iopub.status.idle":"2021-08-29T05:21:29.070774Z","shell.execute_reply.started":"2021-08-29T05:21:29.05415Z","shell.execute_reply":"2021-08-29T05:21:29.069539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_X.shape)\nprint(test_X.shape)\nprint(train_Y.shape)\nprint(test_Y.shape)\nprint(y_combined.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:40:07.899582Z","iopub.execute_input":"2021-08-28T18:40:07.899939Z","iopub.status.idle":"2021-08-28T18:40:07.906212Z","shell.execute_reply.started":"2021-08-28T18:40:07.899903Z","shell.execute_reply":"2021-08-28T18:40:07.905284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(Y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:25:29.314303Z","iopub.execute_input":"2021-08-28T18:25:29.314622Z","iopub.status.idle":"2021-08-28T18:25:29.32256Z","shell.execute_reply.started":"2021-08-28T18:25:29.314594Z","shell.execute_reply":"2021-08-28T18:25:29.321574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: 'Poppins', sans-serif; font-size: 29px; color: #ffa500\">Deep Deep introduction of the algorithm </h3>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€The originator of machine learning is the perceptron. It is a type of neural network that uses multiple formal neurons connected in a network-like fashion. <br>ã€€However, there is a problem that perceptron does not converge on data that cannot be completely linearly separated. Therefore, various methods have been devised to deal with non-linear data.<br>ã€€In the following sections, we will explore this and try to use it in practice.<br>-----<br>ã€€æ©Ÿæ¢°å­¦ç¿’ã®å…ƒç¥–ã¨ã„ãˆã°ã€<b>ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³</b>ã§ã™ã­ã€‚ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸€ç¨®ã§ã€å½¢å¼ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’è¤‡æ•°ç”¨ã„ã¦ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶ã«æ¥ç¶šã—ãŸãƒ¢ãƒã§ã—ãŸã­ã€‚<br>ã€€ã§ã™ãŒã€ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã¯å®Œå…¨ã«ç·šå½¢åˆ†é›¢ã§ããªã„ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã§ã¯åæŸã—ãªã„ã“ã¨ãŒå•é¡Œã§ã™ã€‚ãã“ã§ã„ã‚ã„ã‚ãªå·¥å¤«ãŒãªã•ã‚Œã€éç·šå½¢ã«ã‚‚å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ãã¾ã—ãŸã€‚<br>ã€€ä»¥ä¸‹ã§ã¯ãã‚Œã‚’æ˜ã‚Šä¸‹ã’ãªãŒã‚‰ã€å®Ÿéš›ã«ä½¿ã£ã¦ã¿ã¾ã™ã€‚","metadata":{}},{"cell_type":"markdown","source":"# <b style = \"font-size:20px\">LogisticRegression</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€Logistic regression is an algorithm for linear and binary classification problems. It is a regression method by its name, but what a model for classification. If you know where the name comes from, please let me know! ï¼œ(_ _)ï¼<br>ã€€\nBe careful. This is binary classification. It is multiple regression analysis that predicts  continuous values. <br>-----<br>ã€€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¯ã€ç·šå½¢åˆ†é¡å•é¡Œã¨äºŒå€¤åˆ†é¡å•é¡Œã«å¯¾ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã™ã€‚åå‰ã‹ã‚‰ã—ã¦å›å¸°ãªã®ã§ã™ãŒã€ãªã‚“ã¨åˆ†é¡ã®ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ãªã‚“ã§ã™ã€‚åå‰ã®ç”±æ¥ã‚’çŸ¥ã£ã¦ã„ã‚‹æ–¹ã¯æ˜¯éæ•™ãˆã¦ãã ã•ã„ï¼ï¼œ(_ _)ï¼<br>ã€€æ°—ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚äºŒå€¤åˆ†é¡ã§ã™ã€‚é€£ç¶šå€¤ã‚’äºˆæ¸¬ã™ã‚‹ã®ã¯é‡å›å¸°åˆ†æã§ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<img src = \"http://media5.datahacker.rs/2021/01/83-1024x579.jpg\" alt =\"Titanic\" style=\"height: 300px; width:auto; align: left;\">","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€Rather than thinking of it as classification, it is easier to think of it as caputuring the class label y=1. The function that predicts the probability that a data point belongs to class 1 given a feature x is called the logistic sigmoid function, sometimes simply called the sigmoid function.<br>-----<br>ã€€åˆ†é¡ã¨ã„ã†è€ƒãˆæ–¹ã‚ˆã‚Šã€ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«y = 1ã‚’æ‰ãˆã‚‹ã¨è€ƒãˆãŸã»ã†ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã§ã™ã€‚ç‰¹å¾´é‡xãŒä¸ãˆã‚‰ã‚ŒãŸå ´åˆã«ãƒ‡ãƒ¼ã‚¿ç‚¹ãŒã‚¯ãƒ©ã‚¹1ã«æ‰€å±ã—ã¦ã„ã‚‹ç¢ºç‡ã‚’äºˆæ¸¬ã™ã‚‹é–¢æ•°ã‚’ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã¨å‘¼ã³ã€å˜ã«ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã¨å‘¼ã°ã‚ŒãŸã‚Šã—ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n<math>\n\\[ z = \\log \\frac{p(y = 1|\\mathbf{x})}{1 - p(y = 1|\\mathbf{x})} \\Longleftrightarrow p(y = 1|\\mathbf{x}) = \\frac{1}{1+e^{-z}} \\]\n    </math>\n    </p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€Now, let's take a look at the sigmoid. If you look at this, you can see why this can only be used for binary classification.<br>-----<br>ã€€ã§ã¯ã€ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã“ã‚Œã‚’è¦‹ã‚Œã°ã€äºŒå€¤åˆ†é¡ã§ã—ã‹ä½¿ãˆãªã„ã“ã¨ãŒåˆ†ã‹ã‚‹ã¯ãšã§ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"def sigmoid(z):\n    return 1.0 / (1.0 + np.exp(-z))\n\nz = np.arange(-7, 7, 0.1)\nsig_z = sigmoid(z)\nplt.plot(z, sig_z, color = '#E2421F')\n\nplt.axvline(0.0, color = 'k')\nplt.ylim(-0.1, 1.1)\nplt.xlabel('z')\nplt.ylabel('sigmoid(z)')\n\nplt.yticks(np.arange(0.0, 1.1, 0.5))\nax = plt.gca()\nax.yaxis.grid(True, color = 'orange')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:12:01.42558Z","iopub.execute_input":"2021-08-28T17:12:01.425939Z","iopub.status.idle":"2021-08-28T17:12:01.636594Z","shell.execute_reply.started":"2021-08-28T17:12:01.425904Z","shell.execute_reply":"2021-08-28T17:12:01.635735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n<math>\n    <mfrac numalign=\"left\">\n    ã€€The inner product of the feature vector x and the weight w to be put into the activation function can be expressed by z = <span style=\"font-weight:bold\">w</span><sup>T</sup><span style=\"font-weight:bold\">x</span>, so<br>-----<br>ã€€æ´»æ€§åŒ–é–¢æ•°ã«å…¥ã‚Œã‚‹ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«xã¨ã‚¦ã‚§ã‚¤ãƒˆwã®å†…ç©ã¯ã€\n    z = <span style=\"font-weight:bold\">w</span><sup>T</sup><span style=\"font-weight:bold\">x</span>ã§è¡¨ã›ã‚‹ã®ã§ã€<br><br>\n\\[ f(z) = \\frac{1}{1+e^{-z}} = \\frac{1}{1+e^{-\\mathbf{w}^{T}\\mathbf{x}}} \\]<br>\n   ã€€and we use the threshold to convert the predicted probability into the binary outcome measure.<br>-----<br>ã¨ãªã‚Šã€é–¾å€¤ã‚’ä½¿ã£ã¦ã€äºˆæ¸¬ã•ã‚ŒãŸç¢ºç‡ã‚’äºŒå€¤ã®æˆæœæŒ‡æ¨™ã«å¤‰æ›ã™ã‚‹ã€‚<br><br>\n    \\[\n\\begin{eqnarray}\n\\hat{y} =\n  \\begin{cases}\n    1 & ( f(z) \\ge 0.5 ) \\\\\n    0 & ( f(z) \\lt 0.5 )\n  \\end{cases}\n\\end{eqnarray}\n\\]<br>\n    ã€€So, logistic regression is a binary classification. <br>-----<br>ãªã®ã§ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¯2å€¤åˆ†é¡ãªã®ã§ã™ã€‚\n        </mfrac>\n</math>\n    </p>","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(train_X,train_Y)\npre1 = model.predict(test_X)\nprint('The accuracy of the Logistic Regression is',metrics.accuracy_score(pre1,test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:21:36.514894Z","iopub.execute_input":"2021-08-29T05:21:36.515294Z","iopub.status.idle":"2021-08-29T05:21:36.580521Z","shell.execute_reply.started":"2021-08-29T05:21:36.51526Z","shell.execute_reply":"2021-08-29T05:21:36.579458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style = \"font-size:20px\">Linear Support Vector Machine</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€Suppert Vector Machine is an extension of the Perceptron. The goal is to maximize what is called the <b>margin</b>, red dotted line in the below figure. In other words, it is classifying.<br>-----<br>ã€€ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ãƒˆãƒ«ãƒã‚·ãƒ³ã¯ã€ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã®æ‹¡å¼µã§ã™ã€‚ä¸‹å›³ã®èµ¤ã„ç‚¹ç·š <b>ãƒãƒ¼ã‚¸ãƒ³</b> ã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã‚’æœ€å¤§åŒ–ã™ã‚‹äº‹ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚ã¤ã¾ã‚Šã€åˆ†é¡ã—ã¦ã„ã‚‹ã®ã§ã™ã€‚\n</p><img src= \"https://miro.medium.com/max/724/0*hUAVXd1XaQSsrK-9.png\" alt =\"Titanic\" style=\"height: 450px; width:auto; align: center;\">","metadata":{}},{"cell_type":"code","source":"model = svm.SVC(kernel = 'linear', C = 0.1, gamma = 0.1)\nmodel.fit(train_X, train_Y)\npre2 = model.predict(test_X)\nprint('accuracy: ', metrics.accuracy_score(pre2, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:21:41.334546Z","iopub.execute_input":"2021-08-29T05:21:41.334916Z","iopub.status.idle":"2021-08-29T05:21:41.366292Z","shell.execute_reply.started":"2021-08-29T05:21:41.334848Z","shell.execute_reply":"2021-08-29T05:21:41.364973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style = \"font-size:20px\">Radial Support Vector Machine</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€In the above, we have set kernel to linear. This is linear separation. Actually, there is one more thing. It is <b>rbf</b>.<br>ã€€This caputures non-linear data as a high dimensional space using kernel trick.<br>-----<br>ã€€ä¸Šã§ã¯ã€kernelã‚’linearã«ã—ã¾ã—ãŸã€‚ç·šå½¢åˆ†é›¢ã§ã™ã€‚å®Ÿã¯ã‚‚ã†ä¸€ã¤ã‚ã‚Šã¾ã™ã€‚rbfã§ã™ã€‚ã“ã‚Œã¯ã€éç·šå½¢ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã€ã‚«ãƒ¼ãƒãƒ«ãƒˆãƒªãƒƒã‚¯ã¨ä½¿ã£ã¦åˆ†é›¢è¶…å¹³é¢ã‚’é«˜æ¬¡å…ƒç©ºé–“ã«ã—ã¦æ‰ãˆã¾ã™ã€‚<br><br>\n    <img src= \"https://miro.medium.com/max/1050/0*ngkO1BblQXnOTcmr.png\" alt =\"Titanic\" style=\"height: 300px; width:auto; align: center;\">\n    <br><br>ã€€And, if we put a line between red and blue using projection function, we have classified them. <br>-----<br>ã€€ã‚ã¨ã¯ã€å°„å½±é–¢æ•°ã‚’ä½¿ã£ã¦èµ¤ã¨é’ã®é–“ã«ç·šã‚’å…¥ã‚Œã‚Œã°ã€åˆ†é¡ã§ããŸã“ã¨ã«ãªã‚Šã¾ã™ã­ã€‚</p>","metadata":{}},{"cell_type":"code","source":"model = svm.SVC(kernel='rbf',C=1,gamma=0.1)\nmodel.fit(train_X,train_Y)\npre3 = model.predict(test_X)\nprint('Accuracy for rbf SVM is ',metrics.accuracy_score(pre3,test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:39:14.728106Z","iopub.execute_input":"2021-08-29T05:39:14.728504Z","iopub.status.idle":"2021-08-29T05:39:14.762271Z","shell.execute_reply.started":"2021-08-29T05:39:14.728469Z","shell.execute_reply":"2021-08-29T05:39:14.761399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_combined.iloc[:, 0].min()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:32.233488Z","iopub.execute_input":"2021-06-29T09:26:32.23395Z","iopub.status.idle":"2021-06-29T09:26:32.240274Z","shell.execute_reply.started":"2021-06-29T09:26:32.233921Z","shell.execute_reply":"2021-06-29T09:26:32.239168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style = \"font-size:20px\">Decision Tree</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Decision tree classifiers are powerful when to consider semantic interpretability. As the name suggests, it classifies data by the way it makes decisions on a series of questions. So let's take a look!<br>-----<br>ã€€ã€€æ±ºå®šæœ¨åˆ†é¡å™¨ã¯ã€æ„å‘³è§£é‡ˆå¯èƒ½æ€§ã«é…æ…®ã™ã‚‹å ´åˆã«åŠ›ã‚’ç™ºæ®ã—ã¾ã™ã€‚åå‰ã®é€šã‚Šã€ä¸€é€£ã®è³ªå•ã«å¯¾ã—ã¦æ±ºå®šã‚’ä¸‹ã™ã¨ã„ã†æ–¹æ³•ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é¡ã™ã‚‹ã€‚<br><br><img src= \"https://www.cs.cmu.edu/~bhiksha/courses/10-601/decisiontrees/DT.png\" alt =\"Titanic\" style=\"height: 300px; width:auto; align: left;\"></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n  ã€€In this case, it ask questions such as \"Is the gender male?\", \"Is the Fare more over 60.0?\" and so on, and divide the data by the feture with the greatest information gain. This is repeated until a leaf node appears.\nThe information gain is the smallness of variation in the elements of the segmented set, and the data is segmented by the feature that maximizes this value.\nIn the next section, we will see about the information gain.<br>-----<br>ã€€ä»Šå›ã®å ´åˆã¯ã€ã€Œæ€§åˆ¥ã¯ç”·æ€§ã‹ã€‚ã€ã€ŒFareã¯60.0ä»¥ä¸Šã‹ã€ç­‰ã¨è³ªå•ã—ã¦ã„ãã€æƒ…å ±åˆ©å¾—ãŒæœ€å¤§ã¨ãªã‚‹ç‰¹å¾´é‡ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹ã€‚è‘‰ãƒãƒ¼ãƒ‰ãŒè¡¨ã‚Œã‚‹ã¾ã§ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚<br>ã€€æƒ…å ±åˆ©å¾—ã¨ã¯ã€åˆ†å‰²ã•ã‚ŒãŸé›†åˆã®è¦ç´ ã«ã¤ã„ã¦ã®ã°ã‚‰ã¤ãã®å°‘ãªã•ã®äº‹ã§ã‚ã‚Šã€ã“ã‚ŒãŒæœ€å¤§ã«ãªã‚‹ç‰¹å¾´é‡ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚<br>ã€€æ¬¡ã§ã¯ã€æƒ…å ±åˆ©å¾—ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n  ã€€In order to devide the nodes by the features that is the highest information gain, we need to define the objective function that we want to optimize in the decision tree learning algorithm. Again, I represent it in a general form.<br>-----<br>ã€€æœ€ã‚‚æƒ…å ±åˆ©å¾—ã®é«˜ã„ç‰¹å¾´é‡ã§ãƒãƒ¼ãƒ‰ã‚’åˆ†å‰²ã™ã‚‹ã«ã¯ã€æ±ºå®šæœ¨å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãŠã„ã¦æœ€é©åŒ–ã®å¯¾è±¡ã¨ã—ãŸã„ç›®çš„é–¢æ•°ã‚’å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä»Šå›ã‚‚ã€ä¸€èˆ¬çš„ãªå½¢ã§è¡¨ã—ã¾ã™ã€‚</p><br> æƒ…å ±åˆ©å¾—ã®å¼ <br>ã€€<ul><li>fï¼šfeature to be segmented\n<li>Dpï¼šparent dataset\n<li>Djï¼šdataset of jth child node\n<li>Iï¼šimpurity<br><br>\n\nã€€In short, information gain is just the sum of the \"impurity of parent node\" and the \"impurity of child node\".<br>-----<br>ã€€\n    <li>fï¼šåˆ†å‰²ã‚’è¡Œã†ç‰¹å¾´é‡</li>\n    <li>Dpï¼šè¦ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</li>\n    <li>Djï¼šjç•ªç›®ã®å­ãƒãƒ¼ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</li>\n    <li>Iï¼šä¸ç´”åº¦</li><br>ã§ã‚ã‚‹ã€‚è¦ã¯ã€æƒ…å ±åˆ©å¾—ã¯ã€Œè¦ªãƒãƒ¼ãƒ‰ã®ä¸ç´”åº¦ã€ã¨ã€Œå­ãƒãƒ¼ãƒ‰ã®ä¸ç´”åº¦ã€ã®åˆè¨ˆã«éããªã„ã€‚","metadata":{}},{"cell_type":"markdown","source":"<math>\n    <script src=\n\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n</script>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n  ã€€\n     There are two indicators of impurity: <b>Gini impurity</b> and <b>entropy</b>. Gini impurity is denoted by IG, and entropy by IH.<br>-----<br>ã€€ä¸ç´”åº¦ã®æŒ‡æ¨™ã«ã¯ã€ã€Œã‚¸ãƒ‹ä¸ç´”åº¦ã€ã¨ã€Œã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã€ãŒã‚ã‚Šã¾ã™ã€‚ã‚¸ãƒ‹ä¸ç´”åº¦ã¯$I_{G}$ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¯$I_{H}$ã§è¡¨è¨˜ã—ã¾ã™ã€‚<br>ã€€\n$$I_{H}(t) = -\\sum_{i=1}^cp(i|t)\\log_2p(i|t)$$\n    <br>ã€€ã€€p(i|t) is the percentage of data points belonging to class i at a particular node t. Thus, if all the data points of a node belong to the same class, the entropy is zero. In  binary classification, it is the case when p(i = 1|t) = 1 or p(i = 0|t) = 0.<br>ã€€\nOn the other hand, the entropy is maximum (1 in the case of binary classification) when p(i|t) are equal to each other, i.e., when each class is uniformly distributed. In other words, p(i = 1|t) = 0.5 or p(i = 0|t) = 0.5. <br>ã€€Therefore, we can say that entropy is a condition that tries to maximize the interdependence of two probabilities.<br>-----<br>ã€€p(i|t)ã¯ã€ç‰¹å®šã®ãƒãƒ¼ãƒ‰tã«ãŠã„ã¦ã‚¯ãƒ©ã‚¹iã«æ‰€å±ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ç‚¹ã®å‰²åˆã§ã™ã€‚ã‚ˆã£ã¦ã€ãƒãƒ¼ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ç‚¹ãŒã™ã¹ã¦åŒã˜ã‚¯ãƒ©ã‚¹ã®æ‰€å±ã—ã¦ã„ã‚‹å ´åˆã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¯0ã§ã™ã€‚äºŒå€¤åˆ†é¡ã§ã¯ã€p(i = 1|t) = 1ã¾ãŸã¯ã€p(i = 0|t) = 0ã®å ´åˆã§ã™ã€‚<br>ã€€é€†ã«ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒæœ€å¤§ï¼ˆäºŒå€¤åˆ†é¡ã®å ´åˆã€1ï¼‰ã«ãªã‚‹ã®ã¯ã€p(i|t)åŒå£«ãŒåŒã˜å€¤ã§ã‚ã‚‹ã“ã¨ã€ã™ãªã‚ã¡å„ã‚¯ãƒ©ã‚¹ãŒä¸€æ§˜ã«åˆ†å¸ƒã—ã¦ã„ã‚‹å ´åˆã§ã™ã€‚ã¤ã¾ã‚Šp(i = 1|t) = 0.5ã¾ãŸã¯ã€p(i = 0|t) = 0.5ã®å ´åˆã§ã™ã€‚ã‚ˆã£ã¦ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¯äºŒã¤ã®ç¢ºç‡ã®ç›¸äº’ä¾å­˜åº¦ãŒæœ€å¤§ã«ãªã‚‹ã‚ˆã†è©¦ã¿ã‚‹æ¡ä»¶ã®äº‹ã¨è¨€ãˆã¾ã™ã€‚</p></math>","metadata":{}},{"cell_type":"markdown","source":"<math>\n    <script src=\n\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n</script>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n# In the case of Gini impurity, this is as follows.<br>-----<br>ã€€ã‚¸ãƒ‹ä¸ç´”åº¦ã®å ´åˆã ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã€€$$I_{G}(t) = \\sum_{i=1}^cp(i|t)(1 - p(i|t)) = 1 - \\sum_{i=1}^cp(i|t)^2$$<br><br>ã€€This time, if we put the N as sample num of training data and ni as the num of training data that belongs to class i, then we can represent it p(i|t)=niN, so it will looks like this.<br>-----<br>ã€€ä»Šå›ã€Nã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã€niã‚’ã‚¯ãƒ©ã‚¹iã«å±ã™ã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æ•°ã¨ã™ã‚‹ã¨ã€$p(i|t) = \\frac{ni}{N}$ã€€ã¨ç½®ã‘ã‚‹ã®ã§ã€$$I_{G}(t) = 1 - \\frac{1}{N}$$<br>ã€€Therefore, we can see that when Gini impurity is maximized, it will approximate to 1.<br>-----<br>ã€€ã€€ã¨ãªã‚Šã¾ã™ã€‚ã‚ˆã£ã¦ã€ã‚¸ãƒ‹ä¸ç´”åº¦ãŒæœ€å¤§ã¨ãªã‚‹å ´åˆã€1ã«è¿‘ä¼¼ã—ã¦ã„ãã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚</p></math>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€ã€€But in fact, entropy and Gini impurity often have similar results. The conditions for maximum and minimum are similar, so it is better to spend time pruning the decision tree than to try to decide which one to use.<br>-----<br>ã€€ã§ã™ãŒå®Ÿéš›ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¨ã‚¸ãƒ‹ä¸ç´”åº¦ã¯ä¼¼ãŸçµæœã¨ãªã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚æœ€å¤§æœ€å°ã«ãªã‚‹æ¡ä»¶ãŒä¼¼ã¦ã¾ã™ã®ã§ã€ã©ã£ã¡ã‚’ä½¿ã†ã‹ã«æ™‚é–“ã‚’ä½¿ã†ã‚ˆã‚Šã‹ã¯æ±ºå®šæœ¨ã®å‰ªå®šã«æ™‚é–“ã‚’ã‹ã‘ãŸã»ã†ãŒè‰¯ã„ã§ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Just in case, let's take a look at it visually.<br>-----<br>ã€€ä¸€å¿œã€è¦–è¦šçš„ã«ã‚‚è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"def gini(p):\n    return (p) * (1 - (p)) + (1 - p) * (1 - (1 - p))\n\ndef entropy(p):\n    return - p * np.log2(p) - (1 - p) * np.log2((1 - p))\n\nx = np.arange(0.0, 1.0, 0.01)\nent = [entropy(p) if p != 0 else None for p in x]\n#entropy scaling ver\nsc_ent = [e * 0.5 if e else None for e in ent]\n\nfig = plt.figure()\nax = plt.subplot(111)\n\nfor va, la, ls, co in zip([ent, sc_ent, gini(x)], ['Entropy', 'Scaled_Entropy', 'Gini inpurity'], ['-', '--', '-.'], ['blue', 'red', 'green']):\n    line = ax.plot(x, va,label = la, linestyle = ls, color = co, lw = 2)\n\nax.legend(loc = 'upper center', bbox_to_anchor = (0.5, 1.15), ncol = 5, fancybox = True, shadow = False)\nax.axhline(y = 0.5, linewidth = 1, color = 'k', linestyle = '--')\nax.axhline(y = 1.0, linewidth = 1, color = 'k', linestyle = '--')\n\nplt.ylim([0, 1.1])\nplt.xlabel('p(i = 1)')\nplt.ylabel('impurity index')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T18:43:37.208816Z","iopub.execute_input":"2021-08-28T18:43:37.209218Z","iopub.status.idle":"2021-08-28T18:43:37.399024Z","shell.execute_reply.started":"2021-08-28T18:43:37.209171Z","shell.execute_reply":"2021-08-28T18:43:37.397953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DecisionTreeClassifier(\n    criterion = 'gini',# or criterion = 'entropy'\n    max_depth = 11, random_state = 1)\nmodel.fit(train_X, train_Y)\npre4 = model.predict(test_X)\nprint(metrics.accuracy_score(pre4, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:21:57.68201Z","iopub.execute_input":"2021-08-29T05:21:57.682445Z","iopub.status.idle":"2021-08-29T05:21:57.701092Z","shell.execute_reply.started":"2021-08-29T05:21:57.682408Z","shell.execute_reply":"2021-08-29T05:21:57.699194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€We've done it. Also, scikit-learn has a function to visualize the trained decision tree model. This time we narrowing down the number of features to four for easier viewing to see the trained result.<br>-----<br>ã€€å‡ºæ¥ã¾ã—ãŸã­ã€‚ã¾ãŸã€scikit-learnã«ã¯ã€è¨“ç·´ã•ã‚ŒãŸæ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã‚’å¯è¦–åŒ–ã™ã‚‹æ©Ÿèƒ½ãŒã‚ã‚Šã¾ã™ã€‚ä»Šå›ã¯è¦‹ã‚„ã™ã„ã‚ˆã†ã«ç‰¹å¾´é‡ã‚’4ã¤ã«çµã‚Šã€ã‚‚ã†ä¸€åº¦è¨“ç·´ã—ãŸçµæœã‚’ç¤ºã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"from sklearn import tree\nimport sys\n\nselector = SelectKBest(score_func = f_regression, k = 5)\nselector.fit(train__X, train__y)\nmask = selector.get_support()\nva = data_.columns.drop('Survived')[mask]\ntrain_data__ = train_data[va]\n\ntrain__, _ = train_test_split(train_data__, test_size = 0.1, random_state = 0, stratify = train_data['Survived'])\ntrain_X_ = train__[train__.columns[1:]]\ntrain_Y_ = train__[train__.columns[:1]]\n\nmodel = DecisionTreeClassifier()\nmodel.fit(train_X_, train_Y_)\n\ntree.plot_tree(model)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:22:32.007502Z","iopub.execute_input":"2021-08-29T05:22:32.007924Z","iopub.status.idle":"2021-08-29T05:22:32.542542Z","shell.execute_reply.started":"2021-08-29T05:22:32.007885Z","shell.execute_reply":"2021-08-29T05:22:32.541032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€It is easy to see!<br>ã€€\nIt's hard to see when there is a lot of features like this time, but when there's not much, it's very useful!<br>-----<br>ã€€è¦‹ã‚„ã™ã„ã§ã™ã‚ˆã­ï¼<br>ã€€ä»Šå›ã¿ãŸã„ã«ç‰¹å¾´é‡ãŒå¤šã„ã¨è¦‹ãˆã¥ã‚‰ã„ã§ã™ãŒã€å°‘ãªã„æ™‚ã«ã¯ã¨ã¦ã‚‚å½¹ã«ç«‹ã¡ãã†ã§ã™ï¼ï¼</p>","metadata":{}},{"cell_type":"markdown","source":"<a id = 'section16'></a>\n# <b style = \"font-size:20px\">Random Forest</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nIn explaining RandomForest, I will explain some words that come up. <br>ã€€\n<li><b>Ensemble learning</b>: A learning method that achieve high generalization performance by combining multiple machine learning models. In simple terms, it is the same ideas as incorporating the opinions of ten people is more robust than the opinion of one person.<br>ã€€\n<li><b>Bootstrap sampling</b>: This is a method of sampling from a single sample set allowing duplicates, and creating a new sample set. Since duplicates are allowed, some data may not be selected, and this is called OOB (Out Of Bag).<br>-----<br>RandomForestã‚’èª¬æ˜ã™ã‚‹ã«ã‚ãŸã‚Šã€ã§ã¦ãã‚‹å˜èªã‚’èª¬æ˜ã—ã¾ã™ã€‚\n<ul>\n    <li><b>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’</b>ï¼šè¤‡æ•°ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€é«˜ã„æ±åŒ–æ€§èƒ½ã‚’å®Ÿç¾ã™ã‚‹å­¦ç¿’æ³•ã€‚ç°¡å˜ã«è€ƒãˆã‚Œã°ã€ä¸€äººã®æ„è¦‹ã‚ˆã‚Šåäººã®æ„è¦‹ã‚’å–ã‚Šå…¥ã‚ŒãŸã»ã†ãŒé ‘å¥ãªã‚‚ã®ã«ãªã‚‹ã®ã¨åŒã˜è€ƒãˆã§ã™ã€‚</li>\n    <li><b>ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—</b>ï¼šå…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸€ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒæŠ½å‡ºã¨ã„ã†ã‚„ã‚Šæ–¹ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚</li>\n</ul>ã€€<img src= \"https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png\" alt =\"Titanic\" style=\"height: 450px; width:auto; align: left;\"><br>ã€€RandomForest can be thought of as ensemble of decision trees. By averaging multiple decision trees that each of which has a high variance, we can build a model with higher generalization performance and robustness against overlearning.<br>ã€€The procedure is as follows. <ul>\n    <li>ï¼‘ï¼Sampling random bootstrap sample of size n with replacement. (Select n data points randomly from train dataset.)</li>\n    <li>ï¼’ï¼Grow a decision tree from bootstrap sample. And do the following tasks at each of its nodes.</li>\n        <ul>\n            <li>2.1ã€€Extract d features randomly non-replacement.</li>\n            <li>2.2ã€€By maximize the information gain, the nodes are devided using features that result in an optimal division according to the objective function.</li>\n        </ul>\n    <li>ï¼“ï¼Repeat steps 1-2 k times.</li>\n    <li>ï¼”ï¼Summarize the predictions for each decision tree and assign class labels based on the majority vote.</li>\n<br>ã€€Let's use it in practice.<br>-----<br>ã€€\n\n</ul><br>\nã€€RandomForestã¯ã€æ±ºå®šæœ¨ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¨ã¿ãªã›ã¾ã™ã€‚ãã‚Œãã‚Œãƒãƒªã‚¢ãƒ³ã‚¹ãŒé«˜ã„è¤‡æ•°ã®æ±ºå®šæœ¨ã‚’å¹³å‡åŒ–ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ±åŒ–æ€§èƒ½ãŒé«˜ãéå­¦ç¿’ã«å¯¾ã—ã¦å …ç‰¢ãªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚<br>ã€€æ‰‹é †ã¯ä»¥ä¸‹ã®4ã¤ã§ã™ã€‚<ul>\n    <li>ï¼‘ï¼ã‚µã‚¤ã‚ºnã®ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ–ãƒ¼ã‚¹ãƒˆãƒ©ãƒƒãƒ—æ¨™æœ¬ã‚’å¾©å…ƒæŠ½å‡ºã—ã¾ã™ã€‚ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰nå€‹ã®ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹ã€‚ï¼‰</li>\n    <li>ï¼’ï¼ãƒ–ãƒ¼ã‚¹ãƒˆãƒ©ãƒƒãƒ—æ¨™æœ¬ã‹ã‚‰æ±ºå®šæœ¨ã‚’æˆé•·ã•ã›ã¾ã™ã€‚ãã®å„ãƒãƒ¼ãƒ‰ã§ä»¥ä¸‹ã®ä½œæ¥­ã‚’ã—ã¾ã™ã€‚</li>\n        <ul>\n            <li>2.1ã€€då€‹ã®ç‰¹å¾´é‡ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«éå¾©å…ƒæŠ½å‡ºã—ã¾ã™ã€‚</li>\n            <li>2.2ã€€æƒ…å ±åˆ©å¾—ã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã€ç›®çš„é–¢æ•°ã«å¾“ã£ã¦æœ€é©ãªåˆ†å‰²ã¨ãªã‚‹ç‰¹å¾´é‡ã‚’ä½¿ã£ã¦ãƒãƒ¼ãƒ‰ã‚’åˆ†å‰²ã™ã‚‹ã€‚</li>\n        </ul>\n    <li>ï¼“ï¼æ‰‹é †1~2ã‚’kå›ç¹°ã‚Šè¿”ã™ã€‚</li>\n    <li>ï¼”ï¼æ±ºå®šæ©Ÿã”ã¨ã®äºˆæ¸¬ã‚’ã¾ã¨ã‚ã€å¤šæ•°æ±ºã«åŸºã¥ã„ã¦ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€‚</li>\n\n</ul><br>\nã€€å®Ÿéš›ã«ä½¿ã£ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"#ã‚¸ãƒ‹ä¸ç´”åº¦ã‚’æŒ‡æ¨™ã¨ã™ã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ\nmodel = RandomForestClassifier(criterion = 'gini', n_estimators = 22)\nmodel.fit(train_X, train_Y)\npre4_ = model.predict(test_X)\nprint(metrics.accuracy_score(pre4_, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:38:08.082886Z","iopub.execute_input":"2021-08-29T07:38:08.083242Z","iopub.status.idle":"2021-08-29T07:38:08.151451Z","shell.execute_reply.started":"2021-08-29T07:38:08.083213Z","shell.execute_reply":"2021-08-29T07:38:08.150037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€As for entropy, try it for yourself! However, gini impurity is often used as the default, and I had the impression that gini scores better in my hands.<br>\nWe'll see about ensemble including Randomforest later.<br>-----<br>ã€€entropyã¯ã€è‡ªåˆ†ã§è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼ã§ã™ãŒã€ã‚¸ãƒ‹ä¸ç´”åº¦ãŒå¤šããƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦æ¡ç”¨ã•ã‚Œã¦ã„ã‚‹åˆ†ã€è‡ªåˆ†ã®æ‰‹å…ƒã§ã‚‚giniã®æ–¹ãŒã‚¹ã‚³ã‚¢ãŒé«˜ã„å°è±¡ã§ã—ãŸã€‚<br>ã€€RandomForestã‚’ã¯ã˜ã‚ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«é–¢ã—ã¦ã¯ã€å¾Œã«è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"markdown","source":"# <b style = \"font-size:20px\">K-Nearest neighbor classifier (KNN)</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€KNN is a prime example of lazy learning.  Lazy is, not because of its apparent simplicity, but because it memorize the training dataset without learning discriminant function from training data. A discriminant function is a function that maps an input to a class label.<br>ã€€\nPerceptron, logistic regression, and linear SVM are called parametric models, which estimate parameters from train dataset. On the contrary, KNN belongs to the subcategory of non-parametric models an d is called instance-based learning. This has features that memorize train dataset and its train process cost is zero. It can also be used for both classification and regression. <br>ã€€\nThe procedure for the KNN algorithm is as simple as follows.\n<ul>\n<li>1. Select a value of k and a distance index.</li>\n<li>2. Find k nearest neighbor data point from the data point to be classified. </li>\n<li>3. Assign class labels by majority vote.</li>\n</ul><br>-----<br>ã€€KNNã¯<b>æ€ æƒ°å­¦ç¿’</b>ã®ä»£è¡¨çš„ãªä¾‹ã§ã™ã€‚æ€ æƒ°ã¨ã„ã†ã®ã¯ã€ãã®è¦‹ã‹ã‘ã®å˜ç´”ã•ã¨ã„ã†ã‚ˆã‚Šã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆ¤åˆ¥é–¢æ•°ã‚’å­¦ç¿’ã›ãšã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æš—è¨˜ã™ã‚‹ãŸã‚ã§ã™ã€‚åˆ¤åˆ¥é–¢æ•°ã¯ã€å…¥åŠ›ã‚’ç›´æ¥ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã«å¯¾å¿œã•ã›ã‚‹é–¢æ•°ã®ã“ã¨ã§ã™ã€‚<br>ã€€ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã€ç·šå½¢SVMã¯ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã¨å‘¼ã°ã‚Œã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šã™ã‚‹ã‚‚ã®ã§ã™ã€‚é€†ã«KNNã¯ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã«å±ã—ã¦ãŠã‚Šã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«åŸºã¥ãå­¦ç¿’ã¨å‘¼ã°ã‚Œã¾ã™ã€‚è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¨˜æ†¶ã—ã€å­¦ç¿’éç¨‹ã®ã‚³ã‚¹ãƒˆãŒ0ã¨ã„ã†ç‰¹å¾´ãŒã‚ã‚‹ã€‚ã¾ãŸã€åˆ†é¡ã¨å›å¸°ã®ã©ã¡ã‚‰ã«ã‚‚åˆ©ç”¨ã§ãã¾ã™ã€‚<br>ã€€KNNã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ‰‹é †ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå˜ç´”ãªã‚‚ã®ã§ã™ã€‚\n<ul>\n    <li>ï¼‘ï¼kã®å€¤ã¨è·é›¢æŒ‡æ¨™ã‚’é¸æŠã™ã‚‹ã€‚</li>\n    <li>ï¼’ï¼åˆ†é¡ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ç‚¹ã‹ã‚‰kå€‹ã®æœ€æ–°å‚ã®ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’è¦‹ã¤ã‘å‡ºã™ã€‚</li>\n    <li>ï¼“ï¼å¤šæ•°æ±ºã«ã‚ˆã‚Šã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€‚</li>\n</ul>\n\n  <br><img src= \"https://helloacm.com/wp-content/uploads/2016/03/2012-10-26-knn-concept.png\" alt =\"Titanic\" style=\"height: 300px; width:auto; align: left;\"></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€In this case, the data represented by the star is classified into class B. Let's use it in practice.<br>-----<br>ã€€ã“ã®å ´åˆã€æ˜Ÿã§è¡¨ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã‚¯ãƒ©ã‚¹Bã«åˆ†é¡ã•ã‚Œã¾ã™ã€‚å®Ÿéš›ã«ä½¿ã£ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors = 10)\nmodel.fit(train_X, train_Y)\npre5 = model.predict(test_X)\nprint(metrics.accuracy_score(pre5, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:22:45.266388Z","iopub.execute_input":"2021-08-29T05:22:45.267045Z","iopub.status.idle":"2021-08-29T05:22:45.298458Z","shell.execute_reply.started":"2021-08-29T05:22:45.266995Z","shell.execute_reply":"2021-08-29T05:22:45.297041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style = \"font-size:20px\">Gaussian Naive Bayes</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€<img src= \"https://iq.opengenus.org/content/images/2020/02/Illustration-of-how-a-Gaussian-Naive-Bayes-GNB-classifier-works-For-each-data-point.png\" alt =\"Titanic\" style=\"height: 300px; width:auto; align: left;\"><br><br>ã€€When dealing with continuous data, it is often assumed that the continuous values of each class are distributed according to a normal (or gaussian) distribution. The likelihood is as follows.<br>-----<br>ã€€é€£ç¶šãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†å ´åˆã€å„ã‚¯ãƒ©ã‚¹ã®é€£ç¶šå€¤ãŒæ­£è¦åˆ†å¸ƒï¼ˆã¾ãŸã¯ã‚¬ã‚¦ã‚¹åˆ†å¸ƒï¼‰ã«å¾“ã£ã¦åˆ†å¸ƒã—ã¦ã„ã‚‹ã¨ä»®å®šã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚å°¤åº¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚<math>\n    <script src=\n\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n</script>\n<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n$$P(x_i|y)\\frac{1}{\\sqrt{2\\pi\\sigma_y^2}}\\exp(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y})$$</math><br>ã€€Gaissian Naive Bayes supports continuous value features and models each one to fit a Gaussian distribution.<br>ã€€\nThe figure above shows how the Gaussian Naive Bayes Classifier works. <br>ã€€\nFor every data points, the point and respective class mean z-score distance is calculated. In other words, it is the distance from the class average divided by the standard deviation of the class. <br>-----<br>ã€€Gaussian Naive Bayesã¯é€£ç¶šå€¤ã®ç‰¹å¾´ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ãã‚Œãã‚Œã‚’ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã«é©åˆã™ã‚‹ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚<br>ã€€ä¸Šå›³ã¯ã€Gaussian Naive Bayesåˆ†é¡å™¨ãŒã©ã®ã‚ˆã†ã«å‹•ãã‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ç‚¹ã§ã€ãã®ãƒã‚¤ãƒ³ãƒˆã¨ãã‚Œãã‚Œã®ã‚¯ãƒ©ã‚¹å¹³å‡ã®z-scoreè·é›¢ãŒè¨ˆç®—ã•ã‚Œã¾ã™ã€‚ã™ãªã‚ã¡ã€ã‚¯ãƒ©ã‚¹å¹³å‡ã‹ã‚‰ã®è·é›¢ã‚’ãã®ã‚¯ãƒ©ã‚¹ã®æ¨™æº–åå·®ã§å‰²ã£ãŸã‚‚ã®ã«ãªã‚Šã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"model = GaussianNB()\nmodel.fit(train_X, train_Y)\npre6 = model.predict(test_X)\nprint(metrics.accuracy_score(pre6, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:22:48.764982Z","iopub.execute_input":"2021-08-29T05:22:48.765372Z","iopub.status.idle":"2021-08-29T05:22:48.778189Z","shell.execute_reply.started":"2021-08-29T05:22:48.765339Z","shell.execute_reply":"2021-08-29T05:22:48.777013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style = \"font-size:20px\">Are you going to determine the hyperparameters manually?</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€SVM's C and gamma, and Random Forest's n_estimators are what set the behavior of the classification model. We have to tell it what to do. However, it takes time to test each one for accuracy. <br>ã€€\nSo, we use <b>Optuna</b>. This will search for the best hyperparameters for you.<br>ã€€\nLet's try it with <b>rbf</b>. <br>-----<br>ã€€SVMã®Cã‚„gammaã€RandomForestã®n_estimatorsã¯ã€åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ã‚’è¨­å®šã™ã‚‹ã‚‚ã®ã§ã™ã€‚ãã‚Œã¯ã€ã“ã¡ã‚‰ã‹ã‚‰æŒ‡ç¤ºã—ã¦ã‚ã’ãªã„ã¨ã„ã‘ã¾ã›ã‚“ã€‚ãªã®ã§ã™ãŒã€ç²¾åº¦ã®è‰¯ã„ã‚‚ã®ã‚’ä¸€ã¤ä¸€ã¤è©¦ã™ã®ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚<br>ã€€ãã“ã§ã€Optunaã‚’ä½¿ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢ã—ã¦ãã‚Œã¾ã™ã€‚<br>ã€€è©¦ã—ã«rbfã§ã‚„ã£ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"import optuna\n\ndef objective(trial):\n    params = {\n        'kernel': 'rbf',\n        'C': trial.suggest_loguniform('C', 1e-10, 1e10),\n        'gamma': trial.suggest_loguniform('gamma', 1e-10, 3.0)\n    }\n    model_ = svm.SVC(**params)\n    model_.fit(train_X, train_Y)\n    pre = model_.predict(test_X)\n    acc = metrics.accuracy_score(pre, test_Y)\n    score = 1 - acc\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:46:53.892276Z","iopub.execute_input":"2021-08-29T05:46:53.89285Z","iopub.status.idle":"2021-08-29T05:46:53.899431Z","shell.execute_reply.started":"2021-08-29T05:46:53.892812Z","shell.execute_reply":"2021-08-29T05:46:53.898262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The execution result is long, so please skip to <a href = '#section029'> here</a>.","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(sampler = optuna.samplers.RandomSampler(seed = 0))\nstudy.optimize(objective, n_trials = 100)\nprint(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:46:55.069165Z","iopub.execute_input":"2021-08-29T05:46:55.069561Z","iopub.status.idle":"2021-08-29T05:48:44.516157Z","shell.execute_reply.started":"2021-08-29T05:46:55.069526Z","shell.execute_reply":"2021-08-29T05:48:44.514604Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\"><a id = \"section029\">ã€€</a>Using this, let's look at the classification results again.<br>-----<br>ã€€ã“ã‚Œã‚’ä½¿ã£ã¦ã€ã‚‚ã†ä¸€åº¦åˆ†é¡çµæœã‚’ã¿ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"model = svm.SVC(kernel='rbf', C = 2164.383970701054, gamma = 0.001062561994257736)\nmodel.fit(train_X, train_Y)\npre_3 = model.predict(test_X)\nprint('Accuracy for rbf SVM is ', metrics.accuracy_score(pre_3, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:49:14.86052Z","iopub.execute_input":"2021-08-29T05:49:14.860969Z","iopub.status.idle":"2021-08-29T05:49:14.960656Z","shell.execute_reply.started":"2021-08-29T05:49:14.860933Z","shell.execute_reply":"2021-08-29T05:49:14.959615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€It's getting high!! Let's look at something else.<br>-----<br>ã€€é«˜ããªã‚Šã¾ã—ãŸï¼ï¼æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§ã€ä»–ã«ã‚‚è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"import optuna\n\ndef objective2(trial):\n    params = {\n        'n_neighbors': trial.suggest_int('n_neighbors', 1.0, 100.0)\n    }\n    model = KNeighborsClassifier(**params)\n    model.fit(train_X, train_Y)\n    pre = model.predict(test_X)\n    acc = metrics.accuracy_score(pre, test_Y)\n    score = 1 - acc\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:27:19.316037Z","iopub.execute_input":"2021-08-29T05:27:19.316542Z","iopub.status.idle":"2021-08-29T05:27:19.322615Z","shell.execute_reply.started":"2021-08-29T05:27:19.31651Z","shell.execute_reply":"2021-08-29T05:27:19.321515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The execution result is also long, so please skip to <a href = '#section030'> here</a>.","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(sampler = optuna.samplers.RandomSampler(seed = 0))\nstudy.optimize(objective2, n_trials = 100)\nprint(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:27:20.614604Z","iopub.execute_input":"2021-08-29T05:27:20.615028Z","iopub.status.idle":"2021-08-29T05:27:23.407882Z","shell.execute_reply.started":"2021-08-29T05:27:20.614995Z","shell.execute_reply":"2021-08-29T05:27:23.406472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"section030\"></a>","metadata":{}},{"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors = 22)\nmodel.fit(train_X, train_Y)\npre_4 = model.predict(test_X)\nprint(metrics.accuracy_score(pre_4, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:28:00.196159Z","iopub.execute_input":"2021-08-29T05:28:00.19702Z","iopub.status.idle":"2021-08-29T05:28:00.230163Z","shell.execute_reply.started":"2021-08-29T05:28:00.196976Z","shell.execute_reply":"2021-08-29T05:28:00.229071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective3(trial):\n    params = {\n        'C': trial.suggest_loguniform('C', 1e-10, 1e10)\n    }\n    model = LogisticRegression(**params)\n    model.fit(train_X, train_Y)\n    pre = model.predict(test_X)\n    acc = metrics.accuracy_score(pre, test_Y)\n    score = 1 - acc\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:47:46.021976Z","iopub.execute_input":"2021-08-29T07:47:46.022413Z","iopub.status.idle":"2021-08-29T07:47:46.029507Z","shell.execute_reply.started":"2021-08-29T07:47:46.022379Z","shell.execute_reply":"2021-08-29T07:47:46.027991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The execution result is also long, so please skip to <a href = '#section031'> here</a>.","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(sampler = optuna.samplers.RandomSampler(seed = 0))\nstudy.optimize(objective3, n_trials = 100)\nprint(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:47:47.057263Z","iopub.execute_input":"2021-08-29T07:47:47.057656Z","iopub.status.idle":"2021-08-29T07:47:50.815743Z","shell.execute_reply.started":"2021-08-29T07:47:47.057623Z","shell.execute_reply":"2021-08-29T07:47:50.813945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"section031\"></a>","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression(C = 9.468257892380656)\nmodel.fit(train_X, train_Y)\npre_5 = model.predict(test_X)\nprint(metrics.accuracy_score(pre_5, test_Y))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:50:49.808182Z","iopub.execute_input":"2021-08-29T07:50:49.808545Z","iopub.status.idle":"2021-08-29T07:50:49.884136Z","shell.execute_reply.started":"2021-08-29T07:50:49.808516Z","shell.execute_reply":"2021-08-29T07:50:49.883061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">ã€€This is getting high too! But, there is also a problem with this.<br>-----<br>ã€€ã“ã‚Œã‚‚é«˜ããªã‚Šã¾ã—ãŸï¼ï¼ã§ã™ãŒã€ã“ã‚Œã«ã‚‚å•é¡ŒãŒã‚ã‚‹ã®ã§ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"# <b style = \"font-size:20px\">Problems on Data Partitioning</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€When evaluating different settings of estimators, for example when determining the argument: n_estimators of RandomForest, there is a possibility of overtraining on the testset because the parameters can be adjusted until the estimator is optimal. <br>ã€€So, the solution is to prepare another part of the dataset as the validation data, train with the training data, then evaluate with the validation data, and when the experienment is successful, do the final evaluation with the test set.<br>ã€€\nThis is where Cross Validation is used. We'll see this using a diagram. There are three steps. <ul>\n<li>1. Train the model using k-1 pieces of training data.\n<li>2. The model obtained in step 1 is evaluated on the rest part of the data(it plays an role of a test set in train_test_split.)\n<li>3. Using the parameters that got good results in step 1 and 2, we make a final evaluation on the test set.</ul><br>-----<br>ã€€æ¨å®šé‡ã®ç•°ãªã‚‹è¨­å®šã‚’è©•ä¾¡ã™ã‚‹éš›ã€ä¾‹ãˆã°RandomForestã®å¼•æ•°n_estimatorsã‚’æ±ºã‚ã‚‹éš›ã€æ¨å®šé‡ãŒæœ€é©ã«ãªã‚‹ã¾ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã§ãã‚‹ãŸã‚ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§éå­¦ç¿’ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãã“ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ¥ã®éƒ¨åˆ†ã‚’æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ç”¨æ„ã—ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã‚’ã—ãŸå¾Œæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã‚’è¡Œã„ã€å®Ÿé¨“ãŒã†ã¾ãã„ã£ãŸã¨ãã«ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§æœ€çµ‚çš„ãªè©•ä¾¡ã‚’è¡Œã†ã“ã¨ã§ã€è§£æ±ºã—ã¾ã™ã€‚<br>ã€€ãã“ã§ã€Cross Validationã‚’ä½¿ã„ã¾ã™ã€‚å›³ã‚’ç”¨ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚æ‰‹é †ã¯3ã¤ã§ã™ã€‚\n<ul>\n    <li>ï¼‘ï¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã® k-1 å€‹åˆ†ã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚</li>\n    <li>ï¼’ï¼1ã§å¾—ã‚‰ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®æ®‹ã‚Šã®éƒ¨åˆ†ã«ã¦è©•ä¾¡ã•ã‚Œã‚‹ã€‚ï¼ˆtrain_test_splitã§ã„ã†ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®å½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚ï¼‰</li>\n    <li>ï¼“ï¼1ï¼Œ2ã§è‰¯ã„çµæœãŒå¾—ã‚‰ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«ã¦æœ€çµ‚è©•ä¾¡ã‚’ã™ã‚‹ã€‚</li>\n\n</ul>\n\n  <br><img src= \"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" alt =\"Titanic\" style=\"height: 450px; width:auto; align: left;\"></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€In this case, we will use the most famous k-fold validation.<br>-----<br>ã€€ä»Šå›ã¯ã€ä¸€ç•ªæœ‰åãªk-fold cross validationã‚’ä½¿ã„ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:50:05.952306Z","iopub.execute_input":"2021-08-29T05:50:05.952731Z","iopub.status.idle":"2021-08-29T05:50:05.958227Z","shell.execute_reply.started":"2021-08-29T05:50:05.952697Z","shell.execute_reply":"2021-08-29T05:50:05.956667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = KFold(n_splits = 10, random_state = 22, shuffle=True)#the 'fold' in the above figure becomes 10.\ncv_mean = []\naccuracy = []\nstd = []\nclassifiers = ['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\nmodels = [svm.SVC(kernel = 'linear'), svm.SVC(kernel = 'rbf'), LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(), GaussianNB(), RandomForestClassifier()]\nfor m in models:\n    model = m\n    cv_result = cross_val_score(model, X, Y, cv = kfold, scoring = \"accuracy\")\n    cv_mean.append(cv_result.mean())\n    std.append(cv_result.std())\n    accuracy.append(cv_result)\n    \nnew_models_dataframe2 = pd.DataFrame({'CV Mean': cv_mean, 'Std': std}, index = classifiers)\nnew_models_dataframe2","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:50:42.932151Z","iopub.execute_input":"2021-08-29T05:50:42.932498Z","iopub.status.idle":"2021-08-29T05:50:46.809615Z","shell.execute_reply.started":"2021-08-29T05:50:42.932469Z","shell.execute_reply":"2021-08-29T05:50:46.80856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Let's look at the case without feature selection.<br>-----<br>ã€€ç‰¹å¾´é‡é¸æŠã—ãªã‹ã£ãŸå ´åˆã§ã‚‚è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"X_ = train_data[train_data.columns[1:]]\nY_ = train_data['Survived']\nkfold_ = KFold(n_splits = 10, random_state = 22, shuffle=True)#the 'fold' in the above figure becomes 10.\ncv_mean_ = []\naccuracy_ = []\nstd_ = []\nclassifiers_ = ['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\nmodels_ = [svm.SVC(kernel = 'linear'), svm.SVC(kernel = 'rbf'), LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(), GaussianNB(), RandomForestClassifier()]\nfor m in models_:\n    model = m\n    cv_result = cross_val_score(model, X_, Y_, cv = kfold, scoring = \"accuracy\")\n    cv_mean_.append(cv_result.mean())\n    std_.append(cv_result.std())\n    accuracy_.append(cv_result)\n    \nnew_models_dataframe2_ = pd.DataFrame({'CV Mean': cv_mean_, 'Std': std_}, index = classifiers_)\nnew_models_dataframe2_","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:51:01.27223Z","iopub.execute_input":"2021-08-29T05:51:01.272592Z","iopub.status.idle":"2021-08-29T05:51:05.445414Z","shell.execute_reply.started":"2021-08-29T05:51:01.27256Z","shell.execute_reply":"2021-08-29T05:51:05.444106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€In my environment, the result are below 0.8 for decision tree and naive Bayes. By Selecting features, we can get stable results with any classifier.<br>-----<br>ã€€åƒ•ã®ç’°å¢ƒã§ã¯æ±ºå®šæœ¨ã¨ãƒŠã‚¤ãƒ¼ãƒ–ãƒ™ã‚¤ã‚ºã§0.8ã‚’ä¸‹å›ã‚Šã¾ã—ãŸã€‚ç‰¹å¾´é‡é¸æŠã«ã‚ˆã£ã¦ã€ã©ã®åˆ†é¡å™¨ã§ã‚‚å®‰å®šã—ãŸçµæœãŒå¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize = (12, 6))\nbox = pd.DataFrame(accuracy, index = [classifiers])\nbox.T.boxplot()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:51:31.682446Z","iopub.execute_input":"2021-08-29T05:51:31.682883Z","iopub.status.idle":"2021-08-29T05:51:31.942143Z","shell.execute_reply.started":"2021-08-29T05:51:31.682834Z","shell.execute_reply":"2021-08-29T05:51:31.940848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_models_dataframe2['CV Mean'].plot.barh(width = 0.8)\nplt.title('Ave CV Mean Accuracy')\nfig = plt.gcf()\nfig.set_size_inches(8, 5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:51:54.329507Z","iopub.execute_input":"2021-08-29T05:51:54.329886Z","iopub.status.idle":"2021-08-29T05:51:54.711316Z","shell.execute_reply.started":"2021-08-29T05:51:54.329834Z","shell.execute_reply":"2021-08-29T05:51:54.710068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Using confusion matrix, we can get summary results of where the model went wrong and which classes are predicted incorrectly.<br>-----<br>ã€€confusion matrix ã‚’ä½¿ã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒã©ã“ã§é–“é•ãˆãŸã®ã‹ã€ã©ã®ã‚¯ãƒ©ã‚¹ã‚’é–“é•ã£ã¦äºˆæ¸¬ã—ãŸã‹ã®è¦ç´„çµæœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(3, 3, figsize = (12, 10))\ny_pred = cross_val_predict(LogisticRegression(), X, Y, cv = 10)\nsns.heatmap(confusion_matrix(Y, y_pred), ax = ax[0, 0], annot = True, fmt = '2.0f')\nax[0, 0].set_title('LogisticRegression')\ny_pred = cross_val_predict(svm.SVC(kernel = 'rbf'), X, Y, cv = 10)\nsns.heatmap(confusion_matrix(Y, y_pred), ax = ax[0, 1], annot = True, fmt = '2.0f')\nax[0, 1].set_title('rbf-SVM')\ny_pred = cross_val_predict(svm.SVC(kernel = 'linear'), X, Y, cv = 10)\nsns.heatmap(confusion_matrix(Y, y_pred), ax = ax[0, 2], annot = True, fmt = '2.0f')\nax[0, 2].set_title('linear')\ny_pred = cross_val_predict(RandomForestClassifier(), X, Y, cv = 10)\nsns.heatmap(confusion_matrix(Y, y_pred), ax = ax[1, 0], annot = True, fmt = '2.0f')\nax[1, 0].set_title('RandomForest')\ny_pred = cross_val_predict(DecisionTreeClassifier(), X, Y, cv = 10)\nsns.heatmap(confusion_matrix(Y, y_pred), ax = ax[1, 1], annot = True, fmt = '2.0f')\nax[1, 1].set_title('DecisionTree')\ny_pred = cross_val_predict(KNeighborsClassifier(), X, Y, cv = 10)\nsns.heatmap(confusion_matrix(Y, y_pred), ax = ax[1, 2], annot = True, fmt = '2.0f')\nax[1, 2].set_title('KNN')\ny_pred = cross_val_predict(GaussianNB(), X, Y, cv = 10)\nsns.heatmap(confusion_matrix(Y, y_pred), ax = ax[2, 0], annot = True, fmt = '2.0f')\nax[2, 0].set_title('Naive Bayes')\nplt.subplots_adjust(hspace = 0.2, wspace = 0.2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:52:05.2528Z","iopub.execute_input":"2021-08-29T05:52:05.253175Z","iopub.status.idle":"2021-08-29T05:52:11.328672Z","shell.execute_reply.started":"2021-08-29T05:52:05.253146Z","shell.execute_reply":"2021-08-29T05:52:11.327453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Here is how to look at the figure above. The diagonal line on the left shows the number of correct predictions for each class, and the diagonal line on the right shows the number of incorrect predictions. Let's take LogisticRegression as an example. <br>ã€€\nThe correct prediction is 473 (dead) + 261 (survivors) / 891 = 0.824%. On the other hand, 76 dead people are mispredicted as survivors, and 81 survivors are mispredicted as dead people.<br>ã€€\nLooking at this, rbf predicts the dead people most correctly, and Naive Bayes predicts the survivors most correctly.<br>-----<br>ã€€ä¸Šã®å›³ã®è¦‹æ–¹ã‚’èª¬æ˜ã—ã¾ã™ã€‚å·¦ã®å¯¾è§’ç·šã¯å„ã‚¯ãƒ©ã‚¹ã®æ­£ã—ã„äºˆæ¸¬ã®æ•°ã‚’ã€å³ã®å¯¾è§’ç·šã¯èª¤ã£ãŸäºˆæ¸¬ã®æ•°ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚å·¦ä¸Šã®LogisticRegressionã‚’ä¾‹ã«ã—ã¾ã™ã€‚<br>ã€€æ­£ã—ã„äºˆæ¸¬ã¯473(æ­»è€…) + 261(ç”Ÿå­˜è€…) / 891 = 0.824%ã§ã™ã€‚é€†ã«ã€76ã®æ­»è€…ãŒç”Ÿå­˜è€…ã¨èª¤äºˆæ¸¬ã•ã‚Œã€81ã®ç”Ÿå­˜è€…ãŒæ­»è€…ã¨ã”äºˆæ¸¬ã•ã‚Œã¦ã„ã¾ã™ã€‚<br>ã€€ã“ã‚Œã‚’è¦‹ã‚‹ã¨ã€rbfãŒä¸€ç•ªæ­£ã—ã„æ­»è€…ã®äºˆæ¸¬ã—ã€Naive BayesãŒä¸€ç•ªæ­£ã—ã„ç”Ÿå­˜è€…ã®äºˆæ¸¬ã‚’ã—ã¦ã„ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"# <b style = \"font-size:30px\">Ensembling</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\nã€€The RandomForest we did <a href = '#section16'>here</a> is also based on ensemble learning. We will explore the ensemble learning in depth here. <br>-----<br>ã€€<a href = '#section16'>ã“ã“</a>ã§ã‚„ã£ãŸRandomForestã‚‚ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã«åŸºã¥ã„ãŸã‚‚ã®ã§ã™ã€‚ãã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚’ã€ã“ã“ã§æ·±æ˜ã‚Šã—ã¦ã„ãã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n      This time, we will see the four main methods.<br>-----<br>ã€€ä»Šå›ã§ã¯ã€ä¸»ã«4ã¤ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚<br>ã€€ï¼‘ï¼Voting<br>ã€€ï¼’ï¼Bagging<br>ã€€ï¼“ï¼Boosting<br>ã€€ï¼”ï¼Stacking<br><br>ã€€Before we get into that, let's look at how amazing the ensemble using a little math. First, in a binary classification task, majority prediction can be described as follows.<br>-----<br>ã€€ãã®å‰ã«ã€å°‘ã—æ•°å­¦ã‚’ä½¿ã£ã¦ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®ã™ã”ã•ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚å…ˆãšã€äºŒå€¤åˆ†é¡ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€å¤šæ•°æ±ºäºˆæ¸¬ã¯æ¬¡ã®ã‚ˆã†ã«è¨˜è¿°ã§ãã¾ã™ã€‚<br>ã€€\n$$C(x) = sign\\Biggr[\\sum_{j}^{m}C_j(x)\\Biggr] = \n\\begin{cases}\n1 \\quad (\\sum_jC_j(x) \\ge 0) \\\\\n-1 \\quad (\\sum_jC_j(x) < 0) \\\\\n\\end{cases}\n$$<br><br>ã€€Assume that the misclassification rates of this base classifiers in binary classification task are all equal Îµ. Furthermore, we assume that each classifier is independant and there is no correlation in misclassification rate.<br>ã€€\nUnder this assumption, we can express the misclassification rate of an ensemble of base classifiers as probability mass function of binomial distribution. <br>ã€€In simple terms, this is probability that the number of classifiers that classify incorrectly, y, is more than or equal to k. <br>-----<br>ã€€äºŒå€¤åˆ†é¡ã‚¿ã‚¹ã‚¯ã®ã“ã®ãƒ™ãƒ¼ã‚¹åˆ†é¡å™¨ã®èª¤åˆ†é¡ç‡ãŒã™ã¹ã¦ç­‰ã—ãÎµã§ã‚ã‚‹ã¨ã™ã‚‹ã€‚ã•ã‚‰ã«ã€ãã‚Œãã‚Œã®åˆ†é¡å™¨ãŒç‹¬ç«‹ã—ã€èª¤åˆ†é¡ç‡ã«ç›¸é–¢ãŒãªã„ã‚‚ã®ã¨ã—ã¾ã™ã€‚ã“ã®ä»®å®šã®ä¸‹ã€ãƒ™ãƒ¼ã‚¹åˆ†é¡å™¨ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®èª¤åˆ†é¡ç‡ã‚’äºŒé …åˆ†å¸ƒã®ç¢ºç‡è³ªé‡é–¢æ•°ã¨ã—ã¦è¡¨ã›ã¾ã™ã€‚ç°¡å˜ã«è¨€ã†ã¨ã€èª¤åˆ†é¡ã™ã‚‹åˆ†é¡å™¨ã®å€‹æ•°yãŒkä»¥ä¸Šã¨ãªã‚‹ç¢ºç‡ã§ã™ã€‚<br><br>$$P(y \\ge k) = \\sum_{k}^{n} (_nC_k) \\epsilon^k(1 - \\epsilon)^{n - k}$$<br><br>ã€€This is probability of misclassification. Let's put in some numbers and see the probability that 11 classifiers get more than half wrong actually. However, we assume that the misclassification rate of each classifier Îµ is 0.25.<br>-----<br>ã€€ã“ã‚Œã¯èª¤åˆ†é¡ã™ã‚‹ç¢ºç‡ã§ã™ã€‚å®Ÿéš›ã«æ•°å€¤ã‚’å…¥ã‚Œã¦ã¿ã¾ã—ã‚‡ã†ã€‚11å€‹ã®åˆ†é¡å™¨ãŒåŠåˆ†ä»¥ä¸Šé–“é•ãˆã‚‹ç¢ºç‡ã‚’è¦‹ã¾ã™ã€‚ãŸã ã—ã€æ ¼åˆ†é¡å™¨ã®èª¤åˆ†é¡ç‡Îµ = 0.25ã¨ã—ã¾ã™ã€‚<br><br>$$P(y \\ge k) = \\sum_{k = 6}^{11} (_{11}C_k) 0.25^k (1 - 0.25)^{11-k} = 0.034$$<br>ã€€If there conditions are met, we can see that the ensemble misclassification rate is 0.034, which is much lower than the classifier 0.25 here. This is amazing!!!<br>-----<br>ã€€ã“ã‚Œã‚‰ã®æ¡ä»¶ãŒæº€ãŸã•ã‚Œã¦ã„ã‚Œã°ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®èª¤åˆ†é¡ç‡ã¯ã€ã“ã“ã®åˆ†é¡å™¨0.25ã¨æ¯”ã¹ã¦0.034ã¨ã€å„æ®µã«ä½ã„ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚ã‚¹ã‚´ã‚¤ï¼ï¼ï¼ï¼ï¼</p>","metadata":{}},{"cell_type":"code","source":"from scipy.special import comb\nimport math\nn_classifier = 11\nerror = 0.25\nstart_ = int(math.ceil(n_classifier / 2.))\nprobs = [(comb(n_classifier, k) * (error ** k) * (1 - error) ** (n_classifier - k)) for k in range(start_, n_classifier + 1)]\nsum(probs)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:59:33.289618Z","iopub.execute_input":"2021-08-29T05:59:33.290104Z","iopub.status.idle":"2021-08-29T05:59:33.299079Z","shell.execute_reply.started":"2021-08-29T05:59:33.290068Z","shell.execute_reply":"2021-08-29T05:59:33.298202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style = \"font-size:20px; color: red\">Voting</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n      Voting is the most simple in ensemble. It takes a majority vote from a multi simple machine learning model combination. <br>-----<br>ã€€Votingã¯ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®ä¸­ã§ã‚‚ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ã§ã™ã€‚è¤‡æ•°ã®å˜ç´”ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ã‹ã‚‰å¤šæ•°æ±ºã‚’å–ã‚Šã¾ã™ã€‚<br><br><img src= \"https://www.researchgate.net/publication/324014302/figure/fig2/AS:644424015040514@1530654066950/Majority-voting-algorithm.png\" alt =\"Titanic\" style=\"height: 400px; width:auto; align: left;\"><br><br>ã€€To see the power of ensemble, we will try it without any parameter tuning.<br>-----<br>ã€€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®åŠ›ã‚’è¦‹ã‚‹ãŸã‚ã«ã€ä¸€åˆ‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã›ãšã«ã‚„ã£ã¦ã¿ã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nensemble_voting = VotingClassifier(estimators = [\n    ('KNN', KNeighborsClassifier()),\n    ('rbf', svm.SVC(probability = True, kernel = 'rbf')),\n    ('RFC', RandomForestClassifier()),\n    ('LR', LogisticRegression()),\n    ('DT', DecisionTreeClassifier(random_state = 0)),\n    ('NB', GaussianNB()),\n    ('linear', svm.SVC(kernel = 'linear', probability = True))\n], voting = 'soft').fit(train_X, train_Y)\n\nprint(ensemble_voting.score(test_X, test_Y))\nprint(cross_val_score(ensemble_voting, X, Y, cv = 20, scoring = 'accuracy').mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:00:31.789589Z","iopub.execute_input":"2021-08-29T06:00:31.790038Z","iopub.status.idle":"2021-08-29T06:00:45.267806Z","shell.execute_reply.started":"2021-08-29T06:00:31.789998Z","shell.execute_reply":"2021-08-29T06:00:45.266176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n     Just by combining the two, we are able to get the stable high accuray. There are many more great methods, so let's look at them as we use them together.<br>-----<br>ã€€çµ„ã¿åˆã‚ã›ã¦ã„ã‚‹ã ã‘ã§ã€å®‰å®šã—ãŸé«˜ç²¾åº¦ãŒå¾—ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã‚‚ã£ã¨ã™ã”ã„ã‚‚ã®ãŒãŸãã•ã‚“ã‚ã‚‹ã®ã§ã€ä¸€ç·’ã«ä½¿ã„ãªãŒã‚‰è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"# <b style = \"font-size:20px; color: red\">Bagging</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n     ã€€It is similar to <b>Voting</b>. However, while Voting uses the same training set for each classifier, Bagging extracts bootstrap samples from the first training set.<br>-----<br>ã€€Votingã¨ä¼¼ã¦ã„ã¾ã™ã€‚ã§ã™ãŒã€Votingã¯ãã‚Œãã‚Œã®åˆ†é¡å™¨ã«åŒã˜è¨“ç·´ã‚»ãƒƒãƒˆã‚’ä½¿ã†ã®ã«å¯¾ã—ã€Baggingã¯æœ€åˆã®è¨“ç·´ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ–ãƒ¼ã‚¹ãƒˆãƒ©ãƒƒãƒ—æ¨™æœ¬ã‚’æŠ½å‡ºã—ã¾ã™ã€‚<br><br>ã€€<img src= \"https://static.packt-cdn.com/products/9781787125933/graphics/B07030_07_06.jpg\" alt =\"Titanic\" style=\"height: 400px; width:auto; align: left;\"></p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n      Here, by using unpruned decision trees as the base classifier, we create an ensemble made by 500 decision trees and train it on bootstrap samples of different training datasets.<br>-----<br>ã€€ã“ã“ã§ã¯ã€å‰ªå®šã•ã‚Œã¦ã„ãªã„æ±ºå®šæœ¨ã‚’ãƒ™ãƒ¼ã‚¹åˆ†é¡å™¨ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€500å€‹ã®æ±ºå®šæœ¨ã‹ã‚‰æˆã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’ä½œæˆã—ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç•°ãªã‚‹ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—æ¨™æœ¬ã§å­¦ç¿’ã•ã›ã‚‹ã€‚</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\ntree = DecisionTreeClassifier(max_depth = None)\nmodel = BaggingClassifier(base_estimator = tree, n_estimators = 800)\nmodel.fit(train_X, train_Y)\nbag_pre = model.predict(test_X)\nprint(metrics.accuracy_score(bag_pre, test_Y))\nprint(cross_val_score(model, X, Y, cv = 10, scoring = 'accuracy').mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:00:45.269451Z","iopub.execute_input":"2021-08-29T06:00:45.269938Z","iopub.status.idle":"2021-08-29T06:01:12.382433Z","shell.execute_reply.started":"2021-08-29T06:00:45.269855Z","shell.execute_reply":"2021-08-29T06:01:12.381071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n     ã€€That is a much higher score than with a simple decision tree! <br>ã€€\nThere is something what to check here. If the classification task is complex, or if the number of dataset's dimention is large, a single decision tree is likely to be overtrained. This is because the bias becomes low. <br>ã€€So we have to bag an ensemble of classifiers with as low a bias as possible, such as an unpruned decision tree like this one.<br>-----<br>ã€€å˜ç´”ãªæ±ºå®šæœ¨ã®ã¨ãã‚ˆã‚Šã‚¹ã‚³ã‚¢ãŒä¸ŠãŒã£ã¦ã„ã¾ã™ã­ï¼<br>ã€€ã“ã“ã§ç¢ºèªã—ãŸã„ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚åˆ†é¡ã‚¿ã‚¹ã‚¯ãŒè¤‡é›‘ã§ã‚ã£ãŸã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¬¡å…ƒæ•°ãŒå¤šã‹ã£ãŸã‚Šã™ã‚‹ã¨ã€å˜ä¸€ãªæ±ºå®šæœ¨ã§ã¯éå­¦ç¿’ã«é™¥ã‚Šã‚„ã™ã„ã§ã™ã€‚ãƒã‚¤ã‚¢ã‚¹ãŒä½ããªã‚‹ã‹ã‚‰ã§ã™ã€‚ãªã®ã§ã€ä»Šå›ã®ã‚ˆã†ã«å‰ªå®šã•ã‚Œã¦ã„ãªã„æ±ºå®šæœ¨ãªã©ã€ã§ãã‚‹ã ã‘ãƒã‚¤ã‚¢ã‚¹ã®ä½ã„åˆ†é¡å™¨ã‹ã‚‰æˆã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§ãƒã‚®ãƒ³ã‚°ã—ãŸã„ã§ã™ã€‚</p>","metadata":{}},{"cell_type":"markdown","source":"# <b style = \"font-size:20px; color: red\">Boosting</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n     ã€€In boosting, the ensemble consists of a very simple (weak) base classifier. The performance of this learner, also known as a weak learner, is only slightly better than a guesser. We try to improve the performance of ensemble by training the misclassified training data to the weak learner later.<br>ã€€\nThe procedure is as follows.<br>\n<ul>\n<li>1. Extract a random subset d1 of the training data from training dataset D in a non-recoverable manner and train weak learner C1. \n<li>2. Unrecoverably extract a second random training subset d2 from training data and add 50% of previously misclassified data points to train weak learner C2. \n<li>3. Identify the training data d3 that the result of C1 and C2 is different from training dataset D and train the third weak learner C3.\n<li>4. Combine the weak learner C1, C2 and C3 by majority vote.</ul><br>-----<br>ã€€ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã§ã¯ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¯éå¸¸ã«å˜ç´”ãªï¼ˆå¼±ã„ï¼‰ãƒ™ãƒ¼ã‚¹åˆ†é¡å™¨ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚ã“ã®å¼±å­¦ç¿’å™¨ã¨ã‚‚å‘¼ã°ã‚Œã‚‹å­¦ç¿’å™¨ã®æ€§èƒ½ã¯ã€å½“ã¦æ¨é‡ã‚’ã‚ãšã‹ã«ä¸Šå›ã‚‹ç¨‹åº¦ã§ã™ã€‚èª¤åˆ†é¡ã•ã‚ŒãŸè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å¾Œã‹ã‚‰å¼±å­¦ç¿’å™¨ã«å­¦ç¿’ã•ã›ã‚‹ã“ã¨ã§ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æ€§èƒ½å‘ä¸Šã‚’è©¦ã¿ã¾ã™ã€‚<br>ã€€æ‰‹é †ã¯ä»¥ä¸‹ã®4ã¤ã§ã™ã€‚\n<ul>\n    <li>ï¼‘ï¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆDã‹ã‚‰è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ³ãƒ€ãƒ ãªã‚µãƒ–ã‚»ãƒƒãƒˆd1ã‚’éå¾©å…ƒæŠ½å‡ºã—ã€å¼±å­¦ç¿’å™¨C1ã‚’è¨“ç·´ã™ã‚‹ã€‚</li>\n    <li>ï¼’ï¼2ã¤ç›®ã®ãƒ©ãƒ³ãƒ€ãƒ ãªè¨“ç·´ã‚µãƒ–ã‚»ãƒƒãƒˆd2ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰éå¾©å…ƒæŠ½å‡ºã—ã€ä»¥å‰ã«èª¤åˆ†é¡ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ç‚¹ã®50%ã‚’è¿½åŠ ã—ã¦ã€å¼±å­¦ç¿’å™¨C2ã‚’è¨“ç·´ã™ã‚‹ã€‚</li>\n    <li>ï¼“ï¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆDã‹ã‚‰C1ã¨C2ã®çµæœãŒç•°ãªã‚‹è¨“ç·´ãƒ‡ãƒ¼ã‚¿d3ã‚’æ´—ã„å‡ºã—ã€3ã¤ç›®ã®å¼±å­¦ç¿’å™¨C3ã‚’å­¦ç¿’ã™ã‚‹ã€‚</li>\n    <li>ï¼”ï¼å¼±å­¦ç¿’å™¨C1, C2, C3ã‚’å¤šæ•°æ±ºã«ã‚ˆã‚Šçµ„ã¿åˆã‚ã›ã‚‹ã€‚</li>\n</ul></p>","metadata":{}},{"cell_type":"markdown","source":"<b style = \"font-size:20px\">Adaboost</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins'; sans-serif; font-size: 15px; font-weight: 500;\">\n     ã€€Adaboost is the famous boosting algorithm.<br>-----<br>ã€€ã‚¢ãƒ€ãƒ–ãƒ¼ã‚¹ãƒˆã¯ã€ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ä¸€ç•ªæœ‰åã§ã™ã€‚<br><br><img src= \"https://miro.medium.com/max/1400/0*KYszvMnr3nCtjaGy.png\" alt =\"Titanic\" style=\"height: 400px; width:auto; align: left;\"><br>ã€€On the far left, the bounds are determined by minimizing the cost function (or the impurity that described previously). In the middle, the data points that is midclassified (circled) in the left are given a large weight, and the data point that is correctly classified are given small weights. Then, repeat the same way on the right, and the final output is determined by majority voting on each boundary.<br>-----<br>ã€€ä¸€ç•ªå·¦ã§ã€ã‚³ã‚¹ãƒˆé–¢æ•°ï¼ˆã¾ãŸã¯å‰ã«èª¬æ˜ã—ãŸä¸ç´”åº¦ï¼‰ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å¢ƒç•Œã‚’æ±ºå®šã—ã¾ã™ã€‚çœŸã‚“ä¸­ã§ã¯ã€å·¦ã§èª¤åˆ†é¡ã•ã‚ŒãŸï¼ˆä¸¸ãŒã¤ã„ã¦ã„ã‚‹ï¼‰ãƒ‡ãƒ¼ã‚¿ç‚¹ã®é‡ã¿ãŒå¤§ãããªã‚Šã€æ­£ã—ãåˆ†é¡ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ç‚¹ã®é‡ã¿ãŒå°ã•ããªã£ã¦ã„ã¾ã™ã€‚ãã—ã¦ã€å³ã§åŒã˜ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã€ãã‚Œãã‚Œã®å¢ƒç•Œã®å¤šæ•°æ±ºã§ã€æœ€çµ‚çš„ãªå‡ºåŠ›ãŒæ±ºå®šã•ã‚Œã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier(n_estimators = 200, random_state = 0, learning_rate = 0.1)\nresult = cross_val_score(ada, X, Y, scoring = 'accuracy')\nprint(result.mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:04:41.437252Z","iopub.execute_input":"2021-08-29T06:04:41.437649Z","iopub.status.idle":"2021-08-29T06:04:43.628722Z","shell.execute_reply.started":"2021-08-29T06:04:41.437617Z","shell.execute_reply":"2021-08-29T06:04:43.627699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b style = \"font-size:20px\">Gradient Boosting</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins'; sans-serif; font-size: 15px; font-weight: 500;\">\n     ã€€The overall idea is the same as Adaboost. The different is that Adaboost used weights to identify the correct and incorrect answers of the previous model, while GradientBoosting uses gradients. <br>ã€€To put it a bit more, AdaBoost tweaks the weights of instances in every interaction, while GradientBoosting tries to fit the new predictor to the residual error created by the previous predictor. <br>ã€€In summary, there is a difference in the way it judge the shortcomings of weak learners.<br>-----<br>ã€€å…¨ä½“çš„ãªè€ƒãˆæ–¹ã¯ã€Adaboostã¨åŒã˜ã§ã™ã€‚é•ã„ã¨ã—ã¦ã¯ã€Adaboostã§ã¯ã€å‰ã®ãƒ¢ãƒ‡ãƒ«ã®æ­£è§£ä¸æ­£è§£ã‚’é‡ã¿ã«ã‚ˆã£ã¦è­˜åˆ¥ã—ã¦ã„ã¾ã—ãŸãŒã€GradientBoostingã§ã¯å‹¾é…ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚ã‚‚ã†å°‘ã—è¨€ã†ã¨ã€AdaBoostã¯ã™ã¹ã¦ã®ç›¸äº’ä½œç”¨ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®é‡ã¿ã‚’å¾®èª¿æ•´ã™ã‚‹ã®ã§ã™ãŒã€å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã¯ã€æ–°ã—ã„äºˆæ¸¬å­ã‚’å‰ã®äºˆæ¸¬å­ã«ã‚ˆã£ã¦ä½œæˆã•ã‚ŒãŸæ®‹å·®ã‚¨ãƒ©ãƒ¼ã«é©åˆã•ã›ã‚ˆã†ã¨ã—ã¾ã™ã€‚ã¾ã¨ã‚ã‚‹ã¨ã€å¼±å­¦ç¿’å™¨ã®æ¬ ç‚¹ã‚’åˆ¤æ–­ã™ã‚‹æ–¹æ³•ã«é•ã„ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngrad = GradientBoostingClassifier(n_estimators = 500, random_state = 0, learning_rate = 0.1)\nresult = cross_val_score(grad, X, Y, cv = 10, scoring = 'accuracy')\nprint(result.mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:08:49.321122Z","iopub.execute_input":"2021-08-29T06:08:49.321492Z","iopub.status.idle":"2021-08-29T06:08:55.004042Z","shell.execute_reply.started":"2021-08-29T06:08:49.321461Z","shell.execute_reply":"2021-08-29T06:08:55.002635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b style = \"font-size:20px\">XGBoost</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins'; sans-serif; font-size: 15px; font-weight: 500;\">\n     ã€€You can think of this as a more computationally efficient implementation of GradientBoosting. The flow is the same.<br>-----<br>ã€€GradientBoostingã®è¨ˆç®—åŠ¹ç‡ã®è‰¯ããªã£ãŸå®Ÿè£…ã¨æ€ã£ã¦ã‚‚ã‚‰ã£ã¦ã‚ˆã„ã¨æ€ã„ã¾ã™ã€‚æµã‚Œã¯åŒã˜ã§ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"import xgboost as xg\nxgboost = xg.XGBClassifier()\nresult = cross_val_score(xgboost, X, Y, cv = 10, scoring  = 'accuracy')\nprint(result.mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:27:25.125751Z","iopub.execute_input":"2021-08-29T06:27:25.126491Z","iopub.status.idle":"2021-08-29T06:27:26.37413Z","shell.execute_reply.started":"2021-08-29T06:27:25.12645Z","shell.execute_reply":"2021-08-29T06:27:26.372144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b style = \"font-size:20px\">HistGradientBoostingClassifier</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins'; sans-serif; font-size: 15px; font-weight: 500;\">\n     ã€€This is faster than XGBoost when the data is large. It uses OpenMP for parallelization and can learn even if there are missing values.<br>-----<br>ã€€ãƒ‡ãƒ¼ã‚¿ãŒå¤§ãã„ã¨ã€XGBoostã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã™ã€‚ä¸¦åˆ—åŒ–ã«OpenMPã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã€æ¬ æå€¤ãŒã‚ã£ã¦ã‚‚å­¦ç¿’ã§ãã¾ã™ã€‚</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nhgb = HistGradientBoostingClassifier()\nres = cross_val_score(hgb, X, Y, cv = 10, scoring = 'accuracy')\nprint(res.mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:15:27.376788Z","iopub.execute_input":"2021-08-29T06:15:27.377205Z","iopub.status.idle":"2021-08-29T06:15:33.199024Z","shell.execute_reply.started":"2021-08-29T06:15:27.377172Z","shell.execute_reply":"2021-08-29T06:15:33.198005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins'; sans-serif; font-size: 15px; font-weight: 500;\">\n     ã€€Let's search the parameter using optuna in XGBoost that is the most famous above.<br>-----<br>ã€€ä¸Šã®ä¸­ã§ã‚‚ä¸€ç•ªæœ‰åãªXGBoostã§ã€optunaã‚’ä½¿ã£ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢ã—ã¾ã—ã‚‡ã†ã€‚</p>","metadata":{}},{"cell_type":"code","source":"def objective_xg(trial):\n    params = {\n        'eta': trial.suggest_loguniform('eta', 1e-8, 1.0),\n        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 1, 20),\n        #'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-8, 1.0),\n        #'max_delta_step': trial.suggest_loguniform('max_delta_step', 1e-8, 1.0),\n        #'subsample': trial.suggest_uniform('subsample', 0.0, 1.0),\n        #'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 1000.0),\n        #'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1000.0)\n    }\n    \n    model = xg.XGBClassifier(**params)\n    score = cross_val_score(model, X, Y, cv = 10, scoring = 'accuracy')\n    score = score.mean()\n\n    return 1 - score","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:23:19.60062Z","iopub.execute_input":"2021-08-29T06:23:19.601039Z","iopub.status.idle":"2021-08-29T06:23:19.608344Z","shell.execute_reply.started":"2021-08-29T06:23:19.601006Z","shell.execute_reply":"2021-08-29T06:23:19.60731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The execution result is very long, so please skip to <a href = '#section033'>here</a>.","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(sampler = optuna.samplers.RandomSampler(seed = 0))\nstudy.optimize(objective_xg, n_trials = 100)\nprint(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:23:21.962462Z","iopub.execute_input":"2021-08-29T06:23:21.962863Z","iopub.status.idle":"2021-08-29T06:25:50.084912Z","shell.execute_reply.started":"2021-08-29T06:23:21.962829Z","shell.execute_reply":"2021-08-29T06:25:50.083908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"section033\">ã€€</a>","metadata":{}},{"cell_type":"code","source":"print(study.best_params['eta'],study.best_params['gamma'],\n                                study.best_params['max_depth']#,study.best_params['min_child_weight'],\n                                #study.best_params['max_delta_step'],study.best_params['subsample'],\n                                #study.best_params['reg_lambda'],study.best_params['reg_alpha']\n     )","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:26:35.365852Z","iopub.execute_input":"2021-08-29T06:26:35.366292Z","iopub.status.idle":"2021-08-29T06:26:35.373764Z","shell.execute_reply.started":"2021-08-29T06:26:35.366255Z","shell.execute_reply":"2021-08-29T06:26:35.372585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xg\nxgboost = xg.XGBClassifier(eta = study.best_params['eta'], gamma = study.best_params['gamma'], max_depth = study.best_params['max_depth']#, min_child_weight = study.best_params['min_child_weight'],\n                           #max_delta_step = study.best_params['max_delta_step'], subsample = study.best_params['subsample'], reg_lambda = study.best_params['reg_lambda'], reg_alpha = study.best_params['reg_alpha']\n                          )\nresult = cross_val_score(xgboost, X, Y, cv = 10, scoring  = 'accuracy')\nprint(result.mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T06:26:52.763514Z","iopub.execute_input":"2021-08-29T06:26:52.763957Z","iopub.status.idle":"2021-08-29T06:26:53.297945Z","shell.execute_reply.started":"2021-08-29T06:26:52.763919Z","shell.execute_reply":"2021-08-29T06:26:53.296986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style = \"font-size:20px; color: red\">Stacking</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€Stacking is easy to understand if you think of it as an ensemble of two. The first layer consists of individual classifiers, which feed their predictions to the second layers. Then, in the second layer, another classifier is fitted to the predictions of the first layer to produce the final predictions. This time, we use <b>StackingClassifier</b><br>ã€€\nAlso, <a href=http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/>StackingCVClassifier</a> is an upgraded version of the regular StackingClassifier using cross-validation. This one is not implemented in scikit-learn at this time, so please go to the URL and have a look!<br>-----<br>ã€€ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã¯ã€2å€‹ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¨è€ƒãˆã‚‹ã¨ã‚ã‹ã‚Šã‚„ã™ã„ã§ã™ã€‚ä¸€ã¤ç›®ã®å±¤ã§ã¯ã€ã“ã“ã®åˆ†é¡å™¨ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ãã‚Œã‚‰ã®åˆ†é¡å™¨ã®äºˆæ¸¬å€¤ã‚’äºŒã¤ç›®ã®å±¤ã«ä¾›çµ¦ã—ã¾ã™ã€‚ãã—ã¦ã€äºŒã¤ç›®ã®å±¤ã§ã¯ã€åˆ¥ã®åˆ†é¡å™¨ãŒä¸€ã¤ç›®ã®å±¤ã®äºˆæ¸¬å€¤ã«é©åˆã•ã‚Œã€æœ€çµ‚çš„ãªäºˆæ¸¬å€¤ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä»Šå›ã¯ã€<b>StackingClassifier</b>ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚<br>ã€€ã¾ãŸã€é€šå¸¸ã®StackingClassifierã‚’ã€ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ã£ã¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã•ã›ãŸã‚‚ã®ãŒ<a href=http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/>StackingCVClassifier</a>ã«ãªã‚Šã¾ã™ã€‚ã“ã¡ã‚‰ã¯ç¾æ™‚ç‚¹ã§ã¯scikit-learnã«å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ã®ã§ã€URLã«é£›ã‚“ã§æ˜¯éè¦‹ã¦ã¿ã¦ãã ã•ã„ï¼\n</p>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:20:23.485499Z","iopub.execute_input":"2021-08-29T07:20:23.485953Z","iopub.status.idle":"2021-08-29T07:20:23.492017Z","shell.execute_reply.started":"2021-08-29T07:20:23.485917Z","shell.execute_reply":"2021-08-29T07:20:23.490459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf1 = svm.SVC(kernel = 'rbf', C = 2164.383970701054, gamma = 0.001062561994257736)\nclf2 = LogisticRegression(C = 9.468257892380656)\nclf3 = KNeighborsClassifier(n_neighbors = 22)\nclf4 = GaussianNB()\nclf5 = RandomForestClassifier(criterion = 'gini', n_estimators = 22, random_state = 42)\n\nstacking_classifier_estimators = [\n    ('rbf', clf1), ('knc', clf3), ('gnv', clf4), ('rfc', clf5)\n]\nclf = StackingClassifier(\n    estimators = stacking_classifier_estimators, final_estimator = clf2\n)\n\nresult = cross_val_score(clf, X, Y, cv = 10, scoring = 'accuracy')\nprint(result.mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:54:22.017349Z","iopub.execute_input":"2021-08-29T07:54:22.017761Z","iopub.status.idle":"2021-08-29T07:54:31.212648Z","shell.execute_reply.started":"2021-08-29T07:54:22.017727Z","shell.execute_reply":"2021-08-29T07:54:31.211148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style = \"font-size:20px; color: black\">Feature Importance</b>","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(2,2,figsize=(15,12))\nmodel=RandomForestClassifier(random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,0])\nax[0,0].set_title('Feature Importance in Random Forests')\nmodel=AdaBoostClassifier(random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,1],color='#ddff11')\nax[0,1].set_title('Feature Importance in AdaBoost')\nmodel=GradientBoostingClassifier(random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,0],cmap='RdYlGn_r')\nax[1,0].set_title('Feature Importance in Gradient Boosting')\nmodel=xg.XGBClassifier(learning_rate=0.1)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,1],color='#FD0F00')\nax[1,1].set_title('Feature Importance in XgBoost')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:51:23.766627Z","iopub.execute_input":"2021-08-29T07:51:23.767021Z","iopub.status.idle":"2021-08-29T07:51:25.518394Z","shell.execute_reply.started":"2021-08-29T07:51:23.766987Z","shell.execute_reply":"2021-08-29T07:51:25.517248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-family: 'Poppins', sans-serif; font-size: 15px; font-weight: 500;\">\n    ã€€With this, we can visually see which features were used. As expected, it seems that the initial (Mr), which had a high mortality rate, the gender (Male or Female), which shows a large difference, and Pclass which shows the rank passengers are recognized as the most important ones.<br>ã€€\nNow let's submit actually. This time, we'll submit the result by StackingClassifier.<br>-----<br>ã€€ã“ã‚Œã‚’ä½¿ã†ã¨ã€ã©ã®ç‰¹å¾´é‡ã‚’ä½¿ã£ãŸã®ã‹ãŒè¦–è¦šçš„ã«ã‚ã‹ã‚Šã¾ã™ã€‚ã‚„ã¯ã‚Šã€æ­»äº¡ç‡ãŒé«˜ã‹ã£ãŸã‚¤ãƒ‹ã‚·ãƒ£ãƒ«(Mr)ã‚„ã€å¤§ããªå·®ãŒè¦‹ã‚‰ã‚ŒãŸæ€§åˆ¥(Male or Female)ã€ä¹—å®¢ã®ä½ã‚’è¡¨ã™Pclassè¾ºã‚ŠãŒé‡è¦åº¦ã®é«˜ã„ã‚‚ã®ã¨ã—ã¦èªè­˜ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚<br>ã€€ã§ã¯ã€å®Ÿéš›ã«æå‡ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ä»Šå›ã¯<b>StackingClassifier</b>ã§åˆ†æã—ãŸçµæœã«ã—ã¾ã™ã€‚\n</p>","metadata":{}},{"cell_type":"code","source":"last_model = StackingClassifier(estimators = stacking_classifier_estimators, final_estimator = clf2)\nlast_model.fit(X, Y)\nlast_prediction = last_model.predict(test_data_)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T08:07:47.244998Z","iopub.execute_input":"2021-08-29T08:07:47.245407Z","iopub.status.idle":"2021-08-29T08:07:48.336326Z","shell.execute_reply.started":"2021-08-29T08:07:47.245373Z","shell.execute_reply":"2021-08-29T08:07:48.335236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_prediction","metadata":{"execution":{"iopub.status.busy":"2021-08-29T08:08:05.146463Z","iopub.execute_input":"2021-08-29T08:08:05.147138Z","iopub.status.idle":"2021-08-29T08:08:05.158261Z","shell.execute_reply.started":"2021-08-29T08:08:05.147096Z","shell.execute_reply":"2021-08-29T08:08:05.156996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:57:14.285614Z","iopub.execute_input":"2021-08-29T07:57:14.286088Z","iopub.status.idle":"2021-08-29T07:57:14.297642Z","shell.execute_reply.started":"2021-08-29T07:57:14.28605Z","shell.execute_reply":"2021-08-29T07:57:14.296797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data['Survived'] = last_prediction.astype(int)\nsubmission_data","metadata":{"execution":{"iopub.status.busy":"2021-08-29T08:35:52.641254Z","iopub.execute_input":"2021-08-29T08:35:52.641729Z","iopub.status.idle":"2021-08-29T08:35:52.724336Z","shell.execute_reply.started":"2021-08-29T08:35:52.641621Z","shell.execute_reply":"2021-08-29T08:35:52.72271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data.to_csv('last_submission.csv', index = False)\nprint('Congratulations!! We did it!!')","metadata":{"execution":{"iopub.status.busy":"2021-08-29T08:09:47.252503Z","iopub.execute_input":"2021-08-29T08:09:47.252931Z","iopub.status.idle":"2021-08-29T08:09:47.263699Z","shell.execute_reply.started":"2021-08-29T08:09:47.252897Z","shell.execute_reply":"2021-08-29T08:09:47.262906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Other Work( please **upvote**ï¼œ(_ _)ï¼ )\n\n* [The power of normality and visualization\n](https://www.kaggle.com/fightingmuscle/the-power-of-normality-and-visualization)\n* [EDA more technicalğŸ”¥](https://www.kaggle.com/fightingmuscle/eda-more-technical)\n\n> These notebooks were put together by me as a beginner, so I believe anyone can learn from them!\n\n* [How did I get the silver medal?(0.717)ã€Inferã€‘](https://www.kaggle.com/fightingmuscle/how-did-i-get-the-silver-medal-0-717-infer/comments)\n\n> I got silver medal for the first time! I published my inference code and trained models. My training code will be available soon, please wait. ","metadata":{}},{"cell_type":"markdown","source":"\n<h4 style = \n  \"color: #505050;\n  padding: 1.5em;\n  display: inline-block;\n  line-height: 2;\n  width: 600px;\n  background: #dbebf8;\n  vertical-align: middle;\n  border-radius: 30px 0px 0px 25px;\n  font-family:'Corben', cursive;\n  font-size:24px;\">\n    If this notebook is useful for you, <br>please <b>UPVOTE</b> and <b>COMMENTS</b>Ù©(à¹‘â›á´—â›à¹‘)Û¶ </h4>","metadata":{}}]}