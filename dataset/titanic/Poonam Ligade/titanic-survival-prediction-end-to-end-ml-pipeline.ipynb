{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ac51b485-dd2c-42d6-1063-30f13cf3447b"},"source":"## Introduction\n\n**_Poonam Ligade_**\n\n*27th Dec 2016*\n\nI am are trying to find out how many people on titanic survived from disaster.\n\nHere goes Titanic Survival Prediction End to End ML Pipeline  \n\n 1) **Introduction**\n\n 1. Import Libraries\n 2. Load data\n 3. Run Statistical summeries\n 4. Figure out missing value columns\n\n \n \n2) **Visualizations**\n\n 1. Correlation with target variable\n\n\n3) **Missing values imputation**\n\n 1. train data Missing columns- Embarked,Age,Cabin\n 2. test data Missing columns- Age and Fare\n \n\n4) **Feature Engineering**\n\n 1. Calculate total family size\n 2. Get title from name\n 3. Find out which deck passenger belonged to\n 4. Dealing with Categorical Variables\n     * Label encoding\n 5. Feature Scaling\n\n\n5) **Prediction**\n\n 1. Split into training & test sets\n 2. Build the model\n 3. Feature importance\n 4. Predictions\n 5. Ensemble : Majority voting\n\n6) **Submission**"},{"cell_type":"markdown","metadata":{"_cell_guid":"b08fc249-4282-b9df-caf1-8812ccc3c88a"},"source":"Import libraries\n================"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca368e06-2fa2-9a36-1193-72f7a9c752f2"},"outputs":[],"source":"# We can use the pandas library in python to read in the csv file.\nimport pandas as pd\n#for numerical computaions we can use numpy library\nimport numpy as np"},{"cell_type":"markdown","metadata":{"_cell_guid":"41422d21-5c02-9fd3-c2fb-6a3de9f5e6a0"},"source":"Load train & test data\n======================"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4ab5e1b-0da0-3d9e-b53e-79a17633ca0b"},"outputs":[],"source":"# This creates a pandas dataframe and assigns it to the titanic variable.\ntitanic = pd.read_csv(\"../input/train.csv\")\n# Print the first 5 rows of the dataframe.\ntitanic.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b258ce7d-c480-28aa-edca-7cc1fedc2bd3"},"outputs":[],"source":"titanic_test = pd.read_csv(\"../input/test.csv\")\n#transpose\ntitanic_test.head().T\n#note their is no Survived column here which is our target varible we are trying to predict"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf2a8459-1472-09c1-7c52-0a94f4b07561"},"outputs":[],"source":"#shape command will give number of rows/samples/examples and number of columns/features/predictors in dataset\n#(rows,columns)\ntitanic.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5426fa8f-0323-33c4-f16b-13bece60f111"},"outputs":[],"source":"#Describe gives statistical information about numerical columns in the dataset\ntitanic.describe()\n#you can check from count if there are missing vales in columns, here age has got missing values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3ecec9e-b1b6-f16a-9e1f-81f100e3ec85"},"outputs":[],"source":"#info method provides information about dataset like \n#total values in each column, null/not null, datatype, memory occupied etc\ntitanic.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f252150-c25f-ca25-e981-116fcdd18afc"},"outputs":[],"source":"#lets see if there are any more columns with missing values \nnull_columns=titanic.columns[titanic.isnull().any()]\ntitanic.isnull().sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"acd3b9aa-6d66-f572-05fe-85f9c11ba8a8"},"source":"**yes even Embarked and cabin has missing values.**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45ef8d0c-e417-b9d5-df59-8af551bc9b22"},"outputs":[],"source":"#how about test set??\ntitanic_test.isnull().sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"8e9ebd25-beb4-1cae-31a9-6dec5ad2fba5"},"source":"**Age, Fare and cabin has missing values.\nwe will see how to fill missing values next.**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"272d763e-ec39-8a40-4092-0f52f465f410"},"outputs":[],"source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1)\n\npd.options.display.mpl_style = 'default'\nlabels = []\nvalues = []\nfor col in null_columns:\n    labels.append(col)\n    values.append(titanic[col].isnull().sum())\nind = np.arange(len(labels))\nwidth=0.6\nfig, ax = plt.subplots(figsize=(6,5))\nrects = ax.barh(ind, np.array(values), color='purple')\nax.set_yticks(ind+((width)/2.))\nax.set_yticklabels(labels, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_ylabel(\"Column Names\")\nax.set_title(\"Variables with missing values\");"},{"cell_type":"markdown","metadata":{"_cell_guid":"0cecf155-c3de-71b4-8438-a607071892dc"},"source":"**Visualizations**\n=============="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ab94597-9a8d-513f-0a57-22ba0568b1e0"},"outputs":[],"source":"titanic.hist(bins=10,figsize=(9,7),grid=False);"},{"cell_type":"markdown","metadata":{"_cell_guid":"5fd08b45-dcef-0c2e-853c-7e739a67b8f7"},"source":"**we can see that Age and Fare are measured on very different scaling. So we need to do feature scaling before predictions.**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6475eac5-337b-b723-6917-613bf61e438c"},"outputs":[],"source":"g = sns.FacetGrid(titanic, col=\"Sex\", row=\"Survived\", margin_titles=True)\ng.map(plt.hist, \"Age\",color=\"purple\");"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71adfcb6-e71d-60bc-a0d3-ee4ff1c9c404"},"outputs":[],"source":"g = sns.FacetGrid(titanic, hue=\"Survived\", col=\"Pclass\", margin_titles=True,\n                  palette={1:\"seagreen\", 0:\"gray\"})\ng=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend();"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9bfbe633-b249-e7cb-2fde-4ec2b9097b3f"},"outputs":[],"source":"g = sns.FacetGrid(titanic, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n                palette=\"Set1\",hue_kws=dict(marker=[\"^\", \"v\"]))\ng.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('Survival by Gender , Age and Fare');"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"551673fc-d91a-623a-41f0-5eebe3567ce1"},"outputs":[],"source":"titanic.Embarked.value_counts().plot(kind='bar', alpha=0.55)\nplt.title(\"Passengers per boarding location\");"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d4403b1-daef-2333-5d89-276f25444316"},"outputs":[],"source":"sns.factorplot(x = 'Embarked',y=\"Survived\", data = titanic,color=\"r\");"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c496b777-ca8e-5b3c-af76-5ad8d63b7c95"},"outputs":[],"source":"sns.set(font_scale=1)\ng = sns.factorplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\",\n                    data=titanic, saturation=.5,\n                    kind=\"bar\", ci=None, aspect=.6)\n(g.set_axis_labels(\"\", \"Survival Rate\")\n    .set_xticklabels([\"Men\", \"Women\"])\n    .set_titles(\"{col_name} {col_var}\")\n    .set(ylim=(0, 1))\n    .despine(left=True))  \nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('How many Men and Women Survived by Passenger Class');"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9b046b29-4116-da22-18df-36b7459e68a1"},"outputs":[],"source":"ax = sns.boxplot(x=\"Survived\", y=\"Age\", \n                data=titanic)\nax = sns.stripplot(x=\"Survived\", y=\"Age\",\n                   data=titanic, jitter=True,\n                   edgecolor=\"gray\")\nsns.plt.title(\"Survival by Age\",fontsize=12);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ab7ea3f-ec34-0419-6ac0-b20379a25a49"},"outputs":[],"source":"titanic.Age[titanic.Pclass == 1].plot(kind='kde')    \ntitanic.Age[titanic.Pclass == 2].plot(kind='kde')\ntitanic.Age[titanic.Pclass == 3].plot(kind='kde')\n # plots an axis lable\nplt.xlabel(\"Age\")    \nplt.title(\"Age Distribution within classes\")\n# sets our legend for our graph.\nplt.legend(('1st Class', '2nd Class','3rd Class'),loc='best') ;"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2937ff19-58b1-e044-1254-b5b00e87496c"},"outputs":[],"source":"corr=titanic.corr()#[\"Survived\"]\nplt.figure(figsize=(10, 10))\n\nsns.heatmap(corr, vmax=.8, linewidths=0.01,\n            square=True,annot=True,cmap='YlGnBu',linecolor=\"white\")\nplt.title('Correlation between features');"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1206942-e525-d6fc-e47b-0c1bfd5de79c"},"outputs":[],"source":"#correlation of features with target variable\ntitanic.corr()[\"Survived\"]"},{"cell_type":"markdown","metadata":{"_cell_guid":"c7dd332b-d578-a4c2-6b7a-86412f4da80d"},"source":"**Looks like Pclass has got highest negative correlation with \"Survived\" followed by Fare, Parch and Age** "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b287eec7-bcdb-c034-9246-d07e806d3b40"},"outputs":[],"source":"g = sns.factorplot(x=\"Age\", y=\"Embarked\",\n                    hue=\"Sex\", row=\"Pclass\",\n                    data=titanic[titanic.Embarked.notnull()],\n                    orient=\"h\", size=2, aspect=3.5, \n                   palette={'male':\"purple\", 'female':\"blue\"},\n                    kind=\"violin\", split=True, cut=0, bw=.2);"},{"cell_type":"markdown","metadata":{"_cell_guid":"db0d041c-8f3a-bc68-42fb-1c8fd6a5addf"},"source":"Missing Value Imputation\n========================\n\n**Its important to fill missing values, because some machine learning algorithms can't accept them eg SVM.**\n\n*But filling missing values with mean/median/mode is also a prediction which may not be 100% accurate, instead you can use models like Decision Trees and Random Forest which handle missing values very well.*"},{"cell_type":"markdown","metadata":{"_cell_guid":"7e9f9bac-8e0b-d2b9-4d6d-164266d6f237"},"source":"**Embarked Column**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9cef6611-7c95-8a85-0bba-3074e80e46ad"},"outputs":[],"source":"#Lets check which rows have null Embarked column\ntitanic[titanic['Embarked'].isnull()]"},{"cell_type":"markdown","metadata":{"_cell_guid":"882ac871-7370-9b1f-c4c3-f2bb96e6c484"},"source":"**PassengerId 62 and 830** have missing embarked values\n\nBoth have ***Passenger class 1*** and ***fare $80.***\n\nLets plot a graph to visualize and try to guess from where they embarked"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"258a79df-363e-3f98-233d-e0be38decdc7"},"outputs":[],"source":"sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=titanic);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0246b387-93c3-fd51-4263-034d1580b774"},"outputs":[],"source":"titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('C')"},{"cell_type":"markdown","metadata":{"_cell_guid":"7dc1044b-d0bb-91e3-8254-22f35a88dbb1"},"source":"We can see that for ***1st class*** median line is coming around ***fare $80*** for ***embarked*** value ***'C'***.\nSo we can replace NA values in Embarked column with 'C'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba29dd0b-2809-6dfe-311b-fbf36f649691"},"outputs":[],"source":"#there is an empty fare column in test set\ntitanic_test.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ef40043e-b71a-55a4-6d76-bb153ee46167"},"source":"***Fare Column***"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b12ef788-b106-65b3-4c41-b9074037ccf5"},"outputs":[],"source":"titanic_test[titanic_test['Fare'].isnull()]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bdc9992f-8505-c75c-e851-b9ee44028338"},"outputs":[],"source":"#we can replace missing value in fare by taking median of all fares of those passengers \n#who share 3rd Passenger class and Embarked from 'S' \ndef fill_missing_fare(df):\n    median_fare=df[(df['Pclass'] == 3) & (df['Embarked'] == 'S')]['Fare'].median()\n#'S'\n       #print(median_fare)\n    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n    return df\n\ntitanic_test=fill_missing_fare(titanic_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"5233c2f0-2516-47ca-28e6-b95a5ffaed4b"},"source":"Feature Engineering\n==================="},{"cell_type":"markdown","metadata":{"_cell_guid":"4556983b-1b5a-3443-0eba-f72131ec9f5a"},"source":"***Deck- Where exactly were passenger on the ship?***"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d063ebb6-4ad3-5669-fd20-eda5a80d4ab1"},"outputs":[],"source":"titanic[\"Deck\"]=titanic.Cabin.str[0]\ntitanic_test[\"Deck\"]=titanic_test.Cabin.str[0]\ntitanic[\"Deck\"].unique() # 0 is for null values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7107678-4293-5996-9dbd-16e3ba1d39d1"},"outputs":[],"source":"g = sns.factorplot(\"Survived\", col=\"Deck\", col_wrap=4,\n                    data=titanic[titanic.Deck.notnull()],\n                    kind=\"count\", size=2.5, aspect=.8);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"313b4c34-73aa-be03-e88b-81de3d089b80"},"outputs":[],"source":"titanic = titanic.assign(Deck=titanic.Deck.astype(object)).sort(\"Deck\")\ng = sns.FacetGrid(titanic, col=\"Pclass\", sharex=False,\n                  gridspec_kws={\"width_ratios\": [5, 3, 3]})\ng.map(sns.boxplot, \"Deck\", \"Age\");"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e18f90fe-d145-9ca1-f309-b8d256ae500e"},"outputs":[],"source":"titanic.Deck.fillna('Z', inplace=True)\ntitanic_test.Deck.fillna('Z', inplace=True)\ntitanic[\"Deck\"].unique() # Z is for null values"},{"cell_type":"markdown","metadata":{"_cell_guid":"4e74d0c4-2165-90be-bdf0-17e81d180dd4"},"source":"***How Big is your family?***"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa04d676-b171-a229-c235-e68b2cd4c394"},"outputs":[],"source":"# Create a family size variable including the passenger themselves\ntitanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]+1\ntitanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]+1\nprint(titanic[\"FamilySize\"].value_counts())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0f690fd-b09e-2e3b-43dd-02818c06c6f9"},"outputs":[],"source":"# Discretize family size\ntitanic.loc[titanic[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic.loc[(titanic[\"FamilySize\"] > 1)  &  (titanic[\"FamilySize\"] < 5) , \"FsizeD\"] = 'small'\ntitanic.loc[titanic[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\n\ntitanic_test.loc[titanic_test[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic_test.loc[(titanic_test[\"FamilySize\"] >1) & (titanic_test[\"FamilySize\"] <5) , \"FsizeD\"] = 'small'\ntitanic_test.loc[titanic_test[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\nprint(titanic[\"FsizeD\"].unique())\nprint(titanic[\"FsizeD\"].value_counts())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dfb39182-d1e1-1a96-68dc-60728687a548"},"outputs":[],"source":"sns.factorplot(x=\"FsizeD\", y=\"Survived\", data=titanic);"},{"cell_type":"markdown","metadata":{"_cell_guid":"2f29644d-d862-c207-9699-cba9dc2917d1"},"source":"***Do you have longer names?***"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e10d62f7-c270-01c1-3d09-605b995bba80"},"outputs":[],"source":"#Create feture for length of name \n# The .apply method generates a new series\ntitanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n\ntitanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))\n#print(titanic[\"NameLength\"].value_counts())\n\nbins = [0, 20, 40, 57, 85]\ngroup_names = ['short', 'okay', 'good', 'long']\ntitanic['NlengthD'] = pd.cut(titanic['NameLength'], bins, labels=group_names)\ntitanic_test['NlengthD'] = pd.cut(titanic_test['NameLength'], bins, labels=group_names)\n\nsns.factorplot(x=\"NlengthD\", y=\"Survived\", data=titanic)\nprint(titanic[\"NlengthD\"].unique())"},{"cell_type":"markdown","metadata":{"_cell_guid":"39368ec9-a8be-b5d1-b208-b8674a4be8f8"},"source":"***Whats in the name?***"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"179a8eb2-e927-92fa-e33f-57215c5cb2b9"},"outputs":[],"source":"import re\n\n#A function to get the title from a name.\ndef get_title(name):\n    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    #If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\n#Get all the titles and print how often each one occurs.\ntitles = titanic[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\n\n#Add in the title column.\ntitanic[\"Title\"] = titles\n\n# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\n# Also reassign mlle, ms, and mme accordingly\ntitanic.loc[titanic[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntitanic.loc[titanic[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntitanic.loc[titanic[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntitanic.loc[titanic[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\n#titanic.loc[titanic[\"Title\"].isin(['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n#                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']), \"Title\"] = 'Rare Title'\n\n#titanic[titanic['Title'].isin(['Dona', 'Lady', 'Countess'])]\n#titanic.query(\"Title in ('Dona', 'Lady', 'Countess')\")\n\ntitanic[\"Title\"].value_counts()\n\n\ntitles = titanic_test[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\n#Add in the title column.\ntitanic_test[\"Title\"] = titles\n\n# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\n# Also reassign mlle, ms, and mme accordingly\ntitanic_test.loc[titanic_test[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\ntitanic_test[\"Title\"].value_counts()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b198853-1885-585b-ae20-054116b0a5d3"},"source":"***Ticket column***"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4b7f87f-b33d-de30-8924-e1d432cd0f9f"},"outputs":[],"source":"titanic[\"Ticket\"].tail()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"547cea2d-409f-40f0-3f9e-78eef0c53666"},"outputs":[],"source":"titanic[\"TicketNumber\"] = titanic[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntitanic[\"TicketNumber\"] = titanic[\"TicketNumber\"].apply(pd.to_numeric)\n\n\ntitanic_test[\"TicketNumber\"] = titanic_test[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntitanic_test[\"TicketNumber\"] = titanic_test[\"TicketNumber\"].apply(pd.to_numeric)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d44754c-24a3-0dad-3ec8-2c1ee1d9a2aa"},"outputs":[],"source":"#some rows in ticket column dont have numeric value so we got NaN there\ntitanic[titanic[\"TicketNumber\"].isnull()]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43df4f5b-e871-4bf0-b2d4-2b9f65fa38ec"},"outputs":[],"source":"titanic.TicketNumber.fillna(titanic[\"TicketNumber\"].median(), inplace=True)\ntitanic_test.TicketNumber.fillna(titanic_test[\"TicketNumber\"].median(), inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"062dec4a-6e51-910c-18cc-3f343a51f542"},"source":"Convert Categorical variables into Numerical ones\n================================================="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"539e9eaa-7b17-2e4e-d433-133e6b7ab91b"},"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n\nlabelEnc=LabelEncoder()\n\ncat_vars=['Embarked','Sex',\"Title\",\"FsizeD\",\"NlengthD\",'Deck']\nfor col in cat_vars:\n    titanic[col]=labelEnc.fit_transform(titanic[col])\n    titanic_test[col]=labelEnc.fit_transform(titanic_test[col])\n\ntitanic.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"361f67a8-fa29-eb74-12d9-806dd27a5655"},"source":"***Age Column***\n\nAge seems to be promising feature.\nSo it doesnt make sense to simply fill null values out with median/mean/mode.\n\nWe will use ***Random Forest*** algorithm to predict ages. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"749e5a8c-eaa6-4e65-3ffb-9c463cc55be1"},"outputs":[],"source":"with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(titanic[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"red\")\n    sns.plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\");"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1fd4adce-c3c2-9857-7bd5-aa92e7839096"},"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\n#predicting missing values in age using Random Forest\ndef fill_missing_age(df):\n    \n    #Feature set\n    age_df = df[['Age','Embarked','Fare', 'Parch', 'SibSp',\n                 'TicketNumber', 'Title','Pclass','FamilySize',\n                 'FsizeD','NameLength',\"NlengthD\",'Deck']]\n    # Split sets into train and test\n    train  = age_df.loc[ (df.Age.notnull()) ]# known Age values\n    test = age_df.loc[ (df.Age.isnull()) ]# null Ages\n    \n    # All age values are stored in a target array\n    y = train.values[:, 0]\n    \n    # All the other values are stored in the feature array\n    X = train.values[:, 1::]\n    \n    # Create and fit a model\n    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n    rtr.fit(X, y)\n    \n    # Use the fitted model to predict the missing values\n    predictedAges = rtr.predict(test.values[:, 1::])\n    \n    # Assign those predictions to the full data set\n    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n    \n    return df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fae9d082-458a-4f94-1ac5-70b1e9ab8e6e"},"outputs":[],"source":"titanic=fill_missing_age(titanic)\ntitanic_test=fill_missing_age(titanic_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"28e70904-dcd9-158c-eb2c-3c114c6fc166"},"outputs":[],"source":"with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(titanic[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"tomato\")\n    sns.plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\")\n    plt.xlim((15,100));"},{"cell_type":"markdown","metadata":{"_cell_guid":"e3ea673a-769a-de7b-a95b-5105c3bec1ef"},"source":"**Feature Scaling**\n===============\n\nWe can see that Age, Fare are measured on different scales, so we need to do Feature Scaling first before we proceed with predictions."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e32e691e-1d4b-f9b8-c0b6-bf422879679b"},"outputs":[],"source":"from sklearn import preprocessing\n\nstd_scale = preprocessing.StandardScaler().fit(titanic[['Age', 'Fare']])\ntitanic[['Age', 'Fare']] = std_scale.transform(titanic[['Age', 'Fare']])\n\n\nstd_scale = preprocessing.StandardScaler().fit(titanic_test[['Age', 'Fare']])\ntitanic_test[['Age', 'Fare']] = std_scale.transform(titanic_test[['Age', 'Fare']])"},{"cell_type":"markdown","metadata":{"_cell_guid":"1322bdd4-2438-b77f-1489-21a319a92883"},"source":"Correlation of features with target \n======================="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c66dd526-36a1-f3b2-ed34-4ecfe02bca69"},"outputs":[],"source":"titanic.corr()[\"Survived\"]"},{"cell_type":"markdown","metadata":{"_cell_guid":"dc110fb3-3ac8-f68e-af62-c4d9caef0271"},"source":"Predict Survival\n================"},{"cell_type":"markdown","metadata":{"_cell_guid":"2e105e15-4ca1-c6a9-d52c-1f140eb0a733"},"source":"*Linear Regression*\n-------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef0672f1-9b05-e0d0-6d6b-6334704fbb77"},"outputs":[],"source":"# Import the linear regression class\nfrom sklearn.linear_model import LinearRegression\n# Sklearn also has a helper that makes it easy to do cross validation\nfrom sklearn.cross_validation import KFold\n\n# The columns we'll use to predict the target\npredictors = [\"Pclass\", \"Sex\", \"Age\",\"SibSp\", \"Parch\", \"Fare\",\n              \"Embarked\",\"NlengthD\", \"FsizeD\", \"Title\",\"Deck\"]\ntarget=\"Survived\"\n# Initialize our algorithm class\nalg = LinearRegression()\n\n# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n# We set random_state to ensure we get the same splits every time we run this.\nkf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n\npredictions = []"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"425ab117-b2ea-72d5-651b-15ed0d2f14f8"},"outputs":[],"source":"for train, test in kf:\n    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n    train_predictors = (titanic[predictors].iloc[train,:])\n    # The target we're using to train the algorithm.\n    train_target = titanic[target].iloc[train]\n    # Training the algorithm using the predictors and target.\n    alg.fit(train_predictors, train_target)\n    # We can now make predictions on the test fold\n    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n    predictions.append(test_predictions)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4aacd69-0228-3a8e-5f94-a5e52f834e59"},"outputs":[],"source":"predictions = np.concatenate(predictions, axis=0)\n# Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions > .5] = 1\npredictions[predictions <=.5] = 0\n\n\naccuracy=sum(titanic[\"Survived\"]==predictions)/len(titanic[\"Survived\"])\naccuracy"},{"cell_type":"markdown","metadata":{"_cell_guid":"5b7a8c8c-e97c-a4f1-677b-3daea73885e9"},"source":"*Logistic Regression*\n-------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4332e05-2db0-88ff-0a3a-e4d2d5cbb861"},"outputs":[],"source":"from sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\n\npredictors = [\"Pclass\", \"Sex\", \"Fare\", \"Embarked\",\"Deck\",\"Age\",\n              \"FsizeD\", \"NlengthD\",\"Title\",\"Parch\"]\n\n# Initialize our algorithm\nlr = LogisticRegression(random_state=1)\n# Compute the accuracy score for all the cross validation folds.\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\nscores = cross_val_score(lr, titanic[predictors], \n                                          titanic[\"Survived\"],scoring='f1', cv=cv)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())"},{"cell_type":"markdown","metadata":{"_cell_guid":"c8eee663-2c77-77da-f370-0f7372a3c8e1"},"source":"*Random Forest *\n-------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0eedacc0-6a3f-d35c-ab71-0da403d5d773"},"outputs":[],"source":"from sklearn import cross_validation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import KFold\nfrom sklearn.model_selection import cross_val_predict\n\nimport numpy as np\npredictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\",\"NameLength\", \"FsizeD\", \"Title\",\"Deck\"]\n\n# Initialize our algorithm with the default paramters\n# n_estimators is the number of trees we want to make\n# min_samples_split is the minimum number of rows we need to make a split\n# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\nrf = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, \n                            min_samples_leaf=1)\nkf = KFold(titanic.shape[0], n_folds=5, random_state=1)\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\npredictions = cross_validation.cross_val_predict(rf, titanic[predictors],titanic[\"Survived\"],cv=kf)\npredictions = pd.Series(predictions)\nscores = cross_val_score(rf, titanic[predictors], titanic[\"Survived\"],\n                                          scoring='f1', cv=kf)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d86a3faa-d10b-5b4f-54c8-583e11a5da8d"},"outputs":[],"source":"predictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\",\"NameLength\", \"FsizeD\", \"Title\",\"Deck\",\"TicketNumber\"]\nrf = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=9,min_samples_split=6, min_samples_leaf=4)\nrf.fit(titanic[predictors],titanic[\"Survived\"])\nkf = KFold(titanic.shape[0], n_folds=5, random_state=1)\npredictions = cross_validation.cross_val_predict(rf, titanic[predictors],titanic[\"Survived\"],cv=kf)\npredictions = pd.Series(predictions)\nscores = cross_val_score(rf, titanic[predictors], titanic[\"Survived\"],scoring='f1', cv=kf)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())"},{"cell_type":"markdown","metadata":{"_cell_guid":"b4a08e76-1dfe-468b-d3f8-a6198c59b7bb"},"source":"Important features\n=================="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2567e540-6c3c-0f17-46ce-7f204f0da8fc"},"outputs":[],"source":"importances=rf.feature_importances_\nstd = np.std([rf.feature_importances_ for tree in rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\nsorted_important_features=[]\nfor i in indices:\n    sorted_important_features.append(predictors[i])\n#predictors=titanic.columns\nplt.figure()\nplt.title(\"Feature Importances By Random Forest Model\")\nplt.bar(range(np.size(predictors)), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n\nplt.xlim([-1, np.size(predictors)]);"},{"cell_type":"markdown","metadata":{"_cell_guid":"214e9136-49a1-bcc8-6ff3-063f6907a735"},"source":"*Gradient Boosting*\n-------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"440b4b19-c73b-00cf-8263-ae42daddb889"},"outputs":[],"source":"import numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.cross_validation import KFold\n%matplotlib inline\nimport matplotlib.pyplot as plt\n#predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\",\n #             \"FsizeD\", \"Embarked\", \"NlengthD\",\"Deck\",\"TicketNumber\"]\npredictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\", \"FsizeD\",\"NameLength\",\"Deck\",\"Embarked\"]\n# Perform feature selection\nselector = SelectKBest(f_classif, k=5)\nselector.fit(titanic[predictors], titanic[\"Survived\"])\n\n# Get the raw p-values for each feature, and transform from p-values into scores\nscores = -np.log10(selector.pvalues_)\n\nindices = np.argsort(scores)[::-1]\n\nsorted_important_features=[]\nfor i in indices:\n    sorted_important_features.append(predictors[i])\n\nplt.figure()\nplt.title(\"Feature Importances By SelectKBest\")\nplt.bar(range(np.size(predictors)), scores[indices],\n       color=\"seagreen\", yerr=std[indices], align=\"center\")\nplt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n\nplt.xlim([-1, np.size(predictors)]);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b54f7e1-2c1a-5568-bfc1-e6dd70990678"},"outputs":[],"source":"from sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\"]\n\n# Initialize our algorithm\nlr = LogisticRegression(random_state=1)\n# Compute the accuracy score for all the cross validation folds.  \ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\nscores = cross_val_score(lr, titanic[predictors], titanic[\"Survived\"], scoring='f1',cv=cv)\nprint(scores.mean())"},{"cell_type":"markdown","metadata":{"_cell_guid":"096fcc02-e23b-d9f4-f3a1-d4a9ec23f89a"},"source":"*AdaBoost *\n--------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"892414ea-998b-21c6-85a8-86c8e0c71127"},"outputs":[],"source":"from sklearn.ensemble import AdaBoostClassifier\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"TicketNumber\"]\nadb=AdaBoostClassifier()\nadb.fit(titanic[predictors],titanic[\"Survived\"])\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\nscores = cross_val_score(adb, titanic[predictors], titanic[\"Survived\"], scoring='f1',cv=cv)\nprint(scores.mean())"},{"cell_type":"markdown","metadata":{"_cell_guid":"deb63887-1f64-482d-3ad6-bd5179a8448a"},"source":"Maximum Voting ensemble and Submission\n======="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b98fa41-2376-096f-8dff-525e521c1973"},"outputs":[],"source":"predictions=[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"NameLength\",\"TicketNumber\"]\nfrom sklearn.ensemble import VotingClassifier\neclf1 = VotingClassifier(estimators=[\n        ('lr', lr), ('rf', rf), ('adb', adb)], voting='soft')\neclf1 = eclf1.fit(titanic[predictors], titanic[\"Survived\"])\npredictions=eclf1.predict(titanic[predictors])\npredictions\n\ntest_predictions=eclf1.predict(titanic_test[predictors])\n\ntest_predictions=test_predictions.astype(int)\nsubmission = pd.DataFrame({\n        \"PassengerId\": titanic_test[\"PassengerId\"],\n        \"Survived\": test_predictions\n    })\n\nsubmission.to_csv(\"titanic_submission.csv\", index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"141131e6-ccc2-c5fb-f1d7-43ca7f121703"},"source":"***To do: stacking!. Watch this spaceâ€¦***"},{"cell_type":"markdown","metadata":{"_cell_guid":"0f6cee21-6591-453b-1afa-867fec86cdfb"},"source":"***Hope you find it useful. :)please upvote***"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}