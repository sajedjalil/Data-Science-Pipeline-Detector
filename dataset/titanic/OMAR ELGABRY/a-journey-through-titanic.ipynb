{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cfdaacbc-23a3-423d-8d4d-120939ac7383"},"outputs":[],"source":"# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ab4c525-a5cb-4183-9468-c1dd005c4c78"},"outputs":[],"source":"# get titanic & test csv files as a DataFrame\ntitanic_df = pd.read_csv(\"../input/train.csv\")\ntest_df    = pd.read_csv(\"../input/test.csv\")\n\n# preview the data\ntitanic_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86179af8-3cb4-4661-84ea-addd2c7679d4"},"outputs":[],"source":"titanic_df.info()\nprint(\"----------------------------\")\ntest_df.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7faffa7c-9776-43fb-9c01-786630f237ab"},"outputs":[],"source":"# drop unnecessary columns, these columns won't be useful in analysis and prediction\ntitanic_df = titanic_df.drop(['PassengerId','Name','Ticket'], axis=1)\ntest_df    = test_df.drop(['Name','Ticket'], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1441ec8-7d77-4a69-990b-26e0b1e89b68"},"outputs":[],"source":"# Embarked\n\n# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\ntitanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")\n\n# plot\nsns.factorplot('Embarked','Survived', data=titanic_df,size=4,aspect=3)\n\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n\n# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)\n# sns.factorplot('Survived',hue=\"Embarked\",data=titanic_df,kind='count',order=[1,0],ax=axis2)\nsns.countplot(x='Embarked', data=titanic_df, ax=axis1)\nsns.countplot(x='Survived', hue=\"Embarked\", data=titanic_df, order=[1,0], ax=axis2)\n\n# group by embarked, and get the mean for survived passengers for each value in Embarked\nembark_perc = titanic_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\nsns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n\n# Either to consider Embarked column in predictions,\n# and remove \"S\" dummy variable, \n# and leave \"C\" & \"Q\", since they seem to have a good rate for Survival.\n\n# OR, don't create dummy variables for Embarked column, just drop it, \n# because logically, Embarked doesn't seem to be useful in prediction.\n\nembark_dummies_titanic  = pd.get_dummies(titanic_df['Embarked'])\nembark_dummies_titanic.drop(['S'], axis=1, inplace=True)\n\nembark_dummies_test  = pd.get_dummies(test_df['Embarked'])\nembark_dummies_test.drop(['S'], axis=1, inplace=True)\n\ntitanic_df = titanic_df.join(embark_dummies_titanic)\ntest_df    = test_df.join(embark_dummies_test)\n\ntitanic_df.drop(['Embarked'], axis=1,inplace=True)\ntest_df.drop(['Embarked'], axis=1,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1a9e2e1-1718-4e6a-b037-a2c1eca1c003"},"outputs":[],"source":"# Fare\n\n# only for test_df, since there is a missing \"Fare\" values\ntest_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n\n# convert from float to int\ntitanic_df['Fare'] = titanic_df['Fare'].astype(int)\ntest_df['Fare']    = test_df['Fare'].astype(int)\n\n# get fare for survived & didn't survive passengers \nfare_not_survived = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 0]\nfare_survived     = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 1]\n\n# get average and std for fare of survived/not survived passengers\navgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\nstd_fare      = DataFrame([fare_not_survived.std(), fare_survived.std()])\n\n# plot\ntitanic_df['Fare'].plot(kind='hist', figsize=(15,3),bins=100, xlim=(0,50))\n\navgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\navgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22ab0b38-6285-4d65-bb3e-dc923caed94b"},"outputs":[],"source":"# Age \n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\naxis1.set_title('Original Age values - Titanic')\naxis2.set_title('New Age values - Titanic')\n\n# axis3.set_title('Original Age values - Test')\n# axis4.set_title('New Age values - Test')\n\n# get average, std, and number of NaN values in titanic_df\naverage_age_titanic   = titanic_df[\"Age\"].mean()\nstd_age_titanic       = titanic_df[\"Age\"].std()\ncount_nan_age_titanic = titanic_df[\"Age\"].isnull().sum()\n\n# get average, std, and number of NaN values in test_df\naverage_age_test   = test_df[\"Age\"].mean()\nstd_age_test       = test_df[\"Age\"].std()\ncount_nan_age_test = test_df[\"Age\"].isnull().sum()\n\n# generate random numbers between (mean - std) & (mean + std)\nrand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\nrand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n\n# plot original Age values\n# NOTE: drop all null values, and convert to int\ntitanic_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n\n# fill NaN values in Age column with random values generated\ntitanic_df[\"Age\"][np.isnan(titanic_df[\"Age\"])] = rand_1\ntest_df[\"Age\"][np.isnan(test_df[\"Age\"])] = rand_2\n\n# convert from float to int\ntitanic_df['Age'] = titanic_df['Age'].astype(int)\ntest_df['Age']    = test_df['Age'].astype(int)\n        \n# plot new Age Values\ntitanic_df['Age'].hist(bins=70, ax=axis2)\n# test_df['Age'].hist(bins=70, ax=axis4)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"952009ab-555c-46f8-b419-182f2de39ca0"},"outputs":[],"source":"# .... continue with plot Age column\n\n# peaks for survived/not survived passengers by their age\nfacet = sns.FacetGrid(titanic_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, titanic_df['Age'].max()))\nfacet.add_legend()\n\n# average survived passengers by age\nfig, axis1 = plt.subplots(1,1,figsize=(18,4))\naverage_age = titanic_df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\nsns.barplot(x='Age', y='Survived', data=average_age)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef0f0c9d-6b45-4cb0-9026-86b764084398"},"outputs":[],"source":"# Cabin\n# It has a lot of NaN values, so it won't cause a remarkable impact on prediction\ntitanic_df.drop(\"Cabin\",axis=1,inplace=True)\ntest_df.drop(\"Cabin\",axis=1,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a89c93bb-e45b-44ce-8dee-430f584f4ed4"},"outputs":[],"source":"# Family\n\n# Instead of having two columns Parch & SibSp, \n# we can have only one column represent if the passenger had any family member aboard or not,\n# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\ntitanic_df['Family'] =  titanic_df[\"Parch\"] + titanic_df[\"SibSp\"]\ntitanic_df['Family'].loc[titanic_df['Family'] > 0] = 1\ntitanic_df['Family'].loc[titanic_df['Family'] == 0] = 0\n\ntest_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\ntest_df['Family'].loc[test_df['Family'] > 0] = 1\ntest_df['Family'].loc[test_df['Family'] == 0] = 0\n\n# drop Parch & SibSp\ntitanic_df = titanic_df.drop(['SibSp','Parch'], axis=1)\ntest_df    = test_df.drop(['SibSp','Parch'], axis=1)\n\n# plot\nfig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(10,5))\n\n# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)\nsns.countplot(x='Family', data=titanic_df, order=[1,0], ax=axis1)\n\n# average of survived for those who had/didn't have any family member\nfamily_perc = titanic_df[[\"Family\", \"Survived\"]].groupby(['Family'],as_index=False).mean()\nsns.barplot(x='Family', y='Survived', data=family_perc, order=[1,0], ax=axis2)\n\naxis1.set_xticklabels([\"With Family\",\"Alone\"], rotation=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23c2f140-1dc0-48cd-a6e1-9786510b2606"},"outputs":[],"source":"# Sex\n\n# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n# So, we can classify passengers as males, females, and child\ndef get_person(passenger):\n    age,sex = passenger\n    return 'child' if age < 16 else sex\n    \ntitanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\ntest_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n\n# No need to use Sex column since we created Person column\ntitanic_df.drop(['Sex'],axis=1,inplace=True)\ntest_df.drop(['Sex'],axis=1,inplace=True)\n\n# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\nperson_dummies_titanic  = pd.get_dummies(titanic_df['Person'])\nperson_dummies_titanic.columns = ['Child','Female','Male']\nperson_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n\nperson_dummies_test  = pd.get_dummies(test_df['Person'])\nperson_dummies_test.columns = ['Child','Female','Male']\nperson_dummies_test.drop(['Male'], axis=1, inplace=True)\n\ntitanic_df = titanic_df.join(person_dummies_titanic)\ntest_df    = test_df.join(person_dummies_test)\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n\n# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)\nsns.countplot(x='Person', data=titanic_df, ax=axis1)\n\n# average of survived for each Person(male, female, or child)\nperson_perc = titanic_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\nsns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n\ntitanic_df.drop(['Person'],axis=1,inplace=True)\ntest_df.drop(['Person'],axis=1,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f126c1f-74b8-4063-8ac0-f44e6b8fc0bd"},"outputs":[],"source":"# Pclass\n\n# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])\nsns.factorplot('Pclass','Survived',order=[1,2,3], data=titanic_df,size=5)\n\n# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers\npclass_dummies_titanic  = pd.get_dummies(titanic_df['Pclass'])\npclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\npclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n\npclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\npclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\npclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n\ntitanic_df.drop(['Pclass'],axis=1,inplace=True)\ntest_df.drop(['Pclass'],axis=1,inplace=True)\n\ntitanic_df = titanic_df.join(pclass_dummies_titanic)\ntest_df    = test_df.join(pclass_dummies_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5214295a-19cf-44b5-abe2-8989a0ed9670"},"outputs":[],"source":"# define training and testing sets\n\nX_train = titanic_df.drop(\"Survived\",axis=1)\nY_train = titanic_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\",axis=1).copy()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b5424c0-196f-4d23-b1b8-1b10ac27be10"},"outputs":[],"source":"# Logistic Regression\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nlogreg.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74988880-7f9e-45f4-b6b7-f7fd43a63f95"},"outputs":[],"source":"# Support Vector Machines\n\n# svc = SVC()\n\n# svc.fit(X_train, Y_train)\n\n# Y_pred = svc.predict(X_test)\n\n# svc.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f8b05ff-c21e-4e0e-975d-21af19c6b6b3"},"outputs":[],"source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"499918bf-8ba4-4a79-b8d8-4c26ece9a3b8"},"outputs":[],"source":"# knn = KNeighborsClassifier(n_neighbors = 3)\n\n# knn.fit(X_train, Y_train)\n\n# Y_pred = knn.predict(X_test)\n\n# knn.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15801b79-73c3-4fa4-b8be-21d32645a403"},"outputs":[],"source":"# Gaussian Naive Bayes\n\n# gaussian = GaussianNB()\n\n# gaussian.fit(X_train, Y_train)\n\n# Y_pred = gaussian.predict(X_test)\n\n# gaussian.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26dd2732-b34f-4177-8786-8794537494e1"},"outputs":[],"source":"# get Correlation Coefficient for each feature using Logistic Regression\ncoeff_df = DataFrame(titanic_df.columns.delete(0))\ncoeff_df.columns = ['Features']\ncoeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n\n# preview\ncoeff_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf28672b-9264-4d5a-95f8-47effc0e2e4c"},"outputs":[],"source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('titanic.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}