{"cells":[{"metadata":{"_uuid":"fdc2f9f1d89f2bcb849408b4e52c80a79da7eda7"},"cell_type":"markdown","source":"# Introduction<a id=\"1\"></a> <br>\n\nHello everyone, this is my first competition's solution.The data is about titanic casualties.There are features about casualities in dataset.The aim is predict situation of people who don't known survive or not survive.\n\n* [Introduction](#1)\n    * [Import Libraries](#2)\n    * [Load Data](#3)\n* [Exploratory Data Analysis](#4)\n    * [A Quik View of data](#5)\n    * [Cleaning data for Data Visualisation](#6)\n    * [Data Visualization](#7)\n        * [Line Plot](#8)\n        * [Count Plots](#9)\n\n* [Classification](#10)\n    * [Preparing data for Classification](#11)\n    * [Implementing Classification Algorithms](#12)\n        * [Logistic Regression](#13)\n        * [K-Nearest Neighbors](#14)\n        * [Support Vector Machine](#15)\n        * [Naive Bayes](#16)\n        * [Decision Tree](#17)\n        * [Random Forest](#18)\n    * [Compare and Compound Classificaton Algorithms](#19)\n    * [Preparing Output](#20)\n"},{"metadata":{"_uuid":"83010ee1d60110040cbaa35500d1114d9cc7a154"},"cell_type":"markdown","source":"## Import Libraries<a id=\"2\"></a> <br>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #count plot\n\nimport plotly.plotly as py #plotly library\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c820c2b4408d8273eb785679cca6b0dc75744891"},"cell_type":"markdown","source":"**We have 3 dataset in working directory : **\n\n* train : To train classification models.We know output.\n* test : To test classification models and create a prediction output.\n* gender_submission : A sample of output format."},{"metadata":{"_uuid":"240eb4539f4866b64da80d1849f93149ded9a1ea"},"cell_type":"markdown","source":"## Load  data<a id=\"3\"></a> <br>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('../input/train.csv')\n\ndata_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12d8a318bef4f7c2c4dcfb8bb3f143604ae9c6fd"},"cell_type":"markdown","source":"# Exploratory Data Analysis<a id=\"4\"></a> <br>"},{"metadata":{"_uuid":"141daa3dbb6f8fc04166a44f829e8d645605417d"},"cell_type":"markdown","source":"## A Quik View of Data <a id=\"5\"></a> <br>\n\nLet's look at data quickly to understand the content.\n"},{"metadata":{"trusted":true,"_uuid":"b7b64e08144137c62aecd7ac7e88ec232756d9f2"},"cell_type":"code","source":"data_train.info()\n\nprint()\n\ndata_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a541386f3406f3a377acaa1339104b400ba076c"},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c0ee240a53310899402f4e60451a823f1d69937"},"cell_type":"code","source":"data_test.head()\n\n#As you see, there isn't \"Survived\" column in test data because it requested from us. ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4f5208c4965b305699429829097f51cfc37f6fa"},"cell_type":"markdown","source":"## Cleaning Data <a id=\"6\"></a> <br>\n\nAs you see the datasets have NaN values(this means like empty),unneeded features and object datatype.We should fix them and clean data in order to use classification algorithms.Because the algorithms don't understand 'male' or 'female' .If we transform these to mathematical form (1 and 0) the algorithms work well."},{"metadata":{"trusted":true,"_uuid":"60eadfb9d11623011d223c1b88a4b0936adb8b46"},"cell_type":"code","source":"#Drop unneed columns and save\n\ndata_train.drop([\"Name\",\"Cabin\",\"Ticket\",\"Embarked\"],axis = 1,inplace = True)\n\ndata_test.drop([\"Name\",\"Cabin\",\"Ticket\",\"Embarked\"],axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f56a7302f7a858abdde5176d5bc80f4e186f946e"},"cell_type":"code","source":"#Split dataframe into 'survived' and 'not survived' so we will use these easily at data visualization\n\ndata_survived = data_train[data_train['Survived'] == 1].sort_values('Age') #dataframe that only has datas from survived peoples \n\ndata_not_survived = data_train[data_train['Survived'] == 0].sort_values('Age')\n\n#We will use this serie at line plot\n\nsurvived_age_number = data_survived.Age.value_counts(sort = False,dropna = True)#How many survived people are from which age\n\nnot_survived_age_number = data_not_survived.Age.value_counts(sort = False,dropna = True)\n\ndisplay(survived_age_number)\n\nnot_survived_age_number","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8c575a178f6f3189c5feb40f1c38c20f285c7d0"},"cell_type":"code","source":"#0.42,0.67 .. values at tail of serie and this is a wrong sort.Lets fix it.\n\na = survived_age_number.tail(4)#put values into a.\n\nsurvived_age_number.drop([0.42,0.67,0.83,0.92],inplace = True)#delete these values from tail of serie\n\nsurvived_age_number = pd.concat([a,survived_age_number],axis=0)#attach a to head of serie\n\nsurvived_age_number #Done","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a87d53f44163aed2affa5e7457b1c386ff260d0"},"cell_type":"markdown","source":"## Data Visualization<a id=\"7\"></a> <br>\n\nOur datas are ready for data visualization.Let's make plots to better understand data."},{"metadata":{"_uuid":"806e0579fe26dccdae7e00de5bab10aa0ab96d14"},"cell_type":"markdown","source":"### Line Plot<a id=\"8\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"d7ff1a0bdb57af275c85e006790334db4e990b78"},"cell_type":"code","source":"#trace1 is green line and trace2 is red line.\n\ntrace1 = go.Scatter(\n    x = survived_age_number.index,\n    y = survived_age_number,\n    opacity = 0.75,\n    name = \"Survived\",\n    mode = \"lines\",\n    marker=dict(color = 'rgba(0, 230, 0, 0.6)'))\n\ntrace2 = go.Scatter(\n    x = not_survived_age_number.index,\n    y = not_survived_age_number,\n    opacity=0.75,\n    name = \"Not Survived\",\n    mode = \"lines\",\n    marker=dict(color = 'rgba(230, 0, 0, 0.6)'))\n\ndata = [trace1,trace2]\nlayout = go.Layout(title = 'Age of Survived and not-Survived People in Titanic',\n                   xaxis=dict(title='Age'),\n                   yaxis=dict( title='Count'),)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73da06bb303c4eff60262679cb2ef18f3c49e98b"},"cell_type":"markdown","source":"### Count Plots<a id=\"9\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"356fda9b6b452d35375151ee59d9da9ef2389d63"},"cell_type":"code","source":"sns.countplot(data_survived.Pclass)\nplt.title('Passenger Class of Survived People')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1faa0d6efeb477cf65d95f3b394e50721c13f3a6"},"cell_type":"code","source":"sns.countplot(data_not_survived.Pclass)\nplt.title('Passenger Class of Not Survived People')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0c2acb5af0b1b91c08da0c61d64318bf65819e2"},"cell_type":"code","source":"sns.countplot(data_survived.Sex)\nplt.title('Gender of Survived People')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24c5504a18577900034a9292932e2d80f99dc6b2"},"cell_type":"code","source":"sns.countplot(data_not_survived.Sex)\nplt.title('Gender of Not Survived People')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea3ab9f39d5b3b22dd1e58b35c18c0637850ecf8"},"cell_type":"markdown","source":"# Classification<a id=\"10\"></a> <br>"},{"metadata":{"_uuid":"31b382592c72c66d7b4ff009eceb77083462d761"},"cell_type":"markdown","source":"## Preparing data for Classification<a id=\"11\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"38c8171ef26fdf056faa3e389fb3a48ff24d35d0"},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49872650c9c6eac71a2fac24ad3525aa9035c51a"},"cell_type":"code","source":"data_train_x = data_train #We should prepare x and y data for train classification\n\ndata_train_x.Sex = [1 if i == 'male' else 0 for i in data_train_x.Sex] #Transform strings to integers\n\ndata_train_y = data_train_x.Survived #y is our output  \n\ndata_train_x.drop(['PassengerId','Survived'], axis = 1,inplace = True)#drop passengerÄ±d and survived because they will not use while training\n\ndata_train_x.fillna(0.0,inplace = True) #fill NaN values with zero.We write '0.0' because we want to fill with float values \n\n#normalization :  i encountered 'to make conform to or reduce to a norm or standard' definition when i search normalization on google.\n#But if you ask simply definition i say that : 'to fit values between 0 and 1'\n#Normalization formula : (data - min)/(max-min) \n\ndata_train_x = (data_train_x - np.min(data_train_x))/(np.max(data_train_x) - np.min(data_train_x)).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdf463b2483db789f218957db531562ec4af5a91"},"cell_type":"code","source":"#We repeat same process to test dataset\n\ndata_test.Sex = [1 if i == 'male' else 0 for i in data_test.Sex]\n\nPassengerId = data_test['PassengerId'].values\n\ndata_test.drop(['PassengerId'], axis = 1,inplace = True)\n\ndata_test.fillna(0.0,inplace = True)\n\ndata_test = (data_test - np.min(data_test))/(np.max(data_test) - np.min(data_test)).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27a848348548196187add32cfdf5cac4855f8ee0"},"cell_type":"code","source":"#Split train data in order to reserve %80 of train data for test .You don't confuse this test data is for check.\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(data_train_x,data_train_y,test_size = 0.2,random_state=1)\n\nscore_list = [] #to keep scores of algorithms","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5ff2092765a48a4a3b648b1b43848d931624876"},"cell_type":"markdown","source":"## Implementing Classification Algorithms<a id=\"12\"></a> <br>"},{"metadata":{"_uuid":"b2cfae475ae4aded0ef72368b94b3728e91955f6"},"cell_type":"markdown","source":"### Logistic Regression<a id=\"13\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"fbeb8e4f8b0289bd8093b0168978ebe98ae40aef"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression #importing logistic regression model\n\nlr = LogisticRegression()\n\nlr.fit(x_train,y_train)#fit or train data\n\nprint('Logistic Regression Score : ',lr.score(x_test,y_test))#Ratio of correct predictions\n\nscore_list.append(lr.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c5cbb01234a284bd5fd6a7120f2946333d6e0c6"},"cell_type":"code","source":"#this is our real prediction part\n\nlr.fit(data_train_x,data_train_y)\n\nlr_prediction = lr.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5effe6a5da1bc2751c5d37c4a394c3247717b720"},"cell_type":"markdown","source":"### K-Nearest Neighbors<a id=\"14\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"8f3327c2e31fb32276b2d0839ff3279f5ea6750a"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\n\nknn.fit(x_train,y_train)\n\nprint('K-Nearest Neighbors Score : ',knn.score(x_test,y_test))\n\nscore_list.append(knn.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78bb2a884c6fdee52e93b4ec794baf703c8ff41d"},"cell_type":"code","source":"knn.fit(data_train_x,data_train_y)\n\nknn_prediction = knn.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"357101cef72d1986838ac77adbd8400b49f5af3a"},"cell_type":"markdown","source":"### Support Vector Machine<a id=\"15\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"9567ef84adcf69d7b9d8e917a9a0e750049d3fb4"},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(random_state = 1)\n\nsvm.fit(x_train,y_train)\n\nprint('Support Vector Machine Score : ',svm.score(x_test,y_test))\n\nscore_list.append(svm.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a367dca90de6d66c7f5ad8328898910576456548"},"cell_type":"code","source":"svm.fit(data_train_x,data_train_y)\n\nsvm_prediction = svm.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e86990f1a327280ed7c6acb70650dda623939c8b"},"cell_type":"markdown","source":"### Naive Bayes<a id=\"16\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"01db2475124384fbcebeb23ae4fb701cadab78f4"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\n\nnb.fit(x_train,y_train)\n\nprint('Naive Bayes Score : ',nb.score(x_test,y_test))\n\nscore_list.append(nb.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d20f05e8f8ee86f82fbe1a5b137cee125c72a03"},"cell_type":"code","source":"nb.fit(data_train_x,data_train_y)\n\nnb_prediction = nb.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c62ddcd77a830b39b4bd2927bcd1a0d1838e08b7"},"cell_type":"markdown","source":"### Decision Tree <a id=\"17\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"b00804ffd4058ac0141e1b3522fe930902da10b6"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\n\ndt.fit(x_train,y_train)\n\nprint('Decision Tree Score : ',dt.score(x_test,y_test))\n\nscore_list.append(dt.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2273888f6001f10b2f5add3ce308ff6fdcf5496d"},"cell_type":"code","source":"dt.fit(data_train_x,data_train_y)\n\ndt_prediction = dt.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2eeb552d80a87e7bf56ea56e4d75f5a7259dd0b9"},"cell_type":"markdown","source":"### Random Forest <a id=\"18\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"4062ac09de2d7c86fd19316ea5c114cb23fea680"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators = 22,random_state = 40)\n\nrf.fit(x_train,y_train)\n\nprint('Random Forest Score : ',rf.score(x_test,y_test))\n\nscore_list.append(rf.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aae531cca588995b61c5e0604e0d7ba1bb1f6973"},"cell_type":"code","source":"rf.fit(data_train_x,data_train_y)\n\nrf_prediction = rf.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f3e4260263a360e3d86be755ebee6de3ea4385b"},"cell_type":"markdown","source":"## Compare and Compound Classificaton Algorithms<a id=\"19\"></a> <br>\n\nTo determine the best predict,we will compare all predictions and select final prediction by scores."},{"metadata":{"trusted":true,"_uuid":"923f3ee92be95cf3b059708ebcbb9c6e430580b5"},"cell_type":"code","source":"pr_dict = {'Logistic Regression' : lr_prediction,'KNN' : knn_prediction,'SVM' : svm_prediction,\n           'Naive Bayes' : nb_prediction,'Decision Tree' : dt_prediction, 'Random Forest' : rf_prediction}\n\nall_predictions = pd.DataFrame(pr_dict)\n\nall_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11b307f29efc79e41c11743346334ffceeaed022"},"cell_type":"code","source":"final_prediction = [] #final prediction list\n\n#i : range columns , j : range rows\n\nfor i in all_predictions.values:\n    sum_zero_score = 0 #summary of zero scores\n    \n    sum_one_score = 0 #summary of one scores\n    \n    for j in range(5):\n        if i[j]==0:\n            sum_zero_score += score_list[j]\n        else:\n            sum_one_score += score_list[j]\n    \n    if sum_zero_score >= sum_one_score:\n        final_prediction.append(0)\n    else:\n        final_prediction.append(1)\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fc2407524d7f6c93dc88a32dd683aef8b029371"},"cell_type":"markdown","source":"## Preparing Output<a id=\"20\"></a> <br>"},{"metadata":{"trusted":true,"_uuid":"5630d72c988bb1cec46e77baa2effe961fcb66a2"},"cell_type":"code","source":"output = {'PassengerId' : PassengerId,'Survived' : final_prediction}\n\nsubmission = pd.DataFrame(output)\n\nsubmission.to_csv('output.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e01f7b4048869d4edbf80ce96e1890793478b31f"},"cell_type":"markdown","source":"# The End\n\n\nIf you see any mistake or lack please tell me with comment. Especially  mistakes about language . Thank you.  ðŸ˜Š"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}