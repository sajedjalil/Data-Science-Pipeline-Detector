{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import linear_model\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def comp_plot(col):\n    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\n    data[col].value_counts(normalize=True).plot(kind='bar', figsize=(15,5), ax=ax1)\n    ax1.set_title('Train set')\n    test[col].value_counts(normalize=True).plot(kind='bar', figsize=(15,5), ax=ax2)\n    ax2.set_title('Test set')\n    print('For Train data set', '\\n', data[col].value_counts(normalize='True'), '\\n')\n    print('For Test data set', '\\n',test[col].value_counts(normalize='True'))\n    \n    return 0\n\ncomp_plot('Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_plot('Pclass')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Sur = data.Survived.value_counts(normalize='True')\nprint(Sur)\ndata['Survived'].value_counts(normalize=True).plot(kind='bar')\n\n#only 38% of people survived","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2)  = plt.subplots(1, 2, sharey=True, figsize=(15,5))\ndata.hist(column='Age', ax=ax1)\nax1.set_title('Histogram of Age-Train set')\ntest.hist(column='Age', ax=ax2)\nax2.set_title('Histogram of Age-Test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2)  = plt.subplots(1, 2, sharey=True, figsize=(15,5))\ndata.hist(column='Fare', ax=ax1)\nax1.set_title('Histogram of Fare-Train set')\ntest.hist(column='Fare', ax=ax2)\nax2.set_title('Histogram of Fare-Test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(15,5))\nsns.scatterplot(x='Pclass', y='Age', hue='Survived', data=data, ax=ax1)\nsns.scatterplot(x='Pclass', y='Fare', hue='Survived', size='Survived', data=data, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(15,5))\nsns.scatterplot(x='Survived', y='Fare', data=data, ax=ax1)\nsns.scatterplot(x='Survived', y='Age', data=data, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sur_gen = data.groupby(['Sex'])['Survived'].value_counts(normalize = 'True').unstack('Survived')\nprint(df_sur_gen)\ndf_sur_gen.plot(kind='bar', stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class = data.groupby(['Pclass'])['Survived'].value_counts(normalize=True).unstack('Survived')\nprint(df_class)\ndf_class.plot(kind='bar', stacked=True)\n# 62% of class 1 people survived\n# 47% of class 2 people survived\n# 24% of class 3 people survived","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_age = data.groupby(['Sex','Pclass'])['Age'].mean()\nmean_age.reset_index(name = 'm_Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_Ages(row):\n    if pd.isnull(row['Age']):\n        return mean_age[row['Sex'],row['Pclass']]\n    else:\n        return row['Age']\n\ndata['Age'] =data.apply(fill_Ages, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_age = test.groupby(['Sex','Pclass'])['Age'].mean()\nmean_age.reset_index(name = 'm_Age')\n\ntest['Age'] =test.apply(fill_Ages, axis=1)\n\ntest.Fare.fillna(test.Fare.mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Cabin.fillna('Unknown', inplace=True)\ntest.Cabin.fillna('Unknown', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Embarked.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Embarked.fillna('S', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Title'] = data.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.',expand=False)\n\ntest['Title'] = test.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.',expand=False)\n\ndata['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# noble - 1\n# Mrs - 2\n# Miss - 3\n# Mr - 4\n# Workers - 5\n\ntitle_map = {'Lady':1, 'Master':1, 'the Countess':1, 'Jonkheer':1, 'Sir':1, 'Don':1, 'Dr':1,\n             'Mrs':2, 'Mme':2, 'Miss':3, 'Mlle':3, 'Ms':3,\n             'Mr':4, 'Capt': 5, 'Col':5, 'Major':5, 'Rev':5 }\n\ndata.Title = data.Title.map(title_map)\n\ntest.Title = test.Title.map(title_map)\n\ndata.drop('Name', axis=1, inplace=True) \ntest.drop('Name', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# less than 50 - 1\n# less than 100 - 2\n# less than 150 - 3\n# else - 3\n\ndef Fare_group(fare):\n    a = 0\n    if (fare <= 50):\n        a = 1\n    \n    elif (fare <= 100):\n        a = 2\n    \n    elif (fare <=150):\n        a = 3\n        \n    else:\n        a = 4\n\n    return a\n\n\ndata['Fare Group'] = data.Fare.map(Fare_group)\n#data.drop('Fare', axis=1, inplace=True)\n\ntest['Fare Group'] = test.Fare.map(Fare_group)  \n#test.drop('Fare', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# below 10 - 1\n# below 20 - 2\n# below 40 - 3\n# below 80 - 4\n\ndef Age_group(age):\n    a = 0\n    if (age <= 10):\n        a = 1 \n    \n    elif (age <= 20):\n        a = 2\n    \n    elif (age <=40):\n        a = 3\n        \n    else:\n        a = 4\n\n    return a\n\ndata['Age Group'] = data.Age.map(Age_group)\n#data.drop('Age', axis=1, inplace=True)\n\ntest['Age Group'] = test.Age.map(Age_group)  \n#test.drop('Age', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Sex'] = data.Sex.apply(lambda x:1 if x=='female' else 2)   #converting column Sex into int format\ntest['Sex'] = test.Sex.apply(lambda x:1 if x=='female' else 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# S - 1\n# C - 2\n# Q - 3\n\ndata['Embarked'] = data.Embarked.apply(lambda x:1 if x=='S' else (2 if x=='C' else 3))\ntest['Embarked'] = test.Embarked.apply(lambda x:1 if x=='S' else (2 if x=='C' else 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['No_fam_mem'] = data['SibSp'] + data['Parch']\ndata.drop(['SibSp','Parch', 'Ticket'], axis=1, inplace=True)\n\ntest['No_fam_mem'] = test['SibSp'] + test['Parch']\ntest.drop(['SibSp','Parch', 'Ticket'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.No_fam_mem.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# travelling alone - 1\n# small fam - 2\n# large fam - 3\ndef fam_type(fam_size):\n    a = 0\n    if (fam_size==0):\n        a = 1\n    \n    elif (fam_size<= 5):\n        a = 2\n    \n    else:\n        a = 3\n\n    return a\n\ndata['Fam size'] = data.No_fam_mem.map(fam_type)\n\ndata.drop('No_fam_mem', axis=1, inplace=True)\n\ndata = data[['PassengerId', 'Pclass', 'Title', 'Sex', 'Age', 'Age Group', 'Fam size', 'Fare', 'Fare Group', 'Embarked', 'Cabin', 'Survived']]\n\n\n\ntest['Fam size'] = test.No_fam_mem.map(fam_type)\n\ntest.drop('No_fam_mem', axis=1, inplace=True)\n\ntest = test[['PassengerId', 'Pclass', 'Title', 'Sex', 'Age', 'Age Group', 'Fam size', 'Fare', 'Fare Group', 'Embarked', 'Cabin']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Cabin.value_counts()         #letter of cabin represent the deck","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Cabin = data.Cabin.map(lambda x: x[0])\ntest.Cabin = test.Cabin.map(lambda x: x[0])\n\ndata.Cabin.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unknown-1, A-2, B-3, C-4, D-5, E-6, F-7, G-8, T-9\n\ndeck_map = {'U':1, 'A':2, 'B':3, 'C':4, 'D':5, 'E':6, 'F':7, 'G':8, 'T':9}\n\ndata['Deck'] = data['Cabin']\ndata.Deck = data.Deck.map(deck_map)\n\ndata.drop('Cabin', axis=1, inplace=True)\n\ntest['Deck'] = test['Cabin']\ntest.Deck = test.Deck.map(deck_map)\n\ntest.drop('Cabin', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Title.fillna(3, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['class_age'] = data['Pclass']*data['Age']\n\ndata['class_title'] = data['Pclass']*data['Title']\ndata['class_gen'] = data['Pclass']*data['Sex']\n\ndata['fam_fare'] = data['Fam size']*data['Fare']\n\ndata['em_fare'] = data['Embarked']*data['Fare']\n\ndata['title_age'] = data['Title']*data['Age']\n\n\ntest['class_age'] = test['Pclass']*test['Age']\n\ntest['class_title'] = test['Pclass']*test['Title']\ntest['class_gen'] = test['Pclass']*test['Sex']\n\ntest['fam_fare'] = test['Fam size']*test['Fare']\n\ntest['em_fare'] = test['Embarked']*test['Fare']\n\ntest['title_age'] = test['Title']*test['Age']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Age', 'Fare'], axis=1, inplace=True)\ntest.drop(['Age', 'Fare'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = data.columns.tolist()\nprint(cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ncol_lst = [ 'Pclass', 'Title', 'Age Group', 'Fam size', 'Fare Group', 'Embarked',\n           'Deck', 'class_age', 'class_title', 'class_gen', 'fam_fare', 'em_fare', 'title_age']\n\ndata[col_lst] = scaler.fit_transform(data[col_lst])\ntest[col_lst] = scaler.fit_transform(test[col_lst])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[['Pclass', 'Title', 'Sex', 'Age Group', 'Fam size', 'Fare Group', 'Embarked', 'Deck', 'class_age', \n             'class_title', 'class_gen', 'fam_fare', 'em_fare', 'title_age', 'Survived']]\n\ntest = test[['PassengerId', 'Pclass', 'Title', 'Sex', 'Age Group', 'Fam size', 'Fare Group', 'Embarked', 'Deck', 'class_age', \n             'class_title', 'class_gen', 'fam_fare', 'em_fare', 'title_age']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mat = data.corr()\nnp.tril(np.ones(corr_mat.shape)).astype(np.bool)[0:5,0:5]\ndf_lt = corr_mat.where(np.tril(np.ones(corr_mat.shape)).astype(np.bool))\nplt.subplots(figsize=(15,10))\nsns.heatmap(df_lt, annot=True, cmap=\"Spectral\", fmt='.2g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ************************************"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV\nfrom sklearn.metrics import accuracy_score\n#GridSearchCV - for selecting the best hyperparameter\n#StratifiedKFold  - divide categories in a uniform way\nfrom sklearn.metrics import accuracy_score\n\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)  #StratifiedKFold\n\n#data_1 = data.drop('PassengerId', axis=1).copy()\ntest_2 = test.drop('PassengerId', axis=1).copy()\n\ntarget = data['Survived']\ntrain = data.drop('Survived', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.3, random_state=1)   #Split the train data set\n#train_test_split(X, Y, test_size, random_state)\n# X,Y - dataset we are going to use for splitiing\n#test_size - define the size of the test set\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.fit() is used to train the model on data\n#if y_test is the real labels for X_test, model.score(X_test, y_test)  compare predictions of the model against the real labels\n#model.score(X_train, y_train) measure the accuracy of the model against training data.This has nothing to do with test data\n#model.predict(X_test) predict labels for test set \n#model.score(X_test, y_test) and model.predict(X_test), accuracy_score(y_test, prediction) are both same","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_score(model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n    model.fit(X_train, y_train)\n    model_score = model.score(X_test, y_test)*100\n    \n    return model_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cv_score(model):\n    cv_score = cross_val_score(model, train, target, cv=kf, scoring='accuracy')\n    return cv_score.mean()*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('Cross val score for LR  : ', cv_score(LogisticRegression()))\nprint('LR Score : ', model_score(LogisticRegression()),'\\n')\n\nprint('Cross val score for RF  : ', cv_score(RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=2, \n                                                    min_samples_leaf=6, max_features='auto', random_state=1)))\nprint('RF Score : ', model_score(RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_split=6, min_samples_leaf=6, \n                                    max_features='auto', random_state=1)), '\\n')\n\nprint('Cross val score for SVC : ', cv_score(SVC(C=30)))\nprint('SVC Score : ', model_score(SVC(C=30)), '\\n')\n\nprint('Cross val score for KNN : ', cv_score(KNeighborsClassifier(n_neighbors=50)))\nprint('KNN Score : ', model_score(KNeighborsClassifier(n_neighbors=50)), '\\n')\n\nprint('Cross val score for DT  : ', cv_score(DecisionTreeClassifier(max_depth=12, min_samples_split=2, random_state=1)))\nprint('DT Score : ', model_score(DecisionTreeClassifier(max_depth=12, min_samples_split=2, random_state=1)), '\\n')\n\n#Cross val score for LR  :  81.48189762796505\n#LR Score :  77.98507462686567 \n\n#Cross val score for RF  :  83.2808988764045\n#RF Score :  77.61194029850746 \n\n#Cross val score for SVC :  81.82272159800249\n#SVC Score :  77.98507462686567 \n\n#Cross val score for KNN :  80.13732833957553\n#KNN Score :  75.74626865671642 \n\n#Cross val score for DT  :  82.61173533083645\n#DT Score :  79.1044776119403","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier, plot_importance\n\nxgbc = XGBClassifier(max_depth=15, min_child_weight=1, n_estimators=500, random_state=42, learning_rate=0.01,  \n                     eval_metric=[\"error\", \"logloss\"])\nxgbc.fit(X_train,y_train, early_stopping_rounds=15, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)   \n# verbose=True print val_error and logloss for each iteration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_xgbc = xgbc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc_score_train = xgbc.score(X_train, y_train)\nprint(\"Train Prediction Score\",xgbc_score_train*100)\nxgbc_score_test = accuracy_score(y_test,y_pred_xgbc)    # or print(xgbc.score(X_test, y_test)*100)\nprint(\"Test Prediction Score\",xgbc_score_test*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = xgbc.evals_result()\nepochs = len(results['validation_0']['error'])\nx_axis = range(0, epochs)\n# plot log loss\nfig, ax = plt.subplots()\nax.plot(x_axis, results['validation_0']['logloss'], label='Train')\nax.plot(x_axis, results['validation_1']['logloss'], label='Test')\nax.legend()\nplt.ylabel('Log Loss')\nplt.title('XGBoost Log Loss')\nplt.show()\n# plot classification error\nfig, ax = plt.subplots()\nax.plot(x_axis, results['validation_0']['error'], label='Train')\nax.plot(x_axis, results['validation_1']['error'], label='Test')\nax.legend()\nplt.ylabel('Classification Error')\nplt.title('XGBoost Classification Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_importance(xgbc)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc.fit(train, target)\n\nprediction_xgbc = xgbc.predict(test_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=2,min_samples_leaf=6, max_features='auto', random_state=1)\nmodel.fit(train, target)\n\npred_dt = model.predict(test_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SVC( C=20)\nmodel.fit(train, target)\n\npred_svc = model.predict(test_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived':pred_svc})\nsub.to_csv('sample_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}