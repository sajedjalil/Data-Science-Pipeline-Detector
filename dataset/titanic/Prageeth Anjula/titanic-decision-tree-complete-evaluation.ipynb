{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://uci-seed-dataset.s3.ap-south-1.amazonaws.com/AccuracyOnly.jpg\" width=\"400\">   \n\n\n<h1 style=\"color:red;font-size:40px;\">Hello kagglers,</h1>Accuracy is not the only thing you measure in a model. It typically depends on the problem. Most common example would be class skewness problem where one class appears in the dataset rarely in an application like Anomaly Detection. This simple kernel give you more insights into other evaluation methods along with few key concepts you need.\n\n</br></br>\n1. Missing value identification and handling.    \n1. Handling categorical variables (One-hot encoding).    \n1. Hyper Parameter tuning - GridSearchCV    \n1. Model evaluation (Accuracy, Precision, Recall, F1Score)   \n1. Classification report and confusion matrix analysis. \n1. ROC Curve for the trained clasifier\n1. Decision tree visualization using graphviz.    \n1. Understanding feature importance.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Workspace preparation**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n\nfrom sklearn import preprocessing\n\nfrom yellowbrick.classifier import ConfusionMatrix\nfrom yellowbrick.classifier import ClassificationReport\nfrom yellowbrick.classifier import ROCAUC\nplt.style.use('ggplot')\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Searching for folders inside input folder**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading data file**","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/titanic/train.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe(include = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing value identification/ handling**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(dataset['Embarked'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# File missing values in embarked with S which is the most frequent item.\ndataset = dataset.fillna({\"Embarked\": \"S\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling categorical variables**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## One hot encoding is used since no ordering is available for Sex (male, female) feature.\ndataset = pd.get_dummies(dataset, columns=['Sex'])\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## One hot encoding is used since no ordering is available for Sex (male, female) feature.\ndataset = pd.get_dummies(dataset, columns=['Embarked'])\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Applying model - with default values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_names = ['Pclass', 'Sex_male', 'Sex_female', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Parch', 'SibSp', 'Fare']\ntarg_names = ['Dead (0)', 'Survived (1)'] # 0 - Dead, 1 - Survived\n\ntrain_class = dataset[['Survived']]\ntrain_feature = dataset[feat_names]\ntrain_feature.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\nscoring = {'acc': 'accuracy',\n           'prec_macro': 'precision_macro',\n           'rec_macro': 'recall_macro',\n           'f1_macro': 'f1_macro'}\nscores = cross_validate(clf, train_feature, train_class, cv=10, scoring=scoring)\n# print(scores.keys())\n\nprint ('Accuracy score : %.3f' % scores['test_acc'].mean())\nprint ('Precisoin score : %.3f' % scores['test_prec_macro'].mean())\nprint ('Recall score : %.3f' % scores['test_rec_macro'].mean())\nprint ('F1 score : %.3f' % scores['test_f1_macro'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Parameter tuning - gridSearchCV**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"para_grid = {\n    'min_samples_split' : range(10,500,20),\n    'max_depth': range(1,20,2),\n    'criterion': (\"gini\", \"entropy\")\n}\n\nclf_tree = DecisionTreeClassifier()\nclf_cv = GridSearchCV(clf_tree,\n                   para_grid,\n                   scoring='accuracy',\n                   cv=5,\n                   n_jobs=-1)\nclf_cv.fit(train_feature,train_class)\n\nbest_parameters = clf_cv.best_params_\nprint(best_parameters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model evaluation with tuned parameters using cross validation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = clf_cv.best_estimator_\nscoring = {'acc': 'accuracy',\n           'prec_macro': 'precision_macro',\n           'rec_macro': 'recall_macro',\n           'f1_macro': 'f1_macro'}\nscores = cross_validate(clf, train_feature, train_class, cv=10, scoring=scoring)\n#print(scores.keys())\n\nprint ('Accuracy score : %.3f' % scores['test_acc'].mean())\nprint ('Precisoin score : %.3f' % scores['test_prec_macro'].mean())\nprint ('Recall score : %.3f' % scores['test_rec_macro'].mean())\nprint ('F1 score score : %.3f' % scores['test_f1_macro'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Classification report analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a holdout sample for further testing\n# train_class, train_feature\nX_train, X_test, y_train, y_test = train_test_split(train_feature, train_class, test_size=0.33)\nprint (str(X_train.shape) +\",\"+ str(y_train.shape))\nprint (str(X_test.shape) +\",\"+ str(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf2 = clf_cv.best_estimator_\nclf2.fit(X_train,y_train)\npredictions = clf2.predict(X_test)\nprint(metrics.classification_report(y_test,predictions, target_names=targ_names, digits=3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7,3))\nvisualizer = ClassificationReport(clf2, classes=targ_names, support=True, cmap='RdPu')\nvisualizer.score(X_test, y_test)\nfor label in visualizer.ax.texts:\n    label.set_size(14)\ng = visualizer.poof()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(3,3))\ncm = ConfusionMatrix(clf2, classes=[0, 1], cmap='RdPu')\ncm.score(X_test, y_test)\nfor label in cm.ax.texts:\n    label.set_size(14)\ncm.poof()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ROC Curve**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"modelviz = clf_cv.best_estimator_\nvisualizer = ROCAUC(modelviz, classes=[\"Dead\", \"Survived\"])\n\nvisualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)        # Evaluate the model on the test data\nvisualizer.show()                       # Finalize and render the figure","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Draw the decision tree using graphviz**\n\nNote : Run this on yourown to see the graph since this cannot be published.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import graphviz\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\ndata = export_graphviz(clf,out_file=None,feature_names=feat_names,class_names=targ_names,   \n                         filled=True, rounded=True,  \n                         special_characters=True)\ngraph = graphviz.Source(data)\ngraph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Understanding Feature Importance**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = clf.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [feat_names[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see from the root of the decision tree Sex_female feaure gives the most information context to differentiate survived    \nand dead classes. This is clearly seen in the feature importance value as well. Sex_male and encoded Embarked feature adds very    \nsmall value for the prediction.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Creating submission file**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading test dataset\ntest = pd.read_csv('../input/titanic/test.csv')\n\n# Fit the model\nclf.fit(train_feature, train_class)\n\n# Replace missing Fare values with mean\nmeanFare = dataset['Fare'].mean()\ntest = test.fillna({\"Fare\": meanFare})\n# Categorical -> One hot encoding\ntest = pd.get_dummies(test, columns=['Sex'])\ntest = pd.get_dummies(test, columns=['Embarked'])\n\n#set ids as PassengerId and predict survival\nids = test['PassengerId']\ntest_feature = test[feat_names]\npredictions = clf.predict(test_feature)\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}