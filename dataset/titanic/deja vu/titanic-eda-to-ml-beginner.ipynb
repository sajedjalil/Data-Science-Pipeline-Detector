{"cells":[{"metadata":{"_uuid":"08895c5c643bab33e61205b8340a7ba7b88f8ed2","_cell_guid":"12528ba7-230e-407a-a312-ef8f6ca9a99e"},"cell_type":"markdown","source":"**This is my first Kaggle for the Titanic competition.**\n\nThe notebooks explores the basic use of Pandas and scikit-learn for this Classifcation problem.  \nFor more advanced approaches like using Seaborn plots, Feature Engineering, GridSearch CV  \nand ML models based on stacking and voting have a look at [my second Titanic kernel](https://www.kaggle.com/dejavu23/titanic-survival-my-2nd-titanic-kernel)\n\n\n\n**My goals for this notebook:**\n\n* **[Part 1: Exploratory Data Analysis](#Part-1:-Exploratory-Data-Analysis)**  \nunderstand the data by EDA and derive simple models with Pandas as baseline\n\n\n* **[Part 2: Data wrangling](#Part-2:-Data-wrangling)**  \nfill nan, convert categorical to numerical,  \ncreate train and test data for ML algorithms\n\n* **[Part 3: Scikit-learn basic ML algorithms](#Part-3:-Scikit-learn-basic-ML-algorithms-and-comparison-of-model-results)**  \nimplement different Classifiers from the sklearn library:  \n[Logistic regression](#3.1-Logistic-Regression), [Gaussian naive Bayes](#3.2-Gaussian-Naive-Bayes), [KNN](#3.3-KNN---KNeighborsClassifier), [Decision tree](#3.4-Decision-Tree-Classifier), [Random forest](#3.5-Random-Forest-Classifier), [SVM](#3.6-SVM-Classifier)\n\n\n* **[Part 3: Comparison of Model  results](#Part-3:-Scikit-learn-basic-ML-algorithms-and-comparison-of-model-results)**  \nuse metrics like confusion_matrix, classification_report, accuracy_score  \nand implement k fold cross validation for comparison of test score\n \n\n**References**  \n**This notebook has some own approaches but is also based on these tutorials, notebooks and courses:**\n* **[Datacamp: Kaggle Tutorial: EDA & Machine Learning](https://www.datacamp.com/community/tutorials/kaggle-machine-learning-eda)**\n* **[Udemy: Python for Data Science and Machine Learning Bootcamp](https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp/)**\n* **[Data School: Machine learning in Python with scikit-learn](https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A)**\n\n    \n"},{"metadata":{"_uuid":"ca91678a9dc8cc103a7fbf799a5d903a011334ef","_cell_guid":"e4a1cf77-b695-4ca0-9653-6c41ce2393d8"},"cell_type":"markdown","source":"## Some Background Information\n\n\n**The sinking of the RMS Titanic in the early morning of 15 April 1912, four days into the ship's maiden voyage from Southampton to New York City, was one of the deadliest peacetime maritime disasters in history, killing more than 1,500 people. The largest passenger liner in service at the time, Titanic had an estimated 2,224 people on board when she struck an iceberg in the North Atlantic. The ship had received six warnings of sea ice but was travelling at near maximum speed when the lookouts sighted the iceberg. Unable to turn quickly enough, the ship suffered a glancing blow that buckled the starboard (right) side and opened five of sixteen compartments to the sea. The disaster caused widespread outrage over the lack of lifeboats, lax regulations, and the unequal treatment of the three passenger classes during the evacuation. Inquiries recommended sweeping changes to maritime regulations, leading to the International Convention for the Safety of Life at Sea (1914), which continues to govern maritime safety.**  \n*from Wikipedia*"},{"metadata":{"_uuid":"d3086cb02907affe5a674b54e4baaedd632482c7","_cell_guid":"998b2a03-c60e-4fd6-9f69-784de6e6c9b8"},"cell_type":"markdown","source":"**Imports**"},{"metadata":{"_uuid":"efb595c75201cdb2a53388dc152a8e526e1b921a","_cell_guid":"872b97b2-56fe-4644-a11f-afb00f422169","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n#warnings.filterwarnings(\"ignore\")\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dabb93c5c6480e69cbc93616932445e614f506f"},"cell_type":"code","source":"sns.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0333d5086a63e3870708e7ba7a540d036c53544e","_cell_guid":"080fb327-390d-4124-b287-a561d050fe7e","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13fd8422db7a1ceae9ebb002df452e8293a9ab0c","_cell_guid":"6c7d2500-95b1-4057-98f7-39100e8a6d7f"},"cell_type":"markdown","source":"## Part 1: Exploratory Data Analysis"},{"metadata":{"_uuid":"48a2091edbeacc9c23dad6bc0c64d0302d01b87b","_cell_guid":"17a3c0a2-3aad-47f4-be6f-e8756bddf080","trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f7bf32c6766cffd95125d01d24ccb7204611f45","_cell_guid":"4e0c12ed-f9a7-4a2d-b33c-8e139c6387d1"},"cell_type":"markdown","source":"df_train has 891 entries, some values for Cabin and Age are missing"},{"metadata":{"_uuid":"d3edd77b588d7589154499820fa571a5d7b62035","_cell_guid":"60e47bc5-0749-41ee-979e-58ba2e1d5ce8","trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3c717b8911229098b77175804a0c05c4e8b5828","_cell_guid":"cf04a11c-fada-476a-bf82-437f8f302ca6","trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d34539fd29d18787e98dfae48ac154efd73d55a","_cell_guid":"f0e70763-8b81-401a-92fe-f195ef37b4bc","trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6062b11e45d9f45663bcdbb136eb2a4aa525742","_cell_guid":"bb18628a-d896-4907-9761-aab93999b0b6"},"cell_type":"markdown","source":"Also in df_test some values for Age and many values for Cabin are missing"},{"metadata":{"_uuid":"b0c4e63035e9517722d8dbf8b2bc984410456181","_cell_guid":"0e3973cb-3dee-4dab-9c7f-f4902f62c360","trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10e0b721ca4d05176207e5bfaab3932555271f2b","_cell_guid":"e0e5b43e-3949-420e-960f-697abbec91fb"},"cell_type":"markdown","source":"Comparing distribution of features in df_train and df_test, Pclass and Age seem very similar, distributions for SibSo, Parch and Fare only slightly different"},{"metadata":{"_uuid":"485bc69da85d5596708f385ca477783581df5231","_cell_guid":"0dc4a65f-3460-4fa0-8d0a-0649b679ed01","trusted":true},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20287febf1b25ddf9eccfbb88e363bdb80f3d958","_cell_guid":"94c7f3de-746d-44cb-9a9d-43f32527948c"},"cell_type":"markdown","source":"**Of all passengers in df_train, how many survived, how many died ?** "},{"metadata":{"_uuid":"3fe99f565401dae73cfecd3fb2cf8dc201119b36","_cell_guid":"d2bd2723-3a68-4e94-a629-7a0fca99cb2a","trusted":true},"cell_type":"code","source":"sns.countplot(x='Survived', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26277b12d89958ad5d03a8636786b920c7d4ba08","_cell_guid":"b6aabfa1-fd1b-4ad5-9f95-14a7a703d7ee","trusted":true},"cell_type":"code","source":"print(df_train.Survived.sum()/df_train.Survived.count())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efa6e3dbb66ca31c8aa1a2e4ec934c00bbf2e411","_cell_guid":"1babbbf7-085d-4141-b29a-f9fd8f388e46"},"cell_type":"markdown","source":"more people died than survived (38% survived)\n\n-> base model : no survivors\n\nsubmission : 0.627 accuracy"},{"metadata":{"_uuid":"4d22aef19faa0e9754f27ef26f3b31ec2099f54c"},"cell_type":"markdown","source":"**Uncomment  if you want to check this submission**"},{"metadata":{"_uuid":"8b4ce14f870115759569ca8d8e60c71907fe2095","_cell_guid":"c830a8ca-2bb1-496c-807a-c9913dd5d3f2","trusted":true},"cell_type":"code","source":"#df_test['Survived'] = 0\n#df_test[['PassengerId', 'Survived']].to_csv('no_survivors.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b43c39397eef7815b8d6d7308750e83c171e0e1c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdc97f58b646df5993d1e90ff28abfa2b41b1425","_cell_guid":"d9cd643d-14a4-43e6-8eeb-53fca5e2ffb1"},"cell_type":"markdown","source":"**Sex: Female more likely to survive than male**"},{"metadata":{"_uuid":"1b7ef6637506ba053434c3e0b0b3f0bc0cf4d01d","_cell_guid":"d6dd2033-80b8-44c6-8d91-95a7353552fd","trusted":true},"cell_type":"code","source":"df_train.groupby(['Survived','Sex'])['Survived'].count()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e13eaa5a0070378fc59f3a87c3862b1eb0a804a","_cell_guid":"b1f97218-9ef5-43b3-b946-e067827a6693","trusted":true},"cell_type":"code","source":"sns.catplot(x='Sex', col='Survived', kind='count', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11444fc10bb62ac315a6ab2114b9ff54dde3d45e","_cell_guid":"4a6f8e4e-c58f-4f6f-9287-9f9a741431da","trusted":true},"cell_type":"code","source":"print(\"% of women survived: \" , df_train[df_train.Sex == 'female'].Survived.sum()/df_train[df_train.Sex == 'female'].Survived.count())\nprint(\"% of men survived:   \" , df_train[df_train.Sex == 'male'].Survived.sum()/df_train[df_train.Sex == 'male'].Survived.count())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3994bc6102c107006edc0854ea7663eea2c030d2","_cell_guid":"fbbf541c-ae16-4f7e-a462-fdd6f9898440","trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(16,7))\ndf_train['Survived'][df_train['Sex']=='male'].value_counts().plot.pie(explode=[0,0.2],autopct='%1.1f%%',ax=ax[0],shadow=True)\ndf_train['Survived'][df_train['Sex']=='female'].value_counts().plot.pie(explode=[0,0.2],autopct='%1.1f%%',ax=ax[1],shadow=True)\nax[0].set_title('Survived (male)')\nax[1].set_title('Survived (female)')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76959c99bc83db9fc2896d3c7cea2eeef8ec4527","_cell_guid":"ff42aba4-3b8d-4e63-a086-9f6bcc82c0ae"},"cell_type":"markdown","source":"Women were more likely to survive than men \n\n74 % of women survived\nbut only 19% of men\n(in training set)\n\n-> second model :\nall women survived and all men died\n\nsubmission : 0.766 accuracy\n"},{"metadata":{"_uuid":"0ecbd7c1fb7a7f8facb218dc6abd1ac238e4bf68"},"cell_type":"markdown","source":"**Uncomment  if you want to check this submission**"},{"metadata":{"_uuid":"5a2d99bfb866df607fcf7d598d30d11815e1a9a2","_cell_guid":"b879916b-19c7-48cf-a4ba-905f123e96f8","trusted":true},"cell_type":"code","source":"#df_test['Survived'] = df_test.Sex == 'female'\n#df_test['Survived'] = df_test.Survived.apply(lambda x: int(x))\n#df_test[['PassengerId', 'Survived']].to_csv('women_survive.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bb33fe29a3977709a691c74fea426010d120a3c","_cell_guid":"91aabc83-9f92-4e59-936c-e90fdddb0160"},"cell_type":"markdown","source":"**Passenger Class : Survival rate decreases with Pclass**"},{"metadata":{"_uuid":"b48eb33382fbc5ee059c5c851fac9cf010858508","_cell_guid":"b7182fb8-22cf-4adc-aebb-fb5842a753d6","trusted":true},"cell_type":"code","source":"pd.crosstab(df_train.Pclass, df_train.Survived, margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a943c91ea1ce0dd40e8d53c696432e346d6605ab","_cell_guid":"051feaa9-c5b0-4035-b002-4b9f2ff7e880","trusted":true},"cell_type":"code","source":"print(\"% of survivals in\") \nprint(\"Pclass=1 : \", df_train.Survived[df_train.Pclass == 1].sum()/df_train[df_train.Pclass == 1].Survived.count())\nprint(\"Pclass=2 : \", df_train.Survived[df_train.Pclass == 2].sum()/df_train[df_train.Pclass == 2].Survived.count())\nprint(\"Pclass=3 : \", df_train.Survived[df_train.Pclass == 3].sum()/df_train[df_train.Pclass == 3].Survived.count())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8849e5a5a82f6a1dda18104bb649d304d1925fcd","_cell_guid":"fc517397-1dc7-421e-bc8b-2e287e94ae75","trusted":true},"cell_type":"code","source":"sns.catplot('Pclass','Survived', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dce35a66e5506d07a18cabb0f3440897d459aa7","_cell_guid":"aaccbc96-a530-47df-88d4-0f2e3a6abcf0","collapsed":true},"cell_type":"markdown","source":"**Passenger Class and Sex :**\n\n**Almost all women in Pclass 1 and 2 survived and nearly all men in Pclass 2 and 3 died**"},{"metadata":{"_uuid":"e6bf54da5ad3bf4951330540a5671a2129990b52","_cell_guid":"620eed70-7c9e-408d-b401-30ee97efd139","trusted":true},"cell_type":"code","source":"pd.crosstab([df_train.Sex, df_train.Survived], df_train.Pclass, margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5377daafd312ed7e33376c2599d52d4c4db3ce5b","_cell_guid":"d716de50-8e5f-4a26-9cb9-e95c76e526a3","trusted":true},"cell_type":"code","source":"sns.catplot('Pclass','Survived',hue='Sex', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f042a3bdb18e289edfd62688d308f6c8f6bcd27e","_cell_guid":"8c90fa09-97fc-4143-b364-ff0dabd43292","collapsed":true},"cell_type":"markdown","source":"**Embarked : Survival rate lowest for S and highest for C**"},{"metadata":{"_uuid":"59a813d6b0bf1d1427475ebf92d5791a300f34a8","_cell_guid":"5dc3dccf-9b61-424e-b251-56ce33d1e1b4","trusted":true},"cell_type":"code","source":"sns.catplot(x='Survived', col='Embarked', kind='count', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"805776505e93b1fd06f25f43e6400c6377131320","_cell_guid":"9c55a6cd-cb3e-490b-b272-489252eaf55e","trusted":true},"cell_type":"code","source":"sns.catplot('Embarked','Survived', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2257cddd2784ac55fa3bc40673ef99a7b311aa4","_cell_guid":"5d41c75f-d13a-441e-b8bf-e2605ce42b6b"},"cell_type":"markdown","source":"**Embarked and Sex**"},{"metadata":{"_uuid":"f9d1d2137f0ce7a8ac1ef9d3bf1f3225dbcbdaf4","_cell_guid":"259c13c1-5d2c-4549-95ed-61baa9d2a6c1","trusted":true},"cell_type":"code","source":"sns.catplot('Embarked','Survived', hue= 'Sex', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4a4775d5992483cbca12f98dcff676a3804310c","_cell_guid":"6891d2dc-0121-442b-809e-b236c6d52ca2"},"cell_type":"markdown","source":"**Embarked, Pclass and Sex :**\n\n** Practically all women of Pclass 2 that embarked in C and Q survived, also nearly all women of Pclass 1 survived. **\n\n** All men of Pclass 1 and 2 embarked in Q died, survival rate for men in Pclass 2 and 3 is always below 0.2 **\n\n** For the remaining men in Pclass 1 that embarked in S and Q, survival rate is approx. 0.4 **"},{"metadata":{"_uuid":"a1f54e702d6fe53ef1f60032469d24d956cb366a","_cell_guid":"dc3d169f-b2e8-4df8-b4e6-dced76b43bee","trusted":true},"cell_type":"code","source":"sns.catplot('Embarked','Survived', col='Pclass', hue= 'Sex', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a79d321096144428ad92c82829f6a5c3daee183","_cell_guid":"e2b0c14d-cef5-423e-a433-786c09fdcfa6","trusted":true},"cell_type":"code","source":"pd.crosstab([df_train.Survived], [df_train.Sex, df_train.Pclass, df_train.Embarked], margins=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a53b6d009d7862a454baec4dcac787e22cc6f4d5","_cell_guid":"6b69a722-4335-44cd-baac-5ae3fb02065d"},"cell_type":"markdown","source":"third model :\nbased on PClass, Sex and Embarked ,\nsubmission : 0.779 accuracy"},{"metadata":{"_uuid":"82f6e7102aee58b2d9673ecabb85a6d5b9df91e6","_cell_guid":"c842cd85-5bd1-4b38-914f-99affb2c69b1","trusted":true},"cell_type":"code","source":"# model 3\ndf_test['Survived'] = 0\n# all women survived\ndf_test.loc[ (df_test.Sex == 'female'), 'Survived'] = 1\n# except for those in Pclass 3 and embarked in S\ndf_test.loc[ (df_test.Sex == 'female') & (df_test.Pclass == 3) & (df_test.Embarked == 'S') , 'Survived'] = 0\n#df_test[['PassengerId', 'Survived']].to_csv('embarked_pclass_sex.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"449bb1e89a1d99b85dc03f76034f293db349e42e","_cell_guid":"8e635867-d4a4-4ceb-b7a8-f8260cc01254"},"cell_type":"markdown","source":"**Age:  continuous numerical  to  8 bins **"},{"metadata":{"_uuid":"08da3a287de8af95a4ca012c42fd14dc02554815","_cell_guid":"4f536aeb-8f8b-4b6d-8020-adef0f25b22c","trusted":true},"cell_type":"code","source":"for df in [df_train, df_test]:\n    df['Age_bin']=np.nan\n    for i in range(8,0,-1):\n        df.loc[ df['Age'] <= i*10, 'Age_bin'] = i","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b41dd56f41faff7a762cf1fb0d180f4b113ad26","_cell_guid":"5afbb91b-4407-45b4-81e3-7cf112ddb489","trusted":true},"cell_type":"code","source":"print(df_train[['Age' , 'Age_bin']].head(10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"546efacb21995beea817894c7616bc24950d1f8e","_cell_guid":"d0d60033-5a87-44ec-89d1-45f48bea213e","trusted":true},"cell_type":"code","source":"sns.catplot('Age_bin','Survived',hue='Sex',kind='point',data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a234b585b5826c2cb32631c105e841fc5e6e8362","_cell_guid":"472167a5-72cf-4ba9-be0b-7ff17e161702","trusted":true},"cell_type":"code","source":"sns.catplot('Age_bin','Survived', col='Pclass' , row = 'Sex', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02f16d15f9223c10e3db1f80f6b138275b66ec75","_cell_guid":"63acf86d-0a8f-4ac7-a1a5-ecac2fb7b4c6","trusted":true},"cell_type":"code","source":"pd.crosstab([df_train.Sex, df_train.Survived], [df_train.Age_bin, df_train.Pclass], margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57605b4aefcee3d5ff35c530fdff83c6ffccb3db","_cell_guid":"8af62a6c-65e4-4383-9ea9-daae642f0427","collapsed":true},"cell_type":"markdown","source":"For passengers in Age_bin = 1 (younger than 10) : All male in Pclass 1 and 2 survived\n\nAll female in Pclass 3 and Age_bin = 5 died. \n\n(Survival rate for female in Pclass 3 and Age_bin = 4 is below 50%)\n\n(Survival rate for male in Pclass 1 and Age_bin = 4 is above 50%)\n\n"},{"metadata":{"_uuid":"bc2d2102e698e2e1d02b3b50d6eecd7b5ce4f3fa","_cell_guid":"44cc892a-5f66-4768-947d-029ec46f8b6f","trusted":true},"cell_type":"code","source":"# in Pclass 1 and 2 all men in Age_bin = 1 survived\ndf_test.loc[ (df_test.Sex == 'male') & (df_test.Pclass == 1) & (df_test.Age_bin == 1), 'Survived'] = 1\ndf_test.loc[ (df_test.Sex == 'male') & (df_test.Pclass == 2) & (df_test.Age_bin == 1), 'Survived'] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"747b94caf67dd939f761453c7d53e187bbf7d815","_cell_guid":"6027c753-0a2a-4fe0-b9a8-b151aba7db7e"},"cell_type":"markdown","source":"**SibSp and Parch**"},{"metadata":{"_uuid":"118acf7db03474aa7bb41588f1e1b7475ab6abb8","_cell_guid":"7664f482-0caa-4614-8fe1-419d5b25eeb4","trusted":true},"cell_type":"code","source":"sns.catplot('SibSp','Survived', col='Pclass' , row = 'Sex', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9aaf8e3e51e52aac54cd0818b7284ff9e3ea876e","_cell_guid":"9a22dfd7-5f7a-42d5-9e0f-ba72238f9f40","trusted":true},"cell_type":"code","source":"pd.crosstab([df_train.Sex, df_train.Survived], [df_train.SibSp, df_train.Pclass], margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26aa63ddac2e81f4e72706a035b62dfd0ce60e4b","_cell_guid":"3901a25e-e503-4608-94d1-386c47ebdff6"},"cell_type":"markdown","source":"For males, no survival rate above 0.5 for any values of SibSp.\nFor females, passengers with SibSp = 3 and Pclass = 3 died, also all females with SibSp > 4 died.\nFor females with SibSp = 1 and Pclass = 3 survival rate is below 0.5"},{"metadata":{"_uuid":"7b5cd71b5c35fda0526c3c978a49fd288ac4601b","_cell_guid":"920ae833-cc78-4c62-927b-b3a3a52fbe9b","trusted":true},"cell_type":"code","source":"# all females with SibSp > 7 died\ndf_test.loc[ (df_test.Sex == 'female') & (df_test.SibSp > 7) , 'Survived'] = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b6172a9ee094ee03e0d8ff0cb030c7fcc4afad8","_cell_guid":"f0ddf2ce-3d60-4500-8fce-38e1e1bb0e42","trusted":true},"cell_type":"code","source":"sns.catplot('Parch','Survived', col='Pclass' , row = 'Sex', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37ce56a44ebaf5c40528bb5985dafbc7a64dc346","_cell_guid":"b364bf8a-06c7-4868-a62a-b16ad732f9eb","trusted":true},"cell_type":"code","source":"pd.crosstab([df_train.Sex, df_train.Survived], [df_train.Parch, df_train.Pclass], margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6706031a1f86b950de579014fb9f9b119bdd92dc","_cell_guid":"05fa17b4-c3ca-467b-a11c-3594372e42aa","collapsed":true},"cell_type":"markdown","source":"Very similar to SibSp - 1 , but different values  ?\nFor females with Parch = 2 and Pclass = 3 survival rate is below 0.5  \nAll females with Parch = 4 and Pclass = 3 died.\nAll females with Parch > 4 died.\n(For females with Parch = 1 and Pclass = 3 survival rate is below 0.5)\nFor males,all survival rates below 0.5 for any values of Parch, except for Parch = 2 and Pclass = 1."},{"metadata":{"_uuid":"a557a0e8577d738f623d6ec94fe57b28371347f0","_cell_guid":"1029cc1d-1b73-4a6f-87ed-f12fb744895c","trusted":true},"cell_type":"code","source":"# survival rate is below 0.5 for females with Parch = 2 and Pclass = 3 \n#df_test.loc[ (df_test.Sex == 'female') & (df_test.Pclass == 3) & (df_test.Parch == 2), 'Survived'] = 0\n\n# All females with Parch = 4 and Pclass = 3 died\n##df_test.loc[ (df_test.Sex == 'female') & (df_test.Pclass == 3) & (df_test.Parch == 4), 'Survived'] = 0\n\n# all females with Parch > 4 died\n#df_test.loc[ (df_test.Sex == 'female') & (df_test.Parch > 4) , 'Survived'] = 0\n\n# For males with Parch = 2 and Pclass = 1 survival rate is above 0.5\n##df_test.loc[ (df_test.Sex == 'male') & (df_test.Pclass == 1) & (df_test.Parch == 1) , 'Survived'] = 1\n\n#df_test.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9be20e55154d523983caa038da053b52e16c0231","_cell_guid":"b70366e6-40cd-4b49-be28-d9c6e24b7a91"},"cell_type":"markdown","source":"**Fare:  continuous numerical  to  12 bins **"},{"metadata":{"_uuid":"2bde44c43067232fb1a2ef8deff227374c6eab3a","_cell_guid":"175cc9dd-f96e-47c3-9516-e32d01c28aa3","trusted":true},"cell_type":"code","source":"sns.distplot(df_train['Fare']);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c0b70efca4ecaafbefecdfdcb81868c5221b505","_cell_guid":"8a24e3c4-ea4e-4558-b9f4-d21eff1a5bf0","trusted":true},"cell_type":"code","source":"for df in [df_train, df_test]:\n    df['Fare_bin']=np.nan\n    for i in range(12,0,-1):\n        df.loc[ df['Fare'] <= i*50, 'Fare_bin'] = i","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ac79a5e7f2b7b24b83d3d30d4e98c4985dff982","_cell_guid":"dbd84dd3-877b-4776-bf41-893a1f430db2","trusted":true},"cell_type":"code","source":"sns.catplot('Fare_bin','Survived', col='Pclass' , row = 'Sex', kind='point', data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b53e3f946de54690664973cd7f58846d4d86cda8","_cell_guid":"deed0fac-16b3-4516-aa12-312af2737854","trusted":true},"cell_type":"code","source":"pd.crosstab([df_train.Sex, df_train.Survived], [df_train.Fare_bin, df_train.Pclass], margins=True).style.background_gradient(cmap='autumn_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26c3ecb1baffe766db0c67035c2f2db1810ffcfc","_cell_guid":"0e42bcc2-7e44-428f-9f59-3e5a0a4f45e6"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"99172edb70d21c3fb13de749f9df1569dc7461f9","_cell_guid":"642c5d70-97a9-48cc-b5c8-8e07e4db71ac","trusted":true},"cell_type":"code","source":"# males in Fare_bin = 11 survived\ndf_test.loc[ (df_test.Sex == 'male') & (df_test.Fare_bin == 11), 'Survived'] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1a66aaa910a8c3956dc2c4aa6dc47140713b1fc","_cell_guid":"dd78e40e-e907-4b07-bae8-63c11c626e27"},"cell_type":"markdown","source":"fourth model : model 3 + Age_bin, SibSp, Parch and Fare_bin  \nsubmission : 0.789 accuracy"},{"metadata":{"_uuid":"0f71d8c091cc8275f4ba55ccd3bda94558b2eb08","_cell_guid":"bafbd295-3155-4910-9e31-0d503ff191fa","trusted":true},"cell_type":"code","source":"# model 4\n# df_test[['PassengerId', 'Survived']].to_csv('model_4.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50b87053b54b3c4ff8665140195a1f998b2ab67f","_cell_guid":"a2925f8c-f423-41fa-b5bf-be3aee40085d","trusted":true},"cell_type":"code","source":"df_test.drop(['Survived'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"234841fbf8468fff4dae479d754e2faf7a608d48","_cell_guid":"4ea56fab-36bd-4653-ae5c-84ddd2b952ac"},"cell_type":"markdown","source":"\n## Part 2: Data wrangling\n\nbuilding two new dataframes df_train_ml and df_test_ml  \nthese will have only ordinal features and no missing values so they can be used for ML algorithms  \nconverting categorical to numerical by pd.get_dummies  \ndropping all features that seem to be not useful for prediction  \nThen use the Standard scaler and apply train/test split"},{"metadata":{"_uuid":"9a31d42ed6c2c691a7c623f5a9bb4f22299f89a0","_cell_guid":"652b2dc3-f948-497c-90c1-5be0dea4c8ea","trusted":true},"cell_type":"code","source":"df_train_ml = df_train.copy()\ndf_test_ml = df_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a9e22bc52998976d8db53466f3eb555fea22279"},"cell_type":"markdown","source":"**pandas get_dummies for categorical features**"},{"metadata":{"_uuid":"e92489c48f64a1bb6583433a5b5f05c49aed7525","_cell_guid":"bd6d2c42-c06e-4d90-899b-bb7bd2c7c0bf","trusted":true},"cell_type":"code","source":"df_train_ml = pd.get_dummies(df_train_ml, columns=['Sex', 'Embarked', 'Pclass'], drop_first=True)\ndf_train_ml.drop(['PassengerId','Name','Ticket', 'Cabin', 'Age_bin', 'Fare_bin'],axis=1,inplace=True)\ndf_train_ml.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e62432f4174b210f2495be370071a9fa6b5ba334","_cell_guid":"6260f108-ebbc-4c9b-bd26-e09745db239e","trusted":true},"cell_type":"code","source":"passenger_id = df_test_ml['PassengerId']\ndf_test_ml = pd.get_dummies(df_test_ml, columns=['Sex', 'Embarked', 'Pclass'], drop_first=True)\ndf_test_ml.drop(['PassengerId','Name','Ticket', 'Cabin', 'Age_bin', 'Fare_bin'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1ebf6d67eb088f0d48898311416edb95ae00252","_cell_guid":"bc0ea6bd-cebb-4622-a785-f517e219834d","trusted":true},"cell_type":"code","source":"df_train_ml.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9c0d6596a00d10870061cb5a9ace69c50485acb","_cell_guid":"fce96fa4-31fd-4172-a318-82cc52648334","trusted":true},"cell_type":"code","source":"df_train_ml.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e76005c871612baf9bfa17fec4ed5a0abec70df8","_cell_guid":"e428437a-0d5d-459d-a3e2-25cd21a0985b","trusted":true},"cell_type":"code","source":"df_test_ml.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ea1c0e579b2a914242c8f78dde70fefb1ab7b05","_cell_guid":"0b0bede5-efad-4372-bb5d-efc18da3ca03","trusted":true},"cell_type":"code","source":"df_test_ml.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"119c33bc381878c773350aeb67c50da7b647a0fc","_cell_guid":"f27af614-2e9f-4c84-9ee4-ce559a389cf5"},"cell_type":"markdown","source":"**Correlation Matrix**"},{"metadata":{"_uuid":"56e391dbd1c08c3d2665fb11effa9bfdb26351c2","_cell_guid":"c57bfd45-629a-433d-81c0-648693cd81a7","trusted":true},"cell_type":"code","source":"corr = df_train_ml.corr()\n\nf,ax = plt.subplots(figsize=(9,6))\nsns.heatmap(corr, annot = True, linewidths=1.5 , fmt = '.2f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbc0a3ae5a12f681051ee8b947f445c24d8d13be"},"cell_type":"markdown","source":"Survived and Fare positively correlated, Survived and Sex_male negatively correlated.  \nAlso, Survived and Pclass_3 negatively correlated. SibSp and Parch correlated"},{"metadata":{"_uuid":"01bdefe92d15038b8ab3f586e9c52e524aef019b","_cell_guid":"9e081640-5bd0-4ace-be3b-5ceccc2b11d1"},"cell_type":"markdown","source":"**sklearn StandardScaler**"},{"metadata":{"_uuid":"37da643912238c3168325df04b6e4ed5dc90145d","_cell_guid":"bddddf4c-b292-44f9-9670-869ce82b47a8","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# for df_train_ml\nscaler.fit(df_train_ml.drop('Survived',axis=1))\nscaled_features = scaler.transform(df_train_ml.drop('Survived',axis=1))\ndf_train_ml_sc = pd.DataFrame(scaled_features, columns=df_train_ml.columns[:-1])\n\n# for df_test_ml\ndf_test_ml.fillna(df_test_ml.mean(), inplace=True)\n# scaler.fit(df_test_ml)\nscaled_features = scaler.transform(df_test_ml)\ndf_test_ml_sc = pd.DataFrame(scaled_features, columns=df_test_ml.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17ed2ba80cf75636842a1b27f994766f8ef05c7d","_cell_guid":"69721af1-e5b6-44dd-8031-16f35377d7f7"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"ef6756ea1bb077b36c803069fb12c71fab9b7958","_cell_guid":"2b933e10-5fcb-4e96-82d9-e43a250a5b96"},"cell_type":"markdown","source":"**train_test_split**  \nuse 70% of the data for training and 30% for testing"},{"metadata":{"_uuid":"5ce435c99a735bc0cda9775ef375d3f57ec1ff3b","_cell_guid":"a0f88356-1b14-4a56-9535-e43aa781e2d0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_train_ml.drop('Survived',axis=1), df_train_ml['Survived'], test_size=0.30, random_state=101)\nX_train_sc, X_test_sc, y_train_sc, y_test_sc = train_test_split(df_train_ml_sc, df_train_ml['Survived'], test_size=0.30, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e27b3baf7a41fbc58110d16c36e732b8ec74179","_cell_guid":"306951c3-c004-4c30-929a-54b461c19871"},"cell_type":"markdown","source":"**all data for submission**"},{"metadata":{"_uuid":"6699fa2223103aca2b725b43d0468abaab7a4960","_cell_guid":"1a8b5751-6090-4db1-94c0-38538f6e31d9","trusted":true},"cell_type":"code","source":"# unscaled\nX_train_all = df_train_ml.drop('Survived',axis=1)\ny_train_all = df_train_ml['Survived']\nX_test_all = df_test_ml\n\n# scaled\nX_train_all_sc = df_train_ml_sc\ny_train_all_sc = df_train_ml['Survived']\nX_test_all_sc = df_test_ml_sc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a465421f227fcc37ac587c762aed5cd92bc55983","_cell_guid":"e2cfbf74-9bad-43be-82e3-4fe0bd14777a"},"cell_type":"markdown","source":"**fillna: fill nan with mean values for that column** "},{"metadata":{"_uuid":"b3416d5b019c4ab043880e52a2e3bf15c2be80cc","_cell_guid":"c5e56666-3bf0-4114-8b6e-062bf6a2b57e","trusted":true},"cell_type":"code","source":"X_test_all.fillna(X_test_all.mean(), inplace=True)\nprint(\"*\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad4815f3394926316ab5b96318c16c372be361ee","_cell_guid":"34c5db90-ad9b-4641-8ce8-305950e0ff7f","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b70f2c1e3d0eb733ae55e7ce3194ac5dbbb6610","_cell_guid":"a97ce00f-0e3e-4426-94b8-a72c1dcc7a48"},"cell_type":"markdown","source":"## Part 3: Scikit-learn basic ML algorithms and comparison of model results\n\n**Test simple sklearn models and compare by metrics**\n\n\n**We test the following classifiers from scikit-learn:**  \n3.1 [Logistic Regression](#3.1-Logistic-Regression)  \n3.2 [Gaussian Naive Bayes](#3.2-Gaussian-Naive-Bayes)  \n3.3 [K nearest neighbors KNN](#3.3-KNN---KNeighborsClassifier)  \n3.4 [Decision tree classifier](#3.4-Decision-Tree-Classifier)  \n3.5 [Random forest classifier](#3.5-Random-Forest-Classifier)  \n3.6 [SVM classifier](#3.6-SVM-Classifier)  \n\n\n**First we apply the data from test/train split to get a first overview of the model performance.  \nLater we use the k fold cross validation which gives a better estimate for out of sample data.**  \n\n\n**For comparison of the results we use these metrics:**  \naccuracy_score, classification_report, confusion_matrix\n"},{"metadata":{"_uuid":"5aa7b62561073ef598953a28d653f0efcc084ff3","_cell_guid":"afb9743f-74dd-4ea2-9d1b-62f05c385f06","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a38bb9583a4370505d8fd9fed85884e844c67e42"},"cell_type":"markdown","source":"**confusion matrix** : used to evaluate the quality of the output of a classifier.  \nThe diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions.  \n*(from sklearn documentation, slightly modified)*\n\nThe rows of a confusion matrix correspond to the true (actual) classes and the columns correspond to the predicted classes.  \nSo, all together the confusion matrix for a **binary classifier** consists of 4 values:\n\nTN FP  \nFN TP  \n      \nTN: True negatives (prediction: not survived, true: not survived)  \nFP: False positives (prediction: survived, true: not survived)  \nFN: False negatives (prediction: not survived, true: survived)  \nTP: True positives (prediction: survived, true: survived)\n      \n      "},{"metadata":{"_uuid":"599064d0c5c1f8e2898ac52e74afd3c0b01deeee"},"cell_type":"markdown","source":"**accuracy score**  \nclassification accuracy = correct predictions / total predictions   = (TP + TN)  /  (TP + TN + FP + FN) "},{"metadata":{"_uuid":"6746435e7c2842ea68b7719f4ccec2a943365341"},"cell_type":"markdown","source":"**classification_report**  \n*from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html* :  \n\nThe precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n\nThe recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n\nThe F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n\nThe F-beta score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important.\n\nThe support is the number of occurrences of each class in y_true.\n\nprecision\nrecall\nf1-score\nsupport"},{"metadata":{"trusted":true,"_uuid":"1c0a4d84091df7e2470d60f3d4511be4b2ecc25a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a98974492d221085c59ac67cd9335866f533d9df","_cell_guid":"5dc9f50e-4678-4cac-b76b-a45cdb011c4b"},"cell_type":"markdown","source":"### **3.1 Logistic Regression**  \n[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) ++ [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression) ++ [Coursera Andrew Ng](https://www.coursera.org/lecture/machine-learning/classification-wlPeP)  ++ [towardsdatascience](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc) ++ [DataCamp](https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python) ++ [hackernoon](https://hackernoon.com/introduction-to-machine-learning-algorithms-logistic-regression-cbdd82d81a36) ++ [dataaspirant](http://dataaspirant.com/2017/03/02/how-logistic-regression-model-works/)"},{"metadata":{"_uuid":"e8ca909c5fd5b8cd72fdaff07f9da8c68e6b9dff","_cell_guid":"01dc1500-aecd-448d-a4e5-ba57428bdd76","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\npred_logreg = logreg.predict(X_test)\nprint(confusion_matrix(y_test, pred_logreg))\nprint(classification_report(y_test, pred_logreg))\nprint(accuracy_score(y_test, pred_logreg))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30cb74d5cc08bfb2febce98b7d41184413026790","_cell_guid":"ae4c3814-4809-42be-bb3b-91c19635fc57","collapsed":true},"cell_type":"markdown","source":"**Train again for all data and submit**"},{"metadata":{"_uuid":"c4310a65657f5e23b621bfe3ad746374726ae890","_cell_guid":"9b79843b-f40d-4b59-adb3-62e326a24dec","trusted":true},"cell_type":"code","source":"logreg.fit(X_train_all, y_train_all)\npred_all_logreg = logreg.predict(X_test_all)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a99d5c8f07557a00541ba0ec385994dd0f3bc0b","_cell_guid":"b57744f3-454e-4576-8229-83820684693d","trusted":true},"cell_type":"code","source":"sub_logreg = pd.DataFrame()\nsub_logreg['PassengerId'] = df_test['PassengerId']\nsub_logreg['Survived'] = pred_all_logreg\n#sub_logmodel.to_csv('logmodel.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee96ee067f8ef62ae6a5bce39dc8160b81245a7b","_cell_guid":"d7d6f8e8-9be5-43d0-b494-1150ff590a04"},"cell_type":"markdown","source":"### **3.2 Gaussian Naive Bayes**  \n[sklearn](https://scikit-learn.org/stable/modules/naive_bayes.html) ++ [Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes) ++   [towardsdatascience](https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c) ++ [towardsdatascience](https://towardsdatascience.com/naive-bayes-in-machine-learning-f49cc8f831b4) ++ [DataCamp](https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn) ++ [dataaspirant](http://dataaspirant.com/2017/02/06/naive-bayes-classifier-machine-learning/) \n\n"},{"metadata":{"_uuid":"10b21e9234e15473334284f5fb09865a8f6aed38","_cell_guid":"bab1431a-a998-4690-a723-3bf97c713f81","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb=GaussianNB()\ngnb.fit(X_train,y_train)\npred_gnb = gnb.predict(X_test)\nprint(confusion_matrix(y_test, pred_gnb))\nprint(classification_report(y_test, pred_gnb))\nprint(accuracy_score(y_test, pred_gnb))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0df98617614852e174974ab502030b9537588bd","_cell_guid":"77e67810-007a-4f41-b044-79db7473a702","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d50f9b2bd118508032ee574fb2807bf30fc808e4","_cell_guid":"bba6f74d-86ee-418e-9289-eb6c734a6233"},"cell_type":"markdown","source":"### **3.3 KNN - KNeighborsClassifier**  \n[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) ++ [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) ++   [Medium](https://medium.com/@adi.bronshtein/a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7) ++ [towardsdatascience](https://towardsdatascience.com/introduction-to-k-nearest-neighbors-3b534bb11d26) ++ [datacamp](https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn) ++ [analyticsvidhya](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/) ++ [dataaspirant](http://dataaspirant.com/2016/12/27/k-nearest-neighbor-algorithm-implementaion-python-scratch/)\n\n\n"},{"metadata":{"_uuid":"af2c6002a730507bc05f31317d131239e84926c2","_cell_guid":"cb7cd232-b69e-4607-9d9c-3b879f4bfcca","trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=20)\nknn.fit(X_train_sc,y_train_sc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dd521eb9c17dddbc50464d49fbc6e59efe5070c","_cell_guid":"dc54ea94-83ec-44e3-90c2-aa8cfcf9d296","trusted":true},"cell_type":"code","source":"pred_knn = knn.predict(X_test)\nprint(confusion_matrix(y_test, pred_knn))\nprint(classification_report(y_test, pred_knn))\nprint(accuracy_score(y_test, pred_knn))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebe21f1f1003b10e95065e38f65f2f0be28759d3","_cell_guid":"e33c6acd-800d-4ce4-a360-4a84a4adee63","trusted":true},"cell_type":"code","source":"knn.fit(X_train_all, y_train_all)\npred_all_knn = knn.predict(X_test_all)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9dd159c1daa993b6bca277ea8cb0150f5950d33","_cell_guid":"f2f24f95-f151-4c29-9403-289fda0ca66e","trusted":true},"cell_type":"code","source":"sub_knn = pd.DataFrame()\nsub_knn['PassengerId'] = df_test['PassengerId']\nsub_knn['Survived'] = pred_all_knn\n#sub_knn.to_csv('knn.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa7d54676eabbecfc2a1900f2b807fa09a497325","_cell_guid":"d13d9d1a-ba24-4c6d-bfe1-661684f003a3"},"cell_type":"markdown","source":"### **3.4 Decision Tree Classifier**  \n[sklearn](https://scikit-learn.org/stable/modules/tree.html) ++ [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning) ++   [Medium](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052) ++ [Medium](https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1) ++ [datacamp](https://www.datacamp.com/community/tutorials/decision-tree-classification-python) ++ [hackernoon](https://hackernoon.com/what-is-a-decision-tree-in-machine-learning-15ce51dc445d) ++ [hackerearth](https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/ml-decision-tree/tutorial/)"},{"metadata":{"_uuid":"12d314dfeb7e8426bf7c46426442e9a2001a5b57","_cell_guid":"f13c65cb-8cab-44c9-82e7-1b28c457f4a3","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8978d730e880e08a6eedbc6a04d37fc886d3a1b2","_cell_guid":"c394d4b2-e2bd-4069-bf86-204e832454ae","trusted":true},"cell_type":"code","source":"pred_dtree = dtree.predict(X_test)\nprint(classification_report(y_test,pred_dtree))\nprint(accuracy_score(y_test, pred_dtree))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c0bfe8c80e86cd819035a6e813b011589de7555","_cell_guid":"e740c24c-65eb-43b7-be6c-faae1c0e0f48"},"cell_type":"markdown","source":"another decision tree with different parameters for max_features, max_depth and min_sample_split"},{"metadata":{"_uuid":"35b52e7d6535918d117ea162efded54d5f02a1d4","_cell_guid":"60447787-2162-4c45-8854-8bddc5b843ae","trusted":true},"cell_type":"code","source":"dtree_2 = DecisionTreeClassifier(max_features=7 , max_depth=6,  min_samples_split=8)\ndtree_2.fit(X_train,y_train)\npred_dtree_2 = dtree_2.predict(X_test)\nprint(classification_report(y_test, pred_dtree_2))\nprint(accuracy_score(y_test, pred_dtree_2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"652c6896c85aecd4a97a7012a9a8738f73c86321","_cell_guid":"ea30a39c-8156-47f6-bec9-1a9ccf9650d3"},"cell_type":"markdown","source":"all data"},{"metadata":{"_uuid":"e93797154e1f640b79d3b594e1aa75046be087e8","_cell_guid":"7808aa8f-a1df-4871-a3f2-da23875beb57","trusted":true},"cell_type":"code","source":"dtree_2.fit(X_train_all, y_train_all)\npred_all_dtree2 = dtree_2.predict(X_test_all)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c210aa8b14ec568e092bfe496d5362533ecb458e","_cell_guid":"3e66bcee-31c7-4fbc-a09e-6c32f8859b53","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"281c4476eaa11f290fdbee0ea502d1447f1822f2","_cell_guid":"5f37cb99-42f8-4e05-b9ec-385973f14692","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e318aead214dd88a32dee050b63534baf476204","_cell_guid":"433a8d63-597c-4e26-bbeb-1ed81354f7fa"},"cell_type":"markdown","source":"### **3.5 Random Forest Classifier**  \n[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) ++ [Wikipedia](https://en.wikipedia.org/wiki/Random_forest) ++   [towardsdatascience](https://towardsdatascience.com/the-random-forest-algorithm-d457d499ffcd) ++ [towardsdatascience](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0) ++ [datacamp](https://www.datacamp.com/community/tutorials/random-forests-classifier-python) ++ [youtube](https://www.youtube.com/watch?v=eM4uJ6XGnSM) ++ [jakevdp](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html)"},{"metadata":{"_uuid":"952a8943f083afbd92a9b886a0f34c15b825eaad","_cell_guid":"6a509bda-3707-47a6-8842-575a5301b55b","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(max_depth=6, max_features=7)\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"266fb47dddd6f5f6c6f48234f8882586ab444518","_cell_guid":"cb0bc6b2-59e8-42d2-8715-65cfb03465be","trusted":true},"cell_type":"code","source":"pred_rfc = rfc.predict(X_test)\nprint(confusion_matrix(y_test, pred_rfc))\nprint(classification_report(y_test, pred_rfc))\nprint(accuracy_score(y_test, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7be67c5f903cdc46bccfc4301fc698e202ee362e","_cell_guid":"2bce93e5-6999-461a-9cb5-22c5dddf9d00"},"cell_type":"markdown","source":"**Train again for all data and submit**"},{"metadata":{"_uuid":"eb506f0f8e624250b09d5853093ff76e94709ce7","_cell_guid":"b2ec4f9a-0b1d-4853-8098-34321d6039f1","trusted":true},"cell_type":"code","source":"rfc.fit(X_train_all, y_train_all)\npred_all_rfc = rfc.predict(X_test_all)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c2b67fec6ff809fa8d67bcd73424e6a8fad6279","_cell_guid":"1c2b0457-8122-4bb1-a1ce-f36303fc3d88","trusted":true},"cell_type":"code","source":"sub_rfc = pd.DataFrame()\nsub_rfc['PassengerId'] = df_test['PassengerId']\nsub_rfc['Survived'] = pred_all_rfc\n#sub_rfc.to_csv('randforest.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4021bbeb9afa42781c042b7a5edd03f5c82a939","_cell_guid":"58626def-4075-46df-91ee-43e4e55668c9","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"809ce0be2d8a722b4d8d58418677c0d4966a8f16","_cell_guid":"6e28d3fb-51a7-4e82-a1a5-eeb23da7e4b3"},"cell_type":"markdown","source":"### **3.6 SVM Classifier**  \n[sklearn](https://scikit-learn.org/stable/modules/svm.html) ++ [Wikipedia](https://en.wikipedia.org/wiki/Support-vector_machine) ++   [towardsdatascience](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47) ++ [datacamp](https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python) ++ [medium](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72) ++ [youtube](https://www.youtube.com/watch?v=N1vOgolbjSc) ++ [jakevdp](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)"},{"metadata":{"_uuid":"7dc73547a649cc39dd01307891bee1ccff28d5ac","_cell_guid":"a2f7808b-f2d4-48d2-80ba-6b036a2c71df","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(gamma = 0.01, C = 100)#, probability=True)\nsvc.fit(X_train_sc, y_train_sc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97343ce35fe05636bf7f81bbd19173216b87e7db","_cell_guid":"fc4f1f70-dcaf-44bd-a5e2-e7f59902b085","trusted":true},"cell_type":"code","source":"pred_svc = svc.predict(X_test_sc)\nprint(confusion_matrix(y_test_sc, pred_svc))\nprint(classification_report(y_test_sc, pred_svc))\nprint(accuracy_score(y_test_sc, pred_svc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffcd13b21206badc7107940ea32bf3baa9da34c4","_cell_guid":"c17b5538-45be-46b2-9cf5-cf6f2560059d","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecf4783d0889814d14bf7839ad8b52548aefefc4","_cell_guid":"2722e61a-8a5d-40f6-b239-46cf943f88c2","trusted":true},"cell_type":"code","source":"svc.fit(X_train_all_sc, y_train_all_sc)\npred_all_svc = svc.predict(X_test_all_sc)\n\nsub_svc = pd.DataFrame()\nsub_svc['PassengerId'] = df_test['PassengerId']\nsub_svc['Survived'] = pred_all_svc\nsub_svc.to_csv('svc.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34956bbb95b445fd7d1b9d4304c005b1bc1ce1b8","_cell_guid":"2d30b58c-2db3-4537-a7e5-bc2ec7ee2335","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9a3f6fd15bd825abd64c7be034fba0565e75d94"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44b874933e564fd164b89a9085115690b9f0b766","_cell_guid":"14bf2d14-04cd-4ed7-bbd8-b11f426e60b3","collapsed":true},"cell_type":"markdown","source":"**k fold cross_validation**\n\nThis algorithm splits the data into k sets and then makes k fits using every set k-1 times as training and one time as test data  \nIt leads to a better estimate for out of sample data  than simple train test split"},{"metadata":{"_uuid":"23dc13283588cf185560d4f1046512479009b020","_cell_guid":"8c7aeda5-6c2b-4e57-9a22-fd7995a62916","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fc0e9866290edb4e6b57b2e1af7d30eb704bf21","_cell_guid":"093fb806-4c2a-45ae-a4f5-963c3472540c"},"cell_type":"markdown","source":"for SVM classifier"},{"metadata":{"_uuid":"957698ab13a1ea804ceaaf6163fa5386d5e9b507","_cell_guid":"8b28d8ec-73c9-496f-adfb-f3c0792edfb0","trusted":true},"cell_type":"code","source":"scores_svc = cross_val_score(svc, X_train_all_sc, y_train_all_sc, cv=10, scoring='accuracy')\nprint(scores_svc)\nprint(scores_svc.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc2bebfd922ec1bc69901be66bfc55fbe446f20b","_cell_guid":"3bfa63f6-b29a-441a-9e6a-eac57b7ac517"},"cell_type":"markdown","source":"for Random Forest classifier"},{"metadata":{"_uuid":"c1d0440409da72fa737f99fa78f24aacd9b62c6c","_cell_guid":"3486213b-3f2e-4328-b7a6-a05c2c731f6e","trusted":true},"cell_type":"code","source":"scores_rfc = cross_val_score(rfc, X_train_all_sc, y_train_all_sc, cv=10, scoring='accuracy')\nprint(scores_rfc)\nprint(scores_rfc.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9514b5fe9f1861d014e9a54f5e6624851b7e1fb","_cell_guid":"5f4d9294-89dd-40f4-aa60-ed90349554cb","collapsed":true},"cell_type":"markdown","source":"for DecisionTreeClassifier"},{"metadata":{"_uuid":"c40f7cf3db4c3077e9daa7a011f4bd857f90a360","_cell_guid":"d28462a8-f6ee-49f3-93af-44929b499b4d","trusted":true},"cell_type":"code","source":"scores_dtree_2 = cross_val_score(dtree_2, X_train_all_sc, y_train_all_sc, cv=10, scoring='accuracy')\nprint(scores_dtree_2)\nprint(scores_dtree_2.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7afc8da465448e49eb17a95a339c71b01b4223b4","_cell_guid":"05f734ef-760d-45b3-a2c5-028a9aada184"},"cell_type":"markdown","source":"**The Classifiers with best performance are Decision Tree, Random Forest and SVC**\n"},{"metadata":{"_uuid":"ca0e2a3b1be83597e8b6bf08769e6904b437c332","_cell_guid":"736dc39a-274d-4e16-9882-aa1aed6755ae","trusted":true},"cell_type":"code","source":"print(\"dtree_2 : \" , scores_dtree_2.mean())\nprint(\"rfc     : \" , scores_rfc.mean())\nprint(\"svc     : \" , scores_svc.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51bd69ff52df610d828990090972abf2f8fdb217","_cell_guid":"3b6218bd-cbff-48f6-b1aa-6e53967fe090","collapsed":true},"cell_type":"markdown","source":"**Note on scores**\n\nSome kernels for the Titanic competition calculate scores based on the training set. This is not a good indicator for the model performance, because we want to know how well the model generalizes for data that was not used for fitting the model. Therefore, scores in this and in my other kernels are always for out of sample test or validation data."},{"metadata":{"_uuid":"ee26abaed914638118de10f1cc177184d38abd21","_cell_guid":"b003787b-c505-4a4c-9f43-230acc35c2f5","collapsed":true},"cell_type":"markdown","source":"**Conclusion**  \nWith this notebook we learned the basics of EDA with Pandas and Matplotlib as well as the foundations  \nfor applying the classification models of the scikit learn library.  \nBy EDA we found a strong impact of features like Sex, Age, Embarked on the target.  \nWe then built a simple baseline model with Pandas, using only these features.  \nAgain using Pandas, we also created a dataset that can be used by the sklearn Classifiers for prediction.  \nDeciding by k fold cross validation score, the best ML models for this task and set of features were:  \nDecision Tree, Random Forest and SVC  \nSubmitting their predictions gives a score of 0,78 and a place in the top 30% of the Leaderboard.  \n\nIn [my second Titanic kernel](https://www.kaggle.com/dejavu23/titanic-survival-my-2nd-kernel) I study how to improve this score by \n* using features built from the existing ones (Feature Engineering)\n* optimising the model hyper-parameters with GridSearchCV\n* applying techniques like boosting, stacking and voting"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}