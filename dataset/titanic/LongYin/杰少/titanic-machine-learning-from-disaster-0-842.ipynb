{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","name":"python"}},"cells":[{"cell_type":"markdown","source":"## 1. Introduction\n\n### In this notebook, we  will show our method which can get a PB score <font color = red > 0.84211 </font>. This notebook only uses single model random forest classifier, so there is still room to improve the performance like  using ensemble methods.  \n\n### Because our method based on other great minds and the intuition behind the feature engineering can be found in the following notebooks. Hence, I will omit the details and only provide the codes.\n\n#### 1. Titanic Random Forest: 82.78%\n#### 2. A Journey through Titanic\n#### 3. Titanic Data Science Solutions\n#### 4.Pytanic","metadata":{"_uuid":"98561469c54cbd7b8a07da6ae667f440a6635970","_cell_guid":"403c61e5-c979-403c-ad30-56bc6d9b8c65","collapsed":true}},{"cell_type":"markdown","source":"## 2. Load Libraries and Raw Data","metadata":{"_uuid":"2d6d4d3dc6f7966570274b75219b6ab311d95190","_cell_guid":"f2d6c0e3-8e95-4dc4-95d9-4d25b54b7b32"}},{"metadata":{"_execution_state":"busy","_uuid":"8b8cda16cd629eae909fd1108ef12a4b55b416a3","_cell_guid":"3a0cf604-d311-4bf7-bdb1-3e19de0cf1ff"},"cell_type":"code","outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing \nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn import cross_validation\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')","execution_count":1},{"metadata":{"_execution_state":"busy","_uuid":"541ad1c5e02e65ce56db289646bd5c744d2bfb5e","_cell_guid":"e53ae0c8-ac83-4705-b959-c799836153c9"},"cell_type":"code","outputs":[],"source":"train = pd.read_csv(\"../input/train.csv\")\ntrain.head()","execution_count":2},{"metadata":{"_execution_state":"busy","_uuid":"1187eeac4b61c67e853824f152bbe9864a128fa6","_cell_guid":"9e0f1199-22f4-4a36-bf2f-f35846d045c0"},"cell_type":"code","outputs":[],"source":"test = pd.read_csv(\"../input/test.csv\")\ntest.head()","execution_count":3},{"cell_type":"markdown","source":"## 2. Feature Engineering","metadata":{"_uuid":"a52a172af0c0f4a6a8675a25162ca4bdb8a67df8","_cell_guid":"d74e934a-ba79-47ef-82e0-a984afbaf093"}},{"metadata":{"_execution_state":"busy","_uuid":"1730efc8f3151952620ebf824932c59c87fd2374","_cell_guid":"8320485c-8a1a-4754-a80d-f6dae1bb9690","collapsed":true},"cell_type":"code","outputs":[],"source":"train['Sex'] = train['Sex'].apply(lambda x: 1 if x == 'male' else 0)\ntest['Sex'] = test['Sex'].apply(lambda x: 1 if x == 'male' else 0)","execution_count":4},{"metadata":{"_execution_state":"busy","_uuid":"588cc5692b3696c787ff455df16a6d092e42cdba","_cell_guid":"d547c68e-7641-46bb-8c50-3e32557bffc9","collapsed":true},"cell_type":"code","outputs":[],"source":"def Name_Title_Code(x):\n    if x == 'Mr.':\n        return 1\n    if (x == 'Mrs.') or (x=='Ms.') or (x=='Lady.') or (x == 'Mlle.') or (x =='Mme'):\n        return 2\n    if x == 'Miss':\n        return 3\n    if x == 'Rev.':\n        return 4\n    return 5\n\ntrain['Name_Title'] = train['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\ntest['Name_Title'] = test['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0]) ","execution_count":5},{"metadata":{"_execution_state":"busy","_uuid":"45cbf2fa93e55c29c5fa8bb854b66c9cea6f2a88","_cell_guid":"875237ed-58d9-43e3-9b87-e49b3a861f1f","collapsed":true},"cell_type":"code","outputs":[],"source":"def Age_feature(train, test):\n    for i in [train, test]:\n        i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)  \n        data = train.groupby(['Name_Title', 'Pclass'])['Age']\n        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n#         i['Age'] = data.transform(lambda x: x.fillna(x.median()))\n    return train, test","execution_count":6},{"metadata":{"_execution_state":"busy","_uuid":"8c81ab5f91610ebb3a971842c42b6b8070e37903","_cell_guid":"188c5cb6-4d8b-4b0e-b1d8-61fd38a0e853","collapsed":true},"cell_type":"code","outputs":[],"source":"def Family_feature(train, test):\n    for i in [train, test]:\n        i['Fam_Size'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo',\n                           np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n        del i['SibSp']\n        del i['Parch']\n    return train, test ","execution_count":7},{"metadata":{"_execution_state":"busy","_uuid":"1e6bb34f761ffa1556a5a75d939f8e2bf1640dbc","_cell_guid":"4fd7cc8d-d563-4d1a-854d-339bf6dd998c","collapsed":true},"cell_type":"code","outputs":[],"source":"def ticket_grouped(train, test):\n    for i in [train, test]:\n        i['Ticket_Lett'] = i['Ticket'].apply(lambda x: str(x)[0])\n        i['Ticket_Lett'] = i['Ticket_Lett'].apply(lambda x: str(x))\n        i['Ticket_Lett'] = np.where((i['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), i['Ticket_Lett'],\n                                    np.where((i['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n                                            'Low_ticket', 'Other_ticket'))\n        i['Ticket_Len'] = i['Ticket'].apply(lambda x: len(x))\n        del i['Ticket']\n    return train, test","execution_count":8},{"metadata":{"_execution_state":"busy","_uuid":"18e907093c4bfb6ad3f167fc73d2fc9001685c72","_cell_guid":"5ddfb7ce-f149-4fd7-9ce1-03e8b5384b9d","collapsed":true},"cell_type":"code","outputs":[],"source":"def Cabin_feature(train, test):\n    for i in [train, test]:\n        i['Cabin_Letter'] = i['Cabin'].apply(lambda x: str(x)[0])\n        del i['Cabin']\n    return train, test","execution_count":9},{"metadata":{"_execution_state":"busy","_uuid":"44e3257ae83122cd95181d4c2e10d2f6b26463f9","_cell_guid":"a1bb01e0-ad7a-4557-834c-616e1719da25","collapsed":true},"cell_type":"code","outputs":[],"source":"def cabin_num(train, test):\n    for i in [train, test]:\n        i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n        i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n        i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n        i['Cabin_num'] = pd.qcut(train['Cabin_num1'],3)\n    train = pd.concat((train, pd.get_dummies(train['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n    test = pd.concat((test, pd.get_dummies(test['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n    del train['Cabin_num']\n    del test['Cabin_num']\n    del train['Cabin_num1']\n    del test['Cabin_num1']\n    return train, test","execution_count":10},{"metadata":{"_execution_state":"busy","_uuid":"9da9299ed0b15ebe596b7a51d6c6a864ef843702","_cell_guid":"9d530e95-e6c5-44b6-9837-b1238fd198ce","collapsed":true},"cell_type":"code","outputs":[],"source":"def embarked_impute(train, test):\n    for i in [train, test]:\n        i['Embarked'] = i['Embarked'].fillna('S')\n    return train, test","execution_count":11},{"metadata":{"_execution_state":"busy","_uuid":"d61be3be12d3b279392430b21a7405f7f9f8ca55","_cell_guid":"e90bfd1a-29aa-4001-abf8-39e394d17122","collapsed":true},"cell_type":"code","outputs":[],"source":"test['Fare'].fillna(train['Fare'].mean(), inplace = True)","execution_count":12},{"metadata":{"_execution_state":"busy","_uuid":"5a359c55dfe2e27a3002f71a80ac434010dba018","_cell_guid":"55022d10-c17b-422d-a62c-df6cf36243a8","collapsed":true},"cell_type":"code","outputs":[],"source":"def dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'Fam_Size']):\n    for column in columns:\n        train[column] = train[column].apply(lambda x: str(x))\n        test[column] = test[column].apply(lambda x: str(x))\n        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n        del train[column]\n        del test[column]\n    return train, test","execution_count":13},{"metadata":{"_execution_state":"busy","_uuid":"ad5cf1809c6795cb53716d0cd24da91dacecac89","_cell_guid":"46d8d152-ea0e-4af3-b667-eef9de27a27c","collapsed":true},"cell_type":"code","outputs":[],"source":"def drop(train, test, bye = ['PassengerId']):\n    for i in [train, test]:\n        for z in bye:\n            del i[z]\n    return train, test","execution_count":14},{"metadata":{"_execution_state":"busy","_uuid":"6c82779c3f6fff97cf51bcbb1ffd1e92d99036cf","_cell_guid":"fbcb2a76-e4c5-4ce8-a42e-f875a685e852","collapsed":true},"cell_type":"code","outputs":[],"source":"train, test = Age_feature(train, test)\n \ntrain['Name_Title'] = train['Name_Title'].apply(Name_Title_Code)\ntest['Name_Title'] = test['Name_Title'].apply(Name_Title_Code)\ntrain = pd.get_dummies(columns = ['Name_Title'], data = train)\ntest = pd.get_dummies(columns = ['Name_Title'], data = test)\n\ntrain, test = cabin_num(train, test)\n\ntrain, test = Cabin_feature(train, test)\n\ntrain, test = embarked_impute(train, test)\n\ntrain, test = Family_feature(train, test)\n\ntest['Fare'].fillna(train['Fare'].mean(), inplace = True)\n\ntrain, test = ticket_grouped(train, test)\n\ntrain, test = dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Fam_Size','Cabin_Letter'])  \n\ntrain, test = drop(train, test)","execution_count":15},{"metadata":{"_execution_state":"busy","_uuid":"874257d9c8d5fc0c1a34e864bbbfb306d68094d5","_cell_guid":"4db1fe7f-8b4a-4178-815c-d6417323ca34","collapsed":true},"cell_type":"code","outputs":[],"source":"train.drop('Name',axis=1,inplace=True)\ntest.drop('Name',axis=1,inplace=True)","execution_count":16},{"cell_type":"markdown","source":"## 4. Model training","metadata":{"_uuid":"d6e6f1310db0e9f497ef1ed98dd18d5ed5fe888b","_cell_guid":"8d534c0e-6d69-48c1-9229-0dfdc47775a6"}},{"metadata":{"_execution_state":"busy","_uuid":"b500e8cc97da46ed010fff936445056e2be4dcc3","_cell_guid":"db9f2d4a-befc-4b68-9f31-cc5d9816fb6f","collapsed":true},"cell_type":"code","outputs":[],"source":"\n# rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n# param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10, 12, 16], \"n_estimators\": [50, 100, 400, 700, 1000]}\n# gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n\n# gs = gs.fit(train.iloc[:, 1:], train.iloc[:, 0])\n\n# print(gs.best_score_)\n# print(gs.best_params_) \n","execution_count":17},{"metadata":{"_execution_state":"busy","_uuid":"2361c2e4e0ed4b3eefeb614ed7881b8690a6a2ee","_cell_guid":"46d3294b-f3c0-46e8-9eed-e6a9c99b6039"},"cell_type":"code","outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\n \nrf = RandomForestClassifier(criterion='gini', \n                             n_estimators=700,\n                             min_samples_split=16,\n                             min_samples_leaf=1,\n                             max_features='auto',\n                             oob_score=True,\n                             random_state=1,\n                             n_jobs=-1) \n\nrf.fit(train.iloc[:, 1:], train.iloc[:, 0])\nprint(\"%.4f\" % rf.oob_score_)","execution_count":18},{"metadata":{"_execution_state":"busy","_uuid":"1cd3a701900b591bdad1e1e19f385abe33220b59","_cell_guid":"4444e10c-159a-4f38-a4cd-d31d8ab9ac5d"},"cell_type":"code","outputs":[],"source":"pd.concat((pd.DataFrame(train.iloc[:, 1:].columns, columns = ['variable']), \n           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n          axis = 1).sort_values(by='importance', ascending = False)[:20]","execution_count":19},{"cell_type":"markdown","source":"## 5. Submit","metadata":{"_uuid":"bbad5aff8f09eb3fabe732b03d1d5d4f828d52d7","_cell_guid":"4867dfc3-023c-48fa-8970-bc0a1fbe3547"}},{"metadata":{"_execution_state":"busy","_uuid":"c5dccff507ecae39fc76de6717ac0a06f3a12bf0","_cell_guid":"de6b05c8-17b7-45c2-b813-24af91c2eaca","collapsed":true},"cell_type":"code","outputs":[],"source":"submit = pd.read_csv('../input/genderclassmodel.csv')\nsubmit.set_index('PassengerId',inplace=True)\n\nrf_res =  rf.predict(test)\nsubmit['Survived'] = rf_res\nsubmit['Survived'] = submit['Survived'].apply(int)\nsubmit.to_csv('submit.csv')","execution_count":20},{"metadata":{"_execution_state":"busy","_uuid":"629c209b036372241851c1a19f7d3261b2817169","_cell_guid":"b353357c-0fd3-4f27-b8f7-b1b0f575a548","scrolled":true},"cell_type":"code","outputs":[],"source":"submit","execution_count":21},{"cell_type":"markdown","source":"## 6. Learning together\n### If you have other techniques or expereriences to improve this PB score, I wish you could share with us. Let's learn together.","metadata":{"_uuid":"bea10c198a50f339a11aa8f02fc384ae5b6caa6c","_cell_guid":"a5897e0a-c5ee-49bc-90fe-b61cfa464925"}},{"metadata":{"_execution_state":"busy","_uuid":"db9cec3c19a058de625db1b3338983238013140c","_cell_guid":"ac1d45e5-aafc-4f5d-9ab9-51819a7f066a","collapsed":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"nbformat":4,"nbformat_minor":1}