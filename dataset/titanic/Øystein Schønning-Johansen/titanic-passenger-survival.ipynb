{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"e3230216-1ca6-480e-9367-401bbbf87c01"},"source":"# Titanic passenger survival analysis\nHere is my first kernel written on kaggle.com. **This is work in progress.** Please upvote and comment\nof you like it. Here is a little outline of the notebook.\n\n1. Munging the data\n2. Feature engineering\n3. Feature preparation\n4. Evaluating classifiers\n5. Submitting\n\n*Note:* I'm writing this from my parents residence and the internet connection here is really unstable.\nI loose my connection in the funniest moments.\nI'm also trying to make a nice vacation for my two daughters. That has a higher priority than kaggling.\nSo this notebook will probably progress slowly towards something useful."},{"cell_type":"markdown","metadata":{"_cell_guid":"773a4fd6-68fa-436a-b86a-1d8faef58bb1"},"source":"## Munging the data\nI will start by munging the data a bit. Munging data or data wrangling is the process\nof handling the raw data such that it works for the later analysis. The munging is\noften an important part of the data scientist's work."},{"cell_type":"markdown","metadata":{"_cell_guid":"e96566e8-28c0-4ee9-9e52-ba297cc8a68b"},"source":"### Loading the data.\nI will load the data into two pandas dataframes. The training dataset will be loaded into titanic,\nthe test dataset will be loaded into a dataframe called test. I will also merge the two into a\ndataframe called full, as the statistics\nbased on the both sets, will be used to make some estimations for missing data. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b171cb91-e944-496b-8623-4f00c81cec64"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c2e90dc-12e8-448a-b7ca-3bb160e898e8"},"outputs":[],"source":"titanic = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nfull = pd.concat([titanic, test])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"13f5d87b-8ba6-4dd6-8f79-78c0e9bd1758"},"outputs":[],"source":"titanic.info()\nprint(\"-\"*40)\ntest.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"37cdb577-4704-4e38-9192-6491b15dc944"},"source":"### Filling out some missing values\n#### Filling out the missing embarkment\nI looks like we miss a embarkment port for two passengers in titanic dataframe. Let's not make\na big thing about this, and assume that the the passengers embarked in Southampton. That is natural\nenough as most passengers embarked in Southampton. I also don't believe that the embarkment port\nis a real big indicator to predict survival. **Southampton it is!**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8653247f-fbb4-4875-9845-94af4b6caf99"},"outputs":[],"source":"# just to show the numbers\nfull.Embarked.value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27939c67-35de-466c-80ef-400903ca1a69"},"outputs":[],"source":"# or maybe even more convincing: A plot!\nfull.Embarked.value_counts().plot(kind='bar')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54cac140-347d-4829-b48d-10637dc7fe16"},"outputs":[],"source":"# See? It's pretty safe two assume they came for Southampton\ntitanic.Embarked.fillna(value='S', inplace=True)\n# Let's update the full dataframe as well:\nfull.Embarked.fillna(value='S', inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3c84a01a-7fc8-41ec-b3c7-9b0630c818ab"},"source":"### Filling out the missing fare\nThere is only one passenger where the fare is missing:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d3b09ea-9b5e-4c36-b164-95d9a00c39ab"},"outputs":[],"source":"test[np.isnan(test[\"Fare\"])]"},{"cell_type":"markdown","metadata":{"_cell_guid":"d8219397-07f1-4140-b20c-728e3d0d52e8"},"source":"I will fill this in with the median fare of the passengers for that\nembarkment port (S) on that passenger class (Third)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a4d77bd-212c-47b9-93ac-e1822174f6b3"},"outputs":[],"source":"# Mr. Storey from Southampton in third class.\ntest.loc[test[\"PassengerId\"] == 1044, \"Fare\"] = full[(full[\"Embarked\"]=='S') & (full[\"Pclass\"]==3)].Fare.median()\ntest.loc[test[\"PassengerId\"]==1044,:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"472155ae-d7e1-4632-855c-d6bb8ff9cab5"},"source":"8.05 GBP from Mr. Storey! Sounds good enough to me!\n### Filling out the missing ages\nI must admit that I have read Megan's notebook. She uses a MICE regression to fill in the missing ages.\nI really think that is a great idea, but I will settle for a simpler method in this notebook, as I don't\nbelieve the age is really the strongest indicator. I also want to keep it simple as this is my very\nfirst kernel on kaggle.\n\n(I'm at vacation, visiting my parents and the internet connection is a bit unstable here.... I also get a lot of\ninterruptions of different kinds, so I may use a few days for this notebook.)\n\n#### Age filling strategy\nThere was a \"Women and children first\" policy for filling up the lifeboats, so the important thing\nto consider is if a passenger with missing age was considered a child or adult. So to fill in the\nmissing age data we will use the title of the person, and fill in the median age for the given title.\n\nIt is important to understand that someone with title **Master** is typically a young boy who will be\nconsidered a child. **Master** was used address politely a boy who was too young to be called **Mister**.\nAlso, a **Miss** is typically unmarried and younger than a **Mrs**, so hopefully the strategy will help\nus get good values for the missing ages.\n\nSo the first step will be to make an additional column with the *Title*, in all three dataframes. Megan\nhas already showed us that the title of a passenger is actually an important predictor. So we will add the\ncolumn and keep it there for later."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10f8689e-3cf2-4ffa-a5c0-7558c5d3fee2"},"outputs":[],"source":"# So let's add a title column to each DataFrame\n# we also make a list of all our frames, such that we can easily loop over them.\nframes = [titanic, test, full]\nfor df in frames:\n    df[\"Title\"] = df.Name.str.replace('(.*, )|(\\\\..*)', '')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10c46e64-1e80-4f28-b4d3-f5965c21264a"},"outputs":[],"source":"full.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a3ad8f5e-c816-4235-bd18-aed8f0fe3333"},"source":"Looks like that worked fine! Let's see how many unique titles there are, and how many\nunique titles we need to fill in the age."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec64e9fd-258b-4b63-9dab-ac8703dc0feb"},"outputs":[],"source":"# That went good. There are 18 unique titles.\nfull[\"Title\"].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19c8c2ec-02e2-40ce-9d1b-35237d8a15e0"},"outputs":[],"source":"# Let's check which titles that are missing age data\nfull[np.isnan(full[\"Age\"])].Title.unique()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e56209a6-3d6e-486e-8c5f-bf0879361f12"},"source":"OK. There are only 6 types of titles that is missing age data. The thing that comes to attraction is that \nthere is both a **Miss** and a **Ms** title. Without much considerations, I'm joining the **Ms** titled\nwith **Miss** titled. Then it's only 5 titles to fill with age."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f465b873-8e21-4ee1-a1ef-183c949cdb9a"},"outputs":[],"source":"# Hmmm what's the difference of Miss and Ms?\nfull[full[\"Title\"]==\"Ms\"]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1030423-ce6a-4b34-b7ea-edf8955f87f4"},"outputs":[],"source":"# Let's just set the two Ms to Miss. Can't be that bad.\nfor df in frames:\n    df.loc[df[\"Title\"]==\"Ms\", \"Title\"] = \"Miss\""},{"cell_type":"markdown","metadata":{"_cell_guid":"3048fa0a-8c4f-48cc-95b6-454a722c410f"},"source":"Yes! Then we are ready for the real filling of all missing ages."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8419b07d-77bb-4efc-a200-7d0a7e9db634"},"outputs":[],"source":"# So here is the main juice. Assign the missing age to the median age with the given title.\nfor t in full[np.isnan(full[\"Age\"])].Title.unique():\n    for df in frames:\n        df.loc[(df[\"Title\"]==t) & np.isnan(df[\"Age\"]), \"Age\" ] = full[full[\"Title\"]==t].Age.median()"},{"cell_type":"markdown","metadata":{"_cell_guid":"5233597f-8653-40a1-ab0c-b7b5ecdbb2b7"},"source":"### Filling out the missing cabin\nThere are so many missing cabins in the dataset that we will not even try to fill in the missing elements.\nWe will however try to extract some information from this later in this notebook."},{"cell_type":"markdown","metadata":{"_cell_guid":"e8ea5990-e264-4996-bcb2-b515bc945b7b"},"source":"## Feature engineering\nWe do indeed already have some features, but I think we should try to extract some more. We have the\npassenger class, the sex, the age, #siblings_and_spouses, and #childern_and_parents, the embarkment port\nand the fare. We've also extracted a *Title* from the name column. However, I think we can gain some more.\nLet's consider the cabin first.\n### Engineering a cabin feature\nImportant to note: The way to survive is to get onboard a lifeboat. At the RMS Titanic there were\n20 lifeboats, however only 18 were used. There were less capacity of the lifeboats than the number of\npassengers and crew onboard. Numbers from wikipedia says there was a capacity of 1178 passengers in the\nlifeboats. There were 2224 on board (crew included). Since there was not enough capacity of the lifeboats\nto evacuate everyone, the \"Women and children first\" policy were applied. \n\n#### A side note on the low capacity of the lifeboats\nWe may think today that it was really strange to have less capacity of lifeboats than number of\npassengers and crew. However, the number of lifeboats was well within the maritime laws and regulations\nof the time. The next question that then comes up is: Why was the maritime regulation not requiring\nany liner to have lifeboat capacity for every passenger and crew member? The answer to this is that\nthere never were any concern that all passengers had to be evacuated over a relatively short period of\ntime. A ship in distress would probably stay afloat for many hours. First of all there was a lot of\nmaritime traffic of those days, and a liner in distress would always be able to call for assistance\nfrom a nearby vessel and evacuate the personnel to that vessel. The vessels were equipped with\nwireless telegraphs. That was the common philosophy of the time, and that was the reason why\nthis was not considered a problem. After all, Titanc was the ship that could not sink. It was called\nthe ship that could not sink due to the double bottom and the watertight bulkheads. However the\nbulkheads was not sealed with a ceiling, so when each bulkhead was filled with water, the water\nsimply flooded over to the next bulkhead. She was hence not so unsinkable after all.\n\n#### A feature for the cabin side\nThis is indeed a bit interesting. The \"Women and children first\" policy was indeed enforced differently on\nthe port and starboard side of the ship, so the side of the cabin could be a useful predictor in our\nanalysis. Cabin numbers ending with an odd number indicates that the cabin was on starboard side, while\ncabins ending on an even number were located on the port side. Let's create a feature called\n**CabinSide** that takes the values **unknown**, **starboard** or **port**."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"729ff2da-9098-4032-8a1f-c5e27177c105"},"outputs":[],"source":"# Let's look at the cabin a bit. This might be important. The \"Women and Children\" policy was enforced differently on\n# starboard and port side. Odd numbered cabins are starboard side, and even numbers are port side.\nfor df in [titanic, test]:\n    df[\"CabinSide\"] = \"Unknown\"\n    df.loc[pd.notnull(df[\"Cabin\"]) & df[\"Cabin\"].str[-1].isin([\"1\", \"3\", \"5\", \"7\", \"9\"]),\"CabinSide\"] = \"Starboard\"\n    df.loc[pd.notnull(df[\"Cabin\"]) & df[\"Cabin\"].str[-1].isin([\"0\", \"2\", \"4\", \"6\", \"8\"]),\"CabinSide\"] = \"Port\""},{"cell_type":"markdown","metadata":{"_cell_guid":"78535e9e-3959-48df-a891-5f66bdcbe65a"},"source":"We need some cleanup. The Ryersons had four cabins, three on starboard and one on port. It is natural\nto set them all on starboard, as they probably gathered. They traveled with ticket **PC 17608**, so\nwe use that to index the rows of Ryersons & co."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd7d82db-c408-4104-955d-7ff3bd805714"},"outputs":[],"source":"for df in [titanic, test]:\n    df.loc[df[\"Ticket\"]==\"PC 17608\", \"CabinSide\"] = \"Starboard\""},{"cell_type":"markdown","metadata":{"_cell_guid":"e7f6f6f1-c027-45fb-84b7-e937e50153e0"},"source":"It is also natural to assume that Bowen, Miss. Grace Scott was in cabin B68. According to sources\nshe was the maid for the Ryersons and the deck plan drawing shows this cabin as a maids/servant cabin."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec7fbd33-58c9-4213-a2e8-c2bdff5d00ea"},"outputs":[],"source":"test.loc[test[\"Name\"].str.contains(\"Bowen,\"),\"Cabin\"] = \"B68\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc4b5918-7f08-4fb3-9eea-861962d9b5b4"},"outputs":[],"source":"titanic.CabinSide.value_counts()"},{"cell_type":"markdown","metadata":{"_cell_guid":"956caad2-b876-4a4c-98fa-d38a02f8fa94"},"source":"#### A feature for the cabin deck\nLower deck cabins where flooded with water before the higher level deck. Is it natural to think that\npassengers on low decks gathered to the lifeboats earlier than the passengers at the higher decks?\nAt least I will try out a feature based on the deck. The deck is labeld as the first letter in the\ncabin number. A-G, where A is the highest and G is the lowest."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b027b5eb-0223-43ac-84ef-5370e8ac6bb9"},"outputs":[],"source":"# Maybe the Deck is important? who knows?\nfor df in [titanic, test]:\n    df[\"Deck\"] = \"Unknown\"\n    df.loc[pd.notnull(df[\"Cabin\"]), \"Deck\"] = df[\"Cabin\"].str[0]"},{"cell_type":"markdown","metadata":{"_cell_guid":"0aa73503-574d-46d7-b5bf-8640be3da3f3"},"source":"We need some cleanup as some cabins are numbered \"F Gxx\". I am not sure what this means, but\nI guess it means \"Fore\" deck \"G\" cabin \"xx\". I have asked this on the forum, but I have got no replies\nyet."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"619a44dc-2a53-44e7-9030-86dab232c011"},"outputs":[],"source":"titanic.loc[titanic.Cabin.str.len() == 5,:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1e227fa-2a4d-4fff-9bc5-bab3e5540b27"},"outputs":[],"source":"for df in [titanic, test]:\n    df.loc[pd.notnull(df[\"Cabin\"]) & (df.Cabin.str.len() == 5), \"Deck\"] = df[\"Cabin\"].str[2]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"190160f9-e157-4460-816d-af57e65331eb"},"outputs":[],"source":"test.loc[test.Cabin.str.len() == 5,:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"9aefe948-9a01-43f3-9f16-3935198ae9a2"},"source":"Yes! That looks better."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"649400eb-ed7c-428f-8e4b-6771f5595f0d"},"outputs":[],"source":"# Test if there is some strange decks as well. Deck T ??\ntitanic.Deck.value_counts()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7b4140bc-561c-4172-b25c-c7295ca286d0"},"source":"Yes, there is a deck T? What is that?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"051cc743-118e-4180-bbc8-51380dbda4d6"},"outputs":[],"source":"titanic.loc[titanic[\"Deck\"] == 'T',:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"0be45ff8-9c44-477e-b724-1811ba6229b2"},"source":"I have no idea what cabin T is supposed to mean, so I set this to unknown. (I've also checked test set, but\nthere is no passenger with cabin T in the test part.)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74f38c04-3cec-4f10-9f40-84222ca88d5b"},"outputs":[],"source":"titanic.loc[titanic[\"Deck\"] == 'T',\"Deck\"] = \"Unknown\""},{"cell_type":"markdown","metadata":{"_cell_guid":"f5878d2e-48c1-4600-9e61-4209a63354d1"},"source":"### A family size feature.\nI really don't believe that this gains better classification than the *SibSp* and *ParCh* features\nseparated, since they are linear correlated. I see that a lot of other scripts has this featere, so\nI'm adding this for the fun of it."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79d81923-9f9d-44b3-bb67-49b76b4ce453"},"outputs":[],"source":"# Let's define another feature. FamilySize = Parch + SibSp + 1\nfor df in frames:\n    df[\"FamilySize\"] = df.Parch + df.SibSp + 1"},{"cell_type":"markdown","metadata":{"_cell_guid":"400ef588-21c9-4901-90db-62d870530cc7"},"source":"(Let me continue. I've had a beautiful day with my family at Oscarsborg yesterday, and Friday we also\nfantastic day fishing. We caught three atlantic mackerel and had them for dinner.) \n### Ticket group size feature\nThe ticket looks like they were sold in groups. Can the size of the ticket group be used as an indicator?\nThat will catch other relations than the family relations on ParCh and SibSp, like valet, servant, maid etc.\nThis may or may not improve the predictions. Such a feature will of course be strongly related to\nfamily size, and may therefore not improve the predictions as much as I hope. Also, there are some tickets\nthat are issues with sequential numbers even for groups traveling together.\n\nThere is possibly a simple way to do this in Pandas, but as a long time Python hacker, I will do this the\nPython way. I will create a python dictionary with the ticket number as the key, and the number of\ntickets with that key."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1776833-48d5-435d-8219-37bdfa599c22"},"outputs":[],"source":"# Ticket group size\n# first we make a dictionary\nticket_dict = {}\nfor t in full.Ticket.unique():\n    ticket_dict[t] = 0\nfor t in full.Ticket:\n    ticket_dict[t] += 1\n\n# Then we apply it to the dataframes\nfor df in frames:\n    df[\"TicketGroupSize\"] = df[\"Ticket\"].apply( lambda x: ticket_dict[x])"},{"cell_type":"markdown","metadata":{"_cell_guid":"bdcf29a6-6334-4191-9f6f-96051ac9fcf2"},"source":"### Ticket group survivors feature\nHere is my last predictor for today. For each ticket group, we will count the other survivors in that\ngroup. If there is a *everybody or nobody* connection in the traveling group, this may be a good predictor.\nAlso, a non-linear classifier may also be able to find relations like *everybody except the adult male*\nconnections in the data. That is why I hope this feature can gain something.\n\nI will reuse and overwrite the same dictionary and use the same Python method to add this feature. Again,\nthose who know Pandas well can probably do this simpler. I'm a Pandas beginner myself. \n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1fc4073-9795-44a7-90f6-c5254c41bf66"},"outputs":[],"source":"for t in full.Ticket.unique():\n    ticket_dict[t] = 0\nfor row in full.iterrows():\n    t = row[1][\"Ticket\"]\n    if row[1][\"Survived\"] > 0.1:\n        ticket_dict[t] += 1\n        \n# Then we apply this to the dataframes\nfor df in [titanic, test]:\n    df[\"TicketGroupSurvivors\"] = df[\"Ticket\"].apply( lambda x: ticket_dict[x])"},{"cell_type":"markdown","metadata":{"_cell_guid":"698fe901-0775-40e1-ad89-e120e028e984"},"source":"I really hope that this feature can gain something, however it may be biasing a prediction towards\ndeath to singleton traveling passengers. A singleton passenger (in this case a passenger with a unique\nticket number) will have either 0 ot 1 in this feature. The passenger will always have 0 as \nTicketGroupSurvivors in the test set, and a classifier will train to predicting this as a non-survivor,\nThis feature can therefore may be really bad, rather than smart. I don't know, I'll try it out.\n\n**Update:** After trying a few classifiers, I realize that this really happens. The remedy could be to subtract one form TicketGroupSurvivors where a singleton survived.\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99ae9b50-6adf-035c-abea-1fa3009eb9ac"},"outputs":[],"source":"# Here is the problem:\ntitanic.loc[titanic[\"TicketGroupSize\"] == 1, [\"Survived\", \"TicketGroupSurvivors\"]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c2aa071-caa1-f251-695a-ae0d6291ab22"},"outputs":[],"source":"# Here is the remedy:\ntitanic.loc[titanic[\"TicketGroupSize\"] == 1, [\"Survived\", \"TicketGroupSurvivors\"]] = 0"},{"cell_type":"markdown","metadata":{"_cell_guid":"d612eb16-5ab0-aeaa-5d6e-01428278f42a"},"source":"### Other features\nAt the top of my head I can think of a few other features to add. First of all, if the TicketGroupSize and\nthe TicketGroupSurvivors features are fruitful, we might add a two similar features based on the surname of the passengers.\n\nAnother feature to consider from the cabin column is to see if the cabin is closer to the bow or the\nstern of the ship. From the schematic plan on [wikipedia](https://en.wikipedia.org/wiki/Lifeboats_of_the_RMS_Titanic),\nwe see that for each side there is four lifeboats by the bow and five by the stern. Also the ship sank\nslowly for the first hour with the bow first, so where the cabin was (by the bow or stern) may be a useful\npredictor. I'll see if I can add this later."},{"cell_type":"markdown","metadata":{"_cell_guid":"f6720ec5-52d7-4e04-831f-cd5551a9116e"},"source":"## Feature preparation\nTo be able to use the features, we have to convert them into numeric values. Some of our features are\nalready numerical. It is often a good idea to normalize those features. Some of the features\nare categorical. For categorical features, we simply make indicator (dummy) features.\n\nFor noramlization, I will create a helper function. (I guess scikit learn already has one, but I'm not\nfamiliar with that one yet.) We will normalize by the function $$\\frac{X - \\mu}{\\sigma}$$ The\nimplementation goes like this:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c81b81f5-09c3-4d0e-856c-3456db9f9ec5"},"outputs":[],"source":"# Normalizer\ndef normalize(feat):\n    mean = full[feat].mean()\n    stdv = full[feat].std()\n    for df in [titanic,test]:\n        df[feat + \"_norm\"] = (df[feat] - mean) / stdv"},{"cell_type":"markdown","metadata":{"_cell_guid":"f99e2f47-44d6-4d79-b0da-95bb7bcf73ea"},"source":"Note that we use the full set (combined titanic and test) to estimate the mean and standard deviation.\n### Features to normalize\nSome features should be normalized, others not. Let's discuss.\n#### Age\nAge is already a numeric value. This makes more sense to normalize, at the values are much higher\nthan other numeric features.\n**(Note to myself: Check out sklearn preprocessing\n#### SibSp, ParCh and Family size.\nJust plain normalize all of these. An alternative to be to group then into categories, but let's wait\nwith that.\n#### Fare\nThis is interesting. Is the fare of the ticket based on the ticket group size? Maybe the fare\nshould be divided by the size of the ticket group size and then normalized? Maybe even this should\nbe adjusted and normalized to the fare based on the given class. Let's investigate that later,\nand just do a plain normalization for now.\n#### Passenger Class (Pclass)\nThis is indeed a numeric value, but we would rather consider this categorical feature than numerical.\nLet's *not* normalize this feature.\n#### TicketGroupSize\nJust normalize this."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff84f89e-3a37-4d31-9ba2-57bff47a1c9c"},"outputs":[],"source":"# Age, SibSp, ParCh, FamilySize, Fare and TicketGroupSize. Those are the ones.\n[normalize(x) for x in [\"Age\", \"SibSp\", \"Parch\", \"FamilySize\", \"Fare\", \"TicketGroupSize\"]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc5b8e36-4475-4293-8f3b-5ff25c6f70d6"},"outputs":[],"source":"titanic.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"dcb03cbf-20be-474d-99a6-e9514736af98"},"source":"Looks like it works!\n\n### Categorical features. \n#### Sex\nLet's begin with **Sex** since it's the first thing that comes to my mind (no pun intended). Sex is a\ncategorical value, but it can only take two different values: **female** or **male**. Note that is\nshould not be necessary to have two features, with one **Sex_male** and another **Sex_female**, as\nthat will just make to directly linear correlated values. This actually applies to all categorical\nfeatures. I will therefore drop the most populated category. For sex, the baseline category will\nbe male, and hence sex_male will be dropped.\n#### Passenger class (Pclass)\nI will we can treat this as categorical data. I think I'll handle this as categorical data. I will drop\nPclass_3 as the baseline category.\n#### Embarkment port\nLet's just make a categorical inputs for each port. I'll drop Embarked_S as baseline.\n#### CabinSide\nPlain categorical. Starboard and Port, I will drop CabinSide_unknown as the baseline case.\n#### CabinDeck\nI will also do categories on the deck even though a plain numerical value could be considered.\nDeck_Unknown will be dropped as baseline.\n#### Title\nMagan have already showed us that title is an important feature. However we need to reduce number of\ntitles. Some of the titles are rare and should not have their own category. I suggest these title\ncategories: **Mr**, **Mrs**, **Miss**, **Master**, **Rev**, **Officer**, **Royal**."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78559040-4259-45e3-bd50-ac0b35d2d527"},"outputs":[],"source":"full[\"Title\"].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b05809b0-a90c-4b99-a371-f1a9e120b557"},"outputs":[],"source":"# These can be discussed, of course.\ntitledict = {\"Dr\"   : \"Mr\",\n             \"Col\"  : \"Officer\",\n             \"Mlle\" : \"Miss\",\n             \"Major\": \"Officer\",\n             \"Lady\" : \"Royal\",\n             \"Dona\" : \"Royal\",\n             \"Don\"  : \"Royal\",\n             \"Mme\"  : \"Mrs\",\n             \"the Countess\": \"Royal\",\n             \"Jonkheer\": \"Royal\",\n             \"Capt\" : \"Officer\",\n             \"Sir\"  : \"Mr\"\n             }\n#There is probably a pandas way to do this, however I do it the python way today.\nfor df in frames:\n    for key,val in titledict.items():\n        df.loc[df[\"Title\"]==key, \"Title\"] = val"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d10828f-4db1-42f4-a803-d2c8c2eb78a7"},"outputs":[],"source":"full[\"Title\"].value_counts()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ecd614c5-e727-459e-8a45-3699b973357c"},"source":"Then we have only seven titles. Let's create the indicator variables."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2e96a54-e0cf-4005-8815-c2ff9b9a9ce3"},"outputs":[],"source":"category_list = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\", \"CabinSide\", \"Deck\"]\ntitanic = pd.get_dummies(titanic, columns=category_list)\ntest = pd.get_dummies(test, columns=category_list)"},{"cell_type":"markdown","metadata":{"_cell_guid":"075dd861-ddbc-4bb2-9820-6c4c40c91915"},"source":"#### TicketGroupSurvivors\nMaybe this can be divided by the size of the group?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f04bbd33-b825-472a-a8d8-a1886941864e"},"outputs":[],"source":"for df in [titanic, test]:\n    df[\"TGS_norm\"] = df[\"TicketGroupSurvivors\"] / df[\"TicketGroupSize\"]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3a009976-cbce-43a7-8d9d-f69f226f38ff"},"outputs":[],"source":"titanic.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a768ea30-b452-48e6-a936-f2d1dafb46d5"},"outputs":[],"source":"test.columns"},{"cell_type":"markdown","metadata":{"_cell_guid":"e966a880-c209-4ddb-a58e-a21e82b2820c"},"source":"Enough features for today! Instead of dropping the unwanted columns that will not be used in the\nclassifier, I will rather make a new dataframe for training and testing."},{"cell_type":"markdown","metadata":{"_cell_guid":"a0816ce4-482f-45b6-8ae1-5bd4bdfa3e7c"},"source":"## Evaluating classifiers\nLet's try a few different classifier and use cross validation to find the one we like the most. I suggest\nwe try Naive Bayes, KNN, Logistic Regression and Random Forest. It would be Ã¼bercool if we also could try\na simple neural network to classify, but let's try the other first.\n\n### The dead simple classifier\nBefore we do anything at all, we have to just make a dead simple classifier. I call this dead simple,\nbecause it predicts everyone dead. It can't be much simpler than that. Such preductor will of course\nmake the wrong prediction for every passenger that actually survived. It is nice to have such a reference\nsubmission to know if we are doing good. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0c0c744-2079-4cea-8407-e5a114e9fa0c"},"outputs":[],"source":"# What should we expect if a predictor predicting all dead.\n1 - titanic.Survived.mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b051ded0-a8cf-4020-9587-aebcb36da3a8"},"outputs":[],"source":"# Let's see the real.\nds_submission = pd.DataFrame(test[\"PassengerId\"])\nds_submission[\"Survived\"] = 0  # All dead"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"41e32959-813f-4386-8f99-d4af558935ac"},"outputs":[],"source":"# This is actually the simplest predictor I can imagine so for the fun of it, let's submit this\n# and see how it scores\nds_submission.to_csv(\"all_dead.csv\", index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"4a5b9124-f19f-4039-9cfc-cea4ab6ec1cd"},"source":"Submission says: *Your submission scored **0.62679**, which is not an improvement of your best score.* Keep trying!\nIt's actuallly better than the **0.616** estimated.\n\nWe can actually use this result to say how many survivors there should be in the test set. That can be\nuseful information in the fine tuning of the model."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"64f528b5-1b8c-4efe-b984-b090f4c63453"},"outputs":[],"source":"round(len(test) * 0.62679)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ffac1589-4cbe-4215-bfa7-321d3984216f"},"source":"So there should be about 262 dead passengers in the test set. We do not know which passengers are\ncreating the 0.62679 score, but at least we know the ballpark."},{"cell_type":"markdown","metadata":{"_cell_guid":"0517769c-5860-4995-8ffe-99effeea1161"},"source":"### Gaussian Naive Bayes\n(To be done later)\n### K Nearest Neighbors classifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ecc75304-25bd-4fb6-a5b7-1bfb1a5baaae"},"outputs":[],"source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9013b2d3-6cd2-4e83-b572-c241f55ce1f7"},"outputs":[],"source":"k_range = range(1, 31)\nparam_grid = dict(n_neighbors=list(k_range),weights = [\"uniform\", \"distance\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9306c44b-4ec5-49c7-8704-62f384e4b7f1"},"outputs":[],"source":"knn = KNeighborsClassifier(n_neighbors=5)\ngrid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6838bdf-704a-4064-bab1-e4261a3e3ad3"},"outputs":[],"source":"titanic.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c1a440d-6269-4842-8a8b-72be71740e89"},"outputs":[],"source":"features = ['Age_norm', 'SibSp_norm', 'Parch_norm',\n       'FamilySize_norm', 'Fare_norm', 'TicketGroupSize_norm', 'Pclass_1',\n       'Pclass_2', 'Sex_female', 'Embarked_C',\n       'Embarked_Q', 'Title_Master', 'Title_Miss', \n       'Title_Mrs', 'Title_Officer', 'Title_Rev', 'Title_Royal',\n       'CabinSide_Port', 'CabinSide_Starboard', 'Deck_A',\n       'Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G',\n       'TGS_norm']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14874388-f732-47c3-acb4-b561c7a07867"},"outputs":[],"source":"len(features)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e911d3e-f5b6-4cf2-9ab7-85e3f4dcb316"},"outputs":[],"source":"grid.fit(titanic[features], titanic.Survived)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"169ada64-16d6-4751-9fa0-e6f772978a56"},"outputs":[],"source":"grid.best_score_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3684e48-0e0d-4ccf-9f85-eda0bbc487dd"},"outputs":[],"source":"grid.best_params_"},{"cell_type":"markdown","metadata":{"_cell_guid":"43646bd4-7012-4e5b-aae5-7749526a5cf9"},"source":"No! 0.935 is way better than I expected. This is *too good*! I don't believe this. I believe that this is\na matter of the TGS_norm feature being highly correlated to survived in the train set. Let's try to submit\nthis and see and check this theory."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a5ca31c-0e77-4f2c-8fa0-962f34e2c71e"},"outputs":[],"source":"# rerun fit() with the best parameters with the entire set (no CV)\nknn = KNeighborsClassifier(n_neighbors=7, weights=\"distance\")\nknn.fit(titanic[features], titanic.Survived)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66601965-f36f-4d43-b8ed-21f5027777a9"},"outputs":[],"source":"knn_predictions_with_TGS = knn.predict(test[features])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78cc80a1-e15e-4f38-873b-8eeee549ca24"},"outputs":[],"source":"knn_predictions_with_TGS.sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cb7c59e7-b545-4809-9ac1-8bf336c274b1"},"source":"Only 102. Far from the 262 we estimated. Makes me believe the TGS theory is right. But let's submit\nanyway."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1fe574ec-6161-4256-80ba-f76ab4ccb43a"},"outputs":[],"source":"knn_submission1 = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": knn_predictions_with_TGS\n        })\nknn_submission1.to_csv(\"knn_predictions_with_TGS.csv\", index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b8e7e018-f8b8-4214-9b35-85c6db0035a1"},"source":"On the leaderboard this scores: 0.72727. Not really impressive and far far from the 0.934 we found\nin cross validation. If the TGS_norm feature is bad for the singleton passengers, let's try to\nredo the above steps w/o that feature. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9daea4b5-14b9-4195-b8b8-898a5ab2461f"},"outputs":[],"source":"knn = KNeighborsClassifier(n_neighbors=5)\n# Fit once more without TGS_norm\ngrid.fit(titanic[features[:-1]], titanic.Survived)\nprint(grid.best_score_ , grid.best_params_)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c25e0466-1255-4d98-8216-08a35735bf2e"},"source":"This number looks more like something I could believe. Let's try to submit this."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a306762f-39fa-40e9-a5e5-8a851693e131"},"outputs":[],"source":"# rerun fit() with the best parameters with the entire set (no CV)\nknn = KNeighborsClassifier(n_neighbors=8, weights='distance')\nknn.fit(titanic[features[:-1]], titanic.Survived)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5ae5d09e-34a7-43a4-9306-04be9530194e"},"outputs":[],"source":"knn_predictions_wo_TGS = knn.predict(test[features[:-1]])\nknn_predictions_wo_TGS.sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"07fc7354-7aec-434b-9d62-d399118b0a57"},"source":"Hmmmm... only 103.... that's still a bit off. Let's submit anyway."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06e69776-5e9b-4d1d-a35d-30616f4b6745"},"outputs":[],"source":"knn_submission2 = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": knn_predictions_wo_TGS\n        })\nknn_submission2.to_csv(\"knn_predictions_wo_TGS.csv\", index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"703ff9d5-54a5-4606-84a3-bd1e6293d90c"},"source":"Well ... 0.77990 (?). Not very impressive, but still an improvement. Can we improve from here?\n\nI wonder if the two submissions can be combined? We could either do a OR-operation of the two submissions, or we could check the ticket group size to see if we should use the one or the other. Let's try both these. First the OR-operation:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70a864f9-5ec7-d891-c3be-e04fce7213ad"},"outputs":[],"source":"knn_submission3 = pd.DataFrame({\n    \"PassengerId\": test[\"PassengerId\"],\n    \"Survived\": np.logical_or(knn_predictions_with_TGS, knn_predictions_wo_TGS).astype('int') \n})\nknn_submission3.to_csv(\"knn_predictions_or_TGS.csv\", index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"fb80ca3b-e6a1-b2fd-eee9-22c8285025ba"},"source":"*Your submission scored 0.76077*. Worse than the previous. Let's try the other strategy:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fccad81-5ffb-7c2e-7cf7-1c4bd7f4e2e9"},"outputs":[],"source":"df_tmp = pd.DataFrame({\n    \"PassengerId\": test[\"PassengerId\"],\n    \"TicketGroupSize\": test[\"TicketGroupSize\"],\n    \"s_with_tgs\": knn_predictions_with_TGS,\n    \"s_wo_tgs\": knn_predictions_wo_TGS\n})\ndf_tmp.loc[df_tmp.TicketGroupSize == 1, \"Survived\"] = df_tmp[\"s_wo_tgs\"]\ndf_tmp.loc[df_tmp.TicketGroupSize != 1, \"Survived\"] = df_tmp[\"s_with_tgs\"]\ndf_tmp.drop([\"TicketGroupSize\", \"s_with_tgs\", \"s_wo_tgs\"], axis=1, inplace=True)\ndf_tmp.to_csv(\"knn_predictions_specified_TGS.csv\", index=False, float_format='%.f')"},{"cell_type":"markdown","metadata":{"_cell_guid":"aa688b95-2b08-c5e4-e3f1-818db19fec3e"},"source":"Even worse! Yuck... I'll try something else then. I see a lot of submissions have success with RandomForest. Let me try that."},{"cell_type":"markdown","metadata":{"_cell_guid":"a060ccee-285b-45c3-a524-2af7c481d8a2"},"source":"### Random Forest classifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27bf5abb-9f3b-fc31-1881-65b76255eeb9"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab00133b-cb35-c39a-ae89-9dc9d315e5b0"},"outputs":[],"source":"n_range = range(10, 100, 10)\nparam_grid = dict(n_estimators=list(n_range),criterion = [\"gini\", \"entropy\"])\nrfc = RandomForestClassifier(n_estimators=20)\ngrid = GridSearchCV(rfc, param_grid, cv=10, scoring='accuracy')\ngrid.fit(titanic[features], titanic.Survived)\nprint(grid.best_score_ , grid.best_params_)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ab5c7fb0-bc43-2954-ecd6-c74d82a93541"},"source":"That took a really long time....."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"384138e9-3812-f214-a039-7123c2824686"},"outputs":[],"source":"rfc = RandomForestClassifier(n_estimators=60, criterion='entropy')\nrfc.fit(titanic[features], titanic.Survived)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8acc9fd-02d3-2f1f-0eef-67e4e2cf88aa"},"outputs":[],"source":"pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": rfc.predict(test[features])\n        }).to_csv(\"rfc_predictions.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"daeeaa8f-7809-6661-531c-cd9f79ef1ac7"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}