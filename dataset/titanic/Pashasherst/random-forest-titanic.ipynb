{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello Kaggle! It is my first Competition","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.impute import KNNImputer\nimport os\nimport re\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndef findall_len(string, pattern):\n    return len(pattern.findall(string))\n\ndata_train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndata_test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ndata_train","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data understanding\n\n\n## Histograms","metadata":{}},{"cell_type":"code","source":"#variables used\nhist_vars = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n#Pclass, Sex, Age, SibSp, Parch, Fare\nfig, ax = plt.subplots(len(hist_vars), 2, figsize=(20, 30))\nclasses = set(data_train['Survived'])\nfor i, class_ in enumerate(classes):\n    class_df = data_train.query('Survived == @class_')\n    for j, vars_ in enumerate(hist_vars):\n        ax[j][0].hist(class_df[vars_], alpha = 0.5,\n                      label = class_, bins = 25)\n        ax[j][1].hist(class_df[vars_], alpha = 0.5,\n                      label = class_, bins = 25,\n                      log = True)\n        ax[j][0].set_xlabel(vars_)\n        ax[j][0].legend()\n        ax[j][1].set_xlabel(vars_ + '_log')\n        ax[j][1].legend()\n#Embarked   \nfig, ax = plt.subplots(2, 2, figsize=(20, 15))\nclasses = set(data_train['Survived'])\nfor i, class_ in enumerate(classes):\n    class_df = data_train.query('Survived == @class_')\n    \n    cut = class_df.groupby('Embarked').count()\n    ax[0][0].bar(x = cut.index, height = cut['PassengerId'],\n                     alpha = 0.5, label = class_)\n    ax[0][1].bar(x = cut.index, height = cut['PassengerId'],\n                     alpha = 0.5, label = class_, log = True)\n    ax[0][0].legend()\n    ax[0][0].set_xlabel('Embarked')\n    ax[0][1].legend()\n    ax[0][1].set_xlabel('Embarked_log')\n#Cabin   \ncut = data_train['Cabin'].fillna('').str.replace(r'[0-9]+', '', regex = True)\nfor i, class_ in enumerate(classes):\n    ax[1][1].hist(cut[data_train['Survived'] == class_],\n                  alpha = 0.5, log = True, label = class_)\n    ax[1][0].hist(cut[data_train['Survived'] == class_],\n                  alpha = 0.5, label = class_)\n    ax[1][1].set_xlabel('Cabin_log')\n    ax[1][1].legend()\n    ax[1][0].set_xlabel('Cabin')\n    ax[1][0].legend()\n#Mr, Miss, Mrs and скобками \"()\" \nfilters = {'Mr':re.compile(r\"Mr\\.\"),\n           'Miss':re.compile(r\"Miss\\.\"),\n           'Mrs':re.compile(r\"Mrs\\.\"),\n           'quote':re.compile(r'[\"(<{[|].*[\")>}]|]')}\nfig, ax = plt.subplots(len(filters), 2, figsize=(20, 30))\nclasses = data_train['Survived'].unique()\nfor class_ in classes:\n    text_class = data_train.query('Survived == @class_')['Name']\n    for i, dict_ in enumerate(filters.items()):\n        hist_ = text_class.apply(findall_len, args = [dict_[1]])\n        ax[i][1].hist(hist_, label = class_, alpha = 0.5, log = True)\n        ax[i][1].set_xlabel(str(dict_[0]) + '_log')\n        ax[i][1].legend()\n        ax[i][0].hist(hist_, label = class_, alpha = 0.5, log = False)\n        ax[i][0].set_xlabel(str(dict_[0]))\n        ax[i][0].legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Nans maps","metadata":{}},{"cell_type":"code","source":"fig, ax =plt.subplots(1, 2, figsize=(20, 5))\nsns.heatmap(data_train.isna(), ax=ax[0])\nsns.heatmap(data_test.isna(), ax=ax[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions\n\n1. **Pclass.** Most of the third-class passengers were dead. Only a third survived;\n2. **Sex**. Men died more than women did;\n3. **Age**. People aged 15 to 50 died more than others .Children were more likely to be saved;\n4. **SibSp**. People with more than 3 relatives were more likely to die;\n5. **Parch**. Mostly People who had more than 3 parents or children died more;\n6. **Fare**. People with tickets which prices were higher than 100 survived more than the others;\n7. **Embarked**. More than half of the S people died;\n8. **Cabin**. It seems that people from some cabins survived more often;\n8. **Mr, Miss, Mrs**. Definitely important;\n9. **Brackets**. A dubious sign, but it seems that with brackets in the name, many more people survived. \n\nRemoved:\n1. The **Cabin** had a lot of omissions and will be removed;\n2. The **Ticket** is unique and does not represent any information;\n3. It was decided not to take the presence of **brackets** in the name as a feature..\n\nThe remaining features will be included in the model.","metadata":{}},{"cell_type":"markdown","source":"# Data definition and filling a NaNs\n\n## One hot encoding","metadata":{}},{"cell_type":"code","source":"#variables used in modeling\nvars_ = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\nX_train = pd.get_dummies(data_train[vars_], columns = ['Sex', 'Embarked'])\ny_train = data_train['Survived']\nX_test = pd.get_dummies(data_test[vars_], columns = ['Sex', 'Embarked'])\nX_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#add miss, mr, mrs\nvectorizer = CountVectorizer(binary = True, max_features = 3)\ntext_train = vectorizer.fit_transform(data_train['Name'])\ntext_test = vectorizer.transform(data_test['Name'])\nprint(vectorizer.get_feature_names())\ntext_train.toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filling a NaNs","metadata":{}},{"cell_type":"code","source":"#merge data\nX_train = pd.concat([X_train, pd.DataFrame(text_train.toarray())]\n                    , axis = 1, ignore_index = True)\nX_test = pd.concat([X_test, pd.DataFrame(text_test.toarray())],\n                   axis = 1, ignore_index = True)\n#filling in the nans with the nearest neighbor\nimputer = KNNImputer(n_neighbors=5)\nX_train = imputer.fit_transform(X_train)\nX_test = imputer.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run model\nmodel = RandomForestClassifier(n_estimators = 10, random_state = 0)\ngrid = GridSearchCV(estimator = model, param_grid = {'max_depth': range(2, 6)}, cv = 10)\ngrid.fit(X_train, y_train)\n\npredict = grid.predict(X_test)\noutput = pd.DataFrame({'PassengerId': data_test.PassengerId, 'Survived': predict})\noutput = output.astype({'Survived': 'int32'})\noutput.to_csv('pashasherst_submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thank you for watching","metadata":{}}]}