{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic (End To End ML Workflow)"},{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"**Titanic: Machine Learning from Disaster** is one of the best Kaggle competitions for improving data science skills, especially, feature engineering skills. The Titanic dataset is a pretty good choice for beginners who want to improve data science skills.\n\nIn this project, I will deal with the end-to-end data science cycle. And this project will include the below sections.\n\n### Table of Contents:\n\n* 1. Preprocessing the data\n    * 1.1 Variable Explanations\n    * 1.2 Importing Libraries\n    * 1.3 Getting Data\n    * 1.4 Overview of The Data\n    \n* 2. Exploratory Data Analaysis\n    * 2.1 Missing Values\n        * 2.1.1 Age \n        * 2.1.2 Embarked\n        * 2.1.3 Cabin\n        * 2.1.4 Fare\n    * 2.2 Outliers    \n    * 2.3 Analyzing Target Variable\n    * 2.4 Analyzing Features\n        * 2.4.1 Categorical Features\n        * 2.4.2 Continuous Features\n    * 2.4 Exploring Correlations\n        \n* 3. Feature Engieering\n    * 3.1 Binning Continuous Features\n    * 3.2 Creating New Features\n    * 3.3 Feature Selecting\n    * 3.4 Feature Scaling(Continuous Variables)\n    * 3.5 Feature Transformation (Categoric Variables)\n    \n* 4. Model Selecting And Model Tuning\n    * 4.1 Model Training\n    * 4.2 Model Tuning\n\n* 5. Making a Submission"},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Variable Explanations\n\nFirst of all we need to get some information about data.\n \n\n\n * **PassengerId:**  Unique Id for each passenger (it doesn't have any effect on target)\n \n    \n * **Survived(categorical):** Survival (0 : No, 1 : Yes) (*)\n \n \n * **Pclass(categorical-ordinal) :**\tPassenger class (1 : 1st, 2 : 2nd, 3 : 3rd)\n \n \n * **Name:** Passenger name\n \n \n * **Sex(categorical) :** Passenger sex\n \n \n * **Age:** Passenger age\n \n \n * **SibSp:** Sibling - Spouse (**)\t\n \n \n * **Parch:** Parent - Child (***)\n \n \n * **Ticket:** Ticket number\n \n \n * **Fare:** Passenger fare\n \n \n * **Cabin:** Cabin number\n \n \n * **Embarked(categorical):** Port of Embarkation (C \n : Cherbourg, Q : Queenstown, S : Southampton)\n \n\n(*) 'Survived 'is the target variable we are trying to predict. So test data doesn't have 'Survived' column.\n\n\n(**) sibsp: The dataset defines family relations in this way...\n\n           Sibling = brother, sister, stepbrother, stepsister\n\n           Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n\n(***) parch: The dataset defines family relations in this way...\n\n            Parent = mother, father\n\n            Child = daughter, son, stepdaughter, stepson\n\n            ! Some children travelled only with a nanny, therefore parch=0 for them."},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data processing\nimport numpy as np\nimport pandas as pd \n\n# data visualization\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n# Algorithms\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\n\n# Model Selection\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler,minmax_scale\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 Getting Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading data\ntrain = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train.copy()\ntest_df = test.copy()\ndf = train_df.append(test_df,sort=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.4 Overview of The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('train dataset has ' + str(train_df.shape[0]) + ' observations ' + str(train_df.shape[1])+ ' variables.')\nprint('test dataset has ' + str(test_df.shape[0]) + ' observations ' + str(test_df.shape[1])+ ' variables.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When I look at the statistical summary of the data, I notice a few things :\n* Approximately 38% of the passengers survived. \n* It looks like Fare variable contains outlier observations.\n* The majority of passengers travel alone.\n* The majority of passengers are less than 40 years old\n    \nThese are the things I understand when I first look at the data. I will review the data in more detail later. "},{"metadata":{},"cell_type":"markdown","source":"## 2. Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def explore_missing_values(df) :\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total,percent], axis=1, keys=['Total','Percent'])\n    sns.barplot(x=missing_data.index,y=missing_data['Percent'])\n    plt.xlabel('Features', fontsize=15)\n    plt.ylabel('Percent of Missing Values')\n    plt.title('PERCENT MISSING DATA BY FEATURE')\n    plt.xticks(rotation='75')\n    plt.show()\n    print(missing_data.head(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explore_missing_values(train_df)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"explore_missing_values(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of missing values in the Age, Embarked and Fare columns is relatively low compared to the total number of observations. Therefore, missing values in those columns can simply fill with descriptive statistics measurements.But, it is not the right approach for the 'Cabin' column that includes approximately %80 missing values. "},{"metadata":{},"cell_type":"markdown","source":"#### 2.1.1 Age\n\nI will create Title feature for imputing Age columns, but I won't use that feature in the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_Title(df):\n    titles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        \"Capt\":        \"Rare\",\n        \"Col\":         \"Rare\",\n        \"Major\":       \"Rare\",\n        \"Dr\":          \"Rare\",\n        \"Rev\":         \"Rare\",\n        \"Jonkheer\":    \"Rare\",\n        \"Don\":         \"Rare\",\n        \"Sir\" :        \"Rare\",\n        \"Countess\":    \"Rare\",\n        \"Dona\":        \"Rare\",\n        \"Lady\" :       \"Rare\"\n    }\n    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    df[\"Title\"] = extracted_titles.map(titles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_Title(train_df)\ncreate_Title(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby('Title')['Age'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['Age'].abs().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby(['Title','Pclass'])['Age'].median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pclass and Age have high correlation so decided to group the data by Title and Pclass and fill the Age column with the median of each group."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Imputing 'Age' features\n\ntrain_df[\"Age\"] =train_df.groupby(['Title','Pclass'])[\"Age\"].apply(lambda x : x.fillna(x.median()))\ntest_df[\"Age\"] = test_df.groupby(['Title','Pclass'])[\"Age\"].apply(lambda x : x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.1.2 Embarked"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df['Embarked'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When I googled that names I learned that they boarded the Titanic in from Southampton. I will fill missing values in 'Embarked' with 'S' representing 'Southampton'.\n\nhttps://www.encyclopedia-titanica.org/titanic-survivor/martha-evelyn-stone.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imputing 'Embarked' features\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.1.3 Cabin"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df['Cabin'].isnull()].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although the 'Cabin' feature has too much missing value, for now, I won't drop the column and I will fill them with 'U0'  representing that they are unknown,  after then I will try to extract useful information from the 'Cabin' column."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imputing 'Cabin' features\ntrain_df[\"Cabin\"] = train_df[\"Cabin\"].fillna(\"S\")\ntest_df[\"Cabin\"] = test_df[\"Cabin\"].fillna(\"S\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.1.4 Fare"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['Fare'].abs().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[test_df['Fare'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[test_df['Ticket']=='3701']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imputing 'Fare' features\ntest_df[\"Fare\"] = test_df.groupby(['Pclass'])[\"Fare\"].apply(lambda x : x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explore_missing_values(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explore_missing_values(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Outliers"},{"metadata":{},"cell_type":"markdown","source":"### Fare"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=train_df['Fare']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = train_df['Fare'].quantile(0.05)\nQ3 = train_df['Fare'].quantile(0.95)\nIQR = Q3-Q1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_border_fare = Q3+1.5*IQR\ntop_border_fare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[train_df['Fare'] > top_border_fare,'Fare'] = top_border_fare\ntest_df.loc[test_df['Fare'] > top_border_fare,'Fare'] = top_border_fare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=train_df['Fare']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## 2.3 Exploring Target Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Survived'].describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Survived',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4 Analyzing Features "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = ['Pclass','Sex','SibSp','Parch','Embarked']\ncontinuous_features =['Age','Fare']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4.1 Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_categorical_columns(df,col_list,hue='Survived'):\n    for col in col_list:\n        # hue='Survived'\n        sns.countplot(x=col,data=df,hue=hue)\n        plt.show()\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_categorical_columns(train_df, categorical_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  2.4.2 Continuous Features "},{"metadata":{"trusted":true},"cell_type":"code","source":"def visuzalize_continuous_columns(df,col_list):\n    for col in col_list:\n        sns.distplot(df[col])\n        plt.show()\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" visuzalize_continuous_columns(train_df, continuous_features )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.5 Exploring Correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_df.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train_df.corr(), annot = True, fmt='.1g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['Survived'].abs().sort_values().abs().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Binning Continuous Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Binning 'Age' column\ntrain_df['AgeBinCode'] = LabelEncoder().fit_transform(pd.qcut(train_df[\"Age\"],4))\ntest_df['AgeBinCode'] = LabelEncoder().fit_transform(pd.qcut(test_df[\"Age\"],4))\n\ntrain_df['AgeBinCode'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=train_df['AgeBinCode'], hue='Survived', data=train_df)\nplt.xticks(rotation='75')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Binning 'Fare' column\ntrain_df['FareBinCode'] = LabelEncoder().fit_transform(pd.qcut(train_df[\"Fare\"],5))\ntest_df['FareBinCode'] = LabelEncoder().fit_transform(pd.qcut(test_df[\"Fare\"],5))\n\ntrain_df['FareBinCode'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=train_df['FareBinCode'], hue='Survived', data=train_df)\nplt.xticks(rotation='75')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Creating New Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating FamilySize features\ntrain_df['FamilySize'] = train_df['Parch'] + train_df['SibSp']\ntest_df['FamilySize'] = test_df['Parch'] + test_df['SibSp']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=train_df['FamilySize'], hue='Survived', data=train_df)\nplt.xticks(rotation='75')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating LastName features\ntrain_df['LastName'] = train_df['Name'].apply(lambda x: str.split(x, \",\")[0])\ntest_df['LastName'] =test_df['Name'].apply(lambda x: str.split(x, \",\")[0]) \ndf['LastName'] = df['Name'].apply(lambda x: str.split(x, \",\")[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This feature is from Konstantin's kernel. FamilySurvival variable gathers together families and people with the same ticket and gives a ratio about group survival.\nhttps://www.kaggle.com/konstantinmasich/titanic-0-82-0-83"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating FamilySurvival features\n\nDEFAULT_SURVIVAL_VALUE = 0.5\n\ndf['FamilySurvival'] = DEFAULT_SURVIVAL_VALUE\n\nfor grp, grp_df in df[['Survived', 'Name', 'LastName', 'Fare', 'Ticket', 'PassengerId',\n                            'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['LastName', 'Fare']):\n    \n\n    if (len(grp_df) != 1):\n        # A Family group is found.\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 1\n            elif (smin == 0.0):\n                df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 0\n\nprint(\"Number of passengers with family survival information:\",\n      df.loc[df['FamilySurvival'] != 0.5].shape[0])\n\n\n\nfor _, grp_df in df.groupby('Ticket'):\n    if (len(grp_df) != 1):\n        for ind, row in grp_df.iterrows():\n            if (row['FamilySurvival'] == 0) | (row['FamilySurvival'] == 0.5):\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    df.loc[df['PassengerId'] == passID, 'FamilySurvival'] = 1\n                elif (smin == 0.0):\n                    df.loc[df['PassengerId'] == passID, 'FamilySurvival'] = 0\n\nprint(\"Number of passenger with family/group survival information: \"\n      + str(df[df['FamilySurvival'] != 0.5].shape[0]))\n\n\n\ntrain_df['FamilySurvival'] = df['FamilySurvival'][:891]\ntest_df['FamilySurvival'] = df['FamilySurvival'][891:]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  3.3 Feature Selecting"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train_df.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.corr()['Survived'].abs().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Pclass', 'Sex', 'AgeBinCode', 'FareBinCode', 'FamilySurvival','FamilySize']\ntarget = ['Survived']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train, X_test, y_train\n\nX_train = train_df[features]\ny_train = train_df[target]\nX_test = test_df[features]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.5 Feature Transformation (Categoric Variables)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dummies(df,categorical_features):\n    for column_name in categorical_features:\n        dummies = pd.get_dummies(df[column_name], prefix=column_name, drop_first=True)\n        df = pd.concat([df,dummies],axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['Sex'] = LabelEncoder().fit_transform(X_train['Sex'])\nX_test['Sex'] = LabelEncoder().fit_transform(X_test['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.4 Feature Scaling(Continuous Variables)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train =StandardScaler().fit_transform(X_train)\ny_train = train_df[target]\nX_test = StandardScaler().fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Modelling"},{"metadata":{},"cell_type":"markdown","source":"## 4.1 Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [\n    ('KNN',KNeighborsClassifier()),\n    ('DT', DecisionTreeClassifier()),\n    ('NB', GaussianNB()),\n    ('SVM',SVC()),\n    ('RF', RandomForestClassifier()),\n]\n\nresults = []\nnames = []\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Model Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tuning_model(model,hyperparams_dict):\n    grid = GridSearchCV(model,\n                        param_grid=hyperparams_dict,\n                        cv=10,\n                        n_jobs=-1,\n                        verbose=2)\n    grid.fit(X_train, y_train)\n    best_params = grid.best_params_\n    best_score = grid.best_score_\n  \n    print(\"Best Score: {}\".format(best_score))\n    print(\"Best Parameters: {}\\n\".format(best_params))\n\n    return grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_hyperparams = { \"n_neighbors\" : list(range(1,30,1)),\n\"algorithm\" : ['auto'],\n\"weights\" : ['uniform', 'distance'],\n\"leaf_size\" : list(range(1,50,5))\n}\n\nknn_tuned = tuning_model(KNeighborsClassifier(),knn_hyperparams)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RANDOM FOREST"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_hyperparams = {\"n_estimators\": [40, 60, 90],\n\"criterion\": [\"entropy\", \"gini\"],\n\"max_depth\": [2, 5, 10],\n\"max_features\": [\"log2\", \"sqrt\"],\n\"min_samples_leaf\": [1, 5, 8],\n\"min_samples_split\": [2, 3, 5] }\n\nrf_tuned = tuning_model(RandomForestClassifier(), rf_hyperparams)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Making A Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_submission_file(model,X_test,filename=\"submission.csv\"):\n    submission_df = {\"PassengerId\": test['PassengerId'],\n                     \"Survived\": model.predict(X_test)}\n    submission = pd.DataFrame(submission_df)\n    submission.to_csv(filename,index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_submission_file(knn_tuned,X_test,filename='knn_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_submission_file(rf_tuned,X_test,filename='rf_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}