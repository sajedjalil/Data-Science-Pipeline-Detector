{"cells":[{"metadata":{"_uuid":"f26a73b134893754ec346f453650d22ca5a3cd86"},"cell_type":"markdown","source":"# Awesome Data Science for Beginners with Roadmap and Titanic Exploration\n\n### (Start Here) (TBU)\n\n    This kernel has the curated list of Awesome Data Science Beginners's Resources with Roadmap and Some Exploratory Data Analysis of Titanic Disaster \n    \nIf you want to know more about Data Science but don't know where to start this list is for you!\n\nNo previous knowledge required but Python and statistics basics will definitely come in handy. These resources have been used successfully for many beginners at Data Science student groups.\n \n> #### **Credits**: Thanks to **Practical AI - Goku Mohandas**, **Data Science University** and other contributers for such wonderful work!\n\n### Here are some of *my kernel notebooks* for **Machine Learning and Data Science** as follows, ***Upvote*** them if you *like* them\n\n> * [Awesome Deep Learning Basics and Resources](https://www.kaggle.com/arunkumarramanan/awesome-deep-learning-resources)\n> * [Data Science with R - Awesome Tutorials](https://www.kaggle.com/arunkumarramanan/data-science-with-r-awesome-tutorials)\n> * [Data Science and Machine Learning Cheetcheets](https://www.kaggle.com/arunkumarramanan/data-science-and-machine-learning-cheatsheets)\n> * [Awesome ML Frameworks and MNIST Classification](https://www.kaggle.com/arunkumarramanan/awesome-machine-learning-ml-frameworks)\n> * [Tensorflow Tutorial and House Price Prediction](https://www.kaggle.com/arunkumarramanan/tensorflow-tutorial-and-examples)\n> * [Data Scientist's Toolkits - Awesome Data Science Resources](https://www.kaggle.com/arunkumarramanan/data-scientist-s-toolkits-awesome-ds-resources)\n> * [Awesome Computer Vision Resources (TBU)](https://www.kaggle.com/arunkumarramanan/awesome-computer-vision-resources-to-be-updated)\n> * [Machine Learning and Deep Learning - Awesome Tutorials](https://www.kaggle.com/arunkumarramanan/awesome-deep-learning-ml-tutorials)\n> * [Data Science with Python - Awesome Tutorials](https://www.kaggle.com/arunkumarramanan/data-science-with-python-awesome-tutorials)\n> * [Awesome TensorFlow and PyTorch Resources](https://www.kaggle.com/arunkumarramanan/awesome-tensorflow-and-pytorch-resources)\n> * [Awesome Data Science IPython Notebooks](https://www.kaggle.com/arunkumarramanan/awesome-data-science-ipython-notebooks)\n> * [Machine Learning Engineer's Toolkit with Roadmap](https://www.kaggle.com/arunkumarramanan/machine-learning-engineer-s-toolkit-with-roadmap) \n> * [Hands-on ML with scikit-learn and TensorFlow](https://www.kaggle.com/arunkumarramanan/hands-on-ml-with-scikit-learn-and-tensorflow)\n> * [Practical Machine Learning with PyTorch](https://www.kaggle.com/arunkumarramanan/practical-machine-learning-with-pytorch)\n> * [Awesome Data Science for Beginners with Titanic Exploration](https://kaggle.com/arunkumarramanan/awesome-data-science-for-beginners)\n"},{"metadata":{"_uuid":"0b9575469bd7d50737f054cf4b240e70d0de55f3"},"cell_type":"markdown","source":"# Titanic Exploration\nIn this notebook, we'll do some exploratory data analysis with Titanic Disaster Competition.\n\n### Uploading the data\n\nWe're first going to get some data to play with. We're going to load the titanic dataset from the getting started competition below.\n\n### Loading the data\n\nNow that we have some data to play with, let's load into a Pandas dataframe. Pandas is a great python library for data analysis.****"},{"metadata":{"trusted":true,"_uuid":"de0b0b6116a5cbd5da28ade457601d197055ce7a"},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35d267f533454f99f42e793495099ff601a65632"},"cell_type":"code","source":"# Read from CSV to Pandas DataFrame\ndf = pd.read_csv(\"../input/train.csv\", header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bd2dae6276c18d8bad1cff4342b2a17d9e17806"},"cell_type":"code","source":"# First five items\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5c556259ccfbdce549b693102199bf8a8f3a174"},"cell_type":"markdown","source":"These are the diferent features: \n* pclass: class of travel\n* name: full name of the passenger\n* sex: gender\n* age: numerical age\n* sibsp: # of siblings/spouse aboard\n* parch: number of parents/child aboard\n* ticket: ticket number\n* fare: cost of the ticket\n* cabin: location of room\n* emarked: port that the passenger embarked at (C - Cherbourg, S - Southampton, Q = Queenstown)\n* survived: survial metric (0 - died, 1 - survived)"},{"metadata":{"_uuid":"c99296b4831be144251839a378a9c1a398dc4d12"},"cell_type":"markdown","source":"### Exploratory Dats Analysis EDA\n\nWe're going to explore the Pandas library and see how we can explore and process our data."},{"metadata":{"trusted":true,"_uuid":"dfd96c4ec9021d8471a78da31a46ff653e7a6ff1"},"cell_type":"code","source":"# Describe features\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1626d3b8dd7356243b507a7e4c85ee354a34dff8"},"cell_type":"code","source":"# Histograms\ndf[\"Age\"].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"453a9a4d50b4cab7873df759cb6725f81647d3a9"},"cell_type":"code","source":"# Unique values\ndf[\"Embarked\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e440a9e6bf5199e3ab903f1a8e956f2bfa293dca"},"cell_type":"code","source":"# Selecting data by feature\ndf[\"Name\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed50b952838b4cd040e38548d8ca8049100762e3"},"cell_type":"code","source":"# Filtering\ndf[df[\"Sex\"]==\"female\"].head() # only the female data appear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"278ac6f3e801e8691600c8b666cd88c78f6e8c00"},"cell_type":"code","source":"# Sorting\ndf.sort_values(\"Age\", ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b582a548b87cd0428650bd749162511788a0f8b4"},"cell_type":"code","source":"# Grouping\nsex_group = df.groupby(\"Survived\")\nsex_group.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32cce9dad4a271c8c8b84586cb7f77a6a4d5cdc7"},"cell_type":"code","source":"# Selecting row\ndf.iloc[0, :] # iloc gets rows (or columns) at particular positions in the index (so it only takes integers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd2424be11079489f422f248f2142c16fca25342"},"cell_type":"code","source":"# Selecting specific value\ndf.iloc[0, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03ae2d5c9fb123a63350090118f7bb06e08030b5"},"cell_type":"code","source":"# Selecting by index\ndf.loc[0] # loc gets rows (or columns) with particular labels from the index","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2eea325edab220f6534f59c9ef5c1afa590edc6"},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"trusted":true,"_uuid":"5a78c547e70a750637976f855e6acf2c96be0146"},"cell_type":"code","source":"# Rows with at least one NaN value\ndf[pd.isnull(df).any(axis=1)].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2659bf3cf5f147b106eccebf9d638c6d287a5d5"},"cell_type":"code","source":"# Drop rows with Nan values\ndf = df.dropna() # removes rows with any NaN values\ndf = df.reset_index() # reset's row indexes in case any rows were dropped\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bf4808a1a504c6d993d31362ee7de68bfe8bd99"},"cell_type":"code","source":"# Dropping multiple rows\ndf = df.drop([\"Name\", \"Cabin\", \"Ticket\"], axis=1) # we won't use text features for our initial basic models\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50e722b1c3523a98f38db633f3842d9a3db947ae"},"cell_type":"code","source":"# Map feature values\ndf['Sex'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\ndf[\"Embarked\"] = df['Embarked'].dropna().map( {'S':0, 'C':1, 'Q':2} ).astype(int)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29dcb45fa5e1e1237fea18503ee8e7d9b090fd8a"},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"fd076d961dfd38271ead811b7b7dcc253dca2116"},"cell_type":"code","source":"# Lambda expressions to create new features\ndef get_family_size(sibsp, parch):\n    family_size = sibsp + parch\n    return family_size\n\ndf[\"Family_Size\"] = df[[\"SibSp\", \"Parch\"]].apply(lambda x: get_family_size(x[\"SibSp\"], x[\"Parch\"]), axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7afc5fea06fe7d65a43411f66a3384e7098a111"},"cell_type":"code","source":"# Reorganize headers\ndf = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Family_Size', 'Fare', 'Embarked', 'Survived']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2d616f54f6f06d80826ddb11985d20c111e2cf8"},"cell_type":"markdown","source":"### Saving data"},{"metadata":{"trusted":true,"_uuid":"2448e56e6dac3995be860a6a13401bebe0915fd5"},"cell_type":"code","source":"# Saving dataframe to CSV\ndf.to_csv(\"processed_titanic.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be870372be180a70b203a9148c7707a353b3eab0"},"cell_type":"code","source":"# See your saved file\n!ls -l","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"186a0371837ce5a938069c419c339895e1ced18d"},"cell_type":"markdown","source":"### End of the exploration"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Awesome Data Science for Beginners with Roadmap\n\n## Contents\n\n- [What is Data Science?](#what-is-data-science)\n- [Common Algorithms and Procedures](#common-algorithms-and-procedures)\n- [Data Science using Python](#data-science-using-python)\n- [Data Science Challenges for Beginners](#data-science-challenges-for-beginners)\n- [Data Science and Engineering your way](#data-science-and-engineering-your-way)\n- [More advanced resources and lists](#more-advanced-resources-and-lists)\n\n## What is Data Science?\n\n- ['What is Data Science?' on Quora](https://www.quora.com/What-is-data-science)\n- [Explanation of important vocabulary](https://www.quora.com/What-is-the-difference-between-Data-Analytics-Data-Analysis-Data-Mining-Data-Science-Machine-Learning-and-Big-Data-1?share=1) - Differentiation of Big Data, Machine Learning, Data Science.\n\n## Common Algorithms and Procedures\n\n- [Supervised vs unsupervised learning](https://stackoverflow.com/questions/1832076/what-is-the-difference-between-supervised-learning-and-unsupervised-learning) - The two most common types of Machine Learning algorithms. \n- [9 important Data Science algorithms and their implementation](https://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.05-Naive-Bayes.ipynb) \n- [Cross validation](https://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.03-Hyperparameters-and-Model-Validation.ipynb) - Evaluate the performance of your algorithm / model.\n- [Feature engineering](https://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.04-Feature-Engineering.ipynb) - Modifying the data to better model predictions.\n- [Scientific introduction to 10 important Data Science algorithms](http://www.cs.umd.edu/%7Esamir/498/10Algorithms-08.pdf)\n- [Model ensemble: Explanation](https://www.analyticsvidhya.com/blog/2017/02/introduction-to-ensembling-along-with-implementation-in-r/) - Combine multiple models into one for better performance.\n\n## Data Science using Python\nThis list covers only Python, as many are already familiar with this language. [Data Science tutorials using R](https://github.com/ujjwalkarn/DataScienceR).\n\n### Learning Python\n\n- [YouTube tutorial series by sentdex](https://www.youtube.com/watch?v=oVp1vrfL_w4&list=PLQVvvaa0QuDe8XSftW-RAxdo6OmaeL85M)\n- [Interactive Python tutorial website](http://www.learnpython.org/)\n\n### numpy\n[numpy](http://www.numpy.org/) is a Python library which provides large multidimensional arrays and fast mathematical operations on them.\n\n- [Numpy tutorial on DataCamp](https://www.datacamp.com/community/tutorials/python-numpy-tutorial#gs.h3DvLnk)\n\n### pandas\n[pandas](http://pandas.pydata.org/index.html) provides efficient data structures and analysis tools for Python. It is build on top of numpy.\n\n- [Introduction to pandas](http://www.synesthesiam.com/posts/an-introduction-to-pandas.html)\n- [DataCamp pandas foundations](https://www.datacamp.com/courses/pandas-foundations) - Paid course, but 30 free days upon account creation (enough to complete course).\n- [Pandas cheatsheet](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf) - Quick overview over the most important functions.\n\n### scikit-learn\n[scikit-learn](http://scikit-learn.org/stable/) is the most common library for Machine Learning and Data Science in Python.\n\n- [Introduction and first model application](https://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.02-Introducing-Scikit-Learn.ipynb)\n- [Rough guide for choosing estimators](http://scikit-learn.org/stable/tutorial/machine_learning_map/)\n- [Scikit-learn complete user guide](http://scikit-learn.org/stable/user_guide.html)\n- [Model ensemble: Implementation in Python](http://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)\n\n### Jupyter Notebook\n[Jupyter Notebook](https://jupyter.org/) is a web application for easy data visualisation and code presentation.\n\n- [Downloading and running first Jupyter notebook](https://jupyter.org/install.html)\n- [Example notebook for data exploration](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-instacart)\n- [Seaborn data visualization tutorial](https://elitedatascience.com/python-seaborn-tutorial) - Plot library that works great with Jupyter.\n\n\n### Various other helpful tools and resources\n\n- [Template folder structure for organizing Data Science projects](https://github.com/drivendata/cookiecutter-data-science)\n- [Anaconda Python distribution](https://www.continuum.io/downloads) - Contains most of the important Python packages for Data Science.\n- [Natural Language Toolkit](http://www.nltk.org/) - Collection of libraries for working with text-based data.\n- [LightGBM gradient boosting framework](https://github.com/Microsoft/LightGBM) - Successfully used in many Kaggle challenges.\n- [Amazon AWS](https://aws.amazon.com/) - Rent cloud servers for more timeconsuming calculations (r4.xlarge server is a good place to start).\n\n## Data Science Challenges for Beginners\nSorted by increasing complexity.\n\n- [Walkthrough: House prices challenge](https://www.dataquest.io/blog/kaggle-getting-started/) - Walkthrough through a simple challenge on house prices.\n- [Blood Donation Challenge](https://www.drivendata.org/competitions/2/warm-up-predict-blood-donations/) - Predict if a donor will donate again.\n- [Titanic Challenge](https://www.kaggle.com/c/titanic) - Predict survival on the Titanic.\n- [Water Pump Challenge](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/) - Predict the operating condition of water pumps in Africa.\n\n## Data Science and Engineering your way\n\n##### An introduction to different Data Science and Engineering concepts and Applications using Python and R  \n\nThese series of tutorials on Data Science engineering will try to compare how different concepts in the discipline can be implemented in the two dominant ecosystems nowadays: R and Python.  \n\nWe will do this from a neutral point of view. Our opinion is that each environment has good and bad things, and any data scientist should know how to use both in order to be as prepared as posible for job market or to start personal project.    \n\nTo get a feeling of what is going on regarding this hot topic, we refer the reader to [DataCamp's Data Science War](http://blog.datacamp.com/r-or-python-for-data-analysis/) infographic. Their infographic explores what the strengths of **R** are over **Python** and vice versa, and aims to provide a basic comparison between these two programming languages from a data science and statistics perspective.  \n\nFar from being a repetition from the previous, our series of tutorials will go hands-on into how to actually perform different data science taks such as working with data frames, doing aggregations, or creating different statistical models such in the areas of supervised and unsupervised learning.  \n\nWe will use real-world datasets, and we will build some real data products. This will help us to quickly transfer what we learn here to actual data analysis situations.  \n\nIf your are interested in Big Data products, then you might find interesting our series of [tutorials on using Apache Spark and Python](https://github.com/jadianes/spark-py-notebooks) or [using R on Apache Spark (SparkR)](https://github.com/jadianes/spark-r-notebooks).  \n\n## Tutorials\n\nThis is a growing list of tutorials explaining concepts and applications in Python and R. \n\n### [Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/)\n\nMachine Learning ML Crash Course with TensorFlow APIs is highly recommended by Google as it's developed by googlers.\n\n### [Introduction to Data Frames](https://github.com/jadianes/data-science-your-way/blob/master/01-data-frames/README.md)  \n\nAn introduction to the basic data structure and how to use it in Python/Pandas and R.  \n\n### [Exploratory Data Analysis](https://github.com/jadianes/data-science-your-way/blob/master/02-exploratory-data-analysis/README.md)    \n\nAbout this important task in any data science engineering project.  \n\n### [Dimensionality Reduction and Clustering](https://github.com/jadianes/data-science-your-way/blob/master/03-dimensionality-reduction-and-clustering/README.md)    \nAbout using Principal Component Analysis and k-means Clustering to better represent and understand our data.  \n\n### [Text Mining and Sentiment Classification](https://github.com/jadianes/data-science-your-way/blob/master/04-sentiment-analysis/README.md)    \n\nHow to use text mining techniques to analyse the positive or non-positive sentiment of text documents using just *linear methods*.  \n\n## Applications  \n\nThese are some of the applications we have built using the concepts explained in the tutorials.  \n\n### [A web-based Sentiment Classifier using R and Shiny](https://github.com/jadianes/data-science-your-way/blob/master/apps/sentimentclassifier/README.md)  \n\nHow to build a web applications where we can upload text documents to be sentiment-analysed using the R-based framework [Shiny](http://shiny.rstudio.com/).  \n\n### [Building Data Products with Python](https://github.com/jadianes/data-science-your-way/blob/master/apps/winerama/README.md)  \n\nUsing a [wine reviews and recommendations website](http://jadianes.koding.io:8000/reviews/) as a leitmotif, this series of tutorials, with [its own separate repository](https://github.com/jadianes/winerama-recommender-tutorial) tagged by lessons, digs into how to use Python technologies such as Django, Pandas, or Scikit-learn, in order to build data products.   \n\n### [Red Wine Quality Data analysis with R](https://github.com/jadianes/data-science-your-way/blob/master/apps/wine-quality-data-analysis/README.md)  \n\nUsing R and ggplot2, we perform Exploratory Data Analysis of this reference dataset about wine quality.    \n\n### [Information Retrieval algorithms with Python](https://github.com/jadianes/data-science-your-way/blob/master/apps/information-retrieval/README.md)  \n\nWhere we show our own implementation of a couple of Information Retrieval algorithms: vector space model, and tf-idf.  \n\n### [Kaggle - The Analytics Edge (Spring 2015)](https://github.com/jadianes/data-science-your-way/blob/master/apps/kaggle-analytics-edge-15/)  \n\nMy solution to this Kaggle competition. It was part of the edX MOOC [The Analitics Edge](https://www.edx.org/course/analytics-edge-mitx-15-071x-0). I highly recommend this on-line course. It is one of the most applied I have ever taken about using R for data anlysis and machine learning.  \n\n## More advanced resources and lists\n\n- [Awesome Data Science with Python](https://www.kaggle.com/arunkumarramanan/data-science-with-python-awesome-tutorials)\n- [Awesome Data Science with R](https://www.kaggle.com/arunkumarramanan/data-science-with-r-awesome-tutorials)\n- [Machine Learning & Deep Learning Awesome Tutorials](https://www.kaggle.com/arunkumarramanan/ml-and-deep-learning-awesome-tutorials)\n- [Awesome Data Science Resources](https://www.kaggle.com/arunkumarramanan/awesome-data-science-resources)\n\n# Data Science University (Awesome Data Science MOOCs)\n   An Open Source Society University: ðŸ“Š Path to a free self-taught education in Data Science! \n     \n     Data Science University - Awesome MOOCs (Massive Open Online Courses)\n    \n## Contents\n\n- [About](#about)\n- [Motivation & Preparation](#motivation--preparation)\n- [Curriculum](#curriculum)\n- [How to use this guide](#how-to-use-this-guide)\n- [Prerequisite](#prerequisite)\n- [References](#references)\n\n## About\n\nThis is a **solid path** for those of you who want to complete a **Data Science** course on your own time, **for free**, with courses from the **best universities** in the World.\n\nIn our curriculum, we give preference to MOOC (Massive Open Online Course) style courses because these courses were created with our style of learning in minds.\n\n## Motivation & Preparation\n\nHere are two interesting links that can make **all** the difference in your journey.\n\nThe first one is a motivational video that shows a guy that went through the \"MIT Challenge\", which consists of learning the entire **4-year** MIT curriculum for Computer Science in **1 year**.\n\n- [MIT Challenge](https://www.scotthyoung.com/blog/myprojects/mit-challenge-2/)\n\nThe second link is a MOOC that will teach you learning techniques used by experts in art, music, literature, math, science, sports, and many other disciplines. These are **fundamental abilities** to succeed in our journey.\n\n- [Learning How to Learn](https://www.coursera.org/learn/learning-how-to-learn)\n\n**Are you ready to get started?**\n\n## Curriculum\n\n- [Linear Algebra](#linear-algebra)\n- [Single Variable Calculus](#single-variable-calculus)\n- [Multivariable Calculus](#multivariable-calculus)\n- [Python](#python)\n- [Probability and Statistics](#probability-and-statistics)\n- [Introduction to Data Science](#introduction-to-data-science)\n- [Machine Learning](#machine-learning)\n- [Project](#project)\n- [Convex Optimization](#convex-optimization)\n- [Data Wrangling](#data-wrangling)\n- [Big Data](#big-data)\n- [Database](#database)\n- [Deep Learning](#deep-learning)\n- [Natural Language Processing](#natural-language-processing)\n- [Capstone Project](#capstone-project)\n- [Specializations](#specializations)\n\n\n---\n\n### Linear Algebra\n\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Linear Algebra - Foundations to Frontiers](https://www.edx.org/course/linear-algebra-foundations-frontiers-utaustinx-ut-5-04x#!)| 15 weeks | 8 hours/week\n[Applications of Linear Algebra Part 1](https://www.edx.org/course/applications-linear-algebra-part-1-davidsonx-d003x-1)| 5 weeks | 4 hours/week\n[Applications of Linear Algebra Part 2](https://www.edx.org/course/applications-linear-algebra-part-2-davidsonx-d003x-2)| 4 weeks | 5 hours/week\n\n### Single Variable Calculus\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Calculus 1A: Differentiation](https://www.edx.org/course/calculus-1a-differentiation-mitx-18-01-1x)| 13 weeks | 6-10 hours/week\n[Calculus 1B: Integration](https://www.edx.org/course/calculus-1b-integration-mitx-18-01-2x)| 13 weeks | 5-10 hours/week\n[Calculus 1C: Coordinate Systems & Infinite Series](https://www.edx.org/course/calculus-1c-coordinate-systems-infinite-mitx-18-01-3x)| 13 weeks | 6-10 hours/week\n\n### Multivariable Calculus\nCourses | Duration | Effort\n:-- | :--: | :--:\n[MIT OCW Multivariable Calculus](http://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/index.htm)| 15 weeks | 8 hours/week\n\n### Python\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Introduction to Computer Science and Programming Using Python](https://www.edx.org/course/introduction-computer-science-mitx-6-00-1x-7)| 9 weeks | 15 hours/week\n[Introduction to Computational Thinking and Data Science](https://www.edx.org/course/introduction-computational-thinking-data-mitx-6-00-2x-3)| 10 weeks | 15 hours/week\n[Introduction to Python for Data Science](https://prod-edx-mktg-edit.edx.org/course/introduction-python-data-science-microsoft-dat208x-1)| 6 weeks | 2-4 hours/week\n[Programming with Python for Data Science](https://www.edx.org/course/programming-python-data-science-microsoft-dat210x)| 6 weeks | 3-4 hours/week\n\n### Probability and Statistics\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Introduction to Probability](https://www.edx.org/course/introduction-probability-science-mitx-6-041x-1#.U3yb762SzIo)| 16 weeks | 12 hours/week\n[Statistical Reasoning](https://lagunita.stanford.edu/courses/OLI/StatReasoning/Open/about)| - weeks | - hours/week\n[Introduction to Statistics: Descriptive Statistics](https://www.edx.org/course/introduction-statistics-descriptive-uc-berkeleyx-stat2-1x)| 5 weeks | - hours/week\n[Introduction to Statistics: Probability](https://www.edx.org/course/introduction-statistics-probability-uc-berkeleyx-stat2-2x)| 5 weeks | - hours/week\n[Introduction to Statistics: Inference](https://www.edx.org/course/introduction-statistics-inference-uc-berkeleyx-stat2-3x)| 5 weeks | - hours/week\n\n### Introduction to Data Science\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Introduction to Data Science](https://www.coursera.org/course/datasci)| 8 weeks | 10-12 hours/week\n[Data Science - CS109 from Harvard](http://cs109.github.io/2015/)| 12 weeks | 5-6 hours/week\n[The Analytics Edge](https://www.edx.org/course/analytics-edge-mitx-15-071x-2)| 12 weeks | 10-15 hours/week\n\n### Machine Learning\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Learning From Data (Introductory Machine Learning)](https://www.edx.org/course/learning-data-introductory-machine-caltechx-cs1156x)    [[caltech]](http://work.caltech.edu/lectures.html) | 10 weeks | 10-20 hours/week\n[Statistical Learning](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about)| - weeks | 3 hours/week\n[Stanford's Machine Learning Course](https://www.coursera.org/learn/machine-learning)| - weeks | 8-12 hours/week\n[Google Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)| - weeks | 15 hours\n\n### Project\nComplete Kaggle's Getting Started and Playground Competitions\n\n\n### Convex Optimization\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Convex Optimization](https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about)| 9 weeks | 10 hours/week\n\n### Data Wrangling\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Data Wrangling with MongoDB](https://www.udacity.com/course/data-wrangling-with-mongodb--ud032)| 8 weeks | 10 hours/week\n\n### Big Data\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Intro to Hadoop and MapReduce](https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617)| 4 weeks | 6 hours/week\n[Deploying a Hadoop Cluster](https://www.udacity.com/course/deploying-a-hadoop-cluster--ud1000)| 3 weeks | 6 hours/week\n\n### Database\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Stanford's Database course](https://lagunita.stanford.edu/courses/DB/2014/SelfPaced/about)| - weeks | 8-12 hours/week\n\n### Natural Language Processing\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/)| - weeks | - hours/week\n\n### Deep Learning\nCourses | Duration | Effort\n:-- | :--: | :--:\n[Deep Learning](https://www.udacity.com/course/deep-learning--ud730)| 12 weeks | 8-12 hours/week\n\n### Capstone Project\n- Participate in Kaggle competition\n- List down other ideas\n\n\n### Specializations\n\nAfter finishing the courses above, start your specializations on the topics that you have more interest.\nYou can view a list of available specializations [here](https://github.com/open-source-society/data-science/blob/master/extras/specializations.md).\n\n![keep learning](http://i.imgur.com/REQK0VU.jpg)\n\n## How to use this guide\n\n### Order of the classes\n\nThis guide was developed to be consumed in a linear approach. What does this mean? That you should complete one course at a time.\n\nThe courses are **already** in the order that you should complete them. Just start in the [Linear Algebra](#linear-algebra) section and after finishing the first course, start the next one.\n\n**If the course isn't open, do it anyway with the resources from the previous class.**\n\n### Should I take all courses?\n\n**Yes!** The intention is to conclude **all** the courses listed here!\n\n### Duration of the project\n\nIt may take longer to complete all of the classes compared to a  regular Data Science course, but I can **guarantee** you that your **reward** will be proportional to **your motivation/dedication**!\n\nYou must focus on your **habit**, and **forget** about goals. Try to invest 1 ~ 2 hours **every day** studying this curriculum. If you do this, **inevitably** you'll finish this curriculum.\n\n> See more about \"Commit to a process, not a goal\" [here](http://jamesclear.com/goals-systems).\n\n### Project Based\n\nHere in **Data Science University**, you do **not** need to take exams, because we are focused on **real projects**!\n\nIn order to show for everyone that you **successfully** finished a course, you should create a **real project**.\n\n> \"What does it mean?\"\n\nAfter finish a course, you should think about a **real world problem** that you can solve using the acquired knowledge in the course. You don't need to create a big project, but you must create something to **validate** and **consolidate** your knowledge, and also to show to the world that you are capable to create something useful with the concepts that you learned.\n\nThe projects of all students will be listed in [this](https://github.com/open-source-society/data-science/blob/master/PROJECTS.md) file. Submit your project's information in that file after you conclude it.\n\n**You can create this project alone or with other students!**\n\n#### Project Suggestions\n\n\nAnd you should also...\n\n### Be creative!\n\nThis is a **crucial** part of your journey through all those courses.\n\nYou **need** to have in mind that what you are able to **create** with the concepts that you learned will be your certificate **and this is what really matters**!\n\nIn order to show that you **really** learned those things, you need to be **creative**!\n\nHere are some tips about how you can do that:\n\n- **Articles**: create blog posts to synthesize/summarize what you learned.\n- **GitHub repository**: keep your course's files organized in a GH repository, so in that way other students can use it to study with your annotations.\n\n### Which programming languages should I use?\n\nPython and R are heavily used in Data Science community and our courses teach you both, but...\n\nThe **important** thing for each course is to **internalize** the **core concepts** and to be able to use them with whatever tool (programming language) that you wish.\n\n[Be creative](#be-creative) in order to show your progress! :smile:\n\n### Stay tuned\n\nUPVOTE for futures improvements and general information.\n\n## Prerequisite\n\nThe **only things** that you need to know are how to use **Git** and **GitHub**. Here are some resources to learn about them:\n\n**Note**: Just pick one of the courses below to learn the basics. You will learn a lot more once you get started!\n\n- [Try Git](https://try.github.io/levels/1/challenges/1)\n- [Git - the simple guide](http://rogerdudler.github.io/git-guide/)\n- [GitHub Training & Guides](https://www.youtube.com/playlist?list=PLg7s6cbtAD15G8lNyoaYDuKZSKyJrgwB-)\n- [GitHub Hello World](https://guides.github.com/activities/hello-world/)\n- [Git Immersion](http://gitimmersion.com/index.html)\n- [How to Use Git and GitHub](https://www.udacity.com/course/how-to-use-git-and-github--ud775)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Credits (Reference)\n\n> - [practicalAI - Goku Mohandas](https://github.com/GokuMohandas/practicalAI/)\n> - [Data Science University](https://github.com/ossu/data-science)\n> - [GitHub Awesome Lists Topic](https://github.com/topics/awesome)\n> - [Awesome Learn Data science](https://github.com/siboehm/awesome-learn-datascience)\n\n## License\n\n[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)\n\n### Please ***UPVOTE*** my kernel if you like it or wanna fork it.\n\n##### Feedback: If you have any ideas or you want any other content to be added to this curated list, please feel free to make any comments to make it better.\n#### I am open to have your *feedback* for improving this ***kernel***\n###### Hope you enjoyed this kernel!\n\n### Thanks for visiting my *Kernel* and please *UPVOTE* to stay connected and follow up the *further updates!*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}