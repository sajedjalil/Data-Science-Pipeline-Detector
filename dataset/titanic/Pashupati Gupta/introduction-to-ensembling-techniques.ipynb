{"cells":[{"metadata":{},"cell_type":"markdown","source":"## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:180%; text-align:center\">1. Introduction</p>"},{"metadata":{},"cell_type":"markdown","source":"Wikipedia Says - In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. \n\nIn simple terms - In ensembling we try to use the learnings from multiple algorithms to make a more efficient algorithm. For example Random Forest algorithms - It's a ensembling algorithm that uses multiple decision trees. Look at the below picture - \n\n<img src=\"https://www.kdnuggets.com/wp-content/uploads/ensemble-framework-packt.jpg\">\n\n\n\n<br/>So we try to use multiple algorithms to enhance the performance. The concept of ensembling is pretty simple. What's required is a robust technique to do this ensembling. In this Notebook we'll se what are techniques used for ensembling. For ex - \n\n- Weighted Ensembling Approach\n- VotingClassifier\n- StackingClassifier\n- Ensembling using a custom model\n- Bayesian optimal classifier.\n\nDetails in each forthcoming sections. We'll cover each step of model development. \n\n- Data Processing\n- Feature Engineering\n- Model Development\n- Ensembling\n- Evaluation\n\nLet's Begin!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Basic Library\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport scipy.stats as stats\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# sklearn utility\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics   \nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\n## XGBoost\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\n### LightGBM\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\n\n### CatBoost\nfrom catboost import CatBoostClassifier\nimport catboost as catboost\n\n## sklearn ensembles \nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading the Data!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Titanic Dataset\ntitanic_train = pd.read_csv(\"../input/titanic/train.csv\")\ntitanic_test = pd.read_csv(\"../input/titanic/test.csv\")\ndataset = \"titanic\"\nIdCol = 'PassengerId'\ntargetCol = 'Survived'\ntitanic_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:180%; text-align:center\">2. Data Preparation</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_or_float = titanic_train.dtypes[titanic_train.dtypes.isin(['int64', 'float64'])].index\nprint(\"Int or Flaot Columns : \", list(int_or_float))\nnum_cols = ['Age', 'SibSp', 'Parch', \"Fare\"]\nprint(\"Num Cols : \", num_cols)\ncat_cols = ['Pclass', 'Sex', 'Embarked']\nprint(\"Cat Cols : \", cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_len = len(titanic_train)\ncombined =  pd.concat(objs=[titanic_train, titanic_test], axis=0).reset_index(drop=True)\n#combined.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1) Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values_details(df):\n    total = df.isnull().sum()\n    \n    missing_df = pd.DataFrame({'count_missing': total}).reset_index().rename(columns={'index':'column_name'})\n    missing_df['percent_missing'] = missing_df['count_missing']/len(df)\n    missing_df = missing_df.sort_values(by='count_missing', ascending=False)\n    missing_df = missing_df[missing_df['count_missing']!=0]\n    print('Info : {} out of {} columns have mising values'.format(len(missing_df), len(df.columns)))\n    missing_90 = missing_df[missing_df['percent_missing']>0.9]\n    missing_80 = missing_df[missing_df['percent_missing']>0.8]\n    missing_70 = missing_df[missing_df['percent_missing']>0.7]\n    print(\"Info : {} columns have more that 90% missing values\".format(len(missing_90)))\n    print(\"Info : {} columns have more that 80% missing values\".format(len(missing_80)))\n    print(\"Info : {} columns have more that 70% missing values\".format(len(missing_70)))\n    \n    return missing_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_details(titanic_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2) Check for class balance"},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_class_balance(df, target_col):\n    counts = df[target_col].value_counts()\n    class_df = pd.DataFrame(counts).reset_index().rename(columns={target_col:'counts', 'index':'class'})\n    class_df.plot.bar(x='class', y='counts')\n    print('Info : There are {} classes in the target column'.format(len(class_df)))\n    max_class = class_df['counts'].max() \n    min_class = class_df['counts'].min()\n    max_diff = max_class - min_class\n    print(\"Info : Maximum difference between 2 classes is {} observations that is {} times w.r.t. minimum class\".format(max_diff, (max_diff/min_class)))\n    return class_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_class_balance(titanic_train, 'Survived')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3) Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"def detect_outliers(df,n,features):\n    outlier_indices = []\n    # iterate over features(columns)\n    for col in features:\n        Q1 = np.percentile(df[col], 25)\n        Q3 = np.percentile(df[col],75)\n        IQR = Q3 - Q1\n        \n        outlier_step = 1.5 * IQR\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        outlier_indices.extend(outlier_list_col)\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from num_cols\noutliers_rows = detect_outliers(titanic_train,2,num_cols)\nprint(len(outliers_rows))\n# Drop outliers\ntitanic_train = titanic_train.drop(outliers_rows, axis = 0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:180%; text-align:center\">3. Feature Engineering</p>"},{"metadata":{},"cell_type":"markdown","source":"### 3.1) Numerical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def describe_num_col(train, col):\n    #### This function provides detailed comparison of a numerical varible\n    ### missing value\n    count_train = train[col].isnull().sum()\n    #print(\"######    Variable Name : {}    ######\".format(col))\n    \n    #### Skewness and Kurtosis\n    train_k = stats.kurtosis(train[col].dropna(), bias=False)\n    \n    train_s = stats.skew(train[col].dropna(), bias=False)\n    \n    #### Outliers\n    \n    def count_outliers(df, col):\n        mean_d = np.mean(df[col])\n        std_d = np.std(df[col])\n        \n        scaled = (df[col]-mean_d)/std_d\n        outliers = abs(scaled) > 3\n        if len(outliers.value_counts()) > 1:\n            return outliers.value_counts()[1]\n        else:\n            return 0   \n    \n    train_o = count_outliers(train, col)\n        \n    summ_df = pd.DataFrame({'info':['missing_count', 'missing_percent', 'skewness', 'kurtosis', 'outlier_count', 'outlier_percent'],\n                           'train_set':[count_train, (count_train/len(train))*100, train_s, train_k, train_o, (train_o/len(train))*100]})\n    \n#     print(\"######    Summary Data\")\n#     display(summ_df)\n    \n    #print(\"######    Distribution and Outliers comparision plots\")\n    \n    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 6))\n    \n    plot10 = sns.distplot(train[train['Survived']==0][col],ax=ax1, label='Not Survived')\n    sns.distplot(train[train['Survived']==1][col],ax=ax1,color='red', label='Survived')\n    plot10.axes.legend()\n    ax1.set_title('Distribution of {name}'.format(name=col))\n    \n    sns.boxplot(x='Survived',y=col,data=train,ax=ax2)\n    #plt.xticks(ticks=[0,1],labels=['Non-Diabetes','Diabetes'])\n    ax2.set_xlabel('Category') \n    ax2.set_title('Boxplot of {name}'.format(name=col))\n    \n    \n    fig.show()    \n    \n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in num_cols:\n    describe_num_col(titanic_train, col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### The column Fare is continuous and it is right skewed\n# Apply log transformation to Fare to reduce skewness distribution\ncombined[\"Fare\"] = combined[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2) Catrgorical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def describe_cat_col(df, col):\n    ### unique values\n    count_u = df[col].nunique()\n    #print(\"Info : There are {} unique values\".format(count_u))\n    nulls = df[col].isnull().sum()\n    #print(\"Info : There are {} missing values that is {} percent\".format(nulls, nulls/len(df)))\n    \n    ### Percent share df\n    share_df = pd.DataFrame(df[col].value_counts()).reset_index().rename(columns={'index':'class_name',col:'counts'})\n    share_df['percent_share'] = share_df['counts']/sum(share_df['counts'])\n    share_df = share_df.sort_values(by='percent_share', ascending=False)\n    #display(share_df)\n        \n        \n    if (count_u > 3 and count_u < 10):\n        fig, ax  = plt.subplots()\n        fig.suptitle(col + ' Distribution', color = 'red')\n        explode = list((np.array(list(df[col].dropna().value_counts()))/sum(list(df[col].dropna().value_counts())))[::-1])\n        labels = list(df[col].dropna().unique())\n        sizes = df[col].value_counts()\n        #ax.pie(sizes, explode=explode, colors=bo, startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.9)\n        ax.pie(sizes,  explode=explode, startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.9)\n        ax.add_artist(plt.Circle((0,0),0.2,fc='white'))\n        plt.show()\n    \n    else:\n        plt.figure()\n        plt.title(col + ' Distribution', color = 'red')\n        sns.barplot(x=col,y='Survived', data = df)\n        plt.show()\n        \n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    #print(\"Column Name : {}\".format(col))\n    describe_cat_col(titanic_train, col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3) Filling the missing values\n3.3.1 - Embarked"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Filling the Embarked column with mode\ncombined['Embarked'] = combined['Embarked'].fillna(combined['Embarked'].value_counts().index[0])\ncombined['Embarked'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = pd.get_dummies(combined, columns = [\"Embarked\"], prefix=\"Em\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.3.2 Age\n\n[Reference](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Age vs Sex, Parch , Pclass and SibSP\ng = sns.factorplot(y=\"Age\",x=\"Sex\",data=combined,kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"Sex\",hue=\"Pclass\", data=combined,kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"Parch\", data=combined,kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"SibSp\", data=combined,kind=\"box\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age distribution seems to be the same in Male and Female subpopulations, so Sex is not informative to predict Age.\n\nHowever, 1st class passengers are older than 2nd class passengers who are also older than 3rd class passengers.\n\nMoreover, the more a passenger has parents/children the older he is and the more a passenger has siblings/spouses the younger he is."},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert Sex into categorical value 0 for male and 1 for female\ncombined[\"Sex\"] = combined[\"Sex\"].map({\"male\": 0, \"female\":1})\n\n# Filling missing value of Age \n\n## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n# Index of NaN age rows\nindex_NaN_age = list(combined[\"Age\"][combined[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_med = combined[\"Age\"].median()\n    age_pred = combined[\"Age\"][((combined['SibSp'] == combined.iloc[i][\"SibSp\"]) & (combined['Parch'] == combined.iloc[i][\"Parch\"]) & (combined['Pclass'] == combined.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        combined['Age'].iloc[i] = age_pred\n    else :\n        combined['Age'].iloc[i] = age_med","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.3.3 Cabin"},{"metadata":{"trusted":true},"cell_type":"code","source":"combined['Cabin'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace the Cabin number by the type of cabin 'X' if not\ncombined[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in combined['Cabin'] ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = pd.get_dummies(combined, columns = [\"Cabin\"],prefix=\"Cabin\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4) Feature Transformation\n\n3.4.1 Name -> Title"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get Title from Name\ncombined_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in combined[\"Name\"]]\ncombined[\"Title\"] = pd.Series(combined_title)\ncombined[\"Title\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to categorical values Title \ncombined[\"Title\"] = combined[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ncombined[\"Title\"] = combined[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ncombined[\"Title\"] = combined[\"Title\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"Title\",y=\"Survived\",data=combined,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Name variable\ncombined.drop(labels = [\"Name\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.4.2 Ticket"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n\nTicket = []\nfor i in list(combined.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ncombined[\"Ticket\"] = Ticket\ncombined[\"Ticket\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = pd.get_dummies(combined, columns = [\"Ticket\"], prefix=\"T\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.4.2 Pclass"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create categorical values for Pclass\ncombined[\"Pclass\"] = combined[\"Pclass\"].astype(\"category\")\ncombined = pd.get_dummies(combined, columns = [\"Pclass\"],prefix=\"Pc\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop useless variables \ncombined.drop(labels = [\"PassengerId\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This sums-up the feature engineering part. We have the development data ready now."},{"metadata":{"trusted":true},"cell_type":"code","source":"combined.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = combined[:train_len]\ntest = combined[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)\ntrain[\"Survived\"] = train[\"Survived\"].astype(int)\ny = train[\"Survived\"]\ntrain = train.drop(labels = [\"Survived\"],axis = 1)\ntrain_x, val_x, train_y, val_y = train_test_split(train, y, test_size=0.2)\ntest_id = titanic_test['PassengerId']\ntest_x = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert len(train_x.columns) == len(test_x.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some utility functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Function to evaluate model performance\n\ndef evaluate_model_performnce(y_test, y_pred):\n    cm = confusion_matrix(y_test, y_pred)\n    \n    # Visualizing model performance\n    ax= plt.subplot()\n    sns.heatmap(cm, annot=True, ax = ax, fmt='g'); #annot=True to annotate cells\n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n    ax.set_title('Confusion Matrix'); \n\n    tn, fp, fn, tp = cm.ravel()\n    #print(tn, fp, fn, tp)\n    precision = tp/(tp+fp)\n    recall = tp/(tp+fn)\n    f1 = 2 * (precision * recall) / (precision + recall)\n    accuracy = ((tp+tn)/(tp+tn+fp+fn))*100\n    print(\"Precision : \",precision)\n    print(\"Recall : \",recall)\n    print(\"F1 Score : \",f1)\n    print(\"Validation Accuracy : \",accuracy)\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    print(\"Accuracy Score : \", accuracy)\n\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n    auc = metrics.auc(fpr, tpr)\n    print(\"AUC Value : \", auc)\n    \n    return accuracy, auc, f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function to create the submission file\n\ndef make_submission_file(filename, probab, test_id, IdCol, targetCol, threshold=None):\n    submit = pd.DataFrame()\n    submit[IdCol] = test_id\n    submit[targetCol] = probab\n    if threshold!=None:\n        pred = [1 if x>=threshold else 0 for x in probab]\n        submit[targetCol] = pred\n    submit.to_csv(filename, index=False)\n    return submit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:180%; text-align:center\">Model Development</p>\n\n> ### Training the base learners"},{"metadata":{},"cell_type":"markdown","source":"### Before directly jumping into ensembling. Let's first train some models individually and see how they are performing. \nWe'll train the best models -\n- XGBoost\n- LightBoost\n- CatBoost \n<br/>\n\nAnd the ensemble them. Later we can check with other models too.\n\nNote - We'll be using default parameter's as of now."},{"metadata":{},"cell_type":"markdown","source":"## 1) XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_clf = XGBClassifier()\nxgb_clf.fit(train_x, train_y,eval_metric=[\"auc\", \"logloss\"],verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.4\nxgb_val_prob = xgb_clf.predict_proba(val_x)\nxgb_val_prob = pd.DataFrame(xgb_val_prob)[1]\nxgb_val_pred = [1 if x >= threshold else 0 for x in xgb_val_prob]\nxgb_acc, xgb_auc, xgb_f1 = evaluate_model_performnce(val_y, xgb_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making prediction of leaderboard dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_prob = xgb_clf.predict_proba(test_x)\nxgb_prob = pd.DataFrame(xgb_prob)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xgb_prob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Writitng the submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_sub = make_submission_file(dataset+\"_xgb_default.csv\", xgb_prob, test_id, IdCol, targetCol, threshold=0.5)\nxgb_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_clf = LGBMClassifier()\nlgb_clf.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.4\nlgb_val_prob = lgb_clf.predict_proba(val_x)\nlgb_val_prob = pd.DataFrame(lgb_val_prob)[1]\nlgb_val_pred = [1 if x >= threshold else 0 for x in lgb_val_prob]\nlgb_acc, lgb_auc, lgb_f1 = evaluate_model_performnce(val_y, lgb_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making prediction of leaderboard dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_prob = lgb_clf.predict_proba(test_x)\nlgb_prob = pd.DataFrame(lgb_prob)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lgb_prob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Writitng the submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_sub = make_submission_file(dataset+\"_lgb_default.csv\", lgb_prob, test_id, IdCol, targetCol, threshold=0.5)\nlgb_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3) CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_clf = CatBoostClassifier(verbose=0)\ncat_clf.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.4\ncat_val_prob = cat_clf.predict_proba(val_x)\ncat_val_prob = pd.DataFrame(cat_val_prob)[1]\ncat_val_pred = [1 if x >= threshold else 0 for x in cat_val_prob]\ncat_acc, cat_auc, cat_f1 = evaluate_model_performnce(val_y, cat_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making prediction of leaderboard dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_prob = cat_clf.predict_proba(test_x)\ncat_prob = pd.DataFrame(cat_prob)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cat_prob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Writitng the submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_sub = make_submission_file(dataset+\"_cat_default.csv\", cat_prob, test_id, IdCol, targetCol, threshold=0.5)\ncat_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:180%; text-align:center\">Ensembling</p>"},{"metadata":{},"cell_type":"markdown","source":"## Finally Ensembling!\n\n> #### If you are absolute beginner to ensembling and find this notebook a bit difficult to follow. I encourage you to lokk at this thread [Gateway to Ensembling!!](https://www.kaggle.com/getting-started/219696)\n\nNow we'll se how we can combine the learning from individual models and make an ensemble.\n\n### 1) Weighted Ensembling Approach\n\nThis is the most simple approach for ensembling. We take weighted average of the scores of individual model that gives us the ensembled score. You can decide the weight of an individual model based on the validation score of that model or your experience. \n\nNote - We can treat these weights as hyperparameter and optimize them like we do in Logistic Regression. (w1x1 + w2x2 + ....) Right? Yes, This is the next technique."},{"metadata":{},"cell_type":"markdown","source":"Ensembling on Validation Set and evaluating it!"},{"metadata":{"trusted":true},"cell_type":"code","source":"ens_val_prob = 0.4*cat_val_prob + 0.3*lgb_val_prob + 0.3*xgb_val_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.4\nens_val_pred = [1 if x >= threshold else 0 for x in ens_val_prob]\nens_acc, ens_auc, ens_f1 = evaluate_model_performnce(val_y, ens_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On Leaderboard set"},{"metadata":{"trusted":true},"cell_type":"code","source":"ens_prob = 0.4*cat_prob + 0.3*lgb_prob + 0.3*xgb_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ens_sub = make_submission_file(dataset+\"_weighted_ens.csv\", ens_prob, test_id, IdCol, targetCol, threshold=0.5)\nens_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2) Ensemblinng using a ML model\n\nLike discussed in the previous section here we train a separate model on the outcome of individual models and then using that model an ensembled model."},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_clfs = [xgb_clf, lgb_clf, cat_clf]\n\ndef ensembling_engine(trained_clfs, train_x, train_y, test_x, ensembler):\n    train_matrix = np.empty((train_x.shape[0], len(trained_clfs)))\n    for (n, clf) in enumerate(trained_clfs):\n        train_matrix[:,n] = pd.DataFrame(clf.predict_proba(train_x))[1]      #pd.DataFrame(cat_prob)[1]\n        \n    ensembler.fit(train_matrix, train_y)\n    \n    test_matrix = np.empty((test_x.shape[0], len(trained_clfs)))\n    for (n, clf) in enumerate(trained_clfs):\n        test_matrix[:,n] = pd.DataFrame(clf.predict_proba(test_x))[1]   \n        \n    ens_prob = ensembler.predict_proba(test_matrix)\n    return ens_prob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1) Logistic Regression\n\nLet's try with simple logistic regression. We'll do ensembling on Validation Set and then evaluate it!"},{"metadata":{"trusted":true},"cell_type":"code","source":"ensembler = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_ens_val_prob = ensembling_engine(trained_clfs, train_x, train_y, val_x, ensembler)\nlr_ens_val_prob = pd.DataFrame(lr_ens_val_prob)[1]\nthreshold = 0.4\nlr_ens_val_pred = [1 if x >= threshold else 0 for x in lr_ens_val_prob]\nle_ens_acc, lr_ens_auc, lr_ens_f1 = evaluate_model_performnce(val_y, lr_ens_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensembling on leaderboard dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_ens_prob = ensembling_engine(trained_clfs, train_x, train_y, test_x, ensembler)\nlr_ens_prob = pd.DataFrame(lr_ens_prob)[1]\n#lr_ens_prob\nlr_ens_sub = make_submission_file(dataset+\"lr_ens.csv\", lr_ens_prob, test_id, IdCol, targetCol, threshold=0.5)\nlr_ens_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2) RandomForest\n\nLet's try with random forest. We'll do ensembling on Validation Set and then evaluate it!"},{"metadata":{"trusted":true},"cell_type":"code","source":"ensembler = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_ens_val_prob = ensembling_engine(trained_clfs, train_x, train_y, val_x, ensembler)\nrfc_ens_val_prob = pd.DataFrame(rfc_ens_val_prob)[1]\nthreshold = 0.4\nrfc_ens_val_pred = [1 if x >= threshold else 0 for x in rfc_ens_val_prob]\nrfc_ens_acc, rfc_ens_auc, rfc_ens_f1 = evaluate_model_performnce(val_y, rfc_ens_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_ens_prob = ensembling_engine(trained_clfs, train_x, train_y, test_x, ensembler)\nrfc_ens_prob = pd.DataFrame(rfc_ens_prob)[1]\n#rfc_ens_prob\nrfc_ens_sub = make_submission_file(dataset+\"rfc_ens.csv\", rfc_ens_prob, test_id, IdCol, targetCol, threshold=0.5)\nrfc_ens_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3) Gradient Booster\n\nLet's try with gradient booster. We'll do ensembling on Validation Set and then evaluate it!"},{"metadata":{"trusted":true},"cell_type":"code","source":"ensembler = GradientBoostingClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbc_ens_val_prob = ensembling_engine(trained_clfs, train_x, train_y, val_x, ensembler)\ngbc_ens_val_prob = pd.DataFrame(gbc_ens_val_prob)[1]\nthreshold = 0.4\ngbc_ens_val_pred = [1 if x >= threshold else 0 for x in gbc_ens_val_prob]\ngbc_ens_acc, gbc_ens_auc, gbc_ens_f1 = evaluate_model_performnce(val_y, gbc_ens_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbc_ens_prob = ensembling_engine(trained_clfs, train_x, train_y, test_x, ensembler)\ngbc_ens_prob = pd.DataFrame(gbc_ens_prob)[1]\n#gbc_ens_prob\ngbc_ens_sub = make_submission_file(\"gbc_ens.csv\", gbc_ens_prob, test_id, IdCol, targetCol, threshold=0.5)\ngbc_ens_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next two methods are used on untrained-classifier.\n\n### 3) VotingClassifier\n\nIt's a hard/soft Voting/Majority Rule classifier for unfitted estimators. In ‘hard’ mode, it uses predicted class labels for majority rule voting. Else if ‘soft’, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers. It's available in sklearn."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v_xgb = XGBClassifier()\nv_lgb = LGBMClassifier()\nv_cat = CatBoostClassifier(verbose=0)\n\nv_clf = VotingClassifier(estimators=[('xgb', v_xgb), ('lgb', v_lgb), ('cat', v_cat)], voting='soft')\nv_clf.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.4\nv_val_prob = v_clf.predict_proba(val_x)\nv_val_prob = pd.DataFrame(v_val_prob)[1]\nv_val_pred = [1 if x >= threshold else 0 for x in v_val_prob]\nv_acc, v_auc, v_f1 = evaluate_model_performnce(val_y, v_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making prediction on leaderboard dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"v_prob = v_clf.predict_proba(test_x)\nv_prob = pd.DataFrame(v_prob)[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Writing submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"v_sub = make_submission_file(dataset+\"_voting_ens.csv\", v_prob, test_id, IdCol, targetCol, threshold=0.5)\nv_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4) StackingClassifier\n\nStacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator. So basically what we have implemented in technique 2 is similar to stacking classifier. It's readily available in sklearn."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"st_xgb = XGBClassifier()\nst_lgb = LGBMClassifier()\nst_cat = CatBoostClassifier(verbose=0)\n\nst_clf = StackingClassifier(estimators=[('xgb', st_xgb), ('lgb', st_lgb), ('cat', st_cat)], \n                            final_estimator=GradientBoostingClassifier())\nst_clf.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.4\nst_val_prob = st_clf.predict_proba(val_x)\nst_val_prob = pd.DataFrame(st_val_prob)[1]\nst_val_pred = [1 if x >= threshold else 0 for x in st_val_prob]\nst_acc, st_auc, st_f1 = evaluate_model_performnce(val_y, st_val_pred) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making Prediction on leaderboard dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"st_prob = st_clf.predict_proba(test_x)\nst_prob = pd.DataFrame(st_prob)[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Writing submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"st_sub = make_submission_file(dataset+\"_stacking_ens.csv\", st_prob, test_id, IdCol, targetCol, threshold=0.5)\nst_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### These are some of the methods used for ensembling. If you found this kernel interesting consider UPVOTING it. Thanks! #Open_to_discussion.\n\n#### I have prepared another notebook on Hyper-parameter optimization that you may find insightful. Here - [Getting Started with Hyper-parameter Optimization](https://www.kaggle.com/pashupatigupta/getting-started-with-hyper-parameter-optimization). One highlight is that it talks about Bayesian Optimization in detail.\n\n### Happy Learning!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}