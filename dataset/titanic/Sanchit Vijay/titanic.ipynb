{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id = \"cont\"></a>\n# Contents:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. [ Importing libraries and Reading data](#sec1)\n2. [ Feature Engineering and Data Visualization](#sec2)\n    - [Some Visualizations](#subsec1)\n    - [Name Feature](#subsec2)\n    - [Age Feature](#subsec3)\n    - [Embarked Feature](#subsec4)\n    - [Cabin Feature](#subsec5)\n    - [Fare Feature](#subsec6)\n    - [Sex Feature](#subsec7)\n    - [Pclass Feature](#subsec8)\n    - [SibSp and Parch Feature](#subsec9)\n3. [ Train and Predict](#sec3)\n    - [Logistic Regression](#subsec11)\n    - [K Nearest Neighbors](#subsec12)\n    - [Support Vector Machines](#subsec13)\n    - [Decision Tree](#subsec14)\n    - [Random Forest](#subsec15)\n    - [Adaboost](#subsec16)\n    - [Gradient Boosting](#subsec17)\n    - [XGBoost](#subsec18)\n4. [ Accuracy Comparison through Plot](#sec4)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"sec1\"></a>\n# Importing Libraries and Reading Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport re\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/titanic/train.csv')\nprint(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/titanic/test.csv')\nprint(test_df.shape)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. **Numerical Columns: **Age(Continuous), Fare(Continuous), Sibsp(Discrete), Parch(Discrete)\n2. **Categorical Columns: **Survived, Sex, Embarked, Pclass\n3. **Other Columns: **PassengerID, Name, Ticket, Cabin","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"sec2\"></a>\n# Feature Engineering And Data Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec1\"></a>\n**Let's Visualize Data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Correlation in Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train_df.corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nfig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(20, 6))\nsns.barplot(x = 'SibSp', y = 'Survived', data = train_df, ax = ax1, palette='coolwarm')\nsns.barplot(x = 'Parch', y = 'Survived', data = train_df, ax = ax2, palette = 'magma')\nsns.barplot(x = 'Embarked', y = 'Survived', data = train_df, ax = ax3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\nfemales = train_df[train_df['Sex'] == 'female']\nmales = train_df[train_df['Sex'] == 'male']\n\nax = sns.distplot(females[females['Survived'] == 1].Age, bins=30, label='Survived', ax=axes[0])\nax = sns.distplot(females[females['Survived'] == 0].Age, bins=30, label='Not Survived', ax=axes[0])\nax.legend()\nax.set_title('Female')\nax = sns.distplot(males[males['Survived'] == 1].Age, bins=30, label='Survived', ax=axes[1])\nax = sns.distplot(males[males['Survived'] == 0].Age, bins=30, label='Not Survived', ax=axes[1], )\nax.legend()\nax.set_title('Male')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that where applicable we perform operations on both training and testing datasets together to stay consistent.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = [train_df, test_df]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec2\"></a>\n**Name Feature**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we'll extract titles(salutation) from the 'Name' feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in df:\n    data['Title'] = data['Name'].str.extract(r', (\\w+)\\.', expand=False)\npd.crosstab(train_df['Title'], train_df['Sex']).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most used titles are Mr, Miss, Master ,Mrs. Let's classify features into Mr, Miss, Master, Mrs and Rare.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in df:\n    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n    data['Title'] = data['Title'].replace('Ms', 'Miss')\n    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title']).mean()\n\nlabels = {'Mr':1, 'Mrs':2, 'Master':3, 'Miss':4, 'Rare':5}\ntest_df.replace({'Title':labels}, inplace = True)\ntrain_df.replace({'Title':labels}, inplace = True)\ntrain_df['Title'] = train_df['Title'].fillna(0)\ntrain_df['Title'] = train_df['Title'].astype(int)                     # this is performed beacuse it was giving float values of title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({'Train':train_df.isnull().sum(), 'Test':test_df.isnull().sum()}).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec3\"></a>\n**Age Feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Missing Values in Age column: ',177/len(train_df['Age'])*100)\nprint('Missing Values in Cabin column: ',687/len(train_df['Cabin'])*100)\nprint('Missing Values in Embarked column: ',2/len(train_df['Embarked'])*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Age column has ~20% of missing values. Age feature is pretty important to survival, so we should probably attempt to fill these gaps.\n* We will drop Cabin column because it's not possible to fill so many(77%) missing values.\n* Embarked column with just ~0.2% missing values won't causing any issue.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's visualize missing values using seaborn.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (15,5))\nsns.heatmap(train_df.isnull(), cmap = 'coolwarm', ax = ax1)\nsns.heatmap(test_df.isnull(), cmap = 'mako_r', ax = ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we'll fill in the missing values in the Age feature. Since a higher percentage of values are missing, it is outlandish to fill every one of them with a similar worth (as we did with Embarked). Rather, how about we attempt to figure out how to predict the missing ages.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Age\"] = train_df[\"Age\"].fillna(-0.5)\ntest_df[\"Age\"] = test_df[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain_df['AgeGroup'] = pd.cut(train_df[\"Age\"], bins, labels = labels)\ntest_df['AgeGroup'] = pd.cut(test_df[\"Age\"], bins, labels = labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mr_age = train_df[train_df[\"Title\"] == 1][\"AgeGroup\"].mode() #Young Adult\nmiss_age = train_df[train_df[\"Title\"] == 2][\"AgeGroup\"].mode() #Student\nmrs_age = train_df[train_df[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\nmaster_age = train_df[train_df[\"Title\"] == 4][\"AgeGroup\"].mode() #Baby\nrare_age = train_df[train_df[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult\n\nage_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\"}\n\nfor x in range(len(train_df[\"AgeGroup\"])):\n    if train_df[\"AgeGroup\"][x] == \"Unknown\":\n        train_df[\"AgeGroup\"][x] = age_title_mapping[train_df[\"Title\"][x]]\n        \nfor x in range(len(test_df[\"AgeGroup\"])):\n    if test_df[\"AgeGroup\"][x] == \"Unknown\":\n        test_df[\"AgeGroup\"][x] = age_title_mapping[test_df[\"Title\"][x]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = train_df[train_df['Survived'] == 0]\ndf_f = train_df[train_df['Survived'] == 1]\ndf_m = df_m['AgeGroup'].value_counts()\ndf_f = df_f['AgeGroup'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Not Survived', marker = dict(color = 'dodgerblue'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Survived', marker = dict(color = 'deeppink'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='Age Distribution')\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain_df['AgeGroup'] = train_df['AgeGroup'].map(age_mapping).astype(int)\ntest_df['AgeGroup'] = test_df['AgeGroup'].map(age_mapping).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec4\"></a>\n**Embarked Feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = train_df[train_df['Sex'] == 'male']\ndf_f = train_df[train_df['Sex'] == 'female']\ndf_m = df_m['Embarked'].value_counts()\ndf_f = df_f['Embarked'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Male', marker = dict(color = 'indigo'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Female', marker = dict(color = 'green'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='Embarked Distribution with Sex')\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = train_df[train_df['Survived'] == 0]\ndf_f = train_df[train_df['Survived'] == 1]\ndf_m = df_m['Embarked'].value_counts()\ndf_f = df_f['Embarked'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Male', marker = dict(color = 'burlywood'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Female', marker = dict(color = 'cadetblue'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='Embarked Distribution with Survived')\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Majority of people who survived embarked from S.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Embarked'].fillna('S', inplace = True)\n\nlabel = {'S':1, 'C':2, 'Q':3}\ntrain_df.replace({'Embarked':label}, inplace = True)\ntest_df.replace({'Embarked':label}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec5\"></a>\n**Cabin Feature**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I think the thought here is that individuals with recorded cabin numbers are of higher financial class, and in this manner bound to survive.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Cabin'] = train_df['Cabin'].fillna('X')\ntest_df['Cabin']=test_df['Cabin'].fillna('X')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will extract first letter of assigned cabin and then map it into a category.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in df:\n    data['Cabin'] = data['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    \ncategory = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'X':8, 'T':9}\nfor data in df:\n    data['Cabin'] = data['Cabin'].map(category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = train_df[train_df['Survived'] == 0]\ndf_f = train_df[train_df['Survived'] == 1]\ndf_m = df_m['Cabin'].value_counts()\ndf_f = df_f['Cabin'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Not Survived', marker = dict(color = 'chartreuse'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Survived', marker = dict(color = 'darkred'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='Cabin Distribution')\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec6\"></a>\n**Fare Feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Fare'].fillna(test_df['Fare'].median(), inplace = True)\n\ntrain_df['Fare'] = pd.qcut(train_df['Fare'], 4, labels = [1, 2, 3, 4])\ntest_df['Fare'] = pd.qcut(test_df['Fare'], 4, labels = [1, 2, 3, 4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = train_df[train_df['Survived'] == 0]\ndf_f = train_df[train_df['Survived'] == 1]\ndf_m = df_m['Fare'].value_counts()\ndf_f = df_f['Fare'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Not Survived', marker = dict(color = 'coral'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Survived', marker = dict(color = 'teal'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='Fare Distribution')\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#if we check the data info then fare feature is a category not int, so to convert we are performing this: \ntrain_df['Fare'] = pd.to_numeric(train_df['Fare'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec7\"></a>\n**Sex Feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = train_df[train_df['Sex'] == 'male']\ndf_f = train_df[train_df['Sex'] == 'female']\ndf_m = df_m['Survived'].value_counts()\ndf_f = df_f['Survived'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Male', marker = dict(color = 'lightseagreen'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Female', marker = dict(color = 'crimson'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='Survival Distribution')\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Women are more likely to survive than men.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"label = {'male':1, 'female':0}\ntrain_df.replace({'Sex':label}, inplace = True)\ntest_df.replace({'Sex':label}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id  = \"subsec8\"></a>\n**Pclass Feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = train_df[train_df['Survived'] == 0]\ndf_f = train_df[train_df['Survived'] == 1]\ndf_m = df_m['Pclass'].value_counts()\ndf_f = df_f['Pclass'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Not Survived', marker = dict(color = 'firebrick'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Survived', marker = dict(color = 'gold'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='Pclass Distribution', )\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People in first class are more likely to survive.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec9\"></a>\n**SibSp and Parch Feature**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As indicated by the Kaggle information word reference, both SibSp and Parch identify with going with family. For the wellbeing of simplicity (and to represent conceivable multicollinearity), I'll consolidate the impact of these variables into one categorical predictor: regardless of whether that individual was voyaging alone.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in df:\n    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in df:\n    data['IsAlone'] = 0\n    data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = train_df[train_df['Survived'] == 0]\ndf_f = train_df[train_df['Survived'] == 1]\ndf_m = df_m['IsAlone'].value_counts()\ndf_f = df_f['IsAlone'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Not Survived', marker = dict(color = 'seagreen'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Survived', marker = dict(color = 'aqua'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='IsAlone Distribution', )\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People who are alone are more likely to survive.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop the features PassengerId, Name, Age, SibSp, Parch, FamilySize and Ticket which won't be useful in prediction now.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(['PassengerId', 'Name', 'Ticket', 'Age', 'SibSp', 'Parch', 'FamilySize'], axis = 1, inplace = True)\ntest_df.drop(['Name', 'Ticket', 'Age', 'SibSp', 'Parch', 'FamilySize'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Now our data is ready to train.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop('Survived', axis = 1)\ny = train_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"sec3\"></a>\n# Train and Predict","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec11\"></a>\n**Logistic Regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\nlr_train_acc = round(lr.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', lr_train_acc)\nlr_test_acc = round(lr.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', lr_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec12\"></a>\n**K Nearest Neighbors**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate = []\nfor i in range(1,30):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n    \nplt.figure(figsize = (8,6))\nplt.plot(range(1,30), error_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\nknn_train_acc = round(knn.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', knn_train_acc)\nknn_test_acc = round(knn.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', knn_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec13\"></a>\n**Support Vector Machines**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use GridSearchCV to find best parameters\nsvc = SVC()\nparam_grid = {'C': [0.01, 0.1, 1 ,10 , 100], 'kernel':['linear', 'rbf'], 'gamma':[0.1, 1, 10, 100]}\ngcv = GridSearchCV(estimator = svc, param_grid = param_grid, cv = 5, n_jobs=-1, refit=True)\ngcv.fit(X_train, y_train)\ngcv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(C = 10, gamma = 0.1, kernel = 'rbf')\nsvc.fit(X_train,y_train)\ny_pred = svc.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\nsvc_train_acc = round(svc.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', svc_train_acc)\nsvc_test_acc = round(svc.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', svc_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec14\"></a>\nDecision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(max_depth = 6, min_samples_leaf = 2)\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\ndt_train_acc = round(dt.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', dt_train_acc)\ndt_test_acc = round(dt.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', dt_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec15\"></a>\n**Random Forest**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nparam_grid = {'max_depth': [2, 4, 5, 6, 7, 8], 'criterion':['gini', 'entropy'], 'min_samples_leaf':[1, 2 ,4 ,6], 'max_features':['auto', 'log2'], 'n_estimators':[100,150,200]}\ngcv = GridSearchCV(estimator=rf, param_grid=param_grid, cv = 5, n_jobs = -1)\ngcv.fit(X_train, y_train)\ngcv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(max_depth = 8, min_samples_leaf = 6, n_estimators = 150)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\nrf_train_acc = round(rf.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', rf_train_acc)\nrf_test_acc = round(rf.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', rf_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec16\"></a>\n**AdaBoost**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"adb = AdaBoostClassifier(rf, n_estimators = 200)\nadb.fit(X_train, y_train)\ny_pred = adb.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\nadb_train_acc = round(adb.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', adb_train_acc)\nadb_test_acc = round(adb.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', adb_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec17\"></a>\nGradient Boosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gdb = GradientBoostingClassifier()\nparams = {'learning_rate':[0.01,0.1,1,10],'n_estimators':[100,150,200,300],'subsample':[0.6,0.8,1.0],'max_depth':[2,3,4,6],'min_samples_leaf':[1,2,4,6]}\ngcv = GridSearchCV(estimator=gdb, param_grid=params, cv=5, n_jobs=-1)\ngcv.fit(X_train, y_train)\ngcv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gdb = GradientBoostingClassifier(max_depth = 2, n_estimators = 300, subsample = 0.8)\ngdb.fit(X_train, y_train)\ny_pred = gdb.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\ngdb_train_acc = round(gdb.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', gdb_train_acc)\ngdb_test_acc = round(gdb.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', gdb_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"subsec18\"></a>\nXGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbc = XGBClassifier(max_depth = 4)\nxgbc.fit(X_train, y_train)\ny_pred = xgbc.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\nxgbc_train_acc = round(xgbc.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', xgbc_train_acc)\nxgbc_test_acc = round(xgbc.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', xgbc_test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"sec4\"></a>\n# Accuracy Comparison through Plots","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = ['Logistic Regression', 'KNN', 'SVC', 'Decision Tree','Random Forest','AdaBoost','Gradient Boosting','XGBoost']\ny1 = [lr_train_acc, knn_train_acc, svc_train_acc, dt_train_acc, rf_train_acc, adb_train_acc, gdb_train_acc, xgbc_train_acc]\ny2 = [lr_test_acc, knn_test_acc, svc_test_acc, dt_test_acc, rf_test_acc, adb_test_acc, gdb_test_acc, xgbc_test_acc]\n\ntrace1 = go.Bar(x = x, y = y1, name = 'Training Accuracy', marker = dict(color = 'forestgreen'))\ntrace2 = go.Bar(x = x, y = y2, name = 'Testing Accuracy', marker = dict(color = 'lawngreen'))\ndata = [trace1,trace2]\nlayout = go.Layout(title = 'Accuracy Plot', width = 750)\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Fare'] = pd.to_numeric(test_df['Fare'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Survived'] = rf.predict(test_df.drop(['PassengerId'], axis = 1))\ntest_df[['PassengerId', 'Survived']].to_csv('MySubmission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Back to Contents(Click here)](#cont)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Please upvote if you think it's useful, any suggestions are welcome.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}