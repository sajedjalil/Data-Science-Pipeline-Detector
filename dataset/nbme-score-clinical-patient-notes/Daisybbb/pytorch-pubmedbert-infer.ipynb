{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoModel, AutoTokenizer\n#display options\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:09:44.838142Z","iopub.execute_input":"2022-04-24T02:09:44.83843Z","iopub.status.idle":"2022-04-24T02:09:44.846446Z","shell.execute_reply.started":"2022-04-24T02:09:44.838398Z","shell.execute_reply":"2022-04-24T02:09:44.843533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyperparameters = {\n    \"max_length\": 416,\n    \"padding\": \"max_length\",\n    \"return_offsets_mapping\": True,\n    \"truncation\": \"only_second\",\n    \"debug\": False,\n\n    \"model_name\": (\"../input/layoutlm/BiomedNLP-PubMedBERT\"\n                   \"-base-uncased-abstract-fulltext\"),\n    \"dropout\": 0.2,\n    \"encoder_lr\": 1e-5,\n    \"decoder_lr\": 1e-5,\n    \"weight_decay\": 0.01,\n    \"betas\": (0.9, 0.999),\n    \"lr\": 1e-5,\n    \n    \"seed\": 1268,\n    \"test_batch_size\": 2,\n    \"epochs\": 6,\n    \n    \"apex\": True,\n    \"eps\": 1e-6,\n    \n    \"n_fold\": 5,\n    \"trn_fold\": [1, 2, 3, 4, 5]\n}\nif hyperparameters['debug']:\n    hyperparameters['epochs'] = 2\n    hyperparameters['trn_fold'] = [1,2]","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:09:44.880865Z","iopub.execute_input":"2022-04-24T02:09:44.88118Z","iopub.status.idle":"2022-04-24T02:09:44.889564Z","shell.execute_reply.started":"2022-04-24T02:09:44.881149Z","shell.execute_reply":"2022-04-24T02:09:44.888881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_location_predictions(preds, offset_mapping, sequence_ids, test=False):\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        pred = 1 / (1 + np.exp(-pred))\n        start_idx = None\n        end_idx = None\n        current_preds = []\n        for pred, offset, seq_id in zip(pred, offsets, seq_ids):\n            if seq_id is None or seq_id == 0:\n                continue\n\n            if pred > 0.5:\n                if start_idx is None:\n                    start_idx = offset[0]\n                end_idx = offset[1]\n            elif start_idx is not None:\n                if test:\n                    current_preds.append(f\"{start_idx} {end_idx}\")\n                else:\n                    current_preds.append((start_idx, end_idx))\n                start_idx = None\n        if test:\n            all_predictions.append(\"; \".join(current_preds))\n        else:\n            all_predictions.append(current_preds)\n            \n    return all_predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:09:44.893941Z","iopub.execute_input":"2022-04-24T02:09:44.894408Z","iopub.status.idle":"2022-04-24T02:09:44.903297Z","shell.execute_reply.started":"2022-04-24T02:09:44.894367Z","shell.execute_reply":"2022-04-24T02:09:44.902327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'])\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:09:44.904901Z","iopub.execute_input":"2022-04-24T02:09:44.905319Z","iopub.status.idle":"2022-04-24T02:09:44.936364Z","shell.execute_reply.started":"2022-04-24T02:09:44.905281Z","shell.execute_reply":"2022-04-24T02:09:44.935628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_URL = \"../input/nbme-score-clinical-patient-notes\"\nTRAIN_URL = \"../input/pytorch-pubmedbert\"\n\ndef create_test_df():\n    feats = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    test = pd.read_csv(f\"{BASE_URL}/test.csv\")\n\n    merged = test.merge(notes, how=\"left\")\n    merged = merged.merge(feats, how=\"left\")\n\n    def process_feature_text(text):\n        return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \").replace(\"I-year\", \"1-year\")\n    \n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    return merged\n\n\nclass SubmissionDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        example = self.data.loc[idx]\n        tokenized = self.tokenizer(\n            example[\"feature_text\"],\n            example[\"pn_history\"],\n            truncation = self.config['truncation'],\n            max_length = self.config['max_length'],\n            padding = self.config['padding'],\n            return_offsets_mapping = self.config['return_offsets_mapping']\n        )\n        tokenized[\"sequence_ids\"] = tokenized.sequence_ids()\n\n        input_ids = np.array(tokenized[\"input_ids\"])\n        attention_mask = np.array(tokenized[\"attention_mask\"])\n        token_type_ids = np.array(tokenized[\"token_type_ids\"])\n        offset_mapping = np.array(tokenized[\"offset_mapping\"])\n        sequence_ids = np.array(tokenized[\"sequence_ids\"]).astype(\"float16\")\n\n        return input_ids, attention_mask, token_type_ids, offset_mapping, sequence_ids\n\n\ntest_df = create_test_df()\n\nsubmission_data = SubmissionDataset(test_df, tokenizer, hyperparameters)\nsubmission_dataloader = DataLoader(submission_data,\n                                   batch_size=hyperparameters['test_batch_size'],\n                                   pin_memory=True,\n                                   shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:09:44.937908Z","iopub.execute_input":"2022-04-24T02:09:44.938289Z","iopub.status.idle":"2022-04-24T02:09:45.237622Z","shell.execute_reply.started":"2022-04-24T02:09:44.938249Z","shell.execute_reply":"2022-04-24T02:09:45.236867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass CustomModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.model = AutoModel.from_pretrained(config['model_name']) \n        self.dropout = nn.Dropout(p=config['dropout'])\n        self.config = config\n        self.fc1 = nn.Linear(768, 512)\n        self.fc2 = nn.Linear(512, 512)\n        self.fc3 = nn.Linear(512, 1)\n        \n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.model(input_ids=input_ids,\n                            attention_mask=attention_mask,\n                            token_type_ids=token_type_ids)\n        logits = F.relu(self.fc1(outputs[0]))\n        logits = F.relu(self.fc2(self.dropout(logits)))\n        logits = self.fc3(self.dropout(logits)).squeeze(-1)\n        return logits\n    \nmodel = CustomModel(hyperparameters).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:09:45.239325Z","iopub.execute_input":"2022-04-24T02:09:45.239673Z","iopub.status.idle":"2022-04-24T02:09:46.533313Z","shell.execute_reply.started":"2022-04-24T02:09:45.23963Z","shell.execute_reply":"2022-04-24T02:09:46.532547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\noffsets = []\nseq_ids = []\nlogits_container = []\nfor batch in tqdm(submission_dataloader):\n    input_ids = batch[0].to(DEVICE)\n    attention_mask = batch[1].to(DEVICE)\n    token_type_ids = batch[2].to(DEVICE)\n    offset_mapping = batch[3]\n    sequence_ids = batch[4]\n\n    for fold in hyperparameters['trn_fold']:\n        model.load_state_dict(torch.load(f\"{TRAIN_URL}/nbme_pubmed_bert_fold{fold}.pth\"))\n        model.eval()\n        logits = model(input_ids, attention_mask, token_type_ids).detach().cpu().numpy()\n        logits_container.append(logits)\n    \n#     preds.append(logits.detach().cpu().numpy())\n#     print(logits_container)\n    preds.append(np.mean(logits_container,axis=0))\n    offsets.append(offset_mapping.numpy())\n    seq_ids.append(sequence_ids.numpy())\n\npreds = np.concatenate(preds, axis=0)\noffsets = np.concatenate(offsets, axis=0)\nseq_ids = np.concatenate(seq_ids, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:09:46.53668Z","iopub.execute_input":"2022-04-24T02:09:46.537332Z","iopub.status.idle":"2022-04-24T02:09:50.463241Z","shell.execute_reply.started":"2022-04-24T02:09:46.537288Z","shell.execute_reply":"2022-04-24T02:09:50.462567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"location_preds = get_location_predictions(preds, offsets, seq_ids, test=True)\ntest_df[\"location\"] = location_preds\ntest_df[[\"id\", \"location\"]].to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T02:09:50.465226Z","iopub.execute_input":"2022-04-24T02:09:50.465719Z","iopub.status.idle":"2022-04-24T02:09:50.487405Z","shell.execute_reply.started":"2022-04-24T02:09:50.465677Z","shell.execute_reply":"2022-04-24T02:09:50.486718Z"},"trusted":true},"execution_count":null,"outputs":[]}]}