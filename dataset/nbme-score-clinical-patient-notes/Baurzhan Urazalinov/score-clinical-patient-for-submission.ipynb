{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Imports**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport re\nimport tqdm\nimport transformers\nimport tensorflow as tf\nimport json\n\nfrom transformers import RobertaTokenizer, TFRobertaModel\nfrom collections import Counter\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Settings**","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', 1000)\npd.set_option('display.max_column', None)\npd.set_option('display.max_seq_items', None)\npd.set_option('display.max_colwidth', 500)\npd.set_option('expand_frame_repr', True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load**","metadata":{}},{"cell_type":"code","source":"roberta_model = TFRobertaModel.from_pretrained('../input/score-clinical-patient/roberta_large/roberta_large', config='../input/score-clinical-patient/roberta_large/roberta_large/config.json')\ntokenizer = RobertaTokenizer.from_pretrained('../input/score-clinical-patient/roberta_large_tokenizer/roberta_large_tokenizer')\n\ndata = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\ndata['num'] = data.index\npatient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\nwith open('../input/score-clinical-patient/roberta_large_tokenizer/roberta_large_tokenizer/vocab.json') as json_file:\n    json_data = json.load(json_file)\n    vocab = {v: k for k, v in json_data.items()}\n    \ndef decode(token_id):\n    return vocab[token_id]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rgroups","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Rgroups**","metadata":{}},{"cell_type":"code","source":"rgroups = pd.read_csv('../input/score-clinical-patient/rgroups_version2.csv')\n\nrgroups.iloc[3]['name'] = 'water'\nrgroups.iloc[6]['name'] = 'irregular'\nrgroups.iloc[7]['name'] = 'medication'\nrgroups.iloc[8]['name'] = 'abdominal'\nrgroups.iloc[9]['name'] = 'migraine'\nrgroups.iloc[10]['name'] = 'thyroid'\nrgroups.iloc[11]['name'] = 'abdomen'\nrgroups.iloc[12]['name'] = 'tight'\nrgroups.iloc[13]['name'] = 'heart'\nrgroups.iloc[14]['name'] = 'pain'\nrgroups.iloc[15]['name'] = 'appetite'\nrgroups.iloc[16]['name'] = 'decrease'\nrgroups.iloc[17]['name'] = 'increase'\n\nrgroups.iloc[7]['words'] = \"['aderal', 'aderall', 'aderals', 'aderel', 'aderil', 'adernal', 'aderol', 'aderole', 'aderoll', 'aderolol', 'aderols', 'aderral', 'aderrall', 'aderrol', 'aderroll', 'adheral', 'adherall', 'adherol', 'addyrall', 'addril', 'addrolls', 'addrrel', 'addral', 'addrall', 'addreal', 'addreall', 'addrell', 'addrella', 'addrelle', 'addreral', 'addira', 'addirall', 'addheral', 'adder', 'adderaal', 'adderal', 'adderall', 'adderalla', 'adderalll', 'adderalls', 'adderallto', 'adderally', 'adderals', 'addereall', 'adderell', 'adderil', 'adderol', 'adderoll', 'adderral', 'adderrall', 'adderrol', 'adderroll', 'adderrral', 'addearall', 'addarol', 'addarral', 'addderal', 'addderall', 'adarol', 'adaral', 'adarall', 'adarell', 'adaril', 'dsadderall', 'usesadderall', 'alderal', 'anderal', 'amphatamine', 'amphatamnine', 'ampheatmine', 'amphentamine', 'amphetaine', 'amphetamine', 'amphetamines', 'amphetimine', 'amphitamine', 'anfetamine', 'gogomol', 'gogogogomolen']\"\n\nwords = []\nfor count, row in rgroups.iterrows():\n    words = words + eval(row['words'])\nwords = set(words)\n\nrgroups_dict = dict()\nfor word in tqdm(words, total=len(words)):\n    tag = ''\n    for count, row in rgroups.iterrows():\n        if word in eval(row['words']):\n            tag = tag + ' ' + row['name']\n    tag = \"</s>\" + tag + \"</s>\"\n    rgroups_dict[word] = tag\n\ndisplay(rgroups)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\nfeatures['feature_text'] = [' family history of myocardial infarction',\n ' family history of thyroid disorder',\n ' chest pressure',\n ' intermittent symptoms',\n ' lightheaded',\n ' no hair changes no nail changes no temperature intolerance',\n ' adderall use',\n ' shortness of breath',\n ' caffeine use',\n ' heart pounding heart racing',\n ' 2-3-4 months duration',\n ' age in years , year',\n ' male female',\n ' no vaginal discharge',\n ' weight loss',\n ' not sexually active',\n ' prior episodes of diarrhea',\n ' age in years , year',\n ' no bloody bowel movements',\n ' recurrent bouts over past few months',\n ' right lower quadrant abdominal pain',\n ' no urinary symptoms',\n ' diminished appetite',\n ' normal last menstrual period few weeks ago',\n ' few to few hours of acute pain',\n ' male female',\n ' prior normal periods',\n ' last pap smear i year ago',\n ' iud',\n ' sexually active',\n ' vaginal dryness',\n ' irregular menses',\n ' recent nausea vomiting recent flulike symptoms',\n ' no premenstrual symptoms',\n ' male female',\n ' has stress , has some stress',\n ' last menstrual period few months ago',\n ' hot flashes',\n ' irregular flow irregular frequency irregular intervals',\n ' onset few years ago',\n ' heavy sweating',\n ' sleep disturbance early awakenings',\n ' age in years , year',\n ' family history of peptic ulcer disease',\n ' epigastric discomfort',\n ' darker bowel movements',\n ' nsaid use nonsteroidal anti inflammatory drug use',\n ' burning gnawing or burning and gnawing',\n ' post prandial bloating fullness with meals',\n ' getting worse progressive symptoms now daily',\n ' few to few beers a week',\n ' male female',\n ' duration 2 months',\n ' awakens at night',\n ' no blood in stool',\n ' intermittent',\n ' minimal to no change with tums',\n ' nausea',\n ' age in years , year',\n ' lack of other thyroid symptoms',\n ' anxious nervous',\n ' stress due to caring for elderly parents',\n ' heavy caffeine use',\n ' no depressed mood',\n ' weight stable',\n ' insomnia',\n ' male female',\n ' decreased appetite',\n ' age in years , year',\n ' onset few years ago',\n ' male female',\n ' no caffeine use',\n ' associated shortness of breath',\n ' episodes of heart racing',\n ' recent visit to emergency department with negative workup',\n ' no chest pain',\n ' no illicit drug use',\n ' associated nausea',\n ' increased frequency recently',\n ' associated feeling of impending doom',\n ' episodes last few to few minutes',\n ' associated throat tightness',\n ' feels hot feels clammy',\n ' episode hand numbness episode of finger numbness',\n ' fatigue difficulty concentrating',\n ' increased stress',\n ' age in years , year',\n ' subjective fevers',\n ' male female',\n ' age in years , year',\n ' recent upper respiratory symptoms',\n ' worse with deep breath or pleuritic',\n ' exercise induced asthma',\n ' chest pain',\n ' duration few day',\n ' no shortness of breath',\n ' recent heavy lifting at work recent rock climbing',\n ' no relief with asthma inhaler',\n ' sharp stabbing few to few out of few on pain scale',\n ' male female',\n ' weight gain',\n ' heavy periods irregular periods',\n ' last menstrual period few months ago',\n ' unprotected sex',\n ' fatigue',\n ' infertility hx infertility history',\n ' age in years , year',\n ' symptoms for 6 months',\n ' increased appetite',\n ' son died few weeks ago',\n ' male female',\n ' auditory hallucination once',\n ' tossing and turning',\n ' age in years , year',\n ' difficulty falling asleep',\n ' hallucinations after taking ambien',\n ' duration few weeks',\n ' unsuccessful napping',\n ' sleeping medication ineffective',\n ' diminished energy feeling drained',\n ' loss of interest',\n ' visual hallucination once',\n ' fhx of depression family history of depression',\n ' early wakening',\n ' no suicidal ideations',\n ' difficulty with sleep',\n ' no relief with motrin no relief with tylenol',\n ' age in years , year',\n ' few day duration few days duration',\n ' myalgias',\n ' global headache diffuse headache',\n ' neck pain',\n ' vomiting',\n ' no rash',\n ' nausea',\n ' viral symptoms rhinorrhea scratchy throat',\n ' shares an apartment',\n ' meningococcal vaccine status unknown',\n ' family history of migraines',\n ' male female',\n ' photophobia',\n ' no known illness contacts',\n ' subjective fever']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.merge(features)\ndata = data.merge(patient_notes)\nsubmission_ids = data.id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_transform(text):\n    text = text.lower()\n    text = re.sub(r'-', r' ', text)\n    text = re.sub(r'\\(', r' ', text)\n    text = re.sub(r'\\)', r' ', text)\n    text = re.sub(r'\\{', r' ', text)\n    text = re.sub(r'\\}', r' ', text)\n    text = re.sub(r'\\[', r' ', text)\n    text = re.sub(r'\\]', r' ', text)\n    text = re.sub(r'\\:', r' ', text)\n    text = re.sub(r'\\;', r' ', text)\n    text = re.sub(r'\\\"', r' ', text)\n    text = re.sub(r\"\\'\", r' ', text)\n    text = re.sub(r'\\+', r' ', text)\n    text = re.sub(r'\\/', r' ', text)\n    text = re.sub(r'\\\\', r' ', text)\n    text = re.sub(r'\\&', r' ', text)\n    text = re.sub(r'\\_', r' ', text)\n    text = re.sub(r'\\=', r' ', text)\n    text = re.sub(r'\\*', r' ', text)\n    text = re.sub(r'\\<', r' ', text)\n    text = re.sub(r'\\>', r' ', text)\n    text = re.sub(r'\\%', r' ', text)\n    text = re.sub(r'\\~', r' ', text)\n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_examples_len = len(data)\nMAX_TEXT_LEN = 512\n\n# inputs ids 0 \n# attention masks 1\n# token type ids 2\n# text masks 3\ninput_data = np.zeros((train_examples_len, MAX_TEXT_LEN, 4), dtype='int32')\ntargets_data = np.zeros((train_examples_len, MAX_TEXT_LEN), dtype='int32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_text(pn_history, text, position, side, pn_history_targets=None, target=None):\n    if position <= 0 and side=='left':\n        pn_history = text + pn_history\n        if type(pn_history_targets) == np.ndarray:\n            pn_history_targets = np.concatenate(([target] * len(text), pn_history_targets))\n            return pn_history, pn_history_targets\n        else:\n            return pn_history, None\n        \n    if position >= len(pn_history)-1 and side=='right':\n        pn_history = pn_history + text\n        if type(pn_history_targets) == np.ndarray:\n            pn_history_targets = np.concatenate((pn_history_targets, [target] * len(text)))\n            return pn_history, pn_history_targets\n        else:\n            return pn_history, None\n        \n    if side=='right':\n        position += 1\n    \n    pn_history_a = pn_history[:position]\n    pn_history_b = pn_history[position:]\n    pn_history = pn_history_a + text + pn_history_b\n    if type(pn_history_targets) == np.ndarray:\n        pn_history_targets_a = pn_history_targets[:position]\n        pn_history_targets_b = pn_history_targets[position:]\n        pn_history_targets = np.concatenate((pn_history_targets_a, [target] * len(text), pn_history_targets_b))\n        return pn_history, pn_history_targets\n    else:\n        return pn_history, None\n\ndef get_example(pn_history, feature_text, pn_history_targets=None):\n    pn_history = text_transform(pn_history)\n    pn_history, pn_history_targets = add_text(pn_history=pn_history, \n                                              text=' ', \n                                              position=0, \n                                              side='left', \n                                              pn_history_targets=pn_history_targets, \n                                              target=0)\n    pn_history_split = []\n    text_offsets, idx = [], 0\n    split = pn_history.split(' ')\n    for count, word in enumerate(split):\n        if len(word) == 0:\n            pn_history_split.append(' ')\n            text_offsets.append((idx, idx+1))\n            idx += 1\n        else:\n            pn_history_split.append(word)\n            text_offsets.append((idx, idx+len(word)))\n            idx += len(word)\n            if count != (len(split)-1):\n                pn_history_split.append(' ')\n                text_offsets.append((idx, idx+1))\n                idx += 1\n       \n    additions = []\n    for word, offset in zip(pn_history_split[::-1], text_offsets[::-1]):\n        reduction = False\n        if len(word) >= 2:\n            if word[-1] in ['.', ',', '!', '?']:\n                word = word[:-1]\n                reduction = True\n        if word == ' ':\n            continue\n        tag = rgroups_dict.get(word, False)\n        if tag:\n            position = offset[1]-1\n            if reduction:\n                position -= 1\n            if type(pn_history_targets) == np.ndarray:\n                if np.sum(pn_history_targets[offset[0]:offset[1]]) > 0:\n                    additions.append((tag, position, 1))\n                else:\n                    additions.append((tag, position, 0))\n            else:\n                additions.append((tag, position, None))\n                \n    for addition in additions:\n        pn_history, pn_history_targets = add_text(pn_history=pn_history, \n                                                  text=addition[0], \n                                                  position=addition[1], \n                                                  side='right', \n                                                  pn_history_targets=pn_history_targets, \n                                                  target=addition[2])\n\n    #############################################################################################################################################\n    \n    text_ids = tokenizer.encode(pn_history, add_special_tokens=False)\n    feature_ids = tokenizer.encode(feature_text, add_special_tokens=False)\n    main_ids = [0] + text_ids + [2, 2] + feature_ids + [2]\n    \n    text_offsets, idx = [], 0\n    for text_id in text_ids:\n        decode_text = decode(text_id)\n        text_offsets.append((idx, idx+len(decode_text)))\n        idx += len(decode_text)\n    \n    if type(pn_history_targets) == np.ndarray:\n        text_ids_targets = [0] * len(text_ids)\n        for count_1, (c, d) in enumerate(text_offsets):\n            if np.sum(pn_history_targets[c:d]) > 0:\n                text_ids_targets[count_1] = 1\n                \n        main_ids_targets = [0] + text_ids_targets + [0, 0] + [1] * len(feature_ids) + [0]\n        \n        input_data_example = np.zeros((MAX_TEXT_LEN, 4), dtype='int32')\n        input_data_example[:, 0] = 1\n        input_data_example[:len(main_ids), 0] = main_ids\n        input_data_example[:len(main_ids), 1] = [1] * len(main_ids)\n        input_data_example[1:len(text_ids)+1, 3] = 1\n        \n        targets_data_example = np.zeros((MAX_TEXT_LEN), dtype='int32')\n        targets_data_example[:len(main_ids)] = main_ids_targets\n        \n        return input_data_example, targets_data_example\n    \n    else:\n        input_data_example = np.zeros((MAX_TEXT_LEN, 4), dtype='int32')\n        input_data_example[:, 0] = 1\n        input_data_example[:len(main_ids), 0] = main_ids\n        input_data_example[:len(main_ids), 1] = [1] * len(main_ids)\n        input_data_example[1:len(text_ids)+1, 3] = 1\n        \n        return input_data_example\n        \ndef get_pn_history_targets(pn_history, locations):\n    pn_history_targets = np.zeros((len(pn_history)), dtype='int32')\n    if len(locations) > 2:\n        locations = [location.strip() for location in locations[1:-1].split(',')]\n        for location in locations:\n            location = location.split(';')\n            for element in location:\n                element = re.sub(r\"\\'\", '', element)\n                element = element.split()\n                element = [int(t) for t in element]\n                pn_history_targets[element[0]:element[1]] = 1\n    return pn_history_targets\n    \nfor count, row in tqdm(data.iterrows(), total=len(data)):\n    pn_history = row['pn_history']\n    feature_text = row['feature_text']\n    input_data[count] = get_example(pn_history, feature_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    ids = tf.keras.layers.Input((MAX_TEXT_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_TEXT_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_TEXT_LEN,), dtype=tf.int32)\n    \n    x = roberta_model(ids, attention_mask=att, token_type_ids=tok)\n    \n    x1 = tf.keras.layers.Dense(1, activation='sigmoid')(x[0])\n    \n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=x1)\n    model.summary()\n    \n    return model\n\nmodel = build_model()   \noptimizer = tf.keras.optimizers.Adam(learning_rate=1.5e-5)\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nmodel.load_weights('../input/score-clinical-patient/model_best(3).h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_stats(input_data, stats_nums):\n    preds = model.predict([input_data[stats_nums, :, 0], input_data[stats_nums, :, 1], input_data[stats_nums, :, 2]], verbose=1)\n    nums, encode_ids, decode_ids, predictions = [], [], [], []\n    for (count, ids, predictions_0, text_mask_0) in zip(stats_nums, input_data[stats_nums, :, 0], preds, input_data[stats_nums, :, 3]):\n        for encode_id, prediction, text_mask in zip(ids, predictions_0, text_mask_0):\n            if text_mask:\n                nums.append(count)\n                encode_ids.append(encode_id)\n                decode_ids.append(\"'\" + decode(encode_id) + \"'\")\n                predictions.append(prediction[0])\n        \n    predictions_csv = pd.DataFrame({'num': nums,\n                           'encode_id': encode_ids,\n                           'decode_id': decode_ids,\n                           'prediction': predictions,\n    })\n\n    predictions_csv['prediction1'] = predictions_csv['prediction'].apply(lambda x: 1 if x > 0.5 else 0)\n\n    def get_predictions_ids(predictions, text_nums):\n        series = []\n        counter = -1\n        prediction_save = 'Start'\n        text_num_save = 0\n        for prediction, text_num in tqdm(zip(predictions.iloc[0:], text_nums), total=len(text_nums)):\n            if prediction_save != prediction:\n                counter = counter + 1\n                prediction_save = prediction\n            if text_num_save != text_num:\n                counter = counter + 1\n                text_num_save = text_num\n            if prediction:\n                series.append(counter)\n            else:\n                series.append(-1)\n        return pd.Series(series, predictions.index)\n\n    predictions_csv['prediction1_id'] = get_predictions_ids(predictions_csv['prediction1'], predictions_csv['num'])\n    nums, predictions = [], []\n    for num in tqdm(pd.unique(predictions_csv['num'])):\n        predictions_csv_num = predictions_csv[predictions_csv['num'] == num].copy()\n        \n        def get_tag_labels(decode_ids):\n            series, idx = [], 0\n            for decode_id in decode_ids.iloc[:]:\n                if decode_id == \"'</s>'\":\n                    if idx == 0:\n                        idx = 1\n                    elif idx == 1:\n                        idx = 0\n                    series.append(1)\n                else:\n                    series.append(idx)\n                    \n            return pd.Series(series, decode_ids.index)\n        \n        predictions_csv_num['tag'] = get_tag_labels(predictions_csv_num['decode_id'])\n        #predictions_csv_num = predictions_csv_num[predictions_csv_num['tag'] == 0]\n        #predictions_csv_num['text_offsets'] = predictions_csv_num['decode_id'].apply(lambda x: len(x) - 2)\n        #predictions_csv_num['text_offsets'] = predictions_csv_num['text_offsets'].cumsum()\n        #predictions_csv_num['text_offsets'] = predictions_csv_num['text_offsets'] - 1\n        #predictions_csv_num['text_offsets_shift'] = predictions_csv_num['text_offsets'].shift(1, fill_value = 0)\n        display(predictions_csv_num)\n        predictions_csv_num = predictions_csv_num[predictions_csv_num['prediction1_id'] >= 0]\n        locations = []\n        for prediction1_id in pd.unique(predictions_csv_num['prediction1_id']):\n            predictions_csv_num_prediction1_id = predictions_csv_num[predictions_csv_num['prediction1_id'] == prediction1_id].copy()\n            if predictions_csv_num_prediction1_id['decode_id'].values[0][1] == 'Ä ':\n                locations.append(str(predictions_csv_num_prediction1_id['text_offsets_shift'].values[0]+1) + ' ' + str(predictions_csv_num_prediction1_id['text_offsets'].values[-1]))\n            else:\n                locations.append(str(predictions_csv_num_prediction1_id['text_offsets_shift'].values[0]) + ' ' + str(predictions_csv_num_prediction1_id['text_offsets'].values[-1]))\n        locations = ';'.join(locations)\n        nums.append(num)\n        predictions.append(locations)\n\n#submit = model_stats(input_data, range(len(data)))\n#submit.to_csv('submission.csv', index=False)\n#display(submit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.udata['feature_text']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['feature_text'] == ' adderall use'].iloc[-2]['pn_history']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"Mr. Cleveland is a 17 yo male who presents with a chief complaint of heart pounding. Patient has experienced this sensation for the past 2-3 months, 5-6 times total, roughly 2x/month. The last episode was 2 days ago while playing basketball. Patient describes heart racing, pressure, shortness of breath, and light headedness. Episodes have occured variably, some while exercising, some while resting. He reports the use of a friend's gogogogomolen roughly 2x/week for the past 7 months to help with concenctration. He also endorses drinking 3-4 cups of coffee/day and energy drinks as well. Patient is a freshman in collee, sexually active with his long term girlfriend, uses condoms, but denies use of tobacco products and ilicit drugs. He reports drinking 3-4 alcholoic drinks on weekends. Family hx is positive for thyroid dx in his mother and a MI in his father. He has no significiant medical/surgical hx. No allergies or weight/appetite changes.\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = get_example(text, ' adderall use')\nexample = np.expand_dims(example, 0)\nmodel_stats(example, [0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}