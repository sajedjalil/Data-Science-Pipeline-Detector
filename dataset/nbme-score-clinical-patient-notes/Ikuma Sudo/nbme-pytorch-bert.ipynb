{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# æ¦‚è¦\nã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯[Pytorch Bert baseline NBME by Shudipto Trafder](https://www.kaggle.com/iamsdt/pytorch-bert-baseline-nbme/notebook)ã‚’éå¸¸ã«å‚è€ƒã«ã—ãªãŒã‚‰ï¼Œå„ã‚³ãƒ¼ãƒ‰ã®å‹•ä½œã‚„æ„å›³ã«ã¤ã„ã¦ã®ç§ã®ç†è§£ã‚„ãƒ¡ãƒ¢ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ï¼\n\nç§ãŒä¸Šã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ç†è§£ã™ã‚‹ã¾ã§ã«å­¦ã‚“ã ã“ã¨ã‚„èª¿ã¹ãŸã“ã¨ã‚’æ›¸ã„ã¦ã„ã¾ã™ï¼ç§ã¨åŒã˜ã‚ˆã†ãªåˆå¿ƒè€…ã®æ–¹ã®å‚è€ƒã«ãªã‚Œã°å¹¸ã„ã§ã™ï¼\n\né–“é•ã„ã®æŒ‡æ‘˜ã‚„è³ªå•ãªã©ã‚ã‚Œã°ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰ãŠé¡˜ã„ã—ã¾ã™ï¼\n\nã‚‚ã—ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’æ°—ã«å…¥ã£ã¦ã„ãŸã ã‘ãŸã‚‰ï¼ŒUP VOTEã‚’ãŠé¡˜ã„ã—ã¾ã™ğŸ‰","metadata":{}},{"cell_type":"code","source":"from ast import literal_eval\nfrom itertools import chain\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoModel, AutoTokenizer","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-03-02T02:59:11.109094Z","iopub.execute_input":"2022-03-02T02:59:11.109499Z","iopub.status.idle":"2022-03-02T02:59:13.534794Z","shell.execute_reply.started":"2022-03-02T02:59:11.109471Z","shell.execute_reply":"2022-03-02T02:59:13.533924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª","metadata":{}},{"cell_type":"code","source":"features = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/features.csv\")\nnotes = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/patient_notes.csv\")\ntrain = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/train.csv\")\ntest = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:13.537513Z","iopub.execute_input":"2022-03-02T02:59:13.538022Z","iopub.status.idle":"2022-03-02T02:59:14.19689Z","shell.execute_reply.started":"2022-03-02T02:59:13.537982Z","shell.execute_reply":"2022-03-02T02:59:14.196141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`patient_notes.csv`ã«ã¯patient notesï¼ˆã‚«ãƒ«ãƒ†ï¼‰ãŒå…¥ã£ã¦ã„ã¾ã™ï¼å„ã‚«ãƒ«ãƒ†ã«ã¯`pn_num`ï¼ˆã‚«ãƒ«ãƒ†ç•ªå·ï¼‰ï¼Œ`case_num`ï¼ˆç—‡çŠ¶ç•ªå·ï¼‰ãŒå‰²ã‚ŠæŒ¯ã‚‰ã‚Œã¦ã„ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"notes","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:14.198058Z","iopub.execute_input":"2022-03-02T02:59:14.198334Z","iopub.status.idle":"2022-03-02T02:59:14.219929Z","shell.execute_reply.started":"2022-03-02T02:59:14.198294Z","shell.execute_reply":"2022-03-02T02:59:14.219199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`features.csv`ã«ã¯ï¼Œå„caseã”ã¨ã«é‡è¦ãªfeatureï¼ˆç‰¹å¾´ï¼Œç—‡çŠ¶ï¼‰ãŒå…¥ã£ã¦ã„ã¾ã™ï¼`feature_text`ã¯ãã®featureã®èª¬æ˜ã§ï¼Œä¾‹ãˆã°\"Chest-pressure\"ï¼ˆèƒ¸ã®åœ§è¿«æ„Ÿï¼‰ã‚„\"Photophobia\"ï¼ˆå¼·ã„å…‰ã‚’å—ã‘ãŸéš›ã«ä¸å¿«æ„Ÿã‚„çœ¼ã®ç—›ã¿ãªã©ã‚’ç”Ÿã˜ã‚‹ã“ã¨ï¼‰ãªã©ãŒã‚ã‚Šã¾ã™ï¼\n\n`feature_num`ã®å…ˆé ­ã¯`case_num`ã«å¯¾å¿œã—ã¦ã„ã¾ã™ï¼ˆ`case_num`ãŒ0ã®å ´åˆã‚’é™¤ãï¼‰ï¼","metadata":{}},{"cell_type":"code","source":"features","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:14.222031Z","iopub.execute_input":"2022-03-02T02:59:14.22299Z","iopub.status.idle":"2022-03-02T02:59:14.235993Z","shell.execute_reply.started":"2022-03-02T02:59:14.222956Z","shell.execute_reply":"2022-03-02T02:59:14.234942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`train.csv`ã«ã¯ï¼Œã‚«ãƒ«ãƒ†ã®ä¸­ã§å„featureã«å¯¾å¿œã™ã‚‹è¨˜è¿°`annotation`ã¨ãã®ä½ç½®`location`ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼\n\nã¾ãŸannotaionã‚„locationã®ä¸­èº«ã¯`\"['dad with recent heart attcak']\"`ã‚„`\"['696 724']\"`ã®ã‚ˆã†ãªæ–‡å­—åˆ—ã«ãªã£ã¦ã„ã¾ã™ï¼\n","metadata":{}},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:14.237615Z","iopub.execute_input":"2022-03-02T02:59:14.238215Z","iopub.status.idle":"2022-03-02T02:59:14.254897Z","shell.execute_reply.started":"2022-03-02T02:59:14.238126Z","shell.execute_reply":"2022-03-02T02:59:14.254122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ä¾‹ãˆã°ï¼Œ`id`ãŒ`00016_002`ã®`annotaion`ã¯`\"chest pressure\"`ï¼Œ`location`ã¯`[203 217]`ã¨ãªã£ã¦ã„ã¾ã™ï¼\n\nå®Ÿéš›ï¼Œã‚«ãƒ«ãƒ†ã®ä¸­ã‹ã‚‰`location`ã®ç¯„å›²ã‚’å–ã‚Šå‡ºã—ã¦ã¿ã‚‹ã¨ï¼Œ`annnotaion`ã«ä¸€è‡´ã—ã¦ã„ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"notes[notes[\"pn_num\"]==16][\"pn_history\"].iloc[0][203:217]","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:14.256215Z","iopub.execute_input":"2022-03-02T02:59:14.256488Z","iopub.status.idle":"2022-03-02T02:59:14.266433Z","shell.execute_reply.started":"2022-03-02T02:59:14.256455Z","shell.execute_reply":"2022-03-02T02:59:14.265624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"featureã«ã‚ˆã£ã¦ã¯ã‚«ãƒ«ãƒ†ä¸­ã«annotationãŒå­˜åœ¨ã—ãªã„å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼\n\né€†ã«ï¼‘ã¤ã®featureã«å¯¾ã—ã¦è¤‡æ•°ã®annotaionãŒã‚ã£ãŸã‚Šï¼Œ1ã¤ã®annotationãŒè¤‡æ•°ç®‡æ‰€ã«åˆ¥ã‚Œã¦å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"train[(train[\"id\"]==\"00211_000\")|(train[\"id\"]==\"00100_010\")]","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:14.267914Z","iopub.execute_input":"2022-03-02T02:59:14.268445Z","iopub.status.idle":"2022-03-02T02:59:14.287231Z","shell.execute_reply.started":"2022-03-02T02:59:14.268407Z","shell.execute_reply":"2022-03-02T02:59:14.285843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ã¾ãŸï¼Œã™ã¹ã¦ã®ã‚«ãƒ«ãƒ†ã«å¯¾ã—ã¦annotationãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã‚ˆã†ã§ã™ï¼`train.csv`ã«å«ã¾ã‚Œã¦ã„ã‚‹ï¼Œã¤ã¾ã‚ŠannotationãŒå­˜åœ¨ã—ã¦ã„ã‚‹ã‚«ãƒ«ãƒ†ã®æ•°ã‚’èª¿ã¹ã¦ã¿ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"len(train[\"pn_num\"].unique())","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:14.289021Z","iopub.execute_input":"2022-03-02T02:59:14.289214Z","iopub.status.idle":"2022-03-02T02:59:14.298456Z","shell.execute_reply.started":"2022-03-02T02:59:14.289192Z","shell.execute_reply":"2022-03-02T02:59:14.297682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`test.csv`ã«ã¯äºˆæ¸¬å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã¾ã™ï¼å„è¡Œã«ã¯ã‚«ãƒ«ãƒ†ç•ªå·`pn_num`ï¼Œcaseç•ªå·`case_num`ï¼Œfeatureç•ªå·`feature_num`ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼\n\nãªãŠã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ€ãƒŸãƒ¼ã§ï¼Œæå‡ºæ™‚ã«æœ¬ç‰©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ç½®ãæ›ãˆã‚‰ã‚Œã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:14.299866Z","iopub.execute_input":"2022-03-02T02:59:14.300653Z","iopub.status.idle":"2022-03-02T02:59:14.310221Z","shell.execute_reply.started":"2022-03-02T02:59:14.300616Z","shell.execute_reply":"2022-03-02T02:59:14.309503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ã“ã“ã§ã¯ãƒ‡ãƒ¼ã‚¿ã®ä¸­èº«ã‚„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèªã—ã¾ã—ãŸï¼è©³ç´°ã‚„EDAã«é–¢ã—ã¦ã¯ã™ã§ã«æ§˜ã€…ãªãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãŒå­˜åœ¨ã—ã¦ã„ã¾ã™ï¼\n\n* https://www.kaggle.com/drcapa/nbme-starter\n* https://www.kaggle.com/utcarshagrawal/nbme-complete-eda\n* https://www.kaggle.com/yufuin/nbme-japanese","metadata":{}},{"cell_type":"markdown","source":"ã“ã®å…ˆï¼Œè‡ªç„¶è¨€èªå‡¦ç†ã¨HuggingFaceã®å„ç¨®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆä¸»ã«Transformersï¼‰ã®çŸ¥è­˜ãŒã‚ã‚‹ç¨‹åº¦å¿…è¦ã«ãªã£ã¦ãã¾ã™ï¼\n\nç§ã¯å®Œå…¨ã«ç´ äººã§ã™ãŒï¼Œã“ã®ã‚³ãƒ³ãƒšã«å‚åŠ ã™ã‚‹ç›´å‰ã«å¶ç„¶èª­ã‚“ã§ã„ãŸ[HuggingFaceã®ã‚³ãƒ¼ã‚¹](https://huggingface.co/course)ã®ãŠã‹ã’ã§è‡ªç„¶è¨€èªå‡¦ç†ã‚„ğŸ¤— Transformersã®æœ€ä½é™ã®çŸ¥è­˜ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸï¼ˆå¾—ã‚‰ã‚ŒãŸæ°—ãŒã—ã¦ã„ã¾ã™ï¼‰ï¼é•·ã™ããšã‚ã‹ã‚Šã‚„ã™ã„å†…å®¹ãªã®ã§éå¸¸ã«ãŠã™ã™ã‚ã§ã™ï¼\n\nã‚ˆã‚Šè©³ç´°ãªèª¬æ˜ã¯[ğŸ¤—ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://huggingface.co/docs)ã‚„ï¼Œ[Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/)ãªã©ãŒå‚è€ƒã«ãªã‚Šã¾ã™ï¼","metadata":{}},{"cell_type":"markdown","source":"# å‰å‡¦ç†ãƒ»Datasetä½œæˆ\n## QA/NERãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n\nå‰å‡¦ç†ã‚„Datasetä½œæˆã®å‰ã«ï¼Œãƒ¢ãƒ‡ãƒ«ã®å…¥å‡ºåŠ›ã‚’æŠŠæ¡ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\n\nã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ™ãƒ¼ã‚¹ã«ãªã£ã¦ã„ã‚‹[Pytorch Bert baseline NBME](https://www.kaggle.com/iamsdt/pytorch-bert-baseline-nbme/notebook)ã§ã¯[QA/NER hybrid train ğŸš†](https://www.kaggle.com/nbroad/qa-ner-hybrid-train-nbme)ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹QA(Question Answering)ã¨NER(Named Entity Recognition)ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’åˆ©ç”¨ã—ã¦ã„ã¾ã™ï¼\n\nã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ï¼Œfeature_textï¼ˆfeatureã®èª¬æ˜ï¼‰ã¨ã‚«ãƒ«ãƒ†ã‚’åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã—ã¾ã™ï¼\nã“ã®åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã¯ã‚«ãƒ«ãƒ†ã®ã‚ã‚‹tokenãŒfeatureã«é–¢ã—ã¦é‡è¦ãªè¨˜è¿°ã§ã‚ã‚‹ã‹ï¼Œã¤ã¾ã‚Šannotationã«å«ã¾ã‚Œã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆ0 or 1ï¼‰ã—ã¾ã™ï¼\nã‚«ãƒ«ãƒ†ã®ã™ã¹ã¦ã®tokenã«å¯¾ã—ã¦åˆ¤å®šã‚’è¡Œã„ï¼Œé€£ç¶šã—ã¦é‡è¦ã§ã‚ã‚‹ã¨åˆ¤å®šã•ã‚ŒãŸtokenã‚’ã¾ã¨ã‚ã¦1ã¤ã®äºˆæ¸¬annotationã‚’ä½œã‚Šã¾ã™ï¼\n\nã¤ã¾ã‚ŠDatasetä½œæˆã§ã¯å…¥åŠ›ã¨ã—ã¦feature_textã¨ã‚«ãƒ«ãƒ†ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãã‚Œãã‚Œã‚’tokenizeã—ãŸã‚‚ã®ï¼‰ã¨ï¼Œãƒ©ãƒ™ãƒ«ã¨ã—ã¦ã‚«ãƒ«ãƒ†ã®å„tokenãŒannotationã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’è¡¨ã™0 or 1ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™ï¼","metadata":{}},{"cell_type":"markdown","source":"## å‰å‡¦ç†\n\n3ã¤ã®csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒãƒ¼ã‚¸ã—ï¼Œæ¬¡ã®å‰å‡¦ç†ã‚’è¡Œã„ã¾ã™ï¼\n\n1. `ast.literal_eval`ã§`trian.csv`ã®annotationã¨locationã‚’æ–‡å­—åˆ—ã‹ã‚‰ãƒªã‚¹ãƒˆã«å¤‰æ›\n1. feature_textã«å«ã¾ã‚Œã¦ã„ã‚‹`\"-OR-\"`ã‚’`\"; \"`ã«ï¼Œ`\"-\"`ã‚’`\" \"`ã«ç½®ãæ›ãˆã‚‹\n1. feature_textã¨pn_historyï¼ˆã‚«ãƒ«ãƒ†æ–‡ï¼‰ã«å«ã¾ã‚Œã‚Œã‚‹æ–‡å­—ã‚’ã™ã¹ã¦å°æ–‡å­—ã«å¤‰æ›ï¼\n\nä»Šå›åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯uncasedã®BERTãªã®ã§ï¼Œå¤§æ–‡å­—ã¨å°æ–‡å­—ã‚’åŒºåˆ¥ã—ã¾ã›ã‚“ï¼","metadata":{}},{"cell_type":"code","source":"BASE_URL = \"../input/nbme-score-clinical-patient-notes\"\n\n\ndef process_feature_text(text):\n    return text.replace(\"-OR-\", \"; \").replace(\"-\", \" \")\n\n\ndef prepare_datasets():\n    features = pd.read_csv(f\"{BASE_URL}/features.csv\")\n    notes = pd.read_csv(f\"{BASE_URL}/patient_notes.csv\")\n    train = pd.read_csv(f\"{BASE_URL}/train.csv\")\n\n    merged = train.merge(notes, how=\"left\")\n    merged = merged.merge(features, how=\"left\")\n\n    merged[\"annotation_list\"] = [literal_eval(x) for x in merged[\"annotation\"]]\n    merged[\"location_list\"] = [literal_eval(x) for x in merged[\"location\"]]\n    \n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    \n    merged[\"feature_text\"] = merged[\"feature_text\"].apply(lambda x: x.lower())\n    merged[\"pn_history\"] = merged[\"pn_history\"].apply(lambda x: x.lower())\n\n    return merged\n\ntrain_df = prepare_datasets()\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:14.31258Z","iopub.execute_input":"2022-03-02T02:59:14.313063Z","iopub.status.idle":"2022-03-02T02:59:15.087768Z","shell.execute_reply.started":"2022-03-02T02:59:14.312995Z","shell.execute_reply":"2022-03-02T02:59:15.087076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Datasetä½œæˆ\n\n`train_df`ã‹ã‚‰Pytorch Datasetã‚’ä½œæˆã—ã¾ã™ï¼æœ€åˆã«èª¬æ˜ã—ãŸã‚ˆã†ã«å…¥åŠ›ã¨ã—ã¦feature_textã¨ã‚«ãƒ«ãƒ†ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãã‚Œãã‚Œã‚’tokenizeã—ãŸã‚‚ã®ï¼‰ã¨ï¼Œãƒ©ãƒ™ãƒ«ã¨ã—ã¦ã‚«ãƒ«ãƒ†ã®ãƒ†ã‚­ã‚¹ãƒˆã®tokenãŒannotationã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’è¡¨ã™0 or 1ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™ï¼\n\nè¤‡é›‘ãªå‡¦ç†ãªã®ã§ï¼Œã¾ãšã¯æ¬¡ã®ã‚ˆã†ãªç°¡å˜ãªä¾‹ã‚’ä½¿ã£ã¦å‡¦ç†ã®æµã‚Œã‚’èª¬æ˜ã—ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"example = train_df.loc[14242]\nexample","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:19.175947Z","iopub.execute_input":"2022-03-02T02:59:19.176195Z","iopub.status.idle":"2022-03-02T02:59:19.189629Z","shell.execute_reply.started":"2022-03-02T02:59:19.176166Z","shell.execute_reply":"2022-03-02T02:59:19.188828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## tokenåˆ†å‰²","metadata":{}},{"cell_type":"markdown","source":"ã¾ãštransformersã®Tokenizerã§pn_historyã¨feature_textã‚’tokenã«åˆ†å‰²ã—ã¾ã™ï¼\n\næœ¬ç•ªsubmitæ™‚ã«ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒä½¿ãˆãªã„ã‚‰ã—ãï¼ŒHuggingFace Hubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ããªã„ãŸã‚ï¼ŒKaggleã«ã‚ã‚‹[Huggingface BERT](https://www.kaggle.com/xhlulu/huggingface-bert)ã‚’Notebookã«è¿½åŠ ã—ã¦ä½¿ç”¨ã—ã¾ã™ï¼ï¼ˆå³ã®ã‚¿ãƒ–ã®\"+Add data\"ã‹ã‚‰è¿½åŠ ã—ã¾ã™ï¼‰\n","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"../input/huggingface-bert/bert-base-uncased\")\n\n# submitã—ãªã„ã®ã§ã‚ã‚Œã°ï¼ŒHubã‹ã‚‰ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹\n# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:21.401231Z","iopub.execute_input":"2022-03-02T02:59:21.401913Z","iopub.status.idle":"2022-03-02T02:59:21.472625Z","shell.execute_reply.started":"2022-03-02T02:59:21.401877Z","shell.execute_reply":"2022-03-02T02:59:21.471962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"tokenizerã«ã¯æ–‡ã®ãƒšã‚¢ã‚’æ¸¡ã™ã“ã¨ãŒã§ãã¾ã™ï¼ã“ã“ã§ã¯feature_textã¨pn_historyã‚’ã“ã®é †ç•ªã§tokenizerã«æ¸¡ã—ã¦tokenã«å¤‰æ›ã—ã¾ã™ï¼\n\n[Transformers Docs](https://huggingface.co/docs/transformers/preprocessing)\n\nç§ãŒæ°—ã«ãªã£ãŸã®ã¯ï¼Œ`max_length=416`ã¨ã—ã¦ã„ã‚‹ç‚¹ã§ã™ï¼ã“ã“ã§åˆ©ç”¨ã—ã¦ã„ã‚‹[bert_base_uncasedã®ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰](https://huggingface.co/bert-base-uncased#:~:text=The%20only%20constrain%20is%20that%20the%20result%20with%20the%20two%20%22sentences%22%20has%20a%20combined%20length%20of%20less%20than%20512%20tokens.)ã«ã¯ã€Œï¼’ã¤ã®æ–‡ã‚’åˆã‚ã›ãŸé•·ã•ã¯æœ€å¤§512tokenã«åˆ¶é™ã•ã‚Œã‚‹ã€ã¨æ›¸ã‹ã‚Œã¦ã„ã¾ã™ãŒï¼Œã“ã“ã§ã¯ãªãœã‹ãã‚Œã‚ˆã‚Šã‚‚çŸ­ã„416ã¨ã„ã†å€¤ã‚’ä½¿ã£ã¦ã„ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"out = tokenizer(example[\"feature_text\"], example[\"pn_history\"], max_length=416, truncation=\"only_second\", padding=\"max_length\", return_offsets_mapping=True)\nout.keys()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:24.414529Z","iopub.execute_input":"2022-03-02T02:59:24.415119Z","iopub.status.idle":"2022-03-02T02:59:24.424206Z","shell.execute_reply.started":"2022-03-02T02:59:24.415084Z","shell.execute_reply":"2022-03-02T02:59:24.42323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"input_idsã¯feature_textã¨pn_historyã‚’tokenã«åˆ†å‰²ã—ãŸã‚‚ã®ã§ã™ï¼tokenãã®ã‚‚ã®ã§ã¯ãªãtokenã®idãŒå…¥ã£ã¦ã„ã¾ã™ï¼\n\n`tokenizer.convert_ids_to_tokens`ã§token idã‚’tokenã«å¤‰æ›ã§ãã¾ã™ï¼token idã‚’tokenã«æˆ»ã—ã¦ã¿ã‚‹ã¨ã‚‚ã¨ã®æ–‡ãŒç¢ºèªã§ãã¾ã™ï¼\nfeature_textã¨pn_historyã¯çµåˆã•ã‚Œ`[SEP]`ã§åŒºåˆ‡ã‚‰ã‚Œã¦ã„ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"print(len(out[\"input_ids\"]))\nprint(out[\"input_ids\"])\nprint(tokenizer.convert_ids_to_tokens(out[\"input_ids\"]))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T02:59:40.446107Z","iopub.execute_input":"2022-03-02T02:59:40.446859Z","iopub.status.idle":"2022-03-02T02:59:40.454049Z","shell.execute_reply.started":"2022-03-02T02:59:40.446808Z","shell.execute_reply":"2022-03-02T02:59:40.453328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"tokenizerã§`tokenizer(..., return_offsets_mapping=True)`ã¨ã—ã¦ã„ãŸã®ã§ï¼Œtokenã«å¤‰æ›ã—ãŸéš›ã«offset_mappingã‚‚å¸°ã£ã¦ãã¾ã™ï¼\n\noffset_mappingã‚’è¦‹ã‚‹ã¨ï¼Œå„tokenãŒã‚‚ã¨ã®æ–‡ã®ã©ã®éƒ¨åˆ†ã«å¯¾å¿œã™ã‚‹ã‹ãŒã‚ã‹ã‚Šã¾ã™ï¼\nä¾‹ãˆã°\"lives\"ã¯11ç•ªç›®ã®tokenã§ï¼Œoffset_mappingã¯(13, 18)ã¨ãªã£ã¦ã„ã¾ã™ï¼ã‚‚ã¨ã®æ–‡ï¼ˆpn_historyï¼‰ã§13æ–‡å­—ç›®ã‹ã‚‰17æ–‡å­—ç›®ã¾ã§ã‚’è¦‹ã‚‹ã¨ï¼Œç¢ºã‹ã«\"lives\"ã¨ãªã£ã¦ã„ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"print(out[\"offset_mapping\"][:15]) #é•·ã„ã®ã§æœ€åˆã®15å€‹ã‚’è¡¨ç¤º\nprint(example[\"pn_history\"][13:18])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:28.787971Z","iopub.execute_input":"2022-03-01T15:21:28.788263Z","iopub.status.idle":"2022-03-01T15:21:28.799636Z","shell.execute_reply.started":"2022-03-01T15:21:28.788223Z","shell.execute_reply":"2022-03-01T15:21:28.798569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`out.sequence_ids()`ã‚’è¦‹ã‚‹ã“ã¨ã§ï¼Œå„tokenãŒå…¥åŠ›ã—ãŸï¼’ã¤ã®æ–‡ï¼ˆfeature_textï¼Œpn_historyï¼‰ã®ã©ã¡ã‚‰ã‹ã‚‰ä½œã‚‰ã‚ŒãŸã‹ã‚’çŸ¥ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\n\n416å€‹ã®å„tokenã«ã¤ã„ã¦ï¼Œ`0`ã¯feature_textï¼Œ`1`ã¯pn_historyã«å±ã—ã¦ã„ã‚‹tokenã§ã‚ã‚‹ã“ã¨ã‚’è¡¨ã—ã¦ã„ã¾ã™ï¼`None`ã¨ãªã£ã¦ã„ã‚‹ã®ã¯`[SEP]`ã‚„`[PAD]`ãªã©ã®ç‰¹æ®Šãªtokenã§ã™ï¼\n\n`out[\"sequence_ids\"]`ã«å…¥ã‚Œã¦ãŠãã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"print(len(out.sequence_ids()))\nprint(out.sequence_ids())\n\nout[\"sequence_ids\"] = out.sequence_ids()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:28.801002Z","iopub.execute_input":"2022-03-01T15:21:28.801506Z","iopub.status.idle":"2022-03-01T15:21:28.809729Z","shell.execute_reply.started":"2022-03-01T15:21:28.801469Z","shell.execute_reply":"2022-03-01T15:21:28.808879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ãƒ©ãƒ™ãƒ«ä½œæˆ","metadata":{}},{"cell_type":"markdown","source":"æ¬¡ã«ï¼Œannotaionã®ä½ç½®`example[\"location_list\"]`ã‚’ã‚‚ã¨ã«ã—ã¦ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼\n\nå‰å‡¦ç†ã§æ–‡å­—åˆ—ã‹ã‚‰ãƒªã‚¹ãƒˆã¸å¤‰æ›ã—ã¾ã—ãŸãŒï¼Œã¾ã ä¸­èº«ã¯æ–‡å­—åˆ—ãªã®ã§ã•ã‚‰ã«å¤‰æ›ã‚’è¡Œã„ã¾ã™ï¼`loc_list_to_ints`ã¨ã„ã†é–¢æ•°ã§å¤‰æ›ã‚’è¡Œã„ã¾ã™ï¼\nã¾ãŸå¤‰æ›ã—ãŸã‚‚ã®ã‚’`out[\"location_int\"]`ã«å…¥ã‚Œã¦ãŠãã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"def loc_list_to_ints(loc_list):\n    to_return = []\n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n    return to_return\n\n\nprint(f\"{example['location_list']} -> {loc_list_to_ints(example['location_list'])}\")\n\nprint(f\"{['682 688;695 697']} -> {loc_list_to_ints(['682 688;695 697'])}\")\n\n\nout[\"location_int\"] = loc_list_to_ints(example[\"location_list\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:28.811457Z","iopub.execute_input":"2022-03-01T15:21:28.811968Z","iopub.status.idle":"2022-03-01T15:21:28.821226Z","shell.execute_reply.started":"2022-03-01T15:21:28.81193Z","shell.execute_reply":"2022-03-01T15:21:28.820483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`out[\"sequence_ids\"]`ã¨`out[\"offset_mapping\"]`ï¼Œãã—ã¦`out[\"location_int\"]`ã‚’ä½¿ã£ã¦ï¼Œå„tokenã«ãŒfeatureã«é–¢ã™ã‚‹é‡è¦ãªè¨˜è¿°ã§ã‚ã‚‹ã‹ã©ã†ã‹ï¼ˆannotationã«å«ã‚€ã¾ã‚Œã‚‹ã‹ï¼‰ã‚’è¡¨ã™ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"labels = [0.0] * len(out[\"input_ids\"]) # tokenã®æ•°ã¨åŒã˜é•·ã•ã®ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆã‚’ç”¨æ„\n\n# å„tokenã®seq_idï¼ˆã©ã¡ã‚‰ã®æ–‡ã«å±ã—ã¦ã„ã‚‹ã‹ï¼‰ã¨offsetsï¼ˆã‚‚ã¨ã®æ–‡ã®ã©ã®ç¯„å›²ã«ã‚ã‚‹ã‹ï¼‰\nfor idx, (seq_id, offsets) in enumerate(zip(out[\"sequence_ids\"], out[\"offset_mapping\"])):\n    # tokenãŒç‰¹æ®Šãªtokenï¼ˆ[PAD]ã‚„[SEQ]ï¼‰ã§ã‚ã‚‹å ´åˆï¼Œã‚ã‚‹ã„ã¯ï¼‘ã¤ç›®ã®æ–‡ï¼ˆfeature_textï¼‰ã«å±ã—ã¦ã„ã‚‹å ´åˆã¯ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ãŸããªã„ã®ã§-1ã¨ã—ã¦ãŠãï¼\n    # ï¼ˆãƒ©ãƒ™ãƒ«ãŒ-1ã®tokenã¯ï¼Œå¾Œã§lossã‚’è¨ˆç®—ã™ã‚‹éš›ã«ç„¡è¦–ã•ã‚Œã¾ã™ï¼‰\n    if not seq_id or seq_id == 0:\n        labels[idx] = -1\n        continue\n\n    # tokenãŒannotaionã®ç¯„å›²ã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆï¼Œãã®tokenã®ãƒ©ãƒ™ãƒ«ã‚’1.0ã«ã™ã‚‹ï¼\n    token_start, token_end = offsets\n    for feature_start, feature_end in out[\"location_int\"]:\n        if token_start >= feature_start and token_end <= feature_end:\n            labels[idx] = 1.0\n            break\n\nout[\"labels\"] = labels\n\nprint(out[\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:28.822311Z","iopub.execute_input":"2022-03-01T15:21:28.822613Z","iopub.status.idle":"2022-03-01T15:21:28.833907Z","shell.execute_reply.started":"2022-03-01T15:21:28.822579Z","shell.execute_reply":"2022-03-01T15:21:28.832961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ã“ã‚Œã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã§ãã¾ã™ï¼æ”¹ã‚ã¦ã‚³ãƒ¼ãƒ‰ã‚’ã¾ã¨ã‚ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"hyperparameters = {\n    \"max_length\": 416,\n    \"padding\": \"max_length\",\n    \"return_offsets_mapping\": True,\n    \"truncation\": \"only_second\",\n    \"model_name\": \"../input/huggingface-bert/bert-base-uncased\",\n    \"dropout\": 0.2,\n    \"lr\": 1e-5,\n    \"test_size\": 0.2,\n    \"seed\": 1268,\n    \"batch_size\": 8\n}\n\ndef loc_list_to_ints(loc_list):\n    to_return = []\n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n    return to_return\n\n\ndef tokenize_and_add_labels(tokenizer, data, config):\n    out = tokenizer(\n        data[\"feature_text\"],\n        data[\"pn_history\"],\n        truncation=config['truncation'],\n        max_length=config['max_length'],\n        padding=config['padding'],\n        return_offsets_mapping=config['return_offsets_mapping']\n    )\n    labels = [0.0] * len(out[\"input_ids\"])\n    out[\"location_int\"] = loc_list_to_ints(data[\"location_list\"])\n    out[\"sequence_ids\"] = out.sequence_ids()\n\n    for idx, (seq_id, offsets) in enumerate(zip(out[\"sequence_ids\"], out[\"offset_mapping\"])):\n        if not seq_id or seq_id == 0:\n            labels[idx] = -1\n            continue\n\n        token_start, token_end = offsets\n        for feature_start, feature_end in out[\"location_int\"]:\n            if token_start >= feature_start and token_end <= feature_end:\n                labels[idx] = 1.0\n                break\n\n    out[\"labels\"] = labels\n\n    return out\n\nclass CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        data = self.data.iloc[idx]\n        tokens = tokenize_and_add_labels(self.tokenizer, data, self.config)\n\n        input_ids = np.array(tokens[\"input_ids\"])\n        attention_mask = np.array(tokens[\"attention_mask\"])\n        token_type_ids = np.array(tokens[\"token_type_ids\"])\n\n        labels = np.array(tokens[\"labels\"])\n        offset_mapping = np.array(tokens['offset_mapping'])\n        sequence_ids = np.array(tokens['sequence_ids']).astype(\"float16\")\n        \n        return input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:28.835664Z","iopub.execute_input":"2022-03-01T15:21:28.835943Z","iopub.status.idle":"2022-03-01T15:21:28.853678Z","shell.execute_reply.started":"2022-03-01T15:21:28.835894Z","shell.execute_reply":"2022-03-01T15:21:28.852762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"dataloaderã‚’ä½œæˆã—ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"train_df = prepare_datasets()\n\nX_train, X_test = train_test_split(train_df, test_size=hyperparameters['test_size'],\n                                   random_state=hyperparameters['seed'])\n\nprint(\"Train size\", len(X_train))\nprint(\"Test Size\", len(X_test))\n\ntokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'])\n\ntraining_data = CustomDataset(X_train, tokenizer, hyperparameters)\ntrain_dataloader = DataLoader(training_data, batch_size=hyperparameters['batch_size'], shuffle=True)\n\ntest_data = CustomDataset(X_test, tokenizer, hyperparameters)\ntest_dataloader = DataLoader(test_data, batch_size=hyperparameters['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:28.855133Z","iopub.execute_input":"2022-03-01T15:21:28.855378Z","iopub.status.idle":"2022-03-01T15:21:29.495075Z","shell.execute_reply.started":"2022-03-01T15:21:28.855347Z","shell.execute_reply":"2022-03-01T15:21:29.493398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"è©¦ã—ã«batchã‚’ï¼‘ã¤å–ã‚Šå‡ºã—ã¦ã¿ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"for batch in train_dataloader:\n    input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids = batch\n    print(input_ids.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:29.496566Z","iopub.execute_input":"2022-03-01T15:21:29.496826Z","iopub.status.idle":"2022-03-01T15:21:29.556362Z","shell.execute_reply.started":"2022-03-01T15:21:29.496792Z","shell.execute_reply":"2022-03-01T15:21:29.555274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"æ¬¡ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼BERTã®å‡ºåŠ›ã«FCå±¤ã‚’ã¤ãªã’ãŸãƒ¢ãƒ‡ãƒ«ã«ãªã£ã¦ã„ã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(config['model_name'])  # BERT model\n        self.dropout = nn.Dropout(p=config['dropout'])\n        self.config = config\n        self.fc1 = nn.Linear(768, 512)\n        self.fc2 = nn.Linear(512, 512)\n        self.fc3 = nn.Linear(512, 1)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        logits = self.fc1(outputs[0])\n        logits = self.fc2(self.dropout(logits))\n        logits = self.fc3(self.dropout(logits)).squeeze(-1)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:29.55768Z","iopub.execute_input":"2022-03-01T15:21:29.557954Z","iopub.status.idle":"2022-03-01T15:21:29.565879Z","shell.execute_reply.started":"2022-03-01T15:21:29.55789Z","shell.execute_reply":"2022-03-01T15:21:29.564831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã•ã‚ŒãŸãƒ†ãƒ³ã‚½ãƒ«ã®å½¢ãŒã©ã®ã‚ˆã†ã«å¤‰ã‚ã£ã¦ã„ãã‹ã‚’è¦‹ã¦ã¿ã¾ã™ï¼\n\nBERTã®å‡ºåŠ›ã®å½¢ã¯`(batch_size, n_tokens, hidden_dim) = (8, 416, 768)`ã§ï¼ŒFCå±¤ã‚’é€šã™ã“ã¨ã§æœ€çµ‚çš„ã«`(8, 416)`ã®å½¢ã«ãªã‚Šã¾ã™ï¼å„batchã®å„tokenã«å¯¾ã—ã¦ï¼‘ã¤ã®å€¤ï¼ˆlogitï¼‰ãŒå‡ºåŠ›ã•ã‚Œã¦ã„ã¾ã™ï¼ã“ã‚Œã‚’sigmoidã«é€šã™ã“ã¨ã§ç¢ºç‡ã‚’è¨ˆç®—ã—ã¾ã™ï¼\n\nãƒ¢ãƒ‡ãƒ«ä½œæˆæ™‚ã«\"Some weights of the ...\"ã¨ã„ã†è­¦å‘ŠãŒå‡ºã¦ã„ã¾ã™ãŒæ­£å¸¸ã§ã™ï¼[å‚è€ƒ](https://huggingface.co/course/chapter3/3?fw=pt#:~:text=You%20will%20notice,to%20do%20now.)","metadata":{}},{"cell_type":"code","source":"model = CustomModel(hyperparameters)\n\nfor batch in train_dataloader:\n    input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids = batch\n    bert_output = model.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n    print(bert_output.last_hidden_state.size())\n    \n    logits = model.fc1(bert_output[0]) # bert_output[0]ã¨bert_output.last_hidden_stateã¯åŒã˜\n    logits = model.fc2(model.dropout(logits))\n    logits = model.fc3(model.dropout(logits))\n    print(logits.size())\n    \n    logits = logits.squeeze(-1)\n    print(logits.size())\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:29.567446Z","iopub.execute_input":"2022-03-01T15:21:29.567743Z","iopub.status.idle":"2022-03-01T15:21:45.312594Z","shell.execute_reply.started":"2022-03-01T15:21:29.567706Z","shell.execute_reply":"2022-03-01T15:21:45.311564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"criterion = torch.nn.BCEWithLogitsLoss(reduction = \"none\")\n\ndef train_model(model, dataloader, optimizer, criterion):\n        model.train()\n        train_loss = []\n\n        for batch in tqdm(dataloader):\n            optimizer.zero_grad()\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            labels = batch[3].to(DEVICE)\n\n            logits = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(logits, labels)\n            \n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            train_loss.append(loss.item() * input_ids.size(0))\n            loss.backward()\n            # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n            # it's also improve f1 accuracy slightly\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        return sum(train_loss)/len(train_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:45.313853Z","iopub.execute_input":"2022-03-01T15:21:45.314114Z","iopub.status.idle":"2022-03-01T15:21:45.323091Z","shell.execute_reply.started":"2022-03-01T15:21:45.314077Z","shell.execute_reply":"2022-03-01T15:21:45.322038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"å…ˆã»ã©ã¨åŒæ§˜ã«`train_dataloader`ã‹ã‚‰batchã‚’ï¼‘ã¤å–ã‚Šå‡ºã—ã¦æµã‚Œã‚’ç¢ºèªã—ã¾ã™ï¼\n\n-1.0ã®ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ãŸtokenï¼ˆfeature_textã«å±ã—ã¦ã„ã‚‹ or ç‰¹æ®Šãªtokenï¼‰ã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®lossã¯è¨“ç·´ã«ä½¿ã„ãŸããªã„ãŸã‚ï¼Œ`torch.masked_select`ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã„ã¾ã™ï¼\n\nã¾ãŸ`BCEWithLogitsLoss`ã§`reduction=\"none\"`ã¨ã™ã‚‹ã“ã¨ã§ï¼Œå„tokenã«å¯¾ã™ã‚‹lossã‚’è¨ˆç®—ã§ãã¾ã™ï¼","metadata":{}},{"cell_type":"code","source":"for batch in train_dataloader:\n    input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids = batch\n\n    logits = model(input_ids, attention_mask, token_type_ids)\n    print(logits.size())\n    \n    # criterion = BCEWithLogitsLoss(reduction = \"none\") ã¨ã™ã‚‹ã“ã¨ã§ï¼Œå„batchã®å„tokenã®lossãŒã‚ã‹ã‚‹ï¼\n    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯reduction = \"mean\"\n    loss = criterion(logits, labels)\n    print(loss.size())\n\n    # ãƒ©ãƒ™ãƒ«ä½œæˆæ™‚ã«-1.0ã¨ã—ãŸéƒ¨åˆ†ã®lossã¯ç„¡è¦–ã™ã‚‹ï¼\n    loss = torch.masked_select(loss, labels > -1.0)\n    print(loss.size()) # ãƒ©ãƒ™ãƒ«ãŒ 0 or 1 ã®lossã®ã¿ãŒã®ã“ã‚‹ï¼\n    \n    print(loss.mean())\n    \n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:45.324388Z","iopub.execute_input":"2022-03-01T15:21:45.324885Z","iopub.status.idle":"2022-03-01T15:21:54.314143Z","shell.execute_reply.started":"2022-03-01T15:21:45.324831Z","shell.execute_reply":"2022-03-01T15:21:54.313266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ãƒ©ãƒ™ãƒ«ãŒ 0 or 1 ã®lossã®æ•°\nnp.sum(labels.numpy()>-1.0)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:54.315775Z","iopub.execute_input":"2022-03-01T15:21:54.316118Z","iopub.status.idle":"2022-03-01T15:21:54.322217Z","shell.execute_reply.started":"2022-03-01T15:21:54.316075Z","shell.execute_reply":"2022-03-01T15:21:54.321506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ğŸ¤— Transformersã«ã¯è¨“ç·´ã«å¿…è¦ãªå‡¦ç†ã‚’ã¾ã¨ã‚ãŸTrainerã‚¯ãƒ©ã‚¹ãŒå­˜åœ¨ã—ã¾ã™ãŒï¼Œä»Šå›ã¯ä¸Šã§èª¬æ˜ã—ãŸã‚ˆã†ãªå‡¦ç†ã‚’çµ„ã¿è¾¼ã‚€å¿…è¦ãŒã‚ã£ãŸãŸã‚ä½¿ç”¨ã—ã¦ã„ãªã„ã‚ˆã†ã§ã™ï¼","metadata":{}},{"cell_type":"markdown","source":"æ¬¡ã«è©•ä¾¡ç”¨ã®é–¢æ•°ã§ã™ï¼ã»ã¨ã‚“ã©è¨“ç·´ç”¨ã®é–¢æ•°ã¨åŒã˜ã§ã™ãŒï¼Œtokenå˜ä½ã®äºˆæ¸¬çµæœã‚’æ–‡å­—å˜ä½ã®ç¯„å›²ã«å¤‰æ›ã™ã‚‹å‡¦ç†ã¨metricã®è¨ˆç®—ãŒè¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ï¼\n\n[Evaluationæ–¹æ³•](https://www.kaggle.com/c/nbme-score-clinical-patient-notes/overview/evaluation)","metadata":{}},{"cell_type":"code","source":"def eval_model(model, dataloader, criterion):\n        model.eval()\n        valid_loss = []\n        preds = []\n        offsets = []\n        seq_ids = []\n        valid_labels = []\n\n        for batch in tqdm(dataloader):\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            token_type_ids = batch[2].to(DEVICE)\n            labels = batch[3].to(DEVICE)\n            offset_mapping = batch[4]\n            sequence_ids = batch[5]\n\n            logits = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(logits, labels)\n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            valid_loss.append(loss.item() * input_ids.size(0))\n\n            preds.append(logits.detach().cpu().numpy())\n            offsets.append(offset_mapping.numpy())\n            seq_ids.append(sequence_ids.numpy())\n            valid_labels.append(labels.detach().cpu().numpy())\n\n        preds = np.concatenate(preds, axis=0)\n        offsets = np.concatenate(offsets, axis=0)\n        seq_ids = np.concatenate(seq_ids, axis=0)\n        valid_labels = np.concatenate(valid_labels, axis=0)\n        location_preds = get_location_predictions(preds, offsets, seq_ids, test=False)\n        score = calculate_char_cv(location_preds, offsets, seq_ids, valid_labels)\n\n        return sum(valid_loss)/len(valid_loss), score\n\n    \n# tokenå˜ä½ã®äºˆæ¸¬çµæœã‚’æ–‡å­—å˜ä½ã®ç¯„å›²ã«å¤‰æ›ã™ã‚‹ï¼\ndef get_location_predictions(preds, offset_mapping, sequence_ids, test=False):\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        pred = 1 / (1 + np.exp(-pred)) # logitsã‹ã‚‰probabilityã‚’è¨ˆç®—\n        \n        start_idx = None\n        end_idx = None\n        current_preds = []\n        for pred, offset, seq_id in zip(pred, offsets, seq_ids):\n            if seq_id is None or seq_id == 0:\n                continue\n\n            # probability > 0.5 ãŒé€£ç¶šã—ã¦ã„ã‚‹éƒ¨åˆ†ã‚’tokenå˜ä½ã§æ¢ã—ï¼Œ\n            # ãã®startä½ç½®ã¨stopä½ç½®ã®ï¼ˆæ–‡å­—å˜ä½ã§ã®ï¼‰idxã‚’è¨˜éŒ²ã™ã‚‹ï¼\n            if pred > 0.5:\n                if start_idx is None:\n                    start_idx = offset[0]\n                end_idx = offset[1]\n            elif start_idx is not None:\n                if test:\n                    current_preds.append(f\"{start_idx} {end_idx}\")\n                else:\n                    current_preds.append((start_idx, end_idx))\n                start_idx = None\n        if test:\n            all_predictions.append(\"; \".join(current_preds))\n        else:\n            all_predictions.append(current_preds)\n            \n    return all_predictions\n\n\n# æ–‡å­—å˜ä½ã§è©•ä¾¡å€¤ã‚’è¨ˆç®—ã™ã‚‹ï¼\ndef calculate_char_cv(predictions, offset_mapping, sequence_ids, labels):\n    all_labels = []\n    all_preds = []\n    for preds, offsets, seq_ids, labels in zip(predictions, offset_mapping, sequence_ids, labels):\n\n        num_chars = max(list(chain(*offsets)))\n        char_labels = np.zeros(num_chars)\n\n        # ãƒ©ãƒ™ãƒ«\n        for o, s_id, label in zip(offsets, seq_ids, labels):\n            if s_id is None or s_id == 0:\n                continue\n            if int(label) == 1:\n                char_labels[o[0]:o[1]] = 1\n\n        char_preds = np.zeros(num_chars)\n\n        # äºˆæ¸¬çµæœ\n        for start_idx, end_idx in preds:\n            char_preds[start_idx:end_idx] = 1\n\n        all_labels.extend(char_labels)\n        all_preds.extend(char_preds)\n\n    results = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\", labels=np.unique(all_preds))\n    accuracy = accuracy_score(all_labels, all_preds)\n    \n\n    return {\n        \"Accuracy\": accuracy,\n        \"precision\": results[0],\n        \"recall\": results[1],\n        \"f1\": results[2]\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:54.323613Z","iopub.execute_input":"2022-03-01T15:21:54.324138Z","iopub.status.idle":"2022-03-01T15:21:54.346615Z","shell.execute_reply.started":"2022-03-01T15:21:54.324089Z","shell.execute_reply":"2022-03-01T15:21:54.345797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"å®Ÿéš›ã«è¨“ç·´ã‚’è¡Œã†ã‚³ãƒ¼ãƒ‰ã§ã™ï¼ï¼ˆå®Ÿè¡Œã«æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ã„ã¾ã™ï¼‰","metadata":{}},{"cell_type":"code","source":"# train_df = prepare_datasets()\n# X_train, X_test = train_test_split(train_df, test_size=hyperparameters['test_size'], random_state=hyperparameters['seed'])\n\n# tokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'])\n# training_data = CustomDataset(X_train, tokenizer, hyperparameters)\n# train_dataloader = DataLoader(training_data, batch_size=hyperparameters['batch_size'], shuffle=True)\n# test_data = CustomDataset(X_test, tokenizer, hyperparameters)\n# test_dataloader = DataLoader(test_data, batch_size=hyperparameters['batch_size'], shuffle=False)\n\n# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# model = CustomModel(hyperparameters).to(DEVICE)\n# criterion = torch.nn.BCEWithLogitsLoss(reduction = \"none\")\n# optimizer = optim.AdamW(model.parameters(), lr=hyperparameters['lr'])\n\n# train_loss_data, valid_loss_data = [], []\n# score_data_list = []\n# valid_loss_min = np.Inf\n# since = time.time()\n# epochs = 3\n\n# best_loss = np.inf\n\n# for i in range(epochs):\n#     print(\"Epoch: {}/{}\".format(i + 1, epochs))\n#     # first train model\n#     train_loss = train_model(model, train_dataloader, optimizer, criterion)\n#     train_loss_data.append(train_loss)\n#     print(f\"Train loss: {train_loss}\")\n#     # evaluate model\n#     valid_loss, score = eval_model(model, test_dataloader, criterion)\n#     valid_loss_data.append(valid_loss)\n#     score_data_list.append(score)\n#     print(f\"Valid loss: {valid_loss}\")\n#     print(f\"Valid score: {score}\")\n    \n#     if valid_loss < best_loss:\n#         best_loss = valid_loss\n#         torch.save(model.state_dict(), \"nbme_bert_v2.pth\")\n\n    \n# time_elapsed = time.time() - since\n# print('Training completed in {:.0f}m {:.0f}s'.format(\n#     time_elapsed // 60, time_elapsed % 60))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:21:54.348053Z","iopub.execute_input":"2022-03-01T15:21:54.348565Z","iopub.status.idle":"2022-03-01T15:21:54.358972Z","shell.execute_reply.started":"2022-03-01T15:21:54.348528Z","shell.execute_reply":"2022-03-01T15:21:54.35829Z"},"trusted":true},"execution_count":null,"outputs":[]}]}