{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:5px;background-color:#CCCCFF;\n       font-size:150%;font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 10px;color:white;\"><b> 1- ABOUT THE ANALYSIS:</b></p>\n</div>\n\nThis competition is sponsored by the National Board of Medical Examiners¬Æ (NBME¬Æ). The goal of this competition is to develop an automated way of identifying the relevant features within each patient note, with a special focus on the patient history portions of the notes where the information from the interview with the standardized patient is documented.\n\nI am trying to apply my train of thoughts to explore the data.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:5px;background-color:#CCCCFF;\n       font-size:150%;font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 10px;color:white;\"><b> 2- ABOUT THE DATA:</b></p>\n</div>\n\n\nThere are some important components in the training data provided, that consists of the following:\n\n1. Training data:\n\n> 1.1- train.csv - Feature annotations for 1000 of the patient notes, 100 for each of ten cases.\n\n> 1.2- patient_notes.csv - A collection of about 40,000 Patient Note history portions. \n\n> 1.3- features.csv - The rubric of features (or key concepts) for each clinical case.\n\n2. Test data: Example instances selected from the training set.\n\n3. sample_submission.csv - A sample submission file in the correct format.\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;display:fill;border-radius:5px;background-color:#CCCCFF;\n       font-size:150%;font-family:Nexa;letter-spacing:0.5px\">\n    <p style=\"padding: 10px;color:white;\"><b> 3- EXPLORE THE DATA:</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:05.393527Z","iopub.execute_input":"2022-02-03T21:41:05.394399Z","iopub.status.idle":"2022-02-03T21:41:05.400397Z","shell.execute_reply.started":"2022-02-03T21:41:05.394349Z","shell.execute_reply":"2022-02-03T21:41:05.399327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')\ntest_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/test.csv')\nnotes = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\nfeatures = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\nsample_submission = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:05.402234Z","iopub.execute_input":"2022-02-03T21:41:05.402707Z","iopub.status.idle":"2022-02-03T21:41:05.866582Z","shell.execute_reply.started":"2022-02-03T21:41:05.402664Z","shell.execute_reply":"2022-02-03T21:41:05.865671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exploring the train data:\n\n(Taken from the project description)\n\nThe train data consists of 6 columns with the folllowing details:\n\n* id - Unique identifier for each patient note / feature pair.\n* pn_num - The patient note annotated in this row.\n* feature_num - The feature annotated in this row.\n* case_num - The case to which this patient note belongs.\n* annotation - The text(s) within a patient note indicating a feature. A feature may be indicated multiple times within a single note.\n* location - Character spans indicating the location of each annotation within the note. Multiple spans may be needed to represent an annotation, in which case the spans are delimited by a semicolon ;.","metadata":{}},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:05.867934Z","iopub.execute_input":"2022-02-03T21:41:05.868641Z","iopub.status.idle":"2022-02-03T21:41:05.890006Z","shell.execute_reply.started":"2022-02-03T21:41:05.868597Z","shell.execute_reply":"2022-02-03T21:41:05.888973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look at the train data info below, this shows that we have no NA values but as mentioned in the description, only a fraction of the train data is annotated, that means we don't have all annotations data and it is filled with '[]'. Check above","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:05.893222Z","iopub.execute_input":"2022-02-03T21:41:05.894143Z","iopub.status.idle":"2022-02-03T21:41:05.917631Z","shell.execute_reply.started":"2022-02-03T21:41:05.894077Z","shell.execute_reply":"2022-02-03T21:41:05.916435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:05.919302Z","iopub.execute_input":"2022-02-03T21:41:05.920284Z","iopub.status.idle":"2022-02-03T21:41:05.941388Z","shell.execute_reply.started":"2022-02-03T21:41:05.920231Z","shell.execute_reply":"2022-02-03T21:41:05.940488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:05.942778Z","iopub.execute_input":"2022-02-03T21:41:05.943346Z","iopub.status.idle":"2022-02-03T21:41:05.956845Z","shell.execute_reply.started":"2022-02-03T21:41:05.943298Z","shell.execute_reply":"2022-02-03T21:41:05.95588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot\ntrain_df['case_num'].value_counts(normalize = True).sort_values().plot(kind='bar', figsize=(10,4), color = 'gold', rot=0)\n\nplt.xlabel(\"case_num\", labelpad=10, fontsize=20)\nplt.ylabel(\"Percent of data\", labelpad=10, fontsize=20)\nplt.xticks(size = 12)\nplt.yticks(size = 12)\nplt.title(\"Percent of data belonging to each case_num in the train set\", y=1.02, fontsize=15)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:05.958717Z","iopub.execute_input":"2022-02-03T21:41:05.959277Z","iopub.status.idle":"2022-02-03T21:41:06.240814Z","shell.execute_reply.started":"2022-02-03T21:41:05.95923Z","shell.execute_reply":"2022-02-03T21:41:06.239441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Explore the features data:\n\nfeatures.csv - The rubric of features (or key concepts) for each clinical case.\n* feature_num - A unique identifier for each feature.\n* case_num - A unique identifier for each case.\n* feature_text - A description of the feature.\n","metadata":{}},{"cell_type":"code","source":"features.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:06.242498Z","iopub.execute_input":"2022-02-03T21:41:06.242819Z","iopub.status.idle":"2022-02-03T21:41:06.253656Z","shell.execute_reply.started":"2022-02-03T21:41:06.242776Z","shell.execute_reply":"2022-02-03T21:41:06.252576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:06.255145Z","iopub.execute_input":"2022-02-03T21:41:06.25544Z","iopub.status.idle":"2022-02-03T21:41:06.274177Z","shell.execute_reply.started":"2022-02-03T21:41:06.255395Z","shell.execute_reply":"2022-02-03T21:41:06.273345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:06.276917Z","iopub.execute_input":"2022-02-03T21:41:06.277731Z","iopub.status.idle":"2022-02-03T21:41:06.292617Z","shell.execute_reply.started":"2022-02-03T21:41:06.27769Z","shell.execute_reply":"2022-02-03T21:41:06.291648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How many unique features per case number?\n\nfeat_count = features.groupby('case_num')['feature_num'].count().reset_index()\nprint(feat_count)\nplt.figure(figsize=(10, 4))\nsns.barplot(x = feat_count['case_num'].astype(str), y= feat_count['feature_num'].astype(int))\nplt.xlabel(\"case number\", labelpad=10, fontsize=12)\nplt.ylabel(\"number of features\", labelpad=10, fontsize=12)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nplt.title(\"total number of features per case number\", y=1.02, fontsize=15)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:06.293943Z","iopub.execute_input":"2022-02-03T21:41:06.29426Z","iopub.status.idle":"2022-02-03T21:41:06.581174Z","shell.execute_reply.started":"2022-02-03T21:41:06.294217Z","shell.execute_reply":"2022-02-03T21:41:06.580344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Explore the notes data:\n\npatient_notes.csv - A collection of about 40,000 Patient Note history portions. Only a subset of these have features annotated. \n* pn_num - A unique identifier for each patient note.\n* case_num - A unique identifier for the clinical case a patient note represents.\n* pn_history - The text of the encounter as recorded by the test taker.","metadata":{}},{"cell_type":"code","source":"notes.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:06.582713Z","iopub.execute_input":"2022-02-03T21:41:06.583226Z","iopub.status.idle":"2022-02-03T21:41:06.594507Z","shell.execute_reply.started":"2022-02-03T21:41:06.583158Z","shell.execute_reply":"2022-02-03T21:41:06.593778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notes.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:06.595489Z","iopub.execute_input":"2022-02-03T21:41:06.596037Z","iopub.status.idle":"2022-02-03T21:41:06.619998Z","shell.execute_reply.started":"2022-02-03T21:41:06.596002Z","shell.execute_reply":"2022-02-03T21:41:06.618927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notes.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:06.621209Z","iopub.execute_input":"2022-02-03T21:41:06.621432Z","iopub.status.idle":"2022-02-03T21:41:06.736407Z","shell.execute_reply.started":"2022-02-03T21:41:06.621404Z","shell.execute_reply":"2022-02-03T21:41:06.735636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How many unique patient notes per case number?\n\nnotes_count = notes.groupby('case_num')['pn_num'].count().reset_index()\nplt.figure(figsize=(10, 4))\nsns.barplot(x = notes_count['case_num'].astype(str), y= notes_count['pn_num'].astype(int))\nplt.xlabel(\"case number\", labelpad=10, fontsize=12)\nplt.ylabel(\"number of patient notes\", labelpad=10, fontsize=12)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nplt.grid()\nplt.title(\"total number of patient notes per case number\", y=1.02, fontsize=15)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:06.737806Z","iopub.execute_input":"2022-02-03T21:41:06.738055Z","iopub.status.idle":"2022-02-03T21:41:07.015201Z","shell.execute_reply.started":"2022-02-03T21:41:06.738025Z","shell.execute_reply":"2022-02-03T21:41:07.014214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To sum up, there are 10 case numbers, that have different features/ rubric that needs to be checked for each patient interaction that happens between a USMLE candidate and the standardized patient.\n\nFor example, case number 5(standardized clinical case) has total 18 rubric requirements(the features) and the total number of patient history records(which i think is nothing but the number of students who have interacted with that case) is 7000. We have to find the location in the patient history notes, where the rubric/features has been identified. ","metadata":{}},{"cell_type":"markdown","source":"Some annotations and locations in the train data are not present, we have to find the annotation using the patient history. Let's get the history of each pn_num together with the annotations. ","metadata":{}},{"cell_type":"code","source":"# There are many ways to match the patient history with feature text. I will go with our good old pandas merge. \ndf = pd.merge(train_df, notes, on = ['pn_num', 'case_num'])\ndf1 = pd.merge(df, features, on = ['feature_num', 'case_num'])\n\n# check if we have unique values as per the test data or not\ndf1.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.016624Z","iopub.execute_input":"2022-02-03T21:41:07.017534Z","iopub.status.idle":"2022-02-03T21:41:07.081294Z","shell.execute_reply.started":"2022-02-03T21:41:07.017485Z","shell.execute_reply":"2022-02-03T21:41:07.080407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Few annotations and locations need to be filled in the training data. For example,the pn_num 95333 doesn't have a annotation and location for feature number 912 and 913.","metadata":{}},{"cell_type":"code","source":"final_df = df1[['id','case_num', 'pn_num', 'pn_history','feature_num', 'feature_text', 'annotation', 'location']].sort_values(by ='id')\nfinal_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.082668Z","iopub.execute_input":"2022-02-03T21:41:07.083015Z","iopub.status.idle":"2022-02-03T21:41:07.124096Z","shell.execute_reply.started":"2022-02-03T21:41:07.082972Z","shell.execute_reply":"2022-02-03T21:41:07.123083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trying to find matching phrases and words between the patient notes and the feature text using spaCY's phrasematcher. This will help in getting the location in the patient notes. Let's see how this works. The location doesn't matched though.","metadata":{}},{"cell_type":"code","source":"# Let's take a look at the pn_history, with feature_text and annotation\nprint(f'**** üìú patient history*****\\n{final_df.pn_history.iloc[91]}')\n\nprint(f'****üßÆ feature_text ***** \\n {final_df.feature_text.iloc[91]}')\n\nprint(f'****üìå annotation ***** \\n {final_df.annotation.iloc[91]}')\n\nprint(f'****üìç location ***** \\n {final_df.location.iloc[91]}')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.125528Z","iopub.execute_input":"2022-02-03T21:41:07.125856Z","iopub.status.idle":"2022-02-03T21:41:07.134439Z","shell.execute_reply.started":"2022-02-03T21:41:07.125814Z","shell.execute_reply":"2022-02-03T21:41:07.133579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nfrom spacy import displacy\nfrom spacy.matcher import PhraseMatcher\nnlp = spacy.load(\"en_core_web_sm\")\nfrom textblob import TextBlob\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.135909Z","iopub.execute_input":"2022-02-03T21:41:07.136166Z","iopub.status.idle":"2022-02-03T21:41:07.839199Z","shell.execute_reply.started":"2022-02-03T21:41:07.136136Z","shell.execute_reply":"2022-02-03T21:41:07.838468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parse the feature text\ndef parse_feature_text(feature_text:str):\n    # remove extra characters and make the text lower\n    text = feature_text.replace(\"-\", \" \").lower()\n    # remove stop words\n    clean_text = [x for x in text.split() if x not in stop]\n    return clean_text","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.840178Z","iopub.execute_input":"2022-02-03T21:41:07.840784Z","iopub.status.idle":"2022-02-03T21:41:07.84556Z","shell.execute_reply.started":"2022-02-03T21:41:07.84075Z","shell.execute_reply":"2022-02-03T21:41:07.844736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parsed_feature = parse_feature_text(final_df.feature_text.iloc[91])\nprint(parsed_feature)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.846776Z","iopub.execute_input":"2022-02-03T21:41:07.847118Z","iopub.status.idle":"2022-02-03T21:41:07.861595Z","shell.execute_reply.started":"2022-02-03T21:41:07.847088Z","shell.execute_reply":"2022-02-03T21:41:07.860938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parse the patient notes, with just making the notes lower case. \ndef parse_patient_notes(note_text:str):\n    # just make the text lower\n    text = note_text.lower()\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.862888Z","iopub.execute_input":"2022-02-03T21:41:07.863271Z","iopub.status.idle":"2022-02-03T21:41:07.871881Z","shell.execute_reply.started":"2022-02-03T21:41:07.863238Z","shell.execute_reply":"2022-02-03T21:41:07.871159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('******Patient Notes')\nparsed_notes = parse_patient_notes(final_df.pn_history.iloc[91])\ndoc = nlp(final_df.pn_history.iloc[91])\nsentence_spans = list(doc.sents)\ndisplacy.render(sentence_spans, style=\"ent\", jupyter = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.873128Z","iopub.execute_input":"2022-02-03T21:41:07.873518Z","iopub.status.idle":"2022-02-03T21:41:07.936886Z","shell.execute_reply.started":"2022-02-03T21:41:07.873487Z","shell.execute_reply":"2022-02-03T21:41:07.936214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('******Related feature')\ndoc = nlp(final_df.feature_text.iloc[91])\nsentence_spans = list(doc.sents)\ndisplacy.render(sentence_spans, style=\"dep\", jupyter = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.937964Z","iopub.execute_input":"2022-02-03T21:41:07.938318Z","iopub.status.idle":"2022-02-03T21:41:07.960234Z","shell.execute_reply.started":"2022-02-03T21:41:07.938288Z","shell.execute_reply":"2022-02-03T21:41:07.959126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n# Match the keywords\ndef match_kw(parsed_feature, parsed_notes):\n    matcher = PhraseMatcher(nlp.vocab)\n\n    patterns = [nlp.make_doc(text) for text in parsed_feature]\n    \n    matcher.add(\"TerminologyList\", patterns)\n\n    doc = nlp(parsed_notes)\n    matches = matcher(doc)\n    \n    for match_id, start, end in matches:\n        span = doc[start:end]\n        print([span.text], [start, end])\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.96173Z","iopub.execute_input":"2022-02-03T21:41:07.962582Z","iopub.status.idle":"2022-02-03T21:41:07.970125Z","shell.execute_reply.started":"2022-02-03T21:41:07.962534Z","shell.execute_reply":"2022-02-03T21:41:07.9691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"match_kw(parsed_feature, parsed_notes)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T21:41:07.971519Z","iopub.execute_input":"2022-02-03T21:41:07.97251Z","iopub.status.idle":"2022-02-03T21:41:08.021399Z","shell.execute_reply.started":"2022-02-03T21:41:07.972456Z","shell.execute_reply":"2022-02-03T21:41:08.02049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install git+https://github.com/LIAAD/yake","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-03T21:41:08.0229Z","iopub.execute_input":"2022-02-03T21:41:08.023747Z","iopub.status.idle":"2022-02-03T21:41:08.027443Z","shell.execute_reply.started":"2022-02-03T21:41:08.023707Z","shell.execute_reply":"2022-02-03T21:41:08.02652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # let's extract the keywords from the patient notes and match it with the features.\n# import yake\n# text1 = final_df.pn_history.iloc[0]\n# language = \"en\"\n# max_ngram_size = 5\n# deduplication_thresold = 0.9\n# deduplication_algo = 'leve'\n# windowSize = 3\n# numOfKeywords = 20\n\n# custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_thresold, dedupFunc=deduplication_algo, windowsSize=windowSize, top=numOfKeywords, features=None)\n# keywords = custom_kw_extractor.extract_keywords(text1)\n\n# for kw in keywords:\n#     print(kw)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-03T21:41:08.031991Z","iopub.execute_input":"2022-02-03T21:41:08.032472Z","iopub.status.idle":"2022-02-03T21:41:08.043156Z","shell.execute_reply.started":"2022-02-03T21:41:08.032428Z","shell.execute_reply":"2022-02-03T21:41:08.042165Z"},"trusted":true},"execution_count":null,"outputs":[]}]}