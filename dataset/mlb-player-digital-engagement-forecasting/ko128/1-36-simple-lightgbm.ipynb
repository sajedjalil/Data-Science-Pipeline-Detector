{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Credit to @columbia2131 - I started with his notebook and then added an external data set with descriptive statistics of the targets for each player.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## About Dataset","metadata":{}},{"cell_type":"markdown","source":"Train.csv is stored as a csv file with each column as follows.  \ntrain.csvを以下のようにして各カラムをcsvファイルとして保管しています。\n\nTo use many data, I used fruction of \"reduce_mem_usage\" to reduce CPU load.\nCPU負荷を抑えるためにreduce_mem_usageという関数を使っています。\n\nParams are tuned by Light GBM tuner. \nパラメータはLight GBM tunerで調整しています。\n\nI want to continue feature engineering, because there are other features not used.\n特徴量エンジニアリングを続けたい、まだ使っていない特徴量があるため。","metadata":{}},{"cell_type":"code","source":"%%capture\n\"\"\"\n!pip install pandarallel \n\nimport gc\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom pandarallel import pandarallel\npandarallel.initialize()\n\nBASE_DIR = Path('../input/mlb-player-digital-engagement-forecasting')\ntrain = pd.read_csv(BASE_DIR / 'train.csv')\n\nnull = np.nan\ntrue = True\nfalse = False\n\nfor col in train.columns:\n\n    if col == 'date': continue\n\n    _index = train[col].notnull()\n    train.loc[_index, col] = train.loc[_index, col].parallel_apply(lambda x: eval(x))\n\n    outputs = []\n    for index, date, record in train.loc[_index, ['date', col]].itertuples():\n        _df = pd.DataFrame(record)\n        _df['index'] = index\n        _df['date'] = date\n        outputs.append(_df)\n\n    outputs = pd.concat(outputs).reset_index(drop=True)\n\n    outputs.to_csv(f'{col}_train.csv', index=False)\n    outputs.to_pickle(f'{col}_train.pkl')\n\n    del outputs\n    del train[col]\n    gc.collect()\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:14:52.218471Z","iopub.execute_input":"2021-07-15T13:14:52.218938Z","iopub.status.idle":"2021-07-15T13:14:52.235762Z","shell.execute_reply.started":"2021-07-15T13:14:52.218843Z","shell.execute_reply":"2021-07-15T13:14:52.234551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"execution":{"iopub.status.busy":"2021-06-16T09:14:33.869464Z","iopub.execute_input":"2021-06-16T09:14:33.869905Z","iopub.status.idle":"2021-06-16T09:14:33.874766Z","shell.execute_reply.started":"2021-06-16T09:14:33.869879Z","shell.execute_reply":"2021-06-16T09:14:33.873097Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.metrics import mean_absolute_error\nfrom datetime import timedelta\nfrom functools import reduce\nfrom tqdm import tqdm\nimport lightgbm as lgbm\nimport mlb\nimport gc\n\npd.options.display.max_rows = 200\npd.options.display.max_columns = 100","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:14:52.237375Z","iopub.execute_input":"2021-07-15T13:14:52.237699Z","iopub.status.idle":"2021-07-15T13:14:54.781715Z","shell.execute_reply.started":"2021-07-15T13:14:52.237669Z","shell.execute_reply":"2021-07-15T13:14:54.78043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fruction to reduce CPU load","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:14:54.783639Z","iopub.execute_input":"2021-07-15T13:14:54.784002Z","iopub.status.idle":"2021-07-15T13:14:54.79974Z","shell.execute_reply.started":"2021-07-15T13:14:54.783967Z","shell.execute_reply":"2021-07-15T13:14:54.79841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = Path('../input/mlb-player-digital-engagement-forecasting')\nTRAIN_DIR = Path('../input/mlb-pdef-train-dataset')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:14:54.801888Z","iopub.execute_input":"2021-07-15T13:14:54.80234Z","iopub.status.idle":"2021-07-15T13:14:54.820396Z","shell.execute_reply.started":"2021-07-15T13:14:54.802302Z","shell.execute_reply":"2021-07-15T13:14:54.818984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Select columns","metadata":{}},{"cell_type":"code","source":"targets_cols = [\n    'playerId', \n    'target1', \n    'target2', \n    'target3', \n    'target4', \n    'date'\n]\n\nplayers_cols = [\n    'playerId', \n    'primaryPositionName'\n]\n\nteams_cols = [\n    'id', \n#     'name', \n#     'teamName', \n#     'teamCode', \n#     'shortName', \n#     'abbreviation', \n#     'locationName', \n    'leagueId', \n#     'leagueName', \n    'divisionId', \n#     'divisionName', \n#     'venueId', \n#     'venueName'\n]\n\nrosters_cols = [\n    'playerId', \n    'teamId', \n    'status', \n    'date'\n]\n\nscores_cols = [\n    'playerId', \n    'battingOrder', \n    'gamesPlayedBatting', \n    'flyOuts',\n    'groundOuts', \n    'runsScored', \n    'doubles', \n    'triples', \n    'homeRuns',\n    'strikeOuts', \n    'baseOnBalls', \n    'intentionalWalks', \n    'hits', \n    'hitByPitch',\n    'atBats', \n    'caughtStealing', \n    'stolenBases', \n    'groundIntoDoublePlay',\n    'groundIntoTriplePlay', \n    'plateAppearances', \n    'totalBases', \n    'rbi',\n    'leftOnBase', \n    'sacBunts', \n    'sacFlies', \n    'catchersInterference',\n    'pickoffs', \n    'gamesPlayedPitching', \n    'gamesStartedPitching',\n    'completeGamesPitching', \n    'shutoutsPitching', \n    'winsPitching',\n    'lossesPitching', \n    'flyOutsPitching', \n    'airOutsPitching',\n    'groundOutsPitching', \n    'runsPitching', \n    'doublesPitching',\n    'triplesPitching', \n    'homeRunsPitching', \n    'strikeOutsPitching',\n    'baseOnBallsPitching', \n    'intentionalWalksPitching', \n    'hitsPitching',\n    'hitByPitchPitching', \n    'atBatsPitching', \n    'caughtStealingPitching',\n    'stolenBasesPitching', \n    'inningsPitched', \n    'saveOpportunities',\n    'earnedRuns', \n    'battersFaced', \n    'outsPitching', \n    'pitchesThrown', \n    'balls',\n    'strikes', \n    'hitBatsmen', \n    'balks', \n    'wildPitches', \n    'pickoffsPitching',\n    'rbiPitching', \n    'gamesFinishedPitching', \n    'inheritedRunners',\n    'inheritedRunnersScored', \n    'catchersInterferencePitching',\n    'sacBuntsPitching', \n    'sacFliesPitching', \n    'saves', \n    'holds', \n    'blownSaves',\n    'assists', \n    'putOuts', \n    'errors', \n    'chances', \n    'date'\n]\n\nawards_cols = [\n    'date', \n    'playerId',\n    'awardId'\n]\n\nplayerTwitterFollowers_cols = [\n    'playerId', \n    'numberOfFollowers'\n]\n\nteamTwitterFollowers_cols = [\n    'teamId', \n    'numberOfFollowers'\n]\n\nstandings_cols = [\n    'teamId', \n#     'wildCardRank', \n    'wins', \n    'losses', \n#     'divisionChamp', \n#     'divisionLeader', \n#     'wildCardLeader', \n    'lastTenWins',\n    'lastTenLosses',\n    'date'\n]\n\nfeature_cols = [\n    'label_playerId', \n    'label_primaryPositionName', \n    'label_teamId',\n    'label_status',\n    'playerId', \n    'battingOrder', \n    'gamesPlayedBatting', \n    'flyOuts',\n    'groundOuts', \n    'runsScored', \n    'doubles', \n    'triples', \n    'homeRuns',\n    'strikeOuts', \n    'baseOnBalls', \n    'intentionalWalks', \n    'hits', \n    'hitByPitch',\n    'atBats', \n    'caughtStealing', \n    'stolenBases', \n    'groundIntoDoublePlay',\n    'groundIntoTriplePlay', \n    'plateAppearances', \n    'totalBases', \n    'rbi',\n    'leftOnBase', \n    'sacBunts', \n    'sacFlies', \n    'catchersInterference',\n    'pickoffs', \n    'gamesPlayedPitching', \n    'gamesStartedPitching',\n    'completeGamesPitching', \n    'shutoutsPitching', \n    'winsPitching',\n    'lossesPitching', \n    'flyOutsPitching', \n    'airOutsPitching',\n    'groundOutsPitching', \n    'runsPitching', \n    'doublesPitching',\n    'triplesPitching', \n    'homeRunsPitching', \n    'strikeOutsPitching',\n    'baseOnBallsPitching', \n    'intentionalWalksPitching', \n    'hitsPitching',\n    'hitByPitchPitching', \n    'atBatsPitching', \n    'caughtStealingPitching',\n    'stolenBasesPitching', \n    'inningsPitched', \n    'saveOpportunities',\n    'earnedRuns', \n    'battersFaced', \n    'outsPitching', \n    'pitchesThrown', \n    'balls',\n    'strikes', \n    'hitBatsmen', \n    'balks', \n    'wildPitches', \n    'pickoffsPitching',\n    'rbiPitching', \n    'gamesFinishedPitching', \n    'inheritedRunners',\n    'inheritedRunnersScored', \n    'catchersInterferencePitching',\n    'sacBuntsPitching', \n    'sacFliesPitching', \n    'saves', \n    'holds', \n    'blownSaves',\n    'assists', \n    'putOuts', \n    'errors', \n    'chances', \n    'target1_mean',\n    'target1_median',\n    'target1_std',\n    'target1_min',\n    'target1_max',\n    'target1_prob',\n    'target2_mean',\n    'target2_median',\n    'target2_std',\n    'target2_min',\n    'target2_max',\n    'target2_prob',\n    'target3_mean',\n    'target3_median',\n    'target3_std',\n    'target3_min',\n    'target3_max',\n    'target3_prob',\n    'target4_mean',\n    'target4_median',\n    'target4_std',\n    'target4_min',\n    'target4_max',\n    'target4_prob',\n    'awardId_count',\n    'playernumberOfFollowers',               \n    'teamnumberOfFollowers',\n    'label_leagueId',\n    'label_divisionId',\n    'wins', \n    'losses', \n    'lastTenWins',\n    'lastTenLosses'\n]","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:14:54.822104Z","iopub.execute_input":"2021-07-15T13:14:54.822457Z","iopub.status.idle":"2021-07-15T13:14:54.845179Z","shell.execute_reply.started":"2021-07-15T13:14:54.822421Z","shell.execute_reply":"2021-07-15T13:14:54.843826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read data and groupby","metadata":{}},{"cell_type":"code","source":"players = pd.read_csv(BASE_DIR / 'players.csv', usecols = players_cols)\nplayers = reduce_mem_usage(players)\n\n\nteams = pd.read_csv(BASE_DIR / 'teams.csv', usecols = teams_cols)\nteams = teams.rename(columns = {'id':'teamId'})\nteams = reduce_mem_usage(teams)\n\n\nrosters = pd.read_csv(TRAIN_DIR / 'rosters_train.csv', usecols = rosters_cols)\nrosters = reduce_mem_usage(rosters)\n\n\ntargets = pd.read_csv(TRAIN_DIR / 'nextDayPlayerEngagement_train.csv', usecols = targets_cols)\ntargets = reduce_mem_usage(targets)\n\n\nscores = pd.read_csv(TRAIN_DIR / 'playerBoxScores_train.csv', usecols = scores_cols)\nscores = scores.groupby(['playerId', 'date']).sum().reset_index()\nscores = reduce_mem_usage(scores)\n\n\nawards = pd.read_csv(TRAIN_DIR / 'awards_train.csv', usecols = awards_cols)\n# awards = awards.groupby(['playerId', 'date']).count().reset_index()\n\n\nawards_count = awards[['playerId', 'awardId']].groupby('playerId').count().reset_index()\nawards_count = awards_count.rename(columns = {'awardId':'awardId_count'})\nawards_count = reduce_mem_usage(awards_count)\n\n\nplayerTwitterFollowers = pd.read_csv(TRAIN_DIR / 'playerTwitterFollowers_train.csv', usecols = playerTwitterFollowers_cols)\nplayerTwitterFollowers = playerTwitterFollowers.groupby('playerId').sum().reset_index()\nplayerTwitterFollowers = playerTwitterFollowers.rename(columns = {'numberOfFollowers':'playernumberOfFollowers'})\nplayerTwitterFollowers = reduce_mem_usage(playerTwitterFollowers)\n\n\nteamTwitterFollowers = pd.read_csv(TRAIN_DIR / 'teamTwitterFollowers_train.csv', usecols = teamTwitterFollowers_cols)\nteamTwitterFollowers = teamTwitterFollowers.groupby('teamId').sum().reset_index()\nteamTwitterFollowers = teamTwitterFollowers.rename(columns = {'numberOfFollowers':'teamnumberOfFollowers'})\nteamTwitterFollowers = reduce_mem_usage(teamTwitterFollowers)\n\n\nstandings = pd.read_csv(TRAIN_DIR / 'standings_train.csv', usecols = standings_cols)\nstandings = reduce_mem_usage(standings)\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:14:54.847666Z","iopub.execute_input":"2021-07-15T13:14:54.848236Z","iopub.status.idle":"2021-07-15T13:15:07.532359Z","shell.execute_reply.started":"2021-07-15T13:14:54.848179Z","shell.execute_reply":"2021-07-15T13:15:07.531093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"player_target_stats = pd.read_csv(\"../input/player-target-stats/player_target_stats.csv\")\ndata_names=player_target_stats.columns.values.tolist()\ndata_names","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:15:07.535621Z","iopub.execute_input":"2021-07-15T13:15:07.536174Z","iopub.status.idle":"2021-07-15T13:15:07.578983Z","shell.execute_reply.started":"2021-07-15T13:15:07.536117Z","shell.execute_reply":"2021-07-15T13:15:07.578005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make train data","metadata":{}},{"cell_type":"code","source":"# creat dataset\n\ntrain = targets.copy()[targets_cols]\n\nprint(targets[targets_cols].shape)\n\ntrain = train.merge(\n    players, \n    on=['playerId'], \n    how='left'\n)\ngc.collect()\n\nprint(train.shape, 'after_players')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    rosters, \n    on=['playerId', 'date'], \n    how='left'\n)\ngc.collect()\n\nprint(train.shape, 'after_rosters')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    scores, \n    on=['playerId', 'date'], \n    how='left'\n)\ngc.collect()\n\nprint(train.shape, 'after_scores')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    player_target_stats, \n    how='inner', \n    on= \"playerId\",\n)\ngc.collect()\n\nprint(train.shape, 'after_player_target_stats')\n\n\nprint('--------------------------------------')\n\ntrain = train.merge(\n    teams,\n    on = 'teamId',\n    how='left'\n)\n# del rosters\ngc.collect()\n\nprint(train.shape, 'after_teams')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    awards_count,\n    on = 'playerId',\n    how = 'left'\n)\n\ntrain['awardId_count'] = train['awardId_count'].fillna(0)\n\nprint(train.shape, 'after_awards_count')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    playerTwitterFollowers, \n    how = 'left', \n    on = 'playerId'\n)\ngc.collect()\n\nprint(train.shape, 'after_playerTwitter')\nprint('--------------------------------------')\n\n\ntrain = train.merge(\n    teamTwitterFollowers, \n    how = 'left', \n    on = 'teamId'\n)\ngc.collect()\n\nprint(train.shape, 'after_taemTwitter')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    standings, \n    how = 'left', \n    on = ['teamId', 'date']\n)\ngc.collect()\n\nprint(train.shape, 'after_standings')\nprint('--------------------------------------')\n\n\n# label encoding\nplayer2num = {c: i for i, c in enumerate(train['playerId'].unique())}\nposition2num = {c: i for i, c in enumerate(train['primaryPositionName'].unique())}\nteamid2num = {c: i for i, c in enumerate(train['teamId'].unique())}\nstatus2num = {c: i for i, c in enumerate(train['status'].unique())}\nleagueId2num = {c: i for i, c in enumerate(train['leagueId'].unique())}\ndivisionId2num = {c: i for i, c in enumerate(train['divisionId'].unique())}\n\n\ntrain['label_playerId'] = train['playerId'].map(player2num)\ntrain['label_primaryPositionName'] = train['primaryPositionName'].map(position2num)\ntrain['label_teamId'] = train['teamId'].map(teamid2num)\ntrain['label_status'] = train['status'].map(status2num)\ntrain['label_leagueId'] = train['leagueId'].map(leagueId2num)\ntrain['label_divisionId'] = train['divisionId'].map(divisionId2num)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:15:07.580686Z","iopub.execute_input":"2021-07-15T13:15:07.581242Z","iopub.status.idle":"2021-07-15T13:15:34.846399Z","shell.execute_reply.started":"2021-07-15T13:15:07.581198Z","shell.execute_reply":"2021-07-15T13:15:34.845134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:15:34.848184Z","iopub.execute_input":"2021-07-15T13:15:34.84853Z","iopub.status.idle":"2021-07-15T13:15:34.874149Z","shell.execute_reply.started":"2021-07-15T13:15:34.848494Z","shell.execute_reply":"2021-07-15T13:15:34.872806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:15:34.875573Z","iopub.execute_input":"2021-07-15T13:15:34.875876Z","iopub.status.idle":"2021-07-15T13:15:36.650638Z","shell.execute_reply.started":"2021-07-15T13:15:34.875847Z","shell.execute_reply":"2021-07-15T13:15:36.649485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Divide train and valid data","metadata":{}},{"cell_type":"code","source":"train_X = train[feature_cols]\ntrain_y = train[['target1', 'target2', 'target3', 'target4']]\n\n_index = (train['date'] < 20210401)\nx_train = train_X.loc[_index].reset_index(drop=True)\ny_train = train_y.loc[_index].reset_index(drop=True)\nx_valid = train_X.loc[~_index].reset_index(drop=True)\ny_valid = train_y.loc[~_index].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:15:36.652281Z","iopub.execute_input":"2021-07-15T13:15:36.652858Z","iopub.status.idle":"2021-07-15T13:15:42.300405Z","shell.execute_reply.started":"2021-07-15T13:15:36.65281Z","shell.execute_reply":"2021-07-15T13:15:42.299491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n    oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n    model = lgbm.LGBMRegressor(**params)\n    model.fit(x_train, y_train, \n        eval_set=[(x_valid, y_valid)],  \n        early_stopping_rounds=verbose, \n        verbose=verbose)\n    oof_pred = model.predict(x_valid)\n    score = mean_absolute_error(oof_pred, y_valid)\n    print('mae:', score)\n    return oof_pred, model, score\n\n\"\"\"\n# training lightgbm before param\nparams = {\n 'objective':'mae',\n 'reg_alpha': 0.1,\n 'reg_lambda': 0.1, \n 'n_estimators': 100000,\n 'learning_rate': 0.1,\n 'random_state': 42,\n}\n\"\"\"\n\nparams1 = {'objective': 'mae', 'metric': 'l1', 'feature_pre_filter': False, 'lambda_l1': 3.485822021802935e-08, 'lambda_l2': 4.230468117096112e-06, 'num_leaves': 253, 'feature_fraction': 0.8, 'bagging_fraction': 0.550250698524785, 'bagging_freq': 1, 'min_child_samples': 20, 'num_iterations': 10000, 'early_stopping_round': 100}\n\nparams2 = {'objective': 'mae', 'metric': 'l1', 'feature_pre_filter': False, 'lambda_l1': 3.731605225849285, 'lambda_l2': 0.02803980626777797, 'num_leaves': 8, 'feature_fraction': 0.5, 'bagging_fraction': 0.5262728428461787, 'bagging_freq': 3, 'min_child_samples': 20, 'num_iterations': 10000, 'early_stopping_round': 100}\n\nparams3 = {'objective': 'mae', 'metric': 'l1', 'feature_pre_filter': False, 'lambda_l1': 7.654830305013684, 'lambda_l2': 4.14748542765967e-07, 'num_leaves': 252, 'feature_fraction': 0.7200000000000001, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 10000, 'early_stopping_round': 100}\n\nparams4 = {'objective': 'mae', 'metric': 'l1', 'feature_pre_filter': False, 'lambda_l1': 9.486880706514734e-08, 'lambda_l2': 0.005143767850872896, 'num_leaves': 246, 'feature_fraction': 0.5479999999999999, 'bagging_fraction': 0.5238463354446826, 'bagging_freq': 5, 'min_child_samples': 20, 'num_iterations': 10000, 'early_stopping_round': 100}\n\n\n\noof1, model1, score1 = fit_lgbm(\n    x_train, y_train['target1'],\n    x_valid, y_valid['target1'],\n    params1\n)\noof2, model2, score2 = fit_lgbm(\n    x_train, y_train['target2'],\n    x_valid, y_valid['target2'],\n    params2\n)\noof3, model3, score3 = fit_lgbm(\n    x_train, y_train['target3'],\n    x_valid, y_valid['target3'],\n    params3\n)\noof4, model4, score4 = fit_lgbm(\n    x_train, y_train['target4'],\n    x_valid, y_valid['target4'],\n    params4\n)\n\nscore = (score1+score2+score3+score4) / 4\nprint(f'score: {score}')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:15:42.301626Z","iopub.execute_input":"2021-07-15T13:15:42.302087Z","iopub.status.idle":"2021-07-15T13:23:23.145275Z","shell.execute_reply.started":"2021-07-15T13:15:42.302054Z","shell.execute_reply":"2021-07-15T13:23:23.142217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Example for tuning","metadata":{}},{"cell_type":"raw","source":"import optuna.integration.lightgbm as lgbm\n\ndef fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n        \n    oof_pred = np.zeros(len(y_valid), dtype=np.float32)    \n    \n    trains = lgbm.Dataset(x_train, y_train)\n    valids = lgbm.Dataset(x_valid, y_valid)\n    \n    model = lgbm.train(\n        params, \n        trains,\n        valid_sets = valids,\n        num_boost_round = 10000,\n        verbose_eval = False,\n        early_stopping_rounds = 100\n    )\n    \n    best_params = model.params\n    \n    oof_pred = model.predict(x_valid)\n    score = mean_absolute_error(oof_pred, y_valid)\n    print('mae:', score)\n    return oof_pred, model, score, best_params\n    \nparams = {\n    'objective':'mae',\n    'metric':'mae'\n}\n\n\n\noof4, model4, score4, best_params4 = fit_lgbm(\n        x_train, y_train['target4'],\n        x_valid, y_valid['target4'],\n        params\n)\n\nprint(best_params4)","metadata":{}},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"rosters_cols.remove('date')\nscores_cols.remove('date')\nstandings_cols = [\n    'teamId', \n    'wins', \n    'losses', \n    'lastTenWins',\n    'lastTenLosses'\n]\n\nnull = np.nan\ntrue = True\nfalse = False\n\nenv = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set\n\nfor (test_df, sample_prediction_df) in iter_test: # make predictions here\n    \n    sample_prediction_df = sample_prediction_df.reset_index(drop=True)\n    \n    # creat dataset\n    sample_prediction_df['playerId'] = sample_prediction_df['date_playerId']\\\n                                        .map(lambda x: int(x.split('_')[1]))\n    # Dealing with missing values\n    if test_df['rosters'].iloc[0] == test_df['rosters'].iloc[0]:\n        test_rosters = pd.DataFrame(eval(test_df['rosters'].iloc[0]))\n    else:\n        test_rosters = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in rosters.columns:\n            if col == 'playerId': continue\n            test_rosters[col] = np.nan\n            \n    if test_df['playerBoxScores'].iloc[0] == test_df['playerBoxScores'].iloc[0]:\n        test_scores = pd.DataFrame(eval(test_df['playerBoxScores'].iloc[0]))\n    else:\n        test_scores = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in scores.columns:\n            if col == 'playerId': continue\n            test_scores[col] = np.nan\n            \n    if test_df['standings'].iloc[0] == test_df['standings'].iloc[0]:\n        test_standings = pd.DataFrame(eval(test_df['standings'].iloc[0]))\n    else:\n        test_standings = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in standings.columns:\n            if col == 'playerId': continue\n            test_scores[col] = np.nan\n            \n            \n    test_scores = test_scores.groupby('playerId').sum().reset_index()\n    test = sample_prediction_df[['playerId']].copy()\n    test = test.merge(players[players_cols], on='playerId', how='left')\n    test = test.merge(test_rosters[rosters_cols], on='playerId', how='left')\n    test = test.merge(test_scores[scores_cols], on='playerId', how='left')\n    test = test.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n    test = test.merge(awards_count, how = 'left', on = 'playerId')\n    test = test.merge(teams, how = 'left', on = 'teamId')\n    test['awardId_count'] = test['awardId_count'].fillna(0)\n    test = test.merge(playerTwitterFollowers, how = 'left', on ='playerId')\n    test = test.merge(teamTwitterFollowers, how = 'left', on ='teamId')\n    test = test.merge(test_standings[standings_cols], how = 'left', on = 'teamId')\n\n    \n\n    test['label_playerId'] = test['playerId'].map(player2num)\n    test['label_primaryPositionName'] = test['primaryPositionName'].map(position2num)\n    test['label_teamId'] = test['teamId'].map(teamid2num)\n    test['label_status'] = test['status'].map(status2num)\n    test['label_leagueId'] = test['leagueId'].map(leagueId2num)\n    test['label_divisionId'] = test['divisionId'].map(divisionId2num)\n    \n    test_X = test[feature_cols]\n    \n    # predict\n    pred1 = model1.predict(test_X)\n    pred2 = model2.predict(test_X)\n    pred3 = model3.predict(test_X)\n    pred4 = model4.predict(test_X)\n    \n    # merge submission\n    sample_prediction_df['target1'] = np.clip(pred1, 0, 100)\n    sample_prediction_df['target2'] = np.clip(pred2, 0, 100)\n    sample_prediction_df['target3'] = np.clip(pred3, 0, 100)\n    sample_prediction_df['target4'] = np.clip(pred4, 0, 100)\n    sample_prediction_df = sample_prediction_df.fillna(0.)\n    del sample_prediction_df['playerId']\n    \n    env.predict(sample_prediction_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:23:23.147968Z","iopub.execute_input":"2021-07-15T13:23:23.148557Z","iopub.status.idle":"2021-07-15T13:23:27.03101Z","shell.execute_reply.started":"2021-07-15T13:23:23.148499Z","shell.execute_reply":"2021-07-15T13:23:27.029801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_prediction_df","metadata":{"execution":{"iopub.status.busy":"2021-07-15T13:23:27.032836Z","iopub.execute_input":"2021-07-15T13:23:27.033635Z","iopub.status.idle":"2021-07-15T13:23:27.068751Z","shell.execute_reply.started":"2021-07-15T13:23:27.033581Z","shell.execute_reply":"2021-07-15T13:23:27.06734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}