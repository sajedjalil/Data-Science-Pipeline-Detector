{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.metrics import mean_absolute_error\nfrom datetime import timedelta\nfrom functools import reduce\nfrom tqdm import tqdm\nimport lightgbm as lgbm\nimport mlb\nimport os\n\nimport gc\n\n\nBASE_DIR = Path('../input/mlb-player-digital-engagement-forecasting')\n#train = pd.read_csv(BASE_DIR / 'train_updated.csv')\nif os.path.isfile(BASE_DIR / 'train_updated.csv'):\n    train = pd.read_csv(BASE_DIR / 'train_updated.csv')\n    print(10*'=','train_updated.csv','load',10*'=')\nelse:\n    train = pd.read_csv(BASE_DIR / 'train.csv')\n    print(10*'=','train.csv','load',10*'=')\n            \nnull = np.nan\ntrue = True\nfalse = False\n\nfor col in ['rosters','nextDayPlayerEngagement','playerBoxScores']:\n    print(10*'*','this is',col,10*'*')\n    if col == 'date': continue\n\n    _index = train[col].notnull()\n    train.loc[_index, col] = train.loc[_index, col].apply(lambda x: eval(x))\n\n    outputs = []\n    for index, date, record in train.loc[_index, ['date', col]].itertuples():\n        _df = pd.DataFrame(record)\n        _df['index'] = index\n        _df['date'] = date\n        outputs.append(_df)\n\n    outputs = pd.concat(outputs).reset_index(drop=True)\n\n    outputs.to_csv(f'{col}_train.csv', index=False)\n    outputs.to_pickle(f'{col}_train.pkl')\n\n    del outputs\n    del train[col]\n    gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:20:24.368434Z","iopub.execute_input":"2021-07-26T10:20:24.3689Z","iopub.status.idle":"2021-07-26T10:25:39.685755Z","shell.execute_reply.started":"2021-07-26T10:20:24.36885Z","shell.execute_reply":"2021-07-26T10:25:39.684182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = Path('../input/mlb-player-digital-engagement-forecasting')\nTRAIN_DIR = Path('./')\n\nplayers = pd.read_csv(BASE_DIR / 'players.csv')\n\nrosters = pd.read_pickle(TRAIN_DIR / 'rosters_train.pkl')\ntargets = pd.read_pickle(TRAIN_DIR / 'nextDayPlayerEngagement_train.pkl')\nscores = pd.read_pickle(TRAIN_DIR / 'playerBoxScores_train.pkl')\nscores = scores.groupby(['playerId', 'date']).sum().reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:26:02.194142Z","iopub.execute_input":"2021-07-26T10:26:02.194541Z","iopub.status.idle":"2021-07-26T10:26:03.723654Z","shell.execute_reply.started":"2021-07-26T10:26:02.194504Z","shell.execute_reply":"2021-07-26T10:26:03.722544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets_cols = ['playerId', 'target1', 'target2', 'target3', 'target4', 'date']\nplayers_cols = ['playerId', 'primaryPositionName','heightInches','weight']\nrosters_cols = ['playerId', 'teamId', 'status', 'date']\nscores_cols = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n       'inheritedRunnersScored', 'catchersInterferencePitching',\n       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n       'assists', 'putOuts', 'errors', 'chances', 'date']\n\nfeature_cols = ['label_playerId', 'label_primaryPositionName', 'label_teamId',\n       'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n       'inheritedRunnersScored', 'catchersInterferencePitching',\n       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n       'assists', 'putOuts', 'errors', 'chances','target1_mean',\n 'target1_median',\n 'target1_std',\n 'target1_min',\n 'target1_max',\n 'target1_prob',\n 'target2_mean',\n 'target2_median',\n 'target2_std',\n 'target2_min',\n 'target2_max',\n 'target2_prob',\n 'target3_mean',\n 'target3_median',\n 'target3_std',\n 'target3_min',\n 'target3_max',\n 'target3_prob',\n 'target4_mean',\n 'target4_median',\n 'target4_std',\n 'target4_min',\n 'target4_max',\n 'target4_prob']\nfeature_cols2 = ['label_playerId', 'label_primaryPositionName', 'label_teamId',\n       'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n       'inheritedRunnersScored', 'catchersInterferencePitching',\n       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n       'assists', 'putOuts', 'errors', 'chances','target1_mean',\n 'target1_median',\n 'target1_std',\n 'target1_min',\n 'target1_max',\n 'target1_prob',\n 'target2_mean',\n 'target2_median',\n 'target2_std',\n 'target2_min',\n 'target2_max',\n 'target2_prob',\n 'target3_mean',\n 'target3_median',\n 'target3_std',\n 'target3_min',\n 'target3_max',\n 'target3_prob',\n 'target4_mean',\n 'target4_median',\n 'target4_std',\n 'target4_min',\n 'target4_max',\n 'target4_prob',\n    'target1']","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.802136Z","iopub.status.idle":"2021-07-26T10:19:06.802574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"player_target_stats = pd.read_csv(\"../input/my-player-target-stat/player_target_stats.csv\")\ndata_names=player_target_stats.columns.values.tolist()\ndata_names","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.803548Z","iopub.status.idle":"2021-07-26T10:19:06.804198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creat dataset\ntrain = targets[targets_cols].merge(players[players_cols], on=['playerId'], how='left')\ntrain = train.merge(rosters[rosters_cols], on=['playerId', 'date'], how='left')\ntrain = train.merge(scores[scores_cols], on=['playerId', 'date'], how='left')\ntrain = train.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n\n\n# label encoding\nplayer2num = {c: i for i, c in enumerate(train['playerId'].unique())}\nposition2num = {c: i for i, c in enumerate(train['primaryPositionName'].unique())}\nteamid2num = {c: i for i, c in enumerate(train['teamId'].unique())}\nstatus2num = {c: i for i, c in enumerate(train['status'].unique())}\ntrain['label_playerId'] = train['playerId'].map(player2num)\ntrain['label_primaryPositionName'] = train['primaryPositionName'].map(position2num)\ntrain['label_teamId'] = train['teamId'].map(teamid2num)\ntrain['label_status'] = train['status'].map(status2num)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.80537Z","iopub.status.idle":"2021-07-26T10:19:06.805929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X = train[feature_cols]\ntrain_y = train[['target1', 'target2', 'target3', 'target4']]\n\n#_index = (train['date'] < 20210401)\n_index = ((train['date'] > 20200529) & (train['date'] <= 20200831)) | ((train['date'] > 20190529) & (train['date'] <= 20190831)) | ((train['date'] > 20180529) & (train['date'] <= 20180831))\nx_train1 = train_X.loc[~_index].reset_index(drop=True)\ny_train1 = train_y.loc[~_index].reset_index(drop=True)\nx_valid1 = train_X.loc[_index].reset_index(drop=True)\ny_valid1 = train_y.loc[_index].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.807109Z","iopub.status.idle":"2021-07-26T10:19:06.80773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X = train[feature_cols2]\ntrain_y = train[['target1', 'target2', 'target3', 'target4']]\n\n#_index = (train['date'] < 20210401)\nx_train2 = train_X.loc[~_index].reset_index(drop=True)\ny_train2 = train_y.loc[~_index].reset_index(drop=True)\nx_valid2 = train_X.loc[_index].reset_index(drop=True)\ny_valid2 = train_y.loc[_index].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.809356Z","iopub.status.idle":"2021-07-26T10:19:06.810057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGB","metadata":{}},{"cell_type":"code","source":"def fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n    oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n    model = lgbm.LGBMRegressor(**params)\n    model.fit(x_train, y_train, \n        eval_set=[(x_valid, y_valid)],  \n        early_stopping_rounds=verbose, \n        verbose=verbose)\n    oof_pred = model.predict(x_valid)\n    score = mean_absolute_error(oof_pred, y_valid)\n    print('mae:', score)\n    return oof_pred, model, score\n\n\nparams1 = {'objective':'mae',\n           'reg_alpha': 0.14547461820098767, \n           'reg_lambda': 0.10185644384043743, \n           'n_estimators': 3333, \n           'learning_rate': 0.1046301304430488, \n           'num_leaves': 674, \n           'feature_fraction': 0.8101240539122566, \n           'bagging_fraction': 0.8884451442950513, \n           'bagging_freq': 8, \n           'min_child_samples': 51}\n\nparams2 = {\n 'objective':'mae',\n           'reg_alpha': 0.14947461820098767, \n           'reg_lambda': 0.10185644384043743, \n           'n_estimators': 3633, \n           'learning_rate': 0.08046301304430488, \n           'num_leaves': 64, \n           'feature_fraction': 0.9101240539122566, \n           'bagging_fraction': 0.9884451442950513, \n           'bagging_freq': 3, \n           'min_child_samples': 15\n}\n\nparams4 = {'objective':'mae',\n           'reg_alpha': 0.016468100279441976, \n           'reg_lambda': 0.09128335764019105, \n           'n_estimators': 9868, \n           'learning_rate': 0.10528150510326864, \n           'num_leaves': 157, \n           'feature_fraction': 0.5419185713426886, \n           'bagging_fraction': 0.2637405128936662, \n           'bagging_freq': 19, \n           'min_child_samples': 71}\n\n\nparams = {\n 'objective':'mae',\n#  'reg_alpha': 0.1,\n#  'reg_lambda': 0.1, \n 'n_estimators': 10000,\n 'learning_rate': 0.1,\n 'random_state': 2021,\n \"num_leaves\": 127,\n 'feature_fraction': 0.5419185713426886, \n 'bagging_fraction': 0.5637405128936662, \n 'bagging_freq': 15, \n}\n\n\n\noof1, model1, score1 = fit_lgbm(\n    x_train1, y_train1['target1'],\n    x_valid1, y_valid1['target1'],\n    params1\n )\n\noof2, model2, score2 = fit_lgbm(\n    x_train2, y_train2['target2'],\n    x_valid2, y_valid2['target2'],\n    params2\n)\n\noof3, model3, score3 = fit_lgbm(\n    x_train2, y_train2['target3'],\n    x_valid2, y_valid2['target3'],\n   params\n)\n\noof4, model4, score4 = fit_lgbm(\n    x_train2, y_train2['target4'],\n    x_valid2, y_valid2['target4'],\n    params4\n)\n\nscore = (score1+score2+score3+score4) / 4\nprint(f'score: {score}')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.811353Z","iopub.status.idle":"2021-07-26T10:19:06.812015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cat","metadata":{}},{"cell_type":"code","source":"import pickle\nfrom catboost import CatBoostRegressor\n\ndef fit_lgbm(x_train, y_train, x_valid, y_valid, target, params: dict=None, verbose=100):\n    oof_pred_lgb = np.zeros(len(y_valid), dtype=np.float32)\n    oof_pred_cat = np.zeros(len(y_valid), dtype=np.float32)\n    \n    if os.path.isfile(f'../input/mlb-lightgbm-training/mymodel_lgb_{target}.pkl'):\n        with open(f'../input/mlb-lightgbm-training/mymodel_lgb_{target}.pkl', 'rb') as fin:\n            model = pickle.load(fin)\n            oof_pred_lgb = model.predict(x_valid)\n            score_lgb = mean_absolute_error(oof_pred_lgb, y_valid)\n            print('*'*10,fin,'*'*10)\n            print('mae:', score_lgb)\n    else:\n        with open(f'mymodel_lgb_{target}.pkl', 'wb') as handle:\n            pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n\n    \n    if os.path.isfile(f'../input/mlb-catboost-training/mymodel_cb_{target}.pkl'):\n        with open(f'../input/mlb-catboost-training/mymodel_cb_{target}.pkl', 'rb') as fin:\n            model_cb = pickle.load(fin)\n            oof_pred_cat = model_cb.predict(x_valid)\n            score_cat = mean_absolute_error(oof_pred_cat, y_valid)\n            print('*'*10,fin,'*'*10)\n            print('mae:', score_cat)\n    \n    else:\n\n        with open(f'model_cb_{target}.pkl', 'wb') as handle:\n            pickle.dump(model_cb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n\n    return oof_pred_lgb, model, oof_pred_cat, model_cb, score_lgb, score_cat\n\n\nparams = {\n'boosting_type': 'gbdt',\n'objective':'mae',\n'subsample': 0.6,\n'subsample_freq': 1,\n'learning_rate': 0.03,\n'num_leaves': 2**11-1,\n'min_data_in_leaf': 2**12-1,\n'feature_fraction': 0.6,\n'max_bin': 100,\n'n_estimators': 2500,\n'boost_from_average': False,\n\"random_seed\":2021,\n}\n\noof_pred_lgb2, model_lgb2, oof_pred_cat2, model_cb2, score_lgb2, score_cat2 = fit_lgbm(\n    x_train1, y_train1['target2'],\n    x_valid1, y_valid1['target2'],\n    2, params\n)\n\noof_pred_lgb1, model_lgb1, oof_pred_cat1, model_cb1, score_lgb1, score_cat1 = fit_lgbm(\n    x_train1, y_train1['target1'],\n    x_valid1, y_valid1['target1'],\n    1, params\n)\n\noof_pred_lgb3, model_lgb3, oof_pred_cat3, model_cb3, score_lgb3, score_cat3 = fit_lgbm(\n    x_train1, y_train1['target3'],\n    x_valid1, y_valid1['target3'],\n    3, params\n)\noof_pred_lgb4, model_lgb4, oof_pred_cat4, model_cb4, score_lgb4, score_cat4= fit_lgbm(\n    x_train1, y_train1['target4'],\n    x_valid1, y_valid1['target4'],\n    4, params\n)\n\nscore = (score_lgb1+score_lgb2+score_lgb3+score_lgb4) / 4\nprint(f'LightGBM score: {score}')\n\nscore = (score_cat1+score_cat2+score_cat3+score_cat4) / 4\nprint(f'Catboost score: {score}')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.813626Z","iopub.status.idle":"2021-07-26T10:19:06.81429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ANN","metadata":{}},{"cell_type":"code","source":"players_cols = ['playerId', 'primaryPositionName']\nrosters_cols = ['playerId', 'teamId', 'status']\nscores_cols = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n       'inheritedRunnersScored', 'catchersInterferencePitching',\n       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n       'assists', 'putOuts', 'errors', 'chances']\n\nnull = np.nan\ntrue = True\nfalse = False","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.815701Z","iopub.status.idle":"2021-07-26T10:19:06.816295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import timedelta\nfrom tqdm import tqdm\nimport gc\nfrom functools import reduce\nfrom sklearn.model_selection import StratifiedKFold\n\nROOT_DIR = \"../input/mlb-player-digital-engagement-forecasting\"\n\n#=======================#\ndef flatten(df, col):\n    du = (df.pivot(index=\"playerId\", columns=\"EvalDate\", \n               values=col).add_prefix(f\"{col}_\").\n      rename_axis(None, axis=1).reset_index())\n    return du\n#============================#\ndef reducer(left, right):\n    return left.merge(right, on=\"playerId\")\n#========================\n\nTGTCOLS = [\"target1\",\"target2\",\"target3\",\"target4\"]\ndef train_lag(df, lag=1):\n    dp = df[[\"playerId\",\"EvalDate\"]+TGTCOLS].copy()\n    dp[\"EvalDate\"]  =dp[\"EvalDate\"] + timedelta(days=lag) \n    df = df.merge(dp, on=[\"playerId\", \"EvalDate\"], suffixes=[\"\",f\"_{lag}\"], how=\"left\")\n    return df\n#=================================\ndef test_lag(sub):\n    sub[\"playerId\"] = sub[\"date_playerId\"].apply(lambda s: int(  s.split(\"_\")[1]  ) )\n    assert sub.date.nunique() == 1\n    dte = sub[\"date\"].unique()[0]\n    \n    eval_dt = pd.to_datetime(dte, format=\"%Y%m%d\")\n    dtes = [eval_dt + timedelta(days=-k) for k in LAGS]\n    mp_dtes = {eval_dt + timedelta(days=-k):k for k in LAGS}\n    \n    sl = LAST.loc[LAST.EvalDate.between(dtes[-1], dtes[0]), [\"EvalDate\",\"playerId\"]+TGTCOLS].copy()\n    sl[\"EvalDate\"] = sl[\"EvalDate\"].map(mp_dtes)\n    du = [flatten(sl, col) for col in TGTCOLS]\n    du = reduce(reducer, du)\n    return du, eval_dt\n    #\n#===============\n\ntr = pd.read_csv(\"../input/my-mlb-data/target.csv\")\nprint(tr.shape)\ngc.collect()\n\ntr[\"EvalDate\"] = pd.to_datetime(tr[\"EvalDate\"])\ntr[\"EvalDate\"] = tr[\"EvalDate\"] + timedelta(days=-1)\ntr[\"EvalYear\"] = tr[\"EvalDate\"].dt.year\n\nMED_DF = tr.groupby([\"playerId\",\"EvalYear\"])[TGTCOLS].median().reset_index()\nMEDCOLS = [\"tgt1_med\",\"tgt2_med\", \"tgt3_med\", \"tgt4_med\"]\nMED_DF.columns = [\"playerId\",\"EvalYear\"] + MEDCOLS\n\nLAGS = list(range(1,21))\nFECOLS = [f\"{col}_{lag}\" for lag in reversed(LAGS) for col in TGTCOLS]\n\nfor lag in tqdm(LAGS):\n    tr = train_lag(tr, lag=lag)\n    gc.collect()\n#===========\ntr = tr.sort_values(by=[\"playerId\", \"EvalDate\"])\nprint(tr.shape)\ntr = tr.dropna()\nprint(tr.shape)\ntr = tr.merge(MED_DF, on=[\"playerId\",\"EvalYear\"])\ngc.collect()\n\nX = tr[FECOLS+MEDCOLS].values\ny = tr[TGTCOLS].values\ncl = tr[\"playerId\"].values\n\nNFOLDS = 5\nskf = StratifiedKFold(n_splits=NFOLDS)\nfolds = skf.split(X, cl)\nfolds = list(folds)\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\ntf.random.set_seed(2021)\n\ndef make_model(n_in):\n    inp = L.Input(name=\"inputs\", shape=(n_in,))\n    x = L.Dense(50, activation=\"relu\", name=\"d1\")(inp)\n    x = L.Dense(50, activation=\"relu\", name=\"d2\")(x)\n    preds = L.Dense(4, activation=\"linear\", name=\"preds\")(x)\n    \n    model = M.Model(inp, preds, name=\"ANN\")\n    model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n    return model\n\nnet = make_model(X.shape[1])\nprint(net.summary())\n\noof = np.zeros(y.shape)\nnets = []\nfor idx in range(NFOLDS):\n    print(\"FOLD:\", idx)\n    tr_idx, val_idx = folds[idx]\n    ckpt = ModelCheckpoint(f\"../input/mlb-ann-training/w{idx}.h5\", monitor='val_loss', verbose=1, save_best_only=True,mode='min')\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3, min_lr=0.0001)\n    es = EarlyStopping(monitor='val_loss', patience=5)\n    reg = make_model(X.shape[1])\n#     reg.fit(X[tr_idx], y[tr_idx], epochs=10, batch_size=30_000, validation_data=(X[val_idx], y[val_idx]),\n#             verbose=1, callbacks=[ckpt, reduce_lr, es])\n    reg.load_weights(f\"../input/mlb-ann-training/w{idx}.h5\")\n    oof[val_idx] = reg.predict(X[val_idx], batch_size=50_000, verbose=1)\n    nets.append(reg)\n    gc.collect()\n\nmae = mean_absolute_error(y, oof)\nmse = mean_squared_error(y, oof, squared=False)\nprint(\"mae:\", mae)\nprint(\"mse:\", mse)\n\n# Historical information to use in prediction time\nbound_dt = pd.to_datetime(\"2021-01-01\")\nLAST = tr.loc[tr.EvalDate>bound_dt].copy()\n\nLAST_MED_DF = MED_DF.loc[MED_DF.EvalYear==2021].copy()\nLAST_MED_DF.drop(\"EvalYear\", axis=1, inplace=True)\ndel tr\n\n#\"\"\"\nimport mlb\nFE = []; SUB = [];","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.817504Z","iopub.status.idle":"2021-07-26T10:19:06.817996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"import copy\n\nenv = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set\n\nfor (test_df, sample_prediction_df) in iter_test: # make predictions here\n    \n    sub = copy.deepcopy(sample_prediction_df.reset_index())\n    sample_prediction_df = copy.deepcopy(sample_prediction_df.reset_index(drop=True))\n    \n    # LGBM summit\n    # creat dataset\n    sample_prediction_df['playerId'] = sample_prediction_df['date_playerId']\\\n                                        .map(lambda x: int(x.split('_')[1]))\n    # Dealing with missing values\n    if test_df['rosters'].iloc[0] == test_df['rosters'].iloc[0]:\n        test_rosters = pd.DataFrame(eval(test_df['rosters'].iloc[0]))\n    else:\n        test_rosters = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in rosters.columns:\n            if col == 'playerId': continue\n            test_rosters[col] = np.nan\n            \n    if test_df['playerBoxScores'].iloc[0] == test_df['playerBoxScores'].iloc[0]:\n        test_scores = pd.DataFrame(eval(test_df['playerBoxScores'].iloc[0]))\n    else:\n        test_scores = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in scores.columns:\n            if col == 'playerId': continue\n            test_scores[col] = np.nan\n    test_scores = test_scores.groupby('playerId').sum().reset_index()\n    test = sample_prediction_df[['playerId']].copy()\n    test = test.merge(players[players_cols], on='playerId', how='left')\n    test = test.merge(test_rosters[rosters_cols], on='playerId', how='left')\n    test = test.merge(test_scores[scores_cols], on='playerId', how='left')\n    test = test.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n    \n\n    test['label_playerId'] = test['playerId'].map(player2num)\n    test['label_primaryPositionName'] = test['primaryPositionName'].map(position2num)\n    test['label_teamId'] = test['teamId'].map(teamid2num)\n    test['label_status'] = test['status'].map(status2num)\n    \n    test_X = test[feature_cols]\n    # predict\n    pred1 = model1.predict(test_X)\n    \n    # predict\n    pred_lgd1 = model_lgb1.predict(test_X)\n    pred_lgd2 = model_lgb2.predict(test_X)\n    pred_lgd3 = model_lgb3.predict(test_X)\n    pred_lgd4 = model_lgb4.predict(test_X)\n    \n    pred_cat1 = model_cb1.predict(test_X)\n    pred_cat2 = model_cb2.predict(test_X)\n    pred_cat3 = model_cb3.predict(test_X)\n    pred_cat4 = model_cb4.predict(test_X)\n    \n    test['target1'] = np.clip(pred1,0,100)\n    test_X = test[feature_cols2]\n\n    pred2 = model2.predict(test_X)\n    pred3 = model3.predict(test_X)\n    pred4 = model4.predict(test_X)\n    \n    # merge submission\n    sample_prediction_df['target1'] = 1.00*np.clip(pred1, 0, 100)+0.00*np.clip(pred_lgd1, 0, 100)+0.00*np.clip(pred_cat1, 0, 100)\n    sample_prediction_df['target2'] = 0.05*np.clip(pred2, 0, 100)+0.54*np.clip(pred_lgd2, 0, 100)+0.405*np.clip(pred_cat2, 0, 100)\n    sample_prediction_df['target3'] = 0.76*np.clip(pred3, 0, 100)+0.14*np.clip(pred_lgd3, 0, 100)+0.10*np.clip(pred_cat3, 0, 100)\n    sample_prediction_df['target4'] = 0.77*np.clip(pred4, 0, 100)+0.13*np.clip(pred_lgd4, 0, 100)+0.10*np.clip(pred_cat4, 0, 100)\n    sample_prediction_df = sample_prediction_df.fillna(0.)\n    del sample_prediction_df['playerId']\n    # TF summit\n    # Features computation at Evaluation Date\n    sub_fe, eval_dt = test_lag(sub)\n    sub_fe = sub_fe.merge(LAST_MED_DF, on=\"playerId\", how=\"left\")\n    sub_fe = sub_fe.fillna(0.)\n    \n    _preds = 0.\n    for reg in nets:\n        _preds += reg.predict(sub_fe[FECOLS + MEDCOLS]) / NFOLDS\n    sub_fe[TGTCOLS] = np.clip(_preds, 0, 100)\n    sub.drop([\"date\"]+TGTCOLS, axis=1, inplace=True)\n    sub = sub.merge(sub_fe[[\"playerId\"]+TGTCOLS], on=\"playerId\", how=\"left\")\n    sub.drop(\"playerId\", axis=1, inplace=True)\n    sub = sub.fillna(0.)\n    # Blending\n    blend = pd.concat(\n        [sub[['date_playerId']],\n        (0.22*sub.drop('date_playerId', axis=1) + 0.78*sample_prediction_df.drop('date_playerId', axis=1))],\n        axis=1\n    )\n    env.predict(blend)\n    # Update Available information\n    sub_fe[\"EvalDate\"] = eval_dt\n    #sub_fe.drop(MEDCOLS, axis=1, inplace=True)\n    LAST = LAST.append(sub_fe)\n    LAST = LAST.drop_duplicates(subset=[\"EvalDate\",\"playerId\"], keep=\"last\")","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.819284Z","iopub.status.idle":"2021-07-26T10:19:06.819726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.concat(\n    [sub[['date_playerId']],\n    (sub.drop('date_playerId', axis=1) + sample_prediction_df.drop('date_playerId', axis=1)) / 2],\n    axis=1\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.820729Z","iopub.status.idle":"2021-07-26T10:19:06.821164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_prediction_df","metadata":{"execution":{"iopub.status.busy":"2021-07-26T10:19:06.822006Z","iopub.status.idle":"2021-07-26T10:19:06.822399Z"},"trusted":true},"execution_count":null,"outputs":[]}]}