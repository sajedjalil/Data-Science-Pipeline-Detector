{"cells":[{"metadata":{"_uuid":"e1dbedceef33ee75e74b972dcac5f6eb0c83809f","collapsed":false,"_cell_guid":"fc02850d-cae8-492a-9b06-e982d191efbb","_execution_state":"idle"},"outputs":[],"source":"Hey! It's Max. I'm super pumped to be taking part in Kaggle's competition. \n\nI'm working as a Data Scientist in the E-sports field, but I really enjoy doing all sorts of analysis.<br>\nMy approach is starting off with exploration, getting a feel more the data and everything inside.<br>\nThen, I'll manipulate some of the parameters to hopefully create some that can provide even more value.<br>\nUltimately, we're going to be basing our Machine Learning algorithm on this data, taking into account everything useful we've discovered in our exploration phase.<br>\n\nLet's get started!","cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"107944f02e878aa1966d91a3ff388f5d15843403","trusted":false,"_cell_guid":"a3870dde-eac6-4fab-a3cd-622efad546d6","_execution_state":"idle"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here are several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.neural_network import MLPRegressor\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output\n","cell_type":"code","execution_count":104},{"metadata":{"_uuid":"0e210a39cddab3f7287aab2d06096ae9a51cd4e0","collapsed":false,"_cell_guid":"65988e17-2ec2-42fe-b2f8-72727d5266df","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Alright, so let's get started. \n#The first thing we're going to want to do is import our train and test data\n\ntrainData = pd.read_csv(\"../input/train.csv\")\ntestData = pd.read_csv(\"../input/test.csv\")\n\n#We can most likely assume our data is clean, but let's double check to be sure that it's not a big, awful mess\n\ntrainColumns = list(trainData.columns)\ntestColumns = list(testData.columns)\nprint(set(trainColumns)-set(testColumns))\nif len(trainColumns) != len(testColumns):\n    print(\"Not the same number of columns in train and test\")\n    print(\"trainColumns has:\",len(trainColumns),\"values\")\n    print(\"testColumns has:\",len(testColumns),\"values\")","cell_type":"code","execution_count":105},{"metadata":{"_uuid":"2a723cdce9da14e0c237681458f1db4c9ee76f16","collapsed":false,"_cell_guid":"0a8ae472-092a-47f9-ac0b-fc2c286c58ec","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Ok, so we can see that they didn't include the dropoff time and the trip_duration\n#Makes sense since finding those is the objective of our ML algorithm in the end anyway, otherwise\n#we could just skip ML altogether ^^\n\n#Nice, so now that all of this looks good, let's take a look at our train data in a bit more detail\n\nprint(trainData.describe())","cell_type":"code","execution_count":106},{"metadata":{"_uuid":"7514ae0dff624b831acda17807981c57a1a8766e","collapsed":false,"_cell_guid":"eb6bb359-25a1-4d6f-b72c-ae5574000c10","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Sometimes not all columns appear - strings and such \n#(notice above we should have 11 columns, but we only see 7 here)\n#Let's see the rest of the columns \nprint(trainData.columns)","cell_type":"code","execution_count":107},{"metadata":{"_uuid":"ce957c11400ecb55d8bac630202036cfcac08cb0","collapsed":false,"_cell_guid":"d060f538-7efa-4abf-a9b9-821b32576dc2","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Ok, so the one's were missing are id, the datetimes for pickup and dropoff, and \n#the store and fwd flag\n#let's take a look at the top 5 values of the data, so we can get a feel for how it looks like\nprint(trainData.head())","cell_type":"code","execution_count":108},{"metadata":{"_uuid":"bb48cd248ffc9460fac0faff89b0d3ae600c708b","collapsed":false,"_cell_guid":"26951c18-ef07-4b88-b6f3-d642c88eba6a","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Let's make those id's numeric just so we can use them for plotting\nnumericIds = []\nfor numericId in list(trainData[\"id\"]):\n    numericIds.append(int(numericId[2:])) #since we're dealing with strings and each string starts\n                                        #with id, we just continue from the third character onwards\ntrainData[\"numericId\"] = numericIds\n#and let's take a look to make sure it went well\nprint(trainData[[\"id\",\"numericId\"]].head())\n#And do the same thing for the test data\nnumericIdsTest = []\nfor numericIdTest in list(testData[\"id\"]):\n    numericIdsTest.append(int(numericIdTest[2:])) #since we're dealing with strings and each string starts\n                                        #with id, we just continue from the third character onwards\ntestData[\"numericId\"] = numericIdsTest\nprint(testData[[\"id\",\"numericId\"]].head())","cell_type":"code","execution_count":109},{"metadata":{"_uuid":"ab27d598f852a2d796cbe467e587a49dccc514f3","collapsed":false,"_cell_guid":"8b47d001-f676-4f2b-b2b8-d3156e1747ab","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Let's also add in time of the day as well as the date;\n#that will be quite useful later if we want to see if\n#Trip duration depends on the time of day (morning/evening commutes, school times)\ntimes = []\ndates = []\nfor pickUpDateTime in trainData[\"pickup_datetime\"]:\n    time = [int(x) for x in pickUpDateTime.split(\" \")[1].split(\":\")]\n    currentDate = [int(x) for x in pickUpDateTime.split(\" \")[0].split(\"-\")]\n    times.append(time[0]+time[1]/60+time[2]/3600)\n    dates.append(datetime.date(currentDate[0],currentDate[1],currentDate[2]))\ntrainData[\"pickup_time\"] = times\ntrainData[\"pickup_date\"] = dates\n#We should also transform the dates into day of week, because that will also be interesting\n#to look at later\ndayOfWeek = []\nfor day in dates:\n    dayOfWeek.append(day.weekday())\ntrainData[\"pickup_dayOfWeek\"] = dayOfWeek\n#We'll do the same thing for the testData now\ntimes = []\ndates = []\nfor pickUpDateTime in testData[\"pickup_datetime\"]:\n    time = [int(x) for x in pickUpDateTime.split(\" \")[1].split(\":\")]\n    currentDate = [int(x) for x in pickUpDateTime.split(\" \")[0].split(\"-\")]\n    times.append(time[0]+time[1]/60+time[2]/3600)\n    dates.append(datetime.date(currentDate[0],currentDate[1],currentDate[2]))\ntestData[\"pickup_time\"] = times\ntestData[\"pickup_date\"] = dates\n#We should also transform the dates into day of week, because that will also be interesting\n#to look at later\ndayOfWeek = []\nfor day in dates:\n    dayOfWeek.append(day.weekday())\ntestData[\"pickup_dayOfWeek\"] = dayOfWeek","cell_type":"code","execution_count":110},{"metadata":{"_uuid":"888fa2b6dd0e049fb90ec37d87463805609860bd","collapsed":false,"_cell_guid":"29aa1984-b850-4ac7-a64b-e78c081afb86","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Looks like it went well\n#Also, let's add in latitude and longitude changes, as well as distances, so we get a better look\n#over of that too, rather than just strange coordinates (??) that aren't intuitive to work with\ntrainData[\"latitudeChange\"] = trainData[\"dropoff_latitude\"]-trainData[\"pickup_latitude\"]\ntrainData[\"longitudeChange\"] = trainData[\"dropoff_longitude\"] -trainData[\"pickup_longitude\"]\n\n#To get distance we need to convert latitude and longitude into distance units\nlatDistance = 111 #1 degree latitude is about 111km\nlongDistance = 111 #1 degree longitude is also about 111km\ntrainData[\"distance\"] = np.sqrt(np.power(trainData[\"latitudeChange\"],2)*latDistance+\n                               np.power(trainData[\"longitudeChange\"],2)*longDistance)\n\n#And let's just print out the top to make sure everything worked\nprint(trainData.head())\n\n#And let's do the same for the test data\ntestData[\"latitudeChange\"] = testData[\"dropoff_latitude\"]-testData[\"pickup_latitude\"]\ntestData[\"longitudeChange\"] = testData[\"dropoff_longitude\"] -testData[\"pickup_longitude\"]\n#Since latDistance and longDistance are equal, we can just take one or the other\ntestData[\"distance\"] = latDistance*np.sqrt(np.power(testData[\"latitudeChange\"],2)+\n                               np.power(testData[\"longitudeChange\"],2))\nprint(testData.head())","cell_type":"code","execution_count":111},{"metadata":{"_uuid":"f1474fdce4208227afc9b3109562ec66d57ef279","collapsed":false,"_cell_guid":"1246dad7-a0a9-417d-86bf-7874f4504de5","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Nice, looks good so far\n#But wowzers, take a look at that number of magnitude in the maximum (and minimum) trip duration\n#Let's take a look at the spread of this data\n#Good thing we have our numericId now (almost looks like this was planned - WHAT :O)\nplt.scatter(trainData[\"numericId\"],trainData[\"trip_duration\"])\nplt.xlabel(\"Unique numeric id\")\nplt.ylabel(\"trip duration [s]\")\nplt.title(\"Looking for anything suspicious\")\nplt.show()","cell_type":"code","execution_count":112},{"metadata":{"_uuid":"96eb0d8f0d1b41031777b6b64ea12af2bdd1181f","collapsed":false,"_cell_guid":"ae6e8c9c-522f-45b3-82d0-f3c443c6ff34","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Alright, so we've got some outliers (as suspected)\n#Let's take a look at this in two different ways (but way two is much later, just a heads up)\n#1.) First we'll isolate the large outliers in time\nlargeTimesTrain = trainData.loc[trainData[\"trip_duration\"] > 500000].copy()\nplt.scatter(largeTimesTrain[\"numericId\"],largeTimesTrain[\"trip_duration\"])\nplt.xlabel(\"Unique numeric id\")\nplt.ylabel(\"trip duration [s]\")\nplt.title(\"Looking at the outliers\")\nplt.show()\n#Let's also convert these times into minutes and hours\nlargeTimesTrain[\"min\"] = largeTimesTrain[\"trip_duration\"]/60\nlargeTimesTrain[\"hour\"] = largeTimesTrain[\"min\"]/60\n#It also looks like there aren't a lot of outliers, so we can just print out the whole dataframe\nprint(largeTimesTrain)","cell_type":"code","execution_count":113},{"metadata":{"_uuid":"76f6cc29be6550afd616c39a65306ce8e6353817","collapsed":false,"_cell_guid":"ba555cd6-deb4-44c7-a2dd-64cc791bc59f","_execution_state":"idle","trusted":false},"outputs":[],"source":"#So, we're not going significant distances (at most a little over 2km <- note:\n#we convert the longitude into km distance)\n#If we look at the datetimes for pickup and dropoff we see trips lasting between 22 days and a month \n#and 12 days, damn! What??? I've never gotten that lost before\n#Our store_and_fwd_flag also tells us that the trip was sent off right after it was completed\n#Additionally, although this may just be a conincidence, these trips were all done by the same vendor\n#We'll drop these values for now, since there isn't really a logical explanation - just strange\n#(at least on first sight) for why the trip was so long, and with about 1.5M data points, there\n#really isn't need for speculation\n\ntrainData = trainData.loc[trainData[\"trip_duration\"]<500000]\n#We'll plot the data one more time now, to see if there is anything else that sticks out\nplt.scatter(trainData[\"numericId\"],trainData[\"trip_duration\"])\nplt.xlabel(\"Unique numeric id\")\nplt.ylabel(\"trip duration [s]\")\nplt.title(\"Looking for anything suspicious\")\nplt.show()\n\n","cell_type":"code","execution_count":114},{"metadata":{"_uuid":"a886b23579a39f9acf03621aaf3280699bc8fc40","collapsed":false,"_cell_guid":"17260596-0972-478e-9be5-e4c159e40a30","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Oh, cool, this looks much better\n#Now finally, to the second way: looking for outliers on the other hand\n\n#2) Let's plot a histogram this time\n#Since we got rid of the big outliers we should have better resolution\n#Our first histogram is going to be looking at smaller trip durations\ntripDurations = list(trainData[\"trip_duration\"])\nplt.hist(tripDurations,bins = range(2000))\nplt.xlabel(\"Trip duration\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Trip duration histogram for shorter trips\")\nplt.show()\n\n#The second one will include all trip durations, just in case something big happens to the far right\n#I'm gonna leave it commented out though because it takes FOREVER to run\n#tripDurations = list(trainData[\"trip_duration\"])\n#plt.hist(tripDurations,bins = max(tripDurations))\n#plt.xlabel(\"Trip duration\")\n#plt.ylabel(\"Frequency\")\n#plt.title(\"Trip duration histogram for all trips\")\n#plt.show()","cell_type":"code","execution_count":115},{"metadata":{"_uuid":"4864b4abc25cf127d2ff8aaae31f7c9acea21dd9","collapsed":false,"_cell_guid":"2e2da8ac-985c-4d2b-8b73-ed748eecd8c2","_execution_state":"idle","trusted":false},"outputs":[],"source":"#So what we see from the first plot is a nice, right skewed, histogram, \n#with values continuously decreasing when going towards higher trip durations\n#We also see that on the left there are a lot of cases around 0, this is probably either because someone\n#decided to cancel the fare, or that it was just a test flip, to see if everything is working\n#It's unlikely that people take a fare for less than 1-2 minutes unless you're lazy like me\n#sometimes you just dont want to walk the 2 mins to the store, you know?\n\n#Let's take a look at how much of our data is concentrated to the far right and how much is\n#around 0\nprint(\"Number of trips lasting less than 5 hours:\",\n      len(trainData.loc[trainData[\"trip_duration\"]<18000][\"trip_duration\"]))\nprint(\"Number of trips lasting more than 5 hours:\",\n      len(trainData.loc[trainData[\"trip_duration\"]>18000][\"trip_duration\"]))\nprint(\"Percentage of trips longer than 5 hours:\",\n      round(len(trainData.loc[trainData[\"trip_duration\"]>18000][\"trip_duration\"])/\n     len(trainData)*100,2))\nprint(\"Number of trips lasting less than 1 minute:\",\n      len(trainData.loc[trainData[\"trip_duration\"]<60][\"trip_duration\"]))\nprint(\"Number of trips lasting less than 2 minutes:\",\n      len(trainData.loc[trainData[\"trip_duration\"]<120][\"trip_duration\"]))\nprint(\"Percentage of trips shorter than 1 minute:\",\n      round(len(trainData.loc[trainData[\"trip_duration\"]<60][\"trip_duration\"])/\n     len(trainData)*100,2))\nprint(\"Percentage of trips shorter than 2 minuts:\",\n      round(len(trainData.loc[trainData[\"trip_duration\"]<120][\"trip_duration\"])/\n     len(trainData)*100,2))\n","cell_type":"code","execution_count":116},{"metadata":{"_uuid":"288fb64eaa5040d6924ac23e6ca9fd9126a2f7cd","collapsed":false,"_cell_guid":"ba7eefc5-74d1-4b91-832a-5d41e719f870","_execution_state":"idle","trusted":false},"outputs":[],"source":"#So about 0.14% of our trips are over 5 hours and about 0.6% of our trips are less than 1 minute\n#Let's get a coordinate overview of those cases, maybe there are specific cases this applies to\n#If it's randomly scattered, we can probably take it to be insignificant/bad data\n#For this we'll create a very short and a long trip duration dataframe\nveryshortDurationTrips = trainData.loc[trainData[\"trip_duration\"]<60]\nlongDurationTrips = trainData.loc[trainData[\"trip_duration\"]>18000].copy()\n\n#We'll scale the point sizes by distance, so we know where long trips occured\nplt.scatter(longDurationTrips[\"pickup_longitude\"],longDurationTrips[\"pickup_latitude\"],\n            s = 5*longDurationTrips[\"distance\"],alpha = 0.7)\nplt.ylabel(\"pickup latitude\")\nplt.xlabel(\"pickup longitude\")\nplt.show()\n\n","cell_type":"code","execution_count":117},{"metadata":{"_uuid":"1f31a606596e0a91a55f6b7414622544a9a5888d","collapsed":false,"_cell_guid":"c5df3dba-bf88-4771-b029-55d40e05792d","_execution_state":"idle","trusted":false},"outputs":[],"source":"#OK, it looks like we have one or some outliers, hard to make out with this resolution\n#let's print it out\nprint(len(longDurationTrips.loc[longDurationTrips[\"pickup_longitude\"]<-75][\"distance\"]))\nprint(longDurationTrips.loc[longDurationTrips[\"pickup_longitude\"]<-75][\"distance\"])","cell_type":"code","execution_count":118},{"metadata":{"_uuid":"cbb93d879ea4080d62d311cde018a56cab2be28c","collapsed":false,"_cell_guid":"44072df0-0973-44f6-b359-b75e71907c6b","_execution_state":"idle","trusted":false},"outputs":[],"source":"#So we have just one outlier, let's take this out of our consideration and re-do the plot above\ncutLongDurationTrips = longDurationTrips.loc[longDurationTrips[\"pickup_longitude\"]>-75]\n\n#We'll scale the point sizes by distance, so we know where long trips occured\nplt.scatter(cutLongDurationTrips[\"pickup_longitude\"],cutLongDurationTrips[\"pickup_latitude\"],c=\"g\",\n            s = 5*longDurationTrips[\"distance\"],alpha = 0.7)\n\nplt.ylabel(\"pickup latitude\")\nplt.xlabel(\"pickup longitude\")\n\nplt.show()","cell_type":"code","execution_count":119},{"metadata":{"_uuid":"3c28988524ba6609a0d9bad2004a313687b55253","collapsed":false,"_cell_guid":"8d3f899a-6bb8-4adc-857e-37e888c38aaf","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Now that we know where our data is located, we'll also be plotting all of our trip coordinates,\n#so that we can compare\nplt.scatter(trainData[\"pickup_longitude\"],trainData[\"pickup_latitude\"],c = \"black\",\n            s = 5*longDurationTrips[\"distance\"],alpha = 0.2,\n           label = \"all Data\") #The alpha lets us compare but also keep\n                                                            #the longer durations dominant in \n                                                            #visibility\nplt.scatter(cutLongDurationTrips[\"pickup_longitude\"],cutLongDurationTrips[\"pickup_latitude\"],c=\"g\",\n            s = 5*longDurationTrips[\"distance\"],alpha = 0.5, label = \"long duration\")\nplt.ylabel(\"pickup latitude\")\nplt.xlabel(\"pickup longitude\")\n\n#We'll use the limits seen from the graph above\nplt.xlim(-74.05,-73.75)\nplt.ylim(40.6,40.9)\nplt.legend(loc = \"upper right\")\nplt.show()","cell_type":"code","execution_count":120},{"metadata":{"_uuid":"97253e8a83f69e4393b1b9c4ea6116bbe98c8bf3","collapsed":false,"_cell_guid":"89bcfdbe-3a42-4d75-9734-0cd8997e952a","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Interesting, so most of the long duration trips are on the main island\n#Let's see how things look like when we add in dropoff locations\n#Using the same basis as above\nplt.scatter(trainData[\"pickup_longitude\"],trainData[\"pickup_latitude\"],c = \"black\",\n            s = 5*longDurationTrips[\"distance\"],alpha = 0.2,\n           label = \"all Data\") #The alpha lets us compare but also keep\n                                                            #the longer durations dominant in \n                                                            #visibility\nplt.scatter(cutLongDurationTrips[\"pickup_longitude\"],cutLongDurationTrips[\"pickup_latitude\"],c=\"g\",\n            s = 5*longDurationTrips[\"distance\"],alpha = 0.5, label = \"long dur. pickup\")\nplt.scatter(cutLongDurationTrips[\"dropoff_longitude\"],cutLongDurationTrips[\"dropoff_latitude\"],c=\"b\",\n            s = 5*cutLongDurationTrips[\"distance\"],alpha = 0.5, label = \"long dur. dropoff\")\nplt.ylabel(\"latitude\")\nplt.xlabel(\"longitude\")\n\n#We'll use the limits seen from the graph above\nplt.xlim(-74.05,-73.75)\nplt.ylim(40.6,40.9)\nplt.legend(loc = \"upper right\")\nplt.show()","cell_type":"code","execution_count":121},{"metadata":{"_uuid":"6a94dfc4d0751ea2aa1c5c5081d672bda5b0945c","collapsed":false,"_cell_guid":"71638371-947b-4c35-9ceb-0dc1285c8b7b","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Ok, so they all start and end on the main island\n#What we're really seeing is many small distance trips that have just been counted as very long.\n\n#Let's look at distance one more time using a different lens by\n#getting a histogram overview of the distances for long duration trips\n#We'll round the distances now, so that we can get at 100m accuracy\nlongDurationTrips[\"roundedDistance\"] = np.round(longDurationTrips[\"distance\"],1)\nplt.hist(longDurationTrips[\"roundedDistance\"],bins = 200)\nplt.xlabel(\"Distance [km]\")\nplt.ylabel(\"Frequency\")\nplt.title(\"All distances\")\nplt.show()\nlongDurationShortDistance = longDurationTrips.loc[longDurationTrips[\"roundedDistance\"]<3].copy()\nplt.hist(longDurationShortDistance[\"roundedDistance\"],bins = 30)\nplt.xlabel(\"Distance [km]\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Short distances\")\nplt.show()","cell_type":"code","execution_count":122},{"metadata":{"_uuid":"1f4ad666a1563f8e78679ecf9c42ba24a7a48264","collapsed":false,"_cell_guid":"87f28781-16fc-4a03-88d8-2763a72a1ec0","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Ok, so we see that a lot of long duration trips that take over 5 hours are really\n#only over short distances. Even a 20km trip should not take 5 hours unless you drive super duper slow\n#So let's filter by trip duration and take everything under 5 hours\n#If we take a look at our histogram above, at a trip duration of about 2000 seconds we only have a\n#few data points, this just continues to decrease\n#ergo, we're going to cut off all of the trip durations over 5 hours, because there are so few\n#of them, and it's more likely due to a logging error, or something not concerning\n#trip duration than anything else\nshortDurationTrips = trainData.loc[trainData[\"trip_duration\"]<18000]","cell_type":"code","execution_count":123},{"metadata":{"_uuid":"03224ab1ed5f03a3d6ae852cdb50cf5dbbbb8df3","collapsed":false,"_cell_guid":"3d97cab8-7125-4f15-80e8-a051e45522a5","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Let's try to get a better overview of our trip duration\n#Maybe it is still somehow related to distance?\nplt.scatter(shortDurationTrips[\"distance\"],shortDurationTrips[\"trip_duration\"],s = 2)\nplt.xlabel(\"Trip Distance\")\nplt.ylabel(\"Trip Duration\")\nplt.show()\n#Trip duration variation versus time of day\n#Trip duration variation versus day of the week","cell_type":"code","execution_count":124},{"metadata":{"_uuid":"deafe9ae9e19ea6e5daacb7b0e6edff11a878e5a","collapsed":false,"_cell_guid":"519ef0c6-17ac-4b82-b473-ab60e2071e8d","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Ok, it's kinda hard to see a relation here\n#Let's cut off the large distance trips, and keep everything under 20km\n\nshortDistancesTrain = shortDurationTrips.loc[trainData[\"distance\"]<20]\nplt.scatter(shortDistancesTrain[\"distance\"],shortDistancesTrain[\"trip_duration\"],s = 2)\nplt.xlabel(\"Trip Distance\")\nplt.ylabel(\"Trip Duration\")\nplt.title(\"Duration vs distance for short distances\")\nplt.show()","cell_type":"code","execution_count":125},{"metadata":{"_uuid":"f3b5c5996e2e7498c084c316a4fb2759bb6e0ac7","collapsed":false,"_cell_guid":"c7b2bff0-7f6f-41c2-a1cb-8569ce31e798","_execution_state":"idle","trusted":false},"outputs":[],"source":"#It looks like once we go slightly over 2.5km, around 3km or so,\n#we reach a more predictable range with linearregression, \n#probably because we're leaving the heavy traffic areas\n#let's isolate these medium distance cases and take a closer look\nmediumDistancesTrain = shortDistancesTrain.loc[shortDistancesTrain[\"distance\"]>3]\nplt.scatter(mediumDistancesTrain[\"distance\"],mediumDistancesTrain[\"trip_duration\"],s=10)\nplt.xlabel(\"Trip Distance\")\nplt.ylabel(\"Trip Duration\")\nplt.title(\"Duration vs distance for medium distances\")\nplt.show()","cell_type":"code","execution_count":126},{"metadata":{"_uuid":"cc491657cef14f80b25d06e458849242afb3403c","collapsed":false,"_cell_guid":"e2c8b705-a832-4f58-a8fb-e1c515c13247","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Aright, it still doesn't look super linear, but that's ok, it is a city with traffic and everything\n#after all, I wasn't expcecting to do some linear regression, but always worth checking\n#Maybe there are some patterns we can see based on the time of day?\n\nplt.scatter(shortDistancesTrain[\"pickup_time\"],shortDistancesTrain[\"trip_duration\"],s = 2)\nplt.ylabel(\"trip duration\")\nplt.xlabel(\"pickup time\")\nplt.title(\"Time vs duration for all distances\")\nplt.show()\nplt.scatter(mediumDistancesTrain[\"pickup_time\"],mediumDistancesTrain[\"trip_duration\"],s = 10)\nplt.ylabel(\"trip duration\")\nplt.xlabel(\"pickup time\")\nplt.title(\"Time vs duration for medium distances\")\nplt.show()\nplt.scatter(shortDurationTrips[\"pickup_time\"],shortDurationTrips[\"trip_duration\"],s = 10)\nplt.ylabel(\"trip duration\")\nplt.xlabel(\"pickup time\")\nplt.title(\"Time vs duration for short durations (<5 hours)\")\nplt.show()","cell_type":"code","execution_count":127},{"metadata":{"_uuid":"db6b57ed8255f477f3849be3152442c65456da8d","collapsed":false,"_cell_guid":"349ba4cd-5f70-44e5-bf6b-7831017d4c0a","_execution_state":"idle","trusted":false},"outputs":[],"source":"#That looks pretty messy, let's just plot the average trip duration every minute with its\n#standard error of the mean, so we know the range of the mean to expect\nfig, ax1 = plt.subplots()\naverageTripDurations = []\naverageTripDurationsSEM = []\ntimeOfDay = []\nfor t in range(12*24):\n    currentTime = t/12 #5 minute intervals\n    tripsForCurrentTime = shortDurationTrips.loc[shortDurationTrips[\"pickup_time\"] >=currentTime]\n    tripsForCurrentTime = tripsForCurrentTime.loc[tripsForCurrentTime[\"pickup_time\"]<currentTime+1/12]\n    descriptionForCurrentTime = tripsForCurrentTime[\"trip_duration\"].describe()\n    averageTripDurations.append(descriptionForCurrentTime[\"mean\"])\n    averageTripDurationsSEM.append(descriptionForCurrentTime[\"std\"]/\n                                   descriptionForCurrentTime[\"count\"])\n    timeOfDay.append(currentTime)\nax1.errorbar(timeOfDay, averageTripDurations, yerr=averageTripDurationsSEM, fmt='o',ms = 1)\nax1.set_xlabel(\"Hour of day\")\nax1.set_ylabel(\"Average trip duration\")\nplt.title(\"Average trip duration based on time of day\")\nplt.show()\n#Let's look at average trip duration vs time of day \n#(and we can also look at number of trips at each time)","cell_type":"code","execution_count":128},{"metadata":{"_uuid":"ff86faac6e2464fb411923fc8a78e4b7942d65f0","collapsed":false,"_cell_guid":"7bdb8d20-821e-4078-b79d-caa0b2f9c977","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Alright, that looks pretty cool\n#We can't even see the error bars, so that's also a good sign\n#To see if there's a relation to how busy things are, let's overlay it with average number of trips\nfig, ax1 = plt.subplots()\nax2 = ax1.twinx()\nnumberOfTrips = []\nfor t in range(12*24):\n    currentTime = t/12 #5 minute intervals\n    tripsForCurrentTime = shortDurationTrips.loc[shortDurationTrips[\"pickup_time\"] >=currentTime]\n    tripsForCurrentTime = tripsForCurrentTime.loc[tripsForCurrentTime[\"pickup_time\"]<currentTime+1/12]\n    descriptionForCurrentTime = tripsForCurrentTime[\"trip_duration\"].describe()\n    uniqueTripDates = tripsForCurrentTime[\"pickup_date\"].unique()\n    numberOfTrips.append(descriptionForCurrentTime[\"count\"]/len(uniqueTripDates))\n    \nax1.errorbar(timeOfDay, averageTripDurations, yerr=averageTripDurationsSEM, fmt='o',ms = 1)\nax1.set_xlabel(\"Hour of day\")\nax1.set_ylabel(\"Average trip duration [s]\")\nax2.scatter(timeOfDay,numberOfTrips,color = \"r\",s = 1,alpha = 0.2)\nax2.set_ylabel(\"Number of trips per day\")\nax2.tick_params(color=\"r\")\n\nplt.title(\"Average trip duration and number of trips for time of day\")\nplt.show()\n","cell_type":"code","execution_count":129},{"metadata":{"_uuid":"fae35b42567b549f56db0981c659449b67c4f037","collapsed":false,"_cell_guid":"883728bf-eb50-4c97-95fd-b61325a6f2c8","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Ok, interesting, sometimes we see the number of trips a day showing longer trip durations\n#Which makes sense, since there is more traffic, but sometimes that case is the opposite\n#Let's also add in distance here, maybe that'll explain some things?\n#Like a few people taking longer trips to the airport at 5am?\nfig, ax1 = plt.subplots()\nax2 = ax1.twinx()\nax3 = ax1.twinx()\n\n\nax3.spines['right'].set_position((\"outward\",50))\naverageDistance = []\naverageDistanceSEM = []\nfor t in range(12*24):\n    currentTime = t/12 #5 minute intervals\n    tripsForCurrentTime = shortDurationTrips.loc[shortDurationTrips[\"pickup_time\"] >=currentTime]\n    tripsForCurrentTime = tripsForCurrentTime.loc[tripsForCurrentTime[\"pickup_time\"]<currentTime+1/12]\n    descriptionForCurrentTime = tripsForCurrentTime[\"distance\"].describe()\n    averageDistance.append(descriptionForCurrentTime[\"mean\"])\n    averageDistanceSEM.append(descriptionForCurrentTime[\"std\"]/\n                                   descriptionForCurrentTime[\"count\"])\n    \nax1.errorbar(timeOfDay, averageTripDurations, yerr=averageTripDurationsSEM, fmt='o',ms = 1)\nax1.set_xlabel(\"Hour of day\")\nax1.set_ylabel(\"Average trip duration [s]\")\nax2.scatter(timeOfDay,numberOfTrips,color = \"r\",s = 1,alpha = 0.2)\nax2.set_ylabel(\"Number of trips per day\")\nax2.tick_params(color=\"r\")\nax3.errorbar(timeOfDay,averageDistance,yerr=averageDistanceSEM,color = \"g\",ms = 1,alpha = 0.2)\nax3.set_ylabel(\"Average distance\")\nax3.tick_params(color=\"g\")\n\nplt.title(\"Average trip duration, distance,#trips/day for time of day\")\nplt.show()","cell_type":"code","execution_count":130},{"metadata":{"_uuid":"1f39bad694c9107913df7d71f710f3e494c22db9","collapsed":false,"_cell_guid":"3ca271a9-6d0f-4111-8d32-af906a6f95f3","_execution_state":"idle","trusted":false},"outputs":[],"source":"#So we can see, there's a more complicated relationship between distance, number of trips a day, and\n#trip duration.\n#Sometimes they have an easy relation, other times not soo much\nfig, ax1 = plt.subplots()\nax2 = ax1.twinx()\nax3 = ax1.twinx()\nax3.spines['right'].set_position((\"outward\",50))\n\nweekDays = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\naverageNumberOfTrips = []\naverageTripDuration = []\naverageTripDurationSEM = []\naverageTripDistance = []\naverageTripDistanceSEM = []\nwidth = 0.2\nfor day in range(7):\n    tripsForCurrentDay = shortDurationTrips.loc[shortDurationTrips[\"pickup_dayOfWeek\"]==day]\n    descriptionForCurrentDate = tripsForCurrentDay.describe()\n    uniqueTripDates = tripsForCurrentDay[\"pickup_date\"].unique()\n    averageNumberOfTrips.append(descriptionForCurrentDate[\"trip_duration\"][\"count\"]/\n                               len(uniqueTripDates))\n    averageTripDuration.append(descriptionForCurrentDate[\"trip_duration\"][\"mean\"])\n    averageTripDurationSEM.append(descriptionForCurrentDate[\"trip_duration\"][\"std\"]/\n                              descriptionForCurrentDate[\"trip_duration\"][\"count\"])\n    averageTripDistance.append(descriptionForCurrentDate[\"distance\"][\"mean\"])\n    distanceSTD = descriptionForCurrentDate[\"distance\"][\"std\"]\n    distanceCount = descriptionForCurrentDate[\"distance\"][\"count\"]\n    averageTripDistanceSEM.append(descriptionForCurrentDate[\"distance\"][\"std\"]/\n                              descriptionForCurrentDate[\"distance\"][\"count\"])\n    \nax1.bar(np.arange(7) - width, averageTripDuration, width, color='r', yerr=averageTripDurationSEM,align = \"edge\")\nax1.set_ylabel(\"Average trip duration\",color = \"red\")\nax1.tick_params(color=\"r\")\nax2.bar(np.arange(7), averageNumberOfTrips, width, color='black',align = \"edge\")\nax2.set_ylabel(\"Average number of trips\")\nax2.tick_params(color=\"black\")\nax3.bar(np.arange(7) + width, np.array(averageTripDistance), width, color='g', yerr=averageTripDistanceSEM,align = \"edge\")\nax3.set_ylabel(\"Average trip distance\",color = \"green\")\nax3.tick_params(color=\"g\")\nplt.sca(ax1)\nplt.xticks(np.arange(7),weekDays,rotation = 45)\nplt.show()","cell_type":"code","execution_count":131},{"metadata":{"_uuid":"a6fe45d914cedc3a985eb18e59e3eb3152dbd130","collapsed":false,"_cell_guid":"7c919e3a-a099-4c7e-b334-c42282844f19","_execution_state":"idle","trusted":false},"outputs":[],"source":"#Alright, so we see a little bit of a concave curve happening for each,\n#and trips are a bit shorter on weekends than on weekdays, probably because there's less traffic\n#So let's go and try to start our ML tasks\n#First thing we got to do, split our training data in training and testing\n#so that we can check our results\n\n#Preparing the data\nfinalTrainData = sklearn.utils.shuffle(shortDurationTrips.copy())\ndropColumns = ['numericId','id', 'vendor_id','pickup_datetime', 'dropoff_datetime',\"pickup_date\"]\nfor extraColumns in dropColumns:\n    finalTrainData = finalTrainData.drop(extraColumns, 1)#Getting rid of all the columsn we don't have\n                                                        #In test data set\n        \n#print(finalTrainData.columns)\nfinalTrainData.replace(\"N\",0,inplace = True)\nfinalTrainData.replace(\"Y\",1,inplace = True)\ndataLength = len(finalTrainData[\"distance\"])#Just getting total number of elements\neightyPerc = int(dataLength*0.8)\nrestTwenty = dataLength-eightyPerc\nfinalTrainDataLearn = finalTrainData.head(eightyPerc)\nfinalTrainDataTarget = finalTrainDataLearn[\"trip_duration\"]\nfinalTrainDataIndicators = finalTrainDataLearn.drop(\"trip_duration\",1)\nfinalTrainDataTest = finalTrainData.tail(restTwenty)\nfinalTrainDataTestTarget = finalTrainDataTest[\"trip_duration\"]\nfinalTrainDataTestIndicators = finalTrainDataTest.drop(\"trip_duration\",1)\n","cell_type":"code","execution_count":132},{"metadata":{"_uuid":"06b49808527f545f3efd7af5079a1c3d388004a0","collapsed":false,"_cell_guid":"e13afade-0e1b-463b-88de-f353d38eaf5b","_execution_state":"idle","trusted":false},"outputs":[],"source":"#I'll continue on with the analysis, so make sure to check back soon!","cell_type":"code","execution_count":133}],"nbformat_minor":0,"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","name":"python","pygments_lexer":"ipython3","version":"3.6.1"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4}