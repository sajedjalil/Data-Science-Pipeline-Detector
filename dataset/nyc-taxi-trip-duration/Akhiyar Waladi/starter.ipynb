{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python","version":"3.6.1","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3}}},"cells":[{"metadata":{"_uuid":"c6483e09607a81e0473342a04d822490101a9534"},"outputs":[],"cell_type":"markdown","source":"# Import Library\n> \n* pandas \n* numpy","execution_count":null},{"metadata":{"trusted":true,"_uuid":"4ad7c3e277bb94f65e55e33031cefc84c26bc4a8","_cell_guid":"510c3ded-bbcc-471a-8214-378b72667c7f"},"execution_count":null,"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","outputs":[]},{"metadata":{"_uuid":"631256e53ca51209743d7d30f62cb210d4c53a00"},"outputs":[],"cell_type":"markdown","source":"* read csv\n* check if any missing value","execution_count":null},{"metadata":{"trusted":true,"_uuid":"401acb59c1995208b2cb66225a8a9dfca7e812a5"},"execution_count":null,"cell_type":"code","source":"raw = pd.read_csv(\"../input/train.csv\")\nraw.isnull().sum()","outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1cc4d5a8d4249483d626ad7b63bf7b6c3b7c21a"},"execution_count":null,"cell_type":"code","source":"raw.head(5)","outputs":[]},{"metadata":{"_uuid":"ac78d9b5cbe6bd7c2532328015ee1a2c8e349329"},"outputs":[],"cell_type":"markdown","source":"* compute trip duration from date time pick and drop","execution_count":null},{"metadata":{"trusted":true,"_uuid":"553cc74911cc777ca8dc408c77b82a661905bfaf"},"execution_count":null,"cell_type":"code","source":"from datetime import datetime\npickup = []\ndropoff = []\ndiffTrip = []\nfor i in range(raw.shape[0]):\n    pickup.append(datetime.strptime(raw[\"pickup_datetime\"][i], \"%Y-%m-%d %H:%M:%S\"))\n    dropoff.append(datetime.strptime(raw[\"dropoff_datetime\"][i], \"%Y-%m-%d %H:%M:%S\"))\n    diffTrip.append(dropoff[i] - pickup[i])","outputs":[]},{"metadata":{"trusted":true,"_uuid":"8362c452413bc1de286a89fcdc63b1c35cb38ec3"},"execution_count":null,"cell_type":"code","source":"val = diffTrip[0]\nval.seconds","outputs":[]},{"metadata":{"trusted":true,"_uuid":"426cd1b6e53b6a34eb29a55fe068f879d541638f"},"execution_count":null,"cell_type":"code","source":"for i in range(len(diffTrip)):\n    diffTrip[i] = diffTrip[i].seconds\nse = pd.Series(diffTrip)\nraw['diffTrip'] = se.values\nraw.head(5)","outputs":[]},{"metadata":{"_uuid":"c717f0be507342dd14c17970f566f5f1771891ee"},"outputs":[],"cell_type":"markdown","source":"## Select feature and label\n> \n* for feature, select only numerical data","execution_count":null},{"metadata":{"trusted":true,"_uuid":"86d1877f31f074728db082187f6eae64d9be0a8e"},"execution_count":null,"cell_type":"code","source":"x = raw.drop([\"id\", \"pickup_datetime\", \"store_and_fwd_flag\", \"dropoff_datetime\"],1)\ny = raw[\"trip_duration\"]","outputs":[]},{"metadata":{"_uuid":"0109512fe8ea764b55a1e4abd566b4e05274e47a"},"outputs":[],"cell_type":"markdown","source":"## Make dummy for categorical features","execution_count":null},{"metadata":{"trusted":true,"_uuid":"4bb51f6af4aeac664419dcaad764f09d1eb53d84"},"execution_count":null,"cell_type":"code","source":"var_dummy = pd.get_dummies(raw[\"store_and_fwd_flag\"])\nx_catnum= pd.concat([x, var_dummy], axis = 1)\nx_catnum.head(5)","outputs":[]},{"metadata":{"_uuid":"a4445f5c9517b1de9f58dce22b84bdbe514654ff"},"outputs":[],"cell_type":"markdown","source":"## Standardize data all column","execution_count":null},{"metadata":{"trusted":true,"_uuid":"f6ddceca26b05ba94cc332803cf0a0f91bee93c1"},"execution_count":null,"cell_type":"code","source":"X= x_catnum\nY= y\n# try normalize data, maybe improve accuration\nfrom sklearn.preprocessing import StandardScaler\n# get column name because we lose it after standarization\ndata_columns = X.columns\n# initiate standarscaler\nscaler = StandardScaler()\n# fitting and transform to dataframe feature data\n#X = scaler.fit_transform(X)\nscaler.fit(X)\nnormal_X = pd.DataFrame(scaler.transform(X))\n# get column name back\nnormal_X.columns = data_columns\n# check data after standardize\nnormal_X.head(5)","outputs":[]},{"metadata":{"_uuid":"ee6848de45b9cd41ce741e02943abe9b5812d1c5"},"outputs":[],"cell_type":"markdown","source":"# Split data train and testing\n> \n* 20% of data for validation\n* random state is free any number","execution_count":null},{"metadata":{"trusted":true,"_uuid":"cb82fc9ef6d98528c7ce1efc745ccb293b6ab419","collapsed":true},"execution_count":null,"cell_type":"code","source":"# split data train and data testing\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n  X,\n  Y,\n  test_size=0.2,\n  random_state = 42 )","outputs":[]},{"metadata":{"_uuid":"e5d09da8ca574bfa542a943b7bd89239f814744b"},"outputs":[],"cell_type":"markdown","source":"# Training and testing\n> \n* define all regressor\n* fit with data train\n* predict and compute accuracy score\n* perform 10 cross validation to evaluate reggresor","execution_count":null},{"metadata":{"trusted":true,"_uuid":"c78fa6e84d37bb63bad9376ad63bb1c11bd231c1"},"execution_count":null,"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n\nclassifiers = [\n    LinearRegression(),\n    Ridge(),\n    Lasso(),\n    RandomForestRegressor(n_jobs=-1),\n    DecisionTreeRegressor(),\n    RANSACRegressor(LinearRegression(), \n                     max_trials=100, \n                     min_samples=50, \n                     loss='absolute_loss', \n                     residual_threshold=5.0, \n                     random_state=0)]\n\n\n\nfor clf in classifiers:\n    \n    clf.fit(X_train, y_train)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    \n    ########################## perform split validation ######################\n    train_predictions = clf.predict(X_test)\n    rmse = np.sqrt( metrics.mean_squared_error( y_test, train_predictions ) )\n    print(\"RMSE: {}\".format(rmse))\n    ##########################################################################\n    \n    ########################## perform 10 fold validation ######################\n    kf = KFold(n_splits=10)\n    scorelist = []\n    for train_index, test_index in kf.split(X.values):\n        clf.fit(X.values[train_index], Y.values[train_index])\n        p = clf.predict(X.values[test_index])\n        RMSE = metrics.mean_squared_error(Y.values[test_index], p)**0.5\n        scorelist.append(rmse)\n    \n    print(\"MeanCVScore: {}\".format(sum(scorelist)/len(scorelist)))\n    print(\"10FoldCVScore: {}\".format(scorelist))\n    #############################################################################\n    \nprint(\"=\"*30)","outputs":[]}],"nbformat_minor":1,"nbformat":4}