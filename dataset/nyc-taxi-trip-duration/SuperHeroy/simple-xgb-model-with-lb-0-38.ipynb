{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.1","name":"python"}},"nbformat":4,"cells":[{"metadata":{"collapsed":true,"_uuid":"185cb3a90825e9dec7e89dc50b304a259474cccf","_cell_guid":"29419b08-ee4d-4b61-82c9-8fe42a2a4d15","trusted":false},"outputs":[],"source":"import warnings","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true,"_execution_state":"idle","_uuid":"26535c7319b774940823aca1f3a4bc844b161d9d","_cell_guid":"e4475c3b-f63e-4753-bb0a-99335dbc675d","trusted":false},"outputs":[],"source":"warnings.filterwarnings('ignore')","cell_type":"code","execution_count":null},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e2521595272bda32bb9be83711d6d9f698313cfa","_cell_guid":"02ea94ee-c35d-4a88-871e-6132ef789265"},"outputs":[],"source":"import pandas as pd\nimport datetime\nfrom math import sin, cos, sqrt, atan2, radians, degrees\nimport math\nimport shapefile\nimport matplotlib.path as mplPath\nimport numpy as np\nimport json\nfrom sklearn.cross_validation import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import *\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nimport xgboost as xgb","cell_type":"code","execution_count":1},{"metadata":{"_uuid":"5d79b6f68cdd30a6e4a81a89a79d88a645839538","collapsed":true,"_cell_guid":"4c498392-a67b-4191-9d9d-24e1aec1c38f","trusted":false},"outputs":[],"source":"base_path1 = '../input/nyc-taxi-trip-duration/'\nbase_path2 = '../input/new-york-city-taxi-with-osrm/'\nbase_path3 = '../input/nypdcollisions/'\nbase_path4 = '../input/nycgeoshapes/'\nbase_path5 = '../input/weather-data-in-new-york-city-2016/'","cell_type":"code","execution_count":3},{"metadata":{"_uuid":"5ba607d6b6b09eb26e5848d69577cb3c289c680a","collapsed":true,"_cell_guid":"3f3c06b3-a1a2-4c39-a583-6d1009edb9ae","trusted":false},"outputs":[],"source":"train = pd.read_csv(base_path1 + 'train.csv')\ntest = pd.read_csv(base_path1 + 'test.csv')","cell_type":"code","execution_count":4},{"metadata":{"_uuid":"7ad20bbda794fa32b040d7fd3ae265fb57536511","collapsed":true,"_cell_guid":"020f6992-5d7a-4fc9-8a29-a603172bd4f2","trusted":false},"outputs":[],"source":"### calculate distance per trip\n\ndef distance(lat1, lon1, lat2, lon2):\n\n    # approximate radius of earth in km\n    R = 6373.0\n    lat1 = radians(lat1)\n    lon1 = radians(lon1)\n    lat2 = radians(lat2)\n    lon2 = radians(lon2)\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n\n    distance = R * c\n    return distance\n\n# calculate angle between pickup and dropoff points or angle relative to NYC center\n\ndef angle_between_vectors_degrees(lat1, lon1, lat2, lon2, mode = None):\n    # NYC_center\n    NYC_center = [40.793209, -73.973053]\n    a = np.radians(np.array([lat1, lon1]))\n    b = np.radians(np.array(NYC_center))\n    if mode == 'center':\n        c = np.radians(np.array([NYC_center[0]+1, NYC_center[1]]))\n    else:\n        c = np.radians(np.array([lat2, lon2]))\n    # Vectors in latitude/longitude space\n    avec = a - b\n    cvec = c - b\n\n    # Adjust vectors for changed longitude scale at given latitude into 2D space\n    lat = b[0]\n    avec[1] *= math.cos(lat)\n    cvec[1] *= math.cos(lat)\n    try:\n        return np.degrees(\n            math.acos(np.dot(avec, cvec) / (np.linalg.norm(avec) * np.linalg.norm(cvec))))\n    except ValueError:\n        return 0","cell_type":"code","execution_count":5},{"metadata":{"_uuid":"ce9c158f79c81924be8977d4010dc9d88d0298b6","collapsed":true,"_cell_guid":"86984a59-684b-4b2f-bff5-cccb74e50cd0","trusted":false},"outputs":[],"source":"### get geoshapes of NYC boroughs\n\ndef get_dicty():\n    json_data=open(base_path4 + 'shapes.json').read()\n\n    data = json.loads(json_data)\n\n    dicty = {}\n    for d in data['features']:\n        dicty[d['properties']['BoroName']] = [mplPath.Path([(xx[1], xx[0]) for xx in x[0]]) for x in d['geometry']['coordinates']]\n    \n    return dicty\n\ndef get_district(point1, point2, dicty):\n    result = 'other'\n    for k, v in dicty.items():\n        for vv in v:\n            if vv.contains_point((point1, point2)):\n                result = k\n                break\n    return result","cell_type":"code","execution_count":6},{"metadata":{"_uuid":"1768fc9d44c8cb3ac5400bf7bf4cd658d5a60c69","collapsed":true,"_cell_guid":"ad43f727-f13f-4fd3-ad29-f8c26ade1681","trusted":false},"outputs":[],"source":"def process_df(df):\n    dicty = get_dicty()\n    \n    \n    df['pickup_datetime'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n    df['weekday_pickup'] = df['pickup_datetime'].apply(lambda x: x.weekday())\n    df['month_pickup'] = df['pickup_datetime'].apply(lambda x: x.month)\n    df['week_pickup'] = df['pickup_datetime'].apply(lambda x: x.week)\n    df['hour_pickup'] = df['pickup_datetime'].apply(lambda x: x.hour)\n    df['trip_distance'] = df.apply(lambda x: distance(x['pickup_latitude'], \n                                                       x['pickup_longitude'],\n                                                        x['dropoff_latitude'],\n                                                        x['dropoff_longitude']\n                                                       ), axis = 1 )\n    df['angle_start_end'] = df.apply(lambda x: angle_between_vectors_degrees(x['pickup_latitude'], x['pickup_longitude'],\n                                                x['dropoff_latitude'], x['dropoff_longitude']), axis = 1)\n    df['angle_direction'] = df.apply(lambda x: angle_between_vectors_degrees(x['pickup_latitude'], x['pickup_longitude'],\n                                                x['dropoff_latitude'], x['dropoff_longitude'], mode = 'center'), axis = 1)\n    \n    df['borough_start'] = df.apply(lambda x: get_district(x['pickup_latitude'], x['pickup_longitude'],\n                                                dicty), axis = 1)\n    \n    df['borough_end'] = df.apply(lambda x: get_district(x['dropoff_latitude'], x['dropoff_longitude'],\n                                                dicty), axis = 1)\n    \n    df['store_and_fwd_flag'] = (df['store_and_fwd_flag'] == 'Y') * 1\n    \n    return df","cell_type":"code","execution_count":7},{"metadata":{"_uuid":"18e9825004405891fdcdfe3c7b1fb6dedcc67275","_cell_guid":"20c7bff6-373b-4cce-ac9b-a45986c500d6"},"source":"### Generate first features","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd633e9506cae0555b26f7dd9d1bf030cea28804","collapsed":true,"_cell_guid":"892d5a9d-e2cd-4b84-9f41-0ddd302b9796","trusted":false},"outputs":[],"source":"train = process_df(train)\ntest = process_df(test)","cell_type":"code","execution_count":8},{"metadata":{"_uuid":"72441910da96713096a86d96134f209f6bb505d8","_cell_guid":"b5470bba-3c80-4160-b90b-0ae73f2025b8"},"source":"### Add clusters","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81bac65acd8108d5b863bd58a88353c966e09853","collapsed":true,"_cell_guid":"f3e0d2a4-b9c0-490b-99d8-57d6ca77fd49","trusted":false},"outputs":[],"source":"clf = KMeans(n_clusters = 10)\nclf.fit([[x] for x in train['trip_distance'].values])\ntrain['distance_cluster'] = clf.labels_\ntest['distance_cluster'] = clf.predict([[x] for x in test['trip_distance'].values])","cell_type":"code","execution_count":9},{"metadata":{"_uuid":"b2bdaafa83ed9c3225b345f8a188636b3fe92e67","collapsed":true,"_cell_guid":"d183b804-482b-40e3-9d60-c683896ace1e","trusted":false},"outputs":[],"source":"clf = KMeans(n_clusters = 20)\nclf.fit([[x, y] for x, y in zip(train['pickup_latitude'].values, train['pickup_longitude'].values)])\ntrain['pickup_coord_cluster'] = clf.labels_\ntest['pickup_coord_cluster'] = clf.predict([[x, y] for x, y in zip(test['pickup_latitude'].values, test['pickup_longitude'].values)])","cell_type":"code","execution_count":10},{"metadata":{"_uuid":"ab45c744f07266e691b9be5c3e1b22d7315b4f55","collapsed":true,"_cell_guid":"ae10a153-a98a-4fd5-a8af-cad044a5dcc4","trusted":false},"outputs":[],"source":"clf = KMeans(n_clusters = 20)\nclf.fit([[x, y] for x, y in zip(train['dropoff_latitude'].values, train['dropoff_longitude'].values)])\ntrain['dropoff_coord_cluster'] = clf.labels_\ntest['dropoff_coord_cluster'] = clf.predict([[x, y] for x, y in zip(test['dropoff_latitude'].values, test['dropoff_longitude'].values)])","cell_type":"code","execution_count":11},{"metadata":{"_uuid":"9998bacd5efe2888ae162820a42523f1be4fcfd1","_cell_guid":"021b507b-59ac-4ad2-b77d-684c8517c036"},"source":"### Add weather data","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"453ade694a294a7290bb73e91d1c0ceef0ed434c","collapsed":true,"_cell_guid":"a1f93bef-31bc-4afe-9b6b-232650c2e28a","trusted":false},"outputs":[],"source":"weather = pd.read_csv(base_path5 + 'weather_data_nyc_centralpark_2016.csv')\nweather['date'] = weather['date'].apply(lambda x: x.replace('-', ''))\ntrain['date'] = train['pickup_datetime'].apply(lambda x: (str(x)[8:10] if str(x)[8] != '0' else str(x)[9]) + \n                                               (str(x)[5:7] if str(x)[5] != '0' else str(x)[6]) + \n                                               str(x)[:4])\ntrain = pd.merge(train, weather, how = 'left', on = 'date')\ntest['date'] = test['pickup_datetime'].apply(lambda x: (str(x)[8:10] if str(x)[8] != '0' else str(x)[9]) + \n                                               (str(x)[5:7] if str(x)[5] != '0' else str(x)[6]) + \n                                               str(x)[:4])\ntest = pd.merge(test, weather, how = 'left', on = 'date')\n\nfor c in ['maximum temerature', 'minimum temperature',\n       'average temperature', 'precipitation', 'snow fall', 'snow depth']:\n    print(c)\n    mean_ = np.mean([x for x in train[c].values if type(x) != str])\n    train[c] = train[c].apply(lambda x: x if type(x) != str else mean_)\n    test[c] = test[c].apply(lambda x: x if type(x) != str else mean_)\n\ntrain.drop('date', axis = 1, inplace = True)\ntest.drop('date', axis = 1, inplace = True)","cell_type":"code","execution_count":12},{"metadata":{"_uuid":"10ce332682381f8366ad6e00f3c0ec27e564bb86","_cell_guid":"4ff6feb8-7574-4b5a-85e8-94b379cce7d7"},"source":"### Add routes","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5dcf328e61dbf2253dab07d6c80afce614a3b62","collapsed":true,"_cell_guid":"8a40ee08-94d7-4ebf-b007-2b1e609ee9d7","trusted":false},"outputs":[],"source":"routes1 = pd.read_csv(base_path2 + 'fastest_routes_train_part_1.csv')\nroutes2 = pd.read_csv(base_path2 + 'fastest_routes_train_part_2.csv')\nroutes = routes1.append(routes2, ignore_index = True)\nroutes = routes[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\ntrain = pd.merge(train, routes, how = 'left', on = 'id')\n\n\nroutes = pd.read_csv(base_path2 + 'fastest_routes_test.csv')\nroutes = routes[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\ntest = pd.merge(test, routes, how = 'left', on = 'id')\n\n\nroutes = pd.read_csv(base_path2 + 'second_fastest_routes_train.csv')\nroutes = routes[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\nroutes.columns = ['id', 'total_distance_2', 'total_travel_time_2', 'number_of_steps_2']\ntrain = pd.merge(train, routes, how = 'left', on = 'id')\n\nroutes = pd.read_csv(base_path2 + 'second_fastest_routes_test.csv', engine = 'python',\n                     delimiter = ',', error_bad_lines=False)\nroutes = routes[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\nroutes.columns = ['id', 'total_distance_2', 'total_travel_time_2', 'number_of_steps_2']\ntest = pd.merge(test, routes, how = 'left', on = 'id')\n\ntrain.fillna(0, inplace = True)\ntest.fillna(0, inplace = True)","cell_type":"code","execution_count":13},{"metadata":{"_uuid":"1fdd7714558b96ed70167297efc7980bc4faefcc","_cell_guid":"71551bc3-d451-4a12-931f-f4390fdfdacd"},"source":"### Add traffic collisions","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8eccb5ebc71af352f225e001b15175871f4e8111","collapsed":true,"_cell_guid":"ea2ceddb-718a-40dd-8b11-f20352bc54e7","trusted":false},"outputs":[],"source":"traffic = pd.read_csv(base_path3 + 'NYPD_Motor_Vehicle_Collisions.csv')\ntraffic['BOROUGH'].fillna('other', inplace = True)\n\ntrain['borough_start'] = train['borough_start'].str.upper()\ntrain['borough_end'] = train['borough_end'].str.upper()\ntest['borough_start'] = test['borough_start'].str.upper()\ntest['borough_end'] = test['borough_end'].str.upper()\n\ntraffic['time'] = traffic['TIME'].apply(lambda x: int(str(x)[:2].replace(':', '')))\n\n### Add collisions in total by date and hour match\n\ntr = traffic.groupby(['DATE', 'time'])['BOROUGH'].count().reset_index()\ntr['DATE'] = tr['DATE'].apply(lambda x: datetime.datetime.strptime(x, '%m/%d/%Y'))\ntr.columns = ['DATE', 'time', 'collisions_total']\n\ntrain['year'] = train['pickup_datetime'].apply(lambda x: x.year)\ntrain['month'] = train['pickup_datetime'].apply(lambda x: x.month)\ntrain['day'] = train['pickup_datetime'].apply(lambda x: x.day)\ntrain['time'] = train['pickup_datetime'].apply(lambda x: x.hour)\n\ntest['year'] = test['pickup_datetime'].apply(lambda x: x.year)\ntest['month'] = test['pickup_datetime'].apply(lambda x: x.month)\ntest['day'] = test['pickup_datetime'].apply(lambda x: x.day)\ntest['time'] = test['pickup_datetime'].apply(lambda x: x.hour)\n\ntr['year'] = tr['DATE'].apply(lambda x: x.year)\ntr['day'] = tr['DATE'].apply(lambda x: x.day)\ntr['month'] = tr['DATE'].apply(lambda x: x.month)\n\ntrain = pd.merge(train, tr, how = 'left', on = ['year', 'month', 'day', 'time'])\ntest = pd.merge(test, tr, how = 'left', on = ['year', 'month', 'day', 'time'])\n\ntrain.drop(['DATE'], axis = 1, inplace = True)\ntest.drop(['DATE'], axis = 1, inplace = True)\n\n\n### Add collisions in total by date, hour and borough match\n\n\ntr = traffic.groupby(['DATE', 'time', 'BOROUGH'])['LATITUDE'].count().reset_index()\ntr.columns = ['DATE', 'time', 'BOROUGH','collisions_borough_start']\ntr['DATE'] = tr['DATE'].apply(lambda x: datetime.datetime.strptime(x, '%m/%d/%Y'))\ntr['year'] = tr['DATE'].apply(lambda x: x.year)\ntr['day'] = tr['DATE'].apply(lambda x: x.day)\ntr['month'] = tr['DATE'].apply(lambda x: x.month)\n\n\n\n\ntrain = pd.merge(train, tr, how = 'left', left_on = ['year', 'month', 'day', 'time', 'borough_start'],\n                \n                right_on = ['year', 'month', 'day', 'time', 'BOROUGH']\n                )\n\ntest = pd.merge(test, tr, how = 'left', left_on = ['year', 'month', 'day', 'time', 'borough_start'],\n                \n                right_on = ['year', 'month', 'day', 'time', 'BOROUGH']\n                )\n\ntrain.drop(['BOROUGH', 'DATE'], axis = 1, inplace = True)\ntest.drop(['BOROUGH', 'DATE'], axis = 1, inplace = True)\n\ntr.rename(columns = {'collisions_borough_start' : 'collisions_borough_end'}, inplace = True)\n\ntrain = pd.merge(train, tr, how = 'left', left_on = ['year', 'month', 'day', 'time', 'borough_end'],\n                \n                right_on = ['year', 'month', 'day', 'time', 'BOROUGH']\n                )\n\ntest = pd.merge(test, tr, how = 'left', left_on = ['year', 'month', 'day', 'time', 'borough_end'],\n                \n                right_on = ['year', 'month', 'day', 'time', 'BOROUGH']\n                )\n\ntrain.drop(['BOROUGH', 'DATE'], axis = 1, inplace = True)\ntest.drop(['BOROUGH', 'DATE'], axis = 1, inplace = True)\n\ntrain.fillna(0, inplace = True)\ntest.fillna(0, inplace = True)","cell_type":"code","execution_count":14},{"metadata":{"_uuid":"8f8e2b19c1251e8fa7f6e7573296b789bc47e630","_cell_guid":"72b0cabe-5844-49bf-a6d9-0a74320364d8"},"source":"### Encode text data and delete duplicates","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65b428fb399bd0600116e91cd33a073c39563a5d","collapsed":true,"_cell_guid":"83978920-5271-41ba-bf2d-cfd9d32bba81","trusted":false},"outputs":[],"source":"for c in test.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n        \ntrain.drop_duplicates(subset = ['id'], keep = 'first', inplace = True)\ntest.drop_duplicates(subset = ['id'], keep = 'first', inplace = True)","cell_type":"code","execution_count":17},{"metadata":{"_uuid":"f72faa8e7b09d3390f61fe2ee5e33e40cbd5484a","_cell_guid":"5d31d2ae-00cd-475b-89cf-70f751557313"},"source":"### Add some extra features","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd52806b4e9cf142c876af65518893d3a1186a1c","collapsed":true,"_cell_guid":"15bc3d11-8e8a-49ba-98ee-fd881b902a3d","trusted":false},"outputs":[],"source":"train['borough_same'] = (train['borough_start'] == train['borough_end']) * 1\ntest['borough_same'] = (test['borough_start'] == test['borough_end']) * 1\ntrain['hour_period'] = train['hour_pickup'].apply(lambda x: 0 if x <= 6 else 1 if x <= 12 else 2 if x <= 18 else 3)\ntest['hour_period'] = test['hour_pickup'].apply(lambda x: 0 if x <= 6 else 1 if x <= 12 else 2 if x <= 18 else 3)\ntrain['cluster_same'] = (train['pickup_coord_cluster'] == train['dropoff_coord_cluster']) * 1\ntest['cluster_same'] = (test['pickup_coord_cluster'] == test['dropoff_coord_cluster']) * 1\ntrain['lat_distance'] = train['pickup_latitude'] - train['dropoff_latitude']\ntest['lat_distance'] = test['pickup_latitude'] - test['dropoff_latitude']\n\ntrain['lon_distance'] = train['pickup_longitude'] - train['dropoff_longitude']\ntest['lon_distance'] = test['pickup_longitude'] - test['dropoff_longitude']\n\ntrain['week_end'] = (train['weekday_pickup'] == 0)*1 + (train['weekday_pickup'] == 6)*1\ntest['week_end'] = (test['weekday_pickup'] == 0)*1 + (test['weekday_pickup'] == 6)*1\n\nfull = pd.concat([train, test]).reset_index(drop=True)\ncoords = np.vstack((full[['pickup_latitude', 'pickup_longitude']],\n                    full[['dropoff_latitude', 'dropoff_longitude']]))\n\npca = PCA().fit(coords)\ntrain['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntrain['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntrain['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntrain['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n\ntest['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntest['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntest['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntest['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n\ntrain['pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + \\\n                             np.abs(train['dropoff_pca0'] - train['pickup_pca0'])\n\ntest['pca_manhattan'] = np.abs(test['dropoff_pca1'] - test['pickup_pca1']) + \\\n                        np.abs(test['dropoff_pca0'] - test['pickup_pca0'])\n\ntrain['direction_ns'] = (train.pickup_latitude > train.dropoff_latitude) * 1 + 1\nindices = train[(train.pickup_latitude == train.dropoff_longitude) & (train.pickup_latitude != 0)].index\ntrain.loc[indices, 'direction_ns'] = 0\n\ntrain['direction_ew'] = (train.pickup_longitude > train.dropoff_longitude) * 1 + 1\nindices = train[(train.pickup_longitude == train.dropoff_longitude) & (train.pickup_longitude != 0)].index\ntrain.loc[indices, 'direction_ew'] = 0\n\ntest['direction_ns'] = (test.pickup_latitude > test.dropoff_latitude) * 1 + 1\nindices = test[(test.pickup_latitude == test.dropoff_longitude) & (test.pickup_latitude != 0)].index\ntest.loc[indices, 'direction_ns'] = 0\n\ntest['direction_ew'] = (test.pickup_longitude > test.dropoff_longitude) * 1 + 1\nindices = test[(test.pickup_longitude == test.dropoff_longitude) & (test.pickup_longitude != 0)].index\ntest.loc[indices, 'direction_ew'] = 0\n\n\ntrain['speed'] = train['trip_distance'] / train['trip_duration']\nspeed_cluster = train.groupby(['pickup_coord_cluster', 'hour_pickup'])['speed'].mean().reset_index()\ntrain = pd.merge(train, speed_cluster, how = 'left', on = ['pickup_coord_cluster', 'hour_pickup'])\ntest = pd.merge(test, speed_cluster, how = 'left', on = ['pickup_coord_cluster', 'hour_pickup'])\ntrain.drop('speed_x', axis = 1, inplace = True)\ntrain.rename(columns = {'speed_y':'speed'}, inplace = True)\ntrain.rename(columns = {'speed':'speed_pickup'}, inplace = True)\ntest.rename(columns = {'speed':'speed_pickup'}, inplace = True)\n\ntrain['speed'] = train['trip_distance'] / train['trip_duration']\nspeed_cluster = train.groupby(['dropoff_coord_cluster', 'hour_pickup'])['speed'].mean().reset_index()\ntrain = pd.merge(train, speed_cluster, how = 'left', on = ['dropoff_coord_cluster', 'hour_pickup'])\ntest = pd.merge(test, speed_cluster, how = 'left', on = ['dropoff_coord_cluster', 'hour_pickup'])\ntrain.drop('speed_x', axis = 1, inplace = True)\ntrain.rename(columns = {'speed_y':'speed'}, inplace = True)\ntrain.rename(columns = {'speed':'speed_dropoff'}, inplace = True)\ntest.rename(columns = {'speed':'speed_dropoff'}, inplace = True)\ntrain['direction'] = (train['direction_ns'] == train['direction_ew'])*1\ntest['direction'] = (test['direction_ns'] == test['direction_ew'])*1","cell_type":"code","execution_count":20},{"metadata":{"_uuid":"a22b18824507e13f1f3e69b85403b11ace422a8c","_cell_guid":"8e8df8af-180c-4027-8053-d91c813c0427"},"source":"### Save files","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9a9e65657434e861b9ffecc3842f14f30dc8488","collapsed":true,"_cell_guid":"144d3f0e-7403-4de8-a06c-4fc62a123d8b","trusted":false},"outputs":[],"source":"train.to_csv(base_path1 + 'train_p.csv', index = False)\ntest.to_csv(base_path1 + 'test_p.csv', index = False)","cell_type":"code","execution_count":21},{"metadata":{"_uuid":"b48230bc0e32fcd990c7323f33401031d365c3fb","_cell_guid":"707fe3d4-6948-47a1-92b1-c2461c7cc11b"},"source":"### Get ready for training xgboost","cell_type":"markdown","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3713021e37dc1ab99f620cf774afbbcf5033085","collapsed":true,"_cell_guid":"d9dee8c1-2ae3-4ce0-98e8-9b1463abf4b0","trusted":false},"outputs":[],"source":"train_cols = [\n    'borough_start',\n'borough_end',\n  'vendor_id',\n'passenger_count',\n'pickup_longitude',\n'pickup_latitude',\n'dropoff_longitude',\n'dropoff_latitude',\n'store_and_fwd_flag',\n'weekday_pickup',\n'month_pickup',\n'week_pickup',\n'hour_pickup',\n'trip_distance',\n'angle_start_end',\n'angle_direction',\n'distance_cluster',\n'pickup_coord_cluster',\n'dropoff_coord_cluster',\n'maximum temerature',\n'minimum temperature',\n'average temperature',\n'precipitation',\n'snow fall',\n'snow depth',\n'total_distance',\n'total_travel_time',\n'number_of_steps',\n'total_distance_2',\n'total_travel_time_2',\n'number_of_steps_2' ,\n'collisions_total',\n'collisions_borough_start',\n'collisions_borough_end',\n'borough_same',\n'hour_period',\n'cluster_same',\n'lat_distance',\n'lon_distance',\n'week_end',\n'speed_dropoff',\n'speed_pickup',\n'direction',\n'pickup_pca0',\n'pickup_pca1',\n'dropoff_pca0',\n'dropoff_pca1',\n'pca_manhattan',\n'direction_ns',\n'direction_ew'\n]","cell_type":"code","execution_count":22},{"metadata":{"_uuid":"15ee761397d0f29a5ff527137d6fbc208cf31937","collapsed":true,"_cell_guid":"edff32e4-f0e1-469d-86a1-62ffb184e341","trusted":false},"outputs":[],"source":"train['trip_duration'] = np.log(train['trip_duration'] + 1)","cell_type":"code","execution_count":23},{"metadata":{"_uuid":"659f5f4629bf658241475771e1a25074b859e74c","collapsed":true,"_cell_guid":"4e61b4bb-5204-452c-86a1-ae61acd754fd","trusted":false},"outputs":[],"source":"X_train, X_valid, y_train, y_valid = train_test_split( train[train_cols], train['trip_duration'], test_size=0.2, random_state=42)","cell_type":"code","execution_count":24},{"metadata":{"_uuid":"cff85433d97bd5d46315be33bc2565c1116f80db","collapsed":true,"_cell_guid":"41113d9d-ce48-44ba-95f6-610c5bcdf19a","trusted":false},"outputs":[],"source":"xgb_pars = {'min_child_weight': 10, 'eta': 0.025, 'colsample_bytree': 0.3, 'max_depth': 10,\n            'subsample': 0.9, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n\n\nd_train = xgb.DMatrix(X_train, label=y_train)\nd_valid = xgb.DMatrix(X_valid, label=y_valid)\n\nwatchlist = [(d_train, \n              'train'), (d_valid, 'valid')]\n\nbst = xgb.train(xgb_pars, d_train, 10**6, watchlist, early_stopping_rounds=10, verbose_eval=5, \n               maximize = False\n               )","cell_type":"code","execution_count":25},{"metadata":{"_uuid":"4f78b6d3f2f0fdcd55d5491b9b94d2590e4e12e2","collapsed":true,"_cell_guid":"324da46d-34b6-4132-b9bb-138aca27d0d1","trusted":false},"outputs":[],"source":"d_test = xgb.DMatrix(test[train_cols])","cell_type":"code","execution_count":27},{"metadata":{"_uuid":"43be12b8c837953df85a9ccadca7329c6f537cea","collapsed":true,"_cell_guid":"57411c92-8a29-4428-9370-277714c8de13","trusted":false},"outputs":[],"source":"ytest = bst.predict(d_test)\ntest['trip_duration'] = np.exp(ytest) - 1\ntest[['id', 'trip_duration']].drop_duplicates(subset = ['id'], keep = 'first').to_csv(base_path1 + 'pavel_xgb_submission.csv.gz', index=False, compression='gzip')","cell_type":"code","execution_count":null},{"metadata":{"_uuid":"9f32282a718132067185064450230fe2397a962d","collapsed":true,"_cell_guid":"45f58549-fb4e-43e0-8e62-d2151dc7a66f","trusted":false},"outputs":[],"source":"","cell_type":"code","execution_count":null},{"metadata":{"_uuid":"56f4eed1eb572c454115a4cbd0ca565f88e730f3","collapsed":true,"_cell_guid":"78e03b0f-3b38-430a-8660-51050d90ae3e","trusted":false},"outputs":[],"source":"","cell_type":"code","execution_count":null}],"nbformat_minor":2}