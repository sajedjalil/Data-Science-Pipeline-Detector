{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.1","pygments_lexer":"ipython3","file_extension":".py"}},"nbformat":4,"cells":[{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1ef37ba30d6840dcf0dc1b00dacb4a057ce0a940","_cell_guid":"c84323d7-f0c5-4eb0-acfa-3ea1f0551e46"},"source":"!pip install geopy\n!pip install pandas\n!pip install pathos\n!pip install xgboost\n!pip install azure-storage\n!pip install reverse_geocoder\n!pip install -U scikit-learn"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6998a53c66230d911891fef7d02c0252c324351a","_cell_guid":"b5f56167-fdd7-4059-b2de-7284b8591819"},"source":"import pandas as pd\nfrom azure.storage.file import FileService\nimport os\n\naccount_name = ''\naccount_key = ''\nfile_service = FileService(account_name=account_name, account_key=account_key)\ndef get_train_data():\n    file_service.get_file_to_path('data', None, 'train.csv', 'train.csv')\ndef get_test_data():\n    file_service.get_file_to_path('data', None, 'test.csv', 'test.csv')\n\nif not os.path.exists('train.csv'):\n    get_train_data()\nif not os.path.exists('test.csv'):\n    get_test_data()\ndataframe = pd.read_csv('train.csv', index_col=0)\ntest_dataframe = pd.read_csv('test.csv', index_col=0)\nprint dataframe.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b19f62b7ce17a1f1d5ea548e6c5c74df2b281a95","_cell_guid":"76aa8b53-3070-48b1-b68d-f203f55327bc"},"source":"from geopy.distance import great_circle\nfrom dateutil.parser import parse\nimport time\nfrom pathos.multiprocessing import ProcessingPool as Pool\nfrom pathos.multiprocessing import cpu_count\nimport numpy as np\n\n# def get_borough(lat, lng, retries=3):\n#     if retries <= -1: return None\n#     try:\n#         geolocator = Nominatim()\n#         location = geolocator.reverse('{}, {}'.format(lat, lng))\n#         return location.address.split(', ')[2]\n#     except Exception as e:\n#         print 'Too many requests. Waiting for 2 mins for {}, {}'.format(lat, lng)\n#         time.sleep(30)\n#         return get_borough(lat, lng, retries-1)\n        \ndef transform_df(df, great_circle=great_circle, parse=parse, np=np):\n    yes_func = lambda x: 1 if x == 'Y' else 0\n    df['distance'] = df.apply(lambda row : great_circle((row['pickup_latitude'], row['pickup_longitude']), \n                                                        (row['dropoff_latitude'], row['dropoff_longitude'])).miles, axis=1)\n                              \n    df['month'] = df.apply(lambda row: parse(row['pickup_datetime']).month, axis=1)\n    df['day'] = df.apply(lambda row: parse(row['pickup_datetime']).weekday(), axis=1)\n    df['pickup_hour'] = df.apply(lambda row: parse(row['pickup_datetime']).hour, axis=1)\n    df['store_and_fwd_flag'] = df.apply(lambda row: yes_func(row['store_and_fwd_flag']), axis=1)\n    return df\n\ndef parallelize_dataframe(df, func, num_cores, num_partitions):\n    df_split = np.array_split(df, num_partitions)\n    pool = Pool(num_cores)\n    df = pd.concat(pool.map(func, df_split))\n    pool.clear()\n    return df\n\nnew_df = parallelize_dataframe(dataframe, transform_df, cpu_count(), cpu_count())\nnew_df['trip_duration'] = new_df.apply(lambda row: np.log1p(row['trip_duration']), axis=1)\nprint new_df.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ce61c0f081e31d175246e0eb7b0f286b7b6749ec","_cell_guid":"3447d228-68a6-4e17-87d6-6bac914dc342"},"source":"import reverse_geocoder as rg\nfrom sklearn import preprocessing\n\n# def get_borough_rev_geocoder(lat, lng):\n#     return rg.search((lat, lng))[0]['name']\n# dataframe['pickup_borough'] = dataframe.apply(lambda row: \n#                                               get_borough_rev_geocoder(row['pickup_latitude'], row['pickup_longitude']), axis=1)\ndef get_coords(df, lat_key, long_key):\n    lats = df[lat_key].values.tolist()\n    longs = df[long_key].values.tolist()\n    coords = zip(lats, longs)\n    return coords\ndef encode_labels(labels):\n    le = preprocessing.LabelEncoder()\n    le.fit(labels)\n    return le\ndef add_borough(df):\n    pickup_coords = get_coords(df, 'pickup_latitude', 'pickup_longitude')\n    dropoff_coords = get_coords(df, 'dropoff_latitude', 'dropoff_longitude')\n    pickup_boroughs = np.array([d['admin2'] for d in rg.search(pickup_coords)])\n    dropoff_boroughs = np.array([d['admin2'] for d in rg.search(dropoff_coords)])\n    df['pickup_borough'] = encode_labels(pickup_boroughs).transform(pickup_boroughs)\n    df['dropoff_borough'] = encode_labels(dropoff_boroughs).transform(dropoff_boroughs)\n    return df\nnew_df = add_borough(new_df)\nprint new_df.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"7b9cb0aa247b2938a230db9d5df0e16498d5821e","_cell_guid":"9fd45b23-c6c9-4049-99e6-544a128eac93"},"source":"features = ['vendor_id', 'month', 'day', 'pickup_hour', 'store_and_fwd_flag', 'distance', 'pickup_borough', 'dropoff_borough']\ndef scale_df(df, test=False):\n    if test:\n        customized_df = df[features]\n        x = customized_df.values #returns a numpy array\n    else:\n        customized_df = df[features + ['trip_duration']]\n        x = customized_df.values[:,:-1] #returns a numpy array\n        \n\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    if not test:\n        trip_duration_col = np.array([customized_df['trip_duration'].values])\n        x_scaled = np.concatenate((x_scaled, trip_duration_col.T), 1)\n    scaled_df = pd.DataFrame(x_scaled, columns=customized_df.columns)\n    return scaled_df\nscaled_df = scale_df(new_df)\nprint scaled_df.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"271705276523b4ecdfb55d9d76582451b76d98a8","_cell_guid":"3b2cd22c-02fc-4351-99d0-0377c9d797de"},"source":"from sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n\ndef rlmse_func(predicted, actual):\n    return np.sqrt(np.mean(np.square(np.log(predicted+1.0) - np.log(actual+1.0))))\n\nrlmse = make_scorer(rlmse_func, greater_is_better=False)\n\n# param_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01, 0.3],\n#               'max_depth': range(4, 7),\n#               'subsample': [0.8, 1],\n#               'n_estimators': [1000, 2000]\n#               }\n\nX_train, y_train = scaled_df[features].values, scaled_df[['trip_duration']].values\nxgb_model = XGBRegressor(objective='reg:linear', max_depth=7, learning_rate=0.3, n_estimators=2000, nthread=-1)\nprint -1.0*cross_val_score(xgb_model, X_train, y_train.ravel(), scoring=rlmse, cv=10, verbose=8).mean()\n\n"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b4d5000e8a385985dc8311b440a7fc5216ed3661","_cell_guid":"d735b6dd-1cc5-46eb-9953-59963d0d3e7b"},"source":"test_df = parallelize_dataframe(test_dataframe, transform_df, cpu_count(), cpu_count())\nnew_test_df = scale_df(add_borough(test_df), test=True)\nprint new_test_df.head()"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"791ecfa50a7b193b7429cea335c14fa9d5b19e47","_cell_guid":"30c21cec-c2f9-4e1d-84f1-483a41317521"},"source":"xgb_model = XGBRegressor(objective='reg:linear', max_depth=7, learning_rate=0.3, reg_lambda = 1.5, n_estimators=2000, nthread=-1)\nxgb_model.fit(X_train, y_train)\npredictions = xgb_model.predict(new_test_df.values)\nprint predictions"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4b7edafbdc369d64c98c6b891e048e3993d64861","_cell_guid":"fd406677-80e2-4261-ba7f-a67a29a581b2"},"source":"test_trip_duration = np.expm1(abs(predictions))\nresult_df = pd.DataFrame({'id': test_dataframe.index.values, 'trip_duration': test_trip_duration})\nresult_df.to_csv('answer.csv', index=False)"},{"outputs":[],"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d2558d51c69e9b1b7d8be6c33b3028d3a28b4b18","_cell_guid":"a62a0497-7519-4a33-9998-092aac37ffeb","collapsed":true},"source":""}],"nbformat_minor":2}