{"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.1","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"}},"cells":[{"source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Sep 03 22:33:34 2017\n\n@author: YOANN\n\"\"\"\n    \nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom pandas.tools.plotting import scatter_matrix\n\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"cell_type":"code","metadata":{"_uuid":"75907d05e9b6d5043e5b65719371b3dff71d1539","collapsed":true,"_cell_guid":"22e70dac-4b49-4854-918b-f86b13a8c00a"},"outputs":[]},{"source":"Let's import and have a look at the data","cell_type":"markdown","metadata":{"_cell_guid":"8aade2b3-65cd-4f60-b569-35c88030640f","_uuid":"88b8edb8a5c411ac46a6e1b2f4efc777dfc6e838"}},{"source":"plt.close('all')\n\nprint(\"Loading and displaying data ... \\n\")\ndatafile = '../input/train.csv'\ndata = pd.read_csv(datafile)\n\nm,n = data.shape\n\n#=========================Having a look at the data =========================#\nallLat = np.array(list(data['pickup_latitude'])+list(data['dropoff_latitude']))\nallLong = np.array(list(data['pickup_longitude'])+list(data['dropoff_longitude']))\n\nlatLimits = [np.percentile(allLat,0.3), np.percentile(allLat, 99.7)]\nlonLimits = [np.percentile(allLong,0.3), np.percentile(allLong, 99.7)]\n\ndurLimits  = [np.percentile(data['trip_duration'], 0.4), np.percentile(data['trip_duration'], 99.7)]\n\ndata = data[(data['pickup_latitude']>=latLimits[0])&(data['pickup_latitude']<=latLimits[1])]\ndata = data[(data['dropoff_latitude']>=latLimits[0])&(data['dropoff_latitude']<=latLimits[1])]\ndata = data[(data['pickup_longitude']>=lonLimits[0])&(data['pickup_longitude']<=lonLimits[1])]\ndata = data[(data['dropoff_longitude']>=lonLimits[0])&(data['dropoff_longitude']<=lonLimits[1])]\ndata = data[(data['trip_duration']>=durLimits[0])&(data['trip_duration']<=durLimits[1])]\n    \nallLat = np.array(list(data['pickup_latitude'])+list(data['dropoff_latitude']))\nallLong = np.array(list(data['pickup_longitude'])+list(data['dropoff_longitude']))\n\nmedianLat  = np.percentile(allLat,50)\nmedianLong = np.percentile(allLong,50)\n\nlatMultiplier  = 111.32\nlongMultiplier = np.cos(medianLat*(np.pi/180.0)) * 111.32\n\ndata['duration [min]'] = data['trip_duration']/60.0\ndata['src lat [km]']   = latMultiplier  * (data['pickup_latitude']   - medianLat)\ndata['src long [km]']  = longMultiplier * (data['pickup_longitude']  - medianLong)\ndata['dst lat [km]']   = latMultiplier  * (data['dropoff_latitude']  - medianLat)\ndata['dst long [km]']  = longMultiplier * (data['dropoff_longitude'] - medianLong)\n\nallLat  = np.array(list(data['src lat [km]'])  + list(data['dst lat [km]']))\nallLong = np.array(list(data['src long [km]']) + list(data['dst long [km]']))\n\n\nfig, axArray = plt.subplots(nrows=1,ncols=2,figsize=(12,5))\naxArray[0].set_ylabel('Count')\naxArray[0].hist(allLat,80);axArray[1].set_xlabel('Lat in km')\naxArray[1].hist(allLong,80);axArray[1].set_xlabel('Long in km')","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"c8b56eea-a0f4-41b1-946b-130dd27ec329","_uuid":"7d73fce536fc63eef080bb5f490f81d94bbcbfb5"},"outputs":[]},{"source":"# show the log density of pickup and dropoff locations\nimageSize = (700,700)\nlongRange = [-5,19]\nlatRange = [-13,11]\n\nallLatInds  = imageSize[0] - (imageSize[0] * (allLat  - latRange[0])  / (latRange[1]  - latRange[0]) ).astype(int)\nallLongInds =                (imageSize[1] * (allLong - longRange[0]) / (longRange[1] - longRange[0])).astype(int)\n\nlocationDensityImage = np.zeros(imageSize)\nfor latInd, longInd in zip(allLatInds,allLongInds):\n    locationDensityImage[latInd,longInd] += 1\n\nfig, ax = plt.subplots(nrows=1,ncols=1,figsize=(12,12))\nax.imshow(np.log(locationDensityImage+1),cmap='hot')\nax.set_axis_off()","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"96fcaefb-dfac-4989-bc7f-ac1d45a37bfc","_uuid":"13333bde5475b7fbc639b7f39acea189aaeb8766"},"outputs":[]},{"source":"This is a nice map of Manhattan ! But is the trip duration a function only of the distance ?","cell_type":"markdown","metadata":{"_cell_guid":"3e3528a1-311d-4098-8b28-d3a2c42b7296","_uuid":"a94359eac73e1016eb8a813c174cd2bc813d8168"}},{"source":"pickUpTime = pd.to_datetime(data['pickup_datetime'])\ndata['src hourOfDay'] = pickUpTime.dt.hour + pickUpTime.dt.minute/60.0\ndata['day of week'] = pickUpTime.dt.weekday\ndata['month of year'] = pickUpTime.dt.month\n    \ndelta_lat = np.radians(data['dropoff_latitude']-data['pickup_latitude'])\ndelta_lon = np.radians(data['dropoff_longitude']-data['pickup_longitude'])\nlat_m = np.radians(data['dropoff_latitude']+data['pickup_latitude'])/2.0\n    \ndata['distance'] = np.sqrt((data['dst lat [km]']-data['src lat [km]'])**2\n                           +(data['dst long [km]']-data['src long [km]'])**2)\n\nfig, axArray = plt.subplots(nrows=1,ncols=3,figsize=(12,5))\naxArray[0].hist(data['duration [min]'],80)\naxArray[0].set_xlabel('duration [min]'), axArray[0].set_ylabel('Count')\naxArray[1].hist(data['distance'],80)\naxArray[1].set_xlabel('distance in km')\naxArray[2].scatter(data['distance'], data['duration [min]'])\naxArray[2].set_xlabel('distance in km'); axArray[2].set_ylabel('trip duration in min')","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"2d4cfc6d-033a-4379-bf03-04161c4b4798","_uuid":"a4334448ad13d8a8738c3a856830a157ce0ad0ba"},"outputs":[]},{"source":"data.head(1)","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"10aff876-57c0-4da9-a531-85060bf515ac","_uuid":"7060176e3d709aa26c181430f5b78004fc2d0e95"},"outputs":[]},{"source":"rand_rows = np.random.permutation(data.shape[0])\nplt.scatter(data['distance'][rand_rows[0:100]], data['duration [min]'][rand_rows[0:100]])\n\nX_tot = data.get(['distance','src lat [km]','src long [km]',\n                         'dst lat [km]','dst long [km]', 'src hourOfDay', \n                         'day of week','month of year']).values\ny_tot = data['trip_duration'].values\n    \nrand_rows = np.random.permutation(data.shape[0])\nm_red = 200000\ndata_red = data.ix[rand_rows[0:m_red]].dropna()\n\nX = data_red.get(['distance','src lat [km]','src long [km]',\n                         'dst lat [km]','dst long [km]', 'src hourOfDay', \n                         'day of week','month of year']).values\ny = data_red['trip_duration'].values\n\nmean = np.mean(X, axis=0)\nstd = np.std(X, axis=0)\nX = X/std\n    \nm_red = X.shape[0]\nrand_rows = np.random.permutation(m_red)\n\nm_train = np.int(0.5*m_red)\nX_train = X[rand_rows[0:m_train],:]\ny_train = y[rand_rows[0:m_train]]\nX_test = X[rand_rows[m_train:],:]\ny_test = y[rand_rows[m_train:]]","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"5ff64c75-60a5-4e23-a833-2d0f33c95614","_uuid":"2ac9763514a49190a4ed0b2d1985477578ecfb8c"},"outputs":[]},{"source":"datafiletest = '../input/test.csv'\ndatatest = pd.read_csv(datafiletest)\n\npickUpTime = pd.to_datetime(data['pickup_datetime'])\npickUpTimeTest = pd.to_datetime(datatest['pickup_datetime'])\ndata['pickup_date'] = pickUpTime.dt.date\ndatatest['pickup_date'] = pickUpTimeTest.dt.date\n\nplt.plot(data.groupby('pickup_date').count()[['id']], 'o-', label='train')\nplt.plot(datatest.groupby('pickup_date').count()[['id']], 'o-', label='test')\nplt.title('Train and test period complete overlap.')\nplt.legend(loc=0)\nplt.ylabel('number of records')\nplt.show()","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"9c89b574-4815-42ae-b10f-6af09dbeb658","_uuid":"9038164ae840c9093e7e671a0ad141ec707ec104"},"outputs":[]},{"source":"First Prediction with Linear Regression","cell_type":"markdown","metadata":{"_cell_guid":"67dd725f-68c3-44ef-8771-90607f08ded5","_uuid":"4577f67ca0172402374d795334adca4cae86e86e"}},{"source":"def RMSLE(estimator, X, y_true):\n    y_pred = estimator.predict(X)\n    n = y_pred.shape[0]\n    \n    for i in range(n):\n        if (y_pred[i]<0):\n            y_pred[i]=0\n        \n    return np.sqrt(sum((np.log(y_pred+1)-np.log(y_true+1))**2)/float(n))","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"01d048cd-f0c3-42cf-814e-71113aab2e68","_uuid":"331e3bf0ed14be07229ad0d5625348003fab9659"},"outputs":[]},{"source":"#===========================Linear Regression==========================#\nfrom sklearn.linear_model import Ridge\n\nalpha_range = np.linspace(0.0001,10,10)\n\nparam_grid = dict(alpha=alpha_range)\ncv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 42)\ngrid = GridSearchCV(Ridge(), scoring = RMSLE, param_grid = param_grid, cv = cv)\ngrid.fit(X_train,y_train)\n\nprint(\"The best parameters are %s with a score of %0.5f\"\n      % (grid.best_params_, grid.best_score_))\n\nprint(\"Score for linear ridge is %.5f\"%\n      (RMSLE(grid.best_estimator_,X_test,y_test)))","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"bc262f44-a916-496a-ac05-cdd6791c728f","_uuid":"7a59df6bfe051f4b40311792c8d5342e7a1b21fe"},"outputs":[]},{"source":"from sklearn.neural_network import MLPRegressor\n\nMLP_reg_clf = MLPRegressor(alpha=0.45, solver = 'lbfgs', hidden_layer_sizes=(5,4,3))\nMLP_reg_clf.fit(X_train, y_train)\n\n#alpha_range = np.linspace(0.001,0.5,5)\n\n#param_grid = dict(alpha=alpha_range)\n#cv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 42)\n#grid = GridSearchCV(MLPRegressor(solver = 'lbfgs', hidden_layer_sizes=(5)), scoring = RMSLE, param_grid = param_grid, cv = cv)\n#grid.fit(X,y)\n\n#print(\"The best parameters are %s with a score of %0.5f\"\n#      % (grid.best_params_, grid.best_score_))\n\nprint(\"Score for MLP_reg is %.5f\"%\n      (RMSLE(MLP_reg_clf,X_test,y_test)))","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"fa888ded-9755-4c15-859e-eea428a768e6","_uuid":"5644751bc85c97130cc830e2f138839828b90eab"},"outputs":[]},{"source":"Let's try muticlass classification. For that we need to split the prediction of times into classes. For that purpose, KMeans clustering is used.","cell_type":"markdown","metadata":{"_cell_guid":"97d723c1-6781-4d53-90b0-25e60f006a8f","_uuid":"34181b72c1f43c418be9e2be94025765fa0bb1c8"}},{"source":"from sklearn.cluster import MiniBatchKMeans\n\nn_clusters=200\nKMeans_clf = MiniBatchKMeans(n_clusters=n_clusters)\ny_clusters_indexes = KMeans_clf.fit_predict(np.reshape(y_tot, (y_tot.shape[0],1)))\ny_clusters_values = np.array([KMeans_clf.cluster_centers_[y_clusters_indexes[i]] \n                                for i in range(len(y_clusters_indexes))])\n\nprint(\"Comparison between original trip duration and clusters\")\nfig, axArray = plt.subplots(nrows=1,ncols=2,figsize=(8,5))\naxArray[0].hist(y_tot,n_clusters)\naxArray[0].set_xlabel('duration in sec');axArray[0].set_ylabel('Count')\naxArray[1].hist(y_clusters_values,n_clusters);axArray[1].set_xlabel('duration in sec')","execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"9bfe515f-c692-4549-a349-608cabfa9464","_uuid":"457f13faf1c68519ace45d6b325a06f06a4d61db"},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"_uuid":"24e87b8a3956628950a448bb6149a17d300a0cc7","_cell_guid":"039c75b4-eb64-4247-9edb-50834e95f31c","collapsed":true},"outputs":[]}]}