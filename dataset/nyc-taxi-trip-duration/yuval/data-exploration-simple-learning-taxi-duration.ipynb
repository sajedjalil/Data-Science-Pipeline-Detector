{"cells":[{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Get the data and save it in /data directory\n# ! kg config -c nyc-taxi-trip-duration\n# ! kg download\n#  ! mkdir data\n# ! mv test.zip data/test.zip\n# ! mv train.zip data/train.zip\n# ! mv sample_submission.zip data/sample_submission.zip\n# ! unzip -q data/test.zip -d data/\n# ! unzip -q data/train.zip -d data/\n# ! unzip -q data/sample_submission.zip -d data/","metadata":{"_cell_guid":"1694bd8c-d1f8-45d7-a494-5e6d1d55ac75","collapsed":true,"_uuid":"37b9a7bc6ffda12f6767d7371c2fe5f7d1c6beec"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"import os\nimport numpy as np\nimport pandas as pd","metadata":{"_cell_guid":"e22d6a59-14e3-429a-ab55-109d92497922","collapsed":true,"_uuid":"afe17ab327f71ecd40e88d459ff7cb8d595b9639"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"def distance(pos1, pos2, r = 3958.75):\n    pos1 = np.deg2rad(pos1)\n    pos2 = np.deg2rad(pos2)\n    cos_lat1 = np.cos(pos1[..., 0])\n    cos_lat2 = np.cos(pos2[..., 0])\n    cos_lat_d = np.cos(pos1[..., 0] - pos2[..., 0])\n    cos_lon_d = np.cos(pos1[..., 1] - pos2[..., 1])\n    return r * np.arccos(cos_lat_d - cos_lat1 * cos_lat2 * (1 - cos_lon_d))","metadata":{"_cell_guid":"aa88a326-7730-4bc9-ba1c-295325b72c23","collapsed":true,"_uuid":"a0fc400ebde16f49272e1d2f655c3496587eeafb"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Examine the data we got\ntrain_full = pd.read_csv('../input/train.csv') #pd.read_csv(\"data/train.csv\")\ntest = pd.read_csv('../input/test.csv') #pd.read_csv(\"data/test.csv\")\n\nprint('We have {} training rows and {} test rows.'.format(train_full.shape[0], test.shape[0]))\n\nprint('We have {} training columns and {} test columns.'.format(train_full.shape[1], test.shape[1]))\ntrain_full.head(2)\n","metadata":{"_cell_guid":"0ae3981f-140f-495a-999b-22d969b66259","_uuid":"b8d1f8ff75cab284d4a4a369ba75802c8d5a355c"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"print('Id is unique.' if train_full.id.nunique() == train_full.shape[0] else 'oops')\nprint('Train and test sets are distinct.' if len(np.intersect1d(train_full.id.values, test.id.values))== 0 else 'oops')\nprint('We do not need to worry about missing values.' if train_full.count().min() == train_full.shape[0] and test.count().min() == test.shape[0] else 'oops')\nprint('The vendor_id has only two values {}.'.format(str(set(train_full.vendor_id.unique()) | set(test.vendor_id.unique()))))\nprint('The store_and_fwd_flag has only two values {}.'.format(str(set(train_full.store_and_fwd_flag.unique()) | set(test.store_and_fwd_flag.unique()))))\n","metadata":{"_cell_guid":"dc0492f8-f309-44f4-833f-a45f0668b8d3","_uuid":"3e4d8daffe3301104d04a8f639bd7a23e747c459"}},{"cell_type":"markdown","source":"## Feature Engineering\n1. Remove ID, not helping us\n2. Switch 'store_and_fwd_flag' to a boolean feature\n3. Switch vendor_id to a boolean feature\n4. Add the distance (it's going to be a liner combination of the longitude and altitude) but might help for better understanding, Important not to remove the features we have, we will lose the place of the ride (might be that some areas are slower and some areas are faster)\n5. Instead of date - add time (to minute resolution) & week day features\n6. Add speed for train data","metadata":{"_cell_guid":"ce313d35-98d6-4699-b3b1-29753071488a","_uuid":"8ca7cc6b46d16fbd637df129876068d71b1d4831"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"def change_to_boolean(data):\n    data = data.drop(['id'], axis=1)\n    data['store_and_fwd_flag'] = pd.Series(\n        np.where(data.store_and_fwd_flag.values == 'Y', 1, 0), data.index)\n    data.vendor_id = pd.Series(np.where(data.vendor_id.values == 1, 1, 0), data.index)\n    data = data.rename(columns = {'vendor_id' : 'is_vendor_1'})\n    return data\n\ntrain_full = change_to_boolean(train_full)\ntest = change_to_boolean(test)","metadata":{"_cell_guid":"7f31390e-8c6e-4b55-875f-8124b1fae71b","collapsed":true,"_uuid":"0ee96711bd041108c28e4ea7efb6f91c323f86e2"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"def create_distance_metric(data):\n    pickup = np.column_stack((data.pickup_longitude.values, \n                              data.pickup_latitude.values))\n    dropoff = np.column_stack((data.dropoff_longitude.values, \n                               data.dropoff_latitude.values))\n    data['distance'] = distance(pickup, dropoff)\n    return data\n\ntrain_full = create_distance_metric(train_full)\ntest = create_distance_metric(test)","metadata":{"_cell_guid":"0f059a73-e690-4b36-92ca-40f141e14bb2","collapsed":true,"_uuid":"6683db943db044c26ca23b6f3c1a7b26e4cae0c4"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"def create_time_metric(data):\n    datetime_pickup = pd.to_datetime(data.pickup_datetime, infer_datetime_format=True)\n    data['pickup_time'] = datetime_pickup.dt.time.apply(lambda x: x.replace(second = 0))\n    data['pickup_day'] = datetime_pickup.dt.weekday\n    data['pickup_hour'] = datetime_pickup.dt.hour\n    return data\n    \n    \ntrain_full = create_time_metric(train_full)\ntest = create_time_metric(test)","metadata":{"_cell_guid":"e728e966-000a-427c-94d3-020003405b9d","collapsed":true,"_uuid":"6d6bed148c9f21d0cbb095dab06ef3fa5cd6d027"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"train_full['speed'] = np.round(train_full['distance'] / (train_full['trip_duration'] / (60*60)),2) # KM/H","metadata":{"_cell_guid":"b77e2c8c-f5e6-4c9c-80fa-c6cdbd8d451c","collapsed":true,"_uuid":"e5ead352433d0120f2c2d8b4c7be0191c77c9d17"}},{"cell_type":"markdown","source":"## Visualize the data","metadata":{"_cell_guid":"e4ca84c2-6344-4184-912e-f83b87742173","_uuid":"6a55feb26a427b4226abdbfb3b5e9f02e333ddec"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.hist(train_full.passenger_count, normed=True, bins=np.arange(1,np.max(train_full.passenger_count)) - 0.5)\n#plt.xticks(range(0,train_full.passenger_count))\nplt.title(\"passenger count\")\nplt.show()","metadata":{"_cell_guid":"a13966e1-ef0f-4c51-ad6d-affcf525a4a9","_uuid":"e92800743dade0ddb3aa0eea0ce4bf4a730a82eb"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"plt.hist(train_full.trip_duration, normed=True, \n         bins=range(int(np.percentile(train_full.trip_duration,1)),\n               int(np.percentile(train_full.trip_duration,99)), 60*5))\nplt.title(\"trip duration in (seconds)\")\nplt.show()","metadata":{"_cell_guid":"6130c1f8-f419-4d10-84e3-b65ad588b8b6","_uuid":"70bf2a3dedd591eb01281aca6e9749eed7c33429"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"plt.scatter(train_full.distance, train_full.trip_duration)\nplt.xlabel(\"Distance in KM\")\nplt.ylabel(\"Trip duration in sec\")\nplt.show()","metadata":{"_cell_guid":"49d92ffc-6302-469c-b2ed-49c6f02a5c19","_uuid":"582961627d090e120d736ec470414d790d648f48"}},{"cell_type":"markdown","source":"To many outliers, let's remove some of the points","metadata":{"_cell_guid":"38112638-5fdd-4d86-a74d-a0d11dca3ea7","_uuid":"e099a05615282825ee60501c6df9b13a0bc4a2c5"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"distance_time_no_outliers = np.column_stack((train_full.distance, train_full.trip_duration, train_full.pickup_hour))\ndistance_time_no_outliers = distance_time_no_outliers[distance_time_no_outliers[:,1] < np.percentile(distance_time_no_outliers[:,1], 99.9)]\ndistance_time_no_outliers = distance_time_no_outliers[distance_time_no_outliers[:,0] < np.percentile(distance_time_no_outliers[:,0], 99.9)]\n\nfig, ax = plt.subplots(ncols=2)\nax[0].scatter(distance_time_no_outliers[:,0], distance_time_no_outliers[:,1], s=1, alpha=0.1)\nax[0].set_xlabel(\"Distance in KM\")\nax[0].set_ylabel(\"Trip duration in sec\")\nax[1].scatter(distance_time_no_outliers[:,0], np.log(distance_time_no_outliers[:,1]), s=1, alpha=0.1,\n              c=distance_time_no_outliers[:,2], cmap=plt.get_cmap('jet'))\n#ax[1].set_xlabel(\"Distance in KM\")\nax[1].set_ylabel(\"log Trip duration in sec\")\n\nplt.show()","metadata":{"_cell_guid":"34cdc44d-0bf0-4710-bb95-1dd3c47f613a","collapsed":true,"_uuid":"8d021485532c4727c4590ffa34c1d9e9b0a880e8"}},{"cell_type":"markdown","source":"Out of the graph we see two things:\n1. Might be a problem with the data - plenty of points with distance 0 and trip duration > 0, and trips that their duration is 1 second\n2. The is no obvious connection between distance and trip duration ","metadata":{"_cell_guid":"01eea38b-10ea-446d-84db-d7f8637b9d83","_uuid":"c6ef2a6bc37ebf4c4c4a3f9afb1e077f892ab906"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"dates = pd.to_datetime(train_full.pickup_datetime, infer_datetime_format=True)\n\nfig, ax = plt.subplots(ncols=2, sharey=True)\nax[0].hist(dates.dt.hour, np.arange(24) - 0.5, normed=True, color=['red'], lw=2)\nax[1].hist(dates.dt.weekday, np.arange(8) - 0.5, normed=True, color=['green'], lw=2)\nax[0].set_xticks(range(0,24,3))\nax[1].set_xticks(range(0,7))\nax[0].set_xlabel('hour')\nax[1].set_xlabel('week day')\nax[0].set_ylabel('count')\n\nfig.show()","metadata":{"_cell_guid":"42515634-4db6-466a-bb30-10b18e66dddb","collapsed":true,"_uuid":"7aab082854b8a7ae28ffdeb3a392dced05c88831"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"plt.hist(train_full['speed'], range(0,int(np.ceil(np.percentile(train_full['speed'], 99.9)))),\n         normed=True)\nplt.title(\"Speed\")\nplt.show()","metadata":{"_cell_guid":"e096e856-45f6-4e0f-a7a7-127adad67f88","collapsed":true,"_uuid":"fd399830a583b88bb4c5d53bb3dfff96452e36c2"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Try to find the connection between speed and time of day\n# For that we need hour of week\ntrain_full['pickup_week_hour'] = train_full['pickup_day'] * 24 + pd.to_datetime(train_full.pickup_datetime, infer_datetime_format=True).dt.hour\n\n# Remove ourliers\nno_ourliers = train_full[train_full['speed'] > 0]\nno_ourliers = no_ourliers[no_ourliers['speed'] < np.percentile(no_ourliers['speed'], 99.9)]\n\nfig, ax = plt.subplots(ncols=2, sharey=True)\nax[0].plot(train_full.groupby('pickup_hour').mean()['speed'], lw=2)\nax[0].set_ylabel(\"avg speed\")\nax[0].set_xlabel(\"hour\")\nax[1].plot(train_full.groupby('pickup_week_hour').mean()['speed'], lw=2)\nax[1].set_xlabel(\"week hour\")\n\nax[0].set_xlim(0,24)\nax[1].set_xlim(0,7*24)\nfig.show()\n","metadata":{"_cell_guid":"adf147e4-2dd8-43ff-96aa-6ad7be23c638","collapsed":true,"_uuid":"e0e9d17cdddecef4b5275aa285d735d62ea27149"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Let's look at the origin and destantion frequancy\n\ndef plot_places(longitude, latitude, title):\n    #pickup_lat_bin = np.round(latitude, 3)\n    #pickup_long_bin = np.round(longitude, 3)\n    \n    longitude_limits = (np.percentile(longitude, 0.1), np.percentile(longitude, 99.0))\n    latitude_limits = (np.percentile(latitude, 0.1), np.percentile(latitude, 99.9))\n    \n    fig, ax = plt.subplots(ncols=1, nrows=1)\n    ax.set_title(title)\n    ax.scatter(longitude, latitude, color='black', s=1, alpha=0.5)\n\n    ax.set_xlim(longitude_limits)\n    ax.set_ylim(latitude_limits)\n    ax.set_xlabel('Longitude')\n    ax.set_ylabel('Latitude')\n    plt.show()\n\nplot_places(train_full.pickup_longitude.values, train_full.pickup_latitude.values, \"Pickup locations\")\nplot_places(train_full.dropoff_longitude.values, train_full.dropoff_latitude.values, \"Dropoff Locations\")","metadata":{"_cell_guid":"cde05aa6-5316-4a43-a5ef-a572745b8dd3","collapsed":true,"_uuid":"50dfa16dc1fa998238a2e0eb4c93daed74c5053f"}},{"cell_type":"markdown","source":"# Learn the data\nUsing very simple tools","metadata":{"_cell_guid":"8804a580-4df1-4e0d-bca9-c85b7b61f45b","_uuid":"d8bfaab2d17d79a4c86477c1cc655dfb30b8096f"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Split the train data into train and valid\nfrom sklearn.model_selection import train_test_split\ntrain, valid = train_test_split(train_full,test_size=0.2)\nprint(\"We have {} train rows, and {} test rows.\". format(train.shape[0], valid.shape[0]))","metadata":{"_cell_guid":"cc9cc474-6ab3-4b8d-8952-d2d5fee8d79d","collapsed":true,"_uuid":"232c674e5e0bf773d1cfe6daadd1e36fd991eb7b"}},{"cell_type":"markdown","source":"#### Linear Regression","metadata":{"_cell_guid":"0ab9f2b7-0da4-4ae6-97aa-d35832bf4f8c","_uuid":"651e795b408b414bdf527dc7ce597e40bb596ecf"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Look for linear regression between distance + time + day + origin ~ speed\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndef linear_regresion(x,y):\n    regr = linear_model.LinearRegression()\n    regr.fit(train[x], train[y])\n\n    y_pred = regr.predict(valid[x])\n\n    coef = regr.coef_.tolist()\n    coef.insert(0,regr.intercept_)\n    x.insert(0,\"intercept\")\n    print(\"X columns: {}\\n y columns: {}\\n\\n\".format(x,y))\n    # The coefficients\n    print(pd.DataFrame(list(zip(x, coef))))\n    # The mean squared error\n    print(\"Mean squared error: %.2f\"\n          % mean_squared_error(valid[y], y_pred))\n    # Explained variance score: 1 is perfect prediction\n    print('R2 squre: %.2f' % r2_score(valid[y], y_pred))\n    \nx = ['pickup_day','pickup_hour', 'distance', 'pickup_latitude', 'pickup_longitude', 'dropoff_longitude', 'dropoff_latitude']\nlinear_regresion(x, 'speed')","metadata":{"_cell_guid":"a3672bf2-d98d-455e-a38e-15712c517832","collapsed":true,"_uuid":"c6ab49d2daf13959015a389368178769bad4668e"}},{"cell_type":"markdown","source":"We got very bad results.\nThe most suprising thing is that the pickup latitude is the most importnat parameter and we will need to check why, my first hypotsis is that their are locations that the speed is much slower/faster their, the problem with this hypotsis is that we will excpect also the dropoff to be so strong...\nThe seconds surprising thing, is that the day & hour doesn't seem to be so much predictive, let's tree to find if we remove the location we get better results (maybe the location interferes in some way) ","metadata":{"_cell_guid":"20dbff29-ed74-464c-afda-96d1cc3b36b7","_uuid":"651876839843aa95cec7b0ad3db9620bf645be5d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"x = ['pickup_day','pickup_hour', 'distance']\nlinear_regresion(x, 'speed')","metadata":{"_cell_guid":"a0833964-b757-47a0-8803-f0a5b8e2fa57","collapsed":true,"_uuid":"9f9a34b314949b2337e6d8b06aaf11103bc4cdc4"}},{"cell_type":"markdown","source":"#### Decision Tree","metadata":{"_cell_guid":"30d3ef57-ed0d-4758-882c-6d7ec15f2f1b","_uuid":"364517bd73f0d376baf06c500a18261bcc6479c4"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# First group the trip duration into 10 groups (equal size) and tree to use a decision tree to predict \ngroups = train_full['trip_duration'].quantile(np.arange(0.0, 1.0, 0.05))\ndef get_duration_group(data):\n    data.loc[:, 'duration_group'] =data.loc[:, 'trip_duration'].apply(lambda x: np.where(x >= groups)[0][-1]) \n    return data\n\ntrain = get_duration_group(train)\nvalid = get_duration_group(valid)","metadata":{"_cell_guid":"ba3ea5b2-bdfb-4b94-9994-e3a5543e1b8f","collapsed":true,"_uuid":"3702723cec7713e2d627e1acd584594dec7eac25"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Create the tree and predict the validation set\nfrom sklearn import tree\n\nclf = tree.DecisionTreeClassifier()\nx = ['pickup_day','pickup_hour', 'distance', 'pickup_latitude', 'pickup_longitude', 'dropoff_longitude', 'dropoff_latitude']\n#x = ['pickup_day','pickup_hour', 'distance']\nclf = clf.fit(train[x], train['duration_group'])\ny_pred = clf.predict(valid[x])","metadata":{"_cell_guid":"21978536-5089-4fd1-98a1-93df0b20a3ec","collapsed":true,"_uuid":"61cca69e940215e8a0f9e2984c5811f22f1c355d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"# Look at the results\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error\nprint(\"The accuracy score is: {}\". format(accuracy_score(valid['duration_group'], y_pred)))\nprint(\"The loss (MSE) for the groups is: {}\". format(mean_squared_error(valid['duration_group'], y_pred)))\n\n# For each group get the average duration and calcualte the loss\ngroup_duration = [(groups.values[i] + groups.values[i+1]) / 2 for i in range(len(groups)-1)]\nduration_pred = np.copy(y_pred)\nfor i in range(len(group_duration)):\n    duration_pred[duration_pred == i] = group_duration[i]\n\nprint(\"The loss (MSE) for the trip duration: {}\". format(mean_squared_error(valid['trip_duration'], duration_pred)))\n\ncm = confusion_matrix(valid['duration_group'], y_pred)\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nplt.matshow(cm)\nplt.colorbar()\nplt.title('Confusion Matrix Normalized')\nplt.show()","metadata":{"_cell_guid":"2be88fb7-2de7-4f25-b952-c15fb5084af3","collapsed":true,"_uuid":"3e1f7ebc6a40d3d0922cfe8a81bd7c1af6dfb313"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":"clf.tree_.node_count","metadata":{"_cell_guid":"34a153de-092a-40b5-81cc-0d6c7ac0ea0c","collapsed":true,"_uuid":"0ac7c0a451c607d22d4a2d3be81a3b5bcbacecc6"}}],"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":1}