{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"name":"python"}},"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"045aaf43189604d7e6e5358b9118a87c6f6a4a3d","_cell_guid":"b3efb3c3-072d-41ea-a3c4-164a4f52970a"},"source":"This is a simple implementation of the Xgboost using kfold cross validation. With a few minor tweaks, I have been able to use this implementation to score 0.3674 on the leaderboard. \n\nI encourage all the participants to fork this notebook and make their adjustments as they please to better adjust the error. "},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"8eb85edb33881d6b1579ade62564169bb2c29088","_cell_guid":"f36534af-2d91-4915-be92-02db57d13d12"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import timedelta\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import MiniBatchKMeans\nimport datetime as dt\n\n# Any results you write to the current directory are saved as output.","execution_count":1},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"17477f473d0ee1cd3e7a3a6690e143d4e1ac0ba5","_cell_guid":"0d102856-b123-458b-8ee0-4c669d6dd868"},"outputs":[],"source":"t0 = dt.datetime.now()\ntrain = pd.read_csv('../input/nyc-taxi-trip-duration/train.csv')\ntest = pd.read_csv('../input/nyc-taxi-trip-duration/test.csv')\nsample_submission = pd.read_csv('../input/nyc-taxi-trip-duration/sample_submission.csv')\ntest_1 = test.copy()","execution_count":2},{"cell_type":"markdown","metadata":{"_uuid":"0a5ab9e48951520ee44c2f74974293a98fadce2f","_cell_guid":"78e50c7a-2f20-42ef-a4bd-36f7cd07aa2e"},"source":"### Feature Engineering"},{"cell_type":"markdown","metadata":{"_uuid":"a93d78252699cb1005dc6c4498e1b808192fc199","_cell_guid":"d4f7b603-e426-48cf-94fd-b2c23cbc3281"},"source":"A lot of the features have been extracted using existing models, especially the model of \"beluga\" (Cheers, mate). I also tried using the weather information as a variable but it seems that they do not serve so much of a useful purpose as far the accuracy of the result is concerned. Perhaps, I would use some sort of ensemble learning later to calculate feature importance of variables"},{"cell_type":"markdown","metadata":{"_uuid":"5e31687f59b4eef4ebe035745136e2d0e7254cdd","_cell_guid":"07b21106-6830-4edf-8d9b-169d9844f0f9"},"source":"### Conversion of DATETIME Features"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"af2910dee892104cde38824fdeb1a0134671be9a","_cell_guid":"8d9e894f-d692-4880-b47a-34a04d84ec9f"},"outputs":[],"source":"train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\ntrain.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\ntest.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\ntrain['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\n","execution_count":3},{"cell_type":"markdown","metadata":{"_uuid":"f1c4e5c16586ce84c5cc855e145686592b5fdad6","_cell_guid":"dd60678a-0d60-458a-a1f3-1fd681b91535"},"source":"### DateTime Features"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"bc96e37d272431d3b8cb52663f024a460b3da046","_cell_guid":"8b075e7a-30db-40a2-b337-40a55820f514"},"outputs":[],"source":"train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\ntrain.loc[:, 'pickup_hour_weekofyear'] = train['pickup_datetime'].dt.weekofyear\ntrain.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\ntrain.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\ntrain.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntrain.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n\ntest.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\ntest.loc[:, 'pickup_hour_weekofyear'] = test['pickup_datetime'].dt.weekofyear\ntest.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\ntest.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\ntest.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntest.loc[:, 'pickup_week_hour'] = test['pickup_weekday'] * 24 + test['pickup_hour']\n\ntrain.loc[:, 'pickup_dayofyear'] = train['pickup_datetime'].dt.dayofyear\ntest.loc[:,'pickup_dayofyear'] = test['pickup_datetime'].dt.dayofyear","execution_count":4},{"cell_type":"markdown","metadata":{"_uuid":"c77508b1859beec9b7de39b47af9bc13f53a7a7d","_cell_guid":"75ba15bd-aa92-41c6-8068-a02718a260ba"},"source":"### Bearing Feature"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"c84ffec14bc8d87023e7528682c733a9877ed947","_cell_guid":"9643a807-df80-4794-b709-0afc6babf33d"},"outputs":[],"source":"def bearing_array(lat1, lng1, lat2, lng2):\n    AVG_EARTH_RADIUS = 6371  # in km\n    lng_delta_rad = np.radians(lng2 - lng1)\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    y = np.sin(lng_delta_rad) * np.cos(lat2)\n    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n    return np.degrees(np.arctan2(y, x))\n\ntrain.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values, train['pickup_longitude'].values, \n                                          train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n\ntest.loc[:, 'direction'] = bearing_array(test['pickup_latitude'].values, test['pickup_longitude'].values, \n                                         test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n","execution_count":5},{"cell_type":"markdown","metadata":{"_uuid":"9b5a68218fdc2852fa69e2bf40ef3cac476f9fe2","_cell_guid":"7dbabcde-8ad5-4d7d-ae73-32f7c817e83f"},"source":"### Distance Calculation"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"19cc8a3a2d4b2dd73ad42606e49fa5afa9da5ada","_cell_guid":"e19d9a92-46ca-4f93-be0a-befbf7eb4d60"},"outputs":[],"source":"def haversine_array(lat1, lng1, lat2, lng2):\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    AVG_EARTH_RADIUS = 6371  # in km\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n    return h\n\ndef dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n    a = haversine_array(lat1, lng1, lat1, lng2)\n    b = haversine_array(lat1, lng1, lat2, lng1)\n    return a + b\n\ntrain.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\ntrain.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n\n\ntest.loc[:, 'distance_haversine'] = haversine_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\ntest.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n\n\n\ntrain.loc[:, 'center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2\ntrain.loc[:, 'center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\ntest.loc[:, 'center_latitude'] = (test['pickup_latitude'].values + test['dropoff_latitude'].values) / 2\ntest.loc[:, 'center_longitude'] = (test['pickup_longitude'].values + test['dropoff_longitude'].values) / 2","execution_count":6},{"cell_type":"markdown","metadata":{"_uuid":"5d31acbed3c2a215e724bdb593c815b438a950cd","_cell_guid":"81a5a79e-9bbb-4c4f-89c7-ef738fe569c8"},"source":"### PCA Features"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"f9c3ce5c5d4b25607b72230005f17a769f67d6e1","_cell_guid":"b8f5e474-bfd0-4d4f-ab91-5443cb4db66b"},"outputs":[],"source":"coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n                    train[['dropoff_latitude', 'dropoff_longitude']].values,\n                    test[['pickup_latitude', 'pickup_longitude']].values,\n                    test[['dropoff_latitude', 'dropoff_longitude']].values))\n\npca = PCA().fit(coords)\n","execution_count":7},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"a7de9daaaffa4a8be6f0836a21ebbf125d1173fa","_cell_guid":"4b78ff78-6242-4ef8-9ac4-cd3e30735109"},"outputs":[],"source":"train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntrain['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntrain['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntrain['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\ntest['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntest['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntest['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntest['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n\ntrain.loc[:, 'pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + np.abs(train['dropoff_pca0'] - train['pickup_pca0'])\ntest.loc[:, 'pca_manhattan'] = np.abs(test['dropoff_pca1'] - test['pickup_pca1']) + np.abs(test['dropoff_pca0'] - test['pickup_pca0'])","execution_count":8},{"cell_type":"markdown","metadata":{"_uuid":"d68f565f24ca1a7f12f078b1e4600d2ef583b6e7","_cell_guid":"792caa6b-7f88-4f3d-818e-619a468500e9"},"source":"### Clustering Features"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"47457f290b2eca9e1e2d435b2223bf3c1173197a","_cell_guid":"d64dcf59-fc8d-4fd0-9d40-15892b822c3e"},"outputs":[],"source":"sample_ind = np.random.permutation(len(coords))[:500000]\nkmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind])","execution_count":9},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"a1540023c5ecc7f240e7715b01ef0fc08163d5d1","_cell_guid":"e824f392-eaff-40ef-b9af-b1a31639f39d"},"outputs":[],"source":"train.loc[:, 'pickup_cluster'] = kmeans.predict(train[['pickup_latitude', 'pickup_longitude']])\ntrain.loc[:, 'dropoff_cluster'] = kmeans.predict(train[['dropoff_latitude', 'dropoff_longitude']])\ntest.loc[:, 'pickup_cluster'] = kmeans.predict(test[['pickup_latitude', 'pickup_longitude']])\ntest.loc[:, 'dropoff_cluster'] = kmeans.predict(test[['dropoff_latitude', 'dropoff_longitude']])\nt1 = dt.datetime.now()","execution_count":10},{"cell_type":"markdown","metadata":{"_uuid":"4e28d19de914f1f01c7ea41092f67bbae91b1723","_cell_guid":"974af378-c328-451e-8486-981bbefb4464"},"source":"## OSRM Data"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"58fb8a1e16365bc25d49a9bace100e9fa52f5a93","_cell_guid":"1528dc60-522a-4099-a43c-56c95a48a1d5"},"outputs":[],"source":"fr1 = pd.read_csv('../input/new-york-city-taxi-with-osrm/fastest_routes_train_part_1.csv', usecols=['id', 'total_distance', 'total_travel_time',  'number_of_steps', ])\nfr2 = pd.read_csv('../input/new-york-city-taxi-with-osrm//fastest_routes_train_part_2.csv', usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps'])\ntest_street_info = pd.read_csv('../input/new-york-city-taxi-with-osrm//fastest_routes_test.csv',\n                               usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps'])","execution_count":11},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"8c826a60648eb0fe472053a0ab7c9f174acbe393","_cell_guid":"f97fd3f7-d09a-49f3-bd1c-dc60f8f145e3"},"outputs":[],"source":"train_street_info = pd.concat((fr1, fr2))\ntrain = train.merge(train_street_info, how='left', on='id')\ntest = test.merge(test_street_info, how='left', on='id')","execution_count":12},{"cell_type":"markdown","metadata":{"_uuid":"22dacde008108af2f8338f22c7274bd6e46ee9d5","_cell_guid":"01b39919-6cf9-4e6b-b89b-142fefa0951a"},"source":"### Features Checking"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"58890cbea7cf342b0d8ef86a72fb7a7494ff99cb","_cell_guid":"53508e1f-93b8-4334-a650-a07fee6ed34d"},"outputs":[],"source":"train['log_trip_duration'] = np.log(train['trip_duration'].values + 1)","execution_count":13},{"cell_type":"code","metadata":{"_uuid":"0e8dd8ae20a18b43a10f4b699ef90ff1b5ee84ef","_cell_guid":"7a6b2d5f-839a-4d47-8143-9134910305e5"},"outputs":[],"source":"feature_names = list(train.columns)\nprint(np.setdiff1d(train.columns, test.columns))\n","execution_count":14},{"cell_type":"code","metadata":{"_uuid":"4c093fa09204f16673e47185ffec3b6eeb40153f","_cell_guid":"afa61e1c-97d4-4eac-b2cf-516228b4f50a"},"outputs":[],"source":"do_not_use_for_training = ['id', 'log_trip_duration', 'trip_duration', 'dropoff_datetime', 'pickup_date', \n                           'pickup_datetime', 'date']\nfeature_names = [f for f in train.columns if f not in do_not_use_for_training]\n# print(feature_names)\nprint('We have %i features.' % len(feature_names))\ntrain[feature_names].count()\n         ","execution_count":15},{"cell_type":"markdown","metadata":{"_uuid":"f8877c9ad4516368e7478859128129761cddfb86","_cell_guid":"bae6ed5e-8248-45df-a234-7e01e37c576f"},"source":"### Features Encoding "},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"3bd1df273eb279576655d5ff1a4fcbb1c8a53161","_cell_guid":"46e34e19-cad9-4db9-bfd5-0101c23b41d4"},"outputs":[],"source":"train['store_and_fwd_flag'] = train['store_and_fwd_flag'].map(lambda x: 0 if x == 'N' else 1)","execution_count":16},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"396b0e0ef56a83c4daf3b780567c584a58277fed","_cell_guid":"5e79ef29-bc6a-4192-b12b-18b57c1e5494"},"outputs":[],"source":"test['store_and_fwd_flag'] = test['store_and_fwd_flag'].map(lambda x: 0 if x == 'N' else 1)","execution_count":17},{"cell_type":"markdown","metadata":{"collapsed":true,"_uuid":"4fb025c09b99834da9c821c7d264a75bcb893a41","_cell_guid":"c2f874be-410a-4a01-b0c4-4a66b876b95c"},"source":"### K Fold Cross Validation"},{"cell_type":"code","metadata":{"_uuid":"0578f508d5331705c0ae8ad74e044721384e2dbe","_cell_guid":"72715a79-e072-448a-82db-b91171414a1b"},"outputs":[],"source":"from sklearn.model_selection import KFold\n\nX = train[feature_names].values\ny = np.log(train['trip_duration'].values + 1)  \n\n\nkf = KFold(n_splits=10)\nkf.get_n_splits(X)\n\nprint(kf)  \n\nKFold(n_splits=10, random_state=None, shuffle=False)\nfor train_index, test_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    \n ","execution_count":18},{"cell_type":"markdown","metadata":{"collapsed":true,"_uuid":"8c9322eb02ff71a5d176df71950925f7ef66b337","_cell_guid":"c5537638-11a3-4997-8a9c-6d3e0896bbc1"},"source":"### XgBoost Implementation"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"537c3ded92f5ecf30d640b58242c2bb60a3b254a","_cell_guid":"3a7793c4-6fd9-41a9-97eb-682f35074207"},"outputs":[],"source":"   \ndtrain = xgb.DMatrix(X_train, label=y_train)\ndvalid = xgb.DMatrix(X_test, label=y_test)\ndtest = xgb.DMatrix(test[feature_names].values)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n\n# Try different parameters! My favorite is random search :)\nxgb_pars = {'min_child_weight': 10, 'eta': 0.04, 'colsample_bytree': 0.8, 'max_depth': 15,\n            'subsample': 0.75, 'lambda': 2, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1, 'gamma' : 0,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}    ","execution_count":null},{"cell_type":"code","metadata":{"_uuid":"54d6183828377cd842ba6aa7a8bde18a34f6db4d","_cell_guid":"c44a7935-7873-4f3b-8233-e18616ddf73b"},"outputs":[],"source":"model = xgb.train(xgb_pars, dtrain, 500, watchlist, early_stopping_rounds=250,\n                  maximize=False, verbose_eval=15)","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"da3471a9cf011c5b5fd1d899ef2634068da9c88c","_cell_guid":"1e44ac42-43ad-430c-8cab-f6ba4a053f08"},"outputs":[],"source":"ytest = model.predict(dtest)","execution_count":null},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"dafbc838ec6ee8ba604b2c3c774bbd1079becbf1","_cell_guid":"6e15204d-cb84-4e80-9615-2671de8b5e60"},"outputs":[],"source":"print('Test shape OK.') if test.shape[0] == ytest.shape[0] else print('Oops')\ntest['trip_duration'] = np.exp(ytest) - 1\ntest[['id', 'trip_duration']].to_csv('xgb_submission.csv.gz', index=False, compression='gzip')\n\nprint('Valid prediction mean: %.3f' % ypred.mean())\nprint('Test prediction mean: %.3f' % ytest.mean())\n\nfig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\nsns.distplot(ypred, ax=ax[0], color='red', label='validation prediction')\nsns.distplot(ytest, ax=ax[1], color='blue', label='test prediction')\nax[0].legend(loc=0)\nax[1].legend(loc=0)\nplt.show()\n\nt1 = dt.datetime.now()\nprint('Total time: %i seconds' % (t1 - t0).seconds)","execution_count":null}],"nbformat_minor":1}