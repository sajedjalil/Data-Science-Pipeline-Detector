{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport geopandas as gpd\nimport datetime\nimport lightgbm as lgbm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error as mse\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport os\n        \nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load files\n* All the files used are as per below\n> * fastest_routes_ files \n>> * Provides the shortest path from pickup point to dropoff point. \n>> * This file is from https://www.kaggle.com/oscarleo/new-york-city-taxi-with-osrm\n> * train/test pickup/dropoff files \n>> * Provides the city and county information from the pickup and dropoff points. \n>> * This file is created by myself with New York shapefiles from https://www.kaggle.com/jackcook/neighborhoods-in-new-york\n> * Weather files \n>> * Provides the hourly weather of New York. This file is from https://www.kaggle.com/selfishgene/historical-hourly-weather-data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/nyc-taxi-trip-duration/train.zip', compression='zip')\ntest_df = pd.read_csv('/kaggle/input/nyc-taxi-trip-duration/test.zip', compression='zip') \ntrain_fastroute_df = pd.concat((pd.read_csv('/kaggle/input/osrm-oscarleo/fastest_routes_train_part_1.csv'), pd.read_csv('/kaggle/input/osrm-oscarleo/fastest_routes_train_part_2.csv')), axis = 0).reset_index(drop = True)\ntest_fastroute_df= pd.read_csv('/kaggle/input/osrm-oscarleo/fastest_routes_test.csv')\nny_shape_df = gpd.read_file('/kaggle/input/neighborhoods-in-new-york/ZillowNeighborhoods-NY.shp')\nremain_train_pickup_df = pd.concat((pd.read_csv('/kaggle/input/nyc-tax-train-test-remain-2/train_city_pickup.csv'), pd.read_csv('/kaggle/input/nyc-tax-train-test-remain/train_city_pickup.csv')), axis = 0)\nremain_train_dropoff_df = pd.concat((pd.read_csv('/kaggle/input/nyc-tax-train-test-remain-2/train_city_dropoff.csv'), pd.read_csv('/kaggle/input/nyc-tax-train-test-remain/train_city_dropoff.csv')), axis = 0)\nremain_test_pickup_df = pd.concat((pd.read_csv('/kaggle/input/nyc-tax-train-test-remain-2/test_city_pickup.csv'), pd.read_csv('/kaggle/input/nyc-tax-train-test-remain/test_city_pickup.csv')), axis = 0)\nremain_test_dropoff_df = pd.concat((pd.read_csv('/kaggle/input/nyc-tax-train-test-remain-2/test_city_dropoff.csv'), pd.read_csv('/kaggle/input/nyc-tax-train-test-remain/test_city_dropoff.csv')), axis = 0)\n\ntemperature_df = pd.read_csv('/kaggle/input/historical-hourly-weather-data/temperature.csv')\nhumidity_df = pd.read_csv('/kaggle/input/historical-hourly-weather-data/humidity.csv')\nwind_speed_df = pd.read_csv('/kaggle/input/historical-hourly-weather-data/wind_speed.csv')\nwind_direction_df = pd.read_csv('/kaggle/input/historical-hourly-weather-data/wind_direction.csv')\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functions and Utility Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_df_date_hour(df, string):\n    \"\"\" \n    Utility function to add 'pickup_date' amd 'pickup_hour' for weather data.\n    \"\"\"\n    \n    df['pickup_date'] =  pd.to_datetime(df['datetime']).dt.date\n    df['pickup_hour'] = pd.to_datetime(df['datetime']).dt.hour\n    return df[['pickup_date', 'pickup_hour', 'New York']].rename(columns = {'New York' : string})\n\ndef get_haversine_distance(lat_1, long_1, lat_2, long_2):\n    \"\"\"\n    Calculate the distance of 2 points with consideration of the roundness of earth.\n    \"\"\"\n    \n    AVG_EARTH_RADIUS = 6371\n    lat_1, long1, lat_2, long_2 = map(np.radians, (lat_1, long_1, lat_2, long_2))\n    lat = lat_2 - lat_1 ; long = long_2 - long_1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat_1) * np.cos(lat_2) * np.sin(long * 0.5) ** 2\n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n    return h\n\ndef get_direction(lat_1, long_1, lat_2, long_2):\n    \"\"\"\n    Calculates the angle or direction of 2 points with consideration of the roundness of earth.\n    \"\"\"\n    \n    AVG_EARTH_RADIUS = 6371  # in km\n    long_delta_rad = np.radians(long_2 - long_1)\n    lat_1, long_1, lat_2, long_2 = map(np.radians, (lat_1, long_1, lat_2, long_2))\n    y = np.sin(long_delta_rad) * np.cos(lat_2)\n    x = np.cos(lat_1) * np.sin(lat_2) - np.sin(lat_1) * np.cos(lat_2) * np.cos(long_delta_rad)\n    \n    return np.degrees(np.arctan2(y, x))\n\ndef map_dic_to_dic(dic_1, dic_2):\n    \"\"\"\n    Util function to map dictionary to dictionary\n    \"\"\"\n    \n    return {k : dic_2[v] for k, v in dic_1.items() if v in dic_2.keys()}\n\ndef merge_location_df(df, fastroute_df, pickup_df, dropoff_df):\n    \"\"\"\n    Utility function to merge fastroute df and city/county information from pickup and dropoff points.\n    \"\"\"\n    \n    df = df.merge(fastroute_df, on = 'id')\n    df = df.merge(pickup_df[['id', 'pickup_city']], on = 'id', how = 'left')\n    df = df.merge(dropoff_df[['id', 'dropoff_city']], on = 'id', how = 'left')\n    \n    return df\n\ndef merge_weather_df(df, temp_df, hum_df, ws_df, wd_df):\n    \"\"\"\n    Utilty function to merge weather dataframes.\n    \"\"\"\n    \n    df = df.merge(temp_df, on = ['pickup_date', 'pickup_hour'], how = 'left')\n    df = df.merge(hum_df, on = ['pickup_date', 'pickup_hour'], how = 'left')\n    df = df.merge(ws_df, on = ['pickup_date', 'pickup_hour'], how = 'left')\n    df = df.merge(wd_df, on = ['pickup_date', 'pickup_hour'], how = 'left')\n    \n    return df\n\ndef map_df_to_dic(df, dic, cols):\n    \"\"\"\n    Utility function to map dataframe to dictionary.\n    \"\"\"\n    \n    for k, v in cols.items():\n        df[k] = df[v].map(dic)\n    return df\n\ndef data_preprocessing(df):\n    \"\"\"\n    Data preprocessing for New York Taxi Trip Duration.\n    \"\"\"\n    #Geographical features\n    df['pickup_dropoff_same_county'] = 0\n    df.loc[df['pickup_county'] == df['dropoff_county'], 'pickup_dropoff_same_county'] = 1\n    df['pickup_dropoff_same_city'] = 0\n    df.loc[df['pickup_city'] == df['dropoff_city'], 'pickup_dropoff_same_city'] = 1\n\n    #Type of Route features\n    df['f_road_count'] = df['street_for_each_step'].str.count('Road')\n    df['f_street_count'] = df['street_for_each_step'].str.count('Street')\n    df['f_drive_count'] = df['street_for_each_step'].str.count('Drive')\n    df['f_avenue_count'] = df['street_for_each_step'].str.count('Avenue')\n    df['f_plaza_count'] = df['street_for_each_step'].str.count('Plaza')\n    df['f_square_count'] = df['street_for_each_step'].str.count('Square')\n    df['f_parkway_count'] = df['street_for_each_step'].str.count('Parkway')\n    df['f_boulevard_count'] = df['street_for_each_step'].str.count('Boulevard')\n    df['f_expressway_count'] = df['street_for_each_step'].str.count('Expressway')\n\n    df['f_left_count'] = df['step_direction'].str.count('left')\n    \n    #google the most congested expressway\n    congested_expressways = ['Brooklyn Queens Expressway', 'Cross Bronx Expressway', 'Van Wyck Expressway', 'Long Island Expressway']\n    df['in_congested_expressways'] = df['street_for_each_step'].apply(lambda x: 1 if any(way in x for way in congested_expressways) else 0)\n    \n    #google tourist attraction places\n    tourist_attractions = ['Financial District', 'Little Italy', 'Chinatown', 'Tribeca', 'SoHo', 'Lower East Side', 'Greenwich Village', 'Flatiron District', \n                           'Chelsea', 'The Garment District', 'Hell Kitchen', 'Broadway', 'Times Square', 'Fifth Avenue', 'Central Park', 'Upper East', \n                           'West Sides', 'Harlem', \n                           'Gramercy', 'Union Square', 'Union Square Park', 'Lower East Side', 'East Village', 'Inwood', 'Upper West Side', 'Upper East Side', 'Midtown',\n                          'West Village', 'Central Park', 'East Harlem', 'DUMBO']\n\n    # Time Features\n    df['pickup_hour'] = pd.to_datetime(df['pickup_datetime']).dt.hour\n    df['pickup_min'] = pd.to_datetime(df['pickup_datetime']).dt.minute\n    df['pickup_day'] = pd.to_datetime(df['pickup_datetime']).dt.day\n    df['pickup_date'] = pd.to_datetime(df['pickup_datetime']).dt.date\n    df['pickup_time'] = df['pickup_hour'] + (df['pickup_min'] / 60)\n    df['pickup_dayofweek'] = pd.to_datetime(df['pickup_datetime']).dt.dayofweek\n    df['pickup_weekday'] = 0\n    df.loc[df['pickup_dayofweek'].isin([0, 1, 2, 3, 4]), 'pickup_weekday'] = 1\n\n    #Geographical Features\n    df['pickup_tourist_area'] = 0\n    df.loc[df['pickup_city'].isin(tourist_attractions), 'pickup_tourist_area'] = 1\n\n    df['dropoff_tourist_area'] = 0\n    df.loc[df['dropoff_city'].isin(tourist_attractions), 'dropoff_tourist_area'] = 1\n\n    df['second_last_street'] = df['street_for_each_step'].str.split('|').str[-1]\n    df['second_first_street'] = df['street_for_each_step'].str.split('|').str[1]\n    \n    df['displacement'] = get_haversine_distance(df['pickup_latitude'], df['pickup_longitude'], df['dropoff_latitude'], df['dropoff_longitude'])\n    df['direction'] = get_direction(df['pickup_latitude'], df['pickup_longitude'], df['dropoff_latitude'], df['dropoff_longitude'])\n\n    return df \n\ndef agggregate_processing(train, test):\n    \"\"\"\n    Data aggregation process on both train and test dataset for New York Taxi Trip Duration.\n    \"\"\"\n    #Rotated features from PCA\n    coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n                        train[['dropoff_latitude', 'dropoff_longitude']].values,\n                        test[['pickup_latitude', 'pickup_longitude']].values,\n                        test[['dropoff_latitude', 'dropoff_longitude']].values))\n\n    pca = PCA().fit(coords)\n    train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\n    train['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\n    train['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n    train['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n    test['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\n    test['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\n    test['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n    test['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n\n    #Encoding non-numerical features\n    label_encoder = LabelEncoder()\n    label_features = ['dropoff_city', 'dropoff_county', 'end_street', 'second_last_street', 'pickup_city', 'pickup_county', 'starting_street', \n                      'second_first_street', 'store_and_fwd_flag']\n\n    big_df = pd.concat((train, test), axis = 0, sort = True)\n    train_len = train.shape[0]\n\n    for label_feature in label_features:\n        big_df[label_feature].fillna('-99', inplace = True)\n        big_df[label_feature] = label_encoder.fit_transform(big_df[label_feature].values)\n\n    #Count Features based on date, time and geographical features\n    count_dropoff_city_df = pd.DataFrame(big_df.groupby(['pickup_date', 'pickup_hour', 'dropoff_city'])['passenger_count'].count()).reset_index().rename(columns = {'passenger_count' : 'count_dropoff_city'})\n    count_pickup_city_df = pd.DataFrame(big_df.groupby(['pickup_date', 'pickup_hour', 'pickup_city'])['passenger_count'].count()).reset_index().rename(columns = {'passenger_count' : 'count_pickup_city'})\n    count_dropoff_county_df = pd.DataFrame(big_df.groupby(['pickup_date', 'pickup_hour', 'dropoff_county'])['passenger_count'].count()).reset_index().rename(columns = {'passenger_count' : 'count_dropoff_county'})\n    count_pickup_county_df = pd.DataFrame(big_df.groupby(['pickup_date', 'pickup_hour', 'pickup_county'])['passenger_count'].count()).reset_index().rename(columns = {'passenger_count' : 'count_pickup_county'})\n\n    count_pickup_start_street_df = pd.DataFrame(big_df.groupby(['pickup_date', 'pickup_hour', 'starting_street'])['passenger_count'].count()).reset_index().rename(columns = {'passenger_count' : 'count_pickup_street'})\n    count_pickup_start_sec_street_df = pd.DataFrame(big_df.groupby(['pickup_date', 'pickup_hour', 'second_first_street'])['passenger_count'].count()).reset_index().rename(columns = {'passenger_count' : 'count_pickup_sec_street'})\n\n    count_pickup_end_street_df = pd.DataFrame(big_df.groupby(['pickup_date', 'pickup_hour', 'end_street'])['passenger_count'].count()).reset_index().rename(columns = {'passenger_count' : 'count_dropoff_street'})\n    count_pickup_end_sec_street_df = pd.DataFrame(big_df.groupby(['pickup_date', 'pickup_hour', 'second_last_street'])['passenger_count'].count()).reset_index().rename(columns = {'passenger_count' : 'count_dropoff_sec_street'})\n\n    big_df = big_df.merge(count_dropoff_county_df, on = ['pickup_date', 'pickup_hour', 'dropoff_county'], how = 'left')\n    big_df = big_df.merge(count_pickup_county_df, on = ['pickup_date', 'pickup_hour', 'pickup_county'], how = 'left')\n    big_df = big_df.merge(count_dropoff_city_df, on = ['pickup_date', 'pickup_hour', 'dropoff_city'], how = 'left')\n    big_df = big_df.merge(count_pickup_city_df, on = ['pickup_date', 'pickup_hour', 'pickup_city'], how = 'left')\n\n    big_df = big_df.merge(count_pickup_start_street_df, on = ['pickup_date', 'pickup_hour', 'starting_street'], how = 'left')\n    big_df = big_df.merge(count_pickup_start_sec_street_df, on = ['pickup_date', 'pickup_hour', 'second_first_street'], how = 'left')\n    big_df = big_df.merge(count_pickup_end_street_df, on = ['pickup_date', 'pickup_hour', 'end_street'], how = 'left')\n    big_df = big_df.merge(count_pickup_end_sec_street_df, on = ['pickup_date', 'pickup_hour', 'second_last_street'], how = 'left')\n    \n    train = big_df.iloc[:train.shape[0]]\n    test = big_df.iloc[train.shape[0]:]\n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Main processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"temperature_df = add_df_date_hour(temperature_df, 'temperature')\nhumidity_df = add_df_date_hour(humidity_df, 'humidity')\nwind_speed_df = add_df_date_hour(wind_speed_df, 'wind_speed')\nwind_direction_df = add_df_date_hour(wind_direction_df, 'wind_direction')\n\nmaster_county_dict = {}\nmaster_county_dict.update(ny_shape_df.set_index('Name').to_dict()['County'])\nmaster_county_dict.update(ny_shape_df.set_index('City').to_dict()['County'])\n\ntrain_df = merge_location_df(train_df, train_fastroute_df, remain_train_pickup_df, remain_train_dropoff_df)\ntrain_df = map_df_to_dic(train_df, master_county_dict, {'dropoff_county' :  'dropoff_city', 'pickup_county' : 'pickup_city'})\ntrain_df = data_preprocessing(train_df)\ntrain_df = merge_weather_df(train_df, temperature_df, humidity_df, wind_speed_df, wind_direction_df)\n\ntest_df = merge_location_df(test_df, test_fastroute_df, remain_test_pickup_df, remain_test_dropoff_df)\ntest_df = map_df_to_dic(test_df, master_county_dict, {'dropoff_county' :  'dropoff_city', 'pickup_county' : 'pickup_city'})\ntest_df = data_preprocessing(test_df)\ntest_df = merge_weather_df(test_df, temperature_df, humidity_df, wind_speed_df, wind_direction_df)\n\ntrain_df, test_df = agggregate_processing(train_df, test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing parameter for Stratification of Target with quantiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['bin_target'] = 0\ntrain_df.loc[(train_df['trip_duration'] >= 397.0) & (train_df['trip_duration'] < 662.0), 'bin_target'] = 1\ntrain_df.loc[(train_df['trip_duration'] >= 662.0) & (train_df['trip_duration'] < 1075.0), 'bin_target'] = 2\ntrain_df.loc[(train_df['trip_duration'] >= 1075.0), 'bin_target'] = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Features to be pushed for modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['count_dropoff_city', 'count_dropoff_county', 'count_dropoff_street',\n       'count_pickup_city', 'count_pickup_county', 'count_pickup_street',\n       'direction', 'displacement', 'dropoff_city',\n       'dropoff_county', 'dropoff_latitude', 'dropoff_longitude',\n       'dropoff_pca0', 'dropoff_pca1', 'end_street', 'f_avenue_count',\n       'f_boulevard_count', 'f_drive_count', 'f_expressway_count',\n       'f_left_count', 'f_parkway_count', 'f_plaza_count', 'f_road_count',\n       'f_square_count', 'f_street_count', 'in_congested_expressways',\n       'number_of_steps', 'passenger_count', 'pickup_city', 'pickup_county',\n       'pickup_day', 'pickup_dayofweek', 'pickup_dropoff_same_city',\n       'pickup_dropoff_same_county', 'pickup_latitude', 'pickup_longitude',\n       'pickup_pca0', 'pickup_pca1', 'pickup_time',\n       'starting_street', 'store_and_fwd_flag', 'total_distance',\n        'temperature', 'humidity', 'wind_speed', 'wind_direction',\n       'total_travel_time', 'vendor_id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling with Light GBM\n* Ensemble 5 folds for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'objective': 'regression',\n    'metric' : 'rmse',\n    'learning_rate': 0.1,\n    'max_depth': 25,\n    'num_leaves': 1000, \n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.5,\n    'max_bin': 1000 ,\n    'num_threads' : -1}\n\ntarget = np.log(train_df[['trip_duration']] + 1)\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = RANDOM_SEED)\noof = np.zeros(train_df.shape[0])\ntest_pred = np.zeros(test_df.shape[0])\nfeature_importance_df = pd.DataFrame()\n\nfor _fold, (train_index, eval_index) in enumerate(folds.split(train_df, train_df['bin_target'])):\n    print(f\"\\nFold: {_fold} \\n-------------------------\")\n    x_train = train_df.iloc[train_index][features].values ; y_train = target.iloc[train_index]\n    x_eval = train_df.iloc[eval_index][features].values ; y_eval = target.iloc[eval_index]\n            \n    train_data = lgbm.Dataset(x_train, y_train)\n    eval_data = lgbm.Dataset(x_eval, y_eval)\n\n    model = lgbm.train(params, train_data, num_boost_round=1500, valid_sets= (train_data, eval_data),\n                early_stopping_rounds=100, verbose_eval=100)\n    \n    eval_pred = model.predict(train_df.iloc[eval_index][features], num_iteration = model.best_iteration)\n\n    oof[eval_index] = eval_pred\n    \n    test_pred += (np.exp(model.predict(test_df[features], num_iteration = model.best_iteration)) - 1) / folds.n_splits \n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df['Features'] = features\n    fold_importance_df['Importance'] = model.feature_importance()\n    feature_importance_df = pd.concat((feature_importance_df, fold_importance_df), axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance after Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\n--------------------------------------\\n LGBM results After Feature Engineering\\n--------------------------------------\")\nprint(f\"Overall RMSE out-of-folds: {np.sqrt(mse(target, oof))}\")\n\ncols = (feature_importance_df[[\"Features\", \"Importance\"]]\n        .groupby(\"Features\").mean().sort_values(by=\"Importance\", ascending=False).index)\nbest_features = feature_importance_df.loc[feature_importance_df['Features'].isin(cols)]\n\nplt.figure(figsize=(12,14))\nsns.barplot(x=\"Importance\", y=\"Features\", data=best_features.sort_values(by=\"Importance\",ascending=False))\nplt.title('Features importance after feature engineering (averaged/folds)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/nyc-taxi-trip-duration/sample_submission.zip', compression='zip') \nsubmission['trip_duration'] = test_pred\nsubmission[['id', 'trip_duration']].to_csv('./submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}