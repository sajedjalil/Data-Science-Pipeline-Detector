{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"### Result","metadata":{"_uuid":"8d8f9caa70b4fa17dcb99cbab7a6bdaceff251dc","_cell_guid":"687aa87e-eb7e-4e39-8d7d-bd733ae76443"}},{"cell_type":"markdown","source":"Color corresponds to the cab's velocity on segment.\n\nThickness corresponds to the number of trips.","metadata":{"_uuid":"5ede5ebdd1f331b1615ad0f7bf29b90fe9270871","_cell_guid":"b32915b2-3bb0-4488-8ac1-df49fb3205d8"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"from IPython.display import HTML\nHTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/CmynXBLlCaY\" frameborder=\"0\" allowfullscreen></iframe>')","metadata":{"_uuid":"bcaac8e090e584a362604045f7e65669c32049f5","_cell_guid":"e22d1dc0-a27c-4a63-95ea-93bd7fe9d60b"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport requests\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport json\nimport matplotlib as mpl\nplt.rcParams.update(plt.rcParamsDefault)\nparams = {\n    'axes.labelsize': 12,  # fontsize for x and y labels (was 10)\n    'axes.titlesize': 8,\n    'font.size': 12,\n    'legend.fontsize': 8, \n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'figure.figsize': [30, 10],\n    'font.family': 'serif'\n}\nmatplotlib.rcParams.update(params)\nfrom pymongo import MongoClient\nclient = MongoClient()","metadata":{"_uuid":"69505f8d1198780271d994434e91e77e1508b892","collapsed":true,"_cell_guid":"e712aca0-1080-4ee8-8462-17f356940beb"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"test = pd.read_csv('data/test.csv')\ntrain = pd.read_csv('data/train.csv')","metadata":{"_uuid":"f6a376a1957021f3977ff83f09a722e0ceb7eeb8","collapsed":true,"_cell_guid":"afdab090-6c7c-42d7-a741-1b129bfb570a"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def extract_features(A):\n    A['pickup_datetime'] = pd.to_datetime(A['pickup_datetime'])\n    return A","metadata":{"_uuid":"ed2086470a24263827854944c28f04a711fb8760","collapsed":true,"_cell_guid":"fe74cba4-7a90-4528-8710-6e5056b2066a"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"test = extract_features(test)\ntrain = extract_features(train)","metadata":{"_uuid":"3e9c07252cb227105c3a3e4397525249d8f5ae9e","collapsed":true,"_cell_guid":"faae5394-b9e5-4766-97bc-196409967ca9"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"test.head()","metadata":{"_uuid":"c9f8d2e6ef49487e4d10d90e83aa3e33fb59361a","collapsed":true,"_cell_guid":"8c4a18d1-8e4e-4e89-a67d-d3f26de1c1cd"}},{"cell_type":"markdown","source":"## Calculation all trips and times by OSRM\nhttp://project-osrm.org/","metadata":{"_uuid":"11df9d60db17b10f616ba8191e53d2e05ee79f2e","_cell_guid":"6c940bf0-4022-42c7-b1a1-2a46df723fc9"}},{"cell_type":"markdown","source":"+ Docker installation :\n\n```bash\nsudo apt-get update\nsudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\nsudo apt-add-repository 'deb https://apt.dockerproject.org/repo ubuntu-xenial main'\nsudo apt-get update\nsudo apt-get install -y docker-engine\nsudo usermod -aG docker $(whoami)\n```\n\n+ downloading osm data and running osrm machine:\n\n```bash\nwget http://download.geofabrik.de/north-america/us/new-york-latest.osm.pbf\nsudo docker run -t -v $(pwd):/data osrm/osrm-backend osrm-extract -p /opt/car.lua /data/new-york-latest.osm.pbf\nsudo docker run -t -v $(pwd):/data osrm/osrm-backend osrm-contract /data/new-york-latest.osrm\nsudo docker run -t -i -d -p 5000:5000 -v $(pwd):/data osrm/osrm-backend osrm-routed /data/new-york-latest.osrm\n```\nYou can check that everything is all right by following on link http://0.0.0.0:5000/ , that print you:\n```\n{\"message\":\"URL string malformed close to position 1: \\\"\\/\\\"\",\"code\":\"InvalidUrl\"}\n```\nIf you want calculate paths for another places, you need find .pbf file on http://www.geofabrik.de/data/download.html","metadata":{"_uuid":"4c235d9005b94b78cbaf8fd16b563f2a6cd79cdb","_cell_guid":"b9d2a629-bb4b-487e-ac4a-58813273cdc8"}},{"cell_type":"markdown","source":"## Functions for genereting url for OSRM and processing responses from OSRM","metadata":{"_uuid":"825cb905be95db46eed91aff0c12bb31fe89caf0","_cell_guid":"807aa5c5-7886-484d-bb87-5ebda89956da"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"import grequests\n\ndef make_url(r):\n    url = 'http://0.0.0.0:5000/route/v1/driving/{},{};{},{}?annotations=true&alternatives=false&steps=true&overview=full&geometries=geojson'\n    return url.format(r['pickup_longitude'], r['pickup_latitude'], \n                      r['dropoff_longitude'], r['dropoff_latitude'])\n\ndef response_processing(r, response):\n    try:\n        data = response.json()\n        out = {}\n        coords = data['routes'][0]['geometry']['coordinates']\n        r['segments'] = []\n        for idx, coord in enumerate(coords[:-1]):\n            r['segments'].append([coord, coords[idx+1]])\n\n        r['time'] = data['routes'][0]['legs'][0]['annotation']['duration']\n    #     out['time'] = [0.001+t*sum_real_time/sum_time for t in time]\n        r['sum_time'] = data['routes'][0]['duration']+0.0001\n\n        r['distance'] = data['routes'][0]['legs'][0]['annotation']['distance']\n        \n    except:\n        print('error processing response')\n    return r\n","metadata":{"_uuid":"bddea5a3b6f96c95525df868e2a47e123c4cda35","collapsed":true,"_cell_guid":"ee24c355-16f6-4f46-8c23-97078eb4f340"}},{"cell_type":"markdown","source":"lets start\n\nCalculation of all routes takes 2 hour on my laptop. I store it in mongodb","metadata":{"_uuid":"96afbe6b86a355a9b75258cd792e51fbe946995f","_cell_guid":"78c56439-f8fc-4175-b24f-21068d662a28"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"\nmg = client.pymongo_test.routes\n#mg.delete_many({})\nmg.count()\nchunk_size = 10**2\nfor chunk in tqdm(range(int(len(train)/chunk_size))):\n    df_chunk = train.iloc[chunk_size*chunk:chunk_size*(chunk+1)].reset_index().to_dict(orient='records')\n    requests = [grequests.get(make_url(r)) for r in df_chunk]\n    out = [response_processing(df_chunk[idx], response) \n           for idx, response in enumerate(grequests.map(requests))]\n    mg.insert_many(out)\n","metadata":{"_uuid":"c3a646fc5c95e68d1ecd5bf8e545a9a0798b94a8","collapsed":true,"_cell_guid":"dab796a3-74e3-462b-a5c3-962088fad4ae"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"mg.create_index([('id', 1)])\nmg.count()","metadata":{"_uuid":"92b4cbface3c5f025aa10b2125209a3c8a6e7806","collapsed":true,"_cell_guid":"795ab39c-7390-47b9-a5ff-7ea911cf12e7"}},{"cell_type":"markdown","source":"# Visualisation\n\nI merged all route segments for every hour. Because OSRM gave me segments from road graph, its was merged easily.\n","metadata":{"_uuid":"04184df7beedbe3026234631664e718f7c2169cf","_cell_guid":"0bc4ab62-a9f4-4310-aed6-03f61365d992"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"lon_min, lon_max, lat_min, lat_max = (-74.017236999999994,\n -73.87130999999998,\n 40.699087999999999,\n 40.784724999999999)","metadata":{"_uuid":"3a1e7709fce249dd9194dc63046e809add62817b","collapsed":true,"_cell_guid":"97d854e8-7ccd-432f-a095-94cc349d8c66"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def merge_segments(df):\n    adf = []\n    for i in df.to_dict(orient='records'):\n        try:\n            for idx, segment in enumerate(i['segments']):\n                s = {'id': i['id'], 'distance': i['distance'][idx], 'segment': segment, \n                     'velocity': sum(i['distance']) / i['trip_duration'],\n                    'velocity_osrm': i['distance'][idx] / (0.001 + i['time'][idx] * i['trip_duration'] / i['sum_time'])}\n                adf.append(s)\n        except:\n            print('error')\n    adf = pd.DataFrame(adf)\n    adf['lon0'] = adf.segment.apply(lambda x: x[0][0])\n    adf['lon1'] = adf.segment.apply(lambda x: x[1][0])\n    adf = adf[adf.velocity_osrm < 50]\n\n    adf_gr = adf.groupby(['lon0', 'lon1'], as_index=False)['velocity_osrm'].agg(['mean', 'count']).add_suffix('_velocity').reset_index()\n    adf_gr = adf_gr[adf_gr.count_velocity>1].merge(adf.drop_duplicates(['lon0', 'lon1']), on=['lon0', 'lon1'], how='left')\n    return adf_gr","metadata":{"_uuid":"6ff80b6764173a0adf8373a951e184b200480b27","collapsed":true,"_cell_guid":"f247ccea-f31e-4f1c-a27c-32ef86dac77c"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"cmap = mpl.cm.RdYlGn\nnorm = mpl.colors.Normalize(vmin=0, vmax=20)\ndef plot(adfm, lon_min, lon_max, lat_min, lat_max, output_path, text_on_image):\n    adfm_out = adfm.copy()\n    plt.gcf().clear()\n    fig, ax = pl.subplots()\n    lc = mc.LineCollection(adfm_out['segment'].values, colors=cmap(norm((adfm_out['mean_velocity']))), \n                           alpha=0.9, linewidths=adfm_out['count_velocity']/65)\n    ax.add_collection(lc)\n    ax.text(0.95, 0.01, text_on_image,\n        verticalalignment='bottom', horizontalalignment='right',\n        transform=ax.transAxes,\n        color='white', fontsize=20)\n    plt.xlim(lon_min, lon_max)\n    plt.ylim(lat_min, lat_max)\n    plt.imshow(image, zorder=0, extent=[lon_min, lon_max, lat_min, lat_max])\n    plt.axis('off') \n    plt.savefig(output_path, dpi=400,bbox_inches='tight', pad_inches=0)","metadata":{"_uuid":"b787da9a06ecd0c84edf5536b399f517ddcc732c","collapsed":true,"_cell_guid":"d286081e-ca0a-48f9-8899-e559c083c941"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"file_paths = 'output/{}.png'\nfor hour in range(24):\n    for minute in range(6):\n        filtered_df = train_df[(train_df['pickup_datetime'].dt.minute > 10*minute) & \n           (train_df['pickup_datetime'].dt.minute < 10*(minute+1)) & \n           (train_df['pickup_datetime'].dt.hour == hour)]\n        if len(filtered_df) > 0:\n            print(len(filtered_df))\n            print(hour, minute)\n            df = pd.DataFrame(list(mg.find({'id': {'$in': filtered_df['id'].values.tolist()}})))\n            plot(merge_segments(df), lon_min, lon_max, lat_min, lat_max, \n                 file_paths.format(5*hour+minute), '{}:{}'.format(hour, minute*10))","metadata":{"_uuid":"90b8a4ce779cbbae3e6b992388912c4b4455633e","collapsed":true,"_cell_guid":"4d173d24-ef52-4b97-a33b-c9d673054044"}},{"cell_type":"markdown","source":"Now in folder 'output' are series of pngs.","metadata":{"_uuid":"daa80e6c7756557cf71175e6f287d832f2a1b07c","_cell_guid":"84fad9c5-983f-4de0-b115-04cfcf8f1260"}}],"metadata":{"language_info":{"version":"3.6.3","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}}}