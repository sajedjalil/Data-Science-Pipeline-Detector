{"cells":[{"source":"Importing Libraries","cell_type":"markdown","metadata":{"_cell_guid":"2f5d84cb-b20d-4061-9d14-2097a6823191","_uuid":"41a8d3db97bfe8bd504bd3f5d75060574b890684"}},{"source":"import numpy as np\nimport pandas as pd\nfrom scipy import ndimage\nimport matplotlib.pyplot as plt\nfrom os import listdir\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom PIL import Image","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"bc28ee7a-e446-42c1-9510-3bda05cdcd2f","_uuid":"e3ebaaeefdc46d831442db0f89842d65a6e927b8"},"execution_count":1},{"source":"Setting Path Variables","cell_type":"markdown","metadata":{"_cell_guid":"9843bc2b-8045-4ec0-b36b-d7f07b47636e","_uuid":"d3be088b71b7352b543b87e580d02ffc2095eb81"}},{"source":"path = '../input/images/'\ntrain = pd.read_csv('../input/train.csv')\nimage_paths = [path + f for f in listdir(path)]","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"8f27f213-7832-4b3f-a1e2-153c20cbd93c","collapsed":true,"_uuid":"a5c0d1302adb1d2c3c8b912568a4fe1a15e05da3"},"execution_count":2},{"source":"Defining Image Plotting and imagetraversal functions","cell_type":"markdown","metadata":{"_cell_guid":"52546858-f3b6-4ad5-b0f9-ad26b5cc2daf","_uuid":"78ec4730340f8ad69f6f0591fcfc8584be6a98b6"}},{"source":"def plotGalery(classes, n_col=10, scale_x = 1.5, scale_y = 1.7):\n    \n    def pathsBySpecies(classes):\n        paths = {}\n        for row in train.values:\n            if row[1] in classes:\n                if row[1] in paths:\n                    paths[row[1]].append('../input/images/' + str(row[0]) + '.jpg')\n                else:\n                    paths[row[1]] = ['../input/images/' + str(row[0]) + '.jpg']\n        return paths\n    \n    dic = pathsBySpecies(classes)\n    \n    n_row = len(dic.keys())\n    plt.figure(figsize=(scale_x * n_col, scale_y * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        key = list(dic.keys())[i // n_col]\n        path = dic[key][i % n_col]\n        image = Image.open(path)\n        image = np.array(image)\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(image, cmap=plt.cm.gray, interpolation='none')\n        plt.xticks(())\n        plt.yticks(())\n        plt.tight_layout\n        \ndef imageById(id_):\n    img = Image.open('../input/images/'+str(id_)+'.jpg')\n    #img = img.resize((50, 50), Image.ANTIALIAS)\n    return np.array(img)\n'''\ndef imageByIdPCA(id_):\n    img = Image.open('../input/images/'+str(id_)+'.jpg')\n    img = img.resize((50, 50), Image.ANTIALIAS)\n    from sklearn.decomposition import PCA\n    # Make an instance of the Model\n    pca = PCA(35)\n    pcm = pca.fit_transform(img)\n    return pcm\n'''","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"6d4bf64a-adf0-4008-80b9-a23e0273245e","_uuid":"aafd3f1be60dcf40a5668302140bcde74db08236"},"execution_count":3},{"source":"classes = train.species.value_counts().keys()\nplotGalery(classes)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"0ed21c3b-cc85-46c9-aeb4-38e200de692c","collapsed":true,"_uuid":"1181d37b4a0a94f849990e18774acea525d1147f"},"execution_count":null},{"source":"import cv2\n\ndef imageFeatures(source, filepath):\n    df = pd.read_csv(source)\n    ids = df.values[:,0].astype(np.int)\n    images = [imageById(id_) for id_ in ids]\n    height = [image.shape[0] for image in images]\n    width = [image.shape[1] for image in images]\n    orientation = [int(h > w) for h, w in zip(height, width)]\n    perimeters = [cv2.Canny(im,100,200).sum() / 255.0 for im in images]\n    square = [image.sum() / 255.0/ image.size for image in images]\n    square_r = [im.sum() / sq for im, sq in zip(images, square)]\n    sums = [im.sum() for im in images]\n    pd.DataFrame({\n            'height': height,\n            'width': width,\n            'orientation': orientation,\n            'square': square,\n            'square_r': square_r,\n            'sum': sums\n        }).to_csv(filepath, index=False)\n","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"872b436f-f910-4392-b78c-43b0869592a1","collapsed":true,"_uuid":"8eddfad0c48b65d50ec8e8334e428a03ca44be27"},"execution_count":4},{"source":"PCA","cell_type":"markdown","metadata":{"_cell_guid":"89f36ed8-e33a-4c0d-a0b6-49f779131000","_uuid":"821833902a99f67cd7401225f2c23cbea5803325"}},{"source":"#Principal Component Analysis\nimport matplotlib\ndf = pd.read_csv('../input/train.csv')\ndf2 = pd.read_csv('../input/test.csv')\nids = df.values[:,0].astype(np.int)\ntestids = df2.values[:,0].astype(np.int)\npca_train = []\npca_test = []\nfor id_ in ids:\n    img=Image.open('../input/images/'+str(id_)+'.jpg')\n    img = img.resize((50, 50), Image.ANTIALIAS)\n    img= np.array(img)\n    pca_train.append(img)\nfor id_ in testids:\n    img=Image.open('../input/images/'+str(id_)+'.jpg')\n    img = img.resize((50, 50), Image.ANTIALIAS)\n    img= np.array(img)\n    pca_test.append(img)\npca_train=np.array(pca_train)\npca_test=np.array(pca_test)\npca_train = pca_train.reshape(990,2500)\npca_test = pca_test.reshape(594,2500)\nfrom sklearn.decomposition import PCA\n# Make an instance of the Model\npca = PCA(35)\npca.fit(pca_train)\npca_train = pca.transform(pca_train)\npca_test = pca.transform(pca_test)\n","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"b96c1467-4311-4d3c-a1dc-ded9037a0a9f","collapsed":true,"_uuid":"8391d24cc0c349516d5a9464df702c7bf80759c1"},"execution_count":5},{"source":"Saving PCs as DataFrames","cell_type":"markdown","metadata":{"_cell_guid":"80fc2bf8-894f-40dc-8ad1-59bc66355b6e","_uuid":"31ab10fbb573b3333feb714852d0cc019145f0ba"}},{"source":"pca_train=pd.DataFrame(pca_train)\npca_test = pd.DataFrame(pca_test)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"5e6b4a90-6ba8-4238-b290-e844b8004139","collapsed":true,"_uuid":"9752654409fae0cc30fe7ade4249a5ba6dc4c2bc"},"execution_count":6},{"source":"imageFeatures('../input/train.csv', 'train_f1.csv')\nimageFeatures('../input/test.csv', 'test_f1.csv')\n#pcaImage('../input/train.csv','train_pca.csv')\n#pcaImage('../input/test.csv','test_pca.csv')","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"b7edfa41-c0dd-4bdf-8f1c-c0a1f323c195","collapsed":true,"_uuid":"6cbdc7c4e655852f393e81d6a528427394e1f11c"},"execution_count":7},{"source":"I Moments Functions","cell_type":"markdown","metadata":{"_cell_guid":"a81e084a-2f78-400a-b12f-d47285af039e","_uuid":"ea61c5bd3316135b554eb96364dc21a02320d327"}},{"source":"def M(im):\n    ret,thresh = cv2.threshold(im,127,255,0)\n    contours,hierarchy, _ = cv2.findContours(thresh, 1, 2)\n    cnt = contours[0]\n    x = np.fromiter(iter(cv2.moments(cnt).values()), dtype=float)\n    return x\n\ndef imageMoments(source, filepath):\n    df = pd.read_csv(source)\n    ids = df.values[:,0].astype(np.int)\n    images = [imageById(id_) for id_ in ids]\n        \n    moments = [1.0*M(im)/im.size for im in images]\n    pd.DataFrame(moments).to_csv(filepath, index=False)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"0431821c-cd9c-44fc-b090-dc7203c69206","collapsed":true,"_uuid":"515185ba2ce4ca8b792128f0bb1d5570e2400ee2"},"execution_count":8},{"source":"imageMoments('../input/train.csv', 'train_M1.csv')\nimageMoments('../input/test.csv', 'test_M1.csv')","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"666350ad-f16e-4a49-b570-61e5d7ded2fd","collapsed":true,"_uuid":"fdeb2c447dfa299159d96f3e654723a52a3c6591"},"execution_count":9},{"source":"Performing initial Logistic Regression to figure out confusion classes.","cell_type":"markdown","metadata":{"_cell_guid":"44ddf226-215c-446c-9db4-e3c213989cb9","_uuid":"b63afe3239e965b6a31bd0c26f317af0661591d1"}},{"source":"train_f1 = pd.read_csv('train_f1.csv')\ntrain_M1 = pd.read_csv('train_M1.csv')\ntest_f1 = pd.read_csv('test_f1.csv')\ntest_M1 = pd.read_csv('test_M1.csv')\n\ntest = pd.read_csv(\"../input/test.csv\")\ntrain = pd.read_csv(\"../input/train.csv\")\n\n# train\nx_train = train.drop(['id', 'species'], axis=1)\ny_train = train['species']\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)\ntest_ids = test.pop('id')\nx_test = test\nx_train = pd.concat([train_f1,x_train,pca_train,train_M1], axis=1)\nx_test = pd.concat([test_f1,x_test,pca_test,test_M1], axis =1)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"175da6a5-e0d3-4a7c-9ff6-ed7c5849eb49","collapsed":true,"_uuid":"ddf975c33fcfaca2b90576fc61f878e24b01bfa9"},"execution_count":10},{"source":"scaler = StandardScaler().fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"8c88b296-5a18-4a96-ab59-6684aacef4a0","collapsed":true,"_uuid":"7d30ca458c4501da0443b06742ee2f419d25ad14"},"execution_count":11},{"source":"params = {'C':[1000], 'tol': [0.0008, 0.0007]}\nlog_reg = LogisticRegression(solver='lbfgs', multi_class='multinomial')\nclf = GridSearchCV(log_reg, params, scoring='log_loss', refit='False', cv=3)\nclf.fit(x_train, y_train)\n\ny_pred = clf.predict_proba(x_test)\n\nsubmission = pd.DataFrame(y_pred, index=test_ids, columns=le.classes_)\n#submission.to_csv('test.csv')","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"c55489ce-4f63-49f7-9317-ffa7f598faaa","_uuid":"2d8b0731bee2c8d7715135a033604c7610a4c803"},"execution_count":12},{"source":"Finding Classes which fail to perform well using LR","cell_type":"markdown","metadata":{"_cell_guid":"02dad6f3-7e05-46ce-8db0-ce620a1828e4","_uuid":"a608ac030a42282e74ffd5e799dd0dba2f4affef"}},{"source":"colsub=[]\nfor i in submission.columns:\n    colsub.append(i)\nfinalcol=[]\nfrom sklearn.feature_selection import VarianceThreshold\nselector = VarianceThreshold()\nselector.fit_transform(submission)     \nj=0\nfor i in selector.variances_:\n    if(i>0.009999):\n        finalcol.append(colsub[j])\n    j=j+1\n#finalcol is the nparray of columns that don't perform well using LR","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"fe8f6be5-3719-4dad-8889-80ee4919570e","collapsed":true,"_uuid":"4ea67a768fd551d1b7cfdd1b60dc07a67057777d"},"execution_count":13},{"source":"**Building Final Model**","cell_type":"markdown","metadata":{"_cell_guid":"31b231f8-e373-4d7c-956c-9a0237641757","_uuid":"2ea3253882eca1a71957135d8870d4ba690f6379"}},{"source":"train_f1 = pd.read_csv('train_f1.csv')\ntrain_M1 = pd.read_csv('train_M1.csv')\ntest_f1 = pd.read_csv('test_f1.csv')\ntest_M1 = pd.read_csv('test_M1.csv')\n\ntest = pd.read_csv(\"../input/test.csv\")\ntrain = pd.read_csv(\"../input/train.csv\")\n#Training df\nx_train = train\nx_rf_train = train\n\nle = LabelEncoder()\ny_train = train['species']\ny_rf_train =train['species']\n#labels\ntest_ids = test.pop('id')\nx_test = test\n#merging extracted features with given features\nx_train = pd.concat([train_f1,x_train,pca_train,train_M1], axis=1)\nx_rf_train = pd.concat([train_f1,x_rf_train,pca_train,train_M1], axis=1)\nfor index, row in x_train.iterrows():\n    if(row['species'] in finalcol):\n        x_train = x_train.drop(index)\n        y_train = y_train.drop(index)\n        print(index)\n    else:\n        x_rf_train = x_rf_train.drop(index)\n        y_rf_train = y_rf_train.drop(index)\n\ny_train = le.fit_transform(y_train)\nx_train = x_train.drop(['id', 'species'], axis=1)\nx_rf_train =x_rf_train.drop(['id', 'species'], axis=1)\nx_test = pd.concat([test_f1,x_test,pca_test,test_M1], axis =1)\nlerf=LabelEncoder()\ny_rf_train =lerf.fit_transform(y_rf_train)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"1868b200-a44a-4d9d-a1c5-16a140712643","_uuid":"e928e83b9d3c8b876c66dac7729240e1257dcb91"},"execution_count":14},{"source":"#Scaling for Logistic Regression\nscaler = StandardScaler().fit(x_rf_train)\nx_rf_train = scaler.transform(x_rf_train)\nx_rf_test = scaler.transform(x_test)\n#scaling for Random Forest\nscaler = StandardScaler().fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"94a99067-dcbe-4c72-94bf-4e39daf9d741","collapsed":true,"_uuid":"d41380ebc30bdcd621563defb43190d39ab7e20d"},"execution_count":15},{"source":"Using RandomForest and storing partial results in a dataframe","cell_type":"markdown","metadata":{"_cell_guid":"91fae610-c228-40e2-94ae-a416a9cd1863","_uuid":"d00d4a5ccc1c64ea6b3c347fa84e8c0c85af285c"}},{"source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\n\nclf = RandomForestClassifier()\nclf.fit(x_rf_train, y_rf_train)\ny_predrf = clf.predict_proba(x_rf_test)\nsubmissionrf = pd.DataFrame(y_predrf, index=test_ids, columns=lerf.classes_)\n","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"fd43380a-7b9a-4bfd-9093-46b71bbb35ad","collapsed":true,"_uuid":"a3b5c59ed845f9398ede69754375ba4422fb0b3c"},"execution_count":16},{"source":"Using Logistic Regression and storing the rest of the results in another dataframe","cell_type":"markdown","metadata":{"_cell_guid":"454de4aa-f3e5-48a8-afac-c299f8773533","_uuid":"17d524dc4d9b91f24db08e1fb8de0d05d8bc30f5"}},{"source":"params = {'C':[1000], 'tol': [0.0008, 0.0007]}\nlog_reg = LogisticRegression(solver='lbfgs', multi_class='multinomial')\nclf = GridSearchCV(log_reg, params, scoring='log_loss', refit='False', cv=3)\nclf.fit(x_train, y_train)\n\ny_pred = clf.predict_proba(x_test)\n\nsubmission = pd.DataFrame(y_pred, index=test_ids, columns=le.classes_)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"1730314a-e007-4c94-8aad-5df9210ac4bf","_uuid":"01251588ccc2fdf3c7ed30e429732255ca7c0864"},"execution_count":17},{"source":"Concatening both databases and creating CSV for submission","cell_type":"markdown","metadata":{"_cell_guid":"486e5695-e9db-4950-904b-39ecfb8ce63e","_uuid":"3f84b32ecf50293c66375de73f73d9fdac8870ec"}},{"source":"submission = pd.concat([submission,submissionrf], axis =1)\nsubmission.to_csv('final.csv')","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"cb24e3ad-1c61-42ae-a6d7-e9617b7ef2a6","collapsed":true,"_uuid":"779c52b7f9d19b924218fc2f792dab5f09b53c13"},"execution_count":null},{"source":"","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"4efebb09-1f05-4725-bedc-0b09cd8b1de7","collapsed":true,"_uuid":"4bb73a46bca95b68b5d30014fab1efcf48fc3789"},"execution_count":null},{"source":"> **Rough Work.... Alternate approach.**","cell_type":"markdown","metadata":{"_cell_guid":"a462fbc8-8285-4ed7-adf2-396265eed23b","_uuid":"8ff9390cb66424d285bd33692b956e2f727125b3"}},{"source":"for i in result.index:\n    if(result[prediction[0][i]][i]>0.1):\n        print(prediction[0][i])\n\n","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"76095ed9-cd5c-437c-ad8a-8f2ba5018c06","collapsed":true,"_uuid":"de93cd481e2cd09afcb12c2f143b7a1e16ad95aa"},"execution_count":null},{"source":"train_f1 = pd.read_csv('train_f1.csv')\n#train_M1 = pd.read_csv('train_M1.csv')\ntest_f1 = pd.read_csv('test_f1.csv')\n#test_M1 = pd.read_csv('test_M1.csv')\ntest = pd.read_csv(\"../input/test.csv\")\ntrain = pd.read_csv(\"../input/train.csv\")\ntrain=pd.concat([train_f1,train,pca_train], axis=1)\ntest = pd.concat([test_f1,test,pca_test], axis =1)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"148e9918-81a8-4f0f-afef-4af8eeebba6e","collapsed":true,"_uuid":"f6261983fd23bf1c1e456a91c089d3ec9255705d"},"execution_count":null},{"source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import StratifiedShuffleSplit","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"d9d03cec-d1d8-450e-8ab0-bdbe92a3be2f","collapsed":true,"_uuid":"73856a1f9bf4ca368a70b2b4b0ecc99ba30e2e11"},"execution_count":null},{"source":"def encode(train, test):\n    le = LabelEncoder().fit(train.species) \n    labels = le.transform(train.species)           # encode species strings\n    classes = list(le.classes_)                    # save column names for submission\n    test_ids = test.id                             # save test ids for submission\n    \n    train = train.drop(['species', 'id'], axis=1)  \n    test = test.drop(['id'], axis=1)\n    \n    return train, labels, test, test_ids, classes\n\ntrain, labels, test, test_ids, classes = encode(train, test)\ntrain.head(1)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"a880e5bc-be17-4566-a5a1-c7b5a6b9d770","collapsed":true,"_uuid":"d3f5c991ba447f1b3c23440b0ff74e3b440af84f"},"execution_count":null},{"source":"sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n\nfor train_index, test_index in sss:\n    X_train, X_test = train.values[train_index], train.values[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"5d01da76-3dc0-438a-912c-1c2657a8497d","collapsed":true,"_uuid":"e5a5e121c232f35db63007e29c8bfe2d8d9e8039"},"execution_count":null},{"source":"y_train.shape","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"7f2a01c3-2f65-401b-b662-266ea83fc876","collapsed":true,"_uuid":"f7393deece7c95a3d692704055c4e84836c81fa3"},"execution_count":null},{"source":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    NuSVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis()]\n\n# Logging for Visual Comparison\nlog_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\nlog = pd.DataFrame(columns=log_cols)\n\nfor clf in classifiers:\n    clf.fit(X_train, y_train)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    train_predictions = clf.predict(X_test)\n    acc = accuracy_score(y_test, train_predictions)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_predictions = clf.predict_proba(X_test)\n    ll = log_loss(y_test, train_predictions)\n    print(\"Log Loss: {}\".format(ll))\n    \n    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n    log = log.append(log_entry)\n    \nprint(\"=\"*30)","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"7b24b42e-5aad-4029-b535-ee247a428813","collapsed":true,"_uuid":"b1ebed879ccbc0ea6a8e4011338791108a1eae9e"},"execution_count":null},{"source":"# Predict Test Set\nfavorite_clf =  LinearDiscriminantAnalysis(solver='lbfgs', multi_class='multinomial')\nfavorite_clf.fit(X_train, y_train)\ny_pred = favorite_clf.predict_proba(test)\n\n# Format DataFrame\n#submission = pd.DataFrame(test_predictions, columns=classes)\n#submission.insert(0, 'id', test_ids)\n#ubmission.reset_index()\n\n# Export Submission\n#submission.to_csv('submissiondiff.csv', index = False)\n#submission.tail()","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"84d4c8df-6ddf-4847-be68-f1fdb57f0e22","collapsed":true,"_uuid":"6035a474523f501f49990f566cdd36ef33c7739e"},"execution_count":null},{"source":"","cell_type":"code","outputs":[],"metadata":{"_cell_guid":"762c7ba0-1ea8-4b75-809f-8667eb291966","collapsed":true,"_uuid":"4db007737eb720c976495ba0bf531a0437abc2b2"},"execution_count":null}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"file_extension":".py","name":"python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":1}