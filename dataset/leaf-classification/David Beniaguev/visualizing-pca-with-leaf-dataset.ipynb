{"nbformat_minor":1,"nbformat":4,"cells":[{"cell_type":"markdown","source":"***Visualizing PCA with Leaf Dataset***\n================================\n\nIn this script we will apply PCA on leaf images and try to get a feel for the distribution of leaf images using visualizations that (hopefully) clarify different aspects about how to interpret PCA results.\n\nWe will then continue to see if the PCA features are informative in terms of classifying leafs and determine how many of those we need.\n\nI've just updated another script, similar in nature to this one, just focused about k-means.\nif you enjoyed this one, be sure to also check out the [k-means script][1] as well\n\n  [1]: https://www.kaggle.com/selfishgene/leaf-classification/visualizing-k-means-with-leaf-dataset/notebook","metadata":{"_uuid":"e57fd7c2e8181b3224e7bcdd4c26bb0f824b529d","_cell_guid":"3f7fe7df-1326-d944-2ec5-22c5c9155822"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nfrom sklearn import model_selection\nfrom sklearn import decomposition\nfrom sklearn import linear_model\nfrom sklearn import ensemble\nfrom sklearn import neighbors\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KernelDensity\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import accuracy_score\n\nfrom skimage.transform import rescale\nfrom scipy import ndimage as ndi\n\nmatplotlib.style.use('fivethirtyeight')","metadata":{"collapsed":true,"_uuid":"2f4660dbd15090cbfdd88b93dc7c0c7bb57045ed","_cell_guid":"f0c7a02b-f9b6-f3e8-7b9a-67d34671ef7e"}},{"cell_type":"markdown","source":"## Load the data and Pre-process it\n\nFor the sake of the script not being too cluttered, I suppressed the output of all intermediate plots during the data loading and preparation phases. anyone who is interested is welcome to **fork and unhide output** to see what is going on.\n\n(the main assumption of this pre-processing stage is that the absolute sizes of the leafs matter, and not just their shape. i.e. leafs with different sizes are most definitely different types of leafs. not sure if it's actually important, but just in case)","metadata":{"_uuid":"22276c5c5d157fffa47c5b0cecbde409201557cb","_cell_guid":"347f2648-d405-9620-505c-c7d91d1f9b70"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"#%% load the data\ndataDir = '../input/'\ntrainData = pd.read_csv(dataDir + 'train.csv')\nclassEncoder = LabelEncoder()\ntrainLabels = classEncoder.fit_transform(trainData.loc[:,'species'])\ntrainIDs = np.array(trainData.loc[:,'id'])\n\n# show some random images\nplt.figure(figsize=(12,12))\nfor k in range(28):\n    randTrainInd = np.random.randint(len(trainIDs))\n    randomID = trainIDs[randTrainInd]\n    imageFilename = dataDir + 'images/' + str(randomID) + '.jpg'\n    plt.subplot(4,7,k+1); plt.imshow(mpimg.imread(imageFilename), cmap='gray')\n    plt.title(classEncoder.classes_[trainLabels[randTrainInd]], fontsize=8); plt.axis('off')\n\n#%% preprocess images\n\n# go over training images and store them in a list\nnumImages = 1584\n\nshapesMatrix = np.zeros((2,numImages))\nlistOfImages = []\nfor k in range(numImages):\n    imageFilename = dataDir + 'images/' + str(k+1) + '.jpg'\n    currImage = mpimg.imread(imageFilename)\n    shapesMatrix[:,k] = np.shape(currImage)\n    listOfImages.append(currImage)\n    \n# create a large 3d array with all images\nmaxShapeSize = shapesMatrix.max(axis=1)\nfor k in range(len(maxShapeSize)):\n    if maxShapeSize[k] % 2 == 0:\n        maxShapeSize[k] += 311\n    else:\n        maxShapeSize[k] += 310\n    \nfullImageMatrix3D = np.zeros(np.hstack((maxShapeSize,\n                                        np.shape(shapesMatrix[1]))).astype(int),dtype=np.dtype('u1'))\ndestXc = (maxShapeSize[1]+1)/2; destYc = (maxShapeSize[0]+1)/2\nfor k, currImage in enumerate(listOfImages):\n    Yc, Xc = ndi.center_of_mass(currImage)\n    Xd = destXc - Xc; Yd = destYc - Yc\n    rowIndLims = (int(round(Yd)),int(round(Yd)+np.shape(currImage)[0]))\n    colIndLims = (int(round(Xd)),int(round(Xd)+np.shape(currImage)[1]))\n    fullImageMatrix3D[rowIndLims[0]:rowIndLims[1],colIndLims[0]:colIndLims[1],k] = currImage\n\n# make sure nothing was ruined in the process\nplt.figure(figsize=(12,12))\nplt.suptitle('large reference frame images', fontsize=10)\nfor k in range(28):\n    randInd = np.random.randint(np.shape(fullImageMatrix3D)[2])\n    plt.subplot(4,7,k+1); plt.imshow(fullImageMatrix3D[:,:,randInd], cmap='gray'); plt.axis('off')\n\n# remove redundent rows and columns\nxValid = fullImageMatrix3D.mean(axis=2).sum(axis=0) > 0\nyValid = fullImageMatrix3D.mean(axis=2).sum(axis=1) > 0\nxLims = (np.nonzero(xValid)[0][0],np.nonzero(xValid)[0][-1])\nyLims = (np.nonzero(yValid)[0][0],np.nonzero(yValid)[0][-1])\nfullImageMatrix3D = fullImageMatrix3D[yLims[0]:yLims[1],xLims[0]:xLims[1],:]\n\n# make sure nothing was ruined in the process\nplt.figure(figsize=(12,12))\nplt.suptitle('final reference frame images', fontsize=10)\nfor k in range(28):\n    randInd = np.random.randint(np.shape(fullImageMatrix3D)[2])\n    plt.subplot(4,7,k+1); plt.imshow(fullImageMatrix3D[:,:,randInd], cmap='gray'); plt.axis('off')\n\n# scale down all images\nrescaleFactor = 0.15\n\nscaledDownImage = rescale(fullImageMatrix3D[:,:,0],rescaleFactor)\nscaledDownImages = np.zeros(np.hstack((np.shape(scaledDownImage),\n                                       np.shape(fullImageMatrix3D)[2])),dtype=np.dtype('f4'))\nfor imInd in range(np.shape(fullImageMatrix3D)[2]):\n    scaledDownImages[:,:,imInd] = rescale(fullImageMatrix3D[:,:,imInd],rescaleFactor)\n    \ndel fullImageMatrix3D","metadata":{"_kg_hide-output":true,"_uuid":"44192704e8667c4bc802c472b5c638e958191491","_cell_guid":"a77bab6e-468f-ed20-10fb-3305ae95ee9b"}},{"cell_type":"markdown","source":"## Look at the final processing stage and view several random leaf images:","metadata":{"_uuid":"5c07a06b187fbb71cf54427c1fb9065f06639063","_cell_guid":"7a132a3c-d492-66b5-fc74-884c58dfd0f7"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"np.random.seed(1) # use a nice looking random seed\n\nplt.figure(figsize=(12,10));\nfor k in range(25):\n    randInd = np.random.randint(np.shape(scaledDownImages)[2])\n    plt.subplot(5,5,k+1); \n    plt.imshow(scaledDownImages[:,:,randInd], cmap='gray'); \n    plt.axis('off'); plt.title('imageID = ' + str(randInd), fontsize=12)\nplt.tight_layout()","metadata":{"_uuid":"6968fb0185d84a10743d335b2fe429ee92cc65ab","_cell_guid":"8e6ffe82-b590-d33a-9311-ad7de33d3942"}},{"cell_type":"markdown","source":"## Define a 'GaussianModel' class that will help us visualize things:\n\nThis is long, so I've hidden the code, but if you are intereseted in delving deeper and looking at the implementation then please unhide or better yet fork the script and try playing around by editing the code.","metadata":{"_uuid":"f98c08921d95ec273b556aea4a18d1271de60576","_cell_guid":"e4890d77-fc68-530a-951d-fc097d4c2bf2"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"#%% define GaussianModel class\n\nclass GaussianModel:\n    def __init__(self, X, numBasisFunctions=10, objectPixels=None):\n        '''\n        inputs: \n            X                    - numSamples x numDimentions matrix\n            numBasisFunctions       - number of basis function to use\n            objectPixels (optional) - an binnary mask image used for presentation\n                                      will be used as Im[objectPixels] = dataSample\n                                      must satisfy objectPixels.ravel().sum() = X.shape[1]\n        '''\n        \n        self.numBasisFunctions = numBasisFunctions        \n        if objectPixels is None:\n            self.objectPixels = np.ones((1,X.shape[1]),dtype=np.bool)\n        else:\n            self.objectPixels = objectPixels\n        assert(self.objectPixels.ravel().sum() == X.shape[1])\n\n        PCAModel = decomposition.PCA(n_components=numBasisFunctions, whiten=True)\n        self.dataRepresentation = PCAModel.fit_transform(X)\n        self.PCAModel = PCAModel\n\n    def RepresentUsingModel(self, X):\n        return self.PCAModel.transform(X)\n\n    def ReconstructUsingModel(self, X_transformed):\n        return self.PCAModel.inverse_transform(X_transformed)\n\n    def InterpretUsingModel(self, X):\n        return self.PCAModel.inverse_transform(self.PCAModel.transform(X))\n\n    # shows the eigenvectors of the gaussian covariance matrix\n    def ShowVarianceDirections(self, numDirectionsToShow=16):\n        numDirectionsToShow = min(numDirectionsToShow, self.numBasisFunctions)\n        \n        numFigRows = 4; numFigCols = 4;\n        numDirectionsPerFigure = numFigRows*numFigCols\n        numFigures = int(np.ceil(float(numDirectionsToShow)/numDirectionsPerFigure))\n        \n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotInd in range(numDirectionsPerFigure):\n                eigVecInd = numDirectionsPerFigure*figureInd + plotInd\n                if eigVecInd >= self.numBasisFunctions:\n                    break\n                deltaImage = np.zeros(np.shape(self.objectPixels))\n                deltaImage[self.objectPixels] = self.PCAModel.components_[eigVecInd,:].ravel()\n\n                plt.subplot(numFigRows,numFigCols,plotInd+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(deltaImage)\n                else:\n                    plt.imshow(deltaImage,cmap='jet'); plt.axis('off')\n                titleStr = str(100*self.PCAModel.explained_variance_ratio_[eigVecInd])[0:5]\n                plt.title(titleStr + '% explained');\n            plt.tight_layout()\n            \n    # shows several random model reconstructions\n    def ShowReconstructions(self, X, numReconstructions=5):\n        assert(np.shape(X)[1] == self.objectPixels.ravel().sum())\n        numSamples = np.shape(X)[0]\n        numReconstructions = min(numReconstructions, numSamples)\n        \n        originalImage      = np.zeros(np.shape(self.objectPixels))\n        reconstructedImage = np.zeros(np.shape(self.objectPixels))\n        \n        numReconstructionsPerFigure = min(5, numReconstructions)\n        numFigures = int(np.ceil(float(numReconstructions)/numReconstructionsPerFigure))\n        \n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotCol in range(numReconstructionsPerFigure):\n                dataSampleInd = np.random.randint(numSamples)\n                originalImage[self.objectPixels] = X[dataSampleInd,:].ravel()\n                reconstructedImage[self.objectPixels] = \\\n                    self.InterpretUsingModel(np.reshape(X[dataSampleInd,:],[1,-1])).ravel()\n                diffImage = abs(originalImage - reconstructedImage)\n                \n                # original image\n                plt.subplot(3,numReconstructionsPerFigure,0*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(originalImage); plt.title('original signal')\n                else:\n                    plt.imshow(originalImage, cmap='gray'); \n                    plt.title('original image'); plt.axis('off')\n                    \n                # reconstred image\n                plt.subplot(3,numReconstructionsPerFigure,1*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(reconstructedImage); plt.title('reconstructed signal')\n                else:\n                    plt.imshow(reconstructedImage, cmap='gray'); \n                    plt.title('reconstructed image'); plt.axis('off')\n\n                # diff image\n                plt.subplot(3,numReconstructionsPerFigure,2*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(diffImage); plt.title('abs difference signal')\n                else:\n                    plt.imshow(diffImage, cmap='gray'); \n                    plt.title('abs difference image'); plt.axis('off')\n            plt.tight_layout()\n\n    # shows distrbution along the variance directions and several images along that variance direction\n    def ShowModelVariations(self, numVariations=5):\n\n        showAsTraces = (np.shape(self.objectPixels)[0] == 1)\n        numVariations = min(numVariations, self.numBasisFunctions)\n                \n        numVarsPerFigure = min(5,numVariations)\n        numFigures = int(np.ceil(float(numVariations)/numVarsPerFigure))\n        \n        lowRepVec     = np.percentile(self.dataRepresentation, 2, axis=0)\n        medianRepVec  = np.percentile(self.dataRepresentation, 50, axis=0)\n        highRepVec    = np.percentile(self.dataRepresentation, 98, axis=0)\n\n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotCol in range(numVarsPerFigure):\n                eigVecInd = numVarsPerFigure*figureInd+plotCol\n                if eigVecInd >= self.numBasisFunctions:\n                    break\n\n                # create the low and high precentile representation activation vectors\n                currLowPrecentileRepVec             = medianRepVec.copy()\n                currLowPrecentileRepVec[eigVecInd]  = lowRepVec[eigVecInd]\n                currHighPrecentileRepVec            = medianRepVec.copy()\n                currHighPrecentileRepVec[eigVecInd] = highRepVec[eigVecInd]\n\n                # create blank images\n                deltaImage          = np.zeros(np.shape(self.objectPixels))\n                medianImage         = np.zeros(np.shape(self.objectPixels))\n                lowPrecentileImage  = np.zeros(np.shape(self.objectPixels))\n                highPrecentileImage = np.zeros(np.shape(self.objectPixels))\n\n                # fill the object pixels with the relevant data\n                deltaImage[self.objectPixels]          = \\\n                        self.PCAModel.components_[eigVecInd,:].ravel()\n                lowPrecentileImage[self.objectPixels]  = \\\n                        self.ReconstructUsingModel(currLowPrecentileRepVec).ravel()\n                medianImage[self.objectPixels]         = \\\n                        self.ReconstructUsingModel(medianRepVec).ravel()\n                highPrecentileImage[self.objectPixels] = \\\n                        self.ReconstructUsingModel(currHighPrecentileRepVec).ravel()\n\n                # calculate the Gaussian smoothed distribution of values along the eignevector direction\n                sigmaOfKDE = 0.12\n                pdfStart   = min(self.dataRepresentation[:,eigVecInd]) - 3*sigmaOfKDE\n                pdfStop    = max(self.dataRepresentation[:,eigVecInd]) + 3*sigmaOfKDE\n                xAxis = np.linspace(pdfStart,pdfStop,200)\n                PDF_Model = KernelDensity(kernel='gaussian', \n                                  bandwidth=sigmaOfKDE).fit(self.dataRepresentation[:,eigVecInd].reshape(-1,1))\n                logPDF = PDF_Model.score_samples(xAxis.reshape(-1,1))\n\n                # show distribution of current component \n                plt.subplot(5,numVarsPerFigure,0*numVarsPerFigure+plotCol+1)\n                plt.fill(xAxis, np.exp(logPDF), fc='b');\n                percentExplainedString = str(100*self.PCAModel.explained_variance_ratio_[eigVecInd])[0:5]\n                plt.title(percentExplainedString + '% explained'); \n                \n                # show variance direction (eigenvector)\n                plt.subplot(5,numVarsPerFigure,1*numVarsPerFigure+plotCol+1);\n                if showAsTraces:\n                    plt.plot(deltaImage); plt.title('eigenvector ' + str(eigVecInd))\n                else:\n                    plt.imshow(deltaImage, cmap='jet'); \n                    plt.title('eigenvector ' + str(eigVecInd)); plt.axis('off')\n\n                # show 2nd precentile image\n                plt.subplot(5,numVarsPerFigure,2*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(lowPrecentileImage); plt.title('2nd precentile')\n                else:\n                    plt.imshow(lowPrecentileImage, cmap='gray'); \n                    plt.title('2nd precentile image'); plt.axis('off')\n\n                # show median image\n                plt.subplot(5,numVarsPerFigure,3*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(medianImage); plt.title('median signal')\n                else:\n                    plt.imshow(medianImage, cmap='gray'); \n                    plt.title('median Image'); plt.axis('off')\n\n                # show 98th precentile image\n                plt.subplot(5,numVarsPerFigure,4*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(highPrecentileImage); plt.title('98th precentile')\n                else:\n                    plt.imshow(highPrecentileImage, cmap='gray'); \n                    plt.title('98th precentile image'); plt.axis('off')\n            plt.tight_layout()\n        \n    # shows distrbution along the variance directions and several images along that variance direction\n    def ShowSingleComponentVariation(self, X, listOfComponents=[0,1]):\n\n        showAsTraces = (np.shape(self.objectPixels)[0] == 1)\n        assert(all([(x in range(self.numBasisFunctions)) for x in listOfComponents]))\n                \n        X_rep = self.RepresentUsingModel(X)\n        \n        percentilesToShow = [1,20,40,60,80,99]\n        numReadDataSamplePerPercentile = 4\n        representationPercentiles = []\n        for percentile in percentilesToShow:\n            representationPercentiles.append(np.percentile(self.dataRepresentation, percentile, axis=0))\n        medianRepVec =  np.percentile(self.dataRepresentation, 50, axis=0)\n\n        for eigVecInd in listOfComponents:\n            plt.figure(); gs = gridspec.GridSpec(numReadDataSamplePerPercentile+2,\n                                                 len(percentilesToShow))\n\n            # calculate the Gaussian smoothed distribution of values along the eignevector direction\n            sigmaOfKDE = 0.12\n            pdfStart   = min(self.dataRepresentation[:,eigVecInd]) - 3*sigmaOfKDE\n            pdfStop    = max(self.dataRepresentation[:,eigVecInd]) + 3*sigmaOfKDE\n            xAxis = np.linspace(pdfStart,pdfStop,200)\n            PDF_Model = KernelDensity(kernel='gaussian', \n                              bandwidth=sigmaOfKDE).fit(self.dataRepresentation[:,eigVecInd].reshape(-1,1))\n            logPDF = PDF_Model.score_samples(xAxis.reshape(-1,1))\n            percentileValuesToShow = \\\n                    [representationPercentiles[x][eigVecInd] for x in range(len(representationPercentiles))]\n            percentilesToShowLogPDF = \\\n                    PDF_Model.score_samples(np.array(percentileValuesToShow).reshape(-1,1))\n\n            # show distribution of current component and red dots at the list of precentiles to show \n            plt.subplot(gs[0,:])\n            plt.fill(xAxis, np.exp(logPDF), fc='b');\n            plt.scatter(percentileValuesToShow, np.exp(percentilesToShowLogPDF), c='r',s=40);\n            plt.title(str(100*self.PCAModel.explained_variance_ratio_[eigVecInd]) + '% explained');\n            \n            for plotCol, currPrecentile in enumerate(percentilesToShow):                \n                currPrecentileRepVec             = medianRepVec.copy()\n                currPrecentileRepVec[eigVecInd]  = representationPercentiles[plotCol][eigVecInd]\n                \n                currPrecentileImage = np.zeros(np.shape(self.objectPixels))\n                currPrecentileImage[self.objectPixels] = \\\n                        self.ReconstructUsingModel(currPrecentileRepVec).ravel()\n                \n                # show the median image with current precentile as activation of the curr image\n                plt.subplot(gs[1,plotCol]);\n                if showAsTraces:\n                    plt.plot(currPrecentileImage); \n                    plt.title('precentile: ' + str(percentilesToShow[plotCol]) + '%')\n                else:\n                    plt.imshow(currPrecentileImage, cmap='gray'); \n                    plt.title('precentile: ' + str(percentilesToShow[plotCol]) + '%'); \n                    plt.axis('off')\n\n                # find the most suitible candidates in X for current precentile\n                distFromPercentile = abs(X_rep[:,eigVecInd] - \n                                         representationPercentiles[plotCol][eigVecInd])\n                X_inds = np.argpartition(distFromPercentile, \n                                         numReadDataSamplePerPercentile)[:numReadDataSamplePerPercentile]\n                for k, X_ind in enumerate(X_inds):\n                    currNearestPrecentileImage = np.zeros(np.shape(self.objectPixels))\n                    currNearestPrecentileImage[self.objectPixels]  = X[X_ind,:].ravel()\n                    \n                    plt.subplot(gs[2+k,plotCol]);\n                    if showAsTraces:\n                        plt.plot(currNearestPrecentileImage); \n                        plt.title('NN with closest percentile');\n                    else:\n                        plt.imshow(currNearestPrecentileImage, cmap='gray'); \n                        plt.title('NN with closest percentile'); plt.axis('off')\n            plt.tight_layout()\n            \n    def ShowDataScatterPlotsWithTSNE(self, X=None, y=None, tSNE_perplexity=30.0, colorMap='Paired'):\n        \n        if X is None:\n            X_rep = self.dataRepresentation\n        else:\n            X_rep = self.RepresentUsingModel(X)\n            \n        if y is None:\n            y = np.ones(X_rep.shape[0])\n            \n        tSNE_PCAModel = TSNE(n_components=2, perplexity=tSNE_perplexity, random_state=0)\n        X_rep_tSNE = tSNE_PCAModel.fit_transform(X_rep) \n        (tSNE_xmin, tSNE_xmax) = (np.percentile(X_rep_tSNE[:,0], 0.3), np.percentile(X_rep_tSNE[:,0], 99.7))\n        (tSNE_ymin, tSNE_ymax) = (np.percentile(X_rep_tSNE[:,1], 0.3), np.percentile(X_rep_tSNE[:,1], 99.7))\n\n        plt.figure()\n        plt.subplot(1,2,1); \n        plt.scatter(X_rep[:,0],X_rep[:,1],c=y,cmap=colorMap,s=10,alpha=0.9)\n        plt.title('PCA representation'); plt.xlabel('PC1 coeff'); plt.ylabel('PC2 coeff')\n        plt.subplot(1,2,2); \n        plt.scatter(X_rep_tSNE[:,0],X_rep_tSNE[:,1],c=y,cmap=colorMap,s=10,alpha=0.9)\n        plt.xlim(tSNE_xmin, tSNE_xmax); plt.ylim(tSNE_ymin, tSNE_ymax);\n        plt.title('t-SNE representation'); plt.xlabel('t-SNE axis1'); plt.ylabel('t-SNE axis2')","metadata":{"_kg_hide-output":true,"collapsed":true,"_uuid":"1d48738f23b203d0acdaf81df67f9100ceac2c62","_cell_guid":"c80e25cd-829b-742e-f6a8-482aea76757a","_kg_hide-input":true}},{"cell_type":"markdown","source":"## Train The Gaussian Model (also known as PCA)","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# train the Gaussian Model \nsampleDim = np.shape(scaledDownImages)[0]*np.shape(scaledDownImages)[1]\nX = scaledDownImages.reshape(sampleDim,-1).T\n\nobjectPixelsMask = np.ones((np.shape(scaledDownImages)[0],np.shape(scaledDownImages)[1]))==1\nleaf_PCAModel = GaussianModel(X, numBasisFunctions=100, objectPixels=objectPixelsMask)","metadata":{"_kg_hide-output":true,"_uuid":"98028c6407ce3dfedd16dd7227a15749dc0cb4ea","_cell_guid":"c2a00d98-472a-e719-e4bc-37ae275a44a1"}},{"cell_type":"markdown","source":"## Now lets look at the main variance directions of the PCA\n\nThese are also known as Principal Components.  \nEach image can be though of as a different \"direction\" in the high dimensional image space","metadata":{"_uuid":"1b7d4bde992ae2eacbf389c9e796b74a58e8e666","_cell_guid":"34227248-456f-b1f6-4164-e462246af904"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"matplotlib.rcParams['font.size'] = 10\nmatplotlib.rcParams['figure.figsize'] = (12,9)\nleaf_PCAModel.ShowVarianceDirections(numDirectionsToShow=16)","metadata":{"_uuid":"332bf3b8ccf962af5d191dcbad297f97ef249ce6","_cell_guid":"018bcc67-d694-2094-e413-12b66b25a7ff"}},{"cell_type":"markdown","source":"We can see some interesting shapes arising from the data, especially the first and second row look nice, and we will soon understand exactly what these images mean. \n\nBut first, let's look at **some original images** and how the low dimensional PCA model can **reconstruct** them.","metadata":{"_uuid":"574dc2f6f90de41a57c5b3465259a129bcba6712","_cell_guid":"7b5f8094-d104-0aba-f6c1-a0b6a18bd703"}},{"cell_type":"markdown","source":"## Show some image and their model Reconstructions\n","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"matplotlib.rcParams['font.size'] = 9\nmatplotlib.rcParams['figure.figsize'] = (12,5)\nleaf_PCAModel.ShowReconstructions(X, numReconstructions=10)","metadata":{"_uuid":"0a4ef1f0a89e56ddcf6aa0cbf0aebcfdf82cfd52","_cell_guid":"384eb592-686a-8613-29d2-6f0d0c5fec6e"}},{"cell_type":"markdown","source":"From the absolute difference images on the bottom row of both plots, we can see that the main regions that cannot be reconstructed are the edges of the leafs, but the general leaf structure can be reconstructed using the 100 basis functions.\n\n**Now, let's take a closer look at how the leaf images vary around the mean image:**","metadata":{"_uuid":"9ad2126477bd2d2046bb8f4fed49e82aaf8b14a5","_cell_guid":"04c88ee9-b11d-779c-0188-0a6d1cfcb3f4"}},{"cell_type":"markdown","source":"## Show Model Variations around the Mean Image\n","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"matplotlib.rcParams['font.size'] = 9\nmatplotlib.rcParams['figure.figsize'] = (12,9)\nleaf_PCAModel.ShowModelVariations(numVariations=5)","metadata":{"_uuid":"ad951d20270f7fc46cb62b5f526c3925ce1e4bec","_cell_guid":"731c0170-8911-7489-b28c-e7607226dad3"}},{"cell_type":"markdown","source":"**For those of us unfamiliar with this kind of a plot and since this is quite a busy plot, let me explain what we see:**\n------------------------------------------------------------------------\n  \n\n\n----------\n\n\n - The upper most row contains the data distributions of each eigenvector (i.e. the histogram along that \"direction\")\n - The second row contains what we already saw in a previous plot, what we called the variance directions.\n - The forth row contains the median image of leafs. notice that this row is identical for all eigenvectors\n - The third row holds the 2nd percentile images of each eigenvector. it's easier to think of this as the median image minus the eigenvector image multiplied by some constant. i.e the image we see is the forth row image, minus the second row image, when the second row image is multiplied by a constant. The constant is chosen to show the varying degree of influence of this specific eigenvector on the \"average\" image, so we can visualize what type of variation this particular eigenvector tends to capture. 2nd percentile will subtract a relatively large absolute value from the median image, showing us what images look like when this coefficient is highly negative. 98th percentile would be just the opposite, showing us what images look like when this coefficient is at the upper end of the range. 50th percentile would give us a \"middle of the road\" effect of this coefficient.\n\n\n----------\n\n\nThis plot helps us visualize what a direction in this high dimensional image space means. For example:\n\n - **The first eigenvector** (leftmost column), we can see\n   that it **controls the difference between large radius leafs and small radius\n   leafs**. i.e we can say that some of the variance along the change of leaf radius is explained by this component.\n - The **second eigenvector** (second column from the left) controls the difference between an\n   **upright vetrically oriented leaf** and a **horizontally oriented leaf**.\n\n----------\n\nWe can now deep deeper into some interesting looking eigenvectors\n\n**Eigenvector 1:**\n------------------","metadata":{"_uuid":"b299cafa47119dec2fc33b0d7ef95a64f8e7ab0d","_cell_guid":"67673f0d-c46f-1550-7655-99d0fe568efc"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"matplotlib.rcParams['font.size'] = 6\nmatplotlib.rcParams['figure.figsize'] = (12,8)\nleaf_PCAModel.ShowSingleComponentVariation(X, listOfComponents=[0])","metadata":{"_uuid":"a4e280ce33458b67d810c1102c187d3c609b2b1e","_cell_guid":"7e15f8c5-44fb-d5f4-3b75-deef69e770de"}},{"cell_type":"markdown","source":"Lets explain what we see:\n\n - the first row shows the data distribution of the coefficients along this main variance direction. the red dots correspond to 1st, 20th, 40th, 60th, 80th and 99th percentiles of this distribution.\n - the second row is like the columns were in the previous plot. for example, we can see here in this particular case a gradual increase in leaf size from left to right.\n - the bottom 4 rows at each column hold real leaf images that have the first PCA coefficient be at the value of the corresponding percentile  of that column. for example, the left most 4 bottom pictures are leafs with a PC1 coefficient to be approximately -1.6 and the right most 4 bottom pictures are leafs with a PC1 coefficient to be approximately 2.7\n\nBy examining the the leafs that have different coefficients **we can see what this component coefficient represents**.  from the point of view of this particular component, the leaf images in the same column are very similar. we can therefore see what this particular feature \"thinks\" about similar leafs.\n\nIn this particular case we can see that it's about **leaf size** since we see **a gradual increase in leaf size from left to right**.\n\n\n----------\n\n\n**Eigenvector 2:**\n------------------\n\n","metadata":{"_uuid":"090b81bd356f313c1f9f8ae49ada0c4ff2b3d0ea","_cell_guid":"071253fe-e5a4-c5f0-e721-f19326e205c0"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"matplotlib.rcParams['font.size'] = 6\nmatplotlib.rcParams['figure.figsize'] = (12,8)\nleaf_PCAModel.ShowSingleComponentVariation(X, listOfComponents=[1])","metadata":{"_uuid":"a105cfdbb56bbea98dbe10fcd6cdb9554df47d96","_cell_guid":"a3e69802-5266-beeb-aa75-04dc3915a4ab"}},{"cell_type":"markdown","source":"Here we can see that the second principal component is about explaining the difference between vertical and horizontal leafs","metadata":{"_uuid":"de4bc084ebb9f0a3520f9856bd49c263e8c5b8dc","_cell_guid":"6216ea32-cf9d-f918-3a08-1e0c81037d4b"}},{"cell_type":"markdown","source":"**Eigenvector 4:**\n------------------","metadata":{"_uuid":"b4152cecf9cfbf0c3551597366361cddaa9f177c","_cell_guid":"cab18f4e-00b8-5d9c-39cb-62e75118c902"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"matplotlib.rcParams['font.size'] = 6\nmatplotlib.rcParams['figure.figsize'] = (12,8)\nleaf_PCAModel.ShowSingleComponentVariation(X, listOfComponents=[3])","metadata":{"_uuid":"bcbf5eba827622c066186710e4135d85df53c7f4","_cell_guid":"85b2caca-1cfd-b449-d749-2f82b077dc8e"}},{"cell_type":"markdown","source":"This is another eigenvector that is about vertical vs horizontal, but we can see on the left most column that in addition to being horizontal, these leaf images also have a pointy tip at the top (well, except from the first image)\n\n\n**EigenVector 8:**\n------------------","metadata":{"_uuid":"44acbcd9e499918a21419392dfd6a0aa59d873ca","_cell_guid":"ecdbfdba-bbe6-30aa-b467-7733379c31ba"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"matplotlib.rcParams['font.size'] = 6\nmatplotlib.rcParams['figure.figsize'] = (12,8)\nleaf_PCAModel.ShowSingleComponentVariation(X, listOfComponents=[7])","metadata":{"_uuid":"399eb24a1c1a11b7a92578a2887df62632453f6a","_cell_guid":"cf8e4022-e4c1-f6ef-8ad1-bff41a70adb6"}},{"cell_type":"markdown","source":"This one is about beeing a star like leaf","metadata":{"_uuid":"5789346efe4fcb55298b7d77c49d28e0baae398f","_cell_guid":"58a367b9-09d4-550a-e8bf-05e56fa36643"}},{"cell_type":"markdown","source":"## Show Scatter plot of Leaf images as points in high dimentional space\nOk, now that we have some grasp about these distributions, let's also visualize the scatter of the subspace that is spanned by the PCs. we will do this in two ways:\n\n - Plot the scatter plot of the **first two principal component coeffients**\n - Plot a **2D approximation** of the \"high dimensional scatter plot\" of the entire space using **t-SNE** ","metadata":{"_uuid":"98e9f37aff242c8d2daa8f312e51d5ffbcb1fc3a","_cell_guid":"cff0bb8b-3613-0f04-5519-48b0e5207e2f"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"#%% plot scatter of 2 PCs and t-SNE of all PCs (with labels as colors)\nmatplotlib.rcParams['font.size'] = 12\nmatplotlib.rcParams['figure.figsize'] = (12,8)\n\nX_train = X[trainIDs-1,:]\ny_train = trainLabels\n\nleaf_PCAModel.ShowDataScatterPlotsWithTSNE(X_train, y_train, tSNE_perplexity=10.0)","metadata":{"_uuid":"5ef4faf6a13b186c915a2d5f70719fd4ced81fcc","_cell_guid":"3e6549c4-a554-44f6-0c1e-1fba63c2bc4e"}},{"cell_type":"markdown","source":"We can see that nearby points usually have similar color and this means they have similar leaf label. This makes us confident that we can achieve at least some classification accuracy from these PCA features.\n\n\n----------\n## Show Model Accuracy as function of num PCA components\n\nNow, let's see what is the **classification accuracy** using this PCA representation if we use **different amount of PCA coefficients** for **several different types of classifiers**.","metadata":{"_uuid":"b2141113b8eaaa05f25cffae7464efaf4bc6dedc","_cell_guid":"1c1029eb-7f72-6e45-d936-e6c14e031360"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"#%% plot CV classification accuracy as function of num components used for 3 very different type of classifiers\nmatplotlib.rcParams['font.size'] = 12\nmatplotlib.rcParams['figure.figsize'] = (12,8)\n\nX_PCA = leaf_PCAModel.RepresentUsingModel(X)\n\nX_PCA_train = X_PCA[trainIDs-1,:]\ny_train = trainLabels\n\nnumPCsToUse = [1,2,4,8,16,32,64]\n\nlogReg = linear_model.LogisticRegression(C=10.0)\nkNN = neighbors.KNeighborsClassifier(n_neighbors=7)\nRF = ensemble.RandomForestClassifier(n_estimators=100)\n\nlogRegMeanAccuracy = []; kNN_MeanAccuracy = []; RF_MeanAccuracy = []\nlogRegAccuracyStd  = []; kNN_AccuracyStd  = []; RF_AccuracyStd  = []\n\nfor numPCs in numPCsToUse:\n    stratifiedCV = model_selection.StratifiedKFold(n_splits=5, random_state=1)\n    logRegAccuracy = []; kNN_Accuracy = []; RF_Accuracy = []\n    for trainInds, validInds in stratifiedCV.split(X_PCA_train, y_train):\n        X_train_cv = X_PCA_train[trainInds,:numPCs]\n        X_valid_cv = X_PCA_train[validInds,:numPCs]\n\n        y_train_cv = y_train[trainInds]\n        y_valid_cv = y_train[validInds]\n\n        logReg.fit(X_train_cv, y_train_cv)\n        kNN.fit(X_train_cv, y_train_cv)\n        RF.fit(X_train_cv, y_train_cv)\n    \n        logRegAccuracy.append(accuracy_score(y_valid_cv, logReg.predict(X_valid_cv)))\n        kNN_Accuracy.append(accuracy_score(y_valid_cv, kNN.predict(X_valid_cv)))\n        RF_Accuracy.append(accuracy_score(y_valid_cv, RF.predict(X_valid_cv)))\n\n    logRegMeanAccuracy.append(np.array(logRegAccuracy).mean())\n    logRegAccuracyStd.append(np.array(logRegAccuracy).std())\n\n    kNN_MeanAccuracy.append(np.array(kNN_Accuracy).mean())\n    kNN_AccuracyStd.append(np.array(kNN_Accuracy).std())\n\n    RF_MeanAccuracy.append(np.array(RF_Accuracy).mean()) \n    RF_AccuracyStd.append(np.array(RF_Accuracy).std())\n        \nplt.figure()\nplt.errorbar(x=numPCsToUse, y=logRegMeanAccuracy, yerr=logRegAccuracyStd)\nplt.errorbar(x=numPCsToUse, y=kNN_MeanAccuracy  , yerr=kNN_AccuracyStd)\nplt.errorbar(x=numPCsToUse, y=RF_MeanAccuracy   , yerr=RF_AccuracyStd)\nplt.xlim(min(numPCsToUse)-1,max(numPCsToUse)+1); \nplt.legend(['Logistic Regression','k Nearest Neighbor','Random Forest'],loc=2)\nplt.xlabel('num PCA Components'); \nplt.ylabel('Validation Accuracy'); \nplt.title('Accuracy as function of num PCs')","metadata":{"_uuid":"28de7984bd1ecd96dfc10e050e5f002a61dc2f7f","_cell_guid":"3ccd8f59-2478-1dce-9513-958ff604edb1"}},{"cell_type":"markdown","source":"Overall, it's evident that all classifiers achieve approximately similar performance.\n\nBut it's interesting to note the somewhat different behavior of these different classifiers as a function of number of components used. \n\nFor example, the nearest neighbor classifier flattens out early and does not benefit from additional components beyond 8, whereas the logistic regression classifier continues to increase it's performance up to around 32 components.\nThe Random Forest classifier is consistently the best performing but it also flattens out at around 32 components.","metadata":{"_uuid":"61fed6a317ac5341461787793bf6845e75734714","_cell_guid":"2fd63a23-eb3e-1ac0-1e99-cb63f631e783"}}],"metadata":{"language_info":{"pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python"},"_change_revision":0,"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"_is_fork":false}}