{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"code","execution_count":31,"metadata":{"_cell_guid":"cf50773c-6b91-8e6a-f5f9-7f03d2be4508","_active":false,"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef warn(*args, **kwargs): pass\nimport warnings\nwarnings.warn = warn\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import StratifiedShuffleSplit\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_state":"idle"},{"cell_type":"code","execution_count":32,"metadata":{"_cell_guid":"a78e7350-b022-6f0c-d39e-9f4e0c9d469f","_active":false},"outputs":[],"source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\ndf_test.head()","execution_state":"idle"},{"cell_type":"code","execution_count":33,"metadata":{"_cell_guid":"ab17775d-dbef-c8de-4228-83438154ee2f","_active":false,"collapsed":false},"outputs":[],"source":"def encode(train, test):\n    le = LabelEncoder().fit(train.species)\n    labels = le.transform(train.species)\n    classes = list(le.classes_)\n    test_ids = test.id\n    \n    train_features = train.drop(['species', 'id'], axis = 1)\n    train_target = train.species\n    test_features = test.drop(['id'], axis = 1)\n    \n    return train_features, train_target, labels, test_features, \\\n              test_ids, classes\n    \ntrain_features, train_target, labels, test_features, \\\n        test_ids, classes = encode(df_train, df_test)","execution_state":"idle"},{"metadata":{"_cell_guid":"f0d407fb-4426-27c4-1019-34a6957b01f5","_active":false,"collapsed":false},"source":"sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n\nfor train_index, cross_index in sss:\n    train_training_data, train_cross_data = train_features.values[train_index], train_features.values[cross_index]\n    train_training_target, train_cross_target = labels[train_index], labels[cross_index]\n","execution_count":34,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"ac1a740a-8fb5-4ce7-9069-46b1a11a32f7","_active":true,"collapsed":false},"source":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n\nclassifiers = [\n    KNeighborsClassifier(5),\n    SVC(kernel=\"rbf\", probability = True),\n    LinearSVC(kernel=\"linear\", probability = True),\n    NuSVC(probability = True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis()]\n\nAnalysis_cols = [\"Classifier\", \"Accuracy\", \"Log loss\"]\nanalysis = pd.DataFrame(columns = Analysis_cols)\n\nfor clf in classifiers:\n    clf.fit(train_training_data, train_training_target)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('***Results***')\n    train_prediction = clf.predict(train_cross_data)\n    acc = accuracy_score(train_cross_target, train_prediction)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_prediction = clf.predict_proba(train_cross_data)\n    ll = log_loss(train_cross_target, train_prediction)\n    print(\"Log Loss: {}\".format(ll))\n    \n    analysis = pd.DataFrame([[name, acc*100, ll]], columns = Analysis_cols)\n    \nprint('='*30)","execution_count":36,"cell_type":"code","outputs":[],"execution_state":"idle"}]}