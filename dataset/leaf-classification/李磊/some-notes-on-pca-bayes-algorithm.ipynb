{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d939a075-c4f4-6f17-db08-e3be8fd3b4fa"},"source":"The problem of Native Bayesian algorithm is : all features must be relatively independent. Originally, I directly use bayesian algorithm to classify leaves. the code and result as follows:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6e3f6b2-30b0-6e0e-ffb8-64210dc7ad39"},"outputs":[],"source":"# apply bayesian model for calculating the probability of sample\ndef BayesClassify0(testData,dicSubsetMean,dicSubsetVar,dicSubsetPbi):\n\tdicTestDataBayes = {}\n\tn = np.shape(testData)[1]\n\t#\n\tfor key in dicSubsetMean.keys():\n\t\tdataMean = dicSubsetMean[key][0]\n\t\tdataVar = dicSubsetVar[key][0]\n\t\tPBi = dicSubsetPbi[key]\n\t\ttestData = testData[0]\n\t\tPABi = [0]\n\t\tfor j in range(n):\n\t\t\tif dataVar[0,j]==0:\n\t\t\t\tbreak\n\t\t\tPAjBi = np.exp(-pow((testData[0,j]-dataMean[0,j]),2)/(2*dataVar[0,j]))/np.sqrt(2*3.1415*dataVar[0,j])\n\t\t\tif PAjBi>0:\n\t\t\t\tPABi.append(math.log(PAjBi,2))\n\t\tPBiA = sum(PABi) + PBi\n\t\tdicTestDataBayes[key] = PBiA\n\t#\n\tsortPBiA = sorted(dicTestDataBayes.iteritems(),key=operator.itemgetter(1),reverse=True)\n\treturn sortPBiA[0][0]"},{"cell_type":"markdown","metadata":{"_cell_guid":"ca91baed-5f88-9a79-5647-a23c1f0b110a"},"source":"Total test samples:49 \tavgErrCount:38 \tavgErrRate:0.789116\n\nthe above result is bad, I think the reason is that some original features are locally relevant.\nso I allpy PCA to make features irrelevant, and the run bayesian algorithm again.\nthe code and results as follows:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e0403c0-359e-ea9d-ba39-b058341ae897"},"outputs":[],"source":"# PCA\ndef pca(dataSet,topNfeat=9999):\n\tmeanVals = np.mean(dataSet,axis=0)\n\tdataRemoved = dataSet-meanVals\n\tcovMat = np.cov(dataRemoved,rowvar=0)\n\t#\n\teigVals,eigVects = np.linalg.eig(np.mat(covMat))\n\teigValInd = np.argsort(eigVals)\n\teigValInd = eigValInd[:-(topNfeat+1):-1]\n\tredEigVecs = eigVects[:,eigValInd]\n\t#\n\treduceSet = dataRemoved*redEigVecs\n\treturn reduceSet,eigVals,redEigVecs\n\ndef contribution(eigVals,tops):\n\ttotal = sum(eigVals)\n\tfor i in range(tops):\n\t\tconYi = eigVals[i]/total\n\t\tprint \"No.\",i+1,\" contribution rate:\",conYi\n\tsconYi = sum(eigVals[:i+1])/total\n\tprint \"the top \",i+1,\" contribution rate:\",sconYi,\"\\n\""},{"cell_type":"markdown","metadata":{"_cell_guid":"73f49697-eed8-4c7d-9c29-effc7048d107"},"source":"No. 1  contribution rate: 0.149800041582\n\nNo. 2  contribution rate: 0.101889003956\n\nNo. 3  contribution rate: 0.0867181502113\n\n... ...\n\nNo. 88  contribution rate: 0.000521767479293\n\nNo. 89  contribution rate: 0.000508699929438\n\nNo. 90  contribution rate: 0.000505613673714\n\nthe top  90  contribution rate: 0.99146981703\n\nTotal test samples:49 \tavgErrCount:6 \tavgErrRate:0.123810\n\n\n\nThe result is greatly improved, but still not good enough."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}