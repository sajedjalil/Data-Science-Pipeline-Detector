{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"199705d3-019d-adf9-4f52-1620daa3688f","_active":false},"source":"I've noticed that all types of features contain 64 samples. So it would be good to split them into different dimensions and after it we will have input shape (64, 3) for one sample. \n\nThe simple network described below gives 96% - 98% (depends on random initialization) accuracy on validation set with size 0.1 and  0.05467 of score in Kaggle competition on test set.","outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"8c05420f-90c5-82ff-5a69-29ed12c8112d","_active":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ndef encode(train, test):\n    label_encoder = LabelEncoder().fit(train.species)\n    labels = label_encoder.transform(train.species)\n    classes = list(label_encoder.classes_)\n\n    train = train.drop(['species', 'id'], axis=1)\n    test = test.drop('id', axis=1)\n\n    return train, labels, test, classes\n\ntrain, labels, test, classes = encode(train, test)\n\n# standardize train features\nscaler = StandardScaler().fit(train.values)\nscaled_train = scaler.transform(train.values)\n\n# split train data into train and validation\nsss = StratifiedShuffleSplit(test_size=0.1, random_state=23)\nfor train_index, valid_index in sss.split(scaled_train, labels):\n    X_train, X_valid = scaled_train[train_index], scaled_train[valid_index]\n    y_train, y_valid = labels[train_index], labels[valid_index]\n    \n\nnb_features = 64 # number of features per features type (shape, texture, margin)   \nnb_class = len(classes)\n\n# reshape train data\nX_train_r = np.zeros((len(X_train), nb_features, 3))\nX_train_r[:, :, 0] = X_train[:, :nb_features]\nX_train_r[:, :, 1] = X_train[:, nb_features:128]\nX_train_r[:, :, 2] = X_train[:, 128:]\n\n# reshape validation data\nX_valid_r = np.zeros((len(X_valid), nb_features, 3))\nX_valid_r[:, :, 0] = X_valid[:, :nb_features]\nX_valid_r[:, :, 1] = X_valid[:, nb_features:128]\nX_valid_r[:, :, 2] = X_valid[:, 128:]\n\n# Keras model with one Convolution1D layer\n# unfortunately more number of covnolutional layers, filters and filters lenght \n# don't give better accuracy\nmodel = Sequential()\nmodel.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(nb_features, 3)))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(2048, activation='relu'))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(nb_class))\nmodel.add(Activation('softmax'))\n\n\ny_train = np_utils.to_categorical(y_train, nb_class)\ny_valid = np_utils.to_categorical(y_valid, nb_class)\n\nsgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\nmodel.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n\nnb_epoch = 15\nmodel.fit(X_train_r, y_train, nb_epoch=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0c84878-55d1-bfab-fd7c-091d67c2f58c","_active":false},"outputs":[],"source":null}]}