{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"12482422-20f6-7dff-3ea7-2c291af8f6d9"},"source":"This is my first try to train a CNN network. Planed to use an Alex net, but found that it takes too long to train it on CPU. So I gived up and change to a LeNet-like CNN to get result faster. I started working on this on Sunday morning(2.26), took a day to complete"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef465dc7-56c8-d52b-a82d-23467d8d7775"},"outputs":[],"source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom keras.preprocessing import image\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input"},{"cell_type":"markdown","metadata":{"_cell_guid":"46f890e3-ce52-079f-ad85-477a495ae1f3"},"source":"# Reading data\nRead data from data_folder, and transform it into form demanded by keras"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f51e8ce2-626e-c062-3cbf-37f8635096a3"},"outputs":[],"source":"data_root = \"../input/\"\nimg_folder = data_root + 'images/'\ntrain_data = pd.read_csv(data_root + 'train.csv')\ntrain_ID = train_data['id']\ntrain_Y = train_data['species']\ntest_data = pd.read_csv(data_root + 'test.csv')\ntest_ID = test_data['id']\n\nle = LabelEncoder()\ntrain_y = le.fit_transform(train_Y)"},{"cell_type":"markdown","metadata":{"_cell_guid":"245c8906-fc70-658a-c142-46e522e6bb20"},"source":"# Preprocess img\nDownsize the img and change it into grayscale binary format to save memory.\nCentrelized the image data on the input matrices. This part I took [kaggle notebook][1] as reference.\n\n\n  [1]: https://www.kaggle.com/abhmul/leaf-classification/keras-convnet-lb-0-0052-w-visualization"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20aa2e94-8134-102d-4da3-656b1096ffaa"},"outputs":[],"source":"def resize_img(img, max_dim=96):\n    large_axis = max((0, 1), key=lambda x: img.size[x])\n    scalar = max_dim / float(img.size[large_axis])\n    resized = img.resize(\n        (int(img.size[0] * scalar), int(img.size[1] * scalar)))\n    return resized\n\n\ndef load_image_data(id_list, max_dim=96, center=True):\n    X = np.empty((len(id_list), max_dim, max_dim, 1))\n    for i, idnum in enumerate(id_list):\n        x = image.load_img(\n            (img_folder + str(idnum) + '.jpg'), grayscale=True)\n        x = image.img_to_array(resize_img(x, max_dim=max_dim))\n        height = x.shape[0]\n        width = x.shape[1]\n        if center:\n            h1 = int((max_dim - height) / 2)\n            h2 = h1 + height\n            w1 = int((max_dim - width) / 2)\n            w2 = w1 + width\n        else:\n            h1, w1 = 0, 0\n            h2, w2 = (height, width)\n        X[i, h1:h2, w1:w2, :] = x\n    return np.around(X / 255.0)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e793a0db-1799-d448-60a6-3fa4f80b12f4"},"source":"# Build the Alexnet\nBuild the Alexnet model based on descrption in [This blog (In Chinese)][1]\n\n\n  [1]: http://blog.csdn.net/sunbaigui/article/details/39938097"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c35846a3-5205-cd16-0822-50382f27930e"},"outputs":[],"source":"def AlexNex(input_layer):\n    conv_1 = Convolution2D(96, 11, 11, activation='relu', input_shape=(\n        96, 96, 1), border_mode='same', name='conv1')(input_layer)\n    max_pool_1 = MaxPooling2D((3, 3), strides=(2, 2))(conv_1)\n\n    conv_2 = Convolution2D(256, 5, 5, border_mode='same',\n                           activation='relu')(max_pool_1)\n    max_pool_2 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2)\n\n    conv_3 = Convolution2D(384, 3, 3, border_mode='same',\n                           activation='relu')(max_pool_2)\n    conv_4 = Convolution2D(384, 3, 3, border_mode='same',\n                           activation='relu')(conv_3)\n\n    conv_5 = Convolution2D(256, 3, 3, border_mode='same',\n                           activation='relu')(conv_4)\n    max_pool_5 = MaxPooling2D((3, 3), strides=(2, 2))(conv_5)\n\n    flat = Flatten()(max_pool_5)\n    dense_1 = Dense(4096, init='glorot_normal', activation='relu')(flat)\n    drop_1 = Dropout(0.5)(dense_1)\n\n    dense_2 = Dense(4096, init='glorot_normal', activation='relu')(drop_1)\n    drop_2 = Dropout(0.5)(dense_2)\n\n    output_layer = Dense(99, activation='softmax')(drop_2)\n\n    model = Model(input_layer, output_layer)\n    return model"},{"cell_type":"markdown","metadata":{"_cell_guid":"1ab04b09-2a7f-656c-d7a9-73ad92461a69"},"source":"But the training process is to slow, I start this on Sunday afternoon, and it took about 500 sec to train a epoch.\n\n    990/990 [==============================] - 548s - loss: 0.8667 - acc: 0.6970    \n    Epoch 17/50\n    128/990 [==>...........................] - ETA: 480s - loss: 0.7794 - acc: 0.7656\n    256/990 [======>.......................] - ETA: 408s - loss: 0.7746 - acc: 0.7617\n    384/990 [==========>...................] - ETA: 336s - loss: 0.7541 - acc: 0.7682\n    512/990 [==============>...............] - ETA: 265s - loss: 0.7583 - acc: 0.7715\n    640/990 [==================>...........] - ETA: 193s - loss: 0.7449 - acc: 0.7781[Cancelled]\n\nAnd 50 epoch seems not enough to convergent, so I gived up halfway and build another LeNet-like model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2966c4ab-9cc3-1467-dfb4-4b78ed97868d"},"outputs":[],"source":"def NaiveCovNet(input_layer):\n    x = Convolution2D(8, 5, 5, input_shape=(96, 96, 1),\n                      border_mode='same')(input_layer)\n    x = (Activation('relu'))(x)\n    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n\n    # Now through the second convolutional layer\n    x = (Convolution2D(32, 5, 5, border_mode='same'))(x)\n    x = (Activation('relu'))(x)\n    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n\n    # Flatten our array\n    x = Flatten()(x)\n    dense_1 = Dense(1024, init='glorot_normal', activation='relu')(x)\n    drop_1 = Dropout(0.5)(dense_1)\n\n    dense_2 = Dense(99, init='glorot_normal', activation='relu')(drop_1)\n    drop_2 = Dropout(0.5)(dense_2)\n\n    output_layer = Dense(99, activation='softmax')(drop_2)\n    model = Model(input_layer, output_layer)\n    return model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0b5e9a90-32ee-1e71-c480-ab08c418091a"},"outputs":[],"source":"input_layer = Input(shape=(96, 96, 1), name='image')\nmodel = NaiveCovNet(input_layer)\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ntrian_X = load_image_data(train_ID)\ntrain_y = to_categorical(train_y)\n\nhistory = model.fit(trian_X, train_y, nb_epoch=10, batch_size=128)\n#f_model = './model'\n#json_string = model.to_json()\n#open(os.path.join(f_model, 'model.json'), 'w').write(json_string)\n#print('save weights')\n#model.save_weights(os.path.join(f_model, 'model_weights.hdf5'))"},{"cell_type":"markdown","metadata":{"_cell_guid":"e03656a2-1702-8c7b-b8f9-caa751504052"},"source":"This model took about 20 min to trian for 100 epoch, and get such result:\n\n    Epoch 91/100\n    990/990 [==============================] - 16s - loss: 0.0933 - acc: 0.9727\n    Epoch 92/100\n    990/990 [==============================] - 17s - loss: 0.0869 - acc: 0.9768\n    Epoch 93/100\n    990/990 [==============================] - 16s - loss: 0.0849 - acc: 0.9737\n    Epoch 94/100\n    990/990 [==============================] - 17s - loss: 0.0925 - acc: 0.9727\n    Epoch 95/100\n    990/990 [==============================] - 17s - loss: 0.0859 - acc: 0.9747\n    Epoch 96/100\n    990/990 [==============================] - 17s - loss: 0.0858 - acc: 0.9758\n    Epoch 97/100\n    990/990 [==============================] - 17s - loss: 0.0662 - acc: 0.9798\n    Epoch 98/100\n    990/990 [==============================] - 17s - loss: 0.0896 - acc: 0.9758\n    Epoch 99/100\n    990/990 [==============================] - 16s - loss: 0.0763 - acc: 0.9737\n    Epoch 100/100\n    990/990 [==============================] - 17s - loss: 0.0725 - acc: 0.9778\n    save weights\n\nIt did prety well on training set so I save the weight for further use."},{"cell_type":"markdown","metadata":{"_cell_guid":"37b87822-e9c1-8af7-1f3e-10cbc7887c01"},"source":"Predict and save result"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0ecce33b-cdd3-ea88-cbe9-d6ba126b4db7"},"outputs":[],"source":"#from keras.models import model_from_json\n#f_model = './model'\n#model_filename = 'cnn_model.json'\n#weights_filename = 'cnn_model_weights.hdf5'\n#json_string = open(os.path.join(f_model, model_filename)).read()\n#model = model_from_json(json_string)\n\n#model.summary()\n\n#model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#model.load_weights(os.path.join(f_model,weights_filename))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b19d0946-3adc-6916-c371-ce71e519ba7a"},"outputs":[],"source":"X_test = load_image_data(test_ID)\nCNN_pred = model.predict(X_test)\nLABELS = sorted(pd.read_csv(os.path.join(data_root, 'train.csv')).species.unique())\nsave_File = pd.DataFrame(CNN_pred,index=test_ID,columns=LABELS)\nsave_File.to_csv(\"submission.csv\", index=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a578f054-7df6-6bb9-df0d-d15fa3b53964"},"source":"This is my first time try out CNN method, the result is not ideal, and I plan to improve it with the following method:\n\n - Apply data augment to training set. 990 examples is far from enough,\n   maybe I should try keras pre-built method ImageDataGenerator. \n - Use a machine with GPU and use model like VGG-16 net or Resnet. \n - I have found many pretrained model based on imagenet on Internet. Modify some top layers and fin-tuned them could have better output.\n - Use CNN to extract feathers and combined it with other manully selected feather in dataset.\n\nThis is just a learning process of buliding and training CNN network so I didn't focus on getting better socre and utlizing avalible data."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}