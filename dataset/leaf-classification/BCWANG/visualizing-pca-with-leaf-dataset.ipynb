{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3f7fe7df-1326-d944-2ec5-22c5c9155822"},"source":"***Visualizing PCA with Leaf Dataset***\n================================\n\nIn this script we will apply PCA on leaf images and try to get a feel for the distribution of leaf images using visualizations that (hopefully) clarify different aspects about how to interpret PCA results.\n\nWe will then continue to see if the PCA features are informative in terms of classifying leafs and determine how many of those we need."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0c7a02b-f9b6-f3e8-7b9a-67d34671ef7e"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nfrom sklearn import model_selection\nfrom sklearn import decomposition\nfrom sklearn import linear_model\nfrom sklearn import ensemble\nfrom sklearn import neighbors\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KernelDensity\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import accuracy_score\n\nfrom skimage.transform import rescale\nfrom scipy import ndimage as ndi\n\nmatplotlib.style.use('fivethirtyeight')"},{"cell_type":"markdown","metadata":{"_cell_guid":"347f2648-d405-9620-505c-c7d91d1f9b70"},"source":"**For the sake of the script not being too cluttered, I commented out all intermediate plots in the data loading and preparation phases**\n\nanyone who is interested is welcome to fork and uncomment to see what is going on.\n\n(the main assumption of this pre-processing stage is that the absolute sizes of the leafs matter, and not just their shape. i.e. leafs with different sizes are most definitely different types of leafs. not sure if it's actually important, but just in case)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a77bab6e-468f-ed20-10fb-3305ae95ee9b"},"outputs":[],"source":"#%% load the data\ndataDir = '../input/'\ntrainData = pd.read_csv(dataDir + 'train.csv')\nclassEncoder = LabelEncoder()\ntrainLabels = classEncoder.fit_transform(trainData.ix[:,'species'])\ntrainIDs = np.array(trainData.ix[:,'id'])\n\n#plt.figure()\n#for k in range(28):\n#    randTrainInd = np.random.randint(len(trainIDs))\n#    randomID = trainIDs[randTrainInd]\n#    imageFilename = dataDir + 'images/' + str(randomID) + '.jpg'\n#    plt.subplot(4,7,k+1); plt.imshow(mpimg.imread(imageFilename), cmap='gray')\n#    plt.title(classEncoder.classes_[trainLabels[randTrainInd]]); plt.axis('off')\n\n##%% go over training images and store them in a list\nnumImages = 1584\n\nshapesMatrix = np.zeros((2,numImages))\nlistOfImages = []\nfor k in range(numImages):\n    imageFilename = dataDir + 'images/' + str(k+1) + '.jpg'\n    currImage = mpimg.imread(imageFilename)\n    shapesMatrix[:,k] = np.shape(currImage)\n    listOfImages.append(currImage)\n    \n# create a large 3d array with all images\nmaxShapeSize = shapesMatrix.max(axis=1)\nfor k in range(len(maxShapeSize)):\n    if maxShapeSize[k] % 2 == 0:\n        maxShapeSize[k] += 311\n    else:\n        maxShapeSize[k] += 310\n    \nfullImageMatrix3D = np.zeros(np.hstack((maxShapeSize,np.shape(shapesMatrix[1]))).astype(int),dtype=np.dtype('u1'))\ndestXc = (maxShapeSize[1]+1)/2; destYc = (maxShapeSize[0]+1)/2\nfor k, currImage in enumerate(listOfImages):\n    Yc, Xc = ndi.center_of_mass(currImage)\n    Xd = destXc - Xc; Yd = destYc - Yc\n    fullImageMatrix3D[round(Yd):round(Yd)+np.shape(currImage)[0],round(Xd):round(Xd)+np.shape(currImage)[1],k] = currImage\n\n#plt.figure()\n#for k in range(28):\n#    randInd = np.random.randint(np.shape(fullImageMatrix3D)[2])\n#    plt.subplot(4,7,k+1); plt.imshow(fullImageMatrix3D[:,:,randInd], cmap='gray'); plt.axis('off')\n\n##%% remove redundent rows and columns\n#plt.figure(); \n#plt.subplot(1,2,1); plt.imshow(fullImageMatrix3D.mean(axis=2),cmap='gray'); plt.axis('off')\n#plt.subplot(1,2,2); plt.imshow(fullImageMatrix3D.mean(axis=2) > 0,cmap='gray'); plt.axis('off')\n\nxValid = fullImageMatrix3D.mean(axis=2).sum(axis=0) > 0\nyValid = fullImageMatrix3D.mean(axis=2).sum(axis=1) > 0\nxLims = (np.nonzero(xValid)[0][0],np.nonzero(xValid)[0][-1])\nyLims = (np.nonzero(yValid)[0][0],np.nonzero(yValid)[0][-1])\nfullImageMatrix3D = fullImageMatrix3D[yLims[0]:yLims[1],xLims[0]:xLims[1],:]\n\n#plt.figure()\n#for k in range(28):\n#    randInd = np.random.randint(np.shape(fullImageMatrix3D)[2])\n#    plt.subplot(4,7,k+1); plt.imshow(fullImageMatrix3D[:,:,randInd], cmap='gray'); plt.axis('off')\n\n##%% scale down all images\nrescaleFactor = 0.15\n\nscaledDownImage = rescale(fullImageMatrix3D[:,:,0],rescaleFactor)\nscaledDownImages = np.zeros(np.hstack((np.shape(scaledDownImage),np.shape(fullImageMatrix3D)[2])),dtype=np.dtype('f4'))\nfor imInd in range(np.shape(fullImageMatrix3D)[2]):\n    scaledDownImages[:,:,imInd] = rescale(fullImageMatrix3D[:,:,imInd],rescaleFactor)\n    \ndel fullImageMatrix3D"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e6ffe82-b590-d33a-9311-ad7de33d3942"},"outputs":[],"source":"np.random.seed(1) # use a nice looking random seed\n\nmatplotlib.rcParams['font.size'] = 4\nmatplotlib.rcParams['figure.figsize'] = (9,7)    \nplt.figure();\nfor k in range(25):\n    randInd = np.random.randint(np.shape(scaledDownImages)[2])\n    plt.subplot(5,5,k+1); plt.imshow(scaledDownImages[:,:,randInd], cmap='gray'); plt.axis('off')\n    plt.title('imageID = ' + str(randInd))\nplt.tight_layout()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c80e25cd-829b-742e-f6a8-482aea76757a"},"outputs":[],"source":"#%% define GaussianModel class\n\nclass GaussianModel:\n    def __init__(self, X, numBasisFunctions=10, objectPixels=None):\n        '''\n        inputs: \n            X                    - numSamples x numDimentions matrix\n            numBasisFunctions       - number of basis function to use\n            objectPixels (optional) - an binnary mask image used for presentation\n                                      will be used as Im[objectPixels] = dataSample\n                                      must satisfy objectPixels.ravel().sum() = X.shape[1]\n        '''\n        \n        self.numBasisFunctions = numBasisFunctions        \n        if objectPixels == None:\n            self.objectPixels = np.ones((1,X.shape[1]),dtype=np.bool)\n        else:\n            self.objectPixels = objectPixels\n        assert(self.objectPixels.ravel().sum() == X.shape[1])\n\n        PCAModel = decomposition.PCA(n_components=numBasisFunctions, whiten=True)\n        self.dataRepresentation = PCAModel.fit_transform(X)\n        self.PCAModel = PCAModel\n\n    def RepresentUsingModel(self, X):\n        return self.PCAModel.transform(X)\n\n    def ReconstructUsingModel(self, X_transformed):\n        return self.PCAModel.inverse_transform(X_transformed)\n\n    def InterpretUsingModel(self, X):\n        return self.PCAModel.inverse_transform(self.PCAModel.transform(X))\n\n    # shows the eigenvectors of the gaussian covariance matrix\n    def ShowVarianceDirections(self, numDirectionsToShow=16):\n        numDirectionsToShow = min(numDirectionsToShow, self.numBasisFunctions)\n        \n        numFigRows = 4; numFigCols = 4;\n        numDirectionsPerFigure = numFigRows*numFigCols\n        numFigures = int(np.ceil(float(numDirectionsToShow)/numDirectionsPerFigure))\n        \n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotInd in range(numDirectionsPerFigure):\n                eigVecInd = numDirectionsPerFigure*figureInd + plotInd\n                if eigVecInd >= self.numBasisFunctions:\n                    break\n                deltaImage = np.zeros(np.shape(self.objectPixels))\n                deltaImage[self.objectPixels] = self.PCAModel.components_[eigVecInd,:].ravel()\n\n                plt.subplot(numFigRows,numFigCols,plotInd+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(deltaImage)\n                else:\n                    plt.imshow(deltaImage); plt.axis('off')\n                plt.title(str(100*self.PCAModel.explained_variance_ratio_[eigVecInd]) + '% explained');\n            plt.tight_layout()\n            \n    # shows several random model reconstructions\n    def ShowReconstructions(self, X, numReconstructions=5):\n        assert(np.shape(X)[1] == self.objectPixels.ravel().sum())\n        numSamples = np.shape(X)[0]\n        numReconstructions = min(numReconstructions, numSamples)\n        \n        originalImage      = np.zeros(np.shape(self.objectPixels))\n        reconstructedImage = np.zeros(np.shape(self.objectPixels))\n        \n        numReconstructionsPerFigure = min(5, numReconstructions)\n        numFigures = int(np.ceil(float(numReconstructions)/numReconstructionsPerFigure))\n        \n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotCol in range(numReconstructionsPerFigure):\n                dataSampleInd = np.random.randint(numSamples)\n                originalImage[self.objectPixels] = X[dataSampleInd,:].ravel()\n                reconstructedImage[self.objectPixels] = self.InterpretUsingModel(np.reshape(X[dataSampleInd,:],[1,-1])).ravel()\n                diffImage = abs(originalImage - reconstructedImage)\n                \n                # original image\n                plt.subplot(3,numReconstructionsPerFigure,0*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(originalImage); plt.title('original signal')\n                else:\n                    plt.imshow(originalImage, cmap='gray'); plt.title('original image'); plt.axis('off')\n                    \n                # reconstred image\n                plt.subplot(3,numReconstructionsPerFigure,1*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(reconstructedImage); plt.title('reconstructed signal')\n                else:\n                    plt.imshow(reconstructedImage, cmap='gray'); plt.title('reconstructed image'); plt.axis('off')\n\n                # diff image\n                plt.subplot(3,numReconstructionsPerFigure,2*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(diffImage); plt.title('abs difference signal')\n                else:\n                    plt.imshow(diffImage, cmap='gray'); plt.title('abs difference image'); plt.axis('off')\n            plt.tight_layout()\n\n    # shows distrbution along the variance directions and several images along that variance direction\n    def ShowModelVariations(self, numVariations=5):\n        #matplotlib.rcParams['font.size'] = 14\n\n        showAsTraces = (np.shape(self.objectPixels)[0] == 1)\n        numVariations = min(numVariations, self.numBasisFunctions)\n                \n        numVarsPerFigure = min(5,numVariations)\n        numFigures = int(np.ceil(float(numVariations)/numVarsPerFigure))\n        \n        lowRepVec     = np.percentile(self.dataRepresentation, 2, axis=0)\n        medianRepVec  = np.percentile(self.dataRepresentation, 50, axis=0)\n        highRepVec    = np.percentile(self.dataRepresentation, 98, axis=0)\n\n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotCol in range(numVarsPerFigure):\n                eigVecInd = numVarsPerFigure*figureInd+plotCol\n                if eigVecInd >= self.numBasisFunctions:\n                    break\n\n                # create the low and high precentile representation activation vectors\n                currLowPrecentileRepVec             = medianRepVec.copy()\n                currLowPrecentileRepVec[eigVecInd]  = lowRepVec[eigVecInd]\n                currHighPrecentileRepVec            = medianRepVec.copy()\n                currHighPrecentileRepVec[eigVecInd] = highRepVec[eigVecInd]\n\n                # create blank images\n                deltaImage          = np.zeros(np.shape(self.objectPixels))\n                medianImage         = np.zeros(np.shape(self.objectPixels))\n                lowPrecentileImage  = np.zeros(np.shape(self.objectPixels))\n                highPrecentileImage = np.zeros(np.shape(self.objectPixels))\n\n                # fill the object pixels with the relevant data\n                deltaImage[self.objectPixels]          = self.PCAModel.components_[eigVecInd,:].ravel()\n                lowPrecentileImage[self.objectPixels]  = self.ReconstructUsingModel(currLowPrecentileRepVec).ravel()\n                medianImage[self.objectPixels]         = self.ReconstructUsingModel(medianRepVec).ravel()\n                highPrecentileImage[self.objectPixels] = self.ReconstructUsingModel(currHighPrecentileRepVec).ravel()\n\n                # calculate the Gaussian smoothed distribution of values along the eignevector direction\n                sigmaOfKDE = 0.12\n                pdfStart   = min(self.dataRepresentation[:,eigVecInd]) - 3*sigmaOfKDE\n                pdfStop    = max(self.dataRepresentation[:,eigVecInd]) + 3*sigmaOfKDE\n                xAxis = np.linspace(pdfStart,pdfStop,200)\n                PDF_Model = KernelDensity(kernel='gaussian', bandwidth=sigmaOfKDE).fit(self.dataRepresentation[:,eigVecInd].reshape(-1,1))\n                logPDF = PDF_Model.score_samples(xAxis.reshape(-1,1))\n\n                # show distribution of current component \n                plt.subplot(5,numVarsPerFigure,0*numVarsPerFigure+plotCol+1)\n                plt.fill(xAxis, np.exp(logPDF), fc='b');\n                plt.title(str(100*self.PCAModel.explained_variance_ratio_[eigVecInd]) + '% explained'); \n                \n                # show variance direction (eigenvector)\n                plt.subplot(5,numVarsPerFigure,1*numVarsPerFigure+plotCol+1);\n                if showAsTraces:\n                    plt.plot(deltaImage); plt.title('eigenvector ' + str(eigVecInd))\n                else:\n                    plt.imshow(deltaImage); plt.title('eigenvector ' + str(eigVecInd)); plt.axis('off')\n\n                # show 2nd precentile image\n                plt.subplot(5,numVarsPerFigure,2*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(lowPrecentileImage); plt.title('2nd precentile')\n                else:\n                    plt.imshow(lowPrecentileImage, cmap='gray'); plt.title('2nd precentile image'); plt.axis('off')\n\n                # show median image\n                plt.subplot(5,numVarsPerFigure,3*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(medianImage); plt.title('median signal')\n                else:\n                    plt.imshow(medianImage, cmap='gray'); plt.title('median Image'); plt.axis('off')\n\n                # show 98th precentile image\n                plt.subplot(5,numVarsPerFigure,4*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(highPrecentileImage); plt.title('98th precentile')\n                else:\n                    plt.imshow(highPrecentileImage, cmap='gray'); plt.title('98th precentile image'); plt.axis('off')\n            plt.tight_layout()\n        \n    # shows distrbution along the variance directions and several images along that variance direction\n    def ShowSingleComponentVariation(self, X, listOfComponents=[0,1]):\n        #matplotlib.rcParams['font.size'] = 14\n\n        showAsTraces = (np.shape(self.objectPixels)[0] == 1)\n        assert(all([(x in range(self.numBasisFunctions)) for x in listOfComponents]))\n                \n        X_rep = self.RepresentUsingModel(X)\n        \n        percentilesToShow = [1,20,40,60,80,99]\n        numReadDataSamplePerPercentile = 4\n        representationPercentiles = []\n        for percentile in percentilesToShow:\n            representationPercentiles.append(np.percentile(self.dataRepresentation, percentile, axis=0))\n        medianRepVec =  np.percentile(self.dataRepresentation, 50, axis=0)\n\n        for eigVecInd in listOfComponents:\n            plt.figure(); gs = gridspec.GridSpec(numReadDataSamplePerPercentile+2,len(percentilesToShow))\n\n            # calculate the Gaussian smoothed distribution of values along the eignevector direction\n            sigmaOfKDE = 0.12\n            pdfStart   = min(self.dataRepresentation[:,eigVecInd]) - 3*sigmaOfKDE\n            pdfStop    = max(self.dataRepresentation[:,eigVecInd]) + 3*sigmaOfKDE\n            xAxis = np.linspace(pdfStart,pdfStop,200)\n            PDF_Model = KernelDensity(kernel='gaussian', bandwidth=sigmaOfKDE).fit(self.dataRepresentation[:,eigVecInd].reshape(-1,1))\n            logPDF = PDF_Model.score_samples(xAxis.reshape(-1,1))\n            percentileValuesToShow = [representationPercentiles[x][eigVecInd] for x in range(len(representationPercentiles))]\n            percentilesToShowLogPDF = PDF_Model.score_samples(np.array(percentileValuesToShow).reshape(-1,1))\n\n            # show distribution of current component and red dots at the list of precentiles to show \n            plt.subplot(gs[0,:])\n            plt.fill(xAxis, np.exp(logPDF), fc='b');\n            plt.scatter(percentileValuesToShow, np.exp(percentilesToShowLogPDF), c='r',s=40);\n            plt.title(str(100*self.PCAModel.explained_variance_ratio_[eigVecInd]) + '% explained');\n            \n            for plotCol, currPrecentile in enumerate(percentilesToShow):                \n                currPrecentileRepVec             = medianRepVec.copy()\n                currPrecentileRepVec[eigVecInd]  = representationPercentiles[plotCol][eigVecInd]\n                \n                currPrecentileImage = np.zeros(np.shape(self.objectPixels))\n                currPrecentileImage[self.objectPixels]  = self.ReconstructUsingModel(currPrecentileRepVec).ravel()\n                \n                # show the median image with current precentile as activation of the curr image\n                plt.subplot(gs[1,plotCol]);\n                if showAsTraces:\n                    plt.plot(currPrecentileImage); plt.title('precentile: ' + str(percentilesToShow[plotCol]) + '%')\n                else:\n                    plt.imshow(currPrecentileImage, cmap='gray'); plt.title('precentile: ' + str(percentilesToShow[plotCol]) + '%'); plt.axis('off')\n\n                # find the most suitible candidates in X for current precentile\n                distFromPercentile = abs(X_rep[:,eigVecInd] - representationPercentiles[plotCol][eigVecInd])\n                X_inds = np.argpartition(distFromPercentile, numReadDataSamplePerPercentile)[:numReadDataSamplePerPercentile]\n                for k, X_ind in enumerate(X_inds):\n                    currNearestPrecentileImage = np.zeros(np.shape(self.objectPixels))\n                    currNearestPrecentileImage[self.objectPixels]  = X[X_ind,:].ravel()\n                    \n                    plt.subplot(gs[2+k,plotCol]);\n                    if showAsTraces:\n                        plt.plot(currNearestPrecentileImage); plt.title('NN with closest percentile');\n                    else:\n                        plt.imshow(currNearestPrecentileImage, cmap='gray'); plt.title('NN with closest percentile'); plt.axis('off')\n            plt.tight_layout()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"018bcc67-d694-2094-e413-12b66b25a7ff"},"outputs":[],"source":"matplotlib.rcParams['font.size'] = 4\nmatplotlib.rcParams['figure.figsize'] = (8,6)\nleaf_PCAModel.ShowVarianceDirections(numDirectionsToShow=16)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}