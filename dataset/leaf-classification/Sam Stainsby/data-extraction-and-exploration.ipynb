{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3c0b8314-465d-640d-f803-d9998f496bf8"},"source":"### A quick look at the data for my first Kaggle script."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c6077d2d-d5c6-3f01-4deb-a7d480c0f633"},"outputs":[],"source":"import pandas\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import misc\n\nINPUT_IMAGE_SIZE = 300 # pixels; we will resize and embed all input images into a square of this size"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5fb34a4-ffd7-05bb-f0b1-9d176d3e6251"},"outputs":[],"source":"train_metadata = pandas.read_csv('../input/train.csv')\ntest_metadata = pandas.read_csv('../input/test.csv')\ntrain_metadata"},{"cell_type":"markdown","metadata":{"_cell_guid":"5ad485fc-d369-1fd7-af7c-1cec949f25bd"},"source":"Ignore all feature columns and just use the 'id' and 'species' columns:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4151087a-9829-0c65-35b2-92b4700efa4b"},"outputs":[],"source":"train_ids = train_metadata['id']\ntrain_species = train_metadata['species']\n\nspecies = list(set(train_species))\nspecies.sort()\nnum_species = len(species)\n\nprint('Read %i training samples of %i species.' % (len(train_ids), num_species))\n\ntest_ids = test_metadata['id']\n\nprint('Read %i testing samples.' % len(test_ids))\n\n# some useful maps\n\nspecies_name_2_species_id_map = {}\nspecies_name_2_sample_ids_map = {}\nsample_id_2_species_id_map = {}\nsample_id_2_species_name_map = {}\n\nfor id, name in zip(range(len(species)), species):\n    species_name_2_species_id_map[name] = id\n\nfor i in range(len(train_ids)):\n    sample_id = train_ids[i]\n    species_name = train_species[i]\n    species_id = species_name_2_species_id_map[species_name]\n    if not species_name_2_sample_ids_map.get(species_name, None):\n        species_name_2_sample_ids_map[species_name] = []\n    species_name_2_sample_ids_map[species_name].append(sample_id)\n    sample_id_2_species_id_map[sample_id] = species_id\n    sample_id_2_species_name_map[sample_id] = species_name"},{"cell_type":"markdown","metadata":{"_cell_guid":"61198bd7-a12b-c3e2-bb6a-7a472a3dc3fc"},"source":"How many of each species? We will see there are **exactly ten samples per species**, and so later we should be careful to use stratified sampling."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed1a0f19-88cf-ef74-dd89-d228c535193c"},"outputs":[],"source":"species_counts = [len(species_name_2_sample_ids_map[name]) for name in species]\nprint('Distinct counts per species: %s' % set(np.unique(species_counts)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"0314a4d6-81b1-e3ae-93f0-bdbcfd4e481f"},"source":"### Cleaning up the image data\n\nNow we read all of the image data into memory. We'll see that the images are not properly thresholded, and that there are noisy pixels around the edges of the leaf shapes. This is likely due to JPEG compression artefacts - the provider would have been better off using PNG. Mostly these have values close to zero, with a few near 255 (you typically need to look *very* closely at the histogram near 255, if it is visible at all). We fix the thresholding as we read in the images.\n\nAfter correcting the threshold, the images are each embedded into a `INPUT_IMAGE_SIZE Ã— INPUT_IMAGE_SIZE` square image, which is the standard input resolution we will use during training and evaluation. The values are then normalised on a per-image basis. Lastly, we add a channel dimension of size 1, as our CNNs in Tensorflow that we intend to create later will need this."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"369f1b66-a5d1-198d-9568-53e6e8cd8a16"},"outputs":[],"source":"sample_ids = list(set(train_ids).union(set(test_ids)))\nsample_id_to_image_map = {}\n\n\n# Creates an image in a fixed squared shape with normalised pixel values.\ndef standardise_image(im, size = INPUT_IMAGE_SIZE):\n    \n    # Resize the original image if necessary\n    \n    major_axis = np.max(im.shape)\n    if major_axis > size:\n        resize_factor = size/major_axis\n        im = misc.imresize(im, resize_factor, interp='bilinear')\n    im_height, im_width = im.shape\n    offset_y = (size - im_height)//2\n    offset_x = (size - im_width)//2\n    im_sqr = np.zeros((size, size), dtype=np.float)\n    im_sqr[offset_y:(offset_y + im_height), offset_x:(offset_x + im_width)] = im\n    im = im_sqr\n    \n    # Normalise - this is essential the same as tensoflow's tf.image.per_image_standardization\n    \n    mean = np.mean(im)\n    stddev = np.std(im)\n    adjusted_stddev = np.max([stddev, 1.0/np.sqrt(im.size)])\n    im = (im - mean)/adjusted_stddev\n    \n    # Add a channel dimension of size 1\n    \n    im = im.reshape(size, size, 1)\n    \n    return im\n\n\ndef read_images():\n    np.random.shuffle(sample_ids)\n    print('Number of images to read:', len(sample_ids))\n    sample_id_to_image_map = {}\n    is_first = True\n    image_read_count = 0\n    for id in sample_ids:\n        im0 = misc.imread('../input/images/' + str(id) + '.jpg', mode='L')\n        image_read_count += 1\n        # ensure properly thresholded\n        im = 1*(im0 >= 128)\n        if is_first:\n            is_first = False\n            # these input images are not properly thesholded - this will show it:\n            dirty_pixels = 1*(im0 > 0)*(im0 < 255)\n            im_dirty = im0*dirty_pixels\n            print('Showing a random example:')\n            print('Shape of image:', im.shape, '; id =', id)\n            f, ((dx1, dx2), (ax1, ax2)) = plt.subplots(2, 2, figsize=(9, 9))\n            dx1.imshow(dirty_pixels, cmap='gray')\n            dx1.set_title('locations of values not zero or 255')\n            dx2.hist(im_dirty.flatten(), bins=64, edgecolor='red', facecolor='red')\n            dx2.set_title('value histogram')\n            ax1.imshow(im, cmap='gray')\n            ax1.set_title('thresholded image')\n            _, _, bars = ax2.hist(im.flatten(), bins=2)\n            bars[0].set_facecolor('black')\n            bars[-1].set_facecolor('white')\n            ax2.set_title('value histogram')\n            plt.show()\n            print('Reading in remaining images ...')\n\n        sample_id_to_image_map[id] = standardise_image(im)\n\n    print('Finished reading images - read %d images.' % image_read_count)\n    assert image_read_count == len(sample_ids), 'read the wrong number of images'\n    \n    return sample_id_to_image_map\n\n\nsample_id_to_image_map = read_images()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a158f288-c757-1674-6db2-3992f1cbb47c"},"outputs":[],"source":"# Just a test\ndef test_original_images():\n    print('An input image chosen at random:')\n    im = sample_id_to_image_map[np.random.choice(sample_ids)]\n    plt.figure(figsize=(300/90, 300/90), dpi=90)\n    # we need to squeeze out the channel dimanesion that we added\n    plt.imshow(np.squeeze(im), cmap='gray')\n    plt.show()\n    print('Some more input images:')\n    rows = 6\n    for k in range(rows):\n        _, axs = plt.subplots(1, 9, figsize=(9, 2))\n        for i, ax in zip(range(len(axs)), axs):\n            im = sample_id_to_image_map[sample_ids[i + k*rows]]\n            ax.imshow(np.squeeze(im), cmap='gray')\n            ax.get_xaxis().set_ticks([])\n            ax.get_yaxis().set_ticks([])\n        plt.show()\n\n\ntest_original_images() # just a test"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a906250-9505-28e7-784a-2431157f55be"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}