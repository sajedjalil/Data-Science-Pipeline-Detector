{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f7c93524-2268-d46a-3386-321b5f7f3309"},"source":"## Introduction ##\nThe idea here is to use a bag of visual words model to classify the different images. We will use SIFT algorithm to extract the keypoints of each image and create the bag of words.<br>\nMore information about this method can be found here:<br><ul>\n<li>http://www.cs.cmu.edu/~16385/lectures/Lecture12.pdf</li>\n<li>https://www.youtube.com/watch?v=iGZpJZhqEME</li>\n\nSome part of this script are inside function, it's just a way to avoid error when I will publish this notebook. If you want to use this script, just remove line starting by \"def ...\"."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4fd239a0-39fd-7bc4-4ed3-d3bf87c21305"},"outputs":[],"source":"import cv2\nimport numpy as np\nimport os\nimport pandas as pd\nimport csv\n\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.neural_network import MLPClassifier"},{"cell_type":"markdown","metadata":{"_cell_guid":"bd3316dd-1e7c-5acc-8d86-48e6704b42ee"},"source":"To do it, we will use OpenCV (cv2) library to extract keypoints with SIFT algorithm."},{"cell_type":"markdown","metadata":{"_cell_guid":"0849ae08-ff33-bd8c-abb2-db52e1441eee"},"source":"## Extract keypoints from each image ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd6c53d2-0822-fd32-7a20-447d485ebafe"},"outputs":[],"source":"img_path = '../input/images/'\ntrain = pd.read_csv('../input/train.csv')\nspecies = train.species.sort_values().unique()\n\ndico = []\n\ndef step1():\n    for leaf in train.id:\n        img = cv2.imread(img_path + str(leaf) + \".jpg\")\n        kp, des = sift.detectAndCompute(img, None)\n\n        for d in des:\n            dico.append(d)"},{"cell_type":"markdown","metadata":{"_cell_guid":"58b3257e-6916-0ed0-bdb5-9c23dd6e0ab8"},"source":"## Clustering  ##\nWe now have an array with a huge number of descriptors. We cannot use all of them to create or model so we need to cluster them. A rule-of-thumb is to create k centers with k = number of categories * 10 (in our case, it's 990)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca3fc57e-e7f1-1d10-70fb-0b521b2da700"},"outputs":[],"source":"def step2():\n    k = np.size(species) * 10\n\n    batch_size = np.size(os.listdir(img_path)) * 3\n    kmeans = MiniBatchKMeans(n_clusters=k, batch_size=batch_size, verbose=1).fit(dico)"},{"cell_type":"markdown","metadata":{"_cell_guid":"758507e5-cf26-03f6-3fab-cf55f83accfb"},"source":"I use MiniBatchKMeans to avoid Memory Error."},{"cell_type":"markdown","metadata":{"_cell_guid":"5d9b232c-af09-1673-e3f4-3869ea491321"},"source":"## Creation of the histograms ##\nTo create our each image by a histogram. We will create a vector of k value for each image. For each keypoints in an image, we will find the nearest center and increase by one its value."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47eb763e-b505-1599-2f83-50d013339a0d"},"outputs":[],"source":"def step3():\n    kmeans.verbose = False\n\n    histo_list = []\n\n    for leaf in train.id:\n        img = cv2.imread(img_path + str(leaf) + \".jpg\")\n        kp, des = sift.detectAndCompute(img, None)\n\n        histo = np.zeros(k)\n        nkp = np.size(kp)\n\n        for d in des:\n            idx = kmeans.predict([d])\n            histo[idx] += 1/nkp # Because we need normalized histograms, I prefere to add 1/nkp directly\n\n        histo_list.append(histo)"},{"cell_type":"markdown","metadata":{"_cell_guid":"5197a0cb-cb3c-0968-4521-32d6b9559a79"},"source":"## Training of the neural network ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88e782f5-8f6d-ac67-5e9e-d30eb3b99c26"},"outputs":[],"source":"def step4():\n    X = np.array(histo_list)\n    Y = []\n\n    # It's a way to convert species name into an integer\n    for s in train.species:\n        Y.append(np.min(np.nonzero(species == s)))\n\n    mlp = MLPClassifier(verbose=True, max_iter=600000)\n    mlp.fit(X, Y)"},{"cell_type":"markdown","metadata":{"_cell_guid":"4d5351d1-4609-7ebf-98cf-f48f7068e183"},"source":"## Predictions ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58247f35-2213-d774-4229-48b308c62613"},"outputs":[],"source":"def step5():\n    test = pd.read_csv('../input/test.csv')\n\n    result_file = open(\"sift.csv\", \"w\")\n    result_file_obj = csv.writer(result_file)\n    result_file_obj.writerow(np.append(\"id\", species))\n\n    for leaf in test.id:\n        img = cv2.imread(img_path + str(leaf) + \".jpg\")\n        kp, des = sift.detectAndCompute(img, None)\n\n        x = np.zeros(k)\n        nkp = np.size(kp)\n\n        for d in des:\n            idx = kmeans.predict([d])\n            x[idx] += 1/nkp\n\n        res = mlp.predict_proba([x])\n        row = []\n        row.append(leaf)\n\n        for e in res[0]:\n            row.append(e)\n\n        result_file_obj.writerow(row)\n\n    result_file.close()"},{"cell_type":"markdown","metadata":{"_cell_guid":"d10668e0-7c50-1f79-1cb4-bf4d1b87977b"},"source":"## Alternative ##\nI also run this script with ORB instead of SIFT and I got best results. To do it, just replace `cv2.xfeatures2d.SIFT_create()` by `cv2.ORB_create()`."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}