{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"727469b3-29cd-c14f-73db-c8ce9d570e45"},"source":"# Introduction\nThis notebook contains the basic usage of keras library on leaf classification"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7761a48-c526-f60f-00e4-694a3ac03e41"},"outputs":[],"source":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.preprocessing import image\nfrom keras.utils import np_utils\nfrom keras.models import Sequential, load_model\nfrom keras.layers.convolutional import ZeroPadding2D, Convolution2D, MaxPooling2D\nfrom keras.layers.core import Flatten, Dense, Dropout, Activation, Merge\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.layers.advanced_activations import ELU, LeakyReLU, ThresholdedReLU, SReLU\n\nfrom keras.callbacks import ProgbarLogger, ModelCheckpoint\n\nfrom PIL import Image\n\ntarget_size = (256, 256)\ngrayscale = True\n\n# Relative path for the train, test, and submission file\ntrain_path = '../input/train.csv'\ntest_path = '../input/test.csv'\nsubmission_path = '../input/sample_submission.csv'\nsubmission_output = './submission.csv'\n\ndef load_image(id):\n    img_path = '../input/images/%d.jpg' % (id, )\n    img = image.load_img(img_path,\n                         grayscale=grayscale)\n    img.thumbnail(target_size)\n    bg = Image.new('L', target_size, (0,))\n    bg.paste(\n        img, (int((target_size[0] - img.size[0]) / 2), int((target_size[1] - img.size[1]) / 2))\n    )\n    img_arr = image.img_to_array(bg)\n    \n    return img_arr"},{"cell_type":"markdown","metadata":{"_cell_guid":"869fd19f-c427-b5a5-c1a1-1c3fe8358600"},"source":"# Data preprocessing\nLoad data from csv file"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38836a22-1f97-605f-92ff-2cedf3501952"},"outputs":[],"source":"# Load training data\ntrain_data = pd.read_csv(train_path)\n# load the ids in the training data set\nx_ids = train_data.iloc[:, 0]\nx_images = list()\nfor i in x_ids:\n    x_images.append(load_image(i))\nx_images = np.array(x_images)\nplt.imshow(x_images[0].squeeze())\nplt.show()\nprint('Shape of images', x_images[0].shape)\n# Ignore the first column (id) and the second column (species)\nx_features = train_data.iloc[:, 2:].values\nprint('Number of features', x_features.shape[1])\n\n# Convert the species to category type\ny = train_data['species']\n# Get the corresponding categories list for species\nle = LabelEncoder()\nle.fit(y)\ny = le.transform(y)\n\nnb_classes = len(le.classes_)\nprint('Number of classes', nb_classes)\nprint('Number of instances', len(y))\n\nplt.hist(y, bins=nb_classes)\nplt.title('Number of instances in each class')\nplt.xlabel('Class id')\nplt.ylabel('Number of instances')\nplt.show()\n\n# convert a class vectors (integers) to a binary class matrix\ny = np_utils.to_categorical(y)\n\n# Load testing data\ntest_data = pd.read_csv(test_path)\ntest_ids = test_data.iloc[:, 0]\ntest_images = list()\nfor i in test_ids:\n    test_images.append(load_image(i))\ntest_images = np.array(test_images)\n\n# Load submission file\nsubmission_data = pd.read_csv(submission_path)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3ca41ce6-88d0-92a7-cb5d-5f8a8b23deb9"},"source":"# Train and test split\nSplit the dataset into training and testing part in order to evaluate the performance"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0decf5e-ddc6-4397-0913-34ac1a4fa090"},"outputs":[],"source":"# The folds are made by preserving the percentage of samples for each class\nsss = StratifiedShuffleSplit(10, 0.2, random_state=15)\nfor train_index, test_index in sss.split(x_images, y):\n\tx_train_images, x_test_images, x_train_features, x_test_features = x_images[train_index], x_images[test_index], x_features[train_index], x_features[test_index]\n\ty_train, y_test = y[train_index], y[test_index]\n    \nprint('Shape of x train images', x_train_images.shape)\nprint('Shape of x train features', x_train_features.shape)\nprint('Shape of y train', y_train.shape)\nprint('Shape of x test images', x_test_images.shape)\nprint('Shape of x test features', x_test_features.shape)\nprint('Shape of y test', y_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5554c2dd-dd08-a083-5374-aec619a5798b"},"outputs":[],"source":"def construct_feature_model():\n    print('Contructing the model')\n    \n    model1 = Sequential([\n        Dense(nb_classes * 2, input_shape=x_train_features.shape[1:]),\n        BatchNormalization(),\n        Activation('tanh'),\n        Dropout(0.25)\n    ])\n    \n    model2 = Sequential([\n        Convolution2D(32, 3, 3, border_mode='same',\n                            input_shape=x_images.shape[1:]),\n        Activation('tanh'),\n        MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n        Dropout(0.5),\n        Flatten(),\n        Dense(nb_classes),\n        Activation('tanh')\n    ])\n    \n    model = Sequential([\n        Merge([model1, model2], mode='concat', concat_axis=1),\n        Dense(nb_classes * 2),\n        Activation('tanh'),\n        Dropout(0.5),\n        Dense(nb_classes),\n        Activation('softmax')\n    ])\n    \n    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n    \n    model.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n    \n    print('Finish construction of the model')\n    return model\n\nmodel = construct_feature_model()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e86fbc8-7235-6196-79c5-b8c45501cb25"},"outputs":[],"source":"print('Start to fit')\ns = time.time()\n# Save the parameter for the best model\nbest_model_file = 'leaf.h5'\nbest_model_cb = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=0, save_best_only=True)\n\n# Fitting parameters\nbatch_size = 32\nnb_epoch = 8\nverbose = 2\ncallbacks = [best_model_cb]\nvalidation_split = 0.0\nvalidation_data = ([x_test_features, x_test_images], y_test)\n#validation_data = (x_test_features, y_test)\nshuffle = True\nclass_weight = None\nsample_weight = None\ndata_augmentation = False\n\nif not data_augmentation:\n    print('Not using data augmentation')\n    history = model.fit([x_features, x_images], y,\n    #history = model.fit(x_features, y,\n              batch_size=batch_size,\n              nb_epoch=nb_epoch, \n              verbose=verbose,\n              callbacks=callbacks,\n              validation_split=validation_split,\n              validation_data=validation_data,\n              shuffle=shuffle,\n              class_weight=class_weight,\n              sample_weight=sample_weight)\nprint('Finish fitting\\nFitting time', time.time() - s)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76f51060-c39f-81f0-03e6-ab005a237b42"},"outputs":[],"source":"plt.plot(history.history['val_acc'])\nplt.xlabel('Number of epoch')\nplt.ylabel('Validation accrucy')\nplt.title('Validation accuracy vs number of epoch')\nplt.show()\nprint('Maximum accuracy', max(history.history['val_acc']))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e6bd64f-7623-03dc-7d18-a2361b5e0e81"},"outputs":[],"source":"plt.plot(history.history['val_loss'], color='r')\nplt.xlabel('Number of epoch')\nplt.ylabel('Categorical cross entropy loss')\nplt.title('Categorical cross entropy loss vs number of epoch')\nplt.show()\nprint('Minimum loss', min(history.history['val_loss']))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b06e625c-4958-3837-8a78-4fb9aecb07d2"},"outputs":[],"source":"model = load_model(best_model_file)\n\ny_prob = model.predict([test_data.iloc[:, 1:].values, test_images]) # Remove id column\n#y_prob = model.predict(test_data.iloc[:, 1:].values) # Remove id column\n\nsubmission_data.iloc[:, 1:] = y_prob\nsubmission_data.tail()\n\nf = open(submission_output, 'w')\nf.write(pd.DataFrame(submission_data).to_csv(index = False))\nf.close()"},{"cell_type":"markdown","metadata":{"_cell_guid":"66d98131-7a6f-d158-2ea8-207c5235bc7e"},"source":"# Storing all data into a h5df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92420460-5c7f-ed93-2c51-1eeae7b36683"},"outputs":[],"source":"'''\nfile_name = 'data.h5'\nif os.path.isfile(file_name):\n    os.remove(file_name)\n\nh5f = h5py.File(file_name, 'w')\nh5f.create_dataset('x_train_images', data=x_train_images)\nh5f.create_dataset('x_train_features', data=x_train_features)\nh5f.create_dataset('y_train', data=y_train)\nh5f.create_dataset('x_test_images', data=x_test_images)\nh5f.create_dataset('x_test_features', data=x_test_features)\nh5f.create_dataset('y_test', data=y_test)\n\nh5f.create_dataset('test_images', data=test_images)\nh5f.create_dataset('test_faetures', data=test_data.iloc[:, 1:].values)\n\nh5f.close()\n\n\n    model = Sequential([\n        Dense(nb_classes * 2, input_dim=x_train_features.shape[1]),\n        BatchNormalization(),\n        Activation('relu'),\n        Dropout(0.5),\n        Dense(nb_classes * 2),\n        Activation('relu'),\n        Dropout(0.5),\n        Dense(nb_classes),\n        Activation('softmax'),\n    ])\n'''"},{"cell_type":"markdown","metadata":{"_cell_guid":"98a57e7a-595c-d519-e4a9-656ee09ffaf9"},"source":"# Reference\n1. https://github.com/fchollet/keras/issues/68\n2. http://stackoverflow.com/questions/31997366/python-keras-shape-mismatch-error\n3. https://www.kaggle.com/abhmul/leaf-classification/keras-convnet-lb-0-0052-w-visualization\n4. https://keras.io/models/sequential/\n5. http://stackoverflow.com/questions/1386352/pil-thumbnail-and-end-up-with-a-square-image\n6. http://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7df50e7-a70a-05de-dd2f-7fc44d9b8097"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}