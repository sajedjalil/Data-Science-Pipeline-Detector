{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6c2f8ee8-29fa-7a68-6c7b-4fbba1c11ffc"},"source":"This notebook is the second in a series, that attempts to build better features from the Leaf Classification Dataset, that is already available on the Kaggle site.\n\n1. [The first notebook explores][1]\n- polar projection (something we finally not used) \n- and finding local extremes (i.e. the tips and bottoms)\n2. This second one\n- Puts everything learnt previuosly in proper, well-scoped functions\n- Introduces proper preprocessing, so that all inputs are equal\n- Implements a robust way to separate leaf shape from leaf contour\n3. [The next one will][2]\n- finally turn the two contours into time series\n- will probably look for symmetry\n- and will push forward to the actual machine learning part\n\n\n  [1]: https://www.kaggle.com/lorinc/leaf-classification/feature-extraction-from-images/\n\n  [2]: https://www.kaggle.com/lorinc/leaf-classification/fork-of-feature-extraction-from-images-3\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1073064-2763-7a9c-29d5-29e2a6edf849"},"outputs":[],"source":"import numpy as np\n\nimport scipy as sp\nimport scipy.ndimage as ndi\nfrom scipy.signal import argrelextrema\n\nfrom skimage import measure\nfrom sklearn import metrics\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\n%matplotlib inline\nfrom pylab import rcParams\nrcParams['figure.figsize'] = (6, 6)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d4b7c3d2-b4ec-83f6-560d-34ae30db159b"},"source":"This part contains the already polished functionality."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3da753c-82d4-2de1-c11b-6904b7742ee0"},"outputs":[],"source":"# ----------------------------------------------------- I/O ---\n\ndef read_img(img_no):\n    \"\"\"reads image from disk\"\"\"\n    return mpimg.imread('../input/images/' + str(img_no) + '.jpg')\n\n\ndef get_imgs(num):\n    \"\"\"convenience function, yields random sample from leaves\"\"\"\n    if type(num) == int:\n        imgs = range(1, 1584)\n        num = np.random.choice(imgs, size=num, replace=False)\n        \n    for img_no in num:\n        yield img_no, preprocess(read_img(img_no))\n\n\n# ----------------------------------------------------- preprocessing ---\n\ndef threshold(img, threshold=250):\n    \"\"\"splits img to 0 and 255 values at threshold\"\"\"\n    return ((img > threshold) * 255).astype(img.dtype)\n\n\ndef portrait(img):\n    \"\"\"makes all leaves stand straight\"\"\"\n    y, x = np.shape(img)\n    return img.transpose() if x > y else img\n    \n\ndef resample(img, size):\n    \"\"\"resamples img to size without distorsion\"\"\"\n    ratio = size / max(np.shape(img))\n    return sp.misc.imresize(img, ratio, mode='L', interp='nearest')\n\n    \ndef fill(img, size=500, tolerance=0.95):\n    \"\"\"extends the image if it is signifficantly smaller than size\"\"\"\n    y, x = np.shape(img)\n\n    if x <= size * tolerance:\n        pad = np.zeros((y, int((size - x) / 2)), dtype=int)\n        img = np.concatenate((pad, img, pad), axis=1)\n\n    if y <= size * tolerance:\n        pad = np.zeros((int((size - y) / 2), x), dtype=int)\n        img = np.concatenate((pad, img, pad), axis=0) \n    \n    return img\n\n\n# ----------------------------------------------------- postprocessing ---\n\ndef standardize(arr1d):\n    \"\"\"move mean to zero, 1st SD to -1/+1\"\"\"\n    return (arr1d - arr1d.mean()) / arr1d.std()\n\n\ndef coords_to_cols(coords):\n    \"\"\"from x,y pairs to feature columns\"\"\"\n    return coords[::,1], coords[::,0]\n\n\ndef get_contour(img):\n    \"\"\"returns the coords of the longest contour\"\"\"\n    return max(measure.find_contours(img, .8), key=len)\n\n\ndef get_center(img):\n    \"\"\"so that I do not have to remember the function ;)\"\"\"\n    return ndi.measurements.center_of_mass(img)\n\n\n# ----------------------------------------------------- feature engineering ---\n\ndef extract_shape(img):\n    \"\"\"\n    Expects prepared image, returns leaf shape in img format.\n    The strength of smoothing had to be dynamically set\n    in order to get consistent results for different sizes.\n    \"\"\"\n    size = int(np.count_nonzero(img)/1000)\n    brush = int(5 * size/size**.75)\n    return ndi.gaussian_filter(img, sigma=brush, mode='nearest') > 200\n\n\n# TODO: optimize - do not search the whole array for lmin, just the near0 parts\ndef near0_lmin_ix(timeseries):\n    \"\"\"finds near-zero local *flat* minima in time-series\"\"\"\n    lmin = argrelextrema(timeseries[0], np.less_equal, order=3)\n    near0 = np.where(timeseries[0] < 3)\n    return np.intersect1d(lmin, near0)  # returns indices\n\n\ndef extend_index(ix, radius=4):  # 3 is good, 4 is safe\n    \"\"\"extends near0_lmin_ix results by radius\"\"\"\n    result = []\n    for ix in ix:\n        result += list(range(ix-radius, ix+radius))\n    return np.unique(result)\n\n\ndef dist_line_line(src_arr, tgt_arr):\n    \"\"\"\n    returns 2 tgt_arr length arrays, \n    1st is distances, 2nd is src_arr indices\n    \"\"\"\n    return np.array(sp.spatial.cKDTree(src_arr).query(tgt_arr))\n\n\ndef dist_line_point(src_arr, point):\n    \"\"\"returns 1d array with distances from point\"\"\"\n    point1d = [[point[0], point[1]]] * len(src_arr)\n    return metrics.pairwise.paired_distances(src_arr, point1d)\n\n\ndef index_diff(kdt_output_1):\n    \"\"\"\n    Shows pairwise distance between all n and n+1 elements.\n    Useful to see, how the dist_line_line maps the two lines.\n    \"\"\"\n    return np.diff(kdt_output_1)\n\n\n# ----------------------------------------------------- wrapping functions ---\n\n# wrapper function for all preprocessing tasks    \ndef preprocess(img, do_portrait=True, do_resample=500, \n               do_fill=True, do_threshold=250):\n    \"\"\" prepares image for processing\"\"\"\n    if do_portrait:\n        img = portrait(img)\n    if do_resample:\n        img = resample(img, size=do_resample)\n    if do_fill:\n        img = fill(img, size=do_resample)\n    if do_threshold:\n        img = threshold(img, threshold=do_threshold)\n        \n    return img"},{"cell_type":"markdown","metadata":{"_cell_guid":"ea58bef0-e4ae-25d2-28fd-59715fac4abe"},"source":"This is the exploratory part."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8d8a3ab-b9f7-6264-a8ec-16ea0b00b455"},"outputs":[],"source":"# exploring solution before building it as function\n\n# img, shape\ntitle, img = list(get_imgs([709]))[0]\nblur = extract_shape(img)\n\n# img contour, shape contour  \nblade = get_contour(img)\nshape = get_contour(blur)\n\n# img distance, shape distance  \nshape_y, shape_x = get_center(blur)\nblade_dist = dist_line_line(shape, blade)\nshape_dist = dist_line_point(shape, [shape_x, shape_y])\n\n# finding minima near 0 on the edge\nblade_poi_ix = extend_index(near0_lmin_ix(blade_dist))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43d993cd-64e0-5c0a-f7f2-a6bd43cf57b8"},"outputs":[],"source":"# the points to be checked\nblade_x, blade_y = coords_to_cols(blade)\nshape_x, shape_y = coords_to_cols(shape)\n\nsection_x = blade_x[blade_poi_ix]\nsection_y = blade_y[blade_poi_ix]\n\nplt.plot(blade_x, blade_y, linewidth=.3, c='r')\nplt.plot(shape_x, shape_y, linewidth=.3, c='g')\nplt.scatter(section_x, section_y, \n            marker='x', linewidth=.3, s=10, alpha=.5)\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}