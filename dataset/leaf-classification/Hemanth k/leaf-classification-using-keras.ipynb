{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d4073b27-40a6-cc77-9e4c-fe80bc33512d"},"source":"**<h1>LEAF CLASSIFICATION</h1>**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d9a8f8d-334c-e289-4a03-a9284d883e75"},"outputs":[],"source":"# Package Imports\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n# Keras stuff\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import img_to_array, load_img\n\nroot = '../input'\nnp.random.seed(2016)\nsplit_random_state = 7\nsplit = .9\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# from subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c9c1911-0665-511a-7dd6-d5f7167fcab3"},"outputs":[],"source":"def load_numeric_training(standardize=True):\n    data = pd.read_csv(os.path.join(root, 'train.csv'))\n    ID = data.pop('id')\n\n    y = data.pop('species')\n    y = LabelEncoder().fit(y).transform(y)\n    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n    return ID, X, y"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4c83291-6599-4779-27b9-991f0acf6ca7"},"outputs":[],"source":"def load_numeric_test(standardize=True):\n    test_data = pd.read_csv(os.path.join(root, 'test.csv'))\n    ID = data.pop('id')\n\n    test = StandardScaler().fit(test_data).transform(test_data) if standardize else test_data.values\n    return ID, test"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"444a5165-32b3-8514-c708-d3561c3d2589"},"outputs":[],"source":"def resize_img(img, max_dim=96):\n    max_ax = max((0, 1), key=lambda i: img.size[i])\n    scale = max_dim / float(img.size[max_ax])\n    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f0b119b-fb0e-0027-5ae7-347e0a3bfd46"},"outputs":[],"source":"# Original Image\noriginal_image = load_img(os.path.join(root, 'images', '1'+'.jpg'), grayscale=True)\nplt.imshow(original_image)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ceec7b91-ae03-98f3-6b3e-101e7013dbdd"},"outputs":[],"source":"# Resized Image\nplt.imshow(resize_img(original_image))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f34cdaac-c264-612d-f497-79922552041a"},"outputs":[],"source":"def load_image_data(ids, max_dim=96, center=True):\n    X = np.zeros((len(ids), max_dim, max_dim, 1))\n    for i, ide in enumerate(ids):\n        x = resize_img(load_img(os.path.join(root, 'images', str(ide)+'.jpg'), grayscale=True), max_dim=max_dim)\n        x = img_to_array(x)\n        \n        length = x.shape[0]\n        width = x.shape[1]\n        \n        if center:\n            h1 = int((max_dim - length) / 2)\n            h2 = h1 + length\n            w1 = int((max_dim - width) / 2)\n            w2 = w1 + width\n        else:\n            h1, w1 = 0, 0\n            h2, w2 = (length, width)\n            \n        X[i, h1:h2, w1:w2, 0:1] = x\n        \n    return np.around(X / 255.0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"140c7c47-d4fe-e485-19f2-b1dc41c12ebe"},"outputs":[],"source":"def load_train_data(split=split, random_state=None):\n    # Load the pre-extracted features\n    ID, X_num_tr, y = load_numeric_training()\n    # Load the image data\n    X_img_tr = load_image_data(ID)\n    # Split them into validation and cross-validation\n    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n    train_ind, test_ind = next(sss.split(X_num_tr, y))\n    X_num_val, X_img_val, y_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind]\n    X_num_tr, X_img_tr, y_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind]\n    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"28c7b4da-2183-5a9f-37d9-fc197b750f74"},"outputs":[],"source":"def load_test_data():\n    # Load the pre-extracted features\n    ID, X_num_te = load_numeric_test()\n    # Load the image data\n    X_img_te = load_image_data(ID)\n    return ID, X_num_te, X_img_te"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c343429-b0c4-6425-963e-9b8b4aed9b4a"},"outputs":[],"source":"print('Loading the training data...')\n(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data(random_state=split_random_state)\ny_tr_cat = to_categorical(y_tr)\ny_val_cat = to_categorical(y_val)\nprint('Training data loaded!')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"432f3f5f-1c49-083d-a352-eaf50c56145a"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}