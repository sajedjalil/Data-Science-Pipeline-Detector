{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e2295c62-b360-c048-ab1c-a19e91218aad"},"outputs":[],"source":"## Importing standard libraries\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n## Importing sklearn libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n## Keras Libraries for Neural Networks\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Activation\nfrom keras.utils.np_utils import to_categorical"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fec5a6b6-271f-36e0-a593-a2a258d39bea"},"outputs":[],"source":"## Set figure size to 20x10\n\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10,10"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3883e40b-48fb-03e4-d365-d01af7505e84"},"outputs":[],"source":"## Read data from the CSV file\n\ndata = pd.read_csv('../input/train.csv')\nparent_data = data.copy()    ## Always a good idea to keep a copy of original data\nID = data.pop('id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dacc91e2-d384-5979-0207-66dd145004f9"},"outputs":[],"source":"## Since the labels are textual, so we encode them categorically\n\ny = data.pop('species')\ny = LabelEncoder().fit(y).transform(y)\nprint(y.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"262251c4-2ca1-5a1b-f67d-cf47b7763976"},"outputs":[],"source":"## Most of the learning algorithms are prone to feature scaling\n## Standardising the data to give zero mean =)\n\nX = StandardScaler().fit(data).transform(data)\nprint(X.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6041431-1433-762e-d0e0-91aadb8c3370"},"outputs":[],"source":"## We will be working with categorical crossentropy function\n## It is required to further convert the labels into \"one-hot\" representation\n\ny_cat = to_categorical(y)\nprint(y_cat.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4be105f5-77a6-8c46-182f-42b7241cf150"},"outputs":[],"source":"## Developing a layered model for Neural Networks\n## Input dimensions should be equal to the number of features\n## We used softmax layer to predict a uniform probabilistic distribution of outcomes\n\nmodel = Sequential()\nmodel.add(Dense(1024,input_dim=192))\nmodel.add(Dropout(0.2))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(512))\nmodel.add(Dropout(0.3))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(99))\nmodel.add(Activation('softmax'))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3135f21f-367c-77b7-2fd9-6190296820bd"},"outputs":[],"source":"## Error is measured as categorical crossentropy or multiclass logloss\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52ed1c8d-6dc0-7a91-9828-849ed28c45d0"},"outputs":[],"source":"## Fitting the model on the whole training data\nhistory = model.fit(X, y_cat, batch_size=128, nb_epoch=100, verbose=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e217bd2a-a7b6-3eab-2319-218f27db3e4b"},"outputs":[],"source":"## Plotting the error with the number of iterations\n## With each iteration the error reduces smoothly\n\nplt.plot(history.history['loss'],'o-')\nplt.xlabel('Number of Iterations')\nplt.ylabel('Categorical Crossentropy')\nplt.title('Train Error vs Number of Iterations')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3db1966d-9374-7e6e-6242-6e84b89208f3"},"outputs":[],"source":"test = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d6158f6-2cc5-6e93-6adb-50cff868ab5f"},"outputs":[],"source":"index = test.pop('id')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12f9a9a1-662f-d86b-a653-0405dc0c68ee"},"outputs":[],"source":"test = StandardScaler().fit_transform(test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc41c459-4afe-245c-940a-4ec69de27fce"},"outputs":[],"source":"yPred = model.predict_proba(test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5004cb45-6612-b245-3bf1-30e28a0a77d0"},"outputs":[],"source":"## Converting the test predictions in a dataframe as depicted by sample submission\n\nyPred = pd.DataFrame(yPred,index=index,columns=sorted(parent_data.species.unique()))\nyPred.to_csv('predictions.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0754597d-f556-9bb2-df3b-6b94dd60d9d7"},"outputs":[],"source":"yPred.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3737fdb1-4a75-f2fe-c6cb-5e20ee336616"},"outputs":[],"source":"# try rounding to see if this improves the score\n# nope, made it much worse\n#yPredTest = yPred.round(0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b5cce8b-4b3a-2d79-7c1d-a91cc2bf8117"},"outputs":[],"source":"# check to make sure all rows have exactly one species chosen\nyPredTest.sum(axis=1).sum()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"773cf59a-bdf4-6825-9dfa-3af092b50562"},"outputs":[],"source":"# looks like we're missing one\nyPredTest.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0e297c7-75be-9846-6327-b59534d84535"},"outputs":[],"source":"yPredTest.sum(axis=1).argmin()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d8701cf-3ddc-e251-722b-fbf93995b35e"},"outputs":[],"source":"yPred.ix[1190].argmax()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33494851-0f55-0c3e-d4be-b5085d4aa6ce"},"outputs":[],"source":"yPred.ix[1190, 'Acer_Rubrum']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"beea331c-2632-6b70-2726-bbeca4a0456b"},"outputs":[],"source":"yPredTest = yPredTest.set_value(1190, 'Acer_Rubrum', 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c644350-4a0a-5a6a-75db-626e2ee112ad"},"outputs":[],"source":"yPredTest.to_csv('predictions.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89ea90a7-9991-d4e1-ebe2-c598208bb172"},"outputs":[],"source":"# for each wrong answer (if we round to 1s and 0s), we get a penalty of\n(-np.log10(10**-15)/594)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6396cab9-b782-09cc-a5bf-6a9f40777013"},"outputs":[],"source":"# so for a score of 0.407 (when using this and rounding to 1s and 0s), we get\n0.407/(-np.log10(10**-15)/594)\n# wrong answers"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66076afc-8376-b404-9919-28c2ac5db369"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}