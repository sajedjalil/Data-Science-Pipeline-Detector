{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## How to use mmdetection\nI've already created train images and also coco annotations.\n\n- Create image dataset  \nnotebook: https://www.kaggle.com/bamps53/create-image-dataset  \ndataset: https://www.kaggle.com/bamps53/nfl2021-train-images  \n\n- Convert ground truth to coco format(with train/val split)  \nnotebook: https://www.kaggle.com/bamps53/create-coco-format-annotations-train-val  \ndataset: https://www.kaggle.com/bamps53/nfl2021-coco-train-val-annotations  \n\nNow it's way easy to train your own detector.  \nIn this notebook I'll introduce one of the most famous object detection library, mmdetection.","metadata":{}},{"cell_type":"markdown","source":"## Installation","metadata":{}},{"cell_type":"code","source":"# just following official install instruction.\n# https://github.com/open-mmlab/mmdetection/blob/master/docs/get_started.md\n!pip install openmim\n!mim install mmdet\n!git clone https://github.com/open-mmlab/mmdetection.git\n%cd mmdetection\n!pip install -q -e .","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-13T03:28:33.850871Z","iopub.execute_input":"2021-08-13T03:28:33.851208Z","iopub.status.idle":"2021-08-13T03:29:38.709975Z","shell.execute_reply.started":"2021-08-13T03:28:33.851173Z","shell.execute_reply":"2021-08-13T03:29:38.70898Z"},"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting config\n\nWhat you need to train detector is just to modify config!\n\nIn below example I use FasterRCNN as baseline, but you can use any of configs in mmdetection repository.  \nmodel zoo: https://github.com/open-mmlab/mmdetection/blob/master/docs/model_zoo.md  \nconfigs: https://github.com/open-mmlab/mmdetection/tree/master/configs\n\nBut there are so many parameters and it's not easy to fing what you need to change for beginners.  \nI've annotated where I modified or added in below example, but I'll summarize what you need to do minimally.\n\n### Dataset\n1. You need to change num classes to 1.(We only need to detect only Helmet class.)\n2. You need to specify image dir and annotation path for train/valid/test set.\n\n### Model\n1. You need to change num classes to 1.(We only need to detect only Helmet class.)\n\n### Others\n1. You need to set pretrained model path in `load_from` because what we want to do here is finetune, not training from scratch.\n2. Also it's better to decrease LR for finetuning.\n3. You can also change `max_epochs` as you want, here I set to 1 for just demonstration.\n\nNote that original config files use inheritation system, but here I included full config in a single file.  \n(In my opinion it's easier to understand diff, but may not for others.)","metadata":{}},{"cell_type":"code","source":"%%writefile configs/faster_rcnn/custom_faster_rcnn_r50_fpn.py\n\n# dataset settings\ndataset_type = 'CocoDataset'\nclasses = ('Helmet',) # Added\ndata_root = '/kaggle/input/' # Modified\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        ann_file=data_root + 'nfl2021-coco-train-val-annotations/train.json', # Modified\n        img_prefix=data_root + 'nfl2021-train-images/train_images/', # Modified\n        classes=classes, # Added\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        ann_file=data_root + 'nfl2021-coco-train-val-annotations/valid.json', # Modified\n        img_prefix=data_root + 'nfl2021-train-images/train_images/', # Modified\n        classes=classes, # Added\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        ann_file=data_root + 'nfl2021-coco-train-val-annotations/valid.json', # Modified\n        img_prefix=data_root + 'nfl2021-train-images/train_images/', # Modified\n        classes=classes, # Added\n        pipeline=test_pipeline))\nevaluation = dict(interval=1, metric='bbox')\n\n# model settings\nmodel = dict(\n    type='FasterRCNN',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[.0, .0, .0, .0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    roi_head=dict(\n        type='StandardRoIHead',\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=dict(\n            type='Shared2FCBBoxHead',\n            in_channels=256,\n            fc_out_channels=1024,\n            roi_feat_size=7,\n            num_classes=1, # Modified\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0., 0., 0., 0.],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=False,\n            loss_cls=dict(\n                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n    # model training and testing settings\n    train_cfg=dict(\n        rpn=dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.7,\n                neg_iou_thr=0.3,\n                min_pos_iou=0.3,\n                match_low_quality=True,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=256,\n                pos_fraction=0.5,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=False),\n            allowed_border=-1,\n            pos_weight=-1,\n            debug=False),\n        rpn_proposal=dict(\n            nms_pre=2000,\n            max_per_img=1000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.5,\n                neg_iou_thr=0.5,\n                min_pos_iou=0.5,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            pos_weight=-1,\n            debug=False)),\n    test_cfg=dict(\n        rpn=dict(\n            nms_pre=1000,\n            max_per_img=1000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=dict(\n            score_thr=0.05,\n            nms=dict(type='nms', iou_threshold=0.5),\n            max_per_img=100)\n        # soft-nms is also supported for rcnn testing\n        # e.g., nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)\n    ))\n\n# optimizer\noptimizer = dict(type='SGD', lr=0.002, momentum=0.9, weight_decay=0.0001) # Modified\noptimizer_config = dict(grad_clip=None)\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8,]) # If you changed max_epochs, it's better to change when you decrease LR too here.\nrunner = dict(type='EpochBasedRunner', max_epochs=10) # You can set max_epochs as you want.\n\ncheckpoint_config = dict(interval=1)\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        # dict(type='TensorboardLoggerHook')\n    ])\n# yapf:enable\ncustom_hooks = [dict(type='NumClassCheckHook')]\n\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_mstrain_3x_coco/faster_rcnn_r50_fpn_mstrain_3x_coco_20210524_110822-e10bd31c.pth'  # Modified\nresume_from = None\nworkflow = [('train', 1)]\n","metadata":{"execution":{"iopub.status.busy":"2021-08-13T03:29:38.713452Z","iopub.execute_input":"2021-08-13T03:29:38.713734Z","iopub.status.idle":"2021-08-13T03:29:38.720292Z","shell.execute_reply.started":"2021-08-13T03:29:38.713705Z","shell.execute_reply":"2021-08-13T03:29:38.719563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training is just one line. \n# !python tools/train.py configs/faster_rcnn/custom_faster_rcnn_r50_fpn.py\n\n# You can also test the model like this.\n# !python tools/test.py configs/faster_rcnn/custom_faster_rcnn_r50_fpn.py YOUR_MODEL_PATH --eval bbox","metadata":{"execution":{"iopub.status.busy":"2021-08-13T03:57:50.174457Z","iopub.execute_input":"2021-08-13T03:57:50.174871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}