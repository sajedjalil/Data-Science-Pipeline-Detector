{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook uses CenterNet to detect the helmet as well as the player's orientation and the gap between the helmet and the sensor.\n\nFollowing notetebooks are used here:\n- https://www.kaggle.com/go5kuramubon/merge-label-and-tracking-data\n- https://www.kaggle.com/bamps53/create-coco-format-annotations-train-val\n- https://www.kaggle.com/robikscube/nfl-helmet-assignment-getting-started-guide\n- https://www.kaggle.com/its7171/nfl-baseline-simple-helmet-mapping","metadata":{}},{"cell_type":"code","source":"debug=True   # use 10% sampling data for debug mode","metadata":{"execution":{"iopub.status.busy":"2021-11-11T09:58:15.310006Z","iopub.execute_input":"2021-11-11T09:58:15.310361Z","iopub.status.idle":"2021-11-11T09:58:15.404076Z","shell.execute_reply.started":"2021-11-11T09:58:15.310286Z","shell.execute_reply":"2021-11-11T09:58:15.403379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n!pip install ../input/nfllibs/bounded_pool_executor-0.0.3-py3-none-any.whl\n!pip install ../input/nfllibs/pqdm-0.1.0-py2.py3-none-any.whl\n!pip install ../input/nfllibs/progress-1.6/progress-1.6\n!pip install ../input/nfllibs/pycocotools-2.0.2/dist/pycocotools-2.0.2.tar\n!pip install ../input/nfllibs/filterpy-1.4.5/filterpy-1.4.5","metadata":{"execution":{"iopub.status.busy":"2021-11-11T09:58:15.406819Z","iopub.execute_input":"2021-11-11T09:58:15.407011Z","iopub.status.idle":"2021-11-11T09:59:01.983732Z","shell.execute_reply.started":"2021-11-11T09:58:15.406989Z","shell.execute_reply":"2021-11-11T09:59:01.982633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom matplotlib import pyplot as plt\nfrom multiprocessing import Pool, cpu_count\nfrom pqdm.processes import pqdm\nfrom scipy.spatial import distance\nfrom tqdm.auto import tqdm\nimport cv2\nimport glob\nimport itertools\nimport json\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nimport torch\ntqdm.pandas()","metadata":{"lines_to_next_cell":2,"execution":{"iopub.status.busy":"2021-11-11T09:59:01.985946Z","iopub.execute_input":"2021-11-11T09:59:01.986247Z","iopub.status.idle":"2021-11-11T09:59:06.716235Z","shell.execute_reply.started":"2021-11-11T09:59:01.986208Z","shell.execute_reply":"2021-11-11T09:59:06.715463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prepair data","metadata":{}},{"cell_type":"code","source":"# based on https://www.kaggle.com/go5kuramubon/merge-label-and-tracking-data\nSAVE_DIR = '../train_images'\nBASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\ndef add_track_features(tracks, fps=59.94, snap_frame=10):\n    \"\"\"\n    Add column features helpful for syncing with video data.\n    \"\"\"\n    tracks = tracks.copy()\n    tracks[\"game_play\"] = (\n        tracks[\"gameKey\"].astype(\"str\")\n        + \"_\"\n        + tracks[\"playID\"].astype(\"str\").str.zfill(6)\n    )\n    tracks[\"time\"] = pd.to_datetime(tracks[\"time\"])\n    snap_dict = (\n        tracks.query('event == \"ball_snap\"')\n        .groupby(\"game_play\")[\"time\"]\n        .first()\n        .to_dict()\n    )\n    tracks[\"snap\"] = tracks[\"game_play\"].map(snap_dict)\n    tracks[\"isSnap\"] = tracks[\"snap\"] == tracks[\"time\"]\n    tracks[\"team\"] = tracks[\"player\"].str[0].replace(\"H\", \"Home\").replace(\"V\", \"Away\")\n    tracks[\"snap_offset\"] = (tracks[\"time\"] - tracks[\"snap\"]).astype(\n        \"timedelta64[ms]\"\n    ) / 1_000\n    # Estimated video frame\n    tracks[\"est_frame\"] = (\n        ((tracks[\"snap_offset\"] * fps) + snap_frame).round().astype(\"int\")\n    )\n    return tracks\n\ndef add_cols(df):\n    df['frame'] = df['video_frame'].str.split('_').str[-1].astype(int)\n    df['playID'] = df['video_frame'].str.split('_').str[1].astype(int)\n    df['view'] = df['video_frame'].str.split('_').str[2]\n    if 'video' not in df.columns:\n        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    return df\n\ndef merge_label_and_tracking(tracking_df, label_df):\n    tracking_with_game_index = tracking_df.set_index([\"gameKey\", \"playID\", \"player\"])\n    df_list = []\n    for key, _label_df in tqdm(label_df.groupby([\"gameKey\", \"playID\", \"view\", \"label\"])):\n        # skip because there are sideline player\n        if key[3] == \"H00\" or key[3] == \"V00\":\n            continue\n        tracking_data = tracking_with_game_index.loc[(key[0], key[1], key[3])]\n        _label_df = _label_df.sort_values(\"frame\")\n        # merge with frame and est_frame\n        merged_df = pd.merge_asof(\n            _label_df,\n            tracking_data,\n            left_on=\"frame\",\n            right_on=\"est_frame\",\n            direction='nearest',\n        )\n        df_list.append(merged_df)\n    all_merged_df = pd.concat(df_list)\n    all_merged_df = all_merged_df.sort_values([\"video_frame\", \"label\"], ignore_index=True)\n    \n    return all_merged_df\n\ndef compute_overlap(boxes, query_box):\n    #'XMin', 'YMin', 'XMax', 'YMax'\n    N = boxes.shape[0]\n    overlaps = np.zeros((N), dtype=np.float64)\n    box_area = (\n        (query_box[2] - query_box[0]) *\n        (query_box[3] - query_box[1])\n    )\n    for n in range(N):\n        iw = (\n            min(boxes[n, 2], query_box[2]) -\n            max(boxes[n, 0], query_box[0])\n        )\n        if iw > 0:\n            ih = (\n                min(boxes[n, 3], query_box[3]) -\n                max(boxes[n, 1], query_box[1])\n            )\n            if ih > 0:\n                ua = np.float64(\n                    (boxes[n, 2] - boxes[n, 0]) *\n                    (boxes[n, 3] - boxes[n, 1]) +\n                    box_area - iw * ih\n                )\n                overlaps[n] = iw * ih / ua\n    return overlaps\n\ndef add_xy(df):\n    \"\"\"\n    Adds `x1`, `x2`, `y1`, and `y2` columns necessary for computing IoU.\n\n    Note - for pixel math, 0,0 is the top-left corner so box orientation\n    defined as right and down (height)\n    \"\"\"\n    df[\"x1\"] = df[\"left\"]\n    df[\"x2\"] = df[\"left\"] + df[\"width\"]\n    df[\"y1\"] = df[\"top\"]\n    df[\"y2\"] = df[\"top\"] + df[\"height\"]\n    return df\n\ndef set_counts_columns(df, tgt, dummy):\n    mapping_df = df[[tgt,dummy]].groupby(tgt).count().reset_index().rename(columns={dummy:f'{tgt}_counts'})\n    mapping_dict = mapping_df.set_index(tgt).to_dict()[f'{tgt}_counts']\n    df[f'{tgt}_counts'] = df[tgt].map(mapping_dict)\n    return df, mapping_df\n\n\nlabels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\ntracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\ntracking = add_track_features(tracking)\nlabels = add_cols(labels)\nlabels = merge_label_and_tracking(tracking, labels)\nlabels['team'] = labels['label'].str[0].map({'H':0, 'V':1})\nlabels = add_xy(labels)\nlabels = labels[~(labels.frame == 0)]\nlabels, mapping_df = set_counts_columns(labels, 'video_frame', 'left')\nlabels = labels.reset_index()\ntracking = tracking.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T09:59:06.718653Z","iopub.execute_input":"2021-11-11T09:59:06.71891Z","iopub.status.idle":"2021-11-11T09:59:48.866265Z","shell.execute_reply.started":"2021-11-11T09:59:06.718876Z","shell.execute_reply":"2021-11-11T09:59:48.865471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4-fold CV\ncv_video = [\n{'57584_000336_Endzone.mp4', '57584_000336_Sideline.mp4', '57584_002674_Endzone.mp4', '57584_002674_Sideline.mp4', '57594_000923_Endzone.mp4', '57594_000923_Sideline.mp4', '57682_002630_Endzone.mp4', '57682_002630_Sideline.mp4', '57684_001985_Endzone.mp4', '57684_001985_Sideline.mp4', '57787_003413_Endzone.mp4', '57787_003413_Sideline.mp4', '57905_002404_Endzone.mp4', '57905_002404_Sideline.mp4', '57906_000718_Endzone.mp4', '57906_000718_Sideline.mp4', '57907_003615_Endzone.mp4', '57907_003615_Sideline.mp4', '57910_001164_Endzone.mp4', '57910_001164_Sideline.mp4', '57913_000218_Endzone.mp4', '57913_000218_Sideline.mp4', '57915_003093_Endzone.mp4', '57915_003093_Sideline.mp4', '58048_000086_Endzone.mp4', '58048_000086_Sideline.mp4', '58098_001193_Endzone.mp4', '58098_001193_Sideline.mp4'},\n{'57676_003572_Endzone.mp4', '57676_003572_Sideline.mp4', '57775_000933_Endzone.mp4', '57775_000933_Sideline.mp4', '57778_004244_Endzone.mp4', '57778_004244_Sideline.mp4', '57781_000252_Endzone.mp4', '57781_000252_Sideline.mp4', '57783_003374_Endzone.mp4', '57783_003374_Sideline.mp4', '57911_000147_Endzone.mp4', '57911_000147_Sideline.mp4', '57911_002492_Endzone.mp4', '57911_002492_Sideline.mp4', '57912_001325_Endzone.mp4', '57912_001325_Sideline.mp4', '57992_000301_Endzone.mp4', '57992_000301_Sideline.mp4', '57992_000350_Endzone.mp4', '57992_000350_Sideline.mp4', '57993_000475_Endzone.mp4', '57993_000475_Sideline.mp4', '58093_001923_Endzone.mp4', '58093_001923_Sideline.mp4', '58094_000423_Endzone.mp4', '58094_000423_Sideline.mp4', '58094_002819_Endzone.mp4', '58094_002819_Sideline.mp4', '58102_002798_Endzone.mp4', '58102_002798_Sideline.mp4', '58104_000352_Endzone.mp4', '58104_000352_Sideline.mp4'},\n{'57596_002686_Endzone.mp4', '57596_002686_Sideline.mp4', '57679_003316_Endzone.mp4', '57679_003316_Sideline.mp4', '57686_002546_Endzone.mp4', '57686_002546_Sideline.mp4', '57700_001264_Endzone.mp4', '57700_001264_Sideline.mp4', '57782_000600_Endzone.mp4', '57782_000600_Sideline.mp4', '57785_002026_Endzone.mp4', '57785_002026_Sideline.mp4', '57790_002792_Endzone.mp4', '57790_002792_Sideline.mp4', '57790_002839_Endzone.mp4', '57790_002839_Sideline.mp4', '57904_001367_Endzone.mp4', '57904_001367_Sideline.mp4', '57997_003691_Endzone.mp4', '57997_003691_Sideline.mp4', '57998_002181_Endzone.mp4', '57998_002181_Sideline.mp4', '58005_001254_Endzone.mp4', '58005_001254_Sideline.mp4', '58005_001612_Endzone.mp4', '58005_001612_Sideline.mp4', '58107_004362_Endzone.mp4', '58107_004362_Sideline.mp4'},\n{'57583_000082_Endzone.mp4', '57583_000082_Sideline.mp4', '57586_000540_Endzone.mp4', '57586_000540_Sideline.mp4', '57586_001934_Endzone.mp4', '57586_001934_Sideline.mp4', '57586_004152_Endzone.mp4', '57586_004152_Sideline.mp4', '57597_000658_Endzone.mp4', '57597_000658_Sideline.mp4', '57597_001242_Endzone.mp4', '57597_001242_Sideline.mp4', '57680_002206_Endzone.mp4', '57680_002206_Sideline.mp4', '57680_003470_Endzone.mp4', '57680_003470_Sideline.mp4', '57784_001741_Endzone.mp4', '57784_001741_Sideline.mp4', '57786_003085_Endzone.mp4', '57786_003085_Sideline.mp4', '57788_000781_Endzone.mp4', '57788_000781_Sideline.mp4', '57995_000109_Endzone.mp4', '57995_000109_Sideline.mp4', '58000_001306_Endzone.mp4', '58000_001306_Sideline.mp4', '58095_004022_Endzone.mp4', '58095_004022_Sideline.mp4', '58103_003494_Endzone.mp4', '58103_003494_Sideline.mp4', '58106_002918_Endzone.mp4', '58106_002918_Sideline.mp4'}\n]\nfor f in range(4):\n    labels.loc[labels['video'].isin(cv_video[f]), 'fold'] = f\nlabels['fold'] = labels['fold'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T09:59:48.86773Z","iopub.execute_input":"2021-11-11T09:59:48.867979Z","iopub.status.idle":"2021-11-11T09:59:49.102145Z","shell.execute_reply.started":"2021-11-11T09:59:48.867945Z","shell.execute_reply":"2021-11-11T09:59:49.101352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    labels =labels[labels.frame%10==1]\nlabels.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-11T09:59:49.103322Z","iopub.execute_input":"2021-11-11T09:59:49.103598Z","iopub.status.idle":"2021-11-11T09:59:49.257981Z","shell.execute_reply.started":"2021-11-11T09:59:49.103547Z","shell.execute_reply":"2021-11-11T09:59:49.257284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# find best params\nSearch for the values of Rotation Angle, Trapezoidal Correction, and Home/Visotor that will result in the smallest gap between the players' coordinates.","metadata":{}},{"cell_type":"code","source":"# based on https://www.kaggle.com/its7171/nfl-baseline-simple-helmet-mapping\ndef norm_arr_1dim(a):   \n    a = a-a.min()\n    max_a = a.max()\n    if max_a == 0:\n        print('max_a is 0')\n    else:\n        a = a/max_a\n    return a, max_a\n\ndef norm_arr(a):\n    a[:,0], scale0 = norm_arr_1dim(a[:,0])\n    a[:,1], scale1 = norm_arr_1dim(a[:,1])\n    return a, scale0, scale1\n\ndef dist(a1, a2):\n    #print(a1)\n    #print(a2)\n    distx = np.sum(np.abs(a1[:,0]-a2[:,0]))\n    disty = np.sum(np.abs(a1[:,1]-a2[:,1]))\n    return distx + disty\n\ndef rotate_arr(u, t, pt, w, h, aspect_ratio=(1,1), debug=False):\n    xscale, yscale = aspect_ratio[0], aspect_ratio[1]\n    if xscale > yscale:\n        yscale /= xscale\n        xscale = 1\n    else:\n        xscale /= yscale\n        yscale = 1\n    aspect_ratio = (xscale, yscale)\n\n    rot_center_x = w*xscale/2\n    rot_center_y = w*yscale/2\n    R_rot = cv2.getRotationMatrix2D((rot_center_x, rot_center_y), t, 1)\n    \n    if pt > 1:\n        pt = 1 / pt\n        src_pts = np.array([[0, 0], [0+int(w*(1-pt)/2), h], [w-int(w*(1-pt)/2), h], [w, 0]], dtype=np.float32)\n        dst_pts = np.array([[0, 0], [0, h], [w, h], [w, 0]], dtype=np.float32);\n    else:\n        src_pts = np.array([[0, 0], [0, h], [w, h], [w, 0]], dtype=np.float32)\n        dst_pts = np.array([[0, 0], [0+int(w*(1-pt)/2), h], [w-int(w*(1-pt)/2), h], [w, 0]], dtype=np.float32)\n    R_pt = cv2.getPerspectiveTransform(src_pts, dst_pts)\n\n    if debug:\n        print('R_rot', R_rot, t)\n        print('R_pt', R_pt, pt, w, h, [0+w*pt, 0], [w-w*pt, 0])\n        print('src_pts',src_pts)\n        print('dst_pts',dst_pts)\n    \n    u = u.T\n    # Trapezoidal correction\n    u = np.vstack([u,np.ones(u.shape[1])])\n    u = np.dot(R_pt, u)\n    u = u[:2,:]/u[2,:]\n    # aspect ratio\n    u = u*np.expand_dims(aspect_ratio, axis=1)\n    #ã€€rotate\n    u = np.vstack([u,np.ones(u.shape[1])])\n    u = np.dot(R_rot, u)\n    return  u.T\n\ndef dist_rot(helmets):\n    a2_org = helmets[['center_x','center_y']].values.astype(float)#predicted BB\n    a2_min = np.min(a2_org, axis=0)\n    a2_max = np.max(a2_org, axis=0)\n    a2_len = a2_max - a2_min\n    a2,a2scl0,a2scl1 = norm_arr(a2_org)\n    a1 = helmets[['gt_x','gt_y']].values.astype(float)\n    min_dist = 1000000\n    mean_x = a1[0].mean()\n    if helmets['Endzone'].values[0]:\n        w = 53.3\n        h = 120\n    else:\n        w = 120\n        h = 53.3\n    for dig in range(-DIG_MAX,DIG_MAX+1,DIG_STEP):\n        for x_pt in np.arange(1.0, 1.8, 0.1):\n            a1_rot = rotate_arr(a1, dig, 1, 1280, 720).copy()\n            a1_min = np.min(a1_rot, axis=0)\n            a1_max = np.max(a1_rot, axis=0)\n            a1_len = a1_max - a1_min\n            a1_rot_rescale = (a1_rot-a1_min)*a2_len/a1_len + a2_min \n            a1_rot2 = rotate_arr(a1_rot_rescale, 0, x_pt, 1280, 720).copy()\n            a1_rot,a1scl0,a1scl1 = norm_arr(a1_rot2)\n            this_dist = dist(a1_rot, a2.copy())\n            if min_dist > this_dist:\n                min_dist = this_dist\n                min_rot = dig\n                min_pt = x_pt\n                min_scl0 = a1scl0\n                min_scl1 = a1scl1\n                min_a1_rot = a1_rot.copy()\n    helmets['dist0'] = min_dist\n    helmets['rot0'] = min_rot\n    helmets['pt0'] = min_pt\n    helmets['a1scl0'] = min_scl0\n    helmets['a1scl1'] = min_scl1\n    helmets['x_rot0'] = min_a1_rot[:,0]\n    helmets['y_rot0'] = min_a1_rot[:,1]\n    helmets['x_org0'] = a1[:,0]\n    helmets['y_org0'] = a1[:,1]\n    return min_dist, helmets\n\ndef mapping_df(args):\n    video_frame, df = args\n    gameKey,playID,view,frame = video_frame.split('_')\n    gameKey = int(gameKey)\n    playID = int(playID)\n    frame = int(frame)\n    this_tracking = df\n    len_this_tracking = len(this_tracking)\n    df['center_x'] = (df['left']+df['width']/2).astype(int)\n    df['center_y'] = (df['top']+df['height']/2).astype(int)\n    df_a = df.copy()\n    df_h = df.copy()\n    \n    if view == 'Endzone':\n        # Endzone Home\n        df_h['Endzone'] = True\n        df_h['Home'] = True\n        df_h['gt_x'] = 53.3 - df_h['y'].copy()\n        df_h['gt_y'] = 120  - df_h['x'].copy()\n        # Endzone Visitor\n        df_a['Endzone'] = True\n        df_a['Home'] = False\n        df_a['gt_x'] = df_a['y'].copy()\n        df_a['gt_y'] = df_a['x'].copy()\n    else:\n        # Sideline Home\n        df_h['Endzone'] = False\n        df_h['Home'] = True\n        df_h['gt_x'] = df_h['x'].copy()\n        df_h['gt_y'] = 53.3 - df_h['y'].copy()\n        # Sideline Visitor\n        df_a['Endzone'] = False\n        df_a['Home'] = False\n        df_a['gt_x'] = 120  - df_a['x'].copy()\n        df_a['gt_y'] = df_a['y'].copy()\n\n    min_dist_a, df_a = dist_rot(df_a)\n    min_dist_h, df_h = dist_rot(df_h)\n    if min_dist_a < min_dist_h:\n        tgt_df = df_a\n    else:\n        tgt_df = df_h\n    return tgt_df","metadata":{"incorrectly_encoded_metadata":"_kg_hide-input=true","papermill":{"duration":0.059278,"end_time":"2021-08-21T17:46:50.331142","exception":false,"start_time":"2021-08-21T17:46:50.271864","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-11T09:59:49.25927Z","iopub.execute_input":"2021-11-11T09:59:49.259696Z","iopub.status.idle":"2021-11-11T09:59:49.319479Z","shell.execute_reply.started":"2021-11-11T09:59:49.259661Z","shell.execute_reply":"2021-11-11T09:59:49.318619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_thread_type = 'pqdm'\n#multi_thread_type = 'none'\n#multi_thread_type = 'pool'\nDIG_STEP = 1 \nDIG_MAX = 80\nlabels = labels[labels.frame != 0]\n\nif multi_thread_type == 'pqdm':\n    df_list = list(labels.groupby('video_frame'))\n    submission_df_list = pqdm(df_list, mapping_df, n_jobs=cpu_count())\nelif multi_thread_type == 'pool':\n    p = Pool(processes=cpu_count())\n    submission_df_list = []\n    df_list = list(labels.groupby('video_frame'))\n    with tqdm(total=len(df_list)) as pbar:\n        for this_df in p.imap(mapping_df, df_list):\n            submission_df_list.append(this_df)\n            pbar.update(1)\n    p.close()\nelse:\n    submission_df_list = []\n    df_list = list(labels.groupby('video_frame'))\n    with tqdm(total=len(df_list)) as pbar:\n        for args in df_list:\n            #print(args[0])\n            this_df = mapping_df(args)\n            submission_df_list.append(this_df)\n            pbar.update(1)\n\nlabels =  pd.concat(submission_df_list)","metadata":{"papermill":{"duration":656.578941,"end_time":"2021-08-21T17:57:46.935715","exception":false,"start_time":"2021-08-21T17:46:50.356774","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2021-11-11T09:59:49.32118Z","iopub.execute_input":"2021-11-11T09:59:49.321549Z","iopub.status.idle":"2021-11-11T10:54:56.941393Z","shell.execute_reply.started":"2021-11-11T09:59:49.321481Z","shell.execute_reply":"2021-11-11T10:54:56.94063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.dist0.hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T10:54:56.944477Z","iopub.execute_input":"2021-11-11T10:54:56.944791Z","iopub.status.idle":"2021-11-11T10:54:57.402289Z","shell.execute_reply.started":"2021-11-11T10:54:56.944754Z","shell.execute_reply":"2021-11-11T10:54:57.401491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.rot0.hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T10:54:57.405362Z","iopub.execute_input":"2021-11-11T10:54:57.405556Z","iopub.status.idle":"2021-11-11T10:54:57.818129Z","shell.execute_reply.started":"2021-11-11T10:54:57.405532Z","shell.execute_reply":"2021-11-11T10:54:57.817456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# fix data","metadata":{}},{"cell_type":"code","source":"# Some players are oriented the other way, so we'll fix that.\n# Adjust the angle according to (Endzone or Sideline) and (Home or Visitor)\n\ndef fix_bad_data(labels, tgt_col = 'o'):\n    labels['HorV'] = labels['label'].str[0]\n    labels['gamePlay_label'] = labels['video'].str.rsplit('_').str[0] + '_' + labels['label']\n    labels[\"team_o_mean\"] = labels.groupby([\"video_frame\",\"HorV\"])[tgt_col].transform(\"mean\")\n    labels[\"diff_o_vs_team\"] = np.abs(labels[tgt_col] - labels[\"team_o_mean\"])\n    labels.loc[labels[\"diff_o_vs_team\"]>180, \"diff_o_vs_team\"] = np.abs(labels.loc[labels[\"diff_o_vs_team\"]>180, \"diff_o_vs_team\"] - 360)\n    labels[\"same_direction_vs_team\"] = labels[\"diff_o_vs_team\"] < 100\n    bad_data = labels[(labels['frame']==1)&(labels.same_direction_vs_team==False)]['gamePlay_label'].unique()\n    new_tgt_col = tgt_col + '_fixed'\n    labels[new_tgt_col] = labels[tgt_col]\n    labels.loc[labels[\"gamePlay_label\"].isin(bad_data), new_tgt_col] -= 180\n    labels.loc[labels[new_tgt_col] < 0, new_tgt_col] += 360\n    \n    labels.loc[(labels['Endzone']==True)&(labels['Home']==True), new_tgt_col] = labels.loc[(labels['Endzone']==True)&(labels['Home']==True), new_tgt_col]-180\n    labels.loc[(labels['Endzone']==True)&(labels['Home']==False), new_tgt_col] = labels.loc[(labels['Endzone']==True)&(labels['Home']==False), new_tgt_col]\n    labels.loc[(labels['Endzone']==False)&(labels['Home']==True), new_tgt_col] = labels.loc[(labels['Endzone']==False)&(labels['Home']==True), new_tgt_col]-90\n    labels.loc[(labels['Endzone']==False)&(labels['Home']==False), new_tgt_col] = labels.loc[(labels['Endzone']==False)&(labels['Home']==False), new_tgt_col]-270\n    labels.loc[labels[new_tgt_col]<-180, new_tgt_col] += 360\n    labels.loc[labels[new_tgt_col]>180, new_tgt_col] -= 360\n\n    return labels\nlabels = fix_bad_data(labels, tgt_col = 'o')","metadata":{"execution":{"iopub.status.busy":"2021-11-11T10:54:57.819522Z","iopub.execute_input":"2021-11-11T10:54:57.819782Z","iopub.status.idle":"2021-11-11T10:54:58.250915Z","shell.execute_reply.started":"2021-11-11T10:54:57.819751Z","shell.execute_reply":"2021-11-11T10:54:58.250122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# calculate the gap","metadata":{}},{"cell_type":"code","source":"# calculate the difference between the helmet and the sensor\n# how many times the helmet size is off after rotation\ndef calc_xy_diff(df):\n    dig = df.rot0.values[0]\n    x_pt = df.pt0.values[0]\n    \n    a2 = df[['center_x','center_y']].values.astype(float)\n    a2_min = np.min(a2, axis=0)\n    a2_max = np.max(a2, axis=0)\n    a2_len = a2_max - a2_min\n\n    a1 = df[['gt_x','gt_y']].values.astype(float)\n    a1_rot = rotate_arr(a1, dig, 1, 1280, 720).copy()\n    a1_min = np.min(a1_rot, axis=0)\n    a1_max = np.max(a1_rot, axis=0)\n    a1_len = a1_max - a1_min\n    a1_rot_rescale = (a1_rot-a1_min)*a2_len/a1_len + a2_min \n    a1_rot2 = rotate_arr(a1_rot_rescale, 0, x_pt, 1280, 720).copy()\n\n    a1_min = np.min(a1_rot2, axis=0)\n    a1_max = np.max(a1_rot2, axis=0)\n    a1_len = a1_max - a1_min\n    a1_rot2_rescale = (a1_rot2-a1_min)*a2_len/a1_len + a2_min \n    \n    xy_diff = a1_rot2_rescale - a2\n    # normalize using mean helmet size\n    xy_diff[:,0] = xy_diff[:,0] /  df['width'].mean()\n    xy_diff[:,1] = xy_diff[:,1] /  df['height'].mean()\n        \n    return xy_diff\n\n\nresult = []\nfor video_frame, df in tqdm(labels.groupby('video_frame')):\n    xy_diff = calc_xy_diff(df)\n    df['xdiff'] = xy_diff[:,0]\n    df['ydiff'] = xy_diff[:,1]\n    result.append(df)\nlabels = pd.concat(result)","metadata":{"lines_to_next_cell":0,"scrolled":true,"execution":{"iopub.status.busy":"2021-11-11T10:54:58.252362Z","iopub.execute_input":"2021-11-11T10:54:58.252681Z","iopub.status.idle":"2021-11-11T10:55:29.478611Z","shell.execute_reply.started":"2021-11-11T10:54:58.252644Z","shell.execute_reply":"2021-11-11T10:55:29.477782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# normalization","metadata":{}},{"cell_type":"code","source":"labels['alpha'] = labels['o_fixed'] - labels['rot0']\nlabels.loc[labels['alpha']<-180, 'alpha'] += 360\nlabels.loc[labels['alpha']>180, 'alpha'] -= 360\nlabels['beta'] = labels['dir'] - labels['rot0']\nlabels.loc[labels['beta']<-180, 'beta'] += 360\nlabels.loc[labels['beta']>180, 'beta'] -= 360","metadata":{"execution":{"iopub.status.busy":"2021-11-11T10:55:29.482359Z","iopub.execute_input":"2021-11-11T10:55:29.482575Z","iopub.status.idle":"2021-11-11T10:55:29.503384Z","shell.execute_reply.started":"2021-11-11T10:55:29.48255Z","shell.execute_reply":"2021-11-11T10:55:29.502745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"norm_dict = {'xdiff': {'mean': 0, 'var': 1.0, 'max': 5.0, 'min': -5.0},\n             'ydiff': {'mean': 0, 'var': 1.0, 'max': 5.0, 'min': -5.0},\n             's': {'mean': 1.0, 'var': 2.0, 'max': 10.0, 'min': -1.0},\n             'a': {'mean': 1.0, 'var': 2.0, 'max': 10.0, 'min': -1.0},\n             'dis': {'mean': 0.1, 'var': 0.2, 'max': 1.0, 'min': -1.0},\n            }\nfor lbl in ['xdiff', 'ydiff','s','a','dis','alpha','beta']:\n    print(lbl)\n    labels[lbl].hist(bins=100)\n    plt.show()\n    if lbl in norm_dict:\n        labels.loc[labels[lbl]>norm_dict[lbl]['max'], lbl] = norm_dict[lbl]['max']\n        labels.loc[labels[lbl]<norm_dict[lbl]['min'], lbl] = norm_dict[lbl]['min']\n        labels[lbl] -= norm_dict[lbl]['mean']\n        labels[lbl] /= norm_dict[lbl]['var']\n    labels[lbl].hist(bins=100)\n    plt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-11T10:55:29.504682Z","iopub.execute_input":"2021-11-11T10:55:29.504985Z","iopub.status.idle":"2021-11-11T10:55:34.937862Z","shell.execute_reply.started":"2021-11-11T10:55:29.50495Z","shell.execute_reply":"2021-11-11T10:55:34.937068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# make coco format files","metadata":{}},{"cell_type":"code","source":"# based on https://www.kaggle.com/bamps53/create-coco-format-annotations-train-val\n\nclass NumpyEncoder(json.JSONEncoder):\n    \"\"\" \n    https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable\n    Special json encoder for numpy types\n    \"\"\"\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return json.JSONEncoder.default(self, obj)\n\nclass COCOConverter:\n    \"\"\"Class to convert competition csv to coco format.\"\"\"\n    def __init__(\n        self,\n        df: pd.DataFrame, \n        image_height: int = 720, \n        image_width: int = 1280, \n        type_agnostic: bool = True):\n        \n        self.image_height = image_height\n        self.image_width = image_width\n        self.type_agnostic = type_agnostic\n        if self.type_agnostic:\n            self.categories = [{\"id\": 1, \"name\": \"Helmet\"}]\n        else:\n            self.categories = [\n                {\"id\": 1, \"name\": \"impact_None\",},\n                {\"id\": 2, \"name\": \"impact_Helmet\"},\n                {\"id\": 3, \"name\": \"impact_Shoulder\",},\n                {\"id\": 4, \"name\": \"impact_Body\"},\n                {\"id\": 5, \"name\": \"impact_Ground\",},\n                {\"id\": 6, \"name\": \"impact_Hand\"},\n            ]         \n        self.df = self._initialize(df)\n\n    def _get_file_name(self, row: pd.Series):\n        base_name = row.video[:-4]\n        file_name = f'{base_name}_frame{row.frame:04}.jpg'\n        return file_name\n\n    def _get_bbox(self, row: pd.Series):\n        return [row.left, row.top, row.width, row.height]\n\n    def _initialize(self, df: pd.DataFrame):\n        # set category id\n        if self.type_agnostic:\n            df['impactType'] = 'Helmet'\n            df['category_id'] = 1\n        else:\n            df['category_id'] = df['impactType'].map(\n                {\n                    'None': 1,\n                    'Helmet': 2,\n                    'Shoulder': 3,\n                    'Body': 4,\n                    'Ground': 5,\n                    'Hand': 6\n                }\n            )\n        # some preprocesses\n        df['file_name'] = df[['video', 'frame']].progress_apply(self._get_file_name, axis=1)\n        df['area'] = df['width'] * df['height']\n        df['bbox'] = df[['left', 'top', 'width', 'height']].progress_apply(self._get_bbox, axis=1)\n        df['iscrowd'] = 0\n        return df\n        \n\n    def save(self, save_path):\n        \"\"\"\n        Save as coco json format.\n        But also has many supplemental items like gameKey or view.\n        \"\"\"\n        df = self.df.copy()\n        image_df = df[['gameKey', 'playID', 'view', 'video', 'frame', 'file_name']].drop_duplicates()\n        image_df['height'] = self.image_height\n        image_df['width'] = self.image_width\n        \n        # add image id to images. Note that it's called just \"id\".\n        image_df['id'] = range(1, len(image_df) + 1)\n    \n        # add image id to annotations.\n        df['image_id'] = df[['file_name']].merge(image_df[['file_name', 'id']])['id'].values\n        df['id'] = range(1, len(df) + 1)\n\n        print('start dumping...')\n        coco_annotations = dict()\n        coco_annotations['categories'] = self.categories\n        coco_annotations['images'] = [dict(row) for _, row in image_df.iterrows()]\n        coco_annotations['annotations'] = [dict(row) for _, row in df.iterrows()]\n        json.dump(coco_annotations, open(save_path, 'w'), indent=4, cls=NumpyEncoder)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T10:55:34.940184Z","iopub.execute_input":"2021-11-11T10:55:34.940452Z","iopub.status.idle":"2021-11-11T10:55:34.958734Z","shell.execute_reply.started":"2021-11-11T10:55:34.940426Z","shell.execute_reply":"2021-11-11T10:55:34.958037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ../work\ndf = labels[['video_frame','gameKey','playID','view','video','frame','label','left','width','top','height','impactType','isDefinitiveImpact','isSidelinePlayer','alpha','beta','xdiff','ydiff','x', 'y', 's', 'a', 'dis', 'o', 'dir', 'fold']]\nPH='ph5'\ntrain_coco = COCOConverter(df.copy(), type_agnostic=True)\ntrain_coco.save(f'../work/coco_train_full_{PH}.json')\n\nfor fold in range(4):\n    train_df = df[df['fold']!=fold].reset_index(drop=True).copy()\n    valid_df = df[df['fold']==fold].reset_index(drop=True).copy()\n    print('number of train annotations:', len(train_df))\n    print('number of valid annotations:', len(valid_df))\n    train_coco = COCOConverter(train_df, type_agnostic=True)\n    train_coco.save(f'../work/coco_train_fold{fold}_{PH}.json')\n    valid_coco = COCOConverter(valid_df, type_agnostic=True)\n    valid_coco.save(f'../work/coco_valid_fold{fold}_{PH}.json')","metadata":{"execution":{"iopub.status.busy":"2021-11-11T10:55:34.959994Z","iopub.execute_input":"2021-11-11T10:55:34.960402Z","iopub.status.idle":"2021-11-11T10:58:59.896561Z","shell.execute_reply.started":"2021-11-11T10:55:34.960368Z","shell.execute_reply":"2021-11-11T10:58:59.895648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# make image files","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/bamps53/create-image-dataset\ndef split_to_images(video_path):\n    video_name = os.path.basename(video_path).split('.')[0]\n    cam = cv2.VideoCapture(video_path)\n    frame_count = 1 # To make it consistant with train_labels.csv\n    while True:\n        successed, img = cam.read()\n        if not successed:\n            break\n        if debug == False or (frame_count % 10 == 1):\n            save_name = f'{SAVE_DIR}/{video_name}_frame{frame_count:04}.jpg'\n            cv2.imwrite(save_name, img)\n        frame_count += 1\n\nos.makedirs(SAVE_DIR, exist_ok=True)\nvideo_paths = sorted(glob.glob('../input/nfl-health-and-safety-helmet-assignment/train/*'))\nnum_cpu = cpu_count()\npool = Pool(num_cpu)\nwith tqdm(total=len(video_paths)) as t:\n    for _ in pool.imap_unordered(split_to_images, video_paths):\n        t.update(1)\npool.close()\npool.terminate()","metadata":{"execution":{"iopub.status.busy":"2021-11-11T10:58:59.898707Z","iopub.execute_input":"2021-11-11T10:58:59.899004Z","iopub.status.idle":"2021-11-11T11:04:38.664424Z","shell.execute_reply.started":"2021-11-11T10:58:59.898967Z","shell.execute_reply":"2021-11-11T11:04:38.66361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prepair CenterNet","metadata":{}},{"cell_type":"code","source":"!mkdir -p /kaggle/centernet\n%cd /kaggle/centernet\n\n!tar xfz ../input/nfllibs/centernet.tgz\n%cd src/lib/models/networks/DCNv2\n!python3 setup.py build develop > /dev/null 2>&1\n%cd /kaggle/centernet/src/lib/external\n!make > /dev/null 2>&1\n%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:04:38.667656Z","iopub.execute_input":"2021-11-11T11:04:38.66829Z","iopub.status.idle":"2021-11-11T11:06:02.643872Z","shell.execute_reply.started":"2021-11-11T11:04:38.668258Z","shell.execute_reply":"2021-11-11T11:06:02.642959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CenterNet","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/centernet/src\n\nn_fold = 4\nif debug:\n    n_fold = 1\n\nfor fold in range(n_fold):\n    !python main.py ctdet --exp_id nfl_ph5_fold{fold} --batch_size 4 --lr 0.156e-4  --gpus 0 --split_train ../../work/coco_train_fold{fold}_ph5.json --split_val ../../work/coco_valid_fold{fold}_ph5.json --save_all --num_epochs 5 --val_intervals 1\n# using full data, so validation can not be trusted for full model.\n!python main.py ctdet --exp_id nfl_ph5_full        --batch_size 4 --lr 0.156e-4  --gpus 0 --split_train ../../work/coco_train_full_ph5.json --split_val        ../../work/coco_valid_fold0_ph5.json       --save_all --num_epochs 5 --val_intervals 1\n\nfor fold in range(n_fold):\n    !python test.py ctdet --exp_id nfl_ph5_fold{fold} --keep_res --load_model ../exp/ctdet/nfl_ph5_fold{fold}/model_5.pth --flip_test --split_test ../../work/coco_valid_fold{fold}_ph5.json --K 50\n!python test.py ctdet --exp_id nfl_ph5_full        --keep_res --load_model ../exp/ctdet/nfl_ph5_full/model_5.pth        --flip_test --split_test ../../work/coco_train_full_ph5.json --K 50\n%cd /kaggle/working","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-11T11:06:02.646021Z","iopub.execute_input":"2021-11-11T11:06:02.646616Z","iopub.status.idle":"2021-11-11T14:00:58.882924Z","shell.execute_reply.started":"2021-11-11T11:06:02.646556Z","shell.execute_reply":"2021-11-11T14:00:58.882034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result weight file for full model\n!ls -Rl /kaggle/centernet/exp/ctdet/nfl_ph5_full/model_5.pth","metadata":{"execution":{"iopub.status.busy":"2021-11-11T14:00:58.886151Z","iopub.execute_input":"2021-11-11T14:00:58.886414Z","iopub.status.idle":"2021-11-11T14:00:59.608149Z","shell.execute_reply.started":"2021-11-11T14:00:58.886384Z","shell.execute_reply":"2021-11-11T14:00:59.607287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualization","metadata":{}},{"cell_type":"code","source":"def add_bb_to_image(image, boxes, txt=None, color=(0, 255, 0)):\n    for idx, box in enumerate(boxes.astype(int)):\n        #print(len(box.shape))\n        if len(box) == 2:\n            box = box.copy()\n            box -= 5\n            w = 10\n            h = 10\n        else:\n            w = box[2]\n            h = box[3]\n        cv2.rectangle(image, (box[0], box[1]), (box[0]+w,  box[1]+h), color, 2)\n        if txt is not None:\n            cv2.putText(\n                image,\n                f\"{txt[idx]}\",\n                (box[0], box[1]),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                0.7,\n                color,\n                thickness=1,\n            )\n        \ndef add_arrow_dgree(image, boxes, alpha, len_arrow = 30, color=(0, 255, 0)):\n    ooffset = [np.cos(np.deg2rad(alpha)), np.sin(np.deg2rad(alpha))]\n    o_point = boxes[:,:2]+len_arrow*np.array(ooffset).T\n    for box, o in zip(boxes[:,:2].astype(int), o_point.astype(int)):\n        cv2.arrowedLine(image, (box[0], box[1]), (o[0],  o[1]), color, 2)\n\nprint('GT label:')\nvideo_frame = '57584_000336_Endzone_101'\nvideo = video_frame.rsplit('_',1)[0].replace('.mp4','')\nframe = int(video_frame.rsplit('_',1)[1])\nimg = cv2.imread(f\"../train_images/{video}_frame{frame:04}.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\ndf = labels[labels.video_frame==video_frame].copy().reset_index(drop=True)\nboxes = df[['left','top','width','height']].values\narrow_arr = df['alpha']\nadd_bb_to_image(img, boxes, color=(0, 255, 0))\nadd_arrow_dgree(img, boxes, arrow_arr, color=(255, 64, 64))\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nax.imshow(img)\nplt.show()\n\nprint('predicted:')\nimg = cv2.imread(f\"../train_images/{video}_frame{frame:04}.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nhelmets = pd.read_csv('/kaggle/centernet/exp/ctdet/nfl_ph5_fold0/coco_valid_fold0_ph5.json.csv')\ndf = helmets[helmets.video_frame==video_frame].copy().reset_index(drop=True)\ndf = df[df.conf>0.3]\nboxes = df[['left','top','width','height']].values\narrow_arr = df['alpha']*180/np.pi\nadd_bb_to_image(img, boxes, color=(0, 255, 0))\nadd_arrow_dgree(img, boxes, arrow_arr, color=(255, 64, 64))\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nax.imshow(img)\nplt.show()","metadata":{"lines_to_next_cell":0,"execution":{"iopub.status.busy":"2021-11-11T14:00:59.610133Z","iopub.execute_input":"2021-11-11T14:00:59.61043Z","iopub.status.idle":"2021-11-11T14:01:00.804098Z","shell.execute_reply.started":"2021-11-11T14:00:59.610393Z","shell.execute_reply":"2021-11-11T14:01:00.803445Z"},"trusted":true},"execution_count":null,"outputs":[]}]}